{
  "article_text": [
    "functional data analysis is a branch of statistics that has been the object of many studies and developments these last years .",
    "this kind of data appears in many practical situations , as soon as one is interested in a continuous - time phenomenon for instance . for this reason ,",
    "the possible application fields propitious for the use of functional data are very wide : climatology , economics , linguistics , medicine ,  . since the works of @xcite , many developments have been investigated , in order to build theory and methods around functional data , for instance how it is possible to define the regression function and the quantile regression function of functional data , what kind of model it is possible to consider with functional data .",
    "the study of statistical models for infinite dimensional ( functional ) data has been the subject of several works in the recent statistical literature .",
    "we refer to @xcite , @xcite in the parametric model and the monograph by @xcite for the nonparametric case .",
    "there are many results for nonparametric models .",
    "for instance , @xcite established the strong consistency of kernel estimators of the regression function when the explanatory variable is functional and the response is scalar , and their study is extended to non standard regression problems such as time series prediction or curves discrimination by @xcite and @xcite .",
    "the asymptotic normality result for the same estimator in the alpha - mixing case has been obtained by @xcite .",
    "in addition to the regression function , other statistics such as quantile and mode regression could be with interest for both sides theory and practice .",
    "quantile regression is a common way to describe the dependence structure between a response variable @xmath0 and some covariate @xmath1 . unlike the regression function ( which is defined as the conditional mean ) that relies only on the central tendency of the data , conditional quantile function allows the analyst to estimate the functional dependence between variables for all portions of the conditional distribution of the response variable .",
    "moreover , quantiles are well - known by their robustness to heavy - tailed error distributions and outliers which allows to consider them as a useful alternative to the regression function .",
    "conditional quantiles for scalar response and a scalar / multivariate covariate have received considerable interest in the statistical literature . for completely observed data ,",
    "several nonparametric approaches have been proposed , for instance , @xcite introduced a smoothed estimator based on double kernel and local constant kernel methods and @xcite established its asymptotic normality . under random censoring , @xcite introduced a local linear ( ll ) estimator of quantile regression ( see @xcite for the definition ) and @xcite studied the same ll estimator .",
    "@xcite constructed a kernel estimator of the conditional quantile under independent and identically distributed ( i.i.d . )",
    "censorship model and established its strong uniform convergence rate .",
    "@xcite established the strong uniform convergence ( with rate ) of the conditional quantile function under @xmath2-mixing assumption .",
    "recently , many authors are interested in the estimation of conditional quantiles for a scalar response and functional covariate .",
    "@xcite introduced a nonparametric estimator of conditional quantile defined as the inverse of the conditional cumulative distribution function when the sample is considered as an @xmath2-mixing sequence .",
    "they stated its rate of almost complete consistency and used it to forecast the well - known el nio time series and to build confidence prediction bands .",
    "@xcite established the asymptotic normality of the kernel conditional quantile estimator under @xmath2-mixing assumption . recently , and within the same framework , @xcite provided the consistency in @xmath3 norm of the conditional quantile estimator for functional dependent data .    in this paper",
    "we investigate the asymptotic properties of the conditional quantile function of a scalar response and functional covariate when data are randomly censored and assumed to be sampled from a stationary and ergodic process . here",
    ", we consider a model in which the response variable is censored but not the covariate . besides the infinite dimensional character of the data ,",
    "we avoid here the widely used strong mixing condition and its variants to measure the dependency and the very involved probabilistic calculations that it implies",
    ". moreover , the mixing properties of a number of well - known processes are still open questions .",
    "indeed , several models are given in the literature where mixing properties are still to be verified or even fail to hold for the process they induce .",
    "therefore , we consider in our setting the ergodic property to allow the maximum possible generality with regard to the dependence setting .",
    "further motivations to consider ergodic data are discussed in @xcite where details defining the ergodic property of processes are also given .",
    "as far as we know , the estimation of conditional quantile combining censored data , ergodic theory and functional data has not been studied in statistical literature .    the rest of the paper is organized as follows .",
    "section [ s2 ] introduces the kernel estimator of the conditional quantile under ergodic and random censorship assumptions .",
    "section [ s3 ] formulates main results of strong consistency ( with rate ) and asymptotic normality of the estimator .",
    "an application to peak electricity demand interval prediction with censored smart meter data is given in section [ s4 ] .",
    "section [ s5 ] gives proofs of the main results .",
    "some preliminary lemmas , which are used in the proofs of the main results , are collected in appendix .",
    "in the censoring case , instead of observing the lifetimes @xmath4 ( which has a continuous distribution function ( df ) ) we observe the censored lifetimes of items under study . that is , assuming that @xmath5 is a sequence of i.i.d . censoring random variable ( r.v . ) with common unknown continuous df @xmath6 .",
    "then in the right censorship model , we only observe the @xmath7 pairs @xmath8 with @xmath9 where @xmath10 denotes the indicator function of the set @xmath11 .    to follow the convention in biomedical studies and as indicated before",
    ", we assume that @xmath5 and @xmath12 are independent ; this condition is plausible whenever the censoring is independent of the modality of the patients .",
    "let @xmath13 be @xmath14-valued random elements , where @xmath15 is some semi - metric abstract space .",
    "denote by @xmath16 a semi - metric associated to the space @xmath15 .",
    "suppose now that we observe a sequence @xmath17 of copies of @xmath18 that we assume to be _ stationary _ and _",
    "ergodic_. for @xmath19 , we denote the conditional probability distribution of @xmath4 given @xmath20 by : @xmath21 we denote the conditional quantile , of order @xmath22 , of @xmath4 given @xmath20 , by @xmath23    we suppose that , for any fixed @xmath19 , @xmath24 be continuously differentiable real function , and admits a unique conditional quantile .",
    "let @xmath25 , we will consider the problem of estimating the parameter @xmath26 which satisfies : @xmath27      it is clear that an estimator of @xmath26 can easily be deduced from an estimator of @xmath28 .",
    "let us recall that in the case of _ complete data _ , a well - known kernel - estimator of the conditional distribution function is given by @xmath29 where @xmath30 are the well - known nadaraya - watson weights . here",
    "@xmath31 is a real - valued kernel function , @xmath32 a cumulative distribution function and @xmath33 ( resp .",
    "@xmath34 ) a sequence of positive real numbers which decreases to zero as @xmath7 tends to infinity .",
    "this estimator given by ( [ estf1 ] ) has been introduced in @xcite in the general setting .",
    "an appropriate estimator of the conditional distribution function @xmath28 for censored data is then obtained by adapting ( [ nww ] ) in order to put more emphasis on large values of the interest random variable @xmath4 which are more censored than small one .",
    "based on the same idea as in @xcite and @xcite , we consider the following weights @xmath35 where @xmath36 .",
    "now , we consider a _ \" pseudo - estimator  _ of @xmath28 given by : @xmath37    where @xmath38 and @xmath39 where @xmath40 . in practice",
    "@xmath6 is unknown , we use the @xcite estimator of @xmath6 given by :    @xmath41 where @xmath42 are the order statistics of @xmath43 and @xmath44 is the concomitant of @xmath45 .",
    "therefore , the estimator of @xmath28 is given by : @xmath46 where @xmath47 then a natural estimator of @xmath26 is given by : @xmath48 which satisfies : @xmath49",
    "in order to state our results , we introduce some notations .",
    "let @xmath50 be the @xmath51-field generated by @xmath52 and @xmath53 the one generated by @xmath54 let @xmath55 be the ball centered at @xmath19 with radius @xmath56 .",
    "let @xmath57 so that @xmath58 is a nonnegative real - valued random variable .",
    "working on the probability space @xmath59 , let @xmath60 and @xmath61 be the distribution function and the conditional distribution function , given the @xmath51-field @xmath62 , of @xmath63 respectively .",
    "denote by @xmath64 a real random function @xmath65 such that @xmath66 converges to zero almost surely as @xmath67 similarly , define @xmath68 a real random function @xmath65 such that @xmath66 is almost surely bounded .",
    "furthermore , for any distribution function @xmath69 , let @xmath70 be the support s right endpoint .",
    "let @xmath71 be a compact set such that @xmath72 $ ] , where @xmath73      our results are stated under some assumptions we gather hereafter for easy reference .",
    "* @xmath31 is a nonnegative bounded kernel of class @xmath74 over its support @xmath75 $ ] such that @xmath76 .",
    "the derivative @xmath77 exists on @xmath75 $ ] and satisfy the condition @xmath78 for all @xmath79 $ ] and @xmath80 for @xmath81 * for @xmath19 , there exists a sequence of nonnegative random functionals @xmath82 almost surely bounded by a sequence of deterministic quantities @xmath83 accordingly , a sequence of random functions @xmath84 , a deterministic nonnegative bounded functional @xmath85 and a nonnegative real function @xmath86 tending to zero , as its argument tends to 0 , such that * * @xmath87 as @xmath88 * * for any @xmath89 , @xmath90 with @xmath91 as @xmath92 @xmath93 almost surely bounded and @xmath94 as @xmath95 , @xmath81 * * @xmath96 almost surely as @xmath97 , for @xmath81 * * there exists a nondecreasing bounded function @xmath98 such that , uniformly in @xmath99 $ ] , @xmath100 , as @xmath101 and , for @xmath102 , @xmath103 * * @xmath104 as @xmath105 * the conditional distribution function @xmath28 has a positive first derivative with respect to @xmath106 , for all @xmath19 , denoted @xmath107 and satisfies    * @xmath108 , for all @xmath19 , * for any @xmath19 , there exist @xmath109 a neighborhood of @xmath110 , some constants @xmath111 , @xmath112 and @xmath113 , such that for @xmath114 , we have @xmath115 , @xmath116 , @xmath117    * for any @xmath118 and @xmath114 , @xmath119 = \\e\\left[\\left(h^{(j)}(h_{h}^{-1}(t - t_i))\\right)^m \\mid x_i\\right ] $ ] * the distribution function @xmath32 has a first derivative @xmath120 which is positive and bounded and satisfies @xmath121 * for any @xmath122 and @xmath123 , @xmath124| < \\infty$ ] and @xmath125 is continuous in @xmath109 uniformly in @xmath106 : @xmath126 * @xmath127and @xmath128 are independent .",
    "_ comments on hypothesis _ : conditions ( a1 ) involves the ergodic nature of the data and the small ball techniques used in this paper .",
    "several examples where condition ( a1)(ii ) is satisfied are discussed in @xcite .",
    "assumption ( a3)(ii ) involves the conditional probability and conditional probability density , it means that @xmath129 and @xmath130 are continuous with respect to each variable .",
    "assumption ( a4 ) is of markov s nature .",
    "hypothesis ( a1 ) and ( a5 ) impose some regularity conditions upon the kernels used in our estimates .",
    "condition ( a6 ) stands as regularity condition that is of usual nature .",
    "the independence assumption between @xmath131 and @xmath132 , given by ( a7 ) , may seem to be strong and one can think of replacing it by a classical conditional independence assumption between @xmath131 and @xmath133 given @xmath134 . however considering the latter demands an a priori work of deriving the rate of convergence of the censoring variable s conditional law ( see @xcite ) .",
    "moreover our framework is classical and was considered by @xcite and @xcite , among others .    [ convfhat ] assume that conditions ( a1)-(a7 ) hold true and that @xmath135 then , we have @xmath136    [ theoremq ] under the same assumptions of proposition [ convfhat ] , we have @xmath137      the aim of this section is to establish the asymptotic normality which induces a confidence interval of the conditional quantiles estimator .",
    "for that purpose we need to introduce further notations and assumptions .",
    "we assume , for @xmath138 , that @xmath139 and that , for a fixed @xmath140 , the conditional variance , of @xmath141 given @xmath142 , say , + @xmath143 $ ] exists .    * * * the conditional variance of @xmath144 given the @xmath51-field @xmath145 depends only on @xmath146 , i.e. , for any @xmath147 , @xmath148 = w_2(t\\mid x_i)$ ] almost surely . * * for some @xmath149 , @xmath150<\\infty$ ] and the function + @xmath151 , @xmath152 , is continuous in a neighborhood of @xmath153 + * the distribution function of the censored random variable , @xmath6 has bounded first derivative @xmath154    [ normf ] assume that assumptions ( a1)-(a9 ) hold true and condition ( [ cond ] ) is satisfied , then we have @xmath155 where @xmath156 denotes the convergence in distribution and @xmath157 where @xmath158    [ normality ] under the same assumptions and conditions of theorem [ normf ] , we have @xmath159 @xmath160}{f^2(q_\\a(x)\\mid x))}.\\end{aligned}\\ ] ]    observe that in theorem [ normality ] the limiting variance , for a given @xmath19 , @xmath161 contains the unknown function @xmath162 , the normalization depends on the function @xmath163 which is not identifiable explicitly and the theoretical conditional quantile @xmath26 .",
    "moreover , we have to estimate the quantities @xmath164 , @xmath165 and @xmath166 .",
    "the corollary below allows us to get a suitable form of central limit theorem which can be used in practice to estimate interval prediction .",
    "first of all , we give an estimator of each unknown quantity in theorem [ normality ] . to estimate , for a fixed @xmath19 , @xmath167 the quantities @xmath168 , @xmath24 and @xmath26 should be replaced by their estimators @xmath169 , @xmath170 and @xmath171 respectively .",
    "now , using the decomposition given by assumption ( a2)(i ) , one can estimate @xmath172 by @xmath173 , where @xmath174 therefore , for a given kernel @xmath31 , an estimators of @xmath175 and @xmath176 , namely @xmath177 and @xmath178 respectively , are obtained by plug - in @xmath179 , in place of @xmath98 , in their respective expressions .      [ corr ] assume that conditions ( a1)-(a9 ) hold true , @xmath77 and @xmath180 are integrable functions and @xmath181 where @xmath182 is an estimator of the conditional density function @xmath183    the corollary [ corr ] can be now used to provide the @xmath184 confidence bands for @xmath26 which is given , for @xmath19 , by @xmath185 where @xmath186 is the upper @xmath187 quantile of the distribution of @xmath188 in the following section we give an application of this corollary for interval prediction of the daily electricity peak demand under random censorship .",
    "the evolution of peak electricity demand can be considered an important system design metric for grid operators and planners .",
    "in fact , overall electricity demand and the daily schedules of electricity usage are currently major influences on peak load . in the future",
    ", peak load will be influenced by new or increased demands such as the penetration of clean energy technologies ( wind and photovoltaic generation ) , such as electric vehicles and the increased use of electricity for heating and cooling through technologies such as heat pumps .",
    "smart grid technology , through the use of advanced monitoring and control equipment , could reduce peak demand and thus prolong and optimize use of the existing infrastructure .",
    "regularly , the electricity network constraints are evaluated on a specific area in order to prevent over - voltage problems on the grid .",
    "very localized peak demand forecasting is needed to detect voltage constraints on each node and each feeder in the low - voltage network .",
    "peak demand forecasting of aggregated electricity demand has been widely studied in statistical literature and several approaches have been proposed to solve this issue , see for instance , @xcite and @xcite for short - term peak forecasting and @xcite for long - term density peak forecasting .",
    "the arrival of automated meter reading ( amr ) allows us to receive energy demand measurement at a finite number of equidistant time points , e.g. every half - hour or every ten minutes .",
    "as far as we know , nothing has been done for household - level peak demand forecasting . in this section",
    "we are interested in the estimation of interval prediction of peak demand at the customer level . for a fixed day @xmath189 ,",
    "let us denote by @xmath190 the hourly measurements sent by the amr of some specific customer .",
    "the peak demand observed for the day @xmath189 is defined as @xmath191 the transmission of the consumed energy from the amr to the system information might be made , for instance , by wireless technology .",
    "unfortunately , in practice we can not receive on time the hole measurements for every day .",
    "in fact many sources of such kind of censorship could arise , for instance an interruption in the wireless communication during the day or a physical problem with the amr .",
    "whenever we receive the hole data one can determine the peak for that day , otherwise ( when data are censored ) we can not calculate the true peak . in such case one can delete that observation from the sample which leads to reduce the available information . in this paper",
    "we suggest to keep censored observations in our sample and use them to predict peak demand intervals .",
    "it is well - known that peak demand is very correlated with temperature measurments .",
    "figure [ load ] shows the hourly measurements of electricity demand and temperature during 1000 days .",
    "one can easily observe a seasonality in the load curve which reflects the sensitivity of energy consumption , for that customer , to weather conditions .",
    "figure [ peak ] provides a sample of 10 curves of houly temperature measures and the associated electricity demand curves .",
    "observed peak , for each day , is plotted in solid circles .",
    "we split our sample of 1000 days into learning sample containing the first 970 days and a testing sample with the last 30 days . from the learning sample we selected 30% of days within which we generated randomly the censorship .",
    "figure [ samplecens ] provides a sample of 6 censored daily load curves . for those days ,",
    "the amr send hourly electricity consumption until a certain time @xmath192 $ ] which corresponds to the time of censorship which is plotted in dashed line in figure [ samplecens ] .",
    "for a censored day , we define the censored random variable @xmath193 where @xmath194 is the time from which we do nt receive data from the smart meter .",
    "therefore , our sample is formed as follow @xmath195 , where @xmath196 is the predicted temperature curve for the day @xmath189 and @xmath197 for completely observed days and @xmath198 for censored ones . here , we investigate , for each day @xmath199 , the conditional quantile functions of @xmath200 given the predicted temperature curve @xmath196 .",
    "the @xmath201 and @xmath202 quantiles consists of the @xmath203 confidence intervals of the last 30 peak load in the testing sample , say @xmath204 $ ] for @xmath205 note that these confidence intervals are derived directly from the conditional quantile functions given by ( [ estq ] ) . to estimate conditional quantiles we chose the quadratic kernel defined by @xmath206}$ ] .",
    "because the daily temperature curves are very smooth , we chosed as semi - metric @xmath16 the @xmath207 distance between the sec ond derivative of the curves . finally , we considered the optimal bandwidth @xmath208 chosen by the cross - validation method on the @xmath209-nearest neighbors ( see @xcite , p.102 for more details ) .",
    "figure [ intervals ] provides our results for the peak load interval prediction for the testing sample .",
    "the true peaks are plotted in solid triangles .",
    "solid circles represent the conditional median values . on can easily observe that the conditional median is a consistent predictor of the peak .",
    "in fact , let us define the mean absolute prediction error as @xmath210 where @xmath211 is the true value of the peak for the day @xmath189 and @xmath212 its predicted value based on the conditional median .",
    "we obtain here @xmath213 observe that we over - estimate the peak of the 16th day .",
    "predictive intervals of the peak demand for the last 30 days.,width=529,height=283 ]",
    "the first author would like to thank scottish and southern power distribution ssepd for support and funding via the new thames valley vision project ( sset203 - new thames valley vision ) funded through the low carbon network fund .",
    "in order to proof our results , we introduce some further notations .",
    "let @xmath214\\ ] ] and @xmath215.\\ ] ]    now , lets introduce the decomposition hereafter . for @xmath19 ,",
    "set @xmath216 to get the proof of proposition [ convfhat ] , we establish the following lemmas .",
    "a sequence of random variables @xmath217 is said to be a sequence of martingale differences with respect to the sequence of @xmath51-fields @xmath218 whenever @xmath219 is @xmath220 measurable and @xmath221 almost surely .",
    "in this paper we need an exponential inequality for partial sums of unbounded martingale differences that we use to derive asymptotic results for the nadaraya - watson - type multivariate quantile regression function estimate built upon functional ergodic data .",
    "this inequality is given in the following lemma .",
    "[ fact1 ] let @xmath217 be a sequence of real martingale differences with respect to the sequence of @xmath51-fields @xmath222 , where @xmath223 is the @xmath51-filed generated by the random variables @xmath224 .",
    "set @xmath225 for any @xmath226 and any @xmath227 , assume that there exist some nonnegative constants @xmath228 and @xmath229 such that @xmath230 then , for any @xmath231 , we have @xmath232 where @xmath233    as mentioned in @xcite the proof of this lemma follows as a particular case of theorem 8.2.2 due to @xcite .",
    "we consider also the following technical lemma whose proof my be found in @xcite .",
    "[ lem1 ] assume that assumptions ( a1 ) and ( a2)(i ) , ( a2)(ii ) and ( a2)(iv ) hold true . for any real numbers @xmath234 and @xmath235 with @xmath236 as @xmath97",
    ", we have    * @xmath237 = m_j f_{i,1}(x ) + \\mathcal{o}_{a.s.}\\left ( \\frac{g_{i , x}(h_k)}{\\phi(h_k)}\\right),$ ] * @xmath238 = m_j f_{1}(x ) + o(1)$ ] , * @xmath239    [ lem2 ] assume that hypotheses ( a1)-(a2 ) and the condition ( [ cond ] ) are satisfied",
    ". then , for any @xmath19 , we have    * @xmath240 , * @xmath241    see the proof of lemma 3 in @xcite .",
    "_ of proposition [ convfhat ] _    making use of the decomposition ( [ decomp ] ) , the result follows as a direct consequence of lemmas [ diff ] and [ equiv ] below .",
    "[ diff ] under assumptions ( a1)-(a7 ) and the condition ( [ cond ] ) , we have @xmath242 [ lil ]    [ equiv ] assume that hypothesis ( a1)-(a7 ) and the condition ( [ cond ] ) hold , we have @xmath243 [ lil ]    we provide , in the following lemma , the almost sure consistency , without rate , of @xmath171 .    [ convnr ] under assumptions of proposition [ convfhat ]",
    ", we have @xmath244    _ of lemma [ convnr ] _    following the similar steps as in @xcite , the proof of this lemma is based in the following decomposition . as @xmath24 is a distribution function with a unique quantile of order @xmath245 , then for any @xmath246 , let : @xmath247 then @xmath248 now , using ( [ eq1 ] ) and ( [ verif ] ) we have @xmath249 the consistency of @xmath250 follows then immediately from proposition [ convfhat ] , the continuity of @xmath24 and the following inequality @xmath251    [ density ] under assumptions ( a1)-(a5 ) together with condition ( [ cond ] ) , we have @xmath252    _ of proposition [ density]_.    following a similar decompositions and steps as in the proof of propositions [ convfhat ] , we can easily prove the result of proposition [ density ] .",
    "_ of theorem [ theoremq ] _    using a taylor expansion of the function @xmath253 around @xmath254 we get : @xmath255 where @xmath256 lies between @xmath26 and @xmath171 . equation ( [ taylor1 ] ) shows that from the asymptotic behavior of @xmath257 as @xmath7 goes to infinity , it is easy to obtain asymptotic results for the sequence @xmath258 .",
    "subsequently , considering the statement ( [ ineq ] ) together with the statement ( [ taylor1 ] ) , we obtain @xmath259 using lemma [ convnr ] , condition ( a3 ) and the statement ( [ r1 ] ) , we get @xmath260 which is enough , while considering proposition [ convfhat ] , to complete the proof of theorem [ theoremq ] .",
    "_ of theorem [ normf ] _    to proof our result we need to introduce the following decomposition @xmath261 where @xmath262 , @xmath263 and @xmath264 first",
    ", we establish that @xmath265 and @xmath266 are negligible , as @xmath97 , whereas @xmath267 is asymptotically normal .",
    "observe that the term @xmath268 has been studied in lemma [ equiv ] , then we have @xmath269 on the other hand the term @xmath270 is equal to @xmath271 which uniformly converges almost surely to zero ( with rate @xmath272 ) by the lemma [ biais ] given in the appendix .",
    "then , we have @xmath273    now , let us consider the term @xmath267 which will provide us the asymptotic normality .",
    "for this end , we consider the following decomposition of the term @xmath267 .",
    "@xmath274 where @xmath275 - f(t\\mid x ) ( \\ell_n(x ) - \\overline{\\ell}_n(x))$ ] and @xmath276 , where @xmath277 . using results of lemma [ biais ]",
    ", we have , for any fixed @xmath19 , @xmath278 and therefore @xmath279 converge almost surely to zero when @xmath7 goes to infinity .",
    "thus , the asymptotic normality will be provided by the term @xmath280 which is treated by the lemma [ normalityq ] below .",
    "[ normalityq ] suppose that assumptions ( a1)-(a3 ) , ( a5 ) , ( a8)-(a9 ) hold , and condition ( [ cond ] ) satisfied , then we have @xmath281 where @xmath282 is defined in theorem [ normf ] .",
    "finally , the proof of theorem [ normf ] can be achieved by considering equations ( [ j1 ] ) , ( [ j3 ] ) and lemma [ normalityq ] .    of theorem",
    "[ normality ]    using the taylor expansion of @xmath170 around @xmath26 we get : @xmath283 where @xmath256 lies between @xmath26 and @xmath171 .",
    "then , by combining the consistency result given by lemma [ convnr ] and proposition [ density ] , we get @xmath284 finally , the combination of equation ( [ taylor2 ] ) and theorem [ normf ] allows us to finish the proof of theorem [ normality ] .",
    "_ of corollary [ corr ]",
    "_    first , observe that @xmath285    we have form theorem [ normality ] @xmath286 using results given by @xcite , we have @xmath287 , @xmath288 and @xmath289 as @xmath290    if in addition , we consider proposition [ density ] , lemma [ convnr ] , the consistency of @xmath291 to @xmath292 ( given in @xcite ) , one gets @xmath293 therefore , the proof of corollary [ corr ] is achieved .",
    "define the  _ pseudo - conditional bias \" _ of the conditional distribution function estimate of @xmath294 given @xmath20 as @xmath295 consider now the following quantites @xmath296 and @xmath297 it is then clear that the following decomposition holds @xmath298                by double conditioning with respect to the @xmath51-field @xmath145 and @xmath303 and using assumption ( a4 ) and the fact that @xmath304 , we get @xmath305 \\mid \\f_{i-1}\\right\\}\\\\ & = &   \\frac{1}{n\\e(\\delta_1(x ) ) } \\sum_{i=1}^n \\e\\left\\ {   \\delta_i(x ) \\e\\left [ \\delta_i \\bar{g}^{-1}(y_i)\\ ; h(h_{h}^{-1}(t - y_i))\\mid x_i , t_i \\right ] \\mid \\f_{i-1}\\right\\}\\\\ & = & \\frac{1}{n\\e(\\delta_1(x ) ) } \\sum_{i=1}^n   \\e\\left\\ { \\bar{g}^{-1}(t_i)\\ ; h(h_{h}^{-1}(t - t_i ) ) \\delta_i(x ) \\e\\left [ \\1_{\\ { t_i \\leq c_i\\ } } \\mid x_i , t_i\\right]\\mid \\f_{i-1}\\right\\}\\\\ & = &   \\frac{1}{n\\e(\\delta_1(x ) ) } \\sum_{i=1}^n   \\e\\left\\ {   \\delta_i(x)\\ ; h(h_{h}^{-1}(t - t_i ) ) \\mid \\f_{i-1}\\right\\}\\\\ \\ ] ] then , by a double conditioning with respect to @xmath145 , we have @xmath306 \\mid \\f_{i-1}\\right\\}\\\\ \\ ] ] now , because of conditions ( a3 ) and ( a5 ) , we get @xmath307 therefore , we obtain @xmath308 similarly as in lemma [ lem2 ] , it is easily seen that @xmath309 .",
    "thus , we obtain @xmath310            where @xmath315 is a martingale difference .",
    "therefore , we can use lemma [ fact1 ] to obtain an exponential upper bound relative to the quantity @xmath316 let us now check the conditions under which one can obtain the mentioned exponential upper bound . in this respect , for any @xmath317",
    ", observe that @xmath318^{p - k}\\ ] ] in view of condition ( a4 ) , @xmath319^{p - k}$ ] is @xmath62-measurable , it follows then that @xmath320 ( -1)^{p - k}\\times\\\\ \\left[\\e\\left(\\delta_i \\bar{g}^{-1}(y_i)\\ ; h(h_{h}^{-1}(t - y_i ) ) \\delta_i(x)\\mid \\f_{i-1 } \\right ) \\right]^{p - k}.\\end{aligned}\\ ] ] thus , @xmath321 \\times\\\\   & & \\left[\\e\\left(\\left|\\delta_i \\bar{g}^{-1}(y_i)\\ ; h(h_{h}^{-1}(t - y_i ) ) \\delta_i(x ) \\right| \\mid \\f_{i-1 } \\right ) \\right]^{p - k}.\\end{aligned}\\ ] ] making use of jensen inequality",
    ", one can write    @xmath322   \\left[\\e\\left(\\left|\\delta_i \\bar{g}^{-1}(y_i)\\ ; h(h_{h}^{-1}(t - y_i ) ) \\delta_i(x ) \\right| \\mid \\f_{i-1 } \\right ) \\right]^{p - k } & \\leq&\\\\   \\e\\left(\\left|\\delta_i \\bar{g}^{-1}(y_i)\\ ; h(h_{h}^{-1}(t - y_i ) ) \\delta_i(x ) \\right|^k \\mid \\f_{i-1}\\right )    \\e\\left(\\left|\\delta_i \\bar{g}^{-1}(y_i)\\ ; h(h_{h}^{-1}(t - y_i ) ) \\delta_i(x ) \\right|^{p - k } \\mid \\f_{i-1 } \\right )   & & \\end{aligned}\\ ] ]    observe now that for any @xmath123 @xmath323 in view of assumption ( a6 ) , we have @xmath324\\right\\}\\\\ & \\leq &   \\frac{1}{(\\bar{g}(\\tau))^{m-1 } } \\e[\\delta_i^m(x ) \\mid \\f_{i-1 } ] \\left [ \\sup_{x^\\prime\\in b(x , h ) } |g_{m}(x^\\prime , t)-g_{m}(x , t)| \\right.\\\\ & & \\left.+ g_{m}(x , t)\\right]\\\\ & \\leq &   \\frac{c_0}{(\\bar{g}(\\tau))^{m-1 } } \\e[\\delta_i^m(x ) \\mid \\f_{i-1}],\\end{aligned}\\ ] ] where @xmath325 is a positive constant . by using lemma [ lem1 ] , conditions ( a2)(ii ) and ( a2)(iii ) ,",
    "whenever the kernel @xmath31 and the function @xmath98 are bounded by constants @xmath326 and @xmath327 respectively , we get , for @xmath328 , @xmath329 = \\phi(h_k ) m_k f_{i,1}(x ) + o_{a.s.}(g_{i , x}(h_k ) ) = c_1 \\phi(h_k ) a_1^k f_{i,1}(x ) + o_{a.s.}(g_{i , x}(h_k)).\\ ] ] similarly , with @xmath330 , we get @xmath331 therefore , @xmath332 since @xmath333 is almost surely bounded by a deterministic quantity @xmath334 , @xmath335 almost surely and @xmath336 , for @xmath7 sufficiently large , then following the same arguments as in the proof of lemma 5 in @xcite , one may write almost surely , @xmath337 \\leq p",
    "! c^{p-2 } \\phi(h_k ) [ m b_i(x ) + 1],\\ ] ] where @xmath338 and @xmath339 a positive constant . by taking @xmath340",
    "$ ] , then @xmath341 and by assumptions ( a2)(ii ) and ( a2)(v ) one gets @xmath342 $ ] as @xmath343 we now use the lemma [ fact1 ] with @xmath344 and @xmath345 thus , for any @xmath346 , we can easily get @xmath347 where @xmath348 is a positive constant . therefore ,",
    "choosing @xmath349 large enough , we obtain @xmath350 finally , we achieve the proof by borel - cantelli lemma .",
    "@xmath351 \\ell_n(x ) } \\sum_{i=1}^n\\left|\\delta_i\\delta_i ( x)\\ ; \\ ; h(h_{h}^{-1}(t - y_i))\\left(\\frac{1}{\\bar{g}(y_i)}-\\frac{1}{\\bar{g}_n ( y_i)}\\right)\\right|\\\\ & \\leq & \\frac{\\sup_{t\\in s}|\\bar{g_n}(t)-\\bar{g}(t)|}{\\bar{g}_n(\\tau)}\\ ; \\widetilde{f}_n(t\\mid x)\\\\ \\ ] ]    since @xmath352 in conjuction with the srong law of large numbers ( slln ) and the law of the iterated logarithm ( lil ) on the censoring law ( see theorem 3.2 of @xcite , the result is an immediate consequence of lemmas [ diff ] .",
    "where , for any fixed @xmath19 , the summands in ( [ diffmart ] ) from a triangular array of stationary martingal differences with respect to the @xmath51-field @xmath62 .",
    "this allows us to apply the central limit theorem for discrete - time arrays of real - valued martingales ( see , @xcite , page 23 ) to establish the asymptotic normality of @xmath356 .",
    "therefore , we have to establish the following statements :        observe that @xmath360 - \\sum_{i=1}^n \\e[\\xi_{ni}^2 \\mid \\f_{i-1}]\\big| \\leq \\sum_{i=1}^n ( \\e[\\eta_{ni } \\mid \\f_{i-1}])^2.\\end{aligned}\\ ] ] using lemma [ lem1 ] and inequality ( [ star ] ) , we obtain @xmath361 \\big| & = & \\frac{1}{\\e(\\delta_1(x ) ) } \\left ( \\frac{\\phi(h_k)}{n}\\right)^{1/2 } \\big| \\e\\left [ \\delta_i(x)\\left ( \\frac{\\delta_i}{\\bar{g}(y_i ) } h(h_h^{-1}(t - y_i))- f(t\\mid x)\\right)\\mid \\f_{i-1}\\right ] \\big|\\nonumber\\\\ & = & o_{a.s.}\\left(h_k^\\beta + h_h^\\nu\\right ) \\left ( \\frac{\\phi(h_k)}{n}\\right)^{1/2 } \\left ( \\frac{f_{i,1}(x)}{f_1(x ) } + o_{a.s.}\\left ( \\frac{g_{i , x}(h_k)}{\\phi(h_k)}\\right)\\right ) \\end{aligned}\\ ] ] then , by ( a2)(ii)-(iii ) , we get @xmath362)^2 = o_{a.s.}\\left(\\left(h_k^\\beta + h_h^\\nu\\right)^2 \\phi(h_k)\\right).\\end{aligned}\\ ] ] the statement of ( a ) follows then if we show that @xmath363 \\stackrel{\\mathcal{\\mathbb{p}}}{\\longrightarrow } \\sigma^2(x , t).\\end{aligned}\\ ] ] to prove ( [ proba ] ) , observe that , using assumption ( a8 ) , we have @xmath364 & = & \\frac{\\phi(h_k)}{n(\\e(\\delta_1(x)))^2 } \\sum_{i=1}^n \\e\\left\\{\\delta_i^2(x ) \\left ( \\frac{\\delta_i}{\\bar{g}(y_i ) } h(h_h^{-1}(t - y_i ) ) - f(t \\mid x)\\right)^2\\mid \\f_{i-1}\\right\\ } \\\\ & = &   \\frac{\\phi(h_k)}{n(\\e(\\delta_1(x)))^2 } \\sum_{i=1}^n \\e\\left\\{\\delta_i^2(x ) \\e\\left [ \\left(\\frac{\\delta_i}{\\bar{g}(y_i ) } h(h_h^{-1}(t- y_i ) ) - f(t \\mid x_i ) \\right)^2 \\mid x_i\\right ] \\mid \\f_{i-1}\\right\\}. \\ ] ]    using the definition of the conditional variance , we have @xmath365 & = & \\mbox{var}\\left[\\frac{\\delta_i}{\\bar{g}(y_i ) } h(h_h^{-1}(t- y_i ) )   \\mid x_i\\right ] + \\nonumber\\\\ & & \\left [ \\e\\left ( \\frac{\\delta_i}{\\bar{g}(y_i ) } h(h_h^{-1}(t- y_i ) ) \\mid x_i\\right ) -",
    "f(t\\mid x)\\right]^2 \\nonumber\\\\ & = : & k_{n1 } + k_{n2}\\end{aligned}\\ ] ]    by the use of a double conditioning with respect to @xmath303 , inequality ( [ star ] ) , assumption ( a3 ) and lemma [ lem1 ] , we can easily get @xmath366.\\end{aligned}\\ ] ] let us now examine the term @xmath367 , @xmath368 - \\left [ \\e\\left ( \\frac{\\delta_i}{\\bar{g}(y_i ) } h\\left(\\frac{t - y_i}{h_h}\\right)\\mid x_i\\right)\\right]^2\\\\ & = & \\i_1 + \\i_2.\\end{aligned}\\ ] ]    the first term of the last equality can be developed as follow , @xmath369\\\\ & = & \\int_\\mathbb{r } h^2\\left(\\frac{t - z}{h_h}\\right ) \\frac{1}{\\bar{g}(z ) } f(z\\mid x_i ) dz\\\\ & = &   \\int_\\mathbb{r } h^2(v ) \\frac{1}{\\bar{g}(t - h_hv ) } df(t - h_hv\\mid x_i ) .",
    "\\end{aligned}\\ ] ] by the first order taylor expansion of the function @xmath292 around zero one gets @xmath370 where @xmath371 is between @xmath106 and @xmath372      on the other hand , by integrating by part we have @xmath375 then , under assumption ( a3 ) , we get @xmath376 and therefore @xmath377 finally , we get @xmath378 then , @xmath379 , almost surely and @xmath380 therefore , @xmath364 =   \\left(\\frac{f(t \\mid x)}{\\bar{g}(t ) } - ( f(t \\mid x))^2 \\right ) \\times \\left ( \\frac{m_2}{m_1 ^ 2}\\frac{1}{f_1(x)}\\right)=:\\sigma(x , t).\\end{aligned}\\ ] ]        the lindeberg condition results from corollary 9.5.2 in @xcite which implies that @xmath381 } ] \\leq 4n\\e[\\eta_{ni}^2 \\1_{[|\\eta_{ni}| > \\epsilon/2]}].$ ] let @xmath382 and @xmath383 such that @xmath384 .",
    "making use of hlder and markov inequalities one can write , for all @xmath246 , @xmath385 } ] \\leq \\frac{\\e|\\eta_{ni}|^{2a}}{(\\epsilon/2)^{2a / b}}.\\end{aligned}\\ ] ] taking @xmath325 a positive constant and @xmath386 ( with @xmath387 as in ( a8 ) ) , using the condition ( a8 ) and a double conditioning , we obtain @xmath388 } ] & \\leq & c_0 \\left ( \\frac{\\phi(h_k)}{n}\\right)^{(2+\\delta)/2 } \\frac{n}{(\\e(\\delta_1(x)))^{2+\\delta } } \\times\\\\ & & \\e\\left(\\left[\\big| \\frac{\\delta_i}{\\bar{g}(y_i ) } h(h_h^{-1}(t - y_i ) ) - f(t\\mid x ) \\big| \\delta_i(x ) \\right]^{2+\\delta}\\right)\\\\ & \\leq & c_0 \\left ( \\frac{\\phi(h_k)}{n}\\right)^{(2+\\delta)/2 } \\frac{n}{(\\e(\\delta_1(x)))^{2+\\delta } } \\e\\left [ ( \\delta_i(x))^{2+\\delta } \\overline{w}_{2+\\delta}(t\\mid x_i)\\right]\\\\ & \\leq & c_0   \\left ( \\frac{\\phi(h_k)}{n}\\right)^{(2+\\delta)/2 } \\frac{n\\e[(\\delta_1(x))^{2+\\delta}]}{(\\e(\\delta_1(x)))^{2+\\delta}}\\;\\ ; ( |\\overline{w}_{2+\\delta}(t\\mid x)| + o(1))\\end{aligned}\\ ] ] now , using lemma [ lem1 ] , we get @xmath388 } ]   \\leq c_0 ( n\\phi(h_k))^{-\\delta/2 } \\frac{(m_{2+\\delta})f_1(x ) + o(1)}{(m_1^{2+\\delta}f_1^{2+\\delta}(x ) ) + o(1 ) } \\ ; ( |\\overline{w}_{2+\\delta}(t\\mid x)| + o(1 ) ) = o((n\\phi(h_k))^{-\\delta/2}).\\end{aligned}\\ ] ] this completes the proof of part ( b ) and therefore the proof of lemma [ normalityq ] .",
    "de  la pea , v.  h. and gin , e. ( 1999 ) . .",
    "probability and its applications ( new york ) .",
    "springer - verlag , new york . from dependence to independence , randomly stopped processes .",
    "@xmath390-statistics and processes .",
    "martingales and beyond ."
  ],
  "abstract_text": [
    "<S> this paper , investigates the conditional quantile estimation of a scalar random response and a functional random covariate ( i.e. valued in some infinite - dimensional space ) whenever _ functional stationary ergodic data with random censorship _ are considered . </S>",
    "<S> we introduce a kernel type estimator of the conditional quantile function . </S>",
    "<S> we establish the strong consistency with rate of this estimator as well as the asymptotic normality which induces a confidence interval that is usable in practice since it does not depend on any unknown quantity . </S>",
    "<S> an application to electricity peak demand interval prediction with censored smart meter data is carried out to show the performance of the proposed estimator .    </S>",
    "<S> * keywords : * asymptotic normality , censored data , conditional quantiles , ergodic processes , functional data , interval prediction , martingale difference , peak load forecasting , strong consistency . </S>"
  ]
}