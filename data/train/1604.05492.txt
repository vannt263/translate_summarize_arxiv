{
  "article_text": [
    "the count - min sketch @xcite ( cms ) is a widely adopted structure for approximate event counting in large scale processing . with proved bounds in terms of",
    "mean absolute error and confidence , one can easily design a constant size sketch as an alternative to expensive exact counting for a setting where the total number of event types is approximately known .",
    "the cms is used in many applications , often with a focus on high frequency events @xcite . however , in the domain of text - mining , highest frequency events are often of low interest : frequent words are often grammatical , highly polysemous or without any interesting semantics , while low - frequency words are more relevant . as a matter of fact , a common regularizations in text - mining consist in computing the pointwise mutual information @xcite ( equation [ eqn : pmi ] ) or log - likelihood ratio @xcite between two words in order to estimate the importance of their cooccurrence .",
    "[ eqn : pmi ] @xmath0    where @xmath1 the probability to find word @xmath2 in the corpus and @xmath3 is the probability that both words @xmath2 and @xmath4 appear in the same cooccurrence window .",
    "this formula shows that higher frequency words will induce a relatively lower value at the end .",
    "moreover , they all use a logarithm , hinting that only the order of magnitude is important .",
    "another aspect of text - mining tasks , is that the distribution of word occurrence counts follows the zipf law , which is highly skewed : most of the words have very few occurrences .",
    "the original version of the count - min - sketch ( cms ) is focused toward minimizing the absolute error and for uniform value distributions .",
    "a variant of cms @xcite has been proposed to compensate for the high relative error for low - frequency events , but the solutions explored tend to correct the errors instead of preventing them .",
    "the count - min log proposed by @xcite improves the quality of the approximation by focusing on the relative error , while being highly efficient implementation - wise , but it does not take advantage of the zipfian distribution of counts in text - mining data .",
    "tomb structures @xcite , on the other hand , combines logarithmic counters and multi - level spectral bloom filters , and thus takes advantage of the zipfian distribution .",
    "the tomb structures are , however , not very efficient from a computational perspective , and they use max values as guards to use an upper level of counters .",
    "we have designed and implemented the _ count - min tree sketch _ ( cmts ) [ fig : hierarchie ] , a tree structure mixing * counting bits * and * barrier bits*. a counter starts at the bottom with a counting bit , if its first barrier bit equals one , then the next counting bit is also considered otherwise the counter just uses one counting bit . the counter stops at the bit right after the last contiguously activated barrier . a barrier bit , once set to @xmath5 can never be change anymore . at the very top , after the last barrier bit , a spire holds the remaining counting bits .        the general algorithms for updating and querying a sketch is unchanged . however , given the complexity of the shared bits structure , the algorithms for getting the value , incrementing or merging the counters in case of distributed computing are much more complex than a count - min sketch .",
    "obtaining a competitive implementation has been a major endeavour .",
    "the principle of getting the value of a cmts s counter is the following , and is illustrated figure [ fig : cmts_value ] :    1 .",
    "the binary values of the barrier are gathered from the bottom cell of the counter , up to the first zero barrier .",
    "if there are 2 barrier bits contiguously set ( like counter 0 in figure [ fig : cmts_value ] ) , then @xmath6 .",
    "( @xmath7 ) value bits are gathered in counter @xmath8 . if the bottom value bit is @xmath9 and the two others are @xmath5 , then the counter is @xmath10 3 .",
    "the real value can finally be computed : @xmath11        incrementing can be implemented by getting the real value , incrementing it , then putting the result back into the cmts , by setting the correct barrier and counting bits .",
    "the principle of setting the value of a cmts s counter is the following :    1 .   the new barrier @xmath12 is computed from the post increment value @xmath13 using the following formula : @xmath14 , where @xmath15 gives the bit length of @xmath16 , i.e. the position of the first set bit plus one .",
    "+ within the previous example , the new value of counter 0 is @xmath17 , @xmath18 is @xmath19 and @xmath20 .",
    "hence , @xmath21 2 .   the new counting bit",
    "is then computed by @xmath22 . here",
    "@xmath23 3 .",
    "finally , the new barrier and the new value are set : @xmath12 bits set to one for the barrier , and @xmath24 bits are set for the value using the new counting bit .",
    "+ in our example the number of barrier bits set to one remains the same ( @xmath25 ) , and @xmath26 bits are set for the value using the new counting bit @xmath27 , thus the first three counters are set to @xmath5 . in this case only the first one changes ( from @xmath9 to @xmath5 ) .",
    "the same basic get and set algorithms can be used for merging counters , even though many errors can be avoided by taking into account the possible overflows that can happen due to the conflicts in the tree structure .",
    "we have verified this hypothesis empirically in the following setting : we count unigrams and bigrams of 140 million words of the english wikipedia corpus .",
    "the small corpus analyzed contains 14.7 million distinct tokens .    in the following",
    ", the ideal perfect count storage size corresponds , for a given number of elements , at the minimal amount of memory to store them perfectly , in an ideal setting .",
    "a high - pressure setting corresponds to a setting where the memory footprint is lower than the ideal perfect count storage size for the same number of elements . for our experiment , this size is 59 megabytes ( mib ) .",
    "all sketches use an implementation which is faster than a native dictionary structure ( we use the native c++ stl implementation of an unorderedmap ) .",
    "the memory footprint of this structure is approximately 815 mib , i.e. 1380% of the ideal perfect count storage size .",
    "we compare the estimates of four sketches :    cms - cu : :    is the classical linear count - min sketch with conservative update , cmls16-cu : :    is the count - min - log sketch with conservative update using a    logarithmic base of 1.00025 and 16bits counters , and cmls8-cu : :    is the count - min - log sketch with conservative update using a    logarithmic base of 1.08 and 8bits counters .",
    "cmts - cu : :    is the count - min tree sketch with conservative update .",
    "parameters are :    128 bits base , 32 bits spire .                the results for the average relative error on simple counts of unigrams and bigrams are shown on figure [ fig : pyare ] . the bold vertical line indicates the storage needed to memorize perfectly all the counts ( the extra memory required for accessing the counters and storing the words is not taken into account ) .",
    "this experiment shows that before the perfect storage mark , the estimation error of the cmls16-cu is approximately 2 to 4 times lower than the error of the estimate of the cms - cu .",
    "the cmls8-cu error improvement over cms - cu is in the range of 7 to 12 times .",
    "however , the cmls8-cu reaches a minimal are of @xmath28 at 200% of the perfect size , and stops improving , due to the residual error caused by approximate counting .",
    "the cmts produces an are of @xmath29 at 100% of the perfect size , and @xmath30 at 300% of the perfect size .    with respect to the standard cms",
    ", cmts improves the are by a factor of 100 at the perfect size .",
    "the size improvement for an equivalent error is approximately 800% .",
    "the results for the root mean square error on simple counts of unigrams and bigrams are shown on figure [ fig : pyrmse ] . unlike logarithmic counters , which produce a high absolute error for high values , the cmts - cu always performs better than the cms - cu .      in a second step ,",
    "we compute the pointwise mutual information of the bigrams , and the error between the estimated pmi using counts from the sketch versus using the exact counts .",
    "the results for rmse on estimated pmi are illustrated in figure [ fig : pyrmsepmi ] .",
    "these results show that , with sketches near the theoretical size of a perfect storage , both cmls16-cu and cmls8-cu outperforms cms - cu by a factor of about 2 on the rmse of the pmi .",
    "cmts - cu outperforms cms - cu by a factor of 10 for the rmse at the perfect size , and the size improvement ratio is again approximately about 800% .          when the memory footprint is less than 10% of the ideal storage size , the cmts performance degrades faster than all other variants .",
    "we consider this not to be a real problem for two reasons .",
    "first , at this pressure , the rmse on the pmi is in the range @xmath31 $ ] , and the are on counts is in the range @xmath32 $ ] , which are too high for being practically useable .",
    "in this paper we show how approximate counting can take advantage of the zipfian distribution of the textual data to improve precision to an unprecedented level : improvements over standard count - min sketch range from 100 times smaller for the are , and more than 10 times smaller for the rmse on the pmi .",
    "moreover , like for the count - min sketch , an unsynchronized multithreaded implementation shows very little adversarial effect on the precision of most common sketch sizes : the effects on precision only appear at very low errors ( @xmath33 ) .",
    "amit goyal , hal daum  iii , and graham cormode .",
    "sketch algorithms for estimating point queries in nlp . in _ proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning _",
    ", pages 10931103 .",
    "association for computational linguistics , 2012 ."
  ],
  "abstract_text": [
    "<S> the count - min sketch @xcite is a widely adopted structure for approximate event counting in large scale processing . in previous works @xcite , the original version of the count - min - sketch ( cms ) with conservative update </S>",
    "<S> has been improved using approximate counters @xcite instead of linear counters . </S>",
    "<S> these structures are computationaly efficient and improve the average relative error ( are ) of a cms at constant memory footprint . </S>",
    "<S> these improvements are well suited for nlp tasks , in which one is interested by the low - frequency items . however , </S>",
    "<S> if log counters allow to improve are , they produce a residual error due to the approximation . in this paper </S>",
    "<S> , we propose the count - min tree sketch   variant with pyramidal counters , which are focused toward taking advantage of the zipfian distribution of text data . </S>"
  ]
}