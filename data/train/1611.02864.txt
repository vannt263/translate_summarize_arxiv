{
  "article_text": [
    "a minimum spanning forest ( msf ) of an edge - weighted undirected graph @xmath9 is a forest consisting of msts of the connected components of @xmath9 .",
    "dynamic msf is one of the most fundamental dynamic graph problems with a history spanning more than three decades .",
    "given a graph @xmath9 with a set of vertices and an initially empty set of edges , a data structure for this problem maintains an msf @xmath10 under two types of updates to @xmath9 , namely the insertion or the deletion of an edge in @xmath9 .",
    "after each update to @xmath9 , the data structure needs to respond with the updates to @xmath10 , if any .",
    "an msf of a graph with @xmath11 edges and @xmath0 vertices can be computed in @xmath12 deterministic time  @xcite and in @xmath13 randomized expected time  @xcite .",
    "hence , each update can be handled within either of these time bounds by recomputing an msf from scratch after each edge insertion or deletion . by exploiting the fact that the change to the dynamic graph is small in each update , better update time can be achieved .",
    "the first non - trivial data structure for fully - dynamic msf was due to frederickson  @xcite who achieved @xmath14 deterministic worst - case update time where @xmath11 is the number of edges in the graph at the time of the update . using the sparsification technique , eppstein et al .",
    "@xcite improved this to @xmath5 where @xmath0 is the number of vertices .",
    "faster amortized update time bounds exist .",
    "henzinger an king  @xcite showed how to maintain an msf in @xmath15 amortized expected update time in the restricted setting where the number of distinct edge weights is @xmath16 .",
    "the same authors later showed how to solve the general problem using @xmath17n\\log n)$ ] amortized update time  @xcite .",
    "holm et al .",
    "@xcite presented a data structure for fully - dynamic connectivity with @xmath18 amortized update time and showed how it can easily be adapted to handle decremental ( i.e. , deletions only ) msf within the same time bound .",
    "they also gave a variant of a reduction of henzinger and king  @xcite from fully - dynamic to decremental msf and combining these results , they obtained a data structure for fully - dynamic msf with @xmath19 amortized update time .",
    "this bound was slightly improved to @xmath20 in  @xcite .",
    "a lower bound of @xmath21 was shown in  @xcite and this bound holds even for just maintaining the weight of an msf in a plane graph with unit weights .      in this paper",
    ", we give a fully - dynamic msf data structure with a polynomial speed - up over the @xmath5 worst - case time bound of eppstein et al .",
    "our data structure is las vegas , always correctly maintaining an msf and achieving the polynomial speed - up w.h.p .  in each update .",
    "the following theorem states our main result .",
    "[ thm : main ] there is a las vegas data structure for fully - dynamic msf which for an @xmath0-vertex graph has an expected update time of @xmath1 for some constant @xmath2 ; in each update , this bound holds in the worst - case with probability at least @xmath3 for a constant @xmath4 that can be made arbitrarily large .",
    "we have not calculated the precise value of constant @xmath22 but it is quite small . from a theoretical perspective however , the @xmath5 bound is an important barrier to break .",
    "furthermore , a polynomial speed - up is beyond what can be achieved using word parallelism alone unless we allow a word size polynomial in @xmath0 . indeed , our improvement does not rely on a more powerful model of computation than what is assumed in previous papers . to get our result",
    ", we develop several new tools some of which we believe could be of independent interest .",
    "we sketch these tools later in this section .    as is the case for all randomized algorithms and data structures , it is important that the random bits used are not revealed to an adversary .",
    "it is well - known that if all edge weights in a graph are unique , its msf is uniquely defined .",
    "uniqueness of edge weights can always be achieved using some lexicographical ordering in case of ties . this way",
    ", our data structure can safely reveal the msf after each update without revealing any information about the random bits used .",
    "[ [ dynamic - connectivity ] ] dynamic connectivity : + + + + + + + + + + + + + + + + + + + + +    an immediate corollary of our result is a fully - dynamic data structure for maintaining a spanning forest of an unweighted graph in worst - case time @xmath1 with high probability .",
    "the previous best worst - case bound for this problem was @xmath5 by eppstein et al.@xcite ; if word - parallelism is exploited it , a slightly better bound of @xmath23 was shown by kejlberg - rasmussen et al .",
    "there are monte carlo data structures for fully - dynamic connectivty by kapron et al.@xcite and by gibb et al.@xcite which internally maintain a spanning forest in polylogarithmic time per update .",
    "however , contrary to our data structure , these structures can not reveal the spanning forest to an adversary .",
    "kapron et al .",
    "extend their result to maintaining an msf in @xmath24 time , @xmath25 , and @xmath26 when suppressing @xmath27-factors . ] per update where @xmath28 is the number of distinct weights .",
    "however , their data structure can only reveal the weight of this msf .",
    "furthermore , if all edge weights are unique , this bound becomes @xmath29 .    from our main result , we also immediately get the first las vegas fully - dynamic connectivity structure achieving w.h.p .",
    "a worst - case update time polynomially faster than @xmath30 , improving the previous best las vegas bounds of eppstein et al.@xcite and kejlberg - rasmussen et al .  @xcite . by maintaining the spanning forest using a standard dynamic tree data structure with polynomial fan - out",
    ", our connectivity structure achieves constant worst - case query time .",
    "[ [ monte - carlo - data - structure ] ] monte carlo data structure : + + + + + + + + + + + + + + + + + + + + + + + + + + +    it is easy to modify our las vegas structure to a monte carlo structure which is guaranteed to handle each update in @xmath1 worst - case time .",
    "this is done by simply terminating an update if the @xmath1 time bound is exceeded by some constant factor @xmath31 . by picking @xmath31 sufficiently large",
    ", we can ensure that this termination happens only with low probability in each update .",
    "an issue here is that once the monte carlo structure makes an error , subsequent updates are very likely to also maintain an incorrect msf .",
    "this can be remedied somewhat by periodically rebuilding new msf structures so that after a small number of updates , the data structure again maintains a correct msf with high probability ; we omit the details as our focus is on obtaining a las vegas structure .      in the rest of this section",
    ", we give an overview of our data structure as well as how the paper is organized .",
    "the description of our data structure here will not be completely accurate and we only highlight the main ideas .",
    "section  [ sec : prelim ] introduces some definitions and notation that will be used throughout the paper .",
    "[ [ restricted - decremental - msf - structure - sectionsecrestrictedmsf ] ] restricted decremental msf structure ( section  [ sec : restrictedmsf ] ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in section  [ sec : restrictedmsf ] , we present a data structure for a restricted version of decremental msf where the initial graph has max degree at most @xmath32 and where there is a bound @xmath33 on the total number of edge deletions where @xmath33 may be smaller than the initial number of edges .    the data structure maintains a recursive clustering of the dynamic graph @xmath34 where each cluster is a subgraph of @xmath9 .",
    "this clustering forms a laminar family @xmath35 ( w.r.t .",
    "subgraph containment ) and can be represented as a rooted tree where the root corresponds to the entire graph @xmath9 ; for technical reasons , we refer to the root as a level @xmath36-cluster and the children of an @xmath37-cluster are referred to as level @xmath38-clusters .",
    "the decremental msf structure of holm et al .",
    "@xcite also maintains a recursive clustering but ours differs significantly from theirs , as will become clear .    in our recursive clustering ,",
    "the vertex sets of the level @xmath39-clusters form a partition @xmath40 and w.h.p .",
    ", each level @xmath39-cluster is an expander graph and the number of inter - cluster edges is small .",
    "more specifically , the expansion factor of each expander graph is of the form @xmath41 and the number of inter - cluster edges is at most @xmath42 for some small positive constants @xmath43 and @xmath44 .",
    "such a partition is formed with a new algorithm that we present in section  [ sec : partitionexpanders ] .",
    "next , consider a list of the edges of @xmath45 sorted by decreasing weight .",
    "this list is partitioned into @xmath46 sublists each of size @xmath47 for some small constant @xmath48 .",
    "these sublists correspond to suitable subsets @xmath49 ordered by decreasing weight .",
    "each level @xmath37-cluster @xmath31 contains only edges from @xmath50 . to form the children of @xmath31 in @xmath35",
    ", we remove from @xmath31 the edges in @xmath51 and partition the remaining graph into expander graphs as above ; these expander graphs are then the children of @xmath31 .",
    "the recursion stops when @xmath31 has size polynomially smaller than @xmath0 .",
    "next , we form a new graph @xmath52 from @xmath9 as follows .",
    "initially , @xmath53 . for each @xmath37 and for each level",
    "@xmath37-cluster @xmath31 , all the edges of @xmath54 between distinct child clusters of @xmath31 are added to an auxiliary structure @xmath55 that we describe below . in @xmath52 ,",
    "their edge weights are artificially increased to a value which is smaller than the weight of any edge of @xmath9 in @xmath56 and heavier than the weight of any edge of @xmath9 in @xmath57 .",
    "the edges added to @xmath55 keep their original weights in @xmath9 .",
    "an example is shown in figure  [ fig : nestingmsf ] .",
    "now , we have an auxiliary structure @xmath55 containing a certain subset @xmath58 of edges of @xmath9 and a recursive clustering of @xmath52 . because of the way we defined edge weights in @xmath52 , an msf @xmath59 of this graph has the nice property that it is consistent with the recursive clustering : for any cluster @xmath31 , @xmath59 restricted to @xmath31 is an msf of @xmath31 .",
    "this could also have been achieved if we had simply deleted the edges from @xmath52 whose weights were artificially increased above ; however , it is important to keep them in @xmath52 in order to preserve the property that clusters are expander graphs .",
    "assuming for now that clusters do not become disconnected during updates , it follows from this property that we can maintain @xmath59 by maintaining an msf for each level independently where level @xmath38-clusters are regarded as vertices of the msf at level @xmath37 .",
    "the global msf @xmath59 is then simply the union of ( the edges of ) these msfs .",
    "each edge deletion in @xmath9 only requires an msf at one level to be updated and we show that the number of edges at this level is polynomially smaller than @xmath0 , allowing us to maintain @xmath60 in time polynomially faster than @xmath7 .",
    "we add the edges of @xmath59 to @xmath55 . in order to maintain an msf @xmath60 of @xmath9",
    ", we show that it can be maintained as an msf of the edges added to @xmath55 .",
    "this follows easily from observations similar to those of eppstein et al .",
    "@xcite combined with the fact that any edge that was increased in @xmath52 belongs to @xmath55 with its original weight .",
    "we show that the number of non - tree edges in the graph maintained by @xmath55 is polynomially smaller than @xmath0 .",
    "@xmath55 is an instance of a new data structure ( section  [ sec : fewnontreeedges ] ) which maintains an msf of a graph in @xmath61 worst - case time per update where @xmath62 is an upper bound on the number of non - tree edges ever present in the graph .",
    "hence , maintaining @xmath60 can be done in time polynomially faster than @xmath7 .",
    "the main obstacle to overcome is to handle disconnected clusters .",
    "if a level @xmath38-cluster becomes disconnected , this may affect the msf at level @xmath37 and changes can propagate all the way down to level @xmath36 ( similar to what happens in the data structure in  @xcite ) .",
    "our analysis sketched above then breaks down . however",
    ", this is where we exploit the fact that w.h.p .",
    ", each cluster @xmath31 is initially an expander graph .",
    "this implies that , assuming the total number @xmath33 of edge deletions is not too big , @xmath31 can only become disconnected along a cut where one side is small .    whenever an edge has been deleted from a cluster @xmath31 , a data structure ( sections  [ sec : decdslowcondcuts ] ,  [ sec : lowcondcutssparsification ] , and  [ sec : xprune ] )",
    "is applied which `` prunes '' off parts of @xmath31 so that w.h.p . , the pruned @xmath31 remains an expander graph .",
    "because of the property above , only small parts need to be pruned off .",
    "as we show , this can be handled efficiently for @xmath33 polynomially slightly bigger than @xmath30 . with a reduction ( section  [ sec : reduction ] ) from fully - dynamic msf to the restricted decremental msf problem with this value of @xmath33 , the main result of the paper follows .",
    "[ [ reduction - to - decremental - msf - sectionsecreduction ] ] reduction to decremental msf ( section  [ sec : reduction ] ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in section  [ sec : reduction ] , we give a reduction from fully - dynamic msf to a restricted version of decremental msf where the initial @xmath0-vertex graph has degree at most @xmath32 and where the total number of edge deletions allowed is bounded by a parameter @xmath63 .",
    "the reduction is worst - case time - preserving , meaning roughly that if we have a data structure for the restricted decremental msf problem with small worst - case update time then we also get a data structure for fully - dynamic msf with small worst - case update time .",
    "this is not the case for the reduction presented in  @xcite since it only ensures small amortized update time for the fully - dynamic structure .",
    "more precisely , our reduction states that if the data structure for the restricted decremental problem has preprocessing time @xmath64 and worst - case update time @xmath65 then there is a fully - dynamic structure with worst - case update time @xmath66 .    to get this result",
    ", we modify the reduction of holm et al .  @xcite . in their reduction , @xmath67 decremental structures ( which do not have a @xmath33-bound on the total number of edge deletions )",
    "are maintained . during updates , new decremental structures are added and other decremental structures are merged together . the main reason why this reduction is",
    "not worst - case time - preserving is that a merge is done during a single update and this may take up to linear time .",
    "we modify the reduction using a fairly standard deamortization trick of spreading the work of merging decremental structures over multiple updates .",
    "this gives the desired worst - case time - preserving reduction from fully - dynamic to decremental msf .",
    "we then show how to further reduce the problem to the restricted variant considered in section  [ sec : restrictedmsf ] .",
    "[ [ fully - dynamic - msf - with - few - non - tree - edges - sectionsecfewnontreeedges ] ] fully - dynamic msf with few non - tree edges ( section  [ sec : fewnontreeedges ] ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in section  [ sec : fewnontreeedges ] , we present a fully - dynamic msf structure which has an update time of @xmath61 where @xmath62 is an upper bound on the number of non - tree edges ever present in the graph . at a high level , this structure is similar to that of frederickson  @xcite in that it maintains a clustering of each tree of the msf @xmath60 into subtrees of roughly the same size .",
    "however , because of the bound on the number of non - tree edges , we can represent @xmath60 in a more compact way as follows .",
    "consider the union of all paths in @xmath60 between endpoints of non - tree edges . in this subforest @xmath59 of @xmath60 , consider all maximal paths whose interior vertices have degree @xmath68 .",
    "the compact representation is obtained from @xmath59 by replacing each such path by a single `` super edge '' ; see figure  [ fig : fewnontreeedges ] .",
    "the compact version of @xmath59 only has size @xmath69 .",
    "the update time for frederickson s structure is bounded by the maximum of the number of clusters and the size of each cluster so to get the @xmath70 bound , his structure maintains @xmath14 clusters each of size @xmath14 .",
    "we use essentially the same type of clustering as frederickson but for the compact representation of @xmath60 , giving @xmath71 clusters each of size @xmath71 . using a data structure similar to frederickson for the compact clustering , we show that @xmath60 can be maintained in @xmath61 worst - case time per update . here",
    "we get some additional log - factors since we make use of the top tree data structure in  @xcite to maintain , e.g. , the compact representation of @xmath60 .    [ [ partitioning - a - graph - into - expander - subgraphs - sectionsecpartitionexpanders ] ] partitioning a graph into expander subgraphs ( section  [ sec : partitionexpanders ] ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in section  [ sec : partitionexpanders ] , we present a near - linear time algorithm to partition the vertex set @xmath40 of an @xmath0-veretx constant - degree graph such that w.h.p .",
    ", each set in this partition induces an @xmath41-expander graph and the number of edges between distinct sets is @xmath42 for suitable positive constants @xmath43 and @xmath44 . the algorithm is a recursive variant of the ` partition ` algorithm of spielman and teng  @xcite .    for our application of this result in section  [ sec : restrictedmsf ]",
    ", we need each expander graph @xmath72 to respect a given partition @xmath73 of @xmath40 , meaning that each @xmath74 is either contained in @xmath75 or disjoint from @xmath75 .",
    "ensuring this is a main technical challenge in this section .",
    "[ [ decremental - maintenance - of - expander - graphs - sectionssecdecdslowcondcutsseclowcondcutssparsification - andsecxprune ] ] decremental maintenance of expander graphs ( sections  [ sec : decdslowcondcuts ] ,  [ sec : lowcondcutssparsification ] , and  [ sec : xprune ] ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in section  [ sec : decdslowcondcuts ] , we present a decremental data structure which , given an initial expander graph @xmath72 of degree at most @xmath32 ( such as one from section  [ sec : restrictedmsf ] ) , outputs after each update a subset of vertices such that at any point , there exists a subset @xmath76 of the set of vertices output so far so that @xmath77 $ ] is guaranteed to be connected ; furthermore , w.h.p .",
    ", the set output in each update is small . as we show , this is exactly what is needed in section  [ sec : restrictedmsf ] where we require clusters to be connected at all times and where the vertices pruned off each cluster is small in each update .",
    "this data structure relies on a procedure in section  [ sec : xprune ] which we refer to as ` xprune ` .",
    "it detects low - conductance cuts in a decremental graph ( which is initially an expander graph ) and prunes off the smaller side of such a cut while retaining the larger side .    `",
    "xprune ` uses as a subroutine the procedure ` nibble ` of spielman and teng  @xcite .",
    "given a starting vertex @xmath78 in a ( static ) graph , ` nibble ` computes ( approximate ) probability distributions for a number of steps in a random walk from @xmath78 .",
    "for each step , ` nibble ` attempts to identify a low - conductance cut based on the probability mass currently assigned to each vertex .",
    "spielman and teng show that if the graph has a low - conductance cut then ` nibble ` will find such a cut for at least one choice of @xmath78 .    in section  [ sec : xprune ]",
    ", we show how to adapt ` nibble ` from a static to a decremental setting roughly as follows . in the preprocessing step , ` nibble ` is started from every vertex in the graph and if a low - conductance cut is found , the smaller side is pruned off .",
    "now , consider an update consisting of the deletion of an edge @xmath79 .",
    "we can not afford to rerun ` nibble ` from every vertex as in the preprocessing step .",
    "instead we show that there is only a small set of starting vertices for which ` nibble ` will have a different execution due to the deletion of @xmath79 .",
    "we only run ` nibble ` from starting vertices in this small set ; these vertices can easily be identified since they are exactly those for which ` nibble ` in some step sends a non - zero amount of probability mass along @xmath79 in the graph just prior to the deletion .",
    "hence , we implicitly run ` nibble ` from every starting vertex after each edge deletion so if there is a low - conductance cut , ` xprune ` is guaranteed to find such a cut . when the smaller side of a cut is pruned off , a similar argument",
    "as sketched above implies that ` nibble ` only needs to be rerun from a small number of starting vertices on the larger side .    in order to have ` xprune ` run fast enough , we need an additional trick which is presented in section  [ sec : lowcondcutssparsification ] . here",
    "we show that w.h.p .",
    ", the conductance of every cut in a given multigraph is approximately preserved in a subgraph obtained by sampling each edge independently with probability @xmath80 ; this assumes that @xmath80 and the min degree of the original graph are not too small .",
    "this is somewhat similar to karger s result that the value of each cut is preserved in a sampled subgraph  @xcite .",
    "we make use of this new result in section  [ sec : xprune ] where we run ` nibble ` on the sampled subgraph rather than the full graph .",
    "combined with the above implicit maintenance of calls to ` nibble ` , this gives the desired performance of ` xprune ` .",
    "we conclude the paper in section  [ sec : conclrem ] .",
    "we consider only finite undirected graphs and unless otherwise stated , they are simple . an edge - weighted graph is written on the form @xmath81 where @xmath82 ; we sometimes simply write @xmath34 even if @xmath9 is edge - weighted .    for a simple graph or a multigraph @xmath72",
    ", @xmath75 denotes its vertex set and @xmath83 denotes its edge set .",
    "if @xmath72 is edge - weighted , we regard any subset @xmath45 of @xmath83 as a set of weighted edges and if the edge weight function @xmath84 for @xmath72 is not clear from context , we write @xmath85 instead of @xmath45 .",
    "we sometimes abuse notation and regard @xmath83 as a graph with edge set @xmath83 and vertex set consisting of the endpoints of edges in @xmath83 .",
    "when convenient , we regard the edge set of a minor of @xmath72 as a subset of @xmath83 in the natural way .    given two edge - weighted graphs @xmath86 and @xmath87 , we let @xmath88 denote the multigraph with vertex set @xmath89 and edge set @xmath90 ; if both @xmath91 and @xmath92 contain an edge between the same vertex pair @xmath93 , we keep both edges in @xmath88 , one having weight @xmath94 and the other having weight @xmath95 .    in the rest of this section ,",
    "let @xmath81 be an edge - weighted graph .",
    "component _ of @xmath9 is a connected component of @xmath9 and we sometimes regard it as a subset of @xmath40 . for @xmath96 , @xmath97 $ ] is the subgraph of @xmath9 induced by @xmath76 .",
    "when @xmath40 is clear from context , we say that @xmath76 _ respects _ another subset @xmath31 of @xmath40 if either @xmath98 or @xmath99 . we extend this to a collection @xmath73 of subsets of @xmath40 and",
    "say that @xmath76 respects @xmath73 if @xmath76 respects each set in @xmath73 ; in this case , we let @xmath100 denote the collection of sets of @xmath73 that are contained in @xmath76 . for a subgraph @xmath72 of @xmath9 , we say that @xmath72 respects @xmath31 resp .",
    "@xmath73 if @xmath75 respects @xmath31 resp .",
    "@xmath73 .",
    "a _ cut _ of @xmath9 or of @xmath40 is a pair @xmath101 such that @xmath102 and @xmath103 .",
    "when @xmath40 is clear from context , we identify a cut @xmath101 with @xmath104 or with @xmath105 .    for a subset @xmath106 of @xmath40 , denote by @xmath107 the number of edges of @xmath45 crossing the cut @xmath108 , i.e. , @xmath109 .",
    "the _ volume _",
    "@xmath110 of @xmath106 in @xmath9 is the number of edges of @xmath9 incident to @xmath106 .",
    "assuming both @xmath106 and @xmath111 have positive volume in @xmath9 , the _ conductance _",
    "@xmath112 of @xmath106 ( or of @xmath108 ) is defined as @xmath113 ( this is called sparsity in  @xcite ) .",
    "when @xmath9 is clear from context , we define , for @xmath114 , @xmath115}(s)$ ] , @xmath116}(s)$ ] , and @xmath117}(s)$ ] .",
    "we extend the definitions in this paragraph to multigraphs in the natural way .    given a real value @xmath118 , we say that @xmath9 is a _ @xmath119-expander graph _ and that @xmath9 has _ expansion _",
    "@xmath119 if for every cut @xmath108 , @xmath120 .",
    "note that if @xmath9 is connected and has constant degree then @xmath121 for every @xmath122 ; thus , in this special case , @xmath9 has expansion @xmath123 iff every such cut has conductance @xmath124 .",
    "we let @xmath125 resp .",
    "@xmath126 denote an msf resp .",
    "mst of @xmath9 ; in case this forest resp .",
    "tree is not unique , we choose the msf resp .",
    "mst that has minimum weight w.r.t .",
    "some lexicographical ordering of edge weights .",
    "for instance , consider assigning a unique index between @xmath127 and @xmath0 to each vertex .",
    "if two distinct edges @xmath128 and @xmath129 have the same weight , we regard @xmath130 as being cheaper than @xmath131 iff the index pair corresponding to @xmath132 is lexicograpically smaller than the index pair corresponding to @xmath133 .",
    "we extend @xmath125 and @xmath126 to the case where @xmath9 is a multigraph .",
    "the fully - dynamic msf problem is the problem of maintaining an msf @xmath10 of an @xmath0-vertex edge - weighted dynamic simple graph @xmath9 under updates where each update is either the insertion or the deletion of a single edge .",
    "initially , @xmath9 contains no edges .",
    "the following is well - known and easy to show for the dynamic msf problem .",
    "when an edge @xmath134 is inserted into @xmath9 , @xmath79 becomes a new tree edge ( of @xmath10 ) if it connects two distinct trees in @xmath10 .",
    "if @xmath79 has both endpoints in the same tree , it becomes a tree edge if the heaviest edge @xmath135 on the @xmath136-to-@xmath137 path in @xmath10 has weight greater than @xmath79 , and @xmath135 becomes a non - tree edge ; otherwise @xmath79 becomes a non - tree edge .",
    "no other changes happen to @xmath10 .",
    "after such an insertion , a data structure for the problem should report whether @xmath79 becomes a tree edge and if so , it should report @xmath135 if it exists .",
    "when an edge @xmath134 is deleted , if @xmath93 is a non - tree edge , no updates occur in @xmath10 .",
    "otherwise , @xmath10 is correctly updated by adding a cheapest reconnecting edge ( if any ) for the two new trees of @xmath10 containing @xmath136 and @xmath137 , respectively .",
    "the data structure should report such an edge if it exists .",
    "decremental msf is the same problem as fully - dynamic msf except that we only permit edge deletions ; here we have an initial graph with an initial msf and we allow a preprocessing step ( which in particular needs to compute the initial msf ) . both fully - dynamic and decremental msf extend to multigraphs but unless otherwise stated , we consider these problems for simple graphs .",
    "when convenient , we identify a fully - dynamic or a decremental msf structure with the dynamic graph that it maintains an msf of .",
    "our data structure uses the top tree structure of alstrup et al .",
    "we assume that the reader is familiar with this structure , including concepts like top tree clusters and top tree operations like ` create ` , ` join ` , ` split ` , ` link ` , and ` cut ` .",
    "we shall assume the word - ram model of computation with standard operations where each word consists of @xmath138 bits plus extra bits ( if needed ) to store the weight of an edge .",
    "we use this model to get a cleaner description of our data structure ; with only a logarithmic overhead , our time bound also applies for a pointer machine having the same word size and the same operations as in the word - ram model .",
    "we use the notation @xmath139 , @xmath140 , and @xmath141 when suppressing a factor of @xmath142 or @xmath143 so that , e.g. , a function @xmath144 is @xmath145 if @xmath146 and @xmath147 for some constants @xmath148 .",
    "in this section , we present our data structure for a restricted version of decremental msf where for an @xmath0-vertex graph , the total number of edge deletions allowed is upper bounded by a parameter @xmath63 . the following theorem , whose proof can be found in section  [ sec : reduction ] ,",
    "will imply that this suffices to obtain our fully - dynamic msf structure .",
    "[ thm : reduction ] let a decremental msf structure be given which for an @xmath0-vertex graph of max degree at most @xmath32 and for constants @xmath149 and @xmath150 has preprocessing time at most @xmath151 and supports up to @xmath152 edge deletions each in worst - case time at most @xmath153 . then there is a fully - dynamic msf structure which for an @xmath0-vertex dynamic graph has worst - case update time @xmath154 . if for the decremental structure the preprocessing time and update time bounds hold w.h.p .  then in each update , w.h.p .",
    "the fully - dynamic structure spends no more than @xmath154 worst - case time .",
    "we shall specify @xmath33 later but it will be chosen slightly bigger than @xmath30 .",
    "parts of the structure are regarded as black boxes here and will be presented in detail in later sections .",
    "we assume that the input graph @xmath155 has max degree at most @xmath32 and we will give a data structure with update time polynomially less than @xmath7 . in the following ,",
    "we let @xmath60 denote the decremental msf @xmath125 of @xmath9 that our data structure should maintain .",
    "a key invariant of our data structure is that it maintains a subgraph of @xmath9 having the same msf as @xmath9 but having polynomially less than @xmath0 non - tree edges at all times .",
    "this allows us to apply the data structure of the following theorem whose proof is delayed until section  [ sec : fewnontreeedges ] .",
    "[ thm : msffewnontreeedges ] let @xmath156 be a dynamic @xmath0-vertex graph undergoing insertions and deletions of weighted edges where the initial edge set @xmath157 need not be empty and where the number of non - tree edges never exceeds the value @xmath62 .",
    "then there is a data structure which after @xmath158 worst - case preprocessing time can maintain @xmath159 in @xmath160 worst - case time per update where an update is either the insertion or the deletion of an edge in @xmath72 or a batched insertion of up to @xmath161 edges in @xmath72 , assuming this batched insertion does not change @xmath10 .",
    "the data structure in theorem  [ thm : msffewnontreeedges ] is at a high level similar to those of frederickson  @xcite and eppstein et al .",
    "@xcite and for this reason , we shall refer to each instance of it as an _ ffe structure _ ( fast frederickson / eppstein et al . ) and denote it by @xmath162 .",
    "let @xmath163 be some small positive constant which will be specified later ; for now , we only require it to be chosen such that @xmath46 is an integer that divides @xmath11 . in the first part of the preprocessing , we sort the weights of edges of the initial graph @xmath9 in non - decreasing order and assign a rank to each edge between @xmath39 and @xmath164 according to this order , i.e. , the edge of rank @xmath39 has minimum weight and the edge of rank @xmath165 has maximum weight .",
    "we redefine @xmath166 such that @xmath167 equals the rank of each edge @xmath79 .",
    "msf @xmath60 w.r.t .",
    "these new weights is also an msf w.r.t .  the original weights and uniqueness of edge weights implies uniqueness of @xmath60 . in particular , @xmath60 does not reveal any information about the random bits used by our data structure so we may assume that the sequence of edge deletions in @xmath9 is independent of these bits .",
    "we compute the initial msf @xmath60 using prim s algorithm implemented with binary heaps",
    ". it will be convenient to assume that each component of the initial graph @xmath9 contains at least @xmath168 vertices .",
    "this can be done w.l.o.g .  since we can apply the data structure of eppstein et al .  for every other component , requiring a worst - case update time of @xmath169 which is polynomially less than @xmath30 .",
    "next , frederickson s ` findclusters ` procedure  @xcite is applied to @xmath60 , giving a partition of @xmath40 into subsets each of size between @xmath168 and @xmath170 and each inducing a subtree of @xmath60 ; here we use the fact that @xmath9 and hence @xmath60 has degree at most @xmath32 .",
    "let @xmath171 denote the collection of these subsets .",
    "for each @xmath172 , we refer to @xmath173 $ ] as an _",
    "@xmath60-cluster_. we denote by @xmath174 the union of edges of @xmath60-clusters .    for @xmath175 ,",
    "let @xmath51 be the set of edges of @xmath176 of weights in the range @xmath177 .",
    "note that @xmath178 ; this set is only defined to give a cleaner description of the data structure . for @xmath175 , let @xmath179 , @xmath180 , @xmath181 , and @xmath182 .",
    "[ [ computing - a - laminar - family - of - clusters ] ] computing a laminar family of clusters : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    next , a recursive procedure is executed which outputs a family @xmath35 of subgraphs of @xmath9 that all respect @xmath73 .",
    "we refer to these as _ level @xmath37-clusters _ where @xmath183 .",
    "collectively ( i.e. , over all @xmath37 ) , we refer to them as _",
    "@xmath35-clusters _ in order to distinguish them from @xmath60-clusters .",
    "family @xmath35 will be laminar w.r.t .",
    "subgraph containment .",
    "we need the following theorem whose proof can be found in section  [ sec : partitionexpanders ] .",
    "[ thm : rcpartition ] let @xmath72 be a constant - degree graph with vertex set @xmath40 and let @xmath73 be a partition of @xmath40 into subsets each of size @xmath184 and each inducing a connected subgraph of @xmath72 .",
    "let @xmath2 and @xmath185 be given constants .",
    "there is an algorithm which , given @xmath72 , @xmath73 , and any non - empty set @xmath96 of size @xmath186 respecting @xmath73 , outputs a partition @xmath187 of @xmath76 respecting @xmath73 such that with probability at least @xmath188 , the following three conditions hold for suitable @xmath189 and @xmath190 :    1 .   @xmath191 $ ] is a @xmath119-expander graph for each @xmath192 , 2 .",
    "the number of edges of @xmath72 between distinct sets of @xmath187 is at most @xmath193 , and 3 .",
    "the worst - case time for the algorithm is @xmath194 .",
    "we shall pick @xmath195 in theorem  [ thm : rcpartition ] in the following .",
    "we may assume that @xmath196 .",
    "the recursive procedure takes as input an integer @xmath37 and a set of level @xmath37-clusters and outputs the level @xmath197-clusters contained in these level @xmath37-clusters for @xmath198 .",
    "the first recursive call is given as input @xmath199 and @xmath9 as the single level @xmath36-cluster .",
    "in the general recursive step , for each level @xmath37-cluster @xmath31 , the algorithm of theorem  [ thm : rcpartition ] is applied with @xmath200 , @xmath201 , and @xmath202 , giving a partition @xmath203 of @xmath204 respecting @xmath171 such that for suitable @xmath205 and @xmath206 , the following holds w.h.p .",
    ",    1 .   @xmath207 $ ] is a @xmath119-expander graph for each @xmath208 , and 2 .",
    "the are at most @xmath209 edges of @xmath210 between distinct sets in @xmath203 .",
    "the graphs @xmath207 $ ] for all @xmath208 are defined to be level @xmath38-clusters . if @xmath211 the procedure recurses with @xmath212 and with these level @xmath38-clusters .",
    "the recursion stops when level @xmath37-cluster @xmath31 has at most @xmath213 edges of @xmath214 ; this ensures that the lower bound on @xmath215 in theorem  [ thm : rcpartition ] is satisfied for each application of this theorem .",
    "the laminar family @xmath35 of all the clusters is represented as a rooted tree in the natural way where the root is the single level @xmath36-cluster @xmath9 and a level @xmath37-cluster has as children the level @xmath38-clusters contained in it . for any subset @xmath10 of edges of @xmath45 and for any @xmath35-cluster @xmath31 , we let @xmath216 be the subset of edges of @xmath10 belonging to @xmath31 and having endpoints in distinct children of @xmath31 in @xmath35 ; note that @xmath217 if @xmath31 is a leaf of @xmath35 .",
    "we let @xmath58 be the union of @xmath218 over all @xmath37 and all level @xmath37-clusters @xmath31 .",
    "next , a new graph @xmath219 is formed where for each level @xmath37-cluster @xmath31 the weight @xmath220 of each @xmath221 is set to @xmath222 ; note that this ensures that for all @xmath223 and all @xmath224 , @xmath225 . for all other edges @xmath79 of @xmath45 , we define @xmath226 .",
    "an example is shown in figure  [ fig : nestingmsf ] .",
    "forest @xmath227 is computed and an ffe structure @xmath228 is initialized .",
    "we now describe how our data structure handles updates . first , we extend some of the above definitions from the preprocessing step to any point in the sequence of updates as follows .",
    "@xmath60-clusters are the components ( trees ) of the graph consisting of the initial @xmath60-clusters minus the edges removed so far . hence ,",
    "when an edge of an @xmath60-cluster @xmath31 is removed , the two new trees obtained replace @xmath31 as @xmath60-clusters .",
    "@xmath35-clusters are the initial @xmath35-clusters minus the edges deleted so far .",
    "note that @xmath35 remains a laminar family over all updates .",
    "finally , @xmath58 , @xmath52 , and @xmath174 are the initial @xmath58 , @xmath52 , and @xmath174 , respectively , minus the edges removed so far .",
    "data structure @xmath229 maintains an msf for the dynamic graph @xmath230 .",
    "lemma  [ lem : msfdecompose ] below implies that this msf is @xmath60 .",
    "to show it , we use the following result of eppstein et al .  @xcite .",
    "[ lem : msfsparsification ] let @xmath72 be an edge - weighted multigraph and let @xmath231 and @xmath232 be two subgraphs of @xmath72 such that @xmath233 .",
    "then @xmath234 .",
    "the result was not stated for multigraphs in  @xcite but immediately generalizes to these .",
    "[ lem : msfdecompose ] let @xmath235 be an edge - weighted graph , let @xmath236 , and let @xmath237 where @xmath238 for all @xmath239 and @xmath240 for all @xmath241",
    ". then @xmath242 .    by lemma  [ lem : msfsparsification ]",
    ", we have @xmath243 } ) } }            = { \\ensuremath{\\mbox{msf}({e_h'(w_h)\\cup h ' } ) } }            = { \\ensuremath{\\mbox{msf}({e_h'(w_h)\\cup{\\ensuremath{\\mbox{msf}({h'})}}})}}.\\ ] ]    with the above definitions , @xmath244 .",
    "as we show later , the number of non - tree edges of @xmath229 is at all times polynomially smaller than @xmath0 .",
    "hence , by theorem  [ thm : msffewnontreeedges ] , it suffices to give an efficient data structure to maintain @xmath227 .",
    "we present this in the following . in the rest of this section ,",
    "all edge weights are w.r.t .",
    "@xmath245 unless otherwise stated .",
    "an advantage of considering @xmath52 rather than @xmath9 is that @xmath227 behaves nicely w.r.t .  the laminar family @xmath35 as the following lemma shows .    [ lem : msflaminar ] for any @xmath35-cluster @xmath31 , @xmath246 = { \\ensuremath{\\mbox{msf}({c})}}$ ] .",
    "observe that @xmath247 .",
    "hence , we can obtain @xmath227 by running a kruskal - type algorithm on the edges of @xmath248 where the initial forest has edge set @xmath174 .    given a level @xmath37-cluster @xmath31",
    ", we have @xmath249 . by definition of @xmath245 ,",
    "all edges of @xmath250 are cheaper than all other edges of @xmath251 incident to @xmath31 .",
    "hence , kruskal s algorithm processes all edges of @xmath252 before any other edge of @xmath251 incident to @xmath31 so it will form the spanning forest @xmath246 $ ] of @xmath31 as part of @xmath227 .",
    "it must be a cheapest such spanning forest of @xmath31 since otherwise , the cost of @xmath227 could be reduced .",
    "we now present a data structure @xmath55 that maintains @xmath227 . at a high level , this structure is similar to @xmath229 as it makes use of an ffe structure .",
    "the edge set of @xmath55 is maintained using smaller dynamic structures for the various @xmath35-clusters ; these structures are described below .",
    "we say that a level @xmath37-cluster is _ small _ if initially it contained at most @xmath253 edges of @xmath214 ; otherwise , the cluster is _",
    "large_. note that a large cluster must have children in @xmath35 since otherwise , it is a level @xmath254-cluster and @xmath255 . thus small clusters are leaves in @xmath35 while large clusters are interior nodes .",
    "we shall make the simplifying assumption that each large cluster is connected over all updates .",
    "this is a strong assumption and we shall later focus on how to get rid of it .",
    "part of @xmath55 is a data structure @xmath256 which maintains @xmath257 where @xmath258 is the union of all small @xmath35-clusters .",
    "this structure consists of an ffe structure ( in fact , frederickson s original structure suffices here ) for each small @xmath35-cluster which is initialized during preprocessing . for large clusters , we use more involved data structures which we present in the following .      for each level @xmath37 and each large level @xmath37-cluster @xmath31",
    ", we define the _ compressed _",
    "level @xmath37-cluster @xmath259 as the multigraph obtained from @xmath31 as follows .",
    "first , each large child cluster @xmath260 of @xmath31 is contracted to a single vertex called a _",
    "large cluster vertex _ , and self - loops incident to this new vertex are removed .",
    "second , for each small child cluster @xmath260 of @xmath31 , its edge set is replaced by @xmath261 .",
    "figure  [ fig : compressedcluster](a ) and ( b ) illustrate @xmath31 and @xmath259 , respectively .",
    "we define three subgraphs of @xmath259 :    @xmath262 : : :    consists of the union of @xmath261    over all small child clusters @xmath260 of @xmath31 as    well as the edges of @xmath259 with both endpoints in    small child clusters of @xmath31    ( figure  [ fig : compressedcluster](c ) ) , @xmath263 : : :    consists of the large cluster vertices of @xmath259 ,    @xmath261 for each small child    cluster @xmath260 of @xmath31 , and the edges of    @xmath259 having a large cluster vertex as one    endpoint and having the other endpoint in a small child cluster of    @xmath31 ( figure  [ fig : compressedcluster](d ) ) , @xmath264 : : :    consists of the subgraph of @xmath259 induced by its    large cluster vertices ( figure  [ fig : compressedcluster](e ) ) .",
    "note that @xmath262 , @xmath263 , and @xmath264 together cover all vertices and edges of @xmath259 .",
    "define @xmath265 , @xmath266 , and @xmath267 .",
    "data structure @xmath55 will use an ffe structure for the graph defined as the union of @xmath268 and of @xmath269 , @xmath270 , and @xmath271 over all compressed clusters @xmath259 .",
    "this ffe structure , which we denote by @xmath272 , is initialized during preprocessing . by lemma  [ lem : msflaminar ] , it will maintain @xmath227 as desired . as we show later",
    ", @xmath272 contains polynomially less than @xmath0 non - tree edges at all times so that it can be updated efficiently .",
    "let @xmath259 be a given compressed cluster .",
    "it remains to give efficient data structures that maintain @xmath269 , @xmath270 , and @xmath271 .",
    "we maintain @xmath269 using an ffe structure for @xmath262 , initialized during preprocessing . in the following , we present structures maintaining @xmath270 and @xmath271 .      to maintain @xmath270 and @xmath271 efficiently",
    ", we shall exploit the fact that both @xmath263 and @xmath264 have a subset of only @xmath273 large cluster vertices and ( ignoring in @xmath263 the edges of @xmath261 for all small child clusters @xmath260 of @xmath31 ) all edges of these graphs are incident to this small subset .",
    "forest @xmath270 is represented as a top tree . in the following , we shall abuse notation slightly and refer to this top tree as @xmath270 . each top tree cluster @xmath274 of @xmath270",
    "has as auxiliary data a pair @xmath275 where @xmath276 is the set of large cluster vertices of @xmath259 contained in @xmath274 and @xmath277 contains , for each large cluster vertex @xmath278 a minimum - weight edge @xmath279 having @xmath137 as one endpoint and having the other endpoint in @xmath274 ; if no such edge exists , @xmath279 is assigned some dummy edge @xmath280 whose endpoints are undefined and whose weight is infinite .    in order to maintain @xmath270 , we first describe how to maintain auxiliary data under the basic top tree operations ` create ` , ` split ` , and ` join ` for @xmath270 .",
    "when ` create ` outputs a new cluster @xmath274 consisting of a single edge , we form @xmath276 as the set of at most one large cluster vertex among the endpoints of the edge . then @xmath277 is computed by letting @xmath279 be a cheapest edge incident to both @xmath137 and @xmath274 ( or @xmath280 if undefined ) , for each large cluster vertex @xmath278 .    when a ` split`@xmath281 operation is executed for a top tree cluster @xmath274",
    ", we simply remove @xmath276 and @xmath277 . finally , when two top tree clusters @xmath282 and @xmath283 are joined into a new top tree cluster @xmath274 by ` join`@xmath284",
    ", we first form the set @xmath285",
    ". then we form @xmath277 by letting @xmath279 be an edge of minimum weight among @xmath286 and @xmath287 , for each large cluster vertex @xmath278 .",
    "we are now ready to describe how to maintain @xmath270 when an edge @xmath79 is deleted from @xmath263 .",
    "[ [ deleting - a - non - tree - edge ] ] deleting a non - tree edge : + + + + + + + + + + + + + + + + + + + + + + + + +    assume first that @xmath288 .",
    "then the topology of @xmath270 is unchanged .",
    "if @xmath79 is incident to a large cluster vertex then let @xmath289 be the other endpoint of @xmath79 ( @xmath289 can not be a large cluster vertex ) ; in this case the auxiliary data for each top tree cluster containing @xmath289 needs to be updated .",
    "we do this bottom - up by first applying ` create ` to replace each leaf cluster containing @xmath289 with a new leaf cluster and applying ` join ` to update all non - leaf clusters containing @xmath289 .",
    "note that the new set of top tree clusters is identical to the old set , only their auxiliary data are updated .",
    "[ [ deleting - a - tree - edge ] ] deleting a tree edge : + + + + + + + + + + + + + + + + + + + + +    now assume that @xmath79 belongs to a tree @xmath290 of @xmath270 .",
    "top tree @xmath270 is updated with the operation ` cut`@xmath291 .",
    "if @xmath79 belongs to @xmath261 for some small child cluster @xmath260 of @xmath31 then @xmath79 also belongs to @xmath268 . in this case , if a reconnecting edge was found for @xmath268 , it is added to @xmath270 as a reconnecting edge for @xmath290 . by lemma  [ lem : msflaminar ] , this is the cheapest reconnecting edge for @xmath290 .",
    "top tree @xmath270 is updated using a ` link`-operation .",
    "now assume that no reconnecting edge was found in @xmath268 ( which may also happen if @xmath79 did not belong to @xmath261 for any small child cluster @xmath260 of @xmath31 ) .",
    "let @xmath292 and @xmath293 be the two subtrees of @xmath294 . after having computed top trees for @xmath292 and @xmath293 ,",
    "let @xmath282 resp .",
    "@xmath283 be the root top tree cluster representing @xmath292 resp .",
    "a cheapest reconnecting edge ( if any ) is of one of the following two types : a cheapest edge connecting a large cluster vertex in @xmath293 with a vertex of @xmath282 or a cheapest edge connecting a large cluster vertex in @xmath292 with a vertex of @xmath283 .",
    "we shall only describe how to identify the first type of edge as the second type is symmetric .",
    "first , we identify from @xmath282 the set @xmath295 . then the desired edge is identified as an edge @xmath296 of minimum weight over all large cluster vertices @xmath297 .",
    "having found a cheapest reconnecting edge @xmath298 for @xmath290 , if @xmath299 , we add @xmath298 to @xmath270 to reconnect @xmath290 . in the top tree , this is supported by a ` link`-operation .",
    "maintaining @xmath271 is quite simple . for all distinct pairs of large cluster vertices @xmath93 in @xmath259 ,",
    "the initial set of edges between @xmath136 and @xmath137 in @xmath264 are stored during preprocessing in a list @xmath300 sorted in increasing order of weight . a graph @xmath301 is formed , containing a cheapest edge ( if any ) between each such pair @xmath93 .",
    "the initial @xmath271 is computed from @xmath301 using prim s algorithm with binary heaps . whenever an edge @xmath93 is deleted from @xmath301 ,",
    "it is also deleted from @xmath300 and a cheapest remaining edge ( if any ) between @xmath136 and @xmath137 is identified from @xmath300 and added to @xmath301 . whenever a tree edge is deleted from @xmath271 ,",
    "a simple linear - time algorithm is used to find a cheapest replacement edge by scanning over all edges of @xmath301 .",
    "we now analyze the performance of the data structure presented above .",
    "we start with the preprocessing step .",
    "prim s algorithm finds @xmath60 in @xmath302 time .",
    "having found @xmath60 , @xmath171 can be found in @xmath303 time since this is the time bound for frederickson s ` findclusters ` procedure .    the time to compute @xmath35",
    "is dominated by the total time spent by the algorithm in theorem  [ thm : rcpartition ] . for each @xmath37 , the total vertex size of all level @xmath37-clusters",
    "is at most @xmath0 since their vertex sets are pairwise disjoint .",
    "hence , the total size of all sets @xmath76 given to the algorithm is @xmath304 . by the third part of theorem  [ thm : rcpartition ] , w.h.p .",
    "the total time for computing @xmath35 is @xmath305 .    by theorem  [ thm : msffewnontreeedges ]",
    ", the ffe structures @xmath229 and @xmath256 can be initialized in @xmath306 worst - case time .",
    "this is also the case for the ffe structures of graphs @xmath262 since these graphs are compressed versions of subgraphs of @xmath9 that are pairwise both vertex- and edge - disjoint , implying that their total size is @xmath303 . finally , to bound the time to initialize @xmath307 , note that the graph consisting of the union of @xmath268 and msfs @xmath269 , @xmath270 , and @xmath271 over all @xmath259 contain a total of @xmath303 edges and at most @xmath0 vertices of @xmath9 .",
    "furthermore , the total number of large cluster vertices is @xmath308 .",
    "hence , the total worst - case time spent on initializing ffe structures is @xmath309 .",
    "we conclude that w.h.p . , the total worst - case preprocessing time is @xmath310 .",
    "now we bound the update time of our data structure .",
    "we start by bounding the time to update @xmath229 after a single edge deletion in @xmath9 .",
    "recall that @xmath228 .",
    "a single edge deletion in @xmath9 can cause at most one edge deletion in @xmath58 , at most one edge deletion in @xmath227 , and ( in case a tree edge was deleted from @xmath227 ) at most one edge insertion in @xmath227 .",
    "hence , @xmath230 and thus @xmath229 can be updated with a constant number of edge insertions / deletions .    by theorem  [ thm : msffewnontreeedges ] , in order to bound the time to update @xmath229 after a single edge insertion / deletion",
    ", we need to bound the number of non - tree edges of @xmath229 .",
    "we do this in the following lemma .    at any time during the sequence of updates , the number of non - tree edges of @xmath229 is @xmath311 .    observe that edges of @xmath174 are edges of @xmath60 ( since they belonged to @xmath60 initially and since we only delete edges from @xmath9 ) .",
    "in particular , edges of @xmath227 belonging to @xmath174 are tree edges of @xmath229 . furthermore",
    ", if each @xmath60-cluster is contracted to a vertex in @xmath227 then the number of remaining edges is at most the number of @xmath60-clusters minus @xmath127 .",
    "the initial number of @xmath60-clusters in a tree of @xmath60 is @xmath312 and the number of @xmath60-clusters can increase by at most @xmath127 per edge deletion in @xmath9 . since we have a bound of @xmath33 on the total number of edge deletions in @xmath9 , we conclude that at all times , the number of non - tree edges of @xmath229 is @xmath313 .",
    "next , we bound @xmath314 . by the second property of theorem  [ thm : rcpartition ] , for @xmath315 , and for each non - leaf level @xmath37-cluster @xmath31 , @xmath316 where @xmath203 is the partition of @xmath204 found by the algorithm in theorem  [ thm : rcpartition ] . by a telescoping sums argument applied to laminar family @xmath35 , it follows that @xmath317 .",
    "since @xmath318 , the lemma follows .    to also bound the time to update @xmath55",
    ", we similarly bound its number of non - tree edges .",
    "observe that the compressed clusters are pairwise edge - disjoint .",
    "since we assume that no large cluster becomes disconnected , it follows that at most one compressed cluster is affected by an edge deletion in @xmath9 ; let @xmath259 be such a cluster",
    ". then the number of edge insertions / deletions in each of @xmath269 , @xmath270 , and @xmath271 is @xmath8 .",
    "similarly , the number of edge insertions / deletions in @xmath268 is @xmath8 .",
    "hence , the number of updates required in @xmath55 is @xmath8 so it suffices to bound the number of non - tree edges of @xmath55 .    at any time during the sequence of updates , the number of non - tree edges of @xmath55 is @xmath319 .    at any time , the number of @xmath60-clusters is @xmath319 and the edges of @xmath60-clusters are all tree edges in @xmath55 .",
    "contracting @xmath60-clusters to vertices in @xmath268 gives a forest with @xmath319 edges .",
    "for @xmath320 , consider the graph consisting of the union of @xmath321 over all compressed clusters @xmath259 and @xmath261 over all small clusters @xmath260 .",
    "this graph is a forest and contracting all @xmath60-clusters gives a forest with @xmath319 edges .",
    "this shows the lemma .    combining the above with theorem  [ thm : msffewnontreeedges ]",
    ", it follows that the total time to update @xmath229 and @xmath55 is @xmath322 .",
    "furthermore , @xmath256 can be maintained within this time as well since each small cluster has size @xmath312 and at most one such cluster is affected by an edge deletion in @xmath9 .",
    "we now have the following corollary .",
    "[ cor : timeffestructs ] after each edge deletion in @xmath9 , the total time to update @xmath229 , @xmath55 , and @xmath256 is @xmath322 .",
    "[ [ maintaining - m_1-forests ] ] maintaining @xmath323-forests : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    it remains to bound the time over all @xmath259 to update forests @xmath269 , @xmath270 , and @xmath271 after an edge deletion in @xmath9 .",
    "we first focus on @xmath323-forests .",
    "note that at most one forest @xmath269 needs to be updated after such a deletion .",
    "since the edges of @xmath261 over all child clusters @xmath260 of @xmath31 are all tree edges of @xmath269 , the number of non - tree edges in @xmath262 is @xmath324 so maintaining the @xmath323-forests can be done in @xmath325 per edge deletion in @xmath9 .",
    "[ [ maintaining - m_2-forests ] ] maintaining @xmath326-forests : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the data structure for maintaining @xmath326-forests is described in section  [ subsubsec : maintainm2 ] . to efficiently support the `",
    "join ` of top tree clusters , the large cluster vertices of each compressed cluster @xmath259 are arbitrarily labeled from @xmath127 to @xmath16 where @xmath16 is the number of large cluster vertices in @xmath259 . for each top tree cluster @xmath274 of @xmath270",
    ", the set @xmath276 is represented as an array of @xmath16 bits where the @xmath37th bit is @xmath127 iff large cluster vertex @xmath37 belongs to @xmath276 .",
    "note that @xmath327 .",
    "the set @xmath277 is represented as an array of length @xmath16 where the @xmath37th entry contains the edge @xmath328 where @xmath137 is the @xmath37th large cluster vertex .    with this representation of auxiliary data ,",
    "it is easy to see that each ` join ` of two top tree clusters in @xmath270 and each ` split ` can be done in @xmath329 time .",
    "since @xmath9 has constant degree , we can support ` create ` within this time bound as well .",
    "no more than @xmath67 of these operations are required in @xmath270 in each update , taking a total of @xmath330 time . from our description in section  [ subsubsec :",
    "maintainm2 ] , it is easy to see that finding a minimum - weight replacement edge can be done in linear time in the size of the auxiliary data stored in two top tree clusters , i.e. , in time @xmath331 .    we conclude that maintaining @xmath326-forests can be done in @xmath332 time per edge deletion in @xmath9 .    [ [ maintaining - m_3-forests ] ] maintaining @xmath333-forests : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as observed above , the number of large cluster vertices in a compressed cluster @xmath259 is @xmath331 and hence @xmath334 . maintaining the graph @xmath301",
    "can be done in constant time per edge deletion in @xmath9 and the brute - force algorithm to find a cheapest replacement edge in @xmath271 can be done in @xmath335 time .",
    "we can now summarize the results of this subsection .",
    "[ lem : mainperformance ] assume that no large @xmath35-cluster becomes disconnected during a sequence of at most @xmath33 edge deletions to @xmath9",
    ". then w.h.p .",
    ", the data structure of this section has worst - case preprocessing time @xmath305 and worst - case update time @xmath336 .",
    "we now remove the simplifying assumption that large clusters do not become disconnected . to handle the general case ,",
    "the following theorem is crucial ; its proof can be found in section  [ sec : decdslowcondcuts ] .",
    "[ thm : disconnectexpandergraph ]",
    "let @xmath2 be a constant and let @xmath72 be a dynamic graph of max degree at most @xmath32 and with @xmath337 which undergoes a sequence of at most @xmath338 updates each of which is an edge deletion .",
    "assume that w.h.p .",
    ", @xmath72 is initially a @xmath119-expander graph where @xmath339 . then there is a dynamic data structure for @xmath72 which w.h.p .  has worst - case preprocessing time @xmath340",
    ". if the sequence of updates is independent of the random bits used by the data structure then in the @xmath16th update , the data structure outputs a subset @xmath341 of @xmath75 such that    1 .",
    "@xmath342 $ ] is connected just after the update for some subset @xmath343 of @xmath344 , and 2 .",
    ", @xmath341 has size @xmath345 and is output in @xmath346 worst - case time .    given this theorem , the modification to the data structure described in the previous subsections is quite simple .",
    "the preprocessing step is extended by setting up an instance @xmath347 of the data structure of theorem  [ thm : disconnectexpandergraph ] for each large cluster @xmath31 .",
    "now , consider an update where an edge @xmath79 is to be deleted from @xmath9 .",
    "it will prove useful to split the update into two phases where @xmath79 is not deleted until the second phase .",
    "in the first phase , the following is done for each large cluster @xmath31 and the at most one large child cluster @xmath260 of @xmath31 containing @xmath79 .",
    "first , @xmath348 is updated with the deletion of @xmath79 .",
    "letting @xmath349 be the set output by @xmath348 , all edges of @xmath31 incident to @xmath350 are inserted into @xmath272 , excluding those edges already present in this structure .",
    "then all edges incident to @xmath350 are removed from @xmath263 and @xmath264 and forests @xmath270 and @xmath271 are updated accordingly ; new edges added to these forests are inserted into @xmath272 but edges removed from the forests are not removed from this structure . in the second phase , the same is done as in the previous subsections .",
    "we show that with the above modifications , our data structure still maintains msf @xmath60 of @xmath9 .",
    "it suffices to show that @xmath55 correctly maintains @xmath227 and by lemma  [ lem : msflaminar ] , this follows if we can show that for any @xmath35-cluster @xmath31 , @xmath272 contains @xmath351 after each update .",
    "we show the latter by induction on the height of the subtree of @xmath35 rooted at @xmath31 .",
    "the base case where the height is @xmath39 is straightforward since then @xmath31 is a small cluster and @xmath272 contains @xmath268 at all times and thus also @xmath351 .",
    "now assume that the height is positive and that the claim holds for smaller heights and consider an update where an edge @xmath79 is to be deleted from @xmath9 . assuming that the claim holds at the beginning of the update",
    ", we will show that it also holds at the end of the update .",
    "consider the end of the first phase .",
    "observe that the claim must hold at this point since it did so at the beginning of the update and in the first phase we only add edges to @xmath272 . for the analysis , we construct a subgraph @xmath352 of @xmath31 by initializing @xmath353 and then doing the following for each large child cluster @xmath260 of @xmath31 .",
    "let @xmath354 be the union of subsets output by @xmath348 so far and let @xmath355 be a subset of @xmath354 such that @xmath356 $ ] is connected ; such a subset must exist by theorem  [ thm : disconnectexpandergraph ] .",
    "we remove from @xmath352 all edges of @xmath357 incident to @xmath354 as well as remove all vertices of @xmath355 ; see figure  [ fig : dgraph ] .",
    "define @xmath356 $ ] to be a large child cluster of @xmath352 .",
    "we have defined the large child clusters of @xmath352 and we define the small child clusters of @xmath352 to be the small child clusters of @xmath31 .",
    "with these definitions , let @xmath358 be obtained from @xmath352 exactly in the same manner as @xmath259 is obtained from @xmath31 .",
    "for each large child cluster @xmath260 of @xmath31 , there is a unique large child cluster @xmath359 of @xmath352 such that @xmath360 . for all such pairs @xmath361",
    ", we identify the large cluster vertex in @xmath259 corresponding to @xmath260 with the large cluster vertex in @xmath358 corresponding to @xmath359 . at the end of the first phase",
    ", we then have @xmath362 .    now , consider the end of the second phase of the update . at this point , @xmath79 has been deleted from @xmath31 . since the large cluster vertices of @xmath259 are identified with large cluster vertices of @xmath358 , they correspond to subgraphs of @xmath31 which by theorem  [ thm : disconnectexpandergraph ] are connected .",
    "let @xmath363 be the union of these subgraphs and let @xmath260 be the union of all child clusters of @xmath31 ; note that @xmath364 $ ] . by the induction hypothesis",
    ", @xmath272 contains @xmath261 .",
    "let @xmath365 ; see figure  [ fig : dgraph](b ) . in the first phase",
    ", the edges of @xmath10 were all inserted into @xmath272 and they must still be present in this structure since they were all removed from @xmath259 in the first phase . hence , @xmath272 contains @xmath366 where we view @xmath367 as a subset of edges of @xmath52 , for @xmath320 . with a proof similar to that of lemma  [ lem : msflaminar ]",
    ", we have @xmath368 .",
    "hence , by lemma  [ lem : msfsparsification ] , @xmath272 also contains @xmath369 which shows the induction step .",
    "hence , with the above modification , @xmath229 correctly maintains @xmath60 .",
    "we now analyze the additional preprocessing and update time required with the above modifications .",
    "the total number of large clusters is @xmath370 so by theorem  [ thm : disconnectexpandergraph ] , w.h.p .",
    "the additional preprocessing time is @xmath371 .",
    "now , consider the deletion of an edge @xmath79 from @xmath9 .",
    "the number of large clusters containing @xmath79 is @xmath331 and by keeping pointers from each edge to the large clusters containing it , these clusters can be identified in @xmath331 time .",
    "consider one such large cluster @xmath31 . by theorem  [ thm : disconnectexpandergraph ]",
    ", updating @xmath347 takes @xmath346 time with high probability .",
    "let @xmath350 be the set output by this update .",
    "during the first phase , no changes are made to @xmath227 so all edges inserted into @xmath272 when @xmath31 is processed must belong to @xmath372 . by theorem  [ thm : msffewnontreeedges ] , they can thus be inserted with batched insertions into the ffe structure , taking a total worst - case time of @xmath373 . by our earlier analysis of the data structures maintaining @xmath326- and @xmath333-forests",
    ", it follows that removing edges incident to @xmath350 from @xmath263 and @xmath264 and updating @xmath270 and @xmath271 accordingly takes @xmath374 worst - case time .",
    "summing over all @xmath31 , it follows that w.h.p .",
    ", each update can be supported in @xmath375 worst - case time .    combining the above with lemma  [ lem : mainperformance ]",
    ", we are now ready to choose @xmath33 in order to obtain theorem  [ thm : main ] .",
    "we have shown that w.h.p .",
    ", preprocessing time for the structure of this section is @xmath376 and update time is @xmath377 ; this is under the assumption that @xmath378 since we applied theorem  [ thm : disconnectexpandergraph ] above . by theorem  [ thm :",
    "reduction ] , this gives a fully - dynamic msf structure which for any update requires @xmath379 time with high probability .",
    "picking constant @xmath380 sufficiently small and picking suitable @xmath381 gives an update time of @xmath382 .",
    "this shows theorem  [ thm : main ] except for the expected time bound .",
    "the latter can easily be obtained as follows .",
    "if in an update the @xmath382 time bound is exceeded , the data structure can update the msf deterministically in @xmath303 time ( scanning over all edges ) and then rebuild a new data structure for the next update .",
    "since the @xmath303 time is only spent with low probability , we get an expected time bound of @xmath382 .",
    "in this section , we give a reduction from fully - dynamic msf to a restricted form of decremental msf , showing theorem  [ thm : reduction ] .",
    "holm et al .",
    "@xcite gave a reduction from fully - dynamic to decremental minimum spanning forest .",
    "unfortunately , this reduction will not suffice for our problem since it is not worst - case time - preserving , implying that with a decremental structure having small _ worst - case _ update time , the reduction only yields a fully - dynamic structure with small _ amortized _ update time . in the following ,",
    "we sketch a variant of the reduction in  @xcite but where we assume that for the black - box decremental structure , we have a bound on its worst - case update time . in the next subsection ,",
    "we modify it to a worst - case time - preserving reduction",
    ".    it will be convenient to reduce from fully - dynamic msf in a simple graph to decremental msf in a multigraph .",
    "assume that for an @xmath0-vertex multigraph with initially @xmath11 edges , we have a black - box decremental msf structure with preprocessing time @xmath383 and worst - case update time at most @xmath384 . to simplify our bounds",
    ", we shall assume that @xmath385 and @xmath386 are non - decreasing in @xmath11 and @xmath0 . since we may assume that @xmath385 and @xmath386 are bounded by polynomial functions in @xmath11 and @xmath0",
    ", we may assume that a constant - factor increase in @xmath11 or @xmath0 increases @xmath385 and @xmath386 by no more than a constant factor .",
    "we will obtain a fully - dynamic msf structure with @xmath387 amortized update time over any sequence of updates where @xmath11 is the maximum number of edges present in @xmath9 over all updates and @xmath388 .",
    "let @xmath34 be the dynamic ( simple ) graph , let @xmath10 be the msf of @xmath9 , and let @xmath35 be the fully - dynamic msf structure that maintains @xmath10 .",
    "this structure consists of pairs of decremental msf structures , @xmath389 .",
    "we let @xmath390 denote the multigraph and let @xmath391 denote the msf of @xmath390 maintained by @xmath392 . furthermore",
    ", we let @xmath393 .",
    "similarly , we define @xmath394 , @xmath395 , and @xmath396 for @xmath397 . initially , all multigraphs @xmath390 and @xmath394 are empty . in the general step , we require that every non - tree edge of @xmath9 is a non - tree edge of one of the multigraphs @xmath398 ; with the same proof as in  @xcite , this ensures that whenever an edge of @xmath10 is deleted , a cheapest reconnecting edge ( if any ) is one of the reconnecting edges identified by the decremental msf structures .",
    "msf structure @xmath35 will need an auxiliary operation that , given two sets of edges @xmath91 and @xmath92 , outputs a decremental structure as follows .",
    "first , a new multigraph is formed consisting of the union of @xmath90 and a subgraph @xmath363 of @xmath10 consisting of all simple paths in @xmath10 between vertex pairs @xmath93 where @xmath136 resp .",
    "@xmath137 is an endpoint of an edge of @xmath90 .",
    "the latter ensures that any non - tree edge of @xmath9 belonging to @xmath90 is a non - tree edge of the new multigraph formed .",
    "then a decremental structure is initialized for this new multigraph and the structure is output .",
    "[ [ edge - insertions ] ] edge insertions : + + + + + + + + + + + + + + + +    we now describe how updates are handled . at the end of each update ,",
    "regardless of whether it is an insertion or deletion , a cleanup procedure is applied which we describe below .",
    "first we describe the first part of the update .",
    "we start with an insertion of an edge @xmath79 into @xmath9 .",
    "if @xmath79 connects distinct trees in @xmath10 , @xmath79 is added to @xmath10 and no further updates are done .",
    "now assume that the endpoints of @xmath79 are connected by a path @xmath385 in @xmath10 .",
    "if @xmath79 is lighter than the heaviest edge @xmath135 on @xmath385 , @xmath79 replaces @xmath135 in @xmath10 and the auxiliary operation is applied with @xmath399 and @xmath400 ; let @xmath401 be the structure output by this operation . if @xmath402 is empty , we set it equal to @xmath401 and otherwise we set @xmath403 equal to @xmath401 .",
    "conversely , if @xmath79 is heavier than @xmath135 , we we do the same as just described but with @xmath404 and @xmath400 .    [ [ edge - deletions ] ] edge deletions : + + + + + + + + + + + + + + +    now , consider the deletion of an edge @xmath79 from @xmath9 .",
    "first , in each ( multigraph represented by the ) decremental structure containing @xmath79 , let @xmath385 be a maximal path containing @xmath79 whose interior vertices have degree @xmath68 . viewing @xmath385 as a single `` super edge '' ( defined below ) , @xmath385 is removed and the decremental structure outputs at most one reconnecting edge .",
    "let @xmath405 be the set of replacement edges found by all decremental structures .",
    "if @xmath406 , we delete @xmath79 from @xmath10 and reconnect @xmath10 with the cheapest reconnecting edge from @xmath405 , if any .",
    "finally , we apply the same procedure as for edge insertions but with @xmath407 and @xmath400 .",
    "[ [ the - cleanup - procedure ] ] the cleanup procedure : + + + + + + + + + + + + + + + + + + + + + +    we next describe the cleanup procedure which is applied at the end of each update .",
    "first , we need a definition .",
    "assign time steps @xmath408 to the updates and for each integer @xmath409 , define a _",
    "@xmath16-interval _ as an interval of the form @xmath410 where @xmath411 is an integer .",
    "now consider an update @xmath197 .",
    "for all @xmath37 in increasing order , if @xmath197 is divisible by @xmath412 , i.e. , if @xmath197 is the beginning of a @xmath412-interval , we do as follows .",
    "the auxiliary operation is applied to @xmath413 , giving a new decremental structure @xmath414 .",
    "then @xmath392 and @xmath397 are made empty and if @xmath415 is empty , we update it to @xmath414 , otherwise we update @xmath416 to @xmath414 .    [",
    "[ implementation - and - analysis ] ] implementation and analysis : + + + + + + + + + + + + + + + + + + + + + + + + + + + +    to show correctness , note that when a new decremental structure is about to be added to a pair @xmath417 , either @xmath392 or @xmath397 must be empty since we only add such a new structure at the beginning of a @xmath418-interval and both @xmath392 and @xmath397 are made empty at the start of a @xmath412-interval",
    ". thus we maintain the invariant that every non - tree edge of @xmath9 is a non - tree edge of some decremental structure .",
    "correctness now follows using the same analysis as in  @xcite .",
    "we now sketch the implementation details .",
    "we maintain @xmath10 as a top tree , allowing us to insert and delete edges in @xmath10 and to find the lightest / heaviest edge on a path ; each top tree operation takes @xmath67 time .    for performance reasons",
    ", we would like @xmath419 ( and similarly @xmath420 ) .",
    "this is done by modifying the auxiliary operation above so that instead of explicitly including the subgraph @xmath363 of @xmath10 in the new multigraph @xmath390 , it instead adds _ super edges",
    "_ each of which corresponds to a maximal path in @xmath363 where interior nodes have degree @xmath68 . as shown in  @xcite",
    ", this compact representation of @xmath390 has size @xmath421 and can be identified in @xmath422 time with a suitable top tree @xmath391 ( and @xmath395 for @xmath394 ) of @xmath10 . in total , we maintain @xmath423 such top trees , one for each decremental structure .    in each update , we add at most @xmath28 edges to either @xmath402 or @xmath403 .",
    "hence , at the beginning of every @xmath412-interval , @xmath424 so in the cleanup phase , it takes @xmath425 time to form the multigraph of @xmath414 plus @xmath426 time to initialize @xmath414 . when applying a top tree to form a subgraph @xmath363 of @xmath10 as described above , the information in this top tree changes . after having formed @xmath363 ,",
    "we undo these changes so that the top tree is ready to form the next such tree . undoing",
    "the changes can be done within the time to form @xmath363 .    since the work just described is only done every @xmath412 updates it follows by summing over all @xmath37 that the amortized cost per update for the cleanup phase is @xmath427    in the first part of an update , we delete at most one edge from each decremental structure .",
    "since the bound on @xmath428 implies @xmath429 , the first part of an update takes @xmath430 time .",
    "updating all top trees in an update to the new forest @xmath10 takes a total of @xmath18 time .",
    "we conclude that each update takes amortized time @xmath431      we now modify @xmath35 to get a similar worst - case update time bound for this structure .",
    "a standard deamortization trick is used of spreading the work of constructing a new decremental structure over multiple updates rather than doing all the work in a single update .",
    "for this to work , we introduce , in addition to each pair @xmath417 , an additional pair @xmath432 of decremental structures .",
    "we can think of @xmath433 and @xmath434 as snapshots of @xmath392 and @xmath397 at the beginning of each @xmath412-interval and we use these snapshots to build @xmath414 in the background during this interval .",
    "more precisely , we modify @xmath35 so that in the beginning of a @xmath412-interval @xmath435 , we move @xmath392 to @xmath433 and @xmath397 to @xmath434 and identify @xmath392 and @xmath397 with empty decremental structures .",
    "we now start forming @xmath414 as described above but with @xmath433 and @xmath434 rather than @xmath392 and @xmath397 .",
    "the work for forming @xmath414 is spread evenly over each update of the first half of @xmath435 . in the second half ,",
    "we delete edges from @xmath414 at `` double speed '' .",
    "more precisely , in the @xmath16th update of the second half of @xmath435 , we delete from @xmath414 the edges deleted from @xmath9 in the @xmath436th and @xmath437th update of @xmath435 .",
    "hence , at the end of the last update of @xmath435 , @xmath414 is up - to - date with the current graph @xmath9 . at this point ,",
    "if @xmath415 is empty , we update it to @xmath414 and otherwise we update @xmath416 to @xmath414 .    all other parts of @xmath35 are updated exactly as in the previous version .",
    "[ [ implementation - and - analysis-1 ] ] implementation and analysis : + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the previous version of @xmath35 , @xmath414 was constructed and included in @xmath438 at the beginning of a @xmath412-interval @xmath435 . at this point , both @xmath392 and @xmath397 could be made empty since every non - tree edge of @xmath9 which is a non - tree edge of @xmath392 or @xmath397 is a non - tree edge of either @xmath415 or @xmath416 . in the new version of @xmath35 , @xmath414 is instead added to @xmath438 at the end of @xmath435 .",
    "hence , during the updates of @xmath435 , each non - tree edge of @xmath9 which was a non - tree edge of @xmath414 in the old version is a non - tree edge of either @xmath392 or @xmath397 in the new version .",
    "correctness now follows since the new version also maintains the invariant that every non - tree edge of @xmath9 is a non - tree edge of some structure @xmath392 or @xmath397 .",
    "we change the implementation such that the top trees @xmath391 and @xmath395 are not updated during the first half of a @xmath412-interval @xmath435 .",
    "hence , in each update in the first half of @xmath435 , both @xmath391 and @xmath395 are top trees representing @xmath10 at the start of @xmath435 , allowing @xmath414 to be formed correctly . during the last half of @xmath435 , @xmath391 and @xmath395",
    "are updated at double speed in the same way that @xmath414 is updated in this half of @xmath435 .",
    "we now bound the worst - case update time of @xmath35 .",
    "we first focus on the time to construct and update a decremental structure @xmath414 during a @xmath412-interval @xmath435 . in the first half of @xmath435 , @xmath439 time per update is spent on forming @xmath414 . in the last half of @xmath435 , @xmath440 time is spent on updating @xmath414 and top trees @xmath391 and @xmath395 at double speed . summing over",
    "all @xmath37 gives a worst - case time bound of @xmath441 .    in every update ,",
    "we delete at most one edge from each @xmath392- and @xmath397-structure .",
    "this is @xmath442 worst - case time .",
    "we can now conclude this subsection with the following theorem .",
    "[ thm : worstcasepreservingreduction ] let a decremental msf structure be given which for an @xmath0-vertex multigraph with initially @xmath11 edges has @xmath383 preprocessing time and @xmath384 worst - case update time where both @xmath385 and @xmath386 are non - decreasing .",
    "then there is a fully - dynamic msf structure with worst - case update time @xmath443 for an @xmath0-vertex dynamic graph in which the number of edges never exceeds the value @xmath11 .",
    "we now reduce the decremental msf problem further , first to the case where we have an initial @xmath0-vertex ( simple ) graph of max degree at most @xmath32 and then further to the case where the total number of edge deletions is bounded by some parameter @xmath33 that may be smaller than the initial number of edges .    [ [ reduction - to - degree - at - most-3 ] ] reduction to degree at most @xmath32 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath9 be an edge - weighted multigraph with @xmath11 edges and @xmath0 vertices .",
    "construct a new simple graph @xmath52 of degree at most @xmath32 from @xmath9 as follows . for each vertex @xmath136 of @xmath9 ,",
    "let @xmath444 be its neighbors .",
    "we replace @xmath136 with @xmath16 copies , @xmath445 , replace edges incident to @xmath136 with edges @xmath446 for @xmath447 without changing their weights , and add edges @xmath448 for @xmath449 ; the weight of each such edge @xmath448 is chosen to be smaller than any edge weight in @xmath9 .",
    "we identify each edge @xmath446 with its corresponding edge in @xmath9 .",
    "it is easy to see that an msf of @xmath10 can be obtained from an msf of @xmath52 by contracting all edges that are not present in @xmath9 .",
    "it follows that if we have a decremental msf structure for an @xmath450-vertex graph of degree at most @xmath32 with preprocessing time at most @xmath451 and worst - case update time at most @xmath452 where @xmath385 and @xmath386 are non - decreasing , then there is a decremental msf structure of @xmath9 with preprocessing time @xmath453 and worst - case update time @xmath454 .",
    "[ [ reduction - to - at - most - delta - deletions ] ] reduction to at most @xmath33 deletions : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we shall make a further reduction from decremental msf in an @xmath0-vertex graph of degree at most @xmath32 to the same problem but where we have a bound @xmath63 on the total number of edge deletions permitted . assume for simplicity that @xmath33 is divisible by @xmath32 and assume access to a decremental msf structure @xmath455 which for an @xmath0-vertex graph of degree at most @xmath32 has preprocessing time at most @xmath64 and supports up to @xmath456 edge deletions each in worst case time at most @xmath65 .",
    "now , let @xmath9 be an @xmath0-vertex graph of degree at most @xmath32 . we obtain a decremental msf structure for @xmath9 as follows . at the start of each @xmath457-interval",
    "@xmath458 , a new instance @xmath459 of @xmath455 is initialized for the current graph @xmath9 ; the work for this is spread evenly over the updates of @xmath458 . in the @xmath457-interval @xmath460 following @xmath458",
    ", we delete edges at double speed from @xmath459 ( similar to what we did in the previous subsection when setting up an instance @xmath414 ) so that at the end of @xmath460 , @xmath459 is up to date with the current graph @xmath9 . at this point ,",
    "@xmath461 edges have been deleted from @xmath459 so it still supports an additional @xmath457 deletions . at the beginning of the @xmath457-interval @xmath462 following @xmath460 , @xmath459 the active structure , responsible for maintaining the msf of @xmath9 during the updates of @xmath462 .",
    "hence , in any @xmath457-interval , one instance of @xmath455 is being initialized , one instance has edges deleted from it at double speed , and one instance is the active one , maintaining the msf of @xmath9 .    [ [ proving - theoremthmreduction ] ] proving theorem  [ thm : reduction ] : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we are now ready to prove theorem  [ thm : reduction ] .",
    "using the approach above gives a decremental structure for an @xmath0-vertex graph of degree at most @xmath32 with preprocessing time @xmath463 and worst - case update time @xmath464 .",
    "the vertex - splitting argument above gives a decremental structure with preprocessing time @xmath465 and worst - case update time @xmath466 for an @xmath0-vertex multigraph with initially @xmath11 edges . by theorem  [ thm : worstcasepreservingreduction ]",
    ", we get a fully - dynamic msf structure with worst - case update time @xmath467 . applying theorem 3.3.2 of  @xcite",
    "now gives the first part of the theorem .    to show the second part ,",
    "assume that the preprocessing and update time bound of the restricted decremental msf structure hold with probability at least @xmath468 for an @xmath450-vertex graph where @xmath31 is a large constant @xmath31 .",
    "let @xmath0 be the number of vertices in the graph for the fully - dynamic problem that we reduce from .",
    "note that @xmath450 may be @xmath469 in our reduction , meaning that the preprocessing and update time bounds may fail with constant probability . to handle this ,",
    "we modify the decremental structure so that if @xmath470 , the preprocessing step consists of computing the initial msf in @xmath471 time with prim s algorithm , and each update is handled in @xmath472 time by a simple deterministic linear - time update procedure .",
    "this ensures that for any value of @xmath450 , the decremental structure achieves a preprocessing bound of @xmath473 and a worst - case update time bound of @xmath474 with probability at least @xmath475 .",
    "going through the reduction steps as above now shows the second part of the theorem .",
    "in this section , prove theorem  [ thm : msffewnontreeedges ] .",
    "we consider an edge - weighted graph @xmath476 and present a dynamic data structure with update time polynomially faster than @xmath30 when this property holds .",
    "the dynamic problem considered here differs from the standard fully - dynamic msf problem in that we allow extra operations giving more control to the user regarding the structure of the forest maintained ; in fact , the forest is not required to span @xmath72 .",
    "another way the problem differs from the standard fully - dynamic version is that we do not require that we start with @xmath477 and we allow a preprocessing phase for this initial graph , as stated in theorem  [ thm : msffewnontreeedges ] .",
    "in addition to @xmath72 , we assume that the preprocessing algorithm is given an initial forest @xmath10 in @xmath72 as input . this forest will be maintained during edge updates .",
    "we keep a partition of @xmath10 into subtrees whose vertex sets are called _",
    "regions_. regions are similar to frederickson s clusters except that we do not balance them by size but by the number of endpoints of non - tree edges they contain .",
    "hence , in our application , the average region size will be polynomially greater than @xmath30 , assuming the number of non - tree edges is polynomially smaller than @xmath0 . for a region @xmath405 ,",
    "we denote by @xmath478 the number of vertices of @xmath405 that are incident to edges in @xmath479 . each region",
    "is given a unique label in @xmath480 .",
    "our data structure will not fix such a label for regions @xmath405 where @xmath481 and @xmath405 is a component of @xmath72 ; this is a technicality that will simplify our implementation .",
    "we assign some auxiliary information to each edge @xmath79 of @xmath72 .",
    "a bit @xmath482 is @xmath127 iff @xmath406 .",
    "another bit @xmath483 is @xmath127 iff @xmath484 or @xmath79 is an inter - region edge of @xmath10 .",
    "if @xmath485 , we assign to @xmath79 a label @xmath486 which is a pair of labels denoting the regions containing the endpoints of @xmath79 ; if @xmath487 , we leave @xmath486 undefined . our data structure will only store region labels in such pairs @xmath486 .",
    "we use a top tree structure @xmath488 called the _",
    "region forest _ to maintain and dynamically merge and split regions , similarly to what is needed for clusters in frederickson s data structure .",
    "forest @xmath488 has the same edge set as @xmath10 and supports various operations that we focus on in the following .    in @xmath488 ,",
    "certain vertices are marked .",
    "more specifically , a vertex is marked iff it is incident to an edge @xmath79 with @xmath485 .",
    "in addition to the operations below , @xmath488 supports the @xmath67 time operations of finding a nearest marked vertex to a given vertex , marking and unmarking a vertex , and inserting and deleting an edge .",
    "when implementing ` mergeregion ` and ` splitregion ` below , it will prove useful to have @xmath488 support the auxiliary operation ` findregiontree`@xmath489 for a @xmath490 .",
    "letting @xmath491 be the region containing @xmath137 and letting @xmath492 be the set of marked vertices in @xmath491 , this operation returns the tree @xmath493 consisting of the union of all simple paths between pairs of marked vertices ; see figure  [ fig : fewnontreeedges ]",
    ".    letting @xmath494 , we can support ` findregiontree`@xmath489 in @xmath495 as follows .",
    "first we find a nearest marked vertex @xmath496 to @xmath137 in @xmath488 . among the at most three edges of @xmath72 incident to @xmath496 , delete from @xmath488 those that belong to @xmath10 and leave @xmath491 by checking their @xmath135 and @xmath62 bitmaps .",
    "then unmark @xmath496 and repeat the procedure recursively on @xmath496 until no more marked vertices are encountered .",
    "the edges deleted are exactly the inter - region edges of @xmath10 leaving @xmath491 so this makes @xmath497 $ ] a component of @xmath488 .",
    "the set of unmarked vertices is exactly @xmath492 . extending @xmath488 with additional operations as described in  @xcite ( see the implementation subsection for fully - dynamic minimum spanning tree ) allows us to obtain @xmath493 in @xmath495 time . finally , we clean up by marking the unmarked vertices of @xmath488 and inserting back the deleted edges .",
    "this clean - up step also takes @xmath495 time . note that @xmath498 .",
    "the following two types of operations in @xmath488 allow for merging and splitting regions , respectively :    ` mergeregion`@xmath489 : : :    merges the region @xmath491 containing @xmath137 with a    region incident to @xmath491 in @xmath10 , assuming such    a region exists ; the two regions are thus replaced by their union , ` splitregion`@xmath499 : : :    splits the region @xmath491 containing @xmath137 into    subregions such that for each such subregion @xmath405 ,    @xmath500 ; it is assumed that    @xmath501 .",
    "although these operations apply to @xmath488 , we shall require them to also correctly update the auxiliary information stored at edges of @xmath72 .",
    "we first apply ` findregiontree`@xmath489 to @xmath488 , giving @xmath493 . for each vertex of @xmath493 , we check if any of its incident edges in @xmath72 is an inter - region edge of @xmath10 ( again by checking the @xmath135 and @xmath62 bitmaps of these edges ) .",
    "if no such edge is found , @xmath491 is not incident in @xmath10 to any region .",
    "otherwise , let @xmath502 be one such edge where @xmath503 . from label @xmath486",
    ", we obtain the label @xmath504 of @xmath491 and the label @xmath505 of a region @xmath506 which is incident to @xmath491 in @xmath10 with @xmath507",
    ". we will merge @xmath491 and @xmath506 into a new region with label @xmath504 . to do this ,",
    "we first apply ` findregiontree`@xmath508 to get @xmath509 .",
    "we then visit all edges of @xmath72 incident to @xmath510 . for each such edge @xmath298 ,",
    "if @xmath511 is defined , we update each occurence of @xmath505 in this set to @xmath504 .",
    "finally we set @xmath483 to @xmath39 and delete @xmath486 as @xmath79 is no longer an inter - region edge of @xmath10 .",
    "the running time of ` mergeregion`@xmath489 is @xmath495 where @xmath512 is the total number of marked vertices in @xmath491 and @xmath506 , i.e. , the number of marked vertices in the merged region .",
    "we first apply ` findregiontree`@xmath489 to @xmath488 to get @xmath493 .",
    "let @xmath512 be the number of marked vertices in @xmath493 .",
    "we then apply frederickson s linear - time ` findclusters ` procedure  @xcite to partition @xmath493 into subtrees @xmath513 whose vertex sets @xmath514 form a partition of @xmath515 where @xmath516 for @xmath447",
    ". let @xmath517 be new unique labels for @xmath518 , i.e. , distinct labels none of which are equal to labels of existing regions .    for @xmath447 and for each edge @xmath79 of @xmath519 incident to @xmath520 ,",
    "we update to @xmath521 the labels in @xmath486 for each endpoint of @xmath79 in @xmath522 . for each edge @xmath79 of @xmath10 leaving @xmath520 , we set @xmath483 to @xmath127 since @xmath79 is now an inter - region edge of @xmath10 ; furthermore , we update to @xmath521 the label in @xmath486 for the endpoint of @xmath79 in @xmath522 .    excluding the time to find unique labels , the above takes @xmath495 time where @xmath512 is the number of marked vertices in @xmath491 . to quickly find @xmath523 ,",
    "our data structure maintains a dynamic list @xmath524 consisting of those labels in @xmath480 that are currently not used by any region .",
    "whenever two regions are merged , the now unused label of one of the two regions is added to @xmath524 .",
    "when a new region is formed , we extract the first label from @xmath524 and use it to label this region .",
    "each operation on @xmath524 takes constant time if we use a linked list .",
    "in particular , finding @xmath523 can be done in @xmath525 time .",
    "total time for ` splitregion ` is thus @xmath495 .",
    "we now describe operations that maintain @xmath488 and the auxiliary information stored at edges of @xmath72 under edge insertions and deletions in @xmath72 .",
    "we start with insertions .",
    "since we later need to have some control over which edges belong to @xmath10 ( equivalently , to @xmath488 ) , we extend the insert operation with an extra argument specifying whether the new edge should be a tree edge or a non - tree edge ; if it should be a tree edge , it is assumed that it connects two distinct trees in the current forest @xmath10 .",
    "note that this allows for @xmath10 to be a non - spanning forest of @xmath72 ; we later present an operation to find a minimum - weight connecting edge between two trees in @xmath10 .",
    "this will be needed if we want to maintain @xmath10 as an msf of @xmath72 .",
    "consider the insertion of an edge @xmath134 into @xmath72 .",
    "assume first that it should be added as a non - tree edge .",
    "we look for a nearest marked vertex @xmath526 to @xmath136 in @xmath488 .",
    "if @xmath526 exists , we obtain from one of its incident edges the label @xmath527 of the region @xmath528 containing @xmath136 . if @xmath526 does not exist , we extract from @xmath524 a new label @xmath527 for @xmath528 .",
    "similarly , we find the label @xmath504 of the region @xmath491 containing @xmath137 .",
    "we then add @xmath79 to @xmath72 , mark @xmath136 and @xmath137 in @xmath488 , set @xmath529 , @xmath485 , and @xmath530 .",
    "now suppose that @xmath79 should be added as a tree edge .",
    "prior to the insertion , @xmath79 must connect two distinct trees in @xmath10 so it will be an inter - region edge of @xmath10 .",
    "let @xmath528 and @xmath491 be the regions containing @xmath136 and @xmath137 , respectively . with the same procedure as above , we find labels @xmath527 and @xmath504 for @xmath528 and @xmath491 , respectively .",
    "we then insert @xmath79 into @xmath72 and @xmath488 and set @xmath531 , @xmath485 , and @xmath530 .",
    "the running time for inserting @xmath79 is @xmath67 .",
    "now consider the operation of deleting an edge @xmath134 from @xmath72 .",
    "we do not require this operation to look for a reconnecting edge if @xmath79 belongs to @xmath10 since we later give an operation for this .",
    "we start by removing @xmath79 from @xmath72 .",
    "assume first that @xmath79 was in @xmath10 ; we can check this in constant time by inspecting @xmath482 .",
    "now , consider the subcase that @xmath485",
    ". then @xmath79 must be an inter - region edge of @xmath10 . in this case , we unmark @xmath136 resp .",
    "@xmath137 in @xmath488 unless that vertex is still incident to an edge @xmath298 in @xmath72 with @xmath532 after the deletion of @xmath79 . in case",
    "the region @xmath405 containing @xmath136 resp .",
    "@xmath137 no longer has a marked vertex , we must have that @xmath481 and @xmath405 is a component of @xmath72 ; in this case , the label of that region is added to @xmath524 . finally ,",
    "we delete @xmath79 from @xmath488 .",
    "now assume that @xmath79 was in @xmath10 and @xmath487 .",
    "then @xmath79 must have both endpoints in some region @xmath533 .",
    "the deletion of @xmath79 will split @xmath533 into two subregions .",
    "prior to deleting @xmath79 , we apply ` findregiontree`@xmath534 to @xmath488 to get @xmath535 which contains exactly the marked vertices of @xmath533 .",
    "we obtain @xmath536 resp .",
    "@xmath537 which is the tree in @xmath538 containing @xmath136 resp .",
    "@xmath137 . using the same procedure as in the implementation of ` splitregion `",
    "above , we split @xmath533 into two subregions containing @xmath536 and @xmath537 , respectively , and give unique labels to each of them .",
    "finally , we delete @xmath79 from @xmath488 .",
    "the remaining case is when @xmath79 was a non - tree edge .",
    "this is handled in the same way as the case when @xmath79 was a tree edge and @xmath485 .",
    "total time for handling an edge deletion is @xmath495 where @xmath512 is the number of marked vertices in @xmath533 .",
    "we summarize the results above in the following lemma .",
    "[ lem : maintainhatf ] a call to ` mergeregion ` or ` splitregion ` can be done in @xmath539 time where @xmath540 is the maximum value @xmath478 of any region @xmath405 and @xmath541 is the maximum number of regions ; this includes the time for updating @xmath488 , @xmath135- and @xmath62-bitmaps , and pairs of labels @xmath486 for edges @xmath484 .",
    "updating these for an edge insertion in @xmath72 takes @xmath67 time and takes @xmath539 time for an edge deletion in @xmath72 .",
    "the lemma follows from the above and from the observation that the number of marked vertices in a region is @xmath542 .",
    "we now extend our data structure to support the operation ` connect`@xmath93 which , given two vertices @xmath136 and @xmath137 in distinct trees of @xmath10 , finds a minimum - weight edge of @xmath72 ( if any ) connecting these trees .",
    "to support ` connect`@xmath93 , we introduce a new top tree structure @xmath543 . like @xmath488",
    ", it contains the same edge set as @xmath10 .",
    "each top tree cluster @xmath31 in @xmath543 has as auxiliary data two lists @xmath544 and @xmath545 .",
    "list @xmath544 consists of the pairs @xmath546 where @xmath79 is a minimum - weight edge in @xmath547 with at least one endpoint in @xmath31 and at least one endpoint in the region with label @xmath411 .",
    "list @xmath545 consists of the labels @xmath411 of regions sharing vertices with @xmath31 .",
    "we implement both lists as red - black trees where elements are kept in sorted order by their @xmath411-value .",
    "if we can maintain @xmath543 , we can support ` connect`@xmath93 as we show in the following .",
    "let @xmath548 and @xmath549 be the root clusters of @xmath543 corresponding to the trees @xmath535 and @xmath493 in @xmath10 containing @xmath136 and @xmath137 , respectively ; identifying these top tree clusters from @xmath136 and @xmath137 can be done in @xmath67 time .",
    "observe that if there is a connecting edge for @xmath535 and @xmath493 , a cheapest such edge has one endpoint in @xmath548 and the other endpoint in a region of @xmath493 .",
    "it can be chosen as an edge @xmath79 of minimum weight over all pairs @xmath550 where @xmath551 .",
    "searching in parallel through the two lists in sorted order , @xmath79 is identified in @xmath552 time .",
    "total time for ` connect`@xmath93 is thus @xmath553 .",
    "it remains to describe how @xmath543 is maintained .",
    "there are two types of updates to @xmath543 , topological and non - topological changes .",
    "the topological changes happen when an edge is deleted from or inserted into @xmath543 which causes updates to top tree clusters .",
    "the non - topological changes happen when @xmath519 changes or labels in pairs @xmath486 are updated for edges @xmath79 in @xmath519 .",
    "[ [ topological - changes ] ] topological changes : + + + + + + + + + + + + + + + + + + + +    supporting a topological change in @xmath543 reduces to supporting a sequence of @xmath67 top tree operations ` create`@xmath554 , ` join`@xmath555 , and ` split`@xmath556 .",
    "when a leaf top tree cluster @xmath31 for an edge @xmath79 is constructed with ` create`@xmath554 , we can obtain @xmath557 in constant time since the endpoints of @xmath79 are incident to only a constant number of edges of @xmath72 . supporting `",
    "split`@xmath556 takes @xmath558 time since we simply remove @xmath557 which has length @xmath558 .",
    "it remains to support ` join`@xmath555 . for the output top tree cluster @xmath31 ,",
    "we compute @xmath545 by traversing @xmath559 and @xmath560 in parallel in sorted order and merging these into a single list with duplicates removed . to compute @xmath544",
    ", we similarly merge @xmath561 and @xmath562 into a single list but instead of removing duplicates , we do as follows : if we encounter two elements @xmath563 and @xmath564 with the same region label @xmath411 , we only add one of the elements to @xmath544 , namely the one whose edge has the smaller weight .",
    "this correctly computes the auxiliary data for @xmath31 and takes @xmath558 time .",
    "it follows that each topological change in @xmath543 can be supported in @xmath565 time .",
    "[ [ non - topological - changes ] ] non - topological changes : + + + + + + + + + + + + + + + + + + + + + + + +    a non - topological change in @xmath543 occurs when a label changes in a pair @xmath486 for an edge @xmath484 and when an edge is inserted into or deleted from @xmath519 .",
    "consider first the case where a label in @xmath486 changes from @xmath411 to @xmath566 for an endpoint @xmath136 of some edge @xmath484 .",
    "since @xmath543 has constant degree , the number of top tree clusters containing @xmath136 on each level in the binary rooted tree representation of @xmath543 is @xmath8 for a total of @xmath67 over all levels , and we can find these top tree clusters in @xmath67 time .",
    "we process them bottom - up .",
    "let @xmath31 be the current top tree cluster .",
    "if @xmath31 is a leaf cluster , we can update its auxiliary data in @xmath8 time since @xmath72 has @xmath8 degree .",
    "otherwise , let @xmath567 and @xmath568 be the child top tree clusters of @xmath31 . to update @xmath545 , we search for @xmath411 in @xmath559 and @xmath560 . if @xmath411 is not found in either of the two lists , it is removed from @xmath545 .",
    "we then add @xmath566 to @xmath545 if it is not already in this list .",
    "to update @xmath544 , we search for an entry of the form @xmath569 in @xmath561 and an entry of the form @xmath570 in @xmath562 ; in case @xmath571 resp .",
    "@xmath572 is undefined , regard it as a dummy edge of infinite weight .",
    "we remove the entry of the form @xmath573 in @xmath544 ( if any ) . if at least one of @xmath571 and @xmath572 is defined , we add a new pair @xmath574 to @xmath544 where @xmath575 is an edge of smaller weight among @xmath571 and @xmath572 .",
    "similar operations are done for label @xmath566 .    using standard red - black tree operations to update the lists on each of the @xmath67 levels",
    ", it follows that the update to @xmath543 caused by a single label change can be supported in @xmath18 time . in a similar manner ,",
    "the update to @xmath543 caused by the insertion or deletion of an edge in @xmath519 can be supported in @xmath18 time .    from the above observations , we can now bound the time for a call ` connect`@xmath93 in @xmath543 and for maintaining @xmath543 .    [",
    "lem : maintainhatfprime ] a call ` connect`@xmath93 takes @xmath565 time where @xmath541 is the maximum number of regions in a tree of @xmath10 .",
    "updating @xmath543 after a call to ` mergeregion ` or ` splitregion ` can be done in @xmath576 time where @xmath540 is the maximum value @xmath478 of any region @xmath405 .",
    "updating @xmath543 takes @xmath18 time after an edge insertion or deletion in @xmath519 , takes @xmath565 time after an edge insertion in @xmath10 , and takes @xmath577 time after an edge deletion in @xmath10 .",
    "the first part of the lemma was shown above .    neither a call ` mergeregion ` nor a call ` splitregion ` results in topological changes to @xmath543 .",
    "the number of label changes for such a call is @xmath578 and by the above , the corresponding non - topological changes in @xmath543 can be supported in @xmath576 time .    the insertion of deletion of an edge in @xmath519 causes a non - topological change in @xmath543 which can be supported in @xmath18 time , as shown above .",
    "inserting an edge in @xmath10 causes a topological change in @xmath543 which we can support in @xmath565 time , again by the above .",
    "deleting an edge @xmath79 from @xmath10 causes a topological change in @xmath543 which can be supported in @xmath565 time .",
    "if @xmath487 , the deletion of @xmath79 splits the region @xmath533 containing @xmath79 .",
    "this causes @xmath578 labels to be updated and the corresponding non - topological changes to @xmath543 can be supported in @xmath576 time .",
    "we now focus on maintaining regions in such a way that we can simultaneously get good bounds for the above defined parameters @xmath540 and @xmath541 .",
    "we leave these values unspecified for now since their optimal choices will be easier to derive later .",
    "the preprocessing step is as follows .",
    "we are given a forest @xmath10 in @xmath72 as part of the input such that the number of non - tree edges is at most @xmath62 . in @xmath579 time",
    ", we can obtain @xmath135- and @xmath62-bitmaps and label pairs @xmath486 and find a partition into regions such that @xmath580 for each region @xmath405 and such that for any region @xmath405 which is not equal to a component of @xmath72 , @xmath581 .",
    "we obtain such a set of regions by applying frederickson s ` findclusters ` procedure  @xcite to each tree in @xmath10 with the slight modification that during the construction of regions , instead of keeping track of number of vertices , the modified procedure keeps track of the number of endpoints of non - tree edges that are incident to the region currently being built ; here , a non - tree edge with both endpoints in a region contributes a value of @xmath68 to the number of these endpoints .",
    "each region is given an arbitrary unique label from @xmath480 except regions @xmath405 where @xmath481 and @xmath405 is a component of @xmath72 .",
    "the list @xmath524 of unused labels is set up in @xmath303 time . in time",
    "@xmath579 , we initialize another list @xmath582 consisting of tuples @xmath583 for each label @xmath584 of a region @xmath405 where @xmath585 is a representative vertex of @xmath405 , and @xmath586 .",
    "we keep these tuples sorted by both label value and by @xmath587-value and like @xmath524 , list @xmath582 will be maintained during updates .",
    "we implement @xmath582 using two red - black trees , one for each of the two sorted orders , so that each update to it takes @xmath67 time ; to simplify the presentation , we shall simply refer to @xmath582 as a list .",
    "it is not hard to extend the above operations without an increase in running time so that whenever a labeled region @xmath405 is updated , its representative vertex @xmath588 and @xmath587-value are updated accordingly .",
    "setting up @xmath488 can be done in @xmath303 time . within the same time",
    "bound , we can set up @xmath543 , excluding the time to form auxiliary data for each top tree cluster .",
    "the latter can be done in @xmath589 time since the total length of all lists @xmath545 and @xmath590 over all top tree clusters @xmath31 on a single level of the top tree is @xmath69 and it takes @xmath591 time to sort them .",
    "now , consider edge insertions and deletions . for a suitably large constant @xmath22 ( that we leave unspecified for now ) , our data structure will maintain the following invariants :    upper bound invariant : : :    @xmath592 for any region @xmath405 , lower bound invariant : : :    @xmath593 for any region @xmath405    which is not equal to a component of @xmath72 .",
    "the preprocessing step ensures that both invariants hold initially .",
    "the lower bound invariant implies that at all times , the maximum number of regions in any tree of @xmath10 is @xmath594 .    by lemmas  [ lem : maintainhatf ] and  [ lem : maintainhatfprime ] , updating @xmath488 , @xmath543 , @xmath135- and @xmath62-bitmaps , and label pairs @xmath595 after an edge update in @xmath72 takes @xmath577 time .",
    "[ [ maintaining - the - lower - bound - invariant ] ] maintaining the lower bound invariant : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    an edge update in @xmath72 may cause the invariants to be violated . to reestablish them",
    ", we first focus on the lower bound invariant . it can be violated because an edge of @xmath519 is deleted or if an intra - region edge of @xmath10 is deleted , causing a region to be split in two .",
    "consider first the case where an edge @xmath484 is deleted . from @xmath486",
    ", we obtain labels of the at most two regions incident to @xmath79 . for each such region @xmath405",
    ", we obtain from its label @xmath584 the tuple @xmath596 in @xmath582 and we check if @xmath586 violates the invariant . if so , we apply ` mergeregion`@xmath597 . if @xmath405 was not merged with any region , @xmath405 must be a component of @xmath72 and hence can not violate the invariant .",
    "otherwise , we obtain @xmath598 and the label @xmath599 for the merged region @xmath600 together with its representative vertex @xmath601 with a call to ` findregiontree`@xmath602 , and we replace @xmath603 with @xmath604 in @xmath582 .",
    "note that @xmath600 can not violate the lower bound invariant since the region that @xmath405 was merged with did not violate it .",
    "now , consider the case where an intra - region edge @xmath79 belonging to @xmath10 is deleted . for each of the two subregions , @xmath405 , of the split region , we obtain its label @xmath584 by applying ` findregiontree ` to the endpoint of @xmath79 in @xmath405 and from it identify a marked vertex in @xmath405",
    "; @xmath584 is obtained from @xmath511 for one of the edges @xmath298 incident to this vertex . in case @xmath405",
    "contains no marked vertex , it has no incident non - tree edge and so @xmath405 must be a component of @xmath72 in which case it does not violate the invariant .",
    "otherwise , we proceed as above by applying ` mergeregion`@xmath597 to maintain the invariant for @xmath405 .",
    "the time for the updates above is @xmath605 by lemmas  [ lem : maintainhatf ] and  [ lem : maintainhatfprime ] .",
    "[ [ maintaining - the - upper - bound - invariant ] ] maintaining the upper bound invariant : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    next we focus on maintaining the upper bound invariant .",
    "note that initially , @xmath580 for each region @xmath405 . to ensure that @xmath478 never exceeds @xmath540 by more than a logarithmic factor , we employ the following simple greedy procedure .",
    "after each update , find a tuple @xmath583 in @xmath582 with maximum @xmath587-value and apply ` splitregion`@xmath606 .",
    "total time per update for applying this greedy procedure is @xmath605 . to show that the greedy procedure maintains the upper bound invariant , we need lemma  [ lem : pebble ] below which follows fairly easily from a result in  @xcite .    first , we need some definitions . for a vector @xmath607 in @xmath608 ,",
    "let @xmath609 $ ] denote the @xmath37th coordinate of @xmath607 .",
    "we let @xmath610 denote the vector obtained from @xmath607 by replacing @xmath609 $ ] with @xmath611 - r , 0\\rangle$ ] for all @xmath612 . for two vectors @xmath607 and @xmath613 in @xmath608",
    ", we say that @xmath607 _ dominates _",
    "@xmath613 if @xmath609\\geq \\vec w[i]$ ] for all @xmath612 .",
    "[ lem : pebble ] consider a finite dynamic set of objects distributed into bins @xmath614 such that initially each bin contains at most @xmath540 objects and such that each update is of one of the following types :    ` addtobin`@xmath615 : : :    adds @xmath616 objects to @xmath617 for    @xmath618 where    @xmath619 , ` removefrombin`@xmath620 : : :    deletes @xmath621 objects from @xmath617    where @xmath622 is the number of objects in @xmath617    just prior to this update , ` splitbin ` : : :    picks a bin @xmath617 with maximum number of objects ; if    @xmath617 contains more than @xmath540 objects , these    objects are distributed into empty bins such that each such bin    contains at most @xmath540 objects after the update .",
    "let @xmath623 be a constant and consider a sequence of @xmath0 updates such that every subsequence of @xmath16 consecutive updates includes at least one call to ` splitbin ` .",
    "then at any time during this sequence , the maximum number of objects in any bin is @xmath624 .",
    "we can view a distribution @xmath625 of objects into bins @xmath614 as the vector @xmath626 .",
    "now , consider a sequence of @xmath0 updates such that every subsequence of @xmath16 consecutive updates includes at least one call to ` splitbin ` .",
    "let @xmath627 be the sequence of vectors where @xmath628 is the distribution vector for objects prior to the first update and @xmath629 is the distribution vector just after the @xmath37th update , @xmath630 .    we will define a different sequence of distribution vectors @xmath631 such that @xmath632 dominates @xmath633 for @xmath634 .",
    "the initial vector @xmath635 is the zero vector @xmath636 ; this vector is equal to @xmath637 and hence dominates it .",
    "having defined vectors @xmath638 dominating @xmath639 , respectively , we will define a vector @xmath632 dominating @xmath633 .",
    "if the @xmath37th update is ` addtobin`@xmath615 , we let @xmath640 , ensuring that @xmath632 dominates @xmath633 . if the @xmath37th update is ` removefrombin`@xmath620 , we let @xmath641 which clearly also ensures that @xmath632 dominates @xmath633 .",
    "finally , if the @xmath37th update is ` splitbin ` , let @xmath642 be a coordinate of maximum value in @xmath643 and let @xmath644 be a coordinate of value @xmath39 in @xmath643 ( such coordinates must exist ) .",
    "let @xmath645 be the bucket which is split by ` splitbin ` .",
    "we let @xmath646 be the vector such that @xmath647 = \\vec v_{i-1}[j]$ ] for @xmath648 and @xmath649 = \\vec w_i[j_{\\max } ] = \\lfloor\\frac 1 2 \\vec v_{i-1}[j_{\\max}]\\rfloor$ ] .",
    "note that for each @xmath650 , @xmath651 $ ] is either equal to @xmath652 $ ] or is equal to @xmath39 ; this follows since ` splitbin ` distributes objects from @xmath645 into empty buckets so that each of these buckets contains at most @xmath540 objects after the update .",
    "we define @xmath632 as @xmath646 with coordinates @xmath642 and @xmath653 swapped and it follows that @xmath632 dominates @xmath633 .    for @xmath634 and for all @xmath650",
    ", we have shown that @xmath654\\leq\\delta(\\vec u_i)[j ] + r\\leq\\vec v_i[j ] + r$ ] .",
    "the lemma will thus follow if we can show that each coordinate in @xmath632 is @xmath624 , for @xmath634 .",
    "note that the total value added to all coordinates of @xmath607-vectors is @xmath578 between two consecutive ` splitbin ` updates or before the first ` splitbin ` or after the last ` splitbin ` update ; this holds since each such subsequence consists of at most @xmath655 updates . in each of these subsequences",
    ", we can only increase the values of coordinates of these vectors , never decrease them .",
    "each ` splitbin ` update corresponds to the splitting operation from  @xcite to the piles defined by the @xmath607-vectors .",
    "it follows from that paper that for @xmath634 , each coordinate of @xmath632 is @xmath624 , as desired .    by viewing regions as bins and the number of objects in a bin corresponding to a region @xmath405 as @xmath478",
    ", it follows from lemma  [ lem : pebble ] that our upper bound invariant holds for a sufficiently large constant @xmath22 .",
    "the lemma actually implies an additional result , namely that an update consisting of a batched insertion of any number @xmath656 of edges in @xmath519 can be supported while still maintaining both the upper and lower bound invariants .",
    "the lemmas above imply that the time for this operation plus the time to reestablish the invariants is @xmath657 .    by setting @xmath658 and @xmath659 , we get the following lemma which may be of independent interest .    [",
    "lem : fewnontreeedges ] let @xmath156 be a dynamic @xmath0-vertex graph undergoing insertions and deletions of weighted edges where the initial edge set @xmath157 need not be empty and where the number of non - tree edges never exceeds the value @xmath62 . then there is a data structure which after @xmath660 worst - case preprocessing time can maintain a forest @xmath10 in @xmath72 in @xmath160 worst - case time per update where an update is either inserting an edge in @xmath10 , deleting an edge in @xmath72 , the operation ` connect ` , or a batched insertion of up to @xmath161 edges in @xmath519 .",
    "an arbitrary initial forest @xmath10 may be specified as part of the input to the preprocessing algorithm .",
    "we are now ready to prove theorem  [ thm : msffewnontreeedges ] . with prim s algorithm implemented with binary heaps",
    ", we can compute the initial msf @xmath10 in @xmath661 worst - case time .",
    "setting up the data structure @xmath401 of lemma  [ lem : fewnontreeedges ] takes @xmath660 worst - case time . in @xmath303 time , a top tree @xmath488 for @xmath10 is set up to support queries of the form `` given vertices @xmath136 and @xmath137 in @xmath488 , is there a @xmath662-path in @xmath488 and if so , what is the heaviest edge on this path ? '' . with standard top tree operations , each edge insertion / deletion and",
    "each query in @xmath488 can be executed in @xmath67 time . in the following , when we refer to updates in @xmath10 and @xmath72 ,",
    "these updates are applied to @xmath401 .    supporting the insertion of an edge @xmath134 in @xmath72",
    "is done as follows .",
    "first , we query @xmath488 with the pair @xmath93 .",
    "if no @xmath662-path exists , @xmath79 is inserted in @xmath10 .    now , suppose a @xmath662-path does exist in @xmath488 and let @xmath663 be the heaviest edge on this path that the query to @xmath488 returns . if @xmath664 , @xmath79 is inserted as a non - tree edge in @xmath72 . otherwise , @xmath663 is deleted from @xmath10 and reinserted as a non - tree edge in @xmath72 and @xmath79 is inserted in @xmath10 .    supporting the deletion of an edge @xmath79 from @xmath72",
    "is done as follows .",
    "first , we apply a delete operation to delete @xmath79 from @xmath72 .",
    "if @xmath79 was in @xmath10 , ` connect`@xmath93 is applied and if an edge is returned , it is inserted as a tree edge in @xmath10 .",
    "it follows from lemma  [ lem : fewnontreeedges ] and the above description that @xmath10 can be maintained in @xmath160 worst - case time per update where an update is the insertion of deletion of a single edge in @xmath72 .",
    "it also follows that a batched insertion that does not change @xmath10 can be supported within this time bound as well since all the edges inserted must belong to @xmath519 .",
    "this shows theorem  [ thm : msffewnontreeedges ] .",
    "in this section , we prove theorem  [ thm : rcpartition ] from section  [ subsec : preprocrestricteddecmsf ] by giving an algorithm which , given any non - empty subset @xmath76 of @xmath40 of size @xmath665 respecting @xmath73 , finds a partition @xmath187 of @xmath76 satisfying the requirements in the theorem . to simplify notation , we shall only present the algorithm for the case where @xmath666 . to generalize this to arbitrary subsets",
    "@xmath76 respecting @xmath73 , one issue is that the lower bound on the probability that the algorithm succeeds is of the form @xmath667 rather than @xmath668 .",
    "however , since @xmath669 , we can get a probability of @xmath670 for an arbitrarily big constant @xmath4 by choosing @xmath671 .",
    "we take care of the remaining issues at the end of this section .    for any @xmath672 ,",
    "define @xmath673 and its inverse @xmath674 .",
    "spielman and teng  @xcite presented a procedure called ` partition ` with the properties stated in the following lemma .",
    "[ lem : partition ] let @xmath675 be a graph and let @xmath672 .",
    "let @xmath676 satisfy @xmath677 and @xmath678 .",
    "let @xmath679 be the sets of cuts output by ` partition`@xmath680 , and let @xmath681 .",
    "then @xmath682 , and the following two properties hold    1 .   with probability at least @xmath683 , @xmath684 2 .   with probability @xmath685 , @xmath686 .    `",
    "partition ` runs in time @xmath687 .",
    "this lemma is not quite identical to  @xcite since they define @xmath688 as @xmath689 whereas we use the simpler definition @xmath673 .",
    "it is easy to see that with this simplification , we only lose @xmath27-factors in the second condition and in the running time of lemma  [ lem : partition ] .    with the definitions in theorem  [ thm : rcpartition ]",
    ", we shall need a variant of ` partition ` which when applied to @xmath690 $ ] ensures that the output cut respects @xmath73 .",
    "this variant , which we refer to as ` cpartition ` , is presented in lemma  [ lem : cpartition ] below . `",
    "cpartition ` applies ` partition ` to a graph @xmath691 $ ] obtained from @xmath690 $ ] by replacing @xmath692 $ ] with a sparse @xmath127-expander graph for @xmath204 for each @xmath74 belonging to @xmath76 .",
    "then ` cpartition ` modifies the cut @xmath693 output by ` partition ` to a new cut @xmath694 respecting @xmath73 such that if @xmath693 had sufficiently low conductance in @xmath691 $ ] then @xmath694 has low conductance in @xmath690 $ ] .    before presenting lemma  [ lem : cpartition ] , we need lemma  [ lem : simpleexpander ] which shows how to efficiently find sparse @xmath127-expander graphs , and we need lemma  [ lem : lowconductancemultigraph ] which implies that we can modify a cut as sketched above .",
    "we say that a graph is _ nowhere dense _ if there is a constant @xmath22 such that every subgraph @xmath106 has at most @xmath695 edges .",
    "[ lem : simpleexpander ] let @xmath76 be a vertex set of size @xmath78 and let @xmath2 be any given constant .",
    "there is an @xmath696 worst - case time algorithm constructing a simple graph @xmath72 for @xmath76 such that with probability @xmath697 , @xmath72 is a nowhere dense @xmath127-expander graph for @xmath76 of max degree @xmath698 .",
    "let @xmath699 be a constant integer , to be specified later . in the proof",
    ", we shall implicitly assume that @xmath78 is larger than @xmath4 by a sufficiently big constant factor .",
    "we consider the algorithm that in a first phase constructs a simple graph @xmath72 with vertex set @xmath76 by adding , for each @xmath700 , @xmath4 edges all with one endpoint in @xmath137 and where the @xmath37th endpoint is chosen independently and uniformly at random among the remaining @xmath701 endpoints in @xmath702 , for @xmath703 . note that @xmath72 need not be simple since it may contain two edges between any given pair of vertices @xmath93 . in a second phase , the algorithm replaces each such pair by a single edge @xmath93 .",
    "it is easy to implement the algorithm to have worst - case running time @xmath704 .",
    "furthermore , any subgraph @xmath705 of @xmath72 has @xmath706 edges ; this follows e.g.  by observing that the edges of @xmath705 can be directed so that each vertex has at most @xmath4 outgoing edges .",
    "hence , @xmath72 is nowhere dense .",
    "we will show that for sufficiently large @xmath4 , @xmath72 satisfies also the remaining conditions of the lemma .",
    "we first show that w.h.p .",
    ", @xmath72 is a @xmath127-expander graph .",
    "we will use that for any integers @xmath707 , @xmath708 where we abuse notation and define @xmath709 for @xmath710 .",
    "furthermore , we exploit the fact that for any @xmath711 , the real function @xmath712 with domain @xmath713 achieves its maximum at @xmath714 with value @xmath715 .",
    "let @xmath716 be given .",
    "we show that w.h.p .",
    ", for every cut where the smaller side contains exactly @xmath16 vertices , the number of edges crossing this cut is greater than @xmath16 .",
    "we shall only count the subset of edges chosen by the first phase of the algorithm when it processes the vertices on the side of the cut of size @xmath16 .",
    "this number will be a lower bound on the final number of edges crossing the cut , obtained after the second phase .",
    "hence , in the analysis , we can ignore this second phase . by a union bound , the probability that at least one cut with one side having size @xmath16 has fewer than @xmath16 edges crossing it is at most @xmath717 we now consider two cases , @xmath718 and @xmath719 .",
    "if @xmath718 , we get an upper bound on the probability of @xmath720 we can choose @xmath4 sufficiently large so that this is at most @xmath721 .",
    "now , assume that @xmath719 .",
    "using the fact that @xmath722 , we get an upper bound on the probability of @xmath723 for sufficiently large constant @xmath4 , this is also at most @xmath721 .    taking a union bound over all choices for @xmath16 and picking constant @xmath4 sufficiently big",
    ", it follows that @xmath72 is a @xmath127-expander graph with probability at least @xmath724 .    finally , we show that w.h.p .",
    ", @xmath72 has max degree @xmath698 .",
    "fix a vertex @xmath700 and let @xmath725 be an arbitrary ordering of the remaining vertices .",
    "introduce indicator variables @xmath726 where for @xmath727 , @xmath728 iff @xmath137 is chosen as a random neighbor of @xmath729 when the first phase of the algorithm processes @xmath729 . in total",
    ", @xmath4 edges are added from @xmath729 . for @xmath730 , consider the @xmath197th edge added from @xmath729 .",
    "the probability that its other endpoint is @xmath137 is @xmath39 if @xmath137 was already chosen as an endpoint of one of the previous @xmath731 edges or the probability is at most @xmath732 since there are @xmath733 endpoints available for the @xmath197th edge . since we may assume that @xmath734 , a union bound gives @xmath735 for @xmath727 .",
    "we observe that variables @xmath726 are independent poisson trials and that @xmath736 has expectation @xmath737\\le 2d$ ] .",
    "let @xmath738 be the value such that @xmath739 .",
    "note that @xmath740 .",
    "we may assume that @xmath741 and a chernoff bound gives @xmath742 observe that @xmath137 has degree @xmath743 after the first phase and hence degree at most @xmath743 after the second phase .",
    "it follows that with probability at least @xmath744 , @xmath137 has degree at most @xmath745 after the second phase .",
    "a union bound shows that with probability at least @xmath746 , @xmath72 has degree @xmath698 .    by a union bound and by picking @xmath747",
    ", it follows that with probability @xmath697 , @xmath72 is a simple @xmath127-expander graph of max degree @xmath698 .    [",
    "lem : lowconductancemultigraph ] let @xmath72 and @xmath73 be as in theorem  [ thm : rcpartition ] .",
    "let @xmath705 be the graph obtained from @xmath72 by replacing , for each @xmath74 , the edges of @xmath692 $ ] with a simple nowhere dense @xmath127-expander graph of @xmath204 with @xmath748 edges .",
    "then for any subset @xmath76 of @xmath40 respecting @xmath73 and for any cut @xmath749 of @xmath76 ,    1 .",
    "@xmath750}(s ) = o(\\phi_{h'[w]}(s))$ ] and if @xmath751 respects @xmath73 then @xmath750}(s ) = \\theta(\\phi_{h'[w]}(s))$ ] , 2 .",
    "@xmath752}(s ) = o(\\phi_{h[w]}(s)n^{{\\epsilon}})$ ] , 3 .   there is an @xmath753 time algorithm which , assuming @xmath752}(s)$ ] is less than a sufficiently small constant , obtains from @xmath751 a cut @xmath754 that respects @xmath73 such that @xmath755}(s ' ) = \\theta(\\mbox{vol}_{h'[w]}(s))$ ] , @xmath755}(w - s ' ) = \\theta(\\mbox{vol}_{h'[w]}(w - s))$ ] , and @xmath752}(s ' ) = o(\\phi_{h'[w]}(s))$ ] .",
    "we split the proof into three parts , corresponding to the three cases in the lemma .",
    "[ [ part-1 ] ] part @xmath127 : + + + + + + + + + + + + + + + + + + + + +    first note that since every set of @xmath73 contained in @xmath76 has size greater than @xmath127 and induces a connected subgraph of both @xmath690 $ ] and @xmath691 $ ] , every vertex has degree at least @xmath127 in both @xmath690 $ ] and @xmath691 $ ] . since @xmath690 $ ] has constant degree , we have @xmath756}(s ) = \\theta(|s|)$ ] and @xmath756}(w - s ) = \\theta(|w - s|)$ ] , and since @xmath691 $ ] is nowhere dense , we have @xmath755}(s ) = \\delta_{h'[w]}(s ) + \\theta(|s|)$ ] and @xmath755}(w - s ) = \\delta_{h'[w]}(s ) + \\theta(|w - s|)$ ] .",
    "now , let @xmath74 be a subset intersecting both sides of @xmath751 .",
    "the number of edges of @xmath692 $ ] crossing @xmath751 is @xmath757 since @xmath72 has constant degree .",
    "the number of edges of @xmath758 $ ] crossing @xmath751 is at least @xmath759 since @xmath758 $ ] is a @xmath127-expander graph .",
    "hence , @xmath760}(s ) = o(\\delta_{h'[w]}(s))$ ] .    to show that @xmath750}(s ) = o(\\phi_{h'[w]}(s))$ ]",
    ", we may assume that @xmath761}(s)\\le\\min\\{|s|,|w - s|\\}$ ] since otherwise , @xmath762}(s),\\mbox{vol}_{h'[w]}(w - s)\\ } = \\delta_{h'[w]}(s ) + \\theta(\\min\\{|s|,|w - s|\\ } ) = \\theta(\\delta_{h'[w]}(s))$ ] , implying that @xmath752}(s ) = \\theta(1)$ ] and we trivially have @xmath750}(s)\\le 1 $ ] .",
    "we get @xmath763}(s ) = o\\left(\\frac{\\delta_{h'[w]}(s)}{\\min\\{|s|,|w - s|\\}}\\right )                 = \\theta\\left(\\frac{\\delta_{h'[w]}(s)}{\\delta_{h'[w]}(s ) + \\min\\{|s|,|w - s|\\}}\\right )                 = \\theta(\\phi_{h'[w]}(s)),\\ ] ] as desired .",
    "now assume that @xmath751 respects @xmath73 . then @xmath761}(s )",
    "= \\delta_{h[w]}(s)$ ] and note that @xmath760}(s ) = o(\\min\\{|s|,|w - s|\\})$ ] .",
    "again we may assume that @xmath761}(s)\\le\\min\\{|s|,|w - s|\\}$ ] since otherwise , @xmath762}(s),\\mbox{vol}_{h'[w]}(w - s)\\ } = \\delta_{h'[w]}(s ) + \\theta(\\min\\{|s|,|w - s|\\ } ) = \\theta(\\delta_{h'[w]}(s))$ ] and @xmath764}(s),\\mbox{vol}_{h[w]}(w - s)\\ } = \\theta(\\min\\{|s|,|w - s|\\ } ) = \\theta(\\delta_{h[w]}(s))$ ] so both @xmath752}(s)$ ] and @xmath750}(s)$ ] are @xmath469 .",
    "we get @xmath763}(s ) = \\theta\\left(\\frac{\\delta_{h'[w]}(s)}{\\min\\{|s|,|w - s|\\}}\\right )                 = \\theta\\left(\\frac{\\delta_{h'[w]}(s)}{\\delta_{h'[w]}(s ) + \\min\\{|s|,|w - s|\\}}\\right )                 = \\theta(\\phi_{h'[w]}(s)).\\ ] ]    [ [ part-2 ] ] part @xmath68 : + + + + + + + + + + + + + + + + + + + + +    let @xmath74 intersect both sides of @xmath751 . the number of edges of @xmath692 $ ] crossing @xmath751 is at least @xmath127 since @xmath692 $ ] is connected .",
    "the number of edges of @xmath758 $ ] crossing @xmath751 is @xmath331 since @xmath758 $ ] is sparse .",
    "hence , we have @xmath765}(s ) = \\theta\\left(\\frac{\\delta_{h'[w]}(s)}{\\delta_{h'[w]}(s ) + \\min\\{|s|,|w - s|\\}}\\right ) = o\\left(\\frac{n^{{\\epsilon}}\\delta_{h[w]}(s)}{\\min\\{|s|,|w - s|\\}}\\right ) = o(n^{{\\epsilon}}\\phi_{h[w]}(s)),\\ ] ] as desired .    [ [ part-3 ] ] part @xmath32 : + + + + + + + + + + + + + + + + + + + + +    let @xmath766 consist of the subsets @xmath31 intersecting both sides of @xmath749 and @xmath767 and let @xmath768 consist of the remaining sets intersecting both sides of @xmath751 .",
    "let @xmath769 .",
    "clearly , @xmath754 respects @xmath73 and can be formed in @xmath753 time .    for each @xmath770 ,",
    "the number of edges of @xmath691 $ ] crossing @xmath771 is at least @xmath772 since @xmath758 $ ] is a @xmath127-expander graph .",
    "since @xmath690 $ ] has constant degree and since the edges of @xmath691 $ ] crossing @xmath773 all belong to @xmath690 $ ] , the number of such edges is @xmath774 .",
    "similarly , for each @xmath775 , the number of edges of @xmath691 $ ] crossing @xmath771 is at least @xmath776 while the number of edges crossing @xmath777 is @xmath778 .",
    "it follows that the number of edges of @xmath691 $ ] crossing @xmath779 is @xmath780}(s)\\min\\{\\mbox{vol}_{h'[w]}(s),\\mbox{vol}_{h'[w]}(w - s)\\})$ ] .",
    "next , we consider the volumes of @xmath781 and @xmath782 in @xmath691 $ ] .",
    "note that the number of edges of @xmath691 $ ] crossing @xmath749 is at least @xmath783 and hence @xmath784}(s)\\mbox{vol}_{h'[w]}(s)$ ] .",
    "similarly , the number of edges of @xmath705 crossing @xmath749 is at least @xmath785 so @xmath786}(s)\\mbox{vol}_{h'[w]}(w - s)$ ] .",
    "let @xmath775 . since @xmath691 $ ] is nowhere dense , we have @xmath787| = o(|c\\cap s|)$ ] and since @xmath72 has constant degree , we have @xmath761}(c\\cap s ) = o(|c\\cap s|)$ ] .",
    "combining this gives @xmath788}(c\\cap s ) = o(|c\\cap s|)$ ] .",
    "we can now bound the volume of @xmath781 in @xmath691 $ ] from below as follows : @xmath789}(s ' ) & = \\mbox{vol}_{h'[w]}(s ) + \\sum_{c\\in\\mathcal c_1}\\mbox{vol}_{h'[w]}(c - s ) - \\sum_{c\\in\\mathcal c_2}\\mbox{vol}_{h'[w]}(c\\cap s)\\\\                 & \\ge \\mbox{vol}_{h'[w]}(s ) - \\delta_{h'[w]}(s ) - \\sum_{c\\in\\mathcal c_2}\\mbox{vol}_{h'[s]}(c\\cap s)\\\\                 & = \\mbox{vol}_{h'[w]}(s ) - o(\\phi_{h'[w]}(s)\\mbox{vol}_{h'[w]}(s ) + \\sum_{c\\in\\mathcal c_2}|c\\cap s|)\\\\                 & = ( 1 - o(\\phi_{h'[w]}(s)))\\mbox{vol}_{h'[w]}(s),\\end{aligned}\\ ] ] and similarly , we get @xmath755}(w - s ' ) = ( 1 - o(\\phi_{h'[w]}(s)))\\mbox{vol}_{h'[w]}(w - s)$ ] . hence ,",
    "assuming @xmath752}(s)$ ] is below a sufficiently small constant , we have @xmath755}(s ' ) = \\theta(\\mbox{vol}_{h'[w]}(s))$ ] and @xmath755}(w - s ' ) = \\theta(\\mbox{vol}_{h'[w]}(w - s))$ ] and hence @xmath752}(s ' ) = o(\\phi_{h'[w]}(s))$ ] .",
    "this shows the third part of the lemma .",
    "we are now ready to present our algorithm ` cpartition ` .",
    "[ lem : cpartition ] let @xmath790 , let @xmath2 be a constant , and let @xmath705 , @xmath73 , and @xmath76 be as in theorem  [ thm : rcpartition ] and lemma  [ lem : lowconductancemultigraph ] .",
    "let @xmath751 be a cut such that @xmath755}(s)\\le\\mbox{vol}_{h'[w]}(w - s)$ ] and @xmath752}(s)\\leq\\theta_+$ ] .",
    "if @xmath791 is less than @xmath792 for a sufficiently large constant @xmath793 , then there is a constant @xmath4 with @xmath794 and an algorithm ` cpartition`@xmath795,\\theta , c)$ ] which outputs a cut @xmath796 respecting @xmath73 such that with probability at least @xmath188 , we have @xmath755}(d)\\leq(1-d)\\mbox{vol}_{h'[w]}(w)$ ] as well as the following two conditions :    1 .",
    "@xmath755}(d ) = \\omega(\\mbox{vol}_{h'[w]}(s))$ ] , 2 .",
    "@xmath752}(d ) = \\tilde o(\\theta)$ ] .    `",
    "cpartition ` runs in worst - case time @xmath797 .    before describing ` cpartition ` ,",
    "we first modify ` partition`@xmath680 from lemma  [ lem : partition ] slightly so that if every component of @xmath798 has volume at most @xmath799 then a cut @xmath352 is output such that @xmath800 .",
    "such a cut is obtained with a simple @xmath801 time greedy algorithm that starts with @xmath802 , then considers the components in order of decreasing volume , and adds the current component to the side of @xmath803 with smaller volume .",
    "this cut satisfies the requirements of lemma  [ lem : partition ] and allows us to only use randomization when @xmath804 .",
    "now , we are ready to describe algorithm ` cpartition`@xmath795,\\theta , c)$ ] .",
    "it consists of an outer loop consisting of @xmath805 iterations for some constant @xmath806 to be specified later .",
    "initially , @xmath807 . in each iteration ,",
    "the ( modified ) algorithm ` partition`@xmath795,\\theta)$ ] is called ; let @xmath359 be the union of sets output by this call . if the bound on @xmath752}(d')$ ] in the second property of lemma  [ lem : partition ] does not hold then the next iteration is executed .",
    "otherwise , the algorithm in the third part of lemma  [ lem : lowconductancemultigraph ] is applied with @xmath359 playing the role of @xmath106 , giving a new cut @xmath754 respecting @xmath73 . if @xmath762}(s'),\\mbox{vol}_{h'[w]}(w - s')\\ } > \\mbox{vol}_{h'[w]}(d)$ ] , @xmath352 is updated to the side of the cut @xmath754 of smaller volume in @xmath691 $ ] .",
    "once all iterations have been executed , the algorithm outputs @xmath352 and then halts .",
    "clearly , the set @xmath352 output by this algorithm respects @xmath73 .",
    "since @xmath705 is nowhere dense , we have @xmath808| = o(|w|)$ ] . excluding the time for obtaining @xmath359",
    ", each iteration takes @xmath809| ) = o(|w|)$ ] time by the third part of lemma  [ lem : lowconductancemultigraph ] . each call to ` partition ` takes @xmath810)|/\\theta^5 ) = \\tilde o(|w|/\\theta^5)$ ] time and computing the union @xmath359 of sets can clearly be done within this time bound as well .",
    "hence , the entire algorithm above runs in @xmath797 time .",
    "let @xmath751 be a cut with @xmath755}(s)\\le\\mbox{vol}_{h'[w]}(w - s)$ ] and @xmath752}(s)\\le\\theta_+$ ] .",
    "we need to show that the two conditions of the lemma are satisfied with probability at least @xmath188 .",
    "note that @xmath755}(d)$ ] can only increase over time and can never be larger than @xmath811}(w)$ ] .",
    "consider any iteration and let @xmath812 be the side of @xmath754 of smaller volume in @xmath691 $ ] .",
    "it suffices to show that for sufficiently large constant @xmath31 and sufficiently small constant @xmath4 , the two conditions of the corollary , with @xmath352 replaced by @xmath812 , are satisfied with probability at least @xmath813 in any given iteration .",
    "consider an arbitrary iteration and let @xmath359 be the union of set output by ` partition`@xmath795,\\theta)$ ] . by lemma  [ lem : partition ] ,",
    "@xmath755}(d')\\le\\frac{65}{72}\\mbox{vol}_{h'[w]}(w)$ ] and the following two properties hold with a certain probability that we show is at least @xmath813 :    1 .",
    "either @xmath755}(d')\\ge\\frac{35}{144}\\mbox{vol}_{h'[w]}(w)$ ] or @xmath814}(s\\cap(w - d'))\\le\\frac 1 2 \\mbox{vol}_{h'[w]}(s)$ ] , 2 .",
    "@xmath752}(d ' ) = \\tilde o(\\theta)$ ] .",
    "the probability that these properties hold is @xmath815 due to our modifification to ` partition ` described above . since @xmath790 and since @xmath816 , we get a lower bound on the probability of @xmath817 which is at least @xmath813 for @xmath0 larger than some constant .",
    "we assume in the following that both of these conditions hold .",
    "since @xmath752}(d ' ) = \\tilde o(\\theta)$ ] and since @xmath818 , picking @xmath793 large enough ensures that @xmath752}(d')$ ] is less than a small constant factor such that the condition in the third part of lemma  [ lem : lowconductancemultigraph ] is satisfied , with @xmath359 playing the role of @xmath106 .",
    "hence , @xmath755}(s ' ) = \\theta(\\mbox{vol}_{h'[w]}(d'))$ ] , @xmath755}(w - s ' ) = \\theta(\\mbox{vol}_{h'[w]}(w - d'))$ ] , and @xmath752}(s_{\\min } ' ) = \\theta(\\phi_{h'[w]}(d ' ) ) = \\tilde o(\\theta)$ ] .    it remains to show that for suitable constant @xmath819 either @xmath755}(s_{\\min}')\\ge d\\mbox{vol}_{h'[w]}(w)$ ] or @xmath755}(s_{\\min } ' ) = \\omega(\\mbox{vol}_{h'[w]}(s))$ ] .",
    "assume first that @xmath755}(d')\\ge\\frac{35}{144}\\mbox{vol}_{h'[w]}(w)$ ] .",
    "since also @xmath755}(d')\\le\\frac{65}{72}\\mbox{vol}_{h'[w]}(w)$ ] , it follows from the above that @xmath755}(s ' ) = \\theta(\\mbox{vol}_{h'[w]}(w))$ ] and that @xmath820}(w - s ' ) = \\theta(\\mbox{vol}_{h'[w]}(w - d ' ) ) = \\theta(\\mbox{vol}_{h'[w]}(w ) - \\mbox{vol}_{h'[w]}(d ' ) ) = \\theta(\\mbox{vol}_{h'[w]}(w)).\\ ] ] picking @xmath4 sufficiently small gives @xmath755}(s_{\\min } ' ) = \\min\\{\\mbox{vol}_{h'[w]}(s'),\\mbox{vol}_{h'[w]}(w - s')\\}\\ge d\\mbox{vol}_{h'[w]}(w)$ ] .",
    "this shows the desired since @xmath821}(w ) = \\omega(\\mbox{vol}_{h'[w]}(s)$ ] .",
    "finally , assume that @xmath755}(d ' ) < \\frac{35}{144}\\mbox{vol}_{h'[w]}(w)$ ] and @xmath814}(s\\cap(w - d'))\\le\\frac 1 2 \\mbox{vol}_{h'[w]}(s)$ ] .",
    "the latter implies that @xmath755}(d ' ) = \\omega(\\mbox{vol}_{h'[w]}(s))$ ] so by the above , @xmath755}(s ' ) = \\omega(\\mbox{vol}_{h'[w]}(s))$ ] .",
    "hence , if @xmath755}(s')\\le \\mbox{vol}_{h'[w]}(w - s')$ ] , we get @xmath755}(s_{\\min } ' ) = \\omega(\\mbox{vol}_{h'[w]}(s))$ ] as desired .",
    "if @xmath755}(s ' ) > \\mbox{vol}_{h'[w]}(w - s')$ ] then since @xmath755}(d')\\le\\frac{65}{72}\\mbox{vol}_{h'[w]}(w)$ ] , we have @xmath820}(s_{\\min } ' ) = \\mbox{vol}_{h'[w]}(w - s ' ) = \\theta(\\mbox{vol}_{h'[w]}(w - d ' ) ) = \\theta(\\mbox{vol}_{h'[w]}(w ) ) = \\omega(\\mbox{vol}_{h'[w]}(s)),\\ ] ] again showing the desired .",
    "we will give a recursive version of ` cpartition ` called ` rcpartition ` which w.h.p .",
    "outputs our desired partition @xmath187 .",
    "let @xmath185 be a given constant and let @xmath822 be a constant to be specified later .",
    "let @xmath823 be a function mapping a value @xmath791 to a value which is @xmath824 so that the cut output by a call ` cpartition`@xmath825 has conductance at most @xmath826 , assuming the two conditions in lemma  [ lem : cpartition ] are satisfied . let @xmath827 be its inverse",
    ".    in the following , let @xmath72 , @xmath705 , and @xmath73 be as in theorem  [ thm : rcpartition ] and lemma  [ lem : lowconductancemultigraph ] .",
    "pseudocode for ` rcpartition ` can be seen in figure  [ fig : rcpartition ] ; we assume it has access to @xmath705 and @xmath73 .",
    "define @xmath828 .",
    "the initial call has parameters @xmath666 , @xmath829 , and @xmath830 .    ' '' ''",
    "+ ddd============`rcpartition`@xmath831 : +   + 1 .",
    "let @xmath352 be the output of ` cpartition`@xmath795 , \\theta , c+1)$ ] + 2 .",
    "if @xmath755}(d ) < n^{2\\tau}$ ] then return @xmath832 + 3 . if @xmath755}(d ) > n^{1 - d\\xi}$ ] then return @xmath833 + 4 .",
    "else return @xmath834 +    ' '' ''    [ lem : rcpartition ] let @xmath2 , @xmath185 , and @xmath822 be constants where @xmath835 .",
    "algorithm ` rcpartition`@xmath836 outputs a partition @xmath187 of @xmath40 respecting @xmath73 such that with probability at least @xmath188 , the following three conditions hold :    1 .   for every @xmath192 and for every cut @xmath837 of @xmath838",
    "where @xmath839}(x - s)\\geq \\mbox{vol}_{h[x]}(s ) = \\omega(n^{2\\tau})$ ] , we have @xmath840}(s ) = \\omega(|s|n^{-\\tau-{\\epsilon}})$ ] , 2 .",
    "the number of edges of @xmath72 between distinct sets of @xmath187 is @xmath841 , and 3 .   the worst - case running time of ` rcpartition`@xmath842 is @xmath843 .    by lemma  [ lem : cpartition ] ,",
    "the output is a partition @xmath187 respecting @xmath73 .",
    "we observe that the number of leaves of the recursion tree is @xmath844 since each leaf corresponds to a subset of @xmath40 of size @xmath845 and the subsets corresponding to all leaves form a partition of @xmath40 .",
    "also , the maximum possible value of @xmath4 in any recursive step is at most @xmath846 , implying that the total number of nodes of the recursion tree is @xmath844 .",
    "note that for all values of @xmath791 in the recursive calls , @xmath847 .",
    "hence , the upper bound on @xmath4 implies that in any recursive step , @xmath848 .",
    "since @xmath849 is a monotonically increasing function , we thus have @xmath850 . since @xmath835 , we also have @xmath851 , as required by lemma  [ lem : cpartition ] .",
    "the probability that a single call to ` cpartition ` in line @xmath127 succeeds to satisfy the conditions in lemma  [ lem : cpartition ] is at least @xmath852 . by a union bound over all nodes in the recursion tree ,",
    "all calls to ` cpartition ` succeed with probability at least @xmath188 .",
    "when we show the three conditions below , we assume that this indeed is the case for every call to ` cpartition ` .",
    "[ [ condition-1 ] ] condition @xmath127 : + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath192 be given and let @xmath837 be a cut of @xmath838 with @xmath853}(s)\\le c'n^{-\\tau - { \\epsilon}}$ ] in @xmath191 $ ] where @xmath854 and @xmath855 is a constant specified below .",
    "we choose @xmath106 so that @xmath856 is maximized over all such cuts @xmath837 ; if @xmath106 does not exist , condition @xmath127 can not be violated for set @xmath838 .",
    "consider the recursive call where @xmath838 is output in line @xmath68 and let @xmath352 be the set computed in line @xmath127 in that recursive call .",
    "we have @xmath857}(d ) < n^{2\\tau}$ ] . by lemma  [ lem : cpartition ] , @xmath838",
    "respects @xmath73 so by the second part of lemma  [ lem : lowconductancemultigraph ] , @xmath858}(s ) = o(\\phi_{h[x]}(s)n^{{\\epsilon } } ) = o(c'n^{-\\tau})$ ] .",
    "we choose @xmath793 sufficiently small so that @xmath858}(s)\\le n^{-\\tau}\\le \\theta_+$ ] . applying lemma  [ lem : cpartition ]",
    "gives @xmath859}(d ) = \\omega(\\mbox{vol}_{h'[x]}(s))$ ] , implying that @xmath857}(s ) = o(n^{2\\tau})$ ] . by the choice of @xmath106",
    ", we have shown that for any cut in @xmath191 $ ] of conductance at most @xmath860 , one of the two sides of the cut has volume @xmath861 .",
    "this implies that for any cut @xmath862 where @xmath839}(x - s)\\ge\\mbox{vol}_{h[x]}(s ) = \\omega(n^{2\\tau})$ ] , we have @xmath840}(s ) = \\omega(\\mbox{vol}_{h[x]}(s)n^{-\\tau-{\\epsilon } } ) = \\omega(|s|n^{-\\tau-{\\epsilon}})$ ] , showing the first condition .",
    "[ [ condition-2 ] ] condition @xmath68 : + + + + + + + + + + + + + + + + + + + + + + + + + +    for each call ` cpartition`@xmath795,\\theta , c+1)$ ] , let @xmath352 be the set output and consider charging the number of edges of @xmath691 $ ] crossing the cut @xmath694 evenly to the vertices on the smaller side of the cut . then for each @xmath192 , each vertex of @xmath838 is charged at most @xmath863 times .",
    "since @xmath791 decreases with @xmath4 , the second part of lemma  [ lem : cpartition ] implies that the amount charged to the vertex each time is @xmath864 .",
    "this shows the second condition .",
    "[ [ condition-3 ] ] condition @xmath32 : + + + + + + + + + + + + + + + + + + + + + + + + + +    consider a fixed node of the recursion tree corresponding to a call ` rcpartition`@xmath865 for which line @xmath866 is executed .",
    "let @xmath867 be the maximal subsets @xmath868 for which the two recursive calls in line @xmath32 are made with the first having input @xmath869 .",
    "we order the sets such that @xmath870 is obtained before @xmath871 by the algorithm for @xmath449 .",
    "note that these are pairwise disjoint subsets of @xmath76 .",
    "for @xmath872 , let @xmath873 .    before showing condition @xmath32 , we first show that @xmath755}(s_k ) = o(n^{1 - d\\xi})$ ] . for some constant @xmath874 to be specified below",
    ", we may assume that @xmath755}(w ) > 2cn^{1 - d\\xi}$ ] and @xmath755}(s_k ) > cn^{1 - d\\xi}$ ] .",
    "we will show how to derive a contradiction when @xmath31 is sufficiently large .",
    "consider the largest index @xmath875 for which @xmath755}(s_{k ' } ) \\le cn^{1 - d\\xi } < \\frac 1 2 \\mbox{vol}_{h'[w]}(w)$ ] . for @xmath876 ,",
    "since @xmath871 was obtained by a call ` cpartition`@xmath877,f_+(\\theta),c+1)$ ] , we have @xmath878}(d_{i+1})\\le \\theta_+/\\log n$ ] . hence @xmath879}(s_{k'+1 } ) \\le \\sum_{i = 0}^{k'}\\delta_{h'[w - s_i]}(d_{i+1 } )                        \\le \\frac{\\theta_+}{\\log n}\\sum_{i = 0}^{k'}\\mbox{vol}_{h'[w - s_i]}(d_{i+1 } )                        \\le \\frac{\\theta_+}{\\log n}\\mbox{vol}_{h'[w]}(s_{k'+1}).\\ ] ] by the choice of @xmath880 and by lemma  [ lem : cpartition ] , it follows that @xmath755}(w - s_{k'+1 } ) = \\theta(\\mbox{vol}_{h'[w]}(w ) ) = \\omega(\\mbox{vol}_{h'[w]}(s_{k'+1}))$ ] .",
    "thus , @xmath752}(s_{k'+1 } ) = o(\\theta_+/\\log n)$ ] so for @xmath0 bigger than some constant , we have @xmath752}(s_{k'+1})\\le\\theta_+$ ] . by the choice of @xmath76 , ` cpartition`@xmath795,\\theta , c+1)$ ] gave a set @xmath352 with @xmath755}(d)\\le n^{1 - d\\xi}$ ] .",
    "applying lemma  [ lem : cpartition ] with @xmath881 playing the role of @xmath106 , we can choose constant @xmath31 large enough so that @xmath755}(s_{k'+1 } ) < c\\mbox{vol}_{h'[w]}(d)\\le cn^{1 - d\\xi}$ ] , contradicting the choice of @xmath880 .",
    "it follows from the above that @xmath882}(s_k ) ) = o(n^{1 - d\\xi})$ ] .",
    "we can use this to bound the number of sets @xmath868 for which the test in line @xmath32 succeeds with parameter @xmath883 . for each such @xmath352",
    ", we have @xmath884 and @xmath885}(d ) > n^{1 - ( d+1)\\xi}$ ] for some @xmath886 . since @xmath705 is nowhere dense ,",
    "since @xmath72 has constant degree , and since @xmath352 respects @xmath73 , we have @xmath887)| + |\\delta_{h'[w']}(d)| ) = \\omega(\\mbox{vol}_{h'[w']}(d ) ) = \\omega(n^{1 - ( d+1)\\xi } ) = \\omega(|s_k|/n^{\\xi})$ ] so the number of choices for @xmath352 is @xmath888 .",
    "we have shown that the total number of recursion nodes of the form @xmath889 with @xmath886 is @xmath888 .",
    "the time spent in each of them is dominated by a single call to ` cpartition`@xmath890 which by lemma  [ lem : cpartition ] takes worst - case time @xmath891 .",
    "summing over all choices of @xmath892 , this is @xmath893 . over all @xmath76 ,",
    "this is @xmath894 . finally , summing over all @xmath895 choices of @xmath4",
    "gives a total worst - case running time for ` rcpartition`@xmath896 of @xmath894 , showing the third condition .",
    "we are now ready to prove theorem  [ thm : rcpartition ] from section  [ subsec : preprocrestricteddecmsf ] in the case where @xmath666 .",
    "first , we construct @xmath691 $ ] which by lemma  [ lem : simpleexpander ] takes @xmath753 time .",
    "we then apply lemma  [ lem : rcpartition ] with @xmath897 , @xmath119 of the form @xmath898 for suitable constant @xmath31 , @xmath899 for suitable hidden constants .",
    "denote by @xmath900 the output partition of @xmath40 .",
    "we may assume that the conditions in the lemma are satisfied since this holds with probability at least @xmath188 .",
    "let @xmath187 be the set of components in @xmath901 $ ] over all @xmath902 .",
    "clearly , each set of @xmath187 respects @xmath73 and the second and third conditions of theorem  [ thm : rcpartition ] hold with the above substitutions .    to show the first condition ,",
    "let @xmath192 be given and consider a cut @xmath862 in @xmath838 where @xmath903 .",
    "we will show that @xmath840}(s ) = \\omega(|s|n^{-2{\\epsilon}})$ ] .",
    "assume first that @xmath839}(s ) = \\omega(n^{2\\tau})$ ] and consider the cut @xmath904 where @xmath905 . by picking the hidden constant in @xmath845 sufficiently big",
    ", the first condition of lemma  [ lem : rcpartition ] implies that @xmath840}(s ) = \\delta_{h[x']}(s ) = \\omega(|s|n^{-\\tau-{\\epsilon } } ) = \\omega(|s|n^{-2{\\epsilon}}))$ ] , as desired .",
    "now assume that @xmath839}(s ) = o(n^{2\\tau } ) = o(n^{2{\\epsilon}})$ ] . since @xmath191 $ ]",
    "is connected , @xmath840}(s)\\ge 1 = \\omega(\\mbox{vol}_{h[x]}(s)n^{-2{\\epsilon } } ) = \\omega(|s|n^{-2{\\epsilon}})$ ] , again showing the desired .",
    "hence , @xmath191 $ ] is a @xmath119-expander graph for suitable choice of constant @xmath31 , completing the proof of theorem  [ thm : rcpartition ] in the special case where @xmath666 .    in the general case , @xmath906 and replacing @xmath0 by @xmath215 above",
    ", we get @xmath189 and @xmath899 .",
    "this shows theorem  [ thm : rcpartition ] .",
    "in this section , we present the data structure of theorem  [ thm : disconnectexpandergraph ]",
    ". we shall refer to the dynamic graph as @xmath34 here rather than @xmath72 and to simplify notation , we assume it to have @xmath0 vertices ; it is easy to see that the problem only becomes easier if there are fewer than @xmath0 vertices .",
    "we require that @xmath9 has max degree at most @xmath32 , that it is initially a @xmath119-expander graph w.h.p . , where @xmath907 , and that the total number of edge deletions in @xmath9 is at most @xmath378 .",
    "we also require that the sequence of updates is independent of the random bits used by the data structure .",
    "we regard @xmath9 as an unweighted graph since its edge weights are not relevant in this section . however , since we will apply lemma  [ lem : fewnontreeedges ] which assumes an edge weight function , we pick some arbitrary lexicographical ordering of the edges of @xmath9",
    ". we shall refer to an ffe structure here as an instance of the data structure in this lemma and denote it by @xmath162 for a graph @xmath72 .",
    "we start by describing the preprocessing step of our data structure .",
    "we may restrict our attention to the case where the initial graph @xmath9 is connected as follows . during preprocessing , the data structure checks if @xmath9 is connected .",
    "if @xmath9 is not , it can not be a @xmath119-expander graph and the data structure simply lets the first set @xmath104 output be equal to @xmath40 as this will satisfy the conditions in theorem  [ thm : disconnectexpandergraph ] .",
    "first , for some parameter @xmath908 between @xmath127 and @xmath0 , we apply frederickson s ` findclusters ` procedure  @xcite to an arbitrary spanning tree of of @xmath9 , giving a partition of @xmath40 into a set @xmath73 of _ clusters _ where for each @xmath74 , @xmath909 , and @xmath910 $ ] is connected ; we choose @xmath911 where the hidden constant will be picked sufficiently big ( but independent of @xmath380 which we regard as a variable here ) to make our arguments in this and the next two sections carry through . we compute a spanning tree @xmath912 of @xmath910 $ ] for each cluster @xmath31 .",
    "the set @xmath73 will be dynamic and our data structure maintains this clustering as well as spanning tree @xmath912 of each @xmath74 .",
    "next , we obtain a subset @xmath58 of @xmath45 by sampling each edge independently with some probability @xmath80 to be specified later .",
    "we form a subgraph @xmath72 of @xmath9 consisting of edge set @xmath58 and of @xmath912 for each @xmath74 .",
    "we apply lemma  [ lem : fewnontreeedges ] to set up an ffe structure @xmath162 for @xmath72 where the initial forest @xmath913 is a spanning forest of @xmath72 containing @xmath912 for each @xmath74",
    ". the purpose of @xmath913 will be to certify connectivity of @xmath914 $ ] where @xmath343 is a subset satisfying the first requirement in theorem  [ thm : disconnectexpandergraph ] .",
    "our data structure will maintain a subset @xmath838 of @xmath40 respecting @xmath73 .",
    "we require that vertices can never be added to @xmath838 , only removed . with high probability , at all times ,",
    "@xmath915 $ ] is an expander graph for some later specified expansion factor and @xmath191 $ ] is connected .",
    "we initialize @xmath916 .",
    "finally , we do some additional preprocessing for a procedure called ` xprune ` . its purpose will be to `` prune '' @xmath838 in each update by removing some clusters from this set such that w.h.p .",
    ", @xmath915 $ ] remains an expander graph .",
    "we describe this procedure in detail in section  [ sec : xprune ] ; in this section , we shall regard it as a black box .",
    "when an edge @xmath79 is deleted from @xmath9 , ` xprune`@xmath291 will update @xmath838 and output the clusters of @xmath73 that are removed from @xmath838 .",
    "for some later specified value @xmath917 , we require the following two properties to hold w.h.p .",
    "when ` xprune`@xmath291 returns :    1 .   for",
    "each @xmath73-respecting cut @xmath918 of @xmath838 , the number of edges of @xmath915 $ ] crossing @xmath918 is at least @xmath919 , and 2 .",
    "the total size of all clusters output by ` xprune ` over all updates is @xmath920 .    for",
    "now , we require that @xmath921 .",
    "` xprune ` will have access to @xmath9 and @xmath73 but not to @xmath58 so the updates to @xmath838 will be independent of the random bits used to form @xmath58 .      given the above preprocessing , we now describe how to handle updates .",
    "the following invariants will be maintained :    [ inv : clustering ] for each @xmath74 , @xmath910 $ ] contains a spanning tree @xmath912 , @xmath922 , and either @xmath923 or no edge of @xmath915 $ ] leaves @xmath31 .",
    "[ inv : fh ] @xmath913 is a spanning forest of @xmath72 such that for each @xmath74 , @xmath913 contains @xmath912 .",
    "now we describe how to handle an update to @xmath9 consisting of the deletion of an edge @xmath134 such that the invariants above are maintained . for now , we only focus on maintaining clusters and ignore updates to @xmath838 .",
    "the approach we use is similar to how regions are maintained in section  [ sec : fewnontreeedges ] .",
    "we first delete @xmath79 from @xmath9 , @xmath72 , and @xmath162 .",
    "we then consider two cases :    [ [ subsubsec : intraclusteredge ] ] edge @xmath79 is an intra - cluster edge : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in this case , @xmath924 $ ] for some cluster @xmath74 .",
    "if @xmath925 , no further updates are needed and the invariants are maintained , so consider the case when @xmath926 .",
    "the deletion of @xmath79 splits @xmath912 into two subtrees @xmath927 and @xmath928 spanning subsets @xmath548 and @xmath549 of @xmath31 , respectively .",
    "we visit the edges of @xmath915 $ ] incident to @xmath929 to look for a replacement edge for @xmath912 .",
    "if such an edge @xmath135 is found , @xmath31 remains a cluster , @xmath912 is updated to @xmath930 , and @xmath162 is updated by adding @xmath135 as a tree edge to @xmath913 .",
    "the remaining case is when no replacement edge for @xmath912 was found among the edges in @xmath915 $ ] .",
    "first , @xmath31 is removed from @xmath73 .",
    "next , @xmath548 and @xmath549 are updated ; we only describe the update for @xmath548 as @xmath549 is handled similarly .",
    "if @xmath931 , @xmath548 becomes a new cluster and is added to @xmath73 with spanning tree @xmath929 . otherwise , we look for an edge of @xmath915 $ ] leaving @xmath548 .",
    "if no such edge is found , @xmath548 is added to @xmath73 with spanning tree @xmath929 .",
    "otherwise , let @xmath932 be the lexicographically smallest such edge is not important and is mainly made to emphasize that at any step , the clusters of @xmath73 do not depend on the random bits used to form @xmath58 . ] where @xmath933 and @xmath496 belongs to some other cluster @xmath260 .",
    "we form @xmath934 and let @xmath935 be the spanning tree @xmath936 of @xmath937 .",
    "note that @xmath938 .",
    "if also @xmath939 , we add @xmath937 to @xmath73 .",
    "otherwise , we apply frederickson s ` findclusters ` to @xmath935 to partition @xmath937 into @xmath8 sub - clusters each inducing a subtree of @xmath935 and each of size between @xmath908 and @xmath940 .",
    "we replace @xmath548 and @xmath260 with these sub - clusters in @xmath73 .",
    "it is easy to see that the above satisfies invariant  [ inv : clustering ] . to satisfy invariant  [ inv : fh",
    "] , we do as follows . if a replacement edge @xmath135 was found for @xmath912 in the above procedure , we add it to @xmath913 . otherwise , if @xmath937 could be formed when processing @xmath548 above , we add @xmath298 to @xmath913 .",
    "this may create a cycle in @xmath913 in which case we delete an inter - cluster edge incident to @xmath937 belonging to this cycle .",
    "a similar update is done when processing @xmath549 .    at this point",
    ", it may happen that @xmath913 is no longer a spanning forest of @xmath191 $ ] .",
    "we apply ` connect`@xmath93 to @xmath162 and if a reconnecting edge is found , it is added to @xmath913 .",
    "[ [ edge - e - is - an - inter - cluster - edge ] ] edge @xmath79 is an inter - cluster edge : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this case is handled in the same way as above except",
    "that @xmath73 remains unchanged .",
    "it is easy to see that the above satisfies the invariants .",
    "note that since the procedure above only looks for reconnecting edges in @xmath915 $ ] , a cluster not in @xmath941 can never be merged with another cluster , it can only be split into smaller clusters and these will never intersect @xmath838 . in particular , vertices will never be added to @xmath838 , satisfying our requirement above .",
    "we now present the entire data structure for handling updates which , in addition to maintaining clusters , also supports updates to @xmath838 with the procedure ` xprune ` . at all times ,",
    "@xmath838 respects @xmath73 and this procedure implicitly maintains @xmath838 by maintaining the set @xmath941 of clusters of @xmath73 contained in @xmath838 .    the data structure maintains a subset @xmath942 of @xmath73 which is initialized to be empty during preprocessing .",
    "this set can be regarded as a buffer of clusters whose vertex sets are waiting to be output in subsets @xmath341 in theorem  [ thm : disconnectexpandergraph ] . at all times , @xmath943 .",
    "now consider an update consisting of the deletion of an edge @xmath134 from @xmath9 .",
    "we split the update into two phases where the first phase takes place prior to @xmath79 being deleted and the second phase starts with the deletion of @xmath79 .",
    "[ [ phase-1 ] ] phase @xmath127 : + + + + + + + + + + + + + + + + + + + + + +    we check if @xmath942 is empty .",
    "if not , we continue with phase @xmath68 . otherwise , we first remove from @xmath72 and @xmath162 every edge @xmath944 incident to a cluster of @xmath945 and apply ` connect`@xmath946 in @xmath162 to maintain invariant  [ inv : fh ]",
    ". then we check if @xmath913 contains a tree spanning @xmath838 .",
    "if not , we output @xmath40 and halt , skipping phase @xmath68 .",
    "[ [ phase-2 ] ] phase @xmath68 : + + + + + + + + + + + + + + + + + + + + + +    at the beginning of phase @xmath68 , either @xmath942 is non - empty or @xmath913 contains a tree spanning @xmath838 .",
    "we first apply the procedure described above for updating clusters .",
    "if a cluster @xmath947 is split into two sub - clusters in this procedure , they replace @xmath31 in @xmath942 ; note that clusters in @xmath942 can never be merged since @xmath943 .",
    "let @xmath535 and @xmath493 be the trees of @xmath913 containing @xmath136 and @xmath137 , respectively , after this update .",
    "if @xmath948 , we set @xmath949 to be the smaller of the two sets @xmath950 and @xmath515 ; otherwise , @xmath951 .",
    "we then execute ` xprune`@xmath291 which updates @xmath941 and outputs a subset @xmath952 of clusters ; we update @xmath953 .",
    "next , we remove a subset @xmath954 of clusters from @xmath942 whose total vertex size is between @xmath955 and @xmath956 ; if the total size of clusters in @xmath942 is less than @xmath955 , we set @xmath957 , thereby emptying @xmath942 .",
    "note that by invariant  [ inv : clustering ] , @xmath958 is well - defined .",
    "finally , we output @xmath959 .",
    "we now show that the update procedure described above satisfies the requirements of theorem  [ thm : disconnectexpandergraph ] except that we delay the bound on running time until later .    for suitable sets @xmath343 ,",
    "the procedure above satisfies the first requirement of theorem  [ thm : disconnectexpandergraph ] .",
    "we may assume that @xmath40 is not output in phase @xmath127 of any update since if such an update @xmath16 exists , we can simply pick @xmath960 for every @xmath961 and we only need to focus on updates @xmath962 .",
    "we shall denote the set @xmath838 resp .",
    "@xmath942 at the beginning of an update @xmath16 by @xmath963 resp .",
    "@xmath964 and denote the set @xmath949 formed in update @xmath16 by @xmath965 .",
    "now , consider an update @xmath16 and let @xmath966 be the latest update for which @xmath967 ; note that @xmath880 exists since @xmath942 is empty at the beginning of the first update .",
    "we show that @xmath968 satisfies the first requirement of theorem  [ thm : disconnectexpandergraph ] .    since @xmath967",
    ", every vertex of @xmath969 has been output in updates prior to @xmath880 .",
    "furthermore , @xmath970 is output in update @xmath971 for @xmath972 .",
    "hence , @xmath343 is contained in the union of sets output during the @xmath16 first updates .",
    "it remains to show that @xmath914 $ ] is connected at the end of update @xmath16 . at the end of phase @xmath127 of update @xmath880",
    ", @xmath913 contains a tree spanning @xmath973 .",
    "hence , at the end of update @xmath16 , @xmath913 contains a tree spanning @xmath974 .",
    "since @xmath913 is contained in @xmath9 , it follows that @xmath914 $ ] is connected .",
    "we now consider the second requirement of theorem  [ thm : disconnectexpandergraph ] .",
    "we delay the analysis of the running time until section  [ subsec : decexpimpl ] below and show that w.h.p .",
    ", each set output has size @xmath345 .    in the following ,",
    "let @xmath975 be an integer which w.h.p .",
    "is an upper bound on the maximum number of consecutive updates for which @xmath942 fails to be emptied . since w.h.p .",
    ", the total size of all clusters output by ` xprune ` over all updates is @xmath920 and since we output @xmath976 vertices in each update that does not empty @xmath942 , we can pick @xmath977 .    fix sampling probability @xmath978 for a sufficiently large constant @xmath979 .",
    "we get the following lemma , showing that the data structure is unlikely to output the entire vertex set @xmath40 at the end of phase @xmath127 .",
    "[ lem : skeletoncertificate ] w.h.p .",
    ", at the beginning of each update , @xmath191",
    "$ ] is connected .",
    "we may assume that @xmath980 since otherwise , @xmath191 $ ] is connected as every cluster in @xmath941 is spanned by a tree belonging to @xmath191 $ ] .",
    "given this assumption and since w.h.p .",
    ", @xmath915 $ ] is connected by the first property of ` xprune ` , it follows from invariant  [ inv : clustering ] that w.h.p .",
    ", each cluster in @xmath941 contains at least @xmath908 vertices .",
    "assume in the following that @xmath9 initially is a @xmath119-expander graph and that the first property of ` xprune ` holds after each call to this procedure .",
    "we may make these assumptions since they hold with high probability .    consider the beginning of some update .",
    "if it is the first update then since @xmath915 = g$ ] is a @xmath119-expander graph , we have in particular that for any @xmath73-respecting cut @xmath918 , the number of edges of @xmath981)$ ] crossing @xmath982 is at least @xmath983 . if it is not the first update",
    "then since ` xprune ` was executed at the end of the previous update , the number of edges crossing each such cut is at least @xmath919 .",
    "updates to @xmath838 are independent of the sampled edges of @xmath72 so for any @xmath73-respecting cut @xmath918 , the expected number of edges of @xmath72 crossing @xmath982 is at least @xmath984 .",
    "consider a @xmath73-respecting cut in @xmath838 where the smaller side contains @xmath16 clusters .",
    "the expected number of edges of @xmath72 crossing the cut is at least @xmath985 . by a chernoff bound , the probability that the number of edges of @xmath72 crossing the cut is less than @xmath986 is at most @xmath987 .",
    "the number of @xmath73-respecting cuts of @xmath838 where the smaller side contains @xmath988 clusters is less than @xmath989 .",
    "a union bound over all such cuts and over all @xmath16 shows that with probability at least @xmath990 , the number of edges of @xmath72 crossing any @xmath73-respecting cut of @xmath838 is at least @xmath991 .",
    "in particular , @xmath191 $ ] is connected with probability at least @xmath990 . picking @xmath992",
    "sufficiently large shows the lemma .",
    "we pick @xmath911 sufficiently small such that @xmath993 .",
    "[ lem : hprimesplitbound ] w.h.p .",
    ", at the end of each update , every tree of @xmath913 except one has size @xmath345 .",
    "assign numbers @xmath994 to the updates in the order they occur . for @xmath995 , define @xmath996 such that in the beginning of update @xmath996 , @xmath942 is empty and such that this happened exactly @xmath997 times in previous updates . note that @xmath998 and since @xmath942 is empty initially , we have @xmath999 .",
    "we denote by @xmath1000 the set @xmath838 at the start of update @xmath996 .",
    "note that from the start of phase @xmath68 of update @xmath996 until the end of the last update , all inter - cluster edges of @xmath72 are contained in @xmath1001 $ ] so by invariant  [ inv : clustering ] , all trees of @xmath913 not in @xmath1001 $ ] have size @xmath1002 .",
    "hence , from the end of update @xmath996 until the end of update @xmath1003 , we only need to show the lemma for trees of @xmath913 contained in @xmath1000 . by invariant  [ inv : clustering ] and lemma  [ lem : skeletoncertificate ]",
    ", we may assume that at the beginning of update @xmath996 , each cluster has size @xmath1004 .",
    "consider an update @xmath197 and pick @xmath37 such that @xmath1005 .",
    "with the same arguments as in the proof of lemma  [ lem : skeletoncertificate ] , it follows that at the start of update @xmath996 , w.h.p .",
    ", for every @xmath73-respecting cut @xmath1006 , the number of edges of @xmath1001 $ ] crossing @xmath1006 is at least @xmath1007 .",
    "let @xmath1008 resp .",
    "@xmath1009 be the set @xmath73 at the start of update @xmath996 resp .",
    "note that @xmath1009 is also the set @xmath73 at the end of update @xmath197 .    now , consider the end of update @xmath197 and let @xmath1006 be a @xmath1009-respecting cut where the smaller side contains @xmath16 clusters .",
    "we have @xmath1011 .",
    "hence , only @xmath1012 clusters of @xmath1008 intersect both sides of @xmath1006 since each update changes only @xmath8 clusters .",
    "let @xmath1013 be the union of clusters of @xmath1014 contained in @xmath274 .",
    "note that @xmath1015 contains @xmath1016 clusters of @xmath1008 . by the first property of ` xprune ` , the number of edges of @xmath1001 $ ] that crossed @xmath1017 at the start of update @xmath996 was @xmath1018 .",
    "the number of such edges which have one endpoint in @xmath1015 and one endpoint in @xmath274 is @xmath1019 so the number of edges of @xmath1001 $ ] that crossed @xmath1020 at the start of update @xmath996 was @xmath1018 .",
    "since no more than @xmath975 edges have been deleted since then , there are @xmath1018 edges of @xmath1001 $ ] and hence @xmath1021 expected number of edges of @xmath1022 $ ] crossing @xmath1006 at the end of update @xmath197 .    using chernoff bounds as in the proof of lemma  [ lem : skeletoncertificate ]",
    ", it follows that at the end of update @xmath197 , w.h.p .",
    ", for every @xmath1009-respecting cut where the smaller side contains @xmath1023 clusters , there is at least one edge of @xmath72 crossing this cut .",
    "if at the end of update @xmath197 there were two trees in @xmath913 of size @xmath1024 , there would be a @xmath1009-respecting cut where the smaller side contains @xmath1025 clusters and where no edge of @xmath72 crosses this cut which by the above only occurs with low probability .",
    "the lemma now follows since @xmath993 .",
    "we can now show that the size bound in the second requirement of theorem  [ thm : disconnectexpandergraph ] holds .",
    ", for each update , the set output in phase @xmath68 has size @xmath345 .    by lemma  [ lem : skeletoncertificate ] , w.h.p .",
    ", sets are only output in phase @xmath68 .",
    "consider an execution of this phase when an edge @xmath79 is deleted . by invariant  [ inv : clustering ] ,",
    "the size of each subset @xmath1026 is @xmath345 .",
    "note that when @xmath949 is formed , @xmath913 does not change for the rest of the update .",
    "hence , at the end of the update , if @xmath949 is not empty , it must be the vertex set of some tree of @xmath913 and because of the way we choose @xmath949 , this can not be the tree with the most vertices .",
    "lemma  [ lem : hprimesplitbound ] then implies that @xmath1027 .",
    "we now give the implementation details for the data structure of this section and analyze its preprocessing and update time . the implementation and analysis of the performance of @xmath1028",
    "is delayed until section  [ sec : xprune ] .    by lemma  [ lem : fewnontreeedges ] ,",
    "the preprocessing can be done in @xmath1029 worst - case time .",
    "we shall maintain @xmath942 as a linked list so that each insertion / deletion of a cluster in this list takes @xmath8 time . in the following ,",
    "we focus on an update consisting of the deletion of an edge @xmath79 .",
    "[ [ phase-1 - 1 ] ] phase @xmath127 : + + + + + + + + + + + + + + + + + + + + + +    observe that at all times , the edges of @xmath72 that do not belong to @xmath913 must all belong to sampled set @xmath58 and w.h.p .",
    ", @xmath1030 .",
    "thus , by lemma  [ lem : fewnontreeedges ] , w.h.p .  each update to @xmath162 can be done in @xmath1031 worst - case time .    by the second property of ` xprune ` , w.h.p .",
    ", the total number of vertices in clusters of @xmath945 is @xmath920 .",
    "since updates to @xmath838 are independent of @xmath58 , w.h.p . , the expected number of edges of @xmath58 incident to these clusters is @xmath1032 . by a chernoff bound , w.h.p .",
    "the actual number of such edges is @xmath1033 . for each cluster @xmath74",
    ", we shall maintain a linked list of the edges of @xmath58 incident to @xmath31 ; this can easily be done in @xmath1002 time per update since a single update only affects @xmath8 clusters .    by the first property of ` xprune ` , w.h.p .",
    ", in every update , each cluster of @xmath941 has size @xmath1004 .",
    "hence , w.h.p .",
    ", for any execution of phase @xmath127 where @xmath942 is empty , the number of clusters of @xmath945 that have not been processed in a previous such execution is @xmath1034 .",
    "if we use the edge - lists associated with clusters , we can identify the edges of @xmath58 incident to clusters of @xmath945 in worst - case time @xmath1035 with high probability . by the above , w.h.p .",
    "the total worst - case time for updating @xmath913 is @xmath1036 .    in order to detect",
    "if @xmath913 contains a tree spanning @xmath838 , we shall maintain @xmath1037 as well as the number of trees in @xmath913 .",
    "this can easily be done within the above time bounds .",
    "we observe that after the update of @xmath913 , the number of trees in @xmath913 is equal to @xmath1038 iff @xmath913 contains a tree spanning @xmath838 .",
    "hence , detecting whether the latter holds takes constant time . by lemma  [ lem : skeletoncertificate ]",
    ", we can afford to spend linear time to output @xmath40 since this case occurs with low probability .    combining all of the above",
    ", it follows that w.h.p . , phase @xmath127 can be executed in @xmath1039 worst - case time .",
    "[ [ phase-2 - 1 ] ] phase @xmath68 : + + + + + + + + + + + + + + + + + + + + + +    each execution of the procedure in section  [ subsec : updateclusters ] can easily be done in @xmath1002 time plus the time to execute an operation in @xmath913 where an operation is either detecting a cycle when inserting an edge in @xmath913 or the operation ` connect ` in @xmath162 .",
    "the latter takes @xmath1040 worst - case time . with the notation in section  [ subsec : updateclusters ] , if adding @xmath298 creates a cycle in @xmath913 , we can identify the inter - cluster edge on the cycle incident to @xmath937 in @xmath67 time by maintaining a top tree for @xmath913 which supports the operation of finding the first inter - cluster edge on a path between two query vertices ; inter - cluster edges of @xmath913 are marked in the top tree and finding the nearest marked node is an operation that such a data structure supports .",
    "a top tree can also be used to maintain the vertex size of each tree in @xmath913 in @xmath67 time . by lemma  [ lem : hprimesplitbound ] , w.h.p .",
    "the set @xmath949 can thus be formed in @xmath345 time .",
    "we can easily maintain the size of each cluster within the time bounds above so extracting set @xmath954 from @xmath942 can be done in @xmath1041 worst - case time .",
    "it now follows that w.h.p .",
    ", phase @xmath68 can be executed in @xmath1042 worst - case time , excluding the time for ` xprune ` .",
    "total time for both phases is thus @xmath1043 which is within the time bound of theorem  [ thm : disconnectexpandergraph ] .",
    "in this section , we show corollary  [ cor : lowconductance ] which will be needed in the next section .",
    "it shows a result somewhat similar to karger  @xcite but for conductance instead of cut values . the corollary is a bit technical but it roughly implies that in order to find low - conductance cuts in a graph , it suffices to look for them in a sparse sampled representative of this graph .",
    "first we need the following lemma .",
    "[ lem : lowconductance ] given @xmath2 , @xmath1044 , and @xmath1045 , let @xmath1046 be an @xmath0-vertex multigraph with a finite number of edges and degree at least @xmath1047 .",
    "let @xmath1048 be the multigraph obtained from @xmath1049 by sampling each edge independently with probability @xmath1050 . then with probability @xmath668 , for every cut @xmath1051 in @xmath73 ,    1 .   if @xmath1052 then @xmath1053 deviates from @xmath1054 by a factor of at most @xmath866 , and 2 .   if @xmath1055 then @xmath1056 .",
    "we may assume that @xmath1057 .",
    "let @xmath1058 so that @xmath1059 .",
    "let positive integer @xmath1060 be given .",
    "consider a cut @xmath1051 in @xmath73 where the smaller side has size @xmath16 .",
    "let @xmath1061 resp .",
    "@xmath1062 be a side of the cut with minimum volume in @xmath1049 resp .",
    "let @xmath1064 = p\\delta_{g_{\\mathcal c}}(s_v)$ ] , @xmath1065 = p\\mbox{vol}_{g_{\\mathcal c}}(s_v)$ ] , and @xmath1066 = p\\mbox{vol}_{g_{\\mathcal c}}(s_v')$ ] . by the degree",
    "lower bound , @xmath1067    assume first that @xmath1052 . since @xmath1068 , a chernoff bound implies that the probability that @xmath1069 deviates by at most a factor of @xmath68 from @xmath1070 is at least @xmath1071 .",
    "similarly , @xmath1072 deviates by at most a factor of @xmath68 from @xmath1073 with probability at least @xmath1074 .",
    "we have @xmath1075 by a chernoff bound , the probability that @xmath1076 deviates from @xmath1077 by at most a factor of @xmath68 is at least @xmath1074 .",
    "a union bound then implies that all three chernoff bounds hold with probability at least @xmath1078 , in which case @xmath1079 hence , if @xmath1080 then the first condition of the lemma holds for cut @xmath1081 with probability at least @xmath1078 .",
    "now assume that @xmath1055 . using the observations above and",
    "the fact that @xmath1082 , we can bound the probability that @xmath1053 is greater than @xmath1083 by @xmath1084    we will use a chernoff bound to show that @xmath1085 . pick real number @xmath738 such that @xmath1086 . since @xmath1087 , we have @xmath1088 and hence @xmath1089 .",
    "furthermore , it follows from the above that @xmath1090 and a chernoff bound now shows that @xmath1091 as desired .",
    "we conclude that @xmath1092 .    combining all of the above",
    ", it follows that with probability at least @xmath1078 , @xmath1051 satisfies the first condition of the lemma when @xmath1052 and the second condition when @xmath1055 . the number of cuts of @xmath73 where the smaller side has size @xmath16 is at most @xmath989 . by a union bound ,",
    "the probability that the conditions of the lemma hold for all such cuts is at least @xmath1093 .",
    "the lemma now follows by a union bound over all @xmath1094 .",
    "[ cor : lowconductance ] let @xmath34 be an @xmath0-vertex graph of max degree @xmath4 , let @xmath2 be a constant and let @xmath1044 , and @xmath1045 be given .",
    "let @xmath73 be a clustering of @xmath40 such that for each @xmath74 , @xmath1095 and @xmath910 $ ] is connected .",
    "let @xmath1049 be the multigraph @xmath1096 where @xmath1097 is the set of edges of @xmath45 between distinct clusters of @xmath73 and assume that @xmath1049 has min degree at least @xmath1047 .",
    "let @xmath1048 be the multigraph obtained from @xmath1049 by sampling each edge independently with probability @xmath1050 .",
    "then with probability @xmath1098 , the following holds for every cut @xmath1051 in @xmath73 :    1 .   if @xmath1099 then @xmath1100 for any @xmath1101 , and 2 .   if @xmath1102 then @xmath1103 .",
    "let @xmath1101 be given . by lemma  [ lem : lowconductance ] , with probability @xmath1098 , for every cut @xmath1051 in @xmath73 , if @xmath1104 then @xmath1105 and if @xmath1102 then @xmath1052 . assume that this property holds in the following .",
    "let @xmath1051 be a cut in @xmath73 such that @xmath1099 and let @xmath1106 .",
    "assume w.l.o.g .",
    "that @xmath1107 .",
    "the first part of the corollary follows from @xmath1108    for the second part , assume instead that @xmath1102 .",
    "since each cluster is incident to no more than @xmath1109 edges of @xmath45 and since it has degree at least @xmath1047 when viewed as a vertex in @xmath1049 , we get @xmath1110 and similarly @xmath1111 . since @xmath910 $ ]",
    "is connected for each @xmath74 , each vertex of @xmath9 has degree at least @xmath127",
    "so @xmath1112 it follows that @xmath1113 and hence , @xmath1114 as desired .",
    "in this section , we present the procedure ` xprune ` which we used as a black box in section  [ sec : decdslowcondcuts ] .",
    "it makes use of a new dynamic version of the procedure ` nibble ` of spielman and teng  @xcite so before moving on , we will introduce some notation used in their paper as well as the procedure ` nibble ` .",
    "when we refer to vectors in the following , we assume that each of them has an entry for each vertex in a graph that should be clear from context .",
    "we denote by @xmath1115 the sum of degrees of vertices in a subset @xmath106 and we write @xmath1116 instead of @xmath1117 for a vertex @xmath137 .",
    "let @xmath567 be the adjacency matrix for the graph , let @xmath352 be the diagonal matrix where entry @xmath1118 is the degree of the @xmath37th vertex , and let @xmath435 be the identity matrix of the same dimensions as @xmath567 and @xmath352 .",
    "we define the matrix @xmath385 by @xmath1119 .    for a graph @xmath72 and for a vertex @xmath1120 ,",
    "let @xmath1121 be the vector with an entry for each vertex in @xmath75 where @xmath1122 and @xmath1123 for all @xmath1124 .",
    "for a vector @xmath80 and for @xmath1125 , define the truncation operation @xmath1126_\\varepsilon$ ] by @xmath1127_\\varepsilon(v ) = \\left\\{\\begin{array}{ll } p(v ) & \\mbox{if } p(v)\\geq 2\\varepsilon d(v),\\\\                                             0     & \\mbox{otherwise}.                           \\end{array}\\right.\\ ] ]      pseudocode for ` nibble`@xmath1128 can be seen in figure  [ fig : nibble ] .",
    "ddd============`procedure ` ` nibble`@xmath1128 +   + 1 . set @xmath1129 + 2 . set @xmath1130 and @xmath1131 ) + 3 . for @xmath1132 to @xmath1133 + 4 . set @xmath1134_{\\epsilon_b}$ ] + 5 .",
    "compute a permutation @xmath1135 of @xmath75 such that for all @xmath37 , @xmath1136 + 6 .",
    "if there exists a @xmath1137 such that + 7 .",
    "@xmath1138 , + 8 .",
    "@xmath1139 , and + 9 .",
    "@xmath1140 , + 10.then output @xmath1141 and halt + 11.return _ failed _    it calculates truncated probability distributions for @xmath1133 steps of a random walk in @xmath72 starting in vertex @xmath78 where in each step , the walk stays in the current vertex with probability @xmath813 and otherwise goes to one of the adjacent vertices with equal probability .",
    "it then derives from one of these truncated probability distributions a low - conductance cut , assuming a suitable starting vertex @xmath78 is chosen .    in this section",
    ", we define @xmath1142 and we shall implicitly assume that each graph contains at most @xmath1143 edges , as is the case for @xmath9 .",
    "spielman and teng  @xcite showed the following property of ` nibble ` .",
    "[ lem : nibble ] let @xmath72 be a graph . for each @xmath1144 and for each @xmath1145 satisfying @xmath1146 there is a subset @xmath1147 such that @xmath1148 and this subset can be decomposed into sets @xmath1149 for @xmath1150 such that for each @xmath512 and any @xmath1151 , ` nibble`@xmath1128 outputs a vertex set @xmath31 such that    1 .",
    "@xmath1152 , 2 .",
    "@xmath1153 , and 3 .",
    "@xmath1154 .    for all @xmath512 , `",
    "nibble ` can be implemented to run in worst - case time @xmath1155 .",
    "we will not need the full strength of this result but only the following simpler corollary .",
    "[ cor : simplenibble ] let @xmath72 be a graph of max degree at most @xmath1156 . for each @xmath1144 and for each @xmath1145 with @xmath1157 , there is an @xmath1120 and an integer @xmath1158 such that in worst - case time @xmath1159 , ` nibble`@xmath1128 outputs a vertex set @xmath31 of size between @xmath1160 and @xmath1161 with @xmath1152 .",
    "furthermore , for any @xmath78 and @xmath512 , if ` nibble`@xmath1128 outputs a set , this set has size between @xmath1160 and @xmath1161 and has conductance at most @xmath791 in @xmath72 .",
    "we may assume that @xmath1162 since if this does not hold , we can redefine @xmath106 to be @xmath1163 .",
    "then @xmath106 satisfies the requirements of lemma  [ lem : nibble ] which for suitable @xmath78 and @xmath512 gives a set @xmath31 with @xmath1164 and @xmath1165 .",
    "it follows from the pseudocode in figure  [ fig : nibble ] that each vertex of @xmath31 has a positive @xmath1166-value when ` nibble ` halts and hence by the truncation operation , this value is at least @xmath1167 ( we may assume that each such vertex has degree at least @xmath127 ) .",
    "since the total truncated probability mass is at most @xmath127 , it follows that @xmath1168 .",
    "the last part of the corollary also follows from lemma  [ lem : nibble ] and from analyzing the pseudocode in figure  [ fig : nibble ] .",
    "we need the following result which was shown in  @xcite .",
    "[ lem : nibbletrunc ] let @xmath78 be a vertex of a connected graph @xmath72 , let @xmath1169 and @xmath1170 be integers and let @xmath1171 .",
    "let @xmath1166 be the probability distribution found by iteration @xmath1172 of ` nibble`@xmath1173 .",
    "let @xmath1174 be the probability distribution found by the variant of ` nibble`@xmath1173 which does not truncate probabilities , i.e. , line @xmath866 is replaced by @xmath1175",
    ". then @xmath1176 .",
    "we say that ` nibble ` _ visits _ an edge @xmath134 if in some step , it sends a non - zero amount of probability mass along @xmath79 , i.e. , if @xmath1177 has a non - zero entry for either @xmath136 or @xmath137 ( or both ) in some execution of line @xmath866 in figure  [ fig : nibble ] .",
    "the next lemma bounds the number of edges visited by ` nibble ` .",
    "this is key to making ` nibble ` work efficiently in our dynamic setting .",
    "[ lem : randomwalkoverlap ] let @xmath79 be an edge of an @xmath0-vertex connected graph @xmath72",
    ". then the number of vertices @xmath78 for which ` nibble`@xmath1128 visits @xmath79 is @xmath1178 .",
    "we first consider probability distributions for random walks defined by matrix @xmath385 where no truncation occurs .",
    "let @xmath1179 denote the probability of reaching vertex @xmath166 in @xmath1172 steps in a random walk in @xmath72 from vertex @xmath136 where in each step , the walk remains in the current vertex with probability @xmath813 and otherwise goes to one of the incident vertices with equal probability . given @xmath1180 and integers @xmath1181 , @xmath1182 .",
    "it is well - known that in a connected graph @xmath705 , when the number of steps in a random walk from any starting vertex approaches infinity , the probability distribution for this walk converges to the stationary distribution in which the probability mass at each vertex @xmath1183 is @xmath1184 .",
    "hence , @xmath1185 implying that @xmath1186 .",
    "let @xmath136 and @xmath137 be the endpoints of @xmath79 . `",
    "nibble ` visits @xmath79 if at some point it sends probability mass along @xmath79 either from @xmath136 to @xmath137 or from @xmath137 to @xmath136 ; we shall only bound the number of starting vertices for which the former happens since the same argument applies for the latter . by lemma  [ lem : nibbletrunc ] , ` nibble`@xmath1128 only sends probability mass from @xmath136 to @xmath137 along @xmath79 if there is a @xmath1172 such that @xmath1187 .",
    "let @xmath1188 .",
    "since @xmath72 is connected and contains at least two vertices , it has min degree at least @xmath127 .",
    "the above then implies that the number of starting vertices @xmath78 for which ` nibble`@xmath1128 sends probability mass from @xmath136 to @xmath137 along @xmath79 is at most @xmath1189      we are now ready to present ` xprune`@xmath291 .",
    "pseudocode can be seen in figure  [ fig : xprune ] . in this subsection",
    ", we describe the preprocessing needed by this procedure .    in the following ,",
    "we pick @xmath1190 and @xmath1191 .",
    "note that our previous constraints in section  [ subsec : preprocdecsf ] that @xmath1192 and @xmath1193 are satisfied .",
    "next , let @xmath1194 and let @xmath1195 be the probability from corollary  [ cor : lowconductance ] .",
    "furthermore , let @xmath1196 and let @xmath1197 be the largest integer @xmath512 such that the size lower bound in corollary  [ cor : simplenibble ] is at most @xmath1198 .",
    "note that @xmath1199 .",
    "finally , let @xmath1200 .    in the following ,",
    "let multigraph @xmath1049 be defined as in corollary  [ cor : lowconductance ] . for @xmath1201 ,",
    "we form a multigraph with vertex set @xmath73 by sampling each edge of @xmath1049 independently with probability @xmath80 .",
    "let @xmath1202 denote a list of the @xmath1203 graphs obtained . by invariant  [ inv : clustering ] in section  [ subsec : preprocdecsf",
    "] , each vertex of each graph of @xmath1202 has expected degree at most @xmath1204 so by a chernoff and a union bound , w.h.p .",
    "each graph in @xmath1202 has max degree at most @xmath1156 .",
    "we shall assume that at any point during the sequence of updates , each graph in @xmath1202 is simple so that ` nibble ` can be applied to it .",
    "furthermore , we assume that no edge deletion disconnects a spanning tree @xmath912 ( see section  [ subsec : preprocdecsf ] ) of a cluster @xmath74 .",
    "we later show how to get rid of these assumptions .",
    "the following preprocessing is done for each graph @xmath1205 and for @xmath1206 . for each @xmath1207",
    ", we run ` nibble`@xmath1208 and store the set @xmath1209 of edges of @xmath1210 visited by this call . having executed these calls , we then obtain and store dual sets @xmath1211 consisting of all @xmath78 such that @xmath1212 .",
    "for each @xmath1207 , we store a bit indicating whether @xmath78 is _ @xmath512-active _ or _ @xmath512-passive _ ( in @xmath1210 ) ; we say that @xmath78 is @xmath512-active if ` nibble`@xmath1208 outputs a set . otherwise , @xmath78 is @xmath512-passive .",
    "next , we check the condition in line @xmath866 of ` xprune ` for each @xmath1205 and each @xmath74 .",
    "if the condition is satisfied , we mark @xmath31 as a low - degree cluster in graph @xmath1210 .",
    "we keep these low - degree clusters in a linked list @xmath1213 which will be maintained during updates .",
    "the @xmath1214-sets , their duals @xmath1215 , and the list @xmath1213 will only become relevant later on when we focus on the implementation and show how the tests in lines @xmath866 and @xmath1216 can be done efficiently .    ' '' ''",
    "+ ddd============`xprune`@xmath291 : +   + 1 . for each graph @xmath1205 , @xmath1217 + 2 . while @xmath1218 + 3 .",
    "let @xmath1210 be the first graph in @xmath1202 + 4 . if @xmath1219 s.t .  the number of edges of @xmath1210 leaving @xmath31 is less than @xmath1220 + 5 .",
    "update @xmath1221 + 6 .",
    "@xmath1222 + 7 .",
    "else if @xmath1223 s.t .  `",
    "nibble`@xmath1224 , s , \\theta , b)$ ] outputs a set",
    "@xmath1225 + 8 .",
    "let @xmath1226 be a set of smaller size among @xmath1225 and @xmath1227 + 9 .",
    "update @xmath1228 + 10 .",
    "@xmath1222 + 11 .",
    "else output the set of clusters removed from @xmath941 in lines @xmath68@xmath1229",
    "+    ' '' ''      we now show that the two properties of ` xprune ` in section  [ subsec : preprocdecsf ] hold .",
    "lemma  [ lem : totsizesmallcuts ] below implies the second property of ` xprune ` . to show this lemma , we first need the following result .    [",
    "lem : xprunedeg ] w.h.p .",
    ", in each execution of the while - loop of ` xprune`@xmath291 , @xmath1230 $ ] has min degree at least @xmath1231 in line @xmath1216 , and at the beginning of line @xmath1232 @xmath31 has degree less than @xmath1233 in @xmath1230 $ ] .    procedure ` xprune ` maintains the invariant that in every execution of line @xmath32 , the edges of @xmath1210 are sampled independently of the updates to @xmath838 thus far .",
    "this follows since every time we update @xmath838 , we remove @xmath1210 from @xmath1202 while the updates to @xmath838 have been done independently of the remaining graphs in @xmath1202 .",
    "consider a single iteration of the while - loop and consider some cluster @xmath1234 in line @xmath32 .",
    "let @xmath738 denote its degree in @xmath1230 $ ] and assume first that @xmath1235 .",
    "we will show that w.h.p .",
    ", line @xmath1216 is not reached in the current iteration of the while - loop . by the above , the expected degree of @xmath31 in @xmath1236",
    "$ ] is @xmath1237 and a chernoff bound implies that w.h.p .",
    ", the actual degree in @xmath1236 $ ] is less than @xmath1220 .",
    "thus , w.h.p .",
    ", line @xmath1216 is not reached in this iteration of the while - loop .",
    "now , assume that @xmath1238 .",
    "then the expected degree of @xmath31 in @xmath1236 $ ] is at least @xmath1239 and a chernoff bound shows that w.h.p . , its actual degree in @xmath1236 $ ] is at least @xmath1240 . hence , w.h.p . , @xmath31 is not removed in line @xmath1232 of the current iteration of the while - loop .",
    "a union bound over all choices for @xmath31 shows the second part of the lemma .",
    "the following lemma easily implies the second property of ` xprune ` in section  [ subsec : preprocdecsf ] .",
    "[ lem : totsizesmallcuts ] let @xmath1241 be the union of clusters output over all calls to a variant of ` xprune ` which does not require the upper bound @xmath1197 on @xmath512 in line @xmath1216 . then w.h.p . , @xmath1242 .",
    "first observe that w.h.p .",
    ", @xmath1243 $ ] is a @xmath119-expander graph where @xmath1244 is the initial set @xmath838 .    now , consider the start of an execution of line @xmath1245 and let @xmath1246 . by corollary  [ cor : simplenibble",
    "] , w.h.p . , @xmath1247 and @xmath1248 . by lemma  [ lem : xprunedeg ] , w.h.p .",
    ", @xmath1230 $ ] has min degree at least @xmath1047 . with @xmath1249",
    ", it follows from the first part of corollary  [ cor : lowconductance ] that w.h.p .",
    ", @xmath1250}(k)\\le 4\\theta = \\gamma/24 $ ] so by invariant  [ inv : clustering ] , the number of edges of @xmath915 $ ] crossing @xmath918 is at most @xmath1251}(k),\\mbox{vol}_{g[x]}(x - k)\\}\\le(\\gamma/8)|k|$ ] . since @xmath1248 and since @xmath9 has max degree @xmath32 , invariant  [ inv : clustering ] implies that @xmath1252 so @xmath1253 and hence @xmath1254 .    next , consider the start of an execution of line @xmath1232 . by lemma  [ lem : xprunedeg ] and invariant  [ inv : clustering ] , w.h.p . , the number of edges of @xmath915 $ ] crossing @xmath1255 is less than @xmath1256 .",
    "we may assume that @xmath1257 so that @xmath1258 .",
    "now , let @xmath1259 be the family of all sets removed from @xmath838 , either in an execution of line @xmath1232 or of line @xmath1245 .",
    "note that @xmath1260 .",
    "let @xmath838 denote @xmath1244 and let @xmath1261 .",
    "note that @xmath1262 is a partition of @xmath1244 .",
    "we consider two cases : @xmath1263 and @xmath1264 .    if @xmath1263 then w.h.p . , the initial number of edges of @xmath915 $ ] crossing @xmath1265 is at least @xmath1266 . by the above , w.h.p .",
    "the number of edges of @xmath915 $ ] crossing @xmath1267 at termination is at most @xmath1268 .",
    "hence , w.h.p .",
    "at least @xmath1269 edges crossing this cut have been deleted over all updates in which case @xmath1270 , as desired .",
    "next , assume that @xmath1271 .",
    "order the sets of @xmath1259 by when they were removed from @xmath838 .",
    "there is a an integer @xmath16 such that if @xmath1272 resp .",
    "@xmath1273 is the subset of the @xmath16 resp .",
    "@xmath1274 first sets in this ordering then @xmath1275 has size less than @xmath1276 and @xmath1277 has size at least @xmath1276 . if @xmath1278 then w.h.p . , the total number of deleted edges crossing @xmath1279 is at least @xmath1280 . if @xmath1281 then @xmath1282 so w.h.p . , the total number of deleted edges crossing @xmath1283 is at least @xmath1284 .    in both cases , w.h.p .",
    "@xmath1285 , showing the desired .",
    "the second property of ` xprune ` follows from this lemma since by the choice of @xmath1197 and by invariant  [ inv : clustering ] , w.h.p .",
    "` xprune ` and the variant in lemma  [ lem : totsizesmallcuts ] behave in exactly the same manner .",
    "the next lemma shows that the first property of ` xprune ` is maintained over all edge deletions , assuming @xmath1202 never becomes empty .",
    "[ lem : deleteedgeprop ] suppose a call to ` xprune ` has just returned where in each execution of line @xmath68 , @xmath1202 was non - empty",
    ". then w.h.p . , for every @xmath941-respecting cut @xmath1286 , the number of edges of @xmath915 $ ] crossing @xmath918 is at least @xmath1287 .",
    "we prove the lemma for the variant of ` xprune ` in lemma  [ lem : totsizesmallcuts ] .",
    "this suffices as argued above .",
    "consider a moment where ` xprune ` has just returned and let @xmath1210 be the first graph in @xmath1202 . as argued in the proof of lemma  [ lem : xprunedeg ] , the edges of @xmath1210 are sampled independently of the updates to @xmath838 done so far . by corollary  [ cor : simplenibble ] , for every cut @xmath1288 , @xmath1289 .",
    "lemma  [ lem : xprunedeg ] implies that w.h.p .",
    ", @xmath1230 $ ] has min degree at least @xmath1290 . by the second part of corollary  [ cor : lowconductance ] , w.h.p .  for every cut @xmath1288 , @xmath1250}(k)\\ge \\rho^3/3 ^ 5 = \\gamma'$ ] where @xmath1291 ; hence , the number of edges of @xmath915 $ ] crossing @xmath918 is at least @xmath1292}(k),\\mbox{vol}_{g[x]}(x - k)\\}\\ge \\gamma'\\min\\{|k|,|x - k|\\}$ ] , as desired .",
    "the final lemma of this subsection shows that the requirement in lemma  [ lem : deleteedgeprop ] of @xmath1202 being non - empty can be dropped .",
    "this shows the correctness of ` xprune ` .",
    "[ lem : deleteedget ] w.h.p .",
    ", @xmath1202 is non - empty in all executions of line @xmath32 in calls to ` xprune ` .    since we assume that clusters never become disconnected it follows from invariant  [ inv : clustering ] that every time ` xprune ` removes a graph from @xmath1202 , the size of @xmath838 is reduced by at least @xmath908 . by lemma  [ lem : totsizesmallcuts ] , w.h.p .",
    "this happens no more than @xmath1203 times which is the initial size of @xmath1202 .",
    "we now show how to implement the preprocessing and the update step of ` xprune ` and analyze the performance of this implementation .",
    "we first describe how to obtain the list @xmath1202 of graphs .",
    "we will use an adjacency list representation for each graph in @xmath1202 and we use a linked list representation of @xmath1202 itself .",
    "initially , all @xmath1293 graphs in @xmath1202 are empty , containing only vertices . to obtain the edges",
    ", the trivial way of scanning through all the graphs in @xmath1202 and including each @xmath79 of @xmath1049 in each of them independently with probability @xmath80 will be too slow so we need to do something more clever .    for each edge @xmath1294",
    ", we apply a procedure that we describe in the following .",
    "we keep a list @xmath28 of the graphs from @xmath1202 .",
    "this list will shrink during the course of the algorithm .",
    "we represent the initial @xmath28 as an array and keep an index to the start of @xmath28 .",
    "we implicitly shrink @xmath28 by increasing this index , letting the new @xmath28 be the suffix of the array starting from this index .",
    "let @xmath78 be the current length of @xmath28 .",
    "for @xmath1295 , let @xmath1296 be the event that the @xmath16th graph in @xmath28 is the first to include @xmath79 among all the graphs in @xmath28 .",
    "let @xmath1297 be the event that @xmath79 is not added to any graph in @xmath28 .",
    "then @xmath1298 for @xmath1295 and @xmath1299 for @xmath1300 .",
    "we pick @xmath16 randomly according to this probability distribution , add @xmath79 to the @xmath16th graph in @xmath28 ( assuming @xmath1301 ) , update @xmath28 to its suffix of length @xmath1302 , and then repeat the procedure on the new list @xmath28 .",
    "the procedure stops when @xmath28 is empty .",
    "running this procedure is equivalent to including @xmath79 in each graph of @xmath1202 independently with probability @xmath80 .    we need to describe how to pick @xmath16 from this distribution .",
    "we first precompute @xmath1303 for all @xmath1304 .",
    "we shall not do this explicitly . instead ,",
    "observing that @xmath1305 when @xmath1306 , we only compute @xmath1307 and @xmath1308 for all choices of @xmath1309 and @xmath1310 , using a simple bottom - up dynamic programming procedure . from these values",
    ", we can obtain any @xmath1311 in constant time .",
    "given these precomputed values and letting @xmath78 be the current length of @xmath28 , we find the next @xmath16 with the following recursive procedure which takes the pair @xmath1312 as input which is initially @xmath1313 . if @xmath1314 , let @xmath1315 .",
    "we recurse with the pair @xmath1316 with probability @xmath1317 and recurse with the pair @xmath1318 otherwise , i.e. , with probability @xmath1319 .",
    "the recursion stops once @xmath1320 in which case we pick @xmath1321 .",
    "it is easy to see that this recursive procedure picks @xmath16 according to the distribution above .",
    "this completes the description of the implementation of the procedure for forming @xmath1202 .",
    "each set @xmath1322 resp .",
    "@xmath1323 is stored as a linked list with a pointer from @xmath78 resp .",
    "@xmath79 to the start of this list .",
    "this completes the description of the implementation of the preprocessing step .",
    "the following lemma shows the performance of the procedure just described .",
    "[ lem : constructionhgraphs ] with high probability , the initial graphs in @xmath1202 can be constructed in worst - case time @xmath1324 .    in the proof ,",
    "we use the same notation as in the description of the implementation above . for each edge @xmath1294",
    ", we let @xmath1325 be the number of graphs in @xmath1202 that @xmath79 is included in at the end of the preprocessing step .",
    "consider an edge @xmath1294 .",
    "we get @xmath1326 = \\sum_{e\\in e(g_{\\mathcal c})}e[s(e ) ] = \\sum_{e\\in e(g_{\\mathcal c})}ph_{\\max } = o(ph_{\\max}n)$ ] .",
    "a chernoff bound shows that w.h.p . , @xmath1327 .",
    "excluding the time to precompute @xmath1311 , the lemma will thus follow if we can show that @xmath79 can be processed in @xmath1328 worst - case time .",
    "the number of times we need to pick a @xmath16 from the distribution is either @xmath1325 or @xmath1329 .",
    "it is easy to see that , given precomputed values @xmath1311 , the recursive procedure runs in @xmath67 time , as desired .",
    "values @xmath1311 only need to be computed once , not for each edge @xmath79 .",
    "the time to compute these values is @xmath1330 .",
    "the rest of the preprocessing is dominated by the time for calls to ` nibble ` . with high probability ,",
    "the number of calls to ` nibble ` with parameter @xmath512 is @xmath1331 . by corollary  [ cor : simplenibble",
    "] , each such call takes @xmath1159 ; hence w.h.p .",
    ", the total time for calls to ` nibble ` over all @xmath512 is @xmath1332 .",
    "we conclude that w.h.p .",
    ", the total preprocessing time is @xmath1333 which is within the bound of theorem  [ thm : disconnectexpandergraph ] .",
    "we now describe how to implement ` xprune ` .",
    "note that in line @xmath1216 , ` nibble ` is applied to subgraphs of graphs @xmath1205 induced by @xmath941 . in our implementation , we shall maintain these subgraphs explicitly by removing edges of @xmath1210 incident to clusters removed from @xmath941 .",
    "this way , @xmath1236 $ ] is a component of @xmath1210 so when we run ` nibble ` on @xmath1210 with a start vertex in @xmath941 , we do not need to worry about edges not in @xmath1236 $ ] being visited .    to implement line @xmath127 , we do as follows for each @xmath1205 .",
    "assume that @xmath1334 as otherwise nothing needs to be done .",
    "after deleting @xmath79 from @xmath1210 , for each @xmath1206 , the only calls ` nibble`@xmath1224 , s , \\theta , b)$ ] that are affected by the deletion are those from vertices @xmath1335 . for each such @xmath78 ,",
    "we run ` nibble`@xmath1224 , s , \\theta , b)$ ] ; @xmath78 is made @xmath512-active if a set is returned and @xmath512-passive otherwise .",
    "let @xmath1336 be the set of edges visited by this call .",
    "for each @xmath1337 , we remove @xmath78 from @xmath1338 and for each @xmath1339 , we add @xmath78 to @xmath1338 . finally , we update @xmath1322 to @xmath1336 .",
    "this correctly updates all @xmath1340- and @xmath1341-sets .    to maintain lists @xmath1213 in line @xmath127",
    ", we only need to check the low - degree condition of line @xmath866 for the clusters containing @xmath136 and @xmath137 and for the clusters that have been merged or split during the current update ( the latter will only be relevant when we later allow clusters to change over time ) .",
    "next , we describe how lines @xmath32 to @xmath1342 are implemented . for the condition in line @xmath866 ,",
    "checking each @xmath74 will be too slow .",
    "instead , we make use of the @xmath524-lists .",
    "consider any execution of line @xmath866 .",
    "if @xmath1213 is empty , no @xmath31 exists satisfying the condition .",
    "otherwise , we obtain @xmath31 by extracting the first element of @xmath1213 .    handling the update in line @xmath1232",
    "is done as follows . for each graph @xmath1343",
    ", we delete from @xmath1344 every edge incident to @xmath31 .",
    "for each deleted edge @xmath298 , we run ` nibble ` from all vertices in @xmath1345 for all @xmath512 and update the @xmath512-active/@xmath512-passive bits and the @xmath1340- and @xmath1341-sets as above . for each cluster",
    "@xmath260 incident to @xmath31 in @xmath1344 , the removal of @xmath31 may have caused @xmath260 to now have low degree .",
    "we update the adjacency list of each such @xmath260 and add it to @xmath1346 if it has low degree .",
    "we maintain @xmath941 implicitly by associating a bit with each cluster indicating whether it belongs to @xmath941 .",
    "clusters removed from @xmath941 in lines @xmath1232 and @xmath1347 are stored in a linked list which is output in line @xmath1229 .    to implement line @xmath1216 , we check for each @xmath512 if there are any @xmath512-active vertices in @xmath1210 .",
    "if not , the condition in line @xmath1216 can not be satisfied and we execute line @xmath1229 . otherwise , we pick a @xmath512 and a @xmath512-active vertex @xmath78 in @xmath1210 and run ` nibble`@xmath1224 , s , \\theta , b)$ ] .",
    "the update in line @xmath1245 is handled similarly to line @xmath1232 the only modification being that we process every cluster @xmath31 on the @xmath1225-side of the cut rather than just a single cluster .",
    "[ [ performance-2 ] ] performance : + + + + + + + + + + + +    the update time is dominated by the time spent in the while - loop .",
    "consider a single execution of lines @xmath32 to @xmath1342 . since we maintain the @xmath524-lists",
    ", we can obtain a cluster @xmath31 satisfying the condition in line @xmath866 in @xmath8 time , assuming such a @xmath31 exists . if it does then since w.h.p .",
    ", each vertex of @xmath1210 has degree at most @xmath1348 and since @xmath31 has degree less than @xmath1349 , w.h.p .",
    ", updating @xmath524-lists takes @xmath1350 time per graph @xmath1343 since we only need to update adjacency lists for clusters adjacent to @xmath31 .",
    "since we delete from @xmath1344 the edges incident to @xmath31 , it follows from lemma  [ lem : randomwalkoverlap ] that for each @xmath512 , w.h.p .",
    "only @xmath1351 calls to ` nibble ` in @xmath1344 with parameter @xmath512 need to be updated which by corollary  [ cor : simplenibble ] takes a total of @xmath1352 time . over all @xmath512 and @xmath1344 , this is @xmath1353 time .",
    "we have bounded the time for a single execution of lines @xmath32 to @xmath1342 . by lemma  [ lem : totsizesmallcuts ] , the number of executions of these lines in an update is @xmath1354 which sums up to a total time for these executions of @xmath1355 .",
    "it remains to bound the total time spent in lines @xmath1216 to @xmath1229 during an update .",
    "consider a single execution of these lines . for each @xmath1343 , the number of edges deleted from @xmath1344 is @xmath1356 ( w.h.p . ) where @xmath1246 .",
    "these edges are incident in @xmath1344 to at most @xmath1356 clusters so updating the @xmath524-lists in @xmath1344 takes @xmath1357 time . for each @xmath1205 and each @xmath512",
    ", we keep the set of @xmath512-active vertices of @xmath1210 in a linked list so that we can identify such a vertex in constant time if it exists . by lemma  [ lem : randomwalkoverlap ] ,",
    "the number of calls to ` nibble ` in @xmath1344 with parameter @xmath512 that are updated is @xmath1358 and by corollary  [ cor : simplenibble ] , the total time for these calls is @xmath1359 . over all @xmath512 and @xmath1344 ,",
    "this is @xmath1360 . by lemma  [ lem : totsizesmallcuts ] , the total size of sets @xmath274 over all executions of line @xmath1245 in an update",
    "is @xmath1361 .",
    "hence , total time for lines @xmath1216 to @xmath1229 in a single update is @xmath1355 .",
    "it follows that w.h.p . , we get an update time within the bound of theorem  [ thm : disconnectexpandergraph ] .      above we made two simplifying assumptions , namely that each graph @xmath1205 is simple and that no edge deletion disconnects a cluster in @xmath73 . in this subsection ,",
    "we focus on getting rid of the former assumption .",
    "associate with each graph @xmath1205 a simple graph @xmath1362 as follows . for each vertex @xmath31 of @xmath1210 ,",
    "if @xmath1363 denotes its degree , then we have vertex set @xmath1364 in @xmath1362 where @xmath1365 is the subset of @xmath40 of endpoints in @xmath31 of edges of @xmath1210 incident to @xmath31 . for each edge @xmath1366 of @xmath1210 , if @xmath79 is the @xmath37th edge incident to @xmath31 and the @xmath197th edge incident to @xmath352 in their adjacency list orderings , we add to @xmath1362 the edge @xmath1367 and identify this edge with @xmath79 . to complete the construction of @xmath1362 ,",
    "we apply for each @xmath1368 the algorithm of lemma  [ lem : simpleexpander ] , giving w.h.p .  a @xmath127-expander graph of @xmath259 with @xmath1369 edges and max degree @xmath1370 .",
    "note that @xmath1371 .    in the following ,",
    "let @xmath1372 be @xmath838 restricted to the union of @xmath1373 over all @xmath1374 .",
    "[ [ preprocessing-4 ] ] preprocessing : + + + + + + + + + + + + + +    we now describe the modifications to ` xprune ` . in the preprocessing step ,",
    "we form both graphs @xmath1210 as well as the graphs @xmath1362 . instead of applying ` nibble ` to all vertices of @xmath1210 , we now apply it to all vertices of @xmath1362 and the @xmath1341- and @xmath1340-sets are formed w.r.t .",
    "@xmath1362 but only for inter - cluster edges .",
    "this suffices since edges of @xmath127-expander graphs are unchanged over all updates .",
    "the range of @xmath512-values is changed since @xmath1197 is adjusted , as we describe later .",
    "[ [ updates-4 ] ] updates : + + + + + + + +    now consider the update step where we no longer assume that graphs in @xmath1202 are simple . except for line @xmath1216 in ` xprune ` , we use these graphs as before . in line @xmath1216 , ` nibble ` requires a simple graph as input .",
    "we instead give as input to this procedure the graph @xmath1375 $ ] .",
    "suppose ` nibble ` outputs a set @xmath274 .",
    "note that @xmath274 may not be @xmath941-respecting . to form @xmath1225 in line @xmath1216 of",
    "` xprune ` , we apply an algorithm which is essentially the same as the one in the third part of lemma  [ lem : lowconductancemultigraph ] .",
    "more precisely , let @xmath1376 be the collection of vertex sets @xmath259 intersecting both sides of @xmath1377 and @xmath1378 and let @xmath1379 be the collection of the remaining vertex sets @xmath259 intersecting both sides of @xmath1377 .",
    "we let @xmath1225 be the set of clusters @xmath31 such that @xmath1380 .",
    "the @xmath1341- and @xmath1340-sets are maintained as before but for the graphs @xmath1362 .",
    "this completes the description of the modifications needed in ` xprune ` .",
    "we now show that the modified version of ` xprune ` is correct for suitable new choices of the parameters of this section .",
    "first we claim that for any @xmath1205 and any @xmath941-respecting cut , the conductance of this cut in @xmath1210 and in @xmath1362 differ by only a constant factor . to see this , observe that the number of edges crossing the cut is the same in the two graphs . since the expander graphss inserted when forming @xmath1362 are sparse and since there are @xmath1381 edges of @xmath1210 incident to each cluster @xmath31 , the volume of each side of the cut differs by only a constant factor in the two graphs .",
    "hence , the conductance of the cut differs by only a constant factor in the two graphs .",
    "it follows from what we have just shown that if every cut @xmath1377 has conductance at least @xmath791 in a graph @xmath1375 $ ] then in particular every @xmath941-respecting cut in @xmath1236 $ ] has conductance @xmath1382 .",
    "next , we claim that if a cut @xmath1377 has conductance at most @xmath791 in a graph @xmath1375 $ ] then @xmath1225 , obtained as described above , has conductance @xmath1383 in @xmath1236 $ ] . to see this , note that each vertex of @xmath1362 has only a constant number of incident inter - cluster edges .",
    "the proof now follows using the same arguments as in the proof of the third part of lemma  [ lem : lowconductancemultigraph ] .",
    "these arguments also show that the number of vertices of @xmath1372 in @xmath1225 and in @xmath274 differ by only a constant factor .",
    "we now go through the lemmas in section  [ subsec : xprunecorrectness ] that need to be adjusted to the new version of ` xprune ` .",
    "previously , we set @xmath1384 . by the above observations ,",
    "lemma  [ lem : totsizesmallcuts ] remains correct if we make @xmath791 smaller by a sufficiently big constant factor .    to ensure that lemma  [ lem : deleteedgeprop ] remains correct , first note that w.h.p .",
    ", @xmath1156 in corollary  [ cor : simplenibble ] is now @xmath1385",
    ". we will determine the new value of @xmath1197 .",
    "by lemma  [ lem : totsizesmallcuts ] , ` nibble ` only needs to identify sets @xmath1386 such that @xmath1387 . since w.h.p .",
    "graphs in @xmath1202 have max degree @xmath1388 , we get w.h.p .  that @xmath1389 is upper bounded by @xmath1390 .",
    "defining @xmath1197 as before to be the largest integer @xmath512 such that the size lower bound in corollary  [ cor : simplenibble ] is at most this upper bound , we get @xmath1391 . recall that we previously chose @xmath1392 .",
    "it follows from the above that lemma  [ lem : deleteedgeprop ] remains correct if we make @xmath1393 smaller by a sufficiently large constant factor .",
    "it is easy to see that the remaining lemmas in section  [ subsec : xprunecorrectness ] remain correct for the modified version of ` xprune ` .",
    "it remains to show the performance of the modified version of ` xprune ` .",
    "[ [ preprocessing-5 ] ] preprocessing : + + + + + + + + + + + + + +    by lemma  [ lem : simpleexpander ] , forming graphs @xmath1362 does not increase the asymptotic preprocessing time .",
    "the remaining time spent is dominated by the calls to ` nibble ` . since w.h.p .",
    "the number of vertices of each graph @xmath1362 is a factor of @xmath1394 larger than the number of vertices in @xmath1210 , the number of calls to ` nibble ` increases by this factor as well . since @xmath1395 is a factor of @xmath1350 larger than before and since @xmath1156 in corollary  [ cor : simplenibble ]",
    "is a factor of @xmath1350 smaller , each call to ` nibble ` takes the same time as before up to a constant number of @xmath168-factors .",
    "hence , the overall time for this part of the preprocessing increases by a factor of @xmath1350 . we conclude that the preprocessing time bound in the previous subsection still holds .",
    "[ [ updates-5 ] ] updates : + + + + + + + +    as observed above , each call to ` nibble ` takes the same amount of time as before up to @xmath1396-factors . by lemma  [ lem : randomwalkoverlap ] and the above , the number of calls to ` nibble ` per edge deletion increases by a factor of @xmath1397 .",
    "since we only delete inter - cluster edges , our previous bound on the number of edges deleted per update remains valid .",
    "hence , the update time bound in the previous subsection still holds .",
    "we now remove the remaining simplifying assumption and allow clusters to become disconnected .",
    "clusters can now both split and merge as described in section  [ subsec : updateclusters ] .",
    "the preprocessing step remains the same so we only focus on updates .",
    "recall that only @xmath8 clusters become split or merged per update .",
    "assume for now that at all times , each cluster has size between @xmath908 and @xmath940 .",
    "we modify line @xmath127 of ` xprune`@xmath291 so that it does the following for each @xmath1205 when a cluster is split by the deletion of @xmath79 . for each cluster @xmath31 destroyed by the updates to @xmath73 ,",
    "we delete @xmath31 and temporarily delete its incident inter - cluster edges from @xmath1210 . in @xmath1362 ,",
    "we delete @xmath259 and its @xmath127-expander graph and temporarily delete its incident inter - cluster edges .",
    "for every new cluster @xmath31 , we add @xmath31 to @xmath1210 along with its incident inter - cluster edges that were temporarily deleted . in @xmath1362 , we add @xmath259 and its incident inter - cluster edges together with a new @xmath127-expander graph of @xmath259 .    next , for every inter - cluster edge @xmath298 of @xmath1362 that was temporarily deleted and for each @xmath512 , we run ` nibble ` from every vertex in @xmath1398 and @xmath1340- and @xmath1341-sets are updated accordingly as described earlier .",
    "[ [ correctness-3 ] ] correctness : + + + + + + + + + + + +    in the previous subsection , it sufficed to define the @xmath1340- and @xmath1341-sets only w.r.t .",
    "inter - cluster edges since clusters remained fixed over all updates .",
    "we claim that this still suffices in this subsection . to see this , note that a call to ` nibble ` visits an edge @xmath298 of a @xmath127-expander graph iff it visits an inter - cluster edge incident to this edge . hence ,",
    "if @xmath298 is deleted or if @xmath298 is a new edge , there is an inter - cluster edge incident to @xmath298 which is temporarily deleted in the above procedure .",
    "therefore , ` nibble ` is rerun from every starting vertex that is affected by the deletion or insertion of @xmath298 .",
    "it follows that @xmath1340- and @xmath1341-sets are correctly maintained .    since updates to clusters",
    "happen independently of the random bits used to form the graphs @xmath1210 and @xmath1362 , it follows that ` xprune ` remains correct .",
    "so far , we have assumed that at all times , clusters have size between @xmath908 and @xmath940 . our correctness and performance analysis in this section",
    "rely crucially on this property . by invariant  [ inv : clustering ]",
    ", it may happen that a cluster @xmath31 has size less than @xmath908 .",
    "we modify ` xprune`@xmath291 so that for each such @xmath31 formed in line @xmath127 , we remove it from @xmath941 and add it as part of the set of clusters output in line @xmath1229 . by invariant  [ inv : clustering ] ,",
    "@xmath31 is disconnected from the rest of @xmath915 $ ] so the cut @xmath1399 is independent of any random bits used to form the graphs in @xmath1202 ; hence , unlike in lines @xmath1232 and @xmath1342 , we do not need to remove the current graph from @xmath1202 so lemma  [ lem : deleteedget ] still holds .",
    "also note that no @xmath524-list and no @xmath1340- or @xmath1341-set need to be updated when @xmath31 is removed in line @xmath127 .",
    "the modification to line @xmath127 ensures that in lines @xmath68 to @xmath1245 , every cluster has size between @xmath908 and @xmath940 as desired and correctness of ` xprune ` follows .",
    "[ [ performance-4 ] ] performance : + + + + + + + + + + + +    since the above modification to ` xprune ` makes no changes to the preprocessing step , it suffices to bound the update time .",
    "the only change to ` xprune`@xmath291 is in line @xmath127 . since only @xmath8 clusters",
    "are changed , updating the @xmath524-lists accordingly does not take asymptotically more time than before .",
    "the upper bound on the time spent by ` nibble ` to maintain the @xmath1340- and @xmath1341-sets in the while - loop clearly is also an upper bound on the time spent by ` nibble ` in line @xmath127 , again since only @xmath8 clusters are affected . by lemma  [ lem : simpleexpander ]",
    ", it takes @xmath1002 time to compute @xmath127-expander graphs for the new clusters which is also within our previous update time bound .",
    "we conclude that the new update time is asymptotically the same as in the previous subsection .",
    "we have given a las vegas data structure for fully - dynamic msf which w.h.p .",
    "handles an update in @xmath1 worst - case time for some constant @xmath2 where @xmath0 is the number of vertices of the graph .",
    "this is the first improvement over the @xmath5 worst - case bound of eppstein et al .",
    "previously , such an improvement was not even known for the problem of maintaining a spanning forest of an unweighted fully - dynamic graph .",
    "we also obtain the first las vegas data structure for fully - dynamic connectivity with worst - case update time polynomially better than @xmath5 ; this data structure has @xmath8 worst - case query time .    by breaking this important barrier for fully - dynamic msf",
    ", our hope is that further progress can be made for this problem as well as for fully - dynamic connectivity .",
    "we also hope that our techniques are applicable to other dynamic graph problems .",
    "dynamic global minimum cut may be one such problem , especially given that the recent deterministic near - linear time algorithm for the static version of the problem  @xcite exploits properties related to low - conductance cuts .",
    "we leave two open problems for dynamic msf , namely can polylogarithmic update time be achieved w.h.p . , thereby matching the best known amortized update time bounds , and can the worst - case update time of the type in this paper be matched deterministically ?    99 s.  alstrup , j.  holm , k.  de lichtenberg , and m.  thorup . maintaining information in fully dynamic trees with top trees .",
    "acm transactions on algorithms @xmath127(@xmath68 ) : @xmath1400@xmath1401 ( @xmath1402 ) . b.  chazelle . a minimum spanning tree algorithm with inverse - ackermann type complexity .",
    "j.  acm , @xmath1403 ( @xmath1342 ) : @xmath1404@xmath1405 .",
    "d.  eppstein , z.  galil , g.  f.  italiano , and a.  nissenzweig .",
    "sparsification - a technique for speeding up dynamic graph algorithms .",
    "j.  acm , @xmath1406(@xmath1232):@xmath1407@xmath1408 , @xmath1409 .",
    "see also focs@xmath1410 .",
    "g.  n.  frederickson .",
    "data structures for on - line updating of minimum spanning trees , with applications .",
    "siam j.  comput . ,",
    "@xmath1411(@xmath866):@xmath1412@xmath1413 , @xmath1414 .",
    "see also stoc@xmath1415 .",
    "d.  gibb , b.  m.  kapron , v.  king , and n.  thorn .",
    "dynamic graph connectivity with improved worst case update time and sublinear space .",
    "corr , abs/@xmath1416.@xmath1417 , @xmath1418 . m.  r.  henzinger and v.  king .",
    "fully dynamic @xmath68-edge connectivity algorithm in polylogarithmic time per operation . tech .  rep .",
    "src @xmath1409-@xmath1419a , digitial .",
    "m.  r.  henzinger and v.  king . maintaining minimum spanning trees in dynamic graphs .",
    "in proc .",
    "icalp , lecture notes in computer science , vol .",
    "@xmath1420 , springer - verlag , new york , pp .",
    "m.  r.  henzinger and v.  king .",
    "randomized fully dynamic graph algorithms with polylogarithmic time per operation .",
    "j.  acm @xmath1423 , @xmath866 ( july ) , @xmath1424@xmath1425 .",
    "see also stoc@xmath1426 .",
    "j.  holm , k.  de lichtenberg , and m.  thorup .",
    "poly - logarithmic deterministic fully - dynamic algorithms for connectivity , minimum spanning tree , @xmath68-edge , and biconnectivity .",
    "j.  acm , @xmath1427(@xmath866 ) : @xmath1428@xmath1429 , @xmath1430 .",
    "see also stoc@xmath1431 .",
    "j.  holm , e.  rotenberg , and c.  wulff - nilsen .",
    "faster fully - dynamic minimum spanning forest .",
    "esa @xmath1418 : @xmath1432@xmath1433 . b.  m.  kapron , v.  king , and b.  mountjoy .",
    "dynamic graph connectivity in polylogarithmic worst case time . in proc .",
    "@xmath1434th annual acm - siam symposium on discrete algorithms ( soda ) , pp .",
    "@xmath1435@xmath1436 , @xmath1437 .",
    "d.  r.  karger .",
    "random sampling in cut , flow , and network design problems .",
    "stoc @xmath1438 : @xmath1439@xmath1440 .",
    "d.  r.  karger , p.  n.  klein , and r.  e.  tarjan . a randomized linear - time algorithm to find minimum spanning trees .",
    "j.  acm , @xmath1441 ( @xmath68 ) : @xmath1442@xmath1443 .",
    "k.  kawarabayashi and m.  thorup .",
    "deterministic global minimum cut of a simple graph in near - linear time .",
    "stoc @xmath1418 : @xmath1444@xmath1445 . c.  kejlberg - rasmussen , t.  kopelowitz , s.  pettie , and m.  thorup .",
    "faster worst case deterministic dynamic connectivity .",
    "esa @xmath1446 : @xmath1447:@xmath127@xmath1447:@xmath1448 . c.  levcopoulos and m.  h.  overmars . a balanced search tree with @xmath8 worst - case update time .",
    "acta informatica @xmath1449 , @xmath1450@xmath1451 ( @xmath1452 ) . m.  ptracu and e.  demaine .",
    "logarithmic lower bounds in the cell - probe model .",
    "siam j.  comput . ,",
    "@xmath1453(@xmath866 ) : @xmath1454",
    ". special issue @xmath1455th acm symposium on theory of computing ( stoc @xmath1456 ) .",
    "d.  a.  spielman and s.  teng .",
    "nearly - linear time algorithms for graph partitioning , graph sparsification , and solving linear systems .",
    "stoc @xmath1456 : @xmath1457@xmath1458 ."
  ],
  "abstract_text": [
    "<S> we give a las vegas data structure which maintains a minimum spanning forest in an @xmath0-vertex edge - weighted dynamic graph undergoing updates consisting of any mixture of edge insertions and deletions . </S>",
    "<S> each update is supported in @xmath1 expected worst - case time for some constant @xmath2 and this worst - case bound holds with probability at least @xmath3 where @xmath4 is a constant that can be made arbitrarily large . </S>",
    "<S> this is the first data structure achieving an improvement over the @xmath5 deterministic worst - case update time of eppstein et al . </S>",
    "<S> , a bound that has been standing for nearly @xmath6 years . in fact , it was previously not even known how to maintain a spanning forest of an unweighted graph in worst - case time polynomially faster than @xmath7 . </S>",
    "<S> our result is achieved by first giving a reduction from fully - dynamic to decremental minimum spanning forest preserving worst - case update time up to logarithmic factors . </S>",
    "<S> then decremental minimum spanning forest is solved using several novel techniques , one of which involves keeping track of low - conductance cuts in a dynamic graph . </S>",
    "<S> an immediate corollary of our result is the first las vegas data structure for fully - dynamic connectivity where each update is handled in worst - case time polynomially faster than @xmath7 w.h.p . ; this data structure has @xmath8 worst - case query time . </S>"
  ]
}