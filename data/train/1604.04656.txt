{
  "article_text": [
    "the evaluation of the accuracy of diagnostic tests is an important issue in modern medicine . in order to evaluate a test , knowledge of the true disease status of subjects or patients under study",
    "is necessary .",
    "usually , this is obtained by a gold standard ( gs ) test , or reference test , that always correctly ascertains the true disease status .    sensitivity ( se ) and specificity ( sp )",
    "are frequently used to assess the accuracy of diagnostic tests when the disease status has two categories ( e.g. , `` healthy '' and `` diseased '' ) . in a two - class problem , for a diagnostic test @xmath0 that yields a continuous measure , the receiver operating characteristic ( roc ) curve is a popular tool for displaying the ability of the test to distinguish between non  diseased and diseased subjects .",
    "the roc curve is defined as the set of points @xmath1 in the unit square , where @xmath2 and @xmath3 for given a cut point @xmath4 .",
    "the shape of roc curve allows to evaluate the ability of the test .",
    "for example , a roc curve equal to a straight line joining points @xmath5 and @xmath6 represents a diagnostic test which is the random guess .",
    "a commonly used summary measure that aggregates performance information of the test is the area under roc curve ( auc ) .",
    "reasonable values of auc range from 0.5 , suggesting that the test is no better than chance alone , to 1.0 , which indicates a perfect test .    in some medical studies",
    ", however , the disease status often involves more than two categories ; for example , alzheimer s dementia can be classified into three categories ( see @xcite for more details ) . in such situations ,",
    "quantities used to evaluate the accuracy of tests are the true class fractions ( tcf s ) .",
    "these are well defined as a generalization of sensitivity and specificity . for",
    "given a pair of cut points @xmath7 such that @xmath8 , the true class fractions tcf s of the continuous test @xmath0 at @xmath7 are @xmath9 the plot of ( tcf@xmath10 , tcf@xmath11 , tcf@xmath12 ) at various values of the pair @xmath7 produces the roc surface in the unit cube .",
    "it is not hard to realize that roc surface is a generalization of the roc curve ( see @xcite ) .",
    "indeed , the projection of the roc surface to the plane defined by tcf@xmath11 versus tcf@xmath10 yields the roc curve between classes 1 and 2 .",
    "similarly , by projecting roc surface to the plane defined by the axes tcf@xmath11 and tcf@xmath12 , the roc curve between classes 2 and 3 is produced .",
    "the roc surface will be the triangular plane with vertices @xmath13 , and @xmath14 if all of three tcf s are equal for every pair @xmath7 . in this case",
    ", we say that the diagnostic test is the random guess , again . in practice ,",
    "one can imagine that the graph of the roc surface lies in the unit cube and above the plane of the triangle with three vertices @xmath13 , and @xmath14 .",
    "a summary of the overall diagnostic accuracy of the test under consideration is the volume under the roc surface ( vus ) , which can be seen as a generalization of the auc .",
    "reasonable values of vus vary from 1/6 to 1 , ranging from bad to perfect diagnostic tests .",
    "if we know the true disease status of all patients for which the test @xmath0 is measured , then the roc curve or the roc surface can be estimated unbiasedly . in practice , however , the gs test can be too expensive , or too invasive , or both for regular use .",
    "typically , only a subset of patients undergoes disease verification , and the decision to send a patient to verification is often based on the diagnostic test result and other patient characteristics .",
    "for example , subjects with negative test results may be less likely to receive a gs test than subjects with positive test results .",
    "if only data from patients with verified disease status are used to estimate the roc curve or the roc surface , this generally leads to a biased evaluation of the ability of the diagnostic tests .",
    "this bias is known as verification bias .",
    "see , for example , @xcite and @xcite as general references .    correcting for verification bias is a fascinating issue of medical statistics .",
    "various methods have been developed to deal with the problem , most of which assume that the true disease status , if missing , is missing at random ( mar ) , see @xcite . under the mar assumption , there are some verification bias - corrected methods for diagnostic tests , in the two - class case . among the others ,",
    "@xcite present maximum likelihood approaches , @xcite consider a doubly robust estimation of the area under roc curve , while @xcite study a robust estimator for sensitivity and specificity by using propensity score stratification .",
    "verification bias correction for continuous tests has been studied by @xcite and @xcite . in particular , @xcite propose four types of partially parametric estimators of sensitivity and specificity under the mar assumption , i.e. , full imputation ( fi ) , mean score imputation ( msi ) , inverse probability weighting ( ipw ) and semiparametric efficient ( spe , also known as doubly robust dr ) estimator .",
    "@xcite , instead , proposed a fully nonparametric approach for roc analysis .",
    "the issue of correcting for the verification bias in roc surface analysis is very scarcely considered in the literature . until now , only @xcite and @xcite discuss the issue .",
    "@xcite propose maximum likelihood estimates for roc surface and vus corresponding to ordinal diagnostic tests , whereas @xcite extend the methods in @xcite to the estimation of roc surfaces in cases of continuous diagnostic tests .",
    "fi , msi , ipw and spe methods in @xcite are partially parametric methods .",
    "their use requires the specification of parametric regression models for the probability of a subject being correctly classified with respect to the disease state , or the probability of a subject being verified ( i.e. , tested by gs ) , or both .",
    "a wrong specification of such parametric models can negatively affect the behavior of the estimators , that are no longer consistent . in this paper , we propose a fully nonparametric approach to estimate tcf@xmath10 , tcf@xmath11 and tcf@xmath12 in the presence of verification bias , for continuous diagnostic tests .",
    "the proposed approach is based on a nearest - neighbor ( nn ) imputation rule , as in @xcite .",
    "consistency and asymptotic normality of the estimators derived from the proposed method are studied .",
    "in addition , estimation of their variance is also discussed . to show usefulness of our proposal and advantages in comparison with partially parametric estimators , we conduct some simulation studies and give an illustrative example .",
    "the rest of paper is organized as follows . in section 2 ,",
    "we review partially parametric methods for correcting for verification bias in case of continuous tests .",
    "the proposed nonparametric method for estimating roc surfaces and the related asymptotic results are presented in section 3 . in section 4 , we discuss variance - covariance estimation and in section 5 we give some simulation results . an application is illustrated in section 6 .",
    "finally , conclusions are drawn in section 7 .",
    "consider a study with @xmath15 subjects , for whom the result of a continuous diagnostic test @xmath0 is available . for each subject",
    ", @xmath16 denotes the true disease status , that can be possibly unknown .",
    "hereafter , we will describe the true disease status as a trinomial random vector @xmath17 .",
    "@xmath18 is a binary variable that takes @xmath19 if the subject belongs to class @xmath20 , @xmath21 and @xmath22 otherwise . here ,",
    "class 1 , class 2 and class 3 can be referred , for example , as `` non - diseased '' , `` intermediate '' and `` diseased '' .",
    "further , let @xmath23 be a binary verification status for a subject , such that @xmath24 if he / she is undergoes the gs test , and @xmath25 otherwise . in practice",
    ", some information , other than the results from the test @xmath0 , can be obtained for each patient .",
    "let @xmath26 be the covariate vector for the patients , that may be associated both with @xmath16 and @xmath23 .",
    "we are interested in estimating the roc surface of @xmath0 , and hence the true class factions @xmath27 @xmath28 and @xmath29 , for fixed constants @xmath30 , with @xmath8 .",
    "when all patients have their disease status verified by a gs , i.e. , @xmath31 for all @xmath32 , for any pair of cut points @xmath7 , the true class fractions @xmath33 and @xmath34 can be easily estimated by + @xmath35 where @xmath36 is the indicator function .",
    "it is straightforward to show that the above estimators are unbiased .",
    "however , they can not be employed in case of incomplete data , i.e. when @xmath37 for some @xmath32 .    when only some subjects are selected to undergo the gs test , we need to make an assumption about the selection mechanism .",
    "we assume that the verification status @xmath23 and the disease status @xmath16 are mutually independent given the test result @xmath0 and covariate @xmath26 .",
    "this means that @xmath38 or equivalently @xmath39 .",
    "such assumption is a special case of the missing at random ( mar ) assumption ( @xcite ) .    under mar assumption , verification bias - corrected estimation of the true class factions",
    "is discussed in @xcite , where ( partially ) parametric estimators , based on four different approaches , are given . in particular , full imputation ( fi ) estimators of @xmath33 and @xmath34 are defined as @xmath40 this method requires a parametric model ( e.g. multinomial logistic regression model ) to obtain the estimates @xmath41 of @xmath42 , using only data from verified subjects .",
    "differently , the mean score imputation ( msi ) approach only uses the estimates @xmath41 for the missing values of disease status @xmath43 .",
    "hence , msi estimators are @xmath44}{\\sum\\limits_{i=1}^{n}\\left[v_i d_{1i } + ( 1 - v_i ) \\hat{\\rho}_{1i}\\right ] } , \\nonumber \\\\",
    "\\widehat{{\\mathrm{tcf}}}_{2,\\mathrm{msi}}(c_1,c_2 ) & = &   \\frac{\\sum\\limits_{i=1}^{n}\\mathrm{i}(c_1 \\le t_i < c_2)\\left[v_i d_{2i } + ( 1 - v_i ) \\hat{\\rho}_{2i}\\right]}{\\sum\\limits_{i=1}^{n}\\left[v_i d_{2i } + ( 1 - v_i ) \\hat{\\rho}_{2i}\\right ] } , \\label{est : msi3 } \\\\",
    "\\widehat{{\\mathrm{tcf}}}_{3,\\mathrm{msi}}(c_2 ) & = &   \\frac{\\sum\\limits_{i=1}^{n}\\mathrm{i}(t_i \\ge c_2)\\left[v_i d_{3i } + ( 1 - v_i ) \\hat{\\rho}_{3i}\\right]}{\\sum\\limits_{i=1}^{n}\\left[v_i d_{3i } + ( 1 - v_i ) \\hat{\\rho}_{3i}\\right]}. \\nonumber\\end{aligned}\\ ] ] the inverse probability weighting ( ipw ) approach weights each verified subject by the inverse of the probability that the subject is selected for verification .",
    "thus , @xmath33 and @xmath34 are estimated by @xmath45 where @xmath46 is an estimate of the conditional verification probabilities @xmath47 .",
    "finally , the semiparametric efficient ( spe ) estimators are @xmath48 estimators ( [ est : fi])-([est : spe3 ] ) represent an extension to the three - classes problem of the estimators proposed in @xcite .",
    "spe estimators are also known to be doubly robust estimators , in the sense that they are consistent if either the @xmath49 s or the @xmath50 s are estimated consistently . however , spe estimates could fall outside the interval @xmath51 .",
    "this happens because the quantities @xmath52 can be negative .",
    "all the verification bias - corrected estimators of @xmath33 and @xmath34 revised in the previous section belong to the class of ( partially ) parametric estimators , i.e. , they need regression models to estimate @xmath42 and/or @xmath47 . in what follows ,",
    "we propose a fully nonparametric approach to the estimation of @xmath33 and @xmath34 .",
    "our approach is based on the k - nearest neighbor ( knn ) imputation method .",
    "hereafter , we shall assume that @xmath26 is a continuous random variable .",
    "recall that the true disease status is a trinomial random vector @xmath17 such that @xmath18 is a @xmath15 bernoulli trials with success probability @xmath53 .",
    "note that @xmath54 .",
    "let @xmath55 with @xmath56 and @xmath21 .",
    "since parameters @xmath57 are the means of the random variables @xmath58 , we can use the knn estimation procedure discussed in ( @xcite ) to obtain nonparametric estimates @xmath59 .",
    "more precisely , we define @xmath60 , \\qquad k \\in \\mathbb{n } , \\nonumber \\label{est : knn1}\\ ] ] where @xmath61 , and @xmath62 is a set of @xmath63 observed data pairs and @xmath64 denotes the @xmath65-th nearest neighbor to @xmath66 among all @xmath67 s corresponding to the verified patients , i.e. , to those @xmath68 s with @xmath69 .",
    "similarly , we can define the knn estimates of @xmath70 as follows @xmath71 , \\nonumber \\label{est : knn2}\\ ] ] each @xmath72 .",
    "therefore , the knn imputation estimators for @xmath73 are @xmath74}{\\sum\\limits_{i=1}^{n}\\left[v_i d_{1i } + ( 1 - v_i ) \\hat{\\rho}_{1i , k}\\right ] } \\nonumber , \\displaybreak[3 ] \\\\",
    "\\widehat{{\\mathrm{tcf}}}_{2,\\mathrm{knn}}(c_1,c_2 ) & = \\frac{\\hat{\\beta}_{12 } - \\hat{\\beta}_{22}}{\\hat{\\theta}_2 } = \\frac{\\sum\\limits_{i=1}^{n}\\mathrm{i}(c_1 \\le t_i < c_2)\\left[v_i d_{2i } + ( 1 - v_i ) \\hat{\\rho}_{2i , k}\\right]}{\\sum\\limits_{i=1}^{n}\\left[v_i d_{2i } + ( 1 - v_i ) \\hat{\\rho}_{2i , k}\\right ] } ,   \\label{est : knn3 }   \\\\",
    "\\widehat{{\\mathrm{tcf}}}_{3,\\mathrm{knn}}(c_2 ) & = \\frac{\\hat{\\beta}_{23}}{\\hat{\\theta}_3 } =   \\frac{\\sum\\limits_{i=1}^{n}\\mathrm{i}(t_i \\ge c_2)\\left[v_i d_{3i } + ( 1 - v_i ) \\hat{\\rho}_{3i , k}\\right]}{\\sum\\limits_{i=1}^{n}\\left[v_i d_{3i } + ( 1 - v_i ) \\hat{\\rho}_{3i , k}\\right]}. \\nonumber\\end{aligned}\\ ] ]      let @xmath75 and @xmath76 .",
    "the knn imputation estimators of @xmath33 and @xmath34 are consistent and asymptotically normal .",
    "in fact , we have the following theorems .",
    "[ thr : knn:1 ] assume the functions @xmath77 and @xmath78 are finite and first - order differentiable .",
    "moreover , assume that the expectation of @xmath79 exists .",
    "then , for a fixed pair cut of points @xmath7 such that @xmath8 , the knn imputation estimators @xmath80 , @xmath81 and @xmath82 are consistent .    since the disease status @xmath58 is a bernoulli random variable , its second - order moment , @xmath83 , is finite .",
    "according to the first assumption , we can show that the conditional variance of @xmath58 given the test results @xmath0 and @xmath26 , @xmath84 is equal to @xmath85 $ ] and is clearly finite .",
    "thus , by an application of theorem 1 in @xcite , the knn imputation estimators @xmath59 are consistent .",
    "now , observe that , @xmath86 + \\frac{1}{n}\\sum_{i=1}^{n}\\mathrm{i}(t_i \\ge c_j ) ( 1-v_i)(\\hat{\\rho}_{ki , k } - \\rho_{ki } ) - \\beta_{jk } \\nonumber\\\\ & = & \\frac{1}{n}\\sum_{i=1}^{n}\\mathrm{i}(t_i \\ge c_j)v_i\\left[d_{ki } - \\rho_{ki}\\right ] + \\frac{1}{n}\\sum_{i=1}^{n}\\left[\\mathrm{i}(t_i \\ge c_j)\\rho_{ki } - \\beta_{jk}\\right]\\nonumber \\\\ & & + \\ : \\frac{1}{n}\\sum_{i=1}^{n}\\mathrm{i}(t_i \\ge c_j ) ( 1-v_i)(\\hat{\\rho}_{ki , k } - \\rho_{ki})\\nonumber \\\\ & = & s_{jk } + r_{jk } + t_{jk}. \\nonumber\\end{aligned}\\ ] ] here , the quantities @xmath87 and @xmath88 are similar to the quantities @xmath89 and @xmath0 in the proof of theorem 2.1 in @xcite and theorem 1 in @xcite .",
    "thus , we have that @xmath90\\right ) \\qquad \\text{and } \\qquad \\sqrt{n}s_{jk } \\stackrel{d}{\\to } \\mathcal{n}\\left(0,{\\mathbb{e}}\\left[\\pi(t , a)\\delta^2_{jk}(t , a)\\right]\\right),\\ ] ] where @xmath91 is the conditional variance of @xmath92 given @xmath93 .",
    "also , by using a similar technique to that of proof of theorem 1 in @xcite , we get @xmath94 , where @xmath95.\\ ] ] moreover , @xmath96 and @xmath97 + { \\mathbb{e}}\\left[\\frac{(1-\\pi(t , a))^2\\delta_{jk}^2(t , a)}{\\pi(t , a)}\\right].\\ ] ] then , the markov s inequality implies that @xmath98 as @xmath15 goes to infinity .",
    "this , together with the fact that @xmath99 and @xmath100 converge in probability to zero , leads to the consistency of @xmath101 , i.e , @xmath102 .",
    "it follows that @xmath103 , @xmath104 and @xmath105 are consistent .",
    "[ thr : knn:2 ] assume that the conditions in theorem [ thr : knn:1 ] hold , we get @xmath106 \\stackrel{d}{\\to } \\mathcal{n}(0,\\xi ) , \\label{asy : knn}\\ ] ] where @xmath107 is a suitable matrix .",
    "a direct application of theorem 1 in @xcite gives the result that the quantity @xmath108 converges to a normal random variable with mean @xmath22 and variance @xmath109 $ ] .",
    "here , @xmath110 \\nonumber\\\\ & & + \\ : { \\mathbb{e}}\\left[\\frac{\\rho_k(t , a)(1-\\rho_k(t , a))(1-\\pi(t , a))^2}{\\pi(t , a)}\\right ] .",
    "\\label{omega_k}\\end{aligned}\\ ] ] in addition , from the proof of theorem [ thr : knn:1 ] , we have @xmath111 with @xmath90\\right ) , \\quad \\sqrt{n}s_{jk } \\stackrel{d}{\\to } \\mathcal{n}\\left(0,{\\mathbb{e}}\\left[\\pi(t , a)\\delta^2_{jk}(t , a)\\right]\\right)\\ ] ] and @xmath112 therefore , @xmath113 . here , the asymptotic variance @xmath114 is obtained by @xmath115,\\ ] ] with @xmath116 \\nonumber\\\\ & & + \\ : { \\mathbb{e}}\\left[\\frac{\\mathrm{i}(t \\ge c_j)\\rho_k(t , a)(1-\\rho_k(t , a))(1-\\pi(t , a))^2}{\\pi(t , a)}\\right ] .",
    "\\label{omega_jk}\\end{aligned}\\ ] ] this result follows by the fact that @xmath99 and @xmath117 are uncorrelated and the asymptotic covariance between @xmath100 and @xmath118 is obtained by @xmath119.\\ ] ] moreover , we get that the vector @xmath120 is ( jointly ) asymptotically normally distributed with mean vector @xmath121 and suitable covariance matrix @xmath122 .",
    "then , result follows by applying the multivariate delta method to @xmath123 the asymptotic covariance matrix of @xmath124 , @xmath107 , is obtained by @xmath125 where @xmath126 is the first - order derivative of @xmath127 , i.e. , @xmath128      let @xmath129 the asymptotic covariance matrix @xmath122 is a @xmath130 matrix such that its diagonal elements are the asymptotic variances of @xmath131 and @xmath132 .",
    "let us define @xmath133 , @xmath134 and @xmath135 .",
    "we write @xmath136 hence , from ( [ asym_var : knn1 ] ) and ( [ asym_var : knn2 ] ) , @xmath137 let @xmath138 .",
    "hence , @xmath139 , and @xmath140 observe that @xmath141 .",
    "thus , @xmath142 this leads to the expression @xmath143 .",
    "in addition , @xmath144 therefore , from ( [ av : tcf3 ] ) , the asymptotic variance of @xmath145 is @xmath146 recall that @xmath147 $ ] and @xmath148 $ ] , where @xmath149 and @xmath150 are given in ( [ omega_k ] ) and ( [ omega_jk ] ) , respectively . to obtain @xmath151",
    ", we observe that @xmath152 \\nonumber\\\\ & = & { \\mathrm{pr}}\\left(d_k = 1\\right ) - { \\mathrm{pr}}\\left(d_k = 1\\right){\\mathrm{pr}}\\left(t < c_j| d_k = 1\\right ) \\nonumber \\\\ & = & { \\mathrm{pr}}\\left(d_k = 1\\right ) - { \\mathrm{pr}}\\left(t < c_j , d_k = 1\\right ) \\nonumber\\\\ & = & \\theta_k - \\gamma_{jk}\\nonumber,\\end{aligned}\\ ] ] for @xmath21 and @xmath56 .",
    "then , we define @xmath153.\\ ] ] the asymptotic variance of @xmath154 , @xmath155 , is obtained as that of @xmath132 .",
    "in fact , we get @xmath156 $ ] , where @xmath157 \\nonumber\\\\ & & + \\ : { \\mathbb{e}}\\left[\\frac{\\mathrm{i}(t < c_j)\\rho_k(t , a)\\{1-\\rho_k(t ,",
    "a)\\ } \\{1-\\pi(t , a)\\}^2}{\\pi(t , a)}\\right ] . \\nonumber \\label{eta_jk}\\end{aligned}\\ ] ] it is straightforward to see that @xmath158 . thus , we can compute the asymptotic covariances @xmath151 for @xmath56 and @xmath21 , using the fact that @xmath159 this leads to @xmath160 hence , @xmath161 \\sigma_{222 } & = \\dfrac{1}{2}\\left(\\sigma_2 ^ 2 + \\sigma_{22}^2 - \\zeta_{22}^2\\right ) ; & \\qquad \\sigma_{323 } & = \\dfrac{1}{2}\\left(\\sigma_3 ^ 2 + \\sigma_{23}^2 - \\zeta_{23}^2\\right ) .",
    "\\end{array}\\ ] ] as for @xmath162 , one can show that @xmath163 + \\omega^2_{12 } - \\omega^2_{22}\\right\\}. \\nonumber\\ ] ] ( see appendix 1 and , in particular , equation ( [ eq : rem:2 ] ) ) .",
    "therefore , suitable explicit expressions for the asymptotic variances of knn estimators can be found .",
    "such expressions will depend on quantities as @xmath57 , @xmath70 @xmath164 , @xmath165 , @xmath166 and @xmath167 only . as a consequence , to obtain consistent estimates of the asymptotic variances , ultimately we need to estimate the quantities @xmath168 and @xmath169 .    in appendix 2 we show that suitable expressions can be obtained also for the elements @xmath170 , @xmath171 and @xmath172 of the covariance matrix @xmath107",
    ". such expressions will depend , among others , on certain quantities @xmath173 , @xmath174 , @xmath175 , @xmath176 , @xmath177 , @xmath178 and @xmath179 similar to @xmath164 , @xmath165 or @xmath169",
    ".      the proposed method is based on nearest - neighbor imputation , which requires the choice of a value for @xmath63 as well as a distance measure .    in practice , the selection of a suitable distance is tipically dictated by features of the data and possible subjective evaluations ; thus , a general indication about an adequate choice is difficult to express . in many cases ,",
    "the simple euclidean distance may be appropriate .",
    "other times , the researcher may wish to consider specific characteristics of data at hand , and then make a different choice .",
    "for example , the diagnostic test result @xmath0 and the auxiliary covariate @xmath26 could be heterogeneous with respect to their variances ( which is particularly true when the variables are measured on heterogeneous scales ) . in this case , the choice of the mahalanobis distance may be suitable .",
    "as for the choice of the size of the neighborhood , @xcite argue that nearest - neighbor imputation whit a small value of @xmath63 tipically yields negligible bias of the estimators , but a large variance ; the opposite happen with a large value of @xmath63 .",
    "the authors suggest that the choice of @xmath180 is generally adequate when the aim is to estimate an average .",
    "a similar comment is also raised by @xcite and @xcite , i.e. , a small value of @xmath63 , within the range 13 , may be a good choice to estimate roc curves and auc .",
    "however , the authors stress that , in general , the choice of @xmath63 may depend on the dimension of the feature space , and propose to use cross  validation to find @xmath63 in case of high  dimensional covariate .",
    "specifically , the authors indicate that a suitable value of the size of neighbor could be found by @xmath181 where @xmath182 denotes @xmath183 norm for vector and @xmath184 is the number of verified subjects .",
    "the formula above can be generalized to our multi  class case .",
    "in fact , when the disease status @xmath16 has @xmath185 categories ( @xmath186 ) , the difference between @xmath16 and @xmath187 is a @xmath188 matrix .",
    "in such situation , the selection rule could be @xmath189 where @xmath190 denotes @xmath191 norm of matrix @xmath192 , i.e. , @xmath193",
    "consider first the problem of estimating of the variances of @xmath194 , @xmath195 and @xmath196 . in a nonparametric framework ,",
    "quantities as @xmath197 and @xmath198 can be estimated by their empirical counterparts , using also the plug  in method . here",
    ", we consider an approach that uses a nearest - neighbor rule to estimate both the functions @xmath199 and the propensity score @xmath200 , that are present in the expressions of @xmath197 and @xmath198 .",
    "in particular , for the conditional probabilities of disease , we can use knn estimates @xmath201 , where the integer @xmath202 must be greater than one to avoid estimates equal to zero . for the conditional probabilities of verification",
    ", we can resort to the knn procedure proposed in @xcite , which considers the estimates @xmath203 where @xmath204 is a set of @xmath205 observed pairs and @xmath64 denotes the @xmath65-th nearest neighbor to @xmath66 among all @xmath67 s . when @xmath206 equals 0 , @xmath205 is set equal to the rank of the first verified nearest neighbor to the unit @xmath207 , i.e. , @xmath205 is such that @xmath208 and @xmath209 . in case of @xmath31 , @xmath205 is such that @xmath210 , and @xmath211 , i.e. , @xmath205 is set equal to the rank of the first non  verified nearest neighbor to the unit @xmath207 .",
    "such a procedure automatically avoids zero values for the @xmath212 s .",
    "then , based on the @xmath213 s and @xmath212 s , we obtain the estimates @xmath214 from which , along with @xmath59 , @xmath101 and @xmath215 , one derives the estimates of the variances of the proposed knn imputation estimators .    to obtain estimates of covariances",
    ", we need to estimate also the quantities @xmath173 , @xmath174 , @xmath175 , @xmath176 , @xmath177 , @xmath178 and @xmath179 given in appendix 2 .",
    "however , estimates of such quantities are similar to those given above for @xmath197 and @xmath198 . for example , @xmath216    of course , there are other possible approaches to obtain variance and covariance estimates . for instance",
    ", one could resort to a standard bootstrap procedure . from the original observations @xmath217 , @xmath32 ,",
    "consider @xmath218 bootstrap samples @xmath219 , @xmath220 , and @xmath32 .",
    "for the @xmath221-th sample , compute the bootstrap estimates @xmath222 , @xmath223 and @xmath224 as @xmath225}{\\sum\\limits_{i=1}^{n}\\left[v_i^{*b } d^{*b}_{1i } + ( 1 - v_i^{*b } ) \\hat{\\rho}_{1i , k}^{*b}\\right ] } \\nonumber , \\\\ \\widehat{{\\mathrm{tcf}}}_{2,\\mathrm{knn}}^{*b}(c_1,c_2 ) & = \\frac{\\sum\\limits_{i=1}^{n}\\mathrm{i}(c_1 \\le t_i^{*b } < c_2)\\left[v_i^{*b } d^{*b}_{2i } + ( 1 - v_i^{*b } ) \\hat{\\rho}_{2i , k}^{*b}\\right]}{\\sum\\limits_{i=1}^{n}\\left[v_i^{*b } d^{*b}_{2i } + ( 1 - v_i^{*b } ) \\hat{\\rho}_{2i , k}^{*b}\\right ] } , \\nonumber \\label{boot : est : knn } \\displaybreak[3 ] \\\\",
    "\\widehat{{\\mathrm{tcf}}}_{3,\\mathrm{knn}}^{*b}(c_2 ) & =   \\frac{\\sum\\limits_{i=1}^{n}\\mathrm{i}(t_i^{*b } \\ge c_2)\\left[v_i^{*b } d^{*b}_{3i } + ( 1 - v_i^{*b } ) \\hat{\\rho}_{3i , k}^{*b}\\right]}{\\sum\\limits_{i=1}^{n}\\left[v_i^{*b } d^{*b}_{3i } + ( 1 - v_i^{*b } ) \\hat{\\rho}_{3i , k}^{*b}\\right ] } , \\nonumber\\end{aligned}\\ ] ] where @xmath226 , @xmath21 , denote the knn imputation values for missing labels @xmath227 in the bootstrap sample .",
    "then , the bootstrap estimator of the variance of @xmath228 is @xmath229 where @xmath230 is the mean of the @xmath218 bootstrap estimates @xmath231 .",
    "more generally , the bootstrap estimate of the covariance matrix @xmath107 is @xmath232 where @xmath233 is a @xmath234 matrix , whose element in the @xmath221th row and the @xmath20th column corresponds to @xmath231 , and @xmath235 is a column vector that consist of the means of the @xmath218 bootstrap estimates @xmath231 , @xmath236 .",
    "in this section , the ability of knn method to estimate tcf@xmath10 , tcf@xmath11 and tcf@xmath12 is evaluated by using monte carlo experiments .",
    "we also compare the proposed method with partially parametric approaches , i.e. , fi , msi , ipw and spe approaches .",
    "as already mentioned , partially parametric bias - corrected estimators of tcf@xmath10 , tcf@xmath11 and tcf@xmath12 require parametric regression models to estimate @xmath42 , or @xmath237 , or both .",
    "a wrong specification of such models may affect the estimators .",
    "therefore , in the simulation study we consider two scenarios : in the parametric estimation process ,    1 .",
    "the disease model and the verification model are both correctly specified ; 2 .",
    "the disease model and the verification model are both misspecified .    in both scenarios ,",
    "we execute @xmath238 monte carlo runs at each setting ; we set three sample sizes , i.e. , @xmath239 , @xmath240 and @xmath241 in scenario ( i ) and a sample size of @xmath241 in scenario ( ii ) .",
    "we consider knn estimators based on the euclidean distance , with @xmath242 and @xmath243 .",
    "this in light of the discussion in section 3.4 and some results of a preliminary simulation study presented in section s1 , supplementary material . in such study , we compared the behavior of the knn estimators for several choices of the distance measure ( euclidean , manhattan , canberra and mahalanobis ) and the size of the neighborhood ( @xmath244 ) .",
    "the true disease @xmath16 is generated by a trinomial random vector @xmath245 , such that @xmath58 is a bernoulli random variable with success probability @xmath57 , @xmath236 .",
    "we set @xmath246 and @xmath247 .",
    "the continuous test result @xmath0 and a covariate @xmath26 are generated from the following conditional models @xmath248 where @xmath249 and @xmath250 we consider three different values for @xmath251 , specifically @xmath252 giving rise to a correlation between @xmath0 and @xmath26 equal to @xmath253 and @xmath254 , respectively .",
    "values chosen for @xmath251 give rise to true vus values ranging from 0.7175 to 0.4778 .",
    "the verification status @xmath23 is generated by the following model @xmath255 where we fix @xmath256 and @xmath257 .",
    "this choice corresponds to a verification rate of about @xmath258 .",
    "we consider six pairs of cut points @xmath7 , i.e. , @xmath259 , @xmath260 and @xmath261 .",
    "since the conditional distribution of @xmath0 given @xmath58 is the normal distribution , the true parameters values are @xmath262 where @xmath263 denotes the cumulative distribution function of the standard normal random variable . in this set",
    " up , fi , msi , ipw and spe estimators are computed under correct working models for both the disease and the verification processes . therefore , the conditional verification probabilities @xmath264 are estimated from a logistic model for @xmath23 given @xmath0 and @xmath26 with logit link . under our data",
    " generating process , the true conditional disease model is a multinomial logistic model @xmath265 for suitable @xmath266 , where @xmath267 .",
    "tables [ tab : res11][tab : res13 ] show monte carlo means and standard deviations of the estimators for the three true class factions .",
    "results concern the estimators fi , msi , ipw , spe , and the knn estimator with @xmath242 and @xmath268 computed using the euclidean distance . also , the estimated standard deviations are shown in the tables .",
    "the estimates are obtained by using asymptotic results . to estimate standard deviations of knn estimators",
    ", we use the knn procedure discussed in section 4 , with @xmath269 .",
    "each table refers to a choosen value for @xmath251 .",
    "the sample size is @xmath239 .",
    "the results for sample sizes @xmath240 and @xmath241 are presented in section s2 of supplementary material .",
    "as expected , the parametric approaches work well when both models for @xmath77 and @xmath78 are correctly specified .",
    "fi and msi estimators seem to be the most efficient ones , whereas the ipw approach seems to provide less powerful estimators , in general . the new proposals ( 1nn and 3nn estimators ) yield also good results , comparable , in terms of bias and standard deviation , to those of the parametric competitors . moreover",
    ", estimators 1nn and 3nn seem to achieve similar performances , and the results about estimated standard deviations of knn estimators seem to show the effectiveness of the procedure discussed in section 4 .    finally , some results of simulation experiments performed to explore the effect of a multidimensional vector of auxiliary covariates are given in section s3 , supplementary material .",
    "a vector @xmath26 of dimension 3 is employed .",
    "the results in table 16 , supplementary material , show that knn estimators still behave satisfactorily .",
    ".monte carlo means , monte carlo standard deviations and estimated standard deviations of the estimators for true class fractions , in case of sample size equals to @xmath239 .",
    "the first value of @xmath251 is considered .",
    "`` true '' denotes the true parameter value . [ cols=\"^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     [ tab : res2 ]",
    "we use data on epithelial ovarian cancer ( eoc ) extracted from the pre - plco phase ii dataset from the spore / early detection network / prostate , lung , colon , and ovarian cancer ovarian validation study .. ] as in @xcite , we consider the following three classes of eoc , i.e. , benign disease , early stage ( i and ii ) and late stage ( iii and iv ) cancer , and 12 of the 59 available biomarkers , i.e. ca125 , ca153 , ca724 , kallikrein 6 ( klk6 ) , he4 , chitinase ( ykl40 ) and immune costimulatory protein  b7h4 ( dd0110 ) , insulin  like growth factor 2 ( igf2 ) , soluble mesothelin - related protein ( smrp ) , spondin2 ( dd  p108 ) , decoy receptor 3 ( dcr3 ; dd  c248 ) and macrophage inhibitory cytokine 1 ( dd  x065 ) . in addition , age of patients is also considered .    after cleaning for missing data ,",
    "we are left 134 patients with benign disease , 67 early stage samples and 77 late stage samples . as a preliminary step of our analysis we ranked the 12 markers according to value of vus , estimated on the complete data .",
    "the observed ordering , consistent with medical knowledge , led us to select ca125 as the test @xmath0 to be used to illustrate our method .    to mimic verification bias ,",
    "a subset of the complete dataset is constructed using the test @xmath0 and a vector @xmath270 of two covariates , namely the marker ca153 ( @xmath271 ) and age ( @xmath272 ) .",
    "reasons for using ca153 as a covariate come from the medical literature that suggests that the concomitant measurement of ca153 with ca125 could be advantageous in the pre - operative discrimination of benign and malignant ovarian tumors . in this subset ,",
    "@xmath0 and @xmath26 are known for all samples ( patients ) , but the true status ( benign , early stage or late stage ) is available only for some samples , that we select according to the following mechanism .",
    "we select all samples having a value for @xmath0 , @xmath271 and @xmath272 above their respective medians , i.e. 0.87 , 0.30 and 45 ; as for the others , we apply the following selection process @xmath273 leading to a marginal probability of selection equal to @xmath274 .    since the test @xmath0 and the covariates @xmath275",
    "are heterogeneous with respect to their variances , the mahalanobis distance is used for knn estimators . following discussion in section 3.4 , we use the selection rule ( [ choice : k:1 ] ) to find the size @xmath63 of the neighborhood .",
    "this leads to the choice of @xmath242 for our data .",
    "in addition , we also employ @xmath268 for the sake of comparison with 1nn result , and produce the estimate of the roc surface based on full data ( full estimate ) , displayed in figure [ fg : res : full ] .",
    "figure [ fg : res : knn ] shows the 1nn and 3nn estimated roc surfaces for the test @xmath0 ( ca125 ) . in this figure , we also give the 95% ellipsoidal confidence regions ( green color ) for @xmath276 at cut points @xmath277 .",
    "these regions are built using the asymptotic normality of the estimators . compared with the full estimate ,",
    "knn bias - corrected method proposed in the paper appears well behave , yielding reasonable estimates of the roc surface with incoplete data .",
    "@c@c@ +   &   + [ -0.1em ] ( a ) 1nn & ( b ) 3nn +",
    "a suitable solution for reducing the effects of model misspecification in statistical inference is to resort to fully nonparametric methods .",
    "this paper proposes a nonparametric estimator of the roc surface of a continuous - scale diagnostic test .",
    "the estimator is based on nearest - neighbor imputation and works under mar assumption .",
    "it represents an alternative to ( partially ) parametric estimators discussed in @xcite .",
    "our simulation results and the presented illustrative example show usefulness of the proposal .    as in @xcite and @xcite ,",
    "a simple extension of our estimator , that could be used when categorical auxiliary variables are also available , is possible . without loss of generality",
    ", we suppose that a single factor @xmath278 , with @xmath279 levels , is observed together with @xmath0 and @xmath26 .",
    "we also assume that @xmath278 may be associated with both @xmath16 and @xmath23 . in this case",
    ", the sample can be divided into @xmath279 strata , i.e. @xmath279 groups of units sharing the same level of @xmath280 then , for example , if the mar assumption and first - order differentiability of the functions @xmath77 and @xmath78 hold in each stratum , a consistent and asymptotically normally distributed estimator of tcf@xmath10 is @xmath281 where @xmath282 denotes the size of the @xmath65-th stratum and @xmath283 denotes the knn estimator of the conditional tcf@xmath10 , i.e. , the knn estimator in ( [ est : knn3 ] ) obtained from the patients in the @xmath65-th stratum .",
    "of course , we must assume that , for every @xmath65 , ratios @xmath284 have finite and nonzero limits as @xmath15 goes to infinity .",
    "adimari , g. and chiogna , m. ( 2015a ) .",
    "neighbor estimation for roc analysis under verification bias . _ the international journal of biostatistics _ * 11 * , 1 , 109124 .",
    "adimari , g. and chiogna , m. ( 2015b ) .",
    "nonparametric verification bias  corrected inference for the area under the roc curve of a continuous  scale diagnostic test . _ submitted_.    alonzo , t. a. and pepe , m. s. and lumley , t. ( 2003 ) .",
    "estimating disease prevalence in two - phase studies .",
    "_ biostatistics _ * 4 * , 313326 .",
    "alonzo , t. a. and pepe , m. s. ( 2005 ) . assessing accuracy of a continuous screening test in the presence of verification bias .",
    "_ journal of the royal statistical society : series c ( applied statistics ) _ * 54 * , 173290 .",
    "alonzo , t. a. ( 2014 ) .",
    "verification bias ",
    "impact and methods for correction when assessing accuracy of diagnostic tests .",
    "_ revstat  statistical journal _ * 12 * , 6783 .",
    "bamber , d. ( 1975 ) . the area above the ordinal dominance graph and the area below the receiver operating characteristic graph . _ journal of mathematical psychology _ * 12 * , 387415 .",
    "cheng , p. e. ( 1994 ) .",
    "nonparametric estimation of mean functionals with data missing at random . _ journal of the american statistical association _ * 89 * , 425 , 8187 .",
    "chi , y. y. and zhou , x. h. a. ( 2008 ) .",
    "receiver operating characteristic surfaces in the presence of verification bias .",
    "_ journal of the royal statistical society : series c ( applied statistics ) _ * 57 * , 123 .",
    "he , h. and mcdermott , m. p. ( 2012 ) .",
    "a robust method using propensity score stratification for correcting verification bias for binary tests .",
    "_ biostatistics _ * 13 * , 3247 .",
    "kang , l. and tian , l. ( 2013 ) .",
    "estimation of the volume under the roc surface with three ordinal diagnostic categories .",
    "_ computational statistics and data analysis _ * 62 * , 3951 .",
    "little , r. j. and rubin , d. b. ( 1987 ) .",
    "_ statistical analysis with missing data_. new york : wiley .",
    "nakas , c. t. and yiannoutsos , c. y. ( 2004 ) .",
    "ordered multiple - class roc analysis with continuous measurements . _ statistics in medicine _ * 23 * , 34373449 .",
    "nakas , c. t. ( 2014 ) .",
    "developments in roc surface analysis and assessment of diagnostic markers in three - class classification problems .",
    "_ revstat  statistical journal _ * 12 * , 4365 .",
    "ning , j. and cheng , p. e. ( 2012 ) .",
    "a comparison study of nonparametric imputation methods . _ statistics and computing _ * 22 * , 1 , 273285 .",
    "pepe , m. s. ( 2003 ) . _ the statistical evaluation of medical tests for classification and prediction . _ oxford university press .",
    "rotnitzky , a. and faraggi , d. and schisterman , e. ( 2006 ) . doubly robust estimation of the area under the receiver - operating characteristic curve in the presence of verification bias .",
    "_ journal of the american statistical association _",
    "* 101*.    scurfield , b. k. ( 1996 ) .",
    "multiple - event forced - choice tasks in the theory of signal detectability . _ journal of mathematical psychology _ * 40 * , 253269 .    to duc , k. , chiogna , m. and adimari , g. ( 2015 ) .",
    "bias - corrected methods for estimating the receiver operating characteristic surface of continuous diagnostic tests . _ submitted_.    xiong , c. and van belle , g. and miller , j. p. and morris , j. c. ( 2006 ) .",
    "measuring and estimating diagnostic accuracy when there are three ordinal diagnostic groups .",
    "_ statistics in medicine _ * 25 * , 12511273 .",
    "zhou , x. h. and obuchowski , n. a. and mcclish , d. k. ( 2002 ) .",
    "_ statistical methods in diagnostic medicine .",
    "_ wiley  sons , new york .",
    "according the proof of theorem [ thr : knn:2 ] , we have @xmath285 here , we have @xmath286 \\nonumber \\\\ w_{12 } - w_{22 } & = & \\frac{1}{n}\\sum_{i=1}^{n}\\mathrm{i}(c_1 \\le t_i < c_2)(1-v_i)\\left[\\frac{1}{k}\\sum_{l=1}^{k}\\left(v_{i(l)}d_{2i(l ) } - \\rho_{2i(l)}\\right)\\right ] \\nonumber.\\end{aligned}\\ ] ] under that , we realize that quantities @xmath287 and @xmath100 , so as @xmath288 and @xmath99 , and @xmath289 and @xmath118 , play , in essence , a similar role .",
    "therefore , the quantities in right hand side of equation ( [ eq : rem:1 ] ) have approximately normal distributions with mean @xmath22 and variances @xmath290 , \\nonumber \\\\",
    "{ \\mathbb{v}\\mathrm{ar}}\\left(\\sqrt{n } ( w_{12 } - w_{22 } ) \\right ) & = &   \\frac{1}{k}{\\mathbb{e}}\\left[(1 - \\pi(t , a))\\delta^2(t , a)\\right ] + { \\mathbb{e}}\\left[\\frac{(1-\\pi(t , a))^2\\delta^2(t , a)}{\\pi(t , a)}\\right ] .\\nonumber\\end{aligned}\\ ] ] where , @xmath291 is the conditional variance of @xmath292 given @xmath93 .",
    "then , we get @xmath293 \\stackrel{d}{\\to } \\mathcal{n}(0,\\lambda^2).\\ ] ] to obtain @xmath162 , we notice that the quantities @xmath288 and @xmath294 are uncorrelated and the asymptotic covariance of @xmath287 and @xmath289 equals to @xmath295 $ ] . taking the sum of this covariance and the above variances ,",
    "the desired asymptotic variance @xmath162 is approximately @xmath296 + \\omega^2_{12 } - \\omega^2_{22}\\right\\}. \\label{eq : rem:2}\\ ] ]",
    "here , we focus on the elements @xmath170 , @xmath171 and @xmath172 of the covariance mtrix @xmath107",
    ". we can write @xmath297 ,   \\label{cov:13}\\end{aligned}\\ ] ] and @xmath298 \\nonumber \\\\ & & + \\ : \\frac{\\beta_{23}}{\\theta_2(1 - \\theta_1 - \\theta_2)^2}\\left[\\left(\\sigma_{112 } - \\sigma_{122 } + \\sigma_{212 } - \\sigma_{222}\\right ) - \\frac{\\beta_{12 } - \\beta_{22}}{\\theta_2}\\left(\\sigma_2 ^ 2 + \\sigma_{12}^*\\right)\\right ]",
    ". \\label{cov:23}\\end{aligned}\\ ] ] recall that @xmath299 + \\frac{1}{n}\\sum_{i=1}^{n } ( 1-v_i)(\\hat{\\rho}_{ki , k } - \\rho_{ki } ) - \\theta_{k } \\nonumber\\\\ & = & \\frac{1}{n}\\sum_{i=1}^{n}v_i\\left[d_{ki } - \\rho_{ki}\\right ] + \\frac{1}{n}\\sum_{i=1}^{n}\\left[\\rho_{ki } - \\theta_{k}\\right]\\nonumber \\\\ & & + \\ : \\frac{1}{n}\\sum_{i=1}^{n}\\left[\\frac{1}{k}\\sum_{l=1}^{k}\\left(v_{i(l)}d_{ki(l ) } - \\rho_{ki(l)}\\right)\\right ] + o_p\\left(n^{-1/2}\\right ) \\nonumber \\\\ & = & s_{k } + r_{k } + w_{k } + o_p\\left(n^{-1/2}\\right ) ; \\nonumber\\end{aligned}\\ ] ] and @xmath86 + \\frac{1}{n}\\sum_{i=1}^{n}\\mathrm{i}(t_i \\ge c_j ) ( 1-v_i)(\\hat{\\rho}_{ki , k } - \\rho_{ki } ) - \\beta_{jk } \\nonumber\\\\ & = & \\frac{1}{n}\\sum_{i=1}^{n}\\mathrm{i}(t_i \\ge c_j)v_i\\left[d_{ki } - \\rho_{ki}\\right ] + \\frac{1}{n}\\sum_{i=1}^{n}\\left[\\mathrm{i}(t_i \\ge c_j)\\rho_{ki } - \\beta_{jk}\\right]\\nonumber \\\\ & & + \\ : \\frac{1}{n}\\sum_{i=1}^{n}\\mathrm{i}(t_i \\ge c_j)(1-v_i)\\left[\\frac{1}{k}\\sum_{l=1}^{k}\\left(v_{i(l)}d_{ki(l ) } - \\rho_{ki(l)}\\right)\\right ] + o_p\\left(n^{-1/2}\\right ) \\nonumber \\\\ & = & s_{jk } + r_{jk } + w_{jk } + o_p\\left(n^{-1/2}\\right ) .",
    "\\nonumber\\end{aligned}\\ ] ] then , we restating some terms that appear in expressions ( [ cov:12])([cov:23 ] ) .",
    "first , we consider the term , @xmath300 .",
    "we have @xmath301 this result follows from the fact that @xmath302 and @xmath303 , and @xmath304 and @xmath305 are uncorrelated ( see also @xcite ) . by arguments similar to those used in @xcite",
    ", we also obtain @xmath306 similarly , we have that @xmath307\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } , \\nonumber \\\\ { \\mathrm{as}\\mathbb{c}\\mathrm{ov}}\\left(\\sqrt{n}r_{11},\\sqrt{n}(r_{12 } - r_{22})\\right ) & = &   - \\beta_{11}(\\beta_{12 } - \\beta_{22 } ) + { \\mathbb{e}}\\left\\{\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } , \\nonumber \\\\",
    "{ \\mathrm{as}\\mathbb{c}\\mathrm{ov}}\\left(\\sqrt{n}w_{11},\\sqrt{n}(s_{12 } - s_{22})\\right ) & = & -{\\mathbb{e}}\\left\\{[1-\\pi(t , a)]\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } , \\nonumber \\\\ { \\mathrm{as}\\mathbb{c}\\mathrm{ov}}\\left(\\sqrt{n}w_{11},\\sqrt{n}(w_{12 } - w_{22})\\right ) & = & -\\frac{1}{k}{\\mathbb{e}}\\left\\{[1-\\pi(t , a)]\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } \\nonumber\\\\ & & - { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(c_1 \\le t",
    "< c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)}{\\pi(t",
    ", a)}\\right\\ } . \\nonumber\\end{aligned}\\ ] ] this leads to @xmath308 , \\label{sig_1112 - sig_1122}\\end{aligned}\\ ] ] where @xmath309\\mathrm{i}(c_1 \\le t",
    "< c_2)\\rho_{1}(t , a)\\rho_{2}(t , a ) \\right\\ } \\nonumber \\\\ & & + \\ : { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)}{\\pi(t ,",
    "a)}\\right\\}. \\nonumber \\end{aligned}\\ ] ]    second , we consider @xmath310 . in this case , we have @xmath311 we obtain @xmath312\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } , \\nonumber \\\\",
    "{ \\mathrm{as}\\mathbb{c}\\mathrm{ov}}\\left(\\sqrt{n}r_{1},\\sqrt{n}(r_{12 } - r_{22})\\right ) & = &   - \\theta_{1}(\\beta_{12 } - \\beta_{22 } ) + { \\mathbb{e}}\\left\\{\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } , \\nonumber \\\\",
    "{ \\mathrm{as}\\mathbb{c}\\mathrm{ov}}\\left(\\sqrt{n}w_{1},\\sqrt{n}(s_{12 } - s_{22})\\right ) & = & -{\\mathbb{e}}\\left\\{[1-\\pi(t , a)]\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } , \\nonumber \\\\ { \\mathrm{as}\\mathbb{c}\\mathrm{ov}}\\left(\\sqrt{n}w_{1},\\sqrt{n}(w_{12 } - w_{22})\\right ) & = & -\\frac{1}{k}{\\mathbb{e}}\\left\\{[1-\\pi(t , a)]\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t , a)\\rho_{2}(t , a)\\right\\ } \\nonumber\\\\ & & - { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(c_1 \\le t < c_2)\\rho_{1}(t ,",
    "a)\\rho_{2}(t , a)}{\\pi(t , a)}\\right\\ } , \\nonumber\\end{aligned}\\ ] ] and then @xmath313 .",
    "\\label{sig_112 - sig_122}\\end{aligned}\\ ] ] + similarly , it is straightforward to obtain @xmath314 \\label{sig_211}\\end{aligned}\\ ] ] and @xmath315 , \\label{sig_123}\\end{aligned}\\ ] ] with @xmath316\\mathrm{i}(t \\ge c_1)\\rho_{1}(t , a)\\rho_{2}(t , a ) \\right\\ } \\nonumber \\\\ & & + \\ : { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(t \\ge c_1)\\rho_{1}(t , a)\\rho_{2}(t , a)}{\\pi(t , a)}\\right\\ } \\nonumber \\end{aligned}\\ ] ] and @xmath317\\mathrm{i}(t \\ge c_2)\\rho_{1}(t , a)\\rho_{3}(t , a ) \\right\\ } \\nonumber \\\\ & & + \\ : { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(t \\ge c_2)\\rho_{1}(t , a)\\rho_{3}(t , a)}{\\pi(t , a)}\\right\\}. \\nonumber \\end{aligned}\\ ] ]    the covariance between @xmath318 and @xmath319 is computed analogously , i.e. , @xmath320 , \\label{sig_12*}\\end{aligned}\\ ] ] where @xmath321\\rho_{1}(t , a)\\rho_{2}(t , a ) \\right\\ } \\nonumber \\\\ & & + \\ : { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\rho_{1}(t , a)\\rho_{2}(t , a)}{\\pi(t , a)}\\right\\}. \\nonumber \\end{aligned}\\ ] ]    by using results ( [ sig_1112 - sig_1122 ] ) , ( [ sig_112 - sig_122 ] ) , ( [ sig_211 ] ) and ( [ sig_12 * ] ) into ( [ cov:12 ] ) , we can obtain a suitable expression for @xmath322 , which depends on easily estimable quanties .    clearly , a similar approach can be used to get suitable expressions for @xmath171 and @xmath172 too . in particular",
    ", the estimable version of @xmath171 can be obtained by using suitable expressions for @xmath323 , @xmath324 and @xmath325 .",
    "the quantity @xmath323 is already computed in ( [ sig_123 ] ) , and the formula for @xmath324 can be obtained as @xmath326 .",
    "\\nonumber \\label{sig_1123}\\end{aligned}\\ ] ] to compute @xmath325 , we notice that @xmath327 it leads to @xmath328 .",
    "similarly to ( [ sig_211 ] ) , we have that @xmath329 , \\nonumber \\label{sig_311}\\end{aligned}\\ ] ] where @xmath330\\mathrm{i}(t \\ge c_1)\\rho_{1}(t , a)\\rho_{3}(t , a ) \\right\\ } \\nonumber \\\\ & & + \\ : { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(t \\ge c_1)\\rho_{1}(t , a)\\rho_{3}(t , a)}{\\pi(t ,",
    "a)}\\right\\}. \\nonumber \\end{aligned}\\ ] ]    for the last term @xmath172 , we need to make some other calculations .",
    "first , the quantity @xmath331 is obtained as @xmath300 .",
    "we have @xmath332 because @xmath333 .",
    "second , the term @xmath334 is obtained as @xmath335 , \\nonumber \\label{sig_223}\\end{aligned}\\ ] ] where @xmath336\\mathrm{i}(t \\ge c_2)\\rho_{2}(t , a)\\rho_{3}(t , a ) \\right\\ } \\nonumber \\\\ & & + \\ : { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(t \\ge c_2)\\rho_{2}(t , a)\\rho_{3}(t , a)}{\\pi(t , a)}\\right\\ } .",
    "\\nonumber \\end{aligned}\\ ] ] moreover , it is straightforward to show that @xmath337 and that @xmath338 , \\nonumber \\label{sig_312 - sig_322}\\end{aligned}\\ ] ] with @xmath339\\mathrm{i}(c_1 \\le t",
    "< c_2)\\rho_{2}(t , a)\\rho_{3}(t , a ) \\right\\ } \\nonumber \\\\ & & + \\ : { \\mathbb{e}}\\left\\{\\frac{[1-\\pi(t , a)]^2\\mathrm{i}(c_1 \\le t < c_2)\\rho_{2}(t , a)\\rho_{3}(t , a)}{\\pi(t ,",
    "a)}\\right\\}. \\nonumber \\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> verification bias is a well known problem when the predictive ability of a diagnostic test has to be evaluated . in this paper , we discuss how to assess the accuracy of continuous - scale diagnostic tests in the presence of verification bias , when a three - class disease status is considered . in particular , we propose a fully nonparametric verification bias - corrected estimator of the roc surface . </S>",
    "<S> our approach is based on nearest - neighbor imputation and adopts generic smooth regression models for both the disease and the verification processes . </S>",
    "<S> consistency and asymptotic normality of the proposed estimator are proved and its finite sample behavior is investigated by means of several monte carlo simulation studies . variance estimation is also discussed and an illustrative example is presented . + * key words : * diagnostic tests , missing at random , true class fractions , nearest - neighbor imputation . </S>"
  ]
}