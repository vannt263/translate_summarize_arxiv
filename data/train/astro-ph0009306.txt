{
  "article_text": [
    "the hierarchical clustering hypothesis provides an attractive paradigm for the formation of structure in a universe dominated by cold dark matter .",
    "small - scale objects form first and merge to yield systems of increasing size .",
    "this highly non - linear process has been studied extensively using n - body simulations with particular attention paid to the survival of subhalos once a merger event has occurred .",
    "early results suggested that substructures ( i.e. , subhalos within halos ) are erased efficiently ( white 1976 ; frenk et al.1988 ) .",
    "this so - called overmerging problem plagued investigations of galaxy cluster formation since it lead to the conclusion that the constituent galaxies do not survive .",
    "however , recent high resolution simulations ( ghigna et al.1998 , klypin et al.1999 ) together with analytic work ( moore , katz , & lake 1996 ) demonstrated that the overmerging problem was due entirely to the poor mass and spatial resolution of early simulations .",
    "indeed , moore et al.(1999 ) found that on galactic scales , simulated halos may have too much substructure .",
    "their high resolution simulation of a @xmath0 ( i.e. , milky - way sized ) halo revealed over 500 @xmath1 subhalos , a factor of 50 greater than the number of visible satellites in the milky way .",
    "an essential element in the analysis of cosmological n - body simulations is the identification of physical structures , namely halos and subhalos .",
    "there are now a number of algorithms available to do this such as friends - of - friends ( fof ; davis et al.1985 ) , denmax ( bertschinger & gelb 1991 ; gelb & bertschinger 1994 ) , and skid ( governato et al.1997 ) .",
    "the fof algorithm identifies structures by linking all particle pairs separated by less than a user - supplied distance known as the linking parameter . for a particular choice of linking parameter , the algorithm produces a unique list of structures .",
    "denmax , and the closely related algorthm skid , are based on contour surfaces of the three - dimensional density field .",
    "each local maximum of the density field is assumed to correspond to the center of a halo or subhalo : all particles interior to the last closed contour surrounding a given maximum are assigned to the corresponding halo .",
    "two challenges , brought to the fore by the dramatic improvements in the mass and force resolution of present - day simulations , now confront these methods : ( 1 ) identification of subhalos within the dense regions of a parent halo ; and ( 2 ) analysis of multiple levels of substructure .",
    "a given simulation particle may be a member of a small clump that is , in turn , gravitationally bound to a larger ( sub)halo .",
    "likewise , the subhalo may be gravitationally bound to a galactic or cluster - sized halo .",
    "such a particle is most accurately described as being a member of three distinct structures .",
    "thus , any scheme which assigns a given particle to at most one structure can not hope to capture the hierarchical nature of dark matter halos .",
    "early incarnations of the fof algorithm relied on a single linking length . if the linking length is set to be too large , subhalos in the inner parts of large halos are missed . with a small linking length ,",
    "on the other hand , the algorithm picks out substructure but loses information on large scales .",
    "these problems can be avoided if one uses a `` hierarchical '' version of fof ( klypin et al.1999 ) wherein the algorithm is run several times with different linking lengths .",
    "denmax and skid are best suited to finding substructure since they locate all maxima in the density field",
    ". the hierarchical nature of clustering can be studied by applying smoothing filters to the density field and rerunning the algorithm .    in this paper",
    ", we describe a multiresolution analysis ( mra ) that handles , in a natural way , the multiple levels structure found in cosmological n - body simulations .",
    "mra refers to a general class of tools that provide a simple hierarchical representation of a signal , the signal , in our case , being the density field in a simulation . at each resolution",
    ", the analysis picks out the _ details _ of the signal at a characteristic scale .",
    "thus , mra can be thought of as a `` mathematical microscope '' : coarse resolution ( low magnification ) probes large - scale structures in the signal while fine resolution ( high magnification ) probes small - scale structures .",
    "we employ a specific mra that is based on the wavelet transform known as the .",
    "a wavelet transform allows one to analyze a signal simultaneously in scale and position .",
    "the transform accomplishes this task by convolving the signal with a special type of window function known as a wavelet .",
    "wavelets must have compact support and integrate to zero .",
    "the wavelet transform therefore probes local properties of the density field and is insensitive to a mean background .",
    "the wavelets used in a particular implementation of the transform are chosen to be translations and dilations of a single prototype known as the mother wavelet .",
    "a low resolution analysis of a signal is achieved by using large - scale versions of the mother wavelet : high resolution is achieved by using small - scale versions .",
    "thus , wavelet analysis fits naturally within the framework of mra ( mallat 1989a , 1989b ) .",
    "the wavelet transform can provide a complete description of a density field found in a cosmological n - body simulation .",
    "segmentation analysis produces , from the results of the wavelet transform , a catalog of structures and substructures .",
    "dynamical information can then be used to cull , from this catalog , unbound associations of particles .",
    "the algorithm described in this paper was first used in the context of cosmological n - body simulations by lega et al.(1995 ) and lega et al.(1996 ) who were interested in the morphology of large scale structure in various cosmological models ( e.g. , hot vs.cold dark matter ) .",
    "it has also been used by gambera et al.(1997 ) to analyze observational data for the coma cluster .",
    "we adapt this algorithm to the specific task of sorting out multiple levels of substructure that arise within individual dark matter halos .",
    "our implementation of the algorithm is outlined in section 2 .",
    "results from the analysis of a cluster - sized dark matter halo are presented in section 3 . in section 4",
    "we describe our somewhat unorthodox procedure for identifying bound systems of particles .",
    "statistics of the subhalos are discussed in section 5 where we also present an example of a region of the simulation that exhibits multiple levels of substructure .",
    "in this section , we describe the two steps which comprise the heart of the algorithm : ( 1 ) calculation of the wavelet transform of a density field ; and ( 2 ) application of segmentation analysis to identify individual physical structures .",
    "the wavelet transform of a given signal represents the detail in the signal as a function of position and scale .",
    "operationally , the wavelet transform is computed by convolving the signal with a window function known as a wavelet . for a particular wavelet transform , the set of analyzing wavelets is constructed by applying translations and dilations to the mother wavelet .",
    "thus , the mother wavelet characterizes the transform .    in a continuous wavelet transform ( cwt ) ,",
    "the set of analyzing wavelets is chosen to include all possible translations and dilations of the mother wavelet .",
    "if the signal depends on one variable ( say position ) the cwt will be a continuous function of two variables , position and scale .",
    "it follows that the information contained in a cwt is highly redundant .",
    "by contrast , the discrete wavelet transform ( dwt ) utilizes a countable set of analyzing wavelets constructed by taking discrete translations and dilations of the mother wavelet .",
    "provided certain conditions are met , the redundancy in the wavelet transform can be eliminated . in other words , the set of analyzing wavelets in a dwt can be chosen to form a complete , orthonormal basis for a large class of continuous functions .    for large data sets ,",
    "the number of computations required in the standard dwt becomes exceedingly large .",
    "there are now a number of efficient algorithms which make it possible to perform dwts on large data sets .",
    "these algorithms are related to the standard dwt much in the way the fast fourier transform is related to the standard fourier transform .",
    "the ( holschneider et al.1989 , dutilleux 1989 ) is an example of such an algorithm .",
    "our description of this algorithm is preceded by a general discussion of continuous and discrete wavelet transforms .",
    "the cwt of a one - dimensional function @xmath2 is given by    w(,a ) = _ -^f(x ) ^*(,a;x)dx    where the parameters @xmath3 and @xmath4 characterize the scale and position of the analyzing wavelet @xmath5 and @xmath6 is the complex conjugate of @xmath7 .",
    "@xmath8 is constructed by applying a rescaling ( by @xmath3 ) and a translation ( by @xmath4 ) to the user - supplied mother wavelet @xmath9 :    ( , a;x )  =   _ 0 ( )  .",
    "the original function @xmath10 can be reconstructed via the inverse transform    f(x ) = w(,a ) ( , a;x)dda    provided the mother wavelet satisfies the admissibility condition        where @xmath11 is the fourier transform of @xmath9 . from this condition",
    "it follows that @xmath12 and therefore the wavelet must be oscillatory , i.e. , wavelike in nature .",
    "a cwt resembles a windowed fourier transform ( wft ) in the sense that both operations utilize a set of window functions or filters to analyze a signal simultaneously in scale and position ( see , for example , kaiser 1994 ; burrows , gopinath , & guo 1998 ) .",
    "however , the width of the window function in the cwt scales with @xmath3 whereas the width of the window function in a wft is fixed .",
    "thus , the cwt is _ scale - independent _ : rescaling lengths in the data set leaves the cwt unchanged modulo a shift along the scale axis .",
    "the cwt defined in eq .",
    "maps a function of one variable into a function of two variables .",
    "thus , the resultant transform , @xmath13 , contains redundant information ( i.e. , @xmath8 forms an overcomplete basis ) .",
    "consider instead the dwt and associated reconstruction formula :    w_n , i = _ -^_0^ * ( ) f(x )    f(x ) = _ n , i _ 0 ( ) w_n , i    where @xmath14 and @xmath15 are integers , @xmath16 , and @xmath17 .",
    "@xmath18 and @xmath19 are constants representing respectively the ratio between different levels @xmath15 of the dwt and the sampling interval .",
    "the @xmath20 are referred to as the wavelet amplitude coefficients ( wacs ) . in",
    "what follows , we take @xmath21 to correspond to the smallest scale ( highest resolution ) level in the transform .",
    "increasing @xmath15 corresponds to dilating the wavelet and thus degrading the resolution . in practice",
    ", the signal is sampled at regular intervals  for the case at hand , the sampling interval corresponds to the grid spacing of the discretized density field  and it is natural to choose @xmath19 to be equal to the grid spacing .",
    "the integral in eq .",
    "is then replaced by a sum over @xmath22 where @xmath23 .",
    "the goal in wavelet analysis is to find a set of analyzing wavelets such that any square - integrable function can be expressed by eq .. many examples of suitable wavelet bases have been discovered .",
    "however , for large data sets , the computation requirements become prohibitively large . consider a signal that consists of @xmath24 data points .",
    "if the wavelet has compact support so that it takes @xmath25 computations to perform a single convolution at level @xmath21 , it will take @xmath26 computations to perform a convolution at level @xmath15 and therefore @xmath27 computations in total for level @xmath15 of the transform . in principle , we may consider wavelets whose scale is comparable to the size of the data set , i.e. , @xmath28 where @xmath29 refers to the highest level of the transform . the number of computations for this level will be @xmath30 . since @xmath31",
    "the complexity of the transform will be @xmath32 .",
    "the is an efficient scheme for performing discrete wavelet transforms .",
    "the algorithm assumes a scaling parameter @xmath33 .",
    "wavelet coefficients are obtained recursively in that the wacs at level @xmath15 are calculated by taking an appropriate sum over wacs at level @xmath34 .",
    "thus , the number of computations necessary for the highest level of the transform is at most @xmath35 ( or more accurately , @xmath36 ) . since the algorithm is an example of the application of wavelets to mra ( mallat 1989a , 1989b ) we first interject a few general remarks about mra .",
    "consider a function @xmath2 sampled at a fixed regular interval @xmath37 .",
    "this highest resolution sample of @xmath10 , which we refer to as @xmath38 , is constructed by convolving @xmath10 with a window function @xmath39 :    f_0,i = _ j ( x_i - x_j)f(x_j )  .",
    "( the second subscript on @xmath38 refers to position , i.e. , @xmath40 , etc . ) .",
    "smoother representations of @xmath10 can be constructed with filters @xmath41 that are dilated versions of @xmath39 :    f_n , i = _ j _ n(x_i - x_j)f(x_j )    where    _ n ( x ) = ( )  .",
    "for this reason , @xmath39 is referred to as the scaling function .",
    "the `` details '' @xmath42 of the signal correspond to the part of @xmath10 that is removed as one degrades the resolution from one level to the next .",
    "schematically , we have    f_0  =  w_1+w_2+ ",
    "w_n-1 + f_n    where @xmath43 is the lowest resolution version of @xmath10 and    w_n , i & & f_n-1,i - f_n , i + & = & _ j ( _ n-1(x_i - x_j ) - _ n(x_i - x_j ) ) f_x_j  .    comparing eqs . and",
    "we see that the mother wavelet can be calculated by a simple subtraction    \\(x ) = ( x)- ( )  .    for mra",
    ", we require that the scaling function satisfies the recursion relation    ( ) = _ j h_j ( x - x_j )    where @xmath44 are constants ( mallat 1989a , 1989b ; see , also kaiser 1994 ) .",
    "it is this equation that enables us to calculate the wacs recursively .",
    "the ( holschneider et al.1989 , dutilleux 1989 ) is an mra that has a number of attractive features .",
    "the algorithm is computationally efficient and easy to program .",
    "for example , reconstruction of the original function involves a simple sum over scale at each position . in three dimensions , the algorithm is approximately isotropic . finally ,",
    "the wavelet coefficients at each level are calculated for all points of the highest resolution ( interval @xmath19 ) grid and therefore the shapes and sizes of structures are well - determined . by contrast , the original mra developed by mallat ( 1989a , 1989b ) is computationally intensive , the reconstruction formula is complicated , and the transform in 2 or more dimensions is not isotropic .",
    "moreover , wavelet coefficients are calculated on a decimated grid ( in going from level @xmath15 to level @xmath45 the number of wavelet coefficients is reduced by a factor of 2 in one dimension or 8 in three dimensions ) and therefore the representation of larger structures becomes rather crude .",
    "a detailed comparison of mallat s mra and the can be found in shensa ( 1992 ) .",
    "following lega et al.(1995 ) , we choose the scaling function to be the cubic b - spline :    ( x)= ( |x-2|^3 - 4|x-1|^3 + 6|x|^3 - 4|x+1|^3+|x+2|^3 )    where distances are measured in units of @xmath19 .",
    "note that @xmath46 for @xmath47 .",
    "the recursion formula , eq .",
    ", takes the form    ( ) = _",
    "j=-2 ^ 2 c_2-j^4(x - x_j )    where @xmath48 are the usual binomial coefficients .",
    ". can be verified by a straightforward but tedious calculation .",
    "the mother wavelet , calculated from eq . and shown in figure 1 , is similar to the popular mexican hat wavelet ( the laplacian of a gaussian ) .",
    "explicit formulae used in the calculation of the wavelet coefficients are given in appendix a.    as discussed above , @xmath49 .",
    "in addition , the first moment of @xmath9 also vanishes : @xmath50 .",
    "it follows that the leading contribution to the wavelet transform of @xmath2 is from terms quadratic in @xmath51 : the wavelet transform is evidently unaffected by a constant or linearly varying background .",
    "it is this property of the wavelet transform that makes it ideal for identifying structures in cosmological simulations .    in three dimensions ,",
    "the wavelet is constructed from the scaling function @xmath52 , assumed to be separable in cartesian coordinates :    ( * r*)(x)(y)(z )  .",
    "once again , explicit formulae for the wacs are given in appendix a. the wavelets constructed in this manner are quasi - isotropic , i.e. , the profile of the mother wavelet depends on the direction in space , though it is the same along any three mutually orthogonal directions .",
    "moreover , the differences along non - orthogonal directions are relatively minor as can be seen in figure 1 where we compare the profile of the wavelet along one of the three original axes with that along one of the diagonals @xmath53 .",
    "the first step in applying the to an n - body simulation is to discretize the density field by approximating the density at each point of a three - dimensional cartesian grid .",
    "we use the nearest - grid - point scheme frequently employed in particle - mesh simulations ( hockney & eastwood 1988 ) .",
    "simply put , the density at a particular grid point is given by the sum of the masses of all particles within a cell centered on that point divided by the volume of the cell .",
    "for the analysis presented in this paper was use a grid @xmath54 in size , the maximum one allowed given memory constraints of the available computers . the number of grid points is roughly a factor of four greater than the number of particles in the simulation and therefore we do not expect that a finer mesh will lead to an improvement in the results . indeed , the highest resolution wavelets are able to pick out associations of very small numbers of particles .",
    "the @xmath21 wavelet has a width of approximately five cells .",
    "thus , only wavelets up to @xmath55 ( 80 cells across ) fit into our grid .",
    "the @xmath55 level essentially provides a map of the gross features of the halo and therefore useful information on subhalos is contained in levels @xmath56 .    with the discretized representation of the density field in hand",
    ", the wacs can be calculated according to the formulae in appendix a.      the multiresolution analysis described above provides a complete description of the ( discretized ) density field obtained in an n - body simulation .",
    "the next step in the analysis is to develop a prescription for identifying physical structures . for this step , we take , as a working definition of structure , an association of particles in space that is unlikely to have occurred by chance .",
    "this definition includes both gravitationally bound clumps and the debris of systems that have been tidally disrupted by the parent halo . in the next section , we describe how one can distinguish between these two possibilities .    in the wavelet description ,",
    "structures are identified as connected regions where the wacs rise above a predetermined threshold .",
    "the introduction of a user - supplied threshold is a feature common to all clump - detection algorithms .",
    "for example , in the fof algorithm , the threshold corresponds to the linking parameter . in an mra",
    ", a different threshold is chosen for each level in the analysis .",
    "following lega et al.(1995 ) we calculate the wavelet transform for a random distribution of particles where the number of particles and `` simulation volume '' are chosen to be the same as in the actual simulation to be analyzed . at each level , the threshold is chosen to be five times the rms value of the wavelet coefficients .    at first glance ,",
    "the @xmath57 threshold would seem to eliminate virtually all chance associations of particles .",
    "however , the statistical fluctuations in the particle number are different in a highly nonuniform halo simulation than in a random distribution .",
    "indeed , the wavelet transform maps not only substructure but also the large scale structure of the main halo . in any case ,",
    "application of a @xmath57 threshold is just the first step in producing a catalog of substructures : dynamical information is also used to remove unbound ( supposedly chance ) associations of particles . in the next section we present results for different choices of the threshold which demonstrate that the algorithm , taken as a whole , is relatively robust .",
    "the thresholding procedure leads to a binary representation of the wavelet transform with a value @xmath58 ( @xmath59 ) assigned to gridpoints where the wac is above ( below ) the threshold .",
    "the next step it to identify individual structures .",
    "initially , lists of structures ( connected region of above - threshold wacs ) are generated for each level in the transform .",
    "these structures are identified by a method known as segmentation analysis ( rosenfeld 1969 ; lega et al.1995 ) , the details of which are presented in appendix b.    typically , the larger structures in a simulation lead to significant wacs at multiple levels in the transform .",
    "the spherically averaged radial density profiles for halos and subhalos are well - approximated by piecewise power - law functions of radius .",
    "therefore no single scale can characterize a halo .",
    "the upshot is that the combined list of structures from all levels of a transform will contain numerous redundancies .",
    "for example , a single smooth subhalo ( i.e. , one devoid of substructure ) that is identified at the @xmath60 level will almost certainly also be represented by entries in the @xmath61 and @xmath62 levels .",
    "these unwanted redundances are eliminated as follows : for a given structure identified at the top level of the transform ( @xmath60 for the case at hand ) , we remove a single entry , namely the one closest to the center of the @xmath60 structure , from each of the lists of structures at the lower levels .",
    "the procedure is repeated for the @xmath63 and @xmath64 lists .",
    "the end result is an _ irreducible _ list of subhalos and sub - subhalos where each distinct object is represented by one and only one entry .",
    "the final list of objects will contain not only gravitationally bound systems but also unbound associations of particles ( e.g. , tidal streams ) and density enhancements that occur because of fluctuations in the particle distribution .",
    "dynamical information enables us to distinguish among these possibilities .",
    "our prescription for identifying bound systems is described in section 4 .",
    "our substructure - finding algorithm is applied to the n - body simulations of cluster - sized halos that appeared in dubinski ( 1996 ) and ghigna et al.(1998 ) .",
    "these simulations were performed using parallelized versions of the barnes - hut treecode ( barnes & hut 1986 ) . in each case , the main halo exhibits a high degree of substructure with hundreds of subhalos .    in what follows",
    ", we describe the results from our analysis of the gigna et al.(1998 ) simulation ( figure 2 ) . a more extensive discussion of these results as well as the results for the dubinski ( 1996 ) simulation can be found in seymour ( 2000 ) . in the gigna et al.(1998 )",
    "simulation , the virial radius of the main halo is @xmath65 .",
    "there are approximately @xmath66 particles inside this radius corresponding to a mass of @xmath67 .",
    "we begin by constructing a @xmath54 pixelized map of the density field .",
    "the dwt for levels @xmath56 are then calculated using the formulae in appendix a. two - dimensional projections of the wavelet coefficients , constructed by selecting the maximum wavelet coefficient along each ` line - of - sight ' , are shown in figure 3 .",
    "this figure illustrates the manner in which substructure on different scales is captured in the different levels of the dwt .",
    "note that the central object and many of the larger satellites register strong signals in all four levels illustrating the way in which the dwt captures the internal structure of these systems .",
    "the results of the segmentation analysis are shown in figure 4 where circles , superimposed on the projected particle distribution , are drawn for the structures detected at each level .",
    "the radii of the circles corresponds to the size of the region found to be above threshold ( i.e. , proportional to the cube root of the number of pixels above threshold ) .",
    "the fact that most of the large subhalos are detected in multiple levels in the transform is reflected in the appearance of concentric circles . when this redundancy is removed ( see section 2.3 ) 773 , 223 , 72 , and 5 subhalos remain in levels @xmath68 respectively .",
    "the mra described above identifies structures in the density field but does not distinguish between particles that are members of a subhalo and interlopers , i.e. , particles that are passing through the subhalo but are not associated with it in any true dynamical sense .",
    "in addition , some of the structures that we have identified are extremely small and may in fact be chance associations that arise from poisson fluctuations in the density field .",
    "dynamical information makes it possible to eliminate interlopers and also cull the list of structures of unbound particle groups .",
    "the standard working definition for a bound structure in an n - body simulation is `` the largest set of particles that are _ mutually _ gravitationally bound '' ( see , for example , bertschinger & gelb 1991 ; gigna et al 1998 ) . with this definition ,",
    "the procedure for identifying bound structures given the results of our wavelet and segmentation analysis is as follows : ( 1 ) for each entry in our list of structures , calculate its radius and center - of - mass . for the radius ,",
    "we take @xmath69 where @xmath25 is the number of cells associated with the structure , i.e. , connected cells with wacs above the threshold . likewise",
    ", the center - of - mass is calculated from the wacs that rise above the threshold .",
    "( 2 ) next calculate the total energy ( kinetic plus potential ) for each particle within a distance @xmath70 from the structure s center of mass .",
    "note that the kinetic energy is calculated in the rest frame of the particles .",
    "( 3 ) the highest energy particle is identified and if its energy is greater than zero , it is removed .",
    "one then returns to steps ( 2 ) and ( 3 ) with the proviso that in calculating the potential energy and center of mass frame , only the remaining particles are used .",
    "the procedure is repeated until the highest energy particle that remains has negative energy .",
    "in excluding unbound particles when calculating the gravitational potential , one underestimates the ( negative ) potential energy of the remaining particles and may therefore inadvertently remove bound particles from a subhalo .",
    "an alternative procedure is to recalculate the center - of - mass velocity but _ not _ the potential energies each time an unbound particle is removed . in this way , all of the particles in the neighborhood of the clump contribute to the gravitational potential , as they should !",
    "figure 5 shows an example of a subhalo that is identified as a bound system by the second method ( interlopers included in the potential ) but rejected by the first method ( i.e. , no mutually gravitationally bound ( sub)system of particles was found ) .",
    "the spatial distribution of particles for the three cartesian projections are shown in figure 5a .",
    "note that only a small fraction of the particles ( 26 out of 532 ) are identified as being members of the gravitationally bound system thus explaining why , in this case , the background particles are so important . to check that we have indeed found a bona fide structure , we show , in figure 5b , the velocity space distribution of particles .",
    "the bound clump forms a tight group in velocity space : their velocity dispersion is much smaller than that of all of the particles in this region ( @xmath71 ) .",
    "we can estimate , from poisson statistics , the probability that such a velocity space clump will occur by chance .",
    "the probability of finding a single particle in the velocity - space region of the clump is @xmath72 and thus the probability of finding @xmath73 particles out of @xmath74 in this region is @xmath75 where @xmath76 .",
    "thus , the probability of finding @xmath77 out of @xmath78 particles with velocity dispersion @xmath79 in _ any _ region of velocity space is    p =  .    in the example of figure 5 , @xmath80 .    for many of the systems found by the second method ,",
    "the case that they are bona fide bound structures is not nearly so strong . in particular , for dense regions of the halo , it is not so unlikely to find , by chance , small groups of particles that appear to be bound . thus , we need some additional set of criteria to further cull , from the list of structures , chance associations of particles . the criteria we choose are as follows : for each bound system we calculate the probability @xmath81 as above and also the fraction of local particles @xmath82 that are found to be part of the bound system .",
    "a bound clump is deemed to be genuine if either @xmath83 or @xmath84 .",
    "the first condition applies to bound systems moving through dense regions of the halo ( as in figure 5 ) while the second condition applies to relatively isolated systems in which @xmath85 and @xmath86 .",
    "our criteria are somewhat arbitrary and other choices are possible . for example ,",
    "gigna et al.(1998 ) only consider groups of 16 or more particles .",
    "this particle number cutoff may be overly conservative as our algorithm identifies numerous systems of fewer than 16 particles that are clearly clustered in both velocity and configuration space .",
    "nevertheless , our results at the low - mass end of the subhalo distribution may be suspect . clearly , the relevant numerical experiment is to run a set of simulations with idential initial conditions but with different numbers of particles .",
    "the results for both methods of finding bound clumps are summarized in table 1 . with method 1 ,",
    "nearly three quarters of the level 1 structures and over one half of the level 2 structures are removed as being `` unbound '' while with method two , less than half of the level 1 structures and less than one third of the level two structures are removed .",
    "the additional constraint eliminates ( as potentially being chance associations ) an additional 100 level 1 structures .",
    "ccccc + @xmath15 & @xmath87 & @xmath88 & @xmath89 & @xmath90 + 1 & 773 & 177 & 433 & 328 + 2 & 223 & 119 & 158 & 158 + 3 & 72 & 72 & 72 & 72 + 4 & 5 & 5 & 5 & 5",
    "+    we have repeated the procedure outlined above using both @xmath91 and @xmath92 thresholds and the results are shown in tables 2 and 3 . as expected , the number of structures identified by our wavelet and segmentation analysis using a @xmath91 threshold is higher than the number identified with a @xmath57 threshold and likewise the number identified using a @xmath92 threshold is lower",
    ". however , the unbinding procedure seems to identify the greatest number of structures when a @xmath57 threshold is used .",
    "the unbinding procedure begins with a region specified by the segmentation analysis where it can search for a bound object .",
    "if the region is much larger than the clump , and the clump center - of - mass velocity is much different from the center - of - mass velocity of the background , the unbinding procedure may miss the clump altogether .",
    "these results illustrate a truism common to all substructure - finding algorithms : on an object by object basis near the mass resolution of the simulation subhalo identification is often ambiguous .",
    "that is , one is likely to miss some bound clumps while including , in the catalog of structures , some chance associations .",
    "however , as we demonstrate below , the statistical properties of the subhalo population ( namely fraction of main halo in bound clumps ) appears to be insensitive to the choice of threshold .",
    "ccccc + @xmath15 & @xmath87 & @xmath89 & @xmath90 + 1 & 820 & 335 & 244 + 2 & 212 & 200 & 187 + 3 & 77 & 77 & 77 + 4 & 10 & 10 & 10 +    ccccc + @xmath15 & @xmath87 & @xmath89 & @xmath90 + 1 & 439 & 313 & 240 + 2 & 134 & 134 & 134 + 3 & 63 & 63 & 63 + 4 & 3 & 3 & 3 +    we conclude this section by considering a region of the simulation @xmath93 on a side ( @xmath94 of the simulation volume ) centered on a large subhalo that has been detected at level 4 of the dwt .",
    "the upper left panel of figure 6a displays all of the particles in this region while the upper right panel displays only those particles gravitationally bound to the main subhalo .",
    "we have also identified twelve smaller subhalos within the region defined by the main subhalo .",
    "these are shown in the lower left and lower right panels ( levels 2 and 1 of the analysis respectively ) .",
    "( many of the clumps that appear in the upper left panel are in the foreground or background of the main subhalo and therefore are not shown . )",
    "one of these small subhalos , indicated by the arrow , is gravitationally bound to the main subhalo .",
    "in addition , a second subhalo appears to be associated dynamically with the main subhalo .",
    "the remaining ten subhalos are interlopers as is evident from figure 6b where the 12 small subhalos are plotted in velocity space .",
    "the circle represents the velocity dispersion of the large subhalo .",
    "note that the relative velocities of the subclumps are typically much higher than their internal velocities .",
    "the gravitationally bound subhalo is an example of a third level of substructure in that its constituents can be regarded as members of three distinct systems .",
    "examples of this type are rare , a result that is not surprising given that the systems which constitute the second level of substructure ( the large subhalos orbiting the main halo ) are consist of only a few thousand particles and therefore subject to the purely numerical overmerging problem .",
    "our subhalo detection algorithm has identified over 500 subhalos and it is therefore possible to study , in a statistical sense , their characteristics . in figure 7 , for example , the rms internal velocity dispersion of the clumps are plotted as a function of their position within the main halo . as noted in ghigna et al.1998 , a wide range of clump velocities are found throughout the main halo though there does appear to be a trend toward larger internal velocities for subclumps closer to the center of the main halo .",
    "this result may be an indication that subhalos are heated by the tidal field of the main halo .",
    "in addition , there appears to be a slight enhancement of subclumps with large rms velocities at @xmath95 .",
    "these subhalos are probably associated with the large subhalo evident in figure 2 at @xmath96 . in figure 8 , the masses of the subhalos ( shown in terms of particle number ) are plotted as a function of rms velocity .",
    "one finds a reasonably tight correlation between @xmath97 and @xmath98 with @xmath99 where @xmath100 .",
    "the correlation appears to hold over nearly 3 orders of magnitude in mass .",
    "this result is to be compared with ghigna et al.1998 ( see their figure 20 ) who find @xmath101 over approximately two orders of magnitude in mass .    in figure 8 , there appears to be a distinct population of objects that have , for fixed mass , velocities a factor of 3 - 5 greater than those in the main distribution .",
    "these objects are found preferentially in the inner regions of the main halo once again suggesting that they are heated by the tidal fields of the main halo .",
    "this result brings us to figure 9 where we plot the virial ratio , @xmath102 as a function of position in the main halo . @xmath103 and @xmath104 are respectively the total kinetic and potential energies of the bound system .",
    "@xmath103 is simply the sum of the kinetic energies of the particles in the system .",
    "calculation of @xmath104 is somewhat more involved since a sum of the potential energies of the individual bound particles double counts for pairs of bound particles .",
    "the formula for @xmath104 is :    w = -_i\\{b } ( _ j\\{b};ji + _ j\\{u } )    where @xmath105 and @xmath106 refer respectively to the sets of bound and unbound particles or interlopers .",
    "the population of subhalos exhibit a large scatter in the virial ratio about the equilibrium value of @xmath58 .",
    "this result implies that the halos are , for the most part , not fully virialized , perhaps because that are constantly being disturbed ( if not disrupted ) by the tidal field of the main halo .",
    "indeed , there appears to be a trend toward a larger dispersion in the virial ratio toward the center of the main halo .    finally , in figure 10",
    ", we plot the fraction of the virial mass contained in subhalos of a given size . we find that in total , @xmath107 of the halo is bound in subhalos in good agreement with results from gigna et al.(1998 ) .",
    "the figure includes results for different choices of the threshold .",
    "the fact that the results do not change much is an indication of the robust nature of the algorithm .",
    "recent advances in numerical cosmology lead to the conclusion that the more particles one uses in an n - body simulation , the more substructure one finds in dark matter halos .",
    "this result is consistent with the picture that halos form through hierarchical clustering since an increase in the number of simulation particles translates into an increase in the dynamic range of the hierarchy accessible to the simulation .",
    "what is perhaps surprising is the extent to which substructure survives .",
    "the identification of substructure inside dark matter halos is a nontrivial task .",
    "while large subhalos are easily located by eye , small subsystems , and especially ones inside dense regions of the halo , can be difficult to spot .",
    "moreover , there can be many levels of substructure .",
    "the substructure - finding algorithm presented in this paper is intrinsically hierarchical and therefore perfectly suited to the task at hand .",
    "the dwt analyzes the density field at different resolutions while segmentation analysis produces a catalog of structures at each level of the transform .",
    "further analysis is required to eliminate redundances and cull the catalog of unbound systems .",
    "one advantage of a wavelet - based analysis is that it is insensitive to a constant or linearly varying background density .",
    "this feature makes it possible to pick out structures such as the one shown in figure 5 .",
    "note that the density enhancement for this structure is only @xmath108 . to pick such a structure out",
    "using fof would require an extremely finely tuned linking parameter .",
    "our results indicate that the mra algorithm is competitive with fof and denmax / skid , the two most widely used methods . in particular , our results for the number of subhalos found ,",
    "the fraction of mass in subhalos , and subhalo statistics are consistent with those of gigna et al.(1998 ) . a detailed comparison of the three methods for a sequence of simulations performed at increasing particle resolution is required to determine if there is any true advantage of one method over the others .",
    "in this appendix , we provide the details required to implement the . consider a one - dimensional function @xmath2 .",
    "the highest resolution sample of @xmath10 is constructed from eq . or equivalently    f_0,i = ( f(x_i-1)+ 4f(x_i)+f(x_i+1 ) )  .",
    "@xmath109 can be calculated from @xmath38 using eqs .",
    "and as follows :    f_1,i & = & _ j ( ) f(x_j ) + & = & _ j _ kc^4_2-k ( x_i - x_j - x_k)f(x_j ) + & = & _ kc^4_2-kf_0,i - k  .",
    "likewise , the coefficients corresponding to smoother samples of @xmath10 can be calculated recursively :    f_n , i = _ k c_2-k^4f_n-1,m    where @xmath110 .",
    "the wacs are calculated by a simple subtraction ( eq ..    next , we consider a three - dimensional density field @xmath111 . as in the one - dimensional case ,",
    "the first step is to compute the auxiliary coefficients , here written as @xmath112 .",
    "the @xmath113 coefficients are computed as follows :    c(1,i , j , k ) = _",
    "i,j,k=-2 ^ 2(i,j,k ) ( i-i ) ( j-j ) ( k-k )    where we abbreviate @xmath114 as @xmath14 .",
    "the @xmath115 coefficients are given by    c(n , i , j , k ) = _",
    "i,j,k=-2 ^ 2 h(i)h(j)h(k ) c(n-1,i - i2^n-1,j - j2^n-1,k - k2^n-1 )    where @xmath116 .",
    "finally , the wavelet coefficients are found by performing the subtraction    w(n , i , j , k ) = c(n , i , j , k)-c(n+1,i , j , k )",
    "this appendix provides an outline of the segmentation analysis routine used in the paper .",
    "further details can be found in rosenfeld ( 1969 ) and lega et al.(1995 ) .",
    "the algorithm is introduced by way of a worked example in two spatial dimensions .",
    "the extension to three dimensions is straightforward .",
    "figure 11a presents the results for a single level of a mock wavelet transform of a two - dimensional density field .",
    "the number in each cell represents the wac ( for convenience , rounded off to the nearest whole number ) .",
    "application of a threshold between 4 and 5 leads to figure 11b .",
    "the core of the segmentation algorithm is the _",
    "scan_. the scan identifies connected segments of non - zero elements along each of the two ( or three , for the actual data ) cartesian directions . starting in upper left corner of the data array , the first scan proceeds along rows successively from top to bottom labelling each segment of @xmath117 by a unique integer .",
    "the result of the left - to - right scan is shown in figure 11c .",
    "next , one scans from top to bottom along successive columns . in this scan",
    "one assigns the lowest integer contained in each segment .",
    "the result is shown in figure 11d .",
    "for a three - dimensional data set , there is an additional to be performed .    iterating the above procedure ( i.e. , alternating between horizontal and vertical scans ) will eventually yield the desired result : a unique label for each connected structure .",
    "however , for large data sets and odd - shaped structures , the computation time can become prohibitively long . for a data set containing @xmath118 elements , each scan takes @xmath30 operations ( @xmath24 operations along each row times @xmath24 columns or vice versa ) .",
    "one can imagine particularly perverse examples ( for example , staircase - like structures ) in which one requires @xmath30 scans , in other words , @xmath119 computations . in three dimensions , one could in principle require @xmath120 computations which is unreasonable for even modest values of @xmath24 .",
    "one can obviate the need for repeated scans by means of the following scheme .",
    "the scan is performed once in each of the cartesian directions . by virture of the scanning process",
    ", each cluster of connected segments is described by a unique set of integers .",
    "that is , no cluster of connected segments contains values of another cluster . in our example , the cluster on the left contains values @xmath121 and @xmath122 while the cluster on the right contains values @xmath123 and @xmath124 .",
    "our goal is to group together the integers represented in each cluster .",
    "this step is accomplished by first constructing a dictionary as follows : for each non - zero element in the array , check all non - zero neighboring elements and list the element and its neighbor if they are different .",
    "note that the last direction scanned ( in our example , the vertical direction ) need not be check since all non - zero neighbors are necessarily the same . the dictionary is then pruned for duplicates ( figure 12a ) .    the remaining step is to sort the dictionary into connected pairs .",
    "first , one picks out pairs that have the same number in either the first or second position .",
    "the sort for the cluster on the left of our data is shown in figure 12b .",
    "we then relabel the second digit of those pairs selected by the sort ( figure 12c ) .",
    "the group is then pruned to eliminate redundancy ( figure 12d ) to yield a table that identifies all of the integers for cluster 1 with the single integer 4 .",
    "figure 12e shows the result when the remaining dictionary is sorted ."
  ],
  "abstract_text": [
    "<S> multiresolution analysis is applied to the problem of halo identification in cosmological n - body simulations . </S>",
    "<S> the procedure makes use of a discrete wavelet transform known as the and segmentation analysis . </S>",
    "<S> it has the ability to find subhalos in the dense regions of a parent halo and can discern the multiple levels of substructure expected in the hierarchical clustering scenario . as an illustration , a 500,000 particle dark matter halo is analyzed and over 600 subhalos are found . </S>",
    "<S> statistical properties of the subhalo population are discussed . </S>"
  ]
}