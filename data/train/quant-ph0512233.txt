{
  "article_text": [
    "consider the schematic representation of an experiment in which a source emits objects that carry information represented by an angle @xmath0 ( see fig .  [ machine0 ] ) .",
    "we want to determine this angle as accurately as possible , but there are some limitations on the equipment that is available to us , namely :    .",
    "the processor combines this message with the angle @xmath1 that is controlled by the user , and sends the object through one of its two output channels .",
    "detectors count the number of objects in each channel .",
    ", width=302 ]    * we do not have a device that can measure the angle @xmath2 directly .",
    "* we have detectors that can count the arrival ( or passage ) of individual objects .",
    "* we can build a device , called processor in what follows , that can direct an incoming object to one of its two output channels according to @xmath2 , relative to the orientation @xmath3 of the processor itself . we can count the number of objects in each output channel by using the detectors . * we do not have prior information about the angle @xmath2 itself , implying that there is no reason to assume that particular angles @xmath2 are more likely to occur than others .",
    "note that this does not imply that @xmath2 is a random variable .    given this scenario ,",
    "the obvious question is : what kind of functionality should we build into the processor such that by counting @xmath4 events in the output channels , we obtain an accurate estimate for the angle @xmath2 ?",
    "of course , the optimal design of the processor depends on additional constraints .",
    "usually , we prefer devices of which the output does not change drastically when the input varies a little .",
    "therefore we require that    1 .",
    "the number of events generated in each output channel is most insensitive to small changes in @xmath5 .",
    "2 .   the performance of the processor should be insensitive to the actual value of @xmath6 .    using these two criteria , we consider two extreme realizations of the processor .",
    "first , we construct a simple probabilistic processor that operates according to the rules of probability theory and uses random numbers to transform the input data @xmath2 into a sequence of discrete output events .",
    "then , we present a strictly deterministic processor that performs the same task as the simple probabilistic processor . in both cases , the general strategy to determine",
    "the optimal processor is the same : we search for a probabilistic or deterministic process that satisfies the criteria ( 1 ) and ( 2 ) mentioned earlier .",
    "then we estimate the efficiency of the processor .",
    "as convenient measure for the efficiency ( or performance ) of a processor , we take the number of different messages @xmath7 that can be extracted from a record of @xmath4 bits , each bit representing an event in one of the two output channels , with a specified level of certainty .",
    "the reader may have noticed that the scenario we described earlier applies to the measurement of the polarization of light in the regime where the signal from the detectors consists of discrete `` clicks ''  @xcite . in this case , the objects are represented by photons , the angle @xmath2 describes the polarization ( which we can not measure directly ) , the detectors may be photon multiplier tubes or semiconductor diodes , and the processor a properly prepared calcite crystal  @xcite .",
    "in general terms , we want to characterize the behavior of a system in terms of numerical quantities that we can obtain by repeating measurements that give us partial information only .",
    "this is a characteristic feature of quantum mechanics . in order not to become entangled in the difficulties with the interpretation of quantum theory and the measurement paradox in particular  @xcite , in the theoretical analysis presented in this paper , we avoid the use of words such as photons and polarization .",
    "a remarkable result of this paper is that the search for an efficient ( in the sense specified earlier ) , data processor yields probabilistic and deterministic processors that generate output events according to malus law .",
    "[ sec2 ]    the schematic diagram of the probabilistic processor is shown in fig .",
    "[ machine1 ] .",
    "the input to the processor is an event that carries a message represented by the angle @xmath2 .",
    "the presence of an event in one of the output channels is represented by a message that carries the variable @xmath8 .",
    "we assume that the experimental data is in concert with the hypothesis of rotational invariance .",
    "that is , the number of events in the @xmath9 and @xmath10 channels only depend on the difference @xmath11 between the ( unknown ) angle @xmath2 and the orientation of the device @xmath3 .",
    "furthermore , the number of output events should be periodic in @xmath6 with a period of @xmath12  @xcite .",
    "let the probability @xmath13 describe the process that transforms each input event into an output event @xmath8 . by symmetry",
    "we have @xmath14 and if we assume that each input event generates exactly one output event we have @xmath15 we also assume that there is no logical dependence between two output events @xmath16 and @xmath17 , that is @xmath18 for all @xmath19 .",
    "this implies that the correlation between the output events is zero .",
    "then , this process generates bernoulli trials  @xcite .    under these conditions ,",
    "all information about the polarization is encoded in the measurable quantity @xmath20 from eq .",
    "( [ stoc2 ] ) it is clear that we can completely characterize the process by @xmath21 .     and the setting @xmath1 into a sequence of @xmath8 signals .",
    ", width=340 ]    our task is to design the processor , that is to determine the function @xmath22 , such that a measurement of @xmath23 gives us as much as possible knowledge about the unknown angle @xmath2 .",
    "let us consider the data as collected by an observer who decides to record and analyze data sets of @xmath4 objects each .",
    "we assume that @xmath24 is fixed during this measurement .",
    "each data set looks like @xmath25 where @xmath26 for @xmath27 .",
    "let us assume that the number of @xmath28 events in a particular data set is @xmath29 .",
    "recall that the processor generates bernoulli trials  @xcite .",
    "therefore , the probability for observing this data set is given by  @xcite",
    "@xmath30^{n - n } .",
    "\\label{stoc4}\\ ] ] for convenience of the reader , we first recall some well known facts of probability theory  @xcite . from eq.([stoc4 ] ) it follows that , as a function of @xmath31 , @xmath32 reaches its maximum @xmath33 at @xmath34 .",
    "a simple calculation shows that @xmath35 . \\label{stoc5}\\ ] ] for small values of @xmath36 , the taylor series expansion of the left hand side of eq.([stoc5 ] ) yields @xmath37 \\nonumber\\\\ & + & \\order{(p(\\psiphi)-\\hat p(\\psiphi))^4 } , \\label{stoc6}\\end{aligned}\\ ] ] showing that as a function of @xmath31 , @xmath32 vanishes exponentially fast with @xmath4 , unless @xmath38  @xcite .",
    "therefore , from the point of view of the observer , the procedure is simple : as the observer knows ( the yet unknown ) function @xmath31 , after measuring a data set @xmath25 , the observer finds @xmath6 by solving @xmath39 .",
    "the total number @xmath29 of @xmath28 events contains all the available information about the difference @xmath11 .",
    "a rough estimate for the number of distinguishable messages @xmath7 that the probabilistic processor can encode with an error of approximately one percent can be obtained as follows .",
    "first , we use eq .",
    "( [ stoc4 ] ) to calculate the variance on @xmath29 and find that @xmath40 . for sufficiently large but fixed @xmath4 , the probability distribution eq .",
    "( [ stoc4 ] ) tends to the normal ( gaussian ) distribution with mean @xmath41 and variance @xmath42 .",
    "therefore , the probability to observe @xmath43 ( @xmath44 ) instead of @xmath29 ( @xmath45 ) @xmath28 events is approximately given by @xmath46 .",
    "\\label{stoc6a}\\end{aligned}\\ ] ] from the properties of the normal distribution , it follows that the probability for the observed number @xmath43 of @xmath28 events to lie in the interval @xmath47 $ ] is larger than @xmath48 .",
    "thus , the number of messages @xmath7 that can be encoded with a probability of error that is less that one percent is given by @xmath49 although this is a rough estimate , the result that the number of distinguishable messages is of the order of @xmath50 is to be expected on general grounds , given the constraint that the processor generates probabilistic , bernoulli - like events .",
    "we now apply the criteria 1 and 2 of section  [ sec1 ] to optimize the design , that is we want to determine @xmath22 by which the probabilistic ( bernoulli ) processor will generate the output events . in the foregoing analysis",
    ", we assumed that @xmath24 was fixed during the observation of @xmath4 events .",
    "clearly , this is not a realistic assumption . in a real experiment",
    ", @xmath1 or @xmath2 fluctuates .",
    "therefore , the best we can do is search for the probability @xmath31 that is least sensitive to small changes in @xmath51 .",
    "this is criterion 1 of section  [ sec1 ] .",
    "we determine this probability by considering the likelihood that the observed sequence of @xmath52 s was generated by @xmath53 instead of @xmath54 where @xmath55 is a small positive number .",
    "the larger this likelihood , the larger the probability that the observer draws the wrong conclusion from the data .",
    "the log - likelihood @xmath56 that the data was generated by @xmath53 instead of by @xmath54 is given by  @xcite @xmath57 according to criterion 1 of section  [ sec1 ] , we have to find the probability @xmath31 that minimizes @xmath58 .",
    "we first consider the case that @xmath59 .",
    "then , because @xmath32 is not the maximum , we assign @xmath60 as the most likely guess .",
    "a taylor series expansion of eq .",
    "( [ stoc5a ] ) yields @xmath61 second , we consider the case that @xmath62 . now",
    ", adopting the same reasoning as used previously , the observer assigns @xmath63 and the taylor series expansion of eq .",
    "( [ stoc5a ] ) yields @xmath64 as @xmath55 was arbitrary ( but small ) , minimization of @xmath58 is equivalent to minimizing the fisher information  @xcite @xmath65 for this particular problem .",
    "thus , we conclude that the first criterion tells us that we should minimize the fisher information @xmath66 . substituting @xmath67",
    "we obtain @xmath68 ^ 2 .",
    "\\label{stoc10}\\ ] ]    criterion 2 of section  [ sec1 ] stipulates that the reliability of the procedure to extract @xmath69 from the observed sequence of @xmath52 s should not depend on @xmath69 .",
    "we can realize this by choosing @xmath70 .",
    "using the side information that @xmath71 we find that @xmath72 and @xmath73 for @xmath74 ( @xmath75 is excluded because then @xmath31 does not depend on @xmath24 and the design leads to a useless device ) .",
    "clearly @xmath66 is minimal if @xmath76 and we may absorb the irrelevant phase factor @xmath77 in @xmath1 .    in summary , using the two design criteria of section  [ sec1 ] , we find that for optimal operation ( from the point of view of the observer ) , the processor should use the probabilities @xmath78 to generate the @xmath79 and @xmath80 events , respectively .",
    "put differently , for a fixed processor setting @xmath1 and @xmath4 incoming events with message @xmath2 , the observer will ( in general ) get most out of the data if the processor sends @xmath81 ( @xmath82 ) events to the apparatus that detects the @xmath80 ( @xmath79 ) event . the maximum number @xmath7 of angles @xmath69 we can distinguish is given by @xmath83 where @xmath84 depends on the number of mistakes in determining @xmath69 that we find acceptable .",
    "the larger @xmath84 , the larger is the probability that the result for @xmath69 is erroneous .    obviously , it is easy to simulate this processor on a computer .",
    "for each of the @xmath27 input events , we generate a uniform random number @xmath85 and send out a @xmath28 ( @xmath86 ) event if @xmath87 ( @xmath88 ) .",
    "after processing @xmath4 events , we compute @xmath89 from @xmath90 .",
    "[ sec3a ]    up to this point , there is no relation between the mathematical model that we have analyzed and a physical system .",
    "however , from the description of the scenario and the final result eq .",
    "( [ stoc12 ] ) , it is obvious that a processor that operates according to eq .",
    "( [ stoc12 ] ) is a model for an ideal polarizer .",
    "we now discuss the relation between the optimal probabilistic processor and the measurement of the polarization of photons in more detail .    in classical electrodynamics",
    ", it is well known that the intensity of light transmitted by a polarizer ( such as nicol prism ) is given by malus law @xmath91 where @xmath92 , @xmath93 , and @xmath94 are the intensities of the incident light , the ordinary and extraordinary ray , respectively , @xmath2 is the polarization of the incident light and @xmath1 specifies the orientation of the polarizer  @xcite . from a quantum mechanical point of view , the total energy @xmath95 of a light wave of frequency @xmath96 must be an integer multiple of @xmath97 ( planck s constant ) , that is @xmath98 , where @xmath29 is the number of photons in the wave .",
    "the polarizer splits the incoming beam in two beams .",
    "depending on the type of polarizer , the light in one of the beams is absorbed  @xcite but this is irrelevant for the discussion that follows . in any case , the number of photons in each beam is an integer ( by definition of the concept of a photon , there is no such thing as a half photon ) .",
    "if the number of photons in the incident beam is very large , the mean number of photons that goes into each beam should correspond to the intensity that we find from classical electrodynamics . in the regime",
    "where the photons are detected one - by - one , quantum mechanics postulates that the polarizer sends a photon to the ( extra)ordinary direction with probability ( @xmath99 ) @xmath100  @xcite .    the probabilistic processor that we have described transforms a beam of photons into yes / no events that we can count .",
    "if we require the answers of the transformation process to be probabilistic ( bernoulli trials ) , rotational invariant ( a basic property of ( quantum ) electrodynamics ) , and to satisfy criteria 1 and 2 of section  [ sec1 ] , then the device that performs the transformation will produce data that agrees with malus law .",
    "we did not invoke any law of physics to obtain this result : malus law was recovered as the result of efficient data processing .",
    "this raises the interesting question whether other quantum phenomena also appear as the result of efficient data processing .",
    "the hypothesis that efficient processing of statistical information may be the reason why we observe quantum mechanical phenomena is very explicit in the work of frieden  @xcite , wootters  @xcite , and summhammer  @xcite .",
    "frieden has shown that one can recover all the fundamental equations of physics by finding the extrema of the fisher information plus the `` bound '' information  @xcite . according to frieden",
    ", the act of measurement elicits a physical law and quantum mechanics appears as the result of what frienden calls `` a smart measurement '' , a measurement that tries to make the best estimate  @xcite .",
    "although this approach is similar to ours , our line of reasoning is different .",
    "we do not invoke concepts from estimation theory , such as the estimators and the cramr - rao inequality ( see appendix a ) , nor do we require the concept of random noise .",
    "furthermore , in frieden s formulation , the parameters to be estimated ( such as the position ) are of the same kind as the measured quantities .",
    "this is not the case for the photon polarization that we treat here . in our approach ,",
    "the measuring apparatus ( such as the calcite crystal acting as a polarizer ) transforms the input ( the photon polarization ) into a signal ( @xmath8 ) that can be detected by human beings .",
    "the requirement that the simple probabilistic processor , that transforms the data , operates with optimal efficiency yields malus law .",
    "the fundamental difference between frienden s approach and ours becomes evident by noting that there is no reason why we should limit our search for efficient transformation devices to the most simple , bernoulli - type probabilistic machines . as we explain later",
    ", these machines can simulate the classical and quantum properties of a photon polarizer but are incapable of simulating interference phenomena .",
    "one possible route to solve this problem might be to generalize the probabilistic machine such that it no longer generates bernoulli events , that is allow for correlations between output events .",
    "we do nt follow this route .",
    "instead we consider the most extreme solution , namely a deterministic processor that performs the same task as the probabilistic machine under the conditions specified in section [ sec1 ] .",
    "this forces us to consider deterministic algorithms with primitive learning capabilities ( to allow for correlations between output events ) .",
    "elsewhere , we have shown that these deterministic processors ( and probabilistic versions thereof ) can be used to reproduce quantum interference phenomena  @xcite .",
    "we come back to this topic in section  [ sec5 ] .",
    "[ sec3 ]    from an engineering point of view , the probabilistic processor of section  [ sec2 ] is extremely simple and has a relatively poor performance .",
    "using @xmath4 bits , the probabilistic processor can encode @xmath101 distinguishable messages only .",
    "for example , as shown in section  [ sec2 ] , if we demand the level of certainty of 99.7% , then @xmath102 .",
    "it is not unreasonable to expect that a deterministic machine can do better in this respect .",
    "therefore , the obvious question is to ask if there exists a deterministic processor that generates events according to malus law .",
    "apart from being deterministic , this processor should satisfy the two criteria that we specified in section  [ sec1 ] .    adopting the terminology introduced in our earlier work  @xcite",
    ", we refer to the deterministic processor that we describe in this section as a deterministic learning machine ( dlm ) . for this machine , @xmath103 with nearly 100% certainty .    in this paper",
    ", we analyze a  that has one input channel , two output channels and one internal vector with two real entries . a  responds to an input event by choosing from all possible alternatives , the internal state that minimizes a cost function ( to be defined later ) that depends on the input and the internal state itself .",
    "then the  sends a message through one of its output channels .",
    "the message contains information about the decision the  took while it updated its internal state and , depending on the application , also contains other data that the  may have . by updating its internal state ,",
    "the   learns \" about the input it receives and by sending messages through one of its two output channels , it tells its environment about what it has learned .",
    "a  is a machine that performs real - time recurrent learning  @xcite .",
    "this section consists of three parts .",
    "first , we specify the algorithm that is used by a and we show that in the stationary regime , the number of @xmath79 ( @xmath80 ) events in a sequence of @xmath4 events is given by malus law , see eq .",
    "( [ stoc13 ] ) .",
    "then , we present a detailed mathematical analysis of the dynamic properties of a .",
    "the reader who is not interested in the intricacies of this classical dynamical system can skip section  [ sec4b ] .",
    "we end this section by comparing the performance of the probabilistic and deterministic processor .",
    "[ sec4a ]    the schematic diagram of the  is the same as that of the probabilistic processor of fig .",
    "[ machine1 ] , except that there is no probabilistic process @xmath104 .",
    "the  receives as input , a sequence of angles @xmath105 for @xmath106 and also knows about the orientation of the device through the angle @xmath1 . using rotational invariance ,",
    "we represent these input messages by unit vectors @xmath107 where @xmath108 and @xmath109 .",
    "the fact that eq .",
    "( [ ndimangle ] ) depends on the relative difference of the angles guarantees that the deterministic process is rotational invariant . instead of the random number generator that is part of the probabilistic processor ,",
    "the  has an internal degree of freedom that we represent by the unit vector @xmath110 .",
    "as the  receives input data , it updates its internal state . for all @xmath111 ,",
    "the update rules are defined by @xmath112 where @xmath113 ( @xmath114 ) corresponds to an @xmath79 ( @xmath80 ) output event , and @xmath115 is a parameter that controls the learning process of the .",
    "the requirement that the internal vector @xmath110 stays on the unit circle yields @xmath116 } \\nonumber \\\\ & -&\\alpha[x_{1,n}(1-\\theta_{n+1 } ) + x_{2,n}\\theta_{n+1 } ] .",
    "\\label{circ2}\\end{aligned}\\ ] ] substitution of eq .   in eq .",
    "gives us four different rules : @xmath117 where the first ( last ) two rules correspond to the choice @xmath113 ( @xmath118 ) and the @xmath119-sign takes care of the fact that for each choice of @xmath120 , the  has to decide between two quadrants .",
    "for later , it is important to note that @xmath121 and @xmath122 if @xmath113 . in other words , the angle of the internal vector relative to the @xmath123-axis decreases if we apply the @xmath113 rules .",
    "the  selects one of the four rules in eq .",
    "( [ circ3 ] ) by minimizing the cost function defined by @xmath124 obviously , the cost @xmath125 is small if the vectors @xmath126 and @xmath127 are close to each other . summarizing : a  minimizes the distance between the input vector and its internal vector by means of a simple , deterministic decision process .     representing the internal vector @xmath128 of the  defined by eqs .   and .",
    "bullets ( red ) : input events carry vectors @xmath129 . the initial value @xmath130 . for @xmath131",
    "the ratio of the number of increments ( @xmath118 ) to decrements ( @xmath113 ) is exactly 3/1 , which is @xmath132 .",
    "squares ( blue ) : input events carry vectors @xmath133 . the initial value @xmath134 . for @xmath135",
    "the ratio of the number of increments ( @xmath118 ) to decrements ( @xmath113 ) is exactly 1/3 , which is @xmath136 .",
    "the direction of the initial vectors @xmath137 is chosen at random . in this simulation @xmath138 .",
    "data for @xmath139 has been omitted to show the oscillating behavior more clearly .",
    "lines are guides to the eyes . , width=302 ]    ) events divided by the total number of events as a function of the value of the input variable @xmath24 .",
    "bullets : each data point is obtained from a simulation of 1000 events with a fixed , randomly chosen value of @xmath140 , using the last 500 events to count the number of ( @xmath118 ) events . solid line : @xmath141 .",
    ", width=302 ]    in general , the behavior of the  defined by rules eqs .   and is difficult to analyze without the use of a computer .",
    "however , for a fixed input vector @xmath142 , it is clear what the  will try to do : it will minimize the cost eq .   by rotating its internal vector @xmath126 to bring it as close as possible to @xmath143 .",
    "however , @xmath126 will not converge to a limiting value but instead it will keep oscillating about the input value @xmath143 .",
    "an example of a simulation is given in fig .",
    "in general , for a fixed input vector @xmath142 the  will reach a state in which its internal vector oscillates about @xmath143 .",
    "this is the stationary state of the machine . obviously , the whole process is deterministic .",
    "the details of the approach to the stationary state depend on the initial value of the internal vector @xmath144 , but the properties of the stationary state do not .",
    "[ station ]    the stationary - state analysis is a very useful tool to understand the behavior of the .",
    "let us assume that @xmath145 and that we have reached the stationary regime in which the internal vector performs small oscillations about @xmath146 ( as in fig .",
    "[ c60 ] ) . for simplicity , but without loss of generality , we limit the discussion that follows to @xmath147 . for @xmath113",
    "we substitute @xmath148 and @xmath149 in eq .",
    "( [ circ3 ] ) and obtain @xmath150 similarly , for @xmath118 we substitute @xmath148 and @xmath151 in eq .",
    "( [ circ3 ] ) and obtain @xmath152 in deriving eqs .",
    "( [ circ5b0 ] ) and  ( [ circ5b1 ] ) , we neglected terms of order @xmath153 and @xmath154 , respectively . rearranging eqs .",
    "( [ circ5b0 ] ) and  ( [ circ5b1 ] ) , and using @xmath155 gives @xmath156 in the stationary regime , the sum of all increments of @xmath157 should be compensated by the sum of all decrements of @xmath157 .",
    "therefore , we must have @xmath158 where @xmath159 ( @xmath160 ) is the number of @xmath113 ( @xmath118 ) events . from eq .",
    "it follows immediately that @xmath161 and hence @xmath162 fig .",
    "[ circle2 ] shows that the simulation results generated by the are in excellent agreement with the expressions obtained from this simple analysis .",
    "in fact , we will see later that in the stationary state , a  can encode exactly all angles for which @xmath163 where @xmath106 . from the definition of the  algorithm and eq .  , it is clear that the requirements of rotational invariance and insensitivity with respect to small changes in @xmath164 ( criterion 1 of section  [ sec1 ] ) are automatically satisfied . we emphasize that eq .",
    "is not put into the  algorithm but results from the learning process itself .    comparing eq .",
    "and eq .  , we conclude that once the  has reached a stationary state , the number of @xmath80 and @xmath79 output events in a sequence of @xmath165 events agrees with malus law . of course , the order in which the  generates the @xmath80 and @xmath79 is strictly deterministic .",
    "anticipating that we will show that a  is a very efficient machine , what is most striking is that the number of @xmath79 and @xmath80 events it generates is proportional to @xmath99 and @xmath100 , respectively , just as in the case of the simple probabilistic processor and in the classical electrodynamical and quantum mechanical description of the polarizer .",
    "[ sec4b ]    for a more detailed mathematical analysis of the dynamics of a , it is convenient to write the update rules eq .   as linear difference equations",
    "actually , we need only @xmath166 for simplicity , we restrict the discussion that follows to the case @xmath167 .",
    "other cases can be treated in the same manner .",
    "substituting @xmath148 in eq .",
    "( [ recursion ] ) , we obtain @xmath168 showing that eq .",
    "( [ recursion ] ) has the structure of a so - called circle map  @xcite .",
    "thus , the study of the behavior of the circle map eq .",
    "( [ circlemap ] ) will give us insight into the dynamic properties of the .",
    "[ figcirclemap ] shows an example of circle - map analysis for the case of a fixed input angle of @xmath169 .     for the case of a fixed input angle of @xmath169 .",
    "the dashed ( green ) line shows the evolution of the mapping @xmath170 for @xmath171 .",
    "for clarity , we omitted the first 12 iterations because this allows us to show in detail how the mapping converges to a unique polygon . the function @xmath172 is defined by the rules and cost function eq .",
    "( [ circ3 ] ) and eq .",
    "( [ circ4 ] ) , respectively .",
    "the dotted ( blue ) line separates the case @xmath113 from the case @xmath118 and is given by @xmath173 for @xmath118 ( @xmath174 ) and @xmath175 for @xmath113 ( @xmath176 ) .",
    "the straight solid ( red ) line is given by @xmath177 .",
    "the solid ( red ) line forming the polygon with eight vertices shows the results for @xmath178 : in this case the system has reached the stationary state with a period of four . in this simulation , @xmath138 .",
    ", height=264 ]      [ pattern ]    let us assume that we have reached a stationary state and that the  repeats a sequence @xmath179 in which there are @xmath180 successive events of the type @xmath113 ( decreasing @xmath181 ) and one @xmath118 event ( increasing @xmath181 ) .",
    "let us denote by @xmath182 , the value of @xmath183 before the first of the @xmath180 events of type 0 . from eq .",
    "we obtain @xmath184 as the  repeats the same sequence over and over again , we have @xmath185 . in other words , if we observe the repeated sequence @xmath186 of length @xmath187 , we must have @xmath188 furthermore , as @xmath189 for @xmath190 , the mean value of the @xmath191 s during the sequence is given by @xmath192 in agreement with eq .  . from eq .",
    ", we conclude that the  can encode the values @xmath193 with periodic sequences of the form @xmath186 .    from this analysis",
    "we conclude that if we would limit the design of the device such that it can only generate sequences of the form @xmath186 , then , after observing two one s and counting the zeros between these two one s , we can determine the angle with an error of less than 5 degrees .",
    "this is the worst case and occurs when the sequence is @xmath194 ( @xmath195 ) and @xmath196 ( @xmath197 ) .",
    "clearly , even with this limitation ( @xmath180 zero s followed by one @xmath114 ) on the design , this is already a very efficient method to encode the angle .",
    "we now extend this analysis to a general periodic sequence .",
    "[ resol ]    first we show how the control parameter @xmath198 limits the accuracy with which we can represent the stationary state .",
    "let us assume that the fixed input vector is given by @xmath199 and that for some index @xmath29 , the machine is in the state @xmath200 , as illustrated in fig .",
    "[ machine3 ] ( the cases @xmath201 , @xmath202 , and @xmath203 can be treated in the same manner and lead to the same conclusion ) .    if the machine applies the update rule @xmath113 , the new state and the cost are given by @xmath204 the cost @xmath125 has to be compared to the cost of applying the update rule @xmath118 , in which case we have @xmath205    .",
    "the input vector is @xmath199 .",
    "the internal state is @xmath200 , and the new internal state is either @xmath206 or @xmath207 . in general ,",
    "the smallest angle @xmath208 for which the machine remains in the state @xmath209 depends on the value of the parameter @xmath198 , see eq .",
    "( [ alph5 ] ) . ,",
    "width=283 ]    note that the point @xmath210 is somewhat special in the sense that the machine remains at @xmath210 if it applies the update rule @xmath113 .",
    "the machine stays at @xmath210 ( forever ) unless the cost of applying the update rule @xmath118 , is less than the cost of applying the update rule @xmath113 . from eqs .",
    "( [ alph2 ] ) and ( [ alph1 ] ) , the necessary condition for the machine not to get stuck at @xmath210 is @xmath211 rearranging eq .",
    "( [ alph3 ] ) yields @xmath212 thus , eq .  ( [ alph1 ] ) shows that we can not represent angles @xmath6 that are smaller than @xmath213 for @xmath138 ( @xmath214 ) , typical values used in simulations , @xmath215 ( @xmath216 ) .",
    "note that @xmath208 does not determine the accuracy in the interval @xmath217 $ ] .",
    "[ fixed ]    we now consider situations in which the sequence of events consists of a repetition of the sequence @xmath218 of length @xmath4 .",
    "first , we determine the solution @xmath219 of @xmath220 ( implying @xmath221 ) .",
    "the formal solution of eq .",
    "( [ circ5 ] ) is given by @xmath222 and the requirement @xmath220 yields @xmath223 we conclude that if the machine starts from @xmath219 and generates the events @xmath224 , it returns to the starting point @xmath219 .",
    "for each pattern @xmath224 , there exists such a point @xmath219 .",
    "in other words , if the machine is in the state @xmath219 , repeating the sequence @xmath224 generates a periodic motion of @xmath225 for @xmath226 with period @xmath4 .",
    "second , we consider the situation in which the machine starts from @xmath227 and we keep feeding the machine with the periodic sequence @xmath224 . using the general expression eq .",
    "( [ fix1 ] ) , we find @xmath228 where @xmath229 denotes the number of times the machine processes the periodic sequence @xmath224 . as @xmath230 , @xmath231 , independent of the choice of @xmath55 .",
    "therefore , for any periodic sequence @xmath218 of length @xmath4 , the corresponding sequence @xmath232 converges exponentially fast to the periodic sequence @xmath233 . from eq .",
    "( [ circ5c ] ) it then follows that @xmath234 and using @xmath235 we find @xmath236 note that @xmath237 is a rational number and that according to eq .",
    "( [ circ5c ] ) , we have @xmath238 .",
    "[ lower ]    previously , we have tactically assumed that we can always find the periodic sequence of @xmath239 s that represents the input angle @xmath6 .",
    "we now show that for a fixed input angle @xmath6 , the control parameter @xmath198 has to be large enough ( but smaller than one ) in order that the  repeats the same sequence @xmath224 . as before ,",
    "we confine the discussion to input angles that satisfy @xmath240 .",
    "then , the number of 0 events is larger than the number of 1 events . without loss of generality",
    ", we may put @xmath113 .",
    "this means that the internal state @xmath241 of the  satisfies @xmath242 . if the sequence is to be periodic with period @xmath4 , we must have @xmath243 .",
    "( see eq .",
    "( [ crit4 ] ) ) as a function of @xmath198 for @xmath244 ( solid line ) and @xmath245 ( dashed line ) . in the stationary regime and for @xmath246 ,",
    "the  repeats the sequence @xmath247 with @xmath180 zero s , that is , it generates and exact representation of @xmath180 . , width=321 ]    [ cols=\"^,<,^,^\",options=\"header \" , ]     [ table1 ]    so far , we did not consider the cost of going from @xmath248 to @xmath249 . denoting @xmath250 to simplify the expressions ,",
    "the new internal states after a @xmath251 or @xmath252 event are @xmath253 respectively . according to the general rules , the  determines @xmath254 by comparing the costs @xmath255 for the two alternative internal states of eq .",
    "( [ crit1 ] ) .",
    "the  generates a @xmath252 event if @xmath256 .",
    "after some rearrangements we obtain @xmath257 in general , @xmath258 is a function of @xmath198 .",
    "therefore , for a fixed @xmath198 , eq .",
    "( [ crit3 ] ) sets an upperbound to the input angle for which the  can generate a periodic sequence .    as an illustration",
    ", we consider the sequence @xmath247 in which there are @xmath180 0 events and one 1 event .",
    "the initial point for the periodic continuation @xmath259 of this sequence is given by eq .",
    "( [ circ6b ] ) .",
    "let us assume that the  starts from this initial point and generates @xmath180 zero s , changing its internal state from @xmath260 to @xmath261 .",
    "the  will generate a @xmath262 event if @xmath263 in fig .",
    "[ alpha ] we plot @xmath264 as a function of @xmath198 for @xmath244 and @xmath245 ( plots for other values of @xmath180 show the same behavior ) . from fig .",
    "[ alpha ] and eq .",
    "( [ crit4 ] ) , we conclude that the  will indeed repeat the sequence @xmath247 with @xmath244 ( @xmath245 ) if @xmath265 ( @xmath266 ) . otherwise , if @xmath198 is not within this range , the generates at least one extra 0 event and the does not return to the initial state @xmath260 .",
    "thus , if @xmath198 is such that @xmath267 , the  can not generate the sequence that gives an exact representation of @xmath268 ( although it still gives an accurate approximation ) .",
    "[ variance ]    next , we compute the variance of the periodic , stationary state @xmath233 .",
    "the expression of the variance reads    @xmath269    using @xmath270 we obtain @xmath271 , \\nonumber \\\\ & = & \\frac{1-\\alpha^{2}}{1+\\alpha^{2 } } \\left [ { \\bar \\theta } + \\frac{2\\alpha^{2}}{1-\\alpha^{2n } } \\frac{1}{n } \\sum_{j=0}^{n-1 } \\sum_{i=0}^{n-1 } \\alpha^{2i}\\theta_{n+j+i+1 } \\theta_{n+j } \\right ] , \\nonumber \\\\ & = & \\frac{1-\\alpha^{2}}{1+\\alpha^{2 } } \\left [ \\frac{1+\\alpha^{2n}}{1-\\alpha^{2n } } { \\bar \\theta } + \\frac{2\\alpha^{2}}{1-\\alpha^{2n } } \\frac{1}{n } \\sum_{j=0}^{n-1 } \\sum_{i=0}^{n-2 } \\alpha^{2i}\\theta_{n+j+i+1 } \\theta_{n+j } \\right ] , \\label{fix3a}\\end{aligned}\\ ] ] where in the last step , we have taken out from the double sum , all terms of the form @xmath272 .    in table",
    "[ table1 ] we present analytical results for the initial points and variances of some simple sequences @xmath273 with periods @xmath274 and @xmath275 where both @xmath229 and @xmath274 are integers . if @xmath229 and @xmath274 have a common factor @xmath276 , as is the case for @xmath277 and @xmath278 , the problem simplifies to the case @xmath279 .",
    "the sequences @xmath273 marked with a @xmath280 yield the smallest variance @xmath281 .",
    "these are exactly the sequences that the  generates in the stationary regime , provided @xmath282 is sufficiently small ( @xmath138 is sufficient for the @xmath283-cases presented in table  [ table1 ] ) .",
    "in general , any sequence of 0 s and 1 s that begins with a 1 , can be viewed as a concatenation of subsequences that start with a 1 followed by one or more 0 s .",
    "the examples in table  [ table1 ] suggest that the sequences @xmath273 with the smallest variance consist of @xmath284 subsequences of length @xmath285 and @xmath286 subsequences of length @xmath287 .",
    "we have not been able to prove that in general this is the structure of the minimum variance solution .",
    "however , the relation between the minimum variance solution and the ground state configurations of a one - dimensional lattice model to be discussed next , suggests that this may well be the case .",
    "[ wigner ]    from eqs .",
    "( [ fix2b ] ) and ( [ fix3a ] ) , it follows that minimizing the variance @xmath281 is tantamount to finding the periodic sequence @xmath218 that minimizes the last term in eq .",
    "( [ fix3a ] ) , subject to the constraint @xmath288 .",
    "we now show that solving for the sequence that yields the lowest variance amounts to finding the ground state configuration of a classical many - body system .",
    "if we interpret @xmath289 ( 1 ) as the absence ( presence ) of a particle at the site @xmath17 of a one - dimensional lattice , then the last term in eq .",
    "( [ fix3a ] ) can be written as @xmath290 where @xmath291 and @xmath292 takes the value 0 or 1 if the site @xmath16 is empty or occupied , respectively .",
    "clearly , if @xmath230 , the potential @xmath293 satisfies the two conditions @xmath294 the density of particles @xmath295 is given by @xmath296 .    in the limit @xmath297 , the problem of finding the ground state configuration of particles for a system defined by the hamiltonian @xmath298 and satisfying the two conditions eq .",
    "( [ fix5 ] ) was solved by hubbard  @xcite . for any density @xmath299 where @xmath229 and @xmath274 are integers with no common factor , the ground state of eq .",
    "( [ fix6 ] ) is periodic with period @xmath274 and @xmath229 particles in each period  @xcite .",
    "hubbard gives an algorithm to generate the ground state configuration for a pair ( @xmath229,@xmath274 ) and calls these ground state configurations generalized one - dimensional wigner lattices  @xcite .",
    "his algorithm also generates the sequences @xmath273 in table  [ table1 ] that are marked with a @xmath280 .",
    "this is not a surprise : the periodic sequences with the smallest variance @xmath281 are also the ground state configurations of model eq .",
    "( [ fix6 ] ) .",
    "extensive numerical tests for @xmath300 and @xmath301 ( results not shown ) confirm that the ground state configurations generated by hubbard s algorithm are the same as the periodic sequences generated by the  in the stationary regime , for a fixed input @xmath199 , @xmath302 , @xmath303 , and sufficiently small @xmath198 .",
    "defined by eq .",
    "( [ per0 ] ) as a function of the number of events @xmath4 for @xmath304 ( corresponding to 101 different input angles ) . for each @xmath305",
    ", we generate @xmath4 input events , each input event carrying the message @xmath306 .",
    "note that @xmath127 is a vector of rational numbers .",
    "solid ( red ) line : probabilistic bernoulli - type processor ( see section  [ sec2 ] ) ; dashed ( green ) line : deterministic learning machine ( see section  [ sec3 ] ) . dotted ( blue ) line : modified deterministic learning machine , see eq .",
    "( [ per1 ] ) . in all the  simulations , @xmath307 and",
    "the first 10000 event were discarded to allow the  to approach the stationary state .",
    ", width=326 ]     except that the input events carry the message @xmath308 for @xmath305 .",
    ", width=326 ]      [ sec4 ]    the non - analytic character of the  algorithm and the complicated dependence on the parameter @xmath198 make it difficult for us to proof more rigorous results about the  dynamics than those presented earlier . on the other hand , it is very easy to study the dynamics numerically",
    ". extensive simulation work ( results not shown ) demonstrate that , with a proper choice of @xmath198 ( see sections  [ resol ] and  [ lower ] ) , a  can encode all rational numbers @xmath309 for @xmath106 .",
    "thus , for each input angle @xmath2 for which @xmath99 is a rational number , there is the stationary state in which the generates to a unique , periodic sequence ( with minimum variance ) of 1 s and 0 s from which the value of @xmath99 can be determined with very high precision .",
    "the update rule that the  uses is quite subtle , and we demonstrate this by changing the rules eqs .",
    "( [ circ3 ] ) and ( [ circ4 ] ) to @xmath310 for @xmath311 ( the case of interest for the present analysis ) , this rule tells the machine to rotate its internal vector towards the input vector @xmath107 .",
    "in contrast , the  that operates according to the rules of eqs .",
    "( [ circ3 ] ) and ( [ circ4 ] ) may decide to rotate its internal vector away from the input vector .    for a quantitative comparison of the performance of the probabilistic processor , the  defined by the rules of eqs .",
    "( [ circ3 ] ) and ( [ circ4 ] ) , and the  defined by the rules of eq .",
    "( [ per1 ] ) , we carry out the procedure that follows :    1 .",
    "set @xmath304 and choose @xmath312 randomly 2 .   for each @xmath305 3 .   set @xmath313 4 .",
    "compute @xmath314 5 .   for @xmath315 6 .",
    "generate an input event carrying the message @xmath316 7 .",
    "count the number @xmath180 of 1 events generated by the processor 8 .",
    "end loop over @xmath29 9 .",
    "compute @xmath317 10 .",
    "set @xmath318 11 .",
    "end loop over @xmath43    the number accumulated in @xmath319 yields @xmath320 which is the error averaged over @xmath321 different pairs of ( input , output ) angles for a fixed number @xmath4 of input messages .",
    "[ performance1 ] shows the error @xmath322 as a function of the number of events @xmath4 . in this case ,",
    "@xmath323 and @xmath324 are rational numbers and the results of fig .",
    "[ performance1 ] confirm that the  performs very well , much better than the probabilistic processor .",
    "[ performance1 ] also shows that replacing the update rule eq .",
    "( [ circ5 ] ) by eq .",
    "( [ per1 ] ) has a large impact on the performance of a deterministic learning machine .",
    "if we replace @xmath314 by @xmath325 in step 4 of the procedure described earlier , then @xmath324 is not necessarily a rational number and this affects the performance of the , as shown in fig .  [ performance2 ]",
    ". a closer look at the  data for different @xmath43 ( results not shown ) reveals that the large increase of the error is due to the relatively poor accuracy for @xmath326 and @xmath327 .",
    "this is hardly a surprise : from sections  [ resol ] and  [ lower ] we know that the choice of @xmath198 is more important for @xmath328 than it is for @xmath329 . therefore , if optimal performance for all @xmath6 is crucial , it is necessary to adjust @xmath198 dynamically by another learning process .",
    "we leave this topic for future research .",
    "[ sec5 ]    the fundamental difference between the simple probabilistic processor of section  [ sec2 ] and the  of section  [ sec3 ] is that the latter has a learning capability .",
    "elsewhere , we have shown that learning is an essential ingredient of networks of probabilistic or deterministic processors that are able to simulate , event - by - event , quantum interference phenomena and universal quantum computation  @xcite .",
    "the fundamental reason for this is that some form of communication between individual events is required in order to simulate ( classical or quantum ) interference phenomena .",
    "although the bernoulli - type probabilistic processor of section  [ sec2 ] satisfies our criteria 1 and 2 of section  [ sec1 ] for an efficient processor , it generates uncorrelated events and any form of communication between events is absent .",
    "therefore the probabilistic processor of section  [ sec2 ] can not simulate interference phenomena but the  of section  [ sec3 ] can because it has the additional feature of being able to learn from previous events .    as a non - trivial illustration of the importance of the learning process",
    ", we consider the interferometer depicted in fig .",
    "[ twomzi ]  @xcite .",
    "this interferometer consists of two chained mach - zehnder interferometers  @xcite .",
    "photons leave the source ( not shown ) located at the bottom of the left - most vertical line .",
    "the beam splitters , represented by the large rectangles , transmit or reflect photons with probability 1/2 . after leaving the first beam splitter in the vertical or horizontal direction , the photons experience a time delay that is determined by the length of the optical path from one beam splitter to the next .",
    "the length of each path is variable , as indicated schematically by the controls on the horizontal lines . in a wave mechanical description ,",
    "the time delays correspond to changes in the phase of the wave .",
    "the thin , @xmath330-tilted lines act as perfect mirrors .",
    "in quantum theory , the presence of photons in the input modes 0 or 1 of the interferometer is represented by the probability amplitudes ( @xmath331  @xcite . according to quantum theory ,",
    "the amplitudes ( @xmath332 of the photons in the output modes 0 and 1 of a beam splitter are given by  @xcite @xmath333 the amplitudes to observe a photon in the output modes 0 and 1 of one mach - zehnder interferometer of fig .",
    "[ twomzi ] are given by @xmath334 the amplitudes to observe a photon in the output modes 0 and 1 of two chained mach - zehnder interferometers are given by @xmath335 in eqs .",
    "( [ mz1 ] ) and ( [ mz2 ] ) , the entries @xmath336 for @xmath337 implement the phase shifts that result from the time delays on the corresponding path ( including the phase shifts due to the presence of the perfect mirrors ) .",
    "the probability to detect a photon in either output mode 0 or 1 of the two chained mach - zehnder interferometers are given by @xmath338 or @xmath339 , respectively .",
    "using  networks , it is possible to reproduce the wave - like behavior by an event - by - event , particle - like , simulation without using wave mechanics  @xcite .",
    "elsewhere  @xcite we have shown that  networks can simulate , event by event , single - photon beam splitter and ( modified ) mach - zehnder interferometer experiments  @xcite .",
    "[ twomzi ] shows the schematic diagram of the  network that performs the event - by - event simulation of the two chained mach - zehnder interferometers  @xcite .",
    "particles emerge one - by - one from a source ( not shown ) located at the bottom of the left - most vertical line . at any time",
    ", there is at most one particle ( represented by the small sphere ) in the system .",
    "the number of particles that have left the source is given by @xmath4 .",
    "each particle carries its own clock .",
    "there is a one - to - one correspondence between the direction of the hand of the clock and the message @xmath107 .",
    "the clock is read and manipulated by the beam splitters , represented by the large rectangles .",
    "each beam splitter contains two  @xcite .",
    "the internal structure of the  network that performs the task of a beam splitter is described in detail elsewhere  @xcite , so there is no need to repeat it here .",
    "of course , these networks are the same for the three beam splitters .    after leaving the first beam splitter in either the vertical or horizontal direction ( but never in both ) , the particle experiences a time delay that is determined by the controls on the lines .",
    "this time delay is implemented as a rotation of the hand of the particle s clock .",
    "when a particle leaves the system at the top right , it adds to the count of either detector @xmath340 or @xmath341 .",
    "additional detectors ( @xmath159 , @xmath160 , @xmath342 , and @xmath343 ) count the number of particles on the corresponding lines .",
    "the label of @xmath344 in the quantum mechanical description is the same as the label of the corresponding counter @xmath345 .",
    "the other cells give the ratio of the detector counts to the total number of particles ( messages ) processed and also the corresponding probability of the quantum mechanical description . at any time",
    ", the user can choose between a strictly deterministic and a probabilistic event - by - event simulation by pressing the buttons at the top of the control panel .",
    "we emphasize that this -based simulation is dynamic and adaptive in all respects : during the simulation , the user can change any of the controls and after a short transient period , the -network generates output events according to the quantum mechanical probabilities .    the snapshot in fig .  [ twomzi ]",
    "is taken after @xmath346 particles have been generated by the source ( with one particle still under way ) .",
    "the numbers in the various corresponding fields clearly show that even after a modest number of events , this event - by - event simulation reproduces the quantum mechanical probabilities .",
    "of course , this single snapshot is not a proof that the event - by - event simulation also works for other choices of the delays .",
    "an event - by - event simulation correctly reproduces the quantum mechanical probabilities if and only if @xmath347 for @xmath337 , for any choice of the delays ( phases ) @xmath344 .",
    "very extensive tests , reported elsewhere  @xcite demonstrate that -networks accurately reproduce the probabilities of the quantum theory .    in the event - by - event simulation ,",
    "interference is a direct result of the learning process that takes place in each . in the case at hand ,",
    "the three ( identical ) beam splitters contain the learning machines .",
    "we emphasize that there is no direct communication between the different beam splitters .",
    "all the information is carried by the particle while it is routed through the network .",
    "this is essential for the simulation to satisfy the physical criterion of causality .",
    "[ sec6 ]    in this paper we ask ourselves the question what the optimal design of a processor , which can process and count incoming individual objects carrying information represented by an angle @xmath2 but which can not measure @xmath2 directly , would be if it has to give the most accurate estimate of the angle @xmath2 . in other words",
    ", how can we simulate the operation of a photon polarizer ?",
    "first , we construct a processor operating according to the rules of probability theory .",
    "this so - called probabilistic processor uses random numbers to transform the incoming angle @xmath2 , that is the information carried by the incoming single objects , into a sequence of discrete output events labeled by @xmath348 .",
    "the numbers of @xmath80 and @xmath79 events only depend on the difference @xmath349 between the unknown angle @xmath2 and the orientation @xmath1 of the processor .",
    "we design the probabilistic processor such that the result of the transformation process is probabilistic ( bernoulli trials ) , rotational invariant and satisfies the criteria 1 and 2 of section  [ sec1 ] . for fixed @xmath1 and @xmath4 incoming objects ,",
    "the observer , using the probabilistic processor to measure @xmath2 as accurate as possible , will get most out of the data if the processor sends @xmath350 ( @xmath351 ) events to the apparatus that detects the @xmath80 ( @xmath79 ) events .",
    "the number of angles @xmath6 that the observer can distinguish is proportional to @xmath352 .",
    "the probabilistic processor is thus a model for an ideal polarizer .",
    "it produces data that agrees with malus  law .",
    "however , it is important to note that to obtain this result we do not use any law of physics in the design of the processor .",
    "we do not use the probability distributions derived in quantum theory to generate the @xmath348 events but we design the probabilistic processor in such a way that these probability distributions come out as a result of efficient processing of incoming data by the processor .",
    "hence , we can ask the following important question .",
    "can also other quantum phenomena appear as a result of efficient data processing ?    in order to answer this question",
    "we follow another route .",
    "although the bernoulli type probabilistic processor can simulate the classical and quantum properties of a photon polarizer , it can not simulate interference phenomena . to overcome this problem we could design a probabilistic processor that does not generate bernoulli events but correlated output events .",
    "however , we choose to design processors that use a deterministic algorithm with a primitive learning capability to transform the incoming events into a sequence of discrete output events .",
    "this type of processors we call deterministic processors or deterministic learning machines .",
    "therefore , as a second step , we construct a deterministic processor that models a photon polarizer , that is a deterministic processor that generates output events according to malus law . just as the probabilistic processor , the deterministic processor has one input channel and two output channels labeled by @xmath80 and @xmath79 , respectively .",
    "apart from this the deterministic processor also has an internal vector with two real entries .",
    "the input messages to the deterministic processor are unit vectors @xmath353 for @xmath354 and where @xmath355 .",
    "the deterministic processor learns from the input events by updating its internal vector and uses this internal vector in a completely deterministic decision process to send out a @xmath80 or a @xmath79 event .",
    "hence , the order in which the @xmath80 and @xmath79 events are sent is deterministic .",
    "apart from being deterministic , the result of the transformation process is rotational invariant and satisfies criteria 1 and 2 of section  [ sec1 ] , which are exactly the same requirements as the ones used to construct the probabilistic processor .",
    "further analysis of the output events shows that the number of @xmath80 and @xmath79 output events agrees with malus law .",
    "hence , the photon polarizer can also be modelled by a deterministic processor . as in the case of the probabilistic processor ,",
    "also in this case we did not use any laws of physics to design the processor . the number of angles @xmath6 that the observer , using the deterministic processor to measure @xmath2 , can distinguish is equal to @xmath356 .",
    "hence , in this respect the deterministic processor performs much better than the probabilistic one . however , the more important and fundamental difference between the probabilistic and the deterministic processor is that the latter has a learning capability .",
    "learning is an essential ingredient to simulate interference phenomena since it correlates the output events . as an example we show the event - by - event simulation of photons routed through two chained mach - zehnder interferometers by using a network of deterministic processors .",
    "we show that the quantum mechanical probabilities are also reproduced for this interference experiment .    in conclusion",
    ", processors that efficiently process incoming data in the form of single events can simulate some quantum phenomema , such as the recovery of malus law for a photon polarizer .",
    "however , in order to simulate quantum interference the processor should in addition have the capability of learning .",
    "most importantly , the present work demonstrates that viewing quantum systems as efficient data processors provides a framework to construct adaptive , dynamical systems that can simulate quantum interference on an event - by - event basis , without using concepts of quantum theory .",
    "support from the naregi nanoscience project , ministry of education , culture , sports , science and technology , japan is gratefully acknowledged .",
    "in frieden s approach the cramr - rao inequality plays a central role to motivate the use of the fisher information as a measure of the expected error in measurements  @xcite . from probability theory",
    "it is well known that the cramr - rao inequality sets a lower bound to the variance of an estimator  @xcite . here",
    "we prove that , within the limitations set by our design criteria , the estimation procedure is _ efficient _ in the sense that it satisfies the cramr - rao inequality with equality  @xcite and that this inequality reduces to a trivial identity that contains no information  @xcite . for convenience of the reader ,",
    "we repeat the derivation of the cramr - rao inequality for the case of interest .          where @xmath361 ^ 2 , \\label{appe9}\\ ] ] is the fisher information  @xcite . with the use of eq.([stoc1 ] ) we can write @xmath66 as @xmath362 ^ 2 , \\label{appe10}\\ ] ] which is identical to eq .",
    "( [ stoc9 ] ) . any estimation procedure that satisfies the bound in eq .",
    "( [ appe8 ] ) with equality is called _ efficient _  @xcite . using eq .",
    "( [ stoc2 ] ) and @xmath363 we find @xmath364 ^ 2 % , \\nonumber \\\\ % & = & = \\left[\\frac{\\partial f(\\theta)}{\\partial\\theta}\\right]^2 .\\end{aligned}\\ ] ] hence , the inequality eq .",
    "( [ appe8 ] ) reduces to a trivial identity from which we can not deduce anything useful  @xcite .",
    "99 g. baym , _ lectures on quantum mechanics _ , w.a .",
    "benjamin , reading ma ( 1974 ) .",
    "feynman , r.b .",
    "leighton , m. sands , _ the feynman lectures on physics _ , vol .",
    "3 , addison - wesley , reading ma ( 1996 ) .",
    "m. born and e. wolf , _ principles of optics _ , pergamon , oxford ( 1964 ) .",
    "d. home , _ conceptual foundations of quantum physics _ , plenum press , new york ( 1997 ) .",
    "these constraints simply express the known , basic properties of the photon polarization  @xcite .",
    "grimmet and d.r .",
    "stirzaker , _ probability and random processes _ , clarendon press , oxford uk ( 1995 ) .",
    "m. tribus , _ rational descriptions , decisions , and designs _ , expira press , stockholm sweden ( 1999 ) .",
    "jaynes , _ probability theory : the logic of science _ , cambridge university press , cambridge uk ( 2003 ) .",
    "van trees , _ detection , estimation , and modulation theory ( part i ) _ , wiley , new york ( 1968 ) .",
    "frieden , _ physics from fisher information : a unification _ , cambridge university press , cambridge uk ( 1999 ) .",
    "blahut , _ principles and practice of information theory _",
    ", addison - wesley , reading massachussets ( 1991 ) .",
    "wootters , phys .",
    "d * 23 * , 357 ( 1981 ) .",
    "j. summhammer , in _ foundations of probability and physics _ , a. khrennikov , ed . ,",
    "world scientific , singapore ( 2001 ) . k. de raedt , h. de raedt , and k. michielsen , comp .",
    "( in press ) .",
    "h. de raedt , k. de raedt , and k. michielsen , europhys . lett . * 69 * , 861 ( 2005 ) .",
    "s. haykin , _ neural networks _ , prentice hall , new jersey ( 1999 )",
    "jensen , p. bak , and t. bohr , phys .",
    "lett . * 50 * , 1637 ( 1983 ) .",
    "j. hubbard , phys .",
    "b * 17 * , 494 ( 1978 ) .",
    "fortran and java programs and interactive programs that perform event - based simulations of a beam splitter , one mach - zehnder interferometer , and two chained mach - zehnder interferometers can be found at http://www.compphys.net/dlm p. grangier , r. roger , and a. aspect , europhys .",
    "* 1 * , 173 ( 1986 ) .",
    "braig , p. zarda , c. kurtsiefer , and h. weinfurter , appl .",
    "b * 76 * , 113 ( 2003 ) ."
  ],
  "abstract_text": [
    "<S> we study the relation between the acquisition and analysis of data and quantum theory using a probabilistic and deterministic model for photon polarizers . </S>",
    "<S> we introduce criteria for efficient processing of data and then use these criteria to demonstrate that efficient processing of the data contained in single events is equivalent to the observation that malus law holds . </S>",
    "<S> a strictly deterministic process that also yields malus law is analyzed in detail . </S>",
    "<S> we present a performance analysis of the probabilistic and deterministic model of the photon polarizer . </S>",
    "<S> the latter is an adaptive dynamical system that has primitive learning capabilities . </S>",
    "<S> this additional feature has recently been shown to be sufficient to perform event - by - event simulations of interference phenomena , without using concepts of wave mechanics . </S>",
    "<S> we illustrate this by presenting results for a system of two chained mach - zehnder interferometers , suggesting that systems that perform efficient data processing and have learning capability are able to exhibit behavior that is usually attributed to quantum systems only .    </S>",
    "<S> # 1 # 1#1 # 1#1 # 1#1 # 1#2#1 # 2 # 1([#1 ] ) # 1#1 # 1 </S>"
  ]
}