{
  "article_text": [
    "we shall be concerned with discrete signals @xmath14 and their fourier transforms @xmath15 , defined by @xmath16 . in terms of the fourier basis functions",
    "@xmath17 , @xmath3 can be written as @xmath18 ; this is the ( discrete ) fourier representation of @xmath3 .    in many situations ,",
    "a few large fourier coefficients already capture the major time - invariant wave - like information of the signal and very small fourier coefficients can thus be discarded .",
    "the problem of finding the ( hopefully few ) largest fourier coefficients of a signal that describe most of the signal trends , is a fundamental task in fourier analysis .",
    "techniques to solve this problem are very useful in data compression , feature extraction , finding approximating periods and other data mining tasks @xcite , as well as in situations where multiple scales exist in the domain ( as in e.g. materials science ) , and the solutions have sparse modes in the frequency domain .",
    "let @xmath3 be a signal that is known to have a sparse @xmath1-term fourier representation with @xmath19 , i.e. , @xmath20 and let us assume that it is possible to evaluate @xmath3 , at arbitrary @xmath21 , at cost @xmath22 for every evaluation .    to identify the parameters @xmath23 , one can use the fast fourier transform ( fft ) . starting from the @xmath4 point - evaluations @xmath24",
    ", the fft computes all the fourier coefficients ; one can then take the largest @xmath1 coefficients and the corresponding modes .",
    "the time cost for this procedure is @xmath25 ; this can become very expensive if @xmath4 is huge .",
    "( note that all logarithms in this paper are with base 2 , unless stated otherwise . )",
    "the problem becomes worse in higher dimensions .",
    "if one uses grids of size @xmath4 in each of @xmath26 dimensions , the total number of points is @xmath27 and the fft procedure takes @xmath28 time .",
    "it follows that identifying a sparse number of modes and amplitudes is expensive for even fairly modest @xmath4 .",
    "our goal in this paper is to discuss much faster algorithms that can identify the coefficients @xmath29 and the modes @xmath30 in equation ( [ brepn ] ) .",
    "these algorithms will not use all the samples @xmath31 , but only a very sparse subset of them .",
    "in fact , we need not restrict ourselves to signals that are exactly equal to a @xmath1-term representation .",
    "let us denote the optimal @xmath1-term fourier representation of a signal @xmath3 by @xmath32 ; it is simply a truncated version of the fourier representation of @xmath3 , retaining only the @xmath1 largest coefficients .",
    "we are then interested in identifying ( or finding a close approximation to ) @xmath32 via a fast algorithm . the papers @xcite",
    "@xcite @xcite provide such algorithms ; all compute a ( near-)optimal @xmath1- term fourier representation @xmath2 in time and space @xmath33 , such that @xmath34 , with success probability at least @xmath8 , where @xmath35 is an a priori given upper bound on @xmath36 .",
    "the algorithms in these papers share the property that they need only some random subsets of the input rather than all the data ; they differ in many details : the different papers assume different conditions on @xmath4 , ( for example , @xmath4 is assumed to be a power of 2 or a small prime number in @xcite ; n may be arbitrary but is preferably a prime in @xcite ) ; the algorithms also use different schemes to locate the significant modes .",
    "( here we say a mode @xmath37 is significant if for some pre - set @xmath38 , @xmath39 . )",
    "mansour and sahar @xcite implemented a similar algorithm for fourier analysis on the set @xmath40 , where our algorithm is for fourier analysis on @xmath41 .",
    "the results of @xcite can be extended to more general representations , with respect to a particular basis or a family of bases ; examples are wavelet bases , wavelet packets or fourier bases .",
    "we shall use the acronym ra@xmath0sta ( randomized algorithm for sparse transform analysis ) for this family of algorithms .",
    "we here restrict ourselves to the fourier case and thus ra@xmath0sfa .    for a wide range of applications ,",
    "the speed potential suggested by the sublinear cost of these algorithms is of great importance . in this paper , we concentrate on the approach proposed in @xcite . note that @xcite gives a theoretical rather than a practical analysis in the sense that it does not discuss parameter settings ; it gives few hints about the order of the polynomial in @xmath1 and @xmath42 ; in fact , a straightforward implementation of ra@xmath0sfa following the set - up of @xcite turns out to be too slow to be practical , so that none of the direct implementation work was published .",
    "in addition , @xcite did not discuss extensions to higher dimensions , where the pay - off of ra@xmath0sfa versus the fft is expected to be larger .",
    "our main result in this paper is a version of ra@xmath0sfa that addresses these problems .",
    "we give theoretical and heuristic arguments for the setting of parameters ; we introduce some new ideas that produce a practical ra@xmath0sfa implementation .",
    "our new version can outperform the fftw when @xmath4 is around @xmath43 and @xmath1 is small .    * a motivating example .",
    "* ra@xmath0sfa is an exciting replacement for the fft to solve multiscale models .",
    "typically , one wants to simulate a multiscale model in several dimensions with both a microscopic and a macroscopic description .",
    "the solution to the model has rapidly oscillating coefficients with period proportional to a small parameter @xmath44 . for examples of multiscale problems of size",
    "@xmath4 that are dominated by the behavior of @xmath19 fourier components , see e.g @xcite . in a traditional ( pseudo-)spectral method",
    ", one computes the spatial derivatives by the fft and inverse fft at each time iteration ; consequently the time to find the fourier representation of a signal is the determining factor in the overall time of simulation . in multiscale problems , where only a small number of fourier modes contribute to the energy of an initial condition and coefficient functions",
    ", we expect that ra@xmath0sfa will significantly speed up the calculation for large @xmath4 .",
    "in fact , a preliminary study has shown @xcite that for some transport and diffusion equations with multiple scales , using only significant frequencies to approximate intermediate solutions does not substantially degrade the quality of the approximate final solution to the multiscale problem . by using the most significant frequencies and ra@xmath0sfa instead of all frequencies and the fft",
    ", we could replace a superlinear algorithm by a poly - log ( polynomial in the logarithm ) algorithm .",
    "the corresponding decrease of the running time would make it possible to handle a larger number of grid points in high dimensions .",
    "we shall present detailed applications of this algorithm in multiscale problems in @xcite .",
    "* notation and terminology . * for any two frequencies @xmath45 , @xmath46 , where @xmath47 , we say that @xmath48 is bigger than @xmath49 if @xmath50 .",
    "the squared norm @xmath51 of @xmath3 is also called the energy of @xmath3 ; we shall refer to @xmath52 as the energy of the fourier coefficient @xmath53 .",
    "similarly , the energy of a set of fourier coefficients is the sum of the squares of their magnitudes .",
    "we shall use only the @xmath54-norm in this paper ; for convenience , we therefore drop the subscript from now on , and denote @xmath55 by @xmath56 for any signal @xmath57 .",
    "we denote the convolution by @xmath58 , @xmath59 .",
    "it follows that @xmath60 .",
    "we denote by @xmath61 the signal that equals 1 on a set @xmath62 and zero elsewhere .",
    "the index to @xmath61 may be either time or frequency ; this is made clear from context . for more background on fourier analysis ,",
    "see @xcite .",
    "the support @xmath63 of a vector @xmath57 is the set of @xmath21 for which @xmath64 .",
    "a signal is 98@xmath65 pure if there exists a frequency @xmath37 and some signal @xmath66 , such that @xmath67 and @xmath68 .",
    "ra@xmath0sfa is a randomized algorithm . by this , we do * not * mean the signal is randomly chosen from some kind of distribution , with our timing and memory requirement estimates holding with respect to this distribution ; on the contrary , the signal , once given to us , is * fixed*. the randomness lies in the algorithm . after random sampling",
    ", certain operations are repeated many times , on different subsets of samples , and averages and medians of the results are computed .",
    "we set in advance a desired probability of success @xmath8 , where @xmath69 can be arbitrarily small .",
    "then the claim is that for each arbitrary input @xmath3 , the algorithm succeeds with probability @xmath8 , i.e. , gives a @xmath1-term estimate @xmath2 such that @xmath70 . for given @xmath44 , @xmath71 ,",
    "numerical experiments show that the algorithm may take @xmath72 time and space .",
    "* organization . *",
    "the chapters are organized as follows .",
    "section 2 shows the testbed and numerical experiments about the comparison of our ra@xmath0sfa and the fftw . in section 3 ,",
    "we introduce all the new techniques and ideas of ra@xmath0sfa ( different from @xcite ) and its extension to multi - dimensions .",
    "in this section , we present numerical results of ra@xmath0sfa .",
    "we begin in section [ subset : onedim ] with comparing the running time of ra@xmath0sfa and the fftw for some one dimensional test examples . in section [",
    "sect : ntwodim ] , the performances of two dimensional ra@xmath0sfa and the fftw for some test signals are shown .",
    "the randomness of the algorithm implies that the performance differs each time for the same group of parameters .",
    "hence , we give the average data , bar and quartile graph based on 100 runs as well as the fastest data among these experiments . the popular software fftw @xcite version 2.1.5 is used to determine the timing of the fast fourier transform for the same data .",
    "the test signals are either superpositions of @xmath19 modes in the frequency domain , that is , @xmath73 , contaminated with gaussian white noise , or signals for which the fourier coefficients exhibit rapid decay , so that a @xmath1-mode approximation with @xmath19 will already be very accurate . different choices of the @xmath74 were checked ; these did not influence the whole execution time .",
    "these choices included cases where some frequencies were close ; note that this is the `` hard '' case for most estimation algorithms .",
    "for ra@xmath0sfa , which contains random scrambling operations ( that are later described ) , the distance between the modes does not matter if @xmath4 is prime .",
    "if @xmath4 is not prime , then @xmath75 can not decrease by the scrambling operation , so that different @xmath76 pairs may ( in theory ) lead to different performances ; in practice , this does nt seem to matter . in all these situations , ra@xmath0sfa reliably estimates the size and locations of the few largest coefficients .",
    "we also set other parameters as follows : accuracy factor @xmath77 , failure probability @xmath78 .",
    "the parameter choices in the algorithm are quite tricky .",
    "the theoretical bounds given in @xcite do not work well in practice ; instead much smaller parameters and heuristic settings work more efficiently .",
    "all the experiments were run on an amd athlon(tm ) xp1900 + machine with cache size 256 kb , total memory 512 mb , linux kernel version 2.4.20 - 20.9 and compiler gcc version 3.2.2 .",
    "the first implementation results of ra@xmath0sfa were not published ; the program was basically a proof of concept , not optimized . with the choices and parameters described in @xcite , it was extremely slow and thus not practical for real - world applications .",
    "the implementation we present here runs several order of magnitude faster ; this involves introducing many adjustments and ideas to the algorithm of @xcite .",
    "( see section 3 for details . )",
    "the goal of this paper is to check the possibility to replace the fft with ra@xmath0sfa for sparse and long signals .",
    "therefore , we focus on comparing the performance of ra@xmath0sfa and fftw in the following subsections .",
    "we begin with the experiments for recovering a signal consisting of eight modes ( with and without noise ) . in the noisy signal case ,",
    "the noise is a gaussian white noise with signal - to - noise ratio ( @xmath79 , defined as @xmath80 ) approximately 5db .",
    "the coefficients are randomly taken from the interval @xmath81 $ ] and the significant modes from @xmath82 $ ] .",
    "two kinds of running time for each algorithm are provided .",
    "one is the total running time and another is the running time excluding the sampling time .",
    "as we know , the fft takes @xmath83 to compute all signal values . on the other hand",
    ", our algorithm does nt need all the sample values .",
    "all our conclusions are based on the time _ excluding _ the sampling .",
    "however , we still list the running time including sampling time as well because of the existence of various forms of data in practice .",
    "for example , in pseudospectral applications , the data need to be computed from a b - superposition , which may take @xmath84 per sample .",
    "it is possible to sample more quickly , which is addressed in @xcite . on the other hand ,",
    "if the data is already stored in a file or a disk , we simply get them without any computation .",
    "in all these cases , we assume the data is either already in memory or available through computation .",
    "thus we do nt need to go through every data , which would take time @xmath85 .",
    "table [ tab : b8onedim ] provides a comparison of the running times of the fftw and ra@xmath0sfa for eight - mode clean and noisy signals . in the beginning when @xmath4 is small , the fftw is almost instantaneous .",
    "as the signal length @xmath4 increases , its time grows superlinearly . on the contrary",
    ", ra@xmath0sfa takes longer time in smaller @xmath4 cases ; however the time cost remains almost constant regardless of the signal length .",
    "in addition , the benchmark fftw software fails to process more than @xmath86 data because it runs out of the memory space .",
    "in contrast , ra@xmath0sfa has no difficulty at all since it does not need all the data .",
    "a simple interpolation from the entries in table [ tab : b8onedim ] predicts that ra@xmath0sfa beats the fftw when @xmath87 for eight - mode signals , all the more convincingly when @xmath4 is larger .",
    "if we compare the time including sample computation , the cross - over point would be @xmath88 .",
    "the table also shows the linear relationship between the time cost and the logarithm of the length @xmath4 .    .time comparison between ra@xmath0sfa and fftw ( b=8 ) based on 100 runs .",
    "`` clean '' means that the test signal is pure .",
    "`` noisy '' means the signal is contaminated with noise of @xmath89 .",
    "`` excluding sampling '' column lists the running time without precomputation of sample values .",
    "[ cols= \" < , < , < , < , < , < , < \" , ]",
    "we hope the numerical results have whetted the reader s appetite for a more detailed explanation of the algorithm . before explaining the structure of ra@xmath0sfa",
    "as implemented by us , we review the basic idea of the algorithm . given a signal consisting of several frequency modes with different amplitudes , we could split it into several pieces that have fewer modes .",
    "if one such piece had only a single mode , then it would be fairly easy to identify this mode , and then to approximately find its amplitude .",
    "if the piece were not uni - modal , we could , by repeating the splitting , eventually get uni - modular pieces . in order to compute the amplitudes",
    ", we need to `` estimate coefficients . '' to verify the location of the modes in the frequency domain and concentrate on the most significant part of the energy , we use `` group testing . '' an estimation that recurs over and over again in this testing is the `` evaluation of norms . ''",
    "the first splitting of the signal is done in the `` isolation '' step .",
    "the different steps are carried out on many different variants of the signals , each obtained by a random translation in the frequency domain ( corresponding to a modulation and the inverse dilation in the time domain ) . because the signal is sparse in the frequency domain , the different modes are highly likely",
    "to be well separated after these random operations , facilitating isolation of individual modes .",
    "the main skeleton of the algorithm was already given in @xcite ; in our discussion here , we introduce new ideas and give the corresponding theoretical analysis .",
    "we also explain how to set parameters that are either not mentioned or loose in @xcite . in section [",
    "sect : num ] , the total scheme of ra@xmath0sfa is given . in section [",
    "sect : coeff ] , we show the theoretical basis to choose parameters for estimating coefficients , and introduce some techniques to speed up the algorithm . in section [",
    "sect : norm ] , we set the parameters for norm estimation .",
    "section [ sect : isolation ] presents the heuristic rules to pick the filter width for the isolation procedure .",
    "this is one of the key factors determining the speed .",
    "a new filter is proposed for group testing in section [ sect : group ] , which works more efficiently .",
    "section [ sect : sample ] discusses how to evaluate a random sample from a signal .",
    "finally , we discuss the extension to higher dimensions in section [ sect : twodim ] .",
    "the following theorem is the main result of @xcite .",
    "let an accuracy factor @xmath44 , a failure probability @xmath71 , and a sparsity target @xmath90 be given .",
    "then for an arbitrary signal @xmath3 of length @xmath4 , ra@xmath0sfa will find , at a cost in time and space of order @xmath91 and with probability exceeding @xmath8 , a @xmath92term approximation @xmath2 to @xmath3 , so that @xmath93 .",
    "it is especially striking that the near - optimal representation @xmath2 can be built in sublinear time i.e. , @xmath94 instead of the @xmath95 time requirement of the fft .",
    "ra@xmath0sfa s speed will surpass the fft as long as the length of the signal is sufficiently large .",
    "in particular , if @xmath96 ( that is , @xmath53 vanishes for all but @xmath1 values of @xmath37 ) , then @xmath97 , i.e. , ra@xmath0sfa constructs @xmath3 without any error , at least in theory ; in practice this means the error is limited by accuracy issues .",
    "the main procedure is a greedy pursuit with the following steps :    total scheme + input : signal @xmath3 , the number of nonzero modes @xmath1 or its upper bound , accuracy factor @xmath44 , success probability @xmath8 , an upper bound of the signal energy @xmath35 , the standard deviation of the white gaussian noise @xmath98 , a ratio @xmath99 for relative precision .    1 .",
    "initialize the representation signal @xmath2 to 0 , set the maximum number of iterations @xmath100 , 2 .",
    "test whether @xmath101 .",
    "if yes , return the representation signal @xmath2 and the whole algorithm ends ; else go to step 3 .",
    "3 .   locate fourier modes @xmath37 for the signal @xmath102 by the isolation and group test procedures below .",
    "4 .   estimate fourier coefficients at @xmath37 : @xmath103 .",
    "5 .   if the total number of iterations is less than @xmath62 , go to 2 ; else return the representation @xmath2 .",
    "the test at stage 2 , which is not in @xcite , can allow us to end early .",
    "the criterion @xmath104 , where @xmath99 is a small number chosen heuristically , is suitable when one expects that @xmath3 is sparse , up to a small energy contribution .",
    "( note that step 2 does not use the exact value of @xmath105 , which is not known ; we use a procedure called norm estimation ( see below ) to give a rough estimate ; this is good enough for the stop criterion .",
    "other criteria could be substituted when appropriate . )    in practice , we would not know how many modes a signal has .",
    "in fact , the algorithm does nt really need to know @xmath1 : it can just proceed until the residual energy is estimated to be below threshold .",
    "( the value of @xmath1 is used only to set the maximum number of iterations , and the width of a filter in the isolation procedures below . for the maximum number @xmath62 , a loose upper bound on @xmath1 suffices ;",
    "the isolation filter width depends only very weakly on @xmath1 . )",
    "if either the residual energy or the threshold is large , the program would continue .",
    "note that for each iteration of the algorithm , we take new random samples from the signal @xmath3 .",
    "the original ra@xmath0sfa only shows the validity of estimating coefficients without mentioning parameter settings .",
    "here we introduce a new technique to achieve better and faster estimation ; in the process , we give another proof of lemma 2 in @xcite that contains explicit parameter choices .",
    "[ alg : coeff ] estimate individual fourier coefficients + input : signal @xmath3 , success probability @xmath8 , and accuracy factor @xmath44 .    1 .   randomly sample from signal @xmath3 with indices @xmath106 : @xmath107 , @xmath108 , @xmath109 .",
    "2 .   take the empirical mean of the @xmath110 , @xmath111 , store as @xmath112 .",
    "3 .   take the median @xmath113 , @xmath108 .",
    "4 .   return @xmath114 .",
    "[ alg : estcoef ]    [ lem : coef1 ] every application of algorithm _ [ alg : coeff ] _ constructs a realization of a random variable @xmath115 , that estimates the fourier coefficient @xmath53 , good up to tolerance @xmath116 with high probability @xmath8 , i.e. , @xmath117    define a random vector @xmath118 as follows : @xmath119 where @xmath21 is chosen uniformly and randomly from @xmath120 .",
    "then the expectation of @xmath118 is @xmath121 let x be the random variable @xmath122 , where @xmath123 .",
    "we have @xmath124=\\frac{1}{n}\\sum_{t}{ns(t)\\phi_{\\omega}(t)}=\\hat{s}(\\omega),\\ ] ] and @xmath125 define another random vector @xmath126 as the average of @xmath127 independent realization of @xmath118 , with @xmath128 .",
    "let a random variable @xmath129 then @xmath130=\\hat{s}(\\omega)$ ] and @xmath131=var[x]/l=\\epsilon^{2}\\vert s\\vert^{2}/8 $ ] , so that @xmath132 . + set @xmath133 , where @xmath134 .",
    "if @xmath135 , then for at least half of the @xmath136s , we have @xmath137 therefore @xmath138 so with probability @xmath8 , @xmath115 is a good estimate of the fourier coefficient @xmath53 , good up to tolerance @xmath139    several observations and new techniques can speed up the coefficient estimation even further .",
    "one observation is that fewer samples are already able to give an estimation with desirable accuracy and probability .",
    "our arguments indicate that @xmath140 samples per coefficient suffice to obtain good approximations of the coefficients .",
    "the estimates used to obtain this bound are rather coarse , however . in a practical implementation , if a multi - step evaluation is used ( see below ) , it turns out that three steps , in which every step uses 10 samples per mean , and 5 means per median , for a total of 150 samples ( per coefficient ) already determine the coefficient with accuracy @xmath141 . the major factor in this drastic reduction ( from @xmath142 to 150 ) is the much smaller number of means used ; in practice , the dependence on @xmath44 grows much slower than @xmath143 as @xmath144 if the signal is contaminated by noise or has more than one significant mode , we need more samples for a good estimation of the same accuracy .",
    "an additional difference with the sampling described in @xcite is that one can replace individual random samples by samples on short arithmetic progressions with random initial points .",
    "this technique became one of several components in the ra@xmath0sfa version of @xcite that adapted the original algorithm in order to obtain linearity in @xmath1 .",
    "for a description of the arithmetic progression sampling , we refer to @xcite .",
    "surprisingly , this change not only improves the speed , but also gives a closer approximation than simply random sampling , using the same number of samples .",
    "another idea is a coarse - to - fine multi - step estimation of the coefficients .",
    "there are several reasons for not estimating coefficients with high accuracy in only one step .",
    "one of them is that increasing the accuracy @xmath44 means a corresponding quadratic increase of the number of samples @xmath145 . a multi - step procedure , which produces only an approximate estimate of the coefficients in each step , achieves better accuracy and speed .",
    "to explain how this works , we need the following lemma .",
    "given a signal @xmath3 , let @xmath146 be @xmath147 different frequencies , and define @xmath148/ \\|s\\|^2_2 $ ] . estimate the coefficients @xmath149 where @xmath150 by the following iterative algorithm : apply algorithm _ [ alg : coeff ] _ with precision @xmath151 and probability of failure @xmath71 ; keep the parameters fixed throughout the iterative procedure , and let @xmath152 , @xmath150 , be the estimate ( at the @xmath153-th iteration ) of the @xmath154-th fourier coefficient of @xmath155 .",
    "the total estimate @xmath156 after the @xmath153-th iteration is thus @xmath157 .",
    "then @xmath158 with probability exceeding @xmath159 .",
    "( this is essentially a simplified version of proof for lemma 10 in @xcite ) + by lemma [ lem : coef1 ] , @xmath160 with probability exceeding @xmath8 .",
    "it follows that @xmath161 so that @xmath162 with probability exceeding @xmath163 .",
    "+ consider now the sequence @xmath164 , defined by @xmath165 , where @xmath166 .",
    "it is easy to see that @xmath167 it then follows by induction that @xmath168 , with probability exceeding @xmath169 , for all @xmath153 ; we have thus @xmath170 or equivalently , @xmath171 with probability exceeding @xmath172 .",
    "the above lemma shows that repeated rough estimation can be more efficient than a single accurate estimation . to make this clear ,",
    "if we set @xmath173 then a one - step procedure with parameters @xmath44 , @xmath71 will achieve the same precision as an @xmath153-step iterative procedure with parameters @xmath151 , @xmath174 .",
    "the one - step procedure will use @xmath175 sampling steps ; the iterative procedure will use @xmath176 .",
    "it follows that the @xmath153-step iterative procedure will be more efficient , i.e. , obtain the same accuracy with the same probability while sampling _ fewer _ times , if @xmath177 under the constraints ( [ eq : cofg ] ) . if @xmath178 ( that is , if @xmath3 is a pure @xmath147-component signal ) , then this condition reduces ( under the assumption that @xmath174 , @xmath71 and @xmath151 , @xmath44 are small , so that @xmath179 , @xmath180 ) to @xmath181 which is certainly satisfied if @xmath151 is sufficiently small and @xmath153 sufficiently large . if @xmath182 , matters are more complicated , but by a simple continuity argument we expect the condition still to be satisfied if @xmath183 is sufficiently small . if @xmath183 is too large , ( e.g. if @xmath184 , where @xmath185 is the minimum value of @xmath153 for which ( [ eq : cofg1 ] ) holds ) , then there are no choices of @xmath153 , @xmath151 , @xmath174 that will satisfy ( [ eq : cofg ] ) and ( [ eq : cofgg ] ) . on the other hand , @xmath183 can be large only if @xmath3 has important modes not included in @xmath186 . in practice , we use the multi - step procedure after the most important modes have been identified so that @xmath183 is small .",
    "for sufficiently small @xmath183 , we do gain by taking the iterative procedure .",
    "for example , assume that @xmath187 , for a signal of type @xmath188 with @xmath189 , @xmath190 , @xmath191 , @xmath192 , and with @xmath193 , theoretically we would then use 450,000 samplings for the one - step procedure , versus 150 samples for the iterative procedure .",
    "note that we introduced the parameter @xmath183 only for expository purposes . in practice",
    ", we simply continue with the process of identifying modes and roughly estimating their coefficients until our estimate of the residual signal is small ; at that point , we switch to the above multi - step estimation procedure .",
    "the basic principle to locate the label of the significant frequency is to estimate the energy of the new signals obtained from isolation and group testing steps .",
    "the new signals are supported on only a small number of taps in the time domain and have 98@xmath65 of their energies concentrated on one mode .",
    "the original analysis in @xcite only gave its loose theoretical bound .",
    "here we find the empirical parameters , i.e. , the number of samples for norm estimation .",
    "here is a new scheme for estimating norms , which uses much fewer samples than the original one and still achieves good estimation .",
    "it can ultimately be used to find the significant mode in conjunction with group testing and msb , below .",
    "[ alg : norm ] estimate norms input : signal @xmath3 , failure probability @xmath71 .",
    "1 .   initialize : the number of samples : @xmath194 .",
    "2 .   take @xmath195 independent random samples from the signal @xmath3 : @xmath196 , where @xmath195 is a multiple of 5 .",
    "return @xmath197 `` 60-th percentile of '' @xmath198 .",
    "the following lemma presents the theoretical analysis of this algorithm .",
    "[ lem : norm ] if a signal @xmath3 is @xmath199 pure , the number of samples @xmath200 , the output of algorithm _ [ alg : norm ] _ gives an estimation @xmath201 of its energy which exceeds @xmath202 with probability exceeding @xmath8 .    without loss of generality ,",
    "suppose that @xmath203 .",
    "suppose the signal @xmath204 , where @xmath205 , and @xmath206 and @xmath207 are orthogonal .",
    "we shall sample the signal @xmath3 independently for @xmath195 times , as stated in algorithm [ alg : norm ] .",
    "note that we do not impose that samples be taken at different time positions ; with very small probability , the samples could coincide .",
    "let @xmath208 . hence , for any @xmath209",
    ", we have @xmath210 . also by the purity of @xmath3",
    ", we have @xmath211 . since @xmath212 , we obtain @xmath213 then for any @xmath209",
    ", @xmath214 therefore , @xmath215 it follows that @xmath216 let @xmath217 ; the above inequality becomes @xmath218 .",
    "+ consider now the characteristic function @xmath61 of the set @xmath62 , @xmath219 and define the random variable @xmath220 as @xmath221 , where @xmath222 is picked randomly .",
    "then we have @xmath223 and @xmath224 suppose now we sample the signal @xmath3 @xmath195 times independently , and obtain @xmath225 , where @xmath226 $ ] .",
    "take the percentile of the numbers @xmath227 . by chernoff",
    "s standard argument , we have for @xmath228 @xmath229^r.\\end{aligned}\\ ] ] take @xmath230 , then @xmath231 the right hand side of ( [ eq : norm ] ) is increasing in @xmath232 on the interval @xmath233 $ ] ; since @xmath234 , we obtain an upper bound by substituting 0.403 for @xmath232:@xmath235^r = \\left [ 1.96 \\alpha^{0.6 } ( 1-\\alpha)^{0.4 } \\right ] ^r \\leq e^{-0.08r}.\\end{aligned}\\ ] ] so for @xmath236 , we have @xmath237    in practice , we often generate signals that are not so pure and thus need more samples for norm estimation .",
    "although the estimation is sometimes pretty far away from the true value , it gives a rough idea of where the significant mode might be .",
    "when we desire more accuracy , a smaller constant @xmath238 in the number of samples @xmath239 is chosen . in the statement of the algorithm",
    ", we choose @xmath195 to be a multiple of 5 , so that the percentile would be well - defined . in practice",
    ", it works equally well to take @xmath195 that are not multiples of 5 and to round down , taking the @xmath240-th sample in an increasingly ordered set of samples .",
    "we shall also need an upper bound on the outcome of algorithm [ alg : norm ] , which should hold regardless of whether the signal @xmath3 is highly pure or not .",
    "this is provided by the next lemma , which proves that for general signals , algorithm [ alg : norm ] produces an estimation of the energy , that is less than @xmath241 with high probability .",
    "[ lem : norm2 ] suppose algorithm [ alg : norm ] generates an estimation @xmath201 for @xmath242 , then @xmath243    suppose @xmath195 independent random samples are @xmath244 , then @xmath245 since @xmath201 is the 60-th percentile of the sequence @xmath246 , with @xmath247 , @xmath248      isolation processes a signal @xmath3 and returns a new signal with significant frequency @xmath37 , with 98@xmath65 of the energy concentrated on this mode .",
    "a frequency @xmath37 is called `` significant '' for @xmath3 , if @xmath249 , where @xmath38 is a threshold , fixed by the implementation , which may be fairly small .",
    "more precisely , the isolation step returns a series of signals @xmath250 , such that , with high probability , @xmath251 for some @xmath252 , that is , at least one of the @xmath250 is @xmath253 pure .    typically , not all of the @xmath254s are pure .",
    "we shall nevertheless apply the further steps of the algorithm to each of the @xmath254s , since we do nt know which one is pure .",
    "an impure @xmath254 may lead to a meaningless value for the putative mode @xmath255 located in @xmath254 .",
    "this is detected by the computation of the corresponding coefficients : only when the coefficient corresponding to a mode is significant do we output the mode and its coefficient .",
    "some impure signals might output an insignificant mode .",
    "hence , we estimate and compare their coefficients to check the significance of the modes . finally , we only output the modes with significant coefficients .",
    "the discussion in @xcite proposes a b - tap box - car filter in the time domain , which corresponds to a dirichlet filter with width @xmath256 in the frequency domain .",
    "the whole frequency region would be covered by random dilation and translations of this filter .",
    "notation : as in @xcite , we define a box - car filter @xmath257 as @xmath258}$ ] , where @xmath259 .    1 .   for all @xmath260 , @xmath261 2 .",
    "notation : @xmath262 in the time domain , which is equivalent to a shift of @xmath263 by @xmath264 in the frequency domain .",
    "notation : define @xmath265 by @xmath266 , so that @xmath267 . , where @xmath268 is a dilation and shift operator in the frequency domain .",
    "more detailed description of the box - car filter can be found in @xcite .",
    "the isolation procedure in @xcite randomly permutes the signal @xmath3 and then convolves it with a shifted version of @xmath269 to get a series of new signals @xmath270 , where @xmath271 .",
    "this scheme does not work well in practice . in the new version of the isolation steps",
    ", each @xmath272 corresponds to different randomly generated dilation and modulation factors , with @xmath273 , the parameters @xmath274 and @xmath4 are relatively prime .",
    "these factors are taken at random between 0 and @xmath275 .",
    "the following lemma is similar to lemma 8 in @xcite for the new isolation step , with more explicit values of the parameters .    _",
    "@xcite _ let a signal @xmath3 and a number @xmath38 be given , and create @xmath276 new signals : @xmath277 with @xmath278 , where @xmath279 . if @xmath280 , then for each @xmath37 such that @xmath39 , there exists some @xmath252 such that with high probability @xmath8 , the new signal @xmath281 is @xmath253 pure .",
    "suppose @xmath282 falls into the pass region of the @xmath257 filter , i.e. , that @xmath283 .",
    "we know that @xmath284 so that @xmath285 , of @xmath286 .",
    "since @xmath287 is greater than the average value of @xmath288 , we have @xmath289 moreover , @xmath290 . in particular , @xmath291 if @xmath292 .",
    "we then have @xmath293\\leq\\frac{(1-\\eta)\\| s\\|^{2}}{2k+1}.\\ ] ] define @xmath201 to be the random variable @xmath294 for this random variable , we have @xmath295 since @xmath280 , the right hand side of ( 4.37 ) is @xmath296 , meaning that the signal @xmath281 is 98@xmath65 pure with probability @xmath297 . the success probability , i.e.",
    ", the probability of obtaining at least one @xmath281 that is 98@xmath65 pure , can be boosted from @xmath298 to probability @xmath8 by repeating @xmath299 times , i.e. , generating @xmath299 signals .",
    "the above lemma gives a lower bound for the filter width .",
    "obviously , the larger the width in the time domain , the higher the probability that the frequency will be successfully isolated .",
    "however , a larger width leads to more evaluations of the function and therefore more time for each isolation step .",
    "one needs to balance carefully between the computational time for each iteration step and the total number of iterations .",
    "based on several numerical experiments , we found that a very narrow filter is preferable and gives good performance ; for instance , the filter with three - tap width , i.e. , @xmath300 works best for a signal with 2 modes .",
    "for the choice @xmath301 , the algorithm ends after fewer iterations ; however , each iteration takes much more time .",
    "the choice of a 9-tap width filter makes the code four times slower in total .",
    "the filter width is weakly determined by the number of modes in the signal , not by the length of the signal . through experimentation",
    ", we found that when the number of modes is less than 8 , the 3-tap width filter works very well ; as the number of modes increases , larger width filters are better .",
    "numerical experiments suggests a sublinear relationship between the width of the filter and the number of modes ; in our experiments a 5-tap filter still sufficed for @xmath302 .",
    "after the isolation returns several signals , at least one of which is 98@xmath65 pure with high probability , group testing aims at finding the most significant mode for each .",
    "we use a procedure called most significant bit ( msb ) to approach the mode recursively .    in each msb step",
    ", we use a box - car filter @xmath257 to subdivide the whole region into @xmath303 subregions . by estimating the energies and comparing the estimates for all these new signals",
    ", we find the one with maximum energy , and we exclude those that have estimated energies much smaller than this maximum energy .",
    "we then repeat on the remaining region , a more precisely on the region obtained by removing the largest chain of excluded intervals ; we dilate so that this new region fills the whole original interval , and split again .",
    "the successive outputs of the retained region gives an increasingly good approximation to the dominant frequencies .",
    "the following are the group testing procedures :    [ alg : group]group testing + input : signal @xmath57 , the length @xmath4 of the signal @xmath57 .",
    "+ initialize : set the signal @xmath57 to @xmath304 , iterative step @xmath305 , the length @xmath4 of the signal , the accumulation factor @xmath306 .",
    "+ in the @xmath222th iteration ,    1 .   if @xmath307 , then return 0 . 2 .",
    "find the most significant bit @xmath308 and the number of significant intervals @xmath309 by the procedure msb .",
    "3 .   update @xmath310 , modulate the signal @xmath254 by @xmath311 and dilate it by a factor of @xmath312 . store it in @xmath313 .",
    "4 .   call the group testing again with the new signal @xmath314 , store its result in @xmath315 .",
    "update the accumulation factor @xmath316 .",
    "6 .   if @xmath317 , then @xmath318 . 7 .   return @xmath319 ;    the msb procedure is as follows .",
    "[ alg : msb]msb ( most significant bit ) + input : signal @xmath57 with length @xmath4 , a threshold @xmath320 .    1 .",
    "get a series of new signals @xmath321 , @xmath322 .",
    "that is , each signal @xmath323 concentrates on the pass region @xmath324:=pass_j$ ] .",
    "2 .   estimate the energies @xmath325 of @xmath323 , @xmath322 .",
    "3 .   let @xmath326 be the index for the signal with the maximum energy .",
    "4 .   compare the energies of all other signals with the @xmath326th signal . if @xmath327 , label it as an interval with small energy .",
    "take the center @xmath328 of the longest chain of consecutive small energy intervals , suppose there are @xmath329 intervals altogether in this chain .",
    "the center of the large energy intervals is @xmath330 , the number of intervals with large energy is @xmath331 .",
    "7 .   if @xmath332 , then do the original msb _ @xcite _ to get @xmath308 and set @xmath333 , and @xmath334 .",
    "output the dilation factor @xmath309 and the most significant bit @xmath308 .    given a signal @xmath57 with @xmath335@xmath65 purity ,",
    "suppose @xmath336 .",
    "if @xmath337 , then algorithm _ [ alg : group ] _ can find the significant frequency @xmath37 of the signal @xmath57 with high probability .",
    "suppose the filter width of @xmath257 is @xmath303 .",
    "observe that , for some @xmath252 , @xmath338 , @xmath339 . without loss of generality ,",
    "assume @xmath340 .",
    "now consider the signal @xmath341 .",
    "since @xmath342 , the fourier coefficient @xmath343 satisfies @xmath344 for all @xmath345 .",
    "it follows from lemma [ lem : norm ] , that the output of algorithm [ alg : norm ] , applies to @xmath341 , estimate that is at least @xmath346 on the other hand , now consider @xmath347 . note that @xmath348 also , @xmath349 , because @xmath57 is @xmath253 pure .",
    "thus @xmath350 by lemma [ lem : norm2 ] , if we use algorithm [ alg : norm ] , the estimation result for @xmath347 will be at most @xmath351 with high probability .",
    "it is easy to show that the inequality @xmath352 holds for all @xmath345 .",
    "the same argument applies to @xmath323 with @xmath353 .",
    "it follows that , with high probability , the result of applying algorithm [ alg : norm ] to @xmath341 will give a result that exceeds the result obtained by applying algorithm [ alg : norm ] to @xmath323 with @xmath354 .",
    "in general , if the pass region is at some @xmath355 , we can compare @xmath356with @xmath357for all @xmath358 . if there is some @xmath355",
    "for which the estimation of @xmath356 is apparently larger than @xmath357 , then we conclude @xmath359 ; otherwise , possibly @xmath360 . by the above argument",
    ", we can eliminate @xmath361 consecutive pass regions out of the @xmath362 , leaving a cyclic interval of length at most @xmath363 . in order for the residual region to be smaller or equal to half of the whole region , we need @xmath364 , which is equivalent to the condition @xmath365 .    in the recursive steps ,",
    "let @xmath366 denote a cyclic interval with size at most @xmath363 that includes all the possibilities for @xmath37 .",
    "let @xmath308 denote its center . then generate a new signal @xmath367 ; this is a shift of the spectrum of @xmath57 by @xmath368 .",
    "thus the frequency @xmath369 is the biggest frequency of @xmath370 .",
    ", which is in the range of @xmath371 to @xmath372 .",
    "we will now seek @xmath369 .",
    "since we rule out a fraction of @xmath373 length of the whole region , we may dilate the remainder by @xmath374 , which can be accomplished in the time domain by dilating @xmath375 by @xmath376 .",
    "thus the interval of length just less than @xmath363 known to contain @xmath369 is dilated to the alternate positions in an interval of length just less than @xmath4 .",
    "we then rule out again @xmath377 of this dilated frequency domain , leaving a remainder of length at most @xmath376 length .",
    "then we undo the dilation , getting an interval of length just less than @xmath378 , centered at some @xmath379 , which is the second most significant bit of @xmath37 in a number base @xmath380 .",
    "we would repeat this process to get the other bits of @xmath37 . by getting a series of @xmath381",
    ", we can recover the @xmath37 .",
    "in fact , a narrower filter with a larger shift width than @xmath382 works fine and makes the algorithm faster in practice .",
    "heuristically , we find that the optimal number of taps for small @xmath1 cases is 3 .",
    "suppose the msb filter width is 3 and each msb rules out 2 intervals out of 3 , then the total number of recursive group test is @xmath383 .",
    "then the computational cost is @xmath384 norm estimations and @xmath385 comparisons .",
    "numerical experiments suggests that @xmath260 is probably linear in @xmath386 .",
    "the shift width we use in practice is @xmath387 .",
    "we find that the output of group testing in both the original and the present version of ra@xmath0sfa might differ from the true mode by one place .",
    "we suspect that the reason is that all the float operations and the conversion to integers introduce and accumulate some error into the final frequency . as a solution ,",
    "the coefficients of nearby neighbors are also estimated roughly to determine the true significant modes .      a key issue in the implementation consists of obtaining information ( by sampling ) from a signal after it has been dilated , modulated , or even convolved .",
    "we briefly discuss here how to carry out this sampling in discrete signals .",
    "first , we consider a dilated and modulated signal , for example , in the isolation procedure which uses @xmath388 , which is equivalent to @xmath389 in the frequency domain . here",
    "@xmath98 and @xmath390 are chosen uniformly and randomly , from @xmath391 to @xmath275 for @xmath390 , and from @xmath392 to @xmath275 for @xmath98 .",
    "the sample @xmath393 , where @xmath394,is then @xmath395 , where @xmath396 is chosen so that @xmath397 .",
    "if @xmath4 is prime , then we can always find ( a unique value for ) @xmath398 for arbitrary @xmath98 ; if @xmath4 is not prime , @xmath398 may fail to exist for some choices of @xmath98 .",
    "our program uses the euclidean algorithm to determine @xmath398 ; when @xmath4 is not prime and @xmath98 and @xmath4 are not co - prime , the resulting candidates for @xmath398 are not correct and may lead to estimates for the modes that are incorrect ; these mistakes are detected automatically by the algorithm when it estimates the corresponding coefficient and finds it to be below threshold .",
    "we also need to sample from convolved signals , e.g. @xmath399 .",
    "because @xmath257 has only @xmath303 taps , only @xmath303 points contribute to the calculation of the convolution .",
    "since @xmath400 , we need only the values @xmath401 , @xmath402 , all of which we sample .",
    "the original ra@xmath0sfa discusses only the one dimensional case . as explained earlier , it is of particular interest to extend ra@xmath0sfa to higher dimensional cases because there its advantage over the fft is more pronounced .    in @xmath26 dimensions ,",
    "the fourier basis function is @xmath403 the representation of a signal is @xmath404 suppose the dimension of the signal is @xmath26 , denote @xmath405 , @xmath406 .",
    "the total scheme remains much the same as in one dimension :    [ alg : twodim]total scheme in @xmath26 dimensions + input : signal @xmath3 , the number of nonzero modes @xmath1 or its upper bound , accuracy factor @xmath44 , success probability @xmath8 , an upper bound of the signal energy @xmath35 , the standard deviation of the white gaussian noise @xmath98 .    1 .",
    "initialize the representation signal @xmath2 to 0 , set the maximum number of iterations @xmath100 , .",
    "2 .   test whether @xmath101 .",
    "if yes , return the representation signal @xmath2 and the whole algorithm ends ; else go to step 3 .",
    "3 .   locate fourier modes @xmath407 for the signal @xmath102 by the new isolation and group test procedures .",
    "estimate fourier coefficients at @xmath407 : @xmath408 .",
    "5 .   if the total number of iterations is less than @xmath62 , go to 2 ; else return the representation @xmath2 .    the most important modification with respect to the one dimensional case lies in the procedure to carry out step 3 of algorithm [ alg : twodim ] .",
    "we adapt the technique for frequency identification to fit the high dimensional case ; it is given by the following procedure .",
    "locate the fourier mode in @xmath26 dimensions[locate2d ] input : signal @xmath3 , accuracy factor @xmath44 , success probability @xmath8 , an upper bound of the signal energy @xmath35 .    1 .   random permutations in d dimension .",
    "2 .   isolate in one ( arbitrarily picked ) dimension @xmath222 to get a new signal @xmath409 .",
    "3 .   for each dimension",
    "@xmath410 , find the @xmath410th component @xmath411 of the significant frequency by group testing for the signal @xmath57 in the @xmath410th dimension .",
    "4 .   finally , estimate the fourier coefficients in the frequency @xmath412 .",
    "keep the frequency d - tuple if its fourier coefficient is large .",
    "note that the computational cost of the above algorithm is quadratic in the number of dimensions .",
    "the permutation involves a @xmath413 matrix dimensions our 1-dimensional practice of checking not only the central frequency found , but also nearby neighbors , would make this algorithm exponential in @xmath26 , which is acceptable for small @xmath26 . for large @xmath26 , we expect it would suffice to check a fixed number of randomly picked nearby neighbors , removing the exponential nature of this technical feature . ]",
    "the group test procedure in each dimension processes the _",
    "same _ isolation signal .",
    "if a filter with @xmath1 taps is used for the isolation , then it captures at least one significant frequency in the pass region with probability @xmath414 .",
    "the basic idea behind this procedure is that , because of the sparseness of the fourier representation , cutting the frequency domain into slices of width @xmath414 in 1 dimension , leaving the other dimensions untouched , leads to , with positive probability , a separation of the important modes into different slices .",
    "after this essentially 1-dimensional isolation , we only need to identify the coordinates of the isolated frequency mode .",
    "after isolation , we assume @xmath415 , where @xmath416 and @xmath407 are unknown . to find @xmath417 , we sample in the @xmath418-th coordinate only , keeping @xmath419 fixed , so that ( for this step ) @xmath420 can be viewed as @xmath421 , where @xmath422 , remains the same for different @xmath423 and has the same absolute value as @xmath416 , which we can do in each dimension separately by the following argument .",
    "if we just repeated the 1-dimensional technique in each dimension , that is , carried out isolation in each of the @xmath26 dimensions sequentially , the time cost would be exponential in the dimension @xmath26 .",
    "we discuss now in some detail the steps 1 , 2 , 3 of algorithm [ locate2d ] .      in one dimensional ra@xmath0sfa ,",
    "the isolation part includes random permutations and the construction of signals with one frequency dominant .",
    "however , the situation is more complicated in higher dimensions , which is why we separated out the permutation step in the algorithm .",
    "recall that in one dimension , the signal is dilated and modulated randomly in order to separate possibly neighboring frequencies . in higher dimensions",
    ", different modes can have identical coordinates in some of the dimensions ; they would continue to coincide in these dimensions if we just applied `` diagonal '' dilation , i.e. , if we carried out dilation and modulation sequentially in the different dimensions . to separate such modes ,",
    "we need to use random matrices .",
    "we transform any point @xmath424 into @xmath425 given by @xmath426 where @xmath427 is a random and invertible matrix , the @xmath428 and the @xmath429 are chosen randomly , uniformly and independently , and the arithmetic is modulo @xmath4 .",
    "for example , if @xmath430 , that is , @xmath431 the point @xmath432 gets mapped to @xmath433 , @xmath434 to @xmath435 , and @xmath436 to @xmath437 : even though points @xmath432 and @xmath434 have the same first coordinate , their images do nt share a coordinate ; the same happens with points @xmath434 and @xmath436 . for each dimension",
    "@xmath410 , the @xmath410th components of frequencies are mapped by pairwise independent permutations .",
    "even adjacent points that differ in only one coordinate are destined to be separate with high probability after these random permutations .",
    "after the random permutations , the high dimensional version of isolation can construct a sequence @xmath438 of signals , such that , for some j , @xmath439 .",
    "[ alg : twodimiso]high dimensional isolation + choose an arbitrary dimension @xmath222",
    ".    1 .   filter on the dimension @xmath222 and leave all other dimensions alone , get the signal @xmath440 where @xmath441}$ ] filters on the dimension @xmath222 ; the other dimensions are not affected .",
    "output new signals @xmath57 to be used in the group testing .",
    "after the random permutation and isolation , we expect a @xmath26-dimensional signal with most of its energy concentrated on one mode .",
    "the isolation step effectively separates the @xmath26-dimensional frequency domain in a number of @xmath26-dimensional slices .",
    "group testing has to subdivide these slices .",
    "one naive method is to apply @xmath26 dimensional filters in group testing , concentrating on @xmath26-dimensional cubic subregions in group testing that cover the whole area .",
    "however , this leads to more cost .",
    "if the number of taps of this filter in one dimension is @xmath303 , we obtain @xmath442 subregions . estimating the energies of all subregions slows down the total running time .",
    "consequently we instead locate each component of the significant frequency label separately .",
    "that is , we only use a filter to focus on one dimension and leave other dimensions alone .",
    "the energy of @xmath303 regions are computed in every dimension .",
    "hence , we need to estimate the norm of @xmath443 intervals in total .",
    "this makes group testing linear in the number of dimensions , instead of exponential as in the naive method .",
    "here is the procedure in group test :    [ alg : twodimgroup]high dimensional group test + for @xmath444    1 .",
    "construct signals @xmath445 , @xmath446 , where @xmath447 filters on @xmath410th dimension and leave all other dimensions alone ; 2 .",
    "estimate and compare the energy of each @xmath448 , @xmath446 , use the similar procedure in one dimensional group testing procedure . find the candidates @xmath449 .",
    "the reader may wonder how sampling works out for this @xmath26-dimensional algorithm . in algorithm",
    "[ alg : twodimgroup ] , we will need to sample @xmath450 ( which is the convolution of the ( permuted version of ) signal @xmath3 with 2 filters ) to estimate its energy ; because filtering is done only in the @xmath410-th dimension , we shall sample @xmath451 for different @xmath452 , but keeping the other @xmath453 fixed , where @xmath454 .",
    "the signal @xmath57 itself comes from the isolation step , in which we filter in direction @xmath222 , for which @xmath3 needs to be sampled , in this dimension only . together",
    ", for each choices @xmath410 in algorithm [ alg : twodimiso ] and [ alg : twodimgroup ] , this implies we have @xmath455 different samples of ( the permuted version of ) @xmath3 , in which all but the @xmath222th coordinates of the samples @xmath456 are identical .",
    "we provide both theoretical and experimental evidence to support the advantage of the implementation of ra@xmath0sfa proposed here over the original one sketched in @xcite .",
    "moreover , we extend ra@xmath0sfa to high dimensional cases . for functions with few , dominant fourier modes , ra@xmath0sfa outperforms the fft as @xmath4 increases .",
    "we expect that ra@xmath0sfa will be useful as a substitute for the fft in potential applications that require processing such sparse signals or computing @xmath1-term approximations .",
    "this paper is just the beginning of a series of our papers and researches , many of which are in preparation . for example , the strong dependence of running time on the number of modes @xmath1 will be further lessened , and thus the algorithm would work for more interesting signals @xcite . also , the application of ra@xmath0sfa in multiscale problems will be discussed in @xcite .",
    "for discussions that were a great help , we would like to thank bjorn engquist , weinan e , olof runborg , and josko plazonic ."
  ],
  "abstract_text": [
    "<S> we analyze a sublinear ra@xmath0sfa ( randomized algorithm for sparse fourier analysis ) that finds a near - optimal @xmath1-term sparse representation @xmath2 for a given discrete signal @xmath3 of length @xmath4 , in time and space @xmath5 , following the approach given in @xcite . </S>",
    "<S> its time cost @xmath6 should be compared with the superlinear @xmath7 time requirement of the fast fourier transform ( fft ) . </S>",
    "<S> a straightforward implementation of the ra@xmath0sfa , as presented in the theoretical paper @xcite , turns out to be very slow in practice . </S>",
    "<S> our main result is a greatly improved and practical ra@xmath0sfa . </S>",
    "<S> we introduce several new ideas and techniques that speed up the algorithm . </S>",
    "<S> both rigorous and heuristic arguments for parameter choices are presented . </S>",
    "<S> our ra@xmath0sfa constructs , with probability at least @xmath8 , a near - optimal @xmath1-term representation @xmath2 in time @xmath9 such that @xmath10 . </S>",
    "<S> furthermore , this ra@xmath0sfa implementation already beats the fftw for not unreasonably large @xmath4 . </S>",
    "<S> we extend the algorithm to higher dimensional cases both theoretically and numerically . </S>",
    "<S> the crossover point lies at @xmath11 in one dimension , and at @xmath12 for data on a @xmath13 grid in two dimensions for small @xmath1 signals where there is noise .    </S>",
    "<S> ra@xmath0sfa , sparse fourier representation , fast fourier transform , sublinear algorithm , randomized algorithm    65t50 , 68w20 , 42a10 </S>"
  ]
}