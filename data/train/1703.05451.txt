{
  "article_text": [
    "mage categorization has achieved a great progress in the past few years , but it still needs a massive amount of manually labeled data @xcite .",
    "meanwhile , image sub - categorization has been used to improve performance in a wide variety of vision tasks .",
    "for example , object detection @xcite , animal behaviour analysis @xcite and image classification @xcite . subdividing categories into subcategories",
    "multiples the number of labels , aggravating the annotation problem .    with the development of internet",
    ", the number of digital images is growing extremely rapidly .",
    "how to effectively categorize these images has become an increasingly serious        problem .",
    "further , previously defined noun categories usually unable to have a good description for these emerging images , which have a variable appearance , positions , and poses @xcite .",
    "the categories need to be divided into more semantic rich subcategories to cover the finer semantic differences .",
    "imagenet @xcite is an image dataset organized according to the wordnet @xcite hierarchy .",
    "it provides the research community not only with thousands of categories and millions of images , but also with refinement labels in a hierarchy . however , the process of constructing imagenet is both time - consuming and labor - intensive .",
    "for example , it has taken several years to construct the imagenet .",
    "in addition , the imagenet requires the pre - existing expert knowledge wordnet and it only contains the noun subcategories ( e.g. , category  airplane \" ,  dog \" and  bird \" in fig . [ fig1 ] ) , it does not contain the verb subcategories ( e.g. , category  horse \" in fig .",
    "[ fig1 ] ) .    to reduce the cost of manual annotation , automatic methods by exploiting web images for image categorization @xcite have attracted more and more people s attention .",
    "fergus et al . @xcite took the probabilistic latent semantic analysis ( plsa ) technique to automatically select and learn object categories from web images .",
    "hua et al .",
    "@xcite proposed the use of a clustering based method to filter `` group '' noisy images and a propagation - based method to filter individual noisy images .",
    "niu et al .",
    "@xcite proposed to set each latent domain as a  bag \" and the images therein as  instances \" , then image selection and classifier learning are formulated as a multi - instance learning problem .",
    "the advantage of these methods is that the need for manual intervention is eliminated .",
    "unlike these studies , our proposed work simultaneously addresses the issues of image categorization and sub - categorization by levering the general corpus and web images .",
    "there are also few previous works @xcite dealing with the image sub - categorization problem .",
    "mansur et al .",
    "@xcite proposed using probabilistic latent semantic analysis ( plsa ) to find subcategories and these subcategories are based on the similarity of images . in @xcite ,",
    "both of positive and negative images are used to learn subcategories .",
    "particularly , a new model by joint clustering and classification was proposed for discriminative sub - categorization .",
    "wang et al .",
    "@xcite designed a formulation for dictionary learning ( subcategories ) by maximizing classification margins mil .",
    "however , as some of the previous work @xcite , methods @xcite still can not assign semantic refinement labels for the newly discovered subcategories .",
    "ristin et al .",
    "@xcite adopt the framework of random forests and proposed a regularized objective function that takes into account relations between categories and subcategories to improve the classification of subcategories .",
    "unlike previous works , method @xcite can classify images into subcategories , but only noun subcategories .",
    "it is not comprehensive enough for describing the refinement images ( e.g. , category  horse \" in fig .",
    "[ fig1 ] ) . in our work",
    ", we exploit general corpus information and web images for image categorization and sub - categorization",
    ". our proposed approach can not only classify images into noun subcategories , but also into verb , adjective and adverb subcategories .",
    "motivated by the situation described above , we propose a novel automatically web - supervised image categorization and sub - categorization framework . in our work , we mainly consider the following two important issues : 1 ) the labels of subcategories derived from the general corpus usually have noise , how can we select useful labels of subcategories from these noisy labels ; 2 ) the retrieved web images are often associated with inaccurate labels , so the learnt classifiers may be less robust , and the classification performance may be significantly degraded as well , how can we select useful images and learn domain robust classifiers from these noisy web training images .    to find the labels of semantic refinement subcategories , we search the given categories in google books ngram corpus ( gbnc ) @xcite with parts - of - speech ( pos ) , specifically with noun , verb , adjective and adverb .",
    "further , as the labels of subcategories derived from the general corpus tend to have noise , we apply a relevance - based approach for removing noise and selecting the useful labels of subcategories . finally , to cope with label noise of web training images ,",
    "we treat each selected subcategory as a  bag \" and the images therein as  instances \" . in specific , we propose a new multi - class mil formulation to select the images from each bag and learn the classifiers for the categories and subcategories . our aim is to select a subset of images from each bag to represent this bag , such that the training bags from all the categories can be well separated . to verify the superiority of our proposed approach",
    ", we conducted experiments on both image categorization and sub - categorization tasks .",
    "the experimental results demonstrated the superiority of our proposed approach .",
    "the main contributions of this work are summarized as follows :    1 .",
    "compared to existing methods , our proposed framework can not only classify images into noun subcategories , but also into verb , adverb and adjective subcategories . our proposed framework has a better semantic refinement descriptions for the categories .",
    "2 .   to suppress the search error and noisy subcategories ( which are not filtered out ) induced noisy images , we formulate image selection and classifier learning as a multi - class multi - instance learning problem and propose to solve the employed problem by the cutting - plane algorithm .",
    "we propose a new unified objective function to jointly learn the classifiers for categories and subcategories .",
    "our proposed formulation can not only consider the relationship between category and its subcategories , but also consider the relationship between different categories .",
    "thus , the classifiers in our work have a better domain adaptation ability .",
    "the rest of the paper is organized as follows . in section , a brief discussion of related works is given .",
    "section elaborates the proposed framework with the optimization algorithm .",
    "the experimental evaluations and discussions are presented in section .",
    "lastly , the conclusion and future research directions are offered in section .",
    "due to the emergence of imagenet , deep convolutional neural networks ( cnn ) have achieved a great success in image categorization .",
    "however , deep cnns are computationally intensive and require a large number of labeled data .",
    "simpler classifiers like support vector machine ( svm ) @xcite and nearest class mean classifiers ( ncm ) @xcite provide us with another alternative which have much shorter running time and acceptable classification accuracy .",
    "to reduce the cost of manual annotation , some of the previous works also concentrated on the task of  cleaning up \" web images for training data collection .",
    "for example , fergus et al .",
    "@xcite proposed the use of visual classifiers learned from google image search engine to re - rank the images based on the visual consistency .",
    "subsequent methods @xcite have employed similar removing mechanisms to automatically construct clean image datasets for training classifiers . in our work , we focus on another fundamental , yet often ignored , aspect of the problem : we argue that the current poor performance of classification models learned from the web is due to the selected images which may have different distributions with the test images .    our work is also related to the recent works for latent domains discovering methods . in @xcite ,",
    "hoffman et al . proposed using a hierarchical clustering technique to find the feasible        latent domains while @xcite adopt maximum distinctiveness and maximum learnability for different latent domains separation .",
    "xiong et al .",
    "@xcite proposed a squared - loss mutual information based clustering model with category distribution priority in each domain to infer the domain assignment for images .",
    "the difference between our work and @xcite is methods @xcite can not assign the semantic refinement labels to newly discovered latent domains .",
    "all the discovered latent domains still only have the label of the coarse category .",
    "in contrast , our work aims to classify images into categories and subcategories .",
    "all the images in our work will be assigned two labels including coarse category and refinement subcategory . so their motivations and formulations are inherently different from our work .",
    "our work is more related to the recent image sub - categorization works @xcite , which assume several subcategories exist in each category .",
    "however , the subcategories discovered by @xcite still only have the label of the category . refinement labels of subcategories are still unavailable .",
    "ristin et al .",
    "@xcite adopt the framework of random forests and proposed a regularized objective function that takes into account relations between categories and subcategories to improve the classification accuracy .",
    "unlike previous works , method @xcite can classify images into subcategories , but only the noun subcategories .",
    "the reason is that method @xcite relies on expert knowledge wordnet to obtain the semantic refinement subcategories . in our work",
    ", we eliminate the dependency on expert knowledge and propose to exploit general corpus information to obtain the semantic refinement subcategories .",
    "the advantage of our proposed approach is that our method can not only classify images into noun subcategories , but also into verb , adjective and adverb subcategories .",
    "as our approach relies on weakly labeled web images , it is loosely related to the multi - instance learning works @xcite .",
    "method @xcite and @xcite proposed to partition the weakly labeled web images into a set of clusters and each cluster is treated as a  bag \" , the images therein as  instances \" .",
    "correspondingly , different multi - instance learning methods were proposed in @xcite and @xcite . in @xcite ,",
    "andrews et al .",
    "adopt a heuristic way to iteratively train the image classifier and then infer the category labels of these instance images .",
    "method @xcite proposed two convex optimization methods which maximize the margin of concepts via key instance generation at the instance - level and bag - level for locating the regions of interest ( roi ) in the images automatically .",
    "our work is largely inspired by the following work .",
    "a weakly supervised domain robust visual recognition system was recently proposed in @xcite and achieved impressive performance for video event recognition .",
    "niu et al .",
    "@xcite first applied the latent domain discovering method @xcite to find all the latent domains from the training data .",
    "then the multi - instance learning method was leveraged to cope with noise in the labels of web training images .",
    "the main difference from ours is the formation process of the  bags \" .",
    "method @xcite takes the latent domains as  bags \" while our method applies the selected subcategories .",
    "compared to @xcite , our selected  bags \" which derived from the general corpus have strong supervisory information .",
    "this supervisory information can help us to maximize the inter - class variation and simultaneously minimize the intra - class variation .",
    "in addition , as some of the previous works @xcite , only category label can be assigned to images in @xcite while our method can not only assign the category label , but also the refinement labels of subcategories .",
    "we seek to automate the process of classifying images into categories and subcategories by exploiting general corpus information and web images . as shown in fig .",
    "[ fig2 ] , there is a backend subsystem ( classifier building ) and a frontend subsystem ( categories and subcategories classifying ) . for the backend system ,",
    "the input is a category label that we would like to build a classification model for .",
    "then a set of semantically rich subcategories is obtained by searching in gbnc , from which the noisy subcategories are removed . after obtaining the candidate images by retrieving the labels of selected subcategories with image search engine , we treat each selected subcategory as a  bag \" and the images therein as  instances \" . particularly , we formulate image selecting and classifier learning as a multi - class mil problem by selecting a subset of images from each bag to learn the classifiers . the final outputs of the backend system are ( 1 ) a classifier ( e.g. ,  dog \" ) representing the category ; ( 2 ) a set of classifiers ( e.g ,  golden dog \" ,  fluffy dog \" and  eskimo dog \" ) corresponding to subcategories .",
    "the input of frontend is a set of images which will be given two labels including category and semantic refinement subcategories .",
    "inspired by recent works @xcite , we can use google books ngram english 2012 corpus to discover the labels of semantic refinement subcategories for modifying the given category .",
    "our motivation is to find not only the semantically rich noun subcategories , but also verb , adjective and adverb subcategories .",
    "compared to the expert knowledge wordnet and conceptnet which only have noun subcategories , ngram data is much more general and exhaustive .",
    "following @xcite ( see section 4.3 ) , we specifically use the dependency gram data with parts - of - speech ( pos ) for refinement subcategories discovering .",
    "for example , given a parent category and its corresponding pos tag ( e.g. , ` jumping , verb ' ) , we find all its occurrences annotated with pos tag within the dependency gram data .",
    "of all the ngram dependencies retrieved for the given category , we choose those whose modifiers are tagged as noun , verb , adjective and adverb as the candidate subcategories .",
    "we utilize these semantic refinement subcategories ( corresponding images ) to reflect the different visual distributions of the category .",
    "the detailed subcategories discovered in this step can be found on website https://1drv.ms/f/s!ahpq3qsttg8nsxyjgsle2kjgcvtv .",
    "horse &    .examples of the candidate subcategories discovered by our approach .",
    "[ cols= \" < \" , ]      +    [ tab1 ]      not all the discovered subcategories are useful , some noise may also be included ( e.g. , the bold subcategories in table [ tab1 ] ) . using these noisy subcategories to retrieve images for",
    "the category will have a negative effect on the accuracy and robustness of the classifier .",
    "to this end , we first remove these noisy subcategories before we select images and train classifiers for the category and subcategories .",
    "we retrieve the top @xmath0 images from image search engine for each candidate subcategory to represent their visual distributions . by analyzing the text semantics and visual distributions presented by these subcategories , we choose the following features to separate the useful subcategories from noise .      from the visual relevance perspective",
    ", we want to eliminate visually less relevant subcategories ( e.g. ,  wood horse \" ,  paper boat \" ) .",
    "the intuition is that relevant subcategories should have a relatively small inter - visual distance to its parent category and other relevant subcategories .",
    "we denote each image as @xmath1 and the compound feature @xmath2 of @xmath0 images in each subcategory to represent visual distribution of this subcategory .",
    "suppose a parent category @xmath3 has @xmath4 subcategories , then we will have @xmath5 inter - visual distances between subcategories .",
    "we calculate the minimum , maximum , average and standard deviation of the inter - visual distances between subcategories . besides , we also calculate the inter - visual distance between subcategory and its parent category .",
    "particularly , we denote these inter - visual distances by @xmath6 and normalize these distances to a number in [ 0,1 ] by : @xmath7    from the visual consistency perspective , we want to keep visually salient and eliminate non - salient subcategories ( e.g. ,  missing cat \" ,  betting horse \" ) .",
    "the intuition is that visually salient subcategories have small intra - visual distance and exhibit predictable visual patterns . for the @xmath0 images in each subcategory ,",
    "we calculate the @xmath8 intra - visual distance among these @xmath0 images .",
    "we obtain the minimal , maximal , average and standard deviation of intra - visual distance like how we generate the inter - visual distance .",
    "similarly , we normalize this intra - visual distances .    from the semantic relevance perspective , we want to remove semantically less relevant subcategories ( e.g. , ",
    "tang horse \" ,  metal dog \" ) .",
    "the intuition is that relevant subcategories tend to have a relatively small semantic distance to the parent category .",
    "normalized google distance ( ngd ) constructs a method to extract semantic similarity distance from the world wide web ( www ) using google page counts @xcite . for a search term @xmath9 and search term @xmath10 ,",
    "ngd is defined by : @xmath11 where @xmath12 denotes the number of pages containing @xmath9 , @xmath13 denotes the number of pages containing both @xmath9 and @xmath10 and @xmath4 is the total number of web pages searched by google .    in general",
    ", we derive the following features to separate the useful subcategories from noise :    @xmath14 normalized google distance between subcategory and its parent category    @xmath14 normalized visual distance between subcategory and its parent category    @xmath14 normalized minimum , maximum , average and standard deviation of the inter - visual distance between subcategory and other subcategories    @xmath14 normalized minimum , maximum , average and standard deviation of the intra - visual distance between different images in subcategory      after deriving the selected features , we train a classifier to determine whether or not a subcategory should be selected .",
    "to train this classifier , we label a set of subcategories and this labeling work only needs to be done once for all categories .",
    "this classifier can be , for example , support vector machine ( svm ) based ( which is also the one we used in our paper ) , decision tree based , etc .",
    "although svm is not the prevailing state - of - the - art method for classification , we find our approach to be effective in pruning noisy subcategories .",
    "although the google image search engine has ranked the returned images , some noisy images may still be included .",
    "in addition , a few noisy subcategories which are not filtered out may also induce some noise . to this end",
    ", we propose our web - supervised multi - class mil model for noisy images removing and domain robust classifiers learning .    for ease of presentation",
    ", we denote each instance as @xmath15 with its label @xmath16 and each bag @xmath17 with the label @xmath18 .",
    "a matrix / vector is denoted by a uppercase / lowercase letter in boldface and the element - wise product between two matrices is represented by @xmath19 .",
    "we also define the identity matrix as @xmath20 and @xmath21 , @xmath22 @xmath23 denote the column vectors of all zeros and ones , respectively .",
    "the transpose of a vector or matrix is represented by @xmath24 .",
    "the inequality @xmath25^\\top \\geq \\mathbf{0}$ ] means that @xmath26 for _ i _",
    "= 1, ... ,_n_. the indicator function is represented as @xmath27 , where @xmath28 if @xmath29 , and @xmath30 , otherwise .",
    "since the retrieved web images may contain noise , we need to remove noise and select appropriate samples to train robust classifiers . to this end",
    ", a binary indicator @xmath31 is used to indicate whether or not training instance @xmath15 is selected . to be exact , @xmath32 when @xmath15 is selected , and @xmath33 otherwise . since the precision of images returned from the google image search engine tends to have a relatively high accuracy ,",
    "we define each positive bag as at least having a portion of @xmath34 positive instances .",
    "the value of @xmath34 can be estimated from some prior knowledge @xcite .",
    "we define @xmath35^{\\top}$ ] as the indicator vector , and use @xmath36 to represent the feasible set of @xmath37 , where @xmath38 represents the set of instance indices in @xmath39 , and @xmath40 denotes the cardinality of @xmath39 .",
    "we assume there are @xmath4 retrieved web images coming from @xmath41 categories and @xmath42 subcategories .",
    "@xmath43 is a binary indicator variable and takes the value of 1 when @xmath15 belongs to the _ s_-th subcategory , and 0 otherwise .",
    "we denote @xmath44 as the number of web training images from the _ s_-th subcategories .",
    "based on mil @xcite , we propose our multi - class mil formulation as follows : @xmath45 @xmath46 where @xmath47 is a tradeoff parameter , @xmath48 are slack variables and @xmath49 is the feature mapping function .",
    "@xmath50 is the probability that the _",
    "i_-th training sample comes from the _ s_-th subcategories .",
    "it can be obtained by calculate @xmath51 .",
    "the explanation for constraint is that we force the total decision value ( obtained by using the classifier for its own category ) to be larger than those obtained by using the classifier for other categories .",
    "the motivation is we want to reduce the bag - level loss by removing the noise and identifying the good instances within training bags .",
    "problem is a non - convex mixed integer problem and is hard to solve directly .",
    "inspired by recent works @xcite , we can relax the dual form of as a multiple kernel learning ( mkl ) problem which is much easier to solve .",
    "the derivations of to its below dual form is provided in the appendix a : @xmath52 @xmath53 and @xmath54 is a vector containing dual variables @xmath55 .",
    "@xmath56 is a vector , in which @xmath57 if @xmath58 and @xmath59 otherwise .",
    "each element in matrix @xmath60 can be calculated through : @xmath61 .",
    "problem is a mixed integer programming problem and is hard to directly optimize the indicator vector * h*. inspired by recent work @xcite , we can find the coefficients of @xmath62 . for consistent presentation , we denote @xmath63^{\\top}$ ] , @xmath64 and the feasible set of @xmath65 and * d * as @xmath66 and @xmath67 , respectively",
    ". then we can get the following optimization problem : @xmath68 when we set the base kernel as @xmath69 , the above problem is similar to the mkl dual form and we are able to solve it on its primal form , which is a convex optimization problem : @xmath70 @xmath71 where @xmath72 is the feature mapping function induced by @xmath73 .",
    "the derivations of is the dual form of are provided in the appendix b. in the next , we will give a solution to .",
    "we solve the convex problem in by updating @xmath74 and @xmath75 in an alternative way .",
    "@xmath14 @xmath76 * d * : we firstly fix @xmath75 to solve * d*. by introducing a dual variable @xmath77 for constraint @xmath78 , the lagrangian form of can be derived as : @xmath79    through set the derivative of with respect to @xmath80 as zero , we can get : @xmath81 for parameter @xmath82 , @xmath83 is monotonically decreasing .",
    "in addition , parameter @xmath84 satisfy @xmath85 .",
    "therefore , we can use binary search method to solve @xmath82 and recover @xmath84 according to .",
    "@xmath14 @xmath76 @xmath86 : when @xmath87 is fixed , @xmath86 can be obtained by solving @xmath88 in .",
    "problem is a quadratic programming problem w.r.t @xmath88 .",
    "since there are @xmath89 variables in our problem , it is time - consuming to employ the existing quadratic programming solvers .",
    "inspired by recent works @xcite , we apply the cutting - plane algorithm @xcite to solve this quadratic programming problem .",
    "we start from a small number of base kernels and at each iteration we add a new violating base kernel .",
    "therefore , only a small set of @xmath37 need to be solved at each iteration and the whole problem can be optimized more effectively . by setting the derivatives of with respect to @xmath90 as zeros ,",
    "can be rewritten as : @xmath91    we solve by solving @xmath92 with only one constraint at the first , then add a new violating constraint iteratively .",
    "particularly , since each constraint is associated with an @xmath93 , we can obtain the most violated constraint by optimizing : @xmath94 after a simple derivation , we can rewrite as : @xmath95 where @xmath96 for @xmath97 and @xmath98 .",
    "problem can be solved approximately through enumerate the binary indicator vector @xmath37 in     + auto - labelled image bags @xmath99 , initialize @xmath100 for all @xmath101 in selected bags @xmath102 .",
    "+ set @xmath103 and @xmath104 ; + * repeat * + @xmath105 ; + compute mkl to solve @xmath106 and in based on _ c _ ; + //_find the most violating @xmath93 _ + * for * each bag @xmath107 fix the labelling of instances in all other bags ; enumerate the candidates of @xmath108 in @xmath107 ; + find the optimal @xmath109 by maximizing ; + * end * @xmath110 lines 6 - 10 @xmath111 there is no change in * h * ; add the most violating @xmath93 to the violation set @xmath112 + @xmath113 ; + * until * the objective of converges .",
    "+   + the learnt image classifier _",
    "f_(x ) .",
    "[ alg ]    a bag by bag fashion iteratively to maximize until there is no change in @xmath37 .",
    "the detailed solutions of cut - plane algorithm for our web - supervised multi - class multi - instance learning model are described in algorithm 1 .",
    "since the visual distributions of the training samples from same category or subcategory are generally more similar than different categories and subcategories , we train one classifier for each category and each subcategory . in general , a total of @xmath114 classifiers @xmath115 will be learned .",
    "@xmath116 ( for better representation , we omit the bias term here ) represents the classifier of the _ s_-th subcategory and the _ c_-th category . the decision function for category @xmath117",
    "is obtained by integrating the learned classifiers from multiple subcategories : @xmath118 .    given a testing image * x",
    "* , we want to find the labels of the most matched subcategory and category , whose classifier achieves the largest decision value from all the subcategories and categories respectively . thus , the subcategory label of image * x * can be predicted by : @xmath119 and the category label by : @xmath120    in summary , to suppress the search error induced noisy images , we propose a multi - class mil model to select a subset of training images from selected bags and simultaneously learning the optimal classifiers based on this selected images .",
    "in this section , we first conduct experiments on both image categorization and sub - categorization to demonstrate the superiority of our proposed approach . then we quantitative analyse the role of different steps contributing to the final results .",
    "in addition , we also analyse the parameter sensitivity and time complexity of our proposed approach in this section .",
    "the goal of this experiment is to compare the image categorization ability of our proposed approach with other related works .",
    "we follow the setting in @xcite and exploit web images as the training set , human - labelled images as the testing set .",
    "particularly , we evaluate the performance on the following dataset :    @xmath14 pascal voc 2007 @xcite .",
    "the pascal voc 2007 dataset contains 9963 images in 20 categories .",
    "each category has training / validation data and test data . for this experiment",
    ", we only use the test data in pascal voc 2007 as the benchmark testing set .",
    "the detailed number of images for each category in this experiment is shown in table [ tab_new1 ] .",
    "@xmath14 stl-10 @xcite .",
    "the stl-10 dataset has ten categories , and each category of which contains 500 training images and 800 test images .",
    "all of the images in stl-10 are color 96 @xmath121 96 pixels .",
    "we also use the test images in stl-10 as the benchmark testing set .",
    "@xmath14 cifar-10 @xcite .",
    "the cifar-10 dataset consists of 60000 32@xmath12132 images in 10 categories , with 6000 images per category , of which 5000 are training images and 1000 are test images .",
    "similarly , we only use the test images in cifar-10 as the benchmark testing set .    for each category",
    ", we first obtain the semantic refinement subcategories by searching in the google books ngram corpus .",
    "then we retrieve the top 100 images from the google image search engine for each candidate subcategory to represent its visual distribution .",
    "particularly , we have released the discovered candidate subcategories and retrieved images for all the candidate subcategories on website https://1drv.ms/f/s!ahpq3qsttg8nsxyjgsle2kjgcvtv .",
    "we calculate the normalized google distance between subcategory and its parent category .",
    "we obtain the center of each subcategory by using the k - means clustering algorithm @xcite ( k=1 ) , then we calculate the normalized visual distance ( euclidean distance ) between subcategory and its parent category ; calculate the normalized minimum , maximum , average and standard deviation of inter visual distance between subcategory and other subcategories ; calculate the normalized minimum , maximum , average and standard deviation of intra - visual distance between different images in subcategory .",
    "we label a set of 500 positive samples and 500 negative samples to learn the linear svm classifier for removing noisy subcategories and selecting useful subcategories .",
    "after we obtain the selected subcategories , the first @xmath122 images were selected for constructing the positive bags     * number * + aero & 204 & tabl & 190 + bicycle & 239 & dog & 418 + bird & 282 & horse & 274 + boat & 172 & mbike & 222 + bottle & 212 & person & 2007 + bus & 174 & plant & 224 + car & 721 & sheep & 97 + cat & 322 & sofa & 223 + chair & 417 & train & 259 + cow & 127 & tv & 229 +    [ tab_new1 ]    which corresponding to the selected subcategories .",
    "negative bags can be obtained by randomly sampling a few irrelevant images . by treating each selected subcategory as a  bag \" and the images therein as  instances \" , we formulate a multi - class mil method to select a subset of training images from each bag and simultaneously learning the optimal classifiers based on the selected images .",
    "particularly , we define each positive bag as having at least a portion of @xmath123 positive instances and set the tradeoff parameter @xmath124",
    ". we will discuss the parameter setting more details in section iv - d . to compare with other baseline methods , we evenly select 500 images from positive bags for each category as the training set .",
    "for this experiment , the feature is dense hog @xcite .      in order to quantify the performance of our proposed approach , four set of weakly supervised or web - supervised baselines are selected to compare with our proposed approach :    @xmath14 svm method .",
    "the svm method includes multi - class svm @xcite . for the multi - class svm ,",
    "the 500 training images for each category are directly retrieved from the image search engine with the category label .",
    "@xmath14 mil methods .",
    "the mil methods contain instance level method mi - svm @xcite and bag level method smil @xcite .",
    "for method mi - svm , the training images are also retrieved from the image search engine .",
    "particularly , we take the proposed heuristic way to iteratively select 500 images for each category and train the image classifier . for method smil , we firstly retrieve the candidate images from the image search engine , then we partition the candidate images into a set of clusters .",
    "each cluster is treated as a  bag \" and the images therein as  instances \" . correspondingly , we take the proposed mil method to select the 500 training images for each category and train the image classifier .         & & +    & airplane & bird & car & cat & deer & dog & horse & monkey & ship & truck & + multi - svm & 0.497 & 0.193 & 0.384 & 0.222 & 0.467 & 0.293 & 0.534 & 0.355 & 0.443 & 0.348 & 0.374 + smil & 0.526 & 0.221 & 0.433 & 0.285 & 0.504 & 0.339 & 0.593 & 0.427 & 0.523 & 0.381 & 0.423 +",
    "mi - svm & 0.531 & 0.242 & 0.464 & 0.283 & 0.528 & 0.346 & * 0.642 * & 0.404 & 0.547 & * 0.482 * & 0.444 + dld - mda & 0.549 & 0.265 & 0.483 & 0.335 & 0.542 & 0.363 & 0.613 & 0.477 & 0.556 & 0.434 & 0.461 + rvd - da & 0.557 & 0.271 & 0.488 & 0.326 & 0.547 & 0.352 & 0.608 & 0.484 & 0.567 & 0.446 & 0.458 + sub - cate & 0.553 & * 0.294 * & 0.482 & 0.331 & 0.535 & 0.354 & 0.616 & 0.456 & 0.550 & 0.443 & 0.465 + rncmf & 0.573 & 0.271 & 0.486 & 0.336 & 0.562 & 0.371 & 0.613 & 0.463 & 0.553 & 0.446 & 0.467 + ours & * 0.596 * & 0.284 & * 0.516 * & * 0.366 * & * 0.582 * & * 0.397 * & 0.636 & * 0.502 * & * 0.582 * & 0.473 & * 0.493 * +    [ tab2 ]     & & +    & airplane & car & bird & cat & deer & dog & frog & horse & ship & truck & + multi - svm & 0.397 & 0.304 & 0.094 & 0.163 & 0.345 & 0.264 & 0.153 & 0.423 & 0.342 & 0.277 & 0.276 + smil & 0.423 & 0.302 & 0.073 & 0.241 & 0.352 & 0.285 & 0.201 & 0.453 & 0.325 & 0.271 & 0.293 + mi - svm & 0.422 & 0.328 & 0.103 & 0.232 & 0.354 & 0.323 & 0.203 & 0.414 & 0.372 & 0.274 & 0.302 + dld - mda & 0.451 & 0.293 & 0.124 & 0.271 & 0.322 & 0.335 & 0.197 & 0.393 & 0.337 & 0.265 & 0.298 + rvd - da & * 0.482 * & 0.322 & 0.124 & 0.284 & 0.353 & 0.343 & 0.204 & 0.424 & 0.363 & 0.285 & 0.314 + sub - cate & 0.433 & 0.303 & * 0.132 * & 0.283 & 0.363 & * 0.352 * & 0.214 & 0.454 & 0.323 & 0.285 & 0.318 + rncmf & 0.411 & 0.315 & 0.124 & 0.314 & 0.444 & 0.343 & 0.208 & 0.464 & 0.342 & 0.295 & 0.326 + ours & 0.452 & * 0.373 * & 0.113 & * 0.342 * & * 0.493 * & 0.322 & * 0.265 * & * 0.502 * & * 0.382 * & * 0.322 * & * 0.357 * +    [ tab3 ]    @xmath14 latent domain discovering methods .",
    "the latent domain discovering methods include two methods dld - mda @xcite and rvd - da@xcite .",
    "for method dld - mda , we firstly obtain the candidate images from the image search engine , then we take the hierarchical clustering technique to find the feasible latent domains . by treating each latent domain as a  bag \" and the images therein as  instances \" , we take the proposed mil method to select 500 images for each category and train the image classifier . for method",
    "rvd - da , after we obtain the candidate images from the image search engine , we take the proposed maximum distinctiveness and maximum learnability to find and separate the latent domains . similarly , we take the proposed mil method to select 500 images for each category and train the image classifier .",
    "@xmath14 sub - categorization methods . the sub - categorization methods sub - cate@xcite and rncmf@xcite are also used to do image categorization . for method sub - cate ,",
    "the candidate images are retrieved from the image search engine .",
    "then we discover the subcategories during these candidate images by joint clustering and classification .",
    "we evenly select 500 images from these subcategories and train image classifiers . for method rncmf",
    ", we also obtain the candidate images from the image search engine .",
    "we take the framework of random forests and the proposed regularized objective function to select 500 images for each category and train the image classier .",
    "for all the baseline methods , there are some parameters to be set in advance .",
    "all the training images for each category are obtained by retrieving from the google image search engine . for the other parameters ,",
    "we adopt the same parameter configuration as described in their original works .",
    "the experimental results are summarized in fig .",
    "[ fig3 ] , table [ tab2 ] and table [ tab3 ] . from the results ,",
    "we make the following observations :    during the 20 categories in pascal voc 2007 , we achieved the best results in 19 categories . in the 10 categories of stl-10 and cifar-10",
    ", we obtained the best results in 7 categories respectively .",
    "in addition , our approach also achieved the best average results on all three datasets .",
    "we observe that the mil learning methods @xcite , the latent domain discovering methods @xcite , the sub - categorization methods @xcite and our method are generally better than svm method @xcite .",
    "one possible explanation is that additional information like  bags \" , latent domains or subcategories are beneficial in web training images for image categorization . in specific , mil learning methods smil and",
    "mi - svm achieve better results than svm method multi - svm on all three datasets .",
    "the explanation is perhaps that it is necessary to remove noisy images from the training set during the process of classifier learning .",
    "learning directly from the web images without noise removing may affect the performance of the classifier due to the presence of noisy images in the training data .",
    "sub - categorization methods rncmf and sub - cate generally perform better than other two latent domains discovering methods dld - mda , rvd - da and other mil , svm baseline methods .",
    "one possible explanation is that classifiers learned from sub - categorization methods which exploiting subcategories to learn integrated classifiers are more domain robust than mil methods , domain discovering methods and svm baseline methods for image categorization .",
    "it is interesting to observe that all classifiers have a relatively poor performance on dataset cifar-10 and stl-10 than on dataset pascal voc 2007 .",
    "the explanation is perhaps that all images in cifar-10 are cut to 32@xmath12132 and in stl-10 are 96@xmath12196 .",
    "objects in these small images are placed in the middle of the image",
    ". however , our web training images and the testing images in pascal voc 2007 are both full size and contain relatively more additional objects or scenes in images .",
    "finally , our proposed approach achieves the best average performance on all three datasets , which demonstrate the superiority of our approach .",
    "the reason is our method simultaneously uses the mil technique for handling label noise in the web training images and exploits multiple subcategories to learn integrated classifiers .",
    "compared to svm method , our method not only removes the noise , but also utilizes subcategories to learn integrated domain robust classifiers .",
    "compared to mil , latent domain discovering and sub - categorization        methods , the multiple subcategories in our method have strong supervisory information which was obtained from the perspective of text semantics ( e.g. , subcategories discovering and noisy subcategories removing ) .",
    "this strong supervisory information can help us to maximize the inter - class variation and simultaneously minimize the intra - class variation .",
    "the objective of this experiment is to compare the image sub - categorization ability of our method with four weakly supervised or web - supervised baseline methods .      for image sub - categorization",
    ", we choose a subset of imagenet as the benchmark dataset for testing different methods .",
    "the reason is that imagenet which constructed according to the wordnet has a hierarchy structure . in particular , we select five categories including  airplane \" ,  bird \" ,  cat \" ,  dog \" and  horse \" as the parent categories and all their leaf synsets as the subcategories .",
    "we are only concerned with the two - tier structure and deeper structure synsets are ignored .",
    "thus , we obtain 5 parent categories and 97 subcategories .",
    "a detailed number of subcategories and corresponding images for each category in imagenet for this experiment can be found in table .",
    "we retrieve the top 100 images for each subcategory from the image search engine as the common original training images .",
    "so we have a total of 9700 training images for 5 parent categories and 97 subcategories . for a fair comparison with other baseline methods ,",
    "we replace the subcategories discovering and noisy subcategories removing procedures with the given parent categories and subcategories from imagenet in our work .",
    "so the initial value of @xmath41 and @xmath125 in our work is 5 and 97 respectively . for this experiment ,",
    "the feature is 1000-dimensional bag - of - visual - words ( bow ) based on densely sampled sift features @xcite . the detailed list of the 97 subcategories in imagenet and the common original 9700 web training images can be found on website https://1drv.ms/f/s!ahpq3qsttg8nsxyjgsle2kjgcvtv .",
    "[ t ]     airplane & horse & bird & cat & dog + * number of subcategories * & 15 & 29 & 26 & 9 & 18 + * number of images * & 1434 & 1402 & 2126 & 1404 & 1603 +    [ tab_new2 ]      we compare the image sub - categorization ability of our method with four baseline methods :    @xmath14 multi - svm @xcite . for multi - svm method ,",
    "the class number is 97 .",
    "we directly use the retrieved images from the image search engine as the positive samples to learn classifiers .",
    "@xmath14 sub - cate @xcite .",
    "method sub - cate takes joint clustering and classification for subcategories discovering . for this experiment ,",
    "the latent cluster number for each parent category is known and equal to the number of given subcategories .",
    "@xmath14 rncmf @xcite . for rncmf method ,",
    "the labeled training data is unavailable for both ",
    "coarse \" ( parent ) categories and  fine \" ( sub ) categories .",
    "the training images are retrieved from the image search engine which may include noise due to the error index of image search engine .",
    "we assume there are five trees corresponding to our five parent categories and start the recursively learning .",
    "the depth of the tree for this experiment is all limited to two levels .",
    "@xmath14 mmdl @xcite .",
    "mmdl formulate image selection as a multi - instance learning problem . for this experiment ,",
    "the subcategories are assumed as  bags \" and the retrieved images therein as instances .",
    "we take the proposed multi - instance learning function to select images from the retrieved images and learn the image classifiers .",
    "[ fig4 ] and fig .",
    "[ fig5 ] present the image sub - categorization results achieved by different methods when using a varying number of training images and testing images .",
    "the accuracy is measured by the average classification rate per subcategory .    by observing fig .",
    "[ fig4 ] , the best performance is achieved by our method , which produces significant improvements over method sub - cate and multi - svm , particularly the number of training images over 20 for each subcategory .",
    "the reason is our method considers the noise during the process of classifier learning . due to the error index of the image search engine",
    ", some noise may be included .",
    "we need to select useful images from the retrieved candidate images to learn robust classifiers for each subcategory .    from fig .",
    "[ fig4 ] , we notice that the performance of the multi - svm and sub - cate peaks at the value of training numbers 20 or 30 and decreases monotonically after this peaks .",
    "one possible explanation is that the image search engine provides images based on the estimated relevancy with respect to the query .",
    "images far down in the ranking list are more likely to be noise , which may result in degrading of the sub - categorization accuracy especially for non - robust methods multi - svm and sub - cate .",
    "it is interesting to note in fig .",
    "[ fig4 ] , while method rncmf implements a form of noisy images removing , the classification accuracy did not improve with the number of training images increase .",
    "one possible explanation is that the noise in the training data is not the only factor that affects the classification accuracy .",
    "the visual distribution of the selected images is another important factor .",
    "furthermore , the poor accuracy of sub - cate suggests that naively adding the number of training images without considering the visual distributions not only does not help but actually worsens the classification accuracy .    by observing fig .",
    "[ fig4 ] and fig .",
    "[ fig5 ] , our approach compares very favorably with competing algorithms , in terms of different numbers of training and testing images .",
    "compared to method multi - svm , sub - cate and rncmf , our approach achieves significant improvements in the sub - categorization accuracy .",
    "the reason is our approach not only considers the possible presence of noise in the web training data , but also tries to ensure the diversity of the selected images for classifier learning . besides , our approach performs better than method mmdl .",
    "the reason is we formulate image selection and classifier learning as a multi - class mil problem .",
    "compared to method mmdl which uses the relationship between different subcategories for classifier learning , our method not only uses the relationships between various subcategories , but also leverage the relationships between various parent categories .",
    "therefore , our method achieves a much better result than mmdl .",
    "our proposed framework involves three major steps : subcategories discovering , noisy subcategories removing and multi - class multi - instance learning . in order to quantify the role of different steps contributing to the final classifiers , we construct two new frameworks .",
    "[ t ]    one is based on _ subcategories discovering and noisy subcategories removing _ ( which we refer to sdnsr ) .",
    "another one is based on _ subcategories discovering and multi - class multi - instance learning _ ( which we refer to sdmml ) . for framework sdnsr",
    ", we first obtain the candidate subcategories through searching in the google books ngram corpus .",
    "then we apply the noisy subcategories removing procedure to get the selected subcategories .",
    "we directly retrieve the top images from the image search engine for selected subcategories to train image classifiers ( without noisy images removing ) . for framework sdmml",
    ", we also obtain the candidate subcategories by searching in the google books ngram corpus .",
    "then we retrieve the top images from the image search engine for all the candidate subcategories ( without noisy subcategories removing ) .",
    "we apply the multi - class mil model to select useful images and train image classifiers .",
    "we compare the image classification ability of these two new frameworks with our proposed framework . specifically ,  airplane \" ,  dog \" ,  horse \" and  bird \" are selected as four target categories to compare the image categorization ability .",
    "we sequentially collect [ 200,400,600,800,1000 ] images for each category as the positive training samples and use 1000 fixed irrelevant negative samples to learn image classifiers .",
    "we test the image classification ability of these three frameworks on the pascal voc 2007 dataset .",
    "the results are shown in fig .",
    "[ new_fig1 ] . by observing fig .",
    "[ new_fig1 ] , we have the following observations :    framework sdnsr usually performs better than sdmml when the number of training images for each category is below 600 .",
    "one possible explanation is that the first few images retrieved from the image search engine tend to have a relatively high accuracy .",
    "when the number of training images is below 600 , the noisy images induced by noisy subcategories are more serious than those caused by the image search engine . with the increase of image numbers for each category ,",
    "the images retrieved from the image search engine contain more and more noise . in this condition ,",
    "the noisy images caused by the image search engine have a worse effect than those induced by noisy subcategories .",
    "our proposed framework outperforms both sdnsr and sdmml .",
    "this is because our approach , which takes a combination of noisy subcategories removing and noisy images filtering , can effectively remove the noisy images induced by both noisy subcategories and the error index of image search engine .",
    "our framework can maximize the filtering of noisy    [ t ]    images while maintaining the diversity of the selected images , thereby reducing the negative impact of noisy images on the classifier .",
    "our proposed multi - class multi - instance learning formulation contains two parameters @xmath126 and @xmath127 .",
    "pascal voc 2007 was selected as the benchmark testing dataset to evaluate the performance variation of our proposed approach . in particular ,",
    "we vary one parameter by fixing another parameter as the default value . fig .",
    "[ fig6 ] presents the parameter sensitiveness of @xmath126 and @xmath128 in terms of image classification accuracy .    by observing fig .",
    "[ fig6 ] , we found our method is robust to the parameter @xmath126 when it is varied in a certain range . besides , the performance of our method is growing when @xmath127 increase but less than 0.7",
    "the reason is perhaps that our training data derived from image search engine . due to the error index of image search engine",
    ", there may be too much noise in each bag which will result in decreasing the classification accuracy when @xmath129 .",
    "when @xmath127 increases over 0.7 , the performance of our method decreases .",
    "one possible explanation is that the training set is less diverse . with the increasing of @xmath127 , the number of subcategories is decreasing , which may lead to the degradation of domain robustness of the classifier .      during the process of multi - class multi - instance",
    "learning , we solve the convex problem in by the cutting - plane algorithm . through finding the most violating candidate @xmath130 and solve the mkl subproblem at each iteration , the time complexity of can be approximately computed as @xmath131(mkl ) , where the _ t _ is the number of iterations and the @xmath132(mkl ) is the time complexity of the mkl sub - problem . according to @xcite ,",
    "the time complexity of mkl is between @xmath133 and @xmath134 , where @xmath135 are the numbers of latent domains , bags and categories respectively .",
    "@xmath136 is the number of iterations in mkl .",
    "we take stl-10 as the testing set to evaluate our method . particularly , we use various numbers of training images for each category to learn the classifiers .",
    "stl-10 has 10 categories and we use @xmath137 training images for each category , so we have a total of 10 @xmath137 training images . fig .",
    "[ fig7 ] shows the training time and image classification accuracies with respect to various numbers of training images . from fig .",
    "[ fig7 ] , we can observe that both of training time and image classification accuracy increase with the number of training images grows .",
    "we report the configuration of our experiment .",
    "two hp pcs ( 3.2ghz cpu with 8 gbyte ram ) were used for the web images collection .",
    "all the data processing and experiments were performed on an acer pc ( 3.5ghz cpu , 16 gbyte ram and 4 gbyte vram ) with libsvm @xcite .",
    "in this paper , we presented a new framework for classifying images into categories and subcategories .",
    "three successive modules were employed in the framework including subcategories discovering , noisy subcategories removing and multi - class multi - instance learning . compared to existing methods , our proposed approach can not only classify images into noun subcategories , but also into verb , adjective and adverb subcategories .",
    "our approach has a better semantic refinement descriptions for the categories . to verify the effectiveness of our proposed approach , we conducted experiments on both image categorization and sub - categorization tasks .",
    "the experimental results demonstrated the superiority of our proposed approach over existing weakly supervised and web - supervised approaches .",
    "_ proof : _ in order to deduce the dual form of , we introduce an variable @xmath138 which is defined as : @xmath139 where @xmath140 .",
    "then , we can get : @xmath141 @xmath142 we can further rewrite the constraints in as the following forms : @xmath143 @xmath144 where @xmath57 if @xmath58 and @xmath59 otherwise .",
    "we define : @xmath145}^\\top\\ ] ] and a new mapping function for @xmath146 as : @xmath147 @xmath148 by further denoting : @xmath149 the problem of can be written as : @xmath150 @xmath151    by introducing a dual variable @xmath55 for each constraint in , we can get the lagrangian as : @xmath152 through set the derivatives of @xmath153 with respect to @xmath154 and @xmath48 as zeros , we can get : @xmath155 @xmath156        _ proof : _ we firstly introduce a dual variable @xmath157 for constraint in , then we can rewrite the lagrangian form of as : @xmath158 through set the derivatives of @xmath153 w.r.t .",
    "@xmath159 and @xmath48 as zeros respectively , we can get : @xmath160 through submit back into , we can arrive at the object function in , which completes the proof .",
    "michel , y.  k. shen , a.  p. aiden , a.  veres , m.  k. gray , j.  p. pickett , d.  hoiberg , d.  clancy , p.  norvig , j.  orwant , et  al . quantitative analysis of culture using millions of digitized books .",
    ", 331(6014 ) : 176182 , 2011 ."
  ],
  "abstract_text": [
    "<S> studies show that refining real - world categories into semantic subcategories contributes to better image modeling and classification . </S>",
    "<S> previous image sub - categorization work relying on labeled images and wordnet s hierarchy is not only labor - intensive , but also restricted to classify images into noun subcategories . to tackle these problems , in this work , we exploit general corpus information to automatically select and subsequently classify web images into semantic rich ( sub-)categories . </S>",
    "<S> the following two major challenges are well studied : 1 ) noise in the labels of subcategories derived from the general corpus ; 2 ) noise in the labels of images retrieved from the web . </S>",
    "<S> specifically , we first obtain the semantic refinement subcategories from the text perspective and remove the noise by the relevance - based approach . to suppress the search error induced noisy images , we then formulate image selection and classifier learning as a multi - class multi - instance learning problem and propose to solve the employed problem by the cutting - plane algorithm . </S>",
    "<S> the experiments show significant performance gains by using the generated data of our way on both image categorization and sub - categorization tasks . </S>",
    "<S> the proposed approach also consistently outperforms existing weakly supervised and web - supervised approaches .    </S>",
    "<S> shell : bare demo of ieeetran.cls for ieee journals    general corpus information , image categorization , sub - categorization , web - supervised </S>"
  ]
}