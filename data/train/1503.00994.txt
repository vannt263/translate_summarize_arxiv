{
  "article_text": [
    "let @xmath0 be i.i.d . observations on a data vector @xmath1 with unknown distribution function @xmath2 having a finite expectation , a non - singular variance - covariance matrix and a @xmath3-dimensional parameter of interest , @xmath4 .",
    "all the information about @xmath2 and @xmath5 is available in the form of @xmath6 estimating functions of the data observation @xmath1 and the parameter @xmath5 @xmath7 the model has a true parameter @xmath8 satisfying the moment condition @xmath9   = \\boldsymbol{0}_{r } , \\label{t1b}\\ ] ] where @xmath10   $ ] denotes expectation taken with respect to the distribution of @xmath2 of @xmath1**. * * the parameter @xmath5 has been traditionally estimated using two - step efficient generalized method of moments estimators ( gmm ) .",
    "this method of estimation was introduced by hansen ( 1982 ) . in hayashi ( 2000 ) , for instance , all the estimation techniques are presented and discussed in the gmm framework . a gmm estimator for @xmath8 is @xmath11 , defined by @xmath12 where@xmath13 and @xmath14 is a positive semidefinite matrix . under some regularity conditions",
    "@xmath11 is consistent for @xmath8 but in general it is not efficient if @xmath15 the @xmath11 will be asymptotically efficient if the limit of the matrix @xmath14 is the matrix @xmath16   .",
    "\\label{s11}\\ ] ] a feasible version of this efficient procedure is based on obtaining an initial consistent estimator @xmath17 of @xmath8 by , @xmath18 and then to consider @xmath19 with @xmath20 an alternative to the gmm estimator is the ( cu ) continuous updating estimator obtained by@xmath21    the gmm estimators have nice asymptotic properties ( see gallant and white ( 1988 ) , newey and mcfadden ( 1990 ) ) .",
    "they are consistent , asymptotically normal and asymptotically efficient under some regularity assumptions .",
    "however , several authors report that the two - step gmm estimator suffers from a substantial amount of bias in finite samples ( see altonji and segal ( 1996 ) , andersen and srensen ( 1996 ) and hansen , heaton and yaron ( 1996 ) ) .",
    "this encourages the increasing literature on alternatives to the gmm .",
    "maybe the most known alternative estimators to the gmm are : the continuously updated ( cu ) estimator of hansen , heaton and yaron ( 1996 ) , the empirical likelihood estimator ( el ) of owen ( 1988 , 1990 ) , qin and lawless ( 1994 ) , and imbens ( 1997 ) , the exponential tilting ( et ) estimator of kitamura and stutzer ( 1997 ) and imbens , spady and johnson ( 1998 ) , the minimum hellinger distance estimator of kitamura , otsa and evdokimov ( 2013 ) and the generalized empirical likelihood ( gel ) estimators of newey and smith ( 2004 ) .",
    "although el estimator is preferable to the previous estimators in higher - order asymptotic properties , these properties hold only under correct specification of the moment condition , and the asymptotic behavior of el estimator becomes problematic under misspecification .",
    "the et estimator is inferior to the el estimator in relation to higher - order asymptotic properties , but remain well behaved in presence of misspecification under relative weak regularity conditions . to overcome",
    "this problem , schennach ( 2007 ) suggests the exponentially tilted empirical likelihood ( etel ) that shares the same higher - order property with el under correct specification while maintaining usual asymptotic properties such as @xmath22-consistency and asymptotic normality under misspecification .",
    "qin and lawless ( 1994 ) studied the empirical likelihood ratio statistic for testing simple null hypotheses based on the el estimators .",
    "later balakrishnan et al . (",
    "2015 ) , using el , considered some families of test statistics based on @xmath23-divergence measures : empirical @xmath23-divergence test statistics , which contain the empirical likelihood ratio test as a particular case .",
    "some members of this family have a better behavior for small sample sizes in the sense of the size and power of the test .",
    "the contribution of the current paper is to extend the empirical @xmath23-divergence test statistics replacing the el estimators by the et and etel estimators to study their robustness , in particular under misspecification , which is their major advantage with respect to the previous ones .    in section [ sec2 ]",
    "we introduce the etel estimator given by schennach ( 2007 ) which is obtained as a combination of el and et procedures to deliver an estimator and we present its asymptotic properties .",
    "section [ sec2a ] is devoted to introduce the empirical @xmath23-divergence statistics for testing simple null hypotheses on the basis of the etel estimator and we present their asymptotic distribution .",
    "based on it , power approximations of the empirical @xmath23-divergence test statistics are derived .",
    "a rigorous study of the robustness of the empirical @xmath23-divergence test statistics is derived in section [ robustness ] and the asymptotic distribution of the empirical @xmath23-divergence is developed under misspecified alternative hypotheses . in section [ simulation ] a simulation study is presented and finally , in section [ seccomp ] some conclusions are given .",
    "let @xmath24  be a realization of @xmath25 .",
    "the empirical likelihood function is given by @xmath26 where @xmath27 .",
    "only distributions with an atom of probability at each @xmath28 have non - zero likelihood , and without consideration of estimating functions ,  the empirical likelihood function @xmath29 is seen to be maximized , at @xmath30 , by the empirical distribution function@xmath31 which is associated with the @xmath32-dimensional discrete uniform distribution@xmath33 let@xmath34 be an empirical distribution function associated with the probability vector@xmath35 and@xmath36 the kernel of the empirical log - likelihood function .",
    "the moment conditions given in ( [ t1b ] ) can be expressed from an empirical point of view as@xmath37   = \\sum\\limits_{i=1}^{n}p_{i}\\left ( \\boldsymbol{\\theta}\\right )   \\boldsymbol{g}(\\boldsymbol{x}_{i},\\boldsymbol{\\theta})=\\boldsymbol{0}_{r } , \\label{r1}\\ ] ] which are the so - called estimating equations . if we are interested in maximizing ( [ r1 ] ) subject to ( [ r1 ] ) , by applying the lagrange multipliers method it is possible to reduce the dimension of the probability vector ( @xmath32 ) , to the number of estimating functions ( @xmath38 ) , since@xmath39 where @xmath40 is an @xmath38-dimensional vector to be determined by solving the non - linear system of @xmath38 equations,@xmath41    maximizing expression ( [ r1 ] ) is equivalent to minimize the expression @xmath42 and this expression can be written as the kullback ",
    "leibler divergence measure between the probability vectors @xmath43 and @xmath44 , i.e.,@xmath45 therefore,@xmath46 subject to the restrictions given in ( [ r1 ] ) .",
    "if we consider @xmath47 , rather than @xmath48 , we get the empirical exponential tilting ( et ) estimator , considered for instance in kitamura and stutzer ( 1997 ) . in that case",
    "@xmath49 where@xmath50 and @xmath51 where @xmath52 is an @xmath38-dimensional vector to be determined by solving the non - linear system of @xmath38 equations @xmath53 the exponentially tilted empirical likelihood ( etel ) introduced by schennach ( 2007 ) combines el and et procedures to deliver an estimator .",
    "the etel  estimator is defined as @xmath54 where@xmath55 and @xmath56 is given by ( [ pet ] ) .",
    "theorem 1 in schennach establishes that the etel estimator of @xmath5 maximizes the kernel of the empirical log - likelihood function given by@xmath57   \\right\\ } \\right )   , \\label{t10}\\ ] ] where @xmath52 is obtained by solving ( [ eet ] ) and @xmath58 was defined in ( [ gbar ] ) . in schennach",
    "( 2007 , page 659 ) the following important relation for this paper is presented,@xmath59{c}\\overline{\\boldsymbol{g}}_{n}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\\\ \\boldsymbol{0}_{p}\\end{array } \\right )   + \\left ( \\begin{array } [ c]{cc}\\boldsymbol{s}_{11}\\left (   \\boldsymbol{\\theta}_{0}\\right )   & \\boldsymbol{s}_{12}\\left (   \\boldsymbol{\\theta}_{0}\\right ) \\\\",
    "\\boldsymbol{s}_{12}^{t}\\left (   \\boldsymbol{\\theta}_{0}\\right )   & \\boldsymbol{0}_{p\\times p}\\end{array } \\right )   \\left ( \\begin{array } [ c]{c}\\boldsymbol{t}_{et}(\\widehat{\\boldsymbol{\\theta}}_{etel})\\\\ \\widehat{\\boldsymbol{\\theta}}_{etel}-\\boldsymbol{\\theta}_{0}\\end{array } \\right )   = o_{p}(n^{-1/2 } ) , \\label{for}\\ ] ] with @xmath60  given in ( [ s11 ] ) , and@xmath61 , \\label{s12}\\\\ \\boldsymbol{g}_{\\boldsymbol{x}}(\\boldsymbol{\\theta } )   &   = \\frac{\\partial } { \\partial\\boldsymbol{\\theta}^{t}}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) .",
    "\\label{g}\\ ] ] based on ( [ for ] ) , we have@xmath62 where@xmath63 and @xmath64 where @xmath65 expression ( [ t12 ] ) is obtained from ( [ for ] ) . hence,@xmath66 and @xmath67    in the following section we propose a new family of empirical test statistics for testing a simple null hypothesis , when the unknown parameters are estimated using the etel  estimator defined in ( [ etel ] ) and then derive their asymptotic distribution .",
    "the empirical likelihood ratio statistic for testing@xmath68 based on the etel estimator has the expression @xmath69 where @xmath70 was defined in ( [ t10 ] ) .",
    "schennach ( 2007 ) established that under @xmath71 @xmath72 it is clear that the empirical likelihood ratio test statistic given in ( [ e9 ] ) can be expressed as @xmath73 where @xmath74 is ( [ pppet ] ) .",
    "we shall denote by @xmath75 the class of all convex functions @xmath76 such that at @xmath77 , @xmath78 , @xmath79 , and at @xmath80 , @xmath81 and @xmath82 . if instead of considering the kullback  leibler divergence measure ,  we consider a general function @xmath83 to define the @xmath23-divergence measure between the probability vectors @xmath43 and @xmath44 as @xmath84 we obtain a new family of empirical test statistics for testing ( [ h ] ) given by @xmath85 i.e.,@xmath86 moreover , the empirical likelihood ratio test statistic falls inside this new family since @xmath87 , with @xmath88 .",
    "it is well - known that the family of test statistics based on @xmath23-divergence measures has some nice and optimal properties for different inferential problems in relation to efficiency , but especially in relation to robustness ; see pardo ( 2006 ) and basu et al .",
    "( 2011 ) .    for every @xmath83 differentiable at @xmath77",
    ", the function @xmath89 also belongs to @xmath75 .",
    "then , we have @xmath90 and @xmath91 has the additional property that @xmath92 since the two divergence measures are equivalent , without any loss of generality we can consider the set @xmath93 . in",
    "what follows , we shall assume that @xmath94 .",
    "another family of statistics for testing the hypotheses in ( [ h ] ) based only on the @xmath23-divergence measure between @xmath95 and @xmath96 , namely , @xmath97 , is given by @xmath98 where @xmath23 is a function satisfying the same conditions as function @xmath23 used to construct @xmath99 .",
    "we shall refer to both families of test statistics as empirical @xmath100-divergence test statistics .",
    "the first family has been applied for the first time in broniatowski and keziou ( 2012 ) but using the el estimator rather than the etel estimator and only in the case that the parameter dimension is equal to the number of estimating equations ( @xmath101 ) .",
    "both families were applied in balakrishnan et al .",
    "( 2015 ) only with the el estimator .",
    "[ rc]let @xmath102 denote any vector or matrix norm",
    ". we shall assume the following regularity conditions ( theorem 1 in qin and lawless , 1994):i ) @xmath60 in ( [ s11 ] ) is positive definite , and for @xmath103 in ( [ s12 ] ) , @xmath104;ii ) there exists a neighborhood of @xmath8 in which @xmath105 is bounded by some integrable function of @xmath106;iii ) there exists a neighborhood of @xmath8 in which @xmath107 , given in ( [ g ] ) , is continuous and @xmath108 is bounded by some integrable function of @xmath106;iv ) there exists a neighborhood of @xmath8 in which @xmath109 is continuous and @xmath110 is bounded by some integrable function of @xmath106 .",
    "the asymptotic distribution of the empirical @xmath23-divergence test statistics , @xmath99 and @xmath111 , is given in the following theorem .",
    "[ th1]under condition [ rc ] and under the null hypothesis given in ( [ h]),@xmath112    we shall prove the result for @xmath111 . in a similar way can be established the result for @xmath99.let us consider @xmath113 we rename @xmath114 as a function of @xmath115 and @xmath116 , i.e.@xmath117 a second - order taylor expansion of @xmath118 around @xmath119 gives@xmath120 it is easy to show that@xmath121 then , we have@xmath122 denoting@xmath123 from ( [ eet ] ) the taylor expansion of @xmath124 around @xmath125 is equal to@xmath126 where @xmath127 , @xmath128 , and from it the following relation is obtained@xmath129 taking into account ( [ v ] ) , ( [ t12 ] ) and ( [ ect0 ] ) , it holds @xmath130 and consequently @xmath131 it is clear that @xmath132 where @xmath133  is the @xmath134 identity matrix . now ,",
    "applying lemma 3 of ferguson ( 1996 ) , we readily obtain the desired asymptotic distribution .",
    "based on the asymptotic null distribution presented in theorem [ th1 ] , we reject the null hypothesis in ( [ h ] ) , with significance level @xmath135 in favour of the alternative hypothesis , if @xmath136 ( or  if @xmath137 ) , where @xmath138 is the @xmath139-th quantile of the chi - squared distribution with @xmath3 degrees of freedom . in most cases ,",
    "the power function of this test procedure can not be derived explicitly . in the following theorem",
    ", we present an asymptotic result , which provides an approximation of the power of the empirical @xmath23-divergence test statistics described previously .    [ th5]under the assumption that @xmath140 is the true parameter value@xmath141 where @xmath142   \\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [ \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}\\psi\\left (   \\frac{\\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [ \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}\\right ]   } { \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\right )   \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\right ]   , \\label{st}\\ ]",
    "] @xmath143 is the solution of @xmath144=\\boldsymbol{0}_{r},\\]]@xmath145@xmath146   \\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}[\\exp\\{2\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\boldsymbol{g}^{t}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})])\\nonumber\\\\ &   \\times\\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}^{-1}\\left [ \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _",
    "{ 0})\\}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\boldsymbol{g}^{t}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\right ]   , \\label{mt}\\ ] ] and @xmath147 \\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [   \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\phi\\left ( \\frac{\\mathrm{e}\\left [   \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\right ]   } { \\exp\\{\\boldsymbol{\\tau } ^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\right ) \\right ]   .",
    "\\label{mut}\\ ] ]    we rename @xmath148 as a function of @xmath43 and @xmath149 , i.e.@xmath150 and in particular for @xmath151 and @xmath152 , @xmath153  and @xmath154 . since @xmath155 , we shall consider , on one hand , the first order taylor expansion of @xmath156 around @xmath157 @xmath158 where@xmath159 and since @xmath160 , we shall consider , on the other hand , the first order taylor expansion of @xmath161 around @xmath162@xmath163 then,@xmath164 where @xmath165 , given by ( [ st ] ) , is such that@xmath166 denoting@xmath123 the taylor expansion of @xmath124 around @xmath157 is equal to@xmath167 where @xmath168   + o_{p}(\\boldsymbol{1}_{r\\times r}),\\end{aligned}\\ ] ] and from it the following relation is obtained@xmath169 \\left (   \\frac{1}{n}{\\displaystyle\\sum\\limits_{i=1}^{n } } \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x}_{i},\\boldsymbol{\\theta}_{0})\\}\\boldsymbol{g}(\\boldsymbol{x}_{i},\\boldsymbol{\\theta}_{0})\\right )   + o_{p}(\\boldsymbol{1}_{r}).\\ ] ] we obtain in virtue of the central limit theorem@xmath170 where @xmath171 is ( [ mt ] ) , since@xmath144=\\boldsymbol{0}_{r},\\ ] ] and@xmath172),\\ ] ] on the other hand , since@xmath173 it holds @xmath174 where @xmath175 is ( [ mut ] ) .",
    "hence , from ( [ taylort ] ) it follows@xmath176 which is equivalent to the enunciated result .    [ th5b]under the assumption that @xmath140 is the true parameter value@xmath177 where @xmath178   } { \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}}\\right )   \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}^{\\ast } ) \\right ]   , \\nonumber\\\\ \\boldsymbol{s}_{2,s_{n}^{\\phi}}(\\boldsymbol{\\theta}_{0},\\boldsymbol{\\theta } ^{\\ast } )   &   = -\\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}^{-1}\\left [ \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}\\right ]   \\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}^{-1}\\left [ \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\boldsymbol{g}^{t}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\right ] \\nonumber\\\\ &   \\times\\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [   \\exp \\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\psi\\left (   \\frac{\\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [ \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}\\right ]   } { \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\right )   \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\right ]   , \\nonumber\\end{aligned}\\]]@xmath179   , \\nonumber\\\\ \\boldsymbol{\\sigma}_{22}(\\boldsymbol{\\theta}_{0},\\boldsymbol{\\theta}^{\\ast } ) &   = \\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [   \\exp\\{2\\boldsymbol{\\tau } ^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\boldsymbol{g}^{t}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\right ]   .\\nonumber\\end{aligned}\\ ] ] @xmath143 , @xmath180  and @xmath175 as in theorem [ th5 ] .    since @xmath160 and @xmath155",
    ", we shall consider the first order taylor expansion of @xmath118 around @xmath181,@xmath182 where@xmath183@xmath184 and @xmath185 with @xmath186 given by ( [ psi ] ) .",
    "then,@xmath187 where@xmath188   } { \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\right ) \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}^{\\ast})\\right ] , \\label{q0}\\\\ \\boldsymbol{\\bar{s}}_{2,s_{n}^{\\phi}}(\\boldsymbol{\\theta}^{\\ast},\\boldsymbol{\\theta}_{0 } )   &   = \\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}^{-1}\\left [   \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\right ]   \\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [   \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\psi\\left (   \\frac{\\mathrm{e}_{f_{\\boldsymbol{\\theta } ^{\\ast}}}\\left [   \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\right ]   } { \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\right ) \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\right ]   , \\nonumber\\end{aligned}\\ ] ] are such that@xmath189 denoting@xmath123 the taylor expansion of @xmath124 around @xmath157 is equal to@xmath167 where @xmath168   + o_{p}(\\boldsymbol{1}_{r\\times r}),\\end{aligned}\\ ] ] and from it the following relation is obtained@xmath169 \\left (   \\frac{1}{n}{\\displaystyle\\sum\\limits_{i=1}^{n } } \\exp\\{\\boldsymbol{\\tau}^{t}\\boldsymbol{g}(\\boldsymbol{x}_{i},\\boldsymbol{\\theta}_{0})\\}\\boldsymbol{g}(\\boldsymbol{x}_{i},\\boldsymbol{\\theta}_{0})\\right )   + o_{p}(\\boldsymbol{1}_{r}).\\ ] ] from ( [ t12 ] ) its follows@xmath190 and then@xmath191 where @xmath192 is ( [ ss]),@xmath193 and taking into account that@xmath194   = \\boldsymbol{s}_{s_{n}^{\\phi}}^{t}(\\boldsymbol{\\theta}^{\\ast},\\boldsymbol{\\theta}_{0})\\mathrm{e}_{f_{\\boldsymbol{\\theta}^{\\ast}}}\\left [   \\widetilde{\\boldsymbol{g}}(\\boldsymbol{x},\\widehat{\\boldsymbol{\\theta}}_{etel},\\boldsymbol{\\theta}_{0})\\right ]   = 0,\\ ] ] we obtain in virtue of the central limit theorem@xmath195   \\boldsymbol{s}_{s_{n}^{\\phi}}(\\boldsymbol{\\theta}^{\\ast},\\boldsymbol{\\theta}_{0})}}\\left (   d_{\\phi } ( \\widehat{\\boldsymbol{t}}_{etel},\\boldsymbol{t}_{0})-\\mu_{\\phi}(\\boldsymbol{\\theta}_{0},\\boldsymbol{\\theta}^{\\ast})\\right ) \\overset{\\mathcal{l}}{\\underset{n\\rightarrow\\infty}{\\longrightarrow}}\\mathcal{n}(0,1),\\ ] ] which is equivalent to the theorems result .",
    "let@xmath196 be the exact power functions of @xmath99 and @xmath111  respectively , with respect to the asymptotic critical value of the test , at @xmath140 , for a significance level @xmath197 .",
    "notice that in practice , since the exact distributions of @xmath99 and @xmath111  are unknown , @xmath198 and @xmath199 are also unknown .",
    "the following result provides an approximation for @xmath200 and @xmath201 .",
    "[ beta1]from theorem [ th5 ] , we can present the approximation to the asymptotic power @xmath202 , at @xmath140 , of the empirical @xmath23-divergence test @xmath99 for a significance level @xmath197 , as@xmath203 where @xmath204 is the standard normal distribution function and@xmath205 if some alternative @xmath140 is the true parameter , then the probability of rejecting ( [ h ] ) with the rejection rule @xmath206 , for fixed significance level @xmath197 , tends to one as @xmath207 . thus",
    ", the test is consistent in the sense of fraser ( 1957 ) . in a similar way",
    ", an approximation to the asymptotic power function @xmath201 , at @xmath140 , for the empirical @xmath23-divergence test @xmath111 can be obtained  as@xmath208 where@xmath209 from the parametric statistical inference , @xmath210 and @xmath199 are known to be good approximations of @xmath202 and @xmath201  respectively ( see for instance , menndez et al .",
    "( 1998 ) ) .",
    "notice that in practice , since @xmath2 is unknown , @xmath211 and @xmath199 are also unknown .",
    "however , in practice @xmath198 and @xmath212 are consistently estimated , by replacing expectations by sample means .    to produce some less trivial asymptotic powers that are not all equal to @xmath213",
    ", we can use a pitman - type local analysis , as developed by le cam ( 1960 ) , by confining attention to @xmath214-neighborhoods of the true parameter values . a key tool to get the asymptotic distribution of the statistic @xmath215 ( or @xmath111 ) under such a contiguous hypothesis is le calm s third lemma , as presented in hjek and sidk ( 1967 ) .",
    "instead of relying on these results , we present in the following theorem a proof which is easy and direct to follow . this proof is based on the results of morales and pardo ( 2001 ) . specifically , we consider the power at contiguous alternative hypotheses of the form @xmath216 where @xmath217 is a fixed vector in @xmath218 such that @xmath219 .",
    "[ th1b]under condition [ rc ] and @xmath220 in ( [ cont ] ) , the asymptotic distribution of the empirical @xmath23-divergence test statistics @xmath111 and @xmath99 is a non - central chi - squared with @xmath3 degrees of freedom and non - centrality parameter @xmath221 i.e.@xmath222 where @xmath223  was defined in ( [ v ] ) .",
    "we can write@xmath224 under @xmath220 , we have @xmath225 and @xmath226 in theorem [ th1 ] , it has been shown that @xmath227 on the other hand , we have@xmath228 we thus obtain@xmath229 with @xmath230 as in ( [ ncp ] ) .",
    "a similar procedure can be followed for the proof of @xmath99 .",
    "in robust statistics , two concepts of robustness can be distinguished , robustness with respect to contamination and robustness with respect to model misspecification .",
    "we shall understand misspecification in the sense that ( [ t1b ] ) is not verified for any @xmath231 , in particular there is misspecification for the null hypothesis in ( [ h ] ) if@xmath232   \\right\\vert > 0\\text{.}\\ ] ] for brevity , in the sequel @xmath233 $ ] is denoted by @xmath234 $ ] .",
    "it is well - known ( see imbens et al . ( 1998 ) ) that the estimating equation with respect to @xmath5  for the el and et estimators are given by@xmath235 with@xmath236 in relation to the etel estimators , from theorem 2 of schennach ( 2007 ) the following estimating equation with respect to @xmath5  is obtained@xmath237 with@xmath238 the influence functions for the three types of estimators , el , et , etel , are proportional to the @xmath239 function , for @xmath240 , respectively , given in ( [ roel])-([roetel]),@xmath241 where @xmath242 .",
    "evaluating @xmath243 at perturbations of @xmath244 , it can become unbounded even if @xmath245  is bounded , i.e. the influence function of @xmath246  can be unbounded .",
    "this is in contrast with the influence function of @xmath247 and @xmath248 , since @xmath249 and @xmath250 are affected to a much less extent by perturbations of @xmath251 , @xmath252 , respectively . at the limiting values of the estimators ,",
    "@xmath253 , @xmath254 , for @xmath255 , respectively , the influence functions for the three types of estimators , are identical,@xmath256 reflecting the first order equivalence of the estimators ( for a detailed proof see lemma 1 in balakrishnan et al .",
    "( 2015 ) ) .",
    "let @xmath257 be the functional associated the etel estimator of @xmath5 , i.e.@xmath258 and the test - statistic @xmath111 ,  given in ( [ f2 ] ) , defined now through its functional@xmath259    [ thh]the first and second order influence functions of @xmath260 are@xmath261 and@xmath262    let@xmath263{cc}0 , & \\boldsymbol{s}<\\boldsymbol{x},\\\\ 1 , & \\boldsymbol{s}\\geq\\boldsymbol{x}. \\end{array } \\right .   , \\ ] ] the @xmath264-perturbation of @xmath265  at @xmath266 .",
    "the first and second order influence functions of @xmath267 are defined as@xmath268 and@xmath269    [ corr]under the null hypothesis of the test ( [ h ] ) , the first and second order influence functions of the test - statistic @xmath270 are given by@xmath271 in particular , for large samples@xmath272    both equalities are obtained taking into account@xmath273 since @xmath274 , and@xmath275 since@xmath276 an alternative expression for the second order influence function , for large sample sizes , is ( [ if2 ] ) .",
    "notice that @xmath277 is the same for any @xmath23  function and plugging any estimator into @xmath278 , either el , et or etel , @xmath279 remains unchanged .",
    "a similar results of theorem [ thh ] and corollary [ corr ] can be enuntiated for the other family of test - statistics , @xmath280 .",
    "let @xmath281 denote the etel s pseudo - true value associated with the misspecified model , i.e.@xmath282   \\right )   \\right\\ }   \\right ]   , \\\\ &   \\text{s.t . }",
    "\\mathrm{e}\\left [   \\exp\\left\\ {   \\boldsymbol{t}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) \\right\\ }   \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\right ] = \\boldsymbol{0}_{r}.\\end{aligned}\\ ] ] the etel s pseudo - true value can be interpreted as the best approximation to the true value , according to the etel s estimation method .",
    "[ rc2]we shall assume the following regularity conditions ( schennach , 2007):i ) there exists a neighborhood of @xmath281 in which @xmath109 is continuous and @xmath283 is bounded by some integrable function of @xmath106;ii ) @xmath284",
    "< \\infty$ ] s.t .",
    "@xmath285   = \\boldsymbol{0}_{r}$];iii ) there exists a function of @xmath106 , @xmath286 , such that @xmath287 , @xmath288 are bounded by @xmath286  and @xmath289   < \\infty$ ] , @xmath290 , @xmath291 , s.t . @xmath292   = \\boldsymbol{0}_{r}$ ] .",
    "the etel estimator of @xmath281 , @xmath248 , associated with the misspecified model , is obtained in the same manner done for the true model , in fact in practice it is not possible to know when the model is misspecified . by following lemma 9 of schennach ( 2007 )",
    ", it is convenient to study , apart from the vector of parameters of interest @xmath5 and the lagrange multipliers vector @xmath293 , two additional auxiliary variables @xmath294 and @xmath295 in a joint vector@xmath296 according to theorem 10 of schennach ( 2007 ) , by calculating first the asymptotic distribution of @xmath297 , and subtracting thereafter the marginal distribution of @xmath248 , the procedure to calculate the asymptotic distribution of @xmath298 is simplified , under misspecification .",
    "the following auxiliary function@xmath299 with@xmath300 defines @xmath301 , as the solution of @xmath302 , and the pseudo - true value @xmath303 as the solution of @xmath304   = \\boldsymbol{0}_{p+2r+1}$ ] . under condition [ rc2 ] ,",
    "the asymptotic distribution of @xmath301 is given by@xmath305",
    "with@xmath306   , \\\\ \\phi(\\boldsymbol{\\beta}_{\\ast , etel } )   &   = \\mathrm{e}\\left [ \\boldsymbol{\\varphi}(\\boldsymbol{x},\\boldsymbol{\\beta}_{\\ast , etel})\\boldsymbol{\\varphi}^{t}(\\boldsymbol{x},\\boldsymbol{\\beta}_{\\ast , etel})\\right ]   , \\end{aligned}\\ ] ] assuming that @xmath307 is nonsingular .",
    "based on this result,@xmath308 with@xmath309    [ thdp]the first derivative of ( [ pet ] ) is given by@xmath310   , \\ ] ] where @xmath311 was defined in ( [ roetel]),@xmath312    ( for the proof see appendix )    [ thdd1]the first derivative of @xmath313 is given by@xmath314   , \\label{dd1}\\ ] ] and @xmath315 with @xmath186 given by ( [ psi ] ) , @xmath316   \\left\\ {   \\boldsymbol{r}_{1}(\\boldsymbol{\\theta})-\\boldsymbol{r}_{2}(\\boldsymbol{\\theta})-\\boldsymbol{r}_{3}(\\boldsymbol{\\theta})\\right\\ }   , \\label{s}\\]]@xmath317   \\}}{\\exp\\{\\overline { \\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}}\\right )   \\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta})\\right ]   \\overline{\\boldsymbol{t}}_{et}(\\boldsymbol{\\theta}),\\\\ \\boldsymbol{r}_{2}(\\boldsymbol{\\theta } )   &   = \\mathrm{e}^{-1}\\left [ \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}\\right ]   \\mathrm{e}\\left [ \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}\\psi\\left (   \\frac{\\mathrm{e}\\left [ \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\right ]   } { \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}}\\right )   \\right ] \\\\ &   \\times\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) \\}\\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta})\\right ] \\overline{\\boldsymbol{t}}_{et}(\\boldsymbol{\\theta}),\\\\ \\boldsymbol{r}_{3}(\\boldsymbol{\\theta } )   &   = \\boldsymbol{k}(\\boldsymbol{\\theta } ) \\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}\\psi\\left (   \\frac{\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) \\right ]   } { \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta } ) \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}}\\right )   \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\right ]   , \\end{aligned}\\]]@xmath318 + \\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta } ) \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}\\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta})\\right ]   \\right\\ } \\nonumber\\\\ &   \\times\\mathrm{e}^{-1}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) \\}\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\boldsymbol{g}^{t}(\\boldsymbol{x},\\boldsymbol{\\theta})\\right ]   , \\label{k}\\ ] ] @xmath319 is the solution in @xmath293 of @xmath320   = \\boldsymbol{0}_{r}$ ] .",
    "let @xmath321 be a consistent estimator of @xmath322  given in ( [ s12 ] ) .",
    "it is interesting that according to formula ( 42 ) of schennach ( 2007 ) , @xmath323   \\boldsymbol{t}_{et}(\\boldsymbol{\\theta}),\\end{aligned}\\ ] ] which matches ( [ dd1 ] ) with @xmath324 .",
    "( for the proof see appendix )    [ thdd2]the first derivative of @xmath325 is given by@xmath326 where@xmath327 and @xmath328 with@xmath329@xmath330",
    "\\mathrm{e}\\left [   \\phi^{\\prime}\\left (   \\frac{\\exp\\{\\overline { \\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}}{\\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\frac{\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\right ]   } { \\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) \\right ]   } \\right )   \\right ] \\\\ &   \\times\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) \\}\\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta})\\right ] \\overline{\\boldsymbol{t}}_{et}(\\boldsymbol{\\theta}),\\\\ \\boldsymbol{q}_{2}(\\boldsymbol{\\theta},\\boldsymbol{\\theta}_{0 } )   & = \\boldsymbol{k}(\\boldsymbol{\\theta})\\mathrm{e}\\left [   \\phi^{\\prime}\\left ( \\frac{\\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta } ) \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}}{\\exp\\{\\overline { \\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\frac{\\mathrm{e}\\left [ \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\right ]   } { \\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta } ) \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\right ]   } \\right ) \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\right ]   , \\\\ \\boldsymbol{q}_{3}(\\boldsymbol{\\theta},\\boldsymbol{\\theta}_{0 } )   & = \\mathrm{e}\\left [   \\phi^{\\prime}\\left (   \\frac{\\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\}}{\\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\frac{\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\right ]   } { \\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } ) \\right ]   } \\right )   \\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta } ) \\right ]   \\overline{\\boldsymbol{t}}_{et}(\\boldsymbol{\\theta}),\\end{aligned}\\ ] ] @xmath319 is the solution in @xmath293 of of @xmath320   = \\boldsymbol{0}_{r}$ ] .",
    "the following two theorems evaluate the effect of a misspecified alternative hypothesis on the asymptotic distribution of the empirical @xmath23-divergence test - statistics .",
    "[ th]under the assumption that the pseudo - true parameter value @xmath281 is different from @xmath8@xmath331 where @xmath332 is given by ( [ sigmath ] ) , @xmath333 by ( [ s ] ) and @xmath334 \\\\ &   \\times\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}\\phi\\left (   \\frac{e\\left [   \\exp \\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}\\right ] } { \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}}\\right )   \\right ] \\\\ &   -\\mathrm{e}^{-1}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\right ] \\\\ &   \\times\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\phi\\left (   \\frac{e\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}\\right ]   } { \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta } _ { 0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}}\\right ) \\right ]   , \\end{aligned}\\ ] ] with @xmath319 being the solution in @xmath293 of @xmath320   = \\boldsymbol{0}_{r}$ ] .",
    "the first order taylor expansion of @xmath313 around @xmath281 is@xmath335 in particular , for @xmath336@xmath337 according to theorem [ thdd1 ] @xmath338 converges in probability to a fixed vector , and so@xmath339 from ( [ thetaetel ] ) it holds @xmath340 .",
    "thus , the random variables @xmath341 have the same asymptotic distribution , and since@xmath342    &   = \\mu_{t_{n}^{\\phi}}(\\boldsymbol{\\theta}_{0},\\boldsymbol{\\theta}_{\\ast , etel}),\\end{aligned}\\ ] ] the desired result is obtained .    under the assumption that the pseudo - true parameter value @xmath343 is different from @xmath8@xmath344 where @xmath332 is given by ( [ sigmath ] ) , @xmath345 by ( [ q ] ) and @xmath346 \\\\ &   \\times\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\phi\\left (   \\frac{\\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}}{\\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}}\\frac{\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\}\\right ]   } { \\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}\\right ]   } \\right )   \\right ]   .\\end{aligned}\\ ] ] with @xmath319 being the solution in @xmath293 of @xmath320   = \\boldsymbol{0}_{r}$ ] .",
    "it is omitted since similar steps of the proof for theorem [ th ] are needed .",
    "[ cor]under the assumption that the pseudo - true parameter value @xmath281 is different from @xmath8 , the asymptotic distribution of the likelihood ratio test - statistics is given by@xmath347 where@xmath348",
    "with@xmath349   , \\\\",
    "\\boldsymbol{r}_{g,3}(\\boldsymbol{\\theta}_{\\ast , etel } )   &   = \\left\\ { \\mathrm{e}^{-1}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}\\right ]   \\right .",
    "\\\\ &   \\left .",
    "\\times\\mathrm{e}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}\\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\right ]   -\\mathbf{s}_{12}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\right\\ }   \\overline{\\boldsymbol{t}}_{et}(\\boldsymbol{\\theta}_{\\ast , etel}),\\end{aligned}\\ ] ] @xmath350 is given by ( [ k ] ) and@xmath351   } { e_{f_{\\boldsymbol{\\theta}_{\\ast , etel}}}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{0})\\}\\right ]   } \\nonumber\\\\ &   -e_{f_{\\boldsymbol{\\theta}_{\\ast , etel}}}\\left [   \\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})-\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{0})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta } _ { 0})\\right ]   . \\label{mug}\\ ] ]    with @xmath324 plugged into ( [ psi])@xmath352   } { \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}}\\right )   = \\frac{\\exp\\{\\overline { \\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}}{\\mathrm{e}\\left [ \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}\\right ]   } -1,\\ ] ] is obtained , and then according to theorem [ th ] , plugging@xmath353   } { \\exp\\{\\overline { \\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}}\\right )   \\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\right ] \\\\ &   = \\mathrm{e}^{-1}\\left [   \\exp\\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\right ]   \\mathrm{e}\\left [   \\exp \\{\\overline{\\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}\\boldsymbol{g}_{\\boldsymbol{x}}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\right ]   -\\boldsymbol{s}_{12}^{t}(\\boldsymbol{\\theta}_{\\ast , etel}),\\end{aligned}\\]]@xmath354   } { \\exp\\{\\overline { \\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}}\\right )   \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\right ]   = -\\mathrm{e}\\left [ \\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\right ]   , \\]]@xmath354   } { \\exp\\{\\overline { \\boldsymbol{t}}_{et}^{t}(\\boldsymbol{\\theta}_{\\ast , etel})\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta}_{\\ast , etel})\\}}\\right )   \\right ]   = 0,\\ ] ] into @xmath355 , @xmath356 , @xmath357  of theorem [ th ]  respectively , the desired result is obtained .",
    "the expression of ( [ mug ] ) is a particular case of @xmath358 with @xmath324 .    from the previous two theorems , we can present an approximation of the power function under misspecification @xmath359 , at @xmath360 , of the empirical @xmath23-divergence test @xmath99 for a significance level @xmath197 , as@xmath361 where @xmath362 in a similar way",
    ", an approximation to the asymptotic power function under misspecification @xmath363 , at @xmath364 , for the empirical @xmath23-divergence test @xmath99 can be obtained  as@xmath365 where @xmath366 in practice , @xmath367  and @xmath368 are unknown but their consistent estimators are obtained by replacing the population mean by the sample mean .",
    "the class of @xmath23-divergence measures is a wide family of divergence measures but unfortunately there are some classical divergence measures that are not included in this family of @xmath23-divergence measures such as the rnyi s divergence or the sharma and mittal s divergence .",
    "the expression of rnyi s divergence is given by @xmath369 with @xmath370 and @xmath371 this measure of divergence was introduced in rnyi ( 1961 ) for @xmath372 and @xmath373 and liese and vajda ( 1987 ) extended it for all @xmath374 .",
    "an interesting divergence measure related to rnyi divergence measure is the bhattacharya divergence defined as the rnyi divergence for @xmath375 divided by @xmath376 other interesting example of divergence measure that is not included in the family of @xmath23-divergence measures is the divergence measures introduced by sharma and mittal ( 1997 ) .    in order to unify the previous divergence measures , as well as another divergence measures , menndez et al .",
    "( 1995 , 1997 ) introduced the family of divergences called @xmath377-divergence measures  in the following way @xmath378 where @xmath379 is a differentiable increasing function mapping from @xmath380   $ ] onto @xmath381 , with @xmath382 , @xmath383 , and @xmath94 . in table",
    "[ t1 ] , these divergence measures are presented , along with the corresponding expressions of @xmath379 and @xmath23 .    0.8pt @xmath384{ccccc}\\hline divergence & \\hspace*{0.5 cm } & $ ] h ( x ) @xmath385 ( x ) @xmath386^{\\frac{b-1}{a-1}}-1\\right\\ }   , \\quad b , a\\neq1 $ } &   & \\multicolumn{1}{l}{$\\frac{x^{a}-a\\left (   x-1\\right ) -1}{a\\left (   a-1\\right )   } , \\quad a\\neq0,1$}\\\\\\hline \\end{tabular } $ ]    based on the @xmath377-divergence measures we can define two new families of empirical @xmath377-divergence test statistics , @xmath387 and @xmath388 the results obtained in this paper for the empirical @xmath23-divergence test statistics @xmath99 and @xmath111 can be obtained for the empirical @xmath377-divergence test statistics defined in ( [ ah ] ) and ( [ bh ] ) .",
    "the aim of this simulation study is to analyze the performance of the empirical @xmath23-divergence test - statistics when the etel estimator of an unknown parameter is considered . in this",
    "regard , robustness under misspecification and efficiency are studied , based on the design of the simulation study given in schennach ( 2007 ) .",
    "let @xmath389 be an unknown univariate random variable , with mean @xmath390 and variance @xmath391 both unknown , but it is supposed to be known that @xmath392 .",
    "the corresponding moment based vectorial estimating function is @xmath393 , with @xmath394 , @xmath395 by modifying ( [ g2 ] ) to@xmath396 we are considering a misspecified model , with @xmath397 being a tuning parameter for the model misspecification degree . since the correctly specified model has a variance equal to @xmath398 with @xmath399 , less variance than the correct one is specified when @xmath400 , while a bigger variance than the correct one is specified when @xmath401 .",
    "the el estimator of @xmath402 is given by@xmath403 with@xmath404 the et estimator of @xmath402 by@xmath405 with@xmath406 and the etel of @xmath402 estimator by@xmath407 with @xmath408 , @xmath409 .",
    "the test - statistics @xmath410 and @xmath411 , with @xmath240 , and@xmath412{ll}\\frac{1}{\\lambda(\\lambda+1)}\\left (   x^{\\lambda+1}-x-\\lambda(x-1)\\right )   , & \\lambda\\in\\mathbb{r } -\\{0,-1\\}\\\\ \\lim_{s\\rightarrow0}\\phi_{s}(x)=x\\log x - x+1 , & \\lambda=0\\\\ \\lim_{s\\rightarrow-1}\\phi_{s}(x)=-\\log x+x-1 , & \\lambda=-1 \\end{array } \\right .   , \\ ] ] are the so - called empirical power divergence based test - statistics of cressie and read ( 1984 ) , valid in this new setting for testing@xmath413 the expressions of the empirical power divergence based test - statistics are@xmath414{ll}\\frac{2}{\\lambda(1+\\lambda)}\\left (   \\sum\\limits_{i=1}^{n}\\left (   np_{i,\\ell } ( \\theta_{0})\\right )   ^{-\\lambda}-\\sum\\limits_{i=1}^{n}\\left (   np_{i,\\ell } ( \\widehat{\\theta}_{\\ell})\\right )   ^{-\\lambda}\\right )   , & \\lambda\\in\\mathbb{r } -\\{0,-1\\}\\\\ 2\\sum\\limits_{i=1}^{n}\\log\\left (   \\frac{p_{i,\\ell}(\\widehat{\\theta}_{\\ell})}{p_{i,\\ell}(\\theta_{0})}\\right )   , & \\lambda=0\\\\ 2n\\left (   \\sum\\limits_{i=1}^{n}p_{i,\\ell}(\\theta_{0})\\log\\left (   np_{i,\\ell } ( \\theta_{0})\\right )   -\\sum\\limits_{i=1}^{n}p_{i,\\ell}(\\widehat{\\theta}_{\\ell } ) \\log(np_{i,\\ell}(\\widehat{\\theta}_{\\ell}))\\right )   , & \\lambda=-1 \\end{array } \\right .   , \\ ] ] @xmath415{ll}\\frac{2n}{\\lambda(1+\\lambda)}\\left (   \\sum\\limits_{i=1}^{n}\\frac{p_{i,\\ell } ^{\\lambda+1}(\\widehat{\\theta}_{\\ell})}{p_{i,\\ell}^{\\lambda}(\\theta_{0})}-1\\right )   , & \\lambda\\in\\mathbb{r } -\\{0,-1\\}\\\\ 2n\\sum\\limits_{i=1}^{n}p_{i,\\ell}(\\widehat{\\theta}_{\\ell})\\log\\left ( \\frac{p_{i,\\ell}(\\widehat{\\theta}_{\\ell})}{p_{i,\\ell}(\\theta_{0})}\\right )   , & \\lambda=0\\\\ 2n\\sum\\limits_{i=1}^{n}p_{i,\\ell}(\\theta_{0})\\log\\left (   \\frac{p_{i,\\ell } ( \\theta_{0})}{p_{i,\\ell}(\\widehat{\\theta}_{\\ell})}\\right )   , & \\lambda=-1 \\end{array } \\right .   , \\ ] ] with @xmath255 , @xmath416 given by ( [ ppel ] ) and @xmath408 by ( [ ppet ] ) .",
    "it is worth of mentioning that the empirical likelihood ratio test - statistic of qin and lawless ( 1994 ) matches the case of @xmath417 when the el estimator of @xmath402 is applied , i.e. @xmath418 .    for the study of the performance of @xmath419  and @xmath420 , for illustrative purposes , a subset of tuning parameters of the empirical power divergence based test - statistics are considered , @xmath421 .",
    "when the model is correctly specified , the population s distribution is simulated with a standard normal distribution , i.e. @xmath422 , with @xmath423 and @xmath399 ( @xmath424 ) . when the model is misspecified , two cases are considered , by simulating the population distribution either through @xmath422 , with @xmath423 and @xmath425 ( @xmath426 ) or @xmath423 and @xmath427 ( @xmath428 ) .",
    "the pseudo true value of the etel estimator is @xmath429 for @xmath430 , and @xmath431 , @xmath432 , so even being a misspecified model @xmath433 is a consistent estimator of the true value of @xmath402 . using @xmath434 replications ,",
    "the following results are obtained .    in figure [ fig4 ]",
    "the simulated cumulative distribution functions ( cdf ) of @xmath435 , @xmath436 and @xmath433 are shown with a sample size of @xmath437 , for the correctly specified model ( @xmath399 ) as well as the two misspecified models ( @xmath438 ) . since the sample size is very big , the three types of estimators exhibit almost the same cdf .",
    "the gray color line of the figures indicates the theoretical distribution with correct specification , i.e. the reference line to be compared . under misspecification , as expected according to schennach ( 2007 ) , the most robust estimator under misspecification is @xmath439 ( it is closer to the gray line ) , the least robust @xmath440 ( it is further from the gray line ) , and @xmath433 tends to be between the two . in addition , @xmath433  tends to be in between the two in efficiency with respect to the exact size of the asymptotic test for small sample sizes , no as efficient as @xmath440 but more efficient than @xmath436 . in the same way , we would like to identify a test - statistic @xmath441 or @xmath442 with good performance at the same in robustness under misspecification and efficiency .",
    "2.8pt    [ c]c@xmath443{estimators10.eps}}}$ ] + estimatorsdelta07.eps + estimatorsdelta13.eps    the simulations showed that in robustness under misspecification @xmath411 is much worse than @xmath410 , with @xmath240 , for this reason the following figures are focussed only on @xmath410 . in figure [ fig6 ] the simulated cdfs of @xmath419",
    "are plotted with the three types of estimators and a degree of misspecification equal to @xmath427 , while in figure [ fig5 ] are plotted with a degree of misspecification equal to @xmath425 . from them ,",
    "the test - statistic @xmath444 with @xmath445 seems to be the most robust test - statistic under misspecification .",
    "figure [ fig7 ] has been plotted to compare the performance of @xmath410 with @xmath445 when different types of estimators are plugged , @xmath240 .",
    "as expected , the most robust test - statistic is @xmath446 , the worst one @xmath447 , and @xmath448 is in between . from figures [ fig6 ] and [ fig5 ] , for the misspecified model ( either with @xmath427 or @xmath425 ) ,",
    "the exact significance levels can be visually compared with respect to the @xmath449 nominal level , comparing the values of the black color curves just at @xmath450  in the abscissa axis , with respect to the gray color curve . in this regard ,",
    "the exact sizes for @xmath427 are better than for @xmath425 : for etel estimators the exact significance levels are @xmath451 ( @xmath445 ) , @xmath452 ( @xmath453 ) , @xmath454 ( @xmath417 ) , @xmath455 ( @xmath456 ) when @xmath427 and @xmath457 ( @xmath445 ) , @xmath458 ( @xmath453 ) , @xmath459 ( @xmath417 ) , @xmath460 ( @xmath456 )  when @xmath425 .",
    "the figures of the simulations for @xmath411 , with @xmath437 , were omitted , but the exact sizes are as follows : the exact significance levels are @xmath461 ( @xmath445 ) , @xmath461 ( @xmath453 ) , @xmath461 ( @xmath417 ) , @xmath461 ( @xmath456 ) when @xmath427 and @xmath462 ( @xmath445 ) , @xmath462 ( @xmath453 ) , @xmath463 ( @xmath417 ) , @xmath464 ( @xmath456 )  when @xmath425 .",
    "2.8pt    [ c]ctlambdaseldelta13.eps + tlambdaseteldelta13.eps + tlambdasetdelta13.eps    2.8pt    [ c]ctlambdaseldelta07.eps + tlambdaseteldelta07.eps + tlambdasetdelta07.eps",
    "2.8pt    [ c]ct-1eleteteldelta10.eps + t-1eleteteldelta07.eps + t-1eleteteldelta13.eps    figure [ fig1 ] and [ fig2 ] represent , only for @xmath465 for illustrative purposes , the asymptotic power based on the power - divergence test statistics @xmath466 and @xmath467 , @xmath468 and @xmath469 when the nominal significance level is @xmath470 .",
    "there are no substantial differences for a generic small or moderate samples size .",
    "the test - statistics @xmath466 and @xmath471 , with @xmath445 , exhibit the exact significance levels closest to the nominal significance level , @xmath472 for @xmath466  and @xmath473 for @xmath474 . in the results obtained in balakrishnan et al .",
    "( 2015 ) @xmath475 was found out to be much more efficient than @xmath476 with small sample sizes , for being @xmath475 closer to the nominal level than @xmath477 .",
    "such a difference is less pronounced for @xmath441  and @xmath478 .",
    "the performance of @xmath477 with @xmath445  is then relatively good in efficiency with small sample sizes as well as in robustness under misspecification ( with small and big sample sizes ) .",
    "the approximation to the asymptotic power @xmath479 , at @xmath480 , of the power - divergence test @xmath466 for the correctly specified model , with a significance level @xmath197 , is according to remark [ beta1 ] and doing some algebraic manipulations , @xmath481 , where@xmath482@xmath483{ll}\\frac{1}{\\lambda(\\lambda+1)}\\left (   \\tfrac{\\exp\\left\\ {   \\frac{\\lambda ( \\lambda+1)\\theta^{\\ast2}}{2\\left (   1-\\lambda\\theta^{\\ast2}\\right )   } \\right\\ } } { \\sqrt{\\left (   1-\\lambda\\theta^{\\ast2}\\right )   \\left (   \\theta^{\\ast 2}+1\\right )   ^{\\lambda}}}-1\\right )   , & \\lambda\\in\\mathbb{r } -\\{0,-1\\}\\\\ \\theta^{\\ast2}-\\frac{1}{2}\\log\\left (   1+\\theta^{\\ast2}\\right )   & \\lambda=0\\\\ \\frac{1}{2}\\log\\left (   1+\\theta^{\\ast2}\\right )   & \\lambda=-1 \\end{array } \\right .",
    ", \\]]@xmath484 in particular , figure [ fig3 ] shows the approximated and exact asymptotic powers of @xmath466 when @xmath445 , @xmath485 and @xmath486 , for two sample sizes @xmath465 and @xmath487 .",
    "the approximation is quite good for the values not very close to @xmath488 , @xmath489 when @xmath465 , and @xmath490 when @xmath487 .",
    "2.8pt    [ c]c@xmath491{t_1.eps}}}$ ]    2.8pt    [ c]c@xmath492{tn100.eps}}}$ ]    2.8pt    [ c]c@xmath492{sn100.eps}}}$ ]",
    "this paper introduces empirical @xmath23-divergence test - statistics using exponentially tilted empirical likelihood estimators , as alternative to the empirical likelihood ratio test - statistic .",
    "it is shown that these test - statistics follow the same efficiency and robustness patterns of the corresponding estimators , empirical likelihood estimators , exponential tilted estimators and exponentially tilted empirical likelihood estimators .",
    "this justifies the practical choice of the exponentially tilted empirical likelihood estimator to be plugged into the empirical @xmath23-divergence test - statistics , for being a good compromise between the efficiency of the exact size of the test for small or moderate sample sizes and the robustness under model misspecification . according to the results of the simulation study , the modified empirical likelihood ratio test @xmath493 exhibits , by far , the best performance .",
    "a possible future research could include a correction of the critical value for @xmath448 test - statistic .",
    "for instance , in the line of lee ( 2014 ) , bootstrap critical values of @xmath448 could be studied to be compared with the wald type test - statistic s bootstrap critical values proposed in the aforementioned paper .",
    "menndez , m. l. , morales , d. , pardo , l. and salicr , m. ( 1995 ) .",
    "asymptotic behavior and statistical applications of divergence measures in multinomial populations : a unified study .",
    "_ statistical papers , _ * 36 , * 129 .",
    "menndez , m. l. , pardo , j. a. , pardo , l. and pardo , m. c. ( 1997 ) .",
    "asymptotic approximations for the distributions of the @xmath494-divergence goodness - of - fit statistics : applications to rnyi s statistic .",
    "_ kybernetes , _ * 26 , * 442452 .",
    "[ proof of lemma [ thdp]]taking into account ( [ pet]),@xmath495 } { \\overline{\\exp}_{et}^{2}(\\boldsymbol{\\theta})}\\\\ &   = p_{et , i}\\left (   \\boldsymbol{\\theta}\\right )   \\left [   \\frac{\\partial } { \\partial\\boldsymbol{\\theta}}\\left (   \\boldsymbol{t}_{et}^{t}(\\boldsymbol{\\theta})\\boldsymbol{g}(\\boldsymbol{x}_{i},\\boldsymbol{\\theta } ) \\right )   -\\overline{\\exp}_{et}^{-1}(\\boldsymbol{\\theta})\\frac{\\partial } { \\partial\\boldsymbol{\\theta}}\\overline{\\exp}_{et}(\\boldsymbol{\\theta } ) \\right ]   , \\end{aligned}\\ ] ] where@xmath496@xmath497 according to ( 41 ) of schennach ( 2007 ) , and@xmath498 with@xmath499 from ( [ eet ] ) . using the previous notation@xmath500 and replacing ( [ one ] ) and ( [ two ] ) in the expression of @xmath501 ,",
    "the desired result is obtained .",
    "[ proof of lemma [ thdd1]]taking into account the expression of ( [ f1]),@xmath502 by plugging @xmath503 from theorem [ thdp ] into the previous expression , ( [ dd1 ] ) is obtained . since according to the weak law of large numbers",
    "@xmath504@xmath505 $ ] for any integrable function @xmath506 , taking the approppriate functions in the role of @xmath379 , the limiting value of @xmath507 is obtained ."
  ],
  "abstract_text": [
    "<S> in econometrics , imposing restrictions without assuming underlying distributions to modelize complex realities is a valuable methodological tool . however , </S>",
    "<S> if a subset of restrictions were not correctly specified , the usual test - statistics for correctly specified models tend to reject erronously a simple null hypothesis . in this setting </S>",
    "<S> , we may say that the model suffers from misspecification . </S>",
    "<S> we study the behavior of empirical phi - divergence test - statistics , introduced in _ </S>",
    "<S> balakrishnan et al . ( 2015 ) _ , by using the exponential tilted empirical likelihood estimators of _ schennach ( 2007 ) _ , as a good compromise between the efficiency of the significance level for small sample sizes and the robustness under misspecification .    </S>",
    "<S> * :* c12 ; c14    * :* empirical likelihood , empirical phi - divergence test statistics , model misspecification , phi - divergence measures . </S>"
  ]
}