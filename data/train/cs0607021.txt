{
  "article_text": [
    "consider the problem of encoding @xmath0 with side information @xmath1 at the decoder . here",
    "@xmath2 are two memoryless sources with joint probability distribution @xmath3 on @xmath4 .",
    "this is a special case of slepian - wolf coding .",
    "general cases can be reduced to this special case via either time - sharing or source splitting . for this special case ,",
    "the slepian - wolf theorem states that the minimum rate for reconstructing @xmath0 is @xmath5 . for simplicity , we assume @xmath6 and @xmath7 throughout this paper . the general finite - alphabet case can be reduced to this special case via multilevel coding . in the literature",
    "many low - complexity slepian - wolf coding schemes have been proposed @xcite , almost all of which are based on ideas from channel coding , and simply use some binary linear channel codes as slepian - wolf codes . in this approach",
    "it is implicitly assumed that a good channel code for a channel is also a good slepian - wolf code for the same channel linking the source and the side information ; yet few justifications have been presented except for @xcite .",
    "motivated by these observations , in this paper we consider slepian - wolf code design based on binary ldpc coset codes ( see section  [ review ] for details ) . to this end",
    "we derive the density evolution formula for slepian - wolf coding , equipped with a concentration theorem .",
    "an intimate connection between slepian - wolf coding and channel coding is then established .",
    "specifically we show that , under density evolution , any slepian - wolf source coding problem , where the joint distribution @xmath8 can be arbitrary , is equivalent to a channel coding problem for a binary - input output - symmetric channel .",
    "note that this channel is often different from the channel between the source and the side information in the original slepian - wolf coding problem .",
    "this is in sharp contrast to the practice in the works reviewed above where the two channels are assumed the same .",
    "the rest of this paper is organized as follows . in section [ review ] , we review some basic results in the channel coding theory",
    ". the emphasis will be on binary linear codes with the practical belief - propagation decoding algorithm . in section [ bp_de_concentration ]",
    ", we develop the belief - propagation algorithm for slepian - wolf coding . the associated density evolution formula and concentration theorem",
    "are also provided .",
    "an intimate connection between slepian - wolf coding and channel coding under density evolution is established in section [ scconnection ] .",
    "we conclude the paper in section [ conclusion ] .",
    "any binary linear code @xmath9 can be expressed as the set of solutions @xmath10 to a parity check equation @xmath11 , where @xmath12 is called the parity check matrix of @xmath13 , and here multiplication and addition are modulo 2 .",
    "given some general syndrome @xmath14 , the set of all @xmath15-length vectors @xmath16 satisfying @xmath17 is called a coset @xmath18 .",
    "a @xmath19-regular low - density - parity - check ( ldpc ) code is a binary linear code determined by the condition that every codeword bit participates in exactly @xmath20 parity - check equations and that every such check equation involves exactly @xmath21 codeword bits .",
    "given the parity check matrix @xmath12 , we can construct a bipartite graph with @xmath15 variable nodes and @xmath22 check nodes .",
    "each variable node corresponds to one bit of the codeword , and each check node corresponds to one parity - check equation .",
    "edges in the graph connect variable nodes to check nodes and are in one - to - one correspondence with the nonzero entries of @xmath12 .",
    "the ensemble @xmath23 of @xmath19-regular ldpc codes of length @xmath15 is defined in @xcite .",
    "we can also define the irregular code ensemble @xmath24 , where @xmath25 denotes a degree distribution pair @xcite .",
    "the belief - propagation algorithm is an iterative message - passing algorithm .",
    "let @xmath26 denote the message sent from variable node @xmath27 to its incident check node @xmath28 in the @xmath29th iteration .",
    "similarly , let @xmath30 denote the message sent from check node @xmath28 to its incident variable node @xmath27 in the @xmath29th iteration .",
    "the update equations for the messages under belief propagation are described below : @xmath31 @xmath32 where @xmath33 is the set of check nodes incident to variable node @xmath27 , @xmath34 is the set of variable nodes incident to check node @xmath28 , @xmath35 is the initial message associated with the variable node @xmath27 , and @xmath36 .",
    "the performance of ldpc codes under the belief - propagation algorithm is relatively well - understood for binary - input output - symmetric ( bios ) channels .    a binary input channel with transition probability function @xmath37 $ ] from @xmath38 to @xmath39 is output - symmetric if there exists an injective map @xmath40 such that @xmath41 where @xmath42 is the channel output in response to channel input @xmath43 .",
    "an important property of the bios channel is that under the belief - propagation algorithm , the decoding error probability is independent of the transmitted codeword . so without loss of generality , we can assume the all - zero codeword is transmitted .    in order to analyze the asymptotic ( in codeword length ) performance of the ldpc code ensemble @xmath24 , a powerful technique called density evolution",
    "is developed in @xcite .",
    "the iterative density evolution formula for bios channels is given in the following theorem .",
    "for a given bios memoryless channel let @xmath44 denote the initial message density of log - likelihood ratios , assuming that the all - zero codeword was transmitted . if , for a fixed degree distribution pair @xmath25 , @xmath45 denotes the density of the messages passed from the variable nodes to the check nodes at the @xmath29th iteration of belief propagation then , under the independence assumption @xmath46 where @xmath47 is the density transformation operator induced by @xmath48 .",
    "the theorem below provides a theoretical foundation of density evolution .    over the probability space of all graphs @xmath23 and channel realizations",
    "let @xmath49 be the number of incorrect messages among all @xmath50 variable - to - check node messages passed at iteration @xmath29 .",
    "let @xmath51 be the expected number of incorrect messages passed along an edge with a tree - like directed neighborhood of depth at least @xmath52 at the @xmath29th iteration , i.e. , @xmath53 then , there exist positive constants @xmath54 and @xmath55 such that for any @xmath56 and @xmath57 we have @xmath58    the main contribution of this paper is that we prove a similar density evolution formula with an associated concentration theorem for slepian - wolf coding , and establish an intimate connection between slepian - wolf coding and channel coding under density evolution .    for a given joint distribution @xmath3 on @xmath4 , we can define two channels : one from @xmath0 to @xmath1 with transition probability @xmath59 , the other from @xmath1 to @xmath0 with transition probability @xmath60 .",
    "both channels are somehow related to slepian - wolf coding as we shall discuss in the following two examples :    suppose @xmath61 , where @xmath62 and @xmath49 all assume values in @xmath63 , @xmath64 is the modulo-2 addition , and @xmath65 ( with @xmath66 ) is independent of @xmath1 .",
    "let @xmath12 be an @xmath67 binary parity - check matrix .",
    "let @xmath13 ( i.e. , @xmath68 ) be the linear code with the parity check matrix @xmath12 . assuming that all rows of @xmath12 are linearly independent , there are @xmath69 codewords in @xmath13 ,",
    "so the code rate is @xmath70 .",
    "the following scheme was suggested by wyner @xcite . given @xmath16 , the encoder sends the syndrome @xmath71 to the decoder . with the side information @xmath72",
    ", the decoder can compute @xmath73 .",
    "syndrome decoding can be implemented to find the minimum weight @xmath74 such that @xmath75 .",
    "the decoder then claims that @xmath76 is the target sequence @xmath16 .",
    "it can be shown that if the error probability of @xmath13 when used over the channel from @xmath1 to @xmath0 ( i.e. , a binary symmetric channel with crossover probability @xmath77 ) under syndrome decoding is @xmath78 , then the above slepian - wolf coding scheme is also of error probability @xmath78 . furthermore ,",
    "if @xmath13 is capacity - achieving for the channel from @xmath1 to @xmath0 , i.e , the rate of @xmath13 is @xmath79 , then the rate of this slepian - wolf coding scheme is @xmath80 , which is exactly the slepian - wolf limit .",
    "suppose @xmath0 is uniformly distributed over @xmath63 and @xmath59 is a bios channel .",
    "the encoding procedure is the same as that in example 1 .",
    "given @xmath16 , the encoder finds the coset @xmath81 that contains @xmath16 and send the syndrome @xmath82 to the decoder .",
    "so the encoder rate is @xmath83 .",
    "given the side information @xmath72 , the decoder tries to recover @xmath16 using the belief propagation decoding algorithm for @xmath81 .",
    "for a bios channel , the decoding error probability is the same for all coset codes @xmath18 under the belief - propagation algorithm .",
    "so if @xmath84 is a linear code for channel @xmath59 with error probability @xmath78 under belief - propagation decoding , then the error probability of the above slepian - wolf coset coding scheme is also @xmath78 .",
    "furthermore , assuming @xmath84 is a capacity achieving linear code for channel @xmath59 , the above coding scheme is then of rate @xmath85 , which is exactly the slepian - wolf limit . here",
    "@xmath86 is the capacity of channel @xmath59 .",
    "when @xmath0 is nonuniform , we can still use the above coset coding scheme as long as @xmath84 is a good channel code for channel @xmath59 under the belief - propagation decoding algorithm .",
    "the reason is that for a bios channel , the error probability resulting from the belief propagation decoding algorithm is the same for every codeword in every coset .",
    "nonetheless , since @xmath87 when @xmath0 is nonuniform , we see that the above coset coding scheme fails to achieve the slepian - wolf limit even when @xmath84 is an optimal channel code for channel @xmath60 .",
    "this phenomenon has been observed in @xcite .",
    "when @xmath59 is not output - symmetric , the decoding error probability , under the belief - propagation algorithm , is in general different for different codewords in each coset , and also different for different cosets . in this case , the connection between channel coding for channel @xmath59 and slepian - wolf coding is not clear .",
    "we have seen that although the above two examples exhibit some interesting connections between channel coding ( either for the channel from @xmath0 to @xmath1 or the channel from @xmath1 to @xmath0 ) and slepian - wolf coding , both of them have severe limitations . in this paper",
    "we shall provide a general framework , which includes these two examples as special cases , and within the framework establish the connection between channel coding and slepian - wolf coding .",
    "it should be emphasized that in our framework , @xmath88 does not need to be uniform , and @xmath59 does not need to be output - symmetric .",
    "we use the same encoding method as that in example 1 and example 2 .",
    "we first fix a parity check matrix @xmath12 . given @xmath16 , the encoder sends the syndrome @xmath71 to the decoder .",
    "but we do not use the channel decoding method in example 2 .",
    "the reason is that in channel coding , codewords are assumed to be equally probable , but in slepian - wolf coding , codewords are generated by @xmath88 , and are in general not equally probable if @xmath0 is not uniform over @xmath63 .",
    "it turns out that it is easy to incorporate the prior distribution @xmath88 into the belief - propagation .",
    "the update equations for the messages in this slepian - wolf decoding are described below : @xmath31 @xmath89 where @xmath90 , and @xmath91 is the syndrome value associated with check node @xmath28 .",
    "it can be verified that this algorithm produces the exact symbol - by - symbol _ a posteriori _ estimation of @xmath16 given @xmath72 when the underlying bipartite graph is a tree .",
    "we can see that the only difference from the channel decoding case is the definition of initial message @xmath92 .",
    "this decoding scheme can be viewed as a map - version of the belief propagation algorithm , while the channel decoding scheme can be viewed as a ml - version of the belief propagation algorithm .",
    "now we proceed to develop the density evolution formula for this belief - propagation algorithm .",
    "we use the standard tree assumption .",
    "let @xmath93 @xmath94 be the message distribution from a variable node to a check node at the @xmath29th iteration conditioned on the event that the variable value is @xmath95 .",
    "similarly , let @xmath96 @xmath94 be the message distribution from a check node to a variable node at the @xmath29th iteration conditioned on the event that the target variable value is @xmath95 .",
    "assume @xmath97 .",
    "let @xmath98 , where @xmath99 is a parity reversing function .",
    "we have @xmath100 where @xmath51 is the expected number of incorrect messages sent from a variable node at the @xmath29th iteration .",
    "the following theorem provides a density - evolution formula for @xmath101 .",
    "[ theorem3 ] under the tree assumption , @xmath102    _ remark _ : theorem [ theorem3 ] does not directly follow from the approach in @xcite since the all - zero codeword assumption is not valid in our setting .",
    "[ thm3 ] over the probability space of all graphs @xmath23 and source realizations let @xmath49 be the number of incorrect messages among all @xmath50 variable - to - check node messages passed at iteration @xmath29 . then",
    ", there exist positive constants @xmath54 and @xmath55 such that for any @xmath56 and @xmath57 we have @xmath58    it can be verified that the density evolution formula ( [ sourcede ] ) and concentration theorem ( theorem [ thm3 ] ) do not depend on the definition of the initial message , i.e. , they still hold if we replace @xmath103 by an arbitrary probability distribution .",
    "this provides us a useful tool to study the problem of distribution mismatch . in many applications ,",
    "the true source distribution can not be estimated perfectly .",
    "for example , suppose @xmath3 is the true source distribution and @xmath104 is the estimated source distribution .",
    "the initial message is then given by @xmath105 .",
    "let @xmath106 @xmath94 be the density of the message from a variable node to a check node at the @xmath29th iteration conditioned on the event that the variable value is @xmath95 .",
    "let @xmath107 .",
    "the density evolution formula of this mismatch problem is @xmath108 we can use the density evolution formula ( [ demismatch ] ) to check whether the error probability goes to zero when the distribution mismatch occurs .",
    "we have seen from example 2 in section [ review ] that under the ml - version of the belief - propagation decoding algorithm , the slepian - wolf coset coding scheme still works even if @xmath0 is nonuniform , as long as @xmath84 is a good channel code for channel @xmath59 under the belief - propagation decoding algorithm .",
    "actually , using the ml - version of the belief - propagation algorithm for decoding nonuniform @xmath0 can be viewed as a special case of distribution mismatch , where @xmath109 thus in this example distribution mismatch does not imply decoding failure , but it may cause rate loss .",
    "in the density evolution formula ( [ channelde ] ) in channel coding and density evolution formula ( [ sourcede ] ) in slepian - wolf coding , the channel and source statistics come in only through the initial message distribution ; all the remaining operations depend only on the degree distribution .",
    "so for a fixed degree distribution pair @xmath25 , if @xmath110 , then the two density evolutions are completely identical , i.e. , we have @xmath111 for all @xmath29 .",
    "so a natural question is : for a given slepian - wolf initial message distribution @xmath103 , does there exist a bios channel whose initial message distribution @xmath44 is the same as @xmath103 ?",
    "we now proceed to answer this question .",
    "[ symmetric ] we call a distribution @xmath112 symmetric if @xmath113 for any function @xmath114 for which the integral exists .",
    "[ symmetricini ] @xmath101 is symmetric .    _",
    "remark _ : the reason why @xmath101 is symmetric even when there is no symmetry in the source distribution @xmath3 is that the coset coding scheme is used , and the prior distribution @xmath88 is incorporated in the decoding .",
    "the following theorem is the main result of this section , which essentially says that under belief propagation decoding , for all @xmath2 pairs , slepian - wolf code design with linear codes reduces to design of codes for certain symmetric channels .    for any source distribution @xmath3 on @xmath4 ( @xmath115 with capacity @xmath86",
    "such that its initial message distribution @xmath44 is the same as the initial message distribution @xmath103 induced by @xmath3 .",
    "furthermore , we have @xmath116 .",
    "the conversion from @xmath3 to @xmath117 is given in fig .",
    "_ remark _ : it can be seen from fig . 1 that @xmath117 is in general different from @xmath59 , and @xmath117 is symmetric even when @xmath59 is not .",
    "furthermore , if @xmath88 is nonuniform , then @xmath117 is different from @xmath59 even when @xmath59 is symmetric .",
    "[ r]@xmath118[r]@xmath119[c]@xmath120[c]@xmath121[c]@xmath122[c]@xmath123[c]@xmath124[c]@xmath125[c]@xmath126[c]@xmath127[c]@xmath128[c]@xmath129[c]@xmath130[c]@xmath131[c]@xmath132[c]@xmath133[c]@xmath134 [ c]@xmath135     let @xmath136 be the function that maps @xmath3 to @xmath117 .",
    "it turns out this function is not invertible .",
    "[ equivalence ] two sources distributions , @xmath3 and @xmath137 , are equivalent if they induce the same initial message distribution @xmath103 ( or if @xmath138 ) .    for a symmetric distribution @xmath112 given by @xmath139 , @xmath140 , where @xmath141 $ ] and @xmath142",
    ", we can compute all source distributions for which the induced initial message distribution @xmath103 is equal to @xmath112 .",
    "these can be written ( possibly after relabelling ) in the following parametric form : @xmath143 where @xmath144 $ ] , @xmath145 , @xmath140 .",
    "so for a fixed initial message distribution with @xmath15 probability mass points , the set of equivalent source distributions has totally @xmath146 degrees of freedom .",
    "this should be contrasted with the @xmath147 degrees of freedom for source distributions ( over @xmath4 with @xmath148 and @xmath149 ) under the conditional entropy constraint .",
    "we can also see that the equivalent source distributions must have the same reverse channel @xmath60 ; the freedom comes only from @xmath150 .    consider the following class of source distributions @xmath151 , @xmath152 , @xmath153 , @xmath154 , @xmath155 .",
    "it is easy to verify that this class of source distributions is an equivalence class .",
    "in fact , for any distribution @xmath3 in this class , @xmath156 is the binary erasure channel with erasure probability @xmath78 .",
    "since the capacity of the binary erasure channel can be achieved with ldpc codes under the belief - propagation decoding algorithm , it follows that for distributions in this class , the slepian - wolf limit is achievable with the ldpc coset coding scheme under belief - propagation decoding .",
    "it can be verified that for fixed @xmath77 , the source distributions in example 1 are all equivalent .    given two channels , @xmath59 and @xmath117",
    ", we say @xmath157 if @xmath117 is physically degraded with respect to @xmath59 .",
    "we now generalize this concept to source distributions .",
    "[ monotonicity ] given two source distributions , @xmath3 and @xmath137 , we say @xmath158 if @xmath159 .",
    "_ remark _ : one may tend to define  monotonicity \" in the following way : @xmath158 if ( possibly after relabelling ) @xmath160 for all @xmath161 and @xmath117 is physically degraded with respect to @xmath59 .",
    "it turns out the  monotonicity \" in this sense also satisfies the condition @xmath159 , as illustrated in fig .",
    "[ r]@xmath118[r]@xmath119[c]@xmath120[c]@xmath121[c]@xmath122[c]@xmath123[c]@xmath124[c]@xmath125[c]@xmath126[c]@xmath127[c]@xmath128[c]@xmath129[c]@xmath130[c]@xmath131[c]@xmath132[c]@xmath133[c]@xmath162[c]@xmath163[c]@xmath164[c]@xmath165[c]@xmath166[c]@xmath167[c]@xmath168[c]@xmath169[c]@xmath3 [ c]@xmath137 [ c]ch(@xmath3 ) [ c]ch(@xmath137 ) [ c]@xmath135     the following theorem follows immediately from the monotonicity of density evolution with respect to physically degraded channels .",
    "suppose @xmath158 .",
    "for any fixed degree distribution pair @xmath25 , if , for @xmath137 , the error probability under density evolution goes to zero , then it must also go to zero for @xmath3 .",
    "for a fixed degree distribution pair @xmath25 and a class of distributions @xmath170 over @xmath4 , the feasible domain @xmath171 with respect to @xmath25 is the set of distributions @xmath172 for which the error probability under density evolution goes to zero .",
    "let @xmath170 be the class of distributions @xmath3 over @xmath173 such that @xmath174 .",
    "let @xmath175 and @xmath176",
    ". then @xmath170 can be parameterized by @xmath177 and @xmath77 with @xmath178 $ ] .",
    "let @xmath179\\right\\}$ ] . for any degree distribution pair @xmath25 with syndrome rate less than or equal to @xmath180 , by slepian - wolf theorem we must have @xmath181 . in fig .",
    "3 the area below the solid curve is @xmath182 .",
    "we also plot the feasible domains of several rate one - half codes .",
    "1 .   code 1 : its degree distribution pair is given in ( * ? ? ?",
    "* example 2 ) .",
    "this code is designed for a binary symmetric channel , which corresponds to @xmath183 in fig .",
    "the feasible domain of this degree distribution pair is the area below the  @xmath184 \" curve .",
    "2 .   code 2 : @xmath185 , @xmath186 .",
    "this code is designed for a binary - input awgn channel @xcite .",
    "the feasible domain is the area below the  + \" curve .",
    "code 3 is the @xmath187-regular code .",
    "its feasible domain is the area below the  * \" curve .",
    "code 4 is the @xmath188-regular code .",
    "its feasible domain is the area below the  @xmath189 \" curve .",
    "it can be seen that although code 1 is designed for the case @xmath183 , it performs very well over the whole range ; the performance of code 2 is also quite good , although it is designed for binary - input awgn channel",
    ". this should not be too surprising since under density evolution , every slepian - wolf coding problem is equivalent to a channel coding problem for a corresponding bios channel , and it is a well - known phenomenon that a code good for one bios channel is likely to be good for many other bios channels .",
    "therefore , fig .",
    "3 is simply a manifestation of this phenomenon in the slepian - wolf source coding scenario .",
    "we have established an intimate connection between slepian - wolf coding and channel coding , which clarifies a misconception in the area of slepian - wolf code design .",
    "interested readers may refer to @xcite for more details .",
    "t. p. coleman , a. h. lee , m. m@xmath190dard , and m. effros ,  low - complexity approaches to slepian - wolf near - lossless distributed data compression , \" _ ieee trans . on inform .",
    "theory _ , submitted for publication .",
    "d. schongberg , k. ramchandran , and s. s. pradhan ,  distributed code constructions for the entire slepian - wolf rate region for arbitrarily correlated sources , \" _ proceeding of ieee data compression conference ( dcc ) _ , snowbird , ut , mar .",
    "2004 .    v. stankovic , a. liveris , z. xiong , and c. georghiades ,  on code design for the general slepian - wolf problem and for lossless multiterminal communication networks , \" _ ieee trans .",
    "inform . theory _ , submitted for publication ."
  ],
  "abstract_text": [
    "<S> we consider slepian - wolf code design based on ldpc ( low - density parity - check ) coset codes for memoryless source - side information pairs . </S>",
    "<S> a density evolution formula , equipped with a concentration theorem , is derived for slepian - wolf coding based on ldpc coset codes . as a consequence , an intimate connection between slepian - wolf coding and channel coding is established . </S>",
    "<S> specifically we show that , under density evolution , design of binary ldpc coset codes for slepian - wolf coding of an arbitrary memoryless source - side information pair reduces to design of binary ldpc codes for binary - input output - symmetric channels without loss of optimality . with this connection </S>",
    "<S> , many classic results in channel coding can be easily translated into the slepian - wolf setting . </S>"
  ]
}