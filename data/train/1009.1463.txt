{
  "article_text": [
    "methods for the estimation of bayesian networks , which encode conditional independence relationships of a set of variables , have , until recently , assumed data sets that consist of independent and identically distributed samples , as described in chapter 16 of @xcite .",
    "these methods may be split into two categories , called constraint - based and score - based methods , @xcite .",
    "recent work by kasza _",
    "et al _ @xcite , has extended the applicability of score - based methods to data sets which do not necessarily consist of independent and identically distributed samples .",
    "these authors developed two score metrics which are extensions of the bge metric of geiger and heckerman , @xcite , for use in conjunction with score - based methods , to account for complex sampling structures and additional components of variance .",
    "the first metric , called the bayesian score metric , involves placing a prior distribution on the effects of exogenous variables .",
    "the second metric , inspired by the notion of restricted maximum likelihood , and called the residual score metric , is non - parametric in the effects of exogenous variables .",
    "these two score metrics lead to different posterior distributions for bayesian network parameters , and a formal comparison of these posterior distributions is necessary to determine if the residual approach provides a useful alternative to the ( fully ) bayesian approach .",
    "this comparison is the subject of the present paper .    in section [ scorerevsection ] , score - based estimation of bayesian networks",
    "is briefly reviewed , as are the bayesian and residual score metrics .",
    "the posterior distributions obtained using each score metric are also presented here . in section [ infolosssection ] the posterior distributions are compared using the kullback leibler divergence , which in general provides a useful basis for comparing probability density functions .",
    "the comparison of the posterior densities based on the kullback leibler divergence provides justification for the use of the residual score metric in the estimation of bayesian networks , both theoretically , by simulations and the analysis of data on grape - berry heat - shock genes in section [ examples ] .",
    "bayesian networks were first introduced by pearl in @xcite . a bayesian network @xmath0 , @xmath1 , for a random vector @xmath2 consists of two components : a directed acyclic graph associated with @xmath3 , @xmath4 , with @xmath5 , @xmath6 , and a set of conditional distributions @xmath7 .",
    "the set @xmath8 consists of those variables @xmath9 such that there is a directed edge from @xmath10 to @xmath11 in @xmath12 : @xmath13 . the joint distribution for @xmath3",
    "may then be written as @xmath14 we make the assumption that @xmath15 .",
    "bayesian networks are particularly useful as they allow the estimation of covariance matrices for high - dimensional data sets , which contain fewer samples than random variables , since @xmath16 can be estimated from the bayesian network .",
    "additionally , the directed acyclic graph of a bayesian network encodes information about the conditional dependence relationships between the variables in @xmath3 .",
    "the directed markov properties , as described in lauritzen @xcite , for example , allow for more conditional independence relationships to be read directly from the graph @xmath12 than could be read from @xmath17 .",
    "estimation of a bayesian network for @xmath3 given a data set @xmath18 requires estimation of the parameters @xmath19 and learning the structure of @xmath20 . to learn the structure , score - based methods move through the space of directed acyclic graphs , attempting to find the graph that maximises some score metric .",
    "an obvious choice of score metric is the likelihood of a graph , however , the structure that maximises the likelihood is the complete directed acyclic graph , encoding no conditional independence relationships , @xcite .",
    "bayesian score metrics such as those considered here avoid this problem of over - fitting . when bayesian score metrics are used to learn structure , parameters may be estimated using bayesian techniques .",
    "the bayesian score of a directed acyclic graph @xmath12 for a random variable @xmath3 is defined to be proportional to the posterior probability of the graph given the data set @xmath18 , @xcite : @xmath21 where @xmath22 is the prior probability of the graph @xmath12 , @xmath23 is the marginal likelihood of the data given the structure , and @xmath24 is the space of symmetric positive - definite @xmath25 matrices",
    ". we will not consider @xmath22 any further",
    ".    given the acyclicity of the graphs considered , @xmath26 where @xmath27 is the @xmath28-vector of samples of @xmath29 , and @xmath30 is the @xmath31 matrix of samples of the parents of @xmath29 in the graph @xmath12 .",
    "the usual assumption is that the @xmath28 samples are independent and identically normally distributed : @xmath32    to get the score metric in equation , prior distributions are required for @xmath33 and @xmath34 . as shown by geiger and heckerman , @xcite , in the case of iid samples , to obtain a score metric that scores graphs that encode equivalent sets of independence relationships identically , a property known as score equivalence , the choice of priors for @xmath33 and @xmath34 is limited to priors of the form @xmath35 given these priors , the bge score metric of @xcite is obtained , which we denote @xmath36 . the expression for @xmath37 is provided in appendix a.      often the available data set will be more complex , with non - independent samples , or a complex mean structure including exogenous variables as random effects .",
    "such additional complexities may be accounted for through the inclusion of @xmath38 exogenous variables in the model , @xcite , @xcite .",
    "if @xmath39 is the @xmath40 matrix containing data on @xmath38 exogenous variables , we assume @xmath41 where the elements in @xmath42 are called the effects of the exogenous variables .",
    "in addition to priors for @xmath33 and @xmath34 , a prior is required for @xmath42 , the effect of the exogenous variables .",
    "et al _ @xcite note that @xmath42 may be dealt with in two ways , leading to two different score metrics . to satisfy score equivalence , these approaches both use the priors in equation for @xmath33 and @xmath34 .",
    "the first approach , called the bayesian approach , is to place a prior distribution on @xmath42 .",
    "an extension of a result in @xcite implies that in order for score equivalence to hold , if @xmath43 , @xmath44 must be normally distributed .",
    "we consider prior distributions for @xmath42 that are of the form @xmath45 , since these are the only priors that result in a score metric with a closed form .",
    "the bayesian score metric is given by @xmath46 , where @xmath47 is given in appendix a.    the second approach , called the residual approach , is non - parametric in @xmath42 .",
    "this removes the effects of exogenous variables by using linear combinations of residuals obtained after regressing @xmath27 on the columns of @xmath39 .",
    "this is achieved by pre - multiplying each @xmath27 by @xmath48 , where @xmath49 is an @xmath50 matrix such that @xmath51 , @xmath52 , @xmath53 .",
    "it can then be shown that @xmath54 .",
    "the residual approach is related to restricted maximum likelihood estimation , and is particularly advantageous when the effects of the exogenous variables are included to improve the estimation of a bayesian network for @xmath3 , but are not of intrinsic interest in themselves . additionally , when the prior covariance matrix of @xmath42 can not be accurately specified , or when the assumption of a normal prior distribution for the @xmath42 is not warranted , the residual approach is preferable to the bayesian approach .",
    "the residual score metric is given by @xmath55 , and @xmath56 is shown in appendix a.    having used either the bayesian or residual score metric for learning the graphical structure , parameter estimates may be obtained from posterior distributions . since posterior estimates of @xmath57 are unavailable from the residual approach , we only consider the posterior distributions of @xmath33 and @xmath34 .",
    "using the priors from the bayesian approach , the likelihood given in equation and bayes theorem , the following posteriors are obtained : @xmath58 the joint posterior density obtained under the full bayesian approach is denoted by @xmath59 .",
    "similarly , using the residual approach , the posteriors can be shown to be @xmath60 the joint posterior density obtained under the residual approach is denoted by @xmath61",
    ".    the residual approach does not require the specification of any hyperparameters relating to @xmath42 , making it easier to use than the bayesian approach .",
    "given that in the bayesian approach , the variance of @xmath42 is dependent upon @xmath34 , and in turn related to the variance of @xmath33 , we may obtain less information about these parameters when the residual approach is used instead of the bayesian approach .",
    "it is important to quantify the difference between the bayesian and residual approaches in this respect , and this is done in the next section by measuring the kullback - leibler distance between @xmath59 and @xmath62 .",
    "using the kullback - leibler divergence as a measure of the distance between the density functions , we show that the distance between the posterior densities for the bayesian network parameters @xmath33 and @xmath34 obtained under the bayesian and residual approaches is generally small , and decreases as the sample size increases . in this way",
    ", theoretical justification for the residual approach is provided .",
    "the kullback - leibler divergence , @xcite , between @xmath59 and @xmath62 is given by @xmath63 the exact formula is set out in appendix b. instead of just considering the divergence associated with @xmath33 and @xmath34 associated with a given @xmath29 , the divergence associated with @xmath16 , the covariance matrix of @xmath3 after marginalising over @xmath42 , may be obtained . the divergence between @xmath64 , the posterior density of @xmath16 obtained under the bayesian approach , and @xmath65 , the posterior obtained under the residual approach , is then available .",
    "[ lemma ] if the underlying graphical structure of @xmath3 is known , the divergence between @xmath64 and @xmath65 is given by @xmath66 if the underlying graphical structure of @xmath3 is not known , bounds for the divergence are given by the divergence for the covariance matrix corresponding to a graph with no edges : @xmath67 and the divergence for the covariance matrix of an arbitrary full graph : @xmath68    this result follows directly from the properties of the kullback leibler divergence .",
    "our main result is the following theorem which justifies the use of the residual approach instead of the bayesian approach :    [ dinfinity ] as @xmath69 , @xmath70 .",
    "see appendix c.    this theorem tells us that as sample size increases , the posterior densitites obtained when using the residual metric more closely approximate those obtained using the fully bayesian approach .",
    "hence , provided the sample size is large enough , the residual approach offers a useful alternative to the fully bayesian approach .",
    "in this section , the residual and bayesian approaches are compared using the kullback - leibler divergence for some specific data sets .",
    "we first consider simulated data sets and then consider a data set consisting of expression levels of grape heat - shock genes .      in this example",
    ", multiple data sets were simulated from the following system of linear recursive equations : @xmath71 where the only non - zero @xmath72s were those corresponding to the edges in the graph of figure [ eg1graph ] , and @xmath73 .",
    "one hundred data sets were simulated according to this model for each pair @xmath74 , where @xmath75 and @xmath76 .",
    "for each of the simulated data sets , @xmath77 , @xmath78 , and the divergence corresponding to the true structure were calculated .",
    "the key results are summarised in figure [ eg1results ] .",
    ", scaledwidth=50.0% ]    as the true graph is quite sparse , the true divergence is closer to that of the empty graph than that of the full graph . for all values of @xmath79 , as the sample size increases , the divergence decreases , and for all sample sizes , as @xmath79 increases",
    ", the divergence increases .",
    "when @xmath79 is large , the samples are similar to independent and identically distributed samples , and the fully bayesian approach allows for this , whilst the residual approach can not . in these situations ,",
    "the exogenous variables are over - corrected for when the residual metric is applied . for larger sample sizes , figure [ eg1results ]",
    "shows that the divergences obtained for the empty and full graphs provide reasonable approximations to the divergence associated with the true structure .    , the filled circles the median value of @xmath77 , and the triangles the median loss associated with the true structure , of the 100 simulated data sets for each @xmath80 pair .",
    "the vertical bars represent interquartile ranges .",
    "note that the vertical scales of the plots differ.,scaledwidth=100.0% ]    these observations are useful in providing guidelines for the use of the residual approach for a given data set .",
    "if @xmath79 is small , no matter what size the ratio @xmath81 is , the posterior distributions obtained under the bayesian and residual approaches will be close to each other . in the case where @xmath81 is small ,",
    "provided @xmath79 is large , a similar conclusion is reached . however , for data sets with small values of @xmath81 , if the effect of exogenous variables are _ a priori _ thought to have small variances , the residual approach should be used with caution .      when the bayesian approach is used , not much information is available to guide prior specification of the covariance matrix of the effects , so iid random effects are usually assumed . in this example , we show that there exist situations where the residual posterior density is closer to the posterior obtained using the data - generating prior , than the posterior density obtained by assuming iid random effects .",
    "data sets are simulated from the following system of linear recursive equations : @xmath82 where the only non - zero @xmath83s were those corresponding to the edges in the graph of figure [ eg1graph ] , and the @xmath84 are constant across data sets , having been simulated from a standard normal distribution .",
    "one hundred data sets were simulated according to this model for each of the following selections for @xmath85 : @xmath86    let @xmath87 denote the posterior distribution obtained under the bayesian approach when the prior covariance matrix of the effects of exogenous variables is @xmath88 . for each data",
    "set , @xmath89 is calculated for values of @xmath79 between 0.0001 and 10 , given the true covariance matrix of @xmath42 .",
    "figure [ divdifffig ] summarises the median value , and the upper and lower quartiles of @xmath89 for the 100 data sets simulated under each of the four scenarios .",
    "the solid lines in figure [ divdifffig ] correspond to the scenarios where the effects of exogenous variables are heteroscedastic , and the black lines correspond to the scenarios with independent effects .",
    "when @xmath89 is positive , insufficient variation in the data is accounted for by assuming iid effects of exogenous variables with variance @xmath90 . as can be seen in figure [ divdifffig ]",
    ", this happens for all scenarios with increasing probability as @xmath79 increases .",
    "similarly , when @xmath89 is negative , the residual approach removes too much of the variation in the data .",
    "given the amount of prior information typically available about the covariance structure of the effects of exogenous variables , this example shows that use of the residual approach will often be preferable to assuming independent and identically distributed effects .     for a range of values of @xmath79 , for the 100 data sets generated for each of the scenarios described in example 2 .",
    "blue lines correspond to dependent effects of exogenous variables , black lines to independent effects .",
    "solid lines correspond to heteroscedastic effects of exogenous variables , dashed lines to homoscedastic effects.,scaledwidth=50.0% ]      we now consider a data set consisting of samples of the expression levels of grape genes , previously discussed in @xcite .",
    "this data set consists of @xmath91 expression levels of each of @xmath92 grape genes , where the grapes themselves were sampled from three different vineyards located in different wine growing regions of south australia , australia .",
    "these @xmath93 genes are heat - shock genes , see @xcite , the expression levels of which are known to be associated with changes in ambient temperature .",
    "accordingly , air temperature at each vineyard was recorded every hour from @xmath94 hours to @xmath95 hours before the grapes were sampled .",
    "the data set considered here is a subset of a larger data set obtained from an affymetrix chip microarray experiment conducted over the course of three years .",
    "gene expression values were obtained from @xmath96 grape berry tissue samples : @xmath97 of these tissue samples were taken from one vineyard , @xmath97 from the second vineyard , and @xmath98 from the third . at the first two vineyards , four grape - berry tissue samples were selected each week for @xmath99 weeks , while at the third , @xmath100 grape - berry tissue samples were selected each week for @xmath101 weeks . at each of the vineyards ,",
    "the first samples were taken at fruit set , when the fertilised grape flowers began to form berries .",
    "samples were then taken each week for a pre - specified number of weeks . in this way",
    ", gene expression levels were measured over the course of the development of the grape berries . of",
    "the @xmath96 samples taken , @xmath102 had complete temperature records .",
    "the data analysed consist of the samples from each vineyard taken in the third to seventh weeks of sampling , inclusive .",
    "the samples from these weeks correspond to a period after fruit set , but before veraison , and it is thought that the relationships between expression levels of genes are relatively stable during this period of berry development , @xcite .",
    "let @xmath103 be sample @xmath10 of gene @xmath11 , @xmath104 , @xmath105 , and let @xmath84 be the data associated with sample @xmath10 of exogenous variable @xmath106 , where @xmath38 exogenous variables are included in the model",
    ". then the following model is assumed for each sample of each gene : @xmath107    for the grape - berry genes under study here , temperature , which has been observed directly at the different vineyards , is a known driver of biological activity .",
    "moreover , when two or more genes respond similarly to the same driver of biological activity , the effect is to produce a component of correlation between the corresponding gene expression levels .",
    "thus we should study the effects of temperature as an exogenous variable .",
    "there are also likely to be additional variables which do not correspond directly to a single biological factor such as temperature .",
    "for example , the three vineyards are likely to differ in a number of features such as soil type and fertility , moisture and other micro - climate conditions , each of which could potentially influence the expression levels of certain sets of genes . here",
    "the three vineyards are separated by large regional distances , but share the same macro - climate in southern australia .",
    "thus , vineyards should be modelled as an additional exogenous variable with potentially considerable heterogeneity .",
    "it is unlikely that the effects of temperature and vineyard are independent and identically distributed .",
    "while such a claim may be valid for either the temperature effects or the vineyard effects alone , it is highly unlikely that the effects of temperature and vineyard are identically distributed .",
    "there may also be some dependence between the temperature and vineyard effects .",
    "given the difficulty in specifying a joint prior variance matrix of the temperature and vineyard effects , consideration of models including both temperature and vineyard effects simultaneously are unlikely shed light on the performance of the residual approach to the estimation of bayesian networks .",
    "we therefore proceed by considering simple models , fitting temperature and vineyards as separate exogenous variables .",
    "firstly , we consider the vineyards only model , where @xmath108 and in which we are interested in the temperature - induced correlations between genes , and secondly , the temperature only model , where @xmath109 , where we do not remove the components of correlations induced by the vineyard micro - climates .",
    "note that we are ignoring any temperature trend - component in all our models .",
    "although models containing both temperature and vineyard effects may potentially be of interest , the effects may be confounded as explained above , and there is a risk of over - fitting the data .",
    "in fact , for the full interaction model fitted to the grape - berry gene data , the effective sample size , @xmath110 , would be zero , and the kullback leibler divergence could then be substantially artificially inflated .",
    "since neither the true network nor the true value of @xmath79 is known for this data set , the bounds @xmath78 and @xmath77 are calculated for a range of values of @xmath79 .",
    "the results are shown in figure [ grapedivs ] .",
    "the left - hand graph in the figure displays the loss of information when the three vineyard effects only are included in the analysis and the right - hand graph displays the divergence when only the six main temperature effects are included .",
    "figure [ grapedivs ] indicates that for either model and all considered values of @xmath79 , if the true underlying graph is thought to be sparse , as many biological networks are thought to be , the loss of information about the marginal covariance matrix when the residual approach is used will be minimal .",
    "if the true graph of the expression levels of the genes is thought to be dense , for larger values of @xmath79 , the figure shows that the divergence for the temperature model will be less than that associated with the vineyard model .",
    "the temperature model is naturally likely to be more explanatory , with the higher number of exogenous variables fitted . for either model ,",
    "the kullback - leibler divergence is small and the residual approach metric is of demonstrable practical utility .",
    "using the kullback - leibler divergence , we have compared two methods for estimating bayesian networks for data containing exogenous variables and random effects .",
    "provided that the sample size is not too small in a statistical sense , we can conclude that the residual score metric offers a useful alternative to a fully bayesian approach , with the posterior density functions of key parameters obtained under the two approaches being generally close .",
    "many contemporary bioinformatics studies are conducted using substantial sample sizes , often based on many hundreds of samples or patients . even with smaller studies",
    "however , the results of our simulations and data analysis provide confidence that the residual estimation approach will perform well with small samples in the presence of exogenous variables .",
    "first , consider the log determinant term in @xmath125 : @xmath126 \\notag \\\\ & = & -\\frac{1}{2 }   tr\\left ( \\log\\left [   i - \\left\\ { i-",
    "\\left(\\tau i +   \\boldsymbol{x}_{p_i } ^t h_{v }    \\boldsymbol{x}_{p_i } \\right)^{-1 } \\left ( \\tau i +   \\boldsymbol{x}_{p_i } ^t pp^t   \\boldsymbol{x}_{p_i } \\right ) \\right\\}\\right ] \\right ) ,   \\notag\\end{aligned}\\ ] ] using the taylor series expansion this can be written as @xmath127.\\ ] ] if second- and higher - order terms are ignored , this becomes @xmath128 terms which cancel with other terms in @xmath129 .",
    "note also that @xmath130 and since @xmath131 , second- and higher - order terms in @xmath132 may be ignored , cancelling with other terms in @xmath125 so that the divergence becomes @xmath133 let @xmath134 , and note that as @xmath28 approaches infinity , so too does @xmath135 . from @xcite , as @xmath136 , @xmath137 hence , for large @xmath135 , @xmath138      using the following approximations , @xmath143 where @xmath144 , we may write @xmath145 ^ 2}{\\tau +   \\boldsymbol{x}_{k } ^t \\boldsymbol{x}_{k } - \\boldsymbol{x}_{k } ^tq\\left(v^{-1 } + q^tq \\right)^{-1}q^t\\boldsymbol{x}_{k } } \\right\\ }   \\notag\\end{aligned}\\ ] ] and @xmath146 as @xmath28 increases , @xmath147 approaches 1 , each of the terms in equation approaches zero , proving the result ."
  ],
  "abstract_text": [
    "<S> in this paper , we compare the performance of two methods for estimating bayesian networks from data containing exogenous variables and random effects . </S>",
    "<S> the first method is fully bayesian in which a prior distribution is placed on the exogenous variables , whereas the second method , which we call the residual approach , accounts for the effects of exogenous variables by using the notion of restricted maximum likelihood . </S>",
    "<S> we review the two score - based metrics , then study their performance by measuring the kullback leibler divergence , or distance , between the two resulting posterior density functions . </S>",
    "<S> the kullback leibler divergence provides a natural framework for comparing distributions . </S>",
    "<S> the residual approach is considerably simpler to apply in practice and we demonstrate its utility both theoretically and via simulations . in particular , in applications where the exogenous variables are not of primary interest , we show that the potential loss of information about parameters and induced components of correlation , is generally small .    </S>",
    "<S> keywords : bayesian network , exogenous variables , kullback leibler divergence , gene regulatory networks , variance components </S>"
  ]
}