{
  "article_text": [
    "i would first and foremost like to thank my supervisor alban ponse for the big amounts of time and energy he put into guiding me through this project .",
    "his advice has been invaluable to me and his enthusiasm has been a huge motivation for me throughout .    a thank you also goes out to jan van eijck for pointing me in the right direction halfway through the project .",
    "finally i would like to thank my entire thesis committee , consisting of alban ponse , paul dekker , jan van eijck , sara uckelman and benedikt lwe , for taking the time to read and grade my thesis .",
    " lars wortel , august 2011",
    "in programming practice , _ side effects _ are a well - known phenomenon , even though nobody seems to have an exact definition of what they are . to get a basic idea , here are some examples from natural language and programming that should explain the intuition behind side effects .",
    "suppose you and your wife have come to an agreement regarding grocery shopping . upon leaving for work , she told you that `` if i do nt call , you do not have to do the shopping '' .",
    "later that day , she calls you to tell you something completely different , for instance that she is pregnant .",
    "this call now has as side effect that you no longer know whether you have to do grocery shopping or not , even though the meaning of the call itself was something completely different .",
    "another example is taken from @xcite .",
    "suppose someone tells you that `` phoebe is waiting in front of your door , and you do nt know it ! '' this is a perfectly fine thing to say , but you can not say it twice because then it will no longer be true that you do nt know that phoebe is waiting ( after all , you were just told ) . here , the side effect is that your knowledge gets updated by the sentence , which makes the latter part of that sentence , which is a statement about your knowledge , false .    as said , in programming practice , side effects are a well - known phenomenon . logically , they are interesting because the possible presence of side effects in a program instruction sequence invalidates principles of propositional logic such as commutativity ( @xmath1 ) and idempotency ( @xmath2 ) .",
    "the textbook example is the following program :    .... x:=1",
    "if ( x:=x+1 and x=2 ) then y ....    here the operator @xmath3 stands for assignment and @xmath4 for an equality test .",
    "assuming an assignment instruction always succeeds ( that is , yields the reply ` true ` ) , in the above example the test @xmath5 , where @xmath6 is the instruction ` x:=x+1 ` and @xmath7 the instruction ` x=2 ` , will succeed and therefore , @xmath8 will be executed .",
    "however , should the order of those instructions be reversed ( @xmath9 ) , this no longer will be the case .",
    "the reason is that the instruction @xmath6 has a side effect : apart from returning ` true ` , it also increments the variable @xmath10 with @xmath11 , thus making it @xmath12 . if @xmath6 is executed before @xmath7 , the test in @xmath7 ( `",
    "x=2 ` ) will yield ` true ` . otherwise , it will yield ` false ` .",
    "it is easy to see that should @xmath5 be executed twice , the end result will also be ` false ` .",
    "therefore , for @xmath13 , we have that @xmath14 .",
    "now that i have given a rough idea of what side effects are , the reader is probably wondering about the second part of my thesis title : that of steering fragments .",
    "a _ steering fragment _ or _",
    "test _ is a program fragment which is concerned with the control flow of the execution of that program . to be exact",
    ", a steering fragment will use the evaluation result of a formula ( which is a boolean ) and depending on the outcome , will steer further execution of the program .",
    "thus , a steering fragment consists of two parts : a formula and a control part which decides what to do with the evaluation result of that formula . throughout this thesis",
    ", i will be using the terms steering fragment and test interchangeably .    the formula in a steering fragment can either be a primitive or a compound formula .",
    "the components of a compound formula are usually connected via logical connectives such as @xmath15 and @xmath16 , or involve negation .",
    "if the formula of a steering fragment is compound , we say that the steering fragment is a _",
    "complex steering fragment_.    we have already seen a classical example of a ( complex ) steering fragment in the previous section : the _ if @xmath17 then _ instruction . in the example above , the formula is a compound formula with @xmath18 and @xmath19 as its components , connected via the logical connective @xmath15 .",
    "the control part of this steering fragment consists of _ if _ and _ then _ and the prescription to execute @xmath8 if evaluation of ` x:=x+1 and x=2 ` yields true .",
    "the main contribution of this thesis is to construct a formal model of side effects in dynamic logic .",
    "because of that , i only had limited time and space to properly research related work done in this area . despite that",
    ", i will briefly describe some references i have come across throughout this project .",
    "currently , a formal definition of side effects appears to be missing in literature .",
    "that is not to say that side effects have been completely ignored .",
    "attempts have been made to create a logic which admits the possibility of side effects by bergstra and ponse @xcite .",
    "furthermore , an initial , informal classification of side effects has been presented by bergstra in @xcite .",
    "i will return to those references later in this thesis .",
    "black and windley have made an attempt to reason in a setting with side effects in @xcite . in their goal to verify a secure application written in c using hoare axiomatic semantics to express the correctness of program statements , they encountered the problem of side effects occurring in the evaluation of some c - expressions .",
    "they solved the problem by creating extra inference rules which essentially separate the evaluation of the side effect from the evaluation of the main expression .    also working with c",
    "is norrish in @xcite .",
    "he presents a formal semantics for c and he , too , runs into side effects in the process .",
    "norrish claims that a semantics gives a program meaning by describing the way in which it changes a program state .",
    "such a program state would both include the computer s memory as well as what is commonly known as the environment ( types of variables , mapping of variable names to addresses in memory etc . ) .",
    "norrish claims that in c , changes to the former come about through the actions of side effects , which are created by evaluating certain expression forms such as assignments .",
    "norrish formal semantics for c is able to handle these side effects .",
    "bhm presents a different style of axiomatic definitions for programming languages @xcite . whereas other authors such as black and windley above use hoare axiomatic semantics which bases the logic on the notion of pre- or postcondition , bhm uses the value of a programming language expression as the underlying primitive .",
    "he relies on the fact that the underlying programming language is an expression language such as algol 68 @xcite .",
    "expressions are allowed to have arbitrary side effects and the notions of statement and expression coincide .",
    "bhm claims that his formalism is just as intuitive as hoare - style logic and that the notion of ` easy axiomatizability '  which is a major measurement of the quality of a programming language  is a matter of a choice of formalism , which in turn is arbitrary .    in this thesis",
    "i will develop a variant of dynamic logic to model side effects .",
    "dynamic logic is used for a wide range of applications , ranging from modelling key constructs of imperative programming to developing dynamic semantic theories for natural language .",
    "an early overview of dynamic logic is given by harel in @xcite .",
    "more recently , van eijck and stokhof have given an extensive overview of various systems of dynamic logic in @xcite .",
    "intuitively , a side effect of a propositional statement is a change in state of a program or model other than the effect ( or change in state ) it was initially executed for . in this thesis i will present a system that makes this intuition explicit .",
    "first , in chapter [ ch : qdl ] i will present the preliminaries on which my system , that can model program instructions and their effect on program states , is based .",
    "this system , which i present in chapter [ ch : modifying ] , will be a modified version of quantified dynamic logic , overviews of which can be found in @xcite .    after introducing some terminology and exploring the logic behind this system in chapters [ ch : terminology ] and [ ch : logicalstructure ]",
    ", i can formally define side effects , which i will do in chapter [ ch : treatment ] . in chapter",
    "[ ch : classification ] i will proceed to giving a classification of side effects , introducing marginal side effects as the most important class .    in chapter [ ch : pga ] i will present a case study to see this definition of side effects in action . for this",
    "i will use an  again slightly modified  version of program algebra @xcite .",
    "i will end this thesis with some conclusions and some pointers for future work .",
    "in order to say something useful about side effects , we need a formal definition .",
    "such a definition can be found using dynamic logics .",
    "the basic idea here is that the update of a program instruction is the change in program state it causes .",
    "this allows us to introduce an expected and an actual evaluation of a program instruction .",
    "the expected evaluation of a program instruction is the change you would expect a program instruction to make to the program state upon evaluation .",
    "this may differ , however , from the actual evaluation , namely when a side effect occurs when actually evaluating the program instruction .",
    "the side effect of a program instruction then is defined as the difference in expected and actual evaluation of a program instruction .    to flesh this out in a formal definition ,",
    "we first need a system that is able to model program states and program instructions . _",
    "quantified dynamic logic _ ( qdl ) is such a system .",
    "qdl was developed by harel @xcite and goldblatt @xcite .",
    "it can be seen as a first order version of _ propositional dynamic logic _",
    "( pdl ) , which was developed by pratt in @xcite .",
    "much of the overview of both pdl and qdl i will give below is taken from the overview of dynamic logic by van eijck and stokhof @xcite .",
    "dynamic logic can be viewed as dealing with the logic of action and the result of action @xcite .",
    "although various kinds of actions can be modelled with it , one is of particular interest for us : the actions performed on computers , i.e. computations .",
    "in essence , these are actions that change the memory state of a machine , or on a somewhat higher level the program state of a computer program .",
    "regardless of what kinds of actions are modelled , the core of dynamic logic can in many cases be characterized in a similar way via the logic of ` labelled transistion systems ' . a labelled transition system or lts over a signature @xmath20 , with @xmath21 a set of propositions and",
    "@xmath22 a set of actions , is a triple @xmath23 where @xmath24 is a set of states , @xmath25 is a valuation function and @xmath26 is a set of labelled transitions ( one binary relation on @xmath24 for each label @xmath27 ) .",
    "there are various versions of dynamic logic .",
    "before i will introduce two of these , i will first describe the setting i will be using in my examples . this setting consists of a toy programming language that is expressive enough to model the working examples i need to discuss side effects .",
    "my toy language should be able to handle assignments and steering fragments .",
    "the steering fragment can possibly be complex , so our toy language should be able to handle compound formulas : multiple formulas ( such as equality tests ) connected via logical connectives .",
    "in particular , i will be using short - circuit left and ( @xmath28 ) and short - circuit left or ( @xmath29 ) as connectives .",
    "finally , assignments should be allowed in tests as well : they are , in line with what one would expect , defined to always return ` true ` .    as toy language i will first present the while language defined by van eijck in @xcite .",
    "we will see soon enough that we will actually need more functionality than it offers , but it will serve us well in the introduction of pdl , qdl and the illustration of the problems we will run into .    the while language works on natural numbers and defines arithmetic expressions , boolean expressions and programming commands .",
    "arithmetic expressions @xmath27 with @xmath30 ranging over numerals and @xmath31 over variables from a set @xmath32 are defined as follows : @xmath33 boolean expressions are defined as : @xmath34 finally , we define the following programming commands : @xmath35 for the sake of simplicity , we will postpone the introduction of the while command until after we have presented our modified system in chapter [ ch : modifying ] .",
    "the semantics of the arithmetic expressions are fairly self - explanatory .",
    "we assume that every numeral @xmath30 in @xmath36 has an interpretation @xmath37 and let @xmath38 be a mapping from @xmath32 to @xmath39 .",
    "we then have the following interpretations of the arithmetic expressions , relative to initial valuation or initial program state @xmath38 : @xmath40 the semantics of the boolean expressions are standard as well , writing @xmath41 for true and @xmath42 for false : @xmath43 the semantics of the commands of the toy language can be given in various styles . here",
    "i take a look at a variant called structural operational semantics @xcite .",
    "it is specified using a transition system from pairs of a state and a command , to either a state or again a state and a ( new ) command .",
    "first i will give the transitions for the assignment command .",
    "it looks like this , where we write @xmath44 $ ] for the valuation which is like valuation @xmath38 except for the variable @xmath31 , which has been mapped to @xmath45 : @xmath46\\ ] ] here we have the pair of state @xmath38 and the assignment command @xmath47 at the start of the transition . after the transition",
    ", we only have a new state left , since the execution of this command has finished in a single step .",
    "the skip command does nothing : it does not change the state and it finishes in a single step .",
    "@xmath48    in structural operational semantics , there are two rules for sequential composition , one for when program @xmath49 finishes in a single step and one for which it does not .",
    "@xmath50 @xmath51    finally , we have the rules for conditional action . there are two ( similar ) rules , depending on the outcome of the test : @xmath52 @xmath53      now that i have introduced the toy language , it is time to take a look at the first version of dynamic logic we are interested in : propositional dynamic logic ( pdl in short ) .",
    "the language of pdl consists of formulas @xmath6 ( based on basic propositions @xmath54 ) and programs @xmath55 ( based on basic actions @xmath56 ) : @xmath57 as the name suggests , pdl is based on propositional logic .",
    "this means that the usual properties such as associativity and duality are valid and will be used throughout .",
    "furthermore , we can use the following abbreviations : @xmath58\\phi & = \\lnot\\langle\\alpha\\rangle\\lnot\\phi\\end{aligned}\\ ] ]    the relational composition @xmath59 of binary relations @xmath60 on state set @xmath24 is given by : @xmath61 the @xmath30-fold composition @xmath62 of a binary relation @xmath63 on @xmath24 with itself is recursively defined as follows , with @xmath64 the identity relation on @xmath24 : @xmath65 finally , the reflexive transitive closure of @xmath63 is given by : @xmath66 to define the semantics of pdl over basic propositions @xmath21 and basic actions @xmath22 , we need the labelled transistion system @xmath67 for signature @xmath68 . the formulas of pdl are interpreted as subsets of @xmath69 , the actions as binary relations on @xmath69 .",
    "this leads to the following interpretations : @xmath70 the programming constructs in our toy language are expressed in pdl as follows : @xmath71    although pdl is a powerful logic , it is not enough yet to properly model the toy language we need .",
    "the reason for that is the need for assignments .",
    "since assignments change relational structures , the appropriate assertion language is first order predicate logic , and not propositional logic @xcite .",
    "so instead of pdl , which as the name suggests uses propositional logic , we need a version of dynamic logic that uses first order predicate logic .",
    "this is where quantified dynamic logic ( qdl in short ) comes in .",
    "the language of qdl consists of terms @xmath45 , formulas @xmath6 and programs @xmath72 .",
    "for functions @xmath73 and relational symbols @xmath63 we have : @xmath74 in the case of natural numbers , examples of @xmath73 are @xmath75 etc . and examples of @xmath63 are @xmath76 and @xmath77 .",
    "the same abbreviations as in pdl are used , most notably @xmath78 and @xmath79\\phi = \\lnot\\langle\\pi\\rangle\\lnot\\phi$ ] .",
    "the random assignment ( @xmath80 ) does not increase the expressive power of qdl @xcite .",
    "it can , however , be nicely used to express the universal and existential quantifier : @xmath81\\phi\\end{aligned}\\ ] ]    the pair @xmath82 is called a first order signature .",
    "a model for such a signature is a structure of the form @xmath83 where @xmath84 is a non - empty set , the @xmath85 are interpretations in @xmath84 for the members of @xmath73 and the @xmath86 similarly are the interpretations in @xmath84 for the members of @xmath63 .",
    "now let @xmath32 be the set of variables of the language .",
    "interpretation of terms in @xmath87 is defined relative to an initial valuation @xmath88 : @xmath89 truth in @xmath87 for formulas is defined by simultaneous recursion , where @xmath90 then means that @xmath91 differs at most from @xmath38 on the assignment it gives to variable @xmath31 : @xmath92 the same goes for the relational meaning in @xmath87 for programs : @xmath93\\tag{qdl10}\\\\ _ { g}\\llbracket { \\text{?}}\\phi \\rrbracket_{h}^{m } \\text { iff } & g = h \\text { and } m \\models_{g } \\phi\\tag{qdl11}\\\\ _ { g}\\llbracket \\pi_{1};\\pi_{2 } \\rrbracket_{h}^{m } \\text { iff } & \\exists f\\text { with } _ { g}\\llbracket \\pi_{1}\\rrbracket_{f}^{m } \\text { and } _ { f}\\llbracket \\pi_{2}\\rrbracket_{h}^{m } \\tag{qdl12}\\\\ _ { g}\\llbracket \\pi_{1 } \\cup \\pi_{2 } \\rrbracket_{h}^{m } \\text { iff } & _ { g}\\llbracket \\pi_{1}\\rrbracket_{h}^{m } \\text { or } _ { g}\\llbracket \\pi_{2}\\rrbracket_{h}^{m}\\tag{qdl13}\\\\ _ { g}\\llbracket \\pi^ { * } \\rrbracket_{h}^{m } \\text { iff } & g = h \\text { or } _",
    "{ g}\\llbracket \\pi;\\pi^ { * } \\rrbracket_{h}^{m}\\tag{qdl14}\\end{aligned}\\ ] ] the above definition makes concatenation ( @xmath94 ) an associative operator : @xmath95 as a convention , we omit the brackets wherever possible .",
    "although qdl goes a long way to modelling our toy language and program states , we are not quite there yet .",
    "the modifications we have to make come to light when we examine the expressive power of qdl .",
    "qdl currently has more expressive power than it has semantics defined for .",
    "this problem surfaces when the modality operator is nested within a test , like this : @xmath96 this is the program @xmath97 , with @xmath98 , @xmath99 and @xmath100 . as the semantics of qdl",
    "are currently defined , the program @xmath72 will make a change to an initial valuation @xmath38 if it is interpreted in it , returning valuation @xmath91 where the assignment @xmath38 had for variable @xmath31 will be expressed by @xmath45 .",
    "this is expressed by qdl10 .",
    "however , the current semantics only assign relational meaning to a test instruction @xmath97 as long as @xmath101 , as expressed by qdl11 .",
    "another similar example is the following : @xmath102 although this situation should be similar as above , it is not : because the program state gets changed twice , qdl now _ is _ able to assign semantics to this program since the program state gets returned to the original state by the second program instruction ( and we therefore have @xmath103 ) .",
    "so , not only can we devise even a very simple correct qdl - program for which there are no semantics defined , we can also give a very similar example for which qdl does define semantics .",
    "not only does that somewhat erratic behavior seem undesirable , but the nature of the examples here present us with a problem when we are considering side effects .",
    "exactly for the situations in which side effects occur , namely when an instruction in a test causes a change in the program state , there are no semantics defined in qdl .",
    "therefore , i am going to have to modify qdl so that it does define semantics in those situations .",
    "in this chapter i will present _ dynamic logic with assignments as formulas _ , or dla@xmath0  in short , the resulting dynamic logic after making two major modifications to qdl .",
    "the modifications i will make are such that dla@xmath0  can model the specific kinds of constructions that we are interested in .",
    "this means that , like the name suggests , we have to introduce semantics for assignments in formulas .",
    "furthermore , we will drop or modify some other qdl - instructions that we do not need .",
    "because of that dla@xmath0  evades the problem of qdl mentioned in section [ sec : qdl ] of the previous chapter and one other problem i will get back to in section [ sec : while ] .",
    "before i introduce dla@xmath0 , however , i will show the modifications that need to be done to van eijck s while language so that it can model the instructions we need .    in the while language , boolean",
    "expressions are assumed to cause no state change upon evaluation .",
    "however , for our purpose this is inadequate .",
    "we want to allow assignments in tests as well and they cause a state change .",
    "this warrants the first modification to the while language and its semantics : assignments are allowed in boolean expressions .",
    "the second modification is that the boolean or function will be replaced by a short - circuit version : @xmath104 the new semantics for boolean expressions are like the semantics defined by van eijck , with as major difference that there are now semantics defined for assignments : @xmath105 furthermore , boolean expressions now might introduce a state change , so every command containing a boolean expression ( which for now only is the if then else command ) should account for that . in structural operational semantics ,",
    "we take a look at how the boolean expression changes the state and perform the remaining actions in that new state : @xmath106 and similar for the case that @xmath107 .    as said ,",
    "there is one more thing that needs to be modified in the language above .",
    "in order to be properly able to reason about side effects , the order in which the tests get executed is important . because of that , the or construct in boolean expressions needs to be replaced by a short - circuit directed version : @xmath108 we will make use of its dual , the short - circuit left and ( @xmath28 ) too .",
    "it is defined similarly as above . as a convention , from here on @xmath29 and @xmath28",
    "can be used interchangeably in definitions , unless explicitly stated otherwise . both @xmath29 as well as @xmath28 are associative .",
    "we again omit brackets wherever possible .",
    "all we have left to define now is the state change a boolean can cause .",
    "this is defined as follows : @xmath109 & \\text{if } b = ( v:=t)\\\\ g & \\text{o.w . } \\end{cases}\\end{aligned}\\ ] ]    missing in the above while language are the random assignment and the existential quantifier .",
    "this is because i have decided to drop them .",
    "the reason for that is that they can cause non - deterministic behavior and in this thesis , we are not interested in the ( side effects of ) non - deterministic programs .",
    "in fact it is questionable whether we can say anything about side effects in non - deterministic programs , but i will return to that in my possibilities for future work in chapter [ ch : conclusions ] . aside from that , in our context of (",
    "imperative ) programs , the random assignment is an unusual concept at best .",
    "the same goes for the formula @xmath110 .    with those modifications to the toy language in mind",
    ", we can take a look at the similar modifications that need to be made to qdl . in the resulting dynamic logic dla@xmath0",
    ", we keep the same terms : @xmath111    in dla@xmath0  we of course drop the random assignment and existential quantifier , too . by dropping them ,",
    "we lose the quantified character of qdl . because of that , the resulting logic is no longer called a quantified dynamic logic . the first major change to qdl , besides the absence of the random assignment and the existential quantifier , is that i replace the @xmath112 command with the weaker @xmath113 \\top$ ] : @xmath114 \\top\\ ] ] this modification explicitly expresses the possibility of assignments in formulas .",
    "all other programs , however , are no longer allowed in formulas .",
    "because of this modification we will avoid a number of problems that qdl has , while keeping the desired functionality that there should be room for assignments in formulas .",
    "i will address these problems in detail in section [ sec : while ] .",
    "we have also replaced the @xmath16 connective with its short - circuit variant ( @xmath29 ) and for convenience , have explicitly introduced its dual ( @xmath28 ) .",
    "we will return to the motivation for this change at the end of this chapter .",
    "we also need to replace the qdl - formula associated with this command ( qdl9 ) .",
    "the truth in @xmath87 for the new command is defined as follows : @xmath115 \\top \\text { always } \\tag{dla9}\\ ] ] it should come as no surprise that this always succeeds , since assignments always succeed and yield ` true ` .",
    "since this formula always succeeds , we replaced the possibility modality ( @xmath116 ) for the necessity modality ( @xmath117\\top$ ] ) .",
    "the reason we keep this formula in the form of a modality at all ( and not just @xmath118 ) , is because formulas of this form can change the initial valuation .",
    "this is in sharp contrast to the basic formulas @xmath119 and @xmath120 , which do not change the initial valuation and are typically not modalities .",
    "because of that , it is unintuitive to write the assignment formula as @xmath118 .    on a side note : in our toy language we _ do _ simply write @xmath118 for the assignment , regardless of where it occurs .",
    "this is because in the world of ( imperative ) programming , assignments are allowed in steering fragments .",
    "we will see below that we are going to accept possible state changes in formulas , in contrast to the original qdl versions . for this",
    "we will use a mechanism to determine when a state change happens , that is , a function that returns the program(s ) that are encountered when evaluating a formula @xmath6 .",
    "this function is defined as follows :    the * program extraction function * @xmath121 returns for formula @xmath6 the program(s ) that are encountered when evaluating the formula given modal @xmath87 and initial valuation @xmath38 .",
    "it is defined recursively as follows : @xmath122 \\top ) & = ( v:=t)\\end{aligned}\\ ] ]    in the first three cases , no programs are encountered",
    ". therefore , the program extraction function returns the empty program ( @xmath123 ) .",
    "the formula @xmath124 is transparent , that is , it returns any program encountered in its subformula @xmath6 . because of the short - circuit character of @xmath29 and @xmath28 ,",
    "a case distinction is made here : in case of @xmath29 , @xmath125 will not be evaluated if @xmath126 yields true , therefore only the program(s ) encountered in @xmath126 will be returned .",
    "otherwise , the result is a concatenation of the program(s ) encountered in @xmath126 and @xmath125 .",
    "obviously , for @xmath28 the opposite is the case and this clause is derivable from the previous one using duality .",
    "finally , if the formula is an assignment , the program equivalent of that assignment is returned .    because the evaluation of a formula now can cause a state change ,",
    "the original definition for the truth in @xmath87 of @xmath29 ( qdl7 ) is no longer valid . in case",
    "@xmath126 contains an assignment , @xmath125 must be evaluated in a different valuation , namely the one resulting after evaluating @xmath126 in the initial valuation : @xmath127 since we have added @xmath28 to formulas as well , we also explicitly have to define the truth in @xmath87 for @xmath28 , which is similar to the updated definition of @xmath29 : @xmath128 although @xmath29 and @xmath28 use short - circuit evaluation , we do not explicitly have to define them as such above because we will make sure , via the program extraction function and an updated version of qdl11 ( see below ) , that the valuation does not change as a result of @xmath125 when @xmath129 is true ( in case of @xmath29 ) or false ( in case of @xmath28 ) .",
    "we can now turn our attention to programs in dla@xmath0 .",
    "besides the absence of the random assignment , what a program @xmath72 can be does not change : @xmath130 to remedy the problem that more things can be expressed in qdl than there are semantics for , we need , as mentioned earlier , to accept that a state change can occur when evaluating a program containing formulas . in the case of qdl , that only is the test instruction , given semantics earlier in qdl11 .",
    "so , as second major change we need to replace qdl11 by : @xmath131 the choice here is in place to avoid looping behavior when evaluating @xmath132 .",
    "the definitions above make extensive use of the empty program ( @xmath123 ) . in what follows",
    ", it will be handy to know that the empty program is truly empty .",
    "in particular , we would like to have @xmath133 and @xmath134 .",
    "i will prove that below .",
    "[ emptyprogram ] for any program @xmath72 , initial valuation @xmath38 , output valuation @xmath91 and model @xmath87",
    "@xmath135    the proof follows from the above defined qdl - axioms : @xmath136 since we have @xmath137 iff @xmath138 and @xmath139 , and since the latter is always true , we have @xmath140    for any program @xmath72 , initial valuation @xmath38 , output valuation @xmath91 and model @xmath87",
    "@xmath141    similar as for lemma [ emptyprogram ] .    the change to qdl11 has remedied the problem that there are expressions in qdl for which there are no semantics defined .",
    "of course i made a second major change  namely replacing @xmath142 by @xmath113 \\top$ ] .",
    "the reason for that will come to light as soon as i will reintroduce the while command in section [ sec : while ] . before i will do that , however",
    ", i will first discuss a working example to provide some more insight into the inner workings of dla@xmath0 .      in this section i will present a working example to illustrate how dla@xmath0  works .",
    "i will use the following program , presented here in our toy language :    & x : = 1 ; & + & ( x:=x+1   x = 2 ) & + & y:=1 & + & y:=2 &    in dla@xmath0 , this translates to :    & x:=1 ; & + & ( ( [ x:=x+1 ]   x=2);y:=1 ) & + & & + & ( ( [ x:=x+1 ]   x=2);y:=2 ) &    the valuations @xmath143 are defined for all variables @xmath144 , i.e. they are total functions .",
    "usually we are only interested in a small number of variables , e.g. @xmath10 and @xmath8 , in which case we talk about a valuation @xmath38 such that @xmath145 , or if valuation @xmath91 is an update of valuation @xmath38 , @xmath146 $ ] ( which is a shorthand for @xmath147[y \\mapsto \\llbracket t'\\rrbracket_{g}^{m}]$ ] ) .",
    "in all examples we discuss we take for @xmath87 the model of the natural numbers and we use numerals to denote its elements .    since we are working on natural numbers , as constants we have @xmath30 ranging over numerals , as functions we have @xmath148 and @xmath149 , and as extra relation we have @xmath76 .",
    "our model @xmath87 contains those constants , functions and relations .",
    "assume we have an initial valuation @xmath38 that sets @xmath10 and @xmath8 to @xmath150 : @xmath151 .",
    "we will now first show how the program in our toy language gets evaluated using the structural operational semantics we provided in chapter [ ch : qdl ] : @xmath152,\\big(\\text{if } ( x:=x+1 { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x = 2)\\text { then } y:=1\\text { else } y:=2\\big))\\end{aligned}\\ ] ] we now need to know if @xmath153 } = t$ ] .",
    "we can easily see that it is and furthermore updates the valuation again by incrementing @xmath10 by @xmath11 .",
    "thus we get as valuation @xmath154 $ ] and we can finish our evaluation as follows : @xmath155,\\big(y:=1\\big ) ) \\longrightarrow g[x \\mapsto 2 , y \\mapsto 1]\\end{aligned}\\ ] ] having seen how our example program evaluates using the semantics for our toy language , we can turn our attention to the evaluation using dla@xmath0 .",
    "we need to ask ourselves if @xmath156 exists ( with @xmath72 the program above ) , that is , if there is a valuation @xmath91 that models the state of the program after being executed on initial valuation @xmath38 .",
    "schematically , @xmath72 can be broken down as follows :    & : : = _ 0;_1 & + _ 0 & : : = x:=1 & + _ 1 & : : = ( _ 0 ; _ 2 ) ( _ 0 ; _ 3 ) & + _ 2 & : : = y:=1 & + _ 3 & : : = y:=2 & + _ 0 & : : = _ 1   _ 2 & + _ 1 & : : = [ x:=x+1 ] & + _ 2 & : : = x=2 &    the break - down above paves the way to evaluate @xmath156 using the dla@xmath0-axioms given in the previous sections .",
    "we start by applying qdl12 : @xmath157 we find @xmath73 by evaluating @xmath158 using qdl10 and qdl1 : @xmath159\\\\ & = g[x \\mapsto 1]\\end{aligned}\\ ] ] now we need to evaluate @xmath160 . using qdl13 , we get : @xmath161 first we turn our attention to @xmath162 . using qdl12 again",
    "we get @xmath163 such that @xmath164 and @xmath165 . to evaluate the former , we need to use our own rule dla11 . here",
    "we need the program extraction function @xmath166 for the first time : @xmath167\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2))\\rrbracket_{d}^{m}\\\\ & \\text{iff } m \\models_{f } [ x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2)\\\\ & \\text{and } _ { f}\\llbracket \\pi_{f}^{m } ( [ x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2 ) ) \\rrbracket_{d}^{m}\\end{aligned}\\ ] ] we will first have a look at the program extraction function @xmath166 . below we will see how it calculates the programs that are encountered while evaluating the formula @xmath168 : @xmath169\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2 ) ) & = \\pi_{f}^{m } ( [ x:=x+1]\\top);\\pi_{f}^{m}(x=2)\\\\ & = ( x:=x+1);{\\text{?}}\\top\\end{aligned}\\ ] ] therefore , we have : @xmath167\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2))\\rrbracket_{d}^{m}\\\\ & \\text{iff } m \\models_{f } [ x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2)\\\\ & \\text{and } _ { f}\\llbracket x:=x+1;{\\text{?}}\\top \\rrbracket_{d}^{m } \\text { iff }   _",
    "{ f}\\llbracket x:=x+1 \\rrbracket_{d}^{m}\\end{aligned}\\ ] ] the first of these two , @xmath170\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2)$ ] , nicely shows why we need an updated version of @xmath28 and @xmath29 . as we already noticed the test @xmath171 contains a program ( the assignment @xmath18 ) and therefore the state ( valuation ) changes .",
    "as we will see , this will change the outcome of the second part of the test .",
    "we need dla7b and our program extraction function @xmath166 here : @xmath172 @xmath173 is defined by dla8 to be always true .",
    "applying qdl10 on @xmath174 will give us @xmath175 $ ] .",
    "we can then apply qdl5 on @xmath176 : @xmath177 we can easily see ( using qdl1 ) that @xmath178 .",
    "therefore , we have @xmath176 and thus @xmath170\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2)$ ] .",
    "we now need to finish the evaluation of dla11 by evaluating @xmath179 .",
    "this can again be done using qdl10 and gives us @xmath180 $ ] . because the test @xmath171 has now succeeded",
    ", we can continue to the evaluation of @xmath181 .",
    "this will give us @xmath182 $ ] .",
    "having already established that @xmath183 succeeds , we also know that @xmath184 will not succeed .",
    "therefore , we are done with the evaluation of this program @xmath72 , getting that @xmath156 with @xmath185 is indeed possible with @xmath186 $ ] .      in section [",
    "sec : toy ] i introduced our toy language , which was like van eijck s while language , but without a while ( or : guarded iteration ) programming command . now that we have seen dla@xmath0  in action in our simplified toy language ,",
    "it is time to re - introduce the while command . after doing that",
    ", we will see that the re - introduction of while raises some more issues that warrant the second modification i made to qdl , namely replacing the formula @xmath142 with @xmath117\\top$ ] .",
    "the while command takes the form while @xmath187 do @xmath188 .",
    "the complete list of programming commands in our toy language then is : @xmath189 in structural operational semantics , the semantics for the guarded iteration are as follows .",
    "there are two options : if the guard ( @xmath187 ) is not satisfied , command @xmath188 is not executed .",
    "instead , the command finishes , with as only ( possible ) change the change that the evaluation of guard @xmath187 has made to the state : @xmath190 if the guard _ is _ satisfied , the rule becomes a little more complicated because command @xmath188 gets executed in a state which is possibly changed by guard @xmath187 .",
    "like before , we have two cases : one for which @xmath188 finishes in a single step and one for which it does not .",
    "@xmath191 @xmath192      in pdl , and therefore qdl and dla@xmath0 , while is expressed as follows : @xmath193 thanks to the updated rule for @xmath97 ( dla11 ) , dla@xmath0  is able to handle programs with while perfectly . to see how this works ,",
    "consider the following example :    & x : = 0 ; & + & y : = 0 ; & + & ( x:=x+1   x 2 ) & + & y:= y+ 1 &    in dla@xmath0 , this translates to :    & x:=0 ; & + & y:=0 ; & + & ( ( [ x:=x+1 ]   x2);y:=y+1)^ * ; & + & ( [ x:=x+1 ]   x2 ) &    after the first two commands , we have @xmath194 .",
    "we now need to look at how the @xmath195 operator is evaluated .",
    "qdl14 states that @xmath196 iff @xmath103 or @xmath197 .",
    "this means that @xmath72 is either executed not at all ( in which case @xmath103 ) or at least once . in our case ,",
    "@xmath198\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x\\leq 2);y:=y+1 $ ] .",
    "the first option is that @xmath72 is executed not at all , in which case @xmath103 .",
    "however , under this valuation @xmath91 there is no possible valuation @xmath199 after evaluation of the next program command ( @xmath200\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x\\leq 2)$ ] ) . in other words , @xmath201\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x\\leq 2)\\rrbracket_{h'}^{m}$ ] is false .",
    "therefore , we have to turn our attention to the other option given by the @xmath195 command , which is @xmath202 . for the evaluation of this",
    "we first need qdl12 , which tells us that there has to be an @xmath73 such that @xmath203 and @xmath204 . in section",
    "[ sec : example ] we have already seen how @xmath205 evaluates ; it will succeed and result in a new valuation @xmath206 $ ] .",
    "now we need to evaluate @xmath207 again , but this time with a different initial valuation ( namely @xmath73 ) .",
    "this loop continues until we arrive at a valuation @xmath208 for which the final program command ( the test @xmath200\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x\\leq 2)$ ] ) _ will _ succeed . in our example",
    ", this happens in the second iteration , when we have @xmath209 $ ] , giving us a resulting valuation @xmath210 $ ] , which is exactly what we would expect given this while loop .",
    "an interesting problem regarding the while language and qdl is that while @xmath41 do skip ( looping behavior ) and abort ( abnormal termination ) are indistinguishable . in some semantics , such as natural semantics ,",
    "this is also the case @xcite . in structural operational semantics",
    ", however , there is an ( infinite ) derivation sequence for while @xmath41 do skip , whereas there is no derivation sequence for abort .    using the standard lemma that @xmath211 ( cf .",
    "@xcite ) we can prove the equivalence of while @xmath41 do skip and abort in qdl .",
    "to do so , we need to ask if @xmath212 .    in qdl , looping behavior and abnormal termination are equivalent : for any @xmath6 @xmath213    we will work out the left part first : @xmath214",
    "so we have @xmath215 with @xmath216 .",
    "truth of the former in a random model @xmath87 and for an initial valuation @xmath38 is defined as follows : @xmath217",
    "furthermore we have @xmath218 we have seen in the previous section how such a formula evaluates ; after one iteration we will have @xmath219 , with @xmath138 , as one of the options the @xmath195 command gives us .",
    "finally we have @xmath220 this is always the case , so indeed there is an @xmath91 such that @xmath221 ( namely @xmath222 ) .",
    "therefore , determining the truth of @xmath223 comes down to determining the truth of @xmath224 , which is @xmath225 .",
    "since that is exactly the right hand side of the equation we started out with , we indeed have that @xmath226    not being able to distinguish between looping behavior and abnormal termination seems undesirable .",
    "it is because of this that i have decided to drop the @xmath142 formulas and replace it by the weaker , but less problematic formulas @xmath113 \\top$ ] .",
    "looping behaviour can now no longer be proven to be equivalent to abnormal termination .",
    "furthermore , we avoid problems with formulas that require infinite evaluations , such as @xmath227 .    because looping behavior and abnormal termination can no longer be proven equal in dla@xmath0 , the relational meaning of dla@xmath0-instructions now is an instance of the structural operational semantics we defined for our toy language , with the valuations as ` states ' .",
    "naturally , this is what we want , since it expresses that dla@xmath0  is a fully defined system that has the behavior we would expect given our toy language .",
    "this modification also underlines the usefulness of the switch to short - circuit versions of the logical connectives ( @xmath29 and its dual @xmath28 ) . in qdl",
    ", the steering fragment of the program @xmath228 can be expressed using @xmath229 . in dla@xmath0",
    "such an expression now no longer is allowed .",
    "however , having @xmath28 and @xmath29 in dla@xmath0  allows us to provide a perhaps even more natural translation of this program , namely @xmath230 \\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x=2)$ ] .",
    "the full evaluation versions of these logical connectives ( @xmath15 and @xmath16 ) would not do , because the order of the program instructions is important here .",
    "as we will see in chapter [ ch : terminology ] , we do not _ need _ @xmath28 and @xmath29 in dla@xmath0 , but the fact they provide natural translations of this kind , together with the fact that having logical connectives defined is standard in dynamic logic , is reason enough to keep them .",
    "in this chapter i will present the terminology i will be using in the remainder of this thesis . in particular , i will present a more fine - grained breakdown of the definitions for formulas , instructions and programs .",
    "furthermore , i will introduce a property of formulas called normal form and use that to prove yet another property of dla@xmath0  regarding complex steering fragments .",
    "next , i will introduce a subclass of programs called deterministic programs .",
    "finally , i will introduce a property of deterministic programs called canonical form .      in this section i will present the more fine - grained breakdown of the definitions for formulas , instructions and programs .",
    "[ def : formulas ] * formulas * can either be primitive or compound formulas .",
    "* primitive formulas * are written as @xmath231 and defined as follows : @xmath232 \\top\\ ] ] * compound formulas * are written as @xmath6 and defined similarly , but with negation and short - circuit disjunction and conjunction as addition : @xmath114 \\top\\ ] ]    [ def : instructions ] * instructions * can either be single instructions or basic instructions . *",
    "single instructions * are written as @xmath233 and defined as follows : @xmath234 * basic instructions * are written as @xmath235 and have a little less restrictive definition regarding tests : @xmath236 this means that single instructions form a subset of basic instructions : @xmath237    * programs * are written as @xmath72 and consist of one or more basic instructions joined by either concatenation ( @xmath94 ) , union ( @xmath238 ) or repetition ( @xmath195 ) : @xmath239      in this section i will introduce a property of formulas called normal form and use that to prove a property of dla@xmath0  regarding complex steering fragments .",
    "i will start with the former .",
    "a formula is said to be in its * normal form * iff all negations ( if any ) that occur in the formula are on atomic level , that is if the negations only have primitive formulas as their argument ( i.e. are of the form @xmath240 )",
    ".    any formula can be rewritten into its normal form such that its relational meaning is preserved .",
    "left - sequential versions of de morgan s laws are valid for formulas ( we come back to this point in chapter [ ch : logicalstructure ] ) : given model @xmath87 and initial valuation @xmath38 we prove that @xmath241 for @xmath242 , first assume that @xmath243 , thus @xmath244 for @xmath245 , thus @xmath246 , and thus @xmath247 . if @xmath248 , then @xmath249 , and thus also @xmath247 .    in order to show @xmath250 ,",
    "first assume that @xmath249 , thus @xmath251 , thus @xmath252 . if @xmath243 , then @xmath246 for @xmath253 , so @xmath251 , and thus @xmath252 .",
    "the dual statement can also easily be proved .",
    "the set of side effects caused by the evaluation of a formula does not change under rewritings of this kind . using normal forms",
    ", we can derive an interesting property of dla@xmath0 :    [ prop : noleftand ] let @xmath6 be a formula .",
    "the program @xmath254 can be rewritten to a form in which only primitive formulas or negations thereof occur in tests , such that its relational meaning is preserved .",
    "let @xmath255 be a normal form of @xmath6 and assume @xmath255 is not a primitive formula or the negation thereof .",
    "then , @xmath255 either is of the form @xmath256 or @xmath257 . for conjunctions ,",
    "it is easy to see that the program @xmath97 can be rewritten as meant in the proposition : @xmath258 we can assume by induction that @xmath259 and @xmath260 has been rewritten into a form in which only primitive formulas and negations occur , too .",
    "we now need to prove that these programs have the same relational meaning , that is given model @xmath87 and initial valuation @xmath38 @xmath261 if @xmath262 , then @xmath91 does not exist in both cases .",
    "if , for @xmath263 , @xmath264 , @xmath91 does not exist in both cases either .",
    "otherwise , on the left hand side , we get @xmath91 by applying dla11 : @xmath265 which by definition of the program extraction function , since @xmath266 , equals @xmath267 on the right hand side , we get @xmath91 by first applying qdl12 , then applying dla11 twice and finally applying qdl12 again : @xmath268 for disjunctions , the rewritten version is slightly more complex : @xmath269 we can prove that given model @xmath87 and initial valuation @xmath38 @xmath270 in a similar fashion as above . if @xmath266 , then in both cases @xmath91 is obtained by @xmath271 if @xmath262 , then if for @xmath272 , @xmath264 , in both cases @xmath91 does not exist .",
    "if @xmath273 , then on the left hand side @xmath91 is obtained via @xmath274 and on the right hand side , @xmath91 is obtained by @xmath275    on a side note , a similar result can be obtained for qdl . here the program @xmath276 can be rewritten to @xmath277 the differences between the dla@xmath0  version of the same rule are there because qdl uses full evaluation .",
    "therefore , @xmath260 has to be evaluated even when @xmath259 is true , although @xmath260 does not have to be true anymore .",
    "defining side effects for entire programs can be complicated .",
    "this is because two composition operators , namely union and repetition , can be non - deterministic .",
    "we are , however , not interested in ( the side effects of ) non - deterministic programs , even though they can be expressed in dla@xmath0 . , we can ask ourselves if it is reasonable to talk about side effects in non - deterministic programs .",
    "we have left this question for future work . ] to be exact , we are only interested in _ if @xmath17 then @xmath17 else _ constructions and _ while _ constructions , which in dla@xmath0  are expressed as follows : @xmath278 to formally specify this , we introduce _ deterministic programs _ , which cf .",
    "@xcite are defined as follows :    a * deterministic program * @xmath279 is a dla@xmath0-program in one of the following forms : @xmath280    there are two interesting properties of deterministic programs .",
    "the first is regarding programs of the form @xmath281 .",
    "in this case there will only ever be exactly one situation in which the program gets evaluated .",
    "after all , there is exactly one repetition loop for which the test @xmath97 succeeds , but will fail the next time it is evaluated .",
    "we can formalize this intuition in the following proposition :    [ prop : n ] let @xmath282 be a deterministic program .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be the valuation such that @xmath283 .",
    "there is a unique @xmath284 such that @xmath285 where @xmath286 and @xmath287 .",
    "we first prove that there is at least one @xmath284 for which the above equation holds .",
    "assume such an @xmath30 does not exist .",
    "this means that @xmath184 can never be evaluated , which is a contradiction with our requirement that there is a valuation @xmath91 such that @xmath283 .",
    "next , we have to prove that there is at most one such @xmath30",
    ". let @xmath288 be the valuation such that @xmath289 . by writing this out and then applying dla11 , we know that for @xmath290 , we have @xmath291 .",
    "therefore , for valuation @xmath288 with @xmath290 we can not evaluate @xmath184 and thus there is no @xmath290 for which the above equivalence holds .",
    "we know that for @xmath292 , we have @xmath293 .",
    "this automatically means that for @xmath294 , the above equivalence will not hold either , since we can not satisfy @xmath97 .",
    "thus , we have exactly one @xmath30 .",
    "the second interesting property of a deterministic program is the following :    a deterministic program @xmath279 is said to be in * canonical form * if only concatenations occur as composition operators .",
    "this property is going to be very useful , because we can prove that given an initial valuation @xmath38 , any program has a unique canonical form that has the same behavior :    [ prop : canonical ] let @xmath279 be a deterministic program .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be the valuation such that @xmath295 .",
    "there is a unique deterministic program @xmath296 in canonical form such that @xmath297 and @xmath296 executes the same basic instructions and the same number of basic instructions as @xmath279 .    if @xmath298 , then @xmath296 depends on the truth of @xmath6 : @xmath299 by induction we can assume that @xmath300 and @xmath301 are the canonical forms of @xmath302 and @xmath303 ( if these are not empty ) , respectively .",
    "the truth of @xmath304 follows directly from qdl13 in this case .",
    "if @xmath305 , we need to use @xmath30 as meant in proposition [ prop : n ] : @xmath306 once again we can assume by induction that @xmath300 is the canonical form of @xmath302 ( once again if @xmath307 is not empty ) .",
    "the truth of @xmath304 now follows directly from proposition [ prop : n ] .",
    "it is easy to see that in both these cases , @xmath296 executes the same basic instructions as @xmath279 .",
    "it is also easy to see that @xmath296 is unique : we can not add instructions using union or repetition because then @xmath296 will no longer be in canonical form and we can not add instructions using concatenation because those instructions will be executed , which violates the requirement that @xmath296 only executes the same basic instructions as @xmath279 .",
    "we can not alter or remove instructions in @xmath296 either because all instructions in @xmath296 get executed , so altering or removing one would also violate said requirement .",
    "now that we have dla@xmath0  defined and shown how it works , it is time to examine the logic of formulas a little closer .",
    "as we have mentioned before , we are making use of short - circuit versions of the @xmath15 and @xmath16 connectives , i.e. connectives that prescribe short - circuit evaluation . in @xcite , different flavours of short - circuit logics ( logics that can be defined by short - circuit evaluation ) are identified . in this chapter",
    "we will give a short overview of these and present the short - circuit logic that underlies the formulas in dla@xmath0 , which turns out to be repetition - proof short - circuit logic ( rpscl ) .",
    "short - circuit logic can be defined using _ proposition algebra _ , an algebra that has short - circuit evaluation as its natural semantics .",
    "proposition algebra is introduced by bergstra and ponse in @xcite and makes use of hoare s ternary connective @xmath308 , which is called the _ conditional _ @xcite .",
    "a more common expression for this conditional is _ if y then x else z _ , with @xmath309 and @xmath310 ranging of propositional statements ( including propositional variables ) . throughout this thesis",
    ", we will use _ atom _ as a shorthand for propositional variable .    using a signature which includes this conditional , @xmath311 , the following set  of axioms for proposition algebra",
    "can be defined : @xmath312 in the earlier mentioned paper @xcite , varieties of so - called _ valuation algebras _ are defined that serve the interpretation of a logic over @xmath313 by means of short - circuit evaluation .",
    "the evaluation of the conditional @xmath314 is then as follows : first @xmath315 gets evaluated . that yields either @xmath41 , in which case the final evaluation result is determined by the evaluation of @xmath316 , or @xmath42 , in which case the same goes for @xmath317 .",
    "all varieties mentioned in @xcite satisfy the above four axioms .",
    "the most distinguishing variety is called the variety of _ free reactive valuations _ and is axiomatized by exactly the four axioms above ( further referred to as _ conditional propositions _ ( cp ) ) and nothing more .",
    "the associated valuation congruence is called free valuation congruence and written as @xmath318 .",
    "thus , for each pair of closed terms @xmath319 over @xmath313 , we have @xmath320    using the conditional , we can define negation ( @xmath321 ) , left - sequential conjunction ( @xmath28 ) and left - sequential disjunction ( @xmath29 ) as follows : @xmath322 the above defined connectives are associative and each other s dual . in cp , it is not possible to express the conditional @xmath308 using any set of boolean connectives , such as @xmath28 and @xmath29 @xcite .    by adding axioms",
    "to cp , it can be strengthened .",
    "the signature and axioms of one such extension are called _ memorizing cp_. we write cp@xmath323 for this extension that is obtained by adding the axiom cpmem to cp .",
    "this axiom expresses that the first evaluation value of @xmath8 is memorized : @xmath324 with @xmath325 and by replacing @xmath8 by @xmath326 we get the contraction law : @xmath327 a consequence of contraction is the idempotence of @xmath28 .",
    "furthermore , cp@xmath323 is the least identifying extension of cp for which the conditional can be expressed using negation , conjunction and disjunction . to be exact",
    ", the following holds in cp@xmath323 : @xmath328 we write @xmath329 ( memorizing valuation congruence ) for the valuation congruence axiomatized by @xmath330 .",
    "another extension of cp , the most identifying one distinguised in @xcite , is defined by adding both the contraction law and the axiom below , which expresses how the order of @xmath331 and @xmath8 can be swapped , to cp : @xmath332 the signature and axioms of this extension , for which we write cp@xmath333 , are called _",
    "static cp_. we write @xmath334 ( _ static valuation congruence _ ) for the valuation congruence axiomatized by @xmath335 .",
    "a consequence in @xmath335 is @xmath336 , which can be used to derive the commutativity of @xmath28 : @xmath337 .",
    "cp@xmath333 is the most identifying extension of cp because it is ` equivalent with ' propositional logic , that is , all tautologies in propositional logic can be proved in cp@xmath333 using the above translations of its common connectives @xcite .      in this section",
    "we will present the definition of short - circuit logic and its most basic form , free short - circuit logic ( fscl ) .",
    "the definitions are given using _",
    "module algebra _ @xcite . in module algebra",
    ", @xmath338 is the operation that exports the signature @xmath24 from module @xmath339 while declaring other signature elements hidden . using this operation ,",
    "short - circuit logics are defined as follows :    a * short - circuit logic * is a logic that implies the consequences of the module expression @xmath340    thus , the conditional composition is declared to be an auxiliary operator . in scl , @xmath341 can be used as a shorthand for @xmath342 .",
    "after all , we have that @xmath343 with this definition , we can immediately define the most basic short - circuit logic we distinguish :    * @xmath344 ( free short - circuit logic ) * is the short - circuit logic that implies no other consequences than those of the module expression .    using these definitions",
    "we can provide equations that are derivable from .",
    "the question whether a finite axiomatization of fscl with only sequential conjunction , negation and @xmath345 exists , is open , but the following set  of equations for fscl is proposed in [ 5 ] : it is stated that the authors did not find any equations derivable from fscl but not from eqfscl . ]",
    "\\label{scl2}\\tag{scl2 } x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } y & = \\neg(\\neg x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\neg y)\\\\[0 mm ] \\label{scl3}\\tag{scl3 } \\neg\\neg x & = x\\\\[0 mm ] \\label{scl4}\\tag{scl4 } \\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x & = x\\\\[0 mm ] \\label{scl5}\\tag{scl5 } x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\top & = x\\\\[0 mm ] \\label{scl6}\\tag{scl6 } \\bot { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x & = \\bot\\\\[0 mm ] \\label{scl7}\\tag{scl7 } ( x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } y ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } z & = x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( y { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } z)\\\\[0 mm ] \\label{scl8}\\tag{scl8 } \\qquad(x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } y ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( z { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\bot ) & = ( \\neg x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } ( z { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\bot ) ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( y { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( z { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\bot))\\\\[0 mm ] \\label{scl9}\\tag{scl9 } ( x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } y ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( z { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } \\top)&=(x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( z { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } \\top ) ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } ( y { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( z { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } \\top))\\\\[0 mm ] \\label{scl10}\\tag{scl10 } ( ( x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\bot ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } y ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } z & = ( x { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\bot ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } ( y { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } z)\\end{aligned}\\ ] ] note that equations scl2 and scl3 imply a left - sequential version of de morgan s laws .",
    "an important equation that is absent is the following : @xmath347 this is what we would expect , since evaluation of @xmath348 ( with @xmath45 a closed term ) can generate a side effect that is absent in the evaluation of @xmath341 , although we know that evaluation of @xmath348 always yields @xmath42 .",
    "we now have the most basic short - circuit logic and some of its equations defined , but of course there also is a `` most liberal '' short - circuit logic below propositional logic .",
    "this logic is based on memorizing cp and satisfies idempotence of @xmath28 ( and @xmath29 ) , but not its commutativity .",
    "it is defined as follows :    * @xmath349 ( memorizing short - circuit logic ) * is the short - circuit logic that implies no other consequences than those of the module expression @xmath350    for the set of axioms eqmscl , intuitions and an example , and a completeness proof of mscl we refer the reader to @xcite . adding the axiom @xmath351 to mscl , or equivalently , the axiom @xmath352 to cp@xmath323 , yields so - called static short - circuit logic ( sscl ) , which is equivalent with propositional logic ( be it in sequential notation and defined by short - circuit evaluation ) .",
    "* @xmath353 ( static short - circuit logic ) * is the short - circuit logic that implies no other consequences than those of the module expression @xmath354      with both the most basic as well as the most liberal short - circuit logic we distinguish defined , we can present the variant of short - circuit logic that we are interested in because it underlies the logic of formulas in dla@xmath0 : _ repetition - proof short - circuit logic _ ( rpscl ) .",
    "this scl - variant stems from an axiomatization of proposition algebra called repetition - proof cp ( cp@xmath355 ) that is in between  and @xmath323 and involves explicit reference to a set @xmath22 of atoms ( propositional variables ) .",
    "the axiom system cp@xmath355 is defined as the extension of cp with the following two axiom schemes ( for @xmath356 ) , which imply that any subsequent evaluation result of an atom @xmath27 equals the current one : @xmath357 we write @xmath358 to denote the set of these axioms schemes in the format of module algebra . in cp@xmath355",
    "the conditional can not be expressed in terms of @xmath28 , @xmath359 and @xmath345 : in @xcite it is shown that the propositional statement @xmath360 ( for atoms @xmath361 ) can not be expressed modulo repetition - proof valuation congruence , that is , the valuation congruence axiomatized by cp@xmath355 .",
    "the definition of rpscl then becomes :    * @xmath362 ( repetition - proof short - circuit logic ) * is the short - circuit logic that implies no other consequences than those of the module expression @xmath363    the equations defined by  include those that are defined by  as well as for @xmath56 : @xmath364 it is an open question whether the equations scl1-scl10 and the equation schemes rp1-rp12 axiomatize rpscl , but it will be shown below that rpscl is the logic that models equivalence of formulas in dla@xmath0 , where @xmath365\\top \\}\\ ] ] for this reason , we add the conditional @xmath366 and the constant @xmath341 to dla@xmath0  ( thus making @xmath29 and @xmath359 definable ) . in order to decide whether different dla@xmath0  formulas are equivalent ,",
    "just translate these to cp@xmath355 and decide their equivalence ( either by axiomatic reasoning or by checking their repetition - proof valuation congruence ) .",
    "so , we extend the formulas in dla@xmath0  in order to characterize the logic that models their equivalence . in this extension of dla@xmath0 , which we baptize dlca@xmath0  ( for dynamic logic with the conditional and assignments as formulas ) , truth in @xmath87 relative",
    "an initial valuation @xmath38 for the conditional is defined as follows : @xmath367 this means that we need an extra equation for the program extraction function @xmath166 too which handles the conditional . for model @xmath87 , initial valuation @xmath38 and @xmath368 @xmath369 in the remainder of this section we consider formulas over this signature , thus formulas over @xmath22 composed with @xmath370 .",
    "below we will prove for all mentioned axioms that they are valid in dlca@xmath0 .",
    "let @xmath87 be a model for dlca@xmath0 .",
    "the axiom cp1 , that is @xmath371 is valid in @xmath87 .",
    "let @xmath372 be arbitrary formulas and let @xmath38 be an initial valuation .",
    "regardless of @xmath38 , we have @xmath373 ( by qdl3 ) , so by dlca , we get @xmath374 iff for @xmath375 , @xmath376 . since @xmath103 , we indeed have that @xmath374 iff @xmath377 .",
    "let @xmath87 be a model for dlca@xmath0 .",
    "the axiom cp2 , that is @xmath378 is valid in @xmath87 .",
    "let @xmath372 be arbitrary formulas and let @xmath38 be an initial valuation .",
    "@xmath341 is a shorthand for @xmath379 , so we first need qdl6 , which states that @xmath380 iff not @xmath373 , which is never the case .",
    "so for any initial valuation @xmath38 , @xmath381 is false .",
    "thus by dlca , we get @xmath382 iff for @xmath375 , @xmath376 . since @xmath103",
    ", we indeed have that @xmath382 iff @xmath383 .",
    "let @xmath87 be a model for dlca@xmath0 .",
    "the axiom cp3 , that is @xmath384 is valid in @xmath87 .",
    "let @xmath45 be an arbitrary formula and let @xmath38 be an initial valuation .",
    "if @xmath385 then by dlca we get for @xmath386 , @xmath387 , which also is true .",
    "if @xmath388 then by dlca we obtain @xmath389 ( note that also in this case , @xmath91 is defined ) , which also is false .",
    "thus @xmath385 iff @xmath390 and hence the axiom cp3 is valid .",
    "let @xmath87 be a model for dlca@xmath0 .",
    "the axiom cp4 , that is @xmath391 is valid in @xmath87 .",
    "let @xmath392 be arbitrary formulas and let @xmath38 be an initial valuation .",
    "we are going to have to show that @xmath393 we have to apply dlca multiple times here . by applying it to the left hand side we get for @xmath394 @xmath395 by applying dlca again to @xmath396 we get for @xmath397 @xmath398 so if @xmath399 and @xmath400 , we get @xmath401 . if on the other hand @xmath402 but @xmath403 , we also get @xmath401 . in all other situations",
    "we get @xmath404 .",
    "let us now consider the right hand side of the equation .",
    "here we get for @xmath405 : @xmath406 let us first turn our attention to the situation where @xmath399 . we need to apply dlca again and get for @xmath407 @xmath408 in the situation where @xmath402",
    ", we get for @xmath409 @xmath410 so on the right hand side , if @xmath399 and @xmath411 , we get @xmath376 . if @xmath402 but @xmath412 , we also get @xmath413 . in the other situations we get either @xmath414 or @xmath415 .    to prove that is the same result as on the left - hand side , we need to prove that @xmath416 , @xmath417 if @xmath402 , and @xmath418 if @xmath399 . the last two statements seem contradictory , but as we will see @xmath73 can actually take two different valuations depending on the truth of @xmath317 . the mentioned variations are all determined using the program extraction function .",
    "to recap , we have the following : @xmath419 we can immediately see that @xmath416 . using the updated definition for the program extraction function we get that @xmath420 using the new rule for the conditional , we get that : @xmath421 to determine if @xmath417 , we need to have @xmath399 and we need to evaluate : @xmath422 by qdl12 , we know that is equivalent to @xmath423 so indeed we have that if @xmath399 , then @xmath417 . using the same argument , we get that if @xmath402 , then @xmath424 therefore , if @xmath402 then @xmath418 .    with those four axioms proven , we already know for a fact that the logic of formulas in dla@xmath0  indeed is a short - circuit logic . to prove that it is a repetition - free short - circuit logic , we need to prove the axiom schemes cprp1 and cprp2 , too .",
    "those axiom schemes make use of atoms @xmath56 .",
    "let @xmath87 be a model for dlca@xmath0 .",
    "the axiom cprp1 , that is @xmath425 is valid in @xmath87 .",
    "let @xmath426 be arbitrary formulas and @xmath38 an initial valuation .",
    "@xmath427 can either be true or false .",
    "if it is false , both the left hand side and the right hand side , by dlca , are determined for @xmath428 by @xmath429 . if it is true , the question if @xmath430 is asked .",
    "we have to prove that for every atom @xmath56 , the reply to this will be the same as the reply to @xmath427 ( namely , true ) , that is : @xmath431 recall that @xmath27 can be of the forms @xmath432\\top\\}$ ] .",
    "for the first two atoms we can immediately see our claim is true , since @xmath433 and therefore @xmath101 . for @xmath434\\top$ ]",
    "the claim immediately follows from dla9 : it is , regardless of the valuation , always true .",
    "let @xmath87 be a model for dlca@xmath0 .",
    "the axiom cprp2 , that is @xmath435 is valid in @xmath87 .",
    "this is the symmetric variant of cprp1 and proven similarly .",
    "by proving the validity of these axiom schemes in dlca@xmath0  we have proven that the equations scl1-scl10 together with rp1-rp12 are axioms for formulas in dlca@xmath0 .",
    "cp@xmath355 indeed is the most identifying extension of cp which is valid for formulas .",
    "after all , the first more identifying extension we distinguish is cp@xmath436 ( _ contractive cp _ ) @xcite , from which amongst others the following weak contraction rule can be derived : for @xmath56 @xmath437 clearly this is not valid for dla@xmath0-formulas such as @xmath438\\top$ ] .",
    "now that we have defined a system to model program instructions and program states , we can return to our original problem : that of formally defining side effects .",
    "like i said in section [ sec : introsideeffects ] , the basic idea is that a side effect has occurred in the execution of a program if there is a difference between the actual evaluation and the expected evaluation of a program given an initial valuation .",
    "we can immediately see however , that we can not build a definition of side effects based on the actual and expected evaluation of an entire program .",
    "such a definition will get into trouble when there are multiple side effects , especially if those cancel each other out or reinforce each other .",
    "consider for example the following program : @xmath439\\top);{\\text { ? } } ( [ x:=x+1]\\top)\\ ] ] if we are only going to look at the entire program , we will detect one side effect here , that has incremented the value of @xmath10 by two .",
    "however , it appears to be more acceptable to say that _ two _ side effects have occurred , that happen to affect the same value .",
    "it gets even more interesting if there is a formula in between the two clauses above and the clauses themself cancel each other out : @xmath440\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } \\phi { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }           \\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top)\\end{aligned}\\ ] ] if we again only look at the entire program , we will detect no side effects ( unless side effects occur in @xmath6 ) .",
    "however , because @xmath6 might use or modify @xmath10 as well , it seems we will have to pay attention to the side effect of the first clause , even though it will be cancelled out on by the last clause .",
    "so instead of building a definition of side effects by looking only at the actual and expected evaluation of an entire program , we are going to build it up starting at the instruction level .",
    "as said , we are going to use a bottom - up approach to define side effects , so we will first define side effects for single instructions , then move up to basic instructions and end with a full definition of side effects for programs .",
    "the idea is that the side effect of a single instruction is the difference between the actual and expected evaluation of a single instruction .",
    "this difference is essentially the difference between the resulting valuations after , respectively , the actual and expected evaluation of the single instruction .",
    "the difference between two valuations is defined as follows :    given a model @xmath87 , the * difference * between valuations @xmath38 and @xmath91 is defined as those variables that have a different assignment in @xmath38 and @xmath91 : @xmath441    this notion of difference is not symmetric .",
    "we already know what the actual evaluation of a single instruction is : for this we can use dla@xmath0 .",
    "this leaves us to define the expected evaluation . for this",
    "we need to know for each single instruction how we expect it to evaluate , that is , what changes we expect it to make to the initial valuation .",
    "we have the following expectations of each single instruction :    * * assignments * change the initial valuation by updating the variable assignment of the variable under consideration to the ( interpretation of the ) new variable assignment . * * tests * do not change the initial valuation : they only yield @xmath41 or @xmath42 and steer the rest of the program accordingly .",
    "we need the following equations for determining the expected evaluation @xmath442 of a single instruction : @xmath443 \\top & \\text { always}\\end{aligned}\\ ] ] @xmath444\\\\ \\label{ev6}\\tag{ev6}_{g}\\llbracket { \\text{?}}\\varphi \\rrbracket_{h}^{m,\\mathcal{e } } \\text { iff } & g = h \\text { and } m \\models_{g}^{\\mathcal{e } } \\varphi\\end{aligned}\\ ] ]    now that we have the actual and the expected evaluation of a single instruction , we can define its side effects .",
    "as said , this is going to be the difference between the two resulting valuations .",
    "let @xmath233 be a single instruction .",
    "let model @xmath87 be given and let @xmath38 be an initial valuation .",
    "furthermore , let @xmath91 be a valuation such that @xmath445 and let @xmath199 be a valuation such that @xmath446 .",
    "the set of side effects of single instruction @xmath233 given model @xmath87 and initial valuation @xmath38 is defined as @xmath447    it is important to note that the valuations @xmath91 and @xmath199 as meant in the above definition may not exist .",
    "we are not interested in those situations , however .",
    "if @xmath91 and @xmath199 do exist , they are unique . also note that @xmath448 returns the variable assignment of valuation @xmath91 if there is a difference with the variable assignment of valuation @xmath199 .",
    "thus , the set of side effects is defined as a set containing those variables that have a different assignment after the actual and expected valuation , with as assignments the ones the variables actually get ( that is , the assignments they will have after evaluating the single instruction with the actual evaluation )",
    ".    we will illustrate this with two examples .",
    "first , consider the single instruction @xmath449 , evaluated under model @xmath87 in initial valuation @xmath38 with @xmath450 . we want to know if this causes a side effect ,",
    "so we need to know the actual evaluation and the expected evaluation . to calculate the actual evaluation",
    ", we need to know if @xmath451 and if yes , for which valuation @xmath91 .",
    "the equations for dla@xmath0  immediately give us the answer , in this case via qdl10 : @xmath452 $ ] .",
    "so we get @xmath453 .    getting the expected",
    "evaluation works in a similar fashion , but instead of dla@xmath0  we now use the equations above to evaluate @xmath233 .",
    "since the equation for evaluating an assignment ( ev5 ) is the same as qdl10 , we now get the exact same expected evaluation as the actual evaluation .",
    "thus we get @xmath454 $ ] and therefore @xmath455 .",
    "we can immediately see that this results in the set of side effects being empty : @xmath456 this is of course what we would expect : an assignment should not have a side effect if it does not occur in a steering fragment .",
    "let us now consider an example where we do expect a side effect : namely if an assignment does occur in a steering fragment : @xmath457\\top)$ ] .",
    "we use the same initial valuation @xmath38 .",
    "first we try to find the actual evaluation again , which we do by evaluating @xmath458\\top)\\rrbracket_{h}^{m}$ ] .",
    "we now need dla11 , which tells us that ( in this case ) @xmath458\\top)\\rrbracket_{h}^{m}$ ] iff @xmath459\\top)$ ] and @xmath460\\top)\\rrbracket_{h}^{m } = \\ _ { g}\\llbracket x:=1 \\rrbracket_{h}^{m}$ ] . both evaluate to true , the latter with @xmath461 $ ] .",
    "the expected update once again takes us to the equations above ; we need to determine @xmath199 such that @xmath462\\top)\\rrbracket_{h'}^{m,\\mathcal{e}}$ ] . for tests ,",
    "the demands are fairly simple : @xmath463 and @xmath464\\top$ ] ( see ev6 ) .",
    "the latter is by ev4 defined to be always true . as a result",
    ", we get @xmath465 .",
    "thus we get the following set of side effects : @xmath466\\top ) & = \\delta^{m}(h',h)\\\\ & = \\{x \\mapsto 1\\}\\end{aligned}\\ ] ] again , this is exactly what we want : since we expect formulas to only yield true or false , the change this formula makes to the program state upon evaluation is a side effect .      with side effects for single instructions defined",
    ", we can move up a step to side effects in basic instructions .",
    "the difference between single and basic instructions is that in basic instructions , complex steering fragments are allowed .",
    "this means that we are going to have to define how side effects are handled in tests that contain a disjunction ( @xmath29 ) , conjunction ( @xmath28 ) or negation ( @xmath321 ) .",
    "the idea is that the set of side effects of the whole formula is the union of the sets of side effects of its primitive parts .",
    "however , we also have to pay attention to the short - circuit character of @xmath29 .",
    "only the primitive formulas that get evaluated can contribute to the set of side effects .    with this in mind",
    ", we can give the definition for side effects in ( possibly ) complex steering fragments .",
    "like before , we are only interested in the side effects if the test actually succeeds .",
    "we need to define this for disjunctions , conjuctions and negations :    let @xmath467 be a disjunction .",
    "let model @xmath87 and initial valuation @xmath38 be given , with @xmath468 and where @xmath6 is in its normal form . furthermore , let @xmath73 be the valuation after evaluation of formula @xmath126 , that is , @xmath469 .",
    "the set of side effects @xmath470 is defined as : @xmath471    the case distinction is in place because of the short - circuit character of @xmath29 . for the definition of its dual @xmath28",
    "we do not need this case distinction , because since we are again only interested in the side effects if the ( entire ) formula succeeds , all the formulas in the conjunction have to yield true .",
    "therefore , the definition for conjunction is a bit easier :    let @xmath472 be a conjunction .",
    "let model @xmath87 and initial valuation @xmath38 be given , with @xmath468 and where @xmath6 is in its normal form .",
    "furthermore , let @xmath73 be the valuation after evaluation of primitive formula @xmath126 , that is , @xmath473 .",
    "the set of side effects @xmath470 is defined as : @xmath474    the recursive definitions for disjunction and conjunction work because eventually , a primitive formula will be encountered , for which the side effects are already defined .",
    "unfortunately , we can not use a similar construction for negation .",
    "this is because the side effects in a primitive formula are only defined if that formula yields true upon evaluation , so we can not simply treat negation as a transparent operator ( that is , it is typically not true that @xmath475 ) .",
    "so we will have to define negation the hard way instead . because we are using formulas in normal form in the other definitions",
    ", we only have to define negation for primitive formulas :    let @xmath476 be a negation .",
    "let model @xmath87 be given and let @xmath38 be an initial valuation .",
    "furthermore , let @xmath91 be a valuation such that @xmath477 and let @xmath199 be a valuation such that @xmath478 .",
    "the set of side effects of basic instruction @xmath479 given model @xmath87 and initial valuation @xmath38 is defined as @xmath480    now that we have a definition for side effects in ( complex ) steering fragments , the extension of our definition of side effects in single instructions to side effects in basic instructions is trivial :    let @xmath235 be a basic instruction .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be a valuation such that @xmath481 .",
    "the set of side effects @xmath482 is defined as : @xmath483    we can illustrate this with a simple , yet interesting example . consider the following basic instruction : @xmath484\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }           \\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top)$ ] with initial valuation @xmath38 such that @xmath485 .",
    "in this situation we have two side effects that happen to cancel each other out .",
    "the resulting valuation after the actual evaluation of this basic instruction will be the same as the initial valuation @xmath38 .",
    "first we observe that the formula in this basic instruction is in its normal form , a trivial observation since no negations occur in it .",
    "there are two primitive formulas in this conjunction , so the set of side effects is : @xmath486\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }           \\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top ) ) = \\ & \\mathcal{s}_{g}^{m } ( ?",
    "( [ x:=x+1]\\top))\\ \\cup\\\\ & \\mathcal{s}_{g_{1}}^{m } ( ? ( [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }           \\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top))\\end{aligned}\\ ] ] here",
    "@xmath487 is determined by @xmath488\\top)\\rrbracket_{g_{1}}^{m}$ ] , so we get @xmath489 .",
    "we have already seen in the previous section how the parts of the union above evaluate , so we get : @xmath486\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }           \\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top ) ) & = \\{x \\mapsto 2\\ } \\cup \\{x \\mapsto 1\\}\\\\ & = \\{x \\mapsto",
    "2 , x \\mapsto 1\\}\\end{aligned}\\ ] ] so with this definition we have avoided the trap of not detecting any side effects when there are two side effects that cancel each other out .",
    "instead we have two side effects here , the last of which happens to restore the valuation of @xmath10 to its original one .",
    "if we are going to extend our definition to that of side effects in programs , we are going to have to define how concatenation , union and repetition are handled .",
    "defining side effects for entire programs is more complicated than defining side effects for single and basic instructions .",
    "this is because two composition operators , namely union and repetition , can be non - deterministic . as we have mentioned before , however , we are only interested in ( the side effects of ) deterministic programs .",
    "this leaves us to define how side effects are calculated for the composition operators of deterministic programs . for concatenation",
    ", this is trivial .",
    "we once again require that the entire program can be evaluated with the given initial valuation .",
    "the set of side effects of a program then is the union of the side effects in its basic instructions that are executed given some initial valuation :    let @xmath490 be a deterministic program .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be the valuation such that @xmath283 .",
    "furthermore , let @xmath73 be the valuation such that @xmath491 .",
    "the set of side effects @xmath492 is defined by : @xmath493    this works in a similar fashion as the definition of side effects in complex steering fragments .",
    "we can return now to our example given in the introduction of this chapter : @xmath494\\top);{\\text { ? } } ( [ x:=x+1]\\top)$ ] .",
    "the above definition indeed avoids the trap presented there , namely that this program only yields a single side effect . to see this ,",
    "consider initial valuation @xmath38 such that @xmath450 .",
    "we will then get @xmath495\\top)\\rrbracket_{f}^{m}$ ] and therefore @xmath496 , so the set of side effects becomes : @xmath497\\top ) ) \\cup \\mathcal{s}_{f}^{m}({\\text { ? } } ( [ x:=x+1]\\top))\\\\ & = \\{x \\mapsto 1\\ } \\cup \\{x \\mapsto 2\\}\\\\ & = \\{x \\mapsto 1 , x \\mapsto 2\\}\\end{aligned}\\ ] ] similarly , side effects that cancel each other out , such as in @xmath494\\top);{\\text { ? } } ( [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }           \\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top)$ ] will now perfectly be detected , resulting for the same initial valuation @xmath38 in a set of side effects @xmath498 .",
    "another interesting observation is that the transformation as defined in proposition [ prop : noleftand ] , which eliminates occurences of @xmath28 and @xmath29 in steering fragments , not only preserves the relational meaning , but also the side effects of such a steering fragment .",
    "the programs @xmath499\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }           \\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top)$ ] and its transformed version @xmath499\\top ) ; ? ( [ x:=x{~           \\mathbin{\\setlength{\\unitlength}{1ex }",
    "\\begin{picture}(1.4,1.8)(0,0 )           \\put(-.6,0){$-$ }           \\put(0,0.5){$\\cdot$ }           \\end{picture }           } } 1]\\top)$ ] are an illustration of this : we can easily see that both have the same set of side effects .",
    "with concatenation defined , we can move on to the next composition operators : union and repetition . for this",
    "we can use the property that given an initial valuation , every ( terminating ) deterministic program has a unique canonical form that executes the same basic instructions ( see proposition [ prop : canonical ] in chapter [ ch : terminology ] ) .",
    "this makes the definition of side effects for programs containing a union or repetition straight - forward :    let @xmath279 be a deterministic program .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be the valuation such that @xmath283 .",
    "furthermore , let @xmath296 be the deterministic program in canonical form as meant in proposition [ prop : canonical ] .",
    "the set of side effects @xmath492 is defined by : @xmath500    we can illustrate how this works by returning to our running example , discussed in detail in section [ sec : example ] :    & x : = 1 ; & + & ( x:=x+1   x = 2 ) & + & y:=1 & + & y:=2 &    in dla@xmath0 , this translates to the following deterministic program @xmath279 :    & x:=1 ; & + & ( ( [ x:=x+1 ]   x=2);y:=1 ) & + & & + & ( ( [ x:=x+1 ]   x=2);y:=2 ) &    we have already seen that for @xmath194 , there is a valuation @xmath91 such that @xmath283 ( namely @xmath501 $ ] ) .",
    "we can break this program down as follows : @xmath502\\top\\\\ \\varphi_{2 } & : : = ( x=2)\\end{aligned}\\ ] ] we want to know the set of side effects in this program .",
    "this is determined as follows : @xmath503 where we get @xmath73 by evaluating @xmath158 .",
    "thus , @xmath504 $ ] .",
    "we can easily see that the first set of side effects @xmath505 .",
    "the interesting part is the second set of side effects , since we now have a deterministic program of the form @xmath506 . here",
    "@xmath507 and @xmath508 .",
    "we now have to ask ourselves what the canonical form of @xmath307 given valuation @xmath73 is .",
    "this is determined by the outcome of the test @xmath509\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x=2)\\ ] ] it is easy to see that this yields true .",
    "thus , the canonical form @xmath296 of @xmath307 is @xmath510 therefore according to our definition , for @xmath511 : @xmath512 we can once again immediately see that the second set of side effects @xmath513 .",
    "the first set of side effects is determined in a similar fashion as in the example in the previous section . in the end",
    ", it gives us : @xmath514\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2)))\\\\ & = \\mathcal{s}_{f}^{m}({\\text { ? } } ( [ x:=x+1]\\top ) \\cup \\mathcal{s}_{f'}^{m}({\\text{?}}(x=2)))\\end{aligned}\\ ] ] so we again get a union of two sets of side effects , where we get @xmath208 by evaluating @xmath515\\top\\rrbracket_{f'}^{m}$ ] .",
    "thus , @xmath516 $ ] .",
    "it should be clear by now that the first set of side effects contains one side effect , namely @xmath517 , whereas the latter does not contain any side effects .",
    "this gives us as final set of side effects : @xmath518\\top ) \\cup \\mathcal{s}_{f'}^{m}({\\text{?}}(x=2 ) ) )    ) \\cup \\mathcal{s}_{h}^{m}(\\rho_{2 } )    ) \\\\ & = \\emptyset \\cup ( ( \\{x \\mapsto 2\\ }   \\cup \\emptyset   ) \\cup \\emptyset)\\\\ & = \\{x \\mapsto 2\\}\\end{aligned}\\ ] ] this is exactly the side effect we have come to expect from our running example .",
    "we can now move on to an example of side effects in programs containing a repetition .",
    "recall that repetition is defined as follows : @xmath519 so , @xmath72 either gets executed not at all or at least once .",
    "the form of programs we are interested in is @xmath520 in this case there will only ever be exactly one situation in which the program gets evaluated ( see proposition [ prop : n ] in chapter [ ch : terminology ] ) .",
    "our definition of canonical forms tells us that given an initial valuation @xmath38 and @xmath30 as meant in proposition [ prop : n ] , the canonical form @xmath296 of @xmath279 is @xmath521 using this we get the following set of side effects of a deterministic program of the above form : @xmath522 as an example of this , we can return to a slightly modified version of the example we gave in section [ sec : whileinqdla ] .    &",
    "x : = 0 ; & + & y : = 0 ; & + & ( x:=x+1   x 3 ) & + & y:= y+ 1 &    in dla@xmath0 , this translates to the following deterministic program @xmath279 given model @xmath87 and initial valuation @xmath38 such that @xmath523 : @xmath524\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x\\leq 3));y:=y+1)^ { * } ; { \\text{?}}\\lnot ( [ x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x\\leq 3))\\ ] ] clearly this is a deterministic program in the form we are interested in and there is a valuation @xmath91 such that @xmath295 . in this case",
    "we have @xmath525 with @xmath526\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x\\leq 3)$ ] . to get the canonical form @xmath296 of @xmath279",
    ", we need to find the iteration @xmath30 for which @xmath97 will succeed , but for which the test will not succeed another time",
    ". this will be for @xmath527 .",
    "after all , after three iterations we will have valuation @xmath528 $ ] . with this valuation , the test @xmath529\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x\\leq 3))$ ]",
    "will fail , or to put it formally : @xmath530\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x\\leq 3)$ ] .",
    "this means that we will get the following set of side effects : @xmath531 is this the result we would expect ?",
    "the answer is yes . it is clear that for each time the test is evaluated , a side effect occurs . the test is performed four times : three times it succeeds (",
    "after which the program executes the body of its loop ) and the fourth time it fails , but not after updating the valuation of @xmath10 .",
    "the program evaluates with as final valuation @xmath532 $ ] .",
    "the keen observer will have noticed by now that under our current definition , side effects can only occur in steering fragments .",
    "i have been going through quite some trouble , however , to make my definitions of side effects as general as possible",
    ". even though in this thesis i am only interested in side effects in steering fragments , i am fully aware that views can differ on what the main effect and what the side effect of an instruction is . that may either be a matter of opinion or a matter of necessity , as in different systems , the same instruction may have a side effect in one system and not in the other .    the way my definitions of side effects . ]",
    "are built up , one need only change the _ expected evaluation _ of an instruction in order to change if it is viewed as a side effect in a certain context .",
    "consider , for example , the sometimes accepted view that an assignment causes a side effect , no matter where it occurs in a program .",
    "this view is for example expressed by norrish in @xcite .",
    "the only change we would need to make to our system to incorporate that view is a change to the expected evaluation of the assignment , which would then become : @xmath533 the consequence of this in our current setting would be that the expected evaluation of every program always has a resulting valuation @xmath91 that is equal to the initial valuation @xmath38 , since only assignments can make changes to a valuation currently and by the above definition we do not expect any assignment to do so , wherever it occurs in the program . as a consequence ,",
    "any change to the valuation ( caused by the actual evaluation ) will automatically be a side effect .",
    "it is almost as simple to add new instructions to our setting .",
    "i definitely do not want to claim that the instructions i have defined in dla@xmath0  are exhaustive , so this need may arise .",
    "if we were , for instance , to re - introduce the random assignment @xmath80 , all we would have to do was to define the actual and expected evaluation of this .",
    "the actual evaluation is already given by harel in @xcite and van eijck in @xcite : @xmath534 if we also would want to allow random assignments in tests , we would have to add a rule for that as well , similar to the one already in place for normal assignments : @xmath535\\top \\text { iff } _ { g}\\llbracket v:={\\text{?}}\\rrbracket_{h}^{m}\\ ] ] the definition of the expected evaluation is dictated by what we really expect the random assignment to do .",
    "this can be the same as what it actually does , in which case we have to define the expected evaluation to be the same as the actual evaluation above : @xmath536\\top & \\text { iff } m \\models_{g } [ v:={\\text{?}}]\\top\\end{aligned}\\ ] ] if we expect random assignments to do something different , all we have to do is define the expected evaluation accordingly .",
    "this expected evaluation can literally be anything : from simply not updating the valuation at all to always setting a completely unrelated variable to 42 : @xmath537\\ ] ] on a side note , this example poses some interesting questions about ` negative ' side effects . under our current definition , setting the above mentioned variable to 42 registers as a side effect , but in a somewhat strange fashion . after all @xmath80 is a single instruction and for @xmath538 and @xmath539 , @xmath540 .",
    "there will actually be two differences between valuations @xmath199 and @xmath91 here : the actual evaluation updates variable @xmath31 , whereas the expected evaluation leaves @xmath31 alone but does update the variable _ the answer to life , the universe and everything_. both variables will show up in the set of side effects , both with the assignment the actual evaluation has assigned to them .",
    "this fails to capture what has actually happened here : after all , not only did an unexpected change to the initial valuation happen ( a ` regular ' side effect ) , but an expected change also did _ not _ happen ( a ` negative ' side effect ) .",
    "at least part of the information what should have happened is lost , namely the value the variable _ the answer to life , the universe and everything _ was supposed to get .",
    "it is an open question if we should even allow these somewhat odd situations where the actual evaluation does something completely different than we expect , thereby generating a negative side effect .",
    "we leave this question , as well as the question how we should handle these situations if we do choose to allow them , for future work .",
    "in this chapter we will take a closer look at side effects in steering fragments .",
    "in particular , we will give a classification of side effects .",
    "this classification gives us a measure of the impact of a side effect .",
    "as we have already mentioned in our introduction in chapter [ ch : introduction ] , bergstra has given an informal classification of side effects in @xcite .",
    "bergstra makes a distinction between steering instructions and working instructions .",
    "this distinction is based on a setting called program algebra ( pga ) . in pga , there is no distinction between formulas and single instructions other than formulas , which is why the proposed distinction by bergstra is meaningful in that setting .",
    "every basic instruction @xmath27 in pga yields a boolean reply upon execution and can therefore be made into a positive or negative test instruction @xmath541 or @xmath542 .",
    "naturally , this can not be done in our setting of dla@xmath0 , so instead of giving an overview of bergstra s paper , i will just present the major classes of side effects bergstra distinguishes and what they come down to in our setting .",
    "bergstra s first class of side effects is what he calls ` trivial side effects ' . by this",
    "he means side effects that can only be found in e.g. consequences for the length of the program or its running time .",
    "we are usually not interested in those kinds of side effects , which is exactly why bergstra calls them trivial and why we would say that no side effects occur at all .",
    "an instruction that only returns a meaningful boolean reply ( that is , a boolean reply that may differ depending on the valuation the instruction is evaluated in ) is an instruction that only has trivial side effects .",
    "examples of such instructions are the comparision instructions such as ( @xmath19 ) or ( @xmath543 ) .",
    "these instructions can be turned into meaningful test instructions by prefixing them with a @xmath544 or @xmath545 symbol .",
    "we will return to this in our explanation of pga in chapter [ ch : pga ] . in our terms , these kinds of instructions can only be formulas , occuring in steering fragments such as @xmath546 or @xmath547 . to be precise , they can only be formulas that have the same actual and expected evaluation , and thus no side effects .",
    "the above described situation , where only trivial side effects occur , is one extreme .",
    "the other extreme is when an instruction always yields the same boolean reply , regardless of when it is executed .",
    "bergstra says that in that case , only ` trivial boolean results ' occur and that the instruction should be classified as a working instruction ( that is , a single instruction not being a formula ) . in our",
    "setting this is also true with one notable exception : that of assignments",
    ". as we know , assignments always return true , so their boolean result is trivial .",
    "still , we allow them in formulas , too .",
    "if an instruction with trivial boolean results occurs outside a formula , its only relevance would be its effect other than the boolean reply , in which case you can hardly call that effect a side effect . if it occurs in a formula , however , the boolean result  albeit trivial  does have relevance , so the effect other than the boolean reply can indeed be called a side effect .",
    "this is exactly what happens in our setting .",
    "what the classification between steering instructions and working instructions gives us in the end , is a recommendation on how to use a particular kind of instruction .",
    "instructions such as comparision ( @xmath543 ) , that only give a boolean reply , have no meaning as a working instruction and therefore ideally should only occur in steering fragments .",
    "other instructions such as assignment ( @xmath548 ) can be both steering instructions as well as working instructions and can thus occur both inside as well as outside steering fragments .",
    "finally , instructions such as writing to the screen ( ` write x ` ) do not return a meaningful boolean reply and should therefore ideally not occur in steering fragments .",
    "having seen the base class of side effects , we can move on to the next level , that of _ marginal side effects_. the intuition behind a marginal side effect is fairly simple : the side effect of a single instruction is marginal if the remainder of the execution of the program is unaffected by the occurrence of the side effect .",
    "the following program is a typical example of one where a marginal side effect occurs : @xmath549\\top);y:=1\\ ] ] here @xmath302 can be any ( deterministic ) program .",
    "the side effect occurs in the test .",
    "however , since the variable @xmath10 is no longer used in the remainder of the program ( which only consists of the single instruction @xmath550 ) , the remainder of the program is unaffected by the occurrence of the side effect .",
    "therefore , this side effect is marginal .",
    "so what if @xmath10 does occur in the remainder of the program , for example in this program : @xmath549\\top);x:=x+1\\ ] ] this is a typical example of a program in which the occuring side effect is not marginal .",
    "the reason is that the assignment in the remainder of the program ( @xmath18 ) has a different effect on the variable @xmath10 than when it would have had if the side effect had not occurred .",
    "for instance , for initial valuation @xmath38 such that @xmath551 ( and assuming @xmath10 does not occur in @xmath552 ) , the assignment maps @xmath10 to @xmath553 .",
    "if the side effect had not occurred , it would have had a different effect on @xmath10 ( namely , it would have mapped it to @xmath12 ) .",
    "another typical example of a program in which an occuring side effect is not marginal is our running example : @xmath549\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2));y:=1\\ ] ] here @xmath302 can again be any deterministic program and the side effect occurs in the same place as in our first example .",
    "however , the test is now a complex test and in the second part of the test , @xmath10 is used .",
    "suppose the valuation after evaluation of @xmath302 is @xmath73 such that @xmath554 .",
    "the second part of the test ( @xmath19 ) will now give a different reply if a side effect does not occur in the first part ( or if that side effect would have affected a different variable ) .",
    "as a result , the remainder of the program is affected by the side effect : it will be executed differently if a side effect occurs .",
    "perhaps the answer to the question if the side effect is marginal is less clear when the initial valuation in the previous example would not have been @xmath38 with @xmath555 , but for example with @xmath556 .",
    "it is still the case that the variable @xmath10 , that is affected by a side effect , is used again in the remainder of the program , but now it does not change the outcome of the ( complex ) test .",
    "is that side effect still not marginal then ?",
    "the same question can be posed about the following example : @xmath549\\top);x:=42\\ ] ] regardless of initial valuation @xmath38 , at the end of this program ( assuming @xmath302 terminates ) , @xmath10 will always be mapped to 42 .",
    "so is the side effect in the test marginal or not ?",
    "the answer can be found by checking if the remainder of the program is executed in the same way , or more formally : if the actual update of the remainder of the program is the same regardless of whether a side effect has occurred . in both our last examples ,",
    "the answer to that last question is yes . after all , in the first example the test @xmath19 will fail whether @xmath10 has been incremented first or not , and in the second example @xmath10 will always be mapped to @xmath557 , again regardless of the side effect that incremented @xmath10 earlier .",
    "therefore , the side effects in the discussed instructions are marginal .",
    "although the intuition of marginal side effects should be clear enough by now , formally defining it is tricky because we have to define precisely what the remainder of a ( deterministic ) program @xmath279 given a single instruction @xmath233 and an initial valuation @xmath38 is . before we can define that , we also need to know the _ history _ of that same program given single instruction @xmath233 , which is loosely described as those ( single or basic ) instructions that have already been evaluated when @xmath233 is about to get evaluated .",
    "in what follows we are going to assume that in a certain deterministic program @xmath279 a single instruction @xmath233 occurs that is causing a side effect .",
    "furthermore , we are going to use that given initial valuation @xmath38 , any deterministic program has a unique canonical form that has the same behavior ( see proposition [ prop : canonical ] in chapter [ ch : terminology ] ) .",
    "defining the history and remainder of a deterministic program is straight - forward if that program is in canonical form .",
    "also , we can actually immediately give a more general definition than what we need here , namely the history and remainder of a deterministic program given a basic instruction .",
    "this extra generality will come in handy later on .",
    "let @xmath279 be a deterministic program in canonical form .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be the valuation such that @xmath295 .",
    "let @xmath235 be a basic instruction occuring in @xmath279 , that is , @xmath279 is of the form @xmath558 , with @xmath302 and @xmath303 being possibly empty deterministic programs in canonical form .",
    "the * history * of program @xmath279 given basic instruction @xmath235 is defined as : @xmath559 the * remainder * of program @xmath279 given basic instruction @xmath235 is defined as : @xmath560    using proposition [ prop : canonical ] the extension of the definitions of history and remainder of a program to all deterministic programs ( not just the ones in canonical form ) is trivial :    [ def : historybasic ] let @xmath279 be a deterministic program .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be the valuation such that @xmath295 .",
    "furthermore , let @xmath296 be the deterministic program in canonical form as meant in proposition [ prop : canonical ] .",
    "the * history * of program @xmath279 given basic instruction @xmath235 is defined as : @xmath561 the * remainder * of program @xmath279 given basic instruction @xmath235 is defined as : @xmath562    with definitions for the history and the remainder of a program in hand , we can define marginal side effects . according to our intuition",
    ", a side effect should be marginal if the evaluation of the remainder of the program is the same regardless of whether the side effect occurred .",
    "we can tell if that is the case by evaluating the remainder of the program with two different valuations : one in which the single instruction in which the side effect occurs has been evaluated using the actual evaluation , and one in which is has been evaluated using the expected evaluation .",
    "if the only difference between those two valuations is exactly the side effect that occurred in the single instruction , or if there is no difference between those two valuations at all , then we can say that the evaluation of the remainder of the program has been the same .",
    "this is formally defined as follows :    let @xmath279 be a deterministic program .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath563 be the valuation such that @xmath564 .",
    "let @xmath233 be a single instruction in program @xmath279 causing a side effect , that is , for @xmath565 , @xmath566 .",
    "let @xmath567 be the valuation such that @xmath568 and let @xmath569 be the valuation such that @xmath570 .",
    "the side effect in @xmath233 is marginal iff for @xmath571 @xmath572    so what happens here exactly ? to show this , we return to the examples we have given earlier in this section . first , consider the program @xmath573\\top);y:=1 $ ] , with initial valuation @xmath38 such that @xmath194 .",
    "we can observe that @xmath279 is in canonical form .",
    "in this program , a side effect occurs in the single instruction @xmath574\\top)$ ] .",
    "so is this side effect marginal or not ?",
    "here we have the following : @xmath575\\\\ f_{a } & = f[x \\mapsto 2 , y \\mapsto 0]\\\\ f_{e } & = f[x \\mapsto 1 , y \\mapsto 0]\\\\ h_{a } & = f_{a}[x \\mapsto 2 , y \\mapsto 1]\\\\ h_{e } & = f_{e}[x \\mapsto 1 , y \\mapsto 1]\\end{aligned}\\ ] ] as we can see , the valuations @xmath73 and @xmath569 are the same . using our current definition of the expected evaluation , this will always be the case , so we could just use valuation @xmath73 here .",
    "however , as i have said in section [ sec : outside ] of chapter [ ch : treatment ] , i want to keep generality in the definitions of side effects . we might want to change the definition of the expected evaluation in the future or add new instructions or connectives that do modify the initial valuation .",
    "therefore , we use valuation @xmath569 , the resulting valuation after evaluating the single instruction @xmath233 with the expected evaluation .    to determine if the side effects are marginal , we have to ask ourselves if @xmath576 we know how to calculate the set of side effects ; it is @xmath517 . in this case",
    ", @xmath577 is @xmath517 too , so the side effect occurring in @xmath233 is marginal , which is what we want .",
    "we can also clearly see in this case that it is no coincidence that we are testing @xmath577 and not @xmath578 : we need the valuation that is the result of evaluating the single instruction using the actual evaluation in order to properly compare this with the set of side effects .",
    "we can now take a look at an example in which the side effect should not be marginal .",
    "consider the program @xmath573\\top);x:=x+1 $ ] , with initial valuation @xmath38 such that @xmath579 .",
    "this program is in canonical form too and the side effect occurs in the same single instruction @xmath233 .",
    "this time we get the following : @xmath580\\\\ f_{a } & = f[x \\mapsto 2]\\\\ f_{e } & = f[x \\mapsto 1]\\\\ h_{a } & = f_{a}[x \\mapsto 3]\\\\ h_{e } & = f_{e}[x \\mapsto 1]\\end{aligned}\\ ] ] we have the same set of side effects : @xmath517 .",
    "however , @xmath577 now is @xmath581 .",
    "therefore the side effect is not marginal , which is again what we would expect .",
    "we have given a third example which closely resembles the ones we have discussed above , namely @xmath573\\top);x:=42 $ ] .",
    "if we take the same initial valuation @xmath38 as above , everything except the remainder of the program given @xmath233 will be the same : @xmath582\\\\ f_{a } & = f[x \\mapsto 2]\\\\ f_{e } & = f[x \\mapsto 1]\\\\ h_{a } & = f_{a}[x \\mapsto 42]\\\\ h_{e } & = f_{e}[x \\mapsto 42]\\end{aligned}\\ ] ] with this example we can see why our definition of marginal side effects allows the difference between @xmath563 and @xmath583 to be @xmath584 , too .",
    "we have seen before that in situations like these , the side effects should be marginal , and by allowing the difference to be @xmath584 , that indeed is the case .",
    "as we have seen , our current definition of marginal side effects is capable of determining whether a side effect occurring in a single instruction is marginal or not .",
    "we still have to define marginal side effects for basic instructions .",
    "in particular , we need to have a definition for the situation in which a primitive formula in a complex test causes a side effect and in that same test , the variable affected by that side effect is used again , such as in the following program : @xmath585\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2));y:=1 $ ] . in order to define how to determine if a side effect is marginal or not in these situations , we need to extend our definitions of the history and remainder of a program such that it not only works given a single instruction , but also given a primitive formula . before we can give that definition , we first need to define the history and remainder of a compound formula given a primitive formula .",
    "we are once again only interested in those two concepts if the primitive formula @xmath231 gets evaluated .",
    "to get an idea of what the history and the remainder of a compound formula given a primitive formula should be , consider the following example : @xmath586\\top\\\\ \\phi & = \\neg\\varphi { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } ( x \\leq 10)\\\\ & = \\neg([x:=6]\\top ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } ( x \\leq 10)\\end{aligned}\\ ] ] in this example , the history of @xmath6 given @xmath231 and given model @xmath87 and initial valuation @xmath38 is empty .",
    "the remainder , however , is not : @xmath587 notice that this remainder should be empty if @xmath476 would have been true .",
    "the history of a formula of course is not always empty . to illustrate that",
    ", we will first introduce a notational convention .",
    "we will write @xmath588 to refer to the primitive formula @xmath231 occurring in formula @xmath6 at a specific position .    as an example of this , compare the formulas @xmath589 and @xmath590 .",
    "the difference between the formulas @xmath591 and @xmath592 is in the instance of primitive formula @xmath231 we are referring to .",
    "let @xmath593\\top$ ] and @xmath588 as in the example above .",
    "now consider the following example : @xmath594 here the history of @xmath7 given @xmath595 and given model m and initial valuation @xmath38 such that @xmath596 is not empty : @xmath597 now that we have given an intuition what the history and remainder of a formula given a primitive formula and an initial valuation are going to be , we can move on to giving the actual definitions . in what follows",
    "we will assume that the @xmath6 in @xmath598 is in normal form and that the specific primitive formula @xmath595 actually appears exactly once in formula @xmath588 ( although other instances of @xmath231 may occur in the formula ) .",
    "@xmath588 can take the following forms : @xmath599 here @xmath600 is the same as @xmath231 .",
    "for each of these forms , we will have to define how the history and the remainder is calculated .",
    "[ def : historyremainderformula ] let @xmath6 be a formula of one of the above forms .",
    "let model @xmath87 and initial valuation @xmath38 be given .",
    "let @xmath595 be a primitive formula occurring in @xmath6 such that @xmath595 gets evaluated during the evaluation of @xmath6 given initial valuation @xmath38 .",
    "the * history * of formula @xmath6 given primitive formula @xmath595 is defined as : @xmath601 the * remainder * of formula @xmath6 given primitive formula @xmath595 is defined as : @xmath602    the reason we are only interested in the history and remainder of a primitive formula if that formula is actually evaluated , is straight - forward : we use these definitions to calculate the side effects caused by that primitive formula and those side effects only exist if the primitive formula is evaluated . as straight - forward as this is , the restriction is an important one . because we know that @xmath595 gets evaluated ( not be be confused with ` yielding true ' )",
    ", we do not have to take potentially troublesome formulas into account such as @xmath603 .",
    "the above definitions make the history and remainder of a formula given a primitive formula , partial functions . to see in which situations the history and remainder are defined and for which they are not , consider the following formula : @xmath604\\top ) { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } [ x:=x+2]\\top\\ ] ] now assume we want to know the history of @xmath6 given @xmath605\\top$ ] . this history @xmath606 is only defined if @xmath607\\top$ ] gets evaluated , which in turn only is the case if we have a initial valuation @xmath38 such that @xmath608 . for all initial valuations @xmath609 such that @xmath610 , the history of @xmath6 given @xmath231 is undefined .",
    "if we would be interested in the history of @xmath6 given @xmath611\\top$ ] , the situation would be reversed : in that case the history @xmath612 is only undefined with initial valuation @xmath38 such that @xmath608 .    that the history ( and the remainder ) is undefined in these cases is not problematic because as said , we are going to use these definitions to check",
    "if the side effects caused by @xmath595 are marginal and @xmath595 can only cause side effects if it gets evaluated .    using these definitions",
    ", we can move on to define the history and remainder of a program given a primitive formula :    [ def : historyformula ] let @xmath279 be a deterministic program in canonical form .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath91 be the valuation such that @xmath613 .",
    "let @xmath254 be a test occurring in program @xmath279 , where @xmath6 is a formula in normal form .",
    "finally , let @xmath595 be a primitive formula occuring in @xmath6 such that @xmath595 gets evaluated during the evaluation of @xmath6 given initial valuation @xmath38 .",
    "the * history * of program @xmath279 given primitive formula @xmath595 is , for @xmath614 , defined as : @xmath615 the * remainder * of program @xmath279 given primitive formula @xmath595 is defined as : @xmath616    the final step is to give a definition to determine if a side effect occurring in a primitive formula is marginal . given the above , this definition should not be surprising :    let @xmath279 be a deterministic program .",
    "let model @xmath87 and initial valuation @xmath38 be given and let @xmath617 be the valuation such that @xmath564 .",
    "let @xmath595 be a primitive formula in program @xmath279 causing one of the side effects of @xmath279 .",
    "let @xmath73 be the valuation such that @xmath618 .",
    "let @xmath567 be the valuation such that @xmath619 or @xmath620 and let @xmath569 be the valuation such that @xmath621 or @xmath622",
    ". might actually yield false if @xmath231 is part of a larger formula @xmath6 that despite that yields true , such as @xmath623 such that @xmath624 .",
    "thus , we need either @xmath231 or @xmath476 . ]",
    "the side effect caused by @xmath595 is marginal iff for @xmath625 @xmath626    to show how this works , we return to the example given in the beginning of this section : @xmath573\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2));y:=1 $ ] , with initial valuation @xmath38 such that @xmath523 . here",
    "the primitive formula @xmath627\\top$ ] causes a side effect .",
    "we can now use our definition to find out if that side effect is marginal .",
    "for that , we first need the history of @xmath279 given primitive formula @xmath595 . to calculate @xmath628 , we first observe that @xmath6 is in normal form .",
    "this gives us a go to use definition [ def : historyformula ] .",
    "this definition tells us to first calculate valuation @xmath73 , which we get by evaluating @xmath629 . here",
    "@xmath97 is a basic instruction , so we can use definition [ def : historybasic ] to calculate it .",
    "we have seen before how that evaluates : @xmath630 thus we get @xmath158 , so @xmath631 $ ] .    all we need to do now to get the history we are looking for , is the history of formula @xmath6 given primitive formula @xmath595 : @xmath632 .",
    "we can use definition [ def : historyremainderformula ] here and are in the situation where @xmath633 . here",
    "@xmath634 and @xmath635 , so as history we get : @xmath636 thus , the history of program @xmath279 given primitive formula @xmath595 is : @xmath637 with the information above we can also immediately calculate the remainder of formula @xmath6 given primitive formula @xmath595 : @xmath638 then all we need to determine the remainder of program @xmath279 given primitive formula @xmath595 is the remainder of program @xmath279 given basic instruction @xmath97 . to see how this evaluates ,",
    "see the previous section .",
    "we can use definition [ def : historybasic ] for this again and get : @xmath639\\\\ \\mathcal{r}_{f_{a}}^{m}(d\\pi,\\underline{\\varphi } ) & = ( y:=1)\\end{aligned}\\ ] ] so the remainder of program @xmath279 given primitive formula @xmath595 is : @xmath640 now that we have the history and the remainder of @xmath279 given @xmath595 , we can finally determine if the side effect occurring in @xmath595 is marginal . to quickly recap",
    ", we have : @xmath641\\\\ f_{a } & = f[x \\mapsto 2 , y \\mapsto 0]\\\\ f_{e } & = f[x \\mapsto 1 , y \\mapsto 0]\\\\ h_{a } & = f_{a}[x \\mapsto 2 , y \\mapsto 1]\\\\ h_{e } & \\text { does not exist}\\end{aligned}\\ ] ] here we have an example where we do not even have to determine if @xmath577 is the same as @xmath642 , because there is no valuation @xmath583 such that @xmath643 this is because for valuation @xmath569 the test @xmath644 will fail . therefore , the side effect in @xmath595 is ` automatically ' not marginal , which is indeed what we wanted .",
    "there are two more classes of side effects that i want to discuss .",
    "the first is the class _ detectible side effects_. according to bergstra , a side effect in an instruction is detectible if the fact that that side effect has occured can be measured by means of a steering fragment containing that instruction @xcite .",
    "this is the most general class of side effects : in my terms , any difference between the actual and the expected evaluation of a single instruction is a detectible side effect .",
    "the presence of detectible side effects suggests there are non - detectible side effects as well",
    ". this can indeed be the case . a side effect",
    "is undetectible if the evaluation of a ( single ) instruction causing a side effect would normally change the program state , but because of the specific initial valuation , it does not . as a simple example , consider the single instruction @xmath645\\top)$ ] . under any initial valuation @xmath38 this",
    "would change the program state and cause a side effect , with one exception : namely if @xmath646 .",
    "we can formally define this as follows :    let @xmath233 be a single instruction in model @xmath87 under initial valuation @xmath38 , updating the valuation of a variable @xmath31 .",
    ", this would mean that @xmath233 either is @xmath118 or @xmath647\\top$ ] . ] furthermore , let @xmath648 .",
    "@xmath233 contains an * undetectible side effect * iff for @xmath91 such that @xmath649 : @xmath650    it remains to be seen whether these non - detectible side effects are worth our attention .",
    "after all , not being able to detect side effects suggests that the presence of the side effects does not make much difference , in any case not to the further execution of the program .",
    "possible exceptions to this are the execution speed or the efficiency of the program , especially if there are a lot of undetectible side effects .",
    "in contrast to non - detectible side effects , marginal side effects can potentially be very useful because they can occur far more often . like non - detectible side effects , they are a measure of the impact of a side effect . if a side effect is marginal , that means that the rest of the program is unaffected by it and therefore , the side effect is essentially pretty harmless .",
    "one could at this point imagine a claim that a program in which only marginal side effects occur can be considered a well - written program , whereas a program in which non - marginal side effects occur is one that should probably be rewritten to avoid unexpected behavior .",
    "we will leave further investigation of this claim for future work , however .",
    "in chapter [ ch : treatment ] , i presented the system i will be using for the treatment of side effects . in this chapter",
    "i will provide a case study to see my system in action .",
    "for this , we will use _ program algebra _ ( pga ) @xcite .",
    "since pga is a basic framework for sequential programming , it provides an ideal case study for our treatment of side effects . by showing how side effects are determined in the very general setting of pga",
    ", we are essentially showing how they are dealt with on a host of different , more specific programming languages .",
    "i will first summarize pga and explain how we can use it .",
    "next , some extensions necessary for our purpose will be presented .",
    "finally , i will present some examples to see in full how my system deals with side effects .",
    "pga is built from a set @xmath22 of basic instructions ( not to be confused with the dla@xmath0-notion by the same name ) , which are regarded as indivisible units .",
    "basic instructions always provide a boolean reply , which may be used for program control ( i.e.  in steering fragments ) .",
    "there are two composition constructs : concatenation and repetition .",
    "if @xmath339 and @xmath651 are programs , then so is their concatenation @xmath652 and its repetition @xmath653 .",
    "pga has the following primitive instructions :    * * basic instruction * basic instructions are typically notated as ` a , b,`  . as said",
    "they generate a boolean value . especially important for our purpose",
    "is that their associated behavior may modify a ( program ) state . * * termination instruction * this instruction , notated as @xmath654 , terminates the program .",
    "* * test instruction * test instructions come in two flavours : the positive test instruction , notated as @xmath541 ( where @xmath27 is a basic instruction ) , and its negative counterpart , @xmath542 . for the positive test instruction , @xmath27 is evaluated and if it yields ` true ` , all remaining instructions are executed . if it yields ` false ` , the next instruction is skipped and evaluation continues with the instruction after that . for the negative test instruction ,",
    "this is the other way around . * * forward jump instruction * a jump instruction , notated as @xmath655 where @xmath656 can be any natural number .",
    "this instruction prescribes a jump to @xmath656 instructions from the current one .",
    "if @xmath657 , the program jumps to the same instruction and inaction occurs .",
    "if @xmath658 , the program jumps to the next instruction ( so this is essentially useless ) . if @xmath659 , the next instruction is skipped and the program proceeds with the one after that , and so on .",
    "if two programs execute identical sequences of instructions , _ instruction sequence congruence _ holds between them .",
    "this can be axiomatized by the following four axioms : @xmath660 the _ first canonical form _ of a pga program is then defined to be a pga program which is in one of the following two forms :    1 .",
    "@xmath339 not containing a repetition 2 .",
    "@xmath661 , with both @xmath339 and @xmath651 not containing a repetition    any pga program can be rewritten into a first canonical form using the above four equations .",
    "the next four axiom schemes for pga deal with the simplification of chained jumps : @xmath662 programs are considered to be _ structurally congruent _ if they can be proven equal using the axioms pga1 - 8 .",
    "the _ second canonical form _ of a pga program is defined to be a pga program in first canonical form for which additionally the following holds :    1 .",
    "there are no chained jumps 2 .",
    "counters used for a jump into the repeating part of the expression are as short as possible    each pga expression can be rewritten into a shortest structurally equivalent second canonical form using the above eight equations @xcite .",
    "the previous section describes the forms a pga program can take . in this section",
    "i will explain the behavioral semantics defined in @xcite .",
    "the process of determining the behavior of a pga program given its instructions is called _",
    "behavior extraction_. the behavioral semantics itself is based on thread algebra , ta in short .    like pga",
    ", ta has a set @xmath22 of basic instructions , which in this setting are referred to as actions .",
    "furthermore , it has the following two constants and two composition mechanisms :    * * termination * this is notated as ` s ` ( for stop ) and terminates the behavior . *",
    "* divergent behavior * this is notated as ` d ` ( for divergence ) . divergence ( or inaction ) means there no longer is active behavior .",
    "for instance , infinite jump loops cause divergent behavior since the program only makes jumps and does not perform any actions . *",
    "* postconditional composition * this is notated as @xmath663 and means that first @xmath27 is executed ; if its reply is ` true ` then the behavior proceeds with @xmath21 , otherwise it proceeds with @xmath664 .",
    "* * action prefix * this is notated as @xmath665 and is a shorthand for @xmath666 : regardless of the reply of @xmath27 , the behavior will proceed with @xmath21 .",
    "pga is a most basic framework @xcite .",
    "however , there are many extensions that introduce more ` advanced ' programming features such as goto s and backward jump instructions . via projections ,",
    "each of these extensions can be projected to pga in such a way that the resulting pga - program is behaviorally equivalent to the original program .",
    "examples of such extensions are _ pglb _ , in which pga is extended with a backward jump instruction ( ` \\`@xmath655 ) and _ pglb@xmath671 _ , in which pglb is further extended with a label catch instruction ( @xmath672 ) and an absolute goto instruction ( @xmath673 ) .    of particular interest for our purpose",
    "is the extension of pga with the _ unit instruction operator _ ( pga@xmath674 ) , introduced in @xcite .",
    "the idea of the unit instruction operator , notated as @xmath675 , is to wrap a sequence of instructions into a single unit of length 1 .",
    "that way , a more flexible style of pga - programming is possible . in particular , programs of the form    ....",
    "if a then {      b , c , d } else {      f , g , h } ....    now have a more intuitive translation : @xmath676 . , @xmath38 and @xmath91 from being executed when @xmath27 yields true . ]",
    "because , thanks to the unit instruction operator , the instructions @xmath677 , @xmath678 , @xmath679 and @xmath680 are viewed as a single instruction , the execution of those is skipped when @xmath27 yields ` false ` .        as mentioned in section [ sec",
    ": pga ] , in pga a lot of basic notations for assembly - like programming languages are defined , especially with its extension with unit instruction operators ( pga@xmath674 ) @xcite .",
    "however , one important basic notation is missing : that of complex tests , of the form ` if(a and b ) then c `",
    ". as we have seen , currently there are positive and negative test instructions in pga , which can only test the boolean reply of a single instruction .",
    "more complex constructions such as the one in the working example of section [ sec : example ] are however very common in programming practice and also appear in research papers such as @xcite , where they are referred to as complex steering fragments .",
    "this means that for our purpose , pga will have to be extended to accommodate for complex steering fragments .",
    "i will do so below .",
    "atomic steering fragments ( that is , steering fragments containing only one instruction ) are already present in pga in the form of the positive and negative test instruction ( @xmath541 and @xmath542 respectively ) . if we were to extend this with complex steering fragments , an obvious notation would be @xmath681 and @xmath682 .",
    "the question now is what forms @xmath6 can take and what it means to have such a complex test .",
    "since the instructions in the steering fragment need to produce a boolean reply , the answer to the question above in my opinion should be that a complex test can only be meaningful if all the instructions in the complex test may be used to determine the reply .",
    "it is not necessary that all instructions are always used to determine the reply : for instance when using short - circuit evaluation , in some situations not all components of a complex test have to be ( and therefore are not ) used . however",
    ", my claim here is that if a certain instruction is _ never _ necessary to determine the boolean reply of the whole steering fragment , then is should not be in the steering fragment .    currently , pga has two composition constructs ( composition and repetition ) .",
    "neither of those define anything , however , about the boolean value of multiple instructions .",
    "that is , the boolean value of @xmath683 and of @xmath684 is undefined .",
    "the intuitive way to determine the boolean reply of a sequence of instructions is via logical connections such as and ( @xmath15 ) and or ( @xmath16 ) .",
    "however , these are not present yet in pga .",
    "this means that i will have to introduce them in an extension of pga@xmath674 , which we baptize pga@xmath685 .",
    "before i do so , however , i need to say something more about the type of and and or i will be using",
    ". there are multiple flavours available :    * * logical and / or * these versions are notated as @xmath15 and @xmath16 , respectively .",
    "they use full evaluation and the order of evaluation is undefined . * * short - circuit left and / or * these versions are the ones we use in dla@xmath0  ( see chapter [ ch : treatment ] ) .",
    "they are notated as @xmath28 and @xmath29 . from here on i will refer to them as scland and sclor .",
    "they use short - circuit evaluation and are therefore not commutative .",
    "the left conjunct or disjunct is evaluated first .",
    "there naturally are right - hand versions as well , but i will not be using them .",
    "* * logical left and / or * these versions are a combination of the other two : they use full evaluation , but the left conjunct or disjunct is evaluated first .",
    "i will notate this as @xmath686 and @xmath687 , respectively and refer to them as lland and llor .",
    "i will not discuss right - hand versions .",
    "the latter two are interesting for our purpose , because they are very suitable to demonstrate side effects . however , since we currently only have scland and sclor at our disposal in dla@xmath0 , i will concentrate on those connectives .",
    "although lland and llor can be added to both pga and dla@xmath0 , this would raise more questions than it answers , for instance with regard to the logic which would then be behind the system , which is why we leave it for future work .",
    "the above connectives will almost always be used in combination with either a positive or a negative test .",
    "this will be written as @xmath688 ( and similar for the negative test and the @xmath29 connective ) .",
    "if i am to introduce the mentioned logical connectives in pga@xmath685 , i will have to be able to project this extention into pga .",
    "since the projection of pga@xmath689 to pga is already given in @xcite , it is sufficient to project pga@xmath685  to pga@xmath674 to show that the former can be projected to pga .",
    "below is a proposal of a projection of the scland ( @xmath690 ) connective from pga@xmath685  to pga@xmath674 , for @xmath691 : @xmath692 to see why this projection works , consider the following example : suppose we have the sequence @xmath693 with @xmath694 .",
    "this means that if @xmath27 and @xmath677 are true , @xmath678 and @xmath679 will be executed .",
    "otherwise , only @xmath679 will be executed . in pga@xmath685",
    "this sequence would be @xmath695 .",
    "the projection to pga@xmath674 would then be @xmath696@xmath697@xmath698 .",
    "if @xmath27 is false , the execution skips the unit and executes the jump instruction , ending up executing @xmath679 .",
    "if @xmath27 is true , the unit is entered , starting with the test @xmath677 .",
    "if @xmath677 is false , the execution again arrives at the same jump as before , skipping @xmath678 and executing @xmath679 .",
    "if @xmath677 is true , a different jump is executed which makes the program jump to @xmath678 first and only then moves on to @xmath679 , which is exactly the desired behaviour .",
    "the entire projection is wrapped in a unit because , as we will see later , the scland and other operators we define here also are to be considered units .",
    "therefore , a program sequence prior to ( or after ) the operators discussed here can not jump into the execution of that operator . by wrapping the projection into a unit",
    "i ensure that can not happen after the projection either .    for the sclor connective ,",
    "the projection is a little easier .",
    "it looks like this , again for @xmath691 : @xmath699 to see why this projection works , consider the same example as above : @xmath693 , but now with @xmath700 .",
    "so , if @xmath27 and / or @xmath677 are true , @xmath678 and @xmath679 should be executed .",
    "if they are both false , only @xmath679 should be executed . in pga@xmath685",
    "this looks like this : @xmath701 .",
    "the projection to pga@xmath674 then is @xmath702 .",
    "so , if @xmath27 is true , execution skips testing @xmath677 and moves on directly to @xmath678 . if @xmath27 is false , @xmath677 is tested first .",
    "if @xmath677 is also false , execution skips @xmath678 and @xmath679 is executed .",
    "if @xmath677 is true , @xmath678 gets executed first : exactly the desired behaviour .",
    "so far , we have only been considering programs of the form @xmath693 , that is , with a positive test .",
    "of course , we also have the negative test instruction . for a negative test",
    ", the projection of scland resembles that of sclor .",
    "this comes as no surprise since scland and sclor are each other s dual .",
    "it looks like this , again for @xmath691 : @xmath703    the projection of @xmath29 for a negative test resembles the projection of @xmath28 for a positive test : @xmath704      the implementations in the previous section work for steering fragments containing a single logical connective ( that is , with disjuncts or conjuncts @xmath691 ) .",
    "however , we also need to define what happens for larger complex steering fragments ( for instance @xmath705 ) ) . in order to accommodate this",
    ", we need one more property for the @xmath28 and @xmath29 operators in pga : they have to be treated as units .",
    "if we do this , we can give a recursive definition for the projection , with as base cases the ones given in the previous sections .",
    "in what follows , the formulas @xmath259 and @xmath260 can take the following form : @xmath706 as we can see , this includes negation . for more on negation ,",
    "see the next section .",
    "we get the following projections : @xmath707    this works as follows .",
    "consider the example @xmath708 , with @xmath709 .",
    "in pga@xmath685  this would be written as : @xmath710 we can use our new recursive definition of @xmath28 and get : @xmath711 the projections left now are base cases of @xmath541 and @xmath712 , respectively .",
    "thus , we get @xmath713 an interesting question is whether these projections make @xmath28 an associative operator . to find out ,",
    "we compare the above with the example @xmath708 where this time @xmath714 .",
    "we get : @xmath715 we can use behavior extraction to check if these programs are behavioral equivalent . it turns out that both programs indeed have the same behavior : @xmath716 thus , we can conclude that @xmath28 is associative in pga@xmath685 , as we would expect given scl7 .",
    "we can analyze @xmath29 in a similar manner .",
    "now that we have the projections for positive and negative tests defined , we can turn our attention to one more operator that is common both in programming practice and in logic : negation . in pga ,",
    "negation is absent , so we need to define it here .",
    "not all instructions or sequences of instructions can be negated : after all , there is no intuition for the meaning of the negation of a certain behavior .",
    "we can , however , negate basic instructions : by this we mean its boolean reply changes value .",
    "sequences of instructions consisting of the operators i have defined above can be negated as well , which i will write as @xmath717 .",
    "first , i define the following standard projection rules : @xmath718 now that we have this , we need to take a look at how negation interacts with the @xmath28 and @xmath29 connectives . in particular , we are interested in what happens if one or both of the instructions in such a connective are negated . for this ,",
    "the de morgan s laws will come in handy : @xmath719 with the above equations in combination with the equations [ first]-[last ] , we already have the projections for two possible cases ( namely when no instructions are negated and when both instructions are negated ) . that leaves us two other cases for both @xmath28 and @xmath29 : one in which the first instruction is negated , and one in which the other is .",
    "below are the projections of these cases : @xmath720    for more on the @xmath28 and @xmath29 connectives and the rules that apply to them , see the paper by bergstra and ponse on short - circuit logic @xcite as well as chapter [ ch : logicalstructure ] .      in the previous subsections we have seen what the projections of the new logical connectives in pga@xmath685  to pga@xmath721",
    "look like . to complete the list of projections",
    ", we have to define the projections for the ` regular ' instructions , as well as how concatenation and repetition are projected .",
    "this is trivial , since these ` regular ' instructions are the same in pga@xmath685  and pga@xmath721 .",
    "we get for @xmath56 and pga@xmath685-programs @xmath722 @xmath723      in this section i will show how to detect side effects in a pga@xmath685  program using our treatment of side effects . in essence , all we have to do is translate the pga@xmath685  program to an equivalent dla@xmath0-program , which can then be used to determine the side effects that occur .    to recap",
    ", we have the following operators in pga@xmath685  that have to be translated :    * concatenation ( @xmath724 ) * repetition ( @xmath653 ) * unit instruction operator ( @xmath675 ) * termination ( @xmath654 ) * positive and negative tests ( @xmath725 ) * only in tests : conjunction , disjunction and negation ( @xmath256,@xmath726 )    there are two notable differences between pga@xmath685  and dla@xmath0 .",
    "the first is that in pga@xmath685 a program unsuccessfully terminates unless explicitly instructed otherwise by the termination instruction , whereas in dla@xmath0  the default is a successful termination .",
    "this is an issue that has to be addressed to properly translate pga@xmath685  to dla@xmath0  and the best way to do this , is to add the termination instruction to dla@xmath0 .",
    "this illustrates the point i made in section [ sec : outside ] in chapter [ ch : treatment ] : the instructions i defined so far in dla@xmath0  are by no means exhaustive and new instructions may have to be added to them .",
    "this can usually be done by simply defining the actual and expected evaluation of the new instruction .",
    "the nature of the termination instruction requires us to do a little more than just that .",
    "after all , the termination instruction has a control element to it : just like for instance the test instruction it has an influence on which instructions are to be evaluated next . to be exact , _ no _ instructions are to be evaluated next when a termination instruction is encountered during evaluation of a program .",
    "because of this , we have to slightly modify the concatenation operator in dla@xmath0  too when we introduce the termination instruction .",
    "we baptize the extension of dla@xmath0  with the termination instruction dlta@xmath0  ( for dynamic logic with termination and assignment in formulas ) .",
    "the equation for the relational meaning of @xmath654 in a given model @xmath87 and initial valuation @xmath38 is straight - forward .",
    "execution simply finishes with the same resulting valuation as the initial valuation : @xmath727 the updated rule for concatenation has to express that when a termination instruction is encountered , nothing should be evaluated afterwards .",
    "we use a case distinction for this on the first instruction of a concatenation : @xmath728 we only define the termination instruction in the setting of deterministic programs here . this is sufficient because this is the only setting we are currently interested in .",
    "dlta12 replaces qdl12 , but keeps the associative character of concatenation intact : @xmath729 the addition of the termination instruction allows us to easily express pga@xmath685-programs such as @xmath730 in dlta@xmath0 .",
    "they would otherwise have caused a problem because there would have been no easy way to stop the evaluation of the program from continuing to evaluating @xmath677 , which it of course is not supposed to do if @xmath27 yields true .",
    "the other notable difference between pga@xmath685  and dla@xmath0  is that in the former , anything can be used as a basic instruction .",
    "that includes what we refer to in dla@xmath0  as primitive formulas such as @xmath543 or @xmath119 . in pga",
    "the execution of an instruction always succeeds , even if the boolean reply that it generates , is false . to model this in dlta@xmath0",
    ", we have to add the primitive formulas @xmath231 to the set of instructions , as follows : @xmath731 the relational meaning in @xmath87 given initial valuation @xmath38 for these new instructions is simply that they always succeed without modifying @xmath38 : @xmath732    with the termination instruction and the formulas - as - instructions defined , we can take a first look at the mapping from pga@xmath685  to dlta@xmath0 .",
    "for this we define a translation function @xmath733 pga@xmath685@xmath734 dlta@xmath0 .",
    "we define this translation function for pga programs in first or second canonical form only ; this is sufficient because as we have seen , every pga program can be rewritten to first and second canonical form .",
    "first , we define the set @xmath22 of basic instructions in pga to be equal to the set of primitive formulas and single instructions , not being tests , in dla@xmath0 : @xmath735 where @xmath736 denotes the set of single instructions not being tests . in dla@xmath0 , this set only consists of the assignment instruction @xmath118 .    for finite sequences of instructions with length @xmath737 , @xmath691 and @xmath738 , and @xmath6 a formula as meant in section [ subsec : complex ] ,",
    "@xmath739 is defined as follows : @xmath740 here we can clearly see what effect it has that pga@xmath685  has unsuccessful termination as its default .",
    "we have to explicitly introduce unsuccessful termination in dlta@xmath0  by adding @xmath741 ( a test that always fails ) at the end of every instruction .",
    "furthermore , notice the unit instruction operator that here has length @xmath737 , but is transparent when it has to be translated and thus becomes a sequence of instructions with length @xmath656 that is potentially larger than @xmath11 .",
    "finally , notice that there is no need to translate possibly compound formulas @xmath6 .",
    "this is because formulas have the exact same syntax in pga@xmath685  and dlta@xmath0 .",
    "next , we can show the definition of @xmath739 for finite sequences of instructions with length @xmath742 . for @xmath743 , @xmath738 and @xmath6 a formula as meant in section [ subsec : complex ]",
    ", we have @xmath744    with the above translation rules , we can now translate finite pga@xmath685-programs to their dlta@xmath0-versions .",
    "a complete translation would require a translation of repetition as well .",
    "this , however , is quite a complex task .",
    "the reason for that becomes clear when considering examples like these : @xmath745 because of the behavior of @xmath746 , we get into trouble here if we attempt to use the regular translation .",
    "the problem is that @xmath746 can possibly skip the first instruction of the next repetition loop , which is behavior that is hard to translate without explicitly introducing this variant of repetition ( @xmath747 ) in dla@xmath0 .",
    "the same problem arises with the jump instruction . at first glance , the best solution there is to introduce the jump instruction to dla@xmath0  as well . in that case",
    "the second canonical form of pga - programs comes in handy , as it is designed to manipulate expressions with repetition such that no infinite jumps occur .",
    "since this case study is meant as a relatively clear example of how to use dla@xmath0  to model side effects in other systems such as pga , it is beyond our interest here to present these rather complex translations of repetition .",
    "instead , we restrict ourselves to finite pga@xmath685-programs and leave the relational semantics for dla@xmath0 which models side effects , as the basis for future work on pga involving repetition .      in this section",
    "i will present a working example of the translation from finite pga@xmath685-programs , which we write as pga@xmath748 , to dlta@xmath0 .",
    "in addition , i will show that we get sufficiently similar results if we first translate pga@xmath748  to dlta@xmath0  compared to first projecting pga@xmath748  to pga@xmath749  and then translating that to dlta@xmath0 . to be exact",
    ", we are going to show that the following diagram defines a program transformation @xmath84 on finite deterministic programs in dlta@xmath0 : @xmath750^{f_t } \\ar[d]_{\\text{pgaul2pgau } } & \\text{{dlta$_{\\text{f}}$ } } \\ar@{.>}[d]^{e } \\\\",
    "\\text{{pga$_{\\text{u}}^{\\text{fin}}$ } } \\ar[r]_{f_t }        & \\text{{dlta$_{\\text{f}}$ } } } \\ ] ] here @xmath84 is a reduction function on dlta@xmath0  that yields deterministic dlta@xmath0-programs where occurrences of @xmath28 and @xmath29 have been eliminated .    for the working example",
    ", we return to a variant of our running example .",
    "consider the pga@xmath748-program @xmath751\\top{~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } x=2);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2];!\\ ] ] where @xmath752 $ ] suggests a write command .",
    "this is a program of the form @xmath753 with @xmath754\\top , c=(x=2 ) , d = w[x=2]$ ] and @xmath755 $ ] .",
    "thus , we get the following translation , where we for clarity have underlined the instruction that we are going to translate next :    & f_t(;@xmath697(d;);e;)= & + & ( ( b   c);f_t(;e ; ) ) ( ( b   c);f_t(e;))= & + & ( ( b   c);f_t(;;e ; ) ) ( ( b   c);f_t(e;))= & + & ( ( b   c);d;f_t(;e ; ) ) ( ( b   c);f_t(e;))= & + & ( ( b   c);d ; ) ( ( b   c);f_t(;))= & + & ( ( b   c);d ; ) ( ( b   c);e;f_t())= & + & ( ( b   c);d ; ) ( ( b   c);e ; ) &    so there we have it : if we replace the shorthands with their original instructions or formulas again , we get the following dlta@xmath0-program , which we baptize @xmath756 : @xmath757\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2));w[x=2];{\\text{!}})&\\\\ & \\cup&\\\\ & ( { \\text{?}}\\lnot([x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2));w[x\\ne 2];{\\text{!}})&\\end{aligned}\\ ] ] clearly , given model @xmath87 , @xmath758 implies that @xmath759 $ ] .",
    "so , if @xmath485 , the instruction @xmath760 $ ] is executed , after which the program terminates , while for @xmath761 , the instruction @xmath762 $ ] is executed after which the program terminates .",
    "now let @xmath763 , so @xmath764\\top);{\\ensuremath{\\textup{\\textbf{u}}}}(+(x=2);\\#2 ) ; \\#2\\big);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2];!\\ ] ] we compute @xmath765\\top);{\\ensuremath{\\textup{\\textbf{u}}}}(+(x=2);\\#2 ) ; \\#2;{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2];!)\\\\ & = \\begin{array}[t]{l } ( ? (",
    "[ x:=x+1]\\top);f_t(+(x=2);\\#2;\\#2;{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2];!))\\\\ \\cup\\\\ ( ? \\neg ( [ x:=x+1]\\top);f_t(\\#2;{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2 ] ; ! ) ) \\end{array}\\\\[2 mm ] & = \\begin{array}[t]{l } ( ? ( [ x:=x+1]\\top ) ;    \\begin{array}[t]{l }    ( \\\\    ( ? ( x=2);f_t(\\#2;\\#2;{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2];!))\\\\    \\cup\\\\    ( ?",
    "\\neg(x=2);f_t(\\#2;{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2];!))\\\\    )    \\end{array } \\\\ ) \\\\ \\cup\\\\ ( ? \\neg ( [ x:=x+1]\\top);w[x\\ne 2 ] ; ! ) \\end{array } \\\\ & = \\begin{array}[t]{l } ( ?",
    "( [ x:=x+1]\\top ) ;    \\begin{array}[t]{l }    ( \\\\    ( ? ( x=2);w[x=2];!)\\\\    \\cup\\\\    ( ?",
    "\\neg(x=2);w[x\\ne 2];!)\\\\    )    \\end{array } \\\\ ) \\\\ \\cup\\\\ ( ?",
    "\\neg ( [ x:=x+1]\\top);w[x\\ne 2 ] ; ! ) \\end{array}\\end{aligned}\\ ] ] note that for each model @xmath87 and initial valuation @xmath38 , @xmath766\\top)$ ] , so @xmath767\\top ) ;    \\begin{array}[t]{l }    ( \\\\    ( ? ( x=2);w[x=2];!)\\\\    \\cup\\\\    ( ?",
    "\\neg(x=2);w[x\\ne 2];!)\\\\    ) \\rrbracket_h^m    \\end{array}\\ ] ] thus , writing @xmath768 for the rightmost deterministic dlta@xmath0-program , we find @xmath769 we now need to ask ourselves if @xmath768 is ` sufficiently similar ' to the earlier derived @xmath756 .",
    "intuitively , we would say that in this working example , this indeed is the case .",
    "after all , @xmath607\\top$ ] always yields true , so the truth of @xmath607\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2)$ ] depends solely on the boolean reply that @xmath19 yields .",
    "it therefore does not matter if we lift @xmath770\\top$ ] out of the union , which is essentially what we have done in the case of @xmath768 .",
    "we can call two programs ` sufficiently similar ' if they evaluate the same single instructions , not being tests , or primitive formulas in the same order .",
    "we can formalize that notion with the following proposition :    [ prop : sufficient ] let @xmath339 be a program in pga@xmath748 , let @xmath771 and let @xmath772 .",
    "let model @xmath87 be given and let @xmath38 be an initial valuation such that there exists a valuation @xmath91 such that @xmath773 .",
    "then @xmath774 and the same single instructions , not being tests , and primitive formulas are evaluated in the same order during evaluation of @xmath756 and @xmath775 given @xmath38 .",
    "as said , we do not consider repetition as program constructor in our case study .",
    "furthermore , our model of side effects is limited to terminating programs , as opposed to programs that can either end in termination or in divergence",
    ". a proof of this proposition might be found , but is for these reasons perhaps not very much to the point . in chapter",
    "[ ch : conclusions ] ( conclusions ) we return to this issue .",
    "it is , however , worthwhile to check the proposition for our working example .",
    "recall that we have the following @xmath756 and @xmath768 : @xmath757\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2));w[x=2];{\\text{!}})\\\\ & \\cup\\\\ & ( { \\text{?}}\\lnot([x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2));w[x\\ne 2];{\\text{!}})\\\\ d\\pi_u = \\ & { \\text{?}}([x:=x+1]\\top);\\\\ & ( ? ( x=2);w[x=2];!)\\\\ & \\cup\\\\ & ( ? \\neg(x=2);w[x\\ne 2];!)\\end{aligned}\\ ] ] it is not hard to check in this case that for any model @xmath87 and initial valuation @xmath38 such that @xmath756 can be evaluated , @xmath776 .",
    "it is also easy to see that the same single instructions , not being tests , and primitive formulas are evaluated ( in the same order ) .",
    "after all , @xmath756 , first evaluates the primitive formulas @xmath607\\top$ ] and @xmath19 and uses those to determine the reply of @xmath607\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\wedge$ }       \\put(-.54,-0.2){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,-0.2){\\circle{0.6 } }       \\end{picture }       } } ( x=2)$ ] . depending on the reply",
    ", it then either evaluates the single instructions @xmath760 $ ] and @xmath777 , or @xmath778 $ ] and @xmath777 .",
    "almost the same goes for @xmath768 .",
    "it first evaluates the primitive formula @xmath607\\top$ ] and depending on the reply ( which happens to be always true ) , either stops evaluation ( which therefore is never the case ) or continues with the evaluation of primitive formula @xmath19 . depending on the reply , it like @xmath756 then either evaluates the single instructions @xmath760 $ ] and @xmath777 , or @xmath778 $ ] and @xmath777 .",
    "so at least in our working example , proposition [ prop : sufficient ] holds .    in a similar way , we can analyze the pga@xmath748-program @xmath779\\top{~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];{\\text{!}});w[x\\ne2];{\\text{!}}\\ ] ] we can compute @xmath780 : @xmath781\\top{~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];{\\text{!}});w[x\\ne2];{\\text{!}})\\\\ & = \\begin{array}[t]{l } ( { \\text{?}}(\\neg[x:=x+1]\\top{~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);f_t({\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];{\\text{!}});w[x\\ne2];{\\text{!}})\\\\ \\cup\\\\ ( ?",
    "\\neg(\\neg[x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);f_t(w[x\\ne 2];{\\text { ! } } ) ) \\end{array}\\\\ & = \\begin{array}[t]{l } ( { \\text{?}}(\\neg[x:=x+1]\\top{~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);f_t(w[x=2];{\\text{!}};w[x\\ne2];{\\text{!}})\\\\ \\cup\\\\ ( ?",
    "\\neg(\\neg[x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);w[x\\ne 2];f_t({\\text { ! } } ) ) \\end{array}\\\\ & = \\begin{array}[t]{l } ( { \\text{?}}(\\neg[x:=x+1]\\top{~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);w[x=2];f_t({\\text{!}};w[x\\ne2];{\\text{!}})\\\\ \\cup\\\\ ( ?",
    "\\neg(\\neg[x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);w[x\\ne 2];{\\text { ! } } ) \\end{array}\\\\ & = \\begin{array}[t]{l } ( { \\text{?}}(\\neg[x:=x+1]\\top{~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);w[x=2];{\\text{!}})\\\\ \\cup\\\\ ( ?",
    "\\neg(\\neg[x:=x+1]\\top { ~       \\mathbin{\\setlength{\\unitlength}{1ex }       \\begin{picture}(1.4,1.8)(-.3,0 )       \\put(-.6,0){$\\vee$ }       \\put(-.54,1.54){\\textcolor{white}{\\circle*{0.6 } } }       \\put(-.54,1.54){\\circle{0.6 } }       \\end{picture }       } } x=2);w[x\\ne 2];{\\text { ! } } ) \\end{array}\\end{aligned}\\ ] ] we once again define @xmath763 , so @xmath782\\top);\\#2;+(x=2)\\big);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];!);w[x\\ne 2];{\\text{!}}\\ ] ] we compute @xmath783\\top);\\#2;+(x=2);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];{\\text{!}});w[x\\ne 2];{\\text{!}})\\\\ & = \\begin{array}[t]{l } ( { \\text{?}}(\\neg([x:=x+1]\\top));f_t(\\#2;+(x=2);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];{\\text{!}});w[x\\ne2];{\\text{!}})\\\\ \\cup\\\\ ( ? \\neg(\\neg([x:=x+1]\\top));f_t(+(x=2);{\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];{\\text{!}});w[x\\ne2];{\\text { ! } } ) \\end{array}\\\\ & = \\begin{array}[t]{l } ( { \\text{?}}(\\neg([x:=x+1]\\top));f_t({\\ensuremath{\\textup{\\textbf{u}}}}(w[x=2];{\\text{!}});w[x\\ne2];{\\text{!}})\\\\ \\cup\\\\ ( ? \\neg(\\neg[x:=x+1]\\top ) ; \\begin{array}[t]{l }    ( \\\\    ( ? ( x=2);f_t(w[x=2];{\\text{!}};w[x\\ne2];{\\text{!}}))\\\\    \\cup\\\\    ( ?",
    "\\neg(x=2);f_t(w[x\\ne 2];!))\\\\    )    \\end{array } \\end{array}\\\\ & = \\begin{array}[t]{l } ( { \\text{?}}(\\neg([x:=x+1]\\top));w[x=2];{\\text{!}})\\\\ \\cup\\\\ ( ?",
    "\\neg(\\neg([x:=x+1]\\top ) ) ; \\begin{array}[t]{l }    ( \\\\    ( ?",
    "( x=2);w[x=2];{\\text{!}})\\\\    \\cup\\\\    ( ?",
    "\\neg(x=2);w[x\\ne 2];{\\text{!}})\\\\    )    \\end{array } \\end{array}\\end{aligned}\\ ] ] we can directly eliminate a situation : @xmath784\\top)$ ] is false for any initial valuation @xmath38 .",
    "thus , writing @xmath768 for the second part of the topmost union : @xmath785\\top ) ) ; \\begin{array}[t]{l }    ( \\\\    ( ?",
    "( x=2);w[x=2];{\\text{!}})\\\\    \\cup\\\\    ( ?",
    "\\neg(x=2);w[x\\ne 2];{\\text{!}})\\\\    )    \\end{array}\\ ] ] we get given model @xmath87 for any initial valuation @xmath38 @xmath786 we can check in similar fashion as before that proposition [ prop : sufficient ] holds ( for any initial valuation @xmath38 ) .",
    "we can conclude that at least for these working examples , the mentioned proposition is valid .",
    "as said , we leave the proof for future work .    this case study started from the abstract approach to attempt decomposition of complex steering fragments in instruction sequences in pga@xmath748  as advocated in @xcite .",
    "we show that we can apply this approach to a rather concrete instance in imperative programming ( namely the set @xmath22 of basic instructions given in this chapter ) and we obtain some interesting results . in the first place",
    ", it inspired our definition of dlta@xmath0  and the analysis and classification of side effects as discussed in this thesis .",
    "secondly , by the preservation property formulated in proposition [ prop : sufficient ] , it justifies our proposal for the projection function @xmath787 .",
    "it is an interesting result that we are able to show that the projection @xmath787 , which does not have to anything to do with valuations , preserves the relational semantics ( and therefore side effects ) of a program via the diagram at the beginning of this section , which is based on a very natural translation .",
    "in this thesis i have given a formal definition of side effects .",
    "i have done so by modifying a system for modelling program instructions and program states , quantified dynamic logic , to a system called dla@xmath0  ( dynamic logic with assignments as formulas ) , which in contrast to qdl allows assignments in formulas and makes use of short - circuit evaluation .",
    "i have shown the underlying logic in those formulas to be a variant of short - circuit logic called repetition - proof short - circuit logic .",
    "using dla@xmath0  i have defined the actual and the expected evaluation of a single instruction .",
    "the side effects are then defined to be the difference between the two .",
    "i have given rules for composing those side effects in single instructions , thus scaling up our definition of side effects to a definition of side effects in deterministic dla@xmath0-programs .",
    "using this definition i have given a classification of side effects , introducing as most important class that of marginal side effects .",
    "finally , i have shown how to use our system for calculating the side effects in a real system such as pga .",
    "our definition gives us an intuitive way to calculate the side effects in a program .",
    "because of the definition in terms of actual and expected evaluation , one can easily adapt the system to ones own needs without having to change the definition of side effects .",
    "all one has to do is update the expected evaluation of a single instruction , or if an entirely new single instruction is added to the system , define the actual and expected evaluation for it .    in chapter [ ch : logicalstructure ] we have seen how a sound axiomatization of the formulas in dla@xmath0  can be given using the signature @xmath788 .",
    "i have not used this signature in the first place because i wanted to stick to the conventions in dynamic logic .",
    "it is noteworthy , however , that this alternative and possibly more elegant signature exists , especially because an axiomatization can be given for it .",
    "* i do not want to claim that the instructions i have defined in dla@xmath0  are exhaustive .",
    "finding out what possible other instructions might have to be added to dla@xmath0  can be an interesting project . *",
    "another possible subject for future work is the issue of ` negative ' side effects i briefly touched upon in section [ sec : outside ] .",
    "it is an open question whether or not we should allow situations in which ` negative ' side effects occur and if so , how we should handle them . * in this thesis , we have mostly been looking at imperative programs .",
    "it should be interesting to see if our definition can be extended to , for example , functional programs .",
    "perhaps the work done by van eijck in @xcite , in which he defines functional programs making use of program states , can be used for this .",
    "* another interesting question , which has been raised before in chapters [ ch : qdl ] and [ ch : treatment ] , is that of side effects in non - deterministic programs .",
    "it warrants further research if it is reasonable to talk about side effects there .",
    "one can imagine that if the set of side effects in all possibilities of a non - deterministic program are the same , the side effects of the whole can be defined as exactly that set .",
    "what needs to be done if that s not the case however , or if we should even want to define side effects of such programs , are open questions . * in chapter",
    "[ ch : classification ] , the concept of marginal side effects was introduced and the suggestion was made that this notion can be linked to claims about how well - written a program is .",
    "i have not pursued such claims , but can imagine further research being done in that area . * to develop a direct modelling of side effects for the variant of pga discussed in chapter [ ch : pga ] , one can introduce valuation functions as program states and define a relational meaning that separates termination from deadlock / inaction , say @xmath789_h\\ ] ] the idea of this would be to evaluate @xmath339 as far as possible , which is a reasonable requirement if @xmath339 is in second canonical form .",
    "in addition , we could define a termination predicate , e.g. term@xmath790 , which states that @xmath339 terminates for initial valuation @xmath38 . using this",
    "we could define a `` behavioral equivalence '' on programs @xmath339 and @xmath651 as follows : @xmath791_h \\text { iff } _ g\\llbracket\\ ! [ y \\rrbracket\\!]_h \\text { and } \\text{term}(x , g ) \\text { iff term}(y , g)\\ ] ] using this , proposition [ prop : sufficient ] can probably be proven , especially considering the in chapter [ ch : terminology ] proven property of dla@xmath0  that any program can be rewritten into a form in which its steering fragments only contain primitive formulas and their negations . *",
    "also mentioned in chapter [ ch : pga ] is the possibility to introduce extra logical operators , namely logical left and ( lland ) and its dual logical left or ( llor ) .",
    "introducing these in dla@xmath0  is fairly straight - forward : one only needs to define its truth in @xmath87 : @xmath792 as well as update the program extraction function : @xmath793 to introduce the same operator in pga@xmath685 , projection functions in the same style as the ones given in chapter [ ch : pga ] for scland and sclor need to be defined . *",
    "another possible matter for further study is whether side effects can be used in natural language . in the introduction",
    ", we have already seen that they can occur in the pregnant wife example , where your wife told you to do the grocery shopping if she did not call you , which she later did , but to tell you that she was pregnant .",
    "possibly there is a role for side effects when explaining misunderstandings .",
    "there is no doubt that side effects can be the cause of misunderstandings .",
    "the pregnant wife example illustrates that : you could decide to do grocery shopping to be on the safe side after her call , claiming her call indicated you might have to shop , only to run into your wife at the store also shopping ( who , of course , did nt want to convey the message that you should shop at all ) .",
    "+ when we take the dynamic epistemic logic system mentioned in @xcite , the knowledge of two communicating agents is captured by an epistemic state , one for each agent",
    ". the agents also have an epistemic state for what they think is the ( relevant ) knowledge of the other agent with whom they are in conversation .",
    "a misunderstanding has occurred when an agent updates his own epistemic state in a different way than the other agents expects him to .",
    "there are a lot of ways in which this can happen , but relevant for us is that one of those ways is , when a side effect from an utterance occurs of which one of the agents is not aware .",
    "+ if one of the agents is aware of the side effect and also of the fact the other agent might not be aware of it , it may be recommended to point out this side effect to the other agent . in our example of the pregnant wife calling",
    ", this would mean that you would have to ask your wife on the phone that the fact she called leaves you in doubt about the grocery shopping .",
    "naturally , though , we recommend a more enthusiastic response to the news she is pregnant first .",
    "black and p.j . windley .",
    "inference rules for programming languages with side effects in expressions . in : j. von wright ,",
    "j. grundy and j. harrison ( eds . ) , _ theorem proving in higher order logics : 9th international conference _ ,",
    "springer - verlag , berlin , germany , 1996 .",
    "semantical considerations on floyd - hoare logic . in :",
    "p. abrahams , r. lipton and s. bourne ( eds . ) , _",
    "proceedings 17th ieee symposium on foundations of computer science _ , pp .",
    "109 - 121 .",
    "ieee computer science society press , long beach , ca , 1976 ."
  ],
  "abstract_text": [
    "<S> in this thesis i will give a formal definition of side effects . </S>",
    "<S> i will do so by modifying a system for modelling program instructions and program states , quantified dynamic logic , to a system called dla@xmath0  ( for dynamic logic with assignments as formulas ) , which in contrast to qdl allows assignments in formulas and makes use of short - circuit evaluation . </S>",
    "<S> i will show the underlying logic in those formulas to be a variant of short - circuit logic called repetition - proof short - circuit logic .    using dla@xmath0  </S>",
    "<S> i will define the actual and the expected evaluation of a single instruction . </S>",
    "<S> the side effects are then defined to be the difference between the two . </S>",
    "<S> i will give rules for composing those side effects in single instructions , thus scaling up our definition of side effects to a definition of side effects in deterministic dla@xmath0-programs . using this definition </S>",
    "<S> i will give a classification of side effects , introducing as most important class that of marginal side effects . </S>",
    "<S> finally , i will show how to use our system for calculating the side effects in a real system such as program algebra ( pga ) . </S>"
  ]
}