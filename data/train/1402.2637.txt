{
  "article_text": [
    "examine the problem of identifiability in bilinear inverse problems ( bips ) ,  input signal pair recovery for systems where the output is a bilinear function of two unknown inputs .",
    "important practical examples of bips include blind deconvolution  @xcite , blind source separation  @xcite and dictionary learning  @xcite in signal processing , matrix factorization in machine learning  @xcite , blind equalization in wireless communications  @xcite , of particular interest are signal recovery problems from _ under - determined _ systems of measurement where additional structure is needed in order to ensure recovery , and the observation model is _ non - linear _ in the parametrization of the problem .",
    "consider a discrete - time blind linear deconvolution problem .",
    "let @xmath0 and @xmath1 be respectively @xmath2 and @xmath3 dimensional vectors from domains @xmath4 and @xmath5 , and suppose that the noise free linear convolution of @xmath6 and @xmath7 is observed as @xmath8",
    ". then the blind linear deconvolution problem can be represented as the following feasibility problem .",
    "we draw the reader s attention to the observation / measurement model @xmath9 .",
    "notice that if either @xmath6 or @xmath7 was a fixed and known quantity , then we would have an observation model that is linear in the other variable .",
    "however , when both @xmath6 and @xmath7 are unknown variables , then the linear convolution measurement model @xmath9 is no longer linear in the variable pair @xmath10 .",
    "such a structural characteristic is referred to as a _",
    "bilinear _ measurement structure ( formally defined in  [ sec : model ] ) .",
    "the blind linear deconvolution problem   is the resulting inverse problem .",
    "such inverse problems arising from a bilinear measurement structure shall be referred to as _ bilinear inverse problems _ ( formally defined in  [ sec : model ] ) .",
    "a key issue in many under - determined inverse problems is that of _ identifiability _ : `` does a unique solution exist that satisfies the given observations ? ''",
    "identifiability ( and signal reconstruction ) for _ linear _ inverse problems with sparsity and low - rank structures has received considerable attention in the context of compressed sensing and low - rank matrix recovery , respectively , and are now quite well understood  @xcite . in a nutshell , both compressed sensing and low - rank matrix recovery theories guarantee that the unknown sparse / low - rank signal can be _ unambiguously _ reconstructed from relatively few properly designed linear measurements using algorithms with runtime growing polynomially in the signal dimension . for non - linear inverse problems ( including bips ) , however , characterization of identifiability ( and signal reconstruction ) still remains largely open .",
    "to illustrate that analyzing identifiability is nontrivial , we present a simple example .",
    "consider the blind linear deconvolution problem represented by  .",
    "suppose that we have the observation @xmath11 with @xmath12 and @xmath13 .",
    "it is not difficult to verify that both    @xmath14    are valid solutions to  .",
    "furthermore , it is not immediately obvious as to what structural constraints would disambiguate between the above two solutions .",
    "we have showed identifiability and constructed fast recovery algorithms in a previous work  @xcite when @xmath6 ( possibly sparse ) is in the non - negative orthant ( modulo global sign flip ) , whereas we show negative results for the more general sparse ( with respect to the canonical basis ) blind deconvolution problem in  @xcite .      1",
    ".   we cast conic prior constrained bips as low - rank matrix recovery problems , establish the validity of the ` lifting ' procedure (  [ sec : lifting ] ) and develop deterministic sufficient conditions for identifiability (  [ sec : deterministic identifiability ] ) while bridging the gap to necessary conditions in a special case .",
    "our characterization agrees with the intuition that identifiability subject to priors should depend on the joint geometry of the signal space and the bilinear map .",
    "our results are geared towards bilinear maps that admit a nontrivial rank two null space , as is the case with many important bips like blind deconvolution .",
    "2 .   we develop trade - offs between probability of identifiability of a random instance and the complexity of the rank two null space of the lifted bilinear map under three classes of signal ensembles ,  dependent but uncorrelated , independent gaussian , and independent bernoulli (  [ sec : random identifiability ] ) .",
    "specifically , we demonstrate that instance identifiability can be characterized by the complexity of restricted rank two null space , measured by the covering number of the set @xmath15 , where @xmath16 and @xmath17 denote , respectively , the column and row spaces of the matrix @xmath18 and @xmath19 denotes the rank two null space of the lifted bilinear map @xmath20 restricted by the prior on the signal set to @xmath21 . to the best of our knowledge , this gives new structural results solely based on the bilinear measurement model and is thus applicable to general bips .",
    "we demonstrate that the rank two null space of the lifted bilinear map can be partly characterized in at least one important case ( blind deconvolution ) , and conjecture that the same should be possible for other bilinear maps of interest ( dictionary learning , blind source separation , ) .",
    "based on this characterization , we present numerical simulations for selected variations on the blind deconvolution problem to demonstrate the tightness of our scaling laws (  [ sec : numerical results ] ) .",
    "our treatment of bips draws on several different ideas .",
    "we employ ` lifting ' from optimization  @xcite which enables the creation of good relaxations for intractable optimization problems .",
    "this can come at the expense of an increase in the ambient dimension of the optimization variables .",
    "lifting was used in  @xcite for analyzing the phase retrieval problem and in  @xcite for the analysis of blind circular deconvolution .",
    "we employ lifting in the same spirit as  @xcite but our _ goals are different_. firstly , we deal with general bips which include the linear convolution model of  @xcite , the circular convolution model of  @xcite and the compressed bilinear observation model of  @xcite as special cases .",
    "secondly , we focus solely on identifiability ( as opposed to recoverability by convex optimization  @xcite ) enabling far milder assumptions on the distribution of the input signals .    after lifting",
    ", we have a rank one matrix recovery problem , subject to inherited conic constraints .",
    "while encouraging results have been shown for low - rank matrix recovery using the nuclear norm heuristic  @xcite , quite stringent incoherence assumptions are needed between the sampling operator and the true matrix .",
    "furthermore , the results do not generalize to an analysis of identifiability when the sampling operator admits rank two matrices in its null space .",
    "we are able to relax the incoherence assumptions in special cases for analyzing identifiability and also consider sampling operators with a non - trivial rank two null space . since the works @xcite can be interpreted as solving bips with the lifted map drawn from a gaussian random ensemble , thus leading to a trivial rank two null space with high probability , the results therein are not directly comparable to our results .    in  @xcite , a recoverability analysis for the blind circular deconvolution problem is undertaken , but the knowledge of the sparsity pattern of one input signal is needed .",
    "taking our   as an example ,  @xcite assumes @xmath22 and @xmath23 for some _ tall _ deterministic matrix @xmath24 and a _ tall _ gaussian random matrix @xmath25 , where for any matrix @xmath18 , @xmath26 denotes the column space of @xmath18 . in contrast",
    ", we shall make the less stringent assumption on @xmath6 and @xmath7 and show that _ identifiability _ holds with high probability in the presence of rank two matrices in the null space of the lifted linear operator ( sampling operator ) .",
    "a closely related ( but different ) problem is that of retrieving the phase of a signal from the magnitude of its fourier coefficients ( the fourier phase retrieval problem ) .",
    "this is equivalent to recovering the signal given its auto correlation function  @xcite . in terms of our example",
    "blind deconvolution problem  , phase retrieval is equivalent to having the additional constraints @xmath27 and @xmath7 being the time reversed version of @xmath6 .",
    "while the fourier phase retrieval problem may seem superficially similar to the blind deconvolution problem , there are major differences between the two , so much as to ensure identifiability and efficient recoverability for the sparsity regularized ( in the canonical basis ) version of the former  @xcite , while one can explicitly show _ unidentifiability _ for the sparsity regularized ( in the canonical basis ) version of the latter  @xcite ( even with oracle knowledge of the supports of both signals ) .",
    "the difference arises because the fourier phase retrieval problem is a ( non - convex ) quadratic inverse problem rather than a bip , and it satisfies additional properties ( constant trace of the lifted variable ) which make it better conditioned for efficient recovery algorithms  @xcite .    for the dictionary learning problem , an identifiability analysis is developed in  @xcite leveraging results from  @xcite on matrix factorization for sparse dictionary learning using the @xmath28 norm and @xmath29 quasi - norm for @xmath30 .",
    "more recently , exact recoverability of over - complete dictionaries from training samples ( only polynomially large in the dimensions of the dictionary ) has been proved in  @xcite assuming sparse ( but unknown ) coefficient matrix .",
    "while every bip can be recast as a dictionary learning problem in principle , such a transformation would result in additional structural constraints on the dictionary that may or may not be trivial to incorporate in the existing analyses .",
    "this is especially true for bilinear maps over vector pairs .",
    "in contrast , we develop our methods to specifically target bilinear maps over vector pairs (  convolution map ) and thus obtain definitive results where the dictionary learning based formulations would most likely fail .    some identifiability results for blind deconvolution are summarized in  @xcite , but the treatment therein is inflexible to the inclusion of side information about the input signals .",
    "identifiability for non - negative matrix factorization was examined in  @xcite exploiting geometric properties of the non - negative orthant .",
    "although our results can be easily visualized in terms of geometry , they can also be stated purely in terms of linear algebra (  [ thm : suff_ident ] ) .",
    "identifiability results for low - rank matrix completion  @xcite are provided in  @xcite via algebraic and combinatorial conditions using graph theoretic tools , but there is no straightforward way to extend these results to more general lifted linear operators like the convolution map .",
    "overall , to the best of our knowledge , a unified flexible treatment of identifiability in bips has not been developed till date . in this paper , we present such a framework incorporating conic constraints on the input signals ( which includes sparse signals in particular ) .",
    "the remainder of the paper is organized as follows .",
    "the first half of  [ sec : model ] formally introduces bips and a working definition of identifiability .",
    "[ sec : lifting ] describes the lifting technique to reformulate bips as rank one matrix recovery problems , and characterizes the validity of the technique .",
    "[ sec : results ] states our main results on both deterministic and random instance identifiability .  [ sec : discussion ] elaborates on the intuitions , ideas , assumptions and subtle implications associated with the results of  [ sec : results ] .",
    "[ sec : numerical results ] is devoted to results of numerical verification and  [ sec : conclusion ]",
    "concludes the paper . detailed proofs of all the results in the paper appear in the appendices  [ sec : equivalence theorem proof]-[sec : rank-2 null space proposition proof ] .    in order to maintain linearity of exposition to the greatest extent possible , we chose to create a separate section (  [ sec : discussion ] ) for elaborating on intuitions , ideas , assumptions and implications associated with the important results of the paper",
    ". thus , with the exception of  [ sec : discussion ] , rest of the paper can be read in a linear fashion . however , we recommend the reader to switch between  [ sec : results ] and  [ sec : discussion ] as necessary , to better interpret the results presented in  [ sec : results ] .",
    "we state the notational conventions used throughout rest of the paper .",
    "all vectors are assumed to be column vectors unless stated otherwise .",
    "we shall use lowercase boldface alphabets to denote column vectors  (  @xmath8 ) and uppercase boldface alphabets to denote matrices  (  @xmath31 ) .",
    "the all zero ( respectively all one ) vector / matrix shall be denoted by @xmath32 ( respectively @xmath33 ) and the identity matrix by @xmath34 .",
    "the canonical base matrices for the space of @xmath35 real matrices will be denoted by @xmath36 for @xmath37 , @xmath38 and is defined ( element - wise ) as @xmath39 for vectors and/or matrices , @xmath40 , @xmath41 and @xmath42 respectively denote the transpose , trace and rank of their argument , whenever applicable .",
    "special sets are denoted by uppercase blackboard bold font  (  @xmath43 for real numbers ) .",
    "other sets are denoted by uppercase calligraphic font  (  @xmath44 ) .",
    "linear operators on matrices are denoted by uppercase script font  (  @xmath45 ) .",
    "the set of all matrices of rank at most @xmath46 in the null space of a linear operator @xmath45 will be denoted by  @xmath47 , defined as @xmath48 and referred to as the ` rank @xmath46 null space ' . for any matrix @xmath18",
    ", we denote the row and column spaces by @xmath17 and @xmath26 respectively . the projection matrix onto the column space ( respectively row space ) of @xmath18",
    "shall be denoted by @xmath49 ( respectively @xmath50 ) . for any rank one matrix @xmath51 ,",
    "an expression of the form @xmath52 would denote the singular value decomposition of @xmath51 with vectors @xmath53 and @xmath54 each admitting unit .",
    "the standard euclidean inner product on a vector space will be denoted by @xmath55 and the underlying vector space will be clear from the usage context .",
    "all logarithms are with respect to ( ) base @xmath56 unless specified otherwise .",
    "we shall use the @xmath57 , @xmath58 and @xmath59 notation to denote order of growth of any function @xmath60 of @xmath61  its argument .",
    "we have ,    @xmath62",
    "this section introduces the bilinear observation model and the associated bilinear inverse problem in  [ sec : bilinear maps ] and our working definition of identifiability in  [ sec : identifiability defn ] .",
    "[ sec : lifting ] describes the equivalent linear inverse problem obtained by lifting and conditions under which the equivalence holds .",
    "this equivalence is used to establish all of our identifiability results in  [ sec : results ] .",
    "[ defn : bilinear map ] a mapping @xmath63 is called a bilinear map if @xmath64 is a linear map @xmath65 and @xmath66 is a linear map @xmath67 .",
    "we shall consider the generic bilinear system / measurement model introduced in  @xcite , @xmath68 where @xmath8 is the vector of observations , @xmath63 is a given bilinear map , and @xmath10 denotes the pair of unknown signals with a given domain restriction @xmath69 .",
    "we are interested in solving for vectors @xmath6 and @xmath7 from the noiseless observation @xmath8 as given by .",
    "the bip corresponding to the observation model is represented by the following feasibility problem .",
    "the non - negative matrix factorization problem  @xcite serves as an illustrative example of such a problem .",
    "let @xmath70 and @xmath71 be two element - wise non - negative , unknown matrices and suppose that we observe the matrix product @xmath72 which clearly has a bilinear structure .",
    "the non - negative matrix factorization problem is represented by the feasibility problem where the expressions @xmath73 and @xmath74 constrain the matrices @xmath18 and @xmath75 to be elementwise non - negative .",
    "the elementwise non - negativity constraints @xmath76 form a domain restriction in  , in the same way as the constraint @xmath69 serves to restrict the feasible set in  .      notice that _ every _ bip has an inherent scaling ambiguity due to the identity @xmath77 where @xmath78 represents the bilinear map .",
    "thus , a meaningful definition of identifiability , in the context of bips , must disregard this type of scaling ambiguity .",
    "this leads us to the following definition of identifiability .",
    "[ defn : identifiability ] a vector pair @xmath79 is identifiable  the bilinear map @xmath63 if @xmath80 satisfying @xmath81 , @xmath82 such that @xmath83 .",
    "[ rem : equivalence classes ] it is straightforward to see that our definition of identifiability in turn defines an equivalence class of solutions .",
    "thus , we seek to identify the equivalence class induced by the observation @xmath8 in .",
    "later , in  [ sec : lifting ] , we shall ` lift '   to   where , every equivalence class in the domain @xmath69 of the former problem maps to a single point in the domain @xmath84 of the latter problem .",
    "[ rem : ambiguities ] the scaling ambiguity represented by is common to all bips and our definition of identifiability (  [ defn : identifiability ] ) only allows for this kind of ambiguity",
    ". there may be other types of ambiguities depending on the specific bip .",
    "for example , the forward system model associated with   is given by the matrix product operation @xmath85 which shows the following matrix multiplication ambiguity .",
    "@xmath86 where @xmath87 is the right inverse of @xmath88 .",
    "it is possible to define weaker notions of identifiability to allow for this kind of ambiguity . in this paper",
    ", we shall not address this question any further and limit ourselves to the stricter notion of identifiability as given by  [ defn : identifiability ] .",
    "while   is an accurate representation of the class of bips , the formulation does not easily lend itself to an identifiability analysis .",
    "we next rewrite   to facilitate analysis , subject to some technical conditions  ( see  [ thm : equivalence ] and  [ cor : equivalence ] ) .",
    "the equivalent problem is a matrix rank minimization problem subject to linear equality constraints where @xmath89 is _ any _ set satisfying @xmath90 and @xmath91 is a linear operator that can be _ deterministically _ constructed from the bilinear map @xmath78 with the optimization variable @xmath92 in   being related to the optimization variable pair @xmath10 in   by the relation @xmath93 .",
    "the transformation of   to   is an example of ` lifting ' and we shall refer to @xmath94 as the ` lifted linear operator '  the bilinear map @xmath78 .",
    "other examples on lifting can be found in  @xcite . before stating the equivalence results between   and we describe the construction of @xmath94 from @xmath78 .",
    "let @xmath95 be the @xmath96 coordinate projection operator of @xmath97 dimensional vectors to scalars ,  if @xmath98 then @xmath99 . clearly , @xmath100 is a linear operator and hence the composition @xmath101 is a bilinear map .",
    "as @xmath102 is a finite dimensional operator , it is a bounded operator , hence by the riesz representation theorem  @xcite , @xmath103 such that @xmath104 is the unique linear operator satisfying @xmath105 where @xmath55 denotes an inner product operation in @xmath106 .",
    "using , we can convert the bilinear equality constraint in   into a set of @xmath97 linear equality constraints as follows : @xmath107 for each @xmath108 , where the last inner product in is the trace inner product in the space @xmath109 and @xmath110 denotes the @xmath96 coordinate of the observation vector @xmath8 . setting @xmath111 in ,",
    "the @xmath97 linear equality constraints in can be compactly represented , using operator notation , by the vector equality constraint  @xmath112 , where @xmath91 is a linear operator acting on @xmath113 .",
    "this derivation uniquely specifies @xmath94 using the matrices @xmath114 , @xmath108 , and we have the identity @xmath115    for the sake of completeness , we state the definitions of _ equivalence _ and _ feasibility _ in the context of optimization problems (  [ defn : equivalence ] and  [ defn : feasibility ] ) .",
    "thereafter , the connection between   and is described via the statements of  [ thm : equivalence ] and  [ cor : equivalence ] .",
    "[ defn : equivalence ] two optimization problems p and q are said to be equivalent if every solution to p gives a solution to q and every solution to q gives a solution to p.    [ defn : feasibility ] an optimization problem is said to be feasible , if the domain of the optimization variable is non - empty .",
    "[ thm : equivalence ] let   be feasible and let @xmath116 and @xmath117 denote the set of solutions to   and  , respectively",
    ". then the following are true .    1 .",
    "is feasible with solution(s ) of rank at most one .",
    "2 .   @xmath118 .",
    "3 .   @xmath119 if and only if @xmath120 does not hold .",
    "[ sec : equivalence theorem proof ] .",
    "notice that @xmath116 and @xmath117 in  [ thm : equivalence ] depend on the observation vector @xmath8 , so that the statements of  [ thm : equivalence ] have a hidden dependence on @xmath8 . since the observation vector @xmath8 is a function of the input signal pair",
    "@xmath10 it is desirable to have statements analogous to  [ thm : equivalence ] that do not depend on the observation vector @xmath8 .",
    "this is the purpose of  [ cor : equivalence ] below which makes use of @xmath121 , the rank one null space of the lifted operator @xmath94 ( see ) .",
    "[ cor : equivalence ] let   be feasible and let @xmath122 and @xmath123 respectively denote the set of optimal solutions to   and for a given observation vector @xmath8 .   and are equivalent ,  @xmath124 , for every @xmath125 if and only if @xmath126 does not hold .    [ sec : equivalence corollary proof ] .",
    "[ rem : need for validating lifting ] the statements of  [ thm : equivalence ] and  [ cor : equivalence ] are needed to establish the validity of lifting for general bips with @xmath127 . in case @xmath128 (  blind deconvolution ) ,  [ cor : equivalence ] immediately implies that lifting is valid .",
    "[ rem : relax ] notice that lifting   to   allows us some freedom in the choice of the set @xmath129 .",
    "also , we have the additional _ side information _ that the optimal solution to   is a rank one matrix .",
    "these factors could be potentially helpful to develop tight and tractable relaxations to  , that work better than the simple nuclear norm heuristic @xcite (  see @xcite ) .",
    "we do not pursue this question here .     for linear convolution map with @xmath130 , @xmath131 , @xmath132 and @xmath133 .",
    "]    this transformation from   to   gives us several advantages ,    1 .",
    "has linear equality constraints as opposed to the bilinear equality constraints of  .",
    "the former is much easier to handle from an optimization as well as algorithmic perspective than the latter .",
    "2 .   convex relaxation for the nonconvex rank constraint in   is well known @xcite , which is an important requirement from an algorithmic perspective . in contrast , convex relaxation for a generic bilinear constraint is not known .",
    "3 .   the bilinear map is completely determined by the set of matrices @xmath104 and is separated from the variable @xmath92 in  .",
    "thus ,   can be used to study generic bips .",
    "[ fig : lifting example ] illustrates a toy example involving the linear convolution map .",
    "4 .   for every bip",
    "there is an inherent scaling ambiguity ( see ) associated with the bilinear constraint .",
    "however , in  , this scaling ambiguity has been taken care of implicitly when @xmath111 is the variable to be determined .",
    "clearly , @xmath92 is unaffected by the type of scaling ambiguity described in .",
    "norm constraints on @xmath6 or @xmath7 can be used to recover @xmath6 and @xmath7 from @xmath92 but these constraints do not affect  .",
    "5 .   if @xmath6 and/or @xmath7 are sparse in some known dictionary ( possibly over - complete ) then they can be absorbed into the mapping matrices @xmath104 without altering the structure of  . indeed ,",
    "if @xmath31 and @xmath24 are dictionaries such that @xmath134 and @xmath135 then we have @xmath136 for each @xmath108 .",
    "it is clear that   can be rewritten with @xmath137 as the optimization variable ( with a corresponding modification to @xmath129 ) , and comparing and we see that the matrix @xmath138 can be designated to play the same role in the _ rewritten _   as @xmath114 played in the original  .",
    "thus , without loss of generality , we can consider   to be our lifted problem that retains all available prior information from   ( assuming that the equivalence conditions in  [ cor : equivalence ] are satisfied ) .",
    "we state our main results in this section starting with deterministic characterizations of identifiability in  [ sec : universal identifiability ] and  [ sec : deterministic identifiability ] that are simple to state but computationally hard to check for a given bip .",
    "subsequently , in  [ sec : random identifiability ] we investigate whether identifiability holds for most inputs if the input is drawn from some distribution over the domain .",
    "since we have some freedom of choice in the selection of the set @xmath129 according to  [ rem : relax ] , we will work with an arbitrary @xmath129 satisfying .",
    "the extreme cases of @xmath139 and @xmath140 will sometimes be used for examples and to build intuition .",
    "also , for some of the results , we have converse statements only for one of the extreme cases .",
    "we shall use the set @xmath21 to denote the difference @xmath141 , defined as @xmath142      as a straightforward consequence of lifting , we have the following necessary and sufficient condition for   to succeed for all values of the observation @xmath143 .    [ prop : ident_easy ] let @xmath139 .",
    "the solution to   will be correct for every observation @xmath143 if and only if @xmath144 .    [ sec : ident_easy proposition proof ] .",
    "[ rem : converse in proposition ] notice that the `` only if '' part of  [ prop : ident_easy ] requires uniqueness of an observation @xmath8 that is valid for   as well and not just for  . the latter could have observations that arise because of the freedom in the choice of @xmath129 , but those may not be valid for the former . as a result ,",
    "the conclusion of the `` only if '' part of  [ prop : ident_easy ] is somewhat weaker in that it does not imply @xmath145 .    when @xmath146 , @xmath21 represents the set of all rank two matrices in @xmath109 so that  [ prop : ident_easy ] reduces to the more familiar result : @xmath145 is necessary and sufficient for the action of the linear operator @xmath45 to be invertible on the set of all rank one matrices , where the inversion of the action of @xmath45 is achieved as the solution to  .",
    "while the characterization of @xmath147 for arbitrary linear operators @xmath94 is challenging , it has been shown that if @xmath94 is picked as a realization from some desirable distribution then @xmath145 ( implies @xmath144 ) is satisfied with high probability . as an example ,  @xcite show that if @xmath91 is picked from a gaussian random ensemble , then @xmath145 is satisfied with high probability for @xmath148 .",
    "when @xmath94 is sampled from less desirable distributions , as for matrix completion  @xcite or matrix recovery for a specific given basis  @xcite , one does _ not _ have @xmath145 with high probability . to guarantee identifiability ( and unique reconstruction ) for such realizations of @xmath94 , significant domain restrictions via the set @xmath149 ( or @xmath129 )",
    "are usually needed , so that @xmath144 and  [ prop : ident_easy ] comes into effect .",
    "unfortunately , for many important bips ( blind deconvolution , blind source separation , matrix factorization , ) the lifted linear operator @xmath94 _ does have _ a non - trivial @xmath147 set .",
    "this makes identifiability an important issue in practice .",
    "fortunately , we still have @xmath128 in many of these cases so that  [ cor : equivalence ] implies that lifting is valid . for such maps",
    ", we have the following deterministic sufficient condition (  [ thm : suff_ident ] ) for a rank one matrix @xmath150 to be identifiable as a solution of  .",
    "[ thm : suff_ident ] is heavily used for the results in the sequel .",
    "[ thm : suff_ident ] let @xmath151 and @xmath52 be a rank one matrix in @xmath89 .",
    "suppose that for every @xmath152 either @xmath153 or @xmath154 is true , then given the observation @xmath155 , @xmath51 can be successfully recovered by solving  .    [",
    "sec : suff_ident theorem proof ] .",
    "[ thm : suff_ident ] is only a sufficient condition for identifiability .",
    "we bridge the gap to the necessary conditions under a special case in  [ cor : equal singular values ] below .",
    "we use the notation @xmath156 to denote the set @xmath157 .",
    "[ cor : equal singular values ] let @xmath151 and @xmath52 be a rank one matrix in @xmath89 .",
    "suppose that every matrix @xmath158 admits a singular value decomposition with @xmath159 .",
    "let us denote such a decomposition as @xmath160 , and let @xmath161 and @xmath162 for some @xmath163 with @xmath164 .",
    "given the observation @xmath155 ,   successfully recovers @xmath51 if and only if for every @xmath158 , @xmath165 .",
    "[ sec : equal singular values corollary proof ] .",
    "intuitively ,  [ cor : equal singular values ] exploits the fact that all nonzero singular values of a matrix are of the same sign .",
    "indeed , @xmath166 ( respectively @xmath167 ) is an element of the two dimensional space of representation coefficients of @xmath53  @xmath26 ( respectively @xmath54  @xmath17 ) with a fixed representation basis .",
    "[ cor : equal singular values ] says that identifiability of @xmath51 holds if and only if the vectors @xmath166 and @xmath167 do not form an acute angle between them .",
    "the assumption of @xmath159 has been made in  [ cor : equal singular values ] for ease of intuition .",
    "although we do not state it here , an analogous result holds for @xmath168 with the condition on the inner product @xmath169 replaced by the same condition on a weighted inner product , where the weights depend on the ratio of @xmath170 to @xmath171 .    for arbitrary lifted linear operators @xmath94 ,",
    "checking  [ thm : suff_ident ] for a given rank one matrix @xmath51 is usually hard , unless a simple characterization of @xmath147 or @xmath19 has been provided .",
    "it is reasonable to ask `` how many rank one matrices @xmath51 are identifiable ? '' , given any particular lifted linear operator @xmath94 and assuming that the rank one matrices @xmath51 are drawn at random from some distribution .",
    "it is highly desirable if most rank one matrices @xmath51 are identifiable . before we can show such a result we need to define a random model for the rank one matrix @xmath51 .",
    "we consider @xmath172 as a random rank one matrix drawn from an ensemble with the following properties :    1 .",
    "[ itm : cov i d ] @xmath6 ( and @xmath7 ) is a zero mean random vector with an identity covariance matrix .",
    "[ itm : mutual indep ] @xmath6 and @xmath7 are mutually independent .    as a practical motivation for this random model , we consider a blind channel estimation problem where the transmitted signal @xmath6 passes through an unknown linear time invariant channel impulse response @xmath7 . in the absence of measurement noise",
    ", the observed signal at the receiver would be the linear convolution @xmath9 , which is a bilinear map .",
    "a practical modeling choice puts the channel realization @xmath7 statistically independent of the transmitted signal @xmath6 .",
    "furthermore , if channel phase is rapidly varying , then the sign of each entry for @xmath7 is equally likely to be positive or negative with resultant mean as zero .",
    "the transmitted signal @xmath6 can be assumed to be zero mean with independent and identically distributed entries ( and thus identical variance per entry ) under binary - phase - shift - keying and other balanced phase - shift - keying modulation schemes .",
    "the assumption of equal variance per tap is somewhat idealistic for channel @xmath7 , but strictly speaking , this requirement is _ not _ absolutely necessary for our identifiability results .",
    "first , we consider the case when the elements of @xmath6 ( respectively @xmath7 ) are _ not independent_. we shall be interested in the following two possible properties of @xmath6 and @xmath7 :    1 .",
    "[ itm : factor marginal ] the distribution of @xmath6 ( respectively , @xmath7 ) factors into a product of marginal distributions of @xmath173 and @xmath174 ( respectively , @xmath175 and @xmath176 ) .",
    "[ itm : abs lower bound ] @xmath177 such that @xmath178 ( respectively @xmath179 ) a.s",
    ".    we state the following technical lemmas that will be needed in the proofs of  [ thm : whp_suff_ident ] and  [ cor : whp_suff_ident ] .",
    "[ lem : markov estimate special ] is mainly useful when the assumption   can not be satisfied but one needs bounds that closely resemble that of  [ lem : markov estimate ] .",
    "these lemmas allow us to upper bound the probability that @xmath6 ( respectively @xmath7 ) is close to one of the key subspaces in  [ thm : suff_ident ] ,  @xmath16 ( respectively @xmath180 ) where @xmath18 is in the appropriately constrained subset of @xmath181 .",
    "[ lem : markov estimate ] given any @xmath35 real matrix @xmath152 and a constant @xmath182 , a rank one random matrix @xmath183 satisfying assumptions  - also satisfies ,    @xmath184    [ sec : markov estimate lemma proof ] .",
    "[ lem : markov estimate special ] given any @xmath35 real matrix @xmath152 and a constant @xmath182 , a rank one random matrix @xmath183 satisfying assumptions  - , with @xmath6 ( respectively @xmath7 ) satisfying   for a constant @xmath185 ( respectively @xmath186 ) , also satisfies ,    @xmath187    [ sec : markov estimate special lemma proof ] .",
    "[ rem : when is corollary 3 useful ]  [ lem : markov estimate special ] will give non - trivial bounds if @xmath188 ( respectively @xmath189 ) go to @xmath190 fast enough as @xmath2 ( respectively @xmath3 ) goes to @xmath190 , and this growth rate could be slower than @xmath191 ( respectively @xmath192 ) .",
    "an example where  [ lem : markov estimate special ] is applicable but  [ lem : markov estimate ] is not , can be constructed as follows .",
    "as before , let @xmath7 represent a channel impulse response independent of @xmath6 , so that   is satisfied .",
    "let @xmath6 represent a coded data stream under pulse - amplitude - modulation such that @xmath193 with equal probability , @xmath194 and @xmath195 is coded as a function of @xmath173 yielding the following conditional correlation matrices :    @xmath196    [ eqn : mag azimuth depend ]    where @xmath197 is the matrix with elements given by @xmath198 for every @xmath199 .",
    "the expressions in clearly imply that @xmath173 and @xmath174 are dependent so that   does not hold . nonetheless , by construction",
    ", we have @xmath200 so that implies @xmath201 , thus satisfying  .",
    "also , @xmath202 a.s . so that   is satisfied .",
    "thus ,  [ lem : markov estimate special ] is applicable with @xmath203 .",
    "while  [ lem : markov estimate ] provides useful bounds , it does not suffice for many problems where @xmath19 is large .",
    "we can get much stronger bounds than  [ lem : markov estimate ] if the elements of vector @xmath6 ( respectively @xmath7 ) come from independent distributions , by utilizing the _ concentration of measure _",
    "phenomenon  @xcite .",
    "we shall consider the standard gaussian and the symmetric bernoulli distributions , and sharpen the bounds of  [ lem : markov estimate ] in the two technical lemmas to follow .",
    "note that a zero mean independent and identically distributed assumption on the elements of @xmath6 and @xmath7 already implies the assumptions  - .",
    "the bounds of  [ lem : bernoulli chernoff estimate ] and  [ lem : gaussian chernoff estimate ] have an interpretation similar to the _ restricted isometry property _",
    "@xcite and are used in the proofs for  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] , respectively .",
    "we retain the assumption @xmath151 from  [ thm : suff_ident ] and follow the convention that a random variable @xmath204 has a symmetric bernoulli distribution if @xmath205 .    [",
    "lem : gaussian chernoff estimate ] let @xmath151 . given any @xmath35 real matrix @xmath152 and a constant @xmath182 , a random vector @xmath206 with each element drawn independently from a standard normal distribution satisfies @twocolumn @xmath207 @xmath208    [ sec : gaussian chernoff estimate proof ] .",
    "[ lem : bernoulli chernoff estimate ] let @xmath151 . given any @xmath35 real matrix @xmath152 and a constant @xmath182 , a random vector @xmath206 with each element drawn independently from a symmetric bernoulli distribution satisfies @twocolumn @xmath209 @xmath210    [ sec : bernoulli chernoff estimate proof ] .",
    "[ rem : constant factor loss ] provides additional remarks on  [ lem : bernoulli chernoff estimate ] .",
    "we first consider the special case where the size of the set @xmath19 is small  @xmath211 , in  [ sec : finite cardinality ] .",
    "we use the same intuition in  [ sec : infinite cardinality ] to appropriately partition the set @xmath19 when its size is large ( possibly infinite ) with respect to @xmath212 .",
    "it is intuitive to expect that the number of rank one matrices @xmath51 that are identifiable as optimal solutions to   should depend inversely on the _ size / complexity _ of @xmath19 .",
    "below , we shall make this notion precise .",
    "we shall do so by lower bounding the probability of satisfaction of the sufficient conditions in  [ thm : suff_ident ] .",
    "[ thm : whp_suff_ident ] let @xmath151 and @xmath213 be a rank one random matrix satisfying assumptions  - .",
    "suppose that the set @xmath15 is finite with cardinality @xmath214 . for any constant @xmath215 , the sufficient conditions of  [ thm : suff_ident ] are satisfied with probability greater than @xmath216 .",
    "we describe the basic idea behind the proof and defer the full proof to  [ sec : whp_suff_ident theorem proof ] .",
    "the proof consists of the following important steps .",
    "a.   we fix the matrix @xmath152 and then relax the `` hard '' event of subspace membership @xmath217 to the `` soft '' event of being close to the subspace in @xmath218 .",
    "this `` soft '' event describes a body of nonzero volume in @xmath106 .",
    "a similar argument holds for the vector @xmath54 as well .",
    "b.   next , the volumes ( probabilities ) of both these bodies ( events ) is computed individually and utilizing independence between realizations of @xmath53 and @xmath54 , the probability of the intersection of these events is easily computed .",
    "the bounds of  [ lem : markov estimate ] are used in this step . c.   lastly , we employ a union bound over the set of valid matrices @xmath152 to make our results universal in nature .",
    "[ rem : measuring row column space pairs ] ,  [ rem : role of conic prior ] and  [ rem : role of delta ] provide additional remarks on  [ thm : whp_suff_ident ] .",
    "in  [ thm : whp_suff_ident ] , we can drive the probability of identifiability @xmath219 arbitrarily close to one by increasing @xmath2 and/or @xmath3 provided that @xmath214 grows as @xmath220 . for many important bips ( blind deconvolution , blind source separation , matrix factorization , )",
    "this growth rate requirement on @xmath214 is too pessimistic .",
    "tighter versions of  [ thm : whp_suff_ident ] , with more optimistic growth rate requirements on @xmath214 , are possible if the assumptions of  [ lem : gaussian chernoff estimate ] or  [ lem : bernoulli chernoff estimate ] are satisfied .",
    "this is the content of  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] described in  [ sec : infinite cardinality ] .",
    "we provide a corollary to  [ thm : whp_suff_ident ] when assumption   does not hold so that  [ lem : markov estimate ] is inapplicable .",
    "the result uses  [ lem : markov estimate special ] in place of  [ lem : markov estimate ] for the proof .",
    "the bound is asymptotically useful if @xmath214 grows as @xmath221 .",
    "[ cor : whp_suff_ident ] let @xmath151 and @xmath213 be a rank one random matrix satisfying assumptions  - with @xmath6 ( respectively @xmath7 ) satisfying   for a constant @xmath222 ( respectively @xmath223 ) .",
    "suppose that the set @xmath15 is finite with cardinality @xmath214 .",
    "for any constant @xmath215 , the sufficient conditions of  [ thm : suff_ident ] are satisfied with probability greater than @xmath224 .    [",
    "sec : whp_suff_ident corollary proof ] .",
    "when the complexity of @xmath19 is infinite or exponentially large in @xmath225 , the bounds of  [ sec : finite cardinality ] become trivially true for large enough @xmath2 or @xmath3 .",
    "we investigate an alternative bounding technique for this situation using covering numbers . intuitively speaking , covering numbers measure the size of discretized versions of uncountable sets .",
    "the advantage of using such an approach is that the results are not contingent upon the exact geometry of @xmath19 .",
    "thus , like  [ thm : whp_suff_ident ] , the technique and subsequent results are applicable to every bilinear map .",
    "we shall see that to arrive at any sensible results , we will need to use the tighter estimates given by  [ lem : gaussian chernoff estimate ] and  [ lem : bernoulli chernoff estimate ] that are only possible when our signals @xmath6 and @xmath7 are component - wise independent .",
    "for any two sets @xmath226 , the minimum number of translates of @xmath227 needed to cover @xmath228 is called the of @xmath228  @xmath227 and is denoted by @xmath229 . the quantity @xmath230",
    "is known as the of @xmath228  @xmath227 .",
    "it is known that if @xmath231 is a bounded convex body that is symmetric about the origin , and we let @xmath232 for some @xmath233 , then the covering number @xmath234 obeys  @xcite @xmath235 we can _ equivalently _ say that the metric entropy @xmath236 equals @xmath237 .",
    "we shall use this notation for specifying metric entropies of key sets in the theorems to follow .",
    "we state a technical lemma needed to prove  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] .",
    "the lemma bounds the difference between norms of topologically close projection operators as a function of the covering resolution , thus providing a characterization of the sets used to cover over the space of interest .",
    "[ lem : metric entropy ] let @xmath238 , @xmath239 and @xmath233 .",
    "there exists a covering of @xmath240 with metric entropy @xmath241  @xmath242 such that for any @xmath243 satisfying @xmath244 we have @xmath245 for all @xmath206 .",
    "[ sec : epsilon net proof ] .",
    "[ rem : meaning of covering lemma ] provides additional remarks on  [ lem : metric entropy ] .",
    "we are now ready to extend  [ thm : whp_suff_ident ] to the case where the complexity of @xmath19 is large ( possibly infinite ) .",
    "we shall do so for bernoulli and gaussian priors ( as illustrative distributions ) in  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] respectively . the proofs for both these theorems follow on the same lines as that of  [ thm : whp_suff_ident ] , except that the probability bounds of  [ lem : markov estimate ] are replaced by those of  [ lem : bernoulli chernoff estimate ] and  [ lem : gaussian chernoff estimate ] for bernoulli and gaussian priors , respectively .",
    "@twocolumn    [ thm : whp_infinite ]",
    "let @xmath151 , the sets @xmath246 and @xmath247 be defined according to  [ lem : metric entropy ] , and @xmath248 be a rank one random matrix with components of @xmath6 ( respectively @xmath7 ) drawn independently from a symmetric bernoulli distribution with @xmath129 chosen as @xmath249 and @xmath250 .",
    "let @xmath251 ( respectively @xmath252 ) denote the metric entropy of the set @xmath253",
    "@xmath254 ( respectively @xmath255  @xmath256 ) for any @xmath257 and let @xmath258 .",
    "for any constant @xmath259 , the sufficient conditions of  [ thm : suff_ident ] are satisfied with probability greater than @xmath260 with @xmath261 .",
    "[ thm : whp_infinite ] let @xmath151 , the sets @xmath246 and @xmath247 be defined according to  [ lem : metric entropy ] , and @xmath248 be a rank one random matrix with components of @xmath6 ( respectively @xmath7 ) drawn independently from a symmetric bernoulli distribution with @xmath129 chosen as @xmath249 and @xmath250 .",
    "let @xmath251 denote the metric entropy of the set @xmath253",
    "@xmath254 , @xmath252 denote the metric entropy of the set @xmath255",
    "@xmath256 , for any @xmath257 and let @xmath258 .",
    "for any constant @xmath259 , the sufficient conditions of  [ thm : suff_ident ] are satisfied with probability greater than @xmath260 with @xmath261 .",
    "[ sec : whp_infinite theorem proof ] .",
    "@twocolumn    [ thm : whp_infinite_gaussian ] let @xmath128 , the sets @xmath246 and @xmath247 be defined according to  [ lem : metric entropy ] , and @xmath248 be a rank one random matrix with components of @xmath6 ( respectively @xmath7 ) drawn independently from a standard gaussian distribution .",
    "let @xmath251 ( respectively @xmath252 ) denote the metric entropy of the set @xmath262  @xmath254 ( respectively @xmath263",
    "@xmath256 ) for any @xmath233 and let @xmath258 .",
    "for any constant @xmath259 , the sufficient conditions of  [ thm : suff_ident ] are satisfied with probability greater than @xmath264 where @xmath265 and @xmath261 .",
    "[ thm : whp_infinite_gaussian ] let @xmath128 , the sets @xmath246 and @xmath247 be defined according to  [ lem : metric entropy ] , and @xmath248 be a rank one random matrix with components of @xmath6 ( respectively @xmath7 ) drawn independently from a standard gaussian distribution .",
    "let @xmath251 denote the metric entropy of the set @xmath262",
    "@xmath254 , @xmath252 denote the metric entropy of the set @xmath263",
    "@xmath256 for any @xmath233 and let @xmath258 .",
    "for any constant @xmath259 , the sufficient conditions of  [ thm : suff_ident ] are satisfied with probability greater than @xmath264 where @xmath266 and @xmath261 .    [",
    "sec : whp_infinite_gaussian theorem proof ] .",
    "[ rem : bernoulli example ] and  [ rem : range of epsilon ] provide additional remarks on  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] .",
    "a non - trivial illustration of the theoretical scaling law bound of  [ thm : whp_infinite_gaussian ] is provided in  [ fig : theory bounds ] , with @xmath20 as the lifted linear convolution map .",
    "since the bound is parametrized by @xmath267 , we choose @xmath268 and @xmath269 for the illustration .",
    "quite surprisingly ( and fortunately ) , the metric entropy @xmath270 in  [ thm : whp_infinite_gaussian ] can be exactly characterized when @xmath20 represents the lifted linear convolution map . specifically , we have @xmath271 .",
    "we refer the reader to  [ prop : rank-2 nullspace ] in  [ sec : null space of linear convolution ] for details .    ,",
    "@xmath3 for fixed values of @xmath2 , for parameters @xmath268 , @xmath269 and @xmath271 for the lifted linear convolution map ( @xmath270 defined as in  [ thm : whp_infinite_gaussian ] ) . ]    [ rem : mixed prior distributions ] we can obtain results analogous to  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] when @xmath6 and @xmath7 are drawn from non - identical distributions ,  @xmath6 is component - wise  symmetric bernoulli and @xmath7 is component - wise  standard gaussian . the argument is a straightforward modification of the proof .",
    "in this section , we elaborate on the intuitions , ideas , assumptions and subtle implications associated with the main results of this paper that were presented in  [ sec : results ] .      for the purpose of measuring the size / complexity of @xmath19 in  [ thm : whp_suff_ident ]",
    ", we used the cardinality @xmath214 of the set @xmath15 as a surrogate .",
    "this set essentially lists the distinct pairs of row and column spaces in the rank two null space of the lifted linear operator @xmath94 that are not excluded by the domain restriction @xmath272 .",
    "we note that the cardinality of the set @xmath273 could be infinite while its complexity could be finite in the sense just described . the same measure of complexity is used for the extensions of  [ thm : whp_suff_ident ] in  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] . throughout rest of the paper ,",
    "any reference to the complexity of a set of matrices @xmath274 is in the sense just described ,  through the cardinality of the set @xmath275 .",
    "there are three distinct aspects to the prior knowledge in terms of the conic constraint @xmath272 on the unknown signal .    1 .",
    "_ probability bounds : _ a key advantage of prior knowledge about the signal is apparent from the union bounding step in the proof of  [ thm : whp_suff_ident ] .",
    "union bounding over the set @xmath276 always gives better bounds than union bounding over the superset @xmath277 , the quantitative difference being the number @xmath214 in the bound of  [ thm : whp_suff_ident ] .",
    "in general , the difference could be exponentially large in @xmath2 or @xmath3 ( see  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] ) .",
    "we also note that @xmath129 does not need to be a cone in order to exploit this approach to improve the probability bounds",
    "computational trade - offs : _ recalling  [ rem : relax ] , the size of @xmath129 also trades off the ease of computation and the identifiability bounds of  [ thm : whp_suff_ident ] . if the size of @xmath129 needs to be increased to ease computation , an effort must be made to not suffer a substantial increase in the size / complexity of the set @xmath276 . for high dimensional problems (",
    "@xmath2 or @xmath3 is large ) , non - convex conic priors like the sparse cone in compressed sensing  @xcite and the low - rank cone in matrix completion  @xcite have been shown to admit good computationally tractable relaxations .",
    "3 .   _ geometric complexity measure : _ the measure of geometric complexity described in  [ rem : measuring row column space pairs ] followed naturally from  [ thm : suff_ident ] in an effort to describe the identifiability of a bip in terms of quantities like row and column spaces familiar from linear algebra .",
    "this measure of complexity is _",
    "invariant  conic extensions _ in the following way .",
    "let @xmath274 be any set of matrices and let @xmath278 denote its conic extension , defined as @xmath279 then , we have @twocolumn @xmath280 @xmath281 qualitatively speaking , the flavor of results in this paper could also be derived for non - conic priors but the measure of geometric complexity that is used is implicitly based on conic extensions . thus , there is no significant loss of generality in restricting ourselves to conic priors .",
    "although the parameter @xmath182 appears in  [ thm : whp_suff_ident ] as an artifact of our proof strategy , it has an important practical consequence .",
    "it represents a tolerance parameter for approximate versus exact prior information on the input signals .",
    "specifically ,  [ thm : whp_suff_ident ] is a statement about identifiability up to a @xmath282-neighborhood around the true signal @xmath10 .",
    "the same holds true for  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] describing the large / infinite complexity case .",
    "[ lem : metric entropy ] can be informally restated as follows . keeping satisfied , @xmath240",
    "can always be covered by @xmath242 with metric entropy @xmath241 . in  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] below , we are interested in covering the subset @xmath283 by @xmath242 and suppose that the resulting metric entropy is @xmath251 . in a sense ,",
    "[ lem : metric entropy ] represents the worst case scenario that @xmath284 is upper bounded by @xmath285 and no better upper bound is known . in the worst case ,",
    "the aforementioned subset of @xmath240 has nearly the same complexity as @xmath240 and this happens when the set @xmath286 does not represent a large enough structural restriction on the set of rank two matrices in @xmath109 . for large @xmath2 , to guarantee identifiability for most inputs , we would ( realistically ) want @xmath284 to be less than @xmath2 by at least a constant factor .",
    "this is implied by  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] .",
    "informally , smaller or more structured @xmath286 implies a smaller value of @xmath284 which in turn implies identifiability for a greater fraction of the input ensemble .",
    "a standard gaussian prior on the elements of @xmath6 and @xmath7 gives an example of the set @xmath19 with infinite complexity , provided that @xmath147 is complex enough . in this case , @xmath287 in   implying that @xmath288 from .",
    "thus , @xmath289 and hence @xmath290 . since @xmath21 is superfluous in this case ,  [ thm : whp_infinite_gaussian ] omits all references to it .",
    "if the row or column spaces of matrices in @xmath147 are parametrized by one or more real parameters ( see  [ sec : null space of linear convolution ] for an example involving the linear convolution operator ) , then @xmath147 has infinite complexity .",
    "the scenario of a bernoulli prior on elements of @xmath6 and @xmath7 gives an example of the set @xmath19 with finite ( but exponentially large in @xmath225 ) complexity , provided that @xmath147 is complex enough .",
    "the precise statement requires a little more care than the gaussian case described above .",
    "the motivation behind considering bernoulli priors is to restrict the unit vectors @xmath174 and @xmath176 to take values from a large but finite set while adhering to the requirement of a conic prior on @xmath10 according to  .",
    "thus , in this case we have @xmath291 .",
    "let us select @xmath129 according to , but without any relaxation , as @xmath249 clearly , matrices in @xmath129 can account for at most @xmath292 distinct column spaces and @xmath293 distinct row spaces , thus implying that matrices in @xmath250 are generated by at most @xmath294 distinct column spaces and at most @xmath295 distinct row spaces .",
    "thus , @xmath296 is of finite complexity .",
    "it is clear that the complexity of @xmath21 is @xmath297 so that if @xmath298 is small enough then the complexity of @xmath299 is exponentially large in @xmath212 .",
    "we prevent an arbitrarily small @xmath300 for  [ thm : whp_infinite ] by imposing a strictly positive lower bound @xmath301 .",
    "this is necessary for bernoulli priors on @xmath6 and @xmath7 since @xmath299 has a finite complexity , implying that the covering numbers of @xmath262  @xmath254 and @xmath263  @xmath256 have an absolute upper bound independent of @xmath300 .",
    "thus , the logarithmic dependence ( of the key metric entropies ) on @xmath302 can not hold unless @xmath300 is lower bounded away from zero .",
    "[ thm : whp_infinite_gaussian ] , in contrast , allows for arbitrarily small @xmath300 since @xmath303 has infinite complexity , for gaussian priors on @xmath6 and @xmath7 . despite this distinction between  [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ]",
    ", we choose to present our results in the stated form to emphasize similarity in the theorem statements and proofs .",
    "we loose a constant factor of approximately 2 in the exponent on the r.h.s .",
    "of as compared to for a fixed @xmath182 ( compared using first order approximation of @xmath304 ) .",
    "while this seems to be an artifact of the proof strategy , it is unclear whether a better constant can be obtained for the symmetric bernoulli distribution ( or more generally , for subgaussian distributions  @xcite ) .",
    "indeed , for the proof of  [ lem : gaussian chernoff estimate ] in  [ sec : gaussian chernoff estimate proof ] , we have used the rotational invariance property of the multivariate standard normal distribution .",
    "this property does not carry over to general subgaussian distributions .",
    "we observe that if @xmath144 then @xmath305 and  [ thm : whp_suff_ident ] correctly predicts that the input signals are identifiable with probability one ( in agreement with  [ prop : ident_easy ] ) .",
    "below , we consider example bilinear maps and input distributions with @xmath306 and numerically examine the scaling behavior suggested by  [ lem : markov estimate ] , [ lem : bernoulli chernoff estimate ] and  [ lem : gaussian chernoff estimate ] and  [ thm : whp_suff_ident ] , [ thm : whp_infinite ] and  [ thm : whp_infinite_gaussian ] . since  [ lem : markov estimate ] and  [ thm : whp_suff_ident ] impose only broad constraints on the input distribution , for the purpose of numerical simulations , we construct a specific input distribution that satisfies assumptions  - in  [ sec : dependant but uncorrelated ] .",
    "since this research was motivated by our interest to understand the cone constrained blind deconvolution problem  , our selection of example bilinear maps are closely related to the linear convolution map .",
    "we provide a partial description of the rank two null space for the linear convolution map in  [ sec : null space of linear convolution ] .",
    "a bi - orthogonal set of vectors is a collection of orthonormal vectors and their additive inverses .",
    "it is widely used for signal representation in image processing and as a modulation scheme in communication systems .",
    "we can construct a uniform distribution over a bi - orthogonal set and it would satisfy assumptions  - as shown below .",
    "let @xmath307 be an orthonormal basis for @xmath106 and the random unit vector @xmath308 be drawn according to the law @xmath309 where @xmath53 has the same meaning as in  [ lem : markov estimate ] and  [ thm : whp_suff_ident ] .",
    "let @xmath173 be drawn from a distribution ( independent of @xmath53 ) supported on the non - negative real axis with @xmath310 .",
    "then , by construction , @xmath311 satisfies assumption   and it also satisfies assumption   if @xmath175 and @xmath54 are drawn analogously but independent of @xmath53 and @xmath173 . using , we further observe that @xmath312 and , @twocolumn @xmath313 @xmath314 where the last equality in is true since @xmath307 is an orthonormal basis for @xmath106 . by independence of @xmath173 from @xmath53 we have @xmath315 from , and @xmath316 from .",
    "hence , @xmath6 is a zero mean random vector with an identity covariance matrix and thus satisfies assumption  .    following the same line of reasoning as in  [ rem : bernoulli example ] , we can show that a bi - orthogonally supported uniform prior on @xmath6 and @xmath7 gives an example of the set @xmath19 with small complexity in the sense described in  [ rem : measuring row column space pairs ] .",
    "indeed , we have @xmath317 where @xmath307 and @xmath318 respectively form an orthonormal basis for @xmath106 and @xmath319 .",
    "let us select @xmath129 according to , but without any relaxation , as @xmath320 .",
    "it is clear that matrices in @xmath129 can account for at most @xmath2 distinct column spaces and @xmath3 distinct row spaces , thus implying that matrices in @xmath250 are generated by at most @xmath321 distinct column spaces and by at most @xmath322 distinct row spaces .",
    "thus , @xmath296 is of small complexity ( only polynomially large in @xmath2 and @xmath3 ) .",
    "in fact , _ exhaustive search for   is tractable for any bi - orthogonally supported uniform prior , owing to the small complexity of @xmath19_.      the following proposition establishes a parametric representation of a subset of @xmath147 where @xmath323 denotes the lifted equivalent of the linear convolution map in  . as described by in  [ sec : lifting ] , let @xmath324 , @xmath325 denote a basis for @xmath94 . for @xmath37 , @xmath38 and @xmath325",
    ", we have the description @xmath326  [ fig : lifting example ] illustrates a toy example of the linear convolution map with @xmath327 and @xmath328 .",
    "[ prop : rank-2 nullspace ] if @xmath329 admits a factorization of the form @xmath330 for some @xmath331 and @xmath332 , then @xmath333 .",
    "[ sec : rank-2 null space proposition proof ] .",
    "since the set of @xmath35 dimensional rank two matrices has @xmath334 dof and @xmath94 maps @xmath109 to @xmath335 with @xmath128 , @xmath181 has at most @xmath336 dof .",
    "we see that the representation on the r.h.s .",
    "of also has @xmath337 dof , so that our parametrization is tight up to dof .",
    "the converse of  [ prop : rank-2 nullspace ] is false in general  @xcite .",
    "we test identifiability by ( approximately ) solving the following optimization problem , where @xmath172 is the true matrix and @xmath300 is a tuning parameter .",
    "the rationale behind solving   is as follows . if the sufficient conditions of  [ thm : suff_ident ] are not satisfied , then @xmath338 such that both @xmath339 and @xmath340 are true .",
    "we approximate the event    @xmath341    as   is itself np - hard to solve exactly , we can employ the re - weighted nuclear norm heuristic @xcite to solve   approximately .",
    "if the resulting solution to   has rank two then we declare that event @xmath342 has happened .",
    "clearly , we have @xmath343 so that sufficient conditions for identifiability by  [ thm : suff_ident ] fail if event @xmath342 took place .",
    "the examples we consider in  [ sec : small finite null space ] to [ sec : infinite null space ] are , however , motivated from the representation in and share the same parametrization structure for @xmath147 .",
    "this enables us to use approximate verification techniques that are faster than the re - weighted nuclear norm heuristic , especially if the search space is discrete and finite .",
    "the re - weighted nuclear norm heuristic is still useful if no parametrization structure is available for @xmath147 .",
    "let @xmath344 and @xmath345 be drawn from bi - orthogonally supported uniform distributions , as described in  [ sec : dependant but uncorrelated ] , where @xmath346 and @xmath347 respectively represent the canonical bases for @xmath106 and @xmath319 .",
    "we consider a lifted linear operator @xmath20 with the following description : @xmath19 consists of @xmath348 parts and the @xmath349 part @xmath350 , @xmath351 , @xmath352 is given by @xmath353 where @xmath354 and @xmath355 respectively denote the canonical basis for @xmath356 and @xmath357 , and @xmath358 is the floor function .",
    "clearly , the elements of @xmath350 are closely related to the representation in . for this lifted linear operator ,",
    "the bound of  [ thm : whp_suff_ident ] is applicable with @xmath359 implying that the probability of failure to satisfy the sufficient conditions of  [ thm : suff_ident ] decreases as @xmath360 . since",
    "exhaustive search for event @xmath342 is tractable ( see  [ sec : dependant but uncorrelated ] ) , we employ the same to compute the failure probability .",
    "the results are plotted in  [ fig : example3 ] on a log - log scale .",
    "note that we have plotted the best linear fit for the simulated parameter values , since the probabilities can be locally discontinuous in @xmath361 due to the appearance of @xmath358 function in the expression of @xmath214 .",
    "we see that the simulated order of growth of the failure probability is @xmath362 for every fixed value of @xmath2 ( exponent determined by slope of plot in  [ fig : example3 ] ) almost exactly matches the theoretically predicted order of growth ( equals @xmath363 ) .     with @xmath361 for fixed values of @xmath2 .",
    "the absolute value of the fitted slope is 0.48 . ]",
    "let @xmath206 and @xmath364 be drawn component - wise independently from a symmetric bernoulli distribution ( see  [ rem : bernoulli example ] ) and let @xmath365 be a constant . following our guiding representation , we consider a lifted linear operator @xmath94 with the following description : @xmath147 consists of @xmath366 parts and the @xmath349 part @xmath350 , @xmath367 , @xmath368 , is given by @xmath369 where @xmath370 ( respectively @xmath371 ) denotes the binary representation of @xmath372 ( respectively @xmath373 ) of length @xmath374 bits ( respectively @xmath375 bits ) expressed in the alphabet set @xmath376 , and the all one column vectors in are of appropriate dimensions so that the elements of @xmath350 are matrices in @xmath109 .",
    "the bound in  [ thm : whp_infinite ] is applicable to this example .",
    "we employ exhaustive search for event @xmath342 for small values of @xmath2 and @xmath3 ( it is computationally intractable for large @xmath2 or @xmath3 ) . the results are plotted in  [ fig : example4 ] on a semilog scale , where we have used @xmath377 and @xmath378 and @xmath379 is as in the statement of  [ thm : whp_infinite ] . as in the case of  [ fig : example3 ] , we plot the best linear fit for the simulated parameter values to disregard local discontinuities introduced due to the use of the @xmath358 function .",
    "since it is hard to analytically compute the metric entropies @xmath284 and @xmath380 , we shall settle for a numerical verification of the scaling law with problem dimension and an approximate argument as to the validity of predictions made by  [ thm : whp_infinite ] for this example . by construction",
    ", we have the bounds @xmath381 and @xmath382 but the careful reader will note that because of the element - wise constant magnitude property of a symmetric bernoulli random vector , it does not lie in the column span of any of the matrices in @xmath147 , as described by the generative description in , but can be arbitrarily close to such a span as @xmath2 increases .",
    "we thus expect that @xmath383 and @xmath384 for some parameters @xmath385 and @xmath386 close to zero . by choice of parameters , @xmath387 . with @xmath388 and setting @xmath389 the theoretical prediction on the absolute value of the slope is 0.073 which is quite close to the simulated value of 0.093 .",
    "we clearly recover the linear scaling behavior of the logarithm of failure probability with the problem dimension @xmath3 .     with problem dimension",
    "@xmath3 for fixed values of @xmath2 .",
    "the absolute value of the fitted slopes are between 0.093 and 0.094 . ]",
    "let @xmath206 and @xmath364 be drawn component - wise independently from a standard normal distribution .",
    "we consider the linear convolution operator from  , letting @xmath20 denote the lifted linear convolution map .",
    "a representation of @xmath20 and a description of the rank two null space @xmath181 has been mentioned in the prequel (  [ sec : null space of linear convolution ] ) .",
    "the bound in  [ thm : whp_infinite_gaussian ] is applicable to this example .",
    "however , unlike the examples in  [ sec : small finite null space ] and  [ sec : large finite null space ] , we can not employ exhaustive search over @xmath147 to test identifiability , since the search space is uncountably infinite by  [ prop : rank-2 nullspace ] .",
    "we resort to the method described in  [ sec : verification technique ] relying on the re - weighted nuclear norm heuristic .",
    "the results are plotted in  [ fig : example2 ] on a semilog scale , where we have used @xmath390 to detect the occurrence of the event @xmath342 as described by , and @xmath51 in   is normalized such that @xmath391 .",
    "a relatively high value of @xmath390 is used to ensure that the rare event @xmath342 admits a large enough probability of occurrence .",
    "only data points that satisfy @xmath392 are plotted since the behavior of the convolution operator is symmetric  the order of its inputs . since the re - weighted nuclear norm heuristic",
    "does not always converge monotonically in a small number of steps , we stopped execution after a finite number of steps , which might explain the small deviation from linearity , observed in  [ fig : example2 ] , as compared to the respective best linear fits on the same plot .",
    "nonetheless , we approximately recover the theoretically predicted qualitative linear scaling law of the logarithm of the failure probability with the problem dimension @xmath3 , for fixed values of @xmath2 .",
    "there does not seem to be an easy way of comparing the constants involved in the simulated result to their theoretical counterparts as predicted by  [ thm : whp_infinite_gaussian ] .     for fixed values of @xmath2 , for parameter @xmath390 and the lifted linear convolution map .",
    "the absolute value of the fitted slopes are between 0.94 and 1.08 . ]",
    "bilinear transformations occur in a number of signal processing problems like linear and circular convolution , matrix product , linear mixing of multiple sources , identifiability and signal reconstruction for the corresponding inverse problems are important in practice and identifiability is a precursor to establishing any form of reconstruction guarantee . in the current work , we determined a series of sufficient conditions for identifiability in conic prior constrained bilinear inverse problems ( bips ) and investigated the probability of achieving those conditions under three classes of random input signal ensembles ,  dependent but uncorrelated , independent gaussian , and independent bernoulli .",
    "the theory is _ unified _ in the sense that it is applicable to all bips , and is specifically developed for bilinear maps over vector pairs with non - trivial rank two null space .",
    "universal identifiability is absent for many interesting and important bips owing to the non - triviality of the rank two null space , but a deterministic characterization of the input instance identifiability is still possible ( may be hard to check ) .",
    "our probabilistic results were formulated as scaling laws that trade - off probability of identifiability with the complexity of the restricted rank two null space of the bilinear map in question , and results were derived for three different levels of complexity ,  small ( polynomial in the signal dimension ) , large ( exponential in the signal dimension ) and infinite . in each case",
    ", identifiability can hold with high probability depending on the relative geometry of the null space of the bilinear map and the signal space . overall , most random input instances are identifiable , with the probability of identifiability scaling inversely with the complexity of the rank two null space of the bilinear map .",
    "an especially appealing aspect of our approach is that the rank two null space can be partly or fully characterized for many bilinear problems of interest .",
    "we demonstrated this by partly characterizing the rank two null space of the linear convolution map , and presented numerical verification of the derived scaling laws on examples that were based on variations of the blind deconvolution problem , exploiting the representation of its rank two null space .",
    "overall , the results in this paper indicate that lifting is a powerful technique for identifiability analysis of general cone constrained bips .",
    "suppose that @xmath393 is a solution to   for a given observation @xmath394 .",
    "setting @xmath395 and using we have @xmath396 .",
    "using we get @xmath397 and @xmath398 .",
    "thus , @xmath399 is a feasible point of   with rank at most one .",
    "as there exists a @xmath400 matrix @xmath92 satisfying @xmath112 and @xmath84 , the solution of   must be of rank one or less .",
    "any @xmath401 satisfies @xmath402 ( see proof of first part ) and @xmath112 .",
    "thus , + @twocolumn @xmath403 @xmath404 + where is due to , is due to and is true because   is a feasibility problem .",
    "the feasible set for   is @xmath405 . from the proof of second part",
    ", we know that @twocolumn @xmath406 @xmath407 thus , clearly @xmath408 + we shall prove the contrapositive statement in each direction .",
    "first assume that @xmath120 .",
    "by  , @xmath409 is a feasible point for   and thus @xmath410 is the optimal value for this problem . since every @xmath411 has a rank strictly greater than zero we conclude that @xmath412 .",
    "conversely , suppose that @xmath413 .",
    "since @xmath118 ( see proof of second part ) , @xmath414 such that @xmath415 . by , @xmath416 is a feasible point for   and hence the optimal value of this problem is strictly less than @xmath417 .",
    "the only way for this to be possible is to have @xmath418 and the optimal value of   as zero .",
    "since the only matrix of rank zero is the all zero matrix , we conclude that @xmath419 .",
    "from , and we have @xmath420 we shall prove the contrapositive statements .",
    "first assume that @xmath126 .",
    "using , we have @xmath421 and the last part of  [ thm : equivalence ] implies that @xmath422 . since @xmath423 is nonempty , @xmath424 .",
    "thus ,   and are not equivalent ( equivalence fails for @xmath425 ) .",
    "conversely , suppose that @xmath426 resulting in @xmath427 .",
    "using last part of  [ thm : equivalence ] , we have @xmath428 , which is possible only if @xmath429 . now using we get @xmath126 .",
    "fails if and only if it admits more than one optimal solution .    let @xmath144 and for the sake of contradiction suppose that @xmath430 and @xmath431 denote two solutions to   for some observation @xmath8 , so that @xmath432",
    ". then , @xmath433 so that @xmath434 is in the null space of @xmath45 .",
    "but , @xmath435 so that we have @xmath436 and   has a unique solution .    conversely , let   have a unique solution for every observation @xmath143",
    ". for the sake of contradiction , suppose that there is a matrix @xmath75 in @xmath276 . since @xmath437 , @xmath438 such that @xmath439 .",
    "further , @xmath440 is in the null space of @xmath45 , so that @xmath441 with @xmath442 implying that @xmath443 and @xmath444 are both valid solutions to   for the observation @xmath8 . since @xmath139 , @xmath445 such that @xmath446 and @xmath447 , so that @xmath441 is a valid observation .",
    "this violates the unique solution assumption on   for the valid observation @xmath8 .",
    "hence @xmath144 , completing the proof .",
    "let @xmath448 be a solution to   such that @xmath449 .",
    "since @xmath51 is a valid solution to  , we have @xmath450 and @xmath451 . if @xmath452 , then @xmath453 and @xmath454 .",
    "this contradicts the assumption that at least one of @xmath153 or @xmath154 is true and completes the proof .",
    "we start with the `` if '' part . for @xmath51 to be identifiable , we need @xmath455 for every matrix @xmath456 in the null space of @xmath94 that also satisfies @xmath457 . since @xmath458 , it is sufficient to consider matrices @xmath18 with @xmath459 .",
    "thus , for identifiability of @xmath51 , we need @xmath455 , @xmath460 . using @xmath151 and @xmath158 , we have @xmath461 and @xmath462 and by assumption , we have @xmath159 .",
    "let @xmath160 and @xmath161 , @xmath162 for some @xmath163 with @xmath164 .",
    "it is easy to check that @xmath18 has the following equivalent singular value decompositions , @xmath463 using the representations for @xmath53 and @xmath54 , we have , @xmath464 as the column vectors @xmath161 and @xmath465 on the right hand side of are linearly independent , @xmath466 is possible if and only if every column of @xmath467 combines @xmath53 and @xmath468 in the same ratio .",
    "this means that the row vectors on the r.h.s .  of are scalar multiples of each other .",
    "thus , for @xmath466 it is necessary that    @xmath469    so , @xmath165 implies that @xmath455 . as @xmath158 is arbitrary , @xmath51 is identifiable by  .",
    "next we prove the `` only if '' part .",
    "let @xmath51 be identifiable and @xmath158 so that @xmath467 is feasible for  . as before",
    ", we have @xmath461 , @xmath462 and @xmath159 . if @xmath160 , then @xmath161 , @xmath162 for some @xmath163 with @xmath164 .",
    "it is simple to check that and are valid .",
    "we shall now assume @xmath470 and arrive at a contradiction .",
    "since multiplying a matrix by a nonzero scalar does not change its row or column space and scales every nonzero singular value in the same ratio , we can take @xmath471 without violating any assumptions on @xmath18 .",
    "thus , @xmath472 and we have @xmath473 ( the last implication is due to ) thus contradicting the identifiability of @xmath51 .",
    "using assumption  , we have @xmath474 hence ,    @xmath475    [ eqn : square norm projected estimate ]    where follows from , and are true because @xmath476 and assumption   implies independence of @xmath173 and @xmath53 , is true since @xmath477 for any projection matrix @xmath478 , is true since expectation operator commutes with trace and projection operators , follows from assumption   and , is true since @xmath152 is a matrix of rank at most two .",
    "finally , applying markov inequality to the non - negative random variable @xmath479 and using the computed estimate of @xmath480 from gives @xmath481 we have thus established .",
    "using the exact same sequence of steps for the random vector @xmath54 gives the bound in  .",
    "notice that - in the proof of  [ lem : markov estimate ] in  [ sec : markov estimate lemma proof ] does not use assumption  .",
    "hence , reusing the same arguments we get @xmath482 thus , we have    @twocolumn @xmath483 @xmath484 [ eqn : derivation ]    where is true since @xmath476 , holds because of assumption  , follows from applying markov inequality to the non - negative random variable @xmath485 and , follows from .",
    "thus , the derivation establishes .",
    "using the same sequence of steps for the random vector @xmath54 gives the bound in .",
    "for any constant @xmath215 , let @xmath486 denote the event that @xmath487 satisfying both @xmath488 and @xmath489 . we note that @xmath486 constitutes a non - decreasing sequence of sets as @xmath282 increases .",
    "hence , using continuity of the probability measure from above we have ,    @xmath490    note that @xmath491 denotes the event that @xmath487 satisfying both @xmath492 and @xmath493 which is a `` hard '' event .",
    "the event @xmath494 corresponds precisely to the sufficient conditions of  [ thm : suff_ident ] .",
    "hence , it is sufficient to obtain an appropriate lower bound for @xmath495 to make our desired statement .",
    "drawing inspiration from and , we shall upper bound @xmath496 by @xmath497 .    for",
    "any given @xmath152 we have ,    @xmath498 \\pr\\argd{\\twonorm{\\vec{u } - \\mat{p}_{\\mathcal{c}\\bb{\\mat{x } } } \\vec{u}}^{2 } \\leq \\delta , \\twonorm{\\vec{v } - \\mat{p}_{\\mathcal{r}\\bb{\\mat{x } } } \\vec{v}}^{2 } \\leq \\delta }    \\notag \\\\                  & = \\pr\\argd{\\twonorm{\\vec{u}}^{2 } - \\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{x } } } \\vec{u}}^{2 } \\leq \\delta , \\twonorm{\\vec{v}}^{2 } - \\twonorm{\\mat{p}_{\\mathcal{r}\\bb{\\mat{x } } } \\vec{v}}^{2 } \\leq \\delta } \\label{eqn : orthogonal decomposition } \\\\                  & = \\pr\\argd{\\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{x } } } \\vec{u}}^{2 } \\geq 1 - \\delta , \\twonorm{\\mat{p}_{\\mathcal{r}\\bb{\\mat{x } } } \\vec{v}}^{2 } \\geq 1 - \\delta }   \\label{eqn : unit norm vectors } \\\\                  & = \\pr\\argd{\\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{x } } } \\vec{u}}^{2 } \\geq 1 - \\delta } \\pr\\argd{\\twonorm{\\mat{p}_{\\mathcal{r}\\bb{\\mat{x } } } \\vec{v}}^{2 } \\geq 1 - \\delta } \\label{eqn : by independence } \\\\",
    "& \\leq \\frac{4}{mn \\bb{1 - \\delta}^{2 } } \\label{eqn : from lemma }              \\end{aligned}\\ ] ]    [ eqn : multiplicative estimate ]    where is true because @xmath499 ( respectively @xmath500 ) is the orthogonal projection matrix onto the orthogonal complement space of @xmath26 ( respectively @xmath17 ) , is true because we have @xmath501 , is true by independence of @xmath53 and @xmath54 , and comes from applying  [ lem : markov estimate ] .",
    "next we employ union bounding over all @xmath152 representing distinct pairs of column and row subspaces @xmath502 to upper bound @xmath497 .",
    "we denote the number of these distinct pairs of @xmath502 over @xmath152 by @xmath214 .    finally , using we have    @twocolumn @xmath503 \\pr\\argd{\\mathcal{a}\\argd{\\delta } }",
    "\\notag \\\\                          & \\leq \\sum_{\\bb{\\mathcal{c}\\argd{\\mat{x } } , \\mathcal{r}\\argd{\\mat{x } } } } \\pr\\argd{\\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{x}}^{\\perp } } \\vec{u}}^{2 } \\leq \\delta , \\twonorm{\\mat{p}_{\\mathcal{r}\\bb{\\mat{x}}^{\\perp } } \\vec{v}}^{2 } \\leq \\delta }   \\label{eqn : union bound finite } \\\\                          & = f_{\\mathscr{s } , \\mathcal{m}}\\argd{m , n } \\pr\\argd{\\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{x}}^{\\perp } } \\vec{u}}^{2 } \\leq \\delta , \\twonorm{\\mat{p}_{\\mathcal{r}\\bb{\\mat{x}}^{\\perp } } \\vec{v}}^{2 } \\leq \\delta }    \\notag \\\\                          & \\leq \\frac{4 f_{\\mathscr{s } , \\mathcal{m}}\\argd{m , n}}{mn \\bb{1 - \\delta}^{2 } }   \\label{eqn : lemma 1 result }                      \\end{aligned}\\ ] ] @xmath504 [ eqn : union bound ]    where is an union bounding step .",
    "hence ,    @xmath505    where is from , is from and @xmath506 .",
    "the proof is essentially to that of  [ thm : whp_suff_ident ] in  [ sec : whp_suff_ident theorem proof ] with one important difference : we use  [ lem : markov estimate special ] instead of  [ lem : markov estimate ] when bounding the right hand side of .",
    "this gives us the bound @twocolumn @xmath507 @xmath508 which leads to the bound @xmath509 in place of .",
    "finally ,    @xmath510    where is from , is from and @xmath506 .",
    "this is a chernoff - type bound .",
    "we set @xmath511 and compute the bound @xmath512 that holds for all values of the parameter @xmath513 for which the right hand side of exists . using properties of gaussian random vectors under linear transforms , we have @xmath514 and @xmath515 as statistically independent gaussian random vectors implying @twocolumn @xmath516 @xmath517 with , @xmath518 since @xmath151 , both @xmath26 and @xmath17 are two dimensional spaces .",
    "on rotating coordinates to the basis given by @xmath519 , it can be seen that @xmath520 is the sum of squares of two  standard gaussian random variables and hence has a @xmath521 distribution with two dof . by the same argument",
    ", @xmath522 is a @xmath521 distributed random variable with @xmath523 dof .",
    "recall that the moment generating function of a @xmath521 distributed random variable @xmath204 with @xmath46 dof is given by @xmath524 using , , and we have the bound @twocolumn @xmath525 @xmath526 which can be optimized over @xmath513 .",
    "it can be verified by differentiation that the best bound is obtained for @xmath527 plugging this value of @xmath513 into and using we get the desired result .",
    "this is also a chernoff - type bound .",
    "although the final results of  [ lem : gaussian chernoff estimate ] and  [ lem : bernoulli chernoff estimate ] look quite similar , we can not reuse the manipulations in  [ sec : gaussian chernoff estimate proof ] for this proof and proceed by a slightly different route ( also applicable to other subgaussian distributions ) since the symmetric bernoulli distribution does not share the rotational invariance property of the multivariate standard normal distribution .",
    "let @xmath528 denote an orthonormal basis for @xmath26 and set @xmath529 notice that @xmath530 , so we have    @xmath531    where and utilize elementary union bounds , @xmath532 is a generic unit vector , uses the symmetry of the distribution of @xmath6 about the origin , and is the chernoff bounding step that utilizes the following computation :    @xmath533    where uses independence of elements of @xmath6 , is true because each element of @xmath6 has a symmetric bernoulli distribution , uses the series expansion of the exponential function , follows from @xmath534 and is due to @xmath535 the bound in can be optimized over @xmath513 with the optimum being achieved at @xmath536 plugging this value of @xmath513 into gives the desired result .",
    "consider the norm @xmath537 on @xmath538 defined as @xmath539 for all @xmath540 .",
    "it is clear that @xmath541 is the unit ball @xmath542 of this norm , which is a convex body symmetric about the origin .",
    "hence , using we have the metric entropy of @xmath541  @xmath254 as @xmath543 .",
    "it is clear that @xmath544 , implying that metric entropy of @xmath240  @xmath254 is @xmath241 .",
    "let @xmath545 and @xmath546 be two elements from @xmath240 such that @xmath244 , and let @xmath206 be arbitrary .",
    "then ,    @xmath547    [ eqn : control proj norm diff ]    where is due to @xmath548 , is due to the cauchy - schwartz inequality and the bound @xmath549 as @xmath244 , and is due to the triangle inequality .",
    "since @xmath75 and @xmath550 are interchangeable in the derivation of and @xmath6 is arbitrary , we immediately arrive at .",
    "we follow a proof strategy similar to that of  [ thm : whp_suff_ident ] . for any constant @xmath215 ,",
    "let @xmath551 ( respectively @xmath552 ) denote the event that @xmath487 satisfying , @xmath553 ( respectively @xmath554 ) , and let @xmath486 denote the event that @xmath487 satisfying both @xmath553 and @xmath554 .",
    "we note that @xmath486 constitutes a non - decreasing sequence of sets as @xmath282 increases .",
    "hence , using continuity of the probability measure from above we have ,    @xmath555    note that @xmath491 denotes the event that @xmath487 satisfying both @xmath556 and @xmath557 which is a `` hard '' event .",
    "the event @xmath494 corresponds precisely to the sufficient conditions of  [ thm : suff_ident ] .",
    "hence , it is sufficient to obtain an appropriate lower bound for @xmath495 , or alternatively , upper bound @xmath496 using .",
    "it is straightforward to see that    @xmath558    where is because @xmath486 happens only when @xmath552 and @xmath551 are caused by the same matrix @xmath152 , and is due to mutual independence between @xmath6 and @xmath7 .",
    "we have @xmath6 and @xmath7 drawn component - wise  from a symmetric bernoulli distribution . for any given @xmath559",
    "we have a bound on @xmath560 from  [ lem : bernoulli chernoff estimate ] .",
    "we focus on the union bounding step to compute @xmath561 .",
    "the proof of  [ lem : metric entropy ] assures us that as long as @xmath562 are close enough ,  within the same @xmath254 ball for some @xmath257 , we are guaranteed tight control over @xmath563 for any arbitrary @xmath6 .",
    "in fact , using we have the bound @twocolumn @xmath564 @xmath565 letting @xmath566 denote the center of the @xmath567 @xmath254 ball we have @xmath46 ranging from 1 to @xmath568 .",
    "we thus have @xmath569 upper bounded by    @xmath498 \\sum_{k } \\pr\\argd{\\exists\\mat{y } \\in \\mat{z}_{k } + \\epsilon \\mathcal{d}\\argd{m } , \\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{y } } } \\vec{x } } \\geq \\sqrt{1 - \\delta}\\twonorm{\\vec{x } } }     \\label{eqn : union bounding } \\\\                  & \\leq \\sum_{k } \\pr\\argd{\\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{z}_{k } } } \\vec{x } } \\geq \\bb{\\sqrt{1 - \\delta } - \\sqrt{2}\\epsilon}\\twonorm{\\vec{x } } }    \\label{eqn : pointwise bound}\\\\                  & \\leq \\exp\\bb{p_{c } \\log \\theta\\argd{\\frac{1}{\\epsilon } } } \\pr\\argd{\\twonorm{\\mat{p}_{\\mathcal{c}\\bb{\\mat{z } } } \\vec{x } } \\geq \\sqrt{1 - \\delta'}\\twonorm{\\vec{x } } }    \\label{eqn : intermediate bound } \\\\                  & \\leq 4\\exp\\bb{p_{c } \\log \\theta\\argd{\\frac{1}{\\epsilon } } - \\frac{m\\bb{1 - \\delta'}}{4 } }    \\label{eqn : final bound }              \\end{aligned}\\ ] ]    where is from an elementary union bound , is from , uses @xmath570 with @xmath550 being generic , and is true due to  [ lem : bernoulli chernoff estimate ] .    replicating a similar sequence of steps to bound @xmath571 , one readily obtains the bound @xmath572 with @xmath379 given by .",
    "hence , combining , , and we get @xmath573 which yields the desired bound for @xmath574 when @xmath258 .",
    "we have @xmath6 and @xmath7 drawn component - wise  from a standard gaussian distribution .",
    "the proof is essentially similar to that of  [ thm : whp_infinite ] with one important difference ( beside replacing all occurrences of @xmath299 by @xmath181 and @xmath300 assuming values in @xmath575 ) : we use the bound given by  [ lem : gaussian chernoff estimate ] instead of  [ lem : bernoulli chernoff estimate ] when evaluating @xmath576 in .",
    "this gives us the bounds    @xmath577    where @twocolumn @xmath578 @xmath579 as in , we have @twocolumn @xmath580 @xmath581 which gives the desired bound , since @xmath258 and @xmath582",
    "let @xmath18 admit a factorization as in .",
    "then , @xmath583 and we see that the matrix @xmath584 is obtained by shifting down the elements of the matrix @xmath585 by one unit along the anti diagonals , and then flipping the sign of each element . since the convolution operator @xmath94 sums elements along the anti diagonals ( see  [ fig : lifting example ] for illustration ) , the representation of @xmath18 as in immediately implies that @xmath586 .",
    "since implies that @xmath459 so we have @xmath333 ."
  ],
  "abstract_text": [
    "<S> a number of ill - posed inverse problems in signal processing , like blind deconvolution , matrix factorization , dictionary learning and blind source separation share the common characteristic of being bilinear inverse problems ( bips ) ,  the observation model is a function of two variables and conditioned on one variable being known , the observation is a linear function of the other variable . </S>",
    "<S> a key issue that arises for such inverse problems is that of identifiability ,  whether the observation is sufficient to unambiguously determine the pair of inputs that generated the observation . </S>",
    "<S> identifiability is a key concern for applications like blind equalization in wireless communications and data mining in machine learning . </S>",
    "<S> herein , a unifying and flexible approach to identifiability analysis for general _ conic prior _ constrained bips is presented , exploiting a connection to low - rank matrix recovery via ` lifting ' . </S>",
    "<S> we develop deterministic identifiability conditions on the input signals and examine their satisfiability in practice for three classes of signal distributions ,  dependent but uncorrelated , independent gaussian , and independent bernoulli . in each case </S>",
    "<S> , scaling laws are developed that trade - off probability of robust identifiability with the complexity of the rank two null space . </S>",
    "<S> an added appeal of our approach is that the rank two null space can be partly or fully characterized for many bilinear problems of interest (  blind deconvolution ) . </S>",
    "<S> we present numerical experiments involving variations on the blind deconvolution problem that exploit a characterization of the rank two null space and demonstrate that the scaling laws offer good estimates of identifiability .    </S>",
    "<S> bilinear inverse problems , blind deconvolution , identifiability , rank one matrix recovery </S>"
  ]
}