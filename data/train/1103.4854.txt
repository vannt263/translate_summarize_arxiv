{
  "article_text": [
    "the ability of agents to share information and to coordinate actions and decisions can provide significant practical advantages in real - world searches .",
    "whether the target is a person trapped by an avalanche or a hidden cache of nuclear material , being able to deploy multiple autonomous searchers can be more advantageous and safer than sending human operators .",
    "for example , small autonomous , possibly expendable robots could be utilized in harsh winter climates or on the battlefield .    in some problems , e.g. locating a cellular telephone via the signal strength at several towers , there is often a simple geometrical search strategy , such as triangulation , which works effectively . however , in search problems where the signal is stochastic or no geometrical solution is known , e.g. searching for a weak scent source in a turbulent medium , new methods need to be developed .",
    "this is especially true when designing autonomous and self - repairing algorithms for robotic agents  @xcite .",
    "information theoretical methods provide a promising approach to develop objective functions and search algorithms to fill this gap . in a recent paper ,",
    "vergassola et al . demonstrated that infotaxis , which is motion based on expected information gain , can be a more effective search strategy when the source signal is weak than conventional methods such as moving along the gradient of a chemical concentration  @xcite .",
    "the infotaxis algorithm combines the two competing goals of exploration of possible search moves and exploitation of received signals to guide the searcher in the direction with the highest probability of finding the source  @xcite .    to improve the efficiency of search by using",
    "more than one searcher requires determining under what circumstances a collective ( parallel ) search is better ( faster ) than the independent _ combination _ of the individual searches .",
    "much heuristic work , anecdotally inspired by strategies in social insects and flocking birds  @xcite , has suggested that collective action should be advantageous in searches in real world complex problems , such as foraging , spatial mapping , and navigation .",
    "however , all approaches to date rely on simple heuristics that fail to make explicit the general informational advantages of such strategies .",
    "the simplest extension of infotaxis to collective searches is to have multiple _ independent _ ( uncoordinated ) searchers that share information ; this corresponds in general to a linear increase in performance with the number of searchers . however , given some general knowledge about the structure of the search , substantial increases in the search performance of a collective of agents can be achieved , often leading to exponential reduction in the search effort , in terms of time , energy or number of steps  @xcite . in this work",
    "we explore how the concept of information synergy can be leveraged to improve infotaxis of multiple coordinated searchers .",
    "synergy corresponds to the general situation when measuring two or more variables _ together _ with respect to another ( the target s signal ) results in a greater information gain than the sum of that from each variable _ separately _  @xcite .",
    "we identify the types of spatial search problems for which coordination among multiple searchers is effective ( synergetic ) , as well as when it is ineffective , and corresponds to independence .",
    "we find that classes of statistical sources , such as those that emit uncorrelated signals ( e.g. poisson processes ) provide no opportunity for synergetic coordination . on the other hand , sources that emit particles with spatial , temporal , or categorical correlations ,",
    "do allow for strong synergy between searchers that can be exploited via coordinated motion .",
    "these considerations divide collective search problems into different general classes and are crucial for designing effective algorithms for particular applications .",
    "effective and robust search methods for the location of stochastic sources must balance the competing strategies of exploration and exploitation  @xcite . on the one hand , searchers must exploit measured cues to guide their optimal next move . on the other hand , because this information is statistical , more measurements need to typically be made that are guided by different search scenarios . information theory approaches to search",
    "achieve this balance by utilizing movement strategies that increase the expected information gain , which in turn is a functional of the many possible source locations . in this section",
    "we define the necessary formalism and use it to set up the general structure of the stochastic search problem .",
    "first we define the concepts of information , synergy and redundancy explicitly .",
    "consider the stochastic variables @xmath0 .",
    "each variable @xmath1 can take on specific states , denoted by the corresponding lowercase letter , that is @xmath2 can take on a set of states @xmath3 . for a single variable @xmath2",
    "the shannon entropy ( henceforth `` entropy '' ) is @xmath4 , where @xmath5 is the probability that the variable @xmath2 take on the value",
    "@xmath6  @xcite .",
    "the entropy is a measure of uncertainty about the state of @xmath2 , therefore entropy can only decrease or remain unchanged as more variables are measured .",
    "the conditional entropy of a variable @xmath7 given a second variable @xmath8 is @xmath9 .",
    "the mutual information between two variables , which plays an important role in search strategy , is defined as the change in entropy when a variable is measured @xmath10 .",
    "these definitions can be directly extended to multiple variables . for 3 variables ,",
    "we make the following definition  @xcite : @xmath11 .",
    "this quantity measures the degree of `` overlap '' in the information contained in variables @xmath12 and @xmath13 with respect to @xmath14 .",
    "if @xmath15 , there is overlap and @xmath12 and @xmath13 are said to be redundant with respect to @xmath14 . if @xmath16 , more information is available when these variables are considered together than when considered separately . in this case @xmath12 and @xmath13 are said to be synergetic with respect to @xmath14 . if @xmath17 , @xmath12 and @xmath13 are independent  @xcite .",
    "we now formulate the two - dimensional stochastic search problem .",
    "we consider , for simplicity , the case of two searchers seeking to find a stochastic source located in a finite two - dimensional plane .",
    "this is a generalization of the single searcher formalism presented in ref .",
    "@xcite . at any time step ,",
    "the searchers have positions @xmath18 and observe some number of particles @xmath19 from the source .",
    "the searchers do not get information about the trajectories or speed of the particles ; they only get information if a particle was observed or not . therefore simple geometrical methods such as triangulation are not possible .",
    "let the variable @xmath20 correspond to all the possible locations of the source @xmath21 .",
    "the searchers compute and share a probability distribution @xmath22 for the source at each time index @xmath23 .",
    "initially the probability for the source is assumed to be to be uniform .",
    "after each measurement @xmath24 , the searchers update their estimated probability distribution of source positions via bayesian inference .",
    "first the conditional probability @xmath25 , is calculated , where @xmath26 is a normalization over all possible source locations as required by bayesian inference .",
    "this is then assimilated via bayesian update so that @xmath27 .",
    "if the searchers do not find the source at their present locations they choose the next local move using an infotaxis step to maximize the expected information gain . to describe the infotaxis step we first need some definitions .",
    "the entropy of the distribution @xmath22 at time @xmath23 is defined as @xmath28 . in terms of a specific measurement @xmath24",
    "the entropy is ( _ before _ the bayesian update ) @xmath29 .",
    "we define the difference between the entropy at time @xmath23 and the entropy at time @xmath30 after a measurement @xmath24 to be @xmath31 .",
    "initially the entropy is at its maximum for a uniform prior : @xmath32 , where @xmath33 is the number of possible locations for the source in a discrete space . for each possible joint move @xmath34 ,",
    "the change in expected entropy @xmath35 is computed and the move with the minimum ( most negative ) @xmath35 is executed .",
    "the expected entropy is computed by considering the reduction in entropy for all of the possible joint moves    @xmath36 s{^{(t)}}(r_{0}){\\nonumber\\\\}&+ \\biggl[1 - \\sum_{i}p{^{(t)}}(r_{0}=r_{i})\\biggr ]      \\delta s{^{(t+1)}}_{\\{h_{i},r_{i}\\}}{\\nonumber\\\\}&\\times \\sum _ { h_{1 } , h_{2 } }       \\biggl[\\sum_{r_{0 } } p{^{(t)}}(r_{0})p{^{(t+1)}}(\\{h_{i},r_{i}\\}|r_{0})\\biggr ] .",
    "\\label{eq : deltasbar}\\end{aligned}\\ ] ]    the first term in eq",
    ".   corresponds to one of the searchers finding the source in the next time step ( the final entropy will be @xmath37 so @xmath38 ) .",
    "the second term considers the reduction in entropy for all possible measurements at the proposed location , weighted by the probability of each of those measurements .",
    "the probability of the searchers obtaining the measurement @xmath19 at the location @xmath34 is given by the trace of the probability @xmath39 over all possible source locations .",
    "the expected entropy reduction @xmath35 is calculated for _ joint _ moves of the searchers , that is , all possible combinations of individual moves . compared with multiple independent searchers this calculation incurs some extra computational cost .",
    "thus , when designing a search algorithm , it is important to know whether an advantage ( synergy ) can be gained by considering joint moves instead of individual moves .",
    "since the search is based on optimizing the maximum information gain we need to explore if joint moves are synergetic or redundant . in this section",
    "we will show how correlations in the source affect the synergy and redundancy of the search .",
    "in the following we will assume there are no radial correlations between particles emitted from the source and that the probability of detecting particles decays with distance to the source .",
    "for each particle emitted from the source , the searcher @xmath40 has an associated actual probability @xmath41 of catching the particle . the probability @xmath41 is defined in terms of a possible source location @xmath21 and the location @xmath42 of searcher @xmath40 : @xmath43 , where @xmath34 is the set of all the searcher positions and @xmath44 is a normalization constant . note",
    "that this is just the radial component of the probability ; if there are angular correlations these are treated separately .",
    "we may now write @xmath45 , as a function of the variables @xmath20 , @xmath46 , and @xmath47 , in terms of the conditional probabilities : @xmath48 it is sufficient for @xmath49 that the argument of the logarithm differs from @xmath50 .",
    "this can be achieved even if measurements are conditionally independent ( redundancy ) , mutually independent ( synergy ) , or when neither of these conditions apply .",
    "first , consider a source which emits particles according to a poisson process with known mean @xmath51 so emitted particles are completely uncorrelated spatially and temporally . if searcher 1 is able to get a particle that has already been detected by searcher 2 , it is clear that the searchers are completely independent and there is no chance of synergy .",
    "it may appear at first that implementing a simple exclusion where two searchers can not get the same particle would be enough to foster cooperation between searchers .",
    "we will instead show that it is the poisson nature of the source that makes synergy impossible , even under mutual exclusion of the measurements .",
    "the probability of the measurement @xmath19 is given by @xmath52 the sum is over all possible values of @xmath53 , weighted by the poisson probability mass function with the known mean @xmath51 .",
    "@xmath54 is the probability mass function of the multinomial distribution for that measurement ; it handles the combinatorial degeneracy and the exclusion .",
    "it is not difficult to show by summing over @xmath53 that @xmath55 can be written as a product of poisson distributions with effective means @xmath56 , @xmath57 at this point we consider whether a search like this can be synergetic for the 2 searcher case .",
    ".   shows that the two measurements are conditionally independent and therefore @xmath58 .",
    "it follows from eq .   that @xmath59 @xmath60 . therefore the searchers are either redundant ( if the measurements interfere with each other ) or independent with respect to the source .",
    "synergy is impossible so that searchers gain no advantage by considering joint moves .",
    "the only advantage of coordination comes possibly from avoiding positions that lead to a decrease in performance of the collective due to competition for the same signal .",
    "we now consider a source that emits particles that are spatially correlated .",
    "we assume for simplicity that at each time step the source emits 2 particles .",
    "the first particle is emitted at a random angle @xmath61 chosen uniformly from @xmath62 .",
    "the second particle is emitted at an angle @xmath63 with probability @xmath64 } \\equiv f , \\label{eq : fdefn}\\ ] ] where @xmath65 is a normalization factor .",
    "the searchers are assumed to know the variance @xmath66 for simplicity ; this is a reasonable assumption if the searchers have any information about the nature of the target ( just as for the poisson source they had statistical knowledge of the parameter @xmath51 ) .",
    "the calculation of the conditional probability @xmath55 requires some care . specifically , this quantity is the probability of the measurement @xmath19 , assuming a certain source position .",
    "since there are 2 particles emitted at each time step , there are 4 possible cases , each with a different probability , as shown in table  [ tab : pth1th2 ] . here",
    "@xmath61 and @xmath63 are calculated from @xmath67 and @xmath68 , respectively : @xmath69 .",
    "note that the @xmath70 are functions of @xmath21 .",
    "the coefficient @xmath65 is chosen such that @xmath71 , corresponding to the normalization condition @xmath72 .    [",
    "cols=\"^,^,^,^,^\",options=\"header \" , ]     figure  [ fig : rh1h2r0 ] shows the value of @xmath59 and the values of the mutual informations @xmath73 and @xmath74 for each possible position @xmath75 of searcher 2 .",
    "we assume a nonuniform , peaked probability distribution for the source [ figure  [ fig : rh1h2r0](b ) ] and that the position of searcher 1 is fixed . in this setup",
    "we see that @xmath76 for every possible position of searcher 2 indicating that only synergy is possible .",
    "this is a consequence of the angular spatial correlation between the particles emitted by the source .",
    "the synergy is highest near the source location , where the source probability is strongly peaked , and falls off rapidly away from the source location .",
    "furthermore there is little to no synergy near searcher 1 since in that region it is very unlikely that both searchers would simultaneously observe a particle .",
    "the area of greatest synergy corresponds to the most probable source locations for both searchers to simultaneously observe a particle .",
    "@xmath77 is very flat at the boundaries ; thus @xmath20 contributes little to @xmath78 in the lower left corner and @xmath45 is small .",
    "in the real world , communication between agents , as well as centralized or decentralized real - time computation can be difficult or expensive .",
    "therefore it is important to consider the classes of search problems for which coordination between searchers can achieve quantitative advantages over independent agents . in this work we studied search algorithms for autonomous agents looking for the spatial location of a stochastic source .",
    "we defined the search problem for multiple agents in terms of infotaxis [ see eq .  ] .",
    "we also showed why synergy gives rise to an advantage in this type of search .",
    "we considered two types of sources .",
    "we first demonstrated that a source emitting uncorrelated particles will afford no opportunity for synergy ( see section  [ sec : poisson ] ) . in a search for a poisson source , multiple coordinated searchers ( ones that consider sets of joint moves rather than each considering an independent move ) can not hope to do better than multiple independent searchers .",
    "next we showed that , for a source emitting particles with ( angular ) correlations ( see section  [ sec : angular ] ) , only synergy or independence is possible ( see fig .  [",
    "fig : rh1h2r0 ] ) .",
    "the ability of the searchers to leverage synergy depends strongly on their ability to estimate with some accuracy the probability distribution of source locations .",
    "these general considerations are crucial for the exploitation of social computation in terms of the design of optimal collective algorithms in particular applications .",
    "the next step to making this approach applicable to a broader class of problems , including those not limited to spatial searches , is to generalize the results to more than 2 searchers and to explore how synergy may be best leveraged to give increases in search speed and efficiency ."
  ],
  "abstract_text": [
    "<S> social computation , whether in the form of searches performed by swarms of agents or collective predictions of markets , often supplies remarkably good solutions to complex problems . in many examples , </S>",
    "<S> individuals trying to solve a problem locally can aggregate their information and work together to arrive at a superior global solution . </S>",
    "<S> this suggests that there may be general principles of information aggregation and coordination that can transcend particular applications . </S>",
    "<S> here we show that the general structure of this problem can be cast in terms of information theory and derive mathematical conditions that lead to optimal multi - agent searches . </S>",
    "<S> specifically , we illustrate the problem in terms of local search algorithms for autonomous agents looking for the spatial location of a stochastic source . </S>",
    "<S> we explore the types of search problems , defined in terms of the statistical properties of the source and the nature of measurements at each agent , for which coordination among multiple searchers yields an advantage beyond that gained by having the same number of independent searchers . </S>",
    "<S> we show that effective coordination corresponds to synergy and that ineffective coordination corresponds to independence as defined using information theory . </S>",
    "<S> we classify explicit types of sources in terms of their potential for synergy . </S>",
    "<S> we show that sources that emit uncorrelated signals provide no opportunity for synergetic coordination while sources that emit signals that are correlated in some way , do allow for strong synergy between searchers . </S>",
    "<S> these general considerations are crucial for designing optimal algorithms for particular search problems in real world settings . </S>"
  ]
}