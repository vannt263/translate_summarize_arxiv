{
  "article_text": [
    "recently , general purpose computing on graphics processing units ( gpgpu ) has acquired considerable momentum in the scientific community .",
    "this is confirmed both by increasing numbers of gpgpu - related publications and gpu - based supercomputers in the top500 ] list .",
    "major programming frameworks are nvidia cuda and opencl .",
    "the former is a proprietary parallel computing architecture developed by nvidia for general purpose computing on nvidia graphics adapters , and the latter is an open , royalty - free standard for cross - platform , parallel programming of modern processors and gpus maintained by the khronos group . by nature , the two frameworks have their distinctive pros and cons .",
    "cuda has a more mature programming environment with a larger set of scientific libraries , but is available for nvidia hardware only .",
    "opencl is supported on a wide range of hardware , but its native api requires a much larger amount of boilerplate code from the developer . another problem with opencl is that it is generally difficult to achieve performance portability across different hardware architectures .",
    "both technologies are able to provide scientists with the vast computational resources of modern gpus at the price of a steep learning curve .",
    "programmers need to familiarize themselves with a new programming language and , more importantly , with a new programming paradigm .",
    "however , the entry barrier may be lowered with the help of specialized libraries .",
    "the cuda toolkit includes several such libraries ( blas implementations , fast fourier transform , thrust and others ) .",
    "opencl lacks standard libraries , but there are a number of third - party projects aimed at developing both cuda and opencl programs .",
    "this paper presents a comparison of several modern clibraries aimed at ease of gpgpu development .",
    "we look at both convenience and performance of the libraries under consideration in the context of solving ordinary differential equations .",
    "the comparison is based on odeint ] , a modern clibrary for solving ordinary differential equations ( odes ) numerically @xcite which has been included into the boost libraries ] recently .",
    "it is developed in a generic way using template meta - programming techniques , which leads to extraordinary high flexibility at utmost performance .",
    "the numerical algorithms are implemented independently of the underlying arithmetics .",
    "this results in a broad applicability of the library , especially in non - standard environments .",
    "for example , odeint supports matrix types , arbitrary precision arithmetics , and can be easily adapted to use either cuda or opencl frameworks .",
    "the gpgpu libraries considered in this work are mtl4 , vexcl , and viennacl .",
    "we also employ thrust ] in order to provide a reference point for the comparison of the considered libraries .",
    "thrust is a parallel algorithms library which resembles the cstandard template library @xcite .",
    "its high - level interface greatly enhances developer productivity while enabling performance portability between gpus and multi - core cpus .",
    "thrust is distributed with the nvidia cuda toolkit since version  4.1 .",
    "mtl4 : :    ( the matrix template library ) ] is a clinear algebra library providing an intuitive    interface by establishing a domain - specific language embedded in    c  @xcite .",
    "the library aims for maximal performance achievable by    high - level languages using compile - time transformations .",
    "currently ,    three versions exist : the open - source edition supporting single- and    multi - core cpus , the supercomputing edition providing generic    mpi - based parallelism , and the cuda edition introduced in this paper .    in the following , we will refer to the cuda version of mtl4 as cmtl4 .",
    "vexcl : :    is a vector expression template    library ] for opencl @xcite .",
    "it has been    created for ease of opencl development with c. vexcl strives to reduce    the amount of boilerplate code needed to develop opencl applications .",
    "the library provides a convenient and intuitive notation for vector    arithmetic , reduction , sparse matrix - vector multiplication , etc .",
    "multi - device and even multi - platform computations are supported .",
    "viennacl : :    ( the vienna computing library ) is a scientific computing    library ] written in c@xcite .",
    "cuda and    openmp compute backends were added recently , but only the initial    opencl backend is considered in the remainder of this work . the    programming interface is compatible with    boost.ublas ] and allows for simple ,    high - level access to the vast computing resources available on    parallel architectures such as gpus .",
    "the library s primary focus is on    common linear algebra operations ( blas levels 1 , 2 and 3 ) and the    solution of large sparse systems of equations by means of iterative    methods with optional preconditioners .",
    "cuda and opencl differ in their handling of compute kernels compilation . in nvidia",
    "s framework the compute kernels are compiled to ptx code together with the host program .",
    "ptx is a pseudo - assembler language which is compiled at runtime for the specific nvidia device the kernel is launched on . since ptx is already very low - level , this just - in - time kernel compilation has low overhead . in opencl",
    "the compute kernels are compiled at runtime from higher - level c - like sources , adding an overhead which is particularly noticeable for smaller sized problems .",
    "a portable pre - compilation to some low - level pseudo - code as in cuda is not feasible in opencl because of hardware agnosticism by design .",
    "the approach taken for the generation and compilation of the compute kernels is one of the main differences between the opencl libraries we considered .",
    "vexcl generates and compiles an opencl program with a single kernel for each vector expression it encounters .",
    "this leads to potentially higher initialization overhead , but should prove to be more effective in long runs . on the other hand , viennacl uses a set of predefined kernels , which functionally overlaps with blas level 1 routines for vector operations .",
    "these kernels are compiled in batch at the program start to allow for faster initialization . however , due to this design decision , vector expressions with several operands may result in the launch of more than one kernel .",
    "it should be noted that because of the main focus of viennacl being on iterative solvers for large sparse systems of equations , where complex vector expressions are rare , predefined kernels are favorable in such a setting .",
    "the other difference between cuda and opencl is that cuda supports a subset of the clanguage in compute kernels , while opencl kernels are written in a subset of c99 .",
    "therefore , cuda programmers may use template meta - programming techniques which may lead to more efficient and compact code .",
    "the native opencl api does not provide such features , but the drawback is balanced by the ability of kernel source generation during runtime .",
    "modern clibraries such as those considered in this work successfully use this approach and hide low - level details from their users .",
    "ordinary differential equations play a major role in many scientific disciplines .",
    "they occur naturally in the context of mechanical systems , like granular @xcite and molecular dynamics .",
    "in fact , the newtonian and hamiltonian mechanics are formulated as odes @xcite .",
    "many other applications can be found in such diverse fields as biology @xcite , neuroscience @xcite , chemistry @xcite , and social sciences @xcite .",
    "furthermore , odes are also encountered in the context of the numerical solution of non - stationary partial differential equations ( pdes ) , where they occur after a discretization of the spatial coordinates @xcite .",
    "odeint solves the initial value problem ( ivp ) of ordinary differential equations given by @xmath0 here , @xmath1 is the dependent variable and is usually a vector of real or complex values .",
    "@xmath2  is the independent variable .",
    "we will refer to @xmath2 as the time throughout the article and denote the time derivative with @xmath3 .",
    "@xmath4 is the system function and defines the ode .",
    "typical use cases for solving odes on gpus are large systems of coupled odes which occur as discretizations of pdes , or odes defined on lattices or graphs .",
    "another use case are parameter studies , where the dependence of an ode on some parameters is of interest . here",
    ", a high - dimensional ode consisting of many low - dimensional uncoupled odes , each with a different parameter set , is considered .",
    "this one large system is then solved at once , hence all low - dimensional odes are solved simultaneously .",
    "numerous methods for solving odes exist @xcite , which are usually categorized in the field of numerical analysis .",
    "odeint implements the most prominent of these methods , for example the classical runge - kutta methods and runge - kutta - fehlberg methods , multi - step methods ( adams - bashforth - moulton ) , symplectic runge - kutta - nystrm methods , and implicit methods ( rosenbrock and implicit euler ) .",
    "all of these methods work iteratively , starting from a given initial value @xmath5 to calculate the next value @xmath6 .",
    "@xmath7 is the step size and may be chosen either statically or adaptively . for reference",
    ", we note that the simplest method is the explicit euler scheme @xmath8 its global accuracy is of first order , but the scheme is usually not used for real applications because of stability and accuracy issues .",
    "one main feature of odeint is the decoupling of the specific algorithm for solving the ode from the underlying arithmetic operations .",
    "this is achieved by a combination of a state type , an algebra , and operations .",
    "the state type represents the state of the ode being solved and is usually a vector type like ` std::vector < > ` , ` std::array < > ` , or a vector residing on a gpu .",
    "the algebra is responsible for iterating through all elements of the state , whereas the operations are responsible for the elementary operations .    to see how the explicit euler method ( [ eq : euler ] ) is translated to code in odeint",
    ", we briefly discuss its implementation :    .... template < class state , class algebra , class operations > class euler {      // ...      template < class ode >      void do_step(ode ode , state & x , time_type t , time_type dt ) {          ode(x , m_dxdt , dt ) ;          algebra::for_each3 ( x , x , m_dxdt , operations::scale_sum2(1.0 , dt ) ) ;      } } ; ....    the state type , the algebra , and the operations enter the euler method as template parameters , hence they are exchangeable .",
    "the function object ` ode ` represents the ode and must be provided by the user .",
    "it calculates the right hand side @xmath4 of ( [ eq : ode ] ) and stores the result in ` m_dxdt ` .",
    "the call of ` for_each3 ` iterates simultaneously over all elements of three vectors and applies ` scale_sum2 ` to each triple .",
    "the operation is performed in - place , meaning that @xmath1 is updated to the new value . in the code - snippet above , the call to ` for_each3 ` is thus equivalent to the vector operation    ....   x = 1.0 * x + dt * m_dxdt ....    which is just eq .",
    "( [ eq : euler ] ) , since ` m_dxdt ` holds the values of @xmath9 .",
    "an odeint algebra is a class consisting of ` for_each1 ` ,  , ` for_eachn ` methods .",
    "for example , the ` for_each3 ` method in the ` range_algebra `  the default algebra for most vector types  is similar to    .... struct range_algebra {      // ...",
    "template < class r1 , class r2 , class r3 , class op >      void for_each3(r1 & r1 , r2 & r2 , r3 & r3 , op op ) {          auto it1 = boost::begin(r1 ) ;          auto it2 = boost::begin(r2 ) ;          auto it3 = boost::begin(r3 ) ;          while ( it1 ! = boost::end(r1 ) ) op(*it1++ , * it2++ ; * it3++ ) ;      }      // ... } ; ....    the operations are represented by a struct with public member classes defining the operations used by the algebras .",
    "there is only one default operations class implementation in odeint , which uses the arithmetic operators as usual :    .... struct default_operations {      // ...      template < class fac1 , class fac2 >      struct scale_sum2 {          fac1 m_fac1 ;          fac2 m_fac2 ;          scale_sum2 ( fac1 fac1 , fac2 fac2 ) : m_fac1(fac1 ) , m_fac2(fac2 ) { }          template < class s1 , class s2 , class s3 >          void operator ( ) ( s1 & s1 , const s2 & s2 , const s3 & s3 ) const {              s1 = m_fac1 * s2 + m_fac2 * s3 ;          }      } ;      // ... } ; ....",
    "the main reason for the separation of algebra and operations is that all arithmetic calculations and iterations are completely encapsulated into the algebra and the operations .",
    "therefore , the numerical algorithms to solve the odes are independent from the underlying arithmetics .",
    "note that the algebra and the operations must be chosen such that they interact correctly with the state type .",
    "many libraries for vector and matrix types provide expression templates @xcite for the elementary operations using operator overload convenience .",
    "such libraries do not need to define their own algebra , but can instead be used with a default algebra and a default operation set included in odeint , which simply call the operations directly on the matrix or vector type .",
    "we describe the adaptation of odeint for the gpgpu libraries under consideration in the following .",
    "the adaptations are now part of odeint , thus native support for these libraries is available .",
    "implementation details such as the resizing of vectors is accomplished in a straight - forward manner and not further addressed for the sake of conciseness .    to adapt thrust to odeint",
    ", we need to provide both an algebra and operations .",
    "the algebra needs to define the ` for_each ` family of algorithms .",
    "all of these operations follow the same pattern , so we consider ` for_each3 ` only :    .... struct thrust_algebra {      template < class statetype1 , class statetype2 , class statetype3 , class op >      static void for_each3(statetype1 & s1 , statetype2 & s2 , statetype3 & s3 , op op ) {          thrust::for_each (                  thrust::make_zip_iterator ( thrust::make_tuple (                      s1.begin ( ) , s2.begin ( ) , s3.begin ( ) ) ) ,                  thrust::make_zip_iterator ( thrust::make_tuple (                      s1.end ( ) , s2.end ( ) , s3.end ( ) ) ) ,                  op ) ;      } } ; ....    here , ` thrust::make_zip_iterator ` is used in combination with ` make_tuple ` to pack several device vector iterators into a single iterable sequence .",
    "the sequence is then processed by the ` thrust::for_each ` algorithm , applying the function object ` op ` to each entry .",
    "the operations called via the function object ` op ` are defined in ` thrust_operations ` and are actually function objects executed on the respective cuda device :    .... struct thrust_operations {      template < class fac1 = double , class fac2 = fac1 >      struct scale_sum2 {          const fac1 m_alpha1 ;          const fac2 m_alpha2 ;            scale_sum2(const fac1 alpha1 , const fac2 alpha2 )              : m_alpha1(alpha1 ) , m_alpha2(alpha2 ) { }            template < class tuple >          _ _ host _ _ _ _ device _ _ void operator ( ) ( tuple t ) const {              thrust::get<0>(t ) = m_alpha1 * thrust::get<1>(t )                                 + m_alpha2 * thrust::get<2>(t ) ;          }      } ; } ; ....    the device function object uses ` thrust::get < > ` functions to unpack the zip iterator into separate values .",
    "this approach is heavily used with thrust and allows to process several vectors in a single efficient sweep .",
    "cmtl4 , vexcl , and viennacl libraries provide convenient expression templates that may be directly used with odeint s ` vector_space_algebra ` and ` default_operations ` .",
    "this combination proved to be effective with cmtl4 and vexcl , where each expression results in a single kernel .",
    "for viennacl , however , default operations involving more than two terms result in multiple kernel launches . moreover , temporary vectors are allocated and deallocated for each of such composite operations , resulting in a dramatic decrease of performance .",
    "to address such problems , viennacl provides a kernel generator @xcite , which is able to generate specialized operations for viennacl .",
    "for example , the ` scale_sum2 ` operation is defined as :    .... struct viennacl_operations {      template < class fac1 = double , class fac2 = fac1 >      struct scale_sum2 {          // ...          template < class t1 , class t2 , class t3 >          void operator ( ) ( viennacl::vector < t1 > & v1 ,                      const viennacl::vector < t2 > & v2 ,                      const viennacl::vector",
    "< t3 > & v3 ) const          {              typedef viennacl::generator::vector < t1 > vec ;                viennacl::generator::custom_operation op ;              op.add ( vec(v1 ) = m_alpha1 * vec(v2 ) + m_alpha2 * vec(v3 ) ) ;              op.execute ( ) ;          }      } ; } ; ....    here , a custom opencl kernel is automatically generated from symbolic vector expression in the first call of the ` operator ( ) ` and then buffered and reused for all subsequent calls .",
    "the objects of type ` vec ` are used to distinguish direct viennacl statements from symbolic specifications for the kernel generation facility .",
    "as shown in the previous section , all four gpgpu libraries considered in our comparison could be adapted to odeint without getting in contact with low - level cuda or opencl code .",
    "the purpose of this section is to evaluate the performance of the gpgpu libraries and whether there is a price to pay for the high - level interface .      in the first example we consider the lorenz system @xcite .",
    "the lorenz system is a system of three coupled odes which shows chaotic behavior for a large range of parameters .",
    "it is one of the most frequently used odes for evaluation purposes in the nonlinear dynamics community .",
    "the equations for the lorenz system read @xmath10    solutions of the lorenz system usually furnish very interesting behavior in dependence on one of its parameters .",
    "for example , one might want to study the chaoticity in dependence on the parameter @xmath11 .",
    "therefore , one would create a large set of lorenz systems ( each with a different parameter @xmath11 ) , pack them all into one system and solve them simultaneously . in a real study of chaoticity one",
    "may also calculate the lyapunov exponents @xcite , which requires to solve the lorenz system and their linear perturbations .    the thrust version of the system function object for the lorenz attractor ensemble example is presented below .",
    "it holds the model parameters and provides the necessary ` operator ( ) ` with a signature required by the odeint library .",
    "the state type is represented by ` thrust::device_vector < double > ` :    .... typedef thrust::device_vector < double > state_type ;    struct lorenz_system {      size_t n ;      const state_type & r ;      lorenz_system(size_t n , const state_type & r ) : n(n ) , r(r ) { }      void operator()(const state_type & x , state_type & dxdt , double t ) const ; } ; ....    the @xmath12 , @xmath13 , and @xmath14 components of the state are held in the continuous partitions of the vector . ` operator ( ) `",
    "uses the standard technique of packing the state components into a zip iterator and passes the composite sequence to the ` thrust::for_each ` algorithm together with the provided device function object :    .... struct lorenz_functor ;    void lorenz_system::operator()(const state_type & x , state_type & dxdt , double t ) const {          thrust::for_each (                  thrust::make_zip_iterator ( thrust::make_tuple (                          r.begin ( ) ,                          x.begin ( ) , x.begin ( ) + n , x.begin ( ) + 2 * n ,                          dxdt.begin ( ) , dxdt.begin ( ) + n , dxdt.begin ( ) + 2 * n ) ) ,                  thrust::make_zip_iterator ( thrust::make_tuple (                          r.end ( ) ,                          x.begin ( ) + n , x.begin ( ) + 2 * n , x.end ( ) ,                          dxdt.begin ( ) + n , dxdt.begin ( ) + 2 * n , dxdt.end ( ) ) ) ,                  lorenz_functor ( ) ) ; } ....    the device function object unpacks the individual components and applies the required operations to the derivative part , essentially leading to a one - to - one translation of ( [ eq : lorenz ] ) into code :    .... struct lorenz_functor {      template <",
    "class t >      _ _ host _ _ _ _ device",
    "_ _ void operator ( ) ( t t ) const {          double r = thrust::get<0>(t ) ;          double x = thrust::get<1>(t ) ;          double y = thrust::get<2>(t ) ;          double z = thrust::get<3>(t ) ;          thrust::get<4>(t ) = sigma * ( y - x ) ;          thrust::get<5>(t ) = r * x - y - x * z ;          thrust::get<6>(t ) = -b * z + x * y ;      } } ; ....    the system function object for the cmtl4 version of the lorenz attractor example is more compact than the thrust variant because cmtl4 supports a rich set of vector expressions .",
    "cmtl4 provides the type ` multi_vector ` that allows for expressing the operations directly :    .... typedef mtl::dense_vector < double >       vector_type ; typedef mtl::multi_vector < vector_type > state_type ;    struct lorenz_system {      const vector_type & r ;      explicit lorenz_system(const vector_type & r ) : r(r ) { }        void operator()(const state_type & x , state_type & dxdt , double t ) {      dxdt.at(0 ) = sigma * ( x.at(1 ) - x.at(0 ) ) ;      dxdt.at(1 ) = r * x.at(0 ) - x.at(1 ) - x.at(0 ) * x.at(2 ) ;      dxdt.at(2 ) = x.at(0 ) * x.at(1 ) - b * x.at(2 ) ;      } } ; ....    in this context , the class ` multi_vector ` is used in two ways : expressing operations on sub - vectors and on entire vectors . each operation on sub - vectors of ` x ` and ` dxdt ` causes a kernel call .",
    "there is potential for optimization when the three operations are performed by one kernel .",
    "this can be achieved with the following formulation :    ....      ( lazy(dxdt.at(0 ) ) = sigma * ( x.at(1 ) - x.at(0 ) ) ) ||      ( lazy(dxdt.at(1 ) ) = r * x.at(0 ) - x.at(1 ) - x.at(0 ) * x.at(2 ) ) ||      ( lazy(dxdt.at(2 ) ) = x.at(0 ) * x.at(1 ) - b * x.at(2 ) ) ; ....    the vector assignments are not performed immediately but their evaluation is delayed and can be fused with other expressions   denoted by operator ` || ` .",
    "this formulation has yet another advantage : the three vector operations are performed in one single loop which provides much better data locality for vector ` x ` . for performance sake ,",
    "the multi - vectors are constructed with contiguous memory whenever the types allow for it .",
    "then , expressions on multi - vectors can be evaluated with one kernel call . especially for small vectors ,",
    "the overhead of calling multiple kernels is significant : we observed 150% overhead with 3-component vector with 4k entries compared to one vector of size 12k .",
    "the vexcl implementation of the lorenz attractor ensemble example is as compact as that of cmtl4 . here",
    ", the state is represented by the ` vex::multivector < double,3 > ` type , which holds three instances of ` vex::vector < double > ` and transparently dispatches all operations to the underlying components .",
    "the code for the body of ` operator ( ) ` practically coincides with the problem statement ( [ eq : lorenz ] ) :    .... typedef vex::multivector < double , 3 > state_type ;    struct lorenz_system {      const vex::vector < double > & r ;      lorenz_system(const vex::vector < double > & r ) : r(r ) { }        void operator()(const state_type & x , state_type & dxdt , double t ) const {          dxdt(0 ) = sigma * ( x(1 ) - x(0 ) ) ;          dxdt(1 ) = r * x(0 ) - x(1 ) - x(0 ) * x(2 ) ;          dxdt(2 ) = x(0 ) * x(1 ) - b * x(2 ) ;      } } ; ....    however , the drawback of this variant is that it leads to three kernel launches , namely one per each vector assignment . as we have discussed previously for the cmtl4 variant , this results in suboptimal performance .",
    "a direct use of arithmetic operations for multi - vectors is not possible due to mixed components in the right hand side expressions .",
    "these additional kernel launches can be eliminated in vexcl by assigning a tuple of expressions to a multi - vector .",
    "the required implementation is only slightly less intuitive than the above variant :    ....      dxdt = std::tie (    sigma * ( x(1 ) - x(0 ) ) ,                         r * x(0 ) - x(1 ) - x(0 ) * x(2 ) ,                         x(0 ) * x(1 ) - b * x(2 )           ) ; ....    the performance gain of these fused expressions is a bit larger ( 25% for large systems ) compared to cmtl4",
    ". the reason might be the larger kernel launch overhead for opencl kernels .    for the viennacl version of the lorenz attractor example a ` boost::fusion::vector `",
    "is used to pack the coordinate components of the state vector into a single type .",
    "individual components are instances of the ` viennacl::vector < double > ` type .",
    "the viennacl kernel generation facility already used in sec .  [",
    "sec : adapting - odeint ] is then used to avoid multiple kernel launches . even though a ` custom_operation ` object",
    "is instantiated in each call to ` operator ( ) ` , the kernel is created only once and then buffered internally for further reuse .",
    ".... typedef fusion::vector <      viennacl::vector < double > , viennacl::vector < double > , viennacl::vector < double >      > state_type ;    struct lorenz_system {      const viennacl::vector < double > & r ;      lorenz_system(const viennacl::vector < double > & r ) : r(r ) { }        void operator()(const state_type & x , state_type & dxdt , double t ) const {          typedef viennacl::generator::vector < value_type > vec ;            const auto & x = fusion::at_c<0>(x ) ;          const auto & y = fusion::at_c<1>(x ) ;          const auto & z = fusion::at_c<2>(x ) ;            auto & dx = fusion::at_c<0>(dxdt ) ;          auto & dy = fusion::at_c<1>(dxdt ) ;          auto & dz = fusion::at_c<2>(dxdt ) ;            viennacl::generator::custom_operation op ;          op.add ( vec(dx ) = sigma * ( vec(y ) - vec(x ) ) ) ;          op.add ( vec(dy ) = element_prod(vec(r ) , vec(x ) ) - vec(y )                          - element_prod(vec(x ) , vec(z ) ) ) ;          op.add ( vec(dz ) = element_prod(vec(x ) , vec(y ) ) - b * vec(z ) ) ;          op.excecute ( )      } } ; ....      as a second example we consider a chain of coupled phase oscillators .",
    "a phase oscillator describes the dynamics of an autonomous oscillator @xcite .",
    "its evolution is governed by the phase @xmath15 , which is a @xmath16-periodic variable growing linearly in time , i.e.  @xmath17 , where @xmath18 is the phase velocity .",
    "the amplitude of the oscillator does not occur in this equation , so interesting behavior can only be observed if many of such oscillators are coupled .",
    "in fact , such a system can be used to study such divergent phenomena as synchronization , wave and pattern formation , phase chaos , or oscillation death @xcite .",
    "it is a prominent example of an emergent system where the coupled system shows a more complex behavior than its constitutes .",
    "the concrete example we analyze here is a chain of nearest - neighbor coupled phase oscillators @xcite :",
    "@xmath19 the index @xmath20 denotes here the @xmath20-th phase in the chain .",
    "note , that the phase velocity is different for each oscillator .",
    "the thrust version for the coupled phase oscillator chain is very similar to the lorenz attractor example .",
    "again , a zip iterator is used to pack the required components and to process the resulting sequence with a single sweep of the ` for_each ` algorithm .",
    "the only difference here is that values of neighboring vector elements are needed . in order to access these values ,",
    "we use thrust s permutation iterator , so that ` operator ( ) ` of the system function object becomes    .... thrust::for_each (      thrust::make_zip_iterator (          thrust::make_tuple (              x.begin ( ) ,              thrust::make_permutation_iterator ( x.begin ( ) , prev.begin ( ) ) ,              thrust::make_permutation_iterator ( x.begin ( ) , next.begin ( ) ) ,              omega.begin ( ) , dxdt.begin ( ) ) ) ,      thrust::make_zip_iterator (          thrust::make_tuple (              x.end ( ) ,              thrust::make_permutation_iterator ( x.begin ( ) , prev.end ( ) ) ,              thrust::make_permutation_iterator ( x.begin ( ) , next.end ( ) ) ,              omega.end ( ) , dxdt.end ( ) ) ) ,      phase_oscillators_functor ( )      ) ; ....    here , ` prev ` and ` next ` are vectors of type ` thrust::device_vector < size_t > ` and hold the indices to the left and right vector elements .",
    "the function object ` phase_oscillators_functor ` implements ( [ eq : phasesystem ] ) similarly to the ` lorenz_functor ` above and is thus omitted for brevity .",
    "the stencil operator in cmtl4 is a minimalistic matrix type .",
    "its application is expressed by a matrix - vector product that is assigned to , or is used to either increment or decrement the vector :    .... y = s * x ;        y + = s * x ;       y -= s * x ; ....    the user must provide a function object that applies the stencil on the @xmath20-th element of a vector and its neighbors . for the sake of performance the function object has to provide two methods : one that is checking indices and to be applied near the beginning and the end of the vector and the other without index checking .",
    "for the considered example , the function object is :    .... struct stencil_kernel {      static const int start = -1 , end = 1 ;      int n ;        stencil_kernel(int n ) : n(n ) { }        template < typename vector >      _ _ device _ _ _ _ host _ _ double operator()(const vector & v , int i ) const {      return sin(v[i+1 ] - v[i ] ) + sin(v[i ] - v[i-1 ] ) ;      }        template",
    "< typename vector >      _ _ device _ _ _ _ host _ _      double outer_stencil(const vector & v , int i , int offset= 0 ) const {      double s1 = i > offset ?",
    "sin(v[i ] - v[i-1 ] ) : sin(v[i ] ) ,             s2 = i+1 <",
    "n + offset ?",
    "sin(v[i+1 ] - v[i ] ) : sin(v[i ] ) ;      return s1 + s2 ;      } } ; ....    the parameter ` offset ` is needed when vector parts are cached so that the addressing is shifted . for the sake of backward ( and forward )",
    "compatibility the non - portable keywords ` _ _ device _ _ ` and ` _ _ host _ _ ` should be replaced by a macro that is defined suitably for the according platform , e.g.  to an empty string on regular compilers .",
    "this makes the user code entirely platform - independent .",
    "the stencil function object is passed as a template argument to the stencil matrix :    .... typedef mtl::dense_vector < double >   state_type ;    struct phase_oscillators {      const state_type &   omega ;      mtl::matrix::stencil1d < stencil_kernel > s ;        phase_oscillators(const state & w ) : omega(w ) , s(num_rows(w ) ) { }        void operator()(const state & x , state & dxdt , double t ) const {      dxdt = s * x ;          dxdt + = omega ;      } } ; ....    the stencil matrix ` s ` in the system function above uses shared memory to benefit from re - accessing vector entries and to avoid non - coalesced memory accesses .",
    "the vexcl version of the example is the most concise variant .",
    "the sum of sines in ( [ eq : phasesystem ] ) is encoded using the ` vex_stencil_operator ` preprocessor macro .",
    "its parameters are the name of the resulting function object , the return type , the stencil width , the center , and the body string for the generated opencl function encoding the required operation .",
    "once the stencil operator is defined , ` operator ( ) ` of the system function object is implemented with a single line of code :    .... typedef vex::vector < double > state_type ;    struct phase_oscillators {      const state_type & omega ;      phase_oscillators(const state_type & w ) : omega(w ) { }      void operator()(const state_type & x , state_type & dxdt , double t ) const {          static vex_stencil_operator(s , double , 3 , 1 ,                  \" return sin(x[1 ] - x[0 ] ) + sin(x[0 ] - x[-1 ] ) ; \" , omega.queue_list ( ) ) ;          dxdt = omega + s(x ) ;      } } ; ....    the stencil operations are implemented in viennacl using the ` shift ( ) ` operation , which shifts the indices of a vector by a certain offset .",
    "new shifted values at the beginning or at the end of the vector are by default the same as the first or last entry of the vector , respectively , which is just the required behavior for this example :    .... typedef viennacl::vector < double > state_type ;    struct phase_oscillators {      const state_type & omega ;      phase_oscillators(const state_type & w ) : omega(w ) { }        void operator()(const state_type & x , state_type & dxdt , double t ) const {        typedef viennacl::generator::vector < value_type > vec ;          viennacl::generator::custom_operation op ;        op.add ( vec(dxdt ) = vec(omega ) + sin(shift(vec(x ) ,   1 ) - vec(x ) )                                        + sin(vec(x ) - shift(vec(x ) , -1 ) ) ) ;        op.execute ( ) ;      } } ; ....      the last example in our performance and usage study is a nonlinear disordered hamiltonian lattice @xcite .",
    "its equations of motion are governed by @xmath21 here , @xmath22 denotes the two - dimensional discrete laplacian @xmath23 .",
    "such systems are widely used in theoretical physics to study phenomena like anderson localization @xcite or thermalization @xcite .",
    "an important property of ( [ eq : disordered_ham ] ) is its hamiltonian nature .",
    "it can be obtained from the hamilton equations and energy as well as phase volume conservation during the time evolution can be shown . to account for these properties , a special class of solvers exists , namely symplectic solvers .",
    "odeint implements three different variants of such solvers , all being of the runge - kutta - nystrm type @xcite .",
    "the implementation of these solvers requires only the second part of ( [ eq : disordered_ham ] ) with @xmath24 to be specified by the user .",
    "the natural choice for the implementation of ( [ eq : disordered_ham ] ) is a sparse matrix - vector product .",
    "since thrust neither provides sparse matrix types nor sparse matrix - vector products , thrust was combined with the cusparse library in order to implement this example .",
    "cusparse contains a set of basic linear algebra subroutines used for handling sparse matrices and is included in the cuda toolkit distribution together with the thrust library @xcite .    for better comparison , all libraries considered in our study use the hybrid ell format for storing the sparse matrix on gpus , since it is one of the most efficient formats for sparse matrices on these devices  @xcite",
    "the standard compressed sparse row format is used for cpu runs . as the construction of the sparse matrix for @xmath25 is straight - forward ,",
    "we only provide code for the system function object interface .",
    "the relevant code for the thrust version of the system function object is    .... typedef thrust::device_vector < double > state_type ;    void operator()(const state_type & q , state_type & dp ) const {      static double one = 1 ;      thrust::transform(q.begin ( ) , q.end ( ) , dp.begin ( ) , scaled_pow3_functor(-beta ) ) ;        cusparsedhybmv(handle , cusparse_operation_non_transpose ,              & one , descr , a , thrust::raw_pointer_cast(&q[0 ] ) , & one ,              thrust::raw_pointer_cast(&dp[0 ] ) ) ; } ....    here , ` handle ` , ` descr ` , and ` a ` are cusparse data structures holding the cusparse context and sparse matrix data .",
    "the ` thrust::transform ( ) ` algorithm is used in line 5 to compute the scaled third power of the input vector ` q ` .",
    "lines 79 call the sparse matrix - vector product kernel in cusparse , where ` thrust::raw_pointer_cast ( ) ` is used to convert the thrust device vector iterator to a raw device pointer .",
    "the cmtl4 implementation reads :    .... typedef mtl::dense_vector < double > state_type ;    void operator()(const state_type & q , state_type & dp ) {      dp = a * q ;      dp -= beta * q * q * q ; } ....    here ` a ` is an instance of a sparse matrix holding the discretization of the linear combination @xmath25 .",
    "the expression ` q * q * q ` computes the triple element - wise product of column vector ` q ` .",
    "usually , products of column / row vectors among themselves are often program errors and therefore not allowed in cmtl4 .",
    "their use may be enabled by defining an according macro during compilation .",
    "the vexcl version employs the user - defined opencl function ` pow3 ` , which computes the third power of its argument and is used for the sake of best performance :    .... typedef vex::vector < double > state_type ; vex_function(pow3 , value_type(value_type ) ,   \" return prm1 * prm1 * prm1 ; \" ) ;    void operator()(const state_type & q , state_type & dp ) const {      dp = ( -beta ) * pow3(q ) + a * q ; } ....    similar to cmtl4 , the viennacl version of the system function object is split into two parts : first , the sparse matrix - vector product @xmath26 is computed ; second , the non - linear term @xmath27 is added to the result by means of a custom operation :    .... typedef viennacl::vector < double > state_type ;    void operator()(const state_type & q , state_type & dp ) const {      typedef viennacl::generator::vector",
    "< value_type > vec ;        dp = viennacl::linalg::prod(m_a , q ) ;      viennacl::generator::custom_operation op ;      op.add ( vec(dp ) -= m_beta * element_prod(vec(q ) , element_prod(vec(q ) , vec(q ) ) ) ) ;      op.execute ( ) ; } ....",
    "we present results obtained from our numerical experiments in this section .",
    "the complete source code for the experiments and the full set of results are freely available in a github repository ] .",
    "all the libraries tested in this paper with the exception of cmtl4 and cusparse allow for the use of both cpu and gpu devices .",
    "thrust supports an openmp - based execution on the cpu , which is enabled by a compilation switch , while opencl libraries natively support cpus provided that the respective runtime is installed .",
    "opencl implementations from amd and from intel were used on the cpu and from amd and nvidia on gpus .",
    "the timings provided were obtained on a gentoo linux operating system for two gpus , namely an nvidia tesla c2070 and an amd radeon hd  7970 ( tahiti ) , as well as for an intel core i7 930 cpu .",
    "all reported values are median values of execution times taken for ten runs",
    ".    figures [ fig : lorenz : perf ] through [ fig : lattice : perf ] show performance data for the three examples discussed in the previous section .",
    "the top row in each figure shows the performance obtained from cpu - based experiments , while bottom rows shows gpu - based data . on the gpu plots the graphs for nvidia tesla and amd tahiti boards",
    "are correspondingly plotted with solid and dotted lines .",
    "the plots on the left show absolute solution time over the size of the problem being solved , while the plots on the right depict performances relative to the thrust version with two exceptions , where viennacl is selected as the reference library .",
    "the first exception are gpu plots on fig .",
    "[ fig : phase : perf ] , where thrust library performs badly in case of the coupled phase oscillator chain example .",
    "the other exception is fig .",
    "[ fig : lattice : perf ] , where the combination of thrust and cusparse is not able to run on a cpu .",
    "absolute execution times for the largest problem size for all of the considered libraries are given in table  [ tab : abstimes ] .",
    "the table also provides the achieved memory bandwidth in gb / sec and in fractions of the theoretical peak for each of the compute devices .                  in general ,",
    "all our experiments show up to @xmath28 to @xmath29 acceleration when run on a gpu as compared to the cpu path .",
    "this is the expected acceleration rate for the memory bandwidth bound examples that we looked at .",
    "however , both cuda and opencl programs show considerable overhead at smaller problem sizes , thus requiring problems of sizes between @xmath30 and @xmath31 to see any significant acceleration on a gpu at all .",
    "the overhead for opencl libraries is larger than that of cuda programs , which is mostly due to the additional kernel management logic required by the opencl runtime .",
    "performance - wise , all of the considered libraries are close to each other when run on a gpu .",
    "vexcl and viennacl are in general slower than cmtl4 and thrust by a few percent , which is usually negligible in practice .",
    "apparently , the cusparse implementation of the sparse matrix - vector product is more efficient than that of the rest of the libraries , since it outperforms the competitors by about 20 - 30% in the disordered hamiltonian lattice experiment .",
    "the implementation of the phase oscillator chain example for thrust is rather ineffective since it uses a permutation iterator requiring an additional global vector for storing indices .",
    "the implementations of stencil operations in cmtl4 and viennacl are slightly more efficient than those of vexcl",
    ".    moreover , the overhead of using high - level libraries is negligible compared to the effort spent in getting familiar with the details of cuda or opencl .",
    "thus , we have successfully countered productivity concerns for gpu computing raised in the past  @xcite .",
    "thrust , vexcl , and viennacl show very similar performance on the cpu for larger problem sizes . for smaller problems",
    "the difference between thrust and opencl - based libraries is more pronounced , since thrust uses an openmp backend which does not have any overhead such as opencl initialization and kernel compilation .",
    "the difference between the opencl implementations of amd and the intel is negligible in most cases .",
    "the only exception is the example of the chain of phase oscillators , where the implementation by intel outperforms the one of amd by up to 50 percent .",
    "this might be explained by either a better implementation of trigonometric functions in intel s version , or the autovectorization feature of intel s opencl sdk , which transparently compiles opencl kernels to fully utilize the simd processing on the underlying intel cpu .",
    "it has to be said that the overhead of opencl for small problem sizes is tremendous , if not embarrassing , hence opencl can not be considered to be a competitive cpu programming model for a large area of applications in its present state . a considerable reduction in kernel launch overhead for cpu - based kernel execution is required to make opencl more attractive on this target .     & & & & & & +   + thrust & 242.78 & 105 ( 71% ) & 240.87 & 49 ( 33% ) & 319.60 & 120 ( 81% ) + cmtl4 & 237.91 & 108 ( 73% ) & 161.96 & 73 ( 50% ) & 370.31 & 104 ( 70% ) + vexcl & 246.58 & 104 ( 70% ) & 189.38 & 63 ( 42% ) & 401.39 & 96 ( 65% ) + viennacl & 259.85 & 99 ( 66% ) & 166.20 & 71 ( 48% ) & 433.50 & 89 ( 60% ) +   + vexcl & 149.49 & 171 ( 65% ) & 91.60 & 130 ( 49% ) & 225.41 & 170 ( 65% ) +",
    "viennacl & 148.69 & 172 ( 65% ) & 76.55 & 155 ( 59% ) & 214.87 & 179 ( 68% ) +   + thrust & 2  336.14 & 11 ( 43% ) & 5  182.55 & 2 ( 9% ) & + vexcl ( amd ) & 2  329.00 & 11 ( 43% ) & 5  011.66 & 2 ( 9% ) & 2  934.99 & 13 ( 51% ) + vexcl ( intel ) & 2  372.70 & 11 ( 42% ) & 4  463.24 & 3 ( 10% ) & 3  171.74 & 12 ( 47% ) + viennacl ( amd ) & 2  322.78 & 11 ( 43% ) & 4  246.24 & 3 ( 11% ) & 2  608.80 & 15 ( 58% ) + viennacl ( intel ) & 2  322.39 & 11 ( 43% ) & 2  815.23 & 4 ( 16% ) & 2  580.47 & 15 ( 58% ) +    finally , results for multi - gpu usage as provided by vexcl in a transparent way are considered .",
    "[ fig : scaling ] shows scaling results for up to three gpus .",
    "it can be seen that a notable speed - up for several tesla gpus over a single card is only obtained for problem sizes larger than @xmath32 .",
    "it seems that amd s opencl implementation does not work very well with multiple gpus employed .",
    "still , the combined memory of several gpus allows to solve proportionally larger problems on the same system .",
    "performance - wise , there is almost no difference between various platforms and libraries when those are run on the same hardware for large problem sizes . as we have shown , various computational problems may be solved effectively in terms of both human and machine time with the help of modern high - level libraries .",
    "hence , the differences in the programming interfaces of the libraries are more likely to determine the choice of a particular library for a specific application rather than raw performance .",
    "the focus of thrust is more on providing low - level primitives with an interface very close to the cstandard template library .",
    "special purpose functionality is available via separate libraries such as cusparse and can be integrated without a lot of effort .",
    "the rest of the libraries we looked at demonstrated that they are able to provide a more convenient interface for a scientific programmer than a direct implementation in cuda or opencl .",
    "cmtl4 and vexcl have a richer set of element - wise vector operations and allow for the shortest implementations in the context of the odes considered in this work .",
    "viennacl requires two to three additional lines of code in each of the examples due to the use of the kernel generator facility .",
    "still , this extra effort is acceptable considering that the library s focus is on sparse linear systems solvers , which are , however , beyond the scope of this paper .",
    "regarding a comparison of cuda versus opencl , the main difference observed in this work is the wider range of hardware supported by opencl .",
    "although the performance obtained via cuda is a few percent better than that of opencl on the overall , the differences are mostly too small in order to make a decision in favor of cuda based on performance only .",
    "moreover , the slight performance advantage of cuda can still turn into a disadvantage when taking the larger set of hardware supporting opencl into consideration .",
    "this work has been partially supported by the russian foundation for basic research ( rfbr ) grant no 12 - 07 - 0007 and the austrian science fund ( fwf ) , grant p23598 .",
    "we also would like to thank gradient jsc ] for the kindly provided amd hardware .",
    ", _ odeint v2 - solving ordinary differential equations in c++_. http://www.codeproject.com / articles/268589/odeint - v2-solving - ordinary - d% ifferential - equations[http://www.codeproject.com / articles/268589/odeint - v2-solving - ordinary - d% ifferential - equations ] , oct 2011 .",
    ", _ vexcl : vector expression template library for opencl_. http://www.codeproject.com / articles/415058/vexcl - vector - expression - temp% late - library - for - openc[http://www.codeproject.com / articles/415058/vexcl - vector - expression - temp% late - library - for - openc ] , jul 2012 ."
  ],
  "abstract_text": [
    "<S> we present a comparison of several modern clibraries providing high - level interfaces for programming multi- and many - core architectures on top of cuda or opencl . </S>",
    "<S> the comparison focuses on the solution of ordinary differential equations and is based on odeint , a framework for the solution of systems of ordinary differential equations . </S>",
    "<S> odeint is designed in a very flexible way and may be easily adapted for effective use of libraries such as mtl4 , vexcl , or viennacl , using cuda or opencl technologies . </S>",
    "<S> we found that cuda and opencl work equally well for problems of large sizes , while opencl has higher overhead for smaller problems . </S>",
    "<S> furthermore , we show that modern high - level libraries allow to effectively use the computational resources of many - core gpus or multi - core cpus without much knowledge of the underlying technologies .    </S>",
    "<S> gpgpu , opencl , cuda , c , boost.odeint , mtl4 , vexcl , viennacl    34 - 04 , 65 - 04 , 65y05 , 65y10 , 97n80 </S>"
  ]
}