{
  "article_text": [
    "state - of - the - art automated theorem provers ( atps ) such as e  @xcite and vampire  @xcite achieve their performance by using sophisticated proof search strategies and their combinations .",
    "constructing good atp search strategies is a hard task that is potentially very rewarding . until recently , there has been , however , little research in this direction in the atp community .    with the arrival of large atp problem sets and benchmarks extracted from the libraries of today s",
    "interactive theorem prover ( itp ) systems  @xcite , automated generation of targeted atp strategies became an attractive topic .",
    "it seems unlikely that manual ( `` theory - driven '' ) construction of targeted strategies can scale to large numbers of atp problems spanning many different areas of mathematics and computer science . starting with blind strategymaker ( blistr )  @xcite that was used to invent e s strategies for malarea  @xcite on the 2012 mizar@turing competition problems  @xcite",
    ", several systems have been recently developed to invent targeted atp strategies  @xcite .",
    "the underlying methods used so far include genetic algorithms and iterated local search , as popularized by the paramils  @xcite system .",
    "a particular problem of the methods based on iterated local search is that their performance degrades as the number of possible strategy parameters gets high .",
    "this is the case for e , where a domain specific language allows construction of astronomic numbers of strategies .",
    "this gets worse as more and more sophisticated templates for strategies are added to e , such as our recent family of conjecture - oriented weight functions implementing various notions of term - based similarity  @xcite .",
    "the pragmatic solution used in the original blistr consisted of re - using manually pre - designed high - level strategy components , rather than allowing the system to explore the space of all possible strategies .",
    "this is obviously unsatisfactory .",
    "in this work we introduce blistrtune  a hierarchical extension of blistr .",
    "blistrtune allows exploring much larger space of e strategies by factoring the search into invention of good high - level strategy components and their low - level fine - tuning .",
    "the high - level and low - level inventions communicate to each other their best solutions , iteratively improving all parts of the strategy space .",
    "together with our new conjecture - oriented weight functions , the hierarchical invention produces so far the strongest schedule of strategies on the small ( _ bushy _ ) versions of the mizar@turing problems .",
    "the improvement over vampire 4.0 on the training set is nearly 10% , while the improvement on the testing ( competition ) set is over 5% .",
    "the rest of the paper is organized as follows .",
    "section  [ sec : strats ] introduces the notion of proof search strategies , focusing on resolution / superposition atps and e prover .",
    "we also summarize our recent conjecture - oriented strategies that motivated the work on blistrtune .",
    "section  [ sec : blistr ] describes the ideas behind the original blind strategymaker based on the paramils system ( see section  [ sec : paramils ] for more details on paramils ) .",
    "section  [ sec : blistrtune ] introduces the hierarchical invention algorithm and its implementation .",
    "the system is evaluated in several ways in section  [ sec : experiments ] , showing significant improvements over the original blistr and producing significantly improved atp strategies .",
    "the search space of this loop grows quickly .",
    "several methods can be used to make the proof search more efficient .",
    "the search space can be narrowed by adjusting ( typically restricting ) the inference rules , pruned by using _",
    "forward _ and _ backward subsumption _",
    ", reduced by pre - selecting relevant input clauses , or otherwise simplified .",
    "one of the main sources of non - determinism affecting efficiency of the search is the selection of the given clause .",
    "clever selection mechanism can improve the search dramatically : in principle , one only needs to do the inferences that participate in the final proof .",
    "so far , this is often only a tiny portion of all the inferences done by the atps during the proof search .",
    "the e  @xcite automated theorem prover ( atp ) contains a number of points where learning and tuning methods can be used to improve its performance . since 2006",
    ", the author has experimented with selecting the best predefined e strategies for the mizar / mptp problems  @xcite , and since 2011 the e - males  @xcite system has been developed",
    ". this system uses state - of - the - art learning methods to choose the best schedule of strategies for a problem .",
    "an early evaluation of e - males in casc 2011 has been counterintuitive : e - males solved only one more fof problem than e. under reasonable assumptions ( imperfect knowledge , reasonably orthogonal strategies ) it is however easy to prove that for ( super-)exponentially behaving systems like e , even simple strategy scheduling should on average ( and with sufficiently high time limits ) be better than running only one strategy .",
    "a plausible conclusion was that the set of e strategies is not sufficiently diverse .",
    "for the 2012 mizar@turing competition , 1000 large - theory mptp2078  @xcite problems ( that would not be used in the competition ) were released for pre - competition training and tuning , together with their mizar  @xcite and vampire  @xcite proofs . from the premises used in the mizar proofs , vampire 1.8 ( tuned well for mizar in 2010  @xcite )",
    "could prove 691 of these problems in 300s .",
    "a pre-1.6 version of e run with its old auto - mode could solve only 518 of the problems .",
    "in large - theory competitions like mizar@turing , where learning from previous proofs is allowed , metasystems like malarea  @xcite can improve the performance of the base atp a lot .",
    "but the sine premise - selection heuristic  @xcite has been also tuned for several years , and with the great difference of the base atps on small version of the problems , the result of competition between sine / vampire and malarea / e would be hard to predict .",
    "this provided a direct incentive for constructing a method for automated improvement of e strategies on a large set of related problems .",
    "in this section we briefly describe the proof search of saturation - based automated theorem provers ( atps ) .",
    "section  [ sec : eprover ] describes the proof search control possibilities of e prover  @xcite .",
    "section  [ sec : weights ] describes our previous development of similarity based clause selection strategies  @xcite which we make use of and evaluate here .",
    "many state - of - the - art atps are based on the _ given clause algorithm",
    "_ introduced by _ otter",
    "_  @xcite .",
    "the input problem @xmath0 is translated into a refutationally equivalent set of clauses . then the search for a contradiction , represented by the empty clause ,",
    "is performed maintaining two sets : the set @xmath1 of _ processed clauses _ and the set @xmath2 of _ unprocessed _ clauses .",
    "initially , all the input clauses are unprocessed .",
    "the algorithm repeatedly selects a _ given clause _",
    "@xmath3 from @xmath2 and generates all possible inferences using @xmath3 and the processed clauses from @xmath1 .",
    "then , @xmath3 is moved to @xmath1 , and @xmath2 is extended with the newly produced clauses .",
    "this process continues until a resource limit is reached , or the empty clause is inferred , or @xmath1 becomes _ saturated _ , that is , nothing new can be inferred .",
    "e  @xcite is a state - of - the - art theorem prover which we use as a basis for implementation .",
    "the selection of a given clause in e is implemented by a combination of priority and weight functions .",
    "a _ priority function",
    "_ assigns an integer to a clause and is used to pre - order clauses for weight evaluation .",
    "weight function _ takes additional specific arguments and assigns to each clause a real number called _",
    "weight_. a _ clause evaluation function _ ( @xmath4 ) is specified by a priority function , weight function , and its arguments .",
    "each @xmath4 selects the clause with the smallest pair @xmath5 for inferences .",
    "each @xmath4 is specified using the syntax @xmath6 with a variable number of comma separated arguments of the weight function .",
    "e allows a user to select an _",
    "expert heuristic _ on a command line in the format @xmath7 where integer @xmath8 indicates how often the corresponding @xmath9 should be used to select the given clause .",
    "e additionally supports an _ auto - schedule _ mode where several expert heuristics are tried , each for a selected time period .",
    "the heuristics and time periods are automatically chosen based on input problem properties .",
    "one of the well - performing weight functions in e , which we also use as a reference for evaluation of our weight functions , is the _ conjecture symbol weight_. this weight function counts symbol occurrences with different weights based on their appearance in the conjecture as follows .",
    "different weights @xmath10 , @xmath11 , @xmath12 , and @xmath13 are assigned to function , constant , and predicate symbols , and to variables .",
    "the weight of a symbol which appears in the conjecture is multiplied by @xmath14 , typically @xmath15 to prefer clauses with conjecture symbols . to compute a term weight ,",
    "the given symbol weights are summed for all symbol occurrences .",
    "this evaluation is extended to equations and to clauses .",
    "apart from clause selection , e prover introduces other parameters which influence the choice of the inference rules , term orderings , literal selection , etc .",
    "the selected values of the parameters which control the proof search are called a _",
    "protocol_. because _ protocol _ is a crucial notion in this paper , we provide a simple example for reader s convenience .",
    "[ ex : proto ] let us consider the following simplified e protocol written in e prover command line syntax as follows .    ....",
    "-tkbo6 -wselectcomplexg    -h'(13*refinedweight(prefergoals,1,2,2,3,2 ) ,        2*clauseweight(bycreationdate,-2,-1,0.5 ) ) ' ....    this protocol selects term ordering , literal selection function , and two cefs .",
    "the first cef has frequency 13 , weight function , priority function , and weight function arguments `` '' .",
    "an exact meaning of specific protocol parameters can be found in e manual  @xcite .",
    "many of the best - performing weight functions in e are based on a similarity of a clause with the conjecture , for example , the _ conjecture symbol weight _ from the previous section .",
    "a natural question arises whether or not it makes sense to extend the symbol - based similarity to more complex term - based similarities .",
    "previously we proposed  @xcite , implemented , and evaluated several weight functions which utilize conjecture similarity in different ways .",
    "typically they extend the symbol - based similarity by similarity on terms .",
    "using finer formula features improves the high - level premise selection task  @xcite , which motivated us on steering also the internal selection in e. the following sections summarizes the new weight functions which we further evaluate later in section  [ sec : evaltune ] and section  [ sec : selectsched ] .",
    "the first of our weight functions is similar to the standard _ conjecture symbol weight _",
    ", counting instead of symbols the number of subterms a term shares with the conjecture .",
    "the clause weight function takes five specific arguments @xmath14 , @xmath10 , @xmath11 , @xmath12 and @xmath13 .",
    "the weight of a term equals weight @xmath10 for functional terms , @xmath11 for constants , @xmath12 for predicates , and @xmath13 for variables , possibly multiplied by @xmath14 when @xmath16 appears in the conjecture . to compute a clause weight ,",
    "terms weights are summed for all subterms from a clause .",
    "_ term frequency  inverse document frequency _ , is a numerical statistic intended to reflect how important a word is to a document in a corpus  @xcite .",
    "term frequency _ is the number of occurrences of the term in a given document .",
    "a _ document frequency _ is the number of documents in a corpus which contain the term .",
    "the term frequency is typically multiplied by the logarithm of the inverse of document frequency to reduce frequency of terms which appear often .",
    "we define @xmath17 as the number of occurrences of @xmath16 in a conjecture .",
    "we consider a fixed set of clauses denoted @xmath18 .",
    "we define @xmath19 as the count of clauses from @xmath18 which contain @xmath16 .",
    "out weight function takes one specific argument @xmath20 to select documents , either ( 1 ) @xmath21 for the axioms ( including the conjecture ) or ( 2 ) @xmath22 for all the processed clauses .",
    "first we define the value @xmath23 of term @xmath16 as follows .",
    "@xmath24 the weight of term @xmath16 is computed as @xmath25 and extended to clauses .",
    "the previous weight functions rely on an exact match of a term with a conjecture related term .",
    "the following weight function loosen this restriction and consider also partial matches .",
    "we consider terms as symbol sequences .",
    "let @xmath26 be the longest prefix @xmath16 shares with a conjecture term .",
    "a _ term prefix weight _",
    "( ) counts the length of @xmath26 using weight arguments @xmath27 and @xmath28",
    ". these are used to define the weight of term @xmath16 as follows .",
    "@xmath29      a straightforward extension of is to employ the levenshtein distance  @xcite which measures a distance of two strings as the minimum number of edit operations ( character insertion , deletion , or change ) required to change one word into the other .",
    "our weight function defines the weight of term @xmath16 as the minimal levenshtein distance from @xmath16 to some conjecture term .",
    "it takes additional arguments @xmath30 , @xmath31 , @xmath32 to assign different costs for edit operations .",
    "the levenshtein distance does not respect a tree structure of terms . to achieve that",
    ", we implement the _ tree edit distance _ @xcite which is similar to levenshtein but uses tree editing operations ( inserting a node into a tree , deleting a node while reconnecting its child nodes to the deleted position , and renaming a node label ) .",
    "our weight function takes the same arguments as above and term weight is defined similarly .      with",
    ", a tree produced by the edit operations does not need to represent a valid term as the operations can change number of child nodes . to avoid this",
    "we define a simple _ structural distance _ which measures a distance of two terms by a number of _ generalization _ and _ instantiation _ operations .",
    "generalization transforms an arbitrary term to a variable while instantiation does the reverse .",
    "our weight function takes additional arguments @xmath28 , @xmath33 , and @xmath34 as penalties for variable mismatch and operation costs .",
    "the distance of a variable @xmath35 to a term @xmath16 is the cost of instantiating @xmath35 by @xmath16 , computed as @xmath36 .",
    "the distance of @xmath16 to @xmath35 is defined similarly but with @xmath34 .",
    "a distance of non - variable terms @xmath16 and @xmath37 which share the top - level symbol is the sum of distances of the corresponding arguments .",
    "otherwise , a generic formula @xmath38 is used .",
    "the term weight is as for but using @xmath39 .",
    "in this section we describe blind strategymaker ( blistr )  @xcite which we further extend in the following section .",
    "blistr is a system that develops e prover protocols targeted for a given large set of problems .",
    "the main idea is to interleave ( i ) iterated low - timelimit local search for new protocols on small sets of similar easy problems with ( ii ) higher - timelimit evaluation of the new protocols on all problems .",
    "the accumulated results of the global higher - timelimit runs are used to define and evolve the notion of `` similar easy problems '' , and to control the selection of the next protocol to be improved .",
    "the main criterion for blistr is as follows .",
    "invent a set of e protocols that together solve as many of the given benchmark problems .    to ensure that the invented protocols perform well also on unknown but related problems",
    "a second criterion is considered .",
    "the protocols should be reasonably general .",
    "to simplify employment of the invented protocols , blistr tries to achieve also the third criterion .",
    "the set of such protocols should not be too large .",
    "this setting is very concrete , however , nothing particular is assumed about the input benchmark problems .",
    "the protocol invention methods were intentionally developed in a data - driven way , that is , assuming as little knowledge about the meaning of e s protocols as possible .",
    "the credo of ai research is to automate out human intelligence hence rather than manually developing deep theories about how the protocols work , which parameters are the right for tuning , how they influence each other , etc .",
    ", it was considered more interesting to push such a `` blind '' approach as far as possible , and try hard to automate the discovery process based on data only .    as defined earlier , e protocols consist of many parameters and their values which influence the proof search .",
    "a huge number of weight function arguments within clause evaluation functions ( cefs , see section  [ sec : eprover ] ) makes the set of meaningful protocol parameters very large for a straightforward use of iterative local search as done by the paramils  @xcite system . since paramils otherwise looks like the right tool for the task , a data - driven ( `` blind '' )",
    "approach was applied in the original blistr to get a smaller set of meaningful cefs : the existing e protocols that were most useful on benchmarks of interest were used to extract a smaller set ( a dozen ) of cefs . making this cefs choice",
    "more `` blind '' is the main contribution of this work and it is discussed in details in section  [ sec : blistrtune ] .",
    "even after such reduction , the space of the protocol parameter - value combinations is so large that a random exploration seems unlikely to find good new protocols .",
    "the guiding idea in blistr is to use again a data - driven approach .",
    "problems in a given mathematical field often share a lot of structure and solution methods .",
    "mathematicians become better and better by solving the problems , they become capable of doing larger and larger steps with confidence , and as a result they can gradually attack problems that were previously too hard for them . by this analogy ,",
    "it is plausible to think that if the solvable problems become much easier for an atp system , the system will be able to solve some more ( harder , but related ) problems . for this to work , a method that can improve an atp on a set of solvable problems is needed .",
    "as already mentioned , the established paramils system can be used for this .",
    "let @xmath40 be an algorithm whose parameters come from a _ configuration space _",
    "( product of possible values ) @xmath41 . a _",
    "parameter configuration _ is an element @xmath42 , and @xmath43 denotes the algorithm @xmath40 with the parameter configuration @xmath44 . given a distribution ( set ) of problem instances @xmath45 , the _ algorithm configuration problem _ is to find the parameter configuration @xmath42 resulting in the best performance of @xmath43 on the distribution @xmath45 .",
    "paramils is an a implementation of an _ iterated local search _ ( ils ) algorithm for the algorithm configuration problem . in short , starting with an initial configuration @xmath46 , paramils loops between two steps : ( i ) perturbing the configuration to escape from a local optimum , and ( ii ) iterative improvement of the perturbed configuration .",
    "the result of step ( ii ) is accepted if it improves the previous best configuration .",
    "to fully determine how to use paramils in a particular case , @xmath40 , @xmath41 , @xmath46 , @xmath45 , and a performance metric need to be instantiated .",
    "in our case , @xmath40 is e run with a low timelimit @xmath47 , @xmath41 is the set of expressible e protocols , and as a performance metric we use the number of given - clause loops done by e during solving the problem .",
    "if e can not solve a problem within the low timelimit , a sufficiently high value ( @xmath48 ) is used .",
    "since it is unlikely that there is one best e protocol for all of the given benchmark problems , it would be counterproductive to use all problems as the set @xmath45 for paramils runs .",
    "instead , blistr partitions the set of all solvable problems into subsets on which the particular protocols perform best .",
    "see  @xcite for the technical details of the blistr heuristic for choosing the successive @xmath46 and @xmath45 .",
    "the complete blistr loop then iteratively co - evolves the set of protocols , the set of solved problems , the matrix of the best results , and the set of the protocols eligible for the paramils improvement together with their problem sets .",
    "+   + * blistr selection heuristic : * let @xmath49 be a set of e protocols , @xmath50 a set of problems , and @xmath51 the performance matrix obtained by running e with @xmath49 on @xmath50 with a higher evaluation time limit @xmath52 .",
    "let @xmath53 be the minimal and maximal eligible values of the performance metric ( given - clause count ) ( set to 500 and 30000 ) .",
    "let @xmath54 be @xmath51 modified by using an @xmath55 value for values outside @xmath56 $ ] , and using an @xmath55 value for all but the best ( lowest ) value in each column .",
    "let @xmath57 ( versatility ) be the minimal number ( set to 2 ) of problems for which a protocol has to be best so that it was eligible , and let @xmath58 be the maximum number of eligible protocols ( set to 20 ) .",
    "then the eligible protocols are the first @xmath58 protocols @xmath49 for which their number of defined values in @xmath59 is largest and greater than @xmath57 .",
    "these protocols are ordered by the number of defined values in @xmath59 , that is , the more the better , and their corresponding sets of problems @xmath60 are formed by those problems @xmath50 , such that @xmath54 is defined . less formally , we prefer protocols that have many best - solvable problems which can be solved within @xmath56 $ ] given - clause loops .",
    "we ignore those whose versatility is less than @xmath57 ( guarding the _ gen _ criterion ) , and only consider the best @xmath58 ( guarding the _ size _ criterion ) .",
    "the maximum on the number of given - clause loops guards against using unreasonably hard problems for the paramils runs that are done in the lower time limit @xmath47 ( typically 1s , to do as many paramils loops as possible ) .",
    "it is possible that a newly developed protocols will have better performance on a problem that needed many given - clause loops in the @xmath52 evaluation .",
    "however , sudden big improvements are unlikely , and using very hard problems for guiding paramils would be useless .",
    "too easy problems on the other hand could direct the search to protocols that do not improve the harder problems , which is our ultimate scheme for getting to problems that are still unsolved .",
    "the complete blistr loop is then as follows .",
    "it iteratively co - evolves the set of protocols , the set of solved problems , the matrix of best results , and the set of eligible protocols and their problem sets .    given the selection heuristic , the overall blistr loop is as follows .",
    "whenever a new protocol @xmath44 is produced by a paramils run , @xmath44 is evaluated on all benchmark problems with the high time limit @xmath52 , updating the performance statistics and the ordered list of eligible protocols and their corresponding problem sets .",
    "run the next paramils iteration with the updated best eligible protocol and its updated problem set , unless the exact protocol and problem set was already run by paramils before .",
    "if so , or if no new protocol is produced by the paramils run , try the next best eligible protocol with its problem set .",
    "stop when there are no more eligible protocols , or when all eligible protocols were already run before with their problem sets .",
    "blistr uses a fixed set of cefs for inventing new protocols .",
    "the arguments of these fixed cefs ( the priority function , weight function arguments ) can not be modified during the iterative protocol improvement done by paramils .",
    "a straightforward way to achieve invention ( fine - tuning ) of cef arguments would be to extend the paramils configuration space @xmath41 .",
    "this , however , makes the configuration space grow from ca .",
    "@xmath61 to @xmath62 of possible combinations .",
    "preliminary experiments revealed that with a configuration space of this size paramils does not produce satisfactory results in a reasonable time .    in this section",
    "we describe our new extension of blistr  blistrtune  where the invention of good high - level protocol parameters ( section  [ sec : global ] ) is interleaved with the invention of good cef arguments ( section  [ sec : tuning ] ) . the basic idea behind blistrtune is iterated _ hierarchical invention _ : the large space of the optimized parameters is naturally factored into two ( in general several ) layers , and at any time only one layer is subjected to invention , while the other layer(s ) remain fixed .",
    "the results then propagate between the layers , and the layer - tuning and propagation are iterated .",
    "blistrtune is experimentally evaluated in section  [ sec : experiments ] .",
    "the paramils runs used in the blistrtune s global - tuning phase are essentially the same as in the case of blistr , with the following minor exceptions .",
    "blistr uses a fixed configuration space @xmath41 for all paramils runs .",
    "this is possible because a small set ( currently 12 ) of cefs is hard coded in blistr s @xmath41 .",
    "blistrtune uses in the global - tuning phase a parametrized configuration space @xmath63 where @xmath64 is a collection of cefs that can be different for each paramils run .",
    "this collection can be arbitrary but we use only the 50 best performing cefs in order to limit the configuration space size for the global - tuning phase .",
    "the notion of `` best performing cefs '' develops in time and it is discussed in details in section  [ sec : collection ] .",
    "furthermore , blistrtune introduces additional argument @xmath65 to limit the maximum number of cefs which can occur in a single protocol ( @xmath66 for the case of blistr ) .",
    "blistrtune s global - tuning usage of paramils is otherwise the same as in blistr , that is , given @xmath63 , the initial configuration @xmath67 , and problems @xmath45 , the result of the global tuning is a configuration @xmath68 which has the best found performance on @xmath45 .",
    "this configuration @xmath69 then serves as an input for the next fine - tuning phase .",
    "[ ex : example ] let us consider the e protocol from example  [ ex : proto ] . in the global - tuning phase we instruct paramils to modify top level arguments , that is , term ordering ( `` '' ) , literal selection ( `` '' ) , cef frequencies ( `` '' and `` '' ) , and also the whole cef blocks and their count .",
    "we do not , however , allow paramils to change cef arguments ( priority functions and weight function arguments ) .",
    "the whole cef must be changed to another cef from collection @xmath64 .",
    "given the result of the global - tuning phase @xmath68 a new configuration space for the fine - tuning phase @xmath70 is constructed by ( 1 ) fixing the parameter values from @xmath69 and by ( 2 ) an introduction of new parameters that allow to change the values of the arguments of the cefs used in @xmath69 . in order to do that , we need to describe the space of the possible values of the cef arguments .",
    "the cef arguments ( see section  [ sec : eprover ] ) consist of the priority function and the weight function specific arguments .",
    "because of the different number and semantics of the weight function arguments , we do not allow to change the cef s weight functions during the fine - tuning .",
    "they are fixed to the values provided in @xmath69 . for each weight function argument , we know its type ( such as the symbol _ weight _ , operation _ cost _ , weight _ multiplier _ , etc . ) . for each type",
    "we have pre - designed the set of reasonable values . for the original e weight functions , we extract the reasonable values from the auto - schedule mode of e. for our new weight functions , we use our preliminary experiments  @xcite enhanced with our intuition .    given the configuration space @xmath70 , a configuration @xmath71 can be easily converted to an equivalent configuration @xmath72 by setting the parameter values to those cefs arguments that were previously fixed in @xmath69 and @xmath64 .",
    "then we can run paramils with the configuration space @xmath70 , the initial configuration @xmath73 , and with the same problem set @xmath45 as in the global - tuning phase .",
    "the result is a configuration @xmath74 providing the best found performance on @xmath45 .",
    "the global invention ( global tuning ) and the local invention ( fine - tuning ) phases can be iterated . to do that",
    ", we need to transform the result of the fine - tuning @xmath74 to an equivalent initial configuration @xmath75 for the next global - tuning phase . in order to do that",
    ", the cefs invented by @xmath76 must be present in the cefs collection @xmath64 .",
    "if this is not the case , we simply extend @xmath64 with the new cefs . in practice ,",
    "we now use two iterations of this process ( that is , two phases of global - tuning and two phases of fine - tuning ) which was experimentally evaluated to provide good results .    recall the protocol from example  [ ex : proto ] and example  [ ex : example ] . in the fine - tuning phase",
    "we would fix all the top level arguments modified in global - tuning phase ( `` '' , and so on , as described in example  [ ex : example ] ) and we would instruct paramils to change individual cef arguments .",
    "that is , the values    ....",
    "prefergoals,1,2,2,3,2      bycreationdate,-2,-1,0.5 ....    might be changed to different values while the rest of the protocol stays untouched .",
    "the global - tuning phase of blistrtune requires the collection @xmath64 of cefs as an input .",
    "it is desirable that this collection @xmath64 is limited in size ( currently we use max .",
    "50 cefs ) and that it contains the best performing cefs .    initially , for each weight function @xmath77 defined in e",
    ", we have extracted the cef most often used in the e auto - schedule mode .",
    "we have added a cef for each of our new weight functions .",
    "this gave us the initial collection of 21 cefs .",
    "then we use a global database ( shared by different blistrtune runs ) in which we store all cefs together with the usage counter which states how often each cef was used in a protocol invented by blistrtune . recall that in one blistrtune iteration",
    ", paramils is ran four times ( two phases of global - tuning and two phases of fine - tuning ) .",
    "whenever a cef is contained in a protocol invented by any blistrtune iteration ( after the four paramils runs ) , we increase the cef usage counter , perhaps adding a new cef to the database when used for the first time .",
    "to select the 50 best performing cefs we start with @xmath78 .",
    "we extract all the weight functions @xmath79 used in the global cef database .",
    "this set @xmath79 stays constant because the database already contains all possible weight functions from the very beginning . for each @xmath80 , we compute the list @xmath81 of all cefs from the database which use @xmath77 and sort it by the usage counter .",
    "then we iterate over @xmath79 and for each @xmath77 we move the most often used cef from @xmath81 to @xmath64 .",
    "we repeat this until @xmath64 has the desirable size ( or we are out cefs ) .",
    "this ensures that @xmath64 contains at least one cef for each weight function .",
    "this section provides an experimental evaluationof blistrtune system . in section  [ sec : evaltune ] we compare our improved blistrtune with the original blistr , and we use blistrtune to evaluate the value added by the new weight functions . in section  [ sec : evalvar ] we evaluate the blistrtune runs with different parameters . in section",
    "[ sec : selectsched ] we discuss and compare several methods to construct a protocol scheduler that tries several protocols to solve a problem .",
    "section  [ sec : evalsched ] then compares the best protocol scheduler with state - of - the - art atps , namely , with e 1.9 using its auto - schedule mode and with vampire 4.0 .    for the evaluation we use problems from the mizar@turing division of the casc 2012 ( turing100 ) competition mentioned in section  [ sec : intro ] .",
    "these problems come from the mptp translation  @xcite of the mizar mathematical library  @xcite .",
    "the problems are divided into 1000 training and 400 testing problems .",
    "the training problems were published before the competition , while the testing problems were used in the competition .",
    "this fits our evaluation setting : we can use blistrtune to invent targeted protocols for the training problems and then evaluate them on the testing problems .        to evaluate the hierarchical invention we ran blistr and blistrtune with equivalent arguments .",
    "furthermore , we ran two instances of blistrtune to evaluate the performance added by the new weight functions from section  [ sec : weights ] .",
    "the first instance was allowed to use only the original e 1.9 weight functions , while the second additionally used our new weight functions .",
    "blistr and blistrtune used the same input arguments .",
    "the first argument is the set of the training problems .",
    "we use the 1000 training problems from the mizar@turing competition in all experiments .",
    "other arguments are :      in blistrtune , paramils is run four times in each iteration , hence we set @xmath85 in blistrtune and @xmath86 in blistr .",
    "we set @xmath87 and @xmath88 and additionally , in the case of blistrtune , @xmath89 .",
    "the results are shown in figure  [ fig : improvement ] . in each iteration ( x - axis , logarithmic scale ) we count the total number of the training problems solved ( y - axis ) by all the protocols invented so far , provided each protocol is given the time limit @xmath84 .",
    "this metric gives us relatively good idea of the blistr / tune progress .",
    "the original blistr solved 673 problems , blistrtune without the new weights solved 702 problems , while blistrtune with the new weights solved 711 problems . from this and from the figure",
    "we can see that the greatest improvement is thanks to the hierarchical parameter invention .",
    "however , the new weight functions still provide 9 more solved problems which is a useful additional improvement .",
    "j.  alama , t.  heskes , d.  khlwein , e.  tsivtsivadze , and j.  urban .",
    "premise selection for mathematics by corpus analysis and kernel methods .",
    "_ j. autom .",
    "reasoning _ , 520 ( 2):0 191213 , 2014 .",
    "issn 0168 - 7433 .",
    "doi : 10.1007/s10817 - 013 - 9286 - 5 .",
    "j.  c. blanchette , d.  greenaway , c.  kaliszyk , d.  khlwein , and j.  urban .",
    "a learning - based fact selector for isabelle / hol .",
    "_ j. autom .",
    "reasoning _ , 570 ( 3):0 219244 , 2016 .",
    "doi : 10.1007/s10817 - 016 - 9362 - 8 .",
    "url http://dx.doi.org/10.1007/s10817-016-9362-8 .    t.  gauthier and c.  kaliszyk .",
    "premise selection and external provers for hol4 . in _",
    "certified programs and proofs ( cpp15 ) _ , lncs .",
    "springer , 2015 .",
    "doi : 10.1145/2676724.2693173 .",
    "url http://dx.doi.org/10.1145/2676724.2693173 . http://dx.doi.org/10.1145/2676724.2693173 .",
    "j.  jakubv and j.  urban . extending e prover with similarity based clause selection strategies . in _",
    "intelligent computer mathematics - 9th international conference , cicm 2016 , bialystok , poland , july 25 - 29 , 2016 , proceedings _ , pages 151156 , 2016 .    c.  kaliszyk and j.  urban .",
    "learning - assisted automated reasoning with flyspeck .",
    "_ j. autom .",
    "reasoning _ , 530 ( 2):0 173213 , 2014 .",
    "doi : 10.1007/s10817 - 014 - 9303 - 3 .",
    "url http://dx.doi.org/10.1007/s10817-014-9303-3 .        c.  kaliszyk , j.  urban , and j.  vyskocil .",
    "machine learner for automated reasoning 0.4 and 0.5 . in s.  schulz , l.  d. moura , and b.  konev , editors , _ paar-2014 .",
    "4th workshop on practical aspects of automated reasoning _",
    ", volume  31 of _ epic series in computing _ , pages 6066 .",
    "easychair , 2015 .",
    "d.  khlwein and j.  urban . : a framework for automatic tuning of automated theorem provers .",
    "_ j. autom .",
    "reasoning _ , 550 ( 2):0 91116 , 2015 .",
    "doi : 10.1007/s10817 - 015 - 9329 - 1 .",
    "url http://dx.doi.org/10.1007/s10817-015-9329-1 .",
    "s.  schfer and s.  schulz . breeding theorem proving heuristics with genetic algorithms . in g.",
    "gottlob , g.  sutcliffe , and a.  voronkov , editors , _ global conference on artificial intelligence , gcai 2015 , tbilisi , georgia , october 16 - 19 , 2015 _ , volume  36 of _ epic series in computing _ , pages 263274 .",
    "easychair , 2015 .",
    "url http://www.easychair.org/publications/paper/breeding_theorem_proving_heuristics_with_genetic_algorithms .",
    "s.  schulz .",
    "system description : e 1.8 . in k.",
    "l. mcmillan , a.  middeldorp , and a.  voronkov , editors , _ lpar _ , volume 8312 of _ lncs _ , pages 735743 .",
    "springer , 2013 .",
    "isbn 978 - 3 - 642 - 45220 - 8 .",
    "doi : 10.1007/978 - 3 - 642 - 45221 - 5_49 .",
    ".                k.  zhang and d.  shasha .",
    "simple fast algorithms for the editing distance between trees and related problems .",
    "_ siam j. comput .",
    "_ , 180 ( 6):0 12451262 , dec . 1989 .",
    "issn 0097 - 5397 .",
    "doi : 10.1137/0218082 .",
    "url http://dx.doi.org/10.1137/0218082 ."
  ],
  "abstract_text": [
    "<S> inventing targeted proof search strategies for specific problem sets is a difficult task . </S>",
    "<S> state - of - the - art automated theorem provers ( atps ) such as e allow a large number of user - specified proof search strategies described in a rich domain specific language . </S>",
    "<S> several machine learning methods that invent strategies automatically for atps were proposed previously . </S>",
    "<S> one of them is the blind strategymaker ( blistr ) , a system for automated invention of atp strategies .    in this paper </S>",
    "<S> we introduce blistrtune  a hierarchical extension of blistr . </S>",
    "<S> blistrtune allows exploring much larger space of e strategies by interleaving search for high - level parameters with their fine - tuning . </S>",
    "<S> we use blistrtune to invent new strategies based also on new clause weight functions targeted at problems from large itp libraries . </S>",
    "<S> we show that the new strategies significantly improve e s performance in solving problems from the mizar mathematical library .    automated theorem proving , machine learning , proof search heuristics , clause weight functions </S>"
  ]
}