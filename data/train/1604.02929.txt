{
  "article_text": [
    "nowadays , evolutionary game theory  @xcite represents a field of growing interest in different scientific communities , as biology  @xcite and social science  @xcite .",
    "notably , identifying strategies and methods for triggering cooperative behaviors  @xcite , modeling biological phenomena  @xcite and studying the effects of social influences  @xcite constitute some of the major aims in this field . on the other hand ,",
    "the darwinian concept of evolution , underlying the dynamics of evolutionary games , represents a powerful inspiring source also in the field of natural computing  @xcite . in the last years , many evolutionary algorithms",
    "@xcite have been proposed to solve optimization problems  @xcite , as for instance genetic algorithms  @xcite and ant colonies heuristics  @xcite .",
    "remarkably , optimization problems have been widely investigated also within the realm of statistical physics  @xcite , where theoretical physics and information theory meet forming a powerful framework for studying complex systems  @xcite .",
    "for instance , a statistical physics mindset approach in combinatorial optimization problems emerges when the set of feasible solutions of the traveling salesman problem  @xcite ( tsp hereinafter ) , is represented in terms of an energetic landscape . in doing so , searching",
    "a solution entails finding a minimum of free energy in a landscape whose minimum , i.e. , the deepest valley , corresponds to the optimal solution of the problem .",
    "different models as the curie - weiss  @xcite and spin glasses  @xcite have an energy that can be studied by the landau formulation of phase transitions  @xcite .",
    "these models are successfully adopted for facing different problems as opinion dynamics  @xcite , information retrieval  @xcite , optimization tasks  @xcite and learning processes  @xcite . using the metaphor of the energy , heuristics like genetic algorithms  @xcite and swarm logics  @xcite ,",
    "implement strategies as genetic recombination , mutation , and collective motions , for surfing the landscape aiming to reach one of the deepest valleys in a finite time , representing a suboptimal solution of a problem .",
    "therefore , parameters as the mutation rate in genetic algorithms can be compared to physical parameters as the system temperature . in this work ,",
    "we adopt a mechanism based on partial imitation  @xcite : when an agent interacts with another one having an higher fitness , the former imitates a part of the latter s solution .",
    "for instance , in the tsp , the weaker agent imitates only a part of the path traveled by a stronger neighbor . in doing so , agents are able to generate solutions over time , with the aim to achieve the optimal one . in physical terms , a partial imitation can be interpreted as a slow cooling process of a spin particle system , where the slowness comes from an imitative dynamics that is only ` partial ' ( i.e. , only few entries of a solution array are imitated ) .",
    "our model considers an agent population , whose interactions are based on the spatial public goods game ( pgg hereinafter ) . as we know from evolutionary game theory ( egt hereinafter )  @xcite , the outcomes of the classical pgg are affected by a parameter defined synergy factor @xmath0 , used for supporting cooperators . here , as we show below , this parameter ( i.e. , @xmath0 ) has a marginal interest",
    ", however what that is relevant for our investigations is that an ordered phase ( i.e. , the prevalence of a species in the population ) can be reached by an opportune tuning of its value . in general , ordered phases entail all agents have the same state ( or strategy in egt ) , i.e. , in physical terms all spins are aligned in the same direction .",
    "the system magnetization allows to measure the state of order of a system , and its value equals to @xmath1 in the ordered cases . dealing with neural networks , and in general with spin glasses ,",
    "it is possible to introduce a gauge for the magnetization so that its value goes to @xmath1 when the spin alignments ( i.e. , agent states ) follow particular patterns .",
    "the mentioned gauge is defined mattis magnetization  @xcite , and it reads @xmath2 with @xmath3 value in the @xmath4-th position of the pattern , @xmath5 value of the spin in the same position of a signal @xmath6 of length @xmath7 .",
    "as we can observe , when spins are perfectly aligned with a pattern @xmath8 , the mattis magnetization is @xmath9 . in the proposed model",
    ", we introduce a similar approach .",
    "in particular , each agent is provided with a random solution of the tsp , and the order is reached when all agents hold the same solution . since our agents interact by the pgg , the modification of their solution occurs during the phase of the game usually defined as ` strategy revision phase '  @xcite , that in our case is renamed as ` solution revision phase ' .",
    "furthermore , our agents use their fitness as currency of the game , so that their payoff depends on the quality of their solution and on those of their neighbors .",
    "we performed several numerical simulation to evaluate the quality of our method considering the traveling salesman problem  @xcite as reference , i.e. , a famous np - hard problem .",
    "results show that the spatial pgg can be successfully adopted for developing new heuristics , opening the way to developments that cross the current fences of egt .",
    "the remainder of the paper is organized as follows : section  [ sec : model ] introduces the proposed model .",
    "section  [ sec : results ] shows results of numerical simulations .",
    "eventually , section  [ sec : conclusion ] ends the paper .",
    "before to introduce the proposed model , we recall the basic dynamics of the spatial pgg .",
    "the latter considers a population with @xmath10 agents and two possible strategies : cooperation and defection .",
    "cooperators contribute to a common pool with a coin ( usually of unitary value ) , while defectors do not contribute .",
    "then , the total amount of coins is enhanced by a synergy factor @xmath0 ( whose value is greater than @xmath9 ) , and the resulting value is equally divided among all agents ( no matter their strategy ) . in doing so , each agent receives a payoff which reads @xmath11 with @xmath12 number of cooperators , @xmath13 amount of agents involved in the game , @xmath14 unitary contribution ( we set , without loss of generality , equal for all agents , i.e. , @xmath15 ) , and @xmath16 and @xmath17 payoff of cooperators and defectors , respectively . as the quantitative definition of the payoff suggests , defection is more convenient than cooperation , and it also represents the nash equilibrium of this game .",
    "the role of the synergy factor @xmath0 is promoting cooperation and , as demonstrated in previous investigations , its value may strongly affects the evolution of a population  @xcite . remarkably , in square lattices , values of @xmath0 smaller than @xmath18 entail all agents become defectors , whereas higher values allow cooperators to survive and even to succeed ( for @xmath19 ) . as previously mentioned , the evolution of a population results from a process defined ` strategy revision phase ' .",
    "notably , after each iteration , an agent has the opportunity to change its strategy by imitating that of a richer neighbor ( considering the gained payoff ) . in the proposed model we consider a set of agents , arranged on a square lattice with continuous boundary conditions , provided with a random solution of a tsp .",
    "each solution is evaluated by a fitness @xmath20 computed as follows @xmath21 with @xmath22 number of cities and @xmath23 , total distance of a path . in doing so ,",
    "its range is @xmath24 $ ] . at each time step ,",
    "one agent is randomly selected ( say the @xmath25th ) and plays the pgg with its neighrbors : every agent of the group contributes with its fitness ; then , as in the classical case before described , the total value of contributions is enhanced by a synergy factor @xmath0 , and eventually equally distributed among all agents . due to the considered topology ,",
    "each group is always composed of @xmath26 agents . it is worth noting that now agents always behave as cooperators , so that the payoff reduces to one equation @xmath27 with @xmath28 indicating the payoff of the @xmath25th agent , and @xmath29 its fitness ( i.e. , that corresponding to its solution ) .",
    "finally , the ` strategy revision phase ' is substitute with a ` solution revision phase ' : the randomly selected agent computes the probability @xmath30 to modify each entry of its solution by imitating that of its best neighbor ( if exists ) @xmath31 as in the classical pgg @xmath32 represents the uncertainty in imitating a neighbor ( i.e. , plays the role of temperature ) .",
    "hence , setting @xmath33 we implement a rational approach during the revision phase  @xcite . in doing so",
    ", the @xmath25th agent imitates with probability @xmath30 each entry of the solution of its best neighbors , if the latter has a greater or , at least , equal fitness ( otherwise the @xmath25th agent does not revise its solution ) .",
    "the proposed method can be summarized as follows :    1 .",
    "generate a population and provide agents with a random solution to the problem ( tsp ) ; 2 .",
    "randomly select one agent ( say @xmath25 ) ; 3 .",
    "the @xmath25th agent plays the pgg with its neighbors and compute its payoff ( i.e. , by  [ eq : payoff_mod ] ) ; 4 .",
    "according to its fitness @xmath29 and to the gained payoff @xmath28 , the @xmath25th agent computes the probability @xmath30 to imitate the solution of its best neighbor say the @xmath34th agent ( if exists ) ; 5 .",
    "if @xmath35 , the @xmath25th agent revises its solution : it imitates each entry of the solution of the @xmath34th agent with probability @xmath30 ; 6 .",
    "repeat from @xmath36 until the population reaches an ordered phase ( i.e. , all agent share the same solution ) , or up to a limited number of time steps elapsed .",
    "it is worth observing that for @xmath37 , the imitation process may become full ( not partial ) , as each entry can be imitated provided the best agents has a greater or equal fitness .",
    "numerical simulations have been performed by arranging agents on square lattices with periodic boundary conditions , and considering up to @xmath38 cities for defining the tsp .",
    "notably , agents know the starting city and the landing one so , since each city can be visited only once , the number of feasible solutions is @xmath39 .",
    "moreover , without loss of generality , we consider that the distance between two close cities is always equal to one see figure  [ fig : figure_0 ]",
    ".     cities forming a complete graph .",
    "each node represents a city , and some distances are reported in blue close to the related link .",
    "then , the best solution is shown .",
    "green nodes represent the starting and the landing ones.[fig : figure_0],scaledwidth=55.0% ]    eventually , we set to @xmath40 , the value of the synergy factor . we remind that in the present work we are not interested in studying phenomena as the evolution of cooperation , but we aim to evaluate if agents are able to converge towards an ordered phase characterized by the existence of only one shared solution to a tsp problem . as shown in figure  [ fig : figure_1 ] , the ergodicity of the process always allows agents to converge to one common solution .",
    "moreover , we are able to verify the quality of solution both considering the related fitness and the mattis magnetization ( see the inset of  [ fig : figure_1 ] ) .",
    "in particular , the latter can be used when the solution of a problem is known in advance , as in our case .",
    "agents while solving a tsp with @xmath41 cities ( blue line ) and @xmath42 cities ( red line ) .",
    "the inset shows the related mattis magnetization for the two cases ( both successful ) .",
    "results are averaged over different simulation runs.[fig : figure_1],scaledwidth=55.0% ]    an important relation to be considered is that between the final average fitness and the size of the population @xmath10 , on varying the amount of cities @xmath22 see plot * a * of figure  [ fig : figure_2 ] .        moreover ,",
    "as shown in plot * b * of figure  [ fig : figure_2 ] , it is worth noting that also good suboptimal solutions may be computed using a number of agents @xmath10 smaller than that required to compute the optimal one .",
    "as expected , increasing @xmath22 the average value of @xmath20 reduces ( keeping fixed the number of agents @xmath10 ) . on the other hand ,",
    "as shown in figure  [ fig : figure_3 ] , it is worth to highlight that it is possible to find an opportune @xmath10 for each considered @xmath22 in order to achieve the highest fitness ( i.e. , @xmath43 ) .",
    "we deem relevant to note that the number of agents to compute the best solution , i.e. , @xmath44 , is much smaller than the number of feasible solutions for each problem , therefore , our method can be considered a viable heuristic for facing combinatorial optimization problems .    .",
    "results are averaged over different simulation runs [ fig : figure_3],scaledwidth=55.0% ]    eventually , we focused on the number of time steps to let the population converge , considering in particular the successfull cases , i.e. , those leading to the optimal solution see figure  [ fig : figure_4 ] .",
    "as expected , great search spaces ( e.g. , @xmath38 ) require more time steps to let the population converge to the same final ( and optimal ) solution .",
    "moreover , increasing @xmath10 the number of time steps @xmath45 increases accordingly for the same problem ( i.e. , keeping fixed @xmath22 ) .",
    "these results are in full agreement with converging processes that can be observed in generic agent - based models , e.g. , increasing the size of a population the number of time steps for letting agents converge to the same state increases  @xcite .    , for different population size @xmath10 .",
    "results are averaged over different simulation runs .",
    "[ fig : figure_4],scaledwidth=55.0% ]",
    "in this work we show that evolutionary games as the pgg can be , in principle , applied also for solving combinatorial optimization problems as the tsp . in particular , the order - disorder phase transition occurring in population interacting by the classical pgg can be adopted for letting the population to converge towards a common solution of a given problem .",
    "notably , the solution plays the same role of the strategy in the classical pgg , and the order is reached by implementing a mechanism of ` partial imitation '  @xcite .",
    "the latter allows agents with a weak solution to partially imitate stronger ( i.e. , richer ) neighbors . from a physical perspective",
    ", this mechanism corresponds to a slow cooling process that allows the emerging of solutions over time , whereas the ergodicity of the process allows the population to reach an adsorbing state of full order . in doing so",
    ", an ordered phase entails all agents share the same solution . under the hypothesis",
    "that an evolutionary dynamics driven by the payoff , i.e. , rational , may constitute the base for solving difficult problems as the tsp , we performed several numerical simulations by arranging agents on a square lattice with continuous boundary conditions .",
    "although we implemented a simplified version of the tsp , with a limited number of cities , it is worth noting that results indicate that the proposed model allows to compute the optimal solution in all considered search spaces .",
    "moreover , even using a reduced number of agents , it is possible to compute a good suboptimal solution .",
    "furthermore , we note that even introducing spatial constraints in the tsp definition , the algorithm is able to face the problem , once the driveability graph is known ( as shown in figure  [ fig : figure_0 ] ) . therefore , in the light of the achieved outcomes , we deem relevant to further investigate the potential of evolutionary games in optimization problems , then enlarging the domain of application of egt . to conclude , the proposed heuristic shows that cooperative dynamics , leading from disordered to ordered states , may constitute the basic mechanism for implementing optimization algorithms .",
    "the author wishes to thank adriano barra for his helpful comments and suggestions .",
    "perc , m. , gomez - gardenes , j. , szolnoki , a. , floria , l.m . , and moreno , y. : evolutionary dynamics of group interactions on structured populations : a review .",
    "_ j. r. soc .",
    "interface _ * 10 - 80 * 20120997 ( 2013 )                                                  san miguel , m. , johnson , j.h . ,",
    "kertesz , kaski , k. , diaz - guilera , a. , mackay r.s . ,",
    "loreto , v. , erdi , p. , helbing , d. : challenges in complex systems science . _ the european physical journal special topics _ * 214 - 1 * 245271 ( 2012 )"
  ],
  "abstract_text": [
    "<S> we introduce a method based on the spatial public goods game for solving optimization tasks . in particular , we focus on the traveling salesman problem , i.e. , a problem whose search space exponentially grows increasing the number of cities , then becoming np - hard . </S>",
    "<S> the proposed method considers a population whose agents are provided with a random solution to the given problem . </S>",
    "<S> then , agents interact by playing the public goods game using the fitness of their solution as currency of the game . in doing so </S>",
    "<S> , agents with better solutions provide higher contributions , while agents with lower ones tend to imitate the solution of richer agents to increase their fitness . </S>",
    "<S> numerical simulations show that the proposed method allows to compute exact solutions , and suboptimal ones , in the considered search spaces . as result , beyond to propose a new heuristic for combinatorial optimization tasks , our work aims to highlight the potentiality of evolutionary game theory outside its current horizons . </S>"
  ]
}