{
  "article_text": [
    "graphs are widely used to model complicated data objects in many disciplines , such as bioinformatics , social networks , software and data engineering .",
    "effective analysis and management of graph data become increasingly important .",
    "many queries have been investigated and they can be roughly divided into two broad categories : graph exact search  @xcite and graph similarity search  @xcite .",
    "compared with exact search , similarity search can provide a robust solution that permits error - tolerant and supports to search patterns that are not precisely defined .",
    "similarity computation between two attributed graphs is a core operation of graph similarity search and it has been used in various applications such as pattern recognition , graph classification and chemistry analysis  @xcite .",
    "there are at least four metrics being well investigated : graph edit distance  @xcite , maximal common subgraph distance  @xcite , graph alignment  @xcite and graph kernel functions  @xcite . in this paper , we focus on the graph edit distance since it is applicable to virtually all types of data graphs and can also capture precisely structural differences .",
    "the graph edit distance  @xmath2 between two graphs  @xmath3 and  @xmath4 is defined as the minimum number of edit operations needed to transform one graph to another .",
    "given a graph database  @xmath5 , a query graph  @xmath4 and an edit distance threshold  @xmath6 , the graph similarity search problem aims to find all graphs  @xmath3 in  @xmath5 satisfying @xmath7 .",
    "unfortunately , computing the graph edit distance is known to be an np - hard problem  @xcite .",
    "therefore , for a large transaction database , such as pubchem , which stores information about roughly  50 million chemical compounds , similarity search is very challenging .",
    "most of the existing methods adopt the filter - and - verify schema to speed up the search .",
    "with such a schema , we first filter data graphs that are not possible results to generate a candidate set , and then validate the candidate graphs with the expensive graph edit distance computations .",
    "in general , the existing filters can be divided into four categories : global filter , @xmath0-@xmath1 counting filter , mapping distance - based filter and disjoint partition - based filter .",
    "specifically , number count filter  @xcite and label count filter  @xcite are two global filters .",
    "the former is derived based upon the differences of the number of vertices and edges of comparing graphs .",
    "the later takes labels as well as structures into account , further improving the former .",
    "@xmath8-at  @xcite and gsimjoin  @xcite are two major  @xmath0-@xmath1 counting filters .",
    "they considered a @xmath8-@xmath9 subtree and a simple path of length @xmath10 as a @xmath0-@xmath1 , respectively .",
    "c - star  @xcite and mixed  @xcite are two major mapping distance - based filters .",
    "the lower bounds are derived based on the minimum weighted bipartite graphs between the star and branch structures of comparing graphs , respectively .",
    "pars  @xcite is a disjoint partition - based filter .",
    "it divides each data graph  @xmath3 into several disjoint substructures and prunes  @xmath3 by the subgraph isomorphism .",
    "even though promising preliminary results have been achieved by existing methods gsimjoin  @xcite , c - star  @xcite and mixed  @xcite , our empirical evaluation of all the methods aforementioned showed that they are not scalable to large graph databases .",
    "the critical limitation of existing methods are : ( 1 ) existing filters having a weak filter ability produce large candidate sets , resulting in an unacceptable computational cost for verification , ( 2 ) the index storage cost of the existing methods is too expensive to run properly .",
    "for example , for a database of  10 million graphs , c - star on average produces @xmath11 number of candidates for verification when @xmath12 .",
    "both gsimjoin and mixed produce an index that is too large to fit into the main memory for large input data .",
    "the details of the empirical study are presented in section  [ sec : experiments ] .    to solve the above issues , we propose a space - efficient index structure for graph similarity search which significantly reduces the storage space .",
    "our contributions in this paper are summarized below .",
    "* we propose two effective filters , i.e. degree - based  @xmath0-@xmath1 counting filter and degree - sequence filter , by using the degree structures and label structures .",
    "* we create a @xmath0-@xmath1 tree to speed up filtering process .",
    "more importantly , we propose the succinct representation of the @xmath0-@xmath1 tree which combines with hybrid coding , significantly reducing the space required for the representation of the @xmath0-@xmath1 tree . *",
    "we convert the number count filter to a two - dimensional orthogonal range searching , which helps us perform a query at a reduced region and hence further improves the filtering performance .",
    "* we have conducted extensive experiments over both real and synthetic datasets to evaluate the index storage space , construction time , filtering capability , and response time .",
    "the result is graph similarity search index that we refer to as `` msq - index '' .",
    "it confirms the effectiveness and efficiency of our proposed approaches and show that our method can scale well to cope with the large dataset of 25 million chemical compounds from the pubchem dataset .",
    "the rest of this paper is organized as follows : in section  [ sec : preliminaries ] , we introduce the problem definition . in section  [ sec : filters ] , we present the degree - based @xmath0-@xmath1 counting filter and the degree - sequence filter . in section  [ sec : queryregion ] , we give a method to reduce the query region . in section  [ sec : q - gramindex ] , we introduce the index structure . in section  [ sec : queryprocessing ] , we give the query algorithm . in section  [ sec : experiments ] , we report the experimental results . we investigate the research work related to this paper in section  [ sec : relatedworks ] .",
    "finally , we make concluding remarks in section  [ sec : conclusion ] .",
    "in this section , we introduce the basic notations and definitions of graph edit distance and graph similarity search .",
    "[ def : graph ]    a labeled graph is defined as a six - tuple @xmath13 , where  @xmath14 is the set of vertices , @xmath15 is the set of edges , @xmath16 is the vertex labeling function which assigns a label  @xmath17 to the vertex  @xmath18 , @xmath19 is the edge labeling function which assigns a label  @xmath20 to the edge  @xmath21 , @xmath22 and @xmath23 are the label multisets of  @xmath14 and  @xmath24 , respectively .    in this paper",
    ", we only focus on simple undirected graphs without multi - edge or self - loop .",
    "we use @xmath25 and @xmath26 to denote the number of vertices and edges in @xmath3 , respectively .",
    "the graph size refers to @xmath25 in this paper .",
    "although in the following discussion we only focus on undirected graphs , our methods can be extended to handle directed graphs .",
    "[ def : isomorphism ]    given two graphs @xmath3 and @xmath4 , an isomorphism of graphs @xmath3 and @xmath4 is a bijection @xmath27 , such that ( 1 ) for all @xmath28 , @xmath29 and @xmath30 .",
    "( 2 ) for all  @xmath31 , @xmath32 and @xmath33 .",
    "if  @xmath3 is isomorphic to  @xmath4 , we denote  @xmath34 .",
    "there are six primitive edit operations that can transform one graph to another  @xcite .",
    "these edit operations are inserting / deleting an isolated vertex , inserting / deleting an edge between two vertices and substituting the label of a vertex or an edge .",
    "we denote the substitution of two vertices  @xmath35 and @xmath18 by  @xmath36 , the deletion of vertex  @xmath35 by  @xmath37 , and the insertion of vertex  @xmath18 by @xmath38 . for edges",
    ", we use a similar notation . given two graphs  @xmath3 and @xmath4 , an edit path @xmath39 is a sequence of edit operations that transforms @xmath4 to @xmath3 , such as @xmath40 . in figure",
    "[ fig : fig01 ] , we give an example of an edit path  @xmath41 between  @xmath3 and  @xmath4 , where the vertex labels are represented by different symbols .",
    "the length of @xmath41 is  6 , which consists of two edge deletions , one vertex deletion , one vertex insertion and two edge insertions . in the following sections , we use  @xmath42 to denote the length of @xmath41 .",
    "( 0.5,-1.2)@xmath4    [ def : editpath ]    given two + graphs  @xmath3 and @xmath4 , an edit path @xmath41 between  @xmath3 and  @xmath4 is an optimal edit path if and only if there does not exist another edit path  @xmath43 such that @xmath44 .",
    "the graph edit distance between them , denoted by @xmath2 , is the length of the optimal edit path .",
    "* problem statement * : given a graph database @xmath45 , a query graph @xmath4 , and an edit distance @xmath46 , the problem is to find all the graphs  @xmath3 in  @xmath5 such that @xmath47 , where  @xmath2 is the graph edit distance of graphs  @xmath3 and  @xmath4 defined in definition  [ def : editpath ] .",
    "figure  [ fig : fig02 ] shows a query graph @xmath4 and three data @xmath48  @xmath49 , and @xmath50 . we can obtain that @xmath51 , @xmath52 , and  @xmath53 .",
    "if the edit distance threshold  @xmath6 = 3 , @xmath54 and @xmath50 are the required graphs .",
    "the computation of graph edit distance is an np - hard problem  @xcite . the state - of - the - art approaches like  @xcite for graph similarity search use a filter - and - verify schema to speed up query process . in the filtering phase",
    ", it computes the candidate set @xmath55 , where @xmath56 is the lower bound on @xmath57 . in the verification phase , for each graph @xmath3 in  @xmath58 , it needs to compute @xmath57 .",
    "obviously , it is good for the size  @xmath59 as small as possible .    in this paper , we propose two filters , i.e. , degree - based  @xmath0-@xmath1 counting filter and degree - sequence filter using the degree structures and label structures in a graph . besides , we also use the following two simple but effective global filters , i.e. , number count filter  @xcite and label count filter  @xcite .",
    "number count filter is derived based upon the differences of the number of vertices and edges of comparing graphs and given by @xmath60 .",
    "label count filter improves the number count filter by taking labels as well as structures into account and is given by @xmath61 . by using all of them ,",
    "we can obtain a candidate set as small as possible .",
    "given two graphs @xmath3 and @xmath4 , and an optimal edit path  @xmath41 between them , we group the operations on @xmath41 into five sets of edit operations : vertex deletion group  @xmath62 , vertex insertion group @xmath63 , vertex substitution group @xmath64 , edge deletion group @xmath65 consists of the edge deletions performed on the deleted vertices , and edge operation group @xmath66 consists of the edit operations performed on edges except for those in @xmath67 .",
    "for an optimal edit path @xmath41 between @xmath3 and @xmath4 , the insertion / deletion / substitution edit operation on a vertex  @xmath18 or an edge @xmath21 must happen only once , thus the edit operations in @xmath68 are independent of each other .",
    "therefore , we can obtain an edit path by arbitrarily arranging the edit operations in  @xmath68 . in the rest of this paper",
    ", we use @xmath68 to denote the edit operation set and the edit operation sequence interchangeably when there is no ambiguity .",
    "similarly , @xmath69 , @xmath70 , @xmath67 and @xmath66 could be also considered as the edit operation sets or paths . for an optimal edit path @xmath41",
    ", we can always obtain an optimal edit path @xmath71 by arranging the edit operations in @xmath41 . in the following section , we consider @xmath72 as the default optimal edit path for two given graphs .",
    "[ lem : lem1 ]    given graphs @xmath3 and @xmath4 , and an optimal edit path @xmath41 that transforms  @xmath4 to  @xmath3 , then we have @xmath73 and @xmath74 .",
    "let @xmath72 be an edit optimal path that transforms @xmath4 to @xmath3 .",
    "then we discuss the following three cases .",
    "case i. when @xmath75 .",
    "to transform @xmath4 to @xmath3 , the number of vertex deletions must be equal to that of vertex insertions , i.e. , @xmath76 .",
    "we prove @xmath77 by contradiction . assuming that @xmath78 ,",
    "thus there must exist at least one vertex insertion and one deletion .",
    "let @xmath35 be a deleted vertex and @xmath18 be a inserted vertex .",
    "we construct another edit path @xmath43 by @xmath41 as follows .",
    "first , we substitute the label of  @xmath35 with @xmath17 , and then perform these edit operations on @xmath35 , which were performed on  @xmath18 before in  @xmath66 . finally , we maintain the rest edit operations in @xmath41 .",
    "in other words , we replace @xmath37 and @xmath38 by @xmath36 .",
    "the length of  @xmath43 is @xmath79 , which contradicts the hypothesis that  @xmath41 is an optimal edit path .",
    "therefore , there exists no vertex deletions and insertions in  @xmath41 , i.e. , @xmath80 .",
    "when @xmath81 .",
    "there exists at least @xmath82 vertex insertions in  @xmath41 .",
    "let  @xmath83 be the graph obtained by inserting @xmath82 vertices into  @xmath4 . according to the analysis in case i , no vertex deletions and insertions are needed in an optimal edit path that transforms @xmath83 to  @xmath3 .",
    "thus , @xmath84 @xmath82 vertex insertions are needed in  @xmath41 , i.e. , @xmath85 and @xmath86 .",
    "when @xmath87 .",
    "the proof is similar to the proof of case ii .",
    "we omit it here .",
    "[ def : degreeqgram ]    let @xmath88 be the degree structure of vertex  @xmath18 in graph  @xmath3 , where @xmath17 is the label of  @xmath18 , @xmath89 is the multiset of labels for edges adjacent to  @xmath18 in  @xmath3 , and @xmath90 is the degree of  @xmath18 .",
    "the degree - based @xmath0-@xmath1 set of graph  @xmath3 is defined as @xmath91 .",
    "[ lem : lem2 ]    given two graphs @xmath3 and @xmath4 , if @xmath92 , then we have @xmath93 .",
    "first , we enumerate the effect of various edit operations on  @xmath94 : ( 1 ) vertex insertion / deletion / substitution will affect one degree - based @xmath0-@xmath1 . ( 2 ) edge insertion / deletion/ + substitution will affect two degree - based @xmath0-@xmath95 .",
    "then , without loss of generality we assume that  @xmath96 and prove lemma  [ lem : lem2 ] as follows .",
    "let @xmath97 be an optimal edit path that transforms  @xmath4 to  @xmath3 , such that : @xmath98 , where  @xmath83 is obtained by performing @xmath99 on  @xmath4 , and @xmath3 is obtained by performing @xmath66 on @xmath83 . by lemma  [ lem : lem1 ] , we know that @xmath86 and @xmath100 .",
    "since @xmath67 consists of the edge deletions performed on the deleted vertices , we have @xmath101 . to transform  @xmath4 to  @xmath3 ,",
    "@xmath102 vertex substitutions are needed , thus @xmath103 .",
    "since vertex insertion / substitution only affects one degree - based @xmath0-@xmath1 , we have @xmath104 .",
    "since  @xmath66 only consists of the edit operations performed on edges and each of them affects two degree - based @xmath0-@xmath95 , we have @xmath105 .",
    "thus we have @xmath106 .",
    "[ def : labelqgram ]    the label - based + @xmath0-@xmath1 set of graph  @xmath3 is defined as @xmath107 , where  @xmath22 and @xmath23 are the label multisets of  @xmath14 and  @xmath24 , respectively .    for the label - based @xmath0-@xmath1 , each edit operation @xmath108 one @xmath0-@xmath1 ,",
    "thus we can obtain the label - based @xmath0-@xmath1 counting filter as follows .",
    "if @xmath109 , then we have @xmath110 .",
    "it is a rewritten form of the label count filter  @xcite .",
    "figure  [ fig : fig03 ] shows the degree - based @xmath0-@xmath1 and label - based @xmath0-@xmath1 sets of graphs shown in figure  [ fig : fig02 ] .",
    "note that the number on the left of each subgraph is the times of the  @xmath0-@xmath1 occurring in the graph and we omit the degree value of each degree - based @xmath0-@xmath1 .",
    "( 4.9,-1.7)@xmath54 ( 5.5,-1.7)@xmath111 ( 6.2,-1.7)@xmath50 ( 6.9,-1.7)@xmath4    we use an example to illustrate the degree - based @xmath0-@xmath1 and label - based @xmath0-@xmath1 counting filters . for the graphs  @xmath111 and  @xmath4 shown in figure  [ fig : fig02 ] , if  @xmath6 = 2 , by lemma  [ lem : lem2 ] we have @xmath112 .",
    "thus , @xmath111 will be filtered out . however , for the graph @xmath54 , we have @xmath113 and hence @xmath54 will pass the filter . similarly , only @xmath54 will be filtered out by the label - based @xmath0-@xmath1 counting filter therefore , we can filter  @xmath54 and  @xmath111 out using the degree - based @xmath0-@xmath1 and label - based  @xmath0-@xmath1 counting filters . however , for the graph  @xmath50 shown in figure  [ fig : fig02 ] , none of the above filters can filter it out .",
    "so , we propose another filter , called degree - sequence filter , which utilizes the degrees of vertices .",
    "let @xmath114 $ ] be the degree vector of graph  @xmath3 , where  @xmath115 is the degree of vertex  @xmath116 in  @xmath3 .",
    "the degree sequence  @xmath117 of  @xmath3 is a permutation of @xmath118 satisfying @xmath119 \\geq \\sigma_g[j]$ ] for  @xmath120 . if  @xmath3 is isomorphic to  @xmath4 , then we have  @xmath121 .",
    "therefore , we can compute the lower bound on  @xmath122 using  @xmath117 and @xmath123 .    [",
    "def : degreedistance ] given + two degree vectors  @xmath124 and @xmath125 such that @xmath126 = @xmath127 .",
    "the distance between them is defined as @xmath128 \\leq \\pi_g[i]}(\\pi_g[i]-\\pi_h[i])/2 \\rceil + \\lceil \\sum_{\\pi_h[i ] >",
    "\\pi_g[i]}(\\pi_h[i]-\\pi_g[i])/2 \\rceil$ ] .",
    "[ lem : lem3 ]    let @xmath129 and @xmath130 be two degree vectors such that @xmath131 in non - increasing order . for any bijection function @xmath132 , we have @xmath133 , where @xmath134 = y[f(i)]$ ] for @xmath135 .    for degree vectors  @xmath129 and  @xmath130 , let @xmath136 \\leq y[i]}(y[i]-x[i])$ ] and @xmath137 > y[i ] } ( x[i]-y[i])$ ] .",
    "we have @xmath138 .",
    "we want to prove @xmath139 and @xmath140 , where @xmath134 = y[f(i)]$ ] for @xmath135 .",
    "we prove this claim for  @xmath129 and  @xmath141 by induction on the vector length  @xmath142 .",
    "and similar claim holds for  @xmath130 and  @xmath141 .    for the base case @xmath143 ,",
    "it is trivial that @xmath139 and @xmath140 . for the inductive step , we assume that @xmath144 and @xmath145 for  @xmath146 where @xmath147 , \\ldots , x[k]]$ ] .",
    "we then prove the claim holds for @xmath148 .",
    "first , without loss of generality , we assume that @xmath149 , and @xmath150 \\geq y[i]$ ] , thus we have @xmath151 and @xmath152 - y[i]$ ]",
    ". then we consider the following three cases .",
    "case i. when @xmath150 \\geq x[k+1 ] \\geq y[i ] \\geq y[k+1]$ ] .",
    "@xmath153-y[i ] + x[k+1]-y[k+1 ] \\\\                        & = s_2(x^k , z^k ) + x[k+1]-y[k+1 ] \\\\                        & \\geq s_2(x^k , y^k ) + x[k+1]-y[k+1 ] \\\\                        & = s_2(x^{k+1 } , y^{k+1 } ) .",
    "\\end{aligned}\\ ] ]    case ii .",
    "\\geq y[i ] \\geq x[k+1 ] \\geq y[k+1]$ ] .",
    "@xmath154 { \\begin{aligned } s_1(x^{k+1 } , z^{k+1 } ) & = s_1(x^{k-1 } , z^{k-1 } ) + y[i ] - x[k+1]\\\\                        & = s_1(x^k , z^k ) + y[i]-x[k+1]\\\\                        & \\geq s_1(x^k , y^k ) = s_1(x^{k+1 } , y^{k+1}).\\\\ s_2(x^{k+1 } , z^{k+1 } ) & = s_2(x^{k-1 } , z^{k-1 } ) + x[i]-y[k+1 ] \\\\                        &",
    "= s_2(x^k , z^k ) - ( x[i ] - y[i ] ) + x[i]-y[k+1 ] \\\\                        & = s_2(x^k , z^k ) + y[i ] - y[k+1 ] \\\\                        & \\geq s_2(x^k , y^k ) + x[k+1 ] - y[k+1 ] \\\\                        & = s_2(x^{k+1 } , y^{k+1 } ) . \\end{aligned }",
    "% } \\ ] ]    case iii .",
    "\\geq y[i ] \\geq y[k+1 ] \\geq x[k+1]$ ] .",
    "@xmath154 { \\begin{aligned } s_1(x^{k+1 } , z^{k+1 } ) & = s_1(x^{k-1 } , z^{k-1 } ) + y[i ] - x[k+1]\\\\                        & = s_1(x^k , z^k ) + y[i ] - x[k+1]\\\\                        & \\geq s_1(x^k , y^k ) + y[k+1 ] - x[k+1 ] \\\\                        & = s_1(x^{k+1 } , y^{k+1}).\\\\ s_2(x^{k+1 } , z^{k+1 } ) & = s_2(x^{k-1 } , z^{k-1 } ) + x[i ] - y[k+1]\\\\                        & = s_2(x^k , z^k ) - ( x[i ] - y[i ] ) + x[i ] - y[k+1]\\\\                        & = s_2(x^k , z^k ) + y[i ] - y[k+1]\\\\                        & \\geq s_2(x^k , y^k ) = s_2(x^{k+1 } , y^{k+1 } ) . \\end{aligned } % } \\ ] ]    finally , we note that @xmath155 , and hence we have @xmath133 .    [ lem : lem4 ]    given two graphs  @xmath3 and  @xmath4 with  @xmath156 , then we have @xmath157 .",
    "let  @xmath158 be the bijection from the vertices in @xmath4 to that in  @xmath3 to ensure that the induced edit path is an optimal edit path .",
    "assuming that @xmath159 $ ] and @xmath160 $ ] be the respective degrees of a vertex  @xmath18 in @xmath4 and the corresponding vertex  @xmath35 in  @xmath3 .",
    "if @xmath159 \\leq \\sigma_g[f(i)]$ ] , we must insert at least @xmath161-~\\sigma_h[i])$ ] edges on  @xmath18 ; otherwise , we must delete at least @xmath162-\\sigma_g[f(i)])$ ] edges .",
    "since one edge insertion / deletion affects degrees of two vertices , we must insert at least @xmath163 \\leq \\sigma_g[f(i ) ] } ( \\sigma_g[f(i)]-~\\sigma_h[i])/2 \\rceil$ ] edges .",
    "similarly , we also need to delete at least @xmath163>\\sigma_g[f(i ) ] } ( \\sigma_h[i]-\\sigma_g[f(i)])/2 \\rceil$ ] edges .",
    "thus , we have @xmath164 , where @xmath165 = \\sigma_g[f(i)]$ ] for @xmath166 . by lemma  [ lem : lem3 ]",
    ", we have @xmath167 .",
    "[ lem : lem5 ]    given two + graphs @xmath3 and @xmath4 , and an edit distance threshold  @xmath6 , if + @xmath109 , then we have @xmath168 , where @xmath169 } + \\delta(\\sigma_g , \\sigma_{\\id{h_1}})\\ } & \\idrm{otherwise}. \\\\ \\end{array } \\right.\\ ] ] @xmath170,\\ldots , \\sigma_h[|\\id{v_h}| ] , 0_1,\\dots,0_{|\\id{v_g}|-|\\id{v_h}|}]$ ] and @xmath83 is a subgraph of  @xmath4 obtained by deleting @xmath171 vertices .",
    "let @xmath97 be an optimal edit path that converts  @xmath4 to  @xmath3 , satisfying @xmath172 , where  @xmath83 is obtained by performing @xmath173 on  @xmath4 , @xmath174 is obtained by performing @xmath175 on  @xmath83 and @xmath3 is obtained by performing  @xmath66 on  @xmath174 .",
    "then we discuss the following two cases .",
    "case i. when @xmath176 .",
    "we have @xmath86 and @xmath85 and @xmath177 by lemma  [ lem : lem1 ] .",
    "to transform  @xmath83 to  @xmath174 , @xmath102 vertex substitutions are needed in  @xmath41 , thus we have @xmath178 .",
    "since @xmath174 is obtained by performing @xmath99 on @xmath4 , we have @xmath179,\\ldots , \\sigma_h[|\\id{v_h}| ] , 0_1,\\dots,0_{|\\id{v_g}|-|\\id{v_h}|}]$ ] . by lemma  [ lem : lem4 ]",
    ", we have @xmath180",
    ". therefore @xmath181 .",
    "when @xmath182 .",
    "we have  @xmath183 and @xmath184 by lemma  [ lem : lem1 ] . to transform @xmath4 to @xmath83 ,",
    "the number of edge deletions in @xmath67 is @xmath185/2 $ ] . since",
    "only @xmath102 vertex substitutions are needed to transform  @xmath83 to  @xmath174 , we have @xmath186 and @xmath187 . by lemma  [ lem : lem4 ] , we also have @xmath188 . therefore @xmath189/2 + \\delta(\\sigma_g , \\sigma_{h_1})\\ } = |\\id{v_h}|-|\\sigma_{\\id{v_g } } \\cap \\sigma_{\\id{v_h}}|+\\idrm{min}_{h_1}\\{|\\id{e_h}|- \\sum_j\\sigma_{h_1}[j]/2+\\delta(\\sigma_g , \\sigma_{h_1})\\}$ ] .",
    "we use an example to illustrate the degree - sequence filter . for the graphs",
    "@xmath4 and  @xmath50 shown in figure  [ fig : fig02 ] , we can compute @xmath190 $ ] and @xmath191 $ ] . by lemma  [ lem : lem5 ]",
    ", if @xmath192 , then we have @xmath193 , then we can filter  @xmath50 out .",
    "given a database @xmath5 , we consider each graph  @xmath3 in  @xmath5 as a point in the two - dimensional plane where the x - coordinate and y - coordinate denote the number of vertices and edges in  @xmath3 , respectively .",
    "thus the graph database  @xmath5 can be represented as a set of points @xmath194 .",
    "these points form a rectangle area @xmath195 \\times [ y_{min } , y_{max}]$ ] , where @xmath196 and @xmath197 for @xmath198 . by partitioning  @xmath199 into subregions",
    ", we can perform a query at a reduced query region .",
    "given an initial division point @xmath200 and a length  @xmath201 , we partition  @xmath199 into disjoint subregions as follows .",
    "first , we construct the initial square subregion @xmath202 formed by the point set @xmath203 .",
    "then , we extend along the surrounding of @xmath202 to obtain subregions @xmath204 of the same size with @xmath202 , where @xmath205 and @xmath206 denote the relative offsets with respect to @xmath202 in lines @xmath207 and @xmath208 , respectively .",
    "finally , we repeat this process until all points in  @xmath199 are exhausted .",
    "then  @xmath199 is partitioned into some disjoint subregions such that @xmath209 and @xmath210 for all @xmath211 and  @xmath212 .",
    "note that @xmath205 and @xmath206 can be negative .",
    "[ label : queryrectangle ]    given + a query graph @xmath4 and an edit distance threshold  @xmath6 , query rectangle  @xmath213 of @xmath4 is the rectangle formed by the point set of @xmath214 .",
    "the query region  @xmath215 of  @xmath4 is the union of all subregions intersecting with  @xmath213 , i.e. , @xmath216 such that  @xmath217 .    for graphs @xmath3 and @xmath4 ,",
    "if @xmath218 , then we have @xmath219 .",
    "according to the definition of  @xmath213 , we know that @xmath220 . since @xmath221 and @xmath222 , we have @xmath223 .",
    "therefore we have @xmath224 and hence can reduce the query region from  @xmath199 to  @xmath215 .",
    "in the example of figure  [ fig : fig04 ] , we have @xmath225 and then only need to perform the query at  @xmath215 .    , @xmath215 and @xmath199,width=288 ]    for a two - dimensional point @xmath226 , its coordinates in lines @xmath227 and @xmath228 are @xmath229 , thus its relative offsets with respect to @xmath200 are @xmath230 and @xmath231 in @xmath207 and @xmath208 , respectively",
    ". since the side length of a subregion is @xmath232 , the respective relative offsets with respect to @xmath202 are @xmath233 and @xmath234 in @xmath207 and @xmath208 .",
    "since the subregions in @xmath215 are adjacent , we just need to find the boundaries of subregions intersecting with @xmath213 using the following formula .",
    "@xmath235    where @xmath236 and @xmath237 are the relative positions of the subregion in the lower left corner of  @xmath215 with respect to  @xmath202 in @xmath227 and @xmath228 , respectively , @xmath238 and @xmath239 are the respective relative positions of the subregion in the top right corner of @xmath215 with respect to @xmath202 in @xmath227 and @xmath228 .",
    "recall that we partitioned the region @xmath199 into some subregions and then obtained a reduced query region @xmath215 . in order to efficiently filter the graphs mapped into @xmath215",
    ", we introduce a space - efficient index structure via succinct representation of the @xmath0-@xmath1 tree as follows .",
    "let @xmath240 and @xmath241 be the sets of all distinct degree - based @xmath0-@xmath95 and label - based @xmath0-@xmath95 occurring in @xmath5 , respectively , where @xmath242 and @xmath243 are the  @xmath205th most frequently occurring degree - based @xmath0-@xmath1 and label - based @xmath0-@xmath1 in  @xmath5 , respectively .",
    "we use a four - tuple @xmath244 to represent a graph  @xmath3 , where  @xmath245 and  @xmath246 are the number of vertices and edges in  @xmath3 , respectively , @xmath247 and  @xmath248 are two arrays to store the degree - based @xmath0-@xmath1 and label - based @xmath0-@xmath1 sets @xmath94 and @xmath249 , respectively , where  @xmath250}$ ] and  @xmath251}$ ] are the respective number of occurrences of the degree - based @xmath0-@xmath1 @xmath242 in  @xmath94 and the label - based @xmath0-@xmath252 in  @xmath249 .",
    "[ def : four - union ] given two four - tuples @xmath253 and @xmath254 , the union operator `` @xmath255 '' of  @xmath253 and  @xmath254 is defined as : @xmath256 , where @xmath257 = \\left \\ { \\begin { array}{ll }      \\idrm{max}\\{\\id{f_d[i]},\\id{f_d'[i]}\\ }   & \\idrm{if } \\",
    "i < \\idrm{min}\\{|\\id{f_d}| , |\\id{f_d'}|\\ } ; \\\\",
    "\\id{f_d[i ] }                      & \\idrm{if } \\",
    "|\\id{f_d'}| \\leq i < |\\id{f_d}| ; \\\\       \\id{f_d'[i ] }                     & \\idrm{if } \\",
    "|\\id{f_d}| \\leq i < |\\id{f_d'}|.\\\\ \\end{array } \\right.\\\\\\ ] ] and similar definition for @xmath258 .",
    "similarly , the union of multiple four - tuples can be defined recursively .",
    "a q - gram tree is a balanced tree such that each leaf node stores the four - tuple  @xmath253 of the data graph  @xmath3 and each internal node is the union of its child nodes .",
    "figure  [ fig : fig05 ] gives an example of a @xmath0-@xmath1 tree built on  @xmath54 , @xmath111 , and  @xmath50 shown in figure  [ fig : fig02 ] .",
    "the arrays @xmath247 and @xmath248 may contain lots of zeros , thus a succinct representation of them is a space - efficient way to store them . for a @xmath0-@xmath1 tree ,",
    "we obtain its succinct representation by performing the following three steps . in the following sections , we refer  @xmath259 to be  @xmath260 or  @xmath261 .",
    "\\(1 ) we use a bit vector @xmath262 and an array @xmath263 to represent  @xmath264 as follows : if @xmath265 } = 0 $ ] then we have @xmath266 } = 0 $ ] ; otherwise @xmath266 } = 1 $ ] .",
    "@xmath267}$ ] represents the  @xmath206th nonzero entry in  @xmath264 .",
    "for example , the array  @xmath247 in the node @xmath268 shown in figure  [ fig : fig05 ] is @xmath247 = [ 3 1 0 0 1 0 1 ] , then we use ( @xmath269 , @xmath270 ) = ( [ 1 1 0 0 1 0 1 ] , [ 3 1 1 1 ] ) to represent @xmath247 .",
    "\\(2 ) we concatenate all bit vectors @xmath262 and arrays  @xmath263 for all nodes from the root node to leaves in a depth - first traversal order to obtain a bit vector  @xmath271 and an array  @xmath272 , respectively .",
    "in addition , we also store the left and right boundaries @xmath273 and @xmath274 of @xmath262 for each node , respectively .",
    "for example , for the @xmath0-@xmath1 tree shown in figure  [ fig : fig05 ] , we can obtain @xmath275 = [ 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 ] and @xmath276 = [ 3 1 1 1 1 1 1 3 1 1 1 1 1 1 3 1 1 1 1 1 ] .",
    "\\(3 ) we divide @xmath272 into fixed - length blocks of size  @xmath277 and encode each block by choosing one from two different compression methods so that the encoded bit vector  @xmath278 has the minimum space .",
    "one compression method uses the fixed - length encoding of @xmath279 bits to encode each entry in a fixed - length encoding block , where @xmath280 is the maximum value in this block .",
    "the other method uses elias  @xmath281 encoding to encode each entry in a @xmath281-encoding block .",
    "logarithms in this paper are in base 2 unless otherwise stated .    to support random access to  @xmath282}$ ]",
    ", we also need to store three auxiliary structures  @xmath283 , @xmath284 , and @xmath285 , where  @xmath283 stores the starting position of the encoding of each block in  @xmath278 ; the bit vector  @xmath285 stores the encoding method used in each block such that @xmath286 = 1 $ ] for the fixed - length encoding and @xmath286 = 0 $ ] for the elias  @xmath281 encoding for the @xmath287th block ; @xmath284 stores the number of bits required for each entry in a fixed - length encoding block .",
    "we also build rank dictionaries over the bit vectors @xmath271 and  @xmath285 to obtain @xmath288 and @xmath289 in constant time  @xcite , where @xmath288 and @xmath289 are the respective number of 1 s up to @xmath206 in @xmath271 and @xmath285 .",
    "let @xmath275 and @xmath290 be the respective degree - based and label - based @xmath0-@xmath95 bit vectors , and @xmath276 and  @xmath291 be the respective degree - based and label - based @xmath0-@xmath1 frequency arrays .",
    "we use four structures @xmath292 , @xmath293 , @xmath294 , and  @xmath295 to represent  @xmath276 .",
    "similarly , we use four structures @xmath296 , @xmath297 , @xmath298 , and @xmath299 to represent @xmath291 .",
    "figure  [ fig : fig06 ] shows the succinct representation of the @xmath0-@xmath1 tree shown in figure  [ fig : fig05 ] .",
    "( a )        ( b )        ( c )      to access @xmath282}$ ] , we first query @xmath285 and  @xmath283 to determine the encoding method used and decoding position , respectively , and then decode  @xmath278 from the decoding position .",
    "the last decoded value is @xmath282}$ ] .",
    "@xmath301}= decompress(\\id{s_x } , \\id{flag_x}[\\lfloor j / b \\rfloor],\\ \\id{sb_x}[\\lfloor j / b \\rfloor ] , { } \\\\                  ( j \\ \\idrm{mod } \\ b ) + 1)\\end{gathered}\\ ] ]    where @xmath277 is the block size .",
    "the operation @xmath302 performs a decoding on @xmath278 . the encoding method and decoding position",
    "are determined by the second parameter @xmath303 $ ] and third parameter @xmath304 $ ] of @xmath302 , respectively .",
    "( @xmath305 ) + 1 is the number of times needed to be decoded .",
    "for example , if we want to retrieve @xmath306 $ ] ( suppose that the subscript starts from 0 and @xmath307 ) shown in figure  [ fig : fig06 ] , we find that @xmath308=\\id{flag_d}[3]=0 $ ] and @xmath309=\\id{sb_d}[3]=16 $ ] . thus starting from the  @xmath310th bit of @xmath292",
    ", we sequentially decode elias  @xmath281 encoding three times and the last decoded value is @xmath306=3 $ ] .",
    "we use the following formula  ( [ eq : eq3 ] ) to compute the original entry  @xmath311}$ ] in the node  @xmath268 .",
    "@xmath312 } = \\left \\ { \\begin { array}{ll }            0                               & \\idrm{if } \\id{b_x}[l_x + i ] = 0;\\\\      \\id{\\varpsi_x}[rank_1(b_x , l_x + i ) ] & \\idrm{otherwise . } \\\\",
    "\\end{array } \\right .",
    "\\label{eq : eq3}\\ ] ]    where @xmath313 , and @xmath273 and  @xmath274 are the left and right boundaries of @xmath262 for  @xmath268 , respectively . if @xmath314",
    "= ~0 $ ] , then we have @xmath315 = 0 $ ] since @xmath316 = \\id{b_x}[l_x + i ] = 0 $ ] ; otherwise , we first compute the position of @xmath315 $ ] in @xmath272 , i.e. , @xmath317 , and then use formula  ( [ eq : eq2 ] ) to compute @xmath318 $ ] , where @xmath317 is the number of 1 s up to  @xmath319 in  @xmath271 , which can be computed in constant time using a dictionary of @xmath320 bits  @xcite .    for example , to retrieve @xmath321 $ ] in the node  @xmath111 shown in figure  [ fig : fig05 ] ,",
    "we first obtain @xmath322 = \\id{b_d}[19 ] = 1 $ ] , and then compute its position in @xmath276 is @xmath323 , thus we have @xmath321 = \\id{\\varpsi_d}[14 ] = 3 $ ] by formula  ( [ eq : eq2 ] ) .    as discussed above , the core operation in a succinct @xmath0-@xmath1 tree",
    "is to calculate @xmath324 $ ] by formula  ( [ eq : eq2 ] ) , i.e. ,  the @xmath302 operation . in order to accelerate the @xmath302 process",
    ", we use the look up table technique proposed in  @xcite to ensure that the @xmath302 operation takes a constant time .",
    "in this section we analyze the space occupied by the succinct @xmath0-@xmath1 tree @xmath325 built on @xmath5 .",
    "@xmath325 consists of three parts : the respective index structures for @xmath326 and @xmath327 , and left and right boundaries , # vertices and # edges in each node of the tree .",
    "the former contains encoded sequence @xmath278 and corresponding auxiliary structures @xmath271 , @xmath283 , @xmath285 and @xmath284 ; the latter consists of  @xmath273 , @xmath274 , @xmath245 and @xmath246 stored in each node of @xmath325 , where  @xmath259 denotes  @xmath260 or @xmath261 .",
    "an illustration of these structures is shown in figure  [ fig : fig06 ] .",
    "let @xmath328 , @xmath329 for @xmath330 , @xmath331 , @xmath332 , @xmath333 and @xmath334 be the maximum value in @xmath276 and @xmath291 , respectively .",
    "for a degree - based @xmath0-@xmath1 , its maximum number of occurrence in a graph @xmath3 is @xmath335 , thus we have @xmath336 .",
    "similarly , @xmath337 . we first consider the space required by  @xmath273 , @xmath274 , @xmath338 and @xmath339 .    for any node of @xmath325",
    ", we use @xmath340 bits to store @xmath341 and @xmath342 , respectively , and @xmath343 bits to store @xmath344 and @xmath345 , respectively , since @xmath346 and @xmath347 .",
    "we also use respective @xmath348 and @xmath349 bits to store @xmath338 and @xmath339 , since @xmath350 and @xmath351 . for an average fan - out of  @xmath352 for each node in @xmath325 with @xmath353 leaf nodes ,",
    "the total number of nodes in  @xmath325 is bounded by @xmath354 .",
    "thus , we can use @xmath355 bits to store each child pointer of a node in  @xmath325 .",
    "thus , the total number of bits required by @xmath341 , @xmath342 , @xmath344 , @xmath345 , @xmath338 , @xmath339 and pointers for all nodes in @xmath325 is bounded by    @xmath356    we then consider the space required by @xmath278 , @xmath271 , @xmath283 , @xmath285 and @xmath284 .    first we analyze the space needed by the encoded sequence @xmath278 .",
    "let @xmath357 and @xmath358 be the respective collection of blocks with @xmath281 encoding and fixed - length encoding , and @xmath359 and @xmath360 be the respective number of bits needed to encode the @xmath205th block @xmath361 using @xmath281 encoding and fixed - length encoding . by our hybrid encoding scheme ,",
    "the number of bits required by  @xmath278 is bounded by    @xmath362 where the first inequality is due to the fact that @xmath363 when @xmath364 .",
    "the number of bits required to encode block @xmath361 of @xmath272 using fixed - length encoding is bounded by @xmath365 .",
    "the third inequality is due to the fact that @xmath366 , where @xmath277 is the block size .",
    "second , we analyze the space required by auxiliary structures @xmath271 , @xmath283 , @xmath285 and @xmath284 .    for bit vector @xmath271 , the total number of bits required to store it and its rank dictionary is @xmath367 bits , where  @xmath320 is the space in bits required by the rank dictionary built on @xmath271 @xcite .    for @xmath283 ,",
    "the space needed is @xmath368 in bits in the worst case since each entry needs @xmath369 bits and there are @xmath370 blocks .    for @xmath285 , it is trivial that the total number of bits required is @xmath371 bits , since each block takes one bit and there are total @xmath370 blocks .",
    "the rank dictionary built on @xmath285 needs @xmath372 bits .",
    "for @xmath284 , the space used is bounded by @xmath373 , since each entry requires @xmath374 bits to store and there are  @xmath370 entries in the worst case .    putting all space needed for auxiliary structures @xmath271 , @xmath283 , @xmath285 and @xmath284 together ,",
    "we then obtain    @xmath375    by adding @xmath376 bits required by  @xmath278 to the space required by auxiliary structures , we obtain that the space is @xmath377 bits .    by summing up all space for  @xmath325 and replacing  @xmath259 with  @xmath260 or  @xmath261 , we obtain that the succinct @xmath0-@xmath1 tree @xmath325 takes @xmath378 bits of space .",
    "our query process consists of two phrases . we first compute the reduced query region  @xmath379 by formula  ( [ eq : eq1 ] ) , and then perform the query on the succinct @xmath0-@xmath1 trees built on the graphs mapped into  @xmath379 .",
    "we introduce the query method on the succinct @xmath0-@xmath1 tree  @xmath380 in this section .",
    "[ lem : lem6 ]    let @xmath381 and @xmath382 be the respective number of common degree - based and label - based @xmath0-@xmath95 between any internal node  @xmath268 of  @xmath380 and the query graph @xmath4 , if @xmath383 or @xmath384 , then we can safely prune all child nodes of @xmath268 , where  @xmath245 and  @xmath246 are the number of vertices and edges in @xmath268 , respectively .",
    "let @xmath385 denote the four - tuple of  @xmath129 , where @xmath129 is a node in @xmath380 .",
    "for any internal node  @xmath268 and a query graph @xmath4 , we have @xmath386 , \\id{h.f_d}[i]\\}$ ] . according to definition",
    "[ def : four - union ] , for a child node  @xmath387 of @xmath268 we have @xmath388 \\leq \\id{w.f_d}[i]$ ] .",
    "therefore , for a descendent leaf node ( i.e. , graph ) @xmath3 of  @xmath268 , we have @xmath389 , \\id{h.f_d}[i]\\ } \\leq \\cdots \\leq \\sum_i\\idrm{min}\\{\\id{w_j.f_d}[i ] , \\id{h.f_d}[i]\\ } \\leq \\sum_i\\idrm{min}\\{\\id{w.f_d}[i ] , \\id{h.f_d}[i]\\ } = ~\\id{c_d}$ ] .",
    "similarly , we also have @xmath390 and @xmath391 .",
    "if  @xmath392 , then we have @xmath393 and can safely prune graph  @xmath3 by lemma  [ lem : lem3 ] . similarly ,",
    "if @xmath394 , then we have @xmath395 and then can safely prune @xmath3 by the label - based @xmath0-@xmath1 counting filter .",
    "so , we can safely prune all child nodes of  @xmath268 .",
    "algorithm  [ alg : searchqtree ] gives the query algorithm on  @xmath380 , where  @xmath396 is the root node , @xmath397 is the four - tuple of  @xmath268 , @xmath341 and  @xmath342 are the left and right boundaries of  @xmath269 for  @xmath268 in  @xmath380 , respectively .",
    "@xmath398 compute the four - tuple @xmath399 and degree sequence @xmath123 of @xmath4 @xmath400(@xmath401 ) @xmath58 * procedure * @xmath400(@xmath402 ) @xmath403 , \\id{f_l'}[i]\\}$ ]    in algorithm  [ alg : searchqtree ] , we first compute the four - tuple @xmath404 and degree sequence @xmath123 of  @xmath4 in line  2 , respectively , and then perform the search processing @xmath405 starting from a node  @xmath268 initialized to  @xmath396 , the root node of @xmath380 as follows .",
    "first , we determine whether a node @xmath268 needs to be pruned based upon lemma  [ lem : lem6 ] in lines  612 . in lines  6 and  8",
    ", we compute the number of common label - based @xmath0-@xmath95 @xmath406 and degree - based @xmath0-@xmath95 @xmath381 between  @xmath268 and  @xmath4 , respectively .",
    "note that , each entry @xmath407 $ ] and @xmath408 $ ] are compressed in @xmath276 and @xmath291 , respectively , thus we need to use formula ( 3 ) to compute them . if @xmath409 or @xmath410 , we prune @xmath268 ; otherwise each subtree of @xmath268 will be accessed in lines 1112 .",
    "then , we determine whether a node @xmath268 needs to be pruned based upon lemma  [ lem : lem2 ] in line  13 , i.e. , the degree - based @xmath0-@xmath1 counting filter .",
    "if @xmath411 , we prune  @xmath268 , where @xmath412 is the number of common vertex labels between @xmath268 and @xmath4 obtained while computing  @xmath382 . finally , we first obtain the degree sequence @xmath413 and then determine whether @xmath268 needs to be pruned based upon lemma  [ lem : lem5 ] , i.e. , the degree - sequence filter . in lines  1415 , we first compute the array  @xmath414 storing the degree - based @xmath0-@xmath1 set of @xmath268 and then obtain  @xmath413 using @xmath414 and @xmath415 in line 16 , where @xmath415 is a table storing the mapping between a degree - based @xmath0-@xmath1 and its identifier .",
    "if @xmath416 , then we prune @xmath268 ; otherwise , it passes all filters to become a candidate .",
    "algorithm  [ alg : search ] gives the whole query algorithm , where  ( @xmath417 ) is the initial division point , @xmath201 is the subregion length and @xmath418 is the succinct @xmath0-@xmath1 tree built on the graphs mapped into the subregion  @xmath419 .",
    "@xmath398 @xmath420 for all @xmath421 and @xmath422 @xmath58    in algorithm  [ alg : search ] , we first compute the query region  @xmath215 by formula  ( [ eq : eq1 ] ) in line 2 , where @xmath236 , @xmath238 , @xmath237 and @xmath239 .",
    "then we only need to perform the query on the @xmath0-@xmath1 trees  @xmath423 built on these subregions @xmath419 satisfying @xmath424 in lines  35 . for each candidate graph",
    "@xmath3 in  @xmath58 , we can use the methods in  @xcite to compute the edit distance between  @xmath3 and  @xmath4 to seek for the required graphs .",
    "in this section , we evaluate the performance of our proposed method and compare it with c - star  @xcite , gsimjoin  @xcite and mixed  @xcite on the real and synthetic datasets .",
    "we choose several real and synthetic datasets to test the performance of the above approaches in our experiment , described as follows :    \\(1 ) aids ] .",
    "it is a dtp aids antivirus screen compound dataset from the development and therapeutics program in nci / nih to discover compounds capable of inhibiting the hiv virus .",
    "it contains 42687 chemical compounds .",
    "we generate the labeled graphs from these chemical compounds and omit hydrogen atoms as did in  @xcite .",
    "\\(2 ) pubchem .",
    "it is a nih funded project to record experimental data of chemical interactions with biological systems .",
    "it contains more than 50 million chemical compounds until today .",
    "we randomly select 25 million chemical compounds to make up the large dataset pubchem-25 m used in this experiment .",
    "\\(3 ) synthetic .",
    "the synthetic datasets are generated by the synthetic graph data generator graphgen .",
    "the synthetic generator can create a labeled and undirected graph dataset .",
    "it allows us to specify various parameters , including the dataset size , the average graph density @xmath425 , the number of edges in a graph , and the number of distinct vertex and edge labels in the dataset , respectively . in order to evaluate the performance of the above approaches on the density graphs , we generate the dataset s100k.e30.d50.l5 , which means that this dataset contains 100000 graphs ; the average density of each graph is 50%",
    "; the number of edges in each graph is 30 ; and the number of distinct vertex and edge labels are 5 and 2 , respectively .    for each dataset , we randomly select 50 graphs from it as its query graphs .",
    "table  [ tab : statistics ] summarizes some general characteristics of the three datasets described above .",
    ".statistics of the three data sets [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     we have conducted all experiments on a hp z800 pc with a 2.67 ghz cpu and 24 gb memory , running ubuntu 12.04 operating system . we implemented our algorithm in c++ , with @xmath426 to compile and run . for gsimjoin , we set @xmath427 for the sparse graphs in datasets aids and pubchem-25 m , and @xmath428 for the density graphs in dataset s100k.e30.d50.l5 , which are the recommended values  @xcite . in the following sections , we refer msq - index to our index structure and set the subregion length @xmath429 and block size @xmath430 , respectively .      in this section",
    ", we introduce extensive experiments to evaluate index construction performance of c - star , gsimjoin , mixed and msq - index .      in order to evaluate the effectiveness of our hybrid encoding ,",
    "we compare it with fixed - length encoding , elias  @xmath431 encoding , golomb encoding , and elias  @xmath281 encoding .    for each dataset",
    "described in table  [ tab : statistics ] , we show the number of bits on the average required by each entry in @xmath276 and @xmath291 in table  [ tab : averagebits ] when applying fixed - length encoding ( @xmath158 ) , elias  @xmath431 encoding ( @xmath431 ) , golomb encoding ( @xmath3 ) , elias  @xmath281 encoding ( @xmath281 ) and hybrid encoding ( @xmath4 ) to @xmath276 and @xmath291 , where s100k and pub-25 m stand for s100k.e30.d50.l5 and pubchem-25 m , respectively .",
    "each entry in @xmath276 and @xmath291 uses about between  4 and 6 bits on the tested data , which is much smaller than that used to represent an entry in the previous state - of - the - art indexing methods compared in this paper .         & & + & @xmath158 & @xmath3 & @xmath431 & @xmath281 & @xmath4 & @xmath158 & @xmath3 & @xmath431 & @xmath281 & @xmath4 + aids & 4.51 & 4.25 & 3.68 & 3.57 & * 3.51 * & 5.97 & 6.23 & 6.17 & 6.13 & * 5.93 * + s100k & 3.33 & 4.04 & 3.31 & 3.18 & * 3.08 * & 4.01 & 4.75 & 4.5 & 4.27 & * 3.88 * + pub-25 m & 4.57 & 4.19 & 3.62 & 3.61 & * 3.36 * & 5.73 & 6.07 & 5.85 & 5.79 & * 5.31 * +    among all the encoding methods shown in table  [ tab : averagebits ] , hybrid encoding gives the minimum space . compared with fixed - length encoding , the average number of bits required for hybrid encoding decreases by about 10% .     &",
    "@xmath432 & @xmath433 & @xmath434 & @xmath435 & @xmath436 & @xmath437 + aids & 0.29 & 6.09 & 2.11 & 0.51 & 0.39 & 0.27 + s100k & 0.53 & 5.45 & 7.78 & 1.13 & 0.29 & 0.44 + pub-25 m & 343.58 & 3669.91 & 2014.12 & 598.1 & 303.83 & 237.21 +    in table  [ tab : indexsize ] , we report the storage space of the @xmath0-@xmath1 tree @xmath438 and its succinct representation @xmath325 built on the above three datasets . for @xmath438",
    ", we decompose its storage space into three parts @xmath432 , @xmath433 and @xmath434 , where @xmath432 is the storage space of @xmath439 and pointers of all nodes , and @xmath433 and @xmath434 are the storage space of @xmath247 and @xmath248 of all nodes , respectively .",
    "correspondingly , @xmath435 is the storage space of @xmath338 , @xmath339 , @xmath341 , @xmath342 , @xmath344 , @xmath345 and pointers of all nodes , shown in figure  [ fig : fig06](a ) .",
    "@xmath436 is total storage space of @xmath275 , @xmath292 , @xmath293 , @xmath295 and @xmath294 , shown in figure  [ fig : fig06](b ) , and @xmath437 is total storage space of @xmath290 , @xmath296 , @xmath297 , @xmath299 and @xmath298 , shown in figure  [ fig : fig06](c ) .    from table  [ tab : indexsize ]",
    ", we know that @xmath433 and @xmath434 take up most amount of storage space of @xmath438 , thus a succinct representation of @xmath247 and @xmath248 of all nodes is an efficient way to reduce the storage space of @xmath438 . compared with @xmath433 and @xmath434 , both @xmath436 and @xmath437 can be reduced by more than 90% .",
    "this is because that ( 1 ) only nonzero entries are needed to encode in the succinct representation ; ( 2 ) our hybrid encoding will greatly reduce the number of bits required for each nonzero entry .",
    "compared with the storage space of @xmath438 ( the sum of @xmath432 , @xmath433 and @xmath434 ) , the storage space of @xmath325 ( the sum of @xmath435 , @xmath436 and @xmath437 ) can be reduced by more than 80% .",
    "thus , the succinct representation of @xmath0-@xmath1 tree can greatly reduce the storage space .",
    "we vary the size of datasets to evaluate the index storage space and construction time , and show the results in figure  [ fig : fig08 ] . regarding the index size , mixed consumes the most amount of space in aids and pubchem-25 m since it has to store all branch and disjoint structures .",
    "however , gsimjoin does not perform well in s100k.e30.d50.l5 since the number of paths increases exponentially in the dense graphs .",
    "msq - index performs the best and its index size is only 5% of that of mixed and 15% of that of c - star .",
    "this is because that ( 1 ) the total number of degree structures and label structures is less than the number of tree structures and paths ; ( 2 ) the entries in the succinct @xmath0-@xmath1 tree are compressed for efficient storage . for the large dataset pubchem-25 m , mixed , gsimjoin and c - star can not properly run for the memory error when the dataset size is more than 15 m , while the index size of msq - index is about 1.2 gb , which achieves an excellent performance .    by figure  [ fig : fig08 ] , we know that c - star has the shortest index construction time .",
    "this is because that it only needs to enumerate all star structures in each data graph without any complex index .",
    "although msq - index is stored in a succinct form , its construction time is shorter than gsimjoin and mixed . for the large dataset pubchem-25 m",
    ", it can be built done in 1 hour .      in this section ,",
    "we evaluate the query performance of all tested methods on the datasets aids and s100k.e30.d50.l5 and pubchem-25 m on two metrics : # of candidates passed the filtering and overall processing time . for overall processing ,",
    "we further divide it into two parts : indexing processing time and candidate verification time .",
    "we fix the datasets and vary the edit distance threshold @xmath6 from 1 to 5 to evaluate the filter capability and response time .",
    "figure  [ fig : fig09 ] shows the the average candidate size and total response time ( i.e. , the filtering time plus the verification time ) of different methods for the fifty query graphs .",
    "note that , we combine the heuristic estimate function @xmath440 in  @xcite into the software provided by riesen et al .",
    "@xcite to compute the exact graph edit distance in the verifcation phase for c - star , mixed and msq - index , except for gsimjoin has implemented it in their executable binary file .    regarding the candidate size",
    ", we can know that our method has the smallest candidate size in most case .",
    "gsimjoin and c - star do not perform well because that both tree structures and paths have much more overlapping . in s100k.e30.d50.l5 ,",
    "mixed performs the best when  @xmath441 and our method has a close candidate size with it . for the large dataset pubchem-25 m ,",
    "only our method can properly run since only it can be built done in our environment .",
    "for the response time of c - star ( denoted by `` c '' ) , gsimjoin ( denoted by `` g '' ) , mixed ( denoted by `` m '' ) and msq - index ( denoted by `` s '' ) , we know that c - star consumes the longest filtering time because it needs to construct a minimum weighted bipartite graph between each data graph and the query graph .",
    "even though gsimjoin shows a better filtering time in aids , it produces a large candidate set than msq - index , making the total response time large than msq - index .",
    "compared with mixed , msq - index can achieve 1.6x speedup on aids and 3.8x speedup on s100k.e30.d50.l5 on the average .",
    "in addition , although msq - index are compressed for efficient storage , it can provide good filtering efficiency especially when @xmath6 is small , such as the total filtering time of msq - index is less than 5s in pubchem-25 m when @xmath442 .      in this section",
    ", we evaluate the scalability performance of c - star , gsimjoin , mixed and msq - index on the real and synthetic datasets .",
    "we vary the query graph size from 10 to 60 , and fix the size of pubchem-25 m be 5 m and @xmath444 , respectively , to evaluate the effect of the query graph size on the query performance .",
    "figure  [ fig : fig11 ] shows the distribution of graphs in @xmath5 , where x - axis is the graph size , i.e. , the number of vertices and y - axis is the number of graphs of the same size in the dataset .",
    "figure  [ fig : fig12 ] shows the average candidate size and total filtering time for the fifty query graphs , respectively .        by figure",
    "[ fig : fig11 ] , we know that the distribution of data graphs in @xmath5 is close to a normal distribution and the number of graphs whose size near  30 is relatively large . thus , the average candidate size of all tested ( excepting gsimjoin for the memory error ) methods first increase and then decrease , and achieves the maximum when the query graph size is  30 .    by figure",
    "[ fig : fig12](b ) , we know that msq - index has the shortest filtering time . compared with mixed , msq - index can achieve 840x speedup when the query graph size is less than 20 or more than 50 .",
    "the reason is that the number of data graphs whose size near 20 or 50 in the dataset is relatively small by figure  [ fig : fig11 ] , resulting in the query region @xmath215 containing few data graphs .",
    ".,scaledwidth=100.0% ]    \\(a ) average candidate size    .,scaledwidth=100.0% ]    \\(b ) total filtering time      we fix @xmath12 and vary the size of pubchem-25 m from 500k ( kilo ) to 25 m ( million ) to evaluate the effect of the dataset size .",
    "figure  [ fig : fig10 ] shows the average candidate size and the total response time for the fifty graphs . among all tested methods , msq - index has the smallest candidate size and the shortest response time . when the dataset size is 10 m , gsimjoin and mixed can not properly run for the memory error , and the verification time of c - star is longer than 48 hours , making all of them not be suitable for such large dataset .",
    "only msq - index can easily scale to cope with it .",
    ".,scaledwidth=100.0% ]    \\(a ) average candidate size    .,scaledwidth=100.0% ]    \\(b ) total response time      we fix @xmath12 , the dataset size be 100k , the average graph density @xmath446 , the number of edges in each data graph be 30 , respectively , and then produce a group of synthetic datasets to evaluate the effect of the number of labels .",
    "figure  [ fig : fig13 ] shows the average candidate size of all tested methods . by figure  [ fig : fig13 ] , we know that the average candidate size decreases as the number of vertex labels increases . this is because that more information can be used to filter .",
    "we fix @xmath448 , the dataset size be 100k , the number of edges and vertex labels in each data graph be 30 and 5 , respectively , and then produce a group of synthetic datasets to evaluate the effect of the average density .",
    "figure  [ fig : fig14 ] shows the average candidate size of all tested methods .",
    "it shows that the candidate size of all tested methods increases as @xmath447 increases when @xmath449 .",
    "this is because that all tested methods only using the local structures have a weak filter ability for the the density graphs .",
    "recently , graph similarity search has received considerable attention .",
    "@xmath8-at  @xcite and gsimjoin  @xcite are two major @xmath0-@xmath1 counting filters . in @xmath8-at , a @xmath0-@xmath1",
    "is defined as a tree consisting of a vertex @xmath18 and the paths whose length no longer than @xmath8 starting from @xmath18",
    ". however , gsimjoin considered the simple path whose length is @xmath10 as a @xmath0-@xmath1 .",
    "the principle of the @xmath0-@xmath1 counting filter is stated as follows : if @xmath92 , graphs @xmath3 and @xmath4 must share at least @xmath450 common @xmath0-@xmath95 , where @xmath451 and @xmath452 denote the multisets of @xmath0-@xmath95 in @xmath3 and @xmath4 , respectively , @xmath453 and @xmath454 are the maximum number of @xmath0-@xmath95 that can be affected by an edit operation , respectively .",
    "c - star  @xcite and mixed  @xcite are two mapping distance - based @xmath455 .",
    "the lower bounds are @xmath456 and @xmath457 , respectively , where @xmath458 and @xmath459 are the mapping distances derived based on the minimum weighted bipartite graphs between the star and branch structures of @xmath3 and @xmath4 , respectively , and @xmath460 and @xmath461 are the respective maximum degrees in @xmath3 and @xmath4 .",
    "segos  @xcite introduced a two - level index structure to speed up the filtering process , which has the same filter ability with c - star .",
    "pars  @xcite divided each data graph @xmath3 into @xmath462 non - overlapping substructures , and pruned the graph @xmath3 if there exists no substructure that is subgraph isomorphic to @xmath4 .",
    "the above methods show different performance on different databases and we can hardly prove the merits of them theoretically  @xcite .    in the verification phase , @xmath463 algorithm  @xcite is widely used to compute the exact graph edit distance .",
    "zhao et.al",
    "@xcite and gouda et.al  @xcite designed different heuristic estimate functions to improve @xmath463 .",
    "note that , we only focus on the filtering phase in this paper .    when the database contains millions of graphs , many existing approaches can not properly run .",
    "gwt  @xcite utilized the weisfeiler - lehman ( wl ) kernel  @xcite function to compute the similarity between two graphs and constructed a wavelet tree  @xcite to speed up the query processing .",
    "chen et.al  @xcite built the index structure on a hadoop  @xcite cluster to search on the large database .",
    "unlike previous methods , we propose the first succinct index structure for this problem for efficient storage .",
    "our index can scale to cope with the large dataset of millions of graphs .",
    "we present an space - efficient index structure for the graph similarity search problem , whose encoded sequence  @xmath278 requires @xmath376 bits , where  @xmath259 denotes  @xmath260 or @xmath261 .",
    "our index structure incorporates succinct data structures and hybrid encoding to significantly reduce the index space usage while at the same time keeping fast query performance .",
    "each entry in @xmath272 requires about between 4 and 6 bits on our data , which is much smaller than that used to represent an entry in the compared indexing methods in this paper . however , there is still room for improvement on this space bound of @xmath278 .",
    "the design of a representation of the @xmath0-@xmath1 tree that achieves the entropy - compressed space bound while still preserving query efficiency is left as a future work .",
    "the authors would like to thank weiguo zheng and lei zhou for providing their source files , and thank xiang zhao and xuemin lin for providing their executable files.this work is supported in part by china nsf grants 61173025 and 61373044 , and us nsf grant ccf-1017623 .",
    "hongwei huo is the corresponding author ."
  ],
  "abstract_text": [
    "<S> graph similarity search has received considerable attention in many applications , such as bioinformatics , data mining , pattern recognition , and social networks . </S>",
    "<S> existing methods for this problem have limited scalability because of the huge amount of memory they consume when handling very large graph databases with millions or billions of graphs .    in this paper , we study the problem of graph similarity search under the graph edit distance constraint . </S>",
    "<S> we present a space - efficient index structure based upon the @xmath0-@xmath1 tree that incorporates succinct data structures and hybrid encoding to achieve improved query time performance with minimal space usage . specifically </S>",
    "<S> , the space usage of our index requires only 5%15% of the previous state - of - the - art indexing size on the tested data while at the same time achieving 23 times acceleration in query time with small data sets . </S>",
    "<S> we also boost the query performance by augmenting the global filter with range search , which allows us to perform a query in a reduced region . in addition , we propose two effective filters that combine degree structures and label structures . </S>",
    "<S> extensive experiments demonstrate that our proposed approach is superior in space and competitive in filtering to the state - of - the - art approaches . to the best of our knowledge , </S>",
    "<S> our index is the first in - memory index for this problem that successfully scales to cope with the large dataset of  25 million chemical structure graphs from the pubchem dataset . </S>"
  ]
}