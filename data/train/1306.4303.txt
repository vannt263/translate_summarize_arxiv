{
  "article_text": [
    "in recent years , distributed processing has become popular in wireless communication networks .",
    "this kind of processing can collect data at each node in a given area and convey the information to the whole network in a distributed way .",
    "for instance , each node can get the information from its neighbors , and then combine it with the use of distributed adaptive algorithms ; each node has the ability to estimate the nearby environment itself @xcite .",
    "when compared with the centralized solution , the distributed solution has significant advantages .",
    "the centralized solution needs a central processor , where each node sends its information to the central processor and gets the information back after the processor completes the task .",
    "this type of communication needs the central processor to be powerful and reliable . with distributed solutions ,",
    "each node only requires the local information and its neighbors to process the information .",
    "this kind of processing can significantly reduce the amount of processing and the communications bandwidth requirements .",
    "there are three main cooperation modes : the incremental , the diffusion , and the probabilistic diffusion modes @xcite . for the incremental mode",
    ", we can interpret it as a cycle in which the information goes through the nodes in one direction , which means each node passes the information to its adjacent node in a pre - determined direction . because of its simple method , the need for communication and power is the least @xcite . for the diffusion mode , each node transfers information to its whole neighbors .",
    "this kind of processing costs a huge amount of communication resources , but each node will get more information . to avoid the high communication cost , another kind of diffusion termed probabilistic diffusion is used . instead of transferring information to all its neighbors , each node transfers data to a selected group of its neighbors , which can be chosen randomly .",
    "several algorithms have already been developed and reported in the literature for distributed networks .",
    "steepest - descent , least mean square ( lms ) @xcite and affine projection ( ap ) @xcite solutions have been considered with incremental adaptive strategies over distributed networks @xcite , while the lms and recursive least squares ( rls ) algorithms have been reported using diffusion adaptive strategies @xcite . although the lms - based algorithms have their own advantages , when compared with conjugate gradient ( cg ) algorithms , their shortages are obvious .",
    "first , for the lms- based algorithms , the adaptation speed is often slow , especially for the conventional lms algorithm .",
    "second , when we are trying to increase the adaptation speed , the system stability may decrease significantly .",
    "furthermore , the rls - based algorithms usually have a high complexity . in order to develop a set of distributed solutions with a more attractive tradeoff between performance and complexity , we focus on the cg algorithm .",
    "the cg algorithm has a faster convergence rate @xcite than the lms - type algorithms and a lower computational complexity than rls - type techniques . in this paper",
    ", the main contribution is to develop distributed cg algorithms for both incremental and diffusion adaptive strategies . in particular , we develop distributed versions of the conventional cg algorithm and of the modified cg algorithm for use in distributed estimation over sensor networks .",
    "this paper is organized as follows .",
    "section 2 describes the system model and states the problem .",
    "section 3 presents the incremental distributed cg algorithms , whereas section 4 considers the diffusion distributed cg algorithms .",
    "section 5 presents and discusses the simulation results , whereas section 6 gives the conclusions .",
    "in this part , we describe a system model of the distributed estimation scheme over sensor networks and introduce the problem statement .",
    "the basic idea of this system model is that for each node in a sensor network a designer deals with a system identification problem .",
    "each node is equipped with an adaptive filter .",
    "we focus on the processing of an adaptive filter for adjusting the weight vector @xmath0 with coefficients @xmath1 ( @xmath2 ) , where m is the length of the filter . the desired signal of each node at time instant @xmath3 is @xmath4 where @xmath5 is the received signal sample , @xmath6 is the @xmath7 input signal vector , @xmath8 is the @xmath7 system weight vector",
    ", @xmath9 is the noise sample at each receiver , @xmath10 denotes hermitian transpose and @xmath11 is the number of time instants . at the same time , the output of the adaptive filter for each node is given by @xmath12 where @xmath13 is the local estimator @xmath14 for each node at time instant @xmath3 .",
    "to get the optimum solution of the weight vector , we need to solve a problem expressed in the form of a minimization of a cost function .",
    "consider a network which has @xmath15 nodes , each node @xmath16 has access to time realizations \\{@xmath17 } of zero- mean spatial data \\{@xmath18 } ,   @xmath19=1,2 ,  , n , where each @xmath20 is a scalar measurement and each @xmath21 is a row regression vector @xcite .",
    "after that , two global matrices are built which are used to collect the measurement data and regression data that are expressed in the form of the matrices : @xmath22,~   ( { n \\times m } ) \\label{obsig}\\ ] ] @xmath23^t,~ ( { n \\times 1})\\label{obsig}\\ ] ] the data which these two equations collect cover all nodes . in order to design an algorithm to compute the optimum estimation value ,",
    "we need to first define a cost function : @xmath24 \\label{obsig2},\\ ] ] where the @xmath25 is used to calculate the mse and our aim is to minimize the cost function .",
    "the optimal solution should satisfy @xcite : @xmath26 = { \\boldsymbol 0}. \\label{obsig}\\ ] ] meanwhile , the @xmath27 is also the solution to : @xmath28 where the @xmath29 autocorrelation matrix is given by @xmath30 $ ] and @xmath31 $ ] is an @xmath32 cross - correlation matrix . in this work , we focus on incremental and diffusion cg - based algorithms to solve the equation and perform estimation in a distributed fashion .",
    "for distributed estimation over sensor networks , we develop two cg- based algorithms which are the ccg and mcg with incremental distributed solution ( idcg ) .",
    "we the derive the cg- based algorithms first , then we devise distributed versions of these algorithm for use in the network in an incremental and distributed way .",
    "when a cg algorithm is used in adaptive signal processing , it solves the following equation@xcite : @xmath33 where @xmath34 is the @xmath35 correlation matrix for the input data vector , and @xmath36 is the @xmath7 cross - correlation vector between the input data vector and @xmath37 is the desired response . to solve this equation",
    ", we need to obtain : @xmath38^{-1 } { \\boldsymbol b_k^{(i)}(j ) } \\label{obsig}.\\ ] ] in the cg- based algorithm , the iteration procedure is introduced . for the @xmath39th iteration",
    ", we choose the negative direction as : @xmath40 the cg - based weight vector @xmath41 is defined as : @xmath42 where @xmath43 is the direction vector with conjugacy and @xmath44 is calculated by replacing ( 11 ) in ( 9 ) , then taking the gradient with respect to @xmath44 and using ( 11 ) , we get : @xmath45 where @xmath46 and @xmath47 the direction vector @xmath48 in ( 11 ) is defined as : @xmath49 where @xmath50 is calculated by the gram schmidt orthogonalization procedure@xcite for the conjugacy : @xmath51 with @xmath52 besides the basic cg algorithm , there are two ways to define the correlation and cross - correlation matrices which are finite sliding data window and exponentially decaying data window@xcite . in this paper",
    ", we mainly focus on the exponentially decaying data window because this approach employs the same correlation matrix as the rls algorithm .",
    "the recursions are given by : @xmath53^h \\label{obsig}\\ ] ] @xmath54 where @xmath55 is the forgetting factor .",
    "in the incremental distributed model of our algorithm , each node is only allowed to communicate with its direct neighbor at each time instant . to describe the whole process",
    ", we define a cycle , where each node in this network could only access its immediate neighbor in this cycle @xcite .",
    "the quantity @xmath56 is defined as a local estimate of @xmath57 at time @xmath58 . as a result , we assume that node @xmath19 has access to an estimate of @xmath57 at its immediate neighbor node @xmath59 which is @xmath60 in the defined cycle .",
    "fig.[fig1 ] shows its processing .    # 1#20.825    [ fig1 ]    based on the main steps of the cg algorithm , we propose two distributed adaptive filtering algorithms , namely , the ccg and the mcg for distributed estimating over sensor networks .",
    "the difference between these two strategies is that the ccg needs to run @xmath19 iterations while the mcg only needs one iteration .",
    "the implementation of incremental distributed ccg solution ( idccg ) is showed in table [ table1 ] . similarly to ccg algorithm lowercase",
    ", the incremental distributed mcg solution ( idmcg ) only needs one iteration per time instant and the details are shown in table [ table1 ] .    [ cols=\"<,<\",options=\"header \" , ]     [ table4 ]",
    "in this part , we test the proposed incremental and diffusion distributed cg - based algorithms in a sensor network and compare the results with lms , rls and ap @xcite algorithms based on the performance of excess mse ( emse ) . for each test , the number of repetitions is set to 1000 , and we assume there are 20 nodes in the network .",
    "the number of taps of the adaptive filter is 10 , the variance for the input signal and the noise are 1 and 0.001 , respectively . besides , the noise samples are modelled as complex gaussian noise .",
    "first , we give out the definitions of the parameters of our test for each algorithms and the network .",
    "after 1000 iterations , the performance of each algorithm has been showed in fig .",
    "we can see that , the performance of the idmcg and idccg algorithm is better than idlms , while idmcg is very close to the idrls algorithm s curve .",
    "the reason why the proposed idmcg algorithm has a better performance is idmcg defined the negative gradient vector @xmath61 with a recursive expression and the @xmath62 is computed to avoiding the residue produced by using the polak- ribiere approach .",
    "comparing with the idccg algorithm , the idmcg is a non - reset and low complexity algorithm with one iteration per time instant . because of",
    "how often the algorithm is rest will influence the performance , the idmcg introduce the non - rest method together with polak- ribiere method which is used for improved its performance @xcite .",
    "# 1#20.825    [ fig3 ]      for this group of proposed ddcg algorithms test , we use some similar definitions of parameters as in the last part .",
    "for the diffusion strategy , we build the link between each node randomly , and for the combiner c , we calculate it following the metropolis rule . fig .",
    "[ fig4 ] shows the network structure .",
    "after 1000 iterations , the test result are showed in fig .",
    "we can see that , the proposed ddmcg and ddccg still have a better performance than ddlms algorithm and ddmcg is closer to the ddrls s curve . for the diffusion strategy",
    ", the network structure has a significant influence on the performance of our proposed ddcg algorithms .    #",
    "1#20.825    [ fig4 ]    # 1#20.825    [ fig5 ]",
    "we have developed distributed cg algorithms for incremental and diffusion type estimation over sensor networks .",
    "the cg- based strategies avoid the matrix inversion and numerical instability of rls algorithms and have a faster convergence than lms and ap algorithms .",
    "simulation results have shown that the proposed idmcg and ddmcg algorithms have a better performance than the lms and ap algorithm , and a close performance to the rls algorithm ."
  ],
  "abstract_text": [
    "<S> this paper presents distributed adaptive algorithms based on the conjugate gradient ( cg ) method for distributed networks . </S>",
    "<S> both incremental and diffusion adaptive solutions are all considered . </S>",
    "<S> the distributed conventional ( cg ) and modified cg ( mcg ) algorithms have an improved performance in terms of mean square error as compared with least - mean square ( lms)-based algorithms and a performance that is close to recursive least - squares ( rls ) algorithms . </S>",
    "<S> the resulting algorithms are distributed , cooperative and able to respond in real time to changes in the environment .    </S>",
    "<S> adaptive networks , distributed processing , incremental adaptive solution , diffusion adaptive solution . </S>"
  ]
}