{
  "article_text": [
    "credit risk can be defined as the possibility of a loss occurring due to the financial failure to meet contractual debt obligations .",
    "this is one of the measures of the likelihood that a party will default on a financial agreement .",
    "there exist two classes of credit risk models @xcite , structural models and reduced form models .",
    "structural models can be traced back to the influential works by black , scholes and merton @xcite , while reduced form models seem to originate from contributions by @xcite . the major focus in this contribution is given to structural credit - risk models .    in structural credit - risk models ,",
    "a default occurs when a company can not meet its financial obligations , or in other words , when the firm s value falls below a certain threshold .",
    "one of the major problems in the credit risk analysis is when a default occurs within a given time horizon and what is the default rate during such a time horizon .",
    "this problem can be reduced to a first passage time ( fpt ) problem , that can be formulated mathematically as a certain stochastic differential equation ( sde ) .",
    "it concerns with the estimation of the probability density of the time for a random process to cross a specified threshold level .",
    "an important phenomenon that we account for in our discussion lies with the fact that , in the market economy , individual companies are inevitably linked together via dynamically changing economic conditions .",
    "therefore , the default events of companies are often correlated , especially in the same industry . @xcite and",
    "@xcite were the first to incorporate default correlation into the black - cox first passage structural model , but they have not included the jumps .",
    "as pointed out in @xcite , the standard brownian motion model for market behavior falls short of explaining empirical observations of market returns and their underlying derivative prices . in the meantime ,",
    "jump - diffusion processes ( jdps ) have established themselves as a sound alternative to the standard brownian motion model @xcite .",
    "multivariate jump - diffusion models provide a convenient framework for investigating default correlation with jumps and become more readily accepted in the financial world as an efficient modeling tool .",
    "however , as soon as jumps are incorporated in the model , except for very basic applications where analytical solutions are available , for most practical cases we have to resort to numerical procedures .",
    "examples of known analytical solutions include problems where the jump sizes are doubly exponential or exponentially distributed @xcite as well as the jumps can have only nonnegative values ( assuming that the crossing boundary is below the process starting value ) @xcite . for other situations ,",
    "monte carlo methods remain a primary candidate for applications .",
    "the conventional monte carlo methods are very straightforward to implement .",
    "we discretize the time horizon into @xmath0 intervals with @xmath0 being large enough in order to avoid discretization bias @xcite .",
    "the main drawback of this procedure is that we need to evaluate the processes at each discretized time which is very time - consuming .",
    "many researchers have contributed to the field of enhancement of the efficiency of monte carlo simulations . among others ,",
    "@xcite discussed the solution of sdes in the framework of weak discrete time approximations and @xcite considered the strong approximation where the sde is driven by a high intensity poisson process .",
    "atiya and metwally @xcite have recently developed a fast monte carlo - type numerical methods to solve the fpt problem . in our recent contribution",
    ", we reported an extension of this fast monte - carlo - type method in the context of multiple non - correlated jump - diffusion processes @xcite .    in this contribution , we generalize our previous fast monte - carlo method ( for non - correlated jump - diffusion cases ) to multivariate ( and correlated ) jump - diffusion processes .",
    "the developed technique provides an efficient tool for a number of applications , including credit risk and option pricing .",
    "we demonstrate the applicability of this technique to the analysis of the default rates and default correlations of several different correlated firms via a set of empirical data .",
    "the paper is organized as follows , section [ model ] provides details of our model in the context of multivariate jump - diffusion processes . the algorithms and the calibration of the model",
    "are presented in section [ methodology ] .",
    "section [ application ] demonstrates how the model works via analyzing the credit risk of multi - correlated firms .",
    "conclusions are given in section [ conclusion ] .",
    "as mentioned in the introduction , when we deal with jump - diffusion stochastic processes , we usually have to resort to the application of numerical procedures .",
    "although monte carlo procedure provide a natural in such case , the one - dimensional fast monte - carlo method can not be directly generalized to the multivariate and correlated jump - diffusion case ( e.g. @xcite ) .",
    "the difficulties arise from the fact that the multiple processes as well as their first passage times are indeed correlated , so the simulation must reflect the correlations of first passage times . in this contribution",
    ", we propose a solution to circumvent these difficulties by combining the fast monte - carlo method of one - dimensional jump - diffusion processes and the generation of correlated multidimensional variates .",
    "this approach generalizes our previous results for the non - correlated jump - diffusion case to multivariate and correlated jump - diffusion processes .",
    "in this section , first , we present a probabilistic description of default events and default correlations .",
    "next , we describe the multivariate jump - diffusion processes and provide details on the first passage time distribution under the one - dimensional brownian bridge ( the sum - of - uniforms method which is used to generate correlated multidimensional variates will be described in section [ subsection : sou ] ) .",
    "finally , we presents kernel estimation in the context of our problem that can be used to represent the first passage time density function .      in a structural model , a firm @xmath1 defaults when it can not meet its financial obligations , or in other words , when the firm assets value @xmath2 falls below a threshold level @xmath3 .",
    "generally speaking , finding the threshold level @xmath3 is one of the challenges in using the structural methodology in the credit risk modeling , since in reality firms often rearrange their liability structure when they have credit problems . in this contribution",
    ", we use an exponential form defining the threshold level @xmath4 as proposed by @xcite , where @xmath5 can be interpreted as the growth rate of firm s liabilities .",
    "coefficient @xmath6 captures the liability structure of the firm and is usually defined as a firm s short - term liability plus 50% of the firm s long - term liability .",
    "if we set @xmath7 $ ] , then the threshold of @xmath8 is @xmath9 .",
    "our main interest is in the process @xmath8 .",
    "prior to moving further , we define a default correlation that measures the strength of the default relationship between different firms .",
    "take two firms @xmath1 and @xmath10 as an example , whose probabilities of default are @xmath11 and @xmath12 , respectively .",
    "then the default correlation can be defined as @xmath13 where @xmath14 is the probability of joint default .    from eq .",
    "( [ eq : corr ] ) we have @xmath15 .",
    "let us assume that @xmath16% .",
    "if these two firms are independent , i.e. , the default correlation @xmath17 , then the probability of joint default is @xmath18% .",
    "if the two firms are positively correlated , for example , @xmath19 , then the probability of both firms default becomes @xmath20% that is almost 10 times higher than in the former case .",
    "thus , the default correlation @xmath21 plays a key role in the joint default with important implications in the field of credit analysis .",
    "@xcite and @xcite were the first to incorporate default correlation into the black - cox first passage structural model .",
    "@xcite has proposed a first passage time model to describe default correlations of two firms under the `` bivariate diffusion process '' : @xmath22=    \\left[\\begin{array}{cc }     \\mu_1\\\\     \\mu_2     \\end{array}\\right]dt+     \\omega\\left[\\begin{array}{cc }     dz_1\\\\     dz_2     \\end{array}\\right ] ,    \\label{zhou : two : assets}\\ ] ] where @xmath23 and @xmath24 are constant drift terms , @xmath25 and @xmath26 are two independent standard brownian motions , and @xmath27 is a constant @xmath28 matrix such that @xmath29.\\ ] ] the coefficient @xmath30 reflects the correlation between the movements in the asset values of the two firms",
    ". then the probability of firm @xmath1 defaults at time @xmath31 can be easily calculated as , @xmath32 where @xmath33 is the standardized distance of firm @xmath1 to its default point and @xmath34 denotes the cumulative probability distribution function for a standard normal variable .",
    "furthermore , if we assume that @xmath35 , then the probability of at least one firm defaults by time @xmath31 can be written as @xcite : @xmath36 ,      \\label{eq : por}\\end{aligned}\\ ] ] where @xmath37 is the modified bessel function @xmath38 with order @xmath39 and @xmath40    then , the default correlation of these two firms is @xmath41p_j(t)[1-p_j(t)]}}.    \\label{eq : corr2}\\ ] ]    however , none of the above known models includes jumps in the processes . at the same time",
    ", it is well - known that jumps are a major factor in the credit risk analysis . with jumps included in such analysis ,",
    "a firm can default instantaneously because of a sudden drop in its value which is impossible under a diffusion process .",
    "@xcite has shown the importance of jump risk in credit risk analysis of an obligor .",
    "he implemented a simulation method to show the effect of jump risk in the credit spread of defaultable bonds .",
    "he showed that the misspecification of stochastic processes governing the dynamics of firm value , i.e. , falsely specifying a jump - diffusion process as a continuous brownian motion process , can substantially understate the credit spreads of corporate bonds .",
    "therefore , for multiple processes , considering the simultaneous jumps can be a better way to estimate the correlated default rates .",
    "the multivariate jump - diffusion processes can provide a convenient way to describe multivariate and correlated processes with jumps .",
    "let us consider a complete probability space @xmath42 with information filtration @xmath43 .",
    "suppose that @xmath44 is a markov process in some state space @xmath45 , solving the stochastic differential equation @xcite : @xmath46 where @xmath47 is an @xmath43-standard brownian motion in @xmath48 ; @xmath49 , @xmath50 , and @xmath51 is a pure jump process whose jumps have a fixed probability distribution @xmath39 on @xmath48 such that they arrive with intensity @xmath52 , for some @xmath53 .",
    "under these conditions , the above model is reduced to an affine model if @xcite : @xmath54 where @xmath55 , @xmath56 , @xmath57 .",
    "as we mentioned , one of the major problems in the credit risk analysis is to estimate the default rate of a firm during a given time horizon .",
    "this problem is reduced to a first passage time problem . in order to obtain a computable multi - dimensional formulas of fpt distribution ,",
    "we need to simplify eq .",
    "( [ ajd : diffeq ] ) and ( [ eq : ajd : terms ] ) as follows ,    1 .",
    "each @xmath58 in eq .",
    "( [ ajd : diffeq ] ) is independent ; 2 .",
    "@xmath59 , @xmath60 and @xmath61 in eq .",
    "( [ eq : ajd : terms ] ) which means the drift term , the diffusion process ( brownian motion ) and the arrival intensity are independent of the state vector @xmath62 ; 3 .",
    "the distribution of jump - size @xmath63 is also independent with respect to @xmath62 .    in this scenario , we can rewrite eq . ( [ ajd : diffeq ] ) as @xmath64 where @xmath65      although for jump - diffusion processes , the closed form solutions are usually unavailable , yet between each two jumps the process is a brownian bridge for univariate jump - diffusion process .",
    "@xcite have deduced one - dimensional first passage time distribution in time horizon @xmath66 $ ] . in order to evaluate multiple processes ,",
    "we obtain multi - dimensional formulas from eq .",
    "( [ jdp : multi ] ) and reduce them to computable forms .",
    "first , let us consider a firm @xmath1 , as described by eq .",
    "( [ jdp : multi ] ) , such that its state vector @xmath67 satisfies the following sde : @xmath68 where @xmath69 is a standard brownian motion and @xmath70 is : @xmath71    we assume that in the interval @xmath66 $ ] , total number of jumps for firm @xmath1 is @xmath72 . let the jump instants be @xmath73 .",
    "let @xmath74 and @xmath75 . the quantities @xmath76 equal to interjump times , which is @xmath77 . following the notation of @xcite ,",
    "let @xmath78 be the process value immediately before the @xmath10th jump , and @xmath79 be the process value immediately after the @xmath10th jump .",
    "the jump - size is @xmath80 , and we can use such jump - sizes to generate @xmath79 sequentially .    if we define @xmath81 as the event consisting of process crossed the threshold level @xmath82 for the first time in the interval @xmath83 $ ] , then we have @xmath84    if we only consider one interval @xmath85 $ ] , we can obtain @xmath86^{2}}{2(t_{j}-t)\\sigma_{i}^{2}}\\right)\\nonumber\\\\    & & * \\exp\\left(-\\frac{[x_i(t_{j-1}^{+})-d_{i}(t)+\\mu_{i}(t - t_{j-1})]^{2}}{2(t - t_{j-1})\\sigma_{i}^{2}}\\right ) ,    \\label{fptd : condition}\\end{aligned}\\ ] ] where @xmath87^{2}}{2\\tau_{j}\\sigma_{i}^{2}}\\right).\\ ] ]    after getting result in one interval , we combine the results to obtain the density for the whole interval @xmath66 $ ] .",
    "let @xmath88 be a brownian bridge in the interval @xmath85 $ ] with @xmath89 and @xmath90 .",
    "then the probability that the minimum of @xmath91 is always above the boundary level is @xmath92[x_i(t_{j}^{-})-d_{i}(t)]}{\\tau_{j}\\sigma_{i}^{2}}\\right ) , & \\mathrm{if}\\;x_i(t_{j}^{-})>d_{i}(t),\\\\         0 , & \\mathrm{otherwise}.       \\end{array}\\right .",
    "\\label{bm : default}\\end{aligned}\\ ] ]    this implies that @xmath91 is below the threshold level , which means the default happens or already happened , and its probability is @xmath93 .",
    "let @xmath94 denote the index of the interjump period in which the time @xmath95 ( first passage time ) falls in @xmath96 $ ] .",
    "also , let @xmath97 represent the index of the first jump , which happened in the simulated jump instant , @xmath98    if no such @xmath97 exists , then we set @xmath99 .    by combining eq .",
    "( [ fptd : condition ] ) , ( [ bm : default ] ) and ( [ index_first_jump ] ) , we get the probability of @xmath67 crossing the boundary level in the whole interval @xmath66 $ ] as @xmath100 where @xmath101 is the dirac s delta function .      for firm @xmath1 , after generating a series of first passage times @xmath95 , we use a kernel density estimator with gaussian kernel to estimate the first passage time density ( fptd ) @xmath102 .",
    "the kernel density estimator is based on centering a kernel function of a bandwidth as follows : @xmath103 where @xmath104    the optimal bandwidth in the kernel function @xmath105 can be calculated as @xcite : @xmath106 where @xmath0 is the number of generated points and @xmath107 is the true density .",
    "here we use the approximation for the distribution as a gamma distribution , proposed by @xcite : @xmath108    so the integral in eq .",
    "( [ estamate : hopt ] ) becomes : @xmath109 where @xmath110 and @xmath111    from eq .",
    "( [ eq : hopt2 ] ) , it follows that in order to get a nonzero bandwidth , we have to have constraint @xmath112 to be at least equal to 3 .",
    "the kernel estimator for the multivariate case involves the evaluation of joint conditional interjump first passage time density , as discussed in section [ methodology ] .",
    "the methodology for such an evaluation is quite involved compared to the one - dimensional case and we will focus on these details elsewhere . in what follows we highlight the main steps of the procedure .",
    "first , let us recall the conventional monte - carlo procedure in application to the analysis of the evolution of firm @xmath67 within the time horizon @xmath66 $ ] . we divide the time horizon into @xmath113 small intervals",
    "@xmath114 $ ] , @xmath115 $ ] , @xmath116 , @xmath117 $ ] as displayed in fig .",
    "[ fig : method](a ) . in each monte carlo run , we need to calculate the value of @xmath67 at each discretized time @xmath31 . as usual , in order to exclude discretization bias , the number @xmath113 must be large .",
    "this procedure exhibits substantial computational difficulties when applied to jump - diffusion processes . indeed , for a typical jump - diffusion process , as shown in fig .",
    "[ fig : method](a ) , let @xmath118 and @xmath119 be any successive jump instants , as described above . then , in the conventional monte carlo method , although there is no jump occurring in the interval @xmath120 $ ] , yet we need to evaluate @xmath67 at each discretized time @xmath31 in @xmath120 $ ] . this very time - consuming procedure results in a serious shortcoming of the conventional monte - carlo methodology .",
    "to remedy the situation , two modifications of the conventional procedure were recently proposed @xcite that allow us a potential speed - up of the conventional methodology in 10 - 30 times .",
    "one of the modifications , the uniform sampling method , involves samplings using the uniform distribution .",
    "the other is the inverse gaussian density sampling method .",
    "both methodologies were developed for the univariate case .",
    "the major improvement of the uniform sampling method is based on the fact that it only evaluates @xmath67 at generated jump times , while between each two jumps the process is a brownian bridge ( see fig . [",
    "fig : method](b ) ) .",
    "hence , we just consider the probability of @xmath67 crossing the threshold in @xmath121 instead of evaluating @xmath67 at each discretized time @xmath31 .",
    "more precisely , in the uniform sampling method , we assume that the values of @xmath122 and @xmath123 are known as two end points of the brownian bridge , the probability of firm @xmath1 defaults in @xmath121 is @xmath93 which can be computed according to eq .",
    "( [ bm : default ] ) .",
    "then we generate a variable @xmath95 from a distribution uniform in the interval @xmath124 $ ] .",
    "if the generated point @xmath95 falls in the interjump interval @xmath120 $ ] , then we have successfully generated the first passage time @xmath95 and can neglect the other intervals and perform another monte carlo run . on the other hand ,",
    "if the generated point @xmath95 falls outside the interval @xmath120 $ ] ( which happens with probability @xmath14 ) , then that point is `` rejected '' .",
    "this means that no boundary crossing has occurred in the interval , and we proceed to the next interval and repeat the whole process again .",
    "note that the generated @xmath95 is not obtained according to conditional boundary crossing density @xmath125 as described by eq .",
    "( [ fptd : condition ] ) . in order to obtain an appropriate density estimate",
    ", @xcite proposed that the right hand side summation in eq .",
    "( [ eq : estimator ] ) can be viewed as a finite sample estimate of the following : @xmath126&\\equiv&\\int_{t_{j-1}}^{t_j}g_{ij}(s_i)k(h , t - s_i)ds_i\\nonumber\\\\     & = & \\left(\\frac{t_j - t_{j-1}}{1-p_{ij}}\\right)e_{u(s_i)}[g_{ij}(s_i)k(h , t - s_i)],\\end{aligned}\\ ] ] where @xmath127 means the expectation of @xmath95 , where @xmath95 obeys the density @xmath125 .",
    "@xmath128 is the uniform density in @xmath124 $ ] from which we sample the point @xmath95 .",
    "therefore , we should weight the kernel with @xmath129 to obtain an estimate for the true density .    for the multidimensional density estimate",
    "we need to evaluate the joint conditional boundary crossing density .",
    "this problem can be divided into several one - dimensional density estimate subproblems if the processes are non - correlated @xcite . as for the multivariate correlated processes ,",
    "the joint density becomes very complicated and there are usually no analytical solutions for higher - dimensional processes @xcite .",
    "we will not consider this problem in the current contribution .    instead",
    ", we focus on the further development of the uniform sampling ( unif ) method and extend it to multivariate and correlated jump - diffusion processes . in order to implement the unif method for our multivariate model as described in eq .",
    "( [ jdp : multi ] ) , we need to consider several points :    1 .",
    "we assume that the arrival rate @xmath130 for the poisson jump process and the distribution of @xmath131 are the same for each firm . as for the jump - size",
    ", we generate them by a given distribution which can be different for different firms to reflect specifics of the jump process for each firm .",
    "we exemplify our description by considering an exponential distribution ( mean value @xmath132 ) for @xmath131 and a normal distribution ( mean value @xmath133 and standard deviation @xmath134 ) for the jump - size .",
    "we can use any other distribution when appropriate .",
    "3 .   an array ` isdefault ` ( whose size is the number of firms denoted by @xmath135 ) is used to indicate whether firm @xmath1 has defaulted in this monte carlo run . if the firm defaults , then we set ` isdefault`@xmath136 , and will not evaluate it during this monte carlo run .",
    "4 .   most importantly , as we have mentioned before , the default events of firm @xmath1 are inevitably correlated with other firms , for example firm @xmath137 . the default correlation of firms @xmath1 and @xmath137 is described by eq .",
    "( [ eq : corr2 ] ) . hence , firm @xmath1 s first passage time @xmath95 is indeed correlated with @xmath138  the first passage time of firm @xmath137 .",
    "we must generate several correlated @xmath95 in each interval @xmath124 $ ] which is the key point for multivariate correlated processes .",
    "note that the assumption based on using the same arrival rate @xmath130 and distribution of @xmath131 for different firms may seem to be quite idealized .",
    "one may argue that the arrival rate @xmath130 for the poisson jump process should be different for different firms , which implies that different firms endure different jump rates .",
    "however , if we consider the real market economy , once a firm ( called firm `` a '' ) encounter sudden economic hazard , its correlated firms may also endure the same hazard .",
    "furthermore , it is common that other firms will help firm `` a '' to pull out , which may result in a simultaneous jump for them .",
    "therefore , as a first step , it is reasonable to employ the simultaneous jumps processes for all the different firms .",
    "next , we will give a brief description of the sum - of - uniforms method which is used to generate correlated uniform random variables , followed by the description of the multivariate and correlated unif method and the model calibration .      in the above sections ,",
    "we have reduced the solution of the original problem to a series of one - dimensional jump - diffusion processes as described by eq .",
    "( [ jdp : one ] ) . the first passage time distribution in an interval @xmath85 $ ] ( between two successive jumps )",
    "was obtained in section [ subsection : fptd ] .",
    "as mentioned , the default events of firm @xmath1 are inevitably correlated with other firms , for example firm @xmath137 . in this contribution , we approximate the correlation of @xmath95 and @xmath138 as the default correlation of firm s@xmath1 and @xmath137 by the following formula : @xmath139p_{i+1}(t)[1-p_{i+1}(t ) ] } } ,    \\label{eq : corr : fpt}\\ ] ] where @xmath31 can be chosen as the midpoint of this interval .",
    "therefore , we need to generate several correlated @xmath95 in @xmath124 $ ] whose correlations can be described by eq .",
    "( [ eq : corr : fpt ] ) .",
    "let us introduce a new variable @xmath140 , then we have @xmath141 , where @xmath142",
    "are uniformly distributed in @xmath143 $ ] . moreover ,",
    "the correlation of @xmath142 and @xmath144 is given by @xmath145 .",
    "now we can generate the correlated uniform random variables @xmath146 by using the sum - of - uniforms ( sou ) method @xcite in the following steps :    1 .",
    "generate @xmath147 from numbers uniformly distributed in @xmath143 $ ] .",
    "2 .   for @xmath148 ,",
    "generate @xmath149 , where @xmath150 denotes a uniform random number over range @xmath151 .",
    "@xcite has obtained the relationship of parameter @xmath152 and the correlation @xmath153 ( abbreviated as @xmath154 ) as follows : @xmath155",
    "if @xmath156 and @xmath157 are positively correlated , then let @xmath158 if @xmath156 and @xmath157 are negatively correlated , then let @xmath159 + let @xmath160 , where for @xmath161 , @xmath162 and for @xmath163 , @xmath164      in this subsection , we will describe our algorithm for multivariate jump - diffusion processes , which is an extension of the one - dimensional case developed earlier by other authors ( e.g. @xcite ) .",
    "consider @xmath135 firms in the given time horizon @xmath66 $ ] .",
    "first , we generate the jump instant @xmath165 by generating interjump times @xmath166 and set all the ` isdefault`@xmath167 to indicate that no firm defaults at first .    from fig .",
    "[ fig : method](b ) and eq .",
    "( [ jdp : one ] ) , we can conclude that for each process @xmath67 we can make the following observations :    1 .   if no jump occurs , as described by eq .",
    "( [ jdp : one ] ) , the interjump size @xmath168 follows a normal distribution of mean @xmath169 and standard deviation @xmath170 .",
    "we get @xmath171 where the initial state is @xmath172 .",
    "if jump occurs , we simulate the jump - size by a normal distribution or another distribution when appropriate , and compute the postjump value : @xmath173    this completes the procedure for generating beforejump and postjump values @xmath174 and @xmath175 . as before , @xmath176 where @xmath177 is the total number of jumps for all the firms .",
    "we compute @xmath14 according to eq .",
    "( [ bm : default ] ) . to recur the first passage time density ( fptd ) @xmath178",
    ", we have to consider three possible cases that may occur for each non - default firm @xmath1 :    1 .",
    "* first passage happens inside the interval .",
    "* we know that if @xmath179 and @xmath180 , then the first passage happened in the time interval @xmath85 $ ] .",
    "to evaluate when the first passage happened , we introduce a new viable @xmath181 as @xmath140 .",
    "we generate several correlated uniform numbers @xmath142 by using the sou method as described in section [ subsection : sou ] , then compute @xmath141 .",
    "if @xmath95 belongs to interval @xmath85 $ ] , then the first passage time occurred in this interval .",
    "we set ` isdefault`@xmath136 to indicate firm @xmath1 has defaulted and compute the conditional boundary crossing density @xmath125 according to eq .",
    "( [ fptd : condition ] ) . to get the density for the entire interval @xmath66 $ ] , we use @xmath182 , where @xmath113 is the iteration number of the monte carlo cycle .",
    "2 .   * first passage does not happen in this interval . *",
    "if @xmath95 does nt belong to interval @xmath85 $ ] , then the first passage time has not yet occurred in this interval .",
    "* first passage happens at the right boundary of the interval . *",
    "if @xmath183 and @xmath184 ( see eq .",
    "( [ index_first_jump ] ) ) , then @xmath185 is the first passage time and @xmath186 , we evaluate the density function using kernel function @xmath187 , and set ` isdefault`@xmath136 .    next , we increase @xmath10 and examine the next interval and analyze the above three cases for each non - default firm again . after running @xmath0 times monte carlo cycle , we get the fptd of firm @xmath1 as @xmath188 .",
    "we need to calibrate the developed model , in other words , to numerically choose or optimize the parameters , such as drift , volatility and jumps to fit the most liquid market data .",
    "this can be done by applying the least - square method , minimizing the root mean square error ( _ rmse _ ) given by : @xmath189 @xcite have used a set of european call options @xmath190 as their model price to calibrate their model parameters .",
    "however , as demonstrated in section [ application ] , for a number of practically interesting cases , there is no option value that can be used to calibrate our model , so we have to use the historical default data to optimize the parameters in the model . as mentioned in sections [ subsection : estimation ] and",
    "[ subsection : unif ] , after monte carlo simulation we obtain the estimated density @xmath191 by using the kernel estimator method . the cumulative default rates for firm @xmath1 in our model is defined as , @xmath192    then we minimize the difference between our model and historical default data @xmath193 to obtain the optimized parameters in the model ( such as @xmath194 , arrival intensity @xmath130 in eq .",
    "( [ jdp : one ] ) ) : @xmath195",
    "in this section , we demonstrate the developed model at work for analyzing the default events of multiple correlated firms via a set of historical default data .      first , for completeness ,",
    "let us consider a set of historical default data of differently rated firms as presented by @xcite .",
    "our first task is to describe the first passage time density functions and default rates of these firms .",
    "since there is no option value that can be used , we will employ eq.([eq : calibration : default ] ) to optimize the parameters in our model . for convenience",
    ", we reduce the number of optimizing parameters by :    1 .   setting @xmath196 and @xmath197 .",
    "2 .   setting the growth rate @xmath198 of debt value equivalent to the growth rate @xmath199 of the firm s value @xcite ,",
    "so the default of firm is non - sensitive to @xmath199 . in our computations , we set @xmath200 .",
    "3 .   the interjump times @xmath131 satisfy an exponential distribution with mean value equals to 1 .",
    "the arrival rate for jumps satisfies the poisson distribution with intensity parameter @xmath130 , where the jump size is a normal distribution @xmath201 .    as a result",
    ", we only need to optimize @xmath202 , @xmath130 , @xmath203 , @xmath204 for each firm .",
    "this is done by minimizing the differences between our simulated default rates and historical data . moreover , as mentioned above , we will use the same arrival rate @xmath130 and distribution of @xmath131 for differently rated firms , so we first optimize four parameters for , e.g. , the a - rated firm , and then set the parameter @xmath130 of other three firms the same as a s .",
    "the minimization was performed by the using quasi - newton procedure implemented as a scilab program .",
    "the optimized parameters for each firm are described in table [ table : param : one ] .",
    ".optimized parameters for differently rated firms by using the unif method .",
    "the optimization was performed by using the quasi - newton procedure implemented as a scilab program . in each step of the optimization",
    ", we choose the monte carlo runs @xmath205 . [",
    "cols=\"<,^,^,^,^\",options=\"header \" , ]     next , let us consider the default correlations under the multivariate jump - diffusion processes .",
    "we use the following conditions in our multivariate unif method :    1 .   setting @xmath196 and @xmath197 for all firms .",
    "2 .   setting @xmath206 and @xmath200 for all firms .",
    "since we are considering two correlated firms , we choose @xmath202 as , @xmath207,\\ ] ] where @xmath208 such that , @xmath209,\\ ] ] and @xmath210 in eq .",
    "( [ eq : brownian : corr ] ) , @xmath211 reflects the correlation of diffusion parts of the state vectors of the two firms . in order to compare with the standard brownian motion and to evaluate the default correlations between different firms",
    ", we set all the @xmath212 as in @xcite .",
    "furthermore , we use the optimized @xmath213 and @xmath214 in table [ table : param : one ] for firm 1 and 2 , respectively . assuming @xmath215 , we get , @xmath216 4 .",
    "the arrival rate for jumps satisfies the poisson distribution with intensity parameter @xmath217 for all firms .",
    "the jump size is a normal distribution @xmath218 , where @xmath219 and @xmath220 can be different for different firms to reflect specifics of the jump process for each firm .",
    "we adopt the optimized parameters given in table [ table : param : one ] .",
    "5 .   as before",
    ", we generate the same interjump times @xmath131 that satisfy an exponential distribution with mean value equals to 1 for each two firms .",
    "we carry out the unif method to evaluate the default correlations via the following formula : @xmath221 where @xmath222 is the probability of joint default for firms 1 and 2 in each monte carlo cycle , @xmath223 and @xmath224 are the cumulative default rates of firm 1 and 2 , respectively , in each monte carlo cycle .",
    "the simulated default correlations for one- , two- , five- and ten - years are given in table [ simulate : corr01]-[simulate : corr10 ] .",
    "all the simulations were performed with the monte carlo runs @xmath225 .",
    "comparing those simulated default correlations with the theoretical data for standard brownian motions , we can conclude that    1 .   similarly to conclusions of @xcite , the default correlations of same rated firms are usually large compared to differently rated firms .",
    "furthermore , the default correlations tend to increase over long horizons and may converge to a stable value .",
    "2 .   in our simulations ,",
    "the one year default correlations of ( a , a ) and ( a , baa ) are negative .",
    "this is because they seldom default jointly during one year .",
    "note , however , that the default correlations of other firms are positive and usually larger than the results in @xcite .",
    "3 .   for two and five years , the default correlations of different firms increase .",
    "this can be explained by the fact that their individual first passage time density functions increase during these time horizon , hence the probability of joint default increases .",
    "4 .   as for ten year default correlations ,",
    "our simulated results are almost identical to the theoretical data for standard brownian motions .",
    "the differences are that the default correlations of ( ba , ba ) , ( ba , b ) and ( b , b ) decrease from the fifth year to tenth year in our simulations .",
    "the reason is that the first passage time density function of ba- and b - rated firms begin to decrease from the fifth year , hence the probability of joint default may increase slowly .",
    "in this contribution , we have analyzed the credit risk problems of multiple correlated firms in the structural model framework , where we incorporated jumps to reflect the external shocks or other unpredicted events . by combining the fast monte - carlo method for one - dimensional jump - diffusion processes and the generation of correlated multidimensional variates ,",
    "we have developed a fast monte - carlo type procedure for the analysis of multivariate and correlated jump - diffusion processes .",
    "the developed approach generalizes previously discussed non - correlated jump - diffusion cases for multivariate and correlated jump - diffusion processes .",
    "finally , we have applied the developed technique to analyze the default events of multiple correlated firms via a set of historical default data .",
    "the developed methodology provides an efficient computational technique that is applicable in other areas of credit risk and pricing options .",
    "this work was supported by nserc .",
    "zhang , d. and melnik , r.v.n . ,",
    "first passage time for multivariate jump - diffusion stochastic models with applications in finance .",
    "presented at the sixth aims international conference on dynamical systems and differential equations , university of poitiers , poitiers , france , 2006 ."
  ],
  "abstract_text": [
    "<S> many problems in finance require the information on the first passage time ( fpt ) of a stochastic process . </S>",
    "<S> mathematically , such problems are often reduced to the evaluation of the probability density of the time for such a process to cross a certain level , a boundary , or to enter a certain region . while in other areas of applications the fpt problem can often be solved analytically , in finance we usually have to resort to the application of numerical procedures , in particular when we deal with jump - diffusion stochastic processes ( jdp ) . in this paper , we propose a monte - carlo - based methodology for the solution of the first passage time problem in the context of multivariate ( and correlated ) jump - diffusion processes . </S>",
    "<S> the developed technique provide an efficient tool for a number of applications , including credit risk and option pricing . </S>",
    "<S> we demonstrate its applicability to the analysis of the default rates and default correlations of several different , but correlated firms via a set of empirical data .    </S>",
    "<S> _ keywords _ : first passage time ; monte carlo simulation ; multivariate jump - diffusion processes ; credit risk </S>"
  ]
}