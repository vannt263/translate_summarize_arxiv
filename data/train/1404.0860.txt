{
  "article_text": [
    "for a @xmath0-variate random vector @xmath1 the covariance matrix , or variance - covariance matrix , @xmath2 is a fundamental descriptive measure and is one of the cornerstones in the development of multivariate methods .",
    "the covariance matrix has a number of important basic properties , for example :    [ covprop ] let @xmath3 and @xmath4 be @xmath0-variate continuous random vectors with finite second moments , then +    1 .",
    "the covariance matrix @xmath5 is symmetric and positive semi - definite .",
    "2 .   the covariance matrix is affine equivariant in the sense that @xmath6 for all full rank @xmath7 matrices @xmath8 and all @xmath0-vectors @xmath9 .",
    "3 .   if the @xmath10th and @xmath11th components of @xmath3 are independent , then @xmath12 4 .",
    "if x and y are independent , then the covariance matrix is additive in the sense that @xmath13    furthermore , for a random sample @xmath14 coming from a @xmath0-variate normal distribution @xmath15 , the finite sample version of @xmath5 , i.e.  the sample covariance matrix @xmath16 is the maximum likelihood estimator for the scatter parameter @xmath17 .",
    "also , together with the sample mean vector @xmath18 , the sample covariance matrix gives a sufficient summary of the data under the assumption of multivariate normality .",
    "hence any method derived assuming multivariate normality will be based solely on the the sample mean vector and sample covariance matrix .",
    "it is well known though that multivariate methods based on the sample mean and sample covariance matrix are highly non - robust to departures from multivariate normality .",
    "such methods are extremely sensitive to just a single outlier and are highly inefficient at longer tailed distributions .",
    "consequently , a substantial amount of research has been undertaken in an effort to develop robust multivariate methods which are not based on the mean vector and covariance matrix .",
    "a common approach for `` robustifying '' classical multivariate methods based on the sample mean vector and covariance matrix is the `` plug - in '' method , which means to simply modify the method by replacing the mean vector and covariance matrix with robust estimates of multivariate location and scatter .",
    "however , sometimes crucial properties of the covariance matrix are needed in order for a particular multivariate method to be valid , and investigating whether these properties hold for the robust scatter replacement is often not addressed .",
    "typically , scatter matrices are defined so that they satisfy the first two properties in lemma  [ covprop ] , but not necessarily the other properties .    in this paper , we focus on the third property above and its central role in certain multivariate procedures , in particular in independent components analysis ( section [ section - ica ] ) , in observational regression ( section [ section - obsreg ] ) and in graphical modeling ( section [ section - graphical ] ) .",
    "these cases illustrate why the use of plug - in methods should be done with some caution since not all scatter matrices necessarily satisfy this property .",
    "some counterexamples are given in section [ section - indep ] , where it is it also noted that using symmetrized versions of common robust scatter matrices can make the corresponding plug - in method more meaningful .",
    "some comments on the computational aspects of symmetrization are made in section [ section - comp ] .",
    "all computations reported in this paper were done using r 2.15.0 @xcite , and relied heavily on the r - packages ics @xcite , icsnp @xcite mass @xcite and spatialnp @xcite .",
    "proofs are reserved for the appendix .",
    "to begin , the next section briefly reviews that concepts of scatter matrices , affine equivariance and elliptical distributions , and sets up the notation used in the paper .",
    "many robust variants of the covariance matrix have been proposed within the statistics literature , with the vast majority of these variants satisfying the following definition of a scatter , or pseudo - covariance , matrix .",
    "[ scatterdef ] let @xmath3 be a @xmath0-variate random vector with cdf @xmath19 .",
    "a @xmath7 matrix valued functional @xmath20 is called a scatter functional if it is symmetric , positive semi - definite and affine equivariant in the sense that @xmath21 for any @xmath7 full rank matrix @xmath8 and any @xmath0-vector @xmath9 .",
    "a scatter statistic @xmath22 is then one that satisfies the above definition when @xmath19 is replaced by the empirical cdf .",
    "scatter statistics which satisfy this definition include m - estimators @xcite , minimum volume ellipsoids ( mve ) and minimum covariance determinant ( mcd ) estimators @xcite , s - estimators @xcite , @xmath23-estimators @xcite , projection based scatter estimators @xcite , re - weighted estimators @xcite and mm - estimates @xcite .",
    "definition  [ scatterdef ] emphasizes only the first two properties of the covariance matrix noted in lemma  [ covprop ] , with the other stated properties not necessarily holding for a scatter functional in general .",
    "in addition , a scatter statistic can not be viewed as an estimate of the population covariance matrix , but rather as an estimate of the corresponding scatter functional .",
    "for some important distributions , though , a scatter functional and the covariance matrix have a simple relationship .",
    "for example , elliptically symmetric distributions are often used to evaluate how well a multivariate statistical method performs outside of the normal family . for such distributions , it is known that if @xmath3 possesses second moments then @xmath24 .",
    "this relationship also holds for a broader class of distributions discussed below .",
    "we first recall the definition of elliptical distributions ( see e.g. * ? ? ?",
    "[ elldef ] a @xmath0-variate random vector @xmath4 is said to be spherically distributed around the origin if and only if @xmath25 for all orthogonal @xmath7 matrices @xmath26 .",
    "the random vector @xmath27 is said to have an elliptical distribution if and only if it admits the representation @xmath28 with @xmath4 having a spherical distribution , @xmath29 being a full rank @xmath7 matrix and @xmath30 being a @xmath0-vector .    if the density of an elliptical distribution exists , then it can be expressed as @xmath31 where @xmath32 is a function independent of @xmath33 and @xmath34 and @xmath35 .",
    "we then say that @xmath36 .",
    "( for a symmetric positive definite matrix @xmath37 , the notation @xmath38 refers to its unique symmetric positive semi - definite square root . )",
    "a generalization of the spherical distributions and of the elliptical distributions can be constructed as follows ( see * ? ? ?",
    "[ essdef ] a @xmath0-variate random vector @xmath4 is said to have an exchangeable sign - symmetric distribution about the origin if and only if @xmath39 for all @xmath7 permutation matrices @xmath40 and all @xmath7 sign - change matrices @xmath41 ( a diagonal matrix with @xmath42 on its diagonal ) .",
    "the density @xmath43 ( if it exists ) of an exchangeable sign - symmetric @xmath4 must satisfy the property that @xmath44 for any @xmath40 and @xmath41 .",
    "we then denote @xmath45 if and only if it admits the representation @xmath28 where @xmath4 has a exchangeable sign - symmetric distribution with density @xmath43 , @xmath29 is a full rank @xmath7 matrix and @xmath33 is a @xmath0-vector .",
    "note that in this model @xmath29 is not completely identifiable since @xmath46 for any @xmath40 and @xmath41 .",
    "however , @xmath47 is identifiable since @xmath48 . on the other hand , unlike the elliptical distributions , the distribution @xmath49 can not be completely determined from @xmath50 and @xmath34 .",
    "clearly the multivariate normal distributions are special cases of the family of elliptical distributions and the elliptical distributions in turn belong to the family of @xmath51 distributions .",
    "in particular , @xmath52 with @xmath53 .",
    "the @xmath51 distributions also contain other",
    "well studied distributions such as the family of @xmath54-norm distributions ( see for example * ? ? ?",
    "* ) . for @xmath45 in general , or @xmath36 in particular ,",
    "the parameter @xmath55 provided @xmath5 exist , with the constant of proportionality being dependent on the function @xmath43 or the function @xmath56 respectively .",
    "to simplify notation , it is hereafter assumed that these functions are standardize so that @xmath57 whenever @xmath3 which has finite second moments .",
    "if the second moments do not exist , then @xmath34 still contains information regarding the linear relationship between the components of @xmath3 .",
    "the following lemma notes that the relationship between @xmath34 and @xmath5 extends to any scatter functional .",
    "[ diagvess ] +    1 .   for any @xmath0-vector y which is exchangeable sign - symmetric around the origin",
    "all scatters matrices are proportional to the identity matrix , i.e. for any scatter functional @xmath58 which is well defined at @xmath4 , + @xmath59 where @xmath60 is a constant depending on the density @xmath43 of @xmath4 .",
    "2 .   for @xmath45 with @xmath61 ,",
    "if the scatter functional @xmath62 is well - defined at @xmath3 , then + @xmath63 where @xmath60 is a constant depending on the function @xmath43 .    for these models ,",
    "all scatter functionals are proportional and so any consistent scatter statistic is consistent for @xmath34 up to a scalar multiple .",
    "consequently , and especially when the function @xmath43 is not specified for the @xmath49 distribution , the parameter @xmath34 is usually only of interest up to proportionality .",
    "this motivates considering the broader class of shape functionals as defined below .",
    "lemma [ diagvess ] also holds when @xmath64 is taken to be a shape functional .",
    "[ shapedef ] let @xmath3 be a @xmath0-variate random vector with cdf @xmath19 .",
    "then any @xmath7 matrix valued functional @xmath20 is a shape functional if it is symmetric , positive semi - definite and affine equivariant in the sense that @xmath65 for any @xmath7 full rank matrix @xmath8 and any @xmath0-vector @xmath9 .",
    "an example of a shape functional which is not a scatter functional is the distribution - free m - estimate of scatter @xcite .",
    "it is worth noting that @xcite conjecture in their remark 1 that the @xmath51 distributions are perhaps the largest class of distributions which all scatter or shape matrices are proportional to each other . outside of this class , different scatter or shape statistics",
    "estimate different population quantities .",
    "this is not necessarily a bad feature , since as noted by several authors @xcite the comparison of different scatter / shape matrices can be useful in model selection , outlier detection and clustering .",
    "note that due to lemma [ diagvess ] , any scatter functional satisfies lemma [ covprop ] under an @xmath51 distribution ( although properties 3 , 4 and 5 are vacuous for any non - normal elliptical distribution since such distributions do not have any independent components ) . for general distributions , however , one must check that the scatter functional used in a plug - in method has the properties of the regular covariance matrix needed for the method at hand .",
    "although a zero covariance between two variable does not imply the variables are independent , the property that independence implies a zero covariance ( when the second moments exist ) is of fundamental importance when one wishes to view the covariance or correlation as a measure of dependency between variables .",
    "it has been pointed out by @xcite that many of the popular robust scatter matrices do not posses the property , but they do not present any concrete counterexample . this somewhat surprising observation is not well known and so in this section we explore it in more detail .",
    "some simple counterexamples are given which not only verify this observation but also demonstrates how large a _ pseudo - correlation _ , @xmath66 can be even when the corresponding variables are independent .",
    "the first example involves the family of weighted covariance matrices , which for a given @xmath67 is defined as @xmath68 where @xmath69 is the mahalanobis distance .",
    "it is easy to see that that @xmath70 satisfies definition [ scatterdef ] for a scatter matrix for @xmath3 and that it corresponds to the covariance matrix when @xmath71 .",
    "the weighted covariance matrices do not necessarily have good robustness properties , especially when @xmath72 since this corresponds `` up - weighing '' the values of @xmath3 based on their mahalanobis distances .",
    "they serve , though , as a tractable family of scatter matrices which helps us to illustrate our main points . for simplicity , assume without loss of generality that @xmath73 and @xmath74 , then @xmath75 suppose now that the components of @xmath3 are mutually independent and consider the case @xmath76 . this yields for the diagonal elements @xmath77 and for the off - diagonal elements @xmath78 since @xmath79 corresponds in this case to the skewness of the @xmath11th component of @xmath3 ( given that the components have mean zero and unit variance ) it follows that an off - diagonal element is zero only if at least one of the components has zero skewness .",
    "for example , consider the bivariate case @xmath80 with @xmath81 and @xmath82 being independent and each having the discrete distribution with probability mass function @xmath83 and @xmath84 .",
    "this gives @xmath85 and @xmath86 and hence a pseudo - correlation between @xmath81 and @xmath82 of 0.1743 even though they are independent .",
    "to demonstrate this idea further , figure  [ offfig ] shows the pseudo - correlation obtained from @xmath87 for different values of @xmath67 and @xmath0 in a setting where all @xmath0-components are mutually independent and each having a @xmath88 distribution .",
    "thus , the components have zero mean , unit variance and a skewness of @xmath89 .",
    "the results were obtained by taking the average , over 2000 repetitions , of the sample version of @xmath87 for samples of size 5000 .    .",
    "the vertical lines at 0 and 2 correspond to @xmath90 and @xmath91 respectively.,scaledwidth=80.0% ]    figure  [ offfig ] clearly shows that the pseudo - correlations based @xmath87 can be fairly large especially for negative values of @xmath67 .",
    "curiously , it is for @xmath92 that @xmath93 has a more robust flavor since it corresponds to down - weighing values rather than up - weighting values based on their original mahalanobis distances .",
    "it can also be noticed that the pseudo - covariances are zero when @xmath71 , which corresponds to the covariance matrix , and for @xmath94 .",
    "the case @xmath94 , @xmath95 is sometimes referred to as a _ kurtosis matrix _ , or as a matrix of fourth moments , since it involves the fourth moments of @xmath3 .",
    "it is known in general that @xmath95 is always diagonal whenever the components of @xmath3 are independent and possess fourth moments , which is a key result needed to justify the well - known _ fobi _ algorithm in independent components analysis @xcite .",
    "the next counterexample utilizes the minimum volume ellipsoid ( _ mve _ ) estimators @xcite . for a given @xmath96 , the _ mve _",
    "is defined as the ellipsoid with the minimum volume covering at least @xmath97 of the probability mass , say @xmath98 .",
    "the _ mve _",
    "location functional is then taken to be the center @xmath99 of this ellipsoid and the _ mve _ scatter functional @xmath100 is taken to be proportion to @xmath64 , with the constant of proportionality chosen so that @xmath100 corresponds to the covariance function when @xmath3 is multivariate normal . for our admittedly artificial example , suppose the random vector @xmath101 has independent components with each component following a multinomial distribution with support 0 , 1 and 2 and probabilities @xmath102 , @xmath103 and @xmath104 respectively . for @xmath105 , the points covered by the _ mve _ can be shown to be @xmath106 , @xmath107 and @xmath108 , which then implies that @xmath109 hence @xmath110 yield as a robust pseudo - correlation of @xmath111 between the two independent components of @xmath3 .",
    "of the scatter functionals considered so far , only @xmath90 and @xmath91 are known to be diagonal whenever the components are mutually independent .",
    "@xcite refer to this property as the _ independence property _ and discuss its importance in independent components analysis .",
    "since we are to consider various notions of the independence property here , we refer to this as the _ joint independence property_. that is ,    [ indpropdef ] a scatter matrix @xmath62 is said to have the joint independence property if , provided @xmath62 exists , @xmath112 whenever @xmath3 has independent components and where d(x ) is a positive diagonal matrix dependent on the distribution of @xmath3 .",
    "a common feature of @xmath5 and @xmath95 is that both can be expressed strictly in terms of pairwise differences .",
    "let @xmath113 and @xmath114 be two independent copies of @xmath3 , then @xmath115 @xmath116 in general , scatter functionals usually can not be expressed as a function of pairwise differences . on the other hand ,",
    "given any scatter functional , one can generate its _ symmetrized version _ by simply applying the functional to pairwise differences .",
    "[ symvdef ] let @xmath20 be a scatter functional .",
    "its symmetrized version is then defined to be @xmath117 where @xmath113 and @xmath114 are independent copies of @xmath3 .    symmetrized m - estimators are discussed in @xcite , while symmetrized s - estimators are discussed in @xcite",
    ". the symmetrized version of the covariance matrix is simply @xmath118 , whereas the symmetrized version of the kurtosis matrix is @xmath119 . as shown by theorem 1 of @xcite , any symmetrized scatter matrix ,",
    "provided it exists , possesses the joint independence property . an open question , though , is whether these exist scatter matrices possessing the joint independence property which can not expressed as a function of pairwise differences .",
    "consider again the case where @xmath3 consists of independent @xmath88 components .",
    "for @xmath120 and a sample size of 1000 , figure  [ offscatterfig ] shows the box - plots of the simulated distribution , based upon 2000 repetitions , of the pseudo - correlations using on ( i ) the regular covariance matrix @xmath90 , ( ii ) the m - estimator derived as the maximum likelihood estimator of an elliptical cauchy distribution @xmath121 @xcite , ( iii ) the symmetrized version of @xmath121 denoted as @xmath122 , ( iv ) the m - estimator using huber s weights @xmath123 @xcite , ( v ) the symmetrized version of @xmath123 denoted @xmath124 , ( vi ) tyler s shape matrix @xmath125 @xcite , ( vii ) the symmetrized version of @xmath125 denoted @xmath126 ( also known as dmbgen s shape matrix , @xcite ) , ( viii ) the minimum volume estimator @xmath127 @xcite and ( ix ) the minimum determinant estimator @xmath128 @xcite . throughout the paper ,",
    "unless stated otherwise , the tuning constant for @xmath123 and @xmath124 is taken to be 0.7 while for @xmath127 and for @xmath128 is taken to be @xmath129 , where @xmath130 is the sample size and @xmath0 the dimension .",
    "dimensional random vector @xmath3 having mutually independent @xmath88 components.,scaledwidth=80.0% ]    the box - plots are in agreement with our conjecture that in general only symmetrized scatter matrices have the joint independence property .",
    "the joint independence property is weaker than property 3 of lemma [ covprop ] .",
    "that is , a scatter matrix @xmath62 satisfying definition [ indpropdef ] does not necessarily give @xmath131 whenever @xmath132 and @xmath133 are independent .",
    "for example , consider the kurtosis matrix @xmath95 , which is known to satisfy the joint independence property .",
    "let @xmath134 and @xmath135 be mutually independent , each with zero mean and unit variance , and define @xmath136 , where @xmath137 and .",
    "it readily follows that @xmath138 and @xmath139 .",
    "moreover , @xmath81 and @xmath82 are independent , but a simple calculation gives @xmath140 which is non - zero even for the case when @xmath3 has a symmetric distribution .",
    "symmetrization does not help here since @xmath91 is already symmetrized .",
    "we conjecture that no scatter matrix , other than the covariance matrix , satisfies property 3 of lemma [ covprop ] in general .",
    "as noted in @xcite , if more assumptions on the distribution of @xmath3 other than just independence are made , then unsymmetrized scatter matrices can also yield zero pseudo - correlations .",
    "for example , if @xmath3 is symmetrically distributed about a center @xmath33 , then any scatter functional @xmath62 , provided it exist at @xmath3 , is a diagonal matrix .",
    "this result immediately implies that a symmetrized scatter matrix has the joint independence property . in the following , we state some further conditions under which independence implies a zero pseudo - correlation",
    "the first result shows that symmetry can be slightly relaxed .",
    "[ diagvsym ] let @xmath3 be a @xmath0-variate random vector with independent components . furthermore ,",
    "suppose @xmath141 components of @xmath3 are marginally symmetric , i.e.  for at least @xmath141 components , @xmath142 for some @xmath143 .",
    "then any scatter matrix @xmath62 , provided it exists at @xmath3 , is a diagonal matrix .",
    "next , consider the case for which all @xmath0 components are @xmath3 are not necessarily mutually independent , but rather that the @xmath0-vector @xmath3 consists of independent blocks of components .",
    "this means @xmath3 consists of @xmath144 sub - vectors @xmath145 with dimensions @xmath146 , @xmath147 , such the @xmath148 sub - vectors are mutually independent of each other .",
    "such a setup arises for example in independent subspace analysis ( isa ) @xcite .",
    "we refer to this property as the _ block independence property_.    [ indblockpropdef ] let @xmath3 have @xmath148 independent blocks with dimensions @xmath146 .",
    "the scatter matrix @xmath64 is said to have the block independence property if , provided @xmath62 exists at @xmath3 , @xmath149 where @xmath150 is a block diagonal matrix with block dimensions @xmath146 .",
    "clearly scatter matrices having the block independence property have the joint independence property .",
    "it is not clear though if the converse is true , i.e. whether the joint independence property implies the block independence property .",
    "nevertheless , as the corollary to the next theorem shows , symmetrization again assures that the scatter matrix has zeros at the right places .",
    "[ diagvindblock ] let @xmath151 have @xmath148 independent blocks with dimensions @xmath146 .",
    "if at least @xmath152 blocks are symmetric in the sense that @xmath153 where @xmath154 is the symmetry center of the @xmath10th block , then any scatter matrix @xmath62 , provided it exists at @xmath3 , will be block diagonal .",
    "[ diagvsymindblock ] any symmetrized scatter matrix @xmath155 has the block independence",
    "independent components analysis ( ica ) has become increasingly popular in signal processing and biomedical applications , where it is viewed as a practical replacement for principal components analysis ( pca ) .",
    "ica , in its most basic form , presumes that an observable random @xmath0-vector @xmath3 is a linear mixture of a latent random @xmath0-vector @xmath156 , with the components of @xmath156 being mutually independent .",
    "hence , the ica model is commonly given as @xmath157 where @xmath8 is a full rank _ mixing _ matrix . in order for the model to be identifiable , the _ signal _ @xmath156 can have at most one normally distributed component .",
    "even then , the mixing matrix @xmath8 and signal @xmath156 are not completely identifiable , since @xmath3 can also be represented as @xmath158 where @xmath159 and @xmath160 , with @xmath40 being a permutation matrix and @xmath161 being a full rank diagonal matrix .",
    "this , though , is the only indeterminacy in the model .",
    "the primary goal in independent components analysis ( ica ) is to then find an _ unmixing _",
    "matrix @xmath162 such that @xmath163 has independent components .",
    "consequently , for some permutation matrix @xmath40 and full rank diagonal matrix d , @xmath164 and @xmath165 . a general overview of ica can be found , for example , in the often cited ica book by @xcite .",
    "most approaches to ica typically begin by first whitening the data using the sample covariance matrix .",
    "this is based on the observation that @xmath166 where @xmath26 is an orthogonal matrix whenever @xmath156 is viewed as a standardized signal , i.e.  @xmath167 .",
    "after whitening the data , attention can then be focused on methods for rotating the uncorrelated components of @xmath4 to obtain independent components .",
    "the approach of course presumes that @xmath3 possesses second moments .",
    "an obvious , though naive , way to make this approach more robust would be to simply replace @xmath5 with some robust scatter matrix @xmath62 .",
    "this is proposed , for example , by ( * ? ? ?",
    "* section 14.3.2 ) , and by @xcite , who recommend using the minimum covariance determinant ( mcd ) estimator .",
    "however , in neither case is it noted that for such an approach to be valid either the signal @xmath156 must have a symmetric distribution , or more exactly to have at most one skewed component , or the robust covariance must satisfy the independence property ( [ indpropdef ] ) , which e.g.  is not satisfied by the mcd",
    ". problems in practice , when simply replacing the regular covariance matrix with the mcd in the context of the popular fastica method , have been noted by @xcite .",
    "the reason such problems can arise is that if @xmath62 does not satisfy ( [ indpropdef ] ) , then @xmath168 is not necessarily diagonal and hence the signal may not correspond to any rotation of @xmath169 .    to quantitatively demonstrate the relevance of the independence property",
    ", we consider the bivariate case where @xmath156 has two skew independent components , the first component having a @xmath170 distribution and the second component having a @xmath171 distribution , with both components being standardized to have mean zero and unit variance .",
    "for this example , we use the ica method proposed by @xcite .",
    "this ica method requires two scatter ( or shape ) matrices , say @xmath172 and @xmath173 , with both satisfying the independence property .",
    "the method consists of using @xmath174 to first whiten the data , giving @xmath175 , and then performing a principal component analysis on @xmath176 .",
    "the resulting principal components of @xmath4 then correspond to the independent components .",
    "the results are also the same when the roles of @xmath172 and @xmath173 are interchanged . for more details , see @xcite .",
    "a small simulation study was conducted using samples of size 1000 and with 1000 replications .",
    "since this ica method is affine invariant , the choice of the mixing matrix @xmath8 has no effect on the performance of the method , and so without loss of generality we take @xmath177 . using the terminology established in the earlier sections , we consider the following pairs of scatter matrices ( i ) @xmath90-@xmath178 ( ii ) @xmath121-@xmath90 , ( iii ) @xmath122-@xmath90 , ( iv ) @xmath125-@xmath123 , and ( v ) @xmath126-@xmath124 . case ( iii ) and ( v ) are the symmetrized version of ( ii ) and ( iv ) respectively . case ( i )",
    "is already the same as its symmetrized version , and it corresponds to the classical fobi method @xcite .",
    "note that only for the cases ( i ) , ( iii ) and ( v ) do both scatter matrices satisfy the independence property . to measure the performance of the methods , we use the minimum distance index md , proposed in @xcite , which is defined to be @xmath179 where @xmath40 is a permutation matrix and @xmath161 a diagonal matrix with non - zero entries .",
    "the range of the index is @xmath180 $ ] , with 0 corresponding to an optimal recovery of the independent components .",
    "box - plots for the simulations are shown in figure  [ icaex ] .",
    "the plots clearly show the relevance of the independence property here when there is more than one asymmetric component , even in case ( ii ) which consists on only one scatter matrix without the independence property .",
    "dimensions for the ica method based on two scatter matrices , for various choices of the scatter matrices .",
    "the first component has a @xmath181 distribution and the second a @xmath182 distribution.,scaledwidth=80.0% ]     +",
    "in this section we consider observation multivariate linear regression , that is linear regression for the case when the explanatory variables , as well as the responses , are randomly observed rather than controlled .",
    "the classical multivariate linear regression model is then @xmath183 where @xmath4 is a @xmath184-dimensional response , @xmath3 is a @xmath0-vector of explanatory variables with distribution @xmath185 , and @xmath186 is a random error term , independent of @xmath3 , with distribution @xmath187 . in this",
    "setting , interest usually is focused still on estimating the intercept vector @xmath188 , the @xmath189 slope matrix @xmath190 and perhaps the error variance - covariance matrix @xmath191 if it exists .",
    "the standard least squares approach is well known to be highly non - robust , and so there have been numerous proposed robust regression methods .",
    "one such method is based on the observation that if both @xmath3 and @xmath192 possess second moments , and if @xmath193 , then @xmath194 which corresponds to the population or functional version of the estimates arising from the least squares method .",
    "one can then generate a robust functional version by again simply replacing the first two moments with robust versions of scatter and location .",
    "that is , let @xmath195 , which concatenates @xmath3 and @xmath4 , and consider the corresponding partitions of an affine equivariant location functional @xmath196 and a scatter functional @xmath197 , @xmath198 if the distribution of @xmath192 is symmetric , then it has been observed in @xcite that the parameters @xmath67 and @xmath190 can also be identified , even if no moments exist , through the equations @xmath199 and so using the finite sample versions of @xmath196 and @xmath197 in the above relationship gives , under general regularity conditions , consistent estimates of @xmath190 and @xmath67 .",
    "this approach was first proposed for univariate multiple regression by @xcite using @xmath200-estimators of multivariate location an scatter .",
    "they note that this approach , unlike @xmath200-estimates of regression , yields bounded influence regression estimates .",
    "this approach has also been studied for the oja sign covariance matrix in @xcite , for the lift rank covariance matrix in @xcite , for s - estimators in @xcite and for the mcd in @xcite .",
    "the error variance @xmath201 is not a robust functional itself , and is not identifiable when the error term does not have second moments .",
    "consequently , it is usually replaced by a robust scatter matrix for the residual term .",
    "also , if @xmath192 does not have a symmetric distribution , then the intercept term @xmath67 is confounded with the location of the error term ( chapter 3 of * ? ? ?",
    "it has not been previously noted , though , how the relationship @xmath202 is affected by asymmetric error distributions .",
    "we first note that , due to the affine equivariance property of a scatter ( or shape ) functional @xmath197 , this relationship always yields the proper equivariance properties for the slope parameters .",
    "[ regequi ] let @xmath4 follow the regression model ( [ regmodel ] ) , assume that @xmath197 exists with @xmath203 being nonsingular , and denote @xmath204 .",
    "then @xmath205 is regression , scale and design equivariant .",
    "that is , for @xmath206 , nonsingular @xmath207 and nonsingular @xmath208 , @xmath209    despite these equivariance properties , in order to obtain @xmath210 , additional conditions on @xmath197 are needed , which as shown by corollary [ diagvsymindblock ] , holds for symmetrized scatter / shape matrices .",
    "[ regsymv ] let @xmath4 follow the regression model ( [ regmodel ] ) and assume that @xmath197 exists with @xmath203 being nonsingular .",
    "also , suppose @xmath197 satisfies the block independence property given by definition [ indblockpropdef ] , then @xmath211    consistency of the slope term under asymmetric errors has also been established for rank regression estimates and for @xmath200-estimates of regression . for details",
    "see for example ( chapter 3 of * ? ? ?",
    "* ) and ( chapter 4.9.2 of * ? ? ?",
    "* ) respectively .",
    "in order to demonstrate the necessity of symmetrization here whenever skewness is present in both @xmath3 and @xmath192 , we conducted a simulation study for the model @xmath212 where @xmath3 has a log - normal distribution with shape parameter @xmath213 standardized such that @xmath214 and @xmath215 and @xmath192 has an exponential distribution standardized to have @xmath216 and @xmath217 . for samples of size 2000 , @xmath218 is estimated using ( i ) the regular covariance matrix @xmath90 , ( ii ) m - estimator derived from as the maximum likelihood estimator of an elliptical cauchy distribution @xmath121 , ( iii ) the symmetrized version of @xmath122 , ( iv ) the m - estimator using huber s weights @xmath123 , ( v ) the symmetrized version of @xmath124 , ( vi ) tyler s shape matrix @xmath125 , ( vii ) the symmetrized version of @xmath126 , ( viii ) the minimum volume estimator @xmath127 and ( ix ) the minimum determinant estimator @xmath128 .",
    "the results , based on 1000 replications and presented in figure  [ regex ] , shows the severe bias when non - symmetrized scatter matrices are used .        which clearly shows that in this case the estimate for @xmath218 is severely biased when non - symmetrized scatter matrices are used .",
    "the last method considered in this paper is graphical modeling for quantitative variables based on undirected graphs . in graphical models ,",
    "one is usually interested in those pairs of variables which are independent conditional on all the other variables , or , in graphical modeling terminology , one is interested in those vertices ( variables ) which have no edges between them .",
    "in general , finding conditionally independent variables is challenging and so finding variables with zero partial correlations often serves as a proxy . in this section",
    ", we investigate the relationship between conditional independence and robust versions of the partial correlation .    for random variables ,",
    "consider the relationship between the variables @xmath219 and @xmath114 given @xmath3 , with @xmath3 containing the remaining @xmath220 variables . denoting @xmath221 ,",
    "the partial variance - covariance matrix of @xmath4 given @xmath3 is given by @xmath222 where @xmath223 , which corresponds to the covariance matrix of the residuals between the orthogonal projections of @xmath219 and @xmath114 onto the @xmath220-dimensional subspace spanned by @xmath3 .",
    "the corresponding partial correlation between @xmath219 and @xmath114 given @xmath3 is then simply @xmath224 the partial correlation can also be expressed in terms of the precision or concentration matrix of the combined vector @xmath225 .",
    "specifically , expressing the precision or concentration matrix of @xmath226 as @xmath227 , for @xmath228 , where @xmath229 , one obtains @xmath230 and hence @xmath231 if and only if @xmath232 .    for gaussian graphical models , for which @xmath226 is presumed to be multivariate normal",
    ", conditional independence between @xmath219 and @xmath114 given @xmath3 , i.e.  @xmath233 , is equivalent to the partial correlation @xmath231 . in general",
    ", conditional independence implies a conditional correlation of zero , presuming the second moments exist , although the converse does not hold in general .",
    "however , a perhaps lesser known result is that conditional independence does not imply a zero partial correlation in general .",
    "some additional conditions are needed . in particular ,",
    "if the regression of @xmath4 on @xmath3 is linear , then conditional independence implies a zero partial correlation , see theorem 1 in @xcite . under such conditions ,",
    "variables having zero partial correlations then serve as candidates for conditionally independent variables .",
    "when used in place of conditional independence , zero partial correlations help provide a parsimonious understanding of the relationship between variables .",
    "robustness issues have been considered for graphical models , see for example @xcite and @xcite . in both papers ,",
    "the emphasis is on finding pairs of variables for which a robust version of the partial correlations are zero .",
    "the approach used in @xcite is a robust graphical lasso .",
    "the method uses a penalized maximum likelihood approach based on an elliptical @xmath234-distribution .",
    "the approach advocated in @xcite is a plug - in method based on using robust scatter matrices .",
    "they also study the asymptotic properties of the plug - in method under elliptical distributions .",
    "consequently , neither paper addresses conditional independence since conditional independence can never hold for variables following a joint elliptical distribution other than the multivariate normal .    outside the elliptical family ,",
    "an important question worth addressing is under what conditions does conditional independence imply that the the plug - in version of the partial correlation equals zero ?",
    "since regression , i.e. the conditional mean of @xmath4 given @xmath3 , is itself not a robust concept and also is naturally related to covariances , the condition that regression be linear is not helpful here .",
    "we leave general conditions under which conditional independence implies a zero robust partial correlation as an open question . we can , though , obtain results for the following model @xmath235 where @xmath8 is a non - random @xmath236 matrix , @xmath237 , and @xmath3 , @xmath238 and @xmath239 are mutually independent . for this model",
    ", it readily follows that @xmath233 . also , if the first moments exist then the regression of @xmath4 on @xmath3 is linear . again , if one uses symmetrized scatter matrices than one obtains a plug - in version of the partial correlation which is equal to zero under this model .",
    "[ graphmodtheo ] suppose model ( [ graphmodel ] ) holds , and assume that @xmath197 exists and is nonsingular .",
    "also , suppose @xmath197 satisfies the block independence property given by definition [ indblockpropdef ] , then @xmath240 where @xmath241 is the @xmath242th element of the corresponding precision matrix .",
    "as an example for illustrating theorem  [ graphmodtheo ] , consider the simple graphical model given in figure  [ graph ] , where @xmath243 and @xmath244 , with @xmath3 having a standard normal distribution , @xmath245 a log - normal distribution with shape parameter @xmath213 standardized such that @xmath246 and @xmath247 and @xmath248 a @xmath181 distribution standardized to have @xmath249 and @xmath250 .",
    "using the same nine scatter matrices ( i)-(ix ) as in the previous section , box plots for the plug - in partial correlation of @xmath219 and @xmath114 given @xmath3 for sample of size 2000 based on 1000 replications are presented in figure  [ graphex ] .",
    "again , the advantage to using symmetrized scatter / shape matrices is clearly shown .",
    "for various robust multivariate plug - in methods , we recommend symmetrized scatter matrices since they help protect against severe bias whenever skew components are present . a drawback to using symmetrized scatter matrices , though , is that they are more computationally intensive than their non - symmetrized counterparts . for a sample of size @xmath130 ,",
    "a symmetrized scatter matrix involves @xmath251 pairs . on the other hand",
    ", it does not require an estimate of location since the difference is centered at the origin .",
    "consequently , only those pairwise differences @xmath252 for which @xmath253 are required for its computation and so the number of pairwise differences needed reduces somewhat to @xmath254 .",
    "modern computers , though , have become so powerful that computational cost should not deter the use of symmetrized scatter matrices when appropriate .",
    "unfortunately , most robust scatter matrices implemented in packages such as r do not allow the option of specifying the location vector , and so can not be applied readily in computing symmetrized scatter matrices .",
    "we hope the discussion in this paper will motivate future implementations of scatter matrices to include a fixed location option , as is the case in the r packages ics and icsnp",
    ".    it may be difficult in general to develop algorithms which spread the computation of a scatter matrix over several cores . for @xmath200-estimates of scatter ,",
    "though , parallelization is possible . to see this",
    ", we note that when computing a symmetrized @xmath200-estimate of scatter @xmath255 via the simple iteratively weighted least squares algorithm , the update step is given by @xmath256 where @xmath257 is the current value of the scatter matrix and @xmath258 is the weight function associated with the @xmath200-estimate . a simple way to compute the symmetrized scatter matrix @xmath255 which allows parallelization is to then set @xmath259 and",
    "so the iteration update for the symmetrized version becomes @xmath260 to illustrate computation times , we considered the symmetrized version of tyler s shape matrix @xmath126 , i.e.  dmbgen s shape matrix , implemented as ` duembgen.shape ` in the r - package icsnp and the symmetrized @xmath200-estimator of scatter using huber s weights @xmath124 implemented as ` symm.huber ` in the r - package spatialnp .",
    "the average computing times out of 5 runs for @xmath261 data , where @xmath262 was randomly chosen , computed on a intel(r ) xeon(r ) cpu x5650 with 2.67ghz and 24 gb of memory running a 64-bit redhat linux are presented in figure  [ compt ] .",
    "the figure shows that the computation time as of function of sample size is close to linear when plotted on a log - log scale with a slope of approximately 2 .",
    "hence , the computation times are approximately of the order @xmath251 .",
    "also , for samples of size @xmath263 the computation times tend to be around one second , and that the symmetrized @xmath200-estimates are computationally feasible for even fairly large sample sizes . as a comparison , for @xmath264",
    ", computation times for the non - symmetrized version of the m - estimators are also shown in the figure .    ) and for the symmetrized huber m - estimator of scatter ( @xmath124 ) for various sample sizes @xmath130 and dimensions @xmath0 .",
    "both axes are given on a log - scale .",
    "the non - symmetrized version of the m - estimators are also given for @xmath264.,scaledwidth=80.0% ]",
    "the goal of this paper has been to stress that some important or `` good '' properties of the covariance matrix do not necessarily carry over to affine equivariant scatter matrices .",
    "consequently , it is necessary to exercise some caution when implementing robust multivariate procedures based on the plug - in method , i.e.  when substituting a robust scatter matrix for the covariance matrix in classical multivariate procedures .",
    "in particular , the validity of some important multivariate methods require that the scatter matrix satisfy certain independence properties , which do not necessarily hold whenever the components arise from a skewed distribution .",
    "thus , we recommended the use of symmetrized scatter matrices in such situations , since they are the only known scatter matrices which satisfy the independence property , definition [ indpropdef ] , or the block independence property , definition [ indblockpropdef ] .",
    "we further conjecture that the only scatter matrices that satisfy these independence properties are those which can be expressed in terms of the pairwise differences of the observation .",
    "this paper has focused on the independence properties of scatter matrices .",
    "it would also be worth considering which scatter matrices , if any , possess the additivity property of the covariance matrix , lemma [ covprop].4 .",
    "this property is relevant in factor analysis , in structural equation modeling , and in other multivariate methods .",
    "for example , the factor analysis model is given by @xmath265 where @xmath43 corresponds to @xmath266 latent factors and @xmath192 corresponds to a @xmath0-variate error term . @xmath192 .",
    "the parameter @xmath33 represents a @xmath0-variate location and @xmath267 corresponds to the @xmath268 matrix of factor loadings ( defined up to an orthogonal transformation ) .",
    "the standard factor analysis assumptions are that the components of both @xmath43 are @xmath192 are mutually independent , and that @xmath43 and @xmath192 are also independent of each other .",
    "furthermore , if the first two moments exist , then is further assumed without loss of generality that @xmath269 , @xmath270 , @xmath216 and @xmath271 , where @xmath161 is a diagonal matrix with positive entries .",
    "consequently , one can view such as factor analysis model as a reduced rank covariance model with an additive diagonal term , i.e.  as @xmath272 this decomposition is central to the classical statistical methods in factor analysis .",
    "it is not clear though if one can define other scatter matrices so that @xmath273 with both @xmath274 and @xmath275 being diagonal .",
    "some robust plug - in methods for factor analysis and structural equation models have been considered by @xcite and @xcite .",
    "let @xmath41 again represents a sign - change matrix , that is a diagonal matrix with diagonal elements of either @xmath42 . also , let @xmath40 represent a permutation matrix obtained by permuting the rows and or columns of @xmath276 .      for part 1 , if @xmath277 for all @xmath40 and @xmath41 then @xmath278 for all @xmath41 , which implies all off - diagonal elements are zero .",
    "also , since @xmath279 for all @xmath40 , it follows that all the diagonal elements are equal .",
    "hence , @xmath280 , where @xmath60 is a constant depending on the density of @xmath4 .",
    "part 2 of the lemma then follows from affine equivariance .",
    "let @xmath281 be a vector with independent components where @xmath141 components are marginally symmetric .",
    "let @xmath282 be the component which is not necessarily symmetric and let @xmath283 be any sign - change matrix for which the @xmath10th diagonal element is @xmath284 .",
    "hence , @xmath285 and due to the affine equivariance of @xmath64 we have @xmath286 for any such @xmath283 .",
    "this implies @xmath287 for @xmath288 and hence @xmath62 is a diagonal matrix .",
    "let @xmath151 have @xmath148 independent blocks with dimensions @xmath146 , where all but the @xmath10th block are symmetric in the sense that @xmath289 .",
    "let @xmath290 denote a block sign - change matrix where the signs are changed according to blocks having dimension @xmath146 respectively .",
    "also let @xmath291 denote a block sign - change matrix matrix where the @xmath10th diagonal block is @xmath292 .",
    "since @xmath293 for any such @xmath291 , it follows from the affine equivariance of @xmath64 that @xmath294 .",
    "this implies that off - diagonal block elements are zero and hence @xmath62 is block - diagonal with blocksizes @xmath146 .",
    "let @xmath3 have @xmath148 independent blocks and let @xmath113 and @xmath114 be independent identical copies of @xmath3 .",
    "then also @xmath295 has @xmath148 independent blocks .",
    "furthermore all blocks of @xmath295 are symmetric around the origin and so the corollary follows from theorem  [ diagvindblock ] .",
    "due to the equivariance properties stated in lemma  [ regequi ] it is sufficient to consider the case for which @xmath71 and @xmath296 . for this case @xmath297",
    "consists two independent blocks of dimensions @xmath0 and @xmath184 , which by theorem  [ diagvsymindblock ] implies @xmath197 is block diagonal .",
    "consequently , @xmath298 and so @xmath299 .",
    "let @xmath300 . by property [ indblockpropdef ]",
    ", it follows that @xmath301 where @xmath302 is a @xmath303 diagonal matrix with positive diagonal terms , and @xmath200 is @xmath304 positive definite symmetric matrix . by affine equivariance , under model ( [ graphmodel ] ) it then follows that @xmath305 taking the inverse gives @xmath306 thus , @xmath307 .",
    "ilmonen , p. , nordhausen , k. , oja , h. & ollila , e. ( 2010 ) . a new performance index for ica : properties , computation and asymptotic analysis . in _ latent variable analysis and signal separation _ , v.  vigneron , v.  zarzoso , e.  moreau , r.  gribonval & e.  vincent , eds . heidelberg : springer , pp . 229236 .",
    "nordhausen , k. , oja , h. & ollila , e. ( 2011 ) .",
    "multivariate models and the first four moments . in _ nonparametric statistics and mixture models : a festschrift in honor of thomas p. hettmansperger _ , d.  hunter , d.  richards & j.  rosenberger , eds .",
    "singapore : world scientific , pp .",
    "267287 .",
    "ollila , e. , oja , h. & hettmansperger , t.  p. ( 2002 ) .",
    "estimates of regression coefficients based on the sign covariance matrix .",
    "_ journal of the royal statistical society : series b ( statistical methodology ) _ * 64 * , 447466 .",
    "rousseeuw , p.  j. ( 1986 ) .",
    "multivariate estimation with high breakdown point . in _ mathematical statistics and applications _ , w.  grossman , g.  pflug , i.  vincze & w.  wertz , eds .",
    "dordrecht : reidel , pp ."
  ],
  "abstract_text": [
    "<S> many multivariate statistical methods rely heavily on the sample covariance matrix . </S>",
    "<S> it is well known though that the sample covariance matrix is highly non - robust . one popular alternative approach for `` robustifying '' the multivariate method is to simply replace the role of the covariance matrix with some robust scatter matrix . </S>",
    "<S> the aim of this paper is to point out that in some situations certain properties of the covariance matrix are needed for the corresponding robust `` plug - in '' method to be a valid approach , and that not all scatter matrices necessarily possess these important properties . in particular , the following three multivariate methods are discussed in this paper : independent components analysis , observational regression and graphical modeling . for each case </S>",
    "<S> , it is shown that using a symmetrized robust scatter matrix in place of the covariance matrix results in a proper robust multivariate method . + </S>",
    "<S> * keywords * : factor analysis ; graphical model ; independent components analysis ; observational regression , scatter matrix , symmetrization . </S>"
  ]
}