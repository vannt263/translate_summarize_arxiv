{
  "article_text": [
    "let us first explain our problem more formally . consider two dits @xmath0 and @xmath1 , where the string @xmath2 plays the role of the whole , and @xmath0 , @xmath3 are the individual parts .",
    "let @xmath4 denote an encoding of the string @xmath5 into a classical or quantum state .",
    "in quantum theory , @xmath4 is simply a density operator , and in a nc - hv model it is a preparation @xmath6 described by a probability distribution over hidden variables @xmath7 .",
    "let @xmath8 be a probability distribution over @xmath9 , and imagine that with probability @xmath10 we are given the state @xmath4 .",
    "the optimum probability of guessing @xmath5 given its encoding @xmath4 , which lies in a register @xmath11 , can be written as @xmath12 where @xmath13 is the probability of obtaining outcome @xmath5 when measuring the preparation @xmath6 with @xmath14 , and the maximization is taken over all @xmath15-outcome measurements allowed in the theory . in the case of quantum theory , for example , the maximization is taken over povms @xmath16 and @xmath17 .",
    "the guessing probability is directly related to the conditional min - entropy @xmath18 through the equation  @xcite @xmath19 this measure plays an important role in quantum cryptography and is the relevant measure of information in the single shot setting corresponding to our everyday experience , as opposed to the asymptotic setting captured by the von neumann entropy .",
    "a closely related variant is the smooth min - entropy @xmath20 which can be thought of as being like @xmath18 except with some small error probability @xmath21 .",
    "the main question we are interested in can then be loosely phrased as :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ how does @xmath22 ( ignorance about the whole ) relate to @xmath23 , for @xmath24 ( ignorance about the parts ) ? _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    here the introduction of the additional random variable @xmath25 is crucial , and it can be understood as a pointer to the part of @xmath26 about which there is large ignorance ( given a large ignorance of the whole string @xmath26 ) ; see figure  [ fig : game ] for an illustration of this role . it is important to note that the choice of @xmath25 should be consistent with the encoding prior to its definition",
    "that is , whereas @xmath25 may of course depend on @xmath27 and the encoding @xmath11 , the reduced state on registers holding @xmath27 and @xmath11 after tracing out @xmath25 should remain the same .",
    "in particular , this condition states that @xmath25 can not be the result of a measurement causing disturbance to the encoding register ; if we were allowed to destroy information in the encoding we would effectively alter the original situation .",
    "* an inequality valid in any nc - hv model . *    we first show that classically , or more generally in any non - contextual hidden variable model  @xcite , ignorance about the whole really _ does _ imply ignorance about a part .",
    "more specifically , we show that for any random variable @xmath28 and side information @xmath11 , there exists a random variable @xmath24 such that @xmath29 this inequality can be understood as an information - theoretic analogue of bell inequalities to the question of non - contextuality .",
    "classically , this inequality is known as the _ min - entropy splitting inequality _ , and plays an important role in the proof of security of some ( classical ) cryptographic primitives  @xcite .",
    "the proof of   is a straightforward extension to the case of standard nc - hv models  @xcite of a classical technique known as min - entropy splitting first introduced by wullschleger  @xcite , and we defer details to the appendix .    the fact that @xmath25 is a random variable , rather than being deterministically chosen , is important , and an example will help clarify its role . consider @xmath26 uniformly distributed over @xmath9 and @xmath30 with probability @xmath31 , and @xmath32 with probability @xmath31 . in this case",
    "it is easy to see that _ both _ @xmath33 and @xmath32 can be guessed from @xmath11 with average success probability @xmath34 , so that @xmath35 , which is much less than @xmath36 .",
    "however , define @xmath25 as @xmath37 if @xmath38 and @xmath39 if @xmath40 .",
    "then it is clear that @xmath41 , as we are always asked to predict the variable about which we have no side information at all ! in this case the random variable @xmath25 `` points to the unknown '' by being correlated with the side information @xmath11 , but is entirely consistent with our knowledge about the world : by tracing out @xmath25 we recover the initial joint distribution on @xmath42 .",
    "this also highlights the important difference between the task we are considering and the well - studied random access codes  @xcite , in which the requirement is to be able to predict one of @xmath27 ( adversarially chosen ) from their encoding ; for this task it has been demonstrated that there is virtually no asymptotic difference between classical and quantum encodings ( see below for a discussion ) .",
    "it is interesting to note that   still holds if we consider a somewhat `` helpful '' physical model in which in addition to the encoding one might learn a small number of `` leaked '' bits of information about @xmath26 .",
    "more specifically , if the nc - hv discloses @xmath43 extra bits of information then it follows from the chain rule for the min - entropy ( see appendix ) that @xmath44    * violation in quantum theory . * our main result shows that   is violated in the strongest possible sense by quantum theory .",
    "more specifically , we provide an explicit construction that demonstrates this violation : let @xmath45 be uniformly distributed over @xmath9 .",
    "given @xmath46 , define its encoding @xmath47 as    @xmath48    where @xmath49 and @xmath50 are the generalized pauli matrices and @xmath51 with @xmath52 being the matrix of the fourier transform over @xmath53 . since we are only interested in showing a quantum violation , we will for simplicity always assume that @xmath54 is prime  @xcite .",
    "the system @xmath55 is then described by the ccq - state @xmath56 we first prove that @xmath57 for our choice of encoding .",
    "we then show the striking fact that , even though the encoding we defined gives very little information about the whole string @xmath26 , for any adversarially chosen random variable @xmath25 ( possibly correlated with our encoding ) one can guess @xmath58 from its encoding @xmath59 with essentially constant probability .",
    "more precisely , for any ccqc - state @xmath60 , with @xmath24 , that satisfies the consistency relation @xmath61 , we have @xmath62 for _ any _ sufficiently large @xmath54 .",
    "this shows that the inequality   can be violated arbitrarily ( with @xmath54 ) , giving a striking example of the malleability of quantum information .",
    "what s more , it is not hard to show that this effect still holds even for @xmath63 , for constant error @xmath21 , and a `` helpful '' physical model leaking @xmath64 bits of information with @xmath65 .",
    "hence , the violation of the inequality   has the appealing feature of being very robust . indeed , for any number of bits @xmath43 a nc - hv might leak in addition ,",
    "we could find a @xmath54 to ensure a violation .",
    ", clearly chosen uniformly at random .",
    "unfortunately , he never actually attended and had insufficient time to prepare for his exam .",
    "luckily , however , he has been given some encoding @xmath11 of the possible answers @xmath66 , hastily prepared by his old friend alice .",
    "when entering the room , he had to submit @xmath11 for inspection to the challenger who knows @xmath33 , @xmath32 as well as the encoding alice might use . after inspection ,",
    "the challenger may secretly keep a system @xmath25 , possibly correlated with @xmath11 , but such that the reduced system on @xmath33 , @xmath32 and @xmath11 looks untampered with .",
    "it is immediately obvious to the challenger that bob must be ignorant about the whole of @xmath66 . but can it always measure and point to a @xmath67 such that bob is ignorant about @xmath58 ? that is , can it always detect bob s ignorance by challenging him to output a single @xmath58 ?",
    "classically , this is indeed possible : ignorance about the whole of @xmath66 implies significant ignorance about one of the parts , @xmath58 .",
    "however , a quantum bob could beat the owl . ]",
    "we now provide an outline of the proof that the encoding specified in   leads to a quantum violation of the splitting inequality  ; for completeness , we provide a more detailed derivation in the appendix .",
    "our proof proceeds in three steps : first , by computing @xmath18 we show that the encoding does indeed not reveal much information about the whole .",
    "second , we compute the optimal measurements for extracting @xmath33 and @xmath32 on average , and show that these measurements perform equally well for any other prior distribution on @xmath26 .",
    "finally , we show that even introducing an additional system @xmath25 does not change one s ability to extract @xmath58 from the encoding .",
    "* step 1 : * very intuitively , ignorance about the whole string already follows from holevo s theorem and the fact that we are trying to encode 2 dits into a @xmath54-dimensional quantum system . to see this more explicitly ,",
    "recall that @xmath57 is equivalent to showing that @xmath68 . from   we",
    "have that this guessing probability is given by the solution to the following semidefinite program ( sdp )    maximize@xmath69 & @xmath70  , + & @xmath71  .",
    "the dual sdp is easily found to be    minimize@xmath72 & @xmath73  .",
    "let @xmath74 and @xmath75 be the optimal values of the primal and dual respectively . by the property of weak duality , @xmath76 always holds .",
    "hence , to prove our result , we only need to find a primal and dual solutions for which @xmath77 .",
    "it is easy to check that @xmath78 is a dual solution with value @xmath79 .",
    "similarly , consider the measurement @xmath80 .",
    "using schur s lemma , one can directly verify that @xmath81 , giving @xmath82 .",
    "the claimed value of the conditional min - entropy follows .    *",
    "step 2 : * a similar argument , exploiting the symmetries in the encoding , can be used to show that @xmath83 the measurements that attain these values are given by the eigenbases of @xmath50 and @xmath49 respectively .    as a remark to quantum information theorists , note that this means that our encoding doubles as a random access encoding of the string @xmath5 into a @xmath54-dimensional quantum state @xmath4 with probability   to recover @xmath0 or @xmath3 . for @xmath84 ,",
    "such encodings have previously been considered in the realm of contextuality as a reinterpretation of the chsh inequality  @xcite .",
    "however , we note that this is _ not _ what is surprising here , as there exists an obvious classical random access encoding for 2 dits into a single dit ( see discussion on @xmath25 above ) , with recovery probability @xmath85 .",
    "simply computing   is hence insufficient for our purposes .",
    "let us write @xmath86 for the eigenbasis of @xmath50 , and note that its fourier transform @xmath87 is then the eigenbasis of @xmath49 . exploiting the symmetries in our problem ,",
    "it is straightforward to verify that for all @xmath88 @xmath89 an important consequence of this is that for _ any _ other prior distribution @xmath90 , measurement in the @xmath50 eigenbasis distinguishes the states @xmath91 with probability at least @xmath92 , even when the distribution is unknown .",
    "a similar argument can be made for the marginal states @xmath93 and measurement in the @xmath49 eigenbasis .",
    "* step 3 : * it now remains to show that , for any possible choice of an additional classical system",
    "@xmath25  @xcite , one can still guess @xmath58 from the encoding with a good success probability : one can not construct a @xmath25 which would `` point to the unknown '' . note that we may express the joint state with any other system @xmath25 as @xmath94 for some states @xmath95 on registers @xmath11 and @xmath25 .",
    "since the reduced state on @xmath33,@xmath32 and @xmath11 should be the same for any @xmath25 we have by the fact that @xmath33 and @xmath32 are classical that @xmath96 .",
    "since @xmath97 is a pure state , this implies that @xmath98 .",
    "now imagine that we were to perform some arbitrary measurement on @xmath25 , whose outcome would supposedly point to an unknown substring . but this merely creates a different distribution @xmath90 over encoded strings , and we already know from the above that we can still succeed in retrieving either @xmath0 or @xmath3 with probability at least @xmath92 by making a measurement in the @xmath49 or @xmath50 basis respectively . hence for large @xmath54 we have a recovery probability of roughly @xmath31 , implying @xmath99 which is our main claim .",
    "note that the consistency condition , which states that our choice of @xmath25 should be compatible with the original situation and should not affect the reduced state , is important , and makes our task non - trivial .",
    "as an example , consider our construction for @xmath84 . in that case",
    "the encoding states lie in the xz - plane of the bloch sphere .",
    "imagine now that we measured the encoding register @xmath11 in the eigenbasis of @xmath100 , and let the outcome be @xmath25 .",
    "but for any measurement in the eigenbasis of @xmath100 we observe entirely random outcomes , and the post - measurement states trivially no longer carry any information about the encoded string . indeed",
    ", any choice of @xmath25 would do if we are allowed to destroy information in such a manner .",
    "our result answers an interesting open question in quantum cryptography  @xcite , namely whether min - entropy splitting can still be performed when conditioned on quantum instead of classical knowledge .",
    "this technique was used to deal with classical side information @xmath11 in  @xcite .",
    "our example shows that quantum min - entropy splitting is impossible , even when we would be willing to accept subtracting a large error term on the r.h.s . of",
    "this tells us that classical protocols that rely on such statements may become insecure in the presence of quantum side information , and highlights the importance of so - called min - entropy sampling results of  @xcite used in quantum cryptography  @xcite instead .",
    "it also indicates that contextuality may play a more important role in our understanding of the possibilities and limits of quantum cryptography than previously thought .",
    "the first indication that something may be amiss when looking at knowledge from a quantum perspective was given by schrdinger  @xcite , who pointed out that one can have _ knowledge _ ( not ignorance ) about the whole , while still being ignorant about the parts  @xcite .",
    "here , we tackled this problem from a very different direction , starting with the premise that one has ignorance about the whole .",
    "our results show that contextuality is responsible for much more significant effects than have previously been noted .",
    "in particular , it leads to arbitrarily large quantum violations of  , which can be understood as a bell - type inequality for non - contextuality .",
    "this is still true even for a somewhat `` helpful '' physical model , leaking additional bits of information . to our knowledge",
    ", this is the first _ information - theoretic _",
    "inequality distinguishing nc - hv models from quantum theory .",
    "our question and perspective are completely novel , and we hope that our observations will lead to an increased understanding of the role of contextuality . in this work ,",
    "we have considered standard nc - hvs in which all hvs can be decomposed as convex combinations of extremal hvs which give deterministic outcomes for effects ( see appendix ) .",
    "it is an interesting open question whether our results can be generalized to very general models that distinguish between measurement and preparation contextuality  @xcite .    at the heart of our result",
    "lies the fact that contextuality allows for strong forms of complementarity in quantum mechanics ( often conflated with uncertainty  @xcite ) , which intuitively is responsible for allowing the violation of  .",
    "typically , complementarity is discussed by considering examples of properties of a physical system that one may be able to determine individually , but which can not all be learned at once . in spirit , this is similar to the notion of a random access encoding where we could determine either property @xmath33 or @xmath32 quite well , but not all of @xmath26 .",
    "however , as discussed above this can also be true classically , in a probabilistic sense .",
    "we would thus like to emphasize the novelty of our perspective , as we approach the problem from the other end , and first demonstrate the general result that in an nc - hv ignorance about the whole always implies ignorance about a part .",
    "we then show that in a quantum world , this principle is violated in the strongest possible sense , even with respect to an additional system @xmath25 .",
    "one could think of this as a much more robust way of capturing the intuitive notion of complementarity  @xcite .",
    "finally , it is an interesting open question whether our inequality can be experimentally verified .",
    "note that this made difficult by the fact that our aim would be to test _ ignorance _ rather than knowledge .",
    "however , it is conceivable that such an experiment can be performed by building a larger cryptographic protocol whose security relies on being ignorant about one of the parts of a string @xmath26 created during that protocol  @xcite . a quantum violation",
    "could then be observed by breaking the security of the protocol , and exhibiting _ knowledge _ ( rather than ignorance ) about some information that could not have been obtained if the protocol was secure .",
    "we thank jonathan oppenheim , christian schaffner , tony short , robert spekkens and cqt s  non - local club  for useful comments .",
    "we are particularly grateful to tony short for pointing out that our problem could more easily be explained by means of the game depicted in figure  [ fig : game ] .",
    "tv was supported by aro grant w911nf-09 - 1 - 0440 and nsf grant ccf-0905626 .",
    "sw was supported by the national research foundation , and the ministry of education , singapore .",
    "tv is grateful to cqt , singapore , for hosting him while part of this work was done .",
    "sw is grateful for an invitation from the mittag - leffler institute , sweden , where part of this work was performed .",
    "21 natexlab#1#1bibnamefont # 1#1bibfnamefont # 1#1citenamefont # 1#1url # 1`#1`urlprefix[2]#2 [ 2][]#2    , * * , ( ) .",
    ", , , * * ( ) .    , in _ _ ( , ) , lecture notes in computer science .    , , , , , in _ _ ( , ) , vol . of _ _ , pp . .    , in _ _",
    "( ) , pp . .    , , , , in _ _ ( ) , pp . .",
    ", , , , * * , ( ) .    , , ( ) , .    , , , , * * , ( ) .    , , , , , * * , ( ) .",
    "( ) , .    , , , , in _ _ ( ) , pp . .",
    "( ) , .    , , ( ) , .    , * * , ( )",
    ".    , * * , ( ) .",
    "( ) , .    , * * , ( ) .    , ph.d",
    ". thesis , ( ) , .    , _ _ ( ) .    , * * , ( ) .    in this appendix",
    ", we provide a detailed derivation of our results . to this end",
    ", we first provide some more detailed background on the entropic quantities we use in section  [ sec : entropy ] . in section",
    "[ sec : lhv ] we show that the splitting inequality   is satisfied in any deterministic non - contextual hidden variable model ( nc - hv model for short ) .",
    "this is a minor twist on the existing classical proof  @xcite due to wullschleger  @xcite .",
    "finally , in section  [ sec : encoding ] , we proceed to prove our main result , that there exists a quantum encoding which strongly violates the splitting inequality  .",
    "throughout , we will measure information in terms of the min - entropy , which is directly related to the _ guessing probability _",
    "@xmath101  @xcite , where @xmath26 is a classical string ranging in the set @xmath102 and @xmath11 an auxiliary system .",
    "it is defined as the maximum probability with which one can predict the whole string @xmath26 , given the system @xmath11 .",
    "the maximization is over all possible observations , or measurements , on @xmath11 ; these vary depending on the physical model ( e.g. classical or quantum ) under consideration .",
    "[ def : ncguess ] let @xmath26 be a classical random variable with distribution @xmath8 taking values in a set @xmath102 , and @xmath103 any set of preparations on @xmath11 . then the maximum guessing probability of @xmath26 given @xmath11 is defined as @xmath104 where the maximum is taken over all measurements @xmath105 allowed in the model .",
    "for instance , in the case of quantum mechanics we simply have @xmath106 where the maximization is taken over all povms  @xcite and @xmath107 denotes the reduced state of the system on @xmath11 , when @xmath108 . for _ classical _ side - information @xmath11",
    "this expression simplifies to @xmath109\\ .\\end{aligned}\\ ] ] in other words , for classical side information , the optimal guessing measurement is to simply output the @xmath5 which is most likely given the classical value @xmath110 .    for the case of classical and quantum theories",
    "it is known that the guessing probability directly relates to the conditional min - entropy  @xcite . here , we follow the operational approach of  @xcite , and define the conditional min - entropy for an arbitrary theory with classical @xmath26 as @xmath111 for the case of quantum systems , the conditional min - entropy was first introduced by renner  @xcite as a way to measure randomness conditioned on an adversary s knowledge .",
    "the min - entropy can also be defined when @xmath26 is quantum itself  @xcite , but we will not need it here . in the quantum setting , we will also use a smoothed version of the quantum conditional min - entropy , defined for any @xmath112 as : @xmath113 where the maximization is taken over all ( subnormalized ) states @xmath114 within @xmath21 trace distance of @xmath115 .",
    "a similar definition could be made for arbitrary theories using the distance defined in  @xcite , but we will not require it here .",
    "the conditional min - entropy has a number of appealing properties , which for any nc - hv model essentially follow from its operational interpretation , and also hold in the quantum setting  @xcite .",
    "first of all consider the min - entropy of classical @xmath116 conditioned on side information @xmath11 .",
    "clearly , since guessing @xmath26 _ and _ @xmath117 can only be more difficult then guessing @xmath26 alone , we have @xmath118",
    ". translated , this gives monotonicity of the min - entropy @xmath119 similarly , to guess @xmath26 _ and _ @xmath117 from @xmath11 one strategy would be to guess @xmath117 ( in the worst case , choosing @xmath120 with @xmath121 taken from the uniform distribution ) and then try to guess @xmath26 knowing @xmath117 . in terms of guessing probabilities",
    ", this means that @xmath122 .",
    "translated , we obtain the chain rule @xmath123 a final property that will be important to us is that , as a direct consequence of   we may also write the min - entropy as @xmath124 where the minimization is taken over all measurements @xmath125 , and @xmath126 is the min - entropy conditioned on the classical information obtained by measuring @xmath11 with @xmath125 .",
    "before turning to the proof of the generalized splitting inequality , let us briefly review what is meant by a non - contextual model . in any physical theory",
    ", we can imagine that a system is prepared according to some _ preparation _ @xmath127 , on which we later make _ measurements _ @xmath14 .",
    "each such measurement can be viewed as a collection of elementary effects @xmath128 .",
    "the exact form of the effects depends on the model one considers .",
    "for example , in quantum theory the effects are simply given by povm elements .",
    "a particularly useful effect is given by the so - called _ unit effect _ @xmath129 , corresponding to the identity in the quantum or classical setting . hence to any effect one can associate a two - outcome measurement @xmath130 .    when discussing non - contextuality , this measurement is typically interpreted as a question one might pose to the underlying physical system and has two answers , `` yes '' for @xmath128 and `` no '' for @xmath131 .",
    "we hence also refer to @xmath128 as a question .",
    "of course , one might consider measurements that ask many questions simultaneously , that is , they consist of many individual effects .",
    "two effects are called _ compatible _ if the corresponding questions can be answered simultaneously without causing disturbance to the underlying physical system , in the sense that we would obtain the same answers again were we to ask the same questions repeatedly .    a set of mutually compatible effects / questions is thereby called a _ context_. for example , if @xmath132 is compatible with @xmath133 the set @xmath134 is called a _ context_. similarly , if @xmath132 is compatible with @xmath135 , then the set @xmath136 is also a context .",
    "note , however , that in such a scenario it can still be that @xmath133 and @xmath135 are _ not _ compatible .",
    "that is , any effect can be part of multiple _ distinct _ contexts .    for each effect in a particular context",
    ", one can pose the question @xmath128 by making the measurement @xmath137 defined above .",
    "informally , a model is called _ non - contextual _ if the answer to question @xmath132 will always be the same in both contexts , whether @xmath138 _ or _",
    "@xmath139 are performed simultaneously ( which is possible by definition of being compatible ) . in our example",
    "this means that if were we to make measurement @xmath140 in context @xmath141 , or context @xmath142 , we would always obtain the same distribution on outcomes .",
    "recall that the phenomenon of min - entropy splitting guarantees that , if a string @xmath66 has high min - entropy then there is a way to split it by introducing a binary random variable @xmath25 such that the string @xmath143 has about half as much min - entropy as @xmath66 .",
    "classically , min - entropy splitting follows from the following statement .",
    "[ lem : classicalsplitting ] let @xmath112 and @xmath27 two random variables such that @xmath144 , where @xmath11 is classical .",
    "then , there exists a binary random variable @xmath25 such that @xmath145 .    using the chain rule   and the monotonicity   of the min - entropy one immediately obtains the statement of min - entropy splitting @xmath146      typically , in a non - contextual hidden variable model it is assumed that a preparation @xmath127 is simply a distribution over hidden variables @xmath147 , and",
    "a measurement then corresponds to `` reading out '' such hidden variables .",
    "each outcome event @xmath148 is associated with a corresponding effect @xmath149 , where intuitively @xmath149 `` reads out '' the hidden variables by mapping a certain subset of possible hidden variables to the outcome @xmath148 .",
    "in contrast , some works consider more generalized scenarios known as _",
    "ontological models _",
    "the main difference here is that these hidden variable models can locally model even contextual theories , but specify explicit conditions to make these generalized theories non - contextual again .    in this section",
    "we show that the splitting inequality holds in any standard _",
    "deterministic _ nc - hv , which is the definition taken in most previous work , as in e.g.  @xcite .",
    "we will , however , phrase our result in the general language of non - contextual models as introduced in  @xcite , restricting our attention to those models which are deterministic .",
    "very intuitively , a non - contextual _ ontological model _ for an operational theory associates intrinsic attributes to every physical system , which are supposed to exist independently of the particular context in which the system might be observed .",
    "these attributes are described by a set of hidden variables  @xcite @xmath7 .",
    "hence for us a hidden variable model consists of the following :    1 .",
    "a set of hidden variables @xmath147 .",
    "2 .   for every preparation @xmath127 in the physical theory , a probability distribution @xmath150 over @xmath151 .",
    "3 .   for every @xmath152-outcome measurement @xmath14 , and hidden variable @xmath7 , a probability distribution @xmath153 over @xmath154 : = \\{1,\\ldots,\\ell\\}$ ] .",
    "the model is indeed a model for the physical theory if it accurately predicts the outcome distribution of any measurement on any preparation , i.e. performing measurement @xmath14 on preparation @xmath127 produces outcome @xmath155 with probability @xmath156 where for notational simplicity we assume that @xmath147 is discrete .",
    "_ effects .",
    "_ we adopt the common notion that measurements are a collection of elementary effects . here",
    ", an effect is a linear functional @xmath157 $ ] , mapping hidden variables to outcomes .",
    "as is common in the study of non - contextuality  @xcite , we will consider only measurements which are a collection of deterministic effects @xmath158 .",
    "that is , we effectively work with a _",
    "deterministic _ model .",
    "much more general scenarios are certainly possible  @xcite but we will not consider them here . note that a deterministic model does not mean that there is no more randomness : preparations are given as probability distributions over hidden variables and hence we generally do observe non - deterministic outcomes when measuring a preparation . of particular importance is the unit effect @xmath129 ( i.e , the identity ) , which obeys @xmath159 for all @xmath7 .",
    "a measurement is thus a collection @xmath160 , where we usually index the effects by the outcome that they give in @xmath125 .",
    "we write the probability of obtaining the outcome @xmath155 using measurement @xmath125 containing the effect @xmath149 as @xmath161 note that with every effect , we can again associate a two - outcome measurement @xmath130 where without loss of generality we label @xmath128 using the outcome 1 and @xmath131 using the outcome 0. when concerned with such a measurement @xmath137 we thus also use @xmath162 and @xmath163 to denote the probabilities of obtaining outcomes 1 and 0 respectively .    _ extensions . _",
    "often we wish to relate one physical system to another .",
    "for example , we may wish to perform an additional independent experiment such as flipping a coin . given a system with a set of hidden variables @xmath147",
    ", we allow its extension to a second system in the following way : if @xmath164 is another set of hidden variables used to describe another physical system , then the combined system will have hidden variables @xmath165 . for every preparation @xmath127 on the original system , we say that @xmath166 is an extension of @xmath127 in the combined system if for every @xmath167 @xmath168 a measurement @xmath169 is similarly said to extend @xmath14 as long as @xmath170    _ preparations .",
    "_ to study our problem , we will assume that there is an implicit prior distribution on preparations @xmath127 describing prior knowledge about the state of the system under consideration .",
    "more specifically , we will be concerned with encodings of a string @xmath5 into preparations @xmath171 , where the probability @xmath10 of choosing the string @xmath5 translates into a prior probability on the preparation as @xmath172      we are now ready to generalize lemma  [ lem : classicalsplitting ] to any deterministic nc - hv model .",
    "the analogue of   is then an easy corollary .",
    "note that in this statement , the conditional min - entropy is understood as being defined through the guessing probability   as in equation  .",
    "this assumes given a fixed distribution @xmath173 on the strings @xmath174 , through which a prior distribution on the preparations @xmath175 follows as explained at the end of section  [ sec : nchv ] .",
    "[ thm : mainsplitting ] let a nc - hv model @xmath176 be given , with corresponding set of hidden variables @xmath147 .",
    "let @xmath28 be two classical random variables each taking values in a finite set @xmath102 , and @xmath177 a corresponding fixed set of preparations on a register @xmath11 such that @xmath178 then there exists an extended model @xmath179 over the set of hidden variables @xmath180 , and a set of preparations @xmath181 , for @xmath182 , extending the @xmath175 and such that @xmath183    recall that we assume a prior distribution on the preparations given by @xmath184 .",
    "this lets us define the guessing probability , which by assumption is such that @xmath185 to rewrite the r.h.s . in terms of hidden variables , first of all note that given the prior distribution over preparations we can write the probability of a particular hidden variable @xmath7 as @xmath186 fix a measurement @xmath187 , where we indexed the effects by their outcome in the measurement . by definition ,",
    "the probability of observing the outcome @xmath155 when @xmath14 is performed on the preparation @xmath175 is @xmath188 the overall probability of observing the outcome @xmath155 when @xmath14 is performed on the preparation @xmath127 corresponding to the mixture of the preparations @xmath175 with associated probabilities @xmath189 is then @xmath190 note that by definition the hidden variables @xmath191 give deterministic outcomes under the measurement of any effect , and hence @xmath192 , where @xmath193 is @xmath39 if the measurement @xmath194 deterministically produces the outcome @xmath149 when performed on a system in state @xmath191 , and @xmath37 otherwise . using bayes rule twice we obtain @xmath195 using   and   we obtain that for any measurement @xmath196 , the guessing probability of @xmath66 is determined by the maximum posterior probability of any string @xmath174 , conditioned on obtaining the outcome @xmath155 when measuring @xmath127 with @xmath14 , so that   implies @xmath197\\ .\\label{eq : maxbound}\\end{aligned}\\ ] ] where in order to invert the summations over @xmath155 and @xmath191 with the maximization we used the fact that for any @xmath155 , there exists exactly one @xmath191 such that @xmath198 and vice - versa , so that the summation over @xmath191 ( resp . over @xmath155 ) which is after the @xmath199 in the expressions above contains exactly one term .",
    "this is a consequence of the fact that the @xmath149 form a measurement , so that @xmath200 , together with the variables @xmath191 being deterministic , so that @xmath201 can only be either @xmath37 or @xmath39 .",
    "we now need to define the additional single - bit random variable @xmath25 , which is intuitively supposed to designate which of the two halves , @xmath0 or @xmath3 , the preparation @xmath175 contains the least amount of information about , so that we can indeed lower - bound the min - entropy @xmath202 . for this",
    "we allow @xmath25 to be correlated with the preparation @xmath175 .    in order to accommodate @xmath25 , we extend the set of hidden variables @xmath164 as @xmath203 .",
    "define @xmath204 , where the sum ranges over all @xmath191 such that @xmath205 , and @xmath206 .",
    "note that @xmath207 can be computed by the same summation , but now ranging over all @xmath191 such that @xmath208 .",
    "define two preparations as follows :    * @xmath209 is defined through the distribution @xmath210 0&\\text{otherwise}\\end{array}\\nonumber\\end{aligned}\\ ] ] and @xmath211 for every @xmath191 .",
    "* @xmath212 is defined analogously by @xmath213 0&\\text{otherwise}\\end{array}\\nonumber   \\end{aligned}\\ ] ] and @xmath214 for every @xmath191 .",
    "finally , we define the preparation @xmath215 as the mixture of @xmath209 with probability @xmath216 , and of @xmath212 with probability @xmath207 .",
    "note that the preparation @xmath217 is indeed an extension of @xmath175 in the new theory , as @xmath218 . finally , we update the prior on preparations by setting @xmath219 and @xmath220 , so that @xmath221 one can check that with these definitions , whenever @xmath205 we have , using bayes rule twice , @xmath222 and @xmath37 otherwise , where for the second equality we used @xmath223 for all those @xmath191 such that @xmath224 is not zero .",
    "from this point on , our proof follows very closely the classical proof of lemma  [ lem : classicalsplitting ] . by definition , for every @xmath3 and every @xmath191",
    ", we have that @xmath225 it does not seem possible to similarly bound @xmath226 , but it is not necessary either , as we do not have access to this quantity directly .",
    "rather , let @xmath227 be any @xmath228-outcome measurement ; as in   we need to bound @xmath229\\nonumber \\label{eq : maxbound2}\\end{aligned}\\ ] ] note that by definition , @xmath230 is either @xmath37 or at least @xmath231 , so that for all @xmath0 , @xmath3 and @xmath191 , we have the trivial bound @xmath232 where for the last equality we used  .",
    "summing this equation over all @xmath3 and combining it with   lets us bound   by @xmath233 .",
    "this bound together with   proves the theorem .",
    "the fact that min - entropy splitting holds in any nc - hv model now follows as a corollary from theorem  [ thm : mainsplitting ] and the fact that the chain rule   and monotonicity   of the min - entropy also hold for nc - hv models .",
    "[ cor : mainsplitting ] let a nc - hv model @xmath176 be given , with corresponding set of hidden variables @xmath147 .",
    "let @xmath28 be two classical random variables each taking values in a finite set @xmath102 , and @xmath177 a corresponding fixed set of preparations on a register @xmath11 .",
    "then there exists an extended model @xmath179 over the set of hidden variables @xmath180 , and a set of preparations @xmath234 , for @xmath182 , extending the @xmath175 such that @xmath235    to see that this equality is robust is now again an immediate consequence of the chain rule   and monotonicity property  , which tell us that when we obtain some additional classical information @xmath236 with @xmath237 we have @xmath238 that is , a secretly helpful nc - hv leaking a small number @xmath239 bits of additional information does not decrease the min - entropy by more than @xmath240 bits .",
    "we are now ready to show that the splitting inequality   is violated by quantum mechanics in a very strong sense . to this end",
    ", we first construct a particular quantum encoding of two dits into one qudit .",
    "consider the encoding @xmath241 given by @xmath242 where @xmath243 and @xmath244 are the generalized pauli matrices given by their actions on an orthonormal basis @xmath245 @xmath246 with @xmath247 , and @xmath248 with @xmath52 denoting the quantum fourier transform operator over @xmath53 .",
    "note that @xmath249 .",
    "we also refer to the eigenbasis of @xmath244 as the _ computational basis _ and the eigenbasis of @xmath243 as the _",
    "fourier basis_. below , it will be convenient to note that @xmath244 acts as the cyclic shift operator in the eigenbasis of @xmath243 , and vice versa . throughout",
    ", we will assume that @xmath54 is prime .",
    "imagine a source that chooses @xmath250 uniformly at random and emits @xmath251 , corresponding to the ccq - state @xmath252 throughout , we will consider the probability that we guess @xmath66 or the individual entries @xmath33 and @xmath32 given the register @xmath11 .",
    "we begin by showing that for our specific encoding the probability of guessing _ both _",
    "entries @xmath27 is small .",
    "let @xmath74 and @xmath75 be the optimal values of the primal and dual respectively .",
    "note that by weak duality we have @xmath76 . since @xmath97 is a pure state",
    ", @xmath78 is a feasible dual solution with value @xmath255 .",
    "we now show that @xmath256 is in fact optimal , by constructing a solution to the primal that achieves the same value .",
    "let @xmath80 .",
    "clearly , @xmath257 for all @xmath0 and @xmath3 , and by schur s lemma we have @xmath258 hence , our choice of operators is a feasible primal solution with primal value @xmath259 which concludes our claim .",
    "first of all , note that for all @xmath0 and @xmath3 @xmath262 where we have used the fact that @xmath263 .",
    "similarly , we have @xmath264 with @xmath247 , where the first equality follows from the fact that @xmath265 is an eigenvector of @xmath243 , and the last equality by noting that @xmath266 .",
    "it thus remains to compute @xmath267 from which our claim follows .",
    "we now show that without loss of generality , the optimal measurement has an extremely simple form .",
    "first of all note that @xmath276 = 0 $ ] for all @xmath277 and @xmath0 since @xmath278 hence , if @xmath279 is an optimal solution then so is the measurement given by @xmath280 .",
    "thus without loss of generality we may assume that the optimal measurement operators are diagonal in the computational basis .",
    "now consider the largest term corresponding to @xmath281 and @xmath282 such that @xmath283 for all @xmath0 .",
    "since all measurement operators are hermitian , we can expand @xmath284 in its eigenbasis .",
    "we may now in turn consider the element @xmath285 which has the largest overlap with @xmath282 .",
    "that is , choose @xmath286 that is , @xmath287 for all @xmath288 . clearly , we have that @xmath289 it remains to prove that this inequality is tight . without loss of generality",
    "assume that @xmath290 , any other case will follow by a simple relabeling .",
    "note that by lemma  [ lem : indprob ] we have @xmath291 for all @xmath0 and thus we choose @xmath292 in  .",
    "note that by construction we have @xmath293 , and hence @xmath294 .",
    "thus for the measurement in the computational basis given by @xmath295 , the inequality   is tight which together with   gives our claim .",
    "the case of retrieving @xmath32 is exactly analogous , with the roles of @xmath243 and @xmath244 interchanged .",
    "note that we may express @xmath300 we now first note that by the reduced trace condition and the fact that @xmath33 and @xmath32 are classical we must have that @xmath96 .",
    "since @xmath97 is a pure state , this implies that @xmath98 . since @xmath25 is classical which we can express @xmath301 without loss of generality in the computational basis as @xmath302 for some arbitrary distribution @xmath303 .",
    "let us now consider how well we can compute @xmath304 ; the case of @xmath305 is analogous .",
    "first of all , note that the state obtained from @xmath60 after we measured @xmath25 in the computational basis and obtained outcome @xmath306 , followed by tracing out @xmath25 is given by @xmath307 where @xmath308 and @xmath309 .",
    "the states we wish to distinguish are thus given by @xmath310 note that from lemma  [ lem : indprob ] we have that for all @xmath0 @xmath311 hence , for the measurement in the computational basis we succeed with probability at least @xmath312 , independent of the distributions @xmath303 .",
    "again , by exchanging the roles of @xmath243 and @xmath244 the same probability can be achieved using a measurement in the fourier basis , which proves the theorem .    in terms of min - entropy",
    ", we thus have that @xmath313 but for all @xmath25 we have @xmath314 ! this effect is still observed for the @xmath21-smooth min - entropy for small @xmath21 , since @xmath315 and @xmath316"
  ],
  "abstract_text": [
    "<S> a central question in our understanding of the physical world is how our knowledge of the whole relates to our knowledge of the individual parts . </S>",
    "<S> one aspect of this question is the following : to what extent does ignorance about a whole preclude knowledge of at least one of its parts ? relying purely on classical intuition , one would certainly be inclined to conjecture that a strong ignorance of the whole can not come without significant ignorance of at least one of its parts . indeed </S>",
    "<S> , we show that this reasoning holds in any non - contextual hidden variable model ( nc - hv ) . </S>",
    "<S> curiously , however , such a conjecture is _ false _ in quantum theory : we provide an explicit example where a large ignorance about the whole can coexist with an almost perfect knowledge of each of its parts . </S>",
    "<S> more specifically , we provide a simple information - theoretic inequality satisfied in any nc - hv , but which can be _ arbitrarily _ violated by quantum mechanics . </S>",
    "<S> our inequality has interesting implications for quantum cryptography .    in this note </S>",
    "<S> we examine the following seemingly innocent question : does one s ignorance about the whole necessarily imply ignorance about at least one of its parts ? </S>",
    "<S> given just a moments thought , the initial reaction is generally to give a positive answer . </S>",
    "<S> surely , if one can not know the whole , then one should be able to point to an unknown part . </S>",
    "<S> classically , and more generally for any deterministic non - contextual hidden variable model , our intuition turns out to be correct : ignorance about the whole does indeed imply the existence of a specific part which is unknown , so that one can point to the source of one s ignorance . </S>",
    "<S> however , we will show that in a quantum world this intuition is flawed . </S>"
  ]
}