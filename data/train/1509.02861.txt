{
  "article_text": [
    "model predictive control ( mpc ) is an optimal control technology , which is capable to cope with constrained systems and widely used in industry and academia ; see , e.g. , @xcite , @xcite , and @xcite .",
    "nonlinear mpc ( nmpc ) deals with nonlinear models and/or constraints .",
    "main numerical methods applied in nmpc are surveyed by @xcite .",
    "the continuation / gmres by @xcite is one of the real - time numerical methods for nmpc .",
    "ohtsuka s method combines several techniques including replacement of inequality constraints by equality constraints , numerical elimination of the state , by the forward recursion , and the costate , by the backward recursion , and the krylov subspace iterations for solving nonlinear equations via parameter continuation .",
    "@xcite have introduced a preconditioned c / gmres method , however , their preconditioner is inefficient .",
    "our previous work in @xcite extends ohtsuka s approach in various ways .",
    "the continuation nmpc ( cnpmc ) method is formulated for a more general optimal control model with additional parameters and terminal constraints , which allows us solving minimal time problems .",
    "we also use preconditioners for cnmpc , based on an explicit construction of the jacobian matrices at some time steps , improving convergence of the krylov iterations .",
    "we propose substituting the minres iterative solver for gmres in cnmpc , reducing the memory requirements and the arithmetic costs per iteration .",
    "the present note shows how to reduce the cost of the preconditioning setup , by approximating the jacobian matrix in the newton iterations .",
    "the idea of such an approximation relies on the observation that most entries of the jacobian weakly depend on small perturbations of the state and costate .",
    "most columns of the jacobian can be built from a single instance of the state and costate variables computed , e.g. , during generation of the right - hand side of the system solved by the newton method .",
    "only a small number of columns of the jacobian , specifically , responsible for treating the terminal constraints and the parameter , is sensitive to changes of the state and costate .",
    "we recalculate the state and costate corresponding just to these sensitive columns .",
    "moreover , for the purpose of the preconditioner setup , we can , in addition , compute the state and costate on a coarser grid on the horizon with subsequent linear interpolation of them at the intermediate points .",
    "we can also use other general techniques for fast preconditioner setup , e.g. ,  computation of the state and costate variables , as well as the preconditioner and its factorization , in a reduced computer precision .",
    "our numerical results demonstrate that the preconditioned gmres and minres , where the preconditioner is constructed using the approximate state and costate variables , converge faster , compared to their analogs without preconditioning .",
    "the paper discusses basic principles of preconditioning , and detailed algorithms of computation of the preconditioning schemes are to be reported in our extended paper .",
    "the rest of the note is as follows . in section  2",
    ", we derive the nonlinear equations , which are solved by the continuation newton - krylov method .",
    "section 3 describes how gmres or minres iterations are applied to numerical solution of these nonlinear equations .",
    "section 4 presents our main contribution by giving details of the preconditioner construction , which is based on reusing the previously computed and approximated state and costate variables .",
    "section 5 defines a representative test example ; and section 6 gives numerical results illustrating the quality of the method with the suggested preconditioner .",
    "the mpc approach is based on the prediction by means of a finite horizon optimal control problem along a fictitious time @xmath2 $ ] .",
    "our model finite horizon problem consists in choosing the control @xmath3 and parameter vector @xmath4 , which minimize the performance index @xmath5 as follows : @xmath6 where @xmath7 subject to the equation for the state dynamics @xmath8 and the equality constraints for the state @xmath9 and control @xmath10 @xmath11 @xmath12 the initial value @xmath13 for ( [ e1 ] ) is the state vector @xmath14 of the dynamic system .",
    "the control vector @xmath15 , solving the problem over the prediction horizon , is used afterwards as an input to control the system at time @xmath16 .",
    "the components of the vector @xmath17 are parameters of the system and do not depend on  @xmath18 . in our minimum - time example in section 5 ,",
    "the scalar parameter @xmath17 denotes the time to destination , and the horizon length is @xmath19 .",
    "the prediction problem stated above is discretized on a uniform , for simplicity of presentation , time grid over the horizon @xmath20 $ ] partitioned into @xmath21 time steps of size @xmath22 , and the time - continuous vector functions @xmath23 and @xmath3 are replaced by their sampled values @xmath24 and @xmath25 at the grid points @xmath26 , @xmath27 .",
    "the integral of the performance cost @xmath5 over the horizon is approximated by the rectangular quadrature rule .",
    "equation ( [ e1 ] ) is integrated by the the explicit euler scheme , which is the simplest possible method .",
    "we note that more sofisticated one - step adaptive schemes can be used as well .",
    "the discretized optimal control problem is formulated as follows : @xmath28,\\ ] ] subject to @xmath29 @xmath30 @xmath31    the necessary optimality conditions for the discretized finite horizon problem are the stationarity conditions for the discrete lagrangian function @xmath32+\\sum_{i=0}^{n-1}\\lambda_{i+1}^t[x_i - x_{i+1}+f(\\tau_i , x_i , u_i , p)\\delta\\tau]\\\\ & & + \\sum_{i=0}^{n-1}\\mu_i^tc(\\tau_i , x_i , u_i , p)\\delta\\tau+\\nu^t\\psi(x_n , p),\\end{aligned}\\ ] ] where @xmath33^t$ ] , @xmath27 , and @xmath34^t$ ] , @xmath35 . here",
    ", @xmath36 is the costate vector , @xmath37 is the lagrange multiplier vector associated with the constraint  ( [ e5 ] ) .",
    "the terminal constraint ( [ e6 ] ) is relaxed by the aid of the lagrange multiplier @xmath38 .",
    "the necessary optimality conditions are the system of nonlinear equations @xmath39 , @xmath40 , @xmath27 , @xmath41 , @xmath42 , @xmath35 , @xmath43 , @xmath44 .    for further convenience",
    ", we introduce the hamiltonian function @xmath45 .",
    "the optimality conditions are reformulated in terms of a mapping @xmath46 $ ] , where the vector @xmath47 combines the control input @xmath10 , the lagrange multiplier @xmath37 , the lagrange multiplier @xmath38 , and the parameter @xmath4 , all in one vector : @xmath48^t.\\ ] ] the vector argument @xmath9 in @xmath46 $ ] denotes the state vector at time @xmath16 , which serves as the initial vector @xmath49 in the following procedure .    1 .",
    "starting from the current measured or estimated state @xmath49 , compute all @xmath24 , @xmath50 , by the forward recursion @xmath51 then starting from @xmath52 compute all costates @xmath53 , @xmath54 , by the backward recursion @xmath55 2 .",
    "using just obtained @xmath24 and @xmath53 , calculate the vector @xmath56=\\left[\\begin{array}{c}\\begin{array}{c } \\frac{\\partial h^t}{\\partial u}(\\tau_0,x_0,\\lambda_{1},u_0,\\mu_0,p)\\delta\\tau\\\\ \\vdots\\\\\\frac{\\partial h^t}{\\partial u}(\\tau_i , x_i,\\lambda_{i+1},u_i,\\mu_i , p)\\delta\\tau\\\\ \\vdots\\\\\\frac{\\partial h^t}{\\partial u}(\\tau_{n-1},x_{n-1},\\lambda_{n},u_{n-1 } , \\mu_{n-1},p)\\delta\\tau\\end{array}\\\\\\;\\\\ \\begin{array}{c}c(\\tau_0,x_0,u_0,p)\\delta\\tau\\\\ \\vdots\\\\c(\\tau_i , x_i , u_i , p)\\delta\\tau\\\\\\vdots\\\\ c(\\tau_{n-1},x_{n-1},u_{n-1},p)\\delta\\tau\\end{array}\\\\\\;\\\\ \\psi(x_n , p)\\\\[2ex ] \\begin{array}{c}\\frac{\\partial\\phi^t}{\\partial p}(x_n , p)+ \\frac{\\partial\\psi^t}{\\partial p}(x_n , p)\\nu\\\\ + \\sum_{i=0}^{n-1}\\frac{\\partial h^t}{\\partial p}(\\tau_i , x_i , \\lambda_{i+1},u_i,\\mu_i , p)\\delta\\tau\\end{array } \\end{array}\\right]\\!\\!.\\end{aligned}\\ ] ]    the equation with respect to the unknown vector @xmath57 @xmath58=0\\ ] ] gives the required necessary optimality conditions .",
    "the controlled system is sampled on a uniform time grid @xmath59 , @xmath60 .",
    "solution of equation ( [ e7 ] ) must be found at each time step @xmath61 in real time , which is a challenging part of implementation of nmpc .",
    "let us denote @xmath62 , @xmath63 , and rewrite the equation @xmath64=0 $ ] equivalently in the form @xmath65-f[u_{j-1},x_j , t_j]=b_j,\\ ] ] where @xmath66.\\ ] ]    using a small @xmath67 , which may be different from @xmath68 and @xmath22 , we introduce the operator @xmath69-f[u_{j-1},x_j , t_j])/h.\\end{aligned}\\ ] ] we note that the equation @xmath64=0 $ ] is equivalent to the equation @xmath70 , where @xmath71 .",
    "let us denote the @xmath72-th column of the @xmath73 identity matrix by @xmath74 , where @xmath75 is the dimension of the vector @xmath47 , and define an @xmath73 matrix @xmath76 with the columns @xmath77 , @xmath78 .",
    "the matrix @xmath76 is an @xmath79 approximation of the jacobian matrix @xmath80 $ ] , which is symmetric .",
    "suppose that an approximate solution @xmath81 to the initial equation @xmath82=0 $ ] is available .",
    "the first block entry of @xmath81 is taken as the control @xmath83 at the state @xmath49 .",
    "the next state @xmath84 is either sensor estimated or computed by the formula @xmath85 ; cf .",
    "( [ e1 ] ) .    at the time @xmath61 , @xmath86",
    ", we have the state @xmath87 and the vector @xmath88 from the previous time @xmath89 .",
    "our goal is to solve the following equation with respect to @xmath90 : @xmath91 then we can set @xmath92 and choose the first block component of @xmath93 as the control @xmath94 .",
    "the next system state @xmath95 is either sensor estimated or computed by the formula @xmath96 .",
    "a direct way to solve ( [ e11 ] ) is generating the matrix @xmath76 and then solving the system of linear equations @xmath97 ; e.g. , by the gaussian elimination .",
    "a less expensive alternative is solving ( [ e11 ] ) by the gmres method , where the operator @xmath98 is used without explicit construction of the matrix @xmath76 ( cf . , @xcite ) .",
    "some results on convergence of gmres in the nonlinear case can be found in @xcite .",
    "we recall that , for a given system of linear equations @xmath0 and initial approximation @xmath49 , gmres constructs orthonormal bases of the krylov subspaces @xmath99 , @xmath100 , given by the columns of matrices @xmath101 , such that @xmath102 with the upper hessenberg matrices  @xmath103 and then searches for approximations to the solution @xmath9 in the form @xmath104 , where @xmath105 .",
    "a more efficient variant of gmres , called minres , may be applied when the matrix @xmath1 is symmetric , and the preconditioner is symmetric positive definite . using the minres iteration in ohtsuka",
    "s approach is mentioned in @xcite .",
    "the convergence of gmres can be accelerated by preconditioning . a matrix @xmath106 that is close to the matrix @xmath1 and such that computing @xmath107 for an arbitrary vector @xmath108 is relatively easy ,",
    "is referred to as a preconditioner .",
    "the preconditioning for the system of linear equations @xmath0 with the preconditioner @xmath106 formally replaces the original system @xmath0 with the equivalent preconditioned linear system @xmath109 . if the condition number @xmath110 of the matrix @xmath111 is small , convergence of iterative krylov - based solvers for the preconditioned system can be fast .",
    "however , in general , the convergence speed of , e.g. ,  the preconditioned gmres is not necessarily determined by the condition number alone .",
    "a typical implementation of the preconditioned gmres is given below .",
    "the unpreconditioned gmres is the same algorithm but with @xmath112 , where @xmath113 is the identity matrix .",
    "we denote by @xmath114 the submatrix of @xmath115 with the entries @xmath116 such that @xmath117 and @xmath118 .",
    "l + * * algorithm * * preconditioned gmres(@xmath119 ) +   + * input : * @xmath120 , @xmath121 , @xmath49 , @xmath119 , @xmath106 + * output : * solution @xmath9 of @xmath122 + @xmath123 , @xmath124 , @xmath125 , @xmath126 + * for * @xmath127 * do * + @xmath128 , @xmath124 + @xmath129^tz$ ] + @xmath130h_{1:k , k}$ ] + @xmath131 + @xmath132 + * end for * + @xmath133^t\\|_2 $ ] + @xmath134y$ ] +    in @xcite , the matrix @xmath76 is exactly computed at some time instances @xmath61 and used as a preconditioner in a number of subsequent time instances @xmath61 , @xmath135 ,  , @xmath136 . in the present note ,",
    "we propose to use a close approximation to @xmath76 , which needs much less arithmetic operations for its setup .",
    "construction of such approximations @xmath137 is the main result of this note .",
    "we recall that computation of the @xmath72-th column of @xmath76 requires computation of all states @xmath138 and costates @xmath139 for the parameters stored in the vector @xmath140 .",
    "is it possible to replace them by @xmath138 and @xmath139 computed for the parameters stored in the vector @xmath88 ?",
    "the answer is yes , for the indices @xmath141 , where @xmath142 is the sum of dimensions of @xmath143 and @xmath4 .",
    "these @xmath72 indices correspond to the terms containing the factor @xmath22 in the lagrangian @xmath144 .    the first @xmath145 columns ( and rows , since the preconditioner @xmath137 is symmetric ) are calculated by the same formulas as those in @xmath76 , but with the values @xmath138 and @xmath139 computed only once for the parameters stored in the vector @xmath88 , i.e. , when computing the vector @xmath146 .",
    "thus , the setup of @xmath137 computes the states @xmath138 and costates @xmath139 only @xmath142 times instead of @xmath75 times as for the matrix @xmath76 .",
    "it is this reduction of computing time that makes the preconditioner @xmath137 more efficient , especially in cases where dimension of the state space is very large .",
    "the preconditioner @xmath137 is obtained from @xmath76 by neglecting the derivatives @xmath147 , @xmath148 , @xmath149 and @xmath150 . therefore , the difference @xmath151 is of order @xmath152 since @xmath153 , @xmath154 , @xmath155 and @xmath156 .",
    "the preconditioner application @xmath107 requires the lu factorization @xmath157 , which is computed by the gaussian elimination .",
    "then the vector @xmath158 is obtained by performing back - substitutions for the triangular factors @xmath159 and @xmath47 .",
    "further acceleration of the preconditioner setup is possible by faster computation of the lu factorization .",
    "for example , when computation with lower number of bits is cheaper than computation with the standard precision , the preconditioner @xmath137 and its lu factorization may be computed in lower precision .",
    "another way of reduction of the arithmetical work in the preconditioner setup is the computation of the states @xmath9 and costates @xmath36 with the double step @xmath160 thus halving the arithmetical cost and memory storage .",
    "the intermediate values of @xmath9 and @xmath36 are then obtained from the computed values by simple linear interpolation .",
    "we consider a test nonlinear problem , which describes the minimum - time motion from a state @xmath161 to a state @xmath162 with an inequality constrained control :    * state vector @xmath163 $ ] and input control @xmath164 $ ] .",
    "* parameter variable @xmath165 , where @xmath166 denotes the arrival time at the terminal state @xmath162 . *",
    "nonlinear dynamics is governed by the system of ordinary differential equations @xmath167.\\ ] ] * constraint : @xmath168 , where @xmath169 and @xmath170 is a slack variable , i.e. , the control @xmath10 always stays within the sinusoidal band @xmath171 ) . * terminal constraints : @xmath172=0 $ ] ( the state should pass through the point @xmath162 at @xmath173 ) * objective function on the horizon interval @xmath174 $ ] : @xmath175 where @xmath176 ( the state should arrive at @xmath162 in the shortest time ; the function @xmath159 serves to stabilize the slack variable @xmath170 ) * constants : @xmath177 , @xmath178 , @xmath179 , @xmath180 , @xmath181 , @xmath182 , @xmath183 , @xmath184 .",
    "the horizon interval @xmath174 $ ] is parametrized by the affine mapping @xmath185 with @xmath186 $ ] .",
    "the components of the corresponding discretized problem on the horizon are given below :    * @xmath187 , @xmath188 , @xmath189 ; * the participating variables are the state @xmath190 $ ] , the costate @xmath191 $ ] , the control @xmath192 $ ] , the lagrange multipliers @xmath193 and @xmath194 $ ] , the parameter @xmath4 ; * the state is governed by the model equation @xmath195,\\\\ y_{i+1}=y_i+\\delta\\tau\\left[p\\left(ax_{i}+b\\right)\\sin u_{i}\\right],\\end{array}\\right.\\ ] ] where @xmath35 ; * the costate is determined by the backward recursion ( @xmath196 , @xmath197 ) @xmath198,\\\\ \\lambda_{2,i } = \\lambda_{2,i+1},\\end{array}\\right.\\ ] ] where @xmath199 ; * the equation @xmath200 , where @xmath201,\\end{aligned}\\ ] ] has the following rows from the top to bottom : @xmath202 = 0 \\\\ \\delta\\tau\\left[2\\mu_iu_{di}-w_{d}p\\right ] = 0 \\end{array}\\right.\\ ] ] @xmath203=0\\right.\\hspace*{7em}\\ ] ] @xmath204 @xmath205 + 1 = 0.\\end{array}\\right.\\ ] ]    let us compare the computation costs of the matrices @xmath76 and @xmath137 for this example .",
    "we do not take into account the computation of the right - hand side @xmath206 $ ] because it is a necessary cost .",
    "computation of the matrix @xmath76 requires @xmath207 evaluations of the vector @xmath208 $ ] , where @xmath21 is the number of grid points on the prediction horizon .",
    "setup of @xmath137 requires only 3 evaluations of @xmath208 $ ] , which is @xmath209 times faster .",
    "in our numerical experiments , the weakly nonlinear system  ( [ e11 ] ) for the test problem from section 5 is solved by the gmres and minres iterations .",
    "the number of evaluations of the vector @xmath210 at each time @xmath61 does not exceed an a priori chosen constant @xmath211 .",
    "in other words , the maximum number of gmres or minres iterations is less or equal @xmath119 .",
    "the error tolerance in gmres and minres is @xmath212 .",
    "the number of grid points on the horizon is @xmath213 , the sampling time of simulation is @xmath214 , and @xmath215 .",
    "the preconditioners are set up at the time instances @xmath216 , where @xmath217 is the period , and @xmath218 .",
    "after each setup , the same preconditioner is applied until next setup .",
    "preconditioners for minres must be symmetric positive definite and are built here as the absolute value of @xmath137 , i.e. , if @xmath219 is the singular value decomposition , then @xmath220 ; see @xcite .",
    "figure [ fig1 ] shows the computed trajectory for the test example .",
    "figure [ fig2 ] shows the optimal control by the mpc approach using the preconditioned gmres .",
    "figure  [ fig3 ] displays @xmath221 and the gmres residuals .",
    "the number of iterations of preconditioned gmres is displayed in figure [ fig4 ] . for comparison",
    ", we show the number of iterations of the preconditioned minres in figure [ fig5 ] .",
    "figure [ fig6 ] displays @xmath221 and the 2-norm of the residual after iterations of gmres without preconditioning .",
    "the corresponding number of iterations of gmres without preconditioning is shown in figure [ fig7 ] .",
    "the number of iterations of minres without preconditioning is shown in figure [ fig8 ] .",
    "effect of preconditioning is seen when comparing figures  4 and 7 for gmres and figures 5 and 8 for minres .",
    "preconditioning of gmres reduces the number of iterations by factor 1.2 .",
    "preconditioning of minres reduces the number of iterations by factor 1.4 .",
    "the number of iterations does not necessarily account for the additional complexity that preconditioning brings to the on - line algorithm .",
    "however , the computation time is machine and implementation dependent , while our tests are done in matlab on a generic computer .",
    "specific implementations on dedicated computer chips for on - line controllers is a topic of future work .",
    "we have found a new efficient preconditioner @xmath137 , which approximates the jacobian matrix @xmath76 of the mapping @xmath222 defining equation ( [ e7 ] ) .",
    "computation of @xmath137 is @xmath223 times faster than that of @xmath76 , where @xmath21 is the number of grid points on the prediction horizon .",
    "the preconditioner @xmath137 can be very efficient for the nmpc problems , where dimension of the state space is large , for example , in the control of dynamic systems described by partial differential equations .",
    "other useful techniques for accelerating the preconditioner setup include computation of the matrices @xmath137 and their lu factorizations in lower precision , computation of the state and costate on a coarse grid over the horizon and linear interpolation of the computed values on the fine grid .",
    "m.  diehl , h.  j.  ferreau , and n.  haverbeke .",
    "efficient numerical methods for nonlinear mpc and moving horizon estimation .",
    "l.  magni et al .",
    "( eds . ) : _ nonlinear model predictive control _ , lncis 384 , pp .  391417 , springer , heidelberg , 2009 .",
    "t.  tanida and t.  ohtsuka .",
    "preconditioned c / gmres algorithm for nonlinear receding horizon control of hovercrafts connected by a string .",
    "_ ieee int .",
    "control applic .",
    ", taipei , taiwan , september 2 - 4 , 2004 _ , pp .",
    "16091614 , 2004 ."
  ],
  "abstract_text": [
    "<S> model predictive control ( mpc ) anticipates future events to take appropriate control actions . </S>",
    "<S> nonlinear mpc ( nmpc ) deals with nonlinear models and/or constraints . </S>",
    "<S> a  continuation / gmres method for nmpc , suggested by t. ohtsuka in 2004 , uses the gmres iterative algorithm to solve a forward difference approximation @xmath0 of the original nmpc equations on every time step . </S>",
    "<S> we have previously proposed accelerating the gmres and minres convergence by preconditioning the coefficient matrix @xmath1 . </S>",
    "<S> we now suggest simplifying the construction of the preconditioner , by approximately solving a forward recursion for the state and a backward recursion for the costate , or simply reusing previously computed solutions .    model predictive control , continuation / gmres method , preconditioning . </S>"
  ]
}