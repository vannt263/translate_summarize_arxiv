{
  "article_text": [
    "meetings are a common way for people to share information and discuss problems .",
    "and an effective meeting always leads to concrete decisions . as a result",
    ", it would be useful to develop automatic methods that summarize not the entire meeting dialogue , but just the important decisions made .",
    "in particular , decision summaries would allow participants to review decisions from previous meetings as they prepare for an upcoming meeting .",
    "for those who did not participate in the earlier meetings , decision summaries might provide one type of efficient overview of the meeting contents . for managers , decision summaries could act as a concise record of the idea generation process .",
    "while there has been some previous work in summarizing meetings and conversations , very little work has focused on decision summarization :   and   investigate the use of a semantic parser and machine learning methods for phrase- and token - level decision summarization .",
    "we believe our work is the first to explore and compare token - level and dialogue act - level approaches  using both unsupervised and supervised learning methods  for summarizing decisions in meetings .",
    ".a clip of a meeting from the ami meeting corpus  @xcite .",
    "a , b , c and d refer to distinct speakers ; the numbers in parentheses indicate the associated meeting decision : decision 1 , 2 , 3 or 4",
    ". also shown is the gold - standard ( manual ) abstract ( summary ) for each decision .",
    "[ cols= \" < \" , ]     0.9    0.9    [ [ dialogue - act - based - summarization . ] ] dialogue act - based summarization .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    previous research ( e.g. ,  ,  ,  ) has shown that drda - level extractive summarization can be effective when viewed as a binary classification task . to implement this approach , we assume that the drda to be extracted for the summary is the one with the largest vocabulary overlap with the cluster s gold - standard decision abstract .",
    "this da - level summarization method has an advantage that the summary maintains good readability without a natural language generation component .",
    "[ [ token - based - summarization . ] ] token - based summarization .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    as shown in table 1 , some decision - related das contain many useless words when compared with the gold - standard abstracts . as a result",
    ", we propose a method for token - level decision summarization that focuses on identifying critical keywords from the cluster s drdas .",
    "we follow the method of  , but use a larger set of features and different learning methods .    [ [ adding - discourse - context . ] ] adding discourse context .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    for each of the supervised da- and token - based summarization methods , we also investigate the role of the discourse context .",
    "specifically , we augment the drda clusterings with additional ( not decision - related ) das from the meeting dialogue : for each decision partition , we include the da with the highest tf - idf similarity with the centroid of the partition",
    ". we will investigate the possible effects of this additional context on summary quality . in the next subsection",
    ", we describe the features used for supervised learning of da- and token - based decision summaries .",
    "different from text , dialogues have some notable features that we expect to be useful for finding informative , decision - related utterances .",
    "this section describes some of the dialogue - based features employed in our classifiers .",
    "the full lists of features are shown in table 4 and table 5 .    0.9    [ [ structural - information - adjacency - pairs . ] ] structural information : adjacency pairs .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    an _ adjacency pair _",
    "( ap ) is an important conversational analysis concept ; aps are considered the fundamental unit of conversational organization  @xcite . in the ami corpus ,",
    "an ap pair consists of a source utterance and a target utterance , produced by different speakers .",
    "the source precedes the target but they are not necessarily adjacent .",
    "we include features to indicate whether or not two das are aps indicating question+answer or positive feedback . for these features",
    ", we use the gold - standard ap annotations .",
    "we also include one feature that checks membership in a small set of words to decide whether a da contains positive feedback ( e.g. , ",
    "yeah \" ,  yes \" ) .",
    "[ [ discourse - information - review - and - closing - indicator . ] ] discourse information : review and closing indicator .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    another pragmatic cue for dialogue discussion is terms like  wrap up \" or  recap \" , indicating that speakers will review the key meeting content .",
    "we include the distance between these indicators and das as a feature .",
    "[ [ grammatical - information - dependency - relation - between - words . ] ] grammatical information : dependency relation between words .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for token - level summarization , we make use of the grammatical relationships in the das . as in   and  , we design features that encode ( a ) basic predicate - argument structures involving major phrase types ( s , vp , np , and pp ) and ( b ) additional typed dependencies from  .",
    "we use the stanford parser .",
    "experiments based on supervised learning are performed using 3-fold cross - validation .",
    "we train two different types of classifiers for identifying informative das or tokens : conditional random fields ( crfs ) ( via mallet ) and support vector machines ( svms ) ( via @xmath0 ) .",
    "we remove function words from das before using them as the input of our systems .",
    "the ami decision abstracts are the gold - standard summaries .",
    "we use the rouge  @xcite evaluation measure .",
    "rouge is a recall - based method that can identify systems producing succinct and descriptive summaries .",
    "[ [ results - and - analysis . ] ] results and analysis .",
    "+ + + + + + + + + + + + + + + + + + + + +    results for the unsupervised and supervised summarization methods are shown in tables 6 and 7 , respectively . in the tables ,",
    "true clusterings means that we apply our methods on the gold - standard drda clusterings .",
    "system clusterings use clusterings obtained from the methods introduced in section 4 ; we show results only using the best unsupervised ( using lda ) and supervised ( using svms ) drda clustering techniques .",
    "both table 6 and 7 show that some attempt to cluster drdas improves the summarization results vs.  no clustering . in table 6",
    ", there is no significant difference between the results obtained from the longest da and prototype da for any experiment setting .",
    "this is because the longest da is often selected as the prototype .",
    "an upper bound result is listed for comparison : for each decision cluster , this system selects all words from the drdas that are part of the decision abstract ( discarding duplicates ) .",
    "table 7 presents the results for supervised summarization .",
    "rows starting with da or token indicate results at the da- or token - level .",
    "the + context rows show results when discourse context is included .",
    "we see that : ( 1 ) svms have a superior or comparable summarization performance vs. crfs on every task . ( 2 ) token - level summaries perform better than da - level summaries only using true clusterings and the svm - based summarizer .",
    "( 3 ) discourse context generally improves token - level summaries but not da - level summaries .",
    "( 4 ) drda clusterings produced by ( unsupervised ) lda lead to summaries that are quite comparable in quality to those generated from drda clusterings produced by svms ( supervised ) . from table 6 , we see that f1 is 0.2214 when choosing longest das from lda - generated clusterings , which is comparable with the f1s of 0.1935 and 0.2349 , attained when employing crf and svms on the same clusterings .    the results in table 7 are achieved by comparing abstracts having function words with system - generated summaries without function words . to reduce the vocabulary difference as much as possible , we also ran experiments that remove function words from the gold - standard abstracts , but no significant difference is observed .    finally , we considered comparing our systems to the earlier similar work of  @xcite and  @xcite , but found that it would be quite difficult because they employ a different notion from drdas which is decision dialogue acts(ddas ) .",
    "in addition , they manually annotate words from their ddas as the gold - standard summary , guaranteeing that their decision summaries employ the same vocabulary as the ddas .",
    "we instead use the actual decision abstracts from the ami corpus .      here",
    "we show sample summaries produced using our methods ( table 8) .",
    "we pick one of the clusterings generated by lda consisting of four das which support two decisions and take svms as the supervised summarization method .",
    "we remove function words and special markers like  [ disfmarker ] \" from the das .",
    "the outputs indicate that either the longest da or prototype da contains part of the decisions in this ",
    "mixed \" cluster .",
    "adding discourse context refines the summaries at both the da- and token - levels .",
    "in this work , we explore methods for producing decision summaries from spoken meetings at both the da - level and the token - level .",
    "we show that clustering drdas before identifying informative content to extract can improve summarization quality .",
    "we also find that unsupervised clustering of drdas ( using lda - based topic models ) can produce summaries of comparable quality to those generated from supervised drda clustering .",
    "token - level summarization methods can be boosted by adding discourse context and outperform da - level summarization when true drda clusterings are available ; otherwise , da - level summarization methods offer better performance .",
    "satanjeev banerjee , carolyn  penstein ros , and alexander  i. rudnicky .",
    "the necessity of a meeting recording and playback system , and the benefit of topic - level annotations to meeting browsing . in _ interact _ , pages 643656 .",
    "trung  h. bui , matthew frampton , john dowding , and stanley peters .",
    "2009 . extracting decisions from multi - party dialogue",
    "using directed graphical models and semantic similarity . in _ proceedings of the sigdial 2009 conference _ , pages 235243 .",
    "anne  hendrik buist , wessel kraaij , and stephan raaijmakers",
    "automatic summarization of meeting data : a feasibility study . in _ in proc .",
    "meeting of computational linguistics in the netherlands ( clin_.    jean carletta , simone ashby , sebastien bourban , mike flynn , thomas hain , jaroslav kadlec , vasilis karaiskos , wessel kraaij , melissa kronenthal , guillaume lathoud , mike lincoln , agnes lisowska , and mccowan wilfried post  dennis reidsma . 2005 .",
    "the ami meeting corpus : a pre - announcement .",
    "in _ in proc . mlmi _ ,",
    "pages 2839 .",
    "freddy y.  y. choi . 2000 .",
    "advances in domain independent linear text segmentation . in _ proceedings of the 1st north american chapter of the association for computational linguistics conference _ , pages 2633 .",
    "raquel fernndez , matthew frampton , john dowding , anish adukuzhiyil , patrick ehlen , and stanley peters .",
    "identifying relevant phrases to summarize decisions in spoken meetings .",
    "interspeech-2008 , pages 7881 .",
    "raquel fernndez , matthew frampton , patrick ehlen , matthew purver , and stanley peters .",
    "2008b . modelling and detecting decisions in multi - party dialogue",
    ". in _ proceedings of the 9th sigdial workshop on discourse and dialogue _",
    ", pages 156163 .",
    "matthew frampton , jia huang , trung  huu bui , and stanley peters .",
    "real - time decision detection in multi - party dialogue . in _ proceedings of the 2009 conference on empirical methods in natural language processing",
    ": volume 3 - volume 3 _ , pages 11331141 .    michel galley .",
    "2006 . a skip - chain conditional random field for ranking meeting utterances by importance . in _ proceedings of the 2006 conference on empirical methods in natural language processing _ , pages 364372 .",
    "pei - yun hsueh and johanna  d. moore .",
    "2008 . automatic decision detection in meeting speech . in _ proceedings of",
    "the 4th international conference on machine learning for multimodal interaction _ ,",
    "pages 168179 .",
    "chin - yew lin and eduard hovy .",
    "automatic evaluation of summaries using n - gram co - occurrence statistics . in _ proceedings of the 2003 conference of the north american chapter of the association for computational linguistics on human language technology - volume 1 _ , pages 7178 .",
    "gabriel murray , steve renals , and jean carletta . 2005 .",
    "extractive summarization of meeting recordings .",
    "in _ in proceedings of the 9th european conference on speech communication and technology _ , pages 593596 ."
  ],
  "abstract_text": [
    "<S> this paper addresses the problem of summarizing decisions in spoken meetings : our goal is to produce a concise _ decision abstract _ for each meeting decision . </S>",
    "<S> we explore and compare token - level and dialogue act - level automatic summarization methods using both unsupervised and supervised learning frameworks . in the supervised summarization setting , and given true clusterings of decision - related utterances , we find that token - level summaries that employ discourse context can approach an upper bound for decision abstracts derived directly from dialogue acts . in the unsupervised summarization setting , we find that summaries based on unsupervised partitioning of decision - related utterances perform comparably to those based on partitions generated using supervised techniques ( 0.22 rouge - f1 using lda - based topic models vs.  0.23 using svms ) . </S>"
  ]
}