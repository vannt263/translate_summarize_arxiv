{
  "article_text": [
    "sequential decision making problems under uncertainty appear in most modern applications , such as automated experimental design , recommendation systems and optimisation .",
    "the common structure of these applications that , at each time step @xmath0 , the decision - making agent is faced with a choice . after each decision , it obtains some problem - dependent feedback  @xcite . for the so - called _ bandit _",
    "problem , the choices are between different _ arms _ , and the feedback consists of a single scalar reward obtained by the arm at time @xmath0 . for the _ prediction _ ( or full - information ) problem",
    ", it obtains the reward of the chosen arm , but also observes the rewards of all other choices at time @xmath0 . in both cases ,",
    "the problem is to maximise the total reward obtained over time .",
    "however , dealing with specific types of feedback may require specialised algorithms . in this paper",
    ", we show that the _ thompson sampling _ algorithm can be applied successfully to a range of sequential decision problems , whose feedback structure is characterised by a graph .",
    "our algorithm is an extension of thompson sampling , introduced in @xcite .",
    "although easy to implement and effective in practice , it remained unpopular until relatively recently .",
    "interest grew after empirical studies @xcite demonstrated performance exceeding state of the art .",
    "this has prompted a surge of interest in thompson sampling , with the first theoretical results  @xcite and industrial adoption  @xcite appearing only recently . however , there are still only a few theoretical results and many of these are in the simplest settings . however , it is easy to implement and effective under very many different settings with complex feedback structures , and there is thus great need to extend the theoretical results to these wider settings .",
    "@xcite argue that thompson sampling is a very effective and versatile strategy for different _",
    "information structures_. their paper focuses on specific examples : the two extreme cases of no and full information mentioned above and the case of linear bandits and combinatorial feedback .    here",
    "we consider the case where the feedback is defined through a graph  @xcite . more specifically ,",
    "the arms ( choices ) are vertices of a ( potentially changing ) graph and when an arm is chosen , we see the reward of that arm as well as its neighbours",
    ". on one hand , it is a clean model for theoretical and experimental analysis and on the other hand , it also corresponds to realistic settings in social networks , for example in advertisement settings ( c.f .",
    "@xcite ) .    we provide a problem - independent regret bound that is parametrized by the clique cover number of the graph and naturally generalizes the two extreme cases of zero and full information .",
    "we present two variants of thompson sampling , that are both very easy to implement and computationally efficient .",
    "the first is straightforward thompson sampling , and so draws an arm according to its probability of being the best , but also uses the graph feedback to update the posterior distribution .",
    "the second one can be seen as sampling cliques in the graph according to their probability of containing the best arm , and then choosing the empirically best arm in that clique .",
    "neither algorithm requires knowledge of the complete graph .",
    "almost all previous algorithms require the full structure of the feedback graph in order to operate .",
    "some require the entire graph for performing their updates only at the end of round ( e.g. @xcite ) others actually need the description of the graph at the beginning of the round to make their decision and almost none of the algorithms previously proposed in the literature is able to provide non - trivial regret guarantees without the feedback graphs being disclosed .",
    "however , @xcite ( @xcite ) argue that the assumption that the entire observation system is revealed to the learner on each round , even if only after making her prediction , is rather unnatural . in principle",
    ", the learner need not be even aware of the fact that there is a graph underlying the feedback model ; the feedback graph is merely a technical notion for us to specify a set of observations for each of the possible arms .",
    "ideally , the only signal we would like the agent to receive following each round is the set of observations that corresponds to the arm she has taken on that round ( in addition to the obtained reward ) . our algorithms work in this setup",
    "- they do not need the whole graph to be disclosed either when selecting the arm or when updating beliefs - only the local neighborhood is needed .",
    "furthermore , the underlying graph is allowed to change arbitrarily at each step .",
    "the detailed proofs of all our main results are available in the full version of this paper .",
    "the stochastic k - armed bandit problem is a well known sequential decision problem involving an agent sequentially choosing among a set of k arms @xmath1 . at each round @xmath0",
    ", the agent plays an arm @xmath2 and receives a reward @xmath3 , where @xmath4 is a random variable defined on some probability space @xmath5 and @xmath6 is a reward function .",
    "each arm @xmath7 has mean reward @xmath8 .",
    "our goal is to maximize its expected cumulative reward after @xmath9 rounds .",
    "an equivalent notion is to minimize the expected regret against an oracle which knows @xmath10 .",
    "more formally , the expected regret @xmath11 of an agent policy @xmath12 for a bandit problem @xmath10 is defined as : @xmath13 where @xmath14 is the mean of the optimal arm and @xmath15 is the policy of the agent , defining a probability distribution on the next arm @xmath16 given the history @xmath17 of previous arms and rewards .",
    "the main challenge in this model is that the agent does not know @xmath10 , and it only observes the reward of the arm it played . as a consequence ,",
    "the agent must trade - off exploitation ( taking the apparently best arm ) with exploration ( trying out other arms to assess their quality ) .",
    "the bayesian setting offers a natural way to model this uncertainty , by assuming that the underlying probability law @xmath10 is in some set @xmath18 parametrised by @xmath19 , over which we define a prior probability distribution @xmath20 . in that case",
    ", we can define the bayesian regret : @xmath21 a policy with small bayesian regret may not be uniformly good in all @xmath10 . since in the bayesian setting we frequently need to discuss posterior probabilities and expectations , we also introduce the notation @xmath22 and @xmath23 for expectations and probabilities conditioned on the current history .      in this model",
    ", we assume the existence of an undirected graph @xmath24 with vertices corresponding to arms . by taking an arm @xmath25 ,",
    "we not only receive the reward of the arm we played , but we also observe the rewards of all neighbouring arms @xmath26 .",
    "more precisely , at each time - step @xmath0 we observe @xmath27 for all @xmath28 , while our reward is still @xmath3 .    if the graph is empty , then the setting is equivalent to the bandit problem .",
    "if the graph is fully connected , then it is equivalent to the prediction ( i.e. full information ) problem .",
    "however , many practical graphs , such as those derived from social networks , have an intermediate connectivity . in such cases",
    ", the amount of information that we can obtain by picking an arm can be characterised by graph properties , such as the clique cover number :    a clique covering @xmath29 of a graph @xmath30 is a partition of all its vertices into sets @xmath31 such that the sub - graph formed by each @xmath32 is a clique i.e. all vertices in @xmath32 are connected to each other in @xmath30 .",
    "the smallest number of cliques into which the nodes of @xmath30 can be partitioned is called the clique cover number .",
    "we denote by @xmath33 the minimum clique cover and @xmath34 its size , omitting @xmath35 when clear from the context .",
    "the domination number is another useful similar notion for the amount of information that we can obtain .",
    "a dominating set in a graph @xmath36 is a subset @xmath37 such that for every vertex @xmath38 , either @xmath39 or @xmath40 for some @xmath41",
    ". the smallest size of a dominating set in @xmath30 is called the domination number of @xmath35 and denoted @xmath42 .",
    "optimal policies for the stochastic multi - armed bandit problem were first characterised by  @xcite , while index - based optimal policies for general non - parametric problems were given by  @xcite .",
    "later @xcite proved finite - time regret bounds for a number of ucb ( upper confidence bound ) index policies , while @xcite proved finite - time bounds for index policies similar to those of @xcite , with problem - dependent bounds @xmath43 .",
    "recently , a number of policies based on sampling from the posterior distribution ( i.e. thompson sampling@xcite ) were analysed in both the frequentist  @xcite and bayesian setting  @xcite and shown to obtain the same order of regret bound for the stochastic case .",
    "for the _ adversarial _ bandit problem the bounds are of order @xmath44 .",
    "the analysis for the full information case generally results in @xmath45 bounds on the regret  @xcite , i.e. with a much lower dependence on the number of arms .",
    "intermediate cases between full information and bandit feedback can be obtained through graph feedback , introduced in @xcite , which is the focus of this paper .",
    "in particular , @xcite and @xcite analysed graph feedback problems with stochastic and adversarial reward sequences respectively .",
    "specifically , @xcite analysed variants of upper confidence bound policies , for which they obtained @xmath46 problem - dependent bounds . in more recent work",
    ", @xcite also introduced algorithms for graphs where the structure is never fully revealed showing that ( unlike the bandit setting ) there is a large gap in the regret between the adversarial and stochastic cases . in particular , they show that in the adversarial setting one can not do any better than ignore all additional feedback , while they provide an action - elimination algorithm for the stochastic setting .",
    "finally , @xcite obtain a problem - dependent bound of the form @xmath47 where @xmath48 is the linear programming relaxation to @xmath49 and @xmath50 is the minimum degree of @xmath30 .",
    "[ [ contributions . ] ] contributions .",
    "+ + + + + + + + + + + + + +    in this paper , we provide much simpler strategies based on thompson sampling , with a matching regret bound . unlike previous work , these are also applicable to graphs whose structure is unknown or changing over time . more specifically :    1 .",
    "we extend  @xcite to graph - structured feedback , and obtain a problem - independent bound of @xmath51 .",
    "2 .   using planted partition models , we verify the bound s dependence on the clique cover .",
    "we provide experiments on data drawn from two types of random graphs : erds  rnyi graphs and power law graphs , showing that our algorithms clearly outperform ucb and its variations  @xcite .",
    "finally , we measured the performance on graphs estimated from the data used in @xcite .",
    "once again , thompson sampling clearly outperforms ucb and its variants .",
    "we consider two algorithms based on thompson sampling .",
    "the first uses standard thompson sampling to select arms .",
    "as this also reveals the rewards of neighbouring arms , the posterior is conditioned on those as well .",
    "the second algorithm uses thompson sampling to select an arm , and then chooses the empirically best arm within that arm s clique .",
    "the policy is an adaptation of thompson sampling for graph - structured feedback .",
    "thompson sampling maintains a distribution over the problem parameters . at each step , it selects an arm according to the probability of its mean being the largest .",
    "it then observes a set of rewards which it uses to update its probability distribution over the parameters .    for the case where each arm has an independent parameter defining its reward distribution",
    ", we can update the distribution of all arms observed separately .",
    "a particularly simple case is when all the reward are generated from bernoulli distributions .",
    "then we can simply use a beta prior for each arm , illustrated by the policy in algorithm  [ alg : tsn ] .",
    "we note that the algorithm trivially extends to other priors and families .    for each arm @xmath7 , set @xmath52 and @xmath53    play arm @xmath54    @xmath55",
    "if @xmath56 the @xmath57 , else @xmath58      the policy does not fully exploit the graphical structure .",
    "for example , as noted by @xcite , instead of doing exploration on arm @xmath7 we could explore an apparently better neighbour , which would give us the same information .",
    "more precisely , instead of picking arm @xmath7 , we pick the arm @xmath59 with the best empirical mean .",
    "the intuition behind it is that , if we take any arm in @xmath60 , we are going to observe anyway the reward of @xmath7 .",
    "so it is always better to exploit the best arm in @xmath60 .",
    "the resulting policy , is summarized in algorithm [ alg : tsmaxn ] .",
    "although our theoretical results do not apply to this policy , it can have better performance as it uses more information .    for each arm @xmath7 , set @xmath52 and @xmath53 let @xmath61 be the empirical mean of arm @xmath7",
    "let @xmath62 play arm @xmath63    @xmath55    if @xmath56 the @xmath57 , else @xmath58      russo and van roy introduced an elegant approach to the analysis of thompson sampling .",
    "they define the _ information ratio _ as a key quantity for analysing information structures : @xmath64 ^ 2}{{\\mathbb{i}}_t(a^ * , ( a_t , y_{t , a_t}))},\\ ] ] where @xmath65 and @xmath66 denote expectation and mutual information respectively , conditioned on the history of arms and observations until time @xmath0 .",
    "they show that it follows very generally that    [ prop : ts ] if @xmath67 almost surely for all @xmath68 , then , @xmath69    here @xmath70 denotes entropy . thus to analyse the performance of thompson sampling on a specific problem ,",
    "one may focus on bounding the information ratio ( [ eq : ir ] ) .",
    "for the ( independent ) @xmath71-armed bandit case , they show that @xmath72 , while for full - information ( @xmath71 experts ) case , they show that @xmath73 .",
    "we now give a simple but useful extension of their results which is intermediate between these cases .",
    "[ prop : eq ] let @xmath74 be an equivalence relation defined on the arms with @xmath75 denoting the equivalence class of @xmath76 .",
    "let @xmath77 for sequence of random variables @xmath78",
    ". then @xmath79 , half the number of equivalence classes .",
    "this is a direct generalisation of propositions 3 and 4 in @xcite , to which it reduces when the equivalence relation is trivial ( bandit case ) or full ( expert case ) .",
    "we can now use proposition  [ prop : eq ] to analyse graph structured arms :    [ lem : gr ] let @xmath80 be a graph with @xmath81 corresponding to the arms and suppose that when an arm @xmath76 is played , we observe the rewards @xmath82 for all @xmath83 i.e we observe the rewards corresponding to both @xmath76 and all its neighbours .",
    "let @xmath84 be a clique cover of @xmath30 i.e. a partition of @xmath81 into cliques .",
    "then @xmath85 .",
    "applying proposition  [ prop : ts ] and lemma  [ lem : gr ] , we get a performance guarantee for thompson sampling with graph - structured feedback :    [ th : gr ] for thompson sampling with feedback from the graph @xmath30 , we have @xmath86 , where @xmath87 is the _ clique cover number _ of @xmath30 .",
    "the bandit and expert cases are special cases corresponding to the empty graph and the complete graph respectively since @xmath88 for the empty graph and @xmath89 for the complete graph .",
    "the _ planted partition models _ or _ stochastic block models _",
    "graphs @xmath90 are defined as follows @xcite : first a fixed partition of the @xmath91 vertices into @xmath92 parts is chosen , then an edge between two vertices within the same class exists with probability @xmath93 and that between vertices in different classes exists with probability @xmath94 , independently with @xmath95 .",
    "if @xmath96 , then with high probability , the clique cover number of the resulting graph is @xmath92 ( corresponding to the planted @xmath92 cliques ) .",
    "thus for this class of graphs , the regret grows as @xmath97 as per theorem  [ th : gr ] .",
    "this is explored in section  [ sec : experiments ] .",
    "when @xmath98 but large , the planted partition graph is considered a good model of the structure of network communities .",
    "if the underlying graph changes at each time step , then we also have the bound for the same algorithm :    suppose the underlying graph at time @xmath99 is @xmath100 , then : @xmath101    the information ratio at time @xmath0 is bounded by @xmath102 .",
    "we compared our proposed algorithms in terms of the actual expected regret against a number of other algorithms that can take advantage of the graph structure .",
    "our comparison was performed over both synthetic graphs and networks derived from real - world data .      in all our experiments",
    ", we tested against the and algorithms , introduced in  @xcite .",
    "these are the analogues of our algorithms , using upper confidence bounds instead of thompson sampling .      for the real - world networks",
    ", we also evaluated our algorithms against a variant of @xmath103- from @xcite .",
    "this is based on a linear program formulation for finding a lower bound @xmath104 on the size of the minimum dominating set .",
    "we observe first that their analysis holds for _ any _ fixed dominating set @xmath105 and the bound so obtained is @xmath106 . in particular , we may use a simple greedy algorithm to compute a near  optimal dominating set @xmath107 such that @xmath108 , where @xmath109 is the maximum degree of the graph .",
    "using such a near optimal dominating set in place of the lp relaxation and choosing arms from it uniformly at random , we obtain a variant of the original algorithm , which we call @xmath103- , which is much more computationally efficient , and which enjoys a similar regret bound :    the regret of @xmath103- is at most @xmath110 , where @xmath109 is the maximum degree of the graph .",
    "@xmath103- and @xmath103- have the hyper - parameters @xmath111 and @xmath112 , which control the amount of exploration .",
    "we found that its performance is highly sensitive to their choice . in our experiments , we find the optimal values for these parameters by performing a separate grid search for each problem , and only reporting the best results .",
    "since there is no obvious way to tune these parameters online , this leads to a favourable bias in our results for this algorithm .- greedy performs almost always best , but its performance can degrade significantly when the parameters are changed .",
    "although @xcite suggests a method for selecting these parameters , we find that using it leads to a near - linear regret . ]",
    "as thompson sampling is a bayesian algorithm , we can view the prior distribution as a hyper - parameter . in our experiments",
    ", we always set that to a beta(1,1 ) prior for all rewards .      for all of our experiments",
    ", we performed @xmath113 independent trials and reported the _ median - of - means _ estimator of the cumulative regret .",
    "it partitions the trials into @xmath114 equal groups and return the median of the sample means of each group .",
    "we set the number of groups to @xmath115 , so that the confidence interval holds with probability at least @xmath116 .",
    "we also reported the deviation of each algorithm using the gini s mean difference ( gmd hereafter ) @xcite .",
    "gmd computes the deviation as @xmath117 with @xmath118 the @xmath119-th order statistics of the sample ( that is @xmath120 ) .",
    "as shown in @xcite the gmd provides a superior approximation of the true deviation than the standard one . to account for the fact that the cumulative regret of our algorithms might not follow a symmetric distribution ,",
    "we computed the gmd separately for the values above and below the _ median - of - means_.      in our synthetic problems , unless otherwise stated , the rewards are drawn from a bernoulli distribution whose mean is generated uniformly randomly in @xmath121 $ ] except for the optimal arm whose mean is generated randomly in @xmath122 $ ] .",
    "the number of nodes in the graph is 500 .",
    "we tested with a sparse graph of 2500 edges and also with a dense graph of 62625 edges .",
    "[ [ erdsrnyi - graphs ] ] erds  rnyi graphs + + + + + + + + + + + + + + + + + +    in our first experiment , we generate the graph randomly using the erds  rnyi model . figure  [ fig : erdos : small ] and  [ fig : erdos : large ] respectively show the result in the sparse and dense graph .",
    "our first observation here is that all policies take advantage of a large number of edges as their cumulative regret is better by using the dense graph ( figure [ fig : erdos : large ] ) rather than the sparse one ( figure  [ fig : erdos : small ] ) .",
    "this confirms the theoretical result as a dense graph will have a smaller clique cover number than a sparse one .",
    "the policy outperforms all other in both the sparse and dense graph model .",
    "however , the performance of is very close to that of in the near complete graph . this is explained by the fact that in a near complete graph we have many cliques .",
    "it is revealing to see that outperforms both the and policies .",
    "[ [ power - law - graph ] ] power law graph + + + + + + + + + + + + + + +    such graphs are commonly used to generate static scale - free networks @xcite . in this experiment",
    ", we generated a non - growing random graph with expected power - law degree distribution .",
    "show the results respectively for the dense and sparse graph figure [ fig : powerlaw : large ] and [ fig : powerlaw : small ] show the results respectively for the dense and sparse graph .",
    "again , the policy clearly outperforms all other . in the sparse graph model ,",
    "is beaten by at the beginning of the rounds ( @xmath123 ) , but catches and ended up beating .    [",
    "[ planted - partition - model ] ] planted partition model + + + + + + + + + + + + + + + + + + + + + + +    the aim of the experiment on this model is to check the dependency on the number of cliques for each policy .",
    "figure [ fig : plantedpartition ] shows the results where on the x - axis we have the parameter @xmath92 of the planted partition graph ( which is almost equal to the number of cliques ) on a graph with 1024 nodes . on the y - axis",
    "we have the relative regret of each policy , i.e. the ratio between the regret of each policy with the regret of the best policy when there are two groups , for ease of comparison .",
    "as we can see , all methods regret scales similarly .",
    "thus , the theoretical bounds appear to hold in practice , and to be somewhat pessimistic . for a larger number of nodes",
    ", we would expect the plots to flatten later .",
    "our experiments on real world datasets follow the methodology described in @xcite .",
    "we first infer a graph from data , and then define a reward function for movie recommendation from user ratings .",
    "missing ratings are predicted using matrix factorization .",
    "this enables us to generate rewards from the graph .",
    "we explain the datasets , reward function and graph inference in the full version .",
    "[ [ results ] ] results + + + + + + +    figure  [ fig : facebook:100 ] shows the results for the facebook graph and figure  [ fig : flixster:100 ] for the flixster graph . once again , the thompson sampling strategies dominate all other strategies for the facebook and they are matched by the optimised @xmath103- policy in the flixster graph .",
    "we notice that in this setting the gap between the ucb policies and the rest is much larger , as is the overall regret of all policies .",
    "this can be attributed to the larger size of these graphs .",
    "we have presented the first thompson sampling algorithms for sequential decision problems with graph feedback , where we not only observe the reward of the arm we select , but also those of the neighbouring arms in the graph .",
    "thus , the graph feedback allows us the flexibility to model different types of feedback information , from bandit feedback to expert feedback .",
    "since the structure of the graph need not be known in advance , our algorithms are directly applicable to problems with changing and/or unknown topology .",
    "our analysis leverages the information - theoretic construction of @xcite , by bounding the expected information gain in terms of fundamental graph properties .",
    "although our problem - independent bound of is not directly comparable to @xcite , we believe that a problem - independent version of the latter should be @xmath124 , in which case our results would represent an improvement of @xmath125 .    in practice ,",
    "our two variants always outperform , , which also use graph feedback but rely on upper confidence bounds .",
    "we are also favourably compared against @xmath103- , even when we tune the parameters of the latter _",
    "post hoc_.    it would be interesting to extend our techniques to other types of feedback .",
    "for example , the bayesian foundations of thompson sampling render our algorithms applicable to arbitrary dependencies between arms . in future work",
    ", we will analytically and experimentally consider such problems and related applications .",
    "finally , an open question is the existence of information - theoretic lower bounds in settings with partial feedback .",
    "this research was partially supported by the snsf grants `` adaptive control with approximate bayesian computation and differential privacy '' ( izk0z2_167522 ) , `` swiss sense synergy '' ( crsii2_154458 ) , by the the people programme ( marie curie actions ) of the european union s seventh framework programme ( fp7/2007 - 2013 ) under rea grant agreement number 608743 , and the future of life institute ."
  ],
  "abstract_text": [
    "<S> we present a novel extension of thompson sampling for stochastic sequential decision problems with graph feedback , even when the graph structure itself is unknown and/or changing . </S>",
    "<S> we provide theoretical guarantees on the bayesian regret of the algorithm , linking its performance to the underlying properties of the graph . </S>",
    "<S> thompson sampling has the advantage of being applicable without the need to construct complicated upper confidence bounds for different problems . </S>",
    "<S> we illustrate its performance through extensive experimental results on real and simulated networks with graph feedback . </S>",
    "<S> more specifically , we tested our algorithms on power law , planted partitions and erds  rnyi graphs , as well as on graphs derived from facebook and flixster data . </S>",
    "<S> these all show that our algorithms clearly outperform related methods that employ upper confidence bounds , even if the latter use more information about the graph . </S>"
  ]
}