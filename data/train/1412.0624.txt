{
  "article_text": [
    "a discrete - time signal can be transformed into other domains in various ways .",
    "some signals that cover whole considered interval in one domain could be sparse in a transformation domain .",
    "compressive sensing theory , in general , deals with a lower dimensional set of linear observations of a sparse signal , in order to recover all signal values @xcite-@xcite .",
    "this area intensively develops in the last decade .",
    "a common form of observations are the signal samples .",
    "a reduced set of samples can be considered within the compressive sensing theory in order to represent a signal with the lowest possible number of samples .",
    "this theory may be applied to the situations when the missing samples are not a result of compressive sensing strategy , with the aim to reduce data size . in many engineering applications",
    "the signal samples are missing due to the system physical constraints or unavailability of the measurements .",
    "it can also happen that some arbitrarily positioned samples of a signal are so heavily corrupted by disturbances that it is better to omit them and consider as missing in the analysis @xcite , @xcite .",
    "it is interesting to note that one of the first compressive sensing theory successes in applications ( computed tomography reconstruction ) was not related to the intentional compressive sensing strategy but to the physical problem constraints , restricting the set and positions of the available data .",
    "signal reconstruction , with arbitrary missing samples , not being a result of any intentional compressive sensing strategy , is the topic of this paper .",
    "several approaches to reconstruct sparse signals from their random lower dimensional set of linear observations are introduced @xcite-@xcite .",
    "the most common are the reconstruction algorithms based either on the gradient formulations @xcite or the orthogonal matching pursuit approaches @xcite .",
    "recently a method for the reconstruction of a sparse signal with disturbed / missing samples has been proposed @xcite .",
    "in contrast to the common reconstruction methods that recover the signal in their sparsity domain the proposed method reconstructs missing samples / measurements to make the set of samples / measurements complete .",
    "since the available samples are fixed , the minimization variables are the missing samples .",
    "it means that the number of variables is equal to the number of missing signal samples in the observation domain .",
    "a new criterion for the parameter adaptation of this simple algorithm , based on the gradient directions , is proposed in this paper . computational time to achieve the target reconstruction accuracy is significantly reduced with respect to the original criterion in @xcite .",
    "the fourier transform domain is used as a case study , although the algorithm application is not restricted to this transform @xcite .",
    "the algorithm efficiency is statistically checked .",
    "after the recovery of sparse signal , then its uniqueness is checked by using the proposed theorem .",
    "its application is quite simple and numerically efficient .",
    "sparse signals with available samples being a random subset of nonuniformly sampled signal , not corresponding to the uniform sampling grid , are considered as well @xcite-@xcite .",
    "this case belongs to class of signals with indirect measurements .",
    "a possibility to recalculate the signal values at the sampling theorem positions is exploited in the nonuniform case before a reconstruction algorithm is applied @xcite .",
    "the paper is organized as follows .",
    "after the definitions in the next section , the adaptive gradient algorithm , with a new criterion for the algorithm parameter adaptation , is presented in section 3 .",
    "uniqueness of the obtained solution is analyzed in section 3 .",
    "reconstruction of nonuniformly sampled sparse signals is considered in section 4 .",
    "consider a discrete - time signal @xmath0 with @xmath1 samples whose transform coefficients are @xmath2 $ ] .",
    "signal @xmath0 is sparse in the transformation domain if the number of nonzero transform coefficients @xmath3 is much lower than the number of the original signal samples @xmath1 , @xmath4 , i.e. , @xmath5 for @xmath6 , @xmath7 , ... , @xmath8 .",
    "the dft will be considered in this paper , when @xmath9.$ ]  assume that a set of @xmath10 signal samples in the time domain is available at the instants corresponding to the discrete - time positions @xmath11 in general , the signal recovery within the compressive sensing framework consists in reconstructing the signal ( calculation of missing / unavailable / discarded samples ) so that the number of nonzero transform coefficients @xmath12 is minimal , subject to the available sample values .",
    "counting of the nonzero transform coefficients is achieved by a simple mathematical form @xmath13 , sometimes referred to as the @xmath14-norm , @xcite , @xcite .",
    "thus , the problem statement is @xmath15 where @xmath16^{t}$ ] is the vector of available signal samples , @xmath17^{t}$ ] is the vector of unknown transform coefficients , and @xmath18 is the inverse transform matrix with omitted rows corresponding to the unavailable signal samples .",
    "the @xmath14-norm based formulation is an np - hard combinatorial optimization problem .",
    "its calculation complexity is of order @xmath19 . in theory ,",
    "the np - hard problems can be solved by an exhaustive search .",
    "however , as the problem parameters @xmath1 and @xmath3 increase the running time increases and the problem becomes unsolvable .",
    "these are the reasons why the @xmath20-norm of the signal transform , @xmath21 , is commonly used as a sparsity measure function .",
    "the minimization problem is @xmath22 this minimization problem , under the conditions defined within the restricted isometry property ( rip ) , @xcite , @xcite , can produce the same result as ( [ def_l0 ] ) .",
    "note that other norms @xmath23 _ _ between the @xmath14-norm and the @xmath20-norm , with values @xmath24 , are also used in the minimization in attempts to combine good properties of these two norms @xcite .",
    "a simple gradient - based algorithm that iteratively calculates the missing sample values according to ( [ def_l1 ] ) , is presented next . the basic idea for",
    "the algorithm comes from the gradient - based minimization approaches .",
    "the missing samples are considered as variables .",
    "the influence of their variations on the sparsity measure is checked @xcite . by performing an iterative procedure ,",
    "the missing samples are changed toward lower sparsity measure values , in order to approach the minimum of the convex @xmath20-norm based sparsity measure ( [ def_l1 ] ) . if the recovery conditions for the @xmath20-norm @xcite are met then the @xmath20-norm minimum will be at the same position as the @xmath14-norm minimum , representing the true values of the missing samples .",
    "the initial signal @xmath25 is defined for @xmath26 @xmath27 as : @xmath28{ll}0 & \\text { for missing samples , } n\\in\\mathbb{n}_{q}\\\\ x(n ) & \\text { for available samples , } n\\in\\mathbb{n}_{a}\\end{array } \\right .   , \\label{initsig}\\ ] ] where @xmath29 is the complement of @xmath30 with respect to @xmath31 defined by ( [ set_av ] ) .",
    "the missing signal samples are then corrected in an iterative procedure as @xmath32 where @xmath33 is an estimate of the sparsity measure gradient vector coordinate along the variable @xmath34 direction , in the @xmath35th iteration . at the positions of the available signal samples , @xmath36 , @xmath37 . at the positions of missing samples , @xmath38 , its values",
    "are calculated by changing the signal values and forming new signals @xmath39 and @xmath40 as @xmath41 the algorithm step is denoted by @xmath42 .",
    "the values of @xmath43 at @xmath44 are@xmath45 where @xmath46 $ ] and @xmath47 $ ] .",
    "the initial value for the algorithm adaptation step @xmath42 is estimated as@xmath48    the gradient algorithm will approach the minimum point of the @xmath20-norm based sparsity measure with a precision related to the algorithm step @xmath42 .",
    "rate of the algorithm convergence for different steps is considered in @xcite .",
    "the algorithm performance is significantly improved by using adaptive step @xmath42 . a criterion that efficiently detects the event that the algorithm has reached the vicinity of the sparsity measure minimum is proposed in this paper .",
    "it is based on the direction change of the gradient vector . when the vicinity of the optimal point is reached , the gradient estimate in the @xmath20-norm based sparsity measure function changes direction for almost @xmath49 degrees .",
    "for each two successive gradient estimations @xmath50 and @xmath33 , the angle @xmath51 between gradient vectors is calculated as@xmath52 if the angle @xmath51 is above @xmath53 it means that the values reached oscillatory nature around the minimal measure value position .",
    "when this kind of the angle change is detected the step @xmath42 is reduced , for example , @xmath54 , and the same calculation procedure is continued from the reached reconstructed signal values . when the optimal point is reached with a sufficiently small @xmath42 ,",
    "then this value of @xmath42 is also an indicator of the solution precision .",
    "value of @xmath42 can be used as the algorithm stopping criterion .    a common way to estimate the precision of the result in iterative algorithms is based on the change of the result in the last iteration .",
    "an average of changes in last iteration in a large number of missing samples is a good estimate of the achieved precision .",
    "thus , the value of @xmath55 can be used as an rough estimate of the reconstruction error to signal ratio . here",
    "@xmath56 is the reconstructed signal prior to @xmath42 reduction ( prior to the execution of the algorithm inner loop , lines 7 - 20 in algorithm 1 ) and @xmath57 is the reconstructed signal after the inner loop execution .",
    "this value can also be used as a criterion to stop the algorithm .",
    "if @xmath58 is above the required precision threshold @xmath59 ( for example , if @xmath60 ) , the calculation procedure should be repeated with smaller values @xmath42 .",
    "a pseudo code of this algorithm is presented in algorithm 1 .    *",
    "set of missing / omitted sample positions @xmath29 * available samples @xmath0 , @xmath61    [ alg : init1]set @xmath62 [ alg : init2]set @xmath63 [ alg : init3]set @xmath64 [ alg : init4]set @xmath65 [ alg : loop1 ] set @xmath66 [ alg : loop2 ] @xmath67 [ alg : for ] [ alg : dft1]@xmath68 [ alg : dft2]@xmath69 [ alg : grad]@xmath70 @xmath71 [ alg : adjust]@xmath72 [ alg : next ] @xmath73 @xmath74 [ alg : delta3 ] @xmath75 @xmath57    * reconstructed signal @xmath76    * comments on the algorithm : *    - the inputs to the algorithm are the signal length @xmath1 , the set of available samples @xmath30 , the available signal values @xmath77 , @xmath78 @xmath30 , and the required precision @xmath59 .    -",
    "instead of calculating signals ( [ sig_delta ] ) and their @xmath79 for each @xmath44 we can calculate @xmath80 with @xmath81 $ ] and @xmath82=\\exp(-j2\\pi n_{i}k / n)$ ] , for each @xmath44 .",
    "since @xmath83 are independent of the iteration number @xmath35 they can be calculated only once , independently from the dft of the signal .    - in a gradient - based algorithm , a possible divergence is related to the algorithm behavior for a large step @xmath42 .",
    "small steps influence the rate of the algorithm approach to the solution only , with the assumption that it exists .",
    "influence of small steps to the calculation complexity is considered in @xcite .",
    "here , we will examine the algorithm behavior for a large value of step @xmath42 .",
    "we can write @xmath84 considering the complex number @xmath85 with @xmath86 for a large @xmath42 , from the problem geometry it is easy to show that the following bounds hold @xmath87 .",
    "therefore,@xmath88 lower limit @xmath89 is obtained if @xmath90 is imaginary - valued , while the upper limit @xmath91 follows if @xmath90 is real - valued .",
    "it means that the value of the finite difference @xmath92 that is used to correct the missing signal samples , does not depend on the value of the step @xmath42 , if @xmath42 is large .",
    "the missing signal values will be adapted for a value independent on @xmath42 in that case .",
    "the values of missing samples will oscillate within the range of the original signal values of order @xmath93 , until @xmath42 is reduced in the iterations .",
    "then the missing samples will start approaching to the position of the sparsity measure minimum .",
    "the initial values will be arbitrary changed within the signal amplitude order as far as @xmath42 is too large .",
    "it will not influence further convergence of the algorithm , when the step @xmath42 assumes appropriate values .    - since two successive gradient vectors are required to calculate the gradient angle @xmath51 , it is calculated starting from the second iteration for each @xmath42 .    - the algorithm output is the reconstructed signal @xmath34 , @xmath94 .",
    "- other signal transforms can be used instead of the dft .",
    "the only requirement is that signal is sparse in that transform domain .",
    "_ example 1 : _ consider a signal @xmath95 with @xmath96 @xmath97 , and the total number of samples @xmath98 .",
    "the sparsity parameter @xmath99 is changed from @xmath100 to @xmath101 .",
    "the amplitudes @xmath102 , frequencies @xmath103 , and phases @xmath104 are taken randomly .",
    "amplitude values are modeled as gaussian random variables with variance @xmath105 the frequency indices assume random numbers within @xmath106 , and the phases assume uniform random values within @xmath107 , in each realization .",
    "the reconstruction is performed by using @xmath108 realizations for each @xmath3 with random sets of missing @xmath109 samples in each realization .",
    "the simulations are done for @xmath110 and for @xmath111 .",
    "the reconstructed signals @xmath112 are obtained .",
    "the results are presented in fig.[fig1_fin_crtanje_b](a ) and ( b ) in a form of the signal - to - reconstruction - error ratio ( srr ) in [ db]@xmath113    [ ptb ]    fig1_fin_crtanje_b.eps    it is important to note that the all signal samples are used in this error calculation .",
    "it means that possible nonunique solutions , satisfying the same set of available samples , are considered as the reconstructions with significant error since they significantly differ at the positions of missing / recovered samples .",
    "this kind of reconstruction and uniqueness analysis is exact .",
    "however , it can be used in simulations only since it requires the exact signal in all samples .",
    "a check of the solution uniqueness , using the missing sample positions only , will be discussed later .",
    "red colors indicate the region where the algorithm had fully recovered missing samples ( compared to the original samples ) in all realizations , while blue colors indicate the region where the algorithm could not recover missing samples in any realization . in the transition region for @xmath114 slightly greater than @xmath115 we have cases when the signal recovery is not achieved and the cases of full signal recovery . a stopping criterion for the accuracy of @xmath116 [ db ] is used .",
    "it corresponds to a precision in the recovered signal of the same order as in input samples , if they are acquired by a 20-bit a / d converter .",
    "the case with @xmath111 is repeated with an additive input gaussian noise such that the input signal - to - noise ratio is @xmath117 [ db ] in each realization fig.[fig1_fin_crtanje_b](c ) . the reconstruction error in this case",
    "is limited by the input signal - to - noise value .",
    "the average reconstruction error in the noise - free cases is related to the number of the full recovery events . for @xmath111",
    "the number of the full recovery events is checked and presented in fig.[graphics_gradrec_mse_komp_3gr_4s ] ( a),(b ) .",
    "the average number of the algorithm iterations to produce the required precision , as a function of the number of missing samples and signal sparsity @xmath3 , is presented as well , fig.[graphics_gradrec_mse_komp_3gr_4s](c ) , along with the corresponding average computation time ( in seconds ) for the windows pc with intel dual core processor , fig.[graphics_gradrec_mse_komp_3gr_4s](d ) .",
    "the average computation time is proportional to the average number of iterations multiplied by the number of missing samples ( variables ) @xmath118 .",
    "finite difference method and the adaptation procedure presented in this paper overcome the problem of the derivative existence in the case of the @xmath20-norm near the optimal point .",
    "although the main point of this manuscript is to present a new method of reconstruction , with missing samples being minimization variables , efficiency of the presented algorithm is compared with the standard routines where the @xmath20-norm problem is solved using the linear programming .",
    "direct adaptation of missing samples can be used in various applications ( including recovery of sampled signals where a linear relation between signal and transform can not be established ) .",
    "the performance of the proposed algorithm are compared with the algorithm that recasts the recovery problem ( 6 ) into a linear programming framework and uses the primal - dual interior point method ( l1-magic code in matlab ) .",
    "both algorithms are run with the default parameters using 100 sparse signals with random parameters .",
    "the results are presented in the table [ table_1 ] .",
    "columns notation in the table is : @xmath3 for sparsity , @xmath118 for the number of missing samples , mae stands for the mean absolute error , lp - dp denotes the values obtained by running the linear programming primal - dual algorithm ( matlab l1-magic code ) , and as is for the presented adaptive algorithm with variable step .",
    "calculation time using matlab is presented in both cases .",
    "[ c]cccccc@xmath3 & @xmath109 & mae lp - dp & mae as & time lp - dp & time as + 6 & 16 & @xmath119 & @xmath120 & 0.043390 & 0.013433 + 10 & 16 & @xmath121 & @xmath122 & 0.041121 & 0.013393 + 16 & 16 & @xmath123 & @xmath124 & 0.041569 & 0.014003 + 6 & 32 & @xmath125 & @xmath126 & 0.038492 & 0.025733 + 10 & 32 & @xmath127 & @xmath128 & 0.038578 & 0.027270 + 16 & 32 & @xmath129 & @xmath130 & 0.046595 & 0.029636 + 6 & 45 & @xmath131 & @xmath132 & 0.041317 & 0.036442 + 10 & 45 & @xmath133 & @xmath134 & 0.039162 & 0.041843 + 16 & 45 & @xmath135 & @xmath136 & 0.042910 & 0.054350 +    an illustration of the algorithm performance regarding to the srr and the gradient angle @xmath51 in one realization , with @xmath137 , is presented in fig.[mse_angles_gr ] .",
    "[ ptb ]    mse_angles_gr.eps",
    "uniqueness of the solution is guarantied if the restricted isometry property is used and checked , with appropriate isometry constant for the norm - one based minimization .",
    "however , two problem exist in the implementation of this method . for a specific measurement matrix it produces quite conservative bounds , meaning in practice a large number of false alarms for nonuniqueness .",
    "in addition the check of the restricted isometry property required a combinatorial approach , which is an np hard problem ( like the solution of the problem using zero - norm in minimization ) .",
    "the the gradient - based algorithm presented here considers missing samples / measurements as the minimization variables .",
    "a theorem for the solution uniqueness , in terms of the missing sample positions is used here .",
    "the proof of this theorem , with additional details and examples , is given in @xcite . when the reconstruction of a signal is done and the solution of sparsity @xmath3 in the dft domain is obtained , then the theorem provides an easy check for the solution uniqueness .",
    "consider a signal @xmath138 where @xmath139 for @xmath140 and takes arbitrary values at the positions of missing samples @xmath141 .",
    "the dft of this signal is @xmath142 the values of missing samples @xmath143 for @xmath144 are considered as variables , in the sparsity measure minimization process , with the final goal to get @xmath145 , or @xmath139 for all @xmath146 .",
    "existence of unique solution depends on the number of missing samples @xmath147 , their positions @xmath29 , and the available signal values @xcite .",
    "the uniqueness here means that if a sparse signal , with the transform @xmath12 , is reconstructed using the fixed set of available samples and the gradient - based algorithm ( or any other reconstruction algorithm ) , then there is no other signal transform of the same or lower sparsity satisfying the same set of available sample values .",
    "consider signal @xmath0 that is sparse in the dft domain with unknown sparsity .",
    "assume that the signal length is @xmath148 samples and that @xmath147 samples are missing at the instants @xmath149 .",
    "also assume that the reconstruction is performed and that the dft of reconstructed signal is of sparsity @xmath3 .",
    "assume that the positions of the reconstructed nonzero values in the dft are @xmath150 reconstruction result is unique if the inequality @xmath151 holds .",
    "integers @xmath152 and @xmath153 are calculated as@xmath154 where @xmath155 .",
    "signal independent uniqueness corresponds to the worst case signal form , when @xmath156 .",
    "the answer is obtained almost immediately , since the computational complexity of the theorem is of order @xmath157 . the proof is given in @xcite .",
    "consider now a discrete - time signal obtained by sampling a continuous - time signal @xmath158 at arbitrary positions .",
    "since the dft will be used in the analysis , we can assume that the continuous - time signal is periodically extended with a period @xmath159 .",
    "according to the sampling theorem , the period @xmath159 is related to the number of samples @xmath1 , the sampling interval @xmath160 , and the maximal frequency @xmath161 as @xmath162 .",
    "the continuous - time signal can be written as an inverse fourier series @xmath163 with the fourier series coefficients being related to the dft as @xmath164 $ ] and @xmath165 .",
    "the discrete - time index @xmath146 corresponds to the continuous - time instant @xmath166 .",
    "discrete - frequency indices@xmath167are @xmath168 .",
    "any signal value can be reconstructed from the samples taken according to the sampling theorem , @xmath169}{n\\sin[(n-\\frac{t}{\\delta t})\\pi / n]}.\\label{sig_rec_c}\\ ] ] this relation holds for an even @xmath1 , @xcite , @xcite .",
    "a signal @xmath158 is sparse in the transformation domain if the number of nonzero transform coefficients @xmath3 is much lower than the number of the original signal samples @xmath1 within @xmath159 , @xmath4 , i.e. , @xmath170 for @xmath6 , @xmath7 , ... , @xmath8 .",
    "a signal@xmath171 of sparsity @xmath3 can be reconstructed from @xmath114 samples , where @xmath10 , if the recovery conditions are met .",
    "consider now a random set of possible sampling instants @xmath172 , @xmath173 where @xmath174 is a uniform random variable @xmath175 . here",
    "@xmath176 denotes a time instant , while in the uniform sampling the discrete - time index @xmath177 has been used to indicate instant corresponding to @xmath178 .",
    "assume that a random set of @xmath114 signal samples is available at @xmath179    since the signal is available at randomly positioned instants the fourier transform coefficients estimated as @xmath180 will not be sparse even if a large number @xmath114 of samples is available . to improve the results ,",
    "the problem can be reformulated to produce a better estimation of the sparse signal transform during the recovery process . if the signal values were available at @xmath181 for @xmath182 the signal values at the sampling theorem positions could be recovered .",
    "the transformation matrix relating samples taken at @xmath176 with the signal values at the sampling theorem positions , according to ( [ sig_rec_c ] ) , is @xmath183{c}x(t_{1})\\\\ x(t_{2})\\\\ ... \\\\ x(t_{n } ) \\end{array } \\right ]    &   = \\left [ \\begin{array } [ c]{cccc}b_{11 } & b_{12 } & ... & b_{1n}\\\\ b_{21 } & b_{22 } & ... & b_{2n}\\\\ ... & ... & ... & ... \\\\ b_{n1 } & b_{n2 } & ... & b_{nn}\\end{array } \\right ]   \\left [ \\begin{array } [ c]{c}x(1)\\\\ x(2)\\\\ ... \\\\",
    "x(n ) \\end{array } \\right ] \\\\",
    "\\mathbf{\\hat{x } }   &   \\mathbf{=bx}\\ ] ] with @xmath184}{n\\sin[(j - t_{i}/\\delta t)\\pi /n]}e^{j(j - t_{i}/\\delta t)\\pi / n}\\ ] ] a problem here is that we know just @xmath10 of signal samples .",
    "the values at unavailable positions @xmath185 are assumed to be zero in the initial iteration .",
    "their positions are assumed at the sampling theorem instants , @xmath186 for @xmath185 , since they are not known anyway . with this assumption",
    "the problem reduces to the missing samples @xmath187 , being  considered as variables and the remaining samples , defined by vector @xmath188 , being calculated as @xmath189 the matrix @xmath190 is inverted only once for the given signal sample positions .",
    "there is a direct relation to calculate the values @xmath191 based on the randomly sampled values @xmath192 , @xcite , where the inversion is not needed .",
    "the algorithm is adapted to this kind of signals as follows :    the signals @xmath193 and @xmath194 are formed .",
    "the available samples are recalculated to @xmath39 and @xmath40 according to ( [ inv_sam ] ) as @xmath195 and @xmath196 these signals are used in the next algorithm steps .",
    "_ example 2 : _ consider the signal defined by ( [ signal ] ) .",
    "similar results for the srr and the average number of iterations , for various @xmath114 and @xmath3 , are obtained here as in fig.[fig1_fin_crtanje_b ] .",
    "thus , they will not be repeated .",
    "instead we will present a particular realization with @xmath137 nonzero dft coefficients , out of @xmath110 , and a number of available samples @xmath197 within the transition region , when the recovery is not always obtained .",
    "these realizations , when the recovery conditions , for a given signal and for some of the considered sets of available samples , are met , can still be detected .",
    "this process is especially important if we are not in the position to define the sampling strategy for @xmath198 available samples in advance , like in the cases when the available samples are uncorrupted samples and their positions can be arbitrary .",
    "the criterion for detection of a sparse signal in recovery is the measure of the resulting signal sparsity . in this case measures closer to the @xmath14-norm should be used for a detection .",
    "for example , with @xmath199-form in the case of a false recovery all transform coefficients are nonzero with @xmath200 . for a full recovery of a sparse signal",
    "the number of nonzero coefficients ( the measure value ) is much lower since @xmath4 .",
    "consider the case with @xmath197 available randomly positioned samples and @xmath137 nonzero dft coefficients . among 100 performed realizations",
    "a possible sparse recovery event is detected ( when the described sparsity measure of the result is much lower than @xmath1 ) .",
    "the dft coefficients set of the detected sparse signal is  @xmath201 , @xmath202 , @xmath203 , @xmath204 , @xmath205 , @xmath206 .",
    "it confirms that the reconstructed signal is sparse .",
    "this sparse reconstruction is checked for uniqueness using the theorem .",
    "the missing samples are from the set @xmath149 .",
    "it is a set difference of all samples @xmath207 and @xmath208 for @xmath209 corresponding values of @xmath152 and @xmath153 , defined in the theorem , are calculated .",
    "their values are : @xmath210{|rrrrrrrr|}\\hline $ h$ & $ 0 $ & $ 1 $ & $ 2 $ & $ 3 $ & $ 4 $ & $ 5 $ & $ 6$\\\\\\hline $ q_{2^{h}}$ & $ 112 $ & $ 58 $ & $ 31 $ & $ 16 $ & $ 8 $ & $ 4 $ & $ 2$\\\\\\hline $ s_{2^{7-h}}$ & $ 0 $ & $ 0 $ & $ 4 $ & $ 5 $ & $ 4 $ & $ 4 $ & $ 2$\\\\\\hline \\end{tabular}\\ ] ]    note that @xmath211 is the total number of missing samples , while @xmath212 is obtained by counting odd and even samples in @xmath29 and taking higher number of these two .",
    "since there are @xmath213 samples at odd positions and @xmath214 samples at even positions , it means that @xmath215 .    for @xmath216",
    "there are @xmath217 missing sample @xmath149 with @xmath218 , @xmath219 missing samples with @xmath220 , @xmath221 missing samples with @xmath222 , and @xmath223 missing samples with @xmath224 resulting in @xmath225 , and so on .",
    "we can easily conclude that samples @xmath226 and @xmath227 are missing , meaning that @xmath228 assumes its maximal possible value @xmath229 .",
    "similar counting is done to get @xmath230 .",
    "for example , @xmath231 where array @xmath232 is obtained by sorting number of even and odd elements in @xmath233 .",
    "since there are @xmath234 even and @xmath235 odd elements @xmath236 and @xmath237 resulting in @xmath238 .    as expected this set of @xmath239 missing samples @xmath29 does not guarantee a unique solution for an arbitrary signal of sparsity @xmath137 . by using the theorem with @xmath156 and @xmath152 presented in the previous table we easily get that the solution uniqueness for this set @xmath29 and arbitrary signal requires @xmath240 .",
    "however , for the specific available signal values , a sparse signal is reconstructed in this case , with nonzero coefficients at @xmath201 , @xmath202 , @xmath203 , @xmath204 , @xmath205 , @xmath206 .",
    "the uniqueness then means that starting from this signal we can not find another signal of the same sparsity by varying the missing signal samples positioned at @xmath144 .",
    "the theorem then gives the answer that this specific recovered signal @xmath112 , with specific missing sample values and positions @xmath29 , is unique .",
    "it means that starting from @xmath112 we can not get another signal of the same or lower sparsity by varying the missing samples only .",
    "the reconstructed signal is presented in fig.[grad_rand_samp_0_n_f_varijanta_lett_even ] .",
    "the signal - to - reconstruction - error ratio defined by ( [ srrr ] ) , calculated for all signal samples , is @xmath241 db . it corresponds to the defined reconstruction algorithm precision of about @xmath108 db .    [ ptb ]    grad_rand_samp_0_n_f_varijanta_lett_v_even.eps    in addition to the considered case two obvious cases in the uniqueness analysis may appear : 1 ) when both , the reconstructed signal and the worst case analysis produce a unique solution using the set of missing samples @xmath29 , and 2 ) when both of them produce a result stating that a signal with certain sparsity can not be reconstructed in a unique way with @xmath29 .",
    "finally , it is interesting to mention that there exists a fourth case when the set of missing samples can provide a unique reconstruction of sparse signal ( satisfying unique reconstruction condition if it were possible to use @xmath14-norm in the minimization process ) , however the @xmath20-norm based minimization does not satisfy the additional restricted isometry property constraints @xcite , @xcite to produce this solution ( the same solution as the one which would be produced by the @xmath14-norm ) .",
    "this case will be detected in a correct way using the presented theorem .",
    "it will indicate that a unique solution is possible using @xmath29 , while if the @xmath20-norm based minimization did not produce this solution as a result of the reconstruction algorithm , the specific reconstructed signal will not satisfy the uniqueness condition .",
    "analysis of nonuniformly sampled sparse signals is performed . a gradient - based algorithm with adaptive step",
    "is used for the reconstruction . a new criterion for the parameter adaptation in the algorithm , based on the gradient directions analysis ,",
    "is proposed .",
    "it significantly improves the calculation efficiency of the algorithm .",
    "the random nonuniformly positioned available samples are recalculated based on the sampling theorem reconstruction formula .",
    "based on the new set of samples the recovery is performed .",
    "the methods are checked and illustrated on numerical examples .",
    "99      e.  j. cands , j.  romberg , and t.  tao , robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information ,  _ ieee trans . on information theory _ , vol .",
    "52 , no .  2 ,",
    "489509 , 2006 .",
    "l. stankovi , i. orovi , s. stankovi , and m. amin , robust time frequency analysis based on the l - estimation and compressive sensing ,  _ ieee signal processing letters _ , vol .",
    "5 , pp . 499502 , 2013 .",
    "r. e. carrillo , k. e. barner , and t. c. aysal , robust sampling and reconstruction methods for sparse signals in the presence of impulsive noise ,  _ ieee journal of selected topics in signal processing _",
    ", 2010 , vol .",
    "392408 .",
    "m.  a. figueiredo , r.  d. nowak , and s.  j. wright , gradient projection for sparse reconstruction : application to compressed sensing and other inverse problems ,  _ ieee journal of selected topics in signal processing _ , vol .  1 , no .  4 , pp . 586597 , 2007 .",
    "t. serafini , g. zanghirati and l. zanni , gradient projection methods for large quadratic programs and applications in training support vector machines ,  _ optimization methods and software _ , vol . 20 , no .",
    "23 , pp . 353378 , 2004 .",
    "e. candes , j. romberg and t. tao , robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information ,  _ ieee trans . on information theory _ , vol .",
    "489509 , 2006 .",
    "b. turlach , on algorithms for solving least squares problems under an l1 penalty or an l1 constraint ,  _ proc . of the american statistical association ; statistical computing section _ , pp . 25722577 , alexandria , va , 2005 .",
    "i.  daubechies , m.  defrise , and c.  de  mol , an iterative thresholding algorithm for linear inverse problems with a sparsity constraint ,  _ communications on pure and applied mathematics _ , vol .",
    "57 , no .  11 , pp . 14131457 , 2004 .",
    "y.  d.  zhang and m.  g.  amin , compressive sensing in nonstationary array processing using bilinear transforms ,  in proc",
    ".  _ ieee sensor array and multichannel signal processing workshop _ , hoboken , nj , june 2012 .",
    "l. stankovi , s. stankovi , and m. g. amin , missing samples analysis in signals for applications to l - estimation and compressive sensing ,  _ signal processing _ ,",
    "elsevier , vol .",
    "2014 , pp . 401408 .",
    "e. sejdi , a. cam , l. f. chaparro , c. m. steele , and t. chau , compressive sampling of swallowing accelerometry signals using tf dictionaries based on modulated discrete prolate spheroidal sequences ,  _  eurasip journal on advances in signal processing _ , 2012:101 doi:10.1186/168761802012101 .",
    "l. stankovi , m. dakovi and s. vujovi , adaptive variable step algorithm for missing samples recovery in sparse signals ,  _ iet signal processing _ , vol .  8 , no .  3 , pp .  246 -256 , 2014 , ( arxiv:1309.5749v1 ) .",
    "m. wakin , s. becker , e. nakamura , m. grant , e. sovero , d. ching , y. juhwan , j. romberg , a. emami - neyestanak , e. candes , `` a nonuniform sampler for wideband spectrally - sparse environments , '' _ emerging and selected topics in circuits and systems , ieee journal on _ , vol.2 , no.3 , pp.516,529 , sept .",
    "m. mishali , y.c .",
    "eldar , `` from theory to practice : sub - nyquist sampling of sparse wideband analog signals , '' _ selected topics in signal processing , ieee journal of _ , vol.4 , no.2 , pp.375,391 , april 2010 .",
    "r. grigoryan , t. l. jensen , t. arildsen , t. larsen , `` reducing the computational complexity of reconstruction in compressed sensing nonuniform sampling , '' in _ proceedings of the 21st eusipco 2013 _ , sept .",
    "j. a. tropp , j.n .",
    "laska , m.f .",
    "duarte , j.k .",
    "romberg , r.g .",
    "baraniuk , `` beyond nyquist : efficient sampling of sparse bandlimited signals , '' _ information theory , ieee transactions on , _ vol.56 , no.1 , pp.520,544 , jan .",
    "2010 .",
    "l. stankovi , m. dakovi , `` on the uniqueness of the sparse signals reconstruction based on the missing samples variation analysis '' , _ signal processing _ , submitted ( simultaneously with this paper , can be considered as its second part ) ."
  ],
  "abstract_text": [
    "<S> sparse signals can be recovered from a reduced set of samples by using compressive sensing algorithms . in common methods </S>",
    "<S> the signal is recovered in the sparse domain . a method for the reconstruction of sparse signal which reconstructs the remaining missing samples / measurements </S>",
    "<S> is recently proposed . </S>",
    "<S> the available samples are fixed , while the missing samples are considered as minimization variables . </S>",
    "<S> recovery of missing samples / measurements is done using an adaptive gradient - based algorithm in the time domain . </S>",
    "<S> a new criterion for the parameter adaptation in this algorithm , based on the gradient direction angles , is proposed . </S>",
    "<S> it improves the algorithm computational efficiency . </S>",
    "<S> a theorem for the uniqueness of the recovered signal for given set of missing samples ( reconstruction variables ) is presented . </S>",
    "<S> the case when available samples are a random subset of a uniformly or nonuniformly sampled signal is considered in this paper . </S>",
    "<S> a recalculation procedure is used to reconstruct the nonuniformly sampled signal . </S>",
    "<S> the methods are illustrated on statistical examples . </S>"
  ]
}