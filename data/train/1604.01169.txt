{
  "article_text": [
    "given @xmath0 objective functions @xmath1 , a central theme in multi - objective optimization is to find the pareto set of optimal compromises : the set of points @xmath2 that can not be improved in any objective without getting worse in another one .",
    "the cardinality of this set of often huge or even infinite . in a black - box setting it is best approximated by the set of mutually non - dominated query points .",
    "an archive @xmath3 of non - dominated solutions is a data structure for keeping track of the known non - dominated points @xmath4 of a multi - objective optimization problem .",
    "it can result from a single run of an optimization algorithm , or from many runs of potentially different algorithm .",
    "depending on the application such an archive can serve different purposes .",
    "it can act as a portfolio of solutions accessed by a decision maker , possibly after going through further post - processing steps .",
    "it can also act as input to various algorithms , e.g. , selection operators of evolutionary multi - objective optimization algorithms ( moeas ) , stopping criteria , and performance assessment and monitoring tools .",
    "all of these algorithms may involve the computation of set quality indicators such as dominated hypervolume , for which the computation of the non - dominated subsets is a pre - processing step .    some of the above applications require access to the non - dominated set `` anytime '' , i.e. , already during the optimization ( online case , called dynamic problem in @xcite ) , while others get along with storing all solutions and extracting the non - dominated subset after the optimization is finished ( offline or static case ) .",
    "the storage of millions of intermediate points does not pose a problem on today s computers , and even full non - dominated sorting is feasible on huge collections of objective vectors with suitable algorithms .",
    "hence , we consider the offline case a solved problem , at least for moderate values of  @xmath5 .",
    "in this paper we are interested in archives with the following properties :    online updates of the set of non - dominated points shall be efficient .",
    "in particular , it shall be feasible to process long sequences of candidate solutions one by one , i.e. , as soon as they are proposed and evaluated by an iterative optimization algorithm .",
    "the archive shall not contain dominated points , even if these points were non - dominated at an earlier stage .",
    "i.e. , points shall be removed as soon as they are dominated by a newly inserted point .",
    "the full set of non - dominated points shall be stored , not an approximation set of a - priori bounded cardinality .",
    "ideally , the algorithm should scale well not only to large archives , but also to a large number of objectives .",
    "these prerequisites imply the following processing steps .",
    "first it is checked whether a candidate point @xmath6 is dominated by any point in the archive or not .",
    "if @xmath6 is non - dominated then it is added to the archive .",
    "in addition , any points in @xmath3 that happen to be dominated by @xmath6 are removed .",
    "all of these steps should be as efficient as possible . at the very least",
    ", they should be faster than the @xmath7 linear `` brute force '' search through the archive .",
    "in this paper we propose an algorithm achieving this goal .",
    "it is based on a binary space partitioning tree ( bsp tree ) .",
    "its performance is demonstrated empirically , for large archives ( up to @xmath8 non - dominated points ) and large numbers of objectives ( up to @xmath9 ) , as well as analytically in the form of asymptotic ( lower and upper ) runtime bounds .",
    "we provide c++ source code for the proposed archive .",
    "it is based on the implementation from the ( non - public ) code base of the black box optimization competition ( bbcomp ) , where it is applied for online monitoring of the optimization progress .    in the remainder of this paper",
    "we first define the problem and fix our notation . after reviewing related work we present the proposed archiving algorithm .",
    "we derive asymptotic lower and upper bounds on its runtime and assess its practical performance empirically on a variety of tasks .",
    "[ [ dominance - order ] ] dominance order + + + + + + + + + + + + + + +    the objectives are collected in the vector - valued objective function @xmath10 , @xmath11 . for objective vectors",
    "@xmath12 we define the pareto dominance relation @xmath13 this relation defines a partial order on @xmath14 , incomparable values @xmath15 fulfilling @xmath16 and @xmath17 remain .",
    "the relation is pulled back to the search space  @xmath18 by the definition @xmath19 iff @xmath20 .",
    "[ [ pareto - front - and - pareto - set ] ] pareto front and pareto set + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath21 denote the image of the objective function ( also called the attainable objective space ) .",
    "the pareto front is defined as the set of objective values that are optimal w.r.t .",
    "pareto dominance , i.e. , the set of non - dominated objective vectors @xmath22 the pareto set is @xmath23 .    [ [ non - dominated - points ] ] non - dominated points + + + + + + + + + + + + + + + + + + + +    in the sequel we will deal with objective vectors , not with actual search points . in this paper",
    "we restrict ourselves to maintaining only a single search point for each non - dominated objective vector , although it is possible to observe any number of search points of equal quality . in other words",
    ", we aim to approximate the pareto front , represented by a minimal complete pareto set .    for our purposes",
    ", let @xmath24 denote the set of all known non - dominated objective vectors stored in the archive at some point , with @xmath25 denoting the current cardinality of the archive .",
    "the objective vector of the new candidate @xmath6 is denoted by @xmath26 .",
    "[ [ fixed - memory - approximations . ] ] fixed memory approximations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    the growth of the set of non - dominated points is in general unbounded .",
    "still , many moeas use their ( fixed size ) population as a rough approximation of the pareto front .",
    "even if an external archive is employed , computer memory is finite , which sets limits to the approach of archiving an unbounded number of non - dominated points . therefore limited memory archives ( e.g. , based on clustering ) were subject of intense study  @xcite .",
    "their main disadvantage is the limited precision of their pareto front representation , which can even lead to oscillatory behavior when used for optimization  @xcite .",
    "[ [ memory - consumption . ] ] memory consumption .",
    "+ + + + + + + + + + + + + + + + + + +    nowadays even commodity pcs are equipped with gigabyes of ram , enabling the storage of millions of objective vectors in memory .",
    "this makes it feasible for moeas to maintain all non - dominated points in the population , as proposed by krause et al .  @xcite .",
    "although the algorithm is limited to @xmath27 objectives , it demonstrates successfully that even on standard hardware memory is no longer a limiting factor for archiving of all known non - dominated points .",
    "[ [ offline - case . ] ] offline case .",
    "+ + + + + + + + + + + + +    efficient algorithms are known for the offline case of obtaining the pareto optimal subset from a set of points , i.e. , at the end of an optimization run .",
    "this problem was first addressed in @xcite . even full",
    "non - dominated sorting ( delivering not only the pareto optimal subset , but a partitioning into disjoint fronts ) can be achieved in only @xmath28 operations and @xmath7 memory  @xcite .",
    "however , computing the full pareto front from scratch after every update is wasteful , and hence specialized updating algorithm are needed for the online case .",
    "[ [ skylines . ] ] skylines .",
    "+ + + + + + + + +    a closely related but slightly different problem is found in data base queries : so - called `` skyline queries '' ask for a skyline of records , which is just a different terminology for the non - dominated ( pareto optimal ) subset with respect to a specified subset of fields .",
    "while the offline case is the most important one , online algorithms with good anytime performance are of relevance .",
    "the requirements differ from the problem under study in a decisive point : in the data base setting the full set of records is available from the start .",
    "the process is limited only by computational and memory constraints , but not by the sequential nature of proposing points in an iterative optimizer .",
    "efficient algorithms ( e.g. , based on nearest neighbor queries ) exist for the skyline problem  @xcite .    [ [ search - trees . ] ] search trees .",
    "+ + + + + + + + + + + + +    tree data structures of various sorts are attractive for tackling our problem . they offer a natural problem decomposition , i.e. , adding a single point usually affects only a small neighborhood of the current front , possibly represented by a small sub - tree .",
    "the dominance decision tree ( ddt ) data structure was proposed specifically for the problem at hand @xcite .",
    "they work well if the fraction of non - dominated points and hence the archive is small  @xcite .",
    "in contrast , quad trees can reduce the computational effort for large archives @xcite . a clear disadvantage of quad trees generalized to @xmath29 objectives",
    "is that partitioning a space cell results in @xmath30 sub - cells , which limits the approach to small numbers @xmath5 of objectives .",
    "we first discuss the trivial baseline method and a highly efficient alternative for the special case of @xmath27 objectives",
    ". then we present our core contribution , an efficient method for the general case of @xmath31 objectives .",
    "the naive `` brute force '' baseline method stores all non - dominated points in a flat linear memory vector ( dynamically extensible array ) or linked list .",
    "the insert operation loops over the archive .",
    "it compares the candidate vector @xmath32 to each stored @xmath33 w.r.t .",
    "this takes @xmath34 operations per point in the archive .",
    "if @xmath35 then the point does not need to be archived and the procedure stops . if @xmath36 then @xmath33 is removed . in the list , removal takes @xmath37 operations . in the vector we overwrite the dominated point with the last point , which is then removed ( @xmath34 operations ) .",
    "finally , @xmath32 is appended to the end of the list or vector ( amortized constant time for vectors with a doubling strategy , but even a possible @xmath7 relocation of the memory block does affect the analysis ) .",
    "hence , in the worst case the brute force method performs @xmath38 operations .",
    "it is significantly faster ( in expectation over a presumed random order of the archive ) only if @xmath32 is dominated by more than @xmath39 points from the archive .",
    "advantages of this algorithm are the trivial implementation and , in case of a linear memory array , optimal use of the processor cache .",
    "the method can be considered an online variant of deb s fast non - dominated sorting algorithm @xcite , however , restricted to the first non - dominance rank .      for the bi - objective case the pareto front",
    "is well known to obey a special structure that can be exploited for our purpose : we keep the archive sorted w.r.t .  the first objective @xmath40 in ascending order , which automatically keeps it sorted in descending order w.r.t .",
    "to the second objective @xmath41 . given @xmath32",
    "we search for the indices @xmath42 of @xmath32 s potential `` left '' and `` right '' neighbors on the front . if the @xmath43 is undefined",
    "because the set is empty then @xmath32 is non - dominated and we set @xmath44 for further processing .",
    "if @xmath32 is weakly dominated by any archived point then it is also weakly dominated by @xmath45 , which is the case exactly if @xmath46 .",
    "hence once @xmath47 is found the check is fast .",
    "if @xmath32 happens to dominate any archived points , then these are of the form @xmath48 .",
    "hence , given @xmath49 it is easy to identify the dominated points , which are then removed from the archive .",
    "self - balancing trees such as avl - trees and red - black - trees are suitable data structures for performing these operators quickly .",
    "the search for @xmath47 and @xmath49 and the insert operation require @xmath50 operations each , and so does the removal of a point . in an amortized analysis",
    "there can be at most one removal per insert operation , hence the overall complexity remains as low as @xmath50 , which is far better than the @xmath51 brute - force method ( note that here @xmath5 does not really enter the complexity since it is fixed to the constant @xmath27 ) . with this archive , the cumulated effort of @xmath25",
    "iterative updates equals ( up to a constant ) the full non - dominated sort post - processing step by sweeping objectives  @xcite .      for more than two objectives",
    "non - dominated sets obey far less structure than in the bi - objective case .",
    "hence it is unclear which speed - up is achievable .",
    "however , it should be possible to surpass the linear complexity of the brute - force baseline . in the following",
    "we present an algorithm that achieves this goal .",
    "we propose to store the archived non - dominated points in a binary space partitioning ( bsp ) tree . among the different variants a simple k - d tree @xcite seem to be best suited .",
    "this choice was briefly discussed and quickly dismissed in @xcite and @xcite .",
    "nonetheless we propose an archiving algorithm based on a k - d tree , for the following reason .",
    "we expect most new non - dominated points to dominate only a local patch of the current front",
    ". therefore it should be possible to limit dominance comparisons to few archived points close to the candidate point .",
    "space partitioning is a natural approach to exploiting this locality .",
    "let @xmath52 denote the root node .",
    "each interior node of the tree is a data structure keeping track of its left and right child nodes @xmath47 and @xmath49 , an objective index @xmath53 , and a threshold @xmath54 . for a node @xmath55",
    "we refer to these data fields with the dot - notation , i.e. , @xmath56 refers to the right child node of  @xmath55 . with @xmath57",
    "we refer to the parent node , i.e. , @xmath58 and @xmath59 , while @xmath60 is undefined .",
    "we write @xmath61 , and @xmath62 for the @xmath63-th ancestor of  @xmath55 .",
    "the objective space is partitioned as follows .",
    "let @xmath64 denote the subspace represented by the node @xmath55 .",
    "we have @xmath65 .",
    "we recursively define @xmath66 and @xmath67 .",
    "each leaf node holds a set @xmath68 of objective vectors limited in cardinality by a predefined bucket size  @xmath69 .",
    "in addition , each node ( interior or leaf ) keeps track of the number @xmath25 of objective vectors in the subspace it represents .    newly generated objective vectors @xmath32",
    "are added one by one to the archive with the ` process ` algorithm laid out in algorithm  [ algo : process ] .",
    "@xmath70 checkdominance(@xmath52 , @xmath32 , @xmath71 , @xmath72 ) +    @xmath73 +   +      ` process ` calls the recursive ` checkdominance ` algorithm ( algorithm  [ algo : checkdominance ] ) , which returns the number of points in the archive dominated by @xmath32 , or @xmath74 if @xmath32 is dominated by at least one point in the archive .",
    "the procedure also removes all points dominated by @xmath32 .",
    "if @xmath32 is non - dominated ( i.e. , the return value is non - negative ) , then @xmath32 is inserted into the tree by descending into the leaf node @xmath55 fulfilling @xmath75 . if the insertion would exceed the bucket size ( @xmath76 , with @xmath77 ) , then the node is split . to this end",
    "we need to select an objective index @xmath78 and a threshold @xmath79 .",
    "the only hard constraint on the choice of @xmath78 is that @xmath80 must contain at least two values , so that splitting the space in between yields two leaf nodes holding at most @xmath81 objective vectors .",
    "however , for reasons that will become clear in the next section we prefer to select different objectives if possible when descending the tree . for @xmath53",
    "we define the distance @xmath82 of the node @xmath55 in its chain of ancestors from the next node splitting at objective  @xmath78 .",
    "we set @xmath83 if the root node is reached before observing objective  @xmath78 .",
    "we chose @xmath84 .",
    "for the selection of @xmath79 we have to take into account that multiple objective vectors may agree in their @xmath78-th component .",
    "we select @xmath79 as the midpoint of two values from @xmath85 so that the split balances the leaves as well as possible . for even @xmath81 ( and hence an uneven number of objective vectors )",
    "we prefer more points in the left leaf .",
    "the ` checkdominance ` algorithm is the core of our method .",
    "it takes a node @xmath55 , the candidate point @xmath32 , and two index sets @xmath81 and @xmath86 as input .",
    "it returns the number of points in the subtree strictly dominated by @xmath32 , and @xmath74 if @xmath32 is weakly dominated by any point in the space cell represented by the subtree .",
    "the algorithm furthermore removes all dominated points from the subtree .    when faced with a leaf node it operates similar to the brute force algorithm .",
    "however , for interior nodes it can do better . to this end , note that the set @xmath87 can be written in the form @xmath88 where @xmath89 is the projection of @xmath64 to the @xmath78-th objective . since the reals are totally ordered , we distinguish the cases @xmath90 , @xmath91 , and @xmath92 .",
    "note that @xmath90 for all @xmath78 implies that @xmath32 dominates the whole space cell @xmath64 , similarly @xmath92 implies that @xmath32 is dominated by any point in @xmath64 .",
    "if there exist @xmath93 so that @xmath94 and @xmath92 then @xmath32 is incomparable to all points in @xmath64 .",
    "the algorithm descends the tree by recursively invoking itself on the left and right child nodes , but only if necessary .",
    "the recursion is necessary only if the comparisons represented by the recursive calls up the call stack do not determine the dominance relation between @xmath32 and @xmath64 yet . at the root node",
    "we know that it holds @xmath95 for all @xmath53 .",
    "hence we have either @xmath96 or @xmath97 , and hence either @xmath98 or @xmath99 .",
    "the sets @xmath81 and @xmath86 keep track of the objectives in which @xmath32 is better or worse than @xmath64 .",
    "the two sets are apparently disjoint .",
    "if they are non - empty at the same time then the candidate point and the space cell are incomparable , hence the recursion can be stopped .",
    "if @xmath86 equals the full set @xmath100 then @xmath32 is dominated by the space cell @xmath55 .",
    "the mere existence of the node guarantees that it contains at least one point , so we can conclude that @xmath32 is dominated .",
    "if on the other hand @xmath101 then all points in @xmath55 are dominated are hence removed .",
    "if the algorithm finds one of its child nodes empty after the recursion then it recovers a binary tree by replacing the current node with the remaining child .",
    "no action is required if both child nodes are empty since this implies @xmath102 , and the node will be removed further up in the tree .",
    "in contrast to the bi - objective case it is unclear how to balance the tree at low computational cost . this is not a severe problem for objective vectors drawn i.i.d .  from a fixed distribution .",
    "this situation is fulfilled in good enough approximation when performing many short optimization runs .",
    "however , for a single ( potentially long ) run of an optimizer we can expect a systematic shift from low - quality early objective vectors towards better and better solutions over time . hence most points proposed late during the run will tend to end up in the left child of a node , the split point of which was determined early on .",
    "we counter this effect by introducing a balancing mechanism as follows .",
    "if the quotient @xmath103 raises above a threshold @xmath104 or falls below @xmath105 then the smaller child node is removed , the larger one replaces its parent , and the points represented by the smaller node are inserted .",
    "although this process is computationally costly , it can pay off in the long run in case of highly unbalanced trees .",
    "in this section we analyze on the complexity of the bsp tree based archive algorithm .",
    "we start with the storage requirements . when storing @xmath25 non - dominated points , in the worst case there are @xmath25 distinct leaf nodes , and hence @xmath106 interior nodes in the tree , requiring @xmath51 memory in addition to the unavoidable requirement of @xmath107 for storing the non - dominated objective vectors .",
    "hence the added memory footprint due to the bsp tree is unproblematic . in our implementation",
    "the overhead of a tree node is 56 bytes on a 64bit system , which makes it feasible to store millions of points in ram .",
    "the analysis of the runtime complexity is more involved .",
    "since archiving small numbers of points is uncritical , we focus on the case of large  @xmath25 , which is well described by an average case amortized analysis . for the analysis we drop the rather heuristic balancing mechanism . for simplicity we set the bucket size to @xmath108 and assume a perfectly balanced tree of depth @xmath109 .",
    "although optimistic , this assumption is not too unrealistic : note that the depth of a random tree is typically of order @xmath110 .",
    "the strongest technical assumption we make for the analysis is that objective vectors are sampled i.i.d .  from a static distribution .",
    "let @xmath68 denote a probability distribution on @xmath14 so that for two random objective vectors @xmath111 the events @xmath112 and @xmath113 have probability zero .",
    "we consider a bsp archive constructed by inserting @xmath25 points sampled i.i.d .  from @xmath68 .",
    "then we are interested in bounding the expected runtime @xmath114 required for processing a candidate point @xmath115 .    for a node @xmath55 representing the space cell @xmath64",
    "we define its order w.r.t .",
    "the candidate point @xmath32 as @xmath116 .",
    "we call a node comparable to @xmath32 if its space cell contains at least one comparable point ( w.r.t.the pareto dominance relation ) .",
    "all incomparable cells are skipped by the algorithm , hence the runtime is proportional to the number of comparable nodes .",
    "a node is incomparable to @xmath32 if there exist @xmath117 and @xmath118 such that @xmath119 and @xmath120 .",
    "furthermore , cells dominated by @xmath32 ( @xmath90 for all @xmath78 ) do nt need to be visited , actually , encountering such a cell stops the algorithm immediately .",
    "similarly , nodes dominated by @xmath32 can be ignored in an amortized analysis since on average only one point can be removed per insertion , and the cost of a removal is as low as @xmath50 .",
    "hence all nodes of order @xmath5 can be ignored for the analysis .    in the following",
    "we denote the probability for a random node at depth @xmath121 below the root node ( the root has depth @xmath71 ) to have order @xmath122 with @xmath123 .",
    "we have @xmath124 and @xmath125 for @xmath126 .",
    "the following theorem provides a lower bound on the runtime in the best case , namely when each split of the bsp tree induces the same chance to yield an incomparable child node .",
    "[ theorem : lower ] assume that when traversing from root to leaf no two space splits are along the same objective .",
    "then we have @xmath127 .",
    "the prerequisite implies @xmath128 and hence @xmath129 . since objective vectors are sampled i.i.d . , the probability of the candidate point to be covered by the left or right sub - tree is @xmath130 at each node",
    "this corresponds to a @xmath130 chance to increment the order @xmath63 when descending an edge of the tree , hence @xmath63 follows a binomial distribution .",
    "we obtain @xmath131 for @xmath132 . for given @xmath63 , the chance of a node",
    "to be comparable to the candidate point is @xmath133 , since for this to happen all @xmath63 decisions ( descending left or right in the tree ) must coincide .",
    "hence among the @xmath134 nodes at depth @xmath121 an expected number of @xmath135 nodes is comparable to the candidate point .",
    "the statement follows by summing over all depths @xmath136 . @xmath137    under the milder ( and actually pessimistic ) assumption of random split objectives we obtain a sub - linear upper bound .",
    "[ theorem : upper ] assume that each node splits the space along an objective @xmath78 drawn uniformly at random from @xmath100 .",
    "then we have @xmath138 .    in this case",
    "@xmath139 is described by the following recursive formulas for @xmath140 : @xmath141\\end{aligned}\\ ] ] we obtain @xmath142 , hence only @xmath143 nodes are of order at most @xmath144 , and only a subset of these must be visited . since processing a leaf node requires @xmath34 operations in general , we arrive at @xmath138 .",
    "all three archives were implemented efficiently in c++ . here",
    "we investigate how fast the archives operate in practice , how their runtimes scale to large @xmath25 and @xmath5 , and how their practical performance relates to our analysis .",
    "a first series of tests was performed with sequences of objective vectors following controlled , analytic distributions .",
    "these tests allow us to clearly disentangle effects caused by different fractions of non - dominated points and non - stationarity due to improvement of solutions over time .",
    "processing time per objective vector for @xmath27 objectives ( top ) and @xmath145 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 .",
    ", title=\"fig:\",scaledwidth=50.0% ] processing time per objective vector for @xmath27 objectives ( top ) and @xmath145 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 .",
    ", title=\"fig:\",scaledwidth=50.0% ] +   processing time per objective vector for @xmath27 objectives ( top ) and @xmath145 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 . ,",
    "title=\"fig:\",scaledwidth=50.0% ] processing time per objective vector for @xmath27 objectives ( top ) and @xmath145 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 . , title=\"fig:\",scaledwidth=50.0% ] +      processing time per objective vector for @xmath151 objectives ( top ) and @xmath152 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 .",
    ", title=\"fig:\",scaledwidth=50.0% ] processing time per objective vector for @xmath151 objectives ( top ) and @xmath152 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 .",
    ", title=\"fig:\",scaledwidth=50.0% ] +   processing time per objective vector for @xmath151 objectives ( top ) and @xmath152 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 . ,",
    "title=\"fig:\",scaledwidth=50.0% ] processing time per objective vector for @xmath151 objectives ( top ) and @xmath152 objectives ( bottom ) , for a static distribution ( @xmath146 , left ) and solutions improving over time ( @xmath147 , right ) , for systematically varied numbers of overall points ( @xmath148 ) and non - dominated points ( @xmath55 ) in the range @xmath149 to @xmath150 . , title=\"fig:\",scaledwidth=50.0% ]    we constructed archives from sequences of @xmath153 dominated ( @xmath154 ) and @xmath55 non - dominated ( @xmath155 ) normally distributed objective vectors according to @xmath156 where @xmath157 denotes the identity matrix and @xmath158 is the vector of all ones .",
    "the distribution has unit variance in the subspace orthogonal to the @xmath159 vector .",
    "the parameter @xmath160 controls the systematic improvement of points over time . at position @xmath63 of the sequence",
    "a dominated point was sampled with probability @xmath161 , where @xmath162 and @xmath163 denote the number of remaining dominated and non - dominated points to be placed into the sequence .",
    "hence for @xmath164 there is a preference for observing more dominated points early on in the sequence , while for @xmath165 there is not .",
    "the bucket size  @xmath81 and the tree re - balancing threshold  @xmath104 are tuning parameters of the algorithm .",
    "we propose the settings @xmath166 and @xmath167 as default values since they gave robust results across problems with varying characteristics in preliminary experiments .",
    "the relatively large bucket @xmath81 size yields well balanced trees .",
    "therefore a high value of the threshold  @xmath104 is affordable , because re - balancing is rarely needed .",
    "figures [ figure : timings-1 ] and [ figure : timings-2 ] display the average processing times of the different archives over sequences with varying @xmath5 , @xmath148 , @xmath55 , and @xmath168 .",
    "it is no surprise that for @xmath27 the specialized bi - objective archive performs clearly best . for @xmath31",
    "the bsp tree is in all cases superior to the baseline .",
    "the vector archive is only competitive for @xmath169 , i.e. , as long as the number of non - dominated points in the archive remains small .",
    "unsurprisingly , this is also the domain where the systematic improvement of points over time has a significant effect on archive performance .",
    "the overall effect is similar for all archive types , and in comparison to the static case the bsp archive can even increase its advantage over the linear memory archive .",
    "empirical scaling w.r.t .",
    "@xmath25 ( left ) and @xmath5 ( right ) .",
    "the gray lines in the background of the log - log - plots indicate the exponents @xmath170 and @xmath171 of the hypothetical scaling laws @xmath172 and @xmath173 , respectively .",
    ", title=\"fig : \" ] empirical scaling w.r.t .",
    "@xmath25 ( left ) and @xmath5 ( right ) .",
    "the gray lines in the background of the log - log - plots indicate the exponents @xmath170 and @xmath171 of the hypothetical scaling laws @xmath172 and @xmath173 , respectively .",
    ", title=\"fig : \" ]    figure  [ figure : scaling ] ( left ) shows the empirical scaling of the archives for a setting close to the preconditions of the theoretical analysis : @xmath145 , @xmath174 , @xmath146 .",
    "the actual scaling is very close to the lower bound of order @xmath175 from theorem  [ theorem : lower ] .",
    "in contrast , the vector - based archive scales perfectly linear in  @xmath25 .",
    "figure  [ figure : scaling ] ( right ) investigates the scaling to large numbers of objectives .",
    "it plots the runtime per processing step for an archive consisting of @xmath176 non - dominated points .",
    "in contrast to theorem  [ theorem : lower ] , in practice the curve is of course not flat .",
    "the algorithm still scales gracefully to large numbers of objectives . for the range",
    "@xmath177 we observe sub - linear scaling . the baseline method ( surprisingly ) exhibits even slightly better scaling ( while taking 10 times more time in absolute terms ) .",
    "a second series of tests was performed with objective vectors generated by state - of - the - art moeas on established benchmark functions .",
    "we used two variants of the multi - objective covariance matrix adaptation evolution strategy ( mo - cma - es ) , namely with generational and with steady - state selection @xcite .",
    "we applied the implementations found in the shark library , version 3.1 @xcite .",
    "the population size was set to 100 , all parameters were left at their defaults .",
    "sequences of objective vectors were generated by running the optimizers on the scalable benchmark problems dtlz1 to dtlz4 @xcite , with 30 variables , 3 objectives , and a budget of 200,000 function evaluations .",
    "the results are summarized in table  [ table : emoas ] .    .",
    "[ table : emoas ] the table lists the number @xmath55 of non - dominated points at the end of the optimization run , the average runtimes ( in @xmath178 seconds ) for processing a single point with the bsp tree archive and the vector archive , as well as the speed - up factor of the bsp tree archive over the vector archive . [ cols=\"<,<,>,>,>,>\",options=\"header \" , ]     in all cases the bsp tree archive was significantly faster than the baseline .",
    "it outperformed the vector - based archive roughly by a factor of 10 .",
    "the exact speed - up correlates with the number of non - dominated points .",
    "this is in line with our analysis , as well with the results for analytically controlled distributions of objective vectors .",
    "the results indicate that the tree - based archive also works well for realistic sequences of objective vectors produced by moeas .",
    "it demonstrates its strengths in particular if the set of non - dominated points grows large .",
    "we have presented an algorithm for updating an archive of pareto optimal objective vectors processed iteratively in a sequence .",
    "the data structure is based on a k - d tree for binary space partitioning . this choice yields runtime sub - linear in the archive size  @xmath25 .",
    "the method is shown to perform well for medium to large scale archives , where updating performance matters most .",
    "the archive is applicable to problems with arbitrary number @xmath5 of objectives , including the many - objective case @xmath179 .",
    "overall , these properties make the proposed algorithm suitable for online processing of non - dominated sets , e.g. , in evolutionary multi - objective optimization .",
    "d.  papadias , y.  tao , g.  fu , and b.  seeger .",
    "an optimal and progressive algorithm for skyline queries . in _ proceedings of the 2003 acm",
    "sigmod international conference on management of data _ , pages 467478 .",
    "acm , 2003 ."
  ],
  "abstract_text": [
    "<S> maintaining an archive of all non - dominated points is a standard task in multi - objective optimization . </S>",
    "<S> sometimes it is sufficient to store all evaluated points and to obtain the non - dominated subset in a post - processing step . alternatively </S>",
    "<S> the non - dominated set can be updated on the fly . while keeping track of many non - dominated points efficiently </S>",
    "<S> is easy for two objectives , we propose an efficient algorithm based on a binary space partitioning ( bsp ) tree for the general case of three or more objectives . our analysis and our empirical results demonstrate the superiority of the method over the brute - force baseline method , as well as graceful scaling to large numbers of objectives .    </S>",
    "<S> * a fast incremental bsp tree archive + for non - dominated points * + tobias glasmachers + institute for neural computation , ruhr - university bochum , germany + ` tobias.glasmachers@ini.rub.de ` + note : a paper with identical content was submitted to emo2017 . </S>",
    "<S> +   + </S>"
  ]
}