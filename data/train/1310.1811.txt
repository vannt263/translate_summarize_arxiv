{
  "article_text": [
    "recognizing text in natural images is a challenging problem with many promising applications .",
    "natural attributes such as lighting , shadows , styles , fonts and backgrounds that affect the perception of textual information is the main culprit that shifts this problem away from document text recognition , and closer to a combination of object and handwriting recognition .",
    "the end - to - end text recognition problem can be decomposed into three natural sub - problems : text detection , character recognition and word recognition .",
    "the first problem is to identify text locations in a natural image .",
    "the second problem requires identifying characters in cropped image patches ; this is a classification problem with high confusion due to upper - case / lower - case and letter / number confusion .",
    "the third problem is a sequencing problem , given an image of a word , to output the most likely word corresponding to that image .",
    "these problems clearly overlap as character recognition is a sub - problem of word recognition , which itself is a sub - problem of text detection .",
    "the end - to - end problem presents technical challenges on multiple levels . on the character level ,",
    "the main challenge is to achieve high recognition accuracy . on the word level",
    ", the word recognizer needs to be accurate , fast , and scalable with lexicon size . on the end - to - end level , the system needs to balance precision , recall , complexity and speed . in our work",
    ", we aim for a highly accurate character recognizer , a fast , accurate and scalable word recognizer and for the end - to - end system , we aim for fast performance at query time , and high f - measure .    to achieve the goals specified above , we dissect the end - to - end recognition problem , exploring new solutions for all three subproblems .",
    "more specifically , we leverage a deep , convolutional variant of the recently introduced maxout networks which make heavy use of dropout to beat the state - of - the - art on the character recognition task with minimal preprocessing . also , inspired by the recent breakthroughs in voice recognition @xcite , we propose to treat the word recognition problem in a way similar to the phone - sequence recognition problem . more concretely ,",
    "we create a hybrid hmm / maxout architecture that is able to sequence words into their corresponding characters .",
    "the proposed model allows for simple integration of a lexicon s higher order n - grams , resulting in a method that is fast , accurate and highly tunable , while taking constant time relative to lexicon size .",
    "we then show how to integrate these parts in a novel end - to - end recognition system that achieves state - of - the - art f - measure on the icdar 2003 @xcite and svt @xcite datasets .",
    "due to the hierarchical dependency of the problem , where word recognition is a sub - module of text detection and character recognition is a sub - module of word recognition , we present the modules starting with character recognition in section 4 , proceeding on to word recognition in section 5 , and then joining the previous parts in the end - to - end system in section 6 , with a pipeline of the end - to - end system in figure 6 .",
    "the text recognition problem has been addressed in the literature on multiple levels : character recognition @xcite , word recognition @xcite and text detection @xcite .",
    "most previous works focused on a single stage of the pipeline , with few looking into the end - to - end systems , namely @xcite .",
    "the character recognition problem is a classification problem that is generally addressed with the use of strong classifiers such as convolutional neural nets ( cnns ) @xcite , deformable parts models @xcite or manually - engineered feature - extraction followed by a classifier @xcite .",
    "the word recognition problem is , much like phone recognition and handwriting recognition , a sequence recognition problem .",
    "previous works have addressed this problem using cnns @xcite , conditional random fields ( crfs ) @xcite and pictorial structures ( ps ) @xcite .",
    "most of the work in this area has relied on segmentation - free lexicon - dependent approaches .",
    "the use of the lexicons helps tackle the high confusion inherent in the text recognition problem .",
    "however , despite the argument for the validity of task - specific lexicon use in @xcite , it is clear that we ultimately wish to recognize text with a very general lexicon .",
    "to do so , we require word recognizers that scale well in the size of the lexicon .",
    "the works of @xcite are the only works we know of that show how their methods scale with lexicon size .",
    "the text detection problem is defined such that , given a natural image , the goal is to output bounding boxes on all words in the image .",
    "abstractly speaking , the problem is an instance of the object detection problem , followed by segmenting text regions into their constituent words .",
    "previous works investigated different approaches for text detection , typically trading off precision , recall , training time and time consumed for manually designing features .",
    "pre - trained cnns @xcite applied in a multi - scale sliding window fashion are highly accurate but very time consuming .",
    "viola - jones style classifiers remedy the slowness in cnns , but have long training times and require manually - engineered features @xcite .",
    "alternative methods that cleverly exploit the nature of text such as maximally stable extremal regions ( msers ) @xcite and stroke width transform @xcite generally have lower accuracy but are fast to compute .",
    "such methods were used successfully to detect text as in @xcite .",
    "this section provides technical background on some of the techniques used in the proposed system .",
    "convolutional neural networks ( cnns ) @xcite are discriminativly trained neural networks that alternate convolution layers and pooling layers , with the last layer being usually a softmax or rbf layer . in a convolution layer , an input is convolved with multiple learned filters leading to multiple maps which then are pooled together through a pooling scheme . combined with regularization and pretraining techniques ,",
    "these neural nets achieve state - of - the - art results on many datasets @xcite .",
    "dropout @xcite is a simple and efficient technique that can be used to reduce overfitting in neural networks .",
    "the main idea of dropout is to stochasticly omit some of the units from the network during learning .",
    "intuitively , dropout adds robustness to the network by introducing noise on all levels of the architecture .",
    "another way to view dropout is as a way to do model averaging over exponentially - many models with shared parameters .",
    "a maxout network @xcite is a multi - layer perceptron that makes heavy use of dropout to regularize the neural net , thereby reducing overfitting .",
    "it also uses a @xmath0 activation function that produces a sparse gradient .",
    "specifically , in these networks , for an input @xmath1 , every hidden layer implements the function : @xmath2 where @xmath3 @xmath4    maxout networks have produced state - of - the - art results on benchmark datasets without any pre - training @xcite .",
    "hmms have long been among the main tools used for sequence modelling in voice recognition @xcite and hand - writing recognition @xcite .",
    "hybrid models @xcite extend hmms with a simple idea , that is , instead of using gaussian mixture models ( gmms ) to model the hmms observation model , hybrid models use bayes rule and implicitly model the observation model using a probabilistic classifier . concretely , let @xmath5 be a sequence of observations and let @xmath6 be a state sequence , the purpose of the hmm is to produce @xmath7 . in a standard setting , to train an hmm , we require an observation model @xmath8 where @xmath9 is an observation and @xmath10 is an hmm state . in the hybrid model , we approximate the observation model through bayes rule with a probabilistic classifier that computes the posterior @xmath11 distribution on hmm states @xmath10 given an input @xmath9 . concretely : @xmath12    with @xmath13 assumed to be equal for all observations .",
    "such hybrid models are usually trained with the embedded viterbi algorithm @xcite to maximize the likelihood of the data . in other variants of the model , hybrid models",
    "are discriminatively trained to optimize segmentation accuracy directly  @xcite .",
    "combined with deep architectures , these models have increased accuracies on challenging sequencing tasks primarily in voice - recognition @xcite .",
    "the character recognition problem involves building a character recognizer that when presented with a character image , produces a probability distribution over all characters . in our case , the recognizer classifies characters into 62 classes ( 26 upper - case , 26 lower - case and 10 digits ) .",
    "the dataset we use for this task is the icdar 2003 character recognition dataset @xcite which consists of 6114 training samples and 5379 test samples after removing all non - alphanumeric characters as in @xcite .",
    "we augment the training dataset with 75,495 character images from the chars74k english dataset @xcite and 50,000 synthetic characters generated by @xcite making the total size of the training set 131,609 tightly cropped character images .",
    "the architecture we use for this task is a five - layer convolutional maxout network with the first three layers being convolution - pooling maxout layers , the fourth a maxout layer and finally a softmax layer on top .",
    "the first three layers have respectively 48 , 128 , 128 filters of sizes 8-by-8 for the first two and 5-by-5 for the third , pooling over regions of sizes 4-by-4 , 4-by-4 and 2-by-2 respectively , with 2 linear pieces per maxout unit and a 2-by-2 stride .",
    "the 4th layer has 400 units and 5 linear pieces per maxout unit , fully connected with the softmax output layer .",
    "we train the proposed network on 32-by-32 grey - scale character image patches with a simple preprocessing stage of subtracting the mean of every patch and dividing by its standard deviation + @xmath14 .",
    "similar to @xcite , we train this network using stochastic gradient descent with momentum and dropout to maximize @xmath15 .",
    "training was done on gpus using theano @xcite and pylearn @xcite .",
    "the resulting character recognizer achieves state - of - the - art recognition rates on the icdar 2003 character test set with an accuracy of 85.5% on the 62-way case - sensitive benchmark and 89.9% on the case - insensitive 36-way benchmark .",
    "when we use the maxout network as a feature extractor and feed the features from the penultimate layer into an svm with an rbf kernel , the recognition accuracy increases to 86% on the 62-way benchmark while it remains roughly the same ( 89.8% ) on the 36-way benchmark .",
    "table 1 compares our results to other works on this dataset .",
    "overall , the performance of the maxout networks is slightly superior to that of the cnns used in previous approaches .    as a side note",
    ", we found that different forms of binarization ( otsu , random walkers , grabcuts ) and preprocessing methods , such as zca as used in @xcite , do not enhance the test accuracy and in some cases , decrease it .",
    ".character recognition accuracy on icdar 2003 test set .",
    "all methods use the same augmented training dataset . [",
    "cols=\"^,^,^ \" , ]      +",
    "in this section , we show how the previous parts can be integrated into a full end - to - end text recognition system .",
    "the main issue , unaddressed by the previous sections , is to localize text patches in natural images .      to extract text locations from an image , we start by getting possible text candidates using maximally stable extremal regions ( msers ) .",
    "msers are defined to be regions in the image that are either maximas or minimas of image intensities with respect to their surroundings . while being highly imprecise text detectors , they can be computed very quickly @xcite .",
    "the use of msers allows us to sidestep the enormous time penalty incurred by applying a costly recognizer on multiple scales of the image as in @xcite , thereby allowing our system to become much more efficient .",
    "since msers would ideally correspond to character regions , we form candidate line boxes by clustering the character candidates with dbscan @xcite using multiple distances to obtain candidate line - level bounding boxes .",
    "after we obtain the line - level bounding boxes , we segment these lines using the _ line - to - word hybrid hmm / maxout _ trained to segment lines to words from the icdar 2003 scene training set .",
    "we then add words by gradually introducing gaps from the segmentation one at a time in descending size order .",
    "after this , we threshold the resulting word bounding boxes using the _ word detection maxout _",
    ", a four - layer convolutional maxout network with the same architecture as the one used in sec.5.1 on word / non - text images extracted from icdar 2003 scene training dataset .",
    "we also threshold words on the @xmath16 score resulting from the word recognition module and the edit - distance value .",
    "we follow this pipeline by doing a non - max suppression ( nms ) @xcite on word boxes that overlap by 30% of the area of their bounding box according to the visual cost @xmath16 from the word recognition module .",
    "we tested the above system on both the icdar 2003 and svt end - to - end scene text - recognition test sets .",
    "each of the datasets contain 249 scene images .",
    "more specifically , for the icdar 2003 dataset , we conduct tests under five scenarios , where for the first three , the lexicons consist if \\{5,20,50 } distractor words per image in addition to the ground truth words for that image , in the fourth scenario all the test words are included in the lexicon and in the fifth scenario , we use the same large lexicon we used to test the word recognition module ( sec.5.4 ) .",
    "we label these scenarios i-5 , i-20 , i-50 , i - full and i - large respectively .",
    "the lexicons were provided by the authors of @xcite .",
    "as for the svt dataset , we conduct the tests using the lexicons provided with the dataset .",
    "all tests were done with the text - recognition module in the edit - distance mode .",
    "we test the end - to - end system using the standard precision / recall metrics under the benchmarks specified in @xcite , where a prediction is considered a hit when the area of the overlap between the predicted box and the target box is greater than 50% of the bounding box area and the predicted text matches exactly .",
    "table 3 compares our results to other results in the field . despite our use of a simple method with low accuracy like msers to extract possible text regions ,",
    "our end - to - end system is able to outperform previous state - of - the - art end - to - end systems and produce reasonable results for large lexicons .",
    "figure 8 shows the precision / recall curves for all the tasks on the icdar 2003 dataset and figure 7 shows a few sample outputs from our system .",
    "in this section , we discuss possible ways to increase the accuracy of both the word recognition module and the end - to - end system , and possible ways to make the entire system operate under real - time constraints .",
    "for the word recognition module , using learned edit - distances @xcite would help boost the module s accuracy . beyond that , most of the loss in accuracy comes from segmentations created by the hybrid hmm model . designing a neural net to factor in context information into the hybrid hmm while computing posterior probabilities should help reduce that loss in accuracy .    to increase the f - measures on the end - to - end system",
    ", we should seek to boost recall . as pointed out in @xcite msers do not offer high recall for character location extraction .",
    "the alternative of using a time - consuming but highly accurate classifier as in @xcite is not practical to make the end - to - end system work in real - time . in our opinion",
    ", a promising solution would be to develop a viola - jones - style cascade @xcite coupled with feature - learning .",
    "such an approach could offer a fast , accurate , easy to train and feature - engineering - free text detector that would increase recall .",
    "in this work , we presented a novel end - to - end text recognition system .",
    "we proposed novel solutions to each subproblem in the end - to - end system .",
    "specifically , we leveraged convolutional maxout networks to beat the state - of - the - art on character recognition .",
    "we showed how to use the character recognizer in a word recognizer that is fast , tunable , highly accurate , and scales elegantly with lexicon size .",
    "we then constructed an end - to - end text recognition system using the previous modules in addition to other , relatively simple constructs .",
    "the proposed system outperforms previous works on end - to - end text recognition tasks on standard challenging benchmarks .",
    "we would like to thank yoshua bengio , aaron courville and ian goodfellow for their insightful comments and discussions .",
    "we would also like to thank paul kry and sheldon andrews for providing the gpus .",
    "members of the rl lab for helpful discussions .",
    "financial support for this research was provided by the nserc discovery grant ."
  ],
  "abstract_text": [
    "<S> the problem of detecting and recognizing text in natural scenes has proved to be more challenging than its counterpart in documents , with most of the previous work focusing on a single part of the problem . in this work , </S>",
    "<S> we propose new solutions to the character and word recognition problems and then show how to combine these solutions in an end - to - end text - recognition system . </S>",
    "<S> we do so by leveraging the recently introduced maxout networks along with hybrid hmm models that have proven useful for voice recognition . using these elements </S>",
    "<S> , we build a tunable and highly accurate recognition system that beats state - of - the - art results on all the sub - problems for both the icdar 2003 and svt benchmark datasets . </S>"
  ]
}