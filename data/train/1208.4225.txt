{
  "article_text": [
    "in many computational problems in the field of combinatorial optimization the input partly consists of a set of integers .",
    "since integers are naturally represented in binary , they can be exponential in the number of bits of the input instance .",
    "for many problems this is not an issue , particularly for problems admitting a strongly polynomial - time algorithm ( recall that the running time of such an algorithm does not depend on the size of the integers ) .",
    "however , ( exponentially ) large numbers present a major issue for other problems .",
    "for example , in weakly np - complete problems the large integers are even the sole source of hardness .",
    "strongly np - complete problems are often studied in their weighted variants , and often such weighted variants are even considerably harder than their unweighted counterpart . in this paper , we present a novel method to reduce the challenges posed by ( exponentially ) large numbers in the input of np - complete problems .",
    "we first give a description of the type of problems that we consider .",
    "all of the studied problems can be stated according to the following generic pattern .",
    "first , there is a universe @xmath0 ( for example the set of vertices or edges of a graph ) and a weight function @xmath2 .",
    "second , there is a succinctly - represented set family @xmath8 .",
    "we will assume that membership of the set @xmath9 can be determined in polynomial time by an oracle given as part of the input . finally , we are given two non - negative integers @xmath10 such that @xmath3 .",
    "then the problem is to decide whether there exists an @xmath4 such that @xmath11 $ ] , where @xmath12 .",
    "we call this a _ ranged problem_. if a problem additionally specifies that @xmath6 , this is an _",
    "exact problem_. we will be mainly interested in the case where @xmath13 is exponential , or even super - exponential , in @xmath7 .",
    "the main question that we consider and answer in this paper is whether the computational complexity of a ranged problem is equal to that of its corresponding exact problem .",
    "this question is motivated by the recent availability of powerful tools for exact problems , such as hashing ( see e.g.  @xcite ) and interpolation ( see e.g.  @xcite ) , that do not seem directly applicable to ranged problems .",
    "hence we may wonder whether there is a difference between ranged and exact problems from the point of view of computational complexity .",
    "certain cases of this main question are particularly intriguing .",
    "for example , the arguably most fundamental pair of an exact and its corresponding ranged problem is subset sumand knapsackrespectively .",
    "recall that in subset sum , we are given a set @xmath14 , a weight function @xmath15 , and an integer @xmath16 , and we are asked to decide whether there exists an @xmath17 such that @xmath18 . in the knapsackproblem",
    "we are additionally given a weight function @xmath19 and integer @xmath20 , and we are asked to decide whether there exists a set @xmath21 with @xmath22 among all @xmath17 for which @xmath23 . from the perspective of exact exponential algorithms ( see e.g.  @xcite for an introduction ) , both problems are known to be solvable in @xmath24 time and @xmath25 space @xcite ( see also ( * ? ? ?",
    "* chapter 9 ) ) , while the best polynomial - space algorithms are still the trivial brute - force @xmath26-time algorithms .",
    "it is an interesting question whether either of these problems can be solved in @xmath27 time and polynomial space",
    ". also , are the problems related in the sense that an improved algorithm for subset sumwould imply an improved algorithm for knapsack ?    another interesting perspective is that of _ sparse instances_. it is known that the subset sumand knapsackproblems can be solved in pseudo - polynomial time and space using a dynamic programming ( dp ) algorithm  @xcite .",
    "an intensively studied case of dp is where the dp - table is guaranteed to be sparse . in subset sum",
    ", for example , this means that the number of distinct sums of the subsets of the given integers is small . using memorization",
    ", this type of sparseness can be easily exploited if we are allowed to use exponential space . very recently ,",
    "polynomial - space equivalents of memorization were given in  @xcite ( see also ( * ? ? ?",
    "* chapter 6 ) ) .",
    "the first step in this approach uses hashing , and the second step uses interpolation .",
    "it is unclear whether the approach can be extended to knapsack .",
    "one issue is that a good hash function does not hash the target interval to a single interval .",
    "furthermore , interpolation does not apply directly to the ranged case , and the typical solution of adding a few `` slack weights '' to reduce it to the exact case destroys the sparseness property .",
    "we note that different measures of sparseness for knapsackhave been considered previously .",
    "nemhauser and llmann  @xcite considered the case when the number of pareto - optimal solutions is small .",
    "a solution @xmath21 for knapsackis pareto - optimal if there is no @xmath28 with @xmath29 and @xmath30 , or with @xmath31 and @xmath32 .",
    "note that the number of pareto - optimal solutions is always at most the number of distinct sums in the instance .",
    "the algorithm of nemhauser and llmann uses @xmath33 time and @xmath34 space to enumerate all pareto - optimal solutions , where @xmath35 is the number of pareto - optimal solutions over the first @xmath36 items .",
    "note that the space requirement is polynomial in the sparseness , whereas the space requirement of the algorithm of  @xcite is polynomial in the size of the instance . in the framework of smoothed analysis ,",
    "however , the number of pareto - optimal solutions for knapsackis polynomial in the instance size  @xcite .    in the field of kernelization",
    "( see  @xcite for a survey ) , the subset sumproblem is known to admit a so - called _ polynomial randomized kernel _ when parameterized by the number of integers  @xcite .",
    "can a similar kernel be obtained for the knapsackproblem ? again , since  @xcite heavily relies on hashing , it does not seem to be applicable .",
    "similar questions can be asked for weighted variants of several fundamental problems in the field of kernelization , such as the weighted variant of vertex cover .",
    "is there a ( randomized turing ) kernel for this problem parameterized by @xmath7 , i.e.  can we reduce the weights to be at most @xmath37 ?    _ our results_in this paper , we show that a ranged problem is equally hard as its corresponding exact problem , modulo a factor @xmath38 in the running time .",
    "this implies a positive answer on all of the above questions .",
    "this result uses a generic and clean method to transform a ranged problem into instances of its corresponding exact problem .",
    "the method covers the interval @xmath39 $ ] with a small number of `` fuzzy intervals '' such that an integer is in @xmath39 $ ] if and only if it is in one of the fuzzy intervals .",
    "it relies on a scaling technique that is more commonly found in approximation algorithms ; in fact , the prime example of its use is in the fptas for knapsack  @xcite .    the paper is organized as follows . in section  [ sec : prelim ] , we introduce the required notation and definitions . in section  [ sec : maintool ] , we state and prove our main technical contribution .",
    "sections  [ sec : exactalg ] and  [ sec : kernel ] are dedicated to corollaries of the main theorem in the fields of exact exponential algorithms and kernelization .",
    "finally , we give a conclusion , further remarks , and open questions in section  [ sec : conclusion ] .",
    "throughout , we use the @xmath40 notation that suppresses any factor polynomial in the input size of the given problem instance .",
    "we use greek symbols such as @xmath41 to denote weight functions , i.e.  for a universe @xmath0 and an integer @xmath13 , @xmath2 . in this context , we shorthand @xmath12 for any @xmath17 . for two",
    "integers @xmath42 , the set of integers @xmath43 is denoted by @xmath39 $ ] .    a _ kernelization algorithm _ ( or _ kernel _ ) for a parameterized problem @xmath44 ( that is , a problem together with an input measure @xmath45 ) computes in polynomial time , given an instance @xmath46 of @xmath44 , a new instance @xmath47 of @xmath44 such that @xmath48 if and only if @xmath49 , and @xmath50 for some computable function @xmath51 .",
    "the instance @xmath47 is called a _ kernel _ of @xmath44 , and it is called a _ polynomial kernel _ if @xmath51 is a polynomial . not every problem admits a polynomial kernel , or the polynomial hierarchy collapses to the third level  @xcite .",
    "we refer to  @xcite for a recent overview .",
    "a generalization of the notion of a kernel is a _",
    "turing kernel_. here the requirement that given a kernel yields an equivalent instance is relaxed . instead",
    ", a polynomial number of instances with the same size restrictions as before may be produced .",
    "moreover , there should be a polynomial - time algorithm that , given which of the produced instances are a yes - instance , decides whether the original instance is a yes - instance .",
    "the special case where the algorithm returns the or of the produced instances is called an or - kernel or a many - to - one kernel @xcite . generalizing these notions further , we use the adjective `` randomized '' to indicate that the polynomial - time algorithm computing the final answer may have a constant one - sided error probability .",
    "interestingly , the results of  @xcite even apply to the randomized variant of the original kernel definition , but not to turing kernels .",
    "given a graph @xmath52 , a subset @xmath17 is a _ vertex cover _ if @xmath53 or @xmath54 for every @xmath55 , and it is a _ dominating set _ if @xmath53 or @xmath55 for some @xmath54 for every @xmath56 . in the weighted vertex coverand dominating setproblems , we are given a graph on vertex set @xmath0 together with a weight function @xmath57 and an integer @xmath58 , and are asked to decide whether there is a vertex cover or dominating set @xmath17 , respectively , such that @xmath59 .",
    "a _ hamiltonian cycle _ is a subset @xmath60 such that the graph @xmath61 is a cycle . in the traveling salesmanproblem",
    "we are given a graph on edge set @xmath0 together with a weight function @xmath57 and an integer @xmath58 , and are asked to decide whether there exists a hamiltonian cycle @xmath17 such that @xmath59 .",
    "in this section , we give the main technical contribution of the paper : we transform a ranged problem into a small number of exact problems . the naive way to obtain such a transformation",
    "would be to return a new instance for each @xmath62 $ ] , thus yielding @xmath63 problems .",
    "however , as @xmath64 can be exponential in the size of the input , this procedure is clearly not efficient .",
    "instead , theorem  [ thm : shrinkint ] develops a new family of @xmath65 weight functions .",
    "we want to stress that the main conceptual consequence of theorem  [ thm : shrinkint ] is that , modulo a small polynomial factor , weighted subset - selection problems that aim to find a subset of given exact weight are equally hard as those that aim to find a subset with weight in a given interval .",
    "[ thm : shrinkint ] let @xmath0 be a set of cardinality @xmath66 , let @xmath67 be a weight function , and let @xmath68 be non - negative integers with @xmath69 .",
    "then there is a polynomial - time algorithm that returns a set of pairs @xmath70 with @xmath71 and integers @xmath72 such that    1 .",
    "@xmath73 is at most @xmath74 , and 2 .",
    "for every set @xmath17 it holds that @xmath75 $ ] if and only if there exist an index @xmath36 such that @xmath76 .    the theorem is implemented in algorithm  [ alg : shrink ] .",
    "@xmath77 @xmath78 .",
    "@xmath80 . for every @xmath81 ,",
    "set @xmath82 .",
    "@xmath85 .",
    "let @xmath86 denote the maximum number of pairs that @xmath87 returns .",
    "we claim that @xmath86 is at most @xmath88 .",
    "the cases when either @xmath89 or @xmath90 is odd can only happen twice in a row before either case one or four occurs .",
    "observe that for the first case our claim is clearly true , and that for the last case we obtain the bound @xmath91 , which clearly meets our claim since @xmath92 .",
    "this settles ( c1 ) and the claim concerning the running time .",
    "we prove ( c2 ) by induction . for the thirst",
    "three cases , ( c2 ) clearly holds , so let us directly proceed to the last case . for the forward direction , assume that @xmath75 $ ] . if @xmath93 \\cup [ { u}-2n , { u}]$ ] , then a pair fulfilling ( c2 ) is in @xmath94 .",
    "so assume that @xmath95 $ ] .",
    "then a pair fulfilling ( c2 ) will be added in the recursive step by the induction hypothesis , because @xmath96 $ ] since @xmath97 for the reverse direction , assume that there is a pair @xmath98 such that @xmath99 .",
    "if the pair is from @xmath94 , then @xmath75 $ ] .",
    "so assume that it is added in the recursive step . then by the induction hypothesis , @xmath96 $ ] , and @xmath11 $ ] by  .",
    "in this section , we demonstrate the applicability of theorem  [ thm : shrinkint ] to exact exponential algorithms .",
    "first , we consider the relation between the computational complexity of knapsackand subset sum .",
    "it is trivial that any algorithm for knapsackcan be used for subset sum : given an instance @xmath100 of subset sum , we can define @xmath101 and @xmath102 for every @xmath81 .",
    "then the instance of subset sumis a yes - instance if and only if the constructed instance of knapsackis a yes - instance .",
    "this can be decided by the assumed algorithm for knapsack .",
    "we prove the converse relation below by applying theorem  [ thm : shrinkint ] .",
    "[ thm : sssknp ] if there exists an algorithm that decides the subset sumproblem in @xmath103 time and @xmath104 space , then there exists an algorithm that decides the knapsackproblem in @xmath103 time and @xmath104 space .",
    "consider a knapsackinstance , consisting of a universe @xmath14 , weight functions @xmath105 , and integers @xmath106 .",
    "now we apply theorem  [ thm : shrinkint ] on both weight functions to obtain two sets @xmath107 . by considering the elements of @xmath108 as quadruples , we obtain a set @xmath109 of at most @xmath110 quadruples @xmath111 such that for every @xmath17 it holds that @xmath112 $ ] and @xmath113 $ ] if and only if there exists an @xmath36 such that @xmath114 and @xmath99 .",
    "it remains to show that , for every quadruple @xmath115 , we can determine whether there exists an @xmath17 such that @xmath114 and @xmath116 . to do this ,",
    "we create an instance of subset sumby concatenating the integer values .",
    "specifically , given a quadruple @xmath115 , define @xmath117 it is easy to see that , since @xmath118 , @xmath119 if and only if @xmath114 and @xmath116 .",
    "then the assumed algorithm for subset sumcan be used to decide for every quadruple @xmath120 whether there exists @xmath17 such that @xmath119 .",
    "this in turn enables us to decide the knapsackinstance .",
    "the bound on the time and space complexity follows immediately from the fact that @xmath121 is @xmath122 , which is polynomial in the size of the instance .    as an easy corollary",
    ", we observe that we can apply binary search to even deal with the maximization variant of knapsack .",
    "there exists an algorithm that decides the subset sumproblem in @xmath103 time and @xmath104 space if and only if there exists an algorithm that solves the maximum knapsackproblem in @xmath103 time and @xmath104 space .",
    "we can use the ideas in the proof of theorem  [ thm : sssknp ] to give another result on knapsack . to this end , we assume that the given instance of knapsackor subset sumis sparse , that is , the number of distinct sums in the instance is small .",
    "we recall a recent result of kaski et al .",
    "@xcite .",
    "[ thm : kaski ] there is an algorithm that decides an instance @xmath123 of subset sumin @xmath124 expected time and @xmath125 space , where @xmath126 .",
    "using theorem  [ thm : shrinkint ] and the ideas of theorem  [ thm : sssknp ] , we can prove the following .",
    "[ thm : sparse ] there is an algorithm that decides an instance @xmath127 of knapsackin @xmath124 expected time and @xmath125 space , where @xmath128 .    to prove theorem  [ thm : sparse ] , we require the following auxiliary lemma .    [",
    "lem : sums ] let @xmath0 be a set of @xmath66 elements , let @xmath129 be weight functions , let @xmath130 be an integer , and let @xmath131 and @xmath132 for every @xmath81",
    ". then @xmath133    for any pair of integers @xmath134 , consider the set @xmath135 .",
    "for each @xmath136 , we have that @xmath137 and @xmath138 .",
    "therefore , @xmath139 , and the lemma follows .",
    "we first apply the same construction as in the proof of theorem  [ thm : sssknp ] to obtain pairs @xmath140 .",
    "we then apply the algorithm of theorem  [ thm : kaski ] on all of these pairs and return yes if the algorithm finds an index @xmath36 and a set @xmath17 such that @xmath119 .",
    "it remains to prove that this introduces at most a polynomial overhead .",
    "since the number of pairs is bounded by a polynomial in the input length , it suffices to show that for every @xmath36 , the quantity @xmath141 is at most @xmath124 .",
    "observe that new weight functions are created in two places .",
    "first when theorem  [ thm : shrinkint ] is invoked : note that in algorithm  [ alg : shrink ] , all created weight functions are effectively obtained by halving the weights @xmath142 times and rounding down , which is equivalent to truncating the bitstring or dividing by @xmath143 and rounding down .",
    "hence , for all created weight functions @xmath144 , we have that @xmath145 for every @xmath36 by lemma  [ lem : sums ] .",
    "the second place is when @xmath146 is defined by concatenating the integers : then @xmath147 .",
    "hence the overhead is at most polynomial .",
    "in this section we show that theorem  [ thm : shrinkint ] can be used in combination with a known kernelization technique to reduce the number of bits needed to represent the weights of weighted minimization problems to an amount that is polynomial in the number of bits needed to represent the remainder of the input instance .",
    "[ thm : kernel ] the weighted variants of the vertex coverand dominating setproblems , traveling salesman , and knapsackall admit polynomial randomized turing kernels when parameterized by @xmath7 .",
    "we need the following lemma from harnik and naor  @xcite , which uses randomization to reduce the weights .",
    "[ lem : harniknaor ] let @xmath0 be a set of size @xmath66 . there exists a polynomial - time algorithm that , given @xmath67 , an integer @xmath58 , and a real @xmath148 , returns @xmath149 and integers @xmath150 where @xmath151 such that for every set family @xmath8 :    1 .   if there is an @xmath4 such that @xmath152 , then there exist @xmath36 such that @xmath153 , 2 .   if there is no @xmath4 such that @xmath152 then @xmath154 \\leq \\mathcal{o}(\\epsilon).\\ ] ]    we give the proof of the lemma in the appendix for completeness .",
    "it relies on the fact that in every interval of length @xmath155 the number of primes is roughly @xmath156 and that a random prime can be constructed in time polylogarithmic in the upper bound of the interval .    in all problems mentioned in the statement of theorem  [ thm : kernel ] ,",
    "there is a set family @xmath8 and we are asked whether there exists an @xmath4 such that either @xmath157 $ ] or @xmath158 $ ] ( depending on the problem ) .",
    "note that we can assume that @xmath159 ; otherwise the input is of size at least @xmath160 and we can use a trivial brute - force algorithm to solve the instance and reduce it to an equivalent instance of constant size .",
    "now we use theorem  [ thm : shrinkint ] to obtain a set @xmath109 of @xmath161 pairs @xmath162 and reduce the original problem to detecting whether there exists a pair @xmath98 and @xmath4 such that @xmath99 . to reduce the latter problem further , we apply the algorithm of lemma  [ lem : harniknaor ] , setting @xmath163 for some small value of @xmath164 . hence , for every @xmath162 , we obtain a weight function @xmath165 and @xmath66 integers @xmath166 such that if there exists an @xmath4 with @xmath99 , then there exists a @xmath167 such that @xmath168 for some @xmath167 and otherwise   holds .",
    "hence , this procedure generates @xmath169 pairs such that @xmath170 if there is @xmath4 with @xmath157 $ ] , a pair @xmath171 with @xmath168 is generated @xmath172 if there is no @xmath4 with @xmath157 $ ] : @xmath173 \\leq \\ell \\cdot   \\epsilon = { \\mathcal{o}}(\\epsilon').\\ ] ]    now we have reduced the original decision problem to a problem that is clearly in np : indeed , we can obtain the correct @xmath17 in non - deterministic polynomial time and verify whether it satisfies @xmath4 ( that is , is it a vertex cover , dominating set , ... ) and @xmath174 .",
    "then , since the original problem ( vertex cover , dominating set , ... ) is np - complete , we can reduce the problem to instances of the original problem with a karp - reduction .",
    "hence we have reduced one problem instance to many problem instances such that :    * if the original instance is a yes - instance , then one of the created instances is also a yes - instance ; * if the original instance is a no - instance , then with constant probability all created instances are no - instances .",
    "thus it remains to show that the number and the description lengths of the created instances are bounded by a polynomial in the original input size . to see that this is the case , first note that after applying lemma  [ lem : harniknaor ] we have @xmath169 pairs of weight functions bounded by @xmath175 .",
    "since we assumed that @xmath176 , these weight functions are represented by polynomially many bits .",
    "then , the theorem follows from the fact that a karp - reduction increases the size of a problem by at most a polynomial factor .",
    "we presented a generic and simple method to convert ranged problems into exact problems . while this result is already interesting by itself",
    "given its generality , we also gave a number of corollaries that followed by combining our method with techniques for exact problems already available from previous work .",
    "it is worth emphasizing the generality of our results in section  [ sec : maintool ] and section  [ sec : exactalg ] .",
    "for example , in the context of exact exponential algorithms , traveling salesmanseems to be significantly harder than its unweighted version , hamiltonian cycle .",
    "recently , the latter was shown to be solvable in @xmath177 time and polynomial space  @xcite , whereas the best algorithm for traveling salesmanthat is insensitive to large weights uses @xmath26 and space . by combining the hashing idea of  @xcite with our method , it is for example possible to obtain a polynomial - space algorithm for traveling salesmanthat runs in @xmath178 time , where @xmath179 .",
    "* can we get a `` classical''(i.e .",
    "non - turing or many - to - one ) polynomial kernel for the considered parameterized version of weighted vertex cover ? * further , significant reduction of the weights in polynomial time seems hard ( for example , it would imply an improved pseudo - polynomial algorithm for subset sum ) , but is it possible in pseudo - polynomial time for example for traveling salesman ?",
    "* when is minimizing / maximizing as hard as the general range problem ?",
    "* can we modify theorem  [ thm : shrinkint ] to make it counting - preserving ?",
    "more precisely , can we obtain a variant of the theorem with a third condition @xmath180 saying that for every @xmath17 there is at most one @xmath36 such that @xmath181 ?"
  ],
  "abstract_text": [
    "<S> many combinatorial problems involving weights can be formulated as a so - called _ ranged problem_. that is , their input consists of a universe @xmath0 , a ( succinctly - represented ) set family @xmath1 , a weight function @xmath2 , and integers @xmath3 . </S>",
    "<S> then the problem is to decide whether there is an @xmath4 such that @xmath5 . </S>",
    "<S> well - known examples of such problems include knapsack , subset sum , maximum matching , and traveling salesman . in this paper , we develop a generic method to transform a ranged problem into an _ exact problem _ </S>",
    "<S> ( i.e.  a ranged problem for which @xmath6 ) . </S>",
    "<S> we show that our method has several intriguing applications in exact exponential algorithms and parameterized complexity , namely :    * in exact exponential algorithms , we present new insight into whether subset sumand knapsackhave efficient algorithms in both time and space . </S>",
    "<S> in particular , we show that the time and space complexity of subset sumand knapsackare equivalent up to a small polynomial factor in the input size . </S>",
    "<S> we also give an algorithm that solves sparse instances of knapsackefficiently in terms of space and time . * in parameterized complexity , </S>",
    "<S> we present the first kernelization results on weighted variants of several well - known problems . </S>",
    "<S> in particular , we show that weighted variants of vertex coverand dominating set , traveling salesman , and knapsackall admit polynomial randomized turing kernels when parameterized by @xmath7 .    </S>",
    "<S> curiously , our method relies on a technique more commonly found in approximation algorithms . </S>"
  ]
}