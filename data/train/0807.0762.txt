{
  "article_text": [
    "the basic problem in numerical probability is to _ optimize _ some way or another the computation by a monte carlo simulation of a real quantity @xmath0 known by a probabilistic representation @xmath1\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}\\ ] ] where @xmath2 is a random vector having values in a banach space @xmath3 and @xmath4 is a borel function ( and @xmath5 is square integrable ) .",
    "the space @xmath3 is @xmath6 but can also be a functional space of paths of a process @xmath7}$ ] .",
    "however , in this introduction section , we will first focus on the finite dimensional case @xmath8 .",
    "assume that @xmath9 has an absolutely continuous distribution @xmath10 ( @xmath11 denotes the lebesgue measure on @xmath12 ) and that @xmath13 with @xmath14 ( otherwise the expectation is clearly @xmath15 and the problem is meaningless ) .",
    "furthermore we assume that the probability density @xmath16 is _ everywhere positive _ on @xmath6 .",
    "the paradigm of importance sampling applied to a parametrized family of distributions is the following : consider the family of absolutely continuous probability distributions @xmath17 , @xmath18 , such that @xmath19 , @xmath20-@xmath21 .",
    "one may assume without loss of generality that @xmath22 is an open non empty connected subset of @xmath23 containing @xmath15 so that @xmath24 .",
    "in fact we will assume throughout the paper that @xmath25 .",
    "then for any @xmath6-valued random variable @xmath26 with distribution @xmath27 , we have @xmath28\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f({x^{(\\theta)}})\\frac{p({x^{(\\theta)}})}{p_\\theta({x^{(\\theta ) } } ) } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\ ] ]    among all these random variables having the same expectation @xmath29\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] , the one with the lowest variance is the one with the lowest quadratic norm : minimizing the variance amounts to finding the parameter @xmath30 solution ( if any ) to the following minimization problem @xmath31 where , for every @xmath32 , @xmath33\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } }       = {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^2(x ) \\frac{p(x)}{p_\\theta(x ) } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\le + \\infty.\\ ] ] a typical situation is importance sampling by mean translation in a finite dimensional gaussian framework _",
    "i.e. _ @xmath34\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\ ] ] then the second equality in  ( [ v = e ] ) is simply the cameron - martin formula .",
    "this specific framework is very important for applications , especially in finance , and was the starting point of the new interest for recursive importance sampling procedures , mainly initiated by arouna in  @xcite ( see further on ) .",
    "in fact , as long as variance reduction is concerned , one can consider a more general framework without extra effort . as a matter of fact , if the distributions @xmath35 satisfy @xmath36 and @xmath37 satisfies @xmath38\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty$ ] for every @xmath32 , then ( see proposition  [ prop_intro ] below ) , the function @xmath39 is finite , convex , goes to infinity at infinity . as",
    "a consequence @xmath40 _ is non empty_. assumption @xmath41 can be localized by by considering that one the two conditions holds only on a borel set @xmath42 of @xmath6 such that @xmath43 . if @xmath44 is _ strictly _",
    "@xmath45-concave for every @xmath46 in a borel set @xmath47 such that @xmath48\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}>0 $ ] , then @xmath39 is strictly convex and @xmath40 is reduced to a single @xmath49 .",
    "these results follow from the second representation of @xmath39 as an expectation in  ( [ v = e ] ) which is obtained by a second change of probability ( the reverse one ) . for notational convenience",
    "we will temporarily assume that @xmath50 in this introduction section , although our main result needs no such restriction .",
    "a classical procedure to approximate @xmath51 is the so - called robbins - monro algorithm .",
    "this is a recursive stochastic algorithm ( see  ( [ rm ] ) below ) which can be seen as a stochastic counterpart of deterministic recursive zero search procedures like the newton - raphson one .",
    "it can be formally implemented provided the gradient of the ( convex ) target function @xmath39 admits a representation as an expectation . since we have no _",
    "a priori _ knowledge about the regularity of @xmath37 ( is smooth enough alternative approaches have been developed based on some large deviation estimates which provide a good approximation of @xmath51 by deterministic optimization methods ( see  @xcite ) . ] ) and do not wish to have any , we are naturally lead to _ formally _ differentiate the second representation of @xmath39 in  ( [ v = e ] ) to obtain a representation of @xmath52 as @xmath53\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\ ] ]    then , if we consider the function @xmath54 such that @xmath55 naturally defined by  ( [ grad1 ] ) , the derived robbins - monro procedure writes @xmath56 with @xmath57 a _ step _ sequence decreasing to 0 ( at an appropriate rate ) , @xmath58 a sequence of i.i.d . random variables with distribution @xmath59 . to establish the convergence of a robbins - monro procedure to @xmath60",
    "requires seemingly not so stringent assumptions .",
    "we mean by that : not so different from those needed in a deterministic framework .",
    "however , one of them turns out to be quite restrictive for our purpose : the sub - linear growth assumption in quadratic mean @xmath61 which is the stochastic counterpart of the classical non - explosion condition needed in a deterministic framework . in practice , this condition is almost never satisfied in our framework due to the behaviour of the term @xmath62 as @xmath63 goes to infinity .",
    "the origin of recursive importance sampling as briefly described above goes back to kushner and has recently been brought back to light in a gaussian framework by arouna in  @xcite .",
    "however , as confirmed by the numerical experiments carried out by several authors ( @xcite ) , the regular robbins - monro procedure  ( [ rm ] ) does suffer from a structural instability coming from the violation of  ( [ nec ] ) .",
    "this phenomenon is quite similar to the behaviour of the explicit discretization schemes of an @xmath64 @xmath65 when @xmath66 has a super - linear growth at infinity .",
    "furthermore , in a probabilistic framework no  implicit scheme \" can be devised in general . then the only way out _ mutatis mutandis _ is to kill the procedure when it comes close to explosion and to restart it with a smaller step sequence .",
    "formally , this can be described as some repeated projections or truncations when the algorithm leaves a slowly growing compact set waiting for stabilization which is shown to occur @xmath67 .",
    "then , the algorithm behaves like a regular robbins - monro procedure .",
    "this is the so - called  projection  la chen \" avatar of the robbins - monro algorithm , introduced by chen in  @xcite and then investigated by several authors ( see @xmath68 @xcite ) formally , repeated projections   la chen \" can be written as follows : @xmath69 where @xmath70 denotes the projection on the convex compact @xmath71 ( @xmath72 is increasing to @xmath6 as @xmath73 ) . in  @xcite",
    "is established a a central limit theorem for this version of the recursive variance reduction procedure . some extensions to non gaussian framework",
    "have been carried out by arouna in his phd thesis ( with some applications to reliability ) and more recently to the marginal distributions of a lvy processes by kawai in  @xcite .",
    "however , convergence occurs for this procedure after a long  stabilization phase \"  provided that the sequence of compact sets have been specified in an appropriate way .",
    "this specification turns out to be a rather sensitive phase of the  tuning \" of the algorithm to be combined with that of the step sequence .    in this paper , we show that as soon as the growth of @xmath37 at infinity can be explicitly controlled , it is always possible to design a regular robbins - monro algorithm which @xmath67 converges to a variance minimizer @xmath51 with no risk of explosion ( and subsequently no need of repeated projections ) .    to this end",
    "the key is to introduce a _",
    "third _ change of probability in order to control the term @xmath62 . in a gaussian framework",
    "this amounts to switching the parameter @xmath63 from the density @xmath16 to the function @xmath37 by a third mean translation .",
    "this of course corresponds to a new function @xmath74 but can also be interpreted _ a posteriori _ as a way to introduce an _ adaptive _ step sequence ( in the spirit of  @xcite ) .    in terms of formal importance sampling , we introduce a new positive density @xmath75 ( everywhere positive on @xmath76 ) so that the gradient writes @xmath77\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } \\widetilde h_v(\\theta,\\widetilde { x^{(\\theta ) } } ) { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\ ] ] where @xmath78 .",
    "the  weight \" @xmath79 may seem complicated but the rle of the density @xmath75 is to control the critical term @xmath80 by a ( deterministic ) quantity only depending on @xmath63 .",
    "then we can replace @xmath81 by a function @xmath82 in the above robbins - monro procedure  ( [ rm ] ) where @xmath83 is a positive function used to control the behaviour of @xmath84 for large values of @xmath46 ( note that @xmath85\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = 0 { \\ifcase 2\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } {     \\e\\ ! { } {      { \\ifcase 2\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } h(.,\\widetilde { x^{(\\theta ) } } ) { \\ifcase 2\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = 0 { \\ifcase 2\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } {     \\e\\ ! { } {      { \\ifcase 2\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } h(.,\\widetilde { x^{(\\theta ) } } ) { \\ifcase 2\\or      ]",
    "\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = 0 { \\ifcase 2\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } {     \\e\\ ! { } {      { \\ifcase 2\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } h(.,\\widetilde { x^{(\\theta ) } } ) { \\ifcase 2\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = 0 { \\ifcase 2\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } {     \\e\\ ! { } {      { \\ifcase 2\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } h(.,\\widetilde { x^{(\\theta ) } } ) { \\ifcase 2\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = 0 { \\ifcase 2\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } {     \\e\\ ! { } {      { \\ifcase 2\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } h(.,\\widetilde { x^{(\\theta ) } } ) { \\ifcase 2\\or      ]",
    "\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = 0 { \\ifcase 2\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } = {      { \\ifcase 6\\or      \\ { } \\nabla v = 0 { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } \\nabla v = 0 { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } \\nabla v = 0 { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } \\nabla v = 0 { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } \\nabla v = 0 { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } \\nabla v = 0 { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi}}$ ] ) .",
    "we will first illustrate this paradigm in a finite dimensional setting with parametrized importance sampling procedures : the mean translation and the esscher transform which coincide for gaussian vectors on which a special emphasis will be put .",
    "both cases correspond to a specific choice of @xmath75 which significantly simplifies the expression of the weight .    as a second step",
    ", we will deal with an infinite dimensional setting ( path - dependent diffusion like processes ) where we will rely on the girsanov transform to play the role of mean translator . to be more precise ,",
    "we want now to compute @xmath86\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] where @xmath9 is a path - dependent diffusion process and @xmath37 is a functional defined on the space @xmath87,\\r^d)$ ] of continuous functions defined on @xmath88 $ ] .",
    "we consider a @xmath89-dimensional it process @xmath7}$ ] solution of the path - dependent sde @xmath90 where @xmath91}$ ] is a @xmath92-dimensional standard brownian motion , @xmath93}$ ] is the stopped process at time @xmath94 , @xmath95\\times { \\cal c}([0,t],\\r^d)\\to \\r^d$ ] and @xmath96\\times   { \\cal c}([0,t],\\r^d)\\to { \\cal m}(d , q)$ ] are lipschitz with respect to the @xmath97 on the space @xmath98,\\r^d)$ ] and continuous in @xmath99\\times { \\cal c}([0,t],\\r^d)$ ] ( see  @xcite for more details about these path - dependent sde s ) .",
    "let @xmath100 be a fixed borel bounded functional on @xmath87,\\r^d)$ ] with values in @xmath101 ( where @xmath102 is a free integral parameter ) . then",
    "a girsanov transform yields that for every @xmath103,\\r^p)$ ] , @xmath104\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f({x^{(\\theta ) } } ) e^{-\\int_0^t\\ ! {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } \\varphi({x^{(\\theta),s } } ) \\theta(s ) , \\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } - \\frac{1}{2 } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\varphi({x^{(\\theta)}}{}^{,.})\\theta      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^2 } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}\\ ] ] where @xmath26 is the solution to @xmath105 . the functional to be minimized is now @xmath106\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\qquad \\theta\\!\\in l^2_{t , p}.\\ ] ] in practice we will only minimize @xmath39 over a _ finite dimensional subspace _ of @xmath107 .    the paper is organized as follows .",
    "section [ dimfinie ] is devoted to the finite dimensional setting where we recall the main tool including a slight extension of the robbins - monro theorem in the subsection [ argmin - target ] and the gaussian case investigated in @xcite is revisited to emphasize the new aspects of our algorithm in the subsection [ gaussian_case ] .",
    "in section 2 we successively investigate the translation for log - concave distributions probability and the esscher transform . in section [ diffusion ]",
    "we introduce a functional version of our algorithm based on the girsanov theorem to deal the sde . in section 4",
    "we provide some comments on the practical implementation and in section [ numerical ] some numerical experiments are carried out on some option pricing problems .",
    " @xmath108 we will denote by @xmath109 the fact that a symmetric matrix @xmath110 is positive definite .",
    "@xmath111 will denote the canonical euclidean norm on @xmath112 and @xmath113 will denote the canonical inner product .",
    "@xmath108 the real constant @xmath114 denotes a positive real constant that may vary from line to line .",
    "@xmath108 @xmath115 if @xmath116 is an @xmath117-valued ( class of ) borel function(s ) .",
    "[ prop_intro ] suppose holds .",
    "+ then the function @xmath39 defined by  ( [ v = e ] ) is convex and @xmath119 . as a consequence @xmath120    * proof .",
    "* by the change of probability @xmath121 we have @xmath122\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] .",
    "let @xmath46 fixed in @xmath6 .",
    "the function @xmath123 is concave , hence @xmath124 is convex so that , owing to the young inequality , the function @xmath125 is convex since it is non - negative .    to prove that @xmath39 tends to infinity as @xmath126 goes to infinity , we consider two cases :    * if @xmath127 for every @xmath128 , the result is trivial by fatou s lemma . *",
    "if @xmath129 for every @xmath128 , we apply the reverse hlder inequality with conjugate exponents @xmath130 to obtain @xmath131\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^3 {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 6\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } \\frac{p(x)}{p_{\\theta/2}(x ) } { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi}}^{-1 } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^{-2 } , \\\\      & \\ge {     \\e\\ ! { } {      { \\ifcase 5\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^{2/3}(x ) {      { \\ifcase 4\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } \\frac{p^2_{\\theta/2}(x)}{p(x)p_\\theta(x ) } { \\ifcase 4\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi}}^{\\frac{1}{3 } } { \\ifcase 5\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^3,\\end{aligned}\\ ] ] ( @xmath16 and @xmath132 are probability density functions ) .",
    "one concludes again by fatou s lemma . @xmath133    the set @xmath134 , or to be precise",
    ", the random vectors taking values in @xmath134 will the target(s ) of our new algorithm .",
    "if @xmath39 is strictly convex , @xmath68 if @xmath135\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } > 0,\\ ] ] then @xmath50 .",
    "nevertheless this will not be necessary owing to the combination of the two results that follow .",
    "[ un]let @xmath136 be a convex differentiable function , then @xmath137 furthermore , if @xmath138 is nonempty , it is a convex closed set ( which coincide with @xmath139 ) and @xmath140    a sufficient ( but in no case necessary ) condition for a nonnegative convex function @xmath141 to attain a minimum is that @xmath142 .",
    "now we pass to the statement of the convergence theorem on which we will rely throughout the paper .",
    "it is a slight variant of the regular robbins - monro procedure whose proof is rejected in an annex .",
    "[ thmrz ] ( extended robbins - monro theorem ) let @xmath143 a borel function and @xmath9 an @xmath6-valued random vector such that @xmath144\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}<+\\infty$ ] for every @xmath145 . then set @xmath146\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\ ] ]",
    "suppose that the function @xmath66 is continuous and that @xmath147 satisfies @xmath148 let @xmath149 be a sequence of gain parameters satisfying @xmath150 suppose that @xmath151\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\le c(1 + {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2)\\ ] ] ( which implies @xmath152 ) .",
    "let @xmath153 be an i.i.d .",
    "sequence of random vectors having the distribution of @xmath9 , a random vector @xmath154 , independent of @xmath153 satisfying @xmath155\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty$ ] , all defined on the same probability space @xmath156 .",
    "then , the recursive procedure defined by @xmath157 satisfies : @xmath158 the convergence also holds in @xmath159 , @xmath160 .",
    "the proof is postponed to the appendix at the end of the paper .",
    "the natural way to apply this theorem for our purpose is the following :    * step  1 : we will show that the convex function @xmath39 in  ( [ v = e ] ) is differentiable with a gradient @xmath52 having a representation as an expectation formally given @xmath161\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] .",
    "* step  2 : then set @xmath162 where @xmath163 is a ( strictly ) positive function on @xmath23 . as a matter of fact , with the notations of the above theorem @xmath164 so that @xmath165 and is satisfied ( set @xmath166 in lemma  [ un ] ) . * step  3 : specify in an appropriate way the function @xmath167 so that the linear quadratic growth assumption is satisfied .",
    "this is the sensitive point that will lead us to modify the structure more deeply by finding a new representation of @xmath52 as an expectation not directly based on the local gradient @xmath168 .",
    "the gaussian is the framework of  @xcite .",
    "it is also a kind of introduction to the infinite dimensional diffusion setting investigated in section  [ diffusion ] . in the gaussian case ,",
    "the natural importance sampling density is the translation of the gaussian density : @xmath169 for @xmath170 ( @xmath171 @xmath172 ) .",
    "we have @xmath173    the assumption is clearly satisfied by the gaussian density , and we assume that @xmath37 satisfies @xmath174\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty$ ] so that @xmath39 is well defined .    in  @xcite",
    ", arouna considers the function @xmath54 defined by @xmath175 it is clear that the condition is not satisfied even if we simplify this function by @xmath176 ( which does not modify the problem ) .",
    "when @xmath5 have finite moments of any order , a naive way to control directly @xmath177 by an explicit deterministic function of @xmath63 ( in order to rescale it ) is to proceed as follows : one derives from hlder inequality that for every couple @xmath178 , @xmath179 of conjugate exponents @xmath180 setting @xmath181 and @xmath182 , yields @xmath183    then , @xmath184 satisfies the condition and theoretically the standard robbins - monro algorithm implemented with @xmath185 @xmath67 converges and no projection nor truncation is needed .",
    "numerically , the solution is not satisfactory because the correcting factor @xmath186 goes to zero much too fast as @xmath63 goes to infinity : if at any iteration at the beginning of the procedure @xmath187 is sent  too far \" , then it is frozen instantly .",
    "if @xmath188 is too small it will simply not prevent explosion .",
    "the tuning of @xmath188 becomes quite demanding and payoff dependent .",
    "this is in complete contradiction with our aim of _ a self - controlled variance reducer_. a more robust approach needs to be developed .",
    "on the other hand this kind of behaviour suggests that we are not in the right asymptotics to control @xmath177 .",
    "note however that when @xmath37 is bounded with a compact support , then one can set @xmath189 and the above approach provides an efficient answer to our problem .",
    "we consider the density @xmath190 by , we have @xmath191\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\ ] ] with @xmath192 , _",
    "i.e. _ @xmath193 .",
    "since @xmath16 is the gaussian density , we have @xmath194 . as a consequence ,",
    "the function @xmath195 defined by @xmath196 provides a representation @xmath197\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] of the gradient @xmath52 .",
    "as soon as @xmath37 is bounded , this function satisfies the condition .",
    "otherwise , we note that thanks to this new change of variable the parameter @xmath63 lies now _ inside _ the payoff function @xmath37 and that the _ exponential term _ has disappeared from the expectation .",
    "if we have an _ a priori _ control on the function @xmath198 as @xmath199 goes to infinity , say @xmath200 then we can consider the function @xmath201 which satisfies @xmath202    the resulting robbins - monro algorithm reads @xmath203    we no longer to tune the correcting factor and one verifies on simulations that it does not suffer from freezing in general . in case of a too dissymmetric function @xmath37 this may still happen but a _ self - controlled _ variant is proposed in section  [ translation ] below to completely get rid of this effect ( which can not be compared to an explosion ) .",
    "we consider importance sampling by mean translation , namely we set @xmath204 for @xmath170 .    in this section",
    "we assume that @xmath205 so that holds .",
    "moreover , we make the following additional assumption on the probability density @xmath16 @xmath206   \\ ;   \\mbox { such that } \\;\\left\\ { \\begin{array}{ll}(i ) & \\frac{\\left|\\nabla p\\right|}{p}(x)=o(|x|^{a-1 } )   \\ ; \\mbox { as } \\ ; |x|\\to \\infty \\\\ ( ii)&\\exists \\delta>0,\\ ; \\log   p(x)+\\delta |x|^a\\;\\mbox { is convex . }",
    "\\end{array}\\right.\\ ] ]    first we will use  ( [ v = e ] ) to differentiate @xmath39 since    suppose and are satisfied and the function @xmath37 satisfies @xmath207\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty \\quad\\text { and } \\quad \\forall\\ , c>0,\\quad {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^2(x)e^{c|x|^{a-1 } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty.\\ ] ] then @xmath39 is finite and differentiable on @xmath6 with a gradient given by @xmath208\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}\\\\      & = {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^2(x-\\theta)\\frac{p^2(x-\\theta)}{p(x)p(x-2\\theta)}\\frac{\\nabla p(x-2\\theta)}{p(x-2\\theta ) } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\label{gradv2 } \\end{aligned}\\ ] ]    * proof . * the formal differentiation to get  ( [ gradv1 ] ) from  ( [ v = e ] ) is obvious .",
    "so it remains to check the domination property for @xmath63 lying inside a compact set .",
    "let @xmath209 and @xmath145 .",
    "the @xmath45-concavity of @xmath16 implies that @xmath210 so that @xmath211 using the assumption   yields , for every @xmath212 , @xmath213 to derive the second expression for the gradient , we proceed as follows : an elementary change of variable shows that @xmath214\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\cqfd\\end{aligned}\\ ] ]    the second change of variable ( in  ) has been processed to withdraw the parameter @xmath63 from the possible non smooth function @xmath37 to make possible the differentiation of @xmath39 ( since @xmath16 is smooth ) .",
    "the second expression   results form a _",
    "third _ translation of the variable in order to plug back the parameter @xmath63 into the function @xmath37 which in common applications has a known controlled growth rate at infinity .",
    "this last statement may look strange at a first glance since @xmath63 appears in the  weight \" term of the expectation that involves the probability density @xmath16 .",
    "however , when @xmath215 , this term can be controlled easily since it reduces to @xmath216 the following lemma shows that , more generally in our strongly unimodal setting , if and are satisfied , this ",
    "weight \" can always be controlled by a deterministic function of @xmath63 .",
    "[ lemmetec ] if holds , then there exists two real constants @xmath217 , @xmath47 such that @xmath218    * proof .",
    "* let @xmath219 be the convex function defined on @xmath6 by @xmath220 .",
    "then , for every @xmath221 , @xmath222 note that @xmath223 .",
    "then , using the @xmath45-convexity of @xmath219 and the elementary inequality @xmath224 ( valid if @xmath225 $ ] ) yields @xmath226 one concludes by the point @xmath227 of .",
    "thus the normal distribution satisfies with @xmath228 and @xmath229 .",
    "moreover , note that the last inequality in the above proof holds as an equality .",
    "now we are in position to derive an unconstraint ( extended ) robbins - monro algorithm to minimize the function @xmath39 , provided the function @xmath37 satisfies a sub - multiplicative control property , in which @xmath230 is a real parameter and @xmath231 a function from @xmath232 to @xmath233 , such that , namely @xmath234\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}<+\\infty .",
    "\\end{array}\\right . \\ ] ]    * remark .",
    "* assumption seems almost non - parametric . however , its field of application is somewhat limited by  ( [ h2 ] ) for the following reason : if there exists a positive real number @xmath235 such that @xmath236 is concave , then @xmath237 for some real constant @xmath114 ; which in turn implies that the function @xmath231 in needs to satisfy @xmath238 for some @xmath239 and some @xmath240 .",
    "( then @xmath241 with @xmath242 if @xmath243 $ ] and @xmath244 if @xmath245 , when @xmath246 ) .",
    "[ thmmt ] suppose @xmath9 and @xmath37 satisfy , ,  ( [ conddiff ] ) and for some parameters @xmath225 $ ] , @xmath247 and @xmath240 , and that the step sequence @xmath248 satisfies the usual decreasing step assumption @xmath249 then the recursive procedure defined by @xmath250 where @xmath153 is an i.i.d . sequence with the same distribution as @xmath9 and @xmath251 @xmath67 converges toward an @xmath134-valued ( square integrable ) random variable @xmath51 .",
    "in order to apply theorem  [ thmrz ] , we have to check the following fact :     _ mean reversion _ : the mean function of the procedure defined by  ( [ algorm ] ) reads @xmath252\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = \\frac{e^{-2\\delta |\\theta|^a}}{1+\\widetilde f(-\\theta)^{2c}}\\nabla v(\\theta)\\ ] ] so that @xmath253 and if @xmath254 and @xmath255 , @xmath256 for every @xmath257 .    ",
    "_ linear growth of @xmath258 _ : all our efforts in the design of the procedure are motivated by this assumption  ( [ lingrowth ] ) which prevents explosion .",
    "this condition is clearly fulfilled by @xmath259 since @xmath260\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^2 & = \\frac{e^{-4\\delta |\\theta|^a}}{(1+\\widetilde f(-\\theta)^{2c})^2 } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^4(x-\\theta)\\left(\\frac{p^2(x-\\theta)}{p(x)p(x-2\\theta)}\\frac{|\\nabla p(x-2\\theta)|}{p(x-2\\theta)}\\right)^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } , \\\\   & \\le c e^{-4\\delta |\\theta|^a } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } ( 1+\\widetilde f(x)^{2c})^2 ( a(|x|^{a-1}+|\\theta|^{a-1})+b)^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\end{aligned}\\ ] ] where we used assumption   in the first line and inequality  ( [ ineqtech ] ) from lemma  [ lemmetec ] in the second line .",
    "one derives that there exists a real constant @xmath114 such that @xmath261\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^2 \\le c {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi }   \\widetilde f(x)^{4c}(1+|x|)^{2(a-1 ) } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } ( 1+|\\theta|^{2(a-1)}).\\ ] ] this provides the expected condition since   holds .",
    "@xmath133      * the normal distribution .",
    "its density is given on @xmath6 by @xmath262 so that is satisfied as well as for @xmath228 , @xmath263 .",
    "assumption is satisfied iff @xmath264 .",
    "then the function @xmath259 has a particularly simple form @xmath265 * _ the hyper - exponential distributions _ @xmath266\\ ] ] where @xmath267 is polynomial function .",
    "this wide family includes the normal distributions , the laplace distribution , the symmetric gamma distributions , etc . * _ the logistic distribution _ its density on the real line is given by @xmath268 is satisfied as well as for @xmath269 ( @xmath270 ) , @xmath271 .",
    "assumption is satisfied iff @xmath272 .",
    "a second classical approach is to consider an exponential change of measure ( or esscher transform ) .",
    "this transformation has already been consider for that purpose in  @xcite to extend the procedure with repeated projections introduced in  @xcite .",
    "we denote by @xmath273 the cumulant generating function ( or log  laplace ) of @xmath9 _ i.e. _ @xmath274\\or",
    "\\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] .",
    "we assume that @xmath275 for every @xmath145 ( which implies that @xmath273 is an infinitely differentiable convex function ) and define @xmath276 let @xmath277 denote any random variable with distribution @xmath132 .",
    "we assume that @xmath273 satisfies @xmath278    one must be aware that what follows makes sense as a variance reduction procedure only if the distribution of @xmath26 can be simulated at the same cost as @xmath9 or at least at a reasonable cost @xmath171 @xmath279 where @xmath280 is a borel subset of a metric space and @xmath281 is an explicit borel function . by , the potential @xmath39 to be minimized is @xmath282\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.$ ]    suppose @xmath273 satisfies and @xmath37 satisfies @xmath283\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty.\\ ] ] then is fulfilled and the function @xmath39 is differentiable on @xmath6 with a gradient given by @xmath284\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } , \\\\       & = {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 2\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } \\nabla \\psi(\\theta ) - { x^{(-\\theta)}}{\\ifcase 2\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi } } f^2({x^{(-\\theta ) } } ) { \\ifcase 6\\or      ]",
    "\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } e^{\\psi(\\theta)-\\psi(-\\theta ) } , \\label{diff_esscher}\\end{aligned}\\ ] ] where @xmath285\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } } { {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } e^ { {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } \\theta , x      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}}$ ] .    the function @xmath273 is clearly log - convex so that @xmath286 is @xmath45-concave for every @xmath209 . on the other hand ,",
    "by we have @xmath287 for every @xmath209 , and is fulfilled .",
    "the formal differentiation to get is obvious and is made rigorous by applying the assumption on @xmath37 .",
    "the second expression of the gradient uses a third change of variable @xmath288\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } e^{\\psi(\\theta)-\\psi(-\\theta)}.\\cqfd\\end{aligned}\\ ] ]    we assume that @xmath273 satisfies   and @xmath37 satisfies   and @xmath289\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty.\\ ] ] then the recursive procedure @xmath290 where @xmath291 is an i.i.d .",
    "sequence with the same distribution as @xmath292 in  ( [ rexesscher ] ) and @xmath293 @xmath67 converges toward an @xmath134-valued ( square integrable ) random vector @xmath51 .",
    "we have to check the linear growth of the function @xmath294 ( condition ) .",
    "we have @xmath295\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } & = e^{-\\lambda\\sqrt{d } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(-\\theta )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^4({x^{(-\\theta ) } } ) {      { \\ifcase 2\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(\\theta ) - { x^{(-\\theta)}}{\\ifcase 2\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } , \\notag \\\\      & \\le c e^{-\\lambda\\sqrt{d } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(-\\theta )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } e^{\\lambda {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { x^{(-\\theta)}}{\\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } } {      { \\ifcase 2\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(\\theta ) - { x^{(-\\theta)}}{\\ifcase 2\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } , \\notag \\\\      & \\le c e^{-\\lambda \\sqrt{d } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(-\\theta )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } } {      { \\ifcase 6\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(\\theta )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } e^{\\lambda {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { x^{(-\\theta)}}{\\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } + {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { x^{(-\\theta)}}{\\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 e^{\\lambda {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { x^{(-\\theta)}}{\\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi}}. \\label{esscher - check - nec}\\end{aligned}\\ ] ]    first , by the following inequality @xmath296 we have @xmath297 where @xmath298 if @xmath299 or @xmath300 if @xmath301 . with this notation , we have @xmath302\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } & \\le \\sum_{j\\subset {      { \\ifcase 6\\or      \\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } e^{\\lambda {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } e_j , { x^{(-\\theta)}}{\\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = \\sum_{j\\subset {      { \\ifcase 6\\or      \\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } e^{\\psi(\\lambda e_j-\\theta ) - \\psi(-\\theta)}.\\end{aligned}\\ ] ] by the concavity of @xmath303 , we have @xmath304 so that @xmath305\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\le \\sum_{j\\subset {      { \\ifcase 6\\or      \\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } e^{\\lambda {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } \\nabla \\psi(-\\theta ) , e_j      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi}}+\\delta\\lambda^2|e_j|^2 } \\le c_{d,\\lambda,\\delta }   e^{\\lambda \\sqrt{d } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(-\\theta )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}}. \\label{esscher - check - nec-1}\\ ] ]    in the same way , we have @xmath306\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } & \\le \\sum_{j\\subset {      { \\ifcase 6\\or      \\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } x^{(\\lambda e_j-\\theta ) }      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } e^{\\psi(\\lambda e_j-\\theta ) - \\psi(-\\theta ) } , \\notag \\\\       & \\le c_{d,\\lambda,\\delta }   e^{\\lambda \\sqrt{d } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\nabla \\psi(-\\theta )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}}\\sum_{j\\subset {      { \\ifcase 6\\or      \\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } 1,\\dots , d { \\ifcase 6\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } x^{(\\lambda e_j-\\theta ) }      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}. \\label{esscher - check - nec-2}\\end{aligned}\\ ] ] now , by differentiation of @xmath273 it is easy to check that @xmath307 which implies @xmath308\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = \\operatorname{tr\\ ! } {      { \\ifcase 6\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } { \\operatorname{d\\!}^{\\,2}\\!}\\psi(\\lambda e_j - \\theta ) { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi } } + \\operatorname{tr\\ ! } {      { \\ifcase 6\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } \\nabla \\psi(\\lambda e_j - \\theta)^{\\otimes 2 } { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi}}.\\ ] ] the assumption implies that @xmath309 ( for the partial order on symmetric matrices induced by nonnegative symmetric matrices ) then @xmath310 is a bounded function of @xmath145 and in turn @xmath311 has a linear growth by the fundamental formula of calculus .",
    "consequently , for every @xmath312 , @xmath308\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\le c {      { \\ifcase 6\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } 1 + {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi}}.\\ ] ] plugging this into and using and we obtain @xmath313\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\le c {      { \\ifcase 6\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } 1 + {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi}}$ ]",
    "we consider a @xmath89-dimensional it process @xmath7}$ ] solution to the stochastic differential equation ( sde ) @xmath314 where @xmath91}$ ] is a @xmath92-dimensional standard brownian motion , @xmath93}$ ] is the stopped process at time @xmath94 , @xmath95\\times { \\cal c}([0,t],\\r^d)\\to \\r^d$ ] and @xmath96\\times   { \\cal c}([0,t],\\r^d)\\to { \\cal m}(d , q)$ ] are measurable with respect to the canonical predictable @xmath315-field on @xmath88\\times { \\cal c}([0,t],\\r^d ) $ ] . for further details we refer to  @xcite , p. 124",
    "thus , if @xmath316 and @xmath317 for every @xmath318,\\r^d)$ ] , @xmath9 is a usual diffusion process with drift @xmath319 and diffusion coefficient @xmath320 .",
    "    if @xmath321 and @xmath322 for every @xmath318,\\r^d)$ ] where @xmath323 , then @xmath9 is _ the continuous euler scheme with step _ @xmath324 of the above diffusion with drift @xmath319 and diffusion coefficient @xmath320 .    an easy adaptation of standard proofs for regular sde s show",
    "( see  @xcite ) that strong existence and uniqueness of solutions for  ( [ sdext ] ) follows from the following assumption @xmath325,\\ ; \\forall\\ , x,\\ , y\\!\\in { \\cal c}([0,t],\\r^d),\\ , {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } b(t , y)-b(t , x )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}+ {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\sigma(t , y)-\\sigma(t , x )      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } \\le",
    "c_{b,\\sigma } {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } x - y      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\infty}}}.      \\end{cases}\\end{aligned}\\ ] ]    our aim is to devise an adaptive variance reduction method inspired from section  [ dimfinie ] for the computation of @xmath104\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}\\ ] ] where @xmath37 is an borel functional defined on @xmath87,\\r^d)$ ] such that @xmath326\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}>0 \\quad \\text{and}\\quad f(x)\\!\\in l^2(\\p).\\ ] ] in this functional setting , girsanov theorem will play the role of the invariance of lebesgue measure by translation .",
    "the translation process that we consider in this section is of the form @xmath327 where @xmath22 is defined for every @xmath328,\\r^d)$ ] and @xmath329 by @xmath330 \\times { \\cal c}([0,t],\\r^d ) \\rightarrow { \\cal m}(q , p),\\ ] ] a bounded borel function and @xmath329 ( represented by a borel function ) for @xmath102 . in the sequel ,",
    "we use the following notations @xmath331 , @xmath332 where @xmath333 denotes the solution to @xmath334 .",
    "first we need the following standard abstract lemma .",
    "[ girs ] suppose @xmath335 holds .",
    "+ the sde @xmath336 satisfies the weak existence and uniqueness assumptions and for every non negative borel functional @xmath337,\\r^{d+1 } ) \\to \\r_+$ ] and @xmath338,\\r^{q})$ ] we have , with the above notations , @xmath339\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } }      = {     \\e\\ ! { } {      { \\ifcase 4\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } g {      { \\ifcase 3\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } { x^{(\\theta ) } } , \\int_0^.\\!\\ ! {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } f(s , { x^{(\\theta),s } } ) , \\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } }       + \\int_0^. \\!\\ ! {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } f , \\theta      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi}}(s , { x^{(\\theta),s } } ) \\operatorname{d\\!}s { \\ifcase 3\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi } } \\\\      \\times e^{- \\int_0^t\\!\\ ! {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } { \\theta^{(\\theta)}}_s , \\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } -\\frac{1}{2 } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { \\theta^{(\\theta)}}{\\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^2 } { \\ifcase 4\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\end{gathered}\\ ] ] and @xmath340\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } }      = {     \\e\\ ! { } {      { \\ifcase 4\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } g {      { \\ifcase 3\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } x , \\int_0^. \\!\\ !",
    "{      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } f(s , x^s ) , \\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } }       - \\int_0^. \\!\\ ! {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } f , \\theta      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi}}(s , x^s ) \\operatorname{d\\!}s { \\ifcase 3\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi}}\\\\      \\times e^{\\int_0^t \\!\\ ! {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } \\theta_s , \\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } -\\frac{1}{2 } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta",
    "{ \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^2 } { \\ifcase 4\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\end{gathered}\\ ] ]    this is a straightforward application of theorem 1.11 , p.372 ( and the remark that immediately follows ) in  @xcite once noticed that @xmath341 , @xmath342 and @xmath343 are predictable processes with respect to the completed filtration of @xmath344 .",
    "@xmath133    @xmath108 the dolans exponential @xmath345}$ ] is a true martingale for any @xmath329 .",
    "@xmath108 in fact , still following the above cited remark form  @xcite , the above lemma holds true if we replace @xmath22 by any progressively measurable process @xmath346 such that @xmath347\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } < + \\infty$ ] .",
    "it follows from the first identity in lemma  [ girs ] that for every bounded borel function @xmath348 \\times { \\cal c}([0,t ] , \\r^d ) \\to { \\cal m}(q , p)$ ] and for every @xmath349 @xmath104\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f({x^{(\\theta ) } } )       e^{- \\int_0^t \\ ! {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } { \\theta^{(\\theta)}}_s , \\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } -\\frac{1}{2 } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { \\theta^{(\\theta)}}{\\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^2 } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\ ] ] ( set @xmath350 ) .",
    "so , finding the estimator with the lowest variance amounts to solving the minimization problem @xmath351\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\ ] ] using lemma  [ girs ] with @xmath352 and @xmath353 yields @xmath354\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\ ] ]    assume @xmath355 for some @xmath235 as well as assumptions  ( [ nonvide ] ) and @xmath335 .",
    "then function @xmath39 is finite on @xmath356 and @xmath45-convex .    *",
    "assume that the bounded matrix - valued borel function @xmath100 satisfies that @xmath357 has a non - atomic kernel on the event @xmath358 @xmath171 @xmath359\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}=0\\ ] ] then for every finite dimensional subspace @xmath360 , @xmath361 . if furthermore @xmath362\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\theta(s ) \\operatorname{d\\!}s > 0,\\ ] ] then @xmath363 . *",
    "the function @xmath39 is differentiable at every @xmath364 and the differential @xmath365 is characterized on every @xmath366 by @xmath367\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } ,   \\notag \\\\       & \\ ; = {     \\e\\ ! { } {      { \\ifcase 4\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^2({x^{(-\\theta ) } } ) e^ { {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { \\theta^{(-\\theta)}}{\\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , p}}}}^2 }      {      { \\ifcase 3\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } 2 {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } { \\theta^{(-\\theta ) } } , \\varphi({x^{(-\\theta)}}{}^ { , . } ) \\psi      { { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi}}_{\\scriptscriptstyle{\\ !",
    "l^2_{t , p } } } } - \\int_0^t\\!\\ !   {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } \\varphi({x^{(-\\theta),s } } ) \\psi_s , \\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } { \\ifcase 3\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi } } { \\ifcase 4\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}.\\label{diff2}\\end{aligned}\\ ] ]    * remarks .",
    "* @xmath108 for practical implementation , the ",
    "finite dimensional \" statement is the only result of interest since it ensures that @xmath368 .",
    "@xmath108 if @xmath369 and @xmath370 , the  infinite - dimensional \" assumption is always satisfied .    @xmath371 as concerns the function @xmath39 , we rely on equality  ( [ v3 ] ) . set @xmath372 .",
    "owing to the hlder inequality , showing that this function is finite on the whole space @xmath373 amounts to proving that @xmath374\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } }       \\le e^ { {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\varphi      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\infty}}}^2 {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , p } } } } } r(r+1)/2 } < + \\infty.\\ ] ]    to show that @xmath39 goes to infinity at infinity , one proceeds as follows . using the trivial equality @xmath375 and the reverse hlder inequality with conjugate exponents @xmath376 we obtain @xmath377\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^3 {     \\e\\ ! { } {      { \\ifcase 4\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } e^{\\frac{1}{2 } \\int_0^t\\ ! {",
    "{ \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } \\theta_s,\\operatorname{d\\!}w_s      { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi } } - \\frac{1}{8 } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^2 } { \\ifcase 4\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^{-2 } , \\\\      & \\ge {     \\e\\ ! { } {      { \\ifcase 4\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^{2/3}(x ) e^{\\frac{1}{12 } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^2 } { \\ifcase 4\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^3\\end{aligned}\\ ] ] by the martingale property of the dolans exponential .",
    "let @xmath378 such that @xmath379\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } > 0 $ ] .",
    "we have then @xmath380\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^3 $ ] , and by the conditional jensen inequality @xmath381\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } } { \\ifcase 4\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^3\\\\      & = {     \\e\\ ! { } {      { \\ifcase 4\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {     \\boldsymbol{1 } _ { {      { \\ifcase 1\\or      \\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi}}}}e^{\\frac{1}{12 } {     \\p\\ ! {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^2(x ) \\ge \\varepsilon { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } {     \\e\\ ! { } {      { \\ifcase 2\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^2 {     \\boldsymbol{1 } _ { {      { \\ifcase 1\\or      \\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } } { \\ifcase 2\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } } { \\ifcase 4\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^3 .\\end{aligned}\\ ] ]    now @xmath382\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = \\int_0^t \\theta(s)^ * {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } \\varphi_s(x^s)^ * \\varphi_s(x^s ) {     \\boldsymbol{1 } _ { {      { \\ifcase 1\\or      \\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } f^2(x ) \\ge \\varepsilon { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\theta(s ) \\operatorname{d\\!}s",
    "\\ge 0.\\ ] ] the assumption  ( [ nonatomic ] ) implies that , for every @xmath329 , @xmath383\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\theta(s ) \\operatorname{d\\!}s",
    "\\ge \\int_0^t \\theta(s)^*\\ , {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } \\varphi_s(x^s)^ * \\,\\varphi_s(x^s ) {     \\boldsymbol{1 } _ { {      { \\ifcase 1\\or      \\ { } f^2(x ) \\ge 0 { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge 0 { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\bigl\\ { } f^2(x ) \\ge 0 { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge 0 { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\biggl\\ { } f^2(x ) \\ge 0 { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\or       \\left\\ { } f^2(x ) \\ge 0 { \\ifcase 1\\or      \\\\or       \\bigr\\\\or       \\bigr\\\\or       \\biggr\\\\or       \\biggr\\\\or       \\right\\\\fi}\\fi } } } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\theta(s ) \\operatorname{d\\!}s > 0,\\ ] ] so that if @xmath63 runs over the compact sphere of a finite dimensional subspace @xmath3 of @xmath356 @xmath384\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\theta(s ) \\operatorname{d\\!}s > 0,\\ ] ] so that @xmath385\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = + \\infty,\\ ] ] and one concludes by fatou s lemma using that @xmath386\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } > 0 $ ] .",
    "the second claim easily follows from assumption  ( [ general ] ) .",
    "@xmath387 as a first step , we show that the random functional @xmath388 from @xmath356 into @xmath389 ( @xmath390 ) , is differentiable . indeed , it from the below inequality , @xmath391 where @xmath392 is clearly a bounded random functional from @xmath356 into @xmath389 , with an operator norm @xmath393 ( @xmath394 ( this follows from hlder and _ b.d.g . _",
    "inequalities ) .",
    "then , we derive that @xmath395 is differentiable form @xmath356 into every @xmath389 with differential @xmath396 .",
    "this follows from standard computation based on  ( [ diffl2lp ] ) , the elementary inequality @xmath397 and the fact that @xmath398 where we used both hlder and _ b.d.g . _ inequality .    one concludes that @xmath399\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] is differentiable by using the @xmath400differentiability of @xmath401 with @xmath402 .",
    "the second form of the gradient is obtained by a girsanov transform using lemma  [ girs ] .",
    "@xmath133      in view of a practical implementation of the procedure we are lead to consider some non trivial finite dimensional subspaces @xmath3 of @xmath356 .",
    "the function @xmath39 being strictly @xmath45-convex on @xmath3 and going to infinity as @xmath403 goes to infinity , @xmath404 , the restriction of @xmath39 on @xmath3 attains a minimum @xmath405 which _ de facto _ becomes the target of the procedure .",
    "furthermore , for every @xmath404 , @xmath406 and the quadratic function @xmath407 is a lyapunov function for the problem .    like for the static framework investigated in section  [ translation ] ,",
    "our algorithm will be based on the representation  ( [ diff2 ] ) for the differential @xmath408 of @xmath39 : in this representation the variance reducer @xmath63 appears inside the functional @xmath37 which makes easier a control at infinity in order to prevent from any early explosion of the procedure .",
    "however , to this end we need to control the discrepancy between @xmath9 and @xmath409 .",
    "this is the purpose of the following lemma .",
    "[ xmoinsxtheta ] assume @xmath335 holds .",
    "let @xmath100 be a bounded borel @xmath101-valued function defined on @xmath88 \\times { \\cal c}([0,t ] , \\r^d)$ ] , let @xmath364 and let @xmath9 and @xmath277 denote a strong solutions of @xmath410 and @xmath411 driven by the same brownian motion .",
    "then , for every @xmath412 , there exists a real constant @xmath413 such that @xmath414 } {      { \\ifcase 2\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } x_t - { x^{(\\theta)}}_t      { \\ifcase 2\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } }      { \\ifcase 4\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!r } } } \\le c_{b,\\sigma } e^{c_{b , \\sigma } t } {      { \\ifcase 4\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\int_0^t \\!\\ ! {      { \\ifcase 2\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\sigma(s , { x^{(\\theta),s } } ) { \\theta^{(\\theta)}}_s      { \\ifcase 2\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } \\operatorname{d\\!}s      { \\ifcase 4\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!r}}}. \\ ] ]    the proof follows the lines of the proof of the strong rate of convergence of the euler scheme ( see  @xmath68  @xcite ) . @xmath133    the main result of this section is the following theorem .",
    "suppose that assumption  ( [ nonvide ] ) and @xmath335 hold .",
    "let @xmath100 be a bounded borel @xmath101-valued function ( with @xmath102 ) defined on @xmath88 \\times { \\cal c}([0,t ] , \\r^d)$ ] , and let @xmath37 be a functional @xmath37 satisfying @xmath415,\\r^d),\\qquad {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } f(x )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } } \\le c_{_f}(1 + {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } x      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\infty}}}^\\lambda)\\ ] ] for some positive exponent @xmath240 ( then @xmath416 for every @xmath417 ) . let @xmath3 be a finite dimensional subspace of @xmath356 spanned by an orthonormal basis @xmath418 .",
    "let @xmath419 .",
    "we define the algorithm by @xmath420 where @xmath421 satisfies  ( [ stepcond ] ) , @xmath422 is a sequence of independent brownian motions for which @xmath423 is a strong solution to @xmath424 and for every standard brownian motion @xmath344 , every @xmath425-adapted @xmath117-valued process @xmath426}$ ] , @xmath427 where for @xmath419 @xmath428 then the recursive sequence @xmath429 a.s .",
    "converges toward an @xmath134-valued ( squared integrable ) random variable @xmath51 .    for a practical implementation of this algorithm",
    ", we must have _ for all _ brownian motions @xmath430 a strong solution @xmath431 of @xmath424 .",
    "in particular , this is the case if the driver @xmath100 is locally lipshitz ( in space ) or if @xmath9 is the continuous euler scheme of a diffusion with step @xmath324 ( using the driver @xmath432 ) .",
    "note that if @xmath100 is continuous ( in space ) but not necessarily locally lipshitz , the euler scheme converges in law to the solution of the sde .",
    "when the diffusion coefficient @xmath315 is bounded , it follows from lemma  [ xmoinsxtheta ] that , for every @xmath433 , @xmath434 } {      { \\ifcase 2\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } x_t - { x^{(\\theta)}}_t      { \\ifcase 2\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi } }      { \\ifcase 4\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!r } } } \\le c_{b,\\sigma , t } {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\varphi      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\infty } } } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , p } } } } } {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\sigma      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\infty}}},\\ ] ] where @xmath435\\times{\\cal c}([0,t ] , \\r^d ) } {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\sigma(t , x )      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}$ ] .    first note that for every @xmath436 , the mean function @xmath66 of the algorithm reads @xmath437\\or",
    "\\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } =       {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } \\frac{e^{- {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\varphi      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\infty } } } {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta      { \\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , p}}}}}}}{1 + {     {      { \\ifcase 6\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } { \\theta^{(-\\theta)}}{\\ifcase 6\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}_{\\scriptscriptstyle{\\!l^2_{t , q}}}}}^{2\\lambda+\\eta } } {      { \\ifcase 1\\or      \\langle\\or       \\bigl\\langle\\or       \\bigl\\langle\\or       \\biggl\\langle\\or       \\biggl\\langle\\or       \\left\\langle\\fi } \\operatorname{d\\!}v_{|e}(\\theta ) , \\psi      { { \\ifcase 1\\or      \\rangle\\or       \\bigr\\rangle\\or       \\bigr\\rangle\\or       \\biggr\\rangle\\or       \\biggr\\rangle\\or       \\right\\rangle\\fi}}_{\\scriptscriptstyle{\\ ! l^2_{t , p } } } } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\ ] ] so that , for every @xmath438 , @xmath439\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } > 0.\\ ] ]    it remains to check that for every @xmath440 , @xmath441 to apply the robbins - zygmund lemma which ensures the @xmath67 convergence of the procedure ( see section [ argmin - target ] )",
    ". we first deal with the term @xmath442 .",
    "let @xmath443 .",
    "@xmath444 now @xmath445 one shows likewise that @xmath446 combining theses estimates shows that @xmath447 satisfies the linear growth assumption in @xmath448 .",
    "if @xmath315 is unbounded it follows from assumption   that , for every @xmath99\\times { \\cal c}([0,t],\\r^d)$ ] , @xmath449 elementary computation based on   and lemma  [ girs ] yield @xmath450 for every @xmath417 ( assumption   implies that @xmath451 for every @xmath417 ) .",
    "following the same proof to the bounded case , we obtain easily the results with @xmath452 .",
    "we conclude by noting that @xmath453 is an arbitrary parameter to cancel the denominator .",
    "@xmath133    if the functional @xmath37 is bounded ( @xmath454 ) , we prove in the same way that the algorithm without correction , _",
    "i.e. _ build with @xmath455 , a.s .",
    "for the sake of simplicity we focus in this section on importance sampling by mean translation in a finite dimensional setting ( section  [ translation ] ) although most of the comments below can also be applied at least in the path - dependent diffusions setting .",
    "as proved by arouna ( see @xcite ) , we can consider a purely adaptive approach to reduce the variance .",
    "it consists to perform the robbins - monro algorithm simultaneously with the monte carlo approximation .",
    "more precisely , estimate @xmath86\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}$ ] by @xmath456 where @xmath457 is the _ same innovation _ as that used in the robbins - monro procedure @xmath458 .",
    "this adaptive monte carlo procedure satisfies a central limit theorem with the optimal asymptotic variance @xmath459\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi } } \\xrightarrow{\\cal l } { \\cal n}(0 , \\sigma^2 _ * ) , \\quad \\text{whith } \\quad \\sigma^2 _ * = v(\\theta^ * ) - {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f(x ) { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^2.\\ ] ]    this approach can be extended to the esscher transform when we use the same innovation @xmath460 ( see ) for the monte carlo procedure ( computing @xmath461 ) and the robbins - monro algorithm ( computing @xmath462 ) . likewise in the functional setting",
    "we can combine the variance reduction procedure and the monte carlo simulations using the same brownian motion .    in practice",
    ", it is not clear that this adaptive monte carlo is better than the naive two stage procedure : performing first robbins - monro with a small number of iterations ( to get a rough estimate @xmath51 ) , then performing the monte carlo simulations with this optimized parameter .",
    "as concerns the rate of convergence , once again this a regular stochastic algorithm behaves as described in usual stochastic approximation theory textbooks like  @xcite ,  @xcite ,  @xcite .",
    "so , as soon as the optimal variance reducer set is reduced to a single point @xmath51 , the procedure satisfies under quite standard assumptions a @xmath463 .",
    "we will not enter into technicalities at this stage but only try to emphasize the impact of a renormalization factor @xmath464 like @xmath465 or @xmath466 induced by the function @xmath37 on the  final \" rate of convergence of the algorithm toward @xmath51 .",
    "we will assume that @xmath467 and that @xmath468 for the sake of simplicity .",
    "one can write @xmath469 the function @xmath470 corresponds to the case of a bounded function @xmath37 ( then @xmath471 ) . under simple integration assumptions",
    ", one shows that @xmath39 is twice differentiable and that @xmath472\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}\\ ] ]    consequently the mean functions @xmath66 and @xmath473 related to @xmath259 and @xmath470 which read respectively @xmath474 are differentiable at @xmath51 and @xmath475    now , general results about clt say that if @xmath476 , @xmath477 with @xmath478 then @xmath479 where @xmath480 the mapping @xmath481 reaches its minimum at @xmath482 leading to the minimal asymptotic variance @xmath483\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}}{h_0'(y^*)^2}= \\frac { {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^4(x)(\\theta^*-x)^2e^{-\\theta^*x } { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } } { {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } f^2(x)(x^2-\\theta^*x+1 ) { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}}^2}\\ ] ] by homogeneity .",
    "so the optimal rate of convergence of the procedure is not impacted by the use of the normalizing function @xmath464 . however , coming back to condition  ( [ condtcl ] ) , we see that this assumption on the coefficient @xmath484 is more stringent since @xmath485 ( in practice this factor can be rather large ) .",
    "consequently , given the fact that @xmath486 is unknown to the user , this will induce a blind choice of @xmath484 biased to higher values . with the well - known consequence in practice",
    "that if @xmath484 is too large the `` _ _ clt _ _ regime '' will take place later than it would with smaller values .",
    "one solution to overcome this contradiction can be to make @xmath484 depend on @xmath487 and slowly decrease .    as a conclusion , the algorithm never explodes ( and converges ) even for strongly unbounded functions @xmath37 which is a major asset compared to the version of the algorithm based on repeated projections . nevertheless , the normalizing factor which ensures the non - explosion of the procedure may impact the rate of convergence since it has an influence on the tuning of the step sequence ( which is always more or less  blind \" since it depends on the target @xmath51 .",
    "in fact , we did not meet such difficulty in our numerical experiments reported below .",
    "one classical way to overcome this problem can be to introduce the empirical mean of the algorithm implemented with a slowly decreasing step   la rupert & poliak \" ( see @xmath68  @xcite ) : set @xmath488 , @xmath489 and @xmath490 where @xmath491 denotes the regular robbins - monro algorithm defined by  ( [ algorm ] ) starting at @xmath154 .",
    "then @xmath492 converges toward @xmath51 and satisfies a clt with the optimal asymptotic variance  ( [ asympvar ] ) .",
    "see also a variant based on a gliding window developed in  @xcite .      in many applications ( see below with the spark spread options with the nig distribution ) the natural set of parameters",
    "@xmath22 is not @xmath23 but an open connected subset of @xmath23 . nevertheless , as illustrated below , our unconstrained approach still works provided one can proceed a diffeomorphic change of parameter by setting @xmath493 where @xmath494 is a @xmath495-diffeomorphism with a bounded differential ( @xmath171 @xmath496 ) . as an illustration ,",
    "let us consider the case where the state function @xmath497 of the procedure is designed so that @xmath498 where @xmath39 is the objective function to be minimized over @xmath22 and @xmath499 is a bounded _ positive _ borel function .",
    "then , one replaces @xmath497 by @xmath500 and defines recursively a procedure on @xmath23 by @xmath501 in order to establish the @xmath67 convergence of @xmath502 to @xmath134 , one relies on a variant of robbins - monro algorithm , namely a stochastic gradient approach ( see  @xcite for further details ) : one defines @xmath503 which turns out to be a lyapunov function for the new algorithm since @xmath504 if @xmath141 satisfies @xmath505 ) , one shows under the standard  decreasing \" assumption on the step sequence that @xmath506 and @xmath507 . if @xmath508 or @xmath509 , one easily derives that @xmath510 @xmath67 as @xmath511",
    "first we consider a simple case to compare the two algorithms of section  [ dimfinie ] .",
    "the quantity to compute is @xmath104\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = \\int_{\\r } f(x ) \\ , p_{\\operatorname{nig}}(x;\\alpha,\\beta,\\delta,\\mu ) \\operatorname{d\\!}x,\\ ] ] where @xmath512 is the density of @xmath9 a normal inverse gaussian ( nig ) random variable of parameters @xmath513",
    "i.e. @xmath514 , @xmath515 , @xmath516 , @xmath517 , @xmath518 where @xmath519 is a modified bessel function of the second kind and @xmath520 .    we can summarize the two algorithms presented in section [ dimfinie ] , more precisely the variance reduction based on translation of the density ( see subsection [ translation ] ) and the one based on the esscher transform ( see subsection [ esscher ] ) , by the following simplified ( no computation of the variance ) pseudo - code :    .... for n = 0 to m do      x ~ nig(alpha , beta , mu , delta )      theta = theta - 1/(n+1000)*h1(theta , x ) for n = 0 to n do      x ~ nig(alpha , beta , mu , delta )      mean = mean + f(x ) * p(x+theta)/p(x )      ....    .... for n = 0 to m do      x ~ nig(alpha , beta - theta , mu , delta )      theta = theta - 1/(n+1000)*h2(theta , x ) for n = 0 to n do      x ~ nig(alpha , beta+theta , mu , delta )      mean = mean + f(x ) * exp(-theta*x ) mean = mean * exp(psi(theta ) ) ....    * _ translation case .",
    "_ we consider the function @xmath521 of the robbins - monro procedure of the first algorithm defined by @xmath522 where an analytic formulation of the derivative @xmath523 is easily obtained using the relation on the modified bessel function @xmath524 .",
    "+ the assumption is satisfied with @xmath525 , and our results of subsection [ translation ] apply . * _ esscher transform . _ in the esscher approach we consider the function @xmath526 defined by @xmath527 note that @xmath273 is not well defined for every @xmath170 .",
    "indeed , the cumulant generating function of the nig distribution is defined by @xmath528 for every @xmath529 .",
    "moreover , we need @xmath530 to be well defined _",
    "i.e. _ @xmath531 . to take account of these restrictions ,",
    "we slightly modify the algorithm parametrization ( see subsection [ extension ] ) @xmath532 , and update @xmath533 in the robbins - monro procedure ( multiply the function @xmath534 by the derivative @xmath535 ) .",
    "the payoff @xmath37 is a call option of strike @xmath536 , @xmath537 .",
    "the parameters of the nig random variable @xmath9 are @xmath538 , @xmath539 , @xmath540 and @xmath541 .",
    "the variance reduction obtained for different value of @xmath536 are summarized in the tabular [ tab - trans - esscher ] .",
    "the number of iterations in the robbins - monro variance reduction procedure is @xmath542 and the number of monte carlo iterations is @xmath543 .",
    "note that for each strike , the prices are computed using the same pseudo - random number generator initialized with the same _",
    "seed_.    .variance reduction for different strikes ( one dimensional nig example ) .",
    "[ cols=\"<,^,^,^,>,^ , > \" , ]     0 ( 2005 ) .",
    "stability of stochastic approximation under verifiable conditions .",
    "_ siam j. control optim .",
    "_ , * 44*(1 ) , no .",
    "1 , 283312 ( electronic ) . ( 2004 ) .",
    "adaptative monte carlo method , a variance reduction technique .",
    "_ monte carlo methods and appl .",
    "_ , * 10*(1 ) , 124 .",
    "_ numerical methods for stochastic processes _ , wiley series in probability and mathematical statistics : applied probability and statistics . a wiley - interscience publication .",
    "john wiley & sons , inc .",
    ", new york , 359 pp .",
    "isbn : 0 - 471 - 54641 - 0 .",
    "efficient variance reduction for functionals of diffusions by relative entropy , technical report , cermics - enpc ( france ) .",
    "_ adaptive algorithms and stochastic approximation _ , * 22 * , _ applications of mathematics _ , transl . from french by s. wilson , springer - verlag , berlin .",
    "_ stochastic approximation procedure with randomly varying truncations _ , scientia sinica series .",
    "convergence and robustness of the robbins - monro algorithm truncated at randomly varying bounds , _ stoch .",
    "_ , * 27*(2 ) , 217231 .",
    "_ iterative random models _ , transl . from french , springer - verlag",
    "_ monte carlo methods in financial engineering _ , springer .",
    "asymptotically optimal importance sampling and stratification for pricing path - dependent options .",
    "finance _ * 9*(2 ) , no .",
    "2 , 117152 . ( 2000 ) .",
    "weak approximation of killed diffusion using euler schemes , _ stoch .",
    "_ , * 87*(2 ) , 167197 .",
    "optimal importance sampling parameter search for lvy processes via stochastic approximation , pre - print .",
    "stochastic approximation and recursive algorithms and applications , springer .",
    "( 2007 ) . _",
    "algorithmes stochastiques et options parisiennes _ ,",
    "thse de lenpc , 151p .",
    "an adaptive scheme for the approximation of dissipative systems , _ stoch .",
    "proc . appl .",
    "_ , * 117*(10 ) , 14911518 .",
    "( 1998 ) . _ continuous martingales and brownian motion _ ,",
    "@xmath544  edition , springer , berlin , 1998 ( @xmath545 edition , 1990 ) .",
    "asymptotic almost sure efficiency of averaged stochastic algorithms .",
    "siam j. control optim . * 39*(1 ) , 4972 ( electronic ) .",
    "_ diffusions , markov processes and martingales _ , @xmath546  edition , cambridge mathematical library .",
    "we propose below the proof of the slight extension of the regular robbins - monro algorithm when @xmath547 is not reduced to a single equilibrium point .",
    "the key is still the convergence theorem for non negative super - martingales .",
    "set @xmath548 , @xmath549 .",
    "let @xmath550 .",
    "then @xmath551 where @xmath552\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } = h(\\theta_n , z_{n+1 } ) - h(\\theta_n),\\ ] ] is an increment of ( local ) martingale satisfying @xmath553\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\le c(1 + {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } |\\theta_n-\\theta^*|^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}})$ ] owing to the assumptions on @xmath259 and schwarz inequality which also implies that @xmath554\\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } \\le \\frac 12 {      { \\ifcase 6\\or      ( \\or       \\bigl(\\or       \\bigl(\\or       \\biggl(\\or       \\biggl(\\or       \\left(\\fi } {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta_n-\\theta^ *      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } + {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } h(\\theta_n , z_{n+1 } )      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi } } } { \\ifcase 6\\or      ) \\or       \\bigr)\\or       \\bigr)\\or       \\biggr)\\or       \\biggr)\\or       \\right)\\fi } }       \\le c(1 + {     \\e\\ ! { } {      { \\ifcase 6\\or      [ \\or       \\bigl[\\or       \\bigl[\\or       \\biggl[\\or       \\biggl[\\or       \\left[\\fi } {      { \\ifcase 1\\or      \\lvert\\or       \\bigl\\lvert\\or       \\bigl\\lvert\\or       \\biggl\\lvert\\or       \\biggl\\lvert\\or       \\left\\lvert\\fi } \\theta_n-\\theta^ *      { \\ifcase 1\\or      \\rvert\\or       \\bigr\\rvert\\or       \\bigr\\rvert\\or       \\biggr\\rvert\\or       \\biggr\\rvert\\or       \\right\\rvert\\fi}}^2 { \\ifcase 6\\or      ] \\or       \\bigr]\\or       \\bigr]\\or       \\biggr]\\or       \\biggr]\\or       \\right]\\fi}}},\\ ] ] for an appropriate real constant @xmath42 .",
    "then , one shows by induction on @xmath487 from  ( [ ineql2 ] ) that @xmath555 is square integrable for every @xmath556 and that @xmath557 is integrable , hence a true martingale increment .",
    "now , one derives from the assumptions  ( [ stepcond ] ) and  ( [ ineql2 ] ) that @xmath558 is a ( non negative ) super - martingale with @xmath559 .",
    "this uses the mean - reverting assumption  .",
    "hence @xmath560 is @xmath561-@xmath67 converging toward an integrable r.v .",
    "@xmath562 . consequently , using that @xmath563 , one gets @xmath564 the super - martingale @xmath565 being @xmath566-bounded , one derives likewise that @xmath567 is @xmath566-bounded since @xmath568 now , a series with nonnegative terms which is upper bounded by an ( @xmath67 ) converging sequence , @xmath67 converges in @xmath233 so that @xmath569 it follows from  ( [ cvrz ] ) that , @xmath561-@xmath67 , @xmath570 which is integrable since @xmath571 is @xmath566-bounded and consequently @xmath67 finite .    let @xmath572 . set @xmath573 it follows from the @xmath67 finiteness of @xmath574 that @xmath575 @xmath67 .",
    "now we consider the compact set @xmath576 .",
    "it is separable so there exists an everywhere dense sequence in @xmath577 , denoted for convenience @xmath578 .",
    "the above proof shows that @xmath561-@xmath67 , for every @xmath579 , @xmath580 as @xmath581 .",
    "then set @xmath582 which satisfies @xmath583 .",
    "assume @xmath584 .",
    "up to two successive extractions , there exists a subsequence @xmath585 such that @xmath586 the function @xmath66 being continuous @xmath587 which implies that @xmath588 .",
    "hence @xmath589 .",
    "then any limiting value @xmath590 of the sequence @xmath591 will satisfy @xmath592 which in turn implies that @xmath593 by considering a subsequence @xmath594 .",
    "so , @xmath595 is the unique limiting value of the sequence @xmath596",
    "@xmath171 @xmath597 as @xmath581 .",
    "the fact that the resulting random vector @xmath598 is square integrable follows from fatou s lemma and the @xmath599-boundedness of the sequence @xmath600.@xmath133"
  ],
  "abstract_text": [
    "<S> we propose an _ unconstrained _ stochastic approximation method of finding the optimal measure change ( in an _ a priori _ parametric family ) for monte carlo simulations . </S>",
    "<S> we consider different parametric families based on the girsanov theorem and the esscher transform ( or exponential - tilting ) . in a multidimensional gaussian framework , arouna uses a projected robbins - monro procedure to select the parameter minimizing the variance ( see @xcite ) . in our approach , </S>",
    "<S> the parameter ( scalar or process ) is selected by a classical robbins - monro procedure without projection or truncation . to obtain this unconstrained algorithm </S>",
    "<S> we intensively use the regularity of the density of the law without assume smoothness of the payoff . </S>",
    "<S> we prove the convergence for a large class of multidimensional distributions and diffusion processes .    </S>",
    "<S> we illustrate the effectiveness of our algorithm via pricing a basket payoff under a multidimensional nig distribution , and pricing a barrier options in different markets .    _ </S>",
    "<S> key words : stochastic algorithm , robbins - monro , importance sampling , esscher transform , girsanov , nig distribution , barrier options . _ </S>"
  ]
}