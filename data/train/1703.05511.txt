{
  "article_text": [
    "optimising the design of experiments is an important consideration in many areas of science , including , but not limited , to : biology ( @xcite ) , clinical trials ( @xcite ) and epidemiology ( @xcite ) .",
    "the theory of optimal experimental design is a statistical framework that allows us to determine the optimal experimental protocol to gain the most information about model parameters , given constraints on resources .    in evaluating an optimal bayesian design ,",
    "there are two main components : the search across the design space , and the evaluation of the utility .",
    "there have been many approaches to improving the efficiency of both aspects , summarised by @xcite .",
    "recently , @xcite proposed the approximate coordinate exchange ( ace ) algorithm for finding optimal bayesian experimental designs efficiently .",
    "the method utilises a coordinate exchange algorithm to update one dimension of the design at a time , coupled with a gaussian process in order to search each dimension efficiently .",
    "@xcite proposed an abc - based approach to evaluating the utility in an efficient manner , embedded within an exhaustive search of the design space .",
    "the overall optimal design tool lends itself to evaluating multiple criteria simultaneously ( _ i.e. _ , simultaneously evaluate different utilities for each design ) , albeit without any sensible search mechanism across the design space .",
    "it has been asserted that the future of optimal bayesian experimental design lies in the ability to evaluate the optimal designs for large - scale problems ( _ i.e. _ , large or high - dimensional design spaces ) , in a computationally - efficient manner ( @xcite ) . in this paper",
    ", we address this by proposing a new , efficient search algorithm which is more efficient than the current `` gold - standard '' ace algorithm .",
    "the search heuristic we present performs targeted sampling of the design space to find high utility designs , without making any assumptions about the shape of the utility function .",
    "the algorithm determines similarly well - performing designs as determined by ace ( @xcite ) , with greater computational efficiency .",
    "our method borrows the idea of targeting regions of high utility , as per the mcmc approaches , by sampling new designs at each iteration around the `` best '' designs .",
    "the `` best '' designs are chosen according to some acceptance criteria ; in this work we consider two alternative approaches .",
    "first , we consider accepting all points that are within some proportion of the current maximum objective ( utility ) function , and increase this proportion towards one as the algorithm progresses ( _ i.e. _ , such that only designs that perform as well as the optimal are retained ) .",
    "this choice of acceptance criteria is similar to a fully adaptive cross - entropy algorithm ( @xcite ) , in that the number of `` elite '' samples accepted at each iteration is changed .",
    "alternatively , this increasing cut - off can be thought of in a similar way to an _ annealing schedule _ in a simulated - annealing algorithm ( @xcite ) . the initial cutoff value , and the rate at which the cutoff increases towards one controls the trade - off between exploration and exploitation , as in existing algorithms ( e.g. , the annealing schedule in a simulated - annealing algorithm , @xcite , or the proportion of `` elite '' samples retained in a cross - entropy algorithm , @xcite ) .",
    "second , we consider accepting a fixed number of samples at each iteration of the algorithm , in the same way as a standard cross - entropy algorithm ( @xcite ) .",
    "however , in both scenarios , rather than updating a sampling distribution at each iteration based on a combination of the  best \" samples  as in a cross - entropy or a genetic algorithm  we propose new samples around each of these  best \" samples independently , in a similar way to a sequential importance sampling algorithm .",
    "we describe this algorithm using the notion of  survival - of - the - fittest \" , as the `` fittest '' individuals  according to their objective ( utility ) function value  survive at each iteration ( generation ) based on a user - defined acceptance criteria , to produce offspring for the next generation .",
    "hence , we refer to this new algorithm as an induced natural selection heuristic ( insh ) .    by independently sampling new designs around each accepted design , we aim to avoid the pitfalls associated with some other optimisation routines . for example",
    ", insh is able to sample multiple regions of high utility at a time , thus exploring multiple optima simultaneously , rather than potentially being stuck at a local optima .",
    "furthermore , by not combining the retained designs in any way , insh avoids the potential to move to a region of low utility when there are multiple modes that is at the  centre \" of the modes  as may occur in a cross - entropy or genetic algorithm . by taking a sampling approach ,",
    "as opposed to trying to approximate the function , insh makes no assumptions about the shape of the utility function ",
    "thus , it is not limited to utility functions that are , for example , smooth .",
    "utilising ( embarrassingly ) parallel computation tools , the method can evaluate the utility for a large number of designs in each iteration , in an efficient manner .",
    "the ace algorithm of @xcite has allowed the consideration of bayesian optimal designs for a larger , more - complex class of statistical models and experiments than was possible with previous algorithms .",
    "there are a number of drawbacks to the ace algorithm , however . by searching in one - dimension at a time",
    ", the ace algorithm risks missing the globally optimal design , and instead finding only local - optima .",
    "the authors approach to avoid this is to re - run the algorithm from a number ( typically 20 ) of randomly generated initial designs .",
    "similarly , as noted by the authors , by searching in one - dimension at a time , the algorithm will be inefficient in scenarios where there is a large correlation between the design variables  a problem which adds to the difficulty in choosing a suitable number of iterations for each phase of the algorithm .",
    "the algorithm requires a sufficiently good estimate of the utility when determining whether to accept the candidate design  spurious estimates may lead to sub - optimal candidate designs being accepted , and thus push the algorithm away from regions of high utility .",
    "alternatively , a large improvement in the computation time comes about from the estimation of the utility surface in each dimension in the form of a gaussian process based on a number of candidate points .",
    "this approximation to the utility surface based on noisy evaluations of the utility aims to provide a smooth approximation to the surface . when the surface is not smooth , or has a discontinuity ( e.g. , the utility surface corresponding to the death model in figure [ deathmodel : fullutilitysurface ] ) , this may cause significant problems for the ace algorithm in finding optimal designs .    in the following , we present the insh search algorithm in a general framework , and we note that efficient evaluation of the utility is another problem that needs to be addressed .",
    "we consider two existing approaches to evaluating the utility : the method used in abcde ( @xcite ) in a scenario where the benefits of this approach are realised ; and a nested monte - carlo approximation using code from the ` acebayes ` package ( @xcite ) .",
    "we consider the problem of finding the optimal design for two stochastic models  the death model , and a pharmacokinetic ( pk ) model tracking the concentration of a drug or treatment in the blood . in the death and pk examples ,",
    "a design @xmath3 consists of @xmath4 sampling times @xmath5 , subject to some problem - specific constraints .",
    "the first problem we address is when to observe the stochastic process in order to gain the most information about the model parameters .",
    "the stochastic death model has been considered previously in a bayesian framework by @xcite , @xcite , and @xcite .",
    "we evaluate the optimal experimental designs for 1 - 4 observation times , in order to demonstrate the efficacy of the method , and the relative improvement in computation time .",
    "second , we consider the optimal bayesian experimental design for a pk model  a process where the design space is a considerably higher - dimension  in order to demonstrate the efficiency of the insh algorithm for larger design spaces .",
    "the optimal designs are compared to those evaluated using the `` gold - standard '' approximate coordinate exchange algorithm of @xcite .",
    "we also consider the idea of sampling windows for this example , which have been considered previously by @xcite , @xcite , @xcite , @xcite , and @xcite , for example .",
    "the idea of sampling windows allows those implementing an optimally - chosen design some flexibility in choosing the sampling times , such that the resulting design is more practically feasible . by defining sampling windows",
    ", we can dictate a set of near - optimal designs  which are practically feasible  which can be implemented more easily .",
    "this avoids the scenario where an inferior design is chosen preferentially by those that are implementing the design , having been supplied with an impractical optimal design .",
    "the aim of optimal experimental design is to determine the best experimental protocol in order to maximise some utility of the experiment . to achieve this aim , we specify a utility function @xmath6 representing how we ` value ' the experimental design @xmath3 , chosen from the set of all designs @xmath7 , where @xmath8 represents the model parameters and @xmath9 is the data .",
    "we are interested in the expected utility of using design @xmath3 , over the unknown model parameters and data .",
    "that is , we wish to evaluate , @xmath10 \\notag \\\\          & =   \\int_{\\boldsymbol{x } } \\int_{\\boldsymbol{\\theta } } u(\\boldsymbol{\\theta},\\boldsymbol{x } , d ) p(\\boldsymbol{x } \\mid \\boldsymbol{\\theta},d ) p(\\boldsymbol{\\theta } ) d\\boldsymbol{\\theta } d\\boldsymbol{x } ,      \\label{utilitydefn}\\end{aligned}\\ ] ] where @xmath11 is the likelihood function of the unobserved data @xmath9 , under design @xmath3 , and @xmath12 is the prior distribution of the model parameters . the optimal design @xmath13 maximises the expected utility over the design space @xmath7 , that is , @xmath14 .",
    "the utility function we use throughout this work is the kullback - leibler divergence ( @xcite ) from the prior distribution to the posterior distribution ( which is independent of @xmath8 ) , @xmath15 which leads to an expected utility : @xmath16 see @xcite for details of the derivation .",
    "alternatively , it is commonplace to consider the shannon information gain ( sig ) , which can be written as : @xmath17 through the application of bayes theorem .",
    "maximisation of the expected sig is equivalent to maximisation of the expected kullback - leibler divergence above",
    ".    analytic evaluation of the expected utility function @xmath18 is typically not possible . in light of this limitation",
    ", @xcite proposed an mcmc sampling scheme from the joint probability distribution , @xmath19 .",
    "sampling from @xmath20 in this way allows us to obtain samples from a distribution that is proportional to @xmath18 by considering the marginal distribution of @xmath21 in @xmath3 .",
    "the approximate optimal experimental design is thus obtained as the mode of the function proportional to @xmath18 , as determined by the samples from the mcmc sampling scheme . the mcmc sampling scheme defined by @xcite",
    "is outlined in online resource a. for further details , extensions , and comments on the algorithm , see @xcite .",
    "the difficulty in evaluating the mode of a high - dimensional utility surface is one of the limiting factors of the mcmc algorithms for evaluating optimal experimental designs for a large number of design variables ( @xcite ) .",
    "the approximate coordinate exchange algorithm of @xcite directly addresses the need for a computationally efficient algorithm for determining optimal bayesian experimental designs in large - dimensional design spaces ( @xcite ) .",
    "the reader is directed to @xcite for full details of the algorithm .",
    "briefly , the algorithm considers each dimension of the experimental design one - at - a - time ( e.g. , the first observation time in an observation schedule ) , and evaluates the utility at a number of new , candidate values in that dimension ( e.g. , consider the utility at each of @xmath22 equally spaced times across the feasible range of observation times , conditional on the other elements of the design ) .",
    "having obtained these approximate utilities across the feasible range for the particular dimension of the design , a gaussian process is fit to these candidate values to find an approximate `` optimal '' value as an update to this dimension of the design ( accepted with some probability ) .",
    "the algorithm cycles through each design variable ( probabilistically ) updating them to the best value according to the gaussian process approximation to the utility .",
    "the ace algorithm is the first algorithm that is capable of dealing with designs in large dimensional design spaces , in a computationally feasible amount of time .      in the following work , we utilise the efficient approach to evaluating the utility used in the abcde algorithm by @xcite , within the insh algorithm .",
    "we give a brief description here , and detail the abcde algorithm in online resource a. the abcde algorithm evaluates the utility of a collection of designs ( in @xcite , this collection was all designs across an exhaustive grid on the design space ) simultaneously in an embarrassingly parallel fashion using , e.g. , ` parfor ` in matlab , or the ` doparallel ` and ` foreach ` packages ( @xcite ) in r ( @xcite ) . for each design ,",
    "we pre - simulate @xmath23 data sets from the model , corresponding to parameters independently sampled from the prior distribution .",
    "we use each set of the pre - simulated data as the `` observed datum '' one - by - one , and evaluate the utility using all the @xmath23 data as  simulated data \" .",
    "this creates a set of posterior samples having observed every set of simulated data for a particular design .",
    "that is , for simulated data @xmath24 under design @xmath3 , we determine approximate bayesian computation ( abc ) posterior distributions @xmath25 $ ] using a standard rejection abc algorithm ( detailed in online resource a ) .",
    "we pre - simulate data across all designs and thus we can pass pre - simulated data and corresponding parameter values to the abc rejection - algorithm .",
    "this increases memory requirements , but saves on simulation effort , since we do not simulate new parameter values and data each time , as would typically be done in an abc rejection - algorithm .",
    "we evaluate the utility using each of these @xmath23 posterior distributions under a particular design , and take the average of these @xmath23 values to be our measure of the expected utility for that design .",
    "one of the main advantages of this approach to evaluating the utility comes about for discrete data , and when the number of unique datum are small compared to the number of simulations considered , @xmath23 .",
    "we evaluate a single ( approximate ) posterior for each unique datum only , as the approximate posterior distributions for each of the data sets will be the same ( ignoring the removal of the sampled parameter that was used to produce the data set we are currently considering ) .",
    "we note that it is often not the case that we have discrete data , or , we may wish to consider a large number of design points where the dimension of the data is increased . in these cases ,",
    "this advantage is lost .",
    "hence , we consider this approach to evaluate the utility for the death model only .",
    "in the following , we present a new algorithm to find optimal bayesian experimental designs efficiently . given the current advantages of parallel computing  which are rapidly improving as parallel - computing becomes more widely - available , more easy to implement , and more powerful ",
    "we wish to retain some of the parallel aspects of the abcde algorithm ( or other optimisation routines , for example , @xcite ) . however , we embrace an advantageous aspect of the mcmc search algorithms implemented by @xcite , @xcite , and @xcite , namely , we seek to spend less computational effort evaluating designs in low - utility regions .",
    "this forms the crux of the efficiency of an mcmc approach , and is achieved by sampling from a function proportional to the utility , and hence , more samples are taken from regions of high utility . however , mcmc is inherently sequential , in that the next design is chosen after evaluating the current design , and so it can not be parallelised efficiently .",
    "the new algorithm we propose instead evaluates the utility of multiple designs simultaneously  in order to retain the parallel nature that was advantageous in the abcde algorithm  and samples new designs at each iteration of the algorithm around designs satisfying some acceptance criteria .",
    "the acceptance criteria for designs at each iteration can be chosen in a number of different ways . in this paper",
    ", we demonstrate an increasing cut - off for the proportion of utility compared to the current maximum , similar to an annealing schedule in a simulated - annealing algorithm ( @xcite ) , or alternatively , accepting a fixed number of the `` best '' designs , similar to the proportion of `` elite '' samples in a cross - entropy algorithm ( @xcite ) .",
    "however , in contrast to these existing optimisation algorithms , the algorithm presented here considers multiple designs at each iteration , allowing us to explore the design space more efficiently .",
    "the insh algorithm is detailed in algorithm [ insh_algorithm ] .",
    "note that in order to continue to explore the region near the current optimal design , the optimal design that has been considered thus far is re - introduced into the set of designs that are to be sampled around , at each iteration .",
    "choose an initial set of designs .",
    "@xmath26 ( e.g. , a coarse grid of design points across the design space , or randomly sample ) .",
    "specify the number of generations ( iterations ) of the algorithm @xmath27 , a perturbation function @xmath28 , and the acceptance criteria .",
    "for each design @xmath29 , sample parameters @xmath30 , and simulate data @xmath31 from the model .",
    "evaluate utility @xmath32 , for each design @xmath33 .",
    "[ insh_evaluate_utility ] set @xmath34 to be the designs which satisfy the acceptance criteria , and the current optimal design @xmath13 ( even if it occurred in a previous generation ) .",
    "sample @xmath35 designs from @xmath28 , for each @xmath36 . set @xmath26 to be these newly sampled designs .",
    "set of designs @xmath3 , and corresponding utilities @xmath18 ( and hence , the optimal design @xmath37 )",
    ".      an efficient approach to evaluate the utility of a design in step [ insh_evaluate_utility ] of algorithm [ insh_algorithm ] is the same approach used in the abcde algorithm ( @xcite ) .",
    "in particular , we use steps 3 to 9 of algorithm 2 , in online resource a. note that this approach is suitable for discrete data , and for low - dimensional design spaces .",
    "this is due to the majority of the efficiency coming from having to evaluate a posterior distribution only once for each unique data set , as described previously . as the number of possible unique data sets increases  for example ,",
    "either by observing the process more often ( increasing the size of the design space ) , or having a larger population  this approach becomes less efficient .",
    "we use this approach to demonstrate the efficacy of the insh algorithm for the markovian death model .    for cases where the dimension of the data is too large ( or continuous ) , we must consider an alternative approach to evaluating the utility for each design . as noted previously ,",
    "this is one of the two main challenges when considering bayesian optimal experimental design .",
    "a suitable and efficient method for evaluation of the utility for a design is often problem - specific , and a number of different approaches have been considered  a summary of these approaches can be found in @xcite . for the pharmacokinetic example we consider subsequently , we implement the utility function of @xcite provided in the ` acebayes ` package in r. briefly , the sig utility in equation , is estimated by a nested monte - carlo approximation of the values @xmath38 and @xmath39 , within the monte - carlo approximation to the expected utility , @xmath40 .",
    "borrowing the notation of @xcite , define @xmath41 to be the combination of the parameters of interest , @xmath8 , and nuisance parameters , @xmath42 .",
    "then , we use @xmath43 simulations to approximate the inner monte - carlo estimates : @xmath44 where @xmath45 are the @xmath43 parameters sampled from the prior distribution of @xmath46 .",
    "similarly , @xmath47 simulations are used to evaluate the outer monte - carlo estimate , @xmath48,\\end{aligned}\\ ] ] with @xmath49 parameters , and corresponding simulations , sampled from the prior and simulated from the model , respectively . in the work of @xcite",
    ", the authors use @xmath50 to evaluate the candidate designs utilities in the one - dimensional search ( step 1b of the ace algorithm in @xcite ) , and @xmath51 to evaluate the utility when determining whether to accept the candidate design ( steps 1d and 3e of the ace algorithm in @xcite ; note that step 3 is not implemented for the compartmental model ) . as the insh method considers the utility of multiple designs simultaneously , and multiple designs in each region , rather than searching for the optimal design sequentially , we are able to use significantly less effort ( _ i.e. _ , monte carlo simulations ) to evaluate the utility of each design without detriment to the results .",
    "there are a number of ways the  best \" designs can be retained at each iteration of the insh algorithm .",
    "we propose the following two approaches , which we implement for the markovian death model and pharmacokinetic examples respectively .",
    "first , we propose that those designs which correspond to a utility within some percentage of the current maximum utility are retained .",
    "that is , keep all @xmath52 such that @xmath53 , @xmath54 , @xmath55 , where @xmath13 is the `` best '' design considered up to generation @xmath56 of the algorithm .",
    "the proportional cut - off @xmath57 should increase steadily from some initial value in ( 0,1 ) , up to the maximum of one . the rate at which the cut - off increases balances the trade - off between exploration and exploitation , as in other optimisation routines ( e.g. , the rate at which the annealing schedule converges to zero in simulated - annealing , or the proportion of `` elite '' samples retained in a cross - entropy algorithm ) . as the insh algorithm progresses ,",
    "later generations of candidate designs will ( ideally ) be located closer to the optimal design than many of the earlier generations . if the region containing the optimal design is retained throughout the algorithm , naturally , this region is explored better than regions of low utility .",
    "however , as the cut - off for the utility approaches one , there may be very few designs accepted / retained and thus very few new designs to be considered .",
    "hence , it is sensible to replace the number of sampled designs at each generation , @xmath35 , with a non - decreasing sequence of samples @xmath58 , @xmath55 , such that later generations ( _ i.e. _ , those closer to the optimal ) produce more offspring . hence , we sample more designs around the optimal design , and thus get better resolution in this region .    one downside of this approach to the acceptance criteria is that all designs in the initial waves of the algorithm may be within the initial cutoff @xmath59 .",
    "hence , the algorithm accepts _ all _ designs , and thus samples many designs in the following iteration .",
    "it is possible that this occurs for multiple generations of the algorithm , resulting in a large increase in the computation time , as a larger portion of the design space is explored .",
    "thus , one must first analyse the distribution of utilities across the design space in order to choose a sensible sequence for @xmath57 . in the name of producing an efficient algorithm which is more simple to implement  out - of - the - box \" ,",
    "we propose the following alternative .",
    "the second approach we propose is similar to the `` elite '' samples of a cross - entropy algorithm ( @xcite ) .",
    "that is , at each generation , the algorithm accepts the best @xmath60 designs , based on the utility . at the next generation of the algorithm",
    ", we sample @xmath35 designs from the perturbation kernel from each of these @xmath60 designs .",
    "similar to the first approach , one may sensibly propose an increasing number of samples @xmath58 at each generation in order to provide better resolution around the optimal design .",
    "similarly , the number of `` elite '' samples can be altered at each generation , as is done in a fully - adaptive cross - entropy algorithm ( @xcite )  increasing exploitation at later stages of the algorithm at the cost of exploration .",
    "given one dictates the number of samples that are accepted at each generation , @xmath61 , and the number of new samples at each generation , @xmath58 , this ensures full control over the number of designs considered at each generation of the algorithm , allowing more control over the computational effort .",
    "thus , one may reasonably evaluate the optimal ( or near - optimal ) bayesian design in a computationally efficient time - frame .",
    "the perturbation kernel is used to sample new designs at each generation of the insh algorithm . in the two examples we consider in this work",
    ", we use a truncated , multivariate - normal distribution ( where the dimension is given by the dimension of the design space , and the truncation is to ensure constraints are satisfied ) .",
    "one could alternatively sample from any symmetric distribution , centred on the current design points .",
    "a standard cross - entropy algorithm uses the accepted samples to define the mean and ( co-)variance structure of a ( multivariate-)normal distribution , and all new samples are generated by this distribution .",
    "we prefer to avoid this approach , rather , allowing the region surrounding each accepted point to be explored individually . combining all accepted samples into a single distribution",
    "from which to sample , may result in new samples not being generated in regions of high utility ( for example , when considering multi - modal utility surfaces ) , and requires re - evaluation of the ( co-)variance matrix at each generation .",
    "a common feature of optimisation tools is a criterion for stopping the algorithm",
    ". it would be straight - forward for the user to implement a stopping criteria based on the change in utility of newly sampled designs at each iteration of the algorithm , based on the desired level of accuracy . in the examples in this work , we choose to demonstrate the algorithm by running it for a fixed number of iterations .",
    "consider the markovian death model as defined by @xcite . there is a population of @xmath62 individuals which",
    ", independently , move to an infectious class @xmath63 at constant rate @xmath64  for example , due to infection from an environmental source .",
    "the markov chain models the number of infectious individuals at time @xmath65 , @xmath66 ( where the number of susceptible individuals is @xmath67 ) .",
    "the positive transition rates of the markov chain are given by @xmath68 , for @xmath69 .",
    "the prior distribution we consider is @xmath70 , chosen such that the mean lifetime of individuals in the population is one , with an approximate variance of 0.01 ( as per @xcite ) .",
    "the optimal experimental design for the markovian death model has previously been considered in a bayesian framework by @xcite , @xcite , and @xcite .",
    "@xcite utilised the mcmc approach of @xcite , and used an exact posterior , hence , the designs of @xcite provide a gold - standard with which to compare our results .",
    "@xcite also utilised the mcmc approach of @xcite , however , coupled with an approximate posterior distribution evaluated via an abc approach .",
    "we note however , that the mcmc approach struggles to evaluate the optimal design once the dimension of the design space is more than four .",
    "this is due to the increasing computational difficulty associated with the evaluation of the mode of the multi - dimensional utility surface .",
    "@xcite provided an exhaustive - search across a grid on the design space , where the posterior distributions , and hence the utility , were evaluated using an abc method .",
    "the insh code for the death model is implemented in matlab r2015b .",
    "consider the pharmacokinetic experiment considered by @xcite and @xcite . in these pharmacokinetic experiments , individuals",
    "are administered a fixed amount of a drug .",
    "blood samples are taken in order to understand the behaviour of the drug within the body .",
    "let @xmath71 represent the observed concentration of the drug at time @xmath65 .",
    "we model the concentration as @xmath72 , where , @xmath73 is the mean concentration at time @xmath65 , and @xmath74 , @xmath75 , @xmath76 and @xmath77 .",
    "that is , @xmath78 the blood samples are taken within the first 24 hours after the drug is administered ( that is , @xmath79 $ ] ) , and it is not practical to take blood samples less than 10 - 15 minutes apart ( hence , @xmath80 ) .",
    "we wish to obtain information about the model parameters @xmath81 , where @xmath82 represents the first - order elimination rate constant , @xmath83 represents the first - order absorption rate constant , and @xmath84 represents the _ volume of distribution _  a theoretical volume that a drug would have to occupy in order to provide the same concentration as is currently present in the blood plasma , assuming the drug is uniformly distributed ( @xcite ) .    as per @xcite and @xcite ,",
    "the model parameters @xmath85 are assumed _ a priori _ to be independently , normally distributed on the log - scale , with mean @xmath86 , @xmath87 , and @xmath88 respectively , and variance 0.05 .",
    "@xcite demonstrate that the designs evaluated using their method are clearly better than those obtained via the dimension reduction schemes implemented by @xcite , and so we only compare our results to those of @xcite .",
    "@xcite , @xcite , @xcite , and @xcite have previously evaluated optimal bayesian experimental designs for pharmacokinetic models , either for a few sampling times ( less than five ) , or consider more observations through dimension reduction schemes ( e.g. , search across the two - parameters of a beta distribution , where the quantiles are scaled to give the observation times ) .",
    "@xcite are currently the only example of a method efficient enough to establish optimal bayesian designs for a system of this magnitude without implementing a dimension reduction scheme in a feasible amount of computation time .    furthermore",
    ", we show how the output of the insh algorithm can be used simply to construct _ sampling windows _  a range of values for each observation , rather than a fixed value for each observation time .",
    "the motivation for sampling windows , comes from the potential difficulty associated with implementing what is the  optimal design \" in a practical setting .",
    "sampling windows allow practitioners ( or those implementing the design ) to conduct each sample within a range of values , which may not be as informative as the optimal , but potentially more informative than the practical design that ends up being implemented .",
    "sampling windows have been considered previously for similar types of models , for example , in @xcite , @xcite , @xcite , @xcite , and @xcite , to name a few . as the output of the insh algorithm consists of a large number of designs sampled around regions of high utility  as opposed to a single design , as in ace",
    " the construction of sampling windows is a simple extension to the algorithm .",
    "the insh algorithm for the pharmacokinetic example is implemented in r ( version 3.3.0 ) .",
    "we wish to determine the optimal observation times for the markovian death model .",
    "we consider the optimal observation schedule when the number of observations permitted is @xmath89 or 8 .",
    "the designs and computation times for @xmath90 observation times are compared to existing results .",
    "the observation schedules and computation times for 6 and 8 observations are also provided in order to demonstrate the efficiency of this algorithm for larger design spaces .",
    "first , however , we demonstrate how the insh algorithm works by considering two observation times for the death model .",
    "we choose to implement the first approach to the acceptance criteria : that is , accept designs corresponding to a utility within an increasing proportional cut - off .",
    "we set @xmath91 , for @xmath92 , and @xmath55 , where @xmath93 ( we define the sequence in this way solely for reproducibility  any values can be specified for @xmath57 ) . at each generation , @xmath94 designs are sampled for each accepted design from the perturbation kernel  a normal distribution centred on the accepted design , with fixed standard deviation 0.15 for each design parameter , and zero covariances ( truncated subject to the design constraints , _",
    "i.e. _ , @xmath95 , @xmath96 )",
    ".    figure [ deathmodel : stagesofinsh ] shows the progression of the insh algorithm at each of the first eight generations . for comparison ,",
    "figure [ deathmodel : fullutilitysurface ] shows the full utility surface for the death model , evaluated using the abcde algorithm at all observation times across a grid with spacing 0.1 , with @xmath97 $ ] .",
    "we can clearly see the optimal design is on a ridge at approximately ( 0.9 , 2.8 ) .",
    "there is also a region of high utility around ( 0.7 , 2.0 ) .",
    "regions of low utility exist for very early @xmath98 ( and in particular , @xmath99 ) , or where both @xmath98 and @xmath100 are high ( e.g. , both above 3.5 ) . in figure [ deathmodel : stagesofinsh ] ,",
    "generation 2 ( figure [ insh_g2 ] ) clearly shows that regions of low utility are discarded early , and high utility regions are retained .",
    "generations 2 - 6 ( figures [ insh_g2]-[insh_g6 ] ) clearly demonstrate the convergence of the samples towards the region containing the optimal design .",
    "generation 6 demonstrates the samples converging about the two  peaks \" observed in figure [ deathmodel : fullutilitysurface ]  clearly demonstrating the ability to investigate multiple regions of high utility simultaneously .",
    "figure [ pk_insh_final_samples ] shows all design points considered throughout the insh algorithm , with each point shaded by the utility value ( darker corresponds to higher utility ) .",
    "the regions of high utility clearly have been sampled more thoroughly .",
    "+   +   +   +    online resource b contains box - plots illustrating the convergence of the sampled observation times towards the optimal , and the corresponding utilities towards the maximum .",
    "online resource b also contains tables with the optimal experimental designs determined using the insh algorithm compared to the existing methods ( along with the corresponding insh algorithm inputs ) , and the computation time compared to the abcde algorithm , respectively .",
    "these times are represented in figure [ death : comptimes_plot ] .",
    "figure [ death : comptimes_plot ] clearly depicts the improved efficiency of the insh algorithm for large dimensional design spaces compared to the abcde algorithm .",
    "in particular , we note the increase in computation time is dependent only on the algorithm inputs , which can be controlled by the user , rather than the size of the design space",
    ". note that the insh algorithm is slower than the abcde algorithm for the same number of designs , as the simulations are created at each generation  in the abcde algorithm , all simulations are created in parallel , prior to running the algorithm .",
    "it is clear that the computation times of the insh algorithm are much lower for more observation times compared to the abcde algorithm , as significantly less designs are considered .",
    "we choose the acceptance criteria to be a fixed number of `` elite '' samples at each generation .",
    "that is , we accept at each generation of the algorithm the best @xmath61 designs , and sample @xmath58 designs from the perturbation kernel using these `` best '' @xmath61 designs .",
    "we step down the value of @xmath61 , and increase the value of @xmath58 as @xmath101 increases , such that early iterations are geared towards exploration , while later iterations are focussed on exploitation . due to the physical constraints on the frequency at which sampling can be performed ( at least 15 minutes apart ) , we restrict the designs such that @xmath102 , @xmath103 .",
    "we sample designs from a multivariate - normal perturbation kernel with fixed standard deviation 0.20 , and zero covariance ( truncated subject to the design constraints ) .",
    "the first generation of designs were sampled uniformly from the viable design space , [ 0 , 24 ] , such that the designs satisfied the constraints .    in order to compare the run time of the ace algorithm to the insh algorithm",
    ", we implemented the ace algorithm as detailed in @xcite , ( _ i.e. _ , running 20 instances of the ace algorithm from the ` acebayes ` package in ( embarrassingly ) parallel across four cores ) . on an imac running osx",
    "10.11.4 with 4.0ghz intel core i7 processor and 32 gb memory , this took 15.53 hours .",
    "we did not include the run time of the post - processing utility evaluation of the 20 candidate designs , 20 times each , in order to establish the overall optimal design , for reasons we state shortly .    the ace algorithm for this example in @xcite",
    "was performed 20 times from random initial conditions , each for a total of 20 iterations .",
    "each iteration searches across each of the 15 dimensions of the design , and considers 20 candidate times to fit the gaussian process .",
    "thus , a total of @xmath104 designs are considered ( _ i.e. _ , utility evaluations ) in the ace algorithm , where @xmath105 of these utility evaluations are completed using significantly more monte carlo simulations .",
    "specifically , the utility for the 20 candidate times used to train the gaussian process are evaluated using @xmath50 monte carlo simulations , while the utility corresponding to the design with the proposed new observation time is evaluated using @xmath51 .",
    "the advantage of the insh algorithm is in the ability to consider a large number of designs in multiple regions , simultaneously .",
    "hence , it is sufficient to use less effort to evaluate the utility of each design , as poorly - estimated utilities will have less influence on the output of the algorithm . hence , we used @xmath106 for the evaluation of the utility of each design , which was completed in parallel on four cores ( using ` foreach ` and ` doparallel ` packages in r ) , on the same machine as stated above .",
    "we ran the insh algorithm for @xmath107 iterations , with @xmath108 randomly generated initial designs . at each iteration",
    ", we retained the  best \" 150 , 75 , 50 , 25 , and 10 designs , and proposed two , four , six , 12 and 30 new designs around each accepted design , for 12 iterations of each combination ( _ i.e. _ , @xmath109 )  maintaining consideration of 300 designs at each iteration , while increasing the exploitation and reducing exploration at each iteration .",
    "this run of the insh algorithm took approximately 2.23 hours ( approximately 7 times faster than the ace algorithm ) .",
    "having obtained the designs and utility evaluations from the insh algorithms , we perform the same post - processing utility evaluation on the 20 best considered designs , with 20 evaluations of the utility of each design with @xmath51 , in order to identify the overall optimal .",
    "the total number of designs considered by the insh algorithm with this selection criteria is approximately : @xmath110 . in practice",
    ", this number is often slightly higher , as the @xmath111 ranked design can be a tie , and the optimal design is re - introduced into the set of designs being considered if it occurred in a previous generation ( this run of the insh algorithm considered @xmath112 designs ) . in contrast , if we were to attempt to evaluate the utility at every design across a grid with spacing 0.05 ( e.g. , as in the abcde algorithm of @xcite ) , we would be required to evaluate @xmath113 designs  approximately @xmath114 times as many designs as were considered by the insh algorithm .",
    "figure [ pk_all_insh_designs ] shows box - plots of the 20 utility evaluations for each of the 20 best designs that were considered by the insh algorithm , compared to the same number of evaluations of the ace optimal design reported in ` optdescomp15sig ( ) ` in the ` acebayes ` package ( each utility evaluation using @xmath51 ) .",
    "we can see from this figure that there are three designs that perform similarly well to the design found using the ace algorithm .",
    "online resource c contains a table with summaries of the evaluated utilities for each design , a figure demonstrating convergence of the insh algorithm to the optimal region , and a figure demonstrating how well each design performs with respect to inference ( in particular , a comparison of the posterior variance , and the bias in posterior mode ) .",
    "monte carlo simulations .",
    "]      the nature of the insh algorithm means that we retain a large number of designs with high utility .",
    "we use these `` best '' designs to construct the sampling windows for each sampling time , similar to the approach of @xcite . @xcite",
    "use percentiles of the designs evaluated once a stopping - criteria has been reached in their algorithm to form the sampling windows , whereas we just choose a fixed number of `` best '' designs to form the windows .",
    "given the windows , the one implementing the design can then simply choose each observation time from these windows , ensuring that the physical constraint , @xmath80 , is satisfied .",
    "as an example of this process , we arbitrarily consider the top 20 designs from the output of the insh algorithm for the pharmacokinetic example , and form sampling windows as the range of values considered at each observation time for these `` best '' designs .",
    "alternatively , one could consider all designs that were within some percentage of the utility corresponding to the maximum , or , use a weighting based on the expected utility for each design to approximate a distribution for each sampling time which could subsequently be sampled . in order to construct the sampling window designs for the purpose of evaluating their utility , we  bootstrap \" an observation schedule by randomly selecting each of the 15 sampling times ( with equal probability ) , from the 20 candidate observation times , subject to the constraints .",
    "a new design is sampled for each of the 20 utility evaluations to demonstrate the range of potential outputs from this approach .",
    "figures [ pk_all_plots : sw_range ] and [ pk_all_plots : sw_density ] show the sampling windows for each observation time , calculated using the output of the insh algorithm .",
    "figure [ pk_all_plots : opt_comparison ] shows the optimal observation schedules evaluated using the ace and insh algorithms .",
    "note that the optimal design returned from the insh method , was that which corresponded to the @xmath115 highest utility value from the original output of the insh algorithm ( _ i.e. _ , using @xmath106 ) .",
    "it was deemed the optimal design as it corresponded to the highest mean utility , from 20 utliity evaluations using @xmath51 ( figure [ pk_all_insh_designs ] ) .",
    "figure [ pk_all_plots : util_comparison ] shows box - plots of 20 utility evaluations ( using @xmath51 ) for the ace and insh optimal designs , and the 20 randomly selected designs from the sampling windows .",
    "note that the average efficiency of the sampling windows designs compared to the insh optimal design is 99.07% .",
    "the results of the insh algorithm applied to the death model indicates the suitability of this method , compared to existing methods .",
    "the resulting optimal designs evaluated are near - identical to those evaluated by existing methods  especially abcde .",
    "this makes sense given the estimation of the utility at each design is performed using the same mechanism .",
    "we have omitted the comparison of designs with regards to inference , as the comparison between all existing methods was made in @xcite , and these new designs from insh are not significantly different to those previously considered  the main purpose of this example was to demonstrate the computational efficiency .",
    "the computation time is clearly reliant on the choice of parameters for the algorithm , however the conservative choices made for the death model have clearly demonstrated a vast improvement in the computation time compared to the abcde method , while also allowing a simple approach to evaluated optimal experimental designs for more than four dimensional design spaces that are not practically feasible with the mcmc approaches .",
    "the larger computation time for more observation times for the death model is due to the evaluation of the utility .",
    "as previously stated , the evaluation of the utility is efficient due to the consideration of only unique data sets .",
    "as the number of observation times increases , the number of unique data sets increases , and hence evaluation of the utility for each design is more computationally demanding .",
    "we used the insh algorithm to evaluate the optimal bayesian experimental designs for 15 observation times of the pharmacokinetic model .",
    "previous work had successfully considered fewer observation times ( e.g. , @xcite , @xcite ) , or a re - parameterisation of the problem in order to obtain optimal designs for a large number of sampling times in a computationally feasible amount of time ( @xcite ) .",
    "@xcite provided a significant step forward with their efficient approach to evaluating the optimal design for this model , with a high - dimension design space , that logically perform better than the re - parameterised designs considered previously . here , we have used the insh algorithm to evaluate bayesian experimental designs for the pharmacokinetic model , which slightly outperform those evaluated by the ace algorithm of @xcite .",
    "of particular significance is the small amount of computation time required to evaluate these designs  for the example we considered here , the insh algorithm found a number of well - performing designs in approximately 14% of the computation time of the ace algorithm .    for the pharmacokinetic example , we considered forming sampling windows for practical implementation of near - optimal designs .",
    "we showed that these sampling windows can be derived very simply from the output of the insh algorithm , with minimal post - processing .",
    "we showed that the sampling windows ( chosen in a completely uninformed manner ) provided a similar level of information to that provided by the optimal design evaluated from the insh algorithm .",
    "we note that in evaluating the optimal designs for the ace algorithm , @xmath51 was used .",
    "a more accurate estimate of the utility of each design is required in the ace algorithm , as one design is considered at a time , and subsequent designs considered are dependent on whether or not the new design coordinate is accepted .",
    "an `` extreme '' utility evaluation could push the algorithm from a region of high - utility , and thus the algorithm could converge to , or conclude whilst still in , a sub - optimal region .",
    "the insh algorithm considers a large number of designs simultaneously , and so a spurious utility evaluation has less of an impact on the overall output of the algorithm . by performing the post - processing of the `` best '' designs returned by the insh algorithm  as is done for the ace candidate designs as well",
    " we can use a sufficiently large amount of effort to evaluate the utility of these designs and thus have greater confidence in their estimated utility .",
    "we have not provided a proof that the insh algorithm will converge to the optimal design , however , one can see that in the limit ( _ i.e. _ , @xmath116 , @xmath117 and @xmath118 as @xmath119 , and sufficiently large @xmath35 ) , the insh algorithm will identify the optimal design .",
    "when searching for the design across a gridded design space , less restrictive conditions would be required to ensure convergence to the optimal solution . however , as with all optimisation routines , the aim of this algorithm is to find near - optimal designs in a computationally feasible amount of time .",
    "thus , practical algorithm inputs must be chosen , which may not guarantee convergence to the optimal solution . however",
    ", this trade - off is apparent in a number of existing optimisation routines  for example , simulated - annealing , cross - entropy , and genetic algorithms all have the potential to converge to local , rather than global , optima .",
    "furthermore , the authors believe that the choice of algorithm parameters , in particular those corresponding to the acceptance criteria ( proportion of maximum utility @xmath57 , or number of  elite \" samples @xmath60 ) and perturbation kernel ( distribution @xmath28 , and number of new samples @xmath58 ) , are quite intuitive , and thus , insh is easier to implement than some existing stochastic optimisation methods .",
    "we also note that , as with other stochastic optimisation routines , some trial - and - error may be required in order to choose suitable values of these parameters for particular problem classes .",
    "the insh algorithm we have presented here is quite general , and there exist many aspects of the algorithm which can be explored in order to improve the efficiency of the algorithm for different optimisation problems .",
    "for example , randomly incorporating a sample in a region of the design space that has either not been considered previously , or was dismissed earlier in the algorithm , may be a beneficial approach in order to increase exploration of the input space , and maximise the chances of obtaining the optimal solution .",
    "another important consideration will be to provide some general rules regarding the choice of algorithm inputs for a particular utility surface .",
    "for example , the initial samples could be used to approximate some characteristics of the utility surface , and provide some insight into sensible choices of the inputs for the algorithm . while we did not consider it here , increasing the number of utility evaluations which form the approximate expected utility",
    "could also be increased as the algorithm progresses , _",
    "i.e. _ , specify a sequence for @xmath43 and @xmath47 in the sig utility evaluation  ensuring more effort is spent evaluating a more precise estimate of the utility in regions near to the optimal design .",
    "one could also incorporate the noise in the utility evaluation in the acceptance criteria  discarding only those samples that have an upper limit below the threshold value .",
    "bayesian optimal experimental design has immense potential to inform the collection of data , so as to subsequently enhance our understanding of a variety of processes .",
    "however , a major impediment is the difficulty in evaluating optimal designs for problems with large , or high - dimensional , design spaces ; attempts at evaluating optimal experimental designs prior to the ace algorithm of @xcite have been restricted to considering no more than several design parameters , and typically , for relatively simple models . here",
    ", we have proposed an algorithm which improves the efficiency of the search across the design space , even compared to that of the ace algorithm .",
    "while it still requires identification of an efficient approach to evaluating the utility , this improvement in the search aspect of determining the optimal design is extremely beneficial . in particular ,",
    "coupled with advances in parallel computing  both in power and accessibility  this algorithm should prove to be a significant step towards the wide spread use of bayesian optimal experimental design .",
    "djp acknowledges the support of the bbsrc ( bb / m020193/1 ) awarded to olivier restif .",
    "jvr acknowledges the support of the arc ( future fellowship ft130100254 ; coe acems ) and the nhmrc ( cre prism@xmath1 ) .",
    "24 natexlab#1#1url # 1`#1`urlprefix    analytics , r. , weston , s. , 2015 .",
    "doparallel : foreach parallel adaptor for the ` parallel ' package .",
    "r package version 1.0.10 .",
    "analytics , r. , weston , s. , 2015 .",
    "foreach : provides foreach looping construct for r. r package version 1.4.3 .",
    "https://cran.r-project.org/package=foreach    berry , d.  a. , 2004 .",
    "bayesian statistics and the efficiency and ethics of clinical trials .",
    "statistical science 19 , 175187 .",
    "chenel , m. , ogungbenro , k. , duval , v. , laveille , c. , jochemsen , r. , aarons , l. , 2005 .",
    "optimal blood sampling time windows for parameter estimation using a population approach : design of a phase ii clinical trial .",
    "journal of pharmacokinetics and pharmacodynamics 32 .    cook , a.  r. , gibson , g.  j. , gilligan , c.  a. , 2008 .",
    "optimal observation times in experimental epidemic processes .",
    "biometrics 64  ( 3 ) , 860868 .    de  boer , p. , kroese , d.  p. , mannor , s. , rubinstein , r.  y. , 2005 . a tutorial on the cross - entropy method .",
    "annals of operations research 134 , 1967 .",
    "drovandi , c. , pettitt , a. , 2013 .",
    "bayesian experimental design for models with intractable likelihoods .",
    "biometrics 69 , 937948 .",
    "duffull , s.  b. , graham , g. , mengersen , k. , eccleston , j. , 2012 .",
    "evaluation of the pre - posterior distribution of optimized sampling times for the design of pharmacokinetic studies .",
    "journal of biopharmaceutical statistics 22 , 1629 .",
    "evans , g.  e. , keith , j.  m. , kroese , d.  p. , dec . 2007 .",
    "parallel cross - entropy optimization . in : simulation conference ,",
    "2007 winter .",
    ". 21962202 .",
    "faller , d. , klingmller , u. , timmer , j. , 2003 .",
    "simulation methods for optimal experimental design in systems biology .",
    "simulation 79 , 717725 .",
    "graham , g. , aarons , l. , 2006 .",
    "optimum blood sampling time windows for parameter estimation in population pharmacokinetic experiments .",
    "statistics in medicine 25 , 40044019 .",
    "green , b. , duffull , s.  b. , 2003 . prospective evaluation of a d - optimal designed population pharmacokinetic study .",
    "journal of pharmacokinetics and pharmacodynamics 30 .",
    "kullback , s. , leibler , r.  a. , 1951 . on information and sufficiency .",
    "the annals of mathematical statistics 22 , 7986 .",
    "mcgree , j.  m. , drovandi , c.  c. , pettitt , a.  n. , 2012 . a sequential monte carlo approach to derive sampling times and windows for population pharmacokinetic studies .",
    "journal of pharmacokinetics and pharmacodynamics 39 , 519526 .",
    "mller , p. , 1999 .",
    "simulation based optimal design . in : bernardo , j. ( ed . ) , bayesian statistics .",
    "oxford university press , pp .",
    "459474 .",
    "overstall , a.  m. , woods , d.  c. , 2016 .",
    "acebayes : optimal bayesian experimental design using the ace algorithm .",
    "r package version 1.2 .",
    "https://cran.r-project.org/package=acebayes    overstall , a.  m. , woods , d.  c. , 2016 .",
    "bayesian design of experiments using approximate coordinate exchange .",
    "http://dx.doi.org/10.1080/00401706.2016.1251495    pagendam , d.  e. , pollett , p.  k. , 2013 . optimal design of experimental epidemics . journal of statistical planning and inference 143  ( 3 ) , 563572 .",
    "price , d.  j. , bean , n.  g. , ross , j.  v. , tuke , j. , 2016 . on the efficient determination of optimal bayesian experimental designs using abc : a case study in optimal observation of epidemics .",
    "journal of statistical planning and inference 172 , 115 .",
    "r : a language and environment for statistical computing .",
    "r foundation for statistical computing , vienna , austria .",
    "https://www.r-project.org/    rutenbar , r.  a. , 1989 .",
    "simulated annealing algorithms : an overview .",
    "ieee circuits and devices magazine 5 .",
    "ryan , e.  g. , drovandi , c. , mcgree , j.  m. , pettitt , a. , 2015 .",
    "a review of modern computational algorithms for bayesian optimal design . international statistics review .",
    "ryan , e.  g. , drovandi , c.  c. , pettitt , a.  n. , 2015 .",
    "fully bayesian experimental design for pharmacokinetic studies .",
    "entropy 17 , 10631089 .",
    "ryan , e.  g. , drovandi , c.  c. , thompson , m.  h. , pettitt , a.  n. , 2014 . towards bayesian experimental design for nonlinear models that require a large number of sampling times .",
    "computational statistics & data analysis 70 , 4560 .    * supplementary materials for an induced natural selection heuristic for evaluating optimal bayesian experimental designs * +   + @xmath0disease dynamics unit , department of veterinary medicine , university of cambridge , cambridge cb3 0es , u.k . , + @xmath1school of mathematical sciences , university of adelaide , sa 5005 , australia + @xmath2 arc centre of excellence for mathematical & statistical frontiers +    appendix a contains existing algorithms referenced throughout the main text .",
    "appendix b contains the results , tables and figures corresponding to the markovian death model , as well as some discussion of the choice of inputs to the insh algorithm .",
    "appendix c contains the results , tables and figures corresponding to the pharmacokinetic model .",
    "appendix d contains figures and tables corresponding to the sampling windows for the pharmacokinetic model .",
    "_ existing algorithms _    algorithm [ ourabc ] describes the abc algorithm used by abcde and the insh algorithm ( for the death model ) to evaluate the posterior distribution",
    ".    observed data @xmath9 , simulated data @xmath120 , corresponding parameter values @xmath121 , and tolerance @xmath122 .",
    "evaluate discrepancies @xmath123 , creating particles @xmath124 for @xmath125 . using the posterior sample of parameters @xmath126 such that @xmath127 , evaluate utility .",
    "utility for current design , having observed @xmath9 , @xmath128 .",
    "algorithm [ abcdealgorithm ] describes the abcde algorithm of @xcite , to evaluate the optimal bayesian experimental design .",
    "choose grid over the parameter space for the discrete estimate of the utility , number of simulations @xmath23 , and tolerance @xmath122 .",
    "sample @xmath23 parameters @xmath8 from @xmath12 . for each of the @xmath23 parameters , and under every design @xmath3 in the design space @xmath7 , simulate process and store @xmath129 .",
    "[ abcde_algorithm_line3 ]    the optimal design @xmath37 .",
    "algorithm [ mullersalgorithm ] details the mcmc algorithm for determining bayesian optimal designs proposed by muller [ 1999 ] .",
    "number of samples @xmath35 , prior distribution of model parameters @xmath12 , and proposal density @xmath130 .",
    "choose , or simulate an initial design , @xmath131 .",
    "sample @xmath132 , simulate @xmath133 , and evaluate @xmath134.[mulleralgorithm : initial ] generate a candidate design , @xmath135 , from a proposal density @xmath136 .",
    "sample @xmath137 , simulate @xmath138 , and evaluate @xmath139 .",
    "[ mulleralgorithm : simdata ] calculate , @xmath140 generate @xmath141 set @xmath142 set @xmath143 + sample of @xmath35 designs , @xmath3 .",
    "_ markovian death model abc choices _    we provide the parameter choices for the abc algorithm used to evaluate the approximate posterior distributions when evaluating the utility for the markovian death model example .",
    "prior to running the abc algorithm ( algorithm [ ourabc ] ) , we sample @xmath144 parameter values from the prior distribution , and simulate data corresponding to each under each design . for each of 1 , 2 , 3 , 4 , 6 , and 8 observation times",
    ", we use a tolerance of 0.25 , 0.50 , 0.75 , 1.00 , 1.50 , 1.50 , respectively .",
    "we note however , that these choices are problem specific , and suggest that researchers undertake a pilot - study in order to determine sensible parameter choices , as one would do prior to using abc for inference .",
    ".comparison of the optimal observation times for the death process , from @xcite , @xcite , @xcite , and the insh algorithm .",
    "@xmath145 is the pre - determined number of observation times , and @xmath56 is the @xmath146 time . [ cols=\"^,^,^,^,^,^ \" , ]     figure [ pk_inference ] provides a comparison of the inferential performance of the two optimal designs  corresponding to insh and ace  with regards to bias in a point estimate , and the posterior variance .",
    "we simulated 100 experiments from random parameters drawn from the prior distribution , and evaluated an approximate posterior distribution using a metropolis - hastings algorithm ( retaining 100,000 samples from the posterior , following a burn - in of 10,000 ) .",
    "the bias is estimated as the difference between the map ( _ maximum a posteriori _ ) estimate and the true parameter value that created the simulated data .",
    "recall , the prior variance was 0.05 for each parameter .",
    "it appears as though the design evaluated by the insh algorithm performs marginally better with respect to the posterior variance  that is , the estimated variances are slightly lower for each parameter .",
    "the bias in the parameter estimates appears roughly equivalent between the two designs .",
    "d.  j. price , n.  g. bean , j.  v. ross , and j.  tuke . on the efficient determination of optimal bayesian experimental designs using abc : a case study in optimal observation of epidemics .",
    "_ journal of statistical planning and inference _ , 172:0 115 , 2016 ."
  ],
  "abstract_text": [
    "<S> bayesian optimal experimental design has immense potential to inform the collection of data , so as to subsequently enhance our understanding of a variety of processes . </S>",
    "<S> however , a major impediment is the difficulty in evaluating optimal designs for problems with large , or high - dimensional , design spaces . </S>",
    "<S> we propose an efficient search heuristic suitable for general optimisation problems , with a particular focus on optimal bayesian experimental design problems . </S>",
    "<S> the heuristic evaluates the objective ( utility ) function at an initial , randomly generated set of input values . at each generation of the algorithm , </S>",
    "<S> input values are `` accepted '' if their corresponding objective ( utility ) function satisfies some acceptance criteria , and new inputs are sampled about these accepted points . </S>",
    "<S> we demonstrate the new algorithm by evaluating the optimal bayesian experimental designs for two popular stochastic models : a markovian death model , and a pharmacokinetic model . </S>",
    "<S> the designs from this new algorithm are compared to those evaluated by existing algorithms , and computation times are given as a demonstration of the computational efficiency . a comparison to the current `` gold - standard '' method </S>",
    "<S> are given , to demonstrate that insh finds designs that contain a similar amount of information , but more computationally efficiently . </S>",
    "<S> we also consider a simple approach to the construction of sampling windows for the pharmacokinetic model using the output of the proposed algorithm .    * </S>",
    "<S> an induced natural selection heuristic for evaluating optimal bayesian experimental designs * +   + @xmath0disease dynamics unit , department of veterinary medicine , university of cambridge , cambridge cb3 0es , u.k . </S>",
    "<S> , + @xmath1school of mathematical sciences , university of adelaide , sa 5005 , australia + @xmath2 arc centre of excellence for mathematical & statistical frontiers +    * keywords : * bayesian optimal design ; optimisation heuristic ; stochastic models ; sampling windows </S>"
  ]
}