{
  "article_text": [
    "this paper presents a model for the spatio  temporal field of hourly ozone concentrations for subregions of the eastern united states , one that can in principle be used for both spatial and temporal prediction .",
    "it goes on to critically assess that model and the approach used for its construction , with mixed results .",
    "such models are needed for a variety of purposes described in ozone ( 2005 ) where a comprehensive survey of the literature on such methods is given , along with their strengths and weaknesses .",
    "in particular , they can be used to help characterize population levels of exposures to ozone in outdoor environments , based on measurements taken at often remote ambient monitors .",
    "these interpolated concentrations can also be used as input to computer models that incorporate indoor environments to more accurately predict population levels of exposure to an air pollutant .",
    "such models can reduce the deleterious effects of errors resulting from the use of ambient monitoring measurements to represent exposure .",
    "for example , on hot summer days the ambient levels will overestimate exposure since people tend to stay in air conditioned indoor environments where exposures are lower . to address that problem ,",
    "the us environmental protection agency ( epa ) developed apex .",
    "it is being used by policy  makers to set air quality standards under hypothetical emission reduction scenarios ( ozone , 2005 ) . interpolated ozone fields could well be used as input to apex to further reduce that measurement error although that application has not been made to date for ozone .",
    "however , it has been made for particulate air pollution through an exposure model called sheds ( burke et al . ,",
    "2001 ) as well as a simplified version of sheds ( calder et al . , 2003 ) .",
    "interest in predicting human exposure and hence in mapping ozone space  time fields , stems from concern about the adverse human health effects of ozone .",
    "ozone ( 2005 ) reviews an extensive literature on that subject .",
    "exposure chamber studies show that inhaling high concentrations of ozone compromises lung function quite dramatically in healthy individuals ( and presumably to an even greater degree in unhealthy individuals such as those suffering from asthma ) .",
    "moreover , epidemiology studies show strong associations between adverse health effects such exposures .",
    "consequently , the us clean air act mandates that national ambient air quality standards are necessary for ozone to protect human health and welfare .",
    "thus , spatio  temporal models can have a role in setting these naaqs .",
    "ozone concentrations over a geographic region vary randomly over time , and therefore constitute a spatio  temporal field . in both rural and urban areas such fields",
    "are customarily monitored , the latter to ensure compliance with the naaqs amongst other things .",
    "in fact , failure can result in substantial financial penalties .",
    "a number of approaches can be taken to modelling such space time fields . here",
    "we investigate a promising one that involves selecting a member of a very large class of so  called state space models .",
    "section [ chapter2:dlmbackgrand ] describes our choice , a dynamic linear model ( dlm ) , a variation of those proposed by huerta et al .",
    "( 2004 ) and stroud et al .",
    "( 2001 ) . here",
    "`` dynamic '' , refers to the dlm s capability of systematically modifying its parameters over time , a seemingly attractive feature since the processes it models will themselves generally evolve `` due to the passage of time as a fundamental motive force '' ( west and harrison , 1997 ) .",
    "however , other approaches are possible and in a companion report currently in preparation , the dlm selected here will be compared with other possibilities .",
    "section [ chapter2:dlmbackgrand ] introduces the hourly concentration field that is to be modeled in this report . there consideration of measurements made at fixed site monitors and reported in the airs dataset leads to the construction of our dlm . [ the _ epa _ ( environmental protection agency ) changed the _ airs _ ( aerometric information retrieved system ) to the _ afs _ ( air facility subsystem ) in 2001 . ]",
    "that model becomes the object of our assessment in subsequent sections .",
    "to illustrate how to select some of the model parameters in the dlm , we use the simple first  order polynomial dlm in section [ pred : var : simplest : dlm ] to shed some light on this problem .",
    "moreover , we prove there in a simple but representative case , that under the type of model constructed here and by huerta et al .",
    "( 2004 ) , the predictive variances for successive time points conditional on all the data must be monotonically increasing , an undesirable property .",
    "theoretical results and algorithms on the dlm are represented in sections [ chapter2:algo : est ] and [ chapter2:algo : pred ] .",
    "the mcmc sampling scheme is outlined in section [ chapter2:algo : est : mcmc ] .",
    "the forward  filtering ",
    "backward  sampling ( ffbs ) method is demonstrated in section [ ffbs : state : sample ] to estimate the state parameters in the dlm .",
    "moreover , we outline the mcmc sampling scheme to obtain samples for other model parameters from their posterior conditional distributions with a metropolis  hasting step .",
    "section [ chapter2:algo : pred ] gives theoretical results for prediction and interpolation at unmonitored ( ungauged ) sites from their predictive posterior distributions .",
    "section [ chapter2:example : cluster2 ] shows the results of mcmc sampling along with interpolation results on the ozone study .",
    "section [ problems : in : dlm ] describes problems with the dlm process revealed by our assessment .",
    "we summarize our findings and draw conclusions from our assessment in section [ chapter2:summary ] .    as an added note ,",
    "we have developed software , written in c and r and available online ( http://enviro.stat.ubc.ca ) that may be used to reproduce our findings or to use the model for modeling hourly pollution in other settings .",
    "although we believe the methods described in this paper apply quite generally to hourly pollution concentration space  time fields , it focuses on an hourly ozone concentrations ( ppb ) over part of the eastern united states during the summer of 1995 . in all , @xmath0 irregularly located sites ( or `` stations '' ) monitor that field . to enable a focused assessment of the dlm approach and",
    "make computations feasible , we consider just one cluster of ten stations ( cluster 2 ) , in close proximity to one another .",
    "however , in work not reported here for brevity , two other such clusters led to similar findings .",
    "note that cluster 2 has the same number of stations as the one in mexico city studied by huerta et al.(2004 ) .",
    "the initial exploratory data analysis followed that of huerta et al .",
    "( 2004 ) with a similar result , a square  root transformation of the data is needed to validate the normality assumption for the dlm residuals . [",
    "note that a small amount of randomly missing data were filled in by the spatial regression method ( srm ) , before we began . ]",
    "the plot of a bayesian periodogram ( dou et al . , 2007 ) for the transformed data at the sites in our cluster reveals a peak between 1 pm and 3 pm each day with a significant @xmath1hour cycle for the stations in cluster 2 .",
    "we also found a slightly significant @xmath2hour cycle .",
    "however , no obvious weekly cycles or nightly peaks were seen .",
    "thus , the dlm suggested by our analysis turns out to be a variant of the one in huerta et al .",
    "( 2004 ) ; it has states for both local trends as well as periodicity across sites .    to define the model ,",
    "let @xmath3 denote the square  root of the observable ozone concentration , at site @xmath4 @xmath5 and time @xmath6 @xmath7 @xmath8 being the total number of gauged ( that is , monitoring ) sites in the geographical subregion of interest and @xmath9 the total number of time points .",
    "furthermore , let @xmath10 .",
    "then the dlm for the field is @xmath11 where @xmath12,$ ] @xmath13,$ ] @xmath14,$ ] @xmath15 @xmath16 , @xmath17 and @xmath18 here @xmath19 denotes a canonical spatial trend and @xmath20 a seasonal coefficient for site @xmath21 at time @xmath22 corresponding to a periodic component , @xmath23 where @xmath24 note that @xmath25 represents the distance matrix for the gauged sites @xmath26 that is , @xmath27 for @xmath28 where @xmath29 denotes the euclidean distance ( km ) between sites @xmath30 and @xmath31    models ( [ dlm : y])([dlm : alpha ] ) can also written in the form of a state space model with the observation and state equations @xmath32 @xmath33 where @xmath34 @xmath35 and @xmath36 is given by @xmath37.\\ ] ] note that @xmath38,$ ] @xmath39 being the block diagonal matrix with diagonal entries @xmath40 @xmath41 and @xmath42    let @xmath43 where @xmath44 represents all the missing values and @xmath45 all the observed values in cluster 2 sites for @xmath46 the model unknowns are therefore the coordinates of the vector @xmath47 in which the vector of state parameters up to time @xmath48 is @xmath49 , the range parameter is @xmath50 , the variance parameter is @xmath51 and finally the vector of phase parameters is @xmath52 .",
    "let @xmath53 be the vector of parameters fixed in the dlm to render computation feasible .",
    "specification of the dlm is completed by prescribing the hyperpriors for the distributions of some of the model parameters : @xmath54 notice that @xmath50 and @xmath51 have inverse gamma distributions for computational convenience .",
    "the choice of the hyperpriors is discussed in section [ chapter2:example : cluster2 ] .",
    "we express the state ",
    "space model in two different ways because of our dual objectives of parameter inference and interpolation . for simplicity",
    ", we use models ( [ dlm : obs])([dlm : state ] ) for inference about the range , variance and state parameters ( see section [ ffbs : state : sample ] ) , and use models ( [ dlm : y])([dlm : alpha ] ) for inference on the phase parameters ( see section [ ffbs : phase : sample ] ) and interpolation ( see section [ chapter2:algo : pred ] ) .",
    "before turning to the implementation of the approach in the next section , we explore theoretically , albeit in a tractable special case , some features of the model .",
    "that exploration leads to insight about how the model s parameters should be specified as well as undesirable consequences of inappropriate choices .",
    "our assessment will focus on the accuracy of the model s predictions .",
    "this simple model we consider is a special case of the so  called `` first  order polynomial model '' , a mathematically tractable , commonly used model .",
    "it captures many important features and properties of the dlm we have adopted .    for @xmath55 and @xmath56 , the first ",
    "order polynomial dlm is given by @xmath57 where @xmath58 and @xmath59 assume @xmath60 and @xmath61 and @xmath62 are all currently known .",
    "the first ",
    "order polynomial dlm is particularly useful for short  term prediction since then the underlying evolution @xmath19 is roughly constant .",
    "observe that the zero  mean evolution error @xmath63 process is independent over time , so that the underlying process is merely a random walk ; the model does not anticipate long  term variation . at any fixed time @xmath64 @xmath65 consequently , the first ",
    "order polynomial dlm has the following covariance structure : @xmath66 where @xmath67 for @xmath68 and @xmath69    this dlm defines a non  stationary spatio ",
    "temporal process since for the first ",
    "order polynomial model to be stationary , the eigenvalues of state transfer matrix , @xmath70 in the notation of west and harrison ( 1997 ) , must lie inside of the unit circle .",
    "however , @xmath71 so that this process is not a stationary gaussian dlm . furthermore , the dlm defined in section [ chapter2:dlmbackgrand ] is non  stationary because @xmath72 given all the model parameters in ( [ dlm : obs])([dlm : state ] ) .",
    "the dlm in ( [ pred : var : obs : eqn])([pred : var : state : eqn ] ) has an important property that the covariance functions in ( [ pred : var : cov : yit : yjt])([pred : var : cov : yit : yjs ] ) depends on the time point of @xmath73 , not on @xmath74 thus confirming our observation of non - stationary .",
    "we readily find the correlation between @xmath3 and @xmath75 to be @xmath76 where @xmath77 and @xmath78 .1 in * remarks .",
    "*    * 1 . * the correlations in ( [ pred : var : corr : yit : yjt ] ) and",
    "( [ pred : var : corr : yit : yjs ] ) have the following properties when @xmath79 :    1 .",
    "@xmath80 + for @xmath81 and 2 .",
    "@xmath82 + is a monotone increasing function of @xmath74 .",
    "thus for any fixed time point @xmath22 , @xmath83 as a function of @xmath84 attains its maximum at @xmath85 and decreases as @xmath86 increases .",
    "* 2 . * by ( [ pred : var : corr : yit : yjt ] ) , @xmath87 as @xmath88 for @xmath89 @xmath90 that property seems unreasonable ; the degree of association between two fixed monitors should not increase as an artifact of a larger time t. that suggests a need to make some of the model parameters , say @xmath91 , depend on time .",
    "more specifically , ( [ pred : var : corr : yit : yjt ] ) suggests making @xmath92 stabilize @xmath93 carrying this assessment further , for any two sites in close proximity , i.e. for @xmath94 , @xmath95 a result that seems quite reasonable . for two sites very far apart so that @xmath96 , @xmath97 this correlation should be close to @xmath98 . in other words , we should have @xmath99 a sufficient condition for this to hold is @xmath100 and @xmath101    the key result , ( [ pred : var : corr : yit : yjt ] ) , suggests a simple but straightforward way to adjust the model parameter @xmath91 according to the size of @xmath48 , namely , to replace it by @xmath102 .",
    "that choice is empirically validated in section [ chapter2:summary ] .",
    "we turn now to study the behavior of the predictive variances in the first ",
    "order polynomial dlm that helps us understand the interpolation results . to that end",
    "consider the correlations of responses at an ungauged site @xmath103 with those at the gauged site @xmath104 @xmath105 respectively .",
    "note that both ( [ pred : var : corr : prop1 ] ) and ( [ pred : var : corr : prop2 ] ) hold for @xmath106 the properties of the correlation structure in ( [ pred : var : corr : prop1])([pred : var : corr : prop2 ] ) , lead us to the conjecture that the model s predictive bands should increase monotonically over time as more data become available , in the absence of restrictions on @xmath92 suggested above . furthermore , even conditioning on all the data , the predictive bands should also increase over time . in support of these conjectures",
    ", we prove that they hold in a simple case where @xmath107 and @xmath108 in ( [ pred : var : obs : eqn])([pred : var : state : eqn ] ) .",
    "[ pred : var : simple : dlm : result ] for the first  order polynomial dlm in ( [ pred : var : obs : eqn])([pred : var : state : eqn ] ) with @xmath107 and @xmath108 , assume the prior for @xmath109 to be @xmath110 the joint distribution of @xmath111 is @xmath112 where @xmath113 @xmath114 being the @xmath115 vector of 1s ( @xmath116 )",
    ". then we have the following predictive conditional variances : @xmath117 @xmath118 where @xmath119 and @xmath120    for this simple case , we would expect the predictive variance of @xmath121 based on more data collected over time to be no greater than that of @xmath121 based on less , that is , @xmath122 and @xmath123 moreover , we would expect that , based on the same amount of data , the predictive variance of @xmath121 would be no greater than that of @xmath124 that is , @xmath125    dou et al . ( 2007 ) prove these conjectures and provide other comparisons of these predictive variances .",
    "we conclude that the predictive variance function is a monotonic increasing function of time @xmath22 based on the same set of data .",
    "it decreases when more data or equivalently , more time is involved .",
    "furthermore , the difference between these predictive variances decreases as @xmath22 increases .",
    "it increases with time even when conditioning on the same dataset .",
    "[ pe : timepoint:2:site:2 ] for the first ",
    "order polynomial dlm in theorem [ pred : var : simple : dlm : result ] , we have the following properties of the predictive conditional variances : @xmath126 @xmath127 @xmath128 @xmath129 @xmath130 @xmath131    as an immediate consequence of ( [ pe : diff : y02:y01:y11:y12:spatial ] ) , the predictive variances increase monotonically at successive time points conditional on all the data .",
    "that leads to monotonically increasing coverage probabilities at the ungauged sites , an interesting phenomenon discussed in section [ problems : in : dlm ] .",
    "there we will also discuss the lessons learned in this section in relation to our empirical findings .",
    "next , we present a curious result about the properties of the above predictive variances that may explain some of their key features .",
    "this result concerns these predictive variances as functions of @xmath132 @xmath133 or @xmath134 part of its proof is included in appendix [ pred : var : result3 ] .",
    "[ pred : var : key : result ] the predictive conditional variances in ( [ pe : y01:y11])([pred : var : example : m2 ] ) increase as @xmath133 increases , or @xmath135 increases , or @xmath50 decreases .",
    "thus , keeping two parameters fixed , these predictive conditional variances are monotone functions of the remaining one .",
    "therefore , the dlm can paradoxically lead to larger predictive variances when conditioning on more data .",
    "for example , in the case @xmath107 and @xmath136 applying the dlm model with only the data at @xmath108 yields the predictive variance @xmath137 , which is exactly the same as @xmath138 in ( [ pe : y01:y11 ] ) . this predictive variance is smaller than @xmath139 in ( [ pe : y02:y11:y12 ] ) , which is based on more data , under certain condition specified in the next corollary .",
    "[ pred : var : paradox ] for the first ",
    "order polynomial dlm in theorem 1 , @xmath140    the behavior suggested by corollary [ pred : var : paradox ] is actually observed in our application ( see section [ problems : in : dlm ] ) .",
    "this section very briefly describes how to implement our model using the mcmc method , more specifically , the forward  filtering  backward  sampling algorithm of carter and kohn ( 1994 ) .",
    "the details are given by dou et al .",
    "( 2007 ) .",
    "the joint distribution , @xmath141 , is the object of interest . here",
    "@xmath142 represents the observation matrix at the @xmath8 gauged sites up to time @xmath143 moreover , @xmath144 is the vector of state parameters at the @xmath8 gauged sites until time @xmath143 for simplicity , the values of @xmath145 are fixed but the problem of setting them will be addressed below .",
    "additional detail can be found in appendix [ appendix : section:2:3:1 ] .",
    "since that joint distribution does not have a closed form , direct sampling methods fail , leading to the use of the markov chain monte carlo ( mcmc ) method . a _ blocking mcmc",
    "_ scheme increases iterative sampling efficiency , three blocks being chosen for reasons given in dou et al .",
    "( 2007 ) : @xmath146 @xmath147 and @xmath148 more precisely we can :    1 .   sample from @xmath149 2 .   sample from @xmath150 and 3 .",
    "sample from @xmath151    since @xmath152 has no closed form , the full conditional posterior distribution of @xmath153 is obtained by kalman filtering and smoothing , in other words , by the ffbs algorithm .",
    "assuming an inverse gamma hyperprior for @xmath154 the conditional posterior distribution of @xmath51 given the range and phase parameters is also inverse gamma distributed with new shape and scale parameters .",
    "note that @xmath155 indicating that we can sample iteratively from the three conditional posterior distributions on the right  hand  side of ( [ joint : post : range : variance : state ] ) to obtain samples from @xmath156 however , @xmath157 has no closed form , leading us to sample @xmath50 by a _ metropolis ",
    "chain within a gibbs sampling cycle , an algorithm as described in the next three subsections .      to sample @xmath158 from @xmath159 we use the block mcmc scheme .",
    "because of ( [ joint : post : range : variance : state ] ) , we could ideally iteratively sample @xmath50 from @xmath160 @xmath51 from @xmath161 and @xmath153 from @xmath162 however , because we do not have a closed form for the posterior density of @xmath157 , we use instead the _ metropolis  hasting algorithm _ to sample @xmath50 , given the data , from the following a quantity that is proportional to its posterior density , that is , @xmath163^{-(nt/2+\\alpha)}.\\end{aligned}\\ ] ] since we can not compute the normalization constant for @xmath164 the metropolis  hasting algorithm is used .",
    "the proposal density , @xmath165 is selected to be a lognormal distribution , because the parameter space is bounded below by @xmath98 , making the gaussian distribution inappropriate . as moller ( 2003 ) points out , this alternative to a random walk metropolis considers the proposal move to be a random multiple of the current state . from the current state",
    "@xmath166 the proposed move is @xmath167 where @xmath168 is drawn from a symmetric density , such as normal . in other words , at iteration @xmath169 we sample a new @xmath170 from this proposal distribution , centered at the previously sampled @xmath171 with a tuning parameter , @xmath172 , as the variance for the distribution of @xmath168 .",
    "gamerman ( 2006 ) suggests the acceptance rate , that is , the ratio of accepted @xmath170 to the total number of iterations , be around @xmath173 we tune @xmath172 to attain that rate .",
    "if the acceptance rate were too high , for example , @xmath174 to @xmath175 we would increase @xmath176 if too low , for example , @xmath98 to @xmath177 we would decrease @xmath172 , to narrow down the search area for @xmath178    the metropolis  hasting algorithm proceeds as follows . given @xmath179",
    "@xmath180 @xmath181 and @xmath182 , where @xmath183    1 .",
    "draw @xmath170 from @xmath184 2 .",
    "compute the acceptance probability : @xmath185 3 .",
    "accept @xmath170 with probability @xmath186 in other words , sample @xmath187 $ ] and let @xmath188 if @xmath189 and @xmath190 otherwise .",
    "we run this algorithm iteratively until convergence is reached .",
    "next , we sample @xmath51 given the accepted @xmath50 s , @xmath191 s , @xmath192 s and @xmath193 . the prior for @xmath51",
    "is chosen to be an inverse gamma distribution with shape parameter @xmath194 and scale parameter @xmath195 the posterior distribution for @xmath51 is also an inverse gamma distribution , but with a shape parameter @xmath196 and a scale parameter @xmath197    we now sample @xmath153 given the accepted @xmath50 s , @xmath51 s , phase parameters and @xmath198 using ffbs .",
    "west and harrison ( 1997 ) propose a general theorem for inference about the parameters in the dlm framework . for time",
    "series data , the usual method for updating and predicting is the kalman filter .",
    "dou et al . ( 2007 ) present a ffbs algorithm ( similar to the kalman filter algorithm ) to resample the state parameters conditional on all the other parameters and observations as part of the mcmc method for sampling @xmath199 from the smoothing distribution @xmath200    the initial state parameter is given by @xmath201,\\ ] ] where @xmath202 being the initial information , with @xmath203 and @xmath204 known . later in section [ chapter2:example : cluster2 ]",
    ", we consider how to set them for cluster 2 airs dataset ( 1995 ) .",
    "let @xmath205 now suppose for expository purposes , that all the prior information has been given and @xmath206 s coordinates are mutually independent .",
    "mcmc can be used to fill in missing values at each iteration . to see how , note that at any fixed time point @xmath22 , after appropriately defining a scale matrix @xmath208 we can rewrite the observation vector @xmath209 as follows : @xmath210 where @xmath211 denotes the missing response(s ) at time @xmath22 and @xmath212 the observed response(s ) at @xmath213 notice that `` o '' represents `` observed '' and `` m '' , `` missing '' .    let @xmath214 where @xmath215 represents the set of gauged sites containing missing values at time point @xmath6 @xmath216 the set of gauged sites containing observed values at time @xmath6 for all @xmath217 and @xmath218 such that @xmath219 for @xmath220 and @xmath221    we already know that @xmath222,\\end{aligned}\\ ] ] so that @xmath223 is also multivariate normally distributed , that is , @xmath224 , \\end{array}\\ ] ] where @xmath225    we can also partition @xmath226 as @xmath227 where @xmath228 and @xmath229 similarly , we have @xmath230 where @xmath231 @xmath232 and @xmath233    by a standard property of the multivariate normal distribution , we have @xmath234,\\end{aligned}\\ ] ] where @xmath235 and @xmath236 for @xmath46    at each iteration , we draw @xmath237 from the corresponding distribution ( [ miss : mcmc : distribution ] ) at each time point @xmath22 and then we can write the response variables as @xmath238 where @xmath44 and @xmath239      we now present our method for sampling the phase parameters @xmath241 from its full conditional posterior distribution , that is , @xmath242 by using the samples of @xmath50 , @xmath51 and @xmath153 . for simplicity , we use the notation for models ( [ dlm : y])([dlm : alpha ] ) in this section .",
    "we then sample the constant phase parameters conditional on all the other parameters and observations .",
    "suppose @xmath243 has a conjugate bivariate normal prior with mean vector @xmath244 and covariance matrix @xmath245 then the posterior conditional distribution for @xmath246 is normal with mean vector @xmath247 and covariance matrix @xmath248 where @xmath247 and @xmath249 can be obtained from equations given in dou et al .",
    "( 2007 ) .    we will not use a non  informative prior such as @xmath250 for @xmath246 since that choice can lead to non",
    " identified posterior means or posterior variances .",
    "in fact for that choice we find the posterior conditional distribution of @xmath246 to be normal with mean vector @xmath251 and covariance matrix @xmath252 from equations given in dou et al .",
    "( 2007 ) along with the elements of @xmath252 , where @xmath252 can be singular for any @xmath253 ( @xmath254 ) .",
    "hence , we obtain the extreme values at times @xmath255 that invalidates the assumption of constant phase parameters across all the time scales when we sample from its full conditional posterior distribution .    for fixed values of @xmath132 @xmath51 and @xmath256 we sample the model parameter @xmath257 from @xmath258 at each time point , and",
    "then obtain the `` sample '' of @xmath246 at this iteration by the median of these samples across all the time points , under the assumption that @xmath259 are constant phase parameters in the models ( [ dlm : obs])([dlm : state ] ) .",
    "the mcmc algorithm we use here resembles that of huerta et al .",
    "( 2004 ) , one difference being that we unlike them , use all the samples after the burn  in period , not just the chain containing the accepted samples .",
    "we believe the markov chains of only accepted results will lead to biased samples , thereby changing the detailed balance equation of the metropolis  hasting algorithm .",
    "the above algorithm we use for cluster 2 airs dataset is summarized as follows :    1 .",
    "initialization : sample @xmath260 2 .",
    "given the @xmath261 value @xmath179 @xmath262 @xmath263 @xmath264 @xmath180 @xmath181 and the observations @xmath265 : 1 .",
    "sample @xmath266 from @xmath267 where @xmath268 1 .   1 .",
    "generate a candidate value @xmath170 from a logarithm proposal distribution @xmath269 that is , @xmath270 for some suitable tuning parameter @xmath176 2 .",
    "compute the acceptance ratio @xmath271 where @xmath272 3 .",
    "with probability @xmath271 accept the candidate value and set @xmath273 otherwise reject and set @xmath274 2 .",
    "sample @xmath275 from @xmath276 3 .",
    "sample @xmath277 from @xmath278 2 .",
    "sample @xmath279 from @xmath280 3 .",
    "sample @xmath281 from @xmath282 where @xmath283 3 .",
    "repeat until convergence .",
    "we have developed software to implement the dlm approach of this section . to enhance the metropolis  within ",
    "gibbs algorithm , we augment the r code with c to speed up the computation . the current version , _",
    ", is freely available at http://enviro.stat.ubc.ca for different platforms such as windows , unix and linux .",
    "this section describes how to interpolate hourly ozone concentrations at ungauged sites using the dlm and the simulated markov chains for the model parameters ( see section [ chapter2:algo : est ] ) . in other words , suppose @xmath284 are @xmath285 ungauged sites of interest within the geographical region of cluster 2 sites ( excluding the possibility of extrapolation ) .",
    "the objective is to draw samples from @xmath286 where @xmath287 and @xmath288 denotes the unobserved square  root of ozone concentrations at the ungauged site @xmath289 and time @xmath6 for @xmath56 and for @xmath290 let @xmath291 denote the unobserved state parameters at site @xmath289 and time t. the dlm is given by @xmath292 where @xmath293 @xmath294 and @xmath295    in the following two subsections , we illustrate how to sample the unobserved state parameters @xmath296 from the corresponding conditional posterior distribution , and demonstrate the spatial interpolation at the ungauged site @xmath289 .",
    "we first sample @xmath297 given @xmath298 @xmath299 and @xmath300 from the state equation ( [ dlm : state ] ) for @xmath301 we know that the joint density of @xmath297 and @xmath299 follows a normal distribution , with covariance matrix @xmath302 where @xmath303 denotes the distance matrix for the unobserved station and the monitoring stations . the conditional posterior distribution , @xmath304",
    "is derived in appendix [ appendix : spatial ] .",
    "we interpolate the square  root of ozone concentration at the ungauged sites by conditioning on all the other parameters and observations at the gauged sites . as",
    "above , @xmath288 and @xmath305 are jointly normally distributed as a consequence of the observation equation . the predictive conditional distribution for @xmath306 that is ,",
    "@xmath307 is given in appendix [ appendix : spatial ] .",
    "this section applies our model to the hourly ozone concentration field described above .",
    "six ungauged sites were randomly selected from those available within the range of the sites in cluster 2 to play the role of `` unmonitored sites '' and help us assess the performance of the dlm .",
    "the geographical locations of these six ungauged sites , represented by the alphabetic letters , @xmath308 are shown in figure [ fig : ug ] , along with the sites in cluster 2 .",
    "this subsection presents a mcmc simulation study in which samples are drawn sequentially from the joint posterior distribution of the model parameters in the dlm .",
    "_ initial settings _ + following huerta et al .",
    "( 2004 ) , we use the following initial settings for the starting values , hyperpriors and fixed model parameters in the dlm :    1 .",
    "the hyperprior for @xmath50 is @xmath309 and for @xmath154 @xmath310 the expected value of @xmath309 is @xmath311 and so are both of the variances of @xmath312 and @xmath313 these vague priors for @xmath50 and @xmath51 are selected to reflect our lack of prior knowledge about their distributions .",
    "the initial information for @xmath314 the initial state parameter , is assumed to be normally distributed with mean vector @xmath315 and covariance matrix @xmath316 where @xmath317 and @xmath204 is a block diagonal matrix with diagonal entries @xmath318 @xmath319 and @xmath320 3 .",
    "the hyperprior for @xmath246 is a bivariate normal distribution with mean vector @xmath321 and a diagonal matrix @xmath322 with diagonal entries @xmath323 and @xmath324 4 .",
    "some of the model parameters in the dlm are fixed as follows : @xmath325 @xmath326 @xmath327 @xmath328 and @xmath329    _ monitoring the convergence of the markov chains",
    "_ +    figure [ mcmc : one : chain : converge ] shows the trace plots of model parameters @xmath132 @xmath154 @xmath191 and @xmath192 with the number of iterations of the simulated markov chains where the total number of iterations is @xmath330 the burn  in period is chosen to be @xmath331 and all the remaining markov samples are collected for posterior inference .",
    "the acceptance rate is approximately @xmath332 we observe that the markov chain converges after a run of less than five hundreds iterations .",
    "table [ post : summary ] displays the median and @xmath333 quantile from the simulated markov chains for the model parameters @xmath132 @xmath154 @xmath191 and @xmath334      this subsection assesses the model s performance by comparing the interpolated values at the ungauged sites , @xmath335 , with the measurements made there .",
    "we use the entire dataset to assess the performance of the interpolation results .",
    "table [ cov : prob ] shows the coverage probabilities of the credibility intervals ( or `` credible intervals '' for short ) for these six ungauged sites at various norminal levels .",
    "generally , the coverage probabilities at the ungauged sites exceed their nominal levels indicating that the error bands are too wide .    among these six ungauged sites ,",
    "site @xmath336 has the highest coverage probability seen in table [ cov : prob ] .",
    "this may be because of @xmath336 s nearness to a close `` relative '' among the gauged sites , namely , site @xmath337 that would be consistent with our assumption that the spatial correlation is inversely proportional to the intersite distance . at the same time , these unsatisfactory large coverage probabilities point to a deficiency of the dlm .    to explore this issue further , we compared the values predicted for ungauged site @xmath336 from may 14 to september 11 , 1995 and the measurements made there . figures [ ug : d : wk1:wk4 ] and in more detail [ ug : d : wk17:day120 ] , which exemplify results reported in more detail by dou et al .",
    "( 2007 ) , depict the results for the first four weeks and the last week of that period , respectively .",
    "furthermore , table [ ungauge : gauge : friends ] shows for all the ungauged sites , the close relatives they have among the cluster 2 sites that lie within a radius of 100 km , the corresponding global circle distance ( gcd ) in km , and along with the average of their correlations .",
    "this table confirms that indeed @xmath336 does enjoy the highest correlation with its relative .",
    "that relationship is further explored in figure [ friend : ug : d : g:1 ] where we see a strong linear relationship between sites @xmath336 and @xmath338 as our coverage probability assessment had suggested .    in spite of its reliance on the relatives ,",
    "the dlm does not predict responses at the ungauged sites very accurately as illustrated in figure [ ug : d : wk17:day120 ] . that points to problems with this model which will be discussed in the next section .",
    "in general , the dlm provides a remarkably powerful modelling tool , made practical by advances in statistical computing .",
    "however , its substantial computational requirements still limits its applicability .",
    "moreover , the very flexibility that makes it so powerful also imposes an immense burden of choice on the model .",
    "this section summarizes critical issues and includes some suggestions for improvement .    _ * monitoring mcmc convergence * _ + figure [ mcmc : two : chains ] represents the trace plots of model parameters @xmath132 @xmath154 @xmath191 and @xmath192 of two chains from the initial settings in section [ chapter2:example : cluster2:dlm ] .",
    "these two chains seem to mix well after several hundreds iterations , suggesting at first glance the markov chains have converged .    @xmath339 @xmath339 @xmath339_*autocorrelation and partial autocorrelation of the simulated markov chains * _ + however , we know that the autocorrelation , as measured by the autocorrelation function ( acf ) , is very important when considering the length of the chain .",
    "a highly auto  correlated chain needs a long run to yield accurate estimates .",
    "moreover , the partial autocorrelation function ( pacf ) is also an important index for assessing a markov chain since large values of the pacf at lag @xmath340 indicates that the next value in the chain is dependent on past values , not just on the most recent ones .",
    "figure [ mcmc : hist : acf : pacf ] shows the histogram , acf and pacf plots for the markov chains used in section [ chapter2:example : cluster2:result ] , after a burn  in period of @xmath341 the acf plots show the @xmath50s to be highly autocorrelated , in other words that the @xmath50chain does not mix well , potentially leading to biased estimates in section [ chapter2:example : cluster2:result ] . thinning the chain might reduce that autocorrelation . in other words , using every @xmath342 ( @xmath343 ) @xmath50 generated by the chain could be used to produce the estimates .",
    "however , computational challenges make that strategy impractical ; we need to use the entire chain .    _",
    "* relationship between pairs of @xmath132 @xmath154 @xmath191 and @xmath192 * _ +    our prior assumptions make the model parameters @xmath132 @xmath154 @xmath191 and @xmath192 uncorrelated .",
    "figure [ scatter : model : parameters ] shows the relationship between the pairs of these parameters as a way of investigating that assumption .",
    "it seems valid except for the @xmath50@xmath51 pair in graph @xmath344 that graph shows a weak linear association between @xmath50 and @xmath154 thus pointing to a failure of that assumption for that pair .",
    "since @xmath345 determines spatial variability while @xmath50 determines correlation this relationship seems intriguing .",
    "larger values of @xmath51 tend to go with larger @xmath50s , i.e. , diminished spatial correlation . why they are coupled in this way",
    "is unknown but it should be accounted for in future applications of this model .    _ * time varying @xmath50s and @xmath51s : empirical coverage probabilities versus nominal credible probabilities * _ +    although we follow huerta et al .",
    "( 2004 ) in assuming the temporal constancy of @xmath50 and @xmath154 it is natural to ask if those generated by the mcmc method change over time .",
    "a variant of this issue concerns the time domain of the application .",
    "would the results for these parameters change if we switched from one time span to a longer one containing it ?",
    "a `` yes '' to this question would pose a challenge to anyone intending to apply the model , knowing that the choice would have implications for the size of @xmath345 and @xmath50 .    to address these concerns we carried out the following studies :    1 .",
    "study @xmath346 implement the dlm at ungauged sites using weekly data ( @xmath347 ) . generate markov chains for @xmath132 @xmath154 @xmath191 and @xmath334 obtain the coverage probabilities at each ungauged site and week for fixed credibility interval probabilities .",
    "study @xmath348 implement the dlm at ungauged sites using week @xmath338 to week @xmath349 data ( @xmath350 ) .",
    "estimate model parameters and interpolate the results at those ungauged sites . obtain the coverage probabilities at each ungauged site and week for fixed credibility interval probabilities using each week s data .",
    "study @xmath351 fix @xmath352 at week @xmath353 ( @xmath354 ) using values suggested by the markov chains generated in study @xmath355 .",
    "then use these @xmath356 as fixed values in the dlm to reduce computation time . in other words , go through all the steps in the algorithm of section [ mcmc : algorithm : summary : table ] but now using only fixed @xmath170s instead of generating them by a metropolis  hasting step .",
    "( note that we are then only using gibbs sampling and an mcmc blocking scheme . )",
    "compute the corresponding coverage probabilities using @xmath357 at each ungauged site and week for fixed credibility interval probabilities .",
    "studies @xmath355 and @xmath358 are intended to explore the effect of data and time propagation on the interpolation results .",
    "study @xmath359 aims to pick out any significant difference in the interpolation results when using the fixed @xmath360 rather than using the markov samples of @xmath50s .",
    "it is also aimed at finding how much time would be saved by avoiding the inefficient metropolis step . table [ fix : lambda : weekdata ] shows these fixed @xmath360s used in study @xmath361 table 5 shows the time saved using fixed @xmath170s against the one using the metropolis  hastings algorithm .    figure [ time : vary : lambda : sigma ] illustrates the mcmc estimation results obtained in study @xmath362 it plots the markov chains of @xmath50 and @xmath51 using weekly data .",
    "it is obvious that @xmath50 and @xmath51 vary from week to week , which implies that the constant @xmath50@xmath51 model is not tenable over a whole summer for this dataset .",
    "figure [ cov : prob : paper ] typifies figures in dou et al .",
    "( 2007 ) showing the coverage probabilities for various predictive intervals associated with the interpolators in these three studies .",
    "the solid line with bullets represents the results for study @xmath363 the dotted line with up - triangles for study @xmath364 and the dashed line with squares for study @xmath361 these graphs show that the coverage probabilities of study @xmath365 are similar to that of study @xmath366 this suggests that we could use the entries in table [ fix : lambda : weekdata ] as fixed @xmath170s in the dlm to obtain interpolation results similar to those obtained using the metropolis  within ",
    "gibbs algorithm .",
    "we have studied the prediction accuracy of the simplest dlm , namely , the first ",
    "order polynomial model , in section [ pred : var : simplest : dlm ] . as a result",
    ", the predictive variances should increase monotonically at successive time points conditional on all the 17 weeks data , in the general dlm setting ( see section [ pred : var : simplest : dlm ] ) .",
    "the plots exhibit a monotonic increasing trend in the coverage probabilities of both studies @xmath358 and @xmath361 this trend agrees with the graph of the coverage probabilities in figure [ cov : prob : paper ] . nevertheless ,",
    "those coverage probabilities of both studies deviate slightly from the expected monotonically increasing trend at some time points because of the time varying effect of @xmath50@xmath51 monitored in figure [ time : vary : lambda : sigma ] .",
    "on the other hand , study @xmath359 enjoys significant computational time savings compared with @xmath367 table [ time : saving ] suggests that the computation time of the former is almost 2.8 times faster than the latter .",
    "study @xmath358 shows an intuitively unappealing increase in the uncertainty of interpolation results as time increases ; coverage probabilities get larger over time as we see in table [ cp : threestudies:80cp ] .",
    "this increase may be interpreted as saying that for the dlm models , the @xmath50s and @xmath51s collected from the data should vary over the entire time span of the study , while the prior postulates that they do not vary over that time span .",
    "the observed phenomenon may also be due to mis  specification of the model parameter values @xmath368 ( see the initial settings for @xmath145 in section [ chapter2:example : cluster2:dlm ] . ) .    comparing the results of these studies , we find that sometimes , paradoxically , the model gives better results using only one week s data rather than all . however , corollary [ pred : var : paradox ] in section [ pred : var : simplest : dlm ] predicts this finding . because the prior for @xmath369 is @xmath370 the expectation of @xmath369 is @xmath371 implying that @xmath372 and @xmath373 hence , @xmath374 which is less than @xmath135 ( for example",
    ", the median of @xmath51 is around 1.21 in study @xmath358 and even larger in study @xmath355 ) . by the sufficient and necessary condition in corollary [ pred : var : paradox ] ,",
    "the predictive variance of study @xmath355 is less than that of study @xmath367 however , notice that @xmath51 and @xmath50 vary from week to week in @xmath363 which may also lead to the paradox observed in the empirical findings of this section .",
    "for example , in ( b ) of figure [ cov : prob : paper ] , the coverage probability of @xmath358 at the @xmath375 week is larger than that of @xmath362 from the above discussion , we know that the predictive variance of @xmath355 should be less than that of @xmath367 however , @xmath51 of @xmath355 is larger than that of @xmath364 leading an inflated predictive variance of @xmath362 this feature makes it difficult to compare these two predictive variances , but explains the paradox we see in those figures .",
    "to assess the dynamic linear modelling approach to modelling space  time fields , we have applied it to an hourly ozone concentration field over a geographical spatial domain covering most of the eastern united states . to focus that assessment",
    "we consider just one cluster of spatial sites we call cluster 2 during a single ozone season .",
    "moreover , we have used a variant of the dynamic linear modelling approach of huerta et al .",
    "( 2004 ) implemented through mcmc sampling .",
    "our assessment reveals some difficulties with that very flexible approach and practical challenges that it presents .",
    "we also have made some recommendations on improvement .    a curious finding is the posterior dependence of @xmath50 and @xmath51 , in contradiction to our prior assumption .",
    "although the very efficient method huerta et al .",
    "( 2004 ) propose to sampling these parameters is biased , that bias does not appear large enough to account for that phenomenon .",
    "we also discovered that the assumption of their constancy over time is untenable .",
    "the coverage probabilities of the model s posterior predictive credibility intervals over successive weeks , conditional on all @xmath349 weeks of data , increase monotonically .",
    "counter to intuition , that would imply more and more uncertainty as time evolves , an artifact of the modelling that seems hard to explain . a pragmatic way around this undesirable property involves incorporating the length of the time span of the temporal domain @xmath48 into the selection of the values of the model parameters , such as @xmath40 @xmath376 and @xmath377 section [ pred : var : simplest : dlm ] studies the correlation structure of the simplest first  order polynomial dlm and finds reasonable conditions to impose on those parameters . one further study @xmath378 tests the proposed constraints on the data .",
    "the settings are identical with those in study @xmath359 except that @xmath40 @xmath376 and @xmath379 are replaced by @xmath380 @xmath381 and @xmath382 respectively , to take account of the longer @xmath349 week time span of our study compared to the one week time span of the application in huerta et al .",
    "figure [ cov : prob : paper ] compares study @xmath378 with the others .",
    "observe that its coverage probabilities behave like those of study @xmath362 this adjustment does seem to eliminate the undesirable property of increasing credibility bands of studies @xmath358 and @xmath361    another possible approach to dealing with the unsuitability of fixed model parameters uses the composition of metropolis  hasting kernels .",
    "in other words , we could include these parameters in the metropolis  hasting algorithm as in section [ ffbs : state : sample ] .",
    "we can use six metropolis  hasting kernels to sample from the target distribution @xmath383 , updating each component of @xmath145 iteratively , where @xmath145 has defined in section [ chapter2:dlmbackgrand ] .",
    "but , not surprisingly that approach fails because of the extreme computational burden it entails .",
    "however , that alternative is the subject of current work along with an approach that admits time varying @xmath50s and @xmath51s .    the greatest difficulty involved in the use of the dlm in modelling air pollution space ",
    "time fields lies in the computational burden it entails .",
    "for that reason , we have not been able to address the geographical domain of real interest , one that embraces @xmath384 sites in the eastern united states , with 120 days of hourly ozone concentrations . in a manuscript under preparation , an alternative hierarchical bayesian method that can cope with that larger domain",
    "will be compared with the dlm where the latter can practically be applied .",
    "we thank prasad kasibhatla of nicholas school of the environment of duke university for providing the dataset used in this paper and helping with its installation . the funding for the work",
    "was provided by the natural sciences and engineering research council of canada .",
    "only the results about the predictive variances of @xmath385 and @xmath386 are shown in this appendix .",
    "the other two cases can be obtained by the same method .",
    "refer to theorem [ pred : var : simple : dlm : result ] , the predictive variance of @xmath385 can also be written as follows : @xmath387        and @xmath391 respectively .",
    "it is straightforward to obtain that @xmath138 is increasing when @xmath133 increases , or @xmath50 decreases , or @xmath135 increases .",
    "we next show these properties also hold for @xmath392 by theorem [ pred : var : simple : dlm : result ] , @xmath393 can also be written as : @xmath394 the corresponding first partial derivatives are given as follows : @xmath395              if the prior for @xmath51 is an inverse gamma distribution with shape parameter @xmath194 and scale parameter @xmath407 then the posterior distribution for @xmath51 is also an inverse gamma distribution with shape parameter @xmath196 and scale parameter @xmath408          given the values of the phase parameters , range and variance parameters and the observations until time @xmath22 , the joint distribution of @xmath412 is @xmath413\\ ] ] where @xmath414,\\ ] ] with @xmath415 a scalar , @xmath416 a @xmath338 by @xmath8 vector , and @xmath417 a @xmath8 by @xmath8 matrix .",
    "we use @xmath418 to denote the new distance matrix for the unknown site @xmath84 and the monitoring stations @xmath419            burke , j.m . and zufall , m.j . and ozkaynak , h. ( 2001 ) . a population exposure model for particulate matter : case study results for pm@xmath425 in philadelphia , pa , _ j. exposure anal . environ",
    "epidemiol._,11 , 470489 .",
    "calder , c.a . and",
    "holloman , c.h . and bortnick , s.m . and strauss , w.j . and morara , m. ( 2003 ) . relating ambient particulate matter concentration levels to mortality using an exposure simulator , preprint # 725 , dept .",
    "ohio state u."
  ],
  "abstract_text": [
    "<S> this paper presents a dynamic linear model for modeling hourly ozone concentrations over the eastern united states . </S>",
    "<S> that model , which is developed within an bayesian hierarchical framework , inherits the important feature of such models that its coefficients , treated as states of the process , can change with time . </S>",
    "<S> thus the model includes a time  </S>",
    "<S> varying site invariant mean field as well as time varying coefficients for 24 and 12 diurnal cycle components . </S>",
    "<S> this cost of this model s great flexibility comes at the cost of computational complexity , forcing us to use an mcmc approach and to restrict application of our model domain to a small number of monitoring sites . </S>",
    "<S> we critically assess this model and discover some of its weaknesses in this type of application . </S>"
  ]
}