{
  "article_text": [
    "we analyze a situation where a simple model is used when the true model is , in fact , much more complex .",
    "this situation is particularly common with many contemporary datasets where the number of potentially important covariates or the number of parameters exceeds the sample size ; examples in , say , genomics or economics abound . when facing a large number of potentially important covariates or parameters , and a small sample size , the search for simple models is typically motivated by either one of two types of assumptions : parametric assumptions , which postulate that the true data - generating process is given by a simple finite - dimensional model ; and nonparametric assumptions , which postulate that the true data - generating process can be approximated , with arbitrary accuracy , by comparatively simple finite - dimensional models . in either case",
    ", the underlying postulates can be difficult to verify in practice .",
    "and this difficulty is often further compounded by the relatively small sample size .",
    "the results that we obtain here provide an alternative justification for the use of simple models .",
    "we analyze a scenario where most simple submodels are approximately correct , provided only that the overall model is sufficiently complex , irrespective of whether or not the true data - generating process is given by , or can be closely approximated by , a finite - dimensional simple model .",
    "this is the main conceptual contribution of this paper .    on a technical level , we extend and refine a method pioneered by hall and li  @xcite . in that reference , the authors propose a novel approach for studying conditional means of linear projections under weak distributional assumptions ; cf . theorem  3.2 of  @xcite .",
    "our technical core contribution is an extension of hall and li s approach to also cover conditional variances and higher conditional moments , and a more explicit control of error terms that allows us to prove strong statements like  ( [ c1000 ] ) and  ( [ c2000 ] ) , which follow . note that we deal here with the largest singular value of conditional covariance matrices of increasing dimension , which turns out to be considerably more challenging than handling the norm of the conditional mean vectors that are treated in  @xcite .",
    "the paper is organized as follows : we continue this section with a more detailed overview of our findings , and with a discussion of some interesting consequences . in section  [ s4 ] , we present our main result , namely theorem  [ t0 ] , and give an outline of its proof .",
    "the proof is based on five basic steps that correspond to five propositions that are also given in section  [ s4 ] .",
    "the ( more technical ) proofs of these propositions are relegated to the supplementary material  @xcite .",
    "consider a random @xmath0-vector @xmath1 that has a lebesgue density and that is standardized so that @xmath10 and @xmath3 . throughout , we will study projections of @xmath1 of the form @xmath11 and @xmath12 for unit @xmath0-vectors @xmath4 and @xmath5 . the conditional mean of @xmath13 given @xmath14 will be denoted by @xmath15 $ ] ; other conditional expectations are defined similarly.there is a measurable function @xmath16 so that @xmath17 = g(\\beta ' z)$ ] holds , and we write @xmath18 $ ] for @xmath19 ; the existence of @xmath20 is guaranteed by , say , theorem  4.2.8 of  @xcite .",
    "when we say that @xmath18 $ ] is linear in @xmath9 [ as in condition  ( i ) , which follows ] , we mean that @xmath19 can be chosen to be linear .",
    "similar considerations apply , mutatis mutandis , to expressions like @xmath21 $ ] , @xmath22 $ ] or @xmath23 $ ] . ]",
    "our main results are concerned with the conditional mean and with the conditional variance of @xmath11 given that @xmath24 . to introduce these ,",
    "consider the following two conditions : the vector @xmath5 is such that :    for each @xmath4 , the conditional mean of @xmath13 given @xmath24 is linear in @xmath25 ;    for each @xmath4 , the conditional variance of @xmath11 given @xmath24 is constant in @xmath25 .",
    "suppose that @xmath4 is an unknown parameter and that one can observe @xmath8 and @xmath9 given by @xmath26 and @xmath27 , respectively .",
    "if @xmath5 is such that both ( i ) and ( ii ) hold , then @xmath8 can be decomposed into the sum of a linear function of @xmath9 and a remainder - term , or error - term , whose conditional mean given @xmath9 is zero and whose conditional variance given @xmath9 is constant ; in other words , the model @xmath28 applies , where @xmath29 = 0 $ ] and @xmath30=\\sigma^2 $ ] , and where @xmath31 and @xmath32 are unknown parameters that are given by @xmath33 and @xmath34 , respectively .",
    "( indeed , ( i ) implies that @xmath35 = { \\mathbb{e}}[\\alpha'z\\|\\beta'z ] = \\mu+\\gamma(\\beta'z)$ ] for some real constants @xmath36 and @xmath37 .",
    "it now follows from @xmath10 that @xmath38 , and @xmath3 implies that @xmath39 .",
    "moreover , ( ii ) entails that @xmath40 = \\sigma^2 $ ] for some constant  @xmath41 ; hence @xmath42 + { \\mathbb{e } } [ ( { \\mathbb{e}}[\\alpha'z\\|\\beta'z])^2 ] = \\sigma^2 + ( \\alpha'\\beta)^2 $ ] , so that @xmath41 is given by @xmath34 . ) these observations continue to hold also if the vectors @xmath4 and @xmath5 are not normalized to unit length , mutatis mutandis .    conditions ( i ) and ( ii ) are satisfied for each @xmath5 if @xmath1 is normally distributed , that is , @xmath43 .",
    "but besides the gaussian law , the class of distributions that satisfy  ( i ) and ( ii ) for each @xmath5 appears to be quite small : indeed , if @xmath1 satisfies ( i ) for each @xmath5 , then the law of @xmath1 is spherically symmetric  @xcite . and if , in addition , also ( ii ) holds for some @xmath5 , then @xmath1 is gaussian  @xcite , theorem  4.1.4 .    under comparatively mild conditions on the distribution of @xmath1",
    ", we here show that both conditions ( i ) and ( ii ) are _ approximately _ satisfied for _ most _ unit - vectors  @xmath5 , namely for a set of unit - vectors @xmath5 whose size , as measured by the uniform distribution on the unit - sphere in @xmath44 , goes to one as @xmath45 . to state this more formally ,",
    "we first describe two preliminary results , namely ( [ c100 ] ) and ( [ c200 ] ) , which follow , and then extend these to our main results in ( [ c1000 ] ) and ( [ c2000 ] ) below .    to introduce the two preliminary results mentioned earlier , we note that ( i ) and ( ii ) together are equivalent to the requirement that @xmath46= \\beta x$ ] and @xmath23 = i_d + ( x^2 - 1 ) \\beta\\beta'$ ] hold for each @xmath25 .",
    "( in other words , the first two moments of the conditional distribution coincide with what they would be in the gaussian case . ) from this , it is easy to see that ( i ) and ( ii ) are also equivalent to the requirement that both @xmath47 \\bigr\\vert^2 - x^2 & = & 0 \\quad\\mbox{and } \\\\ \\label{c20 } \\bigl\\vert { \\mathbb{e}}\\bigl [ z z ' \\|\\beta'z = x\\bigr ] - \\bigl(i_d + \\bigl(x^2 - 1\\bigr ) \\beta\\beta ' \\bigr)\\bigr \\vert & = & 0\\end{aligned}\\ ] ] hold for each @xmath25 .",
    "note that we use the notation @xmath48 to denote both the euclidean norm of vectors as in ( [ c10 ] ) and the operator norm of matrices as in ( [ c20 ] ) .",
    "the left - hand side of ( [ c10 ] ) can be written as @xmath49 \\bigr\\vert^2 - x^2 = \\sup_{\\alpha } \\bigl| { \\mathbb{e}}\\bigl[\\alpha ' z\\| \\beta'z = x\\bigr ] - \\alpha ' \\beta x \\bigr|^2,\\ ] ] with the supremum taken over all unit - vectors @xmath50 , as is elementary to verify .",
    "this easily follows from the fact that @xmath51 $ ] ( resp . , @xmath52 )",
    "is the orthogonal projection of  @xmath1 into the space of all measurable ( resp .",
    ", linear ) functions of @xmath53 in @xmath54 , and from the relation between the unconditional and the conditional variance . ]",
    "hence , the left - hand side of ( [ c10 ] ) is always nonnegative and can be interpreted as the worst - case deviation of the regression function @xmath55 $ ] from a linear function at @xmath9 . the left - hand side of ( [ c20 ] )",
    "can be interpreted in a similar fashion . for fixed @xmath25 , the condition ( [ c10 ] )",
    "is approximately satisfied for most @xmath5 s if @xmath0 is large , under the assumptions of theorem  3.2 in  @xcite [ see also equation ( 1.5 ) in that reference ] , in the sense that @xmath56 \\bigr\\vert^2 - x^2 > \\varepsilon \\bigr\\ } \\stackrel{d\\to\\infty } { \\longrightarrow } 0\\ ] ] for each fixed @xmath25 and for each @xmath57 , where @xmath58 denotes the uniform distribution on the unit - sphere in @xmath44 .",
    "we here show that condition ( [ c20 ] ) is similarly approximately satisfied for most @xmath5 s if @xmath0 is large , in the sense that @xmath59 - \\bigl(i_d + \\bigl(x^2 - 1\\bigr ) \\beta\\beta'\\bigr ) \\bigr\\vert >",
    "\\varepsilon \\bigr\\ } \\stackrel{d\\to\\infty } { \\longrightarrow } 0\\ ] ] for each @xmath25 and for each @xmath57 under the assumptions of theorem  [ t0 ] in section  [ s4 ] .",
    "so far , we have seen for _ fixed _",
    "@xmath25 and for most @xmath5 s that ( [ c10 ] ) and ( [ c20 ] ) are approximately satisfied , in the sense that ( [ c100 ] ) and ( [ c200 ] ) hold under some conditions .",
    "our main result is that ( [ c10 ] ) and ( [ c20 ] ) are approximately satisfied for most @xmath5 s and for most @xmath9 s : under the assumptions of theorem  [ t0 ] , there are borel subsets @xmath60 of @xmath44 satisfying @xmath61 so that @xmath62 \\bigr\\vert^2 - \\bigl(\\beta'z\\bigr)^2 > \\varepsilon \\bigr ) & \\stackrel{d\\to\\infty } { \\longrightarrow } & 0 \\quad \\mbox{and } \\\\",
    "\\label{c2000 } \\sup_{\\beta\\in b_d } { \\mathbb{p}}\\bigl ( \\bigl\\vert { \\mathbb{e}}\\bigl [ z z ' \\| \\beta'z\\bigr ] - \\bigl(i_d + \\bigl(\\bigl ( \\beta'z\\bigr)^2 - 1\\bigr ) \\beta\\beta'\\bigr ) \\bigr\\vert > \\varepsilon",
    "\\bigr ) & \\stackrel{d\\to\\infty } { \\longrightarrow } & 0\\end{aligned}\\ ] ] hold for each @xmath57 .    following a referee s suggestion , we now compare our findings to the work of diaconis and freedman  @xcite , which is an important precursor to the results of  @xcite and hence , a fortiori , also to the results in this paper ; see also the discussion surrounding the displays ( 1.7)(1.8 ) in  @xcite .",
    "( moreover , the recent work of dmbgen and zerial  @xcite should be mentioned here , where several extensions and generalizations of the results of  @xcite are provided . ) under the assumptions of theorem  [ t0 ] , proposition  5.2 of  @xcite entails , for large @xmath0 , that the ( bivariate ) joint distribution of @xmath13 and @xmath53 is approximately normal , with zero means , unit variances , and covariance @xmath63 , for most pairs of unit - vectors @xmath4 and @xmath5 ( in the sense of weak convergence in probability with respect to the product measure @xmath64 as @xmath45 ) . because the normal distribution has linear conditional means and constant conditional variances , this suggests , but does not prove , that @xmath65 - \\alpha'\\beta \\beta'z \\bigr|^2 > \\varepsilon",
    "\\bigr ) \\stackrel{d\\to\\infty } { \\longrightarrow } 0\\ ] ] for each @xmath66 and for most pairs of unit - vectors @xmath4 and @xmath5 in @xmath44 ( in the sense of convergence in probability as a function of @xmath4 and @xmath5 with respect to @xmath64 ) .",
    "if  @xmath4 is treated as an unknown parameter , and if the observations @xmath13 and @xmath53 are treated as response and explanatory variable , respectively , then ( [ c150 ] ) entails , for _ most @xmath4 s and @xmath5 s _ , that the response can be approximated by a linear function of the explanatory variable plus an error term with zero mean conditional on @xmath53 , provided that @xmath0 is large .",
    "the approximating linear function is @xmath67 .",
    "but for large @xmath0 , we also have @xmath68 for most @xmath4 s and @xmath5 s ( with respect to @xmath64 ) .",
    "the statement in  ( [ c1000 ] ) , on the other hand , is equivalent to @xmath69 - \\alpha'\\beta \\beta'z \\bigr|^2 > \\varepsilon \\bigr ) \\stackrel{d\\to\\infty } { \\longrightarrow } 0\\ ] ] for each @xmath66 ( in probability as a function of @xmath5 with respect to @xmath58 ) ; cf .",
    "the discussion following ( [ c20 ] ) .",
    "the statement in ( [ c151 ] ) is obviously much stronger than that in  ( [ c150 ] ) . and",
    "it guarantees that the conditional mean of @xmath13 is approximately linear in @xmath53 , _ for all @xmath4 s and for most @xmath5 s _ ; this includes , in particular , the statistically interesting case where @xmath4 is parallel , or close to parallel , to @xmath5 . finally ,",
    "as already observed in  @xcite ,  diaconis and freedman s result does not provide clues as to whether [ statements like ( 1.8 ) ] might be true or false .",
    " similar observations also apply to conditional variances , mutatis mutandis .      if the left - hand sides of ( [ c1000 ] ) and ( [ c2000 ] ) are both small , and if @xmath70 , then the simple linear model , where the response @xmath11 is explained by a linear function of the explanatory variable @xmath12 plus an error that has zero mean and constant variance given @xmath12 , is approximately correct , irrespective of the unit - vector @xmath4 . here , `` approximately correct '' means that the expressions on the left - hand sides of ( [ c10 ] ) and ( [ c20 ] ) are at most @xmath71 for a range of values @xmath9 that contains the explanatory variable @xmath12 with high probability . under the conditions of theorem  [ t0 ] ,",
    "a sufficiently large dimension is enough to guarantee that @xmath60 is large and that the left - hand sides of ( [ c1000 ] ) and ( [ c2000 ] ) are small .",
    ", irrespective of @xmath4 ; the performance of this model , on the other hand , that is , the performance of @xmath53 as a predictor for @xmath13 , depends on both @xmath5 and @xmath4 . under classical parametric or nonparametric assumptions ,",
    "a simple model that is ( approximately ) correct typically also performs well .",
    "]    the statistical impact of our results is most pronounced in situations where the sample size is small and the dimension is large .",
    "assume that theorem  [ t0 ] applies , and consider a collection of @xmath72 independent copies of the pair @xmath73 that we denote by @xmath74 , @xmath75 , with @xmath70 .",
    "if @xmath0 is large and @xmath72 is comparatively small , so that the left - hand sides of both ( [ c1000 ] ) and ( [ c2000 ] ) are still small even when multiplied by @xmath72 , then the simple linear model discussed in the preceding paragraph can also be used to approximately describe the relation between @xmath76 and @xmath77 for each @xmath78 , irrespective of @xmath4 .",
    "we stress that additional data may give reason to dismiss the simple linear model considered in the preceding paragraphs in favor of a more complex one , because the error suffered from using a model that is only approximately correct will typically become apparent if @xmath72 increases to a value that is no longer sufficiently small relative to @xmath0 .",
    "this is in line with r.  a. fisher s 1922 observation that `` more or less elaborate forms [ of models ] will be suitable according to the volume of data ; '' cf .",
    "and we stress that our results can not guarantee that a given simple model , like that discussed in the preceding paragraphs , is correct .",
    "but we can guarantee , under the assumptions of theorem  [ t0 ] , that most simple models are approximately correct , in the sense that @xmath79 is large and in the sense that the left - hand sides of  ( [ c1000 ] ) and  ( [ c2000 ] ) are small , provided only that @xmath0 is sufficiently large .",
    "this also underscores the need for critical examination of the data and of the model fit , irrespective of whether or not @xmath0 is large . to this end , a very useful diagnostic tool is introduced by li in  @xcite , namely a method to estimate , for a given unit - vector  @xmath5 , that unit - vector @xmath4 for which the conditional mean of @xmath13 given @xmath53 is most nonlinear in @xmath53 ; see also section 6.1 in that reference .",
    "the results obtained in this paper do not suggest that one should abandon the search for complex and potentially nonlinear relations in the data .",
    "but after such complex and/or nonlinear relations have been accounted for , or in the case where none such can be found , our results show how the use of simple linear models can be justified without imposing strong regularity conditions on the true data - generating process .",
    "the discussion so far prompts for two extensions of our results that are beyond the scope of this paper .",
    "the first one is to extend our findings to the case of more than one explanatory variable , that is , the case where the conditioning is not on @xmath80 but on @xmath81 for a collection of @xmath82 mutually orthogonal unit - vectors @xmath83 .",
    "in fact , hall and li  @xcite sketch an extension of their results to that situation , so that an appropriate generalization of ( [ c100 ] ) holds .",
    "we will consider a corresponding generalization of ( [ c200 ] ) and also of the main results in ( [ c1000 ] ) and  ( [ c2000 ] ) elsewhere .",
    "the second extension is to provide explicit upper bounds for the expressions on the left - hand sides of ( [ c1000 ] ) and ( [ c2000 ] ) that converge to zero as @xmath45 at a fast rate ; and to provide an explicit lower bound for @xmath79 that converges to one as @xmath45 also at a fast rate .        many modern dimension reduction methods , like those based on inverse conditional moments , rely on conditions like  ( i ) and  ( ii ) in section  [ s2 ] . in particular ,",
    "first - moment - based methods like sliced inverse regression  @xcite are based on a linear conditional mean requirement as in  ( i ) .",
    "( besides , this requirement is also used in several important results on generalized least squares under possible link misspecification ; see , for example ,  @xcite and the references cited therein . ) and second - moment - based techniques like the sliced average variance estimator  @xcite , principal hessian directions  @xcite , or directional regression  @xcite , are based on both a linear conditional mean requirement as in ( i ) , and on a constant conditional variance requirement as in ( ii ) . both conditions ( i ) and ( ii )",
    "are also used in recent works such as  @xcite .    given observations from a potentially rather complex data - generating process , the dimension - reduction methods mentioned in the preceding paragraph aim at finding a simpler model that also describes the data . to justify the dimension reduction",
    ", these methods make assumptions to the effect that requirements like ( i ) or  ( ii ) are satisfied , for _ one particular projection _ , namely for the projection on the so - called central subspace . under such assumptions , the central subspace or , equivalently ,",
    "the projection onto it , can be recovered from the data with good accuracy . but as outlined in the , verifying such assumptions in practice can be hard , particularly in situations where the sample size is comparatively small .",
    "our results provide an alternative justification for requirements like ( i ) and ( ii ) .",
    "in particular , in the setting of theorem  [ t0 ] , we see that both ( i ) and ( ii ) are approximately satisfied for _ most projections _",
    "@xmath12 in the sense of ( [ c1000 ] ) and ( [ c2000 ] ) , provided only that the underlying dimension is large . for the linear conditional mean condition",
    ", we stress that the relation ( [ c100 ] ) has been derived much earlier in  @xcite .",
    "consider the linear model with univariate response @xmath8 and a @xmath0-vector of explanatory variables @xmath84 , that is , @xmath85 where @xmath86 is unknown , and where the error @xmath71 has zero mean and constant variance conditional on @xmath84 .",
    "we also assume that @xmath8 and @xmath84 are square integrable and centered so that @xmath87 .",
    "the leading case we have in mind is a situation where @xmath0 , that is , the number of available regressors , is as large as , or even much larger than , the sample size . to deal with such situations , it is common to assume that the true model ( [ m1 ] ) is equal to , or can be closely approximated by , a `` sparse '' submodel that uses only a few explanatory variables , and to use the available data to select and fit a sparse submodel .",
    "such sparsity assumptions are clearly restrictive . in the following , we argue that the results in this paper provide weaker , and",
    "hence less restrictive , assumptions that also justify the fitting of sparse submodels .    for illustration , consider now an extremely sparse model where @xmath8 is regressed on just one explanatory variable , say , @xmath88 , that is , @xmath89 where @xmath90 is unknown , and where @xmath91 has zero mean and constant variance given  @xmath88 . to consider various possible justifications of the sparse submodel ( [ m2 ] ) , we first rewrite the overall model ( [ m1 ] ) as @xmath92 \\bigr ) + \\bigl ( \\theta_{\\neg1 } ' w_{\\neg1 } - { \\mathbb{e}}\\bigl [ \\theta_{\\neg1 } ' w_{\\neg1 } \\| w_1\\bigr ] + \\varepsilon \\bigr),\\ ] ] where @xmath93 and @xmath94 are obtained from @xmath95 and @xmath84 , respectively , by deleting the first component .",
    "one possibility to justify the sparse model ( [ m2 ] ) is to impose the extreme sparsity assumption that all coefficients of @xmath96 are zero , so that @xmath97 .",
    "then the relation in the preceding display obviously reduces to @xmath98 , and ( [ m2 ] ) applies with @xmath99 and @xmath100 . under this extreme sparsity assumption",
    "we obtain , in particular , that the sparse model ( [ m2 ] ) is equivalent to the overall model ( [ m1 ] ) in terms of prediction , because @xmath101 = { \\mathbb{e}}[y \\| w]$ ] .",
    "a slightly relaxed sparsity condition is to assume that the coefficients of @xmath96 are possibly nonzero but otherwise negligible , that is , @xmath102 , so that the sparse model ( [ m2 ] ) is approximately valid with @xmath103 and @xmath104 .",
    "an alternative justification of ( [ m2 ] ) is to impose the assumption that , given  @xmath88 , the conditional mean of @xmath105 is linear in @xmath88 and the conditional variance of @xmath105 is constant in @xmath88 . in that case , the relation in the preceding display also reduces to ( [ m2 ] ) , but now with @xmath106 /{\\operatorname{var}}[w_1 ] = \\theta_1 + \\sum_{i=2}^d \\theta_i { \\operatorname{cov}}[w_1,w_i]/{\\operatorname{var}}[w_1]$ ] , and @xmath107 + \\varepsilon$ ] . under this alternative assumption ,",
    "the model ( [ m2 ] ) is valid but typically less accurate in terms of prediction than the overall model ( [ m1 ] ) , because , typically , @xmath108 \\neq{\\mathbb{e}}[y\\|w]$ ] and hence @xmath109 > { \\operatorname{var}}[y\\|w]$ ] .",
    "as before , these assumptions can be relaxed by requiring that the conditional mean is approximately linear and the conditional variance is approximately constant .    in the preceding two paragraphs , we have considered two types of justifications for fitting the submodel ( [ m2 ] ) .",
    "type ( a ) : exact or approximate sparsity assumptions . and type ( b ) : exact or approximate linear conditional mean and constant conditional variance assumptions . in practice , verifying either of these assumptions for a given submodel can be difficult . this raises the question as to which set of assumptions , that is , ( a ) or ( b ) , is more restrictive . to this end",
    ", we first note that  ( a ) obviously implies ( b ) . for the more detailed comparison that we give in the following , we assume that the law of @xmath84 is nondegenerate so that @xmath84 can be written as @xmath110 for a @xmath0-vector @xmath1 satisfying @xmath111 and @xmath3 .",
    "the @xmath112 matrix  @xmath113 is a square root of the variance / covariance matrix of @xmath84 , which is nondegenerate by assumption ; which can be assumed to be symmetric ; and which need not be known in practice .",
    "then @xmath105 and @xmath88 can be written as @xmath114 and @xmath115 with @xmath116 and @xmath117 .",
    "the type ( a ) condition that @xmath118 entails that @xmath119 is equal to zero ; the collection of @xmath95 s that satisfy this condition is the @xmath120-dimensional subset of the parameter space @xmath44 that is spanned by @xmath121 ( this collection depends on  @xmath122 ) . more generally , for @xmath8 as in ( [ m1 ] ) and for each vector @xmath123 , the simple model with response @xmath8 and with explanatory variable @xmath124 , that is , @xmath125 , can be justified by the type ( a ) condition that @xmath95 is parallel to @xmath126 . and , for each vector  @xmath123 , the approximate type ( a ) condition , that @xmath95 is approximately parallel to @xmath127 , is satisfied if @xmath95 belongs to an appropriately small neighborhood of the span of @xmath127 .    to study type ( b ) conditions on the conditional moments of @xmath105 given @xmath88 or , equivalently , on the conditional moments of @xmath128 given @xmath129 , we may replace the vectors @xmath119 and @xmath122 by standardized versions @xmath130 and @xmath131 that have length one , for example , @xmath132",
    "( indeed , the conditional mean of @xmath128 given @xmath129 is linear , or approximately linear , in @xmath129 , if and only if the same is true for the conditional mean of @xmath133 given @xmath134 ; and a similar statement applies for the conditional variances , mutatis mutandis . ) if theorem  [ t0 ] applies and if @xmath0 is large , then _ for most @xmath5 s and uniformly in @xmath4 _ , the conditional mean of @xmath13 given @xmath12 is approximately linear and the conditional variance of @xmath11 given @xmath12 is approximately constant , in the sense of ( [ c1000 ] ) and ( [ c2000 ] ) . in terms of the original parameter @xmath95 , we note that uniformity in @xmath4 corresponds to uniformity in @xmath135 .",
    "our main result is that ( [ c100])([c200 ] ) and also ( [ c1000])([c2000 ] ) hold , for sets @xmath60 with @xmath136 . we will establish this under the basic condition that @xmath1 has a lebesgue density and is standardized so that @xmath10 and @xmath3 for each @xmath0 . for the method of proof that we employ",
    ", we also rely on two technical conditions , which follow .",
    "we have @xmath140 = o(1)$ ] as @xmath45 .",
    "moreover , let @xmath141 be a monomial in the elements of @xmath142 of degree @xmath143 . if @xmath141 has a linear factor , then @xmath144 . and if @xmath141 consists only of quadratic factors in the elements of @xmath142 above the diagonal , then @xmath145 .",
    "consider two monomials @xmath146 and @xmath141 of degree @xmath20 and @xmath147 , respectively , in the elements of @xmath148 . if @xmath146 is given by @xmath149 , if @xmath141 depends at least on those @xmath139 s with @xmath150 , and if @xmath151 , then @xmath152 .    for fixed @xmath137 , for each @xmath0 , and for any orthogonal @xmath112 matrix @xmath153 ,",
    "the marginal density of the last @xmath154 components of @xmath155 is bounded by @xmath156 for some constant @xmath157 that does not depend on @xmath0 or @xmath153 .",
    "conditions  ( ) and  ( ) are always satisfied , for any fixed @xmath158 , if the components of @xmath1 are independent , with bounded marginal densities and bounded marginal moments of sufficiently high order ; cf .",
    "example  a.1 in the  supplementary material  @xcite .",
    "also , if @xmath159 = o(1)$ ] , then condition ( ) ( a ) is satisfied if the elements of @xmath160 jointly converge to a gaussian ; cf .",
    "example  a.2 in the  supplementary material  @xcite",
    ". however , these conditions are more general than that and allow , in particular , for situations where the components of @xmath1 are dependent and/or where the elements of @xmath160 do not converge in distribution . also note that both conditions are orthogonally invariant : if @xmath1 satisfies any one of them , then the same is true for any orthogonal transformation of @xmath1 .",
    "the first requirement of condition  ( ) ( a ) entails that @xmath161 for any monomial @xmath141 in the elements of @xmath142 of degree up to @xmath162 .",
    "condition  ( ) ( b ) strengthens parts of condition  ( ) ( a ) in the following sense : consider monomials @xmath146 and @xmath141 as in condition  ( ) ( b ) . if condition  ( ) ( a ) is satisfied , then @xmath163 ( because @xmath164 is a monomial of degree @xmath165 that has a linear factor ) .",
    "condition  ( ) ( b ) requires that @xmath166 converges to zero at the faster rate @xmath167 .",
    "condition  ( ) ensures that the distribution of @xmath1 is not `` too concentrated '' in certain directions , and is used together with ( ) ( a ) to guarantee uniform integrability of @xmath168 and related quantities ( see proposition  e.1 in the  supplementary material  @xcite ) .",
    "also , our conditions should be compared to those used in  @xcite .",
    "the results in  @xcite are stated under high - level assumptions that are less specific but harder to verify ; see , for example , conditions ( 3.21 ) , ( 3.28 ) and ( 3.29 ) of theorem 3.2 in that paper . the only specific example that is actually shown in  @xcite to satisfy all three of these high - level conditions is the normal distribution ; cf .",
    "example  4.2 and remark  4.2 in that paper . ]      [ t0 ] for each @xmath0 , consider a random @xmath0-vector @xmath1 that has a lebesgue density and that is standardized such that @xmath10 and @xmath3 . if conditions   and   are satisfied with @xmath169 , then there are borel sets @xmath170 satisfying @xmath136 , such that ( [ c1000 ] ) holds for each @xmath66 .",
    "if condition   and condition   are satisfied with @xmath171 , then the sets @xmath60 can be chosen so that also ( [ c2000 ] ) holds for each @xmath66 .",
    "[ moreover , for each @xmath25 and each @xmath66 , the relation ( [ c100 ] ) obtains under conditions   and   with @xmath169 , and the relation ( [ c200 ] ) holds under conditions   and   with @xmath171 . ]      as the first step , it will be convenient to replace the usual reference measure on  @xmath44 , that is , lebesgue measure , by the @xmath0-variate standard gaussian measure , that is , @xmath172 .",
    "the effect of this change of measure on conditional densities and on conditional expectations involving @xmath1 is described by the next result .",
    "[ p1 ] fix @xmath173 , and consider a random @xmath0-vector @xmath1 with lebesgue density @xmath174 .",
    "let @xmath175 , and write @xmath176 for the lebesgue density of @xmath177 .",
    "moreover , for a fixed unit - vector @xmath178 and for each @xmath25 , set @xmath179 . then the function @xmath180 defined by @xmath181\\ ] ] for @xmath25 is a density of @xmath53 with respect to the univariate standard gaussian measure [ i.e. , @xmath182 is a lebesgue density of @xmath53 if @xmath183 denotes the @xmath184-density ] . moreover , if @xmath185 is such that @xmath186 is integrable , then a conditional expectation @xmath187 $ ] of @xmath186 given @xmath53 satisfies @xmath188 h(x|\\beta ) = { \\mathbb{e}}\\biggl [ \\psi \\bigl(w^{x|\\beta}\\bigr ) \\frac{f(w^{x|\\beta})}{\\phi(w^{x|\\beta } ) } \\biggr]\\ ] ] whenever @xmath25 is such that @xmath189 .",
    "this result allows us , for fixed @xmath25 , to study the marginal density of @xmath53 at  @xmath9 as well as conditional expectations involving @xmath1 given @xmath14 , by considering unconditional means involving the random variable @xmath190 , which has a @xmath191-distribution .",
    "now , in order to derive  ( [ c100 ] ) , we follow  @xcite and use the following argument ( which can be traced back to hoeffding  @xcite ; see also  @xcite ) : set @xmath192 $ ] , and let @xmath123 be a random vector in @xmath44 with distribution @xmath58 , that is , such that @xmath123 is uniformly distributed on the unit - sphere , that is , on the set of unit - vectors in @xmath44 .",
    "then ( [ c100 ] ) is equivalent to the statement that @xmath193 converges to zero in probability as a function of @xmath123 , and this will follow if @xmath194 \\quad\\mbox{and}\\quad { \\mathbb{e}}\\bigl [ \\bigl ( h(x|b ) - 1 \\bigr)^2 \\bigr]\\ ] ] both converge to zero as @xmath45 , where the expectations are taken with respect to  @xmath123 .",
    "[ note that @xmath195 and @xmath196 are measurable in view of corollary  b.2 .",
    "also note that both integrands in the preceding display are nonnegative . ]",
    "we now compute @xmath197 $ ] as @xmath198 \\biggr)^2 - 2 { \\mathbb{e}}\\biggl [ \\frac{f(w^{x|\\beta})}{\\phi(w^{x|\\beta } ) } \\biggr ] + 1 \\upsilon(d \\beta ) \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\qquad=   { \\mathbb{e}}\\biggl [ \\frac{f(w_1)}{\\phi(w_1 ) } \\frac{f(w_2)}{\\phi(w_2 ) } \\biggr ] - 2 { \\mathbb{e}}\\biggl [ \\frac{f(w_1)}{\\phi(w_1 ) } \\biggr ] + 1,\\end{aligned}\\ ] ] where the @xmath199 s are defined as @xmath200 , @xmath201 , with @xmath202 and @xmath203 i.i.d . @xmath172 and independent of  @xmath123 .",
    "note that @xmath204 and @xmath205 are dependent because both share the same random unit - vector  @xmath123 .",
    "if ( [ e1 ] ) converges to zero or , equivalently , if @xmath206 in @xmath207 as @xmath45 , then @xmath208 with probability one for sufficiently large @xmath0 . for such @xmath0",
    ", we see that the second statement of proposition  [ p1 ] applies for @xmath58-almost all @xmath5 , such that @xmath209 $ ] can be written as @xmath210,\\ ] ] by arguing as in the derivation of ( [ e1 ] ) , as is easy to see . with this",
    ", we see that ( [ c100 ] ) holds if both ( [ e1 ] ) and ( [ e2 ] ) go to zero as @xmath45 . and",
    "if ( [ e1 ] ) and ( [ e2 ] ) converge to zero uniformly in @xmath9 over compact subsets of @xmath211 , that is , if the suprema of ( [ e1 ] ) and ( [ e2 ] ) over @xmath9 satisfying @xmath212 converge to zero as @xmath45 for each @xmath213 , then it is not difficult to also derive ( [ c1000 ] ) by employing standard arguments ; for details , see lemma  b.4(i ) in the  supplementary material  @xcite .    to establish ( [ c200 ] ) , we employ a similar strategy and write @xmath214 as shorthand for the @xmath112 matrix @xmath215 - ( i_d + ( x^2 - 1)\\beta \\beta')$ ] . with @xmath123 again uniform on the unit - sphere , the goal is to show convergence of the largest singular value @xmath216 to zero in probability with respect to @xmath123 . but this follows if @xmath217 as @xmath45 for some even integer @xmath158 ( where , again , corollary  b.2 guarantees measurability ) .",
    "this , and hence also ( [ c200 ] ) , will follow if @xmath218\\ ] ] converges to zero as @xmath45 for some even integer @xmath158 and if , in addition , also ( [ e1 ] ) converges to zero .",
    "( we shall find , at the end of the section , that the expression in the preceding display converges to zero for @xmath171 but typically not for @xmath169 . ) to analyze the expectation in the preceding display , define the function @xmath219 as @xmath220 for @xmath221 .",
    "we now argue as in the preceding paragraph : assume that ( [ e1 ] ) converges to zero , and assume that @xmath0 is sufficiently large so that @xmath222 for @xmath58-almost all @xmath5 .",
    "for such @xmath0 , use proposition  [ p1 ] to see that @xmath223 $ ] equals @xmath224,\\ ] ] where , similarly to before , @xmath225 with the @xmath226 , @xmath227 , i.i.d . @xmath172",
    "independent of @xmath123 . instead of computing the trace in the preceding display directly ,",
    "we find it convenient to break it into smaller , more manageable , pieces . indeed , we find that the expression in the preceding display can be written as the weighted sum of the terms @xmath228 , & \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & \\displaystyle   { \\mathbb{e}}\\biggl [ \\biggl ( \\prod_{i=1}^m w_{j_{i-1}+1 } ' w_{j_{i-1}+2 } \\cdots w_{j_{i}-1 } ' w_{j_{i } } - x^{2(j_m - m ) } \\biggr ) \\frac{f(w_1)}{\\phi(w_1 ) } \\cdots \\frac{f(w_k)}{\\phi(w_k ) } \\biggr]&\\end{aligned}\\ ] ] for @xmath229 and indices @xmath230 satisfying @xmath231 , @xmath232 , and @xmath233 whenever @xmath234 .",
    "in addition , we find that the weights in this weighted sum depend only on @xmath158 and on @xmath9 , and that the weights are continuous in @xmath25 ; cf .",
    "lemma  b.3 for details .",
    "[ note that , in ( [ e3 ] ) , we write @xmath235 as shorthand for @xmath236 , and we also use notation like @xmath237 as shorthand for @xmath238 . ] hence , ( [ c200 ] ) holds if the expression in ( [ e1 ] ) and those in ( [ e3 ] ) go to zero as @xmath45 , the latter for some even integer @xmath158 , and for any @xmath239 and @xmath240 as indicated .",
    "moreover , ( [ c2000 ] ) holds provided that the expressions in ( [ e1 ] ) and ( [ e3 ] ) all converge to zero uniformly in @xmath9 over compact subsets of @xmath211 ; details are given in lemma  b.4(ii ) in the  supplementary material  @xcite .",
    "[ p2 ] for @xmath0 and @xmath158 satisfying @xmath242 , the joint distribution of @xmath243 has a density with respect to lebesgue measure that we denote by @xmath244 , and this density satisfies @xmath245 if @xmath246 is invertible with @xmath247 , and @xmath248 otherwise , where @xmath249 denotes the @xmath250 matrix of scaled inner products of the @xmath251 s , and @xmath252 denotes an appropriate vector of ones .    using proposition  [ p2 ] , we can rewrite the quantities of interest in ( [ e1 ] ) , ( [ e2 ] ) , and ( [ e3 ] ) as follows : for example , ( [ e2 ] ) equals @xmath253,\\nonumber\\end{aligned}\\ ] ] where @xmath254 and @xmath255 are i.i.d .",
    "copies of @xmath1 . in a similar fashion , the quantities in ( [ e3 ] ) can be written as @xmath256 , & \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & \\displaystyle { \\mathbb{e}}\\biggl [ \\biggl ( \\prod_{i=1}^m z_{j_{i-1}+1 } ' z_{j_{i-1}+2 } \\cdots z_{j_{i}-1 } ' z_{j_{i } } - x^{2(j_m - m ) } \\biggr ) \\frac{\\varphi_x(z_1,\\ldots , z_k ) } { \\phi(z_1)\\cdots\\phi(z_k ) } \\biggr]&\\end{aligned}\\ ] ] for @xmath139 , @xmath257 , i.i.d . as @xmath1 . and",
    "finally ( [ e1 ] ) reduces to @xmath258 - 2 { \\mathbb{e}}\\biggl [ \\frac{\\varphi_x(z_1)}{\\phi(z_1 ) } \\biggr ] + 1.\\ ] ]    recall that our goal is to show that the expressions in ( [ a])([c ] ) converge to zero as @xmath45 , uniformly in @xmath9 over compact subsets of @xmath211 .",
    "we show , in fact , a slightly stronger statement , motivated by the obvious conjecture that the expected value of density ratios in ( [ a])([c ] ) , like @xmath259 , converges to one , and also by the observation that the expression in ( [ a ] ) is a special case of the second expression in ( [ b ] ) with @xmath158 replaced by @xmath260 . for an even integer @xmath158 and for each @xmath261 , for each @xmath262 and for any indices",
    "@xmath230 that satisfy @xmath231 , @xmath263 , and @xmath264 whenever @xmath265 , consider the expressions @xmath266 - x^{2(j_m - m)}\\end{aligned}\\ ] ] and also the expression @xmath267 - \\bigl(1-x^2\\bigr)^k .\\end{aligned}\\ ] ] convergence to zero of the expressions in ( [ b ] ) corresponding to @xmath268 ( uniformly over compacts in @xmath9 ) entails convergence to zero of ( [ a ] ) and ( [ c ] ) ( uniformly over compacts in @xmath9 ) . and",
    "if both ( [ b ] ) and ( [ c ] ) converge to zero for some even integer  @xmath158 ( uniformly over compacts ) , then the expressions in ( [ b ] ) corresponding to that same @xmath158 also converge to zero ( uniformly over compacts ) .",
    "[ convergence to zero of ( [ a ] ) follows from convergence to zero of ( [ b ] ) with @xmath269 , @xmath270 and @xmath271 together with convergence to zero of ( [ b ] ) with @xmath272 and @xmath271 .",
    "convergence to zero of  ( [ c ] ) follows from convergence to zero of  ( [ b ] ) with @xmath272 and @xmath273 together with convergence to zero of  ( [ b ] ) with @xmath272 and @xmath271 . for the first expression in ( [ b ] ) , convergence to zero",
    "follows from convergence to zero of  ( [ b ] ) with @xmath272 and @xmath274 and from convergence to zero of ( [ c ] ) , in view of the binomial theorem .",
    "similarly , for the second expression in ( [ b ] ) , convergence to zero follows from convergence to zero of ( [ b ] ) and of convergence to zero of the special case of ( [ b ] ) where @xmath272 and @xmath274 . ]    the expressions in ( [ b])([c ] ) both involve expected values of a polynomial in @xmath275 for some pairs @xmath276 , multiplied by @xmath277 , @xmath261 . to proceed , we need the polynomial approximation to @xmath278 that is provided by the next result .",
    "[ p3 ] fix @xmath213 and @xmath9 satisfying @xmath279 . moreover , consider integers @xmath158 and @xmath0 that satisfy @xmath280 and @xmath281 , and @xmath0-vectors @xmath282 that are such that the @xmath250 matrix @xmath249 satisfies @xmath283 .",
    "then @xmath244 is such that @xmath284 where @xmath285 is a polynomial of degree up to @xmath158 in the elements of @xmath142 .",
    "the coefficients of the polynomial @xmath286 depend on @xmath158 , @xmath9 and @xmath0 , and are bounded , in absolute value and uniformly in @xmath287 $ ] , by a constant @xmath288 , and @xmath289 satisfies @xmath290 , for some constants @xmath291 and @xmath292 that depend only on @xmath158 and on @xmath113 .",
    "moreover , both @xmath285 and @xmath289 are invariant under permutations of the @xmath251 s so that , in particular , @xmath285 is unchanged when @xmath246 is replaced by the matrix @xmath293 for any permutation @xmath294 of @xmath158 elements .",
    "[ the coefficients of @xmath286 and the bounds @xmath288 and @xmath295 can be obtained explicitly upon inspection of the proof . ]",
    "when studying the expected values in ( [ b])([c ] ) , proposition  [ p3 ] suggests that the density ratio @xmath296 can be approximated by the polynomial @xmath285 .",
    "the resulting approximations to ( [ b ] ) and ( [ c ] ) are @xmath297 - x^{2(j_m - m)}\\ ] ] and @xmath298 - \\bigl(1-x^2\\bigr)^k,\\ ] ] respectively . for these approximations to be useful , we need to show that the difference of ( [ b ] ) and ( [ b1 ] ) , and also the difference of ( [ c ] ) and ( [ c1 ] ) , converges to zero as @xmath45 , uniformly in @xmath9 over compact subsets of @xmath211 .",
    "the technical difficulty here is that expressions like , for example , @xmath299 in ( [ c1 ] ) have zero mean but do not converge to zero in probability . to deal with this",
    ", we rely on conditions  ( ) ( a ) and  ( ) .",
    "[ p4 ] for each @xmath0 , consider a random @xmath0-vector @xmath1 that has a lebesgue density , that is standardized such that @xmath10 and @xmath3 , and that satisfies conditions   and   for some fixed integer @xmath158 .",
    "let @xmath300 be a ( fixed ) monomial in the elements of @xmath142 whose degree , denoted by @xmath301 , satisfies @xmath302",
    ". then @xmath303\\ ] ] converges to zero as @xmath45 , uniformly in @xmath9 over compact subsets of @xmath211 .    if proposition  [ p4 ] applies , then it is not difficult to see that the difference between ( [ b ] ) and ( [ b1 ] ) , and also the difference between ( [ c ] ) and ( [ c1 ] ) , converges to zero , uniformly in @xmath9 over compact subsets of @xmath211 , as required .",
    "for example , consider the difference of ( [ c ] ) and ( [ c1 ] ) , which both involve @xmath158 expected values indexed by @xmath304 , and focus on the difference of those expected values corresponding to the index @xmath305 . also , recall that @xmath158 is an even integer , so that @xmath306 . for @xmath307 ,",
    "we simply use proposition  [ p4 ] with the monomial @xmath308 , and note that @xmath309 . for @xmath310 , we first write @xmath311 as @xmath312 now use proposition  [ p4 ] twice , first with the monomial @xmath313 of degree @xmath314 , and then with the degree - zero monomial , and note that @xmath315 here , to see that the difference of expected values corresponding to the index @xmath310 also converges to zero , uniformly in @xmath9 over compact subsets of @xmath211 .",
    "the difference of ( [ b ] ) and ( [ b1 ] ) is treated similarly .    to show that the expressions in ( [ b1 ] ) and ( [ c1 ] ) converge to zero",
    ", the following observation will be useful : if the @xmath139 s in ( [ b1 ] ) and ( [ c1 ] ) are replaced by independent standard normal vectors @xmath226 ( and if @xmath316 and @xmath246 are replaced by the corresponding gram matrices of the @xmath226 s ) , then the resulting expressions both converge to zero as @xmath45 , uniformly in @xmath9 over compact subsets of @xmath211 .",
    "to establish convergence to zero of ( [ b1])([c1 ] ) , uniformly on compacts in @xmath9 , it therefore is sufficient to study the differences between the expressions in ( [ b1])([c1 ] ) and the same expressions with the @xmath139 s replaced by @xmath226 s that are i.i.d .",
    "standard normal , and to show that these differences converge to zero as @xmath45 , uniformly in @xmath9 over compacts subsets of @xmath211 .",
    "( to derive the last observation , we first note that ( [ b ] ) and ( [ c ] ) , with the @xmath139 s replaced by the @xmath226 s , are both equal to zero .",
    "indeed , with this replacement , the expectation in ( [ b ] ) is equal to @xmath317 $ ] , because @xmath318 is the joint density of @xmath319 , and because @xmath320 is the joint density of @xmath321 .",
    "conditional on @xmath123 , the @xmath199 s are conditionally i.i.d . , with @xmath322 = x b$ ] and @xmath323 = i_d + ( x^2 -1 ) b b'$ ] . in view of this",
    ", it is elementary to verify that ( [ b ] ) with the @xmath139 s replaced by the @xmath226 s is equal to zero .",
    "a similar argument applies , mutatis mutandis , to ( [ c ] ) .",
    "next , we note that proposition  [ p4 ] applies if @xmath1 is replaced by a standard normal vector @xmath177 [ that conditions  ( ) ( a ) and  ( ) hold when @xmath1 is replaced by @xmath177 follows either from example  a.1 or upon a simple direct computation ] .",
    "when replacing @xmath1 by @xmath177 throughout , this entails that ( [ b1 ] ) and  ( [ c1 ] ) converge to the same limit as ( [ b ] ) and ( [ c ] ) , that is , to zero , uniformly over compacts in @xmath9 . )",
    "to put this idea to work , expand @xmath285 into a weighted sum of monomials ( in the elements of @xmath142 ) , where the weight of each monomial in the sum is given by the coefficient of that monomial in @xmath285 ; similarly , @xmath324 can also be written as a weighted sum of such monomials for each @xmath325 .",
    "we see that the integrand in ( [ b1 ] ) for @xmath272 , that is , @xmath324 , can be written as the weighted sum of monomials in the elements of @xmath326 .",
    "similarly , for @xmath1 as in theorem  [ t0 ] , the integrand in ( [ b1 ] ) for @xmath327 can be written as the weighted sum of expressions of the form @xmath328 \\bigr ) h\\ ] ] for two monomials @xmath146 and @xmath141 in the elements of @xmath142 of degree @xmath158 or less , where  @xmath146 is given by the monomial @xmath329 of degree @xmath330 , for some @xmath331 and indices @xmath230 that satisfy @xmath231 , @xmath332 , and @xmath333 whenever @xmath265 . in this weighted expansion of  ( [ b1 ] ) ,",
    "note that the weight of ( [ g0 ] ) depends on @xmath9 , on @xmath141 ( through its degrees ) and also on  @xmath0 , in such a way that the weight is bounded in @xmath9 and @xmath0 as long as @xmath9 is restricted to a compact set ( cf .",
    "proposition  [ p3 ] ) .",
    "lastly , consider the integrand in ( [ c1 ] ) , for @xmath1 as in theorem  [ t0 ] . arguing as before ,",
    "we can write that integrand as the weighted sum of expression of the form ( [ g0 ] ) , where here @xmath146 is given by the monomial @xmath334 of degree @xmath305 for some @xmath305 satisfying @xmath335 . and , again , in this weighted sum , the weight of each term depends on @xmath9 and on @xmath141 ( through its degrees ) , and that weight is bounded in @xmath9 and @xmath0 over compacts in @xmath9 .",
    "( note that , under the assumptions of theorem  [ t0 ] , it is elementary to verify that @xmath336 = 0 $ ] whenever @xmath146 is given by  ( [ openc ] ) and also whenever @xmath146 is given by  ( [ closedc ] ) with @xmath307 , and that @xmath337 = d$ ] if @xmath146 is given by  ( [ closedc ] ) with @xmath310 . )    [ p5 ] for each @xmath173 , assume that @xmath1 is as in theorem  [ t0 ] .",
    "fix an integer @xmath280 , and let @xmath146 and @xmath141 be two ( fixed ) monomials in the elements of @xmath326 of degree @xmath158 or less , define @xmath338 and @xmath339 as @xmath146 and @xmath141 , respectively , but with the @xmath340 replaced by i.i.d .",
    "standard gaussian @xmath0-vectors , and consider @xmath341 \\bigr ) h \\bigr ] - { \\mathbb{e}}\\bigl [ d^{\\deg(g^\\ast ) } \\bigl ( g^\\ast- { \\mathbb{e}}\\bigl[g^\\ast\\bigr ] \\bigr ) h^\\ast \\bigr].\\vspace*{-9pt}\\ ] ]    assume that condition   applies with the integer @xmath158 as chosen here , and that @xmath342 .",
    "then @xmath343 - { \\mathbb{e}}[h^\\ast]$ ] and also the expression in ( [ p51 ] ) converge to zero as @xmath45 for each monomial @xmath146 as in ( [ openc ] ) .",
    "[ p5ii ] assume that condition   is satisfied with the integer @xmath158 as chosen here .",
    "let  @xmath146 be given by the monomial in ( [ closedc ] ) for some @xmath305 , @xmath335 .",
    "then the expression in ( [ p51 ] ) converges to zero as @xmath45 , unless either @xmath344 for some @xmath345 satisfying @xmath346 , @xmath347 with @xmath348 , or   @xmath349 with @xmath350 . in case , the expression in ( [ p51 ] ) is equal to @xmath351/d - 2 $ ] ; in case , it is equal to @xmath352/d$ ] ; and in case  , it equals @xmath353/d^2 - 2(1 + 3/d)$ ] .    to complete the proof of theorem  [ t0 ] ,",
    "let @xmath1 be as in the theorem .",
    "we first assume that conditions  ( ) ( a ) and  ( ) are satisfied with @xmath169 . the relation ( [ c100 ] ) holds for each @xmath9 and @xmath71 , if we can show that the expression in ( [ b1 ] ) converges to zero for each collection of indices @xmath354 ,",
    "@xmath239 , @xmath230 so that @xmath355 , @xmath262 , @xmath231 , @xmath356 , and @xmath264 for each @xmath357 . moreover , ( [ c1000 ] ) holds for each @xmath66 , if convergence zero of ( [ b1 ] ) is uniform in @xmath9 over compacts . to this end , consider the difference of the expression in ( [ b1 ] ) and of the same expression with the @xmath139 s replaced by @xmath226 s that are i.i.d .",
    "standard normal @xmath0-vectors . expanding the polynomial @xmath358 into a weighted sum of monomials",
    ", the difference in question can be written as a weighted sum of expressions of the form @xmath343 - { \\mathbb{e}}[h^\\ast]$ ] in case , and as a weighted sum of expressions of the form ( [ p51 ] ) in case , where the weight is given by the coefficient of the monomial @xmath141 in @xmath358 , and where @xmath146 is of the form ( [ openc ] ) [ the monomials @xmath141 , @xmath338 and @xmath339 are as in proposition  [ p5](i ) ] . by proposition",
    "[ p3 ] , we see that the coefficients of @xmath358 are bounded uniformly in @xmath0 and uniformly in @xmath9 over compacts .",
    "and by proposition  [ p5](i ) , we see that expressions of the form @xmath343-{\\mathbb{e}}[h^\\ast]$ ] or of the form ( [ p51 ] ) with @xmath146 as in ( [ openc ] ) all converge to zero .",
    "therefore , ( [ b1 ] ) converges to zero , uniformly in @xmath9 over compacts subsets of @xmath211 .",
    "finally , we assume that conditions  ( ) and  ( ) hold with @xmath171 . to derive ( [ c200 ] ) for fixed @xmath9 and @xmath71",
    ", we show that the expressions in ( [ b1 ] ) and ( [ c1 ] ) converge to zero [ with the indices @xmath354 , @xmath239 , @xmath230 in ( [ b1 ] ) now so that @xmath359 , @xmath262 , @xmath231 , @xmath356 , and @xmath264 for each @xmath357 ] . and ( [ c2000 ] ) holds for each @xmath66 if convergence in ( [ b1 ] ) and ( [ c1 ] ) is uniform in @xmath9 over compact sets .",
    "now convergence to zero of ( [ b1 ] ) ( with @xmath171 here ) , uniformly over compacts , follows by arguing as in the preceding paragraph , mutatis mutandis . to deal with ( [ c1 ] ) , consider the difference of ( [ c1 ] ) and of the same expression with the @xmath139 s replaced by i.i.d .",
    "standard gaussian @xmath226 s .",
    "again , this can be written as a weighted sum of expressions of the form ( [ p51 ] ) , with @xmath146 now as in ( [ closedc ] ) , where the weights are bounded uniformly in @xmath0 and uniformly in @xmath9 over compacts in view of proposition  [ p3 ] .",
    "and by proposition  [ p5](ii ) , we see that ( [ p51 ] ) converges to zero except for those @xmath141 s that correspond to the cases ( a ) , ( b ) and ( c ) in proposition  [ p5](ii ) .",
    "write @xmath361 , @xmath362 , and @xmath363 for the collection of all monomials @xmath141 where the case ( a ) , ( b ) , or ( c ) of proposition  [ p5](ii ) occurs , respectively . for each @xmath364 ,",
    "the value of ( [ p51 ] ) is given @xmath351/d - 2 $ ] and hence does not depend on @xmath141 in view of proposition  [ p5](ii ) . and for each @xmath364 , the coefficient of @xmath141 in the polynomial @xmath365 also does not depend on @xmath141 in view of proposition  [ p3 ] , because the monomials in @xmath361 can be obtained from each other by permutations ( or re - labelings ) of @xmath139 s .",
    "consider now the difference of ( [ c1 ] ) and the same expression with the @xmath139 s replaced by i.i.d .",
    "standard gaussians .",
    "the combined contribution of the monomials in @xmath361 to that difference is given by @xmath366 multiplied by a constant ( namely by @xmath351/d - 2 $ ] times the common coefficient of the monomials from @xmath361 in @xmath285 ) .",
    "similarly , the monomials in @xmath362 contribute @xmath367 multiplied by a constant . and the combined contribution of the monomials in @xmath363 is also given by the expression in the preceding display multiplied by another constant . because we have @xmath171 here , the expressions in the last two displays are both equal to zero .",
    "except for the more technical arguments that we collect in the  supplementary material  @xcite , this concludes the proof of theorem  [ t0 ] ."
  ],
  "abstract_text": [
    "<S> we study the conditional distribution of low - dimensional projections from high - dimensional data , where the conditioning is on other low - dimensional projections . to fix ideas , </S>",
    "<S> consider a random @xmath0-vector @xmath1 that has a lebesgue density and that is standardized so that @xmath2 and @xmath3 . </S>",
    "<S> moreover , consider two projections defined by unit - vectors @xmath4 and @xmath5 , namely a response @xmath6 and an explanatory variable @xmath7 . </S>",
    "<S> it has long been known that the conditional mean of @xmath8 given @xmath9 is approximately linear in @xmath9 , under some regularity conditions ; cf . </S>",
    "<S> hall and li [ _ ann . statist . _ * 21 * ( 1993 ) 867889 ] . </S>",
    "<S> however , a corresponding result for the conditional variance has not been available so far . </S>",
    "<S> we here show that the conditional variance of @xmath8 given @xmath9 is approximately constant in @xmath9 ( again , under some regularity conditions ) . </S>",
    "<S> these results hold uniformly in @xmath4 and for most @xmath5 s , provided only that the dimension of @xmath1 is large . in that sense </S>",
    "<S> , we see that most linear submodels of a high - dimensional overall model are approximately correct . </S>",
    "<S> our findings provide new insights in a variety of modeling scenarios . </S>",
    "<S> we discuss several examples , including sliced inverse regression , sliced average variance estimation , generalized linear models under potential link violation , and sparse linear modeling . </S>"
  ]
}