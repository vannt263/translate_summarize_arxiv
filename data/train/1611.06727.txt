{
  "article_text": [
    "logistic regression is an important and widely used regression model for binary responses , and has found it s use in a variety of applied fields ( cf .",
    "@xcite , @xcite ) , especially in epidemiological research , including medical and social sciences ( cf .",
    "@xcite ) . in many applications , it is not uncommon , that the binary responses are subject to classification errors .",
    "misclassified binary responses occur due to various reasons , e.g. , faulty data collected through surveys ( @xcite , @xcite , @xcite , @xcite ) , limited sensitivity and specificity of the diagnostic tests ( @xcite , @xcite , @xcite ) , incorrect information gathered from medical and other records ( @xcite ) and recall bias in assessing exposure status ( @xcite ) . for pervasiveness of misclassification of important binary outcomes ( _ viz .",
    "_ , program receipt , labor market status , educational attainment , self reported health conditions , physical and mental impairment etc . ) in survey data , and its adverse impact on the estimates of the logistic regression parameters we refer to @xcite and @xcite , and the references therein .",
    "suppose , @xmath0 denotes the true response variable and @xmath1 denotes the misclassified version of @xmath2 .",
    "then , @xmath2 is said to be misclassified , if we observe @xmath3 , when the corresponding @xmath4 , or vice - versa . in this article , we investigate the inference problems in logistic regression when the binary responses are subject to classification errors .",
    "measurement errors in regression models have been widely studied , and excellent text books ( cf .",
    "@xcite , @xcite or @xcite ) are written on it .",
    "the effects of measurement error on covariates has been well investigated for simple logistic regression ( cf .",
    "@xcite , @xcite ) , and also for semiparametric logistic regression ( cf .",
    "@xcite , @xcite ) .",
    "in contrast , the study of the effect of misclassified responses in logistic regression has received lesser attention in statistics literature .",
    "@xcite studied the bias and efficiency loss due to misclassified responses in binary regression .",
    "@xcite ( section 15.3 ) discuss misclassification of binary responses in logistic regression , and show that , not accounting for misclassification introduces severe bias in parameter estimates . throughout , we assume that the information on the underlying covariates is available without any measurement error .    in particular , we assume that the true binary response variable @xmath2 is associated with the @xmath5-dimensional covariate vector @xmath6 by the logistic regression model , @xmath7 where , @xmath8 , is an unknown regression parameter , and @xmath9 denotes the underlying probability distribution corresponding to @xmath10 .",
    "the binary variable @xmath11 , is the misclassified version of the true response @xmath2 .",
    "we assume the following model for misclassification ( @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and @xcite ) , @xmath12 which results in the following regression model for @xmath13 , @xmath14    note @xmath15 are the unknown misclassification probabilities and @xmath9 denotes the probability distribution under @xmath16 .",
    "this misclassification model assumes that , conditional on @xmath2 , the data generation process of @xmath17 is independent of the covariate @xmath6 .",
    "the model , as stated above , is simple , but is not unreasonable as a possible description of the actual data generation process . at the end",
    ", however , we extend our results to the situations , where @xmath16 may depend on @xmath18 .    typically , estimation of the unknown misclassification probabilities @xmath16 ( cf . ) requires information on the pair @xmath19 .",
    "usually , one obtains complete information on @xmath20 for a sub - sample of the main sample known as validation sample .",
    "the validation sample is utilized to obtain an improved estimate of @xmath16 .",
    "the rest of the sample has information available only on @xmath21 , and is known as the non - validation part of the main sample .",
    "use of validation data for adjusting estimates of regression parameters due to misclassification of binary responses is common in many areas of applications .",
    "for example , @xcite , @xcite and @xcite provide examples in epidemiological studies . @xcite and",
    "@xcite describe such situations in the context of economic and social surveys .    in the applications mentioned above ,",
    "though the estimation of regression parameter @xmath10 is of primary interest , the estimation of parameter @xmath16 is also considered to be important as it provides useful information about the level of contamination in the responses .",
    "for estimation of @xmath10 and @xmath16 , a possible approach would be to use the full likelihood based on the combined sample comprising validation and non - validation parts of the main sample .",
    "notice that @xmath16 shows up in the non - validation part of the full - likelihood due to the use of misclassified responses .",
    "the full likelihood , however , as a function of both @xmath10 and @xmath16 is found to be ill behaved , in the sense that it may often lead to nonsensical estimates of @xmath16 even for substantially large sample sizes . in section [ sec - sim - ful - mis ] we will discuss this issue in detail .",
    "an alternative approach is to use pseudo - likelihood method proposed by @xcite .",
    "recently pseudo - likelihood method has been used in various contexts ( cf .",
    "@xcite , @xcite , @xcite , @xcite , @xcite ) especially when , the full likelihood function is ill behaved , yet , the pseudo - likelihood function is well - behaved .",
    "in our situation , pseudo - likelihood based approach amounts to replacing the unknown nuisance parameter @xmath16 in the likelihood by its estimate from the validation sample , and then assuming as if @xmath16 is known , the likelihood is considered as a function of @xmath10 only .",
    "the pseudo - likelihood as a function of @xmath10 is well behaved even for moderately large sample sizes .    since the validation and non - validation parts of the sample do not have identical distributions",
    ", the asymptotic results of @xcite will not be valid in our set up . also plugging in an estimate of @xmath16 , introduces dependence among the validation and the non - validation parts of the pseudo - likelihood function .",
    "we develop rigorous asymptotic results under minimal assumptions , and show that the pseudo likelihood estimator of @xmath10 is asymptotically normal . as shown later in section [ sec-3 - 2 ] , the asymptotic covariance of the pseudo - likelihood estimator is a complicated function of the unknown parameters @xmath10 , @xmath16 , and the unknown distribution of the covariates .",
    "consequently , the analytical computation of the covariance is unwieldy .",
    "thus , for easy implementation of the pseudo - likelihood based inference , we develop a bootstrap methodology .",
    "we prove the distributional consistency of the bootstrapped pseudo - likelihood estimator of @xmath10 .",
    "consistency of bootstrapped pseudo - likelihood estimators has not been investigated widely in the literature , except in very specific scenarios ( cf . @xcite and @xcite ) .",
    "existing approaches for proving consistency of bootstrapped m - estimators ( cf .",
    "@xcite , @xcite and @xcite ) can not be directly applied in our set - up , precisely due to the reasons mentioned in the beginning of this paragraph . in order to establish the consistency of the bootstrapped pseudo - likelihood estimator of @xmath10 , we have developed some new bootstrap stochastic equicontinuity results , which may be of independent interest .",
    "this is a new contribution to the existing literature on bootstrap consistency for pseudo - likelihood estimators .",
    "we discuss the details in section [ sec-4 ] .",
    "we further extend the asymptotic results to the situations where @xmath16 may depend on the covariates @xmath18 in a way as discussed by @xcite and @xcite .",
    "also , we discuss the asymptotic results when one of the components of @xmath16 is zero .    there may be situations when validation data may not be available . in such situations ,",
    "@xcite and @xcite propose maximum likelihood estimators of @xmath16 and @xmath10 based on the contaminated data @xmath22 .",
    "`` as a cautionary note @xcite make the important point for practitioners '' ( @xcite ) that if the sample have a few @xmath18 values for which @xmath23 lie outside the interval @xmath24 then estimation solely on the basis of the contaminated data may lead to serious identifiability problem .",
    "the logit function @xmath23 in this interval is well approximated by a suitably chosen linear function ( cf .",
    "@xcite ) , and thus it is evident from , identifiability of @xmath10 is then a serious issue unless the sample size is large enough to include enough number of @xmath18 values for which @xmath23 lie outside the interval @xmath24 .",
    "we consider this issue in detail in section [ sec - sim - subsub-1 ] .",
    "we conduct simulation studies : ( i ) to compare the performances of the estimators of @xmath16 and @xmath10 based on three different likelihoods discussed above , _",
    "viz_. , full likelihood , pseudo - likelihood and likelihood using contaminated data only , and ( ii ) to investigate the validity of the asymptotic distribution of the pseudo - likelihood estimators and its bootstrap analogues for moderate to large sample sizes .",
    "we report the bias and mean squared error ( mse ) for study ( i ) , and coverage and expected length of the confidence interval of regression parameter for study ( ii ) .",
    "finally , we illustrate our methodology using a real - life data set .    the rest of the article is organized as follows . in section [ sec-2 ] , we state the problem formulation , and describe the pseudo likelihood based estimation methodology .",
    "the main theoretical results on the asymptotic properties of the pseudo - likelihood estimator are given in section [ sec-3 - 2 ] .",
    "theoretical results on the bootstrapped pseudo - likelihood estimator are given in section [ sec-4 ] . in section [ sec-5 ]",
    ", we discuss the extension of our results to more general situations , where misclassification probabilities may depend on the covariates , and also to the situation , where one kind of classification error is absent .",
    "results of numerical study , and the analysis of a real data set are presented in section [ sec - simu ] and concluding remarks are provided in section [ sec : conc ] .",
    "proofs of the main results are given in section [ sec - proofs ] .",
    "in the appendix ( cf .",
    "section [ sec - app ] ) , we provide detailed proofs of auxiliary lemma s needed for proving the main results , we also provide detailed expressions of some matrices used in proving the theorems and prove an useful result on gradients of strictly concave functions .",
    "suppose the complete sample is of size @xmath25 .",
    "the validation sample consists of @xmath26 independent observations on the triplet @xmath27 , and is denoted by @xmath28 .",
    "the non - validation sample consists of @xmath29 independent observations on the pair @xmath30 , and is denoted by @xmath31 .",
    "it is assumed that the validation and non - validation samples are independent of each other .",
    "the full - likelihood at @xmath32 using the complete sample @xmath33 is based on the joint conditional distribution of @xmath34 $ ] and is given by , @xmath35\\right\\}}^{(1-y_i)}\\notag\\\\   & \\quad \\times \\prod_{i = n_1 + 1}^n \\left\\{\\theta^{\\widetilde{y}_i}_1 { ( 1-\\theta_1)}^{(1-\\widetilde{y}_i)}(1-\\psi(\\xbp_i\\bb))+{(1-\\theta_2)}^{\\widetilde{y}_i } \\theta_2^{(1-\\widetilde{y}_i)}\\psi(\\xbp_i\\bb)\\right\\}. \\label{lk - full}\\end{aligned}\\ ] ] where , @xmath36 denotes the logistic link function given in . in order to construct the pseudo likelihood function for @xmath37",
    ", we need to plug in an estimator of the unknown @xmath16 in .",
    "an estimator of @xmath16 arises naturally from the misclassification model .",
    "it is based on the observed cell frequencies of the cells @xmath38 , the four possible values of @xmath39 , obtained from the validation sample .",
    "however , for small validation sample sizes @xmath26 , one or more of theses cell frequencies may be zero .",
    "in such situations , an adjustment of the cell frequencies often improve the performance of the estimator .",
    "one commonly used adjustment ( cf .",
    "@xcite and @xcite ) is to add @xmath40 to each cell frequency , and replace the original cell frequencies in the estimator by the adjusted cell frequencies .",
    "we thus define the estimator @xmath41 , where @xmath42 the small sample properties of the adjusted estimator of the odds ratio in the context of 2@xmath432 contingency tables have been studied in @xcite .",
    "if the validation sample size @xmath26 is large enough , the estimator @xmath44 in is nearly equivalent to the usual cell frequencies based estimator . substituting @xmath44 in the full likelihood function @xmath45 ( cf . )",
    "the scaled pseudo log - likelihood function at @xmath37 becomes , @xmath46\\notag\\\\ & \\quad { } + \\frac{1}{n}\\cdot \\sum_{1\\leq i\\leq n_1,y_i=0 } \\left[{\\widetilde{y}_i}\\log{\\htho } + { ( 1-\\widetilde{y}_i)}\\log{{(1-\\htho)}}+ \\log{\\{1-\\psi(\\xbp_i\\bb)\\}}\\right]\\notag\\\\   & \\quad { } + \\frac{1}{n}\\cdot \\sum_{i = n_1 + 1}^n \\log{\\left[{(\\htho)}^{\\widetilde{y}_i } { ( 1-\\htho)}^{(1-\\widetilde{y}_i)}\\{1-\\psi(\\xbp_i\\bb)\\}+{(1-\\htht)}^{\\widetilde{y}_i } { ( \\htht)}^{(1-\\widetilde{y}_i)}\\psi(\\xbp_i\\bb)\\right]}.   \\ ] ] in order to write down the estimating equation for @xmath37 , we define the following functions : @xmath47 where , @xmath48 , @xmath49 and @xmath50 , for all @xmath37 and @xmath51 .",
    "it should be noted that @xmath52 is the estimating function that arises in simple logistic regression and @xmath53 is same as the conditional expectation of @xmath54 $ ] as in , if @xmath55 is replaced with any arbitrary @xmath32 .",
    "we also define the sequence of validation sample size fractions , @xmath56 and the empirical measures , @xmath57 where , @xmath58 and @xmath59 denote point masses @xmath60 and @xmath61 respectively . for any measurable function @xmath62",
    ", we define @xmath63 and similarly for @xmath64 . with these notations",
    ", the score function corresponding to the pseudo log - likelihood function @xmath65 can be written as , @xmath66          { z}_{n,2}(\\bb ) & = \\prnt h_{2,\\bb,\\thbn }         \\end{aligned}\\right\\ } , \\label{zn1 - 2-def}\\ ] ] note that , @xmath67 is a random function .",
    "the pseudo maximum likelihood estimator ( pmle ) of @xmath10 , which we denote by @xmath68 , satisfies the estimating equation @xmath69 where , @xmath70 denotes the @xmath71 null vector . as seen above ,",
    "the estimating function @xmath72 in is a weighted sum of estimating functions @xmath73 and @xmath74 , which arise from the validation and non - validation samples respectively . if @xmath75 , then the problem reduces to simple logistic regression based estimation of @xmath10 .",
    "the presence of misclassified responses @xmath76 s in the non - validation sample gives rise to the extra term @xmath74 .",
    "since @xmath44 is based on the validation sample and is involved in @xmath74 , the terms @xmath73 and @xmath74 are dependent , even though they arise from independent parts of the complete sample . using and , the pseudo - likelihood estimation problem can be cast into the z - estimation framework ( cf .",
    "chapter 5 of @xcite ) .",
    "although @xmath73 is the sample mean of the independent and identically distributed ( i.i.d . ) summands @xmath77 , and @xmath74 is the sample mean of identical summands @xmath78 , their weighted sum @xmath72 can not be represented as a sample mean of i.i.d .",
    "summands . hence ,",
    "the standard asymptotic theory for z - estimators based on i.i.d .",
    "summands will not be directly applicable for studying the asymptotic properties of @xmath68 .",
    "we describe the theoretical framework for proving the main results .",
    "let @xmath9 be the generic notation for the true distribution of @xmath79 or @xmath80 or @xmath20 under the true value of the parameter @xmath81 .",
    "although the joint distributions of @xmath79 , @xmath80 and @xmath20 are different , we use the same notation for simplicity .",
    "there does not seem to be any confusion , since the underlying random vector is evident from the notation , and the context .",
    "we use the notation @xmath82 , @xmath83 and @xmath84 to denote outer expectation , convergence to zero and bounded in outer probability with respect to the probability measure @xmath9 ( cf .",
    "@xcite ) , respectively . usual expectation , variance and covariance with respect to @xmath9 will be denoted by @xmath85 , @xmath86 and @xmath87 , respectively . the symbol @xmath88 denotes convergence in distribution . unless stated otherwise , we use the symbols , @xmath89 and @xmath90 to denote usual expectation and variance of a random quantity ( with respect to the underlying probability distribution ) .      1 .   the true regression parameter @xmath91 .",
    "2 .   the true misclassification probabilities ,",
    "@xmath92 satisfy the following conditions : 1 .",
    "there exist constants , @xmath93 , such that , @xmath94 .",
    "+ the parameter space of @xmath51 satisfying the above restrictions is denoted by @xmath96 .",
    "3 .   let the marginal distribution of the @xmath5-dimensional covariate vector @xmath97 be denoted by @xmath98 .",
    "we assume that @xmath99 is such that , @xmath100 4 .",
    "the validation sampling fractions @xmath101 , defined in , satisfy the following conditions , 1 .",
    "2 .   @xmath103 .",
    "assumption ( a2)(ii ) is required to avoid a non - identifiability problem . for a discussion on the implication of this assumption",
    ", we refer to @xcite .",
    "assumption ( a2)(i ) ensures that the true misclassification probabilities are bounded away from @xmath104 and @xmath105 .",
    "it is an important technical assumption , and is used throughout the proofs for obtaining upper bounds on the estimating function @xmath106 ( cf . ) .",
    "assumption ( a1 ) states the underlying true parameter @xmath10 may be unbounded .",
    "assumption ( a3 ) implies the existence of first and second moments .",
    "hence , @xmath107 and @xmath108 , for all @xmath109 .",
    "the positive definiteness assumption ensures that the components of @xmath6 are not linearly dependent among themselves , and it is an essential condition to ensure identifiability of the model .",
    "assumptions ( a1 ) and ( a3 ) can be compared with some of the classical assumptions used for studying asymptotic properties of mle s in simple logistic regression .",
    "for example , @xcite assumes boundedness of @xmath10 and @xcite assumes that the covariates are bounded .",
    "@xcite studied mle s in generalized linear models , and do not directly assume boundedness of @xmath10 or the covariates .",
    "however , they use other assumptions on the observed fisher information matrix which are hard to verify , and are dependent on secondary sufficient conditions , among which one of conditions is a boundedness assumption on the covariates ( cf . page 355 of @xcite ) . compared to these restrictive assumptions , assumptions ( a1 ) and ( a3 ) are much weaker and easy to justify , but this leads to substantial technical complications in handling the proofs , and necessitates the use of empirical process tools .",
    "assumptions ( a1 ) , ( a2 ) and ( a3 ) are related to each other , and as we will see later in section [ sec-5-sub-2 ] , if one of the misclassification probabilities is set to zero , the unboundedness assumption on @xmath10 and the covariates has to be modified .    in assumption ( a4 )",
    ", the first condition ensures that the limiting validation sampling fraction @xmath110 is bounded away from @xmath104 and @xmath105 , which in turn implies that both validation and non - validation sample sizes increase with the total sample size , and @xmath111 , as @xmath112 .",
    "the second condition in ( a4 ) provides a convergence rate for @xmath113 , as @xmath112 .",
    "effectively , this ensures that @xmath101 converges to @xmath110 sufficiently quickly as the sample size increases .    before stating the next assumption , we introduce the following notations . for any measurable function @xmath114 , we write , @xmath115 , and similarly for a function @xmath116 . consider the following nonrandom maps , @xmath117 , defined as , @xmath118,\\\\         z_2(\\bb ) & = \\pr_0 h_{2,\\bb,\\thb_0}(\\widetilde{y},\\xb )   \\\\         & = { ( 1-\\theta_{1,0}-\\theta_{2,0})}^2\\cdot \\e\\left[\\xb \\cdot \\frac{\\psi(\\xbp\\bb)\\{1-\\psi(\\xbp\\bb)\\}\\{\\psi(\\xbp\\bb_0)-\\psi(\\xbp\\bb)\\}}{h_{3,\\bb,\\thb_0}(\\xb)\\{1-h_{3,\\bb,\\thb_0}(\\xb)\\}}\\right],\\quad\\text{and}\\\\         z(\\bb ) & = f \\cdot z_1(\\bb ) + ( 1-f)\\cdot z_2(\\bb ) ,        \\end{aligned}\\right\\ } \\label{z1-z2-def}\\ ] ] where , @xmath119 , @xmath120 , @xmath121 are defined in , and @xmath110 is the limiting validation sampling fraction defined in assumption ( a3 ) . note that , in , @xmath89 denotes expectation with respect to the distribution function @xmath98 of the covariate @xmath6 .",
    "let us denote the @xmath122 matrix of partial derivatives of @xmath123 as @xmath124 .    1 .",
    "assume that @xmath125 exists and is nonsingular .",
    "+ this assumption ensures that the limiting score function @xmath123 has a non - singular derivative at @xmath10 , which is a commonly used assumption , similar to the non - singularity assumption of the fisher information matrix used in maximum likelihood estimation . the matrix @xmath125 is given in .",
    "the true model does not explicitly include an intercept term . in case",
    "includes an intercept term , we can write @xmath126 where , @xmath127 is the unknown regression coefficient with intercept term @xmath128 .",
    "to handle this model , we require a simple modification of assumption ( a3 ) .    1 .",
    "the first component of the @xmath5-dimensional covariate vector @xmath6 is equal to @xmath105 , and the remaining @xmath129 components @xmath130 satisfy the following assumptions : 1 .",
    "@xmath131 , for all @xmath132 .",
    "@xmath133 exists and is positive definite .",
    "+ in lemma [ lem3 ] , we make use of the assumption ( a3@xmath134 ) to prove identifiability of the model with an intercept term .",
    "assumption ( a3@xmath134)(ii ) is similar to assumption ( a3 ) , and the additional condition in ( a3@xmath134)(i ) , which is required for centering of the covariates , is to ensure identifiability of the intercept term in . in the rest of the article ,",
    "all theorems will be stated assuming the model without an intercept term and using assumption ( a3 ) . for model with an intercept term , one simply needs to replace assumption ( a3 ) with ( a3@xmath134 ) .      in order to study the limiting behavior of @xmath68 ,",
    "the first step is to study the limit distribution of the estimated misclassification probabilities @xmath44 ( cf . ) , which is given in lemma [ lem - theta - hat ] . in order to describe the results , we introduce the following notations . following the assumptions stated in section [ sec2-sub1-sub1 ] ,",
    "we define the following : @xmath135          \\mathbf{b}_0   & = \\begin{pmatrix }                  { \\pi_{3,0}}/{{(1-a_0)}^2 } & 0 & { ( 1-a_0-\\pi_{3,0})}/{{(1-a_0)}^2}\\\\               { \\pi_{2,0}}/{a^2_0 } & { 1}/{a_0 } & { \\pi_{2,0}}/{a^2_0 }                \\end{pmatrix }         \\end{aligned}\\right\\}. \\label{bmat}\\ ] ] it should be noted that , @xmath136 .",
    "this follows by considering the properties of the logistic link function @xmath36 , and combining assumptions ( a1 ) and ( a3 ) , which state that the components of @xmath10 are finite , and @xmath6 is non - degenerate and tight in @xmath137 . along with assumption ( a2 ) , this implies @xmath138 , and all elements of @xmath139 in are finite .",
    "we also define the matrix , @xmath140    [ lem - theta - hat ] suppose , assumptions ( a1 ) - ( a4 ) hold . then , @xmath141 where , @xmath142 and @xmath139 are defined in and respectively .",
    "this result can be used for statistical inference on @xmath16 . the limit distribution of @xmath68 , however , is affected by the asymptotic covariance of @xmath44 .",
    "+    now we state the main result on the asymptotic behavior of @xmath68 . in order to state our results",
    ", we need to invoke the definitions of the matrices @xmath143 , @xmath144 , @xmath145 , @xmath146 , @xmath139 and @xmath147 , which are given in , , , and respectively .",
    "the explicit forms of these matrices are given in section [ sec - app ] .",
    "[ thm1 ] suppose , assumptions ( a1 ) - ( a5 ) hold .",
    "then the following statements are true :    1 .",
    "the pseudo - maximum likelihood estimator is consistent , _",
    "i.e. _ , @xmath148 2 .",
    "the pseudo - maximum likelihood estimator is asymptotically normal , _",
    "i.e. _ , @xmath149}^{-1}\\sgb_0{\\left({\\big[\\dot{z}(\\bb_0)\\big]}^{-1}\\right)}^{\\prime}\\right ) ,   \\label{beta - hat - limit - law}\\end{aligned}\\ ] ] where , @xmath150 and @xmath125 as defined in .",
    "as stated earlier , asymptotic properties of @xmath68 can not be studied by using results for z - estimators based on i.i.d .",
    "we apply the results for general z - estimators based on arbitrary estimating equations ( cf .",
    "theorems 2.10 and 2.11 of @xcite ) , which necessitates the verification of the required conditions . while verifying these conditions in our case , we face two major difficulties .",
    "first , for proving the consistency of @xmath68 a key step is to show that @xmath10 is an unique and well - separated zero of @xmath123 ( cf . ) .",
    "the difficulty arises because , in our case , the parameter space for @xmath10 is not compact and unlike the case of simple logistic regression , the limiting score function @xmath123 is not the gradient of a strictly concave function . if the limiting score function has an unique zero , then either of these two conditions are helpful in proving well - separatedness .",
    "however , in lemmas [ lem3 ] and [ lem4 ] , we show that it is possible to prove the uniqueness and well - separatedness of @xmath10 under the assumptions stated in section [ sec2-sub1-sub1 ] .",
    "the next difficulty is to properly handle the random indexing term @xmath44 in the classes of functions , @xmath151 , @xmath152 . to be more precise , define the centered and scaled empirical processes , @xmath153 where , the meaning of @xmath9 is clear from the context . in our case , verifying the donsker property for the classes @xmath154 and @xmath155 is not enough .",
    "we need to show that it is possible to replace the functions @xmath156 with @xmath157 , with appropriate scaling and uniformly over @xmath37 , as @xmath44 converges to @xmath16 . in lemma [ lem9 ]",
    "we have shown that , @xmath158 converges in probability to zero .",
    "this crucial uniform convergence result has been used in ( a ) verifying uniform convergence of @xmath159 while proving consistency of @xmath68 , and ( b ) verifying a stochastic equicontinuity condition about the process @xmath160 while proving asymptotic normality of @xmath68 .    since we consider a specific model ( cf . and ) for the proofs , we could avoid the high - level stochastic equicontinuity assumptions on the empirical processes @xmath161 , @xmath162 , and are able to handle the dependence between @xmath73 and @xmath74 . for the same reason , we do not need a compactness assumption on the parameter space for @xmath10 or a boundedness assumption on the covariates .",
    "this can be compared with conditions used in articles with a much wider scope ( cf .",
    "condition ( s1 ) of @xcite or assumption a.2 of @xcite ) , where high - level assumptions are used .",
    "the terms in the expression for the covariance matrix @xmath163 clearly show the distinct contributions of the validation and non - validation parts of the sample .",
    "the first term is the contribution of the validation sample @xmath164 , which follows immediately from the definition of @xmath73 ( cf . ) .",
    "the fourth term is due to the non - validation sample @xmath165 , which can be shown to be true by constructing a process similar to @xmath166 , by replacing @xmath44 with @xmath16 .",
    "finally , the second and third terms arise due to replacing the unknown @xmath16 with its estimator @xmath44 in the non - validation part of the estimating equation .",
    "note that , the asymptotic covariance of @xmath44 is embedded in the third term .",
    "the details are provided in the proofs .",
    "the scaling factors in some of the terms in are intriguing .",
    "the factors in the first and fourth terms are clearly due to the fact , that validation and non - validation samples comprise @xmath167 and @xmath168 proportions of the total sample , respectively .",
    "the scaling factor @xmath169 in the second term of @xmath163 arises from the joint distribution of @xmath170 and @xmath44 , which depends on @xmath171 .",
    "the scaling factor @xmath172 in the third term is hard to anticipate without a theoretical derivation .",
    "it arises from the joint distribution of @xmath173 and @xmath44 , and shows that the effect of increasing or decreasing @xmath110 is asymmetric , and the scaling factor is non - linear in @xmath110 .",
    "finally , notice that for drawing inference on @xmath10 , the asymptotic distribution in is to be estimated .",
    "the elements of @xmath163 and @xmath125 are complicated functions of the unknown parameters @xmath10 , @xmath16 , and are defined in terms of expected values with respect to the unknown distribution of @xmath6 . for estimation of @xmath163 ,",
    "it is possible to plug - in @xmath68 and @xmath44 for @xmath10 and @xmath16 , and replace the expectation with respect to @xmath98 by expectation with respect to the empirical version of @xmath98 based on the observed covariate values .",
    "however , a more convenient approach , especially from the point of view of implementation , is bootstrapping , which we describe in the next section .",
    "in this section , we establish the distributional consistency of the bootstrapped pmle in order to enable us to use the bootstrap approximation to the distribution of @xmath68 for statistical inference on @xmath10 .",
    "for the finite dimensional parameter @xmath55 , we are interested in inference unconditional on @xmath6 .",
    "there can be several approaches to obtain a bootstrap sample in our setup .",
    "since the distribution function @xmath98 is typically unknown ( except for the assumptions made in ( a3 ) ) , to obtain the results unconditional on @xmath6 , we would prefer to use the non - parametric bootstrap or the simple ( efron s ) bootstrap ( @xcite ) . for bootstrapping , we select independent random samples with replacement of sizes @xmath26 and @xmath174 from the validation , and the non - validation samples , respectively .",
    "we denote these bootstrap samples as , @xmath175 based on @xmath176 , we define the bootstrap estimates of the misclassification probabilities @xmath177 , similar to @xmath44 in , where @xmath178 the usual with replacement @xmath25-out - of-@xmath25 bootstrap is a special case of the exchangeably weighted bootstrap ( cf .",
    "@xcite ) with multinomially distributed weight vectors . for the bootstrap samples",
    "@xmath179 , @xmath162 , we define two independent multinomial random vectors @xmath180 , @xmath162 , where @xmath181 where , @xmath182 denotes the frequency of occurrence of the @xmath183-th sample unit in the with replacement sample of size @xmath184 , @xmath162 .",
    "clearly , @xmath185 and @xmath186 are independent of @xmath187 .",
    "now , using the multinomial weights @xmath185 and @xmath186 , we define the weighted empirical measures @xmath188 where , @xmath189 and @xmath190 denote point masses at @xmath191 and @xmath192 , respectively .",
    "following the definition of @xmath72 in , we define the corresponding bootstrap version , @xmath193          \\widehat{z}_{n,2}(\\bb ) & = \\prntw h_{2,\\bb,\\thbns }         \\end{aligned}\\right\\ } , \\label{z - n - hat - def}\\ ] ] where , @xmath194 is defined in .",
    "the bootstrapped pmle , denoted by @xmath195 , satisfies the estimating equation : @xmath196    it should be noted that there is an extensive literature on the asymptotic properties of bootstrap methods in the context of general m - estimation .",
    "@xcite study almost sure convergence results for bootstrapped m - estimators under strong assumptions on the underlying parameter space and estimating functions .",
    "@xcite investigate generalized bootstrap methods for estimating equations , and their results have a wide scope .",
    "however , their results can not handle different exchangeable weights like @xmath197 and @xmath198 , and non - identical random variables @xmath79 and @xmath30 .",
    "@xcite study consistency of exchangeably weighted bootstrap for z - estimators , but their results are valid for i.i.d .",
    "observations , and also require specific measurability assumptions on the class of estimating functions ( cf .",
    "@xcite ) . in an important piece of work , @xcite study consistency of exchangeably weighted bootstrap for z - estimators in general semiparametric setup in the presence of infinite dimensional nuisance parameters using estimating equations based on i.i.d . observations .",
    "the generality and wide scope of these results require assumptions like compactness of the finite dimensional parameter space , stochastic equicontinuity of the underlying empirical process , measurability assumptions on the class of estimating functions , and smoothness conditions on the limiting score functions . besides , while proving bootstrap distributional consistency , in most cases consistency of the estimators of finite dimensional parameters , and their bootstrapped version is assumed .",
    "however , existing bootstrap consistency results for z - estimators , including those mentioned above , can not be directly used for finding the asymptotic distribution of the bootstrapped pseudo mle @xmath195 .",
    "the primary difficulty arises from the dependence between @xmath199 and @xmath200 because of the presence of @xmath194 in the latter .",
    "also , usual empirical process results are not directly applicable to the estimated ( random ) class of functions @xmath201 .",
    "finally , the processes @xmath202 , @xmath162 , are not based on the same set of multinomial weights and involve different sets of random variables ( either @xmath79 or @xmath21 ) , unlike standard with replacement bootstrap procedure . in order to deal with these additional difficulties ,",
    "the asymptotic behavior of each of these two processes needs to be studied separately . in order to study the asymptotic behavior of the bootstrapped pmle @xmath195",
    ", we need to prove two new equicontinuity results .",
    "in particular , we show that @xmath203 converge to zero in probability in an appropriate sense .",
    "unlike the equicontinuity result proved for the pmle @xmath68 , for proving these new results , the results of @xcite can not be directly used .",
    "we show that their approach can be extended for handling both these cases .    as evident from the above discussion",
    ", stochastic convergence of the above mentioned supremums has to be carefully defined , since the random quantities are defined on different probability spaces .",
    "the details are given in the proofs .",
    "this type of stochastic equicontinuity results for bootstrapped empirical processes indexed by a fixed and a random parameter are new , and the line of arguments can be possibly extended to develop bootstrap consistency results for similar problems .      in order to state the bootstrap consistency results , we introduce some concepts and definitions following @xcite and @xcite .    note that",
    ", @xmath204 are i.i.d .",
    "observations from a distribution @xmath9 on a probability space @xmath205 . to deal with measurability issues",
    ", we view @xmath206 as the @xmath207-th coordinate projection from the underlying canonical product probability space @xmath208 into the @xmath207-th copy of @xmath209 .",
    "we assume that the multinomial weight vectors @xmath210 and @xmath211 are independent of @xmath204 , and form a triangular array which is defined on some probability space @xmath212 , for all @xmath213 . to handle the joint randomness of @xmath214 and @xmath215",
    ", we define the product probability space @xmath216 where , @xmath217 , is a product probability measure . for simplicity",
    ", we will denote the product measure @xmath218 as @xmath9 .",
    "we will use the symbols @xmath219 ( @xmath220 ) , @xmath221 ( @xmath82 ) to denote outer probabilities ( expectations ) corresponding to @xmath222 and @xmath9 , respectively .",
    "usual expectation with respect to @xmath223 and @xmath222 will be denoted by @xmath224 and @xmath225 respectively .",
    "we now define stochastic orders based on the above probability measures .",
    "the definitions would be repeatedly used in the proofs , and are crucial for a clear understanding of the results .",
    "consider a sequence of real valued functions @xmath226 , defined on the product probability space @xmath227 .",
    "we say that , @xmath228 in @xmath221-probability , if for any @xmath229 , @xmath230 similarly , @xmath231 in @xmath221-probability if , for any @xmath232 and @xmath233 , there exists a @xmath234 and an integer @xmath235 , such that @xmath236 lemma [ lem - prob ] describes some of the relations among the stochastic orders in terms of different probability measures , and will be heavily used in clearly describing bootstrap convergence results .",
    "for a few other similar results , we refer to lemma 3 of @xcite .",
    "+    lemma [ lem - theta - boot ] describes the limiting behavior of @xmath194 .",
    "[ lem - theta - boot ] suppose , assumptions ( a1)-(a4 ) hold .",
    "then ,    1 .",
    "@xmath237 , conditionally almost surely @xmath238 , where @xmath139 is defined in . 2 .",
    "@xmath239 , unconditionally .",
    "the unconditional distribution of @xmath194 is with respect to the product probability measure @xmath222 .    part ( i ) of lemma [ lem - theta - boot ]",
    "states the bootstrap estimator @xmath194 is distributionally consistent , and this can be used to carry out bootstrap based inference on @xmath16 .",
    "also , we require this result for proving the bootstrap consistency of @xmath195 .",
    "the unconditional convergence result stated in part ( ii ) of lemma [ lem - theta - boot ] is a major technical tool which is used in developing some of the new bootstrap stochastic equicontinuity results .",
    "now we can state the main result on bootstrap consistency .",
    "+    suppose , assumptions ( a1 ) - ( a5 ) hold .",
    "then , the following statements are true :    1 .",
    "the bootstrapped pmle @xmath195 is consistent in @xmath221-probability , _",
    "i.e. _ , @xmath240 2 .",
    "the conditional distribution of @xmath241 , given the sample @xmath187 , consistently estimates the distribution of @xmath242 in the following sense , @xmath243 where , the inequality `` @xmath244 '' is understood to be componentwise .",
    "[ thm - boot ]    note that , the bootstrap consistency result in theorem [ thm - boot ] does not require any additional technical conditions beyond what was needed while proving asymptotic normality of the pmle @xmath68 .",
    "the uniform convergence result , in part ( ii ) above , holds for classes of sets , larger than all @xmath5-dimensional rectangles of the form @xmath245\\times\\cdots\\times ( -\\infty , t_p]$ ] , where @xmath246 . the proof of part ( ii ) shows that , @xmath241 converges conditionally in distribution ( in outer probability ) to the same limiting gaussian distribution , which is described in theorem [ thm1](ii ) . using the absolute continuity of the gaussian distribution , and the results on uniformity classes ( cf .",
    "section 1.2 of @xcite ) , it can be shown that uniform convergence in part ( ii ) is valid over all borel - measurable convex subsets of @xmath137 ( cf .",
    "page 55 of @xcite ) .",
    "theorem [ thm - boot ] enables us to use the bootstrap method for a variety of inference problems on @xmath10 .",
    "more generally , the delta method for bootstrapped estimators can be used for inference on appropriate functions of @xmath10 .",
    "inference on regression coefficient @xmath10 itself is of interest to assess the effect of the covariates on the probability of occurrence of the event under study .",
    "specifically , in epidemiology , @xmath247 , the @xmath248-th component of @xmath10 , represents the log - odds ratio of a disease associated with a unit increase in the scale of @xmath249 , holding all other variables in @xmath18 fixed .",
    "if @xmath249 is a binary variable , then @xmath247 represents the adjusted log - odds ratio adjusted for the covariates in the regression model other than @xmath249 .",
    "inference on a linear parametric function @xmath250 may be of interest in many applications , e.g. , in assessing credit worthiness of a person by a credit bureau . also estimating @xmath23 for a given value of @xmath18 , say , @xmath251 is of interest as it represents the probability of the event under study to happen if @xmath252 .",
    "especially , we may be interested in the estimation of @xmath23 , wherein it represents the risk of an adverse event .",
    "for example , in epidemiological studies , it may represent the risk of a disease associated with the risk factors @xmath18 ; in financial applications , it may represent the risk of a default associated with an individual s profile @xmath18 . in the following ,",
    "we illustrate two common applications of theorem [ thm - boot ] .      we can use theorem [ thm - boot ] to construct an asymptotically consistent confidence interval for @xmath250 .",
    "the confidence interval is , @xmath253 where , @xmath254 is the @xmath255-quantile of @xmath256 , for any @xmath257 . as stated in the next corollary",
    ", @xmath258 is an asymptotically consistent level @xmath259 confidence interval for @xmath250 .    under the conditions of theorem [ thm - boot ] , for any",
    "@xmath260 and any fixed @xmath261 , @xmath262 [ cor1 ]      the risk at @xmath263 is given by @xmath264 to avoid trivialities , we assume that @xmath265 .",
    "the naive estimator of risk at @xmath263 is @xmath266 , and the bootstrap estimator is @xmath267 . for any @xmath268 ,",
    "let @xmath269 denote the @xmath255-quantile of @xmath270 .",
    "define the following confidence interval for @xmath271 , @xmath272    under the conditions of theorem [ thm - boot ] , for any @xmath260 , @xmath273 [ cor2 ]",
    "motivated by the practical applications , we consider two specific situations , wherein the asymptotic results proved in sections [ sec-2 ] and [ sec-4 ] are not directly applicable . in this section ,",
    "we show that , our results continue to hold with appropriate modifications .      until now",
    ", we have developed the asymptotic theory , assuming that , the probabilities of misclassification are independent of the covariates @xmath18 . in other words , we have assumed a non - differential classification error .",
    "however , as mentioned by @xcite , `` there is little ex ante reason to believe that misclassification is independent of the covariates . '' in a hiv related study , @xcite consider a regression model for the misclassification probabilities with subject specific binary covariates . in social and economic surveys ( cf .",
    "@xcite and @xcite ) , it has been observed that , the misclassification probabilities of the binary response ( like , whether beneficiary of a program or not ) depend on the covariates , like union membership of a worker ( a member or not ) , income ( above or below median income ) , age ( above the median age or not ) etc .",
    "we now consider extension of our theory to differential classification errors . for simplicity , we assume that , the sample space for @xmath18 can be divided into @xmath274 non - overlapping subsets , each representing the profile of a distinct group , possibly with different misclassification probabilities .",
    "denote these @xmath274 groups by @xmath275 .",
    "we assume that , a random sample of size @xmath276 is obtained from @xmath277 , with @xmath274 remaining fixed , and @xmath278 .",
    "the underlying true model is , @xmath279 where , @xmath280 are the misclassification probabilities for the group @xmath277 . writing @xmath281 , where @xmath282 and @xmath283 are the validation and the non - validation sample sizes , respectively , we assume that assumption ( a2 ) remains valid with @xmath16 replaced by @xmath284 .",
    "similarly , we assume that assumption ( a4 ) remains true in the following sense : @xmath285 and @xmath286 as @xmath112 .",
    "assumptions ( a1 ) and ( a3 ) or ( a3@xmath134 ) remain unchanged . based on the observations from @xmath277 , one can estimate @xmath287 using . following similar arguments as above , the estimating function can be written as , @xmath288,\\end{aligned}\\ ] ] where , @xmath289 and @xmath290 denote the empirical measures corresponding to validation and non - validation samples in group @xmath277 , respectively .",
    "the pmle @xmath68 satisfies the estimating equation , @xmath291 following the arguments given in lemma [ lem - theta - hat ] , and using the above mentioned assumptions on @xmath284 and @xmath292 , it can be shown that @xmath287 will be asymptotically normal .",
    "also , using the arguments similar to those given in lemma [ lem5 ] , it will follow that , @xmath293 , where , @xmath294.\\ ] ] further , following arguments similar to that used in lemma [ lem3 ] and [ lem4 ] , it can be shown that @xmath295 has an unique and well - separated root at @xmath296 .",
    "specifically , note that @xmath297 , where @xmath110 is defined in ( a4 ) , and @xmath298 is defined in .",
    "so , the arguments in lemma [ lem3 ] can be repeated in this case for @xmath298 , and the rest of the proof follows by sandwiching @xmath295 within constant positive multiples of @xmath298 , as shown in lemma [ lem4 ] .",
    "the proof of donsker and glivenko - cantelli properties can be carried out similarly , and this will imply consistency of @xmath68 ( cf . ) .",
    "next , we will assume that assumption ( a5 ) holds if @xmath123 ( cf . )",
    "is replaced by @xmath295 .",
    "then , following the arguments in case of a single group , it can be shown that @xmath68 will be asymptotically normal , and the bootstrap version of @xmath68 , which can be constructed in the same manner by independently resampling within each group , will also be distributionally consistent in probability .",
    "the asymptotic variance of @xmath68 defined in can be obtained using the variance expression given in .",
    "the primary differences will be , @xmath125 will be replaced by @xmath299 and @xmath163 in will be replaced by , @xmath300,\\end{aligned}\\ ] ] where , the matrices @xmath301 , @xmath302 , @xmath303 , @xmath304 and @xmath305 , are similarly defined as in , , , and respectively , by replacing @xmath16 with @xmath306 .      the classification errors are usually asymmetric . an extreme case of asymmetry could be , one of the misclassification probabilities is equal to zero , while the other is non - zero .",
    "for example , it may be that @xmath307 , while @xmath308 is non - zero . in this case",
    ", the parameter @xmath16 reduces to a scalar parameter @xmath309 . while discussing about literacy data , collected through census in india , @xcite mention that the indirect method of determining the literacy status of an individual leads to misclassification . in this case , the chances of misclassifying a literate person ( @xmath310 ) as an illiterate ( @xmath311 ) are negligible and can be practically considered equal to zero . however , the chance of other type of misclassification is significantly high .",
    "the detailed discussion is deferred to section [ sec - sim - real ] , where this particular example has been analysed .",
    "this type of extreme asymmetrical misclassification may arise in medical diagnostic studies , @xcite ( pp .",
    "512 ) provides such an example related to cancer detection .",
    "the unknown non - zero misclassification probability @xmath309 can be estimated using and for purposes of computation , we can define , @xmath312 with probability @xmath105 .",
    "the pseudo - likelihood based estimating equation in can be used with this modified definition of @xmath313 . in this case , under assumption ( a2)(i ) , we have @xmath314 as a result , @xmath315 remains bounded away from @xmath104 , but not bounded away from @xmath105 .",
    "this implies , @xmath316 can become arbitrarily large .",
    "this is unlike the case when both misclassification probabilities are present in the model , and are bounded away from @xmath104 and @xmath105 . as a result ,",
    "all technical arguments used in the general case will fail in this situation .    in order to extend the theoretical results to this case ,",
    "we need to modify some of the original technical assumptions stated in section [ sec2-sub1-sub1 ] . specifically , we strengthen assumption ( a1 ) to ensure boundedness of the coefficient @xmath10 , assumption ( a2)(i ) is only applicable on the non - zero misclassification probability @xmath309 and it remains bounded away from @xmath104 and @xmath105 , assumption ( a3 ) is also strengthened and we assume boundedness of the covariate @xmath6 along with positive definiteness of @xmath317 . assumption ( a2)(ii ) is redundant in this case , and assumptions ( a4 ) and ( a5 ) remain unchanged . for the model with intercept ,",
    "the same modifications are applicable along with the changes described in assumption ( a3@xmath134 ) .    with these new set of assumptions",
    ", @xmath23 remains bounded away from @xmath104 and @xmath105 , and as a result , @xmath315 is also bounded away from @xmath104 and @xmath105 , for all @xmath18 , @xmath318 and @xmath319 .",
    "it is now possible to prove the theoretical results about the pmle @xmath68 , and it s bootstrap version , by retracing the technical arguments for the general case , replacing @xmath44 by @xmath320 and @xmath194 by @xmath321 .",
    "the boundedness of @xmath10 will simplify some of the convergence arguments used in the proofs .",
    "we skip the details",
    ". there will be some changes while computing the expression for asymptotic covariance of @xmath68 ( cf . and ) , which depend on @xmath16 .",
    "for all matrices , the unknown @xmath322 is to be replaced by @xmath323 . since @xmath322 is not estimated , the asymptotic covariance expression of @xmath44 ( cf .",
    "lemma [ lem - theta - hat ] ) , which is used in the third term of will be slightly changed .",
    "the matrix @xmath324 should be replaced by a @xmath325 matrix , with @xmath326-th element equal to the corresponding element of @xmath324 and all other elements equal to zero .",
    "apparently a simplification of the model , with one of the misclassification probabilities being equal to zero , leads to the use of stronger assumptions requiring boundedness of the covariates and the true regression coefficient . at present",
    ", we do not know of an alternative proof under weaker assumptions .",
    "as mentioned in section [ sec - intro - new ] , we carry out extensive simulation studies to compare the performances of pmle with other likelihood based estimators , one based only on contaminated ( misclassified ) responses , considered by @xcite and @xcite in the absence of any validation sample , and the other , based on the joint likelihood of both validation and non - validation samples considered by @xcite .",
    "we refer to them as cmle , and jmle , respectively . in the following ,",
    "we briefly discuss the likelihood functions , and the associated score equations for finding cmle and jmle .",
    "computation of the likelihood estimates , including pmle involves solving @xmath5 or @xmath327 ( in case of jmle and cmle ) nonlinear equations with the same number of variables . for solving the nonlinear equations , we have used @xmath328-package ` bb ` , developed by @xcite .",
    "in the absence of a validation sample , information on the true responses is not available . in this case , @xcite suggested jointly estimating @xmath32 using the likelihood based on the set of observations @xmath329 .",
    "however , this approach has some serious drawbacks , which we discuss briefly . as noted earlier ( cf . )",
    ", @xmath330~{\\sim}~\\text{bernoulli } \\big(h_{3,\\bb,\\thb}(\\xb_i)\\big)$ ] , for all @xmath331 , and are independent , where @xmath53 is defined in",
    ". the likelihood function will be , @xmath332 the estimating equations for @xmath32 are , @xmath333 = \\zero,\\\\    \\frac{\\pa}{\\pa\\theta_1}~n^{-1}\\log l_{n , c}\\big(\\bb,\\thb\\big ) & = \\prn\\left[\\frac{\\{1-\\psi(\\xbp\\bb)\\}\\cdot\\{\\yt - h_{3,\\bb,\\thb}(\\xb)\\}}{h_{3,\\bb,\\thb}(\\xb)\\cdot\\{1-h_{3,\\bb,\\thb}(\\xb)\\}}\\right ] = 0,\\\\   \\frac{\\pa}{\\pa\\theta_2}~n^{-1}\\log l_{n , c}\\big(\\bb,\\thb\\big ) & = \\prn\\left[\\frac{\\psi(\\xbp\\bb)\\cdot\\{\\yt - h_{3,\\bb,\\thb}(\\xb)\\}}{h_{3,\\bb,\\thb}(\\xb)\\cdot\\{1-h_{3,\\bb,\\thb}(\\xb)\\}}\\right ] = 0 ,         \\end{aligned}\\right\\ }   \\label{ee - haus}\\ ] ] where , @xmath334 , denotes the empirical measure based on @xmath329 .",
    "denote these estimates by @xmath335 .",
    "often , the estimating equations in become nearly non - identifiable , and thus , lead to nonsensical estimates @xmath335 for the following reasons .",
    "it has been noted by @xcite , that for every @xmath37 , there exists a @xmath336 , such that @xmath337 for @xmath338 .",
    "thus , the logistic and linear functions are almost identical on a large part of their range , except for the tails .",
    "hence , for @xmath338 , we have , @xmath339 where , @xmath340 .",
    "thus , if @xmath341 are unknown , the likelihood estimates based on @xmath342 fails to recover the estimates of the model parameters , unless there are enough number of observations in the tails of @xmath343 .",
    "thus , if the covariate @xmath6 is such that , the probability @xmath344 then recovering estimates of the model parameters from @xmath342 is nearly impossible , unless the sample size is very large .      if the validation sample is available , then a natural approach is to consider the joint likelihood function @xmath45 , given in .",
    "following earlier calculations , the estimating equations for @xmath32 will be , @xmath345+(1-f_n)\\cdot\\prnt\\left[\\frac{\\big\\{1-\\psi(\\xbp\\bb)\\big\\}\\cdot\\{\\yt - h_{3,\\bb,\\thb}(\\xb)\\}}{h_{3,\\bb,\\thb}(\\xb)\\cdot\\{1-h_{3,\\bb,\\thb}(\\xb)\\}}\\right ] = 0,\\\\   \\frac{\\pa}{\\pa\\theta_2}~n^{-1 } l_{n}(\\bb,\\thb ) & = f_n\\cdot \\prno\\left[\\frac{y(1-\\yt-\\theta_2)}{\\theta_2(1-\\theta_2)}\\right]-(1-f_n)\\cdot\\prnt\\left[\\frac{\\psi(\\xbp\\bb)\\cdot\\{\\yt - h_{3,\\bb,\\thb}(\\xb)\\}}{h_{3,\\bb,\\thb}(\\xb)\\cdot\\{1-h_{3,\\bb,\\thb}(\\xb)\\}}\\right ] = 0 .",
    "\\end{aligned}\\right\\ }   \\label{ee - full}\\ ] ] let us denote the joint maximum likelihood estimates as @xmath346 . note that has two components representing the contributions of the validation and non - validation data to the likelihood , respectively . if @xmath347 , the non - identifiability problem discussed in the context of will still be present , but plausibly to a lesser extent , especially when the validation sample size is small .",
    "further , note that the first and second components of the joint log - likelihood mentioned above , are sums of @xmath26 , and @xmath174 i.i.d .",
    "random variables , respectively . but the random variables in the two sums are not identically distributed .",
    "the first involves the random vector @xmath79 , and the second , @xmath30 . since , @xmath111",
    ", none of the two sums can be neglected asymptotically .",
    "consequently , the log - likelihood can not be written as a sum of i.i.d .",
    "random variables , even asymptotically , and hence , the classical asymptotic results on maximum likelihood estimation can not be used .",
    "there are other difficulties too , in dealing with the score functions obtained in .",
    "first , the restrictions on the parameter space of @xmath96 ( cf . assumption ( a2 ) ) , and the non - compactness of the parameter space for @xmath10 , make the study of the joint uniform convergence of the score functions ( over @xmath37 and @xmath51 ) difficult .",
    "second , one has to show that , the limiting score functions have an unique and well - separated zero at @xmath55 . the techniques , used in proving the asymptotic results for pmle , can not be used for jmle .",
    "developing an asymptotic theory for the jmle seems to be difficult .      in order to provide a clear motivation for using pseudo - likelihood , we design a simulation study .",
    "we choose , @xmath348 with independent covariates @xmath349 and @xmath350 , where @xmath351 will be chosen later on .",
    "we fix , @xmath352 and @xmath353 . given any @xmath354 , we choose @xmath355 , such that @xmath356 this leads to , @xmath357 where , @xmath358 denote the standard normal quantile function . in order to make sure that @xmath359 , we need to ensure that , @xmath360 . by changing @xmath255 , and consequently @xmath361",
    ", we could control the probability of @xmath362 lying inside @xmath24 .",
    "higher is the value of @xmath255 , lower is the chance of getting extreme observations ( i.e. , observations whose @xmath362 values are near @xmath104 or @xmath105 ) in a sample and more exacerbated would be the effect of non - identifiability .",
    "the primary goal of this study is to investigate the above phenomena .    in the simulation study , besides pmle , cmle and jmle , we have also included naive logistic regression based estimator of @xmath10 , denoted by @xmath363 , which is obtained on the basis of @xmath329 ignoring the misclassification errors . the sample size for the simulation study",
    "is fixed at @xmath364 , with @xmath365 and @xmath366 .",
    "notice that , for computation of cmle , and @xmath363 , we consider only the values of @xmath30 for the entire sample .    in table",
    "[ tab5 ] , we present the results of the simulation study .",
    "the simulation set - up is described at the top of the table . for simplicity of presentation , we report the average bias and mean - squared error ( mse ) of different likelihood estimators of @xmath367 using 250 simulated data - sets . for naive logistic regression",
    "it is for @xmath128 only .",
    "results from table [ tab5 ] clearly show that pmle of @xmath128 has the best performance in terms of mse .",
    "the same conclusion can be drawn from the frequency plots in figures [ fig3 ] and [ fig4 ] .",
    "for estimating @xmath309 , pmle is superior to others both in terms of bias and mse .",
    "as expected , the cmle estimators performance is miserable in terms of both bias and mse .",
    "in fact , often the score equations fail to yield stable solutions .",
    "unless possibly the sample size is very large ( @xcite considered @xmath368 ) , the non - identifiability problem persists .",
    "moreover , the estimator @xmath369 takes negative values and values greater than one ( cf .",
    "figure [ fig5 ] ) .",
    "similar problem also arises , but to a lesser extent , for joint likelihood based estimator @xmath370 , as seen from the frequency plots in figures [ fig5 ] .",
    "evidently , the joint likelihood estimate of @xmath51 could very well be nonsensical .",
    "however , pmle does not suffer from this drawback and seems to perform better than the joint likelihood estimator at least for moderately large sample sizes which is often the case in many real - life applications .",
    "the naive logistic regression based estimator @xmath371 suffers from serious underestimation and has larger mse than pmle or jmle .",
    "overall , pmle based estimates seem to be the best choice among alternative likelihood based procedures .",
    "finally , in terms of computational speed , pmle takes the least time to converge followed by the jmle , which is , of course , considerably slower .",
    "the cmle is the worst , and converges very slowly .",
    "as expected , often , the solutions converge to non - nonsensical values because of the non - identifiability problem .      in this section , we design simulation studies to compare the performances of the penalized likelihood based bootstrap percentile intervals of the regression parameters , with the corresponding intervals based on the asymptotic distribution of the pmle of @xmath10 . for evaluating the performances , we compute the empirical coverage and average length of each such interval .",
    "we consider two regression models for the simulation studies , one with three covariates and the other with nine covariates .",
    "the latter is considered to demonstrate that the pmle based inference is computationally feasible even with a reasonable number of covariates . in the following",
    "we discuss the results .",
    "we consider the following model ( cf .",
    "@xcite ) , @xmath372 the covariates @xmath373 , @xmath374 and @xmath375 are independent , with @xmath376 , @xmath377 and @xmath378 .",
    "all covariates are centered .",
    "we study three different models :    1 .",
    "@xmath379 , @xmath380 .",
    "same choice of @xmath10 as in model ( a ) , with @xmath381 .",
    "@xmath382 and @xmath16 is same as in model ( a ) .    models ( a ) and ( c ) differ only with respect to the intercept term , while models ( a ) and ( b ) with respect to the misclassification probabilities only .    for each of the three models considered above , we consider three different sample sizes @xmath383 , and also three different validation sample fractions @xmath384 .",
    "we compute the empirical coverage probabilities and the average lengths of the bootstrap percentile interval , and the asymptotic confidence intervals for the parameters @xmath385 , @xmath386 , for each of these models .",
    "the bootstrap percentile intervals are obtained from .",
    "the asymptotic confidence intervals are obtained from by plugging in the estimated values of @xmath10 and @xmath16 , and replacing the expectation with respect to the unknown distribution @xmath98 of @xmath387 by the same with respect to the empirical version of @xmath98 in the expression for the asymptotic covariance matrix .",
    "finally , the limiting validation sampling fraction @xmath110 is replaced by @xmath167 .",
    "the empirical coverage probabilities , and the average lengths are computed on the basis of 250 simulated data - sets .",
    "tables [ tab1 ] , [ tab2 ] and [ tab3 ] show the results for @xmath388 , @xmath389 and @xmath390 , respectively .    in table",
    "[ tab1 ] , with @xmath388 , we notice that for @xmath391 and @xmath392 , the asymptotic and bootstrap methods have comparable empirical coverages , although the bootstrap intervals have slightly larger average length .",
    "the average length decreases as @xmath167 increases . in case @xmath393 , the bootstrap based intervals have substantially larger average length , compared to the asymptotic intervals .",
    "this happens when the validation sample size @xmath26 is very small .",
    "the primary reason is , the appearance of a _ bad _ bootstrap validation sample .",
    "it leads to bad estimates of @xmath394 and @xmath395 .",
    "a few such estimates influence the bootstrap percentiles , and hence lead to wider ci s obtained from .",
    "asymptotic ci s are also not exempt from such aberrations , if @xmath26 is very small .",
    "the lengths of asymptotic ci s for components of @xmath10 in model ( c ) with @xmath396 , shown in table [ tab1 ] reveal this phenomenon , although to a lesser extent than that of the bootstrap ci s .",
    "note , however , that the average lengths of asymptotic ci s are based on 250 simulated data - sets while the bootstrap based ci s are based on @xmath397 bootstrap samples from each data - set .",
    "therefore , if the original validation sample @xmath398 is bad , the chances of obtaining a worse bootstrap sample @xmath176 is higher .",
    "this magnifies the problem for the bootstrap case . in worst cases , obtaining even 50 or more extremely large estimates of a single component of @xmath195 out of a total of 700 iterations can have a huge influence on the corresponding bootstrap 2.5% and 97.5% percentiles .",
    "however , this issue disappears if @xmath26 is slightly increased . comparing the same figures for @xmath399 and @xmath400 in tables [ tab2 ] and [ tab3 ]",
    ", we see a dramatic improvement over the earlier case even when @xmath393 .",
    "our simulations suggest that the phenomenon of unstable parameter estimates and large widths of bootstrap ci s is dependent on the validation sample size @xmath26 and not on the actual validation sampling fraction @xmath167 .",
    "we find that @xmath401 or more to be a safe choice for obtaining reliable bootstrap based estimates , irrespective of the total sample size @xmath25 .",
    "it could be achieved either by increasing @xmath25 for a fixed @xmath402 , or by increasing @xmath402 for a fixed @xmath25 .",
    "in fact , for @xmath388 and @xmath403 and @xmath404 , except for a few cases , the widths of bootstrap based ci s are only in between 5 - 20 % larger their asymptotic counterparts , and the situation improves further when @xmath25 increases .",
    "the good performance of the asymptotic ci s is not surprising , since the asymptotic covariance matrix has been estimated by using the exact expression in , and each term has been painstakingly computed . also , the expectation with respect to the empirical distribution of the covariates is a good approximation to the true distribution @xmath98 for @xmath388 or more .",
    "but , exact computation of the asymptotic covariance matrix may not be easy to implement in practice as is evident from the complicated expressions of the matrices involved in , and specially if @xmath5 is large . hence , for moderately large @xmath26 and @xmath25 , clearly the bootstrap is a preferable method for inference on @xmath10 from the point of view of implementation .",
    "here we consider a model with @xmath405 covariates , including an intercept term with a mix of continuous , discrete and categorical covariates .",
    "the covariates @xmath406 are independent , with @xmath376 , @xmath377 , @xmath378 , @xmath407 , @xmath408 , @xmath409 and @xmath410 .",
    "we choose , @xmath411 with @xmath412 .",
    "table [ tab4 ] presents the empirical coverages and average lengths .",
    "the observed patterns are similar to that of tables [ tab2 ] and [ tab3 ] .      in this section",
    "we consider a data set obtained from a household literacy survey conducted across four indian states , and apply our methodology for obtaining confidence intervals for the parameters of interest . for a detailed discussion about the survey",
    "we refer to @xcite .",
    "one of the goals of the survey was to compare the literacy rate obtained from the data collected through indirect responses , which are subject to errors of misclassification , with the literacy rate obtained from the data collected through direct responses , which can be considered as gold - standard .",
    "data on 7409 individuals within the age group 15 - 45 were collected .",
    "literacy was judged directly by evaluating each individual through written / oral tests , and the responses were , literate @xmath413 or illiterate @xmath414 .",
    "the indirect responses were obtained from the head of the family , who reported on the literacy status @xmath415 of each member of the family , with @xmath3 if the member was considered literate and @xmath311 , otherwise .",
    "the latter method is used in indian census for collecting literacy data . since the chances of misclassifying a literate person @xmath413 as an illiterate by the head of the family @xmath416 is zero , this type of misclassification is ignored . for each individual ,",
    "his / her age @xmath417 was also recorded and we treat it as a covariate .",
    "complete information on the triplet , @xmath418 was available for 7409 individuals and based on this , we found @xmath419 .",
    "for our data - analysis , we selected a random sample of size @xmath420 from the complete set ( about 10% of the available number of observations ) , out of which the first @xmath421 observations were treated as the validation sample .",
    "this leads to a validation sample fraction @xmath422 . after including an intercept term in the logistic regression model",
    ", we have @xmath423 based on complete information over 7409 individuals , the _ true _ parameter values were found to be , @xmath424 . however , usually such detailed information would be unavailable . using the validation sample",
    ", we found @xmath425 .",
    "the pseudo - likelihood based estimates using the sample of size @xmath420 are , @xmath426 and @xmath427 , and the corresponding bootstrap percentile 95% confidence intervals are , @xmath428 and @xmath429 respectively .",
    "the ci for the intercept coefficient does not contain @xmath128 , but the ci for the slope parameter @xmath430 contains the true value .",
    "also , the ci for @xmath430 indicates that , plausibly with increase in age , the chances of a person being literate decreases , which is true in general for the indian populace .",
    "in this article , we propose a pseudo likelihood based approach to the estimation of parameters of a regression model that assumes a logistic link and incorporates misclassification probabilities of binary responses as parameters . under a minimal set of assumptions ,",
    "the consistency and asymptotic normality of the resulting estimators are proved . to the best of our knowledge ,",
    "this is possibly the only paper in the existing literature , that provides a rigorous asymptotic theory for likelihood based inference for such models .",
    "also , the asymptotic theory developed here is comprehensive enough to deal with non - differential classification errors .    for drawing inference on the model parameters we propose a bootstrap method supported by its distributional consistency .",
    "the method avoids direct estimation of asymptotic variance of the estimators .",
    "this helps in making the implementation of the methodology easier for practitioners in real - life situations .",
    "the bootstrap distributional consistency result is new to the literature of pseudo - likelihood based estimation .",
    "no result is available to handle bootstrap consistency in this set up .",
    "some of the techniques used in proving the bootstrap consistency result are novel , and could possibly be used to prove bootstrap consistency in similar problems .",
    "the extensive numerical studies presented here clearly show the superiority of the proposed pseudo - likelihood based estimation procedure over the other commonly used likelihood based methods for the estimation of the model parameters . in this context",
    ", it should be mentioned that no asymptotic theory is available for the joint maximum likelihood estimators ( jmle ) , and developing such a theory , at this point , seems to be a formidable problem .",
    "finally , it should be noted that the proposed methodology is applicable for binary regression with a logistic link only .",
    "it is an open problem to develop a similar theory for binary regression with arbitrary , but known link functions .",
    "throughout the proofs many convergence in probability statements involving the @xmath5-dimensional functions @xmath119 or @xmath120 ( cf . ) have been proved by showing that those convergence in probability statements hold for each component of @xmath119 or @xmath120 .",
    "this is possible since @xmath5 is fixed . without loss of generality ,",
    "we have studied the first component of these @xmath5 dimensional functions and for simplicity , we have used the same notation to denote the first components of @xmath119 or @xmath120 . on some occasions",
    ", the same notational convention has been used for the @xmath5-dimensional functions , @xmath72 , @xmath431 , @xmath123 and @xmath432 , ( cf . and ) for @xmath162 . whenever this has been done while proving a result ,",
    "we have noted that in the proof .",
    "the cases where these functions are treated as @xmath5-dimensional functions will be obvious from the context of the concerned statements . in case of the with - intercept model , under the modified assumption ( a3@xmath134 ) , the same results can be proved by studying the second or other components of @xmath119 or @xmath120 , by following exactly same arguments as in the without intercept case , as shown in the proofs below .",
    "hence , separate proofs for the with - intercept case are not shown .",
    "consider the first components of @xmath119 , @xmath120 , @xmath72 , @xmath431 , @xmath123 and @xmath433 , for @xmath162 , and denote them by the same symbols .",
    "using assumptions ( a3 ) and ( a4 ) along with lemma [ lem5 ] and we can write , @xmath434 extending this argument to all @xmath5 components we obtain , @xmath435 . from",
    "we have , @xmath436 . combining these facts with lemma [ lem4 ] and using theorem 2.10 of @xcite",
    "leads to the proof .",
    "we verify the conditions of theorem 2.11 of @xcite to complete the proof .",
    "note that , from lemma [ lem4 ] we have @xmath437 , from it follows that @xmath438 and from theorem [ thm1](i ) it follows that @xmath439 . from lemma [ lem11 ]",
    "we obtain the stochastic equicontinuity condition , @xmath440 . also , as per assumption ( a5 ) , @xmath125 ( cf . )",
    "is nonsingular .",
    "it remains to study the limit distribution of @xmath441 . using the definition of @xmath119 ( cf . ) and @xmath442 s ( cf . ) , we define the @xmath443 dimensional i.i.d .",
    "random vectors @xmath444 s as , @xmath445 note that , @xmath446 and @xmath447 , which is computed in .",
    "using assumption ( a3 ) and the clt for i.i.d .",
    "random vectors , @xmath448 . based on the definition of the @xmath444 s we can write , @xmath449 note that @xmath450 is independent of @xmath451 and @xmath452 .",
    "consider the function @xmath453 , defined in lemma [ lem8](ii ) and its total derivative map @xmath454 evaluated at @xmath455 , shown in .",
    "note that @xmath147 is a @xmath456 matrix and recall the definitions of @xmath457 ( cf . ) and @xmath139 ( cf . ) .",
    "we can use lemma [ lem - theta - hat ] and the delta method ( cf . theorem 3.1 of @xcite ) repeatedly to carry out the following simplification : @xmath458 = \\sqrt{1-f_n}\\cdot \\sqrt{n_2 } \\left[\\bar{f}(\\thbn)-\\bar{f}(\\thb_0)\\right]\\\\ & = \\sqrt{1-f_n}\\cdot\\sqrt{n_2}\\left [ \\mathbf{a}_0(\\thbn-\\thb_0 ) + o_{\\pr^*_0}(\\|\\thbn-\\thb_0\\|)\\right]\\\\ & = \\mathbf{a}_0 \\cdot\\frac{1-f_n}{\\sqrt{f_n}}\\cdot \\sqrt{n_1}\\left(\\boldsymbol{\\phi}(\\widebar{\\w}_{n_1})-\\boldsymbol{\\phi}(\\e_0 \\w_1)\\right ) + \\ops\\\\ & = \\frac{1-f_n}{\\sqrt{f_n } } \\cdot \\big(\\mathbf{a}_0\\mathbf{b}_0\\big ) \\sqrt{n_1}\\cdot \\widebar{\\t}^{(2)}_{n_1 } + \\ops,\\quad\\text{(here , $ \\mathbf{a}_0\\mathbf{b}_0 $ is a $ p\\times 3 $ matrix ) . } \\ ] ] let @xmath459 denote the @xmath5 dimensional identity matrix . following the above steps we have , @xmath460 using assumption ( a3 ) and the clt for i.i.d .",
    "random vectors , @xmath461 with @xmath146 being defined as in .",
    "further , using lemma [ lem9 ] , @xmath462 since @xmath463 and the @xmath464 random vectors can be considered as independent , it follows that @xmath465 where , @xmath466 with @xmath163 given by .",
    "this completes the verification of required conditions in theorem 2.11 of @xcite , and it implies that , @xmath467}^{-1}\\sgb_0{\\left({\\big[\\dot{z}(\\bb_0)\\big]}^{-1}\\right)}^{\\prime}\\right ) , \\ ] ] as stated in .",
    "let us consider the first components of @xmath119 , @xmath120 , @xmath468 , @xmath431 , @xmath123 and @xmath432 , for @xmath162 , and denote them by the same symbols .",
    "define the classes of functions , @xmath469 and @xmath470 .",
    "following the arguments used in the proof of theorem [ thm1 ] , we have @xmath471 consider @xmath472 in .",
    "we can express , @xmath473 .",
    "note that , the ( scaled ) multinomial weights @xmath474 are non - negative and exchangeable random variables and independent of @xmath398 .",
    "further , @xmath475 and @xmath476 , due to the following argument : for each @xmath477 , @xmath478 , where , @xmath479 are i.i.d .",
    "bernoulli @xmath480 .",
    "fix any @xmath481 $ ] .",
    "then , there exists some @xmath482 , such that @xmath483 , which implies , @xmath484 .",
    "we can apply hoeffding s inequality ( proposition a.6.1 of @xcite ) , to obtain @xmath485 since , @xmath486 is a glivenko cantelli ( gc ) class ( from lemma [ lem5](i ) ) , using lemma 3.6.16 of @xcite it follows that @xmath487 in @xmath221-probability . following the same arguments we can show that @xmath488 in @xmath221-probability , since @xmath489 is a gc class ( from lemma [ lem5](ii ) ) and the weights @xmath490 satisfy the required assumptions .    now consider @xmath491 . from lemma [ lem - theta - boot](ii ) and lemma [ lem - prob ]",
    "we know that , @xmath492 in @xmath493-probability .",
    "this implies ( using lemma [ an - lem ] ) , there exists a sequence @xmath494 , such that @xmath495 .",
    "consider the events , @xmath496 $ ] , @xmath152 .",
    "since @xmath494 , there exists some @xmath497 , such that , @xmath498 for all @xmath499 . on the set @xmath500 , using we obtain , @xmath501 fix any @xmath502 . since @xmath503 , assumption ( a3 ) implies that for large enough @xmath25 we must have , @xmath504 . also , @xmath505 in @xmath221 probability , under assumption ( a3 ) .",
    "hence , @xmath506 extending this argument to all components we get , @xmath507 in @xmath221-probability .",
    "the proof follows by using theorem 13.1 of @xcite along with lemma [ lem4 ] .",
    "following the definition of @xmath444 s in , define their bootstrap versions and denote them by @xmath508 , where @xmath509 .",
    "following same arguments as in the proof of theorem [ thm1](ii ) , using lemma [ lem - theta - boot](ii ) and lemma [ lem - prob ] , we can write @xmath510 this implies , @xmath511 following lemma and lemma [ boot - tight ] we can write , @xmath512 and the proof of theorem [ thm1](ii ) essentially shows that , @xmath513 because , @xmath514 . hence subtracting the above two equations , using , using the second equation in and using the limiting distribution of the bootstrap random vectors @xmath515 s",
    ", we obtain @xmath516 + o_{\\prm^*}(1)\\notag\\\\ & = { } -\\begin{pmatrix } \\sqrt{f_n}\\cdot \\mathbf{i}_p & \\frac{1-f_n}{\\sqrt{f_n}}\\cdot\\big(\\mathbf{a}_0\\mathbf{b}_0\\big)\\end{pmatrix }   \\begin{pmatrix }   \\sqrt{n_1}\\cdot\\left({\\widebar{\\widehat{\\t}}}^{(1)}_{n_1}-{\\widebar{{\\t}}}^{(1)}_{n_1}\\right)\\\\[2ex ]   \\sqrt{n_1}\\cdot\\left({\\widebar{\\widehat{\\t}}}^{(2)}_{n_1}-{\\widebar{{\\t}}}^{(2)}_{n_1}\\right )   \\end{pmatrix}\\notag\\\\ & \\quad { } -\\sqrt{1-f_n}\\cdot\\frac{1}{\\sqrt{n_2}}\\sum_{i = n_1 + 1}^{n}\\left\\{h_{2,\\bb_0,\\thb_0}\\left(\\widehat{\\widetilde{y}}_i,\\widehat{\\xb}_i\\right ) - h_{2,\\bb_0,\\thb_0}\\left({\\widetilde{y}}_i,{\\xb}_i\\right)\\right\\ } + \\ophs\\notag\\\\ & \\stackrel{d}{\\rightarrow } { } -\\u,\\quad\\text{conditionally in outer probability $ \\pr^*_0 $ , } \\ ] ] where , @xmath517 is defined in .",
    "this follows because , @xmath518 converges to the same limiting distribution as @xmath519 , conditionally in probability @xmath9 ( cf .",
    "theorem 23.4 of @xcite ) . also , for the same reason @xmath520 has the same limiting distribution as the term @xmath450 in the proof of theorem [ thm1](ii ) .",
    "hence , @xmath521 , conditionally in outer probability @xmath221 .",
    "the proof follows by using lemma 21.2 of @xcite and theorem [ thm - boot ] .",
    "we omit the details .",
    "the proof proceeds in the same manner as that of corollary [ cor1 ] , by noting that : ( i ) the gradient of @xmath522 is non - zero at @xmath296 and ( ii ) @xmath523 and @xmath524 converge to the same limiting normal distribution .      for each i.i.d .",
    "triplet @xmath525 , define the random variables , @xmath526 write , @xmath527 , for @xmath528 .",
    "it is easily seen that , @xmath529 where , @xmath530 has been defined in .",
    "since @xmath136 and @xmath531 are bounded away from @xmath104 and @xmath105 , this implies @xmath532 for all @xmath183 , and satisfy the relations , @xmath533 and @xmath534 . note that , @xmath535 are i.i.d .",
    "random vectors with @xmath536 and it can be shown that @xmath537 ( cf . ) . using the multivariate clt for i.i.d .",
    "random vectors we obtain , @xmath538 .",
    "following the definition of @xmath44 in , we can express @xmath539 define the mapping @xmath540 based on the map @xmath457 described above , define the random quantities @xmath541 then , it is possible to express @xmath542 using the wlln for i.i.d . means and since @xmath136 , we can claim @xmath543 and as a result , @xmath544 .",
    "similarly , we can show that , @xmath545 .",
    "hence , in order to study the asymptotic distribution of @xmath546 , it is enough to study the asymptotic distribution of @xmath547 , where @xmath548 . from",
    "it follows that @xmath549 , for @xmath550 .",
    "the matrix of partial derivatives of @xmath457 will be @xmath551 it follows that , @xmath552 , which is defined in .",
    "following the stated assumptions , it is easy to check that each element of @xmath553 exists in a neighbourhood of @xmath554 and is continuous at @xmath554 .",
    "the proof follows by using the delta method ( cf .",
    "theorem 3.1 of @xcite ) along with the asymptotic normality of @xmath555 .",
    "using the bootstrapped validation sample @xmath176 , we define the bootstrap version of @xmath556 s and @xmath442 s ( cf . ) as , @xmath557 conditional on @xmath398 , the @xmath558 s are i.i.d . and can be considered as a with replacement sample from the finite set of random vectors @xmath559 . also , from the proof of lemma [ lem - theta - hat ] , @xmath560 and @xmath561 .",
    "hence , using theorem 23.4 of @xcite it follows that , @xmath562 where @xmath142 is defined in .",
    "now we handle two statements of lemma [ lem - theta - boot ] separately .    1 .",
    "this proof of this part follows from retracing the arguments used in the proof of lemma [ lem - theta - hat ] , applied to the bootstrapped random vectors @xmath563 , using above , using the fact that the map @xmath457 in is continuously differentiable in a neighbourhood of @xmath554 and by applying the continuous mapping theorem for bootstrapped random variables ( cf .",
    "theorem 23.5 of @xcite ) .",
    "2 .   following the proof of lemma [ lem - theta - hat ] ,",
    "it is enough to study the limiting distribution of @xmath564 , where @xmath565 is the bootstrap version of @xmath566 , defined in .",
    "this follows because @xmath567 .",
    "write , @xmath568 and consider any fixed @xmath569 .",
    "define , @xmath570 and the random variables , @xmath571 write , @xmath572 . from lemma [ lem - theta - hat ] and , it follows that for any fixed @xmath573 , @xmath574 note that , @xmath575 . since the characteristic function of any random variable is bounded , we can use the second assertion in to claim that , @xmath576 fix any @xmath233 and define the sets , @xmath577,\\quad n\\geq 1.\\ ] ] following , there exists some @xmath578 , such that @xmath579 , for all @xmath499",
    "thus , using fubini s theorem for product measures we have @xmath580\\notag\\\\ & = \\e_0\\left[\\left(e^{\\imath\\cdot u r_n(\\tb)}\\right)\\cdot \\left\\{\\e_{\\m}\\left(e^{\\imath \\cdot u \\widehat{r}_n(\\tb)}\\right)-\\chi(u)\\right\\}\\cdot\\left\\{\\mathbf{1}(a^c_n ) + \\mathbf{1}(a_n)\\right\\}\\right]+\\chi(u)\\cdot \\e_0\\left(e^{\\imath\\cdot u r_n(\\tb)}\\right ) .",
    "\\label{cp-3}\\end{aligned}\\ ] ] consider the first term on the right side of .",
    "we can write , @xmath581   \\leq \\eps + 2 \\cdot \\pr_0(a_n )    \\leq \\eps + 2\\eps = 3\\eps,\\end{aligned}\\ ] ] whenever , @xmath499 .",
    "from the first assertion in it follows that , @xmath582 .",
    "combining both parts , we can conclude that , @xmath583 the right side above corresponds to the characteristic function of @xmath584 . by the uniqueness theorem for characteristic functions , the cramer - wold device and slutsky s theorem",
    "we can claim that @xmath585 where the convergence is understood in terms of the product probability @xmath222 .",
    "combining this with @xmath586 , completes the proof .",
    "abrevaya , j. and hausman , j. ( 1999 ) .",
    "semiparametric estimation with mismeasured dependent variables : an application to duration models for unemployment spells . ,",
    "( 55/56):243275 .",
    "aerts , m. and claeskens , g. ( 1999 ) .",
    "bootstrapping pseudolikelihood models for clustered binary data . , 51(3):515530 .",
    "amemiya , t. ( 1985 ) . .",
    "harvard university press .",
    "arcones , m.  a. and gin , e. ( 1992 ) . on the bootstrap of @xmath587-estimators and other statistical functionals . in",
    "_ exploring the limits of bootstrap ( east lansing , mi , 1990 ) _ , wiley ser",
    ". probab . math .",
    ", pages 1347 .",
    "wiley , new york .",
    "bhattacharya , r.  n. and ranga rao , r. ( 1986 ) . .",
    "robert e. krieger publishing co. inc . ,",
    "melbourne , fl .",
    "reprint of the 1976 original .",
    "bollinger , c.  r. and david , m.  h. ( 1997 ) . modeling discrete choice with response error :",
    "food stamp participation .",
    ", 92(439):827835 .",
    "buonaccorsi , j.  p. ( 2010 ) . .",
    "interdisciplinary statistics .",
    "crc press , boca raton , fl .",
    "carroll , r.  j. , ruppert , d. , stefanski , l.  a. , and crainiceanu , c.  m. ( 2006 ) . ,",
    "volume 105 of _ monographs on statistics and applied probability_. chapman & hall / crc , boca raton , fl , second edition . a modern perspective .",
    "carroll , r.  j. , spiegelman , c.  h. , lan , k. k.  g. , bailey , k.  t. , and abbott , r.  d. ( 1984 ) . on errors - in - variables for binary regression models .",
    ", 71(1):1925 .",
    "carroll , r.  j. and wand , m.  p. ( 1991 ) .",
    "semiparametric estimation in logistic measurement error models .",
    ", 53(3):573585 .",
    "chatterjee , s. and bose , a. ( 2005 ) .",
    "generalized bootstrap for estimating equations .",
    ", 33(1):414436 .",
    "chen , y. and liang , k .- y . ( 2010 ) . on the asymptotic behaviour of the pseudolikelihood ratio test statistic with boundary problems .",
    ", 97(3):603620 .",
    "cheng , g. and huang , j.  z. ( 2010 ) . .",
    ", 38(5):28842915 .",
    "copas , j.  b. ( 1988 ) .",
    "binary regression models for contaminated data . , 50(2):225265 .",
    "with discussion .",
    "cox , d.  r. and snell , e.  j. ( 1989 ) .",
    ", volume  32 of _ monographs on statistics and applied probability_. chapman & hall , london , second edition .",
    "demidenko , e. ( 2004 ) . .",
    "wiley series in probability and statistics .",
    "wiley - interscience ( john wiley & sons ) , hoboken , nj . theory and applications .",
    "dudley , r.  m. ( 2014 ) . , volume 142 of _ cambridge studies in advanced mathematics_. cambridge university press , cambridge .",
    "duffy , s.  w. , warwick , j. , williams , a. r.  w. , keshavarz , h. , kaffashian , f. , rohan , t.  e. , nili , f. , and sadeghi - hassanabadi , a. ( 2004 ) . a simple model for potential use with a misclassified binary outcome in epidemiology .",
    ", 58(8):712717 .",
    "edwards , j.  k. , cole , s.  r. , troester , m.  a. , and richardson , d.  b. ( 2013 ) . accounting for misclassified outcomes in binary regression models using multiple imputation with internal validation data . , 177:904912 .",
    "efron , b. ( 1979 ) . .",
    ", 7(1):126 .",
    "ekholm , a. and palmgren , j. ( 1987 ) .",
    "correction for misclassification using doubly sampled data .",
    ", 3(4):419 .",
    "fahrmeir , l. and kaufmann , h. ( 1985 ) .",
    "consistency and asymptotic normality of the maximum likelihood estimator in generalized linear models .",
    ", 13(1):342368 .",
    "fuller , w.  a. ( 2006 ) . .",
    "wiley series in probability and statistics .",
    "wiley - interscience ( john wiley & sons ) , hoboken , nj . reprint of the 1987 original , wiley - interscience paperback series .",
    "gart , j.  j. and zweifel , j.  r. ( 1967 ) . on the bias of various estimators of the logit and its variance with application of quantal bioassay .",
    ", 54:181187 .",
    "ghosh , a. , wright , f.  a. , and zou , f. ( 2013 ) .",
    "unified analysis of secondary traits in case - control association studies .",
    ", 108(502):566576 .",
    "gilbert , p.  b. , yu , x. , and rotnitzky , a. ( 2014 ) .",
    "optimal auxiliary - covariate - based two - phase sampling design for semiparametric efficient estimation of a mean or mean difference , with application to clinical trials .",
    ", 33(6):901917 .",
    "gin , e. and zinn , j. ( 1990 ) . bootstrapping general empirical measures .",
    ", 18(2):851869 .",
    "gong , g. and samaniego , f.  j. ( 1981 ) .",
    "pseudomaximum likelihood estimation : theory and applications .",
    ", 9(4):861869 .",
    "gordis , l. ( 2009 ) . .",
    "philadephia : elsevier / saunders , fourth edition .",
    "gouriroux , c. and monfort , a. ( 1981 ) .",
    "asymptotic properties of the maximum likelihood estimator in dichotomous logit models .",
    ", 17(1):8397 .",
    "guolo , a. ( 2011 ) .",
    "pseudo - likelihood inference for regression models with misclassified and mismeasured variables .",
    ", 21(4):16391663 .",
    "haldane , j. b.  s. ( 1956 ) . . ,",
    "20(4):309311 .",
    "hausman , j. ( 2001 ) .",
    "mismeasured variables in econometric analysis : problems from the right and problems from the left . , 15(4):5767 .",
    "hausman , j.  a. , abrevaya , j. , and scott - morton , f.  m. ( 1998 ) . .",
    ", 87(2):239269 .",
    "hilbe , j.  m. ( 2009 ) . .",
    "chapman & hall / crc texts in statistical science series .",
    "crc press , boca raton , fl .",
    "hosmer , d.  w. and lemeshow , s. ( 2004 ) . .",
    "john wiley & sons .",
    "jewell , n.  p. ( 2003 ) . .",
    "chapman & hall / crc texts in statistical science .",
    "taylor & francis .",
    "kasahara , h. and shimotsu , k. ( 2008 ) .",
    "pseudo - likelihood estimation and bootstrap inference for structural discrete markov decision models . , 146(1):92  106",
    ".    kosorok , m.  r. ( 2008 ) . .",
    "springer , new york .",
    "kothari , b. and bandyopadhyay , t. ( 2011 ) .",
    "can india s `` literate '' read ?",
    ", 56(5):705728 .",
    "lahiri , s.  n. ( 2003 ) . .",
    "springer - verlag , new york .",
    "lyles , r.  h. and kupper , l.  l. ( 2013 ) .",
    "approximate and pseudo - likelihood analysis for logistic regression using external validation data to model log exposure .",
    ", 18(1):2238 .",
    "lyles , r.  h. , tang , l. , superak , h.  m. , king , c.  c. , celentano , d.  d. , lo , y. , and sobel , j.  d. ( 2011 ) . .",
    ", 22(4):589597 .",
    "magder , l.  s. and hughes , j.  p. ( 1997 ) .",
    "logistic regression when the outcome is measured with uncertainty .",
    ", 146(2):195203 .",
    "meyer , b. and mittag , n. ( 2016 ) .",
    "misclassification in binary choice models .",
    "technical report .",
    "preprint available at http://harris.uchicago.edu/sites/default/files/misreporting in    bcm-march-8-2016.pdf[http://harris.uchicago.edu/sites/default/files/misreporting in bcm-march-8-2016.pdf ] .",
    "neuhaus , j.  m. ( 1999 ) .",
    "bias and efficiency loss due to misclassified responses in binary regression .",
    ", 86(4):843855 .",
    "parzen , m. , lipsitz , s. , ibrahim , j. , and klar , n. ( 2002 ) .",
    "an estimate of the odds ratio that always exists .",
    ", 11(2):420436 .",
    "prstgaard , j. and wellner , j.  a. ( 1993 ) .",
    "exchangeably weighted bootstraps of the general empirical process . , 21(4):20532086 .",
    "roy , s. , banerjee , t. , and maiti , t. ( 2005 ) . measurement error model for misclassified binary responses .",
    ", 24(2):269283 .",
    "savoca , e. ( 2011 ) .",
    "accounting for misclassification bias in binary outcome measures of illness : the case of post - traumatic stress disorder in male veterans .",
    ", 41(1):4976 .",
    "sposto , r. , preston , d.  l. , shimizu , y. , and mabuchi , k. ( 1992 ) .",
    "the effect of diagnostic misclassification on non - cancer and cancer mortality dose response in a - bomb survivors .",
    ", 48(2):605617 .",
    "stefanski , l.  a. and carroll , r.  j. ( 1985 ) .",
    "covariate measurement error in logistic regression .",
    ", 13(4):13351351 .",
    "van  der vaart , a.  w. ( 1998 ) .",
    ", volume  3 of _ cambridge series in statistical and probabilistic mathematics_. cambridge university press , cambridge .",
    "van  der vaart , a.  w. ( 2002 ) . ,",
    "volume 1781 of _ lecture notes in mathematics_. springer - verlag , berlin .",
    "lectures from the 29th summer school on probability theory held in saint - flour , july 824 , 1999 , edited by pierre bernard .",
    "van  der vaart , a.  w. and wellner , j.  a. ( 1996 ) . .",
    "springer - verlag , new york . with applications to statistics .",
    "van  der vaart , a.  w. and wellner , j.  a. ( 2007 ) . .",
    "in _ asymptotics : particles , processes and inverse problems _ , volume  55 of _ ims lecture notes monogr . ser .",
    "_ , pages 234252 .",
    "statist . ,",
    "beachwood , oh .    varadhan , r. and gilbert , p. ( 2009 ) .",
    "bb : an r package for solving a large system of nonlinear equations and for optimizing a high - dimensional nonlinear objective function .",
    ", 32(1):126 .",
    "wang , c.  y. and wang , s. ( 1997 ) .",
    "semiparametric methods in logistic regression with measurement error . , 7(4):11031120 .",
    "wang , y .- g . and zhao , y. ( 2007 ) . a modified pseudolikelihood approach for analysis of longitudinal data .",
    ", 63(3):681689 .",
    "wellner , j.  a. and zhan , y. ( 1996 ) . .",
    "technical report , department of statistics , university of washington .",
    "technical report 308 .",
    "we follow the same notational convention , as stated in the beginning of section [ sec - proofs ] .          from the expression of @xmath589 ( cf .",
    ") , it can be seen as a convex combination of @xmath590 and @xmath591 , for any @xmath592 and @xmath51 .",
    "hence , @xmath593 or @xmath594 , depending on which probability is larger .",
    "note that , @xmath595 , due to assumption ( a2)(ii ) . in case @xmath596 , using assumption ( a2)(i ) we must have , @xmath597 . and if , @xmath598 , then @xmath599 . combining",
    "both cases we have , @xmath600 from which follows .",
    "the following result shown in lemma [ lem3 ] shows the uniqueness and well - separability of @xmath10 as a root of the equation @xmath601 , under both without and with intercept models in and separately to illustrate some fine issues related to identifiability of the logistic regression model . for the rest of the article ,",
    "it is enough to consider for all calculations . in case",
    "is considered , we will simply substitute @xmath602 with probability @xmath105 and assume that the conditions in assumption ( a3@xmath134 ) hold .",
    "lemma [ lem4 ] shows the uniqueness and well - separability of @xmath10 as a root of the equation @xmath603 , using lemma [ lem3 ] .      1 .",
    "consider the model , without an intercept term .",
    "suppose , assumptions ( a1 ) and ( a3 ) holds .",
    "then , @xmath298 ( cf . ) has an unique zero at @xmath296 and the unique zero at @xmath10 is well - separated in the following sense , @xmath604 2 .",
    "consider the model , with an intercept term .",
    "suppose , assumptions ( a1 ) and ( a3@xmath134 ) holds .",
    "then , the statement about @xmath298 in part ( i ) above holds in this case .        1 .   in this case , the first component @xmath605 of the @xmath5-dimensional covariate vector @xmath6 is assumed to be a non - degenerate component .",
    "when the underlying regression coefficient is @xmath37 , then @xmath79 has joint density @xmath606 with respect to the product measure @xmath607 , with @xmath608 being the counting measure on @xmath609 and @xmath99 denoting the marginal of @xmath6 . also , the family of densities @xmath610 is identifiable . if not , then for some @xmath611 , we will have @xmath612 , a.e .",
    "@xmath613 . using @xmath614 and @xmath105 , we obtain @xmath615 however , under assumption ( a3 ) this is impossible and hence , @xmath616 , which implies identifiability . for each @xmath37 , define the expected log - likelihood as @xmath617 , where @xmath9 is the distribution corresponding to the density @xmath618 . using assumption ( a3 ) and the dct ( dominated convergence theorem ) ,",
    "it is easy to check that the gradient of @xmath619 , denoted by @xmath620 , exists at all @xmath37 and @xmath621 ( cf . ) . extending the same argument it follows that all second order partial derivatives of @xmath619 will exist at every @xmath37 with , @xmath622 consider any @xmath623 .",
    "then , @xmath624 since , @xmath625 using assumption ( a3 ) and @xmath626 , for all @xmath627 . as a result , the hessian of @xmath619 is strictly negative definite at each @xmath319 , which implies @xmath628 is strictly concave .",
    "a strictly concave function has an unique point of maxima and in this case , due to the identifiability of the family @xmath610 it follows from lemma 5.35 of @xcite that the unique point of maxima of @xmath619 is at the true parameter @xmath10 .",
    "obviously , @xmath629 .",
    "if possible , assume that there exists some @xmath630 , such that @xmath631 .",
    "but due to the strict concavity of @xmath619 , this implies @xmath632 will be an unique maxima of @xmath633 , which is not possible as per the above argument .",
    "hence @xmath10 is the unique zero of @xmath298 which proves the first part of the statement . to prove the second part of the statement we use lemma [ lemconc ] , using the fact that @xmath634 is strictly concave , with an unique maxima at @xmath10 .",
    "this completes the proof .",
    "2 .   in case",
    "an intercept term is included in the model , @xmath635 and @xmath636 where , @xmath128 is the intercept term and @xmath127 .",
    "note that we can re - write , @xmath637 where , @xmath638 .",
    "any of these two representations of the same model can be used and due to assumption ( a3@xmath134 ) , both these representations are equivalent . similar to the no - intercept case , consider densities corresponding to two models @xmath639 and @xmath640 , which satisfy @xmath641 , a.e .",
    "@xmath613 , where , @xmath642 , @xmath162 . following earlier arguments",
    ", we can claim that @xmath643 where , @xmath99 is the joint distribution of @xmath644 .",
    "if possible , assume that , @xmath645 . then , using similar arguments as earlier applied to the vector @xmath644 , we can conclude that @xmath130 is supported on a @xmath646 dimensional hyperplane .",
    "this hyperplane does not ( does ) pass through the origin if @xmath647 is not equal ( equal ) to zero .",
    "this implies linear dependence among the @xmath129 components of @xmath130 , which contradicts assumption ( a3@xmath134 ) .",
    "hence the only possibility is , @xmath645 , which immediately implies @xmath648 .",
    "thus , @xmath649 and the class of models with intercept is identifiable .",
    "the remaining part of the proof follows the same arguments as in the without intercept case .",
    "the proof relies on lemma [ lem3 ] .",
    "using , we have @xmath651.\\end{aligned}\\ ] ] obviously , @xmath652 .",
    "since @xmath653 $ ] , for all @xmath573 , using we obtain @xmath654 for all @xmath18 and @xmath37 .",
    "write , @xmath655 and @xmath656 .",
    "note that , @xmath657 , due to assumption ( a4 ) . as a result we have a componentwise inequality , for all @xmath37 @xmath658 < z(\\bb ) < c_2 \\cdot \\e \\left[\\xb\\cdot \\{\\psi(\\xbp\\bb_0)-\\psi(\\xbp\\bb)\\}\\right ] = c_2\\cdot z_1(\\bb),\\end{aligned}\\ ] ] from lemma [ lem3 ] , we know that @xmath298 has an unique zero at @xmath296 . hence , for all other @xmath630 , there will be a component @xmath659 , such that @xmath660 ( and either it will be negative or positive ) . using the above componentwise inequality , we must have @xmath661 since @xmath662 , so @xmath663 and has the same sign as @xmath664 . as a result",
    ", we have showed that @xmath123 must have an unique zero at @xmath665 .",
    "now , using the componentwise upper and lower bounds on @xmath123 , we have @xmath666 now using part ( i ) of lemma [ lem3 ] , it is easy to see that @xmath667 this completes the proof .            1 .",
    "consider the class @xmath668 . by",
    "referring to the standard orthonormal basis @xmath669 of @xmath137 , we can write @xmath670 for all @xmath671 and @xmath672 .",
    "hence , @xmath668 is generated by linear combinations of the finite set @xmath673 .",
    "this implies , @xmath668 is a vapnik - chervonenkis ( vc ) class of functions , with vc dimension @xmath674 .",
    "also , the logistic link function , @xmath675 $ ] defined as @xmath676 , is monotone on @xmath677 .",
    "this leads to the representation , @xmath678 .",
    "hence , @xmath679 will be a vc class .",
    "finally , @xmath680 since , @xmath681 and @xmath682 , are two fixed functions defined on the sample space , it follows that @xmath154 is also a vc class .",
    "now , consider the countable subclass , @xmath683 , where @xmath684 denotes the set of rationals . since @xmath685 is dense in @xmath137 , hence for any @xmath319",
    ", there will exist a sequence @xmath686 , such that @xmath687 , for all @xmath60 .",
    "thus , @xmath154 will be a pointwise measurable class .",
    "finally , note that due to assumption ( a3 ) , the @xmath248th component of @xmath52 is bounded by the envelope function @xmath688 , for all @xmath659 .",
    "thus , @xmath154 has the envelope function @xmath689 .",
    "combining all steps we conclude that @xmath154 is a @xmath9-donsker class .",
    "2 .   in order to show that the class of @xmath5-dimensional functions @xmath155 is @xmath9-donsker , it is enough to show that classes corresponding to each component of @xmath690 will be donsker . without loss of generality , consider the first component of @xmath690 and define the class of functions , @xmath691 from the proof of part ( i ) above , we know @xmath692 is a vc class and the constants @xmath309 and @xmath693 can be considered as fixed functions on the sample space .",
    "hence , @xmath694 will be a vc class .",
    "since @xmath695 is monotone for positive @xmath696 , the class @xmath697 will be a vc class .",
    "following the proof of lemma [ lem - uppbd ] , without loss of generality we assume that , @xmath698 ( similar argument applies if the range is @xmath699 ) .",
    "hence the constant @xmath700 is an envelope function for this class .",
    "similar arguments show that the class @xmath701 will also be vc with envelope function @xmath702 . also , the classes @xmath703 , @xmath704 and @xmath705 will be vc , following usual vc preservation properties , and will have envelope functions @xmath706 , @xmath105 and @xmath706 respectively .",
    "it is known that any vc class has a bounded uniform entropy integral ( buei ) with respect to any envelope function for that class .",
    "also products of individual buei classes will be buei with envelope function equal to the product of envelope functions of individual classes ( cf .",
    "theorem 9.15 of @xcite ) .",
    "hence , the class @xmath486 which is a subset of the product of these above mentioned classes will also be buei with envelope function @xmath707 .",
    "also define the trivial class @xmath708 , consisting of only one function @xmath709 .",
    "for any @xmath710 and @xmath711 , define the map @xmath712 as , @xmath713 .",
    "due to the trivial nature of @xmath489 , we have @xmath714 where , @xmath715 , @xmath716 , @xmath717 and @xmath718 .",
    "this satisfies equation ( 2.10.19 ) of @xcite and shows that the map @xmath719 is lipschitz of orders @xmath326 . since @xmath716 , we can neglect the second lipschitz order . since the class @xmath486 is buei with envelope function @xmath720 , hence the uniform entropy integral @xmath721 where the supremum is over probability measures @xmath722 on the sample space with @xmath723 and @xmath724 are the associated covering numbers .",
    "the corresponding covering number of the trivial class @xmath708 will be equal to @xmath105 , for any @xmath233 and as a result the uniform entropy integral for @xmath489 will be finite for all @xmath232 .",
    "also , @xmath725 , under assumption ( a3 ) and the class @xmath726 can be shown as pointwise measurable by considering the subclass of @xmath486 indexed by all @xmath727 .",
    "now , using theorem 2.10.20 of @xcite , we can claim that @xmath728 will be @xmath9-donsker . using the same argument for remaining components of @xmath157 we can complete the proof",
    ".      it will be enough to show the convergence of each component of @xmath120 separately and without loss of generality we consider the first component , which is denoted by the same symbol .",
    "define the classes of functions : @xmath731 we use lemma 2.2 of @xcite , which provides sufficient conditions to ensure that , @xmath732 .",
    "these sufficient conditions are essentially the following :    1 .   @xmath733 as @xmath734 .",
    "2 .   the class @xmath735 is pointwise measurable with envelope function @xmath736 and satisfies @xmath737 as @xmath738 , where , @xmath739 3 .   the envelope functions @xmath740 ,",
    "used in part ( c.2 ) above , satisfy the lindeberg condition : @xmath741      1 .",
    "* verification of ( c.1 ) * : define , @xmath742 , @xmath743 , as the partial derivative of @xmath120 with respect to @xmath744 , @xmath745 .",
    "we can show that , for all @xmath746 and any @xmath747 , @xmath748 , \\label{eq-3 - 1}\\end{aligned}\\ ] ] and @xmath749 .",
    "\\label{eq-3 - 2}\\end{aligned}\\ ] ] combining with and , it follows that for @xmath550 , @xmath750 \\leq k_0 |x_1|,\\quad\\text{for all $ \\wyx$ , }   \\label{dsup}\\end{aligned}\\ ] ] where , @xmath751 .",
    "consider a non - random sequence @xmath752 satisfying @xmath753 . since @xmath754 and @xmath96 is open ( cf . assumption ( a2 ) ) , there exists some @xmath497 , such that @xmath755 for all @xmath499 .",
    "for any fixed @xmath37 , there exists sequences @xmath756 ( obtained from using the mean - value theorem around @xmath16 ) , such that @xmath757 following . for any @xmath758 , @xmath759 . using , for large enough @xmath25 and for all @xmath61 , we have @xmath760",
    "then , @xmath761 can be considered as a _ particular _",
    "envelope function for the class @xmath735 .",
    "due to assumption ( a3 ) , @xmath762 which verifies ( c.1 ) .    before verifying ( c.2 ) , the following remarks are essential . a class of functions @xmath763 has a bounded uniform entropy integral ( buei ) with respect to a envelope function @xmath764 ( cf .",
    "section 9.1.2 of @xcite for details ) , if @xmath765 .",
    "any vc class of functions @xmath763 will be buei with respect to any choice of envelope function for @xmath763 . for a sequence of vc classes of functions @xmath766 the main goal will be to study the vc dimensions @xmath767 and show that it remains constant whenever @xmath25 is large enough .",
    "this will ensure that for large enough @xmath25 , @xmath768 remains finite and bounded by a constant and in that case , @xmath769 for any @xmath738 .    1 .",
    "* verification of ( c.2 ) * : for any @xmath758 define the classes of functions : @xmath770 then , @xmath771 .",
    "we will study the properties of the class @xmath772 by considering it s individual components as separate function classes .",
    "+ consider the classes of functions , @xmath773 , @xmath152 .",
    "although this class is not dependent on @xmath25 , but we will use this notation for ease of explanation . following arguments given in the proof of lemma [ donsk - lem](i ) , each @xmath774 will be a vc class with vc dimension independent of @xmath25 .",
    "hence , @xmath774 will be buei with respect to the envelope function @xmath775 .",
    "this leads to @xmath776 , for some @xmath777 , for all @xmath25 .",
    "for same reasons , the classes @xmath778 , @xmath152 , will buei with envelope function @xmath779 , for all @xmath25 .",
    "hence , @xmath780 , for some @xmath781 , for all @xmath25 .",
    "+ now , consider the classes @xmath782 , @xmath152 .",
    "define the class of functions , @xmath783 due to assumption ( a2)(ii ) and since @xmath758 is fixed , there exists some @xmath784 , such that @xmath785 using the arguments given in the proof of lemma 9.9 ( vi ) of @xcite , it can be seen that the vc dimension of @xmath786 , will be same as the vc dimension of @xmath787 for all @xmath499 .",
    "the proof of lemma 9.9 ( v ) of @xcite shows that the vc dimension of @xmath788 will be same as the vc dimension of @xmath787 for @xmath499 .",
    "this shows that the vc dimension of @xmath789 remains constant for all @xmath499 and it will be buei with respect to the envelope function @xmath790 . as a result , @xmath791 , for some @xmath792 , for all @xmath499 .",
    "+ the above statement about @xmath789 and the arguments used in the proof of lemma [ donsk - lem](ii ) imply that , @xmath793 will be a vc class with a constant vc dimension for all @xmath499 , and buei with envelope function @xmath794 ( or @xmath795 ) .",
    "so , @xmath796 , for some constant @xmath797 , for all @xmath499 . using the same reasoning , it follows that @xmath798 will be buei with envelope function @xmath799 ( or @xmath800 ) and @xmath801 , for some constant @xmath802 , for all @xmath499 .",
    "+ since products of individual buei classes are buei with envelope function equal to the product of individual envelope functions ( cf .",
    "theorem 9.15 of @xcite ) , it follows that @xmath803 will be buei with envelope functions , @xmath804 since @xmath805 , the covering numbers satisfy , @xmath806 , for all @xmath233 and as a result , @xmath772 will be buei with envelope function @xmath807 , for all @xmath499 .",
    "hence , @xmath808 a similar arguments shows that the above statement holds if @xmath772 is replaced by @xmath809 .",
    "as a result the class , @xmath810 , will be buei with envelope function @xmath811 , using lemma 9.14 ( part ( iii ) ) of @xcite .",
    "hence , @xmath812 , for all @xmath499 .",
    "using dct , @xmath813 , for any @xmath738 .",
    "the class @xmath735 will be pointwise measurable by considering the countable subclass indexed over all @xmath727 .",
    "this verifies part ( c.2 ) , with envelope function @xmath814 .",
    "* verification of ( c.3 ) * : the envelope function @xmath736 defined above is of the form @xmath815 , for some @xmath816 . using assumption ( a3 ) we obtain , @xmath817 for all @xmath233 .    hence all the three sufficient conditions required by lemma 2.2 of @xcite are verified .",
    "this completes the proof for the first component of @xmath120 and similar arguments can be used for the other components . combining all parts we complete the proof",
    ".      it will be enough to show that the above convergence result is true for the first component of @xmath120 .",
    "we will denote the first component of @xmath120 by the same symbol .",
    "note that , due to lemma [ lem - theta - hat ] and assumption ( a4 ) , @xmath819 converges in distribution to a tight limiting ( normal ) random variable , which takes values in the @xmath820-compact set @xmath821 .",
    "consider any fixed @xmath758 , @xmath319 and a @xmath232 .",
    "following theorem 2.3 of @xcite , define the class of functions , @xmath822 let , @xmath823 . using and we can write , @xmath824 for some constant @xmath825 .",
    "the function @xmath826 can be considered as a _ particular _",
    "envelope function for the class @xmath827 . following and using assumption ( a3 )",
    ", we can apply the clt for i.i.d .",
    "random variables to obtain , @xmath828 finally , note that if @xmath829 , then due to assumption ( a3 ) , @xmath830 this is true uniformly for all @xmath747 and for all @xmath831 , where @xmath832 is any compact set in @xmath821 .",
    "thus , conditions ( ii ) and ( iii ) of theorem 2.3 of @xcite are verified . condition ( i ) of theorem 2.3 of @xcite is verified in lemma [ lem10 ] .",
    "the remaining components can be handled similarly to complete the proof .            1 .",
    "note that , @xmath839 the proof now follows from lemma [ donsk - lem](i ) and by noting that any @xmath9-donsker class will be a gc class .",
    "2 .   define the @xmath5-dimensional process , @xmath840 . note that , @xmath841 using lemma [ donsk - lem](ii )",
    "also , @xmath842 which follows from lemma [ lem9 ] .",
    "in order to handle the last term of , consider the first component of the @xmath5-dimensional function @xmath120 and denote it by the same symbol .",
    "for any @xmath754 , define the function , @xmath843 .",
    "note that , @xmath844 . for any nonrandom sequence @xmath845",
    ", using it follows @xmath846 .",
    "hence , @xmath847 is continuous at @xmath848 . now using lemma [ lem - theta - hat ] and continuous mapping theorem",
    ", it follows that @xmath849 . applying the same argument over other components shows that the last term of is @xmath850 .",
    "combining this with other convergence statements given above completes the proof .      1 .",
    "consider the first component of @xmath120 and denote it by the same symbol .",
    "define the map , @xmath851 as , @xmath852 .",
    "let @xmath853 denote the partial derivative of @xmath854 with respect to @xmath855 , @xmath162 .",
    "then , @xmath853 exists , is continuous everywhere and can be obtained by interchanging the integration and differentiation symbols : @xmath856 the result holds if any other component of @xmath120 is used in defining @xmath854 .",
    "2 .   now , use the original definition of @xmath120 as a @xmath5-dimensional function from . define the map , @xmath857 as , @xmath858 . for any @xmath754 ,",
    "the total derivative of @xmath859 is @xmath860 , a @xmath456 matrix , with the @xmath861-th element being @xmath862 partial derivative of the @xmath207-th component of @xmath859 with respect to @xmath863 , @xmath864 and @xmath865 .      1 .",
    "consider any @xmath319 and any @xmath866 .",
    "consider a real valued sequence @xmath867 satisfying @xmath868 .",
    "write , @xmath869 , @xmath152 . as because @xmath96 is an open set the partial derivative of @xmath120 , with respect to @xmath590 exists at each @xmath754 , with @xmath870/h_n \\rightarrow d_1(h_{2,\\bb,\\thb})(\\widetilde{y},\\xb)$ ] , for all @xmath61 ( cf . ) .",
    "following , @xmath871 .",
    "hence , we can use the dct to claim that @xmath872\\right)~d\\pr_0(\\widetilde{y},\\xb)\\\\   & = \\int d_1(h_{2,\\bb,\\thb})(\\widetilde{y},\\xb)~d\\pr_0(\\widetilde{y},\\xb ) = \\int \\left(\\frac{\\partial}{\\partial \\theta_1 } h_{2,\\bb,\\thb}(\\widetilde{y},\\xb)\\right)~d\\pr_0(\\widetilde{y},\\xb).\\end{aligned}\\ ] ] this proves the existence of the partial derivatives @xmath873 and also shows that they can be obtained by interchanging the differentiation and integration symbols .",
    "now consider any sequence @xmath874 , such that @xmath875 and @xmath876 , where , @xmath877 .",
    "for any fixed choice of @xmath61 , the map @xmath878 ( cf . ) is continuous everywhere .",
    "hence , for any @xmath879 , @xmath880 . combining this with and applying the dct along with assumption ( a3 ) leads to , @xmath881 this proves the continuity of @xmath873 for all @xmath882 .",
    "a similar argument works for @xmath883 .",
    "2 .   a sufficient condition for the existence of the total derivative map @xmath884 requires the following : the partial derivatives exists for all @xmath51 and are continuous in @xmath51 ( cf .",
    "chapter 3 of @xcite ) . following the proof of part ( a ) given above",
    ", this claim follows by keeping @xmath37 fixed at @xmath10 and carrying the same arguments .",
    "the elements of @xmath884 are given in .",
    "[ rem1 ] lemma [ lem11 ] is a stochastic equicontinuity result about the process @xmath160 , required for proving asymptotic normality of @xmath68 and uses the consistency property of @xmath68 ( cf .",
    "theorem [ thm1](i ) ) .",
    "however , the proof of consistency does not require lemma [ lem11 ] and is based on separate arguments , only requiring lemma s [ lem4 ] and [ lem5 ]",
    ".      it will be enough to prove , @xmath886 . using and we can write , @xmath887\\notag\\\\ & \\quad { } + \\sqrt{n}(f_n - f)\\pr_0 \\big(h_{1,\\bbln } - h_{1,\\bb_0}\\big)-\\sqrt{n}(f_n - f)\\left[z_2(\\bbln ) - z_2(\\bb_0)\\right]\\notag\\\\ & \\equiv b_{1,n } + b_{2,n } + b_{3,n } + b_{4,n}. \\label{brk2}\\end{aligned}\\ ] ] note that the right side of is @xmath5-dimensional .",
    "it is enough to show convergence of each component separately . without loss of generality",
    "consider the first component of each term on the right side of .",
    "also , denote the first component of @xmath119 and @xmath120 by the same symbols .",
    "consider any non - random sequence @xmath888 satisfying @xmath889 .",
    "for each fixed @xmath60 , due to continuity of @xmath890 , @xmath891 .",
    "using assumption ( a3 ) we have , @xmath892 , for all @xmath152 and all @xmath60 .",
    "define the map , @xmath893 .",
    "we can now apply the dct to obtain , @xmath894 since @xmath895 , hence @xmath896 is continuous at @xmath665 . using consistency of @xmath68 ( cf .",
    "theorem [ thm1](i ) ) and the continuous mapping theorem , we obtain @xmath897 . using the donsker property shown in lemma [ donsk - lem](i ) and applying lemma 19.24 of @xcite",
    "it follows that , @xmath898 .",
    "note that , @xmath899 can be expressed as @xmath900 .",
    "\\label{b2 }   \\end{aligned}\\ ] ] replacing @xmath44 in by @xmath16 , define @xmath901\\notag\\\\   & = \\sqrt{1-f_n}\\cdot \\grnt\\left(h_{2,\\bbln,\\thb_0 } - h_{2,\\bb_0,\\thb_0}\\right ) ,   \\label{b2t}\\end{aligned}\\ ] ] then , it can be shown that@xmath902 due to lemma [ lem9 ] , @xmath903 .",
    "note that , for any sequence of non - random constants @xmath904 , the sequence , @xmath905 , using lemma [ lem - theta - hat ] .",
    "using lemma [ lem8](i ) and mean - value theorem , we can write , @xmath906 for some sequences @xmath907 , for @xmath865 , and @xmath908 , @xmath865 , are the partial derivative functions defined in lemma [ lem8](i ) . using lemma [ lem - theta - hat ] , theorem [ thm1](i ) , lemma [ lem8](i ) and the continuous mapping theorem , we obtain , @xmath909 this implies , @xmath910 . for same reasons , @xmath911 . applying lemma [ lem - theta - hat ] ,",
    "we get @xmath912 , which implies @xmath913 . note that",
    ", @xmath155 is a donsker class , following lemma [ donsk - lem](ii ) .",
    "so we can apply the same arguments as in the case of @xmath914 to show that @xmath915 . using lemma 19.24 of @xcite",
    "it follows that @xmath916 and hence @xmath917 .    finally , due to assumption ( a3 ) and the dct , @xmath918 is continuous everywhere .",
    "applying the continuous mapping theorem , @xmath919 and by assumption ( a4 ) , @xmath920 .",
    "hence , @xmath921 . similarly , using lemma [ lem8](i ) and the stated assumptions we can claim that , @xmath922 will be continuous at all @xmath319 .",
    "similar arguments imply @xmath923 .",
    "combining the results above shows that the right side is @xmath83 .",
    "applying this over all @xmath5 components separately shows that @xmath924 .",
    "this completes the proof .",
    "we begin with a result which describes the inter - relations among the different probability orders and will frequently be used in the proofs .",
    "extensions to lemma [ lem - prob ] can be found in lemma 3 of @xcite .",
    "further details on outer modes of convergence can be found in @xcite .",
    "consider any class of measurable ( vector valued ) functions @xmath925 .",
    "for any measure @xmath926 , we define , @xmath927 .      1 .",
    "suppose , @xmath928 .",
    "then , @xmath228 in @xmath221-probability .",
    "2 .   suppose , @xmath226 is a sequence of functions defined only the first product probability space @xmath929 and @xmath930 .",
    "then , @xmath928 and @xmath228 in @xmath221-probability .",
    "3 .   suppose , @xmath931 .",
    "then , @xmath231 in @xmath221-probability .        1 .",
    "fix any @xmath229 . then , using markov s inequality and fubini s theorem for product measures ( cf .",
    "lemma 1.2.6 of @xcite ) , @xmath932    \\leq \\frac{1}{\\eta } \\cdot \\er^*\\mathbf{1}(|\\delta_n|>\\eps ) = \\frac{1}{\\eta}\\cdot\\prr^*\\left(|\\delta_n|>\\eps\\right ) \\rightarrow 0,\\end{aligned}\\ ] ] by definition of outer convergence in probability in @xmath222 .",
    "this completes the proof .",
    "2 .   in this case , @xmath933 since @xmath934 depends only the product space @xmath929 so the outer majorant with respect to @xmath222 is same as the outer majorant with respect to @xmath218 ( cf .",
    "page 10 of @xcite ) . since , @xmath928 , we can apply part ( a ) above to obtain , @xmath228 in @xmath221-probability . in case ,",
    "@xmath935 , the a very similar argument implies that @xmath931 .",
    "3 .   for any @xmath232 and @xmath936 ,",
    "we can write @xmath937 provided we choose @xmath938 and @xmath939 , such that @xmath940 , for all @xmath939 .",
    "the latter condition will be true , because @xmath931 .",
    "this completes the proof .",
    "[ rem2 ] lemma s [ lem - boot-1 ] , [ lem - boot-2 ] , [ lem - boot - equi ] and [ boot - tight ] are needed for studying the asymptotic distribution of the bootstrapped pmle @xmath195 and uses consistency of @xmath195 .",
    "the proof of bootstrap consistency of @xmath195 is not dependent on these lemmas .          1 .   without loss of generality",
    "consider the first component of @xmath119 and denote it by the same symbol .",
    "for any @xmath944 , define the semi - metric @xmath945 .",
    "note that , @xmath946 for all @xmath37 .",
    "we claim that there exists a sequence @xmath738 , such that @xmath947 the conclusion for @xmath948 in follows from consistency of @xmath195 in theorem [ thm - boot](i ) , the arguments used in handling the term @xmath914 in and finally using lemma [ an - lem ] . the case of",
    "@xmath949 follows from the case of @xmath948 ( or it can be proved directly ) .",
    "it now follows that there exists a sequence @xmath738 , such that @xmath950 based on the above chosen sequence @xmath951 , define the classes of functions @xmath952 following lemma [ donsk - lem](i ) , it is known that @xmath953 is a donsker class . applying corollary 2.3.12 of @xcite",
    ", it follows that , @xmath954 , which in turn implies , @xmath955 in @xmath221-probability , using lemma [ lem - prob ] .",
    "fix any @xmath233 .",
    "then , @xmath956 we can apply this argument to all other components of @xmath119 separately to complete the proof .",
    "the proof proceeds in exactly the same manner as part ( i ) above and using lemma [ donsk - lem](ii ) , which states that @xmath957 , is a donsker class .",
    "3 .   using lemma [ lem - theta - boot](ii ) and assumption ( a4 ) , we know @xmath958 converges to a tight limiting distribution ( with respect to @xmath222 ) , hence we can apply lemma [ lem9 ] ( with all probability statements understood in terms of @xmath222 ) . thus , for any @xmath233 , @xmath959 applying lemma [ lem - prob ] completes the proof .          1 .   note",
    "that , @xmath963 remains unchanged if @xmath119 is re - centered at @xmath964 .",
    "hence , for the rest of the proof of part ( i ) , we will work with the re - centered versions and assume that @xmath965 for all @xmath37 .",
    "following markov s inequality , it will be enough to show @xmath966 .",
    "note that , the class @xmath967 defined in is not affected , since the @xmath968 semi - metric uses centered versions of @xmath119 .",
    "fix any @xmath233 .",
    "following we can write , @xmath969 since , @xmath154 is a donsker class , we can use the arguments given in the proof of theorem 9.3 of @xcite ( cf .",
    "pg 344 ) to conclude that @xmath970 2 .",
    "we will adapt the proof of theorem 2.3 of @xcite in this case . for any @xmath232 and any compact set @xmath274 , define @xmath971 , where @xmath972 and @xmath973 denotes the euclidean distance in @xmath821 .",
    "since @xmath274 is compact , for any @xmath232 there exists finitely many points @xmath974 , with @xmath975 such that @xmath976 , where @xmath977 denotes an open ball of radius @xmath978 around the point @xmath979 .",
    "hence , @xmath980 .",
    "note that , @xmath981 fix any @xmath502 .",
    "then , for any @xmath232 , @xmath982 from lemma [ lem - theta - boot](iii ) , it follows @xmath983 .",
    "fix any arbitrary @xmath984 . then , following lemma [ lem - prob ] , there exists a compact set @xmath985 and an integer @xmath986 , such that @xmath987 use this choice of @xmath988 in the right side of . following the proof of theorem 2.3 of @xcite and using the same choice of @xmath826 ( cf . ) , the first term on the right side of with @xmath989 , can be written as @xmath990 consider the first term of . since @xmath232 is a fixed quantity and @xmath991 are arbitrary but _ fixed _ positive constants ,",
    "hence @xmath992 is finite . due to finiteness of @xmath5 , showing @xmath993 , is equivalent to showing that @xmath994 in @xmath221-probability for any fixed @xmath758 .",
    "following , we can write @xmath995 under the stated assumptions , @xmath996 in @xmath221-probability . also by lemma [ lem - prob ] , @xmath997 in @xmath221-probability .",
    "+ now , consider the second term of . the definition of @xmath998 in shows that it is independent of @xmath37 and @xmath999 .",
    "hence , for any @xmath829 , using the wlln , assumption ( a3 ) and we have , @xmath1000 hence , @xmath1001 .",
    "+ finally , consider the third term of . due to finiteness of @xmath5",
    ", it enough to show that for any @xmath758 , @xmath1002 in @xmath221-probability , where , @xmath735 is defined in .",
    "let @xmath1003 be a sequence of i.i.d .",
    "poisson@xmath1004 random variables , independent of @xmath1005 and defined on a different probability space .",
    "let @xmath1006 denote the outer expectation with respect to the product probability measure corresponding to the product space @xmath1007 .",
    "following the arguments given in @xcite ( lemma 9.12 and pg .",
    "344 ) , we can write @xmath1008 we will handle each term of separately .",
    "+ starting with the third term of , note that for large enough @xmath174 and fixed @xmath1009 , @xmath1010 .",
    "following and we can write , for some constant @xmath1011 , @xmath1012 due to assumption ( a3 ) . + next , consider the second term of . note that , as per the proof of lemma [ lem10 ] , for any @xmath232 , there exists some @xmath497 , such that @xmath1013 , for all @xmath499 .",
    "now we can apply the sufficient conditions stated in the proof lemma [ lem10 ] and arguments given in theorem 6.16 of @xcite ( pg . 405 ) to show that @xmath1014 .",
    "hence , @xmath1015 .",
    "+ finally , consider the first term of .",
    "define i.i.d .",
    "radamacher random variables @xmath1016 on a different factor of a probability space , which are independent of @xmath1017 and @xmath1018 and denote the outer expectation with respect to the product measure of @xmath1016 and @xmath1019 as and @xmath1003 , but this will not create any confusion as the context will be clear each time . ] @xmath1006 . in order to handle @xmath1020 , for convenience of notation we re - index the indices , so that the index set is @xmath1021 instead of @xmath1022 .",
    "firstly , @xmath1023 the second term in the right side converges to zero for any fixed @xmath999 . note that @xmath1024 are centered i.i.d .",
    "random variables , independent of @xmath1018 .",
    "define , @xmath1025 . also",
    ", @xmath1026 are i.i.d .",
    "stochastic processes with finite expectation over @xmath735 , hence @xmath1027 whenever @xmath25 is large enough , for any fixed @xmath999 ( cf . ) .",
    "now , @xmath1028 , for all @xmath1029 .",
    "hence , @xmath1030 .",
    "also , @xmath1031 , implies , @xmath1032 .",
    "then we can apply the multiplier inequality given in lemma 2.9.1 of @xcite to obtain , @xmath1033 following earlier arguments , for any sequence @xmath1034 , satisfying , @xmath1035 , the first term on the right side of converges to zero as @xmath1036 . and @xmath1037 for any integer @xmath1038 , using lemma 2.3.6 of @xcite , we can remove the radamacher random variables , and obtain @xmath1039 where , @xmath1040 is the analogue of @xmath1041 , based on the i.i.d .",
    "sample @xmath1042 .",
    "now , use @xmath1043 and let @xmath1034 .",
    "it can be verified that the sufficient conditions for lemma [ lem10 ] continue to hold if we replace @xmath1041 by @xmath1044 in the statement of lemma [ lem10 ] . following the arguments used in handling @xmath1045 and removing the radamacher random variables in the above manner",
    ", we can claim that @xmath1046 . in order to handle the first term on the right side of ,",
    "firstly note that @xmath1047 also note that , for any real valued sequence @xmath1048 satisfying @xmath1049 , it follows that @xmath1050 , provided @xmath1051 .",
    "so , it will be enough to show that @xmath1014 , which itself follows from the arguments used in handling @xmath1045 .",
    "since @xmath1034 , the first term in the right side of converges to zero .",
    "thus the right side of converges to zero .",
    "hence , @xmath1052 .",
    "+ combining all these steps and going back to , we conclude that @xmath1053 , which implies for any @xmath502 , @xmath1054 .",
    "thus , @xmath1055 + by lemma [ an - lem ] , there will exist some sequence @xmath738 , such that @xmath1056 and @xmath1057 ( cf . )",
    "are @xmath850 , with the fixed @xmath978 replaced by @xmath1058 .",
    "choose this sequence @xmath1058 in @xmath1059 .",
    "hence the left side of satisfies @xmath1060 combining this with , and since @xmath984 , are arbitrary , we can conclude that @xmath1061 3 .   in this case , from theorem [ lem - theta - hat ]",
    "@xmath1062 and hence @xmath1063 .",
    "the remaining argument can be carried out along the same lines as done in part ( ii ) above .",
    "we skip the details .",
    "recall the definitions of @xmath1065 , @xmath72 and @xmath123 from , and respectively .",
    "then , we can write @xmath1066 + \\sqrt{n}\\left(z_n - z\\right)\\big(\\bbln-\\bb_0\\big ) + \\sqrt{n}\\left(z_n - z\\right)\\big(\\bbbn-\\bb_0\\big)\\notag\\\\ & \\quad { } -\\sqrt{n}\\left(\\widehat{z}_n - z_n\\right)\\left(\\bbbn-\\bb_0\\right)\\notag\\\\ & \\equiv f_{1,n } + f_{2,n } + f_{3,n } - f_{4,n}. \\label{brk5}\\end{aligned}\\ ] ] we will work with the first components of @xmath119 and @xmath120 and denote them by the same symbols .",
    "consider the first components of each term of separately . since @xmath195 is defined to be an exact zero of @xmath1065 , hence @xmath1067 , trivially .",
    "similarly , @xmath1068 . from lemma [ lem - prob",
    "] it now follows that , @xmath1069 also , from lemma [ lem11 ] and lemma [ lem - prob ] we obtain , @xmath1070 in order to study @xmath1071 , we will re - trace the arguments of lemma [ lem11 ] , with some important modifications .",
    "following , we can write , @xmath1072\\notag\\\\ & \\quad { } + \\sqrt{n}\\cdot(f_n - f)\\cdot\\pr_0 \\big(h_{1,\\bbbn } - h_{1,\\bb_0}\\big)-\\sqrt{n}\\cdot(f_n - f)\\cdot\\left[z_2(\\bbbn ) - z_2(\\bb_0)\\right]\\notag\\\\ & \\equiv h_{1,n } + h_{2,n } + h_{3,n } + h_{4,n}. \\label{brk4}\\end{aligned}\\ ] ] we consider each term in the right side of separately . from lemma [ lem - boot-1](i )",
    "it follows that @xmath1073 in @xmath221-probability .",
    "next , following and write , @xmath1074,\\\\   \\widetilde{h}_{2,n } & = \\sqrt{1-f_n}\\cdot \\sqrt{n_2}\\cdot\\left[\\prnt h_{2,\\bbbn,\\thb_0 } - \\pr_0 h_{2,\\bbbn,\\thb_0 } - \\prnt h_{2,\\bb_0,\\thb_0 } + \\pr_0 h_{2,\\bb_0,\\thb_0}\\right]\\\\   & = \\sqrt{1-f_n}\\cdot \\grnt\\left(h_{2,\\bbbn,\\thb_0}-h_{2,\\bb_0,\\thb_0}\\right ) ,   \\end{aligned}\\ ] ] from lemma [ lem - boot-1](ii ) it follows that @xmath1075 in @xmath221-probability .",
    "also , @xmath1076 from lemma [ lem9 ] and lemma [ lem - prob ] , @xmath1077 also , from lemma [ lem - theta - hat ] and lemma [ lem - prob ] it follows that , @xmath1078 in @xmath221-probability . combining this with theorem [ thm - boot](i ) we obtain , @xmath1079 in @xmath221-probability .",
    "following the approach used in handling the term @xmath1080 in the proof of lemma [ lem11 ] and using the continuous mapping theorem repeatedly , we obtain @xmath1081 in @xmath221-probability .",
    "hence , @xmath1082 in @xmath221-probability , which implies @xmath1083 in @xmath221-probability .",
    "finally , mimicking the arguments used for the third and fourth terms in the proof of lemma [ lem11 ] and applying the continuous mapping theorem for bootstrapped random variables , we obtain @xmath1084 in @xmath221-probability , for @xmath1085 . applying the same arguments to all @xmath5 components of @xmath119 and @xmath120",
    ", we can conclude @xmath1086 in @xmath221-probability ( cf . ) .",
    "now , consider the term @xmath1087 in .",
    "then , @xmath1088\\notag\\\\ & = \\sqrt{f_n}\\cdot \\grnow\\left(h_{1,\\bbbn } - h_{1,\\bb_0}\\right)+\\sqrt{n}\\cdot ( 1-f_n)\\cdot\\left[\\prntw h_{2,\\bbbn,\\thbns } - \\prnt h_{2,\\bbbn,\\thbn } - \\prntw h_{2,\\bb_0,\\thbns } + \\prnt h_{2,\\bb_0,\\thbn}\\right]\\notag\\\\ & \\equiv i_{1,n } + i_{2,n}. \\label{brk6}\\end{aligned}\\ ] ] from lemma [ lem - boot-2](i ) it follows that @xmath1089 in @xmath221-probability .",
    "define the new term , @xmath1090\\notag\\\\ & = \\sqrt{1-f_n}\\cdot \\grntw \\left(h_{2,\\bbbn,\\thbn } - h_{2,\\bb_0,\\thbn}\\right ) .",
    "\\label{i2t}\\end{aligned}\\ ] ] then , after some algebra it can be shown that @xmath1091 consider each term of separately . using lemma [ lem - boot-2 ]",
    "it follows that , @xmath1092 and @xmath1093 in @xmath221-probability .",
    "next , note that @xmath1094 converges to a tight limiting distribution under the product probability measure @xmath222 .",
    "hence , the proof of lemma [ lem9 ] holds in this case , without any changes except that all probability statements are understood in terms of @xmath222 instead of @xmath9 .",
    "we skip the details about verification of the conditions .",
    "hence , @xmath1095 which implies , @xmath1096 in @xmath221-probability . from lemma [ lem9 ] and lemma [ lem - prob ]",
    ", it follows that @xmath1097 in @xmath221-probability .",
    "we can use the arguments used to handle the term @xmath1080 ( cf . ) in lemma [ lem11 ] along with the fact that @xmath1098 and @xmath1099 in @xmath221-probability .",
    "we skip the details .",
    "hence , @xmath1100 in @xmath221-probability . combining all parts in the right side of",
    ", we obtain @xmath1101 in @xmath221-probability . also from , @xmath1102 we already know that @xmath1093 in @xmath221-probability .",
    "the second term can be shown to be @xmath1103 in @xmath221-probability , by exactly following the argument given in the proof of lemma [ lem - boot-1](i ) and by noting that @xmath155 is a donsker class .",
    "hence , @xmath1104 in @xmath221-probability . combining all steps and from we",
    "obtain , @xmath1105 in @xmath221-probability . following the argument separately for all @xmath5 components in the right side of",
    "completes completes the proof .      note that @xmath652 and @xmath1107 .",
    "recall the decomposition obtained in .",
    "then , we can write @xmath1108 where , @xmath1071 and @xmath1087 have been defined earlier in . consider each term in the right side of separately .",
    "following the proof of lemma [ lem - boot - equi ] , it follows that @xmath1071 and @xmath1087 are @xmath1103 in @xmath221-probability . also , @xmath1109 , by definition of @xmath195 ( cf . ) .",
    "finally , after some manipulations it can be shown that @xmath1110 since @xmath154 is a donsker class ( cf .",
    "lemma [ donsk - lem](i ) ) , hence @xmath1111 in @xmath221-probability , by theorem 3.6.1 of @xcite .",
    "a similar argument shows that , @xmath1112 in @xmath221-probability , since @xmath155 is donsker . also , using the delta method , lemma [ lem - theta - boot ] and the methods used in the proof of theorem [ thm1 ] we can claim that @xmath1113 following the proof of theorem [ thm1 ] , @xmath1114 . since @xmath154 and @xmath155 are donsker , hence @xmath1115 and @xmath1116 are @xmath1063 .",
    "the remaining terms in the right side of are @xmath1103 in @xmath221-probability , using lemma s [ lem - boot-1 ] and [ lem - boot-2 ] .",
    "so , @xmath1117 in @xmath221-probability .",
    "therefore , continuing from and applying triangle inequality we obtain , @xmath1118 because a @xmath1103 term is obviously a @xmath1119 term in @xmath221-probability . since @xmath123 is differentiable at @xmath10 and",
    "the derivative is nonsingular ( cf .",
    "assumption ( a5 ) ) , we can write for some @xmath1120 , @xmath1121 this implies @xmath1122 in @xmath221-probability .",
    "the result in lemma [ lemconc ] describes an useful property of the gradient vector of a strictly concave function with domain @xmath137 .",
    "this result has been used in the proof of lemma [ lem3 ] to show the well - separated condition for the unique root of @xmath298 .",
    "lemma [ an - lem ] is a simple result about sequences indexed by two indices and has been used in the proofs of lemma [ lem - boot-1 ] , lemma [ lem - boot-2 ] and theorem [ thm - boot](i ) .",
    "the symbol @xmath1123 is used to denote the euclidean norm in @xmath137 .",
    "+    suppose , @xmath1124 is a strictly concave function which is differentiable at all points and has an unique maxima at some @xmath1125 . denote the gradient of @xmath110 at a point @xmath18 by @xmath1126 .",
    "then , the following strict inequalities hold : @xmath1127 [ lemconc ]      1 .",
    "consider any @xmath1128 ( with @xmath1129 ) and the line passing segment joining @xmath263 and @xmath18 .",
    "any point on the interior of this line segment can be represented as , @xmath1130 , for some @xmath1131 .",
    "since @xmath263 is the unique maxima and @xmath110 is strictly concave on this line segment , we must have @xmath1132 now , for any @xmath232 , define the sets @xmath1133 .",
    "we claim that , @xmath1134 if possible , assume that the claim is false and the strict inequality in fails for some pair of values , @xmath1135 with @xmath1136 . note that @xmath1137 are compact .",
    "then , as @xmath110 is continuous , there exists a point @xmath1138 , such that @xmath1139 , @xmath162 . as per our assumption we have , @xmath1140 .",
    "join the points @xmath263 and @xmath1141 by a line segment which intersects @xmath1142 ( which is the inner circle ) at some interior point ( on the line ) @xmath1143 . by strict concavity of @xmath110 over this line segment",
    ", we have @xmath1144 which contradicts our assumption and as a result holds . for any @xmath232 , @xmath1145 for some @xmath1146 .",
    "now , draw a line segment through the points @xmath263 and @xmath1147 . since @xmath1148 , we can use strict concavity to claim that , @xmath1149 .",
    "this completes the proof of the first statement .",
    "2 .   note that @xmath1150 , where @xmath1151 denotes the @xmath248-th partial derivative of @xmath110 at the point @xmath18 .",
    "also , @xmath1151 is the directional derivative of @xmath110 at the point @xmath18 in the direction of @xmath1152 , where @xmath1152 denotes the @xmath248-th unit vector in @xmath137 .",
    "finally note that , for a strictly concave and differentiable function @xmath110 , @xmath1153 , if and only if @xmath18 is a global maxima of @xmath110 .",
    "+ consider the line segment through @xmath263 in the direction @xmath1154 .",
    "define the function , @xmath1155 , @xmath1156 .",
    "it is easily seen that @xmath1157 is strictly concave and also differentiable ( since @xmath110 is differentiable everywhere ) .",
    "fix any @xmath232 . using the proof of part ( i ) above",
    ", we know there exists a point @xmath1147 on @xmath1158 such that , @xmath1159 note that , @xmath1160 .",
    "hence , @xmath1161 this completes the proof .",
    "we provide detailed expressions of the matrices used in the statement of theorem [ thm1 ] and lemma [ lem8 ] .",
    "note that @xmath85 , @xmath86 and @xmath87 denote expectation , variance and covariance under @xmath9 . in case of the with intercept model , computation of the matrices shown below can be carried out by replacing @xmath1167 with @xmath105 .",
    "define , @xmath1168 , where @xmath1169 is defined in .",
    "note that , @xmath1170 has been found in .",
    "the remaining components of @xmath1171 are , @xmath1172 and @xmath1173 .",
    "it is easy to obtain the following expressions , @xmath1174    next , write @xmath1175 ( cf . ) .",
    "the expression for @xmath1176 is , @xmath1177}^2}{h_{3,\\bb_0,\\thb_0}(\\xb)\\cdot(1-h_{3,\\bb_0,\\thb_0}(\\xb ) ) } ~dq(\\xb),\\quad\\text{for all $ 1\\leq i , j\\leq p$. } \\label{gab - mat - def}\\ ] ] the @xmath456 matrix @xmath1178 is the total derivative map of @xmath858 ( cf .",
    "lemma [ lem8](ii ) ) with respect to @xmath51 . also , @xmath147 is the value of @xmath884 at @xmath455 , and is used in theorem [ thm1](ii ) . to simplify the expression ,",
    "define @xmath1179 then , for all @xmath864 and @xmath865 , elements of @xmath884 can be expressed as , @xmath1180~d\\pr_0\\wyx .",
    "\\label{a0-mat - def-1 }                             \\end{aligned}\\ ] ] in case @xmath455 , @xmath1181 , which implies @xmath1182 .",
    "hence , @xmath1183 . after simplification , the expression for elements of @xmath147 will be , @xmath1184"
  ],
  "abstract_text": [
    "<S> logistic regression is an extensively used regression model for binary responses . in many applications , misclassification of binary responses </S>",
    "<S> is not uncommon . </S>",
    "<S> if the misclassification is ignored , it may severely bias the maximum likelihood estimators ( mle ) of regression parameters towards zero . to obviate this difficulty </S>",
    "<S> , we propose a pseudo - likelihood method of estimation , that uses data from internal validation study . under minimal assumptions , </S>",
    "<S> we establish rigorous asymptotic results for the maximum pseudo - likelihood estimators . </S>",
    "<S> a bootstrapped version of the maximum pseudo likelihood estimators is proposed , and its distributional consistency is proved . </S>",
    "<S> it enables us to use bootstrap method for statistical inference . </S>",
    "<S> the results of the simulation studies clearly indicate the superiority of the maximum pseudo - likelihood estimators to the maximum full likelihood estimators , and the maximum likelihood estimators based on misclassified binary responses only . also , inferences on the regression parameters using asymptotic distribution of maximum pseudo - likelihood estimators , and its bootstrap version , are found to be similar .    _ </S>",
    "<S> keywords : _ binary response , misclassification , pseudo - likelihood , bootstrap consistency . </S>"
  ]
}