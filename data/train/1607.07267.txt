{
  "article_text": [
    "the goal of this paper is to present a framework for multiagent systems that will allow individual agents to strike a balance between global performance and the cost of distributedly computing the globally optimal control action .",
    "this computation cost typically comprises the cost of communication among neighboring nodes . in the proposed framework ,",
    "the focus is on designing energy aware local interaction laws for individual agents that can provide performance guarantees , are implementable in real time , and have limited communication and computation overhead .",
    "the framework is presented in the context of a motivating example in which a collection of relay nodes is deployed to establish a communication link between two base stations for a long period of time .",
    "the task is to find an energy efficient and distributed mobility strategy to move the relay nodes to optimal locations such that the total energy consumption is minimized .",
    "we will formulate this problem as a dynamic program in which the cost to be minimized is the sum of the communication and the mobility costs of all the agents . to ensure that the control policy is distributed , energy efficient , and real time implementable , we will propose multiple suboptimal policies and compare their performance with the global optimal policy based on the techniques of approximate dynamic programming @xcite .",
    "a fundamental challenge in designing an energy aware scheme for multiagent systems is that each agent only has limited information of the system but its actions have direct impact on the global performance ( see @xcite and the references therein ) .",
    "another challenge is to ensure that the proposed scheme is feasible for real - time implementation .",
    "this challenge gets more complicated when the objective is to find an optimal trajectory over a given interval because each agent must account for all the possible future trajectories of its neighbors while computing its current control actions , which makes real time implementation impractical even for simple scenarios .",
    "consequently , the control strategies either become too complex and/or require excessive communication among the agents , resulting in large energy consumption .",
    "therefore , an efficient energy aware coordination strategy must have the capability to strike a balance between the performance requirements of the system and the energy requirements of the control strategies that it implements to achieve this performance .",
    "the importance of introducing energy awareness in multiagent systems like wireless sensor networks is widely recognized ( see @xcite and the references therein ) .",
    "however , when it comes to distributed energy aware mobility strategies , the existing literature is somewhat limited and there are still a lot of unanswered questions . in @xcite ,",
    "a distributed energy aware coverage scheme was proposed but it only considered the tradeoff between sensing and processing and did not assign any cost to mobility . in @xcite , synchronous and asynchronous",
    "distributed algorithms were presented for steering relay nodes to the optimal locations for establishing a communication link between two base stations .",
    "however , no cost was assigned to mobility because of the assumption that either the batteries can be recharged or communication is for long time and mobility cost is negligible in comparison with communication cost . in @xcite ,",
    "a similar problem was considered under a static setting in which agents initially determine and move to their optimal locations and then the communication starts .",
    "the proposed solutions were based on heuristics and no optimality guarantees were provided . in @xcite and @xcite",
    "both mobility and communication costs were considered and the problem was formulated as an optimal control problem in a dynamic setting in which agents move and communicate at the same time . in both the references , only a centralized setup was considered .",
    "references @xcite , and @xcite investigated optimal consensus problems using model predictive control ( mpc ) . in all of these works ,",
    "different approximate solutions were proposed with guaranteed asymptotic convergence to the consensus set , but none of these works analyzed the energy consumption profile of the proposed solutions .    in this work",
    ", we will start by formulating the problem under consideration as an infinite horizon discounted lqr problem . using the principal of optimality",
    ", we will formulate an equivalent one stage lookahead problem with optimal cost to go as terminal cost .",
    "this terminal cost will be a quadratic function of a positive definite matrix @xmath0 such that @xmath1 will indicate that the terminal cost of node @xmath2 depends on node @xmath3 .",
    "we will show that all the entries of @xmath0 are non - zero which implies that the terminal cost of each node depends on the states of all the nodes . for a system with fixed communication network ,",
    "the matrix @xmath0 can be computed offline before the system is deployed .",
    "therefore , the original dynamic program will be reduced to a parameter optimization problem over a network of agents for which distributed optimization algorithms exist that can guarantee global optimial solution ( see e.g. , @xcite and @xcite ) .    in @xcite ,",
    "a dual decomposition based distributed optimization algorithm was presented in which dual variables were introduced to decouple the cost of each agent . however , each agent needs to communicate with all the agents whose state directly influence its cost .",
    "since all the entries of @xmath0 are non - zeros , the communication network will be a complete graph and the problem will become centralized . in @xcite , a consensus based algorithm was presented in which only neighboring nodes of a graph were required to communicate as long as the graph was connected .",
    "however , the size of the message that agents have to communicate with their neighbors directly depends on the number of agents which can be large and can result in significant energy consumption .    _ in the proposed framework , we will impose the constraints of the communication network on the optimal cost to go function and will propose approximate cost to go functions such that the cost of each agent will only depend on itself and its neighboring nodes_. this will significantly reduce the size of the communication message since the number of neighboring nodes is typically small as compared to the total nodes in the network .",
    "the price of approximating the optimal cost to go will be a loss in the global performance .",
    "we will analyze this performance loss and provide upper bounds on the performance gap between the actual and optimal performances .",
    "the remainder of this paper is organized as follows .",
    "section [ sec : prob_description ] motivates the problem under investigation and presents a mathematical formulation .",
    "section [ sec : energy - aware architectures ] presents the proposed schemes along with their performance bounds , which are the main results of this paper .",
    "section [ sec : simulation ] provides performance comparisons of the proposed schemes based on simulations . finally , section [ sec : ] concludes the paper .",
    "we denote a graph by @xmath4 where @xmath5 is the set of vertices and @xmath6v@xmath7 is the set of edges .",
    "graph @xmath8 is undirected if its links are bidirectional ( @xmath9 @xmath10 @xmath11 iff @xmath12 @xmath10 @xmath11 ) . the neighborhood set of node @xmath2 is @xmath13 and the cardinality of this set is @xmath14 .",
    "a graph is connected if given any pair of nodes ( @xmath2,@xmath3 ) , either @xmath15 or there exist some intermediate nodes such that @xmath16 .",
    "the degree matrix of @xmath8 is a diagonal matrix @xmath17 with the diagonal entries @xmath18 .",
    "the adjacency matrix @xmath19 is @xmath20 the graph laplacian , @xmath21 is a symmetric and positive semidefinite matrix with real and non - negative eigenvalues for undirected graphs . moreover , for a connected graph , @xmath22 .",
    "let @xmath23 = [ @xmath24 @xmath25@xmath26 denotes the location of node @xmath2 at time @xmath27 in @xmath28 , where @xmath29{^{\\text{{\\tiny $ t$}}}}$ ] is the transpose of a vector .",
    "for concise notation , the locations of all the nodes at time @xmath27 are stacked in vector @xmath30 , i.e. , @xmath31 = [ @xmath32 @xmath33 @xmath34@xmath26 . for @xmath35",
    ", @xmath36 denotes the vector of locations of all neighbors of @xmath2 , i.e. , @xmath37{^{\\text{{\\tiny $ t$}}}}$ ] where @xmath38 . for @xmath39",
    ", @xmath40 denotes the euclidean norm .    for a matrix @xmath41 of dimensions @xmath42",
    ", @xmath43 is the frobenius norm , i.e. , @xmath44 if @xmath45 and @xmath46 are its @xmath47 eigenvalues in non - increasing order , then @xmath48 which implies that @xmath49 will be used both as a function and as a constant value .",
    "the vector @xmath50 denotes the vector @xmath51{^{\\text{{\\tiny $ t$}}}}\\in { { \\mathbb{r}}}^n$ ] , @xmath52 denotes identity matrix , and @xmath53 denotes a matrix of dimension @xmath54 with all entries equal to 0 .",
    "boldface letters like @xmath31 denote collections of vectors , and their subscript represents time .",
    "let @xmath55 be an @xmath56 matrix .",
    "then the spectrum of @xmath55 is the set of all the eigenvalues of @xmath55 and is denoted as @xmath57 .",
    "the spectral radius of @xmath55 is @xmath58 .    if @xmath59 then @xmath60 is a non - singular @xmath61 matrix and if @xmath62 then @xmath60 is a singular @xmath61 matrix .",
    "an essential property of an @xmath61 matrix is that @xmath63 and @xmath64 for all @xmath2 and @xmath3 .",
    "moreover , the inverse of an @xmath61 matrix is a strictly positive matrix , i.e. , all entries are positive @xcite .    _ gershgorin circle theorem : _ if @xmath55 is an @xmath56 matrix , then every eigenvalue of @xmath55 lies in at least one of the circles @xmath65 where @xmath66 has its center at the diagonal entry @xmath67 and its radius @xmath68 .",
    "+ the gershgorin circle theorem provides upper and lower bounds for the spectrum of a square matrix . for a laplacian matrix @xmath69 , @xmath70 since each diagonal entry is equal to the sum of the absolute values of the off diagonal entries of that row .",
    "consider two base stations @xmath71 and @xmath72 separated by a distance @xmath73 . without loss of generality",
    "we can assume that the base station @xmath71 is located at the origin .",
    "the objective is to establish an uninterrupted communication link between these base stations for a time interval of length @xmath74 with minimum energy consumption . from @xcite ,",
    "the power required to successfully transmit over a distance @xmath73 at maximum data rate is directly proportional to the square of the transmission distance @xmath73 , i.e. , @xmath75 where @xmath76 is a proportionality constant and @xmath77 reflects the additional power consumed by transmitter / receiver circuitry . in this work",
    "we are interested in communication power only , so assume @xmath78 .",
    "the energy required to establish the communication link between the two base stations will be extremely high for large values of @xmath73 and @xmath74 .",
    "one solution is to use @xmath47 relay nodes as shown in fig .",
    "[ fig : pic ] . depending on the value of @xmath47 and the deployment locations of the nodes , the overall energy consumption can be significantly reduced . for minimum energy consumption",
    ", the relay nodes must be evenly spaced on the straight line between the two base stations @xcite .",
    "however , we are interested in a scenario in which the nodes are randomly deployed between the base stations and they need to estimate and move to the optimal deployment locations in a decentralized manner while communicating .",
    "this redeployment towards the optimal locations will have its own cost that must be accounted for .",
    "let @xmath23 denotes the location of relay node @xmath2 at time @xmath27 for @xmath35 , and @xmath79 and @xmath80 denote the locations of the base stations @xmath71 and @xmath72 respectively . because the base stations remain stationary , @xmath79 and @xmath80 are constant values .",
    "this network of the relay nodes and the base stations is represented by a graph @xmath81 in which the vertex set @xmath82 consists of @xmath47 relay nodes @xmath83 and two base stations @xmath84 .",
    "an edge exists between two vertices in @xmath85 if the corresponding nodes can communicate with each other , i.e. , @xmath86 is the set of nodes with which node @xmath2 can communicate .",
    "this communication network can be represented algebraically by graph laplacian @xmath87 where @xmath88    to find the optimal locations of the relay nodes , we assume that the system satisfies the following properties .    _ assumptions : _    1 .",
    "the communication network is a line graph , and it remains fixed , i.e. , @xmath89 and has the following structure : @xmath90 2 .",
    "the relay nodes are mobile nodes with single integrator dynamics @xmath91 where @xmath92 is the input at time @xmath27 .",
    "although the communication link is established initially , the overall energy consumption can be minimized if the relay nodes can somehow move to the optimal locations in an efficient manner .",
    "however , there is no leader or centralized authority that has the knowledge of the optimal locations , so the nodes need to figure it out locally based on communication with their neighbors . to ensure that the overall energy consumption is minimized , it is imperative to incorporate the cost of mobility in the system model because mobility is orders of magnitude more expensive than communication . from @xcite",
    ", mobility power consumption can be approximated to be a function of speed , i.e. , @xmath93 where @xmath94 is the robot s velocity at time @xmath27 .",
    "we assume that mobility cost of a node is proportional to the square of its speed , i.e. , @xmath95 , where @xmath96 is a mobility constant .",
    "this choice of mobility model is valid for mobile nodes that use dc motors and operate at low speeds .",
    "the advantage of this model is that it will help in obtaining an analytical solution to the optimization problem .    in this paper",
    ", we will formulate this problem as a dynamic program and propose suboptimal policies that can be implemented in real time and have low energy overhead .",
    "we will also derive upper bounds on the performance gap between the proposed policies and the global optimal policy and compare their performance through simulations .",
    "the total cost that is to be minimized is the sum of the mobility cost and the communication cost of the system .",
    "we will formulate the problem as an infinite horizon problem with a discount factor @xmath97 .",
    "+   + _ problem_:@xmath98 where @xmath99 @xmath100 in the system dynamics , @xmath101,\\ ] ] where @xmath102 corresponds to the base stations that are stationary .",
    "the cost can be represented compactly in matrix vector notation as follows : @xmath103 here , @xmath104 is a diagonal matrix , and @xmath105 is a symmetric and positive semidefinite matrix of dimensions @xmath106 . with linear dynamics and quadratic cost , @xmath107 is an lqr problem where @xmath108 is the control value of agent @xmath2 located at @xmath23 at time @xmath27 , @xmath109 is the policy of agent @xmath2 at time @xmath27 , and @xmath110{^{\\text{{\\tiny $ t$}}}}$ ] is a policy vector at time @xmath27 .",
    "problem @xmath107 is a standard infinite horizon dynamic program with @xmath111 specific stage cost @xmath112 and terminal cost @xmath113 . typically , dynamic programs suffer from the curse of dimensionality and become computationally intractable even for small size problems .",
    "however , @xmath107 is an lqr problem with closed form analytical solution that involves solving the following difference riccati equation iteratively : @xmath114 where @xmath115 is symmetric and positive semidefinite for all @xmath27 . the optimal cost to go at stage @xmath27",
    "is @xmath116 the advantage of formulating @xmath107 as an infinite horizon problem is that @xmath117 as @xmath118 : @xmath119 where @xmath0 is a symmetric and positive definite matrix . because of the stationarity of @xmath0 , the optimal cost is also stationary , i.e. , @xmath120 as @xmath121 , where @xmath122    using the principal of optimality , @xmath107 can be formulated as a one stage lookahead problem with stationary optimal cost to go as its terminal cost , i.e. , @xmath123\\ ] ] subject to the dynamics and constraints in [ eq : problem_infinite ] .",
    "the optimal stationary policy @xmath124 has the form @xmath125 the optimal policy is a simple static feedback law that can be implemented easily under normal circumstances .",
    "however , we will show that the optimal policy is centralized which is an intuitive result and makes this problem challenging since the optimal solution requires complete knowledge of the network and can not be decentralized .",
    "next we will show that @xmath0 is a non - singular @xmath61-matrix and all of its entries are non - zero , which means each agent requires state information of all the other agents to compute the optimal cost to go .",
    "[ prop : k_matrix ] _ if @xmath126 is a symmetric @xmath61 matrix _ , @xmath127 $ ] , and @xmath104 ,",
    "_ then the positive definite solution of the riccati equation _",
    "@xmath128 _ is also an @xmath61 matrix .",
    "moreover , if @xmath129 is a laplacian matrix of a connected graph then all the entries of @xmath0 are non - zero .",
    "_    the proof is presented in the appendix .",
    "problems having structure similar to @xmath107 have been studied in the context of optimal consensus problems for general lti systems ( see for example @xcite , and @xcite ) . in all of these references ,",
    "consensus problem was formulated as an infinite horizon lqr problem with the objective of minimizing disagreement among the agents with minimum control effort . in @xcite",
    "it was shown that the optimal solution to this problem is centralized .",
    "since the problem could not be solved in a decentralized manner , approximations were introduced to decouple the cost along the entire trajectory . in @xcite and @xcite each agent assumed that all of its neighbors remain stationary for all the future time .",
    "based on this assumption , optimal control trajectories were computed and implemented for one time step , a standard approach in mpc , and the process was repeated . in @xcite ,",
    "the same stationarity assumption was used but the update rule was considered to be sequential , i.e. , at each time only one agent was allowed to compute its optimal trajectory . in @xcite , each agent transmitted its assumed trajectory to all of its neighbors . at the same time it received such trajectories from its neighbors .",
    "then , each agent used these assumed trajectories of its neighbors to solve its optimization problem and computed its actual trajectory . for stability , the actual trajectory and the assumed trajectory of each agent should be close .",
    "although @xmath107 has the same cost as the references mentioned , the goal is significantly different .",
    "the schemes in the references are primarily designed for achieving a certain steady state performance ( consensus ) . to ensure that the trajectories computed by agents are feasible , and converge to the consensus set , these schemes rely on extensive communication among neighboring agents .",
    "in fact , some schemes require communication of entire trajectories among the neighboring agents repeatedly at each decision time step ( @xcite and @xcite ) .",
    "this communication results in considerable energy overhead that is typically not taken into account .",
    "_ our focus is on developing a framework for minimizing this communication overhead and ensuring that the scheme is distributed and real time implementable .",
    "_ the price of reducing inter - agent communication will be in terms of global performance .",
    "therefore , we will analyze the effects on system performance and provide upper bounds on the performance gap between the proposed and optimal policies .",
    "furthermore , the proposed framework is not limited to a particular problem .",
    "instead , it is intended to provide energy aware local coordination algorithms that can provide performance guarantees for a class of multiagent systems with fixed communication network .",
    "based on the above discussion , it is inefficient in terms of communication energy overhead to solve problem @xmath107 in its original form .",
    "another formulation of this problem is presented in eq .",
    "( [ eq : onestepoptimal ] ) in which the problem is reduced to one step lookahead with optimal cost to go as the terminal cost .",
    "the optimal cost to go is a quadratic function of @xmath0 , the positive definite solution of the riccati equation ( [ eq : riccati_infinite ] ) , which is a function of communication network @xmath69 , system dynamics @xmath130 , and communication and mobility constants @xmath131 and @xmath96 respectively . from assumption ( 1 ) , @xmath69 is fixed , so @xmath0 can be computed offline before the nodes are deployed . from prop",
    "[ prop : k_matrix ] , all the entries of @xmath0 are non - zero .",
    "therefore , the cost in eq .",
    "( [ eq : onestepoptimal ] ) has a local component and global component .",
    "each node can compute its stage cost @xmath132 using the current information of its neighbors only .",
    "however , the terminal cost requires information of all the nodes in the network .    since both the stage and the terminal costs are convex , the distributed optimization algorithm presented in @xcite can guarantee global optimal solution by allowing communication among neighboring nodes only .",
    "the algorithm is a consensus based distributed optimization algorithm to minimize the following cost @xmath133 where @xmath134 is the decision vector , @xmath135 is the local cost of agent @xmath2 , and each agent can only communicate with its neighbors . to solve this problem ,",
    "each agent maintains an estimate of the entire decision vector .",
    "it communicates its estimate with its neighbors , receives their estimates , and updates its estimate of the decision vector by combining the information it received form its neighbors . for computing action at time @xmath27",
    ", the above process is repeated for a specified number of iterations which impacts the quality of the solution .",
    "if the size of the decision vector is small , the communication overhead of the algorithm can be tolerated .",
    "however , in multiagent systems , the size of the decision vector typically depends directly on the number of nodes @xmath47 and can be very large . consequently , the size of the data packet can get large which will result in significant energy overhead . in the proposed framework , we approximate the global component of the cost ( terminal cost ) with a function that is close to the original function in some sense and is locally computable .",
    "this implies that the size of the data packet for each node will depend on the cardinality of its neighborhood set . typically ,",
    "multiagent systems are sparsely connected , i.e. , @xmath136 , so the size of the data packet is significantly reduced . _",
    "the main idea proposed in this work for designing suboptimal policies for each node @xmath137 is to impose the communication network constraints of node @xmath2 on the global optimal cost matrix @xmath0 .",
    "_ the resulting matrix @xmath138 will observe the constraints of the communication network , i.e. , @xmath139 if @xmath140 , and will be used to design approximate cost to go for the lqr problem .",
    "the suboptimal policy for each node is to solve one step lookahead problem with this approximate cost to go as the terminal cost using some efficient distributed optimization algorithm .",
    "this procedure for designing suboptimal policies will guarantee that the terminal cost can be computed locally and will simplify performance comparison with the global optimal .",
    "in this section we propose three energy aware policies ( eap)s .",
    "the first two policies are distributed in nature and the last one is decentralized .",
    "a policy @xmath141 is distributed if the control action of each agent at time @xmath27 is a function of its current state and the current state and input of its neighbors , i.e. , @xmath142 depends on @xmath23 , @xmath36 and @xmath143 .",
    "a policy @xmath141 is decentralized if the control action of each agent is a function of its current state and the current states of its neighbors , i.e. , @xmath142 depends on @xmath23 , @xmath36 .    in a distributed policy",
    ", node @xmath2 will have to repeatedly communicate with its neighbors to know their current inputs .",
    "however , the current state of the neighbors in a decentralized policy can either be sensed if the nodes are equipped with the required sensors , or it can be communicated by one time communication .",
    "next we propose two distributed energy aware policies eaps i & ii . in eap i , we formulate a semidefinite program to find a matrix that is closest to @xmath0 in terms of frobenius norm and satisfies the desired sparsity structure .    _ energy aware policy i _    compute the positive definite matrix @xmath0 offline that satisfies riccati equation ( [ eq : riccati_infinite ] ) . solve the following semidefinite program to find the projection of @xmath0 on the sparsity structure of @xmath144 .",
    "@xmath145 the proposed approximate cost to go function is @xmath146 and each node solves the following one stage optimization problem to compute its stationary suboptimal policy : @xmath147 with dynamics and constraints specified in [ eq : problem_infinite ] .",
    "_ let @xmath148 be defined as _",
    "@xmath149 _ then _ @xmath150 , _",
    "i.e. , the projection of @xmath0 on @xmath151 can be computed by simply replacing the entries of @xmath0 corresponding to non - neighboring agents with zeros . _",
    "firstly , @xmath148 satisfies the desired sparsity constraints by construction .",
    "secondly , @xmath148 is symmetric because @xmath0 and @xmath151 are both symmetric . to show that @xmath148 is positive definite , we use the fact that @xmath0 is an @xmath61 matrix , i.e.",
    ", all the diagonal entries are positive and the off - diagonal entries are non - positive , and @xmath152 since @xmath153 .",
    "therefore , all the gershgorin circles of @xmath148 lie in the positive half plane , and so all of its eigenvalues are positive .",
    "thus , @xmath154 satisfies all the constraints . to prove that @xmath148 is optimal",
    ", we use the definition of frobenius norm . @xmath155 for @xmath9 pair such that @xmath156 , the value of @xmath157 is fixed by the constraint . for @xmath9 such that @xmath158 , any value for @xmath159 other than @xmath160 will result in a positive contribution in the error term , so @xmath161 is optimal , which concludes the proof .",
    "therefore , we can decompose the matrix @xmath0 into a sum of two matrices @xmath162 where @xmath163    [ prop : eapi_dist ] _ eap i with approximate cost to go _",
    "@xmath164 _ is a distributed policy , i.e. , @xmath165 depends on @xmath23 , @xmath36 , and @xmath166 _    the stage cost @xmath167 can be expanded into @xmath168 from the definition of @xmath157 and using the fact that matrix @xmath0 is a positive definite @xmath61 matrix , ( [ eq : policy1 ] ) can be written as @xmath169 in the above equation , the second summation appears because the terms corresponding to non - neighboring nodes of @xmath2 are set equal to zero in the definition of @xmath157 . from eqs .",
    "( [ eq : stagecost_agent ] ) and ( [ eq : costtogo_agent ] ) , it is straightforward that when solving ( [ eq : policy_iteraton1 ] ) , each node will effectively be solving @xmath170 where @xmath171 . to solve the above problem , node @xmath2 only requires its local information , i.e. , its own states and the states and inputs of its neighbors .    to solve ( [ eq : policy1_agent ] )",
    ", node @xmath2 needs to know @xmath143 as @xmath172 depends on it .",
    "this can be accomplished by implementing an efficient distributed optimization algorithm that can ensure that each node finally has an accurate estimate of the control inputs , @xmath143 , that its neighbors will implement .",
    "the algorithm that we used for simulation in the next section is a distributed subgradient algorithm that was presented in @xcite . in this algorithm ,",
    "each node maintains an estimate @xmath173 of the optimization variables that it needs to compute its cost . for our problem , at time @xmath27 ,",
    "@xmath174 is node @xmath2 s estimate of @xmath175 and @xmath143 .",
    "in particular , if @xmath176 , then @xmath177 $ ] where @xmath178 is node @xmath2 s estimate of @xmath179 for @xmath180 and the vector @xmath181 $ ] . the main idea is the use of consensus to ensure that the estimates of the neighboring nodes converge to same values . to compute @xmath175 and @xmath143",
    ", node @xmath2 performs the following steps :    _ distributed projected subgradient algorithm @xcite _    0 : :    at iteration 0 , node @xmath2 initializes its estimate vector    @xmath173 with some random values . 1 : :    at iteration @xmath182 ,",
    "node @xmath2 updates its    estimate for all @xmath180 as    follows : @xmath183 @xmath184 2 : :    repeat while @xmath185 . 3 : :    @xmath186 .    in this algorithm , ",
    "iter \" is the total number of iterations of the algorithm , and @xmath187 is the step size of the descent . in eq .",
    "( [ eq : estupdate ] ) , @xmath188 is the gradient of the cost function of node @xmath2 evaluated at @xmath189 . to update its estimate",
    ", @xmath190 , node @xmath2 first combines the estimates from its neighbors , which is the consensus step in eq .",
    "( [ eq : estupdate ] ) .",
    "then it computes the gradient of its cost at @xmath189 and updates it estimate by moving the consensus value towards the negative of the gradient .    to compute its cost to go ,",
    "each node exchanges its estimates of control values with its neighbors  iter \" times for all @xmath27 .",
    "although the proposed scheme has communication overhead , it is small since each node is only communicating its estimates of the current control values of itself and its neighbors . in some of the existing schemes for similar problems ,",
    "nodes communicate their entire control and state trajectories with their neighbors which result in huge communication overhead depending on the horizon length and number of nodes in the network ( @xcite and @xcite ) .    in eap",
    "i , we simply imposed the sparsity structure of the communication network on the optimal cost to go matrix @xmath0 . the resulting approximate terminal cost in eq .",
    "( [ eq : costtogo_agent ] ) had one summation that consisted of the square of the distances of nodes @xmath2 and @xmath3 , such that @xmath15 , weighted with @xmath191 . those were the desired terms because the objective in problem @xmath107 is to minimize the distances between the neighboring nodes . however , eq . ( [ eq : costtogo_agent ] )",
    "had a second summation which was @xmath192 one way to interpret the above term is that each node is trying to minimize its distance from the origin .",
    "since base station @xmath71 is assumed to be located at the origin , minimizing distance from the origin can be modeled by adding an edge between each node @xmath2 and @xmath71 .",
    "therefore , the approximate terminal cost in eap i is with respect to a new graph @xmath193 where @xmath194 where @xmath195 and @xmath196 is the index of @xmath71 .",
    "this remodeling of the structure of the system can have serious consequences that are evident in system simulation in section [ sec : simulation ] fig .",
    "[ fig : trajectories ] . figures [ subfig : traj_optimal ] and [ subfig : traj_eapi ] are the trajectories of relay nodes under the optimal policy and eap i respectively . by comparing these trajectories , it is obvious that under eap i , the trajectories of the nodes are biased towards the origin , which results in significant increase in the total cost of the system .",
    "next we propose eap ii , which introduces a refined projection of the optimal cost that removes the undesired terms from the resulting approximate cost to go .",
    "the refined projection will improve performance as will be shown in section [ sec : simulation ] via simulations .",
    "+ _ energy aware policy ii _ + compute the positive definite matrix @xmath0 offline that satisfies riccati equation ( [ eq : riccati_infinite ] ) . decompose the matrix @xmath0 into sum of two matrices .",
    "@xmath197 such that @xmath198 and @xmath199 the proposed approximate cost to go function at time @xmath27 is @xmath200 where @xmath201 is a refined projection of @xmath0 on the sparsity structure of @xmath151 .",
    "each agent solves the following one stage optimization problem to compute its stationary suboptimal policy : @xmath202 with dynamics and constraints specified in [ eq : problem_infinite ] .",
    "[ prop : eapii_dist ] _ eap ii with approximate cost to go function at time @xmath27 _ @xmath203 _ is a distributed policy , i.e. , @xmath204 depends on @xmath23 , @xmath205 , and @xmath206 . _",
    "using the same argument as in prop .",
    "[ prop : eapi_dist ] , stage cost @xmath207 is decentralized . for cost to go , using the definition of @xmath201 and the fact that matrix @xmath0 is a positive definite @xmath61 matrix , eq .",
    "( [ eq : policy2 ] ) can be written as @xmath208 in the above equation , the second summation consisting of the undesirable terms in eq .",
    "( [ eq : costtogo_agent ] ) does not appear anymore because of the correction introduced in the definition of the refined projection matrix .",
    "it is obvious from the above arguments that when solving ( [ eq : policy_iteration2 ] ) , each agent will effectively be solving @xmath209 to solve the above problem , node @xmath2 only requires its own information and the information of its neighbors .",
    "each node can compute its control action @xmath210 by implementing the same distributed optimization algorithm presented for eap i.      next we analyze the performance of the policies presented in the previous section .",
    "however , the analysis carried out in this section is for a more general system in which there are @xmath182 base stations , and @xmath47 mobile nodes have to establish communication links between these base stations .",
    "furthermore , we analyze system performance for an entire class of suboptimal policies . to summarize , we are interested in the analysis of the following one step look - ahead optimization problem : @xmath211 where @xmath212 is defined in eq .",
    "( [ eq : cost_stage_terminal ] ) . here , @xmath213 is an approximate cost to go , @xmath214 is any symmetric positive semi - definite matrix that satisfies the constraints of communication network , and @xmath215 .",
    "$ ] since the problem is a one stage lqr problem , the optimal policy is @xmath216 , @xmath217 and the optimal cost for the approximate problem with one step look ahead is @xmath218 @xmath219 we start the analysis by proving that the optimal policy @xmath220 results in stabilizing system dynamics . for analysis purposes , we use the following matrix partitioning @xmath221,\\ ] ] where @xmath222 , @xmath223 , @xmath224 , @xmath225 , and @xmath226",
    ". if @xmath227 is symmetric then @xmath228 .",
    "[ prop : stability ] _ let @xmath214 be a symmetric and positive semidefinite matrix , and let _ @xmath229 _ then the system dynamics _",
    "@xmath230 _ are marginally stable , where @xmath231 is defined in eq .",
    "( [ eq : l_hat ] ) .",
    "_    let @xmath232 and @xmath233 be the @xmath234 eigenvalue of @xmath235 such that @xmath236 . to prove that the system is marginally stable , we need to show that @xmath237 for all @xmath238 and @xmath239 has @xmath240 independent eigenvectors . by partitioning @xmath214 as in eq .",
    "( [ eq : partitionmatrix ] ) , @xmath241 .",
    "thus , @xmath242.\\ ] ] using the properties of block matrices , the eigenvalues of @xmath243 are the eigenvalues of @xmath244 and @xmath245 .",
    "therefore , @xmath245 contributes @xmath246 zero eigenvalues and @xmath247 contributes @xmath248 eigenvalues .",
    "next we will show that these @xmath248 eigenvalues are real , positive and less then one .",
    "since @xmath214 is symmetric and positive semidefinite , @xmath249 is also symmetric and positive semidefinite .",
    "therefore , @xmath250 has real and non - negative eigenvalues and @xmath248 independent eigenvectors . to show that the eigenvalues are also less then one ,",
    "let @xmath251 be the @xmath234 eigenvalue of @xmath250 .",
    "then @xmath252 and @xmath253are the corresponding eigenvalues of @xmath254 and @xmath255 respectively .",
    "here we have used the fact that if two matrices @xmath256 and @xmath129 have the same set of eigenvectors , then they commute and @xmath257 . therefore , the eigenvalues of @xmath258 are always less than or equal to one for @xmath259 .",
    "this ensures that the eigenvalues of @xmath260 are also less than or equal to one .",
    "since the last @xmath246 rows of @xmath243 are zero , @xmath261 and there will be @xmath246 more independent eigenvectors .",
    "this implies that the eigenvalues of @xmath262 are always less then or equal to one with independent eigenvectors , which concludes the proof .",
    "we can now analyze the stability properties of the proposed policies based on lem . [",
    "prop : stability ] .",
    "since @xmath157 is positive definite and @xmath201 is positive semidefinite , the dynamics for eap i & ii are stable .",
    "an important consequence of lem . [ prop : stability ] is that given the initial locations of the mobile relay nodes , the state space of the system is bounded since the dynamics are stable .",
    "therefore , the performance analysis of the system can be restricted to a bounded set @xmath263 that is invariant under the system dynamics .",
    "we say that a set @xmath263 is invariant under policy @xmath141 if @xmath264 implies that @xmath265 .",
    "we define the max norm of a function @xmath266 over a set @xmath263 by @xmath267 for error analysis we use two mappings from @xcite .",
    "let @xmath268 be an invariant set under policy @xmath269 , i.e. , if @xmath270 then @xmath271 where @xmath272 .",
    "let @xmath273 be the minimum set such that @xmath274 and @xmath270 implies that @xmath275 . for any function @xmath276 , the mappings @xmath74 and @xmath277 are such that @xmath278 and @xmath279 and are defined as @xmath280 let @xmath281 and @xmath282 be the composition of the mappings @xmath74 and @xmath277 with themselves @xmath27 times respectively , i.e. , @xmath283 for a stationary policy @xmath284 , the associated cost to go function @xmath285 satisfies @xmath286 .",
    "it has been proved in @xcite that the optimal cost to go @xmath287 satisfies bellman equation @xmath288 .",
    "similarly , for a stable policy @xmath269 , @xmath289 a mapping @xmath74 is a contraction mapping if there exists a scalar @xmath290 such that @xmath291 the monotonicity lemma ( lem . 2.1 in @xcite ) states that for any two functions @xmath266 and @xmath292 defined on @xmath273 such that @xmath293 the following inequalities hold : @xmath294 finally , for the sets @xmath268 and @xmath273 as defined above , @xmath295 to show this , the first step is to recognize that @xmath269 is the greedy policy with terminal cost @xmath296 , so @xmath297 let @xmath298 . then @xmath299 the second set of inequalities hold because @xmath300 . for @xmath301\\\\ & = ( t \\tilde{j})({\\bf z } )",
    "- \\alpha c.\\end{aligned}\\ ] ] similarly @xmath302 .",
    "using the monotonicity property of @xmath74 , @xmath303 which implies that @xmath304    next we analyze the performance of any approximate policy by comparing it with the global optimal policy .",
    "we will derive bound for maximum error between the optimal and a suboptimal policy .",
    "[ prop : errori ]    _ let @xmath214 be a symmetric and positive semidefinite matrix such that _ @xmath305 _ is the approximate cost to go in ( [ eq : approxprob ] ) .",
    "let @xmath306 and @xmath307 .",
    "then the maximum error between the global optimal solution and the approximate solution is _",
    "@xmath308    the proof of this theorem is based on the properties of the mappings defined in eq .",
    "( [ eq : map_t_tmu ] ) . @xmath309 which concludes the proof . here",
    "we have used the fact the both @xmath74 and @xmath277 are contractions and the result proved in eq .",
    "( [ eq : tmu - t ] ) .    one important advantage of using eaps i @xmath310 ii is that they simplify the computation of these error bounds . for any general suboptimal cost @xmath311",
    ", it is not straightforward to compute @xmath312 .",
    "however for both eaps i @xmath310 ii , their corresponding values of @xmath312 can easily be computed as follows : @xmath313 in fact , we can derive tight upper bounds for both @xmath314 and @xmath315 .",
    "let @xmath316 then from gershgorin circle theorem , @xmath317 here @xmath318 is the sum of the weights assigned to the links between node @xmath2 and its non - neighboring nodes in the global optimal cost to go .",
    "eaps i @xmath310 ii are distributed because each node is able to compute its control action by communicating with its neighbors only .",
    "the communication overhead is small especially in the context of this problem setup in which each agent has at most two neighbors .",
    "however , in networks with dense deployment of nodes , even this communication can cause significant energy consumption , and can result in channel congestion if all the nodes transmit simultaneously . to prevent congestion , nodes need to come up with some scheduling scheme",
    ". however , any scheduling scheme will have its own cost and will introduce latency in the system .",
    "therefore , it is desirable to have a coordination policy that requires no inter - agent communication and can still provide some performance guarantees .",
    "we call such a policy a decentralized policy",
    ". inter - agent communication can be avoided if the nodes are equipped with sensors that can sense the required information of the neighbors . in the absence of such sensors ,",
    "a decentralized coordination policy should only require a node to communicate with its neighbors once to get their current state information .",
    "next we propose a simple decentralized scheme that satisfies these requirements and can be implemented efficiently .",
    "+ _ energy aware policy iii _ + in eap iii , at time @xmath27 , node @xmath2 assumes that @xmath319 for all @xmath320 and @xmath321 for all @xmath322 where @xmath323 .",
    "therefore , the total cost of the system is @xmath324 , where @xmath325 since the cost is convex , the optimal control @xmath175 can easily be computed via first order necessary condition , i.e. , @xmath326 , which yields @xmath327 this means that each agent will have consensus dynamics .",
    "the standard form of the problem under eap iii is @xmath328 the stage and the terminal costs are @xmath329 @xmath330 , @xmath331 , and @xmath332 . here",
    "@xmath333 , @xmath334 is an @xmath335 diagonal matrix with @xmath336 for @xmath137 , and the constant @xmath337 is @xmath338 the resulting optimal policy in vector form is @xmath339 in the above expression , @xmath340 .",
    "we can also express @xmath341 as @xmath342 where @xmath343 is a diagonal matrix with entries @xmath344 for all @xmath137 .    _ eap iii results in a marginally stable system dynamics _    to show that the system dynamics are stable , we need to show that the eigenvalues of @xmath345 lie within the unit circle and its eigenvectors are independent . using the matrix partitioning in eq .",
    "( [ eq : partitionmatrix ] ) , the matrix @xmath346 can be partitioned into @xmath347 $ ] and @xmath348.\\ ] ] from the properties of block matrices , @xmath345 has @xmath246 eigenvalues equal to one and the remaining @xmath248 eigenvalues are the eigenvalues of @xmath349 .",
    "the gershgorin circles of @xmath350 are the same as those of @xmath351 repeated twice . for @xmath137 , @xmath352",
    "this implies that @xmath353 and @xmath354 for all @xmath2 .",
    "thus , all the eigenvalues of @xmath345 lie within the unit circle . to show that all the eigenvectors are independent",
    ", @xmath355 is a laplacian matrix of an undirected graph , i.e. , it is symmetric and positive semidefinite and all of its @xmath248 eigenvectors are orthogonal .",
    "the remaining @xmath246 eigenvectors are those of @xmath356 , which are independent as well .",
    "[ prop : erroriii ] _ let the approximate cost to go _",
    "@xmath357 _ be as defined in eq .",
    "( [ eq : approxcostiii ] ) .",
    "@xmath358 _ and _ @xmath359 .",
    "_ then the maximum error between the global optimal solution and the approximate solution is _",
    "@xmath360    the proof of this proposition consists of the same steps and reasoning as the proof of thm . [ prop : errori ] .",
    "in this section , we present the simulation results of the system under the proposed policies to verify their stability properties and to compare their performance with each other and with the global optimal policy .",
    "the details of the simulated system are as follows .",
    "the two base stations are separated by a distance @xmath361 and are located at @xmath362{^{\\text{{\\tiny $ t$}}}}$ ] and @xmath363{^{\\text{{\\tiny $ t$}}}}$ ] .",
    "the number of relay nodes is @xmath364 and their initial deployment locations are @xmath365{^{\\text{{\\tiny $ t$}}}}$ ] , where @xmath366{^{\\text{{\\tiny $ t$}}}}$ ] and @xmath367{^{\\text{{\\tiny $ t$}}}}$ ] .",
    "the last two entries in @xmath368 and @xmath369 are the locations of the base stations .",
    "the values of the length of the communication interval , communication constant , mobility constant , and the discount factor are @xmath370 , @xmath371 , @xmath372 , and @xmath373 respectively .",
    "for eaps i @xmath310 ii , the distributed optimization algorithm presented in section [ sec : energy - aware architectures ] was implemented with number of iterations @xmath374 and a fixed step size @xmath375 .",
    "the simulation results are presented in figs .",
    "[ fig : sim ] and [ fig : trajectories ] . in fig .",
    "[ fig : sim ] , a comparison of the costs incurred by the system under the optimal and the proposed policies is presented by plotting @xmath376 for @xmath124 , @xmath377 , @xmath378 , and @xmath379 for all @xmath380 .",
    "let the total cost incurred by the system over the interval @xmath381 $ ] under policy @xmath141 be @xmath382 .",
    "then for the simulated system @xmath383 , @xmath384 , @xmath385 , and @xmath386 . based on this comparison for this particular system , the performance of eaps ii and iii is close to each other and their difference from the optimal policy is small relative to eap i. in fig .",
    "[ fig : trajectories ] , the trajectories of the relay nodes under the optimal and the proposed policies are presented .",
    "this figure provides a good insight into the performance of the proposed policies particularly eap i. as mentioned in sec .",
    "[ sec : energy - aware architectures ] , the approximate cost to go of eap i assumes additional edges between each relay node and the origin .",
    "consequently , the trajectories of all the relay nodes are biased towards the origin as compared to their optimal locations .",
    "this bias towards the origin plays a fundamental role in the poor performance of eap i. a couple of interesting observations can be made by comparing figs .",
    "[ subfig : traj_eapii ] and [ subfig : traj_eapiii ] with [ subfig : traj_optimal ] . although the final locations of the relay nodes under eap ii are closer to the optimal terminal locations as compared to the final locations under eap iii , yet the total cost under eap iii is smaller as compared to eap ii .",
    "this observation reinforces the motivation of this work that reaching the same terminal set as the optimal solution under distributed setting may result in more energy consumption .",
    "another interesting observation is that the relay nodes three and four first move away from their final locations and then reverse their directions .",
    "this behavior is justified because the nodes are minimizing the mobility and communication simultaneously .",
    "we proposed an energy aware architecture for multiagent systems that can strike a balance between the global performance of the system and the cost of achieving that performance in terms of communication energy .",
    "the proposed architecture is to formulate an infinite horizon lqr problem as an equivalent one step lookahead problem with optimal cost to go as terminal cost that can be computed offline before the deployment of the system .",
    "it was shown that to compute this cost , each agent either had to communicate with all the agents in the network or communicate extensively with its immediate neighbors to compute the optimal control action , which resulted in excessive communication overhead .    _ to reduce this communication overhead , the main idea behind eaps i @xmath310 ii was to impose the constraints of the communication network on the global optimal cost to go and use the constrained function as an approximate cost to go_. this allowed each node to compute its control action by solving a simple parameter optimization problem using any distributed optimization algorithm .",
    "each node only had to exchange its current estimates of its control values and the control values of its neighbors , with its neighbors instead of exchanging estimates of all the agents as required by the globally optimal solution .    in eap iii",
    ", each node computed its control action with the assumption that all of its neighbors remain stationary .",
    "this simplifying assumption decoupled the cost of each node along the entire trajectory and allowed nodes to compute their suboptimal control action efficiently .",
    "the only information required by a node in eap iii is the current state value of its neighbors which can be either sensed if the required sensors are available or communicated .",
    "we analyzed the performance of the proposed schemes and computed upper bounds for the performance gap between the optimal policy and the proposed policies .",
    "we also compared the performance of the proposed schemes through simulations , which showed that eap iii performed the best for the simulated system .",
    "this setup provides a solid framework for energy aware algorithms for multiagent systems with focus on designing local interactions laws for individual nodes that are efficient in terms of energy consumption , can be implemented in real time on nodes that have limited energy and computation resources , and can provide minimum performance guarantees .    [",
    "sec : appendix ] _ proposition 1 : _ _ if @xmath126 is a symmetric @xmath61 matrix _ , @xmath127 $ ] and @xmath104 ,",
    "_ then the positive definite solution of the riccati equation _",
    "@xmath387 _ is also an @xmath61 matrix .",
    "moreover , if @xmath129 is a laplacian matrix of a connected graph then all the entries of @xmath0 are non - zero . _ +",
    "if @xmath130 = @xmath388 and @xmath389 , then this result has been proved in theorem 5.1 of @xcite .",
    "we will extend this result for @xmath130 and @xmath390 as defined above .",
    "we start the proof by representing the matrices @xmath129 and @xmath0 as block matrices following the convention introduced in ( [ eq : partitionmatrix ] ) : + @xmath391 $ ] and @xmath392 , $ ] + then , @xmath393 the last equality is based on matrix decomposition , @xmath394 and @xmath395 and multiplying both sides by @xmath396 . because @xmath104 , it commutes with any square matrix . using matrix inversion lemma @xmath397 from eq .",
    "( [ eq : rinkf ] ) , @xmath398 . using this equality in the above equation",
    "yields the following quadratic equation .",
    "@xmath399 after performing a series of simple algebraic manipulations @xmath400 where @xmath401 .",
    "since @xmath402 is a symmetric positive semidefinite @xmath61 matrix , @xmath8 is a positive definite @xmath61 matrix and @xmath403 is also a positive definite @xmath61 matrix @xcite , and all of its entries are non - zero @xcite . using _",
    "lemma 5.5 _ of @xcite , @xmath404 is an @xmath61 matrix with negative off - diagonal entries .",
    "now , @xmath405 is a positive definite matrix , so its principal submatrix @xmath406 is also positive definite .",
    "thus , all the diagonal entries of @xmath406 are positive proving that @xmath407 is a positive definite @xmath61 matrix",
    ".    next we will show that all the entries of @xmath408 are negative . using the definition of @xmath130 , @xmath409^{-1}q_{fl } \\\\",
    "& = ( 1-\\alpha)\\left(si - d\\right)^{-1}q_{fl}\\end{aligned}\\ ] ] where @xmath410 and @xmath411 . because @xmath412 is an @xmath61 matrix",
    ", @xmath343 is a positive matrix .",
    "furthermore , @xmath413 , which implies that @xmath59 and @xmath414 is a positive matrix .",
    "since @xmath415 has all the entries non - positive , @xmath408 has all the entries strictly negative unless an entire column of @xmath415 is zero which is not possible for a connected graph .",
    "finally , to show that @xmath416 , @xmath417 since @xmath418 is a positive matrix and all the entries of @xmath408 are negative , @xmath419 is a positive matrix . by definition @xmath420",
    "has positive diagonal entries and non - positive off - diagonal entries . to satisfy the above equation",
    ", @xmath416 must have positive diagonal entries and negative off - diagonal entries .",
    "this concludes the proof .",
    "d. p. bertsekas and j. n. tsitsiklis , _ neuro - dynamic programming _ , athena scientific , 1996 . j. r. marden and j. s. shamma ,  game theory and distributed control , \" in _ handbook of game theory _ , ( h. p.",
    "young and s. zamir , eds . ) , vol .",
    "4 , elsevier science , 2014 .",
    "g. anastasi , m. conti , m. francesco , and a. passarella , `` energy conservation in wireless sensor networks : a survey , '' in _ ad hoc networks _",
    ", vol . 7 , no .",
    "3 , pp . 537568 , 2009 .",
    "f. el - moukaddem , e. torng , g. xing , and s. kulkarni , `` mobile relay configuration in data - intensive wireless sensor networks , '' in _ ieee transactions on mobile computing , _ vol .",
    "261 - 273 , feb . 2013 .",
    "g. ferrari - trecate , l. galbusera , m. p. e. marciandi , and r. scattolini , `` model predictive control schemes for consensus in multi - agent systems with single and double integrator dynamics , '' in _ ieee trans .",
    "25602572 , nov .",
    "m. a. m@xmath421ller , m. reble , and f. allg@xmath422wer , `` cooperative control of dynamically decoupled systems via distributed model predictive control , '' in _ int .",
    "j. of robust . &",
    "nonlinear control _",
    "22 , pp . 13761397 , 2012 .",
    "c. r. johnson , `` inverse m - matrices , '' in _ linear algebra appl .",
    "47 , pp . 195216 , 1982 . y. mei , y - h .",
    "lu , y. c. hu , and c.s",
    ". g. lee , `` a case study of mobile robot s energy consumption and conservation techniques , '' in _ proc .",
    "12@xmath423 ieee icar _ , pp . 492497 , 2005 .",
    "y. cao and w. ren , `` optimal linear consensus algorithms : an lqr perspective , '' in _ ieee trans .",
    "system , man , cybernetics _",
    "3 , pp . 819830 , mar .",
    "t. keviczky , f. borrelli , and g. j. balas ,  decentralized receding horizon control for large scale dynamically decoupled systems , \" in _ automatica _ , vol .",
    "42 , no . 12 , pp .",
    "2105-2115 , dec . 2006 .",
    "g. alefeld and n. schneider , `` on square roots of m - matrices , '' in _ linear algebra appl .",
    "42 , pp . 119132 , feb ."
  ],
  "abstract_text": [
    "<S> our goal is to design distributed coordination strategies that enable agents to achieve global performance guarantees while minimizing the energy cost of their actions with an emphasis on feasibility for real - time implementation . as a motivating scenario that illustrates the importance of introducing energy awareness at the agent level </S>",
    "<S> , we consider a team of mobile nodes that are assigned the task of establishing a communication link between two base stations with minimum energy consumption . </S>",
    "<S> we formulate this problem as a dynamic program in which the total cost of each agent is the sum of both mobility and communication costs . to ensure that the solution is distributed and real time implementable , we propose multiple suboptimal policies based on the concepts of approximate dynamic programming . to provide performance guarantees , we compute upper bounds on the performance gap between the proposed suboptimal policies and the global optimal policy . </S>",
    "<S> finally , we discuss merits and demerits of the proposed policies and compare their performance using simulations . </S>"
  ]
}