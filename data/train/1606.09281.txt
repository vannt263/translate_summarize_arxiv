{
  "article_text": [
    "image segmentation remains at the forefront of issues in computer vision and image processing and an abundance of approaches have been developed to solve a wide range of problems ; see , for example , @xcite .",
    "the goal of image segmentation is to decompose the image domain into a montage of meaningful components .",
    "this has lead to breakthroughs in a number of research areas such as medical imaging @xcite , astronomical imaging @xcite , and biometric recognition @xcite .",
    "segmentation methods can be broadly characterized by the class of target images for which they are intended , either homogeneous ( piecewise smooth ) or textural .",
    "many such methods have been suggested , including approaches based on the intensity of pixels @xcite and others based on curve evolution@xcite . for homogeneous images in particular , the classical approach to segmentation",
    "is based on active contours @xcite .",
    "given an image @xmath0 on a bounded domain @xmath1 , contours are driven to object boundaries by internal and external forces in the functional @xmath2 with a curve @xmath3 \\rightarrow \\mathbb r^2 $ ] and positive parameters @xmath4 and @xmath5 .    under the classical model @xmath6 with @xmath7 , mumford and shah",
    "@xcite proposed a solution by minimizing the energy functional @xmath8 however , this piecewise smooth mumford - shah model is np - hard due to the hausdorff 1-dimensional measure @xmath9 . a simplified version for image segmentation when @xmath0 is assumed to be piecewise constant can be written as @xmath10_{n=1}^n , [ \\omega_n]_{n=1}^n } \\left\\ {    \\sum_{n=1}^n \\int_{\\omega } \\big ( f({{\\boldsymbol x } } ) - c_n \\big)^2 \\mathbf 1_{\\omega_n}({{\\boldsymbol x } } ) d{{\\boldsymbol x}}~+~    \\frac{\\mu}{2 } \\sum_{n=1}^n \\int_\\omega \\abs{\\nabla \\mathbf 1_{\\omega_n}({{\\boldsymbol x } } ) } d { { \\boldsymbol x}}\\right\\ } \\,.\\ ] ] which closely resembles the potts model @xcite developed decades earlier .",
    "rudin et al .",
    "@xcite proposed an alternative , more computationally efficient version of the model in ( [ eq : piecewisesmoothms ] ) that preserves sharp edges in the restored image .",
    "these advantages led to numerous extensions including examination in different functional spaces , @xcite , versions involving higher - order derivatives @xcite , mean curvature @xcite , euler s elastica @xcite , total variation of the first and second order derivatives @xcite , and higher - order pdes for diffusion solved by directional operator splitting schemes @xcite .",
    "various techniques have been proposed for solving the convex optimization including chambolle s projection @xcite , the splitting bregman method @xcite , and iterative shrinkage / thresholding ( ist ) algorithms @xcite . in 2010 , wu et al .",
    "@xcite proved the equivalence between the augmented lagrangian method ( alm ) , dual methods , and the splitting bregman method .    letting @xmath11 denote the indicator function @xmath12 with @xmath7 , ( [ eq : piecewiseconstantms : indicator ] ) can be rewritten as the non - convex constrained minimization @xmath13 where @xmath14_{n=1}^n \\ , , \\vec{p } = [ p_n]_{n=1}^n$ ] .",
    "note that when @xmath15 , this becomes the celebrated chan and vese model @xcite .",
    "brown et al .",
    "@xcite provide a convex relaxation of ( [ eq : piecewiseconstantms : indicator : nonconvex ] ) by relaxing the binary set to @xmath16 $ ] and bae et al .",
    "@xcite solve this relaxed version via a smoothed primal - dual method ; see @xcite for details .",
    "the advantage of the multiphase segmentation is illustrated in figure [ fig : multiphaseover2phase ] using the smoothed primal - dual method in @xcite to recover an object under a spectrum of illumination .    ) .",
    "using multiple phases allows us to recover portions of the image with different illumination ( gradient change ) .",
    ", scaledwidth=100.0% ]    texture segmentation and analysis remains a challenging problem due to its oscillatory nature .",
    "proposed methods include those based on texture descriptors @xcite , histogram metrics @xcite , and finding other meaningful features in an observed image for classification @xcite . among the most popular approaches",
    "is the vector - valued chan - vese model for texture segmentation with a gabor filter @xcite whose convex relaxed version is defined in @xcite .",
    "this can be seen as a generalized version of the two - phase piecewise constant mumford and shah model for a vector valued image @xmath17_{m=1}^m$ ] and constant vector @xmath18_{m=1}^m \\ , , \\vec{c}_2 = \\big [ c_{2 m } \\big]_{m=1}^m$ ] .",
    "the resulting minimization becomes convex by relaxing the binary constraint to @xmath19 $ ] @xcite .",
    "though these techniques have seen much success in their respective domains , many natural images like fingerprints and stem cell imaging contain both homogeneous and textural regions and it is important to define a technique to capture the entirety of this information .",
    "the mumford - shah model fails in this larger class of images due to the absence of measurement for texture ; see figure [ fig : barbara : mssegmentation ] for such an example where textural regions appear in each phase .    .",
    "note that both homogeneous and textural information appear in all three phases ( b)-(d ) . ]    in this work , we provide a method for multiphase segmentation of images that simultaneously contain regions of both homogeneity and texture .",
    "an attempt at this kind of segmentation was provided in @xcite but importantly , our work here can be viewed as a decomposition of the original image which approximates the image in functional space instead of using harmonic analysis .",
    "this approach to the inverse problem allows us to obtain a piecewise constant component as well as sparse directional information ; figure [ fig : fingerprint : approximation ] shows a preview of results obtained using the bilevel sht method outlined in section [ sec : bilevelminimizationscheme ] .",
    "following @xcite , we adopt the idea of the discrete directional @xmath20-norm to measure texture in several directions and the dual of a generalized besov space in the curvelet domain @xmath21 @xcite to measure the residual .",
    "this approach is particularly useful for many natural images such as fingerprints in which texture appears in many directions and can easily be adapted for the shearlet , contourlet , steerable wavelet or 2d empirical transforms @xcite .",
    "because of the curvelet transform , the residual can be either independent or correlated and need not follow a gaussian distribution . since our minimization involves the @xmath20-norm , we propose two alternative methods based on the two primary approaches to handling the @xmath20-norm : a multiphase sht method based on the approach of aujol and chambolle @xcite and a bilevel sht method based on the approach of vese and osher @xcite .    .",
    "the directional texture is shown in the bottom row . ]",
    "the remainder of this paper is organized as follows . in section [ sec : prelim ] , we define some preliminary notation and investigate a simple model where only two - phase segmentation is considered and the homogeneous portion is assumed to be piecewise constant . in section [ sec : multisht ] we generalize this set - up both to multiphase segmentation and also to the case where homogeneous regions are considered piecewise - smooth . in section [ sec : bilevelminimizationscheme ] we introduce a bilevel minimization scheme to more efficiently solve the minimization induced by the multiphase piecewise smooth context . finally , we apply the methodology to a number of representative images and compare to related approaches in section [ sec : comparisons ] . for readability , mathematical details and proofs",
    "are provided in the appendix .",
    "we begin by establishing some background notation and definitions .",
    "let @xmath22 be the euclidean space with dimension given by the size of the lattice @xmath23 \\in [ 0 \\ , , d_1 - 1 ] \\times [ 0 \\ , , d_2 - 1 ] \\subset \\mathbb z^2 \\big\\}$ ] . on the bounded domain @xmath24 , we denote the coordinates of the fourier transform as @xmath25 \\in [ -\\pi \\ , , \\pi]^2 $ ] and the coordinates of the @xmath26 transform ( the discrete version of the fourier transform ) as @xmath27 = \\big[e^{j\\omega_1 } \\ , , e^{j\\omega_2}\\big]$ ] .",
    "denote the discrete fourier transform pair as @xmath28 ~\\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~    { { \\mathcal f}}\\big\\ { f[{{\\boldsymbol k } } ] \\big\\}(e^{j{{\\boldsymbol \\omega } } } ) = f(e^{j{{\\boldsymbol \\omega } } } ) = \\sum_{{{\\boldsymbol k}}\\in \\omega } f[{{\\boldsymbol k } } ] e^{-j \\langle { { \\boldsymbol k}}\\ , , { { \\boldsymbol \\omega}}\\rangle_{\\ell_2}}\\,.\\end{aligned}\\ ] ] given the discrete function @xmath29 \\big]_{{{\\boldsymbol k}}\\in \\omega } \\in x$ ] , a vector @xmath30_{l=0}^{l-1 } \\in x^l$ ] and the direction @xmath31 , we make a few preliminary definitions .",
    "the * directional forward / backward difference operators * are given , in matrix notation , by @xmath32 f({{\\boldsymbol z } } )    \\\\    & \\partial_l^- { { \\mathbf f}}= - \\big [ \\sin\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf f}}+ \\cos\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf f}}{{\\mathbf{d_2}}}\\big ]    ~~ \\stackrel{{{\\mathcal f}}}{\\longleftrightarrow}~       -\\big [ \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1^{-1}-1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2^{-1 } - 1 ) \\big ] f({{\\boldsymbol z } } )    \\end{aligned}\\ ] ] with @xmath33 \\big]_{{{\\boldsymbol k}}\\in \\omega}$ ] and a matrix @xmath34 and similarly @xmath35 .    given the adjoint operators of the difference operators as @xmath36 , the adjoint operators of their directional version are @xmath37 = - \\partial_l^\\mp \\,,\\ ] ] and",
    "we can define the * discrete directional gradient * and * divergence * as @xmath38_{l=0}^{l-1 } \\hspace{5 mm }    \\text {   and   }   \\hspace{5 mm }   \\text{div}_l^\\pm \\vec{{{\\mathbf g } } } = \\sum_{l=0}^{l-1 } \\partial_l^\\pm { { \\mathbf g}}_l\\ ] ] respectively .",
    "note that the adjoint operator of @xmath39 is @xmath40 ; that is @xmath41 given a vector of matrices @xmath42_{l=0}^{l-1 } \\in x^l$ ] , the derivative of the divergence operator @xmath43 w.r.t .",
    "@xmath44 for @xmath31 is given by @xmath45   = \\big [ -\\partial_l^+ \\delta[{{\\boldsymbol k } } ] \\big]_{{{\\boldsymbol k}}\\in \\omega } \\,,\\end{aligned}\\ ] ] where @xmath46 denotes the dirac delta function .",
    "thus , the derivative of the directional divergence w.r.t .",
    "@xmath47 is @xmath48 \\big]_{l=0}^{l-1 } \\big]_{{{\\boldsymbol k}}\\in \\omega }   = \\big [ - \\nabla^+_l \\delta[{{\\boldsymbol k } } ] \\big]_{{{\\boldsymbol k}}\\in \\omega } \\,.\\ ] ]    finally , the * discrete directional @xmath20-norm * @xcite is given by @xmath49_{s=0}^{s-1 } \\in x^s    \\big\\ } \\",
    ",   \\end{aligned}\\ ] ]    and the indicator function on a convex set for noise in the curvelet domain @xmath21 @xcite by @xmath50    for a more thorough background on the mathematical preliminaries ( including the point - wise operators as @xmath51 , etc . ) , we refer the reader to @xcite .",
    "we point out that in the remainder of this work , we use boldface to present a matrix , e.g. @xmath52 , vector with boldface to denote a vector of matrix , e.g. @xmath53_{n=1}^n \\in x^n$ ] , and vector ( without boldface ) to denote constant vector , e.g. @xmath54_{n=1}^n \\in \\mathbb r^n$ ] .",
    "we begin by considering the simple discrete model consisting of a two phase piecewise constant image ( indicated by indicator function @xmath55 and mean values @xmath56 ) and texture @xmath57 corrupted by i.i.d .",
    "( or weakly correlated ) noise @xmath58 as @xmath59 as in @xcite , we propose the model for this segmentation as @xmath60 \\in \\{0 , 1\\ } , \\forall { { \\boldsymbol k}}\\in \\omega   \\bigg\\ } \\ , .",
    "\\end{aligned}\\ ] ] in order to solve a non - convex minimization ( [ eq : twophasedg3pdtexture : minimization:1 ] ) , we relax a binary set @xmath61 \\in \\ { 0 \\ , , 1\\}$ ] to @xmath62 $ ] and then apply alm and the alternating directional method of multipliers ( admm ) ; see proposition [ prop:2phasepiecewiseconst ] and algorithms 5 in appendix for detailed calculations .",
    "figure [ fig:2phasepiecewiseconst ] illustrates the results of this model .",
    "the histogram of the indicator function @xmath55 in figure [ fig:2phasepiecewiseconst ] ( d ) shows that @xmath55 almost converges to @xmath63 after the @xmath64 iteration .",
    "one can use a technique in @xcite to make @xmath55 be exactly a binary setting as a solution of a minimization ( [ eq : twophasedg3pdtexture : minimization:1 ] ) .",
    "is shown in subfigure ( a ) .",
    "subfigure ( b ) shows the same image @xmath65 with additional i.i.d .",
    "noise added from a gaussian distribution with mean 0 and standard deviation @xmath66 .",
    "the segmented version @xmath67 of ( b ) shown in subfigure ( c ) is obtained by solving the minimization in ( [ eq : twophasedg3pdtexture : minimization:1 ] ) , see algorithm 5 in the appendix with the parameters : @xmath68 .",
    "the binarized texture @xmath57 in ( g ) shows its sparsity by a minimization of ( [ eq : twophasedg3pdtexture : minimization:1 ] ) with a percentage of non - zero coefficients in texture @xmath57 as @xmath69 .",
    "figure ( e ) and ( f ) are the indicator function and its complement , respectively .",
    "the mean values are @xmath70 and we choose @xmath71 .",
    "[ fig:2phasepiecewiseconst],scaledwidth=100.0% ]",
    "the above models consider only two - phase segmentation in images where the homogeneous region can be considered piecewise constant .",
    "we now generalize this to allow for multiphase segmentation and also allow for piecewise - smooth homogeneity .      as before",
    ", we assume that a natural image @xmath65 contains both texture @xmath57 and homogeneous regions @xmath72 as well as noise @xmath58 so that @xmath73 .",
    "however , we now further assume that @xmath72 consists of both a multiphase @xmath74 piecewise constant ( indexed by the indicator function @xmath75_{n=1}^n$ ] and their mean values @xmath76_{n=1}^n$ ] ) as well as a bias field @xmath77    @xmath78    to account for the piecewise - smooth component of @xmath65 . following @xcite , we utilize the directional @xmath20-norm to measure the texture @xmath57 and propose a new combined model for multiphase * s*imultaneous * h*omogeneous and * t*exture image segmentation ( the sht model ) as @xmath79 \\in \\{0 , 1\\ } \\ , ,",
    "n = 1 , \\ldots , n \\ , , { { \\boldsymbol k}}\\in \\omega     \\bigg\\ } \\ , .   \\end{aligned}\\ ] ] note that in contrast with ( [ eq : twophasedg3pdtexture : minimization:1 ] ) , we no longer assume a piecewise - constant homogeneous region and thus must also take into account the bias term @xmath77 .",
    "note further that the directional total variation norm ( dtv - norm ) @xmath80 and @xmath20-norm are a dual pair if @xmath81 ; see lemma [ lem : dtvdgnorm : dualpair ] for details . finally , observe that as with the rof model in @xcite , the process of smoothing the homogeneous areas while preserving the edge information is controlled by the dtv - norm for   @xmath72 .      in a similar fashion to @xcite , the minimization in ( [ eq : combinedmodel:1 ] ) can be solved by a smoothed primal - dual model for the @xmath47-problem rather than by the fourier approach used in the two - phase piecewise - constant model in ( [ eq : twophasedg3pdtexture : minimization:1 ] ) .",
    "the remainder of this section provides a sketch of the proposed algorithm ; for details and proofs , see propositions [ prop : directionaltvl2 ] , [ prop : directionalgl1 ] , [ prop : combinedmodel : pproblem ] in the appendix .",
    "define the indicator function on a convex set for the @xmath20-norm as @xmath82 by applying alm to the equality constraint @xmath83 and relaxing the binary setting @xmath84 \\in \\{0 , 1\\}$ ] to the convex set @xmath84 \\in [ 0 , 1]$ ] , the nonconvex minimization in ( [ eq : combinedmodel:1 ] ) becomes convex as @xmath85 > 0 \\ , , n = 1 , \\ldots , n \\ , , { { \\boldsymbol k}}\\in \\omega     \\big\\ }    \\end{aligned}\\ ] ] with @xmath86 due to the multi - variable minimization , we apply admm to ( [ eq : combinedmodel:2 ] ) whose minimizer is numerically computed through iteration @xmath87 with updated lagrange multiplier @xmath88 given the initialization @xmath89 and @xmath90 for @xmath91 , we solve the following five subproblems before updating the lagrange multiplier . + * the @xmath72-problem : * fix @xmath92 and solve @xmath93 where @xmath94 \\ , . $ ]    from proposition [ prop : directionaltvl2 ] and the numerical solver in ( [ eq : sht : numericallagrange ] ) , a primal solution of the dtv-@xmath95 ( [ eq : combinedmodel : uproblem : solution ] ) at iteration @xmath87 is given by @xmath96 with dual variable @xmath97 }        { 1 + \\tau \\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{{{\\mathbf r}}}^{(t-1 ) } - ( \\mu_4 + \\beta ) { { \\mathbf h}}\\big ] } } \\ , .",
    "\\end{aligned}\\ ] ]    * the @xmath57-problem : * fix @xmath98 , denote @xmath99 and solve @xmath100 to simplify the problem , we apply proposition [ prop : directionalgl1 ] with a quadratic penalty @xmath101 .",
    "the primal solution of the directional @xmath102 model ( [ eq : combinedmodel : vproblem : solution ] ) at iteration @xmath87 is updated as @xmath103 with dual variable @xmath104 }          { 1 + \\tau \\abs{\\nabla^+_s \\big [ \\alpha \\mu_1 \\text{div}^-_s \\vec{{{\\mathbf g}}}^{(t-1 ) } - \\alpha { { \\mathbf v}}^{(t-1 ) } \\big ] } } .\\end{aligned}\\ ] ]    * the @xmath58-problem : * fix @xmath105 and solve @xmath106 } ^2_{\\ell_2 }   \\right\\}.\\end{aligned}\\ ] ] in a similar fashion to @xcite , the solution of ( [ eq : combinedmodel : epsilonproblem : solution ] ) is given by @xmath107              - { \\mathop{\\rm cst}}\\big ( \\big[{{\\mathbf f}}- { { \\mathbf u}}- { { \\mathbf v}}+ \\frac{\\boldsymbol{\\lambda}}{\\beta } \\big ] \\ , , \\nu \\big ) \\,.\\ ] ]    * the @xmath76_{n=1}^n$]-problem : * fix @xmath108 and solve @xmath109 due to its separability , the solution of ( [ eq : combinedmodel : cproblem : solution ] ) is given by @xmath110 p_n[{{\\boldsymbol k } } ] }               { \\displaystyle \\sum_{{{\\boldsymbol k}}\\in \\omega } p_n[{{\\boldsymbol k } } ] }     \\,,~ n = 1 , \\ldots , n.\\ ] ]    * the @xmath75_{n=1}^n$]-problem : * fix @xmath111 and solve @xmath112 \\in \\{0 , 1\\ } , n = 1 , \\ldots , n , { { \\boldsymbol k}}\\in \\omega      \\bigg\\ } \\,.\\end{aligned}\\ ] ] from proposition [ prop : combinedmodel : pproblem ] with a smooth primal - dual model and chambolle s projection , the primal solution of ( [ eq : combinedmodel : pproblem : solution ] ) at iteration @xmath87 ( for @xmath91 ) is @xmath113 \\right\\ } }                { \\displaystyle \\sum_{i=1}^n \\exp \\left\\ { - \\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{{{\\mathbf q}}}_i                   + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}-",
    "c_i \\big)^{.2 } \\big ] \\right\\ } }   \\\\   & = \\frac{\\displaystyle \\exp\\left\\ { -\\frac{1}{\\xi } \\big [ -\\sum_{m=0}^{m-1 } \\big [ \\sin(\\frac{\\pi m}{m } ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{nm } + \\cos(\\frac{\\pi m}{m } ) { { \\mathbf q}}_{nm } { { \\mathbf{d_2}}}\\big ]             + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_n \\big)^{.2 }            \\big ] \\right\\ } }           { \\displaystyle \\sum_{i=1}^n \\exp \\left\\ { - \\frac{1}{\\xi } \\big [ -\\sum_{m=0}^{m-1 } \\big [ \\sin(\\frac{\\pi m}{m } ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{im } + \\cos(\\frac{\\pi m}{m } ) { { \\mathbf q}}_{im } { { \\mathbf{d_2}}}\\big ]             + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_i \\big)^{.2 } \\big ] \\right\\ } } \\ , , \\end{aligned}\\ ] ] with dual variable @xmath114 }                          { \\displaystyle 1 + \\tau \\left [ \\sum_{m=0}^{m-1 } \\big [ \\sin(\\frac{\\pi m}{m } ) { { \\mathbf{d_1}}}{{\\mathbf p}}_n^{(t ) } + \\cos(\\frac{\\pi m}{m } ) { { \\mathbf p}}_n^{(t ) } { { \\mathbf{d}_{\\mathbf 2}^{\\text t}}}\\big]^{.2 } \\right]^{.\\frac{1}{2 } } }   \\,,~ m = 0 , \\ldots , m-1 \\,.\\end{aligned}\\ ] ]    finally , we update the lagrange multiplier as @xmath115 this solution is summarized in algorithm 1 .",
    "figures [ fig : barbara : combinedmodel : nonoise ] and [ fig : barbara : combinedmodel : noise ] depict the segmented results without noise and with independent gaussian noise , respectively . in both cases",
    ", our proposed method provides good segmented results , though some large - scale texture ( e.g.  the books shown in the upper left - hand corner ) still remains in the piecewise constant images ; see figures [ fig : barbara : combinedmodel : nonoise ] ( f ) and [ fig : barbara : combinedmodel : noise ] ( f ) .",
    "this is likely due to the minimizer obtained by the primal - dual method with chambolle s projection @xcite and since there is no shrinkage to produce sparse signals in some transform domains .",
    "similar to ( [ eq : twophasedg3pdtexture : minimization:1 ] ) , one can use the technique in @xcite to obtain a binary setting of @xmath55 . as in @xcite , the convergence of the algorithm",
    "is defined by a relative error on the log scale @xmath116     ( a ) is decomposed into a bias field @xmath77 ( e ) , a piecewise constant image @xmath117 ( f ) , small scale objects ( residual ) @xmath58 ( g ) , and sparse texture @xmath57 ( h ) with binarized verion @xmath118 in ( l ) . a piecewise smooth image @xmath72 ( b )",
    "is obtained by a summation of @xmath77 ( e ) and @xmath117 ( f ) .",
    "subfigure ( c ) shows segmented contours superimposed on @xmath72 .",
    "the relative error of @xmath72 is shown in ( d ) .",
    "the indicator functions for phases 1 , 2 , and 3 are shown in subfigures i , j , and k , respectively .",
    "the parameters are @xmath119 .",
    "the mean square error of the original image @xmath65 and a reconstructed image @xmath120 is @xmath121 . ]     with added i.i.d .",
    "noise from @xmath122 is shown in ( a ) . with the addition of noise",
    ", we choose @xmath123 with the remaining parameters set similar to those in figure [ fig : barbara : combinedmodel : nonoise ] .",
    "the qqplot in ( c ) for noise @xmath58 in ( g ) shows that @xmath123 can separate most of the noise and some texture information .",
    "the mse is @xmath124 .",
    "note that increasing @xmath125 will not make @xmath72 ( b ) smoother due to the lack of a sparsity constraint in chambolle s projection .",
    "the algorithm still performs well with sparse texture @xmath57 as illustrated in ( l ) . ]",
    "[ alg : combinedmodel ]",
    "we now propose an alternative to the multiphase sht model . as above",
    ", we assume that an image @xmath65 is composed of a homogeneous region ( consisting of a bias field @xmath77 and piecewise - constant with mean values @xmath126 and indicator functions @xmath47 ) as well as texture @xmath57 and residual @xmath58 , but we now consider a bilevel scheme for decomposing the image into these base components . specifically , we consider the decomposition and segmentation as separate levels :    * * level 1 : * image decomposition @xmath127 * * level 2 : * multiphase piecewise - smooth image segmentation @xmath128 \\in \\{0 , 1\\ }",
    "\\,,~ n = 1 , \\ldots , n \\,,~ { { \\boldsymbol k}}\\in \\omega \\ , .\\ ] ]    the bilevel minimization scheme for simultaneously homogeneous and textural ( sht ) image segmentation is defined as @xmath129 with set @xmath130 @xmath131 \\in \\{0 , 1\\ } \\,,~ n = 1 , \\ldots ,",
    "n \\,,~ { { \\boldsymbol k}}\\in \\omega    \\right\\}\\ ] ] and energy functions @xmath132 similar to the above multiphase sht model , this bilevel - sht model also measures a bias field @xmath77 via @xmath95 distance as data fidelity term in the regularization .",
    "in contrast with @xcite , we enforce the constraint for the smoothness in @xmath72 with @xmath133 .",
    "we now describe a numerical algorithm to obtain the solution of the bilevel - sht model ( [ eq : bilevelminimization:1 ] ) :    * * level 1 : * * d*irectional * g*lobal * t*hree-*p*art * d*ecomposition ( dg3pd ) @xmath134 * * level 2 : * * s*imultaneously * h*omogeneous and * t*exture * m*ultiphase * s*egmentation ( shtms ) @xmath135    as alluded to above , we first decompose the original image @xmath65 into piecewise - smooth , texture , and residual components @xmath72 , @xmath57 , and @xmath58 .",
    "we then segment the piecewise - smooth image @xmath72 into multiphase @xmath74 piecewise - constant images and a bias field @xmath77 .",
    "sparse ( or segmented ) texture @xmath57 is measured by @xmath136 and @xmath137 and we note that @xmath20 is a generalized version of the banach space g in the discrete setting @xcite .",
    "note also that though we assume the original image @xmath65 contains both texture and homogeneous areas , only the homogeneous areas are segmented by level 2 .",
    "the solution of the convex minimization in ( [ eq : bilevelminimization:2:step1 ] ) is defined in ( * ? ? ?",
    "* algorithm 1 ) and @xcite and is solved by introducing new variables and applying alm and admm . in an effort to make this paper",
    "self - contained , the kernel of the dg3pd method is provided in algorithm 3 .    note that dg3pd approximates @xmath138 in the @xmath20-norm by @xmath139 ; see @xcite for details .",
    "this approximation in @xmath140-norm enforces sparsity of @xmath141 ( in our case , the texture @xmath57 ) .",
    "note that since the bias field is defined as @xmath142 with the binary set @xmath84 \\in \\ { 0 \\ , , 1 \\}$ ] , we can rewrite the @xmath95-norm and recast the non - convex minimization in ( [ eq : bilevelminimization:2:step2 ] ) as @xmath143 = 1 , p_n [ { { \\boldsymbol k } } ] \\in \\{0 , 1\\ } , n = 1 , \\ldots , n , { { \\boldsymbol k}}\\in \\omega    \\bigg\\ } \\,.\\end{aligned}\\ ] ] as in @xcite , a solution of the multivariate minimization ( [ eq : bilevelminimization:2:step2:1 ] ) can be obtained by alternating between solving the following two subproblems :    * a. the @xmath76_{n=1}^n$ ] problem : * fix @xmath47 and solve    @xmath144    due to its separability , the solution of ( [ eq : bilevelminimization : level2:cproblem ] ) is given by @xmath110 p_n[{{\\boldsymbol k } } ] }               { \\displaystyle \\sum_{{{\\boldsymbol k}}\\in \\omega } p_n[{{\\boldsymbol k } } ] }     \\,,~ n = 1 , \\ldots , n.\\ ] ]    * b. the @xmath75_{n=1}^n$ ] problem : * fix @xmath126 and find @xmath47 .",
    "as in section [ sec : combinedmodel ] , the nonconvex minimization in ( [ eq : bilevelminimization:2:step2:1 ] ) w.r.t .",
    "@xmath47 is relaxed and made convex by setting a binary set @xmath84 \\in \\{0 \\ , , 1\\}$ ] to @xmath62 $ ] .",
    "following @xcite , we apply a smoothed dual formulation by introducing the primal , primal - dual , and dual models :    * the primal model : * solve @xmath145 over the convex set @xmath146_{n=1}^n \\in x^n ~:~    \\sum_{n=1}^n p_n[{{\\boldsymbol k } } ] = 1 \\,,~   p_n [ { { \\boldsymbol k } } ] > 0 \\,,~ n = 1 , \\ldots , n \\,,~ { { \\boldsymbol k}}\\in \\omega     \\big\\}.\\ ] ]    * the primal - dual model : *    denote a convex set @xmath147 with a dual variable @xmath148_{n=1}^n = \\big [ { { \\mathbf q}}_{nm } \\big]_{n=[1,n]}^{m=[0,m-1 ] } \\in x^{n m}$ ] of a primal variable @xmath75_{n=1}^n \\in x^n$ ] . from lemma [ lem :",
    "dtvdgnorm : dualpair ] in the appendix ( for the dual formulation of the directional total variation norm ) and the minimax theorem as found in ( * ? ? ?",
    "* chapter 6 ) and @xcite , the primal - dual model is defined as @xmath149^n }   \\min _ { \\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {   \\mathcal l^\\text{pd}(\\vec{{{\\mathbf p } } } ; \\vec{{{\\mathbf q } } } ) =   \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_n \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_n \\big\\rangle_{\\ell_2 }     \\bigg\\}.\\ ] ]    * the smoothed primal - dual model : * solve @xmath150^n }   \\underbrace {   \\min _ { \\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {   \\mathcal l^\\text{pd}_{\\xi>0}(\\vec{{{\\mathbf p } } } ; \\vec{{{\\mathbf q } } } ) =    \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_n \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_n \\big\\rangle_{\\ell_2 }   + \\xi \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\log { { \\mathbf p}}_n \\big\\rangle_{\\ell_2 }    \\bigg\\ }   } _ { \\displaystyle = { { \\mathcal l}}^\\text{d}_{\\xi>0 } ( \\vec{{{\\mathbf q } } } ) : = -\\xi \\sum_{{{\\boldsymbol k}}\\in \\omega } \\log \\big [ \\sum_{n=1}^n      \\exp \\big\\ { -\\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } ( u[{{\\boldsymbol k } } ] - c_n)^2 + \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] \\big ] \\big\\ }      \\big ] } \\,.\\ ] ] from proposition [ prop : bilevel : smoothedprimaldualproblem ] in the appendix , the solution of the primal @xmath47-problem @xmath151 is given by ( with @xmath91 ) @xmath152\\bigg ] }                   { \\displaystyle \\sum_{i=1}^n \\exp\\bigg [ - \\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_i \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_i \\big]\\bigg ]   }   \\\\ &    = \\frac{\\displaystyle \\exp\\bigg [ - \\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_n \\big)^{.2 } - \\sum_{m=0}^{m-1 } \\big [ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{nm } + \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf q}}_{nm } { { \\mathbf{d_2}}}\\big ] \\big]\\bigg ] }          { \\displaystyle \\sum_{i=1}^n",
    "\\exp\\bigg [ - \\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_i \\big)^{.2 } - \\sum_{m=0}^{m-1 } \\big [ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{im } + \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf q}}_{im } { { \\mathbf{d_2}}}\\big ] \\big]\\bigg ]   } \\,.\\end{aligned}\\ ] ] due to its separability , we consider the dual @xmath153-problem @xmath154^n } { { \\mathcal l}}^\\text{d}_{s>0 } ( \\vec{{{\\mathbf q}}})\\ ] ] at @xmath91 . given @xmath155_{m=0}^{m-1}$ ] and @xmath156_{m=0}^{m-1}$ ] , the solution of ( [ eq : bilevelminimization:2:step2:smootheddual1 ] ) which is solved by chambolle s projection @xcite at each iteration @xmath87 is @xmath157 and",
    "its element form is ( with @xmath158 ) @xmath159 }                           { \\displaystyle 1 + \\tau \\bigg [ \\sum_{m=0}^{m-1 } \\bigg [ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d_1}}}{{\\mathbf p}}_n + \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf p}}_n { { \\mathbf{d}_{\\mathbf 2}^{\\text t}}}\\bigg]^{.2 } \\bigg]^{.\\frac{1}{2 } } }",
    "\\,.\\end{aligned}\\ ] ] the numerical solution of the bilevel sht model is described in algorithms 2 - 4 .",
    "figure [ fig : barbara : bilevelmodel ] shows the bilevel sht model applied to the same noisy image as in figure [ fig : barbara : combinedmodel : noise ] .",
    "note , by comparing the upper left - hand corners of subfigures ( l ) and ( k ) of figures [ fig : barbara : combinedmodel : noise ] and [ fig : barbara : bilevelmodel ] respectively , that the bilevel sht model does a better job of fully segmenting the large scale texture from the homogeneous regions .",
    "however , these binarized versions also reveal that the bilevel sht model is slightly oversensitive as some small artifacts are introduced .",
    "finally , in figure [ fig : galaxy : bilevelmodel:2 ] we apply the bilevel sht model to an image of a galaxy with many stars in the background .",
    "although the stars may constitute small - scale texture , in cases such as these we may set the texture component ( @xmath57 ) to 0 , thereby treating this fine texture as noise .",
    "[ alg : shtms ]    [ alg : level1:dg3pd : part1 ]    [ alg : level1:dg3pd : part2 ]    @xmath160^{-1 }   \\ , ,   \\\\   & \\mathcal b({{\\boldsymbol z } } ) ~=~   \\beta_2 \\big [ w_a({{\\boldsymbol z } } )   + \\frac{\\lambda_{2a}({{\\boldsymbol z } } ) } { \\beta_2 } \\big ]   ~+~ \\beta_3 \\big [ \\sin\\left ( \\frac{\\pi a}{s } \\right ) ( z_1^{-1 } - 1 ) + \\cos\\left ( \\frac{\\pi a}{s } \\right ) ( z_2^{-1 } - 1 ) \\big ] \\times   \\\\ &   \\bigg [ v({{\\boldsymbol z } } ) - \\sum_{s=[0\\,,s-1 ] \\backslash \\{a\\ } }   \\big [ \\sin\\left ( \\frac{\\pi s}{s } \\right ) ( z_1 - 1 ) + \\cos\\left ( \\frac{\\pi s}{s } \\right ) ( z_2 - 1 ) \\big ] g_s({{\\boldsymbol z } } )   + \\frac{\\lambda_3({{\\boldsymbol z}})}{\\beta_3 } \\bigg ] \\ , ,   \\\\   & \\mathcal x({{\\boldsymbol z } } ) =   \\bigg [ \\beta_4 \\mathbf{1_{mn } } + \\beta_1 \\sum_{l=0}^{l-1 } \\abs { \\sin\\left ( \\frac{\\pi l}{l } \\right ) ( z_1 - 1 ) + \\cos\\left ( \\frac{\\pi l}{l } \\right ) ( z_2 - 1 ) } ^2 \\bigg]^{-1 } \\ , ,   \\\\   & \\mathcal y({{\\boldsymbol z } } ) =   \\beta_4 \\big [ f({{\\boldsymbol z } } ) - v({{\\boldsymbol z } } ) - \\mathcal{e}({{\\boldsymbol z } } ) + \\frac{\\lambda_4({{\\boldsymbol z}})}{\\beta_4 } \\big ]   + \\beta_1 \\sum_{l=0}^{l-1 } \\big [ \\sin \\left ( \\frac{\\pi l}{l } \\right ) ( z_1^{-1 } - 1 ) + \\cos \\left ( \\frac{\\pi l}{l } \\right ) ( z_2^{-1 } -1 ) \\big ]   \\big [ r_l({{\\boldsymbol z } } ) + \\frac{\\lambda_{1l}({{\\boldsymbol z}})}{\\beta_1 } \\big ] .\\end{aligned}\\ ] ] * choice of parameters * @xmath161 } \\big ) \\,,~   \\mu_2 = c_{\\mu_2 } ( \\beta_3 + \\beta_4 ) \\cdot \\max_{{{\\boldsymbol k}}\\in \\omega } \\big ( \\abs{t_{{\\mathbf v}}[{{\\boldsymbol k } } ] } \\big )   \\text {   and   }   \\beta_2 = c_{\\beta_{2 } } \\beta_3 \\ , , \\beta_3 = \\frac{\\theta}{1 - \\theta } \\beta_4 \\ , , \\beta_1 = c_{\\beta_{1 } } \\beta_4.\\end{aligned}\\ ] ]    [ alg : level2:multiphasesegmentation ]     ]    . the constant values are @xmath162 $ ] and @xmath163 .",
    "parameters were chosen as in figure 7 with the exception of @xmath164 ]",
    "we now apply our approach to several images in order to demonstrate and compare the performance with alternative approaches .",
    "the proficiency of and some properties of our models were demonstrated in figures [ fig : barbara : combinedmodel : nonoise ] , [ fig : barbara : combinedmodel : noise ] and [ fig : barbara : bilevelmodel ] .",
    "here we focus on more subtle properties and compare our approach with existing methods .    .",
    "the chan - vese model parameters were chosen as @xmath165 .",
    "the third and fourth rows show reconstructed images from the 2 and 3-phase bilevel sht model with @xmath166 .",
    "the mse for @xmath167 in the 3-phase bilevel sht model is @xmath168 and the relative error in subfigures ( k ) and ( n ) is measured by ( [ eq : relativeerror : u ] ) .",
    "the bilevel model parameters were selected as in figure 7 with @xmath169 and @xmath170 .",
    ", scaledwidth=100.0% ]    figure [ fig : comparison : chanvese_bilevel ] depicts a homogeneous image of an airplane where we compare our bilevel sht model to the classic chan - vese model @xcite .",
    "the chan - vese model is applied in the first two rows and note that for different initial conditions ",
    "subfigures ( a ) and ( e )  that the model produces very different segmentations .",
    "however , in our bilevel sht model , we solve a convex minimization and as a result , produce a nearly unique result .",
    "the bilevel sht model is applied in rows three and four with 2 and 3 phases respectively .",
    "note that the 3-phase model is able to segment the sun , sky , and airplane whereas the 2-phase model combines the sky and airplane .",
    "subfigures ( k ) and ( n ) show convergence on the log scale , thus implying very fast convergence on the linear scale .",
    "as noted in subfigures ( e ) , ( f ) , and ( g ) , respectively . the relative error of @xmath72 is shown in subfigures ( k ) and   ( p).,scaledwidth=100.0% ]    figure [ fig : comparison : baeyuantai2010_bilevel : brain ] contains ( entirely ) homogeneous images of a brain and were analyzed in @xcite .",
    "subfigure ( a ) contains the original image with no noise added and in subfigure ( b ) we add i.i.d .",
    "gaussian noise with standard deviation 20 .",
    "the second row ( subfigures ( c ) - ( f ) ) show the resulting segmented images following the procedures in @xcite , and the bilevel sht method with @xmath169 and @xmath171 , respectively .",
    "we note that subfigure ( d ) was taken directly from @xcite and subfigure ( c ) was programmed by hand .",
    "note that in subfigure ( e ) with @xmath169 , some small - scale residual still remains but when we increase the threshold to @xmath171 in subfigure ( f ) , this residual is removed resulting in a smoother segmented image . thus , our procedure compares favorably even to other methods that apply only to homogeneous images",
    ". further note that when noise is added ( subfigure ( b ) ) , our procedure is able to not only filter out the additional noise from the segmented images  see subfigures ( l ) - ( o )  but also produces a decomposition with well - separated meaningful components .",
    "note also that by examining subfigure ( p ) , we see that with @xmath172 , almost all of the resulting noise was that which was added ( i.e. very little of the information from the original image was classified as noise ) . as in figure [ fig : comparison : baeyuantai2010_bilevel : brain ] , subfigure ( k ) shows convergence on the log scale implying very fast convergence on the linear scale .     for each of the three images ; @xmath173 and @xmath174 for the images in columns 1 , 2 , and 3 , respectively .",
    ", scaledwidth=100.0% ]    finally , we move on to consider images that contain only a textural region of interest . the images in figure [ fig : comparison : texture ] depict various animals each with well - defined textural markings ; the first row of images are taken directly from @xcite .",
    "we begin by noting that many methods already exist to define a region of texture ; see for example the methodology in @xcite .",
    "our sht procedures were not designed for this goal , though extracting such a region is possible with our bilevel sht model .",
    "row three of figure [ fig : comparison : texture ] shows the texture component of the bilevel sht decomposition .",
    "this texture component was then binarized and a morphological operator applied to obtain the textural boundaries shown in row 2 .",
    "rows four and five show the piecewise - smooth and piecewise - constant bilevel sht components , respectively .",
    "note that our bilevel model , though not designed for this purpose , still does an admirable job of capturing the textural boundary .",
    "one advantage to our approach is that instead of only defining this boundary , our procedure also allows one to separate the texture inside from the remainder of the image .",
    "this work provides algorithms to simultaneously decompose and segment images containing regions of both texture and homogeneity .",
    "this can be seen as an extension of the mumford and shah model to a much larger class of natural images .",
    "two approaches are presented corresponding to the two alternative solutions to the @xmath20-norm for texture @xmath57 ; the multiphase sht approach based on the @xmath20-norm solution provided by aujol and chambolle @xcite and bilevel sht approach based on the solution of vese and osher @xcite . in practice we find that the bilevel sht algorithm is better able to discriminate between the homogeneous and textural regions and thus we focus on this approach in section 5 and recommend it in practical applications .",
    "the likely reason for the superior performance of the bilevel model is that the vese and osher @xcite approach to solving the @xmath20-norm utilized in the bilevel sht model approximates @xmath138 with @xmath175 .",
    "this enhances the sparsity of @xmath141 and though the original image is typically not sparse , it is sparse in some transform domain which is usually measured by @xmath176-norm ( or its relaxed @xmath140-norm ) in function space .",
    "one shortcoming of our models is the large number of required parameters and we hope to reduce the size of the parameter set as well as to analyze the convergence of the proposed minimization in future work .",
    "the authors thank professors len stefanski , david banks and ingrid daubechies for their helpful comments .",
    "this material was based upon work partially supported by the national science foundation under grant dms-1127914 to the statistical and applied mathematical sciences institute .",
    "any opinions , findings , and conclusions or recommendations expressed in this material are those of the author(s ) and do not necessarily reflect the views of the national science foundation .    10    r.c . gonzalez and r.e . woods . .",
    "prentice hall , upper saddle river , nj , usa , 2002 .",
    "r.  szeliski . .",
    "springer , london , united kingdom , 2011 .",
    "wiley - ieee press , new york , u.s.a . ,",
    "starck and f.  murtagh , editors . .",
    "springer , new york , ny , usa , 2006 .",
    "a.  jain , a.a .",
    "ross , and k.  nandakumar . .",
    "springer , new york , ny , usa , 2011 .",
    "thai , s.  huckemann , and c.  gottschlich .",
    "filter design and performance evaluation for fingerprint image segmentation .",
    ", 11(5):e0154160 , may 2016 .",
    "thai and c.  gottschlich .",
    "global variational method for fingerprint segmentation by three - part decomposition .",
    ", 5(2):120130 , june 2016 .",
    "n.  otsu .",
    "a threshold selection method from gray - level histograms .",
    ", 9(1):6266 , january 1979 .",
    "p.  sahoo , c.  wilkins , and j.  yeager .",
    "threshold selection using renyi s entropy .",
    ", 30(1):7184 , january 1997 .",
    "albuquerque , i.a .",
    "esquef , a.r.g .",
    "mello , and m.p.d .",
    "image thresholding using tsallis entropy . , 25(9):10591065 , july 2004 .",
    "chan and l.a .",
    "active contours without edges . , 10(2):266277 , february 2001 .",
    "x.  bresson , s.  esedoglu , p.  vandergheynst , j.p .",
    "thiran , and s.  osher .",
    "fast global minimization of the active contour / snake model .",
    ", 28(2):151167 , june 2007 .",
    "chan , s.  esedoglu , and m.  nikolova .",
    "algorithms for finding global minimizers of image segmentation and denoising models .",
    ", 66(5):16321648 , february 2012 .",
    "j.  lie , m.  lysaker , and x.c .",
    "tai . a binary level set model and some applications to mumford - shah image segmentation . , 15(5):11711181 ,",
    "may 2006 .",
    "m.  kass , a.  witkin , and d.  terzopoulos .",
    "snakes : active contour models . , 1(4):321331 , january 1988 .",
    "d.  mumford and j.  shah .",
    "optimal approximations by piecewise smooth functions and associated variational problems . , 42(5):577685 , july 1989 .",
    "potts . some generalized order - disorder transformations .",
    ", 48:106109 , 1952 .",
    "l.  rudin , s.  osher , and e.  fatemi .",
    "nonlinear total variation based noise removal algorithms .",
    ", 60(1 - 4):259268 , november 1992 .",
    "aujol , g.  gilboa , t.  chan , and s.  osher .",
    "structure - texture image decomposition - modeling , algorithms , and parameter selection .",
    ", 67(1):111136 , april 2006 .",
    "aujol , g.  aubert , l.b .",
    "feraud , and a.  chambolle . image decomposition into a bounded variation component and an oscillating component .",
    ", 22(1):7188 , january 2005 .",
    "aujol and g.  gilboa . constrained and snr - based solutions for tv - hilbert space image denoising . , 26(1 - 2):217237 , november 2006 .",
    "a.  buades , t.m .",
    "m . morel , and l.a .",
    "fast cartoon + texture image filters . , 19(8):19781986 , august 2010 .",
    "vese and s.  osher . modeling textures with total variation minimization and oscillatory patterns in image processing . , 19(1 - 3):553572 , december 2003 .",
    "g.  aubert and l.  vese .",
    "a variational method in image recovery .",
    ", 34(5):19481979 , october 1997 .",
    "t.  chan , a.  marquina , and p.  mulet .",
    "high - order total variation - based image restoration .",
    ", 22(2):503516 , july 2000 .",
    "m.  lysaker , a.  lundervold , and x.c .",
    "noise removal using fourth - order partial differential equation with applications to medical magnetic resonance images in space and time .",
    ", 12(12):15791590 , december 2003 .",
    "t.  rahman , x.c .",
    "tai , and s.  osher . a tv - stokes denoising algorithm .",
    ", 4485:473483 , june 2007 .",
    "j.  hahn , c.  wu , and x.c .",
    "augmented lagrangian method for generalized tv - stokes model .",
    ", 50(2):235264 , february 2012 .",
    "w.zhu and t.  chan .",
    "image denoising using mean curvature of image surface . ,",
    "5(1):132 , january 2012 .    x.c .",
    "tai , j.  hahn , and g.j .",
    "chung . a fast algorithm for euler s elastica model using augmented lagrangian method .",
    ", 4(1):313344 , february 2011 .",
    "w.  zhu , x.c .",
    "tai , and t.  chan .",
    "image segmentation using euler s elastica as the regularization . , 57(2):414438 , april 2013 .",
    "k.  papafitsoros and c.b .",
    ". a combined first and second order variational approach for image reconstruction .",
    ", 48(2):308338 , 2014 .",
    "l.  calatroni , b.  dring , and c.b .",
    "splitting schemes for a fourth - order nonlinear partial differential equation from image processing .",
    ", 34(3):931957 , march 2014 .",
    "a.  chambolle .",
    "an algorithm for total variation minimization and applications . , 20(1 - 2):8997 , january 2004 .",
    "t.  goldstein and s.  osher .",
    "the split bregman method for l1-regularized problems . , 2(2):323343 , april 2009 .",
    "i.  daubechies , m.  defrise , and c.  d. mol . an iterative thresholding algorithm for linear inverse problems with a sparsity constraint .",
    ", 57(11):14131457 , august 2004 .",
    "a.  beck and m.  teboulle .",
    "a fast iterative shrinkage - thresholding algorithm for linear inverse problems .",
    ", 2(1):183202 , january 2009 .",
    "dias and m.  figueiredo . a new twist : two - step iterative shrinkage / thresholding algorithms for image restoration . , 16(12):29923004 , december 2007 .    c.  wu and x.  c. tai .",
    "augmented lagrangian method , dual methods , and split bregman iteration for rof , vectorial tv , and higher order methods . , 3(3):300339 , july 2010 .",
    "brown , t.f .",
    "chan , and x.  bresson . a convex relaxation method for a class of vector - valued minimization problems with applications to mumford - shah segmentation . , 2010 .",
    "brown , t.f .",
    "chan , and x.  bresson .",
    "completely convex formulation of the chan - vese image segmentation model .",
    ", 98(1):103121 , may 2012 .",
    "e.  bae , j.  yuan , and x.c .",
    "global minimization for continuous multiphase partitioning problems using a dual approach . , 92(1):112129 , march 2010 .",
    "l.l .  wang y.  gu and x.c .",
    "tai . a direct approach toward global minimization for multiphase labeling and segmentation problems .",
    ", 21(5):23992411 , may 2012 .",
    "e.  bae , j.  lellmann , and x.c .",
    "tai . , pages 223236 .",
    "springer , berlin , germany , 2005 .",
    "y.  gu , l.l .",
    "wang , w.  xiong , j.  cheng , w.  huang , and j.  zhou .",
    "efficient and robust image segmentation with a new piecewise - smooth decomposition model . in _ proc .",
    "ieee icip _ , pages 27182722 , melbourne , australia , september 2013 .",
    "y.  gu , w.  xiong , l.l .",
    "wang , j.  cheng , w.  huang , and j.  zhou . a new approach for multiphase piecewise smooth image segmentation . in _ proc .",
    "ieee icip _ ,",
    "pages 44174421 , paris , france , october 2014 .    c.  sagiv , n.a .",
    "sochen , and y.y .",
    "integrated active contours for texture segmentation . , 15(6):16331646 , june 2006 .",
    "n.  houhou , j.p .",
    "thiran , and x.  bresson .",
    "fast texture segmentation based on semi - local region descriptor and active contour .",
    ", 2(4):445468 , november 2009 .    k.  ni , x.  bresson , t.  chan , and s.  esedoglu .",
    "local histogram based segmentation using the wasserstein distance . , 84(1):97111 , april 2009 .",
    "m.  unser .",
    "texture classification and segmentation using wavelet frames .",
    ", 4(11):15491560 , november 1995 .",
    "chan , b.y .",
    "sandberg , and l.a .",
    "active contours without edges for vector - valued images . , 11(2):130141 , june 2000 .",
    "brown , t.f .",
    "chan , and x.  bresson .",
    "convex formulation and exact global solutions for multi - phase piecewise constant mumford - shah image segmentation .",
    ", 2009 .",
    "j.  liu , x.c .",
    "tai , h.  huang , and z.  huan . a fast segmentation method based on constraint optimization and its applications : intensity inhomogeneity and texture segmentation .",
    ", 44(9):20932108 , september 2011 .",
    "aujol and a.  chambolle .",
    "dual norms and image decomposition models .",
    ", 63(1):85104 , june 2005 .",
    "thai and c.  gottschlich .",
    "directional global three - part image decomposition . , 2016(12):120 , march 2016 .",
    "j.  gilles .",
    "multiscale texture separation .",
    ", 10(4):14091427 , december 2012 .",
    "e.  cands and d.  donoho .",
    "new tight frames of curvelets and optimal representations of objects with piecewise singularities .",
    ", 57(2):219266 , february 2004 .",
    "e.  cands , l.  demanet , d.  donoho , and l.  ying .",
    "fast discrete curvelet transforms . ,",
    "5(3):861899 , september 2006 .",
    "starck , d.l .",
    "donoho , and e.j .",
    "astronomical image representation by the curvelet transform .",
    ", 398(2):785800 , february 2003 .",
    "j.  ma and g.  plonka .",
    "the curvelet transform .",
    ", 27(2):118133 , march 2010 .",
    "g.  kutyniok and d.  labate , editors . .",
    "birkhuser , boston , ma , usa , 2012 .",
    "do and m.  vetterli .",
    "the contourlet transform : an efficient directional multiresolution image representation . , 14(12):20912106 , december 2005 .",
    "m.  unser and d.  van  de ville .",
    "wavelet steerability and the higher - order riesz transform . , 19(3):636652 ,",
    "march 2010 .",
    "j.  gilles , g.  tran , and s.  osher .",
    "2d empirical transforms .",
    "wavelets , ridgelets , and curvelet revisited . ,",
    "7(1):157186 , january 2014 .    d.h .",
    "phd thesis , university of goettingen , goettingen , germany , january 2015 .",
    "y.  meyer . .",
    "american mathematical society , boston , ma , usa , 2001 .",
    "i.  ekeland and r.  t/eman . .",
    "society for industrial and applied mathematics , philadelphia , pa , usa , 1999 .",
    "r.  t. rockafellar . .",
    "princeton mathematical series , no . 28 .",
    "princeton university press , princeton , n.j . ,",
    "[ prop:2phasepiecewiseconst ] the numerical solution of the two - phase piecewise constant and texture image segmentation ( [ eq : twophasedg3pdtexture : minimization:1 ] ) as described in algorithm 5 .",
    "this proof follows many of the techniques in @xcite .",
    "the minimization in ( [ eq : twophasedg3pdtexture : minimization:1 ] ) can be written as @xmath177 \\",
    ", ,   \\notag   \\\\ &   { { \\mathbf f}}= ( c_1 + { { \\mathbf v}}+ { { \\boldsymbol \\epsilon } } ) \\cdot^\\times { { \\mathbf p}}+ ( c_2 + { { \\mathbf v}}+ { { \\boldsymbol \\epsilon } } ) \\cdot^\\times ( 1 - { { \\mathbf p } } ) \\ , ,   p[{{\\boldsymbol k } } ] \\in \\{0 , 1\\ } , \\forall { { \\boldsymbol k}}\\in \\omega   \\bigg\\ } \\ , .",
    "\\end{aligned}\\ ] ] we define a convex set ( by relaxing the binary set ) and its indicator function as @xmath178 \\in [ 0 , 1 ] \\ , , \\forall { { \\boldsymbol k}}\\in \\omega \\big\\ }    ~~\\text{and}~~   h^*({{\\mathbf p } } ) = \\begin{cases } 0 \\ , , & { { \\mathbf p}}\\in \\mathcal d \\\\ + \\infty \\ , , & { { \\mathbf p}}\\notin \\mathcal d \\end{cases } \\,.\\end{aligned}\\ ] ] we introduce two new variables @xmath179 given @xmath180_{s=0}^{s-1 } \\",
    ", , \\vec{{{\\mathbf r } } } = \\big [ { { \\mathbf r}}_l \\big]_{l=0}^{l-1 } \\ , , \\vec{{{\\mathbf w } } } = \\big [ { { \\mathbf w}}_s \\big]_{s=0}^{s-1}$ ] , the augmented lagrangian method of ( [ eq : twophasedg3pdtexture : minimization:1:appendix ] ) is @xmath181 with @xmath182 + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 3}}{\\beta_3 } } ^2_{\\ell_2 }   \\\\ & +   \\underbrace {   \\frac{\\beta_4}{2 } \\big\\langle \\big [ { { \\mathbf f}}- c_1 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 } \\ , , { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   + \\frac{\\beta_4}{2 } \\big\\langle \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 } \\ , , 1 - { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   } _ { \\approx \\frac{\\beta_4}{2 } \\norm { { { \\mathbf f}}- c_1 { { \\mathbf p}}- c_2 ( 1 - { { \\mathbf p } } ) -",
    "{ { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } } ^2_{\\ell_2 } \\quad \\text{(due to the relaxed version of the binary set ) } } \\,.\\end{aligned}\\ ] ] we solve ( [ eq : twophasedg3pdtexture : minimization : alm ] ) by admm with the ordering subproblems and then update the lagrange multipliers at each iteration as    * the @xmath183-problem : * fix @xmath184 and solve @xmath185 - c_1 - v[{{\\boldsymbol k } } ] - \\epsilon[{{\\boldsymbol k } } ] + \\frac{\\lambda_4[{{\\boldsymbol k}}]}{\\beta_4 } \\big]^2 p[{{\\boldsymbol k } } ] \\big\\rangle_{\\ell_2 }   \\big\\}.\\end{aligned}\\ ] ] the euler - lagrange equation is @xmath186 \\big [ f[{{\\boldsymbol k } } ] - c_1 - v[{{\\boldsymbol k } } ] - \\epsilon[{{\\boldsymbol k } } ] + \\frac{\\lambda_4[{{\\boldsymbol k}}]}{\\beta_4 } \\big ]   \\\\",
    "\\leftrightarrow~    c_1 & = \\frac { \\sum_{{{\\boldsymbol k}}\\in \\omega } \\big [ f[{{\\boldsymbol k } } ] - v[{{\\boldsymbol k } } ] - \\epsilon[{{\\boldsymbol k } } ] + \\frac{\\lambda_4[{{\\boldsymbol k}}]}{\\beta_4 } \\big ] p[{{\\boldsymbol k } } ] } { \\sum_{{{\\boldsymbol k}}\\in \\omega } p[{{\\boldsymbol k } } ] } \\ , .",
    "\\end{aligned}\\ ] ]    * the @xmath187-problem : * fix @xmath188 and solve @xmath189 - c_2 - v[{{\\boldsymbol k } } ] - \\epsilon[{{\\boldsymbol k } } ] + \\frac{\\lambda_4[{{\\boldsymbol k}}]}{\\beta_4 } \\big]^2 \\big [ 1 - p[{{\\boldsymbol k } } ] \\big ]   \\big\\}.\\end{aligned}\\ ] ] the euler - lagrange equation is @xmath190 - c_2 - v[{{\\boldsymbol k } } ] - \\epsilon[{{\\boldsymbol k } } ] \\frac{\\lambda_4[{{\\boldsymbol k}}]}{\\beta_4 } \\big ] \\big [ 1 - p[{{\\boldsymbol k } } ] \\big ]   \\\\",
    "\\leftrightarrow~    c_2 & = \\frac { \\sum_{{{\\boldsymbol k}}\\in \\omega } \\big [ f[{{\\boldsymbol k } } ] - v[{{\\boldsymbol k } } ] - \\epsilon[{{\\boldsymbol k } } ] + \\frac{\\lambda_4[{{\\boldsymbol k}}]}{\\beta_4 } \\big ] \\big [ 1 - p[{{\\boldsymbol k } } ] \\big ] } { \\sum_{{{\\boldsymbol k}}\\in \\omega } ( 1 - p[{{\\boldsymbol k } } ] ) } \\,.\\end{aligned}\\ ] ]        * the @xmath180_{s=0}^{s-1}$]-problem : * fix @xmath201 and solve @xmath202 + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 3}}{\\beta_3 } } ^2_{\\ell_2 }   \\right\\}\\end{aligned}\\ ] ] the solution of its separable problem is @xmath203[{{\\boldsymbol k } } ] \\big|_{{{\\boldsymbol k}}\\in \\omega } \\ , , a = 0 , \\ldots , s-1\\end{aligned}\\ ] ] @xmath204    + \\beta_3 \\big [ \\sin\\left(\\frac{\\pi a}{s}\\right)(z_1^{-1 } - 1 ) + \\cos\\left(\\frac{\\pi a}{s}\\right ) ( z_2^{-1 } - 1 ) \\big ] \\times   \\\\ &   \\left [ v({{\\boldsymbol z } } ) - \\sum_{s = [ 0 , s-1 ] \\backslash \\{a\\ } } \\left [ \\sin\\left(\\frac{\\pi s}{s}\\right)(z_1 - 1 ) + \\cos\\left(\\frac{\\pi s}{s}\\right)(z_2 - 1 ) \\right ] g_s({{\\boldsymbol z } } ) + \\frac{\\lambda_3({{\\boldsymbol z}})}{\\beta_3 } \\right]\\end{aligned}\\ ] ]    * the @xmath57-problem : * fix @xmath205 and solve @xmath206 + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 3}}{\\beta_3 } } ^2_{\\ell_2 }   \\\\ & +   \\frac{\\beta_4}{2 } \\big\\langle \\big [ { { \\mathbf f}}- c_1 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 } \\ , , { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   + \\frac{\\beta_4}{2 } \\big\\langle \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 } \\ , , 1 - { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   \\big\\}.\\end{aligned}\\ ] ] the euler - lagrange equation ( in matrix form ) is @xmath207 + \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 3}}{\\beta_3 } \\right ]   \\\\ &   - \\beta_4 \\big [ { { \\mathbf f}}- c_1 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big ] \\cdot^\\times { { \\mathbf p}}- \\beta_4 \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big ] \\cdot^\\times \\big [ 1 - { { \\mathbf p}}\\big ]   \\\\",
    "\\leftrightarrow~    { { \\mathbf v}}&= \\mathcal j -\\frac{\\mu_2}{\\beta_3 + \\beta_4 } \\frac{{{\\mathbf v}}}{\\abs{{{\\mathbf v } } } }   ~:=~ { \\mathop{\\rm shrink}}\\big ( \\mathcal j \\ , , \\frac{\\mu_2}{\\beta_3 + \\beta_4 } \\big)\\end{aligned}\\ ] ] with @xmath208 - \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 3}}{\\beta_3 } \\right ]   + \\frac{\\beta_4}{\\beta_3 + \\beta_4 } \\big [ { { \\mathbf f}}- c_1 - { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big ] \\cdot^\\times { { \\mathbf p}}\\\\ &   + \\frac{\\beta_4}{\\beta_3 + \\beta_4 } \\big [ { { \\mathbf f}}- c_2 - { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big ] \\cdot^\\times \\big [ 1 - { { \\mathbf p}}\\big ] \\,.\\end{aligned}\\ ] ]    * the @xmath55-problem : * fix @xmath209 and solve @xmath210^{\\cdot 2 } \\ , , { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   + \\frac{\\beta_4}{2 } \\big\\langle \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 } \\ , , 1 - { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   \\bigg\\}\\end{aligned}\\ ] ] the euler - lagrange equation is @xmath211 { { \\mathbf{d_2}}}\\\\ &   + \\sin\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}\\big [ { { \\mathbf r}}_l - \\sin\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf{d_1}}}{{\\mathbf p}}- \\cos\\left(\\frac{\\pi l}{l}\\right ) { { \\mathbf p}}{{\\mathbf{d}_{\\mathbf 2}^{\\text t}}}+ \\frac{\\boldsymbol{\\lambda}_{\\boldsymbol 1 l}}{\\beta_1 } \\big ]   \\bigg ]   \\\\ &   + \\frac{\\beta_4}{2 } \\big [ { { \\mathbf f}}- c_1 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 }    - \\frac{\\beta_4}{2 } \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 } \\,.\\end{aligned}\\ ] ] its fourier transform is @xmath212 \\\\   & \\times \\big [ r_l({{\\boldsymbol z } } ) - \\big [ \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) \\big ] p({{\\boldsymbol z } } )   + \\frac{\\lambda_{1 l}({{\\boldsymbol z}})}{\\beta_1 } \\big ]    \\\\ & \\hspace{10 mm }   - \\beta_4 \\mathcal h({{\\boldsymbol z } } ) = 0 \\end{aligned}\\ ] ] with the fourier transform of @xmath213 as @xmath214^{\\cdot 2 }    + \\frac{1}{2 } \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 }    \\right\\ } ( { { \\boldsymbol z } } ) \\,.\\end{aligned}\\ ] ] thus , @xmath215   \\left [ r_l({{\\boldsymbol z } } ) + \\frac{\\lambda_{1 l}({{\\boldsymbol z}})}{\\beta_1 } \\right ]    + \\beta_4 \\mathcal h({{\\boldsymbol z}})\\end{aligned}\\ ] ] to avoid the singularity , we add @xmath216 to the `` @xmath55-problem '' ( [ eq : sht : problem : p : appendix ] ) which results in its solution as @xmath217 = { \\,{\\rm re}}\\big [ { { \\mathcal f}}^{-1 }",
    "\\big\\ { \\frac{\\mathcal y({{\\boldsymbol z}})}{\\mathcal x ( { { \\boldsymbol z } } ) } \\big\\ } \\big ] [ { { \\boldsymbol k } } ] \\ , , { { \\boldsymbol k}}\\in \\omega \\end{aligned}\\ ] ] with @xmath218   \\big [ r_l({{\\boldsymbol z } } ) + \\frac{\\lambda_{1 l}({{\\boldsymbol z}})}{\\beta_1 } \\big ]    + \\beta_4 \\mathcal h({{\\boldsymbol z } } ) \\ , ,   \\\\   \\mathcal x({{\\boldsymbol z } } ) & = \\beta_1 \\sum_{l=0}^{l-1 } \\abs { \\sin\\left(\\frac{\\pi l}{l}\\right ) ( z_1 - 1 ) + \\cos\\left(\\frac{\\pi l}{l}\\right ) ( z_2 - 1 ) } ^2 + \\beta_4 \\,.\\end{aligned}\\ ] ] due to @xmath219 \\big]_{{{\\boldsymbol k}}\\in \\omega } \\in \\mathcal d$ ] , we have @xmath220 = \\begin{cases }               0 \\ , , & \\tilde p[{{\\boldsymbol k } } ] < 0 \\\\               1 \\ , , & \\tilde p[{{\\boldsymbol k } } ] > 1 \\\\               \\tilde p[{{\\boldsymbol k } } ] \\ , , & \\tilde p[{{\\boldsymbol k } } ] \\in [ 0 \\ , , 1 ]              \\end{cases } \\,.\\end{aligned}\\ ] ]    * the @xmath58-problem : * fix @xmath221 and given a convex set with the indicator function @xmath222 @xmath223 the @xmath58-problem can be rewritten as @xmath224^{\\cdot 2 } \\ , , { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   + \\frac{\\beta_4}{2 } \\big\\langle \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big]^{\\cdot 2 } \\ , , 1 - { { \\mathbf p}}\\big\\rangle_{\\ell_2 }   \\right\\}\\end{aligned}\\ ] ] the euler - lagrange equation is @xmath225 \\cdot^\\times { { \\mathbf p}}- \\beta_4 \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big ] \\cdot^\\times \\big [ 1 - { { \\mathbf p}}\\big ]   \\\\",
    "\\leftrightarrow    \\tilde{{{\\boldsymbol \\epsilon } } } & = \\big [ { { \\mathbf f}}- c_1 - { { \\mathbf v}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big ] \\cdot^\\times { { \\mathbf p}}+    \\big [ { { \\mathbf f}}- c_2 - { { \\mathbf v}}+ \\frac{\\boldsymbol{\\lambda_4}}{\\beta_4 } \\big ] \\cdot^\\times \\big [ 1 - { { \\mathbf p}}\\big ] \\,.\\end{aligned}\\ ] ] thus , the solution of the @xmath58-problem is @xmath226    * update the lagrange multipliers : * @xmath227 \\,,~ a = 0 , \\ldots , l-1   \\\\   \\boldsymbol{\\lambda}_{\\boldsymbol 2 a}^{(t ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 2 a}^{(t-1 ) }    + \\beta_2 \\big [ { { \\mathbf w}}_a - { { \\mathbf g}}_a \\big ] \\ , , a = 0 , \\ldots , s-1   \\\\",
    "\\boldsymbol{\\lambda}_{\\boldsymbol 3}^{(t ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 3}^{(t-1 ) }    + \\beta_3 \\big [ { { \\mathbf v}}- \\sum_{s=0}^{s-1 } \\big [ \\sin\\left(\\frac{\\pi s}{s}\\right ) { { \\mathbf{d_1}}}{{\\mathbf g}}_s + \\cos\\left(\\frac{\\pi s}{s}\\right ) { { \\mathbf g}}_s { { \\mathbf{d}_{\\mathbf 2}^{\\text t}}}\\big ] \\big ]   \\\\",
    "\\boldsymbol{\\lambda}_{\\boldsymbol 4}^{(t ) } & = \\boldsymbol{\\lambda}_{\\boldsymbol 4}^{(t-1 ) }    + \\beta_4 \\big [ \\big ( { { \\mathbf f}}- c_1 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}\\big ) \\cdot^\\times { { \\mathbf p}}+ \\big ( { { \\mathbf f}}- c_2 - { { \\mathbf v}}- { { \\boldsymbol \\epsilon}}\\big ) \\cdot^\\times ( 1 - { { \\mathbf p } } ) \\big]\\end{aligned}\\ ] ]    [ lem : dtvdgnorm : dualpair ] the discrete directional total variation ( dtv ) norm @xmath228 and the discrete directional @xmath229-norm @xmath230 are",
    "a dual pair , i.e. @xmath231 with a convex set of @xmath229-norm @xmath232_{l=0}^{l-1 } \\in x^l ~:~ \\norm{{{\\mathbf v}}}_{\\text{g}_l } = \\inf_{\\vec{{{\\mathbf p } } } } \\big\\ { \\underbrace{\\max_{{{\\boldsymbol k}}\\in \\omega } \\sqrt{\\sum_{l=0}^{l-1 } p_l^2[{{\\boldsymbol k } } ] } } _ { = \\norm{\\vec{{{\\mathbf p}}}}_{\\ell_\\infty } } \\big\\ } \\leq \\mu \\big\\ } \\,.\\ ] ]      given a convex set @xmath233 and an adjoint operator @xmath234 , the discrete dtv - norm @xmath235 in ( [ eq : dualpair_tv - g ] ) can be rewritten as @xmath236 since @xmath237 }    = \\max _ { \\vec{{{\\mathbf p } } } \\in k_l(\\mu ) } - \\sum_{{{\\boldsymbol k}}\\in \\omega }    \\big\\langle \\nabla^+_l u[{{\\boldsymbol k } } ] \\ , , \\vec{p}[{{\\boldsymbol k } } ] \\big\\rangle_{\\ell_2 }    = \\max_{\\vec{{{\\mathbf p } } } \\in k_l(\\mu ) } \\sum_{{{\\boldsymbol k}}\\in \\omega }    \\underbrace { \\langle u[{{\\boldsymbol k } } ] \\ , , \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] \\rangle_{\\ell_2 } } _ { = u[{{\\boldsymbol k } } ] \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] } \\,.\\end{aligned}\\ ] ]    * 2 .",
    "the legendre - fenchel transform ( in a discrete setting ) of @xmath238 * @xmath239 denote the dual norm of @xmath240 as @xmath230 .",
    "given @xmath241 , the cauchy schwarz inequality gives @xmath242 we have a biconjugate form @xmath243 : @xmath244 from ( [ eq : deftvnorm : compare ] ) and definition of the dtv - norm ( [ eq : deftvnorm ] ) , we have @xmath245 & = \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] \\,,~ \\forall { { \\boldsymbol k}}\\in \\omega \\\\ { { \\mathbf v}}\\in \\text{g}_l(\\mu ) & = \\big\\ { { { \\mathbf v}}\\in x ~:~ \\norm{{{\\mathbf v}}}_{\\text{g}_l } \\leq \\mu \\big\\ } \\\\ \\vec{{{\\mathbf p } } } \\in k_l(\\mu ) & = \\big\\ { \\text{div}^-_l \\vec{{{\\mathbf p } } } \\,,~ \\vec{{{\\mathbf p } } } \\in x^l ~:~ \\norm{\\vec{{{\\mathbf p}}}}_{\\ell_\\infty } \\leq \\mu \\big\\ } \\end{cases } \\\\ \\leftrightarrow~ & \\vec{{{\\mathbf p } } } \\in k_l(\\mu ) = \\big\\ { { { \\mathbf v}}= \\text{div}^-_l \\vec{{{\\mathbf p } } } \\in x \\,,~   \\vec{{{\\mathbf p } } } \\in x^l ~:~ \\norm{{{\\mathbf v}}}_{\\text{g}_l } = \\norm { \\vec{{{\\mathbf p } } } } _ { \\ell_\\infty } \\leq \\mu \\big\\ } \\equiv \\text{g}_l(\\mu ) \\,.\\end{aligned}\\ ] ] therefore , the discrete @xmath246 dtv - norm and the discrete directional @xmath229-norm are a dual pair by the definition of dual space .    [ prop : directionaltvl2 ] the dtv-@xmath95 model is @xmath247 with @xmath248 and @xmath249 }        { 1 + \\tau \\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{{{\\mathbf p}}}^{(t ) } - \\mu { { \\mathbf f}}\\big ] } }   \\,,~ t = 1 , \\ldots , t \\,.\\end{aligned}\\ ] ]    the proof is extended directly from @xcite for the multi - directional total variation norm @xmath250 .",
    "the euler - lagrange of ( [ eq : directionaltvl2 ] ) is @xmath251 let @xmath252 @xmath253_{l=0}^{l-1 } \\in x^l    ~:~ \\abs{\\vec{p}[{{\\boldsymbol k } } ] } \\leq 1 \\ , , \\forall { { \\boldsymbol k}}\\in \\omega \\big\\ }   \\\\ &   = \\text{div}^-_l \\vec{{{\\mathbf p}}}^*\\end{aligned}\\ ] ] with @xmath254 - 1 \\leq 0 } _",
    "{ \\leftrightarrow~ \\abs{\\vec{p}[{{\\boldsymbol k}}]}^2 -1 \\leq 0 } \\ , , \\forall { { \\boldsymbol k}}\\in \\omega   \\bigg\\ } \\,.\\end{aligned}\\ ] ] due to an inequality constraint , the kkt condition in matrix form @xmath255 > 0 \\ , , \\forall { { \\boldsymbol k}}\\in \\omega)$ ] is @xmath256 due to its separability , we consider this problem at @xmath257 and its euler - lagrange equation is given by @xmath258   ~+~ 2 \\boldsymbol{\\lambda } \\cdot^\\times { { \\mathbf p}}_{l ' }   \\\\ \\leftrightarrow &   -\\partial^+_{l ' } \\big [ \\text{div}^-_l \\vec{{{\\mathbf p } } } - \\mu { { \\mathbf f}}\\big ]   ~+~ \\boldsymbol{\\lambda } \\cdot^\\times { { \\mathbf p}}_{l ' } = 0    \\,,~ l ' = 0 , \\ldots l-1   \\\\ \\leftrightarrow &   -\\nabla_l^+ \\big [ \\text{div}^-_l \\vec{{{\\mathbf p } } } - \\mu { { \\mathbf f}}\\big ]   ~+~ \\boldsymbol{\\lambda } \\cdot^\\times \\vec{{{\\mathbf p } } } = 0    \\,.\\end{aligned}\\ ] ] given @xmath259 , its element form is @xmath260 - \\mu f[{{\\boldsymbol k } } ] \\big ]   ~+~ \\lambda[{{\\boldsymbol k } } ] \\vec{p}[{{\\boldsymbol k } } ] = 0    \\\\",
    "\\leftrightarrow~    & \\lambda[{{\\boldsymbol k } } ] = \\frac{\\displaystyle \\nabla^+_l \\big [ \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] - \\mu f[{{\\boldsymbol k } } ] \\big ] }                        { \\vec{p}[{{\\boldsymbol k } } ] }   : = \\bigg [ \\frac{\\displaystyle \\partial^+_l \\big [ \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] - \\mu f[{{\\boldsymbol k } } ] \\big ] }                  { p_l[{{\\boldsymbol k } } ] }      \\bigg]_{l=0}^{l-1 }   \\notag   \\\\   \\leftrightarrow~    & \\abs{\\lambda[{{\\boldsymbol k } } ] } \\stackrel{\\lambda[{{\\boldsymbol k}}]>0}{= } \\lambda[{{\\boldsymbol k } } ] = \\frac{\\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] - \\mu f[{{\\boldsymbol k } } ] \\big ] } } { \\abs{\\vec{p}[{{\\boldsymbol k } } ] } }   = \\begin{cases }      \\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] - \\mu f[{{\\boldsymbol k } } ] \\big ] } \\ , , & \\abs{\\vec{p}[{{\\boldsymbol k } } ] } = 1      \\\\      0 \\ , , & \\abs{\\vec{p}[{{\\boldsymbol k } } ] } < 1      \\end{cases }   \\notag   \\\\   \\leftrightarrow~    & \\lambda[{{\\boldsymbol k } } ] = \\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] - \\mu f[{{\\boldsymbol k } } ] \\big ] } \\ , .   \\notag\\end{aligned}\\ ] ] note that lagrange multiplier is not active on an open set",
    ". we rewrite ( [ eq : kkt:1 ] ) as @xmath261 - \\mu f[{{\\boldsymbol k } } ] \\big ]   ~+~ \\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{p}[{{\\boldsymbol k } } ] - \\mu f[{{\\boldsymbol k } } ] \\big ] } \\vec{p}[{{\\boldsymbol k } } ] = 0 \\,,~   \\forall { { \\boldsymbol k}}\\in \\omega \\,.\\end{aligned}\\ ] ] applying gradient descent and a fixed point algorithm ( i.e.  a semi - implicit gradient descent scheme ) , we have @xmath262 - \\mu f[{{\\boldsymbol k } } ] \\big ]   ~+~ \\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{p}^{(t-1)}[{{\\boldsymbol k } } ] - \\mu f[{{\\boldsymbol k } } ] \\big ] } \\vec{p}^{(t)}[{{\\boldsymbol k } } ] =    - \\frac{\\vec{p}^{(t)}[{{\\boldsymbol k } } ] - \\vec{p}^{(t-1)}[{{\\boldsymbol k}}]}{\\tau } \\,,~ \\end{aligned}\\ ] ] and the solution in matrix form is given by @xmath263 }        { 1 + \\tau \\abs { \\nabla^+_l \\big [ \\text{div}^-_l \\vec{{{\\mathbf p}}}^{(t-1 ) } - \\mu { { \\mathbf f}}\\big ] } }    \\,,~ t = 1 \\ , , \\ldots\\end{aligned}\\ ] ]      * dual variable @xmath180_{s=0}^{s-1}$ ] * @xmath265 }            { 1 + \\tau \\abs{\\nabla^+_s \\big [ \\alpha \\mu \\text{div}^-_s \\vec{{{\\mathbf g}}}^{(t-1 ) } - \\boldsymbol{\\lambda}_{\\boldsymbol 1}^{(t-1 ) } - \\alpha { { \\mathbf v}}^{(t-1 ) } \\big ] } } \\ , ,    \\end{aligned}\\ ] ]        given the directional @xmath20-norm @xcite , we have the convex set @xmath269_{s=0}^{s-1 } \\in x^s    ~:~ \\underbrace { \\norm{{{\\mathbf v}}}_{\\text{g}_s } = \\norm { \\sqrt { \\sum_{s=0}^{s-1 } { { \\mathbf g}}_s^{\\cdot 2 } } } _ { \\ell_\\infty } \\leq \\mu                  } _ { \\displaystyle \\leftrightarrow \\abs{g[{{\\boldsymbol k } } ] } = \\sqrt{\\sum_{s=0}^{s-1 } g_s^2[{{\\boldsymbol k } } ] } \\leq \\mu \\ , , \\forall { { \\boldsymbol k}}\\in \\omega }   \\bigg\\}\\end{aligned}\\ ] ] note that @xmath270 is identical to @xmath271 ; see lemma [ lem : dtvdgnorm : dualpair ] .",
    "the objective function of ( [ eq : l1dgnorm:1 ] ) can be rewritten as @xmath272 with indicator function @xmath273 thus , we can rewrite ( [ eq : l1dgnorm:1 ] ) as @xmath274}{\\mu } } = \\sqrt{\\sum_{s=0}^{s-1 } \\frac{g_s^2[{{\\boldsymbol k}}]}{\\mu^2 } } \\leq 1 \\ , , \\forall { { \\boldsymbol k}}\\in \\omega   \\right\\ } \\,.\\end{aligned}\\ ] ] by changing variable @xmath275 to @xmath276 , we have @xmath277 - 1 \\leq 0 \\ , , \\forall { { \\boldsymbol k}}\\in \\omega   \\right\\ } \\,.\\end{aligned}\\ ] ] we then apply alm for the equality constraint and the kkt condition ( generalized lagrange multiplier ) for the inequality constraint as @xmath278 with lagrange function @xmath279 note that @xmath280>0 \\ , , \\forall { { \\boldsymbol k}}\\in \\omega$ ] . in a sequential fashion , we consider the primal , dual problems and then update the lagrange multiplier @xmath281 as :    * the primal @xmath57-problem : * fix @xmath141 and solve @xmath282 the euler - lagrange equation is given by @xmath283   \\\\",
    "\\leftrightarrow~   { { \\mathbf v}}^ * & = \\frac{\\beta}{\\alpha + \\beta } { { \\mathbf f}}+ \\frac{\\alpha \\mu}{\\alpha + \\beta } \\text{div}^-_s \\vec{{{\\mathbf g } } }    - \\frac{1}{\\alpha + \\beta } \\boldsymbol{\\lambda_1 }   - \\frac{1}{\\alpha + \\beta } \\frac{{{\\mathbf v}}}{\\abs{{{\\mathbf v } } } }   \\\\&:=   { \\mathop{\\rm shrink}}\\big ( \\frac{\\beta}{\\alpha + \\beta } { { \\mathbf f}}+ \\frac{\\alpha \\mu}{\\alpha + \\beta } \\text{div}^-_s \\vec{{{\\mathbf g } } }                 -\\frac{1}{\\alpha + \\beta } \\boldsymbol{\\lambda_1 }                 \\,,~ \\frac{1}{\\alpha + \\beta }           \\big ) \\,.\\end{aligned}\\ ] ]    * the dual @xmath180_{s=0}^{s-1}$]-problem : * fix @xmath57 and solve @xmath284 due to its separability , we evaluate the dual @xmath141 problem at @xmath285 and its euler - lagrange equation is given by @xmath286   + 2 \\boldsymbol{\\lambda_2 } \\cdot^\\times { { \\mathbf g}}_{s ' }   \\\\ \\leftrightarrow~ &   - \\mu \\partial_{s'}^+ \\big [ \\alpha \\mu \\text{div}^-_s \\vec{{{\\mathbf g } } } - \\boldsymbol{\\lambda_1 } - \\alpha { { \\mathbf v}}\\big ]   + 2 \\boldsymbol{\\lambda_2 } \\cdot^\\times { { \\mathbf g}}_{s ' } = 0   \\,,~ s ' = 0 , \\ldots , s-1   \\\\ \\leftrightarrow~ &    - \\mu \\nabla_s^+ \\big [ \\alpha \\mu \\text{div}^-_s \\vec{{{\\mathbf g } } } - \\boldsymbol{\\lambda_1 } - \\alpha { { \\mathbf v}}\\big ]   + 2 \\boldsymbol{\\lambda_2 } \\cdot^\\times \\vec{{{\\mathbf g } } } = 0 \\,.\\end{aligned}\\ ] ] as in ( [ eq : kkt:1 ] ) , with @xmath280 > 0\\ , , { { \\boldsymbol k}}\\in \\omega$ ] , its element form is @xmath287 - \\lambda_1[{{\\boldsymbol k } } ] - \\alpha v[{{\\boldsymbol k } } ] \\big ]   + 2 \\lambda_2[{{\\boldsymbol k } } ] \\vec{g}[{{\\boldsymbol k } } ] = 0   \\\\ \\leftrightarrow~ &   \\lambda_2[{{\\boldsymbol k } } ] = \\frac{\\mu}{2 } \\abs{\\nabla^+_s \\big [ \\alpha \\mu \\text{div}^-_s \\vec{g}[{{\\boldsymbol k } } ] - \\lambda_1[{{\\boldsymbol k } } ] - \\alpha v[{{\\boldsymbol k } } ] \\big ] } \\ ,",
    ".      \\notag\\end{aligned}\\ ] ] thus , we rewrite ( [ eq : kkt:3 ] ) with @xmath259 as @xmath288 - \\lambda_1[{{\\boldsymbol k } } ] - \\alpha v[{{\\boldsymbol k } } ] \\big ]   + \\abs{\\nabla^+_s \\big [ \\alpha \\mu \\text{div}^-_s \\vec{g}[{{\\boldsymbol k } } ] - \\lambda_1[{{\\boldsymbol k } } ] - \\alpha v[{{\\boldsymbol k } } ] \\big ] } \\vec{g}[{{\\boldsymbol k } } ] = 0 \\,.\\end{aligned}\\ ] ] applying gradient descent and the fixed point algorithm , we have @xmath289 - \\lambda_1[{{\\boldsymbol k } } ] - \\alpha v[{{\\boldsymbol k } } ] \\big ]   + \\abs{\\nabla^+_s \\big [ \\alpha \\mu \\text{div}^-_s \\vec{g}^{(t-1)}[{{\\boldsymbol k } } ] - \\lambda_1[{{\\boldsymbol k } } ] - \\alpha v[{{\\boldsymbol k } } ] \\big ] } \\vec{g}^{(t)}[{{\\boldsymbol k } } ]    \\\\   & = - \\frac { \\vec{g}^{(t)}[{{\\boldsymbol k } } ] - \\vec{g}^{(t-1)}[{{\\boldsymbol k } } ] } { \\tau } \\,,\\end{aligned}\\ ] ] the solution of the @xmath141-problem in matrix form is @xmath290 }          { 1 + \\tau \\abs{\\nabla^+_s \\big [ \\alpha \\mu \\text{div}^-_s \\vec{{{\\mathbf g}}}^{(t-1 ) } - \\boldsymbol{\\lambda_1 } - \\alpha { { \\mathbf v}}\\big ] } }    \\,,~ t = 1 , \\ldots .\\end{aligned}\\ ] ]        * the primal variable : * @xmath293 \\right\\ } }                { \\displaystyle \\sum_{i=1}^n \\exp \\left\\ { - \\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{{{\\mathbf q}}}_i^{(t-1 ) }                   + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_i \\big)^{\\cdot 2 } \\big ] \\right\\ } }   \\\\   & = \\frac{\\displaystyle \\exp\\left\\ { -\\frac{1}{\\xi } \\big [ -\\sum_{m=0}^{m-1 } \\big [",
    "\\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf q}}_{nm}^{(t-1 ) } { { \\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{nm}^{(t-1 ) } \\big ]             + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_n \\big)^{\\cdot 2 }            \\big ] \\right\\ } }           { \\displaystyle \\sum_{i=1}^n \\exp \\left\\ { - \\frac{1}{\\xi } \\big [ -\\sum_{m=0}^{m-1 } \\big [ \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf q}}_{im}^{(t-1 ) } { { \\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{im}^{(t-1 ) } \\big ]             + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_i \\big)^{\\cdot 2 } \\big ] \\right\\ } }   \\,,~ n = 1 , \\ldots , n      \\end{aligned}\\ ] ]    * the dual variable : * @xmath294 }                          { \\displaystyle 1 + \\tau \\left [ \\sum_{m=0}^{m-1 } \\left [ \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf p}}_n^{(t ) } { { \\mathbf{d}_{\\mathbf 2}^{\\text t}}}+ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d_1}}}{{\\mathbf p}}_n^{(t ) } \\right]^{.2 } \\right]^{.\\frac{1}{2 } } }   \\,,~~ n = 1 , \\ldots , n \\,,~ m = 0 , \\ldots , m-1 \\end{aligned}\\ ] ]    this subproblem is solved by a smoothed primal - dual model @xcite and chambolle s projection @xcite for the dual variable ( gradient descent of the euler lagrange equation and fixed point algorithm ) . in order to make the paper self - contained , the extension of @xcite to the multi - directional case is provided here by introducing a primal model , a primal - dual model , a dual model and then a smoothed dual model and a smoothed primal - dual model .",
    "given the relaxed version on the binary set , the `` @xmath47-problem '' can be rewritten as the convex minimization @xmath295 with the convex set @xmath296_{n=1}^n \\in x^n ~:~    \\sum_{n=1}^n { { \\mathbf p}}_n = 1 \\ , , p_n[{{\\boldsymbol k } } ] > 0 \\ , , n = 1 , \\ldots , n \\ , , { { \\boldsymbol k}}\\in \\omega   \\right\\ } \\,.\\end{aligned}\\ ] ]      from lemma [ lem : dtvdgnorm : dualpair ] , given a convex set of the dtv - norm @xmath297_{m=0}^{m-1 } \\in x^m ~:~    \\abs{\\vec{{{\\mathbf q}}}_n } = \\sqrt { \\sum_{m=0}^{m-1 } { { \\mathbf q}}_{nm}^{\\cdot 2 } } \\leq 1   \\right\\}\\ ] ] with the notation @xmath148^n_{n=1 } = \\big [ { { \\mathbf q}}_{nm } \\big]_{n=[1,n]}^{m = [ 0,m-1 ] } \\in x^{n m}$ ] , the primal - dual model of ( [ eq : pproblem : primal ] ) ( a separable problem ) can be written as @xmath298^n }   \\bigg\\ { \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\text{div}^-_m \\vec{{{\\mathbf q}}}_n   + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_n \\big)^{\\cdot 2 }   \\big\\rangle_{\\ell_2 }    \\bigg\\ }   \\,.\\end{aligned}\\ ] ] from ( [ eq : pproblem : primal ] ) and the min - max theorem , the primal @xmath299 - dual @xmath300 model is @xmath301^n }   \\min_{\\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {   { { \\mathcal l}}^\\text{pd}(\\vec{{{\\mathbf q } } } , \\vec{{{\\mathbf p } } } ) = \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\text{div}^-_m \\vec{{{\\mathbf q}}}_n   + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_n \\big)^{\\cdot 2 }   \\big\\rangle_{\\ell_2 }   \\bigg\\ } \\,.\\end{aligned}\\ ] ]        since the pixels are assumed to be independent , the primal - dual model ( [ eq : pproblem : primaldual ] ) can be rewritten as @xmath304^n }   \\min_{\\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {   { { \\mathcal l}}^\\text{pd}(\\vec{{{\\mathbf q } } } , \\vec{{{\\mathbf p } } } ) = \\sum_{{{\\boldsymbol k}}\\in \\omega } \\sum_{n=1}^n p_n[{{\\boldsymbol k } } ]    \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2 \\big ]   \\bigg\\ }   \\\\   & = \\max_{\\vec{{{\\mathbf q } } } \\in \\big [ k_m(1 ) \\big]^n }   \\sum_{{{\\boldsymbol k}}\\in \\omega }   \\underbrace {   \\min_{\\vec{p}[{{\\boldsymbol k } } ] \\in \\mathcal q_{+{{\\boldsymbol k } } } } \\bigg\\ {   { { \\mathcal l}}^\\text{pd}(\\vec{q}[{{\\boldsymbol k } } ] , \\vec{p}[{{\\boldsymbol k } } ] ) = \\sum_{n=1}^n p_n[{{\\boldsymbol k } } ]    \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2 \\big ]   \\bigg\\ }   } _ { \\displaystyle =   \\min_{1\\leq n \\leq n } \\bigg\\ {     \\text{div}^-_m \\vec{q}_1[{{\\boldsymbol k } } ] + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_1 \\big)^{2 } \\ , ,   \\ldots \\ , ,    \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^{2 }   \\bigg\\ }   } \\end{aligned}\\ ] ] with an element version at a pixel @xmath305 of a convex set @xmath306 @xmath307 = \\big [ p_n[{{\\boldsymbol k } } ] \\big]_{n=1}^n \\in \\mathbb r^n ~:~   \\sum_{n=1}^n p_n[{{\\boldsymbol k } } ] = 1 \\ , , p_n[{{\\boldsymbol k } } ] > 0 \\ , , n = 1 , \\ldots , n \\ , , { { \\boldsymbol k}}\\in \\omega   \\big\\ } \\,.\\end{aligned}\\ ] ] thus , the dual problem is @xmath308^n } \\bigg\\ {   { { \\mathcal l}}^\\text{d } ( \\vec{{{\\mathbf q } } } ) =    \\sum_{{{\\boldsymbol k}}\\in \\omega } \\min_{1 \\leq n \\leq n }   \\big\\ {   \\text{div}^-_m \\vec{q}_1[{{\\boldsymbol k } } ]    + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_1 \\big)^2 \\ , , \\ldots \\ , ,     \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2    \\big\\ }     \\bigg\\ } \\,.\\end{aligned}\\ ] ]      [ lem : smoothfunction ] given @xmath309_{n=1}^n$ ] , the non - smooth function @xmath310 is defined as the asympototic function of a proper convex function @xmath311 $ ] as @xmath312   \\\\   & \\approx~ \\xi \\log \\big [ \\sum_{n=1}^n e^{\\frac{u_n}{\\xi } } \\big]\\end{aligned}\\ ] ] for some small constant @xmath313 .    from ( [ eq : pproblem : dual ] )",
    ", we have @xmath314    - \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_1 \\big)^2 \\ , , \\ldots \\ , ,     - \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ]    - \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2     \\bigg\\ }   \\\\   & \\approx - \\xi \\sum_{{{\\boldsymbol k}}\\in \\omega } \\log \\bigg [   \\sum_{n=1}^n \\exp \\big\\ { \\frac{1}{\\xi } \\big [ - \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ]    - \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2   \\big\\ } \\bigg ]   ~:=~ { { \\mathcal l}}^\\text{d}_{\\xi > 0 } ( \\vec{{{\\mathbf q } } } ) \\,.\\end{aligned}\\ ] ] thus , a smoothed dual model is @xmath315^n } \\bigg\\ { { { \\mathcal l}}^\\text{d}_{\\xi > 0 } ( \\vec { { \\mathbf q } } ) =    -\\xi \\sum_{{{\\boldsymbol k}}\\in \\omega }   \\log \\big [ \\sum_{n=1}^n \\exp \\big\\ { -\\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ]     + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2   \\big ] \\big\\ }   \\big ]   \\bigg\\ } \\,.\\end{aligned}\\ ] ]        given the convex set @xmath319 in ( [ eq : convexset : q+k ] ) and because the pixels are assumed to be independent , the energy function of a smoothed dual model ( [ eq : pproblem : smootheddual ] ) can be rewritten as @xmath320 \\in \\mathcal q_{+{{\\boldsymbol k } } } }   \\left\\ { -\\frac{1}{\\xi }   \\big\\langle \\vec{p}_n[{{\\boldsymbol k } } ] \\ , , \\text{div}^-_m \\vec{q}[{{\\boldsymbol k } } ]    + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - \\vec{c } \\big)^2 \\big\\rangle_{\\ell_2 }   - \\sum_{n=1}^n p_n[{{\\boldsymbol k } } ] \\log p_n[{{\\boldsymbol k } } ]   \\right\\ }   \\\\   & = \\min_{\\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {   \\sum_{n=1}^n    \\underbrace {   \\sum_{{{\\boldsymbol k}}\\in \\omega } p_n[{{\\boldsymbol k } } ] \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ]    + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2 \\big ]   } _ { = \\big\\langle { { \\mathbf p}}_n \\ , , \\text{div}^-_m \\vec{{{\\mathbf q}}}_n + \\frac{\\mu_4}{2 \\mu_3 } ( { { \\mathbf u}}- c_n ) ^{\\cdot 2 } \\big\\rangle_{\\ell_2 } }   + \\xi \\sum_{n=1}^n \\underbrace { \\sum_{{{\\boldsymbol k}}\\in \\omega } p_n[{{\\boldsymbol k } } ] \\log p_n[{{\\boldsymbol k } } ] } _ { = \\big\\langle { { \\mathbf p}}_n \\ , , \\log { { \\mathbf p}}_n \\big\\rangle_{\\ell_2 } }   \\bigg\\ } \\,.\\end{aligned}\\ ] ] from ( [ eq : pproblem : smootheddual ] ) , we have the smoothed primal - dual model @xmath321^n }    \\underbrace {   \\min_{\\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {   { { \\mathcal l}}^\\text{pd}_{\\xi>0 } ( \\vec{{{\\mathbf q } } } , \\vec{{{\\mathbf p } } } ) = \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\text{div}^-_m \\vec{{{\\mathbf q}}}_n    + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_n \\big)^{\\cdot2 } \\big\\rangle_{\\ell_2 }   + \\xi \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\log { { \\mathbf p}}_n \\big\\rangle_{\\ell_2 }   \\bigg\\ }   } _ { \\displaystyle = { { \\mathcal l}}^\\text{d}_{\\xi>0 } ( \\vec{{{\\mathbf q } } } ) : = -\\xi \\sum_{{{\\boldsymbol k}}\\in \\omega } \\log \\left [    \\sum_{n=1}^n \\exp \\left\\ { -\\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ]    + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2   \\big ] \\right\\ } \\right ]   }   \\,.\\end{aligned}\\ ] ]    * a ) primal @xmath299-problem : * the primal problem of ( [ eq : pproblem : smoothedprimaldual ] ) over a convex set @xmath322_{n=1}^n \\in x^n ~:~   \\sum_{n=1}^n { { \\mathbf p}}_n = 1 \\ , , p_n[{{\\boldsymbol k } } ] \\geq 0 \\ , ,",
    "n = 1 , \\ldots , n \\ , , { { \\boldsymbol k}}\\in \\omega   \\big\\ }   $ ] is @xmath323 applying alm for the equality constraint , the primal @xmath299-problem can be rewritten as @xmath324 due to its separability , we consider the problem at @xmath325 .",
    "the euler - lagrange equation is @xmath326 } _ { = 0 }   & \\qquad \\text{(b ) } \\end{cases}\\end{aligned}\\ ] ] @xmath327 \\right\\ } \\,,~ a = 1 , \\ldots , n   \\\\   \\text{(a ) } & ~\\leftrightarrow~ \\sum_{n=1}^n \\exp \\left\\ {   - \\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{{{\\mathbf q}}}_n    + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_n \\big)^{\\cdot 2 }   \\big ] \\right\\ } = e^{\\frac{\\boldsymbol{\\lambda}}{\\xi } + 1 } \\,.\\end{aligned}\\ ] ] thus , the primal variable is @xmath328 \\big\\ } }                { \\displaystyle \\sum_{n=1}^n \\exp \\big\\ { - \\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{{{\\mathbf q}}}_n                   + \\frac{\\mu_4}{2 \\mu_3 } \\big ( { { \\mathbf u}}- c_n \\big)^{\\cdot 2 } \\big ] \\big\\ } }   \\,,~ a = 1 , \\ldots , n \\ , .     \\end{aligned}\\ ] ]    * b ) the dual @xmath300-problem : * given the convex set @xmath329_{m=0}^{m-1 } \\in x^m ~:~ \\abs{\\vec{{{\\mathbf q}}}_n } = \\sqrt{\\sum_{m=0}^{m-1 } { { \\mathbf q}}_{nm}^{\\cdot 2 } } \\leq 1\\big\\ }   $ ] , the dual problem of ( [ eq : pproblem : smoothedprimaldual ] ) is @xmath330^n } \\bigg\\ {    { { \\mathcal l}}^\\text{d}_{\\xi>0 } ( \\vec{{{\\mathbf q } } } ) = - \\xi \\sum_{{{\\boldsymbol k}}\\in \\omega } \\log \\big [ \\sum_{n=1}^n \\exp \\big\\ {    -\\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ]    + \\frac{\\mu_4}{2\\mu_3 } \\big ( u[{{\\boldsymbol k } } ] - c_n \\big)^2   \\big ]   \\big\\ }   \\bigg\\ } \\,.\\end{aligned}\\ ] ] due to the pixel independence , we consider the problem at @xmath331 and with the kkt condition ( with the lagrange multiplier @xmath332 > 0 $ ] ) for the inequality constraint , we have @xmath333 }   + \\lambda[{{\\boldsymbol x } } ] \\underbrace { \\frac{\\partial}{\\partial \\vec{q}_a[{{\\boldsymbol x } } ] } \\big\\ { \\abs{\\vec{q}_a[{{\\boldsymbol x}}]}^2 - 1 \\big\\ } }                            _ { = 2 \\vec{q}_a[{{\\boldsymbol x } } ] }   = 0 \\,,~ a = 1 , \\ldots , n \\ , , { { \\boldsymbol x}}\\in \\omega\\end{aligned}\\ ] ] with @xmath334 } & = - \\xi \\frac{\\partial}{\\partial \\vec{q}_a[{{\\boldsymbol x } } ] }   \\bigg\\ { \\log \\big [ \\sum_{n=1}^n    \\exp \\big\\ { -\\frac{1}{\\xi }   \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol x } } ]   + \\frac{\\mu_4}{2\\mu_3 } \\big ( u[{{\\boldsymbol x } } ] - c_n \\big)^2   \\big ] \\big\\ } \\big ]    \\bigg\\ }   \\\\   & = -\\xi ( -\\frac{1}{\\xi } ) \\underbrace { \\frac{\\partial}{\\partial \\vec{q}_a[{{\\boldsymbol x } } ] } \\big\\ { \\text{div}^-_m \\vec{q}_a[{{\\boldsymbol x } } ] \\big\\ } }                                      _ { = ( \\text{div}^-_m)^ * \\frac{\\partial \\vec{q}_a[{{\\boldsymbol x}}]}{\\partial \\vec{q}_a[{{\\boldsymbol x } } ] } = ( -\\nabla^+_m ) \\delta[{{\\boldsymbol x } } ] }       \\underbrace {      \\frac { \\exp \\big\\ { -\\frac{1}{\\xi }             \\big [ \\text{div}^-_m \\vec{q}_a[{{\\boldsymbol x } } ]              + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol x } } ] - c_a \\big)^2 \\big ]             \\big\\ } }           { \\displaystyle \\sum_{n=1}^n \\exp \\big\\ { -\\frac{1}{\\xi } \\big [ \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol x } } ]             + \\frac{\\mu_4}{2 \\mu_3 } \\big ( u[{{\\boldsymbol x } } ] - c_n \\big)^2             \\big ] \\big\\ } }      } _ { = p_a[{{\\boldsymbol x } } ] }   \\\\   & = -\\nabla^+_m p_a[{{\\boldsymbol x } } ] \\,.\\end{aligned}\\ ] ] as in ( [ eq : kkt:1 ] ) , given @xmath335 , we rewrite the kkt condition ( [ eq : kktcondition : dualqproblem ] ) in vector form as @xmath336 + 2 \\lambda[{{\\boldsymbol x } } ] \\vec{q}_a[{{\\boldsymbol x } } ] = 0   ~\\leftrightarrow~   \\lambda[{{\\boldsymbol x } } ] = \\frac{1}{2 } \\abs{\\nabla_m^+ p_a[{{\\boldsymbol x } } ] } \\end{aligned}\\ ] ] and thus @xmath337 ~+~ \\abs{\\nabla_m^+ p_a[{{\\boldsymbol x } } ] } \\vec{q}_a[{{\\boldsymbol x } } ] ~=~ 0 \\,.\\end{aligned}\\ ] ] applying gradient descent and the fixed point algorithm with @xmath338 , we have @xmath339 ~+~ \\abs{\\nabla_m^+ p_a[{{\\boldsymbol x } } ] } \\vec{q}_a^{(t)}[{{\\boldsymbol x } } ] ~=~ - \\frac { \\vec{q}_a^{(t)}[{{\\boldsymbol x } } ] - \\vec{q}_a^{(t-1)}[{{\\boldsymbol x } } ] } { \\tau } \\,,\\end{aligned}\\ ] ] and the solution in matrix form with @xmath340_{m=0}^{m-1}$ ] and @xmath341_{m=0}^{m-1}$ ] is given by @xmath342    [ prop : bilevel : smoothedprimaldualproblem ] given a primal - dual model ( [ eq : bilevelminimization:2:step2:primaldual ] ) in the bilevel - sht , a smoothed primal - dual model is defined as @xmath343^n }    \\underbrace {    \\min _ { \\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {    \\mathcal l^\\text{pd}_{\\xi>0}(\\vec{{{\\mathbf p } } } ; \\vec{{{\\mathbf q } } } ) =     \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_n \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_n \\big\\rangle_{\\ell_2 }    + \\xi \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\log { { \\mathbf p}}_n \\big\\rangle_{\\ell_2 }     \\bigg\\ }    } _ { \\displaystyle = { { \\mathcal l}}^\\text{d}_{\\xi>0 } ( \\vec{{{\\mathbf q } } } ) : = -\\xi \\sum_{{{\\boldsymbol k}}\\in \\omega } \\log \\big [ \\sum_{n=1}^n       \\exp \\big\\ { -\\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } ( u[{{\\boldsymbol k } } ] - c_n)^2 + \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] \\big ] \\big\\ }       \\big ] } \\,.\\ ] ] at iteration @xmath87 , the primal and dual solutions are given by @xmath344\\right ] }                    { \\displaystyle \\sum_{i=1}^n \\exp\\bigg [ - \\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_i \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_i^{(t-1 ) } \\big]\\bigg ]   }    \\\\ &     = \\frac{\\displaystyle \\exp\\left [ - \\frac{1}{\\xi } \\left [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_n \\big)^{.2 } - \\sum_{m=0}^{m-1 } \\left [ \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf q}}_{nm}^{(t-1 ) } { { \\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{nm}^{(t-1 ) } \\right ] \\right]\\right ] }           { \\displaystyle \\sum_{i=1}^n \\exp\\left [ - \\frac{1}{\\xi } \\left [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_i \\big)^{.2 } - \\sum_{m=0}^{m-1 } \\left [ \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf q}}_{im}^{(t-1 ) } { { \\mathbf{d_2}}}+ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d}_{\\mathbf 1}^{\\text t}}}{{\\mathbf q}}_{im}^{(t-1 ) } \\right ] \\right]\\right ]   }    \\,,~~ n = 1 , \\ldots , n \\ , ,   \\end{aligned}\\ ] ] and @xmath345 or @xmath346 }                          { \\displaystyle 1 + \\tau \\left [ \\sum_{m=0}^{m-1 } \\left [ \\cos\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf p}}_n^{(t ) } { { \\mathbf{d}_{\\mathbf 2}^{\\text t}}}+ \\sin\\left(\\frac{\\pi m}{m}\\right ) { { \\mathbf{d_1}}}{{\\mathbf p}}_n^{(t ) } \\right]^{.2 } \\right]^{.\\frac{1}{2 } } }    \\,,~~ n = 1 , \\ldots , n \\,,~ m = 0 , \\ldots , m-1 .   \\end{aligned}\\ ] ]    as in section [ sec : combinedmodel ] , with @xmath347 , a dual - primal model ( [ eq : bilevelminimization:2:step2:primaldual ] ) is recast as the dual model @xmath348^n } \\bigg\\ { \\mathcal l^\\text{d}(\\vec{{{\\mathbf q } } } ) =    \\sum_{{{\\boldsymbol k}}\\in \\omega } \\min \\big\\ {     \\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol k } } ] - c_1 \\big)^2 + \\text{div}^-_m \\vec{q}_1[{{\\boldsymbol k } } ] , \\ldots ,    \\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol k } } ] - c_n \\big)^2 + \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] \\big\\ }      \\bigg\\ } \\,.\\ ] ] due to the min operator in the energy function @xmath349 , the minimization in ( [ eq : bilevelminimization:2:step2:dual : proof ] ) is a non - smooth dual model whose smoothed version ( called a smoothed dual model ) is defined as @xmath350^n } \\left\\ {    \\mathcal l^\\text{d}_{\\xi>0}(\\vec{{{\\mathbf q } } } ) =    - \\xi \\sum_{{{\\boldsymbol k}}\\in \\omega } \\log \\left [ \\sum_{n=1}^n \\exp     \\left\\ { \\frac { -\\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol k } } ] - c_n \\big)^2 - \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] } { \\xi } \\right\\ } \\right ]    \\right\\ } \\ , .",
    "\\end{aligned}\\ ] ] note that @xmath351 . by the smooth log - sum function in convex analysis @xcite and the pixel independence , a smoothed dual energy function in ( [ eq : bilevelminimization:2:step2:smootheddual : proof ] ) can be rewritten as @xmath352 \\in \\mathcal q_{+{{\\boldsymbol k } } } } \\big\\ {    - \\frac{1}{\\xi } \\big\\langle \\vec{p}[{{\\boldsymbol k } } ] \\ , , \\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol k } } ] - \\vec{c } \\big)^2 + \\text{div}^-_m \\vec{q}[{{\\boldsymbol k } } ] \\big\\rangle_{\\ell_2 }    - \\sum_{n=1}^n p_n[{{\\boldsymbol k } } ] \\log p_n[{{\\boldsymbol k } } ]    \\big\\ }     \\\\    & = \\min_{\\vec{{{\\mathbf p } } } \\in \\mathcal q_+ } \\bigg\\ {    \\sum_{n=1}^n \\underbrace { \\sum_{{{\\boldsymbol k}}\\in \\omega } p_n[{{\\boldsymbol k } } ] \\big [ \\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol k } } ] - c_n \\big)^2 + \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol k } } ] \\big ] }                           _ { = \\big\\langle { { \\mathbf p}}_n \\ , , \\frac{\\mu_3}{2 } ( { { \\mathbf u}}- c_n)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_n \\big\\rangle_{\\ell_2 } }    + \\xi \\sum_{n=1}^n \\underbrace { \\sum_{{{\\boldsymbol k}}\\in \\omega } p_n[{{\\boldsymbol k } } ] \\log p_n[{{\\boldsymbol k } } ] }                               _ { = \\big\\langle { { \\mathbf p}}_n \\ , , \\log { { \\mathbf p}}_n \\big\\rangle_{\\ell_2 } }    \\bigg\\ }    \\ , .",
    "\\end{aligned}\\ ] ] thus , we rewrite ( [ eq : bilevelminimization:2:step2:smootheddual : proof ] ) as a smoothed primal - dual model @xmath353^n }    \\bigg\\ {    \\mathcal l^\\text{d}_{\\xi>0}(\\vec{{{\\mathbf q } } } ) =    \\min _ { \\vec{{{\\mathbf p } } } \\in \\mathcal q_+ }     \\big\\ { \\mathcal l^\\text{pd}_{\\xi>0}(\\vec{{{\\mathbf p } } } ; \\vec{{{\\mathbf q } } } ) =     \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_n \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_n \\big\\rangle_{\\ell_2 }    + \\xi \\sum_{n=1}^n \\big\\langle { { \\mathbf p}}_n \\ , , \\log { { \\mathbf p}}_n \\big\\rangle_{\\ell_2 }      \\big\\ }    \\bigg\\ }    \\,.\\ ] ]    * the primal @xmath47-problem : * we apply alm for the equality constraint @xmath354 in a set @xmath355 to the primal @xmath47 problem of ( [ eq : bilevelminimization:2:step2:smoothedprimaldual : proof ] ) as @xmath356 due to the separability in @xmath47 and @xmath357 , the euler lagrange equations of the minimization problem ( [ eq : bilevelminimization:2:step2:smoothedprimaldual : pproblem ] ) w.r.t . a primal variable @xmath358 and the lagrange multiplier @xmath359 are @xmath360      \\end{cases }    \\notag    \\\\",
    "\\leftrightarrow~ &    { { \\mathbf p}}^*_a = \\frac{\\displaystyle \\exp\\bigg [ - \\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_a \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_a \\big]\\bigg ] }                   { \\displaystyle \\sum_{n=1}^n \\exp\\bigg [ - \\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big({{\\mathbf u}}- c_n \\big)^{.2 } + \\text{div}^-_m \\vec{{{\\mathbf q}}}_n \\big]\\bigg ]   }    \\,,~ a = 1 , \\ldots , n.     \\end{aligned}\\ ] ] we observe that @xmath361_{a=1}^n > 0 $ ] , i.e. @xmath362 > 0 , \\forall { { \\boldsymbol k}}\\in \\omega \\,,~ a = 1 , \\ldots , n$ ] .    * the dual @xmath153-problem : * due to the inequality constraint in a convex set @xmath363 , the kkt condition of the minimization in ( [ eq : bilevelminimization:2:step2:smootheddual : proof ] ) ( or in a smoothed primal - dual model ( [ eq : bilevelminimization:2:step2:smoothedprimaldual : proof ] ) ) , with given a lagrange multiplier @xmath364 > 0 \\ , , \\forall { { \\boldsymbol x}}\\in \\omega$ ] yields @xmath365 } ~+~    \\lambda[{{\\boldsymbol x } } ] \\underbrace { \\frac{\\partial}{\\partial \\vec{q}_a[{{\\boldsymbol x } } ] } \\bigg\\ { \\abs{\\vec{q}_a[{{\\boldsymbol x}}]}^2 - 1 \\bigg\\ } }                           _ { \\displaystyle = 2 \\vec{q}_a[{{\\boldsymbol x } } ] }    ~=~ 0 \\,,~~ a = 1 , \\ldots , n \\ , , { { \\boldsymbol x}}\\in \\omega \\ , .",
    "\\end{aligned}\\ ] ] because of the pixel independence @xmath259 , in order to calculate @xmath366 ( in matrix form ) , we consider this derivative in element form at @xmath367 and @xmath368 : @xmath369 }      & = -\\xi ( -\\frac{1}{\\xi } ) \\underbrace { \\frac{\\partial}{\\partial \\vec{q}_a[{{\\boldsymbol x } } ] } \\big\\ { \\text{div}^-_m \\vec{q}_a[{{\\boldsymbol x } } ] \\big\\ } }                                       _ { = \\big ( -\\nabla_m^+ \\big ) \\delta[{{\\boldsymbol x } } ] }       \\frac{\\exp \\big\\ { \\frac { - \\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol x } } ] - c_a \\big)^2 - \\text{div}^-_m \\vec{q}_a[{{\\boldsymbol x } } ] } { \\xi } \\big\\ } }            { \\displaystyle \\sum_{n=1}^n \\exp \\big\\ { \\frac { -\\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol x } } ] - c_n \\big)^2 - \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol x } } ] } { \\xi } \\big\\ } }    \\\\ &    = -\\nabla_m^+ \\left\\ {                  \\frac{\\displaystyle \\exp \\bigg [ -\\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol x } } ] - c_a \\big)^2 + \\text{div}^-_m \\vec{q}_a[{{\\boldsymbol x } } ] \\big ] \\bigg ]                   }                  { \\displaystyle \\sum_{n=1}^n \\exp \\bigg [ -\\frac{1}{\\xi } \\big [ \\frac{\\mu_3}{2 } \\big(u[{{\\boldsymbol x } } ] - c_n \\big)^2 + \\text{div}^-_m \\vec{q}_n[{{\\boldsymbol x } } ] \\big ] \\bigg ] }                  \\right\\ }      \\\\ &    \\stackrel{(\\ref{eq : bilevelminimization:2:step2:smoothedprimaldual : pproblem : solution})}{= }    -\\nabla_m^+ p_a[{{\\boldsymbol x } } ] \\ , .",
    "\\end{aligned}\\ ] ] as in section [ sec : combinedmodel ] and @xcite , the kkt condition ( [ eq : kktcondition ] ) ( in vector form with @xmath370_{m=1}^m$ ] ) can be rewritten as @xmath371 ~+~ \\abs{\\nabla_m^+ p_a[{{\\boldsymbol x } } ] } \\vec{q}_a[{{\\boldsymbol x } } ] ~=~ 0 \\,,~~ a = 1 , \\ldots , n    \\end{aligned}\\ ] ] for @xmath7 .",
    "applying gradient descent and the fixed point algorithm , we have @xmath371 ~+~ \\abs{\\nabla_m^+ p_a[{{\\boldsymbol x } } ] } \\vec{q}_a^{(t)}[{{\\boldsymbol x } } ] ~=~ - \\frac { \\vec{q}_a^{(t)}[{{\\boldsymbol x } } ] - \\vec{q}_a^{(t-1)}[{{\\boldsymbol x } } ] } { \\tau }    \\ , ,   \\end{aligned}\\ ] ] and the solution in matrix form with @xmath340_{m=0}^{m-1}$ ] and @xmath341_{m=0}^{m-1}$ ] is given by @xmath372"
  ],
  "abstract_text": [
    "<S> segmentation remains an important problem in image processing . for homogeneous ( piecewise smooth ) images , </S>",
    "<S> a number of important models have been developed and refined over the past several decades . </S>",
    "<S> however , these models often fail when applied to the substantially larger class of natural images that simultaneously contain regions of both texture and homogeneity . </S>",
    "<S> this work introduces a bi - level constrained minimization model for simultaneous multiphase segmentation of images containing both homogeneous and textural regions . </S>",
    "<S> we develop novel norms defined in different functional banach spaces for the segmentation which results in a non - convex minimization . </S>",
    "<S> finally , we develop a generalized notion of segmentation delving into approximation theory and demonstrating that a more refined decomposition of these images results in multiple meaningful components . </S>",
    "<S> both theoretical results and demonstrations on natural images are provided .    _ </S>",
    "<S> keywords : image decomposition , variational calculus , image denoising , _ + _ feature extraction , image segmentation _ </S>"
  ]
}