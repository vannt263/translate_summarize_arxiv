{
  "article_text": [
    "neural networks @xcite has been an important focus of research area in not only neural networks field but also circit and system theory since early 1980s whose applications vary from combinatorial optimization ( e.g. @xcite , @xcite among many others ) including travelling salesman problem ( e.g. @xcite , @xcite among others ) to image restoration ( e.g. @xcite ) , from various control engineering optimization problems including robotics ( e.g. @xcite among others ) to associative memory systems ( e.g. @xcite , @xcite among others ) , etc . for a tutorial and further references about hopfield nn , see e.g. @xcite and @xcite .    in this paper , we present and analyse two hopfield - like nonlinear networks , called salu - sir and dsalu - sir in continuous - time and discrete - time respectively .",
    "the proposed networks consist of linear and nonlinear parts : an autonomous linear system with a symmetric weight matrix , which is designed to be unstable , and a nonlinear function stabilizing the whole network .",
    "the underlying linear system of the proposed continuous time - network is    @xmath7    where @xmath8 shows the derivative of @xmath9 with respect to time , i.e. , @xmath10 , and @xmath11 is called system matrix or weight matrix .",
    "we define the following system variables denoted as @xmath12 , @xmath13    where @xmath14 represents the @xmath15th neuron and @xmath16 is the @xmath17th element of matrix @xmath11 . in this paper , we assume @xmath18 for the sake of brevity .    we observe that the manipulated state variable @xmath19 of eq.([eq : cira ] ) resembles the well - known signal - to - interference - ratio ( sir ) definition in telecommunicaions engineering , which can be found in any related texbooks : signal - to - interference ratio ( sir ) is an important entity in commucations engineering which indicates the quality of a link between a transmitter and a receiver in a multi transmitter - receiver environment ( see e.g. @xcite , @xcite ) . for example , let @xmath20 represent the number of transmitters and receivers using the same channel .",
    "then the received sir is given by ( e.g. @xcite )    @xmath21    where @xmath22 is the transmission power of transmitter @xmath15 , @xmath23 is the link gain from transmitter @xmath24 to receiver @xmath15 ( e.g. in case of wireless communications , @xmath23 involves path loss , shadowing , etc ) and @xmath25 is the receiver noise at receiver @xmath15 . typically in communication systems like cellular radio systems , every transmitter tries to optimize its power @xmath22 such that the received sir ( i.e. , @xmath26 ) in eq.([eq : cir ] ) is kept at a target sir value , @xmath27 .",
    "it is well - known that the eigenvalues of the system matrix solely determine the stability of a linear dynamic networks .",
    "if any of the eigenvalues is positive , then the system is unstable . designing the linear part of the network to have positive eigenvalue(s ) , we show , in this paper , that the defined `` sir '' in eq.([eq : cira ] ) for any state appraches",
    "asymptotically to a constant , called `` ultimate sir '' , which is a function of the diagonal entry of the system matrix and its maximum eigenvalue .",
    "the nonlinear part of the network uses this result to stabilize the system .",
    "finally , the proposed network is shown to exhibit features which are generally attributed to hopfield networks . taking the sign of the converged states ,",
    "the proposed network is applied to binary associative memory systems design .",
    "the paper is organized as follows : the  ultimate sir `` is analysed for the underlying linear dynamic part of the network with a symmetric weight matrix in section [ section : usir ] .",
    "section [ section : proposednet ] presents the stabilized network by the ultimate ' ' sir \" to be used as a binary associative memory system .",
    "simulation results are presented in section [ section : simuresults ] followed by the conclusions in section [ section : conclusions ] .",
    "in this section , we analyse the underlying linear system of the proposed network in both continuous - time and discrete - time respectively .      in this paper , we examine the case where weight matrix @xmath11 in eq.([eq : diff_linear_trad ] ) is a real symmetric matrix whose diagonal elements are equal to a constant .",
    "so , the linear system in ( [ eq : diff_linear_trad ] ) can be written as follows    @xmath28    where @xmath29 ,   \\quad \\quad   \\textrm{and } \\nonumber \\\\ { \\mathbf w } = \\left [ \\begin{array}{c c c c } 0   &    w_{12 }    & \\ldots   &   w_{1n } \\\\ w_{21 }      &    0 & \\ldots   &   w_{2n } \\\\ \\vdots &      & \\ddots   &   \\vdots \\\\ w_{n1 }     &    w_{n2 }    & \\ldots   &   0 \\end{array } \\right ] % \\quad \\quad % { \\mathbf b } = % \\left [ % \\begin{array}{c } % b_1 \\\\ % b_2 \\\\ % \\vdots \\\\ % b_n % \\end{array } % \\right ] \\label{eq : mata_w_b}\\end{aligned}\\ ] ]    where @xmath30 .    in eq.([eq : mata_w_b ] ) , the design parameter @xmath2 , which corresponds to @xmath31 in the `` sir '' ( @xmath32 ) definition in eq.([eq : cira ] ) , is positive , @xmath33 .",
    "for the sake of brevity , we assume that the @xmath34 in the analysis . it s well known that desigining the weight matrix @xmath35 as a symmetric one yields that all eigenvalues are real ( see e.g. @xcite ) , which we assume throughout the paper for the sake of brevity of its analysis .",
    "_ proposition 1 : _",
    "let s assume that the linear dynamic network of eq.([eq : diff_linear ] ) with a real symmetric @xmath36 in ( [ eq : mata_w_b ] ) has positive eigenvalue(s ) . if @xmath33 is chosen such that it s smaller than the maximum ( positive ) eigenvalue of @xmath36 , then    1 .",
    "the defined `` sir '' ( @xmath32 ) in eq.([eq : cira ] ) for any state @xmath15 asymptotically converges to the following constant as time evolves for any initial vector @xmath37 which is not completely perpendicular to the eigenvector corresponding to the largest eigenvalue of @xmath36 .",
    "is completely perpendicular to the eigenvector of the maximum ( positive ) eigenvalue of @xmath36 or not .",
    "if this is the case , then this can easily be overcome by introducing a small random number to @xmath37 so that it s not completely perpendicular to the mentioned eigenvector . ] + @xmath38 + where @xmath4 is the maximum ( positive ) eigenvalue of the weight matrix @xmath36 .",
    "there exists a finite time constant @xmath39 for a given small positive number @xmath40 such that + @xmath41^t$ ] and @xmath42^t$ ] and @xmath43 shows a vector norm .    defining the following matrix series equation @xmath44    where @xmath45 shows the factorial , and @xmath6 represents the identity matrix of right dimension , it s well known that the solution of the autonomous dynamic linear system in eq.([eq : diff_linear ] ) is ( see e.g. @xcite ) :    @xmath46    where @xmath37 shows the initial state vector at time zero .",
    "so , the state transition matrix of the linear system of eq.([eq : diff_linear ] ) is @xmath47 in eq .",
    "( [ eq : sttrma ] ) ( see e.g. @xcite ) .",
    "let us first examine the powers of the matrix ( @xmath48 ) in ( [ eq : sttrma ] ) in terms of matrix @xmath49 and the eigenvectors of matrix @xmath36 .",
    "first let s remind some spectral features of the symmetric real square matrices that we use in the proof later on :    it s well known that any symmetric real square matrix can be decomposed into    @xmath50    where @xmath51 and @xmath52 show the ( real ) eigenvalues and the corresponding orthonormal eigenvectors ( see e.g. @xcite ) , i.e. , @xmath53    where @xmath54 . defining the outer - product matrices of the eigenvectors",
    "@xmath51 as @xmath55 in eq .",
    "[ eq : symw ] gives    @xmath56    the matrix ( @xmath57 ) can be written using eq.([eq : symw ] ) as follows    @xmath58    where @xmath2 is the diagonal element of matrix @xmath49 , and where @xmath59 is equal to    @xmath60    the matrix @xmath61 can be written using eq.([eq : symw])-([eq : symw_v ] ) as    @xmath62    where @xmath63 is equal to    @xmath64    similarly , the matrix @xmath65 is obtained as    @xmath66    where @xmath67 is    @xmath68    for @xmath69 ,    @xmath70    where @xmath71 is    @xmath72",
    "so , when we continue , we observe that the @xmath73th power of the matrix @xmath74 is obtained as    @xmath75    where @xmath76 for @xmath77 is equal to    @xmath78    in what follows , we summarize the findings about the auxiliary variable @xmath76 from eq.([eq : beta1 ] ) and ( [ eq : beta_k ] ) :    @xmath79    defining @xmath80 , we write the equation eq.([eq : betasumk2 ] ) as follows    @xmath81    defining the sum @xmath82",
    "@xmath83    the eq.([eq : betazeta ] ) is written as    @xmath84    summing @xmath82 with @xmath85 yields @xmath82 as follows    @xmath86    from eq.([eq : betazeta1 ] ) and ( [ eq : s(k ) ] )    @xmath87    from eq.([eq : sttrma ] ) , ( [ eq : wk ] ) and ( [ eq : betazeta2 ] ) , the state transition matrix is    @xmath88    the first phrase of eq.([eq : terms2 ] ) is equal to the exponential matrix series of @xmath89 , i.e. ,    @xmath90    the second phrase in eq.([eq : terms2 ] ) , where the sums over @xmath15 and @xmath73 are interchangable , is obtained using eq.([eq : betazeta2 ] ) as    @xmath91    so , let s put the eigenvalues into two sets : let those eigenvalues which are smaller that @xmath2 , belong to set @xmath92 where @xmath93 is the length of the set ; and let those eigenvalues which are larger than @xmath2 belong to set @xmath94 where @xmath95 is the length of the set .",
    "using eqs .",
    "( [ eq:1stterm])-([eq : betav2 ] ) and the definition @xmath96 , we write the state transition matrix in eq.([eq : terms ] ) as follows    @xmath97    where    @xmath98    and    @xmath99    we call the matrices @xmath100 and @xmath101 in ( [ eq : m1 ] ) and ( [ eq : m2 ] ) as transitory phase part and steady phase part , respectively , of the state transition matrix .    in eq.([eq : m1 ] ) , because @xmath33 and @xmath102 are finite numbers , the matrix @xmath100 exponentially vanishes ( approaches to zero matrix ) and there exists a finite time constant @xmath103 for a given small positive number @xmath104 such that    @xmath105 shows a matrix norm . from eq .",
    "( [ eq : stm_m2 ] ) and ( [ eq : m1_eps1 ] ) , the @xmath100 affects only the transitory phase , and what shapes the steady state behavior is merely @xmath106 .",
    "so , let s examine the steady phase solution in the following :    the steady phase solution , denoted as @xmath107 is obtained from eq.([eq : solution ] ) and ( [ eq : stm_m2 ] ) as    @xmath108    let s define the interference vector @xmath109 as    @xmath110    using eq.([eq : symw ] ) in ( [ eq : j_intrf ] ) and the orthonormal features in ( [ eq : symw_v ] ) yields    @xmath111    defining @xmath112 , we rewrite the eq.([eq : solutionms ] ) and ( [ eq : j_intrf_b ] ) , respectively , as    @xmath113    and    @xmath114    in eq.([eq : solutionms_u ] ) and ( [ eq : j_intrf_u ] ) , we assume that the @xmath115 corresponding to the eigenvector of the largest eigenvalue is different than zero vector .",
    "this means that we assume in the analysis here that @xmath37 is not completely perpendicular to the mentioned eigenvector .",
    "this is something easy to check in advance .",
    "if it is the case , then this can easily be overcome by introducing a small random number to @xmath37 so that it s not completely perpendicular to the mentioned eigenvector .",
    "taking eq.([eq : m1_eps1 ] ) into account and dividing the vector @xmath107 of eq.([eq : solutionms_u ] ) to * j*(t ) of eq.([eq : j_intrf_u ] ) elementwise and comparing the outcome with the `` sir '' ( @xmath116 ) definition in eq.([eq : cira ] ) where @xmath117 results in    @xmath118    where @xmath119 is the @xmath15th element of the vector @xmath120 . from the analysis above",
    ", we observe that    1 .",
    "if there is only one positive eigenvalue and it s a multiple one , denoted as @xmath121 ( i.e. @xmath122 ) , then it s seen from ( [ eq : theta_xj_i2 ] ) that + @xmath123 2 .   similarly , if there is only one positive eigenvalue and it s a single one , shown as @xmath121 , ( i.e. , @xmath124 ) , then eq.([eq : theta_c ] ) holds .",
    "if there are more than two different ( positive ) eigenvalues and the largest positive eigenvalue is single ( not multiple ) , then we observe from ( [ eq : theta_xj_i2 ] ) that the largest ( positive ) eigenvalue dominates the dynamics of eq.([eq : theta_xj_i2 ] ) as time evolves because of the fact that a relatively small increase in the power of the exponential causes exponential increase as time evolves .",
    "this can be seen as follows : + let s show the two largest ( positive ) eigenvalues as @xmath4 and @xmath125 respectively and the difference between them as @xmath126 .",
    "so , @xmath127 . we define the following ratio + @xmath128 + in eq.([eq : expdeltal2 ] ) , because @xmath129 is a finite number , the @xmath130 exponentially vanishes ( approaches to zero ) , as will be depicted in fig .",
    "[ fig : ratiodeltal ] , and there exists a finite time constant @xmath131 for a given small positive number @xmath132 such that + @xmath133 + = 24.0em + so , the @xmath130 in eq.([eq : expdeltal ] ) is obtained as a multiplier in the ratio of the two greatest terms of the sum in both nominator and denominator .",
    "we plot the ratio @xmath130 in fig .",
    "[ fig : ratiodeltal ] for some different @xmath126 values .",
    "the figure [ fig : ratiodeltal ] shows that the term related to the @xmath4 dominates the sum of the nominator and that of the denominator respectively .",
    "this observation implies from eq.([eq : theta_xj_i2 ] ) that + @xmath134 4 .   if the largest positive eigenvalue in case 3 above is a multiple eigenvale , then , similarly , the corresponding terms in the sum of the nominator and that of the demoninator become dominant , which implies from eq.([eq : theta_xj_i2 ] ) that @xmath135 exponentially converges to @xmath136 as time evolves .    using the observations 1 to 4 , and the `` sir '' definition in eq.([eq : cira ] ) , we conclude from eq.([eq : theta_xj_i ] ) , ( [ eq : theta_maxl ] ) and ( [ eq : theta_maxl2 ] ) that for any initial vector @xmath37 which is not completely perpendicular to the eigenvector corresponding to the largest eigenvalue of @xmath36 ,    @xmath137    which completes the first part of the proof .",
    "furthermore , from eq .",
    "( [ eq : m1_eps1 ] ) , ( [ eq : kt_eps2 ] ) and ( [ eq : cira_sp ] ) we conclude that there exists a finite time constant @xmath39 for a given small positive number @xmath40 such that    @xmath138^t$ ] and @xmath42^t$ ] , which completes the proof .",
    "_ definition : _ system - specific ultimate sir value : in proposition 1 , we showed that the sir in ( [ eq : cira ] ) for every state in the autonomous linear dynamic networks in eq.([eq : diff_linear ] ) converges to a constant value as time goes to infinity .",
    "we call this converged constant value as `` system specific ultimate sir '' and denote as @xmath139 :    @xmath140    where @xmath141 is the design parameter and @xmath4 is the maximum ( positive ) eigenvalue of matrix @xmath36 .      in this subsection , we analyse the defined `` sir '' for the the underlying linear part of the proposed discrete - time autonomous network which is obtained by discretizing the continuous - time system of eq.([eq : diff_linear ] ) by using well - known euler method :    @xmath142    where @xmath6 is the identity matrix , @xmath2 is a positive real number , @xmath143 and @xmath36 is as eq.([eq : mata_w_b ] ) , @xmath144 shows the state vector at step @xmath73 , and @xmath145 is the step size .",
    "_ proposition 2 : _    in the autonomous discrete - time linear network of eq.([eq : diff_linear_discrete ] ) , let s assume that the spectral radius of the system matrix @xmath146 is larger than 1 .",
    "( this assumption is equal to the assumption that @xmath36 has positive eigenvalue(s ) and @xmath33 is chosen such that @xmath147 , where @xmath4 is the maximum ( positive ) eigenvalue of @xmath36 ) .",
    "if @xmath148 is chosen such that @xmath149 , then    1 .",
    "the defined `` sir '' @xmath150 in eq.([eq : cira ] ) for any state @xmath15 asymptotically converges to the `` ultimate sir '' constant in ( [ eq : theta_const ] ) as time step evolves for any initial vector @xmath37 which is not completely perpendicular to the eigenvector corresponding to the largest eigenvalue of @xmath36 .",
    "2 .   there exists a finite step number @xmath151 for a given small positive number @xmath152 such that + @xmath153^t$ ] and @xmath42^t$ ] .    from eq .",
    "( [ eq : diff_linear_discrete ] ) , it s obtained @xmath154    where @xmath37 shows the initial state vector at step zero .",
    "let us first examine the powers of the matrix @xmath155 in ( [ eq : solution_ds ] ) in terms of matrix @xmath49 and the eigenvectors of matrix @xmath36 : it s well known that any symmetric real square matrix can be decomposed into    @xmath156    where @xmath51 and @xmath52 show the ( real ) eigenvalues and the corresponding eigenvectors and the eigenvectors @xmath52 are orthonormal ( see e.g. @xcite ) , i.e. ,    @xmath157    let s define the outer - product matrices of the eigenvectors @xmath51 as @xmath158 ; and , furthermore , the matrix @xmath159 as    @xmath160    which is obtained using eq.([eq : symw_ds ] ) as @xmath161    where @xmath141 , @xmath162 , and where @xmath59 is equal to    @xmath163    the matrix @xmath164 can be written as    @xmath165    where @xmath63 is equal to    @xmath166    similarly , the matrix @xmath167 can be written as    @xmath168    where @xmath67 is equal to    @xmath169",
    "so , @xmath170 can be written as    @xmath171    where @xmath71 is equal to    @xmath172    so , at step @xmath73 , the matrix @xmath173 is obtained as    @xmath174    where @xmath76 is equal to    @xmath175    using eq.([eq : beta1_ds ] ) and ( [ eq : beta_i_k ] ) , the @xmath76 is obtained as    @xmath176    defining @xmath177 , we obtain    @xmath178    writing eq.([eq : xy ] ) in eq.([eq : betasumk_ds ] ) gives    @xmath179    where @xmath82 is    @xmath180    summing @xmath181 with @xmath182 yields    @xmath183    from eq.([eq : betazeta_ds ] ) , ( [ eq : series_ds ] ) and ( [ eq : s(k)_ds ] ) , we obtain    @xmath184    using the definition @xmath185 in eq.([eq : betazeta1_ds ] ) gives    @xmath186    from eq.([eq : w_k ] ) and eq.([eq : betazeta2_ds ] ) ,    @xmath187    let s put the @xmath20 eigenvalues of matrix @xmath36 into two groups as follows : let those eigenvalues which are smaller that @xmath2 , belong to set @xmath92 where @xmath93 is the length of the set ; and let those eigenvalues which are larger than @xmath2 belong to set @xmath94 where @xmath95 is the length of the set .",
    "we write the matrix @xmath188 in eq.([eq : w_kfromzeta ] ) using this eigenvalue grouping    @xmath189    where    @xmath190    and    @xmath191    we call the matrices @xmath192 and @xmath193 in ( [ eq : m1_ds ] ) and ( [ eq : m2_ds ] ) as transitory phase part and steady phase part , respectively , of the matrix @xmath194 .",
    "it s observed from eq.([eq : m1_ds ] ) that the @xmath192 converges to zero matrix as time step number evolves because relatively small step number @xmath145 is chosen such that @xmath195 and @xmath196 .",
    "therefore , there exists a finite time step number @xmath197 for a given small positive number @xmath198 such that    @xmath199 ) and ( [ eq : stm_m ] ) ) , what shapes the steady state behavior of the system in eq.([eq : solution_ds ] ) is merely the @xmath193 in eq.([eq : m2_ds ] ) .",
    "so , the steady phase solution is obtained from eqs.([eq : solution_ds ] ) , ( [ eq : m ] ) and ( [ eq : stm_m])-([eq : m2_ds ] ) using the above observations as follows    @xmath200    let s define the interference vector , @xmath201 as    @xmath202    using eq.([eq : symw_ds ] ) in ( [ eq : j_intrf_ds ] ) and the orthonormal features in ( [ eq : v_ortnor_ds ] ) yields    @xmath203    first defining @xmath204 , and @xmath205 , then dividing vector @xmath206 of eq.([eq : solutionms2_ds ] ) to @xmath201 of eq.([eq : j_intrf_b_ds ] ) elementwise and comparing the outcome with the `` sir '' definition in eq.([eq : cira ] ) results in    @xmath207    in eq.([eq : theta_xj_i2_ds ] ) , we assume that the @xmath208 which corresponds to the eigenvector of the largest positive eigenvalue is different than zero vector .",
    "this means that we assume in the analysis here that @xmath37 is not completely perpendicular to the mentioned eigenvector .    from the analysis above",
    ", we observe that    1 .",
    "if there is only one positive eigenvalue which is greater than @xmath2 and it s a multiple one , denoted as @xmath209 , then it s seen from ( [ eq : theta_xj_i2_ds ] ) that + @xmath210 2 .",
    "similarly , if there is only one positive eigenvalue which is larger than @xmath2 and it s a single one , shown as @xmath209 , then eq.([eq : theta_c_ds ] ) holds .",
    "if there are more than two different ( positive ) eigenvalues and the largest positive eigenvalue is single ( not multiple ) , then we see from ( [ eq : theta_xj_i_ds ] ) that the term related to the largest ( positive ) eigenvalue dominates the sum of the nominator .",
    "same observation is valid for the sum of the denominator .",
    "this is because a relatively small increase in @xmath125 causes exponential increase as time step evolves , which is shown in the following : let s show the two largest ( positive ) eigenvalues as @xmath4 and @xmath125 respectively and the difference between them as @xmath126 .",
    "so , @xmath127 . let s define the following ratio between the terms related to the two highest eigenvalues in the nominator + @xmath211 + where + @xmath212 + in eq.([eq : expdeltal_ds ] ) , because @xmath129 , there exists a finite time step number @xmath213 for a given small positive number @xmath198 such that + @xmath214 + from eq.([eq : expdeltal_ds ] ) and ( [ eq : expdeltal_d ] ) , because @xmath129 and @xmath215 , + @xmath216 + and there exists a finite time step number @xmath213 for a given small positive number @xmath217 such that + @xmath218 in fig .",
    "[ fig : ratiodeltal_ds ] for some different @xmath126 values and for a typical @xmath219 value .",
    "the figure [ fig : ratiodeltal_ds ] and eq.([eq : k_dn ] ) implies that the terms related to the @xmath4 dominate the sum of the nominator and that of the denominator respectively .",
    "so , from eq.([eq : theta_xj_i2_ds ] ) and ( [ eq : xi ] ) , + @xmath220 4 .",
    "if the largest positive eigenvalue in case 3 above is a multiple eigenvale , then , similarly , the corresponding terms in the sum of the nominator and that of the demoninator become dominant , which implies from eq.([eq : theta_xj_i2_ds ] ) , ( [ eq : expdeltal_ds ] ) and ( [ eq : expdeltal_d ] ) that @xmath221 converges to @xmath136 as step number increases .    using the observations 1 to 4 , eq.([eq : nmtp_eps3 ] ) , the `` sir '' definition in eq.([eq : cira ] ) , eq.([eq : theta_xj_i_ds ] ) and ( [ eq : theta_xj_i2_ds ] ) , we conclude that    @xmath222    where @xmath223 and @xmath4 is the largest ( positive ) eigenvalue of the matrix * w * , which completes the first part of the proof .",
    "furthermore , from eq .",
    "( [ eq : nmtp_eps3 ] ) , ( [ eq : k_n_eps4 ] ) and ( [ eq : cira_sp_ds ] ) , we conclude that there exists a finite time constant @xmath151 for a given small positive number @xmath152 such that    @xmath224^t$ ] and @xmath42^t$ ] , which completes the proof .",
    "do the results of the ultimate sir analysis in section [ section : usir ] above have any practical meanings ?",
    "our answer is yes . in this section ,",
    "we propose two hopfield - like networks in continuous and discrete - time domain respectively where the `` system - specific ultimate sir '' is used to stabilize the system .      defining the following @xmath225 function ,    @xmath226    we propose the following dynamic network ,    @xmath227    where @xmath228^t$ ] and @xmath42^t$ ] , and @xmath229 is the output of the network .",
    "we call the network in eqs.([eq : gx_fn])-([eq : sal - usir_y ] ) as stabilized autonomous linear networks by ultimate `` sir '' ( sal - u``sir '' ) .",
    "= 24.0em    _ proposition 3 : _    the proposed dynamic network of eqs.([eq : sal - usir_x])-([eq : sal - usir_y ] ) with the weight matrix @xmath230 as defined in eq .",
    "( [ eq : mata_w_b ] ) is stable for any initial condition @xmath37 .    if all the eigenvalues of the symmetrix matrix @xmath230 as defined in eq .",
    "( [ eq : mata_w_b ] ) are negative , then it s well known from linear systems theory that the states go to zero exponentially for any initial vector @xmath37 ( see e.g. @xcite ) .",
    "otherwise , if there exists positive eigenvalue(s ) of @xmath230 , which is the case in our design , then the proposition 1 above proves for the underlying linear system of ( [ eq : sal - usir_x ] ) that i ) the defined sir in eq.([eq : cira ] ) for any state @xmath15 ( @xmath231 ) converges , as time evolves , to the constant system - specific ultimate sir value in eq.([eq : theta_const ] ) for any initial vector @xmath37 , and ii ) there exists a finite time constant @xmath39 for a given small positive number @xmath232 such that @xmath233 .",
    "so , the function @xmath234 stabilizes the system within the @xmath39 seconds , i.e. , once @xmath235 is met .",
    "so , the system is stable .    from the analysis above for symmetric @xmath236 and positive @xmath237",
    ", we observe that    1 .",
    "the sal - u``sir '' does not show oscilatory behaviour because all eigenvalues are real ( i.e. , no imaginary part ) , and at least one eigenvalue is positive , which is assured by choosing the matrix @xmath237 accordingly .",
    "the transition phase of the `` unstable '' linear network is shaped by the initial state vector and the phase space characteristics formed by the eigenvectors .",
    "the network is stabilized by the function @xmath234 once the network has passed the transition phase .",
    "the output of the network then is formed taking the sign of the converged states .",
    "whether the state converges to a plus or minus value is dictated by the phase space shaped by the eigenvectors of @xmath236 and the initial vector @xmath238 .    from observation 1 and 2 above",
    ", we see that choosing the positive matrix @xmath237 such that the matrix @xmath230 has positive eigenvalues makes the proposed sal - u``sir '' exhibit similar features as the hopfield network does .",
    "the computer simulations in section [ section : simuresults ] shows the performance of the proposed network as compared to the hopfield network in some simple associative memory systems examples .",
    "as far as the possible circuital implementations of the proposed network is concerned , a further research is needed on especially how the nonlinear function @xmath234 could be implemented on the circuit . in this paper",
    ", we mainly focus on the analysis part , and the circuital implementation part is left as a future research topic . however , in order to give an insight , in what follows , we propose the following simplified network for numerical implementation purposes :    it s well known that a linear dynamic network like ( [ eq : diff_linear ] ) can be implemented by rc ( resistance - capacitance ) circuits .",
    "corresponding rc dynamic network is given as follows :    @xmath239 =    \\left [ \\begin{array}{c c c c } r_{11 }   &   r_{12 }    & \\ldots   &   r_{1n } \\\\ r_{21 }      &    0 & \\ldots   &   r_{2n } \\\\",
    "\\vdots &      & \\ddots   &   \\vdots \\\\ r_{n1 }     &    r_{n2 }    & \\ldots   &   0 \\end{array } \\right ] \\left [ \\begin{array}{c } v_{c_1 } \\\\",
    "v_{c_2 } \\\\ \\vdots \\\\ v_{c_n } \\end{array } \\right]\\ ] ]    where @xmath240 represents the capacitance , @xmath241 shows the voltage of the capacitance @xmath242 , which is the state @xmath15 of the network and @xmath243 is the resistance .",
    "from eq.([eq : diff_linear_trad ] ) , ( [ eq : mata_w_b ] ) and ( [ eq : rc_dyn ] ) ,    @xmath244    so , we sketch a simplified numerical implementation of the proposed sal - usir  in fig . [ fig : sal - usir ] , omitting the considerations on circuits , where the function @xmath234 is represented by a switch ( `` ultimate sir checking '' ) .",
    "the proposed autonomous network in discrete - time , called dsal - usir ( discrete stabilized autonomous linear networks by ultimate `` sir '' ) is given as follows    @xmath245    where @xmath36 is defined by eq.([eq : mata_w_b ] ) , the function @xmath234 is defined by eq.([eq : gx_fn ] ) , @xmath145 is step size , @xmath6 is identity matrix and @xmath33 as in eq.([eq : diff_linear_discrete ] ) , @xmath228^t$ ] and @xmath42^t$ ] , and @xmath246 is the output of the network .",
    "_ proposition 4 : _    the proposed discrete - time networks , dsal - usir  , in eq.([eq : sal - usir1 ] ) and ( [ eq : sal - usir1n ] ) is stable for any initial vector @xmath37 .",
    "if the spectral radius of the system matrix @xmath146 is smaller than 1 , then it s well known from the discrete - time linear systems theory that the states go to zero exponentially for any initial vector @xmath37 ( see e.g. @xcite ) .",
    "if , on the other hand , the spectral radius is larger than 1 , which is the case in our design , then the proposition 2 above proves for the underlying linear system ( [ eq : diff_linear_discrete ] ) that i ) the defined `` sir '' @xmath150 in eq.([eq : cira ] ) for any state @xmath15 asymptotically converges to the `` system - specific ultimate sir '' constant in ( [ eq : theta_const ] ) as time step evolves for any initial vector @xmath37 ii ) there exists a finite step number @xmath151 for a given small positive number @xmath152 such that @xmath247 .",
    "so , the function @xmath234 stabilizes the system within the @xmath151 steps , i.e. , once @xmath248 is met .",
    "so , the system is stable .    as far as the design of weight matrix @xmath236 and @xmath2",
    "is concerned , we propose to use the following method which is based on the well known hebb - learning rule @xcite .",
    "let s assume that @xmath249 desired prototype vectors , @xmath250 , are given from @xmath251 .",
    "the proposed method is based on well - known hebb - learning @xcite as follows :    step 1 : calculate the sum of outer products of the prototype vectors ( hebb rule , @xcite )    @xmath252    step 2 : determine the diagonal matrix @xmath253 and @xmath254 as follows :    @xmath255    where @xmath256 is a real number and    @xmath257    where @xmath258 shows the entries of matrix @xmath259 , @xmath20 is the dimension of the vector @xmath260 and @xmath249 is the number of the prototype vectors ( @xmath261 ) . from ( [ eq : hebbqd ] ) , @xmath262 in eq.([eq : rfromhebb ] ) since @xmath263 is from @xmath251 .",
    "if the desired prototype vectors are orthogonal , then it can be shown , using the steps of the proofs of prepositions 1 and 3 for continuous and discrete - time respectively , that the `` system specific ultimate sir '' be @xmath264 .",
    "we take the same examples as in @xcite for comparison reasons and for the sake of brevity .    in this section ,",
    "we apply the the proposed networks sal - usir  and dsal - usir  , in continuous and discrete - time respectively , to associate memory systems design , and present their simulation results as compared to those of corresponding hopfield networks .",
    "the weight matrices of the proposed networks and the hopfield networks are designed by the outer - products ( hebb learning @xcite ) learning rule described in section [ subsection : hebbbasedlearning ] .      in this section",
    ", we present two examples , one with 8 neurons and one with 16 neurons , in example 1 and 2 respectively .",
    "the proposed dsalu - sir network is given by eqs .",
    "( [ eq : sal - usir_x ] ) and ( [ eq : sal - usir_y ] ) .",
    "the hopfield network @xcite , used as the reference network , is given by    @xmath265    where @xmath36 is the weight matrix and @xmath266 is the state at time @xmath267 , @xmath268 , @xmath269^t$ ] , the @xmath270 is a sigmoid function , i.e. , @xmath271 , where @xmath272 .",
    "_ example 1 : _    this example is taken from example 1 in @xcite . in the design , @xmath273 and @xmath256 is chosen as -2 , and @xmath274 .",
    "the desired prototype vectors are given in the raws of matrix @xmath275 as follows ,    @xmath276\\ ] ]    the weight matrix , using the design rule in section [ subsection : hebbbasedlearning ] , is obtained as    @xmath277 ,    \\label{eq : mata_w_b_ex1 } % \\quad \\quad % { \\mathbf b } = { \\mathbf 0}\\end{aligned}\\ ] ]    the figure [ fig : salusir_ex1_percentage ] shows the percentages of correctly recovered desired patterns for all possible initial conditions @xmath278 , in the proposed salu-``sir '' as compared to traditional hopfield network .",
    "= 24.0em    let @xmath279 show the number of prototype vectors and @xmath280 , ( such that @xmath281 ) , represent the combination @xmath282 , which is equal to @xmath283 , where @xmath284 shows factorial . in our simulation ,",
    "the prototype vectors are from @xmath285 as seen above . for initial conditions ,",
    "we alter the sign of @xmath286 states where @xmath286=0 , 1 , 2 , 3 and 4 , which means the initial condition is within @xmath286-hamming distance from the corresponding prototype vector .",
    "so , the total number of different possible combinations for the initial conditions for this example is 24 , 84 and 168 for 1 , 2 and 3-hamming distance cases respectively , which could be calculated by @xmath287 , where @xmath288 and @xmath289 1 , 2 and 3 .",
    "as seen from figure [ fig : salusir_ex1_percentage ] , the performance of the proposed network salu``sir '' is the same as that of the continuous hopfield network for 1-hamming distance case ( @xmath290 for both networks ) and is slightly higher than that of the hopfield network for 2 distance case .",
    "_ example 2 : _    this example is taken from example 2 in @xcite .",
    "the desired prototype vectors as well as the obtained weight matrix @xmath36 are shown in appendix i. the other network paramaters are chosen as in example 1 : @xmath291 and @xmath292 .",
    "the figure [ fig : salusir_ex2_percentage ] shows the percentages of correctly recovered desired patterns for all possible initial conditions @xmath293 , in the proposed salu``sir '' as compared to the traditional hopfield network .",
    "= 24.0em    the total number of different possible combinations for the initial conditions for this example is 64 , 480 and 2240 and 7280 for 1 , 2 , 3 and 4-hamming distance cases respectively , which could be calculated by @xmath294 , where @xmath295 and @xmath289 1 , 2 , 3 and 4 .",
    "as seen from figure [ fig : salusir_ex2_percentage ] the performance of the proposed network salu``sir '' is the same as that of hopfield network for 1 , 2 and 3-hamming distance cases ( @xmath290 for both networks ) , and gives comparable performance with the hopfield network for 4-hamming distance case .      in this section",
    ", we present two examples , one with 8 neurons ( example 3 ) and one with 16 neurons ( example 4 ) .",
    "the traditional discrete hopfield network @xcite , shown in the following , is used as a reference network :    @xmath296    where @xmath36 is the weight matrix and @xmath297 is the state at time @xmath73 , and at most one state is updated at a step .    in the simulations in this subsection",
    ", we also examine the following version of the dsal - usir  for comparison reasons :    @xmath298    where @xmath6 is the identity matrix , @xmath299 and @xmath36 is defined in eq.([eq : mata_w_b ] ) , and @xmath246 is the output of the network .",
    "it can be shown that the above network is stable using the steps in dsal - usir  in previous section . here , we omit the proof for the sake of brevity and present only the results for comparison reasons .",
    "let s denote the original network in eqs.([eq : sal - usir1 ] ) - ( [ eq : sal - usir1n ] ) as dsal - usir1 , and let s call the network in eq.([eq : sal - usir2a])-([eq : sal - usir2b ] ) as dsal - u``sir''2 .",
    "_ example 3 : _    the desired prototype vectors are given in the raws of the following matrix    @xmath300\\ ] ]",
    "the weight matrices @xmath301 and @xmath302 , and the threshold vector @xmath303 are obtained as follows by using the outer - products - based design mentioned above and @xmath256 is chosen as -1 and for the dsalu - usir2 network , @xmath304 .",
    "@xmath305 ,   \\\\",
    "{ \\mathbf d } & = & { \\mathbf 0}\\end{aligned}\\ ] ]    the figure [ fig : dsalusir_ex1_percentage ] shows the percentages of correctly recovered desired patterns for all possible initial conditions @xmath306 , in the proposed dsalu-``sir''1 and dsalu-sir2 as compared to the traditional discrete hopfield network in ( [ eq : discretehopfield ] ) .",
    "= 24.0em    as seen from figure [ fig : dsalusir_ex1_percentage ] , the performances of the dsalu-sir1 and 2 are the same as that of the discrete - time hopfield network for 1-hamming distance case ( @xmath290 for both networks ) and are comparable for 2 and 3-hamming distance cases respectively .",
    "_ example 4 : _",
    "the desired prototype vectors as well as the obtained weight matrices are given in in appendix ii ( eq.([eq : ex4_d ] ) ) .",
    "for matrix @xmath49 , @xmath256 is chosen as -2 .",
    "the other network paramaters are chosen as in example 3 .",
    "the figure [ fig : dsalusir_ex2_percentage ] shows the percentages of correctly recovered desired patterns for all possible initial conditions @xmath307 , in the proposed dsalu``sir''1 and 2 as compared to the traditional hopfield network .",
    "= 24.0em    the total number of different possible combinations for the initial conditions for this example is 64 , 480 and 2240 and 7280 for 1 , 2 , 3 and 4-hamming distance cases respectively .",
    "as seen from figure [ fig : dsalusir_ex2_percentage ] the performance of the proposed networks dsalu-``sir''1 and 2 are the same as that of hopfield network for 1 and 2-hamming distance cases ( @xmath290 for both networks ) , and are comparable for 3,4 and 5-hamming distance cases respectively .",
    "in this paper , we present and analyse two hopfield - like nonlinear networks , in continuous - time and discrete - time respectively . the proposed network is based on an autonomous linear system with a symmetric weight matrix , which is designed to be unstable , and a nonlinear function stabilizing the whole network thanks to a manipulated state variable .",
    "this variable is observed to be equal to the traditional signal - to - interference ratio ( sir ) definition in telecommunications engineering .",
    "the underlying linear system of the proposed continuous - time network is @xmath0 where * b * is a real symmetric matrix whose diagonal elements are fixed to a constant .",
    "the nonlinear function , on the other hand , is based on the defined system variables called `` sir ' 's .",
    "we also show that the `` sir ' 's of all the states converge to a constant value , called `` system - specific ultimate sir '' ; which is equal to @xmath1 where @xmath2 is the diagonal element of matrix @xmath3 and @xmath4 is the maximum ( positive ) eigenvalue of diagonally - zero matrix @xmath5 , where @xmath6 denotes the identity matrix .",
    "the same result is obtained in its discrete - time version as well .",
    "computer simulations for binary associative memory design problem show the effectiveness of the proposed network as compared to the traditional hopfield networks .",
    "this work was supported in part by academy of finland and research foundation ( tukisti ) of helsinki university of technology , finland .",
    "the author would also like to thank the anonymous four reviewers for their valuable comments which helped in improving the structure and the content of the paper .",
    "100    j.j .",
    "hopfield and d.w tank , neural computation of decisions in optimization problems , vol . : 141 - 146 , 1985 .",
    "s. matsuda , `` optimal '' hopfield network for combinatorial optimization with linear cost function , , vol .",
    "9 : 1319 - 1330 , nov . 1998 .",
    "k. smith , m. palaniswami , and m. krishnamoorthy , neural techniques for combinatorial optimization with applications , , vol . 9 : 1301 - 1318 , nov .",
    "tan , t. huajin and s.s .",
    "ge , on parameter settings of hopfield networks applied to traveling salesman problems , , vol .",
    "52 , nr . 5 : 994 - 1002 , may 2005 .",
    "t. huajin , k.c . tan and y. zhang , a columnar competitive model for solving combinatorial optimization problems , , vol .",
    "15 , nr . 6 : 1568 - 1574 , nov",
    ". 2004 .    j.k .",
    "paik and a.k .",
    "katsaggelos , image restoration using a modified hopfield network , , vol .",
    "1 , nr . 1:49 - 63 , jan . 1992 .",
    "farrel and a.n .",
    "michel , a synthesis procedure for hofield s continuous - time associative memory , , vol .",
    "37 : 877 - 884 , 1990 .    g.g .",
    "lendaris , k. mathia and r. saeks , linear hopfield networks and constrained optimization , vol .",
    "29 , nr . 1 : 114 - 118 feb .",
    "s. haykin , , macmillan , 1999 .",
    "zurada , , west publishing company , 1992 .",
    "muezzinoglu , m.k . and c. guzelis , a boolean hebb rule for binary associative memory design , , vol .",
    "15 , nr . 1:195 - 202 , jan . 2004 .",
    "muezzinoglu , c. guzelis and j.m .",
    "zurada , an energy function - based design method for discrete hopfield associative memory with attractive fixed points , , vol .",
    "16 , nr . 2:370 - 378 , march 2005 .",
    "rappaport , , prentice - hall , new york , 1996 .",
    "z. uykan ,  from sigmoid power control algorithm to hopfield - like neural networks : `` sir '' ( `` signal''-to-``interference''-ratio)- balancing sigmoid - based networks \" , in september 2009 .",
    "d. o. hebb , , john wiley and sons , new york , 1949 .",
    "o. bretscher , , prentice hall , 2005 .",
    "d. luenberger , , john wiley and sons , inc .",
    "new york , 1979 .",
    "g. m. pan and w. zhou central limit theorem for signal - to - interference ratio of reduced rank linear receiver , , doi : 10.1214/07-aap477 , vol .",
    "18 , no . 3 : 1232 - 1270 , 2008 . (",
    "arxiv:0806.2768v1 [ math.pr ] ) .",
    "in example 2 , the matrix which has the desired prototype vectors as its raws is    @xmath308\\ ] ]    in example 2 , the weight matrices @xmath49 and @xmath36 , which are obtained by the outer products based design as explained in section [ subsection : hebbbasedlearning ] , are as follows :    @xmath309 \\nonumber \\\\   &   &   \\end{aligned}\\ ] ]",
    "in example 4 , the matrix which has the desired prototype vectors as its raws is"
  ],
  "abstract_text": [
    "<S> in this paper , we present and analyse two hopfield - like nonlinear networks , in continuous - time and discrete - time respectively . the proposed network is based on an autonomous linear system with a symmetric weight matrix , which is designed to be unstable , and a nonlinear function stabilizing the whole network thanks to a manipulated state variable called``ultimate sir '' . </S>",
    "<S> this variable is observed to be equal to the traditional signal - to - interference ratio ( sir ) definition in telecommunications engineering .    </S>",
    "<S> the underlying linear system of the proposed continuous - time network is @xmath0 where * b * is a real symmetric matrix whose diagonal elements are fixed to a constant . the nonlinear function , on the other hand , </S>",
    "<S> is based on the defined system variables called `` sir ' 's . </S>",
    "<S> we also show that the `` sir ' 's of all the states converge to a constant value , called `` system - specific ultimate sir '' ; which is equal to @xmath1 where @xmath2 is the diagonal element of matrix @xmath3 and @xmath4 is the maximum ( positive ) eigenvalue of diagonally - zero matrix @xmath5 , where @xmath6 denotes the identity matrix . </S>",
    "<S> the same result is obtained in its discrete - time version as well .    </S>",
    "<S> computer simulations for binary associative memory design problem show the effectiveness of the proposed network as compared to the traditional hopfield networks .    </S>",
    "<S> autonomous continuos / discrete - time linear systems , hopfield networks , signal to interference ratio ( sir ) . </S>"
  ]
}