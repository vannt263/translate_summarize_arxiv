{
  "article_text": [
    "in the theory of inverse problems , structural properties of signals and images have always played an important role . namely , most inverse problems arising in practical applications are ill - posed , which makes them impossible to solve in a robust manner without imposing additional assumptions .",
    "the expected or observed structure of the signal can then serve as a regularizer necessary to allow for efficient solution methods . at the same time",
    ", it was well - known that the success of such approaches heavily depended on the nature of the observed measurements .",
    "usually , these measurements were considered to be given by the application , and the goal was to formulate properties that allow for successful reconstruction .",
    "a different perspective was taken in a number of works over the last decade , starting with the seminal works of donoho @xcite and cands , romberg , and tao @xcite .",
    "namely , the goal was to use the degrees of freedom of the underlying applications to design measurement systems that by construction are well - suited for successful reconstruction of structured signals .",
    "in many cases , as it turned out , measurements selected at random were shown to lead to superior , often near - optimal recovery guarantees .",
    "the tightest recovery guarantees are typically obtained when structural constraints on the measurements as prescribed by the application are ignored and the measurement parameters are chosen completely at random , for example following independent normal distributions . in a next step ,",
    "the constraints then need to be reintroduced , resulting in structured random measurements",
    ". error analysis and recovery guarantees for such structured random measurement systems shall be the main focus of this survey article .",
    "we will focus on three types of signal recovery problems : compressed sensing , low rank matrix recovery , and phaseless estimation .    _ compressed sensing _ is concerned with the recovery of approximately sparse signals from linear measurements .",
    "a signal is said to be _",
    "@xmath0-sparse _ in a given basis or frame , if it can be expressed as a linear combination of only @xmath0 of the basis or frame elements .",
    "approximate sparsity is a common model in signal and image processing , as natural signals are observed to be extremely well represented by restricting to just the very few largest representation coefficients in a suitable basis or frame and setting the remaining ones to zero .",
    "in fact , lossy compression schemes including jpeg , mpeg or mp3 are based on this empirical finding .",
    "suitable representation systems include wavelet bases and shearlet frames , and approximate sparsity is also observed for the discrete gradient ( though it does not constitute a basis or frame representation ) .",
    "motivating applications for this problem setup include magnetic resonance imaging ( mri ) @xcite , coded aperture imaging @xcite , remote sensing @xcite , and infrared imaging @xcite .",
    "figure  [ fig : sparsefourier ] illustrates the recovery of a sparse fourier expansion from few random samples via compressive sensing techniques , and for comparison also shows a traditional reconstruction technique which clearly performs very poorly .",
    "figure  [ fig : spine ] considers the practical example of a @xmath1 mri spine image , which is reconstructed from @xmath2 fourier samples , that is , less than @xmath3 of the information .",
    "it shows the need for variable density sampling schemes as they form the basis of theorem  [ thm2 ] below .",
    "[ fig : sparsefourier ]     +    for _ low - rank matrix recovery _",
    ", one also considers linear measurements , but the structural signal model is that the signal is approximated by a low - rank matrix .",
    "this problem closely relates to applications in recommender systems and signal processing @xcite , but also has connections to quantum physics @xcite .    in _ phaseless estimation _",
    ", only the modulus of each measurement is observed .",
    "such a measurement setup can be found in various applications in physics , such as diffraction imaging and x - ray crystallography . as the phases of an image are known to carry most of its information ,",
    "this is a difficult problem , even when a number of measurements considerably larger than the dimension is used .",
    "besides the general setup with no structural assumptions on the signal , the case of sparse signals has also in the phaseless estimation problem received considerable attention .    a major reason for the large research activity in compressive sensing and its extensions in the recent years is due to its potential for a large number of applications in signal processing and beyond .",
    "besides mri ( as illustrated in figure  [ fig : spine ] and described in more detail below ) , compressive sensing has applications to various signal processing applications .",
    "let us mention a few .",
    "compressive sensing may improve several types of radar imaging .",
    "especially when observing the sky , the fact that usually only a very limited number of airplanes is present at a time , naturally leads to sparsity of the image to be reconstructed .",
    "moreover , the radar measurements can often be designed such that good measurement matrices for compressing arise .",
    "this has been worked out for delay / doppler radar @xcite , for a setup with multiple antennas at random locations @xcite , for sparse mimo radar @xcite , and more @xcite .",
    "another promising signal processing application of compressive sensing appears in microscopy for materials science applications @xcite .",
    "it is also possible to implement certain measurement matrices directly on cmos chips , so that cameras may operate with fewer measurements or may increase resolution by keeping the costs down @xcite . this may also be useful in order to reduce the power consumption of imaging sensors .",
    "further optical and imaging applications of compressive sensing are described for instance in the overview articles @xcite .",
    "further applications of compressive sensing and its extensions will be described in the individual sections below .    in the remainder of this paper",
    ", we will consider each of these scenarios separately , giving an overview over recovery algorithms and reconstruction guarantees for structured measurements . in section  [ sec : cs ] , we discuss compressed sensing , in section  [ sec : mr ] , we consider low rank matrix recovery , and the topic of section  [ sec : pe ] is phaseless estimation . in section  [ sec : mm ] , we give a brief overview of the mathematical proof techniques used to achieve the results , which are somewhat similar in all the three areas .",
    "we concentrate on structured random measurements in this article rather than giving a basic general introduction to the field . for introductory survey papers on compressed sensing we refer to @xcite and for recent books to @xcite .",
    "throughout most of this section , we focus on the following setup .",
    "note that we consider complex - valued signals and matrices , but the reader may as well imagine just the real case .    *",
    "* signals : * let @xmath4 be approximately @xmath0-sparse in a basis @xmath5 , that is , @xmath6 , for @xmath7:= \\{1,2,\\hdots , n\\}$ ] of cardinality @xmath0 .",
    "the important case that the representation system is a frame rather than a basis will not be covered in this survey , we refer the reader to @xcite , @xcite , and many follow - up papers . to quantify the sparse approximation quality",
    ", we define for @xmath8 the @xmath9 best @xmath0-term approximation error @xmath10 . a common model for approximately sparse vectors",
    "is given by the unit @xmath9 ball , @xmath11 .",
    "namely , @xmath12 , @xmath11 , is known to imply @xmath13 @xcite . as @xmath14 ,",
    "these quasinorms converge to the support size @xmath15 . for all of these concepts ,",
    "when no sparsity basis is specified or clear from the context , we will work with the standard basis .",
    "note that in contrast to a noisy sparse signal , there is no underlying sparse `` truth ''",
    ". the goal will be to estimate the approximately sparse signal and the result will not necessarily have to be sparse either . *",
    "* measurements : * we consider @xmath16 linear measurements , represented in matrix form by @xmath17 .",
    "the measurements are affected by additive noise @xmath18 .",
    "thus the observed measurements are given by @xmath19 .",
    "we will mainly consider adversarial noise , i.e. , we are looking for worst case bounds for the reconstruction error .",
    "however , random noise models have also been considered , mainly in a statistical context , see e.g.  @xcite .",
    "as mentioned in the introduction , the general paradigm that we will follow in all three application scenarios will be to design the measurements in a random fashion such that efficient reconstruction can be guaranteed .",
    "as such , the resulting reconstruction guarantees will be probabilistic , namely reconstruction is only guaranteed with high probability .",
    "there are two fundamentally different interpretations of such probabilistic guarantees .",
    "_ uniform recovery guarantees _",
    "concern all ( approximately ) sparse signals at the same time .",
    "that is , one seeks random matrix construction whose realizations , with high probability , allow for the recovery of all sparse signals .",
    "non - uniform recovery guarantees , on the other hand , establish that for any given signal , recovery is possible with high probability .",
    "that is , in the latter case , the matrices for which reconstruction fails can differ for different signals and there is no guarantee that one matrix can be generated that allows for the recovery of all sparse vectors .    the techniques used to establish uniform versus non - uniform recovery guarantees are somewhat different .",
    "an important tool that has been successfully used to establish uniform recovery guarantees is the restricted isometry property .",
    "a matrix @xmath20 is said to have the restricted isometry property of order @xmath0 and level @xmath21 with respect to a basis @xmath22 ( in short , the @xmath23-rip ) , if it satisfies @xmath24 for all @xmath25 which are @xmath0-sparse with respect to @xmath22 .",
    "the smallest @xmath21 that satisfies is called the restricted isometry constant of order @xmath0 and denoted by @xmath26 .",
    "if the measurement matrix has restricted isometry property of order @xmath0 and suitably small level @xmath21 , then reconstruction of sparse vectors can be guaranteed for various algorithms . a simple tractable recovery approach",
    "which is arguably best understood in the context of compressed sensing is @xmath27-minimization ( basis pursuit ) @xcite .",
    "here it is assumed that the noise level @xmath28 is known at least approximately .",
    "furthermore , @xmath29 denotes the change of basis matrix associated to the sparsity basis @xmath22 .",
    "then the resulting minimization problem is as follows , @xmath30 it may not be obvious that @xmath27-minimization promotes sparsity , but there are many theoretical results indicating this fact in general , see e.g.  theorem 3.1 in @xcite . more specifically , the following theorem proved in @xcite shows that this convex optimization problem successfully recovers approximately sparse solutions provided the measurement matrix has a sufficiently small restricted isometry constant .",
    "[ thm : riprc ] let @xmath4 , assume @xmath20 has the restricted isometry property of order @xmath31 and level @xmath32 with respect to the basis @xmath22 , and let @xmath33 , where the noise vector @xmath34 satisfies @xmath35 . then the vector @xmath36 recovered by the minimization problem satisfies @xmath37 here @xmath38 and @xmath39 are absolute constants .",
    "note that for @xmath40 , the theorem implies that under the same conditions on @xmath41 , every @xmath0-sparse vector is recovered exactly by provided the measurements are not affected by noise .",
    "the constant @xmath42 above is optimal @xcite and the error bound as well , see also below .",
    "moreover , also error bounds in @xmath9 with @xmath43 can be shown @xcite .",
    "similar recovery guarantees , though for smaller thresholds for @xmath21 , have been derived for other recovery algorithms than @xmath27-minimization .",
    "examples include cosamp , iterative hard thresholding and iterative hard thresholding pursuit @xcite .",
    "* subgaussian random matrices . * in order to deduce recovery results using these results , the measurement systems under consideration must have restricted isometry constants below some constant threshold .",
    "this can be achieved by choosing a measurement matrix with independent entries drawn according to a subgaussian distribution as given in the following definition ( see for example @xcite for a detailed discussion of subgaussian random variables including a number of equivalent definitions ) .",
    "a real or complex random variable @xmath44 is called subgaussian with parameter @xmath45 if @xmath46 a random matrix @xmath41 is called subgaussian with parameter @xmath47 if its entries are independent mean zero subgaussian random variables with parameter @xmath47 .",
    "examples of subgaussian random variables include centered gaussian random variables and centered bounded random variables such as rademacher random variables , i.e. , @xmath48 .",
    "the following theorem concerning the rip for subgaussian random matrices is well - known , a particularly simple proof can be found in @xcite , see also @xcite .",
    "this and most following results in this survey are probabilistic , that is , they hold with high probability on the draw of the measurement matrices .",
    "the precise meaning of this is that we can make the probability of failure arbitrarily small by ( slightly ) increasing the number @xmath16 of samples . for reasons of simpler presentation",
    ", we will not specify this dependence , but refer to the original research articles .",
    "let @xmath22 be an orthonormal basis of @xmath49 , @xmath20 be a subgaussian random matrix with parameter @xmath47 , and assume that @xmath50 .",
    "then with probability at least @xmath51 , the matrix @xmath52 has the restricted isometry property of order @xmath0 and level @xmath21 with respect to the basis @xmath22 . here",
    "@xmath53 is a constant , which only depends on @xmath47 .",
    "combined with theorem  [ thm : riprc ] , this result yields recovery guarantees for @xmath27-minimization for embedding dimensions @xmath54 .",
    "in particular , if @xmath0 is much smaller than @xmath55 then also the number @xmath16 of measurements can be chosen smaller than the signal length @xmath55 and still signal recovery is ensured .",
    "an embedding dimension of order @xmath56 is known to be necessary to achieve recovery guarantees of the form @xcite . for the case of subgaussian matrices , also",
    "the non - uniform approach mentioned above does not yield recovery guarantees for embedding dimensions of a smaller order .",
    "note that the result is universal in the sense that the recovery guarantees do not depend on the choice of @xmath22 .",
    "subgaussian compressed sensing matrices are often considered a benchmark to judge the quality of a randomized construction .",
    "thus one is typically interested in embedding dimensions which scale linearly in the sparsity @xmath0 , up to logarithmic factors .",
    "deterministic constructions to date are nowhere near this benchmark .",
    "efficient constructions are known for embedding dimensions which scale quadratically in @xmath0 @xcite , the best known infinite family that beats this quadratic bottle neck uses heavy machinery from additive combinatorics to achieve a scaling of @xmath57 @xcite , where the best currently available estimate of @xmath58 is on the order of @xmath59 @xcite .",
    "* random fourier measurements . * from the very beginning , one of the main motivating applications of compressed sensing was magnetic resonance imaging ( mri ) .",
    "mri measurements are known to be well modeled with the ( continuous ) fourier transform .",
    "we will follow the common approach to approximate this setup by discrete fourier transform ( dft ) measurements . in this article we work with",
    "the non - normalized discrete fourier transform matrix with entries given by @xmath60 ( where we assume @xmath61 to be even ) .",
    "the discrete fourier basis then consists of the normalized rows of @xmath62 .",
    "this discretization approach also has the advantage that the resulting ( approximate ) measurement matrix can be efficiently computed using the fast fourier transform ( fft ) .",
    "we note , however , that refined models for compressed sensing mri have been developed ; we mention infinite dimensional compressed sensing @xcite and discrete prolate spheroidal sequences @xcite .    in the undersampled setup that we consider here ,",
    "only a subset of the rows of the dft are chosen .",
    "randomness is introduced into the model by selecting these rows at random .",
    "note that this simple subsampling model does not incorporate certain technical side constraints of the mri acquisition process .",
    "for example , samples are in practice acquired on continuous trajectories , which is not in line with drawing the samples at random . building this and other technical constraints into the compressed sensing model remains an active area of research ,",
    "see for example @xcite for a recent attempt to address the continuity constraint . in this survey , we will , however , stick with the simplified model of randomly chosen dft measurements .    because of the structure of the resulting random matrix",
    ", the recovery guarantees must depend on the basis in which the signal is sparse .",
    "this is most easily seen by considering signals sparse in the discrete fourier basis .",
    "then most dft coefficients of a sparse signal are zero by construction , so one requires a number of measurements much larger than what is needed for subgaussian measurement matrices .",
    "as it turns out , a sufficient property to ensure recovery guarantees is _ incoherence _ between the sparsity basis and the measurement basis ( in this case , the discrete fourier basis ) .    the _ coherence _ between two orthonormal bases @xmath63 and @xmath64 of @xmath65 is defined as @xmath66    a main example for incoherent bases are the standard basis and the fourier basis , their coherence has the minimal value of @xmath67 .",
    "though often formulated specifically for the standard basis as the sparsity basis and the fourier basis as the measurement bases , the uniform recovery results directly generalize to arbitrary incoherent bases .",
    "the first results of the type below were introduced in @xcite and later refined in @xcite .",
    "[ thm : incoh ] consider orthonormal bases @xmath63 and @xmath64 of @xmath65 with coherence bounded by @xmath68 fix @xmath69 and integers @xmath70 , and @xmath0 such that @xmath71 consider the matrix @xmath72 formed by subsampling @xmath16 vectors of @xmath64 independently according to the uniform distribution",
    ". then @xmath73 has the restricted isometry property of order @xmath0 and level @xmath21 with respect to the sparsity basis @xmath63 with probability at least @xmath51 .",
    "the constant @xmath74 is universal ( independent of all other quantities ) .",
    "note that the normalization factor implies that the rows rather than the columns are ( approximately ) normalized .",
    "this renormalization is necessary as the restricted isometry property requires that the columns are approximately unit norm .",
    "in contrast to the case of subgaussian matrices , the best known recovery guarantees for the non - uniform approach are considerably stronger than in the uniform case .",
    "namely , the number of measurements required to guarantee recovery of @xmath0-sparse signals in @xmath61 dimensions with high probability is of order @xmath75 ( see for example @xcite ) .",
    "the direct applicability of theorem  [ thm : incoh ] is somewhat limited .",
    "while for certain applications , such as angiography , sparsity in the standard basis can be assumed , most sparsity inducing representation systems for images , such as wavelets or shearlets are not incoherent with the fourier basis . for haar wavelets , for example",
    ", the constant fourier mode and the constant wavelet mode even agree , so the bases are maximally coherent , that is , @xmath76 or , in the notation of theorem  [ thm : incoh ] , @xmath77 .",
    "in contrast to the case of sparsity in the fourier basis , where hardly any subsampling is possible , this high coherence only concerns very few of the measurement vectors .",
    "most measurement vectors have uniformly small inner products with all vectors in the sparsity basis .",
    "this can be exploited by sampling according to a variable density based on a localized refinement of the coherence . in this way",
    ", one can obtain recovery guarantees for fourier measurements and images approximately sparse in the haar wavelet basis . as the result for noisy measurements becomes quite technical",
    ", we only state the recovery guarantees without noise and refer to @xcite for details on the noisy case . in the following result",
    ", @xmath78 denotes the haar wavelet transform matrix . due to its appearance",
    "we restrict @xmath61 to be a power of @xmath79 for notational simplicity .",
    "[ thm2 ] fix integers @xmath80 and @xmath81 such that @xmath82 select @xmath16 frequencies @xmath83 independently according to @xmath84   = c_n \\min\\left(c , \\tfrac{1}{\\ell_1 ^ 2 + \\ell_2 ^ 2 } \\right),\\ -\\tfrac{n}{2}+1 \\leq \\ell_1 , \\ell_2 \\leq \\tfrac{n}{2},\\end{aligned}\\ ] ] where @xmath85 is an absolute constant and @xmath86 is chosen such that defines a probability distribution .",
    "then with probability at least @xmath51 , the following holds for all images @xmath87 : given measurements @xmath88 , the estimation @xmath89 approximates @xmath90 up to the best @xmath0-term approximation error in the bivariate haar basis : @xmath91    it should be noted that while it is not clear whether the decay of second argument of the @xmath92 in can be improved ( maybe for different families of wavelets ) , the cut - off introduced by the first argument is crucially tied to our sampling model .",
    "as we are sampling with replacement , it is necessary to prevent frequencies near the origin from being sampled too often .",
    "similar recovery guarantees can be derived for images with approximately sparse discrete gradients , where the recovery algorithm is based on total variation minimization ( see @xcite for details ) .",
    "figure  [ fig : spine ] above illustrates the need for variable density sampling by comparing a uniform sampling density and an inverse square density .    in parallel to this refinement of the concept of fourier / wavelet incoherence ,",
    "the concept of sparsity has also been refined to better reflect the fact that wavelet coefficients on larger scales exhibit less sparsity than on smaller scales . in @xcite ,",
    "the authors study a weighted sparsity model and derive rip - based guarantees for uniform recovery . in @xcite ,",
    "the authors work in an infinite - dimensional setup and consider both coherence and sparsity in the asymptotic limit .",
    "these observations may also serve as an explanation that empirically , sampling densities with a faster decay seem to outperform those predicted by theorem  [ thm2 ]",
    ".    * subsampled random convolutions . *",
    "later , further applications of compressed sensing arose that require different structural constraints on the measurements .",
    "for application in remote sensing @xcite and coded aperture imaging @xcite , the model of choice is often that of subsampled convolutions . for simplicity",
    ", we consider the circular convolution @xmath93 given by @xmath94 where @xmath95 denotes subtraction mod @xmath61 .",
    "these convolution measurements are then subsampled by an operator @xmath96 , @xmath97 , which restricts a vector to only those entries indexed by @xmath98 . that is , after normalizing the columns",
    ", we obtain a measurement matrix @xmath20 of the form @xmath99 a matrix @xmath41 of this form is called a _ partial circulant _ matrix . for this setup",
    "there are two alternative ways to introduce randomness into the system .",
    "one can again choose the subsampling pattern @xmath98 at random , or one can choose @xmath98 deterministically and randomize the vector @xmath100 . for both scenarios , recovery guarantees have been derived . in the case of random @xmath98 , the key concept determining",
    "the success is the _ autocorrelation _ of @xmath100 .",
    "namely , as shown in @xcite , a sufficient condition is that @xmath100 is a _ nearly perfect sequence _ in the sense that for @xmath101 its off - peak autocorrelation , that is , the values @xmath102 for @xmath103 not a multiple of @xmath61 , is bounded by a small constant @xmath104 independent of @xmath61 . here",
    "@xmath105 denotes addition mod @xmath61 . with this definition ,",
    "the result in @xcite reads as follows .",
    "let @xmath106 be a nearly perfect sequence , @xmath107 for all @xmath103 not a multiple of @xmath61 , such that @xmath108 for @xmath109 and assume @xmath110 , where @xmath85 is an absolute constant .",
    "then with probability at least @xmath51 the matrix @xmath20 as defined in has the restricted isometry property of order @xmath0 and level @xmath21 both with respect to the standard and the fourier basis .",
    "the proof is closely related to the case of random partial fourier matrices as discussed above . in a similar way , one also obtains non - uniform recovery guarantees for embedding dimensions of order @xmath75 . for a detailed discussion of examples for nearly perfect sequences ,",
    "we refer the reader to @xcite and the references therein .    as in the partial fourier case",
    ", this setup is based on random subsampling .",
    "that is , the sampling setup can not be truly designed for lower sampling frequencies , as with very high probability , _ some _ subsequent samples will be selected .",
    "for this reason , the setup of choosing @xmath98 deterministically and randomizing @xmath111 has received considerable attention . in coded aperture imaging",
    ", this corresponds to choosing a random aperture pattern , and in remote sensing , this concerns a random pulse that is transmitted .",
    "both are often considerably easier to implement than subsampling at random .    the first results on this problem required embedding dimensions significantly worse than the linear benchmark scaling in @xmath0 , namely cubic @xcite , quadratic @xcite , and @xmath112 @xcite .",
    "in @xcite , linear scaling up to logarithmic factors has been achieved , as given in the following result . here",
    "the random vector @xmath100 consists of independent subgaussian entries .",
    "again , this includes the important examples of a gaussian and a rademacher random vector .",
    "[ thm : kmr ] let @xmath113 be a random vector with independent subgaussian entries with parameter @xmath47 and let @xmath114 be a draw of the associated partial random circulant matrix generated by @xmath100 as given in . if @xmath115 then @xmath41 has the rip of order @xmath0 and level @xmath21 with probability at least @xmath51 .",
    "the constant @xmath116 only depends on the subgaussian parameter @xmath47 .",
    "there are also non - uniform recovery guarantees available for subsampled convolutions @xcite .",
    "the best known such result again achieves a scaling of order @xmath75 for the embedding dimension @xcite .",
    "there have been various works on other structured random measurement matrices for compressed sensing .",
    "time - frequency structured random matrices , a class of examples which arises in wireless communication and radar , have been studied in @xcite ( uniform recovery guarantees ) and @xcite ( non - uniform recovery guarantees ) . for a class of matrices which arises in radar imaging with randomly located antennas , only non - uniform guarantees are available to date @xcite .",
    "low rank matrix recovery represents an interesting extension of compressive sensing , where the sparsity assumption is replaced by a low rank assumption .",
    "more precisely , the task is to reconstruct a matrix of low rank ( or approximately low rank ) from incomplete linear measurements .",
    "this problem arises for instance in recommender system design @xcite    and a number of signal processing applications , described briefly next .",
    "suppose that several sensors observe different aspects of the same phenomenon , for instance weather time series at locations distributed in some area .",
    "collecting the signals corresponding to each sensor data as columns into a data matrix , correlatedness of the data may lead to an ( approximately ) low rank of this matrix .",
    "therefore , low rank matrix recovery techniques help in such situations to accurately reconstruct signals from observed data and/or to work with fewer sensor measurements , see @xcite . in wireless communications",
    "it is a main task to estimate both the transmission channel as well as the sent signal from the received signal . in @xcite , this blind deconvolution problem",
    "is reformulated as a low rank matrix recovery problem and recovery guarantees for this scenario are shown .",
    "another important task arising in so - called cognitive radio is to decide whether certain frequency bands are occupied or not so that free bands may be potentially used for wireless transmission by a user . in @xcite",
    "an approach to this problem via low rank matrix recovery was introduced .    in mathematical terms , the measurements of a matrix @xmath117 are provided by a linear map @xmath118 , i.e. , @xmath119 we are interested in the underdetermined case that @xmath120 .",
    "a prominent special case is the matrix completion problem , where one samples entries of a low rank matrix and tries to fill in the missing entries , see also below .",
    "the rank minimization problem @xmath121 is unfortunately np - hard .",
    "( in fact , the np - hard problem of finding for an underdetermined linear system the solution with the smallest support  as it appears in compressed sensing context  can be cast as a rank - minimization problem . )",
    "let @xmath122 , @xmath123 , be the vector of singular values of @xmath44 .",
    "observing that @xmath124 and having the @xmath27-minimization approach for the standard compressed sensing problem in mind , we are led to consider the nuclear norm @xmath125 and the corresponding nuclear norm minimization problem @xcite @xmath126 this is a convex optimization problem for which a number of algorithms exist @xcite .",
    "for instance , it can be reformulated as a semidefinite optimization program .",
    "other algorithmic approaches for the low rank matrix recovery problem including iterative hard thresholding @xcite , iteratively reweighted least squares @xcite and a variant of cosamp called admira can be pursued as well @xcite .",
    "similarly as in the standard compressed sensing case , we are interested in suitable measurement maps @xmath127 and the minimal number @xmath16 of samples required to reconstruct an @xmath128 matrix of rank @xmath129",
    ". it should not be a surprise by now that again , random measurement maps are optimal with high probability in this context in the sense of working with a minimal number of measurements .",
    "we also distinguish uniform and nonuniform recovery guarantees here .    a prominent approach for deriving uniform guarantees consists in studying a version of the restricted isometry property for the low rank case @xcite .",
    "similarly as in we define the restricted isometry constant @xmath130 to be the smallest number such that @xmath131 if @xmath132 , then nuclear norm minimization uniquely recovers every matrix of rank at most @xmath129 from @xmath133 .",
    "moreover , recovery is stable under noise on the measurements and passing to approximately low - rank matrices @xcite .",
    "the simplest model of a random measurement map is a bernoulli or gaussian map , where all the entries of the tensor @xmath134 , i.e. , @xmath135 , are chosen as independent mean - zero rademacher or standard gaussian random variables .",
    "the restricted isometry constant of the rescaled map @xmath136 satisfies @xmath137 with probability at least @xmath51 provided that @xcite @xmath138 this implies rank-@xmath129 matrix recovery with high probability via nuclear norm minimization from @xmath139 measurements .",
    "this bound is optimal as the right hand side represents essentially the number of degrees of freedom of a matrix of rank @xmath129 in dimension @xmath128 .",
    "clearly , if @xmath140 , then @xmath16 can be chosen smaller than the dimension @xmath141 of the underlying matrix space @xmath142 .    while bernoulli and gaussian measurement maps are comparably easy to analyze , they are of limited practical use due to lack of structure . as in the standard sparsity case , we therefore rather look for structured random measurement maps .",
    "( optimal deterministic constructions are not available at this point and likely very hard to achieve . )    * matrix completion . *",
    "imagine an online vendor system which asks clients to rate the products which they have purchased .",
    "such recommendations can be organized in a big matrix where the columns represent products and the rows the clients .",
    "the corresponding ratings are kept as the entries of this matrix . since not every client rates every product , a lot of entries of the matrix are missing .",
    "for obvious reasons , a recommender system needs to guess such missing entries in order to make good suggestions of products that a client will probably like . in other words",
    ", we would like to complete this matrix .",
    "( this was basically the task of the famous netflix prize . ) in practice there are only a few types of significantly different client behavior which results in the matrix being essentially of low rank .",
    "in abstract terms , we are given a matrix like this one @xmath143 and the problem is to replace the question marks with numbers making the whole matrix being of low rank .",
    "let @xmath144 \\times [ n_2]$ ] of size @xmath16 be the location set of the known entries , where @xmath145 : = \\{1,2,\\hdots , n\\}$ ] .",
    "let @xmath146 be the restriction of a matrix @xmath117 to its entries in the set @xmath98 .",
    "the measurements in the matrix completion setup can then be written as @xmath147 . compared to the subgaussian random measurement maps , @xmath96 as a coordinate projection",
    "can be considered a structured measurement map .",
    "later on , we will randomize this map by considering random subsets @xmath98 , and thereby obtain a structured random map .",
    "matrix completion , i.e. , considering maps of the form @xmath96 , has some limitations in terms of low rank recovery .",
    "consider the rank - one matrix @xmath148 , where @xmath149 and @xmath150 are the @xmath151-th and @xmath0-th canonical unit vectors in @xmath152 and @xmath153 , respectively .",
    "then @xmath44 is also one - sparse and if @xmath154 then @xmath155 .",
    "clearly , any reasonable algorithm would recover the zero matrix from the zero measurement vector , so that @xmath44 can not be recovered although it is of rank one .",
    "for this reason , @xmath96 will not satisfy the rank restricted isometry property of any order .",
    "this means that we have to impose further conditions on the matrix apart from being low rank in order to guarantee recovery .",
    "it is natural to impose that the singular vectors of the matrix @xmath44 are incoherent with respect to the canonical basis . in order to make this precise ,",
    "for a subspace @xmath156 of @xmath157 of dimension @xmath129 we introduce the coherence of @xmath156 as @xmath158 where @xmath159 denotes the orthogonal projection onto @xmath156 and the @xmath160 are the canonical unit vectors in @xmath157 .",
    "if @xmath156 contains a canonical unit vector , say @xmath160 , then @xmath161 and the coherence takes the maximal value @xmath162 .",
    "the other extreme case is given for example by a space @xmath156 spanned by @xmath129 orthonormal vectors @xmath163 maximally incoherent with respect to the canonical basis , i.e. , @xmath164 .",
    "in this case , the matrix @xmath165 with rows @xmath163 has all entries of modulus @xmath166 .",
    "now @xmath167 , so @xmath168 , and @xmath169 takes the minimal value @xmath170 .",
    "when restricting to low rank matrices @xmath44 whose right and left singular vectors span incoherent subspaces in the sense that their coherence is small , it was shown by cands and recht in @xcite that nuclear norm minimization is able to recover @xmath44 from @xmath171 from a random choice of @xmath98 with high probability provided that enough measurements are taken . the following statement",
    "@xcite is a refinement of the first results in @xcite .",
    "let @xmath117 of rank @xmath129 with reduced singular value decomposition @xmath172 with @xmath173 and @xmath174 .",
    "assume that the row and column spaces of @xmath44 satisfy @xmath175 for some @xmath176 , where with abuse of notation @xmath156 and @xmath177 also denote the subspaces spanned by the left and right singular vectors , respectively .",
    "moreover , assume that @xmath178 for some @xmath179 .",
    "let the entries of @xmath144 \\times [ n_2]$ ] be sampled independently and uniformly at random . if @xmath180 then @xmath44 is uniquely recovered from @xmath181 via nuclear norm minimization with probability at least @xmath182 .",
    "the bound on the number of measurements is almost optimal in the sense that one can derive a lower bound where only the exponent @xmath79 at the log - factor is replaced by @xmath183 .",
    "moreover , note that the bound on @xmath16 requires @xmath184 to be small , which excludes that the pathological sparse rank - one matrices @xmath185 are recovered from fewer than @xmath186 measurements .",
    "* random measurements with respect to an operator basis .",
    "* motivated by problems from quantum tomography , gross @xcite generalized the matrix completion setup to the following scenario .",
    "let @xmath187 , @xmath188 , be an orthonormal basis with respect to the frobenius inner product , i.e. , @xmath189 .",
    "measurements of a matrix @xmath44 are taken with respect to this basis , i.e. , @xmath190 for some @xmath191 $ ] . in this context , we define again a coherence parameter @xmath58 , this time for the basis @xmath192 , as @xmath193 the intuition is that sampling with respect to an operator basis having a small coherence parameter @xmath58 preserves information about low rank matrices , and works well even for the pathological example @xmath194 . in the symmetric case @xmath195 , the optimal parameter @xmath196 is taken for an operator basis @xmath192",
    "for which @xmath197 is unitary for each @xmath198 $ ] .",
    "an example for such an operator basis is provided by the pauli matrices , see @xcite , which are important in quantum mechanics .",
    "another example is formed by time - frequency shift operators .",
    "the following result from @xcite establishes low rank matrix recovery with respect to randomly chosen coefficients with respect to the orthonormal basis .",
    "[ thm : opbasis ] let @xmath199 be an operator basis with coherence @xmath200 .",
    "let @xmath201 be of rank @xmath129 and @xmath202 $ ] be a subset of size @xmath16 which is chosen uniformly at random . if , for @xmath203 , @xmath204 then @xmath44 is uniquely recovered from the samples @xmath205 , @xmath206 , via nuclear norm minimization with probability at least @xmath182",
    ".    another version of this result , which includes the matrix completion setup as a special case by considering the operator basis @xmath207 , can be found in @xcite .",
    "moreover , for the map of theorem  [ thm : opbasis ] , also the rank - restricted isometry property holds with probability at least @xmath51 under the condition @xmath208 see @xcite .",
    "this implies uniformity of reconstruction as well as stability under passing to approximately low rank matrices and adding noise on the measurements .",
    "( recall however , that for the matrix completion map the restricted isometry property fails . )",
    "* fourier type measurements .",
    "* let us now describe a structured measurement map connected to the fourier transform for which the rank restricted isometry holds .",
    "this map is the concatenation of random sign flips and a randomly subsampled two - dimensional fourier transform . in mathematical terms , for an @xmath128 matrix @xmath209 with independent @xmath210 rademacher entries @xmath211 , we denote by @xmath212 the hadamard multiplication with @xmath213 , i.e. , @xmath214 in other words , @xmath215 performs independent random sign flips on all entries of a matrix",
    ". moreover , let @xmath216 denote the two - dimensional fourier transform , i.e. , @xmath217 finally , for a set @xmath144\\times[n_2]$ ] of size @xmath16 we let @xmath218 be the restriction operator @xmath219 for @xmath220 . with these ingredients our measurement map @xmath118 can be written as @xmath221 where @xmath98 is chosen uniformly at random among all subsets of @xmath222 \\times [ n_2]$ ] of cardinality @xmath16 . exploiting the fft ,",
    "the map @xmath127 can be applied fast .",
    "it is argued in the introduction of @xcite ( but details are not worked out ) , that @xmath127 possesses the rank restricted isometry property with high probability provided that @xmath223 it is interesting to note that this result follows from a combination of several facts : @xmath224 satisfies the standard restricted isometry property with high probability .",
    "together with the main result in @xcite relating johnson - lindenstrauss embeddings and the restricted isometry property if follows that @xmath225 satisfies a certain concentration inequality which can then be used along with @xmath226-net arguments @xcite in order to establish the rank restricted isometry property .",
    "while the signal model used for low - rank matrix recovery and compressed sensing are considerably different , phaseless estimation problems consider structurally different , non - linear measurements .",
    "namely , of each linear measurement , only the ( squared ) modulus is observed , and the phase is lost .",
    "such a measurement setup arises in various applications such as x - ray crystallography and diffraction imaging .",
    "losing the phase here corresponds to observing only the intensity of the measurements .    in more mathematical terms",
    ", the measurements take the form @xmath227 where the non - linear map @xmath228 is given by @xmath229 , where @xmath230 are given measurement vectors .",
    "note that in this setup , the two cases of signal entries in @xmath231 and @xmath232 are structurally different as in the real case , the phase corresponds to the sign and hence only allows for the two different values @xmath210 whereas in the complex case , there are infinitely many possible phases . in the motivating application scenarios , the natural measurement vectors @xmath233",
    "are again discrete fourier basis vectors . as this",
    "obviously does not suffice for recovery , not even in certain cases or under additional assumptions , one often considers , in addition , phaseless coordinate measurements .",
    "that is , @xmath234 , where @xmath235 is the @xmath236-th standard basis vector .",
    "this extended set of measurements is , in general , also known to not suffice to ensure uniqueness of the solution .",
    "however , as additional measurements are typically not available , there have been numerous works in the physics and optimization literature proposing efficient algorithms , showing empirically that they often yield good solutions , and deriving run time guarantees , see for example @xcite , @xcite , and the references therein .",
    "we will again take a different viewpoint here .",
    "namely , the goal will be to design measurements such that they allow for guaranteed recovery of the signal .",
    "as the measurements are always invariant under multiplication by a phase factor , all one can hope for , however , is recovery up to a global phase .    a first natural question to ask concerns the minimal number of measurements such that the measurement map is injective .",
    "a number of works have been studying this question , often combining methods from frame theory and algebraic geometry . typically , they show injectivity for _ generic _ sets of measurement vectors . here",
    "generic means that the set of measurement vector configurations that yield an injective map @xmath237 ( up to a global phase ) is open and dense in the set of frames .",
    "recall that a frame is a set @xmath238 of vectors in @xmath239 or @xmath65 such that there exists @xmath240 such that for all @xmath241 in @xmath239 or @xmath65 it holds that @xmath242 .    in the real case",
    ", the question of injectivity is completely answered in the following result from @xcite .    for a generic frame @xmath243 ,",
    "the phaseless measurement operator @xmath237 corresponding to the measurement vectors @xmath244 is injective provided @xmath245 . on the other hand ,",
    "no set of @xmath246 measurement vectors in @xmath239 yields an injective operator @xmath237 .",
    "the complex case is less understood .",
    "it is known that @xmath247 generic measurement vectors suffice to achieve injectivity @xcite , and that @xmath248 measurements are necessary @xcite , see also @xcite . while it has been conjectured that @xmath247 measurements are also necessary @xcite",
    ", this question is currently open .",
    "while injectivity is certainly a useful indicator for when the phaseless estimation problem has a chance of being solved , it does not imply anything about the existence of tractable recovery algorithms nor about the conditioning ( and hence the possibility of an efficient inversion in case of noisy measurements ) .",
    "a number of works addressing such issues are based on the observation that the measurement information can be expressed in matrix form .",
    "namely , for @xmath249 and @xmath250 , the constraint @xmath251 can be reexpressed as @xmath252 , where one considers the hilbert - schmidt inner product of matrices @xmath253 . in this formulation ,",
    "the constraints are again linear in @xmath41 .",
    "thus for on the order of @xmath254 ( in the real case ) or @xmath255 suitably chosen measurements , one can directly solve for the @xmath256 or @xmath257 entries of the matrix @xmath44 @xcite ( the reduced number of entries in the real case stems from the fact that then @xmath44 is symmetric ) . the global phase ambiguity mentioned above",
    "is also incorporated in this formulation , as changing @xmath241 by a global phase does not change @xmath44 ( and @xmath241 can be determined from @xmath44 up to a global phase ) .",
    "a number of measurements quadratic in the signal dimension , however , is quite far from the injectivity benchmark of linear scaling in @xmath61 .",
    "one may hope for a significantly smaller sufficient number of measurements because @xmath44 is of rank one .",
    "hence while for a subquadratic number of measurements , the matrix reformulation admits additional ( matrix ) solutions , @xmath44 is definitely the one of smallest rank .",
    "thus the problem boils down to recovering a low - rank matrix from linear measurements .",
    "in contrast to the setup derived in section  [ sec : mr ] , however , the measurements correspond to inner products with rank one matrices and do not satisfy any of the conditions required in the results presented there .",
    "as it turns out , however , the same strategy of convex relaxation still works .",
    "as the matrices considered here are all positive semi - definite , the nuclear norm of the matrix is just the trace .",
    "the resulting algorithm , coined phaselift , is introduced in @xcite as the following minimization problem .",
    "@xmath258 here @xmath259 means that @xmath44 is a positive semi - definite matrix .",
    "similar to , the formulation can also be adapted to noisy measurements . as noted in @xcite and @xcite , with high probability",
    "there is just a single positive semi - definite matrix @xmath44 that satisfies the measurement constraints .",
    "hence , the problem becomes a feasibility problem rather than a convex optimization problem .",
    "phaselift is a tractable algorithm , but not comparable in efficiency to the heuristic algorithms mentioned above .",
    "nevertheless , phaselift is considered a breakthrough for the analysis of the phaseless estimation problem , as for the first time , recovery guarantees could be established .",
    "the first scenario considered was that the measurements are chosen to be gaussian vectors or uniformly distributed on the unit sphere .",
    "as the measurement vector and hence also its length is known , these two measurement setups are equivalent when no noise is considered . in @xcite , non - uniform recovery guarantees were established with high probability for a number of measurements on the order of @xmath260 . in @xcite",
    ", these results were refined to yield uniform recovery guarantees for a number of measurements scaling linearly in @xmath61 .",
    "as obviously no recovery is possible for less measurements than the dimension , these embedding dimensions are optimal up to an absolute constant .",
    "the result from @xcite reads as follows .",
    "assume that the number of measurements satisfies @xmath261 , where @xmath262 is a sufficiently large constant .",
    "for @xmath263 , define @xmath264 , where the @xmath233 are independent standard gaussian vectors .",
    "then with probability at least @xmath265 on the draw of the measurement vectors , it holds that for all @xmath241 , the solution to the minimization problem exactly agrees with the signal @xmath241 .",
    "the recovery is uniform in the sense that the same draw guarantees recovery for all @xmath241 from @xmath266 simultaneously .",
    "note that in contrast to compressed sensing , a direct generalization from gaussian vectors to vectors with subgaussian entries is not possible .",
    "namely , for rademacher measurement vectors recovery can not be possible , as each of the standard unit vectors yields the exact same phaseless measurements , so they can not be distinguished .",
    "thus one needs an additional condition on the small ball probabilities of the entries of the measurement vectors .",
    "we refer to @xcite for details , where the authors do not consider a specific algorithm , but rather derive stability in the sense that signals that significantly differ also yield measurements that are not too close",
    ". moreover , @xcite considers recovery via phaselift from measurements with random unitary matrices .",
    "a first attempt to derive recovery guarantees for different , more efficient algorithms was the polarization algorithm provided in @xcite .",
    "later , in @xcite , the authors consider an alternating minimization algorithm , which is inspired by the heuristic algorithms mentioned above .",
    "both these papers provide recovery guarantees for independent gaussian measurement vectors .    the first paper that derived theoretical guarantees for structured measurements in phase retrieval was @xcite . their work is motivated by applications in diffraction imaging .",
    "as mentioned above , measurements in this setup are absolute values of fourier coefficients , which , a priori , do not suffice to recover the signal .",
    "as suggested in @xcite , however , one can introduce masks into the measurement setup , which have the effect that only parts of the object are illuminated . by varying the mask ,",
    "one can obtain multiple images and thus more information in total . with this modification ,",
    "the above limitations do not apply , so recovery of the signal is possible . in @xcite ,",
    "the authors derive recovery guarantees for the polarization algorithm introduced in @xcite and masked fourier measurements .",
    "the number of measurements they require is of order @xmath260 .    for phaselift",
    ", the first structured measurement setup is provided in @xcite .",
    "the paper considers measurements selected uniformly at random from spherical designs ; the number of measurements necessary to guarantee recovery depends on the order of the design . basically at the same time , @xcite considers phaselift for masked fourier measurements and derives recovery guarantees for a number of measurements on the order of @xmath267 , that is , @xmath268 masks .",
    "subsequently , these guarantees have been improved to require only @xmath269 masks @xcite .",
    "in many works on the phaseless estimation problem , there have been attempts to incorporate sparsity assumptions into the problems to reduce the number of required measurements , see @xcite for first algorithmic and applied contributions .",
    "refined recovery guarantees for @xmath0-sparse signals have first been provided in @xcite .",
    "they provide recovery guarantees for a modification of phaselift and a number of measurements on the order of @xmath270 .",
    "as they show , the quadratic dependence on @xmath0 is necessary in their algorithmic setup , see also @xcite for similar lower bounds . as shown in @xcite ,",
    "the number of gaussian measurements required for stability is of order @xmath75 , hence considerably smaller .",
    "thus for sparse signals , the phaselift approach can not work with optimal embedding dimensions .",
    "based on this work , @xcite provides recovery guarantees for sparse vectors with an additional decay condition using a greedy algorithm for a number of measurements on the order of @xmath75 .",
    "due to the comprehensive nature of this survey article , we can not give a self - contained mathematical exposition of the proof techniques .",
    "in the following , however , we provide some key words and references for the different classes of results presented in this article .    for unstructured random matrices / maps ,",
    "the proof of the restricted isometry property is by - now rather standard : using bernstein s inequality one establishes a concentration inequality for @xmath271 for a fixed @xmath241 .",
    "then one covers the @xmath272-sphere restricted to the sparse vectors / low rank matrices with a relatively dense but finite collection of vectors , a so - called @xmath226-net , takes a union bound of the concentration inequality over the net , and extends the resulting estimate to the whole infinite set of interest by a bootstrapping argument @xcite .    as one can imagine , proving recovery guarantees for structured random measurement matrices / maps is considerably harder because these matrices contain much less randomness .",
    "for instance , in order to establish the restricted isometry property for random partial fourier matrices , one first applies symmetrization @xcite , followed by the dudley inequality for the expected supremum of a subgaussian processes which leads to an integral over covering numbers with respect to a certain metric .",
    "then one uses techniques such as the maurey lemma @xcite in order to bound the resulting covering numbers .",
    "the dudley inequality just mentioned is itself proved using the so - called chaining technique .",
    "talagrand has developed a much more general theory of generic chaining @xcite , and in fact , the bound of the restricted isometry property for partial random circulant matrices ( theorem  [ thm : kmr ] ) is based on a new generic chaining bound for certain chaos processes @xcite , which then again requires to obtain bounds for associated covering numbers .",
    "one ingredient for establishing nonuniform recovery guarantees are condition number bounds for a single submatrix of the measurement matrix corresponding to the columns indexed by the support set .",
    "these often require to estimate the operator norm of a sum of independent random matrices .",
    "traditionally , noncommutative khintchine inequalities @xcite were used for this purpose , but recently , tropp @xcite developed extensions of many classical deviation inequalities such as bernstein s inequality to the matrix setting , which are much simpler to use . in the case of partial random circulant matrices",
    "@xcite and similar setups @xcite one ends up with a double sum of random matrices , a so - called second - order matrix - valued chaos for which an extension of khintchine s inequality can be used to obtain operator norm bounds @xcite .",
    "alternatively , the so - called trace method leads to combinatorial estimates @xcite .",
    "in addition to establishing condition number bounds for the submatrix of the measurement matrix corresponding to the support of the sparse vector , one essentially needs to show that this submatrix behaves well with respect to the columns outside the support .",
    "this task is often the harder part of the analysis in the nonuniform setting . in the initial contribution @xcite ,",
    "it was established by following complicated combinatorial arguments , see also @xcite .",
    "a more elegant approach  called golfing scheme  was developed by gross @xcite in the context of matrix completion .",
    "it proceeds via introducing an artificial iteration by partitioning the matrix into smaller blocks of rows .",
    "however , so far it seems that this approach is restricted to matrices with stochastically independent rows .",
    "we refer to @xcite for details .",
    "f. krahmer acknowledges support by the german federal ministry of education and reseach ( bmbf ) through the cooperative research project zemat .",
    "h. rauhut acknowledges support by the european research council through the starting grant 258926 ( spalora ) .",
    "s.  corroy , a.  bollig , and r.  mathar .",
    "distributed sensing of a slowly time - varying sparse spectrum using matrix completion . in _",
    "8th ieee int .",
    "symp . wireless communication systems ( iswcs )",
    "2011 _ , pages 296300 , 2011 .",
    "r.  f. marcia and r.  m. willett .",
    "compressive coded aperture superresolution image reconstruction . in _",
    "acoustics , speech and signal processing , 2008 .",
    "icassp 2008 _ , pages 833836 .",
    "ieee , 2008 .",
    "h.  rauhut .",
    "ompressive sensing and structured random matrices . in m.",
    "fornasier , editor , _ theoretical foundations and numerical methods for sparse recovery _ , volume  9 of _ radon series comp .",
    "_ , pages 192 . de gruyter , 2010 .                                  r.  vershynin .",
    "ntroduction to the non - asymptotic analysis of random matrices .",
    "in y.  eldar and g.  kutyniok , editors , _ compressed sensing : theory and applications _ , pages xii+544 .",
    "cambridge univ press , cambridge , 2012 ."
  ],
  "abstract_text": [
    "<S> compressed sensing and its extensions have recently triggered interest in randomized signal acquisition . </S>",
    "<S> a key finding is that random measurements provide sparse signal reconstruction guarantees for efficient and stable algorithms with a minimal number of samples . </S>",
    "<S> while this was first shown for ( unstructured ) gaussian random measurement matrices , applications require certain structure of the measurements leading to structured random measurement matrices . near optimal recovery guarantees for such structured measurements </S>",
    "<S> have been developed over the past years in a variety of contexts . </S>",
    "<S> this article surveys the theory in three scenarios : compressed sensing ( sparse recovery ) , low rank matrix recovery , and phaseless estimation . </S>",
    "<S> the random measurement matrices to be considered include random partial fourier matrices , partial random circulant matrices ( subsampled convolutions ) , matrix completion , and phase estimation from magnitudes of fourier type measurements . </S>",
    "<S> the article concludes with a brief discussion of the mathematical techniques for the analysis of such structured random measurements .    and holger rauhut </S>"
  ]
}