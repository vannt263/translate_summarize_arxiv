{
  "article_text": [
    "structured information plays an increasingly important role in applications such as information extraction @xcite , question answering @xcite and robotics @xcite . with the notable exceptions of cyc and wordnet ,",
    "most of the knowledge bases that are used in such applications have at least partially been obtained using some form of crowdsourcing ( e.g.  freebase , wikidata , conceptnet ) . to date ,",
    "such knowledge bases are mostly limited to facts ( e.g.  obama is the current president of the us ) and simple taxonomic relationships ( e.g.  every president is a human ) .",
    "one of the main barriers to crowdsourcing more complex domain theories is that most users are not trained in logic .",
    "this is exacerbated by the fact that often ( commonsense ) domain knowledge is easiest to formalize as defaults ( e.g.  birds typically fly ) , and , even for non - monotonic reasoning ( nmr ) experts , it can be challenging to formulate sets of default rules without introducing inconsistencies ( w.r.t .  a given nmr semantics ) or unintended consequences .    in this paper , we propose a method for learning consistent domain theories from crowdsourced examples of defaults and non - defaults . since these examples are provided by different users , who may only have an intuitive understanding of the semantics of defaults , together they will typically be inconsistent .",
    "the problem we consider is to construct a set of defaults which is consistent w.r.t .",
    "the system p semantics @xcite , and which entails as many of the given defaults and as few of the non - defaults as possible .",
    "taking advantage of the relation between system p and possibilistic logic @xcite , we treat this as a learning problem , in which we need to select and stratify a set of propositional formulas .",
    "the contributions of this paper are as follows .",
    "first , we show that the problem of deciding whether a possibilistic logic theory exists that perfectly covers all positive and negative examples is @xmath0-complete .",
    "second , we formally study the problem of learning from defaults in a standard learning theory setting and we determine the corresponding vc - dimension , which allows us to derive theoretical bounds on how much training data we need , on average , to obtain a system that can classify defaults as being valid or invalid with a given accuracy level .",
    "third , we introduce a heuristic algorithm for learning possibilistic logic theories from defaults and non - defaults . to the best of our knowledge ,",
    "our method is the first that can learn a consistent logical theory from a set of noisy defaults .",
    "we evaluate the performance of this algorithm in two crowdsourcing experiments .",
    "in addition , we show how it can be used for approximating maximum a posteriori ( map ) inference in propositional markov logic networks @xcite .",
    "reasoning with defaults of the form `` if @xmath1 then typically @xmath2 '' , denoted as @xmath3 , has been widely studied @xcite .",
    "a central problem in this context is to determine what other defaults can be derived from a given input set .",
    "note , however , that the existing approaches for reasoning about default rules all require some form of consistency ( e.g.  the input set can not contain both @xmath4 and @xmath5 ) . as a result , these approaches can not directly be used for reasoning about noisy crowdsourced defaults .    to the best of our knowledge ,",
    "this is the first paper that considers a machine learning setting where the input consists of default rules .",
    "several authors have proposed approaches for constructing possibility distributions from data ; see @xcite for a recent survey",
    ". however , such methods are generally not practical for constructing possibilistic logic theories .",
    "the possibilistic counterpart of the z - ranking constructs a possibilistic logic theory from a set of defaults , but it requires that these defaults are consistent and can not handle non - defaults @xcite , although an extension of the z - ranking that can cope with non - defaults was proposed in @xcite .",
    "some authors have also looked at the problem of learning sets of defaults from data @xcite , but the performance of these methods has not been experimentally tested . in @xcite ,",
    "a possibilistic inductive logic programming ( ilp ) system is proposed , which uses a variant of possibilistic logic for learning rules with exceptions . however , as is common for ilp systems , this method only considers classification problems , and can not readily be applied to learn general possibilistic logic theories .",
    "finally note that the setting of learning from default rules as introduced in this paper can be seen as a non - monotonic counterpart of an ilp setting called _ learning from entailment _ @xcite .",
    "a stratification of a propositional theory @xmath6 is an ordered partition of @xmath6 .",
    "we will use the notation @xmath7 to denote the set of all such ordered partitions and @xmath8 to denote the set of all ordered partitions into at most @xmath9 subsets of @xmath6 . a theory in possibilistic logic @xcite",
    "is a set of formulas of the form @xmath10 , with @xmath1 a propositional formula and @xmath110,1]$ ] a certainty weight .",
    "these certainty weights are interpreted in a purely ordinal fashion , hence a possibilistic logic theory is essentially a stratification of a propositional theory .",
    "the strict @xmath12-cut @xmath13 of a possibilistic logic theory @xmath14 is defined as @xmath15 .",
    "the inconsistency level @xmath16 of @xmath14 is the lowest certainty level @xmath12 in @xmath17 $ ] for which the classical theory @xmath13 is consistent .",
    "an inconsistency - tolerant inference relation @xmath18 for possibilistic logic can then be defined as follows : @xmath19 we will write @xmath20 as an abbreviation for @xmath21 . it can be shown that @xmath22 can be decided by making @xmath23 calls to a sat solver , with @xmath9 the number of certaintly levels in @xmath14 @xcite .",
    "there is a close relationship between possibilistic logic and the rational closure of a set of defaults .",
    "recall that @xmath3 is tolerated by a set of defaults @xmath24 if the classical formula @xmath25 is consistent @xcite .",
    "let @xmath26 be a set of defaults .",
    "the rational closure of @xmath26 is based on a stratification @xmath27 , known as the z - ordering , where each @xmath28 contains all defaults from @xmath29 which are tolerated by @xmath30 .",
    "intuitively , @xmath31 contains the most general default rules , @xmath32 contains exceptions to these rules , @xmath33 contains exceptions to these exceptions , etc .",
    "given the stratification @xmath27 we define the possibilistic logic theory @xmath34 , where we assume @xmath35 .",
    "it then holds that @xmath3 is in the rational closure of @xmath26 iff @xmath20 @xcite .",
    "we now cover some basic notions from statistical learning theory @xcite .",
    "we restrict ourselves to binary classification problems , where the two labels are @xmath36 and @xmath37 .",
    "let @xmath38 be a set of _",
    "examples_. a _ hypothesis _ is a function @xmath39 .",
    "a hypothesis @xmath40 is said to cover an example @xmath41 if @xmath42 .",
    "consider a set @xmath43 of @xmath44 labeled examples that have been iid sampled from a distribution @xmath45 .",
    "a hypothesis @xmath40 s sample error rate is @xmath46 where @xmath47 if @xmath48 and @xmath49 otherwise . a hypothesis @xmath40 s expected error w.r.t .  the probability distribution @xmath45 is given by @xmath50 .",
    "$ ] statistical learning theory provides tools for bounding the probability @xmath51 , where @xmath52 is known to be sampled iid from @xmath45 but @xmath45 itself is unknown .",
    "these bounds link @xmath40 s training set error to its ( probable ) performance on other examples drawn from the same distribution , and therefore permits theoretically controlling overfitting .",
    "the most important bounds of this type depend on the vapnik - chervonenkis ( vc ) dimension @xcite .",
    "a hypothesis set @xmath53 is said to shatter a set of examples @xmath54 if for every subset @xmath55 there is a hypothesis @xmath56 such that @xmath42 for every @xmath57 and @xmath58 for every @xmath59 .",
    "the vc dimension of @xmath53 is the cardinality of the largest set that is shattered by @xmath53 .",
    "upper bounds based on the vc dimension are increasing functions of the vc dimension and decreasing functions of the number of examples in the training sample @xmath52 .",
    "ideally , the goal is to minimize expected error , but this can not be evaluated since @xmath45 is unknown . _",
    "structural risk minimization _",
    "@xcite helps with this if the hypothesis set can be organized into a hierarchy of nested hypothesis classes of increasing vc dimension .",
    "it suggests selecting hypotheses that minimize a risk composed of the training set error and a complexity term , e.g.  if two hypotheses have the same training set error , the one originating from the class with lower vc dimension should be preferred .",
    "in this section , we formally describe a new learning setting for possibilistic logic called _ learning from default rules_. we assume a finite alphabet @xmath60 is given .",
    "an example is a default rule over @xmath60 and a hypothesis is a possibilistic logic theory over @xmath60 .",
    "a hypothesis @xmath40 predicts the class of an example @xmath61 by checking if @xmath40 covers @xmath62 , in the following sense .",
    "a hypothesis @xmath56 _ covers _ an example @xmath61 if @xmath63 .",
    "the hypothesis @xmath40 predicts positive , i.e.  @xmath64 , iff @xmath40 covers @xmath62 , and else predicts negative , i.e.  @xmath65 .",
    "let us consider the following set of examples @xmath66 the following hypotheses over the alphabet @xmath67 cover all positive and no negative examples : @xmath68    the learning task can be formally described as follows",
    ".    given : : :    a multi - set @xmath52 which is an iid sample from a    set of default rules over a given finite alphabet    @xmath60 .",
    "do : : :    learn a possiblistic logic theory that covers all positive examples    and none of the negative examples in @xmath52 .",
    "the above definition assumes that @xmath52 is perfectly separable , i.e.  it is possible to perfectly distinguish positive examples from negative examples . in practice",
    ", we often relax this requirement , and instead aim to find a theory that minimizes the training set error .",
    "similar to learning in graphical models , this learning task can be decomposed into _ parameter learning _ and _ structure learning_. in our context ,",
    "the goal of parameter learning is to convert a set of propositional formulas into a possibilistic logic theory , while the goal of structure learning is to decide what that set of propositional formulas should be .",
    "parameter learning assumes that the formulas of the possibilistic logic theory are fixed , and only the certainty weights need to be assigned .",
    "as the exact numerical values of the certainty weights are irrelevant , we will treat parameter learning as the process of finding the most suitable stratification of a given set of formulas , e.g.  the one which minimizes training error or structural risk ( cf .",
    "section [ sec : vc ] ) .",
    "[ ex : learning1 ] let @xmath69 and @xmath70 a stratification of @xmath6 which minimizes the training error on the examples from @xmath52 is @xmath71 which is equivalent to @xmath72 because @xmath73 . note that @xmath74 correctly classifies all examples except @xmath75 .",
    "given a set of examples @xmath52 , we write @xmath76 and @xmath77 ) .",
    "a stratification @xmath78 of a theory @xmath6 is a _ separating stratification _ of @xmath79 and @xmath80 if it covers all examples from @xmath79 and no examples from @xmath80 .",
    "[ exzrankingcomparison ] let us consider the following set of examples @xmath81 let @xmath82 .",
    "the following stratification is a separating stratification of @xmath79 and @xmath80 : @xmath83 .",
    "note that the z - ranking of @xmath79 also corresponds to a stratification of @xmath6 , as @xmath6 contains exactly the clause representations of the positive examples . however using the z - ranking leads to a different stratification , which is :",
    "@xmath84 note that @xmath85 whereas @xmath86 .",
    "because arbitrary stratifications can be chosen , there is substantial freedom to ensure that negative examples are not covered .",
    "this is true even when the set of considered formulas is restricted to the clause representations of the positive examples , as seen in example [ exzrankingcomparison ] .",
    "unfortunately , the problem of finding an optimal stratification is computationally hard .",
    "[ thm - complexity ] deciding whether a separating stratification exists for given @xmath6 , @xmath79 and @xmath80 is a @xmath0-complete problem .",
    "the proof of the membership result is trivial .",
    "we show the hardness result by reduction from the @xmath0-complete problem of deciding the satisfiability of quantified boolean formulas of the form @xmath87 where @xmath88 and @xmath89 are vectors of propositional variables and @xmath90 is a propositional formula .",
    "let @xmath91 be a propositional theory , let @xmath92 and @xmath93 .",
    "we need to show that @xmath87 is satisfiable if and only if there exists a separating stratification for @xmath6 , @xmath79 and @xmath80 .",
    "( @xmath94 ) let @xmath95 be an assignment of variables in @xmath88 such that @xmath96 is true",
    ". then we can construct the separating stratification as @xmath97 since @xmath90 will always be true in any model consistent with the highest level of the stratification , because of the way we chose @xmath98 and @xmath99 for this level , so will @xmath100 .",
    "( @xmath101 ) let @xmath78 be a stratification of @xmath6 which entails the default rule @xmath102 .",
    "we can assume w.l.o.g .",
    "that @xmath78 has only two levels .",
    "since @xmath78 is a separating stratification , we must have @xmath103 .",
    "therefore the highest level @xmath104 of @xmath78 must be a consistent theory and @xmath90 must be true in all of its models .",
    "let @xmath105 and @xmath106 .",
    "we can construct an assignment @xmath95 to variables in @xmath107 by setting @xmath108 for @xmath109 and @xmath110 for @xmath111 .",
    "it follows from the construction that @xmath112 must be true .",
    "as this result reveals , in practice we will need to rely on heuristic methods for parameter learning . in section [ secheuristicalgorithm ]",
    "we will propose such a heuristic method , which will moreover also include structure learning .",
    "we explore the vc dimension of the set of possible stratifications of a propositional theory , as this will allow us to provide probabilistic bounds on the generalization ability of a learned possibilistic logic theory .",
    "let us write @xmath7 for the set of all stratifications of a propositional theory @xmath6 , and let @xmath8 be the set of all stratifications with at most @xmath9 levels .",
    "the following proposition provides an upper bound for the vc dimension and can be proved by bounding the cardinality of @xmath8 .",
    "[ prop : upperbound ] let @xmath6 be a set of @xmath44 propositional formulas",
    ". then @xmath113 .    in the next theorem",
    ", we establish a lower bound on the vc dimension of stratifications with at most @xmath9 levels which shows that the above upper bound is asymptotically tight .",
    "[ thm - vc2 ] for every @xmath114 , @xmath115 , there is a propositional theory @xmath6 consisting of @xmath44 formulas such that @xmath116    to prove theorem [ thm - vc2 ] , we need the following lemmas ; some straightforward proofs are omitted due to space constraints .",
    "[ lemma : orders ] if @xmath52 is a totally ordered set , let @xmath117 denote the @xmath118-th highest element of @xmath52 .",
    "let @xmath119 be a set of cardinality @xmath120 where @xmath121 .",
    "let @xmath122 be a set of @xmath123 inequalities .",
    "then for any @xmath124 there is a permutation of @xmath38 satisfying all constraints from @xmath125 and no constraints from @xmath126 .",
    "[ lemma : pos_order ] let @xmath127 denote a boolean formula which is true if and only if at least @xmath9 of the arguments are true .",
    "let @xmath128 be a set of propositional logic variables and @xmath129 be a permutation of elements from @xmath38 .",
    "let @xmath130 .",
    "let @xmath131 be a possibilistic logic theory .",
    "let @xmath132 and @xmath133 be disjoint subsets of @xmath38 . then @xmath134 iff @xmath135 w.r.t .  the ordering given by the permutation @xmath136 .",
    "[ lemma : vc3 ] for every @xmath120 there is a propositional theory @xmath6 consisting of @xmath44 formulas such that @xmath137    let @xmath138 be a set of propositional variables where @xmath120 , @xmath139 and let @xmath140 be defined as in lemma [ lemma : orders ] .",
    "let @xmath141 @xmath142 i.e.  @xmath143 contains one default rule for every inequality from @xmath140 .",
    "it follows from lemma [ lemma : orders ] and lemma [ lemma : pos_order ] that the set @xmath143 can be shattered by stratifications of the propositional theory @xmath6 .",
    "the cardinality of @xmath143 is @xmath144",
    ". therefore the vc dimension of stratifications of @xmath6 is at least @xmath144 .",
    "we show that if @xmath9 and @xmath44 are powers of two then @xmath145 is a lower bound of the vc dimension .",
    "the general case of the theorem then follows straightforwardly .",
    "let @xmath146 and let @xmath147 be a set of default rules of cardinality @xmath148 shattered by @xmath149 .",
    "it follows from lemma [ lemma : vc3 ] that such a set @xmath147 always exists .",
    "let @xmath150 .",
    "then @xmath143 has cardinality @xmath145 and is shattered by @xmath8 . to see that the latter holds , note that the sets of formulas @xmath149 are disjoint",
    "therefore , if we want to find a stratification from @xmath8 which covers only examples from an arbitrary set @xmath151 and no other examples from @xmath143 then we can merge stratifications of @xmath152 which cover exactly the examples from @xmath153 , where merging stratifications is done by level - wise unions .    combining the derived lower bounds and upper bounds on the vc dimension together with the structural risk minimization principle",
    ", we find that given two stratifications with the same training set error rate , we should prefer the one with the fewest levels .",
    "furthermore , when structure learning is used , it is desirable for learned theories to be compact .",
    "a natural learning problem then consists in selecting a small subset of @xmath6 , where @xmath6 corresponds to the set of formulas considered by the structure learner , and identifying a stratification only for that subset . the results in this section can readily be extended to provide bounds on the vc dimension of this problem .",
    "let @xmath6 be a propositional theory of cardinality @xmath44 and let @xmath154 be a positive integer .",
    "the vc dimension of the set of hypotheses involving at most @xmath155 formulas from @xmath6 and having at most @xmath9 levels is bounded by @xmath156 .",
    "this can simply be obtained by upper - bounding the number of the different stratifications with at most @xmath9 levels and @xmath155 formulas selected from a set of cardinality @xmath44 , by @xmath157 .      in this section ,",
    "we propose a practical heuristic algorithm for learning a possibilistic logic theory from a set @xmath52 of positive and negative examples of default rules .",
    "our method combines greedy structure learning with greedy weight learning .",
    "we assume that every default or non - default @xmath3 in @xmath52 is such that @xmath158 and @xmath2 correspond to clauses .",
    "the algorithm starts by initializing the `` working '' stratification @xmath78 to be an empty list .",
    "then it repeats the following revision procedure for a user - defined number of iterations @xmath44 , or until a timeout is reached .",
    "first , it generates a set of candidate propositional clauses @xmath159 as follows :    * it samples a set of defaults @xmath3 from the examples that are misclassified by @xmath78 . * for each default",
    "@xmath3 which has been sampled , it samples a subclause @xmath160 of @xmath161 and a subclause @xmath162 of @xmath2 .",
    "if @xmath3 is a positive example then @xmath163 is added to @xmath159 ; if it is a negative example , then @xmath164 is added instead , where @xmath165 is obtained from @xmath162 by negating each of the literals .",
    "the algorithm then tries to add each formula in @xmath159 to an existing level of @xmath78 or to a newly inserted level .",
    "it picks the clause @xmath166 whose addition leads to the highest accuracy and adds it to @xmath78 .",
    "the other clauses from @xmath159 are discarded . in case of ties , the clause which leads to the stratification with the fewest levels",
    "is selected , in accordance with the structural risk minimization principle and our derived vc dimension .",
    "if there are multiple such clauses , then it selects the shortest among them .",
    "subsequently , the algorithm tries to greedily minimize the newly added clause @xmath166 , by repeatedly removing literals as long as this does not lead to an increase in the training set error .",
    "next , the algorithm tries to revise @xmath78 by greedily removing clauses whose deletion does not increase the training set error . finally , as the last step of each iteration",
    ", the weights of all clauses are optimized by greedily reinserting each clause in the theory .",
    "we evaluate our heuristic learning algorithmthe data , code , and learned models are available from https://github.com / supertweety/. ] in two different applications : learning domain theories from crowdsourced default rules and approximating map inference in propositional markov logic networks . as we are not aware of any existing methods that can learn a consistent logical theory from a set of noisy defaults , there are no baseline methods to which our method can directly be compared .",
    "however , if we fix a target literal @xmath167 , we can train standard classifiers to predict for each propositional context @xmath1 whether the default @xmath168 holds .",
    "this can only be done consistently with `` parallel '' rules , where the literals in the consequent do not appear in antecedents .",
    "we will thus compare our method to three traditional classifiers on two crowdsourced datasets of parallel rules : random forests @xcite , c4.5 decision trees @xcite , and the rule learner ripper @xcite .",
    "random forests achieve state - of - the - art accuracy but its models are difficult to interpret .",
    "decision trees are often less accurate but more interpretable than random forests .",
    "finally , rule learners have the most interpretable models , but often at the expense of lower accuracy . in the second experiment ,",
    "approximating map inference , we do not restrict ourselves to parallel rules . in this case , only our method can guarantee that the predicted defaults will be consistent .",
    "our learning algorithm is implemented in java and uses the sat4j library @xcite .",
    "the implementation contains a number of optimizations which make it possible to handle datasets of thousands of default rules , including caching , parallelization , detection of relevant possibilistic subtheories for deciding entailment queries and unit propagation in the possibilistic logic theories .",
    "we use the weka @xcite implementations for the three baselines .",
    "when using our heuristic learning algorithm , we run it for a maximum time of 10 hours for the crowdsourcing experiments reported in section [ sec : exp - crowd ] and for one hour for the experiments reported in section [ sec : exp - map ] . for c4.5 and ripper ,",
    "we use the default settings . for random forests",
    ", we used the default settings and set the number of trees to 100 .",
    "we used crowdflower , an online crowdsourcing platform , to collect expert rules about two domains . in the first experiment",
    ", we created 3706 scenarios for a team on offense in american football by varying the field position , down and distance , time left , and score difference .",
    "then we presented six choices for a play call ( punt , field goal , run , pass , kneel down , do not know / it depends ) and asked the user to select the most appropriate one .",
    "all scenarios were presented to 5 annotators .",
    "a manual inspection of a subset of the rules revealed that they are of reasonably high quality . in a second experiment , users were presented with 2388 scenarios based on texas holdem poker situations , where users were asked whether in a given situation they would typically fold , call or raise , with a fourth option again being `` do not know / it depends '' . each scenario was again presented to 5 annotators .",
    "given the highly subjective nature of poker strategy , it was not possible to enforce the usual quality control mechanism on crowdflower in this case , and the quality of the collected rules was accordingly found to be more variable .    in both cases ,",
    "the positive examples are the rules obtained via crowdsourcing , while negative examples are created by taking positive examples and randomly selecting a different consequent . to create training and testing sets , we divided the data based on annotator i d so that all rules labeled by a given annotated appear only in the training set or only in the testing set , to prevent leakage of information .",
    "we added a set of hard rules to the possibilistic logic theories to enforce that only one choice should be selected for a game situation .",
    "the baseline methods were presented with the same information , in the sense that the problem was presented as a multi - class classification problem , i.e.  given a game situation , the different algorithms were used to predict the most typical action ( with one additional option being that none of the actions is typical ) .",
    "the results are summarized in table [ tab : mrfs ] .    in the poker experiment ,",
    "our approach obtained slightly higher accuracy than random forest and ripper but performed slightly worse than c4.5 .",
    "however , a manual inspection showed that a meaningful theory about poker strategy was learned .",
    "for example , at the lowest level , the possibilistic logic theory contains the rule `` call '' , which makes sense given the nature of the presented scenarios . at a higher level",
    ", it contains more specific rules such as `` if you have three of a kind then raise '' . at the level above , it contains exceptions to these more specific rules such as `` if you have three of a kind , there are three hearts on the board and your opponent raised on the river then call '' .    in the american football experiment ,",
    "our approach obtained lower accuracy than the competing algorithms .",
    "the best accuracy was achieved by c4.5 .",
    "again , we also manually inspected the learned possibilistic logic theory and found that it captures some general intuitions and known strategy about the game .",
    "for example , the most general rule is `` pass '' which is the most common play type .",
    "another example is that second most general level has several rules that say on fourth down and long you should punt .",
    "more specific levels that allow for cases when you should not punt , such as when you are in field goal range .    despite not achieving the same accuracy as c4.5 in this experiment",
    ", it nonetheless seems that our method is useful for building up domain theories by crowdsourcing opinions .",
    "the learned domain theories are easy to interpret ( e.g. , the size of the poker theory , as a sum of rule lengths , is more than 10 times smaller than the number of nodes in the learned tree ) and capture relevant strategies for both games .",
    "the models obtained by classifiers such as c4.5 , on the other hand , are often difficult to interpret . moreover , traditional classifiers such as c4.5 can only be applied to parallel rules , and will typically lead to inconsistent logical theories in more complex domains .",
    "in contrast , our method can cope with arbitrary default rules as input , making it much more broadly applicable for learning domain theories .",
    ".test set accuracies . [ cols=\"<,^,^,^,^\",options=\"header \" , ]     the implementation available online contains also an optimized version of the exact algorithm.note that due to its high complexity the algorithm described in this section does not scale to problems involving large numbers of default rules . for practical problems ,",
    "it is therefore preferable to use the heuristic algorithm described in section  [ secheuristicalgorithm ] .",
    "in this section we briefly describe two examples of theories , one learned in the crowd - sourced poker domain ( see section [ sec : exp - crowd ] ) and the other learned in map - inference approximation experiments for the nltcs domain ( see section [ sec : exp - map ] ) .",
    "the learned theory for the poker domain is shown in table  [ tab : poker ] . since default rules in the dataset from which this theory was learned were all `` parallel rules '' , most of the formulas in the theory are clausal representations of implications of the form `` if situation @xmath1 then action @xmath2 '' ; an exception to this is one of the rules in the lowest level which has the form `` not situation @xmath1 '' , where @xmath1 is in this case `` the flop cards have just been dealt and you have a straight draw and a flush draw '' , and this rule basically serves to block the other rules in this level for evidence @xmath169 .",
    "the top level of the theory consists of hard integrity constraints .",
    "table [ tab : nltcs ] shows a small theory which was learned in the nltcs domain after 20 iterations of the algorithm ( the complete learned theory available online is larger ) . since in this domain",
    "the default rules were not restricted to be of the `` parallel '' form , also the structure of the rules in the theory is more complex ."
  ],
  "abstract_text": [
    "<S> we introduce a setting for learning possibilistic logic theories from defaults of the form `` if alpha then typically beta '' . </S>",
    "<S> we first analyse this problem from the point of view of machine learning theory , determining the vc dimension of possibilistic stratifications as well as the complexity of the associated learning problems , after which we present a heuristic learning algorithm that can easily scale to thousands of defaults . </S>",
    "<S> an important property of our approach is that it is inherently able to handle noisy and conflicting sets of defaults . among others , </S>",
    "<S> this allows us to learn possibilistic logic theories from crowdsourced data and to approximate propositional markov logic networks using heuristic map solvers . </S>",
    "<S> we present experimental results that demonstrate the effectiveness of this approach . </S>"
  ]
}