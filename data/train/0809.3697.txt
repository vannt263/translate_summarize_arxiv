{
  "article_text": [
    "as stated in @xcite , the current data deluge inundating science is remarkable for the rapid proliferation in new data type .",
    "typical examples are directions in @xmath7 or elements of the grassmann manifold @xmath0 of all vector subspaces of dimension @xmath1 of @xmath2 ( @xmath8 ) , as introduced in @xcite .",
    "being of increasing importance in practical situations ( see e.g. @xcite , @xcite , @xcite , @xcite , @xcite , @xcite or @xcite ) , there is a strong need for studying various classical inference problems , like for example maximum likelihood estimation . to deal with these problems , one can in most cases reparametrize the manifold and recast the inference problem in some euclidean space .",
    "however , this can have the effect of hiding intrinsic geometric properties of the statistical relevant objects ( see below ) .",
    "a typical example is obtained when dealing with @xmath0 when @xmath6 , the set of axes or directions in @xmath2 , see e.g. @xcite and @xcite . in @xcite ,",
    "the manifold is endowed with the _ angular gaussian distribution _ , that is of the law of the random direction obtained by retaining only the axis of a multivariate centered gaussian random vector in @xmath2 of covariance matrix @xmath9 .",
    "kent and tyler @xcite derived sufficient conditions for the existence of the maximum likelihood estimator ( mle ) based on an i.i.d .",
    "sample by working on @xmath10 ; the angular gaussian distribution is then equivalent to the cauchy law .",
    "the mathematical analysis can then be performed in @xmath10 , at the cost of loosing nice properties of the problem . in @xcite ,",
    "the whole picture was obtained using mainly convexity .",
    "the parameter space @xmath11 consists of positive definite self adjoint matrices of determinant 1 , which is considered as a riemanian manifold with a natural metric .",
    "the results derived in @xcite make strong use of this manifold structure , of the particular form of the log likelihood function and of the geometric link between the parameter space @xmath11 and the sample space @xmath0 , @xmath6 .",
    "interestingly , the estimated scatter matrix plays a fundamental rle for multivariate nonparametric tests , where it is known as the _ tyler s transformation matrix _",
    ", see e.g. @xcite , or in finance where the maximum likelihood estimator is used to fit financial data , see @xcite .",
    "when @xmath1 is arbitrary , we obtain random subspaces by retaining only the linear span @xmath12 of an i.i.d .",
    "sample of @xmath1 multivariate centered gaussian random vectors of covariance matrix @xmath13 .",
    "the law of this random subspace has been considered previously in the literature and has been termed as the _ matrix angular gaussian distribution _ ( see e.g. @xcite , @xcite or @xcite ) ; however , basic questions like the existence of the mle remain unexplored .",
    "we will show that a new phenomenon emerges : in most statistical settings , the mle based on some sample @xmath14 exists with probability one when the size @xmath15 is larger that a critical value @xmath16 and does not exist with probability one when @xmath17 , like for example in the angular gaussian case with @xmath6 ( see e.g. @xcite ) . in the grassmannian setting , we show in example 2 of section 3 that there are sizes @xmath15 such that the mle exists with positive probability and does not exist with positive probability ( see e.g. @xcite where a similar phenomenon occurs in logistic regression ) .",
    "section 2 introduces the grassmannian statistical model and the related likelihood function .",
    "section 3 considers the problem of existence and uniqueness of the grassmannian maximum likelihood estimate ( ge ) .",
    "our main results , theorems 1 and 2 give necessary and sufficient conditions for the existence of a unique ge .",
    "the geometrical setting is illustrated in examples 1 and 2 .",
    "section 4 provides fundamental properties of the likelihood function like its convexity when restricted to the geodesics of @xmath11 .",
    "this nice property is then used to prove theorems 1 and 2 .",
    "theorem 4 of section 5 shows finally that the ge of almost all samples of size @xmath15 is unique when @xmath18",
    "we present two versions of the grassmannian  model , real or complex . to treat them in parallel , we set @xmath19 or @xmath20 , and denote by @xmath21 the adjoint of a matrix @xmath22 , i.e. , the transpose of @xmath23 if @xmath19 and the complex conjugate of the transpose of @xmath24 if @xmath25 .",
    "a square matrix @xmath26 is self - adjoint when @xmath27 , i.e. , symmetric if @xmath19 and hermitian if @xmath28 .",
    "let @xmath29 be i.i.d .",
    "random vectors in @xmath30 with central normal distribution of positive definite self - adjoint covariance matrix  @xmath31 .",
    "the density of the normal law is @xmath32 ( @xmath33 ) up to a constant factor in both the real and the complex case .",
    "we define the _ grassmannian  distribution of parameter @xmath31 _ as the law of the linear span @xmath34 of these vectors in @xmath30 .",
    "it is a borel probability measure @xmath35 on the _ grassmann manifold  @xmath0 _ of all vector subspaces of dimension @xmath1 of @xmath30 ( @xmath8 ) .",
    "the parameter @xmath31 of a grassmannian  distribution @xmath35 is defined up to a a positive factor only .",
    "we remove this indeterminacy by requiring the determinant of @xmath31 to be @xmath36 .",
    "so , we parametrize the grassmannian  distributions by the space @xmath37 of positive definite self - adjoint matrices @xmath26 of determinant @xmath36 .    given a regular matrix @xmath38 , the random vectors @xmath39 are i.i.d .",
    "with central normal law of covariance matrix @xmath40 .",
    "hence , the image measure of @xmath35 under the transformation of @xmath0 given by @xmath41 for @xmath42 is @xmath43 in fact , _ the grassmannian  statistical model @xmath44 is the unique family of borel probability measures on @xmath0 indexed by @xmath37 enjoying the equivariance property   for all matrices @xmath38 of determinant @xmath36 . _ to see this , observe that condition implies the invariance of @xmath35 under the group of invertible matrices @xmath24 of determinant  @xmath36 such that @xmath45 .",
    "as this group is compact and acts continuously and transitively on @xmath0 , there is a unique borel probability measure on @xmath0 which is invariant under it , namely @xmath35 .",
    "let us represent a point @xmath42 as the linear span @xmath46 of linearly independent vectors @xmath47 of @xmath48 or , equivalently , as the range @xmath49 of the matrix @xmath50 of rank @xmath1 .",
    "then , a computation shows that the density , or radon - nikodym derivative , of the grassmannian  distribution @xmath35 ( @xmath51 ) with respect to the uniform distribution @xmath52 on @xmath0 ( @xmath53 = identity matrix ) is given by @xmath54 where @xmath55 ( see @xcite for the real case ) .",
    "the meaning of this formula is perhaps more apparent in the form @xmath56 where @xmath57 denotes the ellipsoid associated to @xmath31 ( @xmath58 = unit ball ) , and @xmath59 the lebesgue measure on @xmath48 .    when @xmath6 , the grassmannian  distribution @xmath35 is known as the ( real or complex ) _ angular gaussian distribution _ of parameter @xmath51 on the projective space @xmath60 ( see @xcite ) . for any @xmath8 , the grassmann manifold  @xmath0 can be viewed as the space of projective subspaces of dimension @xmath61 of @xmath62 by identifying a vector @xmath1-subspace @xmath48 of @xmath30 with the projective subspace @xmath63 .",
    "_ in this projective interpretation , the grassmannian  distribution @xmath35 on @xmath0 is the law of the projective span of i.i.d .",
    "random points @xmath64 of @xmath62 with angular gaussian distribution of parameter @xmath31 .",
    "_      let @xmath65 be a borel probability measure on @xmath0 .",
    "typically , we think of @xmath65 as being the empirical measure @xmath66 of a sample @xmath67 in @xmath0 , but other cases are of interest too . a parameter @xmath51 is called a _ grassmannian ( maximum likelihood ) estimate _",
    "abbreviated ge  in the sequel of @xmath65 if it maximizes the log - likelihood @xmath68 .",
    "it is called a ge  of a sample @xmath69 when @xmath65 is the empirical measure @xmath66 .    for convenience",
    ", we shall rather work with the following negative version of the log - likelihood @xmath70 with this notation , a ge  of @xmath65 minimizes @xmath71 .",
    "[ main ] a borel probability measure @xmath65 on the real or complex grassmannian @xmath0 has a unique ge   if and only if @xmath72 for all nontrivial linear subspaces @xmath73 of @xmath30 ( @xmath74 ) .    in the case of an empirical measure",
    "@xmath75 ,    [ cormain ] a sample @xmath76 in the real or complex grassmannian @xmath0 has a unique ge  if and only if @xmath77 for all nontrivial linear subspaces @xmath73 of @xmath30 ( @xmath74 ) .",
    "the proof of the theorem will be presented in the next section .",
    "let us first consider some special cases .",
    "[ proj ] when @xmath6 , @xmath0 is the projective space @xmath62 , and the grassmannian  distributions are known as angular gaussian distributions . in this case ,",
    "@xmath78 or @xmath79 in corollary  [ cormain ] according to whether @xmath80 or not .",
    "the necessary and sufficient condition for a sample of size @xmath15 in @xmath62 to have a unique angular gaussian maximum likelihood estimate is that the number of points of the sample contained in a nontrivial vector subspace @xmath73 of @xmath30 be less than @xmath81 _ ( see @xcite for a more precise result ) .",
    "now , almost all samples in @xmath62 are in general position , ie . , any nontrivial vector subspace @xmath73 of @xmath30 contains at most @xmath82 points of the sample . thus _",
    "almost all samples of size @xmath83 in @xmath62 have a unique angular gaussian maximum likelihood estimate . _",
    "this result goes back to @xcite .",
    "on the other hand , _ no samples of size @xmath84 in @xmath62 have a unique angular gaussian maximum likelihood estimate _ since any point @xmath85 of a sample is , of course , contained in the one - dimensional subspace @xmath86 of @xmath30 , so that the condition for the number of points of the sample contained in @xmath73 to be less than @xmath81 is not satisfied when @xmath84 .    for a grassmannian @xmath0 which is not a projective space , the situation is more involved , even in the simplest case @xmath87 , @xmath88 .",
    "[ lines ] let @xmath67 be a sample in the grassmann manifold  @xmath89 , viewed as the space of lines in the projective space @xmath90 .",
    "suppose that the lines @xmath67 are pairwise skew , i.e. , @xmath91 for @xmath92 .",
    "examining case by case all of the possible values of @xmath82 and @xmath93 in corollary [ cormain ] , we find that the sample has a unique ge  if and only if @xmath94 , where @xmath95 is the maximum number of lines of the sample all of which are met by some line @xmath96 . now ,",
    "given a line @xmath73 , we can choose any number @xmath15 of pairwise skew lines @xmath97 meeting @xmath73 , so that @xmath98 .",
    "hence , there are arbitrary large samples of pairwise skew lines not having a unique ge .",
    "what is needed is a bound for @xmath95 .",
    "recall that the lines meeting each of three pairwise skew lines @xmath99 , @xmath100 and @xmath101 form a one - dimensional family @xmath102 of lines on a quadric surface @xmath103 , whereas the other family @xmath104 of lines on @xmath105 consists of the lines meeting every line of @xmath102 .",
    "a point of intersection @xmath106 of a further line @xmath107 with the quadric @xmath105 determines a line meeting each of the four lines @xmath99 , @xmath100 , @xmath101 and @xmath108 , namely the line @xmath109 through  @xmath106 , and vice versa ( see fig .",
    "[ fig : quadric ] ) .",
    "[ ] @xmath99 [ ] @xmath100 [ ] @xmath101 [ ] @xmath108 [ ] @xmath73 [ ] @xmath106     the number of lines meeting four pairwise skew lines @xmath99 , @xmath100 , @xmath101 and @xmath108 is thus    * @xmath110 if @xmath108 meets @xmath105 transversally , * @xmath79 if @xmath108 does not meet @xmath105 , which can occur only when @xmath19 , * @xmath36 if @xmath108 is tangent to @xmath105 , * infinite if @xmath108 lies on @xmath105 , in which case @xmath111 so that every line meeting @xmath99 , @xmath100 and @xmath101 necessarily meets @xmath108 too .    in",
    "both the real and the complex case , there are at most two lines @xmath96 meeting each of four pairwise skew lines , except when the four lines belong to the same family of lines on a smooth quadric .",
    "so , almost all samples of size @xmath15 in @xmath89 consist of pairwise skew lines of which at most four are intersected by a line @xmath96 .",
    "we conclude from the criterion above that _ almost all samples of size @xmath112 in the real or complex grassmann manifold  @xmath89 have a unique ge . _    in the complex case",
    ", there is a line meeting each of any four pairwise skew lines @xmath99 , @xmath100 , @xmath101 and @xmath108 since @xmath108 always meets the quadric @xmath105 .",
    "the same holds if some of the four lines meet together or even coincide .",
    "thus , by corollary  [ cormain ] , _ no samples of size @xmath113 in the complex grassmann manifold  @xmath89 have a unique ge .",
    "_    the situation is different in the real case since @xmath108 need not meet the quadric  @xmath105 .",
    "if we choose four lines at random , there may be a line meeting each of them or not , with a positive probability in both cases .",
    "therefore , _ the probability that a random sample of size @xmath114 in the real grassmann manifold  @xmath89 has a unique ge  is positive and @xmath115 . _    on the other hand , by corollary  [ cormain ] , _",
    "no samples of size @xmath116 in the real grassmann manifold  @xmath89 have a unique ge  _ since any @xmath116 lines are intersected by some line ( in fact , by infinitely many lines ) .",
    "we first introduce notions from linear algebra which are necessary to settle the likelihood equation on the symmetric space pos(m ) .",
    "consider the scalar product @xmath117 associated to a parameter @xmath51 .",
    "we denote by @xmath118 the _ @xmath31-orthogonal projector _ onto a vector subspace  @xmath48 of @xmath30 .",
    "it is the linear map @xmath119 defined by @xmath120 if @xmath121 , and @xmath122 if @xmath123 is _",
    "@xmath31-orthogonal _ to @xmath48 , i.e. , @xmath124 for all @xmath121 . in matrix notation , @xmath125 where @xmath49 is the range of @xmath126 .",
    "we call a matrix @xmath38 _ self-@xmath31-adjoint _ if @xmath127 for all @xmath128 or , equivalently , if it coincides with its _ @xmath31-adjoint _ @xmath129 .",
    "the parameter space @xmath37 is a riemannian manifold , in fact a symmetric space .",
    "its tangent space @xmath130 at @xmath51 consists of the self-@xmath31-adjoint  matrices @xmath131 of trace zero , and the riemannian metric is defined by the scalar products @xmath132 on the tangent spaces @xmath130 , where @xmath133 denotes the trace of a matrix  @xmath24 .",
    "the geodesic @xmath134 of velocity @xmath135 issuing from @xmath51 is @xmath136 where @xmath137 denotes the matrix exponential .",
    "deriving the expression along a geodesic   and using the matrix form   of the @xmath31-orthogonal projector @xmath118 onto @xmath48 , we find the gradient ( with respect to the riemannian metric   defined above ) of the log - density @xmath138 by integrating these formulas with respect to @xmath65 , and interchanging integration and derivation by means of the lebesgue dominated convergence theorem , we get the gradient of the log - likelihood @xmath139dp(u).\\end{aligned}\\ ] ] a function @xmath140 on @xmath37 is called _ convex _ if its restriction @xmath141 ( @xmath142 ) to any geodesic @xmath143 is convex in the usual sense",
    ". this amounts to saying that the hessian @xmath144 is positive semi - definite , i.e. , @xmath145 for all @xmath51 and @xmath135 , since @xmath146 where @xmath147 is the velocity of the geodesic @xmath143 .",
    "[ convex ] the log - likelihood function @xmath71 is convex .",
    "more precisely , its restriction @xmath148 ( @xmath142 ) to a geodesic @xmath143 is either strictly convex or affine linear .",
    "the latter case occurs if and only if @xmath149 for @xmath65-almost all @xmath42 , where @xmath147  is the velocity of the geodesic .",
    "the convexity can be obtained directly by proceeding as in @xcite . on the other hand",
    ", one can use the fact that the log - likelihood function is a _",
    "busemann function _ for the symmetric space pos(m ) ( see e.g. @xcite ) , and convexity follows .",
    "as the log - likelihood function @xmath71 is convex , its minima are exactly the zeroes of its gradient hence , by formula  ,    a parameter @xmath51 is a ge  of a borel probability measure  @xmath65 on @xmath0 if and only if it satisfies the _ maximum likelihood equation _",
    "@xmath150    _",
    "proof of theorem [ main ]",
    "_    one can either proceed as in @xcite , or use the fact that the log - likelihood functions is a busemann function of the symmetric space pos(m ) , see e.g. @xcite .",
    "the maximum likelihood estimator is then the barycenter of the related probability measure on the grassman manifold , viewed as an orbit in the tits boundary.theorem [ main ] then follows from proposition 6.2 of @xcite .",
    "in order to apply the criteron of corollary  [ cormain ] for the existence and uniqueness of the ge  of a sample , we must first answer the following question .    _ given vector subspaces @xmath151 of dimension @xmath1 of @xmath30 and integers @xmath152 , on what conditions is there a vector subspace @xmath153 of dimension @xmath154 of @xmath30 such that @xmath155 for @xmath156 ? _ a necessary condition , using methods of algebraic geometry , is given by proposition  [ intersection ] below .    in a second step ,",
    "we look for all possibilities with @xmath157 and @xmath158 using methods of linear programming .",
    "this leads to the following .",
    "[ mainbound ] almost all samples of size @xmath159 in the real or complex grassmann manifold  @xmath0 have a unique ge .",
    "our main tool is the schubert calculus on the grassmannian @xmath160 . in general , the _",
    "schubert variety _",
    "( @xcite , @xcite ) associated to a young diagram or partition @xmath161 with at most @xmath154 rows and @xmath162 columns and a complete flag @xmath163 of vector subspaces of @xmath30 is defined as @xmath164 it is an irreducible algebraic subvariety of codimension @xmath165 of the grassmannian @xmath160 of dimension @xmath166 .",
    "in particular , given @xmath42 and an integer @xmath167 such that @xmath168 the set @xmath169 is the schubert variety @xmath170 associated to the rectangular young diagram @xmath171 with @xmath172 rows and @xmath167 columns if we choose the flag in such a way that @xmath173 .",
    "so , @xmath174    [ intersection ] the following property holds for almost all samples @xmath175 in the real or complex grassmann manifold  @xmath0 . for any vector subspace @xmath73 of dimension @xmath154 of @xmath30 ,",
    "@xmath176 where @xmath177 .",
    "_ the conditions   and   are necessary for the existence of a vector subspace @xmath73 such that @xmath177 for @xmath178 .",
    "but they are not sufficient , as shown by the example @xmath179 , @xmath180 , @xmath181 , @xmath182 , @xmath183 . in this case , the inequalities   and   are satisfied , although there is in general no @xmath184 meeting @xmath99 and @xmath100 in subspaces of dimension 2 .    to get necessary and sufficient conditions , we need the schubert calculus .",
    "but computations in the schubert calculus ( littlewood - richardson coefficients ) are algorithmically hard @xcite so we must content ourselves with proposition  [ intersection ] .    the inequalities   for @xmath177 follow from the dimension formula @xmath185 the proof of the rest of the proposition uses standard methods of algebraic geometry .",
    "let @xmath186 be arbitrary integers satisfying the inequalities   and consider the algebraic correspondence @xmath187 the range of @xmath188 is the whole of @xmath160 , and its domain @xmath189 consists of the samples @xmath190 for which there is some @xmath153 with @xmath191 for @xmath178 .",
    "let @xmath192 be a generic point of @xmath188 .",
    "observe that @xmath193 where @xmath194 is a schubert variety with @xmath195 as explained above for @xmath196 .    according to the principle of counting constants @xcite , @xmath197 where @xmath198 consists of all @xmath153 such that @xmath191 for @xmath178 , hence @xmath199 this shows that @xmath189 is a proper algebraic subset of @xmath200 if the inequality   is not satisfied .",
    "let @xmath201 be the union of @xmath189 where @xmath202 runs over all those lists of integers satisfying the inequalities   but not the inequality  , and let @xmath203 be the union of @xmath201 for @xmath204 . as a finite union of proper algebraic subsets , @xmath203 is also a proper algebraic subset by the irreducibility of @xmath200 , hence negligible .",
    "now , take a sample @xmath190 not belonging to  @xmath203 , and any vector subspace  @xmath73 of any dimension @xmath154 of @xmath205",
    ". set @xmath177 for @xmath178 , so that @xmath206 . then @xmath202 must satisfy the inequality  , otherwise @xmath175 would belong to @xmath203 by the very definition of  @xmath203 .",
    "this proves the proposition .",
    "consider next the set @xmath207 of those positive integers @xmath15 for which there are integers @xmath208 satisfying the inequalities @xmath209 and set @xmath210 .",
    "[ lemma1 ] almost all samples of size @xmath211 in the real or complex grassmann manifold  @xmath0 have a unique ge .",
    "suppose that @xmath211 .",
    "according to proposition  [ intersection ] , the following holds for almost all @xmath190 . for any proper vector subspace @xmath73 of dimension @xmath154 of @xmath30 , the integers @xmath177 satisfy the inequalities   and  . but they do not satisfy the inequality   since @xmath211 hence @xmath212 .",
    "thus @xmath213 , which is precisely the condition   of corollary  [ cormain ] for the sample @xmath67 to have a unique ge .",
    "[ bound ] for any integers @xmath214 with @xmath8 , the set @xmath215 is bounded above by @xmath216 .",
    "as @xmath210 , we first look for an upper bound of @xmath207 . to this end",
    ", we replace the unknowns @xmath208 in the the definition of @xmath207 by the number @xmath217 of occurences among @xmath208 of each integer @xmath218 between @xmath219 and @xmath220 , where @xmath221 with these new unknowns @xmath222 , the inequations  translate into the system of linear inequations @xmath223 with @xmath224 .",
    "so , @xmath207 consists of those integers @xmath15 which decompose into a sum @xmath224 of integers @xmath225 satisfying the inequalities .",
    "the maximum of @xmath207 ( if any ) is the solution of the integer linear program @xmath226 relaxing the integrality condition on @xmath225 yields a usual linear program with real @xmath222 , whose solution is an upper bound of @xmath207 .",
    "standard methods of linear programming @xcite show that the constraints  define a bounded polytope whose vertices are of one of the following two types .",
    "* @xmath227 for some @xmath218 and @xmath228 for @xmath229 . *",
    "@xmath225 and @xmath230 are the solutions of the system of equations @xmath231 and @xmath228 for @xmath232 .",
    "now , routine computations show that the sum @xmath224 reaches its maximum on vertices of the the first type when @xmath233 , and on vertices of the second type when @xmath234 .",
    "it can then be checked that these maxima are bounded above by the quantity @xmath216 .",
    "theorem  [ mainbound ] immediately follows from lemma  [ lemma1 ] and  [ bound ] .",
    "let @xmath65 be a probability measure admitting a unique maximum likelihood estimator .",
    "we propose here two algorithms to locate this estimator , using the geometry of the problem ( see section [ likelihoodequation ] ) .",
    "the first one is a gradient - descent dynamics .",
    "the second one is a faster method which avoids the time consuming steps of the first one .",
    "we look for the solution @xmath235 to the equation ( [ likelihoodformula ] ) .",
    "the exponential map @xmath236 from @xmath130 to @xmath37 is given explicitely by @xmath237 .",
    "given some @xmath238 and @xmath239 , the idea is to approximate the gradient @xmath240 using the parallel transport of @xmath241 .",
    "one then computes the solution @xmath242 to the linear system @xmath243 the loop is closed by setting @xmath244 .",
    "our simulations indicate that the sequence @xmath247 converges toward the maximum likelihood estimator @xmath248 .",
    "we have performed a simulation study using @xmath249 i.i.d .",
    "random samples @xmath250 , @xmath251 , distributed according to the grassmannian distribution of parameter @xmath252 given by       10 a. albert and j.a . anderson . on the existence of maximum likelihood estimates in logistic regression models .",
    ", * 71 * 1 - 10 ( 1984 ) . c. auderset , c. mazza , and e. ruh .",
    "angular gaussian and cauchy estimation , , * 93 * 180 - 197 ( 2005 ) .",
    "j. bouchaud , m. potters theory of financial risk and derivative pricing , from statistical physics to risk management .",
    "cambridge university press , cambridge , 2003 .",
    "y. chikuse the matrix angular central gaussian distribution , * 33 * 265 - 274 ( 1990 ) .",
    "mardia , patrangenaru , v. and sugathadasa , s. protein gels matching . in _ quantitative biology ,",
    "shape analysis , and wavelets_. ( s. barber , p.d .",
    "baxter , k.v .",
    "mardia and r.e . walls(eds . ) ) . 163 - 165 , 2005 .",
    "leeds , leeds university press ."
  ],
  "abstract_text": [
    "<S> this paper discusses the family of distributions on the grassmannian @xmath0 of the linear span of @xmath1 central normal vectors in @xmath2 or @xmath3 , parametrized by the covariance matrix ( up to a positive factor ) . </S>",
    "<S> our main result is an existence and uniqueness criterion for the maximum likelihood estimate of a sample in @xmath0 , based on convexity and asymptotic properties of the log - likelihood . by coupling methods of algebraic geometry and linear programming , we show that almost all samples of size @xmath4 in @xmath0 have a unique mle .    in the real case , a new , unexpected phenomenon takes place for some values @xmath5 , which does not occur in the angular gaussian case @xmath6 . </S>",
    "<S> random samples of some critical size in @xmath0 may have a unique estimate or not , with a positive probability in either case . </S>"
  ]
}