{
  "article_text": [
    "consider the problem of identifying the value of a discrete random variable by only asking questions of the sort : is its value x ? that this is",
    "a time - consuming task is a cornerstone of computationally secure ciphers @xcite .",
    "it is tempting to appeal to the asymptotic equipartition property ( aep ) @xcite , and the resulting assignment of code words only to elements of the typical set of the source , to justify restriction to consideration of a uniform source , e.g. @xcite .",
    "this assumed uniformity has many desirable properties , including maximum obfustication and difficulty for the inquisitor , e.g. @xcite . in typical set coding",
    "it is necessary to generate codes for words whose logarithmic probability is within a small distance of the word length times the specific shannon entropy . as a result , while all these words have near - equal likelihood , the distribution is not precisely uniform .",
    "it is the consequence of this lack of perfect uniformity that we investigate here by proving that results on guesswork @xcite extend to this setting .",
    "we establish that for source words originally constructed from an i.i.d .",
    "sequence of letters , as a function of word length it is exponentially easier to guess a word conditioned to be in the source s typical set in comparison to the corresponding equipartition approximation .",
    "this raises questions about the wisdom of appealing to the aep to justify sole consideration of the uniform distributions for cryptanalysis and provides alternate results in their place .",
    "let @xmath0 be a finite alphabet and consider a stochastic sequence of words , @xmath1 , where @xmath2 is a word of length @xmath3 taking values in @xmath4 .",
    "the process @xmath1 has specific shannon entropy @xmath5 and we shall take all logs to base @xmath6 . for @xmath7 , the typical set of words of length @xmath3 is @xmath8 for most reasonable sources @xcite , @xmath9 for all @xmath3 sufficiently large and typical set encoding results in a new source of words of length @xmath3 , @xmath10 , with statistics @xmath11 appealing to the aep , these distributions are often substituted for their more readily manipulated uniformly random counterpart , @xmath12 , @xmath13 where @xmath14 is the number of elements in @xmath15 .",
    "while the distribution of @xmath10 is near - uniform for large @xmath3 , it is not perfectly uniform unless the original @xmath2 was uniformly distributed on a subset of @xmath4 .",
    "is a word selected using the distribution of @xmath10 easier to guess than if it was selected uniformly , @xmath12 ?    given knowledge of @xmath4 , the source statistics of words , say those of @xmath2 , and an oracle against which a word can be tested one at a time , an attacker s optimal strategy is to generate a partial - order of the words from most likely to least likely and guess them in turn @xcite . that is , the attacker generates a function @xmath16 such that @xmath17 if @xmath18 . the integer @xmath19 is the number of guesses until word @xmath20 is guessed , its guesswork .    for fixed @xmath3",
    "it is shown in @xcite that the shannon entropy of the underlying distribution bears little relation to the expected guesswork , @xmath21 , the average number of guesses required to guess a word chosen with distribution @xmath2 using the optimal strategy . in a series of subsequent papers @xcite , under ever less restrictive stochastic assumptions from words made up of i.i.d .",
    "letters to markovian letters to sofic shifts , an asymptotic relationship as word length grows between scaled moments of the guesswork and specific rnyi entropy was identified : @xmath22 for @xmath23 , where @xmath24 is the specific rnyi entropy for the process @xmath1 with parameter @xmath25 , @xmath26    these results have recently @xcite been built on to prove that @xmath27 satisfies a large deviation principle ( ldp ) , e.g @xcite .",
    "define the scaled cumulant generating function ( scgf ) of @xmath27 by @xmath28 and make the following two assumptions .    * _ assumption 1 : _ for @xmath23 , the scgf @xmath29 exists , is equal to @xmath30 and has a continuous derivative in that range . * _ assumption 2 : _ the limit @xmath31 exists in @xmath32 $ ]",
    ".    should assumptions 1 and 2 hold , theorem 3 of @xcite establishes that @xmath33 for all @xmath34 and that the sequence @xmath27 satisfies a ldp with a rate function given by the legendre fenchel transform of the scgf , @xmath35 .",
    "assumption 1 is motivated by equation , while the assumption 2 is a regularity condition on the probability of the most likely word . with @xmath36 where the order of the size of the set of maximum probability words of @xmath2 is @xmath37 @xcite , @xmath38",
    "can be identified as @xmath39\\\\      \\sup_{\\alpha\\in\\r } \\{x\\alpha -\\lambda_w(\\alpha)\\ }           & \\text { if } x\\in(\\turn_w,\\log(m)],\\\\      + \\infty & \\text { if } x\\notin[0,\\log(m ) ] .",
    "\\end{cases } \\label{eq : rf}\\end{aligned}\\ ] ] corollary 5 of @xcite uses this ldp to prove a result suggested in @xcite , that @xmath40 making clear that the specific shannon entropy determines the expectation of the logarithm of the number of guesses to guess the word @xmath2 . the growth rate of the expected guesswork is a distinct quantity whose scaling rules can be determined directly from the scgf in equation , @xmath41 from these expressions and jensen s inequality , it is clear that the growth rate of the expected guesswork is less than @xmath42 .",
    "finally , as a corollary to the ldp , @xcite provides the following approximation to the guesswork distribution for large @xmath3 : @xmath43 for @xmath44 .",
    "thus to approximate the guesswork distribution , it is sufficient to know the specific rnyi entropy of the source and the decay - rate of the likelihood of the sequence of most likely words .",
    "here we show that if @xmath1 is constructed from i.i.d",
    ". letters , then both of the processes @xmath45 and @xmath46 also satisfy assumptions 1 and 2 so that , with the appropriate rate functions , the approximation in equation can be used with @xmath12 or @xmath10 in lieu of @xmath2 .",
    "this enables us to compare the guesswork distribution for typical set encoded words with their assumed uniform counterpart . even in the simple binary alphabet case we establish that ,",
    "apart from edge cases , a word chosen via @xmath10 is exponential easier in @xmath3 to guess on average than one chosen via @xmath12 .",
    "assume that the words @xmath1 are made of i.i.d .",
    "letters , defining @xmath47 by @xmath48 . we shall employ the following short - hand : @xmath49 for @xmath50^m$ ] , @xmath51 , @xmath52 , so that @xmath53 , and @xmath54 . furthermore , define @xmath55^m$ ] and @xmath56^m$ ] @xmath57",
    "should they exist . for @xmath23 , also define @xmath58 and @xmath59 by @xmath60 assume that @xmath61 .",
    "if this is not the case , @xmath62 should be substituted in place of @xmath63 for the @xmath45 results .",
    "proofs of the following are deferred to the appendix .",
    "[ lem : ass1 ] assumption 1 holds for @xmath45 and @xmath46 with @xmath64 and @xmath65 where @xmath66    [ lem : ass2 ] assumption 2 holds for @xmath45 and @xmath46 with @xmath67    thus by direct evaluation of the scgfs at @xmath68 , @xmath69 as the conditions of theorem 3 @xcite are satisfied @xmath70 and we have the approximations @xmath71",
    "consider a binary alphabet @xmath72 and words @xmath1 constructed of i.i.d",
    ". letters with @xmath73 . in this case",
    "there are unique @xmath74 and @xmath75 satisfying equations and determined by : @xmath76 selecting @xmath77 ensures that the typical set is growing more slowly than @xmath78 and that @xmath79 .    with @xmath58 defined in equation , from equations and we have that @xmath80 from lemmas [ lem : ass1 ] and [ lem : ass2 ] we obtain @xmath81 and @xmath65 where @xmath82 is deinfed in equation and @xmath59 defined in equation .    with @xmath83 defined in equation , we have @xmath84 , @xmath85 and @xmath86 so that , as @xmath87 , the ordering of the growth rates with word length of the set of most likely words from smallest to largest is : unconditioned source , conditioned source and uniform approximation .    from these scgf equations , we can determine the average growth rates and estimates on the guesswork distribution .",
    "in particular , we have that @xmath88 as @xmath89 is monotonically decreasing for @xmath90 and @xmath91 , the expectation of the logarithm of the guesswork is growing faster for the uniform approximation than for either the unconditioned or conditioned word source .",
    "the growth rate of the expected guesswork reveals more features .",
    "in particular , with @xmath92 , @xmath93 for the growth rate of the expected guesswork , from these it can be shown that there is no strict order between the unconditioned and uniform source , but there is a strict ordering between the the uniform approximation and the true conditioned distribution , with the former being strictly larger .    with @xmath94 and for a range of @xmath95 ,",
    "these formulae are illustrated in figure [ fig : fest ] .",
    "the top line plots @xmath96 showing that the expected growth rate in the logarithm of the guesswork is always higher for the uniform approximation than both the conditioned and unconditioned sources .",
    "the second highest line plots the difference in growth rates of the expected guesswork of the uniform approximation and the true conditioned source @xmath97 that this difference is always positive , which can be established readily analytically , shows that the expected guesswork of the true conditioned source is growing at a slower exponential rate than the uniform approximation . the second line and the lowest line , the growth rates of the uniform and unconditioned expected guesswork @xmath98 initially agree .",
    "it can , depending on @xmath95 and @xmath99 , be either positive or negative .",
    "it is negative if the typical set is particularly small in comparison to the number of unconditioned words .",
    "difference in exponential growth rates of guesswork between uniform approximation , unconditioned and conditioned distribution with @xmath100 .",
    "top curve is the difference in expected logarithms between the uniform approximation and both the conditioned and unconditioned word sources .",
    "bottom curve is the log - ratio of the expected guesswork of the uniform and unconditioned word sources , with the latter harder to guess for large @xmath95 .",
    "middle curve is the log - ratio of the uniform and conditioned word sources , which initially follows the lower line , before separating and staying positive , showing that the conditioned source is always easier to guess than the typically used uniform approximation . ]    for @xmath101 , the typical set is growing sufficiently slowly that a word selected from the uniform approximation is easier to guess than for unconditioned source . for this value",
    ", we illustrate the difference in guesswork distributions between the unconditioned @xmath1 , conditioned @xmath46 and uniform @xmath45 word sources .",
    "if we used the approximation in directly , the graph would not be informative as the range of the unconditioned source is growing exponentially faster than the other two .",
    "instead figure [ fig : fest2 ] plots @xmath102 for each of the three processes . that is , using equation and its equivalents for the other two processes , it plots @xmath103 against the large deviation approximations to @xmath104 as the resulting plot is unchanging in @xmath3 .",
    "the source of the discrepancy in expected guesswork is apparent , with the unconditioned source having substantially more words to cover ( due to the log x - scale ) .",
    "both it and the true conditioned sources having higher probability words that skew their guesswork .",
    "the first plateau for the conditioned and uniform distributions correspond to those words with approximately maximum highest probability ; that is , the length of this plateau is @xmath105 or @xmath106 , defined in equation , so that , for example , approximately @xmath107 words have probability of approximately @xmath108 .    ) source , @xmath100 .",
    "guesswork distribution approximations . for large @xmath3 ,",
    "@xmath109-axis is @xmath110 for @xmath111 and the @xmath112-axis is the large deviation approximation @xmath113 for @xmath114 and @xmath115 . ]",
    "by establishing that the expected guesswork of a source conditioned on the typical set is growing with a smaller exponent than its usual uniform approximation , we have demonstrated that appealing to the aep for the latter is erroneous in cryptanalysis and instead provide a correct methodology for identifying the guesswork growth rate .",
    "the proportion of the letter @xmath116 in a word @xmath117 is given by @xmath118 the number of words in a type @xmath119 , where @xmath51 for all @xmath116 and @xmath120 , is given by @xmath121 the set of all types , those just in the typical set and smooth approximations to those in the typical set are denoted @xmath122\\right\\},\\\\\\end{aligned}\\ ] ] where it can readily seen that @xmath123 for all @xmath3 .",
    "for @xmath45 we need the following lemma .",
    "[ lem : t ] the exponential growth rate of the size of the typical set is @xmath124 where @xmath74 is defined in equation .    for fixed @xmath3 , by the union bound @xmath125 for the logarithmic limit , these two bounds coincide so consider the concave optimization problem @xmath126 we can upper bound this optimization by replacing @xmath127 with the smoother version , its superset @xmath128 . using stirling s",
    "bound we have that @xmath129    for the lower bound , we need to construct a sequence @xmath130 such that @xmath131 for all @xmath3 sufficiently large and @xmath132 converges to either @xmath62 or @xmath63 , as appropriate .",
    "let @xmath133 or @xmath74 respectively , letting @xmath134 and define @xmath135 then @xmath131 for all @xmath136 and @xmath137 , as required .",
    "proof of lemma [ lem : ass1 ] .",
    "considering @xmath45 first , @xmath138 by lemma [ lem : t ] .",
    "to evaluate @xmath139 , as for any @xmath140 and @xmath141 @xmath142 again using lemma [ lem : t ] we have @xmath143 where we have used lemma [ lem : t ] .",
    "the reverse of these bounds holds for @xmath144 $ ] , giving the result .",
    "we break the argument for @xmath46 into three steps .",
    "step 1 is to show the equivalence of the existence of @xmath145 and @xmath146 for @xmath23 with the existence of the following limit @xmath147 step 2 then establishes this limit and identifies it .",
    "step 3 shows that @xmath148 is continuous for @xmath23 . to achieve steps 1 and 2 , we adopt and adapt the method of types argument employed in the elongated web - version of @xcite .",
    "_ _ two changes from the bounds of @xcite lemma 5.5 are necessary : the consideration of non - i.i.d .",
    "sources by restriction to @xmath15 ; and the extension of the @xmath149 range to include @xmath150 $ ] from that for @xmath151 given in that document . adjusted for conditioning on the typical set we get @xmath152 the necessary modification of these inequalities for @xmath153 $ ] gives @xmath154 to show the lower bound holds if @xmath153 $ ] let @xmath155 taking @xmath156 and @xmath157 of equations and establishes that if the limit exists , @xmath145 exists and equals it .",
    "similar inequalities provide the same result for @xmath146 .    _ _ the problem has been reduced to establishing the existence of @xmath158 and identifying it .",
    "the method of proof is similar to that employed at the start of lemma [ lem : ass1 ] for @xmath45 : we provide an upper bound for the limsup and then establish a corresponding lower bound .",
    "if @xmath159 with @xmath160 , then using stirling s bounds we have that @xmath161 this convergence occurs uniformly in @xmath162 and so , as @xmath123 for all @xmath3 , @xmath163 this is a concave optimization problem in @xmath162 with convex constraints . not requiring @xmath164 ,",
    "the unconstrained optimizer over all @xmath162 is attained at @xmath58 defined in equation , which determines @xmath59 in equation .",
    "thus the optimizer of the constrained problem can be identified as that given in equation .",
    "thus we have that @xmath165 where @xmath82 is defined in equation .",
    "we complete the proof by generating a matching lower bound .",
    "to do so , for given @xmath82 we need only create a sequence such that @xmath166 and @xmath167 for all @xmath3 . if @xmath168 , then the sequence used in the proof of lemma [ lem : t ] suffices . for @xmath169",
    ", we use the same sequence but with floors in lieu of ceilings and the surplus probability distributed to a least likely letter instead of a most likely letter . for @xmath170 ,",
    "either of these sequences can be used .",
    "_ _ as @xmath171 , with @xmath82 defined in equation , @xmath172 thus to establish continuity it suffices to establish continuity of @xmath82 and its derivative , which can be done readily by calculus .",
    "proof of lemma [ lem : ass2 ] .",
    "this can be established directly by a letter substitution argument , however , more generically it can be seen as being a consequence of the existence of specific min - entropy as a result of assumption 1 via the following inequalities @xmath173 @xmath174 equation holds as @xmath175 for all @xmath176 .",
    "the veracity of the lemma follows as @xmath177 exists and is continuous for all @xmath23 by assumption 1 and @xmath178 tends to @xmath179 as @xmath180 .",
    "m.c . and k.d . supported by the science foundation ireland grant no .",
    "11/pi/1177 and the irish higher educational authority ( hea ) prtli network mathematics grant . f.d.p.c . and m.m .",
    "sponsored by the department of defense under air force contract fa8721 - 05-c-0002 .",
    "opinions , interpretations , recommendations , and conclusions are those of the authors and are not necessarily endorsed by the united states government .",
    "specifically , this work was supported by information systems of asd(r&e ) .",
    "f.  du  pin  calmon , m.  mdard , l.  zegler , j.  barros , m.  christiansen , and k.  duffy , `` lists that are smaller than their parts : a coding approach to tunable secrecy , '' in _ proc .",
    "@xmath181 allerton conference _ , 2012 ."
  ],
  "abstract_text": [
    "<S> consider the situation where a word is chosen probabilistically from a finite list . </S>",
    "<S> if an attacker knows the list and can inquire about each word in turn , then selecting the word via the uniform distribution maximizes the attacker s difficulty , its guesswork , in identifying the chosen word . </S>",
    "<S> it is tempting to use this property in cryptanalysis of computationally secure ciphers by assuming coded words are drawn from a source s typical set and so , for all intents and purposes , uniformly distributed within it . by applying recent results on guesswork , for i.i.d . </S>",
    "<S> sources , it is this equipartition ansatz that we investigate here . in particular , we demonstrate that the expected guesswork for a source conditioned to create words in the typical set grows , with word length , at a lower exponential rate than that of the uniform approximation , suggesting use of the approximation is ill - advised .    </S>",
    "<S> [ theorem]lemma    p 1 g </S>"
  ]
}