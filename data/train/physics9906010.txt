{
  "article_text": [
    "a consistently recurring topic at lep2 has been the interpretation and combination of results from searches for new particles .",
    "the fundamental task is to interpret the collected dataset in the context of two complementary hypotheses . the first hypothesis  the _ null hypothesis _  is that the dataset is compatible with non - signal standard model background production alone , and the second is that the dataset is compatible with the sum of signal and standard model background production . in most cases",
    ", the search for new particles proceeds via several parallel searches for final states .",
    "the results from all of these subchannels are then combined to produce a final result .",
    "all existing confidence level calculations follow the same general strategy @xcite . a test statistic or _",
    "estimator _ is constructed to quantify the `` signal - ness '' of a real or simulated experiment .",
    "the `` signal - ness '' of a single observed experiment leads to the confidence level on , for example , the null hypothesis that the observed experiment is incompatible with signal and background both being produced .",
    "most calculation methods use an ensemble of toy monte carlo experiments to generate the estimator distribution against which the observed experiment is compared .",
    "this generation can be rather time - consuming when the number of toy monte carlo experiments is great ( as it must be for high precision calculations ) or if the number of signal and background expected for each experiment is great ( as it is for the case of searches optimized to use background subtraction ) .    in this note , we present an improved method for calculating confidence levels in the context of searches for new particles .",
    "specifically , when the likelihood ratio is used as an estimator , the experiment estimator distribution may be calculated analytically with the fourier transform . with this approach ,",
    "the disadvantage of toy monte carlo experiments is avoided .",
    "the analytic method offers several advantages over existing methods , the most dramatic of which is the increase in calculation speed and precision .",
    "the likelihood ratio estimator is the ratio of the probabilities of observing an event under two search hypotheses .",
    "the estimator for a single experiment is @xmath0    here @xmath1 is the probability density function for signal+background experiments and @xmath2 is the probability density function for background - only experiments . because the constant factor @xmath3 appears in each event s estimator , it does not affect the ordering of the estimators  an event can not become more signal - like by choosing a different @xmath3 . for clarity in this note , the constant is chosen to be @xmath4 , where @xmath5 is the expected number of signal events .",
    "is uniquely determined by the cross section .",
    "if the cross section is not fixed , then @xmath4 is not constant , and @xmath3 may be set to unity . ] for the simplest case of event counting with no discriminant variables ( or , equivalently , with perfectly non - discriminating variables ) , the estimator can be calculated with poisson probabilities alone . in practice ,",
    "not every event is equally signal - like .",
    "each search may have one or more event variables that discriminate between signal - like and background - like events .",
    "for the general case , the probabilities @xmath1 and @xmath2 are functions of the observed events measured variables .    as an example , consider a search using one discriminant variable @xmath6 , the reconstructed higgs mass .",
    "the signal and background have different probability density functions of @xmath6 , defined as @xmath7 and @xmath8 , respectively .",
    "( for searches with more than one discriminant variable , @xmath6 is replaced by a vector of discriminant variables @xmath9 . )",
    "it is then straightforward to calculate @xmath1 and @xmath2 for a single event , taking into account the event weighting coming from the discriminant variables : @xmath10}{e^{-b }      \\left[b f_{b}(m)\\right]}.\\ ] ]    the likelihood ratio estimator can be shown to maximize the discovery potential and exclusion potential of a search for new particles @xcite .",
    "such an estimator , both with and without discriminant variables , has been used successfully by the lep2 collaborations to calculate confidence levels for searches @xcite .",
    "one way to form an estimator for an ensemble of events is to generate a large number of toy monte carlo experiments , each experiment having a number of events generated from a poisson distribution .",
    "another way is to analytically compute the probability density function of the ensemble estimator given the probability density function of the event estimator .",
    "the discussion of this section pursues the latter approach .    the likelihood ratio estimator is a multiplicative estimator .",
    "this means the estimator for an ensemble of events is formed by multiplying the individual event estimators .",
    "alternatively , the logarithms of the estimators may be summed . in the following derivation , @xmath11 , where @xmath12 is the likelihood ratio estimator .    for an experiment with 0 events observed ,",
    "the estimator is trivial : @xmath13 where @xmath14 is the probability density function of @xmath15 for experiments with 0 observed events .    for an experiment with exactly one event ,",
    "the estimator is , again using the reconstructed higgs mass @xmath6 , @xmath16}{e^{-b }      \\left[b f_{b}(m)\\right ] } , \\\\",
    "f & = & \\ln \\frac{s f_{s}(m ) + b f_{b}(m)}{b f_{b}(m)},\\end{aligned}\\ ] ] and the probability density function of @xmath15 is defined as @xmath17 .    for an experiment with exactly two events , the estimators of the two events",
    "are multiplied to form an event estimator .",
    "if the reconstructed higgs masses of the two events are @xmath18 and @xmath19 , then @xmath20 \\left[s f_{s}(m_2 ) + b",
    "f_{b}(m_2)\\right]}{\\left[b f_{b}(m_1)\\right]\\left[b        f_{b}(m_2)\\right ] } \\\\    f & = & \\ln \\frac{s f_{s}(m_1 ) + b f_{b}(m_1)}{b f_{b}(m_1 ) } +     \\ln \\frac{s f_{s}(m_2 ) + b f_{b}(m_2)}{b f_{b}(m_2)}.\\end{aligned}\\ ] ] the probability density function for exactly two particles @xmath21 is simply the convolution of @xmath17 with itself : @xmath22    the generalization to the case of @xmath23 events is straightforward and encouraging : @xmath24 \\delta \\left ( f - \\sum^{n}_{i=1 } f_i \\right ) \\\\    & = & \\underbrace { \\rho_1 ( f ) \\otimes \\dots \\otimes \\rho_1 ( f)}_{n\\       \\text{times}}.\\end{aligned}\\ ] ]    next , the convolution of @xmath17 is rendered manageable by an application of the relationship between the convolution and the fourier transform .",
    "if @xmath25 , then the fourier transforms of @xmath26 , @xmath27 , and @xmath3 satisfy @xmath28 this allows the convolution to be expressed as a simple power : @xmath29^n.\\ ] ] note this equation holds even for @xmath30 , since @xmath31 . for any practical computation ,",
    "the analytic fourier transform can be approximated by a numerical fast fourier transform ( fft ) @xcite .    how does this help to determine @xmath32 and @xmath33 ?",
    "the probability density function for an experiment estimator with @xmath5 expected signal and @xmath34 expected background events is @xmath35 where @xmath23 is the number of events observed in the experiment . upon fourier transformation ,",
    "this becomes @xmath36^n\\end{aligned}\\ ] ]    @xmath37}}\\ ] ]    the function @xmath38 may then be recovered by using the inverse transform .",
    "in general , this relation holds for any multiplicative estimator .",
    "this final relation means that the probability density function for an arbitrary number of expected signal and background events can be calculated analytically once the probability density function of the estimator is known for a single event .",
    "this calculation is therefore just as fast for high background searches as for low background searches . in particular , it holds great promise for higgs searches which , due to use of background subtraction and discriminant variables , are optimized to higher background levels than they have been in the past .    two examples will provide practical proof of the principle . for the first , assume a hypothetical estimator results in a probability density function of simple gaussian form @xmath39 where @xmath40 and @xmath41 .",
    "for an expected @xmath42 , both the fft method and the toy monte carlo method are used to evolute the event estimator probability density function to an experiment estimator probability density function .",
    "the agreement between the two methods ( fig .",
    "1 ) is striking .",
    "[ simple ]    the higher precision of the fft method is apparent , even when compared to 1 million toy monte carlo experiments .",
    "the periodic structure is due to the discontinuous poisson distribution being convolved with a narrow event estimator probability function .",
    "in particular , the peak at @xmath43 corresponds to the probability that exactly zero events be observed ( @xmath44 ) .",
    "the precision of the toy monte carlo method is limited by the number of monte carlo experiments , while the precision of the fft method is limited only by computer precision .",
    "for the second example , a more realistic estimator is calculated using a discriminant variable distribution from an imaginary @xmath45 search .",
    "the variable used here is the reconstructed higgs mass of the event .",
    "this estimator s probability density function is then calculated for an experiment with @xmath46 and @xmath47 expected events ( fig .  2 ) .",
    "[ tt ]    again , the two methods agree well in regions where the toy monte carlo method is useful .",
    "these examples support the mathematical proof of the fft method described above . because the final calculations @xmath48 and @xmath49 are simply integrals of the experiment estimator probability density function , any confidence levels calculated with the fft method and the toy monte carlo method are identical .",
    "the examples also show the precision achievable with the fft method , a precision that will be important when testing discovery hypotheses at the @xmath50 level .",
    "given the multiplicative properties of the likelihood ratio estimator , the combination of several search channels proceeds intuitively .",
    "the estimator for any combination of events is simply the product of the individual event estimators .",
    "consequently , construction of the estimator probability density function for the combination of channels parallels the construction of the estimator probability density function for the combination of events in a single channel . in particular , for a combination with @xmath51 search channels : @xmath52}\\end{aligned}\\ ] ]    due to the strictly multiplicative nature of the estimator , this combination method is internally consistent .",
    "no matter how subsets of the combinations are rearranged ( _ i.e. _ , combining channels in different orders , combining different subsets of data runs ) , the result of the combination does not change .",
    "once a results are obtained for @xmath53 and @xmath54 , simple integration gives the confidence coefficients @xmath48 and @xmath49 . from this point ,",
    "confidence levels for the two search hypotheses may be calculated in a number of ways @xcite .",
    "those straightforward calculations are outside the scope of this note .",
    "a few short remarks conclude this note and emphasize the advantages of calculations using the likelihood ratio with the fast fourier transform ( fft ) method .    1 .",
    "the likelihood ratio estimator is an optimal ordering estimator for maximizing both discovery and exclusion potential .",
    "such an estimator can only improve the discovery or exclusion potential of a search .",
    "2 .    as a multiplicative estimator",
    ", the likelihood ratio estimator ensures internal consistency when results are combined .",
    "for example , if the dataset is split into several smaller pieces , the combined result always remains the same .",
    "the probability density function of an ensemble estimator may be calculated analytically from the event estimator probability density function .",
    "avoiding toy monte carlo generation brings revolutionary advances in speed and precision . for a @xmath55 search with 25 expected background events ,",
    "a full confidence level calculation with @xmath56 toy mc experiments and 60 higgs mass hypotheses takes approximately fifteen cpu hours .",
    "by contrast , the same calculation using the fft method takes approximately two cpu minutes .",
    "this discrepancy only increases as the required confidence level precision and the number of toy mc experiments increase .",
    "for example , confidence level calculations for discovery at the @xmath57 level would require @xmath58 toy mc experiments . given the approximately linear",
    "scaling of calculating time with number of toy experiments , such a calculation would take up almost a year in the 4-jet channel alone !",
    "the precision of the analytic fft method is more than sufficient for a @xmath57 discovery .",
    "a fast confidence level calculation makes possible studies that might have otherwise been too cpu - intensive with the toy mc method .",
    "these include studies of improvements in the event selections , of various working points , and of systematic errors and their effects , among others .",
    "a precise calculation makes possible rejection of null hypotheses at the level necessary for discovery .",
    "the marriage of the likelihood ratio estimator and the fft method seems well - suited for producing extremely fast and precise confidence level results , and the flexibility and ease of use of the clfft package should make this a powerful tool in interpreting searches for new particles .",
    "t. junk , _ confidence level computation for combining searches using the likelihood ratio _ , opal technical note tn-570 ( 1999 ) .",
    "+ t. junk , _ confidence level computation for combining searches with small statistics _ , hep - ex/9902006 ( 1999 ) .",
    "a. l. read , _ optimal statistical analysis of search results based on the likelihood ratio and its application to the search for the msm higgs boson at @xmath59 and @xmath60 gev _ , delphi note 97 - 158 phys 737 ( 1997 ) ."
  ],
  "abstract_text": [
    "<S> the interpretation of new particle search results involves a confidence level calculation on either the discovery hypothesis or the background - only ( `` null '' ) hypothesis . a typical approach uses toy monte carlo experiments to build an expected experiment estimator distribution against which an observed experiment s estimator may be compared . in this note , </S>",
    "<S> a new approach is presented which calculates analytically the experiment estimator distribution via a fourier transform , using the likelihood ratio as an ordering estimator . </S>",
    "<S> the analytic approach enjoys an enormous speed advantage over the toy monte carlo method , making it possible to quickly and precisely calculate confidence level results .    </S>",
    "<S> wisc - ex-99 - 352 + h. hu , j. nielsen + june 1 , 1999 +    * analytic confidence level calculations using + the likelihood ratio and fourier transform * 1.6 cm hongbo hu and jason nielsen + _ university of wisconsin - madison , wisconsin , usa _ </S>"
  ]
}