{
  "article_text": [
    "latent structures are a popular tool for modeling the dependency structure in multivariate data .",
    "two important examples are finite - mixture models [ see @xcite ] and hidden markov models [ see @xcite ] .",
    "although these models arise frequently in applied work , the question of their nonparametric identifiability has attracted substantial attention only quite recently .",
    "@xcite used algebraic results on the uniqueness of decompositions of multiway arrays due to @xcite ( @xcite ) to establish identification in a variety of multivariate latent - structure models .",
    "their setup covers both finite mixtures and hidden markov models , among other models , and their findings substantially generalize the earlier work of @xcite , @xcite , @xcite , and @xcite .    despite these positive identification results , direct application of kruskal s method does not provide an estimator .",
    "taking identification as given , some authors have developed em - type approaches to nonparametrically estimate both multivariate finite mixtures [ @xcite ; levine , hunter and chauveau ( @xcite ) ] and hidden markov models [ @xcite ] .",
    "numerical studies suggest that these estimators are well behave .",
    "however , their statistical properties  their consistency , convergence rates , and asymptotic distribution  are difficult to establish and are currently unknown . , multivariate finite mixtures with identically distributed outcome variables [ @xcite ; @xcite ] , and two - component mixtures [ @xcite ; @xcite ] . ]    in this paper , we show that the multilinear structure underlying the results of @xcite can be used to obtain a constructive proof of identification in a broad class of latent - structure models .",
    "we show that the problem of decomposing a multiway array can be reformulated as the problem of simultaneously diagonalizing a collection of matrices .",
    "this is a least - squares problem that has received considerable attention in the literature on independent component analysis and blind source separation [ see @xcite ] .",
    "moreover , algorithms exist to recover the joint diagonalizer in a computationally efficient manner ; see @xcite , @xcite ( @xcite ) and @xcite ( @xcite ) .",
    "we propose estimating the parameters of the latent - structure model by solving a sample version of the simultaneous diagonalization problem .",
    "we provide distribution theory for this estimator below . under weak conditions",
    ", it converges at the parametric rate and is asymptotically normal . using this result ,",
    "we obtain estimators of finite - mixture models and hidden markov models that have standard asymptotic properties .",
    "moreover , the fact that the dependency structure in the data is latent does not translate into a decrease in the convergence rate of the estimators .",
    "as such , this paper is the first to derive the asymptotic behavior of nonparametric estimators of multivariate finite - mixture models of the form defined in @xcite for more than two latent classes and of hidden markov models of the form in @xcite .",
    "furthermore , our approach can be useful in the analysis of random graph models [ @xcite ] and stochastic blockmodels [ @xcite ; @xcite ] , although we do not consider such models in detail in this paper . in a simulation study",
    ", we find that our approach performs well in small samples .",
    "there is a large literature on parallel factor analysis and canonical polyadic decompositions of tensors building on the work of @xcite ( @xcite ) ; see , for example , @xcite , @xcite , @xcite ( @xcite ) , @xcite and @xcite ( @xcite ) .",
    "although our strategy has some similarity with this literature , both our conclusions and our simultaneous diagonalization problem are different .",
    "most importantly , our simultaneous diagonalization formulation can deal with noise , making it useful as a tool for statistical inference .    in the context of multivariate finite mixtures of",
    "identically distributed variables , @xcite and @xcite also used ( different ) joint - diagonalization arguments to obtain nonparametric identification results .",
    "however , the approaches taken there are different from the one developed in this paper and can not be applied as generally .",
    "we start out by motivating our approach via a discussion on the algebraic structure of multivariate finite - mixture models and hidden markov models .",
    "we then present our identification strategy in a generic setting .",
    "after this we turn to estimation and inference , and to the development of asymptotic theory .",
    "next , the theory is used to set up orthogonal - series estimators of component densities in a finite - mixture model , and to show that these have the standard univariate convergence rates of series estimators .",
    "finally , the orthogonal - series density estimator is put to work in simulation experiments involving finite mixtures and a hidden markov model .",
    "the supplementary material [ @xcite ] contains some additional results and discussion , as well as all technical proofs .",
    "we start by introducing three examples to motivate our subsequent developments .",
    "let @xmath0 be observable random variables that are assumed independent conditional on realizations of a latent random variable @xmath1 .",
    "suppose that @xmath1 has a finite state space of known cardinality @xmath2 , which we set to @xmath3 without loss of generality .",
    "let @xmath4 be the probability distribution of @xmath1 , so @xmath5 and @xmath6 .",
    "then the probability distribution of @xmath0 is a multivariate finite mixture with mixing proportions @xmath7 .",
    "the parameters of interest are the mixing proportions and the distributions of @xmath8 given @xmath1 .",
    "the @xmath9 need not be identically distributed , so the model involves @xmath10 such conditional distributions .",
    "suppose that the scalar random variable @xmath9 can take on a finite number @xmath11 of values .",
    "let @xmath12 denote the probability distribution of @xmath9 given @xmath13 .",
    "let @xmath14 denote the outer ( tensor ) product .",
    "the joint probability distribution of @xmath0 given @xmath13 then is the @xmath15-way table @xmath16 which is of dimension @xmath17 .",
    "the outer - product representation follows from the conditional - independence restriction .",
    "hence , the marginal probability distribution of @xmath0 equals @xmath18 which is an @xmath2-linear decomposition of a @xmath15-way array .",
    "the parameters of the mixture model are all the vectors making up the outer - product arrays , @xmath19 and the coefficients of the linear combination , @xmath20 , transforming the conditional distributions into the marginal distribution @xmath21 .",
    "the @xmath2-linear decomposition is not restricted to the contingency table . indeed ,",
    "any linear functional of @xmath21 admits a decomposition in terms of the same functional of the @xmath22 .",
    "moreover , for any collection of vector - valued transformations @xmath23 we have @xmath24 = \\sum _ { j=1}^r \\pi_j \\bigotimes _ { i=1}^q e\\bigl[\\bolds{\\chi } _ i(y_i ) { |}z = j\\bigr],\\ ] ] provided the expectation exists .",
    "of course , identification of linear functionals follows from identification of the component distributions , but ( [ eqlinfunc ] ) can be useful for the construction of estimators . to illustrate this",
    ", we turn to a model with continuous outcomes .",
    "suppose now that the @xmath9 are continuously distributed random variables .",
    "let @xmath25 be the density of @xmath9 given @xmath13 . in this case",
    ", the @xmath15-variate finite - mixture model with @xmath2 latent classes states that the joint density function of the outcomes @xmath8 factors as @xmath26 again for mixing proportions @xmath7 .",
    "this is an infinite - dimensional version of ( [ eqdiscretemixture ] ) .",
    "setting @xmath27 in ( [ eqlinfunc ] ) to a set of indicators that partition the state space of @xmath9 yields a decomposition as in ( [ eqdiscretemixture ] ) for a discretized version of the mixture model .",
    "this approach has been used by @xcite and @xcite in proving identification .",
    "an alternative approach , which will prove convenient for the construction of density estimators , is as follows .",
    "suppose that @xmath28 lives in the dimensional space @xmath29 .",
    "let @xmath30 $ ] be the space of functions that are square - integrable with respect to the weight function @xmath31 on @xmath32 , endowed with the inner product @xmath33 and the @xmath34-norm @xmath35 .",
    "let @xmath36 be a class of functions that form a complete orthonormal basis for @xmath37 $ ] .",
    "when @xmath32 is compact , polynomials such as those belonging to the jacobi class ( e.g. , chebychev or legendre polynomials ) can serve this purpose .",
    "when @xmath38 , hermite polynomials are a natural choice .",
    "assume that @xmath39 $ ] .",
    "the projection of @xmath25 onto the subspace spanned by @xmath40 for any integer @xmath41 is @xmath42 where the @xmath43\\ ] ] are the ( generalized ) fourier coefficients of @xmath25 .",
    "the projection converges to @xmath25 in @xmath44-norm , that is , @xmath45 as @xmath46 .",
    "such projections are commonly - used tools in the approximation of functions and underlie orthogonal - series estimators of densities",
    ".    the fourier coefficients are not directly observable .",
    "for chosen integers @xmath47 , define @xmath48,\\ ] ] where @xmath49 , which are linear functionals of the @xmath25 . then ( [ eqlinfunc ] ) yields @xmath50 for @xmath51 $ ] .",
    "the latter expectation is a @xmath15-way array that can be computed directly from the data .",
    "it contains the leading fourier coefficients of the @xmath15-variate density function of the data .",
    "again , the array @xmath52 factors into a linear combination of multiway arrays . in section  [ secmixtures ] , we will use this representation to derive orthogonal - series density estimators that have standard large - sample properties .",
    "let @xmath53 be a stationary sequence .",
    "@xmath54 is a latent variable with finite state space @xmath55 , for known @xmath2 , and has first - order markov dependence .",
    "let @xmath56 be the stationary distribution of @xmath54 .",
    "write @xmath57 for the @xmath58 matrix of transition probabilities ; so @xmath59 is the probability of moving from state @xmath60 to state @xmath61 .",
    "the observable scalar random variables @xmath0 are independent conditional on realizations of @xmath62 , and the distribution of @xmath9 only depends on the realization of @xmath54 .",
    "this is a hidden markov model with @xmath2 latent states and @xmath15 observable outcomes .",
    "suppose that @xmath9 is discrete and that its state space contains @xmath63 points of support .",
    "write @xmath64 for the probability vector of @xmath9 given @xmath65 , that is , the emission distributions .",
    "let @xmath66 be the @xmath67 matrix of emission distributions and write @xmath68 .",
    "the markovian assumption implies that @xmath9 and @xmath69 are independent given @xmath54 .",
    "hence , the columns of the matrix @xmath70 contain the probability distributions of @xmath9 for given values of @xmath69 .",
    "likewise , @xmath9 and @xmath71 are independent given @xmath54 , and so the matrix @xmath72 gives the distributions of @xmath9 for given values of @xmath71 .",
    "finally , @xmath73 , @xmath9 , and @xmath74 are independent given @xmath54 .",
    "thus , with @xmath75 measurements , the hidden markov model implies that the contingency table of @xmath76 factors as @xmath77 a detailed derivation is provided in the supplementary material [ @xcite ] ; also see [ @xcite , theorem  2.1 ] and [ @xcite , section  6.1 ] for alternative derivations .",
    "when @xmath78 , we may bin several outcomes together and proceed as before , by using the unfolding argument in section  [ subsecunfolding ] .",
    "equation ( [ eqhmm ] ) shows that appropriate conditioning allows viewing the hidden markov model as a finite - mixture model , thus casting it into the framework of finite mixtures with conditionally - independent ( although not identically - distributed ) outcomes as in ( [ eqdiscretemixture ] ) . here , the parameters of interest are the emission distributions @xmath79 and the stationary distribution of the markov chain @xmath80 , and also the matrix of transition probabilities @xmath57 .",
    "when the @xmath9 are continuously distributed , ( [ eqhmm ] ) becomes a mixture as in ( [ eqcontinuousmixture ] ) , and we may again work with projections of the densities onto an orthogonal basis .",
    "our approach can be applied to @xmath15-variate structures that decompose as @xmath15-ads , which are defined as follows .",
    "[ defqad ] a @xmath15-dimensional array @xmath81 is a @xmath15-ad if it can be decomposed as @xmath82 for some integer @xmath2 , nonzero weights @xmath7 , and vectors @xmath83 .",
    "our interest lies in nonparametrically recovering @xmath84 and @xmath20 from knowledge of @xmath85 and @xmath2 .",
    "clearly , these parameters are not unique , in general .",
    "for example , a permutation of the @xmath86 and @xmath87 leaves @xmath85 unaffected , and a common scaling of the @xmath86 combined with an inverse scaling of the @xmath88 , too , does not change the @xmath15-way array .",
    "however , the work of @xcite ( @xcite ) , @xcite , @xcite and @xcite ( @xcite ) , among others , gives simple sufficient conditions for uniqueness of the decomposition up to these two indeterminacies .",
    "these conditions can not be satisfied when @xmath89 .",
    "while permutational equivalence of possible decompositions of @xmath90 is an inherently unresolvable ambiguity , indeterminacy of the scale of the vectors @xmath86 is undesirable in many situations . indeed , in arrays of the general form in ( [ eqlinfunc ] ) , recovering the scale of the @xmath86 and the constants @xmath88 is fundamental . in some cases",
    ", natural scale restrictions may be present .",
    "indeed , in ( [ eqdiscretemixture ] ) the @xmath86 are known to be probability distributions , and so they have nonnegative entries that sum to one . suitably combining these restrictions with kruskal s theorem , @xcite derived conditions under which the parameters in finite mixtures and hidden markov models are uniquely determined up to relabelling of the latent classes .",
    "we follow a different route to determine @xmath15-adic decompositions up to permutational equivalence that does not require knowledge of the scale of the @xmath86 .",
    "we require that , apart from the @xmath15-way array @xmath85 , lower - dimensional submodels are also observable . by lower - dimensional submodels we mean arrays that factor as @xmath91 for sets @xmath92 that are subsets of the index set @xmath93 .",
    "this is not a strong requirement in the models we have in mind .",
    "for example , in the mixture model in  ( [ eqdiscretemixture ] ) , lower - dimensional submodels are just the contingency tables of a subset of the outcome variables .",
    "there , going from a @xmath15-way table down to a @xmath94-table featuring all but the @xmath95th outcome boils down to summing the array in the @xmath95th direction . in more general situations , such as ( [ eqlinfunc ] ) and in the multilinear equation involving fourier coefficients in particular",
    ", the advantage of working with submodels over marginalizations of the model is apparent . indeed ,",
    "in contrast to when the array is a contingency table , here , there is no natural scale constraint on the @xmath96 .",
    "so , summing the array in one direction does not yield an array that decomposes as in ( [ eqsubmodel ] ) .",
    "nonetheless , expectations concerning any subset of the random variables can still be computed in ( [ eqlinfunc ] ) and so submodels as defined in ( [ eqsubmodel ] ) are observable . in the supplementary material [ @xcite ]",
    "we adapt our main identification result ( theorem  [ thmid1 ] below ) to settings where submodels are not available and marginalizations are used instead .",
    "note that , throughout , we take @xmath2 in ( [ eqqad ] ) to be known .",
    "this ensures @xmath97 and @xmath98 to be unambiguously defined . for a different @xmath2",
    ", there may exist a different set of weights and vectors so that @xmath85 factors as a @xmath15-ad .",
    "the rank of @xmath85 is the smallest integer @xmath2 needed to arrive at a decomposition as in definition [ defqad ] .",
    "for example , in the multivariate mixture model in section  [ sec2.1 ] , @xmath2 is the number of fitted mixture components and the rank is the smallest number of components that would allow us to write the joint distribution of the variables as a mixture that satisfies the required conditional - independence restriction as in ( [ eqdiscretemixture ] ) .",
    "the rank need not be equal to @xmath2 . moreover , besides the factorization of @xmath21 in terms of @xmath7 and @xmath99 in ( [ eqdiscretemixture ] ) , there may exist a different set of , say , @xmath100 weights @xmath101 and distributions @xmath102 that also yield a representation of @xmath21 as a mixture .",
    "identifying the number of components is a difficult issue .",
    "recent work by @xcite shows that a simple lower bound on the number of components is nonparametrically identified ( and estimable ) .",
    "we can state our main identification result for three - way arrays without loss of generality .",
    "this is so because any @xmath15-way array can be unfolded into a @xmath94-way array , much like any matrix can be transformed into a vector using the vec operator . indeed , in any direction @xmath103 , a way array of dimension @xmath104 is a collection of @xmath11 @xmath94-way arrays , each of dimension @xmath105 .",
    "this collection can be stacked in any of @xmath106 directions , that is , @xmath94 different ways , to yield a @xmath94-way array whose dimension will be @xmath107 .",
    "this unfolding process can be iterated until it yields a three - way array . to write this compactly ,",
    "let @xmath108 be the khatri ",
    "rao product . then , for vectors @xmath109 , @xmath110 is the vector containing all interactions between the elements of the @xmath111 .",
    "the end result of iterated unfolding toward direction @xmath95 , say , is a three - way array of the form @xmath112 where @xmath113 and @xmath114 are two index sets that partition @xmath115 .",
    "we will illustrate this in the context of density estimation in section  [ secmixtures ] .",
    "we thus focus on a three - way array @xmath85 of dimension @xmath116 that factors as a tri - ad , that is , @xmath117 let @xmath118 and @xmath119 . also , for each pair @xmath120 with @xmath121 in @xmath122 , let @xmath123 note that , from ( [ eqsubmodel ] ) , @xmath124 is the lower - dimension submodel obtained from @xmath85 by omitting the index @xmath125 .",
    "our first theorem concerns identification of the @xmath126 as the eigenvalues of a set of matrices and is the cornerstone of our argument .",
    "the proof of this result is constructive and will be the basis for our estimator in section  [ secestimation ] below .",
    "[ thmid1 ] if @xmath127 and @xmath128 both have full column rank and @xmath129 is observable , then @xmath130 is identified up to a permutation matrix if all its columns are different .    without loss of generality , fx @xmath131 throughout the proof . in each direction @xmath95 , the three - way array @xmath85 consists of a collection of @xmath11 matrices .",
    "let @xmath132 denote these matrices for @xmath133 .",
    "so , the matrix @xmath134 is obtained from @xmath85 by fixing its third index to the value @xmath135 , that is , @xmath136 , using obvious array - indexing notation . also , let @xmath137 .",
    "note that all of @xmath138 and @xmath139 are observable matrices of dimension @xmath140 .",
    "the lower - dimensional submodel @xmath138 has the structure @xmath141 because the matrices @xmath142 and @xmath143 both have rank @xmath2 and because all @xmath88 are nonzero by definition , the matrix @xmath138 , too , has rank @xmath2 .",
    "therefore , it has a singular - value decomposition @xmath144 for unitary matrices @xmath145 and @xmath146 of dimension @xmath147 and @xmath148 , respectively , and a nonsingular @xmath149 diagonal matrix @xmath150 . now construct @xmath151 and @xmath152 .",
    "then @xmath153 where @xmath154 denotes the @xmath149 identity matrix and @xmath155 .",
    "moving on , each of @xmath156 has the form @xmath157 where @xmath158 denotes the diagonal matrix whose diagonal equals the @xmath135th row of matrix @xmath159 . applying the same transformation to @xmath156 yields the collection of @xmath149 matrices @xmath160",
    "so , the matrices @xmath161 are diagonalizable in the same basis , namely , the columns of matrix @xmath162 .",
    "the associated eigenvalues @xmath163 equal the columns of the matrix @xmath164 .",
    "these eigenvalues are unique up to a joint permutation of the eigenvectors and eigenvalues provided there exist no @xmath165 so that the vectors of eigenvalues of @xmath166 and @xmath167 are equal [ see , e.g. , @xcite , theorem 6.1 ] .",
    "now , this is equivalent to demanding that the columns of @xmath164 are all distinct . as this is true by assumption , the proof is complete .",
    "the proof of theorem [ thmid1 ] shows that access to lower - dimensional submodels allows to disentangle the scale of the columns of the @xmath126 and the weights on the diagonal of @xmath168 .",
    "this is so because the matrix @xmath168 equally shows up in the lower - dimensional submodels , and so transforming @xmath134 to @xmath169 absorbs the weights into the joint diagonalizer @xmath170 in ( [ eqjointdiag ] ) .",
    "also note that the dimension of the matrices in ( [ eqjointdiag ] ) is @xmath149 , independent of the size of the original matrices @xmath126 . on the other hand , larger matrices",
    "@xmath126 could be beneficial for identification , as it becomes easier for them to satisfy the requirement of full column rank .",
    "the full - rank condition that underlies theorem [ thmid1 ] has a simple testable implication .",
    "indeed , by ( [ eqsub ] ) , it implies that the matrix @xmath138 has rank @xmath2 .",
    "as this matrix is observable , so is its rank and , hence , our key identifying assumption is refutable . in applications ,",
    "this can be done using any of a number of available rank tests .",
    "we refer to @xcite and @xcite for practical details on the implementation of such procedures .",
    "theorem [ thmid1 ] can be applied to recover the tri - adic decomposition of @xmath85 up to an arbitrary joint permutation matrix .",
    "we present the result in the form of two theorems .",
    "[ thmvectors ] if @xmath142 , @xmath143 , and @xmath164 have full column rank and for each pair @xmath171 @xmath172 is observable , then @xmath142 , @xmath143 , and @xmath173 are all identified up to a common permutation of their columns .",
    "[ thmweights ] if @xmath126 is identified up to a permutation of its columns and has full column rank , and if @xmath174 is observable , then @xmath80 is identified up to the same permutation .",
    "the one - dimensional submodel @xmath174 is the vector @xmath175 given @xmath126 , the one - dimensional submodel yields linear restrictions on the weight vector @xmath80 .",
    "moreover , if @xmath126 is known and has maximal column rank , these equations can be solved for @xmath80 , giving @xmath176 which is the least - squares coefficient of a regression of @xmath177 on the columns of @xmath126 .    in the supplement , we apply theorems [ thmid1][thmweights ] to the finite - mixture model and the hidden markov model of section  [ secexamples ] to obtain constructive proofs of identification .",
    "the proof of theorem [ thmid1 ] shows that the key restrictions underlying our results take the form of a set of matrices being simultaneously diagonalizable in the same basis .",
    "the problem of joint matrix diagonalization has recently received considerable attention in the field of independent component analysis , and computationally - efficient algorithms for it have been developed ; see @xcite , @xcite ( @xcite ) and @xcite ( @xcite ) .",
    "such algorithms can be exploited here to construct easy - to - implement nonparametric estimators of multivariate latent - structure models .",
    "thus , we propose estimating the latent - structure model in ( [ eqqad ] ) as follows . given an estimate of the array @xmath85 and of its lower - dimensional submodels , first estimate all @xmath96 by solving a sample version of the joint diagonalization problem in  ( [ eqjointdiag ] ) , possibly after unfolding if @xmath78 .",
    "next , back out the weights @xmath7 by solving the sample analog of the minimum - distance problem in  ( [ eqweightsols ] ) .",
    "asymptotic theory for this second step follows readily by the delta method .",
    "if desired , a consistent labelling can be recovered based on the proof of theorem [ thmvectors ] ( see the supplementary material ) .",
    "consider a generic situation in which a set of @xmath178 matrices @xmath179 can be jointly diagonalized by an @xmath149 invertible matrix @xmath180 , that is , @xmath181 for diagonal matrices @xmath182 .",
    "knowledge of the joint eigenvectors implies knowledge of the eigenvalues as @xmath183 the matrix @xmath184 is not unique",
    ". moreover , let @xmath185 and let @xmath186 denote the frobenius norm .",
    "then any solution to the least - squares problem @xmath187 is a joint diagonalizer in the sense of ( [ eqsystem1 ] ) .",
    "each of these delivers the same set of eigenvalues in ( [ eqsystem2 ] ) ( up to a joint permutation ) .",
    "the statistical problem of interest in this section is to perform inference on the @xmath188 when we only observe noisy versions of the input matrices @xmath189 , say @xmath190 .",
    "the sampling noise in the @xmath191 prevents them from sharing the same set of eigenvectors . indeed , in general ,",
    "there does not exist a @xmath162 such that @xmath192 will be exactly diagonal for all @xmath135 .",
    "for this , the least - squares formulation in ( [ eqsystem2])([eqols ] ) is important as it readily suggests using , say @xmath193 , any solution to @xmath194 where @xmath195 is an appropriately - specified space of matrices to search over ; see below .",
    "the estimator @xmath193 is that matrix that makes all these matrices as diagonal as possible , in the sense of minimizing the sum of their squared off - diagonal entries .",
    "it is thus appropriate to call the estimator @xmath193 the joint approximate - diagonalizer of @xmath196 .",
    "an estimator of the @xmath197 ( up to a joint permutation of their eigenvalues ) then is @xmath198 distribution theory for this estimator is not available , however , and so we provide it here . throughout",
    ", we work under the convention that estimates are computed from a sample of size @xmath199 .      for our problem to be well defined , we assume that the matrix of joint eigenvectors is bounded . in ( [ eqolssample ] )",
    ", we may therefore restrict attention to the set of @xmath149 matrices @xmath200 defined as @xmath201 for some @xmath202 .",
    "the restrictions on the determinant and the column norms are without loss of generality and only reduce the space of matrices to be searched over when solving ( [ eqolssample ] ) .",
    "let @xmath203 be any solution to ( [ eqols ] ) on @xmath195 and let @xmath204 be the set of all matrices @xmath205 for permutation matrices @xmath206 and diagonal matrices @xmath207 whose diagonal entries are equal to @xmath208 and @xmath209 and have @xmath210 .",
    "then @xmath211 is the set of solutions to ( [ eqols ] ) on @xmath195 .",
    "construct the @xmath212 matrix @xmath213 by concatenation and define @xmath214 similarly .",
    "[ thmconsistency ] if the set @xmath211 belongs to the interior of @xmath195 , @xmath215 , and @xmath216 satisfies @xmath217 then @xmath218 for any open subset @xmath219 of @xmath195 containing @xmath211 .",
    "each @xmath220 has associated with it a permutation matrix @xmath206 and a diagonal matrix @xmath221 as just defined so that @xmath222 .",
    "theorem [ thmconsistency ] states that ( up to a subsequence ) we have that @xmath223 for well - defined @xmath224 and @xmath225 .",
    "we may then set @xmath226 in ( [ eqsystem1 ] ) .",
    "it then equally follows that @xmath227 where @xmath197 is as in ( [ eqsystem2 ] ) and @xmath228 , both of which are equal up to a permutation .",
    "thus , the consistency of the eigenvalues ( up to a joint permutation ) follows from the consistency of the estimator of the input matrices @xmath229 .",
    "to provide distribution theory , let @xmath230 denote the kronecker difference between the square matrices @xmath231 and @xmath232 . construct the @xmath233 matrix @xmath234 by concatenation and let @xmath235 where @xmath236 is the moore ",
    "penrose pseudo inverse of @xmath170 .",
    "theorem [ thmnormalityq ] contains distribution theory for our estimator of the matrix of joint eigenvectors @xmath237 in ( [ eqolssample ] ) .",
    "[ thmnormalityq ] if @xmath238 , then @xmath239 as @xmath240 .",
    "if , further , @xmath241 for some covariance matrix @xmath146 , theorem  [ thmnormalityq ] implies that @xmath242 as @xmath240 . in our context ,",
    "@xmath243-consistency and asymptotic normality of the input matrices is not a strong requirement .",
    "indeed , the proof of theorem [ thmid1 ] showed that the input matrices are of the form @xmath244 , where @xmath245 and @xmath246 follow from a singular - value decomposition of @xmath138 .",
    "an estimator of @xmath247 can thus be constructed using a sample analog of @xmath138 to estimate @xmath245 and @xmath248 , together with a sample analog of @xmath134 .",
    "if the estimators of @xmath138 and @xmath134 are @xmath249-consistent and asymptotically normal and all nonzero singular values of @xmath138 are simple , then @xmath250 holds . a detailed derivation of @xmath146 is readily obtained from the argument on the estimation of eigen - decompositions of normal matrices in the supplementary material to @xcite [ ( @xcite ) , lemma s.2 ] .",
    "we next present the asymptotic behavior of @xmath251 , our estimator of the eigenvalues @xmath252 .",
    "to state it , let @xmath253 be an @xmath254 selection matrix ; note that @xmath255 . let @xmath256 theorem [ thmnormality ] follows .",
    "[ thmnormality ] if @xmath238 , then @xmath257 as @xmath240 .",
    "again , if @xmath241 , then @xmath258 as @xmath240 .",
    "with discrete outcomes , both the finite - mixture model in ( [ eqdiscretemixture ] ) and the hidden markov model in ( [ eqhmm ] ) are finite dimensional .",
    "further , the matrices to be simultaneously diagonalized are contingency tables .",
    "these tables can be estimated by simple empirical cell probabilities and are @xmath243-consistent and asymptotically normal .",
    "hence , the theory on the asymptotic behavior of the eigenvalues from the previous section ( i.e. , theorem [ thmnormality ] ) can directly be applied to deduce the large - sample behavior of the parameter estimates .    with continuous outcomes , as in ( [ eqcontinuousmixture ] ) ,",
    "the main parameters of the model are density functions .",
    "such an infinite - dimensional problem is not directly covered by the arguments from the previous section .",
    "nonetheless , we will show that theorem  [ thmnormalityq ] can be used to obtain density estimators with standard asymptotic properties .",
    "we provide convergence rates and distribution theory for series estimators based on ( [ eqfouriersystem ] ) . by the results of section  [ subsechmm ] , this also covers the estimation of emission densities in a hidden markov model with continuous outcome variables .",
    "recall from above that the projections @xmath259 yield the multilinear restrictions @xmath260 = \\sum_{j=1}^r \\pi_j \\bigotimes_{i=1}^q e \\bigl[\\bolds{\\varphi}_{\\kappa _ i}(y_i)\\rho(y_i){|}z = j\\bigr ] = \\sum_{j=1}^r \\pi_j \\bigotimes_{i=1}^q \\mathbf{b}_{ij},\\ ] ] where @xmath261 is the vector containing the @xmath11 leading polynomials from the orthogonal system @xmath262 .",
    "as we will show , for fixed @xmath263 , the array @xmath52 provides sufficient information for nonparametric identification of fourier coefficients through the associated joint diagonalizer .",
    "moreover , in the asymptotic analysis , @xmath47 are all held fixed .    for the purpose of this section",
    ", we may fix attention to a given index @xmath95 . by unfolding @xmath52 toward direction @xmath95",
    ", we obtain the ( equivalent ) three - way array @xmath264,\\ ] ] where @xmath113 and @xmath114 partition the index set @xmath265 ( see section  [ secid ] ) and we have introduced the notational shorthand @xmath266 the array @xmath267 can be analyzed using our diagonalization approach . following the notation from the proof of theorem  [ thmid1 ] , the two - dimensional submodel associated with @xmath267 is the matrix @xmath268,\\ ] ] while the array @xmath267 itself consists of the first @xmath269 matrices of the set @xmath270 , where @xmath271.\\ ] ] all these matrices are of dimension @xmath272 .",
    "a singular - value decomposition of @xmath138 provides matrices @xmath245 and @xmath246 so that the @xmath11 matrices @xmath273 are jointly diagonalizable by , say , @xmath162 . from the proof of theorem  [ thmid1 ] ,",
    "the matrix @xmath162 is unique ( up to the usual normalizations on the sign and norm of its columns and a joint permutation of the columns , as discussed before ) as soon as the conditions in theorem  [ thmid1 ] are satisfied .",
    "given @xmath162 , we can compute @xmath274 where , recall , @xmath275 $ ] for any integer @xmath135 ( including those @xmath135 that exceed @xmath11 ) .",
    "equivalently , the @xmath135th fourier coefficient of @xmath25 can be written as @xmath276 where @xmath277 is the @xmath278 selection vector whose @xmath279th entry is equal to one and its other entries are all equal to zero .",
    "our orthogonal - series estimator of @xmath25 is based on sample analogs of the @xmath280 in  ( [ eqcoeff ] ) .",
    "we estimate the array @xmath281 as @xmath282 where @xmath283 is a size-@xmath199 sample drawn at random from the mixture model . from this",
    "we estimate @xmath280 for any @xmath135 as @xmath284 using obvious notation to denote sample counterparts in the first expression and introducing the matrix @xmath285 in the second expression ; here , we let @xmath286 .",
    "the associated orthogonal - series estimator of @xmath287 for some chosen integer @xmath41 is @xmath288\\\\[-8pt]\\nonumber & = & n^{-1 } \\sum_{m=1}^n \\mathbf{e}_j^\\prime\\widehat{\\bolds{\\omega}}_m \\mathbf{e}_j \\sum_{k=1}^{\\varkappa } \\varphi_k(y_{im})\\varphi_k(y ) \\rho(y_{im}).\\end{aligned}\\ ] ] note that , in the absence of @xmath289 , this expression collapses to a standard series estimator of the marginal density of @xmath9 .",
    "hence , the term @xmath290 can be understood as a weight that transforms this estimator into one of the conditional density of @xmath9 given @xmath13 .",
    "equation ( [ eqdensityhat ] ) generalizes the kernel estimator of @xcite .",
    "the term @xmath291 plays the same role as the posterior classification probability ( normalized to sum up to one across observations ) in the em algorithm as well as in its nonparametric version [ @xcite , equations ( 15)(17 ) ] .",
    "a computational advantage here is that the series estimator is available in closed form once @xmath292 has been computed while em requires iterative computation of density estimates and classification probabilities until convergence .",
    "a natural way of choosing the number of series terms in ( [ eqdensityhat ] ) would be by minimizing the squared @xmath34-loss , @xmath293 as a function of @xmath41 . in the supplement",
    "we show that an empirical counterpart of this criterion ( up to terms that do not involve @xmath41 ) is @xmath294 apart from the weight functions , this is the usual cross - validation objective for orthogonal - series estimators [ @xcite ] .    before turning to the statistical properties of @xmath295 we note",
    "that , although we maintain a hard thresholding procedure in ( [ eqdensityhat ] ) , our approach can equally be combined with other popular smoothing policies that shrink the impact of higher - order fourier coefficients ; see @xcite [ ( @xcite ) , chapter  3 ] for a discussion on such policies .      under mild conditions ,",
    "the series estimator in ( [ eqdensityhat ] ) exhibits standard large - sample behavior .",
    "the precise conditions depend on the choice of orthogonal system , that is , @xmath296 .",
    "we give two sets of conditions that cover the most popular choices .",
    "when the component densities are supported on compact intervals , we can restrict attention to @xmath297 $ ] without loss of generality ; translation to generic compact sets is straightforward . in this case",
    ", we will allow for polynomial systems that satisfy the following general requirements . here and later",
    ", we let @xmath298 denote the supremum norm .",
    "the sequence @xmath299 is dominated by a function @xmath300 , which is continuous on @xmath301 and positive almost everywhere on @xmath297 $ ] .",
    "@xmath31 , @xmath302 , and @xmath303 are integrable , and there exists a sequence of constants @xmath304 so that @xmath305 .",
    "these conditions are rather weak .",
    "they are satisfied for the popular class of jacobi polynomials , for example , which includes chebyshev polynomials of the first kind , chebyshev polynomials of the second kind , and legendre polynomials .    in this case , we will need the following regularity from the component densities .",
    "the @xmath306 are integrable .",
    "the weaker requirement that the @xmath307 are integrable will suffice to obtain the convergence rates in theorem  [ thmrates ] below , but will be needed to obtain the pointwise asymptotic - normality result in theorem  [ thmpointwise ] .    when the component densities are supported on the whole real line , we will take @xmath299 to be the orthonormalized system of hermite functions .",
    "the sequence @xmath299 has members @xmath308 where @xmath309 is the system of the hermite polynomials , in which case @xmath310 for @xmath311 .",
    "we will also impose the following regularity and smoothness conditions .",
    "the @xmath25 are continuous .",
    "@xmath312 for some constant @xmath313 .",
    "the singular values of @xmath138 are all simple",
    ".    convergence in @xmath34-norm implies that @xmath314 is finite , and so that the fourier coefficient associated with @xmath315 shrinks to zero as @xmath316 .",
    "the constant @xmath317 is a measure of how fast the fourier coefficients shrink . in general , @xmath317 is larger the smoother the underlying function that is being approximated .",
    "simplicity of the singular values of @xmath138 holds generically and is used here to ensure that the matrices @xmath318 are continuous transformations of @xmath138 .",
    "this is a technical requirement used to derive the convergence rates of their plug - in estimators .    under these assumptions ,",
    "we obtain standard integrated squared - error and uniform convergence rates .",
    "[ thmrates ] let either  and  or and  hold .",
    "then @xmath319 for all @xmath320 .",
    "the rates in theorem  [ thmrates ] equal the conventional univariate rates of series estimators ; see , for example , @xcite .",
    "thus , the fact that @xmath1 is latent does not affect the convergence speed of the density estimates .    to present distribution theory for",
    "the orthogonal - series estimator at a fixed point  @xmath321 , let @xmath322 which is a sample standard deviation , and denote @xmath323 in the following theorem .",
    "[ thmpointwise ] suppose that @xmath324 so that @xmath325 and @xmath326 . then @xmath327 for each @xmath328 that lies in an interval on which @xmath329 is of bounded variation .    under  , @xmath330 grows like @xmath331 , and this depends on the polynomial system used . because states that @xmath332 , a weak bound on the convergence rate that holds for all @xmath321 is @xmath333 .",
    "with legendre polynomials , for example , the orthogonal - series estimator has a variance of order @xmath334 , which is the same as that of an estimator based on a random sample from @xmath25 [ @xcite ] .",
    "likewise , under we have that @xmath335 grows like @xmath336 and so the variance of the estimator is of the order @xmath337 .",
    "this is again the standard convergence rate for conventional hermite series estimators [ @xcite ] .",
    "we evaluated the performance of the orthogonal - series estimator via simulation .",
    "we report root mean integrated squared error ( rmise ) calculations for designs taken from @xcite .",
    "this allows us to compare our estimator to the em - like approaches proposed in the literature .",
    "we also investigate the accuracy of the pointwise asymptotic approximation of the density estimator in theorem [ thmpointwise ] in a monte carlo experiment based on a hidden markov model . throughout this section ,",
    "we use hermite polynomials as basis functions , set @xmath338 for all @xmath95 , and use the cross - validation technique introduced above to select the number of series terms .",
    "joint approximate diagonalization was done using the algorithm of @xcite ( @xcite ) .",
    "we also computed the estimator using the algorithms of @xcite and @xcite ( @xcite ) and found very similar results to the ones reported below .",
    "we evaluate the rmise of the estimator @xmath295 , @xmath339 as approximated by @xmath340 monte carlo replications .",
    "the first set of designs involves mixtures of normals , where @xmath341 the second set of designs deals with mixtures of central and noncentral @xmath342-distributions , that is , @xmath343 where we let @xmath344 denote a @xmath342-distribution with @xmath345 degrees of freedom and noncentrality parameter @xmath346 .",
    "we set @xmath75 , @xmath347 , so the data is drawn from a three - variate two - component mixture .",
    "the parameters of the component densities are set to @xmath348 for the first component and @xmath349 for the second component .",
    "we consider various choices for the mixing proportions @xmath350 .",
    "figure  [ figmcrmise ] plots the rmise as a function of the mixing proportion @xmath351 for samples of size @xmath352 .",
    "the results for the first and second component for each outcome variable are labelled consecutively as @xmath353 and as @xmath354 , @xmath355 , @xmath356 , respectively .",
    "the patterns of the rmise are comparable to those for the em - like estimators in @xcite [ ( @xcite ) , figure  1 ] , although the magnitudes are larger here .",
    "the latter observation agrees with the intuition that joint estimation of classification probabilities and component densities ( as in em ) should be more efficient than sequential estimation ( as here ) .",
    "however , a precise comparison between the methods is complicated by the fact that the em approaches are kernel based while we work with orthogonal series , and because the tuning parameters ( the bandwidths for em and the number of series terms here ) were selected in a different manner .",
    "our least - squares estimator of the mixing proportions was also evaluated in these designs and was found to perform well .",
    "the monte carlo results are provided in the supplementary material [ @xcite ] .",
    "we next consider inference in a hidden markov model with @xmath347 latent states and @xmath75 outcome variables .",
    "the latent markov chain has transition matrix and stationary distribution equal to @xmath357 respectively .",
    "the emission densities @xmath358 and @xmath359 are skew - normal densities [ @xcite ] , @xmath360 with @xmath361 , @xmath362 and @xmath363 , @xmath364 .",
    "the sign of the skewness parameters @xmath365 implies that @xmath358 is skewed to the right while @xmath359 is skewed to the left .    in each of @xmath340 monte carlo replications , we estimated the two emission densities @xmath358 and @xmath359 using our orthogonal - series estimator and constructed @xmath366 confidence intervals at the percentiles of @xmath358 and @xmath359 .",
    "we present results for @xmath352 ( left plot ) and @xmath3675000 ( right plot ) graphically in figure  [ figmchmmcomplete ] .",
    "results for additional sample sizes are available in the supplementary material [ @xcite ] .",
    "each plot in figure  [ figmchmmcomplete ] contains the true functions @xmath358 and @xmath359 ( solid lines ) , and the mean ( across the monte carlo replications ) of our orthogonal - series estimator ( dashed lines ) as well as of an infeasible kernel - density estimator ( dashed  dotted lines ) computed from the subsample of observations that are in the respective latent state ( see the supplementary material for more detail ) .",
    "the plots show that , even in small samples , our estimator essentially coincides with the infeasible estimator , on average .",
    "figure  [ figmchmmcomplete ] also contains average @xmath366 confidence intervals ( @xmath368 ) , based on the pointwise distributional result in theorem  [ thmpointwise ] , for the emission densities at their respective percentiles . to assess the adequacy of our asymptotic approximation",
    ", the plots in the figure also provide @xmath366 confidence intervals at the percentiles constructed using the empirical standard deviation of the point estimates across the monte carlo replications ( @xmath369 ) .",
    "figure  [ figmchmmcomplete ] shows that our estimated standard error captures well the small - sample variability of the orthogonal - series estimator .",
    "we thank the editor ( runze li ) , an associate editor , three referees , xiaohong chen , ignat domanov , marc henry and nick vannieuwenhoven for comments .",
    "we are grateful to laurent albera and xavier luciani for sharing the code for their diagonalization algorithm in @xcite ( @xcite ) with us .",
    "early versions of this paper circulated as `` nonparametric spectral - based estimation of latent structures . ''"
  ],
  "abstract_text": [
    "<S> a constructive proof of identification of multilinear decompositions of multiway arrays is presented . </S>",
    "<S> it can be applied to show identification in a variety of multivariate latent structures . </S>",
    "<S> examples are finite - mixture models and hidden markov models . </S>",
    "<S> the key step to show identification is the joint diagonalization of a set of matrices in the same nonorthogonal basis . </S>",
    "<S> an estimator of the latent - structure model may then be based on a sample version of this joint - diagonalization problem . </S>",
    "<S> algorithms are available for computation and we derive distribution theory . </S>",
    "<S> we further develop asymptotic theory for orthogonal - series estimators of component densities in mixture models and emission densities in hidden markov models .    </S>",
    "<S> ./style / arxiv - general.cfg    , </S>"
  ]
}