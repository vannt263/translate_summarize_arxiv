{
  "article_text": [
    "the analysis of randomly weighted sums plays an important role in the insurance and economic literature .",
    "a well known example in ruin theory interprets the weights as discount factors and the sequence @xmath3 as the net losses of an insurance company to analyze the probability of ruin either in finite or infinite time ( see , e.g. , @xcite ) . in economics ,",
    "the @xmath3 can be interpreted as net incomes of an investment and the weights as random return rates ( see , e.g. , @xcite ) . in general , randomly weighted sums appear in the analysis of random stochastic equations ( e.g. , autoregressive processes ) , and have applications in many areas beyond the ones mentioned above .",
    "if we further assume that the number of terms in the sum can be random , we obtain a randomly stopped and randomly weighted sum .",
    "such _ weighted random sums _ appear in the context of weighted branching processes and fixed - point equations of smoothing transforms ( see @xcite ) , and more recently , in the analysis of information ranking algorithms , e.g. , google s pagerank ( see @xcite ) . in all the examples mentioned above , the @xmath3",
    "are often assumed to be heavy - tailed .",
    "hence , the results in this paper combine two different topics in the literature for sums of heavy - tailed random variables , the analysis of randomly weighted sums and the analysis of randomly stopped sums .",
    "consider a sequence @xmath13 of independent , identically distributed ( i.i.d . )",
    "random variables with finite mean and a heavy right tail distribution @xmath1 , where by heavy we mean @xmath14 = \\infty$ ] for all @xmath15 , and @xmath16 .",
    "let @xmath2 be a nonnegative random vector independent of the @xmath3 with @xmath4 .",
    "we study the asymptotic behavior of the randomly weighted and randomly stopped sum @xmath17 , and of its maximum , @xmath18 ; the weights @xmath19 are allowed to be arbitrarily dependent and may depend on @xmath20 as well , and the convention throughout the paper is that @xmath21 if @xmath22 .",
    "we point out that it is possible to avoid the introduction of @xmath20 by redefining the weights @xmath23 and considering the sum @xmath24 , but to emphasize the possibility of having a random number of summands we choose to keep the results in this paper in terms of @xmath20 . throughout the paper we use @xmath25 as @xmath8 to denote @xmath26 , and @xmath27 as @xmath8 to denote @xmath28 and @xmath29 .",
    "although the literature of both weighted random sums and randomly stopped sums is extensive , this is the first paper , to our knowledge , to combine the two , and in doing so , to obtain the @xmath22 case under conditions that are close to the best possible .",
    "the main results also include an analysis of the cases where the asymptotic behavior of the weighted random sum does not follow the so - called _ one - big - jump principle _",
    "( @xmath30 as @xmath8 ) , and instead is dominated by the sum of the weights , which until now had only been done for the special case @xmath31 ( see @xcite ) .    to gain some insight into the asymptotics @xmath32 , \\qquad x \\to \\infty,\\ ] ] note that if the @xmath3 are i.i.d . and heavy - tailed , and the weights @xmath19 satisfy suitable conditions , then the random variables @xmath33 behave as if they were independent , and the one - big - jump principle gives .",
    "the asymptotic relation @xmath34 \\overline{f}(x ) , \\qquad x \\to \\infty,\\ ] ] was established in @xcite for nonnegative and regularly varying @xmath3 ( denoted @xmath0 in @xmath35 , @xmath36 ) , and was proven in @xcite for real - valued @xmath3 with regularly varying right tail and deterministic @xmath20 , either @xmath37 ( finite ) or @xmath22 .",
    "the setting where the @xmath3 are real - valued with right tail in the extended regular variation class was studied in @xcite ( @xmath37 ) and @xcite ( both @xmath37 and @xmath22 ) ; in the latter the @xmath3 are allowed to be generally dependent with no bivariate upper tail dependence .",
    "deterministic , real - valued weights with the @xmath3 in @xmath35 were considered in @xcite .",
    "we point out that in all the mentioned works where @xmath22 , the conditions imposed on the weights are considerably stronger than those imposed for a finite number of terms .",
    "the first result in this paper establishes for i.i.d .",
    ", real - valued @xmath3 with finite mean , right tail in the intermediate regular variation class , and @xmath20 potentially random ; the conditions on the weights are basically the same regardless of whether @xmath20 is deterministic , random , or infinity .",
    "results for more general classes of heavy - tailed distributions but stronger conditions on the weights and @xmath37 are given in @xcite ( for bounded weights ) and @xcite ( for @xmath38 and @xmath39 i.i.d . from a specific class of distributions ) .",
    "the finite mean restriction is due to our interest in analyzing the asymptotic behavior of the randomly weighted and randomly stopped sum when it is not solely determined by the one - big - jump principle .    as mentioned earlier",
    ", the scope of this paper is to combine the analysis of randomly weighted sums with that of randomly stopped sums .",
    "for instance , if we set @xmath31 for all @xmath40 , then the subexponential asymptotics @xmath41 is known to hold , under suitable conditions on @xmath20 , even for a random number of summands . the asymptotic relation @xmath42 \\overline{f}(x ) , \\qquad x \\to \\infty,\\ ] ] has a long history ( see , e.g. , @xcite , @xcite and the references therein ) , although the analysis when @xmath20 does not have finite exponential moments is more recent .",
    "relation was established in @xcite for several different sets of conditions on @xmath20 and the @xmath3 , including some where @xmath20 may be subexponential .",
    "some results imposing no conditions on @xmath20 and the @xmath3 in either the regularly varying or semi - exponential classes were derived in @xcite .",
    "the most general conditions were recently derived in @xcite for @xmath3 in the class @xmath43 , which includes most subexponential distributions with finite mean . moreover",
    ", the results in @xcite also include the case where the asymptotic behavior of the randomly stopped sum is not solely determined by the one - big - jump principle , and , in particular , it was shown that @xmath44 \\overline{f}(x ) + p(n > x / e[x_1 ] ) , \\qquad x \\to \\infty,\\ ] ] provided that the @xmath3 belong to @xmath43 , @xmath9 > 0 $ ] , and @xmath20 belongs to the intermediate regular variation class .",
    "the term @xmath45)$ ] corresponds to the situation where the asymptotic behavior of the random sum is determined by the law of large numbers .",
    "this last asymptotic relation was previously proven in @xcite for the case where both @xmath20 and @xmath46 are nonnegative and belong to @xmath35 with @xmath47 , @xmath48 for some constant @xmath49 , and @xmath9 < \\infty$ ] .",
    "all the results in @xcite are readily applicable to our randomly weighted sums setting provided that the @xmath19 are i.i.d . , independent of @xmath20 , and that the sequence @xmath50 belongs to @xmath43 .",
    "the second result in this paper extends the analysis to allow the vector @xmath2 to have an arbitrary distribution , but restricts the @xmath3 to belong to the intermediate regular variation class . in this context , the term @xmath45)$ ] is replaced by @xmath51\\right)$ ] .    for completeness",
    ", the third and last result in this paper considers the case where the behavior of the randomly stopped and randomly weighted sum is completely determined by the effects of the sum @xmath52 , which when the weights @xmath19 are i.i.d . and independent of @xmath20 , corresponds to the dominance of the law of large numbers .",
    "the intuition remains the same in the presence of weights , as it corresponds to the situation where all the @xmath3 behave in an ordinary way , i.e. , according to their mean , and it is the sum of the weights that is unusually large . related results to those of theorem [ t.zdominates ] can be found in @xcite for a regularly varying number of summands , @xmath20 , @xmath31 , and nonnegative @xmath3 with lighter tails than @xmath20 .",
    "we end this section with two potential applications .",
    "the first one concerns information ranking algorithms , such as google s pagerank algorithm for ranking webpages in the world wide web ( www ) .",
    "if we let @xmath53 denote the ( scale free ) rank of a randomly chosen webpage , @xmath20 denote the number of webpages pointing to it ( in - degree ) , and set @xmath54 , where @xmath55 is the number of outbound links ( out - degree ) of the @xmath56th neighboring page and @xmath57 is a predetermined constant , then it can be shown that @xmath53 ( approximately ) satisfies the stochastic fixed - point equation @xmath58 where the @xmath59 are i.i.d .",
    "copies of @xmath53 , independent of @xmath2 , and @xmath60 denotes equality in distribution . in the www , as in many other social networks , both the in - degree @xmath20 and the effective out - degree @xmath55 are assumed to be regularly varying .",
    "the problem of interest is to determine the proportion of highly ranked pages , which translates into the analysis of the asymptotic behavior of @xmath61 .",
    "the stochastic model leading to , for the case of i.i.d .",
    "weights @xmath19 independent of @xmath20 , was introduced in @xcite , and has been studied in detail in @xcite .",
    "the more realistic case where the vector @xmath62 is generally correlated serves as a motivating example for the results presented here .",
    "the second application concerns ruin probabilities .",
    "a well known example in ruin theory where randomly weighted sums appear is in the analysis of discrete time risk models ( see , e.g. , @xcite ) .",
    "let @xmath63 be a sequence of i.i.d .",
    "nonnegative random variables representing discount factors per period , and let @xmath0 be another sequence of i.i.d .",
    "real - valued random variables , independent of the @xmath63 , used to denote the per period net losses of an insurance company ; in many settings the @xmath3 are assumed to have a heavy right tail . set the weight @xmath64 to be the compound discount factor for period @xmath56 . if the insurance company starts with an initial capital @xmath65 , then its discounted surplus after @xmath66 periods",
    "is given by @xmath67 the quantities of interest are the probabilities of ruin in finite and infinite time , given respectively by @xmath68 the rest of the paper is organized as follows .",
    "upper bounds for the maximum of the randomly weighted sum are derived in section [ s.upperbound ] , and lower bounds for the randomly stopped and randomly weighted sum are derived in section [ s.lowerbound ] .",
    "finally , the proofs of the main results are given in section  [ s.mainproofs ] .",
    "we start by giving some definitions needed for the statement of the main theorems .",
    "let @xmath69 be a random variable with right tail distribution @xmath70 .",
    "we say that @xmath1 belongs to the _ intermediate regular variation _",
    "( ir ) class if @xmath71    we refer the reader to chapter 2 in @xcite for the definitions of regular variation ( @xmath35 ) , extended regular variation ( er ) , and o - regular variation ( or ) , that are mentioned throughout the paper .",
    "it is well known that @xmath72 .",
    "let @xmath70 , @xmath73 , and define @xmath74 the constant @xmath75 is known as the _ lower matuszewska index _ of @xmath76 , and @xmath77 is known as the _ upper matuszewska index _ of @xmath76 , and they satisfy @xmath78 .",
    "* remark : * for the or family , theorem 3.4.3 in @xcite gives @xmath79 .",
    "furthermore , the constants @xmath80 in the definition of the er class satisfy @xmath81 ( see pg . 68 in @xcite ) .",
    "we are now ready to state the three main theorems of this paper .",
    "the first one corresponds to the setting where the one - big - jump principe dominates the behavior of the weighted random sum and its maximum .",
    "since the weights @xmath19 are nonnegative , we use the convention that @xmath82 for any @xmath83 if @xmath84 .",
    "[ t.summandsdominate ] suppose @xmath3 is a sequence of i.i.d .",
    "random variables with right tail distribution @xmath85 , matuszewska indices @xmath86 , and @xmath87 < \\infty$ ] for some @xmath88 .",
    "let @xmath2 be a nonnegative random vector independent of the @xmath3 with @xmath4 and satisfying @xmath89 < \\infty$ ] and @xmath90 < \\infty$ ] .",
    "if @xmath91 < \\infty$ ] then the condition @xmath89",
    "< \\infty$ ] can be dropped .",
    "let @xmath92 a.s .",
    "if any of the following holds ,    1 .",
    "@xmath9 < 0 $ ] , or , 2 .",
    "@xmath9 = 0 $ ] and @xmath93 as @xmath8 , or , 3 .",
    "@xmath9 > 0 $ ] and @xmath94 as @xmath8 ,    then , as @xmath8 , @xmath95.\\ ] ]    * remark : * it is known that when @xmath37 it is enough to have @xmath96 < \\infty$ ] for to hold ( see @xcite ) .",
    "note that for a finite number of terms this moment condition on the weights implies that @xmath97 \\right)^{1/(\\beta_f+\\epsilon ) } \\leq   \\sum_{i=1}^n \\left(e\\left[c_i^{\\beta_f+\\epsilon}\\right ] \\right)^{1/(\\beta_f+\\epsilon ) } < \\infty,\\ ] ] which in turn implies that @xmath98 ( since @xmath99 ) .",
    "however , for @xmath22 and @xmath100 , the existing literature ( e.g. , @xcite ) , which assumes @xmath101 , requires the conditions @xmath102 \\right)^{1/(d+\\epsilon ) } < \\infty$ ] and @xmath103 \\right)^{1/(d+\\epsilon ) } < \\infty$ ] , which again imply that @xmath104 < \\infty$ ] . in view of theorem [ t.summandsdominate ] ,",
    "the existing conditions are clearly too strong , and a simple example where holds but @xmath102 \\right)^{1/(d+\\epsilon ) } = \\infty$ ] is given below . moreover , that the conditions of theorem [ t.summandsdominate ] are close to being the best possible will follow from theorem [ t.both ] .",
    "suppose that as @xmath8 , @xmath105 for some @xmath106 , @xmath107 , and @xmath9 = 0 $ ] .",
    "furthermore , assume that the @xmath19 are i.i.d .",
    ", independent of @xmath20 , with @xmath108 < \\infty$ ] .",
    "now write @xmath23 so that @xmath109 , and note that for some constant @xmath110 , @xmath111   \\right)^{1/(\\alpha+\\epsilon ) } = \\left ( e [ c_1^{\\alpha+\\epsilon } ] \\right)^{1/(\\alpha+\\epsilon ) } \\sum_{i= 1}^\\infty   p(n \\geq i)^{1/(\\alpha+\\epsilon ) } \\geq   \\sum_{i=1}^\\infty \\frac{k}{i^{\\alpha/(\\alpha+\\epsilon ) } } = \\infty.\\ ] ]    * remarks : * ( i ) the conditions of theorem [ t.summandsdominate ] are very similar to those of theorem 1 in @xcite once we replace the random time @xmath112 by the random sum of the weights @xmath10 .",
    "( ii ) the stronger condition @xmath113 < \\infty$ ] , instead of only @xmath114 < \\infty$ ] , might be avoidable with a different proof technique .",
    "the next result corresponds to the case where the behavior of the weighted random sum and its maximum might be influenced by both the one - big - jump principle and the distribution of the sum of the weights .",
    "this case also illustrates that when @xmath9 > 0 $ ] , the conditions from theorem [ t.summandsdominate ] are the best possible .    [ t.both ]",
    "suppose @xmath3 is a sequence of i.i.d .",
    "random variables with right tail distribution @xmath85 , matuszewska indices @xmath86 , @xmath9 > 0 $ ] , and @xmath87 < \\infty$ ] for some @xmath88 .",
    "let @xmath2 be a nonnegative random vector independent of the @xmath3 with @xmath4 and satisfying @xmath89 < \\infty$ ] and @xmath90 < \\infty$ ] .",
    "if @xmath91 < \\infty$ ] then the condition @xmath89",
    "< \\infty$ ] can be dropped .",
    "let @xmath92 a.s . and",
    "suppose further that its tail distribution @xmath115 .",
    "then , as @xmath8 , @xmath116 + p\\left ( \\sum_{i=1}^n c_i > x / e[x_1 ] \\right).\\ ] ]    * remark : * if @xmath3 is a sequence of i.i.d .",
    "random variables from @xmath35 with @xmath106 , then @xmath117 $ ] can be replaced with @xmath118 \\overline{f}(x)$ ] in theorems [ t.summandsdominate ] and [ t.both ] . in this",
    "setting , theorems [ t.summandsdominate ] and [ t.both ] are generalizations of breiman s theorem to more than one summand and dependent weights .",
    "the third , and the last , result corresponds to the case where the behavior of the weighted random sum is dominated solely by the sum of the weights . note that it is not necessary for the @xmath3 to have any particular structure beyond certain moments and the condition @xmath119 as @xmath8 .",
    "[ t.zdominates ] let @xmath2 be a nonnegative random vector with @xmath4 .",
    "define @xmath92 a.s . and assume that it has a right tail distribution @xmath115 with matuszewska indices @xmath120 .",
    "suppose @xmath3 is a sequence of i.i.d .",
    "random variables , independent of @xmath2 , with @xmath9 > 0 $ ] , and @xmath87 < \\infty$ ] for some @xmath121 .",
    "suppose further that @xmath122 < \\infty$ ] , @xmath123 < \\infty$ ] , and @xmath124 .",
    "if @xmath91 < \\infty$ ] then the condition @xmath125",
    "< \\infty$ ] can be dropped .",
    "then , as @xmath8 , @xmath126 \\right).\\ ] ]",
    "before proceeding with the derivation of the auxiliary results that will be needed for the proofs of the main theorems , we state here the notation that will be used in the remainder of the paper , as well as the main assumption satisfied by the random variables @xmath3 and the vector @xmath2 .    [ a.main ]",
    "let @xmath127 be a sequence of i.i.d .",
    "real - valued random variables with common tail distribution @xmath128 and finite mean @xmath129 $ ] , and let @xmath2 represent a nonnegative random vector , independent of the @xmath3 , with @xmath4 . the vector @xmath2 is assumed to be generally dependent and the weights @xmath19 are not necessarily identically distributed .",
    "we will also use @xmath130)^{1/p}$ ] to denote the @xmath131norm , the operator @xmath132 to denote the cardinality of a set @xmath133 , and the symbols @xmath134 , @xmath135 .",
    "the letter @xmath136 will be used to denote a generic positive constant , which is not always the same in different parts of the paper , i.e. @xmath137 , @xmath138 , etc .",
    "the following random variables will be used throughout the paper : @xmath139 note that when @xmath20 is finite a.s .",
    "the supremum in the definition of @xmath140 can be replaced by a maximum and all the ranges @xmath141 can be replaced by @xmath142 . recall that",
    "since the weights @xmath19 are nonnegative , the convention is that @xmath82 and @xmath143 for any @xmath83 if @xmath84 .",
    "the first result in this section provides a bound for the partial maximum of sums of independent random variables with finite exponential moments .",
    "[ l.expbound ] let @xmath144 be a sequence of independent random variables .",
    "then , for all @xmath145 , @xmath146   \\right\\}.\\ ] ]    the inequality trivially holds in case @xmath147 = \\infty$ ] for some @xmath56 .",
    "thus , we assume that @xmath147 < \\infty$ ] for all @xmath148 . let @xmath149.\\ ] ] then @xmath150 is a nonnegative martingale satisfying @xmath151 = 1 $ ] .",
    "define @xmath152 .",
    "then , by proposition 3.1 and theorem 3.2 in chapter xiii of @xcite there exists a probability measure @xmath153 such that @xmath154 \\\\ & \\leq   \\widetilde{e } \\left [ e^{-\\theta \\sum_{i=1}^\\tau v_i } \\indicator \\left (   \\tau \\leq m   \\right )   \\right ]   \\prod_{i=1}^m \\max\\left\\{1 , e\\left [ e^{\\theta v_i } \\right ]   \\right\\ } \\\\ & \\leq e^{-\\theta t } \\prod_{i=1}^{m } \\max\\left\\{1 , e\\left [ e^{\\theta v_i } \\right ]   \\right\\}.\\end{aligned}\\ ] ]    the following result gives exponential bounds for sums of independent truncated random variables , and it follows the same classical heavy - tailed techniques from @xcite and @xcite ( see also @xcite ) .",
    "note that all of the results in this and the next section are given for random variables satisfying only moment conditions , that is , neither the @xmath3 nor the vector @xmath2 are assumed to belong to any particular class of distributions .",
    "[ l.truncbound ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath155 for some @xmath156 .",
    "then , for any @xmath157 such that @xmath158 any @xmath159 , and any @xmath160 , we have @xmath161   , \\end{aligned}\\ ] ] where @xmath162 is a constant that does not depend on the distributions of @xmath163 .",
    "let @xmath164 , @xmath165 and @xmath166 . by conditioning on @xmath2",
    "we obtain @xmath167 .\\end{aligned}\\ ] ] note that conditional on @xmath168 , @xmath169 is a sum of independent random variables , so by lemma  [ l.expbound ] , @xmath170 \\right\\ } \\\\ & =   e^{-\\theta z } \\prod_{i=1}^{n\\wedge n } \\max\\left\\ { 1 , e\\left [ \\left . e^{\\theta y_i",
    "\\indicator(y_i \\leq v ) } \\right| c_i   \\right ] \\right\\}.\\end{aligned}\\ ] ]    we now bound the individual expectations using integration by parts as follows , @xmath171 & = e\\left [ \\left .",
    "e^{\\theta y_i } \\indicator(y_i \\leq v ) \\right|",
    "c_i \\right ] + e\\left [ \\left .",
    "v ) \\right|",
    "c_i \\right ] \\\\ & = \\int_{-\\infty}^v e^{\\theta t } p(y_i \\in dt | c_i ) + p(y_i > v | c_i ) \\\\ & = p(y_i \\leq 1/\\theta|c_i ) + \\int_{-\\infty}^{1/\\theta } \\theta t p(y_i \\in dt | c_i ) + e p(y_i",
    "> 1/\\theta|c_i ) -e^{\\theta v } p(y_i > v | c_i )    \\\\ & \\hspace{5 mm } + p(y_i > v | c_i ) +   \\int_{-\\infty}^{1/\\theta } ( e^{\\theta t}-1-\\theta t )   p(y_i \\in dt | c_i )   + \\theta \\int_{1/\\theta}^v e^{\\theta t } p(y_i > t|",
    "c_i ) dt \\\\",
    "& \\leq 1 + \\theta e[y_i|c_i ] + ep(y_i > 1/\\theta|c_i ) +    \\int_{-\\infty}^{1/\\theta } ( e^{\\theta t}-1-\\theta t )   p(y_i \\in dt | c_i ) \\\\ & \\hspace{5 mm } + \\theta \\int_{1/\\theta}^v e^{\\theta t } p(y_i > t|",
    "\\end{aligned}\\ ] ] if @xmath172 then the inequality @xmath173 for @xmath174 gives @xmath175.\\ ] ] if @xmath176 , then integration by parts , a change of variables , markov s inequality , and the same inequality used above give @xmath177 u^{-\\eta } du + e\\theta^2 \\int_0^{1/\\theta } t^2",
    "p(y_i \\in dt|c_i ) \\\\ & \\leq e[|y_i|^{\\eta } |c_i ] \\left ( \\theta^2 \\int_0^{1/\\theta } \\frac{1-e^{-\\theta u}}{\\theta u } \\cdot u^{1-\\eta } du + \\theta \\int_{1/\\theta}^\\infty u^{-\\eta } du \\right ) \\\\ &",
    "\\hspace{5 mm } + e\\theta^{\\eta } \\int_0^{1/\\theta } t^{\\eta } p(y_i \\in dt | c_i )   \\\\ & \\leq e[|y_i|^{\\eta } | c_i ] \\left ( \\theta^2 \\int_0^{1/\\theta } u^{1-\\eta } du + \\frac{\\theta^{\\eta}}{\\eta-1 }    + e\\theta^{\\eta } \\right ) \\\\ & = \\theta^{\\eta } e[|y_i|^{\\eta } |c_i ] \\left ( \\frac{1}{2-\\eta } + \\frac{1}{\\eta-1 } + e   \\right),\\end{aligned}\\ ] ] where in the third inequality we used the observation that @xmath178 for all @xmath83 .",
    "we then have that @xmath179,\\ ] ] where @xmath180",
    ". also , for @xmath181 we use markov s inequality to obtain @xmath182 \\theta^{\\eta } + e[|y_i|^{\\eta } | c_i ] \\int_{1/\\theta}^v \\theta e^{\\theta t } t^{-\\eta } dt.\\end{aligned}\\ ] ] to analyze the remaining integral we split it as follows , @xmath183 hence , @xmath184,\\ ] ] where @xmath185 . combining and we obtain @xmath186 \\indicator(c_i \\leq   u/\\gamma_{\\eta } ) \\\\ & \\leq \\left ( 1 + \\theta c_i e[x ] + k_1 \\theta^{\\eta\\wedge 2 } c_i^{\\eta\\wedge 2 } e[| x|^{\\eta\\wedge2 } ] + k_2 e^{\\theta v } v^{-\\eta } c_i^{\\eta } e[|x|^{\\eta } ] \\right ) \\indicator(c_i \\leq u/\\gamma_{\\eta } ) \\\\ & \\leq 1 + \\theta c_i e[x ] + c_i \\left ( k_1 \\theta^{\\eta\\wedge2 } ( u/\\gamma_{\\eta})^{\\eta\\wedge2 - 1 } e[|x|^{\\eta\\wedge2 } ] + k_2 e^{\\theta v } v^{-\\eta } ( u/\\gamma_{\\eta})^{\\eta-1 } e[| x|^{\\eta } ]   \\right ) .\\end{aligned}\\ ] ] we now use the observation that @xmath187 = ||x||_{\\eta\\wedge2}^{\\eta\\wedge2 } \\leq || x||_{\\eta}^{\\eta\\wedge2 } = \\gamma_{\\eta}^{\\eta\\wedge 2}$ ] to obtain @xmath171 \\indicator(c_i \\leq u/\\gamma_{\\eta } ) & \\leq 1 + \\theta c_i \\mu + c_i \\gamma_{\\eta } \\left ( k_1 \\theta^{\\eta\\wedge 2 } u^{\\eta\\wedge2 - 1 } + k_2 e^{\\theta v } v^{-\\eta }   u^{\\eta-1 } \\right ) \\\\ & \\leq 1 + \\theta c_i \\mu + \\theta c_i \\gamma_{\\eta } k_3 \\left ( \\theta^{\\eta\\wedge2 - 1 } u^{\\eta\\wedge2 - 1 } + e^{\\theta v } v^{-\\eta } \\theta^{-1 } u^{\\eta-1 } \\right ) \\\\ & \\triangleq 1 + \\theta c_i \\mu +   \\theta c_i \\gamma_\\eta a(\\theta , u , v ) , \\end{aligned}\\ ] ] where @xmath188 . by using the inequality @xmath189 for all @xmath174 , it follows that @xmath190 \\notag \\\\ & \\leq e\\left [ \\indicator \\left (   z_n \\in a \\right ) e^{-\\theta z } \\prod_{i=1}^{n\\wedge n } \\max\\left\\{1 , e^ { \\theta \\mu c_i + \\theta a(\\theta , u , v ) \\gamma_{\\eta } c_i } \\right\\ } \\right ] \\notag \\\\ & = e\\left [ \\indicator\\left (   z_n \\in a \\right ) e^{-\\theta z +   \\left(\\mu + a(\\theta , u , v)\\gamma_\\eta \\right)^+ \\theta z_{n\\wedge n } }   \\right ]   . \\notag\\end{aligned}\\ ] ] now choose @xmath191 which by assumption satisfies @xmath192 , and note that @xmath193 defining @xmath194 gives @xmath195 .\\end{aligned}\\ ] ] the result now follows by taking @xmath196",
    ".    the main result of this section , given in proposition [ p.upperbounds ] , provides upper bounds for @xmath197 .",
    "the idea of the proof is to split this probability into several smaller probabilities corresponding to the different possible behaviors of @xmath11 and @xmath198 .",
    "the bound derived in lemma [ l.truncbound ] will be essential to the analysis of all the probabilities involving truncated summands .",
    "the lemma given below provides a bound for the probability of two or more summands being large .",
    "[ l.secondmax ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath199 for some @xmath15 .",
    "let @xmath200 , @xmath201 and @xmath202 .",
    "fix @xmath49 .",
    "then , there exist constants @xmath203 such that for all @xmath204 , @xmath205 .\\ ] ]    we start by conditioning on @xmath206 to obtain @xmath207 \\right ] \\\\ & = e\\left [ \\indicator \\left ( z_n \\leq cx , \\ , i_n(w ) = 0 \\right ) e\\left [ \\left .",
    "\\indicator \\left ( \\bigcup_{1\\leq i < j < n+1 } \\left\\ { c_i x_i > y , c_j",
    "x_j > y \\right\\ } \\right ) \\right| \\mathcal{f } \\right ] \\right ] \\\\ & \\leq e\\left [ \\indicator \\left ( z_n \\leq cx , \\ , i_n(w ) = 0 \\right ) \\sum_{1",
    "\\leq i < j < n+1 } e \\left [   \\left .",
    "\\indicator \\left ( c_i x_i > y , c_j x_j > y\\right ) \\right| \\mathcal{f } \\right ] \\right ]   \\\\ & = e\\left [ \\indicator \\left ( z_n \\leq cx , \\ , i_n(w ) = 0 \\right ) \\sum_{1",
    "\\leq i < j < n+1 } \\overline{f}(y/ c_i ) \\overline{f}(y / c_j ) \\right ] \\\\ & \\leq e\\left [ \\indicator \\left ( z_n \\leq cx , \\ , i_n(w ) = 0 \\right ) \\left ( \\sum_{i = 1}^n \\overline{f}(y/ c_i ) \\right)^2 \\right ] ,   \\end{aligned}\\ ] ] where in the third equality we used the conditional independence of the @xmath50 given @xmath208 and the independence of the @xmath3 and @xmath2 .",
    "we now use markov s inequality to obtain @xmath209 \\sum_{j=1}^n c_j^{1+\\epsilon } \\leq k y^{-1-\\epsilon }   \\left ( \\sup_{1\\leq j < n+1 } c_j \\right)^{\\epsilon }   z_n.\\end{aligned}\\ ] ] it follows that @xmath210 & \\leq   k y^{-1-\\epsilon } w^{\\epsilon } x e\\left [   \\indicator \\left ( i_n(w ) = 0 \\right ) \\sum_{i = 1}^n \\overline{f}(y/ c_i )   \\right ] \\\\ & \\leq \\frac{k ( \\log x)^{1+\\epsilon } } { x^{\\epsilon\\nu } } e\\left [   \\indicator \\left ( i_n(w ) = 0 \\right ) \\sum_{i = 1}^n \\overline{f}(y/ c_i )   \\right ]   .\\end{aligned}\\ ] ]    the next preliminary lemma shows that if the summands are heavily truncated , then the supremum of the sums is unlikely to be large .",
    "[ l.strongtrunc ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath199 for some @xmath15 .",
    "let @xmath200 , @xmath201 , @xmath202 and @xmath211 .",
    "then , @xmath212 as @xmath8 , for any @xmath213 .",
    "we use lemma [ l.truncbound ] with @xmath214 $ ] , @xmath215 , @xmath216 , and @xmath217 .",
    "then @xmath218 , \\end{aligned}\\ ] ] where @xmath219 .",
    "note that for this choice of @xmath220 and @xmath221 there exists @xmath222 such that the conditions on @xmath223 required by lemma [ l.truncbound ] are satisfied for all @xmath204 .",
    "moreover , on the set @xmath224 we have @xmath225 where in the last inequality we used @xmath226 \\leq ( e[|x_1|^{1+\\epsilon } ] ) ^{1/(1+\\epsilon ) } = \\gamma_{1+\\epsilon}$ ] and @xmath227 . we then have , for sufficiently large @xmath65 ,",
    "@xmath228   \\leq e^{-\\epsilon \\nu \\delta ( \\log x)^2 \\varphi(x)},\\ ] ] where @xmath229 . since @xmath230",
    ", it holds that @xmath231 as @xmath8 for any @xmath213 .",
    "the last preliminary lemma of this section provides a bound for the case when the summands are moderately truncated and @xmath11 is not too large .",
    "[ l.intertrunc ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath232 and @xmath199 for some @xmath15 .",
    "let @xmath200 , @xmath201 , @xmath202 and @xmath233 . then , as @xmath8 , @xmath234    let @xmath235 , @xmath236 and @xmath217 .",
    "then , by lemma [ l.truncbound ] , we have @xmath237 , \\label{eq : mgf_z}\\end{aligned}\\ ] ] where @xmath238 .",
    "we now separate the rest of the analysis into two cases .",
    "* case 1 : * @xmath239 .",
    "we have that is bounded by @xmath240 for sufficiently large @xmath65 .",
    "* case 2 : * @xmath241 .",
    "note that @xmath242 , so is bounded by @xmath243 & \\leq k   e\\left",
    "[ \\indicator(y < z_n \\leq x/(\\mu+\\delta ) ) e^{-\\frac{\\epsilon \\nu\\log x}{x } \\left ( x - \\mu z_n \\right ) } \\right ] \\\\ & = \\frac{k}{x^{\\epsilon\\nu } } e\\left [ \\indicator(y < z_n \\leq x/(\\mu+\\delta ) ) e^{\\frac{\\epsilon\\nu \\mu \\log x}{x } z_n   } \\right ] .\\end{aligned}\\ ] ] now note that by writing @xmath244",
    "( if @xmath245 the second indicator is zero ) we obtain @xmath246 & \\leq \\frac{1}{x^{\\epsilon\\nu/2 } } p(z_n > y ) + \\frac{e^{\\frac{\\epsilon\\nu \\mu \\log x}{\\mu+\\delta}}}{x^{\\epsilon\\nu } } p(z_n > x/(2\\mu ) ) .",
    "\\end{aligned}\\ ] ] since @xmath247 , the result follows .",
    "we are now ready to provide upper bounds for @xmath197 .",
    "as mentioned earlier , the idea is to split the probability into all the different combinations of events relating @xmath11 and @xmath198 .",
    "we emphasize again that no particular structure on the distributions of @xmath11 or the @xmath3 is imposed beyond moment conditions .",
    "[ p.upperbounds ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath199 for some @xmath15 .",
    "in addition , assume that @xmath248 < \\infty$ ] for some @xmath249",
    ". then , there exist constants @xmath203 such that for all @xmath250 and @xmath211 ,    1 .   for @xmath232 , @xmath251 + p\\left ( ( \\mu+\\delta ) z_n > x",
    "\\right )   \\\\ & \\hspace{5 mm } + k \\left ( \\frac{(\\log x)^{1+\\epsilon } } { x^{\\epsilon\\nu } } e\\left [   \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i = 1}^n \\overline{f}(y / c_i )   \\right ]   + \\frac{1}{x^{\\beta+\\epsilon/2 } }   \\right ) \\\\ & \\hspace{5 mm } + k \\left (   x^{-\\epsilon\\nu/2 } p(z_n >",
    "y )   + e^{-\\frac{\\epsilon\\nu\\sqrt{\\log x}}{\\mu } } p(z_n > x/(2\\mu ) ) \\indicator(\\mu > 0 ) \\right),\\end{aligned}\\ ] ] 2 .   for @xmath252 , @xmath251 \\\\",
    "& \\hspace{5 mm } +   k \\left ( \\frac{(\\log x)^{1+\\epsilon } } { x^{\\epsilon\\nu } } e\\left [   \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i = 1}^n \\overline{f}(y / c_i )   \\right ] + \\frac{1}{x^{\\beta+\\epsilon/2 } }   \\right),\\end{aligned}\\ ] ]    where @xmath202 , @xmath253 and @xmath201 .",
    "we separate the analysis into two cases , @xmath232 and @xmath252 .",
    "* case 1 : * @xmath232 .",
    "we start by splitting the probability as follows : @xmath254 let @xmath206 and recall that the @xmath3 are independent of @xmath62 .",
    "then , from the union bound we obtain , @xmath255 \\right ] \\notag \\\\ & \\leq e \\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n e\\left [ \\left .",
    "\\indicator\\left(c_i x_i > ( 1-\\delta ) x \\right ) \\right| \\mathcal{f } \\right ] \\right ] \\notag \\\\ & = e \\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}((1-\\delta)x / c_i )   \\right ] .",
    "\\label{eq : onebigjump}\\end{aligned}\\ ] ]    applying the union bound , fubini s theorem , and the conditional markov inequality , we obtain @xmath256 \\leq e\\left",
    "[ \\sum_{i=1}^n \\indicator(c_i > w )   \\right ] \\notag \\\\ & = \\sum_{i=1}^\\infty p\\left (    c_i > w , \\ , n \\geq i \\right ) = \\sum_{i=1}^\\infty e\\left [ \\indicator(n \\geq i ) e [ \\indicator(c_i > w )",
    "| n ] \\right ] \\notag   \\\\ & \\leq \\frac{1}{w^{\\beta+\\epsilon } } \\sum_{i=1}^\\infty e\\left [   c_i^{\\beta+\\epsilon } \\indicator(n \\geq i )   \\right ] =   \\frac{\\gamma_{1+\\epsilon}^{\\beta+\\epsilon}}{x^{\\beta+\\epsilon/2 } } e\\left [ \\sum_{i=1}^n c_i^{\\beta+\\epsilon }    \\right ] .",
    "\\label{eq : cmax}\\end{aligned}\\ ] ] now , to analyze the first probability in , split it according to how many summands are greater than @xmath220 as follows : @xmath257 we start by analyzing , which we can bound by separating the summands in @xmath140 into those that are smaller than or equal to @xmath220 and those that are greater than @xmath220 , as the following derivation shows , @xmath258 we can bound similarly to obtain @xmath259 clearly , is not greater than , and to bound we use lemma [ l.strongtrunc ] to obtain @xmath260 for any @xmath213 ( in particular , @xmath261 ) .    by lemma [ l.secondmax ]",
    "we have that is bounded by @xmath262   .\\ ] ]    finally , by lemma [ l.intertrunc ] , is bounded by @xmath263 this completes the case .",
    "* case 2 : * @xmath252 .",
    "the case of negative mean requires some additional work , since in order to use the preliminary lemmas we need to have some control over @xmath11 . for this purpose let @xmath264 and define @xmath265 . now split the probability of interest as follows : @xmath266 and note that the probabilities in are bounded by and . for the remaining probability we use the union bound to obtain @xmath267 since @xmath268 and @xmath269 ,",
    "is bounded by @xmath270 we now split this last probability in a similar way to the previous case : @xmath271    by using the same arguments from the case @xmath232 , we obtain that the sum of the probabilities in and is bounded by @xmath272 which by lemma [ l.truncbound ] ( with @xmath217 , @xmath215 , @xmath273 $ ] , and @xmath274 ) is in turn bounded by @xmath275   \\leq 2 e^{-\\theta \\delta x }   , \\ ] ] for sufficiently large @xmath65 and @xmath276 .",
    "we now note that since @xmath277 , then @xmath278 as @xmath8 . by adapting the proof of lemma [ l.secondmax ] to substitute @xmath20 by @xmath112 but keeping the condition @xmath279",
    ", we obtain that is bounded by @xmath280 \\leq \\frac{k(\\log x)^{1+\\epsilon}}{x^{\\epsilon\\nu } } e\\left [ \\indicator(i_n(w ) = 0 ) \\sum_{i=1}^n \\overline{f}(y / c_i ) \\right ] .\\ ] ]    finally , to analyze let @xmath281 , @xmath282 , and note that we can write the probability as @xmath283 applying lemma [ l.truncbound ] ( with @xmath217 , @xmath284 , and @xmath285 ) gives that is bounded by @xmath286 \\leq e^{-\\phi(1+|\\mu|\\kappa/2)x},\\ ] ] for sufficiently large @xmath65 , where @xmath287 .",
    "the last step is to note that @xmath288 as @xmath8 , which implies that is @xmath289 .",
    "this completes the proof .",
    "we give in this section lower bounds for the tail distribution of the randomly weighted and randomly stopped sum .",
    "the idea of the proof is to split the probability @xmath290 into several different probabilities , similarly to what was done for the upper bounds , and just keep those that determine the asymptotics .",
    "the first lemma is a preliminary step for lemma [ l.maxlowerbound ] , and the main lower bounds are given in lemmas  [ l.maxlowerbound ] and [ l.zlarge ] .",
    "[ l.maxasym ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath199 for some @xmath15 .",
    "let @xmath200 , @xmath201 , @xmath202 and @xmath291 .",
    "then , there exist constants @xmath203 such that for all @xmath204 , @xmath292   \\\\ & \\hspace{5 mm } -    \\frac{k}{x^{\\nu\\epsilon } \\log x } e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right )",
    "\\sum_{i=1}^n \\overline{f}(x/ c_i )    \\right ] .",
    "\\end{aligned}\\ ] ]    let @xmath293 and note that the @xmath294 s are disjoint .",
    "therefore , @xmath295 = e\\left [   \\sum_{i=1}^n \\indicator\\left ( b_i \\right ) \\right].\\end{aligned}\\ ] ] let @xmath206 and use the independence of the @xmath3 and @xmath208 to obtain @xmath296 \\\\ & = e\\left [   \\indicator \\left ( z_n \\leq y , \\ , i_n(w ) = 0 \\right ) \\sum_{i=1}^n e \\left [ \\left .",
    "\\indicator\\left ( c_i x_i > ( 1+\\delta ) x \\right ) \\indicator \\left ( \\sup_{1\\leq j < n+1 , j \\neq i } c_j x_j \\leq ( 1+\\delta)x \\right )   \\right| \\mathcal{f } \\right ] \\right ] \\\\ & = e\\left [   \\indicator \\left ( z_n \\leq y , \\ , i_n(w ) = 0 \\right ) \\sum_{i=1}^n e \\left [ \\left .",
    "\\indicator \\left ( c_i x_i > ( 1+\\delta ) x \\right )   \\right| \\mathcal{f } \\right ]    \\right ] \\\\ & \\hspace{5 mm } - e\\left [   \\indicator \\left ( z_n \\leq y , \\ , i_n(w ) = 0 \\right ) \\sum_{i=1}^n e \\left [ \\left .",
    "\\indicator\\left ( c_i x_i > ( 1+\\delta ) x \\right ) \\indicator \\left ( \\sup_{1\\leq j < n+1 , j \\neq i } c_j x_j > ( 1+\\delta)x \\right )   \\right| \\mathcal{f } \\right ] \\right ] \\\\ & \\geq   e\\left [    \\indicator \\left ( z_n \\leq y , \\ , i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}((1+\\delta)x/ c_i )   \\right ] \\\\ & \\hspace{5 mm } - e\\left [   \\indicator \\left ( z_n \\leq y , \\ , i_n(w ) = 0 \\right ) \\sum_{1",
    "\\leq i \\neq j < n+1 }   e \\left [ \\left .   \\indicator\\left ( c_i x_i > ( 1+\\delta ) x \\right )    \\indicator \\left ( c_j x_j > ( 1+\\delta)x \\right )   \\right| \\mathcal{f } \\right ] \\right],\\end{aligned}\\ ] ] where in the last step we used the union bound . to bound the last expectation note that the conditional independence of the @xmath50 given @xmath208 gives @xmath297 \\right ] \\\\ & \\leq e\\left [   \\indicator \\left ( z_n \\leq y , \\ , i_n(w ) = 0 \\right ) \\left ( \\sum_{i=1}^n \\overline{f}((1+\\delta)x/ c_i )   \\right)^2 \\right].\\end{aligned}\\ ] ] now use the same arguments from lemma [ l.secondmax ] to see that this last term is bounded from above by @xmath298 \\leq \\frac{k } { x^{\\nu \\epsilon } \\log x }   e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n",
    "\\overline{f}(x/ c_i )   \\right].\\end{aligned}\\ ] ]    the following result provides the first of the two terms determining the asymptotic behavior of @xmath290 , the one corresponding to the one - big - jump principle .",
    "lemma [ l.zlarge ] will give the term corresponding to the case where the sum of the weights , @xmath11 , is large .",
    "[ l.maxlowerbound ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath199 for some @xmath15 .",
    "let @xmath200 , @xmath201 , @xmath202 and @xmath211 .",
    "then , for any @xmath213 , there exist constants @xmath203 such that for all @xmath204 , @xmath299 \\\\ & \\hspace{5 mm } - k\\left ( \\frac{(\\log x)^\\epsilon}{x^{\\nu\\epsilon } } e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}(x/ c_i ) \\right ] + \\frac{1}{x^{h } } \\right).\\end{aligned}\\ ] ]    we start by noting that @xmath300 from lemma [ l.maxasym ] we obtain that is greater than or equal to @xmath301   -    \\frac{k}{x^{\\nu\\epsilon } \\log x } e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}(x/ c_i )   \\right ] .\\ ] ]    to bound note that @xmath302 now let @xmath303 and use the union bound plus the conditional independence of the @xmath50 given @xmath208 to obtain @xmath304 \\right ] \\\\ &",
    "\\leq e\\left [ \\indicator(z_n \\leq y , \\ , i_n(w ) = 0 ) \\sum_{1 \\leq i \\neq",
    "j < n+1 } \\overline{f}((1+\\delta)x/ c_i ) f(-y / c_j ) \\right ] \\\\ & \\leq e\\left [ \\indicator(z_n \\leq y , \\ , i_n(w ) = 0 ) \\left ( \\sum_{i = 1}^n \\overline{f}((1+\\delta)x/ c_i ) \\right ) \\left ( \\sum_{j=1}^n f(-y / c_j ) \\right ) \\right ] .\\end{aligned}\\ ] ] the same arguments from lemma [ l.secondmax ] now give that the last expectation is bounded by @xmath305 \\leq \\frac{k ( \\log x)^\\epsilon } { x^{\\nu\\epsilon } } e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i = 1}^n \\overline{f}(x/ c_i )   \\right ] .\\end{aligned}\\ ] ]    finally , to bound note that @xmath306 from where it follows that @xmath307 now apply lemma [ l.strongtrunc ] with @xmath308 replaced by @xmath309 to obtain that @xmath310 as @xmath8 for all @xmath213 .",
    "combining the bounds derived above for , and gives the result .",
    "[ l.zlarge ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] with @xmath199 for some @xmath15 .",
    "in addition assume that @xmath311 a.s . and",
    "@xmath248 < \\infty$ ] for some @xmath249 .",
    "let @xmath253 , @xmath201 and @xmath312 .",
    "then , there exist constants @xmath203 such that for all @xmath204 , @xmath313    we start by noting that @xmath314 from we obtain @xmath315 now let @xmath316 , @xmath317 , @xmath318 , and @xmath319 .",
    "note that @xmath320 to analyze define @xmath321 and note that is bounded by @xmath322 by lemma [ l.truncbound ] with @xmath323 , @xmath217 and @xmath324 $ ] , is bounded by @xmath325 \\\\",
    "& \\leq e^{-\\theta \\delta x + \\frac{4k ||\\overline{x}_1||_{1+\\epsilon}}{\\mu \\log(x^\\nu ) } \\theta x } p(z_n >",
    "x/\\mu ) \\\\ & \\leq k e^{-\\epsilon\\nu\\sqrt{\\log x } } p(z_n > x/\\mu),\\end{aligned}\\ ] ] where @xmath326 .",
    "to analyze let @xmath206 and use the union bound to see that it is bounded by @xmath327 \\right ] \\notag \\\\ & \\leq e\\left [ \\indicator ( ( 1+\\delta)x/\\mu < z_n \\leq 4x/\\mu , \\ , i_n(w ) = 0 ) \\sum_{i=1}^n e\\left [ \\left .",
    "\\indicator(c_i \\overline{x}_i > x ) \\right| c_i \\right ] \\right ] \\notag \\\\ & \\leq \\frac{e[|\\overline{x}_1|^{1+\\epsilon}]}{x^{1+\\epsilon } }   e\\left [ \\indicator ( ( 1+\\delta)x/\\mu < z_n \\leq 4x/\\mu , \\ , i_n(w ) = 0 ) \\sum_{i=1}^n c_i^{1+\\epsilon } \\right ] \\label{eq : intermediatestep } \\\\ & \\leq \\frac{k w^\\epsilon}{x^{1+\\epsilon } } e\\left [ \\indicator ( ( 1+\\delta)x/\\mu < z_n \\leq 4x/\\mu ) z_n \\right ]   \\notag \\\\ & \\leq \\frac{k}{x^{\\nu\\epsilon } } p(z_n > x/\\mu ) .",
    "\\notag\\end{aligned}\\ ] ] now , to analyze define @xmath328 and split the probability into @xmath329 the same steps used to derive give that is bounded by @xmath330 e\\left [ \\indicator(z_n > 4x/\\mu , \\ ,",
    "i_n(w ) = 0 ) ( \\mu z_n)^{-1-\\epsilon } \\sum_{i=1}^n c_i^{1+\\epsilon } \\right ] \\\\ &",
    "\\leq k w^\\epsilon e\\left [ \\indicator(z_n > 4x/\\mu ) z_n^{-\\epsilon } \\right ] \\leq \\frac{k}{x^{\\nu\\epsilon } } p(z_n > 4x/\\mu ) .",
    "\\end{aligned}\\ ] ] finally , to bound we can repeat the proof of lemma [ l.truncbound ] , with the difference that @xmath11 now appears in the truncation and the level to be exceeded . set @xmath331 , @xmath217 , @xmath332 , @xmath333 , and note that on the set @xmath334 we have @xmath335 for sufficiently large @xmath65 , as required .",
    "now , the same proof of lemma [ l.truncbound ] gives that is bounded , for sufficiently large @xmath65 , by @xmath336 & \\leq e\\left",
    "[ \\indicator(z_n > 4x/\\mu ) e^{-\\theta ( \\mu z_n/2-x ) } \\right ] .\\end{aligned}\\ ] ] now note that on @xmath334 we have @xmath337 which shows that is bounded by @xmath338 .",
    "this completes the proof .",
    "in this section we give the proofs of the theorems in section [ s.main ] .",
    "we start by stating two preliminary lemmas . lemma [",
    "l.potter ] is included only for completeness since part ( a ) is a direct consequence of the representation theorem for the @xmath339 class , theorem 2.2.7 in @xcite , and part ( b ) is contained in theorem 2.3 in @xcite .",
    "[ l.potter ] suppose that @xmath340 with matuszewska indices @xmath86 .",
    "then , for any @xmath15 ,    1 .",
    "there exists @xmath341 such that @xmath342 for all @xmath204 .",
    "2 .   there exist @xmath341 and @xmath343 such that for all @xmath344 and @xmath204 , @xmath345    the second preliminary lemma below establishes the one - big - jump asymptotics for the random weighted sum using the properties of the ir class .",
    "[ l.summandsasym ] suppose the @xmath3 and the vector @xmath2 satisfy assumption [ a.main ] .",
    "assume further that @xmath85 and has matuszewska indices @xmath86 , and that @xmath311 a.s . , @xmath346 < \\infty$ ] and @xmath96 < \\infty$ ] for some @xmath88 .",
    "if @xmath91 < \\infty$ ] then the condition @xmath346",
    "< \\infty$ ] can be dropped .",
    "let @xmath347 , @xmath348 , @xmath349 , @xmath202 and @xmath350 , then , as @xmath8 , @xmath351 & \\sim e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}((1-\\delta)x/ c_i ) \\right ]   \\triangleq \\mathbf{u } \\\\ & \\sim e\\left [    \\indicator \\left ( z_n \\leq y , \\ , i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}((1+\\delta)x/ c_i )   \\right ]   \\triangleq \\mathbf{l}.\\end{aligned}\\ ] ]    we start with the upper bounds , @xmath352 \\\\",
    "& \\leq   \\sup_{t \\geq x / w } \\frac{\\overline{f}((1-\\delta)t)}{\\overline{f}(t ) } \\ , \\mathbf{r},\\end{aligned}\\ ] ] and @xmath353 .",
    "it follows that @xmath354    now , for the lower bounds we have @xmath355\\end{aligned}\\ ] ] and @xmath356 \\\\ & \\hspace{5 mm } - e\\left [ \\indicator \\left ( z_n > y , \\ , i_n(w ) = 0\\right ) \\sum_{i=1}^n \\overline{f}(x/ c_i )   \\right ] \\\\ & \\geq \\inf_{t \\geq x / w } \\frac{\\overline{f}((1+\\delta)t ) } { \\overline{f}(t ) } \\left ( \\mathbf{r } - e\\left [ \\indicator\\left(i_n(w ) \\geq 1\\right ) \\sum_{i=1}^n \\overline{f}(x/ c_i ) \\right ] \\right ) \\\\ & \\hspace{5 mm } - e\\left [ \\indicator\\left ( z_n > y , \\ , i_n(w ) = 0 \\right ) \\sum_{i=1}^n",
    "\\overline{f}(x/ c_i ) \\right].\\end{aligned}\\ ] ] it remains to show that @xmath357 + e\\left [ \\indicator\\left(z_n > y , i_n(w ) = 0\\right ) \\sum_{i=1}^n \\overline{f}(x/ c_i )   \\right ] } { \\mathbf{r } } = 0 .\\ ] ] to obtain a lower bound for @xmath358 we use lemma [ l.potter ] ( b ) and fatou s lemma as follows , @xmath359   \\geq k e\\left [ \\sum_{i=1}^n c_i^{\\alpha_f-\\epsilon } \\wedge c_i^{\\beta_f+\\epsilon } \\right ] > 0.\\ ] ] thus , it suffices to prove that @xmath360 =   \\lim_{x \\to \\infty } e\\left [ \\indicator\\left(z_n > y , i_n(w ) = 0\\right ) \\sum_{i=1}^n \\frac{\\overline{f}(x/ c_i)}{\\overline{f}(x ) }    \\right ] = 0 .\\ ] ] we analyze the second limit by noting that by lemma [ l.potter ] ( b ) , we have that for all sufficiently large @xmath65 , @xmath361 & \\leq k e\\left [ \\sum_{i=1}^n c_i^{\\alpha_f-\\epsilon } \\vee c_i^{\\beta_f+\\epsilon }   \\right ]   \\\\ & \\leq k e\\left [ \\sum_{i=1}^n c_i^{\\alpha_f-\\epsilon } \\right ]   + k e\\left [ \\sum_{i=1}^n c_i^{\\beta_f+\\epsilon } \\right ] < \\infty,\\end{aligned}\\ ] ] so by dominated convergence , @xmath362 \\notag \\\\ & \\leq   k e\\left [ \\limsup_{x \\to \\infty } \\indicator\\left(z_n > y \\right ) \\sum_{i=1}^n c_i^{\\alpha_f-\\epsilon } \\vee c_i^{\\beta_f + \\epsilon }   \\right ] = 0 .",
    "\\label{eq : momentcondition}\\end{aligned}\\ ] ] for the first limit in we first split the expectation to obtain @xmath363 & \\leq e\\left [ \\indicator\\left(i_n(w ) \\geq 1\\right ) \\sum_{i=1}^n \\frac{\\overline{f}(x/ c_i)}{\\overline{f}(x ) }   \\indicator(c_i \\leq w )   \\right ] \\label{eq : largebdc } \\\\ & \\hspace{5 mm } + e\\left [ \\indicator\\left(i_n(w ) \\geq 1\\right ) \\sum_{i=1}^n \\frac{\\indicator(c_i > w)}{\\overline{f}(x ) }    \\right ] .\\notag\\end{aligned}\\ ] ] dominated convergence again gives @xmath364 \\\\",
    "& \\leq k e\\left",
    "[ \\limsup_{x \\to \\infty } \\indicator\\left(i_n(w ) \\geq 1\\right ) \\sum_{i=1}^n c_i^{\\alpha_f-\\epsilon } \\vee c_i^{\\beta_f+\\epsilon }   \\right ] = 0.\\end{aligned}\\ ] ] finally , to bound note that by , @xmath365 \\leq e\\left [ \\sum_{i=1}^n \\indicator\\left ( c_i > w \\right ) \\right ] \\leq \\frac{k}{x^{\\beta_f+\\epsilon/2}}.\\ ] ] the observation that by lemma [ l.potter ] ( a ) @xmath366 completes the proof .",
    "* remark : * the proof given above requires that @xmath367 < \\infty$ ] to derive , which is clearly implied by the two conditions @xmath89 < \\infty$ ] and @xmath96 < \\infty$ ] . to see that the first condition can be dropped when @xmath91 < \\infty$ ] note that @xmath368 \\leq e[n ] + e\\left [ \\sum_{i=1}^n c_i^{\\beta_f+\\epsilon } \\right ] < \\infty.\\ ] ]    we are now ready to prove the main theorems from section [ s.main ] .",
    "the first result corresponds to the setting where the asymptotic behavior of both @xmath197 and @xmath290 is determined by the one - big - jump principle .",
    "let @xmath369 , @xmath370 , and @xmath371 $ ] .",
    "note that by we have that @xmath372 , and by lemma [ l.potter ] ( a ) we have that @xmath373 for any @xmath213 , from where it follows that @xmath374 as @xmath8 .",
    "let @xmath253 , @xmath201 , @xmath202 , and @xmath350 .",
    "then , from lemmas [ l.maxlowerbound ] and [ l.summandsasym ] we obtain , for all three cases , that @xmath375    for the upper bound we first note that by lemma [ l.potter ] ( b ) , @xmath376 \\notag   \\\\ & \\leq \\frac{(\\log x)^{1+\\epsilon } } { x^{\\epsilon\\nu } } e\\left [   \\indicator\\left ( i_n(w ) = 0 \\right )   \\sum_{i = 1}^n k ( y / x)^{-\\beta-\\epsilon } \\overline{f}(x/ c_i )   \\right ] \\notag \\\\ & \\leq   \\frac{k(\\log x)^{\\beta+1 + 2\\epsilon } } { x^{\\epsilon\\nu } } \\cdot \\mathbf{r } = o\\left(\\mathbf{r } \\right ) , \\label{eq : littleo2}\\end{aligned}\\ ] ] for all sufficiently large @xmath65 . we split the rest of the analysis of the upper bounds into the three different cases",
    ".    * case 1 : * @xmath252 .",
    "it follows from proposition [ p.upperbounds ] ( b ) , lemma [ l.summandsasym ] , and relations and , that @xmath377    * case 2 : * @xmath239 and @xmath378 .",
    "we use proposition [ p.upperbounds ] ( a ) , lemma [ l.summandsasym ] , and relations and to obtain @xmath379 to see that the last limit is zero use lemma [ l.potter ] to obtain @xmath380    * case 3 : * @xmath241 and @xmath381 .",
    "we use proposition [ p.upperbounds ] ( a ) , lemma [ l.summandsasym ] , and relations and to obtain @xmath382 for the first summand in the limit we use lemma [ l.potter ] to see that @xmath383 for the second limit we use lemma [ l.potter ] again as follows : @xmath384    the next proof corresponds to the setting where the asymptotic behavior of @xmath197 and @xmath290 is determined by both the one - big - jump principle and the tail behavior of @xmath11 .",
    "let @xmath369 , @xmath370 , and @xmath385 $ ] .",
    "note that by we have that @xmath372 , and by lemma [ l.potter ] ( a ) we have that @xmath373 for any @xmath213 , from where it follows that @xmath386 as @xmath8 .",
    "let @xmath253 , @xmath201 , @xmath202 , and @xmath350 .",
    "note that since @xmath11 is @xmath387 , @xmath388 as @xmath8 .",
    "also , since @xmath389 , it holds that @xmath390 moreover , if we let @xmath391 be the lower matuszewska index of @xmath392 , then lemma  [ l.potter ] ( b ) gives @xmath393 these observations combined with proposition [ p.upperbounds ] ( a ) , lemma [ l.summandsasym ] , and relations and , give @xmath394    for the lower bound we use @xmath395 , lemmas [ l.maxlowerbound ] , [ l.zlarge ] and [ l.summandsasym ] , and relations and to obtain @xmath396 this completes the proof .",
    "the last proof corresponds to the setting where the tail behavior of @xmath197 and @xmath290 is solely determined by the sum of the weights , @xmath11 .",
    "let @xmath397 , @xmath398 , @xmath253 , @xmath201 , @xmath202 , and @xmath350 .",
    "recall that @xmath128 and @xmath392 .    note that since @xmath115 , then @xmath399 as @xmath8 .",
    "we start with the upper bound , for which we use proposition [ p.upperbounds ] ( a ) to obtain @xmath400 \\right .",
    "\\\\ & \\hspace{20 mm } \\left .",
    "+ \\frac{(\\log x)^{1+\\epsilon}}{x^{\\epsilon\\nu } } e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}(y / c_i ) \\right ]   + \\frac{1}{x^{\\beta+\\epsilon/2 } } \\right .",
    "\\\\ & \\hspace{12 mm } \\left .",
    "\\phantom{\\left [ \\sum_i^n \\right . } + x^{-\\epsilon\\nu/2 } p(z_n > y ) +   e^{-\\frac{\\epsilon\\nu\\sqrt{\\log x}}{\\mu } } p(z_n > x/(2\\mu ) )   \\right\\}.\\end{aligned}\\ ] ] since the distribution of @xmath11 belongs to @xmath389 , then @xmath401 by lemma  [ l.potter ]  ( a ) . also , by the same arguments used in the proof of theorem [ t.both ] , @xmath402 for the two remaining terms we use lemma [ l.potter ] to obtain , for sufficiently large @xmath65 , @xmath403   + \\frac{(\\log x)^{1+\\epsilon}}{x^{\\epsilon\\nu } } e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\overline{f}(y / c_i ) \\right ]     \\right\\ } \\\\ & \\leq \\sup_{t \\geq y / w } \\frac{\\overline{f}(t)}{\\overline{g}(t ) } \\left\\ { e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\frac{\\overline{g}((1-\\delta)x / c_i)}{\\overline{g}(x/\\mu ) }   \\right ] +   \\frac{(\\log x)^{1+\\epsilon}}{x^{\\epsilon\\nu } } e\\left [ \\indicator\\left ( i_n(w ) = 0 \\right ) \\sum_{i=1}^n \\frac{\\overline{g}(y / c_i)}{\\overline{g}(x/\\mu ) } \\right ]   \\right\\ } \\\\ & \\leq   \\sup_{t \\geq y / w } \\frac{\\overline{f}(t)}{\\overline{g}(t ) } \\left\\ { e\\left [ k   \\sum_{i=1}^n \\left ( \\frac{c_i}{(1-\\delta)\\mu } \\right)^{\\alpha-\\epsilon } \\vee \\left ( \\frac{c_i}{(1-\\delta)\\mu } \\right)^{\\beta+\\epsilon }      \\right ] \\right .",
    "\\\\ & \\hspace{35 mm } \\left .",
    "+   \\frac{(\\log x)^{1+\\epsilon}}{x^{\\epsilon\\nu } } e\\left [   k \\sum_{i=1}^n",
    "\\left ( \\frac{c_i x}{\\mu y } \\right)^{\\alpha-\\epsilon } \\vee \\left ( \\frac{c_i x}{\\mu y } \\right)^{\\beta+\\epsilon }      \\right ]   \\right\\ } \\\\ & \\leq k   \\sup_{t \\geq y / w } \\frac{\\overline{f}(t)}{\\overline{g}(t ) } \\left\\ { 1   +   \\frac{(\\log x)^{\\beta+1 + 2\\epsilon}}{x^{\\epsilon\\nu } } \\right\\ } \\leq k   \\sup_{t \\geq y / w } \\frac{\\overline{f}(t)}{\\overline{g}(t ) }   . \\end{aligned}\\ ] ] since @xmath404 as @xmath8 , we have @xmath405 .",
    "the expectation preceding the supremum is finite either if @xmath406 < \\infty$ ] and @xmath248 < \\infty$ ] , or if @xmath91 < \\infty$ ] and @xmath248 < \\infty$ ] ( see the remark following the proof of lemma [ l.summandsasym ] ) .    for the lower",
    "bound we use @xmath395 and lemma [ l.zlarge ] to obtain @xmath407 this completes the proof .",
    "the author would like to thank an anonymous referee for his / her thorough reading of the paper and helpful comments .",
    "this work was supported by nsf grant cmmi-1131053 ."
  ],
  "abstract_text": [
    "<S> let @xmath0 be a sequence of independent identically distributed random variables with an intermediate regularly varying ( ir ) right tail @xmath1 . </S>",
    "<S> let @xmath2 be a nonnegative random vector independent of the @xmath3 with @xmath4 . </S>",
    "<S> we study the weighted random sum @xmath5 , and its maximum , @xmath6 . </S>",
    "<S> this type of sums appear in the analysis of stochastic recursions , including weighted branching processes and autoregressive processes . </S>",
    "<S> in particular , we derive conditions under which @xmath7,\\ ] ] as @xmath8 . </S>",
    "<S> when @xmath9 > 0 $ ] and the distribution of @xmath10 is also ir , we obtain the asymptotics @xmath7 + p(z_n > x / e[x_1]).\\ ] ] for completeness , when the distribution of @xmath11 is ir and heavier than @xmath1 , we also obtain conditions under which the asymptotic relations @xmath12)\\ ] ] hold . </S>"
  ]
}