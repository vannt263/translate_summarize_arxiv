{
  "article_text": [
    "we consider the detection of edges in piecewise smooth data from its fourier projection , @xmath7 our approach is based on the technique of _ concentration kernels _ advocated in @xcite and the closely related techniques described in @xcite .",
    "the technique presented makes use of the fact that if @xmath8 is discontinuous , its fourier coefficients contain a slowly decaying part associated with the jumps of @xmath8 .",
    "this part decays much more slowly than the rapidly decaying smooth part of @xmath8 . for example , if @xmath8 is smooth except for a single jump discontinuity at @xmath9 of size @xmath10(z):=f(z+)-f(z-)$ ] , the jump discontinuity is associated with slowly decaying fourier coefficients , @xmath11(\\z)\\frac{e^{-ik\\z}}{2\\pi ik } + \\hatgk , \\qquad |\\hatgk| \\lesssim \\frac{1}{|k|^2 } , \\quad [ f](x):=f(x+)-f(x-),\\ ] ] where @xmath12 are the fourier coefficients of @xmath13  the smooth part of @xmath8 ; the smoother @xmath13 is , the faster is the decay of @xmath12 .",
    "concentration kernels succeed in separating the two sets of coefficients . to this end one",
    "computes @xmath14 here , @xmath15 can be drawn from a large family of properly normalized concentration factors that are at our disposal .",
    "the resulting function tends to zero in regions in which @xmath8 is smooth and tends to the amplitude of the jumps at points where the function has a jump discontinuity , @xmath16(x ) + { \\mathcal o}\\big(\\frac{\\log n}{n}\\big).\\ ] ] thus , edges are detected by _",
    "separation of scales_.    in this paper we utilize concentration kernels to detect edges from spectral information which is corrupted by _",
    "white noise_. in this context we observe that there are three scales involved  edges of order @xmath3 , noise with variance @xmath17 and the smooth part of @xmath8 which is resolved within order @xmath18 or smaller . here , we can separate the noisy part , @xmath19 , from the smooth part , @xmath20 if @xmath21 then the noisy part could be identified with ( or below ) the @xmath18-variation of the smooth part of @xmath8 . in this case , there are essentially two scales and edges can be detected using the usual framework of concentration kernels advocated in @xcite .",
    "thus , our main focus in this paper is when the smoothness scale is dominated by the scale of the noise which is still well - separated from the @xmath3-scale of the jumps , @xmath22 the spectral information is now corrupted by white noise , affecting both low and high frequencies , @xmath11(\\z)\\frac{e^{-ik\\z}}{2\\pi ik } + \\hatgk + \\hatnk\\ ] ] in order to separate edges from the noisy scale , the edge detector , @xmath23 , must be properly adapted to the presence of white noise .",
    "we show how to design edge detectors that optimally compensate for noise and for the effects of the smooth part of the signal .",
    "the paper is organized as follows . in section [ sec : concentration ]",
    "we discuss the general framework of edge detection based on concentration kernels .",
    "we revisit the results of @xcite , providing a simpler proof for the concentration property for a large family of concentration factors .",
    "in particular , we trace the precise dependence of the error on the regularity of the associated concentration factor .",
    "this will prove useful when we deal with noisy data in section [ sec : perspective ] . here",
    ", we introduce our new perspective , where concentration factors are derived by a constrained minimization while taking into account the two main ingredients of our data  jump discontinuities and the noisy parts of the data .",
    "numerical results are demonstrated in sections [ sec : numericsi ] . in section [ sec : revisited ] we extend our construction of concentration factors to include the _ three _ ingredients of the data  taking into account the smooth part of the data in addition to the edges and noisy parts ; numerical results are presented in [ sec : numericsii ] .",
    "consider an @xmath8 which is _ piecewise smooth _ in the sense that it is sufficiently smooth except for finitely many jump discontinuities , say at @xmath24 , where @xmath25(\\z_j):=f(\\z_j+)-f(\\z_j- ) \\neq 0 , \\quad j=1,2 , \\ldots j.\\ ] ] given the fourier coefficients , @xmath26 , we are interested in detecting the edges of the underlying piecewise smooth @xmath8 , namely , to detect their location , @xmath27 and their amplitudes , @xmath10(\\z_1 ) , \\ldots , [ f](\\z_j)$ ] .",
    "we utilize edge detection based on _ concentration kernels _    [ eqs : kns ] @xmath28.\\ ] ]    we shall need the kernel @xmath29 to have ( approximately ) unit mass , @xmath30 to this end , we require that @xmath31 be a properly normalized concentration factor ; that @xmath32 satisfy @xmath33    indeed , the rectangular quadrature rule yields @xmath34 with an error estimate , e.g. , @xcite , @xmath35 we set @xmath36 our purpose is to choose the _ concentration factors _ , @xmath37 , such that @xmath38(x)$ ] . thus , @xmath23 will detect the edges , @xmath10(\\z_j ) , \\",
    "j=1,\\ldots , j$ ] , by concentrating near these @xmath3-edges which are to be separated from a much smaller scale of order @xmath39 in regions of smoothness . in the following theorem",
    "we present a rather general framework for edge detectors based on concentration factors .",
    "in particular , we track the precise dependence of the scale separation on the behavior of @xmath40 .",
    "[ thm : concentration ] assume that @xmath41 is piecewise smooth such that the first - variation of @xmath8 is of locally bounded variation , @xmath42(x)}{\\sin(y/2 ) } \\in bv[-\\pi,\\pi].\\ ] ] let @xmath43 be an admissible concentration kernel ( [ eqs : kns ] ) , such that    [ eqs : bounds ] @xmath44    set @xmath45 then , the conjugate sum @xmath23 , @xmath46 satisfies the concentration property , @xmath47(\\z_j ) + { \\mathcal o}\\big ( \\eps_n\\big ) ,   & x\\sim \\z_j , \\ j=1,\\ldots , j\\\\ \\\\   { \\mathcal o}\\big(\\eps_n\\big ) , &",
    "dist\\big\\{x , \\{\\z_1 , \\ldots , \\z_j\\}\\big\\ } \\gg \\eps_n . \\end{array } \\right.\\ ] ]    we simplify the proof in @xcite .",
    "the key to the proof is to observe that @xmath48 is an appropriately normalized _ derivative _ of the delta function ; in particular , since @xmath49 is odd @xmath50(x)\\big)dy -[f](x)\\times \\int_0^{\\pi}\\sknsx(y)dy . \\end{aligned}\\ ] ] since @xmath40 is assumed normalized , the error estimate ( [ eq : quad ] ) tells us @xmath51 and we end up with the error estimate @xmath52(x)\\big| \\lesssim \\big|\\int_0^{\\pi}\\sin(y/2)\\sknsx(y)\\omega_f(y;x)dy\\big| + { \\mathcal o}\\left(\\eps_0(n)\\right).\\ ] ] to upperbound the expression on the right , we sum by parts , deriving the identity @xmath53 the usual cancelation estimate , @xmath54 , implies @xmath55 we conclude @xmath56 the result ( [ eq : edgedetect ] ) follows from ( [ eq : derr ] ) and ( [ eq : ded ] ) .    as an example , we consider the noise - free case with a concentration factor for which @xmath57 clearly @xmath58 , and since @xmath40 is bounded , @xmath59 .",
    "moreover , since @xmath60 is bounded , @xmath61 finally , since @xmath62 then @xmath63 .",
    "theorem [ thm : concentration ] yields the following result of @xcite for edge detection in piecewise - smooth , noiseless data .",
    "[ cor : concentration ] assume that @xmath41 is piecewise smooth such that ( [ eq : pw ] ) holds .",
    "let @xmath43 be a normalized concentration kernel ( [ eqs : kns ] ) with @xmath64 .",
    "then @xmath23 satisfies the concentration property with @xmath65 , @xmath66(\\z_j ) + { \\mathcal o}\\big ( { \\displaystyle \\frac{\\log(n)}{n } } \\big ) ,   & x\\sim \\z_j , \\ j=1,\\ldots , j\\\\ \\\\",
    "{ \\mathcal o}\\big({\\displaystyle \\frac{\\log(n)}{n}}\\big ) , & dist\\big\\{x , \\{\\z_1 , \\ldots , \\z_j\\}\\big\\ } \\gg { \\displaystyle \\frac{1}{n}}. \\end{array } \\right.\\ ] ]",
    "assume that @xmath8 experiences a single jump discontinuity at location @xmath67 of height @xmath10(\\z)$ ] .",
    "this dictates a first order decay of the fourier coefficients , @xmath68(\\z)\\frac{e^{-ik\\z}}{2\\pi ik } + \\hatgk + \\hatnk.\\ ] ] here , @xmath12 are associated with the regular part of @xmath8 after extracting the jump @xmath10(c)$ ] ; their decay is of order @xmath69 or faster , depending on the smoothness of the regular part @xmath70 .",
    "the new aspect of the problem enters through the @xmath71 s , which are the fourier coefficients of the noisy part corrupting the smooth part of the data .",
    "we assume @xmath72 to be white noise whose mean - square power at each frequency is @xmath73 . with ( [ eq : hatnk ] ) ,",
    "the conjugate sum ( [ eq : kns ] ) becomes @xmath74(\\z)\\times 2\\pi i\\sum_{k=1}^n \\frac{\\sigma_n\\big(\\frac{k}{n}\\big)}{k}\\cos k(x-\\z ) } \\\\ & &   - 2\\pi\\sum_{k=1}^n \\sigma\\big(\\frac{k}{n}\\big)\\hatgk \\sin kx - 2\\pi\\sum_{k=1}^n",
    "\\sigma\\big(\\frac{k}{n}\\big)\\hatnk\\sin kx.\\end{aligned}\\ ] ] we quantify the  energy \" of each of the three sums on the right .",
    "@xmath75 and @xmath76 are associated with the discontinuous and regular parts of @xmath8 ,    @xmath77    and @xmath78 associated with the noisy part of @xmath8 which was assumed to have variance @xmath2",
    "@xmath79    our perspective for construction of edge detectors for such noisy data is to treat the problem as a _ constrained minimization_. we seek a function , @xmath32 , which minimizes the total energy , thus making the conjugate sum @xmath80 as localized as possible , subject to prescribed normalization constraint ( [ eq : normalization ] ) , @xmath81 this yields @xmath82 we ignore the relatively negligible contribution of the regular part which becomes even smaller as @xmath70 becomes smoother . setting @xmath83 we end up with concentration factors of the form @xmath84    the corresponding concentration kernel depends",
    "only the _ relative _ size of the amplitudes @xmath85 : indeed , the normalization of @xmath86 ( [ eq : normalization ] ) causes the constant @xmath87 to satisfy @xmath88 and we end up with the _ normalized _ concentration factor @xmath89 the corresponding edge detector then takes the form @xmath90 the concentration factor @xmath91 now involves three factors : the ratio @xmath92 , the noise variance @xmath2 and the number of modes @xmath0 . the concentration kernel ( [ eq : nkernel - a ] ) tends to de - emphasize both the low frequencies which are  corrupted \" by the jump discontinuity(-ies ) and the high frequencies which are corrupted by the noise .",
    "different procedures yield different policies for the choice of @xmath93 ; one will be discussed in the next subsection .",
    "it is worth noting the essential dependence of @xmath94 on the variance of the noise @xmath2 .",
    "there are three scales involved  the small  smoothness \" of order @xmath95 , the noise scale of order @xmath96 and the @xmath3-scale of jump discontinuities .",
    "we distinguish between two cases .",
    "if @xmath97 so that @xmath98 , then the noise can be considered part of the smooth variation of @xmath8 and @xmath99 recovers the usual concentration factor for noise - free data . indeed , @xmath100 at the limit of @xmath101 . otherwise , when the @xmath18-smoothness scale is dominated by the @xmath17-noise scale in the sense that @xmath102 , in which we assume the noise to be still well - below the @xmath3-scale of the jumps , @xmath103 in this case , we can ignore the bounded factor @xmath104 , and we compute the small scale dictated by theorem [ thm : concentration ] .",
    "setting @xmath105 we find , @xmath106 and hence ( [ eqs : bounds ] ) holds with @xmath107 it is remarkable to see how the small scale of smoothness in the noiseless case , @xmath108 , is now replaced by the small scale of noise @xmath109 .",
    "we now appeal to ( [ eq : edgedetect ] ) : since @xmath6 , theorem [ thm : concentration ] implies that @xmath110 separates the @xmath3-scale of the edges from the noise scale of order @xmath111 .",
    "[ thm : noisy ] assume that @xmath41 is piecewise smooth in the sense that ( [ eq : pw ] ) holds . assume that its spectral data contains white noise with variance @xmath6 .",
    "let @xmath112 be a normalized concentration kernel ( [ eq : nkernel - a ] ) @xmath113 associated with the concentration factor @xmath114 we distinguish between two cases : + ( i ) if @xmath98 we set the small scale @xmath115 ; + ( ii ) if @xmath116 we set the small scale @xmath117 .",
    "then , @xmath118 satisfies the following concentration property , @xmath119(\\z_j ) + { \\mathcal o}\\big ( \\eps\\big ) ,   & x\\sim \\z_j , \\",
    "j=1,\\ldots , j\\\\ \\\\   { \\mathcal o}\\big(\\eps\\big ) , & dist\\big\\{x , \\{\\z_1 , \\ldots , \\z_j\\}\\big\\ } \\gg \\eps . \\end{array } \\right.\\ ] ]      in order to choose the free parameter @xmath92 , it is important to know how @xmath92 influences the error at the output of our edge detector .",
    "let us consider @xmath120 .",
    "we have seen that : @xmath121 as @xmath120 is approximately the expected value of the square of the contribution of the noise to the output of the edge detector ",
    "it is approximately the variance of the contribution of the noise , if we want to consider the _ size _ of the noise , we should consider something related to the standard deviation of the contribution .",
    "it is customary to bound the noise by some number of standard deviations  we will use two standard deviations .",
    "we define the _ effective size _ of the noise s contribution to be @xmath122    from the results of theorem [ thm : noisy ] we find that far from jump the contribution from the jump is of order @xmath123 .",
    "the _ effective _ size of this term is therefore @xmath124    let us minimize @xmath125 with respect to @xmath92 .",
    "we find that : @xmath126",
    "[ figs : noisy ]    to illustrate the results of the previous section , we present two sets of numerical results .",
    "we begin with the noiseless case , in figure [ fig : noiseless ] , where we set @xmath127 corresponding to equal weights for the errors due to the noise and the discontinuous parts of the signal .",
    "we plot the output of the concentration factor when a periodic function with a single jump continuity is used as the input .",
    "a simple examination of the results shows that the output is what we predicted .",
    "the output is one at the ( unit ) jump and is zero away from it .",
    "as @xmath2 gets smaller the value away from the jump tends to zero . considering the figure",
    ", we find that the ratio of the size in the continuous region is @xmath128 which is the ratio of the square root of the @xmath2s  as it should be .",
    "next , figure [ fig : noisy - data - a ] demonstrates the edge detected in noisy data using the concentration kernel ( [ eq : nkernel - a ] ) with the advocated @xmath129 .",
    "as an alternative approach to the @xmath130-minimization offered in section [ sec : perspective ] , we now replace the @xmath130-averaged \" effect of the regular part taken in ( [ eq : er ] ) , by the bv - like quantity    [ eq : bv ] @xmath131 where the regular part is sufficiently smooth that @xmath132    as in ( [ eq : minimization ] ) , we consider the constrained minimization    [ eq:2ndmin ] @xmath133 with @xmath134 , where @xmath135 and @xmath136 given by ( [ eq : ej ] ) and ( [ eq : en ] ) but with an alternative expression for the  energy \" of the regular part motivated by ( [ eq : bv ] ) : @xmath137    proceedings formally , the solution for the first variation of ( [ eq:2ndmin ] ) leads to @xmath138 we will show that the resulting optimal concentration factor is given by @xmath139 indeed , to justify the passage to ( [ eq : opt ] ) , one may consider a _",
    "regularized _ version of the variational statement ( [ eq:2ndmin ] ) , @xmath140 , where @xmath141 involves a _ mollified _ absolute value function : @xmath142 the solution of the corresponding regularized first variation yields the minimizer : @xmath143 thus , we end up with the optimal concentration factor , @xmath144 , @xmath145 and ( [ eq : opt ] ) is recovered by letting @xmath146 .",
    "clearly , the resulting optimal concentration factor is non - negative .    it remains to calculate the normalization factor , @xmath87 , for which @xmath147 the integral on the left is found to be @xmath148    we focus our attention on the `` noisy '' case when @xmath149 so that the fourth term on the right is negligible while the second term on the right is approximated by @xmath150 we end up with an approximated integral @xmath151 the balance between these two terms depends on the specific policy for @xmath92 and the detailed balance between @xmath152 and @xmath0 . our normalized concentration factor takes the form    [ eqs : sigeta ] @xmath153    we can simplify this concentration factor in several ways ; we mention two here .",
    "+ ( i ) when @xmath0 is large enough , we have @xmath154 yielding @xmath155 ( ii ) observe that @xmath94 is rapidly decreasing at @xmath156 with @xmath157 so @xmath94 can be set to zero for @xmath158 when @xmath0 is large enough . in order to properly normalize the resulting concentration factor @xmath0",
    "must be replaced by @xmath159 .",
    "this leads us to : @xmath160",
    "we consider two examples depicted in figure [ fig : smooth_noisy ] . in the first case",
    ", we have a noise of variance @xmath161 to be detected out of the first @xmath162 modes . with @xmath163 and by tuning @xmath164 and @xmath165",
    "we find @xmath166    in the second case , of noise variance @xmath167 which led us to the choice of @xmath168 ; setting @xmath169 and @xmath165 we have @xmath170 ( note that in calculating the constants we made use of the exact normalization factor @xmath87 . for our values of @xmath2 and @xmath92",
    "the value @xmath171 is not large enough to make the approximate value given in ( [ eq : sigetac ] ) useful . )",
    "note that even with a large amount of white noise and of smooth signal , the location of the jump discontinuity is still clear .",
    "when considering jumps `` corrupted '' by low frequency data , we avoid low frequency signals by not using low frequency data .",
    "this helps keep the smooth signal from corrupting our results . on the other hand , because the jump discontinuity has most of its energy at low frequencies as well , our technique will increase the noise s effect . comparing figures [ fig : noisy - data - a ] and [ fig : smooth_noisy ] , we find that the latter is not as clean as the former in the sub - figure where the strength of the noise is the same .",
    "99 r. archibald and a. gelb , `` reducing the effects of noise in image reconstruction , '' _",
    "j. of sci .",
    "_ , 17 ( 2002 ) , 167 - 180 .",
    "d. cruz - uribe and c. j. neugebauer , `` sharp error bounds for the trapezoidal rule and simpson s rule , '' j. ineq .",
    "pure appl .",
    "3(4 ) ( 2002 ) , article 49 .",
    "s. engelberg , `` edge detection using fourier coefficients , '' _ amm . math .",
    "monthly _ , to appear .",
    "a. gelb and e. tadmor , `` detection of edges in spectral data , '' _ appl .",
    "harmonic anal . _ 7 ( 1999 ) , 101 - 135 .",
    "a. gelb and e. tadmor , `` detection of edges in spectral data ii .",
    "nonlinear enhancement , '' _",
    "siam j. numer .",
    "_ 38 ( 2000 ) , 1389 - 1408 .",
    "g. polya and g. szego , `` problems and theorems in analysis '' , vol .",
    "i , springer verlag , new york , 1972 , e. tadmor ,",
    " filters , mollifiers and the computation of the gibbs phenomenon \" , to appear ."
  ],
  "abstract_text": [
    "<S> we consider the problem of detecting edges in piecewise smooth functions from their @xmath0-degree spectral content , which is assumed to be corrupted by noise . </S>",
    "<S> there are three scales involved : the  smoothness \" scale of order @xmath1 , the noise scale of order @xmath2 and the @xmath3 scale of the jump discontinuities . </S>",
    "<S> we use concentration factors which are adjusted to the noise variance , @xmath4 , in order to detect the underlying @xmath5-edges , which are separated from the noise scale , @xmath6 . </S>"
  ]
}