{
  "article_text": [
    "high - dimensional data are increasingly encountered in many applications of statistics such as bioinformatics , information technology , medical imaging , astronomy and financial studies . in recent years , there is a growing body of literature concerning inference on the first and second order properties of high dimensional data ; see @xcite among others .",
    "the validity of these procedures is generally established under independence amongst the data vectors , which can be quite restrictive for situations that involve temporally observed data .",
    "examples include spatial - temporal modeling @xcite and financial study of a large number of asset returns @xcite .",
    "although high dimensional statistics has witnessed unprecedented development , statistical inference for high dimensional time series remains largely untouched so far . in the conventional low dimensional setting , inference for time series data typically involves the direct estimation of the asymptotic covariance matrix , which is known to be difficult in the presence of heteroscedasticity and autocorrelation of unknown forms @xcite . in the high dimensional",
    "setting , where the dimension is comparable or even larger than sample size , the classical inferential procedures designed for the low dimensional case are no longer applicable , e.g. , the asymptotic covariance matrix is singular . along a different line , alternative nonparametric procedures including block bootstrap , subsampling and blockwise empirical likelihood @xcite",
    "have been proposed to avoid the direct estimation of covariance matrices .",
    "however , the extension of these procedures ( coupled with suitable testing procedures ) to the high dimensional setting remains unclear .",
    "one relevant high dimensional work ( @xcite ) we are aware is on the estimation rates of the covariance / precision matrices of time series .    in this paper",
    ", we establish a general framework of conducting bootstrap inference for high dimensional stationary time series under weak dependence .",
    "we start from three motivating examples that are mainly concerned with first or second order property of time series : ( 1 ) uniform confidence band for mean vector ; ( 2 ) testing for serial correlation ; ( 3 ) testing on the bandedness of covariance matrix .",
    "the proposed bootstrap procedures are rather simple to implement and supported by simulation results .",
    "we want to emphasize that neither gaussian assumption nor strong restrictions on the covariance structure are imposed in these applications .",
    "an important by - product of examples ( 2 ) and ( 3 ) is the covariance structure testing for high dimensional time series that even does not rely on the existence of the null limit distribution .",
    "this new result is in sharp contrast with the existing literature for i.i.d data such as @xcite .",
    "we also remark that the maximum - type testing procedure considered in these examples is expected to be particularly powerful for detecting sparse alternatives ( see @xcite ) .",
    "a comprehensive investigation along this line is left as our future topic .",
    "the underlying theory in supporting these high dimensional applications is a general gaussian approximation theory and its bootstrap version .",
    "the gaussian approximation theory quantifies the kolmogorov distance between the largest element of a sum of weakly dependent vectors and its gaussian analog that shares the same autocovariance structure .",
    "we develop our theory in the general framework of dependency graph , which leads to delicate bounds on the kolmogorov distance for various types of time series .",
    "the approximation error , which is finite sample valid , decreases polynomially in sample size even when the data dimension is exponentially high .",
    "moreover , we study two important dependence structures in more details : @xmath0-dependent time series and weakly dependent time series .",
    "although the sharpness of kolmogorov distance is not established in this paper , our theoretical results ( also see figure [ fig : interplay ] ) strongly indicate an interesting interplay between dependence and dimensionality : the less dependent of the data vectors , the faster diverging rate of the dimension is allowed for obtaining an accurate gaussian approximation .",
    "we also propose an interesting  dimension free \" dependence structure that allows the dimension to diverge at the rate as if the data were independent .",
    "however , in practice , the intrinsic dependence structure of time series is usually unknown .",
    "this motivates us to develop a bootstrap version of the gaussian approximation theory that does not require such knowledge .",
    "specifically , we propose a blockwise multiplier bootstrap that is able to capture the dependence amongst and within the data vectors .",
    "moreover , it inherits the high quality approximation without relying on the autocovariance information .",
    "we also introduce a non - overlapping block bootstrap as a more flexible alternative .",
    "the above theoretical results are major building blocks of a general framework of conducting bootstrap inference for high dimensional time series .",
    "this general framework assumes that the quantity of interest admits an approximately linear expansion , and thus covers the three examples mentioned above .",
    "this quantity of interest can be expressed as a functional of the distribution of the time series with finite or infinite length .",
    "hence , our result is also useful in making inference for the spectrum of time series .    our general gaussian approximation theory and its block bootstrap version",
    "substantially relax the independence assumption in @xcite , and is established using several techniques including the slepian interpolation @xcite , leave - one - block - out argument ( modification of stein s leave - one - out argument @xcite ) , self - normalization @xcite , weak dependence measure @xcite , and @xmath0-dependent approximation @xcite .",
    "it is worth pointing out that our results are established under the physical / functional dependence measure proposed in @xcite .",
    "this framework ( or its variants ) is known to be very general and easy to verify for linear and nonlinear data - generating mechanisms , and it also provides a convenient way for establishing large - sample theories for stationary causal processes @xcite .",
    "in particular , our work is largely inspired by a recent breakthrough in gaussian approximation for i.i.d data ( @xcite ) that obtained an astounding improvement over the previous results in @xcite by allowing the dimension of the data vectors to be exponentially larger than the sample size .",
    "the rest is organized as follows . in section [ sec : statappl ] , we describe three concrete bootstrap inference procedures mentioned above in details .",
    "section [ sec : maxima ] gives the gaussian approximation result that works even when the dimension is exponentially larger than sample size , and section [ sec : boot ] proposes the blockwise multiplier ( wild ) bootstrap and also the non - overlapping block bootstrap that do not depend on the autocovariance structure of time series .",
    "building on the results in sections  [ sec : maxima ] and  [ sec : boot ] , a general framework of conducting bootstrap inference based on approximately linear statistics is established in section [ sec : ts ] .",
    "three examples considered in [ sec : statappl ] and one spectral testing example are covered by this framework .",
    "all the proofs are gathered in the supplementary material .",
    "to motivate our general theory , we consider three concrete bootstrap inference procedures for high dimensional time series : uniform confidence band ; white noise testing ; and bandedness testing for covariance matrix .",
    "these procedures are rather straightforward to implement .",
    "the main focus of this section is mostly on the methodological side , and the general theoretical results are deferred to section [ sec : ts ] .",
    "an ad - hoc way of choosing block size in bootstrap is discussed in section  [ sec : ucb ] .",
    "consider @xmath1 observations from a sequence of weakly dependent @xmath2-dimensional time series @xmath3 with @xmath4 .",
    "we are interested in constructing a @xmath5th uniform confidence band for the mean vector @xmath6 in the form of @xmath7 where @xmath8 . in the traditional low dimensional regime , confidence region for the mean of a multivariate time series",
    "is typically constructed by inverting a suitable test .",
    "a common choice is the wald type test which is of the form @xmath9 , where @xmath10 and @xmath11 is a consistent estimator of the so - called long run variance matrix .",
    "however , obtaining a consistent @xmath12 could be difficult in practice due to the unknown dependence structure . to avoid this hassle , several appealing nonparametric alternatives , e.g. ,",
    "moving block bootstrap method @xcite , subsampling approach @xcite and block - wise empirical likelihood @xcite , have been proposed . in the high dimensional regime , where the dimension of the time series is comparable with or even much larger than the sample size , inverting the wald type test is no longer applicable because the long run variance estimator @xmath11 is singular for @xmath13 .",
    "moreover , the direct application of the nonparametric approaches described above to the high dimensional setting is unclear yet .    in this subsection",
    ", we propose a bootstrap - assisted method to obtain the critical value @xmath14 in ( [ eg : ucb ] ) , whose theoretical validity will be justified in section [ subsec : als ] . specifically , we introduce the following blockwise multiplier ( wild ) bootstrap . for simplicity ,",
    "suppose @xmath15 with @xmath16 .",
    "define the non - overlapping block sums , @xmath17 and the bootstrap statistic , @xmath18 where @xmath19 is a sequence of i.i.d .",
    "@xmath20 random variables independent of @xmath3 .",
    "the bootstrap critical value is defined as @xmath21    we next conduct a small simulation study to assess the finite sample coverage probability of the uniform confidence band . consider a @xmath2-dimensional var(1 ) ( vector autoregressive ) process , @xmath22 where @xmath23 . for the error process",
    "@xmath24 , we consider three cases : ( 1 ) @xmath25 where @xmath26 ; ( 2 ) @xmath27 , where @xmath28 are generated independently from @xmath29 ( uniform distribution on [ 2,3 ] ) , and @xmath30 are i.i.d @xmath20 random variables ; ( 3 ) @xmath31 is generated from the moving average model in ( 2 ) with @xmath30 being i.i.d centralized gamma@xmath32 random variables . set @xmath33 , @xmath34 , and @xmath35 or @xmath36 in ( [ eq : var ] ) . to implement the blockwise multiplier bootstrap , we choose @xmath37    table [ tab : mean ]",
    "reports the coverage probabilities at 90% and 95% nominal levels based on 5000 simulations and 499 bootstrap resamples .",
    "we note that the coverage probabilities appear to be low for relatively small block size .",
    "when @xmath38 increases , a larger block size is generally required to capture the dependence .",
    "although the coverage probability is generally sensitive to the choice of the block size , with a proper block size , the coverage probability can be reasonably close to the nominal level .",
    "for univariate time series , there are two major approaches for selecting the optimal block size : the nonparametric plug - in method ( e.g. @xcite ) and the empirical criteria - based method @xcite .",
    "however , these selection procedures are deduced based on the bias - variance tradeoff , which are not intended to guarantee the best coverage of confidence interval . moreover , it is still unclear how these selection rules can be extended to the high dimensional context .",
    "hence , we provide an ad - hoc way for choosing the block size below .",
    "given a set of realizations @xmath39 , we pick an initial block size @xmath40 such that @xmath41 where @xmath42 .",
    "conditional on the sample @xmath43 , we let @xmath44 be i.i.d uniform random variables on @xmath45 and define @xmath46 with @xmath47 and @xmath48 in other words , @xmath49 is a non - overlapping block bootstrap sample with block size @xmath40 . for each @xmath50 ( block size for the original sample )",
    ", we can compute the times that the sample mean @xmath51 is contained in the uniform confidence band constructed based on the bootstrap sample @xmath49 and then compute the empirical coverage probabilities based on @xmath52 bootstrap samples .",
    "this is based on the notion that @xmath51 is the true mean for the bootstrap sample conditional on @xmath39 . in this case , the block size , which delivers the most accurate coverage for @xmath53 , can be viewed as an estimate of the optimal @xmath50 for the original series .",
    "we employ the above procedure with @xmath54 and @xmath55 to choose the optimal block size .",
    "based on 200 realizations from the original data generating process , the coverage probabilities ( given the selected block size ) in different simulation setup are summarized in table [ tab : mean - opt ] .",
    "we observe that the coverage probability based on the optimal block size is close to the best coverage presented in table [ tab : mean ] .",
    "finally we point out that it might be possible to iterate the above procedure to further improve the empirical performance .",
    ".coverage probabilities of the uniform confidence band for the mean , where the block size @xmath56 and @xmath33 .",
    "[ cols= \" < , > , > , > , > , > , > , > , > , > , > , > , > \" , ]     the simulation results demonstrate the usefulness of the proposed method but they also leave some room for improvement . here",
    "we point out two possibilities : ( 1 ) it is of interest to study the studentized version of the test statistic which may be more efficient as expected in the low dimensional setting ( see remark [ rk : student ] ) ; ( 2 ) in the sparsity situation , the test statistic can be constructed based on a suitable linear transformation of the observations .",
    "the linear transformation aims to magnify the signals owing to the dependence within the data vector under alternatives , and hence improves the power of the testing procedure , e.g. , @xcite .      in this subsection , we consider testing the bandedness of covariance matrix @xmath57 .",
    "this problem aries , for example , in econometrics when testing certain economic theories ; see @xcite and reference therein .",
    "also see @xcite for independent case . for any integer @xmath58 ( which possibly depends on @xmath1 or @xmath2 )",
    ", we want to test @xmath59 our setting significantly generalizes the one considered in @xcite which focuses on independent gaussian vectors . here",
    ", we shall allow non - gaussian and dependent random vectors .",
    "we define the test statistic as @xmath60 for @xmath15 with @xmath61 , we define the block sums @xmath62 and the bootstrap statistic @xmath63 where @xmath19 is a sequence of i.i.d @xmath20 independent of @xmath3 .",
    "we reject the null @xmath64 if @xmath65 , where @xmath66 alternatively , one can employ the non - overlapping block bootstrap ( to be presented in sections [ subsec : block ] ) to obtain the critical value .",
    "in this section , we derive a gaussian approximation theory that serves as the first step in studying high dimensional inference procedures in section  [ sec : statappl ] . consider a sequence of @xmath2-dimensional dependent random vectors @xmath67 with @xmath4 .",
    "suppose @xmath68 and @xmath69 .",
    "the gaussian counterpart is defined as a sequence of gaussian random variables @xmath70 independent of @xmath71 .",
    "in addition , @xmath70 preserves the autocovariance structure of @xmath3 in the sense that @xmath72 and @xmath73 ( note that this assumption can be weakened , see remark [ rm : cov ] ) .",
    "gaussian approximation theory quantifies the kolmogorov distance defined as @xmath74 where @xmath75 , @xmath76 , and @xmath77    chernozhukov et al ( 2013 ) recently showed that for independent data vectors , @xmath78 decays to zero polynomially in the sample size . in section  [ subsec : dep - graph ] , we substantially relax their independence assumption by first establishing a general proposition , i.e. , proposition  [ prop1 ] , in the framework of dependency graph .",
    "this general result leads to delicate bounds on the kolmogorov distance for various types of weakly dependent time series even when their dimension is exponentially high , i.e. , sections [ subsec : m - dep ]  [ subsec : weak - dep ] .      in this subsection",
    ", we introduce a flexible framework in modelling the dependence among a sequence of @xmath2-dimensional dependent ( _ unnecessarily identical _ ) random vectors @xmath67 .",
    "we call it as dependency graph @xmath79 , where @xmath80 is a set of vertices and @xmath81 is the corresponding set of undirected edges . for any two disjoint subsets of vertices",
    "@xmath82 , if there is no edge from any vertex in @xmath83 to any vertex in @xmath84 , the collections @xmath85 and @xmath86 are independent .",
    "let @xmath87 be the maximum degree of @xmath88 and denote @xmath89 . throughout the paper ,",
    "we allow @xmath90 to grow with the sample size @xmath91 for example , if an array @xmath92 is a @xmath93 dependent sequence ( that is @xmath94 and @xmath95 are independent if @xmath96 ) , then we have @xmath97 . within this general framework , we want to understand the largest possible diverging rate of @xmath2 ( w.r.t .",
    "@xmath1 ) under which the kolmogorov distance between the distributions of @xmath98 and @xmath99 , i.e. , @xmath78 defined in ( [ dfn : rhon ] ) , converges to zero .",
    "recall that @xmath75 , @xmath100 .",
    "the problem of comparing distributions of maxima is nontrivial since the maximum function @xmath101 is non - differentiable . to overcome this difficulty",
    ", we consider a smooth approximation of the maximum function , @xmath102 where @xmath103 is the smoothing parameter that controls the level of approximation .",
    "simple algebra yields that ( see @xcite ) , @xmath104 denote by @xmath105 the class of @xmath106 times continuously differentiable functions from @xmath107 to itself , and denote by @xmath108 the class of functions @xmath109 such that @xmath110 for @xmath111 set @xmath112 with @xmath113 . in proposition  [ prop1 ]",
    "below , we derive a non - asymptotic upper bound for the quantity @xmath114|$ ] by employing the slepian interpolation @xcite , and modifying stein s leave - one - out argument @xcite to the leave - one - block - out argument for capturing the local dependence of the data .",
    "denote the truncated variables @xmath115 $ ] and @xmath116 for some @xmath117 .",
    "let @xmath118 and @xmath119 . for @xmath120 ,",
    "let @xmath121 be the set of neighbors of @xmath122 , and @xmath123 let @xmath124 be a constant depending on the threshold parameter @xmath125 such that @xmath126 analogous quantity @xmath127 can be defined for @xmath128 set @xmath129 . define @xmath130 where @xmath131=\\sum^{n}_{i=1}{{\\mathbb{e}}}z_i / n$ ] for a sequence of random variables @xmath132 .",
    "note that @xmath133 and @xmath134 .",
    "further define an indicator function , @xmath135 where @xmath136 and @xmath137    [ prop1 ] assume that @xmath138 with @xmath139 .",
    "then we have for any @xmath140 @xmath141 , \\end{split}\\ ] ] where @xmath142 for @xmath143 .",
    "in addition , if @xmath144 , we can replace @xmath145 by @xmath146 in the above expression .",
    "the proof of proposition  [ prop1 ] is adapted from that of theorem 2.1 in @xcite for i.i.d case .    by approximating the indicator function @xmath147 with a suitable smooth function @xmath148 , proposition [ prop1 ]",
    "leads to an upper bound on the kolmogorov distance , i.e. , @xmath78 defined in ( [ dfn : rhon ] ) .",
    "in fact , the upper bound in ( [ eq : prop1 ] ) can be further simplified using the self - normalization technique ( see lemma [ lemma : self ] ) and certain arguments under weak dependence assumption .",
    "finally , by optimizing the simplified upper bound ( see theorem [ thm1 ] ) , we obtain various convergence rates for @xmath78 in sections [ subsec : m - dep ]  [ subsec : weak - dep ] .",
    "[ rm : cov ] in view of the proof of proposition [ prop1 ] ( see e.g. ( [ eq : cov - ts ] ) ) , the assumption that @xmath149 preserves the autocovariance structure of @xmath3 can be weakened by assuming that for all @xmath150 @xmath151 thus @xmath149 is allowed to be a sequence of independent ( mean - zero ) @xmath2-dimensional gaussian random variables such that @xmath152 ( provided that @xmath153 is positive - definite ) .",
    "the arguments in the proof of proposition  [ prop1 ] allow us to derive a non - asymptotic upper bound on @xmath154 for a more general function @xmath155 on the high dimensional vector sum ( after some suitable componentwise transformation ) ; see section [ subsec : extension ] .",
    "such general results are potentially useful in studying higher criticism test ( @xcite ) ; see example [ example : general - g ] and remark  [ os : rem ] .",
    "this subsection is devoted to the analysis of @xmath0-dependent time series , which fits in the framework of dependency graph . here",
    ", we allow @xmath0 to grow slowly with the sample size @xmath91 using the arguments in the proof of proposition [ prop1 ] , we obtain the following result for @xmath0-dependent ( _ unnecessarily stationary _ ) sequence .",
    "[ corollary : m - dep ] when @xmath3 is a @xmath0-dependent sequence , under the assumption that @xmath156 we have @xmath157 .",
    "\\end{split}\\ ] ]    let @xmath158 , where @xmath159 and @xmath160 as @xmath161 define the block sums @xmath162 it is not hard to see that @xmath163 and @xmath164 with @xmath165 are two sequences of i.i.d random variables .",
    "let @xmath166 with @xmath167 and @xmath168 . by generalizing theorem 2.16 of de la pea et al ( 2009 )",
    ", we obtain the following lemma .",
    "[ lemma : self ] suppose @xmath3 is a @xmath2-dimensional @xmath0-dependent sequence .",
    "assume that there exist @xmath169 such that @xmath170 then we have @xmath171 for any @xmath172 in particular , we can choose @xmath173 and @xmath174 .",
    "it is worth noting that lemma [ lemma : self ] holds without the stationarity assumption .",
    "this lemma is particularly useful in controlling the last two terms in ( [ eq : m - dep1 ] ) .    throughout the rest of this subsection",
    ", we consider the case where @xmath3 is a @xmath0-dependent _ stationary _ time series .",
    "define @xmath175 for @xmath176 and @xmath177 for @xmath178 , where @xmath179 let @xmath180 , @xmath181 and @xmath182 .",
    "let @xmath183 be the smallest finite constant which satisfies that uniformly for @xmath184 , @xmath185 where @xmath186 and @xmath187 are the truncated versions of @xmath188 and @xmath189 defined as follows : @xmath190 similarly , we can define the quantity @xmath191 for the gaussian sequence @xmath149 .",
    "set @xmath192 .",
    "further let @xmath193 and @xmath194 be the smallest quantities such that @xmath195    building on the above results , we are ready to derive an upper bound for @xmath78 . to this end , consider a `` smooth '' indicator function @xmath196 $ ] such that @xmath197 for @xmath198 and @xmath199 for @xmath200 fix any @xmath201 and define @xmath202 with @xmath203 .",
    "for this function @xmath204 , @xmath205 , @xmath206 , @xmath207 and @xmath208 . here , @xmath209 is a smoothing parameter we will choose carefully in the proof .",
    "corollary [ corollary : m - dep ] and lemma [ lemma : self ] imply the following result .",
    "[ thm1 ] consider a @xmath0-dependent stationary time series @xmath3 .",
    "suppose @xmath210 with @xmath139 , and @xmath211 and @xmath212 for some @xmath213 .",
    "further suppose that there exist constants @xmath214 such that @xmath215 uniformly holds for all large enough @xmath1 , @xmath0 and @xmath2 .",
    "then for any @xmath216 , @xmath217    we point out that the stationarity assumption is non - essential in the proof of theorem [ thm1 ] .    to characterize the dependence of @xmath0-dependent time series , we adopt the idea of viewing the weakly dependent time series as outputs on inputs in physical systems @xcite .",
    "this framework is very general and easy to verify for specific ( linear or nonlinear ) data - generating mechanism ; see @xcite . with some abuse of notation ,",
    "let @xmath218 be a sequence of mean - zero i.i.d random variables .",
    "consider a physical system @xmath219 , where @xmath220 are the inputs and @xmath221 is a ( @xmath2-dimensional ) measurable function such that its output is well defined .",
    "define the sigma field @xmath222 with @xmath223",
    "we suppose the @xmath0-dependent sequence @xmath3 has the following representation ( also see the discussions in the next subsection ) , @xmath224:=\\mathcal{g}^{(m)}(\\epsilon_{i - m},\\epsilon_{i - m+1},\\dots,\\epsilon_i).\\end{aligned}\\ ] ] for any @xmath225 , let @xmath226 = { { \\mathbb{e}}}[\\mathcal{g}(\\dots,\\epsilon_{i-1},\\epsilon_{i})|\\mathcal{f}_{l-1}(i)]$ ] for @xmath227 , and @xmath228 for @xmath229",
    ". by construction , @xmath230 and @xmath231 are independent for any @xmath232 .",
    "let @xmath233 be a convex and strictly increasing function with @xmath234 .",
    "denote by @xmath235 the inverse function of @xmath236 let @xmath237 .",
    "[ assum : tail ] suppose one of the following two conditions holds : ( 1 ) @xmath238 with @xmath239 , and @xmath240 for some constants @xmath241 ; ( 2 ) @xmath242 with @xmath239 , and @xmath243 for some constants @xmath244 .",
    "[ thm2 ] assume that there exist constants @xmath245 such that @xmath246 uniformly for all large enough @xmath247 , and @xmath248 condition ( [ eq : m - dep - couple ] ) also holds for @xmath149 .",
    "then under assumption [ assum : tail ] , we have @xmath249    suppose @xmath250 . then with @xmath251 , @xmath252 , @xmath253 , and @xmath254 , we have condition ( 1 ) in assumption [ assum : tail ] holds with @xmath255 , and @xmath256 if condition ( 2 ) in assumption [ assum : tail ] holds , we can still have ( [ dep1:rhon ] ) when @xmath242 , @xmath251 , @xmath257 , @xmath253 and @xmath258 .",
    "when @xmath259 ( i.e. @xmath260 ) , our result allows @xmath261 with @xmath262 , which is consistent with corollary 2.1 in @xcite for i.i.d random vectors ( assuming that @xmath263 therein ) .",
    "[ rem : interp ] the sharpness of @xmath78 is not established in theorem  [ thm2 ] .",
    "however , the upper bound of @xmath78 given in ( [ dep1:rhon ] ) leads to two conjectures : ( i ) gaussian approximation becomes less accurate when the data vectors are more dependent or the data dimension diverges at a faster rate ; ( ii ) the less dependent of the data vectors , the faster diverging rate of the dimension is allowed for obtaining an accurate gaussian approximation .",
    "the above phenomena will also be observed for the weakly dependent data in section  [ subsec : weak - dep ] .",
    "interestingly , we will show some empirical evidence of both conjectures in that section .",
    "[ rem : xass ] assumption [ assum : tail ] and ( [ eq : condition ] ) impose tail restrictions on @xmath264 .",
    "condition ( [ eq : m - dep - couple ] ) requires @xmath3 to be weakly dependent uniformly as @xmath0 grows , and , in particular , ( [ eq : m - dep - couple ] ) allows us to quantify @xmath265 and @xmath266 ; see ( [ eq : varphi ] ) .      in this subsection",
    ", we extend the results in section [ subsec : m - dep ] to the weakly dependent case , i.e. , @xmath267 .",
    "the key idea here is to approximate the weakly dependent time series by a @xmath0-dependent time series , see the approximation error ( [ eq : m - approx ] ) below .    with slightly abuse of notation ,",
    "suppose the sequence @xmath3 has the following causal representation , @xmath268 where @xmath221 is a @xmath2-dimensional measurable function such that @xmath269 is well defined .",
    "to measure the strength of dependence , we let @xmath270 be an i.i.d copy of @xmath220 and @xmath271 , and define @xmath272 in the subsequent discussions , we assume that the dependence measure @xmath273 for some @xmath274 .",
    "analogous quantity @xmath275 can be defined for the gaussian sequence @xmath149 .",
    "let @xmath276 $ ] be the @xmath0-dependent approximation sequence for @xmath3 .",
    "define @xmath277 in the same way as @xmath278 by replacing @xmath269 with @xmath279 .",
    "because @xmath280 and @xmath281 ( by the lipschitz property of @xmath282 ) , we have @xmath283 , \\end{split}\\ ] ] where @xmath284 for some @xmath285 depending on @xmath0 .",
    "suppose @xmath286 for some @xmath274 . by lemma",
    "a.1 of @xcite , we have @xmath287 where @xmath288 and @xmath289 is a positive constant depending on @xmath290 . for any @xmath291",
    ", we obtain @xmath292   \\leq & \\sum^{p}_{j=1}p(|x_j - x_j^{(m)}|\\geq \\delta_m ) \\leq \\sum^{p}_{j=1}\\frac{1}{\\delta_m^q}{{\\mathbb{e}}}|x_j - x_j^{(m)}|^q \\\\ \\leq & \\sum^{p}_{j=1}\\frac{c^{q/2}_q\\theta_{m , j , q}^q(x)}{\\delta_m^q}=\\sum^{p}_{j=1}\\frac{c^{q/2}_q}{\\delta_m^q}\\left(\\sum^{+\\infty}_{l = m}\\theta_{l , j , q}(x)\\right)^q.\\end{aligned}\\ ] ] optimizing the bound with respect to @xmath293 in ( [ eq : m - approx-1 ] ) , we deduce that @xmath294 which along with ( [ eq : fbeta ] ) implies that @xmath295 with @xmath296 .",
    "we give an explicit expression of the approximation error ( [ eq : m - approx ] ) in the following two examples .",
    "consider a stationary linear process , @xmath297 where @xmath298 and @xmath299 is a sequence of i.i.d random variables .",
    "simple calculation yields that @xmath300 and @xmath301 . for @xmath302",
    ", we have @xmath303 under the assumption that @xmath304 and @xmath305 with @xmath306 , we get @xmath307|\\lesssim   ( g_0g_1^q)^{1/(1+q)}p^{1/(1+q)}\\rho^{(qm)/(1+q)}.\\ ] ]    consider a stationary markov chain defined by an iterated random function @xmath308 here @xmath309 s are i.i.d .",
    "innovations , and @xmath310 is an @xmath311-valued and jointly measurable function , which satisfies the following two conditions : ( 1 ) there exists some @xmath312 such that @xmath313 and ( 2 ) @xmath314 where @xmath315 denotes the euclidean norm for a @xmath2-dimensional vector . then it can be shown that @xmath3 has the geometric moment contraction ( gmc ) condition property @xcite and @xmath316 ( see example 2.1 in @xcite )",
    ". hence @xmath317    we are now ready to present the main result .",
    "recall that @xmath318 and @xmath319 are defined in section  [ subsec : m - dep ] .",
    "[ thm : gaussian - dep ] suppose @xmath3 is a stationary time series which admits the representation ( [ eq : causal ] ) .",
    "assume that @xmath320 , and @xmath321 for some constants @xmath322 and @xmath214 .",
    "suppose that there exist @xmath323 and @xmath0 such that @xmath159 and assumption [ assum : tail ] is fulfilled .",
    "then for @xmath291 , we have @xmath324 where @xmath325 .    the approximation parameter @xmath0 will be chosen appropriately to optimize the bound ( [ rhon1 ] ) .",
    "the gaussian sequence @xmath149 can be constructed as a causal linear process ( e.g. based on the wold representation theorem ) to capture the second order property of @xmath3 .",
    "we note that the conditions in theorem [ thm : gaussian - dep ] can be categorized into two types : tail restriction and weak dependence assumption .",
    "assumption [ assum : tail ] and the condition that @xmath326 impose restrictions on the tails of @xmath327 uniformly across @xmath184 , while conditions ( [ eq : h3])-([eq : h4 ] ) essentially require weak dependence uniformly across all the components of @xmath3 .",
    "when @xmath328 for @xmath306 , we have @xmath329 suppose @xmath330 for some @xmath331 and @xmath332 .",
    "then by choosing @xmath252 with @xmath333 and @xmath334 , @xmath253 and assuming that @xmath335 , condition ( 1 ) in assumption [ assum : tail ] holds with @xmath255 , and @xmath336 the same conclusion holds under condition ( 2 ) in assumption [ assum : tail ] provided that @xmath251 , @xmath257 , @xmath253 and @xmath258 with @xmath334 .",
    "below we provide some empirical evidence for two conjectures proposed in remark  [ rem : interp ] , in particular the interplay between dependence and dimensionality . to this end",
    ", we generate @xmath3 from a multivariate arch model @xmath337 , where @xmath338 with @xmath339 being a sequence of i.i.d @xmath340 random variables , and @xmath341 with @xmath342 being a lower triangular matrix based on the cholesky decomposition of @xmath343 . here",
    "@xmath344 with @xmath345 and @xmath346 for @xmath347 notice that @xmath3 are uncorrelated and @xmath348 . to capture the second order property of @xmath3 ,",
    "we generate independent gaussian vectors @xmath149 from @xmath349 .",
    "figure [ fig : interplay ] illustrates the interplay between dependence and dimensionality using the p - p plots for @xmath350 , @xmath351 , and @xmath352 . for moderate @xmath2 and @xmath353",
    ", the gaussian approximation is reasonably good , which is consistent with our theory .",
    "moreover , we also observe the following phenomena . on one hand , as @xmath2 increases , the approximation deteriorates for the same @xmath353 which controls the strength of dependence ; on the other hand , for fixed @xmath2 , the approximation becomes worse in the right tail which is most relevant for practical applications , as @xmath353 increases .",
    "note that our theoretical results are finite sample valid , and thus the sample size supposed not to play any role here .",
    "hence , we believe that the less dependent of the data vectors , the faster diverging rate of the dimension is allowed for obtaining an accurate gaussian approximation .     and @xmath99.,title=\"fig:\",width=196,height=196 ]   and @xmath99.,title=\"fig:\",width=196,height=196 ]   and @xmath99.,title=\"fig:\",width=196,height=196 ]    in the end , we discuss an intriguing question : is there any so - called `` dimension free dependence structure '' ?",
    "in other words , what kind of dependence assumption will not affect the dimension increase rate ( as compared to the independence case in @xcite ) ? to address this question , we consider one possibility : the original @xmath2-dimensional vector can be decomposed into two components namely one times series component and one independence component , where the former component is asymptotically ignorable comparing to the latter as @xmath1 grows . our contribution here is to precisely characterize such a  dimension free \" dependence structure .",
    "[ prop : dim - free ] consider a @xmath2-dimensional time series @xmath3 .",
    "suppose there exists a permutation @xmath354 such that @xmath355 , where @xmath356 is a @xmath290-dimensional ( possibly nonstationary ) time series and @xmath357 is a @xmath358 dimensional sequence of independent variables .",
    "suppose @xmath356 and @xmath357 are independent .",
    "when @xmath357 satisfies the assumptions in corollary 2.1 of @xcite , we have @xmath359 recall that @xmath360 is @xmath361 and @xmath362 is defined in a similar manner . then under the additional assumption that @xmath363 and @xmath364",
    ", we have @xmath365    the additional assumption ( [ ass : add ] ) implies that @xmath290 is of a polynomial order w.r.t . @xmath1 while @xmath366 achieves the exponential order as specified in corollary 2.1 of @xcite .",
    "therefore , the largest possible diverging rate of @xmath2 allowed in proposition  [ prop : dim - free ] remains the same as that in the independence case ( @xcite ) .",
    "the independence assumption between @xmath356 and @xmath357 might be relaxed . here",
    ", we assume it mainly for technical simplicity so that only one single dependence assumption @xmath367 needs to be imposed on @xmath356 .",
    "in practice , the intrinsic dependence structure of time series data is usually unknown .",
    "hence , the gaussian approximation theory becomes too restrictive to use .",
    "however , this general theory provides a foundation in developing the bootstrap inference theory that do not require such knowledge . in this section",
    ", we consider two types of bootstrap procedures : ( i ) blockwise multiplier bootstrap ; and ( ii ) non - overlapping block bootstrap .",
    "the former is employed in section  [ sec : statappl ] , while the latter is a more flexible alternative .      to approximate the quantiles of @xmath98",
    ", we introduce a blockwise multiplier bootstrap procedure for @xmath0-dependent and weakly dependent time series considered in sections [ subsec : m - dep ] and [ subsec : weak - dep ] .",
    "suppose @xmath158 , where @xmath159 and @xmath160 as @xmath368 .",
    "let @xmath369 be a sequence of i.i.d @xmath370 variables that are independent of @xmath3 .",
    "define @xmath371 recall the definitions of @xmath188 and @xmath189 in ( [ eq : ab ] ) .",
    "conditional on @xmath3 , @xmath372 are mean - zero gaussian random variables such that @xmath373 thus we have @xmath374 conditional on the sample @xmath67 , define the @xmath375-quantile of @xmath376 as @xmath377    our goal below is to quantify @xmath378 to this end , consider the estimation errors @xmath379 where @xmath380 . recall that @xmath318 is a nondecreasing convex function with @xmath234 . define the orlicz norm as @xmath381    we first consider @xmath0-dependent stationary sequence where @xmath0 is allowed to grow with the sample size @xmath1 .",
    "define the following quantities which characterize the higher order properties of the time series ( e.g. , @xmath382 and @xmath383 below characterize the fourth order property of @xmath3 ) , @xmath384 where @xmath385 denotes the cumulant ( see e.g. @xcite ) and @xmath386 .",
    "the following lemma plays an important role in the subsequent derivations .",
    "[ lemma : m - dep - boot ] suppose @xmath3 is a @xmath0-dependent stationary sequence",
    ". then with @xmath387 , @xmath388 alternatively , we have @xmath389    let @xmath390 in the spirit of lemma 3.2 in @xcite , we can show that when @xmath391 for some @xmath392 @xmath393 where @xmath394 for some constant @xmath395 depending on @xmath396 . using the arguments in theorem 3.1 of @xcite ,",
    "it is not hard to show that @xmath397 because @xmath398 , we deduce that @xmath399    [ assum : boot - m - dep ] suppose @xmath330 with @xmath400 set @xmath401 and @xmath402 with @xmath403 , @xmath333 and @xmath404 . assume that @xmath335 under condition ( 1 ) in assumption [ assum : tail ] with @xmath255 or @xmath258 under condition ( 2 ) in assumption [ assum : tail ] .",
    "further assume that one of the following two conditions holds .",
    "+ * condition 1 : * @xmath405 , where @xmath387 and @xmath406 satisfy that @xmath407 * condition 2 : * @xmath408 , and @xmath406 satisfy that @xmath409    we are now in position to present the first main result in this section .",
    "[ thm : m - dep - boot ] consider a @xmath0-dependent stationary time series @xmath3 . under the assumptions in theorem [ thm2 ] and assumption [ assum : boot - m - dep ] , @xmath410",
    "our next theorem extends the above result to weakly dependent stationary time series .",
    "[ thm : dep - boot ] consider a weakly dependent stationary time series @xmath3 .",
    "suppose @xmath328 for @xmath306 and some @xmath411 . then under the assumptions in theorem [ thm : gaussian - dep ] and assumption [ assum : boot - m - dep ] , @xmath412    remark that the results of theorems  [ thm : m - dep - boot ] and  [ thm : dep - boot ] are still valid even when @xmath2 is fixed or @xmath2 grows slower than the exponential rate required in assumption  [ assum : boot - m - dep ] .",
    "when @xmath3 has the so - called geometric moment contraction ( gmc ) property ( uniformly across its components ) , we have @xmath413 ( i.e. , @xmath414 ) by proposition 2 of @xcite and the assumption that @xmath415    it is known that in the low dimensional setting , the tapered block bootstrap method yields an improvement over the block bootstrap in terms of the bias for variance estimation , and thus provides a better mse rate ; see @xcite . hence , we may also want to combine the blockwise multiplier bootstrap method proposed here with the data tapering scheme .",
    "for example , let @xmath416 : @xmath417 be a data taper with @xmath418 for @xmath419 .",
    "one can consider the following modification , @xmath420 more detailed investigation along this direction is left for future study .",
    "in this subsection , we propose an alternative bootstrap procedure in the high dimensional setting : non - overlapping block bootstrap ( @xcite ) .",
    "in general , this bootstrap procedure may avoid estimating the influence function ( defined in section  [ sec : ts ] ) in contrast with blockwise multiplier bootstrap .",
    "we provide theoretical justifications for this procedure through establishing its equivalence with multiplier bootstrap ; see ( [ eq : equi ] ) .",
    "assume for simplicity that @xmath15 , where @xmath61 .",
    "conditional on the sample @xmath421 , we let @xmath422 be i.i.d uniform random variables on @xmath423 and define @xmath424 with @xmath425 and @xmath426 in other words , @xmath427 is a non - overlapping block bootstrap sample with block size @xmath50 .",
    "define @xmath428 where @xmath429 , @xmath430 , and @xmath431 and @xmath432 are i.i.d draws from the empirical distribution of @xmath433 . also define @xmath434 where @xmath435 is a sequence of i.i.d @xmath20 . throughout the following discussions ,",
    "we suppose that @xmath436 the theoretical validity of the multiplier bootstrap based on @xmath437 can be justified using similar arguments in the previous subsection because the same arguments go through when @xmath188 and @xmath189 are replaced by @xmath438 ( provided that @xmath439 ) . by showing that with probability @xmath440 , @xmath441 we establish the validity of non - overlapping block bootstrap in theorem [ thm : block - boot ] .",
    "[ assum : block - boot ] assume that @xmath442 and @xmath443 with @xmath387 , where @xmath444    [ thm : block - boot ] suppose that @xmath445 and @xmath446 for some constants @xmath447 and @xmath448 , where @xmath449 .",
    "further assume that the assumptions in theorem [ thm : m - dep - boot ] or theorem [ thm : dep - boot ] hold with @xmath450 and @xmath451 .",
    "then ( [ eq : equi ] ) holds with probability @xmath440 for some @xmath452",
    ". moreover , we have @xmath453 where @xmath454 and @xmath455",
    "in this section , we establish a general framework of conducting bootstrap inference for high dimensional time series based on the theoretical results in section  [ sec : boot ] .",
    "this general framework assumes that the @xmath290-dimensional quantity of interest , denoted as @xmath456 , admits an approximately linear expansion , and thus covers three examples considered in section  [ sec : statappl ] . in particular , @xmath456 is expressed as a functional of the distribution of a @xmath2-dimensional _ weakly dependent _ stationary time series @xmath457 here is different from the dimension of @xmath269 discussed in previous sections . ]",
    "motivated by the testing on spectral properties , we further extend the results in section  [ subsec : als ] to an infinite dimensional parameter case in section  [ subsec : infinite ] .      in this subsection",
    ", we consider the quantities that can be expressed as functionals of the marginal distribution of a block time series with length @xmath458 : @xmath459 , where @xmath460 and @xmath461 . here",
    ", we allow the integer @xmath458 to grow with @xmath1 .",
    "define @xmath462 as the empirical distribution for @xmath459 .",
    "the distribution function of @xmath463 is denoted as @xmath464 .",
    "we are interested in testing the parameter @xmath465 for some functional @xmath466 .",
    "the parameter dimension @xmath467 depends on either @xmath2 or @xmath458 , e.g. , @xmath468 or @xmath469 . a natural estimator for @xmath470",
    "is then given by @xmath471 .",
    "assume @xmath472 admits the following approximately linear expansion in a neighborhood of @xmath464 : @xmath473 where @xmath474 is called  influence function \" ( see e.g. @xcite ) and @xmath475 is a remainder term .",
    "examples of approximately linear statistics include various location and scale estimators for the marginal distribution of @xmath476 , von mises statistics and @xmath0-estimators of time series models ( see @xcite ) .",
    "we are interested in testing the null hypothesis @xmath477 versus the alternative @xmath478 , where @xmath479 .",
    "the test is proposed as @xmath480 we next apply the bootstrap theory in section  [ sec : boot ] to obtain the critical value @xmath14 .",
    "specifically , we define @xmath481 and @xmath482 , where @xmath483 is some estimate of @xmath484 .",
    "suppose @xmath485 , where @xmath486 and @xmath487 as @xmath488 define the estimated block sums @xmath489 where @xmath490 and @xmath491 .",
    "let @xmath492 where @xmath493 with @xmath369 being a sequence of i.i.d @xmath370 independent of @xmath476 .",
    "the bootstrap critical value is given by @xmath494        [ thm : app-1 ] suppose the assumptions in theorem [ thm : m - dep - boot ] or theorem [ thm : dep - boot ] hold for @xmath3 , where @xmath2 is replaced by @xmath502 . then under assumption [ assum : app-1 ] and @xmath64 , we have @xmath503    theorem  [ thm : app-1 ] applies directly to the methods described in sections  [ sec : ucb]-[subsec : cov ] for both m - dependent and weakly dependent stationary time series .",
    "for example , consider the white noise testing problem in section [ subsec : cov ] .",
    "suppose @xmath504 .",
    "in this example , @xmath505 with @xmath506 and @xmath507",
    ". then we have @xmath508 and @xmath509 with @xmath510 and @xmath511 .",
    "note that the bootstrap procedures considered in section [ sec : statappl ] are in fact simplified versions of the blockwise multiplier bootstrap in section [ sec : boot ] with @xmath512 and @xmath513 .",
    "our next theorem covers the problem of testing the bandedness of covariance matrix in section [ sec : bandtest ] . recall that @xmath514 where @xmath515 . with some abuse of notation ,",
    "let @xmath516 with @xmath517 .",
    "[ thm : bandtest ] suppose the assumptions in theorem [ thm : m - dep - boot ] or theorem [ thm : dep - boot ] hold for @xmath3 , where @xmath2 is replaced by the cardinality of the set @xmath518 .",
    "then under assumption [ assum : band ] in the supplementary material and @xmath64 , we have @xmath519 where @xmath520 is given in section  [ sec : bandtest ] .    the proof of theorem [ thm : bandtest ] is similar as that of theorem  [ thm : app-1 ] , and thus skipped . in section [ subsec :",
    "band ] , we show that assumption [ assum : band ] can be verified under suitable primitive conditions .    to avoid direct estimation of the influence function",
    ", we may alternatively apply the non - overlapping block bootstrap procedure in section  [ subsec : block ] .",
    "assume for simplicity that @xmath521 , where @xmath61 .",
    "let @xmath422 be i.i.d uniform random variables on @xmath423 and define @xmath522 with @xmath425 and @xmath426 compute the block bootstrap estimate @xmath523 based on the bootstrap sample @xmath524 .",
    "let @xmath525 be the @xmath5th quantile of the distribution of @xmath526 conditional on the sample @xmath476 .",
    "in what follows , we further justify the validity of the non - overlapping block bootstrap in the same framework .",
    "[ rk : student ] an alternative way to construct the uniform confidence band or perform hypothesis testing is based on the studentized statistic .",
    "for example , let @xmath531 be a consistent estimator of @xmath532 . then the uniform confidence band can be constructed as @xmath533 the blockwise multiplier bootstrap or non - overlapping block bootstrap can be modified accordingly to obtain the critical value @xmath534 .",
    "to broaden the applicability of our method , we extend the above results to cover infinite dimensional parameters that are functionals of the joint distribution of @xmath535 , denoted as @xmath536 .",
    "a typical example is the spectral quantities that depend on the distribution of the whole time series rather than any finite dimensional distribution ; see example  [ eg : spe ] .",
    "hence , the extension in this section is useful in conducting inference for the spectrum of high dimensional time series .",
    "suppose @xmath537 and its estimator is @xmath538 .",
    "again , @xmath467 is allowed to grow with @xmath1 or @xmath2 .",
    "assume that there exists a sequence of approximating statistics for @xmath539 that is a functional of @xmath540-dimensional empirical distribution , and a sequence of approximating ( non - random ) quantities @xmath541 for @xmath470 .",
    "then our bootstrap method as proposed in section  [ subsec : als ] still works provided that these two approximation errors can be well controlled and similar regularity conditions hold for the expansion of the approximating statistics around @xmath542 , i.e. , ( [ app : exp ] ) . to be more precise , we impose the following assumption .",
    "[ assum : app-3 ] for a sequence of positive integers @xmath540 that grow with @xmath543 let @xmath544 with @xmath545 assume the expansion , @xmath546 where @xmath547 is a remainder term .",
    "denote @xmath548 .",
    "suppose that @xmath549 and @xmath550 for some @xmath551 .",
    "[ eg : spe ] consider the spectral mean @xmath552 , where @xmath553 denotes the trace of a square matrix , @xmath554 is the spectral density of @xmath476 and @xmath555\\rightarrow \\mathbb{r}^{p\\times p}.$ ] for simplicity , assume that @xmath556 suppose the quantity of interest is @xmath557 with @xmath558\\rightarrow \\mathbb{r}^{p\\times p}$ ] for @xmath559 here @xmath560 can be interpreted as the projection of the spectral density matrix onto @xmath467 directions defined by @xmath561 with @xmath559 a sample analogue of @xmath562 is the periodogram @xmath563 with @xmath564 . then a plug - in estimator for @xmath470",
    "is given by @xmath565 .",
    "letting @xmath566 , then @xmath567 with @xmath568 consider the approximating quantity @xmath569 with @xmath570 .",
    "it is then straightforward to see that @xmath571 where @xmath572 and @xmath573 is the corresponding remainder term .",
    "recall that @xmath574 with @xmath536 being the joint distribution of @xmath535 .",
    "the statistic for testing the null hypothesis @xmath575 versus the alternative @xmath576 , where @xmath479 , is given by @xmath577 with some abuse of notation , we now define @xmath578 and @xmath579 with @xmath580 being some estimate of @xmath581 ( note that in this case @xmath582 is an array ) .",
    "suppose @xmath583 .",
    "we can define @xmath584 and @xmath585 in a similar way as before ( see ( [ eq : app - ab ] ) ) , where @xmath586 and @xmath491 .",
    "let @xmath587 where @xmath493 with @xmath369 being a sequence of i.i.d @xmath370 independent of @xmath476 . the bootstrap critical value is then given by @xmath494 following the arguments in the proof of theorem [ thm : app-1 ] , we obtain the following result .    [ thm : app-3 ] suppose assumption [ assum : app-3 ] holds and the assumptions in theorem [ thm : m - dep - boot ] or theorem [ thm : dep - boot ] are satisfied for @xmath3 , where @xmath2 is replaced by @xmath502 .",
    "assume in addition that @xmath497 , where @xmath588 , and @xmath499 with @xmath589 and @xmath590 .",
    "then we have for some @xmath591 @xmath592                      2.3em1 cai , t. t. and jiang , t. ( 2011 ) .",
    "limiting laws of coherence of random matrices with applications to testing covariance structure and construc tion of compressed sensing matrices .",
    "statist . _",
    "* 39 * 1496 - 1525 .",
    "2.3em1 liu , w. , lin , z.y . and shao , q .- m .",
    "the asymptotic distribution and berry - esseen bound of a new test for independence in high dimension with an application to stochastic optimization .",
    "* 18 * 2337 - 2366 .",
    "define @xmath597 with the slepian interpolation @xmath598 and @xmath599 let @xmath600 define @xmath601 and @xmath602 .",
    "write @xmath603 , @xmath604 and @xmath605 for @xmath606 , where @xmath607 .",
    "note that @xmath608dt \\\\=&\\frac{1}{2}(i_1+i_2+i_3 ) , \\end{split}\\ ] ] where @xmath609 and @xmath610dt , \\\\&i_2=\\sum^{n}_{i=1}\\sum^{p}_{k , j=1}\\int^{1}_{0}{{\\mathbb{e}}}[\\partial_k\\partial_j m(z^{(i)}(t))\\dot{z}_{ij}(t)v_{k}^{(i)}(t)]dt , \\\\",
    "& i_3=\\sum^{n}_{i=1}\\sum^{p}_{k , l , j=1}\\int^{1}_{0}\\int^{1}_{0}(1-\\tau){{\\mathbb{e}}}[\\partial_l\\partial_k\\partial_jm(z^{(i)}(t)+\\tau v^{(i)}(t))\\dot{z}_{ij}(t)v_{k}^{(i)}(t)v_{l}^{(i)}(t)]dtd\\tau . \\end{split}\\ ] ]    using the fact that @xmath611 and @xmath612 are independent , and @xmath613 , we have @xmath614 to bound the second term , define the expanded neighborhood around @xmath615 , @xmath616 and @xmath617 , where @xmath618 with @xmath619 . by taylor expansion , we have @xmath620dt \\\\&+\\sum^{n}_{i=1}\\sum^{p}_{k , j , l=1}\\int^{1}_{0}\\int^{1}_{0}{{\\mathbb{e}}}[\\partial_k\\partial_j\\partial_l m(\\mathcal{z}^{(i)}(t)+\\tau \\mathcal{v}^{(i)}(t))\\dot{z}_{ij}(t)v_{k}^{(i)}(t)\\mathcal{v}^{(i)}_l(t)]dtd\\tau \\\\=&\\sum^{n}_{i=1}\\sum^{p}_{k , j=1}\\int^{1}_{0}{{\\mathbb{e}}}[\\partial_k\\partial_j m(\\mathcal{z}^{(i)}(t))]{{\\mathbb{e}}}[\\dot{z}_{ij}(t)v_{k}^{(i)}(t)]dt \\\\&+\\sum^{n}_{i=1}\\sum^{p}_{k , j , l=1}\\int^{1}_{0}\\int^{1}_{0}{{\\mathbb{e}}}[\\partial_k\\partial_j\\partial_l m(\\mathcal{z}^{(i)}(t)+\\tau \\mathcal{v}^{(i)}(t))\\dot{z}_{ij}(t)v_{k}^{(i)}(t)\\mathcal{v}^{(i)}_l(t)]dtd\\tau \\\\= & i_{21}+i_{22},\\end{aligned}\\ ] ] where we have used the fact that @xmath621 and @xmath622 are independent .",
    "let @xmath139 . by the assumption that @xmath623 @xmath624}(2\\sqrt{t}+\\sqrt{1-t})m_{xy}/\\sqrt{n } \\\\",
    "\\leq & \\sqrt{5}d_n^2m_{xy}/\\sqrt{n } \\leq \\beta^{-1}/2 \\leq \\beta^{-1},\\end{aligned}\\ ] ] where the second inequality comes from the facts that @xmath625 , @xmath626 and @xmath627 . by lemma a.5 in @xcite",
    ", we have for every @xmath628 @xmath629 and @xmath630 satisfy that @xmath631 with @xmath142 for @xmath143 . along with lemma a.6 in @xcite , we obtain @xmath632|{{\\mathbb{e}}}[\\dot{z}_{ij}(t)v_{k}^{(i)}(t)]|dt \\\\ \\lesssim & \\sum^{n}_{i=1}\\sum^{p}_{k , j=1}\\int^{1}_{0}{{\\mathbb{e}}}[u_{jk}(z(t))]|{{\\mathbb{e}}}[\\dot{z}_{ij}(t)v_{k}^{(i)}(t)]|dt \\\\ \\lesssim &   ( g_2+g_1\\beta)\\int^{1}_{0}\\max_{1\\leq j , k\\leq p}\\sum^{n}_{i=1}|{{\\mathbb{e}}}[\\dot{z}_{ij}(t)v_{k}^{(i)}(t)]|dt.\\end{aligned}\\ ] ] since @xmath138 , we have @xmath633dtd\\tau \\notag \\\\ \\leq & \\sum^{n}_{i=1}\\sum^{p}_{k , j , l=1}\\int^{1}_{0}\\int^{1}_{0}{{\\mathbb{e}}}[u_{kjl}(\\mathcal{z}^{(i)}(t)+\\tau \\mathcal{v}^{(i)}(t))|\\dot{z}_{ij}(t)v_{k}^{(i)}(t)\\mathcal{v}^{(i)}_l(t)|]dtd\\tau \\notag \\\\ \\lesssim & \\sum^{n}_{i=1}\\sum^{p}_{k , j , l=1}\\int^{1}_{0}{{\\mathbb{e}}}[u_{kjl}(z(t))|\\dot{z}_{ij}(t)v_{k}^{(i)}(t)\\mathcal{v}^{(i)}_l(t)|]dtd\\tau \\notag \\\\ \\leq & \\int^{1}_{0}{{\\mathbb{e}}}\\left[\\sum^{p}_{k , j , l=1}u_{kjl}(z(t))\\max_{1\\leq k , j , l\\leq p}\\sum^{n}_{i=1}|\\dot{z}_{ij}(t)v_{k}^{(i)}(t)\\mathcal{v}^{(i)}_l(t)|\\right]dtd\\tau \\notag \\\\ \\lesssim & ( g_3+g_2\\beta+g_1\\beta^2)\\int^{1}_{0}{{\\mathbb{e}}}\\max_{1\\leq k , j , l\\leq p}\\sum^{n}_{i=1}|\\dot{z}_{ij}(t)v_{k}^{(i)}(t)\\mathcal{v}^{(i)}_l(t)|dtd\\tau.\\end{aligned}\\ ] ]    to bound the integration on ( [ eq : i22 ] ) , we let @xmath634 and note that @xmath635 as for @xmath636 , by the assumption that @xmath637 ( in fact , we only need to require that @xmath638 for all @xmath122 ) , we have @xmath639|=\\max_{1\\leq j , k\\leq p}\\frac{1}{n}\\sum^{n}_{i=1}\\left|\\sum_{l\\in \\widetilde{n}_i}({{\\mathbb{e}}}\\widetilde{x}_{ij}\\widetilde{x}_{lk}-{{\\mathbb{e}}}\\widetilde{y}_{ij}\\widetilde{y}_{lk})\\right| \\\\=&\\max_{1\\leq j , k\\leq p}\\frac{1}{n}\\sum^{n}_{i=1}\\left|\\sum_{l\\in \\widetilde{n}_i}({{\\mathbb{e}}}\\widetilde{x}_{ij}\\widetilde{x}_{lk}-{{\\mathbb{e}}}x_{ij}x_{lk})+\\sum_{l\\in \\widetilde{n}_i}({{\\mathbb{e}}}y_{ij}y_{lk}-{{\\mathbb{e}}}\\widetilde{y}_{ij}\\widetilde{y}_{lk})\\right| \\\\ \\leq & \\max_{1\\leq j , k\\leq p}\\frac{1}{n}\\sum^{n}_{i=1}\\left|\\sum_{l\\in \\widetilde{n}_i}\\left\\{{{\\mathbb{e}}}y_{lk}(y_{ij}-\\widetilde{y}_{ij})+{{\\mathbb{e}}}\\widetilde{y}_{ij}(y_{lk}-\\widetilde{y}_{lk})\\right\\}\\right| \\\\&+\\max_{1\\leq j , k\\leq p}\\frac{1}{n}\\sum^{n}_{i=1}\\left|\\sum_{l\\in \\widetilde{n}_i}\\left\\{{{\\mathbb{e}}}x_{lk}(x_{ij}-\\widetilde{x}_{ij})+{{\\mathbb{e}}}\\widetilde{x}_{ij}(x_{lk}-\\widetilde{x}_{lk})\\right\\}\\right| \\\\ \\leq & \\phi(m_{x},m_y ) .",
    "\\end{split}\\ ] ]    using similar arguments as above , we have @xmath640 with @xmath641 we first consider the term @xmath642 .",
    "using the fact that @xmath643 we get @xmath644 on the other hand , notice that @xmath645 similarly , we have @xmath646 note that @xmath647 summarizing the above results , we have @xmath648    alternatively , we can bound @xmath649 in the following way . by lemmas a.5 and a.6 in @xcite , we have @xmath650dtd\\tau \\\\ \\lesssim & \\sum^{n}_{i=1}\\sum^{p}_{k , j , l=1}\\int^{1}_{0}{{\\mathbb{e}}}[u_{kjl}(\\mathcal{z}^{(i)}(t))]{{\\mathbb{e}}}|\\dot{z}_{ij}(t)v_{k}^{(i)}(t)v_{l}^{(i)}(t)|dt \\\\ \\lesssim & \\sum^{n}_{i=1}\\sum^{p}_{k , j , l=1}\\int^{1}_{0}{{\\mathbb{e}}}[u_{kjl}(z(t))]{{\\mathbb{e}}}|\\dot{z}_{ij}(t)v_{k}^{(i)}(t)v_{l}^{(i)}(t)|dt \\\\ \\leq & n(g_3+g_2\\beta+g_1\\beta^2)\\int^{1}_{0}w(t)\\max_{1\\leq j , k , l\\leq p } ( \\bar{{{\\mathbb{e}}}}|\\dot{z}_{ij}(t)/w(t)|^3)^{1/3 } ( \\bar{{{\\mathbb{e}}}}|v_{k}^{(i)}(t)|^3)^{1/3 } ( \\bar{{{\\mathbb{e}}}}|v_{l}^{(i)}(t)|^3)^{1/3}dt.\\end{aligned}\\ ] ] notice that @xmath651 it is not hard to see that @xmath652 thus we derive that @xmath653          notice that @xmath97 , @xmath661 and @xmath662 .",
    "define the @xmath663 then @xmath664 following the arguments in the proof of proposition [ prop1 ] , we can show that @xmath665 which implies that @xmath666 the conclusion follows from the proof of proposition [ prop1 ] .",
    "we only need to prove the result for @xmath667 as the inequality holds trivially for @xmath668 .",
    "suppose that the distributions of @xmath669 and @xmath670 are both symmetric , then we have @xmath671 where we have used theorem 2.15 in @xcite .",
    "let @xmath672 be an independent copy of @xmath673 in the sense that @xmath672 have the same joint distribution as that for @xmath673 , and define @xmath674 ( @xmath675 and @xmath676 ) in the same way as @xmath677 ( @xmath188 and @xmath189 ) by replacing @xmath673 with @xmath672 .",
    "following the arguments in the proof of theorem 2.16 in @xcite , we deduce that for @xmath667 , @xmath678 where we have used the fact that @xmath679      note that @xmath686\\leq & p(\\max_{1\\leq j\\leq",
    "p}|x_j-\\widetilde{x}_j|>\\delta)+p(\\max_{1\\leq j\\leq p}|y_j-\\widetilde{y}_j|>\\delta ) \\\\ \\leq&\\sum^{p}_{j=1}\\left\\{p(|x_j-\\widetilde{x}_j|>\\delta)+p(|y_j-\\widetilde{y}_j|>\\delta)\\right\\}.\\end{aligned}\\ ] ]",
    "let @xmath687 where @xmath688 applying lemma [ lemma : self ] and using the union bound , we have with probability at least @xmath689 , @xmath690    by the assumption , @xmath691 therefore with probability at least @xmath692 @xmath693 where we have used the fact that @xmath694 and the cauchy - schwarz inequality .",
    "the same argument applies to the gaussian sequence @xmath149 .    summarizing the above results and along with ( [ eq : m - dep1 ] )",
    ", we deduce that @xmath695 which also implies that @xmath696 for @xmath0-dependent sequence , provided that @xmath697 . consider a `` smooth '' indicator function @xmath698 $ ] such that @xmath197 for @xmath198 and @xmath199 for @xmath699 fix any @xmath201 and define @xmath202 with @xmath203 .",
    "the conclusion follows from the proof of corollary f.1 in @xcite and lemma 2.1 in @xcite regarding the anti - concentration property for gaussian distribution .",
    "we omit the details to conserve the space .",
    "let @xmath700 .",
    "define @xmath701 and @xmath702 .",
    "using the fact that @xmath230 and @xmath231 are independent for any @xmath703 and @xmath704 , we obtain for @xmath705 , @xmath706 using the fact that the map @xmath707 is lipschitz continuous , we deduce that @xmath708 note for @xmath709 @xmath710 .",
    "it is not hard to show that the above result holds if @xmath230 ( or @xmath711 ) is replaced by its @xmath712 ( or @xmath713 ) .",
    "therefore by ( [ eq : cov - ts ] ) and the assumptions , we have @xmath714|\\lesssim ( 1/m_x+1/m_y).\\end{aligned}\\ ] ] thus we may set @xmath715 for some constant @xmath716    next we consider @xmath717 . by the stationarity , we have @xmath718 also note that @xmath719 and @xmath720 . because @xmath721 and @xmath722 by ( [ eq : varphi ] ) , we can choose @xmath723 for some constant @xmath724 . by the assumption",
    "that @xmath725 and the fact that @xmath726 , we have @xmath727 , @xmath728 and @xmath729 using similar arguments , we can show that @xmath730 for some constant @xmath731 .",
    "the above argument also implies that @xmath732 thus we ignore the constants and set @xmath733 and @xmath734      under condition ( 1 ) in assumption [ assum : tail ] , @xmath238 . by lemma 2.2 in @xcite , we have @xmath739 and @xmath740 because @xmath741 , we can always choose @xmath742 such that @xmath743 using similar arguments , we can prove the result under condition ( 2 ) in assumption [ assum : tail ] . the proof is thus completed .",
    "define the projection @xmath746-{{\\mathbb{e}}}[x_{ik}|\\mathcal{f}_{j-1}(i)]$ ] .",
    "then we have @xmath747-{{\\mathbb{e}}}[\\mathcal{g}_k(\\dots,\\epsilon_{l},\\epsilon_{l+1})|\\mathcal{f}_{l-1}(l+1 ) ] = \\sum^{m}_{j = l}\\mathcal{p}_jx_{(l+1)k}.\\end{aligned}\\ ] ] note that @xmath748-{{\\mathbb{e}}}[x_{ik}|\\mathcal{f}_{j-1}(i ) ] \\\\=&{{\\mathbb{e}}}[\\mathcal{g}_k(\\dots,\\epsilon_{i-1},\\epsilon_i)-\\mathcal{g}_k(\\dots,\\epsilon_{i - j}',\\epsilon_{i - j+1},\\dots,\\epsilon_{i-1},\\epsilon_i)|\\mathcal{f}_j(i ) ] \\\\=&{{\\mathbb{e}}}[\\mathcal{g}_k(\\dots,\\epsilon_{j-1},\\epsilon_j)-\\mathcal{g}_k(\\dots,\\epsilon_{0}',\\epsilon_{1},\\dots,\\epsilon_{j-1},\\epsilon_j)|\\mathcal{f}_j(j)].\\end{aligned}\\ ] ] jensen s inequality yields that @xmath749 which implies that @xmath750 therefore , we obtain @xmath751    we need to verify that the @xmath0-dependent approximation @xmath752 satisfies the assumptions in theorem [ thm2 ] . using the convexity of @xmath318 and jensen s inequality we have @xmath753 under condition ( 1 ) in assumption [ assum : tail ] , and @xmath754 under condition ( 2 ) in assumption [ assum : tail ] .",
    "we claim that as @xmath755 @xmath756 which implies that @xmath757 and @xmath758 with @xmath759 and @xmath760 . thus under the assumptions in theorem [ thm : gaussian - dep ]",
    ", we have @xmath761 for some constants @xmath214 uniformly for all large enough @xmath0 .",
    "to show ( [ eq : thm : gaussian - dep ] ) , we note that @xmath762 for the first term , we have @xmath763 where we have used the fact that @xmath764 and @xmath765 . under the assumption that @xmath766 , we have @xmath767 as @xmath768 on the other hand , note that for @xmath769 @xmath770 thus we have @xmath771 which implies that @xmath772 as @xmath773    lemma [ lemma : m - dep ] verifies the first condition in ( [ eq : condition ] ) .",
    "the same arguments apply to @xmath149 .",
    "the triangle inequality and ( [ eq : m - approx ] ) imply that @xmath774 with @xmath775 being the @xmath0-dependent approximation for @xmath149 .",
    "the conclusion thus follows from theorem [ thm1 ] and theorem [ thm2 ] .",
    "next we analyze @xmath781 and @xmath782 . under the assumptions in corollary 2.1 of @xcite",
    ", we have @xmath783 notice that in this case , we allow @xmath261 with @xmath262 ( assuming that @xmath263 in corollary 2.1 of @xcite ) . by ( [ eq : dim - free1 ] ) , and the independence between @xmath356 and @xmath357 , we obtain @xmath784 \\lesssim \\sum^{q}_{j=1}{{\\mathbb{e}}}\\left[p_y\\left(\\max_{q+1\\leq i\\leq p}y_i < x_j\\right)\\right]+qn^{-c},\\end{aligned}\\ ] ] where @xmath785 denotes the probability measure with respect to @xmath786 .",
    "let @xmath787 . using the concentration inequality",
    "( see e.g. ( 7.3 ) of @xcite and theorem a.2.1 of @xcite ) , @xmath788 for @xmath789 , we have @xmath790 where @xmath791 . under the assumption that @xmath792 we can choose @xmath793 such that @xmath794 and @xmath795 .",
    "then we have @xmath796\\leq \\sum^{q}_{j=1}{{\\mathbb{e}}}\\exp\\left(-\\frac{1}{2\\bar{\\sigma}}\\left({{\\mathbb{e}}}\\max_{q+1\\leq i\\leq p}y_i - x_j\\right)^2_+\\right ) \\\\",
    "\\leq & \\sum^{q}_{j=1}{{\\mathbb{e}}}\\exp\\left(-\\frac{1}{2\\bar{\\sigma}}\\left({{\\mathbb{e}}}\\max_{q+1\\leq i\\leq p}y_i - x_j\\right)^2_+\\right)\\mathbf{i}\\{x_j\\leq \\widetilde{q}\\}+ \\sum^{q}_{j=1}{{\\mathbb{e}}}\\mathbf{i}\\{x_j>\\widetilde{q}\\ } \\\\",
    "\\leq & \\exp\\left(\\log q-\\frac{1}{2\\bar{\\sigma}}\\left({{\\mathbb{e}}}\\max_{q+1\\leq i\\leq p}y_i-\\widetilde{q}\\right)^2_+\\right)+q\\max_{1\\leq j\\leq q}{{\\mathbb{e}}}|x_j|/\\widetilde{q}=o(1).\\end{aligned}\\ ] ] moreover , if @xmath797 for @xmath798 , we can replace @xmath799 by @xmath800 for some @xmath455 thus we get @xmath801+qn^{-c } \\lesssim n^{-c''}.\\end{aligned}\\ ] ] similar argument applies to @xmath802 and the conclusion follows from ( [ eq : dim - free1 ] ) .",
    "note that for any @xmath804 @xmath805 is a sequence of i.i.d random variables .",
    "let @xmath806 and @xmath807 . then by lemma a.1 in @xcite ,",
    "we have @xmath808 cauchy - schwarz inequality yields that @xmath809        by theorem [ thm2 ] , @xmath814 choosing @xmath815 for some @xmath816 we have @xmath817 . pick @xmath818 with @xmath819 then it is easy to verify that the terms @xmath820 and @xmath821 are both of order @xmath800 with @xmath822 . finally by ( [ eq : boot ] ) ,",
    "we have @xmath823 the result under condition 2 can be proved in a similar manner .",
    "let @xmath279 be the @xmath0-dependent approximation sequence for @xmath269 .",
    "define @xmath824 , @xmath825 , @xmath826 and @xmath827 in a similar way as @xmath188 , @xmath189 , @xmath828 and @xmath829 by replacing @xmath269 with @xmath279 .",
    "notice that @xmath830    by lemma a.1 of @xcite , we have @xmath831 for some @xmath291 .",
    "it follows that @xmath832 similarly we have @xmath833 using similar arguments in the proof of theorem [ thm : gaussian - dep ] , we have @xmath834 thus by ( [ eq : boot ] ) , we have @xmath835    then by lemma a.1 in @xcite , we have @xmath836 where the first two terms can be bounded using similar arguments in the proof of lemma [ lemma : m - dep - boot ] , and the last two terms decay exponentially .",
    "the same arguments apply to the terms associated with @xmath189 .    by theorem [ thm : gaussian - dep ]",
    ", we have @xmath837 the assumption that @xmath328 for @xmath306 , and @xmath838 with @xmath404 implies that @xmath839 decays exponentially .",
    "the rest of the proof is similar to those in the proof of theorem [ lemma : m - dep - boot ] .",
    "our arguments below apply to @xmath0-dependent time series , and can be easily extended to weakly dependent time series by employing the @xmath0-approximation techniques ( that incurs only an asymptotically ignorable error ) .",
    "let @xmath840 , @xmath841 , and @xmath593 be some generic constants which can be different from line to line .",
    "define @xmath842 following the arguments in the proof of lemma [ lemma : m - dep - boot ] , we have @xmath843 similarly we can show that @xmath844 where we have used the fact that @xmath845    by markov s inequality , we have with probability @xmath440 , @xmath846 uniformly for @xmath172 it implies that with probability @xmath440 , @xmath847 . by ( [ eq : block - boot ] ) , we have with probability with @xmath440 , @xmath848 for some small @xmath849 because @xmath443 , we can apply corollary 2.1 in @xcite to conclude that with probability @xmath440 , @xmath850    next , notice that @xmath851 with probability @xmath440 , we have @xmath852 . using the tail property of standard normal distribution , we can choose @xmath853 such that with probability @xmath854 , @xmath855 and @xmath856 for some properly chosen @xmath841 and @xmath857 .",
    "therefore by lemma 2.1 in @xcite , we obtain that with probability @xmath440 , @xmath858 by ( [ eq : block1 ] ) and ( [ eq : block2 ] ) , ( [ eq : equi ] ) holds with probability @xmath440 .",
    "the second part of the theorem follows from theorem [ thm : m - dep - boot ] and theorem [ thm : dep - boot ] .",
    "define @xmath859 where @xmath860 and @xmath861 since @xmath862 we have @xmath863 let @xmath864 and @xmath865 for some large enough @xmath593 and small enough @xmath840 ( e.g. @xmath866 ) such that @xmath867 we show that @xmath868 because @xmath869 and @xmath870 conditional on @xmath871 , we have @xmath872\\leq c'\\sqrt{\\mathcal{e}_{ab}\\log(2q_0)}$ ] for some large enough constant @xmath873 it thus implies that @xmath874>\\zeta_1\\zeta_2 ) \\\\",
    "\\leq & p(\\mathcal{e}_{ab}\\{c'\\log(2q_0)\\}^2>c^4n^{-4c})\\leq cn^{-c},\\end{aligned}\\ ] ] for large enough @xmath593 and sufficiently small @xmath840 ( e.g. @xmath875 ) . by theorem [ thm : dep - boot ] , and lemma 3.3 and the arguments in the proof of theorem 3.2 in @xcite , we derive that under @xmath876 @xmath877 for @xmath878 , where @xmath879 or @xmath857 , which are defined in theorem [ thm : dep - boot ] .",
    "denote by @xmath883 the @xmath884 quantile of the distribution of @xmath885 conditional on the sample @xmath886 .",
    "let @xmath864 and @xmath865 for @xmath887 and @xmath888 with @xmath889 .",
    "assumption [ assum : app-2 ] and lemma 3.3 of @xcite imply that @xmath890 and thus @xmath891 then on the event @xmath892 , we have @xmath893 the conclusion follows from similar arguments in the proof of theorem [ thm : block - boot ] .",
    "below we provide some primitive conditions under which assumption [ assum : band ] holds . to this end , we consider a @xmath0-dependent stationary sequence @xmath3 , where @xmath0 is allowed to grow with the sample size .",
    "let @xmath915 we shall show that @xmath916 similar arguments apply to @xmath917 note that @xmath918 where the value of @xmath919 will be determined later . on the events @xmath920 and @xmath906 , we have @xmath921 we also note that @xmath922 the conclusion therefore follows provided that @xmath923 @xmath924 and @xmath925 for some @xmath926      in this section , we extend the results in section [ subsec : dep - graph ] to general smooth functions @xmath927 on the high - dimensional vector sum .",
    "we impose the following assumption  [ assum : general - g ] regarding the smoothness of @xmath928 .",
    "write @xmath929 , @xmath930 and @xmath931 for @xmath606 , where @xmath607 .",
    "[ assum : general - g ] suppose that @xmath932 where the constants @xmath933 , @xmath934 and @xmath935 do not depend on @xmath936 .",
    "further assume that for any @xmath937 with @xmath938 for some set @xmath939 , @xmath940 where @xmath941 here ,  @xmath942 \" means @xmath943 up to a universal constant .",
    "[ example : general - g ] consider @xmath944 , where @xmath658 and @xmath945 is a thresholding parameter .",
    "here we assume that @xmath946 for @xmath947 and @xmath948 satisfies that @xmath949 for some constant @xmath716 it is straightforward to verify that @xmath950 , @xmath951 and @xmath952 for @xmath941 note that with proper choice of @xmath948 , @xmath953 provides a smooth approximation to the function @xmath954 which serves as a building block for the higher criticism test in @xcite .",
    "assumption [ assum : general - g ] generalizes the results in lemmas a.5 and a.6 of @xcite .",
    "consider the dependency graph in section [ subsec : dep - graph ] .",
    "parallel to proposition [ prop1 ] , we have the following result . with slightly abuse of notation , set @xmath955 with @xmath113 .",
    "[ prop3 ] assume that @xmath956 with @xmath139 .",
    "then under assumption [ assum : general - g ] , we have for any @xmath140 @xmath957|\\lesssim \\{g_2l^2_1(p)+g_1l_2(p)\\}\\phi(m_x , m_y)\\\\&+\\{g_3l_1 ^ 3(p)+3g_2l_1(p)l_2(p)+g_1l_3(p)\\}\\frac{d_n^{2}}{\\sqrt{n}}(\\bar{m}_{x,3}^3+\\bar{m}_{y,3}^3 ) \\\\&+\\{g_3l_1 ^ 3(p)+3g_2l_1(p)l_2(p)+g_1l_3(p)\\}\\frac{d_n^{3}}{\\sqrt{n}}(m_{x,3}^3+m_{y,3}^3)+g_1\\delta+g_0{{\\mathbb{e}}}[1-\\mathcal{i } ] , \\end{split}\\ ] ] where @xmath142 for @xmath143 . in addition , if @xmath958 , we can replace @xmath145 by @xmath146 in the above upper bound .    with the aid of assumption [ assum : general - g ] ,",
    "proposition [ prop3 ] follows from similar arguments in the proof of proposition [ prop1 ] ( the technical details are omitted to conserve space ) .",
    "when specialized to stationary @xmath0-dependent time series , we have the following result .",
    "[ thm - general - g ] suppose @xmath959 with @xmath139 , and @xmath211 and @xmath212 for some @xmath213 .",
    "then @xmath960 under condition ( [ eq : m - dep - couple ] ) , we may set @xmath961 and @xmath962 for some constants @xmath963 in ( [ eq : general - g - m - dep ] ) .    [ os : rem ] consider @xmath944 in example [ example : general - g ] . when @xmath211 and @xmath212 for some @xmath964 we have @xmath965 where @xmath966 .",
    "under condition ( [ eq : m - dep - couple ] ) , @xmath967 by letting @xmath968 , @xmath969 , and @xmath970 , we deduce that @xmath971|\\lesssim m^2(\\bar{m}_{x,3}^3+\\bar{m}_{y,3}^3)/\\sqrt{n}$ ] .",
    "note that in this case , @xmath2 is allowed to grow arbitrarily ."
  ],
  "abstract_text": [
    "<S> this article studies bootstrap inference for high dimensional weakly dependent time series in a general framework of approximately linear statistics . </S>",
    "<S> the following high dimensional applications are covered : ( 1 ) uniform confidence band for mean vector ; ( 2 ) specification testing on the second order property of time series such as white noise testing and bandedness testing of covariance matrix ; ( 3 ) specification testing on the spectral property of time series . in theory </S>",
    "<S> , we first derive a gaussian approximation result for the maximum of a sum of weakly dependent vectors , where the dimension of the vectors is allowed to be exponentially larger than the sample size . </S>",
    "<S> in particular , we illustrate an interesting interplay between dependence and dimensionality , and also discuss one type of  dimension free \" dependence structure . </S>",
    "<S> we further propose a blockwise multiplier ( wild ) bootstrap that works for time series with unknown autocovariance structure . </S>",
    "<S> these distributional approximation errors , which are finite sample valid , decrease polynomially in sample size . </S>",
    "<S> a non - overlapping block bootstrap is also studied as a more flexible alternative . </S>",
    "<S> the above results are established under the general physical / functional dependence framework proposed in wu ( 2005 ) . </S>",
    "<S> our work can be viewed as a substantive extension of chernozhukov et al . </S>",
    "<S> ( 2013 ) to time series based on a variant of stein s method developed therein .    and    blockwise bootstrap , gaussian approximation , high dimensionality , physical dependence measure , slepian interpolation , stein s method , time series . </S>"
  ]
}