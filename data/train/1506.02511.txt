{
  "article_text": [
    "turbulence , though governed by navier - stokes equations , is extremely hard to predict due to its spatiotemporally intermittency as well as three - dimensional and irregular properties .",
    "it is also a multi - scale phenomenon where a very wide range of scales from the largest eddies to kolmogorov micro - scales co - exist and interact . since the ratio between the largest and the smallest scales increases with reynolds number as @xmath0 , flows with high reynolds are the most challenging .",
    "wall bounded flows are particularly difficult to model due to the overlap of several scaling regions as a function of distance to the wall .",
    "coherent structures in such flows can extend up to several boundary layer thickness .",
    "the modeling of such structures and scales therefore requires extremely detailed flow information in both space and time .    despite a constant progress ,",
    "none of the experimental techniques , even in academic researches , is capable of providing spatiotemporally resolved information in sufficiently wide spatial domains and for diverse flow conditions .",
    "particle image velocimetry ( piv ) , the most advanced turbulence measurement technique , can not measure space - time resolved velocities .",
    "stereoscopic piv measures three - component velocities at high spatial resolution and large field - of - view , but limited to a low acquisition rate compared to the flow dynamics .",
    "high repetition tomographic piv and time - resolved piv ( trpiv ) are improving but still limited to small volumes and low speed flows . other point - measurement techniques such as hot wire anemometry ( hwa )",
    "measure the full temporal dynamics .",
    "however , the combination of these devices to get a better spatial resolution is not straightforward and remains intrusive",
    ".    direct numerical simulation ( dns ) can provide reliable and fully resolved velocities of turbulent flows .",
    "it simulates the flows by directly solving navier - stokes equations .",
    "the computational cost of such a numerical approach is very high since the number of simulated grid points increases as @xmath1 .",
    "dns therefore can simulate flows with low to moderate reynolds and simple geometries only .    to have fully resolved velocities",
    ", one idea is to measure and combine two types of complementary measurements in space and time : the low - temporal - high - spatial resolution ( lths ) and the high - temporal - low - spatial resolution ( htls ) measurements .",
    "one particular example of such an idea is presented in ref .",
    "this joint experiment provides a database of high reynolds boundary layer flows .",
    "the data are provided by a stereoscopic piv synchronized with a rake of hwa probes .",
    "piv is with a large field - of - view and at a high spatial resolution but at low acquisition frequency .",
    "hwa measurements are at an extremely high temporal resolution , but the spatial discretization of the rake of probes is very coarse compared to kolmogorov scales .",
    "various methods have been proposed to combine such measured data of turbulent flows to recover the maximum information level .",
    "linear stochastic estimation ( lse ) is the most common one .",
    "its introduction into turbulence community dates back to the works by adrian @xcite and has been further investigated later @xcite .",
    "these works use lse as a tool to extract coherent structures from the measurements .",
    "later works proposed various extensions such as multi - time , nonlinear or higher - order lse @xcite . in these works ,",
    "unknown velocities are reconstructed from measurements of other quantities such as pressure or shear - stress .",
    "lse can be also linked to proper orthogonal decomposition ( pod ) to reduce the order of reconstruction problems @xcite .",
    "the idea of combining sparse velocity measurements to obtain fully - resolved fields has not been addressed until recently @xcite . in ref .",
    "@xcite , 3d smoke intensity and 2d piv measurements are combined using a pod - lse model to get fully resolved 3d velocities of a flow over a flat plate .",
    "pod - lse estimation model has been developed further @xcite with a reconstruction scheme based on a multi - time lse .",
    "either a kalman filter or a kalman smoother is used depending on the problem as real time estimation or data post processing .",
    "the model is tested using trpiv measurements of a bluff - body wake at a low reynolds number .",
    "sparse velocity measurements are virtually extracted from the high resolution ones , while original data are used to estimate reconstruction errors .",
    "lse suffers from critical limitations though extensively used .",
    "first , as a conditional average , lse estimates a set of coefficients that associate the so - called conditional eddies to one flow pattern @xcite .",
    "using these coefficients to reconstruct all velocity fields , lse fails to capture coherent structures and misleads physical interpretations when particular patterns exist .",
    "second , the reconstructed structures are independent of event magnitudes @xcite .",
    "reconstructed flows are associated with weak fluctuations only .",
    "last , lse as a low pass filter reconstructs large scales only and lose flow details even at measured positions .",
    "sketch of an element block with local coordinates @xmath2 .",
    "lths time steps are at @xmath3 and @xmath4 .",
    "htls measurements are represented by red dots and lths measurements by black ones . ]",
    "sketch of an element block with local coordinates @xmath2 .",
    "lths time steps are at @xmath3 and @xmath4 .",
    "htls measurements are represented by red dots and lths measurements by black ones . ]",
    "the present work proposes a novel model to reconstruct the fully resolved hths velocities from htls and lths measurements .",
    "this model is based on a bayesian inference framework using a maximum a posteriori ( map ) estimate @xcite .",
    "it is inspired by the multispectral image fusion problem with the limited resolution of image measurements in space - wavelength domains @xcite .",
    "this framework has been discussed early in communication problems @xcite and is used more extensively in image processing , remote - sensing , and data fusion @xcite .",
    "the bayesian fusion model takes benefit from both sources of information in space and time simultaneously by searching for the most probable flow for given measurements .",
    "better performances are expected since space and time correlations are equally important .",
    "the model also recovers flow details inaccessible from single interpolations . by integrating directly the measurements",
    ", it proposes a compromise estimate such that detailed flow information close to the sensor positions are well preserved .",
    "this approach also overcomes the limitations of lse , which acts as a low pass filter due to the mean square error minimization . to test the model , the dns database of a turbulent wall - bounded flow",
    "these space - time fully resolved data allow the model optimization and validation .",
    "sparse measurements of htls and lths are extracted from the full dataset , while the reference dns data are used in the end to evaluate reconstruction errors .",
    "performances are evaluated for various configurations with different subsampling ratios .",
    "the paper is organized as follows .",
    "section [ sec : bayesian_fusion_model ] presents the bayesian model using a map estimate .",
    "model simplification and statistical parameters estimation are also discussed .",
    "section [ sec : numerical_experiments ] describes the dns database used to test the model and also other reconstruction methods for comparison .",
    "results for various configurations are presented .",
    "conclusions and future works are in section [ sec : conclusions ] .",
    "l p11 cm @xmath5 & @xmath6dimensional vector of hths dns data + @xmath7 & @xmath8dimensional vector of htls measurements + @xmath9 & @xmath10dimensional vector of lths measurements + @xmath11 & number of spatial points in each hths / lths snapshot + @xmath12 & number of spatial points in each htls snapshot + @xmath13 & number of hths or htls snapshots + @xmath14 & number of lths snapshots + @xmath15 & 1d cubic spline interpolator in time + @xmath16 & 2d cubic spline interpolator in space + @xmath17 & subsampling in time from p to q snapshots , @xmath18 + @xmath19 & subsampling in space from n to m points , @xmath20 + @xmath21 & 2d 5th - order least - square spline filter in space + @xmath22 & 1d 5th - order least - square spline filter in time + @xmath23 & loss of kinetic energy computed using eq .  (",
    "[ eq : rms_losses ] ) + @xmath24 & normalized root mean square error ( nrmse ) defined in eq .",
    "( [ eq : nrmse ] ) + @xmath25 & determinant of a matrix + @xmath26 & transpose of vector @xmath27 + @xmath28 & argument of the maximum , which is @xmath5 for which the function attains its maximum + @xmath29 & square of a mahalanobis distance : @xmath30 + @xmath31 & square of a euclidean distance : @xmath32 + @xmath33 & gaussian noise vector of zero - mean and covariance matrix @xmath34 + @xmath35 & gaussian distribution of variable @xmath27 that takes the mean @xmath36 and fluctuates due to @xmath37 of covariance @xmath34 + @xmath38 & distribution of @xmath27 knowing ( or conditioning on ) @xmath39 +      let @xmath40 and @xmath41 denote lths and htls measurements , and @xmath42 denote hths data to reconstruct .",
    "@xmath42 , @xmath40 and @xmath41 are random , zero - mean vectors of size @xmath43 , @xmath44 and @xmath45 respectively . @xmath11 and @xmath12 are numbers of spatial points in each snapshot , while @xmath13 and @xmath14 are numbers of snapshots . the present work is a challenging inverse problem since we consider @xmath46 and @xmath47 . let the subscript `` s '' denote operators performing in space , and `` t '' be those in time ; @xmath48 is an interpolator ; @xmath49 is for subsampling ; @xmath50 is a low - pass filter ( lpf ) .",
    "the cubic spline interpolation either 1d or 2d is used as @xmath48 for its state - of - the - art interpolation results and finite support @xcite .",
    "@xmath50 is a 5th - order least - square spline filter @xcite for its sharp cutoff response to better separate large scales from small scales .",
    "table  [ tab : summary_of_notations ] lists all notations used in this paper .",
    "given sparse measurements of either @xmath7 in space or @xmath9 in time , the fully resolved vector @xmath5 can be reconstructed by single interpolations .",
    "the 1d time interpolation goes from @xmath51 to @xmath52 dimensional space , i.e. @xmath53 , while the 2d space interpolation goes from @xmath54 to @xmath52 dimensional space , i.e. @xmath55 .",
    "let @xmath52 dimensional vectors @xmath56 and @xmath57 denote the information that can not be recovered by simple interpolations ; @xmath58 can be modeled in two ways : @xmath59 missing information @xmath57 and @xmath56 essentially feature small scales . using either @xmath9 or @xmath7 , it is not possible to estimate @xmath57 and @xmath56 .",
    "the idea of bayesian fusion is to combine the two models by using @xmath60 in ( [ eq : bayes11 ] ) to estimate the unknown @xmath56 in  ( [ eq : bayes12 ] ) and vice - versa .",
    "let @xmath61 denote the multivariate gaussian distribution of a @xmath52 dimensional random vector @xmath27 with mean value @xmath62 and covariance matrix @xmath63 .",
    "the @xmath64 matrix is the expectation of @xmath65 .",
    "the probability density function ( pdf ) of @xmath27 with a multivariate gaussian distribution @xmath66 is : @xmath67 where @xmath25 denotes the matrix determinant , and @xmath68 is the mahalanobis distance : @xmath69 let assume that @xmath60 and @xmath57 are approximately independent ; @xmath60 captures temporal large scales of @xmath9 .",
    "similarly , @xmath70 and @xmath56 are assumed to be approximately independent . due to subsampling ,",
    "aliasing terms are also present in each pairs of @xmath71 and @xmath72 .",
    "assume also that @xmath57 and @xmath56 are zero mean gaussian noises , i.e. @xmath73 and @xmath74 .",
    "pdfs of these unknowns are modeled as : @xmath75 and similarly for @xmath76 .",
    "posterior distributions of @xmath5 knowing either @xmath9 or @xmath7 are then modeled as : @xmath77 where @xmath78 , resp .",
    "@xmath78 , is the posterior distribution of @xmath5 knowing @xmath9 , resp . knowing @xmath7 .",
    "the present bayesian model aims to build an estimate of @xmath5 given @xmath9 and @xmath7 using the probability models ( [ eq : bayes21 ] ) and ( [ eq : bayes22 ] ) .",
    "the model uses a map estimate to search the most probable @xmath79 given @xmath40 and @xmath7 such that @xmath79 maximizes the posterior pdf @xmath80 : @xmath81 using bayesian rules @xcite , one has : @xmath82 assuming that @xmath9 and @xmath7 are independent conditioned on @xmath5 , eq .",
    "( [ eq : map2 ] ) becomes : @xmath83 in eq .",
    "( [ eq : map3 ] ) , the likelihood functions @xmath84",
    ", @xmath85 and the prior pdf @xmath86 appear , while only the posterior probabilities @xmath87 and @xmath88 are available in  ( [ eq : bayes21 ] ) and  ( [ eq : bayes22 ] ) .    to complete the model , the likelihood functions can be expressed in term of the posterior pdfs and prior of @xmath5 using bayesian rules .",
    "section 2.3.3 in ref .",
    "@xcite introduces an alternative way to estimate these functions from posterior pdfs using a linear gaussian model .",
    "various tests of different gaussian priors @xmath86 lead to the use of a noninformative prior .",
    "this prior , referred also as vague or flat prior , assumes that all the values of @xmath5 are equally likely @xcite .",
    "the estimation of @xmath79 is now solely based on the measurements and not influenced by external information .",
    "the prior distribution therefore has no influence on the posterior pdfs .    with the assumption of a noninformative prior",
    ", @xmath86 is constant . using bayes rules ,",
    "the relation between the likelihood function and the posterior pdf is : @xmath89 since @xmath86 is replaced by a constant , one gets @xmath90 .",
    "similarly , @xmath91 . eq  ( [ eq : map3 ] ) becomes : @xmath92 the map estimation is : @xmath93 logarithms of @xmath94 and @xmath95 are : @xmath96 where @xmath97 and @xmath98 are independent of @xmath9 , @xmath7 and @xmath5 . solving ( [ eq : map_5 ] ) is equivalent to minimize the cost function : @xmath99 computing the gradient of @xmath100 and setting to zero : @xmath101 the solution to the optimization problem ( [ eq : map1 ] ) is : @xmath102 applying the matrix inversion lemma @xcite : @xmath103 eq .",
    "( [ eq : map9 ] ) can be rewritten as : @xmath104 eq .  ( [ eq : map10 ] ) is the final full form of the proposed bayesian fusion model using a map estimate and assuming a noninformative prior of @xmath5 .",
    "variance matrices @xmath105 and @xmath106 are parameters to be estimated .      though providing the full theoretical estimate of @xmath79 , eq .",
    "( [ eq : map10 ] ) is impractical to use as is for several reasons .",
    "the full covariance matrices @xmath105 and @xmath106 , representing all the sources of correlations in space and time , can not be estimated from only the measurements @xmath9 and @xmath41 .",
    "this is because the unknown @xmath57 and @xmath56 are only accessible at the measured positions in space and time .",
    "also , the covariance matrices of size @xmath64 are very large , making them very difficult to accurately estimate and to inverse . additional assumptions on the shape of @xmath105 and @xmath106 are necessary .    a common and simple approach is to assume diagonal covariance matrices .",
    "this implies the independence between all elements of @xmath57 and @xmath56 . the simplified version of eq .",
    "( [ eq : map10 ] ) becomes a point - wise formula : @xmath107 where @xmath108 is the index of each point in time @xmath109 and space @xmath110 .",
    "the variances @xmath111 and @xmath112 are functions of each position in space and time .",
    "their estimation is detailed in next section .",
    "tehn eq .",
    "( [ eq : map_simplified ] ) will be used to reconstruct hths data . as a weighted average ,",
    "it proposes a compromise estimate from the measurements . with a symmetrical form in space and time ,",
    "the model uses information from both measurements to correct large scales reconstruction and recover certain information at smaller scales .",
    "let @xmath113 , @xmath114 , @xmath115,@xmath116 , @xmath117 , @xmath118 and @xmath119 be the ( time , space ) matrix forms of @xmath5 , @xmath9 , @xmath7 , @xmath57 , @xmath56 , @xmath120 and @xmath121 respectively .",
    "@xmath113 , @xmath116 , @xmath117 , @xmath118 and @xmath119 are of size @xmath122 , while @xmath114 and @xmath115 are of size @xmath123 and @xmath124 .",
    "@xmath118 and @xmath119 are matrices of empirical variances , which are functions of time and space @xmath125 .",
    "variance matrices are estimated from @xmath116 and @xmath117 , which are available at the measurements positions only .",
    "we use : @xmath126 where @xmath17 subsamples in time from @xmath13 to @xmath14 time steps , and @xmath19 subsamples in space from @xmath11 to @xmath12 points .",
    "these q instants and m positions are the same as for lths and htls measurements .",
    "since the flow is approximately stationary and spatial interpolation is independent of time , @xmath127 becomes @xmath128 , a function of spatial locations only .",
    "these variances are estimated by averaging over all time steps : @xmath129 variance in @xmath130 is a function of distances @xmath131 to the previous lths time step only , where @xmath132 , and @xmath133 is the time lag between two consecutive hths time steps .",
    "@xmath118 becomes a function of space and @xmath131 only , i.e. @xmath134 .",
    "it is estimated by averaging over q blocks ( of @xmath135 snapshots ) bounded by two consecutive lths instants : @xmath136 where @xmath137 . since the flow is approximately homogeneous in spanwise direction , @xmath128 and @xmath134",
    "are also averaged over all blocks defined by the four neighboring htls measurements , see fig .",
    "[ fig : element_block ] .",
    "the variances are then functions of only vertical positions and relative distances to the four closest htls sensors .",
    "these estimated variances are rearranged into a vector form @xmath138 and @xmath139 to complete the fusion model using the simplified formula in eq .",
    "( [ eq : map_simplified ] ) .    0.8|c|cc|cc|cc|cccc|cccc| & & & & & +    ' '' ''    case & @xmath140 & @xmath141 & @xmath142 & @xmath143 & @xmath144 & @xmath145 & @xmath146 & @xmath147 & lse & fusion & @xmath146 & @xmath147 & lse & fusion + 1 & 05 & 10 & 0.05 & 0.25 & 0.29 & 4.70 & 0.14 & 0.32 & 0.25 & * 0.12 * & * 0.16 * & 0.56 & 0.33 & * 0.16 * + 2 & 05 & 20 & 0.05 & 0.50 & 0.29 & 13.12 & 0.14 & 0.54 & 0.38 & * 0.13 * & * 0.16 * & 0.89 & 0.49 & * 0.16 * + 3 & 10 & 04 & 0.11 & 0.10 & 5.03 & 0.50 & 0.36 & * 0.11 * & 0.30 & * 0.11 * & 0.47 & * 0.17 * & 0.37 & 0.18 + 4 & 20 & 04 & 0.22 & 0.10 & 9.99 & 0.50 & 0.68 & * 0.11 * & 0.57 & * 0.11 * & 0.86 & * 0.17 * & 0.68 & * 0.17 * + 5 & 05 & 04 & 0.05 & 0.10 & 0.29 & 0.50 & 0.14 & 0.11 & 0.13 & * 0.08 * & 0.16 & 0.18 & 0.15 & * 0.13 * + 6 & 10 & 10 & 0.11 & 0.25 & 5.03 & 4.68 & 0.36 & 0.32 & 0.34 & * 0.25 * & 0.47 & 0.55 & 0.49 & * 0.43 * + 7 & 20 & 20 & 0.22 & 0.50 & 9.99 & 13.12 & 0.68 & 0.54 & 0.64 & * 0.46 * & 0.85 & 0.85 & 0.78 & * 0.73 * +    0.6|c|cccc|cccc| & & + & @xmath146 & @xmath147 & lse & fusion & @xmath146 & @xmath147 & lse & fusion +   + 5 & 0.08 & 0.09 & 0.10 & * 0.05 * & * 0.06 * & 0.15 & 0.11 & 0.07 + 6 & 0.24 & 0.25 & 0.24 & * 0.15 * & 0.22 & 0.45 & 0.28 & * 0.21 * + 7 & 0.56 & 0.36 & 0.51 & * 0.30 * & 0.60 & 0.66 & 0.60 & * 0.46 * +   + 5 & 0.98 & 0.56 & 0.73 & * 0.55 * & 0.98 & 0.86 & 0.89 & * 0.81 * + 6 & 0.98 & 0.81 & 0.90 & * 0.70 * & 0.97 & 1.15 & 1.07 & * 0.92 * + 7 & 0.99 & 0.92 & 0.95 & * 0.78 * & 0.93 & 1.08 & 0.90 & * 0.86 * +",
    "section  [ subsec : database ] describes the dns database used to test the model .",
    "section  [ subsec : other_reconstruction_methods ] discusses other reconstruction methods for comparison .",
    "section  [ subsec : results ] presents results of the fusion model in various cases .",
    "dns database of a turbulent wall - bounded flow is used to test the model .",
    "this simulation uses the numerical procedure described in @xcite .",
    "the flow is at a reynolds number @xmath148 based on the friction velocity .",
    "cartesian coordinates of the simulation in space are @xmath149 for streamwise , vertical and spanwise directions respectively .",
    "the domain size @xmath150 normalized by half the channel height @xmath151 is @xmath152 .",
    "fully resolved fluctuating streamwise velocities in a plane normal to the flow direction are considered as hths data .",
    "this data includes @xmath153 snapshots at spatial resolution of @xmath154 and at sampling frequency of 40 hz .",
    "sparse lths and htls measurements are subsampled from hths data to learn the fusion model .",
    "hths is used as the ground truth to estimate reconstruction errors .",
    "the extension to spanwise and vertical velocity components follows the same procedure .",
    "various cases are investigated . the subsampling ratios @xmath155 applied in each direction of space are 5 , 10 and 20 .",
    "these ratios correspond to a number @xmath12 of htls sensors of @xmath156 , @xmath157 and @xmath158 respectively .",
    "each ratio has a spacing between two successive htls points in spanwise and vertical directions of @xmath159 and @xmath160 . subsampling ratios @xmath135 in time are 4 ( @xmath161 ) , 10 ( @xmath162 ) and 20 ( @xmath163 ) .",
    "each ratio , both in space and time , corresponds to a certain amount of energy loss .",
    "this is essentially the energy of small scales separated from large scales by a low pass filter @xmath50 . here",
    "@xmath50 is the @xmath164order least square spline filter , either temporal 1d ( @xmath22 ) or spatial 2d ( @xmath21 ) , using measurements as knots .",
    "this spline filter has the advantages of a sharp cutoff response and finite support .",
    "the energy loss is defined by comparing the filtered field @xmath165 and the original field @xmath5 : @xmath166_j^2}}}{\\sqrt{\\sum\\limits_{j\\in \\varmathbb{j}}\\boldsymbol{z}_j^2 } }      \\label{eq : rms_losses}\\ ] ] where @xmath167 is the considered set of points . table  [ tab : results ] gathers the energy loss in time ( @xmath168 ) and in space ( @xmath169 ) estimated with @xmath22 and @xmath21 respectively .",
    "the set @xmath167 contains all points at @xmath170 .",
    "other reconstruction methods are used for comparison with the present model .    *",
    "cubic spline interpolation * : interpolation techniques reconstruct hths velocities from either lths or htls measurements independently , i.e. @xmath53 or @xmath55 .",
    "the cubic spline interpolations @xcite , either 1d in time or 2d in space , are used .",
    "these interpolations are by matlab built - in functions , which follow the algorithm in ref .",
    "@xcite .",
    "* linear stochastic estimation * : lse estimates @xmath79 as a linear combination of measurements .",
    "coefficients are estimated from the measurements by solving a system of linear equations to minimize the mean square errors of reconstructed fields .",
    "@xcite describe the physical interpretations of this procedure .",
    "this section derives the model differently @xcite but in accordance with turbulence literature .",
    "matrix forms @xmath114 , @xmath115 and @xmath171 described in section  [ subsec : statistical_parameters_estimation ] are used to build the lse model .",
    "let @xmath172 of size @xmath173 denote a part of @xmath115 subsampled at the same instants as @xmath114 .",
    "lse model finds the optimal matrix @xmath174 of size @xmath175 that minimizes the residual sum of squared errors : @xmath176 let set the gradient of this residual sum to zero : @xmath177 the optimal @xmath178 is obtained as : @xmath179 eq .",
    "( [ eq : lse3 ] ) requires the inversion of @xmath180 that can be singular , leading to a high variance model with large coefficients . a small change of predictors @xmath181 then can lead to a very different reconstruction of @xmath171 , causing model s instability .",
    "tikhonov regularization @xcite , well - known in machine learning problems as l2 penalty or ridge regression @xcite , can be used as a remedy .",
    "it aims to solve this ill - posed problem by imposing a l2 penalty term on the residual sum of errors .",
    "the optimization problem ( [ eq : lse1 ] ) becomes : @xmath182 setting the gradient of the cost function ( for @xmath183 ) to zero : @xmath184 the closed form of @xmath178 is : @xmath185 the regularization parameter @xmath186 can be optimized by ten - fold cross - validation @xcite .",
    "the fully resolved field of @xmath171 is then estimated using these coefficients : @xmath187 matrix @xmath174 encodes the predictor of @xmath113 knowing @xmath181 learnt from the joint observation of @xmath188 and @xmath181 .",
    "a completely analogous procedure can be used switching the roles of @xmath114 and @xmath115 .",
    "the fusion model uses eq .",
    "( [ eq : map_simplified ] ) to reconstruct fully resolved velocities @xmath79 in various cases .",
    "reconstructed fields are compared with the original dns via the normalized root mean square error ( nrmse ) : @xmath189 where @xmath190 is the considered set of points used to estimate the error .",
    "the field @xmath191 is more or less difficult to estimate depending on the considered instant and position with respect to available measurements .",
    "to qualify , two types of nrmse , the mean nrmse @xmath192 and the maximum nrmse @xmath193 , are estimated .",
    "@xmath192 is estimated over @xmath167 including all space - time positions in the outer region of @xmath194 $ ] , where the flow is approximately homogeneous .",
    "it represents how far the reconstructed field departs from ground truth in order to evaluate reconstruction accuracy .",
    "@xmath193 is estimated using all blocks ( in time and in spanwise directions ) bounded by htls sensors at @xmath195 and @xmath196 , see fig .",
    "[ fig : element_block ] .",
    "the set @xmath190 includes centers at local coordinates @xmath197 of all blocks . @xmath192 and @xmath193 of @xmath70 , @xmath60 and lse reconstruction",
    "are also estimated for comparison .",
    "table  [ tab : results ] describes 7 cases with their settings and reconstruction errors . in cases 1 and 2 ,",
    "the energy losses due to subsampling in time are much higher than in space , and vice - versa in cases 3 and 4 .",
    "the model gives similar errors compared to the best interpolation , with smaller @xmath192 and comparable @xmath193 . in cases 5 to 7 ,",
    "the losses are due to both the subsamplings in space and time in a balanced manner .",
    "the proposed model reduces @xmath192 by 15@xmath198 to 30@xmath198 and @xmath193 by 10@xmath198 to 20@xmath198 compared to the best of other methods .",
    "improvements are expected from the weighted average in eq .",
    "( [ eq : map_simplified ] ) .",
    "the present model uses variances @xmath199 and @xmath200 as parameters of the flow s physics , and @xmath60 and @xmath70 as the specific flow information .",
    "it imposes the reconstruction to be consistent with measurements at nearby positions and proposes compromise estimates elsewhere .",
    "simple interpolations use either htls or lths measurements only , losing information from the other source .",
    "lse learns its coefficients from both measurements but inherits the limitations of the conditional averaging .      in cases 1 to 4",
    ", the fusion model performs as the best interpolation with small improvements .",
    "this is expected since one measurement of htls or lths is much better resolved than the other .",
    "cases 5 to 7 are the most interesting since energy losses due to subsampling in space and time are comparable .",
    "the model brings complementary information from both measurements and improves the reconstruction .",
    "we study reconstructions of large and small scales in details for these three cases .",
    "spatial 2d filters @xmath21 ( see section [ subsec : database ] ) are used to separate large scales from small scales .",
    "these filters take htls points as knots to have a cutoff close to the nyquist frequency .",
    "the reconstructed large scales by all methods are compared to the reference @xmath201 .",
    "small scales are estimated using @xmath202 where @xmath203 is the identity matrix .",
    "table  [ tab : results_largescales ] shows nrmses estimated using eq .",
    "( [ eq : nrmse ] ) but normalized by the rms of either @xmath201 or @xmath204 .",
    "the fusion model recovers part of small scales from complementary measurements .",
    "it gives the lowest @xmath192 and @xmath193 of small scales reconstruction in all cases .",
    "it also better reconstructs large scales than other methods . for large scales",
    ", @xmath193 remains the same in case 5 of small subsampling ratios and improves significantly in cases 6 and 7 of high ratios , with @xmath193 reduced by 5 @xmath198 and 25 @xmath198 respectively , and @xmath192 by 20@xmath198 to 40@xmath198 compared to the best of other methods .       a time evolution of fluctuating streamwise velocity at @xmath170 and @xmath205 , the centers of all such @xmath206 planes in fig .  ( [ fig : element_block ] ) .",
    "]     spectra of the fluctuating velocity in fig .",
    "[ fig : improper_point_spacespacing_10_timespacing_10_yid129_zid149 ] .,scaledwidth=70.0% ]     a sample snapshot of fluctuating streamwise velocity at one of the most difficult instant to estimate ( in the middle of two lths time steps ) : reconstruction of all scales ( left ) and large scales only ( right ) .",
    "the figure is better viewed on screen . ]",
    "we focus on case 6 for a model performance analysis .",
    "this case has about 5 @xmath198 energy losses due to both time and space subsamplings , which are critical to highlight interests of the present approach .",
    "the model reduces @xmath192 and @xmath193 by 25 @xmath198 and 35 @xmath198 respectively for all scales reconstruction , 10 @xmath198 and 5 @xmath198 for large scales reconstruction .    to analyze reconstructions in space , fig .",
    "[ fig : error_map_newom1_outer](a ) shows spatial nrmse maps by all methods as functions of local coordinates @xmath206 . for each @xmath206 , nrmse",
    "is estimated using eq .",
    "( [ eq : nrmse ] ) , where @xmath190 includes points at @xmath207 of all blocks used to estimate @xmath193 ( see section  [ subsubsec : impacts_of_subsampling_ratios ] ) . for all methods ,",
    "nrmses are small close to the four htls positions in the corners and increase when approaching the center .",
    "time interpolation behaves differently since its errors are independent of spatial coordinates .",
    "the fusion model yields the smallest errors at all positions .",
    "it improves significantly near the center compared to spatial interpolation , the best of other methods .    to analyze reconstructions in time , fig .",
    "[ fig : error_map_newom1_outer](b ) shows the nrmse curves by all methods as functions of distances @xmath131 from the previous lths time step .",
    "for each @xmath131 , nrmse is estimated using @xmath167 including points at local coordinates @xmath208 of all blocks used to estimate @xmath193 .",
    "nrmses are small close to the lths measurements ( @xmath3 and @xmath4 ) and increase when moving toward the middle ( @xmath209 ) .",
    "spatial interpolation are different with nrmses independent of time .",
    "the fusion model yields the minimum errors at all time steps . even in the middle of two lths instants , the maximum fusion error remains significantly lower than that of all other methods .",
    "[ fig : improper_point_spacespacing_10_timespacing_10_yid129_zid149 ] shows a time evolution of the point at @xmath170 and @xmath205 ( @xmath210 and @xmath211 in local coordinates ) , the most remote from its neighboring htls sensors . a good agreement between fused and reference velocity",
    "is still obtained . a zoom - in period",
    "is shown also for detailed comparisons with other methods .",
    "while time interpolation captures only low frequencies , spatial interpolation generates high frequencies but weakly correlated with the truth .",
    "the fusion model proposes a good compromise to improve both large and small scales reconstruction .",
    "it also captures detailed peaks much better than lse , since lse smooths these small scales out by minimizing the mean square errors .",
    "[ fig : improper_sspacing_10_tspacing_10_spectrum_time ] compares temporal spectra of above evolutions .",
    "time interpolation fails to estimate the signal at higher frequencies than a certain cutoff .",
    "lse keeps both large and small scales , but the loss of large scale energy is critical .",
    "this loss is highlighted in the zoom - in picture of low frequencies spectral .",
    "the present model improves the estimation at both low and high frequencies .",
    "[ fig : improper_outer_spacespacing_10_timespacing_10_subplots_all_t006 ] compares reconstructed snapshots by different methods .",
    "this snapshot is at the most remote instant from its two neighboring lths time steps .",
    "the model reconstructs correctly the velocity field with more flow details than spatial interpolation .",
    "it also recovers better large scales than lse and time interpolation methods .",
    "this work proposes a bayesian fusion model using a map estimate to reconstruct high resolution velocities of a turbulent channel flow from low resolution measurements in space and time .",
    "it searches for the most probable field given available measurements .",
    "this approach yields a simple but efficient weighted average formula in eq .",
    "( [ eq : map_simplified ] )",
    ". weighting coefficients are learnt from measurements and encode the pysics of the flow . the informed fusion of information from available measurements improves the interpolation of large scales and recovers details at small scales .    numerical experiments using a dns database of a turbulent wall - bounded flow at a moderate reynolds number illustrate the efficiency and robustness of the proposed method .",
    "low resolution measurements are extracted to learn model parameters , while original data are used as the ground truth to estimate reconstruction errors .",
    "the model is tested in various cases with different subsampling ratios .",
    "results are compared to more standard methods such as cubic spline interpolation and penalized lse .",
    "bayesian fusion always produces the most accurate reconstruction .",
    "the best results are obtained when missing spatial and temporal information are of the same order of magnitude . in these cases",
    ", it provides a better large scale reconstruction while a certain amount of small scale details are also recovered .",
    "the search for an even more accurate fusion and super - resolution method is the subject of ongoing work .",
    "s.  coudert , j.  m. foucaut , j.  kostas , m.  stanislas , p.  braud , c.  fourment , j.  delville , m.  tutkun , f.  mehdi , p.  johansson , and w.  k. george .",
    "double large field stereoscopic piv in a high reynolds number turbulent boundary layer . , 50(1):112 , 2011 .",
    "d.  ewing and j.  h. citriniti .",
    "examination of a lse / pod complementary technique using single and multi - time information in the axisymmetric shear layer . in _",
    "iutam symposium on simulation and identification of organized structures in flows fluid mechanics and its applications _",
    ", volume  52 , pages 375384 .",
    "springer , 1999 .",
    "t.  d. nguyen , j.  c. wells , p.  mokhasi , and d.  rempfer .",
    "proper orthogonal decomposition - based estimations of the flow field from particle image velocimetry wall - gradient measurements in the backward - facing step flow . , 21(11):115406 , 2010 .",
    "j.  p. bonnet , d.  r. cole , j.  delville , m.  n. glauser , and l.  s. ukeiley .",
    "stochastic estimation and proper orthogonal decomposition : complementary techniques for identifying structure .",
    ", 17(5):307314 , 1994 .",
    "m.  b. melnick and b.  s. thurow .",
    "experimental investigation of a turbulent boundary layer using simultaneous 3-d flow visualization and 2-d piv . in _",
    "50th aiaa aerospace sciences meeting including the new horizons forum and aerospace exposition _ , pages 0752 , 2012 .",
    "j.  h. tu , j.  griffin , a.  hart , c.  w. rowley , l.  n. cattafesta , and l.  s. ukeiley .",
    "integration of non - time - resolved piv and time - resolved velocity point sensors for dynamic estimation of velocity fields .",
    "54(2):120 , 2013 .                                  e.  r. cook and k.  peters .",
    "the smoothing spline : a new approach to standardizing forest interior tree - ring width series for dendroclimatic studies . in _",
    "tree - ring bulletin _ , volume  41 , pages 4553 . tree - ring society , 1981 ."
  ],
  "abstract_text": [
    "<S> the study of turbulent flows calls for measurements with high resolution both in space and in time . we propose a new approach to reconstruct high - temporal - high - spatial resolution velocity fields by combining two sources of information that are well - resolved either in space or in time , the low - temporal - high - spatial ( lths ) and the high - temporal - low - spatial ( htls ) resolution measurements . in the framework of co - conception between sensing and data post - processing </S>",
    "<S> , this work extensively investigates a bayesian reconstruction approach using a simulated database . a bayesian fusion model is developed to solve the inverse problem of data reconstruction . </S>",
    "<S> the model uses a maximum a posteriori estimate , which yields the most probable field knowing the measurements . </S>",
    "<S> the dns of a wall - bounded turbulent flow at moderate reynolds number is used to validate and assess the performances of the present approach . </S>",
    "<S> low resolution measurements are subsampled in time and space from the fully resolved data . </S>",
    "<S> reconstructed velocities are compared to the reference dns to estimate the reconstruction errors . </S>",
    "<S> the model is compared to other conventional methods such as linear stochastic estimation and cubic spline interpolation . </S>",
    "<S> results show the superior accuracy of the proposed method in all configurations . </S>",
    "<S> further investigations of model performances on various range of scales demonstrate its robustness . </S>",
    "<S> numerical experiments also permit to estimate the expected maximum information level corresponding to limitations of experimental instruments . </S>"
  ]
}