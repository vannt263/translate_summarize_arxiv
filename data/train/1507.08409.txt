{
  "article_text": [
    "thermodynamic phase transitions are examples of emergent phenomena in many degrees of freedom systems , described in the framework of statistical mechanics .",
    "the standard statistical ensembles measures relate macroscopic ( thermodynamic ) observables with microscopic degrees of freedom .",
    "the interactions among the microscopic degrees of freedom - which can be either continuous or discrete ( as in the case of spin models , vertex models , and so on ) - are often described by a hamiltonian function ( or a hamiltonian operator in a quantum context ) @xcite .",
    "but what about discrete systems , i.e. networks , undergoing a phase transition for which a microscopic hamiltonian does not exist ?    a paradigmatic example",
    "is represented by a random graphs model @xmath0 devised by choosing with uniform probability a graph from the set of all graphs having @xmath1 vertices and @xmath2 edges @xcite .",
    "we can think of a process evolving by adding the edges one at a time .",
    "when @xmath3 has the same order of magnitude of @xmath4 , the evolution from @xmath5 to @xmath6 yields , according to erds - rnyi theorem @xcite , a _ phase transition _ , revealing itself in a rapid growth with @xmath3 of the size of the largest component ( number of vertices fully connected by edges ) . specifically , the structure of graphs when the expected degree of each of its vertices is close to @xmath7 , i.e. @xmath8 , shows a jump : the order of magnitude of the size of the largest component of graphs rapidly grows , asymptotically almost surely , from @xmath9 to @xmath4 , if @xmath3 has the same order of magnitude of @xmath4 . in fact , if @xmath10 , as the process evolves , the components of a graph [ the largest of them being a.a.s . of size @xmath11",
    "merge mainly by attaching small trees ; thus they grow slowly and quite smoothly .",
    "nonetheless , at the same point of the process , the largest components become so large that it is likely for a new edge to connect two of them .",
    "thus , fairly quickly , all the largest components of a graph merge into one giant component , much larger than any of the remaining ones @xcite .",
    "it is worth noticing that this process represents the mean - field case of percolation @xcite .",
    "regarding @xmath0 as a statistical ensemble it is quite natural to employ tools from statistical mechanics , above all entropy , to analyze it . in ref .",
    "@xcite the gibbs entropy of such random graphs was defined as @xmath12 there , the configuration space was given by @xmath13 graphs with labelled nodes . due to their equiprobability",
    ", they have the same weight , chosen to be @xmath14 in order to account for all the labelling permutations of the nodes .",
    "later , the perspective was to modify the erds - rnyi ensemble by introducing a functional weight which explicitly depends on the graph s topology . in this way",
    "one can eventually characterize other classes of random graphs , like scale free or fixed degree sequence , as well . a research line that has been pursued in the last decade",
    "@xcite , also putting forward variants of the entropy measure @xcite .",
    "however , we may notice that the entropy as a function of the ratio @xmath15 is unable itself to detect the phase transition occurring in the erds - rnyi ensemble .    in the present work ,",
    "focussing on the erds - rnyi ensemble , we propose a general method to associate a continuous mathematical object ( a riemannian manifold ) to a generic discrete system , graph or network , thus allowing the definition of a _ geometric entropy _ which is able to detect a phase transition .",
    "actually , we endow each network with a statistical riemannian manifold . this can be obtained basically via two steps ; first by understanding a network as an undirected graph without loops on the nodes , and account for links ( weighted edges ) between nodes expressed by the adjacency matrix @xmath16 .",
    "second , considering random variables as sitting on the vertices of a network , methods of information geometry @xcite can be employed to lift the network to a statistical riemannian manifold . in this way , we associate a configuration space to each network .",
    "such a space consists of a subset of the linear vector space @xmath17 given by the parameters which characterize the joint probability distribution of the random variables sitting on the nodes of the network .",
    "furthermore , this configuration space is endowed with a riemannian metric which is inspired by the well - known fisher - rao metric @xcite .",
    "then , in analogy with classical statistical mechanics , we define a geometric entropy as the logarithm of the volume of this manifold . applied to erds - rnyi random graphs it proves very effective ( as a function of the ratio @xmath15 ) in detecting the appearance of the so called ` giant component ' as well as any smooth function of order parameters within the framework of statistical mechanics @xcite .",
    "let us start considering a set of @xmath4 real - valued random variables @xmath18 characterized by the following multivariate gaussian probability distribution @xmath19 , \\label{pxt}\\ ] ] where @xmath20 with @xmath21 denoting the transposition and we have also assumed , without loss of generality , that all the mean values are zero .",
    "furthermore , @xmath22 are the real valued parameters characterizing the above probability distribution function , i.e. the entries of the covariance matrix @xmath23 .",
    "hence @xmath24 .",
    "next we consider a family @xmath25 of such probability distributions @xmath26 where @xmath27 and the mapping @xmath28 is injective .",
    "defined in such a way @xmath25 is an @xmath29-dimensional statistical model on @xmath30 .",
    "the open set @xmath31 is defined as follows @xmath32 and we call it the parameter space of the @xmath29-dimensional statistical model @xmath25 .    assuming parametrizations which are @xmath33 we can turn @xmath25 into a @xmath33 differentiable manifold @xcite .",
    "then , given a point @xmath34 , the fisher information matrix of @xmath25 in @xmath34 is the @xmath35 matrix @xmath36 $ ] , where the @xmath37 entry is defined by @xmath38 with @xmath39 standing for @xmath40 .",
    "the matrix @xmath41 is symmetric , positive semidefinite and endows the parameter space @xmath31 with a riemannian metric @xcite .",
    "we highlight that the integral of eq .",
    "with is a gaussian one and amounts to @xmath42f_{\\mu\\nu } |_{x=0 } , \\label{gint}\\end{aligned}\\ ] ] where the exponential stands for a power series expansion over its argument ( the differential operator ) and @xmath43\\ \\partial_\\nu \\log[p(x;\\theta)].\\ ] ] the derivative of the logarithm has the following expression @xmath44=-\\frac 1 2\\bigg[\\frac{\\partial_\\mu(\\det c)}{\\det c } + \\sum_{\\alpha,\\beta=1}^n \\partial_\\mu(c_{\\alpha\\beta}^{-1})x_\\alpha x_\\beta\\bigg],\\ ] ] where @xmath45 denotes the @xmath46 entry of the inverse of the covariance matrix @xmath23 in . the latter equation together with eq .",
    "show the computational complexity of the eq . .",
    "indeed , the well - known formulas @xmath47 require the calculation of @xmath48 derivatives with respect to the variables @xmath49 of eq . in order to work out the derivative of the logarithm in .",
    "finally , to obtain the function @xmath50 in , we have to evaluate @xmath51 derivatives .",
    "this quickly becomes an unfeasible task with growing @xmath4 , even numerically .    in order to overcome the difficulty of explicitly computing the components of the fisher - rao metric",
    ", we proceed by defining a new ( pseudo)-riemannian metric on the parameter space @xmath31 which account as well for the network structure given by the adjacency matrix @xmath16 .    to this end",
    "we consider first a trivial network with null adjacency matrix and interpret @xmath4 independent gaussian random variables @xmath52 as sitting on its vertices . in this particular case",
    ", the joint probability distribution is given with a diagonal covariance matrix with entries given by @xmath53 .",
    "let us denote this matrix as @xmath54 .",
    "so , making use of eqs . and , the statistical riemannian manifold @xmath55 , with @xcite @xmath56 is associated to the _ bare _ network .",
    "given the matrix @xmath57 $ ] , from it is evident that @xmath58 , where @xmath59 is the @xmath60 entry of the inverse matrix of @xmath54 given by @xmath61 , for all @xmath62 .",
    "inspired by this functional form of @xmath63 , we propose to associate a ( pseudo)-riemannian manifold to any network @xmath64 with non vanishing adjacency matrix @xmath16 . to this aim , we consider the map @xmath65 defined by @xmath66 with @xmath67 denoting the set of the symmetric @xmath68 matrices over @xmath69 with vanishing diagonal elements that can represent any simple undirected graph .",
    "then , we deform the manifold @xmath70 in via @xmath71 .",
    "hence the manifold associated to a network @xmath64 with adjacency matrix @xmath16 is @xmath72 with @xmath73 and @xmath74 with components @xmath75 where @xmath76 is the @xmath77 entry of the inverse of the matrix @xmath78 .    in this way , we associated a differentiable system ( riemannian manifold ) to a discrete system ( network ) through the description of network by a set of probability distribution functions .",
    "some other ways to describe a network with probabilistic methods are also employed in literature . among them",
    "it is worth mentioning the random walk method @xcite . here",
    "the green function , meaning the transition amplitude from one vertex to another by accounting for all possible paths , gives rise to a metric @xcite , thus allowing as well for a geometric approach .",
    "however the main difference is that in such a case one deals with a stationary transition probability originating from the adjacency matrix @xcite , in our case beside adjacency matrix also the variances of a gaussian distribution of random variables sitting on nodes of the network play a role ( namely a family of gaussian distributions ) .",
    "we now define a geometric entropy of a network @xmath64 with adjacency matrix @xmath16 and associated manifold @xmath72 as @xmath79 where @xmath80 is the volume of @xmath81 evaluated from the element @xmath82 notice , however , that in such a way @xmath80 is ill - defined .",
    "thus we regularize it as follows @xmath83 where @xmath84 is any suitable `` infrared '' and `` ultraviolet '' regularizing function ; @xmath78 and @xmath85 are given in and , respectively .",
    "the need for regularization is twofold : the set @xmath86 in eq .",
    "is not compact because the variables @xmath87 are unbounded from above ; furthermore , from eq .",
    ", @xmath88 diverges since @xmath89 approaches zero for some @xmath87 .",
    "a possible choice of @xmath90 has recently been defined @xcite , @xmath91,\\ ] ] where @xmath23 is the covariance matrix in when off - diagonal entries are @xmath7 or @xmath92 . in the present work",
    "we would extent such a regularizing function to a more general kind of networks , taking also into account the weights of links between vertices . however , the functional type should be still like in",
    ".    the definition is inspired by the microcanonical definition of entropy @xmath93 in statistical mechanics , that is @xmath94 , where @xmath95 is the phase space volume bounded by the hypersurface of constant energy @xmath96 .",
    "after integration on the momenta one finds @xmath97^{n/2}\\;dq^1\\wedge\\ldots\\wedge dq^n $ ] , where @xmath98 is a constant stemming from the integration on the momenta , @xmath99 is the configuration space subset bounded by the equipotential level set @xmath100 , and @xmath101 are the configurational coordinates .",
    "now , the term @xmath102^{n/2}$ ] is just @xmath103 , with @xmath104 the jacobi kinetic energy metric whose associated geodesic flow coincides with the underlying hamiltonian flow @xcite . in the end",
    "the microcanonical entropy is @xmath105 , that is proportional to the logarithm of the volume of the riemannian manifold associated with the underlying dynamics .    as already stated at the beginning of this paper , in order to assess the interest of the proposed geometric entropy in eq .",
    "we check it against a system undergoing the classical erds - rnyi phase transition in random graphs @xcite .",
    "we numerically compute @xmath106 , the geometric entropy in eq . vs @xmath3 for a fixed @xmath4 in order to investigate its sensitivity to the appearance of the giant component during the evolution of the random graph model @xmath0 .    to this aim",
    ", we consider four different numbers of vertices : @xmath107 .",
    "the choice of @xmath4 determines the dimension of the associated manifold @xmath108 .",
    "then , for a given @xmath4 , we choose the number of links @xmath3 , with @xmath109 .",
    "next , for a given pair @xmath110 we generate at random a set of @xmath3 entries @xmath111 , with @xmath112 , of the non - vanishing adjacency matrix elements @xmath113 .    hence , since the covariance matrix @xmath23 is functionally assigned , we get @xmath114 of eq . and finally the metric @xmath115 of eq .. now , having determined @xmath116 , we can compute the volume @xmath80 in eq . and the entropy @xmath117 of eq .. in numerical computations",
    "the volume regularization is performed in two steps , the first one is by restricting the manifold support @xmath118 to an hypercube . inside @xmath119 we generate a markov chain , to perform a monte carlo estimate of the average @xmath120 the number of random configurations considered varies between @xmath121 and @xmath122 ; the second step of the regularization procedure of the volume is obtained by excluding those points where the value of @xmath123 exceeds @xmath124 ( the numerical overflow limit of the computers used ) . for any given pair @xmath110 this computational scheme is repeated @xmath125 times , each time considering a different randomly generated realisation of the adjacency matrix @xmath16 .",
    "thus the final values of the entropy @xmath117 are obtained as averages on these @xmath125 different manifolds @xmath108 . in the figures [ bifurcation ] and [ linkweight ] we report the monte carlo numerical estimates of @xmath126 repeated for different values of @xmath3 ; here @xmath127 stands for the above mentioned average over the different realisations of the adjacency matrix @xmath16 , and @xmath63 is the metric corresponding to the null adjacency matrix .    for all the four cases reported in figure [ bifurcation ] we have equal weights @xmath128 for all the @xmath3 non - vanishing links .     of @xmath129 ( magenta points ) , @xmath130 ( black points ) , @xmath131 ( red points ) and @xmath132 ( blue points ) networks as a function of the number @xmath3 of randomly chosen links of weights equal to @xmath133 . the black solid line is a guide to the eye coming from a linear fitting of a linear - logarithmic presentation of the data.,width=302,height=226 ]     of @xmath130 networks as a function of the number @xmath3 of randomly chosen links of weights equal to @xmath134 ( green points ) , @xmath133 ( red points ) and @xmath135 ( black points).,width=302,height=226 ]    the reason for displaying @xmath136 of eq . instead of @xmath117 in and _",
    "@xmath15 instead of @xmath3 is that one obtains what in the context of statistical mechanics is called a _ collapse plot _ of the results obtained at different @xmath4-values .",
    "the corresponding points crowd on a common pattern for large @xmath3 whereas for @xmath15 ranging from @xmath92 to approximately @xmath7 the patterns obtained show a phenomenon which is familiar in the context of numerical investigations of second order phase transitions : as in the case of finite - size effects observed for the order parameter , what asymptotically would be a sharp bifurcation is rounded at finite @xmath4 @xcite ; however , the larger @xmath4 the more pronouced the ` knee ' of @xmath137 in the range @xmath138 .",
    "this is clearly in excellent agreement with an @xmath4-asymptotic bifurcation at @xmath139 ( marked by the solid line ) where the erds - rnyi phase transition takes place .    in figure [ linkweight ]",
    "we report the outcomes for @xmath140 having set all the non - vanishing entries @xmath113 of the adjacency matrix again equal to a constant value @xmath141 . for @xmath134 a considerable softening of the shape of @xmath142",
    "is observed ; this is of course an expected result since for @xmath143 the transition must disappear . for @xmath133 and @xmath135 the shapes of @xmath142",
    "look almost the same , the only interesting difference being a slightly more pronounced ` knee ' in the @xmath135 case , which , going in the opposite direction , is coherent with the previous ones .",
    "another interesting property of this entropy consists in its versatility , that is , it can be easily adapted to more refined descriptions of networks / graphs .",
    "for example , we can consider a refined modeling of graphs where the entries of the @xmath68 adjacency matrix @xmath16 are given by terms of the form @xmath144 . here",
    "the @xmath145s ( @xmath146 ) are the weights of the links between the nodes of the network described by @xmath16 .",
    "furthermore , the @xmath87s ( @xmath147 ) are local coordinates on the manifold @xmath81 of eqs . and , representing the variances of the random variables on the nodes of the network .",
    "networks as a function of the number @xmath3 of randomly chosen non - vanishing adjacency matrix elements @xmath113 of the form @xmath144 with @xmath148 . ]",
    "this kind of model has an interesting property : the closer a given variable @xmath87 to zero , the weaker the weights of all the links associated to the @xmath149-th node .",
    "in such a way , this second model , allows one to describe a more general class of networks .",
    "in fact , consider for example the flow of some quantity across a network , the vanishing of the flow on a given node @xmath149 implies that all the other nodes connected to it become effectively independent of it . in view of this argument",
    ", we consider the entropy @xmath150 in eq . against the more general model",
    "just described above . in figure [ linkthetaithetaj ] it",
    "is shown @xmath136 versus @xmath15 where @xmath151 is the dimension of the manifold associated to the network , and @xmath152 is the number of non - vanishing @xmath145 ( all of them are chosen equal to @xmath7 ) , for @xmath153 and @xmath112 .",
    "also in this case our entropy detects the phase - transition predicted by the erds - rnyi theorem occuring at @xmath154 .",
    "the pattern of @xmath142 reported in figure [ linkthetaithetaj ] shows a more pronounced `` knee '' at the asymptotic transition value @xmath154 with respect to what is found for the same @xmath4 value and is reported in figures [ bifurcation ] and [ linkweight ] .",
    "summarizing , the present work puts forward a novel entropic functional useful to characterize probabilistic graph models .",
    "it is inspired to statistical mechanics , however , instead of being modeled on the boltzmann entropy it is rather modeled on the microcanonical ensemble definition of entropy . the phase space volume being replaced by the volume of a ` state manifold ' ( that is a riemannian manifold whose points correspond to all the possible states of a given network ) .",
    "the state manifold is defined through a suitable metric which is borrowed from an information geometry framework .",
    "the result is a constructive way of associating a differentiable and handy mathematical object to any simple undirected and weighted graph or network .",
    "notice that a similar way of associating a probability distribution to a network , is that of probabilistic graphs models @xcite . here",
    "the choice of gaussian probability distributions is motivated by the fact that gaussian networks are extensively used in many applications ranging from neural networks , to wireless communication , from proteins to electronic circuits , and so on .",
    "the most relevant property of the proposed entropic - geometric measure is its ability to detect the phase transition which is rigorously predicted by the erds - rnyi theorem for random graphs : a paradigmatic example of an analytically known emergent phenomenon occurring in a network .",
    "this effect shows up very clearly , in fact , the geometric entropy proposed here displays both the pattern ( as a function of a control parameter ) and the finite - size - dependence which are typically displayed by the order parameter of a second - order phase transition in physics . as natural ,",
    "though non - trivial , extension our entropic - geometric measure could be applied to pseudo - random graphs and dense graphs where the emergence of the giant component has been recently proved @xcite .",
    "finally , the differential - geometric framework proposed opens some fascinating perspectives of application to the study of complex networks @xcite . as matter of fact",
    "the introduced geometric entropic measure could account for both the structural complexity of a given network and for its statistical complexity , that is , for the complexity of the probability distributions of the entities constituting the network .",
    "we acknowledge the financial support of the european commission by the fet - open grant agreement topdrim , number fp7-ict-318121 ."
  ],
  "abstract_text": [
    "<S> we propose a method to associate a differentiable riemannian manifold to a generic many degrees of freedom discrete system which is not described by a hamiltonian function . </S>",
    "<S> then , in analogy with classical statistical mechanics , we introduce an entropy as the logarithm of the volume of the manifold . </S>",
    "<S> the geometric entropy so defined is able to detect a paradigmatic phase transition occurring in random graphs theory : the appearance of the ` giant component ' according to the erds - rnyi theorem .    </S>",
    "<S> * keywords : * probability theory , riemannian geometry , complex systems </S>"
  ]
}