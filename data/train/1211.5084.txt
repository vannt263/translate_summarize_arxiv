{
  "article_text": [
    "the top-@xmath0 nearest neighbor searching is a fundamental and well - studied problem , due to its wide range of applications in databases , computer vision , image processing , information retrieval , pattern recognition , etc @xcite . in general , for a set @xmath16 of points in the @xmath17-d space @xmath18 , the problem asks for a data structure to quickly report the top-@xmath0 nearest neighbors in @xmath16 for any query point .    in many applications , e.g. face recognition and sensor networks ,",
    "data is inherently imprecise due to various reasons , such as noise or multiple observations .",
    "numerous classic problems , including clustering  @xcite , skylines  @xcite , range queries  @xcite , and nearest neighbor searching  @xcite , have been cast and studied under uncertainty in the past few years . in this paper , we consider the top-@xmath0 nearest neighbor searching where the query data is uncertain .",
    "further , we focus on the distances measured by the @xmath1 metric , which is appropriate for applications like vlsi design automation and urban transportation modeling ( `` manhattan metric '' ) . this problem has been studied by agarwal _",
    "_ @xcite and we propose a better solution in this paper . the same problems with euclidean distance measure and squared euclidean distance measure were also studied in @xcite .",
    "the converse problem model where the input data are uncertain and the query data are certain was also considered in @xcite .",
    "refer to @xcite for motivations of these problems .",
    "an _ uncertain _ point @xmath15 in the @xmath17-d space @xmath18 ( for @xmath19 ) is represented as a discrete probability distribution function @xmath20 $ ] . instead of having one exact location",
    ", @xmath15 has a set of @xmath5 possible locations : @xmath21 , where @xmath22 has probability @xmath23 of being the true location of @xmath15 , and @xmath24 . throughout the paper",
    ", we use @xmath5 to denote the number of locations of any uncertain point @xmath15 ; @xmath5 is also known as the _ description complexity _ of @xmath15 @xcite .",
    "for any two exact points @xmath25 and @xmath26 in @xmath18 , denote by @xmath27 the distance of @xmath25 and @xmath26 . for any exact point @xmath25 and any uncertain point @xmath15 , their _ expected distance _",
    ", denoted by @xmath28 , is defined to be @xmath29    let @xmath16 be a set of @xmath2 exact points in @xmath18 . for any uncertain query point @xmath15 and any integer @xmath0 with @xmath6 , the _",
    "top-@xmath0 expected nearest neighbors _ ( top-@xmath0 enns ) of @xmath15 in @xmath16 are the @xmath0 points of @xmath16 whose expected distances to @xmath15 are the smallest among all points in @xmath16 ; we denote by @xmath30 the set of the top-@xmath0 enns ( in particular , when @xmath8 , @xmath31 is the enn of @xmath15 in @xmath16 ) .    given a set @xmath16 of @xmath2 exact points in @xmath18 , the problem is to design a data structure to quickly report the set @xmath30 for any uncertain query point @xmath15 and any integer @xmath0 with @xmath6 . in this paper , we consider the @xmath1 distance metric in the plane .",
    "specifically , for any two exact points @xmath32 and @xmath33 , @xmath34 .",
    "we build an @xmath3-size data structure in @xmath3 time that can support each query in @xmath7 time .",
    "note that we also return the expected distance of each point in @xmath30 to @xmath15 ( the points of @xmath30 are actually reported in sorted order by their expected distances to @xmath15 ) .",
    "previously , only approximation and heuristic results were given for this problem @xcite .",
    "for the special case where @xmath8 , agarwal @xcite built an @xmath9-size data structure in @xmath9 time that can answer each ( top-@xmath35 ) enn query in @xmath10 time .",
    "hence , even for the special case where @xmath8 , our result is better than that in @xcite in all three aspects : preprocessing time , space , and query time .    for the one - dimensional version of this problem , our approach can build an @xmath11-size data structure in @xmath12 time with @xmath13 query time , and the query time can be reduced to @xmath14 time if the locations of @xmath15 are given in sorted order .",
    "note that in the @xmath35-d space , the @xmath1 metric is the same as the @xmath36 metric . for the @xmath36 metric",
    ", only approximation results have been given in @xmath18 when @xmath37 , e.g. , @xcite .",
    "we remark that although @xmath38 in our definition , our results are applicable to the general case where @xmath39 .",
    "hence , the problem is equivalent to the aggregate or group nearest neighbor searching where the aggregate distance function uses the weighted sum as the operator @xcite .",
    "different formulations have been proposed for the nearest neighbor searching when each uncertain point is represented by a probability distribution function .    in the formulation of _",
    "probabilistic nearest neighbor _ ( pnn ) , one considers the probability of each input point being the nearest neighbor of the query point .",
    "the main drawback of pnn is that it is computationally expensive : the probability of each input point being the nearest neighbor not only depends on the query point , but also depends on all the other input points .",
    "the formulation has been widely studied  @xcite .",
    "all of these methods were r - tree based heuristics and did not provide any guarantee on the query time in the worst case .",
    "for instance , cheng @xcite studied the pnn query that returns those uncertain points whose probabilities of being the nearest neighbor are higher than some threshold , allowing some given errors in the answers .",
    "pretty recently , agarwal _ et al . _",
    "@xcite presented non - trivial results on nearest neighbor searching in a probabilistic framework .    in the formulation of _ superseding nearest neighbor _",
    "( snn ) @xcite , one considers the _ superseding _ relationship of each pair of input points : one supersedes the other if and only if it has probability more than 0.5 of being the nearest neighbor of the query point , where the probability computation is restricted to this pair of points .",
    "one can return the point , if such one exists , which supersedes all the others .",
    "otherwise , one returns the minimal set @xmath40 of data points such that any data point in @xmath40 supersedes any data point not in @xmath40 .    in the formulation of _",
    "expected nearest neighbor _ ( enn ) , one considers the expected distance from each data point to the query point .",
    "since the expected distance of any input point only depends on the query point , efficient data structures are available .",
    "recently , agarwal _ et al . _",
    "@xcite gave the first nontrivial methods for answering exact or approximate expected nearest neighbor queries under @xmath1 , @xmath36 , and the squared euclidean distance , with provable performance guarantee .",
    "efficient data structures are also provided in @xcite when the input data is uncertain and the query data is exact .",
    "when the input points are exact and the query point is uncertain , the enn is the same as the weighted version of the sum _ aggregate nearest neighbors _ ( ann ) , which is a generalization of the sum ann .",
    "only heuristics are known for answering sum ann queries  @xcite . the best known heuristic method for exact ( weighted ) sum ann queries",
    "is based on r - tree  @xcite , and li @xcite gave a data structure with 3-approximation query performance for the sum ann .",
    "@xcite gave a data structure with a polynomial - time approximation scheme for the enn queries under the euclidean distance metric , which also works for the sum ann queries .",
    "in the following , in section [ sec:1d ] , we give our results in the 1-d space , which are generalized to the 2-d space in section [ sec:2d ] .",
    "one may view section [ sec:1d ] as a `` warm - up '' for section [ sec:2d ] .",
    "section [ sec : conclusion ] concludes the paper .    for simplicity of discussion",
    ", we make a general position assumption that no two points in @xmath41 have the same @xmath42- or @xmath43-coordinate for any query @xmath15 ; we also assume no two points of @xmath16 have the same expected distance to @xmath15 .",
    "our techniques can be easily extended to the general case .    throughout the paper",
    ", we use @xmath15 to denote the uncertain query point and assume @xmath44 . to simplify the notation , we will write @xmath45 for @xmath28 , and @xmath46 for @xmath30 . for any subset @xmath47 , denote by @xmath48 the set of the top-@xmath0 enns of @xmath15 in @xmath49 . for any point @xmath50 ,",
    "let @xmath51 denote the probability of @xmath15 being located at @xmath26 .",
    "let @xmath52 .",
    "in @xmath35-d , all points in @xmath16 lie on a real line @xmath53 .",
    "we assume @xmath53 is the @xmath42-axis .",
    "for any point @xmath25 on @xmath53 , denote by @xmath54 the coordinate of @xmath25 on @xmath53 .",
    "consider any uncertain point @xmath55 on @xmath53 .",
    "for any point @xmath25 on @xmath53 , the expected distance from @xmath25 to @xmath15 is @xmath56 , where @xmath57 . given any @xmath15 and any @xmath0 , our goal is to compute @xmath46 , i.e. , the set of the top-@xmath0 enns of @xmath15 in @xmath16 .    for a fixed uncertain point @xmath15 , a point @xmath25 on @xmath53",
    "is called a _ global minimum point _ if it minimizes the expected distance @xmath45 among all points on @xmath53 .",
    "such a global minimum point on @xmath53 may not be unique .",
    "the global minimum point is also known as weighted fermat - weber point @xcite , and as shown below , it is very easy to compute in our problem setting .    to find @xmath46",
    ", we will use the following strategy .",
    "first , we find a global minimum point @xmath58 on @xmath53 .",
    "second , the point @xmath58 partitions @xmath16 into two subsets @xmath59 and @xmath60 , for which we compute @xmath61 and @xmath62 .",
    "finally , @xmath46 is obtained by taking the first @xmath0 points after merging @xmath61 and @xmath62 .",
    "note that the points in @xmath15 may not be given sorted on @xmath53 .",
    "recall that @xmath52 .",
    "let @xmath58 be the point in @xmath15 such that @xmath63 if we view @xmath51 as the weight of @xmath64 , then @xmath58 is the _ weighted median _ of the set @xmath65 @xcite .",
    "we claim that @xmath58 is a global minimum point on @xmath53 .",
    "to prove the claim , we first present lemma [ lem:1dmonotone ] . in this paper",
    "`` monotonically increasing '' means `` monotonically non - decreasing '' , and `` monotonically decreasing '' means `` monotonically non - increasing '' .",
    "[ lem:1dmonotone ] for any point @xmath25 on @xmath53 and @xmath66 , if we move @xmath25 on @xmath53 towards @xmath58 , the expected distance @xmath45 is monotonically decreasing .    without loss of generality ,",
    "assume @xmath25 is on the left side of @xmath58 and we move @xmath25 on @xmath53 to the right towards @xmath58 .",
    "the case where @xmath25 is on the right side of @xmath58 can be analyzed similarly . at any moment during the movement of @xmath25 , let @xmath67 and @xmath68 .",
    "according to the definition of @xmath45 , we have @xmath69+\\sum_{q\\in q_r } w(q)\\cdot [ x(q)-x(p)]\\\\      & = \\big[\\sum_{q\\in q_l}w(q)- \\sum_{q\\in q_r}w(q)\\big]\\cdot x(p)-\\sum_{q\\in q_l}w(q)\\cdot x(q)+\\sum_{q\\in          q_r}w(q)\\cdot x(q).\\\\ \\end{split}\\ ] ]    because @xmath25 is to the left of @xmath58 , according to the definition of @xmath58 , @xmath70 holds .",
    "further , as @xmath25 moves to the right towards @xmath58 , the value @xmath54 is monotonically increasing .",
    "suppose @xmath25 is between two points @xmath22 and @xmath71 of @xmath15 such that @xmath72 and there are no other points of @xmath15 between @xmath22 and @xmath71 .",
    "note that it is possible that such a point @xmath22 does not exist ( i.e. , no point of @xmath15 is on the left side of @xmath25 ) , in which case we let @xmath73 .",
    "if @xmath25 moves in the interval @xmath74 to the right , then both sets @xmath75 and @xmath76 stay the same , and thus , the value @xmath77\\cdot x(p)$ ] is monotonically decreasing and neither @xmath78 nor @xmath79 changes",
    ". therefore , if @xmath25 moves in the interval @xmath74 to the right , @xmath45 is monotonically decreasing .",
    "we claim that for any @xmath25 in @xmath74 , it always holds that @xmath80 , which leads to the lemma .",
    "indeed , it can be verified that @xmath81 $ ] . since @xmath82 and @xmath77\\leq 0 $ ] , we obtain that @xmath83 .",
    "the lemma thus follows .",
    "lemma [ lem:1dmonotone ] implies that @xmath45 attains a global minimum at @xmath84 .",
    "hence , the point @xmath58 is a global minimum point on @xmath53 .",
    "next , we find the set @xmath46 with the help of @xmath58 and lemma [ lem:1dmonotone ] .",
    "let @xmath85 and @xmath86 .",
    "we find the set @xmath87 of top-@xmath0 enns of @xmath15 in @xmath60 by scanning the sorted list of @xmath88 from left to right and reporting the first @xmath0 scanned points .",
    "@xmath89 can be obtained similarly . among the @xmath90 points obtained above",
    ", we report the set of @xmath0 points with the smallest expected distances to @xmath15 as @xmath46 .",
    "we deduce the following theorem .",
    "[ theo:1d ] given a set @xmath16 of @xmath2 exact points on the real line @xmath53 , with @xmath12 preprocessing time and @xmath11 space , the top-@xmath0 enn set @xmath46 can be found in @xmath13 time for any uncertain query point @xmath15 and any @xmath91 ; if the points of @xmath15 are given sorted on @xmath53 , then the query time is @xmath92 ( particularly , if @xmath8 , the query time is @xmath93 ) .",
    "the only preprocessing is to sort the points in @xmath16 from left to right , which takes @xmath12 time and @xmath11 space .    given any query @xmath15 and any @xmath0 , we first compute the point @xmath58 , in @xmath94 time by the weighted selection algorithm @xcite . the sorted lists of @xmath95 and @xmath88 can be obtained implicitly in @xmath96 time by determining the two neighboring points of @xmath97 in the sorted list @xmath16 .",
    "if @xmath8 , it is sufficient to consider the two neighboring points of @xmath58 in @xmath16 : we compute , in @xmath94 time , their expected distances to @xmath15 , and return the point with smaller expected distance . hence , the total time for finding @xmath98 is @xmath93 .",
    "below , we compute @xmath46 for general @xmath0 .    for simplicity of discussion , we assume @xmath99 and @xmath100 .",
    "we first compute the set @xmath87 of top-@xmath0 enns of @xmath15 in @xmath88 by scanning the sorted list of @xmath88 from left to right and report the first @xmath0 points .",
    "@xmath89 can be obtained similarly . among the found @xmath90 points in @xmath101 , we report the set of @xmath0 points with the smallest expected distances to @xmath15 as @xmath46 .",
    "let @xmath102 denote the set of @xmath0 expected distance values @xmath45 of all points @xmath25 in @xmath89 .",
    "similarly , we define @xmath103 .",
    "set @xmath104 .",
    "if we know @xmath105 , the final step can be done easily in @xmath106 time .",
    "@xmath105 can be computed in @xmath107 time in a straightforward way , leading to @xmath108 overall query time . in the following ,",
    "we show that @xmath105 can be computed in @xmath109 time , which leads to @xmath110 overall query time , and further , if @xmath15 is given sorted , @xmath105 can be computed in @xmath111 time .",
    "the @xmath5 points in @xmath15 partition @xmath53 into @xmath112 intervals and an easy observation is that the expected distance @xmath45 changes linearly as @xmath25 changes in each interval .",
    "specifically , consider computing @xmath45 for any given point @xmath25 : if we know the four values @xmath113 , @xmath114 , @xmath115 , and @xmath116 in eq .",
    "( [ eq:1dspace ] ) in the proof of lemma [ lem:1dmonotone ] , then @xmath45 can be computed in constant time . in order to utilize this , we preprocess @xmath15 as follows .",
    "we sort the points of @xmath15 from left to right and assume the sorted list is @xmath117 . for each @xmath118",
    ", we compute the four values @xmath119 , @xmath120 , @xmath121 , and @xmath122 . note that all these @xmath123 values can be computed in @xmath94 time ( after @xmath15 is sorted )",
    "then , given any point @xmath25 , if we know the index @xmath124 such that @xmath125 , then @xmath45 can be computed in constant time .",
    "now , we compute @xmath105 .",
    "let @xmath126 and @xmath127 . after having @xmath58 , @xmath128 and @xmath129 can be obtained implicitly in @xmath130 time by binary search on the sorted list of @xmath15 .",
    "recall that we scan the points in @xmath88 from left to right to find @xmath131 .",
    "if we scan both @xmath88 and @xmath129 simultaneously , then at the moment of scanning any point , say @xmath25 , we already know the index @xmath124 such that @xmath125 and thus @xmath45 can be computed in constant time . hence , @xmath103 can be computed in @xmath111 time , so can @xmath132 . in this way , the total time for computing @xmath105 is @xmath133 . note that if @xmath15 is given sorted on @xmath53 , the query time becomes @xmath134 .",
    "the theorem thus follows .",
    "in this section , we present our results in two - dimensional space , where the input point set @xmath16 and the query point @xmath15 are given in the plane .",
    "we generalize the techniques in section [ sec:1d ] . for any query @xmath15 , we first find a global minimum @xmath58 in the plane .",
    "then , for each quadrant @xmath135 of the four quadrants with respect to @xmath58 ( i.e. , the four quadrants partitioned by the vertical line and the horizontal line through @xmath58 ) , we find the top-@xmath0 enns of @xmath15 in @xmath136 ( i.e. , @xmath137 ) and compute the expected distance values @xmath45 for all @xmath138 ; among the found @xmath139 points , we report the set of @xmath0 points with smallest expected distances to @xmath15 as @xmath46 .",
    "note that we view each quadrant as a closed region including its two bounding half - lines ( with the common endpoint  @xmath58 ) .",
    "we describe our algorithm for the first quadrant , and the other three quadrants can be treated in a similar manner .",
    "let @xmath140 be the set of points lying in the first quadrant , i.e. , @xmath141 , the set of top-@xmath0 enns of @xmath15 in @xmath142 .",
    "let @xmath143 denote the @xmath124-th enn of @xmath15 in @xmath142 .",
    "our algorithm computes @xmath144 in the order of @xmath145 .",
    "the problem here is more difficult than that in the 1-d case .",
    "for example , in the 1-d case , for all @xmath146 , the @xmath124-th enn in @xmath95 or @xmath88 can be easily found by scanning a sorted list . here ,",
    "in contrast , by proving a monotonicity property as lemma [ lem:1dmonotone ] , we show that the @xmath124-th enn @xmath143 in @xmath142 must be on a `` skyline '' and we need to somehow search the `` skyline '' .",
    "after @xmath143 is found , we determine a new skyline without considering @xmath147 , and then find @xmath148 by searching the new skyline .",
    "this procedure continues until @xmath149 is obtained .",
    "advanced data structures ( e.g. , compact interval trees @xcite and segment - dragging query data structure @xcite ) are also used for efficient implementations .",
    "consider any uncertain query point @xmath150 and any @xmath0 .",
    "for any point @xmath25 in the plane , denote by @xmath54 the @xmath42-coordinate of @xmath25 and by @xmath151 the @xmath43-coordinate of @xmath25 .",
    "the expected distance of @xmath25 to @xmath15 is @xmath56 , where @xmath34 .",
    "our goal is to find the top-@xmath0 enn set @xmath46 .",
    "a point @xmath25 in the plane is called a _ global minimum point _ if it minimizes the expected distance @xmath45 among all points in the plane .",
    "below , we first find a global minimum point and prove a monotonicity property .",
    "recall that @xmath52 .",
    "let @xmath152 be the point such that @xmath153 if we view @xmath51 as the weight of @xmath64 for each @xmath50 , then @xmath154 is the weighted median of the set @xmath155 @xcite .",
    "similarly , let @xmath156 be the point in @xmath15 such that @xmath157 we claim that @xmath158 is a global minimum point .",
    "to prove the claim , we first present lemma [ lem:2dmonotone ] , which generalizes lemma [ lem:1dmonotone ] .",
    "a path in the plane is _ monotone _",
    "if we move from one endpoint of it to the other , the @xmath42-coordinate ( resp .",
    "@xmath43-coordinate ) is monotonically changing ( either increasing or decreasing ) .",
    "[ lem:2dmonotone ] for any point @xmath25 in the plane with @xmath66 , if we move @xmath25 towards @xmath58 along a monotone path , the expected distance @xmath45 is monotonically decreasing .    according to the definition of @xmath45 , we have @xmath159 where @xmath160",
    "if we move @xmath25 towards @xmath58 along a monotone path , on the @xmath42-projection , we are moving @xmath54 towards @xmath161 . by lemma [ lem:1dmonotone ]",
    ", @xmath162 is monotonically decreasing , so is @xmath163 .",
    "the lemma thus follows .",
    "lemma [ lem:2dmonotone ] implies that @xmath45 attains a global minimum at @xmath84 .",
    "hence , the point @xmath58 is a global minimum point in the plane .",
    "next , based on the point @xmath58 and lemma [ lem:2dmonotone ] , we introduce the minimal points and the skyline , and present some observations .",
    "we first show how to find @xmath164 ( i.e. , the enn of @xmath15 in @xmath142 ) . for any two different points @xmath165 and @xmath166 in @xmath142 , we say that @xmath165 _ dominates _",
    "@xmath166 if and only if @xmath167 and @xmath168 .",
    "a point @xmath25 in @xmath142 is called a _ minimal point _ if no point in @xmath142 dominates @xmath25 .",
    "if @xmath169 dominates @xmath170 , then there exists a monotone path",
    "@xmath171 connecting @xmath166 and @xmath58 such that @xmath172 ( see fig .  [ fig : minpoints ] ) .",
    "by lemma [ lem:2dmonotone ] , @xmath173 .",
    "therefore , to compute @xmath164 , we only need to consider the set of minimal points in @xmath142 , denoted by @xmath174 .",
    "our discussion above leads to the following lemma",
    ".     dominates @xmath166 and the dotted curve connecting @xmath58 and @xmath166 is a monotone path . ]",
    "[ lem:40 ] @xmath175 .",
    "one tempting approach is to first find the set @xmath174 and then find @xmath164 .",
    "unfortunately , here @xmath174 may have @xmath176 points and we can not afford to check every point of @xmath174 .",
    "below , we give a better approach .    for each @xmath50 ,",
    "we induce a horizontal line and a vertical line through @xmath26 , respectively ; let @xmath177 be the arrangement of the resulting @xmath178 lines .",
    "each cell of @xmath177 is a ( possibly unbounded ) rectangle .",
    "each point in @xmath15 is a vertex of @xmath177 .",
    "note that our algorithm does not explicitly compute @xmath177 .",
    "we will show below that @xmath45 is a linear function of @xmath54 and @xmath151 inside any cell @xmath179 of @xmath177 , implying that the enn of @xmath15 in @xmath180 is on the convex hull of @xmath180 , as discussed in @xcite .",
    "for any cell @xmath179 , suppose @xmath181 \\times [ y_{b } , y_{t}]$ ] .",
    "set @xmath182 , @xmath183 , @xmath184 and @xmath185 .",
    "according to the construction of @xmath177 , no point of @xmath15 lies strictly inside  @xmath179 .",
    "hence @xmath186 .",
    "we have the following lemma .    [ lem:50 ] for any point @xmath25 in the cell @xmath179 , @xmath187 , where @xmath188 @xmath189 further , with @xmath190 time preprocessing on @xmath15 , given any cell @xmath179 of @xmath177 , we can compute @xmath191 , @xmath192 , and @xmath193 in @xmath130 time .    the first part ( i.e. , computing the values of @xmath191 , @xmath192 , and @xmath193 ) has been discussed in @xcite and it can also be easily verified by our analysis in lemma [ lem:2dmonotone ] . hence , we omit the proof for it .    for the second part , given any cell @xmath179 ,",
    "our goal is to compute the three values @xmath191 , @xmath192 , and @xmath193 . generally speaking , if",
    ", as preprocessing , we compute the prefix sums of the values @xmath51 and @xmath194 in the sorted list of the points of @xmath15 by their @xmath42-coordinates , and compute the prefix sum of @xmath195 in the sorted list of the points of @xmath15 by their @xmath43-coordinates , then @xmath191 , @xmath192 , and @xmath193 can be computed in @xmath130 time .",
    "the details are given below .",
    "to compute @xmath191 , we need to know the value @xmath113 and the value @xmath196 .",
    "note that @xmath197 .",
    "we can do the following preprocessing .",
    "we sort all points in @xmath15 by their @xmath42-coordinates .",
    "suppose the sorted list is @xmath117 from left to right .",
    "for each @xmath118 , we compute the value @xmath198 . for any given cell @xmath179 ,",
    "let @xmath199 be the @xmath42-coordinate of the vertical line containing the left side of @xmath179 . by binary search on the sorted list @xmath117 , in @xmath130 time",
    ", we can find the rightmost point @xmath200 in @xmath15 such that @xmath201 .",
    "it is easy to see that @xmath202 .",
    "note that the above preprocessing takes @xmath190 time , and @xmath191 can be computed in @xmath130 time .",
    "in similar ways , we can compute @xmath192 and @xmath193 in @xmath130 time , with @xmath190 preprocessing time .",
    "hence , the second part of the lemma follows .",
    "as discussed in @xcite , lemma [ lem:50 ] implies that @xmath203 ( i.e. , the enn of @xmath15 in @xmath180 ) is on the convex hull of @xmath180 .",
    "more specifically , @xmath203 is an extreme point of @xmath180 along a certain direction that is determined by @xmath191 and @xmath192 , and thus we can do binary search on the convex hull to find it .    to compute @xmath164 , the algorithm in @xcite checks every cell @xmath179 of @xmath177 in the first quadrant , and it finds @xmath203 by doing binary search on the convex hull of the points in @xmath180 . the number of cells checked in @xcite is @xmath204 . in contrast , based on lemma [ lem:40 ] , we show below that we only need to check @xmath94 cells .",
    "although the number of minimal points in @xmath174 can be @xmath176 , we show that the number of cells of @xmath177 that contain these minimal points is @xmath94 , and further , we can find these cells efficiently .",
    "if we order the points in @xmath174 by their @xmath42-coordinates and connect every pair of adjacent points by a line segment , then we can obtain a path @xmath205 , which we call a _ skyline _ ( see fig .",
    "[ fig : minpoints ] ) .",
    "the points of @xmath174 are also considered as the _ vertices _ of @xmath205 .",
    "if we move on @xmath205 from its left endpoint to its right endpoint , then the @xmath42-coordinate is monotonically increasing and the @xmath43-coordinate is monotonically decreasing .",
    "hence , @xmath205 is a monotone path .",
    "denote by @xmath206 the set of cells of @xmath177 that contain the minimal points in @xmath174 .",
    "[ lem:60 ] @xmath207 .    due to our general position assumption that no two points in @xmath41 have the same @xmath42-coordinate or @xmath43-coordinate .",
    "each edge of @xmath205 is neither horizontal nor vertical .",
    "because @xmath205 is a monotone path , each line of @xmath177 can intersect @xmath205 at most once .",
    "hence , the number of intersections between @xmath205 and @xmath177 is @xmath94 , which implies that the number of cells that intersect @xmath205 is @xmath94 . since all points in @xmath174 are on @xmath205 , the lemma follows .",
    "due to lemma [ lem:40 ] , the following lemma is obvious .",
    "[ lem:65 ] the point @xmath164 is in one of the cells of @xmath206 .",
    "next , we show how to compute @xmath206 .",
    "a straightforward way is to first compute @xmath177 and then traverse @xmath177 by following the skyline @xmath205 . but this approach is not efficient due to :",
    "( 1 ) computing @xmath177 takes @xmath208 time ; ( 2 ) the size of @xmath205 may be @xmath176 due to @xmath209 in the worst case .",
    "below in lemma [ lem:70 ] , we propose to compute  @xmath206 in @xmath210 time .",
    "first of all , we sort all points in @xmath15 by their @xmath42-coordinates and @xmath43-coordinates , respectively ; accordingly , we obtain a sorted list for the horizontal lines of @xmath177 and a sorted list for the vertical lines of @xmath177 . with these two sorted lists ,",
    "given any point @xmath25 , we can determine the cell of @xmath177 that contains @xmath25 in @xmath130 time by doing binary search on the two sorted lists .",
    "we should point out that there might be other ways to compute @xmath206 , but the algorithm we propose for lemma [ lem:70 ] is particularly useful later when we compute other points in @xmath144 than @xmath164 .",
    "[ lem:70 ] @xmath16 can be preprocessed in @xmath12 time using @xmath11 space , such that given any @xmath15 , we can compute the set @xmath206 in @xmath210 time .",
    "one operation frequently used for computing @xmath206 is the following _ segment - dragging queries_. given any horizontal or vertical line segment @xmath211 , we move @xmath211 along a given direction perpendicular to @xmath211 ; the query asks for the first point of @xmath16 hit by @xmath211 or reports no such point exists .",
    "chazelle @xcite constructed an @xmath11-size data structure in @xmath12 time such that each segment - dragging query can be answered in @xmath96 time .",
    "as preprocessing , we build such a data structure on @xmath16 .",
    "hence , the preprocessing takes @xmath12 time and @xmath11 space .",
    "for each cell @xmath179 of @xmath206 , we call the leftmost point of @xmath212 the _ skyline - left point _ of @xmath179 and call the bottommost point of @xmath213 the _ skyline - bottom point _ of @xmath179 . in other words , if we move along the skyline @xmath205 from its left endpoint to its right endpoint , then the skyline - left point of @xmath179 is the first vertex of @xmath205 we meet in @xmath179 and the skyline - bottom point of @xmath179 is the last vertex of @xmath205 we meet in @xmath179 .",
    "note that if @xmath179 has only one minimal point of @xmath174 , then the only minimum point is both the skyline - left point and the skyline - bottom point of @xmath179 .",
    "we will find the skyline - left point and the skyline - bottom point for each cell @xmath214 .",
    "each such point @xmath25 is determined by a segment - dragging query on a segment @xmath211 and we call @xmath211 the _ generating segment _ of @xmath25 ; @xmath211 will be associated with @xmath25 for later use ( for computing other points in @xmath144 than @xmath164 ) .",
    "further , we will classify these generating segments into four types , and again , they will be useful later in lemma [ lem:100 ] for computing @xmath144 .",
    "all the vertical lines passing through points in @xmath15 partition the space into @xmath94 regions , which we refer to as _ columns _",
    "( including bounding lines ) .",
    "let @xmath215 denote the set of columns of @xmath177 each of which contains at least one cell of @xmath206 .",
    "we search the columns of @xmath215 from left to right . for each column @xmath216",
    ", we will first find the topmost cell and the bottommost cell of @xmath206 in @xmath217 ; then , from the bottommost cell to the topmost cell , we search all other cells of @xmath206 in @xmath217 in a bottom - up fashion . after the searching on @xmath217 is done , we proceed to the next column of @xmath215 .",
    "the details are given below .",
    "note that due to the general position assumption that no two points in @xmath41 have the same @xmath42- or @xmath43-coordinate , each point of @xmath16 lies strictly inside a cell of @xmath177 .",
    "we first determine the leftmost column of @xmath215 , denoted by @xmath217 , which is the one containing the leftmost point @xmath218 of @xmath174 ( see fig .  [",
    "fig : searchcells ] ) .",
    "@xmath218 can be found by the following segment - dragging query .",
    "let @xmath219 .",
    "consider a vertical segment @xmath220 where @xmath221 .",
    "if we drag @xmath222 rightwards ( i.e. , horizontally to the right ) , @xmath218 will be the first point of @xmath142 hit by @xmath222 . by using the segment - dragging query data structure on @xmath16 , @xmath218",
    "can be found in @xmath96 time . after having @xmath218",
    ", @xmath217 can be determined in @xmath130 time using binary search on the sorted list of the vertical lines of @xmath177 .",
    ": the dashed grid is @xmath177 . ]",
    "notice that the cell of @xmath177 that contains @xmath218 is the topmost cell in @xmath223 , which we denote by @xmath224 , and that @xmath218 is the skyline - left point of @xmath224 ( see fig .",
    "[ fig : searchcells ] ) .",
    "the segment @xmath222 is the generating segment of @xmath218 and we classify @xmath222 as an _ @xmath222-type _ generating segment . in general , the @xmath222-type generating segments are used to find the skyline - left points of the topmost cells of the columns of @xmath215 .",
    "next , we determine the bottommost cell of @xmath223 , denoted by @xmath192 .",
    "we first determine the skyline - bottom point @xmath165 of @xmath192 by a segment - dragging query as follows .",
    "let @xmath225 denote the horizontal line @xmath226 .",
    "set @xmath227 .",
    "if we drag @xmath228 upwards , @xmath165 will be the first point of @xmath142 hit by @xmath228 ( see fig .  [",
    "fig : searchcells ] ) .",
    "after @xmath165 is found in @xmath96 time , @xmath192 can be determined in additional @xmath130 time .",
    "@xmath228 is the generating segment of @xmath165 and we classify @xmath228 as the _ @xmath228-type _ generating segment . in general , @xmath228-type generating segments are used to find the skyline - bottom points of the bottommost cells of the columns of @xmath215 .",
    "if @xmath229 , then the column @xmath217 contains only one cell of @xmath206 , and our searching on @xmath217 is done .",
    "below , we assume @xmath230 .    in the sequel , from the bottommost cell @xmath192 , we search the cells of @xmath206 in @xmath217 in a bottom - up manner until we meet the topmost cell @xmath224 .",
    "we first show how to determine the second lowest cell of @xmath231 ( i.e. , the one of @xmath232 right above @xmath192 ) , denoted by @xmath233 .    to determine @xmath233 , we first find the skyline - left point @xmath166 of @xmath192 using a segment - dragging query , as follows .",
    "let @xmath234 be the left side of @xmath192 .",
    "@xmath166 is the first point in @xmath142 hit by dragging @xmath234 rightwards ( see fig .",
    "[ fig : searchcells ] ) .",
    "@xmath234 is the generating segment of @xmath166 and we classify @xmath234 as the _ @xmath234-type _ generating segment . in general ,",
    "each @xmath234-type generating segment is used to find the skyline - left point of a cell whose skyline - bottom point has just been found .",
    "next , we determine @xmath233 by using @xmath166 .",
    "we first determine the skyline - bottom point @xmath235 of @xmath233 . since @xmath236 , @xmath237 ( otherwise @xmath166 would dominate @xmath235 ) .",
    "an easy observation is that @xmath235 is the lowest point among all points of @xmath238 whose @xmath42-coordinates are less than @xmath239 ( see fig .",
    "[ fig : searchcells ] ) .",
    "we can determine @xmath235 by the following segment - dragging query .",
    "let @xmath240 be the horizontal line segment on the top side of the cell @xmath192 such that the left endpoint of @xmath240 is the upper left vertex of @xmath192 and the right endpoint has @xmath42-coordinate @xmath239 ( see fig .",
    "[ fig : searchcells ] ) . due to our general position assumption that no two points in @xmath41 have the same @xmath42- or @xmath43-coordinate",
    ", @xmath235 is the point of @xmath241 hit first by dragging @xmath240 upwards .",
    "after @xmath235 is found , @xmath233 can be determined .",
    "therefore , we can determine @xmath233 in @xmath242 time .",
    "@xmath240 is the generating segment of @xmath235 and we classify @xmath240 as the _ @xmath240-type _ generating segments . in general , @xmath240-type generating segments are used to find the skyline - bottom points for non - bottommost cells of the columns of @xmath215 .",
    "if @xmath243 , we are done searching on @xmath217 . otherwise , we continue the above procedure to search other cells of @xmath232 until we meet the topmost cell @xmath224",
    ".    now we proceed to the next column @xmath244 , in the following way .",
    "we first determine @xmath245 by a segment - dragging query as follows .",
    "recall that @xmath165 is the lowest point in @xmath238 .",
    "let @xmath246 be the vertical line segment on the right bounding line of @xmath217 such that the lower endpoint of @xmath246 has @xmath43-coordinate @xmath247 and the upper endpoint has @xmath43-coordinate @xmath248 ( see fig .  [",
    "fig : searchcells ] ) .",
    "we drag the segment @xmath246 rightwards , and let @xmath249 be the first point of @xmath142 hit by @xmath246 ( see fig .",
    "[ fig : searchcells ] ) .",
    "it is not difficult to see that @xmath249 is a minimal point and the column of @xmath177 containing @xmath249 is @xmath245 .",
    "further , @xmath249 is the skyline - left point of the topmost cell of @xmath250 .",
    "hence , after @xmath249 is found , @xmath245 and the topmost cell of @xmath251 can be determined in @xmath130 time .",
    "@xmath246 is the generating segment of @xmath249 ; note that @xmath246 is an @xmath222-type generating segment .",
    "note that if the above segment - dragging query on @xmath246 fails to find any point ( i.e. , such a point @xmath249 does not exist ) , then all cells of @xmath206 have been found , and we terminate .",
    "otherwise , we proceed to search all cells in @xmath250 in the same way as in the column @xmath217 , and then search other columns of @xmath215 similarly .    for the running time , as shown above , the algorithm spends @xmath242 time finding each cell of @xmath206 . due to @xmath252 ( by lemma [ lem:60 ] ) ,",
    "computing @xmath206 takes @xmath210 time .",
    "the lemma thus follows .      in this section ,",
    "we compute @xmath144 in the order of @xmath145 .    since @xmath164 is in one of the cells of @xmath206 , once we have @xmath206 , we compute the enn of @xmath15 in @xmath253 in each cell @xmath214 ; among the @xmath254 candidate points , @xmath164 is the one with the smallest expected distance to @xmath15 .",
    "once @xmath164 is obtained , we use a similar approach to compute @xmath255 .",
    "let @xmath256 be the skyline of @xmath257 , and let @xmath258 be the set of cells of @xmath177 that contain the vertices of @xmath256 .",
    "again , @xmath255 must be in one of the cells of @xmath258 , and we find @xmath255 by searching the cells of @xmath258 . in general , let @xmath259 be the skyline of @xmath260 , and let @xmath261 be the set of cells of @xmath177 that contain the vertices of @xmath259 .",
    "the point @xmath262 must be in one of the cells of @xmath261 , and we find @xmath262 by searching the cells of @xmath261 .",
    "we repeat this till @xmath149 is found .    for each @xmath263 , since @xmath264 is a skyline , @xmath265 .",
    "a straightforward implementation will need to search @xmath266 cells .",
    "we will show that we only need to search @xmath134 cells in total , and more importantly , we can find all these cells efficiently . specifically ,",
    "we propose an algorithm that can efficiently determine the set @xmath267 by updating the set @xmath268 , for all @xmath269 .    in the sequel , we first present an algorithm that can quickly compute the enn of @xmath15 in @xmath253 for any cell @xmath179 of @xmath177 .",
    "an @xmath9-size data structure was given in @xcite that can be built in @xmath9 time and can compute the enn in any cell @xmath179 of @xmath177 in @xmath270 time . by using compact interval trees @xcite",
    ", we have the following improved result in lemma [ lem:80 ] .    [ lem:80 ] for a set @xmath16 of @xmath2 points in the plane",
    ", an @xmath3-size data structure can be built in @xmath3 time , such that given any axis - parallel rectangle @xmath179 ( e.g. , any cell of @xmath177 ) , the enn of @xmath15 in @xmath180 can be computed in @xmath271 time .",
    "our data structure uses the compact interval tree @xcite , which is for solving the following _ sub - path hull queries _ in @xcite .",
    "let @xmath171 be a simple path of @xmath2 vertices in the plane and suppose the vertices are @xmath272 ordered along @xmath171 .",
    "given two vertex indices @xmath124 and @xmath273 with @xmath274 , the _ sub - path hull query _ asks for the convex hull of all vertices @xmath275 .",
    "a compact interval tree data structure was given in @xcite , and for each sub - path hull query , it can report in @xmath96 time a data structure that represents the convex hull such that any standard binary - search based operation on the convex hull can be implemented in @xmath96 time ( e.g. , finding an extreme point on the convex hull along any given direction ) .",
    "the compact interval tree is of @xmath276 size and can be built in @xmath276 time after the vertices of @xmath171 are sorted by their @xmath42- or @xmath43-coordinates .",
    "our data structure for the lemma is constructed as follows . at the high - level",
    ", it is similar to the two - dimensional orthogonal range tree @xcite .",
    "a balanced binary search tree @xmath277 is built based on the @xmath42-coordinates of the points in @xmath16 .",
    "the leaves of @xmath277 store the points of @xmath16 in sorted order from left to right , and the internal nodes store splitting values to guide the search on @xmath277 . for each node @xmath278 of @xmath277",
    ", it also stores the subset @xmath279 of points in the subtree of @xmath277 rooted at @xmath278 , and @xmath280 is called the _ canonical subset _ of @xmath278 . for each canonical subset @xmath280",
    ", we build a compact interval tree in the following way .",
    "if we sort the points of @xmath280 by their @xmath43-coordinates and connect each pair of adjacent points in the sorted list by a line segment , we obtain a path @xmath281 .",
    "the points in @xmath280 are vertices of @xmath281 .",
    "note that @xmath281 is a simple path and each horizontal line intersects @xmath281 at most once .",
    "we build a compact interval tree data structure on @xmath281 using the approach in @xcite .",
    "this finishes the construction of our data structure",
    ".    for each canonical subset @xmath280 , constructing the compact interval tree data structure on @xmath281 takes @xmath282 time and space , where @xmath283 .",
    "note that the @xmath43-sorted list of @xmath280 can be built during the construction of @xmath277 in a bottom - up manner .",
    "hence , the whole data structure uses @xmath3 space and can be constructed in @xmath3 time .",
    "given any axis - parallel rectangle @xmath179 , our goal is to find the enn of @xmath15 in @xmath253 .",
    "essentially , we are looking for an extreme point in @xmath253 along a certain direction , denoted by @xmath284 .",
    "as discussed in @xcite , @xmath284 is determined by the two factors @xmath191 and @xmath192 defined in lemma [ lem:50 ] , and can be computed in @xmath130 time by lemma [ lem:50 ] .",
    "suppose @xmath285 \\times [ y_{b } , y_{t}]$ ] .",
    "using the range @xmath286 $ ] , we first find the @xmath96 canonical subsets whose union is the set of points in @xmath16 lying between the two vertical lines @xmath287 and @xmath288 . for each such canonical subset @xmath280",
    ", we use the range @xmath289 $ ] to determine the sub - path of @xmath281 inside @xmath179 , which can be done by binary search on the @xmath43-sorted list of @xmath280 ; subsequently , we use the compact interval tree data structure on @xmath281 to ( implicitly ) report the convex hull of the sub - path , after which we search the extreme point on the convex hull along the direction @xmath284 in @xmath96 time . in this way",
    ", we obtain @xmath96 extreme points for these @xmath96 canonical subsets , and the one minimizing the expected distance to @xmath15 is the enn of @xmath15 in @xmath253 . assuming that we have computed the three factors @xmath191 , @xmath192 , and @xmath193",
    "as defined in lemma [ lem:50 ] , for each extreme point found above , its expected distance to @xmath15 can be computed in constant time .",
    "therefore , the enn of @xmath15 in @xmath253 can be found in @xmath271 time .",
    "let @xmath290 for each @xmath263 . by lemma [ lem:80 ]",
    ", we can determine @xmath164 in @xmath291 time .",
    "next we continue to compute @xmath255 . to this end , we need to find the set @xmath258 first . instead of computing @xmath258 from scratch as we did for @xmath206",
    ", we obtain @xmath258 by updating @xmath206 .",
    "specifically , if some cells are both in @xmath206 and @xmath258 , we do not need to compute them again .",
    "in other words , we only need to compute the cells in @xmath292 .",
    "let @xmath293 denote the cell containing @xmath164 .",
    "in fact , we will show that all the cells of @xmath206 except @xmath293 must be in @xmath258 .",
    "the cell @xmath293 may or may not be in @xmath258 . if @xmath294 , then special care needs to be taken when searching @xmath293 because we are looking for @xmath255 and the point @xmath164 should not be considered any more .",
    "the details are given below .",
    "for each @xmath269 , let @xmath295 and @xmath296 .",
    "we first show that @xmath258 can be obtained in @xmath297 time , and specifically , we compute the cells of @xmath298 and determine whether @xmath299 .",
    "we need a dynamic version of the segment - dragging query data structure that can support point deletions and insertions for @xmath16 . in the following lemma [ lem : dynamic ]",
    ", we present such a data structure by using the range trees @xcite .",
    "note that the performance of the data structure in lemma [ lem : dynamic ] may not be the best : since other parts of our algorithm for computing @xmath144 dominate the overall running time , we choose to present a data structure that is simple and does not affect the overall performance .",
    "[ lem : dynamic ] for a set @xmath16 of @xmath2 points in the plane , we can build a data structure in @xmath12 time and @xmath12 space that can answer each segment - dragging query in @xmath271 time and support each point deletion and insertion for @xmath16 in @xmath271 time .",
    "our data structure consists of two range trees , one for horizontal segment - dragging queries and the other for vertical segment - dragging queries .",
    "below , we only present the one for horizontal segment - dragging queries and the other one can be obtained similarly .",
    "we first sort the points in @xmath16 by their @xmath42-coordinates and @xmath43-coordinates , respectively .",
    "we build a balanced binary search tree @xmath277 based on the @xmath42-coordinates of the points in @xmath16 .",
    "the leaves of @xmath277 store the points of @xmath16 in sorted order from left to right .",
    "each node @xmath278 of @xmath277 also stores the subset @xmath280 of points stored in the leaves of the subtree rooted at @xmath278 ; @xmath280 is called the _ canonical subset _ of @xmath278 . for each node @xmath278",
    ", we use another balanced binary search tree @xmath300 to store the points in @xmath280 based on the @xmath43-coordinates of the points .",
    "it is commonly known that @xmath277 can be constructed in @xmath12 time using @xmath12 space @xcite .",
    "consider any segment - dragging query . without loss of generality ,",
    "assume we drag upwards a horizontal segment @xmath301 \\times \\{y(s)\\}$ ] ( i.e. , its @xmath43-coordinate is @xmath302 and its @xmath42-coordinate spans the interval @xmath303 $ ] ) .",
    "we first determine the @xmath96 canonical subsets of @xmath277 whose union is the subset of points of @xmath16 with @xmath42-coordinates lying in @xmath303 $ ] . for each canonical subset @xmath280",
    ", we use the tree @xmath300 to determine in @xmath96 time the lowest point of @xmath280 whose @xmath43-coordinate is no less than @xmath302 and that point will be the first point hit by dragging @xmath211 upwards . after we find such a point in each canonical subset , we report the point with smallest @xmath43-coordinate as the answer to the segment - dragging query for @xmath211 .",
    "the total query time is @xmath271 time .",
    "now consider deleting a point @xmath25 from @xmath16 .",
    "we can simply remove the leave of @xmath277 storing @xmath25 .",
    "further , for each ancestor @xmath278 of the leave storing @xmath25 , we delete @xmath25 from the tree @xmath300 , which can be done in @xmath96 time .",
    "hence , it takes @xmath271 time for each point deletion .",
    "point insertions can be done symmetrically .",
    "note that it will be seen later that the points that are inserted are exactly those points that have been deleted , and therefore , we do not need to do `` rotation '' operations when deleting or inserting a point because the height of @xmath277 will always be bounded by @xmath96 .",
    "the lemma thus follows .",
    "next , we compute @xmath258 based on @xmath206 . by using the data structure in lemma [ lem : dynamic ] , we have the following lemma [ lem:100 ] .",
    "the algorithm for lemma [ lem:100 ] essentially follows the behavior of the algorithm for lemma [ lem:70 ] , but only focuses on searching the cells of @xmath298 .",
    "the efficiency of the algorithm for lemma [ lem:100 ] also hinges on the observation that the cells of @xmath298 form at most two subsets ( separated by @xmath293 if @xmath294 ) of consecutive cells of @xmath258 if we order the cells of @xmath258 from `` northwest '' to `` southeast '' .",
    "[ lem:100 ] we can determine the set @xmath258 in @xmath304 time , where @xmath305 , and more specifically , our algorithm will compute the cells of @xmath298 and determine whether @xmath306 .",
    "we call the order of the cells of @xmath206 by which the skyline @xmath205 crosses them from left to right the _ canonical order _ of @xmath206 . in other words ,",
    "the canonical order of @xmath206 follows the northwest - to - southeast order .",
    "we define the canonical order of @xmath258 similarly .",
    "suppose the canonical order of the cells of @xmath206 is : @xmath307 .",
    "note that we can obtain this ordered list during computing @xmath206 in lemma [ lem:70 ] within the same running time .",
    "recall that when computing @xmath206 we also computed a skyline - left point and a skyline - bottom point for each cell of @xmath206 as well as their generating segments .",
    "let @xmath308 , i.e. , the cell that contains @xmath164 .",
    "we assume @xmath309 and @xmath310 ( otherwise the algorithm is similar and much simpler ) . in order to better understand the algorithm we present below , we first discuss a question : which cells are possibly in @xmath311 ?",
    "imagine that we partition the plane into four quadrants with respect to @xmath164 by the vertical line through @xmath164 and the horizontal line through @xmath164 ; an easy observation is that only the cells intersecting the first quadrant can possibly be in @xmath311 because only points in the first quadrant are dominated by @xmath164 .",
    "further , for each cell @xmath312 with @xmath313 , none of the vertices of the skyline @xmath205 in @xmath312 is dominated by @xmath164 , and thus @xmath312 is still in @xmath258 . in other words ,",
    "all cells of @xmath314 are still in @xmath258 .",
    "the cell @xmath315 may or may not be in @xmath258 . also note that if we remove @xmath164 from @xmath16 , then the skyline - bottom point of @xmath316 may be changed ( see fig .",
    "[ fig : newskyline ] ) , but the skyline - left point of @xmath316 does not change ; for each cell @xmath312 with @xmath317 , neither its skyline - left point nor its skyline - bottom point changes . similarly , due to the removal of @xmath164 , the skyline - left point of @xmath318 may be changed , but its skyline - bottom point does not change ; for each cell @xmath312 with @xmath319 , neither its skyline - left point nor its skyline - bottom point changes .     and the blue points are in @xmath320 .",
    "the skyline - bottom point of the cell @xmath179 is @xmath165 in @xmath205 but @xmath166 in @xmath256 . ]",
    "the above implies that to determine @xmath258 , we need to do the following .",
    "( 1 ) find all cells in @xmath311 , and as in lemma [ lem:70 ] , for each cell of @xmath311 , compute its skyline - left point and skyline - bottom point as well as their generating segments .",
    "( 2 ) determine whether @xmath315 is still in @xmath258 , and if yes , compute its new skyline - left point and skyline - bottom point as well as their generating segments , if any of them changes .",
    "( 3 ) compute the new skyline - bottom point ( and its generating segment ) for @xmath316 if it changes .",
    "( 4 ) compute the new skyline - left point ( and its generating segment ) for @xmath318 if it changes .",
    "let @xmath321 be the dynamic segment - dragging data structure in lemma [ lem : dynamic ] we built on @xmath16 .",
    "below , we give an algorithm that can determine @xmath258 in @xmath304 time , and in particular , we need to find the cells of @xmath311 . intuitively ,",
    "if @xmath322 , then @xmath311 consists of all cells of @xmath258 between @xmath316 and @xmath318 in the canonical order ; otherwise , @xmath311 consists of all cells of @xmath258 between @xmath316 and @xmath315 and all cells between @xmath315 and @xmath318 .",
    "our algorithm essentially follows the behavior of the algorithm in lemma [ lem:70 ] , but only focuses on the cells in @xmath323 .",
    "recall that @xmath315 is the cell of @xmath206 that contains @xmath164 .",
    "first of all , we delete the point @xmath164 from the data structure @xmath321 .",
    "the point @xmath164 can be the skyline - left point of @xmath315 , or the skyline - bottom point of @xmath315 , or both of them , or neither of them .",
    "our algorithm works differently for these cases , as follows .",
    "recall that according to our algorithm in lemma [ lem:70 ] , if @xmath164 is either the skyline - left point or the skyline - bottom point of @xmath315 , then @xmath164 has a generating segment , denoted by @xmath324 .",
    "in other words , @xmath164 is identified by a segment - dragging query on @xmath324 in our algorithm in lemma [ lem:70 ] .    1 .",
    "if @xmath164 is neither the skyline - left point nor the skyline - bottom point of @xmath315 , then @xmath315 is still in @xmath258 and @xmath325 .",
    "in fact , @xmath326 .",
    "further , the skyline - left and skyline - bottom points of any cell of @xmath206 do not change .",
    "hence , we are done for this case .",
    "if @xmath164 is the skyline - left point but not the skyline - bottom point , then according to our algorithm in lemma [ lem:70 ] , the generating segment @xmath324 is either an @xmath234-type or an @xmath222-type . note that since @xmath164 is not the skyline - bottom point of @xmath315 , the skyline - bottom point of @xmath315 is still in the skyline @xmath256 , which implies that @xmath315 is still in @xmath258 and no cell of @xmath311 is between @xmath315 and @xmath318 in the canonical order of @xmath258 .",
    "in other words , all cells of @xmath311 are between @xmath316 and @xmath315 in the canonical order of @xmath258 .",
    "denote by @xmath217 the column of @xmath177 that contains @xmath315 .",
    "if @xmath324 is an @xmath234-type , then @xmath315 is not the topmost cell of @xmath206 in the column @xmath217 , which implies that @xmath316 is in @xmath217 . according to the algorithm in lemma [ lem:70 ]",
    ", @xmath324 is the left side of @xmath315 ( i.e. , @xmath164 is the first point of @xmath16 hit by dragging @xmath324 rightwards ) . by using the data structure @xmath321 ( after deleting @xmath164 ) , we do a segment - dragging query by dragging @xmath324 rightwards to find the first point of @xmath327 hit by @xmath324 , and we denote the point by @xmath25 .",
    "then , @xmath25 is the new skyline - left point of @xmath315 ( without considering @xmath164 ) .",
    "note that @xmath324 is still an @xmath234-type generating segment for @xmath25 .",
    "+ next , from @xmath315 , we continue to find the cells of @xmath311 in a bottom - up manner in the same way as the algorithm in lemma [ lem:70 ] until we meet the cell @xmath316 .",
    "note that it is possible that @xmath325 .",
    "again , it takes two segment - dragging queries ( using @xmath321 ) on each cell of @xmath311 to find its skyline - left and skyline - bottom point as well as their generating segments . also , the algorithm will find the new skyline - bottom point of @xmath316 if it changes in @xmath256 . recall that given any point @xmath25 , we can determine the cell of @xmath177 that contains @xmath25 in @xmath130 time ( by binary search on the sorted vertical lines of @xmath177 and on the sorted horizontal lines of @xmath177 ) .",
    "therefore , in this case , the total running time to determine @xmath258 is @xmath304 time . 2 .   if @xmath324 is an @xmath222-type , then @xmath328 is the topmost cell of @xmath206 in the column @xmath217 , which implies that @xmath316 is in a column to the left of @xmath217 .",
    "denote by @xmath245 the column of @xmath177 containing @xmath316 and let @xmath25 be the skyline - bottom point of @xmath316 . according to the algorithm in lemma [ lem:70 ]",
    ", @xmath324 is the vertical line segment on the right side of @xmath245 where the lower endpoint of @xmath324 is on the horizontal line @xmath329 and the upper endpoint has the same @xmath43-coordinate as @xmath25 , and @xmath164 is the first point of @xmath16 hit by dragging @xmath324 rightwards . + by using the data structure @xmath321 ( after deleting @xmath164 ) ,",
    "we do a segment - dragging query by dragging @xmath324 rightwards ; let @xmath330 be the point returned by the query ( i.e. , @xmath330 is the first point of @xmath331 hit by dragging @xmath324 rightwards ) .",
    "note that @xmath324 is still an @xmath222-type generating segment for @xmath330 .",
    "if @xmath330 is in @xmath315 , then @xmath330 is the new skyline - left point of @xmath315 , and @xmath315 is still the topmost cell of @xmath258 in @xmath217 , which implies @xmath325 .",
    "[ lab:200 ] + if @xmath330 is not in @xmath315 , then let @xmath332 be the cell containing @xmath330 and @xmath330 is the skyline - left point of @xmath332 .",
    "since @xmath164 is not the skyline - bottom point of @xmath315 , the cell @xmath332 is still in the column @xmath217 and is higher than @xmath315 ( see fig .  [",
    "fig : cases](a ) ) .",
    "then , from the cell @xmath315 to @xmath332 , we use the bottom - up procedure as in the algorithm in lemma [ lem:70 ] to find the cells of @xmath258 between @xmath315 and @xmath332 in the column @xmath217 and these cells ( expect @xmath315 ) constitute the set @xmath311 .",
    "again , it takes two segment - dragging queries ( using @xmath321 ) for each cell of @xmath311 to find its skyline - left and skyline - bottom point as well as their generating segments .",
    "+ the total running time is @xmath304 time .",
    "if @xmath164 is the skyline - bottom point but not the skyline - left point , then according to our algorithm in lemma [ lem:70 ] , @xmath324 is either an @xmath228-type or an @xmath240-type .",
    "note that since @xmath164 is not the skyline - left point of @xmath315 , the skyline - left point of @xmath315 is still in the skyline @xmath256 , which implies that @xmath315 is still in @xmath258 and no cell of @xmath311 is between @xmath316 and @xmath315 in the canonical order of @xmath258 .",
    "in other words , all cells of @xmath311 are between @xmath328 and @xmath318 in the canonical order of @xmath258 .",
    "denote by @xmath217 the column of @xmath177 that contains @xmath315 .",
    "+ [ cols=\"^,^,^ \" , ]    1 .",
    "[ item:20 ] if @xmath324 is an @xmath228-type , then @xmath315 is the bottommost cell of @xmath206 in @xmath217 . according to the algorithm in lemma [ lem:70 ]",
    ", @xmath324 is the intersection of @xmath217 and the horizontal line @xmath329 . by using the data structure @xmath321 ( after deleting @xmath164 ) ,",
    "we do a segment - dragging query by dragging @xmath324 upwards and let @xmath25 be the point returned by the query . then @xmath25 is the new skyline - bottom point of @xmath315 .",
    "next , we find the cells in @xmath311 .",
    "+ let @xmath333 be the vertical segment on the right side of @xmath217 where the lower endpoint of @xmath333 is on the horizontal line @xmath329 and the upper endpoint of @xmath333 has the same @xmath43-coordinate as @xmath25 .",
    "we do a segment - dragging query by dragging @xmath333 rightwards and let @xmath330 be the point given by the query .",
    "the segment @xmath333 is the generating segment of @xmath330 , and in fact , @xmath333 is an @xmath222-type generating segment based on our definition in the proof of lemma [ lem:70 ] .",
    "denote by @xmath334 the cell of @xmath177 that contains @xmath330 .",
    "let @xmath245 be the column that contains @xmath318 .",
    "if @xmath334 is in @xmath245 , then there are further two cases .",
    "if @xmath334 is @xmath318 , then @xmath330 is the new skyline - left point of @xmath318 , and @xmath325 .",
    "otherwise , from @xmath318 to @xmath334 , we use the same bottom - up procedure as in the algorithm in lemma [ lem:70 ] to find all cells of @xmath258 between @xmath318 and @xmath334 , and these cells ( expect @xmath318 ) constitute the set @xmath311 .",
    "2 .   if @xmath334 is not in @xmath245 , then it must be in a column to the left of @xmath245 .",
    "from the cell @xmath334 , we proceed in the same way as in the algorithm in lemma [ lem:70 ] until the first time we find a cell in the column @xmath245 .",
    "then , we use the same algorithm as the above case where @xmath334 is in @xmath245 .",
    "[ lab:100 ] + if @xmath324 is an @xmath240-type , then @xmath315 is the not bottommost cell of @xmath206 in @xmath217 , which implies that @xmath318 is in @xmath217 .",
    "we show below that @xmath325 ; further , we will find a new skyline - bottom point in @xmath315 ( without considering @xmath164 ) .",
    "+ based on our algorithm in lemma [ lem:70 ] , the generating segment @xmath324 of @xmath164 is the horizontal line segment on the top side of @xmath318 whose left endpoint is the upper left vertex of @xmath318 and right endpoint has the same @xmath42-coordinate as the skyline - left point of @xmath318 . by using the data structure @xmath321 ( after deleting @xmath164 ) , we do a segment - dragging query by dragging @xmath324 upwards , and let @xmath25 be the point returned by the query .",
    "+ note that @xmath164 is the lowest point of @xmath16 that will be hit by dragging @xmath324 upwards and @xmath164 is in @xmath315 .",
    "the point @xmath25 is the lowest point of @xmath331 that will be hit by dragging @xmath324 upwards ( see fig .",
    "[ fig : cases](b ) ) .",
    "clearly , @xmath25 can not be any cell of @xmath217 lower than @xmath315 .",
    "on the other hand , since @xmath164 is not the skyline - left point of @xmath315 , the skyline - left point of @xmath315 is still in @xmath315 .",
    "note that when we drag @xmath324 upwards , the skyline - left point of @xmath315 will be hit by @xmath324 ( but not necessarily the first point hit by @xmath324 ) , and this implies that the point @xmath25 must be in @xmath315 .",
    "in other words , @xmath25 is the skyline - bottom point of @xmath315 in the new skyline @xmath256 , and further @xmath325 .",
    "+ in any case above , the total running time is @xmath304 time . 4 .",
    "it remains to discuss the case where @xmath164 is both the skyline - left point and the skyline - bottom point of @xmath315 . in this case",
    ", @xmath164 is the first time identified as either the skyline - left point or the skyline - bottom point . in general , unlike the second and the third cases where the cells of @xmath311 are either between @xmath316 and @xmath315 or between @xmath315 and @xmath318 in the canonical order of @xmath258 , in this case the cells of @xmath311 may lie both between @xmath316 and @xmath315 and between @xmath315 and @xmath318 .",
    "hence , our algorithm may need to search on both `` directions '' .",
    "in addition , in the previous three cases , the cell @xmath315 must be in @xmath258 ; in this case , however , it is possible that @xmath315 is not in @xmath258 . 1 .",
    "if @xmath164 is the first time identified as the skyline - left point of @xmath315 , then @xmath315 must be the topmost cell of @xmath206 in @xmath217 where @xmath217 is the column of @xmath177 that contains @xmath315 , which implies that its generating segment @xmath324 must be an @xmath222-type .",
    "+ let @xmath25 be the skyline - bottom point of the cell @xmath316 .",
    "let @xmath245 be the column of @xmath177 that contains @xmath316 . according to the algorithm in lemma [ lem:70 ]",
    ", @xmath324 is the vertical line segment on the right side of @xmath245 where the lower endpoint of @xmath324 is on the horizontal line @xmath329 and the upper endpoint has the same @xmath43-coordinate as @xmath25 . by using the data structure @xmath321 ( after deleting @xmath164 ) , we do a segment - dragging query by dragging @xmath324 rightwards , and let @xmath330 be the point given by the query .",
    "let @xmath334 be the cell that contains @xmath330 .",
    "note that @xmath330 is the skyline - left point of @xmath334 .",
    "let @xmath335 be the column that contains the cell @xmath318 .",
    "note that it is possible that @xmath336 . 1 .",
    "if @xmath334 is also in @xmath335 , then there are further two cases .",
    "+ if @xmath337 , then @xmath325 and @xmath322 .",
    "+ otherwise , @xmath334 must be higher than @xmath318 in @xmath335 .",
    "then , from the cell @xmath318 to @xmath334 , we use the same bottom - up procedure as in the algorithm in lemma [ lem:70 ] to find all cells of @xmath258 between @xmath318 and @xmath334 , and these cells ( except @xmath318 and possibly @xmath315 ) constitute the set @xmath311 .",
    "note that the cell @xmath315 may or may not be identified as in @xmath258 in the above procedure .",
    "[ item:100 ] if @xmath334 is not in @xmath335 , then @xmath334 must be in a column to the left of @xmath335 .",
    "we proceed from @xmath334 in the same way as in the algorithm in lemma [ lem:70 ] until the first time we find a cell in @xmath335 .",
    "then , we use the same algorithm as in the above case ( i. ) to determine @xmath258 .",
    "+ in any case , the total running time is @xmath304 time . 2 .   if @xmath164 is the first time identified as the skyline - bottom point , then its generating segment @xmath324 can be either an @xmath228-type or an @xmath240-type segment .",
    "let @xmath217 be the column that contains @xmath315 . in this case",
    ", @xmath315 is not the topmost cell of @xmath258 in @xmath217 since otherwise @xmath164 would be the first time identified as the skyline - left point of @xmath315 .",
    "this means that @xmath316 is also in @xmath217 .",
    "1 .   if @xmath324 is an @xmath228-type segment , then @xmath315 must be the bottommost cell of @xmath206 in the column @xmath217 . according to the algorithm in lemma [ lem:70 ]",
    ", @xmath324 is the intersection of @xmath217 and the horizontal line @xmath329 . by using the data structure @xmath321 ( after deleting @xmath164 ) , we do a segment - dragging query by dragging @xmath324 upwards and let @xmath25 be the point returned by the query .",
    "let @xmath338 be the cell that contains @xmath25 . clearly , @xmath338 is in @xmath258 .",
    "let @xmath339 be the subset of cells in @xmath311 that are between @xmath316 and @xmath338 in the canonical order of @xmath258 , and let @xmath340 ; in other words , @xmath341 is the subset of cells in @xmath311 that are between @xmath338 and @xmath318 in the canonical order of @xmath258 .",
    "below , we will find @xmath339 and @xmath341 separately , by searching from @xmath338 towards two `` directions '' : one towards @xmath316 and the other towards @xmath318 .",
    "+ since @xmath316 is also in @xmath217 , from @xmath338 to @xmath316 , we use the bottom - up procedure to find the cells of @xmath258 between @xmath338 and @xmath316 , and these cells ( except @xmath316 and possibly @xmath315 ) constitute the set @xmath339 . note that the cell @xmath315 may also be identified in @xmath258 .",
    "+ next , we find the set @xmath341 , which can be done by the same algorithm as in case [ item:20 ] .",
    "we omit the details .",
    "2 .   if @xmath324 is an @xmath240-type , then @xmath315 is the not bottommost cell of @xmath206 in @xmath217 , which implies that @xmath318 is in @xmath217 .",
    "+ based on our algorithm in lemma [ lem:70 ] , the generating segment @xmath324 of @xmath164 is the horizontal line segment on the top side of @xmath318 whose left endpoint is the upper left vertex of @xmath318 and right endpoint has the same @xmath42-coordinate as the skyline - left point of @xmath318 . by using the data structure @xmath321 ( after deleting @xmath164 ) , we do a segment - dragging query by dragging @xmath324 upwards , and let @xmath25 be the point returned by the query .",
    "let @xmath338 be the cell that contains @xmath25 .",
    "+ note that @xmath164 is the lowest point of @xmath16 that will be hit by dragging @xmath324 upwards and @xmath164 is in @xmath315 .",
    "the point @xmath25 is the lowest point of @xmath331 that will be hit by dragging @xmath324 upwards .",
    "since @xmath316 is also in @xmath217 , @xmath316 is higher than @xmath315 .",
    "hence , the cell @xmath338 is one of the cells of @xmath217 between ( and including ) @xmath316 and @xmath315 ( this is because the vertices of @xmath205 in @xmath316 are all to the left of the right endpoint of @xmath324 and to the right of the left endpoint of @xmath324 ) .",
    "hence , from @xmath338 to @xmath316 , we can use the bottom - up procedure as before to find the cells of @xmath258 , these cells ( except @xmath316 and possibly @xmath315 ) constitute the set @xmath311 . + in any case , the total running time is @xmath304 time .    in summary , we can determine the set @xmath258 in @xmath304 time . more specifically , for each cell in @xmath311 , we have computed its skyline - left point and its skyline - bottom point as well as their generating segments .",
    "we have also determined whether @xmath315 is in @xmath258 , and if yes , its new skyline - bottom point and skyline - left point are computed if any of them changes .",
    "the new skyline - bottom point of @xmath316 has been found if it changes , and the new skyline - left point of @xmath318 has been found if it changes .",
    "in addition , in the above algorithm , we can also order all cells of @xmath311 ( with @xmath315 if @xmath342 ) from northwest to southeast with the same running time , and therefore , along with the ordered cells from @xmath343 to @xmath316 and the ordered cells from @xmath318 to @xmath344 , we have obtained a canonical order for  @xmath258 .    by lemma [ lem:100 ] , we can determine the set @xmath258 , and in particular , we have the set @xmath311 explicitly , and we know whether the cell @xmath294 . similarly to lemma [ lem:65 ] , the second enn @xmath255 is in one of the cells of @xmath258 .",
    "denote by @xmath345 .    to find @xmath255 , as in the case for finding @xmath164 ,",
    "a straightforward approach is to compute the enn of @xmath15 in @xmath346 for each @xmath347 , and then among the @xmath348 candidate points , report the one with the smallest expected distance to @xmath15 as @xmath255 .",
    "this approach will lead to an @xmath266 time query algorithm for finding @xmath144 .",
    "below , we present a better method .",
    "note that when computing @xmath164 , we have computed the enn @xmath203 for each @xmath349 . also , for each cell @xmath350 , if @xmath351 , then @xmath350 and @xmath352 .",
    "therefore , if we maintain the enns for all cells of @xmath353 , we do not have to compute them again .",
    "in other words , when computing @xmath255 , we only need to compute the enns in the cells of @xmath311 .",
    "in addition , if @xmath294 , we will use a special approach to compute @xmath354 . to maintain the enns in the involved cells mentioned above",
    ", we use a min - heap @xmath355 , as follows .",
    "when searching @xmath164 , for each @xmath350 , after the enn @xmath203 is computed , we insert it into @xmath355 with its expected distance to @xmath15 as the `` key '' . after the enns for all cells of @xmath206 are computed and inserted into @xmath355 , the point in @xmath355 with the smallest key is @xmath164 .",
    "note that @xmath355 has @xmath356 points . to compute the second enn @xmath255",
    ", we first determine @xmath311 by lemma [ lem:100 ] . by the `` extract - min '' operation of min - heaps @xcite",
    ", we remove @xmath164 from @xmath355 .",
    "we compute the enns of the cells in @xmath298 and insert them into @xmath355 . if @xmath357 , then the point of @xmath355 with the smallest key is @xmath255 .",
    "otherwise , we use the following special approach to determine @xmath354 .",
    "one tempting approach is to have a dynamic version of the data structure in lemma [ lem:80 ] to support point deletions from @xmath16 .",
    "unfortunately , due to the `` static '' nature of compact interval trees , it is not clear to us how to design such a dynamic data structure without deteriorating the performance . here",
    ", we give another method to `` mimic '' point deletions without deteriorating the performance of the data structure in lemma [ lem:80 ] , as follows .",
    "we divide the cell @xmath293 into two sub - cells @xmath358 and @xmath359 using the horizontal line through @xmath164 . hence , @xmath164 is on the common edge of the two sub - cells .",
    "note that due to our general position assumption , no point of @xmath16 is on the boundary of @xmath293 .",
    "hence , no point of @xmath345 is on the boundary of @xmath358 ( or @xmath359 ) .",
    "below , we use @xmath358 ( resp . , @xmath359 ) to refer to only its interior . instead of computing the enn @xmath354 and",
    "insert it into @xmath355 , we compute the enns @xmath360 and @xmath361 and insert them into @xmath355 ; note that one of them is @xmath354 .",
    "the reason we divide @xmath293 into two sub - cells as above is that we can now simply use the data structure in lemma [ lem:80 ] to compute @xmath360 and @xmath361 ; in other words , @xmath164 appears to be `` deleted '' from the data structure of lemma [ lem:80 ] .",
    "clearly , now , the point of @xmath355 with smallest key is @xmath255 .    to analyze the running time for computing @xmath255 ,",
    "@xmath258 can be determined in @xmath304 time , after which , we compute the enns for the cells of @xmath311 and possibly for the two sub - cells of @xmath293 in @xmath362 time by lemma [ lem:80 ] .",
    "then , one `` extract - min '' operation and at most @xmath363 insertions on @xmath355 together take @xmath364 time ; note that @xmath365 ( here `` 2 '' corresponds to the number of possible sub - cells ) .",
    "it should be noted that we need to explicitly maintain the two sub - cells @xmath358 and @xmath359 because later they may be further divided into smaller sub - cells ( e.g. , if @xmath366 and @xmath367 , then @xmath358 will be divided for computing @xmath368 ) .",
    "also note that these sub - cells are only maintained for the computation of enns and they will not be considered when we determine the sets @xmath267 s ( in lemma [ lem:100 ] ) .",
    "after @xmath255 is found , we proceed to search the third enn @xmath368 similarly .    in general ,",
    "suppose we have computed @xmath267 and @xmath143 , and we are about to find @xmath148 .",
    "we first determine @xmath369 by computing @xmath370 and determining whether @xmath371 , where @xmath372 is the cell of @xmath261 that contains @xmath143 ; this can be done in @xmath373 time similarly as in lemma [ lem:100 ] .",
    "note that for any cell @xmath374 , it never appears in @xmath375 for any @xmath376 .",
    "next , we determine the enns in the cells of @xmath377 by lemma [ lem:80 ] and insert them into the heap @xmath355 .",
    "we also need to remove @xmath143 from @xmath355 . if @xmath378 , then the point of @xmath355 with smallest key is @xmath148 . otherwise , as before",
    ", we divide @xmath372 into two sub - cells and compute their enns and insert them into @xmath355 .",
    "note that @xmath372 may have already been divided into many sub - cells before .",
    "if so , they are explicitly maintained , and we can find the sub - cell that contains @xmath143 in @xmath379 time by binary search since @xmath372 has at most @xmath380 sub - cells ordered by @xmath43 values .",
    "then , we divide the sub - cell into two smaller sub - cells by the horizontal line through @xmath143 and compute the enns in the two smaller sub - cells by lemma [ lem:80 ] and insert them into @xmath355 .",
    "now , the point of @xmath355 with smallest key is @xmath148 .    to analyze the running time for computing @xmath148 ,",
    "@xmath369 can be determined in @xmath373 time .",
    "the time for computing the enns for the cells in @xmath377 and possibly two sub - cells is bounded by @xmath381 .",
    "there are @xmath382 insertions and one `` extract - min '' operation on @xmath355 , which together take @xmath383 time . note that @xmath384 .",
    "we repeat the above procedure until @xmath149 is found .",
    "we have the following lemma ( an observation is @xmath385 ) .",
    "[ lem:110 ] the overall running time of our query algorithm for finding @xmath386 is @xmath7 .",
    "let @xmath387 denote the total number of cells in @xmath388 .    by lemma [ lem:70 ] ,",
    "we compute @xmath206 in @xmath210 time . by lemma [ lem:100 ] ,",
    "the total time for finding all cells of @xmath389 is @xmath390 .    in the entire algorithm ,",
    "the total number of operations for finding the enns in the cells of @xmath177 ( not including the sub - cells ) is @xmath391 because the above cells are those in @xmath388 . after finding @xmath143 for each @xmath263 ,",
    "we have at most two more sub - cells , and thus the total number of operations for finding the enns in the sub - cells is @xmath106 .",
    "hence , by lemma [ lem:80 ] , the total time for finding the enns in the cells and sub - cells is @xmath392 .",
    "also , we only need to explicitly maintain at most @xmath106 sub - cells in the entire algorithm .",
    "similarly , the total number of operations on the heap @xmath355 is @xmath393 , and the size of @xmath355 in the entire algorithm is always bounded by @xmath393 .",
    "hence , the total operations on @xmath355 take @xmath394 time .    in summary ,",
    "the overall running time is @xmath395 . to prove the lemma",
    ", we prove an important _ claim _ : @xmath396 .",
    "the proof for the claim is based on the fact that @xmath265 for each @xmath263 , since each skyline @xmath264 intersects @xmath94 cells . in particular , @xmath397 . for each @xmath398 , all the cells of @xmath267 except @xmath372 are in @xmath369 and the cell @xmath372 may or may not be in @xmath369 .",
    "hence , @xmath399 , i.e. , @xmath400 .",
    "therefore , @xmath401 . due to @xmath402 , we have @xmath403 .",
    "the above claim thus follows .",
    "due to the above claim , the overall running time for finding @xmath144 is @xmath404 , which is @xmath7 ( to see this , note that if @xmath405 , then since @xmath406 , @xmath407 holds ) .",
    "note that after obtaining @xmath144 , we also need to insert the points of @xmath144 back to the data structure in lemma [ lem : dynamic ] for answering other top-@xmath0 enn queries in future .",
    "we summarize our methods for the top-@xmath0 enn searching .",
    "our preprocessing on @xmath16 includes the following steps .",
    "( 1 ) sort all points in @xmath16 by their @xmath42-coordinates and @xmath43-coordinates , respectively . ( 2 )",
    "build the dynamic segment - dragging query data structure in lemma [ lem : dynamic ] on @xmath16 .",
    "( 3 ) construct the data structure in lemma [ lem:80 ] . the total time and space",
    "are dominated by step ( 3 ) , i.e. , @xmath3 time and @xmath3 space .    given any uncertain query point @xmath15 and any @xmath0 , we compute @xmath46 in the following steps .",
    "( 1 ) sort all points in @xmath15 by their their @xmath42-coordinates and @xmath43-coordinates , respectively . ( 2 )",
    "process @xmath15 as in lemma [ lem:50 ] .",
    "( 3 ) compute a global minimum point @xmath58 .",
    "( 4 ) divide the plane into four quadrants with respect to @xmath58 . in each quadrant @xmath135 , we find the top-@xmath0 enns of @xmath15 in @xmath136 as follows .",
    "suppose @xmath135 is the first quadrant .",
    "( 4.1 ) find the set @xmath206 by lemma [ lem:70 ] , and for each cell @xmath350 , find the enn of @xmath15 in @xmath180 by lemma [ lem:80 ] and insert the point into a min - heap @xmath355 ; the point of @xmath355 with smallest expected distance to @xmath15 is the enn of @xmath15 in @xmath136 . ( 4.2 ) based on @xmath206 and @xmath164 , determine @xmath258 and find @xmath255 .",
    "( 4.3 ) the above procedure continues until we find @xmath149 .",
    "( 5 ) among the found @xmath139 points from all four quadrants of @xmath58 ( their expected distances to @xmath15 have also been computed ) , we report the @xmath0 points with smallest expected distances to @xmath15 as @xmath46 .",
    "( 6 ) insert the above @xmath139 points back to the data structure in lemma [ lem : dynamic ] ( for answering other top-@xmath0 enn queries in future ) .    for the running time of the query algorithm ,",
    "the first three steps can be done in @xmath190 time ; step ( 4 ) can be done in @xmath7 time .",
    "step ( 5 ) takes @xmath106 time .",
    "step ( 6 ) needs @xmath408 time .",
    "hence , the total query time is bounded by @xmath7 .    [ theo:2d ] given a set @xmath16 of @xmath2 exact points in the plane , a data structure of @xmath3 size can be built in @xmath3 time , such that for any uncertain query point @xmath15 and any @xmath0 , the top-@xmath0 enn set @xmath46 can be found in @xmath409 time .",
    "we present efficient algorithms and data structures for the top-@xmath0 nearest neighbor searching in the plane where the data are exact and the query is uncertain under the @xmath1 distance metric . previously , only approximation or heuristic solutions were given .",
    "our results also improve the previous work for the special case where @xmath8 .",
    "an interesting open problem is whether and how the techniques proposed in this paper can be extended to higher dimensional spaces .",
    "agarwal , b.  aronov , s.  har - peled , j.m .",
    "phillips , k.  yi , and w.  zhang .",
    "nearest neighbor searching under uncertainty ii . in _ proc .",
    "of the 32nd symposium on principles of database systems _ , pages 115126 , 2012 .",
    "r.  cheng , j.  chen , m.  mokbel , and c .- y .",
    "probabilistic verifiers : evaluating constrained nearest - neighbor queries over uncertain data . in _ proc . of the 24th international conference on data engineering _ , pages 973982 , 2008 .",
    "r.  cheng , l.  chen , j.  chen , and x.  xie .",
    "evaluating probability threshold k - nearest - neighbor queries over uncertain data . in _ proc .",
    "of the 12th international conference on extending database technology : advances in database technology _ , pages 672683 , 2009 .",
    "kriegel , p.  kunath , and m.  renz .",
    "probabilistic nearest - neighbor query on uncertain objects . in _ proc . of the 12th international conference on database systems for advanced applications",
    "_ , pages 337348 , 2007 .",
    "h.  li , h.  lu , b.  huang , and z.  huang .",
    "two ellipse - based pruning methods for group nearest neighbor queries . in _ proc . of the 13th annual acm international workshop on geographic information systems _ , pages 192199 , 2005 .",
    "y.  luo , h.  chen , k.  furuse , and n.  ohbo .",
    "efficient methods in finding aggregate nearest neighbor by projection - based filtering . in _ proc . of the 12nd international conference on computational science and its applications _ , pages 821833 , 2007 ."
  ],
  "abstract_text": [
    "<S> in this paper , we present algorithms for the top-@xmath0 nearest neighbor searching where the input points are exact and the query point is uncertain under the @xmath1 metric in the plane . </S>",
    "<S> the uncertain query point is represented by a discrete probability distribution function , and the goal is to efficiently return the top-@xmath0 expected nearest neighbors , which have the smallest expected distances to the query point . </S>",
    "<S> given a set of @xmath2 exact points in the plane , we build an @xmath3-size data structure in @xmath4 time , such that for any uncertain query point with @xmath5 possible locations and any integer @xmath0 with @xmath6 , the top-@xmath0 expected nearest neighbors can be found in @xmath7 time . even for the special case where </S>",
    "<S> @xmath8 , our result is better than the previously best method ( in pods 2012 ) , which requires @xmath9 preprocessing time , @xmath9 space , and @xmath10 query time . </S>",
    "<S> in addition , for the one - dimensional version of this problem , our approach can build an @xmath11-size data structure in @xmath12 time that can support @xmath13 time queries and the query time can be reduced to @xmath14 time if the locations of @xmath15 are given sorted . in fact , the problem is equivalent to the aggregate or group nearest neighbor searching with the weighted sum as the aggregate distance function operator . </S>"
  ]
}