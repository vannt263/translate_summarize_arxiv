{
  "article_text": [
    "the amount of multimedia traffic transfered over the internet is steadily growing , mainly driven by video traffic .",
    "a large fraction of this traffic is already carried by dedicated content delivery networks ( cdns ) and this trend is expected to continue @xcite .",
    "the largest cdns are distributed , with a herd of storage points and data centers spread over many networks . with the cooperation of the internet service providers",
    ", cdns can deploy storage points anywhere in the network . however , these cooperations require a lot of negociations and are therefore only slowly getting established , and it also seems necessary to consider alternatives to a global cache - network planning .",
    "an easily deployable solution is to make use of the ressources ( storage , upload bandwidth ) already present at the edge of the network .",
    "such an architecture offers a lot of potential for cost reduction and quality of service upgrade , but it also comes with new design issues @xcite as the operation of a very distributed overlay of small caches with limited capabilities is harder than that of a more centralized system composed of only a few large data centers .    in this paper , we consider a hybrid cdn consisting of both a data center and an edge - assistance in the form of many small servers located at the edge of the network ; we call such a system an edge - assisted cdn .",
    "the small servers are here to reduce the cost of operation of the cdn , while the data center helps provide reliability and quality of service guarantees .",
    "we stress the fact that the small servers have a limited storage and service capacity as well as limited coordination capabilities , which makes cheap devices eligible for that role . as their respective roles hint , we assume the service of a request by the data center is much more costly than by a small server , thus requests are served from the small servers in priority .",
    "in fact , we only send requests to the data center if no idle server storing the corresponding content is present .",
    "we assume the data center is dimensioned to absorb any such remaining flow of requests .",
    "we restrict our attention here to contents which require immediate service , which is why we do not allow requests to be delayed or queued .",
    "stringent delay constraints are indeed often the case for video contents for example in the context of a video - on - demand ( vod ) service , which represent already more than half of the internet traffic .    in that context , we address the problem of determining which contents to store in the small servers .",
    "the goal is to find content placement strategies which offload as much as possible the data center . in this optic , it is obvious that popular contents should be more replicated , but there is still a lot of freedom in the replication strategy . in order to compare different policies , we model the system constituted by the small servers alone as a loss network , where each loss corresponds to a request to the data center .",
    "the relevant performance metric is then simply the expected number of losses induced by each policy .",
    "we make three main contributions : first , using a mean - field heuristic for our system with a large number of servers with limited coordination , we compute accurately the loss rate of each content based on its replication ; building on this analysis , we derive an optimized static replication policy and show that it outperforms significantly standard replications in the literature ; finally , we propose adaptive algorithms attaining the optimal replication .",
    "contrary to most caching schemes , our eviction rules are based on loss statistics instead of access statistics ; in particular our algorithms do not know or learn the popularities of the contents and will adapt automatically .",
    "we also propose a simple mechanism relying heavily on our mean - field analysis that allows us to speed up significantly the rate of adaptation of our algorithms . at each step , extensive simulations support and",
    "illustrate our main points .",
    "the rest of the paper is organized as follows : we review related work in section  [ sec : related work ] and describe more in detail our system model in section  [ sec : model ] . in section  [ sec : analysis by approximation ] , we analyse our model under a mean - field approximation and obtain an asymptotic expression for the optimal replication . then , in section  [ sec : replication policy ] , leveraging the insights from the analysis we propose new adaptive schemes minimizing the average loss rate , as well as ways to further enhance their adaptation speed .",
    "our edge - assisted cdn model is related to a few other models .",
    "a major difference though is our focus on modeling the basic constraints of a realistic system , in particular regarding the limited capacity of servers ( in terms of storage , service and coordination ) and the way requests are handled , i.e. the _ matching _ policy , which role is to determine which server an incoming request should be directed to .",
    "we indeed consider the most basic matching policy : an idle server storing the content is chosen uniformly at random ; and no queueing of requests , no re - direction during service and no splitting are allowed .",
    "the reason for modeling such stringent constraints and refusing simplifying assumptions in this domain is that this should lead to fundamental intuitions and qualitative results that should apply to most practical systems .",
    "our edge - assisted cdn model is very similar to the distributed server system model of @xcite ; we merely use a different name to emphasize the presence in the core of the network of a data center , which makes it clear what performance metric to consider , while otherwise availability of contents for example may become a relevant metric .",
    "the edge - assisted cdn model is also related to peer - to - peer ( p2p ) vod systems , which however have to deal with the behavior of peers , and to cache networks , where caches are deployed in a potentially complex overlay structure in which the flow of requests entering a cache is the `` miss '' flow of another one .",
    "previous work on p2p vod typically does not model all the fundamental constraints we mentioned , and the cache networks literature tends to completely obliterate the fact servers become unavailable while they are serving requests and to focus on alternative performance metrics such as search time or network distance to a copy of requested contents .    in distributed server networks , a maximum matching policy ( with re - packing of the requests at any time but",
    "no splitting or queueing ) has been considered in @xcite . in this",
    "setting , in @xcite it was shown that replicating contents proportionally to their popularity leads to full efficiency in large system and large storage limits , and in @xcite it was further proved that there is actually a wide range of policies having such an asymptotic property and an exact characterisation of the speed at which efficiency decreases for a given policy was obtained . however , that formula for the efficiency is too complicated to derive any practical scheme from it , and anyway maximum matching at any time is probably unrealistic for most practical systems .",
    "finding efficient content replications in cache networks is a very active area of research .",
    "the optimal replication is not yet understood , however adaptive strategies are studied ; they create replicas for contents when incoming requests arrive and evict contents based on either random , least frequently used ( lfu ) or least recently used ( lru ) rules , or a variation of those .",
    "there is an extensive literature on the subject and we only mention the most relevant papers to the present work .",
    "an approximation for lru cache performance is proposed in @xcite and further supported in @xcite ; it allows @xcite to study cache networks with a two - levels hierarchy of caches under a mix of traffic with various types of contents .",
    "based on the differences in their respective popularity distributions , @xcite advocates that vod contents are cached very close to the network edge while user - generated contents , web and file sharing are only stored in the network core . in a loose sense",
    ", we also study such type of two - layer systems , with the small servers at the edge of the network and the data center in the core , and address the question of determining whether to store contents at the edge ( and in what proportion ) or to rely on the core to serve them .    concerning p2p vod models ,",
    "content pre - fetching strategies have been investigated in many papers ( e.g. @xcite ) , where optimal replication strategies and/or adaptive schemes were derived .",
    "they work under a maximum matching assumption and most of them assume infinite divisibility of the requests , i.e. that a request can be served in parallel by all the servers storing the corresponding content ; we want to take into account more realistic constraints in that respect .",
    "one can also explore the direction of optimizing distributed systems with a special care for the geographical aspects as in @xcite .",
    "these papers solve content placement and matching problems between many regions , while not modeling in a detailed way what happens inside a region .",
    "finally , most of the work in these related domains focuses on different performance metrics : in hierarchical cache networks , @xcite addresses the problem of joint dimensioning of caches and content placement in order to reduce overall bandwidth consumed ; @xcite optimizes replication in order to minimize search time and devises elegant adaptive strategies towards that end .",
    "surprisingly , for various alternative objectives and network models , the proportional ( to popularity ) replication exhibits good properties : it minimizes the download time in a fully connected network with infinite divisibility of requests and convex server efficiency @xcite , as well as the average distance to the closest cache holding a copy of the requested content in a random network with exponential expansion @xcite ; and recall that @xcite also advocated using this replication policy .",
    "therefore , due to its ubiquity in the literature , proportional replication is the natural and most relevant scheme to which we should compare any proposed policy ; we will obtain substantial improvements over it in our model .",
    "in this section , we describe in detail our edge - assisted cdn model .",
    "as already mentioned , the basic components of an edge - assisted cdn are a data center and a large number @xmath0 of small servers .",
    "the cdn offers access to a catalog of @xmath1 contents , which all have the same size for simplicity ( otherwise , they could be fragmented into constant - size segments ) .",
    "the data center stores the entire catalog of contents and can serve all the requests directed towards it , whereas each small server can only store a fixed number @xmath2 of contents and can provide service for at most one request at a time .",
    "we can represent the information of which server stores which content in a bipartite graph @xmath3 , where @xmath4 is the set of servers , @xmath5 the set of contents , and there is an edge in @xmath6 between a content @xmath7 and a server @xmath8 if @xmath8 stores a copy of @xmath7 ; an edge therefore indicates that a server is able to serve requests for the content with which it is linked .",
    "given numbers of replicas @xmath9 for the contents , we assume that the graph @xmath10 is a uniform random bipartite graph with fixed degrees @xmath2 on the servers side and fixed degree sequence @xmath9 on the contents side .",
    "this models the lack of coordination between servers and would result from them doing independent caching choices .",
    "we do not allow requests to be queued , delayed or re - allocated during service , and as a result a server which begins serving a request will then remain unavailable until it completes its service .",
    "splitting of requests is not considered either , in the sense that only one server is providing service for a particular request . with these constraints , at any time , the subset of edges of @xmath10 over which some service is being provided form a generalized matching of the graph @xmath10 ( the analysis in @xcite relies heavily on this ) .",
    "the contents of the catalog may have different popularities , leading to different requests arrival rates @xmath11 .",
    "we let @xmath12 be the average request rate , i.e. @xmath13 . according to the independent reference model ( irm ) , the requests for the various contents arrive as independent poisson processes with rates @xmath11 .",
    "the service times of all the requests are independent exponential random variables with mean @xmath14 , which is consistent with all the servers having the same service capacity ( upload bandwidth ) and all the contents having the same size .",
    "we let @xmath15 denote the expected load of the system , i.e. @xmath16 .",
    "the distribution of popularities of the contents is left arbitrary , although in practice zipf distributions are often encountered ( see @xcite for a page - long survey of many studies ) and it seems therefore mandatory to evaluate the replication schemes proposed under a zipf popularity distribution .    when a request arrives , we first look for an idle server storing the corresponding content ; if none is found then the request is sent to the data center to be served at a higher cost . as in the end all the requests",
    "are served without delay , be it by the data center or by a small server , the performance of the system is mainly described by the cost associated with the service .",
    "this cost is mostly tied to the number of requests served by the data center , therefore the most relevant performance metric here is the fraction of the load left - over to the data center .",
    "then , it makes sense to view the requests that the small servers can not handle as `` lost '' .",
    "in fact , the system consisting of the small servers alone with fixed caches is a loss network in the sense of @xcite .",
    "this implies that the system corresponds to a reversible stochastic process , with a product form stationary distribution @xmath17 .",
    "however , the exact expression of that stationary distribution is too complex to be exploited in our case ( as opposed to @xcite where the maximum matching assumption yields a much simpler expression ) .",
    "we call @xmath18 the rate at which requests for content @xmath7 are lost , and @xmath19 the average loss rate among contents , i.e. @xmath20 . the main goal is to make @xmath19 as small as possible .",
    "we refer to the fraction of lost requests @xmath21 as the inefficiency of the system .",
    "finally , as in many real cases cdns are quite large , with often thousands of servers and similar numbers of contents , it seems reasonable to pay a particular attention to the asymptotics of the performance of the system as @xmath22 . to keep things simple",
    ", we can assume that the number of servers @xmath0 and the number of contents @xmath1 grow to infinity together , i.e. @xmath23 for some fixed @xmath24 .",
    "in addition , as storage is cheap nowadays compared to access bandwidth , it also makes sense to focus on a regime with @xmath2 large ( but still small compared to @xmath1 ) . in these regimes",
    ", the inefficiency will tend to @xmath25 as the system size increases under most reasonable replications ( as was shown in @xcite under the maximum matching assumption ) .",
    "however , as the cost of operation is only tied to losses , further optimizing an already small inefficency is still important and can lead to order improvements on the overall system cost .",
    "in this section , we propose an approximation to understand in a precise manner the relation between any fixed replication of contents and the loss rates in the system .",
    "this analytical step has many advantages : it allows us to formally demonstrate that to optimize the system one needs to make the loss rates equal for all the contents ; as a consequence we obtain an explicit expression for the optimal replication ( subsection  [ sec : optimized replication ] ) ; finally , in subsection  [ sec : virtual losses ] , we will leverage our analytical expression for the full distribution of the number of available replicas of a content to propose a mechanism enhancing the speed of adaptive algorithms .",
    "we validate our approximation and show that our optimized replication strategy largely outperforms proportional replication through extensive simulations .      for a given fixed constitution of the caches ( i.e. a fixed graph @xmath10 ) ,",
    "the system as described in the previous section is markovian , the minimum state space indicating which servers are busy ( it is not necessarily to remember which content they serve ) .",
    "we want to understand how the loss rate @xmath18 for a particular content @xmath7 relates to the graph @xmath10 , but using too detailed information about @xmath10 , such as the exact constitution of the caches containing @xmath7 , would have the drawback that it would not lead to a simple analysis when considering adaptive replication policies ( as the graph @xmath10 would then keep changing ) . therefore , we need to obtain a simple enough but still accurate approximate model tying @xmath18 to @xmath10 .",
    "the expected loss rate @xmath18 of content @xmath7 is equal to its requests arrival rate @xmath11 multiplied by the steady state probability that @xmath7 has no replicas available .",
    "let @xmath26 be the total number of replicas of content @xmath7 and @xmath27 be its number of _ available _ replicas , i.e. those stored on a currently idle server .",
    "we thus want to compute @xmath28 to get access to @xmath18 .",
    "however , the markov chain describing the system is too complicated to be able to say much on its steady state . in order to simplify the system",
    ", one can remark that in a large such system the state of any fixed number of servers ( i.e. their current caches and whether they are busy or idle ) are only weakly dependent , and similarly the number of available replicas @xmath27 of any fixed number of contents are only weakly dependent .",
    "therefore , it is natural to approximate the system by decoupling the different contents and the different servers ( similar phenomenon are explained rigorously in @xcite ) . in other words , this amounts to forgetting the exact constitution of the caches ; as a result , the correlation between contents which are stored together is lost .",
    "then , the evolution of @xmath27 becomes a one dimensional markov chain , independent of the values of @xmath29 for other contents , and we can try to compute its steady - state distribution .    for any @xmath30 ,",
    "the rate of transition from @xmath31 to @xmath32 is always @xmath33 : it is the rate at which one of the @xmath33 occupied servers storing @xmath7 completes its current service ; we do not need to distinguish whether a server is actually serving a request for @xmath7 or for another content @xmath34 as we assume the service times are independent and identically distributed across contents . for any @xmath35 , the transitions from @xmath31 to @xmath36 are more complicated .",
    "they happen in the two following cases :    * either a request arrives for content @xmath7 and as @xmath37 it is assigned an idle servers storing @xmath7 ; * or a request arrives for another content @xmath34 and it is served by a server which also stores content @xmath7",
    ".    the first event occurs at rate @xmath11 and the second one at expected rate @xmath38,\\ ] ] where @xmath39 indicates that the content @xmath7 is stored on the server @xmath8 . at any time and for any @xmath34",
    ", @xmath40 is equal to @xmath29 .",
    "the term @xmath41 is equal in expectation to the number of idle servers storing @xmath34 ( i.e. @xmath42 ) times the probability that such a server also stores @xmath7 . as we forget about the correlations in the caching , this last probability is approximated as the probability to pick one of the @xmath43 remaining memory slots in an idle servers storing @xmath34 when we dispatch at random the @xmath27 available replicas of content @xmath7 between all the remaining slots in idle servers .",
    "thus , @xmath44\\approx\\frac{z_{c'}(d-1)}{(1-\\rhoeff)md}z_c,\\ ] ] where @xmath45 is the average load effectively absorbed by the system , so that the total number of memory slots on the idle servers is @xmath46 .",
    "we also neglected the @xmath29 memory slots occupied by @xmath34 in these idle servers when computing the total number of idle slots @xmath46 .",
    "we obtain the following approximation for the expected rate at which the second event occurs : @xmath47 where we neglected the rate @xmath11 at which requests arrive for content @xmath7 compared to the aggregate arrival rate of requests , and we let @xmath48 . note that the interesting regime , with reasonably high effective load @xmath49 , corresponds to large values of @xmath50 , as @xmath51 implies @xmath52 .",
    "the markov chain obtained satisfies the local balance equations : for @xmath30 , @xmath53 this yields the following steady - state probability : @xmath54 where the binomial coefficient does not really have a combinatorial interpretation as one of its arguments is not an integer , but should only be understood as @xmath55 , for @xmath56 and @xmath57 .",
    "we now have an approximation for the full distribution of the number @xmath27 of available replicas of content @xmath7 , which yields an approximation for the loss rate @xmath58 .",
    "we can also compute the mode @xmath59 of this distribution : @xmath60 , which can be used as an approximation for the expectation @xmath61 $ ] ( in fact , simulations show the two are nearly indistinguishable ) .",
    "we further simplify the expression obtained by providing a good approximation for the normalization factor @xmath62 in equation  ( [ eqn : approximation z_c ] ) : @xmath63 to that end , we use the fact that we aim at small loss rates , and thus most of the time at small probabilities of unavailability .",
    "therefore , the bulk of the mass of the distribution of @xmath27 should be away from @xmath25 , which means that the terms for @xmath64 close to @xmath26 should be fairly small in the previous expression .",
    "we thus extend artificially the range of the summation in this expression and approximate @xmath62 as follows : @xmath65 we obtain the following approximation for @xmath28:@xmath66 finally , as we are interested in large systems and large storage / replication , we can leverage the following asymptotic behavior : @xmath67 for @xmath68 large enough and where @xmath69 is the gamma function : @xmath70 ; @xmath71 is the @xmath72-th harmonic number : @xmath73 ; and @xmath74 is the euler - mascheroni constant : @xmath75 . for large number of replicas @xmath26 , we thus obtain the approximation : @xmath76 where we let @xmath77 and the term @xmath78 is an approximation of @xmath79 . the approximation for @xmath28",
    "immediately yields an approximation for the loss rate @xmath18 : @xmath80 note that the expression of @xmath50 involves the average effective load @xmath49 , which itself depends on the average loss rate @xmath19 .",
    "we thus have a fixed point equation in @xmath19 ( just as in @xcite ) , which we can easily solve numerically .",
    "indeed , the output value @xmath19 of our approximation is a decreasing function of the input value @xmath19 used in @xmath49 , which implies simple iterative methods converge exponentially fast to a fixed - point value for @xmath19 .      in this subsection",
    ", we exploit the approximation obtained in equation  ( [ eqn : loss rate ] ) to understand which replication strategy minimizes the total loss rate in the system .",
    "in other words , we approximately solve the optimization problem : @xmath81 note that the approximation from equation  ( [ eqn : loss rate ] ) is consistent with the intuition that @xmath18 is a decreasing , convex function of @xmath26 .",
    "indeed , letting @xmath82 since we have @xmath83 in the regime of interest , we compute @xmath84 the loss rate @xmath18 is a convex function of @xmath26 as shown by @xmath85 as a consequence , the optimization problem  ( [ eqn : optimization problem ] ) is approximately convex , and we thus obtain an approximate solution by making the first derivatives of the loss rates @xmath86 equal . keeping only the dominant orders in @xmath26 , we have @xmath87    in the first order , equalizing the first derivatives in  ( [ eqn : first derivative ] ) using the expression in  ( [ eqn : loss rate ] ) leads to equalizing the number of replicas for every content , i.e. setting @xmath88 where @xmath89 is the average number of replicas of contents . going after the second order term",
    ", we get @xmath90 we therefore obtain that the asymptotically optimal replication is uniform with an adjustment due to popularity of the order of the log of the average number of replicas .",
    "this agrees with the results in @xcite and goes beyond . finally , inserting back this expression for @xmath26 into equation  ( [ eqn : loss rate ] ) yields @xmath91 which shows that the average loss rate @xmath19 under optimized replication behaves as the loss rate of an imaginary average content ( one with popularity @xmath12 and replication @xmath92 ) .      in the process of approximating the loss rate @xmath18 of a content @xmath7",
    ", we performed many approximations based on asymptotic behaviors for large systems and large storage / replication .",
    "it is therefore necessary to check whether the formula of equation  ( [ eqn : loss rate ] ) is not too far off , which we do in this section via simulation .",
    "the systems we simulate are of quite reasonable size ( with a few hundred contents and servers ) . however , the accuracy of the approximation should only improve as the system grows .",
    "we use two scenarios for the popularity distribution of the contents : a class model ( similar to that of @xcite ) , which allows us to compare between many contents with similar characteristics , and a zipf popularity model , which is deemed more realistic .",
    "we evaluate the accuracy of the approximation using proportional replication ( other replications were also simulated and yield similar results ) . to compute the approximate expressions ,",
    "we solve numerically the fixed point equation in @xmath19 .",
    "we simulate systems under a reasonably high load of @xmath93 .",
    "as often , it is mainly interesting to know how the system behaves when the load is high , as otherwise its performance is almost always good .",
    "however , as requests arrive and are served stochastically , if the average load were too close to @xmath14 then the instantaneous load would exceed @xmath14 quite often , which would automatically induce massive losses and mask the influence of the replication .",
    "in fact , it is easy to see that we need to work with systems with a number of servers @xmath0 large compared to @xmath94 in order to mitigate this effect .",
    ".properties of the content classes , and numerical results on the accuracy of the approximation . [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     the setup with the class model is the following : there are @xmath95 contents divided into @xmath96 classes ; the characteristics of the classes are given in the first part of table  [ table : class properties ] .",
    "the popularities in table  [ table : class properties ] together with @xmath95 and @xmath97 result in @xmath98 servers .",
    "each server can store @xmath99 contents , which is @xmath100 of the catalog of contents .",
    "we let the system run for @xmath101 units of time , i.e. contents of class 3 should have received close to @xmath101 requests each .",
    "@xmath102{available_replicas_class_model.eps } & \\includegraphics[width=1.7in , keepaspectratio]{loss_rates_class_model.eps } \\end{array}\\ ] ]    figure  [ fig : simulation vs approximation , class model ] and the second part of table  [ table : class properties ] show the results for the class model : the left part of figure  [ fig : simulation vs approximation , class model ] shows the distributions of the numbers of available replicas for all the contents against the approximation from equation  ( [ eqn : approximation z_c ] ) for each class ; the right part shows the loss rates for all the contents against the approximation from equation  ( [ eqn : loss rate ] ) for each class . although it is not apparent at first sight , the left part of figure  [ fig : simulation vs approximation , class model ] actually displays a plot for each of the @xmath103 contents , but the graphs for contents of the same class overlap almost perfectly , which supports our approximation hypothesis that the stationary distribution of the number of available replicas is not very dependent on the specific servers on which a content is cached or on the other contents with which it is cached .",
    "this behavior is also apparent on the right part of figure  [ fig : simulation vs approximation , class model ] , as the loss rates for the contents of the same class are quite similar . from figure",
    "[ fig : simulation vs approximation , class model ] and table  [ table : class properties ] , it appears that the approximations from equations  ( [ eqn : approximation z_c ] ) and  ( [ eqn : loss rate ] ) are quite accurate , with for example a relative error of around @xmath100 in the inefficiency of the system ( @xmath104 vs @xmath105 ) .",
    "we consider such an accuracy is quite good given that some of the approximations done are based on a large storage / replication asymptotic , while the simulation setup is with a storage capacity of @xmath99 contents only and contents of class @xmath106 ( responsible for the bulk of losses ) have only @xmath107 replicas each .",
    "we now turn to the zipf popularity model . in this model ,",
    "the contents are ranked from the most popular to the least ; for a given exponent parameter @xmath108 , the popularity of the content of rank @xmath109 is given by @xmath110 .",
    "we use two different values for the zipf exponent @xmath108 , @xmath111 and @xmath112 , as proposed in @xcite .",
    "the exponent @xmath111 is meant to represent correctly the popularity distribution for web , file sharing and user generated contents , while the exponent @xmath112 is more fit for video - on - demand , which has a more accentuated popularity distribution .",
    "we simulate networks of @xmath113 contents and @xmath114 servers of storage capacity @xmath115 under a load @xmath97 .",
    "this yields an average content popularity @xmath116 .",
    "note that under proportional replication the numbers of replicas of the most popular contents are actually larger than the number of servers @xmath0 for @xmath117 ; we thus enforce that no content is replicated in more than @xmath118 of the servers . as expected and confirmed by the simulations , this is anyway benefical to the system .",
    "each setup is simulated for at least @xmath101 units of time .",
    "@xmath102{log - log_available_zipf.eps } & \\includegraphics[width=1.7in , keepaspectratio]{loss_rates_approximation_zipf.eps } \\end{array}\\ ] ]    we show the results for the zipf model with both exponent values in figure  [ fig : simulation vs approximation , zipf model ] and in the third part of table  [ table : class properties ] : the left part of figure  [ fig : simulation vs approximation , zipf model ] shows the expected number of available replicas for all the contents against the approximation from equation  ( [ eqn : approximation z_c ] ) ; the right part shows the loss rates for all the contents against the approximation from equation  ( [ eqn : loss rate ] ) .",
    "again , the results from both figure  [ fig : simulation vs approximation , zipf model ] and table  [ table : class properties ] confirm the accuracy of the approximations .",
    "we now turn to evaluating the performance of the optimized replication from equation  ( [ eqn : optimal replication ] ) .",
    "figure  [ fig : optimized replication ] shows the resulting loss rates under the optimized replication , with both zipf exponents .",
    "this figure is to be compared with the right part of figure  [ fig : simulation vs approximation , zipf model ] , which showed the same results for proportional replication .",
    "it is clear that the optimized replication succeeds at reducing the overall inefficiency @xmath21 compared to proportional replication ( from @xmath119 to @xmath120 for @xmath121 , and from @xmath122 to @xmath123 for @xmath117 ) .",
    "note that in the case of zipf exponent @xmath117 the popularity distribution is more `` cacheable '' as it is more accentuated , and the optimized replication achieves extremely small loss rates .",
    "however , the loss rates for all the contents are not trully equalized , as popular contents are still too much favored ( as can be seen for zipf exponent @xmath121 ) . this may be because the expression for optimized replication is asymptotic in the system size and storage capacity .",
    "hence , there is still room for additional finite - size corrections to the optimized replication .    as an outcome of this section ,",
    "we conclude that the approximations proposed are accurate , even at reasonable system size .",
    "in addition , the optimized scheme largely outperforms proportional replication . in the next section",
    ", we derive adaptive schemes equalizing the loss rates of all the contents and achieving similar performances as the optimized replication .",
    "in a practical system , we would want to adapt the replication in an online fashion as much as possible , as it provides more reactivity to variations in the popularity of contents .",
    "such variations are naturally expected for reasons such as the introduction of new contents in the catalog or a loss of interest for old contents .",
    "thus , blindly enforcing the replication of equation  ( [ eqn : optimal replication ] ) is not always desirable in practice . instead",
    ", we can extract general principles from the analysis performed in section  [ sec : analysis by approximation ] to guide the design of adaptive algorithms .    in this section ,",
    "we first show how basic adaptive rules from cache networks can be translated into our context based on the insights from section  [ sec : analysis by approximation ] to yield adaptive algorithms minimizing the overall loss rate .",
    "then , we show how the more detailed information contained in equation  ( [ eqn : approximation z_c ] ) allows the design of faster schemes attaining the same target replication .",
    "finally , we validate the path followed in this paper by evaluating through simulations the adaptive schemes proposed .",
    "the analysis in section  [ sec : optimized replication ] shows that the problem of minimizing the average loss rate @xmath19 is approximately a convex problem , and that therefore one should aim at equalizing the derivatives @xmath124 of the stationary loss rates of all the contents .",
    "in addition , equation  ( [ eqn : first derivative ] ) points out that these derivatives are proportional to @xmath125 in the limit of large replication / storage , and thus equalizing the loss rates should provide an approximate solution for the optimization problem .",
    "an immediate remark at this point is that it is unnecessary to store contents with very low popularity @xmath11 if the loss rate of the other contents is already larger than @xmath11 .",
    "an adaptive replication mechanism is characterized by two rules : a rule for creating new replicas and another one for evicting contents to make space for the new replicas . in order to figure out how to set these rules",
    ", we analyze the system in the fluid limit regime , with a separation of timescales such that the dynamics of the system with fixed replication have enough time to converge to their steady - state between every modification of the replication . achieving this separation of timescales in practice",
    "would require slowing down enough the adaptation mechanism , which reduces the capacity of the system to react to changes .",
    "therefore , we keep in mind such a separation of timescales as a justification for our theoretical analysis but we do not slow down our adaptive algorithms .",
    "when trying to equalize the loss rates , it is natural to use the loss events to trigger the creation of new replicas .",
    "then , new replicas for content @xmath7 are created at rate @xmath18 , and we let @xmath126 be the rate at which replicas of @xmath7 are deleted from the system . in the fluid limit regime under the separation of timescale assumption , the number of replicas of @xmath7 evolves according to @xmath127 , where all the quantities refer to expectations in the steady - state of the system with fixed replication . at equilibrium , we have @xmath128 and @xmath129 for all the contents @xmath7 , thus we need @xmath130 for all @xmath7 to equalize the loss rates .",
    "this would be achieved for example if we picked a content for eviction uniformly at random among all contents .",
    "however , the contents eligible for eviction are only those which are available ( although some systems may allow modifying the caches of busy servers , as serving requests consumes upload bandwidth while updating caches requires only download bandwidth ) .",
    "therefore , the most natural and practical eviction rule is to pick an _ available _ content uniformly at random ( hereafter , we refer to this policy simply as the random policy ) .",
    "then , the eviction rate for content @xmath7 is given by @xmath131 .",
    "so , at equilibrium , we can expect to have @xmath132 , @xmath133 . in a large system , with large storage / replication and loss rates tending to zero ,",
    "the difference with a replication trully equalizing the loss rates is negligeable .",
    "if we are confronted to a system with a large number of very unpopular contents though , we can compensate for this effect at the cost of maintaining additional counters for the number of evictions of each content .",
    "once the rule for creating replicas if fixed , we immediately obtain a family of adaptive algorithms by modifying the eviction rules from the cache network context as we did above for the random policy .",
    "instead of focusing on `` usage '' and the incoming requests process as in cache networks with the lfu and lru policies , we react here to the loss process .",
    "this yields the lfl ( least frequently lost ) and lrl ( least recently lost ) policies .",
    "random , lrl , and lfl are only three variants of a generic adaptive algorithm which performs the following actions at every loss for content @xmath7 :    1 .",
    "create an empty slot on an available server , using the eviction rule ( random / lrl / lfl ) ; 2 .",
    "add a copy of the content @xmath7 into the empty slot .",
    "the three eviction rules considered here require a very elementary centralized coordinating entity .",
    "for the random rule , this coordinator simply checks which contents are available , picks one uniformly at random , say @xmath34 , and then chooses a random idle server @xmath8 storing @xmath34 .",
    "the server @xmath8 then picks a random memory slot and clears it , to store instead a copy of @xmath7 . in the case of lrl ,",
    "the coordinator needs in addition to maintain an ordered list of the least recently lost content ( we call such a list an lrl list ) .",
    "whenever a loss occurs for @xmath7 , the coordinator picks the least recently lost available content @xmath34 based on the lrl list ( possibly restricting to contents less recently lost than @xmath7 ) and then updates the position of @xmath7 in the lrl list .",
    "it then picks a random idle server @xmath8 storing @xmath34 , which proceeds as for random . finally , for lfl , the coordinator would need to maintain estimates of the loss rates of each content ( by whatever means , e.g. exponentially weighted moving averages ) ; when a loss happens , the coordinator picks the available content @xmath34 with the smallest loss rate estimate and then proceeds as the other two rules .",
    "this last rule is more complicated as it involves a timescale adjustement for the estimation of the loss rates , therefore we will focus on the first two options in this paper .",
    "note that the lfl policy does not suffer from the drawback that the eviction rate is biased towards popular contents due to their small unavailability , and this effect is also attenuated under the lrl policy .",
    "we point out that it is possible to operate the system in a fully distributed way ( finding a random idle server first and then picking a content on it by whatever rule ) , but this approach is biased into selecting for eviction contents with a large number of available replicas ( i.e. popular contents ) , which will lead to a replication with reduced efficency .",
    "it is of interest for future work to find a way to unbias such a distributed mechanism .      in the algorithms proposed in the previous subsection",
    ", we use the losses of the system as the only trigger for creating new replicas .",
    "it is convenient as these events are directly tied to the quantity we wish to control ( the loss rates ) , however it also has drawbacks .",
    "firstly , it implies that we want to generate a new replica for a content precisely when we have no available server for uploading it , and thus either we send two requests at a time to the data center instead of one ( one for the user which we could not serve and one to generate a new copy ) or we must delay the creation of the new replica and tolerate an inedaquate replication in - between , which also hinders the reactivity of the system . secondly ,",
    "unless in practice we intend to slow down the adaptation enough , there will always be oscillations in the replication . if losses happen",
    "almost as a poisson process , then only a bit of slow - down is necessary to moderate the oscillations , but if they happen in batches ( as it may very well be for the most popular contents ) then we will create many replicas in a row for the same contents .",
    "if in addition we use the lrl or lfl rules for evicting replicas , then the same contents will suffer many evictions successively , fuelling again the oscillations in the replication .",
    "finally , it is very likely that popularities are constantly changing . if the system is slow to react , then the replication may never be in phase with the current popularities but always lagging behind .",
    "for all these reasons , it is important to find a way to decouple the adaptation mechanisms from the losses in the system to some extent , and at least to find other ways to trigger adaptation .",
    "we propose a solution , relying on the analysis in section  [ sec : analysis by approximation ] .",
    "a loss for content @xmath7 occurs when , upon arrival of a request for @xmath7 , its number of available replicas is equal to @xmath25 . in the same way ,",
    "whenever a request arrives , we can use the current value of @xmath27 to estimate the loss rate of @xmath7 .",
    "indeed , equation  ( [ eqn : approximation z_c ] ) tells us how to relate the probability of @xmath31 to the loss rate @xmath18 , for any @xmath134 .",
    "of course , successive samples of @xmath27 are very correlated ( note that losses may also be correlated though ) and we must be careful not to be too confident in the estimate they provide . a simple way to use those estimates to improve",
    "the adaptation scheme is to generate _ virtual _ loss events , to which any standard adaptive scheme such as those introduced in the previous subsection may then react .",
    "to that end , whenever a request for @xmath7 arrives , we generate a virtual loss with a certain probability @xmath135 depending on the current number of available replicas @xmath27 .",
    "the objective is to define @xmath135 so that the rates @xmath136 of generation of virtual losses satisfy @xmath137 for all @xmath138 ( so that the target replication still equalizes loss rates ) and @xmath139 is as high as possible ( to get fast adaptation ) .    as a first step towards setting the probability @xmath135 , we write equation  ( [ eqn : approximation z_c ] ) as follows : @xmath140 this shows that , for any fixed value @xmath141 with @xmath142 , we can generate events at rate @xmath18 by subsampling at the time of a request arrival with @xmath31 with a first probability @xmath143 if on the contrary @xmath141 is such that @xmath144 , then the value of @xmath145 given above is larger than @xmath14 as we can not generate events at rate @xmath18 by subsampling even more unlikely events .",
    "if we generated virtual losses at rate @xmath18 as above for each value of @xmath141 , then the total rate of virtual losses for content @xmath7 would be @xmath146 , which clearly still depends on @xmath7 .",
    "we thus proceed in two additional steps towards setting @xmath135 : we first restrict the range of admissible values of @xmath27 , for which we may generate virtual losses , by excluding the values @xmath141 such that @xmath144 . in the regime @xmath147 , this can be done in a coarse way by letting @xmath148 and rejecting all the values @xmath149 .",
    "indeed , @xmath150 and the distribution of @xmath27 is unimodal with the mode at a smaller value @xmath151 .",
    "now , subsampling with probability @xmath152 when a request arrives for content @xmath7 and @xmath153 would generate events at a total rate @xmath154 .",
    "thus , it suffices to subsample again with probability @xmath155 to obtain the same rate of virtual losses for all the contents ( another approach would be to restrict again the range of admissible values of @xmath141 , e.g. to values around the mode @xmath59 ) .    to sum up , our approach is to generate a virtual loss for content @xmath7 at each arrival of a request for @xmath7 with probability @xmath156 the rate @xmath157 at which virtual losses are generated for content @xmath7 is then given by @xmath158 , which is independent of @xmath7 as planned .",
    "whenever a virtual loss occurs , we can use whatever algorithm we wanted to use in the first place with real losses ; there is no need to distinguish between the real losses and the virtual ones .",
    "for example , if we use the lrl policy , we update the position of @xmath7 in the lrl list and create a new replica for @xmath7 by evicting a least recently lost available content ( from a server which does not already store @xmath7 ) .",
    "if we choose to test for virtual losses at ends of service for @xmath7 ( which yields the same outcome in distribution , as the system is reversible ) , the new replica can simply be uploaded by the server which just completed a service for @xmath7 . furthermore , in practice , we advocate estimating the values of @xmath159 and @xmath135 on the fly rather than learning these values for each content : @xmath50 can be computed from @xmath49 , which is naturally approximated by the ratio of the current number of busy servers to the total number of servers ; similarly , we can approximate @xmath11 by the current number of requests for @xmath7 being served . from these",
    ", we can compute @xmath159 and @xmath135 ; it is only necessary to maintain an estimate for @xmath160 , which can be for example an average over the few least popular contents updated whenever a service ends for one of them .    in the next subsection ,",
    "we evaluate the performance of the adaptative schemes proposed and the virtual losses mechanism .      before getting to the simulation results ,",
    "let us just mention that the complexity of simulating the adaptive algorithms grows very fast with the system size ( with @xmath1 , @xmath0 and @xmath2 ) .",
    "indeed , it is easy to see that simulating the system for a fixed duration @xmath161 requires @xmath162 operations .",
    "furthermore , the time needed for the random algorithm to converge , when started at proportional replication , is roughly of the order of @xmath163 , where @xmath19 is the average loss rate for the limit replication , which decreases exponentially fast in @xmath2 as seen in equation  ( [ eqn : optimal gamma ] ) .",
    "therefore , if we want to compare all the adaptive schemes , we can not simulate very large networks .",
    "anyway , our intention is to show that our schemes work even for networks of reasonable size .",
    "as in section  [ sec : simulation approximation ] , we used zipf popularity distributions with exponents @xmath111 and @xmath112 and a class model to evaluate the performance of the various schemes .",
    "the results are qualitatively identical under all these models , so we only show the results for zipf popularity with exponent @xmath121 .",
    "we compare the various schemes in terms of the replication achieved and its associated loss rates , as well as the speed at which the target replication is reached .",
    "we do not slow down the dynamics of the adaptive schemes even though this necessarily induces some oscillations in the replication obtained .",
    "nonetheless , this setup is already sufficient to demonstrate the performance of the adaptive schemes .",
    "it would be interesting to quantify the potential improvement if one reduces the oscillations of the replication obtained ( e.g. by quantifying the variance of the stationary distribution for the number of replicas for each content ) ; we leave this out for future work . also",
    ", we did not account for the load put on the data center to create new copies of the contents ; one can simply double the loss rates for the adaptive schemes to capture this effect .",
    "note that if adaptation speed is not a priority , one can trade it off to almost cancel this factor of @xmath164 .",
    "finally , concerning the virtual loss mechanism , we estimate all the quantities involved on the fly , as recommended in the previous section .",
    "@xmath165{loss_rates_zipf.eps } & \\includegraphics[width=1.55in , keepaspectratio]{log - log_replication_zipf.eps } \\end{array}\\ ] ]        in figure  [ fig : loss rates and replication ] , we show results for the various adaptive schemes . on the left part of the figure , we show the stationary loss rates of all the contents ; on the right part we show in log - log scale the stationary expectation of the numbers of replicas for each content .",
    "this plot shows firstly that all the adaptive schemes converge to the same replication and secondly that this replication equalizes the loss rates , as intended .",
    "in addition , the adaptive schemes perform even better than the optimized static replication , which suffers from finite network / finite storage effects , as they manage to find the right balance between popular and unpopular contents .",
    "we compare the adaptation speed of the various schemes on figure  [ fig : time evolution ] , where we plot both the evolution of the average number of replicas of the @xmath166 most popular contents and that of the @xmath166 least popular ones , starting from proportional replication .",
    "as expected , the lrl schemes are faster than the random ones , but more importantly this plot clearly demonstrates the speed enhancement offered by the virtual loss method of section  [ sec : virtual losses ] . regarding the benefits of such an enhanced reaction capability",
    ", there is an interesting property which we did not point out nor illustrate with the simulations : the virtual loss scheme has the potential to follow a constantly evolving popularity profile at no cost , as the required creations of replicas to adapt to the changing popularities can be done without requesting copies of the contents to the data center .",
    "we addressed the problem of content replication in edge - assisted cdns , with a special attention to capturing the most important constraints on server capabilities and matching policy .",
    "based on large system and large storage asymptotics , we derived an accurate approximation for the performance of any given replication , thereby allowing offline optimization of the replication .",
    "in addition , levaraging the insights gathered in the analysis , we designed adaptive schemes converging to the optimal replication .",
    "our basic adaptive algorithms react to losses , but we proposed further mechanisms to move away from losses and adapt even faster than they occur .      , ``",
    "cisco visual networking index : forecast and methodology , 2012 - 2017 , '' may 2013 .",
    "[ online ] .",
    "available : http://www.cisco.com / en / us / solutions / collateral / ns341/ns525/ns537/ns705% /ns827/white_paper_c11 - 481360.pdf[http://www.cisco.com / en / us / solutions / collateral / ns341/ns525/ns537/ns705% /ns827/white_paper_c11 - 481360.pdf ]        m.  leconte , m.  lelarge , and l.  massouli , `` bipartite graph structures for efficient balancing of heterogeneous loads , '' _ acm sigmetrics performance evaluation review _",
    "40 , no .  1 ,",
    "pp . 4152 , 2012 .",
    "c.  fricker , p.  robert , j.  roberts , and n.  sbihi , `` impact of traffic mix on caching performance in a content - centric network , '' in _ ieee conference on computer communications workshops ( infocom wkshps ) _ , 2012 ,",
    "pp . 310315 .",
    "w.  jiang , s.  ioannidis , l.  massouli , and f.  picconi , `` orchestrating massively distributed cdns , '' in _ proceedings of the 8th international conference on emerging networking experiments and technologies_.1em plus 0.5em minus 0.4emacm , 2012 , pp .",
    "133144 .",
    " , `` max percentile replication for optimal performance in multi - regional p2p vod systems , '' in _ ninth international conference on quantitative evaluation of systems ( qest)_.1em plus 0.5em minus 0.4emieee , 2012 , pp .",
    "238248 .",
    "s.  tewari and l.  kleinrock , `` on fairness , optimal download performance and proportional replication in peer - to - peer networks , '' in _ networking 2005 .",
    "networking technologies , services , and protocols ; performance of computer and communication networks ; mobile and wireless communications systems_.1em plus 0.5em minus 0.4emspringer , 2005 , pp . 709717 .",
    "m.  leconte , m.  lelarge , and l.  massouli , `` convergence of multivariate belief propagation , with applications to cuckoo hashing and load balancing , '' in _ proceedings of the twenty - fourth annual acm - siam symposium on discrete algorithms ( soda ) _",
    ", s.  khanna , ed.1em plus 0.5em minus 0.4emsiam , 2013 , pp ."
  ],
  "abstract_text": [
    "<S> we address the problem of content replication in large distributed content delivery networks , composed of a data center assisted by many small servers with limited capabilities and located at the edge of the network . </S>",
    "<S> the objective is to optimize the placement of contents on the servers to offload as much as possible the data center . </S>",
    "<S> we model the system constituted by the small servers as a loss network , each loss corresponding to a request to the data center . </S>",
    "<S> based on large system / storage behavior , we obtain an asymptotic formula for the optimal replication of contents and propose adaptive schemes related to those encountered in cache networks but reacting here to loss events , and faster algorithms generating virtual events at higher rate while keeping the same target replication . </S>",
    "<S> we show through simulations that our adaptive schemes outperform significantly standard replication strategies both in terms of loss rates and adaptation speed . </S>"
  ]
}