{
  "article_text": [
    "two - level telegraph noise , sometimes called popcorn noise or burst noise , appears in a variety of sources . at any given time @xmath1 , the random telegraph signal @xmath2 , which represents the derivative of the noise , is in either the positive state @xmath3 or the negative state @xmath4 .",
    "it has probability @xmath5 of flipping from the positive state to the negative state , and probability @xmath6 of switching from the negative state to the positive state .",
    "after time @xmath1 , the parameter of the noise is given by @xmath7 .",
    "if there are no flips , then after time @xmath1 the parameter will be @xmath8 , where @xmath9 .",
    "an example of a @xmath2 and its corresponding @xmath10 as a function of time is given in fig .",
    "[ rtnfig ] .    in this paper ,",
    "we show how to find the expectation value of a function @xmath11 , which we shall write as @xmath12 $ ] .",
    "we can write a function in the fourier basis , and then find the expected values of @xmath13 $ ] , which we show in sec .",
    "[ evendist ] , for the case in which the correlation times @xmath14 and @xmath15 are equal , and in the general case of @xmath16 in sec .",
    "[ generalrtn ] .    in sec .",
    "[ control ] , we look at how control can be used to suppress effects of this noise on a pair of qubits . in sec .",
    "[ example ] , the results are applied to a superconducting qubit system which looks promising for quantum computing@xcite .",
    "here we assume that the correlation time @xmath17 is the same in both directions of flips .",
    "suppose we want to find the expectation value @xmath12 $ ] , where @xmath10 has a random telegraph distribution .",
    "[ telegraphdist ] since it is poisson in the number of flips @xmath18 , the distribution of @xmath10 after time @xmath1 is given by @xmath19 where the distribution for a given number of flips is on this same domain @xmath20    first we look at the discrete case with @xmath21 steps .",
    "@xmath22 represents the number of ways to put @xmath23 identical objects into @xmath24 different boxes .",
    "we have @xmath25 intervals where we are heading @xmath26 to the right per unit of time , and @xmath27 intervals where we are heading @xmath26 to the left per unit of time .",
    "the probability of being at position @xmath28 afterwards is the coefficient of @xmath29 in @xmath30 since @xmath31 is asymptotically equivalent in @xmath23 to @xmath32 , for large @xmath33 and @xmath21 , this becomes @xmath34 to get the continuous case , we replace these with @xmath35 , and @xmath36 , so we have the distribution @xmath37 then , if we have @xmath18 flips , the distribution is @xmath38    we let @xmath39_f$ ] represent the expected value of an function @xmath40 given that @xmath18 flips occurred . if @xmath40 is odd , then @xmath39=0 $ ] . if @xmath40 is even , then @xmath41_f = \\begin{cases } g(\\theta_c )   & \\text { for $ f=0$}\\\\ \\frac{f!}{2^{\\frac{f-1}{2 } }",
    "\\theta_c^f \\frac{f-1}{2 } ! }",
    "g_f(\\theta_c ) & \\text { for odd $ f$}\\\\ e[g(\\theta)]_{f-1 } & \\text { for even $ f > 0 $ } \\end{cases},\\ ] ]    where    @xmath42    it then follows from eq .",
    "[ poissondist ] that the total expected value of an even function @xmath40 can be written as a sum over the @xmath39_f$ ] for odd @xmath18 as @xmath43 = e^{-\\lambda } \\left ( g(\\theta_c ) + \\sum_{n=0}^{\\infty } e[g(\\theta)]_{2n+1 } ( \\frac{\\lambda^{2n+1}}{(2n+1)!}+\\frac{\\lambda^{2n+2}}{(2n+2 ) ! } ) \\right ) \\ ] ]    if @xmath18 is odd , then by integration by parts , the expected value of @xmath40 is @xmath44_f= \\int_{-\\theta_c}^{\\theta_c } d_f(\\theta ) g(\\theta ) d\\theta = \\frac{f!}{(2\\theta_c)^f ( \\frac{f-1}{2}!)^2}\\int_{-\\theta_c}^{\\theta_c } ( \\theta_c^2-\\theta^2)^{\\frac{f-1}{2 } } \\theta g_{-1}(\\theta )   d\\theta\\\\ = ( f-1 ) \\frac{f!}{(2 \\theta_c)^f ( \\frac{f-1}{2}!)^2 } \\int_{-\\theta_c}^{\\theta_c } ( \\theta_c^2-\\theta^2)^{\\frac{f-3}{2 } } \\theta g_1(\\theta ) d\\theta\\\\ = ( f-1)(f-3)\\ldots 2 \\frac{f!}{(2\\theta_c)^f ( \\frac{f-1}{2}!)^2 } \\int_{-\\theta_c}^{\\theta_c } \\theta g_{f-2}(\\theta)d\\theta\\\\ = \\frac{f!}{2^{\\frac{f-1}{2}}\\theta_c^f \\frac{f-1}{2 } ! } \\frac{g_f(\\theta_c)-g_f(-\\theta_c)}{2 } = f ( f-2 ) \\ldots 1 \\frac{g_f(\\theta_c)-g_f(-\\theta_c)}{2 \\theta_c^f},\\end{aligned}\\ ] ] where @xmath45 , and @xmath46 .",
    "this is zero for odd functions , and we obtain the desired result for even functions .    applying this to @xmath47 for even @xmath48 and odd @xmath18 , we get @xmath49_f = \\delta^m \\frac{1 \\times 3 \\cdots f}{(m+1)(m+3 ) \\cdots(m+f ) } = \\delta^m   \\frac{1 \\times 3 \\cdots ( m-1)}{(f+2)(f+4)\\cdots ( f+m)}.\\ ] ] for @xmath50 , @xmath51_f = \\frac{\\theta_c^2}{f+2}$ ] . applying this to eq .",
    "[ oddsum ] , the variance is @xmath52   = \\theta_c^2 ( \\frac{1}{\\lambda } + \\frac{e^{-2\\lambda}-1}{2\\lambda^2 } ) = \\delta^2 t \\tau_c + \\frac{\\delta^2 \\tau_c}{2 } ( e^{-\\frac{2 t}{\\tau_c } } -1)\\ ] ] the variance is additive with independent noise sources . for @xmath53 , @xmath54 . for @xmath55 , @xmath56 , and",
    "the @xmath57 part is dominant .",
    "[ expectfourier ] @xmath58=0 $ ] , and @xmath59 = ( \\frac{1}{2 } + \\frac{1}{2v } ) e^{\\lambda ( -1 + v ) } + ( \\frac{1}{2 } - \\frac{1}{2v } ) e^{\\lambda ( -1 - v)},\\ ] ] where @xmath60    for the fourier transform @xmath61 , we get @xmath62 where @xmath63 are the spherical bessel functions of the first kind @xcite , which are written as the series @xmath64 then , the expected value for odd @xmath18 or even @xmath65 flips is @xmath66_f = \\frac{f!}{2^{\\frac{f-1}{2 } } \\frac{f-1}{2 } ! } \\frac{j_{\\frac{f-1}{2}}(m",
    "\\theta_c)}{(m \\theta_c)^{\\frac{f-1}{2 } } } = \\frac{f ! j_{\\frac{f-1}{2}}(z)}{\\frac{f-1}{2 } ! ( 2z)^{\\frac{f-1}{2}}},\\ ] ] where @xmath67 . from eq .",
    "[ oddsum ] , it follows that @xmath68=e^{-\\lambda}(\\cos(z)+ \\sum_{k=0}^{\\infty } \\frac{(2k+1 ) ! j_k(z)}{k !",
    "( 2z)^k}(\\frac{\\lambda^{2k+1}}{(2k+1)!}+\\frac{\\lambda^{2k+2}}{(2k+2)!}))\\\\ = e^{-\\lambda}(\\cos(z ) + z \\sum_{k=1}^{\\infty } \\frac{j_{k-1}(z)}{k!}(\\frac{\\lambda^2}{2z})^k + \\lambda \\sum_{k=0}^{\\infty } \\frac{j_k(z)}{k!}(\\frac{\\lambda^2}{2 z})^k.\\end{aligned}\\ ] ] now since @xmath69 , and @xmath70 satisfies the equations @xmath71 we have @xmath72= e[e^{im \\theta}]=e^{-\\lambda}(\\cos \\sqrt{z^2-\\lambda^2 } + \\lambda \\text{sinc } \\sqrt{z^2-\\lambda^2})\\\\ = e^{-\\frac{t}{\\tau_c } } \\left ( \\cos \\sqrt{(m t \\delta)^2 - ( \\frac{t}{\\tau_c})^2 } + \\frac{t}{\\tau_c } \\text{sinc } \\sqrt{(m t \\delta)^2 - ( \\frac{t}{\\tau_c})^2 } \\right)\\\\ = e^{-\\frac{t}{\\tau_c } } \\left ( \\cos(t \\sqrt{m^2a^2 - \\frac{1}{\\tau_c^2 } } ) + \\frac{t}{\\tau_c } \\text{sinc } ( t \\sqrt{m^2 \\delta^2 - \\frac{1}{\\tau_c^2 } } ) \\right)\\\\ = e^{-\\frac{t}{\\tau_c } } \\left ( \\cosh ( \\frac{t}{\\tau_c}v ) + v^{-1 } \\sinh(\\frac{t}{\\tau_c}v ) \\right ) = e^{-\\lambda } \\left ( \\cosh(\\lambda v ) + v^{-1 } \\sinh(\\lambda v ) \\right)\\end{aligned}\\ ] ]    [ [ different - limits ] ] different limits + + + + + + + + + + + + + + + +    for small @xmath73 we have @xmath74 , and therefore @xmath75 \\approx e^{-\\frac{1}{2 } t m^2 \\delta^2 \\tau_c}.\\ ] ]    if @xmath76 , then @xmath77 \\approx e^{-\\lambda } \\cos ( v)$ ] . if in addition , @xmath78 , then @xmath79 \\approx cos(m \\theta_c)$ ] .    up to first order in @xmath80 , we have @xmath81 \\approx \\cos z + \\lambda ( \\text{sinc } z - \\cos z ) \\approx \\cos z + \\lambda \\frac{z^2}{3}.\\ ] ]      if we have multiple independent sources of random telegraph noise , then since @xmath82 is a characteristic function , the expectation value is the product of the expectation value for each source .",
    "@xmath66 = e^{-\\sum_i \\lambda_i } \\prod_i \\left ( \\cos \\sqrt{(mtx_{0_i})^2-\\lambda_i^2 } + \\lambda_i \\text{sinc } \\sqrt{(mtx_{0_i})^2-\\lambda_i^2 } \\right)\\ ] ]    if the number of flips @xmath80 is large , then by the central limit theorem , the distribution of @xmath10 will approach the gaussian ( also called normal ) distribution @xmath83    for a single source of noise , from eq .",
    "[ rtnvar ] , for large @xmath80 , @xmath84 .",
    "this is also @xmath85 , as one would expect from a random walk .",
    "if we have @xmath25 telegraph noise sources , with a mean correlation time of @xmath86 and a distribution of telegraph strength with mean @xmath87 and standard deviation @xmath88 , then @xmath89 .",
    "[ [ f - noise ] ] @xmath0 noise + + + + + + + + + + + + + + + + + + + + + + +    suppose we have @xmath25 @xmath0 telegraph noise sources with a frequency in the range @xmath90 $ ] .",
    "the distribution for @xmath18 is @xmath91 @xcite . since @xmath92 , then @xmath93 , so we have a distribution in @xmath80 of @xmath94 , where @xmath95 . from eq . [ rtnvar ]",
    ", it follows that @xmath96 where @xmath97 is the exponential integral .",
    "now if the @xmath98 are large , the @xmath99 part dominates , and so @xmath100 where @xmath101 .",
    "this could also be found directly from @xmath102 for a single source . if @xmath103 , then @xmath104 .",
    "since @xmath105 , @xmath106 . if @xmath107 , and @xmath108 , this gives the single source result .    sometimes by @xmath0 noise , we mean that the noise has a power spectrum of @xmath109 for some @xmath110 . in this case , then by a similar calculation to that of @xcite , on the domain @xmath111 $ ] , a power spectrum of @xmath109 would give a density of random telegraph correlation times of @xmath112 , and so @xmath113 = \\int_0^{\\tau_b } \\tau_c \\frac{(\\alpha -1 ) \\tau_c^{\\alpha -2}}{\\tau_b^{\\alpha -1 } } = \\frac{\\alpha -1}{\\alpha } \\tau_b$ ] .",
    "[ [ expected - values ] ] expected values + + + + + + + + + + + + + + +    since @xmath114 is even , @xmath115=0 $ ] for odd @xmath116 . for even @xmath116 , we have @xmath117 = \\frac{1}{\\sigma \\sqrt{2 \\pi } } \\int_{-\\infty}^{\\infty } x^n e^{-\\frac{x^2}{2 \\sigma^2}}\\\\   = \\frac{1}{\\sigma \\sqrt{2 \\pi } } ( -\\sigma^2 x^{n-1}e^{-\\frac{x^2}{2 \\sigma^2 } } |_{-\\infty}^{\\infty } + \\int_{-\\infty}^{\\infty } ( n-1 ) x^{n-2 } \\sigma^2 e^{-\\frac{x^2}{2 \\sigma^2}})\\\\   = ( n-1 ) \\sigma^2 e[x^{n-2 } ] = \\sigma^n ( 1 \\times 3 \\cdots ( n-1 ) ) = \\sigma^n \\frac{n!}{2^{\\frac{n}{2 } } \\frac{n}{2}!}.\\end{aligned}\\ ] ] now @xmath58 = 0 $ ] , and @xmath118 = \\sum_n \\frac{(-m^2)^n e[x^{2n}]}{(2n ) ! } = \\sum_n \\frac{(-m^2)^n \\sigma^{2n } ( 2n)!}{(2n ) ! 2^n n ! } = \\sum_n \\frac{(\\frac{-m^2 \\sigma^2}{2})^n}{n ! }   = e^{- \\frac{m^2 \\sigma^2}{2}}.\\end{aligned}\\ ] ] in the case where we have just one flip time @xmath73 , we get the same result as in eq .",
    "[ likegauss ] .",
    "in this section , we assume that the noise is only generated from some hamiltonian that can be switched on and off .",
    "we assume that we need to apply this hamiltonian for time @xmath1 .",
    "lemma [ expectfourier ] gives the expected values of the fourier functions without control , assuming that the telegraph starts off in either state with equal probability .",
    "up to second order in @xmath1 , this is @xmath119 \\approx 1 - \\frac{1-v^2}{2 } \\lambda^2 \\approx   1 - \\frac{(m \\delta t)^2}{2}.\\ ] ] now , we have the following two possible methods to reduce errors .",
    "suppose we wait for a time much greater than the correlation time @xmath120 .",
    "this will randomize which direction the telegraph is going before we apply a hamiltonian .",
    "if we do this @xmath116 times , then @xmath121 = ( \\frac{1}{2 } ( 1 + v^{-1})e^{\\frac{t}{n \\tau_c } ( -1 + v ) } + ( 1 - v^{-1 } ) e^{\\frac{t}{n \\tau_c } ( -1-v)})^n\\\\   \\approx ( 1 - \\frac{m \\delta \\frac{t}{n}}{2})^n \\approx 1 - \\frac{m^2 \\delta^2 t^2}{2 n},\\end{aligned}\\ ] ] and @xmath122=0 $ ] , so by applying the hamiltonian for time @xmath123 @xmath116 different times , and waiting a while in between , the rate of error @xmath124 is changed to @xmath125 .",
    "suppose that we have a hamiltonian @xmath126 that we use to create the quantum gate @xmath127 , and it generates a noise hamiltonian @xmath128 , so that errors are of the form @xmath129 where @xmath10 follows a random telegraph noise distribution .",
    "if @xmath126 and @xmath128 commute , and we can apply a gate @xmath130 with a low rate of errors that commutes with @xmath126 and anti - commutes with @xmath128 , then instead of applying @xmath127 , we apply the gate @xmath131 this breaks the time @xmath1 into @xmath116 intervals of equal length , with the direction of the telegraph reversed in between .",
    "the expected value of @xmath132=0 $ ] , and @xmath133 \\approx 1 - \\frac{m^2 \\delta^2 t^3}{n^2 \\tau_c}\\ ] ]    in this case a rate of error of @xmath124 is changed to @xmath134 .",
    "assume that the telegraph starts going off to the right .",
    "then from eq .",
    "[ generaltelegraph ] , since @xmath135 , @xmath136 = e^{-\\lambda}(\\cosh ( \\lambda v ) + ( \\frac{1}{v } + \\frac{im \\theta_c}{\\lambda v } ) \\sinh(\\lambda v),\\ ] ] where @xmath137 .",
    "up to third order in @xmath1 , this is @xmath136_r \\approx ( 1 - \\lambda   + \\frac{1}{2 } \\lambda^2 - \\frac{1}{6 } \\lambda^3 ) ( ( 1 + \\frac{(\\lambda v)^2}{2 } ) + ( \\frac{1}{v } + \\frac{i m t \\delta}{\\lambda v})((\\lambda v ) + \\frac{(\\lambda v)^3}{6})).\\ ] ] up to second order , this is @xmath136_r \\approx 1 - \\frac{1 - v^2}{2 } \\lambda^2 + i m t \\delta ( 1 - \\lambda ) = 1 - \\frac{(m \\delta t)^2}{2 } + i m t \\delta ( 1 - \\frac{t}{\\tau_c})\\ ] ] now suppose that we have two intervals of time @xmath1 of telegraph noise , with the direction of the telegraph noise reversed in between . the expectation value of @xmath61 for the first is @xmath13_r$ ] . reversing the initial direction sends @xmath138 for the second , giving @xmath139_r$ ] , and so the total expected value of @xmath61 is @xmath140 =   e[e^{i m \\theta}]_r e[e^{- i m \\theta}]_r \\approx ( 1 - \\frac{(m \\delta t)^2}{2})^2 + ( m t \\delta ( 1 - \\frac{t}{\\tau_c})^2 \\\\ \\approx 1 - 2 m^2 \\delta^2 \\tau_c^{-1 } t^3 \\end{aligned}\\ ] ] for @xmath141 pairs of intervals with @xmath123 time per interval , this becomes @xmath136 \\approx   ( 1 - \\frac{2 m^2 \\delta^2 t^3}{n^3 \\tau_c})^{\\frac{n}{2}}\\approx 1 - \\frac{m^2 \\delta^2 t^3}{n^2 \\tau_c}\\ ] ]    from eq .",
    "[ generaltelegraph ] , if the telegraph starts off to the right , instead of @xmath58=0 $ ] , we now have @xmath142 = e^{-\\lambda } \\frac{m \\theta_c}{\\sqrt{\\lambda^2 - m^2 \\theta_c } } sinh ( v ) \\\\= e^{-\\frac{t}{\\tau_c } } \\frac{m \\delta}{\\sqrt{\\tau_c^{-2 } - m^2 \\delta^2 } } \\sinh(t \\sqrt{\\tau_c^{-2 } - m^2 \\delta^2}).\\end{aligned}\\ ] ] up to first order in @xmath1 , this is @xmath143 .",
    "both methods assume that the telegraph is equally likely to go in either direction .",
    "the waiting method assumes that general decoherence is nt a problem .",
    "the suppression method assumes that the gate @xmath130 can be quickly performed without errors .",
    "these assumptions are unrealistic , and other types of noise will likely be created , but these methods could allow for a significant reduction of the magnitude of the noise .",
    "from a superconducting qubit system @xcite we have the noise @xmath144 where @xmath10 has a random telegraph distribution . now , @xmath145 so the probability of no @xmath146 error @xmath147 , each of the probabilities of a @xmath146 error on exactly one qubit are @xmath148 , and the probability of a @xmath146 error on both qubits is @xmath149 .",
    "we have that @xmath150\\cr e[\\sin^2 \\theta \\cos^2 \\theta]\\cr e[\\sin^4 \\theta ] { \\end{bmatrix}}= { \\begin{bmatrix}}\\frac{3}{8 } & \\frac{1}{2 } & \\frac{1}{8}\\cr \\frac{1}{8 } & 0 & -\\frac{1}{8 } \\cr \\frac{3}{8 } & -\\frac{1}{2 } & \\frac{1}{8 }   { \\end{bmatrix}}{\\begin{bmatrix}}e[1]\\cr e[\\cos 2\\theta]\\cr e[\\cos 4\\theta]\\cr { \\end{bmatrix}},\\end{gathered}\\ ] ] where the @xmath151 $ ] are given in thm .. [ expectfourier ] .",
    "then from equation [ rtnapprox ] , we have that up to 1st order in @xmath80 and 3nd order in @xmath152 , @xmath153    [ [ gaussian - noise ] ] gaussian noise + + + + + + + + + + + + + +    suppose we assume the noise is gaussian distributed with a standard deviation of @xmath154 , then @xmath155 where @xmath156 .",
    "this gives , up to @xmath157 , @xmath158 , @xmath159 , @xmath160 .",
    "[ [ control ] ] control + + + + + + +    the system @xcite has a 2 qubit hamiltonian @xmath161 , which commutes with the error hamiltonian of @xmath162 . the gate @xmath163 commutes with @xmath126 , and anti - commutes with @xmath164 .",
    "this is very useful , because @xmath130 is entirely composed of local gates , which have a much lower rate of errors .",
    "this is similar to quantum `` bang - bang '' control @xcite .",
    "in section [ evendist ] , we considered the expectations of a @xmath165 state random telegraph source with a correlation time @xmath166 . in this section",
    "we consider that the correlation time depends on which state we re in , that is we have @xmath5 chance of flipping per unit time if the telegraph is in the positive state , and @xmath6 of flipping time if the telegraph is in the negative state .",
    "this is relevant to a physical system at finite temperatures .",
    "also we assume that the telegraph starts off in the positive state .",
    "note that if for the positive state @xmath167_+ = v(m , \\tau_0 , \\tau_1)$ ] , and there is probability of @xmath168 of starting in the positive state , and @xmath169 of starting in the negative state , then @xmath170 = p_0 e[e^{im ( -\\theta)}]_- + p_1 e[e^{im \\theta}]_+ = p_0 v(-m , \\tau_1 , \\tau_0 ) + p_1 v(m , \\tau_0 , \\tau_1).\\ ] ]    [ distlemma ] suppose the telegraph starts off in the positive state ( so that the noise parameter is increasing ) .",
    "the distribution of @xmath10 is given by a sum over all of the possible number of flips @xmath171 where @xmath172    on the domain @xmath173 $ ] , where @xmath174 , @xmath175 .",
    "there are no flips with probability @xmath176 , in which case @xmath177 , which gives @xmath178 .",
    "suppose we have @xmath25 intervals where the telegraph is in the positive state and so the noise parameter is increasing , and @xmath27 intervals where the telegraph noise is in the negative state and so the noise parameter is decreasing , and we have @xmath21 steps .",
    "then we have @xmath179 ways to end up at position @xmath180 .",
    "suppose we start off in the increasing telegraph state , and the probability of flipping if we re increasing is @xmath181 , and if we re decreasing is @xmath182 .",
    "the probability of being at position @xmath28 afterwards is the coefficient of @xmath29 in @xmath183 we make this continuous , so we have @xmath184 , @xmath35 , and pick up a factor @xmath185 from @xmath186 , and so have    @xmath187    if we have an even number of telegraph flips @xmath188 , then @xmath189 , @xmath190 . if we have an odd number of telegraph flips , then @xmath191 .",
    "plugging these into the previous equation produces the desired result .",
    "[ intlemma ]    @xmath192    where the @xmath193 are the carlitz bessel polynomials described in @xcite .",
    "if we let @xmath194 then by integration by parts , @xmath195 so @xmath196 now , from the the formula for the carlitz bessel functions , it can be shown that they satisfy the differential equation @xmath197 note that this implies that @xmath198 .",
    "if we let @xmath199 then this satisfies the differential equations @xmath200 , @xmath201 , and so we get the desired result .",
    "the expectation of a characteristic function @xmath61 is @xmath202 = e^{-\\frac{\\lambda_0 + \\lambda_1}{2 } } ( \\cosh u + \\frac{\\lambda_1 + c \\theta_c}{u } \\sinh u)\\ ] ] where @xmath203 where @xmath204 .    from lemma [ distlemma ] ,",
    "the contribution from an odd number of flips @xmath18 is @xmath140_{\\text{odd } } = \\sum_{n=0}^{\\infty } \\int_{-\\theta_c}^{\\theta_c } e^{i m \\theta } d_{2n+1}(\\theta ) d \\theta",
    "\\\\ = e^{-\\frac{\\lambda_0 + \\lambda_1}{2 } } \\lambda_1 \\sum_{n=0}^{\\infty } \\frac{(\\lambda_0 \\lambda_1)^n}{(2 \\theta_c)^{2n+1 } ( n!)^2 } \\int_{-\\theta_c}^{\\theta_c } ( \\theta_c^2 - \\theta^2)^n e^c d \\theta,\\end{aligned}\\ ] ]    by integration by parts , @xmath205 and so from lemma [ intlemma ] , if @xmath206 , @xmath140_{\\text{odd } } = - \\lambda_1 \\frac{e^{- \\frac{\\lambda_0+\\lambda_1}{2}}}{2 z^2 } \\sum_n ( -\\frac{\\lambda_0 \\lambda_1}{2 z^2})^n \\frac{1}{n ! } ( p_{n+1}(-z ) e^z + p_{n+1}(z ) e^{-z})\\end{aligned}\\ ] ] now , by differentiating the formula @xmath207 from @xcite , we get @xmath208 so if @xmath209 , @xmath210_{\\text{odd } } =   - \\lambda_1 e^{-\\frac{\\lambda_0 + \\lambda_1}{2 } } \\frac{-z e^{-z(1-\\sqrt{1 - 2 t } } e^z + z e^{z ( 1-\\sqrt{1 - 2 t } ) } e^{-z}}{2 z^2 \\sqrt{1 - 2t}}\\\\ = \\lambda_1 e^{-\\frac{\\lambda_0 + \\lambda_1}{2 } } \\frac{\\sinh ( z \\sqrt{1 - 2t})}{z \\sqrt{1 - 2 t } } =   \\lambda_1 e^{\\frac{\\lambda_0 + \\lambda_1}{2 } } \\frac{\\sinh u}{u}\\end{aligned}\\ ] ]    for even @xmath211 , the contribution is @xmath136_{\\text{even } > 0 } = e^{-\\frac{\\lambda_0 + \\lambda_1}{2 } } \\sum_{n=1}^{\\infty } \\frac{(\\lambda_0 \\lambda_1)^n}{(2 \\theta_c)^{2n } n ! ( n-1 ) ! } \\int_{-\\theta_c}^{\\theta_c } ( \\theta_c^2 - \\theta^2)^{n-1 } ( \\theta_c + \\theta ) e^{c \\theta } d \\theta,\\ ] ] and @xmath212 so if @xmath206 , @xmath140_{\\text{even } > 0",
    "} = \\frac{e^{-\\frac{\\lambda_0 + \\lambda_1}{2}}}{2 } \\sum_{n=1}^{\\infty }   ( -\\frac{\\lambda_0 \\lambda_1}{2 z^2})^n \\frac{1}{n!}\\\\ ( ( p_n(-z)e^z + p_n(z)e^{-z})-    \\frac{p_{n+1}(-z)e^{z } + p_{n+1}(z)e^{-z}}{z}).\\end{aligned}\\ ] ] in the sum , if @xmath213 , @xmath214",
    "so we can include @xmath215 , and so we get a sum over all even @xmath18 , with @xmath216 , @xmath140_{\\text{even } } = \\frac{e^{-\\frac{\\lambda_0 + \\lambda_1}{2}}}{2 } \\sum_{n=0}^{\\infty } \\frac{t^n}{n ! } ( p_n(-z)e^z + p_n(z)e^{-z})\\\\   - \\frac{e^{-\\frac{\\lambda_0 + \\lambda_1}{2}}}{2 } \\sum_{n=0}^{\\infty } \\frac{t^n}{n ! } ( p_{n+1}(-z)e^z + p_{n+1}(z)e^{-z})\\\\ = \\frac{e^{-\\frac{\\lambda_0 + \\lambda_1}{2}}}{2 } ( e^{-z(1-\\sqrt{1 - 2 t } ) } e^z + e^{z(1-\\sqrt{1 - 2 t } ) } e^{-z } ) + z e^{\\frac{\\lambda_0 + \\lambda_1}{2 } } \\frac{\\sinh u}{u}\\\\ = e^{\\frac{\\lambda_0 + \\lambda_1}{2 } } ( \\cosh u + \\frac{z}{u } \\sinh u)\\end{aligned}\\ ] ]",
    "we thank the nsf for financial support under itr grant no . eia-0205641 ."
  ],
  "abstract_text": [
    "<S> we find expectation values of functions of time integrated two - level telegraph noise . </S>",
    "<S> expectation values of this noise are evaluated under simple control pulses . </S>",
    "<S> both the gaussian limit and @xmath0 noise are considered . </S>",
    "<S> we apply the results to a specific superconducting quantum computing example , which illustrates the use of this technique for calculating error probabilities . </S>"
  ]
}