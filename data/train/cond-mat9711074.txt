{
  "article_text": [
    "those conceptual approaches to a subject that offer both wider applicability , and reduced algorithmic complexity , might be called `` deep simplifications '' .",
    "minkowski s approach to special relativity via the metric equation is a classic example .",
    "the first impressions of `` superfluous erudition''@xcite have now been eclipsed , by uses for minkowski s perspective in developing general relativity@xcite as well as first introductions to space - time@xcite .",
    "similarly , the communication - theory insights of shannon@xcite led jaynes@xcite in the middle of this century to clarify the distinction in thermal physics between `` describing the dice '' ( i.e. physical description ) , and `` taking the best guess '' ( the `` gambling theory '' part ) .",
    "thus for example , the 1st through 3rd laws of thermodynamics help `` describe the dice '' , while the zeroth law , as well as the boltzmann ( canonical ) and gibbs ( grand canonical ) factors , are `` dice - independent '' tools of statistical inference@xcite .",
    "hence we can ( with increasing help from undergraduate texts@xcite ) deepen understanding ( including the physical intuition of computer science and biology students on matters of `` code '' ) by disclosing that entropy @xmath7 is a measure of statistical uncertainty , expressible using information units as well as in j / k . from this",
    ", it follows that temperature ( i.e. the reciprocal of uncertainty slope @xmath8 ) can be measured in units of energy per unit information ( e.g. room temperature @xmath9 @xmath10 ev per nat ) .",
    "thus heat capacities ( i.e. @xmath11 ) , normally understood in units of energy per degree kelvin , may find themselves measured in units of information alone ! as we will show ,",
    "this is part of a larger trend in statistical physics to shift the focus from temperature ( or its reciprocal ) to the physical dependence of multiplicity ( or entropy ) on variables conserved in the interaction between complex systems .",
    "but , what is the _ physical _ meaning of a heat capacity without reference to historical temperature units ?",
    "bits of what ?",
    "an answer to this question ( something any student might ask ) does not appear to be common knowledge among physics teachers , so we outline an answer here .",
    "we show further why total thermal energy over kt _ for any system _ serves at once : ( i ) as the instantaneous exponent of energy in the expression for accessible state multiplicity , ( ii ) as a measure of the number of bits of ( micro - canonical ) uncertainty added per two - fold increase in thermal energy , and ( iii ) _ for quadratic systems _ as the number of degrees freedom over two .",
    "the dice of thermal physics are usually physical systems capable of accomodating thermal energy ( as well as other quantities that may be conserved , like volume and particles ) in a _ multiplicity _ of ways .",
    "this multiplicity is itself the key to understanding , particularly when systems are seen from the ( micro - canonical ) vantage point of the conserved quantities _ per se_. for example ,",
    "many gases , liquids , and solids behave over some of their temperature range as though multiplicity ( @xmath12 ) is proportional to @xmath13 , where @xmath1 is thermal energy , @xmath14 is the number of molecules , and @xmath15 is the number of ways to store thermal energy per molecule .",
    "such systems are called `` quadratic '' , since the proportionality results from a `` sum of squares '' connection between @xmath1 and the state coordinates involved in storing energy .",
    "application of gambling theory to physical systems begins with the question : where might we expect to find a conserved quantity @xmath16 which has been randomly ( as far as we know ) shared between systems for so long that prior information about the whereabouts of @xmath16 is irrelevant ? in the jargon of the field , this is the same as asking : where is @xmath16 likely to be _",
    "after equilibration _ ?",
    "the science of decision - making in the presence of uncertainty ( i.e. statistical inference or `` gambling theory '' ) suggests that the best bet is the distribution of @xmath16 that can happen in the most ways , provided there is no reason to prefer one way over another . in the jargon of probability theory , this is the recommendation : assume equal _ a priori _ probabilities , when evidence to the contrary is not available .",
    "for example , if systems a and b have a total energy @xmath1 to share between them , then the best bet after equilibration will be that value of @xmath17 that has the largest total multiplicity @xmath18 . setting to zero the derivative of @xmath12 with respect to @xmath19 ,",
    "one finds that this maximum requires that @xmath20 , and hence that @xmath21 be the same for both systems ! these derivatives ( and most others in this paper ) are taken under `` microcanonical constraints '' , i.e. they are partial derivatives with other extensive quantities ( like volume or number of particles ) held constant .",
    "information theorists , of course , define the logarithm of multiplicity as uncertainty via the equation @xmath22 , and measure it in \\{nats , bits , bytes , or j / k } if @xmath23 is \\{@xmath24,@xmath25,@xmath26,@xmath27 } , respectively .",
    "thus the best bet for any two systems sharing a conserved quantity @xmath16 , in the absence of information to the contrary , is that @xmath16 will rearrange itself between the two systems until each system s _ uncertainty slope _ ( @xmath28 )",
    "has reached a common value .",
    "this is a quantitative version of the zeroth law of thermodynamics , based purely in the science of statistical inference , which applies to _ any systems _ sharing conserved quantities .    of course , when energy @xmath1 is the quantity shared randomly between systems , the uncertainty slope @xmath29 is the reciprocal temperature or _",
    "_ @xmath30 .",
    "hence temperature is a property which signals the propensity of a system for sharing of energy thermally .",
    "for example , calculating the uncertainty slope for quadratic systems from the multiplicity given above yields the widely useful equipartition relation : @xmath31 .    when @xmath32 is the quantity shared randomly between systems , the uncertainty slope @xmath33 is the _ free - expansion coefficient _ equal to @xmath34 at equilibrium@xcite . for an ideal gas , @xmath35 . solving this for @xmath36 yields the ideal gas equation of state @xmath37 .",
    "when @xmath14 is the quantity shared randomly , the uncertainty slope @xmath38 is the _ chemical affinity _ ,",
    "equal to @xmath39 at equilibrium . from this , for example , reaction equilibrium constants may be calculated .",
    "this quantitative version of the zeroth law applies to all thermal systems which equilibrate , including spin systems ( like magnets ) capable of population inversions and hence negative absolute temperatures .",
    "moreover , as a theorem of statistical inference not involving energy at all , it applies also to thermally unequilibrated systems sharing other conserved quantities ( even money , for example ) , provided the only prior information we have is how the multiplicity of ways that quantity can be distributed depends on the amount of that conserved quantity to begin with !",
    "if we have other kinds of information , such as knowledge of a system s temperature but not its total energy , then the broader class of maximum entropy strategies in statistical inference ( e.g. the canonical and grand ensembles ) predict the distribution of outcomes we can expect there as well .",
    "a closer look shows that the statistical definition of temperature above can be rewritten as :    @xmath40    the quantity in curly brackets is the log - log derivative of multiplicity with respect to thermal energy .",
    "we can also think of this as the `` instantaneous exponent '' of energy in the expression of multiplicity as energy to some power , or as the slope of the multiplicity versus energy curve on a log - log plot .    rearranging the equation yields something that looks very much like the familiar equipartition theorem , except that the relation applies to all thermal systems under conditions of maximum ignorance ( i.e. at equilibrium ) :",
    "@xmath41    for quadratic systems , it is easy to see that our log - log derivative is nothing more than half the number of degrees of freedom ( @xmath42 ) . for any system",
    ", however , @xmath43 measures the instantaneous energy exponent , as well as the number of _ nats of information lost about the state of the system per e - fold increase in thermal energy _ of the system.the last term in the equality string simply notes that the value is independent of the base @xmath3 of the logarithms used , provided the same base is used in numerator and denominator .",
    "thus we can also think of @xmath43 as the number of bits of information lost per @xmath44-fold increase in thermal energy , or more generally the number of base-@xmath3 units of information lost per @xmath3-fold increase in thermal energy . in our search for the meaning of heat capacity in natural units ,",
    "this is our first big clue .",
    "before we move on , we should also point out something that applies if our energy origin has been chosen so that @xmath45 as @xmath46 , something we _ might _ expect for a measure of thermal energy . in terms of the no - work ( e.g. constant volume ) heat - capacity @xmath47 , we can write :    @xmath48    with the middle equality applying only for systems not in a population inversion , so that absolute temperature @xmath4 and @xmath49 .",
    "thus when absolute temperature is positive , @xmath43 is a _ heat capacity average _ over temperatures ranging between @xmath50 and absolute zero .",
    "we ve shown here that the log - log derivative of multiplicity , with respect to energy , has a simple information theoretic interpretation , and is elegantly given in natural units by @xmath51 as well . from the perspective of an experimentalist , however , it has one glaring disadvantage : _ it s numeric value depends on our choice for the zero of thermal energy . _    to illustrate the problem , consider the cooling of water until it becomes ice . as water cools initially ,",
    "the temperature drop per unit energy removed is roughly constant .",
    "one might easily say : `` this looks like a quadratic system with about 18 degrees of freedom per molecule '' , so @xmath43 must be about 9 bits per 2-fold increase in thermal energy . then",
    ", at the freezing point , the temperature stops dropping as energy continues to be removed , suggesting a quadratic system with nearly infinite degrees of freedom !",
    "once all is frozen , of course , temperature continues its drop , this time suggesting a quadratic system with about 8 degrees of freedom per molecule , or @xmath43 closer to 4 bits per 2-fold increase in thermal energy !",
    "since @xmath2 may change little during this experiment , how can @xmath5 be jumping around so much ?",
    "the answer of course is that these inference follow not by measuring total energy @xmath1 , but only changes in energy .",
    "moreover , in the process our preferred zero of thermal energy has been shifting about .",
    "we can see the effects of this more explicitly if we plot energy versus temperature for water , as shown in the lower left panel of figure 1 .",
    "the question then is , can we modify our estimate for the log - log derivative of thermal energy so as to reflect only data on temperature changes over a limited energy range ? such a quantity might allow us to probe the ways that thermal energy is being accomodated specifically , one energy range at a time .",
    "the no - work ( e.g. constant volume ) instantaneous heat capacity , in natural units , can be written in terms above as :    @xmath52 = \\left [ 1+t\\frac \\partial { \\partial t}\\right ] \\xi = t% \\frac{\\partial \\ln \\omega } { \\partial t}=t\\frac{\\partial ( s / k)}{\\partial t}% \\text{. }   \\label{heatcapacity}\\ ] ]    here @xmath50 is absolute temperature in any units you like , and the partials are taken with work parameters ( like volume ) held constant .",
    "this quantity has an interesting property . if we define thermal energy @xmath1 as a difference between total energy @xmath53 and a specified `` zero thermal energy '' origin @xmath54 , i.e. as @xmath55 , then it is easy to see that @xmath56 is independent of our choice for @xmath57 .",
    "thus , although @xmath43 obviously depends on one s choice of @xmath54 , @xmath58 does not .    to see what @xmath58 actually measures ,",
    "let s suppose that we have a quadratic system whose multiplicity obeys @xmath59 .",
    "it then follows simply that @xmath60 , @xmath61 , @xmath62 . thus @xmath63 estimates not @xmath64 but @xmath65 , where @xmath66 is the `` true origin '' of thermal energy for this quadratic system .",
    "this is illustrated in figure 2 , which plots for an ideal monatomic gas ( the classical quadratic system ) the same quantities plotted for water in fig .",
    "if the system is not simply quadratic ( e.g. if it has phase changes , modes of energy storage which freeze out , etc . ) , then @xmath63 is simply a local estimate of thermal energy over @xmath2 , under the quadratic assumption .",
    "thus @xmath67 modifies the log - log derivative of multiplicity with respect to energy , by combining it with its rate of increase per e - fold change in temperature , to yield an estimate of @xmath65 , where @xmath66 is a zero of thermal energy determined by assuming that the locally - measured log - log derivative of multiplicity is constant down to @xmath68 .",
    "this observation also provides a different perspective on the mechanism by which heat capacity blows up during a phase change .",
    "thermal energy over @xmath2 ( or the log - log derivative of multiplicity ) of course should have no singularities in it , since both energy and @xmath69 are expected to be finite for finite systems .",
    "it is thus the 2nd term in the two - term expression for heat capacity above , namely the temperature derivative , that provides the instability .",
    "discontinuous shifts in the locally - inferred energy zero ( @xmath66 ) on which heat capacity is based during a phase change thus , via this second term , also cause heat capacity to become singular .",
    "returning to figure 1 , this raises the interesting question : _ does the thermal energy of steam increase , decrease , or go negative , when it condenses to water ?",
    "_ from the above , we can see that it of course decreases ( perhaps even goes negative ) if one s `` zero of thermal energy '' is held constant , since steam loses the latent heat of vaporization when it condenses , bringing it s total energy down .",
    "however , because the specific heat of water at boiling is higher than that for steam , energy of random motion measured with respect to our locally - inferred zero of thermal energy ( e.g. at 100c ) actually goes up ! in other words , a small part of the binding energy , liberated when water molecules fall into the potential well of their neighbors , goes to /em increase the energy of random motion in the condensed phase relative to that available to particles in uncondensed gas !",
    "the observations above suggest that introductory texts might consider highlighting @xmath63 per molecule in natural units for common substances , with no apology for the fact that it is near but not exactly half - integral in many cases .",
    "after all , thermal energy may not have the same access to all molecules , all of the time .",
    "this quantity nonetheless provides deep insight into the relationship between uncertainty and thermal energy .    in shifting the focus from historical temperature units to the multiplicities which underlie our inferences , we can say that both @xmath43 and @xmath63 measure bits of uncertainty per 2-fold increase in energy for _ all _ physical systems , with respect to their respective choices for energy origin . in this sense , they represent physical quantities like degrees freedom , but with wider applicability .",
    "after all , _",
    "degrees freedom _ presumes not only multiplicities that are linear with energy on a log - log plot ( like a high - temperature einstein solid ) , but it also presumes quadratic energies ( i.e. energies proportional to a sum of squares of some `` randomly - occupied '' coordinates of state ) . the idea that `` every active coordinate gets @xmath70 '' , as we show below , even more strongly resists extension to systems with one or more entropy maxima .",
    "we begin , however , with a non - quadratic example of less drastic proportion .",
    "the debye heat capacity of a solid is one case where @xmath63 depends strongly on temperature@xcite . in the debye low temperature limit",
    ", one has @xmath71 , so that @xmath72 , while @xmath73 . here of course , @xmath74 is the debye temperature related to the density and speed of sound in the solid .",
    "note that in this limit , only a quarter of @xmath63comes from equipartition ( @xmath51 ) , the remaining three quarters from the time derivative of @xmath75 ( in effect , from the unfreezing of new modes of energy accomodation ) .",
    "as you can see from figure 1 , such unfreezing is associated with a lowering of the thermal energy zero locally referenced by the heat capacity .",
    "thus attempts to infer @xmath43 from the heat capacity by assuming that @xmath76 yield a 4-fold overestimate of the number of degrees of freedom !",
    "this overestimate decreases as temperatures work themselves up to and beyond the debye temperature @xmath74 of the solid , as illustrated in figure 1 for temperatures well above @xmath74 .",
    "there in the high temperature limit , @xmath77 , as one expects from a classical lattice model above with @xmath78 .",
    "a system more challenging to the traditional interpretation of `` degrees freedom '' is that for a system of @xmath14 half - integral spins ( i.e. a two - state paramagnet ) of orientation energy @xmath79 .",
    "i like it because , as dan schroeder says@xcite , `` it forces us to think primarily in terms of entropy rather than temperature '' .",
    "begin with any system whose energy - storing coordinates ( e.g. displacements in a potential field ) in practice have an upper limit on the amount of energy they ll accomodate . as long as energy is low enough that no single coordinate approaches the maximum value , then we may well find behavior very much like that of the systems discussed above .",
    "however , when individual coordinate energies begin to approach their maximum ( this happens quickly for two - state paramagnets whose coordinates accomodate but one unit of energy ) , things change fundamentally . in particular , there will be but one way ( neglecting degeneracies ) for the system to store the maximum amount of energy ( namely when each of the coordinates is fully energized ) . with but one way to accomodate either minimum energy or maximum energy , multiplicities will approach 1 at both endpoints of the continuum . since large systems may have many ways to store intermediate amounts of energy , multiplicity ( and entropy ) as a function of system energy will have a maximum ( or _ maxima _ ) somewhere between . at such maxima",
    ", @xmath80 will be zero , while on their high - energy side @xmath81 will be negative ( signaling `` population - inverted '' states not accessible by thermal contact with reservoirs at positive absolute temperature ) .",
    "taylor - expanding to second order about the energy ( @xmath82 ) of such multiplicity maxima gives @xmath83 in the neighborhood as @xmath84 , where @xmath85 .",
    "hence for energies near @xmath82 , @xmath86 . thus deviations from @xmath82 are negative at positive absolute temperature , and ( for small deviations at least ) are proportional to reciprocal temperature @xmath87 , as illustrated in figure 3 .",
    "of course , this law was discovered by pierre curie in experimental study of magnetization , and bears his name .    for two - state paramagnets , @xmath88 and @xmath89 , where @xmath90 is the energy of alignment per spin ( magnetic moment times magnetic field strength ) .",
    "thus for @xmath1 near @xmath91 , @xmath92 , while @xmath93 . since @xmath94 for these systems may be positive or negative , @xmath43 will be negative for some @xmath95 values regardless of our choice of the thermal energy zero ! although negative `` degrees freedom '' may cause discomfort for some , a negative value for @xmath43 should disturb no one since , to paraphrase a related comment by schroeder@xcite , there s no law of physics guaranteeing that there will not be fewer ways to distribute energy , as more energy is added .",
    "in fact , as we now know ,",
    "temperature and reciprocal temperature are simply different forms for the lagrange multiplier that characterizes a system s willingness to share thermal energy@xcite . systems , like these spin systems , capable of taking on ( and sharing energy from ) negative absolute temperature states show clearly that for them reciprocal temperature has more fundamental significance , and that the `` absolute zeros '' of temperature ( approached from negative or positive directions ) are indeed at opposite ends of a continuum@xcite .",
    "but if reciprocal temperature is more fundamental , our instantaneous no - work heat capacity should be no less simply connected to the log - log derivative via reciprocal temperature .",
    "rearrangement of the equation above shows that indeed this is the case .",
    "@xmath96 = \\left [ 1-\\beta \\frac \\partial { % \\partial \\beta } \\right ] \\left\\ { \\frac{\\partial ( \\ln \\omega ) } { \\partial \\left ( \\ln e\\right ) } \\right\\ } = -\\beta \\frac{\\partial \\ln \\omega } { \\partial \\beta } = -\\beta \\frac{\\partial ( s / k)}{\\partial \\beta } \\text{.}\\ ] ]    had we historically adopted as our measure of `` willingness to share energy '' some other power of the uncertainty slope , say @xmath97 where @xmath98 , the instantaneous heat capacity would have remained proportional to the log - log derivative of multiplicity with respect to that measure as well .",
    "this version of the relation now lets us simplify our perspective on entropy maxima . in the continuum ( stirling )",
    "approximation for spin system accessible states @xmath99 , and measuring energy from the `` low - energy side '' , equation ( [ temperature ] ) yields @xmath100 where @xmath101 , so that @xmath102 and @xmath103 ^ 2e^xn$ ] .",
    "here of course , @xmath104 takes on positive and negative values , ranging from around @xmath105 to @xmath106 respectively for orientation energies @xmath1 with allowed values from @xmath107 to @xmath108 . as you can see from the plot in fig .",
    "3 , again @xmath63 overestimates @xmath75 at low temperatures ( high values of @xmath104 ) , although the estimate becomes exact when @xmath104 decreases to around @xmath109 ( the solution of @xmath110 ) .",
    "after this @xmath63 _ underestimates _",
    "@xmath51 , which begins to decrease as @xmath111 decreases and @xmath50 increases from this point .",
    "all of this switches again when @xmath112 passes through zero , since @xmath63 remains positive while the change in uncertainty per @xmath113-fold increase in energy ( @xmath114 ) becomes negative since uncertainty about the system state _ decreases _ with added energy past this point .",
    "also , of course , average heat capacity goes to zero and no longer equals @xmath51 , since the average must be obtained piecewise when temperature ( unlike reciprocal temperature ) breaches the discontinuity from plus infinity to minus infinity .",
    "thus in addition to information units for heat capacity , we gain from this approach a way to visualize the limits of equipartition , and minimize consternation over negative degrees of freedom ( e.g. for spin and virial systems ) as well .",
    "in short , we ve looked here at natural ( as distinct from historical ) units for the common thermodynamic quantities , so that we might explore the possibility that common uses of @xmath50 and @xmath115 , as measures of `` willingness to share thermal energy '' , have inherited their present emphasis partly because they predate our present understanding of multiplicity ( the @xmath116 in @xmath117 on josiah willard gibb s tombstone ) .",
    "heat capacity is a particularly knotty concept in this regard , since for most of us it has always been a change in energy `` per degree kelvin '' . in fundamental units ,",
    "if heat capacity has any dimensions at all they are those of the base-@xmath3 information units , since `` change in energy per unit change in energy per bit '' leaves us with nothing but bits in the bargain .",
    "we point out a simple interpretation for the result , namely that thermal energy @xmath1 , divided by temperature @xmath118 , is fundamentally @xmath119 , i.e. the log - log derivative of multiplicity with respect to energy ( e.g. a measure of the bits of uncertainty increase per two - fold increase in energy ) .",
    "the instantaneous no - work heat capacity in this context is @xmath120 , an estimate of @xmath121 with an energy - zero inferred from the `` local slope '' of the log - log plot .",
    "we show that these two quantities bear a simple relationship to each other , regardless of the variable ( e.g. @xmath50 or @xmath69 ) chosen to keep track of a system s willingness to share energy thermally .",
    "the former of the quantities , namely @xmath121 , plays the role of `` degrees freedom over two '' in quadratic systems , but is dependent on the energy zero , and regardless can take on negative values in systems with entropy maxima .",
    "its limitations are those of the concept of equipartition itself .",
    "the latter quantity , namely @xmath63 , provides deep insight into the ways a system accomodates _ new _ thermal energy .",
    "because these quantities are defined in terms of state multiplicity and the conserved variable being shared ( in this case energy ) , and relatively independent of the form chosen for the lagrange multiplier in the problem ( e.g. temperature in historical units ) , their _ analogs _ in problems that involve the sharing of other conserved quantities ( e.g. volume , particles , or even dollars ) may be easier to recognize and put to use as well .",
    "this work has benefited indirectly from support by the u.s .",
    "department of energy , the missouri research board , as well as monsanto and memc electronic materials companies .",
    "it has benefited most , however , from the interest and support of students at um - st .",
    "louis .",
    "e. f. taylor ,  the boundaries of nature , special and general relativity and quantum mechanics : a second course in physics ,  oersted medal lecture , _ the american journal of physics _ * 66 * , 369 - 376 ( may 1998 ) .        c. e. shannon , _ bell system tech .",
    "j. _ * 27 * , 379 , 623 ( 1949 ) ; these papers are reprinted in c. e. shannon and w. weaver , * the mathematical theory of communication * ( university of illinois press , urbana , 1949 ) ."
  ],
  "abstract_text": [
    "<S> information theory this century has clarified the 19th century work of gibbs , and has shown that natural units for temperature kt , defined via @xmath0 , are energy per nat of information uncertainty . </S>",
    "<S> this means that ( for _ any _ system ) the total thermal energy @xmath1 over @xmath2 is the log - log derivative of multiplicity with respect to energy , and ( for _ all _ b ) the number of base-@xmath3 units of information lost about the state of the system per @xmath3-fold increase in the amount of thermal energy therein . for `` un - inverted '' ( @xmath4 ) systems </S>",
    "<S> , @xmath5 is also a temperature - averaged heat capacity , equaling `` degrees - freedom over two '' for the quadratic case . in similar units </S>",
    "<S> the work - free differential heat capacity @xmath6 is a `` local version '' of this log - log derivative , equal to bits of uncertainty gained per 2-fold increase in temperature . </S>",
    "<S> this makes @xmath6 ( unlike @xmath5 ) independent of the energy zero , explaining in statistical terms its usefulness for detecting both phase changes and quadratic modes . from umstl - cme-94a09pf </S>"
  ]
}