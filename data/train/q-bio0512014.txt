{
  "article_text": [
    "game theory conceptualizes many of the circumstances that drive the dynamics of social and economic systems . if such systems consist of many pair - wise interacting agents they can be modeled as networks . in such networks",
    "one can relate the function of a vertex to its position .",
    "for example , in business connections an agent would presumably like to be close , in network distance , to the average other agent  @xcite .",
    "this ensures the information received from other agents to be up to date  @xcite and will likely increase the agent s sphere of influence . at the same time",
    "the agent would seek to limit the work load by minimizing its degree ( number of connections ) . in this paper",
    "we define an iterative @xmath0-player game where agents try simultaneously to obtain high centrality and low degree . agents remove and add edges by individual strategies .",
    "furthermore they update the strategies throughout the game by imitating successful agents .",
    "we assume the agents have only information about their immediate surroundings . as a result",
    "an agent can only re - link to , or observe and mimic the strategies of , other agents a fixed distance away .",
    "most recent studies of games on networks , have considered a static underlying network defining the possible competitive encounters  @xcite . in other models where the network co - evolves with the game  @xcite ,",
    "the agents are assigned additional variables which serve as the basis of the game . in our model however , the score of an agent is determined by the network dynamics alone .",
    "this setting , apart from being conceptually simpler , makes the relation between the game and network dynamics more transparent .",
    "the rest of the paper contains a precise definition of the model , an investigation of the time evolution of the strategies and network structure , and an investigation of the dependence on model parameters .",
    "in our model @xmath0 agents are synchronously updated over @xmath1 iterations .",
    "the initial configuration is an erds - rnyi network  @xcite of @xmath2 edges .",
    "all steps of the dynamics keep the network simple so that as multiple edges or self - edges do not occur .",
    "the score , in our game , is an effective score taking into account both the benefit of centrality and the inevitable cost of maintaining the network ties .",
    "we want the score of a vertex @xmath3 to increase with centrality and decrease with its degree @xmath4 .",
    "of many centrality concepts  @xcite we choose to base our score on the simplest non - local centrality measure  closeness centrality ( the reciprocal average path - length from one vertex to the rest of the graph ) .",
    "furthermore , if the network is disconnected we would like the score to increase with the number of vertices reachable from @xmath3 . to incorporate this",
    "we use a slight modification of closeness @xmath5 where @xmath6 is the connected subgraph @xmath3 belongs to and @xmath7 is the graph distance between @xmath3 and @xmath8 . the number of elements in the sum of eq .",
    "( [ eq : cent ] ) is proportional to the number of vertices of @xmath3 s connected component .",
    "we use the average reciprocal distance , rather than the reciprocal average distance .",
    "the former gives a higher weight on the count of closer vertices , but captures similar features as the original closeness does .",
    "we define a score function that incorporates the desired properties mentioned above : @xmath9 in addition we assume the accessible information is restricted to a close neighborhood of a vertex . to be precise , the moves allowed to a vertex is to delete or add edges to agents up to two steps away .",
    "our assumption is motivated by the fact that in real world systems , agents are more likely to have knowledge of a restricted fraction than the whole network itself .",
    "when a vertex @xmath3 updates its position , it selects another vertex in a set @xmath10 ( the neighborhood @xmath11 if an edge is to be removed , or the second neighborhood @xmath12 if an edge is to be added ) .",
    "this is done by successively applying six tiebreaking _ actions _ :    * choose vertices with maximal ( minimal ) degree ( maxd / mind ) .",
    "* choose vertices with maximal ( minimal ) centrality in the sense of eq .",
    "( [ eq : cent ] ) ( maxc / minc ) . * pick a vertex at random ( rnd ) .",
    "* do not add ( or remove ) any edge ( no ) .",
    "the strategies of a vertex is encoded in two six - tuples @xmath13 and @xmath14 representing a priority ordering of the addition and deletion actions respectively . if @xmath15 then @xmath3 tries at first to attach an edge to the vertex in @xmath16 with highest degree . if more than one vertex has the highest degree , then one of these is selected by the minc strategy . if still no unique vertex is found , nothing is done ( by application of the no strategy ) .",
    "note that such a vertex is always found after strategies no or rnd are applied . if @xmath17 no edge is added ( or deleted ) .",
    "the strategy vectors are initialized to random permutations of the six actions .",
    "every @xmath18th time step a vertex @xmath3 updates its strategy vectors by identifying the vertex in @xmath19 with highest accumulated score since the last strategy update .",
    "then @xmath3 copies the parts of @xmath20 and @xmath21 that @xmath8 used the last time step , and let the remaining actions come in the same order as the strategy vectors prior to the update . for the purposes of making the set of strategy vectors ergodic , drive the strategy optimization  @xcite and model irrational moves by the agents  @xcite we swap , with probability @xmath22 , two random elements of @xmath20 and @xmath21 every strategy vector update . like the strategy space",
    "we also want the network space to be ergodic ( i.e.  that the game can generate all @xmath0-vertex graphs from all initial configurations ) . in order to ensure ergodicity disconnected clusters should be able to be re - connected .",
    "we obtain this by letting a vertex @xmath3 attach to a random vertex ( not just a second neighbor ) with probability @xmath23 every @xmath24th time step .",
    "this is also plausible in real socioeconomic networks  even if agents are more influenced by their network surrounding , long - range links can form by other mechanisms ( cf .",
    "@xcite ) .",
    "the outline of the algorithm is thus :    1 .",
    "[ step : init_nwk ] initialize the network to an erds - rnyi network with @xmath0 vertices and @xmath25 edges . 2 .",
    "[ step : init_s ] use random permutations of the six actions as @xmath26 and @xmath14 for all vertices .",
    "[ step : score ] calculate the score for all vertices .",
    "[ step : rewi ] update the vertices synchronously by adding and deleting edges as selected by the strategy vectors . with probability @xmath23 an edge",
    "is added to a random vertex instead of a neighbor s neighbor .",
    "[ step : strat ] every @xmath18th time step , update the strategy vectors . for each vertex , with probability @xmath22 , swap two elements in a vertex strategy vector .",
    "[ step : iter ] increment the simulation time @xmath27 and , if @xmath28 , go to step  [ step : score ] .",
    "@xmath29 averages over different realizations of the algorithm are performed .",
    "we will use parameter values @xmath30 , @xmath31 , @xmath32 , @xmath33 and @xmath34 throughout the paper (",
    "the conclusions will not depend sensitively on these values ) .",
    "a part of the time evolution of a run of the game is displayed in fig .",
    "[ fig : evo ] . fig .",
    "[ fig : evo](a ) and ( b ) show the fraction of the agents having a specific main addition ( @xmath35 ) and deletion action ( @xmath36 ) respectively .",
    "as we can see , the time evolution can be very complex , having sudden cascades of strategy changes .",
    "we do not display actions with lower priorities ( @xmath37 ) , but we note that they are less clear - cut as they experience a lower selection pressure . typically the time evolution shows rather lengthy quasi - stable periods punctuated by outbursts of strategy changing cascades ( in both the addition and deletion strategies ) as seen in fig .  [",
    "fig : evo](a ) and ( b ) .",
    "not all strategies , as we will see later , invade the population . as illustrated in this example , maxc is the most frequent main action for most parameter values , whereas minc and mind ( and no for addition ) are rare . from the definition of the actions we anticipate differences in the network structure for time frames of different dominating strategies .",
    "this is indeed the case as evident from panels ( c ) , ( d ) and ( e ) of fig .",
    "[ fig : evo ] which display the average score @xmath38 , degree @xmath39 and number of vertices in the largest connected cluster @xmath40 .",
    "the average score fluctuates wildly suggesting that states of global prosperity are unstable .",
    "likewise the degree has an intermittent time evolution with sudden high - degree spikes and periods of sparseness .",
    "unsurprisingly , the high - degree spikes are located at the outbursts of the no deletion strategy where edges are not deleted , but only added .",
    "the size of the largest connected cluster has an even more dramatic time evolution , fluctuating between fully connected and fragmented states .",
    "note that there need not be a dramatic change in degree to initiate a drop in @xmath40this leads us to conclude that the phenomenon probably arises from network topological effects .    [ cols=\">,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]     note that in fig .",
    "[ fig : evo](b ) the strategies seem to differ in their ability to invade one another , e.g.  maxc is followed by a peak in rnd .",
    "we investigate this qualitatively by calculating the `` transition matrix '' @xmath41 with elements @xmath42 giving the probability of a vertex with the leading action @xmath43 to have the leading action @xmath44 at the next time step .",
    "however note that the dynamics is not fully determined by @xmath41 , and is thus not a transition matrix in the sense of other physical models .",
    "if that were the case ( i.e.  the current strategy is independent of the strategy adopted in the previous time step ) we would have the relation @xmath45 .",
    "so we measure the deviation from such a null - model by assuming the diagonal ( i.e.  the frequencies of the strategies ) and calculating @xmath46 defined by @xmath47 the values of @xmath46 for the parameters defined in fig .",
    "[ fig : evo ] are displayed in tab .",
    "[ tab : trans ] .",
    "the off - diagonal elements are much lower than @xmath48 ( the average off - diagonal @xmath49 values are @xmath50 for addition strategies and @xmath51 for deletion ) .",
    "this reflects the contiguous periods of one dominating action .",
    "note that transitions between maxc and rnd are over - represented : @xmath52 , which is more than twice the value of any other off - diagonal element involving maxc or rnd . to add to the complexity",
    ", the matrix is not completely symmetric @xmath53 is twice ( @xmath54 s.d . )  as large as @xmath55 meaning that it is easier for rnd to invade no as a leading deletion action , than vice versa .",
    "to get a more detailed view of the relation between the preferred actions and the structure of the network , we investigate the degree distribution @xmath56 for different leading actions . in fig .",
    "[ fig : d](a ) we plot the degree distribution for the maxc dominating addition action .",
    "it is conspicuously wide ",
    "so despite the fact that the vertex strategies are similar , the network structure evolves into a highly inhomogeneous state .",
    "there are peaks in the degree distribution close to @xmath57 and @xmath58 , meaning that the network has at least one or more hubs of extremely high degree .",
    "a snapshot of the network with two hubs , each with degree close to @xmath59 is seen in fig .",
    "[ fig : d](b ) .",
    "such a situation can indeed be rather stable : the most central vertices ( the vertices between the hubs ) have rather low degree , and thus have a very high score .",
    "since these are in @xmath60 ( but not in @xmath61 ) of most vertices , these will be the hubs of the next time step , and the old hub will likely be between these .",
    "thus the property of being a hub will effectively oscillate between members of two sets of vertices .",
    "next we turn to the scaling of the strategy preferences and structural measures with respect to model parameters . in fig .",
    "[ fig : r ] we tune the fraction of random attachments @xmath23 for three system sizes . in panels ( a)-(c ) we display the fraction of leading addition actions among the agents @xmath62 ( averaged over @xmath63 runs and @xmath64 time steps ) . as observed in fig .",
    "[ fig : evo](a ) the dominant strategy is maxc followed by maxd and rnd .",
    "the leading deleting actions , as seen in panels ( d)-(f ) , are ranked similarly expect that maxd has a larger ( and increasing ) presence .",
    "there are trends in the @xmath23-dependences of @xmath65 , but apparently no incipient discontinuity .",
    "this observation ( which also seems to hold for @xmath22 scaling ) is an indication that the results above can be generalized to a large parameter range .",
    "we also note that although the system has the opportunity to be passive ( i.e.agents having @xmath66 ) , it does not .",
    "this is reminiscent of the `` red queen hypothesis '' of evolution  @xcite  organisms need to keep evolving to maintain their fitness . the average degree , plotted in fig .",
    "[ fig : evo](g ) is monotonously increasing with @xmath23 and decreasing with @xmath0 ( if @xmath67 ) .",
    "for all network models that we are aware of ( allowing for fragmented networks ) decreasing average degree implies a smaller giant component . in our model the picture is the opposite , as the system grows the giant component spans an increasing fraction of the network .",
    "this also means that the agents collectively reach the twin goals of keeping the degree low and the graph connected .",
    "to summarize , we have investigated an @xmath0-player game of networking agents .",
    "the success of an agent @xmath3 increases with the closeness centrality and the size of the connected component @xmath3 belongs to , while it decreases with @xmath3 s degree .",
    "such a situation may occur in diplomacy , lobbying or business networks , where an agent wants to be central in the network ( for the purpose of having as new information as possible and be more actively involved in the decision making process ) but not at the expense of having too many direct contacts .",
    "the dynamics proceed by the agents deleting edges and attaching new edges to their second - neighbors according to strategies based on local information . once in a while ( every tenth time step in our simulation )",
    "the agents evaluate the strategies of the neighborhood and imitate the best performing neighbor to optimize their strategy .",
    "as the vertices of our model have no additional traits  their competitive situation is completely determined by their network position  the time evolution of strategies is immediately tied to the evolution of network structure .",
    "these evolutionary trajectories are strikingly complex having long periods of relative stability followed by sudden transitions , spikes , or chaotic periods visible in both the strategies and the network structure .",
    "one such instability is manifested in a transient fragmentation of the network , this occurs more rarely as the network size increases .",
    "in fact the network gets more connected as size is increased , interestingly this is accompanied with a decreasing fraction of links  thus , with a growing number of actors the system gets better at achieving the common goal of being connected and keeping the degree low .",
    "we also observe that the network dynamics never reaches a fixed point of passivity ( where the network is largely static ) , this suggests situation similar to the red queen hypothesis ",
    "agents have to keep on networking to maintain their success .",
    "we believe network positional games will prove to be a useful framework for modeling dynamical networks , and anticipate much future work in this direction .",
    "p.  holme , a.  trusina , b.  j. kim , and p.  minnhagen .",
    "prisoners dilemma in real - world acquaintance networks : spikes and quasiequilibria induced by the interplay between structure and dynamics .",
    ", 68:030901(r ) , 2003 ."
  ],
  "abstract_text": [
    "<S> we model a system of networking agents that seek to optimize their centrality in the network while keeping their cost , the number of connections they are participating in , low . </S>",
    "<S> unlike other game - theory based models for network evolution , the success of the agents is related only to their position in the network . </S>",
    "<S> the agents use strategies based on local information to improve their chance of success . </S>",
    "<S> both the evolution of strategies and network structure are investigated . </S>",
    "<S> we find a dramatic time evolution with cascades of strategy change accompanied by a change in network structure . on average </S>",
    "<S> the network self - organizes to a state close to the transition between a fragmented state and a state with a giant component . </S>",
    "<S> furthermore , with increasing system size both the average degree and the level of fragmentation decreases . </S>",
    "<S> we also observe that the network keeps on actively evolving , although it does not have to , thus suggesting a red queen - like situation where agents have to keep on networking and responding to the moves of the others in order to stay successful . </S>"
  ]
}