{
  "article_text": [
    "compressed sensing finds a variety of applications in practice as many natural signals admit a sparse or an approximate sparse representation in a certain basis . nevertheless , accurate reconstruction of a sparse signal relies on the knowledge of the sparsifying dictionary , while in many applications , it is often impractical to pre - specify a dictionary that can sparsely represent the signal .",
    "for example , for the line spectral estimation problem , using a preset discrete fourier transform ( dft ) matrix suffers from considerable performance degradation because the true frequency components may not lie on the pre - specified frequency grid @xcite .",
    "the same is true for direction - of - arrival ( doa ) estimation and source localization in sensor networks , where the true directions or locations of sources may not be aligned on the presumed grid @xcite .",
    "overall , in these applications , the sparsifying dictionary is characterized by a set of unknown parameters in a continuous domain . in order to apply",
    "compressed sensing to such applications , the continuous parameter space has to be discretized to a finite set of grid points , based on which a presumed dictionary is constructed for sparse signal recovery .",
    "discretization , however , inevitably incurs errors since the true parameters do not necessarily lie on the discretized grid .",
    "this error , also referred to as the grid mismatch , leads to deteriorated performance or even failure in recovering the sparse signal .",
    "finer grids can certainly be used to reduce grid mismatch and improve the reconstruction accuracy .",
    "nevertheless , recovery algorithms may become numerically instable and computationally prohibitive when very fine discretized grids are employed .",
    "the grid mismatch problem has attracted a lot of attention over the past few years . specifically , in @xcite , the problem was addressed in a general framework of `` basis mismatch '' where the mismatch is modeled as a perturbation ( caused by grid discretization , calibration errors or other factors ) between the presumed and the actual dictionaries , and the impact of the basis mismatch on the reconstruction error was analyzed . in @xcite , to deal with grid mismatch , the true dictionary is approximated as a summation of a presumed dictionary and a structured parameterized matrix via the taylor expansion .",
    "the recovery performance of this method , however , depends on the accuracy of the taylor expansion in approximating the true dictionary .",
    "the grid mismatch problem was also examined in @xcite , where a highly coherent dictionary ( very fine grids ) is used to mitigate the discretization error , and a class of greedy algorithms which use the technique of band exclusion ( coherence - inhibiting ) were proposed for sparse signal recovery .",
    "besides these efforts , another line of work @xcite studied the problem of grid mismatch in a more fundamental way : they circumvent the discretization issue by working directly on the continuous parameter space , leading to the so - called super - resolution technique . in @xcite , an atomic norm - minimization ( also referred to as the total variation norm - minimization )",
    "approach was proposed to handle the infinite dictionary with continuous atoms .",
    "it was shown that given that the frequency components are sufficiently separated , the frequency components of a mixture of complex sinusoids can be super - resolved with infinite precision from coarse - scale information only .",
    "nevertheless , finding a solution to the atomic norm problem is quite challenging .",
    "although the atomic norm problem can be cast into a convex semidefinite program optimization for the complex sinusoid mixture problem , it still remains unclear how this reformulation generalizes to other scenarios . in @xcite , by treating the sparse signal as hidden variables , a bayesian approach was proposed to iteratively refine the dictionary , and is shown able to achieve super - resolution accuracy .    in this paper",
    ", we propose a generalized iterative reweighted @xmath0 method for joint dictionary parameter learning and sparse signal recovery .",
    "the proposed method is developed by iteratively decreasing a surrogate function that majorizes the original objective function .",
    "note that the use of the iterative reweighted scheme for sparse signal recovery is not new and has achieved great success over past few years ( e.g. @xcite ) . nevertheless , previous works concern only recovery of the sparse signal . the current work , instead , generalizes the iterative reweighted scheme for joint dictionary parameter learning and sparse signal recovery .",
    "moreover , previous iterative reweighted algorithms usually involve iterative minimization of a surrogate function majorizing a given objective function , while our proposed method only requires iteratively decreasing a surrogate function .",
    "we will show that through iteratively decreasing ( not necessarily minimizing ) the surrogate function , the iterative process yields a non - increasing objective function value as well , and is guaranteed to converge to a stationary point of the objective function .",
    "this generalization extends the applicability of the iterative reweighted scheme since finding a simple and convex surrogate function which admits an analytical solution could be difficult for many complex problems . in addition , iteratively decreasing the surrogate function results in an interweaved and gradual refinement of the signal and the unknown parameters , which enables the algorithm to produce more focal and reliable estimates as the optimization progresses .",
    "the current work is an extension of our previous work @xcite to more general scenarios involving noisy and/or multiple measurement vectors .",
    "as shown in this paper , this extension is technically non - trivial and also brings in substantial reduction in computational complexity .",
    "the rest of the paper is organized as follows . in section [",
    "sec : formulation ] , the line spectral estimation problem is formulated as a joint sparse representation and dictionary parameter estimation problem .",
    "a generalized iterative reweighted @xmath0 algorithm is developed in section [ sec : algorithm ] .",
    "the choice of the regularization parameter controlling the tradeoff between sparsity and data fitting is discussed in section [ sec : lambda - choice ] , where a simple and effective update rule for the regularization parameter is proposed .",
    "extension of the proposed algorithm to the multiple measurement vector scenario is studied in section [ sec : mmv ] . in section",
    "[ sec : analysis ] , we provide a heuristic but enlightening analysis on the exact reconstruction condition of the considered problem for the noiseless case .",
    "simulation results are provided in section [ sec : simulation ] , followed by concluding remarks in section [ sec : conclusion ] .",
    "in many practical applications such as direction - of - arrival ( doa ) estimation and line spectral estimation , the sparsifying dictionary is usually characterized by a set of unknown parameters in a continuous domain .",
    "for example , consider the line spectral estimation problem where the observed signal is a summation of a number of complex sinusoids : @xmath1 where @xmath2 and @xmath3 denote the frequency and the complex amplitude of the @xmath4-th component , respectively , and @xmath5 represents the observation noise .",
    "define @xmath6^t$ ] , the model ( [ data - model ] ) can be rewritten in a vector - matrix form as @xmath7 where @xmath8^t$ ] , @xmath9^t$ ] , and @xmath10 $ ] .",
    "note that in some applications , to facilitate data acquisition and subsequent processing , we may wish to estimate @xmath11 and @xmath12 from a subset of measurements randomly extracted from @xmath13 .",
    "this random sampling operation amounts to retaining the corresponding rows of @xmath14 and removing the rest rows from the dictionary .",
    "this modification , however , makes no difference to our algorithm development .",
    "we see that the dictionary @xmath14 is characterized by a number of unknown parameters @xmath11 which need to be estimated along with the unknown complex amplitudes @xmath12 . to deal with this problem , conventional compressed sensing techniques discretize the continuous parameter space into a finite set of grid points , assuming that the unknown frequency components @xmath11 lie on the discretized grid . estimating @xmath11 and @xmath12",
    "can then be formulated as a sparse signal recovery problem @xmath15 , where @xmath16 ( @xmath17 ) is an overcomplete dictionary constructed based on the discretized grid points .",
    "discretization , however , inevitably incurs errors since the true parameters do not necessarily lie on the discretized grid .",
    "this error , also referred to as the grid mismatch , leads to deteriorated performance or even failure in recovering the sparse signal .    to circumvent this issue",
    ", we treat the overcomplete dictionary as an unknown parameterized matrix @xmath18 $ ] , with each atom @xmath19 determined by an unknown frequency parameter @xmath20 . estimating @xmath11 and @xmath12",
    "can still be formulated as a sparse signal recovery problem . nevertheless , in this framework , the frequency parameters @xmath21 need to be optimized along with the sparse signal such that the parametric dictionary will approach the true sparsifying dictionary .",
    "specifically , the problem can be presented as follows : we search for a set of unknown parameters @xmath22 with which the observed signal @xmath23 can be represented by as few atoms as possible with a specified error tolerance .",
    "such a problem can be readily formulated as @xmath24 where @xmath25 stands for the number of the nonzero components of @xmath26 , and @xmath27 is an error tolerance parameter related to noise statistics .",
    "the optimization ( [ opt-1 ] ) , however , is an np - hard problem .",
    "thus , alternative sparsity - promoting functionals which are more computationally efficient in finding the sparse solution are desirable . in this paper , we consider the use of the log - sum sparsity - encouraging functional for sparse signal recovery .",
    "log - sum penalty function has been extensively used for sparse signal recovery , e.g. @xcite .",
    "it was proved theoretically @xcite and shown in a series of experiments @xcite that log - sum based methods present uniform superiority over the conventional @xmath28-type methods . replacing the @xmath29-norm in ( [ opt-1 ] ) with the log - sum functional leads to @xmath30 where @xmath31 denotes",
    "the @xmath32th component of the vector @xmath26 , and @xmath33 is a positive parameter to ensure that the function is well - defined .",
    "the optimization ( [ opt-2 ] ) can be formulated as an unconstrained optimization problem by removing the constraint and adding a tikhonov regularization term , @xmath34 , to the objective functional , which yields the following optimization @xmath35 where @xmath36 is a regularization parameter controlling the tradeoff between data fitting and the sparsity of the solution , and its choice will be more thoroughly discussed later in this paper .",
    "we now develop a generalized iterative reweighted @xmath0 algorithm for joint dictionary parameter learning and sparse signal recovery .",
    "we resort to a bounded optimization approach , also known as the majorization - minimization ( mm ) approach @xcite , to solve the optimization ( [ opt - r4 ] ) .",
    "the idea of the mm approach is to iteratively minimize a simple surrogate function majorizing the given objective function . nevertheless ,",
    "in this paper we will show that through iteratively decreasing ( not necessarily minimizing ) the surrogate function , the iterative process also yields a non - increasing objective function value and eventually converges to a stationary point of @xmath37 . to obtain an appropriate surrogate function for ( [ opt - r4 ] )",
    ", we first find a suitable surrogate function for the log - sum functional @xmath38 .",
    "it has been shown in @xcite that a differentiable and convex surrogate function majorizing @xmath38 is given by @xmath39 where @xmath40^t$ ] denotes an estimate of @xmath26 at iteration @xmath41 .",
    "we can easily verify that @xmath42 , with the equality attained when @xmath43 .",
    "consequently the surrogate function for the objective function @xmath37 is @xmath44    solving ( [ opt - r4 ] ) now reduces to minimizing the surrogate function iteratively . ignoring terms independent of @xmath45 , optimizing the surrogate function ( [ surrogate - function - r1 ] )",
    "is simplified as @xmath46 where @xmath47^{h}$ ] denotes the conjugate transpose , and @xmath48 is a diagonal matrix given as @xmath49 conditioned on @xmath50 , the optimal @xmath26 of ( [ opt - r5 ] ) can be readily obtained as @xmath51 substituting ( [ eqn - r2 ] ) back into ( [ opt - r5 ] ) , the optimization simply becomes searching for the unknown parameter @xmath50 : @xmath52 an analytical solution of the above optimization ( [ opt - r6 ] ) is difficult to obtain .",
    "nevertheless , in our algorithm , we only need to search for a new estimate @xmath53 such that the following inequality holds @xmath54 such an estimate can be easily obtained by using a gradient descent method .",
    "given @xmath53 , @xmath55 can be obtained via ( [ eqn - r2 ] ) , with @xmath50 replaced by @xmath53 , i.e. @xmath56    in the following , we show that the new estimate @xmath57 results in a non - increasing objective function value , that is , @xmath58 to this goal , we first show the following inequality @xmath59 where @xmath60 comes from the fact that @xmath61 is the optimal solution to the optimization ( [ opt - r5 ] ) ; @xmath62 and @xmath63 follow from ( [ eqn - r3 ] ) and ( [ eqn - r4 ] ) , respectively .",
    "moreover , we have @xmath64 where @xmath60 follows from the fact that @xmath65 attains its minimum when @xmath43 . combining ( [ inequality - r1])([inequality - r2 ] ) , we eventually arrive at @xmath66 we see that through iteratively decreasing ( not necessarily minimizing ) the surrogate function , the objective function @xmath37 is guaranteed to be non - increasing at each iteration .    for clarification ,",
    "we summarize our algorithm as follows .    * iterative reweighted algorithm i *    [ cols= \" < , < \" , ]",
    "this paper studied the super - resolution compressed sensing problem where the sparsifying dictionary is characterized by a set of unknown parameters in a continuous domain .",
    "such a problem arises in many practical applications such as direction - of - arrival estimation and line spectral estimation . by resorting to the majorization - minimization approach",
    ", we developed a generalized iterative reweighted @xmath0 algorithm for joint dictionary parameter learning and sparse signal recovery .",
    "the proposed algorithm iteratively decreases a surrogate function majorizing a given objective function , leading to a gradual and interweaved iterative process to refine the unknown parameters and the sparse signal .",
    "simulation results show that our proposed algorithm effectively overcomes the grid mismatch problem and achieves a super - resolution accuracy in resolving the unknown frequency parameters .",
    "the proposed algorithm also demonstrates superiority over several existing super - resolution compressed sensing methods in resolving the unknown parameters and reconstructing the original signal .",
    "define @xmath68 using the chain rule , the first derivative of @xmath67 with respect to @xmath69 , @xmath70 can be computed as @xmath71 where @xmath72 donates the conjugate of the complex matrix @xmath73 , and @xmath74                l.  hu , j.  zhou , z.  shi , and q.  fu , `` a fast and accurate reconstruction algorithm for compressed sensing of complex sinusoids , '' _ ieee trans . signal processing _ , vol .",
    "61 , no .",
    "57445754 , nov .",
    "2013 .",
    "i.  f. gorodnitsky and b.  d. rao , `` sparse signal reconstructions from limited data using focuss : a re - weighted minimum norm algorithm , '' _ ieee trans . signal processing _",
    "45 , no .  3 , pp .",
    "699616 , mar .",
    "1997 .",
    "d.  wipf and s.  nagarajan , `` iterative reweighted @xmath28 and @xmath0 methods for finding sparse solutions , '' _ ieee journals of selected topics in signal processing _ , vol .  4 , no .  2 ,",
    ". 317329 , apr .",
    "j.  fang , j.  li , y.  shen , h.  li , and s.  li , `` super - resolution compressed sensing : an iterative reweighted algorithm for joint parameter learning and sparse signal recovery , '' _ ieee signal processing letters _ ,",
    "21 , no .  6 , pp .",
    "761765 , june 2014 .",
    "s.  f. cotter , b.  d. rao , k.  engan , and k.  kreutz - delgado , `` sparse solutions to linear inverse problems with multiple measurement vectors , '' _ ieee trans . signal processing _ , vol .",
    "53 , no .  7 , pp .",
    "24772488 , july 2005 .",
    "j.  a. tropp , j.  n. laska , m.  f. duarte , j.  k. romberg , and r.  g. baraniuk , `` beyond nyquist : efficient sampling of sparse bandlimited signals , '' _ ieee trans .",
    "information theory _ ,",
    "56 , no .  1 ,",
    "pp . 520544 , jan ."
  ],
  "abstract_text": [
    "<S> conventional compressed sensing theory assumes signals have sparse representations in a known , finite dictionary . </S>",
    "<S> nevertheless , in many practical applications such as direction - of - arrival ( doa ) estimation and line spectral estimation , the sparsifying dictionary is usually characterized by a set of unknown parameters in a continuous domain . </S>",
    "<S> to apply the conventional compressed sensing technique to such applications , the continuous parameter space has to be discretized to a finite set of grid points , based on which a `` presumed dictionary '' is constructed for sparse signal recovery . </S>",
    "<S> discretization , however , inevitably incurs errors since the true parameters do not necessarily lie on the discretized grid . </S>",
    "<S> this error , also referred to as grid mismatch , may lead to deteriorated recovery performance or even recovery failure . to address this issue , </S>",
    "<S> in this paper , we propose a generalized iterative reweighted @xmath0 method which jointly estimates the sparse signals and the unknown parameters associated with the true dictionary . </S>",
    "<S> the proposed algorithm is developed by iteratively decreasing a surrogate function majorizing a given objective function , resulting in a gradual and interweaved iterative process to refine the unknown parameters and the sparse signal . </S>",
    "<S> a simple yet effective scheme is developed for adaptively updating the regularization parameter that controls the tradeoff between the sparsity of the solution and the data fitting error . </S>",
    "<S> extension of the proposed algorithm to the multiple measurement vector scenario is also considered . </S>",
    "<S> numerical results show that the proposed algorithm achieves a super - resolution accuracy and presents superiority over other existing methods .    </S>",
    "<S> super - resolution compressed sensing , grid mismatch , iterative reweighted methods , joint parameter learning and sparse signal recovery . </S>"
  ]
}