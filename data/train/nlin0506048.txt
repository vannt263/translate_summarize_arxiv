{
  "article_text": [
    "what is the difference between adaptation and normalization ? are these just two distinct processes , or can they be related ?",
    "the purpose of this paper is to develop a model whose dynamic smoothly proceeds from local adaptation to global normalization .",
    "mathematical properties of the model are analyzed , and its dynamical properties are evaluated with luminance images .",
    "i study the model within the framework of biological vision , where emphasis is laid on understanding the emergence of adaptation within the model s dynamic .",
    "finally , a method is proposed for freezing the dynamic at the moment when adaptation occurs . but to begin with , i briefly describe how adaptation and normalization contribute to information processing in the brain .",
    "+ adaptation refers to the adjustment of a sense organ to the intensity or quality of stimulation @xcite .",
    "there is agreement that adaptation is important for the function of nervous systems , since without corresponding mechanisms any given neuron with its limited dynamic range would stay silent or operate in saturation most of the time @xcite . when considering a population of _ cells _",
    "( e.g. formal processing units or biological neurons ) , then adaptation is usually understood as a locally acting process , which can be carried out independently for individual cells or groups of cells , respectively ( e.g. , individual photoreceptors @xcite vs. groups of photoreceptors@xcite ) . thus , adaptation refers to sensitivity adjustment of output signals as a function of input signals .",
    "+ normalization on the other hand usually refers to establishing standardized conditions for one or more qualities .",
    "for example , at some stage in the brain , the retinal image may have been normalized with respect to illumination conditions , such that each face or object is represented to have similar illumination patterns , and subsequent recognition stages work in a more robust fashion . or , once a face image has been detected by an artificial face recognition system , it can be normalized with respect to head tilt or head rotation . in this way a standardized candidate face is obtained , which facilitates matching it to other standardized faces from a database .",
    "+ normalization is also used for describing the establishment of standardized conditions for a population of neurons . in this context , normalization processes usually act as gain control mechanisms .",
    "for instance , grossberg @xcite proposed `` shunting competitive networks '' ( in his terms ) for accurate signal processing in the presence of noise to avoid the noise - saturation dilemma . because neurons have a fixed input range , weak signals get masked by noise , and neurons signal only the noisy fluctuations in the input signal . on the other hand , strong signals",
    "cause neurons to saturate , and any variations within the input can not be distinguished .",
    "shunting networks implement the multiplicative relationship between membrane voltages of neurons and conductance changes that are caused by network input on the one hand and signals on the other .",
    "this multiplicative relationship acts as a gain control mechanism that enables these networks to automatically re - tune their sensitivity in response to fluctuating background inputs . as grossberg demonstrated @xcite , such networks exhibit a normalization property in the sense that the total ( or pooled ) activity of all neurons is independent of the number of neurons . along these lines ,",
    "heeger and co - workers proposed a normalization model to account for the observed non - linearities with the cortical simple cell responses , such as response saturation and cross - orientation inhibition @xcite .",
    "similar to grossberg s `` shunting competitive networks '' , in heeger s model a neuron s output activity is adjusted by the pooled activity of a population of many other neurons ( `` normalization pool '' ) .",
    "this `` normalization pool '' exerts divisive inhibition on the response of a target neuron , and in this way it acts as a gain control mechanism for that cell . + the circuit models proposed by grossberg and heeger describe how responses of a group of neurons can be normalized .",
    "both methods rely on the interaction of some target neuron with a number of surrounding neurons .",
    "the interaction is brought about by hard - wiring the target neurons with surrounding neurons .",
    "in contrast , the normalization scheme introduced in this paper is based on diffusion mechanisms , and thus interactions only take place between adjacent cells .",
    "specifically , within the scope of the present paper , normalization is understood as mapping a set of numbers with finite but in principle arbitrary numerical range onto a fixed target range ( below we will see that non - trivial features like contrast enhancement and adaptation phenomena emerge from a network which implements this normalization mechanism ) .",
    "+ whereas in grossberg s scheme the normalization process renders the total activity of a group of cells independent of the number of cells ( @xcite ) , with my definition of normalization it is clear that in most cases the activity summed over all cells will depend on their number .",
    "a further difference concerns the implementation of activity bounds . in grossberg",
    "s scheme , reversal potentials establish an upper ( lower ) bound on the activity of each cell which can be reached by excitation ( inhibition ) .",
    "however , the highest activity value of the normalized cell population depends on the activity of all other cells ( as the total activity is constant ) . in other words",
    ", one can not rely on the presence of distinguished activity values as it is the case in my approach . in a normalized population of my approach",
    "there is always at least one cell which has zero activity , and at least one cell with activity one .",
    "+ the usual proceeding for normalizing a set of numbers can be subdivided into two successive stages . first , the maximum and the minimum members of the set are determined .",
    "these two values are then used in a second stage for re - scaling all set elements such that after re - scaling the elements fall into a pre - defined numerical interval ( or numerical range ) .",
    "+ if we wish to design a corresponding algorithm for the first stage of the just described process ( i.e. finding the maximum and the minimum ) , we would have to employ two memories for storing the _ current _",
    "( i.e. , a local ) maximum and minimum , and compare these values successively with all remaining set elements . after we finished with comparing",
    ", the memory would contain the _ global _ maximum and minimum . because every set member has to interact explicitly with the memories ,",
    "the whole process is said to involve global operations .",
    "the global nature is mirrored in the connection structure of a correspondingly designed network .",
    "( a ) shows a schematic drawing of such a network , where one distinguished network unit shares connections with all the others .",
    "this unit is supposed to represent the maximum ( or minimum ) activity value of the set of units to which it is connected to . due to its global connectivity",
    ", however , our network seems not to be a very plausible candidate for a `` biologically '' model , because ( biological ) neurons are known to interact in a more local fashion .",
    "this implausibility can be relaxed by proposing an alternative connectivity pattern ( ( b ) ) .",
    "+ nevertheless , the two units representing the maximum and the minimum , respectively , need to interact subsequently again with the input units , in order to put into effect the re - scaling operation that implements the gain control mechanism .",
    "this means that one would require yet another set of non - local connections , analogously to the pattern shown in .",
    "this led me to the question whether such normalization can be achieved in a more `` biological '' or local fashion , or even by employing only interactions between adjacent network units . presuming the existence of corresponding mechanisms",
    ", one has to explore in addition whether they could , in principle , be carried out by nerve cells in a biophysically plausible way .",
    "+ below i present a network ( the _ dynamical normalization network _ ) , which achieves normalization by means of lateral propagation of activity between adjacent network cells . to this end , parameterized diffusion operators were developed . in their limit cases ,",
    "these operators implement non - linear and non - conservative diffusion processes ( `` -diffusion '' ) .",
    "the dynamic of -diffusion proceeds from local to global in a continuous fashion , without utilizing any connectivity structure apart from coupling among nearest neighbors .",
    "+ the dynamic normalization network consists of a total of four layers : an input layer , two diffusion layers , and the normalization or output layer , where all layers interact .",
    "numerical simulations with luminance images revealed that the dynamic of the normalization layer is functionally more rich than just performing a re - scaling of its input .",
    "initially , the dynamic reveals contrast enhancement similar to high - pass filtering .",
    "+ furthermore , under certain conditions , an adaptation phenomenon ( `` dynamic compression '' ) can be observed in the initial phase of the dynamic .",
    "as it is described in detail below ( section [ section_dynamiccompression ] ) , the strength of the dynamic compression effect depends on the size of high activity regions in the input , and their relative positions with respect to other local maxima .",
    "the dynamic normalization network is based on nonlinear diffusion operators . in order to proof some of their properties ,",
    "it is necessary that the nonlinear diffusion operators are differentiable .",
    "accordingly , we define at first an operator @xmath0 $ ] which is parameterized over @xmath1 as where @xmath2 is a normalization constant that is defined as through the specific choice of @xmath1 , we can `` steer '' the operator @xmath0 $ ] continuously from linearity ( @xmath3 ) to half wave rectification ( i.e. selection of the maximum between zero and its argument ) or inverse half wave rectification ( i.e. selection of the minimum between zero and its argument ) notice that the operator satisfies @xmath4=-t_{+\\infty}[x]$ ] .      with the operator @xmath0 $ ] , one can define a general diffusion scheme which contains heat - diffusion as a special case for @xmath5 . to this end , consider , without loss of generality , the general form of a diffusion equation for a quantity @xmath6 ( here referred to as `` activity '' ) where @xmath7 is the diffusion coefficient .",
    "if @xmath8 depends on @xmath9 , then the last equation describes a nonlinear diffusion process , otherwise ordinary heat diffusion .",
    "consequently , by applying the operator @xmath0 $ ] on the gradients , the following _ -diffusion _ process is obtained ( which reduces to heat diffusion for @xmath5 ) : by defining @xmath10 and differencing we obtain if @xmath11 , the last equation reduces to the last equation looks in fact like an ordinary diffusion equation if we consider the factor @xmath12 / \\partial z$ ] as an `` effective diffusion coefficient '' .",
    "but which effect has the derivative @xmath13 / \\partial z$ ] ? in appendix [ proofone ]",
    "it is shown that it approximates a heaviside ( or step ) function @xmath14 for @xmath15 , that is in analogy to the previous case it can be shown that for a given cell , @xmath1 specifies the ratio between negative and positive influx into the cell from its neighbors .",
    "consider the case @xmath16 for a cell at position @xmath9 .",
    "if the activity of any adjacent cell is higher , then the gradient @xmath10 will be positive and an influx of activity to cell @xmath9 takes place , because in the -diffusion term @xmath17 is multiplied by one as a consequence of .",
    "also implies that any negative gradient at @xmath9 will make the -diffusion term be multiplied by zero , and thus prevents an influx of negative activity into cell @xmath9 .",
    "the essence of this mechanism is that activity at @xmath9 can only increase until any gradient has dissipated . as an alternative",
    ", this mechanism may be understood as an auto - adaptive diffusion constant which regulates its value according to the current gradient at @xmath9 ( ) . + for @xmath18 the mechanism works just vice versa , and the activity for a cell at position @xmath9 may only decrease . the linear ( or heat ) diffusion equation is obtained for @xmath5 , where both a positive - valued and a negative - valued influx can enter the cell .    * ( a ) *      intermediate values of @xmath1 attenuate either negative ( @xmath19 ) or positive influx ( @xmath20 ) .",
    "the amount of attenuation depends on @xmath1 . to illustrate , consider a simplified -diffusion system which consists only of two cells @xmath21 and @xmath22 : @xmath23 & = & \\mathcal{t}_{\\lambda}[v - u]\\\\      \\partialddt[v ] & = & \\mathcal{t}_{\\lambda}[u - v]\\nonumber\\end{aligned}\\ ] ] furthermore , we define the following _ surrogate _ system @xmath24 & = & \\gamma ( b - a)\\\\      \\partialddt[b ] & = & a - b \\nonumber\\end{aligned}\\ ] ] with a diffusion coefficient @xmath25 . note that",
    "because diffusion coefficients are different for @xmath26 and @xmath27 ( that is , @xmath25 and @xmath28 , respectively ) , the last equation implements a nonlinear diffusion system . without loss of generality , we assume @xmath19 , and @xmath29 at @xmath30 .",
    "furthermore , let both diffusion systems have the same initial conditions @xmath31 and @xmath32 . with this configuration of parameters ,",
    "the influx into cell @xmath33 is negative , and will be attenuated because of @xmath19 .",
    "dependent on the precise value of @xmath1 , the steady - state values of @xmath34 and @xmath35 will be situated somewhere between @xmath36 for @xmath5 , or @xmath37 for @xmath38 .",
    "now , to understand the behavior for @xmath39 , the diffusion coefficient @xmath25 is ( numerically ) determined such that both diffusion systems ( equations [ twocells ] and [ twocells_surrogate ] ) have the same equilibrium state , that is @xmath40 and @xmath41 ( and also @xmath42 ) .",
    "+ with the assumptions @xmath19 and @xmath29 , it follows that @xmath43 , because in order to obtain the same steady - state values for both diffusion systems , the negative influx into cell @xmath44 needs to be attenuated .",
    "_ a _ shows that in this case the effective diffusion coefficient @xmath25 and @xmath1 have a sigmoidal relationship .",
    "the sigmoid shifts to the left as a function of @xmath45 ( or equivalently @xmath46 ) . + _",
    "b _ shows that steady - state values as a function of @xmath1 also follow a sigmoidal relationship .",
    "cell values at convergence smoothly pass from heat diffusion ( @xmath47/2 $ ] for @xmath5 ) to implementing a maximum operation ( @xmath48 $ ] for @xmath49 ) .",
    "analogous considerations hold for negative values of @xmath1 .",
    "based on a centered finite difference representation of the laplacian operator , we define a parameterized diffusion operator acting on a function @xmath50 as where a grid spacing of @xmath51 is assumed .",
    "we will make use of the following compact notation and note that @xmath52 \\approx \\lap$ ] from .",
    "+ in order to formulate a spatially discrete -diffusion scheme , we consider a diffusion layer ( i.e. a finite grid on which diffusion takes place ) with an equal number @xmath53 of rows @xmath54 and columns @xmath55 , that is @xmath56 .",
    "we use a discrete - in - space and continuous - in - time notation , where @xmath57 , @xmath58 and so on @xcite . with the above definitions ,",
    "heat diffusion is described as : where @xmath59 is the diffusion coefficient .",
    "the process is assumed to start at time @xmath60 with the initial condition @xmath61 . from now on we assume that the @xmath62 represent an intensity or luminance distribution ( i.e. ,  @xmath63 represents a gray level image ) .",
    "since diffusion takes place in a bounded domain ( i.e. we have a finite number @xmath64 of grid points ) , and we also use adiabatic boundary conditions ( i.e. there is neither inward flux nor any flux outward over the domain boundary , i.e. @xmath65 for @xmath66 ) @xcite , the total activity described by does not depend on time ( ) , that is the last expression expresses that diffusion is conservative  activity is neither created nor destroyed . although the 2-d heat diffusion equation can not create new activity levels which have not already been present at time @xmath67 @xcite , it can create extrema in activity domains that have a dimension greater than one ( cf .",
    "@xcite , p.532 ) .",
    "a _ _ will eventually compute the minimum of all values and is defined as : a _ _ will eventually compute the maximum of all values and is defined as : we assume equal initial conditions @xmath68 for the and the at time @xmath60 .",
    "+ whereas preserves its total activity , the and , respectively , do not .",
    "the total activity of the decreases with time and converges to ( ) the total activity of the increases with time and converges to ( ) in other words , all cells @xmath69 of the will finally contain the global minimum of the input @xmath62 @xmath70 and all cells @xmath71 of the will end up with the global maximum @xmath72 this can be explained as follows .",
    "a cell @xmath69 of the may only _ decrease _ its activity from one time step to the next , until any activity gradient between @xmath69 and its nearest neighbors has dissipated . as a consequence",
    ", @xmath69 adopts the minimum activity value of the neighborhood , including itself .",
    "because the last arguments apply to _ all _ cells @xmath69 , eventually all cells will adopt the minimum activity @xmath73 at convergence .",
    "convergence occurs if @xmath74 ( i.e. when no more activity gradient exists ) .",
    "the dynamic of the process is illustrated by .",
    "+ in an analogous way , in the diffusion process described by the , all cells @xmath71 could only _ increase _ their activity , given the existence of any activity gradient .",
    "if any cell has a maximum activity value , then finally all cells will adopt this maximum , since only then all gradients have dissipated .",
    "+ hence , both nonlinear diffusion systems are non - conservative , because they do not fulfill requirements analogous to .",
    "equipped with the -diffusion operators defined in the last section , we are now ready to define the _ dynamic normalization _ network .",
    "the network normalizes a given input @xmath62 with respect to numerical range , but without taking resort to any global memory for determining the minimum and maximum .",
    "rather , the global minimum and maximum are computed in the and the , respectively , by only exchanging information between adjacent cells .",
    "+ we start with the following linear scaling scheme , which is typically used for normalizing a fixed set of numbers ( again , see introduction ) : because of and [ minmax ] the variable @xmath75 will contain ( after a sufficiently long time ) a normalized representation of @xmath62 , that is ( @xmath76 and @xmath77 are the global minimum and maximum , respectively , of @xmath78 ) .",
    "to arrive at a fully dynamical system , we formally interpret as the steady - state solution of which shall be called _ _ .",
    "notice that by using we naturally avoid the singularity of that occurs for @xmath79 .",
    "+    visualizes the state of at different time steps .",
    "initially , the process is similar to high - pass filtering ( ) , what can be explained as follows .",
    "contrasts are abrupt changes in luminance . consider a luminance change from dark to bright .",
    "then , the dark side has a local minimum , and the bright side a local maximum , which propagates in the and the , respectively ( ) . when the local minimum ( maximum ) has propagated to the position of the bright ( dark ) side of the step , then the bright ( dark ) side will be normalized to one ( zero ) . as the dynamic continues to evolve , local maxima and minima",
    "propagate further , thereby `` eating '' ( i.e. , annihilating ) other smaller local maxima and minima . in , this annihilation of local maxima and minima ,",
    "respectively , is visible through a gradual filling - in of image structures from the boundaries .",
    "a normalized version of the original image is finally obtained when @xmath80 .",
    "depending on _",
    "( i ) _ how small the @xmath81 are , and _",
    "( ii ) _ the choice of integration step size @xmath82 , the steady - state of @xmath83 can be reached with delay compared to the steady - states of @xmath84 and @xmath85 , respectively .",
    "this is now examined in more detail .    *",
    "( a ) *      shows the relationship between the time to convergence and the numerical range of the input @xmath62 : the smaller the @xmath62 , the more iterations are necessary to accomplish the mapping expressed by .",
    "mathematically , this can be seen as follows .",
    "assume that a general solution of has the form where @xmath86 and @xmath87 are constants which are defined by the initial conditions , and @xmath88 is a time constant . plugging the last equation into yields by identifying we obtain and from the initial condition @xmath89 we furthermore get @xmath90 , which finally gives the solution on grounds of the definition of @xmath88 ( ) we obtain two insights .",
    "+ first , since the time constant @xmath88 of the process is a function of both @xmath91 and @xmath92 , it is not really a constant , but rather depends on time and space because of and [ minmaxdiffmax ] , respectively .",
    "however , @xmath88 can be approximated by recalling that @xmath91 and @xmath92 converge in time and space to the global minimum @xmath76 and global maximum @xmath77 , respectively , of the input @xmath62 ( and [ minmax ] ) .",
    "thus , @xmath93 .",
    "this leads to the second insight : the smaller are @xmath76 and @xmath77 , the longer it takes to converge to a steady state . or",
    ", otherwise expressed , the smaller @xmath88 is , the faster the system converges . + notice that when using the steady - state solution ( ) of instead of the full dynamic process ( ) , no dependency on input contrast is revealed , and the dependence on spatial frequency structure of the input is much weaker .",
    "the layer reveals distinct dynamic phases . in the initial phase ,",
    "image contrasts are extracted .",
    "contrast enhancement occurs in a subsequent phase . in the final phase ,",
    "the activity distribution in the layer is just a re - scaled version of the input . in a second phase between the initial and the final phase",
    ", one observes adaptation : image structures with substantially different light intensities in the input are mapped to a smaller range of activities in the layer .",
    "this effect is the _ dynamic range compression_. for its illustration an input image was subdivided into four quadrants ( `` contrast tiles '' , ) .",
    "each of the tiles has a different range of luminance values . because the available tonal range for displaying the tiled image is too small to match the range of all tiles , some of the image details in the darker tiles are displayed in black",
    "nevertheless , a part of these details are rendered visible in the layer at around 100 iterations ( top row in ) , implying that cell activities in this layer have less dynamic range than in the input .",
    "the compression effect is quantized in , where each curve represent the mean activity and the maximum activity , respectively , of all cells of one the four tiles .",
    "the curves approach each other at around 100 iterations .",
    "thus , the output of the network can be encoded with a smaller than the original numerical range .",
    "+ illustrates the mechanism which underlies dynamic compression .",
    "a necessary condition for dynamic compression to occur is that the global maximum propagates with finite speed in the , and that it is spatially separated from image structures that have less dynamic range ( @xmath94 local maxima ) . when the global maxima has not yet propagated to the local maxima ,",
    "then image structures are normalized by their `` own '' local maxima .",
    "since normalization rescales all cell activities to the same target range ( all image structures normalize to one ) , local normalization implies a reduction of the dynamic range . however , local maxima are annihilated as the global maximum propagates , and image structures are now getting normalized by the global maximum .",
    "then , the entire dynamic range of the input image is recovered in the normalization layer , and dynamic range compression is abolished .",
    "the recovery of the original dynamic range can be seen when the entropy curves of ( b ) reduce to the entropy of the input image at @xmath95 iterations ( dashed horizontal line ) .    * ( a ) *      \\(b ) shows entropy as a function of time computed over the layer .",
    "the entropy reaches a maximum in the time window where dynamic compression occurs .",
    "notice that this maximum in entropy exceeds the entropy of the input image ( dashed horizontal line ) . because entropy quantifies the degree of flatness of a histogram ( or probability distribution )",
    ", the observed entropy maximum implies that cell activities of the layer are more homogeneously distributed across the histogram than luminance values of the input .",
    "shows how the distribution of activities evolve over time .",
    "initially , cell activities in the layer are small , and tend to cluster around a single spot in the histogram ( the cropped  hot spot  in the upper left corner of the histogram ) . emanating from this `` hot spot '' , values start to occupy nearly the entire histogram .",
    "it is just then when an observer who is monitoring the output of the network gathers the highest information about the input image .",
    "+ in the consecutive part of the dynamic , the values are redistributed again in a way that they concentrate around four principal stripes .",
    "these stripes correspond to the four contrast tiles .",
    "therefore , dynamic range compression is compatible with adaptation , since adaptation maximizes the transfer of information @xcite .",
    "when computing the shannon entropy of the output of the network @xcite , one observes an entropy maximum at the dynamic compression effect ( and [ dynamiccompressionhistogram ] ) .",
    "hence , a straightforward algorithm for the adaptation of images is to stop the process when an entropy maximum is reached ( `` one feedback loop '' ) . to further enhance the dynamic compression effect ,",
    "the output at the entropy maximum can be taken again as input to the network , and once again we can let the process continue until it reaches a maximum of entropy ( `` two feedback loops '' ) . the entropy across @xmath96 feedback loops of the just described algorithm is illustrated in with the curve designated by `` process entropy '' .",
    "shows the output images obtained for one , two , three and @xmath97 feedback loops . with increasing number of feedback loops ,",
    "luminance information is suppressed , while contrasts are enhanced . at around @xmath97 loops ,",
    "one obtains an image which seems to contain only contours , but iterating further enhances also noise and leaves one with an image without any recognizable structures . shows that entropy decreases with increasing number of feedback loops ( each data point is the entropy of the output at the indicated number of feedback loops ) . for the `` _",
    "_ tiled _ _ '' and the `` _ _ 4th power _",
    "_ '' image , the entropy versus feedback loops has a maximum .",
    "concluding , in terms of entropy , but also by visual inspection , a small number of feedback loops ( one or two ) seems optimal for the proposed adaptation algorithm .",
    "the algorithm should be understood as a `` proof - of - concept '' rather than a definite tool for image processing , because it occasionally develops artifacts .",
    "for example , future versions could address the suppression of the dark zone which emanates from the tiles of the `` _ _ tiled _ _ '' image .    * ( a ) *      one may argue that an adaptive mechanism designed in a way suggested by is highly sensitive to noise , because it is based on the computation of minimum and maximum operations . to address this issue",
    ", we further distinguish between static noise ( i.e. an offset added to the input @xmath62 which does not vary with time ) , and dynamic noise ( i.e. an offset added to each layer which varies with time ) .",
    "for the first case we presume the existence of a noise - free input pattern , to which static noise is added .",
    "a worst case scenario is on hand if a couple of cells @xmath62 have high activities due to noise ( `` noisy cells '' ) which lead to an undesired increase of the true dynamic range of the input .",
    "if a read - out mechanism for the layer had only the same dynamic range as the input , then the noise would obscure the relevant information of the input at convergence .",
    "nevertheless , if there were only a few noisy cells in the input layer , then the dynamic compression effect could mitigate the worst case scenario to some extent . + to assess the robustness of against temporally varying noise , numerical experiments were conducted with additive , normal - distributed noise ( `` gaussian noise '' ) , with zero mean and standard deviation @xmath98 .",
    "apart , additional simulations were conducted with multiplicative , uniform noise ( `` white noise '' ) .",
    "temporally fluctuating normal - distributed noise @xmath99 was added to the equations [ minmaxdiffmin ] , [ minmaxdiffmax ] , [ minmaxdynamicnorm ] , and the input @xmath62 , according to in the last equation , @xmath100 stands for one of the variables @xmath69 , @xmath71 , @xmath75 , and @xmath62 , respectively , and `` @xmath101 '' means that the left hand side is replaced by the right hand side .",
    "the noise level is specified by @xmath98 ( assuming zero mean ) , and @xmath99 is assumed to be not correlated across time and/or spatial positions . a luminance step ( 32 @xmath102 32 pixels )",
    "was used as input , with luminance value zero on the dark side ( `` black patch '' , columns 1 to 16 ) , and 1 on the bright side ( `` white patch '' , columns 17 to 32 ) .",
    "thus , the mean activity of the noise free system should approach one at steady - state .",
    "we furthermore computed the michelson contrast @xmath103 at each position @xmath104 according to where @xmath105 means @xmath106 and @xmath107 means @xmath108 ( the row index runs over all positions @xmath109 ) .",
    "+ ( a ) shows the temporal evolution of the mean activity of ( i.e. averaged over white patch positions ) for various noise levels @xmath98",
    ". sufficiently high noise levels significantly affect the convergence behavior of - the response plateau which is seen in the noise - free case is no longer reached . instead of the plateau ,",
    "a maximum is approached , the amplitude of which decreases with increasing noise level .",
    "( b ) shows that a similar behavior is also seen for the averaged michelson - contrast : the contrast between the black and the white patch decreases with increasing noise level .",
    "this implies that image structures are obscured by noise .",
    "+ how does noise take influence on dynamic range compression ?",
    "three answers exist to this question , and they depend on the noise level .",
    "for relatively small noise levels ( @xmath110 ) , no dramatic effect on dynamic compression is observed . for intermediate noise levels ( @xmath111 ) ,",
    "dynamic compression is enhanced ( bottom row in , and ) .",
    "enhancement happens because the net effect of noise is to add an offset , which `` lifts '' the darker patches of the tiled image . for higher noise levels , however , the darker patches drown in noise and image details get lost .",
    "consequently , if the goal of was adaptation , then suitable chosen noise levels would aid to enhance range compression , although this comes at the prize of reduced contrasts in regions with low activities ( dark quadrants in the tiled image ) .",
    "+ notice that additive gaussian noise can be easily counteracted by proposing additional mechanisms with low - pass characteristics , like spatial or temporal pooling of activity .",
    "then , as long as the noise is not correlated over positions and time , it would simply average out .",
    "multiplicative noise was applied to variables @xmath69 , @xmath71 , @xmath75 , and @xmath62 , respectively , according to with @xmath112 representing uniformly distributed noise which was uncorrelated across time and/or space .",
    "the noise level is specified by @xmath113 $ ] .",
    "is not significantly affected by this type of noise , not even for @xmath114 ( hence results are not shown ) . multiplicative noise acts differently on maxima and minima .",
    "maximum activities can only decrease , but never increase beyond their value in the noise free case .",
    "therefore , no spurious maxima are introduced into the by the type of multiplicative noise considered here . on the other hand",
    ", multiplicative noise can inject spurious minima into the , if the lowest luminance value in the input image was bigger than zero .",
    "as the minimum luminance values of our images were always zero , they are consequently not affected by the multiplicative noise .",
    "the operator @xmath115 $ ] models different types of electrical synapses ( gap junctions ) . in its linear version , @xmath52 $ ] describes the exchange of both depolarizing ( i.e. directed towards a neuron s firing threshold ) and hyperpolarizing ( i.e. directed away from a neuron s firing threshold ) currents between adjacent neurons .",
    "networks of electrically coupled neurons are ubiquitous both in the retina ( e.g. @xcite ) and the cortex ( e.g. @xcite ) .",
    "these networks can be modeled by diffusion equations ( e.g. @xcite ) .",
    "conversely , the operators defined by and [ minmaxcompactneg ] represent models for rectifying ( i.e. voltage sensitive ) gap - junctions . rectifying gap junctions",
    "were described in the crayfish ( e.g. @xcite ) , and unidirectional and gated gap junctions were reported in the rat ( e.g. @xcite ) and turtle ( e.g. @xcite ) , respectively .",
    "+ in organisms , rectifying gap junctions may nevertheless be implemented in a `` dirty '' fashion .",
    "this means that a current flux may not strictly occur in only one direction .",
    "rather , a small amount of current may as well flow in the opposite direction . such behavior is captured by setting @xmath1 to a finite value @xmath116 , and was analyzed in .",
    "substitution of two global memories ( for the minimum and the maximum activity ) by two -diffusion layers of size @xmath64 leads to a computationally more demanding system , because more memory resources are needed and significantly more computational operations need to be carried out for their simulation .",
    "moreover , because computation of the global maximum or minimum is based on local , diffusion - like interactions , a maximum or a minimum does not propagate from one cell to another from one time step to the next .",
    "the diffusion rate can not be chosen arbitrarily high to guarantee the numerical stability of the process . the time to convergence",
    "does not only depend on the -diffusion layers reaching a steady - state , but is mainly determined by the layer . the number of iterations that is needed until convergence occurs scales with the numerical range of the input .",
    "thus , for small input values , the number of required iterations can be quite large ( see ) .",
    "therefore , the network can not be seriously considered as an alternative to an ordinary normalization algorithm ( i.e. , searching the global maximum and minimum , and then rescaling ) .",
    "however , the network can accomplish different tasks which can not be accomplished with an ordinary normalization algorithm , for example detection of contrast contours , or compression of the dynamic range of the input .",
    "this paper introduced a parameterized diffusion operator ( parameter @xmath1 ) and analyzed some of its properties mathematically and by computer simulations .",
    "as a special case , heat diffusion is obtained for @xmath5 .",
    "diffusion layers which are based on the two limit cases of the operator ( for @xmath117 ) compute the global maximum and minimum , respectively , of the initial cell activities of the layer .",
    "this means that at convergence , all cells of the diffusion layers contain the same activity value  the maximum ( @xmath118 ) or the minimum ( @xmath119 ) .",
    "based on these operators , a network was defined ( ) .",
    "its steady - state solution is functionally equivalent to the ordinary rescaling of a set of numbers ( ) , but by making the normalization process dynamic , one observes two additional properties : contrast enhancement and dynamic range compression .",
    "both effects occur because at first normalization acts locally , similar to adaptation mechanisms . with increasing time , the normalization process gets continuously more global , until a steady - state is reached .",
    "the steady - state corresponds to a rescaling of the input in the layer .",
    "+ by exploiting the dynamic compression effect , it should thus be possible to design a powerful adaptation mechanism which maps an input image of an arbitrary numerical range to a smaller target range .",
    "to do so , the normalization process has to be `` frozen '' when dynamic compression occurs . as a first step into that direction ,",
    "a simple adaptation algorithm based on the maximisation of entropy was proposed ( ): the dynamic is frozen as soon as a maximum of entropy is reached , and the output is then fed back as new input to the network . as a further improvement , the diffusion operators could be modified such that activity exchange between two cells is blocked for sufficiently large activity gradients @xcite .",
    "doing so would possibly prevent in ( first and second row ) the global maximum from spreading between tiles , and would normalize each tile independently , such that ideally a dynamic similar to the bottom row in is produced .",
    "+ systems based on -diffusion have already turned out to be of utility for a variety of purposes in image processing ( for implementing filling - in mechanisms , or winner - takes all inhibition , see @xcite ) .",
    "-diffusion systems can generally be used for implementing the max - operation without the need for globally acting pooling units ( see for example @xcite and @xcite ) .",
    "the advantage over functionally equivalent but hardwired systems is that the region where normalization takes place can be dynamically adjusted .",
    "furthermore , the maximum operation serves to implement invariance properties in models for object recognition ( e.g. @xcite ) .",
    "this work was supported by the _",
    "juan de la cierva _ program of the spanish government , and the the mcyt grant sej 2006 - 15095 .",
    "further support was provided by the amovip inco - dc 961646 grant from the european community .",
    "the author likes to thank the anonymous reviewer of _ physica d _ for his valuable suggestions which helped to improve the manuscript ( the present version is the long version ; a shorter version is to be published in _ physica d _ ) .",
    "all simulations were carried out using the matlab environment ( r2006b ) on a linux workstation , where both native matlab code and mex - files programmed in c++ were used .",
    "diffusion operators were normalized by the number of adjacent cells ( normally four , along the domain boundaries three , and in the corners two ) . normally , the equations describing the diffusion layers ( eqs .",
    "[ minmaxdiffmin ] and [ minmaxdiffmax ] ) , and ( eq . [ minmaxdynamicnorm ] ) turned out to be numerically stable such that a forward - time - centered - space ( ftcs ) euler scheme with step size one is sufficient .",
    "( here , we understand numerical stability such that the solution converges rather than growing in an unbounded fashion ) .",
    "notice , however , the stability criterion associated with the ftcs - integration of the heat diffusion equation @xmath120 ( assuming grid spacing one , see section 19.2 in @xcite ) where @xmath121 is the diffusion coefficient , and @xmath82 is the integration step size . since we compared -diffusion with laplacian or heat diffusion ( eq . [ minmaxdiffmean ] ) , by default we employed euler s method with integration step size @xmath122 and diffusion coefficient @xmath123 .",
    "exceptions are as follows .",
    "was simulated with @xmath124 and @xmath125 , respectively .",
    ", [ minmaxchesscontrast ] , and figures [ dnepepperstiles ] to [ dynamiccompressionnoise ] were integrated with the fourth - order runge - kutta method ( @xmath122 , @xmath123 ) .",
    "for the compilation of , again the forth - order runge - kutta method was used with @xmath126 and @xmath127 , to guarantee numerical stability in the presence of high noise levels .",
    "+ it should be emphasized that the results presented in this paper do not depend critically on the exact value of neither @xmath82 and @xmath121 , nor on the specific choice of the integration method .",
    "variation of these parameters leads to a corresponding rescaling of the time axis . although we exemplified the behavior of the model only by means of two standard images which are commonly used for image processing ( and ) , all characteristics of the model can as well be reproduced with other images .",
    "consider the derivative of the operator @xmath0 $ ] ( ) , where the following three cases have to be analyzed :    case @xmath5 .",
    ": :    in this case @xmath128 from , and thus , for    @xmath5 the derivative is constant one for all    @xmath129 , and reduces to the linear diffusion .",
    "case @xmath38 .",
    ": :    in this case @xmath114 from , and we have to consider three    additional cases according to the value of @xmath129 .",
    "note that    @xmath129 is treated as a constant . hence ,    +",
    "; ;      this is to say that if the gradient @xmath129 vanishes , then      the derivative is constant with value @xmath130 .",
    "; ;      we start with evaluating _",
    "term i _ of , in the numerator of _ term ii _      appears a product of the kind `` @xmath131 '' .",
    "one      may argue that the exponential @xmath132      always approaches zero much more faster than the term      @xmath133 is able grow ( or one may equivalently      apply lhospital s rule to this product by applying      @xmath134 on each factor ) ,      +      thus , for @xmath15 evaluates to 1 for all      @xmath135 .",
    "; ;      evaluating _",
    "term i _ , evaluating _ term ii _",
    "( again there is a little      more work to do ) ,      +      hence , for @xmath15 evaluates to 0 for all      @xmath136 .",
    "+    +    @xmath137 +"
  ],
  "abstract_text": [
    "<S> here , i present a novel method for normalizing a finite set of numbers , which is studied by the domain of biological vision . </S>",
    "<S> normalizing in this context means searching the maximum and minimum number in a set and then rescaling all numbers such that they fit into a numerical interval . </S>",
    "<S> my method computes the minimum and maximum number by two pseudo - diffusion processes in separate diffusion layers . </S>",
    "<S> activity of these layers feed into a third layer for performing the rescaling operation . </S>",
    "<S> the dynamic of the network is richer than merely performing a rescaling of its input , and reveals phenomena like contrast detection , contrast enhancement , and a transient compression of the numerical range of the input . </S>",
    "<S> apart from presenting computer simulations , some properties of the diffusion operators and the network are analyzed mathematically . </S>",
    "<S> furthermore , a method is proposed for to freeze the model s state when adaptation is observed . </S>"
  ]
}