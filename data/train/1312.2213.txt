{
  "article_text": [
    "we are grateful for support from the sfb / trr 102 ( project b04 ) , the leipzig graduate school of excellence gsc185 `` buildmona '' and the deutsch - franzsische hochschule ( dfh - ufa ) under grant no .",
    "cdfa-02 - 07 .",
    "j.z . and m.m .",
    "were funded by the european union and the free state of saxony .",
    "10 b.  a. berg , t. neuhaus , phys .",
    "b 267 ( 1991 ) 249 ; + b.  a. berg , t. neuhaus , phys .",
    "68 ( 1992 ) 9 . w. janke , int . j. mod",
    "c3 ( 1992 ) 1137 ; + w. janke , physica a 254 ( 1998 ) 164 .",
    "f. wang , d.  p. landau , phys .",
    "86 ( 2001 ) 2050 ; + f. wang , d.  p. landau , phys .",
    "e 64 ( 2001 ) 056101 .",
    "w. janke ( ed . ) , rugged free - energy landscapes , lect .",
    "notes phys . 736 ( 2008 )",
    "203 ; + a. mitsutake , y. sugita , y. okamoto , biopolymers ( peptide science ) 60 ( 2001 ) 96 .",
    "l. zhan , comput .",
    "( 2008 ) 339 .",
    "j. yin , d.  p. landau , comput .",
    "( 2012 ) 1568 .",
    "v. v. slavin , low temp .",
    "36 ( 2010 ) 243 ; + a. ghazisaeidi , f. vacondio , l.  a. rusch , j. lightwave technol . 28 ( 2010 ) 79 .",
    "j. zierenberg , m. marenz , w. janke , comput .",
    "( 2013 ) 1155 .",
    "w. janke , b.  a. berg , m. katoot , nucl .",
    "b 382 ( 1992 ) 649 .",
    "a. milchev , a. bhattacharaya , k. binder , macromolecules 34 ( 2001 ) 1881 ; + s. schnabel , m. bachmann , w. janke , j. chem .",
    "( 2009 ) 124904 ."
  ],
  "abstract_text": [
    "<S> we implemented a parallel version of the multicanonical algorithm and applied it to a variety of systems with phase transitions of first and second order . </S>",
    "<S> the parallelization relies on independent equilibrium simulations that only communicate when the multicanonical weight function is updated . </S>",
    "<S> that way , the markov chains efficiently sample the temporary distributions allowing for good estimations of consecutive weight functions .    </S>",
    "<S> the systems investigated range from the well known ising and potts spin systems to bead - spring polymers . </S>",
    "<S> we estimate the speedup with increasing number of parallel processes . </S>",
    "<S> overall , the parallelization is shown to scale quite well . in the case of multicanonical simulations of the @xmath0-state potts model ( @xmath1 ) and multimagnetic simulations of the ising model , the optimal performance </S>",
    "<S> is limited due to emerging barriers .    </S>",
    "<S> multicanonical simulations , parallel implementation , ising , potts , bead - spring polymer    umbrella sampling algorithms like the multicanonical method  @xcite and the wang - landau method  @xcite have been applied to a variety of complex systems over the last two decades . </S>",
    "<S> they are well suited for the investigation of phase transitions , especially of first order and may be applied to systems with rugged free - energy landscapes in physics , biology , and chemistry  @xcite .    for complex systems , </S>",
    "<S> a carefully chosen set of monte carlo update moves is usually the key to a successful simulation . but with computer performance increasing mainly in terms of parallel processing on multi - core architectures , it is of advantage when the algorithm can be parallelized . </S>",
    "<S> this has been done recently for the wang - landau recursion  @xcite and for the standard multicanonical recursion  @xcite . while the former implementation relies on shared memory , introducing racing conditions and frequent communication , the latter benefits from independent markov chains with occasional communication .    </S>",
    "<S> after a short summary of the parallel multicanonical method , we will proceed with a demonstration of its performance for several spin systems and a flexible polymer .    </S>",
    "<S> the multicanonical ( muca ) method can be applied to a variety of ensembles . </S>",
    "<S> still , it is probably easiest to understand using the example of the canonical ensemble . for a fixed temperature , all configurations that the system may assume are weighted with the boltzmann weight @xmath2 $ ] , resulting in a temperature dependent energy distribution </S>",
    "<S> the idea is to replace this boltzmann weight by an arbitrary weight function @xmath3 , which may be modified iteratively such that the resulting energy distribution covers the full range of canonical distributions , hence it is called multicanonical . in terms of the partition function , this may be written as @xmath4 where @xmath5 is the density of states . </S>",
    "<S> the canonical distributions and expectation values are recovered by reweighting : @xmath6 the most difficult task is the weight modification , which requires some effort . </S>",
    "<S> the easiest way is to construct consecutive weights from the last weights and the current energy histogram : @xmath7 . </S>",
    "<S> more sophisticated methods use the full statistics of previous iterations for a stable and efficient approximation of the density of states  @xcite . </S>",
    "<S> all our simulations use the latter version implemented with logarithmic weights in order to avoid numerical problems .    the basic idea of the parallel implementation </S>",
    "<S> is shown in fig .  </S>",
    "<S> [ fig : pmuca ] . </S>",
    "<S> the system is initialized in @xmath8 independent realizations with the same weight function , which are distributed onto different cores . after each iteration , </S>",
    "<S> the individual histograms are merged and provide an estimate of the distribution @xmath9 belonging to the current weight function @xmath10 . </S>",
    "<S> this is used to determine the consecutive weight function @xmath11 , which is again distributed to all @xmath8 cores . </S>",
    "<S> the whole procedure is repeated until the weight function results in a flat energy distribution . since the weight modification is usually very fast compared to a single iteration , communication is kept to a bare minimum </S>",
    "<S> .     cores . after each iteration with independent markov chains </S>",
    "<S> ( but identical weights ) , the histograms are merged , the new weights are estimated and distributed to all processes again . , width=340 ]    moreover , the parallelization may easily be applied to other ensembles , for example multimagnetic ( muma ) simulations . in this case , the coefficients of the partition function are modified by a correction weight function , which depends for example on the magnetization and is again modified iteratively in order to yield a flat histogram in the parameter : @xmath12 the parallelization is completely analogous to the standard case and the performance of the parallel multimagnetic simulation will be demonstrated below .    for a fair comparison of the performance of this parallel implementation , we need to consider a few aspects . </S>",
    "<S> first of all , the parallelization relies on independent markov processes , which leads to different simulations for different degrees of parallelization . </S>",
    "<S> consequently , we may only compare the average performance per degree of parallelization . </S>",
    "<S> furthermore , a number of parameters can influence the results and need to be fixed . </S>",
    "<S> one example is the number of sweeps per iteration . in order to provide a proper estimate of the performance </S>",
    "<S> , we determined the optimal number of sweeps per iteration @xmath13 for all degrees of parallelization in the cases of the ising model and the @xmath14-state potts model . </S>",
    "<S> a detailed description can be found in @xcite . </S>",
    "<S> the results of this analysis are @xmath15 we extrapolated this result for the remaining spin systems . </S>",
    "<S> another factor to consider is the thermalization time . in order to remove additional parameters in our investigation </S>",
    "<S> , we decided to thermalize only in the beginning and not in between iterations .    </S>",
    "<S> since the parallelization changes the outcome of the simulation , also the number of iterations until convergence is influenced . </S>",
    "<S> this allows us to consider two different measures of the performance . </S>",
    "<S> one is given by the speedup in convergence time , comparing the time @xmath16 a @xmath8-core simulation needs until convergence of the muca weights with the time @xmath17 a single - core simulation needs : @xmath18 obviously , this answers the question of required simulation time with increasing parallelization but depends strongly on the involved hardware . </S>",
    "<S> thus , the result may differ if investigated on different compute clusters . </S>",
    "<S> another possibility is to consider a time - independent statistical speedup by comparing the total number of sweeps per core until convergence . </S>",
    "<S> as the optimal number of sweeps per iteration @xmath19 is fixed for all realizations , this results in measuring the average number of iterations until convergence @xmath20 . </S>",
    "<S> @xmath21_{1 } } { [ \\bar{n}_{\\rm iter } m_{\\rm opt}(p)]_{p}},\\ ] ] in the following , we will use the ising model to demonstrate the differences . </S>",
    "<S> afterwards we will restrict ourselves to the time - independent statistical speedup for simplicity .    </S>",
    "<S> we consider the two - dimensional ising system as a first test case . </S>",
    "<S> this spin model with nearest - neighbor interaction exhibits a temperature driven second - order phase transition . </S>",
    "<S> the hamiltonian is defined as @xmath22 . </S>",
    "<S> figure [ fig : ising ] shows the performance of the method . </S>",
    "<S> it can be seen that the statistical speedup scales nicely for all system sizes , in fact @xmath23 . </S>",
    "<S> this means that the total statistics is efficiently distributed onto all cores . </S>",
    "<S> the time speedup also scales well , except for the small system sizes where the duration of a single iteration was of the order of milliseconds for which our network communication is insufficient .         </S>",
    "<S> the two - dimensional @xmath0-state potts model is described by @xmath24 , where @xmath25 and interaction is restricted to nearest neighbors . </S>",
    "<S> the system shows a temperature driven first - order phase transition for @xmath26 and a second - order phase transition otherwise . </S>",
    "<S> applying the parallel multicanonical method to the potts model demonstrates its effect on systems with first - order phase transitions . </S>",
    "<S> indeed , also in this case the parallelization works well , but with increasing degree of parallelization the speedup seems to saturate ( see fig .  </S>",
    "<S> [ fig : spinsystems ] ) . </S>",
    "<S> a similar effect is observed when applying the parallelization to a multimagnetic simulation of the ising system , also shown in the figure . in this case , the ising system is simulated at fixed temperature @xmath27 , while it is attempted to achieve a flat distribution of the magnetization . </S>",
    "<S> the occurring field - driven phase transition is of first order . </S>",
    "<S> the saturation of the speedup may be explained by large integrated autocorrelation times accompanying concealed barriers . </S>",
    "<S> thus , when reducing the number of sweeps per core with increasing degree of parallelization this might reach a point where the individual sweeps are too short in order to efficiently cross emerging concealed barriers . for a detailed description </S>",
    "<S> we refer to @xcite .        </S>",
    "<S> the @xmath0-state potts model is furthermore well suited to take a look at the performance of the parallelization in the crossover regime from a second - order phase transition to a first - order phase transition . to this end , </S>",
    "<S> we considered extrapolated @xmath13 for different @xmath0 values . </S>",
    "<S> the result is shown in fig .  </S>",
    "<S> [ fig : qpotts ] . for @xmath28 </S>",
    "<S> the temperature - driven phase transition is of second - order and the scaling of the performance is very well . </S>",
    "<S> this still holds for @xmath29 where a so - called weak first - order phase transition occurs . </S>",
    "<S> already for @xmath30 , we can see the drop in performance for large degrees of parallelization , as before .    </S>",
    "<S> -state potts models on a @xmath31 square lattice . for @xmath28 </S>",
    "<S> the potts model exhibits a second - order phase transition , while for @xmath32 the phase transition becomes first order . ]    leaving the constraint of a lattice , we applied the parallel multicanonical method to a more complex system , a single flexible bead - spring polymer . </S>",
    "<S> it consists of @xmath33 identical monomers , which are connected to their bonded neighbors by a fene spring potential and which interact with other monomers via a lennard - jones potential . </S>",
    "<S> the hamiltonian is given by @xmath34 ^ 2\\right),\\ ] ] where @xmath35 is the average bond length , @xmath36 , @xmath37 , and @xmath38 is the spring constant . the parameters where chosen @xmath39 , @xmath40 , and @xmath41 according to @xcite . </S>",
    "<S> as mentioned above , the choice of updates is crucial . </S>",
    "<S> here , we used a combination of single monomer shift , spherical rotation , and double - bridging moves . using the example of a polymer system , we want to show the general applicability of the parallel multicanonical method </S>",
    "<S> thus , we took an existing code of a multicanonical simulation with a fixed number of sweeps per iteration and some thermalization between iterations . </S>",
    "<S> the total number of sweeps per iteration was distributed onto the cores . while we considered the full energy range for the spin systems , we restricted the multicanonical simulation of the homo - polymer to an energy range around the collapse transition . figure [ fig : polymer ] shows that the straightforward parallelization works also well for complex off - lattice systems , which involve computationally more expensive energy calculations . </S>",
    "<S> moreover , this shows that the parallelization may be applied straightforwardly without taking too much care about the involved parameters .    . </S>",
    "<S> ]    in summary , the application of the parallel multicanonical method presented here is straightforward and very efficient for a range of systems . </S>",
    "<S> we studied the performance on the example of the ising model , the @xmath0-state potts model and a coarse - grained polymer model . furthermore </S>",
    "<S> , we showed that the parallelization may easily be adapted to flat histogram simulations in other ensembles . </S>",
    "<S> overall , we could demonstrate a good performance yielding a close - to - perfect scaling @xmath23 for up to @xmath42 cores . </S>"
  ]
}