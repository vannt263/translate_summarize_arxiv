{
  "article_text": [
    "deep learning has achieved great success in many areas  @xcite@xcite@xcite . for problems related to sequential data such as audio , video and text ,",
    "significant improvements have been achieved by gated recurrent neural networks ( grnn ) , in which the hidden neurons form a directed cycle suitable for processing sequential data  @xcite@xcite@xcite@xcite .",
    "in addition to taking the neural network outputs to be used in the target applications , internal signals within the neural networks were also found useful .",
    "a good example is the bottleneck features  @xcite@xcite .",
    "on the other hand , in the era of big data , huge quantities of unlabeled speech data are available but difficult to annotate , and unsupervised approaches to effectively extract useful information out of such unlabeled data are highly attractive  @xcite@xcite .",
    "autoencoder structures have been used for extracting bottleneck features  @xcite , while grnn with various structures can be learned very well without labeled data .",
    "as one example , the outputs of grnn learned in an unsupervised fashion have been shown to carry phoneme boundary information and used in phoneme segmentation  @xcite@xcite .    in this paper , we try to analyze the gate activation signals ( gas ) in grnn , which are internal signals within such networks .",
    "we found such signals have temporal structures highly related to the phoneme boundaries , which was further verified by phoneme segmentation experiments .",
    "recurrent neural networks ( rnn ) are neural networks whose hidden neurons form a directed cycle . given a sequence * x * = ( @xmath0 , @xmath1 , ... ,",
    "@xmath2 ) , rnn updates its hidden state @xmath3 at time index @xmath4 according to the current input @xmath5 and the previous hidden state @xmath6 .",
    "gated recurrent neural networks ( grnn ) achieved better performance than rnn by introducing * gates * in the units to control the information flow .",
    "two popularly used gated units are lstm and gru  @xcite@xcite .    the signals within an lstm recurrent unit are formulated as : @xmath7 @xmath8 @xmath9 @xmath10 @xmath11 @xmath12 where @xmath13 , @xmath14 , @xmath15 , @xmath16 , @xmath17 and @xmath18 are the signals over the forget gate , input gate , output gate , cell state , candidate cell state and hidden state at time @xmath4 , respectively ; @xmath19 and @xmath20 are the sigmoid and hyperbolic tangent activation functions respectively ; @xmath21 and @xmath22 are the weight matrices and @xmath23 are the biases .",
    "the gru modulates the information flow inside the unit without a memory cell ,    @xmath24    @xmath25    @xmath26    @xmath27    where @xmath28 , @xmath29 , @xmath18 and @xmath30 are the signals over the update gate , reset gate , hidden state and candidate hidden state at time @xmath4 , respectively ; @xmath31 means element - wise product  @xcite .    here",
    "we wish to analyze the gate activations computed in equations ( [ eq : f ] ) , ( [ eq : i ] ) , ( [ eq : o ] ) , ( [ eq : u ] ) , ( [ eq : r ] )  @xcite and consider their temporal structures . for a grnn layer consisting of @xmath32 gated units ,",
    "we view the activations for a specific gate at time step @xmath4 as a vector @xmath33 with dimensionality @xmath32 , called _ gate activation signals _ ( gas ) . here",
    "@xmath33 can be @xmath3 , @xmath34 , @xmath35 , @xmath36 or @xmath37 above . figure  [ fig : gas ] is the schematic plot showing how gas may imply for a gate in an gated unit .",
    "autoencoders can be trained in an unsupervised way , and have been shown to be very useful for many applications  @xcite .",
    "we can have an autoencoder with grnn as in figure  [ fig : ae_grnn_fig ] called ae - grnn here .",
    "given an input utterance represented by its acoustic feature sequence @xmath38 , at each time step @xmath4 , ae - grnn takes the input vector @xmath5 , and produces the output @xmath39 , the reconstruction of @xmath5 . due to the recurrent structure , to generate @xmath39 , ae - grnn actually considers all information up to @xmath5 in the sequence , @xmath40 , or @xmath41 ) .",
    "the loss function @xmath42 of ae - grnn in ( [ eq : ae_loss_eq ] ) is the averaged squared @xmath43 - 2 norm for the reconstruction error of @xmath5 .",
    "@xmath44    where the superscript @xmath45 indicates the @xmath45-th training utterance with length @xmath46 , and @xmath47 is the number of utterances used in training .",
    "@xmath48 indicates the number of dimensions of @xmath49 .",
    "we conducted our initial experiments on timit , including 4620 training utterances and 1680 testing utterances .",
    "the ground truth phoneme boundaries provided in timit are used here .",
    "we train models on the training utterances , and perform analysis on the testing ones .    in the ae - grnn",
    "tested , both the encoder and the decoder consisted of a recurrent layer and a feed - forward layer .",
    "the recurrent layers consisted of 32 recurrent units , while the feed - forward layers consisted of 64 neurons .",
    "we used relu as the activation function for the feed - forward layers  @xcite .",
    "the dropout rate was set to be 0.3  @xcite .",
    "the networks were trained with adam  @xcite .",
    "the acoustic features used were the mfccs of 39-dim with utterance - wise cepstral mean and variance normalization ( cmvn ) applied .",
    "figure  [ fig : gas_frame ] shows the means of the gate activation signals over all gated units in the encoder of ae - grnn with respect to the frame index , taken from an example utterance .",
    "the upper three subfigures ( a)(b)(c ) are for lstm gates , while the lower two ( d)(e ) for gru gates .",
    "the temporal variations of gru gates are similar to the forget gate of lstm to some degree , and looks like the negative of the input gate of lstm except for a level shift .",
    "more importantly , when compared with the phoneme boundaries shown as the blue dashed lines , a very strong correlation can be found . in other words ,",
    "whenever the signal switches from a phoneme to the next across the phoneme boundary , the changes in signal characteristics are reflected in the gate activation signals .",
    "this is consistent to the previous finding that the sudden bursts of gate activations indicated that there were boundaries of phonemes in a speech synthesis task  @xcite .          with the above observations , we define difference gas as follows . for a gas vector at time index @xmath4 , @xmath33 , we compute its mean over all units to get a real value @xmath50 .",
    "we can then compute the difference gas as the following : @xmath51 the difference gas can also be evaluated for each individual gated unit for each dimension of the vector @xmath33 , @xmath52 where @xmath53 is the @xmath54-th component of the vector @xmath33 .",
    "we plotted the difference gas and the individual difference gas for the first 8 units in a grnn over the frame index for an example utterance as in figure  [ fig : individual_gas ] .",
    "we see those differences bear even stronger correlation with phoneme boundaries shown by vertical dashed lines .",
    "all these results are consistent with the finding that the gate activations of forget gate over recurrent lstm units in the same layer have close correlation with phoneme boundaries in speech synthesis  @xcite , although here the experiments were performed with ae - grnn .     for forget gate of lstm for an example utterance over frame index .",
    "subfigure ( b ) shows the plots of @xmath55 with different colors ( only shows @xmath56 to @xmath57 for clarity ) .",
    "the blue dashed lines indicate phone boundaries . ]",
    "because the gas was found to be closely related to phoneme boundaries , we tried to use these signals to perform phoneme segmentation .",
    "the segmentation accuracy can be a good indicator to show the degree of the correlation between gas and phoneme boundaries . in this section",
    ", we will first describe recurrent predictor model ( rpm ) , an unsupervised phoneme segmentation approach , which servers as the baseline .",
    "then we will describe how to use gas in phoneme segmentation .",
    "rpm was proposed earlier to train grnn without labeled data , and it was found the discontinuity on model outputs have to do with phoneme boundaries  @xcite@xcite .",
    "an rpm has only the lower half of figure  [ fig : ae_grnn_fig ] .",
    "the model output at time @xmath4 , @xmath58 , is to predict the next input @xmath59 .",
    "the loss function @xmath42 used in training rpm is the averaged squared @xmath43 - 2 norm of prediction error ,    @xmath60    which is actually parallel to ( [ eq : ae_loss_eq ] ) .",
    "the superscript @xmath45 indicates the @xmath45-th training utterance and @xmath48 indicates the number of dimensions of @xmath49 .",
    "because frames which are difficult to predict or with significantly larger errors are likely to be phoneme boundaries , the error signals @xmath61 of rpm , @xmath62 can be used to predict the phoneme boundary similar to gas here .",
    "a time index is taken as a phoneme boundary if @xmath61 is a local maximum , that is @xmath63 and @xmath64 , and @xmath61 exceeds a selected threshold .      from figure",
    "[ fig : individual_gas ] , a direct approach to use gas for phoneme segmentation is to take a time index as a phoneme boundary if @xmath65 is a local maximum , that is @xmath66 and @xmath67 , and @xmath65 exceeds a selected threshold .",
    "gas can also be integrated with rpm .",
    "since rpm also includes grnn within its structure , gas can also be obtained and interpolated with the error signals obtained in ( [ eq : error_signal_eq ] ) as in ( [ eq : interpolated_eq ] ) , where @xmath68 is the weight .",
    "a time index is taken as a phoneme boundary if @xmath69 is a local maximum and exceeds a selected threshold . @xmath70",
    "here we take phoneme segmentation accuracy as an indicator to show the correlation between gas and phoneme boundaries .",
    "the setup is the same as in section 3.1 . in the segmentation experiments ,",
    "a 20-ms tolerance window is used for evaluation .",
    "all gas were obtained from the first recurrent layer .",
    "different segmentation results were obtained according to different thresholds , we report the best results in the following tables .",
    "it is well - known that the f1-score is not suitable for segmentation , because over segmentation may give very high recall leading to high f1-score , even with a relatively low precision@xcite . in our preliminary experiments , a periodic predictor which predicted a boundary for every 40 ms gave f1-score 71.07 with precision 55.13 and recall 99.99 , which did nt look reasonable .",
    "it has been shown that a better evaluation metric is the r - value  @xcite , which properly penalized the over segmentation phenomenon .",
    "the approach proposed in a previous work  @xcite achieved an r - value 76.0 , while the 40-ms periodic predictor only achieved 30.53 .",
    "therefore , we chose to use r - value on the performance measure .",
    "the r - values using different gates of lstm and gru are shown in table  [ table : gates_exp ] .",
    "the results for lstm gates are consistent with the findings in the previous works  @xcite@xcite . in lstm",
    ", the forget gate clearly captures the temporal structure most related to phoneme boundaries .",
    "gru outperformed lstm which is also consistent with earlier results  @xcite@xcite .",
    "the highest r - value is obtained with the update gate of gru .",
    "the update gate in gru is similar to the forget gate in lstm .",
    "both of them control whether the memory units should be overwritten .",
    "interestingly , the reset gate of gru achieved an r - value significantly higher than the corresponding input gate in lstm .",
    "the reason is probably the location of reset gate . in gru",
    ", the reset gate does not control the amount of the candidate hidden state independently , but shares some information of the update gate , thus has better access to more temporal information for phoneme segmentation  @xcite .",
    "the update gate in gru was used for extracting gas in the following experiments .",
    ".the comparison between different gates in gated recurrent neural networks .",
    "[ cols=\"<,^\",options=\"header \" , ]     .",
    "different markers on the curves stand for the results of different thresholds . ]",
    "we show that the gate activation signals ( gas ) obtained in an unsupervised fashion have temporal structures highly correlated with the phoneme changes in the signals , and this correlation was verified in the experiments for phoneme segmentation .",
    "also , our experiments also showed that gas bring improvements to rpm without additional parameters . like bottleneck features",
    ", gas are obtained from the element of neural networks , instead of networks outputs , and both of them are shown to bring improvements . with the promising results of gas shown in the paper , we hope gas can brought the same improvements as the ones brought by bottleneck features .",
    "g.  hinton , l.  deng , d.  yu , g.  e. dahl , a .-",
    "mohamed , n.  jaitly , a.  senior , v.  vanhoucke , p.  nguyen , t.  n. sainath _",
    "_ , `` deep neural networks for acoustic modeling in speech recognition : the shared views of four research groups , '' _ ieee signal processing magazine _ , vol .  29 , no .  6 , pp .",
    "8297 , 2012 .",
    "h.  hermansky , d.  p. ellis , and s.  sharma , `` tandem connectionist feature extraction for conventional hmm systems , '' in _ acoustics , speech , and signal processing , 2000 .",
    "icassp00 . proceedings .",
    "2000 ieee international conference on _ , vol .",
    "3.1em plus 0.5em minus 0.4emieee , 2000 , pp .",
    "16351638 .",
    "s.  yeung , o.  russakovsky , g.  mori , and l.  fei - fei , `` end - to - end learning of action detection from frame glimpses in videos , '' _ corr _ , vol .",
    "abs/1511.06984 , 2015 .",
    "[ online ] .",
    "available : http://arxiv.org/abs/1511.06984    g.  lample , m.  ballesteros , s.  subramanian , k.  kawakami , and c.  dyer , `` neural architectures for named entity recognition , '' _ corr _ , vol .",
    "abs/1603.01360 , 2016 .",
    "[ online ] .",
    "available : http://arxiv.org/abs/1603.01360    y .- a .",
    "chung , c .- c .",
    "wu , c .- h .",
    "shen , h .- y .",
    "lee , and l .- s .",
    "lee , `` audio word2vec : unsupervised learning of audio segment representations using sequence - to - sequence autoencoder , '' _ arxiv preprint arxiv:1603.00982 _ , 2016 .",
    "f.  grzl , m.  karafit , s.  kontr , and j.  cernocky , `` probabilistic and bottle - neck features for lvcsr of meetings , '' in _ acoustics , speech and signal processing , 2007 .",
    "icassp 2007 .",
    "ieee international conference on _ , vol .",
    "4.1em plus 0.5em minus 0.4emieee , 2007 , pp .",
    "iv757 .",
    "lee and j.  glass , `` a nonparametric bayesian approach to acoustic model discovery , '' in _ proceedings of the 50th annual meeting of the association for computational linguistics : long papers - volume 1_.1em plus 0.5em minus 0.4emassociation for computational linguistics , 2012 , pp .",
    "chung , c .- a .",
    "chan , and l .- s .",
    "lee , `` unsupervised discovery of linguistic structure including two - level acoustic patterns using three cascaded stages of iterative optimization , '' in _ acoustics , speech and signal processing ( icassp ) , 2013 ieee international conference on_.1em plus 0.5em minus 0.4emieee , 2013 , pp .",
    "80818085 .",
    "j.  gehring , y.  miao , f.  metze , and a.  waibel , `` extracting deep bottleneck features using stacked auto - encoders , '' in _ acoustics , speech and signal processing ( icassp ) , 2013 ieee international conference on_.1em plus 0.5em minus 0.4emieee , 2013 , pp . 33773381 .",
    "p.  michel , o.  rsnen , r.  thiollire , and e.  dupoux , `` improving phoneme segmentation with recurrent neural networks , '' _ corr _ , vol .",
    "abs/1608.00508 , 2016 .",
    "[ online ] .",
    "available : http://arxiv.org/abs/1608.00508            l.  deng , m.  l. seltzer , d.  yu , a.  acero , a .- r .",
    "mohamed , and g.  e. hinton , `` binary coding of speech spectrograms using a deep auto - encoder . '' in _",
    "interspeech_.1em plus 0.5em minus 0.4emciteseer , 2010 , pp .",
    "16921695 .",
    "n.  srivastava , g.  e. hinton , a.  krizhevsky , i.  sutskever , and r.  salakhutdinov , `` dropout : a simple way to prevent neural networks from overfitting . '' _ journal of machine learning research _ , vol .  15 , no .  1 ,",
    "pp . 19291958 , 2014 .",
    "z.  wu and s.  king , `` investigating gated recurrent networks for speech synthesis , '' in _ acoustics , speech and signal processing ( icassp ) , 2016 ieee international conference on_.1em plus 0.5em minus 0.4em ieee , 2016 , pp .",
    "51405144 .",
    "y.  qiao , n.  shimomura , and n.  minematsu , `` unsupervised optimal phoneme segmentation : objectives , algorithm and comparisons , '' in _ acoustics , speech and signal processing , 2008 .",
    "icassp 2008 .",
    "ieee international conference on_.1em plus 0.5em minus 0.4emieee , 2008 , pp . 39893992 ."
  ],
  "abstract_text": [
    "<S> in this paper we analyze the gate activation signals inside the gated recurrent neural networks , and find the temporal structure of such signals is highly correlated with the phoneme boundaries . </S>",
    "<S> this correlation is further verified by a set of experiments for phoneme segmentation , in which better results compared to standard approaches were obtained .    * index terms * : autoencoder , recurrent neural network </S>"
  ]
}