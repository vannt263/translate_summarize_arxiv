{
  "article_text": [
    "low - density parity - check codes ( ldpc ) have attracted significant interest in recent years due to their simplicity and exceptionally high performance  @xcite .",
    "their simplicity and inherent randomness make them amenable to analysis using established methods in the area of statistical physics .",
    "these have been employed in a number of papers  @xcite-@xcite to gain insight into the properties of ldpc codes and to evaluate their performance .",
    "these studies include the evaluation of critical noise levels for given codes  @xcite , an exact calculation of weight and magnetisation enumerators  @xcite , the performance of irregular codes  @xcite , properties of codes in real - valued channels  @xcite , and the derivation of bounds for the reliability exponent  @xcite , to name but a few .",
    "these studies also represent the interdisciplinary nature of this research area and illustrate the successful interaction between researchers in the two disciplines .",
    "the evaluation of error exponents has been a long - standing problem in information theory  @xcite .",
    "efforts to obtain exact expressions and/or bounds to the error exponent resulted in partial success ; although tight bounds have been derived in the case of random codes and ldpc with infinite connectivity  @xcite , only limited results have been obtained for sparely connected codes .",
    "main stream techniques to tackle the problem include sphere - packing and union - bound arguments  @xcite . below a certain code - rate value",
    ", the estimated bounds also become loose and require using the ` expurgated exponent ' techniques  @xcite for obtaining a tighter bound .    in this paper , we employ methods of statistical physics to evaluate directly the average error exponent and typical reliability exponent in gallager and mn  @xcite ldpc codes . the _ average error exponent _",
    "is obtained by carrying out averages over the ensemble of randomly generated ldpc codes of given rate and connectivity ; while the _ reliability exponent _ is obtained by selecting the best codes in that ensemble .",
    "averages result in the emergence of macroscopic variables , representative of the ensemble properties , that can be obtained numerically and used to calculate the average error exponent ( in the current calculation we assume that short loops , which contribute polynomially to the block error probability in ldpc codes  @xcite , have been removed ) .",
    "average error exponent solutions have been obtained for both finite and infinite connectivity vector ensembles , while reliability exponent solutions have been obtained only in the case of infinite connectivity .    as a reference point",
    "to test our theory , we use known results obtained in the information theory literature for solvable limits ( e.g. codes of infinite connectivity ) , and find that our method reproduces them exactly . perhaps",
    "not surprisingly , we also find that at fixed noise level and code rate , the reliability exponent for codes of finite connectivity is always upper - bounded by that of the infinite - connectivity case .",
    "before we proceed , the distinction between the typical bounds found previously using methods of statistical physics  @xcite , and the current calculation should be clarified . in the former ,",
    "one employs methods of statistical physics to calculate the typical value of a _ bound _ based on inequalities introduced by gallager ; while in the current calculation , a direct estimation of the average error exponent , rather than a bound , is sought .",
    "an additional advantage of the current approach is that it can be extended to provide reliability exponent values for ldpc codes by restricted averages over codes of high performance .",
    "the paper is organised as follows : in section  [ sec : definitions ] , we introduce the general coding framework and the technique used . in sections  [ sec : solution ] and  [ sec : exactsolution ] we present an outline of the derivation and the solutions obtained in both finite and infinite connectivity cases respectively . in section  [ sec : mn ] we compare the error exponent results obtained for mn codes to those of gallager codes in both finite and infinite connectivity cases .",
    "discussion and conclusions are presented in section  [ sec : conclusions ] .",
    "a regular ( @xmath0 ) gallager error - correcting code is defined by the binary @xmath1 ( parity check ) matrix @xmath2 $ ] , which is known to both sender and receiver .",
    "the @xmath3 matrix @xmath4 is taken to be invertible .",
    "the number of non - zero elements in each row of @xmath5 is given by @xmath6 , while the number of non - zero elements per column is given by @xmath7 .",
    "gallager s encoding scheme consists of generating a codeword @xmath8 from an information ( message ) vector @xmath9 ( with @xmath10 ) via the linear operation @xmath11 ( mod 2 ) where @xmath12 is the generator matrix defined by @xmath13 $ ] ( mod 2 ) .",
    "the code rate is then given by @xmath14 , and measures the information redundancy of the transmitted vector .",
    "upon transmission of the codeword @xmath15 via a noisy channel , taken here to be a bsc , the vector @xmath16 ( mod 2 ) is received , where @xmath17 is the true channel noise .",
    "the statistics of the bsc is fully determined by the flip rate @xmath18 $ ] : @xmath19 decoding is carried out by multiplying @xmath20 by @xmath5 to produce the syndrome vector @xmath21 , since @xmath22 by construction . in order to reconstruct the original message @xmath23",
    ", one has to obtain an estimate @xmath24 for the true noise @xmath25 .",
    "first we select the parity check set of @xmath5 and @xmath25 , i.e. all @xmath24 that satisfy the parity check equations : @xmath26 .",
    "since all operations are performed in modulo 2 arithmetic , @xmath27 typically contains @xmath28 $ ] candidates for the true noise vector @xmath25 .",
    "it was shown ( see e.g. @xcite for technical details ) that this problem can be cast into a statistical mechanics formulation , by replacing the field @xmath29 by ( @xmath30 ) , and by adapting the parity checks correspondingly . from the parity check matrix @xmath5 we construct the binary tensor @xmath31 , where @xmath32 if @xmath5 has a row in which the elements @xmath33 are all 1 ( i.e. when the bits @xmath34 are involved in the same parity check ) , and 0 otherwise . the fact that each bit @xmath35 is involved in exactly @xmath36 parity checks",
    "is then expressed by @xmath37 and the parity check equations become @xmath38 , @xmath39 .",
    "decoding now consists in selecting an @xmath24 from @xmath40 , on the basis of its noise statistics , which are fully described by its _ magnetisation _",
    "@xmath41 ( corresponding to the weight in the information theory literature ) .",
    "note that the number of flipped bits in a candidate noise vector @xmath24 is given by @xmath42 .",
    "therefore , we introduce a hamiltonian or cost function for each noise candidate that is negatively proportional to its magnetisation : @xmath43 where we take @xmath44 , such that up to normalisation @xmath45 yields the correct prior for candidate noise vectors generated by the bsc @xcite . then , a vector @xmath24 from @xmath40 with the highest magnetisation ( lowest weight ) is selected as a solution ; this corresponds to maximum a posteriori ( map ) decoding .",
    "we are now interested in the probability that other candidate noise vectors are selected from the parity check set @xmath40 , other than the correct ( i.e. true ) noise vector @xmath25 , for any given combination @xmath46 ; this is termed the _ block error probability_. in order to calculate this probability , we introduce an indicator function : @xmath47\\right|_{\\beta_1=\\beta_2=\\beta } \\label{eq : delta_def}\\ ] ] where @xmath48 the partition functions @xmath49 and @xmath50 differ only in the exclusion of @xmath25 from @xmath51 .",
    "if the true noise @xmath25 has the highest magnetisation of all candidates in the parity check set ( decoding success ) , the boltzmann factor @xmath52 $ ] will dominate the sum over states in @xmath53 in the limit @xmath54 , and @xmath55 .",
    "alternatively , if some other vector @xmath56 has the highest magnetisation of all candidates in the parity check set ( decoding failure ) , its boltzmann factor will dominate both @xmath51 and @xmath53 and @xmath57 .",
    "note that the separate temperatures @xmath58 and @xmath59 , which are put to be equal to @xmath60 in the end , and the powers @xmath61 which are taken to be @xmath62 in the end , have been introduced in order to allow us to determine whether obtained solutions are physical or not .",
    "the power @xmath63 have been introduced to restrict the indicator function results to 0/1 . in principle , this can be done by taking the limit @xmath64 ; however , in section  [ sec : solution ] , we show that finite @xmath65 values will be used due to various constraints .    to derive the _",
    "average error exponent _ , we take the logarithm of the indicator function average with respect to all possible realisations of true noise vectors @xmath25 , and",
    "the ensemble of regular @xmath66 codes @xmath67 : @xmath68 where @xmath69 and @xmath70~f(\\mca ) }         { \\sum_{\\mca}\\prod_{i_1=1}^n       \\delta[\\sum_{{i_2}<\\cdots<{i_k}}\\mca_{\\bra i_1\\cdots i_k\\ket}-j ]         } .",
    "\\label{eq : tensor_average}\\ ] ] to obtain an expression for the _ reliability exponent _ one carries out a similar calculation with one main difference : prior to averaging the indicator function over the ensemble of regular @xmath66 codes @xmath67 , one takes the averaged expression with respect to realisations of true noise vectors @xmath25 to a power @xmath71 which favours code constructions with a low average error probability ( i.e. , @xmath72 ) .",
    "the logarithm of the expression averaged over the ensemble of codes @xmath67 is then divided by @xmath71 to remove the exponent .",
    "the expression calculated is : @xmath73^{r}\\right\\ket_{\\mca } \\label{eq : reliability_exp}\\ ] ] since there are only discrete degrees of freedom , physically meaningful solutions must have a non - negative entropy , requiring the disorder - averaged entropies of the two partition functions ( [ eq : partition_sums ] ) to be non - negative .",
    "note that due to the order of taking the logarithm vs the various averages , expressions ( [ eq : reliability ] ) and ( [ eq : reliability_exp ] ) are not equivalent to a ( quenched ) disorder - averaged free energy .",
    "using general principles one can show that for general values of @xmath74 and @xmath61 , the disordered - averaged entropies ( with averages taken over the joint distribution of code - constructions @xmath75 , true- and candidate - noise @xmath76 as suggested by ( [ eq : reliability ] ) and ( [ eq : reliability_exp ] ) ) are given , for both calculations ( [ eq : reliability ] ) and ( [ eq : reliability_exp ] ) , by @xmath77 which have to be positive .",
    "using standard statistical physics methods such as in @xcite , we perform the gauge transformation @xmath78 , and the averages over true noise ( [ eq : truenoise_average ] ) and code constructions ( [ eq : tensor_average ] ) . in the case of @xmath79 ,",
    "each quantity carries two indices ( a replica index and another index coming from the power @xmath71 ) ; however , the two indices factorise _ unless an explicit , more complex , symmetry breaking structure is introduced_. here , we do not assume a more complex structure that entangles the two types of indices ; we also assume the simplest replica symmetric scheme @xcite to arrive at the following expression for the average error exponent ( @xmath80 ) , and for the reliability exponent ( optimised @xmath71 ) : @xmath81-j\\log~i_2[\\pi,\\hat{\\pi}]+\\log~i_3[\\hat{\\pi } ]                               \\right ] \\label{eq : reliability_final_r}\\ ] ] where @xmath82 @xmath83 @xmath84^{\\lambda_1}\\right .",
    "\\nonumber \\\\ & & \\hspace*{37mm}\\times\\left .",
    "\\left[\\sum_{v=\\pm 1}e^{\\beta_2 f n^0 v}\\prod_{c=1}^j      \\left(\\frac{1+v\\hat{y}_c}{2}\\right)\\right]^{\\lambda_2 }    \\right\\ket_{n^0}^r \\label{eq : i3_r}\\end{aligned}\\ ] ] where we have used the short - hand notation @xmath85=@xmath86 . for @xmath80 , functional extremisation of ( [ eq : reliability_final_r ] ) with respect to the densities @xmath87 and @xmath88 results in a closed set of equations ( reminiscent of ` density evolution ' equations @xcite ) : @xmath89\\    \\delta\\left[\\hat{y}-\\prod_{c=1}^{k-1}y_c\\right ] \\label{eq : sp1}\\ ] ] @xmath90       \\delta\\left[y-\\frac{d_-(\\hat{\\by};\\beta_2)}{d_+(\\hat{\\by};\\beta_2)}\\right ]                 \\ket\\!\\ket ' }                { \\bra\\!\\bra1\\frac{}{}\\ket\\!\\ket'}. \\label{eq : sp2}\\ ] ] where @xmath91         \\pm[e^{-\\beta f n^0}\\prod_{c=1}^{j-1}(1-z_c)].\\end{aligned}\\ ] ] for given @xmath92 in general , solutions to ( [ eq : sp1 ] ) and ( [ eq : sp2 ] ) can only be obtained numerically .",
    "inserting these solutions into ( [ eq : reliability_final_r ] ) we then obtain @xmath93 , which becomes the _ average error exponent _ for @xmath94 , and for @xmath95 .",
    "we must recall , however , that physically meaningful solutions must satisfy the conditions ( [ eq : entropies ] ) stating that the entropies related to the full and the restricted partition sums are non - negative .",
    "we restrict ourselves to regions below the thermodynamic transition where the average case is dominated by the ferromagnetic solution , such that we can fix the system described by @xmath53 in ( [ eq : partition_sums ] ) to the ferromagnetic solution .",
    "this dominance is guaranteed if the following constraint is satisfied @xmath96 it turns out that for given @xmath97 , the largest value of @xmath98 for which ( [ eq : condition3 ] ) is satisfied is given by the simple expression @xmath99 .",
    "hence , in order to maximise @xmath98 , we must look for the smallest value @xmath100 that satisfies the conditions on the non - negativity of the entropies ( [ eq : entropies ] ) .",
    "unfortunately , in general this value @xmath100 can only be obtained numerically .",
    "the value obtained for the average error exponent by this analysis is then given by @xmath101 from ( [ eq : reliability_final_r ] ) .    in figure [",
    "fig : kcfinite ] we present the obtained average error exponent as a function of the flip rate for @xmath102 , ( @xmath103 ) and @xmath104 ( @xmath105 ) codes .",
    "we observe that the error exponent indeed converges to zero , as it should , when the flip rate approaches its critical value .",
    "notice the similarity between the equations obtained here and in  @xcite in spite of the different starting points .",
    "it has been shown in  @xcite that the analysis should be refined in low rate regions by considering a more complex bound .",
    "the refined analysis resulted in tight bounds of the error exponent even in the region of low code - rates , similar to those obtained using expurgated exponent methods .",
    "in the next section we will show that the selection of best codes through the optimisation of the power @xmath71 , in calculating the reliability exponent , provides similar results to those obtained in  @xcite .",
    "( 120,55 ) ( 10 , 0)=40 ( 65 , 0)=40 ( 5,25)@xmath106 ( 62,25)@xmath106 ( 40,0)@xmath107 ( 95,0)@xmath107      the average error exponent can be calculated numerically for finite @xmath0 and @xmath144 values ; the average error exponent @xmath106 as function of the flip rate @xmath107 is shown in figure  [ fig : mnfinite ] .",
    "on the left , we show results for mn codes of fixed rate @xmath160 with three different sets of parameters @xmath161 ( circles ) , @xmath162 ( diamonds ) and @xmath163 ( upper line ) .",
    "it is interesting to notice that average exponents for either @xmath164 or @xmath165 values coincide with that of the infinite connectivity case ( which can be obtained analytically ) .",
    "this complements other interesting properties of mn codes , to do with their critical flip rate values , that have been obtained previously , distinguishing them from gallager ldpc codes  @xcite .    on the right ,",
    "we see a comparison between average error exponents of gallager and mn codes ( @xmath105 ) .",
    "the gallager code @xmath104 average error exponent ( circles ) is significantly below the random code @xmath163 value ( thin upper line ) and the equivalent mn code @xmath166 result ( diamonds ) .",
    "( 120,55 ) ( 8 , 5)=40 ( 63 , 5)=40 ( 4,25)@xmath106 ( 61,25)@xmath106 ( 35,2)@xmath107 ( 90,2)@xmath107",
    "whereas for finite density codes solutions for the average error exponent are obtained numerically , in the limit of @xmath108 ( while keeping the rate @xmath109 finite ) one obtains two types of analytic solutions to equations ( [ eq : sp1 ] ) and ( [ eq : sp2 ] ) , which can be verified by substitution . moreover , in this limit one also obtains solutions in the reliability exponent calculation ( [ eq : reliability_exp ] ) , which are generally difficult to obtain for finite @xmath6 and @xmath36 values .",
    "solutions obtained in the average error exponent calculation take the following form : type i : @xmath110~\\delta(y-1 ) \\nonumber\\\\ \\hat{\\pi}(\\hat{x},\\hat{y})&=&\\frac12 \\left[\\delta(\\hat{x}-1)+\\delta(\\hat{x}+1)\\right]~\\delta(\\hat{y}-1 ) \\label{eq : typei}\\end{aligned}\\ ] ] type ii : @xmath111 \\nonumber\\\\ \\hat{\\pi}(\\hat{x},\\hat{y})&=&\\delta(\\hat{y}-1)~\\delta(\\hat{x } ) \\label{eq : typeii}\\end{aligned}\\ ] ] with @xmath112 $ ] .",
    "taking @xmath113 and @xmath114 , the average error exponent as obtained from the type i solution is given by @xmath115 we find that the entropies ( [ eq : entropies ] ) are always identically zero , and that the constraint ( [ eq : condition3 ] ) requires that @xmath116 , such that @xmath117 and @xmath118+\\log [ e^f+e^{-f}+2 ] \\label{eq : kcinfty1}\\ ] ] which is exactly the bhattacharyya limit @xcite .",
    "the average error exponent as obtained from the type ii solution is given by @xmath119\\right ]         + \\log [ 2\\cosh(f-\\beta f\\lambda)]-\\log 2\\cosh f\\ ] ] the condition on the entropy @xmath120 is satisfied for all @xmath121 , whereas the condition @xmath122 is violated below the critical ( freezing ) temperature @xmath123 obtained from @xmath124+\\log2\\cosh[\\beta^*f]=0\\ ] ] this negative entropy is an artifact of the assumption about the symmetry between replicas , and is easily remedied by considering a ` frozen rsb ' ansatz @xcite . using this ansatz and taking into account condition ( [ eq : condition3 ] ) , the ( frozen ) average error exponent obtained from the type ii solution , is finally given by @xmath125+\\frac{j}{k}\\log 2-\\log 2\\cosh f \\label{eq : kcinfty2}\\ ] ]    what remains is to determine whether the type i or type ii solution is physically dominant , by using @xmath106 as a generating function for calculating the related free energies ( through its derivative with respect to @xmath126 ) .",
    "results for the case of @xmath108 are presented in figure [ fig : kctoinfty ] for @xmath127 and @xmath128 .      to obtain the reliability exponent we take equations ( [ eq : reliability_final_r])-([eq : i3_r ] ) and optimise with respect to @xmath71 . deriving a general set of equations similar to ( [ eq : sp1],[eq : sp2 ] ) , that can be solved iteratively , is difficult in this case . however , in the limit @xmath108 , we observe that we can restrict the possible solutions of @xmath88 to two different types : type i : @xmath129\\delta(\\hat{y}-1 ) \\label{eq : typeir}\\ ] ] type ii : @xmath130 in this case , knowledge of the solution for @xmath88 is sufficient for calculation the reliability exponent ( [ eq : reliability_final_r ] ) .",
    "furthermore , the expression obtained from the type ii solution turns out to be identical to that of the average error exponent ( [ eq : kcinfty2 ] ) .    on the other hand ,",
    "the reliability exponent obtained from the type i solution is somewhat different , and takes the form : @xmath131+\\frac{1}{r } \\log [ \\cosh^{r}(f ) + \\cosh^{r}((2\\beta\\lambda-1)f ) ] \\ .",
    "\\label{eq : kcinfty1r}\\ ] ] given the relation ( [ eq : condition3 ] ) and @xmath99 , one obtains @xmath117 , @xmath116 , and the expression reduces to @xmath131+\\frac{1}{r } \\log [ \\cosh^{r}(f ) + 1 ] \\ .",
    "\\label{eq : kcinfty1rf}\\ ] ] optimising the expression with respect to @xmath71 , one obtains a similar expression to the expurgated exponent result  @xcite @xmath132 + \\frac{1}{r}(1-r ) \\ln 2 \\right \\ } \\ , \\ ] ] which is also identical to the result obtained for the average bound of the reliability exponent in  @xcite .",
    "the reliability exponent is therefore identical to the average error exponent except for very low @xmath133 values as shown in figure [ fig : kctoinfty ] for @xmath127 and @xmath128 ( marked by a dotted line in the two cases considered ) .",
    "( 120,75 ) ( 15,7 )    0    ( 7,35)@xmath134 ( 60,0)@xmath133 ( 28.5,30)@xmath135 ( 46.5,31.5)@xmath135 ( 60,21.5)@xmath136 ( 42,20.3)@xmath136 ( 73.5,10.8)@xmath137 ( 87.75,10.8)@xmath137",
    "in this section , we extend our treatment of the average error and reliability exponent to regular mn codes  @xcite , a variant of ldpc codes .",
    "a regular mn code is defined by the binary @xmath138 matrix @xmath139 $ ] , concatenating two sparse matrices with the @xmath140 matrix @xmath141 assumed invertible .",
    "the @xmath142 matrix @xmath143 has @xmath6 non - zero elements per row and @xmath36 per column while @xmath141 has @xmath144 non - zero elements per row and per column .",
    "the code rate is given by @xmath145 .",
    "the encoding scheme consists of generating a codeword @xmath146 from an ( unbiased ) message vector @xmath147 via @xmath148 . upon sending @xmath149 through the noisy channel the vector @xmath150",
    "is received , where @xmath25 is the true channel noise ( [ noise ] ) .",
    "decoding is carried out by multiplying the received vector @xmath20 by @xmath141 to produce the syndrome vector @xmath151 . in order to reconstruct the original message",
    ", one selects the best estimate @xmath152 , for the true @xmath153 from the parity check set @xmath154 , on the basis of the message / noise statistics . note that since we take the message vector @xmath155 to be unbiased , the selection will only be based on the noise statistics .",
    "since most calculation steps are completely analogous ( although lengthier ) to those of gallager codes , we only state the final general expression for mn codes : @xmath156^{r\\lambda_1 }    \\left[\\sum_{\\s=\\pm}\\prod_{c=1}^j\\left (               \\frac{1+\\s\\hat{y}_c}{2}\\right)\\right]^{r\\lambda_2 } \\nonumber\\\\&&\\hspace*{-40 mm }    + \\log\\int\\prod_{l=1}^t\\left\\{d\\hat{\\rho}(\\hat{x}_l,\\hat{y}_l )    \\right\\ }    \\left\\bra\\left [    \\sum_{\\tau=\\pm}e^{\\beta_1\\tau f n^0}\\prod_{l=1}^t    \\left(\\frac{1+\\tau\\hat{x}_l}{2}\\right)\\right]^{\\lambda_1 }    \\right . \\nonumber\\\\&&\\hspace * { 20 mm }    \\left.\\left.\\times    \\left [    \\sum_{\\tau=\\pm}e^{\\beta_2\\tau f n^0}\\prod_{l=1}^t    \\left(\\frac{1+\\tau\\hat{y}_l}{2}\\right)\\right]^{\\lambda_2 }    \\right\\ket_{n^0}^r\\right\\ }   \\nonumber\\end{aligned}\\ ] ] with the short - hand notation @xmath85=@xmath86 . as for gallager codes , for @xmath113 , and @xmath114",
    ", @xmath157 becomes the _ average error exponent _ for @xmath80 , while for optimised @xmath71 it becomes the _ reliability exponent_. furthermore , the conditions ( [ eq : entropies ] ) and ( [ eq : condition3 ] ) must always be satisfied .    similarly to the case of gallager codes one can derive a set of functional equations ( reminiscent of density evolution equations @xcite ) for @xmath158 and @xmath159 .",
    "the case of @xmath168 is solvable exactly for all transmission rates , and both average and reliability error exponents can be obtained analytically .",
    "the solutions obtained as well as the average and reliability error exponents calculated are identical to those of gallager ldpc codes . retrospectively ,",
    "this is not surprising as both codes become random codes in this limit .",
    "in this paper we suggest a method for direct evaluation of the average and reliability error exponent over the ensemble of ldpc error - correcting codes of given rate and connectivity .",
    "an analytical solution has been obtained , for both gallager and mn codes , using methods of statistical physics , which is in perfect agreement with known results in the limit @xmath169 ( with @xmath133 finite ) .",
    "the results for mn and gallager codes become identical in this limit as both become random codes .",
    "average error exponent results obtained by our method for codes of finite @xmath66 values can not be obtained using traditional approaches used in the information theory community . as expected , they seem to be upper bounded by the @xmath108 curves , but suggest a profoundly different behaviour for gallager and mn ldpc codes .",
    "average error exponent results for gallager codes show a gradually improved performance as the parameters ( @xmath0 ) increase , until they finally coincide with the @xmath108 error exponent result .",
    "the results for mn codes becomes identical to the @xmath108 error exponent result for all @xmath164 or @xmath165 . to some extent",
    ", this is in agreement with previous results obtained for the critical flip rate of mn codes  @xcite and is a result of the close - to - random codebook they generate .    an interesting feature of the present study is the similarity of our equations to those obtained in  @xcite in spite of the different approaches used .",
    "an important advantage offered by the current approach is a potential extension to select high performance codes to obtain _ reliability exponent _ values for ldpc codes of finite connectivity ; obtaining such solutions remains a difficult task and is currently under study .",
    "support from epsrc research grant gr / n63178 ( ds , ns ) , the royal society ( ds , ns , jvm ) , grants - in - aid , mext ( 13680400 and 13780208 ) and jsps ( yk ) is acknowledged .",
    "99 t richardson , a shokrollahi and r urbanke ( 2001 ) , _ ieee trans . on info .",
    "theory _ * 47 * 619 - 637 r vicente , d saad and y kabashima ( 1999 ) _ phys rev e _ * 60 * 5352 - 5366 r vicente , d saad and y kabashima ( 2000 ) _ j phys a _ * 33 * 6527 - 6542 j van mourik , d saad and y kabashima ( 2002 ) _ phys rev e _ * 66 * 026705 t tanaka and d saad , ( 2003 ) submitted in _",
    "phys rev e _",
    "y kabashima , n sazuka , k nakamura and d saad ( 2001 ) _ phys rev e _ ( 2001 ) * 64 * 046113 a montanari and n sourlas _ eur phys j b _ * 18 * 107 - 119 a montanari _ eur phys j b _ * 23 * 121 - 136 s.  franz , m.  leone , a.  montanari and f.  ricci - tersenghi , _ phys rev e _ * 66 * 046120 r g gallager ( 2001 ) information theory and reliable communication wiley & sons , ny a j viterbi and j k omura ( 1979 ) ` principles of digital communication and coding ' , mcgraw - hill int ed ( singapore ) d.j.c .  mackay ( 1999 )",
    "_ ieee trans .",
    "* 45 * 399 g.  miller and d.  burshtein ( 2001 ) _ ieee trans .",
    "theory _ * 47 * 2696 h nishimori ( 2001 ) statistical physics of spin glasses and information processing , oxford university press , uk k y m wong and d sherrington ( 1987 ) _ j phys a _ * 20 * l793-l799"
  ],
  "abstract_text": [
    "<S> we present a theoretical method for a _ direct _ evaluation of the average and reliability error exponents in low - density parity - check error - correcting codes using methods of statistical physics . </S>",
    "<S> results for the binary symmetric channel ( bsc ) are presented for codes of both finite and infinite connectivity . </S>"
  ]
}