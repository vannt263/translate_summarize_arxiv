{
  "article_text": [
    "source separation consists in recovering components from a set of observed mixtures .",
    "component separation is a topic of major interest to the planck space mission , to be launched in 2007 by esa to map the cosmic microwave background ( cmb ) .",
    "the blackbody temperature of this radiation as a function of direction on the sky will be measured in @xmath0 different frequency channels , corresponding to wavelengths ranging from @xmath1microns to @xmath2 cm . in each channel",
    ", the temperature map will show not only the cmb contribution but also contributions from other sources called _ foregrounds _ , among which galactic dust emission , emission from very remote ( and hence quasi point - like ) galaxy clusters , and several others .",
    "it is expected that ( after some heavy pre - processing ) , the map built from the @xmath3-th channel can be accurately modeled as @xmath4 where @xmath5 is the spatial pattern for the @xmath6-th component and @xmath7 is an additive detector noise . in other words , cosmologists expect to observe a noisy instantaneous ( _ i.e. _ non convolutive ) mixture of essentially independent components ( independence being the consequence of the physically distinct origins of the various components ) .",
    "even though recovering as cleanly as possible the cmb component is the primary goal of the mission , astrophysicists are also interested in the _ other _ components , in particular for collecting data regarding the morphology and physical properties of galactic foregrounds ( dust  ) and the distribution of galaxy clusters .",
    "this paper deals with _ blind _ component separation .",
    "blindness means recovering the components without knowing in advance the coefficients of the mixture . in practice , this may be achieved by resorting to the strong but often plausible assumption of mutual statistical independence between the components .",
    "the motivation for a blind approach is obvious : even though some coefficients of the mixture may be known in advance with good accuracy ( in particular those related to the cmb ) , some other components are less well known or predictable .",
    "it is thus very tempting to run blind algorithms which do not require _ a priori _ information about the mixture coefficients .",
    "several attempts at blind component separation for cmb imaging have already been reported . the first proposal , due to baccigalupi _",
    "_ use a non gaussian noise - free i.i.d .",
    "model for the components@xcite , hence following the ` standard ' path to source separation .",
    "one problem with this approach is that the most important component , namely the cmb itself , seems to closely follow a gaussian distribution .",
    "it is well known that , in i.i.d .",
    "models , it is possible to accommodate at most one gaussian component .",
    "it does not seem to be a good idea , however , to use a non gaussian model when the main component itself has a gaussian distribution .",
    "another reason why the i.i.d .",
    "modeling ( which is implicit in ` standard ' ica ) probably is not appropriate to our application : most of the components are very much dominated by the low - frequency part of their spectra .",
    "thus sample averages taken through the data set tend not to converge very quickly to their expected values .",
    "this may explain why fourier methods , presented below , seem to perform better .",
    "thus , rather than exploiting the non gaussianity of ( all but one of ) the components , one may think of exploiting their spectral diversity .",
    "a very sensible approach is proposed by pham : using the whittle approximation of the likelihood , he shows that blind separation can be achieved by jointly diagonalizing spectral covariance matrices computed over several frequency bands  @xcite .",
    "this conclusion however is reached only in the case of noise - free models .",
    "therefore , it is not appropriate for cmb imaging where a very significant amount of noise is expected .    in this paper",
    ", we follow pham s approach but we take additive noise into account , leading to a likelihood function which is no longer a joint diagonality criterion , thus requiring some new algorithmics .",
    "we present below the form taken by the em algorithm when applied to a set of spectral covariance matrices .",
    "this approach leads to an efficient algorithm , much faster than the algorithms obtained via the em technique in the case of non gaussian i.i.d .",
    "modeling as in  @xcite or  @xcite .",
    "our method is obtained by starting from a stationary gaussian model .",
    "for ease of exposition , we assume that the observations are @xmath8 times series rather than @xmath8 images ( extension to images is straightforward ) . the @xmath9-dimensional observed process @xmath10 $ ] is modeled as @xmath11 where @xmath12 is an @xmath13 matrix with linearly independent columns . the @xmath14-dimensional source process @xmath15 ( the components ) and the @xmath8-dimensional noise process @xmath16 are modeled as real valued , mutually independent and stationary with spectra @xmath17 and @xmath18 respectively .",
    "the spectrum of the observed process then is @xmath19 the @xmath20 superscript denotes transconjugation even though transposition would be enough almost everywhere in this paper ( our method is easily adapted to deal with complex signals / mixtures ) .",
    "the assumption of independence between components implies that @xmath17 is a diagonal matrix : @xmath21_{ij } = \\delta_{ij } p_i(\\nu ) \\ ] ] where @xmath22 is the power spectrum of the @xmath3th source at frequency @xmath23 . for simplicity",
    ", we also assume that the observation noise is uncorrelated both in time and across sensors : @xmath24_{ij } = \\delta_{ij } \\sigma_i^2\\ ] ] meaning that the noise spectral density @xmath25 on the @xmath3th detector does not depend on frequency @xmath23 . in summary",
    "the probability distribution of the process is fully specified by @xmath13 mixture coefficients , @xmath8 noise levels and @xmath14 power spectra .",
    "our method boils down to adjusting smoothed versions of the spectral covariance matrices  ( [ eq : specmody ] ) to their empirical estimates .",
    "the estimated parameters are those which give the best match , as measured by an objective function .",
    "this objective function is introduced in this section . in the following section ,",
    "we show how it stems from the maximum likelihood principle .",
    "a key feature of our method is that it uses low dimensional statistics obtained as averages over _ spectral domains _ in fourier space .",
    "these fourier domains simply are frequency bands in the 1d case or are two - dimensional domains of the fourier plane when the method is applied to images .    consider a partition of the frequency interval @xmath26 into @xmath27 domains ( bands ) : @xmath28 which are required to be symmetric : @xmath29 . for any function @xmath30 of frequency ,",
    "denote @xmath31 its average over the @xmath32-th spectral domain when sampled at multiples of @xmath33 : @xmath34 where @xmath35 is the number of points in domain @xmath36 .",
    "denoting @xmath37 the discrete - time fourier transform of @xmath38 samples : @xmath39 the _ periodogram _ is @xmath40 and its averaged version is @xmath41 note that @xmath42 for real data so that @xmath43 actually is a real valued matrix if @xmath36 is a symmetric domain .",
    "this sample spectral covariance matrix will be our estimate for the corresponding averaged quantity @xmath44 where the equality results from averaging model  ( [ eq : specmody ] ) .",
    "a key point is that the structure of the model is not affected by spectral averaging since @xmath45 remains a diagonal matrix after averaging : @xmath46\\ ] ] and , of course , @xmath47 still is a constant diagonal matrix .",
    "our proposal for blind identification simply is to match the sample spectral covariance matrices @xmath48 , which depend on the data , to their theoretical values @xmath49 , which depend on the unknown parameters .",
    "there are @xmath50 of these parameters , redundant parameters since a scale factor can be exchanged between each column of @xmath12 and the corresponding power spectra . ] collectively referred to as @xmath51 : @xmath52_{i=1,j=1}^{i=\\nbd , j=\\nbc }   ; \\ \\    [ \\langle p_j \\rangle_q ] _ { j=1,q=1}^{j=\\nbc , q = q }   ; \\ \\    [ \\sigma_i^2]_{i=1}^{i=\\nbd }    \\right\\ }    .\\ ] ]",
    "the mismatch between the sample statistics and their expected values is quantified by the average divergence : @xmath53 where the positive weight @xmath35 is ( as above ) proportional to the size of the @xmath32-th spectral domain and where @xmath54 is a measure of divergence between two @xmath55 positive matrices defined as @xmath56 this is nothing but the kullback divergence between two @xmath14-dimensional zero - mean gaussian distributions with positive covariance matrices @xmath57 and @xmath58 respectively .",
    "the reason for using the mismatch measure  ( [ eq : obj ] ) is its connection to maximum likelihood principle ( see below ) . even though the divergence  ( [ eq : obj ] ) may , at first sight , seem more difficult to deal with than a simple quadratic distance , it is actually a better choice in at least two respects : first , we expect it to yield efficient parameters estimates because of the asymptotic optimality of maximum likelihood estimation ; second , thanks to its connection to the log - likelihood , it lends itself to simple optimization via the em algorithm ( see below ) .    a last note : since domain averaging does not change the algebraic structure of the spectral covariance matrices ( _ i.e. _ eq .",
    "( [ eq : specmody ] ) becomes  ( [ eq : modbydom ] ) ) , it does not introduce any bias in the estimation of @xmath12 .",
    "the whittle approximation is a spectral approximation to the likelihood of stationary processes .",
    "it has been introduced for the blind separation of noise - free mixtures by pham  @xcite . simplifying a little bit",
    ", this approximation boils down to asserting that the coefficients @xmath59 of definition  ( [ eq : dft ] ) taken at frequencies @xmath60 are uncorrelated , have zero - mean and a covariance matrix equal to @xmath61 .",
    "simple computations then show that up to a constant and a scalar factor the ( negative ) log - likelihood of the data takes the form  ( [ eq : obj ] ) under the additional approximation that @xmath62 is constant over each spectral domain .",
    "the whittle approximation is good for gaussian processes but certainly does not capture all the probability structure , even for large @xmath38 , for non gaussian processes .",
    "however , it it still provides a principled way of exploiting the spectral structure of the process , leading to the selecting of  ( [ eq : obj ] ) as an objective function .",
    "in addition , it suggests to use the em algorithm for minimizing  ( [ eq : obj ] ) .      using the em technique for maximizing a likelihood function requires defining latent ( unobserved ) data . in the case of source separation",
    ", there is an obvious choice : take the components as the latent data .",
    "this approach was introduced in  @xcite for a noisy non gaussian i.i.d .",
    "model of source separation and later in  @xcite for a noisy non gaussian model in the spectral domain .",
    "both these models lead to heavy computation .",
    "in contrast , by i ) using only a gaussian model ( the whittle approximation ) and ii ) averaging over spectral domains , the em algorithm becomes very computationally attractive .",
    "room is lacking for a complete derivation of the em algorithm in our case but it is not difficult to adapt , for instance , the computations of  @xcite to our case .",
    "let us only mention why the resulting algorithm is much simpler .",
    "first , when dealing with data structured as @xmath63 , em needs to evaluate conditional expectations @xmath64 and @xmath65 .",
    "thanks to the gaussian model , these are readily found to be _ linear _ functions of @xmath66 and @xmath67 respectively : @xmath68 where matrices @xmath69 and @xmath70 are defined as @xmath71 with covariance matrices @xmath72 , @xmath73 .",
    "second , this linearity is preserved through domain averaging , meaning that the em algorithm only needs to operate on the sample covariance matrices @xmath48 .",
    "this set of matrices is a sufficient statistic set in our model ; it is also all that is needed to run the em algorithm .",
    "thus , blind separation of noisy mixtures of stationary sources can be achieved by computing the periodogram , averaging it into a set of sample covariance matrices and maximizing the likelihood by then running the em algorithm .",
    "the algorithm is summarized in pseudo - code ( see alg .  [",
    "tab : em ] ) , but its derivation ( which is purely mechanical ) is omitted .",
    "* start * with sample covariance matrices @xmath48 , and initial guesses for @xmath12 , @xmath74 and @xmath75 .",
    "@xmath76 @xmath77 @xmath78 @xmath79 @xmath80 @xmath81 @xmath82 @xmath83 @xmath84 @xmath85 for @xmath86 .",
    "renormalize @xmath12 and the @xmath75    in this pseudo - code , the @xmath87 operator sets to @xmath88 the off - diagonal elements of its argument .",
    "we also include a renormalization step which deals with the scale indetermination inherent to source separation : each column of @xmath12 is normalized to have unit norm and the corresponding scale factor is applied to the average source spectra .",
    "preliminary tests have been carried on simulated observations in six channels at microwave frequencies 100 , 143 , 217 , 353 , 545 and 857 ghz , over sky patches of size @xmath89 sampled over a @xmath90 pixel grid .",
    "mixtures include three astrophysical components ( cmb , galactic dust , and emission from galaxy clusters ) and white noise .    since isotropic observations are expected , we choose spectral domains which are not only symmetric but also rotation invariant ; in other words : spectral rings .",
    "the sample spectral covariance are computed over 15 such rings equally spaced over the whole band .",
    "data reduction thus is by a factor of @xmath91 .",
    "the em algorithm converges in a few tens of iterations amounting to a few seconds on a 1 ghz machine when coded in octave ( a free clone of matlab : ` http://www.octave.org ` ) .",
    "a notable feature here is the separation of the galaxy clusters .",
    "the snr on the cmb component is also much improved at high frequency even though this can not be assessed from the picture .",
    "see the companion paper in these proceedings for more details .",
    "we have proposed an efficient method to maximize the likelihood of a model of noisy mixtures of stationary sources by implementing the em algorithm on spectral domains .",
    "the procedure jointly estimates all the parameters : mixing matrix , average source spectra , noise level in each sensor .",
    "spectral averaging offers large computational savings , especially when dealing with images .",
    "since the inference principle is maximum likelihood for a ` smooth ' gaussian stationary model , we expect a good statistical efficiency when the source spectra are reasonably smooth ( even though we saw little performance degradation in our experiments when using a very coarse @xmath92 spectral partition ) and when the sources actually are gaussian . in the cmb application ,",
    "some components are very close to gaussian ( the cmb itself ) while others are strongly non gaussian ; it is not clear yet how to best combine non gaussian information with spectral diversity .    as final note",
    ", we recall that , in the noise - free case , the ability to blindly separate gaussian stationary components rests on _ spectral diversity _ : the spectra of any two sources should not be proportional .",
    "the noisy case is complicated by the fact that the noise parameters also have to be estimated ."
  ],
  "abstract_text": [
    "<S> we present a new source separation method which maximizes the likelihood of a model of _ noisy _ mixtures of stationary , possibly gaussian , independent components . </S>",
    "<S> the method has been devised to address an astronomical imaging problem . </S>",
    "<S> it works in the spectral domain where , thanks to two simple approximations , the likelihood assumes a simple form which is easy to handle ( low dimensional sufficient statistics ) and to maximize ( via the em algorithm ) . </S>"
  ]
}