{
  "article_text": [
    "although low - density parity - check block codes ( ldpc - bcs ) have very good performance under message - passing iterative ( mpi ) decoding , they are known to be subject to decoding failures due to so - called pseudo - codewords . these are real - valued vectors that can be loosely described as error patterns that cause non - convergence in iterative decoding due to the fact that the algorithm works locally and can give priority to a vector that fulfills the equations of a graph cover rather than the graph itself .",
    "[ example : introduction ] consider the trivial length-@xmath0 and dimension-@xmath1 code @xmath2 defined by the @xmath3 parity - check matrix @xmath4 and whose tanner graph is shown in fig .",
    "[ fig : smallgraph:1 ]  ( left ) .",
    "a possible cubic cover of this tanner graph is also depicted in fig .",
    "[ fig : smallgraph:1 ] ( right ) . because @xmath5 is a valid configuration in this cubic cover ,",
    "the vector @xmath6 is a pseudo - codeword of the code @xmath7 defined by @xmath8 ( see  @xcite ) .",
    "it has been shown  @xcite that the performance of mpi decoding schemes for ldpc - bcs is largely dominated _ not _ by minimum hamming weight considerations but by minimum _ pseudo - weight _ considerations , where the minimum pseudo - weight in the case of an additive white gaussian noise channel ( awgnc ) is defined as @xmath9 where @xmath10 and @xmath11 are , respectively , the @xmath12-norm and @xmath13-norm , and @xmath14 is the set of all pseudo - codewords for the code @xmath7 defined by @xmath8 .",
    "the minimum pseudo - weight is a measure of the effect that decoding failures have on the performance of the code .",
    ", the minimum hamming weight may still be a key factor in performance analysis ; however , the larger the gap between @xmath15 and @xmath16 , the greater role the minimum pseudo - weight plays . in any case",
    ", the minimum hamming weight is important for quantifying the impact of undetectable errors . ] as a consequence , the large signal - to - noise ratio ( snr ) performance of mpi decoding can be worse than that predicted by the maximum - likelihood decoding union bound , which constitutes a major problem when trying to determine performance guarantees . addressing this problem from the convolutional - code perspective",
    ", i.e. , studying the pseudo - codeword problem described above for ldpc convolutional codes ( ldpc - ccs ) , constitutes the major topic of this paper .",
    "we investigate a class of time - invariant ldpc convolutional codes derived by `` unwrapping '' certain classes of quasi - cyclic ( qc ) ldpc block codes that are known to have good performance @xcite . unwrapping a qc block code to obtain",
    "a time - invariant convolutional code represents a major link between qc block codes and convolutional codes .",
    "this link was first introduced in a paper by tanner  @xcite , where it was shown that the free distance of the unwrapped convolutional code , if non - trivial , can not be smaller than the minimum distance of the underlying qc code .",
    "this idea was later extended in  @xcite .",
    "more recently , a construction for ldpc convolutional codes based on qc - ldpc block codes was introduced by tanner et al .",
    "@xcite , and a sliding - window mpi decoder was described . in that paper",
    "it was noted that the ( non - trivial ) convolutional versions of these codes significantly outperformed their block code counterparts in the waterfall region of the bit error rate ( ber ) curve , even though the graphical representations of mpi decoders were essentially equivalent .    throughout this paper",
    "we mainly take the approach of  @xcite , which connects the presence of pseudo - codewords in mpi decoding and linear programming ( lp ) decoding .",
    "lp decoding was introduced by feldman , wainwright , and karger  @xcite and can be seen as a relaxation of the maximum - likelihood decoding problem .",
    "more precisely , maximum - likelihood decoding can be formulated as the solution to an optimization problem , where a linear cost function is minimized over a certain polytope , namely the polytope that is spanned by the set of all codewords . for general codes",
    ", there is no efficient description of this polytope and so feldman et al",
    ".  suggested replacing it with an ( efficiently describable ) relaxed polytope , which in the following will be called the `` fundamental polytope '' .",
    "in other words , the decoding result of the lp decoder is the point in the fundamental polytope that minimizes the above - mentioned linear cost function .    in order to analyze the behavior of unwrapped ldpc convolutional codes under lp decoding , we need to examine the fundamental polytope  @xcite of the underlying qc - ldpc block codes .",
    "( because of symmetries , it is actually sufficient to study the structure of the fundamental polytope around the zero codeword , i.e. , it is sufficient to study the so - called fundamental cone . )",
    "our goal is to formulate analytical results ( or at least efficient procedures ) that will allow us to bound the minimum pseudo - weight of the pseudo - codewords of the block and convolutional codes .",
    "the paper aims at addressing this question and related issues . in the following sections",
    ", we will study the connections that exist between pseudo - codewords in qc codes and pseudo - codewords in the associated convolutional codes and show that this connection mimics the connection between the codewords in qc codes and the associated convolutional codes .      as a motivational example we simulated a rate @xmath17 @xmath18-regular ldpc - cc with syndrome former memory @xmath19 , together with three wrapped block code versions : a @xmath20 $ ] @xmath18-regular qc - ldpc block code , a @xmath21 $ ] code , and a @xmath22 $ ] code , with parity - check matrices of increasing circulant sizes @xmath23",
    ", @xmath24 , and @xmath25 , respectively , while keeping the same structure within each @xmath26 circulant  @xcite ( see section  [ sec : link : qc : and : conv : codes:1 ] ) .",
    "( note that increasing the circulant size of the qc code increases its complexity , i.e. , its block length .",
    "also note that each of the three block codes has rate slightly greater than @xmath27 . ) a sliding - window mpi decoder as in  @xcite was used to decode the convolutional code .",
    "conventional ldpc - bc mpi decoders were employed to decode the qc - ldpc block codes .",
    "all decoders were allowed a maximum of @xmath28 iterations .",
    "the resulting ber performance of these codes on a binary - input awgn channel is shown in fig .",
    "[ fig : compare:1 ] .",
    "we note that , particularly in the low - to - moderate snr region , where the complete pseudo - weight spectrum plays an important role , the unwrapped ldpc - cc performs between @xmath29 and @xmath30 better than the associated qc - ldpc block codes .",
    "also , as the circulant size increases , the performance of the block codes approaches that of the convolutional code .",
    "these performance curves suggest that the pseudo - codewords in the block code that result in decoding failures may not cause such failures in the convolutional code , which suggests that ldpc - ccs may have better iterative decoding thresholds than comparable ldpc - bcs ( see also  @xcite and  @xcite ) .    in order to underline the influence of pseudo - codewords under mpi decoding , we consider the following experiment .",
    "let @xmath31 be a _",
    "minimal pseudo - codeword _",
    "@xcite for the above - mentioned @xmath17 @xmath18-regular ldpc - cc , i.e. , a pseudo - codeword that corresponds to an _ edge of the fundamental cone _ of that ldpc - cc .",
    "moreover , we define the log - likelihood ratio vector @xmath32 to be is not squared , therefore this ratio does not correspond to the awgnc pseudo - weight of @xmath31 ( see sec .  [",
    "sec : pseudo : weight : comparison:1 ] ) , although it is closely related to that value .",
    "] @xmath33 we then run the mpi decoder that is initialized with @xmath34 and count how many iterations it takes until the decoder decides for the all - zero codeword as a function of @xmath35 and @xmath36 .",
    "the results are shown in fig .",
    "[ fig : alphabetaplot:1 ] .",
    "the meaning of @xmath32 is the following .",
    "if @xmath37 , then @xmath38 corresponds to the log - likelihood ratio vector that the receiver sees when the communication system operates at a signal - to - noise ratio @xmath39 and when the noise vector that is added by the binary - input awgn channel happens to be the all - zero vector ( see , e.g. , the discussion in  ( * ? ? ?",
    "3 ) ) . for non - zero @xmath35",
    "the expression for @xmath40 has been set up such that the lp decoder has a decision boundary at @xmath41 : for @xmath42 the all - zero codeword wins against the pseudo - codeword @xmath31 whereas for @xmath43 the all - zero codeword loses against the pseudo - codeword @xmath31 under lp decoding .",
    "the simulations in fig .",
    "[ fig : alphabetaplot:1 ] were obtained using a search algorithm that looked for a low - pseudo - weight minimal pseudo - codeword @xmath31 in the fundamental cone of the above - mentioned ldpc - cc .",
    "the @xmath31 that we found has awgnc pseudo - weight @xmath44 , which happens to be smaller than the free distance . secondly , we ran the mpi decoder for various choices of @xmath35 and @xmath36 : fig .",
    "[ fig : alphabetaplot:1 ]  left shows the number of iterations needed using a sum - product - algorithm - type mpi decoder whereas fig .",
    "[ fig : alphabetaplot:1 ]  right shows the number of iterations needed using a min - sum - algorithm - type mpi decoder .",
    "( note that the decisions reached by the latter are independent of the choice of @xmath36 , @xmath45 . ) because of the more oscillatory behavior of the min - sum - algorithm - type mpi decoder close to decision boundaries of the lp decoder , observed empirically , it is advantageous to run that decoder for many iterations in our scenario , whereas in the case of the sum - product - algorithm - type mpi decoder it hardly pays to go beyond @xmath46 iterations .      in this paper",
    ", we provide a possible explanation for the performance difference observed in the motivational example above .",
    "based on the results of  @xcite that relate code performance to the existence of pseudo - codewords , we examine the pseudo - codeword weight spectra of qc - ldpc block codes and their associated convolutional codes .",
    "we will show that for a non - trivial ldpc - cc derived by unwrapping a non - trivial qc - ldpc block code , the minimum pseudo - weight of the convolutional code is at least as large as the minimum pseudo - weight of the underlying qc code@xcite , i.e. , @xmath47    this result , which parallels the well - known relationship between the free hamming distance of non - trivial convolutional codes and the minimum hamming distance of their non - trivial quasi - cyclic counterparts  @xcite , is based on the fact that every pseudo - codeword in the convolutional code induces a pseudo - codeword in the block code with pseudo - weight no larger than that of the convolutional code s pseudo - codeword .",
    "this difference in the weight spectra leads to improved ber performance at low - to - moderate snrs for the convolutional code , a conclusion supported by the simulation results presented in fig .",
    "[ fig : compare:1 ] .",
    "the paper is structured as follows . in sec .  [",
    "sec : ps : qc : and : conv : codes:1 ] we develop the background necessary to describe the connection between pseudo - codewords in unwrapped ldpc convolutional codes and those in the associated qc - ldpc codes .",
    "thus , in sec .  [",
    "sec : link : qc : and : conv : codes:1 ] we briefly discuss the connection between convolutional codes and their associated qc codes , especially how codewords in the former can be used to construct codewords in the latter , and in sec .",
    "[ sec : fundam : cone : par : check : matrix:1 ] we define the fundamental polytope / cone of a matrix and show how we can describe the fundamental cone of a polynomial parity - check matrix through polynomial inequalities .",
    "we end the section by showing how pseudo - codewords in unwrapped ldpc convolutional codes yield pseudo - codewords in the associated qc - ldpc codes . in sec .",
    "[ sec : pseudo : weight : comparison:1 ] , we compare the pseudo - weights of unwrapped convolutional and their associated qc block codes . sec .",
    "[ sec : pseudo : weight : definitions:1 ] introduces various channel pseudo - weights and sec .  [ sec : pseudo : weight : inequality:1 ] presents the main result , namely that the minimum awgn pseudo - weight , the minimum binary erasure channel ( bec ) pseudo - weight , the minimum binary symmetric channel ( bsc ) pseudo - weight , and the minimum max - fractional weight of a convolutional code are at least as large as the corresponding minimum pseudo - weights of a wrapped qc block code .",
    "[ sec : analysis : problematic : pseudo : codewords : conv : codes:1 ] discusses a method to analyze problematic pseudo - codewords , i.e. , pseudo - codewords with small pseudo - weight .",
    "the method addresses the convolutional code case .",
    "it introduces two sequences of `` truncated '' pseudo - weights and , respectively , `` bounded pseudo - codeword '' pseudo - weights , that play an important role in identifying the minimum pseudo - weight of the convolutional code , similar to the role that column distances and row distances play in identifying the free distance .",
    "we end with some conclusions in sec .",
    "[ sec : conclusions:1 ] .      throughout the paper we will use the standard way of associating a tanner graph with a parity - check matrix and vice - versa .",
    "we will use the following notation .",
    "we let @xmath48 , @xmath49 , @xmath50 , and @xmath51 be the galois field of size @xmath13 , the field of real numbers , the set of non - negative real numbers , and the set of positive real numbers , respectively .",
    "if @xmath52 is a polynomial over some field and @xmath53 is some positive integer then @xmath54 denotes the polynomial @xmath55 of degree smaller than @xmath53 such that @xmath56 .",
    "we say that a polynomial @xmath57 with real coefficients is non - negative , and we write @xmath58 , if all its coefficients @xmath59 satisfy @xmath60 .",
    "similarly , a polynomial vector @xmath61 is non - negative , and we write @xmath62 , if all its polynomial components @xmath63 satisfy @xmath58 for all @xmath64 .",
    "moreover , a polynomial matrix @xmath65 is non - negative , and we write @xmath66 , if all its entries are non - negative polynomials .",
    "finally , for any positive integer @xmath53 and for any @xmath67 , @xmath68 will represent the @xmath69-times cyclically left - shifted identity matrix of size @xmath70 .",
    "we begin this section by presenting an important link between qc block codes and convolutional codes that was first introduced in a paper by tanner  @xcite and later extended in  @xcite .",
    "similar to the connection between codewords in an unwrapped convolutional code and codewords in the underlying qc code , we will show that pseudo - codewords in the convolutional code give pseudo - codewords when projected onto an underlying qc code .      in this section",
    "we introduce the background needed for the later development of the paper .",
    "note that all codes will be binary linear codes .",
    "any length @xmath71 quasi - cyclic ( qc ) code @xmath72 with period @xmath73 can be represented by an @xmath74 _ scalar _ block parity - check matrix @xmath75 that consists of @xmath76 circulant matrices of size @xmath26 . using the isomorphism between the ring of binary circulant matrices of size @xmath26 and the ring of polynomials @xmath77 / \\langle x^r - 1 \\rangle}$ ] of degree less than @xmath53 , we can associate with the scalar parity - check matrix @xmath75 the _ polynomial _ parity - check matrix @xmath78 / \\langle x^r - 1 \\rangle}\\big)^{j \\times l}$ ] , with polynomial operations performed modulo @xmath79 .",
    "due to the existence of this isomorphism , we can identify two descriptions , scalar and polynomial , and use either of the two depending on their usefulness .",
    "[ cubic : matrices ] the cubic cover @xmath80 of the trivial code in depicted in fig .",
    "[ fig : smallgraph:1 ] is a quasi - cyclic code with scalar parity - check matrix @xmath81 and corresponding polynomial parity - check matrix @xmath82 / \\langle x^r - 1 \\rangle}\\big)^{3 \\times 3}$ ] ( @xmath83 ) given by    @xmath84    by permuting the rows and columns of the scalar parity - check matrix @xmath75 ( i.e. , by taking the first row in the first block of @xmath53 rows , the first row of the second block of @xmath53 rows , etc .",
    ", then the second row in the first block , the second row in the second block , etc .",
    ", and similarly for the columns ) , we obtain the parity - check matrix @xmath85 of a code that is equivalent to @xmath86 .",
    "the scalar parity - check matrix @xmath85 has the form @xmath87 where the scalar @xmath88-matrices @xmath89 satisfy @xmath90 .",
    "[ cubic : matrices : decomposition ] the code in example  [ cubic : matrices ] has @xmath91 , where @xmath92    given the polynomial parity - check matrix of a qc - code , it is easy to see the natural connection that exists between quasi - cyclic codes and convolutional codes ( see , e.g. , @xcite ) .",
    "briefly , with any qc block code @xmath86 of length @xmath93 , given by a @xmath94 polynomial matrix parity - check matrix @xmath95 , with polynomial operations performed modulo @xmath79 , we can associate a rate @xmath96 convolutional code @xmath97 given by the same @xmath94 polynomial parity - check matrix @xmath98 , where the change of variables indicates the lack of modulo @xmath99 operations  @xcite .",
    "let the _ syndrome former memory _",
    "@xmath100 of @xmath97 be the largest integer in @xmath101 such that @xmath102 . then the polynomial parity - check matrix @xmath103 has the following scalar description ( see , e.g. , @xcite ) @xmath104 ( note that @xmath105 is a semi - infinite parity - check matrix . )",
    "[ conv : matrix ] unwrapping the code in example  [ cubic : matrices ] , we obtain a convolutional code with polynomial parity - check matrix @xmath106 given by @xmath107 the syndrome former memory is equal to 2 and the decomposition leading to the scalar matrix @xmath105 is @xmath108 where @xmath109 are the same matrices as in  .    in the same way as we obtained @xmath97 from @xmath86 , we can , upon choosing a positive integer @xmath53 , obtain a code @xmath110 from a given code @xmath111 .",
    ", i.e. ,  @xmath112 . some of the results can be stated for an arbitrary @xmath53 .",
    "] it easily follows that , similar to obtaining @xmath105 by unwrapping @xmath85 , @xmath85 is obtained from @xmath105 by suitably wrapping @xmath105 .",
    "this unwrapping / wrapping can also be observed in the tanner graph representations of @xmath113 and @xmath103 , as illustrated in fig .",
    "[ fig : tanner : graph:1 ] .",
    "we turn now our attention to codewords in these codes .",
    "codewords in @xmath86 will be denoted by a polynomial vector like @xmath114 and codewords in @xmath97 will be denoted by a polynomial vector like @xmath115 ( when the code is represented by a scalar parity - check matrix @xmath105 , then it will be denoted by a vector like @xmath116 ) .",
    "( we will later use a similar notation for pseudo - codewords . )    for any non - zero codeword @xmath115 with finite support in the convolutional code , its @xmath53 _ wrap - around _ ,",
    "defined by the vector @xmath117 / \\langle x^r - 1 \\rangle}\\big)^l$ ] , is a codeword in the associated qc - code , since @xmath118 in @xmath119 / \\langle x^r - 1 \\rangle}\\big)^l$ ] .",
    "in addition , the hamming weight of the two codewords is linked by the following inequality @xmath120 , which gives the inequality  @xcite ( we assume all codes are non - trivial ) @xmath121 moreover , we have the following inequalities .",
    "@xmath122    and @xmath123    let @xmath124 be a parity - check matrix of @xmath125 and @xmath126 be the corresponding parity - check matrix of @xmath86 .",
    "let @xmath114 be a nonzero codeword in @xmath127 of weight equal to the minimum distance @xmath128 .",
    "we have @xmath129 in @xmath119 / \\langle x^{2r } - 1 \\rangle}\\big)^l$ ] and since @xmath130 , it follows that @xmath131 in @xmath119 / \\langle x^r - 1 \\rangle}\\big)^l$ ] .",
    "if @xmath132 then we obtain the inequality @xmath133 if @xmath134 we can write @xmath135 with @xmath136 ( otherwise @xmath137 . ) hence @xmath138 or equivalently , @xmath139 , which implies that @xmath140 is a nonzero codeword in @xmath86 .",
    "the hamming weight @xmath141 mimicking this proof we also obtain @xmath142 and hence the desired inequality @xmath143    from the way we construct the semi - infinite sliding matrix of the convolutional by unwrapping the scalar parity - check matrix of the qc block code versions , we can see that there exists a qc code of circulant size @xmath53 large enough , so that its minimum distance is equal to the free distance of the convolutional code .",
    "this assures the limit equality above .",
    "if we denote by @xmath144 , @xmath145 , @xmath146 , @xmath147 the tanner graphs associated with the parity - check matrices of @xmath86 , @xmath148 , @xmath149 , @xmath147 of increasing size ( which are associated with the same polynomial matrix @xmath150 ) , it is easy to see that we obtain a _ tower of covers _ of the graph @xmath151 .",
    "the above relationship between the minimum distances of the codes in the tower is then easily verified in graph language , since a codeword @xmath115 in a larger graph , say @xmath149 , when projected onto the graphs of @xmath86 and @xmath148 using the formula @xmath152 , respectively , @xmath153 , gives another codeword .",
    "finally , the graph of the associated convolutional code is an infinite cover of each of the graphs in the tower .",
    "[ codewords ] using the graphs associated with the trivial code @xmath154 and its cubic cover @xmath80 having parity - check matrix @xmath81 ( see example  [ cubic : matrices ] ) corresponding to the codeword @xmath155 in @xmath7 , we can identify the codeword @xmath156 in @xmath80 .",
    "the polynomial description of @xmath116 is @xmath157 the wrap - around of @xmath114 @xmath158 , @xmath159 / \\langle x^r - 1 \\rangle}\\big)^3 , r=1 $ ] , gives the codeword @xmath160 in @xmath161 the associated convolutional code is trivially zero .      in this section",
    "we introduce our main object of study , the fundamental cone of a matrix , a set that contains all relevant pseudo - codewords  @xcite .",
    "[ def : fundamental : cone:1 ]    let @xmath8 be a binary matrix of size @xmath162 , let @xmath163 be the set of column indices of @xmath8 , and let @xmath164 be the set of row indices of @xmath8 , respectively .",
    "for each @xmath165 , we let @xmath166 be the support of the @xmath167-th row of @xmath8 .",
    "the _ fundamental polytope _",
    "@xmath168 of @xmath8 is then defined as @xcite @xmath169 where @xmath170 is the @xmath167-th row of @xmath8 , and @xmath171 is the convex hull of @xmath172 , defined as the set of convex combinations of points in @xmath172 when seen as points in @xmath173 .",
    "the _ fundamental cone _",
    "@xmath174 of @xmath8 is defined as the conic hull of the fundamental polytope @xmath175 , which includes the vertex @xmath176 , stretched to infinity .",
    "note that if @xmath177 , then also @xmath178 for any real @xmath179 .",
    "moreover , for any @xmath177 , there exists an @xmath179 ( in fact , a whole interval of @xmath35 s ) such that @xmath180.@xmath181    vectors in @xmath182 are called _ pseudo - codewords of @xmath8 _ , and we will call any vector in @xmath174 a pseudo - codeword and two pseudo - codewords that are equal up to a positive scaling constant will be considered to be equivalent .",
    "clearly , not all pseudo - codewords are codewords , but all codewords are pseudo - codewords",
    ".    the fundamental cone and polytope can both be described by certain sets of inequalities that are computationally useful  @xcite .",
    "since our study of pseudo - codewords will rely heavily on the fundamental cone , we now describe it in more detail .",
    "a vector @xmath183 is in the fundamental cone @xmath184 if and only if @xmath185    let @xmath186 $ ] be a parity - check matrix for the code @xmath187 @xmath188 .",
    "the fundamental polytope @xmath182 associated with @xmath8 is ( see fig .  [",
    "fig : polytope:1 ] ) @xmath189 from which we obtain the fundamental cone @xmath174 associated with @xmath8 : @xmath190 we see that the pseudo - codeword @xmath191 satisfies the inequalities of both the fundamental polytope and the fundamental cone . also , the pseudo - codeword @xmath192 and its positive multiples are in the fundamental cone but not necessarily in the fundamental polytope .    as explained briefly in sec .  [",
    "sec : introduction ] , pseudo - codewords can also be described using graph theory language as vectors corresponding to codewords in a cover graph .",
    "looking again at the cover tower @xmath193 ,",
    "@xmath145 , @xmath146 , @xmath147 , a codeword @xmath115 of a larger graph , say @xmath149 , seen as a vector with real components , when projected over @xmath49 onto the graphs of @xmath86 and @xmath148 , using the formula @xmath194 , respectively , @xmath153 , gives a pseudo - codeword .",
    "similarly , a codeword @xmath115 of the unwrapped convolutional code @xmath97 , when projected onto the graphs of @xmath86 @xmath148 , @xmath195 using the formulas @xmath152 , @xmath153 , @xmath196 , gives pseudo - codewords in the qc codes .",
    "let @xmath197 be the codeword identified in example  [ codewords ] for the code @xmath80 , with corresponding polynomial description @xmath198 . when projecting @xmath114 over @xmath49 onto the graph of @xmath154 we obtain @xmath199 , which is a pseudo - codeword in @xmath7 , equivalent to the pseudo - codeword @xmath200 presented in example  [ example : introduction ] .",
    "the fundamental cone of the convolutional code given by @xmath103 in example  [ conv : matrix ] is trivially zero , i.e. , it does not contain any non - zero pseudo - codewords .    in the above example we made the following important connection between two graphical ways of representing pseudo - codewords @xmath31 of a qc code @xmath7 of length @xmath201 as vectors corresponding to codewords @xmath114 in some qc code ( or convolutional code ) associated with an @xmath202-cover ( or an infinite cover ) of the graph of @xmath7 .",
    "we can see them as vectors with each entry representing an average of the ones attributed to the variable nodes of the cover graph that are in the `` cloud '' of that entry , e.  g. , @xmath200 , corresponding to pseudo - codewords in the polytope of @xmath7 , or we can see them as vectors that are the projections of @xmath114 onto the code @xmath7 by the formula @xmath152 , e.g. , @xmath203 , corresponding to pseudo - codewords in the fundamental cone of @xmath7 that are not necessarily in the polytope .",
    "in fact a similar statement can be made about pseudo - codewords in any block code @xmath7 of length @xmath201 , not having necessarily a qc structure .",
    "a pseudo - codeword @xmath31 in @xmath7 is a vector corresponding to some codeword @xmath116 in some block code ( or convolutional code ) associated with an @xmath202-cover ( or an infinite cover ) of the graph of @xmath7 with each entry representing an average of the ones attributed to the variable nodes of the cover graph that are in the `` cloud '' of that entry .",
    "however , this is the same , under the equivalence between different representations of a pseudo - codeword in the fundamental cone , as defining a pseudo - codeword @xmath31 as a vector for which there exists a cover corresponding to a block code or to a convolutional code , @xmath204 , of the code @xmath7 , and there exists some codeword , @xmath116 in @xmath204 , such that @xmath205 where the vector @xmath206 is equal to a permutation of the vector @xmath116 ( where the components of @xmath116 are taken in the following order @xmath207 ) .",
    "the vector @xmath208 it is seen as a vector with real entries and the modular operation @xmath209 is performed over the real numbers .",
    "the above description of the fundamental polytope and cone provides computationally easy descriptions of the pseudo - codewords , especially in the case of qc and convolutional codes . from   and",
    "it follows that for any parity - check matrix @xmath8 there is a matrix @xmath210 such that a vector @xmath31 is a pseudo - codeword in the fundamental code @xmath211 if and only if @xmath212 . in the case of qc and convolutional codes",
    ", the fundamental cone can be described with the help of polynomial matrices .",
    "namely , for any @xmath113 there is a polynomial matrix @xmath213 such that @xmath214 if and only if @xmath215 .",
    "similarly , for any @xmath103 there is a polynomial matrix @xmath216 such that @xmath217 if and only if @xmath218 .",
    "this fundamental - cone description is particularly simple and hence useful in the case of * monomial * parity - check matrices @xmath106 ( see  @xcite ) , since the fundamental - cone inequalities can then be stated very simply as follows .",
    "a vector @xmath31 is a pseudo - codeword in the fundamental cone of a monomial matrix @xmath219 if and only if the associated polynomial vector @xmath220 satisfies : @xmath221 equivalently , if @xmath222 is an @xmath223 matrix with @xmath224-th row vector @xmath225 for @xmath226 , then @xmath227 is a pseudo - codeword if and only if @xmath228 for all @xmath229 and @xmath230    [ ex : smallexample:1 ]    let @xmath231 be a polynomial parity - check matrix of a rate-@xmath232 convolutional code .",
    "the following vector @xmath233 corresponding to the scalar vector @xmath234 is a pseudo - codeword for the convolutional code since @xmath235 and the matrix @xmath236 gives @xmath237 i.e. , @xmath238 has all polynomial entries with non - negative coefficients .    similarly , for a qc code that is described by a * monomial * @xmath88 parity - check matrix @xmath113 , a vector @xmath239 is a pseudo - codeword in the corresponding fundamental cone if and only if the associated polynomial vector @xmath240 satisfies @xmath241 and @xmath242    [ ex : small : example : qc:1 ]    let @xmath243 be the @xmath244 parity - check matrix obtained from @xmath103 in example  [ ex : smallexample:1 ] for a qc block code of length @xmath245 .",
    "then , for the polynomial vector @xmath246 we obtain @xmath247 since @xmath248 and @xmath249 , we know that @xmath250 is a pseudo - codeword .",
    "the pseudo - codeword @xmath251 in example  [ ex : smallexample:1 ] was obtained by using a method to be described in sec .",
    "[ sec : analysis : problematic : pseudo : codewords : conv : codes:1 ] . projecting this pseudo - codeword in the convolutional code onto the @xmath53-wrapped qc code , for @xmath244",
    ", we obtained the pseudo - codeword @xmath252 in the qc code .",
    "this is not a mere coincidence as the following lemma shows .",
    "[ lemma : qc : vs : conv : code : pseudo : codeword:1 ]    let @xmath227 be a pseudo - codeword in the convolutional code defined by @xmath103 , i.e. , @xmath253 .",
    "then its @xmath53 wrap - around polynomial vector is a pseudo - codeword in the associated qc - code defined by @xmath113 , i.e. , @xmath254 .",
    "we have seen that for any @xmath103 describing a convolutional code there is a matrix @xmath216 such that a polynomial vector @xmath227 is a pseudo - codeword in the fundamental cone @xmath255 if and only if @xmath256 . by reducing @xmath216 modulo @xmath99",
    ", we obtain a matrix @xmath257 with the property that a polynomial vector @xmath239 is a pseudo - codeword in the fundamental cone @xmath258 if and only if @xmath259 . reducing @xmath256 modulo @xmath99",
    ", we obtain @xmath260 , which proves the claim .",
    "this result can be easily deduced using the graph - theory language at the end of sec .",
    "[ sec : link : qc : and : conv : codes:1 ] .",
    "indeed , looking again at the cover tower @xmath261 , a pseudo - codeword @xmath262 of a larger graph , say @xmath149 , when projected onto the graphs of @xmath86 and @xmath148 , using the formula @xmath263 , respectively , @xmath264 , gives another pseudo - codeword .",
    "similarly , a pseudo - codeword @xmath262 of the unwrapped convolutional code @xmath97 , when projected onto the graphs of @xmath86 @xmath148 , @xmath195 using the formulas @xmath265 , @xmath264 , @xmath266 gives pseudo - codewords in the qc codes .",
    "[ projecting : conv : pseudo - codewords ] the pseudo - codeword @xmath267 of the convolutional code in example  [ ex : smallexample:1 ] projects onto the following pseudo - codewords in the qc wrapped block code versions of parity - check matrix @xmath268 , for all @xmath269 : , as lemma  [ lemma : qc : vs : conv : code : pseudo : codeword:1 ] holds for each @xmath270 . ]",
    "this section begins with an introductory subsection in which various channel pseudo - weights are defined and continues with the main result that the minimum awgnc , bec , bsc , and max - fractional pseudo - weights of a convolutional code are at least as large as the corresponding pseudo - weights of a wrapped qc block code .",
    "@xcite let @xmath272 @xmath273 be a _",
    "nonzero _ vector in @xmath274 .",
    "the awgnc pseudo - weight and the bec pseudo - weight of the vector @xmath31 are defined to be , respectively , @xmath275 where @xmath276 and @xmath277 are the @xmath12-norm , respectively @xmath13-norm , of @xmath31 , and @xmath278 is the set of all indices @xmath279 corresponding to nonzero components @xmath280 of @xmath31 . in order to define the bsc pseudo - weight @xmath281 , we let @xmath282 be the vector of length @xmath283 with the same components as @xmath31 but in non - increasing order . now let @xmath284 then the binary symmetric channel ( bsc)-pseudo - weight @xmath281 is @xmath285 .",
    "finally , the fractional weight of a vector @xmath286^n$ ] and the max - fractional weights of a vector @xmath287 are defined to be , respectively , @xmath288 where @xmath289 is the infinite or max norm .",
    "for @xmath290 we define all of the above pseudo - weights , fractional weights , and max - fractional weights to be zero .",
    "@xmath181    a discussion of the motivation and significance of these definitions can be found in  @xcite .",
    "note that whereas the fractional weight has an operational meaning only for vertices of the fundamental polytope , the other measures have an operational meaning for any vector in the fundamental polytope or cone .",
    "note also that here @xmath291 and @xmath292 are defined for any vector in @xmath274 , whereas @xmath291 and @xmath292 in  @xcite are what we will call @xmath293 and @xmath294 .",
    "let @xmath295 be the pseudo - codeword in example  [ ex : smallexample:1 ] and let @xmath296 @xmath297 be its scalar vector description .",
    "then @xmath298 in order to compute @xmath281 , we let @xmath299 be the vector that lists the components of @xmath31 in non - increasing order . we obtain @xmath300 , since we need to add up @xmath301 ordered components of @xmath282 to obtain @xmath302 .",
    "finally @xmath303 , from which it follows that @xmath304 .    a measure of the effect that the pseudo - codewords have on the performance of a code is given by the minimum _ pseudo - weight _  @xcite @xmath305 where @xmath306 is the set of all non - zero vertices in the fundamental polytope @xmath182 and the pseudo - weights are the appropriate ones for each channel ( awgnc , bsc , and bec pseudo - weights ) and the minimum fractional and max - fractional weights .",
    "computing these values can be quite challenging , since the task of finding the set of vertices of @xmath182 is in general very complex .",
    "however , in the case of four of the above pseudo - weights ( the minimum awgnc , bsc , and bec pseudo - weights and the minimum max - fractional weight ) there is a computationally simpler description given by @xmath307 for the appropriate pseudo - weight .",
    "( note that there is no such statement for the minimum fractional weight ; see , e.g. ,  @xcite ) .",
    "let @xmath243 be the matrix of example  [ ex : small : example : qc:1 ] and let @xmath86 be the qc block code of length @xmath308 , with @xmath309 .",
    "the minimum distance is 6 and it is equal to the @xmath310 .",
    "( this was obtained using a vertex enumeration program for polytopes that lists all the minimal pseudo - codewords of a code , see  @xcite . )    [ remark : relationship : minium : weights:1 ]    in  @xcite it was shown that for any code defined by a parity - check matrix @xmath8 , the following inequalities hold : @xmath311 therefore , @xmath312 and @xmath313 can serve as lower bounds for @xmath314 , @xmath315 , and @xmath316 .",
    "in what follows , we compare the minimum pseudo - weights and minimum max - fractional weight of a qc block code to those of its corresponding convolutional code which we assume to have a fundamental cone containing non - zero vectors . in order to analyze the minimum pseudo - weight and minimum max - fractional weight ,",
    "it is sufficient to analyze the weights of the non - zero vectors in the fundamental cone . throughout this section , without loss of generality , all pseudo - codewords @xmath227 are assumed to have finite support . with @xmath317 .",
    "note that such polynomial vectors also fulfill @xmath318 . ]",
    "[ th : qc : vs : conv : code : pseudo : weight:1 ]    for the awgnc , bec , and bsc pseudo - weights , if @xmath319 , then @xmath320 therefore , if the fundamental cone of the convolutional code is not trivial ( i.e. , it contains non - zero vectors ) we obtain @xmath321    in the following , we need to analyze separately the awgnc , bec , and bsc pseudo - weights of @xmath227 and of its @xmath53 wrap - around @xmath322 .",
    "let @xmath323 be a pseudo - codeword",
    ". by assumption @xmath227 has finite support , i.e. ,  there exists an integer @xmath324 such that the maximal degree of any @xmath63 , @xmath64 , is smaller than @xmath324 .    * case 1 ( awgnc ) : * since @xmath325 and @xmath326 we obtain @xmath327 .    *",
    "case 2 ( bec ) : * since the components of the vector @xmath322 are obtained by adding in @xmath50 certain non - negative components of @xmath227 , it follows that @xmath328 and we obtain @xmath329 .",
    "* case 3 ( bsc ) : * in order to compare the bsc - pseudo - weight of the two vectors , we first need to arrange the components in decreasing order .",
    "let @xmath330 and @xmath331 be listings of all the coefficients of all the components of @xmath227 and @xmath332 , respectively , in non - increasing order . since @xmath333 , we obtain that @xmath334 , which gives @xmath335 .",
    "hence the two sequences of non - negative integers form two partitions , @xmath336 and @xmath337 , respectively , of @xmath338 .",
    "we fill the shorter partition with zeros so that both partitions have the same length , say @xmath339 .",
    "it is enough to show that @xmath340 for all @xmath341 , i.e. , that @xmath337 majorizes @xmath336 @xcite .",
    "we show first that @xmath342 .",
    "suppose the contrary , i.e. , @xmath343 . since @xmath344 for all @xmath345 , we obtain that @xmath346 for all @xmath345 .",
    "but @xmath347 , @xmath348 , was obtained by adding over @xmath50 a certain subset of the set @xmath349 .",
    "so there should be at least one @xmath350 that has @xmath351 in its composition , and hence @xmath352 .",
    "this is a contradiction , from which we obtain @xmath342 .",
    "we finish the proof by induction .",
    "namely , we want to show that from @xmath353 for some @xmath354 , it follows that @xmath355 . if @xmath356 then this induction step clearly holds .",
    "so , assume that @xmath357 .",
    "since @xmath358 , we can deduce that @xmath359 , and in fact all @xmath347 with @xmath360 , can not contain any @xmath361 with @xmath362 in its composition .",
    "hence all possible @xmath361 , @xmath363 , have occurred in the composition of @xmath347 for @xmath364 , which gives @xmath365 .",
    "this proves that @xmath337 majorizes @xmath336 and we obtain @xmath366    theorem  [ th : qc : vs : conv : code : pseudo : weight:1 ] implies that low - pseudo - weight vectors in the block code may correspond to higher pseudo - weight vectors in the convolutional code , but the opposite is not possible .",
    "this suggests that the pseudo - codewords in the block code that result in decoding failures may not cause such failures in the convolutional code , thereby resulting in improved performance for the convolutional code at low - to - moderate signal - to - noise ratios ( snrs ) .",
    "a similar bound also holds for the max - fractional weight , as shown in the next theorem .",
    "[ th : qc : vs : conv : code : max : frac : weight:1 ] if @xmath253 , then @xmath367 therefore , @xmath368    we have @xmath333 and @xmath369 which leads to @xmath370 it now follows that @xmath371    in the case of the fractional weight , it is easy to see that for any @xmath372 , we have @xmath333 , and hence @xmath373 . when comparing the minimum fractional weight of the convolutional and qc codes , we encounter a computatinally harder case , as these values must be computed over the set of nonzero pseudo - codewords that are vertices of the fundamental polytope .",
    "this is not an easy task , because a vertex pseudo - codeword in the convolutional code might not map into a vertex pseudo - codeword in the qc code .",
    "the theorem below , however , can be established .",
    "for its better understanding , we recall that @xmath374 has the following meaning  @xcite .",
    "let @xmath375 be the set of positions where bit flips occurred when using @xmath86 for data transmission over a bsc with crossover probability @xmath376 , @xmath377 . if @xmath378 , then lp decoding is correct .",
    "similarly , @xmath379 implies the following .",
    "if @xmath380 is the set of positions where bit flips occurred when using @xmath97 for data transmission over a bsc , then @xmath381 guarantees that lp decoding is correct .",
    "[ th : qc : vs : conv : code : frac : weight:1 ]    assume that we are using @xmath97 for data transmission over a bsc with cross - over probability @xmath376 , where @xmath377 , and that bit flips occur at positions @xmath380 .",
    "if @xmath382 , then lp decoding is correct .",
    "( note that on the right - hand side of the previous inequality we have @xmath374 and not @xmath379 . )",
    "we know that @xmath383 where step @xmath384 follows from  @xcite ( see also  @xcite ) and step @xmath385 follows from theorem  [ th : qc : vs : conv : code : max : frac : weight:1 ] .",
    "remember that @xmath386 has the following meaning  @xcite .",
    "let @xmath380 be the set of positions where the bit flips occured when using @xmath97 for data transmission over a bsc .",
    "if @xmath387 , then lp decoding is correct .    now , because the theorem statement assumes that @xmath388 , using   we have @xmath389 and so , according to the meaning of @xmath390 , lp decoding is correct .",
    ".the pseudo - weights of the pseudo - codewords in example  [ projecting : conv : pseudo - codewords ] . [ cols=\"^,^,^,^,^,^ \" , ]",
    "studying pseudo - codewords of small pseudo - weight , and , in particular ( since the minimum pseudo - weight is upper bounded by the minimum hamming weight ) , studying pseudo - codewords of pseudo - weight smaller than the minimum hamming weight , represents an important problem in the performance analysis of ldpc codes because it allows us to identify potential failures in mpi decoding .",
    "upper and lower bounds on the minimum pseudo - weight of a convolutional code can be obtained by exploiting the `` sliding '' structure of its semi - infinite parity - check matrix @xmath106 and some of its sub - matrices , which allows relatively easy computations by taking advantage of the increased sparseness compared to the corresponding parity - check matrix of an underlying qc code . on the one hand , this technique allows us to find certain existing low - weight pseudo - codewords , and on the other , it illustrates the advantage of using a convolutional code structure over a block code structure in pseudo - codeword analysis .",
    "in addition , similar to the possible increase in minimum distance expected when going from a qc code to its unwrapped convolutional version , we expect an increase in the minimum pseudo - weight of the convolutional code , leading to better performance compared to the original qc code .",
    "our theoretical results and experimental observations point strongly in this direction .",
    "we now explain briefly our technique .",
    "similar to associating with a convolutional code  @xcite an increasing sequence of _ column distances _",
    "@xmath391 , and a decreasing sequence of _ row distances _",
    "@xmath392 having the property that @xmath393 we define two sequences of pseudo - weights that prove helpful in identifying the overall minimum pseudo - weight .",
    "we recall that an encoder polynomial generator matrix @xmath394 of a rate @xmath395 convolutional code with encoder memory @xmath396 has associated with it a semi - infinite sliding generator matrix @xmath397 .",
    "let @xmath398 denote the @xmath399 submatrix of @xmath397 with rows indexed by the first @xmath167 block rows of @xmath397 and columns indexed by the first @xmath279 block columns of @xmath397 , and let @xmath400 the following two sequences of matrices @xmath401 and @xmath402 give us an increasing sequence of distances @xmath391 , @xmath403 , commonly called _",
    "column distances _ , associated with the first sequence , and a decreasing sequence of distances @xmath392 @xmath404 , commonly called _ row distances _ , associated with the second sequence .",
    "the column distance @xmath405 is a `` truncation '' distance , i.e. , it measures the minimum of the hamming weights of the vectors of length @xmath406 that constitute the first @xmath406 components of some codeword with non - zero first component .",
    "the row distance @xmath407 is a `` bounded codeword '' distance , i.e. , it measures the minimum of the hamming weights of the codewords with non - zero first component and of length @xmath406 or smaller , or equivalently , of polynomial degree @xmath408 or smaller .",
    "the column distances and row distances represent valuable lower bounds and , respectively , upper bounds , on the free distance that become increasingly tight with increasing @xmath408 , and , in the limit , become equal to the free distance .",
    "if similar sequences could be defined for pseudo - weights , they would prove helpful in identifying the overall minimum pseudo - weight .    with this in mind , we define corresponding sequences of `` truncated '' pseudo - weights and `` bounded pseudo - codeword '' pseudo - weights .",
    "let @xmath150 be a polynomial parity - check matrix for a convolutional code @xmath97 with syndrome former memory @xmath409 , and let @xmath105 be its semi - infinite sliding parity - check matrix .",
    "similar to the notation above , let @xmath410 be the @xmath411 submatrix of @xmath105 with rows indexed by the first @xmath167 block rows of @xmath105 and columns indexed by the first @xmath279 block rows of @xmath105 .",
    "we will consider two sequences of such sub - matrices : @xmath412 in which @xmath413 is the @xmath414 submatrix of the @xmath415 matrix @xmath416 formed by its first @xmath417 columns , for all @xmath418 , and @xmath419 in which @xmath420 is the @xmath421 submatrix of the @xmath422 matrix @xmath423 formed by its first @xmath424 rows , for all @xmath418 .",
    "in the first sequence , the first matrix that has with certainty a nonzero nullspace is @xmath425 , since there is a nonzero polynomial codeword of degree @xmath396 ( associated with a scalar codeword of length @xmath426 ) . since @xmath427^{\\mathsf{t}}=0 $ ]",
    ", these matrices act like parity - check matrices in computing the row distances , with @xmath428 giving the @xmath408-th row distance , for all @xmath429 .",
    "there might be nonzero nullspaces earlier in the sequence , so we denote by @xmath430 the first matrix with a non - zero nullspace .",
    "obviously this would mean that @xmath431 is the first matrix in the second sequence @xmath432 , to have a nonzero nullspace .",
    "similarly , @xmath433 will act like parity - check matrices in computing the @xmath408th column distances .",
    "so by computing the nullspaces of these parity - check matrices we get upper and lower bounds on @xmath434 for the convolutional code that are similar to the column and row distances defined from the generator matrix .",
    "we remark also that if we wrap the convolutional code modulo @xmath79 , with @xmath435 , then the matrix @xmath430 is a submatrix of the parity - check matrix @xmath75 of the qc code that remains unchanged after the wrapping .",
    "hence a codeword of minimum weight for the matrix @xmath430 will be , if extended by zeros , a codeword in the qc code .",
    "if this codeword has weight equal to the minimum distance of the qc code , then the free distance of the convolutional code is equal to the weight of this codeword .",
    "the minimum distance of the qc code could be smaller , however , and in this case the free distance will only be upper bounded by the weight of this codeword and lower bounded by the minimum distance of the qc code .    in what follows",
    "we will mimic the theory of row distances and column distances of a convolutional codes to bound the minimum pseudo - weight of the convolutional code .",
    "we obtain upper and lower bounds on the minimum pseudo - weight of the convolutional code as follows :    @xmath436    as above , we will denote by @xmath437 and @xmath438 , respectively , the first matrices in the above sequences whose fundamental cones contain a non - zero vector .",
    "so by computing vectors in the fundamental cones of these parity - check matrices we get upper and lower bounds on @xmath439 for the convolutional code that are similar to the column and row distances defined from the generator matrix .",
    "the pseudo - codeword in example  [ ex : smallexample:1 ] was obtained by attempting to compute small degree non - zero vectors in the fundamental cone of @xmath440 using the above technique .",
    "the first nonzero `` row pseudo - weight '' is @xmath441 , and the vector @xmath442 is in the fundamental cone of @xmath443 .",
    "its awgn pseudo - weight is @xmath444 , which is an upper bound on the minimum pseudo - weight of the convolutional code .",
    "the free distance of this code is @xmath445 .",
    "the reduced pseudo - codeword @xmath446 modulo @xmath447 , for @xmath448 has the same weight @xmath444 , larger than the minimum distance of the @xmath449 $ ] code , which makes this pseudo - codeword irrelevant , but smaller than the minimum distances of the codes @xmath450 $ ] , @xmath451 $ ] , @xmath452 $ ] .",
    "the upper bound @xmath453 in example  [ smallexample2 ] therefore becomes @xmath454 based on this pseudo - codeword .",
    "this computational method has been applied successfully to larger codes as well .",
    "an example is the rate @xmath17 ldpc - cc with syndrome former memory @xmath19 that was simulated in fig .",
    "[ fig : compare:1 ] .",
    "the code was constructed by unwrapping a @xmath455 $ ] @xmath18-regular qc - ldpc block code with minimum hamming distance @xmath456 .",
    "the convolutional code has free distance @xmath457 , which already suggests a possible performance improvement compared to the qc code . following the approach described above",
    ", we constructed a class of pseudo - codewords for which we obtained a minimum pseudo - weight of @xmath458 .",
    "thus this class of pseudo - codewords contains vectors of weight less than the free distance , which makes them relevant to the performance analysis of iterative decoding .",
    "consequently , an upper bound on the minimum pseudo - weight of the convolutional code is @xmath458 , and , from the way we constructed this class of pseudo - codewords , we believe it is a very tight bound . projecting this pseudo - codeword onto the qc codes obtained by wrapping the convolutional code gives upper bounds on the minimum pseudo - weight of these codes as well ( in some cases tighter than the ones obtained using the methods of  @xcite ) .",
    "the upper bound in  @xcite for the minimum pseudo - weight of the @xmath20 $ ] code is @xmath459 .",
    "these upper bounds together with our simulation curves suggest that the minimum pseudo - weight of the convolutional code is strictly greater than the minimum pseudo - weight of the [ 155,64 ] qc code .",
    "an evaluation of the exact values of the minimum pseudo - weight in this cases is not possible , however , due to the large complexity of such a task .",
    "also note that if an upper bound on the minimum pseudo - weight of the convolutional code smaller than @xmath459 could be found , it would decrease the upper bound on the minimum pseudo - weight of the @xmath20 $ ] @xmath18-regular qc - ldpc block code as well .",
    "for an ldpc convolutional code derived by unwrapping an ldpc - qc block code , we have shown that the free pseudo - weight of the convolutional code is at least as large as the minimum pseudo - weight of the underlying qc code .",
    "this result suggests that the pseudo - weight spectrum of the convolutional code is `` thinner '' than that of the block code .",
    "this difference in the weight spectra leads to improved ber performance at low - to - moderate snrs for the convolutional code , a conclusion supported by the simulation results presented in figs .",
    "[ fig : compare:1 ] and  [ fig : compare : small:1 ] .",
    "we also presented three methods of analysis for problematic pseudo - codewords , i.e. ,  pseudo - codewords with small pseudo - weight .",
    "the first method introduces two sequences of `` truncated '' pseudo - weights and , respectively , `` bounded pseudo - codeword '' pseudo - weights , which lower and upper bound the minimum pseudo - weight of the convolutional code , similar to the role that column distances and row distances play in bounding from below and above the free distance .",
    "the other two methods can be applied to any qc or convolutional code and consist of projecting codewords with small weight in qc codes or convolutional codes onto tanner graph covers of the code .",
    "r.  smarandache , a.  e. pusane , p.  o. vontobel , and d.  j. costello , jr .",
    ", `` pseudo - codewords in ldpc convolutional codes , '' in _ proc .  ieee intern .  symp .  on inform .",
    "theory _ , seattle , wa , usa , july 914 2006 , pp . 13641368 .",
    "o. vontobel and r.  koetter , `` graph - cover decoding and finite - length analysis of message - passing iterative decoding of ldpc codes , '' _ submitted to ieee trans .  inform .",
    "theory , available online under _ ` http://www.arxiv.org/abs/cs.it/0512078`_ _ , dec .",
    "2005 .",
    "g.  d. forney , jr .",
    ", r.  koetter , f.  r. kschischang , and a.  reznik , `` on the effective weights of pseudocodewords for codes defined on graphs with cycles , '' in _ codes , systems , and graphical models ( minneapolis , mn , 1999 ) _ , ser .",
    "i m a vol .",
    "b.  marcus and j.  rosenthal , eds.1em plus 0.5em minus 0.4emspringer verlag , new york , inc .",
    ", 2001 , vol .",
    "101112 .",
    "r.  m. tanner , d.  sridhara , a.  sridharan , t.  e. fuja , and d.  j. costello , jr .",
    ", `` ldpc block and convolutional codes based on circulant matrices , '' _ ieee trans .  on inform .",
    "theory _ , vol .",
    "it50 , no .",
    "29662984 , dec . 2004 .",
    "a.  sridharan , d.  j. costello , jr . , d.  sridhara , t.  e. fuja , and r.  m. tanner , `` a construction for low density parity check convolutional codes based on quasi - cyclic block codes , '' in _ proc .",
    "ieee intern .",
    "symp .  on inform .",
    "theory _ , lausanne , switzerland , june 30july 5 2002 , p. 481 .",
    "r.  m. tanner , `` convolutional codes from quasi - cyclic codes : a link between the theories of block and convolutional codes , '' _ university of california , santa cruz , tech report ucsc - crl-87 - 21 _ , nov . 1987 .",
    "y.  levy and d.  j. costello , jr .",
    ", `` an algebraic approach to constructing convolutional codes from quasi - cyclic codes , '' in _ coding and quantization ( piscataway , nj , 1992 ) _ , ser .",
    ". discrete math .",
    "sci.1em plus 0.5em minus 0.4emprovidence , ri : amer .",
    ". , 1993 , vol .",
    "14 , pp . 189198 .",
    "a.  sridharan , m.  lentmaier , k.  s. zigangirov , and d.  j. costello , jr . , `` convergence analysis of ldpc convolutional codes on the erasure channel , '' in _ proc .",
    "42nd allerton conf .  on communications , control , and computing _ ,",
    "allerton house , monticello , illinois , usa , sep .",
    "29oct .  1 2004 .",
    "o. vontobel and r.  koetter , `` on the relationship between linear programming decoding and min - sum algorithm decoding , '' in _ proc .  intern .",
    "symp .  on inform .",
    "theory and its applications ( isita ) _ , parma , italy , oct .",
    "1013 2004 , pp . 991996 .",
    "j.  feldman , `` decoding error - correcting codes via linear programming , '' ph.d .",
    "dissertation , massachusetts institute of technology , cambridge , ma , 2003 , available online under ` http://www.columbia.edu/~jf2189/pubs.html ` .",
    "j.  feldman , t.  malkin , c.  stein , r.  a. servedio , and m.  j. wainwright , `` lp decoding corrects a constant fraction of errors , '' in _ proc .",
    "ieee intern .",
    "symp .  on inform .",
    "theory _ , chicago , il , usa , june 27july 2 2004 , p.  68 .",
    "d.  avis , `` a revised implementation of the reverse search vertex enumeration algorithm '' , in _ polytopes  combinatorics and computation _ , birkhuser - verlag , pp . 177198 , 2000 , programs are available online under _ `",
    "http://cgm.cs.mcgill.ca/~avis/c/lrs.html ` _"
  ],
  "abstract_text": [
    "<S> message - passing iterative decoders for low - density parity - check ( ldpc ) block codes are known to be subject to decoding failures due to so - called pseudo - codewords . </S>",
    "<S> these failures can cause the large signal - to - noise ratio performance of message - passing iterative decoding to be worse than that predicted by the maximum - likelihood decoding union bound .    in this paper </S>",
    "<S> we address the pseudo - codeword problem from the convolutional - code perspective . </S>",
    "<S> in particular , we compare the performance of ldpc convolutional codes with that of their `` wrapped '' quasi - cyclic block versions and we show that the minimum pseudo - weight of an ldpc convolutional code is at least as large as the minimum pseudo - weight of an underlying quasi - cyclic code . </S>",
    "<S> this result , which parallels a well - known relationship between the minimum hamming weight of convolutional codes and the minimum hamming weight of their quasi - cyclic counterparts , is due to the fact that every pseudo - codeword in the convolutional code induces a pseudo - codeword in the block code with pseudo - weight no larger than that of the convolutional code s pseudo - codeword . </S>",
    "<S> this difference in the weight spectra leads to improved performance at low - to - moderate signal - to - noise ratios for the convolutional code , a conclusion supported by simulation results .    </S>",
    "<S> * index terms *  convolutional codes , quasi - cyclic codes , low - density parity - check ( ldpc ) codes , linear programming decoding , message - passing iterative decoding , pseudo - codewords , pseudo - weights . </S>"
  ]
}