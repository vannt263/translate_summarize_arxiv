{
  "article_text": [
    "for a point set @xmath0 and a point @xmath1 in @xmath2^d$ ] , the local star discrepancy @xmath3 of @xmath4 in @xmath1 measures the absolute difference between the volume of the box @xmath5 and the fraction of points of @xmath4 that are inside that box , cf .  figure  [ fig : localstardisc ] .",
    "the star discrepancy of @xmath4 is the largest such value ; i.e. , @xmath6^d}{{d_{\\infty}^*}(x , y)}$ ] .     in @xmath1",
    "is @xmath7 . ]",
    "star discrepancies are deeply related to the ubiquitous task of numerical integration but have found several applications also in computer graphics , pseudorandom number generators , experimental design , and option pricing , to name but a few domains .",
    "the approximation error of monte carlo and quasi - monte carlo methods can be expressed in terms of the star discrepancy . to be more precise ,",
    "let @xmath8^d \\rightarrow { \\mathbb{r}}$ ] be a function for which we want to compute the integral @xmath9^d}{f(s){\\rm d}s}$ ] .",
    "the koksma - hlawka inequality  @xcite states that , for suitable @xmath10 , the difference between this integral and the average function value of @xmath10 on a point set @xmath4 is bounded by @xmath11^d}{f(s ) { \\rm d}s } - \\frac{1}{n}\\sum_{i=1}^n{f(x^{(i ) } ) } \\right| \\leq v(f)\\cdot { d_{\\infty}^*}(x)\\ , , \\label{eq : koksma}\\ ] ] where @xmath12 denotes the so - called variation in the sense of hardy and krause .",
    "since @xmath12 depends only on @xmath10 and not on @xmath4 , the smaller the discrepancy @xmath13 , the better approximation we can expect .    while the points @xmath14 in eq .",
    "[ eq : koksma ] are chosen randomly in monte carlo integration , it has been known for a long time that we can achieve better results by evaluating @xmath10 in _ low discrepancy point sets_. thus , in quasi - monte carlo numerical integration , the set @xmath15 is chosen deterministically , so that the factor @xmath13 in eq .  [",
    "eq : koksma ] is as small as possible .",
    "it is thus one of the main challenges in numerical analysis to compute explicit point sets @xmath4 of smallest possible star discrepancy value .      in this work",
    ", we present a new algorithm for constructing low discrepancy point sets .",
    "in particular , we provide improved upper bounds for the following two questions .    1 .   _",
    "star discrepancy : _ for given @xmath16 and @xmath17 , what is the smallest star discrepancy that can be achieved by an @xmath16-point configuration in @xmath18 ?",
    "inverse star discrepancy : _ for given @xmath17 and @xmath19 , what is the smallest possible value of @xmath16 such that there exists a set @xmath20 of size @xmath21 such that @xmath22 ?",
    "note that the first question asks where to place the @xmath16 points such that the irregularity measured by the star discrepancy is as small as possible , while the second question is even more involved .",
    "it asks us to decide how many points we need and ( indirectly ) where to place them , such that the resulting irregularity is at most @xmath19 .",
    "our algorithm has originally been developed to address the first question .",
    "however , it turns out that , using a bisection approach and multi - objective selection ( see section  [ sec : algorithm ] ) , we can easily adapt it to answer also the second question .",
    "our algorithm builds on previous work presented in  @xcite on the construction of low @xmath23-discrepancy sequences ( see  @xcite for an earlier gecco version ) and in  @xcite on the evaluation of the star discrepancy of a given point set .",
    "it has two components , an _ optimization component _ , which computes candidate point sets , and an _ evaluation component _ for assessing the quality of the proposed solutions . during the optimization process",
    ", the evaluation component is called several times .",
    "the two components of the algorithm will be described in section  [ sec : algorithm ] . on the structure of the algorithms",
    "we note here only that the optimization part is based on a genetic algorithm , while the evaluation component is based on threshold accepting ( ta)a variant of simulated annealing with derandomized selection rules .",
    "evaluating the star discrepancy of a given point set @xmath4 is known to be np - hard  @xcite .",
    "in fact , it is even w[1]-hard in @xmath17  @xcite , implying that , under standard complexity assumptions , there is no algorithm to evaluate the star discrepancy of @xmath16 points in @xmath17 dimension in a running time @xmath24 .",
    "the best known exact algorithm for evaluating discrepancies , the dem - algorithm , has a running time of @xmath25  @xcite . for most relevant settings",
    "this is too slow to be applicable .",
    "this is true in particular for our setting , where many candidate point sets need to be evaluated .",
    "in fact , the complexity of star discrepancy evaluation is the main reason why only few algorithmic approaches are known for the explicit construction of low star discrepancy point sets , cf .",
    "also the comment in  @xcite .",
    "a new robust algorithm to estimate star discrepancy values has been proposed in  @xcite .",
    "this algorithm has been reported to give very accurate discrepancy estimates , and our experiments confirm these statements .",
    "we thus use this algorithm for the intermediate discrepancy evaluations ; i.e. , for the optimization process of creating good candidate point configurations .",
    "where feasible , we do a final evaluation of the candidate sets using the exact dem - algorithm described above .      an introduction to the star discrepancy problem",
    "is given in section  [ sec : stardisc ] .",
    "we discuss there also the issue of computing star discrepancy values , and we introduce the generalized halton sequence , for which our algorithm finds good generating vectors .",
    "the algorithm itself is presented in section  [ sec : algorithm ] .",
    "section  [ sec : results ] surveys our empirical results . for the star discrepancy problem",
    "we compare our results with those presented in  @xcite .",
    "the point sets computed by our algorithm clearly outperform those reported there .",
    "we also show that our algorithm produces surprisingly good bounds for the inverse star discrepancy problem , thus easily answering one of the subproblems in open question 42 from  @xcite .",
    "our bounds for all three subproblems are better by a factor  ( ! ) of 5 to 7 compared to what was asked for in  @xcite , but for two subproblems our values are computed only by the algorithms from  @xcite and need to be verified by computations with the dem - algorithm .",
    "throughout this work , we denote by @xmath16 the size of the set @xmath26 under consideration and by @xmath17 the dimension of the problem instance .    for a point @xmath27^d$ ] the local discrepancy of @xmath1 with respect to @xmath4 is defined by @xmath28 where @xmath29 denotes the lebesgue volume of the box @xmath5 and @xmath30 is the number of points of @xmath4 that fall into this box .",
    "the discrepancy of @xmath4 is @xmath31^d } { { d_{\\infty}^*}(y , x)}\\,,\\end{aligned}\\ ] ] the largest local discrepancy value .",
    "it has been observed in  @xcite that the computation of @xmath13 can be discretized .",
    "in fact , if we let @xmath32 , the set of @xmath4-values in the @xmath33th coordinate ( @xmath34 ) , and @xmath35 be the _ grid spanned by _",
    "@xmath4 , then @xmath36 where @xmath37 is simply the number of points of @xmath4 that fall into the _ closed _",
    "box @xmath38 $ ] .",
    "that is , instead of evaluating the continuous space @xmath2^d$ ] , the search space can be reduced to a discrete one of size @xmath39 , cf .  figure  [ fig : grid ] .     is obtained in one of the grid points @xmath40 . ]    however , for most practical purposes , @xmath41 function evaluations are way too many , and one has to resort to different methods for evaluating star discrepancy values . as mentioned in the introduction ,",
    "computing the star discrepancy of a given point set is known to be a hard problem , and the best known exact algorithm , the dem - algorithm from  @xcite , has a running time of @xmath25 . a new promising algorithm for _ approximate _ star discrepancy evaluation has been presented in  @xcite .",
    "we discuss this algorithm in sec .",
    "[ sec : fitnessevaluation ] .",
    "given the importance of low star discrepancy point sequences in numerical integration and its various other applications in computer science , it is thus mainly due to the complexity of evaluating star discrepancies that not much work has been done in the search heuristics community to construct low star discrepancy point sequences . on the other hand , there has been some effort to construct low discrepancy point sets for other measures of irregularity , see , for example , the work in  @xcite , which constructs point sets that are optimized for _ hickernell s modified @xmath23-discrepancy_a measure that can be computed efficiently in @xmath42 arithmetic operations .",
    "see  @xcite for a recent survey on the computation of geometric discrepancies .      the ultimate goal of star discrepancy theory is to find , for given parameters @xmath16 and @xmath17 , a set @xmath20 of size @xmath21 such that @xmath13 is as small as possible .",
    "a closely related question of similar practical and theoretical relevance is the _ inverse star discrepancy _ problem : for given @xmath17 and @xmath43 , what is the smallest integer @xmath16 such that there exists a point set @xmath4 of size @xmath21 satisfying @xmath22 .    since the early twentieth century",
    ", a lot of work has been done to address these two questions , see  @xcite for recent surveys .",
    "many different low discrepancy sequences have been defined ( e.g. , sobol , faure , and halton sequences ) , and theoretical bounds on their performance have been proven .",
    "furthermore , general lower bounds for the star discrepancy of any @xmath16-point set in @xmath17 dimensions exist .",
    "however , the problem with all these bounds ( in the interest of space , we can not give a detailed survey here but we refer to  @xcite for a concise summary of the known bounds ) is that they are either asymptotic statements ( and thus of limited relevance in the regime of practical interest ) or the precision of the results is not accurate enough to allow for a comparison between the different constructions .",
    "we note also that there is a gap between all known lower bounds and the best known upper bounds for the star discrepancy problem .",
    "it thus remains a challenging open question to construct such point sets , and it is a well suitable problem for demonstrating the strength of bio - inspired approaches for classical optimization challenges .    in  @xcite ,",
    "the candidates for the @xmath23-optimized point sets are so - called _ generalized halton sequences_. since these point sets exhibit not only low @xmath23 discrepancies , but also low star discrepancies , we use here the same construction for finding our candidate sets .",
    "given the lack of space , we give here only the required definitions of the point sets , and we refer the interested reader to  @xcite and the books  @xcite or the recent survey  @xcite for further information on generalized halton sequences .    * the generalized halton sequence .",
    "* the halton sequence  @xcite is a generalization of the one - dimensional _ van der corput sequence _  @xcite . for any prime number @xmath44 the @xmath45th number of this latter sequence in base @xmath46 ,",
    "is given by @xmath47 where @xmath48 is the digital expansion of @xmath45 in base @xmath46 ; i.e. , @xmath49 .",
    "the multidimensional halton sequence is simply obtained by grouping together van der corput sequences of different bases .",
    "more precisely , let @xmath50 be the first @xmath17 prime numbers .",
    "the @xmath45th element of the @xmath17-dimensional halton sequence is given by @xmath51    the halton sequence is a low - discrepancy sequence ; i.e. , its first @xmath16 points @xmath52 in dimension @xmath17 satisfy the star discrepancy bound @xmath53 in fact , the halton sequence was the first construction for which eq .",
    "[ halton_bound ] was verified for any dimension @xmath17",
    "@xcite , and up to now there is no sequence known that exhibits a better asymptotic behavior .    nevertheless , the halton sequence suffers from strong correlation between the sequences in high dimensions , thus motivating braaten and weller  @xcite to suggest a _",
    "generalized _ ( also referred to as _ scrambled _ ) _ halton sequence _ . in this sequence , eq .  [ eqn : vdc ] is replaced by @xmath54 where @xmath55 is a permutation of @xmath56 with fixpoint @xmath57 ( so that @xmath58 ) .",
    "the @xmath45th element of the @xmath17-dimensional generalized halton sequence is then defined by @xmath59 where we abbreviate @xmath60 .    to answer the discrepancy question ,",
    "we thus need to find a vector of permutations @xmath61 such that the star discrepancy of the point set @xmath62 is as small as possible . since the point set is completely determined by the permutations @xmath61 , we call @xmath61 the _ generating vector of _ @xmath63 .",
    "the optimization of the generating vectors for the generalized halton sequence is made with a very simple genetic algorithm . as presented in algorithm [ algo : opt ] , a @xmath64 scheme is used . in each generation",
    "an offspring population @xmath65 of @xmath66 individuals is generated from the parental population @xmath67 .",
    "each individual is produced using either mutation or crossover according to some probabilities .",
    "the new individuals are evaluated ( @xmath68 in line  [ line : evaluation ] ) and the parents reevaluated ( @xmath69 in line  [ line : reevaluation ] ) with respect to the discrepancy of the point set that they generate .",
    "the selection of the next generation parental population is made based on the fitness of the individuals of both populations @xmath67 and @xmath65 .",
    "we use as stopping criterion a fixed number of generations .",
    "this section describes in more detail each component of the genetic algorithm .",
    "initialize @xmath70      following a similar procedure as in @xcite , we optimize over the generating vector @xmath61 of the generalized halton sequence .",
    "the difference of our work compared to @xcite is the objective function@xcite considers @xmath23-discrepancies while we optimize for star discrepancy  and the fact that here in our work , we are interested in generating low star discrepancy _ point sets _ , not _",
    "sequences_. this allows us to do the optimization for all the permutations at the same time ( since we do not need to find a configuration that would be good also for all smaller number of points ) .",
    "therefore , we use an adjusted implementation of the algorithm from  @xcite .    for the optimization of a @xmath17-dimensional point set , the genotype of the individuals contains @xmath71 independent permutations .",
    "by definition , the first permutation of the generating vector is always @xmath72 $ ] since the first prime number @xmath73 is 2 and we require that @xmath74 always . for the same reasons ,",
    "the second permutation @xmath75 is either @xmath76 $ ] or @xmath77 $ ] and the third one , @xmath78 is chosen from all @xmath79 possible permutations of @xmath80 with @xmath81 . for technical reasons ,",
    "the @xmath82 is removed from the permutations in the genotype , and we call the permutation itself ( with the prepending 0 ) the _ configuration_. finally , the point set @xmath4 is generated by eq .",
    "[ eqn : ghalton ] with the generating vector @xmath61 set to the configuration constructed from the genotype .",
    "an example showing the translation from a genotype into a phenotype for a 4-dimensional point set is given in figure  [ fig : representation ] .",
    "as seen in algorithm  [ algo : opt ] , crossover and mutation are used to produce the offspring .",
    "these operators , when applied on an individual , affect all underlying permutation vectors of its genotype .",
    "the crossover chosen is the partially matched crossover @xcite ; it chooses two crossover points and exchanges the alleles between these two points .",
    "the mutation is a uniform partial reordering of the alleles as presented in @xcite ; the reordered alleles are chosen by a uniform matching probability .",
    "both operators preserve the validity of a permutation representation ; i.e. , the resulting offspring are again permutations of the required length .      naturally , the fitness of the individuals is the star discrepancy of the point set that they generate ; i.e. , the star discrepancy of their phenotype .",
    "we aim at minimizing this value . to assess the discrepancy values we use two different algorithms , the dem - algorithm proposed in  @xcite and the ta - algorithm from  @xcite .",
    "the dem - algorithm is an exact algorithm for computing the star discrepancy of a given point set .",
    "it is based on dynamic programming and has a running time of @xmath25 .",
    "the algorithm has been implemented by m. wahlstrm and is available from  @xcite .",
    "we use his implementation to evaluate point sets for up to 9 dimensions . for these point sets ,",
    "the reevaluation step in line  [ line : reevaluation ] of algorithm  [ algo : opt ] can be skipped .",
    "where the exact dem - algorithm has an infeasible running time , we resort to the ta - heuristic proposed in  @xcite . this algorithm gives a lower bound for the discrepancy of a point set and we use this lower bound to guide our optimization procedure .    in the interest of space",
    ", we can not give a full description of this ta - approach but provide only a high level overview .",
    "the goal of the ta - algorithm is to find a good ( i.e. , large ) lower bound for the star discrepancy of the given point set @xmath4 . to this end , it performs a guided random search on the grid spanned by @xmath4 , cf .  section  [ subsec : computation ] .",
    "the algorithm uses a @xmath83 scheme ; i.e. , it keeps one individual at a time . in each iteration ,",
    "an offspring is created by sampling according to some probability distribution from the neighborhood of the parent individuum .",
    "the local star discrepancy is computed , and the offspring replaces the parent if its local discrepancy value is larger than or at least not much smaller than the parent s one .",
    "the `` not much smaller part '' is quantified by a threshold value @xmath84 ; i.e. , we replace the parent grid point @xmath46 by the offspring point @xmath85 if and only if @xmath86 . the threshold value changes over time , and converges to @xmath82 so that the algorithm finally outputs a local maximum of the star discrepancy value of @xmath4 .    in order to gain precision on our estimation ,",
    "the ta - algorithm is reapplied on the parental population in each generation ( line  [ line : reevaluation ] ) and the individual s fitness is the maximum value of the current estimate and the newly calculated one .",
    "for the final candidate point sets we increase the accuracy of our star discrepancy estimation by performing an additional 50 runs of the ta - algorithm .",
    "these values either re - affirmed the previously computed ones , or they give a slightly larger bound on the star discrepancy of the point set , deviating by at most 5 to 10@xmath87 from the previous values .",
    "we note that for all reference point sets for which we know the exact discrepancy , we also do an exact dem - evaluation of our candidate point set . only for combinations of @xmath16 and @xmath17 where no exact discrepancy values are found in the literature ,",
    "we resort to the lower bounds provided by the ta - algorithm .",
    "these lower bounds are at least as good as the ones presented in the literature , since the new ta - evaluation algorithm is better than the ones used in the previous works , cf .  @xcite .",
    "when dealing with the star discrepancy question , we use tournaments as selection mechanism @xcite .",
    "tournament selection selects the best individual among @xmath88 individuals which are selected at random from the entire population .    for the inverse star discrepancy question",
    ", we are dealing with two competing objectives : the number of points @xmath16 on the one hand , and the smallest star discrepancy of any @xmath16-point set on the other .",
    "we thus need to resort here to a totally different evaluation and selection scheme .",
    "we have used for this problem the nsga - ii  @xcite , a standard multiobjective selection algorithm .",
    "the evaluation is made using a bisection method . for a given configuration",
    ", we try to find the smallest number of points for which the discrepancy is lower than the threshold .",
    "this method allows us to run only @xmath89 times the discrepancy algorithm for a single configuration , where @xmath90 and @xmath91 are the frontiers of the search for the number of points .",
    "the bisection evaluation returns both the discrepancy ( which is lower than the threshold ) and the number of points . here",
    "again the discrepancy is either computed by the dem - algorithm ( wherever feasible ) or by the ta - heuristic ( in all other cases ) .",
    "we give a brief overview of the experimental setup in section  [ sec : setup ] .",
    "we then present the results of our algorithm . for the star discrepancy question , we compare the results obtained by our algorithm with those found in the literature ( sec .  [ comp : discrepancy ] ) . for the inverse discrepancy problem , we are not aware of any paper addressing this question experimentally .",
    "we thus present our results for answering a question on the inverse discrepancy presented in  @xcite and  @xcite ( sec .  [ comp : inverse ] ) .",
    "all point configurations achieving the bounds presented below are available online on  @xcite .",
    "all the experiments were run with the algorithm described in the last section .",
    "specific parameters for the operators are given in table  [ tab : params ] .",
    "given the satisfying results of these settings , we did not attempt to fine tune these parameters . during each discrepancy experiment",
    "the 25 best individuals are kept in an archive .",
    "where discrepancy values are computed only by the ta - algorithm and are thus just lower bounds for the exact value , the fitness of the individuals kept in the archive is dynamic as well ( i.e. , if the value of the individual changes due to a reevaluation , it also changes in the archive ) .",
    "the process is the same for the inverse discrepancy experiments , but instead of a list of the best individuals , the archive contains all the individuals that are not pareto - dominated by the archive .",
    "is pareto - dominated by a set @xmath92 if there exists a vector @xmath93 that for all objectives @xmath94 is at least as good as @xmath95 ( i.e. , @xmath96 for minimization objectives and @xmath97 for objectives to be maximized ) , and is strictly better ( @xmath98 and @xmath99 , respectively ) for at least one objective @xmath100 . ]    at the end of an experiment , we send to the final evaluation the entire archive and the final population .",
    ".optimization algorithm parameters . [ cols=\"<,^,^,^\",options=\"header \" , ]     figures  [ fig : tradeoff8d ] to [ fig : tradeoff25d ] present the pareto front of the final populations for the 8- , 15- , and 25-dimensional cases .. ] it can be seen that our method achieves a nice diversity in the found point sets giving a broad range of candidates with different trade - offs .",
    "the difference between the final front and the reevaluated one can be explained by the fact that the optimization algorithm takes advantage of the errors made by the ta - algorithm .",
    "for example , the same sequence can appear multiple times during the evolution , most of the time its approximated discrepancy will be very close to the true one , but it takes only one bad evaluation ( the approximation is lower than expected ) for that point set to make its way into the archive . increasing",
    "the number of repetitions of the ta - algorithm would prevent this from happening , but it would also increase the running time of the optimization .",
    "we have presented a new algorithm for computing low star discrepancy point sets . as shown in section  [ sec : results ] , our results outperform previous point configurations . furthermore , our algorithm can be easily adapted to compute upper bounds for the inverse discrepancy .",
    "the point sets are available online at  @xcite .",
    "we are confident that our algorithm and the generated point sets will be useful in a broad range of applications .",
    "most notably , our point sets can ensure a better approximation errors in quasi - monte carlo numerical integration and in experimental design",
    ".    it would be interesting to study whether our results can be further improved by resorting to other point sets , such as ( scrambled ) sobol or faure configurations .",
    "another interesting research direction concerns the evaluation of star discrepancy values . as exhibited above , this is a provably difficult task .",
    "still we have seen that the ta - algorithm from  @xcite provides an accurate estimate wherever this can be checked .",
    "is it possible to design similar heuristics for computing reasonable _ upper bounds _ for the star discrepancy of a given point set ?",
    "we would like to thank magnus wahlstrm from the max planck institute for informatics for providing an implementation of the dem algorithm  @xcite , for his excellent support regarding the evaluation algorithm  @xcite , and for his constructive feedback regarding our work .                      c.  doerr , m.  gnewuch , and m.  wahlstrm , _ calculation of discrepancy measures and applications _ , preprint ( 2013 ) , available online on http://www.numerik.uni-kiel.de/~mig/book_chapter_gnewuch_wahlstroem_winzen.pdf .",
    "k.  deb , a.  pratab , s.  agarwal , and t.  meyarivan , _ a fast elitist non - dominated sorting genetic algorithm for multi - objective optimization : nsga - ii _ , ieee trans .",
    "* 6 * ( 2002 ) , no .  2 , 849858 ."
  ],
  "abstract_text": [
    "<S> geometric discrepancies are standard measures to quantify the irregularity of distributions . </S>",
    "<S> they are an important notion in numerical integration . </S>",
    "<S> one of the most important discrepancy notions is the so - called _ </S>",
    "<S> star discrepancy_. roughly speaking , a point set of low star discrepancy value allows for a small approximation error in quasi - monte carlo integration . </S>",
    "<S> it is thus the most studied discrepancy notion .    in this work we present a new algorithm to compute point sets of low star discrepancy . </S>",
    "<S> the two components of the algorithm ( for the optimization and the evaluation , respectively ) are based on evolutionary principles . </S>",
    "<S> our algorithm clearly outperforms existing approaches . to the best of our knowledge , it is also the first algorithm which can be adapted easily to optimize inverse star discrepancies .    </S>",
    "<S> * categories : * f.2.1 theory of computationanalysis of algorithms and problem complexity [ numerical algorithms and problems ] + i.2.8 artificial intelligenceproblem solving , control methods , and search [ heuristic methods ] + * keywords : * geometric discrepancy , monte - carlo methods , information - based complexity , search heuristics , genetic algorithms , algorithm engineering </S>"
  ]
}