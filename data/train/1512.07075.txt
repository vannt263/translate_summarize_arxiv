{
  "article_text": [
    "the past few years have seen a large increase in the interest for modeling dynamic interactions between individuals . while many real world data contain continuous - time information on the interactions , as e.g. email exchanges between employees in a company  @xcite or face - to - face contact between individuals measured through sensors  @xcite , most models are discrete in time .",
    "commonly , data are aggregated on predefined time intervals to obtain a sequence of snapshots of interaction random graphs .",
    "besides the loss of information induced by data aggregation , the specific choice of the time intervals has a direct impact on the results , which is most often overlooked .",
    "thus , developing models of interaction that exploit the continuous - time aspect of the data  either called _ longitudinal networks , interaction event data , link streams _ or _ temporal networks _",
    " is an important research issue .",
    "statistical methods for the analysis of longitudinal networks form a huge corpus , especially in social sciences and we do not pretend to provide an exhaustive bibliography on this topic .",
    "we refer to the very nice and recent review by  @xcite for a more complete view on temporal networks .",
    "a natural way of modeling temporal event data is based on stochastic point processes .",
    "an important line of research involves continuous - time markov processes with seminal works on dyad - independent models @xcite up to the development of so - called stochastic actor oriented models  ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) . in these works observations consist in a series of time intervals of interaction and interactions",
    "are assumed to last during the whole corresponding time interval . here , we focus on a rather different setup where each interaction is identified with a time point .",
    "furthermore , we consider a model that allows for dependencies of the processes modeling the interactions of pairs of individuals .",
    "the analysis of event data is an old and important area in statistics  ( see e.g. * ? ? ?",
    "generally a multivariate counting process @xmath0 is considered , that counts the number of interactions of each pair @xmath1 of individuals up to time @xmath2 . in  @xcite counting processes",
    "have been introduced in the context of _ action _ data , which are a set of time - stamped directed interactions between individuals that , in addition , are marked by a label ( representing a behavioral event ) .",
    "the model may be viewed as an instance of cox s multiplicative hazard model with time - dependent covariates and constant baseline function . in the same vein ,",
    "@xcite propose a general regression - based modeling of the intensity of non recurrent interaction events .",
    "they consider two different frameworks : cox s multiplicative and aalen s additive hazard rates  ( see e. g. * ? ? ?",
    "@xcite propose another variant of cox s multiplicative intensity model for recurrent interaction events where the baseline function is specific to each individual . in the above",
    "mentioned works a set of statistics is chosen by the user as potential candidates that modulate the interactions .",
    "as in any regression framework , the choice of these statistics might raise some issues : increasing their number potentially leads to a high - dimensional problem , and interpretation of the results might be blurred by the correlation between these statistics .",
    "the approaches by  @xcite , @xcite , @xcite and others are based on conditional poisson processes characterized by random intensities , also known as doubly stochastic poisson processes or cox processes .",
    "a particular instance of the conditional poisson process is the hawkes process , which is a collection of point processes with some background rate , where each event adds a nonnegative impulse to the intensity of all other processes .",
    "@xcite develop a model for spatial - temporal networks with missing information , based on such self - exciting point processes for temporal dynamics combined with a gaussian mixture for the spatial dynamics .",
    "similarly ,  @xcite combine temporal hawkes processes with latent distance models for implicit networks that can not be observed directly .",
    "clustering individuals based on interaction data represents a well - established technique for taking into account the intrinsic heterogeneity and summarizing information . in the context of dynamic random graphs , where a discrete - time sequence of graphs is observed ,",
    "recent approaches propose to generalize the so - called stochastic block model to a dynamic context  @xcite .",
    "stochastic block models posit that each individual belongs to a latent group and interactions between two individuals are conditionally independent of the interactions of any other pair , given the latent groups of the interacting individuals .",
    "another attempt to use stochastic block models in the context of interaction events appears in  @xcite generalizing the approach of  @xcite by adding discrete latent variables on the individuals .    in this work a semiparametric stochastic block model for recurrent interaction events in continuous time",
    "is introduced , to which we refer as the poisson process stochastic block model .",
    "this is a stochastic block model where interactions are modeled by conditional inhomogeneous poisson processes , whose intensities only depend on the latent groups of the interacting individuals . in contrast to many other works",
    ", we do not rely on a parametric model where intensities are modulated by predefined network statistics , but intensities are modeled and estimated in a nonparametric way .",
    "the model is shown to be identifiable .",
    "our estimation and clustering approach is a semiparametric version of the variational expectation - maximization algorithm , where the maximization step is replaced by nonparametric estimators of the intensities .",
    "semiparametric generalizations of the classical expectation - maximization ( ` em ` ) algorithm have been proposed in many different contexts ( see e.g. @xcite for semiparametric mixtures or @xcite for a semiparametric hidden markov model ) .",
    "however , we are not aware of other attempts to incorporate nonparametric estimates in a variational approximation of ` em ` .",
    "two versions are developed for the nonparametric part of the model : a histogram approach based on the work of @xcite and a kernel estimator based on  @xcite .",
    "for the histogram approach , an integrated classification likelihood criterion is proposed to select the number of latent groups adaptively .",
    "synthetic experiments enlighten both the clustering capacities of our method as well as the performance of the nonparametric estimation of the different intensities .",
    "moreover , the analysis of several real datasets illustrates the strengths and weaknesses of our approach .",
    "the supplementary material , whose references appear as s.xx , provides the proofs of all theoretical results , technical details on the algorithm and more detailed results of the analysis of the real data examples .",
    "we are interested in the pairwise interactions of @xmath3 individuals during some time interval @xmath4 $ ] . for notational convenience ,",
    "we choose to restrict our attention to directed interactions without self - interactions .",
    "the undirected case as well as self - interactions are treated similarly and simulations as well as a real data example from section  [ sec : real_data ] use the undirected setup .",
    "the set of all possible pairs of individuals , which is also the set of all possible dyads in the graph , is denoted by @xmath5 the cardinality of @xmath6 is @xmath7 .",
    "the observations @xmath8 are the interactions occurring in time interval @xmath4 $ ] , that is @xmath9 where @xmath10\\times \\mathcal r$ ] corresponds to the event that the individuals with indices @xmath11 and @xmath12 interact at time @xmath13 .",
    "the number of events in time interval @xmath4 $ ] is @xmath14 .",
    "we assume that @xmath15 , i.e. there is at most one event at a time .    to model the distribution of these observations , every individual is assumed to belong to one out of @xmath16 groups , and the relation between two individuals , that is the way they interact with another , is driven by their group membership .",
    "more precisely , let @xmath17 be independent and identically distributed ( latent ) random variables taking values in @xmath18 with non zero probabilities @xmath19 for the moment , @xmath16 is considered to be fixed and known .",
    "when no confusion occurs , we also use the notation @xmath20 with @xmath21 such that @xmath22 has multinomial distribution @xmath23 with @xmath24 .",
    "now , our poisson process stochastic block model ( ppsbm ) is defined as follows . for every @xmath25 ,",
    "the interactions of individuals @xmath26 and @xmath27 , conditional on the latent groups @xmath22 and @xmath28 , are modeled by a conditional inhomogeneous poisson process @xmath29 on @xmath4 $ ] with intensity depending only on the latent groups @xmath22 and @xmath28 .",
    "we consider nonnegative intensity functions @xmath30 with @xmath31 such that the conditional intensity of process @xmath29 , given that @xmath32 and @xmath33 , is @xmath34 for any @xmath25 .",
    "the corresponding cumulative intensities are denoted by @xmath35.\\ ] ] the set of observations @xmath8 is a realization of the multivariate counting process @xmath36 with conditional intensity process @xmath37 .",
    "the process @xmath38 is not a poisson process , but a counting process with intensity @xmath39 .",
    "we denote @xmath40 the infinite - dimensional parameter of a poisson process stochastic block model .",
    "the distribution of the multivariate counting process @xmath41 under parameter value @xmath42 is denoted @xmath43 .      concerning the identifiability of parameter @xmath42 from the distribution of the multivariate counting process @xmath41 , it is clear that at best the poisson process stochastic block model is identifiable up to label switching , as defined below .",
    "furthermore , as the functions @xmath30 are intensities , they are only identifiable almost everywhere on @xmath4 $ ] .",
    "we denote @xmath44 the set of permutations of @xmath45 .",
    "the parameter @xmath46 of a poisson process stochastic block model is identifiable on @xmath4 $ ] up to label switching if for all @xmath42 and @xmath47 such that @xmath48 , there exists a permutation @xmath49 such that @xmath50 , \\qquad   ( q , l=1,\\dots , q).\\ ] ]    the following assumption ensures identifiability up to label switching in a very general setting .",
    "[ hyp : ident ] the set of intensities @xmath51 contains exactly @xmath52 distinct functions .    the intensities @xmath30 may take identical values at some points or on subsets of @xmath4 $ ] , but should not be equal almost everywhere .",
    "[ prop : ident ] under assumption  [ hyp : ident ] , the parameter @xmath53 is identifiable on @xmath4 $ ] , up to label switching , from the poisson process stochastic block model distribution of the multivariate counting process @xmath41 on the same interval , as soon as @xmath54 .",
    "this result strongly relies on the only available identifiability result for weighted stochastic block models , namely theorem 12 in  @xcite , which can be applied under assumption  [ hyp : ident ] .",
    "one may wonder whether the necessary condition that any two rows ( or any two columns ) of the parameter matrix @xmath55 are distinct is , in fact , a sufficient condition for identifiability .",
    "however , to our knowledge such a result has never been established even in the simple binary case . in the binary stochastic block model ,",
    "the results in  @xcite establish _ generic _ identifiability , which means identifiability except on a subset of parameters with lebesgue measure zero , without specifying the exceptional subset .",
    "for the directed and binary stochastic block model ,  @xcite establish identifiability under the assumption that the product vector @xmath56 ( or @xmath57 ) has distinct coordinates .",
    "this condition is slightly stronger than the one previously mentioned .",
    "another partial identifiability result appears in  @xcite for some block models .",
    "these last two approaches are specifically adapted to the discrete setup ( maybe even to the binary one ) and can not be generalized to the continuous case .",
    "proposition [ prop : ident ] does not cover the affiliation case , where only two intensities @xmath58 and @xmath59 are considered such that for all @xmath60 @xmath61    [ prop : ident_affil ] if the intensities @xmath62 and @xmath63 are distinct functions on @xmath4 $ ] , then both @xmath62 and @xmath63 are identifiable on @xmath4 $ ] from the affiliation poisson process stochastic block model distribution of the multivariate counting process @xmath41 on the same interval , as soon as @xmath54 . moreover , for any @xmath64 , the proportions @xmath65 are also identifiable , up to a permutation , from the same distribution .      in this section",
    "we introduce processes and notation that will be used throughout the manuscript .",
    "first , for any @xmath66 , we consider the ( unobserved ) number of dyads @xmath67 with latent groups @xmath60 @xmath68 the ( unobserved ) counting process @xmath69 has conditional intensity @xmath70 and falls in the class of aalen s multiplicative intensity models .",
    "this is a central property on which our work often relies .",
    "we also define @xmath71 as the ( unobserved ) binary indicator of observation @xmath72 belonging to groups @xmath60 by @xmath73 as these quantities are unobserved , our work relies on proxies .",
    "we consider the set @xmath74 of candidate proxies for the unobserved latent groups @xmath75 given by @xmath76 , \\sum_{q=1}^q\\tau^{i , q}=1 ~~\\text { for } i=1,\\dots , n , q=1,\\dots , q \\right\\}.\\ ] ] while the latent variables @xmath75 are indicators , their counterparts @xmath77 are weights representing the probability that node @xmath26 belongs to group @xmath78 . now , for every @xmath79 , replacing all latent variables @xmath75 in  by @xmath77 , we define @xmath80 , @xmath81 and @xmath82 which are estimators of @xmath83 , @xmath84 and @xmath85 , respectively .",
    "the complete - data likelihood of observation @xmath8 and latent variables @xmath86 is @xmath87 the likelihood of the observed data @xmath88 is obtained by summing the complete - data likelihood over the set of all possible configurations of the latent variables @xmath89 .",
    "this set is so huge that the likelihood of the observed data is intractable for direct maximization .",
    "hence , an expectation - maximization ( ` em ` ) algorithm  @xcite is used , which is an iterative procedure especially adapted to cope with latent variables .",
    "the ` em ` algorithm consists of an ` e`-step and an ` m`-step that are iterated until convergence . in our model",
    "two different issues arise .",
    "first , as already observed for the standard stochastic block model  @xcite , the ` e`-step requires the computation of the conditional distribution of @xmath90 given the observations @xmath8 , which is not tractable .",
    "therefore , we use a variational approximation  @xcite of the latent variables conditional distribution to perform the ` e`-step .",
    "we refer , for instance , to  @xcite for a general description of the variational ` em ` algorithm and its links to ` em ` in stochastic block models .",
    "second , part of our parameter is infinite dimensional so that the ` m`-step is partly replaced by a nonparametric estimation procedure , giving rise to a semiparametric ` em ` algorithm .",
    "our complete algorithm is summarized in section  [ sec : vem ] , algorithm  [ algo : vem ] .",
    "the standard ` e`-step consists in computing the expectation of the complete log - likelihood given the observations at some current parameter value @xmath42 .",
    "this requires the knowledge of the conditional latent variables distribution @xmath91 , which is not tractable , mainly because the latent variables @xmath22 are not conditionally independent .",
    "the idea is to perform a variational approximation of the conditional latent variables distribution @xmath92 by a simpler distribution .",
    "more precisely , using the class of parameters @xmath93 defined in  , we consider for every @xmath79 the conditional factorized distribution @xmath94 of @xmath90 given @xmath8 defined by @xmath95 with corresponding expectation @xmath96 .",
    "then , we search for the parameter @xmath97 that yields the best approximation @xmath94 of @xmath92 .",
    "more precisely , @xmath98 where @xmath99 denotes the kullback - leibler divergence .",
    "the variational ` e`-step is completed by the computation of the current expected complete data log - likelihood @xmath100    from a practical point of view , it can be shown that the solution @xmath101 of is also the solution of a fixed point equation , which in practice is found by successively updating the variational parameters @xmath77 via the following equation   until convergence .",
    "[ prop : e_step ] the solution @xmath101 to the minimization problem given in satisfies the following fixed - point equation @xmath102,\\qquad ( i=1,\\dots , n,~q=1,\\dots , q),\\ ] ] where @xmath103 means proportional to and @xmath104 with @xmath105 the indicator function of set @xmath106 .      in a parametric context ,",
    "the ` m`-step consists in the maximization of @xmath107 with respect to @xmath53 . considering only the finite - dimensional part @xmath108 of the parameter",
    ", we easily obtain that the maximizer @xmath109 of @xmath110 with respect to @xmath108 is @xmath111 concerning the infinite - dimensional parameter @xmath55 , we replace the maximization of @xmath110 with respect to @xmath55 by a nonparametric estimation step . in the following ,",
    "we develop two different approaches for updating @xmath55 : a histogram and a kernel method . in both cases estimation",
    "would be straightforward using the process @xmath112 defined by  , which unfortunately is not observed .",
    "it is thus natural to use its ( current ) variational approximation , namely the weighted cumulative process @xmath113 defined in section  [ sec : proc_notation ] .      in this part",
    "the intensities @xmath30 are estimated by piecewise constant functions and we propose a data - driven choice of the partition of the time interval @xmath4 $ ] . the procedure is based on a least - squares penalized criterion following the work of  @xcite . the detailed construction is provided in the supplementary material .    for @xmath114 , where @xmath115 is to be chosen ,",
    "we denote by @xmath116 the regular partition of @xmath4 $ ] into @xmath117 intervals with length @xmath118 , namely @xmath119 one may also use regular dyadic partitions , where @xmath120 , defining nested models that have some practical advantages concerning the implementation of the algorithm . in the following",
    "let @xmath121 be fixed .",
    "for @xmath122 the estimated mean number of observed interactions between individuals @xmath72 with latent groups @xmath60 occurring in time interval @xmath123 is @xmath124    for any fixed value of @xmath117 , a projection estimator @xmath125 on the space of piecewise constant functions on @xmath116 is given by @xmath126 where @xmath127 is the length of interval @xmath128 .",
    "now , adaptive estimation consists in choosing the best estimator among the collection of estimators @xmath129 .",
    "so we introduce an estimator of the partition through @xmath130 that minimizes a penalized least - squares criterion , that simplifies to @xmath131 the selected partition size @xmath130 depends on the groups @xmath60 and may be different for different values of @xmath60 .",
    "finally , the adaptive estimator of intensity @xmath30 is @xmath132    @xcite develops her approach in the aalen multiplicative intensity model , which is slightly different from our context .",
    "moreover , our setup does not satisfy the assumptions of theorem 1 in @xcite , since the number of jumps of the processes @xmath38 is not bounded by a known positive number , because here the @xmath38 are counting processes .",
    "nevertheless , in our simulations this procedure successfully estimates the intensities @xmath30 ( see section  [ sec : simus ] ) .",
    "we refer to  @xcite for a theoretical study of an adaptive nonparametric estimation of the intensity of a poisson process .",
    "@xcite also studies other penalized least squares estimators ( for e.g. using fourier bases ) , which might be used here similarly .",
    "an alternative way for nonparametric intensity estimation is based on kernel estimators , that are explored in the following section .",
    "kernel methods are suited to estimate smooth functions . in this",
    "part kernel estimators of the intensities @xmath30 are provided .",
    "a similar procedure has been proposed for a non variational version of the ` em ` algorithm in @xcite . if the variational parameters @xmath77 are good approximations of the latent variables @xmath75 , then the intensity of process @xmath81 defined in section  [ sec : proc_notation ] is approximately @xmath133 , where @xmath80 is the variational mean number of dyads with latent groups @xmath60 . following  @xcite and considering a nonnegative kernel function @xmath134 with support within @xmath135",
    "$ ] together with some bandwidth @xmath136 , the intensity @xmath30 is estimated by @xmath137 if @xmath138 and @xmath139 otherwise , where @xmath82 is defined in section  [ sec : proc_notation ] .",
    "the bandwidth @xmath140 can be chosen adaptively from the data following the procedure proposed by  @xcite .",
    "kernel methods are not always suited to infer a function on a bounded interval as boundary effects may deteriorate their quality .",
    "however , it is out of the scope of this work to investigate refinements of this kind .      during the implementation of the algorithm ,",
    "two issues arise : convergence and initialization .",
    "as our algorithm is an iterative procedure , one has to test for convergence .",
    "a stopping criterion can be defined based on the current expected complete data log - likelihood @xmath141}}(\\theta^{[s]})$ ] .",
    "concerning initialization the algorithm be may run several times with different starting values .",
    "one can choose them randomly or by some k - means method .",
    "see the supplementary material for details . algorithm  [ algo : vem ] provides a full description of the procedure .",
    "@xmath142 initialize @xmath143}$ ] output @xmath144},\\alpha^{[s]})$ ]      to choose the best number of groups @xmath16 , we propose an integrated classification likelihood criterion that performs data - driven model selection .",
    "roughly , this criterion is based on the complete data log - likelihood penalized by the number of parameters .",
    "it has been introduced in the mixture context in  @xcite and adapted to the stochastic block model in  @xcite .",
    "the issue here is that our model contains a nonparametric part , so that the parameter is infinite dimensional .",
    "however , in the case of histogram estimators , once the partition is selected , there is only a finite number of parameters to estimate , which can be used to build our integrated classification likelihood criterion .",
    "more precisely , for any @xmath16 let @xmath145 be the estimated parameter with @xmath16 groups and @xmath146 the corresponding maximum a posteriori classification at @xmath145 obtained by our variational ` em ` algorithm .",
    "the parameter @xmath147 has two components : the first one @xmath148 is a vector of dimension @xmath149 , while the second has dimension @xmath150 , where @xmath151 denotes the size of the partition used in the histogram estimator @xmath152 . in the adaptation of the integrated classification likelihood criterion to the stochastic block model",
    "these components are treated differently : the first one , that concerns the @xmath3 individuals , is penalized by a @xmath153 term , while the second one concerning the dyads is penalized by a @xmath154 term .",
    "we refer to  @xcite for more details . in our case ,",
    "the integrated classification likelihood criterion is @xmath155 after fixing an upper bound @xmath156 we select the number of groups @xmath157",
    "in this section we investigate the numerical performance of our method for clustering individuals and estimating the intensities of the inhomogeneous poisson processes .",
    "we also study the performance of the integrated classification likelihood criterion for recovering the true number of latent groups .",
    "the following two scenarios are used in our simulations in the undirected setup where @xmath158 for any @xmath66 .    1 .",
    "we consider the affiliation model with @xmath159 latent groups and equal group probabilities @xmath160 . to evaluate the classification performance , the intensities are sinusoids with varying shifting parameter @xmath161 .",
    "clustering is supposed to be more difficult for small values of @xmath161 .",
    "the intensities are shown in figure  [ fig_intensities_q2 ] in the supplementary material .",
    "the number of individuals @xmath3 varies in @xmath162 .",
    "2 .   to evaluate the intensity estimators ,",
    "we consider a poisson process stochastic block model with @xmath163 groups with equal probabilities @xmath164 .",
    "the six intensity functions have rather different shapes and amplitudes ( see figure  [ estimated_intensities_q3_n20 ] ) .",
    "the number of individuals @xmath3 varies in @xmath165 .    for every setting",
    ", @xmath166 datasets are simulated under the corresponding poisson process stochastic block model and the variational ` em ` algorithm is applied .",
    "the histogram estimator is applied with a regular partition and @xmath167 , while the kernel estimator uses the epanechnikov kernel .    .",
    "left : @xmath168 , right : @xmath169.,title=\"fig:\",scaledwidth=40.0%,height=151 ] .",
    "left : @xmath168 , right : @xmath169.,title=\"fig:\",scaledwidth=40.0%,height=151 ]    to assess the clustering performance , we use the adjusted rand index  @xcite that evaluates the agreement between the estimated and the true latent structure . for two classifications that are identical ( up to label switching ) ,",
    "this index equals @xmath170 , otherwise the adjusted rand index is smaller than @xmath170 and negative values are possible . figure  [ boxplot_affiliation ] shows the boxplots of the adjusted rand index obtained with the histogram and the kernel versions of our method in scenario 1 . for small values of the shifting parameter ( @xmath171 ) , the intensities are so close that the classification is very difficult , especially when @xmath172 is small .",
    "the classification improves when the shift between the intensities and/or the number of observations increase , achieving ( almost ) perfect classification for large values of @xmath161 and/or @xmath3 .",
    "we also observe that the kernel version of our method gives better classification results than the histogram method , which might be due to the choice of actually continuous intensities .    concerning the recovery of the intensities in scenario 2",
    ", the quadratic risk is used to measure the distance between the true intensity @xmath30 and its estimate @xmath173 defined by @xmath174 table  [ risk_q3 ] gives the mean value of the risk @xmath175 and its standard deviation estimated over @xmath166 repetitions for both the histogram and the kernel version of our method .",
    "table  [ risk_q3 ] also reports the mean number of observations @xmath72 with latent groups @xmath60 , namely @xmath176 .",
    "moreover , figure  [ estimated_intensities_q3_n20 ] shows for each pair of groups @xmath60 the true and the estimated intensities for one dataset with @xmath177 .       .",
    "mean number of events with latent groups @xmath60 and mean quadratic risk ( with standard deviation ) for the histogram and the kernel estimators of the intensities in scenario 2 averaged over @xmath178 repetitions .",
    "all values associated with the risk are multiplied by 100 . [ cols=\"^,^,^,^,^,^,^,^,^,^,^ \" , ]     .",
    "true intensities ( black continuous ) , histogram estimator ( red dashed ) and kernel estimator ( blue dotted ) for each pair of groups @xmath60.,height=264 ]    as expected , when the true intensity is piecewise - constant , the histogram version of our method outperforms the kernel estimator .",
    "conversely , when the true intensity is smooth , the kernel estimator is more appropriate to recover the shape of the intensity . in some cases , as e.g. for the intensity with latent groups @xmath179 , the estimators achieve comparable results .",
    "a well - known drawback of the kernel estimator is that it suffers from boundary effects .",
    "this is observed here for the intensities with groups @xmath180 and @xmath181 , but is less crucial for the other intensities that appear to be null at the interval boundaries .",
    "finally , we use scenario 2 to illustrate the performance of the integrated classification likelihood criterion to select the number @xmath16 of latent groups from the data . for each of the 1000 simulated datasets ,",
    "the maximizer @xmath182 of the integrated classification likelihood criterion defined in   with @xmath183 is computed .",
    "results are reported in figure  [ qbest-20 ] in the supplementary material .",
    "for @xmath177 the correct number of groups is recovered in @xmath184 of the cases . moreover , when the criterion does not select the correct number @xmath16 , the adjusted rand index of the classification with three groups is rather low .",
    "this indicates that in those cases the classification obtained with three groups is not the correct one , so that rather the variational em algorithm is to blame for bad results than the integrated classification likelihood criterion . for @xmath185",
    "our procedure selects the correct number of groups for each simulated datasets .",
    "here , we use the cycle hire usage data from the bike sharing system of the city of london from 2012 to 2015  @xcite . these data are also analyzed in  @xcite with a different perspective .",
    "we focus on two randomly chosen weekdays , which are february 1st , 2012 ( day 1 ) and february 2nd , 2012 ( day 2 ) .",
    "data consist in pairs of stations associated with a single hiring / journey ( departure station , ending station ) and corresponding time stamp ( hire time with second precision ) .",
    "the datasets have been pre - processed to remove journeys that either correspond to loops , last less than 1 minute or more than 3 hours or do not have an ending station ( lost or stolen bikes ) .",
    "the datasets contain @xmath186 and @xmath187 stations on day 1 and day 2 with @xmath188 and @xmath189 hire events respectively . with more than 170,000 oriented pairs of stations",
    "the number of processes @xmath38 is huge , but only a very small fraction  around 7%  of these point processes are non null ( i.e. contain at least one hiring event between these stations ) .",
    "this is to be expected as bike sharing systems are mostly used for short trips and stations far one from another are unlikely to be connected .",
    "as data correspond to origin / destination flows , it is natural to work with a directed setup and we applied the histograms version of our algorithm on a dyadic partition with maximum size @xmath190 .",
    "the integrated classification likelihood criterion achieves its maximum with @xmath191 latent groups for day 2 and @xmath192 on day 1 . in order to compare results across the two datasets and keep interpretation simple ,",
    "we focus on the classification obtained with @xmath193 clusters .",
    "geographic locations of the bike stations and the clusters are represented on a city map ( thanks to the openstreetmap project ) , see figure  [ fig : cycles_day2 ] in the supplementary material for day 2 .",
    "clusters for day  1 are very similar , so that in the following we only concentrate on day 2 .",
    "we observe that our procedure globally recovers geographic clusters , as stations are expected to be mainly linked through geographic proximity in the datasets",
    ". a closer look at the clusters then reveals more information .",
    "there is one cluster containing only four bike stations ( cluster number 5 , appearing as light blue diamonds in figure  [ fig : cycles_day2 ] ) , while all other clusters contain between 38 and 125 stations .",
    "this small cluster contains one bike station at kings cross railway station and three stations next to waterloo railway station .",
    "indeed , two of these bike stations are among those with the highest activities ( for both departures and arrivals ) in comparison to all other stations , while this is not the case of the other two stations in the cluster .",
    "thus it is very unlikely that a snapshot approach , where events are aggregated over a predetermined time window , would have yield the same cluster .",
    "consequently , the explanation for this clustering is the similarity of the temporal profiles of these four stations .",
    "indeed , figure  [ fig : cycles_temp_2 ] shows that these four stations are outgoing stations in the morning with much more departures than arrivals around 8 a.m. and incoming stations at the end of the day , with more arrivals than departures between 5p.m and 7 p.m. looking at the temporal profiles of stations close to the two other main railway stations in london ( victoria and liverpool street stations ) , this pattern is not observed and the stations are clustered differently .",
    "thus , this small cluster is characterized by stations used by people living in the suburbs and working in the city center .",
    "this result highlights the specificity of our model that is able to find clusters from similar temporal profiles in sharp contrast with aggregated data approaches .    ) and incoming ( @xmath194 ) processes from the 4 stations @xmath26 in the smallest cluster : representation of volumes of connections to all other stations during day 2.,scaledwidth=80.0%,height=377 ]    we then used a kernel estimator of the intensities per ( directed ) groups pairs @xmath195 ( see figure  [ fig : cycles_intens ] in the supplementary material ) .",
    "cluster number 5 ( which is the small cluster mentioned above ) has high ( directed ) intensities of connections with cluster number 3 ( shown in green plus sign @xmath196 in figure  [ fig : cycles_day2 ] ) .",
    "this last cluster groups the stations belonging to the business city center of london .",
    "we observe a large intensity of connections from cluster 5 ( king s cross and waterloo railway stations ) to cluster 3 ( city business center ) in the morning and in the other direction ( from cluster 3 to cluster 5 ) at the end of the day .",
    "moreover , cluster 5 also appears to have ( a smaller amount of ) connections with clusters 1,4 and itself .",
    "connections with cluster 1 ( black circles @xmath197 in figure  [ fig : cycles_day2 ] ) and cluster 4 ( blue cross @xmath198 in figure  [ fig : cycles_day2 ] ) are similar ( from cluster 5 in the morning and back to cluster 5 in the evening ) to those with cluster 3 but at a smaller scale . those results support and extend the previous description of the role of cluster 5 .    to conclude this section",
    "we mention that  @xcite use a completely different approach , relying on poisson mixture models on the same origin / destination flows .",
    "this approach does not take into account the network structure of the data ( where e.g. two flows from the same station are related ) . as a consequence",
    ", clusters are obtained on pairs of stations from which interpretation is completely different and in a way less natural .      to understand contacts between children at school and to quantify the transmission opportunities of respiratory infections , data on face - to - face interactions in a french primary school were collected .",
    "the dataset is presented in detail in  @xcite and available online  @xcite .",
    "children are aged from 6 to 12 years and the school is composed of five grades , each of them comprising two classes , for a total of 10 classes ( denoted by @xmath199 ) .",
    "each class has an assigned teacher and an assigned room .",
    "the school day runs from 8.30am to 4.30pm , with a lunch break from 12 pm to 2 pm and two breaks of 20 - 25 min around 10.30am and 3.30pm .",
    "lunch is served in a common canteen and a shared playground is located outside the main building . as the playground and the canteen do not have enough capacity to host all pupils at a time , only two or three classes have breaks together , and lunch is served in two turns .",
    "the dataset contains @xmath200 face to face contacts among @xmath201 individuals ( @xmath202 children and @xmath203 teachers ) observed during two days .",
    "we applied our procedure in the undirected setup with histograms based on a dyadic partition with maximum size @xmath204 . for @xmath205 ,",
    "figure  [ fig_school_tau ] shows the clustering of the @xmath3 individuals into @xmath16 groups , where children from different classes are represented in different colors .",
    "when q is small ( @xmath206 ) , our procedure gathers all pupils from one class and their corresponding teacher in the same cluster . for larger values of @xmath16 ,",
    "our procedure makes a sharper clustering according to the behavior of the children .",
    "for example for @xmath207 , the procedure separates children from the same class : either to isolate a few of them in a group ( 3 children of class @xmath208 are put together in one group ) , or to put together children of different classes ( one group is made of children of classes @xmath209 and @xmath210 ) .",
    "teachers never form a particular group apart , but they are in the cluster of their assigned class , suggesting that contacts among teachers are sparse and that in this dataset clustering is mainly driven by communities ( _ i.e. _ groups of highly connected individuals , with few inter - groups interactions ) .",
    "the model selection criterion for choosing the best number of groups @xmath16 does not provide a reasonably small number of clusters that could be used for interpretation of the data .",
    "it has already been observed by other authors that this may happen for large datasets  ( see * ? ? ? * and the references therein ) .",
    "thus , we choose to further analyse the data for @xmath207 groups .     individuals ( represented by different colours ) into @xmath211 groups . for each picture",
    "the vertical bars represent the @xmath16 clusters .",
    "colours indicate the grades and the teachers , plain and hatching distinguish the two classes in the same grade .",
    ", height=377 ]    we observe that the intensities representing the most activity are the intra - group intensities . as clusters mainly correspond to classes",
    ", this highlights that most contacts involve children of the same class and that the dataset is structured into communities .",
    "moreover , peaks of interactions are observed during the two breaks around 10.30am and 3.30pm . at lunch time interactions between children",
    "vary from the first to the second day and are less important than during the breaks where they play together .",
    "concerning inter - group connections , most of the estimated intensities for groups @xmath60 with @xmath212 can be considered as null , except for some that we discuss now .",
    "first , as our procedure splits some children of the same class into separate groups , the inter - group interactions associated with these clusters correspond in fact to intra - class interactions .",
    "second , intensities between groups made of children of the same grade are significant , suggesting that children mostly interact with children of the same age .",
    "third , the children of class @xmath213 are partitioned into two clusters , and the intensity of one of these clusters drops to zero during lunch time , whereas children of the other group interact a lot during lunch .",
    "it seems that our procedure has recognized two subgroups in class @xmath213 : children having lunch at school and those going home for lunch",
    ". fourth , class @xmath208 is split into three groups with 20 , 3 and 2 pupils , respectively .",
    "the estimated intensities suggest a particular behaviour of some of the children : there is no contact between the two children in the smallest cluster , but they have very strong interaction with the three pupils in the other cluster .    as a conclusion",
    ", we recover many results of @xcite .",
    "in particular , we detect subgroups of pupils with a specific behavior at some period of the day ( leaving school for lunch ) .",
    "we think that this is mainly due to the fact that the poisson process stochastic block model takes into account the information provided by the timestamps of the events . without this temporal information",
    ", it is hard to imagine to obtain similar results . in particular",
    ", aggregating data on a day scale to construct discrete time networks would not provide such a refined analysis .",
    "we analyse the email exchanges between @xmath214 persons working at enron , mostly in the senior management , covering the period of the affair that led to the bankruptcy of the company  @xcite .",
    "the dataset  @xcite contains @xmath215 emails exchanged among these 147 persons between june 14 , 2000 and june 13 , 2002 , for which the sender , the recipient and the time when the email was sent are known .",
    "as data are obviously directed , we use the directed version of our method to analyse them .    here again , the integrated classification likelihood criterion does not provide a reasonably small enough number of clusters that could be used for interpretation . we choose to analyse the data with @xmath216 clusters .",
    "there is one group which is rather silent with very little activity and intensities close to zero .",
    "the other groups are characterized by substantial intra - group communication .",
    "it is instructive to compare the temporal profiles of the estimated intensities .",
    "first , we observe that communication is not symmetric .",
    "for example , people in cluster 3 regularly send emails to cluster 2 over the whole observation period , but the latter only respond rather late during the second half of 2001 , see figure [ fig_enron_intra ] .",
    "second , the intra - group communication differs a lot from one group to the other , see figure [ fig_enron_inter ] .",
    "cluster 3 has a rather constant communication intensity over the whole period , while the intra - group intensity of cluster 1 is increasing with a peak at the end of 2002 , which seems to be the consequence of the beginning of the investigations .",
    "in contrast , cluster 4 has an important intra - group activity until june 2001 , then the intensity drops down and achieves another peak just before the inquiry , when it is known that number of individuals acted to hide sensitive information on the scandal .",
    "thus , one may suspect people from cluster 4 to hold relevant information for the investigators .",
    "finally , we compare these results with those obtained using a classical stochastic block model .",
    "indeed , taking @xmath217 in our approach amounts to forget the timestamps of the emails , as the algorithm then only considers email counts over the whole observation period .",
    "in other words , using @xmath217 boils down to a classical stochastic block model with poisson emission distribution and mean parameter @xmath218  ( see for instance * ? ? ? * ) .",
    "we compare the classifications obtained by the two procedures for @xmath216 clusters .",
    "the associated adjusted rand index is @xmath219 indicating that part of the individuals are clustered in the same way and some are treated very differently in the two models .",
    "indeed , both methods find a large common cluster with people that do not communicate a lot , while most hesitation is about persons in cluster 3 in the poisson process stochastic block model , which are mainly split into two groups in the classical stochastic block model and partly mixed with people from cluster 1 .",
    "in fact , cluster 1 and 3 in the poisson process stochastic block model have significant intra - group communication but very different temporal profiles as mentioned above .",
    "intuitively , it may be difficult to distinguish these groups when we only look at the total count data as in classical stochastic block model .",
    "this means that taking into account the time information of the events may be very useful to improve the classification of the individuals compared to classical stochastic block model .",
    "we would like to thank agathe guilloux for pointing out valuable references , nathalie eisenbaum for her help on doubly stochastic counting processes and pierre latouche for sharing information on datasets .",
    "43 natexlab#1#1    allman , e. , matias , c. & rhodes , j. ( 2009 ) .",
    "identifiability of parameters in latent structure models with many observed variables .",
    "statist . _",
    "* 37 * , 30993132 .",
    "allman , e. , matias , c. & rhodes , j. ( 2011 ) .",
    "parameters identifiability in a class of random graph mixture models .",
    "_ j. stat . plan",
    ". inference _ * 141 * , 17191736 .",
    "andersen , p.  k. , borgan ,  .",
    ", gill , r.  d. & keiding , n. ( 1993 ) .",
    "_ statistical models based on counting processes_. springer series in statistics .",
    "springer - verlag , new york .",
    "baraud , y. & birg , l. ( 2009 ) .",
    "estimating the intensity of a random measure by histogram type estimators .",
    "theory related fields _ * 143 * , 239284",
    ".    bickel , p.  j. , chen , a. & levina , e. ( 2011 ) .",
    "the method of moments and degree distributions for network models .",
    "statist . _",
    "* 39 * , 22802301 .",
    "biernacki , c. , celeux , g. & govaert , g. ( 2000 ) . assessing a mixture model for clustering with the integrated completed likelihood .",
    "_ ieee trans . pattern anal .",
    "machine intel . _",
    "* 22 * , 719725 .",
    "bhning , d. ( 1995 ) . a review of reliable maximum likelihood algorithms for semiparametric mixture models . _ j. stat",
    ". plan . inference _ * 47 * , 5  28 .",
    "bordes , l. , chauveau , d. & vandekerkhove , p. ( 2007 ) . a stochastic em algorithm for a semiparametric mixture model .",
    "data anal . _",
    "* 51 * , 5429  5443 .",
    "butts , c.  t. ( 2008 ) .",
    "a relational event framework for social action .",
    "methodol . _ * 38 * , 155200 .",
    "calo  project ( 2015 ) .",
    "http://www.cs.cmu.edu/  enron/.    celisse , a. , daudin , j .-",
    "j . & pierre , l. ( 2012 ) .",
    "consistency of maximum - likelihood and variational estimators in the stochastic block model .",
    "_ electron .",
    "j. statist . _ * 6 * , 18471899 .",
    "cho , y .- s . ,",
    "galstyan , a. , brantingham , p.  j. & tita , g. ( 2014 ) . latent self - exciting point process model for spatial - temporal networks .",
    "_ discrete continuous dyn .",
    "b _ * 19 * , 13351354 .    corneli , m. , latouche , p. & rossi , f. ( 2016 )",
    ". exact icl maximization in a non - stationary temporal extension of the stochastic block model for dynamic networks .",
    "_ neurocomputing _ * 192 * , 81  91 .",
    "dannemann , j. ( 2012 ) .",
    "semiparametric hidden markov models .",
    "_ j. comput . graph .",
    "statist . _",
    "* 21 * , 677692 .",
    "daudin , j .-",
    ", picard , f. & robin , s. ( 2008 ) . a mixture model for random graphs .",
    "_ statist .",
    "comput . _ * 18 * , 173183 .",
    "dempster , a.  p. , laird , n.  m. & rubin , d.  b. ( 1977 ) .",
    "maximum likelihood from incomplete data via the em algorithm . _ j. roy .",
    "ser . b _ * 39 * , 138 .    dubois , c. , butts , c.  t. & smyth , p. ( 2013 ) .",
    "stochastic blockmodeling of relational event dynamics . in",
    "_ aistats _ , vol",
    "jmlr workshop and conference proceedings .",
    "grgoire , g. ( 1993 ) .",
    "least squares cross - validation for counting process intensities .",
    "j. statist .",
    "_ * 20 * , pp .",
    "343360 .",
    "guigours , r. , boull , m. & rossi , f. ( 2015 ) . discovering patterns in time - varying graphs : a triclustering approach .",
    "data anal .",
    "classif . _ , 128 .",
    "holme , p. ( 2015 ) .",
    "modern temporal network theory : a colloquium .",
    "j. b _ * 88 * , 234 .",
    "hubert , l. & arabie , p. ( 1985 ) .",
    "comparing partitions .",
    "_ j. classif .",
    "_ * 2 * , 193218 .",
    "jordan , m. , ghahramani , z. , jaakkola , t. & saul , l. ( 1999 ) .",
    "an introduction to variational methods for graphical models .",
    "* 37 * , 183233 .",
    "klimt , b. & yang , y. ( 2004 ) .",
    "the enron corpus : a new dataset for email classification research . in _",
    "machine learning : ecml 2004 _ , j .- f .",
    "boulicaut , f.  esposito , f.  giannotti & d.  pedreschi , eds .",
    "lecture notes in computer science_. springer berlin heidelberg .",
    "linderman , s. & adams , r. ( 2014 ) .",
    "discovering latent network structure in point process data . in _ proceedings of the 31st international conference on machine learning ( icml-14 ) _ ,",
    "e.  p. xing & t.  jebara , eds .",
    "mariadassou , m. , robin , s. & vacher , c. ( 2010 ) . uncovering latent structure in valued graphs : a variational approach .",
    "stat . _ * 4 * , 71542 .",
    "martinussen , t. & scheike , t.  h. ( 2006 ) . _ dynamic regression models for survival data_. statistics for biology and health .",
    "springer , new york .",
    "matias , c. & miele , v. ( to appear ) .",
    "statistical clustering of temporal networks through a dynamic stochastic block model .",
    "_ j. r. stat .",
    "_ available at arxiv:1506.07464 .",
    "matias , c. & robin , s. ( 2014 ) . modeling heterogeneity in random graphs through latent space models : a selective review .",
    "_ esaim proc . & surveys _ * 47 * , 5574 .",
    "perry , p.  o. & wolfe , p.  j. ( 2013 ) .",
    "point process modelling for directed interaction networks .",
    "_ j. r. stat .",
    ". b. stat .",
    "methodol . _ * 75 * , 821849 .",
    "ramlau - hansen , h. ( 1983 ) .",
    "smoothing counting process intensities by means of kernel functions .",
    "_ * 11 * , pp . 453466 .",
    "randriamanamihaga , a.  n. , cme , e. , oukhellou , l. & govaert , g. ( 2014 ) . clustering the vlib dynamic origin / destination flows using a family of poisson mixture models .",
    "_ neurocomputing _ * 141 * , 124  138 .",
    "reynaud - bouret , p. ( 2006 ) .",
    "penalized projection estimators of the aalen multiplicative intensity .",
    "_ bernoulli _ * 12 * , 633661 .",
    "robin , s. , bar - hen , a. , daudin , j .-",
    "j . & pierre , l. ( 2007 ) . a semi - parametric approach for mixture models : application to local false discovery rate estimation . _",
    "data anal . _ * 51 * , 5483  5493 .",
    "snijders , t. & van duijn , m. ( 1997 ) .",
    "simulation for statistical inference in dynamic network models . in",
    "_ simulating social phenomena",
    "_ , r.  conte , r.  hegselmann & p.  terna , eds .",
    "456 of _ lecture notes in economics and mathematical systems_. springer berlin heidelberg , pp . 493512 .",
    "snijders , t. a.  b. , koskinen , j. & schweinberger , m. ( 2010 ) .",
    "maximum likelihood estimation for social network dynamics .",
    "stat . _ * 4 * , 567588 .    sociopatterns ( 2015 ) .",
    "http://www.sociopatterns.org/.    stehl , j. , voirin , n. , barrat , a. , cattuto , c. , isella , l. , pinton , j .- f . &",
    "et  al . (",
    "high - resolution measurements of face - to - face contact patterns in a primary school .",
    "_ plos one _ * 6 * , e23176 .    transport for london ( 2016 ) .",
    "cycle hire usage data 2012 - 2015 .",
    "vu , d.  q. , hunter , d. , smyth , p. & asuncion , a.  u. ( 2011 ) .",
    "continuous - time regression models for longitudinal networks . in _",
    "adv neural inf process syst 24 _ , j.  shawe - taylor , r.  zemel , p.  bartlett , f.  pereira & k.  weinberger , eds .",
    "curran associates , inc . , pp . 24922500 .",
    "wasserman , s. ( 1980 ) .",
    "analyzing social networks as stochastic processes .",
    "_ jasa _ * 75 * , 280294 .",
    "wasserman , s. ( 1980 ) . a stochastic model for directed graphs with transition rates determined by reciprocity .",
    "methodol . _ * 11 * , pp .",
    "392412 .",
    "xu , k. & hero , a. ( 2014 ) .",
    "dynamic stochastic blockmodels for time - evolving social networks .",
    "_ ieee j. sel .",
    "topics signal process . _",
    "* 8 * , 552562 .",
    "yang , t. , chi , y. , zhu , s. , gong , y. & jin , r. ( 2011 ) . detecting communities and their evolutions in dynamic social networks",
    " a bayesian approach .",
    "_ * 82 * , 157189 .    supplementary material for : a semiparametric extension of the stochastic block model for longitudinal networks +    _",
    "all the references are from the main manuscript , except for those appearing as s - xx that are within this file . _",
    "for notational convenience , the proofs are presented in the undirected setup , where the set of intensities is @xmath220 .",
    "the directed case can be treated in the same way .",
    "we start by considering the distribution of one marginal process @xmath38 , which is a cox process directed by the random measure @xmath221 such that @xmath222 ( here , for any @xmath223 , we use the notation @xmath224 for the measure on @xmath4 $ ] defined by @xmath225 for all measurable @xmath226 $ ] .",
    "we also recall that @xmath227 is the dirac mass at point @xmath228 ) .",
    "it is known that the mapping of probability laws of random measures into laws of cox processes directed by them is a bijection  ( see for example proposition 6.2.ii in * ? ? ?",
    "in other words , here the distribution of @xmath38 uniquely determines the finite measure ( on the set of measures on @xmath4 $ ] ) @xmath229 .",
    "then , under assumption  1 that the intensities @xmath30 are distinct , the corresponding measures @xmath224 are all different and we may recover from the distribution of our counting process @xmath38 the set of values @xmath230 or equivalently the set @xmath231 .",
    "in particular , we recover the functions @xmath30 almost everywhere on @xmath232 $ ] , up to a permutation of these @xmath233 values . however , to recover those values up to a permutation in @xmath44 , it is necessary to consider higher - order marginals .",
    "we now fix three distinct indices @xmath234 and consider the trivariate counting process @xmath235 . in the same way ,",
    "these are cox processes directed by the triplet of random measures @xmath236 such that @xmath237 we write this distribution in such a way that distinct components appear only once @xmath238 \\nonumber\\\\ & + \\sum_{\\substack{q , l , m \\\\",
    "|\\{q , l , m\\}|=3 } } \\pi_q\\pi_l\\pi_m   \\delta_{(a^{(q , l ) } ,   a^{(q , m ) } , a^{(l , m ) } ) } .",
    "\\end{aligned}\\ ] ] using the same reasoning , we identify the triplets of values @xmath239 up to a permutation on the triplets @xmath240 . among these ,",
    "the only values with three identical components are @xmath241 and thus the measures @xmath242 are identifiable , up to a permutation in @xmath44 .",
    "going back to   and looking for the dirac terms at points that have two identical components ( of the form @xmath243 and two other with permuted components ) , we can now identify the set of measures @xmath244 this is equivalent to saying that we identify the measures @xmath245 up to a permutation in @xmath44 .",
    "obviously , this also identifies the corresponding intensities @xmath246 almost everywhere on @xmath4 $ ] , up to a permutation in @xmath44 .",
    "to finish the proof , we need to identify the proportions @xmath247 .",
    "note that as we identified the components @xmath248 , we recover from   the set of values @xmath249 up to the same permutation as on the @xmath250 s .",
    "this concludes the proof .",
    "we follow some of the arguments already appearing in the proof of proposition 1 .",
    "let @xmath251 ( resp .",
    "@xmath252 ) denote the measure whose intensity is @xmath58 ( resp .",
    "@xmath59 ) the univariate process @xmath38 is a cox process directed by the random measure @xmath221 that is now distributed as @xmath253 thus the measures @xmath251 and @xmath252 are identifiable from the distribution of @xmath38 , but only up to a permutation .",
    "once again , we rather consider the trivariate cox processes @xmath235 directed by the random measures @xmath236 whose distribution in the affiliation case has now five atoms @xmath254 as previously , these five components are identifiable , up to a permutation on @xmath255 .",
    "now it is easy to identify the three components for which two marginals have same parameters and the third one has a different parameter .",
    "thus , we recover exactly the measures @xmath251 and @xmath252 .",
    "this also identifies the corresponding intensities @xmath58 and @xmath59 almost everywhere on @xmath4 $ ] .",
    "now , the identification of the proportions @xmath256 follows an argument already used in the proof of theorem 13 in  @xcite that we recall here for completeness . from the trivariate distribution of @xmath235 and the already recovered values @xmath251 and @xmath252 , we identify the proportion @xmath257 .",
    "similarly , for any @xmath258 , by considering the multivariate distribution of @xmath259 , we can identify the dirac mass at point @xmath260 and thus its weight , which is equal to @xmath261 . by the newton identities ,",
    "the values @xmath262 determine the values of elementary symmetric polynomials @xmath263 .",
    "these , in turn , are ( up to sign ) the coefficients of the monic polynomial whose roots ( with multiplicities ) are precisely @xmath264 .",
    "thus , the proportion parameters are recovered up to a permutation .",
    "for the kullback - leibler divergence we compute @xmath265 according to  , the complete - data log - likelihood @xmath266 is @xmath267 where @xmath83 and @xmath85 have been introduced in equations   and  , respectively .",
    "now , note that @xmath268 = \\p_\\tau(z^{i , q}=1|\\mathcal o ) = \\p_\\tau(z_i = q|\\mathcal o)=\\tau^{i , q}$ ] .",
    "moreover , by the factorization property  , for every @xmath269 we have @xmath270={e}_\\tau[z^{i , q}|\\mathcal o]{e}_\\tau[z^{j , l}|\\mathcal o]=\\tau^{i , q}\\tau^{j , l } .\\ ] ] the quantity @xmath80 is thus equal to @xmath271 $ ] , namely the variational approximation of the mean number of dyads with latent groups @xmath60 .",
    "similarly , @xmath82 equals @xmath272 $ ] , the variational approximation of the probability that observation @xmath273 corresponds to a dyad with latent groups @xmath60 .",
    "it follows that @xmath274 where @xmath275 is @xmath276 the variational ` e`-step consists in maximizing @xmath277 with respect to the @xmath77 s which are constrained to satisfy @xmath278 for all @xmath26 . in other words",
    ", we maximize @xmath279 with lagrange multipliers @xmath280 .",
    "the partial derivatives are @xmath281 the partial derivatives are null iff @xmath282 and the @xmath77 s satisfy the fixed point equations  , with @xmath283 being the normalizing constant .      in this part , each intensity @xmath30 is estimated by a piecewise constant function and we propose a data - driven choice of the partition of the time interval @xmath4 $ ] . in the following @xmath60 is fixed and we start by considering a fixed partition @xmath284 of @xmath4 $ ] with partition size @xmath285 .",
    "denote @xmath286 the space of piecewise constant functions on @xmath287 .",
    "note that the total number of dyads @xmath288 is an upper bound for @xmath80 ( the variational mean number of dyads in group @xmath60 ) .",
    "following  @xcite , we consider the projection estimator of @xmath30 on @xmath286 defined as @xmath289 where the least - squares contrast is defined ( relatively to the counting process @xmath81 ) for all @xmath290,dt)$ ] by @xmath291 the ( variational ) mean number of observations @xmath72 with group membership @xmath60 occurring in time interval @xmath292 for @xmath293 is @xmath294 denote @xmath295 the length of interval @xmath292 .",
    "then the estimator @xmath296 is given by @xmath297 we remark that with a fixed partition @xmath298 , the setup is purely parametric with a finite number of parameters @xmath299 that determine the piecewise constant function @xmath300 this means that with this point of view , a classical ` m`-step can be performed with some objective function @xmath301 to be maximized with respect to @xmath108 and @xmath302 .",
    "interestingly , it turns out that the solution of this ` m`-step is exactly the same as the projection estimators given by  , that minimize the contrasts @xmath303 on @xmath286 .",
    "note that as the estimators of @xmath30 are computed separately , the approach allows to choose different partitions for different groups @xmath60 .",
    "now we turn to the choice of the partition and provide an adaptive model selection method , that is applied to every function @xmath30 separately .",
    "let @xmath304 be a finite collection of partitions of @xmath4 $ ] considered for the estimation of @xmath30 with fixed @xmath60 .",
    "adaptive estimation consists in choosing the best estimator among the collection of estimators @xmath305 with @xmath296 defined by  .",
    "the choice is based on a penalized least - squares criterion of the form @xmath306 for some penalty function @xmath307 that penalizes large partitions . following  @xcite we take for @xmath304 either the collection of regular partitions @xmath308 of @xmath4 $ ] with @xmath309 intervals each of length @xmath310 for @xmath311 , or the collection of dyadic partitions @xmath312 of @xmath4 $ ] with @xmath313 intervals of length @xmath314 for @xmath315 ( where @xmath115 and @xmath316 are to be chosen ) .",
    "furthermore , the penalty function is given by @xmath317 where @xmath318 denotes the finest partition in the collection @xmath319 , that is @xmath320 in the regular case and @xmath321 in the dyadic case , and @xmath322 denotes the @xmath323-th interval of partition @xmath324 .",
    "denote by @xmath325 the partition that minimizes @xmath326 over @xmath327 .",
    "let @xmath328 be the size of partition @xmath329 .",
    "then the adaptive estimator of intensity @xmath30 is given by @xmath330 that writes @xmath331 , \\quad \\hat { \\alpha}^{(q , l)}_{\\text{hist } } ( t ) = \\hat \\alpha_{\\hat { \\mathcal{e}}^{(q , l)}}^{(q , l)}(t )    = \\frac1{t\\bar{y}^{(q , l)}}\\sum_{k=1}^{\\hat d^{(q , l ) } } \\hat d^{(q , l)}n^{(q , l)}(e_k^{\\hat{\\mathcal e } } )    \\1_{e_k^{\\hat{\\mathcal e}}}(t).\\ ] ]      a natural stopping criterion of the variational ` em ` algorithm is based on function @xmath277 defined in .",
    "indeed , @xmath332 , where @xmath333 denotes the entropy of the distribution @xmath334 defined as @xmath335 .",
    "as our estimation procedure aims at maximizing @xmath277 , the algorithm may be stopped at iteration @xmath336 if the increase of @xmath277 is less than a given threshold @xmath337 , that is when @xmath338},\\tau^{[s+1]})-j(\\theta^{[s]},\\tau^{[s]})}{j(\\theta^{[s]},\\tau^{[s]})}\\right|<\\varepsilon.\\ ] ]    we use several initializations of the algorithm , relying on different aggregated datasets ( on the whole time interval or on sub - intervals ) and applying a k - means algorithm on the rows of the adjacency matrix of these aggregated datasets .",
    "( bold line ) and the inter - group intensity @xmath30 for @xmath212 ( dotted line ) with different shifting parameter @xmath339 . , height=340 ]                          d.  j. daley and d.  vere - jones .",
    "_ an introduction to the theory of point processes .",
    "i_. probability and its applications ( new york ) .",
    "springer - verlag , new york , second edition , 2003 . elementary theory and methods ."
  ],
  "abstract_text": [
    "<S> to model recurrent interaction events in continuous time , we propose an extension of the stochastic block model where each individual belongs to a latent group and interactions between two individuals follow a conditional inhomogeneous poisson process whose intensity is driven by the individuals latent groups . </S>",
    "<S> the model is shown to be identifiable and an estimation procedure is proposed based on a semiparametric variational expectation - maximization algorithm . </S>",
    "<S> two versions of the method are developed , using either a nonparametric histogram approach ( with an adaptive choice of the partition size ) or kernel intensity estimators . </S>",
    "<S> the number of latent groups can be selected by an integrated classification likelihood criterion . </S>",
    "<S> finally , we demonstrate the performance of our procedure on synthetic experiments and the analysis of several real datasets illustrates the utility of our approach .    </S>",
    "<S> * keywords : * dynamic interactions ; expectation - maximization algorithm ; integrated classification likelihood ; link streams ; longitudinal network ; semiparametric model ; stochastic block model ; variational approximation . </S>"
  ]
}