{
  "article_text": [
    "sparse channel estimation is an important topic found in many different applications ( see e.g @xcite and the references therein ) .",
    "in fact , in many real - world channels of practical interest , e.g. underwater acoustic channels @xcite , digital television channels @xcite , and residential ultrawideband channels @xcite , the associated impulse response tends to be sparse . to obtain an accurate channel impulse response is crucial since it is used in the decoding stage .",
    "sparsity helps one can obtain better channel estimates .",
    "in addition , the most common technique for promoting sparsity is by an @xmath0norm regularization , commonly termed as lasso @xcite .",
    "however , sparsity can be promoted in different ways .",
    "for example , in @xcite , sparsity is promoted by generating a pool of possible models , and then performing model selection .",
    "a special characteristic of ofdm systems is its sensitivity to frequency synchronizations errors ( see e.g. @xcite ) , which is produced ( among other causes ) by carrier frequency offset ( cfo ) .",
    "this adds an extra difficulty to the channel estimation problem , since the cfo must be estimated as well as other channel parameters . to estimate the cfo , maximum likelihood ( ml )",
    "estimation has been successfully utilized ( see e.g. @xcite ) .    in this work ,",
    "we combine the following problems : ( i ) estimation of a sparse channel impulse response ( cir ) in ofdm systems , ( ii ) estimation of cfo , ( iii ) estimation of the noise variance , ( iv ) estimation of the transmitted symbol , and ( v ) estimation of the ( hyper ) parameter defining the prior probability density function ( pdf ) of the sparse channel .",
    "the estimation problem is solved by utilizing a generalization of the em algorithm ( see e.g. @xcite and the references therein ) for map estimation , based on the @xmath0norm of the cir . in particular , the same methodology has been applied in @xcite for the identificaton of a sparse finite impulse response filter with quantized data .",
    "our work generalizes previous work on joint cfo and cir estimation , see @xcite and the generalization @xcite .",
    "the problem of estimating a sparse channel and the transmitted symbol has been previously addresses in the literature @xcite . in @xcite , it is also considered bit interleaved coded modulation ( bicm ) in ofdm systems .",
    "the approach in @xcite corresponds to the utilization of the _ generalized approximate message passing _ ( gamp ) algorithm @xcite , which allows for solving the bicm problem .",
    "gamp corresponds to a generalization of the _ approximate message passing _ ( amp ) algorithm @xcite , although it does not allow for unknown parameters other than the channel .",
    "the amp and gamp algorithms are based on belief propagation @xcite . when the system is linear ( with respect to the channel response ) , gamp and amp are the same algorithm @xcite .",
    "in addition , for sparsity problems , the amp algorithm corresponds to an efficient implementation of the lasso estimator , see@xcite and the references therein .",
    "hence , under the same setup , the map - em algorithm we propose and the gamp algorithm utilized in @xcite yield the same results .",
    "we consider the following ofdm system model ( see e.g. @xcite and the references therein ) , depiected in fig .",
    "[ fig : signal ] @xcite :    0 cm the channel is modelled as a finite impulse response ( fir ) filter @xmath1^t \\in \\mathbb{c}^{l}$ ] with @xmath2 taps",
    ".    cfo is modelled by @xmath3 , with @xmath4 ; @xmath5 is the _",
    "normalized _ frequency offset ( @xmath6 , @xmath7 is the number of subcarriers ) .    the cyclic prefix ( cp )",
    "is removed at the receiver .",
    "thus , the received signal is given by @xmath8 where the channel matrix @xmath9 is an @xmath10 circulant matrix whose first column is given by @xmath11 @xmath12^t $ ] , * x * is the transmitted signal ( after the inverse discrete fourier transform ) , @xmath13 is a permutation matrix that shuffles the transmitted symbol samples in any desired fashion @xcite , @xmath14 , and @xmath15 is the identity matrix of dimension @xmath7 .",
    "notice that the time - domain representation of the multicarrier signals in resembles a single - carrier system .",
    "however , the main difference corresponds to the utilization of the cyclic prefix , which yields a circulant channel matrix at the receiver after the cyclic prefix removal .",
    "[ fig : signal ]    the transmitted signal is assumed to have a deterministic part ( comprising known training data ) and a stochastic part ( comprising the unknown data ) .",
    "thus , the transmitted signal corresponds , after the application of the idft , to the time domain multiplexing of a training sequence and data coming from the data terminal equipment .",
    "we also need to express the transmitted signal in terms of the known ( training ) component , @xmath16 , and the unknown component , @xmath17 .",
    "thus , the real representation of the transmitted signal @xmath18 is given by @xmath19^t \\",
    ", \\in \\mathbb{r}^{2n_c } , \\vspace{-1mm}\\ ] ] where @xmath20 , @xmath21 , @xmath22 and @xmath23 represent the real part , imaginary part , training part , and unknown part , respectively .    for estimation purposes , it is possible to express the model in as a real - valued state - space model with sample index @xmath24 : @xmath25 { \\bar{\\textbf{x}}}+ \\bar{{\\boldsymbol{\\eta}}}_k   = \\bar{\\textbf{m}}_k   { \\bar{\\textbf{x}}}+ \\bar{{\\boldsymbol{\\eta}}}_k , \\label{eq : sss}\\ ] ] where @xmath26^t$ ] , @xmath27^t$ ] , @xmath28 is the time sample index of the ofdm symbol , @xmath29 and @xmath30 denote the real and imaginary parts , respectively",
    ", @xmath31 and @xmath32 is the @xmath24th column of the identity matrix .",
    "this state - space representation is equivalent to , but it is more convenient for the identification approach used in this work .",
    "in addition , and as it will be shown in section [ section : q_ml ] , the estimation procedure is based upon expressions in the form of @xmath33 $ ] and @xmath34 $ ] , amongst other quantities .",
    "the attainment of these two expectations can be achieved , for instance , by applying bayes rule for the _ posterior _ pdf @xmath35 for any given _ prior _ pdf @xmath36 .",
    "it is possible to extend the state - space model in by including a constant state vector that corresponds to the whole unknown transmitted signal ( see e.g ( * ? ? ?",
    "9 ) ) . that is ,",
    "notice that the subindex @xmath24 for @xmath37 in indicates that @xmath37 remains unchanged for every sample index @xmath28 .",
    "this extension allows for the utilization of _ filtering techniques _ for the attainment of ( and consequently and ) .",
    "we consider a general state - space model that can be utilized for proper and improper signals @xcite . in this sense",
    ", our approach can be applied to all common modulation schemes , such as binary phase shift keying ( bpsk ) and gaussian minimum shift keying ( gmsk ) , which are improper ( see e.g. @xcite ) .",
    "@xmath38 +    regarding the received signal , the conditional pdf of @xmath39^t$ ] is given by @xmath40 where the vector of parameters @xmath41 , @xmath42^t$ ] , and @xmath43 , \\vspace{-2mm}\\ ] ] with @xmath44 $ ] .",
    "for proper additive white noise with variance @xmath45 , @xmath46 .",
    "for the unknown part of the transmitted signal , the corresponding pdf is simply expressed as @xmath47 .",
    "this allows the transmitted signal to be generated by any modulation scheme , yielding a family of possible pdf s .    in this work",
    ", we consider a time - domain processing for the attainment of the estimates .",
    "this approach yields a special structure that closely resembles single - carrier systems @xcite .",
    "however , to be consistent with previous works , we present our method in the ofdm framework . because of the similarity of ofdm systems in time domain and single - carrier systems , the present algorithm can also be modified to cover the latter case . @xmath38 +",
    "to promote sparsity in the parameter @xmath48 , we include an @xmath49 regularization term in the form of a prior distribution , @xmath50 , which , in turn , leads to a map estimation problem .",
    "in general , map estimation allows for the inclusion of one or more terms that account for statistical prior knowledge of the parameters @xmath51 . however , here we are interested in utilizing prior knowledge of the channel impulse response only . on the other hand , in a map estimation problem ,",
    "a good estimate @xmath52 is crucial .",
    "thus , it is important to take into account @xmath53 in the definition of the problem ( see e.g. @xcite ) .",
    "if this is not done , the regularized optimization problem may be non - convex and exhibit numerical difficulties . to address this issue",
    ", we can express the prior distribution for @xmath48 as @xmath54 since we assume no prior knowledge for the channel noise variance nor the cfo , we choose non - informative marginal prior distributions , for example , @xmath55 ( see @xcite ) .",
    "then , the maximization problem becomes @xmath56 .",
    "\\ ] ] where @xmath57 is the _ likelihood _ function .    to achieve convexity",
    ", we now can use the procedure suggested in @xcite .",
    "that is , we introduce the following reparametrization : @xmath58 , @xmath59 . we therefore define a new parameter to be estimated : @xmath60 . using the new parametrization , and looking at the second term of the right hand side of",
    ", this term can expressed as a function of @xmath61 ( or equivalently of the `` individual '' terms of @xmath62 , @xmath63 is the @xmath64th element of @xmath61 , @xmath65 , as ( see e.g. @xcite ) @xmath66 where @xmath67 is a function specifying the log - prior .",
    "the em algorithm is an iterative method that generates a succession of estimates @xmath68 , @xmath69 of the parameters @xmath70 , which converges to a local maximum of the log - likelihood function ( see e.g. @xcite ) .",
    "the em algorithm consists of an iterative two - step procedure : i ) an expectation step ( e - step ) , and ii ) a maximization step ( m - step ) . in our case",
    ", we develop an augmented em algorithm to solve the map estimation problem presented in this work .",
    "the e - step consists of computing the auxiliary function @xmath71 where @xmath72 is the function corresponding to the a priori distribution .",
    "the function @xmath73 is the typical auxiliary function arising from the related ml estimation problem , given by @xmath74\\,\\vert \\textbf{y},\\hat{{\\boldsymbol{\\gamma}}}^{(i ) }    \\right ] .",
    "\\vspace{-2mm}\\ ] ]    on the other hand , the m - step consists of maximizing the auxiliary function @xmath75 , yielding @xmath76      the e - step of the em algorithm given in can be expressed as @xmath78 + k_y \\nonumber \\\\ \\label{eq : em2 } &   -\\frac{1}{2}\\mathbb{e}\\left[(\\textbf{y}-\\textbf{m } { \\bar{\\textbf{x}}})^t    { \\boldsymbol \\sigma}_y^{-1}(\\textbf{y}- \\textbf{m } { \\bar{\\textbf{x } } } ) \\vert \\textbf{y } , \\hat{\\boldsymbol{\\gamma}}^{(i)}\\right],\\vspace{-5mm}\\end{aligned}\\ ] ] where @xmath79 is a ( matrix ) function of the parameters @xmath70 , and @xmath80 .",
    "in addition , we define @xmath81 with @xmath82 and @xmath83 being the circulant matrices generated by @xmath84 and @xmath85 , respectively , and @xmath86^t$ ] .",
    "then , we can write @xmath87 . replacing this equality in , and taking the derivative of @xmath88 with respect to @xmath61 , and @xmath89 , we obtain : @xmath90 -    \\mathbb{e } [ { \\boldsymbol{{\\mathcal{m}}}}^t{\\boldsymbol{{\\mathcal{m } } } } \\vert \\textbf{y } , \\hat{\\boldsymbol{\\gamma}}^{(i ) } ] \\textbf{\\textscg } \\right),\\\\ \\frac{\\partial { \\mathcal{q}}_{\\text{ml}}}{\\partial \\rho } & = \\frac{2    n_c}{\\rho } -   2\\left ( \\rho \\textbf{y}^t \\textbf{y } -   \\textbf{y}^t    \\mathbb{e}\\left[({\\boldsymbol{{\\mathcal{m}}}})\\vert   \\textbf{y } ,      \\hat{\\boldsymbol{\\gamma}}^{(i)}\\right ]    \\textbf{\\textscg}\\right ) .",
    "\\label{eq : dq_dsigma2}\\end{aligned}\\ ] ]      we express @xmath67 as a variance - mean gaussian mixture ( vmgm ) @xcite . when expressed in terms @xmath92 , a vmgm for the parameters is given by ( see e.g @xcite ) @xmath93 where @xmath94 . in this sense , the random variable @xmath95 ( @xmath96 ) can be considered as a _",
    "hidden variable _ in the em algorithm .",
    "hence , given , the auxiliary function @xmath97 , can be expressed as @xmath98 p(\\lambda_j|\\hat{{\\text{\\textscg}}}_j^{(i)})d(\\lambda_j )     \\vspace{-3mm}\\ ] ] @xmath99+\\log    [ p(\\lambda_j ) ] \\right ) p(\\lambda_j|\\hat{{\\text{\\textscg}}}_j^{(i)})d(\\lambda_j),\\vspace{-2 mm }    \\label{eq : q_prior1}\\ ] ] since @xmath100 @xmath101 .    in the case that is given by ,",
    "then its derivative is given by where is the expectation obtained from    see @xcite .",
    "@xmath102 +    from the m - step , at the @xmath103th iteration , an estimate ( @xmath104 ) of @xmath63 is obtained .",
    "this estimate is , then , inserted into , in order to obtain an estimate of @xmath105 , which in turn is utilized in the maximization of @xmath106 . once the new estimate",
    "@xmath107 has been obtained , it is inserted into and the iteration continues until convergence has been reached .    in our particular case , we only want to promote sparsity in @xmath62 ( consequently in the cir @xmath48 ) .",
    "thus , our chosen penalty function is @xmath108 = -\\tau \\text{sign}(\\hat{{\\text{\\textscg}}}^{(i)}_j)/ \\hat{{\\text{\\textscg}}}^{(i)}_j$ ] .",
    "using this value for @xmath109 , and calculating @xmath110 we have that @xmath111 where @xmath112 .",
    "we are building our strategy on an underlying ml estimation algorithm .",
    "thus , we assume @xmath113 and @xmath114 known .",
    "the strategy is then to derive the augmented e - step considering both @xmath115 and @xmath116 with respect to @xmath61 , that is , @xmath117 using , , , and , and expressing @xmath61 as a function of @xmath5 , we have @xmath118 + \\frac{1}{2\\tau^2 } \\textbf{e }   \\right]^{-1 } \\ ! \\ ! \\mathbb{e}[{\\boldsymbol{{\\mathcal{m}}}}\\vert   \\textbf{y } , \\hat{\\boldsymbol{\\gamma}}^{(i)}]^t \\rho \\textbf{y}. \\vspace{-1mm}\\ ] ] replacing the expression for @xmath61 in , we can optimize @xmath119 in with respect to the parameter @xmath5 .",
    "thus , the parameter @xmath61 ( consequently @xmath120 ) is obtained by replacing the result of the optimization for @xmath5 in .",
    "one advantage of our method is that it allows the concentration of the cost in one variable , namely cfo . in addition , we obtain closed form expressions for the optimization of the regularized communication channel , namely cir , which , in general , is not possible with other methods when applying @xmath49-norm regularization .",
    "so far , the proposed algorithm for sparse channel estimation relies upon knowledge of @xmath121 ( or at least a good estimate of it ) .",
    "knowledge of this variable is important for accurate estimates of @xmath48 .",
    "however , having _ a priori _ knowledge of this parameter is not always possible .",
    "for example , in an urban cellular network , the channel can exhibit different behaviours depending on the location , presenting the possibility of having different values of @xmath121 ( at each one of the locations ) .",
    "thus , we seek an estimate of @xmath121 .    using , the empirical - bayes ( eb ) estimate is given by    we define an auxiliary function @xmath122 $ ] , take derivative with respect to @xmath123 , and then set the result equal to zero .",
    "@xmath102 +    in general , the computation of @xmath124 $ ] is computational expensive , requiring , in addition , many observations @xmath125 . to avoid this problem ,",
    "we approximate @xmath126\\approx    where @xmath127 and @xmath128 are the ml estimates using no regularization term , and where @xmath129 is completely known ( 100% training ) .",
    "the solution to the regularized estimation problem ( considering the reparametrization ) presented in this work can be summarized in the following steps :    * with 100% training , and no regularization term , calculate @xmath130 , * @xmath131 , and form the new variables : @xmath132 , and @xmath133 , * with a fixed @xmath134 from ( ii ) , optimize for @xmath5 after replacing in , * with the estimate ( @xmath135 ) ( consequently @xmath136 ) obtained in ( iii ) , find @xmath137 from making zero the right - hand side of , and solve a quadratic equation , * go back to ( ii ) until convergence .",
    "[ table : variance_u ]    $ ] . ]    in this section , we present a numerical example using our approach for an ofdm system with cfo .",
    "we assume that the unknown part of the time - domain transmitted signal is approximately gaussian distributed ( a consequence of the central limit theorem ) .",
    "thus , @xmath138 , where @xmath139 , @xmath140 $ ] , @xmath141 $ ] , and @xmath142 $ ] ( known ) .    the expectations on the right hand side of and can be readily calculated by applying kalman filtering to the model in .",
    "in addition , we consider that channel noise variance is unknown .",
    "we consider the following set - up : ( i ) @xmath143 , ( ii ) a sparse channel impulse response of length @xmath144 , with @xmath145 taps equal to zero , ( iii ) the transmitted signal is gaussian distributed , ( iv ) the signal to noise ratio is @xmath146 $ ] and @xmath147 $ ] , ( v ) @xmath148 , and ( vi ) @xmath149 of training . as a performance measure",
    ", we consider the normalized mean square error , defined as @xmath150 . using 100 different realizations for the noise , the results can be seen in table [ table : variance_u ] .",
    "we can conclude that regularization only helps if limited amount of data is available .",
    "for the case of @xmath151 $ ] , in fig [ fig : ber ] , the average ber for ml estimation is 0.0195 , and for map estimation is 0.0132 .",
    "in this work , we have proposed an algorithm to estimate sparse channels in ofdm systems , the cfo , the variance of the noise , the symbol , and the parameter defining the a priori distribution of the sparse channel .",
    "this is achieved in the framework of map estimation , using the em algorithm .",
    "sparsity has been promoted by using an @xmath49-norm regularization , in the form of a prior distribution for the cir .",
    "for that , the em algorithm has been modified to include this case .",
    "in addition , we have concentrated the cost function in the m - step to numerically optimize one single variable ( @xmath5 ) .",
    "the numerical examples illustrate the effectiveness of this approach for the partial training case , obtaining , in most cases studied , a lower value for nmse using regularization compared to the value for nmse using no regularization . for the full training case",
    ", there is no noticeable difference between the estimates obtained with ml and map .",
    "this confirms that prior knowledge is useful when the amount of data is limited .",
    "s. zhou , j.c .",
    "preisig , and p. willett ",
    "sparse channel estimation for muticarrier underwater acoustic communication : from subspace methods to compressed sensing ,  _ ieee trans . signal proc . , _",
    "58(3 ) , pp . 17081721 , 2010 .",
    "r. mo , y. h. chew , t. t. tjhung , and c. c. ko , `` an em - based semiblind joint channel and frequency offset estimator for ofdm systems over frequency selective fading channels , '' _ ieee trans .",
    "57(5 ) , pp.32753282 , 2008 .",
    "b. godoy , j.c .",
    "agero , r. carvajal , g.c .",
    "goodwin , and j.i .",
    "yuz , `` identification of sparse fir systems using a general quantization scheme , '' _ international journal of control _ , accepted for publication ."
  ],
  "abstract_text": [
    "<S> ' '' ''    ' '' ''    ' '' ''    ' '' '' </S>"
  ]
}