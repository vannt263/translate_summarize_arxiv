{
  "article_text": [
    "a common problem , in astronomy and in other fields , is to detect the presence and characteristics of an unknown periodic signal in irregularly - spaced data . throughout this paper",
    "i will use examples and language drawn from the study of periodic variable stars , but the techniques can be applied to many other situations .    generally , detecting periodicity is achieved by comparing the measurements phased at each of a set of trial frequencies to a model periodic phase function , @xmath2 , and selecting the frequency that yields a high value for a quality function .",
    "the commonly - used techniques vary in the form and parameterization of @xmath3 , the evaluation of the fit quality between model and data , the set of frequencies searched , and the methods used for computational efficiency .",
    "the lomb algorithm , for example , uses a sinusoid plus constant for its model function .",
    "the quality is the amplitude of the unweighted least - squares fit at the trial frequency .",
    "a simple implementation takes @xmath4 computations , where @xmath5 is the number of measurements and @xmath6 is the number of frequencies searched .",
    "@xcite present an implementation that uses the fast fourier transform ( fft ) to give @xmath7 performance .",
    "spurious detections can be produced at frequencies where the sample times have significant periodicity , power from harmonics above the fundamental sine wave is lost , and the algorithm is statistically inefficient in the sense that it ignores point - to - point variation in the measurement error .    @xcite use a lomb algorithm to find a candidate period , then test the measurements reduction between a constant value and a model periodic lightcurve obtained by folding the measurements at that period and applying smoothing .",
    "phase dispersion minimization @xcite divides a cycle into ( possibly overlapping ) phase bins .",
    "the quality is calculated from the agreement among those data points that fall into each bin at the trial frequency .",
    "this also has @xmath4 performance .",
    "the size and number of the bins , and the time of @xmath8 , are choices that can affect the detection probability of a particular signal .",
    "the fast ( hereafter 2 ) technique presented here uses a fourier series truncated at harmonic @xmath9 : @xmath10 for the model periodic function .",
    "the fit quality is the of all data , jointly minimized over the fourier coefficients , @xmath11 , and the frequency , @xmath12 .",
    "@xcite investigates the statistics of these fits .",
    "the set of frequencies searched can have arbitrary density and range .",
    "the computational complexity of this implementation is @xmath13 .",
    "the optimal choice of @xmath9 depends on the ( generally - unknown ) true shape of the periodic signal , but evaluations with multiple @xmath9 values can share computational stages , resulting in determinations at @xmath14 at only a slight premium .",
    "the fit follows standard statistics and makes efficient use of measurement errors .",
    "minimization is the standard method to fit a data set with unequal , gaussian , measurement errors .",
    "( other maximum likelihood methods can handle more general error distributions , but are beyond the scope of this paper . )",
    "a hypothesis may be expressed as a model @xmath15 , where @xmath16 is the set of unknown model parameters and @xmath17 is an independent variable .",
    "this is compared to measurements @xmath18 , with standard errors @xmath19 , made at @xmath20 .",
    "the comparison is made by finding the @xmath16 that minimizes @xmath21 ( in this paper @xmath17 is a scalar value which , for the variable star case , represents time .",
    "however , the extension of this technique to spatial or other dimensions , to higher dimension such as the @xmath22 baselines of interferometry , and to non - scalar measurements , @xmath23 , is straightforward . )",
    "if this minimum is significantly below that for a null hypothesis , then this is evidence for the model , and for the value of @xmath16 at the minimum .",
    "the extent by which the model decreases the compared to the null hypotheses , @xmath24 , is known as the minimization index and , if the null hypothesis is true and other conditions apply , has a probability distribution with the same number of degrees of freedom as the model .",
    "many models of interest are linear in some parameters , and non - linear in others .",
    "these models can be factored into the linear parameters , @xmath25 , and a set of functions @xmath26 of the non - linear parameters , @xmath27 , so that @xmath28    for any given @xmath27 , the minimized with respect to @xmath25 can be rapidly found in closed form by linear regression .",
    "finding the global minimum of thus reduces to searching the non - linear parameter space @xmath27 .",
    "the truncated fourier series function in equation [ eqtrunc ] is linear in the coefficients @xmath29 , and non - linear in @xmath30 , with component functions @xmath31 therefore , the minimum can be quickly calculated at any chosen frequency .",
    "complete , dense coverage of the frequency range of interest is required to find the overall minimum  the orthogonality of the fourier basis tends to make the minima very narrow .",
    "proceeding in the usual manner for linear regression ( see , _ numerical recipes _ @xcite ,  15.4 for a review ) we produce the @xmath32 matrix and @xmath33 vector used in the ` normal equations ' .",
    "the values of @xmath32 and @xmath33 depend on the frequency @xmath12 .",
    "the @xmath32 matrix comes from the cross terms of the model components , as a weighted sum over the data points : @xmath34    the @xmath33 vector is the weighted sum of the product of the data and the model components : @xmath35    a frequency - independent scalar , @xmath36 , which is the corresponding to a @xmath37 model : @xmath38 is also used in the calculation of .",
    "the minimization of equation [ eqchigen ] over the linear @xmath25 parameters can be shown to give a minimum subject to @xmath12 of @xmath39    the fourier coefficients corresponding to this minimum are @xmath40    we can use the trigonometric product relations : @xmath41 to reduce the cross - terms of sines and cosines in @xmath32 to @xmath42 while the terms for @xmath33 are @xmath43 where @xmath44",
    "the functions @xmath45 and @xmath46 are the cosine and sine parts of the fourier transforms of the weighted data and the weights : @xmath47    the function @xmath48 is the weighted data , and @xmath49 is the weight , as a function of time .",
    "these are both zero at times when there is no data , and dirac delta functions at the time of each measurement . @xmath50 and @xmath51",
    "can be efficiently computed by the application of the fft to @xmath52 and @xmath53 .",
    "this fft calculation of @xmath50 and @xmath51 , their use in construction of @xmath32 and @xmath33 for a set of frequencies , and the minimization by equation [ eqchix ] for each of those frequencies , are the components of the 2 algorithm .",
    "the steps in implementing a 2 search are : a ) choosing the search space b ) generating the fourier transforms c ) calculating the normal equations at each frequency d ) finding the minimum e ) interpreting the result    _ a ) choosing the search space _    the frequency range of interest , the number of harmonics , and the density of coverage may be chosen based on physical expectations , measurement characteristics , processing limitations , or other considerations .",
    "the maximum frequency searched may be where the exposure times of the observations are a large fraction of the period of the highest harmonic , or some other upper bound placed by experience or the physics of the source . at low frequencies , if there are only a few cycles or less of the fundamental over the span of all observations , a large decrease may be evidence of variability but not necessarily of periodicity .",
    "it is not necessary that the fitting function accurately represent all aspects of the physical process .",
    "sharp features in the actual phase function may require high harmonics to reproduce as a fourier sum , but can be detected with adequate sensitivity using a small number of harmonics .",
    "details of the phase function ( , the behavior on ingress and egress of an eclipsing binary ) may be determined by other techniques once a candidate frequency has been found .",
    "the density of the search  how closely the trial frequencies are spaced  affects the sensitivity as well . for a simple fourier analysis of the fundamental , a spacing of one cycle over the span of observations can cause a reduction in amplitude to @xmath54 if the true frequency is intermediate between two trial frequencies . for an analysis to harmonic @xmath9",
    ", the spacing of trial fundamental frequencies must be correspondingly tighter .",
    "the maximum sensitivity loss depends on the harmonic content of the signal , which is generally not _ a priori _ known , but a spacing much looser than @xmath55 cycles will typically lose the advantage of going to harmonic @xmath9 , while a much tighter spacing will consume resources that might be better employed with a search to @xmath56 , depending on the characteristics of the source .",
    "if @xmath57 is the timespan of all observations and @xmath58 is the fastest timescale of interest , then a reasonable maximum frequency and spacing for the fundamental would be @xmath59 and @xmath60 .    _",
    "b ) generating the fourier transforms _",
    "the calculation of @xmath61 requires evaluation of the fourier functions @xmath50 , at @xmath62 , and @xmath51 , at @xmath63 .",
    "the real - to - complex fft , as typically implemented , takes as input @xmath64 real data points from uniformly - spaced discrete times @xmath65 .",
    "if the data were not sampled at those exact times , they are ` gridded ' ( , by interpolation , or by nearest - neighbor sampling ) to estimate what the data values at those times would have been .",
    "the output of the fft is the @xmath66 complex fourier components corresponding to frequencies @xmath67 , where @xmath68 .    to provide the frequency range and density required for the 2 method , the weighted - data and the weights are placed in sparse , zero - padded arrays , with @xmath58 bin width , that cover at least @xmath69 times the observed time period",
    "this produces discrete functions ( using @xmath70 symbols to indicate discrete quantities ) @xmath71 & = \\sum_i \\hat{\\delta}[\\hat{t},\\hat{t}_i ] \\frac{x_i - \\bar{x}}{\\sigma_i^2 } \\\\",
    "\\hat{q}[\\hat{t } ] & = \\sum_i \\hat{\\delta}[\\hat{t},\\hat{t}_i ] \\frac{1}{\\sigma_i^2}\\end{aligned}\\ ] ] in this notation , hatted times are integer indices offset by a starting epoch , @xmath72 , scaled by @xmath58 , and rounded down to the lower integer : @xmath73 ; and @xmath74 is the kronecker delta : @xmath75   = \\left\\ { { \\begin{array}{cc }   1 & \\hspace{1 cm } m = n \\\\ 0 & \\hspace{1 cm } m \\not=",
    "n \\\\ \\end{array } } \\right.\\ ] ]    for numerical reasons , the measurements are adjusted by the mean value , @xmath76 and the value of @xmath77 found by the algorithm should have @xmath78 added back to find the true mean value of the source .",
    "when implemented , these discrete functions can be represented as arrays with indices @xmath79 $ ] . to search an acceptable density of frequencies , you should choose @xmath80 .",
    "most practical implementations of the fft place requirements on @xmath81 for the sake of efficiency , such as being a power of 2 or having only small prime factors .",
    "the real arrays @xmath82 $ ] and @xmath83 $ ] are then passed to an fft routine to get the complex arrays @xmath84 $ ] and @xmath85 $ ] .",
    "the discrete frequency indices @xmath86 correspond to frequencies @xmath87 .",
    "( many fft implementations use the imaginary part of the @xmath88 element to store the cosine component at the nyquist frequency @xmath89 . )    _ c ) calculating the normal equations at each frequency _    equations [ eqalphafirst][eqpq ] describe how to construct @xmath32 and @xmath33 .",
    "the @xmath32 matrix at a given @xmath90 is based on the terms of @xmath91 at indices @xmath92 .",
    "the @xmath33 vector is based on the terms of @xmath93 at @xmath94 .",
    "streamlining the notation so that @xmath95 = \\qr_n + i~\\qi_n$ ] and @xmath96 = \\pr_n + i~\\pi_n$ ] , the @xmath97 case can be written :    @xmath98    @xmath99    the minimum @xmath100 at each frequency is less than or equal to that for the constant value null hypothesis : @xmath101    the values of the fourier coefficients , @xmath102 , are not required for finding the minimum .",
    "however , they will typically be calculated as an intermediate result and may be used for further analysis .",
    "_ e ) interpreting the result _",
    "the value of @xmath90 with the largest value of @xmath103 ( and thus the lowest ) provides the best fit among the searched frequencies .",
    "the @xmath104 value tells how much better the model at that frequency fits the data than the constant - value null hypothesis does .",
    "@xmath104 must be compared to what is expected by chance , given the number of additional free parameters in the model ( @xmath69 ) and the number of trials ( representing independent frequencies searched ) .",
    "the number of independent frequencies searched can be made arbitrarily large by decreasing the gridding interval , and so any given improvement can in theory be diluted away to insignificance .",
    "however , the number of trials is only unbounded towards higher frequencies .",
    "if you search starting at low frequencies , the number of trials ` so far ' can be treated as being proportional to @xmath12 . in that case , the value to be minimized is @xmath105 where @xmath106 is the cumulative distribution with @xmath69 degrees of freedom .",
    "@xmath107 is proportional to the probability , given the null hypothesis , of finding such a large decrease in by chance at a frequency @xmath12 or below .",
    "the use of @xmath12 to adjust @xmath108 is straightforward from a frequentist perspective . from a bayesian perspective",
    "it corresponds to a prior assumption that the distribution of @xmath109 is uniform ( which is equivalent to @xmath110 being uniform ) over the search interval .",
    "a different adjustment could be made if a different bayesian prior were desired .    because the true minimum might fall between two adjacent frequency bins , and because the gridding of the data causes some sensitivity loss , frequencies in the vicinity of the minimum , and in the vicinities of other frequencies that have local minima that are almost as good ,",
    "should be searched more finely .",
    "these searches should use the ungridded data to directly calculate a locally - optimum @xmath111 and adjustments .",
    "multiple candidate frequencies can be extracted and examined to see if they can reject the null hypothesis using other statistics in combination with @xmath111 .",
    "for example , in a search for stars with transiting planets a particular shape of light curve is expected .",
    "finding an otherwise marginal @xmath111 in combination with this light curve shape would be a convincing detection .",
    "2 can quickly find all candidate frequencies with marginal or better @xmath111 .",
    "the reduced- , the ratio of the minimized to the degrees of freedom , is a useful measure of how well the data fits the model . however",
    ", even the correct frequency can produce a poor reduced - under several circumstances .",
    "the source may have a light curve that has sharp features , or is otherwise poorly - described by an @xmath9-harmonic fourier series .",
    "the source may have ` noisy ' variations in addition to periodic behavior .",
    "there may be multiple frequencies involved , as in blazhko effect rr lyraes , overtone cepheids , or eclipsing binaries where one of the components is itself variable .",
    "in all these cases , the detection of a period can provide a starting point for further analysis of the source s behavior .    because the source may be noisier ( compared to the model ) than the measurement error , an adjusted 2 may be defined @xmath112 for a noisy source",
    ", this will allow significance calculations to be based on the noise of the source , rather than the measurement error , preventing false positives due to fitting the source noise . for truly constant sources , and for sources that are accurately described by the harmonic fit",
    ", the measurement error will dominate .",
    "this is an improvement over the traditional method of using the standard deviation of the data as a surrogate for measurement error because it continues to incorporate the known instrumental characteristics and because it does not overstate the source noise of a well - behaved variable source .",
    "for any given fit , the period with the best 2 will also have the best 2 .",
    "the best - fit frequency is not necessarily the ` right answer ' .",
    "there are several effects that can produce minima at frequencies that are not the frequency of the physical system being studied .",
    "some examples of this are shown in  4 .",
    "for example , a mutual - eclipsing binary of two similar stars may be better fit at @xmath113 than at @xmath114 for a given @xmath9 .",
    "if the set of sampling times has a strong periodic component , then this can produce ` aliasing ' against periodic or long - term variations .",
    "irregular sampling improves the behavior of -based period searches . for alias peaks to be strong",
    ", there must be some frequency , @xmath115 for which a large fraction of the sampling times are clustered in phase to within a small fraction of the true source variation timescale . for many astronomical datasets taken from a single location only at night ,",
    "this is the case with @xmath116 or @xmath117 .",
    "depending on the observation strategy ( , observing each field as it transits the meridian _",
    "vs_. observing several times a night ) the clustering in phase can be tighter or looser , and thus produce greater or lesser aliasing at short periods .    if there is long - term variation in the source , then there may be alias peaks near @xmath115 and its harmonics , even if the long - term variation is aperiodic .",
    "if the source combines a high - frequency periodicity with a higher - amplitude long - term aperiodic variation , then the alias peaks can provide the lowest . to detect the short period variation ,",
    "the long - term variation may be removed with , , a polynomial fit ( although , as discussed in  4 , this will not necessarily result in an improvement ) .",
    "an initial run of the 2 algorithm with @xmath118 can be used to quickly test whether the long - term variations are themselves periodic .",
    "one advantage of methods over lomb is that they do not produce alias peaks near @xmath115 if the source is constant . near @xmath115 ,",
    "the limited phase coverage of the samples provides only weak constraints on the amplitude of the fourier components .",
    "statistical fluctuations can produce large amplitudes ( and thus high lomb values ) , but the correspondingly large standard error on the amplitude ensures that such fits do not yield a large improvement in .",
    "an implementation of the algorithm , written in c , is available at the author s website . for maximum portability and clarity",
    ", it uses the gnu scientific library ( gsl , * ? ? ? * ) and includes a driver interface that reads the input data as ascii files .",
    "the processing speed might be improved by using a different fft package , such as fftw @xcite , by stripping the gsl and cblas layers from the core blas routines , and by using binary i / o .",
    "if many sources are measured at the same set of sampling times and have proportional measurement errors ( , an imaging instrument returning to the same field of view many times ) then the same @xmath119 matrix may be reused on the @xmath120 vectors of all sources .",
    "additional speed - ups are also possible .",
    "however , before implementing such optimizations , users should balance the potential efficiency gains against the cost of the modification and determine whether the reference implementation is already fast enough for their purposes .    as a test case , the reference implementation was applied to the hipparcos epoch photometry catalogue ( hep ) @xcite .",
    "although the primary mission of hipparcos was to provide high accuracy positional astrometry , it also produced a large easily - available high - quality photometry dataset .",
    "the processed data includes variability annex 1 ( hereafter va1 ) , listing variables with periods derived from the the hipparcos data , or periods from the previous literature consistent with the hipparcos data .",
    "the hep was later reprocessed by several groups , such as @xcite , to discover additional periodic variables .",
    "the complete dataset of @xmath121 stars , averaging @xmath122 measurements each , spanning @xmath123 days , takes @xmath124 hours to search to frequencies up to @xmath125 and @xmath126 on a standard desktop computer ( a 2006 apple mac pro with 2@xmath1272 intel cores at 2.66 ghz ) .",
    "this is a factor of 2 - 3 times slower than the ` fast computation of the lomb periodogram ' code in _ numerical recipes _",
    " 13.9 , with comparable parameters for the search space , using the same computer and compiler . profiling the code during execution finds that the bulk of the cpu time is split roughly evenly between the fft and the linear regression stages .    of the 118218 stars in the hep , 115375 had sufficient high quality data to be processed by the reference implementation .",
    "( most of the others had interfering objects in the field of view . ) of these , 2275 had periods listed in va1 , @xmath128 , and had at least 50 measurements with no quality flags set spanning more than @xmath129",
    ".    in the subset of 2275 va1 stars , 2066 ( 88.5% ) had calculated periods that either agreed with ( 50.0% ) or were harmonically related to @xmath128 . in descending order of incidence , these harmonic relations were @xmath130 ( 15.7% ) ; @xmath131 ( 12.8% ) ; @xmath132 ( 9.5% ) ; and @xmath133 ( 0.6% ) .",
    "the other 262 stars ( 11.5% ) had calculated periods that were unrelated to the hep value .",
    "the reference implementation has the ability to detrend the the data with a polynomial fit ( to search for periodic variation on top of a slow irregular variation ) . however applying this to the hep data , removing variation out to @xmath134 ,",
    "decreased the agreement with the va1 periods , increasing the number of harmonically unrelated periods from 11.5% to 16.9% , and decreasing the number at @xmath128 from 50.0% to 42.4% .",
    "koen & eyer recommend that if analysis with and without such detrending find different periods , then the periods should be considered unreliable .",
    "figure  [ figfalsepos ] shows the cumulative distribution of 2 for the hep data and for randomized data .",
    "this demonstrates a well - behaved false - positive rate when observing constant sources . excluding the va1 stars ( representing 2% of the population ) a further @xmath13510% of the hep stars are clearly distinguishable from randomized data by 2 algorithm .",
    "this indicates variability in these stars , although they do not have to be strictly periodic as long as there is significant power at some period .",
    "figure [ figperiodogram ] shows a comparison of the results of the 2 and lomb algorithms for an example star , hip 69358 , which is listed as an unsolved variable in the hipparcos catalog .",
    "a single strong peak at @xmath136 is consistent with the period of @xmath137 found by @xcite .",
    "however , the lomb algorithm finds 12 peaks with higher strength than the one at that period .",
    "as seen from the folded light curves at the strongest @xmath138 and @xmath139 , 2 found the characteristic light curve of an eclipsing binary while lomb found a noise peak .",
    "cases where 2 does not find the fundamental period are useful for examining the limitations of this algorithm .",
    "some examples of this are presented in figure [ figlightcurves ] and discussed in its caption .",
    "the fast technique is a statistically efficient , statistically valid method of searching for periodicity in data that may have irregular sampling and non - uniform standard errors ."
  ],
  "abstract_text": [
    "<S> a new , computationally- and statistically - efficient algorithm , the fast @xmath0 algorithm ( 2 ) , can find a periodic signal with harmonic content in irregularly - sampled data with non - uniform errors . </S>",
    "<S> the algorithm calculates the minimized @xmath0 as a function of frequency at the desired number of harmonics , using fast fourier transforms to provide @xmath1 performance . </S>",
    "<S> the code for a reference implementation is provided . </S>"
  ]
}