{
  "article_text": [
    "convergence to the poisson distribution , for the number of occurrences of possibly dependent events , naturally arises in various applications . following the work of poisson ,",
    "there has been considerable interest in how well the poisson distribution approximates the binomial distribution .    the basic idea which serves for the starting point of the so called _ chen - stein method for the poisson approximation _",
    "is the following ( see chen ( 1975 ) ) .",
    "let @xmath0 be independent bernoulli random variables with @xmath1 .",
    "let @xmath2 and @xmath3 for every @xmath4 , and @xmath5 with mean @xmath6 .",
    "it is easy to show that @xmath7 = 0 \\label{eq : basic equation of the chen - stein method for poisson approximation}\\ ] ] holds for an arbitrary bounded function @xmath8 where @xmath9 .",
    "furthermore ( see , e.g. , chapter  2 in ross and pekz ( 2007 ) ) @xmath10 = \\sum_{j=1}^n p_j^2 \\ , { \\ensuremath{\\mathbb{e}}}\\bigl[f(v_j+2 ) - f(v_j+1 ) \\bigr ] \\label{eq : first step in the derivation of the improved lower bound on total variation distance}\\ ] ] which then serves to provide rigorous bounds on the difference between the distributions of @xmath11 and @xmath12 , by the chen - stein method for poisson approximations .",
    "this method , and more generally the so called _ stein method _",
    ", serves as a powerful tool for the derivation of rigorous bounds for various distributional approximations .",
    "nice expositions of this method are provided by , e.g. , arratia et al .",
    "( 1990 ) , ross and pekz ( 2007 ) and ross ( 2011 ) .",
    "furthermore , some interesting links between the chen - stein method and information - theoretic functionals in the context of poisson and compound poisson approximations are provided by barbour et al .",
    "( 2010 ) .    throughout this letter",
    ", the term ` distribution ' refers to a discrete probability mass function of an integer - valued random variable . in the following , we introduce some known results that are related to the presentation of the new results .",
    "let @xmath13 and @xmath14 be two probability measures defined on a set @xmath15 .",
    "then , the total variation distance between @xmath13 and @xmath14 is defined by @xmath16 where the supremum is taken w.r.t . all the borel subsets @xmath17 of @xmath15 .",
    "if @xmath15 is a countable set then is simplified to @xmath18 so the total variation distance is equal to half of the @xmath19-distance between the two probability distributions .",
    "[ definition : total variation distance ]    among old and interesting results that are related to the poisson approximation , le cam s inequality ( see le cam ( 1960 ) ) provides an upper bound on the total variation distance between the distribution of the sum @xmath20 of @xmath21 independent bernoulli random variables @xmath0 , where @xmath22 , and a poisson distribution @xmath23 with mean @xmath24 .",
    "this inequality states that @xmath25 so if , e.g. , @xmath26 for every @xmath4 ( referring to the case where @xmath11 is binomially distributed ) then this upper bound is equal to @xmath27 , decaying to zero as @xmath28 .",
    "the following theorem combines theorems  1 and 2 of barbour and hall ( 1984 ) , and its proof relies on the chen - stein method :    let @xmath20 be a sum of @xmath21 independent bernoulli random variables with @xmath1 for @xmath4 , and @xmath29 .",
    "then , the total variation distance between the probability distribution of @xmath11 and the poisson distribution with mean @xmath30 satisfies @xmath31 where @xmath32 for every @xmath33 .",
    "[ theorem : bounds on the total variation distance - barbour and hall 1984 ]    as a consequence of theorem  [ theorem : bounds on the total variation distance - barbour and hall 1984 ] , it follows that the ratio between the upper and lower bounds in is not larger than  32 , irrespectively of the values of @xmath34 .",
    "the factor @xmath35 in the lower bound was claimed to be improvable to @xmath36 with no explicit proof ( see remark  3.2.2 in barbour et al .",
    "( 1992 ) ) .",
    "this shows that , for independent bernoulli random variables , these bounds are essentially tight .",
    "furthermore , note that the upper bound in improves le cam s inequality ; for large values of @xmath30 , this improvement is by approximately a factor of @xmath37 .",
    "this letter presents new lower bounds on the total variation distance between the distribution of a sum of independent bernoulli random variables and the poisson random variable ( with the same mean ) .",
    "the derivation of these new bounds generalizes and improves the analysis by barbour and hall ( 1984 ) , based on the chen - stein method for the poisson approximation .",
    "this letter concludes by outlining a use of the new lower bounds for the analysis in sason ( 2012 ) , followed by a comparison of the new bounds to previously reported bounds .",
    "this work forms a continuation of the line of work in barbour and chen ( 2005)kontoyiannis et al .",
    "( 2005 ) where the chen - stein method was studied in the context of the poisson and compound poisson approximations , and it was linked to an information - theoretic context by barbour et al .",
    "( 2010 ) , kontoyiannis et al .",
    "( 2005 ) , and sason ( 2012 ) .",
    "in the following , we introduce an improved lower bound on the total variation distance and then provide a loosened version of this bound that is expressed in closed form .    in the setting of theorem  [ theorem : bounds on the total variation distance - barbour and hall 1984 ]",
    ", the total variation distance between the probability distribution of @xmath11 and the poisson distribution with mean @xmath30 satisfies the inequality @xmath38 where @xmath39 and @xmath40 & & \\hspace*{-0.5 cm } x_+ \\triangleq \\max\\{x , 0\\ } , \\quad x_+^2 \\triangleq \\bigl(x_+)^2 , \\quad \\forall \\ , x \\in { \\ensuremath{\\mathbb{r}}}\\\\[0.1 cm ] & & \\hspace*{-0.5 cm } g_{\\lambda}(\\alpha_1 , \\alpha_2 , \\theta ) \\triangleq \\max \\left\\ { \\ , \\left| \\left(1 + \\sqrt{\\frac{2}{\\theta \\lambda e } } \\cdot    & & \\hspace*{3.2 cm } \\left .",
    "\\left| \\left(2 e^{-\\frac{3}{2 } } + \\sqrt{\\frac{2}{\\theta \\lambda e } }   \\cdot    \\right\\ } \\label{eq",
    ": g in the lower bound on the total variation distance } \\\\[0.1 cm ] & & \\hspace*{-0.5 cm } x(u ) \\triangleq ( c_0 + c_1 u + c_2",
    "u^2 ) \\ , \\exp(-u^2 ) , \\quad \\forall \\ , u \\in { \\ensuremath{\\mathbb{r}}}\\label{eq : function x } \\\\[0.2 cm ] & & \\hspace*{-0.5 cm } \\{u_i\\ } \\triangleq \\bigl\\ { u \\in { \\ensuremath{\\mathbb{r } } } : \\ , 2 c_2 u^3 + 2 c_1 u^2 - 2(c_2 - c_0 ) u - c_1 = 0\\bigr\\ } \\label{eq : zeros of a cubic polynomial equation } \\\\[0.1 cm ] & & \\hspace*{-0.5 cm } c_0 \\triangleq ( \\alpha_2 - \\alpha_1 ) ( \\lambda - \\alpha_2 ) \\label{eq : c0 } \\\\ & & \\hspace*{-0.5 cm } c_1 \\triangleq \\sqrt{\\theta \\lambda } \\ , ( \\lambda + \\alpha_1 - 2 \\alpha_2 ) \\label{eq : c1 } \\\\ & & \\hspace*{-0.5 cm } c_2 \\triangleq -\\theta \\lambda .",
    "\\label{eq : c2}\\end{aligned}\\ ] ] [ theorem : improved lower bound on the total variation distance ]    see section  [ subsubsection : proof of the theorem with the improved lower bound on the total variation distance ] .",
    "the derivation relies on the chen - stein method for the poisson approximation , and it improves ( significantly ) the constant in the lower bound of theorem  2 of barbour and hall ( 1984 ) .    the upper and lower bounds on the total variation distance in scale like @xmath41 , similarly to the known bounds in theorem  [ theorem : bounds on the total variation distance - barbour and hall 1984 ] ,",
    "but they offer a significant improvement in their tightness ( see section  [ section : connection of the improved lower bounds with known results ] ) .",
    "the cardinality of the set @xmath42 in is equal to  3 ( see section  [ subsubsection : proof of the theorem with the improved lower bound on the total variation distance ] ) . [",
    "remark : the size of the set of real zeros is equal to 3 ]    the optimization that is required for the computation of @xmath43 in w.r.t .",
    "the three parameters @xmath44 and @xmath45 is performed numerically .    in the following ,",
    "we introduce a looser lower bound on the total variation distance as compared to the lower bound in theorem  [ theorem : improved lower bound on the total variation distance ] , but its advantage is that it is expressed in closed form .",
    "both lower bounds improve ( significantly ) the lower bound in theorem  2 of barbour and hall ( 1984 ) .",
    "the following lower bound follows from theorem  [ theorem : improved lower bound on the total variation distance ] via the special choice of @xmath46 that is included in the optimization set for @xmath43 on the right - hand side of . following this sub - optimal choice , the lower bound in the next corollary",
    "is obtained by a derivation of a closed - form expression for the third free parameter @xmath45 ( in fact , this was our first step towards the derivation of an improved lower bound on the total variation distance ) .    under the assumptions in theorem",
    "[ theorem : improved lower bound on the total variation distance ] , then @xmath47 where @xmath48 & & \\hspace*{-1 cm } \\theta \\triangleq 3 + \\frac{7}{\\lambda } + \\frac{1}{\\lambda } \\cdot \\sqrt{(3\\lambda+7)\\bigl[(3 + 2e^{-1/2 } ) \\lambda + 7\\bigr]}. \\label{eq : optimal theta for alpha1 and alpha2 equal to lambda}\\end{aligned}\\ ] ] [ corollary : lower bound on the total variation distance ]    see section  [ subsubsection : proof of the corollary with the improved lower bound on the total variation distance ] .",
    "we conclude our discussion in this letter by outlining a use of the new lower bounds in this work : the use of the new lower bound on the total variation distance for the poisson approximation of a sum of independent bernoulli random variables is exemplified by sason ( 2012 ) .",
    "this work introduces new entropy bounds for discrete random variables via maximal coupling , providing bounds on the difference between the entropies of two discrete random variables in terms of the local and total variation distances between their probability mass functions .",
    "the new lower bound on the total variation distance for the poisson approximation from this work was involved in the calculation of some improved bounds on the difference between the entropy of a sum of independent bernoulli random variables and the entropy of a poisson random variable of the same mean .",
    "a possible application of the latter problem is related to getting bounds on the sum - rate capacity of a noiseless @xmath49-user binary adder multiple - access channel ( see sason ( 2012 ) ) .",
    "the proof of theorem  [ theorem : improved lower bound on the total variation distance ] starts similarly to the proof of theorem  2 of barbour and hall ( 1984 ) .",
    "however , it significantly deviates from the original analysis in order to derive an improved lower bound on the total variation distance .",
    "let @xmath0 be independent bernoulli random variables with @xmath1 .",
    "let @xmath2 , @xmath3 for every @xmath4 , and @xmath5 with mean @xmath6 . from the basic equation of the chen - stein method , equation holds for an arbitrary bounded function @xmath8 .",
    "furthermore , it follows from the proof of theorem  2 of barbour and hall ( 1984 ) that @xmath50 \\bigr\\}}{2 \\ , \\sup_{k \\in { \\ensuremath{\\mathbb{n}}}_0 } \\bigl| \\lambda f(k+1 ) - k f(k ) \\bigr| } \\label{eq : fourth step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] which holds , in general , for an arbitrary bounded function @xmath8 .    at this point , we deviate from the proof of theorem  2 of barbour and hall ( 1984 ) by generalizing and refining ( in a non - trivial way ) the original analysis .",
    "the general problem with the current lower bound in is that it is not calculable in closed form for a given @xmath51 , so one needs to choose a proper function @xmath51 and derive a closed - form expression for a lower bound on the right - hand side of . to this end , let @xmath52 where @xmath44 and @xmath45 are fixed constants ( note that @xmath53 in needs to be positive for @xmath51 to be a bounded function ) . in order to derive a lower bound on the total variation distance",
    ", we calculate a lower bound on the numerator and an upper bound on the denominator of the right - hand side of for the function @xmath51 in . referring to the numerator of the right - hand side of with @xmath51 in , for every @xmath54 , @xmath55 & & = \\int_{v_j + 1 - \\alpha_2}^{v_j + 2 - \\alpha_2 } \\frac{\\mathrm{d}}{\\mathrm{d}u } \\left ( ( u+\\alpha_2-\\alpha_1 ) \\ , \\exp\\bigl(-\\frac{u^2}{\\theta \\lambda}\\bigr ) \\right ) \\ , \\mathrm{d}u   \\nonumber \\\\[0.2 cm ] & & = \\int_{v_j + 1 - \\alpha_2}^{v_j + 2 - \\alpha_2 } \\left(1 - \\frac{2u ( u+\\alpha_2-\\alpha_1)}{\\theta \\lambda } \\right ) \\exp\\bigl(-\\frac{u^2}{\\theta \\lambda}\\bigr ) \\ ,",
    "\\mathrm{d}u \\nonumber \\\\[0.2 cm ] & & = \\int_{v_j + 1 - \\alpha_2}^{v_j + 2 - \\alpha_2 } \\left(1 - \\frac{2 u^2}{\\theta \\lambda}\\right ) \\ , \\exp\\bigl(-\\frac{u^2}{\\theta \\lambda}\\bigr ) \\ , \\mathrm{d}u - \\frac{2(\\alpha_2 - \\alpha_1)}{\\theta \\lambda } \\int_{v_j + 1 - \\alpha_2}^{v_j + 2 - \\alpha_2 }",
    "u \\ , \\exp\\bigl(-\\frac{u^2}{\\theta \\lambda}\\bigr ) \\ , \\mathrm{d}u \\nonumber \\\\[0.2 cm ] & & = \\int_{v_j + 1 - \\alpha_2}^{v_j + 2 - \\alpha_2 } \\left(1 - \\frac{2 u^2}{\\theta \\lambda}\\right ) \\ , \\exp\\bigl(-\\frac{u^2}{\\theta \\lambda}\\bigr ) \\ , \\mathrm{d}u \\nonumber \\\\ & & \\hspace*{0.4 cm } - ( \\alpha_2 - \\alpha_1 ) \\left [ \\exp\\biggl(-\\frac{(v_j + 2 - \\alpha_2)^2}{\\theta \\lambda}\\biggr ) - \\exp\\biggl(-\\frac{(v_j + 1 - \\alpha_2)^2}{\\theta \\lambda}\\biggr ) \\right ] .",
    "\\label{eq : fifth step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] we rely in the following on the inequality @xmath56 applying it to the integral on the right - hand side of gives that @xmath55 & & \\geq \\int_{v_j + 1 - \\alpha_2}^{v_j + 2 - \\alpha_2 } \\left(1 - \\frac{3 u^2}{\\theta \\lambda}\\right ) \\",
    ", \\mathrm{d}u - ( \\alpha_2 - \\alpha_1 ) \\left [ \\exp\\biggl(-\\frac{(v_j + 2 - \\alpha_2)^2}{\\theta \\lambda}\\biggr ) - \\exp\\biggl(-\\frac{(v_j + 1 - \\alpha_2)^2}{\\theta \\lambda}\\biggr ) \\right ] \\nonumber \\\\[0.1 cm ] & & \\geq 1 - \\frac{\\bigl(v_j + 2 - \\alpha_2\\bigr)^3 - \\bigl(v_j + 1 - \\alpha_2\\bigr)^3}{\\theta \\lambda } \\nonumber \\\\[0.1 cm ] & & \\hspace*{0.4 cm } - \\bigl|\\alpha_2 - \\alpha_1\\bigr| \\cdot \\left| \\exp\\biggl(-\\frac{(v_j + 2 - \\alpha_2)^2}{\\theta \\lambda}\\biggr ) - \\exp\\biggl(-\\frac{(v_j + 1 - \\alpha_2)^2}{\\theta \\lambda}\\biggr ) \\right| .",
    "\\label{eq : sixth step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] in order to proceed , note that if @xmath57 then ( on the basis of the mean - value theorem of calculus ) @xmath58 \\\\[0.1 cm ] & & \\leq e^{-\\min\\{x_1 , x_2\\ } } \\ , |x_1 - x_2|\\end{aligned}\\ ] ] which , by applying it to the second term on the right - hand side of , gives that for every @xmath54 @xmath59 & & \\leq \\exp\\left(-\\frac{\\min\\bigl\\{(v_j+2-\\alpha_2)^2 , \\ , ( v_j+1-\\alpha_2)^2 \\bigr\\}}{\\theta \\lambda}\\right ) \\cdot \\left(\\frac{(v_j+2-\\alpha_2)^2-(v_j+1-\\alpha_2)^2}{\\theta \\lambda}\\right ) \\ , .",
    "\\label{eq : seventh step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] since @xmath60 then @xmath61 & & \\geq \\left\\ { \\begin{array}{cl } 0 \\quad & \\mbox{if $ \\alpha_2 \\geq 1 $ } \\\\[0.1",
    "cm ] ( 1-\\alpha_2)^2 \\quad & \\mbox{if $ \\alpha_2 < 1 $ } \\end{array } \\right .",
    "\\nonumber \\\\[0.1 cm ] & & = \\bigl(1-\\alpha_2\\bigr)_{+}^2 \\label{eq : 8th step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] where @xmath62 hence , the combination of the two inequalities in  gives that @xmath59 & & \\leq \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\cdot \\left(\\frac{\\left|(v_j + 2 - \\alpha_2)^2 - ( v_j + 1 - \\alpha_2)^2 \\right|}{\\theta \\lambda } \\right ) \\nonumber \\\\[0.1 cm ] & & = \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\cdot \\frac{\\left|2v_j + 3 - 2 \\alpha_2 \\right|}{\\theta \\lambda } \\nonumber \\\\[0.1 cm ] & & \\leq \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\cdot \\frac{2v_j + \\left|3 - 2 \\alpha_2 \\right|}{\\theta \\lambda } \\label{eq : ninth step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] and therefore , a combination of the inequalities in and gives that @xmath55 & & \\geq 1 - \\frac{\\bigl(v_j + 2 - \\alpha_2\\bigr)^3 - \\bigl(v_j + 1 - \\alpha_2\\bigr)^3}{\\theta \\lambda } \\nonumber \\\\[0.1 cm ] & & \\hspace*{0.4 cm } - \\bigl|\\alpha_2 - \\alpha_1\\bigr| \\cdot \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\cdot \\frac{2v_j + \\left|3 - 2 \\alpha_2 \\right|}{\\theta \\lambda } \\ ; .",
    "\\label{eq : 10th step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] let @xmath63 ; then @xmath55 & & \\geq 1 - \\frac{\\bigl(u_j + \\lambda + 2 - \\alpha_2\\bigr)^3 - \\bigl(u_j + \\lambda + 1 - \\alpha_2\\bigr)^3}{\\theta \\lambda } \\nonumber \\\\[0.1 cm ] & & \\hspace*{0.4 cm } - \\bigl|\\alpha_2 - \\alpha_1\\bigr| \\cdot \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\cdot \\frac{2u_j + 2\\lambda + \\left|3 - 2 \\alpha_2 \\right|}{\\theta \\lambda } \\nonumber \\\\[0.1 cm ] & & = 1 - \\frac{3 u_j^2 + 3 \\bigl(3 - 2\\alpha_2 + 2 \\lambda\\bigr ) u_j + ( 2-\\alpha_2+\\lambda)^3 - ( 1-\\alpha_2+\\lambda)^3}{\\theta \\lambda } \\nonumber \\\\[0.1 cm ] & & \\hspace*{0.4 cm } - \\bigl|\\alpha_2 - \\alpha_1\\bigr| \\cdot \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\cdot \\frac{2u_j + 2\\lambda + \\left|3 - 2 \\alpha_2 \\right|}{\\theta \\lambda } \\ ; .",
    "\\label{eq : 11th step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] in order to derive a lower bound on the numerator of the right - hand side of , for the function @xmath51 in , we need to calculate the expected value of the right - hand side of . to this end",
    ", the first and second moments of @xmath64 are calculated as follows : @xmath65 where equality  ( a ) holds since the binary random variables @xmath0 are independent and @xmath66 . by taking expectations on both sides of , one obtains from and that @xmath67 \\nonumber \\\\[0.2 cm ] & & \\geq 1 - \\frac{3 \\bigl(\\lambda - p_j - \\sum_{i \\neq j } p_i^2 + p_j^2\\bigr ) + 3 \\bigl(3 - 2\\alpha_2 + 2 \\lambda\\bigr ) \\bigl(-p_j \\bigr ) + ( 2-\\alpha_2+\\lambda)^3 - ( 1-\\alpha_2+\\lambda)^3}{\\theta \\lambda } \\nonumber \\\\[0.2 cm ] & & \\hspace*{0.4 cm } - \\bigl|\\alpha_2 - \\alpha_1\\bigr| \\cdot \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\cdot \\left(\\frac{-2p_j + 2\\lambda + \\left|3 - 2 \\alpha_2",
    "\\right|}{\\theta \\lambda } \\right ) \\nonumber \\\\[0.2 cm ] & & = 1 - \\frac{3 \\lambda + ( 2-\\alpha_2+\\lambda)^3 - ( 1-\\alpha_2+\\lambda)^3 - \\bigl[3p_j(1-p_j ) + 3 \\sum_{i \\neq j } p_i^2 + 3 \\bigl(3 - 2\\alpha_2 + 2 \\lambda\\bigr ) p_j \\bigr]}{\\theta \\lambda } \\nonumber \\\\[0.2 cm ] & & \\hspace*{0.4 cm } - \\biggl(\\frac{\\bigl|\\alpha_2 - \\alpha_1\\bigr| \\ , \\bigl(2\\lambda - 2 p_j+ \\left|3 - 2 \\alpha_2 \\right| \\bigr)}{\\theta \\lambda } \\biggr ) \\cdot \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right ) \\nonumber \\\\[0.2 cm ] & & \\geq 1 - \\frac{3 \\lambda + ( 2-\\alpha_2+\\lambda)^3 - ( 1-\\alpha_2+\\lambda)^3 - \\bigl(9 - 6\\alpha_2 + 6 \\lambda\\bigr ) p_j}{\\theta \\lambda } \\nonumber",
    "\\\\[0.2 cm ] & & \\hspace*{0.4 cm } - \\biggl(\\frac{\\bigl|\\alpha_2 - \\alpha_1\\bigr| \\ , \\bigl(2\\lambda+ \\left|3 - 2 \\alpha_2 \\right| \\bigr)}{\\theta \\lambda } \\biggr ) \\cdot \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda }",
    "\\right ) \\ ; .",
    "\\label{eq : 12th step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] therefore , from , the following lower bound on the right - hand side of holds @xmath68 \\bigr\\ } \\geq \\left ( \\frac{3\\bigl(3 - 2\\alpha_2 + 2\\lambda\\bigr)}{\\theta \\lambda } \\right ) \\sum_{j=1}^n p_j^3 \\nonumber \\\\ & & \\hspace*{-1.2 cm } + \\left(1-\\frac{3 \\lambda + ( 2-\\alpha_2+\\lambda)^3 - ( 1-\\alpha_2+\\lambda)^3 + |\\alpha_1 - \\alpha_2| \\bigl(2\\lambda+|3 - 2\\alpha_2|\\bigr ) \\exp\\left(-\\frac{(1-\\alpha_2)_+^2}{\\theta \\lambda } \\right)}{\\theta \\lambda } \\right ) \\sum_{j=1}^n p_j^2 \\ , .",
    "\\label{eq : 12.5th step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] note that if @xmath69 , which is a condition that is involved in the maximization of , then the first term on the right - hand side of can be removed , and the resulting lower bound on the numerator of the right - hand side of takes the form @xmath70 \\bigr\\ } \\geq \\bigl(1 - h_{\\lambda}(\\alpha_1 , \\alpha_2 , \\theta ) \\bigr ) \\sum_{j=1}^n p_j^2 \\label{eq : 13th step in the derivation of the improved lower bound on total variation distance}\\ ] ] where the function @xmath71 is introduced in .",
    "we turn now to deriving an upper bound on the denominator of the right - hand side of .",
    "therefore , we need to derive a closed - form upper bound on @xmath72 with the function @xmath51 in . for every @xmath73 , @xmath74 + ( \\lambda - k ) \\ , f(k ) .",
    "\\label{eq : 14th step in the derivation of the improved lower bound on total variation distance}\\ ] ] in the following , we derive bounds on each of the two terms on the right - hand side of , and we start with the first term .",
    "let @xmath75 then @xmath76 for every @xmath73 , and by the mean - value theorem of calculus , @xmath77 \\nonumber \\\\ & & = \\left(1-\\frac{2 c_k^2}{\\theta \\lambda}\\right ) \\",
    ", \\exp\\left(-\\frac{c_k^2}{\\theta \\lambda}\\right ) + \\left(\\frac{2(\\alpha_1-\\alpha_2 ) c_k}{\\theta \\lambda}\\right ) \\ , \\exp\\left(-\\frac{c_k^2}{\\theta \\lambda}\\right ) \\ , .",
    "\\label{eq : 15th step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] referring to the first term on the right - hand side of , let @xmath78 then the global maximum and minimum of @xmath79 over the non - negative real line are obtained at @xmath80 and @xmath81 , respectively , and therefore @xmath82 let @xmath83 ; then it follows that the first term on the right - hand side of satisfies the inequality @xmath84 furthermore , referring to the second term on the right - hand side of , let @xmath85 then the global maximum and minimum of @xmath86 over the real line are obtained at @xmath87 and @xmath88 , respectively , and therefore @xmath89 let this time @xmath90 ; then it follows that the second term on the right - hand side of satisfies @xmath91 hence , on combining the equality in with the two inequalities in and , it follows that the first term on the right - hand side of satisfies @xmath92 \\leq \\lambda + \\sqrt{\\frac{2\\lambda}{\\theta e } } \\cdot |\\alpha_1 - \\alpha_2| \\ , , \\quad \\forall \\ , k \\in { \\ensuremath{\\mathbb{n}}}_0 . \\label{eq : 18th step in the derivation of the improved lower bound on total variation distance}\\ ] ] we continue the analysis by a derivation of bounds on the second term of the right - hand side of . for the function @xmath51 in",
    ", it is equal to @xmath93 \\ , \\bigl [ ( k-\\alpha_2)+(\\alpha_2-\\alpha_1 ) \\bigr ] \\",
    ", \\exp\\biggl(-\\frac{(k-\\alpha_2)^2}{\\theta \\lambda}\\biggr ) \\nonumber \\\\ & & = \\bigl [ ( \\lambda-\\alpha_2 ) ( k-\\alpha_2 ) + ( \\alpha_2-\\alpha_1 ) ( \\lambda-\\alpha_2 ) - ( k-\\alpha_2)^2 + ( \\alpha_1 - \\alpha_2 ) ( k-\\alpha_2 ) \\bigr ] \\ , \\exp\\biggl(-\\frac{(k-\\alpha_2)^2}{\\theta \\lambda}\\biggr ) \\nonumber \\\\[0.1 cm ] & & = \\bigl [ \\sqrt{\\theta \\lambda } \\ , ( \\lambda-\\alpha_2 ) \\ , v_k - \\theta \\lambda \\ , v_k^2 - \\sqrt{\\theta \\lambda } \\ , ( \\alpha_2 - \\alpha_1 ) \\ , v_k + ( \\alpha_2 - \\alpha_1 ) ( \\lambda - \\alpha_2 ) \\bigr ] \\ , e^{-v_k^2 } \\ , , \\quad v_k \\triangleq \\frac{k-\\alpha_2}{\\sqrt{\\theta \\lambda } } \\ ; \\ ; \\forall \\ , k \\in { \\ensuremath{\\mathbb{n}}}_0 \\nonumber \\\\ & & = ( c_0 + c_1 v_k + c_2 v_k^2 ) \\ , e^{-v_k^2 } \\label{eq : 19th step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] where the coefficients @xmath94 and @xmath95 are introduced in eqs .   ,",
    "respectively . in order to derive bounds on the left - hand side of , let us find the global maximum and minimum of the function @xmath96 in : @xmath97 note that @xmath98 and @xmath96 is differentiable over the real line , so the global maximum and minimum of @xmath96 are attained at finite points and their corresponding values are finite . by setting the derivative of @xmath96 to zero",
    ", we have that the candidates for the global maximum and minimum of @xmath96 over the real line are the real zeros @xmath42 of the cubic polynomial equation in .",
    "note that by their definition in , the values of @xmath42 are _ independent _ of the value of @xmath73 , and also the size of the set @xmath42 is equal to  3 ( see remark  [ remark : the size of the set of real zeros is equal to 3 ] ) . hence , it follows from that @xmath99 where these bounds on the second term on the right - hand side of are independent of the value of @xmath73 .    in order to get bounds on the left - hand side of ,",
    "note that from the bounds on the first and second terms on the right - hand side of ( see and , respectively ) then for every @xmath73 @xmath100 & & \\leq \\lambda \\ , f(k+1 ) - k \\ , f(k ) \\nonumber \\\\[0.1 cm ] & & \\leq \\max_{i \\in \\{1 , 2 , 3\\ } } \\{x(u_i)\\ } + \\lambda + \\sqrt{\\frac{2\\lambda}{\\theta e } } \\cdot |\\alpha_1 - \\alpha_2| \\label{eq : 21st step in the derivation of the improved lower bound on total variation distance}\\end{aligned}\\ ] ] which yields that the following inequality is satisfied : @xmath101 where the function @xmath102 is introduced in . finally , by combining the inequalities in eqs .  , and , the lower bound on the total variation distance in follows .",
    "the existing upper bound on the total variation distance in was derived in theorem  1 of barbour and hall ( 1984 ) ( see theorem  [ theorem : bounds on the total variation distance - barbour and hall 1984 ] here ) .",
    "this completes the proof of theorem  [ theorem : improved lower bound on the total variation distance ] .",
    "corollary  [ corollary : lower bound on the total variation distance ] follows as a special case of theorem  [ theorem : improved lower bound on the total variation distance ] when the proposed function @xmath51 in is chosen such that two of its three free parameters ( i.e. , @xmath103 and @xmath104 ) are determined sub - optimally , and its third parameter ( @xmath53 ) is determined optimally in terms of the sub - optimal selection of the two other parameters .",
    "more explicitly , let @xmath103 and @xmath104 in be set to be equal to @xmath30 ( i.e. , @xmath46 ) . from ",
    ", this setting implies that @xmath105 and @xmath106 ( since @xmath107 ) .",
    "the cubic polynomial equation in , which corresponds to this ( possibly sub - optimal ) setting of @xmath103 and @xmath104 , is @xmath108 whose zeros are @xmath109 .",
    "the function @xmath96 in therefore takes the form @xmath110 so @xmath111 and @xmath112 .",
    "this implies that @xmath113 and therefore @xmath71 and @xmath102 in and , respectively , are simplified to @xmath114 this sub - optimal setting of @xmath103 and @xmath104 in implies that the coefficient @xmath43 in is replaced with a loosened version @xmath115 let @xmath116 ; then is simplified to @xmath117 .",
    "it therefore follows from , and  that @xmath118 where @xmath119 and , in general , @xmath120 due to the above restricted constraint on @xmath53 ( see versus ) . differentiating the function inside the supremum w.r.t . @xmath53 and setting its derivative to zero , one gets the following quadratic equation in @xmath53 : @xmath121 whose positive solution is the optimized value of @xmath53 in .",
    "furthermore , it is clear that this value of @xmath53 in is larger than , e.g. , 3 , so it satisfies the constraint in .",
    "this completes the proof of corollary  [ corollary : lower bound on the total variation distance ] .",
    "the new lower bounds on the total variation distance in theorem  [ theorem : improved lower bound on the total variation distance ] and corollary  [ corollary : lower bound on the total variation distance ] scale like @xmath41 , similarly to the known upper and lower bounds in theorem  [ theorem : bounds on the total variation distance - barbour and hall 1984 ] that originally appear in theorems  1 and 2 of barbour and hall ( 1984 ) .",
    "however , the new lower bounds offer a significant improvement over the known lower bound in theorem  [ theorem : bounds on the total variation distance - barbour and hall 1984 ] .",
    "more explicitly , from theorems  1 and 2 of barbour and hall ( 1984 ) , the ratio between the upper and lower bounds on the total variation distance ( see ) is equal to 32 in the two extreme cases where @xmath122 or @xmath123 . in the following ,",
    "we calculate the ratio of the same upper bound and the new lower bound in corollary  [ corollary : lower bound on the total variation distance ] at these two extreme cases . in the limit where @xmath123 , this ratio tends to @xmath124 & & = \\frac{2}{e } \\ , \\lim_{\\lambda \\rightarrow \\infty } \\frac{\\theta \\bigl(2 e^{-{1/2}}+\\theta \\bigr)}{\\theta-\\bigl(3+\\frac{7}{\\lambda}\\bigr ) } \\nonumber \\\\[0.1 cm ] & & = \\frac{6}{e } \\ , \\left(1+\\sqrt{1+\\frac{2}{3 } \\cdot e^{-1/2 } } \\right)^2 \\approx 10.539 \\label{eq : limit of the ratio between the upper and lower bounds on the total variation distance when lambda tends to infinity}\\end{aligned}\\ ] ] where the last equality follows from , since @xmath125",
    ". furthermore , the limit of this ratio when @xmath122 is equal to @xmath126 & & \\stackrel{\\text{(a)}}{= } \\frac{28}{e } \\ , \\lim_{\\lambda \\rightarrow 0 } \\left(\\frac{2 e^{-{1/2}}+\\theta)}{\\theta-\\bigl(3+\\frac{7}{\\lambda}\\bigr)}\\right ) \\nonumber \\\\ & & \\stackrel{\\text{(b)}}{= } \\frac{56}{e } \\approx 20.601 \\label{eq : limit of the ratio between the upper and lower bounds on the total variation distance when lambda tends to zero}\\end{aligned}\\ ] ] where equalities  ( a ) and ( b ) hold since , from , it follows that @xmath127 .",
    "this implies that corollary  [ corollary : lower bound on the total variation distance ] improves the original lower bound on the total variation distance in theorem  2 of barbour and hall ( 1984 ) by a factor of @xmath128 in the limit where @xmath123 , and it also improves it by a factor of @xmath129 if @xmath122 while still having a closed - form expression for the lower bound in corollary  [ corollary : lower bound on the total variation distance ] .",
    "the only reason for this improvement is related to the optimal choice of the free parameter @xmath53 in , versus its sub - optimal choice in the proof of theorem  2 of barbour and hall ( 1984 ) . this observation has motivated to further improve the lower bound by introducing the two additional parameters @xmath44 in theorem  [ theorem : improved lower bound on the total variation distance ] ; these parameters give two additional degrees of freedom in the function @xmath51 in ( according to the proof in section  [ subsubsection : proof of the corollary with the improved lower bound on the total variation distance ] , these two parameters are set to be equal to @xmath30 for the derivation of the loosened and simplified bound in corollary  [ corollary : lower bound on the total variation distance ] ) .",
    "the improvement in the lower bound of theorem  [ theorem : improved lower bound on the total variation distance ] ( in comparison to corollary  [ corollary : lower bound on the total variation distance ] ) is especially dominant for low values of @xmath30 , as is shown in figure  [ figure : ratio ot upper and lower bounds on the total variation distance ] . note , however , that no improvement is obtained for high values of @xmath30 ( e.g. , for @xmath130 , as is shown by figure  [ figure : ratio ot upper and lower bounds on the total variation distance ] on noticing that the curves in this plot merge at large values of @xmath30 ) .",
    "the lower bound on the total variation distance in theorem  [ theorem : improved lower bound on the total variation distance ] implies the bound in corollary  [ corollary : lower bound on the total variation distance ] ( see the proof in section  [ subsubsection : proof of the corollary with the improved lower bound on the total variation distance ] ) .",
    "corollary  [ corollary : lower bound on the total variation distance ] further implies the lower bound on the total variation distance in theorem  2 of barbour and hall ( 1984 ) ( see theorem  [ theorem : bounds on the total variation distance - barbour and hall 1984 ] here ) .",
    "the latter claim follows from the fact that the lower bound in with the coefficient @xmath131 in was loosened in the proof of theorem  2 of barbour and hall ( 1984 ) by a sub - optimal selection of the parameter @xmath53 , which leads to a lower bound on @xmath131 ( the sub - optimal selection of @xmath53 in the proof of theorem  2 of barbour and hall ( 1984 ) is @xmath132 ) . on the other hand , the optimized value of @xmath53 that is used in provides an exact closed - form expression for @xmath131 in , and it leads to the derivation of the improved lower bound in corollary  [ corollary : lower bound on the total variation distance ] .",
    "theorem  1.2 of deheuvels and pfeifer ( 1986 ) provides an asymptotic result for the total variation distance between the distribution of the sum @xmath11 of @xmath21 independent bernoulli random variables with @xmath1 and the poisson distribution with mean @xmath24 .",
    "it shows that when @xmath133 and @xmath134 as @xmath28 then @xmath135 this implies that the ratio of the upper bound on the total variation distance in theorem  1 of barbour and hall ( 1984 ) ( see theorems  [ theorem : bounds on the total variation distance - barbour and hall 1984 ] here ) and this asymptotic expression is equal to @xmath136 .",
    "therefore , the ratio between the exact asymptotic value in and the new lower bound in is equal to @xmath137 .",
    "it therefore follows that , in the limit where @xmath122 , the new lower bound on the total variation in is smaller than the exact value by no more than 1.69 , and for @xmath138 , it is smaller than the exact asymptotic result by a factor of 2.55 .    : the anonymous reviewer is acknowledged for suggestions that led to improvement of the presentation of this paper .",
    "this research work was supported by the israeli science foundation ( isf ) , grant number 12/12 .",
    "arratia , r. , goldstein , l. , gordon , l. , 1990 . poisson approximation and the chen - stein method . statistical science  5 , 403424 .",
    "+ barbour , a.d . , chen , l. h. y. , 2005 .",
    "an introduction to stein s method .",
    "lecture notes series , institute for mathematical sciences , singapore university press and world scientific .",
    "+ barbour , a.d . , hall , p. , 1984 .",
    "on the rate of poisson convergence .",
    "mathematical proceedings of the cambridge philosophical society  95 , 473480 .",
    "+ barbour , a.d . ,",
    "holst , l. , janson , s. , 1992 .",
    "poisson approximation .",
    "oxford university press .",
    "+ barbour , a. d. , johnson , o. , kontoyiannis , i. , madiman , m. , 2010 .",
    "compound poisson approximation via information functionals .",
    "electronic journal of probability  15 , 13441369 .",
    "+ chen , l.h.y .",
    "poisson approximation for dependent trials .",
    "annals of probability  3 , 534545 .",
    "+ deheuvels , p. , pfeifer , d. , 1986 . a semigroup approach to poisson approximation .",
    "annals of probability  14 , 663676 .",
    "+ kontoyiannis , i. , harremos , p. , johnson , o. , 2005 .",
    "entropy and the law of small numbers .",
    "ieee trans . on information theory  51 , 466472 .",
    "+ le cam , l. , 1960 .",
    "an approximation theorem for the poisson binomial distribution .",
    "pacific journal of mathematics  10 , 11811197 .",
    "+ ross , s.m . , pekz , e.a .",
    "2007 . a second course in probability . probability bookstore .",
    "+ ross , n. , 2011 . fundamentals of stein s method .",
    "probability surveys  8 , 210293 .",
    "+ sason , i. , 2012 .",
    "entropy bounds for discrete random variables via coupling .",
    "[ online ] .",
    "available : http://arxiv.org/abs/1209.5259 ."
  ],
  "abstract_text": [
    "<S> new lower bounds on the total variation distance between the distribution of a sum of independent bernoulli random variables and the poisson random variable ( with the same mean ) are derived via the chen - stein method . </S>",
    "<S> the new bounds rely on a non - trivial modification of the analysis by barbour and hall ( 1984 ) which surprisingly gives a significant improvement . </S>",
    "<S> a use of the new lower bounds is addressed .    _ </S>",
    "<S> keywords : _ chen - stein method , poisson approximation , total variation distance . </S>"
  ]
}