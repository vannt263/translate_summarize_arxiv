{
  "article_text": [
    "the pagerank algorithm ( pra ) @xcite is a cornerstone element of the google search engine which allows to perform an efficient information retrieval from the world wide web ( www ) and other enormous directed networks created by the modern society during last two decades @xcite .",
    "the ranking based on pra finds applications in such diverse fields as physical review citation network @xcite , scientific journals rating @xcite , ranking of tennis players @xcite and many others @xcite .",
    "the pra allows to find efficiently the pagerank vector of the google matrix of the network whose values enable to rank the nodes . for a given network with @xmath3 nodes the google matrix",
    "is defined as @xmath4 where the matrix @xmath5 is obtained from an adjacency matrix @xmath6 by normalizing all nonzero colummns to one ( @xmath7 ) and replacing columns with only zero elements by @xmath8 ( _ dangling nodes _ ) . for the www an element @xmath9 of the adjacency matrix is equal to unity if a node @xmath10 points to node @xmath11 and zero otherwise . here",
    "@xmath12 is the unit column vector and @xmath13 is its transposition .",
    "the damping parameter @xmath14 in the www context describes the probability @xmath15 to jump to any node for a random surfer . for www",
    "the google search uses @xmath16 @xcite .",
    "the matrix @xmath17 belongs to the class of perron - frobenius operators naturally appearing for markov chains and dynamical systems @xcite . for @xmath18",
    "there is only one maximal eigenvalue @xmath19 of @xmath17 .",
    "the corresponding eigenvector is the pagerank vector which has nonnegative components @xmath20 with @xmath21 , which can be ranked in decreasing order to give the pagerank index @xmath22 .",
    "for www it is known that the probability distribution @xmath23 of @xmath20 values is described by a power law @xmath24 with @xmath25 @xcite , corresponding to the related cumulative dependence @xmath26 with @xmath27 at @xmath28 .",
    "the pagerank performs ranking which in average is proportional to the number of ingoing links @xcite , putting at the top the most known and popular nodes .",
    "however , in certain networks outgoing links also play an important role .",
    "recently , on the examples of the procedure call network of linux kernel software @xcite and the wikipedia articles network @xcite , it was shown that a relevant additional ranking is obtained by considering the network with inverse link directions in the adjacency matrix corresponding to @xmath29 and constructing from it a reverse google matrix @xmath30 according to relation ( [ eq1 ] ) at the same @xmath14 .",
    "the eigenvector of @xmath30 with eigenvalue @xmath19 gives then a new pagerank @xmath31 with ranking index @xmath32 , which was named cheirank @xcite .",
    "it rates nodes in average proportionally to the number of outgoing links highlighting their communicative properties @xcite . for www one",
    "finds @xmath33 @xcite so that the decay of cheirank @xmath34 is characterized by a slower decay exponent @xmath35 compared to pagerank . in fig .",
    "[ fig1 ] , we show pagerank and cheirank distributions for the www networks of the universities of cambridge and oxford ( 2006 ) , obtained from the database @xcite .     and cheirank @xmath36 versus the corresponding rank indexes @xmath37 and @xmath38 for the www networks of cambridge 2006 ( left panel ) and oxford 2006 ( right panel ) ; here @xmath39 ( @xmath40 ) and the number of links is @xmath41 ( @xmath42 ) for cambridge ( oxford).,scaledwidth=70.0% ]    due to importance of pagerank for information retrieval and ranking of various directed networks @xcite it is important to understand how it is affected by the variation of the damping parameter @xmath14 . in the limit @xmath43 the pagerank is determined by the eigenvectors of the highly degenerate eigenvalue @xmath44 @xcite .",
    "these eigenvectors correspond by definition to invariant subspaces through the matrix @xmath5 .",
    "it is known @xcite that in general these subspaces correspond to sets of nodes with ingoing links from the rest of the network but no outgoing link to it .",
    "these parts of the network have been given different names in the literature ( rank sink , out component , bucket , and so on ) .",
    "in this paper , we show that for large matrices of size up to several millions the structure of these invariant subspaces is universal and study in detail the universal behavior of the pagerank at @xmath43 related to the spectrum of @xmath17 , using an optimized arnoldi algorithm .",
    "we note that this behavior is linked to the internal structure of the network . indeed , it is possible to randomize real networks by randomly exchanging the links while keeping exactly the same number of ingoing and outgoing links .",
    "it was shown in @xcite that this process generally destroys the structure of the network and creates a huge gap between the first unit eigenvalue and the second eigenvalue ( with modulus below @xmath45 ) . in this case",
    "the pagerank simply goes for @xmath43 to the unique eigenvector of the matrix @xmath5 associated with the unit eigenvalue .",
    "the paper is organized as follows : in section 2 we discuss the spectrum and subspace structure of the google matrix ; in section 3 we present the construction of invariant subspaces , the numerical method of pagerank computation at small damping factors is given in section 4 , the projected power method is described in section 5 , universal properties of pagerank are analyzed in section 6 and discussion of the results is given in section 7 .",
    "in order to obtain the invariant subspaces , for each node we determine iteratively the set of nodes that can be reached by a chain of non - zero matrix elements . if this set contains all nodes of the network , we say that the initial node belongs to the _ core space _ @xmath46 . otherwise , the limit set defines a subspace which is invariant with respect to applications of the matrix @xmath5 . in a second step",
    "we merge all subspaces with common members , and obtain a sequence of disjoint subspaces @xmath47 of dimension @xmath48 invariant by applications of @xmath5 .",
    "this scheme , which can be efficiently implemented in a computer program , provides a subdivision of network nodes in @xmath49 core space nodes ( typically 70 - 80% of @xmath3 ) and @xmath50 subspace nodes belonging to at least one of the invariant subspaces @xmath47 inducing the block triangular structure , @xmath51 where the subspace - subspace block @xmath52 is actually composed of many diagonal blocks for each of the invariant subspaces .",
    "each of these blocks correspond to a column sum normalized matrix of the same type as @xmath17 and has therefore at least one unit eigenvalue thus explaining the high degeneracy .",
    "its eigenvalues and eigenvectors are easily accessible by numerical diagonalization ( for full matrices ) thus allowing to count the number of unit eigenvalues , e.g. 1832 ( 2360 ) for the www networks of cambridge 2006 ( oxford 2006 ) and also to verify that all eigenvectors of the unit eigenvalue are in one of the subspaces .",
    "the remaining eigenvalues of @xmath5 can be obtained from the projected core block @xmath53 which is not column sum normalized ( due to non - zero matrix elements in the block @xmath54 ) and has therefore eigenvalues strictly inside the unit circle @xmath55 .",
    "we have applied the arnoldi method ( am ) @xcite with arnoldi dimension @xmath56 to determine the largest eigenvalues of @xmath53 . for both example networks",
    "this provides at least about 4000 numerical accurate eigenvalues in the range @xmath57 .",
    "for the two networks the largest core space eigenvalues are given by @xmath58 ( 0.999982435081 ) with a quite clear gap @xmath59 ( @xmath60 ) .",
    "we also mention that the largest subspace eigenvalues with modulus below 1 also have a comparable gap @xmath60 . in order to obtain this accuracy",
    "it is highly important to apply the am to @xmath53 and not to the full matrix @xmath5 ( see more details below ) . in the latter case",
    "the am fails to determine the degeneracy of the unit eigenvalue and for the same value of @xmath61 it produces less accurate results .",
    "( blue dots or crosses ) and core space eigenvalues ( red dots ) in @xmath62plane ( green curve shows unit circle ) ; here @xmath63 ( 30579 ) , there are 1543 ( 1889 ) invariant subspaces , with maximal dimension 4656 ( 1545 ) and the sum of all subspace dimensions is @xmath63 ( 30579 ) .",
    "the core space eigenvalues are obtained from the arnoldi method applied to the block @xmath64 with arnoldi dimension 20000 and are numerically accurate for @xmath57 .",
    "_ middle row : _ eigenvalue spectrum for the matrix @xmath65 , corresponding to the cheirank , for cambridge 2006 ( left panel ) and oxford 2006 ( right panel ) with red dots for core space eigenvalues ( obtained by the arnoldi method applied to @xmath66 with @xmath67 ) , blue crosses for subspace eigenvalues and the green curve showing the unit circle . _ bottom row : _",
    "fraction @xmath68 of eigenvalues with @xmath69 for the core space eigenvalues ( red bottom curve ) and all eigenvalues ( blue top curve ) from top row data .",
    "the number of eigenvalues with @xmath70 is 3508 ( 3275 ) of which 1832 ( 2360 ) are at @xmath71 ; it larger than the number of invariant subspaces which have each at least one unit eigenvalue.,scaledwidth=70.0% ]    in fig .",
    "[ fig2 ] we present the spectra of subspace and core space eigenvalues in the complex plane @xmath72 as well as the fraction of eigenvalues with modulus larger than @xmath73 , showing that subspace eigenvalues are spread around the unit circle being closer to @xmath74 than core eigenvalues .",
    "the fraction of states with @xmath69 has a sharp jump at @xmath19 , corresponding to the contribution of @xmath50 , followed by an approximate linear growth .",
    "we now turn to the implications of this structure to the pagerank vector @xmath75 ; it can be formally expressed as @xmath76 let us first assume that @xmath5 is diagonalizable ( with no non - trivial jordan blocks ) .",
    "we denote by @xmath77 its ( right ) eigenvectors and expand the vector @xmath78 in this eigenvector basis with coefficients @xmath79 . inserting this expansion in eq .",
    "( [ pagerank1 ] ) , we obtain @xmath80 in the case of non - trivial jordan blocks we may have in the second sum contributions @xmath81 with some integer @xmath82 smaller or equal to the size of the jordan block @xcite .",
    "suppose we have for example a jordan block of dimension 2 with a principal vector @xmath83 such that @xmath84 with @xmath77 the corresponding eigenvector . from this",
    "we obtain for arbitrary integer @xmath85 the following condition on the 1-norm of these vectors  : @xmath86 showing that one should have @xmath87 if @xmath70 . even if @xmath88 this condition is hard to fulfill for all @xmath85 if @xmath89 is close to 1 . in general",
    "the largest eigenvalues with modulus below 1 are not likely to belong to a non - trivial jordan block ; this is indeed well verified for our university networks since the largest core space eigenvalues are not degenerate .    here",
    "( [ pagerank2 ] ) indicates that in the limit @xmath43 the pagerank converges to a particular linear combination of the eigenvectors with @xmath90 , which are all localized in one of the subspaces . for a finite value of @xmath91",
    "the scale of this convergence is set by the condition @xmath92 ( @xmath93 ) and the corrections for the contributions of the core space nodes are @xmath94 . in order to test this behavior",
    "we have numerically computed the pagerank vector for values @xmath95 . for @xmath96 , the usual power method (",
    "iterating the matrix @xmath17 on an initial vector ) is very slow and in many cases fails to converge with a reasonable precision . in order to get the pagerank vector in this regime",
    ", we use a combination of power and arnoldi methods that allowed us to reach the precision @xmath97 : after each @xmath98 iterations with the power method we use the resulting vector as initial vector for an arnoldi diagonalization choosing an arnoldi matrix size @xmath61 ; the resulting eigenvector for the largest eigenvalue is used as a new vector to which we apply the power method and so on until convergence by the condition @xmath97 is reached . for the university network data of @xcite in most cases",
    "the values @xmath99 and @xmath100 ( @xmath101 for cambridge 2006 ) provide convergence with about @xmath102 iterations of the process ( for @xmath103 ) .",
    "additional details are given below .",
    "in order to construct the invariant subspaces we use the following scheme which we implemented in an efficient computer program .    for each node @xmath104 we determine iteratively a sequence of sets @xmath105 , with @xmath106 and @xmath107 containing the nodes @xmath108 which can be reached by a non - zero matrix element @xmath109 from one of the nodes @xmath110 .",
    "depending on the initial node @xmath10 there are two possibilities : a ) @xmath105 increases with the iterations until it contains all nodes of the network , especially if one set @xmath105 contains a dangling node connected ( by construction of @xmath5 ) to all other nodes , or b ) @xmath105 saturates at a limit set @xmath111 of small or modest size @xmath112 . in the first case , we say that the node @xmath10 belongs to the _ core space _ @xmath46 . in the second case",
    "the limit set defines a subspace @xmath47 of dimension @xmath48 which is invariant with respect to applications of the matrix @xmath5 .",
    "we call the initial node @xmath10 the _ root node _ of this subspace ; the members of @xmath111 do not need to be tested themselves as initial nodes subsequently since they are already identified as _ subspace nodes_. if during the iterations a former root node appears as a member in a new subspace one can absorb its subspace in the new one and this node loses its status as root node .",
    "furthermore , the scheme is greatly simplified if during the iterations a dangling node or another node already being identified as core space node is reached . in this case",
    "one can immediately attribute the initial node @xmath10 to the core space as well .    for practical reasons it may be useful to stop the iteration",
    "if the set @xmath105 contains a macroscopic number of nodes larger than @xmath113 where @xmath114 is some constant of order one and to attribute in this case the node @xmath10 to the core space .",
    "this does not change the results provided that @xmath113 is above the maximal subspace dimensions . for the university networks we studied ,",
    "the choice @xmath115 turned out to be sufficient since there is always a considerable number of dangling nodes .    in this way",
    ", we obtain a subdivision of the nodes of the network in @xmath49 core space nodes ( typically 70 - 80% of @xmath3 ) and @xmath50 subspace nodes belonging to at least one of the invariant subspaces @xmath47 .",
    "however , at this point it is still possible , even likely , that two subspaces have common members .",
    "therefore in a second step we merge all subspace with common members and choose arbitrarily one of the root nodes as the `` root node '' of the new bigger subspace which is of course also invariant with respect to @xmath5 .",
    "we can also mention that most of the subspaces contain one or more `` zero nodes '' ( of first order ) with outgoing links to the subspace but no incoming links from the same or other subspaces ( but they may have incoming links from core space nodes as every subspace node ) .",
    "these nodes correspond to complete zero lines in the corresponding diagonal block for this subspace in the matrix @xmath5 and therefore they produce a trivial eigenvalue zero . furthermore , there are also zero nodes of higher order @xmath10 ( @xmath116 ) which have incoming subspace links only from other zero nodes of order @xmath117 resulting in a non - trivial jordan block structure with eigenvalue zero . in other words ,",
    "when one applies the matrix @xmath5 to a vector with non - zero elements on all nodes of one subspace one eliminates successively the zero nodes of order @xmath118 and finally the resulting vector will have non - zero values only for the other `` non - zero nodes '' . due to this any subspace eigenvector of @xmath5 with an eigenvalue different from zero ( and in particular the pagerank vector ) can not have any contribution from a zero node .    in a third step of our scheme",
    "we therefore determined the zero nodes ( of all orders ) and the reduced subspaces without these zero nodes .",
    "the results for the distribution of subspace dimensions is discussed in section 6 ( see the left panel of fig .  [ fig7 ] ) .",
    "the distribution is essentially unchanged if we use the reduced subspaces since the number of zero nodes is below @xmath119 of @xmath50 for most of universities . only for the matrix @xmath65 of",
    "wikipedia we have about @xmath120 of zero nodes that reduces the value of @xmath50 from 21198 to 11625 .",
    "once the invariant subspaces of @xmath5 are known it is quite obvious to obtain numerically the exact eigenvalues of the subspaces , including the exact degeneracies .",
    "thus , using the arnoldi method we determine the largest remaining eigenvalues of the core projected block @xmath53 . in fig .",
    "[ fig2 ] the complex spectra of subspace and core space eigenvalues of @xmath5 and @xmath65 are shown for the two networks of cambridge 2006 and oxford 2006 as well as the fraction of eigenvalues with modulus larger than @xmath73 indicating a macroscopic fraction of about 2% of eigenvalues with @xmath70 .    in table 1 , we summarize the main quantities of networks studied : network size @xmath3 , number of network links @xmath121 , number of subspace nodes @xmath50 and average subspace dimension @xmath122 for the university networks considered in fig .  [ fig4 ] and the matrix @xmath123 of wikipedia .",
    ".[table1 ] network parameters [ cols=\"<,^,^,^,^\",options=\"header \" , ]     in fig .",
    "[ fig4 ] we compare these gap values to the other university networks for which we found by the arnoldi method larger gaps @xmath124 .     versus its rank index @xmath125 for the university networks with a small core space gap @xmath126 .",
    ", scaledwidth=70.0% ]    in fig .",
    "[ fig5 ] we show the eigenvectors @xmath127 obtained by the projected power method versus their rank index @xmath125 defined by the ordering of the components of theses vectors .",
    "we can clearly identify the exponential localization on 40 nodes for leeds 2006 or 110 nodes for cambridge 2002 , 2003 and 2005 with values below @xmath128 ( leeds 2006 ) or @xmath129 ( cambridge 2002 , 2003 and 2005 ) .",
    "the case cambridge 2004 with a quite larger gap @xmath130 provides at first the same exponential localization as the other three cases of cambridge but after 50 nodes it goes over to a tail in the range @xmath131 to @xmath132 . in all cases",
    "the range of values of the small tail is in qualitative agreement with the gap values in the table 2 and the expression ( [ good_lambda_gap ] ) .",
    "when the iteration with the matrix @xmath5 starts at the maximal node the vector diffuses first quite slowly inside the localization domain for a considerable number of iterations ( 46 for leeds 2006 and 35 for cambridge 2002 , 2003 and 2005 ) until it reaches a dangling node at which point the diffusion immediately extends to the full network since the dangling node is artificially connected to all nodes .",
    "however , at this point the probability of the amplitude is already extremely small .",
    "therefore the initial node belongs technically to the core space ( since it is `` connected '' to all other nodes ) but practically it defines a quasi subspace ( since the probability to leave the localization domain is very small @xmath133 or @xmath134 ) . at @xmath103 , which is much larger than the gap",
    ", this quasi subspace also contributes to the pagerank in the same way as the exact invariant subspaces .",
    "this provides somehow a slight increase of the effective value of @xmath50 but it does not change the overall picture as described in section 2 .    fig .",
    "[ fig5 ] also shows that apparently the particular network structure responsible for this quasi subspace behavior is identical for the three cases cambridge 2002 , 2003 and 2005 . for cambridge 2004",
    "this structure also exists but here there is one additional dangling node which is reached at an earlier point of the initial slow diffusion providing delocalization on a scale @xmath135 . for the case of cambridge 2006 with a `` large '' gap @xmath136 this structure seems to be completely destroyed but this may be due to one single modified matrix element @xmath137 if compared to the networks of the previous years .",
    "using the powerful numerical methods described above we turn to the analysis of universal properties of pagerank .",
    "[ fig6 ] clearly confirms the theoretical picture given in section 2 of the limit behavior for the pagerank at @xmath1 . in particular one",
    "can clearly identify the limit where it is localized in the invariant subspaces @xcite with only small corrections @xmath138 at the core space nodes .",
    "we also determine the eigenvector of the largest core space eigenvalue @xmath139 of the projected matrix @xmath53 . in the lower panels of fig .",
    "[ fig6 ] , we compare the pagerank at @xmath103 with this vector ( normalized by the 1-norm ) multiplied by @xmath140 . we observe that except for a very small number of particular nodes this vector approximates quite well the core space correction of the pagerank even though the corrections due to the second term in ( [ pagerank2 ] ) are more complicated with contributions from many eigenvectors . in the inserts , we also show the fidelity of the pagerank , which decays from 1 at @xmath141 to about 0.188 ( 0.097 ) at @xmath103 , and the residual weight @xmath142 of the core space @xmath46 in the pagerank which behaves as @xmath143 [ @xmath144 for @xmath145 .     for @xmath146 .",
    "numerical precision is such that @xmath147 . _",
    "bottom row : _ @xmath148 at @xmath103 .",
    "blue crosses correspond to the eigenvector of the largest core space eigenvalue @xmath58 ( 0.999982435081 ) multiplied by @xmath149 .",
    "the arrow indicates the first position where a site of the core space @xmath46 contributes to the rank index ; all sites at its left are in an invariant subspace .",
    "insert shows the residual weight @xmath150 with @xmath142 of the core space @xmath46 in the pagerank and the difference @xmath151 versus @xmath91 where @xmath152 is the pagerank fidelity with respect to @xmath153 , i.e. @xmath154 .",
    "note that @xmath155 since the pagerank is normalized through the 1-norm : @xmath156 .",
    "the limiting value @xmath157 ( 0.097481331613 ) is obtained from linear extrapolation from the data with smallest values of @xmath91 which we verified to be exact up to machine precison .",
    ", scaledwidth=70.0% ]    as mentioned in the previous section , we also determine the subspace structure and the pagerank at @xmath103 for other university networks available at @xcite and for the matrix @xmath158 of wikipedia @xcite with @xmath159 and @xmath160 ( it turns out that the matrix @xmath5 for wikipedia provides only very few small size subspaces with no reliable statistics ) .",
    "a striking feature is that the distribution of subspace dimensions @xmath48 is universal for all networks considered ( fig .",
    "[ fig7 ] left panel ) .",
    "the fraction of subspaces with dimensions larger than @xmath161 is well described by the power law @xmath162 with the dimensionless variable @xmath163 , where @xmath122 is the average subspace dimension .",
    "the fit of all cases gives @xmath164 .",
    "it is interesting to note that the value of @xmath165 is close to the exponent of poincar recurrences in dynamical systems @xcite .",
    "possible links with the percolation on directed networks ( see e.g. @xcite ) are still to be elucidated .",
    "the rescaled pagerank @xmath166 ( or cheirank @xmath167 for the case of wikipedia ) takes a universal form with a power law @xmath168 for @xmath169 with an exponent @xmath170 and @xmath171 close to zero for @xmath172 ( see right panel of fig .",
    "[ fig7 ] ) .     with dimensions larger than @xmath161 as a function of the rescaled variable @xmath163 .",
    "upper curves correspond to cambridge ( green ) and oxford ( blue ) for years 2002 to 2006 and middle curves ( shifted down by a factor of 10 ) to the university networks of glasgow , cambridge , oxford , edinburgh , ucl , manchester , leeds , bristol and birkbeck for year 2006 with @xmath122 between 14 and 31 .",
    "lower curve ( shifted down by a factor of 100 ) corresponds to the matrix @xmath158 of wikipedia with @xmath173 .",
    "the thick black line is @xmath174 .",
    "_ right panel : _ rescaled pagerank @xmath175 versus rescaled rank index @xmath176 for @xmath103 and @xmath177 for the same university networks as in the left panel ( upper and middle curves , the latter shifted down and left by a factor of 10 ) .",
    "the lower curve ( shifted down and left by a factor of 100 ) shows the rescaled cheirank of wikipedia @xmath178 versus @xmath179 with @xmath160 .",
    "the thick black line corresponds to a power law with exponent @xmath180 .",
    ", scaledwidth=70.0% ]    for certain university networks , cambridge 2002 , 2003 and 2005 and leeds 2006 , there is a specific complication .",
    "indeed , the am ( with @xmath181 ) provides a maximal core space eigenvalue @xmath139 _ numerically _ equal to 1 , which should not be possible .",
    "a more careful evaluation by a different algorithm , based on the power method ( iterating @xmath5 with a subsequent core space projection ) and measuring the loss of probability at each iteration , shows that this eigenvalue is indeed very close but still _ smaller _ than 1 .",
    "for the three cases of cambridge we find @xmath182 and for leeds 2006 : @xmath183 ( see details in section 5 ) .",
    "the corresponding eigenvectors are exponentially localized on a small number of nodes ( about 110 nodes for cambridge and 40 nodes for leeds 2006 ) being very small ( @xmath184 for cambridge and @xmath185 for leeds 2006 ) on other nodes .",
    "these quasi - subspaces with small number of nodes belong _ technically _ to the core space , since they are eventually linked to a dangling node , but when starting from the maximal node of these eigenvectors it takes a considerable number of iterations with a strong reduction of probability to reach the dangling node . since their eigenvalue is very close to 1 , these quasi - subspaces also contribute to the pagerank at @xmath103 in the same way as the exact invariant subspaces .",
    "however , since the size of these quasi - subspaces is small they do not change the overall picture and we can still identify a region of large pagerank with @xmath50 subspace or quasi - subspace nodes and vanishing pagerank for the other core space nodes . for most of the other universities and also the matrix @xmath158 of",
    "wikipedia we have @xmath186 ( and @xmath187 for cambridge 2004 ) .",
    "our results show that for @xmath1 the pagerank vector converges to a universal distribution @xmath188 determined by the invariant subspaces ( with @xmath189 ) .",
    "the fraction of nodes which belong to these subspaces varies greatly depending on the network , but the distribution of the subspace sizes is described by a universal function @xmath190 that reminds the properties of critical percolation clusters .",
    "when @xmath14 decreases from @xmath44 , the pagerank undergoes a transition which allows to properly rank all nodes .",
    "this process is controlled by the largest eigenvalues of the core matrix @xmath53 , which are strictly below @xmath44 but can be extremely close to it .",
    "their distance from @xmath44 sets the scale of the transition , and the associated eigenvectors of @xmath53 control the new ranking of nodes .",
    "although at @xmath191 the eigenspace for eigenvalue @xmath44 can be very large , for @xmath14 sufficiently larger in norm than the eigenvalues of @xmath53 , the pagerank remains fixed when @xmath1 , in a way reminiscent of degenerate perturbation theory in quantum mechanics .",
    "our highly accurate numerical method based on alternations of arnoldi iterations and direct iterations of @xmath17 matrix enables to determine the correct pagerank even where the scale of this transition is extremely small ( @xmath192 ) and the matrix size is very large ( up to several millions ) .",
    "the very slow convergence of the power method in this regime is reminiscent of very long equilibration times in certain physical systems ( e.g. spin glasses ) , and thus arnoldi iterations can be viewed as a certain kind of simulated annealing process which enables to select the correct eigenvector among many others with very close eigenvalues .",
    "the pagerank in this regime of @xmath1 shows universal properties being different from the usual pagerank at @xmath16 , with a different statistical distribution .",
    "this can be used to refine search and ranking in complex networks and hidden communities extraction .",
    "finally we note that usually in quantum physics one deals with unitary matrices with a real spectrum . in the case of directed markov chains",
    "we naturally obtain a complex spectrum . in physical quantum systems",
    "a complex spectrum appears in positive quantum maps @xcite , problems of decoherence and quantum measurements @xcite and random matrix theory of quantum chaotic scattering @xcite .",
    "thus we hope that a cross - fertilization between complex matrices and directed network will highlight in a new way the properties of complex networks .",
    "we thank calmip for supercomputer access and a.d.chepelianskii for help in data collection from @xcite .",
    "99 brin s. and page l. 1998 _ computer networks and isdn systems _ * 30 * , 107 . langville a m and meyer c d 2006 _ google s pagerank and beyond : the science of search engine rankings _",
    "( princeton : princeton university press ) .",
    "redner s. 2005 _ phys . today",
    "_ * 58 * , 49 .",
    "radicchi f. , fortunato s. , markines b. , and vespignani a. 2009 _ phys .",
    "e _ * 80 * , 056103 .",
    "west j.d . ,",
    "bergstrom t.c . , and",
    "bergstrom c. t. 2010 _ coll .",
    "_ * 71 * , 236 ; ` http://www.eigenfactor.org/ ` radicchi f. 2011 _ plos one _ * 6 * , e17249 .",
    "avrachenkov k. , donato d. and litvak n. ( eds . ) 2009 _ algorithms and models for the web - graph : proc .",
    "of 6th international workshop , waw 2009 barcelona _ _ lect .",
    "notes comp .",
    "sci . _ * 5427 * ( 2009 ) .",
    "brin m. and stuck g. 2002 _ introduction to dynamical systems _ , ( cambridge : cambridge univ .",
    "donato d. , laura l. , leonardi s. and millozzi s. 2005 _ eur .",
    "j. b _ * 38 * , 239 ; pandurangan g. , raghavan p. and upfal e. 2005 _ internet math .",
    "_ * 3 * , 1 .",
    "litvak n. , scheinhardt w. r. w. and volkovich y. 2008 _ lect .",
    "notes comp .",
    "sci . _ * 4936 * , 72 .",
    "chepelianskii a. d. 2010 _ towards physical laws for software architecture _ , arxiv:1003.5455[cs.se ] .",
    "zhirov a. o. , zhirov o. v. and shepelyansky d. l. 2010 _ eur .",
    "j. b _ * 77 * , 523 .",
    "` academic web link database project ` ` http://cybermetrics.wlv.ac.uk/database/ ` serra - capizzano s. 2005 _ siam j. matrix anal .",
    "* 27 * , 305 .",
    "avrachenkov k. , litvak n. and pham k. s. 2007 _ lect .",
    "notes comp .",
    "_ * 4863 * , 16 ; boldi p. , santini m. and vigna s. 2009 _ acm trans . on inf",
    "_ * 27 * , 19 .",
    "giraud o. , georgeot b. and shepelyansky d.  l. 2009 _ phys .",
    "e _ * 80 * , 026107 .",
    "stewart g. w. 2001 _ matrix algorithms volume ii : eigensystems _ , ( siam ) .",
    "golub g. h. and greif c. 2006 _ bit num . math .",
    "_ * 46 * , 759 .",
    "frahm k. m. and shepelyansky d. l. 2010 _ eur .",
    "j. b _ * 76 * , 57 . in certain invariant subspaces , there are nodes with no ingoing links from the same subspace , which do not contribute to the pagerank for @xmath193 . except for wikipedia ( cheirank ) , they are very few in our data and their effect is not visible in the figures .",
    "schwartz n. , cohen r. , ben - avraham d. , barabasi a .-",
    "havlin s. 2002 _ phys .",
    "e _ * 66 * , 015104(r ) .",
    "bruzda w. , cappellini v. , sommers h .- j .",
    ", zyczkowski k. 2009 _ phys .",
    "a _ * 373 * , 320 .",
    "bruzda w. , smaczynski , m. , cappellini v. , sommers h .- j . and zyczkowski k. 2010 _ phys . rev .",
    "e _ * 81 * , 066209 .",
    "guhr t. , mller - groeling a. and weidenmller h.a .",
    "1998 _ phys .",
    "rep . _ * 299 * , 189 ."
  ],
  "abstract_text": [
    "<S> the pagerank algorithm enables to rank the nodes of a network through a specific eigenvector of the google matrix , using a damping parameter @xmath00,1[$ ] . </S>",
    "<S> using extensive numerical simulations of large web networks , with a special accent on british university networks , we determine numerically and analytically the universal features of pagerank vector at its emergence when @xmath1 . </S>",
    "<S> the whole network can be divided into a core part and a group of invariant subspaces . for @xmath2 </S>",
    "<S> the pagerank converges to a universal power law distribution on the invariant subspaces whose size distribution also follows a universal power law . </S>",
    "<S> the convergence of pagerank at @xmath2 is controlled by eigenvalues of the core part of the google matrix which are extremely close to unity leading to large relaxation times as for example in spin glasses . </S>"
  ]
}