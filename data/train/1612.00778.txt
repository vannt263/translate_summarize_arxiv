{
  "article_text": [
    "what do reported uncertainties actually tell us about the accuracy of scientific measurements and the likelihood that different measurements will disagree ?",
    "no scientist expects different research studies to always agree , but the frequent failure of published research to be confirmed has generated much concern about scientific reproducibility @xcite .",
    "when scientists investigate many quantities in very large amounts of data , interesting but ultimately false results may occur by chance and are often published . in particle physics ,",
    "bitter experience with frequent failures to confirm such results eventually led to an ad hoc `` 5-sigma '' discovery criterion @xcite , i.e. a `` discovery '' is only taken seriously if the estimated probability for observing the result without new physics is less than the chance of a single sample from a normal distribution being more than five standard deviations ( `` @xmath1 '' ) from the mean .    in other fields , arguments that most novel discoveries are false @xcite",
    "have caused increased emphasis on reporting the value and uncertainty of measured quantities , not just whether the value is statistically different from zero @xcite .",
    "research confirmation is then judged by how well independent studies agree according to their reported uncertainties , so assessing reproducibility requires accurate evaluation and realistic understanding of these uncertainties .",
    "this understanding is also required when analysing data , combining studies in meta - analyses , or making scientific , business , or policy judgments based on research .",
    "the experience of research fields such as physics , where values and uncertainties have long been regularly reported , may provide some guidance on what reproducibility can reasonably be expected @xcite .    most recent investigations into reproducibility focus on",
    "how often observed effects disappear in subsequent research , revealing strong selection bias in published results .",
    "removing such bias is extremely important , but may not reduce the absolute number of false discoveries since not publishing non - significant results does not make the `` discoveries '' go away . controlling the rate of false discoveries depends on establishing criteria that reflect real measurement uncertainties , especially the likelihood of extreme fluctuations and outliers @xcite .",
    "outliers are observations that disagree by an abnormal amount with other measurements of the same quantity . despite every scientist knowing that the rate of outliers is always greater than naively expected , there is no widely accepted heuristic for estimating the size or shape of these long tails .",
    "these estimates are often assumed to be approximately normal ( gaussian ) , but it is easy to find examples where this is clearly untrue @xcite .    to examine the accuracy of reported uncertainties ,",
    "this paper reviews multiple published measurements of many different quantities , looking at the differences between measurements of each quantity normalized by their reported uncertainties .",
    "previous similar studies @xcite reported on only a few hundred to a few thousand measurements , mostly in subatomic physics .",
    "this study reports on how well multiple measurements of the same quantity agree , and hence what are reasonable expectations for the reproducibility of published scientific measurements .",
    "of particular interest is the frequency of large disagreements which usually reflect unexpected systematic effects .",
    "sources of uncertainty are often categorized as statistical or systematic , and their methods of evaluation classified as type a or b @xcite .",
    "type a evaluations are based on observed frequency distributions ; type b evaluations use other methods .",
    "statistical uncertainties are always evaluated from primary data using type a methods , and can in principle be made arbitrarily small by repeated measurement or large enough sample size .",
    "uncertainties due to systematic effects may be evaluated by either type a or b methods , and fall into several overlapping classes @xcite .",
    "class 1 systematics , which include many calibration and background uncertainties , are evaluated by type a methods using ancillary data .",
    "class 2 systematics are almost everything else that might bias a measurement , and are caused by a lack of knowledge or uncertainty in the measurement model , such as the reading error of an instrument or the uncertainties in monte carlo estimates of corrections to the measurement .",
    "class 3 systematics are theoretical uncertainties in the interpretation of a measurement . for example , determining the proton radius using the lamb shift of muonic hydrogen requires over 20 theoretical corrections @xcite that are potential sources of uncertainty in the proton radius , even if the actual measurement of the lamb shift is perfect .",
    "the uncertainties associated with class 2 and 3 systematic effects can not be made arbitrarily small by simply getting more data .    when considering the likelihood of extreme fluctuations in measurements , mistakes and `` unknown unknowns '' are particularly important , but they are usually assumed to be statistically intractable and are not often considered in traditional uncertainty analysis .",
    "mistakes are `` unknown knowns '' , i.e. something that is thought to be known but is not , and it is believed that good scientists should not make mistakes .",
    "`` unknown unknowns '' are factors that affect a measurement but are unknown and unanticipated based on past experience and knowledge @xcite . for example , during the first 5 years of operation of lep ( the large electron positron collider ) , the effect of local railway traffic on measurements of the @xmath2 boson mass was an `` unknown unknown '' that no - one thought about .",
    "then improved monitoring revealed unexpected variations in the accelerator magnetic field , and after much investigation these variations were found to be caused by electric rail line ground leakage currents flowing through the lep vacuum pipe @xcite .",
    "in general , systematic effects are challenging to , but can be partially constrained by researchers making multiple internal and external consistency checks : is the result compatible with previous data or theoretical expectations ?",
    "is the same result obtained for different times , places , assumptions , instruments , or subgroups ?",
    "as described by dorsey @xcite , scientists `` change every condition that seems by any chance likely to affect the result , and some that do not , in every case pushing the change well beyond any that seems at all likely '' .",
    "if an inconsistency is observed and its cause understood , the problem can often be fixed and new data taken , or the effect monitored and corrections made . if the cause can not be identified , however , then the observed dispersion of values must be included in the uncertainty .",
    "the existence of unknown systematic effects or mistakes may be revealed by consistency checks @xcite , but small unknown systematics and mistakes are unlikely to be noticed if they do not affect the measurement by more than the expected uncertainty .",
    "even large problems can be missed by chance ( see sec .  [",
    "ssec : modelling ] ) or if the conditions changed between consistency checks do not alter the size of the systematic effect .",
    "the power of consistency checks is limited by the impossibility of completely changing all apparatus , methods , theory , and researchers between measurements , so one can never be certain that all significant systematic effects have been identified .",
    "quantities were only included in this study if they are significant enough to have warranted at least five independent measurements with clearly stated uncertainties .",
    "medical and health research data were extracted from some of the many meta - analyses published by the cochrane collaboration @xcite ; a total of 5580 measurements of 310 quantities generating 99433 comparison pairs were included . particle physics data ( 8469 measurements , 864 quantities , 53988 pairs ) were retrieved from the review of particle physics  @xcite . nuclear physics data ( 12380 measurements , 1437 quantities , 66677 pairs )",
    "were obtained from the table of radionuclides @xcite .",
    "most nuclear and particle physics measurements have prior experimental or theoretical expectations which may influence results from nominally independent experiments @xcite , and medical research has similar biases @xcite , so this study also includes a large sample of interlaboratory studies that do not have precise prior expectations for their results . in these studies , multiple independent laboratories",
    "measure the same quantity and compare results .",
    "for example , the same mass standard might be measured by national laboratories in different countries , or an unknown archaeological sample might be divided and distributed to many labs , with each lab reporting back its carbon-14 measurement of the sample s age .",
    "none of the laboratories knows the expected value for the quantity nor the results from other labs , so there should be no expectation , selection , or publication biases .",
    "these interlab studies ( 14097 measurements , 617 quantities , 965416 pairs ) were selected from a wide range of sources in fields such as analytical chemistry , environmental sciences , metrology , and toxicology .",
    "the measurements ranged from genetic contamination of food to high precision comparison of fundamental physical standards , and were carried out by a mix of national , university , and commercial laboratories .    all quantities analysed are listed in the supplementary materials @xcite .",
    "data were entered using a variety of semi - automatic scripts , optical - character recognition , and manual methods .",
    "no attempt was made to recalculate past results based on current knowledge , or to remove results that were later retracted or amended , since the original paper was the best result at the time it was published .",
    "when the review of particle physics @xcite noted that earlier data had been dropped , the missing results were retrieved from previous editions  @xcite .    to ensure that measurements were as independent as possible , measurements were excluded if they were obviously not independent of other data already included . because relationships between measurements are often obscure , however , there undoubtedly remain many correlations between the published results used .",
    "medical and health data were selected from the 8105 reviews in the cochrane database @xcite as of 25 september 2013 .",
    "data were analysed from 221 intervention reviews whose abstract mentioned @xmath3 trials with @xmath4 total participants , and which reported at least one analysis with @xmath5 studies with @xmath6 total participants . the average heterogeneity inconsistency index ( @xmath7 ) @xcite is about 40% for the analyses reported here .",
    "because analyses within a review may be correlated , only a maximum of 3 analyses and 5 comparison groups were included from any one review .",
    "about 80% of the cochrane results are the ratio of intervention and control binomial probabilities , e.g. mortality rates for a drug and a placebo .",
    "such ratios are not normal  @xcite , so they were converted to differences that should be normal in the gaussian limit , i.e. when the group size @xmath8 and probability @xmath9 are such that @xmath8 , @xmath10 , and @xmath11 are all @xmath12 , so the binomial distribution converges towards a gaussian distribution .",
    "( the median observed values for these data were @xmath13 , @xmath14 . )",
    "the 68.3% binomial probability confidence interval was calculated for both the intervention and control groups to determine the uncertainties .",
    "measurements with uncertainties are typically reported as @xmath15 , which means that the interval @xmath16 to @xmath17 contains with some defined probability `` the values that could reasonably be attributed to the measurand '' @xcite .",
    "most frequently , uncertainty intervals are given as @xmath18 , where @xmath19 is the coverage factor and @xmath20 is the `` standard uncertainty '' , i.e. the uncertainty of a measurement expressed as the standard deviation of the expected dispersion of values .",
    "uncertainties in particle physics and medicine are often instead reported as the bounds of either 68.3% or 95% confidence intervals , which for a normal distribution are equivalent to the @xmath21 and @xmath22 standard uncertainty intervals .    for this study , all uncertainties were converted to nominal 68.3% confidence interval uncertainties .",
    "the vast majority of measurements reported simple single uncertainties , but if more than a single uncertainty was reported , e.g. `` statistical '' and `` systematic '' , they were added in quadrature .      all measurements , @xmath23 , of a given quantity were combined in all possible pairs and the difference between the two measurements of each pair calculated in units of their combined uncertainty @xmath24 : @xmath25 the dispersion of @xmath26 values can be used to judge whether independent measurements of a quantity are `` compatible '' @xcite .",
    "a feature of @xmath27 as a metric for measurement agreement is that it does not require a reference value for the quantity .",
    "( the challenges and effects of using reference values are discussed in section [ ssec : alternate ] . )    the uncertainties in equation  [ eq : zdefinition ] are combined in quadrature , as expected for standard uncertainties of independent measurements .",
    "( the effects of any lack of independence are discussed in section  [ ssec : uncertaintyschemes ] . )",
    "uncertainties based on confidence intervals may not be symmetric about the reported value , which is the case for about 13% of particle , 6% of medical , 0.3% of nuclear , and 0.06% of interlab measurements .",
    "following common ( albeit imperfect ) practice @xcite , if the reported plus and minus uncertainties were asymmetric , @xmath26 was calculated from eq .",
    "[ eq : zdefinition ] using the uncertainty for the side towards the other member of the comparison pair .",
    "for example , if @xmath28 , @xmath29 , and @xmath30 , then @xmath31 and @xmath32 .",
    "the distributions of the @xmath26 differences are histogrammed in fig .",
    "[ fig : differential ] , with each pair weighted such that the total weight for a quantity is the number of measurements of that quantity .",
    "for example , if a quantity has 10 measurements , there are 45 possible pairs , and each entry has a weight of 10/45 .",
    "( other weighting schemes are discussed in section [ ssec : alternate ] . )",
    "the final frequency distribution within each research area is then normalized so that its total observed probability adds up to 1 . if the measurement uncertainties are well evaluated and correspond to normally distributed probabilities for @xmath33 , then @xmath27 is expected to be normally distributed with a standard deviation @xmath34 .",
    "probability distribution uncertainties ( e.g. the vertical error bars in fig .  [",
    "fig : differential ] ) were evaluated using a bootstrap monte carlo method where quantities were drawn randomly with replacement from the actual data set until the number of monte carlo quantities equaled the actual number of quantities .",
    "the resulting artificial data set was histogrammed , the process repeated 1000 times , and the standard deviations of the monte carlo probabilities calculated for each @xmath27 bin .    random selection of measurements instead of quantities was not chosen for uncertainty evaluation because of the corrections then required to avoid bias and artifacts .",
    "for example , if measurements are randomly drawn , a quantity with only 5 measurements will often be missing from the artificial data set for having too few ( @xmath35 ) measurements drawn , or if it does have 5 measurements some of them will be duplicates generating unrealistic @xmath36 values , or if duplicates are excluded then they will always be the same 5 nonrandom measurements . without correcting for such effects , the resulting measurement monte carlo generated uncertainties are too small to be consistent with the observed bin - to - bin fluctuations in fig .  [",
    "fig : differential ] . correcting for such effects",
    "requires using characteristics of the actual quantities and would be effectively equivalent to using random quantities .",
    "attempts were made to fit the data to a wide variety of functions , but by far the best fits were to non - standardized student - t probability density distributions with @xmath37 degrees of freedom . @xmath38",
    "a student - t distribution is essentially a smoothly symmetric normalizable power - law , with @xmath39 for @xmath40 .",
    "the fitted parameter @xmath41 defines the core width and overall scale of the distribution and is equal to the standard deviation in the gaussian limit and to the half - width at half maximum in the cauchy ( also known as lorentzian or breit - wigner ) limit .",
    "the parameter @xmath37 determines the size of the tails , with small @xmath37 corresponding to large tails .",
    "the values and standard uncertainties in @xmath41 and @xmath37 were determined from a non - linear least squares fit to the data that minimizes the nominal @xmath42 @xcite : @xmath43 where @xmath44 , @xmath45 and @xmath46 are the bin @xmath27 , contents , and uncertainties of the observed @xmath27 distributions shown in fig .",
    "[ fig : differential ] .",
    "possible values of @xmath27 are sometimes limited by the allowed range of measurement values , which could suppress heavy tails .",
    "for example , many quantities are fractions that must lie between 0 and 1 , and there is less room for two measurements with 10% uncertainty to disagree by @xmath0 than for two 0.01% measurements .",
    "the size of this effect was estimated using monte carlo methods to generate simulated data based on the values and uncertainties of the actual data , constrained by any obvious bounds on their allowed values .",
    "the simulated data was then fit to see if applying the bounds changed the fitted values for @xmath41 and @xmath37 .",
    "the largest effect was for medical data where @xmath37 was reduced by about 0.1 when minimally restrictive bounds were assumed .",
    "stronger bounds might exist for some quantities , but determining them would require careful measurement - by - measurement assessment beyond the scope of this study .",
    "for example , each measurement of the long - term duration of the effect of a medical drug or treatment would have an upper bound set by the length of that study .",
    "since correcting for bounds can only make @xmath37 smaller ( corresponding to even heavier tails ) , and the observed effects were negligible , no corrections were applied to the values of @xmath37 reported here .",
    "histograms of the @xmath27 distributions for different data sets are shown in fig .  [",
    "fig : differential ] .",
    "the complementary cumulative distributions of the data are given in table  [ tab : cl ] and shown in fig .",
    "[ fig : cumulative ] .",
    "@llllll|rr  @xmath47 & 1 & 2 & 3 & 5 & 10 & @xmath48&@xmath49 +    ' '' ''    interlab & @xmath50 & @xmath51 & @xmath52 & @xmath53 & @xmath54 & @xmath55 & @xmath56 + ( key ) & @xmath57 & @xmath52 & @xmath58 & @xmath59 & @xmath60 & @xmath61 & @xmath62 + nuclear & @xmath63 & @xmath64 & @xmath65 & @xmath66 & @xmath67 & @xmath68 & @xmath69 + particle & @xmath70 & @xmath64 & @xmath71 & @xmath72 & @xmath73 & @xmath74 & @xmath75 + ( stable ) & @xmath76 & @xmath77 & @xmath66 & @xmath78 & @xmath79 & @xmath80 & @xmath81 + medical & @xmath82 & @xmath83 & @xmath84 & @xmath85 & @xmath86 & @xmath87 & @xmath88 + constants & @xmath89 & @xmath90 & @xmath91 & @xmath92 & @xmath93 & @xmath94 & @xmath95 +    ' '' ''    normal ( gaussian ) & @xmath96 & @xmath97 & @xmath98 & @xmath99 & @xmath100 & @xmath101 & @xmath102 + student - t ( @xmath103 ) & @xmath104 & @xmath105 & @xmath106 & @xmath107 & @xmath108 & @xmath109 & @xmath110 + exponential & @xmath111 & @xmath91 & @xmath112 & @xmath78 & @xmath113 & @xmath114 & @xmath115 + student - t ( @xmath116 ) & @xmath89 & @xmath83 & @xmath117 & @xmath118 & @xmath119 & @xmath120 & @xmath121 + cauchy & @xmath122 & @xmath123 & @xmath124 & @xmath58 & @xmath125 & @xmath126 & @xmath127 +    the observed probability of two measurements disagreeing by more than @xmath27 standard uncertainties for different data sets : @xmath128 .",
    "( see also table  [ tab : cl ] ) ]    none of the data are close to gaussian , but all can reasonably be described by almost - cauchy student - t distributions with @xmath129 . for comparison ,",
    "fits to these data with lvy stable distributions have nominal @xmath42 4 to 30 times worse than the fits to student - t distributions .",
    "the number of `` @xmath0 '' ( i.e. @xmath130 ) disagreements observed is as high as @xmath53 , compared to the @xmath131 expected for a normal distribution .",
    "the fitted values for @xmath37 and @xmath41 are shown in table  [ tab : fits ] .",
    "also shown in table  [ tab : fits ] are two data subsets expected to be of higher quality , bipm interlaboratory key comparisons ( 372 quantities , 3712 measurements , 20245 pairs ) and stable particle properties ( 335 quantities , 3041 measurements , 16649 pairs ) . the key comparisons @xcite should define state - of - the - art accuracy , since they are measurements of important metrological standards carried out by national laboratories .",
    "stable particles are often easier to study than other particles , so their properties are expected to be better determined .",
    "both `` better '' data subsets do have narrower distributions consistent with higher quality , but they still have heavy tails .",
    "more selected data subsets are discussed in section [ ssec : selected subsets ] .    [ cols=\"<,^,^,^,^,^,^,^,^,^ \" , ]     the key metrology data subset is for electrical , radioactivity , length , mass , and other similar physical metrology standards . to see",
    "if the most experienced national laboratories were more consistent , table  [ tab : special ] also lists selected metrology data from only the six national labs that reported the most key metrology measurements . these laboratories were ptb ( physikalisch - technische bundesanstalt , germany ) , nmij ( national metrology institute of japan ) , nist ( national institutes of standards and technology , usa ) , npl ( national physical laboratory , uk ) , nrc ( national research council , canada ) , and lne ( laboratoire national de mtrologie et dessais , france ) .",
    "similarly , key analytical chemistry data selected from the same national labs are also shown .",
    "these are for measurements such as the amount of mercury in salmon , pcbs in sediment , or chromium in steel .",
    "the metrology measurements by the selected national laboratories do have much lighter tails with @xmath132 , but this is not the case for their analytical measurements where @xmath133 .",
    "new stable particle data have the lightest tail in table  [ tab : fits ] , but it is not clear if this is because the newer results have better determined uncertainties or are just more correlated . the trend in particle physics is for fewer but larger experiments , and more than a third of the newer stable measurements were made by just two very similar experiments ( belle and babar ) , so the new stable data is split into two groups in table  [ tab : special ] .",
    "there is no significant difference between the belle / babar and other experiments data .",
    "nuclear lifetimes with small and large relative uncertainties were compared .",
    "they have similar tails , but the smaller uncertainty measurements appear to underestimate their uncertainty scales .    measurements of newton s gravitation constant are notoriously variable @xcite , so a data - set without @xmath134 results was examined .",
    "the heavy tail is reduced , albeit with large uncertainty .",
    "the accuracy of uncertainty evaluations appears to be similar in all fields , but unsurprisingly there are noticeable differences in the relative sizes of the uncertainties . in particular , although individual physics measurements are not typically more reproducible than in medicine , they often have smaller relative uncertainty ( i.e. uncertainty / value ) as shown in fig .",
    "[ fig : precision ] .",
    "distribution of the relative uncertainty for data from fig .",
    "[ fig : differential ] . ]",
    "median ratio of the relative uncertainties ( newer / older ) for measurements in each @xmath27 pair as a function of the years between the two measurements : medical ( brown circles ) , particle ( green triangles ) , nuclear ( red squares ) , stable ( green dashed point - down triangles ) , constants ( orange diamonds ) . ]",
    "perhaps more importantly for discovery reproducibility , uncertainty improves more rapidly in physics than in medicine , as is shown in fig .",
    "[ fig : precisionimprovement ] .",
    "this difference in rates of improvement reflects the difference between measurements that depend on steadily evolving technology versus those using stable methods that are limited by sample sizes and heterogeneity @xcite .",
    "the expectation of reduced uncertainty in physics means that it is feasible to take a wait - and - see attitude towards new discoveries , since better measurements will quickly confirm or refute the new result .",
    "measurement uncertainty in nuclear and particle physics typically improves by about a factor of 2 every 15 years .",
    "constants data improve twice as fast , which is unsurprising since more effort is expected for more important quantities .",
    "physicists also tend not to make new measurements unless they are expected to be more accurate than previous measurements . in the data sets reported here , the median improvement in uncertainty of nuclear measurements compared to the best previous measurement of the same quantity is @xmath135 , and the improvement factors for constants , particle , and stable measurements are @xmath136 , @xmath137 , and @xmath138 .",
    "in contrast , medical measurements typically have greater uncertainties than the best previous measurements , with median @xmath139 .",
    "this is an understandable consequence of different uncertainty to cost relationships in physics and medicine .",
    "study population size is a major cost driver in medical research , so reducing the uncertainty by a factor of two can cost almost four times as much , which is rarely the case in physics .",
    "prior expectations exist for most measurements reported here except for the interlab data .",
    "such expectations may suppress heavy tails by discouraging publication of the anomalous results that populate the tails , since before publishing a result dramatically different from prior results or theoretical expectations , researchers are likely to make great efforts to ensure that they have not made a mistake .",
    "journal editors , referees and other readers also ask tough questions of such results , either preventing publication or inducing further investigation . for example , initial claims @xcite of @xmath140 evidence for faster - than - light neutrinos and cosmic inflation did not survive to actual publication @xcite .",
    "median @xmath27 value as a function of time difference between the two measurements in each @xmath27 pair : medical ( brown circles ) , particle ( green point - up triangles ) , nuclear ( red squares ) , constants ( orange diamonds ) , and stable ( green dashed point - down triangles ) . ]    fig .",
    "[ fig : correlation ] shows that physics ( particle , nuclear , constants ) measurements are more likely to agree if the difference in their publication dates is small .",
    "such `` bandwagon effects '' @xcite are not observed in the medical data , and they are irrelevant for interlab quantities which are usually measured almost simultaneously .",
    "these correlations imply that measurements are biased either by expectations or common methodologies .",
    "such correlations might explain the small ( @xmath141 ) values of @xmath142 for nuclear , particle , and constants data , or it could be that researchers in these fields simply tend to overestimate the scale of their uncertainties @xcite .",
    "removing expectation biases from the physics data would likely make their tails heavier .    although interlab data are not supposed to have any expectation biases , they are subject to methodological correlations due to common measurement models , procedures , and types of instrumentation , so even their tails would likely increase if all measurements could be made truly independent .",
    "in a famous dispute with cauchy in 1853 , eminent statistician irne - jules bienaym ridiculed the idea that any sensible instrument had cauchy uncertainties @xcite .",
    "a century later , however , harold jeffreys noted that systematic errors may have a significant cauchy component , and that the scale of the uncertainty contributed by systematic effects depends on the size of the random errors @xcite .",
    "the results of this study agree with earlier research that also observed student - t tails , but only looked at a handful of subatomic or astrophysics quantities up to @xmath143  @xcite .",
    "unsurprisingly , the tails reported here are mostly heavier than those reported for repeated measurements made with the same instrument ( @xmath144 ) @xcite , which should be closer to normal since they are not independent and share most systematic effects .    instead of student - t tails , exponential tails have been reported for several nuclear and particle physics data sets @xcite , but in all cases some measurements were excluded . for example , the largest of these studies @xcite looked at particle data ( 315 quantities , 53322 pairs ) using essentially the same method as this paper , but rejected the 20% of the data that gave the largest contributions to the @xmath42 for each quantity , suppressing the heaviest tails . despite this data selection , all these studies have supra - exponential heavy tails for @xmath145 , and so are qualitatively consistent with the results of this paper .",
    "it is possible that averaging different quantities with exponential tails might produce apparent power - laws @xcite , but this would require wild variations in the accuracy of the uncertainty estimates .    instead of looking directly at the shapes of the measurement consistency distributions , hedges @xcite compared particle physics and psychology results and found them to have similar compatibility , with typically almost half of the quantities in both fields having statistically significant disagreements .",
    "thompson and ellison reported substantial amounts of `` dark uncertainty '' in chemical analysis interlaboratory comparisons @xcite .",
    "uncertainty is `` dark '' if it does not appear as part of the known contributions to the uncertainty of individual measurements , but is inferred to exist because the dispersion of measured values is greater than expected based on the reported uncertainties .",
    "for example , six ( 21% ) of 28 bipm key comparisons studied had ratios ( @xmath146 ) of expected to observed standard deviations less than 0.2 .",
    "this agrees with the key analytical results in table  [ tab : special ] ( which include some of the same key comparisons ) . for sample sizes matching the 28 comparisons , 20% of samples drawn from a @xmath147 student - t distribution",
    "would be expected to have @xmath148 .",
    "the open science collaboration ( osc ) recently replicated 100 studies in psychology @xcite , providing some of the most direct evidence yet for poor scientific reproducibility . using the osc study s supplementary information",
    ", @xmath27 can be calculated for 87 of the reported original / replication measurement pairs , and 27 ( 31% ) disagree by more than @xmath149 , and 2 ( 2.3% ) by more than @xmath1 .",
    "this rate of disagreements is inconsistent with selection bias acting on a normal distribution unless the @xmath150 data are excluded , but can be explained by selection biased student - t data with @xmath151 , consistent with the medical data reported in table  [ tab : fits ] .      when a measurement turns out to be wrong , the reasons for this failure are often unknown , or at least unpublished , so it is interesting to look at examples where the causes were later understood or can be inferred",
    ".    for medical research , heterogeneity in methods or populations is a major source of variance .",
    "the largest inconsistency in the medical dataset is in a comparison of fever rates after acellular versus whole - cell pertussis vaccines @xcite .",
    "the large variance can likely be explained by significant differences among the study populations and especially in how minor adverse events were defined and reported .",
    "the biggest @xmath27 values in the particle data come from complicated multi - channel partial wave analyses of strong scattering processes , where many dozens of quantities ( particle masses , widths , helicities ,  ) are simultaneously determined .",
    "significant correlations often exist between the fitted values of the parameters but are not always clearly reported , and evaluations may not always include the often large uncertainties from choices in data and parameterization .",
    "the largest disagreement in the interlab data appears to be an obvious mistake . in a comparison of radioactivity in water @xcite ,",
    "one lab reported an activity of @xmath152 bq / kg when the true value was about 31 . even without knowing the expected activity , the unreasonably small fractional uncertainty should probably have flagged this result .",
    "such gross errors can produce almost - cauchy deviations .",
    "for example , if the numerical result of a measurement is simply considered as an infinite bit string , then any `` typographical '' glitch that randomly flips any bit with equal probability will produce deviations with a @xmath153 distribution .",
    "one can hope that the best research will not be sloppy , but not even the most careful scientists can avoid all unpleasant surprises . in 1996 a team from ptb ( the national metrological institute of germany ) reported a measurement of @xmath134 that differed by @xmath154 from the accepted value ; it took 8 years to track down the cause  a plausible but erroneous assumption about their electrostatic torque transmitter unit @xcite .",
    "a @xmath155 difference between the codata2006 and codata2010 fine structure constant values was due to a mistake in the calculation of some eighth - order terms in the theoretical value of the electron anomalous magnetic moment @xcite . a 1999 determination @xcite of avogadro s number by a team from japan s national research laboratory of metrology using the newer x - ray crystal density method was off by @xmath156 due to subtle silicon inhomogeneities @xcite . in an interlaboratory comparison measuring pcb contamination in sediments , the initial measurement by bam ( the german federal institute for materials research and testing ) disagreed by many standard uncertainties , but",
    "this was later traced to cross - contamination in sample preparation @xcite .",
    "several nuclear half - lives measured by the us national institute for standards and technology were known for some years to be inconsistent with other measurements ; it was finally discovered that a nist sample positioning ring had been slowly slipping over 35 years of use @xcite .",
    "often discrepancies are never understood and are simply replaced by newer results .",
    "for example , despite bringing in a whole new research team to go over every component and system , the reason for a discordant nist measurement of planck s constant was never found , but newer measurements by the same group were not anomalous @xcite .",
    "heavy tails have many potential causes , including bias @xcite , overconfident uncertainty underestimates @xcite , and uncertainty in the uncertainties @xcite , but it is not immediately obvious how these would produce the observed t distributions with so few degrees of freedom .    even when the uncertainty @xmath157 is evaluated from the standard deviation of multiple measurements from a normal distribution so that a student - t distribution would be expected , there are typically so many measurements that @xmath37 should be much larger than what is observed . exceptions to this are when calibration uncertainties dominate , since often only a few independent calibration points are available , or when uncertainties from systematic effects are evaluated by making a few variations to the measurements , but these can not explain most of the data .",
    "any reasonable publication bias applied to measurements with gaussian uncertainties can not create very heavy tails , just a distorted distribution with gaussian tails  to produce one false published @xmath158 result would require bias strong enough to reject millions of studies . underestimating @xmath41 does not produce a heavy tail , only a broader normal @xmath27 distribution . mixing multiple normal distributions does not naturally produce almost - cauchy distributions , except in special cases such as the ratio of two zero - mean gaussians .",
    "the heavy tails are not caused by poor older results .",
    "the heaviest - tailed data in fig .",
    "[ fig : differential ] are actually the newest ",
    "93% of the interlaboratory data are less than 16 years old  and eliminating older results taken prior to the year 2000 does not reduce the tails for most data as shown in table  [ tab : fits ] .",
    "intentionally making up results , i.e. fraud , could certainly produce outliers , but this is unlikely to be a significant problem here .",
    "since most of the data were extracted from secondary meta - analyses ( e.g. review of particle properties , table of radionuclides , and cochrane systematic reviews ) , results withdrawn for misconduct prior to the time of the review would likely be excluded .",
    "one meta - analysis in the medical dataset does include studies that were later shown to be fraudulent @xcite , but the fraudulent results actually contribute slightly less than average to the overall variance among the results for that meta - analysis .",
    "modelling the heavy tails may help us understand the observed distributions .",
    "one way is to assume that the measurement values are normally distributed with standard deviation @xmath159 that is unknown but which has a probability distribution @xmath160 @xcite .",
    "the measured value @xmath33 is then expected to have a probability distribution @xmath161 this is essentially a bayesian estimate with prior @xmath162 and a normal likelihood with unknown variance .",
    "if the uncertainties are accurately evaluated and normal with variance @xmath163 , @xmath162 will be a narrow peak at @xmath164 . assuming that @xmath162 is a broad normal distribution leads to exponential tails  @xcite for large @xmath27 .",
    "in order to generate student - t distributions , @xmath162 must be a scaled inverse chi - squared ( or gamma ) distribution in @xmath165 @xcite .",
    "this works mathematically , but why would variations in @xmath41 for independent measurements have such a distribution ?",
    "heavy tails can only be generated by effects that can produce a wide range of variance , so we must model how consistency testing is used by researchers to constrain such effects .",
    "consistency is typically tested using a metric such as the calculated chi - squared statistic for the agreement of @xmath166 measurements @xmath167 @xcite @xmath168 where @xmath169 is the @xmath167 weighted mean and @xmath170 are the standard uncertainties reported by the researchers . for accurate standard uncertainties",
    ", @xmath171 will have a chi - squared probability distribution with .",
    "if , however , the reported uncertainties are incorrect and the true standard uncertainties are @xmath172 , then it will be @xmath173 that is chi - squared distributed .",
    "researchers will likely search for problems if different consistency measurements have a poor @xmath174 , which typically means @xmath175 .",
    "the larger an unknown systematic error is , the more likely it is to be detected and either corrected or included in the reported uncertainty , so published results typically have @xmath176 .",
    "since @xmath177 is expected to have a chi - squared distribution , a natural prior for @xmath165 is indeed the scaled inverse chi - squared distribution needed to generate student - t distributions from equation  [ eq : shlyakhter ] .",
    "more mechanistically , it could be assumed that a normally distributed systematic error will be missed by @xmath178 independent measurements if their @xmath179 is less than some threshold @xmath180 .",
    "if the distribution of all possible systematic effects is @xmath181 , then the probability distribution for the unfound errors will be @xmath182 where @xmath183 is the cumulative @xmath42 distribution .",
    "@xmath181 is unknown , but a common bayesian scale - invariant choice is @xmath184 , with @xmath185 .    using this model with the reported uncertainty @xmath41 as the lower integration bound , the curve generated from equations  [ eq : shlyakhter ] and [ eq : model ] is very close to a @xmath186 student - t distribution .",
    "the observed small values for @xmath37 mean that both @xmath178 and @xmath187 must be small .",
    "making truly independent consistency tests is difficult , so it is not surprising that the effective number of checks ( @xmath178 ) is usually small .",
    "this model is plausible , but why are systematic effects consistent with a @xmath184 power - law size distribution ?",
    "scientific measurements are made by complex systems of people and procedures , hardware and software , so one would expect the distribution of scientific errors to be similar to those produced by other comparable systems .",
    "power - law behaviour is ubiquitous in complex systems  @xcite , with the cumulative distributions of observed sizes ( @xmath188 ) for many effects falling as @xmath189 , and these heavy tails exist even when the system has been designed and refined for optimal results .",
    "a student - t distribution has cumulative tail exponent @xmath190 , and the values for @xmath37 reported here are consistent with power - law tails observed in other designed complex systems .",
    "the frequency of software errors typically has a cumulative power - law tail corresponding to small @xmath191 @xcite , and in scientific computing these errors can lead to quantitative discrepancies orders of magnitude greater than expected  @xcite .",
    "the size distribution of electrical power grid failures has @xmath192 @xcite , and the frequency of spacecraft failures has @xmath193 @xcite .",
    "even when designers and operators really , really want to avoid mistakes , they still occur : the severity of nuclear accidents falls off only as @xmath194  @xcite , similar to the power - laws observed for the sizes of industrial accidents @xcite and oil spills  @xcite .",
    "some complex medical interventions have power - law distributed outcomes with @xmath195 @xcite .    combining the observed power - law responses of complex systems with the power - law constraints of consistency checking for systematic effects discussed in section [ ssec : modelling ]",
    ", leads naturally to the observed consistency distributions with heavy power - law tails .",
    "there are also several theoretical arguments that such distributions should be expected .",
    "a systematic error or mistake is an example of a risk analysis incident , and power - law distributions are the maximal entropy solutions for such incidents when there are multiple nonlinear interdependent causes  @xcite , which is often the case when things go wrong in research .",
    "scientists want to make the best measurements possible with the limited resources they have available , so scientific research endeavours are good examples of highly structured complex systems designed to optimize outcomes in the presence of constraints .",
    "such systems are expected to exhibit `` highly optimized tolerance '' @xcite , being very robust against designed - for uncertainties , but also hypersensitive to unanticipated effects , resulting in power - law distributed responses .",
    "simple continuous models for highly optimized tolerant systems are consistent with the heavy tails observed in this study .",
    "these models predict that @xmath196 @xcite , where @xmath197 is the effective dimensionality of the system , but larger values of @xmath187 arise when some of the resources are used to avoid large deviations @xcite , e.g. spending time doing consistency checks .",
    "if one believes that mistakes can be eliminated and all systematic errors found if we just work hard enough and apply the most rigorous methodological and statistical techniques , then results from the best scientists should not have heavy tails .",
    "such a belief , however , is not consistent with the experienced challenges of experimental science , which are usually hidden in most papers reporting scientific measurements @xcite .",
    "as beveridge famously noted @xcite , often everyone else believes an experiment more than the experimenters themselves .",
    "researchers always fear that there are unknown problems with their work , and traditional error analysis can not `` include what was not thought of '' @xcite .",
    "it is not easy to make accurate _ a priori _ identifications of those measurements that are so well done that they avoid having almost - cauchy tails .",
    "expert judgement is subject to well - known biases @xcite , and obvious criteria to identify better measurements may not work .",
    "for example , the open science collaboration found that researchers experience or expertise did not significantly correlate with the reproducibility of their results @xcite  the best predictive factor was simply the statistical significance of the original result .",
    "the best researchers may be better at identifying problems and not making mistakes , but they also tend to choose the most difficult challenges that provide the most opportunities to go wrong .    reducing heavy tails",
    "is challenging because complex systems exhibit scale invariant behaviour such that reducing the size of failures does not significantly change the shape of their distribution . improving sensitivity makes previously unknown small systematic issues visible so they can be corrected or included in the total uncertainty .",
    "this improvement reduces @xmath41 , but even smaller systematic effects now become significant and tails may even become heavier and @xmath37 smaller . comparing figures  [ fig : differential ] and [ fig : precision ]",
    ", it appears that data with higher average relative uncertainty tend to have heavier tails .",
    "this relationship between relative uncertainty and measurement dispersion is reminiscent of the empirical horwitz power - law in analytical chemistry @xcite , where the relative spread of interlaboratory measurements increases as the required sensitivity gets smaller , and of taylor s law in ecology where the variance grows with sample size so that the uncertainty on the mean does not shrink as @xmath198 @xcite .    in principle",
    ", statistical errors can be made arbitrarily small by taking enough data , and @xmath37 can be made arbitrarily large by making enough independent consistency checks , but researchers have only finite time and resources so choices must be made .",
    "taking more consistency check data limits the statistical uncertainty , since it is risky to treat data taken under different conditions as a single data set .",
    "consistency checks are never completely independent since it is impossible for different measurements of the same quantity not to share any people , methods , apparatus , theory or biases , so researchers must decide what tests are reasonable .",
    "the observed similar small values for @xmath37 may reflect similar spontaneous and often unconscious cost - benefit analyses made by researchers .    the data showing the lightest tail reported here ( in table  [ tab : special ] )",
    "may provide some guidance and caution .",
    "the high quality of the selected metrology standards measurements by leading national laboratories shows that heavy tails can be reduced by collaboratively taking great care to ensure consistency by sharing methodology and making regular comparisons .",
    "there are , however , limits to what can be achieved , as illustrated by the much heavier tail of the analytical standards measured by the same leading labs .",
    "second , consistency is easier than accuracy .",
    "interlaboratory comparisons typically take place over relatively short periods of time , with participating institutions using the best standard methods available at that time .",
    "biases in the standard methods may only be later discovered when new methods are introduced .",
    "for example , work towards a redefinition of the kilogram and the associated development of new silicon atom counting technology revealed inconsistencies with earlier watt - balance measurements , and this has driven improvements in both methods @xcite . finally , selection bias that hides anomalous results is hard to eliminate . for one metrology key comparison ,",
    "results from one quantity were not published because some laboratories reported `` incorrect results '' @xcite .    reducing tails is particularly challenging for measurements where the primary goal is improved sensitivity that may lead to new scientific understanding . by definition ,",
    "a better measurement is not an identical measurement , and every difference provides room for new systematic errors , and every improvement that reduces the uncertainty makes smaller systematic effects more significant .",
    "frontier measurements are always likely to have heavier tails .",
    "published scientific measurements typically have non - gaussian almost - cauchy @xmath199 error distributions , with up to @xmath200 of results in disagreement by @xmath150 .",
    "these heavy tails occur in even the most careful modern research , and do not appear to be caused by selection bias , old inaccurate data , or sloppy measurements of uninteresting quantities . for even the best scientists working on well understood measurements using similar methodology , it appears difficult to achieve consistency better than @xmath201 , with about @xmath202 of results expected to be @xmath150 outliers , a rate a thousand times higher than for a normal distribution . these may , however , be underestimates . because of selection / confirmation biases and methodological correlations , historical consistency can only set lower bounds on heavy tails ",
    "multiple measurements may all agree but all be ( somewhat ) wrong .",
    "the effects of unknown systematic problems are not completely unpredictable .",
    "scientific measurement is a complex process and the observed distributions are consistent with unknown systematics following the low - exponent power - laws that are theoretically expected and experimentally observed for fluctuations and failures in almost all complex systems .",
    "researchers do determine the scale of their uncertainties with fair accuracy , with the scale of medical uncertainties ( @xmath203 ) slightly more consistent with the expected value ( @xmath204 ) than in physics ( @xmath205 ) .",
    "medical and physics research have comparable reproducibility in terms of how well different studies agree within their uncertainties , consistent with a previous comparison of particle physics with social sciences @xcite .",
    "medical research may have slightly lighter tails , while physics results typically have better relative uncertainty and greater statistical significance .",
    "understanding that error distributions are often almost - cauchy should encourage use of t - based @xcite , median @xcite , and other robust statistical methods @xcite , and supports choosing student - t @xcite or cauchy @xcite priors in bayesian analysis .",
    "outlier - tolerant methods are already common in modern meta - analysis , so there should be little effect on accepted values of quantities with multiple published measurements , but this better understanding of the uncertainty may help improve methods and encourage consistency .",
    "false discoveries are more likely if researchers apply normal conventions to almost - cauchy data . although much abused , the historically common use of @xmath206 as a discovery criterion suggests that many scientists would like to be wrong less than 5% of the time . if so , the results reported here support the nominal 5-sigma discovery rule in particle physics , and may help discussion of more rigorous significance criteria in other fields @xcite .    this study should help researchers better understand the uncertainties in their measurements , and may help decision makers and the public better interpret the implications of scientific research @xcite . if nothing else , it should also remind everyone to never use normal / gaussian statistics when discussing the likelihood of extreme results .",
    "i thank the students of the university of toronto advanced undergraduate physics lab for inspiring consideration of realistic experimental expectations , and the university of auckland physics department for their hospitality during very early stages of this work .",
    "i am grateful to d. pitman for patient and extensive feedback , to r. bailey for his constructive criticism , to r. cousins , d. harrison , j. rosenthal , and p. sinervo for useful suggestions and discussion , and to m. cox for many helpful comments on the manuscript .",
    "the sources for all data analysed are listed in the associated ancillary file : uncertaintydatadescription.xls .",
    "rosenfeld ah .",
    "1968 are there any far - out mesons or baryons ? in _",
    "meson spectroscopy _ ( eds baltay c , rosenfeld ah ) .",
    "new york , usa : w. a. benjamin .",
    ".  455483 .",
    "https://archive.org/details/mesonspectroscopy [ ]            nakagawa s , cuthill ic .",
    "2007 effect size , confidence interval and statistical significance : a practical guide for biologists .",
    "rev . _ * 82 * , 591605 . http://dx.doi.org/10.1111/j.1469-185x.2007.00027.x [ ]                              sinervo pk .",
    "2003 definition and treatment of systematic uncertainties in high energy physics and astrophysics . in _",
    "phystat 2003 , stanford , usa _",
    "( eds lyons l , mount rp , reitmeyer r ) .",
    "http://stanford.io/2fdpkta [ ]        bravin e , brun g , dehning b , drees a , galbraith p , geitz m , henrichsen k , koratzinos m , mugnai g , tonutti m. 1998 the influence of train leakage currents on the lep dipole field . _ nucl .",
    "instrum . meth . a _ * 417 * , 915 .",
    "http://dx.doi.org/10.1016/s0168-9002(98)00020-5 [ ]          attivissimo f , cataldo a , fabbiano l , giaquinto n. 2011 systematic errors and measurement uncertainty : an experimental approach .",
    "_ measurement _ * 44 * , 17811789 .",
    "http://dx.doi.org/10.1016/j.measurement.2011.07.011 [ ]",
    "willink r. 2004 approximating the difference of two t - variables for all degrees of freedom using truncated variables .",
    "n. z. j. stat . _",
    "* 46 * , 495504 .",
    "[ ]      faller je .",
    "2014 precision measurement , scientific personalities and error budgets : the sine quibus non for big g determinations .",
    "r. soc . a _ * 372 * , 20140023 .",
    "http://dx.doi.org/10.1098/rsta.2014.0023 [ ]",
    "bienaym m. 1853 considrations a lappui de la dcourverte de laplace sur la loi de probabilit dans la mthode des moindres carrs . _ c. r. acad .",
    "sci . _ * xxxvii * , 309324 .",
    "https://books.google.com/books?id=qhjfaaaacaaj&pg=pa322 [ ]",
    "zhang l , prietsch so , axelsson i , halperin sa .",
    "2012 acellular vaccines for preventing whooping cough in children . _",
    "cochrane database of systematic reviews _",
    "http://dx.doi.org/10.1002/14651858.cd001478.pub5 [ ]    .",
    "2010 almera proficiency test determination of naturally occurring radionuclides in phosphogypsum and water ( iaea - cu-2008 - 04 ) .",
    "austria : international atomic energy agency iaea / aq/15 . http://www-pub.iaea.org/mtcd/publications/pdf/iaea-aq-15_web.pdf [ ]        fujii k , tanaka m , nezu y , nakayama k , fujimoto h , de  bievre p , valkiers s. 1999 determination of the avogadro constant by accurate measurement of the molar volume of a silicon crystal .",
    "_ metrologia _ * 36 * , 455464 . http://dx.doi.org/10.1088/0026-1394/36/5/7 [ ]              carlisle j , pace n",
    ", cracknell j , mller a , pedersen t , zacharias m. 2013 ( 5 ) what should the cochrane collaboration do about research that is , or might be , fraudulent ? _ cochrane database of systematic reviews_. http://dx.doi.org/10.1002/14651858.ed000060 [ ]    dose v , von der  linden w. 1999 outlier tolerant parameter estimation . in _",
    "maximum entropy and bayesian methods : garching , germany 1998 _ vol .",
    "105 of _ fundamental theories of physics_. netherlands : springer .",
    ".  4756 .",
    "http://dx.doi.org/10.1007/978-94-011-4710-1_4 [ ]",
    "dobson i , carreras ba , lynch ve , newman de .",
    "2007 complex systems analysis of series of blackouts : cascading failure , critical points , and self - organization .",
    "_ chaos _ * 17 * , 026103 .",
    "http://dx.doi.org/10.1063/1.2737822 [ ]    karimova lm , kruglun oa , makarenko ng , romanova nv .",
    "2011 power law distribution in statistics of failures in operation of spacecraft onboard equipment .",
    "res . _ * 49 * , 458463 .",
    "http://dx.doi.org/10.1134/s0010952511040058 [ ]    sornette d , maillart t , kroeger w. 2013 exploring the limits of safety analysis in complex technological systems .",
    ". j. disaster risk reduct . _ * 6 * , 5966 ."
  ],
  "abstract_text": [
    "<S> judging the significance and reproducibility of quantitative research requires a good understanding of relevant uncertainties , but it is often unclear how well these have been evaluated and what they imply . </S>",
    "<S> reported scientific uncertainties were studied by analysing 41000 measurements of 3200 quantities from medicine , nuclear and particle physics , and interlaboratory comparisons ranging from chemistry to toxicology . </S>",
    "<S> outliers are common , with @xmath0 disagreements up to five orders of magnitude more frequent than naively expected </S>",
    "<S> . uncertainty - normalized differences between multiple measurements of the same quantity are consistent with heavy - tailed distributions that are often almost cauchy , far from a gaussian normal bell curve . </S>",
    "<S> medical research uncertainties are generally as well evaluated as those in physics , but physics uncertainty improves more rapidly , making feasible simple significance criteria such as the @xmath0 discovery convention in particle physics . </S>",
    "<S> contributions to measurement uncertainty from mistakes and unknown problems are not completely unpredictable . </S>",
    "<S> such errors appear to have power - law distributions consistent with how designed complex systems fail , and how unknown systematic errors are constrained by researchers . </S>",
    "<S> this better understanding may help improve analysis and meta - analysis of data , and help scientists and the public have more realistic expectations of what scientific results imply . </S>"
  ]
}