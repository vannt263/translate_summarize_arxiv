{
  "article_text": [
    "many components to build a high quality natural language processing system rely on the synonym extraction .",
    "examples include query expansion , text summarization  @xcite , question answering  @xcite , and paraphrase detection . although the value of synonym extraction is undisputed , manual construction of such resources is always expensive , leading to a low knowledgebase ( kb ) coverage  @xcite .    in the medical domain ,",
    "this kb coverage issue is more serious , since the language use variability is exceptionally high  @xcite .",
    "in addition , the natural language content in the medical domain is also growing at an extremely high speed , making people hard to understand it , and update it in the knowledgebase in a timely manner .    to construct a large scale medical synonym extraction system ,",
    "the main challenge to address is how to build a system that can automatically combine the existing manually extracted medical knowledge with the huge amount of the knowledge buried in the unstructured text . in this paper , we construct a medical corpus containing 130 m sentences ( 20 gigabytes pure text ) .",
    "we also construct a semi - supervised framework to generate a vector representation for each medical term in this corpus .",
    "our framework extends the word2vec model  @xcite by integrating the existing medical knowledge in the model training process .    to model the concept of synonym ,",
    "we build a `` * * concept space * * '' that contains both the semi - supervised term embedding features and the expanded features that capture the similarity of two terms on both the word embedding space and the surface form .",
    "we then apply a linear classifier directly to this space for synonym extraction .",
    "since both the manually extracted medical knowledge and the knowledge buried under the unstructured text have been encoded in the concept space , a cheap classifier can produce satisfying extraction results , making it possible to efficiently process a huge amount of the term pairs .",
    "our system is designed in such a way that both the existing medical knowledge and the context in the unstructured text are used in the training process .",
    "the system can be directly applied to the input term pairs without considering the context .",
    "the overall contributions of this paper on medical synonym extraction are two - fold :    * from the perspective of applications , we identify a number of unified medical language system ( umls )  @xcite relations that can be mapped to the synonym relation ( table [ tbl : synonymrelations ] ) , and present an automatic approach to collect a large amount of the training and test data for this application .",
    "we also apply our model to a set of 11b medical term pairs , resulting in a new medical synonym knowledgebase with more than 3 m synonym candidates unseen in the previous medical resources . * from the perspective of methodologies , we present a semi - supervised term embedding approach that can train the vector space model using both the existing medical domain knowledge and the text data in a large corpus .",
    "we also expand the term embedding features to form a concept space , and use it to facilitate synonym extraction .",
    "the experimental results show that our synonym extraction models are fast and outperform the state - of - the - art approaches on medical synonym extraction by a large margin .",
    "the resulting synonym kb can also be used as a complement to the existing knowledgebases in information extraction tasks .",
    "a wide range of techniques has been applied to synonym detection , including the use of lexicosyntactic patterns  @xcite , clustering  @xcite , graph - based models  @xcite@xcite@xcite@xcite and distributional semantics  @xcite@xcite@xcite@xcite@xcite .",
    "there are also efforts to improve the detection performance using multiple sources or ensemble methods  @xcite@xcite@xcite .",
    "the vector space models are directly related to synonym extraction .",
    "some approaches use the low rank approximation idea to decompose large matrices that capture the statistical information of the corpus .",
    "the most representative method under this category is latent semantic analysis ( lsa )  @xcite .",
    "some new models also follow this approach like hellinger pca  @xcite and glove  @xcite .",
    "neural network based representation learning has attracted a lot of attentions recently .",
    "one of the earliest work was done in @xcite .",
    "this idea was then applied to language modeling  @xcite , which motivated a number of research projects in machine learning to construct the vector representations for natural language processing tasks   @xcite@xcite@xcite@xcite@xcite@xcite .    following the same neural network language modeling idea ,",
    "word2vec  @xcite significantly simplifies the previous models , and becomes one of the most efficient approach to learn word embeddings . in word2vec , there are two ways to generate the `` input - desired output '' pairs from the context : `` skipgram '' ( predicts the surrounding words given the current word ) and `` cbow '' ( predicts the current word based on the surrounding words ) , and two approaches to simplify the training : `` negative sampling '' ( the vocabulary is represented in one hot representation , and the algorithm only takes a number of randomly sampled `` negative '' examples into consideration at each training step ) and `` hierarchical softmax '' ( the vocabulary is represented as a huffman binary tree ) .",
    "so one can train a word2vec model from the input under 4 different settings , like `` skipgram''+negative sampling \" .",
    "word2vec is the basis of our semi - supervised word embedding model , and we will discuss it with more details in section  [ sec : conceptembedding ] .",
    "our medical corpus has incorporated a set of wikipedia articles and medline abstracts ( 2013 version ) .",
    "we also complemented these sources with around 20 medical journals and books like _ merck manual of diagnosis and therapy_. in total , the corpus contains about 130 m sentences ( about 20 g pure text ) , and about 15 m distinct terms in the vocabulary set .",
    "a significant amount of the medical knowledge has already been stored in the unified medical language system ( umls )  @xcite , which includes medical concepts , definitions , relations , etc .",
    "the 2012 version of the umls contains more than 2.7 million concepts from over 160 source vocabularies .",
    "each concept is associated with a unique keyword called cui ( concept unique identifier ) , and each cui is associated with a term called preferred name .",
    "the umls consists of a set of 133 subject categories , or semantic types , that provide a consistent categorization of all cuis .",
    "the semantic types can be further grouped into 15 semantic groups .",
    "these semantic groups provide a partition of the umls metathesaurus for 99.5% of the concepts .",
    "domain specific parsers are required to accurately process the medical text .",
    "the most well - known parsers in this area include metamap ( aronson , 2001 ) and medicalesg , an adaptation of the english slot grammar parser  @xcite to the medical domain .",
    "these tools can detect medical entity mentions in a given sentence , and automatically associate each term with a number of cuis .",
    "not all the cuis are actively used in the medical text .",
    "for example , only 150k cuis have been identified by medicalesg in our corpus , even though there are in total 2.7 m cuis in umls .",
    "synonymy is a semantic relation between two terms with very similar meaning .",
    "however , it is extremely rare that two terms have the exact same meaning . in this paper ,",
    "our focus is to identify the near - synonyms , i.e. two terms are interchangeable in some contexts  @xcite .",
    "the umls 2012 release contains more than 600 relations and 50 m relation instances under 15 categories .",
    "each category covers a number of relations , and each relation has a certain number of cui pairs that are known to bear that relation . from umls relations , we manually choose a subset of them that are directly related to synonyms , and summarize them in table  [ tbl : synonymrelations ] . in table",
    "[ tbl : synonymexamples ] , we list several synonym examples provided by these relations .",
    ".umls relations corresponding to the synonym relation , where `` ro '' stands for `` has relationship other than synonymous , narrower , or broader '' , `` rq '' stands for `` related and possibly synonymous '' , and `` sy '' stands for `` source asserted synonymy '' .",
    "[ cols=\"^,^\",options=\"header \" , ]     our method was very scalable .",
    "it took on average several hours to generate the word embedding file from our medical corpus with 20 g text using @xmath0 g cpus and roughly 30 minutes to finish the training process using one cpu . to measure the scalability at the apply time",
    ", we constructed a new medical synonym knowledgebase with our best synonym extractor .",
    "this was done by applying the concept space model trained under the neg+skip setting to a set of 11b pairs of terms .",
    "all these terms are associated with cuis , and occur at least twice in our medical corpus .",
    "this kb construction process finished in less than 10 hours using one cpu , resulting in more than 3 m medical synonym term pairs . to evaluate the recall of this knowledgebase",
    ", we checked each term pair in the held out synonym dataset against this kb , and found that more than @xmath1 of them were covered by this new kb .",
    "precision evaluation of this kb requires a lot of manual annotation effort , and will be included in our future work .      in section  [ sec : featureexpansion ] , we expand the raw features with the matching features and several other feature expansions to model the term relationships . in this section , we study the contribution of each individual feature to the final results .",
    "we added all those expanded features to the raw features one by one and re - ran the experiments for the concept space model .",
    "the results and the feature contributions are summarized in table  [ tbl : featurecontributions ] .",
    "the results show that adding matching features , `` sum '' and `` difference '' features can significantly improve the @xmath2 scores .",
    "we can also see that adding the last two feature sets does not seem to contribute a lot to the average @xmath2 score .",
    "however , they do contribute significantly to our best @xmath2 score by about @xmath3 .",
    "in this paper , we present an approach to construct a medical concept space from manually extracted medical knowledge and a large corpus with 20 g unstructured text .",
    "our approach extends the word2vec model by making use of the medical knowledge as extra label information during the training process .",
    "this new approach fits well for the medical domain , where the language use variability is exceptionally high and the existing knowledge is also abundant .",
    "experiment results show that the proposed model outperforms the baseline approaches by a large margin on a dataset with more than one million term pairs .",
    "future work includes doing a precision analysis of the resulting synonym knowledgebase , and exploring how deep learning models can be combined with our concept space model for better synonym extraction .",
    "r.  collobert and j.  weston . a unified architecture for natural language processing : deep neural networks with multitask learning . in _ proceedings of the 25th international conference on machine learning _ , 2008 .",
    "x.  glorot , a.  bordes , and y.  bengio .",
    "domain adaptation for large - scale sentiment classification : a deep learning approach . in _ proceedings of the 28th international conference on machine learning _ , 2011 .",
    "a.  henriksson , m.  conway , m.  duneld , and w.  w. chapman .",
    "identifying synonymy between snomed clinical terms of varying length using distributional analysis of electronic health records . in _ proceedings of amia annual symposium .",
    "_ , 2013 .",
    "a.  henriksson , m.  skeppstedt , m.  kvist , m.  conway , and m.  duneld .",
    "corpus - driven terminology development : populating swedish snomed ct with synonyms extracted from electronic health records . in _ proceedings of bionlp _ , 2013 .",
    "p.  huang , x.  he , j.  gao , l.  deng , a.  acero , and l.  heck .",
    "learning deep structured semantic models for web search using clickthrough data . in _ proceedings of the acm international conference on information and knowledge management ( cikm ) _ , 2013 .",
    "t.  mikolov , k.  chen , g.  corrado , and j.  dean .",
    "efficient estimation of word representations in vector space . in _ proceedings of the workshop at international conference on learning representations _ , 2013 .",
    "y.  peirsman and d.  geeraerts .",
    "predicting strong associations on the basis of corpus data . in _ proceedings of the 12th conference of the european chapter of the association for computational linguistics _ , 2009 .",
    "r.  socher , c.  c. lin , a.  ng , and c.  d. manning .",
    "parsing natural scenes and natural language with recursive neural networks . in _ proceedings of the 28th international conference on machine learning ( icml ) _ , 2011 ."
  ],
  "abstract_text": [
    "<S> in this paper , we present a novel approach for medical synonym extraction . </S>",
    "<S> we aim to integrate the term embedding with the medical domain knowledge for healthcare applications . </S>",
    "<S> one advantage of our method is that it is very scalable . </S>",
    "<S> experiments on a dataset with more than 1 m term pairs show that the proposed approach outperforms the baseline approaches by a large margin . </S>"
  ]
}