{
  "article_text": [
    "measuring the similarity of curves is a classic problem in computational geometry with many applications .",
    "for example , it is used for map - matching tracking data  @xcite and moving objects analysis  @xcite . in all these applications",
    "it is important to take the continuity of the curves into account .",
    "therefore , the _ frchet distance _ and its variants are popular metrics to quantify ( dis)similarity . the frchet distance between two curves",
    "is defined by taking a homeomorphism between the curves that minimizes the maximum pairwise distance .",
    "it is commonly described using the _",
    "leash_-metaphor : a man walks on one curve and has a dog on a leash on the other curve . both man and dog can vary their speeds , but they may not walk backwards . the frchet distance is the length of the shortest leash with which man and dog can walk from the beginning to the end of the respective curves .    [ [ related - work ] ] related work + + + + + + + + + + + +    the algorithmic study of the frchet distance was initiated by alt and godau  @xcite . for polygonal curves ,",
    "they give an algorithm to solve the decision version in @xmath5 time , and then use parametric search to find the optimum in @xmath6 time .",
    "several randomized algorithms have been proposed which are based on the decision version in combination with sampling possible values for the distance , one running in @xmath4 time  @xcite and the other in @xmath6 time  @xcite .",
    "recently , buchin et al .",
    "@xcite showed how to solve the decision version in subquadratic time , resulting in a randomized algorithm for computing the frchet distance in @xmath7 time . in terms of the leash - metaphor",
    "these algorithms simply give a leash to the man and his dog to try if a walk is possible . by cleverly picking the different leash - lengths ,",
    "one then finds the frchet distance in an efficient way .",
    "several algorithms exist to approximate the frchet distance ( e.g. @xcite ) .",
    "however , these rely on various assumptions of the input curve ; no approximation algorithm is known for the general case .",
    "[ [ contribution ] ] contribution + + + + + + + + + + + +    we present a novel approach that does not use the decision problem as an intermediate stage .",
    "we give the man a `` retractable leash '' which can be lengthened or shortened as required . to this end",
    ", we consider monotone paths on the _ distance terrain _ , a generalization of the free space diagram typically used for the decision problem .",
    "similar concepts have been studied before , but without the monotonicity requirement ( e.g. , @xcite or the _ weak _ frchet distance @xcite ) .",
    "we show that it is sufficient to focus on the boundaries of cells of the distance terrain ( defined by the vertices of the curves ) .",
    "it seems natural to propagate through the terrain for any point on a boundary the minimal `` height '' ( leash length ) @xmath8 required to reach that point .",
    "however , this may lead to an amortized linear number of changes when moving from one boundary to the next , giving a lower bound of @xmath9 .",
    "we therefore do not maintain these functions explicitly .",
    "instead , we maintain sufficient information to compute the lowest @xmath8 for a boundary .",
    "a single pass over the terrain then finds the lowest @xmath8 for reaching the other end , giving the frchet distance .",
    "we present the core ideas for our approach in section  [ sec : framework ] .",
    "this framework gives a choice of distance metric , but it requires an implementation of a certain data structure .",
    "we apply this framework to the euclidean distance ( section  [ sec : euclidean ] ) and polyhedral distances ( section  [ sec : polyhedral ] ) .",
    "we also show how to use the latter to obtain a @xmath3-approximation for the former .",
    "this is the first approximation algorithm for the general case .",
    "we conclude with two open problems in section  [ sec : conclusion ] .",
    "* curves and distances .",
    "* throughout we wish to compute the dissimilarity of two polygonal curves , @xmath10 and @xmath11 . for simplicity , we assume that both curves consist of @xmath12 segments .",
    "this represents the computational worst case ; of course our algorithm can also cope with asymmetric cases .",
    "both curves are given as piecewise - linear functions @xmath13 \\rightarrow { \\mathbb{r}}^d$ ] .",
    "that is , @xmath14 holds for any integer @xmath15 and @xmath16 $ ] , and similarly for @xmath11 .",
    "let @xmath17 be the set of all continuous and nondecreasing functions @xmath18 \\rightarrow [ 0,n]$ ] with @xmath19 and @xmath20 .",
    "then the _ frchet distance _ is defined as @xmath21}\\ { \\delta(p(t ) , q(\\psi(t ) ) ) \\}.\\ ] ] here , @xmath22 may represent any distance function between two points in @xmath0 .",
    "typically , the euclidean distance function is used ; we consider this scenario in section  [ sec : euclidean ] .",
    "another option we shall consider are polyhedral distance functions ( section  [ sec : polyhedral ] ) . for our framework , we require that the distance function is convex .",
    "[ [ distance - terrain ] ] distance terrain + + + + + + + + + + + + + + + +    let us consider the joint parameter space @xmath23 \\times [ 0,n]$ ] of @xmath10 and @xmath11 .",
    "a pair @xmath24 corresponds to the points @xmath25 and @xmath26 , and the distance function @xmath22 assigns a value @xmath27 to @xmath28 .",
    "we interpret this value as the `` height '' at point @xmath24 .",
    "this gives a _ distance terrain _",
    "@xmath29 , i.e. , @xmath30 with @xmath31",
    ". we segment @xmath29 into @xmath32 _ cells _ based on the vertices of @xmath10 and @xmath11 . for integers @xmath33 , the cell @xmath34 $ ] is defined as the subset @xmath35 \\times [ j , j+1]$ ] of the parameter space .",
    "the cells form a regular grid , and we assume that @xmath36 represents the column and @xmath37 represents the row of each cell .",
    "an example of two curves and their distance terrain is given in figure  [ fig : terrain ] .    .",
    "( left ) two curves .",
    "( middle ) cells as seen from above .",
    "dark colors indicate low `` height '' .",
    "( right ) perspective view . ]",
    "a path @xmath38 \\rightarrow r$ ] is called _ bimonotone _ if it is both @xmath39- and @xmath40-monotone . for @xmath24 , we let @xmath41 denote the set of all bimonotone continuous paths from the origin to @xmath28 .",
    "acrophobia function _",
    "@xmath42 is defined as @xmath43 } t(\\pi(\\lambda)).\\ ] ] intuitively , @xmath44 represents the lowest height that an acrophobic climber needs to master in order to reach @xmath28 from the origin on a bimonotone path . clearly , we have @xmath45 .",
    "let @xmath46 and @xmath47 be a bimonotone path from @xmath48 to @xmath39 .",
    "let @xmath8 be a value greater than zero .",
    "we call @xmath49 an",
    "_ @xmath8-witness _ for @xmath39 if @xmath50 }",
    "t(\\pi(\\lambda ) )   \\leq { \\varepsilon}$ ] .",
    "we call @xmath49 a _ witness _ for @xmath39 if @xmath50 }",
    "t(\\pi(\\lambda ) )   = { \\widetilde{t}}(x)$ ] , i.e. , @xmath49 is an optimal path for the acrophobic climber .",
    "the frchet distance corresponds to the acrophobia function on the distance terrain . to compute @xmath51",
    ", we show that it is sufficient to consider only the cell boundaries . for this , we generalize the fact that cells of the free space diagram are convex  @xcite to convex distance functions .    [ lem : convexthreshold ] for a convex distance function @xmath22 and @xmath52 , the set of points @xmath28 in a given cell",
    "@xmath34 $ ] with @xmath53 is convex .",
    "the cell @xmath34 $ ] represents the parameter space of two line segments in @xmath0 .",
    "let @xmath54 and @xmath55 denote the parameterized lines coinciding with these line segments .",
    "both @xmath56 and @xmath57 are affine mappings .",
    "we take the mapping @xmath58 defined by @xmath59 , which is affine by closure of affine mappings .",
    "let @xmath60 denote the convex set of points @xmath61 .",
    "we take the preimage of @xmath62 with the convex set @xmath60 .",
    "the result contains all the points of @xmath63 such that @xmath64 .",
    "since the preimage of an affine mapping is affine too , we can apply an affine mapping to the convex set @xmath60 . an affine mapping to a convex set results in a convex set and",
    "thereby we have a convex set of all points @xmath28 which fit in @xmath60 .",
    "we take the intersection of cell @xmath34 $ ] with @xmath65 to find the set of points in @xmath34 $ ] with @xmath53 .",
    "this set is convex as it is the intersection of two convex sets .",
    "lemma  [ lem : convexthreshold ] has two important consequences .",
    "first , it implies that it is indeed sufficient to consider only the cell boundaries .",
    "second , it tells us that the distance terrain along a boundary is well - behaved . in this corollary and in the remainder of the paper",
    ", we refer to a function with a single local minimum as _ unimodal_.    [ col : witnessedge ] let @xmath34 $ ] be a cell of the distance terrain , and let @xmath66 and @xmath67 be two points on different boundaries of @xmath34 $ ] . for any @xmath40 on the line segment @xmath68 , we have @xmath69 .",
    "[ col : convexboundary ] the distance along every boundary of a cell in distance terrain @xmath29 is a unimodal function .    for any cell @xmath34 $ ] , we denote with @xmath70 $ ] and @xmath71 $ ] its left and bottom boundary respectively ( and their height functions in @xmath29 ) . the right and top boundary",
    "are given by @xmath72 $ ] and @xmath73$].$ ] or @xmath74 $ ] . ] with @xmath75 $ ] and @xmath76 $ ] we denote the acrophobia function along the boundary .",
    "all these restricted functions have a single parameter in the interval @xmath77 $ ] that represents the boundary .    assuming that the distance function @xmath22 is symmetric , computing values for rows and columns of @xmath29 is symmetric as well .",
    "hence , we present only how to compute with rows . if @xmath22 is asymmetric , our methods still work , but some extra care needs to be taken when computing distances .    consider a vertical boundary @xmath70 $ ] .",
    "we use @xmath78 $ ] to denote the minimum of the acrophobia function @xmath75 $ ] along @xmath70 $ ] .",
    "an analogous definition is used for horizontal boundaries .",
    "our goal is to compute @xmath78 $ ] and @xmath79 $ ] for all cell boundaries of the grid .",
    "we say that an @xmath8-witness @xmath49 _ passes through _ an edge @xmath71 $ ] , if there is a @xmath16 $ ] with @xmath80 $ ] .",
    "[ lem : moverighterwitness ] let @xmath81 , and let @xmath39 be a point on @xmath70 $ ] .",
    "let @xmath49 be an @xmath8-witness for @xmath39 that passes through @xmath82 $ ] , for @xmath83 .",
    "suppose further that there exists a column @xmath84 with @xmath85 and @xmath86 \\leq { \\varepsilon}$ ] .",
    "then there exists an @xmath8-witness for @xmath39 that passes through @xmath87 $ ] .",
    "let @xmath40 be the point on @xmath87 $ ] that achieves @xmath86 $ ] , and let @xmath88 be a witness for @xmath40 .",
    "since @xmath49 is bimonotone and since @xmath49 passes through @xmath82 $ ] , it follows that @xmath49 must also pass through @xmath89 $ ] .",
    "let @xmath90 be the ( lowest ) intersection point , and @xmath91 the subpath of @xmath49 from @xmath90 to @xmath39 .",
    "let @xmath92 be the path obtained by concatenating @xmath88 , line segment @xmath93 , and @xmath91 . by our assumption on @xmath8 and by corollary  [ col : witnessedge ] ,",
    "path @xmath92 is an @xmath8-witness for @xmath39 that passes through @xmath87 $ ] .",
    "this is illustrated in figure  [ fig : rightmost ] .",
    "on @xmath70 $ ] has an @xmath8-witness @xmath49 that passes through @xmath82 $ ] and @xmath86 \\leq { \\varepsilon}$ ] holds for some @xmath85 . then combining the witness @xmath88 for point @xmath40 with segment @xmath93 and @xmath91 , the subpath of @xmath49 that starts at @xmath94 $ ] , yields an @xmath8-witness for @xmath39 that passes through @xmath87 $ ] . ]",
    "lemma  [ lem : moverighterwitness ] implies that there are always _ rightmost _ witnesses for any point @xmath39 on @xmath70 $ ] .",
    "for such witness , if it passes through boundary @xmath82 $ ] for some @xmath95 , then the acrophobia function of all later bottom boundaries is strictly greater than the acrophobia function at @xmath39 . in particular",
    ", this also holds for the minimum of these later boundaries , @xmath86 $ ] .",
    "[ col : rightmost ] let @xmath39 be a point on @xmath70 $ ] .",
    "then there is a witness for @xmath39 that passes through some @xmath82 $ ] such that @xmath86 > { \\widetilde{t}}(x)$ ] for any @xmath85 .",
    "next , we argue that there is a witness for @xmath96 $ ] that enters row j at or after the horizontal boundary point used by the witness for @xmath78 $ ] . in other words ,",
    "the rightmost witnesses behave `` monotonically '' in the terrain .",
    "[ lem : lowestoptcp ] let @xmath49 be a witness for @xmath78 $ ] that passes through @xmath82 $ ] , for a @xmath83 . then there exists a @xmath97 such that @xmath98 $ ] has a witness that passes through @xmath87 $ ]",
    ".    choose @xmath84 maximal such that @xmath98 $ ] has a witness that passes through @xmath87 $ ] .",
    "if @xmath99 , we are done . hence , suppose @xmath100 .",
    "let @xmath92 be such a witness .",
    "we know that @xmath98 \\geq { { { \\widetilde{l}}^*}}[i , j]$ ] , since @xmath92 passes through @xmath70 $ ] .",
    "however , we can now construct a witness for @xmath98 $ ] that passes through @xmath82 $ ] : follow @xmath49 to @xmath82 $ ] and then switch to the intersection of @xmath92 and @xmath101 $ ] .",
    "this contradicts the choice of @xmath84 .",
    "we now characterize @xmath75 $ ] via a _ witness envelope_. fix a column @xmath36 and a row @xmath37 .",
    "suppose that @xmath102 $ ] has a witness that passes through @xmath103 $ ] . fix a second column @xmath104 .",
    "we are interested in the best witness for @xmath70 $ ] that passes through @xmath105 $ ] .",
    "the envelope is a function @xmath106 \\rightarrow { \\mathbb{r}}$ ] .",
    "the witnesses must pass through @xmath105 $ ] and @xmath107 $ ] ( if @xmath108 ) , and it ends on @xmath70 $ ] .",
    "hence , we know that @xmath109 , { { { \\widetilde{l}}^*}}[i-1,j ] , l[i , j](\\lambda ) \\}$ ] . however , this is not enough to exactly characterize the best witness for @xmath70 $ ] through @xmath82 $ ] . to this end",
    ", we introduce _ truncated terrain functions _",
    "@xmath110(\\lambda ) = \\min_{\\mu \\in [ 0,\\lambda ] } l[b , j](\\mu)$ ] for @xmath85 .",
    "since @xmath111 $ ] is a unimodal function , @xmath110 $ ] represents the decreasing part stopping at its minimal value and remaining constant there .",
    "the reason for these truncated functions is the following . to arrive at @xmath70(\\lambda)$ ] , we must cross all @xmath111 $ ] below @xmath112 . on the decreasing part , passing the boundary below the minimum position results in a higher value and thus this may be relevant",
    ". the increasing part of @xmath111 $ ] however is not important , because we might just pass @xmath111 $ ] closer to the minimum .",
    "this intuition is not quite true , since the order of the increasing parts may be relevant , but we will see below that this is not a problem . therefore , we also know that @xmath113(\\lambda)$ ] for @xmath85 .",
    "summarizing , the witness envelope for the column interval @xmath114 $ ] in row @xmath37 is the upper envelope of the following functions on the interval @xmath77 $ ] :    * the terrain function @xmath70(\\lambda)$ ] ; * the constant function @xmath115 $ ] ; * the constant function @xmath102 $ ] if @xmath116 ; * the truncated terrain functions @xmath110(\\lambda)$ ] for @xmath85 .",
    "an example of a witness envelope is given in figure  [ fig : witnessenvelope ] . even though the usage of the truncated functions may appear to be an underestimate of the witness envelope , we prove with the following lemma that it in fact exactly characterizes @xmath75 $ ] for witnesses that pass through @xmath82 $ ] .    .",
    "it is the upper envelope of two constant functions , one ( untruncated ) terrain function , and 2 truncated terrain functions . ]",
    "[ lem : witnessenvelope ] fix a row @xmath37 and two columns @xmath95 as above .",
    "let @xmath117 $ ] and @xmath81 .",
    "the point @xmath118 has an @xmath8-witness that passes through @xmath82 $ ] if and only if @xmath119 lies above the witness envelope for @xmath114 $ ] in row @xmath37 .",
    "let @xmath49 be an @xmath8-witness for @xmath39 that passes through @xmath82 $ ] .",
    "then clearly @xmath120 $ ] and @xmath121(\\alpha)$ ] .",
    "if @xmath122 , then @xmath49 must pass through @xmath107 $ ] , so @xmath123 $ ] .",
    "since @xmath49 is bimonotone , it has to pass through @xmath111 $ ] for @xmath85 .",
    "let @xmath124 be the points of intersection , from left to right",
    ". then @xmath125 and @xmath126(\\alpha_i ) \\geq { \\overline{l}}[a+l , j](\\alpha)$ ] , for @xmath127 .",
    "hence @xmath119 is above the witness envelope .",
    "suppose @xmath119 is above the witness envelope .",
    "the conclusion follows directly if @xmath128 .",
    "otherwise , @xmath123 $ ] holds .",
    "let @xmath129 be such that the witness for @xmath102 $ ] that passes through @xmath103 $ ] reaches @xmath107 $ ] at point @xmath130 .",
    "if @xmath131 , we construct an appropriate @xmath8-witness @xmath92 for @xmath39 by following the witness for @xmath132 $ ] , then passing to the witness for @xmath102 $ ] and then taking the line segment to @xmath39 .",
    "if @xmath133 , we construct a curve @xmath92 as before .",
    "however , @xmath92 is not bimonotone ( the last line segment goes down ) . to fix this ,",
    "let @xmath134 and @xmath39 be the two intersection points of @xmath92 with the horizontal line @xmath135 .",
    "we shortcut @xmath92 at the line segment @xmath136 as illustrated in figure  [ fig : witnessproof ] .",
    "the resulting curve @xmath49 is clearly bimonotone and passes through @xmath82 $ ] . to see that @xmath49 is an @xmath8-witness , it suffices to check that along the segment @xmath136 , the distance terrain never goes above @xmath8 . for this , we need to consider only the intersections of @xmath136 with the vertical cell boundaries .",
    "let @xmath137 $ ] be such a boundary .",
    "we know that @xmath111 $ ] is unimodal ( corollary  [ col : convexboundary ] ) and let @xmath138 denote the value where the minimum is obtained . by definition of the truncated terrain function , @xmath111(\\alpha )",
    "= { \\overline{l}}[b , j](\\alpha)$ ] if @xmath139 . by assumption ,",
    "the witness for @xmath102 $ ] passes @xmath111 $ ] at @xmath140 or higher .",
    "hence , if @xmath141 , then @xmath102 \\geq l[b , j](\\alpha)$ ] .",
    "it follows that @xmath142(\\alpha ) , { { { \\widetilde{l}}^*}}[i-1,j]\\ } \\geq l[b , j](\\alpha)$ ] . by definition @xmath143(\\alpha ) , { { { \\widetilde{l}}^*}}[i-1,j]\\}$ ] holds and thus @xmath144(\\alpha)$ ] .    , we combine the witness for @xmath115 $ ] , the witness for @xmath102 $ ] , and the segment from @xmath102 $ ] to @xmath39 .",
    "note that by assumption , the witness for @xmath102 $ ] passes through @xmath82 $ ] or an earlier bottom boundary of row @xmath37 . if @xmath133 , then @xmath92 is not bimonotone .",
    "we use shortcut with segment @xmath136 ( dotted ) to obtain a bimonotone path @xmath49 . ]",
    "we are now ready to present the algorithm .",
    "we walk through the distance terrain , row by row , in each row from left to right .",
    "when processing a cell @xmath34 $ ] , we compute @xmath96 $ ] and @xmath145 $ ] . for each row @xmath37",
    ", we maintain a double - ended queue ( deque ) @xmath146 that stores a sequence of column indices .",
    "we also store a data structure @xmath147 that contains a set of ( truncated ) terrain functions on the vertical boundaries in @xmath37 .",
    "it supports insertion , deletion , and a minimum - point query that , given up to two additional constants , returns the lowest point on the upper envelope of the terrain functions and the given constants . in other words",
    ", @xmath147 implicitly represents a witness envelope .",
    "the data structures fulfill the following invariant .",
    "suppose that @xmath78 $ ] is the rightmost optimum we have computed so far in row @xmath37 , and suppose that a rightmost witness for @xmath78 $ ] passes through @xmath82 $ ] .",
    "a point @xmath148 _ dominates _ a point @xmath149 if @xmath150 and @xmath151 .",
    "then @xmath146 stores the first coordinates of the points in the sequence @xmath152 ) , ( a+1 , { { { \\widetilde{b}}^*}}[a+1,j ] ) , \\dots , ( i-1 , { { { \\widetilde{b}}^*}}[i-1,j])$ ] that are not dominated by any other point in the sequence . furthermore ,",
    "the structure @xmath147 stores the ( truncated ) terrain functions for the vertical boundaries from column @xmath153 to @xmath36 .",
    "we maintain analogous data structures and invariants for each column @xmath36 .",
    "the algorithm proceeds as follows ( see algorithm  [ alg : frechetbasic ] ) : since @xmath48 belongs to any path through the distance terrain , we initialize @xmath154 $ ] to use @xmath48 as its lowest point and compute the distance accordingly .",
    "the left- and bottommost boundaries of the distance terrain are considered unreachable .",
    "any path to such a point also goes through the adjacent horizontal boundaries or vertical boundaries respectively .",
    "these adjacent boundaries therefore ensure a correct result .    in the body of the for - loop , we compute @xmath96 $ ] and @xmath145 $ ] .",
    "let us describe how to find @xmath96 $ ] .",
    "first , we add index @xmath36 to @xmath146 and remove all previous indices that are dominated by it from the back of the deque .",
    "we add @xmath72 $ ] to upper envelope @xmath147 .",
    "let @xmath155 and @xmath156 be the first and second element of @xmath146 .",
    "we perform a minimum query on @xmath147 in order to find the smallest @xmath157 for which a point on @xmath72 $ ] has an @xmath157-witness that passes through @xmath158 $ ] . by lemma  [ lem : witnessenvelope ]",
    ", this query requires the height at which the old witness enters the row ( @xmath159 $ ] ) and the value of the previous boundary @xmath78 $ ] . ( the latter is needed only for @xmath160 , i.e. if @xmath161 . for simplicity ,",
    "we omit this detail in the overview . )",
    "if @xmath162 $ ] , there is an @xmath157 witness for @xmath72 $ ] through @xmath163 $ ] , so we can repeat the process with @xmath156 ( after updating @xmath147 ) . if @xmath156 does not exist ( i.e. , @xmath164 ) or @xmath165 $ ] , we stop and declare @xmath157 to be optimal",
    "finally , we update @xmath147 to use the truncated terrain function @xmath166 $ ] instead of the untruncated @xmath167 $ ] .",
    "we prove that this process is correct and maintains the invariant .",
    "since the invariant is clearly satisfied at the beginning , correctness then follows by induction .",
    "@xmath10 and @xmath11 are polygonal curves with @xmath12 edges in @xmath0 ; + @xmath22 is a convex distance function in @xmath0 frchet distance @xmath168    @xmath169 \\gets \\delta(p(0 ) , q(0))$ ] @xmath170 \\gets \\infty$ ] for all @xmath171 for each row @xmath37 , create empty deque @xmath146 and upper envelope structure @xmath147    remove any values @xmath39 from @xmath146 with @xmath172 \\geq { { { \\widetilde{b}}^*}}[i , j]$ ] and append @xmath36 to @xmath146 [ line : clearqueue ] clear @xmath147 add @xmath72 $ ] to @xmath147 [ line : insertenvelope ]    let @xmath155 and @xmath156 be the first and second element in @xmath146 @xmath173 , { { { \\widetilde{b}}^*}}[h , j])$ ] [ line : query1 ] [ line : while ] remove all @xmath174 $ ] from @xmath147 with @xmath175 [ line : deleteenvelope ] remove the head @xmath155 from @xmath146 let @xmath155 and @xmath156 be the first and second element in @xmath146 @xmath173 , { { { \\widetilde{b}}^*}}[h , j])$ ] [ line : query2 ] @xmath96 \\gets { \\varepsilon}_\\alpha$ ] update @xmath72 $ ] to @xmath166 $ ] in @xmath147 [ line : trunc ]    @xmath176 , { { { \\widetilde{b}}^*}}[n-1,n-1 ] \\ } \\}$ ]    [ lem : basiccorrect ] algorithm  [ alg : frechetbasic ] computes @xmath96 $ ] and maintains the invariant .    by the invariant , a rightmost witness for @xmath78 $ ] passes through @xmath177 $ ] , where @xmath178 is initial head of @xmath146 .",
    "let @xmath179 be the column index such that a rightmost witness for @xmath96 $ ] passes through @xmath180 $ ]",
    ". then @xmath179 must be contained in @xmath146 initially , because by lemma  [ lem : lowestoptcp ] , we have @xmath181 , and by corollary  [ col : rightmost ] , there can be no column index @xmath182 with @xmath183 that dominates @xmath184)$ ] .",
    "( note that if @xmath185 , it is added at the beginning of the iteration . )",
    "now let @xmath155 be the current head of @xmath146 .",
    "by lemma  [ lem : witnessenvelope ] , the minimum query on @xmath147 gives the smallest @xmath157 for which there exists an @xmath157-witness for @xmath72 $ ] that passes through @xmath158 $ ] .",
    "if the current @xmath155 is less than @xmath179 , then @xmath186 $ ] ( definition of @xmath187 ) ; @xmath98 \\geq { { { \\widetilde{b}}^*}}[h^ * , j]$ ] ( there is a witness through @xmath188 $ ] ) ; and @xmath189 \\geq { { { \\widetilde{b}}^*}}[h ' , j]$ ] ( the dominance relation ensures that the @xmath190-values for the indices in @xmath146 are increasing ) .",
    "thus , the while - loop in line  [ line : while ] proceeds to the next iteration .",
    "if the current @xmath155 equals @xmath179 , then by corollary  [ col : rightmost ] , we have @xmath132 > { { { \\widetilde{b}}^*}}[h^ * , j]$ ] for all @xmath183 , and the while - loop terminates with the correct value for @xmath78 $ ] .",
    "it is straightforward to check that algorithm  [ alg : frechetbasic ] maintains the data structures @xmath146 and @xmath147 according to the invariant .",
    "[ thm : basicalg ] algorithm  [ alg : frechetbasic ] computes @xmath168 for convex distance function @xmath22 in @xmath0 in @xmath191 time , where @xmath192 represents the time to insert into , delete from , and query the upper envelope data structure .    the correctness of the algorithm follows from lemma  [ lem : basiccorrect ] . for the running time",
    ", we observe that we insert values only once into @xmath146 and functions of boundaries at most twice into @xmath147 ( once untruncated , once truncated ) .",
    "hence , we can remove elements at most once or twice , leading to an amortized running time of @xmath193 for a single iteration of the loop .",
    "since there are @xmath5 cells , the total running time is @xmath191 assuming that @xmath192 is @xmath194 .    in the generic algorithm",
    ", we must take care that @xmath147 uses the ( full ) unimodal function only for @xmath72 $ ] and the truncated versions for the other boundaries .",
    "as it turns out , we can use the full unimodal distance functions if these behave as pseudolines ( i.e. , they intersect at most once ) .",
    "since we compare only functions in the same row ( or column ) , functions of different rows or columns may still intersect more than once .",
    "this allows us to avoid updating @xmath147 in line  [ line : trunc ] .",
    "moreover , it may allow for more efficient implementations of the data structure @xmath147 .",
    "for this approach to work , we must remove from @xmath147 any function that is no longer relevant for our computation .",
    "this implies that @xmath147 no longer contains all functions @xmath195 $ ] with @xmath196 but a subset of these .",
    "we prove the following .",
    "[ lem : unimodalpseudolines ] assume that the distance functions @xmath174 $ ] in row @xmath37 intersect pairwise at most once .",
    "let @xmath155 denote a candidate bottom boundary .",
    "let @xmath197 denote the minimum on the upper envelope of the full unimodal distance functions in @xmath147 .",
    "then one of the following holds :    * @xmath197 is the minimum of the upper envelope of @xmath72 $ ] and the truncated @xmath198 $ ] for @xmath199 .",
    "* @xmath197 lies on two functions @xmath200 $ ] and @xmath111 $ ] , one of which can be removed from @xmath147 . *",
    "@xmath201 $ ] .",
    "if @xmath197 lies on the minimum of some function @xmath195 $ ] , then case ( i ) holds : the minimum of @xmath195 $ ] is equal to the minimum of @xmath198 $ ] and therefore also the minimum of the upper envelope for case ( i ) .",
    "if @xmath202 does not lie on the minimum of a function , then it must lie on the intersection of two functions @xmath200 $ ] and @xmath111 $ ] . without loss of generality , assume @xmath203 .",
    "one of the functions must be increasing and the other decreasing ( otherwise , @xmath202 would not be a minimum ) .",
    "we distinguish two cases .",
    "assume @xmath200 $ ] is increasing and @xmath111 $ ] is decreasing .",
    "since @xmath200 $ ] and @xmath111 $ ] intersect at most once , we know that @xmath200(\\lambda ) \\leq l[b , j](\\lambda)$ ] for @xmath204",
    ". now consider some witness that passes through both these boundaries to some point @xmath39 on @xmath205 $ ] with @xmath206 .",
    "if @xmath207 , then @xmath208(\\lambda ) \\leq l[a , j](\\lambda ) \\leq l[b , j](\\lambda ) = { \\overline{l}}[b , j](\\lambda)$ ] holds for @xmath209 and thus @xmath208 $ ] is not part of the witness envelope for any @xmath210 $ ] with @xmath211 .",
    "if @xmath212 , we argue as follows .",
    "since the minimum of @xmath200 $ ] provides a lower bound on @xmath78 $ ] , we know that the truncated part of @xmath200 $ ] is not part of the witness envelope for any @xmath210 $ ] with @xmath211 . we conclude that @xmath200 $ ] can not ever be part of a witness envelope anymore , and thus can be safely removed from @xmath147 ( case ( ii ) ) .",
    "assume @xmath200 $ ] is decreasing and @xmath111 $ ] is increasing .",
    "since @xmath155 ( the head of @xmath146 ) is a candidate for @xmath72 $ ] , we know that the rightmost witness of @xmath78 $ ] passes through @xmath158 $ ] or an earlier bottom boundary .",
    "this rightmost witness passes through both @xmath200 $ ] and @xmath111 $ ] and therefore @xmath78 \\geq { { { \\widetilde{l}}^*}}[b , j]$ ] .",
    "since the increasing part of @xmath111 $ ] was significant for the computation of @xmath213 $ ] , we know that @xmath213 \\geq { \\varepsilon}_\\alpha$ ] . by transitivity , we know that case ( iii ) must hold .    from this lemma",
    ", we learn how to modify a minimum - point query .",
    "we run the query on the full unimodal functions , ignoring the given constants .",
    "if case ( ii ) holds , that is , the minimum lies on an increasing @xmath200 $ ] and a decreasing @xmath111 $ ] with @xmath203 , we remove @xmath200 $ ] from @xmath147 and repeat the query . in both of the other cases , the minimum is either the computed minimum or one of the constants @xmath78 $ ] and @xmath159 $ ] .",
    "we take the maximum of these three values .",
    "in this section we apply our framework to the euclidean distance measure @xmath214 .",
    "obviously , @xmath214 is convex ( and symmetric ) , so our framework applies .",
    "however , instead of computing with the euclidean distance , we use the squared euclidean distance @xmath215 . squaring does not change any relative order of height on the distance terrain @xmath29 , so computing the frchet distance with the squared euclidean distance is equivalent to the euclidean distance : if @xmath216 for @xmath217 , then @xmath218 for @xmath214 .",
    "we now show that for @xmath217 , the distance functions in a row or column behave like pseudolines .",
    "we argue only for the vertical boundaries ; horizontal boundaries are analogous .",
    "[ lem : sqreucl ] for @xmath219 , each distance terrain function @xmath70 $ ] is part of a parabola , and any two functions @xmath70 $ ] and @xmath220 $ ] intersect at most once .",
    "function @xmath70 $ ] represents part of the distance between point @xmath221 and line segment @xmath222 .",
    "assume @xmath223 is the line though @xmath224 , uniformly parameterized by @xmath225 , i.e. @xmath226 .",
    "let @xmath227 denote the @xmath112 such that @xmath228 is closest to @xmath134 .",
    "we see that @xmath70(\\lambda ) = |p   - \\ell'(\\lambda_p)|^2 + |\\ell'(\\lambda ) - \\ell'(\\lambda_p)|^2 $ ] .",
    "since @xmath223 is uniformly parameterized according to @xmath224 , we get that the last term is @xmath229 . hence , the function is equal to @xmath230 , which is a parabolic function in @xmath112 .",
    "the quadratic factor depends only on @xmath224 . for two functions in the same row ,",
    "this line segment is the same , and thus the parabolas intersect at most once .    by lemma  [ lem : unimodalpseudolines ] , we know that data structure @xmath147 can use the full parabolas . the parabolas of a single row share the same quadratic term , so we can treat them as lines by subtracting @xmath231",
    ". the constant functions are now downward parabolas .",
    "this poses no problem , as we can first determine the minimum of the ( original ) parabolas and later include the constants",
    ". however , observe that the minimum of the upper envelope of parabolas does not necessarily correspond to the minimum of the lines .",
    "the interpretation of the parabolas as lines allows us to implement @xmath147 with a standard data structure for dynamic half - plane intersections , or its dual problem : dynamic convex hulls .",
    "the fastest such structure is given by brodal and jacob @xcite .",
    "however , this structure does not explicitly represent the upper envelope , and it is not clear whether it can be modified easily to support our special minimal - point query .",
    "therefore , we use the slightly slower structure by overmars and van leeuwen  @xcite , giving @xmath232 time insertions and deletions . for each insertion",
    ", we also have to compute the corresponding parabola , in @xmath233 additional time .",
    "we now describe the minimum - point query .",
    "the data structure by overmars and van leeuwen maintains a _",
    "concatenable queue _ for the upper envelope .",
    "recall that a concatenable queue is an abstract data type that provides the operations _ insert _ , _ delete _ , _ concatenate _ , and _",
    "split_. when the queue is implemented with a red - black tree , all these operations can be performed in time @xmath234 .",
    "in addition to the tree , we have a doubly - linked list that stores the elements in sorted order , together with cross - pointers between the corresponding nodes in the tree and in the list . the list and the cross - pointers",
    "can be maintained with constant overhead .",
    "furthermore , the list enables us to perform predecessor and successor queries in @xmath235 time , given that a pointer to the appropriate node is available .",
    "the order of the points on the convex hull corresponds directly to the order of the lines , and hence to the order of the parabolas on their respective upper envelopes .",
    "we use the red - black tree to perform a binary search for the minimum point of the upper envelope @xmath236 of the parabolas .",
    "we can not decide how to proceed solely based on the parabola @xmath134 of a single node .",
    "however , using the predecessor and successor of @xmath134 , we can determine the `` local '' intersection pattern .",
    "based on this , we perform the binary search",
    ".    let @xmath134 be a parabola on @xmath236 ; let @xmath237 and @xmath238 denote its predecessor and successor , respectively .",
    "let @xmath239 , @xmath240 , and @xmath241 denote their respective minima . since these parabolas are on @xmath236 , they pairwise intersect exactly once .",
    "as @xmath237 and @xmath238 are the neighbors of @xmath134 on @xmath236 , the intersection @xmath242 lies before the intersection @xmath243 ; the part of @xmath134 on @xmath236 is exactly between them .",
    "first , we distinguish three cases based on @xmath244 as illustrated in figure  [ fig : bscases ] : ( i ) @xmath244 lies after @xmath239 but before @xmath240 ; ( ii ) @xmath244 lies after @xmath239 and @xmath240 ; or ( iii ) @xmath244 lies before @xmath239 . the point @xmath244 can not lie before @xmath239 but after @xmath240 as this would imply that @xmath237 is above @xmath134 after @xmath244 , contradicting that @xmath237 is the predecessor of @xmath134 . in case ( i ) , @xmath237 is decreasing and @xmath134 is increasing at @xmath244 , so @xmath244 is the minimum of @xmath236 . in case ( ii ) ,",
    "@xmath134 and the part of @xmath236 after @xmath134 are not incident to the minimum , as @xmath237 is decreasing to the left of the intersection .",
    "thus , we recurse on the left child of @xmath134 . in case ( iii ) , the part of @xmath236 before @xmath134 is higher than @xmath134 . in this case",
    ", we consider the analogous cases for @xmath245 : ( a ) @xmath245 lies before @xmath239 but after @xmath241 ; ( b ) @xmath245 lies before @xmath239 and @xmath241 ; ( c ) @xmath245 lies after @xmath239 .",
    "again , in case ( a ) , @xmath245 is the minimum point . in case",
    "( b ) , we recurse on the right child of @xmath134 . in case ( c ) , we know that @xmath244 is before @xmath239 and that @xmath245 is after @xmath239 . therefore , @xmath239 is the minimum point of the upper envelope .",
    "and @xmath237 determines the minimum point .",
    "( ii ) intersection of @xmath134 and @xmath237 excludes the possibility of the minimum point being on @xmath134 or a later part .",
    "( iii / c ) any parabola before @xmath134 can not be incident to the minimum point . if the analogous case holds for @xmath238 as well , then the minimum of @xmath134 is the minimum of the upper envelope . ]",
    "as we can access the predecessor and successor of a node and determine the intersection pattern in constant time , a minimum - point query takes @xmath234 time . to include the constants , we take the maximum of the minimum point and the constants",
    "we now obtain the following result .",
    "[ thm : euclalgo ] algorithm  [ alg : frechetbasic ] computes the frchet distance under the euclidean distance in @xmath246 in @xmath247 time .",
    "this is slightly slower than known results for the euclidean metric .",
    "however , we think that our framework has potential for a faster algorithm ( see section  [ sec : conclusion ] ) .",
    "here we consider the frchet distance with a ( convex ) polyhedral distance function @xmath248 , i.e. , the `` unit sphere '' of @xmath248 is a convex polytope in @xmath0 .",
    "for instance , the @xmath1 and the @xmath2 distance are polyhedral with the cross - polytope and the hypercube as respective unit spheres . throughout",
    "we assume that @xmath248 has _ complexity _",
    "@xmath249 , i.e. , its unit sphere has @xmath249 facets .",
    "the distance terrain functions @xmath70 $ ] and @xmath71 $ ] are now piecewise linear with at most @xmath249 parts ; in each row and column the corresponding parts are parallel . depending on the polytope",
    ", the actual maximum number @xmath250 of parts may be less .",
    "the distance @xmath248 has to be neither regular nor symmetric , but as before , we simplify the presentation by assuming symmetry .",
    "we present three approaches .",
    "first , we use an upper envelope structure as in the euclidean case , but exploiting that the distance functions are now piecewise linear .",
    "second , we use a brute - force approach which is more efficient for small to moderate dimension @xmath251 and complexity @xmath249 .",
    "third , we combine these methods to deal with the case of moderately sized @xmath251 and @xmath250 much smaller than @xmath249 .    [ [ upper - envelope - data - structure ] ] upper envelope data structure + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for piecewise linear @xmath70 $ ] and @xmath71 $ ] , we can relax the requirements for the upper envelope data structure @xmath147 .",
    "there are no parabolas involved , so we only need a data structure that dynamically maintains the upper envelope of lines under insertions , deletions , and minimum queries .",
    "every function @xmath70 $ ] ( and @xmath71 $ ] ) contains at most @xmath250 parts , so we insert at most @xmath252 lines into the upper envelope . maintaining and querying the upper envelope per row or column takes @xmath253 time with the data structure by brodal and jacob  @xcite .",
    "thus , the total running time is @xmath254 , where @xmath255 is the time to find the parts of the function .    [ [ brute - force - approach ] ] brute - force approach + + + + + + + + + + + + + + + + + + + +    we implement @xmath147 naively . for each segment of @xmath256 ,",
    "we sort the facets of @xmath248 by the corresponding slope on the witness envelope , in @xmath257 total time . for each facet",
    "@xmath258 , we store a doubly linked list @xmath259 of lines representing the linear parts of the unimodal functions in @xmath147 corresponding to facet @xmath237 , sorted from top to bottom ( the lines are parallel ) .",
    "when processing a cell boundary @xmath70 $ ] , we update each list @xmath259 : remove all lines below the line for @xmath260 from the back , and append the line for @xmath260 .",
    "this takes amortized @xmath233 time per facet , @xmath261 time per cell boundary .",
    "we then go through the top lines in the @xmath259 in sorted order to determine ( the minimum of ) the upper envelope .",
    "this takes @xmath262 time .",
    "the total time is @xmath263 .",
    "[ [ a - hybrid - approach ] ] a hybrid approach + + + + + + + + + + + + + + + + +    as in the brute force approach , we maintain a list @xmath259 for each of the @xmath249 slopes .",
    "for each segment in @xmath256 we initialize these lists , which takes @xmath264 time .",
    "but instead of sorting the slopes initially , we maintain the upper hull of the top lines in each @xmath259 .",
    "thus , we only need a dynamic upper hull for @xmath249 lines . at each cell boundary",
    ", we only update @xmath250 lines , so we need @xmath265 time per cell boundary , @xmath266 in total .",
    "therefore , the total time is @xmath267 , an improvement for @xmath268 .    combining the previous three paragraphs , yields the following result .",
    "the method that works best depends on the relation between @xmath12 , @xmath249 , @xmath250 , and @xmath251 .",
    "[ thm : polyhedral ] algorithm  [ alg : frechetbasic ] computes the frchet distance with a convex polyhedral distance function @xmath22 of complexity @xmath249 in @xmath0 in @xmath269 @xmath270 time , where @xmath255 is the time to find the parts of a distance function .    let us consider the implications for @xmath1 and @xmath2 .",
    "let @xmath224 be the line segment and @xmath134 the point defining @xmath70 $ ] .",
    "for @xmath1 at the breakpoints between the linear parts of @xmath70 $ ] one of the coordinates of @xmath271 is zero : there are at most @xmath272 parts .",
    "the facet of the cross - polytope is determined by the signs of the coordinates . for each linear part",
    "we compute the slope in @xmath233 time , thus @xmath273 .",
    "hence , the hybrid approach outperforms the brute - force approach .",
    "[ col : l1 ] algorithm  [ alg : frechetbasic ] computes the frchet distance with the @xmath1 distance in @xmath0 in + @xmath274 time .    for the @xmath2 distance the facet is determined by the maximum coordinate .",
    "we have @xmath275 .",
    "however a facet depends on only one dimension . hence , for the brute - force method computing the slopes does not take @xmath276 time , but @xmath262 .",
    "thus the brute - force method outperforms the other methods for @xmath2 .",
    "[ col : linf ] algorithm  [ alg : frechetbasic ] computes the frchet distance with the @xmath2 distance in @xmath0 in @xmath277 time .",
    "[ [ approximating - the - euclidean - distance ] ] approximating the euclidean distance + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we can use a polyhedral distance function to approximate the euclidean distance .",
    "a line segment and a point span exactly one single plane in @xmath0 ( unless they are collinear , in which case we pick an arbitrary one ) . on this plane ,",
    "the euclidean unit sphere is a circle ; the same circle for each plane .",
    "we approximate this circle with a @xmath249-regular polygon in @xmath246 that has one side parallel to the line segment .",
    "simple geometry shows that for @xmath278 , we get a @xmath3-approximation .",
    "the computation is two - dimensional , but we must find the appropriate transformations , which takes @xmath233 time per boundary . we no longer need to sort the facets of the polytope for each edge ;",
    "the order is given by the @xmath249-regular polygon .",
    "this saves a logarithmic factor for the initialization .",
    "again , the brute - force method is best , and theorem  [ thm : polyhedral ] gives the following .",
    "[ col : approxeuclid ] algorithm  [ alg : frechetbasic ] computes a @xmath3-approximation of the frchet distance with the euclidean distance in @xmath0 in @xmath279 time .",
    "alternatively we can use corollary  [ col : linf ] to obtain a @xmath280-approximation for the euclidean distance .",
    "if we are willing to invoke an algorithm for the decision version of the frchet distance problem , we can go from a @xmath280-approximation to a @xmath3-approximation by binary search .",
    "we can calculate a @xmath281-approximation of the frchet distance with the euclidean distance in @xmath282 time , where @xmath283 is the time needed to solve the decision problem for the frchet distance .",
    "solving the decision version takes @xmath284 time  @xcite . for @xmath285 , one can do slightly better and solve the decision version in @xmath286 or @xmath287 time , depending on the model of computation  @xcite",
    "* faster euclidean distance . *",
    "the framework presented in this paper computes the frchet distance for polyhedral distance functions in quadratic time , which is faster than the best algorithm for the euclidean distance .",
    "for the euclidean distance we do not achieve this running time , but we conjecture that it is possible to improve our result to an @xmath5 algorithm for this case also .",
    "currently we use the full power of dynamic upper envelopes , which does not seem necessary since all information about the distance terrain functions is available upfront .    we can for instance determine the order in which the parabolas occur on the upper envelopes , in @xmath5 time for all boundaries . from the proof of lemma  [ lem : sqreucl ] , we know that the order is given by the projection of the vertices onto the line .",
    "we compute the arrangement of the lines dual to the vertices of a curve in @xmath5 time .",
    "we then determine the order of the projected points by traversing the zone of a vertical line .",
    "this takes @xmath288 for one row or column .",
    "unfortunately , this alone is insufficient to obtain the quadratic time bound .      a matching between two curves that is a frchet matching for any two matched subcurves",
    "is called a locally correct frchet matching  @xcite .",
    "it enforces a relatively `` tight '' matching , even if the distances are locally much smaller than the frchet distance of the complete curves .",
    "the algorithm in @xcite uses a linear overhead on the algorithm of alt and godau  @xcite resulting in an @xmath289 execution time .",
    "we conjecture that our framework is able to avoid this overhead",
    ". however , the information we currently propagate is insufficient : a large distance early on may `` obscure '' the rest of the computations , making it hard to decide which path would be locally correct ."
  ],
  "abstract_text": [
    "<S> all known algorithms for the frchet distance between curves proceed in two steps : first , they construct an efficient oracle for the decision version ; then they use this oracle to find the optimum among a finite set of critical values . </S>",
    "<S> we present a novel approach that avoids the detour through the decision version . </S>",
    "<S> we demonstrate its strength by presenting a quadratic time algorithm for the frchet distance between polygonal curves in @xmath0 under polyhedral distance functions , including @xmath1 and @xmath2 . </S>",
    "<S> we also get a @xmath3-approximation of the frchet distance under the euclidean metric . for the exact euclidean case </S>",
    "<S> , our framework currently gives an algorithm with running time @xmath4 . </S>",
    "<S> however , we conjecture that it may eventually lead to a faster exact algorithm . </S>"
  ]
}