{
  "article_text": [
    "in recent years , increased resolution in the measurement of the cosmic microwave background ( cmb ) have driven the need for more accurate data analysis techniques . during the early years of cmb experiments ,",
    "data was so sparse and noise levels so high that error bars in general overshadowed the observed signal . with the cobe experiment ,",
    "@xcite posteriors were mapped out by brute force , and the statistical methods employed were simplistic .",
    "this was sufficient , as advanced statistical methods were nt needed for analyzing crude data . however , all this changed with the wilkinson microwave anisotropy probe ( wmap ) experiment @xcite .",
    "suddenly , cosmological data became much more detailed , vastly improving our knowledge of the universe , but also introduced new problems .",
    "which parts of the signal were pure cmb , and which were not ?",
    "the need for knowledge about instrumental noise , point sources , dust emission , synchrotron radiation and other contaminations were required in order to estimate the pure cmb signal from the data . and",
    ", how does one properly deal with the the sky cut , the contamination from our galaxy ? even harder , how does one maximize the probability that the resulting signal really is the correct cmb signal ?",
    "a new era of cosmological statistics emerged .",
    "an important event was the introduction of bayesian statistics in cosmological data analysis .",
    "bayesian statistics differs from the frequentist thought by quantizing ignorance : what one knows and not knows are intrinsic parts of the analysis .",
    "the goal of any bayesian analysis is to go from the prior @xmath0 , or what is known about the model , to the posterior @xmath1 , the probability of a model given data .",
    "this is summarized via bayes famous theorem : @xmath2 the posterior @xmath3 tells us something about how well a model @xmath4 fits the data , and is obtained by multiplying the prior @xmath0 , our assumption of the model , with the likelihood @xmath5 , the probability that the data fits the model .",
    "the need for bayesian statistics becomes evident when considering that we only have data from one single experiment to analyze .",
    "bayesian statistics merges with frequentist statistics for large number of samples . and , in a cosmological context",
    ", we are stuck with only one sample , a sample that we are constantly measuring to higher accuracies .",
    "this sample is one realization of the underlying universe model , and we are unable to obtain data from another sample . in a standard metropolis - hastings ( mh ) monte carlo markov chain - approach ( mcmc ) ,",
    "one samples from the joint distribution by letting chains of `` random walkers '' transverse the parameter space .",
    "the posterior is obtained by calculating the normalized histogram of all the samples in the chains .",
    "the posterior will eventually resemble the underlying joint distribution , or the likelihood surface .",
    "this is a simple and easy - to - understand approach , but not without drawbacks . for one ,",
    "each mh step is required to test the likelihood value of the chain at the current position in parameter space up against a new proposed position .",
    "many of these steps will be rejected , and this is where the computational costs usually reside .",
    "the gibbs sampler provides something new : one never needs to reject samples , and every move becomes accepted and usable for building the posterior .",
    "this is done by assuming that we have prior knowledge of the conditional distributions .",
    "these are then sampled from , each in turn yielding accepted steps .",
    "however , the main motivation for introducing the cmb gibbs sampler is the drastically improvement in scaling . with conventional mcmc methods , one needs to sample from the joint distribution , which results in an @xmath6 operation . for a white noise case ,",
    "the gibbs sampler splits the sampling process into independently sampling from the two conditional distributions , which together yields a @xmath7 operation . in other words",
    ", the gibbs sampler enables sampling the high-@xmath8 regime much more effective than previous mcmc methods .",
    "the problem of estimating the cosmological signal @xmath9 from the full signal by gibbs sampling was first addressed in @xcite , @xcite and @xcite .",
    "the ultimate goal of the gibbs sampler is to estimate the cmb signal @xmath10 from the data @xmath11 , eliminating noise @xmath12 , convolution @xmath13 , all while including the sky cut .",
    "today , a great number of papers have employed the gibbs sampler since the introduction of the method @xcite .    in this paper , we review the basics of the cmb gibbs sampler , and provide a simple , intuitive non - parallelized cmb gibbs software bundle named ` slave ` . `",
    "slave ` is written in c++ , and employs object - oriented design in order to simplify mathematical implementation .",
    "the oop design of ` slave ` is presented in figure [ fig : diagram ] .",
    "for instance , assuming @xmath14 and @xmath15 are instances of the `` real alm '' class ( they contain a set of real @xmath16s ) , operator overloading enables us to directly translate the expression @xmath17 by writing    ....    a = ( b+c).invert ( ) ; ....    this yields fast code that closely resembles equations , without having optimized too much for parallel computing , multiple data sets and other complexities .",
    "one method of likelihood - estimator for obtaining the best - fit power spectrum for masked cmb data is given by the ` master ` algorithm @xcite . while gibbs sampling estimates the full cmb signal @xmath10 , the ` master ` method only estimates the power spectrum .",
    "this method does not allow for variations in the estimated signal , except for the natural variations from simulating different realizations from the same power spectrum . however , the master algorithm estimates the power spectrum with cost scaling as @xmath6 , which is slow for high-@xmath8 operations .",
    "often , people misunderstand the concepts behind the cmb gibbs sampler , and what the gibbs sampler can be used for . in this section , we try to explain in simple terms when you should consider employing the cmb gibbs sampler .",
    "assume that you have a theoretical universe model @xmath18 , where @xmath19 is a set of cosmological parameters .",
    "this model might give rise to some additional gaussian effects in the cmb map , either as fluctuations , altered power , anisotropic contributions , dipoles , ring structures or whatever .",
    "you now wish to test whether existing cmb data contains traces of your fabulous new model , and how significant those traces are .",
    "or maybe you are just interested in ruling out the possibility that this model could be observed at all . in any case",
    ", you need to implement some sort of numerical library that generates cmb maps based on your model .",
    "these maps will be `` pure '' , in the sense that you have complete control over its generation process and systematics .",
    "assume that your model has 1 free parameter .",
    "you could now loop over the 1-dimensional parameter space and calculate the @xmath20 between a pure cmb signal map and the map from your model .",
    "this would have to be done for each step in parameter space , before obtaining the minimum .",
    "even better , you could implement a monte carlo markov chain framework , letting random walkers traverse a likelihood surface , yielding posteriors .",
    "this would enable support for a larger number of parameters , and is superior to the slow brute force approach .",
    "in real - life however , things are not this simple .",
    "data from any cmb experiment is contaminated by noise and foregrounds , most notably our own galaxy .",
    "this means that estimating the signal @xmath10 from the data is not trivial - one needs to `` rebuild '' , or make an assumption of what the fluctuations are within the sky cut and noise limits .",
    "this implies that it really is nt possible to obtain `` the correct '' cmb map , all we can know is that there exist a statistical range of validity where a simulated map agrees with the true cmb signal .",
    "therefore , the consideration that that the estimated cmb signal @xmath10 is a statistical random variable and not a fixed map should be included in the analysis .",
    "hence , if you have implemented the ` master ` method mentioned in section [ sec : master ] , you should test your model map against a set of realizations from the ` master`-estimated signal power spectrum .",
    "this is where the gibbs sampler enters the stage .",
    "as previously mentioned , the gibbs sampler will estimate the cmb signal given data , and not only the power spectrum .",
    "the gibbs sampler also ensures that every step in parameter space is always valid , so one never needs to discard samples . and even better ,",
    "each of these independent steps provide an operation cost for obtaining samples that are much lower than more conventional mcmc methods . in order to test whether your model @xmath21 fits the data ,",
    "you therefore include the uncertainty in data by varying the signal .",
    "for example :    .... initialize cl do    s = the cmb signal given the          power spectrum cl    m = the cmb signal of your model given          the estimated cmb signal s     cl = the cmb power spectrum given m    save s , m and cl repeat until convergence ....    in the end , you calculate the statistical properties of s , m and cl .",
    "your model parameters have now been estimated , and the process included the intrinsic uncertainties in the signal .",
    "this method is not the most rapid - but it will always yield correct results .",
    "throughout this paper , we assume that the data can be expressed as @xmath22 where @xmath10 is the cmb signal , @xmath13 the instrument beam and @xmath12 uncorrelated noise .",
    "the ` master ` algorithm estimates the the power spectrum @xmath23 and the standard deviation @xmath24 .",
    "however , this method is a approximation to a full likelihood that can be expressed as follows : @xmath25 where @xmath26 and @xmath27 are the signal and noise covariance matrices , respectively .",
    "while it is fully possible to use mcmc - methods to sample from this distribution , the calculation of the @xmath28-matrix scales as @xmath29 , where @xmath12 is the size of the @xmath30 matrix .",
    "this is therefore an extremely slow operation , and is not feasible for large @xmath8s .",
    "if we demand that we sample the sky signal @xmath10 as well , the joint distribution becomes @xmath31 .",
    "this might seem unnecessary complicated , as one most of the time does nt need the signal @xmath10 .",
    "but when feeding this distribution through the gibbs sampler - that is , calculating the conditional distributions @xmath32 and @xmath33 , we find that sampling from both are computationally faster than sampling from the full distribution in equation [ eq : fulldist ] .",
    "the derivations of the conditional distributions are presented in section [ sec : methods ] .",
    "the gibbs sampler is a special case of the metropolis - hastings algorithm .",
    "we therefore review the basics of monte carlo markov ( mcmc ) chain methods .",
    "the metropolis - hastings algorithm is a mcmc method for sampling directly from a probability distribution .",
    "this is done by letting `` random walkers '' transverse a parameter space , guided by the likelihood function , the probability that the data fits the model for the given parameter configuration .",
    "if a proposal step yields a likelihood greater than the current likelihood , then random walker accepts the step immediately .",
    "if the likelihood is less , then the walker will with a certain probability step `` down '' the likelihood surface . eventually , the histogram of all the random walkers will converge to the posterior , the full underlying distribution .",
    "assume you have a model with @xmath12 parameters , @xmath34 and you wish to map out a joint distribution from @xmath0 .",
    "usually , one calculates the ratio @xmath35 between the posteriors at the two steps @xmath36 and @xmath37 , such that @xmath38 where @xmath39 is the proposal distribution for going left or right . if the proposal distribution is symmetric ( i.e. the probability of going left - right is equal for all @xmath40 ) , then @xmath41 such that : @xmath42 the mh acceptance rule now states : if @xmath35 is larger than 1 , accepted the step unconditionally . if @xmath43 , then accept the step if a random uniform variable @xmath44 .",
    "assume you have a model with two parameters , @xmath45 and @xmath46 , and you wish to map out a joint distribution from @xmath47 .",
    "now , also presume that you have prior knowledge of the conditional distributions , @xmath48 and @xmath49 .",
    "a general proposal density is not necessary symmetric , and one must therefore consider the asymmetric proposal term as described in equation [ eq : asymmprop ] .",
    "however , we now define the proposal density @xmath50 for @xmath46 to be the conditional distributions : @xmath51 in words , the proposal is only considered when @xmath52 , which means that @xmath45 is fixed while @xmath46 can vary . if so , the acceptance is then given as the conditional distribution @xmath53 , which we must have prior knowledge of .",
    "the reason for choosing such a proposal density becomes clear when investigating the metropolis hastings acceptance rate : @xmath54 using the conditional sampling proposal ( [ eq : prop ] ) one obtains @xmath55 we now enforce the delta - function such that @xmath56 . this sampling from the conditional distributions",
    "is the crucial step in the gibbs sampler , such that all terms cancel out : @xmath57 this implies that all steps are valid , and none are ever rejected .",
    "hence one alternates between sampling from the known conditional distributions , where each step is independently accepted and can be performed as many times as needed .    [ sampling ]",
    "in section [ sec : method_gibbs ] , it was explained how the gibbs sampler requires previous knowledge about the underlying conditional distributions .",
    "the cmb gibbs sampler will alternate between sampling power spectra @xmath58 and cmb signal @xmath10 , where each proposed step will always be valid . in order to enable sampling from the joint distribution ,",
    "we therefore need to derive the analytical properties of the conditional distributions : @xmath59 the derivations described here were first presented in @xcite , @xcite and @xcite.the full , joint distribution is expressed as @xmath60 where @xmath61 is a prior on @xmath58 , typically chosen to be flat .",
    "the first term , @xmath62 , is nothing but the @xmath20 .",
    "the @xmath20 measures the goodness - of - fit between model and data , leaving only fluctuations in noise . as @xmath63 is distributed accordingly to a gaussian with mean 0 and variance @xmath27 , we find that @xmath64    as we now assume that the signal @xmath10 is known and fixed , the data @xmath11 becomes redundant and @xmath65 .",
    "we therefore first need to obtain an expression for @xmath66 .",
    "assuming that the cmb map consists of gaussian fluctuations , we can express the conditional probability density for a power spectrum @xmath58 given a sky signal @xmath10 as follows : @xmath67 where @xmath68 is the covariance matrix .",
    "we now perform a transformation to spherical harmonics space , where @xmath69 and @xmath70",
    ". then equation ( [ eq : pscl ] ) transforms to @xmath71 as the spherical harmonics are orthogonal , they all cancel out and leave delta functions for @xmath72 such that @xmath73 we now define a power spectrum @xmath74 such that @xmath75    similarly , the determinant is given as the product of the diagonal matrix @xmath15 , which for each @xmath76 has @xmath77 values of @xmath58 .",
    "the determinant is thus @xmath78 .",
    "expression ( [ eq : pscl ] ) can now be written as @xmath79 which by definition means that the @xmath80 s are distributed as an inverse gamma function . in the computational section",
    ", we will discuss how to draw random variables from this distribution .",
    "again , we begin with the full , joint distribution : @xmath81 we now know from equation [ eq : invgamma ] and [ eq : chisq ] that the joint distribution can be expressed as @xmath82 omitting the prior @xmath61 . again",
    ", note that it would be nearly impossible to sample directly from the full distribution .",
    "we now investigate what happens with equation [ eq : fullpost ] when @xmath58 becomes a fixed quantity .",
    "as the @xmath58s in the denominator vanishes , we use equation [ eq : pscl ] to obtain @xmath83    we now introduce a residual variable @xmath84 , such that @xmath85 roughly consist of noise . as noise",
    "was uncorrelated , we can expect that @xmath85 follows a gaussian distribution with zero mean and @xmath27 variance . also , if @xmath10 is known , then @xmath58 is redundant .",
    "we complete the square , and introduce @xmath86 .",
    "equation ( [ eq : scldbefore ] ) can now be rewritten as @xmath87 hence @xmath33 is a gaussian distribution with mean @xmath88 and covariance @xmath89 . in the computational section",
    ", we will discuss how to draw random variables from this distribution .",
    "in its utter simplicity , the mechanics of the gibbs sampler can be summarized as follows :    ....   load data   initialize s and cl   loop number of chains     s = generate from p(s | cl , d )     cl = generate from p(cl | s , d )     save s and cl   end loop ....",
    "we now present the computational methods for drawing from @xmath90 and @xmath91 .",
    "we show that equation [ eq : invgamma ] is an inverse gamma distribution .",
    "a general gamma - distribution is proportional to @xmath92 equation [ eq : invgamma ] can be expressed as @xmath93 where @xmath94 .",
    "if we now perform a substitution @xmath95 , we see that @xmath96 where the last term is the jacobian .",
    "hence @xmath97 which is a gamma - distribution for @xmath98 .",
    "we now show that this particular distribution also happens to be a special case of the @xmath20 distribution : @xmath99 letting @xmath100 and ignoring the constants , we find that @xmath101 such that if @xmath102 , @xmath103 is distributed according to a @xmath20 distribution with @xmath104 degrees of freedom . a random variable following such",
    "a distribution can be drawn as follows : @xmath105 where @xmath106 are random gaussian variables with mean @xmath107 and variance @xmath108 . since @xmath109 , we find that @xmath110 numerically , one can implement this as    ....   for each l    z = 0    for i=0 to 2l-1      z = z+ rand_gauss()^2    end    c(l ) = ( 2l+1)*sigma(l)/z end ....    an example of this method can be found in the ` slave ` libraries , within class `` powerspectrum '' method `` draw_gamma '' .      from equation [ eq : scomplete ] ,",
    "it is easy to see that @xmath90 is a gaussian distribution with mean @xmath88 and variance @xmath89 . instead of deriving a method for drawing a random variable from this distribution",
    ", we present the solution and show that this solution indeed has the necessary properties @xcite .",
    "let @xmath111 where @xmath112 and @xmath113 are independent , random @xmath114 variables .",
    "we now show that the random variable @xmath10 indeed has mean @xmath88 and variance @xmath115 .",
    "first , @xmath116 as @xmath117 , @xmath118 by definition .",
    "the covariance is then @xmath119 note that in the term @xmath120 , we have @xmath121 , so we are only left with the terms with the random variables @xmath122 : @xmath123 but , as @xmath112 and @xmath113 are independently drawn from a @xmath114 distribution , then @xmath124 , and we end up with @xmath125 which shows that a random variable drawn using equation [ eq : draws ] has the desired properties of being drawn from @xmath126 .",
    "having implemented a `` real alm '' class in ` slave ` with operator overloading , it is possible to directly translate equation [ eq : draws ] into code :    ....    omega1.gaussian_draw(0 , 1 , rng ) ;    omega2.gaussian_draw(0 , 1 , rng ) ;    calculate_cni ( ) ;    s = cni * ( ni*d + ni.square_root()*omega1        + ci.square_root()*omega2 ) ; ....    where the code has been slightly optimized : both @xmath127 , @xmath128 and @xmath89 has been pre - calculated for efficiency . note that this is only possible to do when assuming full - sky coverage with constant rms noise .",
    "if the noise is nt constant on the sky , then @xmath27 is a dense off - diagonal matrix , nearly impossible to calculate directly for large @xmath8 .",
    "however , it is still possible to perform the calculation in pixel space , but this requires that we assume @xmath27 to be an operator instead of a matrix",
    ". we will address this issue in section [ sec : skycut ] .",
    "we have now presented the main simplified gibbs - steps for calculating @xmath126 and @xmath66 , without convolution , uniform noise and no sky cut . sampling from these two distributions",
    "is then done alternating between the two gibbs steps , and the chain output - @xmath10 and @xmath58 - are saved to disk during each step .",
    "we now investigate the behavior of these fields , as each have special properties .",
    "equation [ eq : draws ] can be broken into two separate parts : the wiener filter @xmath129 and the fluctuation map @xmath130 . in figure",
    "[ fig : wiener ] , each of these maps are depicted .",
    "the wiener filter map determines the fluctuations outside the sky cut - where they are heavily constrained by the known data , given cosmic variance and noise .",
    "however , within the sky cut , large - scale fluctuations are possible to pin down statistically while small - scales are repressed .",
    "the fluctuation map determines the small - scale fluctuations within the unknown sky cut , and are constrained by cosmic variance and noise effects . outside the sky cut , the fluctuation map is constrained by the data , yielding very low small - scale fluctuations .",
    "the sum of these two parts make up the full cmb signal sample .      when the signal is being sampled , it is vital to check that the input parameters / data maps are correctly set up .",
    "for instance , if you use ` slave ` to start a large job , say , estimating the cmb signal @xmath10 for a @xmath131 map , it can be very frustrating when realizing that one of the input parameters were incorrect , for instance beam convolution or noise rms",
    ". the software will continue to run without errors , but the resulting output files will be incorrect .",
    "we therefore adopt a simple and useful method for verifying that the estimated cmb signal @xmath10 for each gibbs step really is close to what one would expect .",
    "the trick lies with the noise . as @xmath132 , then @xmath133 .",
    "uniform white noise is assumed to be @xmath134-distributed , so @xmath135 a @xmath20 distribution is nothing but a sum of squared gaussian distributions .",
    "hence @xmath136 and the @xmath20 should be close to the number of pixels in the map plus minus @xmath137 . usually , when an incorrect parameter is used , the @xmath20 comes out far away from the expected value .",
    "calculating the @xmath20 is not particularly time - consuming , but it has other uses as well : the @xmath20 is used in the estimation of noise , as presented in section [ sec : noiseestimation ] .",
    "a thing we did not address in the previous section was the inclusion of the instrumental beam convolution @xmath13 .",
    "including this in equation [ eq : draws ] , we obtain @xmath138 in ` slave ` , the beam is loaded directly from a fits file , or generated as a gaussian beam given a full width half - maximum ( fwhm ) range . the beam is then multiplied with the corresponding pixel window , and stored in the @xmath16-object @xmath13 throughout the code .      until now",
    ", we have only assumed full - sky data sets contaminated by constant noise .",
    "however , in order to be able to investigate real data , we need to take into account both the foreground galaxy and anisotropic noise .",
    "the galaxy contributes to almost 20% of the wmap data , and needs to be removed with a mask .",
    "this means that the usable pars of the maps becomes anisotropic , giving rise to correlations in the spherical harmonics @xmath16s .",
    "in other words , all the previously diagonal and well - behaved matrices now have off - diagonal elements , which for large @xmath139 is an impossible feat to perform for dense matrices .",
    "one way to get around these problems is to perform the calculations containing the sky cut mask in pixel space .",
    "this means that every time one needs to take into account the sky cut , one transforms from harmonic to pixel space , performs the operation including the sky cut before transforming back to harmonic space .",
    "while this operation in itself is trivial , equation [ eq : draws ] provides a few other problems : @xmath140 the right - hand side can easily be calculated , letting @xmath128 be an operator acting on @xmath11 and @xmath112 , switching from spherical harmonics to pixel space and back . however , the left - hand side is troublesome - one can not solve this equation explicitly .",
    "first , we need to rewrite [ eq : draws2 ] a bit : @xmath141 the first thing one should note about equation [ eq : draws3 ] is that the left - hand term is proportional to @xmath142 , where the diagonal parts are just the signal - to - noise ratios of the corresponding mode .",
    "another nice feature about this form is that the variance of the signal is kept constant , that is , @xmath143 , but @xmath144 .",
    "hence we obtain better numerical stability . in order to solve the equation @xmath145",
    ", we implement a direct - from - textbook conjugate gradient ( cg ) algorithm presented on page 40 in @xcite .",
    "the code looks like this :    ....    b = l * ( a*ni(d ) + a*ni(map_work2,true ) ) + omega2 ;    mi = setup_preconditioner ( ) ;    x = mult_by_a(x ) ;    r =   b - x ;    d = mi*r ;    r0 = r.norm_l1(r ) ;    do {      ad = mult_by_a(d ) ;      alpha = r.dot(mi*r ) / ( d.dot(ad ) ) ;      x = x + d*alpha ;      rn = r - ad*alpha ;      beta = rn.dot(mi*rn ) / ( r.dot(mi*r ) ) ;      d = mi * rn + d*beta ;      r = rn ;      norm = r.norm_l1(r ) ;    }     while ( norm > r0*epsilon ) ;    s = l*x ; ....",
    "c++ enables the cg algorithm to be translated almost directly from mathematical syntax to code . here ,",
    "the sky cut mask is taken into account in the @xmath146-method - one only needs the mask when multiplying with the inverse noise matrix .",
    "the only other `` initial condition '' is the preconditioner .",
    "the preconditioner can not affect the result , that is , it has nothing to do with the estimated signal @xmath10 .",
    "the preconditioner only affects the number of iterations needed for the equation @xmath147 to be solved , and corresponds to a `` best guess '' of @xmath13 . without going into details , the standard preconditioner in ` slave ` is proportional to @xmath148 , but there exists many other suggestions for better pre - conditioners , yielding quicker convergence .",
    "see @xcite or @xcite for more examples .",
    "when the cg search has completed , the signal @xmath26 has been obtained , including the sky cut and anisotropic noise .",
    "a final thing we need to take into account is the low signal - to - noise regime .",
    "when the noise starts dominating the signal , the estimated @xmath10 will fluctuate wildly on small scales .",
    "in addition , the deconvolution will add to this effect , blowing up noise to extreme values . in itself",
    ", this is nt a bad thing as we really can not say exactly what is going in this regime , but it will affect the overall correlations between chains . in order to reduce this effect , we present a simple way to bin multipoles together on large l , reducing noise variance .",
    "let @xmath149 be the noise rms in harmonic space .",
    "the variance is then given as @xmath150 for a single binned set with @xmath12 multipoles ranging from @xmath151 to @xmath152 , the average value of the power spectrum is given as @xmath153 similarly for the noise power spectrum , @xmath154 thus , the variance of the noise is given as @xmath155 obviously , @xmath156 is reduced as the number of multipoles in the bin @xmath12 is increased .",
    "we now select bins such that the noise variance in a single bin is always less than three times the value of the angular power spectrum , or @xmath157 .",
    "the only affected part of the code is where one determines @xmath158 .",
    "instead of generating a power spectrum @xmath58 given a set of @xmath159 , the calculation is now performed via a binning class that calculates the binned power spectrum @xmath160 .",
    "that is , @xmath161 absorbing the product into the exponential , this becomes @xmath162 we now sample the signal with flat bins in @xmath163 , not in @xmath8 .",
    "in this section , we give a direct example of how one could extend the data model to the ` slave ` gibbs sampler .",
    "we derive the necessary conditional distribution , explain how this was integrated , and present some results from @xcite , where a full analysis of the noise levels in the wmap data was performed using the ` slave ` framework .",
    "traditionally , the noise properties used in the gibbs sampler ( e.g. , * ? ? ?",
    "* ) have been assumed known to infinite precision . in this section , however , we relax this assumption , and introduce a new free parameter , @xmath164 , that scales the fiducial noise covariance matrix , @xmath165 , such that @xmath166 . thus ,",
    "if there is no deviation between the assumed and real noise levels , then @xmath164 should equal 1 .",
    "the full analysis of the 5-yr wmap data was presented in @xcite , with interesting results . for the foreground - reduced 5-year wmap sky maps ,",
    "we find that the posterior means typically range between @xmath167 and @xmath168 depending on differencing assembly , indicating that the noise level of these maps are underestimated by 0.5 - 1.0% .",
    "the same problem is not observed for the uncorrected wmap sky maps .",
    "the full joint posterior , @xmath169 , now includes the amplitude @xmath164 .",
    "we can rewrite this as follows : @xmath170 where the first term is the likelihood , @xmath171 the second term is a cmb prior , and the third term is a prior on @xmath164 .",
    "note that the latter two are independent , given that these describe two a - priori independent objects . in this paper",
    ", we adopt a gaussian prior centered on unity on @xmath164 , @xmath172 .",
    "typically , we choose a very loose prior , such that the posterior is completely data - driven .",
    "the conditional distribution for @xmath164 can now be expressed as @xmath173 where @xmath174 and @xmath175 is the @xmath20 .",
    "( note that the @xmath20 is already calculated within the gibbs sampler , as it is used to validate that the input noise maps and beams are within a correct range for each gibbs iteration .",
    "sampling from this distribution within the gibbs sampler represent therefore a completely negligible extra computational cost . ) for the gaussian prior with unity mean and standard deviation @xmath176 , we find that @xmath177    for large degrees of freedom , @xmath12 , the inverse gamma function converges to a gaussian distribution with mean @xmath178 , where we have defined @xmath179 , and variance @xmath180 .",
    "a good approximation is therefore letting @xmath181 be drawn from a product of two gaussian distributions , which itself is a gaussian , with mean and standard deviation @xmath182",
    "@xmath183    this sampling step has been implemented in ` slave ` and we have successfully tested it on simulated maps . with @xmath184 and @xmath185 and full sky coverage ,",
    "we find @xmath186 .",
    "the chains for the noise amplitude @xmath164 are shown in figure [ fig : alpha_simulated ] .",
    "note that with such high resolution , the standard deviation on @xmath164 is extremely low , and any deviation from the exact @xmath187 will be detected .",
    "in this section , we quickly review how to use ` slave ` . for a more detailed usage",
    ", please see the ` slave ` documentation ( when the framework will be released ) .    `",
    "slave ` requires the ` healpix ` @xcite cxx - libraries installed",
    ". please see the ` healpix ` documentation on this topic . `",
    "slave ` is run command - line , and requires a parameter file as command - line parameter .",
    "the most important options in the parameter file are listed in table [ tab : main ] .",
    "lll ` seed ` & int & initial random seed + ` verbosity ` & int & text output level ( 0=none ) + ` healpix_dir ` & string & healpix home directory + ` output_sigmas ` & bool & output @xmath188 or not + ` output_cls ` & bool & output @xmath58s or not + ` output_directory ` & string & output file directory + ` output_chisq ` & bool & output the @xmath20 or not + ` output_beam ` & bool & output the beam or not + ` output_beam_file ` & string & beam output filename + ` method ` & string & analysis type : brute force_fullsky or cg ( normal ) + ` cg_convergence ` & double & cg convergence criteria ( type @xmath189 ) + ` preconditioner ` & string & pre - conditioner type : none , static or 3j + ` init_powerspectrum_power ` & double & initialized flat power spectrum value + ` init_powerspectrum_use_file ` & bool & use file instead of flat power spectrum + ` init_powerspectrum_file ` & string & initial power spectrum file + ` samples ` & int & number of gibbs samples to produce + ` burnin ` & int & number of burn - in samples to reject + ` datasets ` & int & number of data sets ( only 1 allowed yet .. ) + ` data_nsiden ` & int & @xmath190 for data set @xmath191 + ` data_mapn ` & string & fits map for data set @xmath191 + ` data_rmsn ` & string & fits rms map for data set @xmath191 + ` data_maskn ` & string & fits mask for data set @xmath191 + ` beam_filen ` & string & fits beam for data set @xmath191 + ` lmax ` & int & @xmath139 for the analysis + ` constant_rms ` & bool & use constant rms or not + ` constant_rms_value ` & double & value of constant rms + ` gaussian_beam ` & bool & use a gaussian beam or not + ` gaussian_beam_fwhm ` & double & value of gaussian beam + ` enable_noise_amplitude_sampling ` & bool & enable noise estimation or not + ` noise_sampling_sigma ` & double & the noise prior sigma + ` noise_amplitude_filename ` & string & output noise filename + ` noise_alpha_init_val ` & double & initial value for @xmath164 + ` use_binning ` & bool & enable binning of power spectrum + ` binning_powerspectrum ` & string & power spectrum used for binning + ` bins_filename ` & string & text output the bins      after the gibbs sampler has been cooking for a while , it is time to investigate the results .",
    "the main output of ` slave ` are the estimated power spectra @xmath58 s and the signals @xmath10 .",
    "however , as the signal is assumed to be statistically isotropic , we instead output the signal power spectra @xmath188 defined as : @xmath192 the text - files may be plotted directly through software such as ` xmgrace ` , as presented in figure [ fig : result_cls ] .",
    "in addition , ` slave ` outputs the @xmath188 s as a binary file for each chain",
    ". these binary files can be combined through the main post - processing software utility for ` slave ` called ` slave_process ` .",
    "this software will combine the binary chains into a single file , in addition to removing burn - in samples . to combine the sigmas into one file , type    ....",
    "slave_process 1 [ no_chains ] [ no_samples ]                    [ burnin ] [ output sigma_l file ] ....      the first important step is to verify that the output @xmath58s follow the desired inverse - gamma distribution for low @xmath8 , but converges to gaussians for larger @xmath8 .",
    "the ` slave ` processing utility ` slave_process ` can generate a set of @xmath58s from the @xmath188s and output the corresponding values for a single @xmath8 .",
    "it is then straight - forward to use a graphical utility such as ` xmgrace ` to obtain the histogram .",
    "such histograms are plotted together with the analytical likelihoods in figure [ fig : br_likelihoods ] .",
    "note the good match between the histogram of the @xmath58s and the likelihoods obtained from the blackwell - rao estimator .",
    "the analysis for producing these plots was performed on simulated high - detail data , in order to verify the validity of the br - estimator .    to save the cls for a specific @xmath8 , type    ....",
    "./process 4 [ sigma_l file ] [ l ] [ generate no cls ]                [ output textfile ]   ....      our primary objective is obtaining the best - fit power spectrum from the estimated signal power spectra .",
    "if the @xmath58s were completely distributed according to a gaussian , one would only need to select the maximum of the distribution for each @xmath58 .",
    "however , as we saw in equation [ eq : invgamma ] , this is not the case , and we need a better way to obtain the likelihood @xmath193 for each @xmath8 .",
    "luckily , we can obtain an analytical expression of the likelihood for the @xmath58s via the blackwell - rao ( br ) estimator , as presented in @xcite . by using prior knowledge of the distributions of the @xmath58s",
    ", we can build an analytical expression for the distribution for each @xmath58 given the signal power spectrum @xmath188 , or @xmath194 .",
    "note that since the power spectrum only depends on the data through the signal and thus @xmath188 , then @xmath195 it is therefore possible to approximate the distribution @xmath196 where @xmath197 is the number of gibbs samples in the chain .",
    "this method of estimating the @xmath198 is called the blackwell - rao estimator .",
    "now , for a gaussian field ,    @xmath199    taking the logarithm , we obtain a nice expression @xmath200 - \\textrm{ln } \\sigma_l \\big)\\ ] ] which is straight - forward to implement numerically . to output the br - estimated likelihood for one @xmath8 , type    ....",
    "./process 3 [ sigma_l file ] [ l ]                [ output likelihood ] ....      the best - fit br - estimated power spectrum is obtained by choosing the maximum likelihood value of @xmath58 for each @xmath8 . to do so , type    ....   ./process 2 [ sigma_l file ]                [ output power spectrum file ] ....",
    "an example of a br - estimated power spectrum can be seen in figure [ fig : br_powerspectrum ] .",
    "in addition , both the input - and noise power spectra are shown .",
    "note how the br - estimated power spectrum is exact on small scales ( low @xmath8 ) , while the convolution and noise dominated on higher scales .",
    "we have presented a self - contained guide to a cmb gibbs sampler , having focused on both deriving the conditional probability distributions and code design .",
    "we described in detail how one can draw samples from the conditional distributions , and saw how the gibbs sampler is numerically superior to conventional mcmc methods , scaling as @xmath7 .",
    "we have also introduced a new object - oriented cmb gibbs framework , which employs the existing ` healpix ` @xcite c++ package .",
    "we presented a small guide to the usage of ` slave ` , including post - processing tools and the blackwell - rao estimator for obtaining the likelihoods and the best - fit power spectrum .",
    "we also reviewed a new way of estimating noise levels in cmb maps , as presented in @xcite .",
    "the software package ` slave ` will hopefully be released when it is completed during 2009 , and will run on all operating systems supporting the gnu c++ compiler .",
    "please see ` http://www.irio.co.uk ` for release details and information .",
    "nicolaas e. groeneboom acknowledges financial support from the research council of norway .",
    "nicolaas especially wishes to thank hans kristian eriksen , but also jeffrey jewell , kris gorski , benjamin wandelt and the whole `` gibbs team '' at jet propulsion laboratories ( jpl ) for useful discussions , comments and input .",
    "the computations presented in this paper were carried out on titan , a cluster owned and maintained by the university of oslo and notur .",
    "we acknowledge use of the ` healpix ` software @xcite and analysis package for deriving the results in this paper .",
    "we acknowledge the use of the legacy archive for microwave background data analysis ( lambda ) .",
    "support for lambda is provided by the nasa office of space science ."
  ],
  "abstract_text": [
    "<S> we present a consistent self - contained and pedagogical review of the cmb gibbs sampler , focusing on computational methods and code design . </S>",
    "<S> we provide an easy - to - use cmb gibbs sampler named ` slave ` developed in c++ using object - oriented design . </S>",
    "<S> while discussing why the need for a gibbs sampler is evident and what the gibbs sampler can be used for in a cosmological context , we review in detail the analytical expressions for the conditional probability densities and discuss the problems of galactic foreground removal and anisotropic noise . having demonstrated that ` slave ` is a working , usable cmb gibbs sampler , we present the algorithm for white noise level estimation . </S>",
    "<S> we then give a short guide on operating ` slave ` before introducing the post - processing utilities for obtaining the best - fit power spectrum using the blackwell - rao estimator . </S>"
  ]
}