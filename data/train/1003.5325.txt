{
  "article_text": [
    "we report our analysis of the web traffic of approximately one thousand residential users over a two - month period .",
    "this data set preserves the distinctions between individual users , making possible detailed per - user analysis .",
    "we believe this is the largest study to date to examine the complete click streams of so many users in their place of residence for an extended period of time , allowing us to observe how actual users navigate a hyperlinked information space while not under direct observation .",
    "the first contributions of this work include the discoveries that the popularity of web sites as measured by distinct visitors is unbounded ; that many of the power - law distributions previously observed in web traffic are aggregates of log - normal distributions at the user level ; and that there exist two populations of users who are distinguished by whether or not their web activity is largely mediated by portal sites .",
    "a second set of contributions concerns our analysis of browsing sessions within the click streams of individual users .",
    "the concept of a web session is critical to modeling real - world navigation of hypertext , understanding the impact of search engines , developing techniques to identify automated navigation and retrieval , and creating means of anonymizing ( and de - anonymizing ) user activity on the web .",
    "we show that a simple timeout - based approach is inadequate for identifying sessions and present an algorithm for segmenting a click stream into _ logical sessions _ based on referrer information .",
    "we use the properties of these logical sessions to show that actual users navigate hypertext in ways that violate a stateless random surfer model and require the addition of backtracking or branching .",
    "finally , we emphasize which aspects of this data present possible opportunities for anomaly detection in web traffic .",
    "robust anomaly detection using these properties makes it possible to uncover `` bots '' masquerading as legitimate user agents .",
    "it may also undermine the effectiveness of anonymization tools , making it necessary to obscure additional properties of a user s web surfing to avoid betraying their identity .",
    "in the remainder of this paper , after some background and related work , we describe the source and collection procedures of our web traffic data .",
    "the raw data set includes over 400 million http requests generated by over a thousand residential users over the course of two months , and we believe it to provide the most accurate picture to date of the hypertext browsing behavior of individual users as observed directly from the network .",
    "our main contributions are organized into three sections :    * we confirm earlier findings of scale - free distributions for various per - site traffic properties aggregated across users .",
    "we show this also holds for site popularity as measured by the number of unique vistors .",
    "(   [ section - host ] ) * we offer the first characterization of individual traffic patterns involving continuous collection from a large population .",
    "we find that properties such as jump frequency , browsing rates , and the use of portals are not scale - free , but rather log - normally distributed .",
    "only when aggregated across users do these properties exhibit scale - free behavior .",
    "(   [ section - user ] ) * we investigate the notion of a web `` session , '' showing that neither a simple timeout nor a rolling average provide a robust definition .",
    "we propose an alternative notion of _ logical _ session and provide an algorithm for its construction . while logical sessions have no inherent temporal scale , they are amenable to the addition of a timeout with little net effect on their statistical properties .",
    "(   [ section - session ] )    we conclude with a discussion of the limitations of our data , the implications of this work for modeling and anomaly detection , and potential future work in the area .",
    "internet researchers have been quick to recognize that structural analysis of the web becomes far more useful when combined with actual _ behavioral _ data .",
    "the link structure of the web can differ greatly from the set of paths that are actually navigated , and it tells us little about the behavior of individual users .",
    "a variety of behavioral data sources exist that can allow researchers to identify these paths and improve web models accordingly .",
    "the earliest efforts have used browser logs to characterize user navigation patterns  @xcite , time spent on pages , bookmark usage , page revisit frequencies , and overlap among user paths  @xcite .",
    "the most direct source of behavioral data comes from the logs of web servers , which have been used for applications such as personalization  @xcite and improving caching behavior  @xcite .",
    "more recent efforts involving server logs have met with notable success in describing typical user behavior  @xcite . because search engines serve a central role in users navigation , their log data is particularly useful in improving search results based on user behavior  @xcite .",
    "other researchers have turned to the internet itself as a source of data on web behavior .",
    "network flow data generated by routers , which incorporates high - level details of internet connections without revealing the contents of individual packets , has been used to identify statistical properties of web user behavior and discriminate peer - to - peer traffic from genuine web activity  @xcite .",
    "the most detailed source of behavioral data consists of actual web traffic captured from a running network , as we do here .",
    "the present study most closely relates to the work of qiu _ et al . _",
    "@xcite , who used captured http packet traces to investigate a variety of statistical properties of users browsing behavior , especially the extent on which they appear to rely on search engines in their navigation of the web .",
    "we have also used captured http requests in our previous work to describe ways in which pagerank s random - surfer model fails to approximate actual user behavior , which calls into question its use for ranking search results  @xcite .",
    "one way of overcoming these shortcomings is to substitute actual traffic data for ranking pages  @xcite .",
    "however , this may create a feedback cycle in which traffic grows super - linearly with popularity , leading to a situation ( sometimes called `` googlearchy '' ) in which a few popular sites dominate the web and lesser known sites are difficult to discover  @xcite .",
    "more importantly for the present work , simply accepting traffic data as a given does not further our understanding of user behavior .",
    "we can also overcome the deficiencies of the random - surfer model by improving the model itself . this paper offers analysis of key features of observed behavior to support the development of improved agent - based models of web traffic  @xcite",
    ".    the present study also relates to work in anomaly detection and anonymization software for the web .",
    "the web tap project , for example , attempted to discover anomalous traffic requests using metrics such as request regularity and interrequest delay time , quantities which we discuss in the present work  @xcite .",
    "the success of systems that aim to preserve the anonymity of web users is known to be dependent on a variety of empirical properties of behavioral data , some of which we directly address here  @xcite .",
    "the click data we use in this study was gathered from a dedicated freebsd server located in the central routing facility of the bloomington campus of indiana university ( figure  [ fig : architecture ] ) .",
    "this system had a 1  gbps ethernet port that received a mirror of all outbound network traffic from one of the undergraduate dormitories .",
    "this dormitory consists of four wings of five floors each and is home to just over a thousand undergraduates .",
    "its population is split roughly evenly between men and women , and its location causes it to have a somewhat greater proportion of music and education students than other campus housing .        to obtain information on individual http requests passing over this interface",
    ", we first use a berkeley packet filter to capture only packets destined for tcp port 80 . while this eliminates from consideration all web traffic running on non - standard ports",
    ", it does give us access to the great majority of it .",
    "we make no attempt to capture or analyze encrypted ( https ) traffic using tcp port 443 .",
    "once we have obtained a packet destined for port 80 , we use a regular expression search against the payload of the packet to determine whether it contains an http get request .    if we do find an http get request in the packet",
    ", we analyze the packet further to determine the virtual host contacted , the path requested , the referring url , and the advertised identity of the user agent .",
    "we then write a record to our raw data files that contains the mac address of the client system , a timestamp , the virtual host , the path requested , the referring url , and a flag indicating whether the user agent matches a mainstream browser ( internet explorer , mozilla / firefox , safari , or opera ) .",
    "we maintain record of the mac address only in order to distinguish the traffic of individual users .",
    "we thus assume that most computers in the building have a single primary user , which is reasonable in light of the connectedness of the student population ( only a small number of public workstations are available in the dormitory ) . furthermore",
    ", as long as the users do not replace the network interface in their computer , this information remains constant .",
    "the aggregate traffic of the dormitory was sufficiently low so that our sniffing system could maintain a full rate of collection without dropping packets .",
    "while our collection system offers a rare opportunity to capture the complete browsing activity of a large user population , we do recognize some potential disadvantages of our data source . because we do not perform tcp stream reassembly",
    ", we can only analyze http requests that fit in a single 1,500 byte ethernet frame . while the vast majority of requests do so , some get - based web services generate extremely long urls . without stream",
    "reassembly , we can not log the web server s response to each request : some requests will result in redirections or server errors , and we are unable to determine which ones . finally , a user can spoof the http referrer field ; we assume that few students do so , and those who do generate a small portion of the overall traffic .",
    "the click data was collected over a period of about two months , from march 5 , 2008 through may 3 , 2008 .",
    "this period included a week - long vacation during which no students were present in the building . during the full data collection period",
    ", we logged nearly 408 million http requests from a total of 1,083 unique mac addresses .",
    "not every http request from a client is indicative of an actual human being trying to fetch a web page ; in fact , such requests actually constitute a minority of all http requests . for this reason ,",
    "we retain only those urls that are likely to be requests for actual web pages , as opposed to media files , style sheets , javascript code , images , and so forth .",
    "this determination is based on the extension of the url requested , which is imprecise but functions well as a heuristic in the absence of access to the http _ content - type _ header in the server responses .",
    "we also filtered out a small subset of users with negligible activity ; their traffic consisted largely of automated windows update requests and did not provide meaningful data about user activity .",
    "finally , we also discovered the presence of a poorly - written anonymization service that was attempting to obscure traffic to a particular adult chat site by spoofing requests from hundreds of uninvolved clients .",
    "these requests were also removed from the data set .",
    "we found that some web clients issue duplicate http requests ( same referring url and same target url ) in nearly simultaneous bursts .",
    "these bursts occur independently of the type of url being requested and are less than a single second wide .",
    "we conjecture that they may involve checking for updated content , but we are unable to confirm this without access to the original http headers .",
    "because this behavior is so rapid that it can not reflect deliberate activity of individual users , we also removed the duplicate requests from the data set .",
    "privacy concerns and our agreement with the human subjects committee of our institution also obliged us to try to remove all identifying information from the referring and target urls .",
    "one means of doing so is to strip off all identifiable query parameters from the urls . applying this anonymization procedure affects roughly one - third of the remaining requests .",
    "the resulting data set ( summarized in table  [ table : data ] ) is the basis for all of the description and analysis that follows .",
    ".approximate dimensions of the filtered and anonymized data set . [ cols=\"<,^ \" , ]     even though we have defined sessions logically , they can still be considered from the perspective of time .",
    "if we calculate the difference between the timestamp of the request that first created the session and the timestamp of the most recent request to add a leaf node , we obtain the duration of the logical session .",
    "when we examine the distribution of the durations of the sessions of a user , we encounter the same situation as for the case of interclick times : power - law distributions @xmath0 for every user .",
    "furthermore , when we consider the exponent of the best power - law fit of each user s data , we find the values are normally distributed with a mean value @xmath1 , as shown in figure  [ fig : bracket_gamma ] .",
    "no user has a well - defined mean duration for their logical sessions ; as also suggested by the statistics of interclick times , the presence of strong regularity in a user s session behavior would be anomalous .     for the best power - law approximation to the distribution of logical session duration for each user .",
    "the fit is a normal distribution with mean @xmath2 and standard deviation @xmath3 .",
    "these low values of @xmath4 indicate unbounded variance and the lack of any central tendency in the duration of a logical session . ]",
    "it is natural to speculate that we can get the best of both worlds by extending the definition of a logical session to include a timeout , as was done in previous work on referrer trees  @xcite .",
    "such a change is quite straightforward to implement : we simply modify the algorithm so that a request can not attach to an existing session unless the attachment point was itself added within the timeout .",
    "this allows us to have one branch of the browsing tree time out while still allowing attachment on a more active branch .    while the idea is reasonable",
    ", we unfortunately find that the addition of such a timeout mechanism once again makes the statistics of the sessions strongly dependent on the particular timeout selected .",
    "as shown in figure  [ fig : logical_stat ] , the number of sessions per user , mean node count , mean depth , and ratio of nodes to tree depth are all dependent on the timeout . on the other hand , in contrast to sessions defined purely by timeout , this dependence becomes smaller as the timeout increases , suggesting that logical sessions with a timeout of around 15 minutes may be a reasonable compromise for modeling and further analysis .",
    "in this paper we have built on the network - sniffing approach to gathering web traffic that we first explored in  @xcite , extending it to track the behavior of individual users .",
    "the resulting data set provides an unprecedented and accurate picture of human browsing behavior in a hypertext information space as manifested by over a thousand undergraduate students in their residences .",
    "the data confirm previous findings about long - tailed distributions in site traffic and reveal that the popularity of sites is likewise unbounded and without any central tendency .",
    "they also show that while many aspects of web traffic have been shown to obey power laws , these power - law distributions often represent the aggregate of distributions that are actually log - normal at the user level .",
    "the lack of any regularity in interclick times for web users leads to the conclusion that sessions can not be meaningfully defined with a simple timeout , leading to our presentation of logical sessions and an algorithm for deriving them from a click stream .",
    "these logical sessions illustrate further drawbacks of the random surfer model and can be modified to incorporate timeouts in a relatively robust way .",
    "these findings have direct bearing on future work in modeling user behavior in hypertext navigation .",
    "the stability of the proportion of empty - referrer requests across all users implies that although not every page is equally likely to be the cause of a jump , the overall chance of a jump occurring is constant in the long run .",
    "the finding that the branching factor of the logical sessions is definitely greater than one means that plausible agent - based models for random walks must incorporate state , either through backtracking or branching  @xcite .",
    "our indications as to which distributions show central tendencies and which do not are of critical importance for anomaly detection and anonymization . to appear plausibly human ,",
    "an agent must not stray too far from the expected rate of requests , proportion of empty - referrer requests , referrer - to - host ratio , and node count and tree depth values for logical sessions . because these are log - normal distributions",
    ", agents can not deviate more than a multiplicative factor away from their means . at the same time , a clever agent must mimic the heavy - tailed distributions of the spacing between requests and duration of sessions ; too _ much _ regularity appears artificial .",
    "although our method of collection does afford us with a large volume of data , it suffers from several disadvantages which we are working to overcome in future studies .",
    "first , our use of the file extension ( if any ) in requested urls is a noisy indicator of whether a request truly represent a page fetch .",
    "we are also unable to detect whether any request is actually satisfied or not ; many of the requests may actually result in server errors or redirects . both of these problems could be largely mitigated without much overhead by capturing the first packet of the server s response , which should indicate an http response code and a content type in the case of successful requests .",
    "this data set is inspiring the development of an agent - based model that replaces the uniform distributions of pagerank with more realistic distributions and incorporates bookmarking behavior to capture the branching behavior observed in logical sessions  @xcite .",
    "the authors would like to thank the advanced network management laboratory at indiana university and dr",
    ".  jean camp of the iu school of informatics for support and infrastructure .",
    "we also thank the network engineers of indiana university for their support in deploying and managing the data collection system .",
    "special thanks are due to alessandro flammini for his insight and support during the analysis of this data .",
    "this work was produced in part with support from the institute for information infrastructure protection research program .",
    "the i3p is managed by dartmouth college and supported under award number 2003-tk - tx-0003 from the u.s .",
    "dhs , science and technology directorate .",
    "this material is based upon work supported by the national science foundation under award number 0705676 .",
    "this work was supported in part by a gift from google .",
    "opinions , findings , conclusions , recommendations or points of view in this document are those of the authors and do not necessarily represent the official position of the u.s .",
    "department of homeland security , science and technology directorate , i3p , national science foundation , indiana university , google , or dartmouth college .",
    "m.  bouklit and f.  mathieu .",
    "backrank : an alternative for pagerank ? in _",
    "www 05 : special interest tracks and posters of the 14th international conference on world wide web _ , pages 11221123 , new york , ny , usa , 2005 .",
    "acm .",
    "s.  pandey , s.  roy , c.  olston , j.  cho , and s.  chakrabarti .",
    "shuffling a stacked deck : the case for partially randomized ranking of search engine results . in k.",
    "bhm , c.  s. jensen , l.  m. haas , m.  l. kersten , p .-  .",
    "larson , and b.  c. ooi , editors , _ proc .",
    "31st international conference on very large databases ( vldb ) _ , pages 781792 , 2005 .",
    "f.  qiu , z.  liu , and j.  cho .",
    "analysis of user web traffic with a focus on search activities . in a.",
    "doan , f.  neven , r.  mccann , and g.  j. bex , editors , _ proc .",
    "8th international workshop on the web and databases ( webdb ) _",
    ", pages 103108 , 2005 ."
  ],
  "abstract_text": [
    "<S> we examine the properties of all http requests generated by a thousand undergraduates over a span of two months . </S>",
    "<S> preserving user identity in the data set allows us to discover novel properties of web traffic that directly affect models of hypertext navigation . </S>",
    "<S> we find that the popularity of web sites  the number of users who contribute to their traffic  lacks any intrinsic mean and may be unbounded . </S>",
    "<S> further , many aspects of the browsing behavior of individual users can be approximated by log - normal distributions even though their aggregate behavior is scale - free . </S>",
    "<S> finally , we show that users click streams can not be cleanly segmented into sessions using timeouts , affecting any attempt to model hypertext navigation using statistics of individual sessions . </S>",
    "<S> we propose a strictly logical definition of sessions based on browsing activity as revealed by referrer urls ; a user may have several active sessions in their click stream at any one time . </S>",
    "<S> we demonstrate that applying a timeout to these logical sessions affects their statistics to a lesser extent than a purely timeout - based mechanism .    </S>",
    "<S> [ http ] [ information networks ] [ navigation , user issues ] </S>"
  ]
}