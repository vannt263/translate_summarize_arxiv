{
  "article_text": [
    "state estimation is one of the essential issues in systems and control theory , and has attracted extensive attentions from various fields for a long time .",
    "major cornerstones in this field include the winner filter , the kalman filter , the particle filter , the set - membership filter , etc . while the developed state estimators have numerous distinguished forms in their appearances , most of them are in essence closely related to least squares estimations , and some of them can even be regarded as its extensions to various different situations , such as multiple - input multiple - output systems , systems disturbed by non - normal external noises , etc . @xcite .    with recent significant advancements of network technologies , utility of wireless networks , internet , etc . ,",
    "is strongly expected in increasing structure flexibilities and reducing infrastructure investments in building a large scale system , and/or implementing remote monitoring , etc . to make this conception applicable to actual engineering problems ,",
    "however , various new theoretical challenges should be attacked .",
    "for example , in a communication network , data packets carrying an observed plant output can be randomly lost , delayed or even their original order can be changed , due to traffic conditions of the internet and/or propagation property variations of wireless medium , etc.@xcite .    over the last decade",
    ", various efforts have been devoted to state estimations with random missing measurements . in @xcite , it is proved that when a plant model is accurate and external disturbances are normally distributed , the kalman filter is still optimal in the sense of mean squared errors ( mse ) even if there exist random measurement droppings , provided that information is available on whether or not the received data is a measured plant output .",
    "it has also been proved there that for an unstable plant , even it is both controllable and observable , the expectation of the covariance matrix of estimation errors may become infinitely large when the probability of receiving a plant output measurement is too low .",
    "afterwards , it has been argued by many researchers that it may be more appropriate to investigate the probability distribution of this covariance matrix , as events of very low probability may cause an infinite expectation .",
    "particularly , some upper and lower bounds have been derived in @xcite for the probability of this covariance matrix being smaller than a prescribed positive definite matrix ( pdm ) . in @xcite",
    ", it is proved that under some controllability and observability conditions , the trace of this covariance matrix follows a power decay law for an unstable plant with a diagonalizable state transition matrix .",
    "on the basis of the contractiveness of riccati recursions and convergence of random iterated functions , it has been proved in @xcite that this covariance matrix usually converges to a stationary distribution that is independent of the plant initial states , no matter the communication channel is described by a bernoulli process , a markov chain or a semi - markov chain . in @xcite , it is proved that when the observation arrival is modeled by a bernoulli process and the packet arrival probability approaches to 1 , the covariance matrix converges weakly to a unique invariant distribution that satisfies a moderate deviation principle with a good rate function . in @xcite",
    ", one - step prediction is investigated using an estimator with a prescribed structure that tolerates both random measurement droppings and some specific kinds of parametric modelling errors , and a recursive estimation procedure has been respectively derived through minimizing an upper bound of the covariance matrix of estimation errors .",
    "while the obtained estimators share a similar form as that of the kalman filter , a parameter should be adjusted on - line to guarantee the existence of the inverse of a matrix , which may restrict successful implementation of the developed recursive estimation procedure .",
    "these investigations have clarified many important characteristics about state estimations with random measurement arrivals , and have greatly advanced studies on analysis and synthesis of networked systems . but except @xcite , plant models are assumed precisely known in almost all these investigations . in actual engineering applications ,",
    "however , model errors , which include parametric deviations from nominal values , unmodelled dynamics , approximation errors due to plant nonlinear dynamics , etc . , are usually unavoidable . in addition , it has also been widely observed that estimation accuracies of some optimal estimators , including the kalman filter , may be deteriorated appreciably by modelling errors @xcite .    to make a state estimator robust against modelling errors , various approaches",
    "have been proposed , such as the @xmath0 norm optimization based method , the guaranteed cost based approach , etc . among these approaches ,",
    "the sensitivity penalization based method has some appreciated properties , such as its similarities to the kalman filter in estimation procedures , no requirements on verification of matrix inequalities during estimate updates , capability of dealing with various kinds of parametric modelling errors , etc . @xcite . in @xcite",
    ", an attempt has been made to extend this method to situations in which random measurement dropping tolerances are required . while some results have been obtained , its success is rather limited , noting that the developed estimation algorithm requires some ergodic conditions on the received signal which can hardly be satisfied by a time varying system .",
    "in addition , the developed estimation procedure has not efficiently utilized the information contained in a received signal about whether or not it is the measurement of a plant output .",
    "another restriction of the results in @xcite is that they are only valid for systems with a communication channel described by the bernoulli random process .    in this paper , we reinvestigate the extension of the sensitivity penalization based robust state estimation method to systems with random measurement droppings .",
    "all the above limitations have been successfully removed . through introducing a new cost function ,",
    "a novel recursive procedure has been derived for state estimation with random missing measurements .",
    "this procedure also reduces to the kalman filter when the plant model is accurate .",
    "a new recursion formula has been established for the pseudo - covariance matrix ( pcm ) of estimation errors which makes it possible to analyze asymptotic properties of the developed robust state estimator ( rse ) .",
    "it has also been proved that under some controllability and observability conditions on the nominal and adjusted system matrices , as well as some weak requirements on the random measurement loss process , the gain matrix of the rse converges with probability one to a stationary distribution that is independent of its initial values .",
    "some numerical simulation results are also provided to illustrate its characteristics in estimating states of a plant with both parametric modelling errors and random measurement droppings .",
    "the outline of this paper is as follows . at first , in section ii , the problem formulation is provided and the estimation procedure is derived .",
    "afterwards , some related properties on riccati recursions are introduced in subsection iii.a as preliminary results , while asymptotic characteristics of the estimator are investigated in subsection iii.b .",
    "a numerical example is then provided in section iv to illustrate the effectiveness of the proposed estimator .",
    "finally , some concluding remarks are given in section v summarizing characteristics of the suggested method .",
    "an appendix is included to give proofs of some technical results .    the following notation and symbols are adopted .",
    "@xmath1 stands for the euclidean norm of a vector , while @xmath2 is a shorthand for @xmath3 .",
    "@xmath4 denotes a block diagonal matrix with its @xmath5-th diagonal block being @xmath6 , while @xmath7 the vector / matrix stacked by @xmath8 with its @xmath5-th row block vector / matrix being @xmath6 .",
    "@xmath9 $ ] represents a matrix with @xmath10 blocks and its @xmath5-th row @xmath11-th column block matrix being @xmath12 , while the product @xmath13 is denoted by @xmath14 .",
    "the superscript @xmath15 is used to denote the transpose of a matrix / vector , and @xmath16 or @xmath17 is sometimes abbreviated as @xmath18 or @xmath19 , especially when the term @xmath20 has a complicated expression .",
    "@xmath21 stands for the determinant of a matrix , while @xmath22 the lipschitz constant of a function .",
    "@xmath23 is used to denote the probability of the occurrence of a random event , while @xmath24 the mathematical expectation of a matrix valued function ( mvf ) @xmath25 with respect to the random variable @xmath26 .",
    "the subscript @xmath26 is usually omitted when it is obvious .",
    "consider a linear time varying dynamic system @xmath27 with both parametric modelling errors due to imperfect information about the plant dynamics and stochastic measurement loss due to communication failures .",
    "assume that its input output relations can be described by the following discrete state - space model , @xmath28 here , @xmath29 is a @xmath30 dimensional vector representing parametric errors of the plant state - space model at the time instant @xmath31 , @xmath32 is a random variable characterizing successes and failures of communications between the plant output measurement sensors and the state estimator .",
    "it takes the value of @xmath33 when a plant output measurement is successfully transmitted , and the value of @xmath34 when the communication channel is out of order .",
    "vectors @xmath35 and @xmath36 denote respectively process noises and composite influences of measurement errors and communication errors . it is assumed in this paper that both @xmath35 and @xmath36 are white and normally distributed , @xmath37 and @xmath38 , @xmath39 . here , @xmath40 stands for the kronecker delta function , and @xmath41 and @xmath42 are known positive definite mvfs of the temporal variable @xmath31 , while @xmath43 is a known pdm .",
    "these assumptions imply that these two external disturbances are independent of each other , and are also independent of the plant initial conditions .",
    "another hypothesis adopted in this paper is that all the system matrices @xmath44 , @xmath45 and @xmath46 are time varying but known mvfs with all elements differentiable with respect to every element of @xmath29 at each time instant .",
    "it is also assumed throughout this paper that the state vector @xmath47 of the dynamic system @xmath27 has a dimension @xmath48 , and an indicator is included in the received signal @xmath49 that reveals whether or not it contains information about plant outputs .    in the above descriptions , @xmath44 , @xmath45 and @xmath46 with @xmath50 are plant nominal system matrices . according to the adopted hypotheses ,",
    "all these matrices are assumed known .",
    "the vector @xmath29 stands for deviations of plant actual parameters from their nominal values , which are permitted to be time varying and are generally unknown . in model based robust system designs or state estimations , however , some upper magnitude bounds or stochastic properties are usually assumed available for this parametric error vector @xcite . while this kind of information is important in determining the design parameter @xmath51 of the following equation ( [ eqn:7 ] ) , which is also illustrated by the numerical example of section iv , it is not used in this paper .",
    "the main objectives of this paper are to derive an estimate for the plant state vector @xmath47 using the received plant output measurements @xmath52 and information about the corresponding realization of @xmath53 , as well as to analyze its asymptotic statistical characteristics .",
    "when the plant state space model for a linear time varying system is precise , a widely adopted state estimation procedure is the kalman filter , which can be recursively realized and have achieved extensive success in actual engineering applications @xcite .",
    "this estimation procedure , however , may sometimes not work very satisfactorily due to modelling errors . to overcome this disadvantage , various modifications",
    "have been suggested which make the corresponding estimation accuracy more robust against modelling errors @xcite . among these modifications ,",
    "one effective method is based on sensitivity penalization , in which a cost function is constructed on the basis of least squares / likelihood maximization interpretations for the kalman filter and a penalization on the sensitivity of its innovation process to modelling errors @xcite .",
    "more precisely , assume that plant parameters are accurately known for the above dynamic system @xmath27 and there do not exist measurement droppings .",
    "these requirements are respectively equivalent to @xmath54 and @xmath55",
    ". let @xmath56}$ ] and @xmath57}$ ] represent respectively the estimate of the kalman filter for the plant state vector @xmath47 based on plant output measurements @xmath52 and the covariance matrix of the corresponding estimation errors .",
    "then , @xmath58}$ ] , the estimate of the plant state vector at the time instant @xmath59 based on plant output measurements @xmath60 , can also be recursively expressed as @xmath58}=a_{t}(0)\\hat{x}_{t|t+1}^{[kal]}+b_{t}(0)\\hat{w}_{t|t+1}^{[kal]}$ ] , in which @xmath61}$ ] and @xmath62}$ ] stand for vectors @xmath63 and @xmath64 that minimize the cost function @xmath65}(x_{t|t+1},\\;w_{t|t+1})=||x_{t|t+1}-\\hat{x}_{t|t}^{[kal]}||_{(p_{t|t}^{[kal]})^{-1}}^{2}+||w_{t|t+1}||_{q_{t}^{-1}}^{2 } + ||e_{t}(0,\\;0)||_{r_{t+1}^{-1}}^{2}$ ] , in which @xmath66 $ ] that is generally called the innovation process in estimation theory when the plant model is accurate @xcite .",
    "note that from the markov properties of the plant dynamics and the fact that the kalman filter is a linear function of plant output measurements , it can be claimed that both the plant state vector and its kalman filter based estimate are normally distributed .",
    "based on these facts , it can be further declared that the aforementioned @xmath61}$ ] and @xmath62}$ ] are in fact respectively the @xmath60 based maximum likelihood estimates of @xmath47 and @xmath35 . on the other hand , from the expression of the cost function @xmath65}(x_{t|t+1},\\;w_{t|t+1})$ ] , the kalman filter can also be interpreted as a least squares estimator @xcite .    when @xmath67 and _ only _ nominal plant parameters are known , in order to increase robustness of the kalman filter against parametric modelling errors , it is suggested in @xcite to add some penalties on the sensitivity of the innovation process @xmath68 to modelling errors into this cost function .",
    "the rationale is that deviations of this innovation process from its nominal values reflect contributions of parametric modelling errors to prediction errors of the kalman filter about plant outputs .",
    "note that when @xmath69 , @xmath68 is the only factor in the cost function @xmath65}(x_{t|t+1},\\;w_{t|t+1})$ ] that depends on system parameters .",
    "this means that reduction of its deviations due to modelling errors in fact also reduces the counterpart of this cost function , and therefore increases robustness of the corresponding state estimator . noting also that accurate expression for this deviation generally has a complicated form and",
    "may make the corresponding estimation problem mathematically intractable , it is suggested in @xcite to consider its first order approximation , that is , to linearize @xmath68 at the origin .",
    "specifically , the cost function @xmath65}(x_{t|t+1},\\;w_{t|t+1})$ ] is modified to @xmath70}(x_{t|t+1},w_{t|t+1})\\!=\\!\\mu_{t}j^{[kal]}(x_{t|t+1},w_{t|t+1})\\!+\\!(1\\!-\\!\\mu_{t})\\!\\!\\left.\\sum_{k=1}^{n_{e}}\\!\\!\\left ( \\left|\\left|\\frac{\\partial e_{t}(\\varepsilon_{t},\\;\\varepsilon_{t+1})}{\\partial \\varepsilon_{t , k}}\\right|\\right|_{2}^{2}\\!\\!+\\!\\!\\left|\\left|\\frac{\\partial e_{t}(\\varepsilon_{t},\\;\\varepsilon_{t+1})}{\\partial \\varepsilon_{t+1,k}}\\right|\\right|_{2}^{2}\\!\\right)\\!\\right|\\!\\!\\!{\\footnotesize\\begin{array}{l } \\\\",
    "\\varepsilon_{t}\\!=\\!0 \\vspace{-0.25 cm } \\\\",
    "\\varepsilon_{t+1}\\!=\\!0\\end{array}}\\ ] ] in which @xmath51 is a positive design parameter belonging to @xmath71 $ ] that reflects a trade - off between nominal value of estimation accuracy and penalization on the first order approximation of deviations of the innovation process due to parametric modelling errors .",
    "based on this modified cost function @xmath72}(x_{t|t+1},\\;w_{t})$ ] , a state estimation procedure is derived in @xcite .",
    "it has also been proved there that except some parameter adjustments , this estimation procedure has a similar form as that of the kalman filter , and its estimation gain matrix also converges to a constant matrix if some controllability and observability conditions are satisfied .",
    "boundedness of the covariance matrix of its estimation errors has also been established under some weak conditions like quadratic stability of the plant and contractiveness of the parametric errors , etc .",
    "it has been shown that the estimation procedure reduces to the kalman filtering if parametric uncertainties disappear @xcite .    in this paper ,",
    "the same approach is adopted to deal with the state estimations for the linear time varying dynamic system @xmath27 in which both parametric uncertainties and random measurement droppings exist .",
    "it is worthwhile to point out that although this extension has been attempted in @xcite , the success is rather limited .",
    "one of the major restrictions on applicability of the obtained results is the implicit ergodic requirement on the received plant output measurements , which is generally not satisfied by a time varying system .",
    "another major restriction is that in developing the estimation procedure , information about the realization of the random process @xmath32 has not been efficiently utilized , which makes the corresponding estimation accuracy sometimes even worse than the traditional kalman filter that does not take either parametric errors or random measurement loss into account .",
    "these disadvantages have been successfully overcome in this paper through introducing another cost function which is more appropriate in dealing with simultaneous existence of parametric uncertainties and random measurement droppings .",
    "more precisely , assume that at the time instant @xmath31 , an estimate is obtained for the plant state using the received plant output measurements @xmath52 , denote it by @xmath73 .",
    "let @xmath74 represent the pcm of the corresponding state estimation errors .",
    "construct a cost function @xmath75 as follows , @xmath76 + \\gamma_{t+1}\\left[\\mu_{t}||e_{t}(0,\\;0)||_{r_{t+1}^{-1}}^{2}+(1-\\mu_{t})\\times\\right.\\right.\\nonumber\\\\ & & \\hspace*{2cm}\\left.\\left.\\left.\\sum_{k=1}^{n_{e}}\\left ( \\left|\\left|\\frac{\\partial e_{t}(\\varepsilon_{t},\\;\\varepsilon_{t+1})}{\\partial \\varepsilon_{t , k}}\\right|\\right|_{2}^{2}+\\left|\\left|\\frac{\\partial e_{t}(\\varepsilon_{t},\\;\\varepsilon_{t+1})}{\\partial \\varepsilon_{t+1,k}}\\right|\\right|_{2}^{2}\\right)\\right|\\!\\!\\!{\\footnotesize\\begin{array}{l } \\\\",
    "\\varepsilon_{t}=0 \\vspace{-0.25 cm } \\\\",
    "\\varepsilon_{t+1}=0\\end{array}}\\right]\\right\\ } \\label{eqn:7}\\end{aligned}\\ ] ] here , both @xmath68 and @xmath51 have the same definitions as those in the aforementioned sensitivity penalization based robust estimator design . while @xmath51 selection is an important issue in designing a robust state estimator and depends on properties of parametric modelling errors",
    "@xcite , it is assumed given in this paper .",
    "in this cost function , @xmath77 is explicitly utilized which is generally available in communications after @xmath78 is received .",
    "in fact , to make this information accessible , the only requirement is to include an indication code in a communication channel which is usually possible @xcite . on the other hand , if @xmath79 , that is , if there is no measurement loss from the system output measurement sensor to the state estimator , this cost function is equivalent to @xmath72}(x_{t|t+1},\\;w_{t|t+1})$ ] , which means that as some new information on @xmath47 contained in @xmath78 has arrived at the time instant @xmath59 , its estimate should be updated in a robust way that is not sensitive to parametric modelling errors . if a measurement dropping happens in communications , then , @xmath78 does not contain any information about the plant output and therefore @xmath47 . in this case , as the existing estimate on @xmath47 is optimal and no new information about it arrives , there is no need to update this estimate , which is equivalent to that the cost function does not depend on either the nominal value of @xmath68 or its sensitivity to parametric modelling errors . in other words ,",
    "when no plant output measurement is available at a time instant , the estimator can only predict the plant state vector using the previously collected information , and this physically obvious characteristic has been satisfactorily reflected by the above cost function . from these aspects , it appears safe to declare that the cost function @xmath75 has simultaneously satisfied both the optimality requirements and the robustness requirements in state estimations under simultaneous existence of parametric modelling errors and measurement loss , and is therefore physically more reasonable than that of @xcite .",
    "however , it is worthwhile to mention that in the above cost function @xmath75 , the purpose to include a penalty on the sensitivity of the innovation process @xmath80 to modelling errors is to increase the robustness of state estimations against deviations of plant parameters from their nominal values .",
    "there are also many important practical situations , for example , fault detection , signal segmentation , financial market monitoring , etc . , in which an estimate sensitive to actual parameter variations are more greatly appreciated @xcite . under these situations , the above cost function , and therefore the corresponding state estimate procedure , are no longer appropriate .",
    "let @xmath81 and @xmath82 denote the optimal @xmath63 and @xmath64 that minimize the above cost function @xmath83 . then , according to the sensitivity penalization approach towards robust state estimations , an @xmath60 based estimate of the plant state vector @xmath84 , denote it by @xmath85 , can be constructed as follows , @xmath86    when there are no parametric uncertainties in the plant model , the matrix @xmath74 is in fact the covariance matrix of the estimation errors of the kalman filter .",
    "this makes it possible to explain @xmath81 and @xmath82 respectively as the @xmath60 based maximum likelihood estimates of @xmath47 and @xmath35 @xcite .",
    "but when there exist modelling errors in the system matrices @xmath44 , @xmath45 and @xmath46 , physical interpretations of the matrix @xmath74 need further clarifications @xcite . to avoid possible misunderstandings ,",
    "it is called pseudo - covariance matrix ( pcm ) in this paper .",
    "based on the above construction procedure , a recursive estimation algorithm can be derived for the state vector of a plant with both parametric uncertainties and random measurement loss , while its proof is deferred to the appendix .",
    "let @xmath87 denote @xmath88 .",
    "assume that both @xmath74 and @xmath41 are invertible .",
    "then , the estimate of the state vector @xmath84 of the dynamic system @xmath27 based on @xmath89 and equations ( [ eqn:7 ] ) and ( [ eqn:8 ] ) has the following recursive expression , @xmath90 moreover , the pcm @xmath74 can be recursively updated as @xmath91^{-1}+c_{t+1}^{t}(0)r_{t+1}^{-1}c_{t+1}(0)\\right\\}^{-1 } & \\gamma_{t+1}=1 \\end{array}\\right.\\ ] ] in which @xmath92^{-1 } \\\\ & & \\hat{b}_{t}(0)=b_{t}(0)-\\lambda_{t}a_{t}(0)\\hat{p}_{t|t}s_{t}^{t}t_{t},\\hspace{0.5 cm } \\hat{a}_{t}(0)=[a_{t}(0)-\\hat{b}_{t}(0)\\hat{q}_{t}t_{t}^{t}s_{t}][i-\\lambda_{t}\\hat{p}_{t|t}s_{t}^{t}s_{t}]\\\\ & & s_{t}={\\rm\\bf col}\\!\\left.\\left\\{\\left[\\begin{array}{cc } c_{t+1}(\\varepsilon_{t+1})\\frac{\\partial(a_{t}(\\varepsilon_{t}))}{\\partial\\varepsilon_{t , k } } \\\\ \\frac{\\partial(c_{t+1}(\\varepsilon_{t+1}))}{\\partial\\varepsilon_{t+1,k}}a_{t}(\\varepsilon_{t } ) \\end{array}\\right]_{k=1}^{n_{e}}\\right\\}\\right|\\!\\!\\!{\\footnotesize\\begin{array}{l } \\\\",
    "\\varepsilon_{t}=0 \\vspace{-0.25 cm } \\\\ \\varepsilon_{t+1}=0\\end{array}}\\!\\!\\!\\!\\!,\\hspace{0.25 cm } t_{t}={\\rm\\bf",
    "col}\\!\\left.\\left\\{\\left[\\begin{array}{cc } c_{t+1}(\\varepsilon_{t+1})\\frac{\\partial(b_{t}(\\varepsilon_{t}))}{\\partial\\varepsilon_{t , k } } \\\\ \\frac{\\partial(c_{t+1}(\\varepsilon_{t+1}))}{\\partial\\varepsilon_{t+1,k}}b_{t}(\\varepsilon_{t } ) \\end{array}\\right]_{k=1}^{n_{e}}\\right\\}\\right|\\!\\!\\!{\\footnotesize\\begin{array}{l } \\\\",
    "\\varepsilon_{t}=0 \\vspace{-0.25 cm } \\\\",
    "\\varepsilon_{t+1}=0\\end{array}}\\end{aligned}\\ ] ]    note that when @xmath93 , the above estimator is just a one - step state predictor using nominal system matrices .",
    "on the other hand , when @xmath79 , the above estimator still has the same structure as that of the kalman filter , except that the nominal system matrices @xmath94 , @xmath95 , etc .",
    ", should be adjusted to reduce sensitivity of estimation accuracy to modelling errors .",
    "the adjustment method of these matrices is completely the same as that of the sensitivity penalization based rse developed in @xcite and is no longer required if the design parameter @xmath51 is selected to be @xmath33 .",
    "this means that the above recursive estimation procedure is consistent with both rse of @xcite and the kalman filtering with intermittent observations ( kfio ) reported in @xcite . as a by - product of this investigation , another derivation of kfio is obtained , in which the assumption is no longer required that the covariance matrix of measurement noise tends to infinity when a measured plant output is lost by a communication channel .",
    "this assumption is essential in the kfio derivations given in @xcite , but does not appear very natural from an engineering point of view .",
    "however , theorem 1 also makes it clear that when there exist both parametric modelling errors and random measurement droppings , the system matrices used by the estimator depend on whether or not @xmath78 contains information about plant outputs .",
    "this makes the estimator different from kfio , and also makes analysis more mathematically involved about its asymptotic characteristics .",
    "in evaluating performances of a state estimator , one extensively utilized metric is about its convergence .",
    "a general belief is that if an estimator does not converge , satisfactory performance can not be anticipated .",
    "it is now well known that for a linear time invariant system , under some controllability and observability conditions , the gain of the kalman filter converges to a constant matrix .",
    "this property makes it possible to approximate the kalman filter satisfactorily with an a constant gain observer @xcite .    when plant output measurements are randomly received , @xmath32 of equation ( [ eqn:1 ] ) is a random process .",
    "this makes the pcm @xmath74 , and therefore the gain matrix of the state estimator , also a random process .",
    "generally , it can not be anticipated that they converge to constant matrices , but it is still theoretically and practically interesting to see whether or not they have stationary distributions @xcite . note that both the matrix @xmath96 and the matrix @xmath42 are deterministic mvfs of the temporal variable @xmath31 .",
    "an interesting and basic issue here is therefore that whether or not the matrix @xmath74 converges to a stationary distribution .",
    "although the derived rse has a similar structure as that of kfio , the recursions for the pcm @xmath74 have a more complicated form , as system matrices should be adjusted when a received packet contains information about plant output .",
    "this adjustment invalidates the relatively simple relations between the @xmath97s of kfio with respectively @xmath98 and @xmath99 that play essential roles in establishing its asymptotic properties @xcite . as a matter of fact , this adjustment makes the corresponding analysis much more mathematically involved for the rse developed in this paper , which is abbreviated for brevity to rseio in the rest of this paper , and leads to conclusions different from those of kfio .      to investigate the asymptotic properties of rseio , some preliminary results are required , which include a matrix transformation , a riemannian distance for pdms and some characteristics of a hamiltonian matrix .",
    "some of them have already been utilized in analyzing asymptotic properties of kfio and kalman filter with random coefficients @xcite .",
    "assume that @xmath100 and @xmath101 are two @xmath102 dimensional pdms .",
    "let @xmath103 denote the eigenvalues of the matrix @xmath104 .",
    "the riemannian distance between these two matrices , denote it by @xmath105 , is defined as @xmath106 .",
    "an attractive property of this distance is its invariance under conjugacy transformations and inversions .",
    "it is now also known that when equipped with this distance , the space of @xmath102 dimensional pdms is complete .",
    "this metric , although not widely known , has been recognized very useful for many years in studying asymptotic properties of kalman filtering with random system matrices @xcite .",
    "its effectiveness in studying asymptotic properties of kfio has also been discovered recently @xcite .    for matrices @xmath100 and @xmath107 $ ] with appropriate dimensions , define a homographic transformation @xmath108 as @xmath109[\\phi_{21}p+\\phi_{22}]^{-1}$ ] . here , the matrix @xmath110 is assumed to be square and of full rank .",
    "this matrix transformation has been proved very useful in solving many theoretical problems in systems and control , such as the @xmath0 control problem , convergence analysis of riccati recursions , etc .",
    "an attractive property of this transformation lies in its simplicity in representing cascade connections , which is given in the following lemma and can be obtained through straightforward algebraic manipulations .",
    "this property plays important roles in analyzing the asymptotic properties of the pcm @xmath74 .",
    "@xcite assume that matrices @xmath111 , @xmath112 and @xmath100 have compatible dimensions .",
    "moreover , assume that all the required matrix inverses exist .",
    "then , @xmath113",
    ".    on the other hand , a matrix @xmath114 $ ] with @xmath115 , @xmath116 , is called hamiltonian if it satisfies @xmath117 , in which @xmath118 $ ] .",
    "hamiltonian matrices are well encountered in optimal estimation and control , and their characteristics have been extensively studied @xcite .",
    "moreover , define four subsets of hamiltonian matrices @xmath119 , @xmath120 , @xmath121 and @xmath122 respectively as @xmath123_{i , j=1}^{2},\\ ; \\phi_{ij}\\in{\\cal r}^{n\\times n},\\;\\phi^{t}j\\phi = j,\\;\\phi_{11}\\;{\\rm invertible},\\ ; \\phi_{12}\\phi_{11}^{t}\\geq 0,\\;\\phi_{11}^{t}\\phi_{21}\\geq 0 \\;\\right.\\right\\}$ ] , @xmath124 , @xmath125 and @xmath126 @xmath127 .",
    "then , from their definitions , it can be straightforwardly declared that @xmath128 , @xmath129 , @xmath130 and @xmath131 .",
    "the following properties of hamiltonian matrices are given in @xcite , which are repeatedly used in the remaining theoretical studies of this paper .",
    "@xcite assume that all the involved matrices have compatible dimensions .",
    "then , among elements of the sets @xmath119 , @xmath120 , @xmath121 and @xmath132 , and ( semi-)pdms , the following relations exist .    * if @xmath133 and @xmath134 ( or @xmath120 , or @xmath121 , or @xmath122 ) , then , both @xmath135 and @xmath136 belongs to @xmath119 ( or @xmath120 , or @xmath121 , or @xmath122 ) ; * assume that @xmath137\\in{\\cal h}$ ] , @xmath138 .",
    "then , * * @xmath139 if and only if @xmath140\\right\\}\\neq 0\\ ] ] * * @xmath141 if and only if @xmath142+\\phi_{m,12}\\phi_{m,11}^{t}\\right\\}\\neq 0\\ ] ] * assume that @xmath143 .",
    "then , for an arbitrary @xmath144 , @xmath145 is well defined and is at least a semi - pdm . if in addition that @xmath146 , then @xmath147 is also positive ; * assume that @xmath148 .",
    "then , for every @xmath144 , @xmath145 is certainly a pdm ; * assume that @xmath143 .",
    "then , @xmath149 , whenever @xmath150 ; * assume that @xmath151 or @xmath152 . then , for any @xmath150 , @xmath153 @xmath154 ; * assume that @xmath148 .",
    "then , there exists a @xmath155 belonging to @xmath156 , such that for all @xmath150 , @xmath157 .",
    "to analyze asymptotic properties of rseio , the following results on iterated functions governed by a semi - markov process are also needed , which have been successfully applied to establishing convergence properties of kfio @xcite .",
    "@xcite let @xmath158 , @xmath159 , be a map from a metric space @xmath160 to itself , and @xmath161 a semi - markov chain taking values only from the set @xmath162 .",
    "denote the renewal process related to @xmath161 by @xmath163 , and the departure of @xmath164 from the last renewal by @xmath165 .",
    "assume that @xmath166 is irreducible , @xmath167 is aperiodic , and @xmath168 . if there exists an integer @xmath169 , such that @xmath170\\right\\}<0\\ ] ] then , the recursive random walk @xmath171 with @xmath172 has a unique stationary distribution .",
    "moreover , for any initial @xmath173 , the empirical distribution tends to this stationary distribution with probability one .      to utilize the results of the previous subsection",
    ", @xmath174 should be expressed as a homographic transformation of @xmath74 . when no information is contained in @xmath78 about the plant output",
    ", rseio performs a lyapunov recursion using nominal system matrices , which makes it straightforward to establish this expected relation .",
    "however , when the received signal @xmath78 contains information about plant output , although the estimation is still similar to that of the kalman filter , the relation between @xmath174 and @xmath74 is quite complicated .",
    "this means that to clarify the asymptotic characteristics of the pcm @xmath74 , another recursive form is required for it under the situation @xmath79 .",
    "note that in the convergence analysis of the sensitivity penalization based rse , a relatively compact relation between @xmath175 and @xmath97 has been established in @xcite .",
    "however , this relation is not very convenient in deriving the required relation between @xmath174 and @xmath74 . in this paper",
    ", we take a different approach in establishing this relation , which is given in the next theorem and whose proof is deferred to the appendix .",
    "denote the matrix @xmath176 by @xmath177 and assume it is invertible . define matrices @xmath178 , @xmath179 , @xmath180 , @xmath181 and @xmath182 respectively as follows , @xmath183^{-1/2}s_{t},\\hspace{0.25 cm } \\tilde{c}_{t+1}\\!=\\!\\left[\\begin{array}{c } \\tilde{s}_{t}\\check{a}_{t}^{-1 } \\\\",
    "c_{t+1}(0 ) \\end{array}\\right],\\hspace{0.25 cm } \\tilde{r}_{t+1}\\!=\\!\\left[\\begin{array}{cc } i+\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}\\tilde{s}_{t}^{t } & 0 \\\\ 0 & r_{t+1 } \\end{array}\\right]\\end{aligned}\\ ] ] in which @xmath184 .",
    "if @xmath185 , then , @xmath186^{-1}+\\tilde{c}_{t+1}^{t}\\tilde{r}^{-1}_{t+1}\\tilde{c}_{t+1}\\ ] ]    note that although the matrices @xmath178 , @xmath180 , @xmath181 and @xmath182 have a complicated form , all of them are independent of system input - output data , and can therefore be computed off - line .",
    "this also means that the recursion formula for @xmath174 in theorem 1 is more suitable for performing robust state estimations , while that in theorem 2 matches better for its asymptotic property analysis .",
    "it is also worthwhile to point out that invertibility of the matrix @xmath177 is not required in deriving the rse of theorem 1 , which implies that further efforts are still required to establish its asymptotic properties in the most general situation .    from theorems 1 and 2 ,",
    "it is clear that depending on whether or not @xmath78 contains information about plant outputs , the pcm @xmath174 performs alternatively a lyapunov recursion and a riccati recursion .",
    "this is very similar to that of kfio .",
    "but as robustness has been taken into account , system matrices in the riccati recursion are different from those in the lyapunov recursion .",
    "this difference significantly complicates convergence analysis for rseio and makes its conclusions different from those of kfio .",
    "lyapunov and riccati equations / recursions play important roles in system analysis and synthesis , and their properties have been extensively studied @xcite .",
    "when plant measurements are missed randomly , the alternative lyapunov / riccati recursion in both the kfio and the resio becomes a random process , which makes its convergence analysis much more mathematically difficult and some basic conclusions different from their counterparts of deterministic recursions @xcite .",
    "for example , in @xcite , it is proved that for an unstable system , simultaneous controllability and observability are no longer sufficient for guaranteeing the boundedness of the covariance matrix of estimation errors of the kfio .",
    "it can also be seen in the following analysis that when plant output measurement receiving probability is greater than @xmath34 , controllability and observability are _ only _ a sufficient condition for the convergence of the resio . on the other hand ,",
    "as system matrices in the riccati recursion are different from those in the lyapunov recursion in resio , its convergence analysis is more mathematically involved than that of kfio .    to simplify mathematical expressions in the following discussions , @xmath94 and @xmath95 are respectively abbreviated to @xmath187 and @xmath188",
    "moreover , assume that both the matrix @xmath187 and the matrix @xmath178 are invertible . define matrix @xmath189 as @xmath190 & \\gamma_{t+1}=0 \\\\",
    "\\left[\\begin{array}{cc } \\tilde{a}_{t } & b_{t}\\tilde{q}_{t}b_{t}^{t}\\tilde{a}_{t}^{-t } \\\\",
    "\\tilde{c}_{t+1}^{t}\\tilde{r}_{t+1}^{-1}\\tilde{c}_{t+1}\\tilde{a}_{t } & [ i+\\tilde{c}_{t+1}^{t}\\tilde{r}_{t+1}^{-1}\\tilde{c}_{t+1}b_{t}\\tilde{q}_{t}b_{t}^{t}]\\tilde{a}_{t}^{-t } \\end{array}\\right ] & \\gamma_{t+1}=1 \\end{array}\\right . \\label{eqn:2}\\ ] ] then , straightforward algebraic manipulations show that @xmath189 is always a hamiltonian matrix , and always belongs to the set @xmath191 .",
    "moreover , the following results can be immediately obtained from lemmas 1 and 2 , as well as theorems 1 and 2 .",
    "assume that rseio starts from @xmath192 with @xmath193 and @xmath194 .",
    "moreover , assume that both the matrix @xmath187 and the matrix @xmath178 are of full rank at all the sampled time instants .",
    "then , for an arbitrary semi - pdm @xmath194 and an arbitrary time instant @xmath195 , @xmath196    note that @xmath197 , @xmath198 . it can be declared from lemma 2 that when both the matrix @xmath199 and the matrix @xmath200 are invertible , the homographic transformation @xmath201 is always well defined for every @xmath102 dimensional semi - pdm @xmath100 .    from the definition of the matrix @xmath202 and theorems 1 and 2 , it is obvious that for every @xmath203 , no matter @xmath204 or @xmath205 , we always have that @xmath206",
    "hence , it can be claimed from lemma 2 that when @xmath194 is a semi - pdm , all the involved @xmath207s are well defined and are at least a semi - pdm .",
    "moreover , a repetitive utilization of lemma 1 leads to , @xmath208    this completes the proof .",
    "similar to the proof of corollary 1 , it can also be proved that for every semi - pdm @xmath20 , @xmath210 @xmath211 .    in the rest of this paper , in order to explicitly express the dependence of the matrix @xmath212 on a realization of @xmath32 , this matrix is sometimes , with a little abuse of symbols , written as @xmath213 when necessary , in which @xmath214 is a realization of the random process @xmath215",
    ".    having these preparations , we are ready to analyze asymptotic properties of the pcm @xmath74 . to perform this analysis ,",
    "it is assumed in the remaining of this section that the nominal model of the plant , as well as the first order derivatives of the innovation process @xmath80 with respect to every parametric modelling error , do not change with the variable @xmath31 .",
    "that is , @xmath94 , @xmath95 , @xmath96 , @xmath42 , @xmath41 , @xmath216 and @xmath217 are no longer a function of the temporal variable @xmath31 . under this assumption , it is feasible to define matrices @xmath218}$ ] , @xmath219}$ ] , @xmath220}$ ] , @xmath221}$ ] and @xmath222}$ ] , all of which do not depend on the variable @xmath31 , respectively as @xmath223}=\\tilde{a}_{t } , \\hspace{0.5cm}g^{[1]}=b_{t}{\\tilde{q}_{t}^{1/2}},\\hspace{0.5 cm } h^{[1]}=\\tilde{r}_{t+1}^{-1/2}\\tilde{c}_{t+1 } ,   \\hspace{0.5 cm } a^{[2]}=a_{t } , \\hspace{0.5 cm } g^{[2]}=b_{t}q_{t}^{1/2}\\ ] ]    using these symbols , it can be straightforwardly proved that @xmath224}g^{[2]t}$ ] , @xmath225}g^{[1]t}$ ] and @xmath226t}h^{[1]}$ ] . on the basis of these relations and lemmas 1 and 2 ,",
    "the following conclusions are obtained on the product of matrices @xmath227 for an arbitrary positive integer @xmath228 . their proof is given in the appendix .    for a prescribed positive integer @xmath228 , @xmath229 if and only if there exists an integer sequence @xmath230 satisfying @xmath231 , such that the matrix @xmath232 is of full column rank which is defined as @xmath233},\\ ; h^{[1]}a^{[1]}(a^{[2]})^{t_{p}-t_{p-1}-1},\\ ; \\cdots,\\ ; h^{[1]}\\prod_{j=1}^{p}a^{[1]}(a^{[2]})^{t_{j}-t_{j-1}-1}\\right\\ } \\label{eqn:11}\\ ] ]    when the subset @xmath121 is concerned , we have the following results . their proof is also deferred to the appendix .    for a prescribed positive integer @xmath228 , @xmath234 if and only if there exists an integer sequence @xmath235 satisfying @xmath236 , such that the matrix @xmath237 defined as @xmath238})^{t_{1}-1}c_{n,0}\\;\\ ; c_{n,1}\\;\\;(a^{[2]})^{t_{1}-1}a^{[1]}\\left[c_{n,2}\\;\\;\\cdots\\;\\ ; \\left(\\prod_{s=1}^{p-1}(a^{[2]})^{t_{s+1}-t_{s}-1}a^{[1]}\\right)c_{n , p+1 } \\right]\\right ] \\label{eqn:12}\\ ] ] is of full row rank , in which @xmath239}\\;\\;a^{[1]}(a^{[2]})^{t_{2}-t_{1}-1}g^{[1]}\\;\\;\\cdots\\;\\ ; \\left(\\prod_{s=1}^{p-1}a^{[1]}(a^{[2]})^{t_{s+1}-t_{s}-1}\\right)g^{[1]}\\right ] \\\\ & & c_{n , i}=\\left[g^{[2]}\\;\\;a^{[2]}g^{[2]}\\;\\ ; \\cdots\\;\\ ; ( a^{[2]})^{t_{i}-t_{i-1}-2}g^{[2]}\\right],\\hspace{0.5cm}i=1,2,\\cdots , p+1\\end{aligned}\\ ] ]    from these results , some sufficient conditions can be obtained for the existence of a finite positive integer @xmath228 , such that a map defined in a similar way as that of equation ( [ eqn:9 ] ) is strictly contractive .",
    "there exists a finite binary sequence @xmath240}(t)|_{t=1}^{n}$ ] with @xmath228 a finite positive integer , such that the corresponding matrices @xmath241}(t)}|_{t=1}^{n}$ ] satisfy    * @xmath242}(t)}$ ] belongs to @xmath120 , if there exists an integer @xmath243 belonging to @xmath244 $ ] , such that the matrix pair @xmath245}(a^{[2]})^{m},\\;h^{[1]})$ ] is observable . *",
    "@xmath242}(t)}$ ] belongs to @xmath121 , if one of the following conditions are satisfied .",
    "* * there exists an integer @xmath243 belonging to @xmath244 $ ] , such that the matrix pair @xmath245}(a^{[2]})^{m},\\;g^{[1]})$ ] is controllable ; * * the matrix pair @xmath246},\\;g^{[2]})$ ] is controllable ; * * there exists an integer @xmath243 belonging to @xmath244 $ ] , such that the matrix pair @xmath247})^{m}a^{[1]},\\;g^{[2]})$ ] is controllable .",
    "* @xmath242}(t)}$ ] belongs to @xmath122 , if both the above observability condition and one of the above controllability conditions are satisfied simultaneously .",
    "assume that there exists an integer @xmath243 , such that @xmath248 and the matrix pair @xmath245}(a^{[2]})^{m},\\;h^{[1]})$ ] is observable .",
    "designate @xmath228 and @xmath249 respectively as @xmath250 and @xmath251 , @xmath252 .",
    "then , @xmath228 is of a finite value .",
    "moreover , from the observability of @xmath245}(a^{[2]})^{m},\\;h^{[1]})$ ] and the definition of the matrix @xmath232 in equation ( [ eqn:11 ] ) , it can be declared that the matrix @xmath232 is of full column rank .",
    "it can therefore be claimed from theorem 3 that @xmath242}(t)}\\in { \\cal h}_{l}$ ] .",
    "note that both the matrix @xmath218}$ ] and the matrix @xmath219}$ ] are assumed invertible .",
    "it can therefore be declared from the definition of the matrix @xmath237 in equation ( [ eqn:12 ] ) that , @xmath237 is of full row rank if any of the matrices @xmath253 , @xmath254 , has this property .",
    "the remaining arguments are similar to those for showing the existence of a finite integer @xmath228 such that @xmath242}(t)}\\in { \\cal h}_{l}$ ] , and are therefore omitted .",
    "from the definitions of the sets @xmath120 , @xmath121 and @xmath122 , it is obvious that a matrix @xmath255 belongs to @xmath122 if and only if it simultaneously belongs to both @xmath120 and @xmath121 . on the other hand , if there exist positive integers @xmath256 and @xmath228 with @xmath257 such that @xmath258}(t)}\\in { \\cal h}_{l}$ ] and @xmath259}(t)}\\in { \\cal h}_{r}$ ] , then , it can be claimed from lemma 2 that @xmath242}(t)}$ ] belongs to both the set @xmath120 and the set @xmath121 , and therefore @xmath242}(t)}\\in { \\cal h}_{lr}$ ] .",
    "similarly , if there exist positive integers @xmath256 and @xmath228 with @xmath257 such that @xmath258}(t)}\\in { \\cal h}_{r}$ ] and @xmath259}(t)}\\in { \\cal h}_{l}$ ] , then , @xmath242}(t)}$ ] also belongs to the set @xmath122 .",
    "the conclusions about the existence of a finite integer @xmath228 such that @xmath242}(t)}\\in { \\cal h}_{lr}$ ] are therefore straightforward results of those for @xmath242}(t)}\\in { \\cal h}_{l}$ ] and @xmath242}(t)}\\in { \\cal h}_{r}$ ] .",
    "this completes the proof .",
    "@xmath209    in the above proof , a periodic @xmath240}(t)|_{t=1}^{n}$ ] is constructed to derive conditions for the existence of a finite integer @xmath228 such that @xmath260 belongs respectively to the sets @xmath120 , @xmath121 and @xmath122 .",
    "these conditions are generally conservative but are simple to verify , noting that both controllability and observability are wildly accepted concepts in system analysis and synthesis , and various efficient methods have been developed to check these properties for a given dynamic system .",
    "if the matrices @xmath218}$ ] and @xmath219}$ ] have the property that @xmath218}a^{[2]}=a^{[2]}a^{[1]}$ ] , then , less conservative results can be derived .",
    "the details are omitted due to space considerations .",
    "these conditions are very important in investigating asymptotic properties of rseio , which becomes clear in the following theorem 5 .",
    "it remains interesting to establish less conservative but easily verifiable conditions for the existence of a finite integer @xmath228 , such that the matrices @xmath232 in equation ( [ eqn:11 ] ) and @xmath237 in equation ( [ eqn:12 ] ) are respectively of full column rank and of full row rank .    on the other hand , if @xmath218}=a^{[2]}$ ] and @xmath220}=g^{[2]}$ ] are simultaneously satisfied , then , it is straightforward to show that the matrix @xmath232 in equation ( [ eqn:11 ] ) is of full column rank if and only if the matrix pair @xmath245},\\;h^{[1]})$ ] is observable , while the matrix @xmath237 in equation ( [ eqn:12 ] ) is of full row rank if and only if the matrix pair @xmath245},\\;g^{[1]})$ ] is controllable .",
    "this means that if the dynamic system @xmath27 is time invariant and its state space model is accurate , then , the existence of a finite positive integer @xmath228 such that the matrix product @xmath260 belongs to the set @xmath122 is equivalent to its simultaneous controllability and observability , which is consistent with that reported in @xcite .    to investigate the asymptotic property of rseio",
    ", probability should be investigated about the existence of strictly contractive mappings among the random mvfs defined in a similar way as that of equation ( [ eqn:9 ] ) . for this purpose ,",
    "some symbols are introduced which are some modifications of those adopted in @xcite .",
    "let @xmath261}$ ] represent a finite random sequence @xmath262 with @xmath32 takes values only from the set @xmath263 .",
    "let @xmath264}$ ] denote the set consisting of all binary sequences of length @xmath228 , that is , @xmath265}=\\left\\{\\;s_{m}^{[n]}\\;\\left|\\;s_{m}^{[n]}=\\{\\;s_{m}^{[n]}(i)|_{i=1}^{n}\\;\\},\\ ; s_{m}^{[n]}(i)\\in\\{0,\\;1\\},\\;m=\\sum_{i=1}^{n}2^{i-1}s_{m}^{[n]}(i)\\;\\right.\\right\\}\\ ] ] then , it is clear that the set @xmath264}$ ] have exactly @xmath266 elements , and every element is a realization of the finite random sequence @xmath261}$ ] .",
    "the following results are some extensions and modifications of those of @xcite .",
    "their proof is given in the appendix .    for an arbitrary positive integer @xmath228 ,",
    "let @xmath267}$ ] denote the @xmath268-th element of the set @xmath269}$ ] .",
    "then ,    * if the stochastic sequence @xmath215 is a series of independent random variables with the bernoulli distribution of a constant expectation @xmath270 , then , @xmath271}=s_{m}^{[n]}\\right)\\right]={\\rm log}(\\bar{\\gamma})\\sum_{i=1}^{n}s_{m}^{[n]}(i)+{\\rm log}(1-\\bar{\\gamma})\\left(n-\\sum_{i=1}^{n}s_{m}^{[n]}(i)\\right)\\ ] ] * if the random sequence @xmath215 is a markov chain with a transition probability matrix @xmath272 $ ] and @xmath273 , in which both @xmath274 and @xmath275 belong to @xmath276 . then , @xmath277}\\!=\\!s_{m}^{[n]}\\right)\\!\\right]\\!\\!\\!\\!&=&\\!\\!\\!\\!(n\\!-\\!1){\\rm log}(\\beta)\\!+\\!{\\rm log}\\!\\left(\\!\\frac{1\\!-\\!\\alpha}{\\beta}\\!\\right)\\!\\sum_{k=1}^{n-1}\\!s_{m}^{[n]}(k)\\!+\\!{\\rm log}\\!\\left(\\!\\frac{1}{\\beta}\\!-\\!1\\!\\right)\\!\\sum_{k=2}^{n}s_{m}^{[n]}(k)\\!+\\nonumber\\\\ & & \\!\\!\\!\\!\\hspace*{2cm}{\\rm log}\\!\\left(\\!\\frac{\\alpha\\beta}{(1\\!-\\!\\alpha)(1\\!-\\!\\beta)}\\!\\right)\\!\\sum_{k=2}^{n}\\!\\left[\\!s_{m}^{[n]}(k)s_{m}^{[n]}(k\\!-\\!1)\\!\\right]\\!+\\nonumber\\\\ & & \\!\\!\\!\\",
    "log}\\!\\left\\{\\!s_{m}^{[n]}(1)\\!+\\![1\\!-\\!2s_{m}^{[n]}(1)][\\beta\\!+\\!\\bar{\\gamma}(1\\!-\\!\\alpha\\!-\\!\\beta)]\\!\\right\\}\\end{aligned}\\ ] ]    lemma 4 makes it clear that for an identically and independently distributed ( i.i.d . ) bernoulli process , if its expectation is greater than @xmath34 , then , for any positive integer @xmath228 and any element @xmath267}$ ] of the set @xmath264}$ ] that does not take a constant value , the probability that the random sequence @xmath261}$ ] has a realization @xmath267}$ ] is greater than @xmath34 .",
    "that is , when @xmath278 , except the element @xmath267}$ ] with @xmath279 or @xmath280 , every other element of the set @xmath269}$ ] has a positive probability to become a realization of the random sequence @xmath261}$ ] . on the other hand , when the random sequence @xmath32 is described by a markov chain ,",
    "then , if @xmath281 , every element of the set @xmath264}$ ] with @xmath282 , can also be realized by the random sequence @xmath261}$ ] with a positive probability .",
    "similar results can be derived for situations in which random measurement droppings are described by other stochastic process , such as a semi - markov chain , etc .",
    "the details are not included for space considerations .    from the above results ,",
    "a convergence property can be established for the pcm @xmath74 of rseio .",
    "its proof is provided in the appendix .    for",
    "the dynamic system @xmath283 with @xmath94 , @xmath177 and @xmath178 invertible , assume that there exist two positive integers @xmath284 and @xmath285 such that the matrix pair @xmath245}(a^{[2]})^{m_{1}},\\;h^{[1]})$ ] is observable and one of the following three conditions is satisfied ,    * the matrix pair @xmath245}(a^{[2]})^{m_{2}},\\;g^{[1]})$ ] is controllable ; * the matrix pair @xmath247})^{m_{2}}a^{[1]},\\;g^{[2]})$ ] is controllable ; * the matrix pair @xmath246},\\;g^{[2]})$ ] is controllable .",
    "then , the pcm @xmath74 of rseio converges to a stationary distribution with probability one that is independent of its initial value @xmath194 , provided that one of the following two conditions is satisfied by the random measurement dropping process @xmath32 ,    * at every sampled time instant @xmath31 , the random dropping is an i.i.d .",
    "bernoulli variable with a positive expectation ; * the random dropping process can be described by a markov chain with a transition probability matrix @xmath286 $ ] and @xmath281 .",
    "the above theorem gives some sufficient conditions for the convergence of the pcm @xmath74 of rseio .",
    "note that for a @xmath287 dimensional matrix @xmath288 , from the hamiltonian - cayley theorem @xcite , we know that @xmath289 with any @xmath290 can be expressed as a linear combination of @xmath291 , @xmath292 . from this result and the discussions after corollary 2 , straightforward algebraic manipulations show that if the dynamic system @xmath27 is time invariant and has an accurate state space model , then , simultaneous observability of the matrix pair @xmath245},\\;h^{[1]})$ ] and controllability of the matrix pair @xmath245},\\;g^{[1]})$ ] are in fact necessary and sufficient condition on the system matrices .",
    "these mean that the conditions of theorem 5 reduce to those of @xcite in which asymptotic properties of the covariance matrix is investigated for kfio . however , when there are modelling errors , observability of @xmath245},\\;h^{[1]})$ ] and controllability of @xmath245},\\;g^{[1]})$ ] or @xmath246},\\;g^{[2]})$ ] are _ only _ sufficient conditions .",
    "this implies that more opportunities exist for the convergence of the pcm @xmath74 when the plant system matrices are not accurate .",
    "note that the gain matrix of rseio is equal to @xmath293 at the time instant @xmath31 when @xmath49 contains information about plant output , and is equal to @xmath34 in other situations .",
    "sufficient conditions can be derived directly from theorem 5 for the convergence of this gain matrix . on the other hand , it is worthwhile to point out that estimation accuracy is a very important performance index for estimators , which is usually reflected by the covariance matrix of estimation errors . while the pcm of the rseio is closely related to the covariance matrix of its estimation errors , these two matrices are not equal to each other in general .",
    "it is expected that through some arguments similar to those of @xcite , some asymptotic properties can be established for an upper bound of the covariance matrix of estimation errors of rseio .",
    "this establishment , of course , requires some assumptions on the parametric modelling errors , such as their variation intervals and/or statistical distributions , etc .",
    "this is an interesting issue under current investigations .",
    "due to space considerations , detailed discussions are omitted .",
    "results of theorem 5 can be easily extended to other descriptions of the random measurement dropping process .",
    "however , this theorem only establishes existence of a stationary distribution for the pcm matrix @xmath74 .",
    "further efforts are still required to derive an explicit expression for this stationary distribution .",
    "to illustrate estimation performances of the developed estimation algorithm , some numerical simulation results are reported in this section .",
    "the plant is selected to be the same as that of @xcite which has the following system matrices , initial conditions , and covariance matrices for process noises and measurement errors , respectively .",
    "@xmath294\\!+\\!\\left[\\!\\!\\begin{array}{c } 0.0198 \\\\ 0 \\end{array}\\!\\!\\right]\\!\\varepsilon_{t}\\left[0\\;\\ ; 5\\right],\\hspace{0.2 cm } b_{t}(\\varepsilon_{t})\\!=\\!\\left[\\!\\!\\begin{array}{cc } 1 & 0 \\\\ 0 & 1 \\end{array}\\!\\!\\right],\\hspace{0.2 cm } q_{t}\\!=\\!\\left[\\!\\!\\begin{array}{cc } 1.9608 & 0.0195 \\\\ 0.0195 & 1.9605 \\end{array}\\!\\!\\right ] \\\\ & & c_{t}(\\varepsilon_{t})=[1\\;\\ ; -1],\\hspace{0.5 cm } r_{t}=1,\\hspace{0.5 cm } { \\rm\\bf e}\\{x_{0}\\}=[1\\;\\;0]^{t},\\hspace{0.5 cm } p_{0}=i_{2}\\end{aligned}\\ ] ] in which @xmath29 stands for a time varying parametric error that is independent of each other and has a uniform distribution over the interval @xmath295 $ ] . the measurement dropping process @xmath32 is assumed to be a stationary bernoulli process with its expectation equal to @xmath296 . to compare estimation accuracy of different methods ,",
    "the estimator design parameter @xmath51 is at first selected to be the same as that of @xcite , that is , @xmath297 .    :",
    "kalman filter ; @xmath298",
    ": estimator of @xcite ; @xmath299 : estimator of @xcite ; @xmath300 : estimator of @xcite ; @xmath301 : estimator of this paper.,title=\"fig:\",width=211 ] : kalman filter ; @xmath298 : estimator of @xcite ; @xmath299 : estimator of @xcite ; @xmath300 : estimator of @xcite ; @xmath301 : estimator of this paper.,title=\"fig:\",width=211 ]    : kalman filter ; @xmath298 : estimator of @xcite ; @xmath299 : estimator of @xcite ; @xmath300 : estimator of @xcite ; @xmath301 : estimator of this paper.,title=\"fig:\",width=211 ] : kalman filter ; @xmath298 : estimator of @xcite ; @xmath299 : estimator of @xcite ; @xmath300 : estimator of @xcite ; @xmath301 : estimator of this paper.,title=\"fig:\",width=211 ]    : kalman filter ; @xmath298 : estimator of @xcite ; @xmath299 : estimator of @xcite ; @xmath300 : estimator of @xcite ; @xmath301 : estimator of this paper.,title=\"fig:\",width=211 ] : kalman filter ; @xmath298 : estimator of @xcite ; @xmath299 : estimator of @xcite ; @xmath300 : estimator of @xcite ; @xmath301 : estimator of this paper.,title=\"fig:\",width=211 ]    kalman filter , kfio of @xcite , rse of @xcite , the rse with missing measurements ( rsemm ) developed in @xcite , as well as the rse developed in this paper ( rseio ) , are utilized to estimate the plant states . when the kalman filter , rse of @xcite and rsemm are utilized , every received @xmath49 is regarded as a plant output measurement .",
    "empirical mse is used to measure estimation accuracy of these methods .",
    "more precisely , @xmath302 numerical experiments are performed with the temporal variable @xmath31 varies from @xmath34 to @xmath303 .",
    "let @xmath304}$ ] and @xmath305}$ ] represent respectively the actual plant state and its estimate at the time instant @xmath31 in the @xmath11-th numerical experiment .",
    "then , the empirical mse of estimations at this time instant is defined as follows @xmath306}-\\hat{x}_{t}^{[j]}]^{t}[x_{t}^{[j]}-\\hat{x}_{t}^{[j]}]\\ ] ]    in figure 1a , simulation results with @xmath307 is shown .",
    "this case is completely the same as that of @xcite . to make the differences among these curves clear when the temporal variable @xmath31 takes a large value , in figure 1b , they are re - plotted for the time interval @xmath308 . from these simulations",
    ", it becomes clear that when modelling errors fall into the interval @xmath309 $ ] , kfio outperforms rseio .",
    "this is not a surprise , but only means that for this numerical example , estimation accuracy of the kalman filter is not very sensitive to modelling errors , and in order to make a better trade - off between nominal performance and accuracy deteriorations , a greater value should be selected for the design parameter @xmath51 of rseio . as a matter of fact",
    ", actual computations show that if this design parameter is selected to be @xmath310 , then , rseio will have a slightly higher estimation accuracy than kfio .",
    "the corresponding results are given in figures 1c and 1d .",
    "to clarify necessities to take into account of modelling errors in state estimations , as well as influences of the design parameter @xmath51 on estimation accuracy , simulation results with @xmath311 and @xmath297 are also provided in figures 1e and 1f .",
    "results of these sub - figures clearly show that when the magnitude of modelling errors is large , sensitivity reduction for the innovation process of the kalman filter is really very helpful in increasing its robustness against parametric modelling errors , and therefore improve its estimation accuracy .",
    "it is also clear from these simulation results that an appropriate selection of the estimator design parameter @xmath51 heavily depends on specific descriptions of modelling errors , such as their variation intervals , etc .    in all these computations",
    ", rseio has a better estimation accuracy than both rse of @xcite and rsemm of @xcite .",
    "this result may imply that information about random measurement droppings is more efficiently utilized by the estimation procedure of this paper , and the cost function @xmath75 of equation ( [ eqn:7 ] ) is more physically reasonable than that adopted in @xcite when information is contained in @xmath78 about whether or not it is a plant output measurement .",
    "these simulation results also show that kfio outperforms the traditional kalman filter appreciably , but in comparison with rse of @xcite , accuracy improvement by rsemm is not very significant .    .",
    "@xmath299 : @xmath312 ; @xmath313 : @xmath314 ; @xmath315 : @xmath316 ; @xmath298 : @xmath317 . ,",
    "title=\"fig:\",width=211 ] .",
    "@xmath299 : @xmath312 ; @xmath313 : @xmath314 ; @xmath315 : @xmath316 ; @xmath298 : @xmath317 . ,",
    "title=\"fig:\",width=211 ]    .",
    "@xmath299 : @xmath312 ; @xmath313 : @xmath314 ; @xmath315 : @xmath316 ; @xmath298 : @xmath317 . , title=\"fig:\",width=211 ] .",
    "@xmath299 : @xmath312 ; @xmath313 : @xmath314 ; @xmath315 : @xmath316 ; @xmath298 : @xmath317 . , title=\"fig:\",width=211 ]    in figure 2 , empirical probability density function ( epdf ) is shown for every element of the pcm @xmath74 at @xmath318 with 4 different initial @xmath194 . in computing these epdfs",
    ", @xmath302 independent numerical experiments have been performed for each situation and the matlab file _ ksdensity.m _ is used with default parameters in estimating the epdf . moreover , the magnitude bound of modelling errors and the rseio design parameter are respectively selected as @xmath311 and @xmath297 . from this figure , it is clear that although the initial @xmath194s are significantly distinct from each other , the epdfs are very close for every element of the final @xmath319 .",
    "this confirms the theoretical results on the convergence of the resio . on the other hand",
    ", it appears that the pdf of every element of the stationary pcm is a continuous function , which is greatly different from the conclusion about kfio , in which it has been demonstrated in @xcite that the stationary distribution has a fractured support .",
    "moreover , the epdfs of the non - diagonal elements are almost the same .",
    "this is due to the symmetry of the pcm .",
    "it is worthwhile to point out that the comparisons of @xcite , in both its theoretical analyzes and its numerical simulations , are not appropriate , noting that in @xcite , a one - step recursive robust state predictor is derived , while the problem discussed in @xcite is to robustly estimate plant state using current and past observations .",
    "in fact , from figure 1 , it is clear that estimation accuracy of rsemm is even slightly worse than the traditional kalman filter , in which neither parametric errors nor random measurement droppings are taken into account .",
    "however , it is declared in @xcite that rsemm is slightly better than the estimator of @xcite , while @xcite claims its superiority over the traditional kalman filter in prediction accuracies .",
    "these conclusions are apparently contradictory .",
    "moreover , the numerical examples adopted in these two papers are completely different .",
    "in addition , time averaging is adopted in @xcite for estimation accuracy evaluations , but @xcite used ensemble averaging .",
    "these differences make the comparisons more unreasonable and the conclusions more confusing .",
    "regretfully , these important things have been overlooked by this author .",
    "in this paper , the sensitivity penalization based robust state estimation procedure is extended to situations in which plant output measurements may be randomly dropped due to communication failures .",
    "a new recursion formula has been derived for the pcm of estimation errors .",
    "necessary and sufficient conditions have been established for the strict contractiveness of an iteration of this recursion .",
    "it has been proved that under some controllability and observability conditions , as well as some weak restrictions on the arrival probability of plant output measurements , the gain matrix of the developed rse converges with probability one to a stationary distribution .",
    "numerical simulations show that this rse may outperform the well known kalman filter in estimation accuracy .",
    "while some progress have been made in robust state estimations with random measurement droppings , various important issues ask for further efforts . among them , more general and less conservative conditions for the convergence of the obtained rse , explicit expressions for the stationary distribution of the pcm , etc . , seem essential in determining required capacity of a communication channel and selecting a suitable estimator design parameter .",
    "in order to prove the theoretical results of this paper , the following results are required , which are well known in matrix analysis and linear estimations , and can be straightforwardly proved through algebraic manipulations @xcite .    for arbitrary matrices",
    "@xmath320 with compatible dimensions , assume that all the involved matrix inverses exist .",
    "then @xmath321= \\left[\\begin{array}{cc } i & 0 \\\\ ca^{-1 } & i \\end{array}\\right ] \\left[\\begin{array}{cc } a & 0 \\\\ 0 & d - ca^{-1}b \\end{array}\\right ] \\left[\\begin{array}{cc } i & a^{-1}b \\\\ 0 & i \\end{array}\\right]\\nonumber\\\\ & & \\hspace*{2cm}= \\left[\\begin{array}{cc } i & bd^{-1 } \\\\ 0 & i \\end{array}\\right ] \\left[\\begin{array}{cc } a - bd^{-1}c & 0 \\\\ 0 & d \\end{array}\\right ] \\left[\\begin{array}{cc } i & 0 \\\\ d^{-1}c & i \\end{array}\\right ] \\\\ & & [ a+cbd]^{-1}=a^{-1}-a^{-1}c[b^{-1}+da^{-1}c]^{-1}da^{-1 } \\\\ & & a(i+ba)^{-1}=(i+ab)^{-1}a\\end{aligned}\\ ] ]    for brevity , define vectors @xmath322 and @xmath323 respectively as @xmath324 and @xmath325 . moreover , define matrices @xmath326 , @xmath327 , @xmath328 and @xmath329",
    "respectively as @xmath330^{-1 } \\\\ & & \\hspace*{-1 cm } \\bar{b}_{t}(0)=b_{t}(0)-\\lambda_{t}\\gamma_{t+1}a_{t}(0)\\bar{p}_{t|t}s_{t}^{t}t_{t},\\hspace{0.25 cm } \\bar{a}_{t}(0)=[a_{t}(0)-\\lambda_{t}\\gamma_{t+1}\\bar{b}_{t}(0)\\bar{q}_{t}t_{t}^{t}s_{t}][i-\\lambda_{t}\\gamma_{t+1}\\bar{p}_{t|t}s_{t}^{t}s_{t}]\\end{aligned}\\ ] ] furthermore , abbreviate @xmath94 , @xmath329 , @xmath95 , @xmath328 and @xmath96 respectively as @xmath187 , @xmath331 , @xmath188 , @xmath332 and @xmath333 . note that for every @xmath334 , we have @xmath335 then , from the definition of the cost function @xmath83 , it can be straightforwardly proved that @xmath336\\alpha_{t}\\!\\!-\\!\\!y_{t+1})\\!\\!+\\!\\!\\lambda_{t}\\gamma_{t\\!+\\!1}(\\star)^{t}([s_{t}\\ ; t_{t}]\\alpha_{t})\\!\\!\\right\\}\\ ] ] therefore , @xmath337)^{t}r_{t+1}^{-1}(c_{t+1}[a_{t}\\ ; b_{t}]\\alpha_{t}\\!-\\!y_{t+1})\\!+\\!\\right.\\nonumber\\\\ & & \\hspace*{8.5cm}\\left.\\lambda_{t}\\gamma_{t+1}[s_{t}\\;t_{t}]^{t}[s_{t}\\ ; t_{t}]\\alpha_{t}\\!\\!\\right\\}\\nonumber\\\\ & = & \\!\\!\\!\\!\\mu_{t}\\!\\left\\{\\!\\!\\left(\\!\\!{\\rm\\bf diag}\\!\\left\\{\\ ! p_{t|t}^{-1}\\!,\\;\\ !",
    "q_{t}^{-1 } \\!\\right\\}+\\lambda_{t}\\gamma_{t\\!+\\!1}\\![s_{t}\\;t_{t}]^{t}[s_{t}\\ ; t_{t}]\\!+\\!\\gamma_{t\\!+\\!1}[a_{t}\\;b_{t}]^{t}c_{t\\!+\\!1}^{t}r_{t\\!+\\!1}^{-1}c_{t\\!+\\!1}[a_{t}\\ ; b_{t}]\\!\\!\\right)\\!\\!\\alpha_{t}\\!-\\right.\\nonumber\\\\ & & \\hspace*{4cm}\\left . { \\rm\\bf diag}\\left\\{\\!p_{t|t}^{-1},\\;q_{t}^{-1 } \\!\\right\\}\\alpha_{t0}-\\gamma_{t+1}[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\}\\end{aligned}\\ ] ]    note that @xmath338 is a convex function and @xmath339 .",
    "it is obvious that the optimal @xmath322 , denote it by @xmath340 , which minimizes @xmath338 , is given by its first derivative condition .",
    "that is , @xmath341^{t}[s_{t}\\ ; t_{t}]+\\gamma_{t+1}[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}[a_{t}\\ ; b_{t}]\\!\\!\\right\\}^{-1}\\times\\nonumber\\\\ & & \\hspace*{3cm}\\left\\{{\\rm\\bf diag}\\left\\{\\!p_{t|t}^{-1},\\;\\ !",
    "q_{t}^{-1 } \\!\\right\\}\\alpha_{t0}+\\gamma_{t+1}[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\ } \\label{eqn : a1}\\end{aligned}\\ ] ]    on the other hand , direct algebraic manipulations show that @xmath342^{-1}s_{t}^{t}t_{t}= t_{t}^{t}[i+\\lambda_{t}\\gamma_{t+1}s_{t}p_{t|t}s_{t}^{t}]^{-1}t_{t}\\ ] ] then , from lemma a1 and the definitions of the matrices @xmath326 and @xmath327 , the following relation can be immediately obtained , @xmath343^{t}[s_{t}\\ ; t_{t}]\\!\\!=\\!\\!\\left[\\!\\!\\begin{array}{cc } i & 0 \\\\ \\lambda_{t}\\gamma_{t\\!+\\!1}t_{t}^{t}s_{t}\\bar{p}_{t|t } & i \\end{array}\\!\\!\\right]\\ !",
    "\\left[\\!\\!\\begin{array}{cc } \\bar{p}_{t|t}^{-1 } & 0 \\\\ 0 & \\bar{q}_{t}^{-1 } \\end{array}\\!\\!\\right ] \\left[\\!\\!\\begin{array}{cc } i & \\lambda_{t}\\gamma_{t\\!+\\!1}\\bar{p}_{t|t}s_{t}^{t}t_{t } \\\\ 0 & i \\end{array}\\!\\!\\right ] \\label{eqn : a2}\\ ] ]    substitute this relation into equation ( [ eqn : a1 ] ) , it can be further proved that @xmath344 \\left[\\begin{array}{cc } \\bar{p}_{t|t}^{-1 } & 0 \\\\ 0 & \\bar{q}_{t}^{-1 } \\end{array}\\right ] \\left[\\begin{array}{cc } i & \\lambda_{t}\\gamma_{t+1}\\bar{p}_{t|t}s_{t}^{t}t_{t } \\\\ 0 & i \\end{array}\\right]+\\right.\\nonumber\\\\ & & \\hspace*{0.5cm}\\left.\\gamma_{t+1}[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}[a_{t}\\ ;",
    "b_{t}]\\!\\!\\right\\}^{-1}\\left\\{{\\rm\\bf diag}\\left\\{\\!p_{t|t}^{-1},\\ ; q_{t}^{-1}\\!\\right\\}\\alpha_{t0}+\\gamma_{t+1}[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\}\\nonumber\\\\ & = & \\!\\!\\left[\\begin{array}{cc } i & -\\lambda_{t}\\gamma_{t+1}\\bar{p}_{t|t}s_{t}^{t}t_{t } \\\\ 0 & i \\end{array}\\right]\\left\\{\\!\\!\\left[\\begin{array}{cc } \\bar{p}_{t|t}^{-1 } & 0 \\\\ 0 & \\bar{q}_{t}^{-1 } \\end{array}\\right]+\\gamma_{t+1}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}[a_{t}\\ ; \\bar{b}_{t}]\\!\\!\\right\\}^{-1}\\times\\nonumber\\\\ & & \\hspace*{3cm}\\left[{\\rm\\bf col}\\!\\!\\left\\{i,\\;\\ ! -\\lambda_{t}\\gamma_{t+1}t_{t}^{t}s_{t}\\bar{p}_{t|t}\\right\\}p_{t|t}^{-1}\\hat{x}_{t|t}+\\gamma_{t+1}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right]\\end{aligned}\\ ] ]    hence , @xmath345\\hat{\\alpha}_{t } \\nonumber\\\\ & = & \\!\\ ! [ a_{t}\\;\\bar{b}_{t}]\\left\\{\\!\\!{\\rm\\bf diag}\\left\\{\\!\\bar{p}_{t|t}^{-1},\\ ; \\bar{q}_{t}^{-1 } \\right\\}+\\gamma_{t+1}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}[a_{t}\\ ; \\bar{b}_{t}]\\!\\!\\right\\}^{-1}\\times\\nonumber\\\\ & & \\hspace*{3cm}\\left\\{{\\rm\\bf col}\\!\\!\\left\\{i,\\;\\ ! -\\lambda_{t}\\gamma_{t+1}t_{t}^{t}s_{t}\\bar{p}_{t|t}\\right\\}p_{t|t}^{-1}\\hat{x}_{t|t}+\\gamma_{t+1}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\ } \\nonumber\\\\ & = & \\!\\ ! [ a_{t}\\;\\bar{b}_{t}]\\left\\{\\!\\!i+\\gamma_{t+1}{\\rm\\bf diag}\\left\\{\\!\\bar{p}_{t|t},\\ ; \\bar{q}_{t}\\right\\}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}[a_{t}\\ ; \\bar{b}_{t}]\\!\\right\\}^{-1}{\\rm\\bf diag}\\left\\{\\!\\bar{p}_{t|t},\\;\\bar{q}_{t } \\!\\right\\}\\times\\nonumber\\\\ & & \\hspace*{3cm}\\left\\{{\\rm\\bf col}\\!\\!\\left\\{i,\\;\\ ! -\\lambda_{t}\\gamma_{t+1}t_{t}^{t}s_{t}\\bar{p}_{t|t}\\right\\}p_{t|t}^{-1}\\hat{x}_{t|t}+\\gamma_{t+1}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\}\\nonumber\\\\ & = & \\!\\ ! \\left\\{\\!\\!i+\\gamma_{t+1}[a_{t}\\;\\bar{b}_{t}]{\\rm\\bf diag}\\left\\{\\!\\bar{p}_{t|t},\\;\\bar{q}_{t } \\!\\right\\}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}\\!\\!\\right\\}^{-1}[a_{t}\\;\\bar{b}_{t}]{\\rm\\bf diag}\\left\\{\\!\\bar{p}_{t|t},\\;\\bar{q}_{t } \\!\\right\\}\\times\\nonumber\\\\ & & \\hspace*{3cm}\\left\\{{\\rm\\bf col}\\!\\!\\left\\{i,\\;\\ ! -\\lambda_{t}\\gamma_{t+1}t_{t}^{t}s_{t}\\bar{p}_{t|t}\\right\\}p_{t|t}^{-1}\\hat{x}_{t|t}+\\gamma_{t+1}[a_{t}\\;\\bar{b}_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\}\\nonumber\\\\ & = & \\!\\!\\left[i+\\gamma_{t+1}p_{t+1|t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}\\right]^{-1}\\left\\{\\bar{a}_{t}\\hat{x}_{t|t}+\\gamma_{t+1}p_{t+1|t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\}\\end{aligned}\\ ] ] in which @xmath346 . in the derivation of the last equality of the above equation ,",
    "the relation @xmath347 has been utilized , which is a direct result of the definition of the matrix @xmath326 .",
    "therefore , @xmath348^{-1}p_{t+1|t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\nonumber\\\\ & & \\hspace*{2 cm } -\\gamma_{t+1}\\left[i+\\gamma_{t+1}p_{t+1|t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}\\right]^{-1}p_{t+1|t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}\\bar{a}_{t}\\hat{x}_{t|t}\\nonumber\\\\ & = & \\!\\!\\bar{a}_{t}\\hat{x}_{t|t}+\\gamma_{t+1}\\left[p_{t+1|t}^{-1}+\\gamma_{t+1}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}\\right]^{-1}c_{t+1}^{t}r_{t+1}^{-1}\\left\\{y_{t+1 } -c_{t+1}\\bar{a}_{t}\\hat{x}_{t|t}\\right\\}\\end{aligned}\\ ] ]    comparing this recursive formula for @xmath85 with that of the kalman filter given in @xcite , it is clear that the matrix @xmath349^{-1}$ ] plays the same role as that of the covariance matrix of estimation errors in kalman filtering .",
    "it is therefore reasonable to denote it by @xmath174 .",
    "the proof can now be completed by noting that if @xmath93 , then @xmath350 , @xmath351 , @xmath352 and @xmath353 , as well as that if @xmath79 , then @xmath354 , @xmath355 , @xmath356 and @xmath357 .",
    "@xmath209    to simplify mathematical expressions , in this proof , @xmath94 , @xmath95 and @xmath358 are again respectively abbreviated to be @xmath187 , @xmath188 and @xmath359 . from the proof of theorem 1 ,",
    "it is clear that when @xmath79 , @xmath345\\left\\{\\!\\!{\\rm\\bf diag}\\left\\{\\!p_{t|t}^{-1},\\;\\ ! q_{t}^{-1 } \\!\\right\\}+\\lambda_{t}[s_{t}\\;t_{t}]^{t}[s_{t}\\ ; t_{t}]+[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}[a_{t}\\ ; b_{t}]\\!\\!\\right\\}^{-1}\\times\\nonumber\\\\ & & \\hspace*{3cm}\\left\\{{\\rm\\bf diag}\\!\\!\\left\\{\\!p_{t|t}^{-1},\\;q_{t}^{-1}\\!\\right\\}\\!{\\rm\\bf col}\\!\\!\\left\\{\\hat{x}_{t|t},\\ ; 0\\right\\}+[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}y_{t+1}\\right\\ } \\label{eqn : a4}\\end{aligned}\\ ] ] moreover , theorem 1 also declares that under such a situation , @xmath360 \\label{eqn : a5}\\ ] ]    as equations ( [ eqn : a4 ] ) and ( [ eqn : a5 ] ) are just two different expressions for the same state estimate @xmath85 , the coefficient matrices respectively for @xmath73 and @xmath78 should be equal to each other .",
    "a comparison of the coefficient matrices of @xmath78 show that @xmath361\\left\\{\\!\\!{\\rm\\bf diag}\\left\\{\\!p_{t|t}^{-1},\\;\\ !",
    "q_{t}^{-1 } \\!\\right\\}+\\lambda_{t}[s_{t}\\;t_{t}]^{t}[s_{t}\\ ; t_{t}]+[a_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}[a_{t}\\ ; b_{t}]\\!\\!\\right\\}^{\\!-1}\\!\\!\\!\\!\\![a_{t}\\;b_{t}]^{t } \\label{eqn : a6}\\ ] ]    on the other hand , direct algebraic operations show that @xmath362^{-1}t_{t}^{t}s_{t } & = & \\lambda_{t}s_{t}^{t}\\left\\{i-\\lambda_{t}t_{t}[i+\\lambda_{t}q_{t}t_{t}^{t}t_{t}]^{-1}q_{t}t_{t}^{t}\\right\\}s_{t}\\nonumber\\\\ & = & \\lambda_{t}s_{t}^{t}[i+\\lambda_{t}t_{t}q_{t}t_{t}^{t}]^{-1}s_{t}\\nonumber\\\\ & = & \\tilde{s}_{t}^{t}\\tilde{s}_{t}\\end{aligned}\\ ] ] then , from lemma a1 and the definition of @xmath363 , the following relation can be immediately obtained , @xmath364^{t}[s_{t}\\ ; t_{t}]\\!=\\ !",
    "\\left[\\!\\!\\begin{array}{cc } i & \\lambda_{t}s_{t}^{t}t_{t}\\check{q}_{t } \\\\ 0 & i \\end{array}\\!\\!\\right]\\ !",
    "\\left[\\!\\!\\begin{array}{cc } p_{t|t}^{-1}+\\tilde{s}_{t}^{t}\\tilde{s}_{t } & 0 \\\\ 0 & \\check{q}_{t}^{-1 } \\end{array}\\!\\!\\right]\\ !",
    "\\left[\\!\\!\\begin{array}{cc } i & 0 \\\\ \\lambda_{t}\\check{q}_{t}t_{t}^{t}s_{t } & i \\end{array}\\!\\!\\right ]",
    "\\label{eqn : a3}\\ ] ]    substitute equation ( [ eqn : a3 ] ) into equation ( [ eqn : a6 ] ) , we have @xmath365 \\left[\\!\\!\\begin{array}{cc } i & 0 \\\\ \\lambda_{t}\\check{q}_{t}t_{t}^{t}s_{t } & i \\end{array}\\!\\!\\right]^{\\!\\!-1}\\!\\right)\\!\\!\\left\\{\\!\\!\\left[\\!\\!\\begin{array}{cc } p_{t|t}^{-1}\\!+\\!\\tilde{s}_{t}^{t}\\tilde{s}_{t } & 0 \\\\ 0 & \\check{q}_{t}^{-1 } \\end{array}\\!\\!\\right]\\!+\\!\\left(\\!\\![a_{t}\\;b_{t } ] \\left[\\begin{array}{cc } i & 0 \\\\ \\lambda_{t}\\check{q}_{t}t_{t}^{t}s_{t } & i \\end{array}\\right]^{\\!\\!-1}\\!\\right)^{t}\\right.\\!\\!\\!\\!\\times\\nonumber\\\\ & & \\hspace*{0.5cm}\\left.c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}\\left([a_{t}\\ ; b_{t}]\\!\\!\\left[\\!\\!\\begin{array}{cc } i & 0 \\\\ \\lambda_{t}\\check{q}_{t}t_{t}^{t}s_{t } & i \\end{array}\\!\\!\\right]^{-1}\\!\\right)\\!\\!\\right\\}^{\\!-1}\\!\\!\\!\\!\\left(\\!\\![a_{t}\\;b_{t } ] \\!\\!\\left[\\!\\!\\begin{array}{cc } i & 0 \\\\ \\lambda_{t}\\check{q}_{t}t_{t}^{t}s_{t } & i \\end{array}\\!\\!\\right]^{-1}\\!\\right)^{t } \\nonumber\\\\ & = & \\!\\!\\!\\![\\check{a}_{t}\\;b_{t}]\\!\\!\\left\\{\\!\\!{\\rm\\bf diag}\\left\\{\\ ! p_{t|t}^{-1}\\!+\\!\\tilde{s}_{t}^{t}\\tilde{s}_{t},\\;\\check{q}_{t}^{-1 } \\!\\right\\}\\!+\\![\\check{a}_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1 } [ \\check{a}_{t}\\;b_{t}]\\!\\!\\right\\}^{-1}\\!\\![\\check{a}_{t}\\;b_{t}]^{t}\\nonumber\\\\ & = & \\!\\!\\!\\!\\left\\{\\!\\!i\\!+\\![\\check{a}_{t}\\;b_{t}]{\\rm\\bf diag}\\left\\{\\ ! ( p_{t|t}^{-1}\\!+\\!\\tilde{s}_{t}^{t}\\tilde{s}_{t})^{-1},\\;\\check{q}_{t } \\!\\right\\}\\!\\![\\check{a}_{t}\\;b_{t}]^{t}c_{t+1}^{t}r_{t+1}^{-1}c_{t+1}\\!\\!\\right\\}^{\\!\\!-1}\\!\\!\\!\\!\\times\\nonumber\\\\ & & \\hspace*{6cm}[\\check{a}_{t}\\;b_{t}]{\\rm\\bf diag}\\left\\{\\ ! ( p_{t|t}^{-1}\\!+\\!\\tilde{s}_{t}^{t}\\tilde{s}_{t})^{-1},\\ ; \\check{q}_{t}\\!\\right\\}\\!\\![\\check{a}_{t}\\;b_{t}]^{t}\\nonumber\\\\ & = & \\!\\!\\!\\!\\left\\{\\left[\\check{a}_{t}(p_{t|t}^{-1}\\!+\\!\\tilde{s}_{t}^{t}\\tilde{s}_{t})^{-1 } \\check{a}^{t}_{t}+b_{t}\\check{q}_{t}b_{t}^{t}\\right]^{-1}+c_{t+1}^{t}r_{t+1}c_{t+1}\\right\\}^{-1 }",
    "\\label{eqn : a7}\\end{aligned}\\ ] ]      note that @xmath367 ( i+\\right.\\nonumber\\\\ & & \\hspace{4cm}\\left.\\tilde{s}_{t}^{t}\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t})^{-1}\\tilde{s}_{t}^{t}\\tilde{s}_{t}-\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t } ( i+\\tilde{s}_{t}^{t}\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t})^{-1}\\tilde{s}_{t}^{t}\\tilde{s}_{t}\\right\\}\\nonumber\\\\ & = & \\!\\!\\!\\!\\tilde{s}_{t}^{t}(i+\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t})^{-1}\\tilde{s}_{t}+ \\left\\{\\tilde{b}_{t}(\\check{q}_{t}+\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t})\\tilde{b}_{t}^{t } + ( i+\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t})p_{t|t}\\!\\times\\right.\\nonumber\\\\ & & \\hspace{8cm}\\left .",
    "( i+\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t})^{t}\\right\\}^{-1 } \\label{eqn : a9}\\end{aligned}\\ ] ]    substitute equations ( [ eqn : a8 ] ) and ( [ eqn : a9 ] ) into equation ( [ eqn : a7 ] ) , the following recursive expression for @xmath174 is obtained for situations when @xmath177 is invertible , @xmath368^{-1}\\check{a}_{t}^{-1}+c_{t+1}^{t}r_{t+1}c_{t+1}\\nonumber\\\\ & = & \\!\\!\\!\\ ! \\check{a}_{t}^{-t}\\!\\ ! \\left\\{\\!\\!\\tilde{b}_{t}(\\check{q}_{t}\\!+\\!\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t})\\tilde{b}_{t}^{t } \\!+\\!(i\\!+\\!\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t})p_{t|t } ( i\\!+\\!\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t})^{t}\\!\\right\\}^{\\!-1}\\!\\ !",
    "\\check{a}_{t}^{\\!-1}\\!+\\nonumber\\\\ & & \\hspace*{4 cm } \\check{a}_{t}^{-t}\\tilde{s}_{t}^{t}(i+\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t})^{-1}\\tilde{s}_{t } \\check{a}_{t}^{-1}+c_{t+1}^{t}r_{t+1}c_{t+1}\\nonumber\\\\ & = & \\!\\!\\!\\!\\left\\{\\!\\!b_{t}(\\check{q}_{t}\\!+\\!\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t})b_{t}^{t } \\!+\\!(\\check{a}_{t}\\!+\\!b_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t})p_{t|t } ( \\check{a}_{t}\\!+\\!b_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t}\\tilde{s}_{t})^{t}\\!\\right\\}^{\\!-1}\\!\\!\\!+\\nonumber\\\\ & & \\hspace*{4 cm } ( \\tilde{s}_{t}\\check{a}_{t}^{-1})^{t}(i+\\tilde{s}_{t}\\tilde{b}_{t}\\check{q}_{t}\\tilde{b}_{t}^{t}\\tilde{s}_{t}^{t})^{-1}(\\tilde{s}_{t } \\check{a}_{t}^{-1})+c_{t+1}^{t}r_{t+1}c_{t+1}\\nonumber\\\\ & = & \\!\\!\\!\\![\\tilde{a}_{t}p_{t|t}\\tilde{a}_{t}^{t}+b_{t}\\tilde{q}_{t}b_{t}^{t}]^{-1}+\\tilde{c}_{t+1}^{t}\\tilde{r}_{t+1}^{-1}\\tilde{c}_{t+1}\\end{aligned}\\ ] ]        assume that at the sampling instants @xmath372 , with @xmath373 , @xmath374 ; and at any other sampling instants between @xmath33 and @xmath228 , @xmath375 .",
    "define @xmath376 as @xmath377 .",
    "then , according to the definition of @xmath212 , the following relation is obtained , @xmath378 \\label{eqn : a10}\\ ] ] in which @xmath379 is defined to be the identity matrix if @xmath380 .",
    "this situation occurs when @xmath381 .",
    "note that for every @xmath382 with @xmath383 , @xmath384t}h^{[1]t}h^{[1]}a^{[1 ] } = ( h^{[1]}a^{[1]})^{t}(h^{[1]}a^{[1 ] } ) \\label{eqn : a11}\\ ] ] moreover , @xmath385})^{t_{j+1}-t_{j}-1}a^{[1]}(a^{[2]})^{t_{j+2}-t_{j+1}-1}a^{[1]}\\cdots ( a^{[2]})^{n - t_{p } } \\nonumber\\\\ & = & \\left(\\prod_{s = j}^{p-1}\\left[(a^{[2]})^{t_{s+1}-t_{s}-1}a^{[1]}\\right]\\right ) ( a^{[2]})^{n - t_{p } } \\label{eqn : a12}\\end{aligned}\\ ] ]    substitute equations ( [ eqn : a11 ] ) and ( [ eqn : a12 ] ) into equation ( [ eqn : a10 ] ) , the following relation is obtained , @xmath386^{t } ( h^{[1]}a^{[1]})^{t}(h^{[1]}a^{[1 ] } ) \\left[\\!\\!\\left(\\prod_{s = j}^{p-1}\\left[(a^{[2]})^{t_{s+1}-t_{s}-1}a^{[1]}\\right]\\right ) ( a^{[2]})^{n - t_{p}}\\right)\\right\\}\\nonumber\\\\ & = & \\!\\!\\!\\!\\sum_{j=0}^{p}\\left\\{\\!\\!\\left[\\star\\right]^{t } \\left[h^{[1]}a^{[1]}\\left(\\prod_{s = j}^{p-1}\\left[(a^{[2]})^{t_{s+1}-t_{s}-1}a^{[1]}\\right]\\right ) ( a^{[2]})^{n - t_{p}}\\right)\\right\\}\\nonumber\\\\ & = & \\!\\!\\!\\!\\left[\\star\\right]^{t}\\left[\\begin{array}{c } h^{[1]}(a^{[2]})^{n - t_{p } } \\\\ h^{[1]}a^{[1]}(a^{[2]})^{t_{p}-t_{p-1}-1}(a^{[2]})^{n - t_{p } } \\\\ \\vdots \\\\ h^{[1]}\\prod_{j=1}^{p}\\left(a^{[1]}(a^{[2]})^{t_{j}-t_{j-1}-1}\\right)(a^{[2]})^{n - t_{p } } \\end{array}\\right]\\nonumber\\\\ & = & \\!\\!\\!\\ ! ( a^{[2]t})^{n - t_{p}}o_{b}^{t}o_{b}(a^{[2]})^{n - t_{p}}\\end{aligned}\\ ] ]    recall that the matrix @xmath219}$ ] is assumed invertible . it is obvious from the above equality that the satisfaction of the inequality @xmath387 is equivalent to that the matrix @xmath232 is of full column rank .",
    "this completes the proof .",
    "similar to the proof of theorem 3 , assume that at the sampling instants @xmath390 , with @xmath391 , @xmath374 ; and at any other sampling instants between @xmath33 and @xmath228 , @xmath375 .",
    "moreover , @xmath376 is once again defined as @xmath377 .",
    "furthermore , define @xmath392 as @xmath393 .",
    "when @xmath396 , assume that @xmath397 , @xmath398 .",
    "we have @xmath399}g^{[1]t}(a^{[1]})^{-t}\\right]a^{[1]t}=g^{[1]}g^{[1]t } \\\\",
    "\\prod_{k=1}^{i-1}\\phi_{k,11}\\!\\!\\!\\!&=&\\!\\!\\!\\!\\left(\\prod_{k=1}^{t_{1}-1}\\phi_{k,11}\\right)\\phi_{t_{1},11 } \\left(\\prod_{k = t_{1}+1}^{t_{2}-1}\\phi_{k,11}\\right)\\phi_{t_{2},11}\\cdots \\left(\\prod_{k = t_{j-1}+1}^{t_{j}-1}\\phi_{k,11}\\right)\\nonumber\\\\ & = & \\!\\!\\!\\!(a^{[2]})^{t_{1}-1}a^{[1]}(a^{[2]})^{t_{2}-t_{1}-1}a^{[1]}\\cdots ( a^{[2]})^{t_{j}-t_{j-1}-1}\\nonumber\\\\ & = & \\!\\!\\!\\!(a^{[2]})^{t_{1}-1}\\prod_{s=1}^{j-1}\\left[a^{[1]}(a^{[2]})^{t_{s+1}-t_{s}-1}\\right ] \\label{eqn : a15}\\end{aligned}\\ ] ]    when @xmath400 , assume that @xmath401 , @xmath402 . on the basis of equation ( [ eqn : a15 ] ) , we then have @xmath403}g^{[2]t}(a^{[2]})^{-t}\\right]a^{[2]t}=g^{[2]}g^{[2]t } \\\\",
    "\\prod_{k=1}^{i-1}\\phi_{k,11}\\!\\!\\!\\!&=&\\!\\!\\!\\!\\left(\\prod_{k=1}^{t_{j-1}-1}\\phi_{k,11}\\right)\\phi_{t_{j-1},11 } \\left(\\prod_{k = t_{j-1}+1}^{i-1}\\phi_{k,11}\\right)\\nonumber\\\\ & = & \\!\\!\\!\\!(a^{[2]})^{t_{1}-1}\\left(\\prod_{s=1}^{j-2}\\left[a^{[1]}(a^{[2]})^{t_{s+1}-t_{s}-1}\\right]\\right ) a^{[1]}(a^{[2]})^{i - t_{j-1}-1}\\end{aligned}\\ ] ]    when @xmath404 , direct algebraic manipulations show that @xmath403}g^{[2]t}(a^{[2]})^{-t}\\right]a^{[2]t}=g^{[2]}g^{[2]t } \\\\",
    "\\prod_{k=1}^{i-1}\\phi_{k,11}\\!\\!\\!\\!&=&\\!\\!\\!\\!\\prod_{k=1}^{i-1}a^{[2]}\\!=\\!\\left(a^{[2]}\\right)^{i-1}\\end{aligned}\\ ] ]    substitute these relations into equation ( [ eqn : a13 ] ) , the following equalities are obtained .",
    "@xmath405 + \\sum_{j=2}^{p+1}\\left\\{\\left[\\left(\\prod_{k=1}^{t_{j-1}-1 } \\phi_{k,11}\\right)\\phi_{t_{j-1},12}\\phi_{t_{j-1},11}^{t}\\left(\\star\\right)^{t}\\right]+\\right.\\nonumber\\\\ & & \\hspace*{6cm}\\left.\\sum_{i = t_{j-1}+1}^{t_{j}-1}\\left[\\left(\\prod_{k=1}^{i-1 } \\phi_{k,11}\\right)\\phi_{i,12}\\phi_{i,11}^{t}\\left(\\star\\right)^{t}\\right]\\right\\}\\nonumber\\\\ & = & \\!\\!\\!\\!\\sum_{i=0}^{t_{1}-2}\\left[\\left(a^{[2]}\\right)^{i}g^{[2]}\\right]\\left[\\star\\right]^{t}+ ( a^{[2]})^{t_{1}-1 } \\sum_{j=2}^{p+1}\\left\\{\\left(\\prod_{s=1}^{j-1}\\left[a^{[1]}(a^{[2]})^{t_{s+1}-t_{s}-1}\\right ] g^{[1]}\\right)\\left(\\star\\right)^{t}+\\right.\\nonumber\\\\ & & \\hspace*{0.5cm}\\left.\\sum_{i = t_{j-1}+1}^{t_{j}-1}\\left(a^{[1]}\\prod_{s=1}^{j-2}\\left[(a^{[2]})^{t_{s+1}-t_{s}-1}a^{[1]}\\right ] ( a^{[2]})^{i - t_{j-1}-1}g^{[2]}\\right)\\left(\\star\\right)^{t}\\right\\}(a^{[2]t})^{t_{1}-1}\\nonumber\\\\ & = & \\!\\!\\!\\!c_{o}c_{o}^{t}\\end{aligned}\\ ] ]      when @xmath408 is white and has a bernoulli distribution , we have @xmath409}=s_{m}^{[n]}\\right)&=&\\prod_{k = n}^{1}{\\rm\\bf p}_{r}\\left(\\gamma_{k}=s_{m}^{[n]}(k)\\right)\\nonumber \\\\ & = & \\prod_{k = n}^{1}\\bar{\\gamma}^{s_{m}^{[n]}(k)}(1-\\bar{\\gamma})^{1-s_{m}^{[n]}(k)}\\end{aligned}\\ ] ] hence , @xmath410}=s_{m}^{[n]}\\right)\\right]&=&\\sum_{i=1}^{n}\\left[s_{m}^{[n]}(k){\\rm",
    "log}\\!(\\bar{\\gamma})+(1-s_{m}^{[n]}(k)){\\rm log}\\!(1-\\bar{\\gamma})\\right]\\nonumber\\\\ & = & { \\rm log}(\\bar{\\gamma})\\sum_{i=1}^{n}s_{m}^{[n]}(i)+{\\rm log}(1-\\bar{\\gamma})\\left(n-\\sum_{i=1}^{n}s_{m}^{[n]}(i)\\right)\\end{aligned}\\ ] ]    when @xmath408 is a markov chain , @xmath411}=s_{m}^{[n]}\\right)=\\left\\{\\prod_{k = n}^{2}{\\rm\\bf p}_{r}\\left(\\left.\\gamma_{k}=s_{m}^{[n]}(k)\\right|\\gamma_{k-1}=s_{m}^{[n]}(k-1)\\right)\\right\\ } { \\rm\\bf p}_{r}\\left(\\gamma_{1}=s_{m}^{[n]}(1)\\right ) \\label{eqn:4}\\ ] ]    note that @xmath412}(1)\\right)=\\left\\{\\begin{array}{ll } ( 1-\\alpha){\\rm\\bf p}_{r}(\\gamma_{0}=1)+\\beta { \\rm\\bf p}_{r}(\\gamma_{0}=0 )    & s_{m}^{[n]}(1)=0 \\\\",
    "\\alpha{\\rm\\bf p}_{r}(\\gamma_{0}=1)+(1-\\beta){\\rm\\bf p}_{r}(\\gamma_{0}=0 )    & s_{m}^{[n]}(1)=1 \\end{array}\\right.\\ ] ] it can therefore be concluded from the assumption @xmath413 and the fact that @xmath414 that @xmath415}(1)\\right)&= & [ 1-s_{m}^{[n]}(1)]\\left[(1-\\alpha){\\rm\\bf p}_{r}(\\gamma_{0}=1)+\\beta { \\rm\\bf p}_{r}(\\gamma_{0}=0)\\right]+\\nonumber\\\\ & & \\hspace*{1cm}s_{m}^{[n]}(1)\\left[\\alpha{\\rm\\bf p}_{r}(\\gamma_{0}=1)+(1-\\beta){\\rm\\bf p}_{r}(\\gamma_{0}=0)\\right]\\nonumber\\\\ & = & s_{m}^{[n]}(1)\\!+\\![1\\!-\\!2s_{m}^{[n]}(1)][\\beta\\!+\\!\\bar{\\gamma}(1\\!-\\!\\alpha\\!-\\!\\beta ) ] \\label{eqn:5}\\end{aligned}\\ ] ]    on the other hand , for an arbitrary @xmath416 , it can be straightforwardly declared from the definition of a markov chain and the assumption @xmath281 that @xmath417}(k)\\right|\\gamma_{k-1}=s_{m}^{[n]}(k-1)\\right ) \\nonumber\\\\ & = & \\left\\{\\begin{array}{lll } \\alpha , & & s_{m}^{[n]}(k)=1,\\;s_{m}^{[n]}(k-1)=1 \\\\ 1-\\alpha , & & s_{m}^{[n]}(k)=1,\\;s_{m}^{[n]}(k-1)=0 \\\\",
    "\\beta , & & s_{m}^{[n]}(k)=0,\\;s_{m}^{[n]}(k-1)=1 \\\\ 1-\\beta , & \\;\\;\\;\\ ; & s_{m}^{[n]}(k)=0,\\;s_{m}^{[n]}(k-1)=0 \\end{array}\\right.\\nonumber\\\\ & = & \\alpha^{s_{m}^{[n]}(k)s_{m}^{[n]}(k-1)}(1-\\alpha)^{(1-s_{m}^{[n]}(k))s_{m}^{[n]}(k-1 ) } ( 1-\\beta)^{s_{m}^{[n]}(k)(1-s_{m}^{[n]}(k-1))}\\beta^{(1-s_{m}^{[n]}(k))(1-s_{m}^{[n]}(k-1 ) ) } \\nonumber\\\\ & = & \\beta\\left(\\frac{1-\\alpha}{\\beta}\\right)^{s_{m}^{[n]}(k-1)}\\left(\\frac{1-\\beta}{\\beta}\\right)^{s_{m}^{[n]}(k ) } \\left(\\frac{\\alpha\\beta}{(1-\\alpha)(1-\\beta)}\\right)^{s_{m}^{[n]}(k)s_{m}^{[n]}(k-1 ) } \\label{eqn:6}\\end{aligned}\\ ] ]    substitute equations ( [ eqn:5 ] ) and ( [ eqn:6 ] ) into equation ( [ eqn:4 ] ) , the following relation is obtained , @xmath277}\\!=\\!s_{m}^{[n]}\\right)\\!\\right]\\!\\!\\!\\!&=&\\!\\!\\!\\ ! \\sum_{k = n}^{2}{\\rm log}\\!\\left[{\\rm\\bf p}_{r}\\left(\\left.\\gamma_{k}=s_{m}^{[n]}(k)\\right|\\gamma_{k-1}=s_{m}^{[n]}(k-1)\\right)\\right ] + { \\rm log}\\!\\left[{\\rm\\bf p}_{r}\\left(\\gamma_{1}=s_{m}^{[n]}(1)\\right)\\right]\\nonumber\\\\ & = & \\!\\!\\!\\ ! \\sum_{k = n}^{2}\\left\\{{\\rm log}(\\beta)+ s_{m}^{[n]}(k-1){\\rm log}\\!\\left(\\frac{1-\\alpha}{\\beta}\\right ) + s_{m}^{[n]}(k){\\rm log}\\!\\left(\\frac{1-\\beta}{\\beta}\\right ) + \\right.\\nonumber\\\\ & & \\hspace*{2cm}\\left.s_{m}^{[n]}(k)s_{m}^{[n]}(k-1){\\rm log}\\!\\left(\\frac{\\alpha\\beta}{(1-\\alpha)(1-\\beta)}\\right)\\right\\}+\\nonumber\\\\ & & \\hspace*{2cm}{\\rm log}\\!\\left\\{s_{m}^{[n]}(1)\\!+\\![1\\!-\\!2s_{m}^{[n]}(1)][\\beta\\!+\\!\\bar{\\gamma}(1\\!-\\!\\alpha\\!-\\!\\beta)]\\right\\}\\nonumber\\\\ & = & \\!\\!\\!\\!(n\\!-\\!1){\\rm log}(\\beta)\\!+\\!{\\rm log}\\!\\left(\\!\\frac{1\\!-\\!\\alpha}{\\beta}\\!\\right)\\!\\sum_{k=1}^{n-1}\\!s_{m}^{[n]}(k)\\!+\\!{\\rm log}\\!\\left(\\!\\frac{1}{\\beta}\\!-\\!1\\!\\right)\\!\\sum_{k=2}^{n}s_{m}^{[n]}(k)\\!+\\nonumber\\\\ & & \\!\\!\\!\\!\\hspace*{2cm}{\\rm log}\\!\\left(\\!\\frac{\\alpha\\beta}{(1\\!-\\!\\alpha)(1\\!-\\!\\beta)}\\!\\right)\\!\\sum_{k=2}^{n}\\!\\left[\\!s_{m}^{[n]}(k)s_{m}^{[n]}(k\\!-\\!1)\\!\\right]\\!+\\nonumber\\\\ & & \\!\\!\\!\\",
    "! \\hspace*{2cm}{\\rm log}\\!\\left\\{\\!s_{m}^{[n]}(1)\\!+\\![1\\!-\\!2s_{m}^{[n]}(1)][\\beta\\!+\\!\\bar{\\gamma}(1\\!-\\!\\alpha\\!-\\!\\beta)]\\!\\right\\}\\end{aligned}\\ ] ]      assume that there exist two positive integers @xmath284 and @xmath285 such that the matrix pairs @xmath245}(a^{[2]})^{m_{1}},\\;h^{[1]})$ ] and @xmath247})^{m_{2}}a^{[1]},\\;g^{[2]})$ ] are respectively observable and controllable .",
    "then , the following two matrices @xmath418 and @xmath419 are respectively of full column rank and full row rank , @xmath420 } \\\\ h^{[1]}a^{[1]}(a^{[2]})^{m_{1 } } \\\\ \\vdots \\\\ h^{[1]}\\left(a^{[1]}(a^{[2]})^{m_{1}}\\right)^{n-1 } \\end{array}\\right],\\hspace{0.5 cm } \\bar{c}_{n}=\\left[g^{[2]}\\;\\ ; ( a^{[2]})^{m_{2}}a^{[1]}g^{[2 ] } \\cdots \\left((a^{[2]})^{m_{2}}a^{[1]}\\right)^{n-1}g^{[2]}\\right]\\ ] ]    define positive integers @xmath256 and @xmath228 , as well as a finite binary sequence @xmath240}=\\{r^{[n]}(t)|_{t=1}^{n}\\}$ ] , respectively as @xmath421 , @xmath422 , and @xmath423}(t)=\\left\\{\\begin{array}{lll } 0 & t\\in \\left(1+(j-1)(m_{1}+1),\\ ; 1+j(m_{1}+1)\\right)\\\\ 1 & t=1+(j-1)(m_{1}+1 ) \\\\ 0 & t = n_{*}+(j-1)(m_{2}+1)+1\\\\ 1 & t\\in \\left(n_{*}+(j-1)(m_{2}+1)+1,\\;n_{*}+j(m_{2}+1)+1\\right ) \\end{array}\\right.\\ ] ] in which @xmath424 .",
    "then , it can be claimed from theorems 3 and 4 that when the finite random sequence @xmath261}$ ] has the realization @xmath240}$ ] , the corresponding matrices @xmath241}(t)}|_{t=1}^{n}$ ] simultaneously satisfy @xmath258}(t)}\\in{\\cal h}_{l}$ ] and @xmath259}(t)}\\in{\\cal h}_{r}$ ] .",
    "hence , according to lemma 2 , @xmath242}(t)}=\\prod_{t=1}^{n_{*}}\\phi_{r^{[n]}(t)}\\prod_{t = n_{*}+1}^{n}\\phi_{r^{[n]}(t)}$ ] belongs to both @xmath120 and @xmath121 , and therefore @xmath122 .",
    "it can therefore be declared from lemma 2 that with respect to this particular realization of @xmath262 , the corresponding matrix valued function @xmath425}(t)},\\star\\right)$ ] , which is defined on the set of @xmath102 dimensional positive definite matrices , is strictly contractive under the riemannian distance defined in equation ( [ eqn:10 ] ) .",
    "this means that if during the time interval @xmath426 $ ] , the random measurement dropping process @xmath215 has this particular realization , then , @xmath427}(t)},\\star\\right)\\!\\right)$ ] @xmath428 . from lemma 1 , this inequality is further equivalent to @xmath429}(1)},{\\rm\\bf h}_{m}\\left(\\phi_{r^{[n]}(2)},\\cdots,{\\rm\\bf h}_{m}\\left(\\phi_{r^{[n]}(n)},\\star\\right)\\cdots\\right)\\right)\\right)<1\\ ] ]    on the other hand , from the definition of the set @xmath264}$ ] , it is obvious that @xmath240}\\in { \\cal s}^{[n]}$ ] .",
    "hence , according to lemma 4 , when the measurement dropping process @xmath215 has an independent and identical bernoulli distribution with a constant positive expectation , the probability of the occurrence of this sequence is certainly greater than @xmath34 .",
    "in addition , from lemma 2 and the fact that @xmath430 no matter @xmath98 or @xmath99 , it can be declared that for every other element @xmath267}$ ] of the set @xmath264}$ ] , the random alternative lyapunov and riccati recursions corresponding to the particular realization @xmath261}=s_{m}^{[n]}$ ] of the pseudo - covariance matrix @xmath74 in rseio , satisfies @xmath431}(t)},\\star\\right)\\right)\\leq 1 $ ] , which is further equivalent to @xmath432}(1)},{\\rm\\bf h}_{m}\\left(\\phi_{s_{m}^{[n]}(2)},\\cdots,{\\rm\\bf h}_{m}\\left(\\phi_{s_{m}^{[n]}(n)},\\star\\right)\\cdots\\right)\\right)\\right)\\leq 1\\ ] ]    therefore , @xmath433}(1)},{\\rm\\bf",
    "p}_{r}\\left(\\gamma^{[n]}=r^{[n]}\\right)+\\nonumber \\\\ & & \\sum_{s_{m}^{[n]}\\in{\\cal s}^{[n]}\\backslash r^{[n]}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!{\\rm log}{\\rm\\bf l}_{ip}\\!\\left({\\rm\\bf h}_{m}\\left(\\phi_{s_{m}^{[n]}(1)},{\\rm\\bf h}_{m}\\left(\\phi_{s_{m}^{[n]}(2)},\\cdots,{\\rm\\bf h}_{m}\\left(\\phi_{s_{m}^{[n]}(n)},\\star\\right)\\cdots\\right)\\right)\\right){\\rm\\bf p}_{r}\\left(\\gamma^{[n]}=s_{m}^{[n]}\\right)\\nonumber\\\\ & < & 0\\end{aligned}\\ ] ]    it can therefore be declared from lemma 3 that , if the random measurement dropping process @xmath215 has an independent and identical bernoulli distribution with a constant positive expectation , and there exist two positive integers @xmath284 and @xmath285 such that the matrix pair @xmath245}(a^{[2]})^{m_{1}},\\;h^{[1]})$ ] is observable and the matrix pair @xmath247})^{m_{2}}a^{[1]},\\;g^{[2]})$ ] is controllable , then , with the increment of the variable @xmath31 , the pseudo - covariance matrix @xmath74 of rseio converges with probability one to a stationary distribution that is independent of its initial value @xmath194 ."
  ],
  "abstract_text": [
    "<S> a recursive state estimation procedure is derived for a linear time varying system with both parametric uncertainties and stochastic measurement droppings . </S>",
    "<S> this estimator has a similar form as that of the kalman filter with intermittent observations , but its parameters should be adjusted when a plant output measurement arrives . </S>",
    "<S> a new recursive form is derived for the pseudo - covariance matrix of estimation errors , which plays important roles in analyzing its asymptotic properties . based on a riemannian metric for positive definite matrices , </S>",
    "<S> some necessary and sufficient conditions have been obtained for the strict contractiveness of an iteration of this recursion . </S>",
    "<S> it has also been proved that under some controllability and observability conditions , as well as some weak requirements on measurement arrival probability , the gain matrix of this recursive robust state estimator converges in probability one to a stationary distribution . </S>",
    "<S> numerical simulation results show that estimation accuracy of the suggested procedure is more robust against parametric modelling errors than the kalman filter .    * _ key words-_*intermittent measurements , networked system , recursive state estimation , robustness , sensitivity penalization . </S>"
  ]
}