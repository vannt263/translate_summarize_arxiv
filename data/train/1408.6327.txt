{
  "article_text": [
    "double - bootstrap methods that use a single simulation at the second bootstrap level have been studied in at least one context for more than a decade .",
    "an early contribution was made by @xcite , although in the setting of diagnosing the overuse of a dataset , rather than speeding up monte carlo simulation for general applications of the bootstrap .",
    "@xcite , and the same authors in a number of subsequent papers accessible via @xcite and @xcite , introduced the concept independently and explored its applications .",
    "@xcite christened the technique the warp - speed double - bootstrap method , nomenclature that we shall use here , too .",
    "@xcite demonstrated that this approach is asymptotically consistent .",
    "all this work is for the case of distribution estimation and its application to constructing confidence intervals and hypothesis tests .    in statistics",
    "the conventional double bootstrap is used in two main classes of problems : ( i )  to improve the effectiveness of bias correction , and ( ii )  to improve the coverage accuracy of confidence intervals . in problem  ( i )",
    ", an application of the double bootstrap reduces the order of magnitude of bias by the factor  @xmath0 , and in problem  ( ii ) it reduces coverage error by the factor @xmath1 for one - sided confidence intervals , and @xmath0 for two - sided intervals . in the setting of problem  ( i ) , it is not clear whether there exists a version of warp - speed methodology for bias correction , and whether , should it exist , it successfully reduces the order of magnitude of bias . call these questions  1 and  2 , respectively . in problem",
    "( ii ) , it is unclear whether the warp - speed double bootstrap is as effective as the conventional double bootstrap , in the sense of offering the above levels of improved accuracy ; we shall refer to this as question  3 . in the present paper",
    "we show that the answers to questions  1 and  2 are positive , but that the answer to question  3 is negative .",
    "in particular , the warp - speed bootstrap does not reduce the order of magnitude of coverage error of a confidence interval .",
    "there is an extensive literature on conventional double - bootstrap methods , particularly in the context of improving the coverage accuracy of single - bootstrap methods . the first mention of the double bootstrap in this setting apparently was by @xcite , followed quickly by contributions of @xcite .",
    "see also @xcite .",
    "the approach suggested by hall ( 1992 , chap .",
    "3 ) allows general multiple bootstrap methods to be developed together , so that different settings do not require separate treatment .",
    "however , details of properties of the technique seem to be very problem - specific .",
    "@xcite was the first to use the double bootstrap in any setting ; in that paper his work was in the context of estimating the error rate of classifiers .",
    "research on optimising the trade - off between the numbers of simulations in the first and second stages of the conventional double bootstrap , in the context of distribution estimation and constructing confidence intervals , includes that of @xcite , @xcite and @xcite .",
    "it has become conventional to assess performance of the bootstrap in terms of edgeworth expansions , not least because that approach enables theoretical properties to be developed in the very broad context addressed by @xcite .",
    "the resulting approximations are valid , in absolute rather than relative terms , uniformly in the tails .",
    "an alternative approach , based on large deviation probabilities , is valid in relative terms ; see e.g.  @xcite .",
    "however , it requires either more stringent assumptions or specialised methods that , at least at present , are not available in the context of the models used by @xcite . in the setting of absolute rather than relative accuracy , arbitrarily far out into the tails , the results in this paper",
    "take the result of consistency , demonstrated by @xcite , much further .",
    "let @xmath2 be a parameter expressible as a known function , @xmath3 , of a @xmath4-variate mean , @xmath5 , and let @xmath6 denote an unbiased estimator of  @xmath7 .",
    "our estimator of @xmath8 is the same function of a sample mean ,  @xmath6 : @xmath9 the smooth function @xmath3 maps a point @xmath10 in @xmath4-variate euclidean space to a point on the real line .",
    "we do not insist that @xmath6 be a mean of @xmath11 , say , independent and identically distributed random @xmath4-vectors , since it might be the case that @xmath12 , with @xmath13 where @xmath14 , for @xmath15 , are independent for each @xmath16 , @xmath17 for each @xmath18 , and the @xmath19s are not all equal .",
    "nevertheless , in mathematical terms we shall assume that the @xmath19s are all functions of an integer parameter @xmath11 , and that each @xmath20 ; that is , each ratio @xmath21 is bounded away from zero and infinity as @xmath22 .",
    "these issues are related to dependence relationships among the random variables @xmath14 , which should be reflected in resampling methodology . in our theoretical work",
    "we shall suppose that : @xmath23{.88\\linewidth } either ( i)~each $ n_j = n$ and the vectors $ ( x_{1i},\\ldots , x_{pi})^\\t$ , for $ i\\geq1 $ , are independent and identically distributed ; or ( ii)~the $ x\\ji$s are totally independent , for $ 1\\leq i\\leq n_j$ and $ 1\\leq j\\leq p$ , and in this case , for each $ j\\in\\{1,\\ldots , p\\}$ the variables $ x_{j1},x_{j2},\\ldots$ are identically distributed , and $ n_j\\asymp n$. \\end{minipage}}\\ ] ]    each of ( i ) and ( ii ) above can be generalized , for example to hybrid cases where , for positive integers @xmath24 that satisfy @xmath25 , and defining @xmath26 , the vectors @xmath27 , for @xmath28 and @xmath29 , are completely independent , and for each @xmath18 the vectors @xmath30 , for @xmath29 , are identically distributed .",
    "bootstrap methods that reflect these properties can be constructed readily , and theory providing authoritative support in this setting can be developed , but for the sake of brevity , in our theoretical work we shall restrict attention to cases where ( [ eq:2.2 ] ) holds .",
    "bias - corrected estimators of @xmath8 , based on the conventional bootstrap and the double bootstrap , respectively , are given by @xmath31 here @xmath32 denotes the original dataset , @xmath33 is the version of @xmath34 computed from a resample @xmath35 drawn randomly , with replacement , from @xmath36 , in a manner that reflects appropriately the dependence structure , and @xmath37 is the version of @xmath34 computed from @xmath38 , which in turn is drawn randomly with replacement from @xmath35 , again reflecting dependence .",
    "monte carlo approximations to the quantities @xmath39 and @xmath40 in ( [ eq:2.3 ] ) are given respectively by @xmath41 where @xmath42 denotes the @xmath43th out of @xmath44 independent and identically distributed , conditional on @xmath36 , versions of @xmath33 , computed from respective resamples @xmath45 drawn by sampling randomly , with replacement , from the data in @xmath36 , and @xmath46 is the @xmath47th out of @xmath48 independent and identically distributed , conditional on @xmath36 and @xmath35 , versions of @xmath37 , and is computed from a resample @xmath49 drawn by sampling randomly , with replacement , from  @xmath45 .",
    "reflecting the model at ( [ eq:2.1 ] ) , we can express @xmath42 and @xmath46 in ( [ eq:2.4 ] ) as @xmath50 and @xmath51 , where @xmath52 , @xmath53 , @xmath54 denotes the mean of data in the resample @xmath55 , @xmath56 is the mean of data in the re - resample @xmath57 drawn by sampling with replacement from @xmath58 , the resampling operations at the first bootstrap level are undertaken by resampling the vectors @xmath59 randomly , with replacement , if ( [ eq:2.2])(i ) holds , or by resampling the @xmath14s randomly and completely independently , conditional on @xmath36 and with replacement , if ( [ eq:2.2])(ii ) obtains , and resampling at the second bootstrap level is undertaken analogously .      in theorem  1 in section  5.1 we shall show that if @xmath60 , no matter how slowly , as @xmath11 and @xmath44 diverge , then the asymptotic distribution of the monte carlo simulation error incurred when constructing @xmath61 at ( [ eq:2.4 ] ) is the same as it would be if @xmath62 . in particular , not only is the error of order @xmath63 , the large - sample limiting distribution of the relevant asymptotically normal random variable , which has standard deviation proportional to @xmath63 , and which describes in relative detail the accuracy of monte carlo bootstrap simulation , is identical to the limiting distribution that would arise if @xmath62 .",
    "moreover , if @xmath48 is held fixed then the order of magnitude , @xmath63 , remains unchanged , but the standard deviation of the large - sample limiting distribution referred to above changes by a constant factor .",
    "this result is critical .",
    "it demonstrates the relatively small gains that are to be achieved by taking @xmath48 to be large , and argues in favour of taking @xmath64 , for example .",
    "this is the analogue , for bias correction , of the warp - speed bootstrap for distribution estimation when constructing confidence intervals .",
    "therefore the order of magnitude of monte carlo simulation error in @xmath61 is unchanged even if @xmath48 is held fixed .",
    "incidentally , the order of magnitude , @xmath63 , should be compared with that of the uncorrected bias that remains after applying the bias correction that leads to  @xmath61 ; it is  @xmath65 .",
    "therefore , unless @xmath44 is of order @xmath66 or larger , for the regular bootstrap , the orders of magnitude involving @xmath44 , discussed above , dominate the error in the bias correction .",
    "as in section  2.1 we shall assume that the parameter @xmath8 can be represented as @xmath67 , where the function @xmath68 is known , and @xmath69 is an unknown @xmath4-vector of parameters , estimated by @xmath70 where @xmath71 is a random sample of data vectors . here and",
    "below we use model ( [ eq:2.2])(i ) for the data , but only minor modifications are needed if ( [ eq:2.2])(ii ) is employed instead",
    ".    in such cases , provided that @xmath3 is sufficiently smooth and @xmath34 is given by ( [ eq:2.1 ] ) , the asymptotic variance , @xmath72 , of @xmath34 is estimated root-@xmath11 consistently by @xmath73 , where @xmath74 here , given a @xmath4-vector @xmath75 , and integers @xmath76 between 1 and @xmath4 ; and assuming that @xmath3 has @xmath77 well - defined derivatives with respect to each variable ; we put @xmath78 the above definitions of @xmath34 and @xmath79 are used in ( [ eq:3.1 ] ) below .",
    "let @xmath80 , referred to as the `` root '' by @xcite , be given by either of the formulae @xmath81 here @xmath34 and @xmath79 are estimators of parameters @xmath8 and @xmath82 computed from the random sample @xmath36 , and @xmath83 denotes the asymptotic variance of  @xmath84 .",
    "the warp - speed bootstrap of @xcite , closely related to suggestions by @xcite and @xcite , can be defined as follows .    as in section  2 , let @xmath45 , for @xmath85 , be drawn randomly , with replacement , from @xmath36 , and be independent conditional on  @xmath36 .",
    "draw @xmath86 , denoting a single double - bootstrap resample , by sampling randomly , with replacement , from @xmath45 for @xmath87 , in such a manner that these re - resamples are independent , conditional on @xmath36 and @xmath88 . in the context of section  2",
    ", @xmath86 would be one of the resamples @xmath89 which were drawn by resampling from @xmath45 , but on the present occasion we require only one of these resamples .",
    "let @xmath42 and @xmath90 denote the versions of @xmath34 computed from @xmath45 and @xmath86 , respectively , instead of @xmath36 , and write @xmath91 and @xmath92 for the corresponding versions of  @xmath79 .",
    "if @xmath80 is given by one of the formulae at ( [ eq:3.1 ] ) , define @xmath93 @xmath94 in the respective cases , and put @xmath95 then @xmath96 is the conventional single - bootstrap , monte carlo approximation to the distribution function @xmath97 of @xmath80 , and the limit of @xmath96 , as @xmath98 , is the conventional single - bootstrap approximation to  @xmath97 .",
    "the function @xmath99 is a short - cut , warp - speed , double - bootstrap approximation to  @xmath97 .",
    "given a nominal coverage level @xmath100 of a confidence interval , define @xmath101 to be the solution of the equation @xmath102 , and similarly let @xmath103 be the solution of @xmath104 .",
    "if @xmath80 is given by either of the two expressions in ( [ eq:3.1 ] ) , consider the respective confidence intervals , @xmath105 which are bootstrap versions of the respective intervals @xmath106 in either case , our estimator of the probability @xmath107 that the interval @xmath108 covers @xmath8 is given by @xmath109 we take the final interval to be @xmath110 , where @xmath111 denotes the solution of @xmath112 .",
    "earlier warp - speed bootstrap methodology is a little ambiguous in the percentile-@xmath113 setting , i.e.  in the context of the second definition in each of ( [ eq:3.1])([eq:3.3 ] ) , where the technique is not completely clear from the algorithms of @xcite , @xcite and giacomini ( 2013 , pp .",
    "570571 ) .",
    "in particular it is unclear from @xcite when , or whether , the estimator @xmath79 should be replaced by its single- or double - bootstrap forms , @xmath114 and @xmath115 , for example in ( [ eq:3.2])([eq:3.5 ] ) .",
    "the choices we have made are appropriate , however , and in particular the algorithm would not be second - order accurate , or third - order accurate in the case of the double bootstrap , if we were to use simply @xmath79 in those instances .      in section  5.2 we shall show that in the percentile-@xmath113 case , using the case @xmath116 as a benchmark , the approach suggested above produces quantile estimators that are identical to those obtained using the standard single - bootstrap method , up to an error of order  @xmath117 . in particular , they do not reduce the @xmath0 coverage error of single - bootstrap methods .",
    "similar results hold for percentile - method bootstrap procedures .",
    "here we report the results of a simulation study comparing the performances of five different bootstrap methods for bias correction : the single bootstrap , the conventional double bootstrap , and the suggested alternative method involving only @xmath64 , 2 , 5 or 10 double - bootstrap replications .",
    "the data were of two types , either the exponential distribution , with density @xmath118 on the positive half - line , or the log - normal distribution .",
    "these two distributions both have nonzero skewness and nonzero kurtosis , making them challenging for the bootstrap .",
    "the parameter of interest also took two forms , both of them nonlinear : either @xmath119 or @xmath120 , where @xmath5 was the population mean .",
    "in such cases there is a term with order @xmath121 in the bias expansion , which can not be eliminated by the single bootstrap but can be removed by the double bootstrap .",
    "this is reflected in our simulation results , which show that the double bootstrap provides better bias correction than the single bootstrap method .",
    "sample size , @xmath11 , was chosen in steps of 20 between 20 and  80 ; the number of simulations , @xmath44 , in the first bootstrap step was set equal to @xmath122 , for each of the bootstrap methods ; and the number of simulations , @xmath48 , for the second bootstrap step in the conventional double bootstrap was taken to be the integer part of  @xmath123 , which we write as @xmath124 .",
    "the choice of @xmath125 here was suggested by @xcite in the context of confidence intervals , and gives an expression for @xmath48 that is orders of magnitude larger than obtained using relatively small , fixed  @xmath48 .",
    "for example , when @xmath126 the value of @xmath127 is between 20 and 200 times the values @xmath64 , 2 , 5 or 10 used to simulate the alternative approach to double - bootstrap methods ; when @xmath128 the respective factors are 80 to  800 .    from equation ( [ eq:2.4 ] )",
    ", @xmath129 provide the estimates of the true bias of @xmath130 , i.e. , @xmath131 , via single bootstrap and double bootstrap , respectively .",
    "empirical approximations to bias , computed by averaging over the results of 5,000 monte carlo trials in each case , are reported in tables 1 - 2 in supplementary material , and the ratios of such approximations and true bias are graphed in figure  1 .",
    "the figure shows that , for the values of @xmath44 used in our analysis , there is little to choose between performance when using @xmath64 and @xmath132 .",
    "+   +      in this section we illustrate the coverage performance of bootstrap confidence intervals , with nominal coverage @xmath133 , for the population means of the two distributions considered in section 4.1 , i.e. the exponential and log - normal distributions .",
    "sample size @xmath11 was taken equal to 20 and 40 in each case ; @xmath44 was increased from @xmath134 to @xmath135 in steps of @xmath136 , as indicated on the horizontal axis of each panel ; and one - sided and two - sided equal - tailed bootstrap confidence intervals were considered , each using either the percentile or percentile-@xmath113 bootstrap , implemented via the single bootstrap , the conventional double bootstrap , @xmath137 ; and the warp speed bootstrap , i.e.  the double bootstrap with @xmath64 .",
    "this choice of @xmath48 was suggested by @xcite . to provide a perspective different from that in section  4.1 , in the present section we graph coverage as a function of @xmath44 for fixed @xmath11 , rather than as a function of @xmath11 for fixed @xmath44 as in section  4.1 .",
    "results in the two settings can of course be expressed in same way ; the conclusions do not alter .",
    "results for sample size @xmath126 , with each point on each graph based on 5,000 monte carlo simulations , are presented in figure  2 .",
    "it can be seen that , for each confidence interval type , the conventional double - bootstrap method gives greater coverage accuracy than the single - bootstrap and warp - speed bootstrap .",
    "results for sample size @xmath138 are similar , and are reported in supplementary material .     +   +",
    "our main regularity condition , in addition to the model assumptions ( [ eq:2.1 ] ) and ( [ eq:2.2 ] ) , is the following condition : @xmath139{.88\\linewidth } ( i ) $ f(x)$ is differentiable six times with respect to any combination of the $ p$ components of $ x$ ; and those derivatives , as well as $ f$ itself , are uniformly bounded ; and ( ii ) the data $ x_{ji}$ have at least six finite moments , and $ e(x_{ji}^6)$ is bounded uniformly in $ i$ and $ j$. \\end{minipage}}\\ ] ] condition ( [ eq:5.1 ] ) can be generalized , but ( for example ) if we relax significantly the condition of boundedness of @xmath3 and its derivatives , in ( [ eq:5.1])(i ) , then we need to strengthen the assumption about tails of the distributions of the @xmath14s , in  ( [ eq:5.1])(ii )",
    ". we shall define @xmath140\\,.\\label{eq:5.2}\\ ] ]    in theorem  1 , below , we decompose the bias - corrected estimators @xmath141 , based on the single bootstrap , and @xmath61 , based the double bootstrap , as follows : @xmath142 here @xmath143 and @xmath144 are the `` ideal '' versions of @xmath141 and and @xmath61 , respectively , that we would obtain if we were to do an infinite number of simulations , i.e.  if we were to take @xmath145 ; and @xmath146 and @xmath147 denote error terms arising from doing only a finite number of monte carlo simulations .",
    "part  ( d ) of theorem  1 shows that the error terms @xmath146 in the case of the single bootstrap , and @xmath147 for the double bootstrap , both equal @xmath148 , and that this is the exact order , regardless of the selection of @xmath48 in the second bootstrap stage .",
    "although the monte carlo error terms in the single bootstrap and the double bootstrap share the same convergence rate , equations show that the double bootstrap provides a higher degree of accuracy , in terms of bias correction , than the single bootstrap if we take @xmath145 .",
    "part  ( d ) also implies that if @xmath44 is sufficiently large , or more precisely if @xmath149 , then the monte carlo error is of the same order as , or order smaller than , the deterministic remainders in  .",
    "these are the main theoretical findings of theorem  1 .",
    "assume that the data are generated according to either of the models at , that holds , and that @xmath150 as @xmath22 .",
    "then : ( a )  equations hold , where @xmath143 and @xmath144 are functions of @xmath36 alone , and in particular do not involve @xmath35 or @xmath38 , and satisfy @xmath151 and @xmath146 and @xmath147 are functions of both @xmath36 and @xmath35 ( and also of @xmath38 , in the case of @xmath147 ) , and satisfy @xmath152 .",
    "( b )  both @xmath143 and @xmath144 equal @xmath153 , and both satisfy the same central limit theorem as  @xmath34 .",
    "( c )  in particular , both @xmath143 and @xmath144 are asymptotically normally distributed with mean @xmath8 and a variance , @xmath72 say , which has the property that @xmath154 is bounded as @xmath22 .",
    "( d )  conditional on @xmath36 , @xmath146 and @xmath147 are asymptotically normally distributed with zero means and variances of size @xmath155 , and",
    "if @xmath156 as @xmath22 then the ratio of the variances converges to  1 as @xmath11 diverges . in the case of the asymptotic variances of @xmath146 and @xmath147 , both conditional on @xmath36 and unconditionally , are @xmath157 and @xmath158 , respectively .    in connection with part ( d ) it can be shown that , if @xmath48 diverges ( no matter how slowly ) as @xmath11 increases , the asymptotic distribution of the error is the same as it would be if @xmath62 . if @xmath159 is as in part  ( c ) then , under the model ( [ eq:2.2])(i ) , there exists a positive constant @xmath47 such that @xmath160 as @xmath22 .",
    "however , this is not necessarily correct under the model ( [ eq:2.2])(ii ) , since in that setting we do not require the ratios @xmath21 to converge",
    ". in the context of ( [ eq:2.2])(i ) , formulae for @xmath143 and @xmath144 are given at ( 9 ) and ( 10 ) , respectively , in the supplementary material .",
    "the orders of magnitude of the remainders in are exact when skewness and kurtosis are nonzero .",
    "it follows from part  ( b ) of theorem  1 that , in the case @xmath145 , @xmath141 and @xmath61 satisfy identical central limit theorems , and in particular both have the same asymptotic variances .",
    "we shall assume that @xmath161 , which represents a generic @xmath4-vector @xmath59 , where @xmath162 and ( [ eq:2.2])(i ) holds , satisfies the following multivariate version of cramr s continuity condition @xcite : @xmath163 on this occasion , @xmath16 denotes @xmath164 .",
    "for brevity we shall treat in detail only the percentile-@xmath113 case , evidenced by the second formula in each of ( [ eq:3.1])([eq:3.3 ] ) , and discuss the percentile method briefly below theorem  2 .",
    "let @xmath165 and @xmath166 denote the standard normal distribution and density functions , respectively .",
    "assume that an unknown scalar parameter @xmath8 can be written as @xmath2 , where @xmath69 , and that our estimator of @xmath8 is @xmath167 , as at ( [ eq:2.1 ] ) , where @xmath70 .",
    "methods of @xcite can be used to prove that , under conventional assumptions such as those in theorem  2 below , @xmath168 where @xmath169 is a polynomial of degree @xmath170 , and is an even or odd function according as @xmath18 is odd or even , respectively ; and the remainder @xmath171 satisfies @xmath172 the coefficients of @xmath169 are rational polynomials in moments of the distribution of @xmath161 .    for simplicity in this section",
    "we take @xmath116 , which is the ideal case where there is no error generated from monte carlo approximation .",
    "inverting the edgeworth expansion at we obtain a cornish - fisher expansion : @xmath173 where @xmath174 , the functions @xmath175 , @xmath176 and @xmath177 are cornish - fisher polynomials and for example are given by @xmath178 and @xmath179 , and the remainder in is of the stated order , uniformly in @xmath180 $ ] , whenever @xmath181 .",
    "the conventional percentile-@xmath113 bootstrap estimator of @xmath182 is @xmath183 , defined  by @xmath184 and satisfying an empirical version of the edgeworth expansion at : @xmath185 where @xmath186 is derived from empirical edgeworth polynomials @xmath187 in the standard way , discussed below ( [ eq:5.a8 ] ) ; and @xmath188 is derived from the edgeworth polynomial , @xmath189 , on replacing moments of the distribution of @xmath161 , appearing in coefficients of @xmath189 , by the same respective moments of the distribution of @xmath190 , conditional on @xmath36 , with @xmath190 drawn by sampling , randomly and with replacement , from  @xmath36 .",
    "note too that the coefficients of @xmath188 depend on moments of @xmath190 , conditional on @xmath36 , through rational polynomials in those conditional moments .",
    "if we knew the sampling distribution of @xmath161 , and wished to construct an upper one - sided confidence interval for @xmath8 , we would employ the studentised confidence interval @xmath191 , where @xmath192 is as at ; if we were to use the percentile-@xmath113 bootstrap method , it would be @xmath193 , where @xmath103 is as at ; and if we were to employ the warp - speed bootstrap method , it would be @xmath194 , as discussed in section  3.2 , where @xmath195 denotes the limit , as @xmath98 , of the quantity @xmath196 introduced there",
    ". however , we shall show in theorem  2 that @xmath197 , and so the endpoints of standard percentile-@xmath113 and warp - speed bootstrap confidence intervals differ only to order  @xmath117 .",
    "this signals that conventional arguments , based on edgeworth expansions , can be used to prove that the standard percentile-@xmath113 confidence interval , and its warp - speed bootstrap variant , have identical coverage error up to and including terms of order @xmath198 , and of course that can be done under the assumptions of theorem  2 .",
    "since , as is well known , the coverage error of the percentile-@xmath113 interval is genuinely of order @xmath198 @xcite , then it follows that the warp - speed bootstrap does not improve on that accuracy .",
    "assume that model applies ; that the function @xmath3 , in the definition @xmath2 , has five bounded derivatives ; and that holds , @xmath199 for sufficiently large @xmath200 , and @xmath116",
    ". then @xmath197 .",
    "the appropriate number of moments that should be assumed for general edgeworth or cornish fisher expansions , even in relatively simple , non - bootstrap cases , is awkward to determine .",
    "for example , the argument of @xcite requires at least six moments in the case of the studentised mean , whereas it is known that three moments are sufficient ; see e.g.  @xcite .",
    "even if we were to develop , in full detail , a proof of theorem  2 based on the methods of @xcite , the number of moments we would need to assume would be unduly generous , and instead refer to the number as simply  @xmath201 .",
    "we choose not to provide such a detailed development here .",
    "however , the number of derivatives is relatively easy to address , and the theorem provides detail in that respect .    let @xmath202 which is the limit of @xmath203 , defined in ( [ eq:3.4 ] ) , as @xmath204 .",
    "then @xmath205 is the solution of @xmath206 .",
    "our focus on the case @xmath116 deserves comment . in the early days of the bootstrap , @xmath116",
    "was seen as `` the statistical bootstrap method , '' and the case of finite @xmath44 was interpreted as a monte carlo approximation to the bootstrap .",
    "indeed , taking @xmath207 was viewed more as an issue to be addressed in computational or numerical terms , rather than statistical ones . reflecting this , for about eight years from the mid 1980s considerable effort",
    "was spent developing efficient computational methods for undertaking bootstrap resampling . however , by the early 1990s computers had become so fast that this area of research had largely disappeared .",
    "this remains the case today ; taking @xmath44 in the thousands , without using numerical devices to increase simulation efficiency , is now the rule rather than the exception .",
    "the difference between such large values of @xmath44 , and using the mathematical ideal value @xmath116 , is particularly small .",
    "we have investigated the role played by @xmath48 , the number of resamples used in the second bootstrap stage , in double bootstrap methods for bias correction and confidence intervals .",
    "specifically , we have shown that the double bootstrap is largely insensitive to choice of @xmath48 in the context of bias correction .",
    "indeed , double bootstrap methods with fixed @xmath48 can produce third - order accuracy , much as do conventional double bootstrap methods with diverging  @xmath48 .",
    "this result demonstrates the effectiveness , for bias correction , of using the double bootstrap with a single double - bootstrap simulation .",
    "although existing work shows that the warp - speed double bootstrap @xmath208 can improve accuracy in hypothesis testing , there has not been , until now , any theoretical underpinning of its performance in the context of confidence intervals .",
    "however , when only a single bootstrap resample is used in the second - bootstrap stage to construct confidence intervals , the order of magnitude of coverage error is not improved relative to that for the single bootstrap .",
    "supplementary material available for theoretical proofs of theorems 1 and 2 , and additional simulation results in sections 4.1 and 4.2 .",
    "( 1987 ) . prepivoting to reduce level error in confidence sets .",
    "_ biometrika _ * 74 * , 457468 .",
    "( 1988 ) . prepivoting test statistics : a bootstrap view of asymptotic refinements .",
    "_ j. amer .",
    "assoc . _ * 83 * , 687697 .",
    "( 1978 ) . on the validity of the formal edgeworth expansion .",
    "statist . _",
    "* 6 * , 434451 .",
    "monte carlo approximation and the iterated bootstrap .",
    "_ biometrika _ * 81 * , 331340 .",
    "allocation of monte carlo resources for the iterated bootstrap .",
    "_ j. comput . graph .",
    "statist . _",
    "* 7 * , 92112 .",
    "( 2001 ) . improving the reliability of bootstrap tests .",
    "queens institute for economic research discussion paper no .",
    "995 , revised .",
    "fast double bootstrap tests of nonnested linear regression models .",
    "_ econometric rev . _ * 21 * , 417427 .",
    "( 2007 ) . improving the reliability of bootstrap tests with the fast double bootstrap . _",
    "statist . data anal . _ * 51 * , 32593281 .",
    "efficient bootstrap simulation .",
    "_ biometrika _ * 73 * , 555566 .",
    "estimating the error rate of a prediction rule : improvement on cross - validation .",
    "_ j. amer .",
    "assoc . _ * 78 * , 316331 .",
    "a warp - speed method for conducting monte carlo experiments involving bootstrap estimators .",
    "_ econometric theory _ * 29 * , 567589 .",
    "( 1986 ) . on the bootstrap and confidence intervals .",
    "statist . _",
    "* 14 * , 14311452 .",
    "edgeworth expansion for student",
    "s @xmath113 statistic under minimal moment conditions .",
    "probab . _ * 15 * , 920931 .",
    "on symmetric bootstrap confidence intervals .",
    "b * 50 * , 3545 .    on the relative performance of bootstrap and edgeworth approximations of a distribution function .",
    "_ j. multivariate anal . _",
    "* 35 * , 108129 .",
    "( 1992 ) . _",
    "the bootstrap and edgeworth expansion_. springer , new york .",
    "( 1988 ) . on bootstrap resampling and iteration .",
    "_ biometrika _ * 75 * , 661671 .",
    "the effect of monte carlo approximation on coverage error of double - bootstrap confidence intervals . _ j. roy .",
    "b * 61 * , 353366 .",
    "applications of the fast double bootstrap .",
    "queens economics department working paper no .",
    "a reality check for data snooping .",
    "_ econometrica _ * 68 * , 10971126 .    * supplementary material for ",
    "double - bootstrap methods use a single double - bootstrap simulation \" * + jinyuan changpeter hall + department of mathematics and statistics + the university of melbourne , vic , 3010 , australia",
    "in view of ( 12 ) , taylor expansion can be used to derive the following formulae : @xmath209 and @xmath210 where the remainder term @xmath211 that is denoted by @xmath212 in ( 1 ) satisfies @xmath213 .",
    "define @xmath214 then , if ( 2)(i ) holds , @xmath215 hence , by  ( 2 ) , @xmath216 where , for @xmath217 , @xmath218    if ( 2)(ii ) holds , instead of ( 2)(i ) ; and if we define @xmath219 , and write @xmath220 for the indicator function of an event @xmath221 ; then the following relations obtain : @xmath222 and @xmath223 therefore we can write ( 2 ) as @xmath224 where the quantities @xmath225 and @xmath226 may depend on @xmath11 but are bounded as @xmath22 .",
    "property ( 4 ) is the analogue , in the context of ( 2)(ii ) rather than ( 2)(i ) , of  ( 3 ) .    to explore properties of monte carlo approximations to the quantities @xmath227 and @xmath228 ( compare ( 3 ) and ( 4 ) ) , observe first that",
    ", analogously to  ( 1 ) , @xmath229 averaging these formulae over bootstrap replicates we obtain the following expansions : @xmath230 in view of ( 12 ) , the remainder terms @xmath211 , say , that are denoted by @xmath212 in ( 5 ) and ( 6 ) satisfy @xmath213 .",
    "define @xmath231 the latter for @xmath217 . in the discussion below",
    "we shall assume , for the sake of definiteness , that the data are generated by the model ( 2)(i ) .",
    "the case of model ( 2)(ii ) is similar .",
    "suppose first that we use the regular bootstrap , both for resampling @xmath45 from @xmath36 and for resampling @xmath232 from  @xmath45 .",
    "then the conditional expected values of the non - remainder terms on the right - hand sides of ( 5 ) and ( 6 ) satisfy the following identities , respectively : @xmath233 where , as before , the expected values of the @xmath212 remainder terms equal  @xmath234 .",
    "recall the definitions of @xmath141 and @xmath61 at ( 4 ) , and define @xmath235 then ( 7 ) and ( 8) imply that @xmath236 and @xmath237 , where the expected values of the @xmath238 remainder terms equal @xmath239 , and @xmath240 therefore @xmath143 and @xmath144 both equal @xmath153 , as claimed in part  ( b ) of theorem  1 .    put @xmath241 and @xmath242 . employing ( 3 ) and the properties @xmath243 for @xmath244",
    ", we deduce that @xmath245 , and that @xmath246 is a function of both @xmath36 and @xmath35 , satisfying @xmath247 ( in the context of ( 2)(i ) ) and @xmath248 .",
    "central limit theorems for @xmath143 and @xmath146 follow from lindeberg s theorem . in the context of ( 2)(i ) , those parts of ( 15 ) and ( b)(d ) , in theorem  1 , that pertain to the single - bootstrap estimator @xmath141 , follow from these properties .",
    "( the exactness of the orders of magnitude of remainders in ( 15 ) can be proved by deriving concise formulae for those terms , using ( 9)(11 ) . )",
    "consider first the solution @xmath256 , say , of the equation @xmath257 where @xmath258 is the solution of @xmath259 note that @xmath260 where the remainder @xmath261 satisfies @xmath262 and the constants @xmath263 and @xmath264 , both of which are strictly positive , can be chosen as small or as large , respectively , as desired , at the expense of having to assume a higher moment of @xmath265 in the theorem .",
    "the left - hand side of equals the expected value of the left - hand side of , and hence also of the right - hand side of that formula .",
    "the coefficients of @xmath188 depend on moments of @xmath190 , conditional on @xmath36 , through rational polynomials in those conditional moments .",
    "the denominators in those rational polynomials can be taylor expanded , obtaining quantities @xmath266 , say , which have the property that @xmath267=o(1)\\,,\\quad e\\big\\{\\hq_k^{{\\rm exp}}(x)\\big\\}\\,\\phi(x)=q_k(x)\\,\\phi(x)+o(n\\mo)\\,,\\ ] ] where the latter identity holds uniformly in @xmath10 ; and also , @xmath268 and @xmath269 satisfies and additionally , @xmath270 , uniformly in  @xmath10 . hence , taking the expected value of both sides of , we deduce that @xmath271 from which it follows that @xmath272    however , the solution @xmath273 of @xmath274 is identical , up to terms of order @xmath117 , to the solution @xmath275 of equation when @xmath276 there , and in particular , @xmath277 therefore , @xmath278    recall that the distribution function estimator with which we are working is the version of the second formula in ( 8) when @xmath116 and @xmath64 : @xmath279 where @xmath33 , @xmath37 and @xmath115 are computed from @xmath35 , @xmath38 and @xmath38 , respectively .",
    "since we are taking @xmath116 in our analysis then @xmath103 , defined ( 9 ) in the case of finite @xmath44 , is now given by the limit as @xmath98 of that definition , i.e.  the solution in @xmath10 of @xmath280 . in this notation , @xmath195 is defined to be the solution in @xmath281 of the equation @xmath282 , i.e.  the solution in @xmath281 of @xmath283 now , the solution in @xmath281 of is an estimator of the solution @xmath256 of @xmath284 where @xmath258 is the solution of .",
    "that is , a representation of @xmath285 as a cornish - fisher expansion is identical to the analogous representation of @xmath286 , except that moments of @xmath161 are replaced by the corresponding moments of @xmath190 conditional on  @xmath36 .",
    "since the cornish - fisher expansion of @xmath286 is given by , up to and including terms of order @xmath198 , then @xmath287 this is identical to the expansion of @xmath103 , the solution of @xmath288 up to and including terms of order @xmath198 , and so @xmath197 , as had to be proved .",
    "in this section , we provide the simulation results for sections 4.1 and 4.2 .",
    "tables 1 and 2 report the empirical approximations to bias computed by averaging over the results of 5,000 monte carlo trials in the settings of exponential distribution and log - normal distribution , respectively ."
  ],
  "abstract_text": [
    "<S> we show that , when the double bootstrap is used to improve performance of bootstrap methods for bias correction , techniques based on using a single double - bootstrap sample for each single - bootstrap sample can be particularly effective . </S>",
    "<S> in particular , they produce third - order accuracy for much less computational expense than is required by conventional double - bootstrap methods . however , this improved level of performance is not available for the single double - bootstrap methods that have been suggested to construct confidence intervals or distribution estimators .    </S>",
    "<S> * keywords : * bias correction ; bias estimation ; confidence intervals ; distribution estimation ; edgeworth expansion ; second - order correctness ; third - order correctness . </S>"
  ]
}