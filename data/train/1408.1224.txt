{
  "article_text": [
    "including information processing into thermodynamics has received much attention since its starting point with maxwell s demon @xcite .",
    "the first considerations of `` violations '' of the second law induced by an external controller were restricted to thought experiments that could not be reproduced in the laboratory . the situation has recently changed , as experiments with colloids allow the verification of landauer s principle @xcite and the conversion of information into work @xcite , for example . moreover , this fundamental generalization of thermodynamics should play an important role in improving our understanding of problems like computer dissipation @xcite and cellular sensing @xcite .",
    "one approach to study the relation between information and thermodynamics is to consider feedback driven systems @xcite , for which a controller measures the state of the system and changes the protocol according to the measurement outcome and some probabilistic rule .",
    "the second law of thermodynamics for feedback driven systems also includes the mutual information between the system and controller @xcite .",
    "prominently among the many recent works on the relation between information and thermodynamics @xcite , sagawa and ueda obtained a fluctuation relation for feedback driven systems generalizing this second law @xcite .",
    "a different approach to study the thermodynamics of information processing has been recently proposed by mandal and jarzynski ( mj ) @xcite .",
    "they introduced a simple model for a thermodynamic system interacting with a tape ( a sequence of bits ) , where work can be extracted from a system in contact with a single heat bath by increasing the shannon entropy of the tape , i.e. , by writing information on the tape . within the mj model",
    "a tape full of zeros is a thermodynamic resource that can be consumed to do useful work , an idea expressed by bennett some time ago @xcite .",
    "two generalizations of the mj model feature a tape that can move in both directions @xcite and a thermal tape with non - zero temperature @xcite .",
    "furthermore , a similar model for a refrigerator powered by writing information on a tape was introduced in @xcite .",
    "more generally , this tape can be viewed as an information reservoir @xcite , which is a reservoir that only changes the entropy balance .",
    "thus it must be accounted for in the second law while leaving the first law intact , as no energy is exchanged between the information reservoir and the system .",
    "deffner and jarzynski have obtained the generalizations of the second law with an information reservoir using an hamiltonian framework @xcite .",
    "we have shown that the theory of stochastic thermodynamics could be generalized to include an information reservoir @xcite .    in this paper",
    "we further extend the result obtained in @xcite , by proving an inequality that allows us to generalize stochastic thermodynamics to the presence of several information reservoirs .",
    "this generalization is achieved by introducing an information processing entropy production ( ip - entropy production ) , which takes into account information reservoirs interacting with the system . a master fluctuation theorem leading to our generalized inequality",
    "is also proved .",
    "furthermore , we obtain the modified forms for the second and first law in the presence of information reservoirs and demonstrate with specific examples that our formalism can be used to study a generic thermodynamic system interacting with information reservoirs .",
    "a precursor in analyzing thermodynamic systems out of equilibrium is linear response theory @xcite . whereas even fluctuation theorems are available for information processing machines @xcite , a systematic linear response theory has not yet been considered , apart from our case study in @xcite .",
    "our present framework allows for the development of such a linear response theory .",
    "we obtain a general form for the ip - entropy production in terms of the affinities and the onsager matrix . for uni - cyclic machines ,",
    "we show that an ip - efficiency , involving information processing , at maximum power varies between @xmath0 and @xmath1 , whereas the ip - efficiency at maximum erasure rate is @xmath0 .",
    "the paper is organized as follows . in sec .",
    "[ sec2 ] , we explain the notion of an information reservoir using a two - state version of the mj model . a general inequality , from which the standard entropy production of stochastic thermodynamics and a novel ip - entropy production accounting for information reservoirs are obtained , is proved in sec .",
    "[ sec3 ] . furthermore , with the transition rates fulfilling a generalized detailed balance relation",
    ", we identify the general first and second law for a thermodynamic system interacting with information reservoirs . in sec .",
    "[ sec4 ] , we study a simple three - state model illustrating how an information reservoir changes the second law and a two - state system that only interacts with information reservoirs , with no heat dissipation or work exchange . a linear response theory including information processing is developed in sec . [ sec5 ] .",
    "we conclude in sec .",
    "[ sec6 ] . in appendix",
    "[ appa ] , we prove a master fluctuation theorem generalizing the inequality from sec .",
    "we can motivate our generalization of stochastic thermodynamics and give a clear interpretation of an information reservoir by starting with a simple paradigmatic model @xcite , which corresponds to a reduced ( from six to two states ) version of the mj model .",
    "the system consists of two states , labeled @xmath2 and @xmath3 .",
    "state @xmath2 has internal energy @xmath4 and the internal energy of state @xmath3 is @xmath5 .",
    "transitions between the states are mediated by thermal reservoir at temperature @xmath6 , implying @xmath7 where @xmath8 is the transition rate from @xmath2 to @xmath3 and @xmath9 is the transition rate from @xmath3 to @xmath2 .",
    "the system is also connected to a work reservoir .",
    "( @xmath3 ) to @xmath3 ( @xmath2 ) the bit changes its state from @xmath4 ( @xmath10 ) to @xmath10 ( @xmath4 ) . , width=272 ]    in order to extract work from a single heat bath an information reservoir is also needed , which can be understood as a sequence of bits , i.e. , a tape , that interacts with the system . as represented in fig .",
    "[ fig1 ] , a bit from the tape interacts with the system for a certain time interval in such a way that the bit state @xmath4 ( @xmath10 ) is coupled to the system state @xmath2 ( @xmath3 ) . for example , during this time interval , if the system makes a thermal transition from @xmath2 to @xmath3 the bit changes from @xmath4 to @xmath10 .",
    "after this interaction time interval the tape moves one step forward , with the bit that interacted with the system leaving and a next bit from the tape coming to interact with the system . this new incoming bit can generate effective transitions between the states of the system , leading to an exchange of energy with the work reservoir , as shown in fig .",
    "[ fig2 ] .     and the new incoming bit in state @xmath4 , leading to extracting a quantity @xmath5 of work . in case 2",
    "the system is in state @xmath2 and the new incoming bit is in state @xmath10 , which leads to a quantity @xmath5 of work entering the system from the work reservoir .",
    "case 3 ( 4 ) corresponds to the system being in state @xmath2 ( @xmath3 ) and the the new incoming bit in state @xmath4 ( @xmath10 ) , which does involve exchange of energy with the work reservoir .",
    "the letter @xmath11 in the tape represents a bit that can be either in state @xmath4 or @xmath10 .",
    ", width=309 ]    more precisely , if the system finishes the time interval in state @xmath3 and the new incoming bit is in state @xmath4 , the energy levels of the system are interchanged with the occupied level @xmath3 being lowered to energy @xmath4 and the empty level @xmath2 being raised to energy @xmath5 .",
    "the lowering of the occupied level @xmath3 leads to a work extraction of @xmath5 . after changing the energy levels ,",
    "the labels of the states are also interchanged and , therefore , this operation leads to a transition from @xmath3 to @xmath2 . in the same way ,",
    "if the system finishes the time interval in state @xmath2 and the new incoming bit is in state @xmath10 , then an effective transition from @xmath2 to @xmath3 resulting in work @xmath5 flowing from the work reservoir to the system occurs . in the other two cases , namely , the system finishing the time interval in state @xmath2 and the new incoming bit being @xmath4 or the system finishing in state @xmath3 and the new incoming bit being @xmath10 , no work exchange takes place .",
    "the probability that the new incoming bit is in state @xmath10 is @xmath12 and in state @xmath4 is @xmath13 .",
    "the interaction time interval is assumed to be exponentially distributed with a rate @xmath14 , which characterizes the velocity of the tape . assuming a constant time interval , as in @xcite , does not change the qualitative behavior of the model @xcite .",
    "the advantage of working with exponentially distributed time intervals is that the model can be described as a nonequilibrium steady state ( ness ) .",
    "the transition rates for the four - state markov process , corresponding to a duplication of the two - state system are displayed in fig .",
    "this duplication is necessary to include transitions generated by the new incoming bit .",
    "more precisely , a transition between the different subscripts @xmath15 and @xmath16 is generated by the new incoming bit and implies the tape moving forward .",
    "the time - scale for these transitions is then @xmath17 and , as the new incoming bit does not depend on the state of the system , the transition rates between states with different subscripts are independent of the state of the system , e.g. , the transition rate from @xmath18 to @xmath19 is the same as the transition rate from @xmath20 to @xmath19 .",
    "transitions between states with the same subscript are related to the thermal reservoir .     and @xmath9 .",
    "transition between states with a different subscript are related to the tape moving forward and a new bit coming to interact with the system .",
    "the solid arrows represent transitions with rate @xmath21 ) and the dashed arrows with @xmath22.,width=272 ]      in the limit @xmath23 , the probability of finishing the interaction time interval in state @xmath3 is @xmath24 .",
    "we denote the stationary probability of , for example , state @xmath18 as @xmath25 . defining @xmath26 , with @xmath27 , the stationary probability of state @xmath3 , in the four - state model in fig .",
    "[ fig3 ] , is @xmath28 where @xmath29 .",
    "this stationary probability corresponds to the probability of finishing an interacting time interval in state @xmath3 . in other words",
    ", @xmath30 is the probability of being in state @xmath3 before a jump between different subscripts occurs .",
    "the rate of extracted work is @xmath31=\\gamma e[p_\\tau-\\epsilon ] .",
    "\\label{wout2s}\\ ] ] since @xmath30 is the probability of being in state @xmath3 at the end of an interacting time interval , the probability of finding a @xmath10 in the outgoing tape , which amounts to the sequence of bits that has already interacted with the system , is @xmath30 .",
    "this outgoing tape is then a record of the interaction with the system , and has shannon entropy @xmath32 while the incoming tape has shannon entropy @xmath33 . as we demonstrate in the next section , the following second law inequality holds , @xmath34-\\dot{w}_{\\textrm{out}}\\ge0 , \\label{s1a}\\ ] ] where @xmath35 is the ip - entropy production .",
    "the physical meaning of the inequality is the following .",
    "let us consider the case @xmath36 and @xmath37 .",
    "for @xmath38 , the system operates as a machine , with the extracted work being bounded by the shannon entropy change in the tape @xmath39 , which is positive . considering a tape with larger shannon entropy as containing more information , the capacity of the tape to store information is the thermodynamic resource that is consumed in this process . if @xmath40 , it is convenient to rewrite ( [ s1a ] ) as @xmath41 where @xmath42 is the rate of work entering the system . in this case",
    "the system operates as an eraser : work is consumed in order to decrease the shannon entropy of , or erase information from , the tape .",
    "for a complete discussion of the full phase diagram of a similar model see @xcite .",
    "we note that the exactly same model can be interpreted as a feedback driven system with a controller performing measurements . with this interpretation a different entropy production",
    "is obtained @xcite .",
    "the stationary state properties of the four - state model are identical to the stationary state properties of the two - state model represented in fig .",
    "[ fig4 ] , with the stationary probability of state @xmath3 in the two - state model @xmath43 . within this reduced two - state model , one link , with the transition rates",
    "@xmath8 and @xmath9 , is related to a thermal reservoir .",
    "the other transitions are generated by the information reservoir as explained above .",
    "whenever the system makes a transition through the thermal link , heat is exchanged with the heat reservoir . if the transition is through the link associated with the information reservoir the system exchanges work with the work reservoir . from the first law the heat taken from the thermal reservoir equals the extracted work .",
    "the contribution to @xmath35 in eq .",
    "( [ s1a ] ) related to the link associated with the thermal reservoir is the rate of dissipated heat @xmath44 and the contribution of the link associated with the information reservoir is @xmath45 .    as we will show in the next sections a more general second law inequality allows for this interpretation of any link between states as being associated with an information reservoir .",
    "the terms in @xmath35 related to information reservoirs are proportional to a shannon entropy change , as is @xmath39 in ( [ s1a ] ) .    .",
    ", width=272 ]      besides @xmath35 , the standard thermodynamic entropy production of stochastic thermodynamics @xcite for the two - state model reads @xmath46 comparing with the entropy rate ( [ s1a ] ) we obtain @xmath47 .",
    "the contribution @xmath48 has a clear physical interpretation .",
    "let us first take @xmath49 . consider another two - state system with which we can reset the tape .",
    "the energy difference of this auxiliary system is chosen as @xmath50 $ ] , the incoming tape is characterized by the probability of a @xmath10 being @xmath30 , and @xmath51 , where @xmath52 is the time - scale of its thermal transitions .",
    "the auxiliary two - state system acts as an eraser and its entropy rate ( [ s1b ] ) becomes @xmath53\\ge0,\\ ] ] where the first term is obtained from ( [ wout2s ] ) with energy @xmath50 $ ] .",
    "hence , the term @xmath48 , appearing in ( [ sa ] ) is the rate of work that must be consumed , which equals the rate of heat that must be dissipated , in order to recover the original tape with shannon entropy @xmath33 from a tape with shannon entropy @xmath54 , using an auxiliary two - state system with @xmath51 and @xmath50 $ ] .",
    "similarly , if @xmath49 , the term @xmath55 in @xmath56 corresponds to the work that would be extracted from an incoming tape with shannon entropy @xmath54 interacting with the auxiliary two - state system with @xmath50 $ ] and @xmath51 .",
    "hence , the standard entropy production of stochastic thermodynamic @xmath56 contains the full thermodynamic cost of restoring the tape to its original distribution @xcite .",
    "we consider a thermodynamic system with generic states denoted by @xmath57 and @xmath58 with internal energy @xmath59 and @xmath60 .",
    "this system is in contact with reservoirs @xmath61 at inverse temperature @xmath62 . in a transition from @xmath57 to @xmath58 , besides exchanging heat with the reservoir @xmath61 the system can also exchange work if a generic quantity @xmath63 changes . the field",
    "associated with this quantity and reservoir @xmath64 is @xmath65 .",
    "for example , if @xmath66 , where @xmath67 is the number of particles in the system in state @xmath57 , then @xmath68 is the chemical potential of these particles . note that changing the parameter @xmath61 corresponds to a different chemical potential and the same particles , whereas , changing @xmath69 could correspond to another kind of particle that is exchanged with the system .     and field @xmath70 .",
    "information reservoirs are characterized by @xmath71 , the probability of a bit in state @xmath10 . the additional work reservoir , related to transitions mediated by the information reservoir for which the internal energy of the system changes , is indicated by @xmath72.,width=272 ]    besides these standard reservoirs the system also interacts with information reservoirs , which can be understood as a tape interacting with a pair of states of the system in the way explained in sec . [ sec2 ] . an information reservoir @xmath73",
    "is characterized by @xmath71 , the probability that an incoming bit is in the state @xmath10 .",
    "the coupling between information reservoirs and the system changes the entropy balance while keeping the first law intact , as they do not exchange energy with the system . in fig .",
    "[ fig6 ] , a system interacting with both standard and information reservoirs is depicted .",
    "there is also an additional work reservoir , which is related to the fact that if the system goes from state @xmath57 to @xmath58 through a transition mediated by an information reservoir the change in internal energy of the system is assumed to be compensated by an exchange of work with this additional work reservoir .",
    "the system is assumed to be described by markovian dynamics with the transition rates from @xmath57 to @xmath58 related to a standard reservoir @xmath61 being @xmath74 .",
    "these transition rates fulfill the local detailed balance relation @xcite @xmath75 for an information reservoir @xmath73 , the associated transition rates fulfill @xmath76 where state @xmath57 is related to the bit state @xmath4 and state @xmath58 to @xmath10 .",
    "the steady state probability of state @xmath57 is denoted @xmath77 and the stationary probability current from @xmath57 to @xmath58 related to reservoir @xmath78 is @xmath79 where @xmath78 can be either a standard or an information reservoir .",
    "the rate of internal energy variation related to transitions mediated by reservoir @xmath78 is @xmath80 where @xmath81 means a sum over all pairs @xmath82 without summing the same pair twice . in the steady state ,",
    "the contribution due to all reservoirs must be zero , i.e. , @xmath83 furthermore , the rate of variation of a generic quantity @xmath84 due to the interaction with a standard reservoir @xmath61 reads @xmath85 the rate of heat dissipated in reservoir @xmath61 is identified as @xmath86 information reservoirs @xmath73 , on the other hand , do not involve any heat dissipation .",
    "the rate of work entering the system is @xmath87 where the contribution @xmath88 is the work entering the system from the additional work reservoir .",
    "the first law then becomes @xmath89    the second law inequality generalizing stochastic thermodynamics for a system interacting with information reservoirs , which follows from a more general inequality proved in the next subsection , reads @xmath90 where @xmath91 , \\label{sharate}\\ ] ] with @xmath92 and @xmath93 the term @xmath94 is the rate at which the entropy of the information reservoir changes due to the interaction with the system . the term @xmath95 in eq . ( [ sharate ] ) is the time - scale for transitions between @xmath57 and @xmath58 through @xmath73 multiplied by the stationary probability of the pair of states @xmath96 , whereas the term @xmath97 is the shannon entropy change , with the outgoing tape being a record of the stationary relative probability of the pair @xmath98 .",
    "if an information reservoir labeled by @xmath73 is related to more than one pair of states , one can imagine that each pair is related to a different tape , with all incoming tapes having distribution @xmath71 and each outgoing tape having distribution @xmath98 .",
    "the information reservoir does not need to be understood as a tape of ordered bits running through the system .",
    "another possibility is to consider it as some bath of particles that can be in states @xmath4 and @xmath10 @xcite . during a transition",
    ", the system takes a new particle from this bath with distribution @xmath71 and releases the old particle to another bath that will have distribution @xmath98 . within this view",
    ", the same bath is related to all pair of states associated with @xmath73 .",
    "we note that it is also possible to study entropic interactions with the standard entropy production . specifically , assigning an intrinsic entropy to a state @xmath57 @xcite , entropic currents related to this intrinsic entropy appear in the standard thermodynamic entropy production , modifying the second law while keeping the first law unaltered .",
    "entropic currents can also be interpreted as being related to a maxwell s demon monitoring the transitions of the system @xcite . moreover , in a recent case study of a quantum dot interacting with a tape , the term related to the shannon entropy change was found to be proportional to an entropic current @xcite .",
    "assuming first that there is only one link for each pair of states , the stationary master equation reads @xmath99=0 . \\label{meq}\\ ] ] the standard thermodynamic entropy production is @xmath100 to obtain a more general formula , we consider auxiliary transition rates @xmath101 .",
    "moreover , we define the quantities @xmath102 and @xmath103 , which are constrained to fulfill the relation @xmath104 with these auxiliary transition rates we define @xmath105 using the inequality @xmath106 and summing @xmath107 to the right hand side of the above equation , we obtain @xmath108 where we used eq .",
    "( [ wconstraint ] ) .",
    "this inequality is a generalization of ( [ secine ] ) , since for the choice @xmath109 the rate @xmath110 becomes the entropy production @xmath56 .",
    "a fluctuation theorem generalizing ( [ gensecond ] ) is proved in app .",
    "[ appa ] .",
    "we now consider the possibility of more than one link between the same pair of states , since different reservoirs can be related to the same pair of states .",
    "this is the case of the two - state model of sec .",
    "[ sec2 ] . in this case",
    "the total transition rate reads @xmath111 , where @xmath78 label different links ( reservoirs ) . the same is valid for the auxiliary rates @xmath112 .",
    "furthermore , for convenience , we write @xmath113 and @xmath114 . for multiple reservoirs we then define the quantity @xmath115 which , from the log sum inequality , is larger than @xmath110 defined in eq .",
    "( [ eqom ] ) .",
    "the standard entropy production with multiple links becomes @xcite @xmath116 where @xmath117 .",
    "this formula can also be obtained from eq .",
    "( [ gensecond2 ] ) by setting @xmath118 and @xmath119 . to obtain the ip - entropy production we separate the links @xmath78 into links related to standard reservoirs @xmath61 and link related to information reservoirs @xmath73 . for the @xmath61",
    "links the choice for the auxiliary rates is the same as the one used to obtain @xmath56 . for reservoirs @xmath73 , choosing @xmath120 , @xmath121 , @xmath122 , and @xmath123 , eq .",
    "( [ gensecond2 ] ) becomes the ip - entropy production @xmath124 where @xmath94 is defined in eq .",
    "( [ sharate ] )    from ( [ fullent ] ) and ( [ infent ] ) , we obtain the difference between @xmath56 and @xmath35 as @xmath125 where @xmath126 is the kullback - leibler distance @xcite .",
    "the physical meaning of this inequality is the same as in the two - state model .",
    "the standard entropy production @xmath56 contains the thermodynamic cost of resetting each tape @xmath73 , using an auxiliary two - state system as discussed in sec .",
    "in the model analyzed in sec . [ sec2 ] , the presence of an information reservoir allowed the work extraction from a single heat bath . using inequality ( [ entinfphys ] ) ,",
    "we now introduce a simple model where the presence of a information reservoir allows heat to flow from a cold to a hot reservoir .",
    "a four - state model with fixed interaction time intervals for a refrigerator powered by a tape has been analyzed in @xcite .     and are @xmath127 are relate to the information reservoir .",
    "they are the same for both the refrigerator powered by a tape ( sec .",
    "[ sec4a ] ) and the thermoelectric machine interacting with a tape ( sec . [ sec4b]).,width=234 ]    for a system interacting with one information reservoir , related to a rate of shannon entropy change @xmath128 from eq .",
    "( [ sharate ] ) , and two heat reservoirs at inverse temperatures @xmath129 and @xmath130 , with @xmath131 , the first law ( [ firstlaw ] ) becomes @xmath132 where @xmath133 is the rate at which heat flows from the cold to the hot reservoir defined in ( [ heatdef ] ) .",
    "the ip - entropy production ( [ entinfphys ] ) is @xmath134 hence , if @xmath135 then @xmath133 can be positive , i.e. , heat can flow from the cold to the hot reservoir .",
    "this specific form of the second law has also been obtained in @xcite using an hamiltonian formalism .    a specific three - state model with states @xmath136 , @xmath11 , and @xmath137",
    "is represented in fig .",
    "the transition rates between @xmath136 and @xmath11 are associated with the cold reservoir at inverse temperature @xmath129 , whereas the transition rates between @xmath11 and @xmath137 are associated with the hot reservoir with inverse temperature @xmath131 .",
    "states @xmath136 and @xmath137 have internal energy @xmath4 , and state @xmath11 has internal energy @xmath5 .",
    "the local detailed balance relation then reads @xmath138 we choose these transition rates as @xmath139 , @xmath140 , @xmath141 , and @xmath142 .",
    "the parameter @xmath143 sets the time - scale of the thermal transitions .",
    "the transition rates between @xmath136 and @xmath137 are related to an information reservoir such that state @xmath136 ( @xmath137 ) is coupled to the bit state @xmath4 ( @xmath10 ) . with the probability of a bit in state @xmath10 being @xmath37 in the incoming tape , the transition rates are then written as @xmath144 and @xmath145 , where @xmath14 sets the time - scale of the information reservoir .    calculating the stationary probability distribution",
    "we obtain @xmath146 where @xmath147 , @xmath148 , and @xmath26 .",
    "furthermore , the probability current in the clockwise direction in fig .",
    "[ fig5 ] is @xmath149= \\gamma(p_a+p_c)[p_\\tau-\\epsilon]\\propto ( p-\\epsilon ) , \\label{curr3}\\ ] ] where @xmath150 restricting to @xmath37 , for @xmath151 the probability current in eq .",
    "( [ curr3 ] ) is positive leading to heat flowing from the cold to the hot reservoir .",
    "more precisely , the ip - entropy production ( [ entinfphys ] ) becomes @xmath152-\\dot{q}(\\beta_1-\\beta_2),\\ ] ] where @xmath153 is the rate at which heat flows from the cold to the hot reservoir .",
    "the refrigerator mode of operation ( @xmath151 ) is powered by the tape , which has its shannon entropy increased from @xmath33 to @xmath54 .",
    "for @xmath49 the probability current @xmath154 becomes negative and heat flows from the hot to the cold reservoir . in this case information",
    "is erased from the tape and the rate of shannon entropy decrease of the tape is compensated by the rate of entropy increase of the external environment due to the heat flow , i.e. , @xmath155\\le-\\dot{q}(\\beta_1-\\beta_2)$ ] .",
    "we now consider the case where the system also exchanges particles with the standard reservoirs .",
    "the system is in contact with a reservoir at inverse temperature @xmath129 and chemical potential @xmath156 , another reservoir characterized by @xmath130 and @xmath157 , and an information reservoir .",
    "the chemical potentials fulfill @xmath158 , where @xmath10 is assumed to be the hot reservoir , i.e. , @xmath159 . the first law ( [ firstlaw ] ) is reduced to @xmath160 where @xmath161 is the rate of work extracted from the system to move particles against the chemical potential gradient @xmath162 ( from @xmath10 to @xmath163 ) at a rate @xmath164 , and @xmath165 ( @xmath166 ) is the rate of dissipated heat related to reservoir @xmath10 ( @xmath163 ) .",
    "the ip - entropy production ( [ entinfphys ] ) for this case reads @xmath167 where @xmath128 is the rate of shannon entropy change given in eq .",
    "( [ sharate ] ) .",
    "first , we note that if @xmath168 a positive @xmath128 can move particles against the chemical potential .",
    "this corresponds to extracting work from a single heat bath , which was also the case of the model from sec .",
    "second , for the case where the temperature gradient @xmath169 drives the particles against @xmath162 , the pseudo - efficiency @xmath170 becomes @xmath171 where @xmath172 is the carnot efficiency .",
    "hence this pseudo - efficiency can exceeded the carnot efficiency @xmath173 .",
    "actually , it can even exceed @xmath10 as demonstrated below .",
    "a relation similar to ( [ eefstrange ] ) has also been obtained in @xcite using different frameworks .    as a specific model describing such situation",
    "we take the three - state model from fig .",
    "we now assume that in state @xmath11 the number of particles in the system is @xmath174 and in states @xmath136 and @xmath137 it is @xmath175 .",
    "the local detailed balance relation must be modified to @xmath176 where @xmath156 and @xmath157 are chemical potentials .",
    "we set these transition rates to @xmath177 , @xmath178 , @xmath179 , and @xmath180 .",
    "the transition rates between @xmath136 and @xmath137 are mediated by an information reservoir and are as in the model from sec .",
    "[ sec4a ] .    calculating the stationary distribution",
    "we obtain @xmath181 where @xmath26 , @xmath182 , @xmath183 , and @xmath184 } ) .",
    "\\label{defp}\\ ] ] the probability current is again @xmath149= \\gamma(p_a+p_c)[p_\\tau-\\epsilon]\\propto ( p-\\epsilon).\\ ] ] therefore , the rate of heat taken from the hot reservoir becomes @xmath185 the rate of heat dissipated in the cold reservoir @xmath186 and the rate of extracted work @xmath187 moreover , the rate at which the shannon entropy of the information reservoir increases due to the interaction with the system is @xmath188.\\ ] ]     with particle exchange with the reservoirs .",
    "the signs of the triplet @xmath189 are : @xmath190 in @xmath191 ; @xmath192 in @xmath193 ; @xmath194 in @xmath195 ; @xmath196 in @xmath197 ; @xmath198 in @xmath199 ; @xmath200 in @xmath201",
    ". the differences between the phases are explained in the text .",
    ", width=272 ]    we restrict to the case @xmath37 and @xmath36 , which from ( [ defp ] ) implies @xmath202 . from eq .",
    "( [ eqq1 ] ) and eq .",
    "( [ eqw ] ) , the pseudo - efficiency ( [ pseudoeff ] ) is given by @xmath203 we define @xmath204 ( @xmath205 ) as the probability @xmath206 , given in eq .",
    "( [ defp ] ) , for @xmath207 ( @xmath208 ) .",
    "the phase diagram of the model is shown in fig . [ fig7 ] .",
    "first we take @xmath151 , for which @xmath135 . for @xmath209 , corresponding to region @xmath191 in fig .",
    "[ fig7 ] , the pseudo - efficiency @xmath210 is smaller than one and the system operates as a standard thermoelectric machine with an improved efficiency . in region @xmath193 with @xmath211 , the system takes heat from the hot and the cold reservoir , i.e. , @xmath166 in eq .",
    "( [ q2model ] ) becomes negative .",
    "the pseudo - efficiency then fulfills @xmath212 , since the extracted work is larger than the heat taken from the hot reservoir . for @xmath213 from above @xmath214 . crossing to region @xmath195 , where @xmath215 , the pseudo - efficiency becomes formally negative : the system takes heat from the cold reservoir , dissipates heat in the hot reservoir and does work against the chemical gradient .",
    "the unusual modes of operation @xmath193 and @xmath195 are only possible because of the entropy increase in the information reservoir .",
    "second we consider @xmath49 , corresponding to erasure of information from the tape",
    ". in the region @xmath197 the system operates as a refrigerator , with the work entering the system @xmath216 being used to erase the tape and produce a heat flow from the cold to the hot reservoir . in the region @xmath199 the work entering the system is dissipated as heat in both reservoirs . in the region @xmath201 the system takes heat from the hot reservoir and dissipates heat in the cold reservoir .",
    "it is also possible for a system to interact with more than one information reservoir .",
    "the simplest case is a system interacting with two information reservoirs , with no exchange of energy . as an example",
    ", we consider a two - state model with two links between the states as the model from sec .",
    "however , instead of one link being related to a thermal reservoir , both links are associated with information reservoirs . for one tape",
    "the probability of a @xmath10 is @xmath217 and for the other one this probability is @xmath218 .",
    "the bit state @xmath4 ( @xmath10 ) couples with state @xmath2 ( @xmath3 ) .",
    "the transition rates from @xmath2 to @xmath3 is @xmath219 for link @xmath10 and @xmath220 for link @xmath163 .",
    "the reversed transition rates from @xmath3 to @xmath2 are @xmath221 and @xmath222 , respectively .",
    "the ip - entropy production ( [ entinfphys ] ) is @xmath223+\\gamma_2[h(p_\\tau)-h(\\epsilon_2)]\\ge 0,\\ ] ] where @xmath224 .",
    "assuming @xmath225 , information is written on tape @xmath10 and erased from tape @xmath163 .",
    "the efficiency of erasing information is @xmath226}{\\gamma_1[h(p_\\tau)-h(\\epsilon_1)]}\\le 1.\\ ] ] we call any efficiency involving a rate of shannon entropy change of an information reservoir , as the efficiency above , an ip - efficiency .",
    "for @xmath227 we obtain @xmath228 and for @xmath229 the ip - efficiency reaches @xmath230 it is interesting to compare the present situation with the case of a model in contact with two heat baths , for which heat flows from the hot to the cold reservoir . for the system in contact with thermal reservoirs , the heat that leaves",
    "the hot reservoir is the heat entering the cold reservoir .",
    "on the other hand , information ( or entropy ) , unlike energy , is in general not conserved , with the information erased from tape @xmath163 being smaller than the information written on tape @xmath10 .",
    "we denote ordinary affinities by @xmath231 and the conjugate flux by @xmath232 .",
    "the number of independent ordinary affinities ( or fluxes ) depend on how many standard reservoirs @xmath61 and fields @xmath65 we have .",
    "for example , for two reservoirs @xmath233 exchanging energy and particles , related to the chemical potentials @xmath156 and @xmath157 , there are two ordinary affinities @xmath234 .",
    "the first affinity is @xmath235 and the associated flux is @xmath236 .",
    "the second affinity is @xmath237 and the associated flux is @xmath238 .    for simplicity",
    "we assume that each information reservoir @xmath73 is related to only one pair @xmath82 so that @xmath239 and @xmath240 , where @xmath95 is defined in ( [ gammadef ] ) and @xmath98 in ( [ pijdef ] ) .",
    "the standard entropy production @xmath56 is known to be given by a sum of terms composed by a current multiplying an affinity @xcite . hence , from eqs .",
    "( [ infaff ] ) and ( [ fullent ] ) , the affinity related to an information reservoir is @xmath241 , \\label{aff}\\ ] ] with the associated current being @xmath242",
    ". the variable @xmath78 in the formulas below can be either the index @xmath143 or the index @xmath73 , so that @xmath243 . near equilibrium , where all affinities are close to zero ,",
    "a flux can be written as @xmath244 where @xmath245 is the onsager coefficient , with @xmath246 representing a vector with all affinities .",
    "the standard entropy production ( [ fullent ] ) then becomes @xmath247    from ( [ infaff ] ) , ( [ gammadef ] ) , and ( [ pijdef ] ) , the current related to reservoir @xmath73 , as given in eq .",
    "( [ gencurr ] ) , can be written as @xmath248 which leads to @xmath249 assuming @xmath250 small , we expand the rate of shannon entropy change ( [ sharate ] ) in the following way , @xmath251 where we set @xmath252 for the term @xmath253 .",
    "the choice @xmath252 corresponds to the genuine equilibrium of the system , with the affinity in eq .",
    "( [ aff ] ) being @xmath254 . on the other hand",
    ", @xmath255 corresponds to a `` stall force '' case .",
    "hence , setting @xmath252 in eq .",
    "( [ linear1 ] ) implies a linear response treatment with respect to genuine equilibrium . using eqs .",
    "( [ entinfphys ] ) , ( [ linear2 ] ) , and ( [ linear1 ] ) , we obtain the ip - entropy production in the linear response regime , @xmath256 note that @xmath257 can be obtained from the equilibrium probabilities with @xmath258 .",
    "a well known result in linear response theory is that the efficiency at maximum power for uni - cyclic machines is @xmath0 @xcite .",
    "we now calculate the ip - efficiencies at maximum power for uni - cyclic machines .",
    "the standard efficiency contains the work entering the system in its denominator , which corresponds to the work to reset the tape appearing in the standard entropy production , as explained in sec .",
    "since this work is larger than the rate of shannon entropy change , the ip - efficiency at maximum power should not be smaller than @xmath0 .     and",
    "@xmath10 are associated with an information reservoir , whereas the other transition rates are related to a standard reservoir .",
    "note that we have a cyclic system with @xmath259 being the @xmath4 state again . , width=272 ]    we consider the generic uni - cyclic machine with @xmath259 states on a ring depicted in fig .",
    "the transition rates between states @xmath4 and @xmath10 , which are related to the information reservoir , are @xmath260 and @xmath22 , with the first being from @xmath4 to @xmath10 .",
    "the other transition rates are related to standard reservoirs with inverse temperature @xmath261 , and the transition rate from @xmath73 ( @xmath262 ) to @xmath262 ( @xmath73 ) is @xmath263 ( @xmath264 ) .",
    "we assume that the affinity @xmath265 where @xmath266 and @xmath267 , is related to work extracted from the system .    for the system to operate as a machine the probability current from left to right in fig .",
    "[ fig8 ] must be positive .",
    "this probability current is @xmath268 where @xmath269 .",
    "the affinity related to the information reservoir is @xmath270.\\ ] ] it is convenient to define @xmath271 and @xmath272 using a diagrammatic method to obtain the stationary probability distribution @xcite , we obtain @xmath273 where @xmath274 , with @xmath275 and @xmath276 $ ] . note that this formula is similar to the formula ( [ ptaueq ] ) for the two state model of sec .",
    "[ sec2 ] , which corresponds to @xmath174 .",
    "the parameter @xmath52 has dimension of a transition rate and is related to the thermal transition rates .",
    "therefore , the parameter @xmath277 is dimensionless being @xmath10 ( @xmath4 ) if the transitions of the information reservoir , which are proportional to @xmath14 , are much slower ( faster ) than thermal transitions .    up to first order in the affinities ,",
    "the current ( [ curruni ] ) becomes @xmath278 where @xmath279 .",
    "hence , within linear response , the rate of extracted work is @xmath280 and the rate of shannon entropy change ( [ linear1 ] ) is @xmath281 .",
    "\\label{hheq}\\ ] ]    we now maximize the power @xmath282 with respect to the output @xmath283 for fixed input @xmath284 .",
    "the power is maximum at @xmath285 , which gives the ip - efficiency at maximum power @xmath286 where @xmath287 and @xmath288 are obtained from ( [ wweq ] ) and ( [ hheq ] ) with @xmath285 , respectively .",
    "the ip - efficiency at maximum power reaches its maximum value @xmath1 for @xmath289 , where the transitions related to the information reservoir are much slower than the thermal transitions .",
    "if we had taken the work to reset the tape @xmath290 in the denominator , leading to the usual efficiency based on @xmath56 , the standard result @xmath0 would have been obtained .",
    "another interesting case is the ip - efficiency at maximum erasure rate when the system operates as an eraser , i.e. , @xmath291 .",
    "the work entering the system to erase the tape is @xmath292 where @xmath293 . rewriting ( [ hheq ] )",
    ", the erasure rate becomes @xmath294 .",
    "\\label{hhheq}\\ ] ] maximizing the erasure rate with respect to @xmath284 for fixed input , we obtain that @xmath295 is maximal at @xmath296 . the ip - efficiency at maximum erasure rate is then @xmath297 where @xmath298 and @xmath299 are evaluated at @xmath300 .",
    "note that this efficiency , unlike ( [ maxpower ] ) is independent of @xmath301 whereas @xmath296 , unlike @xmath285 , depends on @xmath301 .",
    "in @xcite we have obtained an efficiency at maximum erasure for a specific model of a system interacting with a tape that could move in both directions .",
    "the result obtained in this reference was @xmath302 .",
    "the difference with the present result comes from the fact that in @xcite we have considered an extra term in the denominator which was related to the possibility of taking back a bit from the outgoing tape to interact with the system .",
    "we have generalized the theory of stochastic thermodynamics to include information reservoirs .",
    "such reservoirs can be understood as a tape that has its shannon entropy modified due to the interaction with the system but does not exchange energy with the system .",
    "thus information reservoirs contribute to the second law while leaving the first law unaltered .",
    "this generalization is achieved with the ip - entropy production , which differs from the standard entropy production of stochastic thermodynamics .",
    "both entropy productions follow from the more general inequality ( [ gensecond ] ) , which can be further generalized with the fluctuation theorem proved in app .",
    "[ appa ] .    in principle , with our framework any thermodynamic system interacting with information reservoirs can be studied .",
    "our theory allows for the construction of simple models that can be used to understand the qualitative behavior of a thermodynamic system interacting with an information reservoir .",
    "for example , with the three - state model for a thermoelectric effect of sec .",
    "[ sec4 ] , we have shown that that there are regions in the phase diagram where the system can take heat from the cold reservoir and drive particles against the chemical potential gradient .",
    "furthermore , a convenient feature is that the full thermodynamic cost to reset the tapes to their original configurations is easily accessible , being contained in the standard entropy production .",
    "the power of our approach is also demonstrated by the fact that it allowed for the development of a systematic linear response theory for information processing machines , which was still lacking in the literature . as main results",
    ", we have obtained the ip - entropy production in the linear response regime in terms of the onsager coefficients and the affinities , and we have obtained ip - efficiencies ( at maximum power and maximum erasure rate ) for uni - cyclic machines .",
    "we thank d. hartich for helpful discussions .",
    "we prove a fluctuation theorem leading to the inequality ( [ gensecond ] ) .",
    "we consider a generic markov jump process with transition rates denoted by @xmath303 .",
    "the number of states is duplicated , with state @xmath57 being duplicated to @xmath304 and @xmath305 .",
    "the transition rates in the new duplicated system are such that states with the same subscript are not connected , i.e. , the transition rates between them are zero .",
    "the transition rates in the duplicated system are related to the transition rates in the original system system by the formula @xmath306 . moreover , the transition rates between @xmath304 and @xmath305 are @xmath307 .",
    "the stationary probability in the duplicated system is the same as in the original system .",
    "more precisely , the stationary master equation for @xmath308 in the duplicated system is @xmath309 comparing with eq .",
    "( [ meq ] ) , we see that @xmath310 , where @xmath77 indicates the stationary probability of state @xmath57 in the original system . a definition that is useful for the discussion below is the escape rate of state @xmath304 @xmath311 note that @xmath312 .    a stochastic trajectory in the duplicated system for a time interval @xmath313 $ ]",
    "is denoted @xmath314 , where @xmath315 is the state for @xmath316 $ ] , with @xmath317 , @xmath318 , and @xmath319 .",
    "the probability of a trajectory is @xmath320= p(x_0)\\left(\\prod_{n=0}^{n-1}w_{x_nx_{n+1}}\\right)\\prod_{n=0}^{n}\\exp(-\\lambda(x_n)\\tau_n)\\ ] ] where @xmath321 denotes the initial probability .",
    "the probability of the reversed trajectory @xmath322 with modified transition rates @xmath101 ( or @xmath323 is the jump is between @xmath304 and @xmath305 ) reads @xmath324= \\tilde{p}(x_n)\\left(\\prod_{n=0}^{n-1}\\overline{w}_{x_{n+1}x_n}\\right)\\prod_{n=0}^{n}\\exp(-\\overline{\\lambda}(x_n)\\tau_n),\\ ] ] where @xmath325 is the initial probability of the reversed trajectory and @xmath326 is the escape rate for the modified rates .",
    "the ratio of trajectory probabilities then becomes @xmath327}{\\overline{\\mathcal{p}}[\\tilde{x}_t]}= & \\frac{p(x_0)}{\\tilde{p}(x_n)}\\left(\\prod_{n=0}^{n-1}\\frac{w_{x_nx_{n+1}}}{\\overline{w}_{x_{n+1}x_n}}\\right)\\nonumber\\\\ & \\times\\prod_{n=0}^{n}\\exp[(\\overline{\\lambda}(x_n)-\\lambda(x_n))\\tau_n ) ] .",
    "\\label{ratioeq}\\end{aligned}\\ ] ] from eq .",
    "( [ escaprat ] ) , we obtain that the term @xmath328 if @xmath329 which is the constraint ( [ wconstraint ] ) .",
    "the activity for jumps from @xmath304 to @xmath330 and from @xmath305 to @xmath331 is a functional of the the trajectory @xmath332 defined as @xmath333\\equiv \\sum_{n=0}^{n}\\left(\\delta_{x_n , i_a}\\delta_{x_{n+1},j_b}+\\delta_{x_n , i_b}\\delta_{x_{n+1},j_a}\\right).\\ ] ] with this activity we define the functional @xmath334\\equiv \\sum_i\\left(\\sum_{j\\neq i}\\mathcal{k}_{ij}[x_t]\\ln\\frac{w_{ij}}{\\overline{w}_{ji}}+\\mathcal{k}_{ii}[x_t]\\ln\\frac{r_i}{\\overline{r}_i}\\right).\\ ] ] if the constraint ( [ wconstraint2 ] ) is satisfied , by choosing uniform distributions for both @xmath321 and @xmath325 in eq .",
    "( [ ratioeq ] ) , we obtain @xmath335}{\\overline{\\mathcal{p}}[\\tilde{x}_t]}= \\exp\\left(\\omega[x_t]\\right).\\ ] ] this relation then implies @xmath336\\right)\\mathcal{p}[x_t]=\\sum_{x_t}\\overline{\\mathcal{p}}[\\tilde{x}_t]=1,\\ ] ] where @xmath337 represents an integral over all stochastic trajectories .",
    "this integral fluctuation theorem leads to the inequality @xmath338 the above inequality is equivalent to ( [ gensecond ] ) , as @xmath339 .",
    "we note that the functional @xmath340 is , in general , not antisymmetric , i.e. , it can not be written as a sum of probability currents .",
    "it does become antisymmetric if the auxiliary rates are chosen so that @xmath341 becomes the standard entropy production but for auxiliary rates leading to the ip - entropy production it does not .    whereas the standard entropy production @xmath56 can be obtained from a fluctuation theorem for the original system @xcite , in order to obtain the ip - entropy production @xmath35 we need this fluctuation theorem for the duplicated system .",
    "this duplication has a physical interpretation if we compare fig .",
    "[ fig3 ] with fig .",
    "[ fig4 ] for the paradigmatic model of sec .",
    "[ sec2 ] . the duplication in fig .",
    "[ fig3 ] is necessary to include the possibility of transitions from @xmath18 to @xmath342 and @xmath20 to @xmath19 , which corresponds to transitions where the new incoming bit is in a state that couples to the state of the system .",
    "note that in the duplicated system of fig [ fig3 ] the states in the same replica are connected by the thermal transition link , which is different from the duplication in this appendix .",
    "if a set of links is assumed to be related to standard reservoirs , then a duplicated system keeping these links connecting states in the same replica and not in different replicas suffices to obtain a fluctuation theorem leading to the corresponding @xmath35 @xcite .",
    "the derivation of the fluctuation theorem in this case is very similar . here",
    ", we have chosen the duplication scheme above in order to obtain the most general inequality .",
    "10 [ 2]#2 [ 1]#1 [ 1]#1 and , ( , bristol and philadelphia , ) . , , and , , ( ) . , , , , , and , , ( )",
    ", , , , and , , ( ) .",
    ", , ( ) . , ( , ) .",
    ", , ( ) . and , , ( ) . and , , ( )",
    ". and , , ( ) . and , , ( ) . , , and , ( 09 ) , ( )",
    ". and , , ( ) . , , ( ) . and , , ( )",
    ". and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . , , and , , ( ) . , , ( ) . , , , and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . , , , and , , ( ) . , , , and , , ( ) . , , and , , ( ) . and , , ( ) . , , and , , ( ) . and , , ( ) . and , , ( ) . , , ( ) . , , and , , ( ) . , , and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . and , , ( ) . , , and , , ( ) . and , , ( ) . and , , ( ) . and , ( , amsterdam , ) . , ( , new york , ) . , , ( ) . , , ( ) . , , ( ) . , , ( ) .",
    ", , , and , ( ) . and , , ( , hoboken , nj , and canada , ) . , ( , mineola , new york , ) , 2nd ed ."
  ],
  "abstract_text": [
    "<S> we generalize stochastic thermodynamics to include information reservoirs . such information reservoirs , which can be modeled as a sequence of bits , modify the second law . for example </S>",
    "<S> , work extraction from a system in contact with a single heat bath becomes possible if the system also interacts with an information reservoir . </S>",
    "<S> we obtain an inequality , and the corresponding fluctuation theorem , generalizing the standard entropy production of stochastic thermodynamics . from this inequality </S>",
    "<S> we can derive an information processing entropy production , which gives the second law in the presence of information reservoirs . </S>",
    "<S> we also develop a systematic linear response theory for information processing machines . </S>",
    "<S> for an uni - cyclic machine powered by an information reservoir , the efficiency at maximum power can deviate from the standard value @xmath0 . </S>",
    "<S> for the case where energy is consumed to erase the tape , the efficiency at maximum erasure rate is found to be @xmath0 .    </S>"
  ]
}