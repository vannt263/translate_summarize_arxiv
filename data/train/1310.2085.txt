{
  "article_text": [
    "the sharpening of blurred images is a standard problem in many imaging applications . a great variety of different approaches to this severely ill - posed inverse problem",
    "have been developped over time which differ in the assumptions they make , and in their suitability for different application contexts .",
    "blur of an image is described by a _ point - spread function ( psf ) _ which describes the redistribution of light energy in the image domain @xmath1 . when blurring acts equally at all locations , one has a _ space - invariant psf _ @xmath2 which acts by convolution .",
    "accounting also for the impact of noise @xmath3 , a typical blur model ( with additive noise ) then reads @xmath4 where @xmath5 is the observed image , and @xmath6 the unknown sharp image .    in the more general case of a space - variant blur",
    "one needs a point - spread function with two arguments , @xmath7 , and @xmath8 is replaced with the integral operator @xmath9 such that @xmath10 which subsumes the space - invariant case by setting @xmath11 .",
    "we denote by @xmath12 the adjoint of the point - spread function @xmath13 , which is given by @xmath14 .",
    "conservation of energy implies generally that @xmath15 , however , this condition may be violated near image boundaries due to blurring across the boundary .    in deblurring , we want to obtain a restored image @xmath16 that approximates @xmath6 , with the degraded image @xmath5 and the psf @xmath13 as input .",
    "this is the case of _ non - blind _ deconvolution ( as opposed to blind deconvolution which aims at inferring the sharp image and the psf simultaneously from the degraded image ) .",
    "some approaches to the deconvolution problem are presented in more detail in section  [ sec - exdcvm ] .",
    "[ [ our - contribution . ] ] our contribution .",
    "+ + + + + + + + + + + + + + + + +    the main subject of this paper is to discuss a modification of the richardson - lucy ( rl ) deconvolution method @xcite by robust data terms .",
    "building on the known variational interpretation of rl deconvolution @xcite , we replace the asymmetric penaliser function in the data term in such a way that larger residual errors are penalised less than with the standard csiszr divergence term .    using robust data terms together with a regulariser similar to @xcite we",
    "obtain a robust and regularised richardson - lucy variant that unites the high restoration quality of variational deconvolution methods with high efficiency that is not far from the original richardson - lucy iteration .",
    "this method has already been used for experiments on recovering information from diffuse reflections in @xcite and , combined with interpolation , for the enhancement of confocal microscopy images @xcite .",
    "it has also been used to achieve efficient deconvolution under real - time or almost - real - time conditions @xcite .",
    "we demonstrate that both robust data terms and regularisers contribute substantially to its performance",
    ".    an earlier version of the present work is the technical report @xcite .",
    "[ [ related - work . ] ] related work .",
    "+ + + + + + + + + + + + +    the omnipresence of deblurring problems has made researchers address this problem since long @xcite . from the abundant literature on this topic , the most relevant work in our present context includes richardson - lucy deconvolution @xcite , variational methods @xcite , and their interplay @xcite ; see also @xcite for another approach to combine richardson - lucy deconvolution with regularisation .",
    "fundamental theoretical results on existence and uniqueness of solutions of deconvolution problems can be found in the work of bertero et al .",
    "@xcite .",
    "robust data terms in deconvolution go back to zervakis et al .",
    "@xcite in statistical models , and have recently been used intensively in the variational context by bar et al .",
    "@xcite and welk et al .",
    "positivity constraints were studied in discrete iterative deconvolution by nagy and strako @xcite and in a variational framework by welk and nagy @xcite .",
    "the extension of variational approaches to multi - channel images has been studied in @xcite and more specifically in deconvolution in @xcite .",
    "[ [ structure - of - the - paper . ] ] structure of the paper .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    in section  [ sec - exdcvm ] we recall approaches to image deconvolution which form the background for our approach , and discuss some aspects of noise models and robustness .",
    "section  [ sec - rrrl ] recalls the embedding of richardson - lucy deconvolution into a variational context . exploiting this connection ,",
    "the rl algorithm can be modified in order to increase restoration quality and robustness with respect to noise and perturbations .",
    "an experimental comparison of the deconvolution techniques under consideration is provided in section  [ sec - exp ] based on both synthetic and real - world data .",
    "conclusions in section  [ sec - conc ] end the paper .",
    "we start by recalling selected deconvolution approaches from the literature which we will refer to later .",
    "richardson - lucy ( rl ) deconvolution @xcite is a nonlinear iterative method originally motivated from statistical considerations .",
    "it is based on the assumption of positive grey - values and poisson noise distribution .",
    "if the degraded and sharp images , and the point - spread function are smooth functions over @xmath17 with positive real values , one uses the iteration @xmath18 to generate a sequence of successively sharpened images @xmath19 from the initial image @xmath20 .    in the absence of noise the sharp image @xmath6 is a fixed point of , as in this case the multiplier @xmath21 equals the constant function @xmath22 .",
    "the single parameter of the procedure is the number of iterations .",
    "while with increasing number of iterations greater sharpness is achieved , the degree of regularisation is reduced , which leads to amplification of artifacts that in the long run dominate the filtered image .",
    "this phenomenon is known by the name of _ semi - convergence_.      variational methods @xcite address the deconvolution task by minimising a functional that consists of two parts : a _ data term _ that enforces the match between the sought image and the observed image via the blur model , and a _ smoothness term _ or _ regulariser _ that brings in regularity assumptions about the unknown sharp image .",
    "the strength of variational approaches lies in their great flexibility , and in the explicit way of expressing the assumptions made .",
    "they achieve often an excellent reconstruction quality , but their computational cost tends to be rather high .    a general model for variational deconvolution of a grey - value image @xmath16 with known point - spread function @xmath13 is based on minimising the energy functional @xmath23 = \\int\\limits_\\varomega \\left ( \\varphi\\bigl((f - h\\circledast u)^2\\bigr ) + \\alpha\\ , \\varpsi\\bigl ( \\lvert\\nabla u\\rvert^2 \\bigr ) \\right ) { \\,\\mathrm{d}}{\\bm{x}}\\ ] ] in which the data term @xmath24 penalises the reconstruction error or _ residual _ @xmath25 to suppress deviations from the blur model , while the smoothness term @xmath26 penalises roughness of the reconstructed image . the _ regularisation weight _ @xmath27 balances the influences of both terms .",
    "@xmath28 are increasing penalty functions .    in the simplest case , @xmath29 is the identity , thus imposing a quadratic penalty on the data model .",
    "doing the same in the regulariser , one has whittaker - tikhonov regularisation @xcite with @xmath30 . as this choice leads to a blurring that directly counteracts the desired sharpening , it is often avoided in favour of regularisers with edge - preserving properties .",
    "a popular representative is total variation deconvolution @xcite which uses @xmath31 .",
    "edge - enhancing regularisers ( e.g.  of the perona - malik @xcite type ) were studied in @xcite . in @xcite ,",
    "nonlocal regularisation was proposed .    for the actual minimisation , often gradient descent or lagged - diffusivity - type",
    "minimisation schemes are employed .",
    "iterative schemes with advantageous convergence behaviour are derived from a half - quadratic approach in @xcite ( for the total variation regulariser ) and @xcite ( for certain non - convex regularisers ) .",
    "using in a penaliser @xmath29 with less - than - quadratic growth leads to _ robust data terms _ @xcite .",
    "for example , @xcite use the @xmath32 penaliser @xmath33 .",
    "the concept of robustness originates from statistics @xcite , and will be discussed in more detail below .",
    "spatially variant robust deconvolution models were investigated in @xcite .",
    "even richardson - lucy deconvolution can be interpreted as a fixed point iteration for an optimisation problem @xcite , using csiszr s _ information divergence _ @xcite as an ( asymmetric ) penaliser function . in a space - continuous formulation , one has the energy functional @xmath34 : = \\int\\limits_{\\varomega }   \\left(h\\circledast u - f - f\\ln\\frac{h\\circledast u}{f}\\right ) { \\,\\mathrm{d}}{\\bm{x}}\\;.\\ ] ] no regularisation term",
    "is included , which is linked to the above - mentioned semi - convergence behaviour . nevertheless , the energy formulation permits to modify richardson - lucy deconvolution in the same flexible manner as the standard variational approach by introducing robust data terms and edge - preserving , or even edge - enhancing , regularisers . while an edge - preserving regulariser in combination with richardson - lucy deconvolution has been used by dey et al .",
    "@xcite ( in a space - invariant setting ) , the possibility of a robust data term has so far not been studied in detail , although it has been used successfully in applications @xcite .",
    "statistical considerations @xcite link particular data terms to specific noise models , in the sense that minimising the so constructed energy functional yields a maximum likelihood estimator under the corresponding type of noise . for example , quadratic penalisation @xmath35 pertains to gaussian noise , while the @xmath32 penaliser @xmath36 matches laplacian noise . the asymmetric penaliser in is related to poisson noise .",
    "this relation allows to use an optimally adapted energy model whenever one has full control over the imaging process and can therefore establish an accurate noise model . in practice",
    ", one does not always have perfect control and knowledge of the imaging process .",
    "this is where the concept of _ robustness _ comes into play .",
    "according to huber @xcite , `` robustness signifies insensitivity to small deviations from the assumptions '' . in particular , `` distributional robustness '' means that `` the shape of the underlying distribution deviates slightly from the assumed model '' @xcite .",
    "this obviously applies to imaging processes in which no exact noise model is known , but also further violations of model assumptions can be subsumed here , such as imprecise estimates of psf , or errors near the image boundary due to blurring across the boundary , see @xcite .    to incorporate each single influence factor into a model is not always feasible .",
    "robust models are designed to cope with remaining deviations , and still produce usable results . in view of the uncertainty about the true distribution of noise",
    ", they are often based on data terms that match types of noise that are assumed to be `` worse '' than the real noise .",
    "a crucial point is to suppress the effect of outliers , which is achieved e.g.  by data terms that penalise outliers less .",
    "models are then adapted to distributions with `` pessimistically '' heavy tails .    to evaluate robustness experimentally ,",
    "it is not only legitimate but even necessary to test such models against severe , maybe even unrealistic , types of noise that do not exactly match the model .",
    "a frequently used test case is impulse noise , and it turns out that variational approaches actually designed for laplacian noise can cope with it practically well @xcite .",
    "of course , one can no longer expect to establish optimality in the maximum - likelihood sense with respect to the true noise .",
    "furthermore , any comparison between methods that are optimised for different noise models inevitably involves testing at least one of them with non - matching noise .",
    "for example , this happens already in any comparison of wiener filtering ( gaussian noise ) against richardson - lucy ( poisson noise ) .",
    "functionals of type are often minimised using gradient descent @xcite . alternatively",
    ", elliptic iteration schemes can be used @xcite .    [",
    "[ standard - gradient - descent . ] ] standard gradient descent .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    to derive a gradient descent equation for the energy @xmath37 from , one computes by the usual euler - lagrange formalism @xmath38\\right|_{\\varepsilon=0}$ ] for a small additive perturbation @xmath39 .",
    "the variational gradient ( gteaux derivative ) @xmath40 is obtained from @xmath41 by the requirement that @xmath42 holds for all test functions @xmath39 , where @xmath43 is the standard inner product of functions .    in an elliptic approach ,",
    "one now solves the euler - lagrange equation @xmath44 .",
    "a gradient descent for is given by the integro - differential equation ( compare @xcite ) @xmath45 complementing this equation with e.g.  the blurred image @xmath5 as initial condition and suitable boundary conditions , one has an initial - boundary value problem which is then approximated numerically until a steady state is reached , for example via an explicit euler scheme . as each iteration involves two @xmath46 operations , the computational expense is fairly high .",
    "even more sophisticated approaches like semi - implicit schemes with conjugate gradients for or the elliptic approach do not change the computational cost substantially , as the number of iterations for convergence in any scheme depends primarily on the extent and structure of the psf .",
    "[ [ positivity - constrained - gradient - descent . ] ] positivity - constrained gradient descent .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    from modelling considerations one can often infer additional information that helps to mitigate the ill - posedness of the deconvolution problem .",
    "for instance , in a scalar - valued image with grey - values proportional to radiance , only positive values are admissible .",
    "a strategy to incorporate this positivity constraint in the minimisation of has been described in @xcite .",
    "based on earlier work @xcite , it is proposed to reparametrise the grey - values by the substitution @xmath47 .",
    "the values of the new image function @xmath48 are unconstrained in @xmath49 .",
    "instead of one obtains thereby the gradient descent @xmath50    as detailed in @xcite , performing the gradient descent based on the variation of the function @xmath48 comes down to a function space transformation .",
    "essentially , the positivity - constrained gradient descent turns out to be the gradient descent in a hyperbolic metric . from this viewpoint , zero and",
    "negative grey - values are avoided because they are put at infinite distance from any positive values .",
    "this reinterpretation can immediately be transferred to interval constraints with a suitable metric on the open interval @xmath51 .",
    "we want to point out here another reinterpretation which is obtained by using a _ multiplicative _ gradient descent . to this end",
    ", one considers a multiplicative perturbation with a test function @xmath39 and computes the variation @xmath52 \\right|_{\\varepsilon=0}$ ] .",
    "analogous to the ordinary gteaux derivative @xmath40 above , a `` multiplicative gradient '' @xmath53 is then derived from the requirement @xmath54 .",
    "one finds @xmath55 , which constitutes a new derivation of the gradient descent without the substitution of @xmath16 .",
    "for given @xmath5 , @xmath13 , equation can be understood as a fixed point iteration associated to the minimisation of the functional , compare @xcite .",
    "this is the so - called _ information divergence _ introduced by csiszr @xcite .",
    "the asymmetric penaliser function @xmath56 is strictly convex for @xmath57 with its minimum at @xmath58 .    as a necessary condition for @xmath16 to be a minimiser of",
    ", one can compute an euler - lagrange equation which in this case becomes particularly simple as no derivatives of @xmath16 are present in the integrand . in view of the positivity requirement for @xmath16",
    "we start by a multiplicative perturbation of with a test function @xmath39 , @xmath59 \\right|_{\\varepsilon=0 }   & = \\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon }   \\int\\limits_{\\varomega }   \\biggl(h\\circledast \\bigl(u(1+\\varepsilon v)\\bigr ) -f- f\\ln\\frac{h\\circledast \\bigl(u(1+\\varepsilon v)\\bigr)}{f}\\biggr ) { \\,\\mathrm{d}}{\\bm{x}}\\bigg|_{\\varepsilon=0 } \\notag \\\\ & = \\int\\limits_\\omega \\left(1-\\frac{f}{h\\circledast u}\\right)\\ , \\bigl(h\\circledast ( uv)\\bigr ) { \\,\\mathrm{d}}{\\bm{x}}\\;.\\end{aligned}\\ ] ] with for the integral operator @xmath46 this becomes @xmath60 and , after changing the order of integration and rewriting @xmath13 into @xmath12 , @xmath61 requiring that this expression vanishes for all test functions @xmath39 yields the minimality condition @xmath62 because of the energy conservation property @xmath63 one sees that is a fixed point iteration for .      in the presence of noise",
    "the functional is not minimised by a smooth function @xmath16 ; in fact , the fixed - point iteration shows the above - mentioned semi - convergence behaviour and diverges for @xmath64 . from the variational viewpoint ,",
    "the functional needs to be regularised . in standard richardson - lucy deconvolution , this regularisation is provided implicitly by stopping the iteration after a finite number of steps .",
    "the earlier the iteration is stopped , the higher is the degree of regularisation .",
    "although this sort of regularisation is not represented in the functional , the variational picture is advantageous because can be modified in the same flexible way as standard variational approaches .",
    "the structure of the iterative minimisation procedure is preserved throughout these modifications , which leads to good computational efficiency .",
    "let us first note that by limiting the growth of high - frequency signal components , regularisation has a smoothing effect that in deconvolution problems acts contrary to the intended image sharpening .",
    "it is desirable to steer this effect in such a way that it interferes as little as possible with the enhancement of salient image structures , such as edges .",
    "implicit regularisation by stopping , however , allows little control over the way it affects image structures . for this reason",
    ", it makes sense to introduce a variational regularisation term into the objective functional .",
    "this yields the functional @xmath65 = \\int\\limits_{\\omega } \\left ( r_f(h\\circledast u ) + \\alpha\\ , \\varpsi(\\lvert\\nabla u\\rvert^2 ) \\right ) { \\,\\mathrm{d}}{\\bm{x}}\\ ] ] in which the richardson - lucy data term is complemented by a regulariser whose influence is weighted by the regularisation weight @xmath66 .",
    "concerning the penalisation function @xmath67 in the regulariser , our discussion from section  [ sec - exdcvm ] applies analogously . with the total variation regulariser given by @xmath68 , the energy functional corresponds to the method proposed ( in space - invariant formulation ) by dey et al .",
    "@xcite ; compare also the more recent work @xcite for a similar approach .",
    "the euler - lagrange equation for under multiplicative perturbation is given by @xmath69 which combines with the same multiplicative gradient for the regulariser as in , compare @xcite .    in converting this into a fixed point iteration",
    ", we evaluate the divergence expression with @xmath70 , yielding @xmath71 .",
    "dependent on whether the factor @xmath16 with which the divergence term in is multiplied is chosen as @xmath72 or @xmath73 , the right - hand side of either receives the additional summand @xmath74 , or is divided by @xmath75 .",
    "however , @xmath74 can have either sign , and a negative value in the numerator or denominator will lead to a violation of the positivity requirement . for this reason ,",
    "we choose the outer factor for @xmath74 as @xmath72 if @xmath76 , or @xmath73 if @xmath77 . using the abbreviations @xmath78_\\pm:=\\frac12(z\\pm\\lvert z\\rvert)$ ]",
    "we can therefore write our final fixed point iteration as @xmath79_+ } { 1 -   \\alpha \\left[{\\operatorname{div}}\\bigl ( \\varpsi'(\\lvert\\nabla u^k\\rvert^2)\\,\\nabla u^k\\bigr)\\right]_- } u^k\\;. \\label{nrrl}\\ ] ] we will refer to this method as _ regularised rl_.      up to scaling and shifting , the asymmetric penaliser function @xmath80 equals the logarithmic density of a gamma distribution .",
    "minimisation of the integral thus corresponds to a bayesian estimation of the sharp image assuming a poisson distribution for the intensities , with the gamma distribution as conjugate prior .    in variational deconvolution , it has turned out useful to replace quadratic data terms that mirror a gaussian noise model by robust data terms associated with `` heavy - tailed '' noise distributions . not only can the resulting model handle extreme noise but it can also cope with imprecisions in the blur model .",
    "following this idea , we replace the data term of by one that is adapted to a broader distribution on @xmath81 .",
    "to retain the structure of the fixed point iterations and , we keep @xmath82 in the data term , but apply a penaliser function @xmath29 that grows less than linear .",
    "our modified functional therefore reads @xmath83 = \\int\\limits_\\omega \\left ( \\varphi\\bigl(r_f(h\\circledast u)\\bigr ) + \\alpha\\ , \\varpsi(\\lvert\\nabla u\\rvert^2 ) \\right ) { \\,\\mathrm{d}}{\\bm{x}}\\;.\\kern-.7em\\ ] ]    by an analogous derivation as before , one obtains for the minimality condition @xmath84 that leads to the new fixed point iteration @xmath85_+ } { h^*\\circledast\\varphi'(r_f(h\\circledast u ) )   -   \\alpha \\left[{\\operatorname{div}}\\bigl ( \\varpsi'(\\lvert\\nabla u^k\\rvert^2)\\,\\nabla u^k\\bigr)\\right]_- } \\,\\cdot\\ , u^k \\label{rrrl}\\ ] ] which we call _ robust and regularised rl deconvolution _ ( rrrl ) . comparing to",
    ", computational cost grows by one more convolution and the evaluation of @xmath86 .",
    "clearly , contains regularised rl as special case ( @xmath87 ) .",
    "similarly , @xmath88 yields a non - regularised method which we will call _ robust rl deconvolution_.      assume now that the blurred image is a multi - channel image @xmath89 with a channel index set @xmath90 , e.g.  an rgb colour image , whose channels are uniformly blurred , i.e.the psf @xmath13 is equal for all channels . replacing the expressions @xmath82 and @xmath91 in the arguments of @xmath29 and @xmath92 with their sums over image channels , @xmath93 and @xmath94 , we obtain as multi - channel analog of the functional @xmath95 = \\int\\limits_\\omega \\bigl ( \\varphi(r )   + \\alpha\\ , \\varpsi(g ) \\bigr ) { \\,\\mathrm{d}}{\\bm{x}}\\;.\\ ] ]    this yields as the iteration rule for multi - channel rrrl @xmath96_+ } { h^*\\circledast\\varphi'(r ) - \\alpha \\left[{\\operatorname{div}}\\left ( \\varpsi'(g)\\ , \\nabla u_j^k\\right)\\right]_- } \\,\\cdot\\ , u_j^k\\;. \\label{rrrlmc}\\ ] ] the same procedure works for the non - robust and/or non - regularised rl variants .",
    "note that in the case of standard rl this boils down to channel - wise application .      the regularised rl model by dey et al .",
    "@xcite places the regularisation only in the denominator of the fixed point iteration rule .",
    "this imposes a tight bound on @xmath27 : as soon as @xmath97 exceeds @xmath22 , positivity is violated , and the iteration becomes unstable , in our iteration rule , sign - dependent distribution of divergence expressions to the enumerator and denominator prevents positivity violations , thus enabling larger values of @xmath27 .",
    "nevertheless , for substantially larger values of @xmath27 instabilities are observed which can be attributed to amplifying perturbations of high spatial frequency in almost homogeneous image regions . in @xcite",
    "therefore a modification of the fixed point iteration to optimise has been proposed that guarantees stability for arbitrary @xmath27 .",
    "a detailed analysis of stability bounds on @xmath27 in the iteration will be given in a forthcoming publication .",
    "we turn now to evaluate the performance of our newly developped deconvolution methods , and comparing them to existing approaches .",
    "methods chosen for comparison include classical richardson - lucy deconvolution , variational gradient descent methods , and the methods from @xcite which are advocated for performant deblurring in several recent papers , see e.g.  @xcite .",
    "we start our tests on grey - value images that are synthetically blurred by convolution . since in this case the correct sharp image is known , we can rate restoration quality by the signal - to - noise ratio @xmath98 here , @xmath6 and @xmath16 are the original sharp image and restored image , respectively . by @xmath99",
    "we denote the variance of the image @xmath39 .",
    "one should be aware that snr measurements do often not capture visual quality of deblurred images very well .",
    "the parameters in our experiments are optimised primarily for visual quality , not for snr .",
    "we remark also that in synthetically blurring images , we use convolution via the fourier domain , which involves treating the image domain as periodic .",
    "in contrast , we use convolution in the spatial domain in the variational deconvolution procedures as well as in the richardson - lucy method and its modifications .",
    "this discrepancy in the convolution procedure and boundary treatment is by purpose : it helps to prevent `` inverse crimes '' @xcite that could unduly embellish results .",
    "moreover , our implementations can thereby easily be adapted to spatially variant blurs .",
    "the methods from @xcite require computations in the fourier transforms by design .    [ cols=\"^,^,^,^,^ \" , ]     in order to achieve its high restoration quality , rrrl required in both synthetic experiments significantly higher computational effort than standard rl . however , run times still remained by a factor @xmath100 below those for the robust variational model from literature .",
    "this is caused by the favourable structure of the minimality condition and the fixed point iteration obtained from it .",
    "in contrast , minimisation of the classical variational model becomes very slow when getting close to the optimum , thus requiring much more iterations .",
    "our last experiment ( figures [ f - rwc - sivp][f - rwc2 ] ) is based on real - world data . the colour photograph shown in figure  [ f - rwc - sivp](a )",
    "was blurred during acquisition with an unknown point - spread function that is inferred approximately from the shape of a point light source . for restoration",
    ", we use the multi - channel versions of our methods .",
    "restoration by standard rl achieves a decent acuity at moderate computational cost , see the detail view , figure  [ f - rwc2](a ) . increasing",
    "the number of iterations quickly leads to ringing artifacts that are visible as shadows in the vicinity of all high - contrast image structures , see figure  [ f - rwc2](b ) .",
    "variational deconvolution with a robust @xmath32 data term and perona - malik regulariser allows a visible improvement in acuity over rl deconvolution while reducing artifacts , see the detail view in figure  [ f - rwc2](c ) .",
    "using the positivity - constrained gradient descent brings about a further significant improvement , see figure [ f - rwc2](f ) . due to the better suppression of ringing artifacts",
    "the regularisation weight @xmath27 could be reduced by half here  in contrast , unconstrained variational deconvolution with the same reduced @xmath27 creates much stronger artifacts , see figure  [ f - rwc2](d ) . imposing the constraint but retaining the larger weight @xmath27 , see figure  [ f - rwc2](e ) ,",
    "already improves acuity but still smoothes out more fine details than in figure  [ f - rwc2](f ) .",
    "the excellent restoration quality of variational deconvolution , however , comes at the cost of significantly increased computation time needed in order to approximate the steady state .",
    "robust and regularised richardson - lucy deconvolution as shown in the last rows of figure  [ f - rwc2 ] provides an attractive compromise between standard rl and the variational gradient descent .",
    "figure  [ f - rwc2](g ) shows a rrrl result with tv regulariser which can be computed fairly fast . with the perona - malik regulariser instead ,",
    "see figures  [ f - rwc - sivp](b ) and [ f - rwc2](h ) , more iterations are required in order for the edge - enhancing properties of the regulariser to pay off , but still the computation time is lower than with the gradient descent algorithm , compare also table  [ t - rwc ] . in terms of restoration quality ,",
    "both rrrl results range between the variational deconvolution without and with constraints .",
    "we remark that the test image consisting of large dark regions with few highlights makes the positivity constraint particularly valuable .",
    "in this paper , we have investigated richardson - lucy deconvolution from the variational viewpoint . based on the observation",
    "@xcite that the rl method can be understood as a fixed point iteration associated to the minimisation of the information divergence @xcite , it is embedded into the framework of variational methods .",
    "this allows in turn to apply to it the modifications that have made variational deconvolution the flexible and high - quality deconvolution tool that it is .",
    "besides regularisation that has been proposed before in @xcite , we have introduced robust data terms into the model . as a result",
    ", we have obtained a novel robust and regularised richardson - lucy deconvolution method that competes in quality with state - of - the - art variational methods , while in terms of numerical efficiency it moves considerably closer to richardson - lucy deconvolution .",
    "m.  backes , t.  chen , m.  drmuth , h.  lensch , and m.  welk .",
    "tempest in a teapot : compromising reflections revisited . in _ proc .",
    "30th ieee symposium on security and privacy _ , pages 315327 , oakland , california , usa , 2009 .",
    "l.  bar , a.  brook , n.  sochen , and n.  kiryati .",
    "color image deblurring with impulsive noise . in n.",
    "paragios , o.  faugeras , t.  chan , and c.  schnrr , editors , _ variational and level set methods in computer vision _ , volume 3752 of _ lecture notes in computer science _ , pages 4960 .",
    "springer , berlin , 2005 .",
    "l.  bar , n.  sochen , and n.  kiryati .",
    "variational pairing of image segmentation and blind restoration . in t.",
    "pajdla and j.  matas , editors , _ computer vision ",
    "eccv 2004 , part ii _ ,",
    "volume 3022 of _ lecture notes in computer science _ , pages 166177 .",
    "springer , berlin , 2004 .",
    "l.  bar , n.  sochen , and n.  kiryati .",
    "image deblurring in the presence of salt - and - pepper noise . in r.",
    "kimmel , n.  sochen , and j.  weickert , editors , _ scale space and pde methods in computer vision _",
    ", volume 3459 of _ lecture notes in computer science _ , pages 107118 .",
    "springer , berlin , 2005 .",
    "l.  bar , n.  sochen , and n.  kiryati .",
    "restoration of images with piecewise space - variant blur . in f.",
    "sgallari , f.  murli , and n.  paragios , editors , _ scale space and variational methods in computer vision _ ,",
    "volume 4485 of _ lecture notes in computer science _ , pages 533544 .",
    "springer , berlin , 2007 .",
    "n.  dey , l.  blanc - fraud , c.  zimmer , z.  kam , j .- c .",
    "olivo - marin , and j.  zerubia .",
    "a deconvolution method for confocal microscopy with total variation regularization . in _ proc .",
    "ieee international symposium on biomedical imaging ( isbi ) _ , april 2004 .",
    "n.  dey , l.  blanc - feraud , c.  zimmer , p.  roux , z.  kam , j .- c .",
    "olivo - marin , and j.  zerubia .",
    "ichardson - lucy algorithm with total variation regularization for 3d confocal microscope deconvolution .",
    ", 69:260266 , 2006 .",
    "a.  elhayek , m.  welk , and j.  weickert . simultaneous interpolation and deconvolution model for the 3-d reconstruction of cell images . in r.",
    "mester and m.  felsberg , editors , _ pattern recognition _ , volume 6835 of _ lecture notes in computer science _ , pages 316325 .",
    "springer , berlin , 2011 .",
    "m.  jung and l.  a. vese .",
    "nonlocal variational image deblurring models in the presence of gaussian or impulse noise . in x .-",
    "tai , k.  mrken , m.  lysaker , and k .- a .",
    "lie , editors , _ scale - space and variational methods in computer vision _ , volume 5567 of _ lecture notes in computer science _ ,",
    "pages 402413 .",
    "springer , berlin , 2009 .",
    "j.  g. nagy and z.  strako . enforcing nonnegativity in image reconstruction algorithms . in d.  c. wilson , h.  d. tagare , f.  l. bookstein , f.  j. preteux , and e.  r. dougherty , editors , _ advanced signal processing algorithms , architectures , and implementations _ ,",
    "volume 4121 of _ proceedings of spie _ , pages 182190 .",
    "spie press , bellingham , 2000 .",
    "n.  persch , a.  elhayek , m.  welk , a.  bruhn , s.  grewenig , k.  bse , a.  kraegeloh , and j.  weickert .",
    "enhancing 3-d cell structures in confocal and sted microscopy : a joint model for interpolation , deblurring and anisotropic smoothing .",
    ", in press , 2013 .",
    "a.  sawatzky and m.  burger .",
    "edge - preserving regularization for the deconvolution of biological images in nanoscopy . in g.",
    "psihoyios , t.  simos , and c.  tsitouras , editors , _ proc .",
    "8th international conference of numerical analysis and applied mathematics _ , volume 1281 of _ conference proceedings _ , pages 19831986 .",
    "aip , september 2010 .                m.  welk and m.  erler .",
    "algorithmic optimisations for iterative deconvolution methods . in j.",
    "piater and a.  rodrguez - snchez , editors , _ proceedings of the 37th annual workshop of the austrian association for pattern recognition ( agm / aapr ) , 2013_. arxiv:1304.7211 [ cs.cv ] , 2013 .",
    "m.  welk and j.  g. nagy .",
    "variational deconvolution of multi - channel images with inequality constraints . in j.",
    "mart , j.  m. bened , a.  m. mendona , and j.  serrat , editors , _ pattern recognition and image analysis _ ,",
    "volume 4477 of _ lecture notes in computer science _ , pages 386393 .",
    "springer , berlin , 2007 .",
    "m.  welk , d.  theis , t.  brox , and j.  weickert . -based deconvolution with forward - backward diffusivities and diffusion tensors . in r.",
    "kimmel , n.  sochen , and j.  weickert , editors , _ scale space and pde methods in computer vision _ , volume 3459 of _ lecture notes in computer science _",
    ", pages 585597 .",
    "springer , berlin , 2005 .",
    "m.  welk , d.  theis , and j.  weickert .",
    "variational deblurring of images with uncertain and spatially variant blurs . in w.",
    "kropatsch , r.  sablatnig , and a.  hanbury , editors , _ pattern recognition _",
    ", volume 3663 of _ lecture notes in computer science _ , pages 485492 .",
    "springer , berlin , 2005 ."
  ],
  "abstract_text": [
    "<S> in this paper , an iterative method for robust deconvolution with positivity constraints is discussed . </S>",
    "<S> it is based on the known variational interpretation of the richardson - lucy iterative deconvolution as fixed - point iteration for the minimisation of an information divergence functional under a multiplicative perturbation model . the asymmetric penaliser function involved in this functional </S>",
    "<S> is then modified into a robust penaliser , and complemented with a regulariser . </S>",
    "<S> the resulting functional gives rise to a fixed point iteration that we call robust and regularised richardson - lucy deconvolution . </S>",
    "<S> it achieves an image restoration quality comparable to state - of - the - art robust variational deconvolution with a computational efficiency similar to that of the original richardson - lucy method . </S>",
    "<S> experiments on synthetic and real - world image data demonstrate the performance of the proposed method .    </S>",
    "<S> * keywords : * non - blind deblurring @xmath0 richardson - lucy deconvolution @xmath0 regularization @xmath0 robust data term </S>"
  ]
}