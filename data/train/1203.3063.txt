{
  "article_text": [
    "one of the most challenging aspects of multiple testing problems in spatial and temporal domains is how to account for the spatial or temporal structure in the underlying signal .",
    "the usual paradigm considers a separate test at each observed location .",
    "however , the interest is usually in detecting signal regions that span several neighboring locations .",
    "this paper considers a new multiple testing paradigm for spatial and temporal domains where tests are not performed at every observed location , but only at the local maxima of the observed data , seen as representatives of underlying signal peak regions .",
    "the proposed inference is not pointwise but topological , based on the observed local maxima as topological features .    in pointwise testing , the control of family - wise error rate ( fwer ) , now common in neuroimaging , was established by keith worsley [ @xcite , worsley et  al .",
    "( @xcite ) ] , who exploited the euler characteristic heuristic for approximating the distribution of the maximum of a random field [ @xcite , @xcite ] .",
    "methods for controlling the false discovery rate ( fdr ) [ @xcite ] are also applied routinely in this setting , but the spatial structure is difficult to incorporate and often ignored [ @xcite , @xcite , @xcite ] .    despite pointwise testing being",
    "so common , the real interest is usually not in detecting individual locations , but connected regions or clusters .",
    "this has prompted the adaptation of discrete fdr methods to pre - defined clusters [ @xcite , @xcite ] , and the use of gaussian random field theory for computing @xmath0-values corresponding to the height , extent and mass of clusters obtained by pre - thresholding the observed random field [ @xcite , @xcite ] .",
    "perone  pacifico et  al .",
    "( @xcite ) proposed data - dependent thresholds so that fdr is controlled at the cluster level , using gaussian random field theory to approximate the null distribution .",
    "however , the definition of type i error for clusters requires a tolerance parameter for the overlap between a discovered cluster and the null region [ @xcite ] , while spatial smoothing , which is often applied for improving signal - to - noise ratio ( snr ) , creates the need to remove the spread of the signal over the null region to avoid error inflation [ @xcite ] . @xcite",
    "have argued that current cluster methods are unsatisfactory because , just like marginal fdr procedures , they rely on the basic premise of having a test at each spatial location ; instead , inference should be topological .",
    "this article proposes a different multiple testing paradigm where tests are performed , not at each spatial or temporal location , but only at the local maxima of the smoothed data , seen as topological representatives of their neighborhood region or cluster .",
    "a similar idea was recently proposed independently by @xcite , but they did not consider whether type i error could be controlled . here",
    "we extend the classical control of fwer via the global maximum to control of both fwer and fdr via local maxima . because the distributional theory for local maxima of random fields is more difficult than that for global maxima",
    ", this paper only considers one - dimensional domains ( spatial or temporal ) , where closed - form solutions exist , leaving the two- and three - dimensional cases for future work .",
    "our general proposed algorithm consists of the following steps :    _ kernel smoothing _ : to increase snr [ @xcite , @xcite ] .    _ candidate peaks _ : find local maxima of the smoothed sequence .    _",
    "@xmath0-values _ : computed at each local maximum under the complete null hypothesis of no signal anywhere .",
    "_ multiple testing _ : apply a multiple testing procedure and declare as detected peaks those local maxima whose @xmath0-values are significant .    in this paper , the @xmath0-values in step ( 3 )",
    "are computed using theory of gaussian processes .",
    "for step ( 4 ) , we consider two standard multiple testing procedures : bonferroni to control fwer and benjamini  hochberg ( bh ) [ @xcite ] to control fdr .",
    "the algorithm is illustrated by a simulated example in figure [ figsimulexample ] .",
    "( green ) and smoothed sequence @xmath1 ( blue ) over five underlying true peaks of different shapes comprising @xmath2 ( red ) . out of 33 local maxima of @xmath1 ( yellow ) ,",
    "the bh detection threshold at fdr level 0.2 ( dashed magenta ) selects five , one of which is a false positive . at this noise level , four out of five true peaks are detected .",
    "note that this bandwidth is able to distinguish the overlapping peaks . ]",
    "we study the theoretical properties of the above algorithm under a specific signal - plus - noise model and then relax these assumptions in the simulations .",
    "for type i errors to be well defined , the signal is modeled as if composed of unimodal peak regions , each considered detected if a significant local maximum occurs inside its finite support . for simplicity ,",
    "we concentrate on positive signals and one - sided tests , but this is not crucial . for tractability ,",
    "the theory assumes that the observation noise follows a smooth stationary ergodic gaussian process .",
    "this assumption permits an explicit formula for computing the @xmath0-values corresponding to local maxima of the observed process .",
    "the distribution of the height of a local maximum of a gaussian process is not gaussian but has a heavier tail , and its computation requires careful conditioning based on the calculus of palm probabilities [ @xcite , @xcite ] .",
    "an interesting and challenging aspect of inference for local maxima is the fact that the number of tests , equal to the number of observed local maxima , is random .",
    "the multiple testing literature usually assumes the number of tests to be fixed .",
    "we overcome this difficulty with an asymptotic argument for large search space , so that by ergodicity , the error behaves approximately as it would if the number of tests were equal to its expected value .    in order to achieve strong control of fwer and fdr ,",
    "the asymptotics for large search space are combined with asymptotics for strong signal .",
    "the strong signal assumption asymptotically eliminates the false positives caused by the smoothed signal spreading into the null regions , by assuring that each signal peak region is represented by only one observed local maximum within the true domain with probability tending to one .",
    "the strong signal assumption is not restrictive in the sense that the search space may grow exponentially faster .",
    "simulations show that error levels are maintained at finite search spaces and moderate signal strength .    defining detection power as the expected fraction of true peaks detected , we prove that the algorithm is consistent in the sense that its power tends to one under the above asymptotic conditions .",
    "we find that the optimal smoothing kernel is approximately that which is closest in shape and bandwidth to the signal peaks to be detected , akin to the so - called matched filter theorem in signal processing [ @xcite , @xcite ] .",
    "this optimal bandwidth is much larger than the usual optimal bandwidth for nonparametric regression .    in one dimension , the problem of identifying significant local maxima is similar to that of peak detection in signal processing [ e.g. , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ] . in this literature ,",
    "though large , the detection threshold is predominantly chosen heuristically and conservatively .",
    "our multiple testing viewpoint provides a formal mechanism for choosing the detection threshold , allowing detection under higher noise conditions .",
    "this view also eliminates the need to estimate an unknown number of peak location parameters , encountered in the signal estimation approach [ li and speed ( @xcite ) , @xcite , @xcite ] .",
    "we illustrate our procedure with a data set of neural electrical recordings , where the objective is to detect action potentials representing cell activity [ @xcite , segev et al .",
    "( @xcite ) ] .",
    "the noise parameters and signal peak shape are estimated from a training set and then applied to a  test set for peak detection .",
    "the data analysis and all simulations were implemented in ` matlab ` .",
    "consider the signal - plus - noise model @xmath3 where the signal @xmath2 is a train of unimodal positive peaks of the form @xmath4 and the peak shape @xmath5 has compact connected support @xmath6 and unit action @xmath7 for each @xmath8 .",
    "let @xmath9 with bandwidth parameter @xmath10 be a unimodal kernel with compact connected support and unit action . convolving the process ( [ eqsignal+noise ] ) with the kernel @xmath11 results in the smoothed process @xmath12 where the smoothed signal and smoothed noise are defined as @xmath13    for each @xmath8 , the smoothed peak shape @xmath14 is unimodal and has compact connected support @xmath15 and unit action .",
    "for each @xmath8 , we require that @xmath16 is twice differentiable in the interior of @xmath15 and has no other critical points within its support .",
    "for simplicity , the theory requires that the supports @xmath15 do not overlap ( but this is not required in practice , as shown via simulations in section [ secsimulations ] ) .",
    "the smoothed noise @xmath17 defined by ( [ eqconv ] ) and ( [ eqmu - gamma ] ) is assumed to be a zero - mean thrice differentiable stationary ergodic gaussian process .",
    "suppose we observe @xmath18 defined by ( [ eqsignal+noise ] ) in the segment @xmath19 $ ] , which contains @xmath20 peaks .",
    "we call the following procedure stem ( smoothing and testing of maxima ) .    [ algstem ]    \\(1 ) _ kernel smoothing _ : construct the process ( [ eqconv ] ) , ignoring the boundary effects at @xmath21 .",
    "_ candidate peaks _ : find the set of local maxima of @xmath1 in @xmath19 $ ] @xmath22\\dvtx \\dot{y}_{\\gamma}(t ) = \\frac{dy_{\\gamma}(t)}{dt } = 0 , \\ddot{y}_{\\gamma}(t ) = \\frac{d^2 y_{\\gamma}(t)}{dt^2 } < 0 \\biggr\\}.\\ ] ]    _ @xmath0-values _ : for each @xmath23 compute the @xmath0-value @xmath24 for testing the ( conditional ) hypothesis @xmath25    _ multiple testing _ : let @xmath26 be the number of tested hypotheses , equal to the number of local maxima in @xmath27 . apply a multiple testing procedure on the set of @xmath26 @xmath0-values @xmath28 , and declare significant all peaks whose @xmath0-values are smaller than the significance threshold .",
    "steps ( 1 ) and ( 2 ) above are well defined under the model assumptions ( for data on a grid , local maxima are defined as points higher than their neighbors ) .",
    "step ( 3 ) is detailed in section [ secpvalue ] below . for step ( 4 )",
    ", we use the bonferroni procedure to control fwer and the bh procedure to control fdr . to apply bonferroni at level  @xmath29 ,",
    "declare significant all peaks whose @xmath0-values are smaller than @xmath30 . to apply bh at level @xmath29 ,",
    "find the largest index  @xmath31 for which the @xmath32th smallest @xmath0-value is smaller than @xmath33 , and declare as significant the @xmath31 peaks with smallest @xmath0-values .",
    "notice that , in contrast to the usual application of the bonferroni and bh procedures , the number of tests @xmath26 is random .      given",
    "the observed heights @xmath1 at the local maxima , the @xmath0-values in step ( 3 ) of algorithm [ algstem ] are computed as @xmath34,\\qquad t\\in\\tilde{t},\\ ] ] where @xmath35 denotes the _ right _ cumulative distribution function ( cdf ) of @xmath17 at the local maxima @xmath23 , evaluated under the complete null hypothesis @xmath36 .    the conditional distribution ( [ eqpalm ] )",
    "is called a palm distribution [ @xcite , chapter 6 ] . unlike the marginal distribution of @xmath17 , it is not gaussian but stochastically greater .",
    "this is because the point of evaluation @xmath37 is not a fixed point @xmath38 , but the random location of a local maximum of @xmath17 .",
    "moreover , the conditioning event has probability zero .",
    "the palm distribution ( [ eqpalm ] ) has a closed - form expression , originally obtained by cramr and leadbetter [ ( @xcite ) , chapter 11 ] ( equation 11.6.14 ) , using the well - known kac ",
    "rice formula [ @xcite , @xcite , chapter 11 ] . a direct application , borrowing notation from those sources , gives the following .",
    "[ proppalm ] suppose the assumptions of section [ secmodel ] hold and that @xmath39 .",
    "define the moments @xmath40,\\qquad \\lambda_{2,\\gamma } = { \\operatorname{var}}[\\dot{z}_\\gamma(t)],\\qquad \\lambda_{4,\\gamma } = { \\operatorname{var}}[\\ddot{z}_\\gamma(t)].\\ ] ] then the distribution ( [ eqpalm ] ) is given by @xmath41 where @xmath42 , and @xmath43 , @xmath44 are the standard normal density and cdf , respectively .",
    "the quantities @xmath45 , @xmath46 and @xmath47 in proposition [ proppalm ] depend on the kernel  @xmath11 and the autocorrelation function of the original noise process @xmath48 .",
    "explicit expressions may be obtained , for instance , for the following gaussian autocorrelation model , which we use later in the simulations .",
    "[ exgaussian - acvf ] let the noise @xmath48 in ( [ eqsignal+noise ] ) be constructed as @xmath49 where @xmath50 is standard brownian motion and @xmath51 .",
    "convolving with a  gaussian kernel @xmath52 with @xmath53 as in ( [ eqmu - gamma ] ) produces a zero - mean infinitely differentiable stationary ergodic gaussian process @xmath54 with moments ( [ eqmoments ] ) given by @xmath55 , @xmath56 , @xmath57 .",
    "the above expressions may be used as approximations if the kernel , required to have finite support , is truncated at @xmath58 for moderately large  @xmath59 , say @xmath60 .      because truly detected peaks may be shifted with respect to the true peaks as a result of noise",
    ", we define a significant local maximum to be a true positive if it falls anywhere inside the support of a  true peak .",
    "conversely , we define it to be a false positive if it falls outside the support of any true peak . assuming the model of section [ secmodel ] ,",
    "define the signal region @xmath61 and null region @xmath62 , respectively , by @xmath63 \\bigm\\backslash \\biggl ( \\bigcup_{j=1}^j s_j \\biggr).\\ ] ] for a significance threshold @xmath64 , the total number of detected peaks and the number of falsely detected peaks are @xmath65 respectively .",
    "both are defined as zero if @xmath27 is empty .",
    "the fwer is defined as the probability of obtaining at least one falsely detected peak @xmath66 the fdr is defined as the expected proportion of falsely detected peaks @xmath67        note that the above definitions are with respect to the original signal support @xmath61 , while the inference is carried out using the smoothed observed process @xmath1 .",
    "kernel smoothing enlarges the signal support and increases the probability of obtaining false positives in the null regions neighboring the signal [ @xcite ] .",
    "in contrast to ( [ eqnull - region ] ) , the smoothed signal region @xmath68 and smoothed null region @xmath69 are @xmath70 \\bigm\\backslash\\biggl ( \\bigcup_{j=1}^j s_{j , \\gamma}\\biggr),\\ ] ] respectively ( figure [ figs0 ] ) .",
    "we call the difference between the expanded signal support and the true signal support the transition region @xmath71 where @xmath72 is the transition region corresponding to each peak @xmath8",
    ".    in general , a true peak may produce more than one significant local maximum , affecting the interpretation of definition ( [ eqfdr ] ) and the nonasymptotic validity of the fdr controlling procedure .",
    "however , as explained below , this multiplicity is unlikely to occur for strong signals , assuring validity at least asymptotically under that regime .",
    "the simulations of section [ secsim1 ] show it not to be problematic in nonasymptotic situations for moderate signals and appropriate smoothing .      in algorithm [ algstem ] ,",
    "step ( 3 ) produces a list of @xmath26 @xmath0-values .",
    "if the bonferroni correction is applied in step ( 4 ) with level@xmath73 , then the null hypothesis @xmath74 at @xmath75 is rejected if @xmath76 where @xmath77 is defined as 1 if @xmath78 .",
    "recall that , in contrast to the usual bonferroni algorithm , the number of @xmath0-values @xmath26 is random .",
    "define the conditions :    the assumptions of section [ secmodel ] hold .",
    "@xmath79 and @xmath80 , such that @xmath81 and with @xmath82 .",
    "[ thmfwer ] suppose that algorithm [ algstem ] is applied with the bonferroni threshold @xmath83 ( [ eqthresh - bon - random ] ) .",
    "then , under conditions and , @xmath84    the proof of theorem [ thmfwer ] is given in section [ appfwer ] .",
    "the large search space assumption in ( c2 ) solves the problem of @xmath85 being random , implying that by the weak law of large numbers , the ratio @xmath86 is close to its expectation @xmath87 $ ] for large @xmath88 .",
    "thus the bonferroni procedure with random threshold  ( [ eqthresh - bon - random ] ) has asymptotically the same error control properties as if the threshold were deterministic and equal to @xmath89}\\biggr ) \\approx f_\\gamma^{-1}\\biggl(\\frac{\\alpha / l}{a_1 + { \\mathrm{e}}[\\tilde{m}_{0,\\gamma}(0,1)]}\\biggr),\\ ] ] where @xmath90 = \\frac{1}{2\\pi}\\sqrt{\\frac { \\lambda_{4,\\gamma}}{\\lambda_{2,\\gamma}}}\\ ] ] is the expected number of local maxima of @xmath17 in the unit interval @xmath91 [ @xcite , chapter 10 ] .",
    "the strong signal assumption in ( c2 ) implies ( lemma [ lemmaunique - max ] in section [ applemmas ] ) that , with probability tending to 1 , no local maxima are obtained in the transition region @xmath92 ( [ eqtransition - region ] ) , and exactly one local maxima is obtained for each signal peak in @xmath61 .",
    "this avoids the error inflation due to smoothing and provides the approximation in  ( [ eqthresh - bon - fixed ] ) .",
    "the proof of lemma [ lemmaunique - max ] shows that the asymptotic rates are exponential and controlled partially by the smallest absolute derivative of the smoothed peak shape in the transition region and the curvature of the smoothed peak shape at the mode .",
    "suppose the bh procedure is applied in step ( 4 ) of algorithm [ algstem ] .",
    "for a fixed @xmath73 , let @xmath31 be the largest index for which the @xmath32th smallest @xmath0-value is less than @xmath93 .",
    "then the null hypothesis @xmath74 at @xmath23 is rejected if @xmath94 where @xmath95 is defined as 1 if @xmath78 .",
    "[ thmfdr ] suppose that algorithm [ algstem ] is applied with the bh threshold  @xmath96  ( [ eqthresh - bh - random ] ) .",
    "then , under conditions and , @xmath97    the proof of theorem [ thmfdr ] is given in section [ appfdr ] .",
    "the asymptotic assumptions  ( c2 ) , imply that the bh procedure with random threshold ( [ eqthresh - bh - random ] ) has asymptotically the same error control properties as if the threshold were deterministic and equal to @xmath98(1-\\alpha)}\\biggr),\\ ] ] where @xmath99 $ ] is given by ( [ eqexpected - local - maxima ] ) .",
    "the threshold ( [ eqthresh - bh - random ] ) can be viewed as the largest solution of the equation @xmath100 , where @xmath101 is the empirical right cumulative distribution function of @xmath102 [ @xcite ] .",
    "taking the limit of that equation as @xmath88 gets large yields the solution ( [ eqthresh - bh - fixed ] ) .",
    "as before , the strong signal assumption in ( c2 ) implies that there exists exactly one significant local maximum at each true peak with probability tending to 1 ( lemma [ lemmaunique - max ] in section [ applemmas ] ) , avoiding error inflation in the transition region and justifying the interpretation of definition ( [ eqfdr ] ) as the expected proportion of falsely discovered peaks .",
    "again , the asymptotic rates are exponential and controlled partially by the smallest absolute derivative of the smoothed peak shape in the transition region and the curvature of the smoothed peak shape at the mode .",
    "notice that , in contrast to the asymptotic bonferroni threshold  @xmath103  ( [ eqthresh - bon - fixed ] ) which grows unbounded with increasing @xmath88 , the asymptotic bh thresh - old  @xmath104  ( [ eqthresh - bh - fixed ] ) is finite .",
    "recall from section [ secerrors ] that a significant local maximum is considered a true positive if it falls in the true signal region @xmath105 .",
    "we define the power of algorithm [ algstem ] as the expected fraction of true discovered peaks @xmath106\\nonumber\\\\[-8pt]\\\\[-8pt ] & = & \\frac{1}{j } \\sum_{j=1}^{j } { \\operatorname{power}}_j(u),\\nonumber\\end{aligned}\\ ] ] where @xmath107 is the probability of detecting peak @xmath8 @xmath108 the maximum operator above indicates that if more than one significant local maximum fall within the same peak support , only one is counted , so power is not inflated . however , this has no effect asymptotically because each true peak is represented by exactly one local maximum of the smoothed observed process with probability tending to 1 ( lemma [ lemmaunique - max ] in section [ applemmas ] ) .",
    "the next result indicates that both the bonferroni and bh procedures are asymptotically consistent .",
    "the proof is given in section [ apppower ] .",
    "[ thmpower ] let the power be defined by ( [ eqpower ] ) , and let @xmath83 and @xmath96 be the bonferroni and bh thresholds ( [ eqthresh - bon - random ] ) and ( [ eqthresh - bh - random ] ) , respectively . under conditions and , @xmath109    for pointwise tests ,",
    "if there exists a signal anywhere , the bh procedure is more powerful than the bonferroni procedure [ @xcite ] .",
    "this is also true in our case . comparing ( [ eqthresh - bon - fixed ] ) and ( [ eqthresh - bh - fixed ] ) , if @xmath110 , the threshold @xmath103 is higher than the threshold @xmath104 , promising a larger power for the bh procedure .",
    "the best smoothing kernel @xmath11 is that which maximizes the power ( [ eqpower ] ) under the true model .",
    "because this maximization is analytically difficult , we resort to a less formal argument here .",
    "lemma [ lemmaunique - max ] in section [ applemmas ] shows that , under conditions ( c1 ) and ( c2 ) , every true peak @xmath8 is represented by exactly one significant local maximum located in a small neighborhood containing the true peak mode @xmath111 with probability tending to 1 .",
    "thus the power for peak @xmath8 ( [ eqpower - j ] ) may be approximated as @xmath112,\\ ] ] because @xmath113 . by lemma [ lemmafwer - fdr - threshold ] in section [ apppower ] , the asymptotically equivalent thresholds ( [ eqthresh - bon - fixed ] ) and ( [ eqthresh - bh - fixed ] ) for the bonferroni and bh procedures satisfy @xmath114 and @xmath115 for any @xmath8 .",
    "thus , for large  @xmath116 , the power ( [ eqapprox - power ] ) is maximized approximately by maximizing the snr @xmath117 where @xmath118 is the standard deviation of the observed process @xmath18 .",
    "the optimal smoothing kernel @xmath11 is that which is closest to @xmath119 in an @xmath120 sense .",
    "this result is similar to the matched filter theorem for detecting a single signal peak of known shape at a fixed time location @xmath121 [ @xcite , @xcite ] .",
    "the result only holds approximately in our case because the peak locations are unknown .",
    "[ exgaussian - gamma - choice ] @xmath122suppose the signal peak  @xmath8 is a truncated gaussian density @xmath123\\mathbf{1}[-c_j , c_j]$ ] , @xmath124 , and let the noise be generated as in example [ exgaussian - acvf ] . ignoring the truncation , @xmath125 in ( [ eqsnr ] )",
    "is the convolution of two gaussian densities with variances @xmath126 and @xmath127 , which is another gaussian density with variance @xmath128 . using the moments from example [ exgaussian - acvf ]",
    ", we have that @xmath129^{1/4}.\\ ] ] as a function of @xmath130 , the snr is maximized at @xmath131 in particular , when @xmath132 , we have that the optimal bandwidth for peak @xmath8 is , the same as the signal bandwidth .",
    "we show in the simulations below that the optimal @xmath130 is indeed close to ( [ eqoptimal - gamma ] ) .",
    "simulations were used to evaluate the performance and limitations of the stem algorithm for finite range @xmath88 and moderate signal strength @xmath133 . in a segment of length @xmath134 , @xmath135 equal",
    "truncated gaussian peaks @xmath136 \\mathbf{1}[-cb , cb]$ ] , @xmath137 , as in example [ exgaussian - gamma - choice ] with @xmath138 , @xmath139 and varying @xmath133 , were placed at uniformly spaced locations @xmath140 , @xmath137 , and sampled at integer values of @xmath121 .",
    "the noise @xmath48 was constructed as in example [ exgaussian - acvf ] with @xmath141 and varying @xmath142 .",
    "algorithm [ algstem ] was carried out using as smoothing kernel a truncated gaussian density @xmath143 $ ] as in example [ exgaussian - acvf ] with @xmath139 and varying  @xmath130 .",
    "the noise parameters ( [ eqmoments ] ) were estimated independently as the empirical moments of smoothed sequences i.i.d .",
    "gaussian noise of length 1000 and their first and second - order differences , using the same smoothing kernel .",
    "the bonferroni and bh procedures were applied at level @xmath144 .",
    "( solid ) , @xmath145 ( dashed ) and @xmath146 ( dotted ) .",
    "nominal error level is 0.05 . ]",
    "figure [ figerror ] shows the realized fwer and fdr levels of the bonferroni and bh procedures , evaluated according to ( [ eqfwer ] ) and ( [ eqfdr ] ) with the expectations replaced by ensemble averages over 10,000 replications .",
    "error rates are maintained below the nominal level @xmath144 for all bandwidths and large enough signal strength @xmath133 .",
    "the convergence is slower , however , when the bandwidth  @xmath130 is much larger than the signal peak bandwidth @xmath138 .",
    "the increased error rates are the result of true peak maxima being shifted from the original signal region @xmath61 into the transition region  @xmath92 , where they are counted as false positives .",
    "this phenomenon disappears with increasing signal strength  @xmath133 because the probability of obtaining any local maxima in the transition region goes to zero asymptotically ( lemma [ lemmaunique - max ] in section  [ applemmas ] ) .",
    "( solid ) , @xmath145 ( dashed ) and @xmath146 ( dotted ) . ]    as noted in section [ secerrors ] , each true peak may contain more than one local maximum of the smoothed data @xmath1 .",
    "figure [ figlocmax ] shows that the expected number of local maxima per true peak decreases with increasing bandwidth , and is essentially equal to 1 for bandwidths equal to or greater than the optimal bandwidth .",
    "it also gets closer to 1 with increasing signal strength , consistent with the result of lemma [ lemmaunique - max ] .",
    "( solid ) , @xmath145 ( dashed ) and @xmath146 ( dotted ) .",
    "the maxima of the curves ( solid circles ) approach the asymptotic optimal bandwidth ( vertical dashed ) . ]",
    "figure [ figpower ] shows the realized power of the bonferroni and bh procedures , evaluated according to ( [ eqpower ] ) with the expectations replaced by ensemble averages over the same 10,000 replications . in all cases ,",
    "the power increases asymptotically to  1 with the signal strength for every fixed bandwidth , and is always larger for bh than it is for bonferroni .",
    "the convergence is slower , however , when the bandwidth @xmath130 is far from the optimal value . to understand the dependence on bandwidth , superimposed is the theoretical approximate power ( [ eqapprox - power ] ) evaluated at the asymptotic thresholds @xmath103 ( [ eqthresh - bon - fixed ] ) and @xmath104 ( [ eqthresh - bh - fixed ] ) and plugging in the snr ( [ eqsnr - gaussian ] ) .",
    "the `` theoretical '' power curves largely capture the shape of the realized ones , but are lower because the asymptotic thresholds are more conservative .",
    "the curve shape is mostly determined by the snr ( [ eqsnr - gaussian ] ) as a function of @xmath130 .",
    "the bandwidth @xmath130 producing the largest power is always larger than the theoretical optimal bandwidth ( [ eqoptimal - gamma ] ) , but it approaches it from the right as @xmath133 increases .     locations ( blue ) and supremum ( green ) .",
    "right panels : fdr and power of three fdr methods : stem with bh ( black ) , bh on all @xmath88 locations ( blue ) .",
    "results in all panels are for @xmath147 ( solid ) , @xmath145 ( dashed ) and @xmath146 ( dotted ) .",
    "nominal error level is 0.05 . ]      by assumption ( section [ secmodel ] ) , the signal peaks need not be equal . as in figure",
    "[ figsimulexample ] , @xmath148 unequal peaks ( epanechnikov , triangular and truncated gaussian , laplace and cauchy , with average half - support 24 ) were corrupted with white standard normal noise .",
    "algorithm [ algstem ] was applied using a quartic smoothing kernel @xmath149 ^ 2 \\mathbf { 1}[-\\gamma,\\gamma]$ ] with varying @xmath130 , the noise parameters estimated independently as in section [ secsim1 ] . for this configuration and 10,000 repetitions , the error was controlled below the nominal level 0.05 for values of @xmath130 up to 40 , obtaining a maximum power of 0.81 and 0.88 for the bonferroni and bh procedures at @xmath150 .",
    "the maximizing bandwidth represents the average best match between the quartic smoothing kernel and the peaks present in the data .",
    "the theory of section [ sectheory ] assumed that the signal peaks had nonoverlapping supports .",
    "simulations similar to those of section  [ secsim1 ] with @xmath135 partially overlapping peaks showed that the error rates were below the nominal level regardless of the amount of overlap between peaks .",
    "the detection power , however , deceptively increased with increasing overlap .",
    "this is because definition ( [ eqpower ] ) counts two overlapping peaks as detected even if only one significant local maximum is found in the overlapping region between them , as it belongs to both .",
    "definition ( [ eqpower ] ) does not measure the ability to distinguish between overlapping peaks .      to see the benefits of testing local maxima , figure [ figcompare - methods ]",
    "compares the performance of the stem algorithm ( with bonferroni and bh corrections ) to three other methods that test at every single location .",
    "simulated data sets as in section [ secsim1 ] with @xmath138 and @xmath151 were smoothed with varying @xmath130 . for the pointwise bonferroni and bh methods ,",
    "@xmath0-values for testing @xmath152 at each @xmath153 were computed as @xmath154 $ ] and then corrected using bonferroni and bh , respectively . the method `` supremum '' was adapted from @xcite as follows .",
    "the probability that the supremum of any differentiable random process @xmath155 in the interval @xmath156 $ ] exceeds @xmath64 is bounded by [ @xcite ] @xmath157}f(t ) \\ge u\\bigr ) \\le{\\mathrm{p}}[f(0 ) \\ge u ] + { \\mathrm{e}}[n_u],\\ ] ] where @xmath158 is the number of up - crossings by @xmath155 of the level @xmath64 in @xmath159 $ ] .",
    "for the stationary gaussian process",
    "@xmath17 , application of the kac  rice formula [ @xcite , page 194 ] gives that @xmath160 = l ( \\sqrt{\\lambda_{2 , \\gamma}}/\\allowbreak\\sigma_\\gamma ) \\phi(u/\\sigma_\\gamma)$ ] .",
    "the significance threshold is found as the largest @xmath64 such that @xmath161 } z_\\gamma(t ) \\ge u\\bigr ) \\le1 -\\phi\\biggl(\\frac{u}{\\sigma_\\gamma}\\biggr ) + l \\frac{\\sqrt{\\lambda_{2,\\gamma}}}{\\sigma_\\gamma } \\phi \\biggl(\\frac{u}{\\sigma_\\gamma}\\biggr ) \\le\\alpha.\\ ] ]    figure [ figcompare - methods ] indicates that the pointwise bonferroni correction is too conservative .",
    "the supremum method , despite accounting explicitly for the noise autocorrelation , performs only slightly better than pointwise bonferroni , and not as well as bonferroni performed on local maxima .",
    "the pointwise bh correction is designed to control fdr at the level of individual locations , and thus produces too many false positives when the fdr is measured in terms of detected peaks using ( [ eqfdr ] ) .",
    "further simulations with @xmath162 and @xmath163 yielded similar results ( not shown ) .      rather than using a fixed smoothing bandwidth @xmath130 , the bandwidth",
    "may be chosen automatically from the data as the one that yields the largest number of discoveries for a fixed error level .",
    "for simulated data sets as in section [ secsim1 ] with @xmath138 and @xmath151 , the stem algorithm was applied with @xmath130 ranging from @xmath164 to @xmath165 , and results were retained for the bandwidth @xmath166 that yielded the largest number of discoveries in each run .",
    "figure [ figgammaest](a ) shows that this automatic criterion biases the results toward more detected peaks and therefore results in higher    [ cols=\"^,^ \" , ]     algorithm [ algstem ] was applied to the test set ( figure [ figspike - data ] , top left ) by convolving it with the template of figure [ figtemplate - fp](a ) , producing the smoothed process in figure  [ figspike - data ] ( bottom left ) . in @xmath167 samples ,",
    "@xmath168 local maxima were found and their @xmath0-values were computed according to ( [ eqp - value ] ) and ( [ eqdistr ] ) , plugging in the estimates @xmath169 , @xmath170 and @xmath171 found above .",
    "the empirical cdf of the @xmath0-values [ figure [ figtemplate - fp](b ) ] shows a large fraction of nonnull @xmath0-values near 0 . for comparison , the same procedure of smoothing , finding local maxima and computing their @xmath0-values",
    "was applied to training set 2 .",
    "the empirical cdf of those @xmath0-values is virtually uniform , emphasizing that formula ( [ eqdistr ] ) for gaussian noise is appropriate .",
    "also in figure [ figtemplate - fp](b ) , the excess of large @xmath0-values from the test set is due to the negative portions of the smoothing function [ figure [ figtemplate - fp](a ) ] .",
    "these produce small negative anti - spikes whose @xmath0-values are large when tested for positiveness .",
    "applying the bh procedure to the @xmath172 @xmath0-values obtained from the test set at fdr level 0.01 resulted in a @xmath0-value threshold of @xmath173 and @xmath174 significant local maxima .",
    "these are indicated in figure [ figspike - data ] ( bottom left ) , showing three levels of spike strengths .",
    "figure [ figspike - data ] ( bottom right ) zooms in to show a few of the weaker spikes . applying the bonferroni procedure instead in algorithm [ algstem ] resulted in a @xmath0-value threshold of @xmath175 and only 411 detected spikes",
    ".    for comparison , figure [ figspike - data ] ( top right ) shows the same segment of the raw data and the spikes selected using one of the recommended methods in the neuroscience literature , which is to threshold at 4 standard deviations of the raw data [ segev et al .",
    "( @xcite ) ] .",
    "our method is able to identify more spikes at a low fdr level of 0.01 , but more importantly , it attaches to the findings a  significance level , expecting about 1% of the detected spikes to be false . the conventional method does not offer this useful statistical interpretation .    as in section [ seccompare - simul ] ,",
    "computing @xmath0-values at each location as @xmath176 , @xmath177 , and applying a global bonferroni at level 0.01 was more conservative , resulting in a height threshold of 1.235 ( comparable to figure  [ figspike - data ] bottom right ) and detecting only 393 spikes .",
    "similarly , the `` supremum '' method , applied by replacing @xmath178 and @xmath179 in ( [ eqsup - approx ] ) at level 0.01 , yielded a height threshold 1.229 and 394 detected spikes .",
    "finally , applying the global bh procedure at level 0.01 with @xmath88 @xmath0-values gave a height threshold of 0.780 detecting 1149 spikes , but as shown in section [ seccompare - simul ] , this result is too optimistic because the actual error rate for peaks is higher than 0.01 .",
    "for the theoretical results , the most critical assumptions were that the noise process is stationary ergodic gaussian and that the signal peaks are unimodal with compact support .",
    "the gaussianity assumption was chosen because it enabled a closed formula for computing the @xmath0-values associated with the heights of local maxima . for non - gaussian noise ,",
    "@xmath0-values could be computed via monte carlo simulation .",
    "the assumption of compact support for the signal peaks was necessary for true and false positives to be well defined .",
    "@xcite argued for testing local maxima when the signal spreads over the entire domain , but in that case every positive is a true positive , making the inference unclear . on the other hand , agreeing with @xcite , applying bh globally resulted in inflated error rates for peaks , while applying bonferroni or the supremum method globally was too conservative .",
    "the unimodality assumption made local maxima good representatives of true peaks , being unique for medium to large bandwidths and asymptotically for increasing signal strength .",
    "the strong signal assumption in condition ( c2 ) was introduced to remove the excess error produced by the smoothed signal spreading into the neighboring null regions , thereby enabling asymptotic error control .",
    "the assumption is not restrictive in the sense that the search space may grow exponentially faster .",
    "similar conditions are common for high - dimensional data .",
    "if the data are pointwise test statistics based on a sample of size @xmath180 , with snr increasing as @xmath181 , then the condition @xmath81 becomes @xmath182 .",
    "this is similar to the condition @xmath183 required for consistent model selection in high - dimensional regression under sparsity where @xmath0 is the number of features [ @xcite , @xcite ] .",
    "our results , however , do not require sparsity .",
    "condition ( c2 ) is easy to state but stronger than needed ; upon close inspection of the proof of lemma [ lemmaunique - max ] in section [ applemmas ] , the limit of @xmath184 need not be zero but need only be bounded by a constant that depends on the signal and noise first and second derivatives .",
    "while the theory was developed for continuous processes , in practice the observations are given in a discrete grid .",
    "in our simulations we found that the results were not reliable when the smoothing bandwidth was smaller than the grid spacing , as the theory for continuous random processes is no longer a good approximation in that case .",
    "the asymptotic error control and power consistency did not require the peaks to have the same shape or width .",
    "the asymptotic results were found to hold in practice for a wide range of bandwithds and strong enough signal . however , the convergence rate was slower for bandwidths less than half or more than double the optimal value .",
    "the matched filter principle suggests that the smoothing kernel should be chosen to be as close as possible in an @xmath185 sense to the peaks to be detected . in the neuronal data analyzed , the peak shape and width were estimated from the data , dictating the best smoothing kernel .",
    "if the peaks to be detected have different widths , then the bandwidth may be adapted to the width of each peak .",
    "we leave this possibility for future work , as well as the obliged extension of the proposed methods to two- and three - dimensional domains .",
    "[ lemmapalm - s0 ] let @xmath186 be be the number of local maxima of @xmath1 [ or @xmath17 ] in @xmath188 .",
    "let @xmath189 be the number of local maxima of @xmath1 [ or @xmath17 ] in @xmath188 whose heights are above the level @xmath64",
    ". then @xmath190}{{\\mathrm{e}}[\\tilde{m}_{0,\\gamma } ] } = f_\\gamma(u)\\ ] ] in probability as @xmath191 , where @xmath192 is the palm distribution ( [ eqpalm ] ) .",
    "notice that @xmath193 for all @xmath194 , so the process @xmath1 has the same properties as the stationary process @xmath17 on the set @xmath195 . by ergodicity ,",
    "the weak law of large numbers applied to the numerator and denominator gives that @xmath196 converges to [ @xcite ] @xmath197}{{\\mathrm{e}}[\\#\\ { t\\in\\tilde{t}\\cap\\mathbb{s}_{0,\\gamma}\\ } ] } = \\frac{{\\mathrm{e}}[v_\\gamma(u)]}{{\\mathrm{e}}[\\tilde{m}_{0,\\gamma}]}.\\ ] ] but also by ergodicity , ratio ( [ eqv - over - m ] ) converges to the conditional probability @xmath198 = f_\\gamma(u)$ ] by definition ( [ eqpalm ] ) .",
    "the two limits must be equal .",
    "[ lemmabounds ] assume the model of section [ secmodel ] .",
    "let @xmath199 be a partition , where @xmath200 \\subset s_j$ ] is a fixed interval containing the mode of @xmath201 in @xmath202 as an interior point , such that @xmath203 for @xmath204 , @xmath205 for @xmath206 and @xmath207 for @xmath208 .",
    "let :    * @xmath209 be the largest value of @xmath210 in @xmath15 ; * @xmath211 be the smallest value of @xmath212 in @xmath213 ; * @xmath214 be the smallest value of @xmath215 in @xmath216 .    for @xmath27 given by ( [ eqt ] ) and any threshold @xmath64 , @xmath217\\\\[-8pt ] & & \\qquad\\ge \\phi\\biggl(\\frac{a_j",
    "d_j}{\\sqrt{\\lambda_{4,\\gamma}}}\\biggr ) -    \\lambda_{4 , \\gamma } } } \\phi\\biggl(\\frac{a_j d_j}{\\sqrt{\\lambda_{4 , \\gamma}}}\\biggr ) - 2\\phi\\biggl(\\frac{-a_j c_j}{\\sqrt{\\lambda_{2,\\gamma}}}\\biggr ) , \\nonumber\\\\ & & { \\mathrm{p}}\\bigl(\\ # \\{t \\in\\tilde{t}\\cap i_j^{\\mathrm{mode}}\\dvtx y_\\gamma(t ) > u \\ } = 1\\bigr ) \\nonumber\\\\ & & \\qquad\\ge \\phi\\biggl(\\frac{a_j d_j}{\\sqrt{\\lambda_{4,\\gamma}}}\\biggr ) -    \\lambda_{4 , \\gamma } } } \\phi\\biggl(\\frac{a_j d_j}{\\sqrt{\\lambda_{4 , \\gamma}}}\\biggr ) - \\phi\\biggl(\\frac{u - a_j m_j}{\\sigma_\\gamma}\\biggr ) , \\nonumber\\end{aligned}\\ ] ] where @xmath218 , @xmath219 and @xmath220 are given by ( [ eqmoments ] ) and @xmath221 $ ] .",
    "\\(1 ) consider first the compact interval @xmath222 .",
    "the probability that there are no local maxima of @xmath1 in @xmath222 is greater than the probability that @xmath223 for all @xmath121 in the interval .",
    "this probability is equal to @xmath224\\\\[-8pt ] & = & 1 - { \\mathrm{p}}\\bigl(\\sup_{i_j^{\\mathrm{left } } } [ -\\dot{z}_\\gamma(t ) ] > a_j c_j^{\\mathrm{left } } \\bigr),\\nonumber\\end{aligned}\\ ] ] where @xmath225 is the smallest value of @xmath226 in @xmath222 .",
    "inequality ( [ eqsup ] ) applies above to the stationary gaussian process @xmath227 .",
    "the kac  rice formula [ @xcite , page 194 ] gives in this case that @xmath160 = |i_j^{\\mathrm{left}}| \\sqrt{\\lambda_{4 , \\gamma}}/\\sqrt{\\lambda_{2 , \\gamma } } \\phi(u/\\sqrt{\\lambda_{2 , \\gamma}})$ ] .",
    "thus ( [ eqi - left ] ) has the lower bound @xmath228 a similar calculation for @xmath229 gives a similar bound with the superscript `` left '' replaced by `` right '' and @xmath230 being the smallest value of @xmath212 in @xmath229 . putting the two together , the required probability @xmath231 that there are no local maxima in @xmath222 nor @xmath229 is bounded as in the first row of ( [ eqi - bound ] ) .",
    "\\(2 ) the probability that @xmath1 has no local maxima in @xmath216 is less than the probability that @xmath232 or @xmath233 , for a positive derivative at @xmath234 and a  negative one at @xmath235 would imply the existence of at least one local maximum in @xmath236 .",
    "thus , the probability of no local maxima in @xmath216 is bounded above  by @xmath237 + { \\mathrm{p}}[\\dot{y}_\\gamma(d_{j } ) \\ge0 ] \\nonumber\\\\ & = & \\phi\\biggl(\\frac{-a_j \\dot{h}_{j,\\gamma}(c_j)}{\\sqrt{\\lambda _ { 2,\\gamma}}}\\biggr ) + 1 - \\phi\\biggl(\\frac{-a_j \\dot{h}_{j,\\gamma}(d_j)}{\\sqrt{\\lambda _ { 2,\\gamma}}}\\biggr)\\\\ & \\le&2 - 2\\phi\\biggl(\\frac{a_j c_j}{\\sqrt{\\lambda_{2,\\gamma } } } \\biggr ) , \\nonumber\\end{aligned}\\ ] ] because @xmath238 and @xmath239 and @xmath240 .",
    "on the other hand , the probability that @xmath1 has more than one local maxima in @xmath216 is less than the probability that @xmath241 for some @xmath121 in  @xmath216 .",
    "this probability is @xmath242 where @xmath243 is the largest value of @xmath244 in @xmath216 . applying ( [ eqsup ] ) to the process @xmath245 gives the further upper bound @xmath246 putting ( [ eqi - mode - bound-0 ] ) and ( [ eqi - mode - bound-1 ] ) together gives the bound in the second row of ( [ eqi - bound ] ) .",
    "\\(3 ) the probability that no local maxima of @xmath1 in @xmath216 exceed the threshold @xmath64 is less than the probability that @xmath1 is below @xmath64 anywhere in  @xmath216 , so it is bounded above by @xmath247 $ ] . on the other hand , the probability that",
    "more than one local maxima of @xmath1 in @xmath216 exceed @xmath64 is less than the probability that there exist more than one local maximum , which is bounded above by ( [ eqi - mode - bound-1 ] ) .",
    "putting the two together gives the bound in the third row of ( [ eqi - bound ] ) .",
    "[ lemmaunique - max ] assume the model of section [ secmodel ] .",
    "for @xmath27 given by ( [ eqt ] ) , let @xmath248 be the number of local maxima in the set @xmath249 , and recall that @xmath250 is the number of local maxima in  @xmath249 above threshold  @xmath64 . under conditions and",
    ":    the probability that @xmath1 has any local maxima in the transition region @xmath251 tends to 0 .",
    "@xmath252    the probability to get exactly @xmath20 local maxima in the set @xmath249 , @xmath253    the probability to get exactly @xmath20 local maxima in the set @xmath249 that exceed any fixed threshold @xmath64 , @xmath254 = { \\mathrm{p}}[\\ # \\{t\\in\\tilde { t}\\cap\\mathbb{s}_{1 , \\gamma}\\dvtx y_\\gamma(t ) > u \\}=j ] \\to1.\\ ] ]    @xmath255 in probability .",
    "@xmath256 in probability .",
    "\\(1 ) write @xmath257 , where @xmath258 is the transition region for peak @xmath8 ( figure [ figs0 ] ) . under the assumptions of lemma [ lemmabounds ]",
    ", @xmath259 is a  subset of @xmath260 because @xmath222 or @xmath229 may include points inside @xmath202 . using  ( [ eqi - bound ] )",
    ", the required probability @xmath261 that @xmath262 has any local maxima in the transition region @xmath263 is bounded above by @xmath264 \\\\ & & \\qquad\\le2 \\frac{j}{l } l \\biggl[1 - \\phi\\biggl(\\frac{a c}{\\sqrt{\\lambda _ { 2,\\gamma}}}\\biggr ) \\biggr ] + l \\sqrt{\\frac{\\lambda_{4 , \\gamma } } { \\lambda_{2 , \\gamma } } } \\phi \\biggl(\\frac{a c}{\\sqrt{\\lambda_{2 , \\gamma}}}\\biggr),\\end{aligned}\\ ] ] where @xmath265 is the infimum of the @xmath116 s and @xmath266 is the infimum of the  @xmath211 s , that is , the infimum of @xmath212 for @xmath267 [ recall that every peak  @xmath16 has no critical points in the transition region for any @xmath8 ] .",
    "but the expression above goes to zero under condition ( c2 ) because , for any @xmath269 , @xmath270 \\to0\\ ] ] and @xmath271 \\le l\\phi(ka)/(ka ) \\to0 $ ] .",
    "\\(2 ) the required probability to obtain exactly @xmath20 local maxima in the set @xmath272 is greater than the probability of obtaining exactly one local maximum in each interval @xmath273 and none in @xmath260 for any @xmath8 .",
    "thus , using  ( [ eqi - bound ] ) , the required probability is bounded below by @xmath274 \\\\ & & \\qquad\\ge1- \\sum_{j=1}^{j } [ 1 - { \\mathrm{p}}(\\#\\{t \\in\\tilde{t}\\cap i_j^{\\mathrm{mode } } \\ } = 1 \\cap\\#\\{t \\in\\tilde{t}\\cap i_j^{\\mathrm{side } } \\ } = 0 ) ] \\\\ & & \\qquad\\ge1- \\sum_{j=1}^{j } \\biggl [ 5 - 4\\phi\\biggl(\\frac{a_j c_j}{\\sqrt{\\lambda_{2,\\gamma}}}\\biggr ) - \\phi\\biggl(\\frac{a_j d_j}{\\sqrt{\\lambda_{4,\\gamma}}}\\biggr)\\\\ & & \\qquad\\quad\\hspace*{38pt } { } +    \\lambda_{2 , \\gamma } } } \\phi\\biggl(\\frac{a_j c_j}{\\sqrt{\\lambda_{4 , \\gamma}}}\\biggr ) +    \\lambda_{4 , \\gamma } } } \\phi\\biggl(\\frac{a_j d_j}{\\sqrt{\\lambda_{4 , \\gamma}}}\\biggr ) \\biggr ] \\\\ & & \\qquad\\ge 1 - \\frac{j}{l } l \\biggl [ 5 - 4\\phi\\biggl(\\frac{a c}{\\sqrt{\\lambda_{2,\\gamma}}}\\biggr ) - \\phi\\biggl(\\frac{a d}{\\sqrt{\\lambda_{4,\\gamma}}}\\biggr)\\biggr]\\\\ & & \\qquad\\quad{}- l \\sqrt{\\frac{\\lambda_{4 , \\gamma } } { \\lambda_{2 , \\gamma } } } \\phi \\biggl(\\frac{a c}{\\sqrt{\\lambda_{4 , \\gamma}}}\\biggr ) - l \\sqrt{\\frac{\\lambda_{6 , \\gamma } } { \\lambda_{4 , \\gamma } } } \\phi \\biggl(\\frac{a d}{\\sqrt{\\lambda_{4 , \\gamma}}}\\biggr).\\end{aligned}\\ ] ] but this bound goes to 1 under condition ( c2 ) as in part ( 1 ) .",
    "\\(3 ) the required probability to obtain exactly @xmath20 local maxima in the set @xmath272 that exceed @xmath64 is greater than the probability that exactly one local maximum exceeds @xmath64 in each interval @xmath216 .",
    "this probability is bounded below by @xmath275,\\ ] ] but this goes to 1 by a similar argument as the one in part ( 2 ) of this lemma .",
    "\\(4 ) since @xmath276 , with @xmath277 , we need to show that @xmath278 in probability . for any fixed @xmath279 , @xmath280 since @xmath281 and @xmath20 are integers .",
    "but the probability to get exactly @xmath20 local maxima goes to 1 by part ( 2 ) of this lemma .",
    "\\(5 ) by part ( 2 ) of this lemma , @xmath282\\to1 $ ] in probability ; therefore , using the same arguments as in part ( 4 ) of this lemma , we get @xmath283 .",
    "now , @xmath284 but @xmath285 by part ( 3 ) of this lemma .",
    "[ lemmathreshold ] let @xmath286 be the number of local maxima in @xmath287 as in lemma  [ lemmapalm - s0 ] .",
    "define the thresholds @xmath288 , random , and @xmath289)$ ] , deterministic .",
    "then @xmath290 in probability as @xmath291 .    by ergodicity",
    ", the weak law of large numbers gives that @xmath292\\biggr| \\to0\\vadjust{\\goodbreak}\\ ] ] in probability as @xmath79 , where @xmath99 = { \\mathrm{e}}[\\tilde{m}_{0,\\gamma}]/l$ ] , given by ( [ eqexpected - local - maxima ] ) , does not depend on @xmath88 [ @xcite ] .",
    "since @xmath293 is continuous , the continuous mapping theorem gives that @xmath294}{l } \\biggr| = \\biggl|\\log\\frac{\\tilde{m}_0}{\\alpha } - \\log\\frac{{\\mathrm{e}}[\\tilde { m}_{0,\\gamma}]}{\\alpha } \\biggr| \\to0,\\ ] ] where we have used the additive property of the logarithm .",
    "define now the monotone increasing function @xmath295 .",
    "the function @xmath296 is lipschitz continuous for all @xmath297 because its derivative @xmath298 $ ] is bounded for all @xmath299 .",
    "hence , as @xmath79 , @xmath300}{\\alpha } \\biggr ) \\biggr| = |\\tilde{v}_{{\\operatorname{bon } } } - v^*_{{\\operatorname{bon}}}| \\to0.\\ ] ]    proof of theorem [ thmfwer ] let @xmath301 be the number of local maxima in the set @xmath302 as in lemma [ lemmathreshold ] , and let @xmath303 . then @xmath304 .",
    "further , the bound @xmath305 is the probability of obtaining at least one local maximum greater than @xmath306 in @xmath307 , which is less than the probability of obtaining at least one local maximum greater than @xmath306 in @xmath188 or at least one local maximum in  @xmath251 . @xmath308 + { \\mathrm{p}}(\\ # \\{t\\in\\tilde{t } \\cap\\mathbb{t}_\\gamma\\}\\ge1 ) , \\ ] ] where @xmath309 as in lemma [ lemmapalm - s0 ] .",
    "the second probability in ( [ eqsfwer2 ] ) goes to zero by lemma [ lemmaunique - max ] , part ( 1 ) . to bound the first probability in ( [ eqsfwer2 ] ) , write @xmath310 = { \\mathrm{p}}\\bigl\\ { \\tilde{t } \\cap\\mathbb{s}_{0,\\gamma } \\ne\\varnothing\\mbox { and } \\max_{t \\in\\tilde{t } } y_\\gamma(t ) > ( \\tilde{v}_{{\\operatorname{bon } } } - v^*_{{\\operatorname{bon } } } ) + v^*_{{\\operatorname{bon } } } \\bigr\\},\\ ] ] where @xmath311)$ ] is deterministic .",
    "for any two random variables  @xmath312 , @xmath313 and any two constants @xmath314 , @xmath315 : @xmath316 . applying this inequality with @xmath317 , @xmath318 and , @xmath319 & \\le&{\\mathrm{p}}[v_\\gamma(v^*_{{\\operatorname{bon } } } - { \\varepsilon})\\ge1]\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + { \\mathrm{p}}\\{\\tilde{t } \\cap\\mathbb{s}_{0,\\gamma } \\ne\\varnothing \\mbox { and } |\\tilde{v}_{{\\operatorname{bon } } } - v^*_{{\\operatorname{bon}}}| > { \\varepsilon}\\}.\\nonumber\\end{aligned}\\ ] ]    the second summand goes to 0 in probability as @xmath79 by lemma [ lemmathreshold ] . for the first summand , lemma [ lemmapalm - s0 ] with level @xmath320 gives that @xmath321 & \\le&{\\mathrm{e}}[v_\\gamma(v^*_{{\\operatorname{bon } } } - { \\varepsilon } ) ] = { \\mathrm{e}}[\\tilde{m}_{0,\\gamma } ] f_\\gamma(v^*_{{\\operatorname{bon}}}-{\\varepsilon})\\\\ & = & \\alpha\\frac { f_\\gamma(v^*_{{\\operatorname{bon } } } - { \\varepsilon } ) } { f_\\gamma(v^*_{{\\operatorname{bon}}})},\\end{aligned}\\ ] ] but the last fraction goes to 1 as @xmath79 . replacing in ( [ eqsfwer3 ] ) and ( [ eqsfwer2 ] ) gives the result .",
    "[ lemmamfdr ] for any nonnegative integer random variables @xmath322 , @xmath323 and fixed positive integer @xmath20 , @xmath324}{{\\mathrm{e}}[v]+j } .\\ ] ]    @xmath325 & & { } + \\sum_{v=0}^\\infty\\sum_{w = j}^\\infty\\biggl(\\frac{v}{v+w } \\biggr){\\mathrm{p}}(v = v , w = w ) \\\\[-3pt ] & \\le&\\sum_{w=0}^{j-1}\\sum_{v=0}^\\infty{\\mathrm{p}}(v = v , w = w ) \\\\[-3pt ] & & { } + \\sum_{v=0}^\\infty \\sum_{w = j}^\\infty\\biggl(\\frac{v}{v+j } \\biggr){\\mathrm{p}}(v = v , w = w ) \\\\[-3pt ] & \\le&{\\mathrm{p } } ( w \\le j-1 ) + { \\mathrm{e}}\\biggl(\\frac{v}{v+j } \\biggr)\\\\[-3pt ] & \\le&{\\mathrm{p } } ( w \\le j-1 ) + \\frac{{\\mathrm{e}}(v)}{{\\mathrm{e}}(v)+j}.\\end{aligned}\\ ] ]    the last inequality holds by jensen s inequality , since @xmath326 is a concave function of @xmath322 for @xmath327 and @xmath328 .",
    "proof of theorem [ thmfdr ] let @xmath329 be the empirical marginal right cdf of @xmath1 given @xmath23 .",
    "then the bh threshold  @xmath96  ( [ eqthresh - bh - random ] ) satisfies @xmath330 , so @xmath96 is the largest @xmath64 that solves the equation @xmath331 the strategy is to solve equation ( [ eqfdrthreshold ] ) in the limit when @xmath332 .",
    "we first find the limit of @xmath333 .",
    "letting @xmath309 as in lemma [ lemmapalm - s0 ] and @xmath334 , so that @xmath335 , write @xmath336 by the weak law of large numbers ( [ eqwlln ] ) and lemma [ lemmaunique - max ] , part ( 3 ) , @xmath337}{{\\mathrm{e}}[\\tilde{m}_{0,\\gamma } ( 0,1 ) ] + a_1}\\vadjust{\\goodbreak}\\ ] ] as @xmath191 , where the expectation is given by ( [ eqexpected - local - maxima ] ) .",
    "in addition we have the results of lemma [ lemmapalm - s0 ] and lemma [ lemmaunique - max ] , parts ( 4 ) and ( 5 ) .",
    "replacing these three limits in ( [ eqecdf ] ) , we obtain @xmath338}{{\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1 ) ] + a_1 } + \\frac{a_1}{{\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1 ) ] + a_1}.\\ ] ] now replacing @xmath333 by its limit in ( [ eqfdrthreshold ] ) , and solving for @xmath64 gives the deterministic solution @xmath339(1-\\alpha)}.\\ ] ]    the fdr at the threshold @xmath104 is bounded by lemma [ lemmamfdr ] by @xmath340 } { { \\mathrm{e}}[v(u^*_{{\\operatorname{bh } } } ) ] + j } \\nonumber\\\\ & = & { \\mathrm{p}}\\bigl(w(u^*_{{\\operatorname{bh}}})\\le j-1\\bigr)\\\\ & & { } + \\frac{{\\mathrm{e } } [ v_\\gamma(u^*_{{\\operatorname{bh } } } ) ] + { \\mathrm{e } } [ \\#\\{t \\in\\tilde{t } \\cap\\mathbb{t}_\\gamma\\dvtx y_\\gamma(t)>u^*_{{\\operatorname{bh } } } \\ } ] } { { \\mathrm{e}}[v_\\gamma(u^*_{{\\operatorname{bh } } } ) ] + { \\mathrm{e } } [ \\#\\{t \\in\\tilde{t } \\cap\\mathbb{t}_\\gamma\\dvtx y_\\gamma(t)>u^*_{{\\operatorname{bh } } } \\ } ] + j } , \\nonumber\\end{aligned}\\ ] ] where we have split @xmath341 into the reduced null region @xmath302 and the transition region @xmath342 . under condition ( c2 ) ,",
    "lemma [ lemmaunique - max ] , part ( 1 ) , gives @xmath343 \\le{\\mathrm{e } } [ \\#\\{t\\in\\tilde{t}\\cap\\mathbb{t}_\\gamma\\ } ] \\to0.\\ ] ] by lemma [ lemmapalm - s0 ] , the remaining terms of the last fraction in ( [ eqfdr - u * ] ) can be written as @xmath344 } { { \\mathrm{e } } [ v_\\gamma(u^*_{{\\operatorname{bh}}})]+j } & = & \\frac{f_\\gamma(u^*_{{\\operatorname{bh}}}){\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1)]l } { f_\\gamma(u^*_{{\\operatorname{bh}}}){\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1)]l + j } \\\\ & = & \\frac{f_\\gamma(u^*_{{\\operatorname{bh}}}){\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1 ) ] } { f_\\gamma(u^*_{{\\operatorname{bh}}}){\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1 ) ] + j / l}.\\end{aligned}\\ ] ] since @xmath104 solves ( [ equbh^ * ] ) , for @xmath79 such that @xmath277 , the above expression tends to @xmath345}{\\alpha{\\mathrm{e}}[\\tilde { m}_{0 , \\gamma}(0,1 ) ] + a_1 + ( 1-\\alpha){\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1 ) ] } = \\alpha\\frac{{\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1)]}{{\\mathrm{e}}[\\tilde{m}_{0 , \\gamma}(0,1 ) ] + a_1 } \\le\\alpha.\\hspace*{-28pt}\\ ] ] combining equations ( [ eqlim2 ] ) , ( [ eqlim1 ] ) and lemma [ lemmaunique - max ] , part ( 3 ) , in ( [ eqfdr - u * ] ) , we obtain @xmath346 .",
    "recall that the bh threshold @xmath96 solves equation ( [ eqfdrthreshold ] ) , and @xmath104 satisfies  ( [ equbh^ * ] ) , where the empirical marginal distribution , @xmath333 , is replaced by its limit . since @xmath347 is continuous , @xmath348 , leading to .",
    "[ apppower ]    [ lemmafwer - fdr - threshold ] for any @xmath349 , let @xmath121 be any interior point of the support @xmath202 of peak @xmath8 . under conditions and , @xmath350 \\to0 , \\qquad u^*_{{\\operatorname{bh}}}/[a_j h_{j,\\gamma}(t ) ] \\to0\\ ] ] in probability , where @xmath103 and @xmath104 are given by ( [ eqthresh - bon - fixed ] ) and ( [ eqthresh - bh - fixed ] ) , respectively .",
    "\\(1 ) from ( [ eqdistr ] ) , for @xmath351 , @xmath192 is bounded above and below by @xmath352 where the lower bound was obtained using @xmath353 for @xmath354 , and the upper bound used the fact that @xmath355 and @xmath356 for @xmath354 . let @xmath357 .",
    "inverting the bounds in ( [ eqf - bounds ] ) we obtain @xmath358 applying these inequalities to @xmath359 and @xmath360 $ ] gives that @xmath361 ^ 2 } < \\frac{\\log[(c_1 + 1)/\\sqrt{2\\pi } ] - \\log(v^*)}{\\log[c_1/(2\\sqrt { 2\\pi } ) ] - \\log(w)}.\\ ] ] applying lhpital s rule , the limit of the above fraction when @xmath362 and @xmath363 go to zero is the same as the limit of @xmath364 .",
    "but this limit is zero because , by the upper bound in ( [ eqf - bounds ] ) and ( [ eqthresh - bon - fixed ] ) , @xmath365}{f_\\gamma(u^*_{{\\operatorname{bon } } } ) } < ( c_1 + 1)\\frac{a_1 + { \\mathrm{e}}[\\tilde{m}_{0,\\gamma}(0,1)]}{\\alpha } l\\phi \\biggl(\\frac{a_j h_{j,\\gamma}(t)}{\\sigma_\\gamma}\\biggr),\\ ] ] which goes to zero by the lemma s conditions .",
    "\\(2 ) the fdr threshold @xmath104 ( [ eqthresh - bh - fixed ] ) is bounded , so the result is immediate .",
    "proof of theorem [ thmpower ] for any threshold @xmath64 , the detection power@xmath366  ( [ eqpower ] ) is greater than @xmath367 / j \\ge{\\mathrm{p}}[w_\\gamma(u ) = j]$ ] . but",
    "this probability goes to  1 by lemma [ lemmaunique - max ] , part ( 3 ) , particularly for the deterministic thresholds  @xmath103 and @xmath104 .",
    "it was shown in the proofs of theorems [ thmfwer ] and [ thmfdr ] that the gap between the deterministic thresholds and the random thresholds  @xmath83 and  @xmath96 narrows to zero asymptotically .",
    "therefore the power for these thresholds goes to 1 as well .",
    "the authors thank pablo jadzinsky for providing the neural recordings data , as well as igor wigman , felix abramovich and yoav benjamini for helpful discussions .",
    "the authors also thank the editor , associate editor and referees for their handling of the manuscript and their useful suggestions ."
  ],
  "abstract_text": [
    "<S> a topological multiple testing scheme for one - dimensional domains is proposed where , rather than testing every spatial or temporal location for the presence of a signal , tests are performed only at the local maxima of the smoothed observed sequence . </S>",
    "<S> assuming unimodal true peaks with finite support and gaussian stationary ergodic noise , it is shown that the algorithm with bonferroni or benjamini  hochberg correction provides asymptotic strong control of the family wise error rate and false discovery rate , and is power consistent , as the search space and the signal strength get large , where the search space may grow exponentially faster than the signal strength . </S>",
    "<S> simulations show that error levels are maintained for nonasymptotic conditions , and that power is maximized when the smoothing kernel is close in shape and bandwidth to the signal peaks , akin to the matched filter theorem in signal processing . </S>",
    "<S> the methods are illustrated in an analysis of electrical recordings of neuronal cell activity .    </S>",
    "<S> ,    .    . </S>"
  ]
}