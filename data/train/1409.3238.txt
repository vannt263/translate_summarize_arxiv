{
  "article_text": [
    "the observed 3d clustering of galaxies provides a wealth of cosmological information : the comoving clustering pattern was encoded in the early universe and thus depends on the physical energy densities ( e.g. @xcite ) , while the bias on large - scales encodes primordial non - gaussianity @xcite .",
    "secondary measurements can be made from the observed projection of this clustering , including using baryon acoustic oscillations ( bao ) as a standard ruler @xcite or by comparing clustering along and across the line - of - sight @xcite . in this paper",
    "we focus on a third type of measurement that can be made , called redshift - space distortions ( rsd ; @xcite ) .",
    "rsd arise because redshifts include both the hubble expansion , and the peculiar velocity of any galaxy .",
    "the component of the peculiar velocity due to structure growth is coherent with the structure itself , leading to an enhanced clustering signal along the line - of - sight .",
    "the enhancement to the overdensity is additive , with the extra component dependent on the amplitude of the velocity field , which is commonly parameterised on large - scales by @xmath5 , where @xmath11 is the logarithmic derivative of the growth factor with respect to the scale factor and @xmath12 is the linear matter variance in a spherical shell of radius @xmath13 .",
    "together these parameterise the amplitude of the velocity power spectrum .",
    "the largest spectroscopic galaxy survey undertaken to - date is the sloan digital sky survey ( sdss ) , which has observed multiple samples over its lifetime .",
    "the sdss - i and sdss - ii @xcite observed two samples of galaxies : the @xmath14-band selected main galaxy sample @xcite , and a sample of luminous red galaxies ( lrgs ; @xcite ) to higher redshifts .",
    "the baryon oscillation spectroscopic survey ( boss ; @xcite ) , part of sdss - iii @xcite extended the lrg sample to higher redshifts with a sample at @xmath15 called cmass , and a sample at @xmath16 called lowz that subsumed the sdss - ii lrg sample .",
    "sdss - iv will extend the lrg sample to even higher redshifts , while simultaneously observing a sample of quasars and emission line galaxies ( elgs ) .    in this paper",
    "we revisit the sdss - ii main - galaxy sample , herein denoted mgs , applying the latest analysis techniques .",
    "we have sub - sampled this catalogue to select high - bias galaxies at @xmath17 ( details can be found in our companion paper @xcite , paper i , which also presents bao - scale measurements made from these data ) .",
    "this sampling positions the galaxies redshift between boss lowz , and the 6-degree field galaxy survey ( 6dfgs ; @xcite ) , filling in a gap in the chain of measurements at different redshifts . selecting high - bias galaxies means that we can easily simulate the sample . in this paper",
    "we present rsd measurements made using the mgs data .",
    "recent analyses of boss have emphasised the importance of accurate mock catalogues @xcite ; these provide both a mechanism to test analysis pipelines and to determine covariances for the measurements made . for the mgs data , we create 1000 new mock catalogues using a fast n - body code based on a new parallelisation of the cola algorithm @xcite , designed to quickly create approximate evolved dark matter fields .",
    "haloes are then selected using a friends - of - friends algorithm , and a halo - occupation distribution based method is used to populate the haloes with galaxies . the algorithms and methods behind picola",
    "can be found in howlett et .",
    "( in prep . )",
    ".    our paper is outlined as follows : in section 2 we describe the properties of the mgs data . in section 3",
    "we summarise how we create dark matter halo simulations using picola . in section 4 , we describe how we calculate clustering statistics , determine the halo occupation distribution we apply to mock galaxies to match the observed clustering , and test for systematic effects . in section 5 , we describe how we model the redshift space correlation function using the gaussian streaming / convolved lagrangian perturbation theory ( clpt ) model of @xcite . in section 6 ,",
    "we describe how we fit the mgs clustering in the range @xmath18 , test our method and validate our choice of fitting parameters and priors using the mock catalogues . in section 7",
    "we present the results from fitting to the mgs data and present our constraints on @xmath5 . in section 8 , we compare our measurements to rsd measurements at other redshifts , including results from @xcite and @xcite , and test for consistency with general relativity .",
    "we conclude in section 9 .",
    "where appropriate , we assume a fiducial cosmology given by @xmath19 , @xmath20 , @xmath21 , @xmath22 , and @xmath23 .",
    "we use the same sdss dr7 mgs data as analysed in paper i , which is drawn from the completed data set of sdss - i and sdss - ii .",
    "these surveys obtained wide - field ccd photometry ( @xcite ) in five passbands ( @xmath24 ; @xcite ) , amassing a total footprint of 11,663 deg@xmath2 , internally calibrated using the ` uber - calibration ' process described in @xcite , and with a 50% completeness limit of point sources at @xmath25 ( @xcite ) . from these imaging data , the main galaxy sample ( mgs ; @xcite )",
    "was selected for spectroscopic follow - up , which to good approximation , consists of all galaxies with @xmath26 , where @xmath27 is the extinction - corrected @xmath14-band petrosian magnitude , within a footprint of 9,380 deg@xmath2 @xcite .    .",
    "the red area shows the same geometry , after a 180@xmath28 rotation .",
    "this illustrates how we produce two mock galaxy samples from every full - sky dark matter halo catalog.,width=317 ]    for our analysis , we start with the sdss mgs value - added galaxy catalog ` safe0 ' hosted by nyu ( nyu - vagc ) , which was created following the methods described in @xcite .",
    "the catalog includes @xmath29-corrected absolute magnitudes , determined using the methods of @xcite , and detailed information on the mask .",
    "we only use the contiguous area in the north galactic cap and only areas where the completeness is greater than 0.9 , yielding a footprint of 6,813 deg@xmath2 , compared to the original 7,356 deg@xmath2 .",
    "we create the mask describing this footprint from the window given by the nyu - vagc , which provides the completeness in every mask region , and the mangle software @xcite .",
    "we also use the mangle software to obtain angular positions of unclustered random points , distributed matching the completeness in every mask region .",
    "the angular footprint of our sample is displayed in blue in fig .",
    "[ fig : foot ] . the red patch in fig .",
    "[ fig : foot ] shows the angular footprint of our galaxy sample after rotating the coordinates via @xmath30 , @xmath31 and once again applying the mask . as described in section [ sec : sim ] , we choose to create full - sky simulations , and in doing so , we can use the mask to create two mock galaxy catalogues that match our footprint , reducing the noise in our estimates of the covariance matrix at almost no extra cost replicates of our survey footprint in each full - sky simulation without overlap , though not , perhaps , without significant cross - correlation between patches taken from the same realisation . in practice",
    "we simply generate two survey patches from each simulation . ] .",
    "we make further cuts on the nyu vagc safe0 sample based on colour , magnitude , and redshift .",
    "these are @xmath32 , @xmath33 and @xmath34 , where @xmath35 is the @xmath14-band absolute magnitude provided by the nyu - vagc .",
    "these cuts produce a sample of moderately high bias ( @xmath36 ) , with a nearly constant number density that is independent of boss and 6dfgs samples .",
    "the resulting sample contains 63,163 galaxies . the redshift distribution is shown in fig .",
    "[ nzmock ] .",
    "the effective redshift of our sample is @xmath37 , calculated as described in paper i , where further details on the sample selection criteria can be found .",
    "[ nzmock ] also shows ( solid line ) the average number density of the mock galaxy catalogues described in section  [ sec : sim ] .",
    "we determine the @xmath38 that we apply to the mocks by fitting to a model with two linear relationships and a transition redshift .",
    "the best - fit is given by @xmath39 we see that the mock galaxy catalogues agree with the data very well , with @xmath40 for @xmath41 degrees of freedom ( 26 redshift bins and 4 independent fitting parameters ) .",
    "the errors come from the standard deviation in number density across the set of mock catalogues .",
    "simulations of our mgs data are vital in order to accurately estimate the covariance matrix of our clustering measurements and to perform systematic tests on our bao and rsd fitting procedures . of order 1000 mock galaxy catalogues ( mocks ) are necessary to ensure noise in the covariance matrix does not add significant noise to our measurements @xcite . for boss galaxies ,",
    "such mocks were created using the methods described in @xcite .",
    "the galaxies in our sample have lower bias than those of boss , and we therefore require a method of producing dark matter halos at higher resolution than used in boss , yet in such a way that we can still create a large number of realisations in a timely fashion . for this we have created the code picola , a highly - developed , planar - parallel implementation of the cola method of @xcite ; this implementation is described in howlett et .",
    "( in prep . ) , and a user guide that will be included with the public release of the code .",
    "it should be noted that a similar method has also recently been used to create mock catalogues for the wigglez survey @xcite , though the codes were developed independently .    in this section ,",
    "we describe how we use picola to produce dark matter fields and then halo catalogues , and how we apply a halo occupation distribution ( hod , @xcite ) prescription to these halo catalogues to produce mock galaxy catalogues .",
    "we expect that the methods we use to generate these halo catalogues will be generally applicable to any future galaxy survey analyses . in section [",
    "sec : clus ] , we describe how we specifically fit an hod model to the measured clustering of the mgs to produce mocks that simulate our mgs data .",
    "these mocks are used in the rsd analyses we present and the bao analysis of paper  i.      we generate 500 dark matter snapshot realisations using our fiducial cosmology , which we convert into 1000 mock galaxy catalogues . although our code is capable of generating lightcones ` on the fly ' without sacrificing speed , we stick with snapshots for simplicity in later stages and because we expect the inaccuracies arising from using snapshots to be small due to the low redshift of our sample . for each simulation",
    "we evolve @xmath42 particles , with a mesh size equal to the mean particle separation , in a box of edge length @xmath43 .",
    "we choose this volume as it is large enough to cover the full sky out to the maximum comoving distance of our sample at @xmath44 ( for our fiducial cosmology this is @xmath45 ) .",
    "we evolve our simulation from @xmath46 to @xmath4 , using 10 timesteps equally spaced in @xmath47 , the scale factor .",
    "this results in a mass resolution of @xmath48 , a factor of @xmath49 smaller than that used for the boss lowz mock catalogues .",
    "each simulation takes around 20 minutes ( including halo - finding ) on 256 cores . in terms of the actual computing time",
    "used , our picola run took @xmath50 cpu - hours compared to @xmath51 cpu - hours for the gadget-2 run described below .",
    "however , it should be noted that the actual ( wall)time taken for the gadget-2 run was not 1000 times that of the picola run , rather the memory requirements of gadget-2 are also larger than those of picola , requiring more processors to run ( 384 in this case ) .",
    "[ pkpicola ] shows the power spectrum of the dark matter fields for one of our picola simulations and for a tree - pm n - body simulation performed using gadget-2 @xcite .",
    "both simulations use the same initial conditions and the same mesh resolution .",
    "we can see that the power spectra agree to within 2 percent across all scales of interest to bao measurements and the agreement continues to within 10 percent to @xmath52 .",
    "we generate halos for our picola dark matter simulations using the friends - of - friends algorithm ( fof ; @xcite ) with linking length equal to the commonly used value of @xmath53 , in units of the mean particle separation .",
    "we average over all of the constituent particles of each halo to calculate the position and velocity of the centre - of - mass .",
    "the halo mass , @xmath54 , is given by the individual particle mass multiplied by the number of constituent particles that make up the halo .",
    "the virial radius is then estimated as @xmath55 where @xmath56 is the critical density , and we use a value @xmath57 ( e.g. @xcite ) .",
    "the clustering of the dark matter particles is recovered well by picola .",
    "it is slightly under - represented on small scales , but we do not need to modify the linking length in order to recover our halos ( unlike , for example , in @xcite ) .",
    "[ halomass ] shows the level of agreement between halo mass functions recovered from our matched parameter picola and gadget-2 runs .",
    "the difference in halo number density for low - mass halos is a direct consequence of the mesh resolution of our simulations . as picola does not calculate additional contributions to the inter - particle forces ( i.e. , via a tree - level particle - particle summation ) on scales smaller than the mesh , using instead the approximate , interpolated forces from the nearest mesh points , we do not produce the correct structure on the order of a few mesh cells or smaller .",
    "this results in slightly ` puffy ' halos .",
    "this is shown in figure  [ picoladensity ] , where for halos within a given mass range we plot the normalised number of dark matter particles in that halo as a function of their separation from the centre of mass , normalised by the halo virial radius .",
    "for the halo mass range in question we see that the constituent particles of the picola halos are located at slightly larger radii than their gadget counterparts .",
    "this difference is reduced as we go to higher mass halos where the overall properties of the halo are still captured .",
    "however , it does mean that we miss some of the outlying particles of the larger halos , and some smaller halos altogether , as the dark matter particles have not collapsed sufficiently to be grouped together by the fof algorithm .",
    "regardless of this , the effect is small enough over the halo mass range of interest for the mgs that we find no correction is necessary before we apply our hod model .",
    "in addition , as described in section  [ sec : phod ] , we determine the hod parameters directly by populating mock dark matter halos .",
    "the deficit of lower mass halos is thus compensated for by assigning more galaxies to lower mass halos .",
    "it should also be noted that although other halo - finding techniques may produce better results , we retain the fof algorithm in the interest of speed .",
    "we populate our halos in a very similar way to that of @xcite using the hod model @xcite . within this framework",
    "we assign galaxies to halos based solely on the mass of the halo , splitting the galaxies into central and satellite types .",
    "we define two mass - dependent functions , @xmath58 and @xmath59 , where @xmath58 denotes the probability that a halo of mass @xmath54 contains a central galaxy and @xmath59 is the mean of the poisson distribution from which we randomly generate the number of satellite galaxies .",
    "these functions are themselves modelled with parameters estimated from a fit to the mgs data , as described in section  [ sec : phod ] .",
    "central galaxies are placed at the centre of mass of the halo , and satellites at radii @xmath60 with probability derived from the nfw profile @xcite @xmath61 where @xmath62 is the characteristic radius , at which the slope of the density profile is -2 , and @xmath63 is the density at this radius .",
    "@xmath64 is the concentration parameter , which we calculate for a halo of mass @xmath54 using the fitting formulae of @xcite . on top of this",
    "we add a dispersion to the mass - concentration relation using a lognormal distribution with mean equal to that evaluated from the fitting functions and variance @xmath65 .",
    "this is the same value as that used in @xcite and is a typical value , as measured from fitting nfw profiles to halos recovered from simulations @xcite .",
    "both central and satellite galaxies are given the velocity of the centre of mass of the halo .",
    "satellite galaxies are then assigned an extra peculiar velocity contribution drawn from a gaussian , with the velocity dispersion calculated from the virial theorem @xmath66 for an nfw profile , the mass inside a radius @xmath14 is @xmath67,\\ ] ] and hence the velocity dispersion for a halo of mass @xmath54 is @xmath68 in order to assign the additional satellite velocities in each direction we use a gaussian distribution with zero mean and variance @xmath69 .    to simulate the effects of redshift - space distortions we displace each galaxy along the line - of - sight by @xmath70 given @xmath71 and a galaxy s true position , we determine angles and redshifts using our fiducial cosmology , placing the observer at the centre of each simulation box .",
    "although we obtain our cosmological constraints from measuring the correlation function and not the data power spectrum , we do use the monopole moment of the power spectrum to determine the hod model used for the mocks , as it is faster to compute than its configuration - space analogue .",
    "we estimate the monopole of the power spectrum , which we denote @xmath72 , using the fourier - based method of @xcite .",
    "we convert each galaxy s redshift space coordinates to a cartesian basis using our fiducial cosmology .",
    "we then compute the overdensity on a grid containing @xmath73 cells in a box of edge length @xmath74 .",
    "this provides ample room to zero pad the galaxies to improve the frequency sampling and results in a nyquist frequency of @xmath75 , much larger than the largest frequency of interest .",
    "we use the random catalogue to estimate the expected density at each grid point .",
    "galaxies and randoms are weighted based on the number density as a function of redshift , @xmath76 where we set @xmath77 , which is close to the measured amplitude at @xmath78 .",
    "this corresponds to physical scales @xmath79 , which are well within our fitting range , and , in any case , the efficiency of this weighting system has only a very weak scale - dependence .",
    "after fourier transforming the overdensity grid we calculate the spherically - averaged power spectrum in bins of @xmath80 , correcting for gridding effects and shot - noise .",
    "the power spectrum of the mgs data is displayed as points in fig .",
    "[ pkmock ] .",
    "the smooth curve and error - bars display the mean of the mock @xmath72 and their standard deviation .",
    "we match the measured @xmath72 of the mgs and the average from 10 halo catalogues in order to determine the hod model that we then apply to all of the mock catalogues . in this way",
    ", we do not need to correct our halo mass function at the low - mass end , as the lack of low - mass halos will be compensated via the population of lower - mass halos .",
    "we use the five parameter functional form of @xcite for the number of central and satellite galaxies , @xmath81 , \\notag\\\\[9pt ]    \\langle n_{sat}(m)\\rangle & = \\langle n_{cen}\\rangle \\left ( \\dfrac{m - m_{cut}}{m_{1}}\\right ) ^\\alpha.\\end{aligned}\\ ] ] for a halo of @xmath82 we set @xmath83 and in the case where we assign satellite galaxies but no central galaxy to a halo , we remove one of the potential satellite galaxies and replace it with a central .",
    "we set the values of the five free parameters by iterating over the following steps :    1 .   populate a subset of the mocks using a given set of hod parameters , 2 .",
    "mask the mock galaxies so that they match the data , 3 .",
    "subsample the mock galaxies to match our idealised @xmath38 , 4 .",
    "calculate the average power spectrum of our populated mocks and compare to the data .",
    "we use 10 mocks to fit our hod , populating and masking them individually , but reproducing the radial selection function by sub - sampling based on the ratio between the analytic fit to the data @xmath38 and the average number density of the 10 mocks .",
    "the fit is performed using a downhill simplex minimisation of the @xmath84 difference between the average , 10-mock power spectrum and the data power spectrum in the range @xmath85 .",
    "the fit is performed twice , first using analytic errors on the power spectrum from @xcite ( equations 4 and 5 therein ) , and then using the covariance matrix from the first fit to generate our final best fit model .    ) between these up to @xmath86 except on large scales ( small @xmath87 ) where the window function introduces additional covariance between different k - bins.,width=317 ]    our best fit hod model has the parameters @xmath88 where @xmath89 is dependent on the five other parameters .",
    "the best fit hod parameters are in good agreement with the hod parameters reported by @xcite for another sdss galaxy sample with similar number density and magnitude limit .",
    "[ pkmockdiff ] shows the percentage difference between the average mock power spectrum and the power spectrum of the data .",
    "the errors come from the covariance estimated from the full mock sample .",
    "we can see that the amplitude of the power spectra matches well on all scales , with @xmath90 agreement up to @xmath91 , except on the largest scales where the window function has a large effect .",
    "the fit is good , as we find @xmath92 for @xmath93 degrees of freedom ( 37 @xmath87-bins and 5 free parameters ) .",
    "[ hodnumber ] shows the expected number of galaxies in our mock halos for our best fit hod model .",
    "this highlights how we are able to recover the clustering properties of the data even though we lack the correct number of low mass halos .",
    "all of the satellite galaxies exist in halos with @xmath94 , which are recovered quite well by our simulations .",
    "below this mass , where our simulations lack sufficient number density , the probability of finding any galaxies within a halo also drops rapidly , such that even though these halos are more abundant in general , the contribution to the total clustering from these halos is small in comparison to the larger mass halos .",
    "there exists significant degeneracy between the five free hod parameters , which can not be broken completely by just the one - dimensional , two - point clustering statistics .",
    "three - point statistics could be used to break this degeneracy @xcite , however this would be prohibitively time - consuming and potentially very noise dominated .",
    "another possibility is to use the quadrupole or hexadecapole moments of the power spectrum , as these contain additional information about the position and velocity distribution of the satellite galaxies within their host halos @xcite .",
    "again , however , in our case these statistics will almost certainly be noise dominated , and are consequently not important for our current implementation of the method . as such",
    "we leave these as future improvements for our mock catalogue production process .",
    "we base our cosmological fits on configuration - space clustering measurements , calculating the correlation function for both mocks and data as a function of both the redshift space separation @xmath95 , and the cosine of the angle to the line of sight @xmath96 , using the same coordinate transformation as for the power spectrum .",
    "we use the minimum variance estimator of @xcite , with galaxy and random weights as given in eq .",
    "( [ weights ] ) , to calculate the correlation function from the normalised galaxy - galaxy , galaxy - random and random - random pair counts for @xmath97 and @xmath98 in bins of @xmath99 and @xmath100 .",
    "from there we perform a multipole expansion of the two - dimensional correlation function via the riemann sum @xmath101 where @xmath102 and @xmath103 are the legendre polynomials of order @xmath104 .",
    "we generate the monopole and quadrupole for different bin widths by re - summing the pair counts before applying eq .",
    "( [ moments ] ) .            figs .",
    "[ xi0mock ] and [ xi2mock ] show the monopole and quadrupole of the correlation function for the average of the mocks and for the data for the 24 measurements in the range @xmath105mpc .",
    "the mean of the mock @xmath106 and @xmath107 do not match the data within the error - bars at many scales .",
    "however , we only plot the diagonal elements of the covariance matrix and the off - diagonal elements represent a significant component ( see fig . [ covar ] ) .",
    "a more proper comparison is the @xmath108 between the mean of the mocks and the data , using the full covariance matrix . for both @xmath106 and @xmath107",
    "the @xmath108/d.o.f is slightly less than one , implying the anisotropic clustering in the mock samples is a good representation of the data , even at 10@xmath109mpc scales ( and hence ` @xmath110 by eye ' is a bad idea ) .",
    "+      we use our sample of mock galaxy catalogues to estimate the covariance matrix for both the power spectrum and correlation function in the standard way , and invert to give an estimate of the inverse matrix .",
    "we remove the bias in the inverse covariance matrix by rescaling by a factor that depends on the number of mocks and measurement bins ( e.g. @xcite ) .",
    "[ covar ] shows the correlation matrix , @xmath111 , for the power spectrum and the monopole and quadrupole moments of the correlation function using our fiducial binning scheme .",
    "we can see that there is significant off - diagonal covariance in the correlation function and non - negligible cross - covariance between the monopole and quadrupole , however the power spectrum covariance matrix is much more diagonal .    to fit to the correlation function moments , we assume that the binned monopole and quadrupole are drawn from a multi - variate gaussian distribution , and assume the standard gaussian likelihood , @xmath112",
    ". the validity of this assumption , for both our fits and the bao fits to the power spectrum found in paper i , is tested in the following section .",
    "there are additional factors that one must apply to uncertainties determined using a covariance matrix that is constructed from a finite number of realisations and to standard deviations determined from those realisations @xcite . in this work",
    "we multiply the inverse covariance matrix estimate by a further factor given by @xmath113 in equation  18 of @xcite , such that the errors derived from the shape of the likelihood are automatically corrected for this bias .",
    "we have the number of mocks @xmath114 , the number of bins @xmath115 and the number of parameters fitted @xmath116 , giving only a small correction to the inverse covariance matrix of @xmath117 .",
    "the coordinate transformation that allows us to create two distinct mocks from each dark matter realisation puts the two patches as far apart as possible to minimise the covariance between mocks based on the same dark matter cube .",
    "the minimum possible distance between two objects in different patches is @xmath118 .",
    "whilst this is within the range of scales we are interested in , the total cross - correlation between patches is very small .",
    "we number our mocks such that pairs of mocks ( e.g. 1 & 2 , or 3 & 4 ) were drawn from the same dark matter cube .",
    "thus we expect the set of @xmath119 even numbered mocks and the set of @xmath119 odd numbered mocks to be independent of any correlations caused by the sampling , and any cross correlation to be due to noise .",
    "the cross correlation coefficient , @xmath120 for both the monopole and quadrupole of the correlation function , and for the power spectrum , calculated from the 500 pairs of mocks drawn from the same dark matter cube is shown in fig .",
    "[ crosscoeff ] .",
    "the dashed lines in fig .  [ crosscoeff ] indicate the maximum and minimum correlation coefficient ( at any scale considered ) between 500 pairs of independent mocks ( i.e. taking pairs where both mocks have even or odd numbers ) .",
    "the fact that the cross correlation between pairs drawn from the same dark matter cube is almost entirely within these bounds indicates that there is no cross correlation above the level of noise in our combined covariance matrix , even on scales where the pairs of mocks could , theoretically , be covariant .",
    "we also test the effect of assigning redshifts to our random data points from randomly chosen galaxies as opposed to simply generating them by sampling a smooth fit to the number density . in fig .",
    "[ reshuffled ] we present the differences in the measured correlation function monopole and quadrupole moments of the mgs data , when they are calculated either using random data points that are assigned redshifts from the corresponding galaxy catalogue ( ` shuffled ' ) , or when they are given redshifts sampled from the fitted number density described in section  [ sec : data ] .",
    "we may expect ` shuffling ' to reduce the clustering , especially on scales below @xmath121 , because spherically averaged features in the galaxy field are removed in the shuffled approach .",
    "the power removed is predominantly along the line of sight , and hence the quadrupole is affected more than the monopole . from fig .  [",
    "reshuffled ] we see that for both monopole and quadrupole , the difference in clustering between the two methods is well below the level of the noise .",
    "we adopt the shuffling approach as we do not know the true radial distribution for the data , and this approach allows for all features caused by the galaxy selection , at the expense of a small reduction in the monopole and quadrupole moments .",
    "further , @xcite found that the shuffling approach is less biased than fitting to a smooth @xmath38 when both methods were tested on boss mocks ( with a known @xmath38 ) , and the differences we find are consistent with those of @xcite .",
    "such differences are so small that we do not need to account for this in our model fitting .",
    "our final test is on the assumption that the measured correlation function and power spectrum are drawn from an underlying multivariate gaussian distribution .",
    "this assumption is the basis of the likelihood calculations made in both the bao fits of paper i and the rsd fits presented in this paper .",
    "we perform a kolmogorovsmirnov test on the log of the power spectrum ( which is used in the bao fits of paper i ) and monopole and quadrupole of our mock catalogues , using the cumulative distribution function ( cdf ) of the normalised differences between the two - point statistics measured from each mock realisation and the average over all the mock catalogues . following the standard method of the kolmogorovsmirnov test",
    "we define the parameter @xmath122 as the maximum difference between our cdf and the cdf of the distribution we wish to test against , in this case a gaussian . the p - value for this test , which indicates the probability that the observed value of @xmath122 would be a large as it is if our underlying distribution _ were _ gaussian , is then given by a simple rescaling of the parameter d , @xmath123 and the the approximate expression @xmath124 here",
    ", @xmath125 is the number of bins in our measured cdf .",
    "as elsewhere , we use bins of width @xmath126 for the power spectrum and @xmath127 for the correlation function .",
    "[ kstest ] shows the kolmogorovsmirnov test p - value for the two - point statistics as a function of scale .",
    "we can see that there is no trend with scale and across all scales of interest the p - value indicates a high probability that both the power spectrum and correlation function are drawn from a gaussian distribution .",
    "the log of the power spectrum has a particularly high probability of being drawn from a gaussian distribution , which is why we use this rather than the power spectrum itself when fitting the bao feature in paper i. based on the p - values we obtain , we find that even for those bins in the correlation function where the difference between our measured cdf and a gaussian cdf is largest , we could expect a greater difference at least 20% of the time if our measured clustering statistics were drawn from an underlying gaussian distribution .",
    "to model our redshift space monopole and quadrupole we use the combined gaussian streaming / convolved lagrangian perturbation theory ( clpt ) model of @xcite .",
    "the clustering of galaxies in redshift space can be written as a function of their real space correlation and their full pairwise velocity dispersion @xcite . in the gaussian streaming model , introduced by @xcite ,",
    "the pairwise velocity dispersion is approximated as a gaussian , which allows one to write the two - dimensional redshift space correlation function , @xmath128 , as a function of the real - space correlation function , @xmath129 , and the mean infall velocity and velocity dispersions betweens pairs of galaxies , @xmath130 and @xmath131 respectively , @xmath132^{1/2}}[1+\\xi(r ) ] \\\\ & \\times \\text{exp } \\left\\ { -\\frac{[s_{||}-r_{||}-\\mu v_{12}(r)]^{2}}{2\\sigma_{12}^{2}(r,\\mu ) } \\right\\}. \\label{eq : gs } \\end{aligned}\\ ] ] here @xmath133 and @xmath134 denote redshift space separations transverse and parallel to the line of sight , @xmath135 denotes the real space separation parallel to the line of sight , such that @xmath136 , and @xmath137 is as defined previously .",
    "@xcite evaluate @xmath130 and @xmath131 using a standard perturbation theory expansion of a linearly biased tracer density field , however this does not accurately replicate the velocity statistics of the tracer field on small scales , nor the smoothing of the bao feature .",
    "this was improved upon by @xcite in their analysis of the boss cmass galaxy sample by using lagrangian perturbation theory to generate the real - space correlation function above scales of @xmath138 .",
    "this proved effective for the boss cmass sample , although @xcite note that the boss cmass galaxy sample has a second order bias close to zero , the point at which the accuracy of the standard perturbation theory evaluation of @xmath130 and its derivative is greatest .",
    "@xcite and @xcite further improve the modelling of the correlation function by computing the real - space correlation function using convolved lagrangian perturbation theory and evaluating @xmath130 and @xmath131 in the same framework .",
    "this formulation relies on a perturbative expansion of the lagrangian overdensity and displacement which in turn allows us to write the correlation function and velocity statistics as a series of integrals over powers of the linear power spectrum . for biased tracers",
    "the model assumes a local real - space lagrangian bias function , @xmath139 , and solutions up to @xmath140 reveal a dependence on both the first and second derivatives of the bias function , @xmath141 and @xmath142 , and combinations thereof .",
    "furthermore , as would be expected , the velocity statistics have a dependency on the growth rate of structure , @xmath143 , via the multiplicative factor , @xmath144 .",
    "from @xcite we can easily relate the linear galaxy bias , @xmath145 , to the first derivative of the lagrangian bias function by @xmath146 .",
    "the model is calculated as follows . for a vector @xmath147 in real space and vector @xmath148 in langrangian space",
    ", we can define three functions that depend on the lagrangian bias , growth rate and linear power spectrum : @xmath149 , @xmath150 and @xmath151 .",
    "@xmath152 is a scalar function , whilst @xmath153 and @xmath154 are vector and tensor functions along cartesian directions @xmath155 and @xmath156 .",
    "the exact form of the functions @xmath152 , @xmath153 , and @xmath154 are given in @xcite    we can then calculate @xmath129 and @xmath130 by projecting the scalar and vector functions along the pair separation vector and integrating with respect to the lagrangian separation , @xmath157^{-1}\\int d^{3}q m_{1,n}(\\boldsymbol{r},\\boldsymbol{q})\\hat{r}_{n}.\\end{aligned}\\ ] ] we split the velocity dispersion @xmath131 into components perpendicular and parallel to the pair separation vector and evaluate these separately by projecting and integrating the tensor function , @xmath158 where @xmath159^{-1}\\int d^{3}q m_{2,nm}(\\boldsymbol{r},\\boldsymbol{q})\\hat{r}_{n}\\hat{r}_{m } , \\\\",
    "\\sigma_{\\perp}^{2}(r ) & = \\frac{[1+\\xi(r)]^{-1}}{2}\\int d^{3}q m_{2,nm}(\\boldsymbol{r},\\boldsymbol{q})\\delta_{nm}^{k } - \\frac{\\sigma_{||}^{2}}{2}\\end{aligned}\\ ] ] and @xmath160 is the kronecker delta .    hence , for a given cosmological model parameterised by @xmath161 and @xmath143 , we can calculate , for any scale of interest , a unique set of @xmath129 , @xmath130 and @xmath131",
    "entering these into eq .",
    "( [ eq : gs ] ) allows us to generate our two - dimensional redshift space correlation function and from there we can generate a model monopole and quadrupole .",
    "these models are fitted to the measurements from data and mocks as described later to constrain a given set of cosmological parameters .      in calculating the correlation function of our data",
    "we have to assume a ( fiducial ) cosmological model to calculate the physical separations between galaxies parallel and transverse to the line of sight .",
    "specifically , to calculate the separation along the line of sight we require the hubble parameter , @xmath162 , and the galaxy redshifts , whilst the transverse separation requires knowledge of the angular diameter distance , @xmath163 , and the angular separation of the galaxy pair .",
    "any difference between the relative values of these parameters in the fiducial cosmology and the true cosmology will manifest as anisotropic clustering , that is , a difference in the clustering of galaxies parallel and perpendicular to the line of sight .",
    "if an observable such as the bao feature is expected to be statistically isotropic , then any measured anisotropy can also be used to constrain the true cosmology of our universe .",
    "this is the alcock - paczynski ( ap ) test @xcite .",
    "anisotropy is also being added by redshift space distortions . as such",
    ", the ap effect and rsd are degenerate and we need a way to disentangle these effects .    following @xcite , we introduce two scale parameters , @xmath164 and @xmath165 .",
    "@xmath164 denotes the stretching of all scales and hence encapsulates the isotropic shift whilst @xmath165 parameterises the ap effect .",
    "measuring these two parameters allows us to constrain the angular diameter distance and hubble expansion independently , @xmath166 where a subscript ` fid ' denotes our fiducial model and @xmath167 is the measured bao peak position .",
    "values @xmath168 and @xmath169 would indicate that our fiducial cosmology is the true cosmology of the measured correlation function .    in terms of our model correlation function the @xmath164 and @xmath165 parameters modify the scales at which we measure a given value for the correlation function , @xmath170    during our fits we apply the values of @xmath164 and @xmath165 directly to alter the scales at which we calculate the two - dimensional redshift space correlation function ( given by eq .",
    "( [ eq : gs ] ) ) , calculating the necessary correction to the parallel and perpendicular separations , @xmath134 and @xmath171 , before using these to calculate the corresponding values of @xmath172 and @xmath96 required by the integrand .",
    "we subsequently integrate the 2d model for the correlation function to estimate monopole and quadrupole moments .      finally , we must account for the way we bin our data when calculating our model . rather than evaluating our model at the centre of those bins",
    ", we take into account variations in the model correlation function across each bin , and instead take the weighted average of our model within each bin . for a bin from @xmath173 to @xmath174",
    "centred at @xmath95 , our model is @xmath175 where @xmath176 is the normalisation for the weighted mean , @xmath177    for all the fits detailed in this paper we calculate our model in bins of width @xmath178 between @xmath179 , before calculating eq .",
    "( [ eq : bincentre ] ) , using a cubic spline interpolation method to interpolate the value of the monopole and quadrupole at any point required for the integration .",
    "for our analysis , we consider the shape of the linear power spectrum to be parameterised by the cold dark matter and baryonic matter densities , @xmath180 and @xmath181 , and the scalar index , @xmath182 , whilst the amplitude of the power spectrum is quantified using @xmath12 . on top of this",
    "we add the growth rate of structure , @xmath143 , which we wish to measure via the rsd signal , galaxy bias parameters @xmath145 and @xmath142 , and bao dilation parameters @xmath164 and @xmath165 , which we measure independently of the power spectrum shape .    in theory , the dependence of the clpt model on @xmath183 , @xmath145 , @xmath143 , @xmath142 and @xmath12 is such that , combined with the other dependencies , all of the above parameters can be independently measured if the data has no noise . in practice however , the parameters @xmath143 , @xmath145 and @xmath12 are strongly degenerate at the linear level and we are unable to constrain these independently .",
    "in addition , we can provide no constraints on the shape of the linear power spectrum beyond those , already tight , constraints given by the planck collaboration s analysis of the cosmic microwave background radiation . in lieu of this we fix @xmath180 , @xmath181 and @xmath182 to the fiducial values used to create our mock catalogues , which correspond closely to the planck best - fit values , and assume that any variation in these parameters can be captured by departures from @xmath184 and @xmath185 .",
    "overall , then , we explore a combination of cosmological parameters @xmath186 . here",
    "we treat @xmath12 as containing two separate contributions , linear and non - linear .",
    "the former of these is contained in the @xmath187 and @xmath5 parameters which are our parameters of interest and are responsible for the overall amplitude of the monopole and quadrupole of the correlation function .",
    "the latter , @xmath188 , is only effective at the smallest scales we fit against and as such is largely unconstrained and degenerate with the second order bias parameter @xmath142 .    in all fits",
    "we do not allow @xmath5 to vary in such way that we choose unphysical values of @xmath189 or @xmath190 , and we apply uniform priors of @xmath191 and @xmath192 , as for the bao fits of paper i. we include priors on @xmath164 and @xmath188 as described and tested in section  [ sec : priors ] .",
    "we marginalise over two nuisance parameters while fitting the correlation function , which we denote @xmath193 and @xmath194 .",
    "the first of these corresponds to an additive correction to @xmath195 in the gaussian streaming model .",
    "this compensates for two different effects that both manifest at the same point in the model .",
    "the first is the clpt model s inability to fully recover the large scale halo velocity dispersion . whilst the scale - dependence of both the @xmath196 and @xmath197 parts of @xmath195",
    "is well recovered by the clpt , there is a mass - dependent , constant amplitude shift across all scales .",
    "this systematic offset in the halo velocity dispersion offset is identified in @xcite and further explored in @xcite , who go on to suggest that it stems from gravitational evolution on the smallest scales , which can not be accurately predicted by perturbation theory and hence can not be separated from the overall scale - dependence of @xmath195 . rather than calibrate the corrective factor required to shift the amplitude of the velocity dispersion using , for example , n - body simulations we simply treat this as a free parameter , and part of the @xmath193 nuisance parameter .",
    "the second component of @xmath193 is the additional velocity dispersion along the line of sight due to the so called , ` fingers - of - god ' , resulting from peculiar motions of the galaxies within their host halos .",
    "this effect is expected to be small on our scales of interest and in the monopole and quadrupole of the correlation function .",
    "we apply a very broad , flat prior of @xmath198 .",
    "this range is similar to that used in @xcite , where they allow the fingers - of - god intra - halo velocity dispersion to vary from @xmath199 to @xmath200 , providing a detailed set of tests to validate this prior .",
    "we additionally allow this term to go negative over the same range to account for the fact that , as mentioned in @xcite , the perturbation theory calculation of @xmath195 overestimates the amplitude of the positive offset required to bring linear theory in line with the measurements from n - body simulations , hence resulting in a @xmath195 which is larger than would be measured .",
    "our second nuisance term is the integral constraint , which takes the form of an additional constant added to the correlation function monopole .",
    "this accounts for incorrect clustering on the largest scales due to the finite volume of our survey .",
    "whilst , given a model , this can be calculated analytically from the properties of our survey , we include it as a free parameter to also account for additional uncertainties in the modelling of the monopole and potential observational systematic effects , which tend to add nearly scale - independent clustering @xcite . under the assumption that the integral constraint is independent of the angle to the los , this vanishes for the quadrupole and so we only apply a nuisance parameter of this form to the monopole .",
    "we test the model and our fitting methodology by fitting the average monopole and quadrupole of the correlation function recovered from the 1000 mocks .",
    "we use the joint covariance matrix appropriate for a single realisation , including the cross - covariance between the monopole and quadrupole : thus the errors recovered should match those from a single realisation . to perform the fit , we perform a mcmc sampling over models using the publicly available emcee python routine @xcite . for each parameter",
    "we quote the best - fit value of the marginalised likelihood , with @xmath201 errors defined by the @xmath202 regions around this point .",
    "our fiducial fitting choices are as follows : we use @xmath203 as our fiducial bin width , and keep only those bins with centres @xmath18 .",
    "we apply a prior on @xmath164 based on the results of paper i , and we apply priors on @xmath165 and @xmath188 based on results using data from the planck satellite @xcite .",
    "our fiducial range of scales is chosen based on the facts that including larger scales adds little extra information and the accuracy of the clpt model starts to decrease below @xmath204 for the range of halo masses where galaxies in our sample are found @xcite .",
    "we will motivate our other choices and demonstrate that our @xmath5 measurements are largely independent of these choices in the following sections .",
    "llccc & * average of mocks : * + no . & case & @xmath205 & @xmath187 + 1 & full fit & @xmath206 & @xmath207 + 2 & prior on @xmath164 & @xmath208 & @xmath209 + 3 & prior on @xmath188 & @xmath210 & @xmath211 + 4 & @xmath212 & @xmath213 & @xmath214 + 5 & @xmath215 & @xmath216 & @xmath217 + 6 & @xmath218 & @xmath219 & @xmath220 + 7 & @xmath221 & @xmath222 & @xmath223 + 8 & @xmath224 , @xmath185 & @xmath222 & @xmath225 + 9 & @xmath226 , @xmath185 & @xmath227 & @xmath228 + 10 & linear fit & @xmath229 & @xmath230 + [ tab : mockrsd ]     and @xmath187 values and one - sigma errors from fitting to the mean of the mocks for the 10 cases listed in table [ tab : mockrsd ] .",
    "the dashed line indicates the expected growth rate assuming our fiducial @xmath8cdm cosmology .",
    "the shaded band indicates the expected linear galaxy bias as measured from our hod fits to the mgs sample , we use a band rather than a line to account for the fact that the calculated value depends slightly on the range of scales used . , width=317 ]",
    "the best fit values for all of our fitting cases are collated in table  [ tab : mockrsd ] .",
    "[ mockrsdplot ] shows the best - fit values for the cases listed in the table along with the @xmath8cdm prediction of @xmath5 , which closely matches that used in the production of the mock catalogues , and the expected galaxy bias assuming linear theory @xcite . for our fiducial",
    "@xmath8cdm cosmology , and assuming gr , we have @xmath231 and @xmath232 , and from our hod fits to the mgs we have @xmath233 depending on the exact scales used to estimate the linear galaxy bias .     and @xmath188 .",
    "the errors are derived from the covariance matrix and are the errors on a single realisation .",
    "the clpt model does a fantastic job of reproducing the measured clustering on all scales of interest.,width=317 ]    in fig .",
    "[ rsdmcmock ] we plot the best - fitting model monopole and quadrupole for our fiducial fit alongside that measured from the average of mocks .",
    "we can see that the clpt model does remarkably well in modelling the monopole and quadrupole across all the scales we fit against , with only small inaccuracies at the smallest scales and around @xmath234 .",
    "the inaccuracies are clearly well below the expected level of noise in our measurements .",
    "we include a prior on @xmath164 , motivated by the expected improvement in the bao peak position after reconstruction , in our fiducial @xmath5 measurements , and we test the effect of including this for mock results in this section .",
    "much of the information on @xmath164 comes from the bao feature , however in our data , as may be inferred from fig .",
    "[ xi0mock ] , the bao feature in the monopole is very noisy .",
    "reconstruction provides a means for us to recover more of the information within the bao feature and hence can improve our constraints on @xmath164 , as was done in paper i. during reconstruction we assume a linear rsd model to convert the galaxy overdensity in redshift space to a lagrangian displacement for each galaxy .",
    "it is common , but not necessary , to also scale the displacements to remove the linear rsd and simplify the bao constraints by making the amplitude of the signal isotropic when analysed in the true cosmology .",
    "the effect of this process on the quadrupole of the correlation function is not well understood and so post - reconstruction measurements can not currently be used for rsd constraints .    however , as a result of the bao fits in paper i , we still have a greater knowledge of @xmath164 than is apparent in the pre - reconstruction monopole .",
    "we encapsulate this using a gaussian prior on @xmath164 , centred on the recovered post - reconstruction best - fit values from paper i , and with a variance calculated from the difference between pre- and post - reconstruction fits to the bao feature ( the pre - reconstruction uncertainty is a factor 2.5 times greater than the post - reconstruction result ) . in other words",
    ", we expect the inclusion of the @xmath164 prior to recover the same uncertainty on @xmath164 as found in paper i. reconstruction also shifts the position of the bao peak due to the removal of coupling between different k - modes on the scale of the bao feature .",
    "paper i fits the post - reconstruction ( hence no mode - coupling ) correlation function with a model that does not include mode - coupling , whereas we fit the pre - reconstruction correlation function with a non - linear model that does include mode - coupling and hence the expected values of @xmath164 returned by both methods should be the same .",
    "we find that including such a prior has only a small effect on the recovered values and errors for @xmath5 and @xmath187 , slightly decreasing the error range for both .",
    "the recovered best - fit values only change by a small amount compared to the statistical error on the measurements .",
    "this indicates that such a process introduces no bias into our results , which is not surprising , as the @xmath164 prior comes from the comparison of the data itself before and after reconstruction , and we expect systematic effects entering during the reconstruction process to be very small .",
    "the reduction in the error range comes from the improvement in the alcock - paczynski measurement when the bao position is known , and not from double counting as we have carefully only included the extra information recovered post - reconstruction .",
    "the clpt model s dependency on @xmath188 in the non - linear regime is weak enough that our data provides no constraints on this except through the first order measurements of @xmath187 and @xmath5 .",
    "the remaining non - linear contribution is largely unconstrained .",
    "we therefore consider a planck+wp+highl prior on @xmath188 ( planck collaboration et al .",
    "2013 ) , which takes the form of a gaussian with mean @xmath235 and variance 0.012 , so that the second order corrections to the model do not stray into unphysical regions of parameter space , where the model itself is not expected to be accurate",
    ". for our baseline fits , we adopt this prior , which we consider not to be introducing any additional information to our measurements , but simply forcing us to only consider physical solutions for the clpt model .",
    "when we include this prior there is a small change in the recovered mean values of @xmath5 and @xmath187 . for the average of the mocks we can see that the value of @xmath5 decreases slightly from 0.49 to 0.45",
    "this shift actually brings the values of @xmath5 closer to that expected based on the cosmology used to generate the mocks and is well within the expected statistical deviation of the measurement . additionally , adding in the @xmath188 prior increases the value of @xmath187 and",
    "tightens our constraints , bringing them closer to the expected value .",
    "this is because the prior allows us place constraints on the second order contribution to the galaxy bias , which , in the clpt model , enters as additional small scale clustering proportional to @xmath236 . when this contribution is completely unconstrained , large values force the linear galaxy bias to be lower than it should be to fit the smallest scales . due to the strong degeneracy between @xmath187 and @xmath5",
    "it is actually this stronger constraint on @xmath187 that has a knock - on effect of reducing the value of @xmath5 we obtain .",
    "we perform several robustness tests using the @xmath164 and planck prior measurement , looking at the effects of changing both the bin width of our measurements and the fitting range .",
    "when we change the fitting range to @xmath237 we see a slight increase in @xmath5 , and corresponding decrease in @xmath187 , though these shifts are well within the statistical uncertainty .",
    "the reason for this shift stems from the higher order lagrangian bias contributions : when we remove the small scale data , our constraints on @xmath142 become much weaker and it is harder to decouple from @xmath141 .",
    "we can also see that the errors on @xmath5 and @xmath187 increase when we reduce our fitting range , consistent with the loss of information , particularly at small scales .",
    "the results in table  [ tab : mockrsd ] and figure  [ mockrsdplot ] also show that our choice of bin width has negligible effect on the results we obtain . in cases 5 and 6",
    "we perform fits using our fiducial fitting range and priors but using a correlation function and covariance matrix that has been binned using @xmath238 and @xmath239 respectively .",
    "we find that the results are fully consistent with each other and our fiducial bin width case , with only small , statistically driven deviations in the mean and @xmath201 marginalised values of @xmath5 and @xmath187 .",
    "we also look at models where we do not vary the values of @xmath164 and @xmath165 , as in several previous studies @xcite .",
    "this carries the implicit assumption that our fiducial cosmology is the true cosmology .",
    "figure  [ planckap ] shows the expected deviation of these parameters , assuming @xmath8cdm , at our effective redshift based on the cosmological results from planck @xcitecdm base - planck - lowl - lowlike - highl chains which , at the time of writing , are publicly available for download from the planck legacy archive at http://pla.esac.esa.int/pla/aio/planckproducts.html . ] , which is the basis for our fiducial cosmology .     and @xmath165 at @xmath4 based on planck @xmath8cdm cosmological constraints .",
    "ellipses show the 1 , 2 and 3@xmath240 regions , whilst dashed lines show the mean and @xmath201 errors of the marginalised distributions.,width=317 ]    we see that @xmath165 , which is related to the ap parameter f as in eq .",
    "( 21 ) , is very well defined at the effective redshift of our sample , with only a 1% deviation from @xmath169 allowed to within 5@xmath240 .",
    "even relatively large deviations from our fiducial cosmology manifest as only small changes in @xmath165 away from zero . as a majority of the information on @xmath165 comes from the quadrupole , which is also where we obtain most of the information on @xmath5",
    ", we can conclude that the actual ap signal we expect to measure as part of our fitting is also small .",
    "however , from figure  [ planckap ] we can also see that fixing alpha to our fiducial value is not supported by the planck data , where even large deviations from @xmath168 can be found to within 5@xmath240 .",
    "it is mainly the monopole of the correlation function that constrains @xmath164 , but the large degeneracies between @xmath164 and @xmath187 , and @xmath187 and @xmath5 means that fixing this value could have a knock - on effect on our @xmath5 constraints . as such we hypothesise that though the expected degeneracy between the ap and rsd signals is small , not allowing @xmath164 to vary could bias our constraints on @xmath187 and @xmath5 .    finally , it also important to note that figure [ planckap ] is only true when we assume a @xmath8cdm cosmology . allowing for @xmath241 , a time - dependent equation of state for",
    "dark energy , or other non - standard cosmological models could allow for a much greater variation in @xmath164 and @xmath165 from their fiducial values . as these phenomena are only emergent at late times they would be largely unconstrained by planck , rendering any apparent planck priors on @xmath164 and @xmath165 moot .",
    "to test this we perform additional fits to the average of the mocks : first fixing @xmath169 and allowing alpha to vary , then fixing @xmath165 and @xmath164 .",
    "we fix @xmath164 to two different values : @xmath184 , which is what we expect for the mean of the mocks , and @xmath242 which is the value recovered from the bao - only fits to the mgs data in paper i.    from table  [ tab : mockrsd ] and figure  [ mockrsdplot ] we can see the recovered values of @xmath5 and @xmath187 when fixing @xmath165 do shift slightly , but are still in very good agreement with the expected values for the mocks .",
    "this indicates that we are not introducing any bias into our results .",
    "the uncertainty on @xmath5 is also reduced substantially , with the lower bound especially reduced by a factor of 2 .",
    "this is because confining our model to only those regions of parameter space that are in agreement with the planck-@xmath8cdm predictions greatly reduces the degeneracy between @xmath5 and @xmath165 , improving our constraints .",
    "it should be noted however that this result would also be recovered if we were to take the case where we vary @xmath164 and @xmath165 and simply combined with planck data at a later stage , as the constraints from planck are tight enough to effectively fix @xmath165 .",
    "the benefit to allowing @xmath165 to vary is that the subsequent @xmath5 results are more general and can be combined with any additional models , not just those that agree with the planck-@xmath8cdm constraints .",
    "when fixing @xmath164 to different values we do see a small change in the recovered best fit values of @xmath187 and @xmath5 , whilst the uncertainties therein remain unchanged .",
    "however this is not much beyond that seen when fixing @xmath165 to the value expected from the mocks .",
    "we will reiterate , however , that fixing @xmath164 is not supported by the planck-@xmath8cdm predictions and so this should be allowed to vary .",
    "lastly , we investigate the case where we perform a simple linear model fit as per @xcite . in table  [ tab : mockrsd ] and figure  [ mockrsdplot ] we show the results when fitting using a linear model .",
    "here we still keep our reconstruction - motivated prior on @xmath164 , and vary @xmath243 and @xmath194 . in this case",
    "we find that the error budget for both @xmath5 and @xmath187 is significantly reduced in comparison to our fiducial fit , and to a greater extent than when we use our perturbation theory model but fix @xmath164 and @xmath165 .",
    "a simple linear model neglects the contributions from higher order bias corrections which for our sample are non - negligible and have been shown to affect our estimation of @xmath187 and , by way of the strong degeneracy therein , @xmath5 .",
    "however , we find that there is no significant bias in the recovered best - fit values themselves when using a linear model and that any differences between the observed rsd signal and the prediction from linear theory are largely hidden by noise .",
    ".the mean values and one - sigma errors on @xmath5 and @xmath187 from fitting to the data monopole and quadrupole , when different priors are applied and certain parameter combinations are fixed . from @xmath8cdm and",
    "gr we expect @xmath244 and from our hod fits to the mgs data we expect @xmath245 .",
    "[ cols=\"<,<,^,^,^ \" , ]      and @xmath187 values and one - sigma errors from fitting to the data for the 10 cases listed in table [ tab : datarsd ] . as for fig .",
    "[ mockrsdplot ] , the dashed line indicates the expected growth rate assuming our fiducial @xmath8cdm cosmology .",
    "the shaded band indicates the expected linear galaxy bias as measured from our hod fits to the mgs sample , we use a band rather than a line to account for the fact that the calculated value depends slightly on the range of scales used . , width=317 ]",
    "@xmath187 and @xmath5 likelihood contours and respective 1d marginalised likelihoods for the mgs galaxy sample using our fits to the monopole and quadrupole in the range @xmath246 with bins of width @xmath203 and priors on @xmath164 and @xmath188.,width=317 ]    in this section we present our constraints on @xmath5 and @xmath187 from fitting to the mgs data using the method detailed and tested in the previous section .",
    "we have shown that our fitting method is independent of our choice of priors , fitting range and bin size , but in the interest of completeness we perform a range of fits equal to those performed on the average of the mocks .",
    "for equivalent fits to both data and mocks we use the same covariance matrix , so any differences stem from noise in the data or , of course , differences between our fiducial cosmology and the true cosmology .",
    "the marginalised mean values and @xmath201 constraints on @xmath5 and @xmath187 for all of our fits are given in table  [ tab : datarsd ] with the minimum @xmath108 values , and shown in the corresponding fig .",
    "[ datarsdplot ] .    as for the results fitting the average of the mocks",
    ", we can see that adding a prior on @xmath164 introduces no noticeable bias to our best fit @xmath5 and @xmath187 values and only a slight reduction in the errors .",
    "when fitting to the data , the best fit @xmath84 increases slightly from @xmath247 to @xmath248 for 26 degrees of freedom ( 34 bins and 8 free parameters ) when we introduce our prior on @xmath164 .",
    "such an increase is to be expected as the prior forces our best - fit model away from the overall maximum likelihood model , however the difference is very small indicating no strong preference for models outside our prior range .",
    "when we add in the planck prior on @xmath188 we find a larger difference in the @xmath5 and @xmath187 constraints than for the mocks , though the value of @xmath5 does not shift by more than we would expect based on the statistical errors , and as we do not believe this prior to be adding in any bias to our results from our tests on the mocks , this change is purely statistically driven . before adding in the @xmath249 prior the measured values of @xmath187 are lower than we would expect , but this value increases by @xmath250 when this prior is included .",
    "it is this change in the mean recovered value of @xmath187 which causes the slight change in @xmath5 .",
    "the reason for the underestimation of @xmath187 is as mentioned previously ; without this prior helping to constrain @xmath188 we overestimate @xmath142 and hence underestimate @xmath187 . for this",
    "prior we find @xmath251 , which is again a slight increase compared to the fits with only the @xmath164 prior , however for all three cases with different priors the recovered @xmath84 values for our model are very reasonable .",
    "our fiducial fitting case including both @xmath164 and @xmath188 priors is shown in fig .",
    "[ rsdmc2d ] , where we plot the 2-d redshift space correlation function of our data along with the maximum likelihood model . in fig .",
    "[ rsdmccontour ] , we also plot the recovered @xmath187@xmath5 contour for our fiducial fitting case , alongside the marginalised 1d histograms for these parameters . here",
    "we can see the strong degeneracy between @xmath5 and @xmath187 that drives the small variations we see in our mean values when fitting to both the data and the average of the mocks .",
    "when we change the fitting range or the bin size , we see similar results as for our fiducial case , and as with the average of the mocks there is no indication that our fitting choices are creating biased results . as for the average of the mocks removing the smallest scales from our fits reduces our recovered @xmath187 value and increases the error , but the mean @xmath5 remains almost unchanged . for all of our tests of bin width and fitting range",
    ", we find @xmath84 values that are in agreement with our fiducial case and which indicate that all of our fits are good .",
    "the largest @xmath84/dof belongs to the case where we modify our fitting range , where we find @xmath252 for 20 degrees of freedom .",
    "however , this value is still very good and we would expect a worse @xmath253 of the time .    for all our fits to the data it is worth noting that we do seem to fit a slightly lower value for @xmath187 than we would expect based on our hod fits to the mgs data . looking back to fig .",
    "[ xi0mock ] we can see why .",
    "the amplitude of the monopole on the scales @xmath254 , where most of our information on the linear bias comes from , seems to be slightly lower for the data than for our hod fit applied to mocks , though when we include scales above and below this range the mock amplitude is well matched . in our fitting",
    "we are not including scales below @xmath255 , where the mocks and data are in better agreement , and so it is not surprising the data prefers slightly smaller values of @xmath187 .    the final set of fits we perform , fixing @xmath164 and @xmath165 and using a simpler linear model , corroborate our results when fitting to the average of the mocks .",
    "we see that making use of the reasonable assumption that @xmath169 tightens our constraints on @xmath187 and @xmath5 without adding any notable change in the best fit results .",
    "the upper and lower bounds on @xmath5 reduce from @xmath256 and @xmath256 to @xmath257 to @xmath258 respectively .",
    "fixing @xmath164 to different values does change the best fit results slightly too , as was seen in the fits to the mean of the mocks , whilst keeping the errors almost unchanged compared to the fixed @xmath165 case .",
    "this is not a substantial change , though as we do not have strong planck constraints on @xmath164 , as we do for @xmath165 , we conclude that fixing @xmath164 could lead to biased results .",
    "overall , the @xmath84 values we find when fixing @xmath164 and @xmath165 or using a linear model are similar in comparison to using the clpt model and allowing @xmath164 and @xmath165 to vary .",
    "the data is not powerful enough to discriminate between these different models , however from @xcite we do know that we can not expect that a linear model to fully reproduce the rsd signal on the smallest scales that we fit against , where non - linear effects start to dominate , and that when fitting the rsd signal on these small scales the clpt model is a more reliable choice .",
    "we have performed several fits to the mgs data assuming different values for @xmath164 and @xmath165 . here",
    "we provide an overview of those that we quote , those that should be used for further cosmological studies and those that should not .    by fitting the full - shape of the correlation function monopole and quadrupole , and varying @xmath164 and @xmath165",
    ", we find best - fit values of @xmath259 and @xmath260 .",
    "these values make no assumption on the underlying , late - time , cosmology and so we recommend the usage of these for future cosmological constraints . in the following section we will use these results to constrain the growth index , @xmath7 , and",
    "compare this to the prediction from general relativity .",
    "as the 1-d @xmath5 and 3-d @xmath261 and @xmath165 likelihoods can not be well approximated by a gaussian we use the likelihoods themselves to achieve this , rather than just the quoted numbers . for future analyses making use of our results the prepared mcmc samples for this fit",
    "will be made publicly available upon acceptance .",
    "if we assume a @xmath8cdm cosmology , we are able to improve our constraints by fixing @xmath169 yet still allowing @xmath164 to vary . here",
    "we find @xmath262 and @xmath263 .",
    "this is well motivated by the planck data , where we find that , unless we have a late time dark energy model quite different from those commonly assumed , we would expect to detect no deviation from @xmath169 .",
    "as such this measurement is presented as our quoted , fiducial results and should be used for comparison with other @xmath5 results under the @xmath8cdm framework . however",
    ", this result should not be combined with planck data as that would result in effectively double counting the planck constraints .",
    "rather , from figure  [ planckap ] , we can see that combining our publicly available chains with planck data will effectively fix @xmath165 and recover the fiducial results .",
    "from the same figure though we would we not recommend the usage of our results where @xmath164 is not allowed to vary .",
    "in fact , as @xmath164 dilates the whole correlation function , not just the bao peak , and captures the late - time cosmological dependence of the shape of the correlation even on small scales , we would recommend that @xmath164 be allowed to vary for any measurements of the growth of structure .",
    "in this section we compare our measurements of @xmath5 to those from a range of different galaxy surveys and perform a simple consistency test against the prediction of the growth rate from general relativity ( gr ) using the commonly used @xmath7 parameterisation of the growth rate , where @xmath264 is approximated as @xmath265 for gr we have @xmath10 @xcite .",
    "measurements of @xmath5 have been made up to @xmath266 using data from the 2-degree field galaxy redshift ( 2dfgrs ; @xcite ) , 6-degree field galaxy ( 6dfgs ; @xcite ) , sdss - ii luminous red galaxy @xcite , boss @xcite , vvds @xcite and wigglez @xcite surveys among others .",
    "although these measurements were all made using different models of varying complexity and different fitting methods to either the correlation function or power spectrum , they can be roughly grouped into two distinct categories : those that were made assuming a fixed fiducial cosmological model and those that fit the full shape of the galaxy clustering statistics .",
    "the latter simultaneously measures both the rsd and bao signals and as such includes the degeneracy between @xmath5 , @xmath187 and @xmath164 highlighted in section [ sec : fixedepsilon ]    we plot these two sets of measurements separately in fig .",
    "[ fsigma8plot ] . the @xmath267 boss and",
    "four wigglez measurements were calculated with and without the inclusion of the ap effect and we can see that they too find a large difference in the constraints when incorporating this degeneracy into their measurements . alongside these measurements",
    "we also plot the planck-@xmath8cdm predictions for @xmath5 assuming different values for the @xmath7 parameter .",
    "we can see that the majority of the measurements , including our mgs measurements , are in good agreement with the gr prediction .    as a more quantitative consistency test of gr we use the likelihood recovered from our full - fit mcmc analysis to put constraints on @xmath7 itself .",
    "we use our data in combination with the publicly available planck likelihood chains , subsampling these to enforce a prior on @xmath268 .",
    "we importance - sample the planck chain by randomly choosing a value @xmath269 for each point in the chain and evaluating the likelihood for that parameter combination . one caveat , however , is that we have to correct the value of @xmath12 to account for the fact that this also depends on @xmath7 . for each point in the planck chains we have",
    "@xmath270 and @xmath271 , where the later is derived from the cmb power spectrum amplitude assuming gr .",
    "the correct value of @xmath5 is then evaluated by scaling back @xmath12 to a suitably high redshift ( for simplicity we use the redshift of recombination , @xmath272 ) and then scaling both @xmath12 and @xmath268 to our effective redshift using the correct value of @xmath7 .",
    "i.e. , for scale factor @xmath273 , @xmath274 where , @xmath275 @xmath276 @xmath277\\ ] ] and @xmath278     and @xmath268 from the combination of our marginalised @xmath5 and planck likelihoods .",
    "contours correspond to the @xmath201 and @xmath279 confidence intervals of the recovered posterior distribution .",
    "we additionally look at the case where we include the boss - dr11 cmass measurement of the growth rate @xcite . in both cases",
    "we find good agreement with the prediction from gr ( dotted line).,width=317 ]    even though our fiducial @xmath5 measurements use a prior to better constraint @xmath188 and stop the non - linear aspects of the clpt model from straying into non - physical regions of our cosmological parameter space , all of the information on @xmath5 , @xmath164 and @xmath165 comes solely from the amplitude and bao features of the monopole and quadrupole . as such we are able to combine our results with planck data for this consistency test without the risk of double counting the planck measurements .",
    "our subsequent constraints on @xmath7 and @xmath268 are shown in fig .",
    "[ gamma1d ] . here",
    "we also show the joint constraints when including the measurements of @xmath5 from the boss - dr11 cmass sample @xcite . for our simple consistency check",
    "we only include the cmass measurement as the method used to make this measurement is very similar to that used in this work . on top of this",
    ", the boss - dr11 lowz and wigglez measurements do overlap partially in terms of area and redshift distribution with both our measurement and the cmass measurement , so to properly include these would require an accurate computation of the cross correlation between these measurements which is beyond the scope of this work . when combining the mgs result with our planck prior we recover @xmath280 , consistent with gr . with the addition of the cmass measurement we recover @xmath281 , which is also consistent with gr to within @xmath201 .",
    "however it should be noted that in both cases we do find a slight preference for higher values of @xmath7 than would be expected from gr .     and",
    "@xmath268 from the combination of our 3-dimensional , marginalised @xmath5 , @xmath164 and @xmath165 likelihood with the planck likelihood .",
    "contours correspond to the @xmath201 and @xmath279 confidence intervals of the recovered posterior distribution . in both cases",
    "we find good agreement with the prediction from gr ( dotted line ) and a reduction in the uncertainty on @xmath7 , compared to fig .",
    "[ gamma1d ] , when we include the anisotropic bao information from the cmass and mgs measurements.,width=317 ]    we take this one step further and include bao information from our measurement and from the boss - dr11 cmass results as the inclusion of anisotropic distance information helps to better constrain @xmath268 and hence can reduce the uncertainty on our @xmath7 constraints .",
    "we use the 3d @xmath261 and @xmath165 likelihood from our fiducial fits as well as the equivalent constraints from the cmass sample .",
    "the results of this are shown in fig .",
    "[ gamma3d ] where we find @xmath282 with , and @xmath283 without , the inclusion of the cmass measurement",
    ". both of these measurements are consistent with gr to within @xmath201 .",
    "the addition of our mgs @xmath261 and @xmath165 measurements improves the constraints on @xmath7 by @xmath284 compared to the constraints we get on @xmath7 using the cmass measurement alone .",
    "the growth index has also been measured by @xcite , @xcite and @xcite from the combination of boss cmass and planck data .",
    "additionally @xcite use boss lowz data to produce their constraints . in fig .",
    "[ gamma_compare ] we plot our mgs+planck constraint on @xmath7 alongside these other measurements .",
    "we see good consistency between all measurements , even though the methods used to measure the growth rate and anisotropic bao information are very different . in all cases",
    "we also see a slight preference for higher values of @xmath7 , which corresponds to models where gravitational interactions are weaker .",
    "constraints from several independent measurements of the growth rate using combinations of boss cmass ( and in the case of @xcite , boss lowz ) and planck data . for consistency",
    "we plot our mgs+planck only measurement alongside .",
    "we can see good agreement between all independent probes and a somewhat consistent favour for higher values of @xmath7 than would be predicted by gr ( dashed line).,width=317 ]    there exists significant tension ( @xmath285 ) between the @xcite boss cmass measurement of the growth index and the prediction from gr .",
    "an interesting question to ask is whether the addition of our measurements at low redshift helps to alleviate this tension and how this combination of measurements compares to the result presented previously when we combine the mgs and @xcite boss cmass measurements .",
    "the results from these two combinations are also presented in fig .",
    "[ gamma_compare ] , where we find that our measurement brings both combinations towards better agreement with the gr prediction , however there is still a @xmath279 tension between this prediction and the value of @xmath7 recovered when combining our measurements with the @xcite cmass results .",
    "in this paper we have presented measurements of the growth rate of structure at an effective redshift of @xmath4 from fits to the monopole and quadrupole of the correlation function of the sdss data release 7 main galaxy sample ( mgs ) . we have also described the creation of a large ensemble of 1000 simulated galaxy catalogues which enabled both this measurement and the isotropic bao measurements made in paper i , where the sample itself is detailed .",
    "our main results can be summarised as follows :    * we have used a newly developed code picola to generate 500 unique dark matter realisations .",
    "we use the friends - of - friends algorithm to create halos and populate these halos using a hod model fitted to the power spectrum of the mgs .",
    "we find that the resultant 1000 galaxy catalogues are highly accurate , reproducing the observed clustering down to scales less than @xmath286 .",
    "full details of our code picola can be found in howlett et .",
    "( in prep . )",
    "* using these mock catalogues we construct covariance matrices for our two - point clustering measurements and test some of the assumptions made in the bao fits presented in paper i. we find : negligible cross - correlation between mock galaxy catalogues generated from the same dark matter field ; that the method used to generate our random data points introduces no significant systematic effects ; and that we can assume our errors on the power spectrum and correlation function are drawn from an underlying multivariate gaussian distribution .",
    "* we use the clpt model @xcite to fit the monopole and quadrupole of the correlation function .",
    "we use our mock catalogues to test the model for systematic effects and find excellent agreement between the model and the average monopole and quadrupole of the correlation function .",
    "we also perform a series of robustness tests of our method , looking at our choice of priors , fitting range and binsize . in all cases",
    "we see no evidence that our results are biased in any way , with all methods recovering the expected value of @xmath5 for our mock catalogues . * fitting to the mgs data we measure @xmath287 when fitting to the full shape of the correlation function and @xmath288 when assuming no ap effect and fixing @xmath289 .",
    "this assumption is validated by the fact that we expect to detect @xmath289 for any commonly assumed model of the expansion history based on the planck-@xmath8cdm results .",
    "however , we have also shown that even at the low effective redshift of our measurement , and assuming @xmath8cdm , @xmath164 can be expected to vary substantially from that expected for our fiducial cosmology . as such , fixing this to a specific value is not recomended for measurements of the growth of structure . * using our fiducial results to fit the growth index , @xmath7 , we find @xmath280 when including planck data and @xmath281 when also including boss - dr11 cmass measurements of the growth rate .",
    "when we include the additional anisotropic bao from the full fits to the shape of the correlation function our constraints tighten to @xmath290 and @xmath9 respectively , the latter of which is a @xmath291 improvements on the constraints from the cmass and planck measurements alone .",
    "all of our results are fully consistent with the predictions of general relativity , @xmath10 , and the constraints from other measurements at different redshifts .",
    "the mcmc chains used for this analysis will be made publicly available upon acceptance .",
    "ch is grateful for funding from the united kingdom science & technology facilities council ( uk stfc ) .",
    "ajr is thankful for support from university of portsmouth research infrastructure funding .",
    "ls is grateful to the european research council for funding .",
    "wjp acknowledges support from the uk stfc through the consolidated grant st / k0090x/1 , and from the european research council through grants mdepugs , and _",
    "darksurvey_.    mock catalog generation , correlation function and power spectrum calculations , and fitting made use of the facilities and staff of the uk sciama high performance computing cluster supported by the icg , sepnet and the university of portsmouth .",
    "funding for the creation and distribution of the sdss archive has been provided by the alfred p. sloan foundation , the participating institutions , the national aeronautics and space administration , the national science foundation , the u.s .",
    "department of energy , the japanese monbukagakusho , and the max planck society .",
    "the sdss web site is http://www.sdss.org/.    the sdss i and ii is managed by the astrophysical research consortium ( arc ) for the participating institutions .",
    "the participating institutions are the university of chicago , fermilab , the institute for advanced study , the japan participationgroup , johns hopkins university , the korean scientist group , los alamos national laboratory , the max planck institute for astronomy ( mpia ) , the max planck institute for astrophysics ( mpa ) , new mexico state university , the university of pittsburgh , the university of portsmouth , princeton university , the united states naval observatory , and the university of washington ."
  ],
  "abstract_text": [
    "<S> we measure redshift - space distortions ( rsd ) in the two - point correlation function of a sample of @xmath0 spectroscopically identified galaxies with @xmath1 , an epoch where there are currently only limited measurements , from the sloan digital sky survey ( sdss ) data release 7 main galaxy sample . </S>",
    "<S> our sample , which we denote mgs , covers 6,813 deg@xmath2 with an effective redshift @xmath3 and is described in our companion paper ( paper i ) , which concentrates on bao measurements . in order to validate the fitting methods used in both papers , and derive errors , we create and analyse 1000 mock catalogues using a new algorithm called picola to generate accurate dark matter fields . </S>",
    "<S> haloes are then selected using a friends - of - friends algorithm , and populated with galaxies using a halo - occupation distribution fitted to the data . using errors derived from these mocks </S>",
    "<S> , we fit a model to the monopole and quadrupole moments of the mgs correlation function . </S>",
    "<S> if we assume no alcock - paczynski ( ap ) effect ( valid at @xmath4 for any smooth model of the expansion history ) , we measure the amplitude of the velocity field , @xmath5 , at @xmath4 to be @xmath6 </S>",
    "<S> . we also measure @xmath5 including the ap effect . </S>",
    "<S> this latter measurement can be freely combined with recent cosmic microwave background results to constrain the growth index of fluctuations , @xmath7 . assuming a background @xmath8cdm cosmology and combining with current baryon acoustic oscillation data we find @xmath9 , which is consistent with the prediction of general relativity ( @xmath10 ) , though with a slight preference for higher @xmath7 and hence models with weaker gravitational interactions .    </S>",
    "<S> [ firstpage ]    surveys - galaxies : statistics - cosmological parameters - cosmology : observations - large - scale structure of universe </S>"
  ]
}