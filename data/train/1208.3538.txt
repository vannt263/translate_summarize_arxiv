{
  "article_text": [
    "in the classical paradox known as  buridan s ass , \" first posed in the 14th century by jean buridan , an ass is placed midway between a pail of water and a bale of hay .",
    "assuming the donkey prefers the closer object , he theoretically never decides to approach one or the other when placed equidistant between the two @xcite .",
    "this problem can be generalized as a dynamical system in which the donkey is free to roam between the two objects , nevertheless changing his preference before ever actually reaching one or the other . in this formulation ,",
    "the donkey s indecision is modeled by a discrete - state markov process , the state being the donkey s current preference .",
    "the parameters governing this markov process are the probabilities of the donkey switching that preference .",
    "we begin by exploring the mathematical generalization of the classical , two - state paradox with the goal of estimating these parameters .",
    "we consider both method of moments type estimators and likelihood - based estimators to achieve this goal .",
    "we also develop an algorithm that allows us to directly estimate the parameters .",
    "we are interested in the behavior of the system in higher dimensions , so we also consider the donkey in a triangular pen . by adding one more state to the system and extending the problem from one to two dimensions , many of the methods we explore for the donkey on a line become intractable .",
    "nevertheless , our algorithm , which detects the donkey s state at each unit time step , still allows us to measure the parameters of the system . in the absence of measurement noise",
    ", this state detector gives us the most reasonable values for our parameters . in the presence of noise ,",
    "though , the state detector performs poorly .",
    "consequently , we employ methods of denoising the system before applying state detection .",
    "following the setup of buridan s ass , we place the donkey on a line between a pail of water at @xmath0 and a bale of hay at @xmath1 .",
    "we define state 0 as the state in which the donkey is moving towards the pail of water , and state 1 as the state in which the donkey is moving towards the bale of hay . and",
    "is taken to be in state 0 . ]",
    "the donkey slows as he comes closer to either object , so he never actually reaches the water or the hay .",
    "the donkey s movement is modeled by the following differential equations : @xmath2 the constant @xmath3 controls the speed of the donkey .",
    "while the donkey obeys these differential equations in a continuous fashion , we allow him to change state only at unit time steps .",
    "we let @xmath4 be the probability that the donkey switches from state 0 to state 1 at any given time step , and @xmath5 be the probability that the donkey switches from state 1 to state 0 .",
    "these are the parameters we estimate in our mathematical model of buridan s ass .",
    "we assume we know the constant @xmath3 ( even if not known , it is easily measured ) , and we observe only the donkey s position at each of finitely many time steps . notice that the parameters @xmath4 and @xmath5 change with neither time nor the donkey s current state , imparting them the independence that characterizes the stochastic switching of this system as a markov process .",
    "one way to estimate @xmath4 and @xmath5 is the method of moments approach .",
    "the standard method of moments estimation scheme uses moments of measured data , such as mean and variance , to estimate unknown parameters @xcite .",
    "the approach relies on deriving algebraic expressions for these moments in terms of the parameters .",
    "when these expressions are invertible , they give closed - form estimates of parameters in terms of only measured data . furthermore",
    ", this technique can be used with feature statistics such as frequency and cumulative power . since the donkey on a line system has two parameters , we require couplets , or pairs of invertible expressions , to estimate @xmath4 and @xmath6      the probability distribution of the donkey s state at the @xmath7th time step is given by the discrete - state markov chain @xmath8 where @xmath9 and @xmath10 is a vector whose entries are the initial probabilities of the donkey being in either state .",
    "notice that @xmath11 is a column stochastic matrix ( one whose columns each have entries summing to 1 ) .",
    "any such matrix has an eigenvector associated with an eigenvalue of 1 ( see ) .",
    "it is a well - known fact that under certain conditions , @xmath12 finally , an irreducible chain is one in which any state can somehow be reached from any other state . ]",
    ", this eigenvector is unique to make sense as a probability distribution , it must be normalized so that its entries sum to 1 . ] and represents a stable distribution to which any initial distribution vector will converge after repeated applications of . for @xmath13",
    "this eigenvector is @xmath14   \\dfrac{\\tau_{01}}{\\tau_{01}+\\tau_{10 } } \\end{bmatrix}.\\end{aligned}\\ ] ] this vector shows that the expected proportion of time the donkey spends in state 0 is @xmath15 , and the expected proportion of time he spends in state 1 is @xmath16 these proportions motivate the conditional probability tree in .",
    "child node[bag ] state @xmath17 child node[end , label = right : state 1  @xmath18 edge from parent node[above ] node[below ] @xmath19 child node[end , label = right : state 0  @xmath20 edge from parent node[above ] @xmath5 node[below ] edge from parent node[above ] node[below ] @xmath21 child node[bag ] state @xmath22 child node[end , label = right : state 1  @xmath20 edge from parent node[above ] node[below ] @xmath4 child node[end , label = right : state 0  @xmath23 edge from parent node[above ] @xmath24 node[below ] edge from parent node[above ] @xmath25 node[below ] ;    the first two branches of the tree show the marginal probabilities of the donkey being in either state , as given by the eigenvector @xmath26 the second layer of branches identifies the conditional probabilities of the donkey staying in his current state or transitioning to the other .",
    "these probabilities come simply from the problem s construction . by the independence of the markov chain , we can multiply connected branches to produce the final , joint probabilities of the tree .",
    "for example , the probability of the donkey being in state 0 and then switching to state 1 is @xmath27 .",
    "notice this is equal to the probability of the donkey being in state 1 and then switching to state 0 .",
    "therefore , we define our frequency of transition as @xmath28 we may think of @xmath29 as the probability of observing some state transition at a given time step .",
    "this is our first statistic for use in a method of moments couplet .",
    "although the donkey s state is discrete , his position is continuous in both space and time .",
    "we let @xmath30 be the probability density of the donkey s position , @xmath31 , at time @xmath32 note that for fixed @xmath33 , @xmath30 is a probability density of one variable .",
    "furthermore , since the donkey can not simultaneously be in both states , we can express @xmath34 as the sum of state - dependent , conditional probabilities , and @xmath35 as probabilities , we do not mean that their integrals over their support equal 1 , but rather that they sum to a valid probability density function .",
    "if properly normalized , @xmath36 and @xmath35 would be the probability densities of the donkey s position given his being in state 0 or state 1 , respectively . ]",
    "@xmath37 and @xmath38 : @xmath39 over time , the probability associated with state 0 is advected towards 0 and the probability associated with state 1 is advected towards 1 .",
    "probability is also transferred among states by the switching probabilities , @xmath4 and @xmath5 .",
    "these changes in probability density are captured by the conservation conditions @xmath40 - \\tau_{01}{p}_{0}(x , t ) + \\tau_{10}{p}_{1}(x , t ) \\label{eq : cc1}\\\\ \\frac{\\partial{p_{1}}}{\\partial{t } } & = -\\frac{\\partial}{\\partial{x}}\\left[v\\left(1-x\\right)p_{1}(x , t)\\right ] + \\tau_{01}{p}_{0}(x , t ) - \\tau_{10}{p}_{1}(x , t ) .",
    "\\label{eq : cc2}\\end{aligned}\\ ] ]    we are interested in the long term behavior of the system , and thus we look for time - invariant steady - state solutions .",
    "that is , we examine the case in which @xmath41 and we can , therefore , drop the dependence of @xmath36 and @xmath35 on @xmath32 furthermore , we anticipate that in a steady - state solution , total fluxes are balanced : @xmath42 the steady - state condition in state 1 is now @xmath43 + \\tau_{01}\\frac{1-x}{x}p_{1}(x ) - \\tau_{10}{p}_{1}(x ) .",
    "\\label{eq : prederiv}\\end{aligned}\\ ] ] applying the derivative operator in and rearranging terms , we have @xmath44 this is a separable first - order ordinary differential equation . using separation of variables we get @xmath45\\partial{x } \\\\",
    "\\ln\\left(p_{1}(x)\\right ) & = \\frac{\\tau_{01}}{v}\\ln\\left(x\\right ) + \\frac{\\tau_{10}}{v}\\ln\\left(1-x\\right ) - \\ln\\left(1-x\\right ) + k \\\\",
    "p_{1}(x ) & = cx^{\\frac{\\tau_{01}}{v}}\\left(1-x\\right)^{\\frac{\\tau_{10}}{v}-1}.\\end{aligned}\\ ] ] substituting @xmath46 into , we find that @xmath47 we then combine @xmath36 and @xmath35 , yielding the probability distribution @xmath48 thus , the constant @xmath49 where @xmath50 this makes @xmath51 a beta probability distribution @xcite with parameters @xmath52 and @xmath53 the first two moments of @xmath51 are thus @xmath54 and @xmath55 the mean , @xmath56 and the variance , @xmath57 provide two more statistics with which to form couplets .",
    "a final statistic we examine is cumulative power . for a twice differentiable signal @xmath58 and finite @xmath33 , cumulative power , @xmath59 ,",
    "is defined as @xmath60 cumulative power has been shown to be @xmath61 for any @xmath62 that is a finite sum of sine and cosine functions . moreover , the average derivative of @xmath59 for such an @xmath62 is pivotal with respect to the frequency and the amplitude of @xmath62 @xcite .",
    "thus , measurements of the rate of growth in @xmath59 ( with respect to time ) can provide statistics amenable to method of moments type estimators .    in the donkey on a line system",
    ", we take @xmath62 to be the donkey s position , @xmath31 .",
    "although @xmath31 is not a periodic function , we derive a similar condition to the above for its cumulative power .",
    "first , however , we must adjust the definition to account for the times @xmath63 at which @xmath31 is not twice differentiable .",
    "we note that @xmath63 are the times at which the donkey changes state . from here on , we redefine the cumulative power of @xmath31 as @xmath64 where @xmath65 in , @xmath59 is shown to be @xmath66 .",
    "anticipating , then , that @xmath67 can be approximated by a line , we look to obtain another statistic for use in the method of moments approach : the expected value of @xmath68 in terms of @xmath4 and @xmath6 in carrying out the calculation , we employ the gamma function @xmath69 defineddenotes the set of positive real numbers . the gamma function can also be defined for complex numbers with positive real part @xcite . ] by @xmath70 two useful properties of the gamma function @xcite are @xmath71 from , we easily obtain the identity @xmath72    now beginning our derivation of the expected value of @xmath73 , in state 0 we have @xmath74^{2}=(v^{2}x)^{2}=v^{4}x^{2 } , \\label{eq : power1}\\end{aligned}\\ ] ] and in state 1 we have @xmath75^{2}=\\bigl(v^{2}(x-1)\\bigr)^{2}=v^{4}(1-x)^{2}. \\label{eq : power2}\\end{aligned}\\ ] ] let @xmath76 be the donkey s current state . from and , it is clear that @xmath73 is conditional upon the donkey s current position and state .",
    "the expectation for @xmath73 , therefore , is found by averaging @xmath73 over all possible position and state combinations .",
    "the likelihood of observing any one of these combinations is conditional upon the parameters @xmath4 and @xmath6 more formally , @xmath77 } & = \\int_{0}^{1}\\big[v^{4}x^{2}{\\pr\\left(x | z=0,\\tau_{01},\\tau_{10}\\right)}{\\pr\\left(z=0 | \\tau_{01},\\tau_{10}\\right)}\\\\ & \\phantom{=\\int_0 ^ 1\\big[}+v^{4}\\left(1-x\\right)^{2}{\\pr\\left(x | z=1,\\tau_{01},\\tau_{10}\\right)}{\\pr\\left(z = 1 | \\tau_{01},\\tau_{10}\\right)}\\big ] dx . \\label{eq : int1 } \\end{split}\\end{aligned}\\ ] ]    for ease of notation , we denote @xmath78}.$ ] substituting known probabilities and probability densities , becomes @xmath79 .",
    "\\end{split}\\end{aligned}\\ ] ] we can multiply by fractions equal to 1 : @xmath80 . \\end{split } \\label{eq : ugly1}\\end{aligned}\\ ] ] factoring out certain constants in we get @xmath81",
    ". \\end{split } \\label{eq : ugly2}\\end{aligned}\\ ] ] recognizing that the integrals in are of densities taken over their support and are thus equal to 1 , we are left with @xmath82 .",
    "\\label{eq : ugly3}\\end{aligned}\\ ] ] applying to the first term of the right - hand side of yields @xmath83 now , by applying to we have @xmath84 a similar computation on the second term of the right - hand side of yields @xmath85 now , substituting and into , we have @xmath86}\\bigg ] .",
    "\\label{eq : final1 }          \\end{aligned}\\ ] ] finally , simplifying gives @xmath87 \\\\          & = \\frac{v^{4}\\tau_{01}\\tau_{10}}{(\\tau_{01}+\\tau_{10})(\\tau_{01}+\\tau_{10}+v)}.          \\end{aligned}\\ ] ] therefore , the average slope of the cumulative power of @xmath31 is @xmath88 giving us our final statistic for use in a couplet .",
    "now we have derived closed - form expressions for mean , variance , frequency , and the average slope of cumulative power , in terms of @xmath4 and @xmath6 the method of moments approach demands , however , that each of these statistics can be measured given the data . for mean and variance , this is clearly possible .",
    "measuring frequency , though , requires accurate detection of state transitions . finally , cumulative power is perhaps the most difficult to measure , as it requires knowledge of the donkey s state at all time steps . in",
    "the following simulations , we ignore these issues as to identify which couplets perform most effectively . that is , we assume we have perfect measurements of the four chosen statistics .    to complete our method of moments approach , we find invertible couplets of our closed - form expressions . examining the equation for each statistic ( , , , and ) , we find that each one is symmetric with respect to @xmath4 and @xmath89 with the exception of the mean , @xmath90 this implies that any invertible couplet will include the mean .",
    "for example , inverting the equations for mean , @xmath91 , and frequency , @xmath92 , we find    [ eq : mf ] @xmath93    inverting the equations for mean and variance , @xmath94 , we obtain    [ eq : mv ] @xmath95    finally , inverting the equations for mean and average cumulative power slope , + @xmath96 , we find    [ eq : ms ] @xmath97    each of these couplet inversions vary in accuracy and precision , depending on the true values of @xmath4 and @xmath6 for instance , shows how well the mean and frequency couplet performs for different pairs of @xmath4 and @xmath6 the surfaces shown were generated by running twenty simulations of donkey on a line , each one for 20,000 time steps , for every pair of parameters .",
    "there were 361 total pairs , created by meshing grids of 19 equally spaced points from 0.01 to 0.1 . in each diagram",
    ", the vertical axis identifies the average absolute error seen in the estimates and .",
    "we can see that estimates improve as @xmath4 and @xmath5 both approach zero .",
    "similar behavior was observed for the couplets and .",
    "next we compare the different couplets to one another .",
    "shows boxplots of the residuals for the estimators , , and .",
    "these boxplots were generated in the same manner as the results of , except simulations were run with a varying number of total time steps .",
    "as the number of observed time steps increases , estimates become more accurate .",
    "this is due to the law of large numbers : as the donkey takes more steps , his observable statistics  mean , variance , frequency , and cumulative power , in our case  approach their theoretical values , improving the accuracy of the inverted couplets .",
    "based on these boxplots , the mean and frequency couplet produces , on average , the best estimates of @xmath4 and @xmath5 .",
    "the median residual ( shown as the middle , red line ) appears to converge to zero quickly , and the interquartile range ( the vertical distance between the two blue lines ) is narrow even for a small number of time steps .",
    "these qualities indicate that the mean and frequency couplet is a more efficient and less biased estimator of @xmath4 and @xmath5 than the other two couplets .",
    "another method of parameter estimation takes a likelihood - based approach .",
    "this approach involves calculating a function , @xmath98 , that measures the likelihood of the observed data matching the parameters @xmath99 and @xmath100 .",
    "one such function is the log - likelihood function .",
    "given a set of data , the log - likelihood function evaluates the beta probability density function @xmath101 at the observed data ( the donkey s observed positions ) .",
    "the function then takes the log of each result and sums these new results .",
    "ideally , when this process is performed with the true @xmath4 and @xmath89 the majority of data is concentrated in areas of high density , so that @xmath102 is maximized at @xmath103 to make this maximum a minimum , we examine @xmath104 instead of @xmath105 the estimates for @xmath4 and @xmath5 are taken to be the location of this minimum .",
    "for example , graphs the negative log - likelihood function given a simulation of donkey on a line with 10,000 time steps .",
    "the input parameters were @xmath106 and @xmath107 with @xmath108 the minimum of the negative log - likelihood function , shown in as a blue dot , is located at @xmath109 and @xmath110 thus , estimation errors are quite low . and as with couplet inversion , this likelihood - based technique benefits from greater observation time .",
    ", scaledwidth=60.0% ]      while method of moments type estimators and likelihood - based estimators provide reasonable estimates for @xmath4 and @xmath5 , we are , in fact , able to calculate these parameters directly from our data . by comparing two consecutive positions of the donkey , we have a vector that points in the direction the donkey is moving .",
    "if the donkey s position is increasing , we know he is in state 1 .",
    "by contrast , if the donkey s position is decreasing , we know he is in state 0 . by dividing the number of time steps",
    "that the donkey changes from state 0 to state 1 by the number of time steps the donkey spends in state 0 , we have our result for @xmath4 . a similar computation yields @xmath5 .",
    "this state detection technique provides the actual , observed values of @xmath4 and @xmath5 . because of the stochastic nature of the system",
    ", we do not expect these measured values to exactly match our input values . nevertheless , by the law of large numbers , a greater number of observed time steps should lend measured values closer to the input values .",
    "affirms this expectation .",
    ".comparison of input and observed values for @xmath111 [ cols=\"^,^,^,^ \" , ]     [ tab : joseph ]    we are lead to the following conjecture .",
    "[ conj : joseph ] if @xmath11 is the @xmath112 matrix given by , then each coordinate of the eigenvector @xmath113 given by , when expressed in terms of the various @xmath114 is the sum of @xmath115 monomials , each with coefficient 1 .",
    "if this conjecture is true , a derivation may proceed as follows .",
    "we let @xmath116 be the number of monomials in a coordinate of @xmath117 the number we conjecture is equal to @xmath118 let @xmath119 as in .",
    "as prescribed by , to compute the @xmath120th entry of @xmath117 we must calculate @xmath121 to do so , we will use the leibniz formula @xcite , presented here for a general matrix @xmath122 : @xmath123 where @xmath124 is the symmetric group on @xmath7 elements , and @xmath125 denotes an entry in @xmath126    in applying this formula , for example , to @xmath127 we notice that    1 .",
    "each term in the sum of is a product of @xmath128 entries of @xmath129 exactly one from each row and column . 2 .",
    "in a particular summand of , the sign of each monomial produced is the same and is determined by two things .",
    "first , each diagonal entry in the product forming the monomial contributes a power of @xmath130 second , the signum of the permutation involved could contribute an additional factor of @xmath130 3 .",
    "diagonal entries being involved in a particular summand of is equivalent to the permutation involved having a fixed point .",
    "4 .   the number of diagonal entries involved in a particular summand of determines how many monomials the summand contains .",
    "in particular , if @xmath131 denotes the number of fixed points of the permutation @xmath132 then the associated summand will contain @xmath133 monomials .",
    "the assumption we now make , albeit possibly incorrect , is that monomials of opposite sign will cancel to leave only monomials with identical sign . in this case , the four observations above imply @xmath134 the factor of @xmath135 in ensures @xmath116 is always positive .",
    "if @xmath7 is even , then the monomials comprising @xmath117 as determined by , have negative coefficients .",
    "this fact is seen by noting that the majority of monomials come from the summand associated with the identity permutation ",
    "the summand in that multiplies all diagonal elements .",
    "since the identity permutation has positive signum , the sign of the monomials in this summand is entirely determined by @xmath7 .",
    "if @xmath7 is even , then @xmath128 is odd , so the sign of these monomials is @xmath136 as there are @xmath128 diagonal entries",
    ".    provided our assumption is correct , proving is now reduced to showing the right - hand side of is equal to @xmath118 the sum in may be easier to manipulate if permutations were grouped by cycle structure .      in @xcite",
    ", the author shows that , for finite sums of sines and cosines , cumulative power is @xmath66 .",
    "here we prove the same growth relationship for the cumulative power of the donkey s position , @xmath31 , in the one - dimensional case .",
    "if @xmath31 obeys and and switches between the two states by the markov process , then its cumulative power is @xmath66 .",
    "notice from and that @xmath137 since @xmath138 for all time @xmath139 under the assumption @xmath140 .",
    "thus , we have @xmath141 \\\\ & = v^4 t , \\label{eq : proof}\\end{aligned}\\ ] ] for all time @xmath32 since @xmath142 is constant and cumulative power @xmath59 is always positive , shows @xmath143 .",
    "this work was completed as part of the summer undergraduate research institute in experimental mathematics ( suriem ) at the lyman briggs college of michigan state university .",
    "we thank the sponsorship of the national security agency and the national science foundation in funding this reu program .",
    "we thank professor daniel p.  dougherty for his mentorship , as well as joseph e.  roth for his assistance .",
    "we also wish to credit mr .",
    "roth for his observations leading to ."
  ],
  "abstract_text": [
    "<S> the buridan s ass paradox is characterized by perpetual indecision between two states , which are never attained . </S>",
    "<S> when this problem is formulated as a dynamical system , indecision is modeled by a discrete - state markov process determined by the system s unknown parameters . </S>",
    "<S> interest lies in estimating these parameters from a limited number of observations . </S>",
    "<S> we compare estimation methods and examine how well each can be generalized to multi - dimensional extensions of this system . by quantifying statistics such as mean , variance , frequency , and cumulative power , </S>",
    "<S> we construct both method of moments type estimators and likelihood - based estimators . </S>",
    "<S> we show , however , why these techniques become intractable in higher dimensions , and thus develop a geometric approach to reveal the parameters underlying the markov process . </S>",
    "<S> we also examine the robustness of this method to the presence of noise . </S>"
  ]
}