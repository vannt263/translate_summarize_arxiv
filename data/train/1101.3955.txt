{
  "article_text": [
    "lisa ( laser interferometer space antenna ) is a joint esa / nasa space mission aimed at detecting low frequency gravitational waves , in the range between 10@xmath0hz and 1hz .",
    "lisa will be a constellation of three spacecraft which occupy the vertexes of an equilateral triangle , with sides of 5 million kilometers .",
    "the barycenter of the constellation will revolve around the sun in a quasi circular orbit , inclined 1@xmath1 with respect to the ecliptic , and trailing the earth by some 20@xmath1 , about 45 million kilometres .",
    "each spacecraft harbors two proof masses , carefully protected against external disturbances such as solar radiation pressure and charged particles , which ensures they are in nominal free - fall in the interplanetary gravitational field .",
    "gravitational waves show up as differential accelerations between pairs of proof masses in distant spacecrafts , and the working principle of lisa is to measure such accelerations using picometer precision laser interferometry .",
    "the interested reader is referred to references  @xcite and  @xcite for more extensive information , as well as to the lisa international science team ( list ) webpage  @xcite .",
    "the technologies required for the lisa mission are many and very challenging .",
    "this , coupled with the fact that some flight hardware can not be tested on ground since free fall conditions can not be maintained during periods of hours , led to set up a technology demonstrator to test critical lisa technologies in a flight environment .",
    "these technologies will be tested in a precursor mission , which is called lisa pathfinder ( lpf ) .",
    "this mission is framed within the scientific program of esa , and it is expected to be launched towards early 2012 . the idea of lpf is to squeeze one lisa arm from five million kilometers to 35 centimeters , then determine the noise of the measurements in a frequency range which is slightly less demanding than that of lisa .",
    "more specifically , the requirement is formulated in terms of spectral density of acceleration noise as @xmath2\\    { \\rm m\\,s}^{-2}\\,{\\rm hz}^{-1/2 }   \\label{eq.0}\\ ] ] for 1mhz@xmath3@xmath4@xmath330mhz , where @xmath4 is the frequency in hz .",
    "the payload on board lpf is called the lisa technology package ( ltp )  @xcite .",
    "its main components are the two gravitational reference sensors , which are the two large vertical cylinders in figure  [ fig : ltp ] . in this figure",
    "it can also be seen the optical metrology subsystem , which provides picometer precision measurements of the relative position and acceleration of the two test masses , using precise interferometry .",
    "this system is located between the two gravitational reference sensors . also visible , and specially relevant here , are the four tri - axial magnetometers , which are represented as floating boxes .",
    "their actual physical support is the lateral wall of a ( not drawn ) larger cylinder which encloses the entire ltp .",
    "magnetic noise in the ltp is required to be not more than 40% of the total readout noise , i.e. , @xmath5ms@xmath6hz@xmath7 out of @xmath8ms@xmath6hz@xmath7 in the measurement bandwidth , see eq .",
    "( [ eq.0 ] ) .",
    "this noise appears because the residual magnetization and susceptibility of the test masses couple with the surrounding magnetic field , giving rise to a force in each of them @xmath9{\\bf b}\\right\\rangle v.   \\label{eq.1}\\ ] ] in this expression * b * is the magnetic field in the test mass , * m * is its density of magnetic moment ( magnetization ) , @xmath10 is the volume of the test mass , @xmath11 is its magnetic susceptibility , @xmath12 is the vacuum magnetic constant ( @xmath13 m kg s@xmath6 a@xmath6 ) , and @xmath14 indicates the volume average of the enclosed quantity . as clearly seen from eq .",
    "( [ eq.1 ] ) , there are two sources of magnetic noise .",
    "the first one is due to the fluctuations of the magnetic field and its gradient in the regions occupied by the test masses @xcite .",
    "the second one comes from the susceptibility of the test mass and the magnetic remanence fluctuations  @xcite .",
    "this additional noise is expected to be much less important , and it is usually disregarded .    clearly , a quantitative assessment of magnetic noise in the ltp requires real - time monitoring of the magnetic field and its gradient  @xcite .",
    "this is the ultimate goal of the tri - axial fluxgate magnetometers  @xcite .",
    "these devices have a high permeability magnetic core , which drives a design constraint to keep them somewhat far from the test masses .",
    "thus , their readouts do not provide a direct measurement of the magnetic field at the position of the test masses , complicating the task of inferring the field at their position , and forcing the implementation of an interpolation method to overcome this shortcoming .",
    "however , such interpolation process faces serious difficulties .",
    "indeed , the size of the interpolation region , that is , the interior of the ltp core assembly ( lca ) , is too large for a linear interpolation scheme to be reliable .",
    "additionally , the number of magnetometer channels does not provide sufficient data to go beyond a poor linear approximation @xcite .",
    "however , the structure of the magnetic field is rather complex , as the sources of magnetic field are essentially the electronic components inside the spacecraft .",
    "the number of identified sources is about 50 , and they behave as magnetic dipoles , the only exception being the solar panel , which is best approximated by a quadrupole .",
    "the positions of the sources are dictated by the architecture of the satellite , which defines the exact position of each electronic subsystem .",
    "fortunately , there are no sources of magnetic field inside the lca , all being placed within the spacecraft , but outside the lca walls .",
    "adequate processing of all the available information shows that the magnetic field is smaller towards the center of the spacecraft ( where the test masses are located ) than it is in its periphery ( where the magnetometers take measurements ) .",
    "it has been recently shown @xcite that since the standard interpolation scheme , which is based in multipole expansion of the magnetic field inside the lca volume , does not go beyond quadrupole order , its performance in estimating the magnetic field and its gradients is very poor .",
    "on the contrary , artificial neural networks have been shown to be a reliable alternative to estimate the required field and gradient values at the positions of the test masses .",
    "the reasons for this are multiple .",
    "firstly , the multipole expansion only takes into account the readings of the magnetometers , whereas the artificial neural network also uses the actual value of the magnetic field at the position of the test masses to train the network .",
    "this is a crucial issue since the interpolation algorithm is fed with additional information .",
    "secondly , the classical interpolation method seeks for a global solution of the magnetic field .",
    "that is , the multipole expansion models the magnetic field inside the entire volume of the lca .",
    "clearly , since the available information for the multipole expansion is rather limited , the quality of the global solution is very poor . in sharp contrast",
    ", the artificial neural network first finds and then uses the correlation between the magnetic field at the positions of the magnetometers and the test masses to obtain reliable values of the magnetic field for any magnetic configuration . as a matter of fact",
    ", the artificial neural network performs a point - to - point interpolation and it is not aimed at reproducing the highly non - linear magnetic field well at any arbitrary position within the volume of the lca .",
    "finally , artificial neural networks are trained using a large number of magnetic field realizations , thus the interpolating algorithm uses a statiscally elaborated information . in this sense , it is important to realize that artificial neural networks have been shown to be a robust and easily implementable technique among numerous statistical modeling tools @xcite . on the contrary ,",
    "the multipole expansion does not use statistical information .",
    "once the readings of the magnetometers are known , the theoretical solution for the magnetic field within the entire volume of the lca is determined in a straightforward way .",
    "nevertheless , an in depth study of how the results of the interpolation procedure depend on the specific characteristics of the neural network remains to be done .",
    "it also remains to further investigate why the neural network  which uses lineal transfer functions  obtains such good results interpolating the value of the magnetic field at the positions of the test masses , which are well inside a deep well of magnetic field .",
    "finally , an assessment of the robustness of the neural network interpolating scheme in front of the unavoidable errors in the positions of the magnetometers , or in front of low - frequency variations of the magnetic environment and , more importantly , in front of offsets in the readings of the magnetometers still is needed .",
    "these are precisely the goals of this paper .",
    "the paper is organized as follows . in sect .",
    "[ chap.2 ] we discuss the appropriateness of our neural network approach to measure the magnetic field and its gradients at the positions of the test masses , and we discuss which are the accuracies obtained when different architectures of the neural network are adopted .",
    "it follows sect .",
    "[ chap.3 ] , where we discuss how the unavoidable errors in the onground measurements of the magnetic dipoles of each electronic box affect the performance of the adopted neural network . in sect .",
    "[ chap.4 ] we evaluate the expected errors in the estimate of the magnetic field and its gradients due to a possible offset in the readings of the magnetometers due to launch stresses , whereas in sect .",
    "[ chap.5 ] we study how the mechanical precision of the positions of the tri - axial magnetometers and their spatial resolution affect the determination of the magnetic field and its gradients .",
    "[ chap.6 ] is devoted to assess the reliability of our neural network approach in front of a slowly varying magnetic environment . finally , in sect .",
    "[ chap.7 ] we summarize our main findings , we discuss the significance of our results and we draw our conclusions .",
    "although neural networks have been used in different space applications @xcite , to the best of our knowledge this is the first application of neural networks to analyze inflight outputs in space missions .",
    "hence , studying the robustness of the neural network architecture proposed to estimate the magnetic field inside the lca is a mandatory task .",
    "[ fig : neuralarquitecture ] shows a simplified version of the fiducial architecture of our neural network . as can be seen",
    ", the number of inputs is twelve  one for each magnetometer readout  corresponding to the four tri - axial magnetometers placed in the spacecraft .",
    "these readings are the only valuable information which can be used to estimate the magnetic field at the positions of the test masses , and constitute the input layer of the neural network . on the other hand , to estimate the magnetic field three outputs will be required  corresponding to the three field components per test mass  whereas to estimate the gradient only five additional outputs are needed .",
    "this is because the magnetic field has zero divergence and zero rotational .",
    "thus , the gradient matrix @xmath15 is a traceless symmetric matrix , and therefore only 5 out of its 9 components are independent .",
    "these outputs are the output layer of the neural network .",
    "in addition to the two previously described layers , there is only one intermediate layer , which constitutes the hidden layer .",
    "this layer is made of 15 neurons . using this architecture for the neural network",
    "the magnetic field estimates typically have standard deviations on the order of @xmath16 @xcite , a value to which we compare the results of our analysis .",
    "training and testing data sets were simulated using the most complete and up - to - date information about the magnetic configuration within the spacecraft .",
    "the complete magnetic configuration of the satellite has not been measured yet , because some units have not been delivered yet to the prime contractor . nevertheless , the exact position of each unit in the spacecraft reference frame is known . on the other hand ,",
    "the magnetic moments used in our simulations are those reported by the constructors of each subsystem .",
    "unfortunately , this data is not available yet for all units , and moreover although the moduli of the dipoles are known for all the subsystems their directions are not known yet for most of the units .",
    "the three - dimensional values of the magnetic dipoles of each unit will be accurately measured in the final testing campaign to be performed on each subsystem before assembling .",
    "this campaign is expected to be performed on the assembled spacecraft during 2011 .",
    "the training and validation of the neural network using the measured values of the magnetic dipoles will be done after the campaign but the specific details of the processing algorithm are expected to remain unchanged . moreover",
    ", the magnetic field inside the lca is expected to vary substantially between the different operational modes . accordingly , since the magnetic configuration of the spacecraft may have different characteristics for different operational modes , it is foreseen that a different neural network will be trained for each of these configurations .",
    "given the unknown orientations of the magnetic dipoles we generate several magnetic configurations assigning randomly the orientations of the 46 dipoles .",
    "an example scenario is thus characterized by a selection of the 46 dipoles with random orientations .",
    "the random character of the procedure may seem unrealistic , since the actual satellite configuration is not random . in this context",
    ", however , randomness is an efficient way of mimicking our lack of knowledge of all the directions of the sources of magnetic field .",
    "nevertheless , it is worth mentioning that the produced sets are consistent with our expectations and the mission requirements @xcite since at the positions of the test masses we obtain magnetic fields @xmath17 nt , while the readings at the magnetometers are of the order of 4 to 10 @xmath18 t . with this approach the magnetic field generated by the dipole distribution at a generic point * x * and time @xmath19",
    "is therefore given by @xmath20\\,{\\bf n}_a -       { \\bf m}_a(t)}{\\left|{\\bf x}-{\\bf x}_a\\right|^3 }      \\label{eq.15}\\ ] ] where * n*@xmath21= @xmath22/@xmath23 are unit vectors connecting the the @xmath24-th dipole * m*@xmath21 with the field point * x * , and @xmath25 is the number of dipoles . in order to simulate realistic magnetic environments , we compute the magnetic field at the positions of the magnetometers and at the positions of the test masses using eq .",
    "( [ eq.15 ] ) .",
    "the positions of the test masses and of the magnetometers are shown in table [ tab : positions ] .",
    "two different batches of @xmath26 samples are generated .",
    "the first batch was used as the training set for a neural network with the architecture of fig .",
    "[ fig : neuralarquitecture ] .",
    "this batch consists in 12 inputs ( 3 inputs for each of the 4 vector magnetometers ) and 16 outputs representing the field information at the position of the two test masses ( 3 field plus 5 gradient components per test mass ) .",
    "the second batch has been used for validation to assess the performance of the neural network .",
    "l r r r test masses & @xmath27 [ m ] & @xmath28 [ m ] & @xmath29 [ m ] + 1 & @xmath300.1880 & 0 & 0.4784 + 2 & 0.1880 & 0 & 0.4784 + magnetometers & @xmath27 [ m ] & @xmath28 [ m ] & @xmath29 [ m ] + 1 & @xmath300.0758 & 0.3694 & 0.4784 + 2 & @xmath300.3765 & 0 & 0.4784 + 3 & 0.0758 & @xmath300.3694 & 0.4784 + 4 & 0.3765 & 0 & 0.4784 +       neurons in the hidden layer .",
    "the solid line corresponds to the @xmath31-component , the dotted line to the @xmath32-component and , the dashed line to the @xmath33-component.,title=\"fig:\",scaledwidth=90.0% ]   neurons in the hidden layer .",
    "the solid line corresponds to the @xmath31-component , the dotted line to the @xmath32-component and , the dashed line to the @xmath33-component.,title=\"fig:\",scaledwidth=90.0% ]    assesing the correct choice of the number of neurons of a neural network is not a simple task .",
    "when the neural network is composed by only one hidden layer , the input layer contains as many inputs - neurons as the information we provide to the network and as many output - neurons as the target information we want to reconstruct .",
    "nevertheless , as far as the number of neurons of the hidden layer is concerned , it is not guaranteed that the architecture of the selected neural network is optimal nor there is an algorithm in the current literature to determine the optimal number of neurons  @xcite . normally , to obtain good results , the smallest system obtained after prunning that is capable to fit the data should be used .",
    "unfortunately , it is not obvious what size is best",
    ". a system with a small number of neurons will not be able to learn from the data , while one with a large number of neurons may learn very slowly and , moreover , it will be very sensitive to the initial conditions and learning paramaters .",
    "additionally , it should be taken into account that one of the biggest problems of large networks for some specific problems is the fact that in the early stages of training , the error on both the training and tests tends to decrease with time as the network generalizes for the examples to the underlying function .",
    "however , at some point , the error on the testing set reaches a minimum and begins to increase again as the network starts to adapt to artifacts and specific details in the training data , while the training error asymptotically decreases .",
    "this problem , known as overfitting , occurs more frequently in large networks due to the excessive number of degrees of freedom in comparison to the training set @xcite . to avoid this ,",
    "we have used the early stopping technique , which overcomes this shortcoming .    in the early stopping technique",
    "the available data is divided into three subsets @xcite .",
    "the first subset is the training set , which is used for computing the gradient and updating the network weights and biases .",
    "the second subset is the validation set .",
    "the error on the validation set is monitored during the training process .",
    "the validation error normally decreases during the initial phase of training , as does the training set error .",
    "however , when the network begins to overfit the data , the error on the validation set typically begins to rise .",
    "when the validation error increases for a specified number of iterations , the training is stopped , and the weights and biases at the minimum of the validation error are returned to the values obtained at the minimum .",
    "all these precautionary measures avoid overfitting .",
    "therefore , the analysis of the number of neurons needed for the hidden layer can be made analyzing the evolution of the estimation error on the testing set as the number of neurons increases .",
    "the results of such an analysis are depicted in figure  [ fig : numberneuronsfield ] , which shows the standard deviation of the estimate for both test mass 1 , @xmath34 , and test masss 2 , @xmath35 as a function of the number of neurons in the hidden layer , @xmath36 .",
    "lcccccc & & + function & @xmath37 & @xmath38 & @xmath39 & @xmath37 & @xmath38 & @xmath39 + tangent sigmoid & 4.1 & 3.8 & 2.5 & 5.9 & 5.2 & 4.5 + linear & 3.8 & 3.5 & 2.3 & 5.7 & 5.4 & 4.2 + logarithmic sigmoid & 4.2 & 3.8 & 2.5 & 6.2 & 5.1 & 4.5 + radial base & 4.2 & 4.3 & 3.9 & 6.3 & 6.0 & 4.8 + step & 7.5 & 7.6 & 4.9 & 12.3 & 8.2 & 7.9 +    as can be seen in this figure , when a reduced number of neurons is used the model can not accurately estimate the underlying function due to the lack of tunnable parameters .",
    "as the number of neurons in the hidden layer is increased , the neural network performs better and for a number of neurons larger than 15 the error is not further reduced .",
    "consequently , we conclude that for this specific application the adequate number of neurons for the hidden layer lies between 10 and 15 .",
    "this choice ensures a network large enough to be capable of estimating the underlying relationship and not excessively large to consume excessive training time , learn slowly and be dependent on the learning algorithm .",
    "we have also checked that increasing the number of hidden layers of the neural network does not result in a better performance of the interpolating algorithm , but for the sake of conciseness we do not show the results here .",
    "all in all , it seems that our fiducial architecture seems to work best .",
    "most of the feed - forward networks are trained with the back - propagation algorithm and gradient descent techniques are used to minimize some specific cost function , and this has been the case for the training algorithm used here .",
    "this means that all activation functions within the network must be differentiable to be able to compute the network gradient for each learning step .",
    "normally , the most commonly used type of functions are the tangent sigmoid or the logarithmic sigmoid  @xcite , which can model any non - linear function if properly trained  @xcite , whereas linear functions are usually employed for linear models with high dimensionality .",
    "we have studied several possibilities and the results are listed in table  [ tab : typeneuron ] , where we show for the different types of neurons the standard deviations of the probability density functions of the estimates of the magnetic field for both test mass 1 and 2 ( tm@xmath40 and tm@xmath41 , respectively ) . in our case , and as borne out from table  [ tab : typeneuron ] , the linear function together with the tangent sigmoid and the logarithmic sigmoid are the most efficient choices , while the performance of the radial base function is slightly worse .",
    "finally , the step function ( the popular perceptron ) does not yield good results because it is specifically designed to be used for classification problems . specifically",
    ", the linear neuron is the one for which we obtain the best results .",
    "this could be surprising given that our problem is highly non - linear .",
    "the reason is that for every magnetic configuration there exists a large and fairly stable difference between the value of the magnetic field at the location of the magnetometers ( all of the components of the magnetic field are @xmath42 @xmath18 t ) and the field at the position of the test masses ( all the components are on the 100 nt level ) . for this reason",
    ", the weigths of the network happen to be the most relevant modeling factors .",
    "that is , the point - to - point interpolation can be understood in the linear case as a simple weighted sum of the magnetometers measurements .",
    "accordingly , because of its simplicity and good results , we use the linear function as the basic unit in our regression study .",
    "it is worth noting at this point that similar results could be obtained using a high - dimensionality least squares analysis , but in our specific case we have found matrix inversion problems because some magnetometer channels present highly correlated signals .",
    "we have already shown that our neural network is highly reliable .",
    "thus , it is normal to ask ourselves which is the ultimate reason of this behavior .",
    "the answer to this question is that during the training process , the neural network eventually learns that the magnetic field at the positions of the test masses is generally smaller than the magnetometers readouts  with occasional exceptions due to the rich and complex profile structure of the field inside the lca .",
    "moreover , the neural network is able to learn an inference procedure which is actually quite efficient . to better understand this , we found instructive to look into relationships between the data read by the magnetometers and the estimates of the magnetic field generated by the neural network .",
    "we chose to calculate correlation coefficients between input and output data , and the results are displayed in table  [ table : input - ouput ] .",
    "the test masses are labeled as tm@xmath40 and tm@xmath41 , respectively , whilst the four magnetometers are listed as m@xmath43 , @xmath44 .",
    "crrr output & @xmath31 & @xmath32 & @xmath33 + @xmath31 tm@xmath40 & & & + @xmath45 m@xmath40 & 0.2177 & @xmath46 & 0.0134 + @xmath45 m@xmath41 & 0.2581 & @xmath47 & 0.1564 + @xmath45 m@xmath48 & 0.3754 & 0.0985 & 0.0054 + @xmath45 m@xmath49 & 0.9340 & 0.1528 & @xmath50 + @xmath32 tm@xmath40 & & & + @xmath45 m@xmath40 & @xmath51 & 0.3556 & @xmath52 + @xmath45 m@xmath41 & 0.0031 & 0.2240 & 0.0601 + @xmath45 m@xmath48 & @xmath53 & 0.4249 & 0.1217 + @xmath45 m@xmath49 & 0.0668 & 0.9035 & 0.0102 + @xmath33 tm@xmath40 & & & + @xmath45 m@xmath40 & @xmath54 & @xmath55 & 0.3090 + @xmath45 m@xmath41 & @xmath56 & 0.0083 & 0.3377 + @xmath45 m@xmath48 & @xmath57 & @xmath58 & 0.5002 + @xmath45 m@xmath49 & 0.0493 & 0.0615 & 0.9041 + @xmath31 tm@xmath41 & & & + @xmath45 m@xmath40 & 0.3506 & 0.1862 & 0.0840 + @xmath45 m@xmath41 & 0.9081 & @xmath59 & 0.3782 + @xmath45 m@xmath48 & 0.1230 & @xmath60 & @xmath61 + @xmath45 m@xmath49 & 0.2502 & 0.0184 & @xmath62 + @xmath32 tm@xmath41 & & & + @xmath45 m@xmath40 & @xmath63 & 0.3877 & @xmath64 + @xmath45 m@xmath41 & 0.0184 & 0.8398 & @xmath65 + @xmath45 m@xmath48 & 0.3722 & 0.2400 & 0.0927 + @xmath45 m@xmath49 & @xmath66 & 0.2379 & @xmath67 + @xmath33 tm@xmath41 & & & + @xmath45 m@xmath40 & 0.1217 & 0.0267 & 0.4111 + @xmath45 m@xmath41 & 0.0144 & @xmath68 & 0.8740 + @xmath45 m@xmath48 & 0.0333 & 0.0233 & 0.5054 + @xmath45 m@xmath49 & 0.0310 & 0.0141 & 0.2685 +    the following major features can be easily identified .",
    "firstly , each component of the field is basically estimated from the magnetometers reading of the same component .",
    "for example , the interpolation of the @xmath69-component in test mass 1 is mostly dependent on the @xmath69-readings of the magnetometers .",
    "secondly , the measurements of the magnetometers closer to the interpolation points have larger weights .",
    "for instance , when the field is estimated at the position of tm@xmath40 , to which the magnetometer m@xmath49 is the closest magnetometer , the value it measures is the largest contributor to the interpolated field in tm@xmath40 . at the same time ,",
    "magnetometers m@xmath40 and m@xmath48 being nearly equidistant from both test masses , their weights are almost identical ( see table [ tab : positions ] for more details ) .",
    "finally , no apparent or easily deductible physical relationship is found between the estimated gradient at the positions of the test masses and the magnetometer inputs .",
    "the numerical experiments done so far indicate that the neural network interpolating scheme offers good performances when properly trained , irrespective of its specific architecture .",
    "however , we emphasize that the neural network has been trained using simulated data , while for the real spacecraft the neural network will be trained using onground measured data . this data , as already mentioned in section [ sec : model ] , is planned to be obtained in spacecraft magnetic test campaign , to be performed at during 2011 . to assess how this could be done we have determined how many batches of samples need to be fed in the neural network to obtain the desired accuracies .",
    "we have found that for a proper training of the network , at least 10 batches of samples must be recorded from the real spacecraft with all the sources of magnetic field onboard . only in this way",
    "we can be sufficiently confident on the trained neural network .",
    "each of these batches will be constituted of @xmath26 vectors of 28 values each , corresponding to 12 readings of the magnetometers ( 3 components for each of the 4 magnetometers ) , 6 magnetic field readings ( 3 components of the magnetic field measured at the positions of each test mass ) and 10 readings of the gradients of the magnetic field ( 5 values for each test mass ) .",
    "this will allow to choose an specific neural network model in a realistic case .",
    "-component , the dotted line to the @xmath32-component and , the dashed line to the @xmath33-component.,title=\"fig:\",scaledwidth=90.0% ] -component , the dotted line to the @xmath32-component and , the dashed line to the @xmath33-component.,title=\"fig:\",scaledwidth=90.0% ]    it is expected that the magnetic characteristics of each of the spacecraft units will not change due to launch stresses .",
    "however , the measurements taken onground may not be accurate enough to represent the real magnetic inflight characteristics of these units .",
    "for instance , some units would be missing during the onground measurement campaign or some others can change their magnetic characteristics during the lifetime of the mission or , finally , it could be as well that the system operation can not be measured onground accurately .",
    "for all these reasons the predictions of the neural network may be biased .",
    "hence , it is important to assess the robustness of the predictions of the neural network in front of changes in the magnetic dipoles of the electronic boxes .",
    "to do so we have adopted the following procedure .",
    "we varied randomly each of the components of the magnetic field of all the sources of magnetic field according to gaussian distributions .",
    "the width of such gaussians , @xmath70 , is our free parameter and corresponds to a given percentage of deviation of the specific component with respect to that of the training set . in this way we can simulate a difference between flight and ground data in a simple and realistic manner",
    "the results obtained using this procedure are shown in figure  [ fig : uncertaintyfield ] , where we show the standard deviation of the probability density function of the estimation of the three components of the magnetic field interpolated using the trained neural network as a function of the width of the gaussians .",
    "as can be seen in this figure , the error of the estimate increases linearly for increasing widths of the gaussian .",
    "nevertheless , our simulations show that offsets of @xmath71 per component in each of the magnetic sources result in a global error of the estimate of @xmath72 for the magnetic field and of only @xmath73 for the gradient at the positions of the test masses , a very interesting result .",
    "thus , we conclude that our interpolation scheme is fairly robust in front of small differences in the flight - ground data configuration .",
    "-component , the dotted line to the @xmath32-component and , the dashed line to the @xmath33-component.,title=\"fig:\",scaledwidth=90.0% ] -component , the dotted line to the @xmath32-component and , the dashed line to the @xmath33-component.,title=\"fig:\",scaledwidth=90.0% ]    it has been shown recently that the magnetometers readings may suffer from an unpredictable offsets @xcite due to launch stresses . in particular , this offset is most problably due to temperature changes during launch , and varies from @xmath74 nt to several nt .",
    "this , of course , may have important consequences in the estimate of the magnetic field at the positions of the magnetometers , as the interpolating algorithm presented here largely depends on the reading of the magnetometers .    to assess the robustness of the interpolation scheme to the offsets in the readings of the magnetometers we have simulated a random vector of offsets ( a 12 valued - vector , 1 offset for each of the 12 magnetic channels ) , according to a gaussian distribution of width @xmath75 .",
    "this offset vector has been added to the inflight readings when performing the assessment of the results output by the interpolation network .",
    "several simulations have been performed varying @xmath75 from 1 nt to 200 nt .",
    "the results are shown in figure [ fig : offsetmag ] .",
    "as can be observed , the errors in magnetic field estimation are below 10% up to an offset level at the magnetomters of 80 nt  which is one order of magnitude larger than the offset observed in other space missions  @xcite .",
    "consequently , we conclude that the magnetic data analysis of the mission will not be appreciably affected by the possible offset of the magnetometers readings .",
    "another aspect which may also be relevant for the determination of the magnetic field and gradients at the positions of the test masses is the uncertainty in the location of the heads of the magnetometers .",
    "actually , the neural network is trained with the nominal position of the magnetometers , and the inflight training will be done with these nominal values .",
    "the uncertainty in these values may represent an important source of error because the neural network learns from the geometrical distances between the test masses and the magnetometers  see table [ table : input - ouput ] .",
    "the onboard tri - axial magnetometers will be four tfm100g4-s .",
    "these are fluxgate magnetometers built by billingsley . by construction ,",
    "these magnetometers consist of three different magnetic sensors , along the @xmath27- , @xmath28- and @xmath29-directions . for each of these axes ,",
    "the fluxgate magnetometer consists of a sensing ( secondary ) coil surrounding an inner drive ( primary ) coil around permeable core material . due to the large size of the head of these low - noise magnetometers , the spatial resolution in each of the directions",
    "is @xmath76 mm . on the other hand ,",
    "the coils of the magnetometers have an orthogonality better than @xmath77 .",
    "this angular error may be transformed to a linear uncertainty by multiplying by the longest distance inside the magnetometer caging , @xmath78 mm , resulting in an uncertainty of @xmath79 mm .",
    "finally , the exact placement of the satellite units onto the satellite walls may be unprecise .",
    "it is estimated that the mechanical precision will be on the order of the @xmath18 m , and therefore it will be considered negligible in this analysis . the overall spatial uncertainty of the sensing position of the magnetometers can be computed by adding in quadrature the different contributions , and turns out to be @xmath80 mm . in view of these conundrums",
    "we performed an additional set of simulations in which the positions of the magnetometers where randomly changed within 5 mm .",
    "we then computed the error in the estimate of the interpolating neural network .",
    "the results are shown in figure [ fig : posmag ] . clearly , the neural network outputs a mean error in interpolation below 6% if the mechanical uncertainty lies below 4.3 mm , which is the worst case expected in the mission .",
    "therefore , the neural network is expected to be very robust to this kind of uncontrollabale situations .",
    "as can be seen in eq .",
    "( [ eq.1 ] ) , there is a non - linear dependence of the force on the magnetic field .",
    "this means that the acceleration depends on the temporal variations of the magnetic field and its gradient .",
    "specifically , a coupling of the value of the magnetic field with the variations of its gradient ( and viceversa ) exists . in the previous sections we have shown that our neural network interpolating algorithm correctly retrieves the values of the magnetic field and its gradient at the positions of the test masses when they are assumed to do not vary with time .",
    "however , these quantities are expected to be subject to small low - frequency fluctuations .",
    "thus , we need to assess if our method is able to correctly follow a slow drift of the magnetic field and its gradient .    as previously mentioned , the magnetic field inside the lca is a consequence of the electronic subsystems present inside the spacecraft .",
    "almost all operational amplifiers ( the most important source of noise of the electronics processing chain of each unit ) are subject to a @xmath81 noise around 0.1 hz or higher frequencies .",
    "magnetic tests of every unit have not yet been performed , but it is foreseen that the spectrum of fluctuations of the magnetic field at the position of the test masses will be very similar to the noise spectrum of the amplifiers . in particular , it is expected that the spectrum will have a @xmath81 branch below a roll - off frequency of 0.1 hz , and a white noise branch extending up to 10 hz .",
    "the predicted spectrum , which has been obtained assuming a worst - case scenario  that is , assuming an amplitude @xmath82 a m@xmath83 at 0.1 hz  is shown in figure [ fig : spectrumtms ] . as it will be shown below ,",
    "one of the direct consequences of including the fluctuations given by the noise spectrum of figure [ fig : spectrumtms ] is the presence of low - frequency variations of up to 300 nt for each of the three magnetic components .",
    "these fluctuations may cause important errors in the magnetic field estimation if not considered in the training process .",
    "neural networks can be classified into dynamic and static categories .",
    "static networks have no feedback elements and , consequently , contain no delays .",
    "thus , the output is calculated directly from the input ( and only the current input ) through feedforward connections @xcite .",
    "the training of static networks is performed with the well known and efficient backpropagation algorithm , as described in section 2.2 . in dynamic networks ,",
    "the output depends not only on the current input to the network , but also on its previous inputs and outputs @xcite .",
    "thus , for our case one might quite naturally think that we should be forced to choose a dynamic neural network . nevertheless , as shown in section 2.5 , the most important feature of our interpolation scheme is the ability of the neural network to learn the underlying structures of the magnetic field inside the lca .",
    "since training a dynamic network is hard task and , moreover , the learning rate is usually very slow it is worth exploring the possibility of using instead a static network with an adequate training procedure adapted to this new scenario . in other words",
    ", we have to let know the network during the training process that a drift occurs .",
    "to do this we use a simple and effective training procedure .",
    "we first generate 10 different time series using uncorrelated white noise realizations .",
    "we then compute the dynamic range of the magnetic field for each of these realizations . of these time series",
    "we select those five which have the widest dynamical range , and we concatenate them . these 5 time series",
    "are then used to train the network .",
    "lcccccc & & + & @xmath84 & @xmath85 & @xmath84 & @xmath85 + @xmath31 & 2.68 & 3.28 & 8.75 & 14.75 + @xmath32 & 2.71 & 3.27 & 4.86 & 8.46 + @xmath33 & 3.15 & 3.82 & 2.92 & 13.16 + @xmath86 & 2.13 & 3.15 & 5.85 & 16.30 +    with this new training technique the interpolation results are remarkably good . to illustrate the goodness of our interpolation procedure in the top panel of figure [ fig : temporal ] we show the temporal evolution of the fluctuating magnetic field for test mass 1 ( black line ) and the interpolated result obtained using the neural network trained with the fluctating examples ( cyan line ) .",
    "as can be seen , although there are some differences , the result of the interpolation closely resembles the actual magnetic field . this can be better appreciated when both signals are filtered at 10 mhz using a low - pass filter ( bottom panel of this figure ) .",
    "clearly , the interpolated magnetic field follows very closely the real magnetic field .",
    "moreover , the spectrum of the interpolated magnetic field is very similar to that of figure [ fig : spectrumtms ] .",
    "this is borne out from figure [ fig : spectrums ] , in which we compare both spectra .",
    "clearly , the interpolated spectrum ( cyan line ) follows very closely the real one ( black line ) , indicating that the neural network correctly describes the physical properties of the varying magnetic field .",
    "the only remarkable difference when a fluctuating magnetic field is analyzed is that in this case the neural network performs slightly worse .",
    "this can be seen in table [ tab : comparison ] , where we show the standard deviations of the estimates for both a constant magnetic field and a fluctuating one , for all the field components and its modulus and for both test mass 1 ( @xmath84 ) and test mass 2 ( @xmath85 ) .",
    "as can be seen , the estimation errors are larger for a fluctuating magnetic field , as it should be expected , but do not increase dramatically .",
    "lisa pathfinder is a very challenging space mission , since it will test in flight many novel ( and critical ) technologies which are needed to satisfactorily put in orbit the first space - borne gravitational wave detector .",
    "more specifically , this mission will measure and control very accurately the motion of two test masses in almost perfect gravitational free - fall . to do this",
    ", the diagnostic system of lisa pathfinder will monitor with unprecedented accuracy the disturbances of the motion of the test masses .",
    "an essential part of this subsystem is the magnetic diagnostics subsystem , which will be in charge of measuring the magnetic noise . to this end",
    ", this subsystem has four tri - axial magnetometers , which due to design constraints are placed far from the positions of the test masses .",
    "thus , measuring the magnetic field at these positions is not an easy task . to overcome this problem a novel approach in which neural networks were used",
    "was recently proposed @xcite .",
    "the initial results obtained using this technique were encouraging but a full assessment of its reliability was still lacking .",
    "accordingly , we have studied how different alternatives for the architecture of the neural network affect the precision of the interpolation of the magnetic field and its gradients at the position of the test masses .",
    "we have performed a study of the underlying structures of the neural network and we have found that the ability of our interpolating scheme to recover the correct values of the magnetic field and gradients at the positions of the test masses is due to the fact that the neural network is able to learn from the readings of the magnetometers which are closest to the corresponding test mass , and that the most important contribution for each component field comes from the corresponding magnetomer reading .",
    "we have also found that the number of neurons in the hidden layer originally proposed is the optimal one , and that a larger number of neurons in this layer does not improve the quality of the interpolation .",
    "also , the results are not sensitive to the choice of the transfer function , and consequently the simplest choice , a linear transfer function , is the best option . finally , we have also found that the optimal number of hidden layers is just one .    we have also discussed how the neural network must be trained with real data . in particular , we stress the importance of finding a training process adequate to the set of data the magnetometers will deliver in flight .",
    "this underlines the need to characterize on ground to our best ability the magnetic field distribution across the lca for as many as possible foreseeable working conditions .",
    "this information will be obtained from the magnetic test campaign , to be performed during 2011 .",
    "reliable information on the magnetic characteristics is essential for a meaningful assessment of magnetic noise in the ltp , and may lead to model various networks for different magnetic configurations .",
    "our results indicate that when typical variations in the magnitudes of the magnetic dipoles of the electronic units are fed into our neural network algorithm the quality of the estimates of the magnetic field and its gradients degrade linearly with increasing departures from the onground measurement , although the measurements of the magnetic field degrade faster than those of the gradient components .",
    "however , the quality of the estimates does not degrade dramatically .",
    "we have also studied which would be the effect in the on - flight measurements of an offset in the readings of magnetometers caused by temperature changes during launch , and we have found that , for typical offsets , the interpolating algorithm works reasonably well .",
    "the same can be said about the uncertainty in the position of the head of the magnetometers .",
    "finally , we have also assessed the accuracy of the magnetic field interpolation when a low - frequency drift of the magnetic characteristics is present , concluding that with an appropriate training procedure , good results are obtained .",
    "thus , we conclude that the neural network interpolating algorithm is robust enough to obtain a good estimate of the magnetic field at the positions of the test masses under most circumstances .",
    "this work was partially supported by mcinn grants esp2004 - 01647 and aya0804211c0201 .",
    "part of this work was also supported by the agaur .",
    "we thank our anonymous referee , whose comments helped to improve the manuscript .    99 a. hammesfahr et al .",
    ", _ lisa final technical report _ , estec contract 13631/99/nl / ms report li - rp - ds-009 ( 2000 ) w.m .",
    "folkner , f. hechler , t.h .",
    "sweetser , m.a .",
    "vincent , & p.l .",
    "bender , _ class .",
    "& quantum grav .",
    "_ , * 14 * , 1405 ( 1997 ) s. anza et al . , _ class . & quantum grav .",
    "_ , * 22 * , 125 ( 2005 ) the lisa international team , esa - nasa report lisa - scrd - iss5-rev1 ( 2008 ) j. sanjun et al . , _ rev . of sci",
    "_ , * 79 * , 084503 ( 2008 ) s. vitale , _ science requirements and top - level architecture definition for the lisa technology package ( ltp ) on board lisa pathfinder ( smart-2 ) _ , report no .",
    "ltpa - utn - scrd - iss003-rev1 ( 2005 ) p. canizares et al .",
    ", _ class .",
    "& quantum grav .",
    "_ , * 26 * , 094005 ( 2009 ) m. diaz - aguilo , e. garca ",
    "berro & a. lobo , _ class .",
    "& quantum grav .",
    "_ , * 27 * , 035005 ( 2010 ) v. kecman , _ learning and soft computing _ , mit press , 1st edition ( 2001 ) r.j .",
    "bullen , d. cornford , & i.t .",
    "nabney , _ neural networks _ , * 16 * , 419 ( 2003 ) d.g .",
    "loyola , _ neural networks _ , * 19 * , 168 ( 2006 ) r. reed , _ ieee trans . on neural networks _ , * 4 * , 740 ( 1993 ) b. amirikian , & h. nishimura , in _ proc . of the second international symposium on intelligent information technology applications _ ( 2008 ) c. schittenkopf , g. deco , & w. brauer , _ neural networks _ , * 10 * , 505 ( 1997 ) g. dreyfus , _ neural networks : methodology and applications _ , springer verlag , 2nd edition ( 2005 ) f. primdahl , t. risbo , j. merayo , p. brauer , & l. toffner - clausen , _ meas .",
    "sci . & technology _ , * 17 * , 1563 ( 2006 )"
  ],
  "abstract_text": [
    "<S> lisa pathfinder is a science and technology demonstrator of the european space agency within the framework of its lisa mission , which aims to be the first space - borne gravitational wave observatory . </S>",
    "<S> the payload of lisa pathfinder is the so - called lisa technology package , which is designed to measure relative accelerations between two test masses in nominal free fall . </S>",
    "<S> its disturbances are monitored and dealt by the diagnostics subsystem . </S>",
    "<S> this subsystem consists of several modules , and one of these is the magnetic diagnostics system , which includes a set of four tri - axial fluxgate magnetometers , intended to measure with high precision the magnetic field at the positions of the test masses . </S>",
    "<S> however , since the magnetometers are located far from the positions of the test masses , the magnetic field at their positions must be interpolated . </S>",
    "<S> it has been recently shown that because there are not enough magnetic channels , classical interpolation methods fail to derive reliable measurements at the positions of the test masses , while neural network interpolation can provide the required measurements at the desired accuracy . in this paper </S>",
    "<S> we expand these studies and we assess the reliability and robustness of the neural network interpolation scheme for variations of the locations and possible offsets of the magnetometers , as well as for changes in environmental conditions . </S>",
    "<S> we find that neural networks are robust enough to derive accurate measurements of the magnetic field at the positions of the test masses in most circumstances . </S>"
  ]
}