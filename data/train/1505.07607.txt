{
  "article_text": [
    "a fundamental statistical problem is shrinkage estimation of a multivariate normal mean .",
    "see , for example , the february 2012 issue of _ statistical science _ for a broad range of theory , methods , and applications .",
    "let @xmath0 be multivariate normal with _ unknown _ mean vector @xmath1 and _ known _ variance matrix @xmath2 .",
    "consider the problem of estimating @xmath3 by an estimator @xmath4 under the loss @xmath5 , where @xmath6 is a _ known _ positive definite , symmetric matrix .",
    "the risk of @xmath7 is @xmath8 .",
    "the general problem can be transformed into a canonical form such that @xmath2 is diagonal and @xmath9 , the identity matrix ( e.g. , lehmann and casella @xcite , problem 5.5.11 ) . for simplicity , assume except in section  [ sec3.2 ] that @xmath2 is @xmath10 and @xmath11 , where @xmath12 for a column vector @xmath13 .",
    "the letter @xmath14 is substituted for @xmath2 to emphasize that it is diagonal .    for this problem , we aim to develop shrinkage estimators that are both minimax and capable of effective risk reduction over the usual estimator @xmath15 even in the heteroscedastic case ( i.e. , @xmath16 are not equal ) .",
    "an estimator of @xmath3 is minimax if and only if , _ regardless of _ @xmath17 , its risk is always no greater than @xmath18 , the risk of @xmath19 . for @xmath20 ,",
    "minimax estimators different from and hence dominating @xmath21 are first discovered in the homoscedastic case where @xmath22 ( i.e. , @xmath23 ) . james and stein @xcite showed that @xmath24 is minimax provided @xmath25 .",
    "stein @xcite suggested the positive - part estimator @xmath26 , which dominates @xmath27 .",
    "throughout , @xmath28 .",
    "shrinkage estimation has since been developed into a general methodology with various approaches , including empirical bayes ( efron and morris @xcite ; morris @xcite ) and hierarchical bayes ( strawderman @xcite ; berger and robert @xcite ) . while these approaches are prescriptive for constructing shrinkage estimators , minimaxity is not automatically achieved but needs to be checked separately .    for the heteroscedastic case ,",
    "there remain challenging issues on how much observations with different variances should be shrunk relatively to each other ( e.g. , casella @xcite , morris @xcite ) . for the empirical bayes approach ( efron and morris @xcite ) ,",
    "the coordinates of @xmath29 are shrunk directly in proportion to their variances .",
    "but the existing estimators are , in general , non - minimax ( i.e. , may have a greater risk than the usual estimator @xmath21 ) . on the other hand , berger @xcite proposed minimax estimators , including admissible minimax estimators , such that the coordinates of @xmath29 are shrunk inversely in proportion to their variances .",
    "but the risk reduction achieved over @xmath21 is insubstantial unless all the observations have similar variances .    to address the foregoing issues , we develop novel minimax estimators for multivariate normal means under heteroscedasticity .",
    "there are two central ideas in our approach .",
    "the first is to develop a class of minimax estimators by generalizing a geometric argument essentially in stein @xcite ( see also brandwein and strawderman @xcite ) . for the homoscedastic case , the argument shows that @xmath27 can be derived as an approximation to the best linear estimator of the form @xmath30 , where @xmath31 is a scalar .",
    "in fact , the optimal choice of @xmath31 in minimizing the risk is @xmath32 .",
    "replacing @xmath33 by @xmath34 leads to @xmath35 with @xmath36 .",
    "this derivation is highly informative , even though it does not yield the optimal value @xmath37 .",
    "our class of minimax estimators are of the linear form @xmath38 , where @xmath39 is a nonnegative definite , diagonal matrix indicating the direction of shrinkage and @xmath31 is a scalar indicating the magnitude of shrinkage .",
    "the matrix @xmath39 is open to specification , depending on the variance matrix @xmath14 but _ not _ on the data @xmath29 . for a fixed @xmath39 , the scalar @xmath31",
    "is determined to achieve minimaxity , depending on both @xmath14 and @xmath29 .",
    "@xcite minimax estimator corresponds to the special choice @xmath40 , thereby leading to the unusual pattern of shrinkage discussed above .",
    "the second idea of our approach is to choose @xmath39 by approximately minimizing the bayes risk with a normal prior in our class of minimax estimators .",
    "the bayes risk is used to measure average risk reduction for @xmath3 in an elliptical region as in berger @xcite .",
    "it turns out that the solution of @xmath39 obtained by our approximation strategy has an interesting simple form .",
    "in fact , the coordinates of @xmath29 are automatically segmented into two groups , based on their bayes `` importance '' ( berger @xcite ) , which is of the same order as the coordinate variances when the specified prior is homoscedastic .",
    "the coordinates of high bayes `` importance '' are shrunk inversely in proportion to their variances , whereas the remaining coordinates are shrunk in the direction of the bayes rule .",
    "this shrinkage pattern may appear paradoxical : it may be expected that the coordinates of high bayes `` importance '' are to be shrunk in the direction of the bayes rule .",
    "but that scheme is inherently aimed at reducing the bayes risk under the specified prior and , in general , fails to achieve minimaxity ( i.e. , it may lead to even a greater risk than the usual estimator @xmath21 ) .",
    "in addition to simplicity and minimaxity , we further show that the proposed estimator is scale adaptive in reducing the bayes risk : it achieves close to the minimum bayes risk , with the difference no greater than the sum of the 4 highest bayes `` importance '' of the coordinates of @xmath29 , simultaneously over a scale class of normal priors ( including the specified prior ) . to our knowledge",
    ", the proposed estimator seems to be the first one with such a property in the general heteroscedastic case .",
    "previously , in the homoscedastic case , @xmath41 is known to achieve the minimum bayes risk up to the sum of 2 ( equal - valued ) bayes `` importance '' of the coordinates over the scale class of homoscedastic normal priors ( efron and morris @xcite ) .",
    "the rest of this article is organized as follows .",
    "section  [ sec2 ] gives a review of existing estimators .",
    "section  [ sec3 ] develops the new approach and studies risk properties of the proposed estimator .",
    "section  [ sec4 ] presents a simulation study .",
    "section  [ sec5 ] provides concluding remarks .",
    "all proofs are collected in the .",
    "we describe a number of existing shrinkage estimators . see lehmann and casella @xcite for a textbook account and strawderman @xcite and morris and lysy @xcite for recent reviews . throughout",
    ", @xmath42 denotes the trace and @xmath43 denotes the largest eigenvalue",
    ". then @xmath44 and @xmath45 .    for a bayes approach ,",
    "assume the prior distribution : @xmath46 , where @xmath47 is the prior variance .",
    "the bayes rule is given componentwise by @xmath48 .",
    "then the greater @xmath49 is , the more @xmath50 is shrunk whether @xmath47 is fixed or estimated from the data . for the empirical bayes approach of efron and morris @xcite , @xmath47",
    "is estimated by the maximum likelihood estimator @xmath51 such that @xmath52 morris @xcite suggested the modified estimator @xmath53 in our implementation , the right - hand side of ( [ eb - iter ] ) is computed to update @xmath51 from the initial guess , @xmath54 , for up to 100 iterations until the successive absolute difference in @xmath51 is @xmath55@xmath56 , or @xmath51 is set to @xmath57 so that @xmath58 otherwise .    alternatively , xie _ et al . _",
    "@xcite proposed empirical bayes - type estimators based on minimizing stein s @xcite unbiased risk estimate ( sure ) under heteroscedasticity .",
    "their basic estimator is defined componentwise by @xmath59 where @xmath60 is obtained by minimizing the sure of @xmath61 , that is , @xmath62 . in general , the two types of empirical bayes estimators , @xmath63 and @xmath64 , are non - minimax , as shown in section  [ sec4 ] .    for a direct extension of @xmath27 ,",
    "consider the estimator @xmath65 and , more generally , @xmath66 , where @xmath67 is a scalar constant and @xmath68 a scalar function .",
    "see lehmann and casella @xcite , theorem  5.7 , although there are some typos .",
    "both @xmath69 and @xmath70 are spherically symmetric .",
    "the estimator @xmath69 is minimax provided @xmath71 and @xmath70 is minimax provided @xmath72 .",
    "no such @xmath73 exists unless @xmath74 , which restricts how much @xmath75 can differ from each other .",
    "for example , condition ( [ s - cond ] ) fails when @xmath76 and @xmath77 because @xmath78 and @xmath79 .",
    "berger @xcite proposed estimators of the form @xmath80 and @xmath81 , where @xmath67 is a scalar constant and @xmath68 a scalar function .",
    "then @xmath82 is minimax provided @xmath25 , and @xmath83 is minimax provided @xmath84 , regardless of differences between @xmath75 .",
    "however , a striking feature of @xmath82 and @xmath83 , compared with @xmath63 and @xmath64 , is that the smaller @xmath49 is , the more @xmath50 is shrunk . for example ( [ example ] ) , under @xmath82 ,",
    "the coordinates @xmath85 are shrunk only slightly , whereas @xmath86 are shrunk as if they were shrunk as a 7-dimensional vector under @xmath27 .",
    "the associated risk reduction is insubstantial , because the risk of estimating @xmath87 is a small fraction of the overall risk of estimating @xmath3 .",
    "define the positive - part version of @xmath82 componentwise as @xmath88 the estimator @xmath89 dominates @xmath82 by baranchik @xcite , section  2.5 .",
    "berger @xcite , equation ( 5.32 ) , stated a different positive - part estimator , @xmath83 with @xmath90 , but the @xmath91th component may not be of the same sign as @xmath50 .    given a prior @xmath92 , berger @xcite suggested an approximation of berger s",
    "@xcite robust generalized bayes estimator as @xmath93 x.\\end{aligned}\\ ] ] the estimator is expected to provide significant risk reduction over @xmath15 if the prior is correct and be robust to misspecification of the prior , but it is , in general , non - minimax . in the case of @xmath94 , @xmath95 becomes @xmath96 , in the form of spherically symmetric estimators @xmath97 , where @xmath68 is a scalar function ( bock @xcite , brown @xcite ) .",
    "the estimator @xmath98 is minimax provided @xmath99 and @xmath68 is nondecreasing .",
    "moreover , if @xmath100 , then @xmath98 is non - minimax unless @xmath101 .    to overcome the non - minimaxity of @xmath95 ,",
    "berger @xcite developed a minimax estimator @xmath102 by combining @xmath103 , @xmath95 , and a minimax estimator of bhattacharya @xcite .",
    "suppose that @xmath104 and the indices are sorted such that @xmath105 , where @xmath106 .",
    "define @xmath102 componentwise as @xmath107\\frac{d_j}{d_j+\\gamma_j } x_j,\\end{aligned}\\ ] ] where @xmath108 . in the case of @xmath94",
    ", @xmath102 reduces to the original estimator of bhattacharya @xcite .",
    "the factor @xmath109 is replaced by @xmath110 in berger s",
    "@xcite original definition of @xmath102 , corresponding to replacing @xmath111 by @xmath112 in @xmath95 . in our simulations ,",
    "the two versions of @xmath102 somehow yield rather different risk curves , and so do the corresponding versions of other estimators .",
    "but there has been limited theory supporting one version over the other .",
    "therefore , we focus on comparisons of only the corresponding versions of @xmath102 and other estimators .",
    "we develop a useful approach for shrinkage estimation under heteroscedasticity , by making explicit how different coordinates are shrunk differently .",
    "the approach not only sheds new light on existing results , but also lead to new minimax estimators .",
    "assume that @xmath113 ( diagonal ) and @xmath9 .",
    "consider estimators of the linear form @xmath114 where @xmath39 is a nonnegative definite , diagonal matrix indicating the _ direction _ of shrinkage and @xmath31 is a scalar indicating the _ magnitude _ of shrinkage .",
    "both @xmath39 and @xmath31 are to be determined .",
    "a sketch of our approach is as follows .",
    "a.   for a fixed @xmath39 , the optimal choice of @xmath31 in minimizing the risk is @xmath115 b.   for a fixed @xmath39 and a scalar constant @xmath116 , consider the estimator @xmath117 by theorem  [ th1 ] , an upper bound on the risk function of @xmath118 is @xmath119,\\end{aligned}\\ ] ] where @xmath120 .",
    "requiring the second term to be no greater than 0 shows that if @xmath121 , then @xmath118 is minimax provided @xmath122 if @xmath121 , then the upper bound ( [ upper - bound ] ) has a minimum at @xmath123 . c.   by taking @xmath123 in @xmath118 ,",
    "consider the estimator @xmath124 subject to @xmath125 , so that @xmath126 is minimax by step ( ii ) .",
    "a positive - part estimator dominating @xmath126 is defined componentwise by @xmath127 where @xmath128 are the diagonal elements of @xmath39 .",
    "the upper bound ( [ upper - bound ] ) on the risk functions of @xmath129 and @xmath130 , subject to @xmath125 , gives @xmath131 we propose to choose @xmath39 based on some optimality criterion , such as minimizing the bayes risk with a normal prior centered at 0 ( berger @xcite ) .",
    "further discussions of steps ( i)(iii ) are provided in sections  [ sec3.2][sec3.3 ] .",
    "we first develop steps ( i)(ii ) for the general problem where neither @xmath2 nor @xmath6 may be diagonal .",
    "the results can be as concisely stated as those just presented for the canonical problem where @xmath132 is diagonal and @xmath9 .",
    "such a unification adds to the attractiveness of the proposed approach .",
    "consider estimators of the form ( [ delta - form ] ) , where @xmath39 is not necessarily diagonal , but @xmath133 condition ( [ a - cond ] ) is invariant under a linear transformation . to see this ,",
    "let @xmath134 be a nonsingular matrix and @xmath135 and @xmath136 .",
    "for the transformed problem of estimating @xmath137 based on @xmath138 with variance matrix @xmath139 , the transformed estimator from ( [ delta - form ] ) is @xmath140 .",
    "the application of condition ( [ a - cond ] ) to @xmath141 says that @xmath142 is nonnegative definite and therefore is equivalent to ( [ a - cond ] ) itself . for the canonical problem where @xmath113 ( diagonal ) , condition ( [ a - cond ] ) only requires that @xmath143 is nonnegative definite , allowing @xmath39 to be non - diagonal . on the other hand",
    ", it seems intuitively appropriate to restrict @xmath39 to be diagonal",
    ". then condition ( [ a - cond ] ) is equivalent to saying that @xmath39 is nonnegative definite ( and diagonal ) , which is the condition introduced on @xmath39 in the sketch in section  [ sec3.1 ] .",
    "the risk of an estimator of the form ( [ delta - form ] ) is @xmath144 for a fixed @xmath39 , the optimal @xmath31 in minimizing the risk is @xmath145 replacing @xmath146 by @xmath147 and @xmath148 by a scalar constant @xmath149 leads to the estimator @xmath150 for a generalization , replacing @xmath67 by @xmath151 with a scalar function @xmath152 leads to the estimator @xmath153 we provide in theorem  [ th1 ] an upper bound on the risk function of @xmath154 .",
    "[ th1 ] assume that @xmath68 almost differentiable ( stein @xcite ) . if ( [ a - cond ] ) holds and @xmath155 is nondecreasing , then for each @xmath3 , @xmath156,\\end{aligned}\\ ] ] where @xmath157 and @xmath158 . taking @xmath159 in ( [ r - upper - bound ] )",
    "gives an upper bound on @xmath160 .    requiring the second term in the risk upper bound ( [ r - upper - bound ] ) to be no greater than 0 leads to a sufficient condition for @xmath154 to be minimax .",
    "[ cor1 ] if ( [ a - cond ] ) holds and @xmath161 , then @xmath154 is minimax provided @xmath162 particularly , @xmath118 is minimax provided @xmath163 .    for the canonical problem , inequality ( [ r - upper - bound ] ) and condition ( [ tan - cond2 ] ) for @xmath118 give respectively ( [ upper - bound ] ) and ( [ tan - cond ] ) .",
    "these results generalize the corresponding ones for @xmath69 and @xmath82 in section  [ sec2 ] , by the specific choices @xmath164 or @xmath165 .",
    "the generalization also holds if @xmath67 is replaced by a scalar function @xmath166 .",
    "in fact , condition ( [ tan - cond2 ] ) reduces to baranchik s @xcite condition in the homoscedastic case .    if @xmath167 , then the risk upper bound ( [ r - upper - bound ] ) has a minimum at @xmath168 . as a result , consider the estimator @xmath169 which is minimax provided @xmath167 . if @xmath170 ( berger @xcite ) , then @xmath171 and , by the proof of theorem  [ th1 ] in the , the risk upper bound ( [ r - upper - bound ] ) becomes exact for @xmath118 .",
    "therefore , for @xmath170 , the estimator @xmath172 is uniformly best in the class @xmath118 , in agreement with the result that @xmath41 is uniformly best among @xmath27 in the homoscedastic case .",
    "the estimator @xmath126 has desirable properties of invariance .",
    "first , @xmath126 is easily shown to be invariant under a multiplicative transformation @xmath173 for a scalar @xmath174 .",
    "second , @xmath126 is invariant under a linear transformation of the inference problem .",
    "similarly as discussed below ( [ a - cond ] ) , let @xmath134 be a nonsingular matrix and @xmath175 , @xmath176 , and @xmath136 .",
    "for the transformed problem of estimating @xmath137 based on @xmath138 , the transformed estimator from @xmath126 is @xmath177 , whereas the application of @xmath126 is @xmath178 .",
    "the two estimators are identical because @xmath179 , @xmath180 , and hence @xmath181 .    finally , we present a positive - part estimator dominating @xmath126 in the case where both @xmath182 and @xmath183 are symmetric , that is , @xmath184 similarly to ( [ a - cond ] ) , it is easy to see that this condition is invariant under a linear transformation . condition ( [ a - cond2 ] ) is trivially true if @xmath2 , @xmath6 , and @xmath39 are diagonal . in the",
    ", we show that ( [ a - cond2 ] ) holds if and only if there exists a nonsingular matrix @xmath134 such that @xmath185 , @xmath186 , and @xmath187 , where @xmath14 and @xmath188 are diagonal and the diagonal elements of @xmath14 or @xmath188 are , respectively , the eigenvalues of @xmath189 or @xmath39 . in the foregoing notation , @xmath190 and @xmath191 . for the problem of estimating @xmath192 based on @xmath138 , consider the estimator @xmath193 and the positive - part estimator @xmath194 with the @xmath91th component , @xmath195 where @xmath196 are the diagonal elements of @xmath188 .",
    "the estimator @xmath194 dominates @xmath197 by a simple extension of baranchik @xcite , section  2.5 . by a transformation back to the original problem , @xmath197 yields @xmath126 , whereas @xmath198 yields @xmath199 b x.\\end{aligned}\\ ] ] then @xmath200 dominates @xmath126 .",
    "therefore , ( [ r - upper - bound ] ) also gives an upper bound on the risk of @xmath201 , with @xmath202 , even though @xmath201 is not of the form @xmath154 .",
    "in practice , a matrix @xmath39 satisfying ( [ a - cond2 ] ) can be specified in two steps .",
    "first , find a nonsingular matrix @xmath134 such that @xmath185 and @xmath203 , where @xmath14 is diagonal .",
    "second , pick a diagonal matrix @xmath188 and define @xmath204 .",
    "the first step is always feasible by taking @xmath205 , where @xmath206 is a nonsingular matrix such that @xmath207 and @xmath208 is an orthogonal matrix @xmath208 such that @xmath209 is diagonal . given @xmath210 and @xmath14 , it can be shown that @xmath39 and @xmath200 depend on the choice of @xmath188 , but not on that of @xmath134 , provided that @xmath211 if @xmath212 for any @xmath213 . in the canonical case",
    "where @xmath113 and @xmath9 , this condition amounts to saying that any coordinates of @xmath29 with the same variances should be shrunk in the same way .",
    "different choices of @xmath39 lead to different estimators @xmath126 and @xmath200 .",
    "we study how to choose @xmath39 , depending on @xmath214 but _ not _ on @xmath29 , to approximately optimize risk reduction while preserving minimaxity for @xmath126 .",
    "the estimator @xmath201 provides even greater risk reduction than @xmath126 .",
    "we focus on the canonical problem where @xmath113 ( diagonal ) and @xmath9 .",
    "further , we restrict @xmath39 to be diagonal and nonnegative definite .    as discussed in berger @xcite , any estimator can have significantly smaller risk than @xmath15 only for @xmath3 in a specific region .",
    "berger @xcite considered the situation where significant risk reduction is desired for an elliptical region @xmath215 with @xmath216 and @xmath217 the prior mean and prior variance matrix .",
    "see @xmath95 and @xmath102 reviewed in section  [ sec2 ] .",
    "to measure average risk reduction for @xmath3 in region ( [ region ] ) , berger @xcite used the bayes risk with the normal prior @xmath218 . for simplicity , assume throughout that @xmath219 and @xmath220 is diagonal .",
    "we adopt berger s @xcite ideas of specifying an elliptical region and using the bayes risk to quantify average risk reduction in this region .",
    "we aim to find @xmath39 , subject to @xmath125 , minimizing the bayes risk of @xmath126 with the prior @xmath221 , @xmath222 , @xmath223 where @xmath224 denotes the expectation with respect to the prior @xmath221 .",
    "given @xmath39 , the risk @xmath225 can be numerically evaluated .",
    "a simple monte carlo method is to repeatedly draw @xmath92 and @xmath226 and then take the average of @xmath227 .",
    "but it seems difficult to literally implement the foregoing optimization .",
    "alternatively , we develop a simple method for choosing @xmath39 by two approximations .",
    "first , if @xmath125 , then taking the expectation of both sides of ( [ point - bound ] ) with respect to the prior @xmath221 gives an upper bound on the bayes risk of @xmath126 : @xmath228 where @xmath229 denotes the expectation with respect to the marginal distribution of @xmath29 in the bayes model , that is , @xmath230 .",
    "an approximation strategy for choosing @xmath39 is to minimize the upper bound ( [ bayes - bound ] ) on the bayes risk or to maximize the second term .",
    "the expectation @xmath231 can be evaluated as a 1-dimensional integral by results on inverse moments of quadratic forms in normal variables ( e.g. , jones @xcite ) .",
    "but the required optimization problem remains difficult .",
    "second , approximations can be made to the distribution of the quadratic form @xmath232 .",
    "suppose that @xmath232 is approximated with the same mean by @xmath233 , where @xmath234 is a chi - squared variable with @xmath235 degrees of freedom .",
    "then @xmath231 is approximated by @xmath236 .",
    "we show in the that this approximation gives a valid lower bound : @xmath237 a direct application of jensen s inequality shows that @xmath238 .",
    "but the lower bound ( [ bayes - bound2 ] ) is strictly tighter and becomes exact when @xmath239 .",
    "no simple bounds such as ( [ bayes - bound2 ] ) seem to hold if more complicated approximations ( e.g. , satterthwaite @xcite ) are used .",
    "combining ( [ bayes - bound ] ) and ( [ bayes - bound2 ] ) shows that if @xmath125 , then @xmath240 notice that @xmath126 is invariant under a multiplicative transformation @xmath241 for a scalar @xmath174 , and so is the upper bound ( [ bayes - bound3 ] ) . our strategy for choosing @xmath39 is to minimize the upper bound ( [ bayes - bound3 ] ) subject to @xmath125 or , equivalently , to solve the constrained optimization problem : @xmath242\\\\[-8pt ] & & \\quad \\mbox{subject to } \\quad   \\sum_{j=1}^p ( d_j+ \\gamma_j ) a_j^2 = \\mbox{fixed}. \\nonumber\\end{aligned}\\ ] ] the condition @xmath125 is dropped , because for @xmath20 , the achieved maximum is at least @xmath243 for some scalar @xmath244 . in spite of the approximations used in our approach ,",
    "theorem  [ th2 ] shows that not only the problem ( [ opt ] ) admits a non - iterative solution , but also the solution has a very interesting interpretation . for convenience ,",
    "assume thereafter that the indices are sorted such that @xmath245 .",
    "[ th2 ] assume that @xmath20 , @xmath246 with @xmath247 and @xmath248 with @xmath249 ( @xmath250 ) .",
    "for problem ( [ opt ] ) , assume that @xmath251 with @xmath252 ( @xmath253 ) and @xmath254 , satisfied by @xmath255",
    ". then the following results hold .",
    "a.   there exists a _",
    "unique _ solution , @xmath256 , to problem ( [ opt ] ) .",
    "b.   let @xmath257 be the largest index such that @xmath258 .",
    "then @xmath259 , @xmath260 for @xmath261 , and @xmath262 where @xmath263 and @xmath264 the achieved maximum value , @xmath265 , is @xmath266 . c.   the resulting estimator @xmath267 is minimax .",
    "we emphasize that , although @xmath39 can be considered a tuning parameter , the solution @xmath268 is _ data independent _ , so that @xmath269 is automatically minimax .",
    "if a data - dependent choice of @xmath39 were used , minimaxity would not necessarily hold .",
    "this result is achieved both because each estimator @xmath126 with @xmath125 is minimax and because a global criterion ( such as the bayes risk ) is used , instead of a pointwise criterion ( such as the frequentist risk at the unknown @xmath3 ) , to select @xmath39 . by these considerations ,",
    "our approach differs from the usual exercise of selecting a tuning parameter in a data - dependent manner for a class of candidate estimators .",
    "there is a remarkable property of monotonicity for the sequence @xmath270 , which underlies the uniqueness of @xmath257 and @xmath268 .",
    "[ cor2 ] the sequence @xmath271 is nonincreasing : for @xmath272 , @xmath273 , where the equality holds if and only if @xmath274 the condition @xmath275 is equivalent to saying that the left side is greater than the right - hand side in the above expression for @xmath276 . therefore , @xmath257 is the smallest index @xmath272 with this property , and @xmath277 .",
    "the estimator @xmath267 is invariant under scale transformations of @xmath268 .",
    "therefore , the constant @xmath278 can be dropped from the expression of @xmath268 in theorem  [ th1 ] .",
    "[ cor3 ] the solution @xmath279 can be rescaled such that @xmath280 then @xmath281 .",
    "moreover , it holds that @xmath282 the estimator @xmath267 can be expressed as @xmath283    the foregoing results lead to a simple algorithm for solving problem ( [ opt ] ) :    a.   sort the indices such that @xmath284 .",
    "b.   take @xmath257 to be the smallest index @xmath285 ( corresponding to the largest @xmath286 ) such that @xmath272 and @xmath287 or take @xmath288 if there exists no such @xmath285 . c.   compute @xmath289 by ( [ sol1])([sol2 ] ) .",
    "this algorithm is guaranteed to find the ( unique ) solution to problem ( [ opt ] ) by a fixed number of numerical operations .",
    "no iteration or convergence diagnosis is required .",
    "therefore , the algorithm is exact and non - iterative , in contrast with usual iterative algorithms for nonlinear , constrained optimization .",
    "the estimator @xmath267 has an interesting interpretation . by ( [ sol1])([sol2 ] )",
    ", there is a dichotomous segmentation in the shrinkage direction of the coordinates of @xmath29 based on @xmath290 .",
    "this quantity @xmath291 is said to reflect the bayes `` importance '' of @xmath292 , that is , the amount of reduction in bayes risk obtainable in estimating @xmath292 in berger @xcite .",
    "the coordinates with high @xmath291 are shrunk inversely in proportion to their variances @xmath49 as in berger s",
    "@xcite estimator @xmath82 , whereas the coordinates with low @xmath291 are shrunk in the direction of the bayes rule .",
    "therefore , @xmath267 mimics the bayes rule to reduce the bayes risk , except that @xmath267 mimics @xmath82 for some coordinates of highest bayes `` importance '' in order to achieve minimaxity .",
    "in fact , by inequality ( [ sol - ineq ] ) , the relative shrinkage , @xmath293 , of each @xmath50 ( @xmath294 ) in @xmath267 versus the bayes rule is always no greater than that of @xmath295 ( @xmath296 ) .",
    "the expression ( [ delta - a ] ) suggests that there is a close relationship in beyond the shrinkage direction between @xmath297 and the bayes rule under the bayes model , @xmath298 . in this case , @xmath299 , and hence @xmath297 behaves similarly to @xmath300 .",
    "therefore , _ on average _ under the bayes model , the coordinates of @xmath29 are shrunk in @xmath269 the same as in the bayes rule , except that some coordinates of highest bayes `` importance '' are shrunk no greater than in the bayes rule .",
    "while this discussion seems heuristic , we provide in section  [ sec3.4 ] a rigorous analysis of the bayes risk of @xmath267 , compared with that of the bayes rule .",
    "we now examine @xmath267 for two types of priors : @xmath301 and @xmath302 ( @xmath303 ) , referred to as the homoscedastic and heteroscedastic priors . for both types ,",
    "@xmath304 are of the same order as the variances @xmath305 .",
    "recall that @xmath126 is invariant under a multiplicative transformation of @xmath39 .",
    "for both the homoscedastic prior with @xmath306 and the heteroscedastic prior _ regardless _ of @xmath307 , the solution @xmath308 can be rescaled such that @xmath309 denote by @xmath310 this rescaled matrix @xmath268 , corresponding to @xmath94 .",
    "then coordinates with high variances are shrunk inversely in proportion to their variances , whereas coordinates with low variances are shrunk symmetrically . for @xmath94 ,",
    "the proposed method has a purely frequentist interpretation : it seeks to minimize the upper bound ( [ bayes - bound3 ] ) on the pointwise risk of @xmath126 at .    for the homoscedastic prior with @xmath311 ,",
    "the proposed method is then to minimize the upper bound ( [ bayes - bound3 ] ) on the bayes risk of @xmath126 with an extremely flat , homoscedastic prior . as @xmath311",
    ", the solution @xmath268 can be rescaled such that @xmath312 denote by @xmath313 this rescaled matrix @xmath268 .",
    "then coordinates with low ( or high ) variances are shrunk directly ( or inversely ) in proportion to their variances . the direction @xmath313 can also be obtained by using a fixed prior in the form @xmath314 ( @xmath250 ) for arbitrary @xmath315 , where @xmath316 .",
    "finally , in the homoscedastic case ( @xmath23 ) , if the prior is also homoscedastic ( @xmath317 ) , then @xmath288 , @xmath318 , and @xmath269 reduces to the james  stein estimator @xmath319 , _ regardless _ of @xmath320 and @xmath47 .      the estimator @xmath267 is constructed by minimizing the upper bound ( [ bayes - bound3 ] ) on the bayes risk subject to minimaxity .",
    "in addition to simplicity , interpretability , and minimaxity demonstrated for @xmath267 , it remains important to further study risk properties of @xmath267 and show that @xmath269 can provide effective risk reduction over @xmath15 .",
    "write @xmath321 whenever needed to make explicit the dependency of @xmath268 on @xmath217 .",
    "first , we study how close the bayes risk of @xmath322 can be to that of the bayes rule , which is the smallest possible among _ all _ estimators including non - minimax ones , under the prior @xmath221 , @xmath323 .",
    "the bayes rule @xmath324 is given componentwise by @xmath325 , with the bayes risk @xmath326 where @xmath327 , indicating the bayes `` importance '' of @xmath292 ( berger @xcite ) .",
    "the upper bound ( [ bayes - bound3 ] ) on the bayes risk of @xmath328 gives @xmath329 because @xmath330 and hence @xmath331 by corollary  [ cor3 ] .",
    "it appears that the difference between @xmath332 and @xmath333 tends to be large if @xmath257 is large .",
    "but @xmath334 can not differ too much from each other because by corollary  [ cor1 ] , @xmath335 then the difference between @xmath336 and @xmath337 should be limited even if @xmath257 is large .",
    "a careful analysis using these ideas leads to the following result .",
    "[ th3 ] suppose that the prior is @xmath222 .",
    "if @xmath338 , then @xmath339 if @xmath340 , then @xmath341 throughout , an empty summation is 0 .",
    "there are interesting implications of theorem  3 . by ( [ loose - bound1 ] ) and ( [ loose - bound2 ] ) , @xmath342 then @xmath343 achieves almost the minimum bayes risk if @xmath344 . in terms of bayes",
    "risk reduction , the bound ( [ bayes - close ] ) shows that @xmath345 therefore , @xmath343 achieves bayes risk reduction within a negligible factor of that achieved by the bayes rule if @xmath346 .    in the homoscedastic case",
    "where both @xmath22 and @xmath347 , @xmath267 reduces to @xmath319 , regardless of @xmath307 ( section  [ sec3.3 ] ) .",
    "then the bounds ( [ tight - bound1 ] ) and ( [ tight - bound2 ] ) become exact and give efron and morris s @xcite result that @xmath348 or equivalently @xmath349 .",
    "it is interesting to compare the bayes risk bound of @xmath350 with that of the following simpler version of berger s",
    "@xcite estimator @xmath102 : @xmath351 by berger @xcite , @xmath352 is minimax and @xmath353 there seems to be no definite comparison between the bounds ( [ tight - bound1 ] ) and ( [ tight - bound2 ] ) on @xmath354 and the exact expression ( [ mb - bayes1 ] ) for @xmath355 , although the simple bounds ( [ loose - bound1 ] ) and ( [ loose - bound2 ] ) is slightly higher , by at most @xmath356 , than the bound ( [ mb - bayes2 ] ) .",
    "of course , each risk upper bound gives a conservative estimate of the actual performance , and comparison of two upper bounds should be interpreted with caution .",
    "in fact , the positive - part estimator @xmath357 yields lower risks than those of the non - simplified estimator @xmath102 in our simulation study ( section  [ sec4 ] ) .",
    "the simplicity of @xmath267 and @xmath357 makes it easy to further study them in other ways than using the bayes ( or average ) risk .",
    "no similar result to the following theorem  [ th4 ] has been established for @xmath102 or @xmath358 .",
    "corresponding to the prior @xmath359 , consider the worst - case ( or maximum ) risk @xmath360 over the hyper - rectangle @xmath361 ( e.g. , donoho _ et al . _",
    "@xcite ) . applying jensen s inequality to ( [ point - bound ] ) shows that if @xmath362 , then @xmath363 which immediately leads to @xmath364 by the discussion after ( [ bayes - bound2 ] ) , a direct application of jensen s inequality to ( [ bayes - bound ] ) shows that the bayes risk @xmath225 is also no greater than the right - hand side of ( [ minimax - bound ] ) , whereas inequality ( [ bayes - bound2 ] ) leads to a strictly tighter bound ( [ bayes - bound3 ] ) .",
    "nevertheless , the upper bound ( [ minimax - bound ] ) on the worst - case risk of @xmath343 gives @xmath365 similarly as how ( [ bayes - bound3 ] ) leads to ( [ bayes - bound4 ] ) on the bayes risk of @xmath343 .",
    "therefore , the following result holds by the same proof of theorem  3 .",
    "[ th4 ] suppose that @xmath366 .",
    "if @xmath338 , then @xmath367 if @xmath340 , then @xmath368    there are similar implications of theorem  [ th4 ] to those of theorem  [ th3 ] . by donoho",
    "@xcite , the minimax linear risk over @xmath369 , @xmath370 , coincides with the minimum bayes risk @xmath337 , and is no greater than @xmath371 times the minimax risk over @xmath372 , @xmath373 .",
    "these results are originally obtained in the homoscedastic case ( @xmath374 ) , but they remain valid in the heteroscedastic case by the independence of the observations @xmath50 and the separate constraints on @xmath292 . therefore , a similar result to ( [ bayes - close ] ) holds : @xmath375 if @xmath344 , then @xmath269 achieves almost the minimax linear risk ( or the minimax risk up to a factor of @xmath371 ) over the hyper - rectangle @xmath369 , in addition to being globally minimax with @xmath3 unrestricted .",
    "the foregoing results might be considered non - adaptive in that @xmath328 is evaluated with respect to the prior @xmath376 or the parameter set @xmath372 with the same @xmath217 used to construct @xmath343 .",
    "but , by the invariance of @xmath126 under scale transformations of @xmath39 , @xmath328 is identical to the estimator , @xmath377 , that would be obtained if @xmath217 is replaced by @xmath378 for any scalar @xmath379 such that the diagonal matrix @xmath380 is nonnegative definite . by theorems 34 , this observation leads directly to the following adaptive result .",
    "in contrast , no adaptive result seems possible for @xmath102 .",
    "[ cor4 ] let @xmath378 and @xmath381 .",
    "then for each @xmath382 , @xmath383 & \\le & r\\bigl ( \\delta^{\\mathrm{bayes}}_{\\gamma_\\alpha } , \\pi_{\\gamma_\\alpha}\\bigr ) + \\alpha^{-1 } \\bigl(d_1^*+d_2^*+d_3^*+d_4^ * \\bigr ) \\\\ & = & r^l(\\mathcal h_{\\gamma_\\alpha})+ \\alpha^{-1 } \\bigl ( d_1^*+d_2^*+d_3^*+d_4^*\\bigr),\\end{aligned}\\ ] ] where @xmath384 .    for fixed @xmath217",
    ", @xmath343 can achieve close to the minimum bayes risk or the minimax linear risk with respect to each prior in the class @xmath385 or each parameter set in the class @xmath386 under mild conditions . for illustration , consider the case of a heteroscedastic prior with @xmath387 .",
    "then @xmath388 can be reparameterized as @xmath389 . by corollary  [ cor4 ] , for each @xmath307 , @xmath390 where @xmath391 and @xmath392 . therefore , if @xmath393 , then @xmath394 achieves the minimum bayes risk , within a negligible factor , under the prior @xmath395 for each @xmath396 .",
    "this can be seen as an extension of the result that in the homoscedastic case , @xmath41 asymptotically achieves the minimum bayes risk under the prior @xmath397 for each @xmath396 as @xmath398 .",
    "finally , we compare the estimator @xmath267 with a block shrinkage estimator , suggested by the differentiation in the shrinkage of low- and high - variance coordinates by @xmath267 .",
    "consider the estimator @xmath399 where @xmath400 is a cutoff index , and @xmath401 if @xmath402 is of dimension 1 or 2 .",
    "the index @xmath400 can be selected such that the coordinate variances are relatively homogeneous in each block .",
    "alternatively , a specific strategy for selecting @xmath400 is to minimize an upper bound on the bayes risk of @xmath403 , similarly as in the development of @xmath267 . applying ( [ bayes - bound3 ] ) with @xmath40 to @xmath404 in the two blocks shows that @xmath405 , where @xmath406 the first ( or second ) term in @xmath407 is set to 0 if @xmath408 ( or @xmath409 )",
    ". then @xmath400 can be defined as the smallest index such that @xmath410 .",
    "but the upper bound ( [ bayes - bound4 ] ) on @xmath411 is likely to be smaller than the corresponding bound on @xmath412 , because @xmath413 for each @xmath414 by the cauchy  schwarz inequality @xmath415 .",
    "therefore , @xmath267 tends to yield greater risk reduction than @xmath403 .",
    "this analysis also indicates that @xmath267 can be advantageous over @xmath403 extended to multiple blocks .",
    "the rationale of forming blocks in @xmath267 and @xmath416 differs from that in existing block shrinkage estimators ( e.g. , brown and zhao @xcite ) . as discussed in cai @xcite ,",
    "block shrinkage has been developed mainly in the homoscedastic case as a technique for pooling information : the coordinate means are likely to be similar to each other within a block .",
    "nevertheless , it is possible to both deal with heterogeneity among coordinate variances and exploit homogeneity among coordinate means within individual blocks in our approach using a block - homoscedastic prior ( i.e. , the prior variances are equal within each block ) .",
    "this topic can be pursued in future work .",
    "we conduct a simulation study to compare the following 8 estimators ,    a.   non - minimax estimators : @xmath63 by ( [ eb ] ) , @xmath64 by ( [ xkb ] ) , @xmath95 by ( [ rb ] ) with @xmath94 ; b.   minimax estimators : @xmath417 by ( [ b+ ] ) , @xmath102 by ( [ mb ] ) with @xmath94 or @xmath418 for some large @xmath47 , @xmath419 by ( [ a+ ] ) with @xmath420 and @xmath313 .",
    "recall that @xmath421 corresponds to @xmath94 or @xmath422 and @xmath423 corresponds to @xmath424 with @xmath311 .",
    "in contrast , letting the diagonal elements of @xmath217 tend to @xmath57 in any direction in @xmath95 and @xmath102 leads to @xmath15 . setting @xmath217 to 0 or @xmath57",
    "is used here to specify the relevant estimators , rather than to restrict the prior on @xmath3 .    for completeness",
    ", we also study the following estimators : @xmath425 by ( [ b+ ] ) , @xmath95 with @xmath111 replaced by @xmath112 in ( [ rb ] ) , @xmath102 with @xmath109 replaced by @xmath110 in ( [ mb ] ) , and @xmath419 with @xmath426 replaced by @xmath427 in ( [ a+ ] ) , referred to as the alternative versions of @xmath428 , @xmath95 , @xmath102 , and @xmath429 respectively .",
    "the usual choices of the factors , @xmath111 , @xmath109 , and @xmath426 , are motivated to minimize the risks of the non - positive - part estimators , but may not be the most desirable for the positive - part estimators . as seen below , the alternative choices @xmath112 , @xmath110 , and @xmath430 can lead to risk curves for the positive - part estimators rather different from those based on the usual choices @xmath431 , @xmath109 , and @xmath426 .",
    "therefore , we compare the estimators @xmath432 , @xmath95 , @xmath102 , and @xmath419 and , separately , their alternative versions .",
    "each estimator @xmath7 is evaluated by the pointwise risk function @xmath433 as @xmath3 moves in a certain direction or the bayes risk function @xmath434 as @xmath435 varies in a set of priors on @xmath3 .",
    "consider the homoscedastic prior @xmath436 or the heteroscedastic prior @xmath437 for @xmath438 .",
    "as discussed in section  [ sec3.3 ] , the bayes risk with the first or second prior is meant to measure average risk reduction over the region @xmath439 or @xmath440 .",
    "corresponding to the two priors , consider the direction along @xmath441 or @xmath442 , where @xmath197 gives the euclidean distance from 0 to the point indexed by @xmath197 .",
    "the two directions are referred to as the homoscedastic and heteroscedastic directions .",
    "we investigate several configurations for @xmath14 , including ( [ example ] ) and @xmath443 where @xmath444 is a chi - squared variable with @xmath285 degrees of freedom . in the last case ,",
    "@xmath445 can be considered a typical sample from a scaled inverse chi - squared distribution , which is the conjugate distribution for normal variances . in the case ( [ example - group3 ] ) , the coordinates may be segmented intuitively into three groups with relatively homogeneous variances . in the case ( [ example - group22 ] ) , there is no clear intuition about how the coordinates should be segmented into groups .    for fixed @xmath14 ,",
    "the pointwise risk @xmath433 is computed by repeatedly drawing @xmath446 and then taking the average of @xmath447 .",
    "the bayes risk is computed by repeatedly drawing @xmath92 and @xmath448 and then taking the average of @xmath447 .",
    "each monte carlo sample size is set to @xmath449 .",
    "axis ( third row ) in the case ( [ example - group3 ] ) . left : non - minimax estimators @xmath63 ( @xmath450 ) , @xmath95 ( @xmath451 ) , @xmath64 ( @xmath452 ) .",
    "right : minimax estimators @xmath417 ( @xmath453 ) , @xmath102 with @xmath94 ( @xmath454 ) and @xmath455 ( @xmath456 ) , @xmath419 with @xmath420 ( @xmath457 ) and @xmath458 ( @xmath459 ) . ]",
    "axis ( third row ) in the case ( [ example - group3 ] ) , with the same legend as in figure  [ fig1 ] .",
    "the alternative versions of @xmath428 , @xmath460 , @xmath102 , and @xmath419 are used . ]      the relative performances of the estimators are found to be consistent across different configurations of @xmath14 studied . moreover , the bayes risk curves under the homoscedastic prior are similar to the pointwise risk curves along the homoscedastic direction .",
    "the bayes risk curves under the heteroscedastic prior are similar to the pointwise risk curves along the heteroscedastic direction .",
    "figure  [ fig1 ] shows the pointwise risks of the estimators with the usual versions of @xmath428 , @xmath95 , @xmath102 , and @xmath419 and figure  [ fig2 ] shows those of the estimators with the alternative versions of @xmath428 , @xmath95 , @xmath102 , and @xmath419 for the case ( [ example - group3 ] ) , with roughly three groups of coordinate variances , which might be considered unfavorable to our approach . for both @xmath310 and @xmath313 , the cutoff index @xmath257 is found to be 3 .",
    "see the supplementary material ( tan @xcite ) for the bayes risk curves of all these estimators for the case ( [ example - group3 ] ) and the results for other configurations of @xmath14 .",
    "a number of observations can be drawn from figures  [ fig1][fig2 ] .",
    "first , @xmath461 , @xmath64 , and @xmath95 have among the lowest risk curves along the homoscedastic direction . but along the heteroscedastic direction , the risk curves of @xmath63 and @xmath64 rise quickly above the constant risk of @xmath29 as @xmath197 increases .",
    "moreover , all the risk curves of @xmath63 , @xmath64 , and @xmath95 along the @xmath462 axis exceed the constant risk of @xmath29 as @xmath463 increases .",
    "therefore , @xmath63 , @xmath64 , and @xmath460 fail to be minimax , as mentioned in section  [ sec2 ] .",
    "second , @xmath417 or @xmath464 has among the highest risk curve , except where the risk curves of @xmath63 and @xmath64 exceed the constant risk of @xmath29 along the heteroscedastic direction .",
    "the poor performance is expected for @xmath465 or @xmath464 , because there are considerable differences between the coordinate variances in ( [ example - group3 ] ) .",
    "third , among the minimax estimators , @xmath419 with @xmath420 or @xmath313 has the lowest risk curve along various directions , whether the usual versions of @xmath428 , @xmath466 , and @xmath419 are compared ( figure  [ fig1 ] ) or the alternative versions are compared ( figure  [ fig2 ] ) .",
    "fourth , the risk curve of @xmath419 with @xmath420 is similar to that of @xmath419 with @xmath467 along the heteroscedastic direction .",
    "but the former is noticeably higher than the latter along the homoscedastic direction as @xmath197 increases , whereas is noticeably lower than the latter along the @xmath462 axis as @xmath463 increases .",
    "these results agree with the construction of @xmath310 using a heteroscedastic prior and @xmath313 using a flat , homoscedastic prior .",
    "their relative performances depend on the direction in which the risks are evaluated .",
    "fifth , @xmath102 with @xmath94 has risk curves below that of @xmath417 or @xmath464 , but either above or crossing those of @xmath419 with @xmath420 and @xmath458 .",
    "moreover , @xmath102 with @xmath455 has elevated , almost flat risk curves for @xmath197 from 0 to 16 .",
    "this seems to indicate an undesirable consequence of using a non - degenerate prior for @xmath102 in that the risk tends to increase for @xmath3 near 0 , and remains high for @xmath3 far away from 0 .",
    "the foregoing discussion involves the comparison of the risk curves as @xmath3 moves away from 0 between @xmath102 and @xmath468 specified with fixed priors .",
    "alternatively , we compare the pointwise risks at @xmath469 or @xmath442 and the bayes risks under the prior @xmath470 or @xmath471 between @xmath102 and @xmath357 specified with the prior @xmath470 for a range of @xmath197 .",
    "the homoscedastic prior used in the specification of @xmath102 and @xmath357 can be considered correctly specified or misspecified , when the bayes risks are evaluated under , respectively , the homoscedastic or heteroscedastic prior or when the pointwise risks are evaluated along the homoscedastic or heteroscedastic direction .",
    "for each situation , @xmath357 has lower pointwise or bayes risks than @xmath102",
    ". see figure a2 in the supplementary material ( tan @xcite ) .",
    "the estimator @xmath267 and its positive - part version @xmath472 are not only minimax and but also have desirable properties including simplicity , interpretability , and effectiveness in risk reduction .",
    "in fact , @xmath267 is defined by taking @xmath473 in a class of minimax estimators @xmath126 .",
    "the simplicity of @xmath267 holds because @xmath126 is of the linear form @xmath474 , with @xmath39 and @xmath31 indicating the direction and magnitude of shrinkage .",
    "the interpretability of @xmath269 holds because the form of @xmath268 indicates that one group of coordinates are shrunk in the direction of berger s",
    "@xcite minimax estimator whereas the remaining coordinates are shrunk in the direction of the bayes rule .",
    "the effectiveness of @xmath267 in risk reduction is supported , in theory , by showing that @xmath269 can achieve close to the minimum bayes risk simultaneously over a scale class of normal priors ( corollary  [ cor4 ] ) . for various scenarios in our numerical study ,",
    "the estimators @xmath475 with extreme priors yield more substantial risk reduction than existing minimax estimators .",
    "it is interesting to discuss a special feature of @xmath154 and hence of @xmath118 and @xmath126 among linear , shrinkage estimators of the form @xmath476 where @xmath39 and @xmath134 are nonnegative definite matrices and @xmath477 is a scalar function .",
    "the estimator @xmath154 corresponds to the choice @xmath478 , which is motivated by the form of the optimal @xmath31 in minimizing the risk of @xmath479 for fixed @xmath39 .",
    "on the other hand , berger and srinivasan @xcite showed that under certain regularity conditions on @xmath477 , an estimator ( [ general ] ) can be generalized bayes or admissible only if @xmath480 .",
    "this condition is incompatible with @xmath481 , unless @xmath482 as in berger s @xcite estimator .",
    "therefore , @xmath126 including @xmath267 is , in general , not generalized bayes or admissible .",
    "this conclusion , however , does not apply directly to the positive - part estimator @xmath200 , which is no longer of the linear form @xmath474 .",
    "there are various topics that can be further studied .",
    "first , the prior on @xmath3 is fixed , independently of data in the current paper .",
    "a useful extension is to allow the prior to be estimated within a certain class , for example , homoscedastic priors @xmath483 , from the data , in the spirit of empirical bayes estimation ( e.g. , efron and morris @xcite ) .",
    "second , the bayes risk with a normal prior is used to measure average risk reduction in an elliptical region ( section  [ sec3.3 ] ) .",
    "it is interesting to study how our approach can be extended when using a non - normal prior on @xmath3 , corresponding to a non - elliptical region in which risk reduction is desired .",
    "the following extends stein s @xcite lemma for computing the expectation of the inner product of @xmath484 and a vector of functions of @xmath29 .",
    "[ lem1 ] let @xmath485 be multivariate normal with mean @xmath3 and variance matrix @xmath2 .",
    "assume that @xmath486 is almost differentiable stein @xcite with @xmath487 for @xmath488 , where @xmath489",
    ". then @xmath490,\\ ] ] where @xmath491 is the matrix with @xmath492th element @xmath493 .",
    "a direct generalization of lemma  2 in stein @xcite to a normal random vector with non - identity variance matrix gives @xmath494 where @xmath495 is the row vector with @xmath91th element @xmath496 .",
    "taking the @xmath497th element of both sides of the equation gives @xmath498 where @xmath499 is the @xmath492th element of @xmath2 .",
    "summing both sides of the preceding equation over @xmath497 gives the desired result .",
    "proof of theorem  [ th1 ] by direct calculation , the risk of @xmath154 is @xmath500 by lemma  [ lem1 ] and the fact that @xmath501 , the third term after the minus sign in @xmath502 is @xmath503 by condition ( [ a - cond ] ) , @xmath504 is nonnegative definite . by section  21.14 and",
    "exercise 21.32 in harville @xcite , @xmath505 for @xmath506 .",
    "then the preceding expression is bounded from below by @xmath507 which leads immediately to the upper bound on @xmath508 .",
    "proof for condition ( [ a - cond2 ] ) we show that if condition ( [ a - cond2 ] ) holds , then there exists a nonsingular matrix @xmath134 with the claimed properties .",
    "the converse is trivially true .",
    "let @xmath509 be the unique symmetric , positive definite matrix such that @xmath510 .",
    "then @xmath511 is symmetric , that is , @xmath512 , because @xmath513 .",
    "moreover , @xmath514 and @xmath511 commute , that is , @xmath515 , because @xmath516 and @xmath511 is symmetric .",
    "therefore , @xmath517 and @xmath511 are simultaneously diagonalizable ( harville @xcite , section  21.13 ) .",
    "there exists an orthogonal matrix @xmath208 such that @xmath518 and @xmath519 for some diagonal matrices @xmath14 and @xmath188 .",
    "then @xmath520 satisfies the claimed properties .",
    "proof of inequality ( [ bayes - bound2 ] ) we show that if @xmath521 are independent standard normal variables , then @xmath522 .",
    ". then @xmath524 and @xmath525 are independent , @xmath526 , and @xmath527 .",
    "the claimed inequality follows because @xmath528 , @xmath529 , and @xmath530 @xmath531 by jensen s inequality .",
    "proofs of theorem  [ th2 ] and corollary  [ cor2 ] consider the transformation @xmath532 and @xmath533 , so that @xmath534 and @xmath535 .",
    "problem ( [ opt ] ) is then transformed to @xmath536 , subject to @xmath537 ( @xmath538 ) and @xmath539 , which is of the form of the special case of ( [ opt ] ) with @xmath540 ( @xmath250 ) .",
    "but it is easy to verify that if the claimed results hold for the transformed problem , then the results hold for original problem ( [ opt ] ) .",
    "therefore , assume in the rest of proof that @xmath540 ( @xmath250 )",
    ".    there exists at least a solution , @xmath268 , to problem ( [ opt ] ) by boundedness of the constraint set .",
    "let @xmath541 and @xmath542 .",
    "a key of the proof is to exploit the fact that , by the setup of problem ( [ opt ] ) , @xmath289 is automatically a solution to the problem @xmath543 the karush ",
    "tucker condition for this problem gives @xmath544 where @xmath31 , @xmath545 ( @xmath546 ) , and @xmath547 satisfying @xmath548 ( @xmath250 ) are lagrange multipliers .",
    "first , we show that @xmath549 and hence @xmath550 for @xmath253 .",
    "if @xmath551 , then either @xmath549 for @xmath250 , or @xmath552 .",
    "the latter case is infeasible by the constraint @xmath553 .",
    "suppose @xmath554 . by ( [ a2 ] ) , @xmath549 for each @xmath555 .",
    "then @xmath556 for each @xmath557 because @xmath558 .",
    "second , we show that @xmath259 . if @xmath551 , then @xmath559 .",
    ". then @xmath560 by ( [ a2 ] ) . summing ( [ a3 ] ) over @xmath561 and ( [ a4 ] ) shows that @xmath562 .",
    "therefore , @xmath563 or equivalently @xmath259 .",
    "third , we show that @xmath564 and @xmath565 . for each @xmath566 and @xmath567 ,",
    "@xmath568 by ( [ a2])([a3 ] ) and then @xmath569 because @xmath558",
    ". the inequalities also hold for @xmath276 , by application of the argument to problem ( [ a1 ] ) with @xmath257 replaced by some @xmath566 .",
    "then @xmath570 because @xmath571 for each @xmath555 , @xmath572 , and @xmath257 is the largest element in @xmath573 .",
    "fourth , we show the expressions for @xmath574 and the achieved maximum value . by the definition of @xmath573 ,",
    "@xmath575 for @xmath576 . by ( [ a2 ] ) , @xmath577 for @xmath578 .",
    "let @xmath579 and @xmath580 .",
    "then @xmath581 is a solution to the problem @xmath582 by the definition of @xmath573 , @xmath583 and hence @xmath584 lies off the boundary in the constraint set .",
    "then @xmath581 is a solution to the foregoing problem with the constraint @xmath585 removed .",
    "the problem is of the form of maximizing a linear function of @xmath586 subject to an elliptical constraint .",
    "straightforward calculation shows that @xmath587 and the achieved maximum value is @xmath588 , where @xmath589 @xmath590 .",
    "finally , we show that the sequence @xmath591 is nonincreasing : @xmath273 , where the equality holds if and only if @xmath592 . because @xmath593 or @xmath594 , this result implies that @xmath595 and hence @xmath268 is a unique solution to ( [ opt ] ) .",
    "let @xmath596 so that @xmath597 . by the identity",
    "@xmath598 and simple calculation , @xmath599 \\frac { d_{k+1}^{-1}}{\\sum_{j=1}^{k+1 } d_j^{-1 } } \\nonumber \\\\[-6pt ] \\\\[-10pt ] & = & d_{k+1 } \\frac { \\ { r_k - ( k-2 ) \\}^2}{r_k ( r_k+1)},\\nonumber\\end{aligned}\\ ] ] where @xmath600 .",
    "therefore , @xmath601 .",
    "moreover , @xmath602 if and only if @xmath603 , that is , @xmath604 .",
    "proof of corollary  [ cor3 ] it suffices to show ( [ sol - ineq ] ) . by corollary  [ cor2 ] , @xmath605 and hence @xmath606 .",
    "then for @xmath294 .",
    "@xmath607 because @xmath608 for @xmath609 .",
    "proof of theorem  [ th3 ] let @xmath610 so that @xmath611 , similarly as in the proof of theorem  [ th2 ] . by equation ( [ a5 ] ) with @xmath612 and @xmath613 replaced by @xmath614 , @xmath615 by the relationship @xmath616 and simple calculation ,",
    "@xmath617 if @xmath340 , combining the two preceding equation gives @xmath618 the first inequality follows because @xmath619 for @xmath620 and @xmath621 is increasing for @xmath622 with a maximum at @xmath623 .",
    "the second inequality follows because @xmath624 .",
    "therefore , if @xmath340 then @xmath625 if @xmath338 , then @xmath626 and hence @xmath627 this completes the proof .",
    "the author thanks bill strawderman and cunhui zhang for helpful discussions ."
  ],
  "abstract_text": [
    "<S> consider the problem of estimating a multivariate normal mean with a known variance matrix , which is not necessarily proportional to the identity matrix . </S>",
    "<S> the coordinates are shrunk directly in proportion to their variances in efron and morris ( _ j . </S>",
    "<S> amer . </S>",
    "<S> statist . </S>",
    "<S> assoc . _ </S>",
    "<S> * 68 * ( 1973 ) 117130 ) empirical bayes approach , whereas inversely in proportion to their variances in berger s ( _ ann . </S>",
    "<S> statist . </S>",
    "<S> _ * 4 * ( 1976 ) 223226 ) minimax estimators . </S>",
    "<S> we propose a new minimax estimator , by approximately minimizing the bayes risk with a normal prior among a class of minimax estimators where the shrinkage direction is open to specification and the shrinkage magnitude is determined to achieve minimaxity . </S>",
    "<S> the proposed estimator has an interesting simple form such that one group of coordinates are shrunk in the direction of berger s estimator and the remaining coordinates are shrunk in the direction of the bayes rule . </S>",
    "<S> moreover , the proposed estimator is scale adaptive : it can achieve close to the minimum bayes risk simultaneously over a scale class of normal priors ( including the specified prior ) and achieve close to the minimax linear risk over a corresponding scale class of hyper - rectangles . </S>",
    "<S> for various scenarios in our numerical study , the proposed estimators with extreme priors yield more substantial risk reduction than existing minimax estimators . </S>"
  ]
}