{
  "article_text": [
    "recent years have seen tremendous progress in the development of computer vision algorithms for semantic tasks such as image classification  @xcite , object detection  @xcite , and semantic segmentation  @xcite , with most modern state - of - the - art methods based on convolutional neural networks .",
    "these methods owe much of their success to the availability of large image datasets  @xcite with ground truth data collected through human annotation . to build datasets at such scales ,",
    "researchers have had to rely on images freely shared by regular users .",
    "but the statistics of photographs people upload to a photo - sharing website could be different from those a vision system encounters while operating .",
    "this is a concern since modern methods are not only trained , _ but also evaluated _",
    ", on these datasets .",
    "in particular , there is significant potential for a disparity between the low - level statistics of images a vision algorithm receives as training input , and publicly shared photographs .",
    "this is because users tend to upload photographs , often selected from among multiple trials of capturing the same object , that are high - quality and free of artifacts  saturation , distortions , and motion and defocus blur . in this paper , we concentrate on blur , since it is quite easy to end up with a blurred image even with a high - quality camera , especially in a setting where the user is not concerned about image quality ( , when the image is being taken for a vision application , rather than for photography ) , or when the image is being captured automatically by a device or robot .",
    "we are also motivated by the recent findings of dodge and karam  @xcite , who show that existing image classification networks exhibit significant lower accuracies when evaluated on images with gaussian blur .",
    "we conduct a systematic survey of the effect of blur on the performance of convolutional neural networks for image recognition .",
    "we begin by evaluating pre - trained network models on images degraded with a range of different blurs , and reach a similar conclusion as @xcite : state - of - the - art networks trained on sharp image datasets make unreliable predictions when evaluated on blurry images .",
    "moreover , we find that these unreliable predictions are accompanied by underlying high - entropy class distributions ( , see fig .",
    "[ fig : teaser ] ) .",
    "this is encouraging since it can allow vision systems using these networks to account for the low - confidence of their predictions ( and , say , ask the user to take another image ) .",
    "we also examine the interaction between blur and multi - scale processing : applying the trained network at multiple resized versions of the input image is commonly used as a way to build robustness to variations to the relative scale of objects in the image .",
    "however , we find that the inclusion of larger sized versions is detrimental when blur may be present , since it exaggerates the effect of such blur .",
    "next , we demonstrate that much of this performance degradation is an artifact of these models being trained only on sharp images , rather than due to an intrinsic absence of information in blurry images , or a deficiency in the networks architectures . by fine - tuning with a mix of blurry and sharp images for only three epochs , we find that a network trained only on sharp images is able to recover most of its lost accuracy on blurry images . in these experiments , we also investigate the role of uncertainty about the nature of blur in the input , by fine - tuning over different distributions of blur .",
    "we find that a model fine - tuned with a fairly diverse range of blurs performs reasonably well , and is only slightly less accurate than a network that is trained and evaluated on a single blur level ( which in - turn performs worse on other blur levels ) .",
    "this demonstrates the ability of the network to learn a level of blur _ invariance _ , which we further examine by comparing the activations for a sharp and blurred image pair , at different layers in the network .",
    "finally , in addition to image classification , we find that these observations also largely carry over to the task of semantic segmentation , where fine - tuning with blurry images is able to improve accuracy in both identifying and localizing objects in blurred images .    broadly , our findings reinforce the fact that convolutional neural networks are resilient  when presented with an out - of - distribution input , they are able to signal a low - confidence in their predictions , and are quickly able to adapt when provided with additional training data , without any modification in architecture .",
    "moreover , our experiments provide useful insight for designing vision systems that need to reason with potentially blurred images in a practical , non - idealized , setting .",
    "blur is a degradation in image quality caused by camera sensor pixels averaging light from overlapping regions in the scene , typically due to defocus or motion in the capture interval . often , an observed blurry image can be well - modeled as a convolution of a _ latent _ sharp image ( , the image that would have been captured in the absence of blur ) , and a blur kernel or point - spread - function . in the case of defocus blur , this kernel is an image of the lens aperture ( typically a disk ) scaled by a factor proportional to the distance of the imaged object from the focal plane . for motion blur , it is the projection of the moving object or camera s trajectory during the exposure interval",
    ". both kinds of blur kernels are `` low - pass '' filters , , they lead to a loss or attenuation of high - frequency image detail .    reversing the effect of blur to obtain a sharp image from a blurred observation is an ill - posed inverse problem , especially when the blur is unknown .",
    "graphics and vision researchers have made significant progress on this problem across the last decade  @xcite  including with recent neural network - based methods  @xcite .",
    "nevertheless , image deblurring remains a challenging and computationally expensive task .",
    "however , our goal in this paper is different . instead of processing blurred images to recover sharp photographs for human consumption , we seek to understand , and ameliorate , the effect of using these images as input to algorithms for recognition .",
    "nearly all state - of - the - art computer vision algorithms for semantic visual tasks rely on the use of convolutional neural networks  @xcite .",
    "critical to their success is the ability to train on large annotated datasets , like imagenet  @xcite and pascal voc  @xcite  both of which contain photographs downloaded from the photo sharing website flickr.com .",
    "therefore , these datasets contain images that users  amateurs and professional photographers alike  have _ chosen _ to upload , and are consequently of high - quality with few artifacts .",
    "since standard recognition benchmarks perform their evaluation on held - out portions of the same dataset , the reported performance of state - of - the - art algorithms can at best be interpreted to accurately characterize their expected accuracy on similar high - quality image data . to address this ,",
    "dodge and karam  @xcite recently carried out an evaluation of standard neural network - based methods for image classification on images degraded by gaussian blur , and reported a significant drop in classification accuracy .",
    "karahan  @xcite perform a similar evaluation for face - recognition , while ullman  @xcite contrasted the drop in the accuracy of computational recognition to that of humans .",
    "we too study the classification accuracy of pre - trained networks on blurry images  for a larger family of realistic blur kernels  and find a similar drop in performance . however , we find that while networks trained on sharp images make erroneous predictions on blurred input , they do so with low - confidence .",
    "moreover , we show that this drop is mainly caused by the high - quality bias in the images used for training these networks , and that performance on blurred images can be significantly improved with adding such images to the training set  without requiring a change in their architecture .",
    "we also examine the ability of the networks to learn to perform consistently across a diversity of possible blurs , and find that these networks are able to do so by learning feature representations that are invariant to blur .",
    "finally , we investigate the impact of blur on a different task  semantic segmentation .",
    "we find that blur affects the ability of pre - trained networks to both identify and localize objects , but that like for classification , this ability can be recovered to a considerable extent by training with blurred images .",
    "therefore , we find that convolutional neural networks can succeed despite degradations in image quality from blur .",
    "this is consistent with such networks having been used quite successfully for the classification of very low - quality images , albeit on smaller benchmarks , cifar-100  @xcite that contains extremely low - resolution images of size @xmath0 . in this context , recently peng  @xcite explored the potential of jointly training with high - resolution images to boost performance on low - resolution inputs .",
    "our work also demonstrates the success of neural networks in the face of lower image quality , with joint training with images of varying quality , to deal with degradation due to optical blur for large - scale visual recognition .",
    "finally , it is worth noting here the work of szegedy  @xcite , who found that specific small - magnitude perturbations could cause network models to produce erroneous estimates .",
    "however , these perturbations were not random , and determined through an optimization process .",
    "in contrast , our focus is on errors due to a naturally prevalent form of image degradation  blur .",
    "we begin by evaluating the performance of state - of - the - art convolutional neural network models ",
    "vgg-16  @xcite and resnet  @xcite  on blurred versions of the imagenet  @xcite standard 2012 validation set .",
    "these models were trained on the imagenet training set that comprised of largely sharp , high - quality images .",
    "we generate the blurred versions of the validation set by convolving the original sharp images with a range of different blur kernels .",
    "note that both @xcite and @xcite resize their input to one or more pre - determined scales ( to match their smaller side to the scale value ) , and then compute class probability distributions by feeding this resized image to their network model .",
    "however , images in the imagenet dataset are of various sizes",
    ". therefore , rather than blur the original images directly , we first resize the image to a fixed scale ( 384 in our experiments ) and then convolve the result with the blur kernel .",
    "this ensures that the effective blur for a chosen kernel is consistent across images , irrespective of their original size .",
    "we then quantize the blurred intensities to form 8-bit images , which are then further rescaled and fed into the classification networks .",
    "we begin by reporting the performance vgg-16 network  @xcite for a diverse set of blur kernels in table  [ tab : origall ] .",
    "we consider disk kernels of different radii @xmath1 ( that have a constant value within their radius , and zero outside ) to simulate defocus blur , and with horizontal and vertical box kernels of single pixel width and different lengths that correspond to motion blur ( for uniform linear motion ) . like @xcite",
    ", we also report results on blurring with gaussian kernels of different standard deviations @xmath2 .",
    "all kernels are normalized to be unit sum , , they have a `` dc value '' of one .",
    ".top-5 accuracy on sharp and blurred versions of imagenet val images , using the original * vgg-16 * network that was trained on sharp images .",
    "we report performance for applying the network at different scales , where the input images were resized to make their smaller side fit the indicated scale value . [ cols=\"^,^,^,^,^ \" , ]",
    "state - of - the - art network models trained on high - quality image datasets make unreliable , albeit low - confidence , predictions when they encounter blur in their inputs . in this work",
    ", we found that much of this unreliability is due to an inability to generalize from their sharp training sets , and that fine - tuning these models for a relatively small number of epochs with blurred training examples significantly improves their performance on blurry inputs .",
    "moreover , we showed that standard architectures are able to deal with a diverse range of blurs , by learning to produce internal representations that are invariant to blur .",
    "our analysis provides insights for building and deploying vision systems in real - world settings where blur may be present .",
    "more broadly , we expect our findings to be relevant for other forms of imaging non - idealities beyond blur . in future work",
    ", we plan to explore un - supervised ways of achieving robustness to image artifacts , when we have access to examples of distorted natural images , but not to a precise model for the distortion ."
  ],
  "abstract_text": [
    "<S> state - of - the - art algorithms for semantic visual tasks  such as image classification and semantic segmentation  are based on the use of convolutional neural networks . </S>",
    "<S> these networks are commonly trained , and evaluated , on large annotated datasets of high - quality images that are free of artifacts . in this paper , we investigate the effect of one such artifact that is quite common in natural capture settings  blur . </S>",
    "<S> we show that standard pre - trained network models suffer a significant degradation in performance when applied to blurred images . </S>",
    "<S> we investigate the extent to which this degradation is due to the mismatch between training and input image statistics . </S>",
    "<S> specifically , we find that fine - tuning a pre - trained model with blurred images added to the training set allows it to regain much of the lost accuracy . by considering different combinations of sharp and blurred images in the training set , </S>",
    "<S> we characterize how much degradation is caused by loss of information , and how much by the uncertainty of not knowing the nature and magnitude of blur . </S>",
    "<S> we find that by fine - tuning on a diverse mix of blurred images , convolutional neural networks can in fact learn to generate a blur invariant representation in their hidden layers . </S>",
    "<S> broadly , our results provide practitioners with useful insights for developing vision systems that perform reliably on real world images affected by blur . </S>"
  ]
}