{
  "article_text": [
    "@xmath0-machine reconstruction or computational mechanics is an approach to discover the nature of patterns and to quantify it @xcite . building from information theory concepts",
    ", it has found applications in several fields and proved its value in a number of context@xcite .",
    "its use in statistical mechanics allows to define and calculate magnitudes that complements thermodynamic quantities such as entropy , specific heat , correlation length or structure factor@xcite . for a stochastic process considered to be stationary ,",
    "the @xmath0-machine is its optimal minimal description , understood , as having the best ( most accurate ) predictive power while using the least possible resources ( minimal statistical complexity)@xcite . in computational mechanics ,",
    "the notion of causality is taken in a general temporal sense , in a given context , cause to effect relations are established between past to future events@xcite .    although a general framework , computational mechanics has been thoroughly developed for discrete time and space process by several authors @xcite .",
    "one of the earlier developments in computational mechanics has been the analysis of patterns in one dimensional spin systems under ising - type models@xcite .",
    "the use of the @xmath0-machine reconstruction for the one dimensional ising model allowed the analysis of such systems as a deterministic finite state machine , and close expressions for the entropy density , statistical complexity and excess entropy were found@xcite .",
    "unfortunately , this treatments failed to understand that the ising model has to be considered a markov ( gibbs ) random field in order to correctly determine the probability measure of the associated markov process@xcite .",
    "the failure of not considering correctly the markov random field , leads to incorrect expressions for the stochastic matrix governing the conditional probability between spin blocks . as a consequence ,",
    "all quantitative results derived from such matrix are incorrect and this includes the determination of the causal states , the statistical complexity , the entropy density and the excess entropy .",
    "this includes the worked example on the ising 1/2-nearest neighbor model and next nearest neighbor model .    in this contribution",
    "the framework of computational mechanics for the ising model from the most general setting in one dimension is developed .",
    "it is shown how to obtain the stochastic matrix from the markov field : an inverse problem not usually treated on the literature .",
    "the results goes beyond correcting the mathematical treatment .",
    "an important consequence of the presented mathematical development is whether is it possible to cast the ising model , in the general case , a single emission spin sequential process .",
    "we finally show the use of the developed framework via three examples .    the paper is organized as follows . in section [ sec : intr ] the transfer matrix method for the ising model",
    "is shortly reviewed for self - completeness and to fix the used notation . in section [ sec : randomfield ] we describe the ising model as a random field and deduce the expression for the stochastic conditional matrix . in section [ sec :",
    "epsilonmachine ] , building from the previous sections , the @xmath0-machine formalism for the ising model is discussed and the entropic magnitudes are introduced .",
    "finally , in section [ sec : example ] worked examples applying the developed mathematical tools is presented .",
    "conclusions follow .",
    "the ising ( -lenz ) model is probably the most studied lattice type model in statistical mechanics , and is well covered in several statistical physics books for nearest 1/2 spin neighbor interactions@xcite .",
    "let us briefly recap , for completeness and notation purposes , the basic ideas of the transfer matrix formalism ( we closely follow dobson@xcite ) but in a general setting of a local type interaction hamiltonian which is usually not found in texts .",
    "consider an one dimensional chain of discrete values of length @xmath1 : @xmath2 where @xmath3 can take values from a finite alphabet @xmath4 of cardinality @xmath5 ( there will be @xmath6 possible sequences @xmath7 ) .",
    "each individual @xmath3 is called a spin . the interaction energy between spins of the sequence",
    "has a finite range @xmath8 such that it can be written as @xmath9    the @xmath7 sequence can be partitioned into blocks of length @xmath8 , considering @xmath10 , @xmath11[s_{n}s_{n+1}\\ldots s_{2n-1}]\\ldots [ s_{(n-1)n}s_{(n-1)n+1}\\ldots s_{nn-1}],\\ ] ] which can be relabeled @xmath12[s^{(1)}_{0}s^{(1)}_{1}\\ldots s^{(1)}_{n-1}]\\ldots [ s^{(n-1)}_{0}s^{(n-1)}_{1}\\ldots s^{(n-1)}_{n-1 } ] .   \\\\",
    "& = \\eta_{0}\\eta_{1}\\ldots \\eta_{n-1}.\\end{array}\\ ] ] where @xmath13 the set of all possible blocks @xmath14 will be denoted by @xmath15 with cardinality @xmath16 .",
    "@xmath15 will be taken as an ordered set ( e.g lexicographic order ) and to each @xmath14 a natural number , between @xmath17 and @xmath18 , will be assigned . in",
    "what follows , @xmath14 should be understood not only as the configuration ( [ eta ] ) but also as its corresponding order in the set @xmath15 , context will eliminate any ambiguity .    as the interaction energy has range @xmath8 , one spin corresponding to the @xmath14 block , can only interact with all the spins within @xmath14 ( type i ) and at least one spin from the adjacent blocks @xmath19 ( type ii ) .",
    "taking into account that @xmath20 , the interaction energy of type i for the @xmath21 block , in the presence of an external field b , will be @xmath22 which defines a vector @xmath23 of length @xmath24 .",
    "the contribution of type ii will be denoted by @xmath25 , and will be given by @xmath26 which defines a @xmath27 matrix .",
    "in general @xmath28 which makes @xmath29 non symmetric . the energy of the whole configuration @xmath30 can then be written as @xmath31    the vector @xmath32 and the matrix @xmath33 are then introduced as @xmath34 @xmath35.\\label{vmatrix}\\ ] ] where @xmath36 is the boltzmann product .",
    "@xmath33 is known as the transfer matrix .",
    "the partition function follows @xmath37 \\\\ \\\\",
    "= \\langle u | v^{n-1 } | u\\rangle\\end{array},\\label{eq : partition}\\ ] ] for open ( free ) boundary conditions . for close ( periodic ) boundary conditions @xmath38 @xmath39",
    "denotes the trace of the matrix @xmath40 .",
    "as the trace of a matrix is invariant to similarity transformations , from equation ( [ eq : znperiodic ] ) for close boundary conditions @xmath41 follows .",
    "@xmath42 are the eigenvalues of the matrix @xmath33 .",
    "if @xmath42 is degenerate , then the term is added as much times as its multiplicity .",
    "if the eigenvalues are labeled in non increasing order ( @xmath43 ) , then for @xmath44 @xmath45 where @xmath46 is known as the dominant eigenvalue and , according to the perron - frobenius theorem , it is real , positive and non - degenerate@xcite .    for open boundary conditions , using again the perron- frobenius theorem for a square positive defined matrix @xmath33 , the following holds @xmath47 where @xmath48 y @xmath49 are respectively , the left and right eigenvectors corresponding to the dominant eigenvalue .",
    "the eigenvectors are normalized in the sense of @xmath50 .",
    "the matrix @xmath51 is known as perron projection matrix . using ( [ eq : pf ] ) and ( [ eq : partition ] ) we arrive at @xmath52 which in the particular case of a diagonalizable matrix reduces to @xmath53 and @xmath54 are the components of the vector @xmath55 in the orthogonal base defined by the eigenvectors @xmath56 .",
    "it is well documented how the thermodynamic magnitudes can be obtained from the partition function @xcite .",
    "the probability of a given spin chain will be given by @xmath57 valid for free boundary conditions , and where we have written @xmath58 . ) , but the interpretation made of the parameters is different , as in @xcite the product appearing in the numerator is identified with the product of the eigenvectors , which is not the case . ] for periodic boundary conditions @xmath59asked in both cases @xmath44 .",
    "consider the spin chain divided in two half , the fist half will be called the past @xmath60 while the second half , called the future , is given by @xmath61 the spin @xmath62 is sometimes refered to as the present .    the known relation @xmath63 may tempt to use equations ( [ eq : prslabierto ] ) or ( [ eq : prslciclico ] ) , but one must be warned against doing so .",
    "both expressions must be understood as valid for whole systems ( spin chains ) and not for portions of the systems . in this way , @xmath64 in the denominator of ( [ eq : prsfuturospasado ] ) can not be taken as the probability of the isolated configuration @xmath65 instead , use must be made of the relation @xmath66 the reader can check that the result is not the same .",
    "this is at the heart of the failure in the mathematical treatment in [ @xcite ] the random field character of the system is overlooked .",
    "the ising model is a particular case of a gibbs random field@xcite . in a formal way ,",
    "a set of sites @xmath67 is given , together with a finite set @xmath15 of cardinality @xmath24 .",
    "there is a correspondence @xmath68 such that @xmath69 represents the configuration where each site @xmath70 has been assigned a value @xmath71 .",
    "@xmath72 is the set of all possible configurations .",
    "consider a probabilistic measure @xmath73 associated to the space @xmath72 .",
    "@xmath74 will be called a random field and @xmath14 will be random variables with stochastic dependence among them . for each @xmath71 the conditional probabilities @xmath75 are well defined , where @xmath76 denotes the configuration @xmath7 excluding site @xmath77 ( a better notation would had been @xmath78 , but the introduced one is sufficiently clear and convenient in what follows ) .",
    "the case of interest is one where it is not necessary to know the whole configuration @xmath76 to determine the probabilities ( [ eq : prrandom ] ) but it suffices to know the values @xmath79 in a subset @xmath80 , which is called neighborhood and complies with the conditions    1 .   for @xmath70",
    ", @xmath81 is a subset ( possibly empty ) of @xmath82 that does not contain @xmath77 .",
    "2 .   @xmath83    a markov random field is defined as one fulfilling @xmath84 these probabilities are called the local characteristics associated to @xmath73 .",
    "let @xmath85 for @xmath86 , @xmath87 , @xmath88 . then , with respect to this system of neighborhood of the markov random field , there is associated a markov chain @xmath89 .",
    "if @xmath76 is the configuration @xmath7 without considering the block @xmath14 , then , the probability @xmath90 that the @xmath77-block has value @xmath14 when all the other spins ( that is , excluding the @xmath14 block ) will have the configuration @xmath76 will be given by the product rule @xmath91 where the sum @xmath92 is over all configurations identical to @xmath7 except , possibly , for the block @xmath14 .",
    "using equation ( [ eq : prslabierto ] ) , the probability of a configuration will be @xmath93\\\\\\\\ & \\displaystyle=\\frac{1}{z_{nn } } e^{-\\beta x_{\\eta_{n-1}}}\\prod_{j=1}^{n-2}e^{-\\beta x_{\\eta_{j } } } e^{-\\beta y_{\\eta_{j}\\eta_{j+1 } } } \\end{array}\\ ] ] and , @xmath94 e^{-\\beta x_{\\eta_{i-1}}}\\\\\\\\ \\displaystyle \\sum_{\\eta_{k}}e^{-\\beta y_{\\eta_{i-1}\\eta_{k } } } e^{-\\beta x_{\\eta_{k } } } e^{-\\beta y_{\\eta_{k}\\eta_{i+1}}}. \\end{array}\\ ] ] for the local characteristics equation ( [ eq : prcaterva ] ) will now be @xmath95 for blocks @xmath14 not at the extremes .",
    "for the first block @xmath96 similar expression can be found for the last block .",
    "expression ( [ eq : caractloc ] ) has the important consequence that @xmath97    it must be noted that one of the consequence of equations ( [ eq : caractloc ] ) and ( [ eq : caractloceta0 ] ) , is that the probability of @xmath14 taking a particular value is conditional on the values of the immediate neighboring blocks , and not by the whole configuration @xmath76 , this determines the markov character of the random field .",
    "the stochastic matrix @xmath98 will be defined by @xmath99 which defines a transition probability from state @xmath100 to state @xmath101 . by definition @xmath102 . if @xmath103 is the vector of probabilities over the blocks @xmath14 then is well known that the stationary distribution@xcite is given by @xmath104 where @xmath105 is the left dominant eigenvector of the matrix @xmath98 .",
    "the vector @xmath103 allows to calculate @xmath106 when the markov process has been running for a sufficiently long time .",
    "the local characteristics can be written in terms of the stochastic matrix @xmath98 using bayes theorem @xmath107 similarly @xmath108 now equating both ( [ eq : protra ] ) and ( [ eq : protra1 ] ) @xmath109 where the markov character of the field has been used and the last step is justified by the total probability theorem ) shows that equation ( 7.6 ) and ( 7.15 ) in @xcite are flawed . ] .",
    "equation ( [ eq : localcstochstic ] ) can be rewritten as @xmath110 which forms , when written for each @xmath14 , an homogeneous system of quadratic forms .",
    "such system can have non trivial solution if it is undetermined , which happens in this case if the square of the number of unknown is larger than the number of equations .    as each local characteristic",
    "is determined by three @xmath111 s , there will be @xmath112 equations and @xmath113 unknowns .",
    "the relations @xmath114 must be added that eliminates @xmath115 unknowns .",
    "the total number of unknowns is then @xmath116 and the total number of equations @xmath117 .",
    "@xmath118 for @xmath119 , the system will also have non trivial solution as a result of the additional reduction of equations by the symmetry of the transfer matrix . returning to equation ( [ eq : localcstochstic1 ] ) and rewriting for any local characteristic @xmath120 introducing @xmath121 equation ( [ eq : localcstochstic2 ] )",
    "can be written as @xmath122 the normalization condition ( which can be derived from equation ( [ eq : localcstochstic ] ) ) over the local characteristics determines @xmath123 equation ( [ eq : localcstochstic3 ] ) is linear and homogeneous over the @xmath124 which , upon solving for the non trivial - case , leads to a system of simple homogeneous quadratic equations ( [ eq : yfunc ] ) which can be readily solved .",
    "the markov character of the system means that the generation process can forget of all the past except the last block @xmath125 ( the last @xmath8 spins ) , to determine , as certain as possible the future . in other words , if the local characteristics implies a stochastic matrix as equation ( [ eq : localcstochstic2 ] ) imply , then all past configuration @xmath65 with the same last block @xmath125 conditions ( statistically ) the same future , this fact allows to consider the ising chain as a canonical finite state machine known as @xmath0-machine .",
    "causal states are at the core of the computational mechanic framework@xcite . if two blocks @xmath125 and @xmath126 give the same @xmath127 , for all possible futures @xmath128 , then @xmath125 y @xmath126 are said to belong to the same causal state ( @xmath129 ) and we write @xmath130 .",
    "two blocks belonging to the same causal state @xmath129 define identical rows in the stochastic matrix .",
    "the partition of the set @xmath15 in classes of causal states is an equivalence relation complying with the transitivity condition ( if @xmath131 y @xmath132 then @xmath133 ) , symmetry ( if @xmath131 then @xmath134 ) and reflectivity ( @xmath135 ) . the set of causal state uniquely determines the future of a sequence .",
    "the set of all causal states will be denoted by @xmath136 with cardinality @xmath137 .",
    "a function @xmath0 can be defined over @xmath111 , @xmath138 which relates @xmath111 with its causal states @xmath139 , @xmath140    the probability of a ( recursive ) causal state is directly deducible from equation ( [ eq : prstac ] ) , @xmath141 as each causal state represents the set of past that determines ( probabilistically ) the same future , the set of causal state represents the memory the system has to keep in order to predict , as good as possible , the future .",
    "the statistical complexity has been defined as the shannon entropy over the causal states@xcite @xmath142 .",
    "\\end{array}\\label{eq : cmu}\\ ] ] the logarithm is usually taken in base two and the units are then bits . statistical complexity is a measure of how much memory ( resources ) the system needs to optimally predict the future .",
    "if the system has @xmath143 causal states then the statistical complexity has the upper bound @xmath144 corresponding to a uniform distribution of probabilities over the causal states .",
    "the relation follows from a known property of the shannon entropy .",
    "the upper bound of the statistical complexity is also known as topological entropy . as",
    "already stated , for a fixed number of causal states , the increase of statistical complexity is the result of a more uniform distribution over the causal state , in this sense such increase witness the increase of uncertainty over the occurrence of such states and therefore the unreductible entropy of the system ( e.g. thermal noise ) .",
    "the system needs more resources to account for the unpredictable behavior of the system .",
    "the probability of occurrence of block @xmath14 conditional on the causal state @xmath139 will be given by @xmath145 in the first step the total probability theorem was used , in the second step use has been made of the fact that conditioning in @xmath146 is equal to conditioning in @xmath147 if the block belongs to the causal state @xmath139 and , finally @xmath148 .",
    "@xmath149 now we make use of equation ( [ eq : pretac ] ) to get @xmath150 which allows to compute the occurrence of a block from the probabilities over the causal states .",
    "the probability of a transition from one causal state to other will be given by @xmath151    if we define the transition matrix @xmath152 , whose elements are the probability of going from state @xmath153 to state @xmath129 upon emitting a block @xmath111 : @xmath154 by construction , the emission of a block @xmath111 determines uniquely the causal state to where the transition occurs ( this is called the unifiliar property@xcite ) . in this sense ,",
    "the generation process is deterministic .",
    "correspondingly , the connectivity matrix @xmath155 is defined as @xmath156 which connects causal states without regard of the emitted block .",
    "an @xmath0-machine is defined by the causal state function @xmath0 , which relates histories with causal states and the transition matrices between them . in the case of the ising model ,",
    "the @xmath0-machine is represented by a deterministic finite state machine with vertex defined by the causal states and edges labeled according to the transition probabilities@xcite .    in order to account for the irreducible randomness ,",
    "the density of entropy is defined as@xcite @xmath157\\\\\\\\ & = \\lim_{l\\rightarrow \\infty } h[\\eta_{0}|\\overleftarrow{s}^{l } ] \\end{array}\\label{eq : hmiubloque}\\ ] ] @xmath158 is the uncertainty on the next emitted block @xmath159 conditional on having seen infinite previous blocks ( spins ) . by definition @xmath160 .",
    "@xmath161&=-\\sum_{\\eta_{0}}\\sum_{\\eta_{-n}}\\ldots \\sum_{\\eta_{-1 } } pr(\\overleftarrow{s}^{l}\\eta_{0})\\log pr(\\eta_{0}|\\overleftarrow{s}^{l})\\\\ \\\\ & = -\\sum_{\\eta_{0}}\\sum_{\\eta_{-n}}\\ldots \\sum_{\\eta_{-1 } } pr(\\eta_{0}|\\overleftarrow{s}^{l } ) pr(\\overleftarrow{s}^{l})\\log pr(\\eta_{0}|\\overleftarrow{s}^{l } ) \\end{array}\\label{eq : entropyrate1}\\ ] ] where @xmath162 , , on the other hand , using @xmath163 @xmath164 in the last step , use has been made of bayes theorem .",
    "substituting equation ( [ eq : prslbayesbloque ] ) on equation ( [ eq : entropyrate1 ] ) and reordering terms @xmath165=-\\sum_{\\eta_{0}}\\left [ \\sum_{\\eta_{-1 } } pr(\\eta_{0}|\\eta_{-1})pr(\\eta_{-1})\\log pr(\\eta_{0}|\\eta_{-1 } ) \\right.\\\\ \\\\ \\left . \\left \\ { \\sum_{\\eta_{-n}}\\ldots \\sum_{\\eta_{-2}}pr(\\overleftarrow{s}^{l - n}|\\eta_{-1})\\right \\}\\right ] , \\end{array}\\label{eq : hsslbloque}\\ ] ]",
    "now @xmath166 is the probability that from @xmath125 any configuration is conditioned and that probability is @xmath167 .",
    "equation ( [ eq : hsslbloque ] ) then reduces to @xmath168=h[\\eta_{0}|\\eta_{-1}]\\\\\\\\ & = -\\sum_{\\eta_{j}\\in \\sigma}pr(\\eta_{j})\\sum_{\\eta_{i}\\in \\sigma}pr(\\eta_{i}|\\eta_{j})\\log pr(\\eta_{i}|\\eta_{j})\\\\\\\\ & = -\\sum_{c_{\\alpha}\\in \\mathcal{c } } pr(c_{\\alpha})\\sum_{\\eta_{k } \\in \\sigma}pr(\\eta_{k}|c_{\\alpha})\\log pr(\\eta_{k}|c_{\\alpha } ) \\end{array}\\label{eq : entropyrateblock}\\ ] ]    the mutual information between past and future is called the excess entropy@xcite @xmath169,\\ ] ] where @xmath170 $ ] is the mutual information between @xmath171 e @xmath29 . from the finite range character of the interaction in the ising model @xmath172&=i[\\eta_{-1}:\\eta_{0}]\\\\ & \\\\ & = h[\\eta_{-1}]-h[\\eta_{0}|\\eta_{-1 } ] \\end{array}\\label{eq : excess}\\ ] ] where @xmath173=\\sum_{\\eta_{i}\\in \\sigma}pr(\\eta_{i})\\log pr(\\eta_{i}),\\label{eq : hetai}\\ ] ] and @xmath174=h[\\eta_{0}|\\overleftarrow{s}^{l}]=h_{\\mu}\\ ] ] given by equation ( [ eq : entropyrateblock ] ) .    from equation ( [ eq : cmu ] ) and ( [ eq : entropyrateblock ] ) we arrive to the expression @xmath175 excess entropy is a measure of the resources needed by the system in order to optimally predict the future , once the irreducible randomness has been subtracted@xcite . as @xmath176 is a mutual information",
    ", it will always be a non - negative value , which implies @xmath177 if the system is completely ordered then @xmath178 and @xmath179      the result , that in order to correctly derive the stochastic matrix , one needs the local characteristic of the markov field , points to fact that is not straight forward to cast a spacially extended process into a sequencial process . in the markov field , all spin values over the whole one dimensional lattice is given simultaneously .",
    "in general , the spin value at one site depends on the spin values to the right , as well as to the left , within the interaction range .",
    "it is the transfer matrix method that rewrites the whole system as a one over blocks of size equal to the interaction range , that allows to cast the dynamics of the system as markov process , but in doing so , the building blocks cease to be the individual spins and instead the @xmath111 blocks are the new individual entities .",
    "it is then , not straight forward to consider valid , if one can describe the @xmath0-machine process over single spin emission .",
    "this is contrast with previous treatment of the subject @xcite and some general conclusion derived from it @xcite . to exemplify the problems associated with defining the markov process over the emission of a single spin ,",
    "consider a general hamiltonian with interaction range @xmath180 , in such system a eight period perfect sequence is possible with probability larger than zero .",
    "the four state fsm with single spin emission is incapable of topologically reproducing such sequence .",
    "there is then the need to introduce `` bogus '' states additional to the @xmath111 blocks . yet",
    ", the stochastic matrix is well defined by the local characteristic over the @xmath111 blocks and the @xmath0-machine over block emission makes the introduction of unnatural states unnecessary .",
    "having said so , in what follows the markov process will be formally cast in terms of a single spin process to bridge the gap with the mathematical developments made before .",
    "in the previous treatment , the markov process has been constructed taking as a single event the emission of a whole block @xmath111 of length @xmath8 .",
    "other treatments have considered the markov process single event the emission of a single spin@xcite .",
    "let us introduce the operator @xmath181 such that if @xmath182 , then @xmath183 and @xmath184 has length @xmath185 .",
    "similarly @xmath186    the probability of emitting a single spin @xmath187 conditioned in being on the causal state @xmath139 will be denoted by @xmath188 .",
    "using equation ( [ eq : pretac ] ) , @xmath189 and the sum is over all configurations @xmath14 with spin @xmath187 .",
    "it is important to notice that upon emitting a spin @xmath190 a transition occurs from @xmath65 to @xmath191 which implies a new causal state to which @xmath192 belongs and which is uniquely determined by the generated spin .",
    "the transition @xmath193 conditional on the emission of spin @xmath190 , @xmath194 , is equal to 1 if the transition is allowed .",
    "if @xmath14 and @xmath195 are taken to belong to the same causal state @xmath139 , then by construction @xmath196 where @xmath197 is the set of all possible futures and @xmath198 is the operation of prefixing to each future the spin @xmath190 .",
    "it is clear that @xmath199 can be split into events : @xmath187 and @xmath200 , then @xmath201 using the product rule on both sides and taking into account that for three random variables @xmath171 , @xmath29 y @xmath202 , @xmath203 , @xmath204    and because @xmath205 is defined strictly positive , @xmath206 expression ( [ eq : equivs ] ) is equivalent to say that @xmath207 and @xmath208 belong to the same causal state and therefore , the emission of one spin determines uniquely the causal state transition .",
    "therefore , the following holds @xmath209 now , the transition matrix @xmath210 whose elements are the probability of making a transition from state @xmath153 to state @xmath129 upon emitting a spin @xmath190 , will be : @xmath211 and @xmath212 , @xmath213 .",
    "the transition matrix between causal states regardless of the emitted symbol will be given by @xmath214 where the left dominant eigenvector determines the probability of the causal state ( equation ( [ eq : prstac ] ) and ( [ eq : prcp ] ) ) .",
    "the statistical complexity @xmath215 follows .",
    "the entropy density will now be @xmath216\\ ] ] @xmath217 is now the uncertainty in the next emitted spin @xmath190 conditional of having observed infinite preceding spins in the past .",
    "now @xmath218=h[s|\\eta_{-1}]\\\\\\\\ & = -\\sum_{c_{\\alpha}\\in \\mathcal{c } } pr(c_{\\alpha})\\sum_{s \\in \\theta}pr(s|c_{\\alpha})\\log pr(s|c_{\\alpha } ) \\end{array}\\ ] ]    the excess entropy will now be @xmath219 @xmath8 is the interaction range ( the size of the @xmath111 blocks ) .",
    "the 1/2-spin ising model for the nearest neighbor interaction is defined by the interaction hamiltonian@xcite @xmath220 where @xmath221 is the external field , and @xmath222 is the interaction parameter .",
    "both parameters are independent .",
    "the @xmath111 blocks set will be @xmath223    the local characteristics derived from equation ( [ eq : caractloc ] ) reduce to @xmath224 solving the linear system of equation ( [ eq : localcstochstic3 ] ) , results in the system of quadratic equations @xmath225 together with the normalization conditions @xmath226 lead to the solution for @xmath227 and the other entries of the stochastic matrix follows .    from the stochastic matrix ,",
    "the two state @xmath0-machine was built and @xmath228 were calculated for @xmath229 points taking randomly the value of the parameters .",
    "the corresponding plot is shown in figure [ fig : nnising ] .",
    "this type of complexity map has been discussed before@xcite .",
    "small values of disorder can accommodate a large range of excess entropy values , which means varying probability between the two possible causal states . as disorder increases ,",
    "the system looses structure tending towards a single state process which although increasingly random is also increasingly less complex .      the 1/2-spin ising model for the next nearest neighbor interaction is defined by the interaction hamiltonian@xcite @xmath230 where @xmath221 is the external field , and @xmath231 , @xmath232 are spin coupling parameters . the @xmath111 blocks set",
    "will be @xmath233 we can take the value @xmath167 to correspond to spin up , whereas @xmath234 corresponds to spin down .",
    "figure [ fig : nnn ] shows the excess entropy as a function of @xmath231 and @xmath232 for the ground state ( @xmath235 ) at zero field ( @xmath236 ) and as a function of @xmath237 and @xmath238 for non - zero field ( @xmath239 ) .",
    "the excess entropy together with the @xmath0-machine reconstruction allows to distinguish four orderings of periodicity 1,2,3 and 4 , identified as the ordered sequences @xmath240 which are the expected phases@xcite .",
    "the pure ferromagnetic phase ( 1 ) and pure anti - ferromagnetic phase ( 2 ) are constructed from a single causal state , while ( 4 ) needs two causal states .",
    "the ordered phase ( 3 ) requires tree causal state and it only happens for @xmath239 .      consider a one dimensional random walk in which at each event the walker moves one step in the same direction as the previous event with probability @xmath241 ( the probability of changing the direction of movement is then @xmath242 ) , we also define the probability that the random walker will move to the right ( left ) at each event by @xmath243 ( @xmath244 ) .",
    "the described model is known as the persistent biased random walk@xcite and has been found to be isomorphous with the nearest neighbor ising chain .",
    "the developed formalism has been used to calculate the excess entropy as a function of the probabilities @xmath243 and @xmath241 , as well as the entropy density , both are shown in figure [ fig : pbrw ] .",
    "the @xmath0-machine reconstruction for different value range of @xmath243 and @xmath241 is shown in figure [ fig : fsm ] .",
    "there should be a symmetry in @xmath243 and @xmath244 , as there is no distinction between `` right '' and `` left '' , and indeed this is the case , so only values of @xmath243 up to @xmath245 are shown . for arbitrary values of the probabilities",
    "the finite state machines has two causal states ( figure [ fig : fsm]d ) and disorder is a consequence of the competing `` interaction '' between ( anti)persistence of motion direction whose strength is given by @xmath241 , and the movement in some fixed direction measured by @xmath243 .    if @xmath243 is small , and @xmath241 is near one , then persistence takes charge and the random walk will be mostly to the left with seldom changes of direction , this is seen in the low values of @xmath158 . at @xmath246 , persistence overtakes any other behavior , and the @xmath0-machine is a single causal state equivalent to a ferromagnetic state ( figure [ fig : fsm]a ) .",
    "if @xmath243 is small ( @xmath247 ) and @xmath241 is also small ( @xmath248 ) , the random walker has a strong tendency to change the movement direction at every step , which is the absolute dominant behavior at @xmath249 resulting in a perfect anti - ferromagnetic state ( figure [ fig : fsm]b ) . at @xmath250 the maximum state of disorder",
    "is reached which is equivalent to an unbiased coin tossing ( figure [ fig : fsm]c ) . in the entropy plot (",
    "fig [ fig : pbrw]a ) a large central region of almost no structure is seen , this same region is where large value of disorder is achieved as seen in the @xmath158 plot ( fig .",
    "[ fig : pbrw]b ) .",
    "finally , a complexity - entropy map@xcite of the model is shown in figure [ fig : pbrw]c .",
    "compare the map with that of the @xmath245-nearest neighbor ising model .",
    "@xmath0-machines reconstruction or computational mechanics , is a powerful tool in the analysis of complexity , which has been used in a wealth of different theoretical and practical situations .",
    "unfortunately , for the case of the one dimensional ising model , previous treatment were flawed by improper treatment of the model as a markov random field , which , it gave wrong numerical results and misleading behaviors for specific realization of the model . in this paper",
    "we developed the complete formalism for @xmath0-machine construction of the one dimensional ising model .",
    "the given expressions can be then used to model specific instance of the interaction hamiltonian , opening the way to the correct use of computational mechanics for the analysis of complexity behavior in the one - dimensional ising model . a computer library with the full implementation of the framework",
    "can be requested from the authors .",
    "this work was partially financed by fapemig under the project bpv-00047 - 13 .",
    "eer which to thank pve / capes for financial support under the grant 1149 - 14 - 8 .",
    "infrastructure support was given under project fapemig apq-02256 - 12 .",
    "movement and the probability of persistent @xmath241 movement .",
    "( c ) the complexity - entropy diagram of the persistent random walker , @xmath229 points with random parameters @xmath254 between 0 and 1 were used . ]"
  ],
  "abstract_text": [
    "<S> the complete framework for the @xmath0-machine construction of the one dimensional ising model is presented correcting previous mistakes on the subject . </S>",
    "<S> the approach follows the known treatment of the ising model as a markov random field , where usually the local characteristic are obtained from the stochastic matrix , the problem at hand needs the inverse relation , or how to obtain the stochastic matrix from the local characteristics , which are given via the transfer matrix treatment . </S>",
    "<S> the obtained expressions allow to perform complexity - entropy analysis of particular instance of the ising model . </S>",
    "<S> three examples are discussed : the 1/2-spin nearest neighbor and next nearest neighbor ising model , and the persistent biased random walk . </S>"
  ]
}