{
  "article_text": [
    "there is growing evidence that output signals of many physical  @xcite , biological  @xcite , physiological  @xcite and economic systems  @xcite , where multiple component feedback interactions play a central role , exhibit complex self - similar fluctuations over a broad range of space and/or time scales .",
    "these fluctuating signals can be characterized by long - range power - law correlations .",
    "due to nonlinear mechanisms controlling the underlying interactions , the output signals of complex systems are also typically non - stationary , characterized by embedded trends and heterogeneous segments ( patches with different local statistical properties )  @xcite .",
    "traditional methods such as power - spectrum and auto - correlation analysis  @xcite are not suitable for non - stationary signals .",
    "recently , new methods have been developed to address the problem of accurately quantifying long - range correlations in non - stationary fluctuating signals : ( a ) the detrended fluctuation analysis ( dfa )  @xcite , and ( b ) the detrended moving average method ( dma )  @xcite .",
    "an advantage of the dfa method  @xcite is that it can reliably quantify scaling features in the fluctuations by filtering out polynomial trends .",
    "however , trends may not necessarily be polynomial , and the dma method was introduced to estimate correlation properties of non - stationary signals without any assumptions on the type of trends , the probability distribution , or other characteristics of the underlying stochastic process .    here",
    ", we systematically compare the performance of the dfa and different variants of the dma method . to this end",
    "we generate long - range power - law correlated signals with an _ a - priori _ known correlation exponent @xmath0 using the fourier filtering method  @xcite . tuning the value of the correlation exponent @xmath0",
    ", we compare the scaling behavior obtained from the dfa and different variants of the dma methods to determine : ( 1 ) how accurately these methods reproduce @xmath0 ; ( 2 ) what are the limitations of the methods when applied to signals with small or large values of @xmath0 . based on single realization as well as on ensemble averages of a large number of artificially generated signals",
    ", we also compare the best fitting range ( i.e. the minimum and the maximum scales ) over which the correlation exponent @xmath0 can be reliably estimated by the dfa and dma methods .",
    "the outline of this paper is as follows . in sec .",
    "ii , we review the dfa method and we introduce variants of the dma method based on different types of moving average filters . in sec .",
    "iii we compare the performance of dfa and dma on correlated and anti - correlated signals .",
    "we also test and compare the stability of the scaling curves obtained by these methods by estimating the local scaling behavior within a given window of scales and for different scaling regions . in sec .",
    "iv we summarize our results and discuss the advantages and disadvantages of the two methods .",
    "in appendix i we consider higher order weighted detrended moving average methods , and in appendix ii we discuss moving average techniques in the frequency domain .",
    "the dfa method is a modified root - mean - square ( rms ) analysis of a random walk .",
    "starting with a signal @xmath1 , where @xmath2 , and @xmath3 is the length of the signal , the first step of the dfa method is to integrate @xmath1 and obtain @xmath4 where @xmath5 is the mean .",
    "the integrated profile @xmath6 is then divided into boxes of equal length @xmath7 . in each box @xmath7 ,",
    "we fit @xmath6 using a polynomial function @xmath8 , which represents the local trend in that box .",
    "when a different order of a polynomial fit is used , we have a different order dfa-@xmath9 ( e.g. , dfa-1 if @xmath10 , dfa-2 if @xmath11 , etc ) .",
    "next , the integrated profile @xmath6 is detrended by subtracting the local trend @xmath8 in each box of length @xmath7 : @xmath12 finally , for each box @xmath7 , the rms fluctuation for the integrated and detrended signal is calculated : @xmath13^{2}}.\\ ] ] the above calculation is then repeated for varied box length @xmath7 to obtain the behavior of @xmath14 over a broad range of scales . for scale - invariant signals with power - law correlations ,",
    "there is a power - law relationship between the rms fluctuation function @xmath14 and the scale @xmath7 : @xmath15    because power - laws are scale invariant , @xmath14 is also called the scaling function and the parameter @xmath16 is the scaling exponent .",
    "the value of @xmath16 represents the degree of the correlation in the signal : if @xmath17 , the signal is uncorrelated ( white noise ) ; if @xmath18 , the signal is correlated ; if @xmath19 , the signal is anti - correlated .",
    "the dma method is a new approach to quantify correlation properties in non - stationary signals with underlying trends  @xcite . moving average methods",
    "are widely used in fields such as chemical kinetics , biological processes , and finance  @xcite to quantify signals where large high - frequency fluctuations may mask characteristic low - frequency patterns . comparing each data point to the moving average",
    ", the dma method determines whether data follow the trend , and how deviations from the trend are correlated .",
    "* step 1 : * the first step of the dma method is to detect trends in data employing a moving average .",
    "there are two important categories of moving average : ( i ) simple moving average and ( ii ) weighted moving average .    * ( i ) simple moving average*. the simple moving average assigns equal weight to each data point in a window of size @xmath7 .",
    "the position to which the average of all weighted data points is assigned determines the relative contribution of the `` past '' and `` future '' points . in the following we consider the backward and the centered moving average .",
    "\\(a ) _ backward moving average_. for a window of size @xmath7 the simple backward moving average is defined as @xmath20 where @xmath6 is the integrated signal defined in eq.([integrate_signal ] ) . here , the average of the signal data points within the window refers to the last datapoint covered by the window .",
    "thus , the operator @xmath21 in eq.([ma ] ) is `` causal '' , i.e. , the averaged value at each data point @xmath22 depends only on the past @xmath23 values of the signal .",
    "the backward moving average is however affected by a rather slow reaction to changes in the signal , due to a delay of length @xmath24 ( half thewindow size ) compared to the signal .",
    "\\(b ) _ centered moving average _ this is an alternative moving average method , where the average of the signal data points within a window of size @xmath7 is placed at the center of the window .",
    "the moving average function is defined as @xmath25 + 1}^{[\\frac{n}{2}]}y(i+k),\\ ] ] where @xmath6 is the integrated signal defined in eq.([integrate_signal ] ) and @xmath26 $ ] is the integer part of @xmath27 .",
    "the function @xmath21 defined in eq.([cma ] ) is not `` causal '' , since the centered moving average performs dynamic averaging of the signal by mixing data points lying to the left and to the right side of @xmath22 . in practice , while the dynamical system under investigation evolves with time @xmath22 according to @xmath6 , the output of eq.([cma ] ) mix past and future values of @xmath6 .",
    "however , this averaging procedure is more sensitive to changes in the signal without introducing delay in the moving average compared to the signal .    *",
    "( ii ) weighted moving average*. in dynamical systems the most recent data points tend to reflect better the current state of the underlying `` forces '' .",
    "thus , a filter that places more emphasis on the recent data values may be more useful in determining reversals of trends in data .",
    "a widely used filter is the exponentially weighted moving average , which we employ in our study . in the following we consider the backward and the centered weighted moving average .",
    "\\(a ) _ backward moving average_. the weighted backward moving average is defined as @xmath28 where the parameter @xmath29 , @xmath7 is the window size , @xmath30 and @xmath31 . expanding the term @xmath32 in eq .",
    "(  [ wdma1 ] ) , we obtain a recursive relation of step one with previous data points weighted by increasing powers of @xmath33 . since @xmath34 , the contribution of the previous data points becomes exponentially small .",
    "the weighted backward moving average of higher order @xmath35 ( wdma-@xmath9 ) where @xmath9 is the step size in the recursive eq.([wdma1 ] ) is defined in appendix i.    \\(b ) _ centered moving average_. the weighted centered moving average is defined as @xmath36,\\ ] ] where @xmath37 is defined by eq.([wdma1 ] ) , and @xmath38 , where @xmath39 and @xmath40 .",
    "the term @xmath41 is the weighted contribution of all data points to the right of @xmath22 ( from @xmath42 to the end of the signal @xmath3 ) , and @xmath37 is the weighted contribution of all data points to the left of @xmath22 .",
    "the exponentially weighted moving average reduces the correlation between the current data point at which the moving average window is positioned and the previous and future points .",
    "= 0.85    = 0.83 = 0.83    = 0.83 = 0.83    = 0.85    = 0.85    = 0.85    = 0.7 = 0.7    = 0.7 = 0.7    * step 2 : * once the moving average @xmath43 is obtained , we next detrend the signal by subtracting the trend @xmath21 from the integrated profile @xmath6 @xmath44 for the backward moving average , we then calculate the fluctuation for a window of size @xmath7 as @xmath45 ^ 2}.\\ ] ] for the centered moving average the fluctuation for a window of size @xmath7 is calculated as @xmath46}^{n-[\\frac{n}{2}]}[c_{n}(i)]^2},\\ ] ]    * step 3 : * repeating the calculation for different @xmath7 , we obtain the fluctuation function @xmath14 . a power law relation between the fluctuation function @xmath14 and the scale @xmath7 ( see eq.([dfa ] ) ) indicates a self - similar behavior .",
    "when the moving average @xmath21 is calculated as in eq.([ma ] ) , eq.([cma ] ) , eq.([wdma1 ] ) and eq.([wcdma ] ) , we have the detrended moving method ( dma ) , the centered detrened moving average ( cdma ) , the weighted detrended moving average with order @xmath9 ( wdma-@xmath9 ) and the weighted centered detrended moving average ( wcdma ) respectively .",
    "using the modified fourier filtering method  @xcite , we generate uncorrelated , positively correlated , and anti - correlated signals @xmath1 , where @xmath47 and @xmath48 , with a zero mean and unit standard deviation . by introducing a designed power - law behavior in the fourier spectrum @xcite",
    ", the method can efficiently generate signals with long - range power - law correlations characterized by an _ a - priori _ known correlation exponent @xmath0 .      in this section",
    "we investigate the performance of the dma and wdma-1 methods when applied to signals with different type and degree of correlations , and compare them to the dfa method . specifically , we compare the features of the scaling function @xmath14 obtained from the dma and wdma-1 methods with the dfa method , and how accurately these methods estimate the correlation properties of the artificially generated signals @xmath1 .",
    "ideally , the output scaling function @xmath14 should exhibit a power - law behavior over all scales @xmath7 , characterized by a scaling exponent @xmath16 which is identical to the given correlation exponent @xmath0 of the artificial signals .",
    "previous studies  @xcite show that the scaling behavior obtained from the dfa method depends on the scale @xmath7 and the order @xmath9 of the polynomial fit when detrending the signal .",
    "we investigate if the results of the dma and wdma-1 method also have a similar dependence on the scale @xmath7 .",
    "we also show how the scaling results depend on the order @xmath9 when using wdma-@xmath9 with @xmath49 are applied to the signals ( see appendix i ) .    to compare the performance of different methods , we first study the behavior of the scaling function @xmath14 obtained from dfa-0 , dfa-1 , dma , and wdma-1 . in fig .  [ fnvsn ] we show the rms fluctuation function @xmath14 obtained from the different methods for an anti - correlated signal with correlation exponent @xmath50 , an uncorrelated signal with @xmath51 , and a positively correlated signal with @xmath52 .",
    "we find that in the intermediate regime @xmath14 ( obtained from all methods ) exhibits an approximate power - law behavior characterized by a single scaling exponent @xmath16 . at large scales @xmath7 for dfa-0 , dma , and wdma-1",
    ", we observe a crossover in @xmath14 leading to a flat regime . with increasing @xmath0",
    "this crossover becomes more pronounced and moves to the intermediate scaling range .",
    "in contrast , such a crossover at large scales is not observed for dfa-1 , indicating that the dfa-1 method can better quantify the correlation properties at large scales . at small scales",
    "@xmath7 the scaling curves @xmath14 obtained from all methods exhibit a crossover which is more pronounced for anti - correlated signals ( @xmath50 ) and becomes less pronounced for uncorrelated ( @xmath51 ) and positively correlated signals ( @xmath52 ) .",
    "we next systematically examine the performance of the dfa-0 , dfa-1 , dma and wdma-1 methods by varying @xmath0 over a very broad range of values ( @xmath53 ) [ fig .",
    "[ alphavsalpha0 ] ] . for all four methods ,",
    "we compare @xmath0 with the exponent @xmath16 obtained from fitting the rms fluctuation function @xmath14 in the scaling range @xmath54 , i.e. , the range where all methods perform well according to our observations in fig .",
    "[ fnvsn ] . if the methods work properly , for each value of the `` input '' exponent @xmath0 we expect the estimated `` output '' exponent to be @xmath55 .",
    "we find that the scaling exponent @xmath16 , obtained from different methods , saturates as the `` input '' correlation exponent @xmath0 increases , indicating the limitation of each method .",
    "the saturation of scaling exponent at @xmath56 indicates that dma and wdma-1 do not accurately quantify the correlation properties of signals with @xmath57 .",
    "in contrast , the dfa-@xmath9 method can quantify accurately the scaling behavior of strongly correlated signals if the appropriate order @xmath9 of the polynomial fit is used in the detrending procedure .",
    "specifically , we find that the values of the scaling exponent @xmath16 obtained from the dfa-@xmath9 are limited to @xmath58 . thus the dfa-@xmath9 can quantify the correlation properties of signals characterized by exponent @xmath59 . for signals with @xmath60",
    "we find that the output exponent @xmath16 from the dfa-@xmath9 method remains constant at @xmath61 .",
    "these findings suggest that in order to obtain a reliable estimate of the correlations in a signal one has to apply the dfa-@xmath9 for several increasing orders @xmath9 until the obtained scaling exponent @xmath16 stops changing with increasing @xmath9 .",
    "since the accuracy of the scaling exponent obtained from the different methods depends on the range of scales @xmath7 over which we fit the rms fluctuation function @xmath14 ( as seen in fig .  [ fnvsn ] ) , and since different methods exhibit different limitations for the range of scaling exponent values ( as demonstrated in fig .  [ alphavsalpha0 ] ) , we next investigate the local scaling behavior of the @xmath14 curves to quantify the performance of the different methods in greater details . to ensure a good estimation of the local scaling behavior",
    ", we calculate @xmath14 at scales @xmath62 , @xmath63 , which in log scale provides @xmath64 equidistant points for @xmath14 per bin of size @xmath65 . to estimate the local scaling exponent @xmath66",
    ", we locally fit @xmath14 in a window of size @xmath67 , e.g , @xmath68 is the slope of @xmath14 in a window containing @xmath69 points . to quantify the detailed features of the scaling curve @xmath14 at different scales @xmath7",
    ", we slide the window @xmath70 in small steps of size @xmath71 starting at @xmath72 , thus obtaining approximately @xmath73 equidistant @xmath68 in log scale per each scaling curve .",
    "we consider the average value of @xmath68 obtained from @xmath74 different realizations of signals with the same correlation exponent @xmath0 .    in fig .",
    "[ alphalocvsn ] , we compare the behavior of @xmath66 as a function of the scale @xmath7 to more accurately determine the best fitting range in the scaling curves @xmath14 obtained from the dma , wdma-1 , dfa-0 , and dfa-1 . a rms fluctuation function exhibiting a perfect scaling behavior would be characterized by @xmath75 for all scales @xmath7 and for all values of @xmath0 denoted by horizontal lines in fig .",
    "[ alphalocvsn ] .",
    "a deviation of the @xmath68 curves from these horizontal lines indicates an inaccuracy in quantifying the correlation properties of a signal and the limitation of the methods .",
    "our results show that the performance of different methods depends on the `` input '' @xmath0 and scale @xmath7 . at small scales and for @xmath76",
    "we observe that @xmath68 for all methods deviates up from the horizontal lines suggesting an overestimation of the real correlation exponent @xmath0 .",
    "this effect is less pronounced for uncorrelated and positively correlated signals . at intermediate scales",
    "@xmath66 exhibits a horizontal plateau indicating that all methods closely reproduce the input exponent for @xmath76 .",
    "this intermediate scaling regime changes for different types of correlations and for different methods . at large scales of @xmath77 , the dma ,",
    "wdma-1 , and dfa-0 methods strongly underestimate the actual correlations in the signal , with @xmath68 curves sharply dropping for all values of @xmath0 [ fig .",
    "[ alphalocvsn](a),(b),(c ) ] . in contrast , the dfa-1 method accurately reproduces @xmath0 at large scales with @xmath68 following the horizontal lines up to approximately @xmath78 [ fig .",
    "[ alphalocvsn](d ) ] . in addition , the dfa-1 method accurately reproduces the correlation exponent at small and intermediate scales even when @xmath57 [ fig .",
    "[ alphalocvsn](d ) ] , while the dma , wdma-1 and dfa-0 are limited to @xmath76 .    for a certain `` input '' correlation exponent @xmath0",
    ", we can estimate the good fitting regime of @xmath14 to be the length of the plateau in fig .",
    "[ alphalocvsn ] . for example",
    ", for @xmath50 the calculated scaling exponent @xmath79 obtained from the dma method is approximately equal to the expected value @xmath50 within a range of two decades ( @xmath80 ) .",
    "similarly , the good fitting range of @xmath14 obtained from the dfa-0 for @xmath50 is about three decades ( @xmath81 ) .",
    "however , the calculated local scaling exponent @xmath79 can fluctuate for different realizations of correlated signals .",
    "although the mean value obtained from many independent realizations is close to the expected value , the fluctuation of the estimated scaling exponent can be very large .",
    "thus , it is possible for @xmath79 to deviate from @xmath0 and the scaling range estimated from fig .",
    "[ alphalocvsn ] may not be a good fitting range .",
    "therefore , it is necessary to study the dispersion of the local scaling exponent to determine the reliability of the `` good '' fitting range estimated from fig .",
    "[ alphalocvsn ] . in fig .",
    "[ dispersion1 ] ,  [ dispersion2 ] ,  [ dispersion3 ] we show the results for @xmath68 from 20 different realizations of the correlated signal with @xmath50 , @xmath51 , and @xmath52 respectively . for all methods ,",
    "we observe that there is a large dispersion of @xmath68 , indicating strong fluctuations in the scaling function @xmath14 at large scales @xmath7 ( @xmath82 for dma and wdma-1 and @xmath83 for dfa-0 and dfa-1 ) [ fig .",
    "[ dispersion1 ] ,  [ dispersion2 ] ,  [ dispersion3 ] ] .",
    "this suggests that the good fitting range obtained only from the mean value of @xmath79 , as shown in fig .",
    "[ alphalocvsn ] , may be overestimated .    to better quantify the best fitting range for different methods and for different types of correlations we develop a three - dimensional representation [ fig .",
    "[ distribution1 ] ] . based on 50 realizations of correlated signals with different values of @xmath84 , for each scale",
    "@xmath7 we define the probability @xmath85 ( normalized frequency ) to obtain values for @xmath86 , where @xmath87 ( arguments supporting this choice of @xmath88 are presented in section iii(b ) ) . again , as in fig .",
    "[ alphalocvsn ] , for each realization of correlated signals with a given @xmath0 , we calculate @xmath68 by fitting the rms fluctuation function @xmath14 in a window of size @xmath67 sliding in steps of @xmath71 .",
    "vertical color bars in fig .",
    "[ distribution1 ] represent the value of the probability @xmath85  darker colors corresponding to higher probability to obtain accurate values for @xmath79 .",
    "thus dark - colored columns in the panels of fig .",
    "[ distribution1 ] represent the range of scales @xmath7 where the methods perform best .    for the dma and wdma-1 methods",
    ", we find that with high probability @xmath89 , accurate scaling results can be obtained in the scaling range of two decades for @xmath90 .",
    "however , wdma-1 performs better at small scales compared to dma . for explanation why the wdma-1 performs better at small scales compared to dma ,",
    "see appendix ii .",
    "in contrast , dfa-0 exhibits an increased fitting range of about three decades for @xmath91 , while for the dfa-1 we find the best fitting range to be around three decades for @xmath92 . for strongly anti - correlated signals ( @xmath93 )",
    ", all methods do not provide an accurate estimate of the scaling exponents @xmath0 .",
    "however , by integrating anti - correlated signals with @xmath94 and applying the dfa-1 method , we can reliably quantify the scaling exponent , since dfa-1 has the advantage to quantify signals with @xmath57 [ fig .",
    "[ distribution1](d ) ] .",
    "this can not be obtained by the other three methods [ fig .",
    "[ distribution1](a),(b),(c ) ] .",
    "= 0.83 = 0.83    = 0.83 = 0.83      = 0.7    = 0.7    = 0.9    = 0.81    = 0.81    = 0.7    = 0.7    = 0.83 = 0.83    = 0.83 = 0.83    = 0.7 = 0.7    = 0.7 = 0.7    to test the accuracy of the cdma method we perform the same procedure as shown in fig.[alphalocvsn ] .",
    "we calculate the local scaling exponent @xmath79 for signals with different `` input '' correlation exponent @xmath0 and for a broad range of scales @xmath7 [ fig.[alphadis ] ] .",
    "we find that for @xmath95 the cdma method performs better than the dma for all scales @xmath7 , and the average value of @xmath79 follows very closely the expected values of @xmath16 indicated by horizontal lines in fig.[alphadis ] . for anti - correlated signals with @xmath96 ,",
    "both dma and cdma overestimate the value of @xmath0 at small scales @xmath97 . for strongly correlated signals with @xmath98 ,",
    "cdma underestimates @xmath0 at small scales @xmath97 , in contrast to dma which overestimates @xmath0 . for correlated signals with @xmath99 ( not shown in fig.[alphadis](c ) )",
    "the deviation of @xmath79 from the expected value @xmath0 for the cdma method becomes even more pronounced and spreads to large scales . at intermediate and large scales cdma",
    "performs much better  @xmath79 closely follows the horizontal lines [ fig.[alphadis ] ( a),(c ) ] . these differences in the performance of the dma and cdma methods are also clearly seen in the probability density plots shown in fig.[cdmadistribution ] .    next , we compare the stability of the dma , cdma , dfa-0 , and dfa-1 methods in reproducing the same `` input '' value of @xmath0 for different realizations of correlated signals .",
    "we generate 50 realizations of signals for each @xmath0 , and we obtain the average value and the standard deviation of @xmath79 for a range of scales @xmath7 .",
    "the values of the standard deviation are represented by error bars in fig.[alphadis ] for each value of @xmath79 at all scales @xmath7 .",
    "we find that with increasing scales @xmath7 , the standard deviation gradually increases , and that for dma the standard deviation is less than @xmath100 while for dfa the standard deviation is less than @xmath101 in the range of scales @xmath7 up to @xmath102 ( @xmath3 is the signal length ) .",
    "for all methods at scales @xmath103 , the standard deviation increases more rapidly , and thus the stability of the methods in reproducing the same value of the exponent for different realizations decreases .    in fig.[wcdma_alphaloc_n ]",
    "we present the dependence of @xmath79 on the scale @xmath7 for the weighted centered detrended moving average method . compared to the cdma method",
    ", the wcdma method weakens the overestimation of @xmath79 at small scale for anti - correlated signals and provides accurate results of @xmath79 at small scales for positively correlated signals with @xmath104 .",
    "compared to the dfa method , the wcdma performs better at small scales for @xmath105 .",
    "however , at larger scales @xmath106 , the standard deviation of dfa-1 is smaller than that of wcdma ( figs.[alphadis](d ) , [ wcdma_alphaloc_n ] and [ wcdma - dfa1 - 1.1 - 1.5 ] ) , indicating more reliable results for the local scaling exponent @xmath79 obtained from dfa-1 .",
    "finally , we test how the choice of the parameter @xmath88 will affect the probability density plots shown in fig.[distribution1 ] and fig.[cdmadistribution ] .",
    "to access the precision of the methods one has to increase the confidence level by decreasing @xmath88 . in fig.[distribution1 ] and fig.[cdmadistribution ] we have chosen @xmath87 to correspond to the value of the standard deviation for @xmath79 at scales @xmath107 as estimated by the dma method [ fig.[alphadis ] ] .",
    "we demonstrate that the distribution plot for dma with @xmath87 ( shown in fig.[distribution1 ] ) changes dramatically when we chose @xmath108 ( as shown in fig.[distribution001](b ) ) .",
    "this result confirms the observation from fig.[alphadis](a ) and ( d ) that the dfa-1 method is more stable ( smaller standard deviation ) and more accurate ( average of @xmath79 closer to the theoretically expected value @xmath0 ) than the dma method .",
    "we have systematically studied the performance of the different variants of dma method when applied to signals with long - range power - law correlations , and we have compared them to the dfa method . specially , we have considered two categories of detrended moving average methods  the simple moving average and the weighted moving average  in order to investigate the effect of the relative contribution of data points included in the moving average window when estimating correlations in signals . to investigate the role of `` past '' and `` future '' data points in the dynamic averaging process for signals with different correlations , we have also considered the cases of backward and centered moving average within each of the above two categories .",
    "finally , we have introduced a three - dimensional representation to compare the performance of different variants of the dma method and the dfa methods over different scaling ranges based on an ensemble of multiple signal realizations .",
    "we find that the simple backward moving average dma method and the weighted backward moving average method wdma-@xmath9 have limitations when applied to signals with very strong correlations characterized by scaling exponent @xmath98 . a similar limitation is also found for the @xmath109 order of the dfa method .",
    "however , for higher order @xmath9 , the dfa-@xmath9 method can accurately quantify correlations with @xmath110 .",
    "we also find that at large scales the dma , wdma-@xmath9 , and dfa-0 methods underestimate the correlations in signals with @xmath105 , while the dfa-@xmath9 method can more accurately quantify the scaling behavior of such signals .",
    "further , we find that the scaling curves obtained from the dfa-1 method are stable over a much broader range of scales compared to the dma , wdma-1 , and dfa-0 methods , indicating a better fitting range to quantify the correlation exponent @xmath0 .",
    "in contrast , we find that wdma-@xmath111 with a higher order @xmath9 , more accurately reproduce the correlation properties of anti - correlated signals ( @xmath112 ) at small scales .",
    "accurate results for anti - correlated signals can also be obtained from the dfa-1 method after first integrating the signal and thus reducing the value of the estimated correlation exponent by  1 .",
    "in contrast to the simple backward moving average ( dma ) and dfa-0 methods , the centered moving average cdma provides a more accurate estimate of the correlations in signals with @xmath113 at small scales @xmath97 , and in signals with @xmath114 at intermediate scales @xmath54 . however , the cdma method strongly underestimates correlations in signals with @xmath114 at small scales @xmath115 , while the dfa-1 method reproduces quite accurately the correlations of signals with @xmath114 at both small and intermediate scales .",
    "we also find that by introducing weighted centered moving average wcdma , one can overcome the limitation of the cdma method in estimating correlations in signals with @xmath92 at small scales @xmath115 . on the other hand ,",
    "the wcdma method is characterized by larger error bars for @xmath79 at intermediate scales compared to the cdma method .",
    "further , we find that the performance of the wcdma is comparable to the dfa-1 method for signals with @xmath104 . at small scales the wcdma performs better than the dfa-1 method , while at the intermediate scales",
    "@xmath54 , dfa-1 provides more reliable local scaling exponent with smaller standard deviation based on 50 independent realizations for each @xmath0 .",
    "for very strongly correlated signals with @xmath57 , we find that the dfa-1 method performs much better at all scales compared to wcdma and all other variants of the dma method .",
    "this work was supported by nih grant hl071972 and by the miur ( prin - 2003029008 ) .",
    "* higer order weighted moving average *    to account for different types of correlations in signals , we consider the @xmath9-order weighted moving average ( wdma-@xmath9 ) , defined as @xmath116 where @xmath117 , @xmath9 is the order of the moving average , @xmath6 is defined in eq.([integrate_signal ] ) .",
    "the relative importance of the two terms entering the function in eq.([wdmal ] ) , can be further understood by analyzing the properties of the transfer function @xmath118 in the frequency domain ( see appendix ii ) .",
    "compared to the traditional exponentially weighted moving average ( of order @xmath10 ) where the terms in eq.([wdmal ] ) decrease exponentially , the higher order @xmath119 allows for a slower , step - size decrease of the terms in eq.([wdmal ] ) with a `` step '' of size @xmath9 . the fluctuation function @xmath14 is obtained following eq.([cn ] ) and eq.([fn_dma ] ) .",
    "the wdma-@xmath9 allows for a more gradual decrease in the distribution of weights in the moving average box , and thus may be more appropriate when estimating the scaling behavior of anti - correlated and uncorrelated signals .",
    "we apply the wdma-@xmath9 method for increasing values of @xmath9 to correlated signals with varied values of the scaling exponent @xmath0 .",
    "to study the performance of the wdma-@xmath9 methods , we estimate the scaling behavior of the rms fluctuation function @xmath14 at different scales @xmath7 by calculating the local scaling exponent @xmath68 in the same way as discussed in fig .",
    "[ alphalocvsn ] .",
    "we find that at large scales for @xmath120 , the @xmath68 curves deviate significantly from the expected values @xmath0  presented with horizontal dashed lines in fig .",
    "[ alphalocvsn2 ] .",
    "this indicates that the wdma-@xmath9 method significantly underestimates the strength of the correlations in our artificially generated signals .",
    "further , as for @xmath10 , we find that for higher order @xmath119 the wdma-@xmath9 methods exhibit an inherent limitation to accurately quantify the scaling behavior of positively correlated signals with @xmath114 .",
    "this behavior is also clear from our three - dimensional presentation in fig .",
    "[ distribution2 ] . for anti - correlated signals , however , the wdma-@xmath9 performs better at small and intermediate scales for increasing order @xmath9 as @xmath0 decreases [ fig .",
    "[ alphalocvsn2 ] ] ( see appendix ii ) .",
    "these observations are also confirmed from the three - dimensional probability histograms in fig .",
    "[ distribution2 ] , where it is clear that the scaling range for the best fit shrinks for positively correlated signals @xmath121 ) for increasing order @xmath9 , while for anti - correlated signals @xmath122 , there is a broader range of scales over which a best fit ( with a probability of @xmath123 ) is observed .",
    "* moving average methods in frequency domain *        in this appendix , the performance of the dma algorithm is discussed in the frequency domain .",
    "the interest of the frequency domain derives from the simplification designed to describe the effect of the detrending function @xmath124 in terms of the product of the square modulus of the transfer function @xmath125 and of @xmath126 , the power spectral density of the noisy signal @xmath6 .",
    "the simple moving average @xmath124 of window size @xmath7 is defined as @xmath127 corresponding to the discrete form of the causal convolution integral , where the convolution kernel introduces the memory effect .",
    "eq.([movingaverage ] ) is a sum with a constant memory kernel @xmath128 , i.e. , a step function with an amplitude @xmath129 [ fig.[fig1app](a ) ] .",
    "the function @xmath128 uniformly weights the contribution of all the past events in the window @xmath130 , thus it works better for random paths with a correlation exponent centered around @xmath131 . for higher degrees of correlation / anti - correlation , it should be taken into account ( as already explained in the section describing the dma function ) that each data point is more correlated to the most recent points than to the points further away .      the transfer function @xmath118 of any filter",
    "should ideally be a window of constant amplitude , going to zero very quickly above the cut - off frequency @xmath129 . by observing the curves of fig.[fig1app](b ) and fig.[fig3app ] ,",
    "it is clear that the filtering performance of @xmath133 is affected by the presence of the side lobes at frequency higher than @xmath129 .    as observed in fig.[fig3app ] , @xmath137 presents a side lobe allowing the components of the signal @xmath6 , with a frequency between @xmath129 and @xmath138 ( i.e. , time scales between @xmath24 and @xmath7 ) to pass through the filter , thus giving a spurious contribution to @xmath124 .",
    "these components contribute to the rms @xmath14 ( defined in eq.([fn_dma ] ) ) less than what should correspond to @xmath7 on the basis of the scaling law @xmath139 , with the consequence of increasing the slope @xmath14 at small scales .",
    "we next discuss the reasons why the weighted moving average might reduce this effect . the exponentially weighted moving average ( wdma-@xmath9 )",
    "weights recent data more than older data . it is defined as @xmath140 the coefficients",
    "are commonly indicated as _",
    "weights _ of the filter and are given by @xmath141 taking the fourier transform on eq .",
    "( [ wdma ] ) , we obtain @xmath142 where @xmath143 , @xmath144 are the fourier transforms of @xmath6 and @xmath145 respectively .",
    "further , we have @xmath146 thus the transfer function is @xmath147 from eq.([h_nl ] ) , one can find that the cutoff frequency for @xmath148 is @xmath149[@xmath150 . in fig .",
    "[ fig3app ] , the transfer function of the weighted moving averages with @xmath72 and @xmath11 and with @xmath72 and @xmath151 respectively are shown .",
    "it can be observed that the effect of the side lobe to the performance of @xmath152 and @xmath153 has become negligible compared to that of @xmath154 , with the consequence of reducing the high frequency components in the detrended signal and thus reducing the deviation of the @xmath68 , as discussed in the paper .",
    "p.  carpena , p.  bernaola  galvn , p.  ch .",
    "ivanov , and h.  e.  stanley , nature ( london ) * 418 * , 955 ( 2002 ) .",
    "n.  iyengar , c.  -k .",
    "peng , r.  morin , a.  l.  goldberger , and l.  a.   lipsitz , am .  j.  physiol .",
    "* 40 * , r1078 ( 1996 ) .",
    "ivanov , a. bunde , l.  a. nunes amaral , s. havlin , j. fritsch - yelle , r.  m. baevsky , h.  e. stanley , and a.  l. goldberger , europhys .",
    "* 48 * , 594 ( 1999 ) ."
  ],
  "abstract_text": [
    "<S> detrended fluctuation analysis ( dfa ) and detrended moving average ( dma ) are two scaling analysis methods designed to quantify correlations in noisy non - stationary signals . </S>",
    "<S> we systematically study the performance of different variants of the dma method when applied to artificially generated long - range power - law correlated signals with an _ a - priori _ known scaling exponent @xmath0 and compare them with the dfa method . </S>",
    "<S> we find that the scaling results obtained from different variants of the dma method strongly depend on the type of the moving average filter . </S>",
    "<S> further , we investigate the optimal scaling regime where the dfa and dma methods accurately quantify the scaling exponent @xmath0 , and how this regime depends on the correlations in the signal . finally , we develop a three - dimensional representation to determine how the stability of the scaling curves obtained from the dfa and dma methods depends on the scale of analysis , the order of detrending , and the order of the moving average we use , as well as on the type of correlations in the signal . </S>"
  ]
}