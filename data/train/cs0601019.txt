{
  "article_text": [
    "rewriting and pattern - matching are of general use for describing computations and deduction . programming with rewrite rules and strategies has been proven most useful for describing computational logics , transition systems or transformation engines , and the notions of rewriting and pattern matching are central notions in many systems , like expert systems ( jrule ) , programming languages based on rewriting ( elan , maude , obj ) or functional programming ( , haskell ) .    in this context , we are developing the system  @xcite , which consists of a language extension adding syntactic and associative pattern matching and strategic rewriting capabilities to existing languages like , and ocaml .",
    "this hybrid approach is particularly well - suited when describing transformations of structured entities like trees / terms and documents .",
    "one of the main originalities of this system is to be data structure independent .",
    "this means that a _ mapping _ has to be defined to connect algebraic data structures , on which pattern matching is performed , to low - level data structures , that correspond to the implementation .",
    "thus , given an algebraic data structure definition , it is needed to implement an efficient support for this definition in the language targeted by the system , as or do not provide such data structures .",
    "tools like apigen  @xcite and vas , which is a human readable language for apigen input where used previously for generating such an implementation to use with .    however , experience showed that providing an efficient term data structure implementation is not enough . when implementing computational logics or transition systems with rewriting and equational matching ,",
    "it is convenient to consider terms modulo a particular theory , as identity , associativity , commutativity , idempotency , or more problem specific equations  @xcite .",
    "then , it becomes crucial to provide the user of the data structure a way to conveniently describe such rules , and to have the insurance that only chosen equivalence class representatives will be manipulated by the program .",
    "this need shows up in many situations .",
    "for instance when dealing with abstract syntax trees in a compiler , and requiring constant folding or unboxing operators protecting particular data structures .",
    "is a language for describing multi - sorted term algebras designed to solve this problem . like apigen , vas or  @xcite ,",
    "its goal is to allow the user of an imperative or object oriented language to describe concisely the algebra of terms he wants to use in an application , and to provide an ( efficient ) implementation of this algebra .",
    "moreover , it provides a mechanism to describe normalization functions for the operators , and it ensures that all terms manipulated by the user of the data structure are normal with respect to those rules .",
    "includes the same basic functionality as apigen and vas , and ensures that the data structure implementation it provides are maximally shared .",
    "also , the generated data structure implementation supports the visitor combinator  @xcite pattern , as the strategy language of relies on this pattern .",
    "even though can be used in any environment , its features have been designed to work in synergy with .",
    "thus , it is able to generate correct mappings for the data structure ( i.e. being _ formal anchors _",
    "@xcite ) . provides a way to define computationally complex constructors for a data structure .",
    "it also ensures those constructors are used , and that no _ raw _ term can be constructed .",
    "private types  @xcite in the ocaml language do provide a similar functionality by hiding the type constructors in a private module , and exporting construction functions .",
    "however , using private types or normal types is made explicit to the user , while it is fully transparent in .",
    "moca , developed by frdric blanqui and pierre weis is a tool that implements normalization functions for theories like associativity or distributivity for ocaml types .",
    "it internally uses private types to implement those normalization functions and ensure they are used , but could also provide such an implementation for .",
    "the rest of the paper is organized as follows : in section  [ sec : tom ] , to motivate the introduction of , we describe the programming environment and its facilities .",
    "section  [ sec : gom ] presents the language , its semantics and some simple use cases . after presenting how can cooperate with in section  [ sec : interact ] ,",
    "we expose in section  [ sec : structure ] the example of a prover for the calculus of structures  @xcite showing how the combination of and can help producing a reliable and extendable implementation for a complex system .",
    "we conclude with summary and discussions in section  [ sec : conclusion ] .",
    "is a language extension which adds pattern matching primitives to existing imperative languages .",
    "pattern - matching is directly related to the structure of objects and therefore is a very natural programming language feature , commonly found in functional languages .",
    "this is particularly well - suited when describing various transformations of structured entities like , for example , trees / terms , hierarchized objects , and documents .",
    "the main originality of the system is its language and data - structure independence . from an implementation point of view",
    ", it is a compiler which accepts different _ native languages _ like or and whose compilation process consists in translating the matching constructs into the underlying native language .",
    "it has been designed taking into account experience about efficient compilation of rule - based systems  @xcite , and allows the definition of rewriting systems , rewriting rules and strategies . for an interested reader ,",
    "design and implementation issues related to are presented in  @xcite .",
    "is based on the notion of formal anchor presented in  @xcite , which defines a mapping between the algebraic terms used to express pattern matching and the actual objects the underlying language manipulates . thus , it is data structure independent , and customizable for any term implementation .",
    "for example , when using as the host language , the sum of two integers can be described in as follows :    ....    term plus(term t1 , term t2 ) {      % match(nat t1 , nat t2 ) {        x , zero    - > { return x ; }        x , suc(y ) - > { return suc(plus(x , y ) ) ; }       }    } ....    here the definition of ` plus ` is specified functionally , but the function ` plus ` can be used as a function to perform addition . `",
    "nat ` is the algebraic sort manipulates , which is mapped to objects of type ` term ` .",
    "the mapping between the actual object ` term ` and the algebraic view ` nat ` has to be provided by the user .",
    "the language provides support for matching modulo sophisticated theories .",
    "for example , we can specify a matching modulo associativity and neutral element ( also known as list - matching ) that is particularly useful to model the exploration of a search space and to perform list or based transformations . to illustrate the expressivity of list - matching",
    "we can define the search of a ` zero ` in a list as follows :",
    "....    boolean haszero(termlist l ) {      % match(natlist l ) {        conc(x1*,zero , x2 * ) - > { return true ; }      }      return false ;    } ....    in this example , _ list variables _ , annotated by a ` * ` should be instantiated by a ( possibly empty ) list . given a list ,",
    "if a solution to the matching problem exists , a ` zero ` can be found in the list and the function returns ` true ` , ` false ` otherwise , since no ` zero ` can be found .",
    "although this mechanism is simple and powerful , it requires a lot of work to implement an efficient data structure for a given algebraic signature , as well as to provide a _ formal anchor _ for the abstract data structure .",
    "thus we need a tool to generate such an efficient implementation from a given signature .",
    "this is what tools like apigen  @xcite do .",
    "however , apigen itself only provides a tree implementation , but does not allow to add behavior and properties to the tree data structure , like defining ordered lists , neutral element or constant propagation in the context of a compiler manipulating abstract syntax tree .",
    "hence the idea to define a new language that would overcome those problems .",
    "we describe here the language and its syntax , and present an example data - structure description in .",
    "we first show the basic functionality of , which is to provide an efficient implementation in for a given algebraic signature .",
    "we then detail what makes suitable for efficiently implement normalized rewriting  @xcite , and how allows us to write any normalization function .",
    "an algebraic signature describes how a tree - like data structure should be constructed .",
    "such a description contains _ sorts _ and _ operators_. _ operators _ define the different node shapes for a certain _ sort _ by their name and the names and sorts of their children .",
    "formalisms to describe such data structure definitions include apigen  @xcite , schema , types , and  @xcite .    to this basic signature definition ,",
    "we add the notion of _ module _ as a set of sorts .",
    "this allows to define new signatures by composing existing signatures , and is particularly useful when dealing with huge signatures , as can be the abstract syntax tree definition of a compiler .",
    "figure  [ fig : lightsyntax ] shows a simplified syntax for signature definition language . in this syntax",
    ", we see that a module can import existing modules to reuse its sorts and operators definitions .",
    "also , each module declares the sorts it defines with the * sorts * keyword , and declares operators for those sorts with productions .",
    "[ cols=\"<,^ , < \" , ]     this syntax is strongly influenced by the syntax of sdf  @xcite , but simpler , since it intends to deal with abstract syntax trees , instead of parse trees .",
    "one of its peculiarities lies in the productions using the * @xmath0 * symbol , defining variadic operators .",
    "the notation * @xmath0 * is the same as in  ( * ? ? ?",
    "* section  2.1.6 ) for a similar construction , and can be seen as a family of operators with arities in @xmath1 .    we will now consider a simple example of signature for booleans :    .... module boolean    sorts bool    abstract syntax      true                    - > bool      false                   - > bool      not(b : bool )             - > bool      and(lhs : bool , rhs : bool ) - > bool      or(lhs : bool , rhs : bool )   - > bool ....    from this description , generates a class hierarchy where to each sort corresponds an abstract class , and to each operator a class extending this _ sort _ class .",
    "the generator also creates a factory class for each module ( in this example , called ` booleanfactory ` ) , providing the user a single entry point for creating objects corresponding to the algebraic terms . like apigen and vas ,",
    "relies on the aterm  @xcite library , which provides an efficient implementation of unsorted terms for the and languages , as a basis for the generated classes . the generated data structure",
    "can then be characterized by strong typing ( as provided by the _ composite _",
    "pattern used for generation ) and maximal subterm sharing .",
    "also , the generated class hierarchy does provide support for the visitor combinator pattern  @xcite , allowing the user to easily define arbitrary tree traversals over data structures using high level constructs ( providing congruence operators ) .      when using abstract data types in a program , it is useful to also define a notion of canonical representative , or ensure some invariant of the structure",
    "this is particularly the case when considering an equational theory associated to the terms of the signature , such as associativity , commutativity or neutral element for an operator , or distributivity of one operator over another one .",
    "considering our previous example with boolean , we can consider the de morgan rules as an equational theory for booleans .",
    "de morgan s laws state @xmath2 and @xmath3 .",
    "we can orient those equations to get a confluent and terminating rewrite system , suitable to implement a normalization system , where only boolean atoms are negated .",
    "we can also add a rule for removing duplicate negation .",
    "we obtain the system : @xmath4 s objective is to provide a low level system for implementing such normalizing rewrite systems in an efficient way , while giving the user control on how the rules are applied . to achieve this goal ,",
    "provides a _ hook _ mechanism , allowing to define arbitrary code to execute before , or replacing the original construction function of an operator .",
    "this code can be any or code , allowing to use pattern matching to specify the normalization rules . to allow _ hooks _ definitions , we add to the syntax the definitions for _ hooks _ , and add @xmath5 and @xmath6 to the productions :    lcl @xmath6 & : : =  & * * factory \\ { @xmath7 * } * + @xmath5 & : : =  & @xmath8 * :* @xmath9 * * \\ { @xmath7 * } * + @xmath9 & : : =  & @xmath10 * ( * ( @xmath11 ) * * ) * + @xmath10 & : : =  & * make * @xmath12  * make_before * @xmath12  * make_after * +   + @xmath7 & : : =  & @xmath13    a _ factory hook _",
    "@xmath6 is attached to the module , and allows to define additional functions .",
    "we will see in section  [ sub : invariant ] an example of use for such a _ hook_. an _ operator hook _",
    "@xmath5 is attached to an operator definition , and allows to extend or redefine the construction function for this operator .",
    "depending on the @xmath10 , the hook redefines the construction function ( * make * ) , or insert code before ( * make_before * ) or after ( * make_after * ) the construction function .",
    "those _ hooks _ take as many arguments as the operator they modify has children .",
    "we also define operation types with an appended * insert * , used for variadic operators .",
    "those hooks only take two arguments , when the operator they apply to is variadic , and allow to modify the operation of adding one element to the list of arguments of a variadic operator .",
    "such _ hooks _ can be used to define the boolean normalization system :    .... module boolean    sorts bool    abstract syntax      true                    - > bool      false                   - > bool      not(b : bool )             - > bool      and(lhs : bool , rhs : bool ) - > bool      or(lhs : bool , rhs : bool )   - > bool      not : make(arg ) {        % match(bool arg ) {          not(x )    - > { return ` x ; }          and(l , r ) - > { return ` or(not(l),not(r ) ) ; }          or(l , r )   - > { return ` and(not(l),not(r ) ) ; }        }        return ` make_not(arg ) ;      } ....    we see in this example that it is possible to use in the _ hook _ definition , and to use the algebraic signature being defined in in the _ hook _ code .",
    "this lets the user define _ hooks _ as rewriting rules , to obtain the normalization system .",
    "the signature in the case of is extended to provide access to the default construction function of an operator .",
    "this is done here with the ` make_not(arg ) ` call .",
    "when using the _ hook _ mechanism of , the user has to ensure that the normalization system the hooks define is terminating and confluent , as it will not be enforced by the system .",
    "also , combining hooks for different equational theories in the same signature definition can lead to non confluent systems , as combining rewrite systems is not a straightforward task .    however , a higher level strata providing completion to compute normalization functions from their equational definition , and allowing to combine theories and rules could take advantage of s design to focus on high level tasks , while getting maximal subterm sharing , strong typing of the generated code and _ hooks _ for implementing the normalization functions from the strata .",
    "can then be seen as a reusable component , intended to be used as a tool for implementing another language ( as apigen was used as basis for  @xcite ) or as component in a more complex architecture .",
    "the tool is best used in conjunction with the compiler .",
    "is used to provide an implementation for the abstract data type to be used in a program .",
    "the data structure definition will also contain the description of the invariants the data structure has to preserve , by the mean of _ hooks _ , such that it is ensured the program will only manipulate terms verifying those invariants .",
    "starting from an input datatype signature definition , generates an implementation in of this data structure ( possibly using internally ) and also generates an anchor for this data structure implementation for ( see figure  [ fig : interaction ] ) .",
    "the users can then write code using the match construct on the generated mapping and compiles this to plain .",
    "the dashed box represents the part handled by the tool , while the grey boxes highlight the source files the user writes .",
    "the generated code is characterized by strong typing combined with a generic interface and by maximal sub - term sharing for memory efficiency and fast equality checking , as well as the insurance the hooks defined for the data structure are always applied , leading to canonical terms .",
    "although it is possible to manually implement a data structure satisfying those constraints , it is difficult , as all those features are strongly interdependent .",
    "nonetheless , it is then very difficult to let the data structure evolve when the program matures while keeping those properties , and keep the task of maintaining the resulting program manageable .    in the following example , we see how the use of for the data structure definition and for expressing both the invariants in and the rewriting rules and strategy in the program leads to a robust and reliable implementation for a prover in the structure calculus .",
    "we describe here a real world example of a program written using and together .",
    "we implement a prover for the calculus of structure  @xcite where some rules are promoted to the level of data structure invariants , allowing a simpler and more efficient implementation of the calculus rules .",
    "those invariants and rules have been shown correct with respect to the original calculus , leading to an efficient prover that can be proven correct .",
    "details about the correctness proofs and about the proof search strategy can be found in  @xcite .",
    "we concentrate here on the implementation using .",
    "when building a prover for a particular logic , and in particular for the system @xmath14 in the structure calculus , one needs to refine the strategy of applying the calculus rules .",
    "this is particularly true with the calculus of structure , because of deep inference , non confluence of the calculus and associative - commutative structures .",
    "we describe here briefly the system @xmath14 , to show how and can help to provide a robust and efficient implementation of such a system .    atoms in @xmath14 are denoted by @xmath15 structures are denoted by @xmath16 and generated by @xmath17 where @xmath18 , the _ unit _ , is not an atom .",
    "@xmath19 is called a _ seq structure _ , @xmath20 is called a _",
    "par structure _ , and @xmath21 is called a _ copar structure _ , @xmath22 is the _ negation _ of the structure @xmath23 .",
    "a structure @xmath24 is called a _ proper par structure _ if @xmath25 where @xmath26 and @xmath27 . a _ structure context _ , denoted as in @xmath28 , is a structure with a hole .",
    "we use this notation to express the deduction rules for system @xmath14 , and will omit context braces when there is no ambiguity .",
    "the rules for system @xmath14 are simple , provided some equivalence relations on @xmath14 terms .",
    "the seq , par and copar structures are associative , par and copar being commutative too . also , @xmath29 is a neutral element for seq , par and copar structures , and a seq , par or copar structure with only one substructure is equivalent to its content .",
    "then the deduction rules for system @xmath14 can be expressed as in figure  [ fig : bv ] .",
    "because of the contexts in the rules , the corresponding rewriting rules can be applied not only at the top of a structure , but also on each subterm of a structure , for implementing deep inference .",
    "deep inference then , combined with associativity , commutativity and @xmath29 as a neutral element for seq , par and copar structures leads to a huge amount of non - determinism in the calculus .",
    "a structure calculus prover implementation following strictly this description will have to deal with this non - determinism , and handle a huge search space , leading to inefficiency  @xcite .",
    "the approach when using and will be to identify canonical representatives , or preferred representatives for equivalence classes , and implement the normalization for structures leading to the selection of the canonical representative by using s _ hooks_. this process requires to define the data structure first , and then define the normalization .",
    "this normalization will make sure all units @xmath29 in seq , par and copar structures are removed , as @xmath29 is a neutral for those structures .",
    "we will also make sure the manipulated structures are _ flattened _ , which corresponds to selecting a canonical representative for the associativity of seq , par and copar , and also that subterms of par and copar structures are ordered , taking a total order on structures , to take commutativity into account .    when implementing the deduction rule , it will be necessary to take into account the fact that the prover only manipulates canonical representatives .",
    "this leads to simpler rules , and allow some new optimizations on the rules to be performed .",
    "we first have to give a syntactic description of the structure data - type the @xmath14 prover will use , to provide an object representation for the _ seq _ , _ par _ and _ copar _ structures ( @xmath30 , @xmath31 and @xmath32 ) . in our implementation , we considered these constructors as unary operators which take a _ list of structures _ as argument . using ,",
    "the considered data structure can be described by the following signature :    .... module struct    imports     public      sorts struc strucpar struccop strucseq    abstract syntax      o - > struc      a - > struc      b - > struc      c - > struc      d - > struc      ... other atom constants      neg(a : struc ) - > struc      concpar ( struc * )   - > strucpar      conccop ( struc * )   - > struccop      concseq ( struc * )   - > strucseq      cop(copl : struccop ) - > struc      par(parl : strucpar ) - > struc      seq(seql : strucseq ) - > struc ....    to represent structures , we define first some constant atoms . among them , the ` o ` constant will be used to represent the unit @xmath29 .",
    "the ` neg ` operator builds the negation of its argument .",
    "the grammar rule ` par(strucpar ) - > struc ` defines a unary operator ` par ` of sort ` struc ` which takes a ` strucpar ` as unique argument .",
    "similarly , the rule ` concpar(struc * ) - > strucpar ` defines the ` concpar ` operator of sort ` strucpar ` .",
    "the syntax ` struc * ` indicates that ` concpar ` is a _ variadic - operator _ which takes an indefinite number of ` struc ` as arguments .",
    "thus , by combining ` par ` and ` concpar ` it becomes possible to represent the structure @xmath33 by ` par(concpar(a , b , c ) ) ` .",
    "note that this structure is flattened , but with this description , we could also use nested ` par ` structures , as in ` par(concpar(a , par(concpar(b , c ) ) ) ) ` to represent this structure . @xmath32 and @xmath30 are represented in a similar way , using ` cop , seq ` , ` conccop ` , and ` concseq ` .",
    "so far , we can manipulate objects , like ` par(concpar ( ) ) ` , which do not necessarily correspond to intended structures .",
    "it is also possible to have several representations for the same structure .",
    "hence , ` par(concpar(a ) ) ` and ` cop(conccop(a ) ) ` both denote the structure  ` a ` , as @xmath34 .",
    "thus , we define the canonical ( prefered ) representative by ensuring that    * @xmath35 , @xmath36 and @xmath37 are reduced when containing only one sub - structure : + @xmath38 * nested structures are flattened , using the rule : @xmath39 * subterms are sorted ( according to a given total lexical order  @xmath40 ) : + @xmath41 if @xmath42 .    this notion of canonical form allows us to efficiently check if two terms represent the same structure with respect to commutativity of those connectors , neutral elements and reduction rules .",
    "the first invariant we want to maintain is the reduction of singleton for _ seq _ , _ par _ and _ copar _ structures .",
    "if we try to build a ` cop ` , ` par ` or ` seq ` with an empty list of structures , then the creation function shall return the unit ` o ` .",
    "else if the list contains only one element , it has to return this element .",
    "otherwise , it will just build the requested structure .",
    "as all manipulated terms are canonical forms , we do not have for this invariant to handle the case of a structure list containing the unit , as it will be enforced by the list invariants .",
    "this behavior can be implemented as a _ hook _ for the ` seq ` , ` par ` and ` cop ` operators .",
    ".... par(parl : strucpar ) - > struc par : make ( l ) {    % match(strucpar l ) {      concpar ( ) - > { return ` o ( ) ; }      concpar(x)- > { return ` x ; }    }    return ` make_par(l ) ; } ....    this simple _ hook _ implements the invariant for singletons for ` par ` , and use a call to the constructor ` make_par(l ) ` to call the intern constructor ( without the normalization process ) , to avoid an infinite loop .",
    "similar hooks are added to the description for ` cop ` and ` seq ` operators .",
    "we see here how the pattern matching facilities of embedded in can be used to easily implement normalization strategies .",
    "the _ hooks _ for normalizing structure lists are more complex .",
    "they first require a total order on structures .",
    "this can be easily provided as a function , defined in a ` factory ` hook .",
    "the comparison function we provide here uses the builtin translation of generated data structures to text to implement a lexical total order",
    ". a more specific ( and efficient ) comparison function could be written , but for the price of readability .",
    ".... factory {    public int comparestruc(object t1 , object t2 ) {      string s1 = t1.tostring ( ) ;      string s2 = t2.tostring ( ) ;      int res = s1.compareto(s2 ) ;      return res ;    } } ....    once this function is provided , we can define the hooks for the variadic operators ` concseq ` , ` concpar ` and ` conccop ` .",
    "the hook for ` concseq ` is the simplest , since the @xmath36 structures are only associative , with @xmath18 as neutral element .",
    "then the corresponding hook has to remove the units , and flatten nested ` seq ` .",
    ".... concseq ( struc * )   - > strucseq concseq : make_insert(e , l ) {    % match(struc e ) {      o ( )               - > { return l ; }      seq(concseq(l * ) ) - > { return ` concseq(l*,l * ) ; }    }    return ` make_concseq(e , l ) ; } ....    this _ hook _ only checks the form of the element to add to the arguments of the variadic operator , but does not use the shape of the previous arguments .",
    "the _ hooks _ for ` conccop ` and ` concpar ` are similar , but they do examine also the previous arguments , to perform sorted insertion of the new argument .",
    "this leads to a sorted list of arguments for the operator , providing a canonical representative for commutative structures .",
    ".... concpar ( struc * )   - > strucpar concpar : make_insert(e , l ) {    % match(struc e ) {      o ( ) - > { return l ; }      par(concpar(l * ) ) - > { return ` concpar(l*,l * ) ; }    }    % match(strucpar",
    "l ) {      concpar(head , tail * ) - > {        if(!(comparestruc(e , head )",
    "< 0 ) ) {          return ` make_concpar(head , concpar(e , tail * ) ) ;        }      }    }    return ` make_concpar(e , l ) ; } ....    the associative matching facility of is used to examine the arguments of the variadic operator , and decide whether to call the builtin construction function , or perform a recursive call to get a sorted insertion .",
    "as the structure calculus verify the de morgan rules for the negation , we could write a hook for the ` neg ` construction function applying the de morgan rules as in section  [ sub : canon ] to ensure only atoms are negated .",
    "this will make implementing the deduction rules even simpler , since there is then no need to propagate negations in the rules .",
    "once the data structure is defined , we can implement proof search in system @xmath14 in a program using the defined data structure by applying rewriting rules corresponding to the calculus rules to the input structure repeatedly , until reaching the goal of the prover ( usually , the unit @xmath29 ) .",
    "those rules are expressed using s pattern matching over the data structure .",
    "they are kept simple because the equivalence relation over structures is integrated in the data structure with invariants . in this example ,",
    "@xmath35 and @xmath37 structures are associative and commutative , while the canonical representatives we use are sorted and flattened variadic operators .",
    "for instance , the rule @xmath43 of figure  [ fig : bv ] can be expressed as the two rules @xmath44 and @xmath45 , using only associative matching instead of associative commutative matching .",
    "then , those rules are encoded by the following match construct , which is placed into a strategy implementing rewriting in arbitrary context ( congruence ) to get deep inference , the ` c ` collection being used to gather multiple results :    .... % match(struc t ) {    par(concpar(x1*,cop(conccop(r*,t*)),x2*,u , x3 * ) ) - > {      if(`t*.isempty ( ) || ` r*.isempty ( ) ) { }       else {        strucpar context = ` concpar(x1*,x2*,x3 * ) ;        if(canreact(`r*,`u ) ) {          strucpar parr = cop2par(`r * ) ;              // transform a struccop into a strucpar          struc elt1 = ` par(concpar (                cop(conccop(par(concpar(parr*,u)),t*)),context * ) ) ;",
    "c.add(elt1 ) ;               }        if(canreact(`t*,`u ) ) {          strucpar part = cop2par(`t * ) ;          struc elt2 = ` par(concpar (                cop(conccop(par(concpar(part*,u)),r*)),context * ) ) ;          c.add(elt2 ) ;    }   }   } } ....    we ensure that we do not execute the right - hand side of the rule if either ` r ` or ` t ` are empty lists .",
    "the other tests implement restrictions on the application of the rules reducing the non - determinism .",
    "this is done by using an auxiliary predicate function ` canreact(a , b ) ` which can be expressed using all the expressive power of both and in a ` factory ` hook .",
    "the interested reader is referred to  @xcite for a detailed description of those restrictions .",
    "also , the search strategy can be carefully crafted using both and constructions , to achieve a very fine grained and evolutive strategy , where usual algebraic languages only allow breadth - first or depth - first strategies , but do not let the programmer easily define a particular hybrid search strategy . while the approach of search strategies may lead to more complex implementations for simple examples ( as the search space has to be handled explicitly ) , it allows us to define fine and efficient strategies for complex cases .",
    "the implementation of a prover for system @xmath14 with and leads not only to an efficient implementation , allowing to cleanly separate concerns about strategy , rules and canonical representatives of terms , but also to an implementation that can be proven correct , because most parts are expressed with the high level constructs of and instead of pure . as the data structure invariants in and the deduction rules in are defined algebraically , it is possible to prove that the implemented system is correct and complete with respect to the original system  @xcite , while benefiting from the expressive power and flexibility of to express non algebraic concerns ( like building a web applet for the resulting program , or sending the results in a network ) .",
    "we have presented the language , a language for describing algebraic signatures and normalization systems for the terms in those signatures .",
    "this language is kept low level by using and to express the normalization rules , and by using _",
    "hooks _ for describing how to use the normalizers .",
    "this allows an efficient implementation of the resulting data structure , preserving properties important to the implementation level , such as maximal subterm sharing and a strongly typed implementation .",
    "we have shown how this new tool interacts with the language .",
    "as provides pattern matching , rewrite rules and strategies in imperative languages like or , provides algebraic data structures and canonical representatives to . even though can be used simply within ,",
    "most benefits are gained when using it with , allowing to integrate formal algebraic developments into mainstream languages .",
    "this integration can allow to formally prove the implemented algorithms with high level proofs using rewriting techniques , while getting a implementation as result .",
    "we have applied this approach to the example of system @xmath14 in the structure calculus , and shown how the method can lead to an efficient implementation for a complex problem ( the implemented prover can tackle more problems than previous rule based implementation  @xcite ) .    as the compilation process of s pattern matching is formally verified and shown correct  @xcite ,",
    "proving the correctness of the generated data structure and normalizers with respect to the description would allow to expand the trust path from the high level algorithm expressed with rewrite rules and strategies to the code generated by the compilation of and .",
    "this allows to not only prove the correctness of the implementation , but also to show that the formal parts of the implementation preserve the properties of the high level rewrite system , such as confluence or termination .",
    "* acknowledgments : * i would like to thank claude kirchner , pierre tienne moreau and all the developers for their help and comments .",
    "special thanks are due to pierre weis and frederic blanqui for fruitful discussions and their help in understanding the design issues .",
    "comon , h. and j .- p .",
    "jouannaud , _ les termes en logique et en programmation _ ( 2003 ) , master lectures at univ .",
    "paris sud .",
    "http://www.lix.polytechnique.fr / labo/% jean - pierre.jouannaud / articles / cours - tlpo.pdf[http://www.lix.polytechnique.fr / labo/% jean-pierre.jouannaud/articles/cours-tlpo.pdf ]        , o. , _ implementing system bv of the calculus of structures in maude _ , in : l.  a. i  alemany and p.  ' egr ' e , editors , _ proceedings of the esslli-2004 student session _ ,",
    "universit ' e henri poincar ' e , nancy , france , 2004 , pp . 117127 , 16th european summer school in logic , language and information .",
    "kirchner , c. , p .- e .",
    "moreau and a.  reilles , _ formal validation of pattern matching code _ , in : p.  barahone and a.  felty , editors , _ proceedings of the 7th acm sigplan international conference on principles and practice of declarative programming _ ( 2005 ) , pp .",
    "187197 .",
    "kirchner , h. and p .- e .",
    "moreau , _ promoting rewriting to a programming language : a compiler for non - deterministic rewrite programs in associative - commutative theories _ ,",
    "journal of functional programming * 11 * ( 2001 ) , pp .",
    "207251 .",
    "moreau , p .- e .",
    ", c.  ringeissen and m.  vittek , _ a pattern matching compiler for multiple target languages _ , in : g.  hedin , editor , _",
    "12th conference on compiler construction , warsaw ( poland ) _ , lncs * 2622 * ( 2003 ) , pp . 6176 ."
  ],
  "abstract_text": [
    "<S> this paper presents , a language for describing abstract syntax trees and generating a implementation for those trees . includes features allowing the user to specify and modify the interface of the data structure . </S>",
    "<S> these features provide in particular the capability to maintain the internal representation of data in canonical form with respect to a rewrite system . </S>",
    "<S> this explicitly guarantees that the client program only manipulates normal forms for this rewrite system , a feature which is only implicitly used in many implementations . </S>"
  ]
}