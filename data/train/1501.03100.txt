{
  "article_text": [
    "traditionally , robot grasping is understood in terms of two related subproblems : perception and planning .",
    "the goal of the perceptual component is to estimate the position and orientation ( pose ) of an object to be grasped .",
    "then , grasp and motion planners are used to calculate where to move the robot arm and hand in order to perform grasp .",
    "while this approach can work in ideal scenarios , it has proven to be surprisingly difficult to localize the pose of novel objects in clutter accurately  @xcite .",
    "more recently , researchers have proposed various grasp point detection methods that localize grasps independently of object identity .",
    "one class of approaches use a sliding window to detect regions of an rgbd image or a height map where a grasp is likely to succeed  @xcite .",
    "other approaches extrapolate local `` grasp prototypes '' based on human - provided grasp demonstrations  @xcite .",
    "a missing element in the above works is that they do not leverage the geometry of grasping to improve detection .",
    "grasp geometry has been studied extensively in the literature ( for example  @xcite ) .",
    "moreover , point clouds created using depth sensors would seem to be well suited for geometric reasoning . in this paper",
    ", we propose an algorithm that detects grasps in a point cloud by predicting the presence of necessary and sufficient geometric conditions for grasping .",
    "the algorithm has two steps .",
    "first , we sample a large set of grasp hypotheses . then",
    ", we classify those hypotheses as grasps or not using machine learning .",
    "geometric information is used in both steps .",
    "first , we use geometry to reduce the size of the sample space . a trivial necessary condition for a grasp to exist is that the    r0.5    hand must be collision - free and part of the object surface must be contained between the two fingers .",
    "we propose a sampling method that only produces hypotheses that satisfy this condition .",
    "this simple step should boost detection accuracy relative to approaches that consider every possible hand placement a valid hypothesis .",
    "the second way that our algorithm uses geometric information is to automatically label the training set .",
    "a necessary and sufficient condition for a two - finger grasp is an antipodal contact configuration ( see definition  [ defn : nguyen ] ) .",
    "unfortunately , we can not reliably detect an antipodal configuration in most real - world point clouds because of occlusions .",
    "however , it is nevertheless possible _ sometimes _ to verify a grasp using this condition .",
    "we use the antipodal condition to label a subset of grasp hypotheses in arbitrary point clouds containing ordinary graspable objects .",
    "we generate large amounts of training data this way because it is relatively easy to take lots of range images of ordinary objects .",
    "this is a huge advantage relative to approaches that depend on human annotations because large amounts of training data can significantly improve classification performance .",
    "our experiments indicate that the approach described above performs well in practice .",
    "we find that without using any machine learning and just using our collision - free sampling algorithm as a grasp detection method , we achieve a 73% grasp success rate for novel objects .",
    "this is remarkable because this is a trivially simple detection criterion . when a classification step is added to the process , our grasp success rate jumps to 88% .",
    "this success rate is competitive with the best results that have been reported .",
    "however , what is particularly interesting is the fact that our algorithm achieves an average 73% grasp success rate in dense clutter such as that shown in figure  [ fig : overall ] .",
    "this is exciting because dense clutter is a worst - case scenario for grasping .",
    "clutter creates lots of occlusions that make perception more difficult and obstacles that make reaching and grasping harder .",
    "the idea of searching an image for grasp targets independently of object identity was probably explored first in saxena s early work that used a sliding window classifier to localize good grasps based on a broad collection of local visual features  @xcite .",
    "later work extended this concept to range data  @xcite and explored a deep learning approach  @xcite . in  @xcite , they obtain an 84% success rate on baxter and a 92% success rate on the pr2 for objects presented in isolation ( averaged over 100 trials ) .",
    "fischinger and vincze developed a similar method that uses heightmaps instead of range images and develops a different haar - like feature representation  @xcite . in",
    "@xcite , they report a 92% single - object grasp success rate averaged over 50 grasp trials using the pr2 .",
    "this work is particularly interesting because they demonstrate clutter results where the robot grasps and removes up to 10 piled objects from a box .",
    "they report that over six clear - the - box runs , their algorithm removes an average of 87% of the objects from the box .",
    "other approaches search a range image or point cloud for hand - coded geometries that are expected to be associated with a good grasp .",
    "for example klingbeil _ et .",
    "al _ search a range image for a gripper - shaped pattern  @xcite . in our prior work",
    ", we developed an approach to localizing handles by searching a point cloud for a cylindrical shell  @xcite .",
    "other approaches follow a template - based approach where grasps that are demonstrated on a set of training objects are generalized to new objects .",
    "for example , herzog _ et .",
    "al _ learn to select a grasp template from a library based on features of the novel object  @xcite .",
    "detry _ et .",
    "al _ grasp novel objects by modeling the geometry of local object shapes and fitting these shapes to new objects  @xcite .",
    "kroemer _ et . al _ propose an object affordance learning strategy where the system learns to match shape templates against various actions afforded by those templates  @xcite .",
    "another class of approaches worth mentioning are based on interacting with a stack of objects .",
    "for example , katz _ et .",
    "al _ developed a method of grasping novel objects based on interactively pushing the objects in order to improve object segmentation  @xcite .",
    "_ developed a method of segmenting objects by physically manipulating them  @xcite .",
    "the approach presented in this paper is distinguished from the above primarily because of the way we use geometric information .",
    "our use of geometry to generate grasp hypotheses is novel .",
    "moreover , our ability to generate large amounts of labeled training data could be very important for improving detection accuracy in the future .",
    "however , what is perhaps most important is that we demonstrate `` reasonable '' ( 73% ) grasp success rates in dense clutter  arguably a worst - case scenario for grasping .",
    "we frame the problem of localizing grasp targets in terms of locating _ antipodal hands _",
    ", an idea that we introduce based on the concept of an antipodal grasp . in an antipodal grasp , the robot hand is able to apply opposite and co - linear forces at two points :    [ defn : nguyen ] a pair of point contacts with friction is * antipodal * if and only if the line connecting the contact points lies inside both friction cones  .    if an antipodal grasp exists , then the robot can hold the object by applying sufficiently large forces along the line connecting the two contact points . in this paper",
    ", we restrict consideration to parallel jaw grippers  hands with parallel fingers and a single closing degree of freedom .",
    "since a parallel jaw gripper can only apply forces along the ( single ) direction of gripper motion , we will additionally require the two contact points to lie along a line parallel to the direction of finger motion . rather than localizing antipodal contact configurations directly",
    ", we will localize hand configurations where we expect an antipodal grasp to be achieved in the future when the hand closes .",
    "let @xmath0 denote the robot workspace and let @xmath1 denote space occupied by objects or obstacles .",
    "let @xmath2 denote the configuration space of the hand when the fingers are fully open .",
    "we will refer to a configuration @xmath3 as simply a `` hand '' .",
    "let @xmath4 denote the volume occupied by the hand in configuration @xmath3 , when the fingers are fully open .",
    "[ def : pre_antipodal_hand ] an * antipodal hand * is a pose of the hand , @xmath3 , such that the hand is not in collision with any objects or obstacles , @xmath5 , and at least one pair of antipodal contacts will be formed when the fingers close such that the line connecting the two contacts is parallel to the direction of finger motion .",
    "algorithm  [ alg : overall ] illustrates at a high level our algorithm for detecting antipodal hands .",
    "it takes a point cloud , @xmath6 , and a geometric model of the robot hand as input and produces as output a set of hands , @xmath7 , that are predicted to be antipodal .",
    "there are two main steps .",
    "first , we sample a set of hand hypotheses .",
    "then , we classify each hypothesis as an antipodal hand or not .",
    "these steps are described in detail in the following sections .",
    "a point cloud , @xmath8 , and hand parameters , @xmath9 + * output : * antipodal hands , @xmath10 + [ alg : overall ]    @xmath11 @xmath12",
    "a key part of our algorithm is the approach to sampling from the space of hand hypotheses .",
    "a naive approach would be to sample directly from @xmath2 .",
    "unfortunately , this would be immensely inefficient because @xmath13 is a 6-dof space and many hands sampled this way would be far away from any visible parts of the point cloud .",
    "instead , we define a lower - dimensional sample space constrained by the geometry of the point cloud .      r0.5    before describing the sample space , we quantify certain parameters related to the grasp geometry .",
    "we assume the hand , @xmath3 , is a parallel jaw gripper comprised of two parallel fingers each modeled as a rectangular prism that moves parallel to a common plane .",
    "let @xmath14 denote a unit vector orthogonal to this plane .",
    "the hand is fully specified by the parameter vector @xmath15 where @xmath16 and @xmath17 denote the length and width of the fingers ; @xmath18 denotes the distance between the fingers when fully open ; and @xmath19 denotes the thickness of the fingers ( orthogonal to the page in figure  [ fig : hand ] ( a ) ) . define the * closing region * , @xmath20 , to be the volumetric region swept out by the fingers when they close .",
    "let @xmath21 denote an arbitrary reference point in the closing region .",
    "define the * closing plane * , @xmath22 , to be the subset of the plane that intersects @xmath23 , is orthogonal to @xmath14 , and is contained within @xmath24 : @xmath25    we also introduce some notation related to the differential geometry of the surfaces we are grasping . recall that each point on a differentiable surface is associated with a surface normal and two principal curvatures where each principal curvature is associated with a principal direction .",
    "the surface normal and the two principal directions define an orthogonal basis known as a darboux frame  .",
    "the darboux frame at point @xmath26 will be denoted : @xmath27 , where @xmath28 denotes the unit surface normal and @xmath29 denotes the direction of minimum principal curvature at point @xmath30 .",
    "define the * cutting plane * to be the plane orthogonal to @xmath29 that passes through @xmath30 ( see figure  [ fig : hand ] ( b ) ) .",
    "since we are dealing with point clouds , it is not possible to measure the darboux frame exactly at each point .",
    "instead , we estimate the surface normal and principle directions over a small neighborhood",
    ". we fit a quadratic function over the points contained within a small ball ( 3 cm radius in our experiments ) using taubin s method  @xcite and use that to calculate the darboux frame   matrices  @xcite . in comparison to using first order estimates of surface normal and curvature ,",
    "the estimates derived from this quadratic are more robust to local surface discontinuities . ] .",
    "we want a set that contains many antipodal hands and from which it is easy to draw samples .",
    "the following conditions define the set @xmath10 .",
    "first , for every hand , @xmath31 :    the body of the hand is not in collision with the point cloud : @xmath32 ,    furthermore , there must exist a point in the cloud , @xmath33 , such that :    the hand closing plane contains @xmath30 : @xmath34 .",
    "[ const : parallel ] the closing plane of the hand is parallel to the cutting plane at @xmath30 : @xmath35 .",
    "these three constraints define the following set of hands : @xmath36    constraint  [ const : parallel ] is essentially a heuristic that limits the hand hypotheses that our algorithm considers .",
    "while this eliminates from consideration many otherwise good grasps , it is a practical way to focus detection on likely candidates .",
    "moreover , it is easy to sample from @xmath10 by : 1 ) sampling a point , @xmath33 , from the cloud ; 2 ) sampling one or more hands from @xmath37 .",
    "notice that for each @xmath26 , @xmath37 is three - dof because we have constrained two dof of orientation and one dof of position .",
    "this means that @xmath10 is much smaller than @xmath38 and it can therefore be covered by many fewer samples .",
    "point cloud , @xmath8 , hand parameters , @xmath9 + * output : * grasp hypotheses , @xmath10 + [ alg : gethypo ]    @xmath39 preprocess @xmath8 ( voxelize ; workspace limits ; _ etc .",
    "_ ) sample @xmath26 uniformly randomly calculate @xmath18-ball about @xmath30 : @xmath40 estimate local darboux frame at @xmath30 : @xmath41 @xmath42 @xmath43    the sampling process is detailed in algorithm  [ alg : gethypo ] .",
    "first , we preprocess the point cloud , @xmath8 , in the usual way by voxelizing ( we use voxels 3 mm on a side in our experiments ) and applying workspace limits ( step 2 ) .",
    "second , we iteratively sample a set of @xmath44 points ( @xmath44 is between 4000 and 8000 in our experiments ) from the cloud ( step 4 ) . for each point , @xmath26 , we calculate a neighborhood , @xmath45 , in the @xmath18-ball around @xmath30 ( using a kd - tree , step 5 ) .",
    "the next step is to estimate the darboux frame at @xmath30 by fitting a quadratic surface using taubin s method and calculating the surface normal and principal curvature directions ( step 6 ) .",
    "next , we sample a set of hand configurations over a coarse two - dof grid in a neighborhood about @xmath30 .",
    "let @xmath46 denote the hand at position @xmath47 with orientation @xmath48 with respect to the darboux frame , @xmath49 .",
    "let @xmath50 denote a discrete set of orientations ( 8 in our implementation ) .",
    "let @xmath51 denote a discrete set of hand positions ( 20 in our implementation ) .",
    "for each hand configuration @xmath52 , we calculate the hand configuration furthest along the @xmath53 axis that remains collision free : @xmath54 such that @xmath55 , where @xmath56 $ ] ( step 3 )",
    ". then , we check whether the closing plane for this hand configuration contains points in the cloud ( step 4 ) .",
    "if it does , then we add the hand to the hypotheses set ( step 5 ) .",
    "neighborhood point cloud , @xmath57 ; darboux frame , @xmath58 + * output : * neighborhood grasp hypotheses , @xmath38 + [ alg : grasphyp ]    @xmath59 push hand until collision : @xmath54 such that @xmath60      interestingly , our experiments indicate that this sampling method by itself can be used to do grasping . in algorithm  [ alg : overall ] , the sampling process is followed by the grasp classification process described in the next section . however ,",
    "if we omit classification , implicitly assuming that all grasp hypotheses are true grasps , we obtain a surprisingly high grasp success rate of approximately 73% ( the column labeled _ nc , 2v _ in figure  [ fig : per_obj_results_all ] ) .",
    "the experimental context of this result is described in section  [ sect : exps ] .",
    "essentially , we cluster the sampled hands and use a heuristic grasp selection strategy to choose a grasp to execute ( see section  [ sect : grasp_selection ] ) .",
    "this result is surprising because the sampling constraints ( constraints 13 ) encode relatively simple geometric conditions .",
    "it suggests that these sampling constraints are an important part of our overall grasp success rates .",
    "after generating hand hypotheses , the next step is to classify each of those hypotheses as antipodal or not . the simplest approach would be to infer object surface geometry from the point cloud and then check which hands satisfy definition  [ def : pre_antipodal_hand ] . unfortunately , since most real - world point clouds are partial , many hand hypotheses will fail this check simply because all relevant object surfaces were not visible to a sensor . instead",
    ", we infer which hypotheses are likely to be antipodal using machine learning ( _ i.e. _ classification ) .      r0.3        many approaches to grasp point detection require large amounts of training data where humans have annotated images with good grasp points  @xcite .",
    "unfortunately , obtaining these labels is challenging because it can be hard for human labelers to predict what object surfaces in a scene might be graspable for a robot .",
    "instead , our method automatically labels a set of training images by checking a relaxed version of the conditions of definition  [ def : pre_antipodal_hand ] . in order to check whether a hand hypotheses , @xmath3 ,",
    "is antipodal , we need to determine whether an antipodal pair of contacts will be formed when the hand closes",
    ". let @xmath61 denote the direction of closing of one finger .",
    "( in a parallel jaw gripper , the other finger closes in the opposite direction ) . when the fingers close , they will make first contact with an extremal pair of points , @xmath62 such that @xmath63 .",
    "an antipodal hand requires two such extremal points to be antipodal and for the line connecting the points to be parallel to the direction of finger closing . in practice , we relax this condition slightly as follows .",
    "first , rather than checking for extremal points , we check for points that have a surface normal parallel to the direction of closing .",
    "this is essentially a first - order condition for an extremal point that is more robust to outliers in the cloud .",
    "the second way that we relax definition  [ def : pre_antipodal_hand ] is to drop the requirement that the line connecting the two contacts be parallel to the direction of finger closing and to substitute a requirement that at least @xmath64 points are found with an appropriate surface normal .",
    "again , the intention here is to make detection more robust : if there are at least @xmath64 points near each finger with surface normals parallel to the direction of closing , then it is likely that the line connecting at least one pair will be nearly parallel to the direction of finger closing . in summary , we check whether the following definition is satisfied :    [ defn : nearantipodal ] a hand , @xmath3 , is * near antipodal * for thresholds @xmath65 and @xmath66 $ ] when there exist @xmath64 points @xmath67 such that @xmath68 and @xmath64 points @xmath69 such that @xmath70 .",
    "when definition  [ defn : nearantipodal ] is satisfied , then we label the corresponding hand a positive instance .",
    "note that in order to check for this condition , it is necessary to register at least two point clouds produced by range sensors that have observed the scene from different perspectives ( figure  [ fig : stereo ] ) .",
    "this is because we need to `` see '' two nearly opposite surfaces on an object .",
    "even then , many antipodal hands will not be identified as such because only one side of the object is visible .",
    "these `` indeterminate '' hands are omitted from the training set . in some cases , it is possible to verify that a particular hand is _ not _ antipodal by checking that there are fewer than @xmath64 points in the hand closing region that satisfy either of the conditions of definition  [ defn : nearantipodal ] .",
    "these hands are included in the training set as negative examples .",
    "this assumes that the closing region of every sampled hand hypothesis is at least partially visible to a sensor .",
    "if there are fewer than @xmath64 satisfying points , then definition  [ defn : nearantipodal ] would not be satisfied even if the opposite side of an object was observed . in our experiments",
    ", we set the thresholds @xmath71 and @xmath72 degrees .",
    "r0.25     in order to classify hand hypotheses , a feature descriptor is needed .",
    "specifically , for a given hand @xmath3 , we need to encode the geometry of the points contained within the hand closing region , @xmath73 .",
    "a variety of relevant descriptors have been explored in the literature  @xcite . in our case , we achieve good performance using a simple descriptor based on hog features . for a point cloud , @xmath8 , a two dimensional image of the closing region is created by projecting the points @xmath73 onto the hand closing plane : @xmath74 , where @xmath75 selects the first two rows of @xmath76 .",
    "we call this the * grasp hypothesis image*. we encode it using the hog descriptor , @xmath77 . in our implementation , we chose a hog cell size such that the grasp hypothesis image was covered by @xmath78 cells with a standard @xmath79 block size .      in order to create the training set",
    ", we obtain a set of objects that have local geometries similar to what might be expected in the field . in our work",
    ", we selected the set of 18 objects shown in figure  [ fig : trainingdata ] ( a ) .",
    "each object was placed in front of the robot in two configurations : one upright configuration and one on its side . for each configuration ( 36 configurations total ) , let @xmath80 and @xmath81 denote the voxelized point clouds obtained from each of the two sensors , respectively , and let @xmath82 denote the registered two - view cloud .",
    "the training data is generated as follows .",
    "first , we extract hand hypotheses from the registered cloud , @xmath83 using the methods of section  [ sect : finding_hypotheses ] .",
    "second , for each @xmath84 , we determine whether it is a positive , negative , or indeterminate by checking the conditions of definition  [ defn : nearantipodal ] .",
    "indeterminate hands are discarded from training .",
    "third , for each positive or negative hand , we extract three feature descriptors : @xmath85 , @xmath86 , and @xmath87 . each descriptor is given the same label and incorporated into the training set .",
    "over our 18 object training set , this procedure generated approximately 6500 positive and negative labeled examples that were used to train an svm .",
    "we only did one round of training using this single training set .",
    "the fact that we extract three feature descriptors per hand in step three above is important because it helps us to capture the appearance of partial views in the training set .",
    "figure  [ fig : trainingdata ] ( b - d ) illustrates the three descriptors for an antipodal hand .",
    "even though the closing region of this hand is relatively well observed in @xmath83 , the fact that we incorporate @xmath85 and @xmath86 into the dataset means that we are emulating what _ would _ have been observed if we only had a partial view .",
    "this makes our method much more robust to partial point cloud information .",
    "we performed cross validation on a dataset derived from the 18 training objects shown in figure  [ fig : trainingdata ] ( a ) . for each object",
    ", we obtained a registered point cloud for two configurations ( total of 36 configurations ) . following the procedure described in this section , we obtained 6500 labeled features with 3405 positives and 3095 negatives .",
    "we did 10-fold cross validation on this dataset using an svm for the various gaussian and polynomial kernels available in matlab .",
    "we obtained 97.8% accuracy using a degree - three polynomial kernel and used this kernel in the remainder of our experiments . in the cross validation experiment described above",
    ", the folds were random across the labeled pairs in the dataset .",
    "this does not capture the effects of experiencing novel objects or the expected performance when only single - view point clouds are available .",
    "therefore , we did the following .",
    "first , we trained the system using the degree - three polynomial kernel on the 6500 labeled examples as described above .",
    "then , we obtained additional single - view    r0.4        point clouds for each of the 30 novel test objects shown in figure  [ fig : testset ] ( each object was presented in isolation ) for a total of 122 single - view points clouds . we used the methods described in this section to obtain ground - truth for this dataset .",
    "this gave us a total of 7250 labeled single - view hypotheses on novel objects with 1130 positives and 6120 negatives .",
    "we obtained 94.3% accuracy on this dataset .",
    "the fact that we do relatively well in these cross validation experiments using a relatively simple feature descriptor and without mining hard negatives suggests that our approach to sampling hands and creating the grasp hypothesis image makes the grasp classification task easier than it is in approaches that do not use this kind of structure  @xcite .",
    "we evaluated the performance of our algorithms using the baxter robot from rethink robotics .",
    "we explore two experimental settings : when objects are presented to the robot in isolation and when objects are presented in a dense clutter scenario .",
    "we use the baxter right arm equipped with the stock two - finger baxter gripper .",
    "a key constraint of the baxter gripper is the limited finger stroke : each finger has only 2 cm stroke . in these experiments , we adjust the finger positions such that they are 3 cm apart when closed and 7 cm apart when open .",
    "this means we can not grasp anything smaller than 3 cm or larger than 7 cm .",
    "we chose each object in the training and test sets so that it could be grasped under these constraints .",
    "two - view registered point clouds were created using asus xtion pro range sensors ( see figure  [ fig : stereo ] ) .",
    "it should be possible for anyone with a baxter robot and the appropriate depth sensors to replicate any of these experiments by running our ros package at http://wiki.ros.org/agile_grasp .",
    "since our algorithm typically finds tens or hundreds of potential antipodal hands , depending upon the number of objects in the scene , it is necessary to select one to execute .",
    "one method might be to select a grasp on an object of interest .",
    "however , in this paper , we ignore object identity and perform any feasible grasp .",
    "we choose a grasp to attempt as follows .",
    "first , we sparsify the set of grasp choices by clustering antipodal hands based on distance and orientation .",
    "grasp hypothesis that are nearby each other and that are roughly aligned in orientation are grouped together",
    ". each cluster must be composed of a specified minimum number of constituent grasps . if a cluster is found , then we create a new grasp hypothesis positioned at the mean of the cluster and oriented with the `` average '' orientation of the constituent grasps .",
    "the next step is to select a grasp based on how easily it can be reached by the robot .",
    "first , we solve the inverse kinematics ( ik ) for each of the potential grasps and discard those for which no solution exists .",
    "the remaining grasps are ranked according to three criteria : 1 ) distance from joint limits ( a piecewise function that is zero far from the arm joint limits and quadratic nearby the limits ) ; 2 ) distance from hand joint limits ( zero far from the limits and quadratic nearby limits ) ; 3 ) workspace distance traveled by the hand starting from a fixed pre - grasp arm configuration .",
    "these three criteria are minimized in order of priority : first we select the set of grasps that minimize criterion # 1 . of those , we select those that minimize criterion # 2 . of those",
    ", we select the one that minimizes criterion # 3 as the grasp to be executed by the robot .      [",
    "cols=\"<,^,^,^,^,^,^,^ \" , ]     we performed a series of experiments to evaluate how well various parts of our algorithm perform in the context of grasping each of the 30 test set objects ( figure  [ fig : testset ] ) .",
    "each object was presented to the robot in isolation on a table in front of the robot .",
    "we characterize three variations on our algorithm :    1 .   * no classification : * we assume that all hand hypotheses generated by the sampling algorithm ( algorithm  [ alg : gethypo ] ) are antipodal and pass all hand samples directly to the grasp selection mechanism without classification as described in section  [ sect : grasp_selection ] .",
    "* antipodal : * we classify hand hypotheses by evaluating the conditions of definition  [ defn : nearantipodal ] directly for each hand and pass the results to grasp selection .",
    "* svm : * we classify hand hypotheses using the svm and pass the results to grasp selection .",
    "the system was trained using the 18-object training set as described in section  [ sect : crossvalidation ] .    in all scenarios ,",
    "a grasp trial was considered a success only when the robot successfully localized , grasped , lifted , and transported the object to a box on the side of the table .",
    "we evaluate _ no classification _ and _ svm _ for single - view and two - view registered points clouds over 214 grasps of the 30 test objects .",
    "each object was placed in between 6 and 8 systematically different orientations relative to the robot .",
    "figure  [ fig : per_obj_results_all ] shows the results .",
    "the results for _ no classification _ are shown in columns _ nc , 1v _ and",
    "_ nc , 2v_. column _ nc , 1v _ shows that with a point cloud created using only one depth sensor , using the results of sampling with no additional classification results in an average grasp success rate of 58% .",
    "however , as shown in column _ nc , 2v _ , it is possible to raise this success rate to 73% just by adding a second depth sensor and using the resulting two - view registered cloud .",
    "the fact that we obtain a grasp success rate as high as 73% here is surprising considering that the sample strategy employs rather simple geometric constraints .",
    "this suggests that even simple geometric constraints can improve grasp detection significantly .",
    "the results for _ antipodal _ are shown in the column labeled _ a , 2v_. we did not evaluate this variation for a one - view cloud because a two - view cloud is needed for definition  [ defn : nearantipodal ] to find any near antipodal hands . compared to the other two approaches , _ antipodal _ finds relatively few positives .",
    "this is because this method needs to `` see '' two sides of a potential grasp surface in order to verify the presence of a grasp . as a result",
    ", we were only able to evaluate this method over three poses per object instead of six or eight .",
    "in fact , _ antipodal _ failed to find any grasps at all for four of the 30 objects .",
    "overall , _",
    "antipodal _ can be an effective way to detect grasps ( 94.7% grasp success rate ) , but since it is not robust to occlusions at all , it is not very useful in practice .",
    "the results for _ svm _ are shown in columns _",
    "svm , 1v _ and _ svm , 2v _ ( results for one - view and two - view point clouds , respectively ) .",
    "interestingly , there is not much advantage here to adding a second depth camera : we achieve an 85.0% success rate with a one - view point cloud and an 87.8% success rate with a two - view registered cloud .",
    "drilling down into these numbers , we find the following three major causes of grasp failure : 1 ) approximately 5.6% of the grasp failure rate in both scenarios is due to collisions between the gripper and the object caused by arm calibration errors or collisions with observed or unobserved parts of the environment ; 2 ) approximately 3.5% of the objects were dropped after a successful initial grasp ; 3 ) approximately 2.3% of grasp failures in the two - view case ( 3.7% in the one view case ) were caused by perceptual errors .",
    "the striking thing about the causes of failure listed above is that they are not all perceptual errors : if we want to improve beyond the 87.8% success rate , we need to improve performance in multiple areas .",
    "r0.32        in the experiments described above , we eliminated seven objects from the test set because they were hard to see with our depth sensor ( asus primesense ) due to specularity , transparency , or color .",
    "we characterized grasp performance for these objects separately by grasping each of these objects in eight different poses ( total of 56 grasps over all seven objects ) . using _",
    ", we obtain a 66.7% grasp success rate using a single - view point cloud and a 83.3% grasp success rate when a two - view cloud is used .",
    "this result suggests : 1 ) our 87.8% success rate drops to 83% for hard - to - see objects ; 2 ) creating a more complete point cloud by adding additional sensors is particularly important in non - ideal viewing conditions .",
    "we also characterized our algorithm in dense clutter as illustrated in figure  [ fig : clutterexamples ] .",
    "we created a test scenario where ten objects are piled together in a shallow box .",
    "we used exactly the same algorithm ( i.e. _ svm _ ) in this experiment as in the isolated object experiments .",
    "we used a two - view registered point cloud in all cluttered scenarios .",
    "the 27 objects used in this experiment are a subset of the 30 objects used in the single object experiments .",
    "we eliminated the computer mouse and the engraver because they have cables attached to them that can get stuck in the clutter .",
    "we also removed the vacuum brush because the brush part can not be grasped by the baxter gripper in some configurations due to the 37 cm aperture limits . at the beginning of each run , we randomly selected 10 out of the 27 objects and placed them in a small rectangular container .",
    "we then shook the container to mix up the items and emptied it into the shallow box on top of the table .",
    "we excluded all runs where the sandcastle landed upside down because the baxter gripper can not grasp it in that configuration .",
    "a run was terminated when three consecutive localization failures occurred . in total",
    ", we performed 10 runs of this experiment .",
    "over all 10 runs of this experiment , the robot performed 113 grasps . on average , it succeeded in removing 85% of the objects from each box .",
    "the remaining objects were not grasped because the system failed to localize a grasp point three times in a row . over all grasp attempts , 73% succeeded .",
    "the 27% failure rate breaks down into the following major failure modes : 3% due to arm calibration errors ; 9% due to perceptual errors ; 4% due to dropped objects following a successful grasp ; and 4% due to collision with the environment . in comparison with the isolation results ,",
    "these results have a significantly higher perceptual failure rate .",
    "we believe this is mainly due to the extensive occlusions in the clutter scenario .",
    "this paper proposes a new approach to localizing grasp points on novel objects presented in clutter .",
    "our main idea is to improve detection by using geometric knowledge about good grasps .",
    "we first create a large set of high quality grasp hypotheses by drawing samples that satisfy simple , geometrically necessary conditions .",
    "we then use the geometry of an antipodal grasp to create a large automatically labeled training set that enables us to achieve high classification accuracy using an svm .",
    "if we omit the classification phase of this algorithm and consider all samples to be good grasps , then we achieve an average grasp success rate of 73% when grasping objects presented in isolation .",
    "this success rate is surprisingly high because the sampling process only checks very simple necessary conditions on the presence of a grasp .",
    "it suggests that our proposed geometry - based sampling method is very effective .",
    "the average success rate increases to 87.8% when the sampled hypotheses are classified as antipodal grasps using an svm .",
    "when grasping novel objects presented in dense clutter , the success rate drops to 73% as a result of extensive occlusions .",
    "the fact that performance drops so significantly in dense clutter suggests that it is important to study the perceptual challenges unique to dense clutter grasp scenarios .",
    "this paper is one of the first to propose a systematic way of measuring grasp performance in dense clutter .",
    "we hope to expand on this analysis of dense clutter in the future .",
    "this system is available as a ros package at http://wiki.ros.org/agile_grasp ."
  ],
  "abstract_text": [
    "<S> this paper proposes a new approach to detecting grasp points on novel objects presented in clutter . </S>",
    "<S> the input to our algorithm is a point cloud and the geometric parameters of the robot hand . </S>",
    "<S> the output is a set of hand configurations that are expected to be good grasps . </S>",
    "<S> our key idea is to use knowledge of the geometry of a good grasp to improve detection . </S>",
    "<S> first , we use a geometrically necessary condition to sample a large set of high quality grasp hypotheses . </S>",
    "<S> we were surprised to find that using simple geometric conditions for detection can result in a relatively high grasp success rate . </S>",
    "<S> second , we use the notion of an antipodal grasp ( a standard characterization of a good two fingered grasp ) to help us classify these grasp hypotheses . </S>",
    "<S> in particular , we generate a large automatically labeled training set that gives us high classification accuracy . </S>",
    "<S> overall , our method achieves an average grasp success rate of 88% when grasping novels objects presented in isolation and an average success rate of 73% when grasping novel objects presented in dense clutter . </S>",
    "<S> this system is available as a ros package at http://wiki.ros.org/agile_grasp . </S>"
  ]
}