{
  "article_text": [
    "wireless data traffic is predicted to continue its exponential growth in the coming years , mainly driven by the proliferation of mobile devices with increased processing and display capabilities , and the explosion of available online contents .",
    "current wireless architecture is widely acknowledged not to be sufficient to sustain this dramatic growth . a promising approach to alleviate the looming network congestion is to _ proactively _ place popular contents , fully or partially , at the network edge during off - peak traffic periods ( see , for example , @xcite , and references therein ) .",
    "conventional caching schemes utilize orthogonal unicast transmissions , and benefit mainly from local duplication . on the other hand , by _ coded caching _",
    ", a novel caching mechanism introduced in@xcite , further gains can be obtained by creating multicasting opportunities even across different requests .",
    "this is achieved by jointly optimizing the _ placement _ and _ delivery _ phases .",
    "coded caching has recently been investigated under various settings , e.g. , decentralized coded caching  @xcite , online coded caching  @xcite , distributed caching  @xcite , etc .",
    "most of the existing literature follow the model in @xcite , in the sense that each file is assumed to have a fixed size , and users are interested in the whole file .",
    "however , in many practical applications , particularly involving multimedia contents , files can be downloaded at various quality levels depending on the channel and traffic conditions , or device capabilities .",
    "this calls for the design of _ lossy _ caching and delivery mechanisms .",
    "we model the scenario in which each user has a preset distortion requirement known to the server .",
    "for example , a laptop may require high quality descriptions of requested files , whereas a mobile phone is satisfied with much lower resolution .",
    "users may request any of the popular files , and the server is expected to satisfy all request combinations at their desired quality levels .",
    "we model the files in the server as independent sequences of gaussian distributed random variables . exploiting the successive refinability  @xcite of gaussian sources ,",
    "we derive the optimal caching scheme for the two - user , two - file scenario . for the general case",
    ", we propose an efficient coded caching scheme which considers multiple layers for each file , and first allocates the available cache capacity among these layers , and then solves the lossless caching problem with asymmetric cache capacities for each layer .",
    "we propose two algorithms for cache capacity allocation , namely _ proportional cache allocation ( pca ) _ and _ ordered cache allocation ( oca ) _ , and numerically compare the performance of the proposed layered caching scheme with the cut - set lower bound .",
    "the most related work to this paper is  @xcite , in which hassanzadeh et al .",
    "solve the inverse of the problem studied here , and aim at minimizing the average distortion across users under constraints on the delivery rate as well as the cache capacities . in  @xcite",
    ", authors also consider lossy caching taking into account the correlation among the available contents , based on which the tradeoff between the compression rate , reconstruction distortion and cache capacity is characterized for single , and some special two - user scenarios .",
    "the rest of the paper is organized as follows .",
    "we present the system model in section  [ sec1 ] .",
    "section  [ section:2 ] presents results on the case with two files and two users .",
    "general case is investigated in section  [ sec2b ] , including a lower bound on the delivery rate .",
    "numerical simulations are presented in section  [ sec4 ] .",
    "finally , we conclude the paper in section vi .",
    "we consider a server that is connected to @xmath0 users through a shared , error - free link .",
    "the server has a database of @xmath1 independent files , @xmath2 , ... , @xmath3 , where file @xmath4 consists of @xmath5 independent and identically distributed ( i.i.d ) samples @xmath6 , ... ,",
    "@xmath7 from a gaussian distribution with zero - mean and variance @xmath8 , i.e. , @xmath9 , for @xmath10 .",
    "the system operates in two phases . in the _ placement phase _",
    ", users caches are filled with the knowledge of the number of users and each user s quality requirement ; but without the particular user demands .",
    "each user has a cache of size @xmath11 bits , whose content at the end of the _ placement phase _ is denoted by @xmath12 , @xmath13 .",
    "users requests , @xmath14 , @xmath15 , are revealed after the _ placement phase_. in the _ delivery phase _ , the server transmits a single message @xmath16 of size @xmath17 bits over the shared link according to all the users requests and the cache contents . using @xmath12 and @xmath16",
    ", each user @xmath18 aims at reconstructing the file it requests within a certain distortion target @xmath19 .",
    "an @xmath20 _ lossy caching code _",
    "consists of @xmath0 cache placement functions : @xmath21 where @xmath22 ; one delivery function : @xmath23 where @xmath24 ; and @xmath0 decoding functions : @xmath25 where @xmath26 .",
    "note that each user knows the requests of all other users in the delivery phase .",
    "we consider quadratic ( squared - error ) distortion , and assume that each user has a fixed distortion requirement @xmath19 , @xmath13 . without loss of generality , let @xmath27 .",
    "accordingly , we say that a distortion tuple @xmath28 is _ achievable _ if there exists a sequence of caching codes @xmath20 , such that @xmath29 holds for all possible request combinations @xmath30 .",
    "we reemphasize that @xmath30 is not known during the _ placement phase _ , while @xmath31 is known . for a given distortion tuple @xmath31",
    ", we define the _ cache capacity - delivery rate tradeoff _ as follows : @xmath32    note that this problem is closely related to the classical rate - distortion problem .",
    "let @xmath33 denote the _ rate - distortion function _ of a gaussian source @xmath34 .",
    "we have @xmath35  @xcite .    in the sequel",
    "we heavily exploit the _ successive refinability _ of a gaussian source under squared - error distortion measure  @xcite .",
    "successive refinement refers to compressing a sequence of source samples in multiple stages , such that the quality of reconstruction improves , i.e. , distortion reduces , at every stage .",
    "a given source is said to be successively refinable under a given distortion measure if the single resolution distortion - rate function can be achieved at every stage .",
    "successive refinement has been extensively studied in the source coding literature ; please see  @xcite for its use in the caching context .",
    "in this section , we characterize the optimal cache capacity - delivery rate tradeoff for the lossy caching problem with two users ( @xmath37 ) and two files ( @xmath38 ) .",
    "the target average distortion values for user 1 and user 2 are @xmath39 and @xmath40 , respectively , with @xmath41 .",
    "let @xmath42 and @xmath43 be the minimum compression rates that achieve @xmath39 and @xmath40 , respectively ; that is @xmath44 , @xmath45 .",
    "this means that , to achieve the target distortion of @xmath46 , the user has to receive a minimum of @xmath47 bits corresponding to its desired file .",
    "[ table1 ]    [ cols=\"<,^,^,^,^,^,^,^,^ \" , ]     we first present lemma 1 specifying the lower bound on the delivery rate for given @xmath48 and @xmath49 in this particular scenario , followed by the coded caching scheme achieving this lower bound .",
    "the proof of the lemma is skipped due to space limitations .",
    "[ lemma_nk2 ] for the lossy caching problem with @xmath50 , a lower bound on the cache capacity - delivery rate tradeoff is given by @xmath51    the first three terms in ( [ eq44 ] ) are derived from the cut - set lower bound , which will be presented for the general scenario in theorem 1 .",
    "based on ( [ eq44 ] ) , we consider five cases depending on the cache capacities of the users , illustrated in fig .  1 :    [ fig1 ]   and @xmath49 , depending on the distortion requirements of the users , @xmath42 and @xmath43.,title=\"fig : \" ]    _ case i _ : @xmath52 .",
    "in this case , @xmath53 .    _ case",
    "ii _ : @xmath54 , @xmath55 , @xmath56 .",
    "we have @xmath57 .",
    "_ case iii _ : @xmath58 , @xmath59 , @xmath60 . then @xmath61 .",
    "_ case iv _ : @xmath62 , @xmath63 , @xmath64 .",
    "it yields @xmath65 .",
    "_ case v _ : @xmath66 , @xmath67 . then @xmath68 .    next , for each of these cases , we explain the coded caching scheme that achieves the corresponding @xmath69 .",
    "we assume that the server employs an optimal successive refinement source code , denoted by @xmath70 the source codeword of length @xmath71 bits that can achieve a distortion of @xmath40 for file @xmath72 .",
    "thanks to the successive refinability of gaussian sources , a receiver having received only the first @xmath73 of these bits can achieve a distortion of @xmath39 .",
    "we refer to the first @xmath73 bits as the first layer , and the @xmath74 remaining bits as the second layer .    in each case",
    ", we divide the first layers of codewords @xmath75 and @xmath76 into six disjoint parts denoted by @xmath77 , @xmath78 , @xmath79 and @xmath80 , @xmath78 , @xmath81 , and the second layers into two disjoint parts denoted by @xmath82 , @xmath83 and @xmath84 , @xmath85 , such that @xmath86 for @xmath87 , where @xmath88 denotes the length of the binary sequence @xmath89 ( normalized by @xmath5 ) .",
    "table  i illustrates the placement of contents in users caches for each case .",
    "the second and third rows illustrate how the first and second layers are partitioned for each file .",
    "the fourth and fifth rows indicate the cache contents of each user at the end of the _ placement phase_. in all the cases , user 1 caches @xmath90 and user 2 caches @xmath91 .",
    "the entries from the 6th row to the 10th specify the size of each portion in each case .",
    "for example , the 6th row implies that in _ case i _ , @xmath92 , @xmath93 , @xmath94 , @xmath95 , and the sizes of all other portions are equal to @xmath96 , which is equivalent to dividing @xmath70 into four portions @xmath97 , @xmath98 , @xmath99 and @xmath100 .",
    "thus , in the placement phase , user 1 caches @xmath101 , and user 2 caches @xmath102 so that @xmath103 and @xmath104 , which meets the cache capacity constraints .",
    "the cache placements of the other 4 cases are presented in a similar manner in table  i.    next , we focus on the delivery phase",
    ". we will explain the delivered message in each case to satisfy demands @xmath105 .",
    "all other requests can be satisfied similarly , without requiring higher delivery rates .",
    "_ case i _ ( @xmath52 ) : the server sends @xmath80 , @xmath106 , @xmath79 , @xmath81 and @xmath85 .",
    "thus , the delivery rate is @xmath107    _ case ii _",
    "( @xmath54 , @xmath55 , @xmath56 ) : server delivers @xmath80 , @xmath106 and @xmath85 .",
    "we have @xmath108    _ case iii _",
    "( @xmath58 , @xmath59 , @xmath60 ) : the values of @xmath109 and @xmath110 in table i are given as : @xmath111 and @xmath112 .",
    "the server sends @xmath80 , @xmath113 and @xmath85 in the delivery phase , which results in @xmath114    _ case iv _  ( @xmath62 , @xmath63 , @xmath64 ) : the server sends @xmath115 , @xmath113 and we have @xmath116    _ case v _ ( @xmath66 , @xmath67 ) : the cache capacities of both users are sufficient to cache the required descriptions for both files .",
    "thus , any request can be satisfied from local caches at desired distortion levels , and we have @xmath117 .    for @xmath50 , the proposed caching scheme meets the lower bound in lemma [ lemma_nk2 ] ; and hence , it is optimal , i.e. , we have @xmath118 .",
    "in this section , we tackle the lossy content caching problem in the general setting with @xmath1 files and @xmath0 users . recall that the distortion requirements are assumed to be ordered as @xmath27 .",
    "let @xmath119 , @xmath13 . exploiting the successive refinability of gaussian sequences , we consider a layered structure of descriptions for each file , where the first layer , called the @xmath42-description , consists of @xmath73 bits , and achieves distortion @xmath39 when decoded .",
    "the @xmath18th layer , called the @xmath120-refinement , @xmath121 , consists of @xmath122 bits , and having received the first @xmath18 layers , a user achieves a distortion of @xmath19 .",
    "the example in section  [ section:2 ] illustrates the complexity of the problem ; we had five different cases even for two users and two files .",
    "the problem becomes intractable quickly with the increasing number of files and users .",
    "however , note that only users @xmath123 , whose distortion requirements are lower than @xmath19 , need to decode the @xmath18th layer for the file they request , for @xmath13 . therefore ,",
    "once all the contents are compressed into @xmath0 layers based on the distortion requirements of the users employing an optimal successive refinement source code , we have , for each layer , a lossless caching problem .",
    "however , each user also has to decide how much of its cache capacity to allocate for each layer .",
    "hence , the lossy caching problem is divided into two subproblems : the lossless caching problem of each source coding layer , and the cache allocation problem among different layers .",
    "here we focus on the first subproblem , and investigate centralized lossless caching with heterogeneous cache sizes , which is unsolved in the literature , regarding each layer separately .",
    "consider , for example , the @xmath18th refinement layers of all the files .",
    "there are only @xmath124 users ( users @xmath123 ) who may request these layers .",
    "let user @xmath125 , @xmath126 , allocate @xmath127 ( normalized by @xmath5 ) of its cache capacity for this layer . without loss of generality , we order users @xmath128 according to the cache capacity they allocate , and re - index them , such that @xmath129 .",
    "we would like to have symmetry among allocated cache capacities to enable multicasting to a group of users . based on this intuition ,",
    "we further divide layer @xmath18 into @xmath130 sub - layers , and let each user in @xmath131 allocate @xmath132 of its cache for the first sub - layer , and each user in @xmath133 allocate @xmath134 of its cache for the @xmath135th sublayer , for @xmath136 .",
    "overall , we have @xmath130 sub - layers , and users @xmath137 allocate @xmath138 of their caches for sub - layer @xmath135 , whereas no cache is allocated by users @xmath139 .",
    "we denote by @xmath140 the size of the @xmath135th sub - layer of the @xmath18th refinement layer , and by @xmath141 the minimum required delivery rate for this sub - layer .",
    "the rates , @xmath140 , @xmath142 , should be optimized jointly in order to minimize the total delivery rate for the @xmath18th layer .",
    "the optimization problem can be formulated as follows :    @xmath143    @xmath144    we explore the achievable @xmath141 based on the existing caching schemes in in  @xcite and @xcite , which are referred to as _ coded delivery _ and _ coded placement _ , respectively .",
    "we consider two cases :    case 1 ) @xmath145 . in this case ,",
    "coded placement scheme of @xcite provides no global caching gain .",
    "thus , we employ only coded delivery , and illustrate this scheme in our setup by focusing on the @xmath135th sub - layer : users @xmath146 to @xmath0 each allocate @xmath147 of cache capacity , while users @xmath18 to @xmath148 allocate no cache for this sublayer . if @xmath149 , where @xmath150 , we have @xmath151 the first term on the right hand side is due to unicasting to users @xmath18 to @xmath148 , while the second term is the _ coded delivery _ rate to users @xmath146 to @xmath0 given in  @xcite . based on the memory sharing argument , any point on the line connecting two points , @xmath152 and @xmath153 , is also achievable , i.e. , if @xmath154 $ ] , then we have @xmath155 where @xmath156 ; and if @xmath157 , we have @xmath158    case 2 ) @xmath159 . in this case , _ coded placement _ outperforms _ coded delivery _ if the allocated cache capacity satisfies @xmath160@xcite .",
    "note that for the @xmath135th sub - layer , there are @xmath161 users with no cache allocation .",
    "if @xmath162 , there will be no gain with either schemes .",
    "when @xmath163 and @xmath164 , the delivery rate of _ coded placement _",
    "is @xmath165 when @xmath166 , the delivery rate is given by the lower convex envelope of points @xmath167 given by ( [ eq6 ] ) and @xmath168 , and for @xmath169 , given by ( [ eq3 ] ) .",
    "we propose two algorithms for cache allocation among layers : _ proportional cache allocation _ ( pca ) and _ ordered cache allocation _ ( oca ) , which are elaborated in algorithms  1 and  2 , respectively , where @xmath170 is as defined earlier , and we let @xmath171 . .",
    "[ alg3 ]    [ alg4 ]    pca allocates each user s cache among the layers it may request proportionally to the sizes of the layers , while oca gives priority to lower layers .",
    "the server can choose the one resulting in a lower delivery rate .",
    "numerical comparison of these two allocation schemes will be presented in section v.      the following lower bound is obtained using cut - set arguments .",
    "( cut - set bound ) for the lossy caching problem described in section  [ sec1 ] , the optimal achievable delivery rate is lower bounded by @xmath172",
    "in this section , we numerically compare the achievable delivery rates for uncoded caching , the proposed caching schemes , and the lower bound . in fig .",
    "2 , we consider @xmath173 users and @xmath174 files in the server .",
    "cache sizes of the users are identical , i.e. , @xmath175 .",
    "the distortion levels @xmath176 are such that @xmath177 .",
    "while we observe that the proposed coded caching scheme greatly reduces the delivery rate , oca performs better for small cache sizes , while pca dominates as @xmath178 increases .",
    "using memory sharing , we can argue that the dotted curve in fig .",
    "2 , which is obtained through the convex combination of the delivery rates achieved by the two proposed schemes , is also achievable .",
    "[ fig4 ]     in fig .",
    "3 , we consider the same setting but with heterogeneous cache sizes , where @xmath179 , for @xmath180 . in this",
    "setting , pca allocates the same amount of cache to each layer at different users , which creates symmetry among the caches .",
    "the achievable delivery rates in fig . 3 illustrate significant improvements in coded caching with pca over both uncoded and oca schemes in terms of the achievable delivery rates .",
    "we observe that the gains become more significant as the cache capacity , @xmath178 , increases . while the lower bound is not tight in general , we see in both figures that the pca performance follows the lower bound with an approximately constant gap over the range of @xmath178 values considered .",
    "we investigated the lossy caching problem where users have different distortion requirements for the reconstruction of contents they request .",
    "we proposed a coded caching scheme that achieves the information - theoretic lower bound for the special case with two users and two files .",
    "then , we tackled the general case with @xmath0 users and @xmath1 files in two steps : delivery rate minimization , which finds the minimum delivery rate for each layer separately , and cache allocation among layers .",
    "we proposed two different algorithms for the latter , namely , pca and oca .",
    "our simulation results have shown that the proposed pca scheme improves the required delivery rate significantly for a wide range of cache capacities ; and particularly when the users cache capacities are heterogenous .",
    "n.  golrezaei , k.  shanmugam , a. g.  dimakis , a.  f.  molisch and g.  caire , `` femtocaching : wireless video content delivery through distributed caching helpers , '' in _ proc .",
    "ieee infocom _ ,",
    "orlando , fl , mar .",
    "2012 , pp.11071115 ."
  ],
  "abstract_text": [
    "<S> _ centralized coded caching _ of popular contents is studied for users with heterogeneous distortion requirements , corresponding to diverse processing and display capabilities of mobile devices . </S>",
    "<S> users distortion requirements are assumed to be fixed and known , while their particular demands are revealed only after the _ placement phase_. modeling each file in the database as an independent and identically distributed gaussian vector , the minimum _ delivery rate _ that can satisfy any demand combination within the corresponding distortion target is studied . </S>",
    "<S> the optimal delivery rate is characterized for the special case of two users and two files for any pair of distortion requirements . for the general </S>",
    "<S> setting with multiple users and files , a layered caching and delivery scheme , which exploits the successive refinability of gaussian sources , is proposed . </S>",
    "<S> this scheme caches each content in multiple layers , and it is optimized by solving two subproblems : lossless caching of each layer with heterogeneous cache capacities , and allocation of available caches among layers . the delivery rate minimization problem for each layer is solved numerically , while two schemes , called the _ proportional cache allocation ( pca ) _ and _ ordered cache allocation ( oca ) _ , are proposed for cache allocation . </S>",
    "<S> these schemes are compared with each other and the cut - set bound through numerical simulations . </S>"
  ]
}