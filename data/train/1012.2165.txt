{
  "article_text": [
    "many applied probability problems , ranging from the average case analysis of algorithms to statistical physics , reduce to distributional fixed point equations of the form @xmath10 where @xmath1 is a possibly random real valued function , @xmath11 , @xmath12 , @xmath3 are real valued random weights and @xmath4 are iid copies of @xmath5 , independent of @xmath6 . for a recent survey of a variety of problems where these equations appear see @xcite .",
    "the solutions to these types of equations can be recursively constructed on a weighted branching tree , where @xmath13 represents the generic branching variable and the @xmath3 are the branching weights .",
    "for this reason , we also refer to as recursions on weighted branching trees .    in this paper",
    ", we develop an implicit renewal theorem , stated in theorem  [ t.newgoldie ] , that enables the characterization of the power tail behavior of the solutions @xmath5 to many equations of multiplicative nature of the form in .",
    "this result extends the prior work in @xcite , which assumed nonnegative weights @xmath8 , to general real valued weights .",
    "this work also fully generalizes the implicit renewal theorem of goldie ( 1991 ) @xcite , which was derived for equations of the form @xmath14 ( equivalently @xmath15 in our case ) , to recursions ( fixed point equations ) on trees .",
    "note that even in the classical non - branching problem the proof of the mixed sign case is quite involved , see the proof of case  2 on pp .",
    "145 - 149 in @xcite .",
    "we provide here a streamlined matrix form derivation of theorem 2.3 in @xcite that seamlessly extends to trees . for completeness",
    ", we also derive the lattice version of our implicit renewal theorem in theorem  [ t.newgoldie_lattice ] .",
    "one of the key observations leading to theorems  [ t.newgoldie ] and  [ t.newgoldie_lattice ] is that an appropriately constructed measure on a weighted branching tree is a matrix renewal measure , see lemma  [ l.renewalmeasure ] and equation .",
    "we illustrate the developed theorem by deriving the power tail asymptotics of the nonhomogeneous linear recursion @xmath16 where @xmath17 , @xmath3 are real valued random weights , @xmath18 is a real valued random variable with @xmath19 and @xmath4 are iid copies of @xmath5 , independent of @xmath6 .",
    "this recursion appeared recently in the stochastic analysis of google s pagerank algorithm , see @xcite and the references therein for the latest work in the area .",
    "these types of weighted recursions , also known as weighted branching processes @xcite , are found in the probabilistic analysis of other algorithms as well @xcite , e.g. quicksort algorithm @xcite , see @xcite for additional references .",
    "in addition , equation generalizes other well studied problems in the literature , e.g. : for @xmath20 , it reduces to an autoregressive process of order one and for @xmath21 constant , @xmath5 represents the busy period of an m / g/1 queue ( e.g. see @xcite ) . in the context of google",
    "s pagerank algorithm , @xmath5 represents the rank of a generic page , @xmath13 is the number of neighbors of such a page , and the @xmath8 are the weights that determine the contribution of each neighboring page to the total rank @xmath5 . here , we argue that if the pointer by neighbor @xmath22 represents a negative reference , then the weight @xmath23 of such a reference should be negative as well , i.e. , negative references should not increase the rank of @xmath5 .",
    "hence , in this paper , we allow the weights @xmath8 to be possibly negative .",
    "note that the majority of the work in the rest of the paper goes into the application of the main theorem to the nonhomogeneous recursion in . in this regard , in section  [ s.linearrec ]",
    ", we first construct an explicit solution to on a weighted branching tree and then provide sufficient conditions for the finiteness of moments of this solution in lemma  [ l.moments_r ] .",
    "in addition , under quite general conditions , it can be shown that this solution is unique under iterations , see lemma  4.5 in @xcite .",
    "however , the fixed point equation can have additional stable solutions , as it was recently discovered in @xcite ; earlier work for the case when @xmath24 are deterministic real - valued constants can be found in @xcite .",
    "furthermore , it is worth noting that our moment estimates are explicit , see lemma [ l.generalmoment ] , which may be of independent interest .",
    "then , the main result , which characterizes the power - tail behavior of @xmath5 is presented in theorem  [ t.linearrecursion ] .",
    "in addition , for integer power exponent ( @xmath25 ) the asymptotic tail behavior can be explicitly computed , see corollary  4.9 in @xcite .",
    "furthermore , for non integer @xmath26 , lemma [ l.alpha_moments ] can be used to derive an explicit bound on the tail behavior of @xmath5 .",
    "similarly as in @xcite , our technique could be potentially applied to study the tail asymptotics of the solution to the critical , @xmath27 = 1 $ ] , homogeneous linear equation @xmath28 where @xmath3 is a real valued random vector with @xmath29 and @xmath4 is a sequence of iid random variables independent of @xmath6 having the same distribution as @xmath5 ; note that @xcite considered the nonnegative @xmath3 case .",
    "see @xcite and the references therein for prior work on the power tail asymptotics of the homogeneous linear recursion . for additional references on weighted branching processes and multiplicative cascades see @xcite and the references therein . for earlier historical references",
    "see @xcite . in the same fashion",
    ", one can also study many other possibly nonlinear distributional equations , e.g. , @xmath30 see @xcite for additional details on how theorem  [ t.newgoldie ] can be applied to these , as well as other stochastic recursions .",
    "the majority of the proofs are postponed to section  [ s.proofs ] .",
    "first we construct a random tree @xmath31 .",
    "we use the notation @xmath32 to denote the root node of @xmath31 , and @xmath33 , @xmath34 , to denote the set of all individuals in the @xmath35th generation of @xmath31 , @xmath36 .",
    "let @xmath37 be the number of individuals in the @xmath35th generation , that is , @xmath38 , where @xmath39 denotes the cardinality of a set ; in particular , @xmath40 .",
    "next , let @xmath41 be the set of positive integers and let @xmath42 be the set of all finite sequences @xmath43 , where by convention @xmath44 contains the null sequence @xmath32 . to ease the exposition , for a sequence @xmath45 we write @xmath46 , provided @xmath47 , and @xmath48 to denote the index truncation at level @xmath35 , @xmath34 .",
    "also , for @xmath49 we simply use the notation @xmath50 , that is , without the parenthesis . similarly , for @xmath51 we will use @xmath52 to denote the index concatenation operation , if @xmath53 , then @xmath54 .",
    "we iteratively construct the tree as follows .",
    "let @xmath13 be the number of individuals born to the root node @xmath32 , @xmath55 , and let @xmath56 be iid copies of @xmath13 .",
    "define now @xmath57 it follows that the number of individuals @xmath38 in the @xmath35th generation , @xmath58 , satisfies the branching recursion @xmath59    ( 430,160)(0,0 ) ( 0,0 ) ( 125,150)@xmath60 ( 69,83)@xmath61 ( 131,83)@xmath62 ( 219,83)@xmath63 ( 22,17)@xmath64 ( 78,17)@xmath65 ( 126,17)@xmath66 ( 162,17)@xmath67 ( 213,17)@xmath68 ( 268,17)@xmath69 ( 350,150)@xmath40 ( 350,83)@xmath70 ( 350,17)@xmath71    now , we construct the weighted branching tree @xmath72 as follows .",
    "let @xmath73 be a sequence of iid copies of @xmath74 .",
    "@xmath75 determines the number of nodes in the first generation of of @xmath31 according to , and each node in the first generation is then assigned its corresponding vector @xmath76 from the iid sequence defined above .",
    "in general , for @xmath77 , to each node @xmath78 we assign its corresponding @xmath79 from the sequence and construct @xmath80 . for each node in @xmath72",
    "we also define the weight @xmath81 via the recursion @xmath82 where @xmath83 is the weight of the root node .",
    "note that the weight @xmath84 is equal to the product of all the weights @xmath85 along the branch leading to node @xmath86 , as depicted in figure [ f.tree ] . in some places ,",
    "e.g. in the following section , the value of @xmath18 may be of no importance , and thus we will consider a weighted branching tree defined by the smaller vector @xmath87 . this tree can be obtained form @xmath72 by simply disregarding the values for @xmath88 and is denoted by @xmath89 .",
    "studying recursions and fixed point equations embedded in this weighted branching tree is the objective of this paper .",
    "in this section we present an extension of goldie s implicit renewal theorem @xcite to weighted branching trees with real valued weights @xmath8 . the key observation that facilitates",
    "this generalization is the following lemma which shows that a certain measure on a tree is a matrix product measure ; its proof is given in section  [ ss.proofsrenewal ] .",
    "for the case of positive weights , a similar observation was made for a scalar measure in @xcite . throughout the paper",
    "we use the standard convention @xmath90 for all @xmath91 .",
    "let @xmath92 be an @xmath93 matrix whose elements are finite nonnegative measures concentrated on @xmath94 .",
    "the convolution @xmath95 of two such matrices is the matrix with elements @xmath96 , @xmath97 , where @xmath98 is the convolution of individual measures .",
    "a matrix renewal measure is the matrix of measures @xmath99 where @xmath100 , @xmath101 , @xmath102 , @xmath103 is the point measure at 0 , and @xmath104 is the identity @xmath105 matrix .",
    "a distribution @xmath106 on @xmath94 is said to be _ lattice _ if it is concentrated on a set that forms an arithmetic progression , that is , on a set of points of the form @xmath107 , where @xmath108 , @xmath109 are constant numbers and @xmath110 .",
    "the largest number @xmath111 with this property is called the span of @xmath106 . a distribution",
    "that is not lattice is said to be nonlattice .",
    "[ l.renewalmeasure ] let @xmath112 be the weighted branching tree defined by the vector @xmath113 , where @xmath29 and the @xmath8 are real valued . for any @xmath114 and @xmath115 , let @xmath116 and @xmath117 ; @xmath118 , @xmath119 .",
    "for @xmath91 define the measures @xmath120 , \\\\",
    "\\mu_n^{(-)}(dt ) & = e^{\\alpha t } e\\left [   \\sum_{{\\bf i } \\in a_{n } } 1(x_{\\bf i } = -1 , v_{\\bf i }   \\in dt )    \\right],\\end{aligned}\\ ] ] for @xmath121 , and let @xmath122 .",
    "suppose that @xmath123 \\geq 0 $ ] and @xmath124 = 1 $ ] .",
    "then , @xmath125 is a probability measure on @xmath94 that places no mass at @xmath126 , and has mean @xmath127 .\\ ] ] furthermore , if we let @xmath128 , @xmath129 and @xmath130 , then @xmath131 where @xmath132 denotes the @xmath35th matrix convolution of @xmath133 with itself .",
    "we now present a generalization of goldie s implicit renewal theorem @xcite that will enable the analysis of recursions on weighted branching trees . note that except for the independence assumption , the random variable @xmath5 and the vector @xmath87 are arbitrary , and therefore the applicability of this theorem goes beyond the linear recursion that we study here .",
    "[ t.newgoldie ] let @xmath113 be a random vector , where @xmath29 and the @xmath8 are real valued .",
    "suppose that there exists @xmath134 with @xmath135 such that the measure @xmath136 is nonlattice .",
    "assume further that @xmath137 > 0 $ ] , @xmath138 = 1 $ ] , @xmath139 < \\infty$ ] for some @xmath140 , and that @xmath5 is independent of @xmath87 .    1 .",
    "if @xmath141 a.s .",
    ", @xmath142 < \\infty$ ] for any @xmath143 , and @xmath144 \\right| t^{\\alpha-1 } dt < \\infty,\\ ] ] or , respectively , @xmath145 <",
    "\\infty$ ] for any @xmath143 , and @xmath146 \\right| t^{\\alpha-1 } dt < \\infty,\\ ] ] then @xmath147 or , respectively , @xmath148 where @xmath149 are given by @xmath150 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p((\\pm 1 ) r > v ) - e\\left [ \\sum_{j=1}^{n } 1((\\pm 1 ) c_{j } r > v ) \\right ]     \\right ) dv .\\end{aligned}\\ ] ] 2 .   if @xmath151 for some @xmath134 , @xmath152 < \\infty$ ] for any @xmath143 , and both and are satisfied , then @xmath153 where @xmath154 is given by @xmath155 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(|r| > v ) - e\\left [ \\sum_{j=1}^{n } 1(|c_{j } r| >",
    "v ) \\right ]     \\right ) dv .\\end{aligned}\\ ] ]    \\(i ) as pointed out in @xcite , the statement of the theorem only has content when @xmath156 , @xmath157 or @xmath158 , respectively , has infinite moments of order @xmath26 , since otherwise @xmath159 , @xmath160 or @xmath161 , respectively , are zero .",
    "( ii ) note that the case of nonnegative weights @xmath162 a.s .",
    "was recently proved in theorem  3.2 in @xcite . here ,",
    "in the proof of theorem  [ t.newgoldie ] we refer to it as case a ) , and provide an alternative proof that does not require the finiteness of @xmath163 $ ] ; when this expectation is infinite the constants @xmath164 are zero which can be interpreted as @xmath5 having lighter tails than @xmath165 .",
    "( iii ) we also point out that our proof provides a streamlined derivation of the classical theorem of goldie @xcite ( @xmath166 ) through the use of a matrix renewal measure .",
    "( iv ) note that in both cases , ( a ) and ( b ) , provided that and hold , we have @xmath167 ( v ) it appears , as noted in @xcite , that some of the early ideas of applying renewal theory to study the power tail asymptotics of autoregressive processes ( perpetuities ) is due to @xcite .",
    "we give below the corresponding theorem for the lattice case .",
    "[ t.newgoldie_lattice ] let @xmath113 be a random vector , where @xmath29 and the @xmath8 are real valued random variables such that for all @xmath22 , given @xmath168 , @xmath169 , where @xmath170 for some @xmath109 .",
    "assume further that @xmath137 > 0 $ ] , @xmath138 = 1 $ ] , @xmath139 < \\infty$ ] for some @xmath140 , and that @xmath5 is independent of @xmath87 .    1 .",
    "if @xmath141 a.s .",
    ", @xmath142 < \\infty$ ] for any @xmath143 , and @xmath171 \\right| t^{\\alpha-1 } dt < \\infty,\\ ] ] or , respectively , @xmath145 <",
    "\\infty$ ] for any @xmath143 , and @xmath172 \\right| t^{\\alpha-1 } dt < \\infty,\\ ] ] then , for almost every @xmath173 ( with respect to the lebesgue measure ) , @xmath174 or , respectively , @xmath175 where @xmath176 are given by @xmath177 } \\sum_{k=-\\infty}^\\infty e^{\\alpha(t+k\\lambda ) } \\left ( p((\\pm 1)r > e^{t+k\\lambda } ) - e\\left [ \\sum_{j=1}^n 1((\\pm 1)c_j r > e^{t+k\\lambda } ) \\right ] \\right )   .\\end{aligned}\\ ] ] 2 .",
    "if @xmath151 for some @xmath134 , @xmath152 < \\infty$ ] for any @xmath143 , and both and are satisfied , then , for almost every @xmath173 ( with respect to the lebesgue measure ) , @xmath178 where @xmath179 is given by @xmath180 } \\sum_{k=-\\infty}^\\infty e^{\\alpha(t+k\\lambda ) } \\left ( p(|r| > e^{t+k\\lambda } ) - e\\left [ \\sum_{j=1}^n 1 ( |c_j r| > e^{t+k\\lambda } ) \\right ] \\right )    .\\end{aligned}\\ ] ]    \\(i ) the absolute integrability conditions and can be replaced by @xmath181 \\right| < \\infty.\\ ] ] ( ii ) this theorem can be used to derive the tail behavior of the solutions to a variety of fixed point equations under the lattice assumption , e.g. , those studied in @xcite for the nonlattice case . in particular",
    ", one can obtain an alternative derivation of existing results in the literature for the homogeneous equation ( @xmath182 ) with nonnegative weights ( @xmath183 ) under the lattice assumption , e.g. , see proposition  7 in @xcite and theorem  29(b ) in @xcite .",
    "we refrain from such possible derivations here since our primary motivation for this work is the nonhomogeneous linear recursion . in addition , we focus on the nonlattice assumption since the results tend to be more explicit .",
    "( iii ) early results for perpetuities ( @xmath184 ) in the lattice case can be found in theorem  2(b ) of @xcite .    before going into the proof of theorem [ t.newgoldie ] we need the following monotone density lemma , which is taken from @xcite . since the proof of the lattice case is very similar to that of theorem [ t.newgoldie ] , we postpone the proof of theorem [ t.newgoldie_lattice ] to section [ ss.proofsrenewal ] .",
    "[ l.derivative ] let @xmath185 and @xmath186 .",
    "suppose @xmath187 as @xmath188 .",
    "then , @xmath189    let @xmath112 be the weighted branching tree defined by the vector @xmath113 . for each @xmath115 and all",
    "@xmath190 define @xmath191 ; note that @xmath192 is independent of @xmath193 but not of @xmath194 for any @xmath195 .",
    "also note that @xmath196 since @xmath115 .",
    "let @xmath197 , @xmath198 , denote the @xmath199-algebra generated by @xmath200 , and let @xmath201 , @xmath202 .",
    "assume also that @xmath5 is independent of the entire weighted tree , @xmath89 .",
    "then , for any @xmath173 , we can write @xmath203 via a telescoping sum as follows ( note that all the expectations in are finite by markov s inequality and ) @xmath204 - e\\left [ \\sum_{({\\bf i}|k+1 ) \\in a_{k+1 } } 1(\\pi_{{\\bf i}|k+1 } r > e^t ) \\right ]   \\right ) \\label{eq : telescoping } \\\\ & \\hspace{5 mm } + e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } 1(\\pi_{{\\bf i}|n } r > e^t ) \\right ] \\notag \\\\ & = \\sum_{k=0}^{n-1 }   e\\left [ \\sum_{({\\bf i}|k ) \\in a_{k } } \\left ( 1(\\pi_{{\\bf i}|k } r >",
    "e^t ) -   \\sum_{j=1}^{n_{{\\bf i}|k } } 1(\\pi_{{\\bf i}|k } c_{({\\bf i}|k , j ) } r > e^t ) \\right ) \\right ]   + e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } 1(\\pi_{{\\bf i}|n } r > e^t ) \\right ] \\notag \\\\ & = \\sum_{k=0}^{n-1 } e\\left [ \\sum_{({\\bf i}|k ) \\in a_{k } } \\left ( 1(x_{{\\bf i}|k } = 1 ,    r > e^{t - v_{{\\bf i}|k } } ) -   \\sum_{j=1}^{n_{{\\bf i}|k } } 1 ( x_{{\\bf i}|k } = 1 ,   c_{({\\bf i}|k , j ) } r > e^{t - v_{{\\bf i}|k } } ) \\right ) \\right ]   \\notag \\\\ & \\hspace{5 mm } +   \\sum_{k=0}^{n-1 } e\\left [ \\sum_{({\\bf i}|k ) \\in a_{k } } \\left ( 1(x_{{\\bf i}|k } = -1 ,   r < - e^{t - v_{{\\bf i}|k } } ) -   \\sum_{j=1}^{n_{{\\bf i}|k } } 1 ( x_{{\\bf i}|k}= -1 ,   c_{({\\bf i}|k , j ) } r < - e^{t - v_{{\\bf i}|k } } ) \\right ) \\right ]   \\notag \\\\ & \\hspace{5 mm } + e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } 1(\\pi_{{\\bf i}|n } r >",
    "e^t ) \\right ] \\notag \\\\ & = \\sum_{k=0}^{n-1 } e\\left [ \\sum_{({\\bf i}|k ) \\in a_{k } } 1(x_{{\\bf i}|k } = 1 ) e \\left [ \\left .    1 ( r > e^{t - v_{{\\bf i}|k } } )",
    "-   \\sum_{j=1}^{n_{{\\bf i}|k } } 1 ( c_{({\\bf i}|k , j ) } r > e^{t - v_{{\\bf i}|k } } ) \\right| \\mathcal{f}_k \\right ] \\right ]   \\notag \\\\ &",
    "\\hspace{5 mm } +   \\sum_{k=0}^{n-1 } e\\left",
    "[ \\sum_{({\\bf i}|k ) \\in a_{k } }   1(x_{{\\bf i}|k } = -1 ) e \\left [ \\left .",
    "1 ( r < - e^{t - v_{{\\bf i}|k } } ) -   \\sum_{j=1}^{n_{{\\bf i}|k } } 1 ( c_{({\\bf i}|k , j ) } r < - e^{t - v_{{\\bf i}|k } } )    \\right| \\mathcal{f}_k \\right ] \\right ]   \\notag \\\\ & \\hspace{5 mm } + e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } 1(\\pi_{{\\bf i}|n } r > e^t ) \\right].\\end{aligned}\\ ] ]    now , define the measures @xmath205 and @xmath206 according to lemma [ l.renewalmeasure ] and let @xmath207 \\right),\\ ] ] @xmath208     \\right),\\ ] ] @xmath209.\\ ] ]    since @xmath5 and @xmath210 are independent of @xmath211 , then @xmath212 = e^{\\alpha ( v_{{\\bf i}|k } - t ) } g_+(t - v_{{\\bf i}|k } ) , \\quad \\text{and } \\\\ & e \\left [ \\left .",
    "1 ( r < - e^{t - v_{{\\bf i}|k } } ) -   \\sum_{j=1}^{n_{{\\bf i}|k } } 1 ( c_{({\\bf i}|k , j ) } r < - e^{t - v_{{\\bf i}|k } } )    \\right| \\mathcal{f}_k \\right ] = e^{\\alpha ( v_{{\\bf i}|k } - t ) } g_-(t - v_{{\\bf i}|k}).\\end{aligned}\\ ] ] it follows that for any @xmath173 and @xmath114 , @xmath213 next , for any @xmath214 , define the operator @xmath215 and note that @xmath216    now , we will show that one can pass @xmath217 in the preceding identity . to this end , let @xmath218 , and note that by lemma [ l.renewalmeasure ] @xmath219 is a probability measure on @xmath94 that places no mass at @xmath126 and has mean , @xmath220 > 0 .\\ ] ] to see that @xmath221 is nonlattice note that by assumption the measure @xmath222 is nonlattice , since , if we suppose to the contrary that it is lattice on a lattice set @xmath223 , then on the complement @xmath224 of this set we have ( by conditioning on @xmath13 ) @xmath225\\ge p(\\log |c_j| \\in l^c , |c_j|>0,n \\ge j)>0,\\ ] ] which is a contradiction .",
    "moreover , in the notation of lemma [ l.renewalmeasure ] , @xmath226 , @xmath129 and @xmath130 , which gives @xmath227 also , @xmath228 being nonlattice implies that at least one of @xmath229 or @xmath230 is nonlattice , and therefore @xmath133 is nonlattice .    since @xmath231 , then @xmath232 for all @xmath233 whenever",
    "@xmath234 is directly riemann integrable . by",
    "and we know that @xmath235 , so by lemma 9.1 from @xcite , @xmath236 is directly riemann integrable , resulting in @xmath237 for all @xmath233 . thus , @xmath238   < \\infty$ ] , implying that @xmath239 $ ] exist , and by fubini s theorem , @xmath240   \\\\ & = \\sum_{k=0}^\\infty e\\left [ \\sum_{({\\bf i}|k ) \\in a_{k } } e^{\\alpha v_{{\\bf i}|k } } \\breve{g}_\\pm(t - v_{{\\bf i}|k } ) \\indicator(x_{{\\bf i}|k } = \\pm 1 ) \\right ]   = \\lim_{n\\to \\infty }   ( \\breve{g}_\\pm*\\nu_n^{(\\pm)})(t).\\end{aligned}\\ ] ]    for case b ) , to see that @xmath241 as @xmath217 for all fixed @xmath233 , note that from the assumptions @xmath138 = 1 $ ] , @xmath242 > 0 $ ] , , and @xmath139 < \\infty$ ] for some @xmath140 , there exists @xmath243 such that @xmath244 < 1 $ ] ( by convexity ) .",
    "therefore , for such @xmath245 , @xmath246   du \\notag \\\\ & \\leq e^{(\\alpha-\\beta)t } e\\left [ \\sum_{({\\bf i}|n ) \\in a_n }   \\int_{-\\infty}^t e^{\\beta u } 1(|\\pi_{{\\bf i}|n } r| > e^{u } ) du \\right ] \\notag    \\\\ & =   e^{(\\alpha-\\beta)t } e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } \\int_0^{\\min\\{t , \\log ( |\\pi_{{\\bf i}|n } r| )   \\ } } e^{\\beta u }    du \\right ] \\notag \\\\ & \\leq \\frac{e^{(\\alpha-\\beta)t}}{\\beta } e\\left [ \\sum_{({\\bf i}|n ) \\in a_n }   |\\pi_{{\\bf i}|n } r|^\\beta \\right ] .",
    "\\label{eq : geometric}\\end{aligned}\\ ] ] similarly , one obtains bounds for case a ) by replacing @xmath158 by either @xmath156 or @xmath157 .",
    "it remains to show that the expectation in converges to zero as @xmath217 .",
    "first note that from the independence of @xmath5 and @xmath89 , @xmath247   = e[|r|^\\beta ] e\\left [ \\sum_{({\\bf i}|n ) \\in a_n }   |\\pi_{{\\bf i}|n}|^\\beta \\right],\\ ] ] where @xmath152 < \\infty$ ] , for @xmath248 .",
    "for the expectation involving @xmath249 condition on @xmath250 and use the independence of @xmath251 from @xmath250 as follows @xmath252 & = e\\left [    \\sum_{({\\bf i}|n-1 ) \\in a_{n-1 } }   e\\left [ \\left . \\sum_{j=1}^{n_{{\\bf",
    "i}|n-1 } }   |\\pi_{{\\bf i}|n-1}|^{\\beta } |c_{({\\bf i}|n-1 , j)}|^\\beta \\right| \\mathcal{f}_{n-1 } \\right ]   \\right ] \\notag \\\\ & = e\\left [    \\sum_{({\\bf i}|n-1 ) \\in a_{n-1 } } |\\pi_{{\\bf i}|n-1}|^\\beta   e\\left [ \\left .",
    "\\sum_{j=1}^{n_{{\\bf i}|n-1 } } |c_{({\\bf i}|n-1 , j)}|^\\beta \\right| \\mathcal{f}_{n-1 } \\right ]   \\right ]   \\notag \\\\ & = e\\left [ \\sum_{j=1}^n |c_j|^\\beta \\right ] e\\left [    \\sum_{({\\bf i}|n-1 ) \\in a_{n-1 } } |\\pi_{{\\bf i}|n-1}|^\\beta     \\right ]   \\notag \\\\ & = \\left ( e\\left [      \\sum_{j=1}^{n }   |c_{j}|^{\\beta }    \\right ] \\right)^n",
    "\\qquad \\text{(iterating $ n-1 $ times)}. \\label{eq : pimoments}\\end{aligned}\\ ] ] since @xmath253 < 1 $ ] , then the above converges to zero as @xmath217 .",
    "hence , the preceding arguments allow us to pass @xmath217 in , and obtain @xmath254 where @xmath255 and @xmath256 . to complete the analysis we need to consider two cases separately .",
    "* case a ) : * @xmath257 for all @xmath22 .",
    "for this case we have @xmath258 , from where it follows that @xmath259 which in turn implies that @xmath260 then , by the matrix version of the key renewal theorem on the real line , theorem 4 in @xcite , @xmath261 clearly , @xmath262 since the left - hand side of the preceding equation is positive , and thus , by lemma [ l.derivative ] , @xmath263 to derive the result for @xmath264 , simply start by developing a telescoping sum for @xmath265 in , define @xmath266 and follow exactly the same steps to obtain @xmath267 and @xmath268 to compute the constants @xmath269 note that @xmath270     \\right ) dt \\\\ & = \\frac{1 } { \\mu } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p((\\pm 1 ) r >",
    "v ) - e\\left [ \\sum_{j=1}^{n } 1((\\pm 1 ) c_{j } r >",
    "v ) \\right ]     \\right ) dv .",
    "\\end{aligned}\\ ] ]    * case b ) : * @xmath151 for some @xmath134 .",
    "for this case we have that @xmath230 is nonzero . also , note that the matrix @xmath271 & e\\left [ \\sum_{j=1}^n |c_j|^\\alpha \\indicator(x_j = -1 ) \\right ] \\\\",
    "e\\left [ \\sum_{j=1}^n |c_j|^\\alpha \\indicator(x_j = -1 ) \\right ] & e\\left [ \\sum_{j=1}^n |c_j|^\\alpha \\indicator(x_j = 1 ) \\right ]    \\end{matrix } \\right ) \\triangleq \\left ( \\begin{matrix } p &   q \\\\ q & p \\end{matrix } \\right)\\ ] ] is irreducible and has eigenvalues @xmath272 , and therefore spectral radius equal to one .",
    "moreover , @xmath273 and @xmath274 are left and right eigenvalues , respectively , of @xmath275 corresponding to eigenvalue one , and by assumption , @xmath276 = 2\\mu > 0.\\ ] ] furthermore , since the matrix of measures * h * is nonlattice , theorem 4 in @xcite gives @xmath277 from where it follows that @xmath278 note that @xmath279 , and by lemma [ l.derivative ] , @xmath189 to derive the result for @xmath264 simply start by defining @xmath280 , which in this case leads to the same asymptotics as above , that is , @xmath281 finally , we note , by using the representations for @xmath159 and @xmath160 from case a ) , that @xmath282 \\right ) dv \\\\ & \\hspace{5 mm } + \\frac{1}{2\\mu } \\int_0^\\infty v^{\\alpha-1 } \\left ( p ( r < -v ) - e\\left [ \\sum_{j=1}^n 1(c_j r < - v ) \\right ] \\right ) dv \\\\ & = \\frac{1}{2\\mu } \\int_0^\\infty v^{\\alpha-1 } \\left ( p",
    "( |r| > v ) - e\\left [ \\sum_{j=1}^n 1(|c_j r| >",
    "v ) \\right ] \\right ) dv.\\end{aligned}\\ ] ]",
    "motivated by the information ranking problem on the internet , e.g. google s pagerank algorithm @xcite , in this section we apply the implicit renewal theory for trees developed in the previous section to the following linear recursion : @xmath284 where @xmath17 , @xmath3 are real valued random weights , @xmath18 is a real valued random variable with @xmath19 and @xmath4 are iid copies of @xmath5 , independent of @xmath6 .",
    "note that the power tail of @xmath5 for the case @xmath285 , @xmath286 was previously studied in @xcite , the critical homogeneous case @xmath287 with @xmath288 was considered in @xcite and @xcite .",
    "the first result we need to establish is the existence and finiteness of a solution to . for the purpose of existence we will provide an explicit construction of a solution @xmath5 to on a tree .",
    "note that such constructed @xmath5 will be the main object of study of this section .",
    "recall that throughout the paper the convention is to denote the random vector associated to the root node @xmath32 by @xmath289 .",
    "we now define the process @xmath290 on the weighted branching tree @xmath291 , as constructed in section [ s.modeldescription ] .",
    "define the process @xmath292 according to @xmath293 that is , @xmath294 is the sum of the weights of all the nodes on the tree up to the @xmath35th generation .",
    "it is not hard to see that @xmath294 satisfies the recursion @xmath295 where @xmath296 are independent copies of @xmath297 corresponding to the tree starting with individual @xmath298 in the first generation and ending on the @xmath35th generation ; note that @xmath299 .",
    "moreover , since the tree structure repeats itself after the first generation , @xmath300 satisfies @xmath301 where @xmath302 is a sequence of iid random variables independent of @xmath87 and having the same distribution as @xmath303 .",
    "[ l.rnconvergence ] if for some @xmath304 , @xmath305<\\infty$ ] , @xmath306<1 $ ] , then @xmath307 a.s . as @xmath308 , where @xmath152<\\infty$ ] and is given by @xmath309",
    "if @xmath310 < 1 $ ] the tree is finite a.s . and",
    "thus @xmath5 is finite a.s . for any choice of @xmath18 and @xmath8 .    by corollary  4 on p.  68",
    "in @xcite the a.s .",
    "convergence of @xmath294 will follow once we show that , in probability , @xmath311 to this end , note that that for any @xmath312 @xmath313 \\notag\\\\ & \\le \\frac{1}{\\epsilon^\\beta}e\\left [ \\sum_{i = n+1}^\\infty |w_i|^\\beta\\right],\\label{eq : rnconvergence}\\end{aligned}\\ ] ] where the last inequality follows from the elementrary inequality @xmath314 for @xmath315 and @xmath304 ; this elementary inequality is used repeatedly in the remainder of this proof and paper .",
    "now , the last sum can be easily evaluated since by lemma [ l.momentsmaller_1 ] below we have @xmath316\\le e\\left[|q|^\\beta\\right]\\rho_\\beta^i,\\ ] ] where @xmath317 $ ] .",
    "therefore , by combining the preceding two inequalities we obtain @xmath318\\rho_\\beta^{n+1}}{1-\\rho_\\beta}\\rightarrow 0\\ ] ] as @xmath308 , which completes the proof of the a.s .",
    "convergence part .",
    "thus , the infinite sum in is properly defined and @xmath319\\le e\\left[\\sum_{i=0}^\\infty |w_i|^\\beta\\right]=\\frac{e\\left[|q|^\\beta\\right]}{1-\\rho_\\beta}<\\infty.\\ ] ]    furthermore , under the assumption of the preceding lemma , it is easy to see that the sum of all the absolute values of the weights on the tree are a.s .",
    "finite , i.e. , @xmath320 hence , it can be easily seen from the construction of @xmath5 on the tree , that it can be decomposed into the following identity @xmath321 where @xmath322 are independent copies of @xmath5 corresponding to the infinite subtree starting with individual @xmath298 in the first generation .",
    "the derivation provided above implies in particular the existence of a solution in distribution to .",
    "moreover , we will show in the following section that , under additional technical conditions , @xmath5 is the unique solution .",
    "the constructed @xmath5 , as defined in , is the main object of study in the remainder of this section .",
    "note that , in view of the very recent work in @xcite , may have other stable law solutions that are not considered here .      in order to establish the finiteness of moments of @xmath300 and @xmath5",
    "let @xmath323 and note that @xmath324 so lemmas 4.2 , 4.3 and 4.4 in @xcite apply and we immediately obtain the following results . throughout the rest of the paper we use",
    "@xmath325 $ ] and @xmath326 .",
    "[ l.momentsmaller_1 ] let @xmath327 .",
    "then , for all @xmath34 , @xmath328 \\leq   e [ |q|^\\beta ] \\rho_\\beta^{n}.\\ ] ]    [ l.generalmoment ] let @xmath329 and suppose @xmath330 < \\infty$ ] , @xmath331 < \\infty$ ] , and @xmath332 . then , there exists a constant @xmath333 such that for all @xmath34 , @xmath328 \\leq k_\\beta ( \\rho \\vee \\rho_\\beta   ) ^{n}.\\ ] ]    [ l.moments_r ] assume @xmath331 <",
    "\\infty$ ] for some @xmath214 .",
    "in addition , suppose either ( i ) @xmath334 if @xmath335 , or ( ii ) @xmath336 and @xmath337 < \\infty$ ] if @xmath338 .",
    "then , @xmath339 <",
    "\\infty$ ] for all @xmath340 . moreover , if @xmath338 , @xmath341 , where @xmath342 stands for convergence in @xmath343 norm .",
    "we now characterize the tail behavior of the distribution of the solution @xmath5 to the nonhomogeneous equation , as defined by .",
    "[ t.linearrecursion ] let @xmath74 be a random vector , with @xmath29 , @xmath3 real valued weights , @xmath18 a real valued random variable with @xmath344 and @xmath5 be the solution to given by .",
    "suppose that there exists @xmath134 with @xmath135 such that the measure @xmath136 is nonlattice , and that for some @xmath91 ,",
    "@xmath345 < \\infty$ ] , @xmath346 > 0 $ ] and @xmath347 = 1 $ ] .",
    "in addition , assume    1 .",
    "@xmath348 < 1 $ ] and @xmath349 < \\infty$ ] , if @xmath350 ; or , 2 .",
    "@xmath351 < \\infty$ ] for some @xmath352 , if @xmath353 .",
    "then ,    1 .",
    "if @xmath354 a.s .",
    "@xmath355 where @xmath356 are given by @xmath357 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p((\\pm 1 ) r > v ) - e\\left [ \\sum_{i=1}^{n } 1((\\pm 1 ) c_{i } r > v ) \\right ]     \\right ) dv \\\\ & = \\frac{e\\left [ \\left(\\left ( \\sum_{i=1}^n c_i r_i + q \\right)^\\pm\\right)^\\alpha - \\sum_{i=1}^n \\left((c_i r_i ) ^\\pm \\right)^\\alpha \\right]}{\\alpha e\\left [ \\sum_{i=1}^n     2 .   if @xmath151 for some @xmath134 , @xmath153 where @xmath358 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(|r| >",
    "v ) - e\\left [ \\sum_{i=1}^{n } 1 ( |c_{i } r| > v ) \\right ]     \\right ) dv \\\\ & = \\frac{e\\left [ \\left| \\sum_{i=1}^n c_i r_i + q \\right|^\\alpha - \\sum_{i=1}^n |c_i r_i |^\\alpha \\right]}{2\\alpha e\\left [ \\sum_{i=1}^n |c_i|^\\alpha \\log |c_i|   \\right ] } .\\end{aligned}\\ ] ]    \\(i ) when @xmath350 , the condition @xmath349",
    "< \\infty$ ] is needed to ensure that the tails of @xmath5 are not dominated by @xmath13 .",
    "in particular , if the @xmath8 are nonnegative iid and independent of @xmath13 , the condition reduces to @xmath359 < \\infty$ ] since @xmath360 < \\infty$ ] is implied by the other conditions ; see theorems  4.2 and 5.4 in @xcite .",
    "furthermore , when @xmath353 the condition @xmath349",
    "< \\infty$ ] is redundant since @xmath349 \\leq e\\left [   \\sum_{i=1}^n |c_i|^\\alpha \\right ] = 1 $ ] , and the additional condition @xmath361 < \\infty$ ] is needed . when the @xmath362 are nonnegative iid and independent of @xmath13 ( given the other assumptions ) , the latter condition reduces to @xmath363 < \\infty$ ] , which is consistent with theorem 4.2 in @xcite .",
    "( ii ) note that the expressions for @xmath364 and @xmath161 given in terms of moments are more suitable for actually computing them , especially in the case of @xmath26 being an integer ( see corollary 4.9 in @xcite ) .",
    "when @xmath26 is not an integer , we can derive bounds on @xmath364 and @xmath161 by using moment inequalities , e.g. in the case when @xmath285 and @xmath365 , the elementary inequality @xmath366 for @xmath367 and @xmath368 , yields @xmath369}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } > 0.\\ ] ]    before giving the proof of theorem [ t.linearrecursion ] , we state the following preliminary lemmas ; their proofs are contained in section [ ss.proofslinearrec ] . with some abuse of notation , we will use throughout the paper @xmath370 to denote @xmath371 in case @xmath372 .",
    "[ l.d_moments_larger1 ] suppose @xmath87 is a random vector with @xmath373 and @xmath8 real valued random variables .",
    "let @xmath374 be a sequence of iid real valued random variables having the same distribution as @xmath5 , independent of @xmath6 .",
    "further assume @xmath375 a.s .",
    ", @xmath330 < \\infty$ ] for some @xmath329 , and @xmath376 < \\infty$ ] for all @xmath377 .",
    "then , for @xmath378 equal to any of the functions @xmath379 , @xmath380 or @xmath381 , @xmath382 < \\infty.\\ ] ]    [ l.d_moments_smaller1 ] suppose @xmath87 is a random vector with @xmath373 and @xmath8 real valued random variables .",
    "let @xmath374 be a sequence of iid real valued random variables having the same distribution as @xmath5 , independent of @xmath6 .",
    "further assume @xmath375 a.s .",
    ", @xmath383 < \\infty$ ] , @xmath384 $ ] for some @xmath327 , @xmath385 , and @xmath376 < \\infty$ ] for all @xmath377 .",
    "then , for @xmath378 equal to any of the functions @xmath379 , @xmath380 or @xmath381 , @xmath382 < \\infty.\\ ] ]    [ l.max_approx ] suppose @xmath87 is a random vector , with @xmath29 and @xmath3 real valued weights , and let @xmath374 be a sequence of iid random variables having the same distribution as @xmath5 , independent of @xmath386 .",
    "for @xmath387 , suppose that @xmath388 a.s . and",
    "@xmath152 < \\infty$ ] for any @xmath248 .",
    "furthermore , assume that @xmath351 < \\infty$ ] for some @xmath352 . then , @xmath389 - p\\left ( \\max_{1\\leq i \\leq",
    "> t \\right ) \\right )   t^{\\alpha -1 } \\ , dt \\\\ & = \\frac{1}{\\alpha } e \\left [   \\sum_{i=1}^n   \\left ( t_i^+ \\right)^\\alpha - \\left ( \\left ( \\max_{1\\leq i \\leq n } t_i \\right)^+ \\right)^\\alpha    \\right ]   < \\infty,\\end{aligned}\\ ] ] where @xmath390 can be taken to be any of the random variables @xmath391 , @xmath392 , or @xmath393 .    [ l.extraq ]",
    "let @xmath74 be a random vector with @xmath29 , @xmath3 real valued weights and @xmath18 real valued , and let @xmath374 be a sequence of iid random variables independent of @xmath394 .",
    "suppose that for some @xmath91 we have @xmath345 < \\infty$ ] , @xmath349 < \\infty$ ] , @xmath152 < \\infty$ ] for any @xmath248 , and @xmath395 a.s .",
    "then , for @xmath378 equal to any of the functions @xmath379 , @xmath380 or @xmath381 , @xmath396   < \\infty .\\ ] ]    by lemma [ l.moments_r ] we know that @xmath152 < \\infty$ ] for any @xmath248 . to verify that",
    "@xmath397 < \\infty$ ] for some @xmath140 note that if @xmath350 we have , by the assumptions of the theorem and jensen s inequality , @xmath398 \\leq e\\left [ \\left ( \\sum_{i=1}^n |c_i| \\right)^\\gamma \\right ] \\leq   \\left ( e\\left [ \\left ( \\sum_{i=1}^n |c_i| \\right)^\\alpha \\right ]   \\right)^{\\gamma/\\alpha } < \\infty\\ ] ] for any @xmath399 . if @xmath353 , then for @xmath400 we have @xmath398 \\leq e\\left [ \\left ( \\sum_{i=1}^n |c_i|^{\\alpha/(1+\\epsilon ) } \\right)^{1+\\epsilon/2 } \\right ] \\leq \\left ( e\\left [ \\left ( \\sum_{i=1}^n |c_i|^{\\alpha/(1+\\epsilon ) } \\right)^{1+\\epsilon } \\right ] \\right)^\\frac{1+\\epsilon/2}{1+\\epsilon } < \\infty.\\ ] ]    the statement of the theorem with the first expressions for @xmath401 will follow from theorem [ t.newgoldie ] once we prove that conditions and hold",
    ". to this end define @xmath402 and let @xmath390 be any of @xmath391 , @xmath403 or @xmath393 , depending on which condition is being verified ; respectively , let @xmath404 be the corresponding @xmath405 , @xmath406 or @xmath407 .",
    "then , @xmath408 \\right|   & \\leq \\left| p(t^ *",
    "> t ) - p\\left ( \\max_{1\\leq i \\leq n } t_i > t \\right ) \\right|    \\\\ & \\hspace{5 mm } + \\left| p\\left ( \\max_{1\\leq i \\leq",
    "n } t_i > t   \\right )    - e\\left [ \\sum_{i=1}^n 1(t_i > t ) \\right ]   \\right|.\\end{aligned}\\ ] ] to analyze the second absolute value , note that @xmath409   -   p\\left (   \\max_{1\\leq i \\leq n } t_i > t   \\right )   \\\\ & = e\\left [ \\sum_{i=1}^n 1(t_i > t ) \\right ]   - e\\left [ 1\\left (   \\max_{1\\leq",
    "t_i > t   \\right ) \\right ] \\geq 0.\\end{aligned}\\ ] ] now it follows that @xmath410 \\right|   & \\leq \\left| p(t^ * > t ) - p\\left ( \\max_{1\\leq i \\leq n } t_i",
    "> t \\right ) \\right| \\notag \\\\",
    "& \\hspace{5 mm } + e\\left [ \\sum_{i=1}^n 1(t_i > t ) \\right ] - p\\left ( \\max_{1\\leq i \\leq n } t_i > t \\right )   .",
    "\\label{eq : term2}\\end{aligned}\\ ] ] note that the integral corresponding to is finite by lemma  [ l.max_approx ] if we show that the assumptions of lemma  [ l.max_approx ] are satisfied when @xmath350 .",
    "note that in this case we can choose @xmath411 such that @xmath412 and use the inequality @xmath413 for @xmath414 , @xmath368 , @xmath415 to obtain @xmath416 \\leq e\\left [ \\left ( \\sum_{i=1}^n |c_i| \\right)^\\alpha \\right ]   < \\infty.\\ ] ] therefore , it only remains to show that @xmath417 t^{\\alpha-1 } \\ , dt < \\infty .",
    "\\label{eq : recvsmax}\\end{aligned}\\ ] ]    by lemma [ l.newintegralineq ] in section [ ss.proofslinearrec ] , @xmath418 t^{\\alpha-1 } \\ , dt & \\leq \\frac{1}{\\alpha } e\\left [ \\left|    \\left((t^*)^+\\right)^\\alpha - \\left(\\left ( \\max_{1\\leq i\\leq n } t_i \\right)^+ \\right)^\\alpha \\right|   \\right ] \\notag \\\\ & \\leq \\frac{1}{\\alpha } e\\left [ \\left|   ( ( t^*)^+)^\\alpha -   \\sum_{i=1}^n ( t_i^+)^\\alpha \\right| \\right ] \\label{eq : maindifference } \\\\ & \\hspace{5 mm } + \\frac{1}{\\alpha } e\\left [   \\sum_{i=1}^n ( t_i^+)^\\alpha -   \\left(\\left ( \\max_{1\\leq i\\leq n } t_i \\right)^+ \\right)^\\alpha   \\right ] .",
    "\\label{eq : maxdifference}\\end{aligned}\\ ] ] note that is finite by lemma [ l.max_approx ] , so it only remains to verifty that is finite .",
    "to see this let @xmath419 , @xmath380 or @xmath381 depending on whether @xmath420 is @xmath421 , @xmath422 or @xmath423 , respectively , and let @xmath424 .",
    "then , the expectation in is equal to @xmath425 & \\leq e\\left [ \\left| d(s+q)^\\alpha - d(s)^\\alpha   \\right| \\right ]   + e\\left [ \\left| d(s)^\\alpha - \\sum_{i=1}^n d(c_ir_i)^\\alpha \\right| \\right ] .\\end{aligned}\\ ] ] the first expectation on the right hand side is finite by lemma  [ l.extraq ] , while the second one is finite by lemmas  [ l.d_moments_larger1 ] and [ l.d_moments_smaller1 ] .    finally , applying theorem [ t.newgoldie ] gives the asymptotic expressions for @xmath426 and @xmath264 with the integral representation of the constants @xmath159 , @xmath160 and @xmath161 .    to obtain the expressions for @xmath159 , @xmath160 and @xmath161 in terms of moments note that @xmath427     \\right ) dv \\notag \\\\ & = \\int_0^\\infty v^{\\alpha-1 }   e\\left [   1(t^ * >",
    "v ) - \\sum_{i=1}^n 1(t_i > v )   \\right ]   \\ , dv \\notag \\\\   & = e \\left [    \\int_0^\\infty v^{\\alpha-1 }   \\left (   1(t^ * >",
    "v )   -   \\sum_{i=1}^n 1(t_i > v ) \\right ) dv   \\right ] \\label{eq : fubini } \\\\ & = e \\left [    \\int_0^{(t^*)^+ } v^{\\alpha-1 } dv   -   \\sum_{i=1}^n \\int_0^{t_i^+ } v^{\\alpha-1 }   dv   \\right ] \\label{eq : diffintegrals } \\\\ & = \\frac{1}{\\alpha } e\\left [ \\left ( ( t^*)^+ \\right)^\\alpha - \\sum_{i=1}^n ( t_i^+)^\\alpha    \\right ] , \\notag\\end{aligned}\\ ] ] where is justified by fubini s theorem and the integrability of @xmath428 which is a consequence of and lemma [ l.max_approx ] ; and follows from the observation that @xmath429 are each almost surely absolutely integrable with respect to @xmath430 as well .",
    "this completes the proof .",
    "we separate the proofs corresponding to sections [ s.renewal ] and [ s.linearrec ] into the following two subsections .        to see that @xmath228 is a probability measure note that @xmath431 \\\\ & = e\\left [ \\sum_{j=1}^n \\int_{-\\infty}^\\infty e^{\\alpha u } 1(x_j = \\pm 1 , \\log |c_j| \\in du )   \\right ] \\qquad \\text{(by fubini 's theorem ) } \\\\ & = e\\left [ \\sum_{j=1}^n 1(x_j = \\pm 1 ) \\int_{-\\infty}^\\infty e^{\\alpha u } 1(\\log |c_j| \\in du )   \\right ]   \\\\ & = e\\left [ \\sum_{j=1}^n 1(x_j = \\pm 1 )   |c_j|^\\alpha   \\right ]   \\end{aligned}\\ ] ] we then have that @xmath432 = 1.\\ ] ] similarly",
    ", the mean of @xmath228 is given by @xmath433 .\\ ] ]    to show that holds we proceed by induction .",
    "for @xmath115 , set @xmath434 , and let @xmath435 , @xmath58 , denote the @xmath199-algebra generated by @xmath436 ; @xmath201 , @xmath202 .",
    "let @xmath437 .",
    "hence , using this notation we derive @xmath438 ) & = \\int_{-\\infty}^t e^{\\alpha u } e\\left [   \\sum_{{\\bf i } \\in a_{n+1 } } 1(x_{\\bf i } = 1 , v_{{\\bf i } } \\in du )    \\right ] \\\\ & = \\int_{-\\infty}^t e^{\\alpha u }   e\\left [   \\sum_{{\\bf i } \\in a_{n } } \\sum_{j=1}^{n_{\\bf i } } \\left\\ { 1(x_{{\\bf i } } = 1 , y_{({\\bf i},j ) } = 1 , v_{{\\bf i } } + \\log |c_{({\\bf i } , j)}| \\in du )    \\right . \\right . \\\\ & \\hspace{15 mm } \\left . \\phantom{\\sum_{j=1}^{n_i } } + \\left . 1(x_{{\\bf",
    "i } } = -1 , y_{({\\bf i},j ) } = -1 , v_{{\\bf i } } + \\log |c_{({\\bf i } , j)}| \\in du )   \\right\\ }   \\right ] \\\\ & = \\int_{-\\infty}^t e^{\\alpha u }   e\\left [   \\sum_{{\\bf i } \\in a_{n } } \\left\\ { 1(x_{\\bf i } = 1 ) \\sum_{j=1}^{n_{\\bf i } }   \\right .",
    "1(y_{({\\bf i},j ) } = 1 , v_{\\bf i } + \\log |c_{({\\bf i } , j)}| \\in du )   \\right .",
    "\\\\ & \\hspace{15 mm } + \\left .",
    "1 ( x_{\\bf i } = -1 )   \\sum_{j=1}^{n_{\\bf i}}1(y_{({\\bf i},j ) } = -1 , v_{\\bf i } + \\log |c_{({\\bf i } , j)}| \\in du )    \\right\\ }   \\right ] \\\\ & = \\int_{-\\infty}^t e^{\\alpha u }   e\\left [   \\sum_{{\\bf i } \\in a_{n } } \\left\\ { 1(x_{\\bf i } = 1 )   e\\left [ \\left .",
    "\\sum_{j=1}^{n_{\\bf i } }   \\right .",
    "1(y_{({\\bf i},j ) } = 1 , v_{\\bf i } + \\log |c_{({\\bf i } , j)}| \\in du ) \\right|",
    "\\mathcal{f}_n \\right ] \\right .",
    "\\\\ & \\hspace{15 mm } + \\left .",
    "\\left .   1 ( x_{\\bf i } = -1 )   e\\left [ \\sum_{j=1}^{n_{\\bf i}}1(y_{({\\bf i},j ) } = -1 , v_{\\bf i } + \\log |c_{({\\bf i } , j)}| \\in du )    \\right| \\mathcal{f}_n \\right ]   \\right\\ } \\right ] .",
    "\\end{aligned}\\ ] ] using the independence of @xmath439 and @xmath440 we obtain @xmath441   = e^{-\\alpha ( u- v_{\\bf i } ) } \\eta_\\pm ( du - v_{\\bf i}),\\ ] ] from where it follows that @xmath442 ) & = \\int_{-\\infty}^t   e\\left [ \\sum_{{\\bf i } \\in a_n } \\left\\ { 1(x_{\\bf i } = 1 ) e^{\\alpha v_{\\bf i } } \\eta_+ ( du - v_{\\bf i } ) +",
    "1(x_{\\bf i } = -1 ) e^{\\alpha v_{\\bf i } } \\eta_- ( du - v_{\\bf i } ) \\right\\ } \\right ] \\\\ & =    e\\left [ \\sum_{{\\bf i } \\in a_n }   1(x_{\\bf i } = 1 ) e^{\\alpha v_{\\bf i } }   \\eta_+ ( ( -\\infty , t - v_{\\bf i } ] ) \\right ] + e\\left [ \\sum_{{\\bf i } \\in a_n } 1(x_{\\bf",
    "i } = -1 ) e^{\\alpha v_{\\bf i } }   \\eta_- ( ( -\\infty , t - v_{\\bf i } ] )   \\right ]   \\\\ & = \\int_{-\\infty}^\\infty \\eta_+ ( ( -\\infty , t - v ] ) \\mu_n^{(+)}(dv ) + \\int_{-\\infty}^\\infty \\eta_- ( ( -\\infty , t - v ] ) \\mu_n^{(-)}(dv),\\end{aligned}\\ ] ] and hence @xmath443 .",
    "the same arguments also give @xmath444 in matrix notation the last two equations can be written as @xmath445 and now the induction hypothesis gives the result .",
    "fix @xmath450 . by assumption ,",
    "for any @xmath451 , @xmath452 , and @xmath35 sufficiently large , @xmath453 since @xmath454 was arbitrary , we can take the limit as @xmath455 to obtain @xmath456 now take the limit as @xmath457 to obtain @xmath458 similarly , one can prove that @xmath459 by starting with the integral @xmath460 .",
    "define @xmath229 , @xmath230 and @xmath133 as in lemma [ l.renewalmeasure ] .",
    "we first note that by assumption , @xmath461 \\quad \\text{and } \\\\ \\eta_-(dt ) & = e^{\\alpha t } e\\left [ \\sum_{i=1}^n 1 ( { { \\rm sgn } \\mspace{1mu}}(c_i ) = -1 , \\log |c_i| \\in dt ) \\right]\\end{aligned}\\ ] ] are both lattice measures on the lattice @xmath223 .",
    "then , according to definition 5 in @xcite ( with @xmath462 ) , the matrix @xmath133 is lattice with span @xmath111 .",
    "applying theorem 4 in @xcite we obtain that for any @xmath173 , @xmath463 and @xmath464 we now verify that the limit @xmath465 exists .",
    "to do this first define the function @xmath466 and fix @xmath467 .",
    "then , @xmath468 where the rearrangement of summands in the first equality is justified by the absolute summability of the expressions , and the exchange of the integral and sum in the fourth equality is justified by fubini s theorem and the observation that by and @xmath469 similarly , @xmath470 taking the limit as @xmath471 and using the lebesgue differentiation theorem gives @xmath472 for almost every @xmath173 .",
    "applying theorem 4 in @xcite we obtain that for any @xmath173 , @xmath475 and @xmath476 where @xmath477 . by using lemma [ l.derivativediscrete ]",
    "we obtain ( for almost every @xmath173 ) @xmath478 where @xmath479 .      in this section",
    "we give the proofs of lemmas [ l.d_moments_larger1]@xmath480[l.extraq ] .",
    "we also state and prove an analogue of lemma 4.1 in @xcite for the positive parts of general random variables , which will be used in the proofs of the lemmas mentioned above , and a version of lemma 9.4 in @xcite needed in the proof of theorem [ t.linearrecursion ] .    [ l.alpha_moments ] for any @xmath481 let @xmath482 be a sequence of real valued random variables and let @xmath483 be a sequence of real valued iid random variables having the same distribution as @xmath484 , independent of the @xmath485",
    ". for @xmath329 set @xmath486 , and if @xmath487 assume that @xmath488 a.s .",
    "then , @xmath489 \\leq e\\left [ |y|^{p-1 } \\right]^{\\beta/(p-1 ) } e\\left [ \\left(\\sum_{i=1}^k |d_i| \\right)^\\beta   \\right].\\ ] ]      let @xmath492 and @xmath493 $ ] .",
    "suppose first that @xmath494 and define @xmath495 .",
    "then , for any sequence of nonnegative numbers @xmath496 we have @xmath497 where for the last step we used the well known inequality @xmath498 for @xmath499 and @xmath368 .",
    "we now use the conditional jensen s inequality to obtain @xmath500 \\\\ & \\leq e\\left [   \\left ( \\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } ( ( d_1y_1)^+)^{j_1 } \\cdots ( ( d_k y_k)^+)^{j_k } \\right)^\\gamma \\right ] \\qquad \\text{(by \\eqref{eq : scalarbound } ) } \\\\ & \\leq     e\\left [ \\left (   e\\left [ \\left .",
    "\\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } |d_1y_1|^{j_1 } \\cdots |d_k y_k|^{j_k } \\right| d_1,\\dots , d_k \\right ] \\right)^\\gamma \\right ]   \\\\ & = e \\left [ \\left (   \\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } |d_1|^{j_1 } \\cdots |d_k|^{j_k } e\\left [ \\left . |y_1|^{j_1 } \\cdots |y_k|^{j_k } \\right| d_1,\\dots , d_k \\right ] \\right)^\\gamma   \\right].\\end{aligned}\\ ] ] the rest of the proof is essentially the same as that of lemma 4.1 in @xcite , and is therefore omitted .",
    "suppose first that @xmath419 and let @xmath501 , @xmath502 , and @xmath503 , then @xmath504 \\notag \\\\ & \\leq e\\left [   \\sum_{i=1}^n ( ( c_ir_i)^+)^\\beta \\indicator(s_+ \\leq s_- ) \\right ] +   e\\left [ \\left| ( s_+ - s_-)^\\beta - s_+^\\beta \\right| \\indicator(s_+ > s_- ) \\right ] \\label{eq : possum } \\\\ & \\hspace{5 mm } + e\\left [ \\left| s_+^\\beta - \\sum_{i=1}^n ( ( c_ir_i)^+)^\\beta \\right|\\right ] .\\label{eq : pospartslemma}\\end{aligned}\\ ] ]    note that is finite by lemma [ l.alpha_moments ] .",
    "the first expectation in can be bounded as follows @xmath505 & = e\\left [ \\sum_{i=1}^n e\\left [ \\left .",
    "( ( c_ir_i)^+)^\\beta \\indicator(s_+ \\leq s_- ) \\right| n , c_1 , \\dots , c_n \\right ] \\right ] \\notag \\\\ & = e\\left [ \\sum_{i=1}^n e\\left [ \\left .",
    "( c_ir_i)^\\beta \\indicator\\left(0 < c_i r_i \\leq -s + c_i r_i \\right ) \\right| n , c_1 , \\dots , c_n \\right ] \\right ] .",
    "\\label{eq : betaindicator } \\end{aligned}\\ ] ] when @xmath506 , we have that is bounded by @xmath507 \\right ] \\notag \\\\ & = e\\left [ |r| \\right ] e\\left [ \\sum_{i=1}^n |c_i|   e\\left [ \\left .",
    "|s - c_ir_i|^{\\beta-1 } \\right| n , c_1 , \\dots , c_n \\right ] \\right ] \\label{eq : indepprod1 } \\\\ & \\leq e\\left [ |r| \\right ] e\\left [ \\sum_{i=1}^n |c_i|   \\left ( e\\left [ \\left .",
    "|s - c_ir_i| \\right| n , c_1 , \\dots , c_n \\right ] \\right)^{\\beta-1 } \\right ] \\label{eq : jensenconcave } \\\\",
    "& \\leq e\\left [ |r| \\right]^\\beta e\\left [ \\sum_{i=1}^n |c_i|   \\left (    \\sum_{j=1}^n |c_j|   \\right)^{\\beta-1 } \\right ] \\notag \\\\ & = e\\left [ |r| \\right]^\\beta e\\left [   \\left (    \\sum_{j=1}^n |c_j|   \\right)^{\\beta } \\right ] < \\infty ,",
    "\\notag\\end{aligned}\\ ] ] where in we used the conditional independence of @xmath508 and @xmath509 and in we used jensen s inequality . now , when @xmath510 is bounded by @xmath511 \\right ] \\notag \\\\ & = e\\left [ |r|^{\\beta-1 }   \\right ] e\\left [ \\sum_{i=1}^n |c_i|^{\\beta-1 }   e\\left [ \\left .",
    "|s - c_ir_i| \\right| n , c_1 , \\dots , c_n \\right ] \\right ] \\label{eq : indepprod2 } \\\\ & \\leq e\\left [ |r|^{\\beta-1 }   \\right ] e[|r| ] e\\left [ \\sum_{i=1}^n |c_i|^{\\beta-1 }     \\sum_{j=1}^n |c_j| \\right ] \\notag \\\\ & \\leq e\\left [ |r|^{\\beta-1 }   \\right ] e[|r| ] e\\left [ \\left ( \\sum_{i=1}^n |c_i| \\right)^{\\beta-1 }     \\sum_{j=1}^n |c_j| \\right ] < \\infty , \\notag\\end{aligned}\\ ] ] where in we used the conditional independence of @xmath508 and @xmath512 .    for the second expectation in we use the elementary inequality @xmath513 for any @xmath514 to obtain that @xmath515 \\\\ & \\leq \\beta e\\left [ s_+^{\\beta-1 } s_- \\right ] \\notag \\\\ & = \\beta e\\left [ \\sum_{i=1}^n e\\left [ \\left . s_+^{\\beta-1 } ( c_ir_i)^-   \\right| n , c_1 , \\dots , c_n \\right ] \\right ] \\notag \\\\ & = \\beta e\\left [ \\sum_{i=1}^n e\\left [ \\left .",
    "\\left ( s_+ - ( c_i r_i)^+ \\right)^{\\beta-1 } ( c_i r_i)^-   \\right| n , c_1 , \\dots , c_n \\right ] \\right ] \\notag \\\\ & = \\beta e\\left [ \\sum_{i=1}^n e\\left [ \\left .",
    "\\left ( s_+ - ( c_i r_i)^+ \\right)^{\\beta-1 } \\right| n , c_1,\\dots , c_n \\right ] e\\left [ \\left .",
    "( c_i r_i)^-   \\right| n , c_1 , \\dots , c_n \\right ] \\right ] \\notag \\\\ & \\leq \\beta e[|r| ] e\\left [ \\sum_{i=1}^n |c_i| e\\left [ \\left .",
    "s_+^{\\beta-1 } \\right| n , c_1,\\dots , c_n \\right ]   \\right ] , \\label{eq : mixedexp}\\end{aligned}\\ ] ] where in the last equality we used the conditional independence of @xmath516 and @xmath517 . to see that is finite note that if @xmath506 , jensen s inequality gives @xmath518   \\right ] & \\leq e\\left [ \\sum_{i=1}^n |c_i| \\left ( e\\left [ \\left .",
    "s_+ \\right| n , c_1,\\dots , c_n \\right ] \\right)^{\\beta-1 } \\right ] \\\\ & \\leq e[|r|]^{\\beta-1 } e\\left [ \\sum_{i=1}^n |c_i|   \\left ( \\sum_{j=1}^n |c_j| \\right)^{\\beta-1 }    \\right ] < \\infty.\\end{aligned}\\ ] ] and if @xmath510 , we use lemma [ l.alpha_moments ] to obtain , for @xmath519 , @xmath520 & \\leq e\\left [ \\left .",
    "\\sum_{j=1}^n ( ( c_jr_j)^+)^{\\beta-1 } \\right| n , c_1,\\dots , c_n \\right ]   + e\\left[|r|^{p-1}\\right]^{(\\beta-1)/(p-1 ) } \\left ( \\sum_{j=1}^n |c_j| \\right)^{\\beta-1 } \\\\ & \\leq e\\left[|r|^{\\beta-1}\\right ] \\sum_{j=1}^n |c_j|^{\\beta-1 } + e\\left[|r|^{p-1}\\right]^{(\\beta-1)/(p-1 ) } \\left ( \\sum_{j=1}^n |c_j| \\right)^{\\beta-1 } \\\\ & \\leq \\left ( ||r||_{\\beta-1}^{\\beta-1 } + || r ||_{p-1}^{\\beta-1 } \\right ) \\left ( \\sum_{j=1}^n |c_j| \\right)^{\\beta-1},\\end{aligned}\\ ] ] where @xmath521 \\right)^{1/r}$ ] .",
    "next , using the monotonicity of @xmath522 it follows that    @xmath523   \\right ]   \\leq 2 e\\left [ |r|^{\\beta-1 } \\right ]   e\\left [ \\sum_{i=1}^n |c_i| \\left ( \\sum_{j=1}^n |c_j| \\right)^{\\beta-1 } \\right ] < \\infty.\\ ] ] this completes the proof for @xmath419 . to obtain the same result for",
    "@xmath524 simply note that @xmath525 = e\\left [ \\left| \\left ( \\left ( \\sum_{i=1}^n ( - c_i r_i ) \\right)^+ \\right)^\\beta - \\sum_{i=1}^n ( ( -c_i r_i)^+)^\\beta \\right| \\right]\\ ] ] and apply the result for @xmath419 .    finally , for @xmath526 , we use the fact that @xmath527 for any @xmath528 to obtain @xmath529   & = e\\left [ \\left| ( s^+)^\\beta + ( s^-)^\\beta - \\sum_{i=1}^n \\left ( ( ( c_i r_i)^+)^\\beta + ( ( c_ir_i)^-)^\\beta \\right ) \\right| \\right ] \\end{aligned}\\ ] ] which is finite by the previous cases @xmath530 and @xmath524 .    from the proof of lemma [ l.d_moments_larger1 ]",
    "we see that it is enough to prove the result for @xmath419 .",
    "let @xmath531 , @xmath502 and @xmath503 . since @xmath327 , we have @xmath532 for any real numbers @xmath533 and any @xmath534 .",
    "hence , @xmath535 \\notag \\\\ & = e\\left [ \\sum_{i=1}^n ( ( c_ir_i)^+)^\\beta \\indicator(s_+ \\leq s_- ) \\right ] +   e\\left [ \\left ( \\sum_{i=1}^n ( ( c_ir_i)^+)^\\beta - s_+^\\beta \\right ) \\indicator(s_+ > s_- ) \\right ] \\label{eq : concavesum1 } \\\\ & \\hspace{5 mm } + e\\left [ \\left ( s_+^\\beta - ( s_+-s_-)^\\beta \\right ) \\indicator(s_+ > s_- ) \\right ] .",
    "\\label{eq : concavesum2}\\end{aligned}\\ ] ]    the first expectation in can be bounded as follows .",
    "let @xmath536 and @xmath537 @xmath538   & = e\\left [ \\sum_{i=1}^n e\\left [ \\left . (",
    "( c_ir_i)^+)^\\beta \\indicator(0 < c_ir_i \\leq -s + c_ir_i ) \\right| n , c_1,\\dots , c_n \\right ] \\right ] \\\\ & \\leq e\\left [ \\sum_{i=1}^n e\\left [ \\left . |c_ir_i|^{a } |s - c_ir_i|^{b } \\right| n , c_1,\\dots , c_n \\right ] \\right ] \\\\ & = e\\left [ |r|^{a } \\right ] e\\left [ \\sum_{i=1}^n |c_i|^{a }   e\\left [ \\left .",
    "|s - c_ir_i|^{a \\cdot \\frac{b}{a } } \\right| n , c_1,\\dots , c_n \\right ] \\right ]   \\\\ & \\leq e\\left [ |r|^{a } \\right ]   e\\left [ \\sum_{i=1}^n |c_i|^{a } \\left ( e\\left [ \\left .",
    "\\sum_{j=1}^n |c_jr_j|^{a } \\right| n , c_1,\\dots , c_n \\right ]   \\right)^{\\frac{b}{a } } \\right ] \\\\ & = \\left ( e\\left [ |r|^{a } \\right ] \\right)^{1+b / a } e\\left [ \\sum_{i=1}^n |c_i|^a \\left ( \\sum_{j=1}^n |c_j|^{a } \\right)^\\frac{b}{a } \\right ] \\\\ & =   \\left ( e\\left [ |r|^{\\beta/(1+\\epsilon ) } \\right ] \\right)^{1+\\epsilon } e\\left [   \\left ( \\sum_{i=1}^n |c_i|^{\\beta/(1+\\epsilon ) } \\right)^{1+\\epsilon } \\right ]   < \\infty , \\end{aligned}\\ ] ] where in the second equality we used the conditional independence of @xmath391 and @xmath509 .    to analyze the expectation in note that",
    "since @xmath539 for any @xmath514 , it follows that @xmath540 & \\leq e\\left [ s_-^\\beta   \\indicator(s_+ > s_- ) \\right ] \\leq e\\left [ \\sum_{i=1}^n ( ( c_ir_i)^-)^\\beta \\indicator(s_- \\leq s_+ ) \\right],\\end{aligned}\\ ] ] which is finite by the same arguments used above .    finally , to analyze the second expectation in , note that it is bounded by @xmath541 & \\leq e\\left [   \\sum_{i=1}^n ( ( c_ir_i)^+)^\\beta -   \\left ( \\max_{1\\leq i \\leq n } ( c_ir_i)^+\\right)^\\beta    \\right ] + e\\left [   \\left| \\left ( \\max_{1\\leq i \\leq n } ( c_ir_i)^+\\right)^\\beta - s_+^\\beta \\right|   \\right ] \\\\ & \\leq 2 e\\left [   \\sum_{i=1}^n ( ( c_ir_i)^+)^\\beta -   \\left ( \\max_{1\\leq i \\leq n } ( c_ir_i)^+\\right)^\\beta    \\right ]   , \\end{aligned}\\ ] ] which is finite by lemma [ l.max_approx ] .",
    "let @xmath390 be any of the random variables @xmath391 , @xmath392 , or @xmath393 and note that the integral is positive since @xmath542 & \\leq e\\left [    \\sum_{i=1}^n 1\\left ( t_i > t    \\right )   \\right ] .\\end{aligned}\\ ] ] to see that the integral is equal to the expectation involving the @xmath26-moments note that @xmath543 - p\\left ( \\max_{1\\leq i \\leq n } t_i > t \\right ) \\right )   t^{\\alpha -1 } \\ , dt \\\\ & = \\int_0^\\infty \\left ( e\\left [ \\sum_{i=1}^n 1(t_i > t )    -   1\\left(\\max_{1\\leq i \\leq n } t_i",
    "> t \\right )   \\right ] \\right )   t^{\\alpha -1 } \\ , dt \\\\ & = e\\left [   \\int_0^\\infty \\left (    \\sum_{i=1}^n   1(t_i > t )   - 1\\left(\\max_{1\\leq i \\leq n } t_i",
    "> t \\right )   \\right )   t^{\\alpha -1 } \\ , dt   \\right ] \\qquad \\text{(by fubini 's theorem ) } \\\\ & = e\\left [    \\sum_{i=1}^n   \\frac{1}{\\alpha } ( t_i^+)^{\\alpha }   - \\frac{1}{\\alpha } \\left ( \\left ( \\max_{1\\leq i \\leq n } t_i \\right)^+\\right)^{\\alpha }   \\right ] , \\end{aligned}\\ ] ] where the last equality is justified by the assumption that @xmath544 a.s .",
    "let @xmath545 and suppose first that @xmath419 .",
    "if @xmath353 , then we can use the inequality @xmath546 for all @xmath514 to obtain @xmath547 & \\leq   e\\left [ \\left| ( s+q)^+ - s^+ \\right|^\\alpha \\right ] \\\\ & = e\\left [ \\left ( ( s+q)^+- s^+ \\right)^\\alpha \\indicator(q \\geq 0 ) \\right ] + e\\left [ \\left ( s - ( s+q ) \\right)^\\alpha \\indicator(q < 0 \\leq s+q ) \\right ] \\\\ & \\hspace{5 mm } + e\\left [ ( s^+)^\\alpha \\indicator(q < 0 , s+q < 0 ) \\right ] \\\\ &",
    "\\leq e\\left [ ( q^+)^\\alpha \\indicator(q \\geq 0 ) \\right ] + e\\left [ \\left ( -q \\right)^\\alpha \\indicator(q < 0 \\leq s+q ) \\right ] \\\\ & \\hspace{5 mm } + e\\left [ ( ( -q)^+)^\\alpha \\indicator(q < 0 , s+q < 0 ) \\right ] \\\\ & \\leq e[|q|^\\alpha ] < \\infty.\\end{aligned}\\ ] ] if @xmath350 we use the inequality @xmath548 for any @xmath549 .",
    "let @xmath550 , apply the second inequality @xmath551 times and then the first one to obtain @xmath552 hence , it follows that @xmath547 & = e\\left [ \\left ( ( ( s+q)^+)^\\alpha - ( s^+)^\\alpha \\right ) \\indicator(q \\geq 0 ) \\right ] + e\\left [ \\left ( s^\\alpha- ( s+q)^\\alpha \\right ) \\indicator(q < 0 \\leq s+q ) \\right ]   \\\\ & \\hspace{5 mm } +   e\\left [ ( s^+)^\\alpha \\indicator(q < 0 , s+q < 0 ) \\right ] \\\\ & \\leq e\\left [ \\left ( ( s^+ + q^+)^\\alpha - ( s^+)^\\alpha \\right ) \\indicator(q \\geq 0 ) \\right ] + e\\left [ \\left ( s^\\alpha- ( s- q^-)^\\alpha \\right ) \\indicator(q < 0 \\leq s+q ) \\right ]   \\\\ & \\hspace{5 mm } +   e\\left [ ( ( -q)^+)^\\alpha \\indicator(q < 0 , s+q < 0 ) \\right ] \\\\ & \\leq e\\left [ \\left ( \\alpha^p ( q^+)^\\alpha + \\alpha^p \\sum_{i=1}^{p-1 } ( s^+)^{\\alpha - i } ( q^+)^i \\right ) \\indicator(q \\geq 0 ) \\right ]   \\\\ & \\hspace{5 mm } + e\\left [ \\alpha s^{\\alpha-1 } ( q^- ) \\indicator(q < 0 \\leq s+q ) \\right ] + e\\left [ ( q^-)^\\alpha \\indicator(q < 0 , s+q < 0 ) \\right ] \\\\   & \\leq \\alpha^p e[|q|^\\alpha ] + 2 \\alpha^p \\sum_{i=1}^{p-1 } e\\left[(s^+)^{\\alpha - i } |q|^i \\right].\\end{aligned}\\ ] ] to see that each of the expectations of the form @xmath553 $ ] is finite note that @xmath554 and follow the same steps as in the proof of lemma 4.8 in @xcite .    to establish the result for",
    "@xmath524 simply note that @xmath555 = e\\left [ \\left| ( ( -s - q)^+)^\\alpha - ( ( -s)^+)^\\alpha \\right| \\right]\\ ] ] and apply the result for the positive part .",
    "finally , for @xmath526 we use the fact that @xmath527 for any @xmath528 to obtain @xmath556 & =   e\\left [ \\left| ( ( s+q)^+)^\\alpha   + ( ( s+q)^-)^\\alpha - ( s^+)^\\alpha - ( s^-)^\\alpha   \\right| \\right ] , \\end{aligned}\\ ] ] which is finite by the previous two cases @xmath419 and @xmath524 .    [ l.newintegralineq ] for any two real valued random variables @xmath557 and @xmath484 on a common probability space , @xmath558 t^{\\alpha-1 } dt \\leq \\frac{1}{\\alpha } e\\left [   \\left| ( x^+)^\\alpha - ( y^+)^\\alpha \\right| \\right],\\ ] ] finite or infinite .    note that @xmath559 it follows from this observation and fubini s theorem that @xmath560 t^{\\alpha-1 } dt   \\\\ & = e\\left [   \\int_0^\\infty \\left| 1(x > t ) - 1(y > t ) \\right| t^{\\alpha-1 } dt   \\right ]   \\\\ & \\leq e\\left [ \\int_0^\\infty 1(y \\leq t < x ) t^{\\alpha-1 } dt + \\int_0^\\infty 1(x \\leq t < y ) t^{\\alpha-1 } dt \\right ] \\\\ & = e\\left [ \\int_{y^+}^{x^+ } t^{\\alpha-1}dt \\ , 1(y^+ < x^+ ) + \\int_{x^+}^{y^+ } t^{\\alpha-1 } dt \\ , 1(x^+ < y^+ ) \\right ] \\\\ & = e\\left [ \\frac{1}{\\alpha } ( ( x^+)^\\alpha - ( y^+)^\\alpha ) 1(y^+",
    "< x^+ ) + \\frac{1}{\\alpha } ( ( y^+)^\\alpha - ( x^+)^\\alpha ) 1(x^+ < y^+ ) \\right ] \\\\ & = \\frac{1}{\\alpha }   e\\left [ | ( x^+)^\\alpha - ( y^+)^\\alpha | \\right].\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> consider distributional fixed point equations of the form @xmath0 where @xmath1 is a possibly random real valued function , @xmath2 , @xmath3 are real valued random weights and @xmath4 are iid copies of @xmath5 , independent of @xmath6 ; @xmath7 represents equality in distribution . </S>",
    "<S> fixed point equations of this type are of utmost importance for solving many applied probability problems , ranging from the average case analysis of algorithms to statistical physics . </S>",
    "<S> we develop an implicit renewal theorem that enables the characterization of the power tail behavior of the solutions @xmath5 to many equations of multiplicative nature that fall into this category . </S>",
    "<S> this result extends the prior work in @xcite , which assumed nonnegative weights @xmath8 , to general real valued weights . </S>",
    "<S> we illustrate the developed theorem by deriving the power tail asymptotics of the solution @xmath5 to the linear equation @xmath9 . </S>"
  ]
}