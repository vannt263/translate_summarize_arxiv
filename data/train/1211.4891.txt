{
  "article_text": [
    "kolmogorov complexity ( also known as kolmogorov - chaitin or program - size complexity ) is recognized as a fundamental concept , but it is also often thought of as having little or no applicability because it is not possible to provide stable numerical approximations for finite  particularly short  strings by using the traditional approach , namely lossless compression algorithms .",
    "we advance a method that can overcome this limitation , and which , though itself limited in ways both theoretical and numerical , nonetheless offers a means of providing sensible values for the complexity of short strings , complementing the traditional lossless compression method that works well for long strings .",
    "this is done at the cost of massive numerical calculations and through the application of the coding theorem from algorithmic probability theory that relates the frequency of production of a string to its kolmogorov complexity .",
    "bennett s logical depth , on the other hand , is a measure of the complexity of strings that , unlike kolmogorov complexity , measures the _ organized _ information content of a string . in",
    "@xcite an application inspired by the notion of logical depth was reported in the context of the problem of image classification .",
    "however , the results in this paper represent the first attempt to provide direct numerical approximations of logical depth .    the independence of the two measures kolmogorov complexity and logical depth which has been established theoretically , is also numerically tested and confirmed in this paper .",
    "our work is in agreement with what the theory predicts , even for short strings  despite the limitations of our approach .",
    "our attempt to apply these concepts to practical problems ( detailed in a series of articles ( see e.g.  @xcite ) ) is novel , and they are indeed proving to have interesting applications where evaluations of the complexity of finite short strings are needed  @xcite .    in sections",
    "[ kolmochap ] ,  [ ld ] ,  [ codingchap ] and  [ formal ] , we introduce the measures , tools and formalism used for the method described in section  [ dist ] . in section  [ comparison ] ,",
    "we report the numerical results of the evaluation and analysis of the comparisons among the various measures , particularly the connection between number of instructions , integer valued program - size complexity , kolmogorov complexity approximated by means of the coding theorem method , and logical depth .",
    "when researchers have chosen to apply the theory of algorithmic information ( ait ) , it has proven to be of great value despite initial reservations  @xcite .",
    "it has been successfully applied , for example , to dna false positive repeat sequence detection in genetic sequence analysis  @xcite , in distance measures and classification methods  @xcite , and in numerous other applications  @xcite .",
    "this effort has , however , been hamstrung by the limitations of compression algorithms  currently the only method used to approximate the kolmogorov complexity of a string  given that this measure is not computable .",
    "central to ait is the basic definition of plain algorithmic ( kolmogorov - chaitin or program - size ) complexity  @xcite :    @xmath3    where @xmath4 is a universal turing machine and @xmath5 the program that , running on @xmath4 , produces @xmath1 . traditionally , the way to approach the algorithmic complexity of a string has been by using lossless compression algorithms .",
    "the result of a lossless compression algorithm applied to @xmath1 is an upper bound of the kolmogorov complexity of @xmath1 .",
    "short strings , however , are difficult to compress in practice , and the theory does not provide a satisfactory solution to the problem of the instability of the measure for short strings .    the invariance theorem , however , guarantees that complexity values will only diverge by a constant @xmath6 ( e.g. the length of a compiler or a translation program ) . +",
    "* invariance theorem * ( @xcite ) : if @xmath7 and @xmath8 are two universal turing machines , and @xmath9 and @xmath10 the algorithmic complexity of @xmath1 for @xmath7 and @xmath8 respectively , there exists a constant @xmath6 such that :    latexmath:[\\[\\label{invariance }     hence the longer the string , the less important @xmath6 is ( i.e. the choice of programming language or universal turing machine ) .",
    "however , in practice @xmath6 can be arbitrarily large , thus having a very great impact on the stability of kolmogorov complexity approximations for short strings .",
    "a measure of the structural complexity ( i.e. richness of structure and organization ) of a string can be arrived at by combining the notions of algorithmic information and time complexity . according to the concept of logical depth @xcite , the complexity of a string",
    "is best defined by the time that an unfolding process takes to reproduce the string from its shortest description .",
    "while kolmogorov complexity is related to compression length , bennett s logical depth is related to decompression time .    a typical example that illustrates the concept of logical depth , underscoring its potential as a measure of complexity , is a sequence of fair coin tosses .",
    "such a sequence would have a high information content ( kolmogorov complexity ) because the outcomes are random , but it would have no structure because it is easily generated . the string 1111  1111 would be equally shallow as measured by logical depth . its compressed version , while very small , requires little time to decompress into the original string . in contrast , the binary expansion of the mathematical constant @xmath12 is not shallow , because though highly compressible and hence having a low kolmogorov complexity , it requires non - negligible computational time to produce arbitrary numbers of digits from its shortest program ( or indeed from any short program computing the digits of @xmath12 ) .",
    "a detailed explanation pointing out the convenience of the concept of logical depth as a measure of organized complexity as compared to plain algorithmic complexity , which is what is usually used , is provided in @xcite . for finite strings , one of bennett s formal approaches to the logical depth of a string",
    "is defined as follows : + let @xmath1 be a string and @xmath13 a significance parameter . a string s",
    "depth at significance @xmath13 is given by @xmath14    with @xmath15 the length of the shortest program for @xmath1 , ( therefore @xmath16 ) .",
    "in other words , @xmath17 is the least time @xmath18 required to compute @xmath1 from a @xmath13-incompressible program @xmath5 on a universal turing machine @xmath4 .",
    "each of the three linked definitions of logical depth provided in  @xcite comes closer to a definition in which near - shortest programs are taken into consideration . in this experimental approach",
    "we make no such distinction among significance parameters , so we will denote the logical depth of a string @xmath1 simply by @xmath2 .    like @xmath16 ,",
    "@xmath2 as a function of @xmath1 is uncomputable .",
    "a novel feature of this research is that we provide exact numerical approximations for both measures @xmath16 and @xmath2 for specific short @xmath1 , allowing a direct comparison .",
    "this was achieved by running a large set of random turing machines and finding the smallest and fastest machines generating each output string .",
    "hence these approximations are deeply related to another important measure of algorithmic information theory .",
    "the algorithmic probability ( also known as levin s semi - measure ) of a string @xmath1 , is a measure that describes the expected probability of a random program @xmath5 running on a universal ( prefix - free  . for details see  @xcite ) . ] ) turing machine @xmath4 producing @xmath1 .",
    "formally  @xcite ,    @xmath19    i.e. the sum over all the programs for which @xmath4 with @xmath5 outputs @xmath1 and halts .",
    "levin s semi - measure @xmath20 defines a distribution known as the _ universal distribution _  @xcite .",
    "it is important to notice that the value of @xmath20 is dominated by the length of the smallest program @xmath5 ( when the denominator of @xmath21 reaches its largest value ) .",
    "the length of the smallest program @xmath5 that produces the string @xmath1 is @xmath16 .",
    "the semi - measure @xmath20 is therefore also uncomputable , because for every @xmath1 , @xmath20 requires the calculation of @xmath22 , involving @xmath23 , which is itself uncomputable . an extension of @xmath20 to non - binary alphabets",
    "is natural .",
    "more formally , @xmath24 can be associated with the original definition for binary strings .",
    "however , one may want to extend @xmath24 to @xmath25 , in which case for every @xmath26 , the function @xmath27 is semi - computable ( for the same reason that @xmath28 is uncomputable ) .",
    "an alternative  @xcite to the traditional use of compression algorithms to approximate @xmath23 can be derived from a fundamental theorem that establishes the exact connection between @xmath20 and @xmath16 . +",
    "* coding theorem * ( levin  @xcite ) : @xmath29    where we will use @xmath0 to indicate that @xmath23 has been approximated by means of @xmath21 through the coding theorem .",
    "an important property of @xmath21 as a semi - measure is that it dominates any other effective semi - measure @xmath30 , because there is a constant @xmath31 such that for all @xmath1 , @xmath32 .",
    "for this reason @xmath20 is often called a _ universal distribution _  @xcite .",
    "the ability of a universal turing machine to simulate any algorithmic process has motivated and justified the use of universal turing machines as the language framework within which definitions and properties of mathematical objects are given and studied .    however , it is important to describe the formalism of a turing machine , because exact values of algorithmic probability for short strings will be approximated under this model , both for @xmath16 through @xmath20 ( denoted by @xmath0 ) , and for @xmath16in terms of the number of instructions used by the smallest turing machine producing @xmath1 .",
    "+ consider a turing machine @xmath33 with alphabet @xmath34 symbols , @xmath35 states and an additional halting state denoted by @xmath36 ( as defined by rado in his original busy beaver paper  @xcite ) . at the outset",
    "the turing machine is in its initial state @xmath37 .",
    "the machine runs on a @xmath38-way unbounded tape .",
    "its behavior is determined by the transition function @xmath39 .",
    "so , at each step :    the machine s current `` state '' ( instruction ) @xmath1 ; and    the tape symbol the machine s head is scanning @xmath26    define the transition @xmath40 with    a unique symbol @xmath41 to write ( the machine can overwrite a @xmath37 on a @xmath36 , a @xmath36 on a @xmath37 , a @xmath37 on a @xmath37 , and a @xmath36 on a @xmath36 ) ;    a direction @xmath13 to move in : @xmath42 ( left ) , @xmath37 ( right ) or @xmath36 ( none , when halting ) ; and    a state @xmath43 to transition into ( which may be the same as the one it was in ) .",
    "the machine halts if and when it reaches the special halt state @xmath36",
    ". there are @xmath44 turing machines with @xmath45 states and @xmath38 symbols according to the formalism described above , as there are @xmath46 entries in the transition table and any of them may have @xmath47 possible instructions : there are @xmath38 halting instructions ( writing ` 0 ' and ` 1 ' ) and @xmath48 non - halting instructions ( @xmath38 movements , @xmath38 possible symbols to write and @xmath45 states ) .",
    "the output string is taken from the number of contiguous cells on the tape the head of the halting @xmath45-state machine has gone through .",
    "a turing machine is considered to produce an output string only if it halts .",
    "the output is what the machine has written on the tape .",
    "in order to arrive at an approximation of @xmath20 , a method based on the coding theorem was advanced in  @xcite .",
    "it is captured in the following function .",
    "let @xmath33 be a turing machine in @xmath49 with empty input . then :    @xmath50    where @xmath51 denotes the number of elements of @xmath52 .",
    "let @xmath21 be fixed .",
    "it has been proved  @xcite that the function @xmath53 is non - computable ( due to the denominator ) .",
    "however , @xmath54 for fixed and small values @xmath45 and @xmath21 is computable for values of the busy beaver problem  @xcite that are known . for @xmath55 , for example , the busy beaver function @xmath56 tells us that @xmath57  @xcite , so given a turing machine with 4 states running on a blank tape that hasnt halted after 107 steps , we know it will never stop .    more generally , for every string @xmath1 ( with alphabet @xmath58 ) one can compute a sequence @xmath59 which converges to @xmath60 when @xmath61 . for @xmath62",
    "we compute for @xmath18 steps all @xmath21-turing machines with @xmath45 states ( there is a finite number of them ) and compute the quotient for @xmath60 for machines that halted before @xmath18 steps . since @xmath62 converges for every @xmath1 to @xmath63 (",
    "@xmath21 fixed , @xmath45 fixed , @xmath1 fixed ) , the value of @xmath64 converges for fixed @xmath21 and @xmath45 . in this specific sense @xmath65",
    "is approachable , even if @xmath62 as a function of increasing time @xmath18 may increase when a machine produces @xmath1 , or decrease when a machine halts without producing @xmath1 . by the invariance theorem ( eq .  [ invariance ] ) and the coding theorem ( eq .  [ coding ] ) , @xmath63 is guaranteed to converge to @xmath20 .",
    "exact values of @xmath62 were previously calculated  @xcite for @xmath66 symbols and @xmath67 states for which the busy beaver values are known .",
    "that is , a total of 36 , 10000 , 7529536 and 11019960576 turing machines respectively .",
    "the distributions were very stable and are proving to be capable of delivering applications that are also in agreement with results from lossless compression algorithms  @xcite for boundary cases ( where both methods can be applied ) , hence validating the utility of both methods ( compression being largely validated by its plethora of applications and by the fact that it achieves an approximation of @xmath23 , see e.g.  @xcite ) .",
    "the chief advantage of the coding theorem method , however , is that it is capable of dealing with short entities ( unlike compression algorithms , which are designed for large entities ) .",
    "there are 26559922791424 turing machines with 5 states and 2 symbols , and the values of busy beaver functions for these machines are unknown . in what follows",
    "we describe how we proceeded .",
    "calculating @xmath68 is an improvement on our previous numerical evaluations and provides a larger data set to work with , allowing us to draw more significant statistical conclusions vis -  - vis the relation between these calculations and strict integer value program - size complexity , as well as to make a direct comparison to bennett s logical depth .",
    "we did not run all the turing machines with 5 states to produce @xmath69 , because one can take advantage of symmetries and anticipate some of the behavior of the turing machines directly from their transition tables without actually running them ( this is impossible generally due to the halting problem , but some reductions are possible ) .",
    "if @xmath70 is the set of turing machines with @xmath45 states and @xmath21 symbols , as defined above , we reduce it to : @xmath71 where @xmath39 is the transition function of @xmath33 .",
    "so @xmath72 is a subset of @xmath70 , with machines with the transition corresponding to initial state @xmath37 and symbol @xmath36 ( this is the initial transition in a ` 0'-filled blank tape ) moving to the right and changing to a state different from the initial and halting ones .    for machines with two symbols , @xmath73 as there are @xmath74 different initial transitions ( the machine can write ` 0 ' or ` 1 ' and move to one of the @xmath75 states in @xmath76 ) , and for the other @xmath77 transitions there are @xmath47 possibilities , as in @xmath70 .",
    "after running @xmath78 on a ` 0'-filled tape , the procedure for completing the output strings so that they reach the frequency they have in @xmath70 is :    * for every @xmath79 , * * if @xmath33 halts and produces the output string @xmath1 , add one occurrence of @xmath80 , the reverse of @xmath1 .",
    "* * if @xmath33 does not halt , count another non - halting machine .",
    "+ these two completions add the output ( or number of non - halting machines ) of @xmath81 new machines , one for each machine in @xmath78 .",
    "these new machines are left - right symmetric to the machines in @xmath78 .",
    "formally , this is the set @xmath82 when the original machine halts , its symmetric counterpart halts too and produces the reversed strings , and if the original machine does not halt , neither does the symmetric machine . this way we consider the output of all machines with the initial transition moving to the left and to a state not in @xmath83 . *",
    "include @xmath84 occurrences of string `` 1 '' .",
    "this corresponds to the machines writing ` 1 ' and halting at the initial transition .",
    "there is just one possible initial transition for these machines ( move to the halting state , write ` 1 ' and remain in the initial cell ) .",
    "the other @xmath77 transitions can have any of the @xmath47 possible instructions .",
    "* include @xmath84 occurrences of string `` 0 '' .",
    "this is justified as above , for machines writing ` 0 ' and halting at the initial transition . *",
    "include @xmath85 additional non - halting machines , corresponding to machines remaining in the initial state in the initial transition ( these machines never halt , as they remain forever in the initial state ) .",
    "there are @xmath86 initial transitions of this kind , as the machine can write @xmath38 different symbols and move in @xmath38 possible directions .",
    "if we sum @xmath87 and the machines considered above , having completed them in the manner described , we get the output corresponding to the @xmath88 machines in @xmath89 .",
    "moreover , we need the output of those machines starting with a ` 0'-filled tape and with a ` 1'-filled tape .",
    "but we do not run any machine twice , as for every machine @xmath90 producing the binary string @xmath1 starting with a ` 1'-filled tape , there is also a 0 - 1 symmetric machine @xmath91 ( where the role of 1 ( of 0 ) in the transition table of @xmath92 is the role of 0 ( of 1 ) in the transition table of @xmath33 ) that when starting with a ` 0'-filled tape produces the complement to one of @xmath1 , that is , the result of replacing all 0s in s with 1s and all 1s with 0s .",
    "so we add the complement to every one of the strings found and count the non - halting machines twice to obtain the output of all machines in @xmath89 starting both with a ` 0'-filled tape and with a ` 1'-filled tape .",
    "to construct @xmath69 , we ran the @xmath93 machines in @xmath94 , which is @xmath95 of @xmath96 .",
    "the output strings found in @xmath94 , together with their frequencies , were completed prior to constructing @xmath69 , following the procedure explained above .",
    "it is useful to avoid running machines that we can easily determine will not stop .",
    "these machines will consume the runtime without yielding an output . as we have shown above",
    ", we can avoid generating many non - halting machines .",
    "in other cases , we can detect them at runtime , by setting appropriate filters .",
    "the theoretical limit of the filters is the halting problem , which means that they can not be exhaustive . but a practical limit is imposed by the difficulty of checking some filters , which takes up more time than the runtime that is saved .",
    "we have employed some filters that have proven useful .",
    "briefly , these are :    * * machines without transitions to the halting state*. while the transition table is being filled , the simulator checks to ascertain whether there is some transition to the halting state .",
    "if not , it avoids running it .",
    "* * escapees*. these are machines that at some stage begin running forever in the same direction . as they are always reading new blank symbols , as soon as the number @xmath6 of non - previously visited positions is greater than the number @xmath45 of states , we know that they will not stop , because the machines have necessarily entered an infinite loop . given that @xmath97 , while visiting the last @xmath6 new cells , some of the @xmath45 states have been repeated , and will repeat forever , as the machine s behavior is deterministic .",
    "* * cycles of period two*. these cycles are easy to detect .",
    "they are produced when in steps @xmath18 and @xmath98 the tape is identical and the machine is in the same state and the same position .",
    "when this is the case , the cycle will be repeated infinitely .",
    "these filters were implemented in our c++ simulator , which also uses the reduced enumeration of section  [ sec : some - reductions ] . to test them we calculated @xmath99 with the simulator and compared the output to the list that was computed in  @xcite , arriving at exactly the same results , and thereby validating our reduction techniques .",
    "running @xmath100 without reducing the enumeration or detecting non - halting machines took 952 minutes . running the reduced enumeration with non - halting detectors took 226 minutes .",
    "the busy beaver for turing machines with 4 states is known to be 107 steps @xcite , that is , any turing machine with 2 symbols and 4 states running longer than 107 steps will never halt .",
    "however , the exact number is not known for turing machines with 2 symbols and 5 states , although it is believed to be 47176870 , as there is a candidate machine that runs for this length of time and halts and no machine with a greater runtime has yet been found .",
    "so we decided to let the machines with 5 states run for 4.6 times the busy beaver value for 4-state turing machines ( for 107 steps ) , knowing that this would constitute a sample significant enough to capture the behavior of turing machines with 5 states .",
    "the chosen runtime was rounded to 500 steps , which was used to construct the output frequency distribution for @xmath69 .",
    "not all 5-state turing machines have been used to build @xmath69 , since only the output of machines that halted at or before 500 steps was taken into consideration . as an experiment to ascertain how many machines we were leaving out , we ran @xmath101 random turing machines for up to 5000 steps . among these ,",
    "only 50 machines halted after 500 steps and before 5000 ( that is , a fraction less than @xmath102 , because in the reduced enumeration we do nt include those machines that halt in one step or that we know wo nt halt before we generate them , so it s a smaller fraction ) , with the remaining 1496491379 machines not halting at 5000 steps . as far as these are concerned  and given that the busy beaver values for 5 states are unknown  we do not know after how many steps they would eventually halt , if they ever do . according to the following analysis , our election of a runtime of 500 steps therefore provides a good estimation of @xmath69 .",
    "the frequency of runtimes of ( halting ) turing machines has theoretically been proven to drop exponentially @xcite , and our experiments are closer to the theoretically predicted behavior . to estimate the fraction of halting machines that were missed because turing machines with 5 states were stopped after 500 steps , we hypothesize that the number of steps @xmath56 a random halting machine needs before halting is an exponential random variable , defined by @xmath103 we do not have direct access to an evaluation of @xmath104 , since we only have data for those machines for which @xmath105 .",
    "but we may compute an approximation of @xmath106 , @xmath107 , which is proportional to the desired distribution .    a non - linear regression using ordinary least - squares",
    "gives the approximation @xmath108 with @xmath109 and @xmath110 .",
    "the residual sum - of - squares is @xmath111 ; the number of iterations with starting values @xmath112 and @xmath113 is nine .",
    "the model s @xmath114 is the same @xmath114 appearing in the general law @xmath104 , and may be used to estimate the number of machines we lose by using a 500 step cut - off point for running time : @xmath115 .",
    "this estimate is far below the point where it could seriously impair our results : the less probable ( non - impossible ) string according to @xmath69 has an observed probability of @xmath116 .",
    "although this is only an estimate , it suggests that missed machines are few enough to be considered negligible .",
    "we now study the relation of @xmath0 to the minimal number of instructions used by a turing machine producing a given string , and to bennett s concept of logical depth .",
    "as expected , @xmath0 shows a correlation with the number of instructions used but not with logical depth .",
    "first , we are interested in the relation of @xmath117 to the minimal number of instructions that a turing machine producing a string @xmath1 uses .",
    "machines in @xmath69 have a transition table with 10 entries , corresponding to the different pairs @xmath49 , with @xmath1 one of the five states and @xmath21 either `` 0 '' or `` 1 '' .",
    "these are the 10 instructions that the machine can use .",
    "but for a fixed input not all instructions are necessarily used .",
    "then , for a blank tape , not all machines that halt use the same number of instructions .",
    "the simplest cases are machines halting in just one step , that is , machines whose transition for @xmath118 goes to the halting state , producing a string `` 0 '' or `` 1 '' .",
    "so the simplest strings produced in @xmath68 are computed by machines using just one instruction .",
    "we expected a correlation between the @xmath0-complexity of the strings and the number of instructions used . as we show",
    ", the following experiment confirmed this .",
    "we used a sample of @xmath119 random machines in the reduced enumeration for @xmath68 , that is , @xmath120 the total number of machines .",
    "the output of the sample returns the strings produced by halting machines together with the number of instructions used , the runtime and the instructions for the turing machine ( see fig .  [",
    "fig : distribins ] ) . in order to save space",
    ", we only saved the smallest number of instructions found for each string produced , and the smallest runtime corresponding to that particular number of instructions .",
    "values according to the minimum number of instructions required . each ",
    "drop - like \" distribution is the set of strings that are minimally produced with the same number of instructions ( horizontal axis ) .",
    "the more instructions needed to produce the strings , the more complex they are ( vertical axis in @xmath121 units).,width=377 ]    after doing the appropriate symmetry completions we have 99584 different strings , which is to say almost all the 99608 strings found in @xmath68 .",
    "the number of instructions used goes from 1 to 10 .",
    "when 1 instruction is used only `` 0 '' and `` 1 '' are generated , with a @xmath0 value of @xmath122 . with 2 instructions ,",
    "all 2-bit strings are generated , with a @xmath0 value of @xmath123 . for 3 or more instructions , fig .",
    "[ fig : distribins ] shows the distribution of values of @xmath0 .",
    "table  [ tab : meankl ] shows the mean @xmath0 values for the different numbers of instructions used .",
    ".mean @xmath0 and string length for different numbers of instructions used .",
    "[ cols=\">,>,>\",options=\"header \" , ]     we now provide some examples of the discordance between @xmath0 and @xmath124 .",
    "`` 0011110001011 '' is a string with high @xmath0 and low @xmath124 .",
    "[ fig : tablelowtime ] shows the transition table of the smallest machine found producing this string .",
    "the runtime is low  just 29 steps ( of the 99584 different strings found in our sample , only 3360 are produced in fewer steps ) , but it uses 10 instructions and produces a string with complexity @xmath125 .",
    "it is the greatest complexity we have calculated for @xmath0 .",
    "[ fig : execlowtime ] shows the execution of the machine .            on the other hand , `` @xmath126 ''",
    "is a string with high @xmath124 but a low @xmath0 value .",
    "[ tmtablehightime ] shows the transition table of the machine found producing this string , and fig .",
    "[ tmrunhightime ] depicts the execution .",
    "the machine uses 9 instructions and runs for 441 steps ( only 710 strings out of the 99584 strings in our sample require more time ) but its @xmath0 value is @xmath127 .",
    "this is a low complexity if we consider that in @xmath0 there are 99608 strings and that 90842 are more complex than this one .    ' ' .,width=415 ]    '' . with a high runtime ,",
    "it produces a string with low complexity.,width=453 ]    we may rate the overall strength of the relation between @xmath128 and @xmath124 by the correlation @xmath129 , corresponding to a medium positive link . as we previously mentioned , however , the fact that the length @xmath130 of the strings is linked with both variables may bias our interpretation .",
    "a more relevant measure is thus @xmath131 , a slight negative but with no significant value between @xmath128 and @xmath124 once @xmath130 is controlled .",
    "the results in this paper are important because these measures can be better studied and understood under a specific but widely known general formalism .",
    "what we have found is very interesting because it is what one would wish in the best case scenario , stable and reasonable distributions rather than chaotic and unstable ones .",
    "the results also suggest that these measures can be applied even if numerically approximated using a specific model of computation .",
    "for example , as we expected , the kolmogorov - chaitin complexity evaluated by means of levin s coding theorem from the output distribution of small turing machines correlates with the number of instructions used but not with logical depth .",
    "logical depth also yields a measure that is different from the measure obtained by considering algorithmic complexity ( @xmath23 ) alone , and this investigation proves that all these three measures ( kolmogorov - chaitin complexity , solomonoff - levin algorithmic probability and bennett s logic depth ) are consistent with theoretical expectations .",
    "@xmath23 as a measure of program - size complexity is traditionally expected to be an integer ( the length of a program in bits ) , but when evaluated through algorithmic probability using the coding theorem it retrieves non - integer values ( still bits ) .",
    "these results confirm the utility of non - integer values in the approximation of the algorithmic complexity of short strings , as they provide finer values with which one can tell apart small differences among short strings  which also means one can avoid the longer calculations that would be necessary in order to tell apart the complexity of very small objects if only integer values were allowed .",
    "thus it also constitutes a complementary and alternative method to compression algorithms .    an _ on - line algorithmic complexity calculator _ ( or oacc ) is now available at http://www.complexitycalculator.com .",
    "it represents a long - term project to develop an encompassing universal tool implementing some of the measures and techniques described in this paper .",
    "it is expected to be expanded in the future as it currently only implements numerical approximations of kolmogorov complexity and levin s semi - measure for short binary strings .",
    "more measures , more data and better approximations will be gradually incorporated in the future , covering a wider range of objects , such as longer binary strings , non - binary strings and multidimensional arrays ( such as images ) .",
    "bennett , logical depth and physical complexity in rolf herken ( ed ) _ the universal turing machine  a half - century survey , _ oxford university press 227257 , 1988 .",
    "bennett , how to define complexity in physics and why . in _ complexity , entropy and the physics of information .",
    "_ zurek , w. h. , addison - wesley , eds .",
    "sfi studies in the sciences of complexity , p 137 - 148 , 1990 .",
    "brady , the determination of the value of rado s noncomputable function @xmath132 for four - state turing machines , _ mathematics of computation 40 _ ( 162 ) : 647665 , 1983 .",
    "calude , _ information and randomness _ , springer , 2002 .",
    "calude and m.a .",
    "stay , most programs stop quickly or never halt , _ advances in applied mathematics _",
    ", 40 , 295 - 308 , 2008 .",
    "chaitin , on the length of programs for computing finite binary sequences : statistical considerations , _ journal of the acm _ , 16(1):145159 , 1969 .",
    "_ from philosophy to program size , _ 8th .",
    "estonian winter school in computer science , institute of cybernetics , tallinn , 2003 .",
    "r. cilibrasi , p. vitanyi , clustering by compression , _ ieee transactions on information theory , _ 51 , 4 , 15231545 , 2005 .",
    "t.m . cover and j.a .",
    "thomas , _ information theory , _",
    "j. wiley and sons , 2006 .",
    "delahaye , _ complexit alatoire et complexit organise , _ editions quae , 2009 .",
    "delahaye , h. zenil , towards a stable definition of kolmogorov - chaitin complexity , arxiv:0804.3459 , 2007 .",
    "delahaye and h. zenil , on the kolmogorov - chaitin complexity for short sequences . in c.",
    "calude ( ed . ) , _ randomness and complexity : from leibniz to chaitin _ , world scientific , 2007 .",
    "delahaye & h. zenil , numerical evaluation of the complexity of short strings : a glance into the innermost structure of algorithmic randomness , _ applied math . and comp .",
    "w. kircher , m. li , and p. vitanyi , the miraculous universal distribution , _ the mathematical intelligencer , _ 19:4 , 715 , 1997 .",
    "kolmogorov , three approaches to the quantitative definition of information , _ problems of information and transmission _ , 1(1):17 , 1965 . l. levin , laws of information conservation ( non - growth ) and aspects of the foundation of probability theory .",
    ", _ problems in form . transmission _ 10 . 206210 , 1974 . m. li , p. vitnyi , _ an introduction to kolmogorov complexity and its applications , _ springer , 2008 .",
    " . rivals , m. dauchet , j .-",
    "delahaye , o. delgrange , compression and genetic sequence analysis . , _ biochimie _ , 78 , pp 315 - 322 , 1996 . t. rad , on non - computable functions , _ bell system technical journal , _ vol .",
    "3 , pp . 877884 , 1962 .",
    "solomonoff , a formal theory of inductive inference : parts 1 and 2 . _ information and control _ , 7:122 and 224254 , 1964 .",
    "h. zenil , une approche exprimentale  la thorie algorithmique de la complexit , dissertation in fulfilment of the degree of doctor in computer science ( jury members : j .- p .",
    "delahaye and c.s .",
    "calude , g. chaitin , s. grigorieff , p. mathieu and h. zwirn ) , universit de lille 1 , 2011 .",
    "h. zenil , f. soler - toscano , j .-",
    "delahaye and n. gauvrit , two - dimensional kolmogorov complexity and validation of the coding theorem method by compressibility , arxiv:1212.6745 [ cs.cc ] .",
    "h. zenil , j .-",
    "delahaye and c. gaucherel , image information content characterization and classification by physical complexity , _ complexity _ , vol .",
    "173 , pages 2642 , 2012 ."
  ],
  "abstract_text": [
    "<S> we show that real - value approximations of kolmogorov - chaitin ( @xmath0 ) using the algorithmic coding theorem as calculated from the output frequency of a large set of small deterministic turing machines with up to 5 states ( and 2 symbols ) , is in agreement with the number of instructions used by the turing machines producing @xmath1 , which is consistent with strict integer - value program - size complexity . </S>",
    "<S> nevertheless , @xmath0 proves to be a finer - grained measure and a potential alternative approach to lossless compression algorithms for small entities , where compression fails . </S>",
    "<S> we also show that neither @xmath0 nor the number of instructions used shows any correlation with bennett s logical depth @xmath2 other than what s predicted by the theory . </S>",
    "<S> the agreement between theory and numerical calculations shows that despite the undecidability of these theoretical measures , approximations are stable and meaningful , even for small programs and for short strings . </S>",
    "<S> we also announce a first beta version of an online algorithmic complexity calculator ( oacc ) , based on a combination of theoretical concepts , as a numerical implementation of the _ coding theorem method_. + * keywords : * coding theorem method ; kolmogorov complexity ; solomonoff - levin algorithmic probability ; program - size complexity ; bennett s logical depth ; small turing machines . </S>"
  ]
}