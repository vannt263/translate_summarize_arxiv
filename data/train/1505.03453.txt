{
  "article_text": [
    "given a large @xmath7 complex matrix @xmath0 and a sufficiently regular function @xmath1 so that @xmath2 is well defined , we are interested in approximating the largest singular values and corresponding singular vectors of the matrix function @xmath2 . this computation will also give an approximation to its 2-norm , namely , @xmath3 , where @xmath8 is the matrix norm induced by the euclidean vector norm , and it is defined as @xmath9 in our presentation we will chiefly discuss this norm approximation because of its interest in applications .",
    "however , we shall keep in mind that the considered procedure allows us to also determine both associated left and right singular vectors , and that a group of singular triplets can be determined simultaneously .    the problem of approximating the norm of a matrix function arises in the solution of stiff linear initial value problems @xcite,@xcite , in the evaluation of derivatives and perturbations of matrix functions , which arise for instance in electronic structure theory @xcite,@xcite,@xcite , and in monitoring the magnitude of the inverse of distance matrices @xcite .",
    "in numerical linear algebra the norm of matrix polynomials may be used in the analysis of iterative procedures , and the norm of rational matrix functions , and in particular of the transfer function may give information on the sensitivity of the matrix itself to perturbations ; see , e.g. , @xcite,@xcite and their references .    if @xmath0 were normal , then the approximation could be stated in terms of an eigenvalue problem in @xmath0 . indeed , if @xmath10 is the eigendecomposition of @xmath0 with @xmath11 unitary and @xmath12 diagonal , then @xmath13 @xcite , so that the leading singular values of @xmath2 could be determined by a procedure that approximates the eigenvalues of @xmath0 .",
    "the problem is significantly more challenging if @xmath0 is large and non - normal , since there is no relation between eigenvalues and singular values that can be readily exploited during the computation .",
    "moreover , although @xmath0 may be sparse , in general @xmath2 will be dense , and it can not be computed explicitly .",
    "we are thus left with procedures that use @xmath1 and @xmath0 by means of the action of @xmath2 to a vector @xmath14 .",
    "the lanczos bidiagonalization is among the most used strategies for approximating selected singular triplets of a given matrix .",
    "given a matrix @xmath15 , this procedure generates a sequence of orthonormal vectors @xmath16 and @xmath17 by alternating products of @xmath18 and @xmath19 . in our case , @xmath20 and therefore these matrix vector products can be approximately computed .",
    "in fact , since this computation is expensive , we shall consider an _",
    "inexact _ implementation of the lanczos bidiagonalization process , where at each iteration the action of @xmath21 and @xmath22 is approximated with some loose tolerance by means of a projection method .",
    "the problem of approximating @xmath21 has seen a great interest growth in the past fifteen years , due to the emerging occurrence of this computation in many scientific and engineering applications ; see , e.g. , @xcite,@xcite,@xcite,@xcite,@xcite,@xcite,@xcite , and their references . for our purposes",
    "we shall use krylov subspace methods for approximating @xmath22 and @xmath21 at each iteration , equipped with a cheap stopping criterion that may also be adapted to the outer current accuracy .",
    "we shall show that the inexactness in the lanczos bidiagonalization causes the loss of the known symmetry structure of the process .",
    "nonetheless , as is the case in finite precision analysis @xcite , orthogonality of the basis can be preserved , so that the recurrence maintains its effectiveness .",
    "if a rough approximation to @xmath3 is the only quantity of interest , instead of a group of singular triplets , then other approaches could be considered .",
    "for instance , @xmath1 could be approximated by some other more convenient functions , and then the resulting matrix function norm could be more easily estimated . as an alternative ,",
    "equivalent definitions of @xmath2 could be used , from which the norm could also be estimated ; or , the relation of @xmath3 with other norms or with some other spectral tool could be used ; some of these approaches are briefly recalled in section [ sec : known_methods ] .",
    "methods in the mentioned classes , however , usually at most provide the order of magnitude of the actual norm and are thus inappropriate if more correct digits are needed .    this paper is organized as follows . section  [ sec : known_methods ] reviews some methods available for the approximation of @xmath3 . in section",
    "[ sec : lanczos bidiag ] the standard lanczos bidiagonalization is recalled and the general notation used in this paper is introduced .",
    "section  [ sec : inexact lanczos bidiag ] presents the inexact lanczos bidiagonalization procedure , including the details on the stopping criteria in section [ sec : comput_stop ] .",
    "section  [ sec : inner ] discusses the approximation of the matrix function multiplication , and a stopping criterion for its accuracy , while in section  [ sec : flex ] a stopping criterion in case an inner flexible strategy is analyzed . in section  [ sec : spectral properties ] we show how specific spectral properties allow us to make a variable accuracy for the inner iteration feasible , which is finalized in section  [ sec : variable ] .",
    "section  [ sec : practical implementation ] focuses on the practical implementation and the numerical results are presented in section  [ sec : expes ] .",
    "we will conclude with some discussion in section  [ sec : discussion ] .",
    "the following notation will be used throughout .",
    "the vector @xmath23 indicates the @xmath24th column of the identity matrix of a given dimension .",
    "the conjugate transpose of a matrix @xmath0 will be denoted by @xmath25 .",
    "we will use the matlab - like notation @xmath26 $ ] to denote the column vector @xmath27 the euclidean vector norm for vectors will be used , namely @xmath28 , for @xmath29 . unless explicitly stated , the induced matrix norm ( [ eqn:2norm ] ) will be used for matrices . for @xmath30 , spec(@xmath0 ) denotes the set of its eigenvalues , and @xmath31 is its field of values .",
    "while the lanczos bidiagonalization is widely recognized as the method of choice for approximating selected singular triplets of a large matrix , if one is only interested in estimates of @xmath32 with @xmath0 non - hermitian , then rather different procedures could also be used .",
    "a simple approach consists of roughly estimating @xmath33 by using some other matrix norm .",
    "for instance , @xmath34 where @xmath35 is once again an induced norm @xcite .",
    "this bound is usually pessimistic , and it is clearly unsatisfactory for @xmath36 large .",
    "the fact that for @xmath0 large the entries of @xmath2 are not all readily available provides an additional challenge .    in the following",
    "we describe a few approaches available in the literature that are tailored to the matrix function case .",
    "some of them first determine an explicit upper bound for the norm , which only depends on scalar quantities .",
    "the core computation will then be to determine a good approximation to the obtained upper bound .",
    "the quality of the final estimate of @xmath32 will thus depend both on the sharpness of the initial upper bound and on the accuracy of the computation .",
    "for general non - normal matrices the initial bound is often not very sharp , limiting the quality of the overall estimation .",
    "finally , a computation - oriented estimation is the power method , which directly approximates @xmath32 as the square root of the largest eigenvalue of @xmath37 .",
    "a more detailed list follows .    1 .",
    "let @xmath38 be the numerical radius of @xmath0 , that is @xmath39 , where @xmath40 is the field of values of @xmath0 .",
    "since ( see , e.g. , ( * ? ? ?",
    "* theorem 1.3 - 1 ) ) @xmath41 by applying the bounds to @xmath2 instead of @xmath0 , it is possible to estimate @xmath32 by means of @xmath42 ; see , e.g. , @xcite,@xcite for numerical methods to compute the numerical radius of a given matrix .",
    "a related special case is given by the exponential function , for which the bound @xmath43 holds , where @xmath44 is the largest eigenvalue of the hermitian part of @xmath0 , that is of @xmath45 @xcite .",
    "2 .   if it is possible to find @xmath46 and @xmath47 such that @xmath48 then it is sufficient to estimate @xmath49 ; here @xmath49 is the @xmath50-norm of @xmath1 on @xmath51 .",
    "this can be done for instance when @xmath1 is a polynomial , @xcite , for which @xmath52 is known to be less than 11.08 and conjectured to be equal to 2 , and @xmath51 coincides with the field of values of @xmath0 .",
    "we refer to the ph.d .",
    "thesis of d. choi @xcite , for a discussion on the use if this bound when @xmath0 is normal , or when @xmath0 is a contraction ; see also @xcite for a detailed analysis of this bound when using pseudospectral information .",
    "the computational intensive task is given by the determination of @xmath51 .",
    "if @xmath51 coincides with @xmath40 , then the cost of accurately approximating @xmath51 may be superior to that of approximating the single quantity @xmath32 .",
    "this approach is in the same spirit as the one above , but with a higher computational component . for @xmath53 ,",
    "let @xmath54 and assume that @xmath1 is analytic in @xmath55 .",
    "if @xmath56 denotes the length of the boundary @xmath57 , then by using the cauchy integral expression for @xmath2 we obtain ( see , e.g. , @xcite ) @xmath58 although the involved quantities may be easier to compute than in the previous case , the dependence on @xmath53 remains not fully controllable .",
    "4 .   using the relation @xmath59 a run of a few iterations of the power method can give an estimate to @xmath60 ; see , e.g. , ( * ? ? ?",
    "* algorithm 3.19 ) for an algorithm specifically designed for the largest singular triplet .",
    "the power method is probably the most appealing approach among the ones listed above .",
    "if a rough approximation is required , typically to determine the order of magnitude , then its low cost provides a satisfactory answer .",
    "however , if more than one digit of accuracy is required , then the process may become slow .",
    "as for with @xmath0 , the stability in the computation may be highly influenced by the squaring ; we refer to section [ sec : expes ] for an example of this well known phenomenon .",
    "we start by recalling the golub - kahan bidiagonalization process in our context , in terms of the matrix function @xmath2 ; then we will discuss how to actually obtain @xmath2 times a vector .",
    "let @xmath61 and @xmath62 , then for @xmath63 the following recurrence relations define the lanczos algorithm @xmath64 the coefficients @xmath65 are computed so that the corresponding vectors @xmath14 s and @xmath66 s have unit norm . by collecting the two sets of vectors",
    "as @xmath67 $ ] , @xmath68 $ ] , we observe that @xmath69 , @xmath70 , @xmath71 . moreover , the two recurrences can be compactly written as @xmath72 where @xmath73 is the following bidiagonal matrix @xmath74 it can be shown that the columns of @xmath75 span the krylov subspace @xmath76 and the columns of @xmath77 span the krylov subspace @xmath78 .",
    "define @xmath79 and @xmath80 then the recursion ( [ eqn : gk ] ) can be rewritten as a standard lanczos process , in the more compact matrix notation ( @xcite , ( * ? ? ?",
    "* , p.  495 ) ) @xmath81 for both even and odd @xmath82 , the eigenvalues of @xmath83 occur in @xmath84 pairs , with the exception of an extra extraneous zero eigenvalue in the odd case . within this setting ,",
    "is it thus possible to approximate the singular values of @xmath85 by the positive eigenvalues of @xmath86 , or , equivalently , by the singular values of @xmath87 . in particular , for the largest singular value it holds that ( see ( * ? ? ?",
    "* corollary @xmath88 , lemma @xmath89 ) ) : @xmath90 there are several advantages of the golub - kahan bidiagonalization over the simpler power method applied to @xmath37 , which are mainly related to the fact that the eigenvalue squaring in this latter problem may lead to severe loss of information in the case very small or very large singular values arise . in the inexact case",
    "the bidiagonal formulation also allows us to better trace the inexactness during the whole approximation process ; this is discussed in the next section .",
    "when neither the explicit computation of the matrix @xmath2 nor the accurate operation @xmath21 ( or @xmath91 ) are feasible , then approximate computations must be performed , resulting in an _ inexact _ lanczos bidiagonalization procedure . as a consequence ,",
    "the recurrence ( [ eqn : gk ] ) needs to be significantly revised so as to aknowledge for the quantities that are actually computed .    for a given @xmath14 ,",
    "the exact matrix - vector multiplication @xmath92 has to be replaced by an inner procedure that approximates the resulting vector up to a certain accuracy .",
    "the same holds for the operation @xmath22 for a given vector @xmath66 . for the sake of the analysis , at each iteration",
    "@xmath93 we shall formalize this difference by writing , for some matrices @xmath94 and @xmath95 , @xmath96 where @xmath97 implicitly represent the perturbation induced by the approximate computations .",
    "since in general @xmath98 is no longer the conjugate transpose of @xmath99 , orthogonality of a new vector @xmath100 has to be enforced by explicit orthogonalization with respect to all previous vectors @xmath101 , @xmath102 .",
    "the same holds for the vectors @xmath103 , @xmath104 .",
    "therefore , instead of one bidiagonal matrix @xmath73 in the exact relation , we now obtain an upper triangular matrix @xmath105 and an upper hessenberg matrix @xmath106 .",
    "this leads to the following relations for the inexact ( perturbed ) lanczos bidiagonalization : @xmath107 where @xmath108 and @xmath109 .",
    "the matrices @xmath75 and @xmath77 are different from the matrices in the exact relation , but they still have orthonormal columns",
    ".    the inexact lanczos bidiagonalization can also be described using the notation of ( [ eq : lbd with b 2 ] ) .",
    "define @xmath110 , \\qquad { \\mathcal{w}}_{2 m } = \\left [ \\begin{array}{cc } u_m & 0 \\\\ 0 & v_m \\end{array } \\right],\\ ] ] and the perturbation matrix @xmath111 the perturbed relation thus becomes @xmath112{\\mathbf e}_{m}^ * , \\quad { \\mathbf e}_m \\in\\mathbb{r}^{2m},\\ ] ] where @xmath113 in contrast to the exact case , the space spanned by the columns of @xmath114 is not a krylov subspace .",
    "however , when @xmath115 is small , this new space is close to an invariant subspace of the perturbed matrix @xmath116 , because then @xmath117 .",
    "notice the similarity of ( [ eq : inexact lbd k ] ) with equation ( 3.1 ) in @xcite , which shows that with this formulation , the inexact projection problem amounts to solving a structured eigenvalue problem , where the original hermitian matrix @xmath118 has been perturbed by a structured non - hermitian perturbation @xmath119 .",
    "the theory in @xcite can then be used to analyze and monitor the inexact computations , although the general results in @xcite should be carefully adapted to the new problem structure .",
    "if @xmath120 is small in norm , the eigenvalues of the _ non - hermitian _ matrix @xmath121 are small perturbations of the eigenvalues of the _ hermitian _ matrix @xmath118 .",
    "indeed , the eigenvalues of the perturbed matrix @xmath116 lie in discs with radius @xmath122 and center the ( real ) eigenvalues of @xmath118 ( see , e.g. , ( * ? ? ?",
    "* , theorem 5.1 ) ) .",
    "therefore , for small perturbations in the computations , the eigenvalues of the symmetric matrix @xmath118 will be perturbed accordingly . on the other hand , in the following we shall consider the case when @xmath123 is larger than usually allowed by a perturbation analysis argument , therefore different strategies need to be devised to ensure good approximations to the wanted eigenvalues of @xmath118 .    following the standard procedure of the exact case , we should consider the matrix @xmath124 to approximate the largest eigenpairs of @xmath116 , and according to the discussion above , of @xmath118 . due to the non - hermitian structure of @xmath124 , however , there are different matrices that can provide the sought after singular value information , namely the matrix @xmath124 itself , and the two distinct matrices @xmath106 or @xmath105 .",
    "the last two matrices yield approximations to the corresponding triplets of @xmath125 and @xmath126 .",
    "the following bound between the largest eigenvalue of @xmath127 and the largest singular values of @xmath106 and @xmath105 shows that all these quantities can be easily related .",
    "let @xmath128 $ ] .",
    "using @xmath129 we obtain . ]",
    "@xmath130\\neq 0 } \\left|\\frac{{\\mathbf x}^*m_m{\\mathbf y}+ { \\mathbf y}^*t_m{\\mathbf x}}{{\\mathbf x}^*{\\mathbf x}+ { \\mathbf y}^*{\\mathbf y}}\\right|\\\\                    & \\le &   \\displaystyle\\max_{[{\\mathbf x};{\\mathbf y}]\\neq 0}\\frac{\\|{\\mathbf x}\\|\\|m_m{\\mathbf y}\\|}{\\|{\\mathbf x}\\|^2 + \\|{\\mathbf y}\\|^2 } +   \\max_{[{\\mathbf x};{\\mathbf y}]\\neq 0}\\frac{\\|{\\mathbf y}\\|\\|t_m{\\mathbf x}\\|}{\\|{\\mathbf x}\\|^2 + \\|{\\mathbf y}\\|^2}\\le",
    "\\frac{1}{2}(\\sigma_1(m_m ) + \\sigma_1(t_m)).\\end{aligned}\\ ] ] if the inexactness of the bidiagonalization is very large , @xmath105 and @xmath131 are very different from each other . in this case , the leading singular values of these two matrices - and thus their mean - may be significantly larger than the biggest ( in modulo ) eigenvalue of @xmath124 , since they are related to the numerical radius of @xmath124 , rather than to its spectrum .",
    "this motivated us to use the eigenvalues of @xmath124 in the approximation , rather than the singular values of its blocks .",
    "moreover , working with @xmath124 made the analysis of the relaxed strategy particularly convenient , since known results on relaxed eigenvalue computation could be exploited .      in this section",
    "we analyze a strategy for monitoring the convergence of the inexact bidiagonal iteration .",
    "as it is common to other inexact processes , the true problem residual is inaccessible as soon as inexactness takes place .",
    "however , on the one hand some stopping criterion needs to be introduced to exit the process . on the other hand ,",
    "it is unclear whether the computed approximations are still meaningful for the original problem , since they were computed with significantly modified data .",
    "let @xmath132 be an eigenpair of @xmath124 , where @xmath133 is a unit vector .",
    "as the iterations proceed , @xmath134 tends to approximate an eigenpair of @xmath127 .",
    "we would like to ensure that @xmath134 also tends to an eigenpair of @xmath118 . to monitor the convergence of @xmath135 and to define a stopping criterion for the outer iteration , the residual is used .",
    "we call @xmath136 the _ true residual _ , which is not available , since @xmath118 can not be applied exactly .",
    "we thus introduce the _ computed residual _ , which is the residual of the actually computed quantities , namely ( see ( [ eq : inexact lbd k ] ) ) @xmath137 in the sequel , we shall use the following obvious inequality to estimate the true residual norm : @xmath138 where @xmath139 is the gap between the computed and the true residuals , in short the `` residual gap '' .",
    "if this gap can be imposed to be small , then the computed residual will give an estimate for the true residual .",
    "in this case , convergence can be monitored by only using the ( available ) computed residual , and the following relative stopping criterion can be used : @xmath140 for some outer tolerance @xmath141 , where @xmath135 is the largest ( in modulo ) eigenvalue . finally , as the computed residual norm goes to zero , the quantity @xmath139 will tend to dominate again , playing the role of the final attainable accuracy level .    to see how we can impose the residual gap to be small , and recalling the definition of @xmath142 , we first consider a more convenient expression for @xmath143 , with @xmath144 $ ] , that is @xmath145 let @xmath146 $ ] .",
    "then @xmath147 , @xmath148 , implicitly carry the error caused by the inexact computation of @xmath149 and @xmath150 , respectively , in the inner iteration . if every term of this sum is small , the computed residual will be close to the true residual .",
    "the following lemma states how the inaccuracy in the matrix - vector products relates to the residual gap ; its proof is based on the corresponding result in @xcite , however the structure is exploited so as to have a dependence with respect to @xmath151 instead of @xmath152 , the size of @xmath153 .",
    "[ lemma : res bound ] assume that @xmath151 iterations of the inexact lanczos bidiagonalization process have been taken .",
    "if @xmath154 for @xmath155 , then @xmath156 .    _ proof . _ from @xmath157 with @xmath158 $ ] it follows that @xmath159\\|\\le 1 $ ] . from ( [ eqn : g ] ) we obtain @xmath160 this result shows that if @xmath161 is sufficiently small , then the residual gap will stay below the computed residual norm until convergence . in our experiments",
    ", @xmath151 will play the role of the maximum number of lanczos bidiagonalization iterations , which is usually set to a number between @xmath162 and @xmath163 .",
    "the performance of the inexact lanczos bidiagonalization process depends on the approximation accuracy of the matrix - vector products @xmath149 and @xmath150 . due to the size of @xmath0",
    ", we consider approximating this quantity by means of a projection - type iterative method as follows ; we limit our discussion to @xmath149 , and a corresponding procedure can be used for @xmath150 .",
    "starting with the unit vector @xmath14 and the matrix @xmath0 , we construct a sequence of approximation subspaces @xmath164 of @xmath165 , @xmath166 and define the matrix @xmath167 \\in{\\mathbb c}^{n\\times k}$ ] , whose orthonormal columns span the subspace , and @xmath168 , in a way so that the spaces are nested , that is @xmath169 .",
    "typical such choices are krylov and rational krylov subspaces @xcite,@xcite .",
    "the desired approximation is then obtained as @xmath170 for small @xmath93 , the reduced non - hermitian matrix @xmath171 has small size , so that @xmath172 can be computed efficiently by decomposition - type methods @xcite .",
    "our stopping criterion of this approximation process is based on an estimation of the error norm , and it uses an approach previously introduced in ( * ? ? ?",
    "* proposition  2.2 ) .",
    "* proposition 2.2 ) assume that @xmath173 inner iterations have been executed .",
    "let @xmath174 be an approximation to @xmath149 and define @xmath175 .",
    "if @xmath176 and @xmath177 , then @xmath178    the result in ( [ eqn : error_estimate ] ) shows that after @xmath173 iterations it is possible to provide an estimate of the error norm at iteration @xmath93 .",
    "therefore , we introduce the following stopping criterion for the approximation of @xmath92 : @xmath179 for some inner tolerance @xmath180 . the accuracy of the inner iteration will influence the final accuracy of the inexact lanczos bidiagonalization . in the notation of the previous section ,",
    "once the stopping criterion is satisfied , we have thus derived the following estimate for the perturbation occurring in the lanczos step , @xmath181 note that here @xmath182 , with the notation in ( [ eqn : g ] ) .",
    "an analogous relation holds with respect to @xmath183 and thus @xmath184 .",
    "we stress here that , since the approximation process changes at each iteration , the quantity @xmath185 will vary as the lanczos bidiagonalization proceeds . the threshold itself may vary during the lanczos iteration , so that @xmath186 .",
    "as experienced with other eigenvalue and linear system problems , @xmath187 may even be allowed to grow during the iteration , without significantly affecting the overall process .",
    "this is discussed in the next section .",
    "the bound in ( [ eqn : g ] ) on the residual gap suggests that the accuracy on the inner solution approximation can be relaxed as convergence takes place .",
    "indeed , following similar strategies in @xcite,@xcite,@xcite , we observe that it is the product @xmath188 in ( [ eqn : g ] ) that needs to be small , and not each factor , to ensure a small gap ; the same for @xmath189 .",
    "therefore , if @xmath190 is sufficiently small , indicating that the @xmath191th component of the eigenvector @xmath133 is small , @xmath192 is allowed to be larger , and the required accuracy of @xmath161 can still be achieved .",
    "this induces a variable ( possibly growing ) accuracy in the inner iteration , which drives the size of @xmath192 . in the following",
    "we shall first show that the quantities @xmath190 and @xmath193 do tend to decrease as the approximation improves .",
    "we then derive a computable expression for the variable stopping tolerance in the approximation of @xmath21 and @xmath22 at each iteration of the resulting `` relaxed '' lanczos bidiagonalization process .",
    "this strategy may be convenient in case the cost approximating @xmath21 and @xmath22 is very high , as is the case for instance if an accurate approximation to the leading singular triplets is requested .      to ensure that the magnitude of @xmath194 , @xmath195 , can be relaxed in the bound ( [ eqn : g ] ) , we need to verify that @xmath193 and @xmath190 become small as convergence takes place .",
    "this fact has been verified in the eigenvalue setting in @xcite , however the peculiar structure of the lanczos bidiagonal recurrence requires the validation of the results in @xcite . to this end",
    ", we first define the submatrix of @xmath124 of size @xmath196 as @xmath197 where @xmath198 , @xmath199 are the leading portions of the corresponding @xmath200 matrices .",
    "let @xmath201 be an eigenpair of @xmath202 , where @xmath203 $ ] has unit norm , and @xmath204 .",
    "further , let @xmath205 where the @xmath206-vectors have length @xmath207 , and define @xmath208 $ ] , where @xmath209 is chosen such that @xmath210 is unitary .",
    "define @xmath211 .",
    "the following result shows that under certain hypotheses some of the components of the approximate eigenvectors do tend to zero as convergence takes place .",
    "its proof is analogous to that of ( * ? ? ?",
    "2.2 ) , and can be found in the appendix .",
    "[ prop : tau ] let @xmath212 be an eigenpair of @xmath202 , and @xmath213 be as defined in _ ( [ eq : q tilde])_. let @xmath214 , @xmath215 , and @xmath216{\\mathbf e}_k^*{\\mathbf q}^{(2k)}$ ] . if @xmath217 then there exists a unit norm eigenvector @xmath218 $ ] of @xmath124 with @xmath219 , @xmath220 , such that @xmath221 with @xmath222 , @xmath223 .",
    "moreover , if @xmath135 is the eigenvalue associated with @xmath133 , we have @xmath224 iterations of lanczos bidiagonalization the computed residual @xmath225 is sufficiently small , then there exists an eigenvector of @xmath124 such that some of its components are bounded correspondingly .",
    "these are precisely the components that allow us to relax the accuracy in the inner iteration .",
    "note that @xmath226 gives an indication of the distance between the spectrum of @xmath227 and @xmath228 .",
    "it should be kept in mind that for non - normal matrices , the value of @xmath226 may be much smaller ( * ? ? ?",
    "* example 2.4 , p. 234 ) .",
    "on the other hand , since @xmath229 is a perturbation to a hermitian matrix , the quantity @xmath230 is an approximate residual for @xmath201 as an eigenpair of @xmath229 , and thus it will be small as @xmath151 grows . as a consequence ,",
    "the condition in the theorem is likely to be satisfied , and the eigenvalue error ( [ eqn : thetas ] ) may be much smaller than @xmath231 .      in this section",
    "we show that relaxation in the inner accuracy at step @xmath232 is possible if there exists an eigenpair @xmath233 of @xmath234 such that @xmath235 the first condition ( [ restriction 1 ] ) ensures that there exists an eigenvector @xmath133 of @xmath153 whose specified components are small , according to proposition [ prop : tau ] .",
    "let @xmath135 be the eigenvalue associated with this @xmath133 .",
    "the second condition , ( [ restriction 2 ] ) , guarantees that the eigenvalue @xmath236 of @xmath234 is a perturbation of the eigenvalue @xmath135 of @xmath124 , which is the final approximation to the original problem .",
    "the following theorem states how the use of a variable accuracy will still guarantee a small residual gap , and hence yields a true residual with an accuracy which is bounded by the accuracy of the gap , in agreement with ( [ eq : true comp gap ] ) .",
    "assume @xmath151 inexact lanczos bidiagonalization iterations are carried out .",
    "let @xmath132 be an eigenpair of @xmath124 , where @xmath135 is simple and @xmath237 .",
    "given @xmath238 , with the notation of ( [ eqn : g ] ) assume that for @xmath239 @xmath240 then @xmath241 .",
    "_ this proof is analogous to the proof of theorem 3.1 in @xcite .",
    "suppose that at the @xmath242th iteration there exists an eigenpair @xmath233 of @xmath234 satisfying the conditions @xmath243 and @xmath244 .",
    "this implies that @xmath236 is a perturbation of the considered eigenvalue @xmath135 of @xmath124 , since @xmath135 is the only eigenvalue of @xmath124 such that @xmath245 let @xmath246 be defined such that for each @xmath247 there exists a eigenpair @xmath248 of @xmath234 satisfying the conditions @xmath243 and @xmath244 .",
    "then , similar to the reasoning in the proof of lemma [ lemma : res bound ] and using ( [ eqn : g ] ) , @xmath249    [ algorithm1 ]    height 0pt depth 0.5pt width + * algorithm 1 : * inexact lanczos bidiagonalization + height 0pt depth 0.3pt width + * input : * @xmath30 non - hermitian , a function @xmath1 , a maximum number of ( outer ) iterations @xmath151 , an ( outer ) tolerance @xmath141 . + * output : * an approximation to the leading singular triplet + height 0pt depth 0.3pt width +    [ cols= \" > , < \" , ]",
    "we have explored the use of an inexact lanczos bidiagonalization method for approximating the leading singular triplet of a large matrix function , and in particular its 2-norm .",
    "although several strategies are known to provide rough estimates of a matrix function 2-norm , more accurate approximations require a careful implementation of available approaches , since neither @xmath2 nor products of the type @xmath21 are available exactly .",
    "in particular , we showed that the lanczos bidiagonalization yields a non - hermitian perturbation of the original hermitian matrix , and the recurrence needs to be revisited .",
    "our numerical experiments showed that the computational complexity may vary significantly depending on the requested final accuracy , since the two inner iterations for the approximation of @xmath21 and @xmath22 may be very time and memory consuming .",
    "we showed that the relaxed strategy alleviates this problem whenever accurate approximations are required .",
    "however , for particular selections of matrices and functions , the approximation of @xmath21 can still be very expensive , and some other strategies could be exploited , such as restarting ; see , e.g. , @xcite,@xcite,@xcite and references therein .",
    "finally , our approach could be used to estimate the norm of other matrix objects , such as the geometric mean @xcite , or the _ derivatives _ of matrix functions , such as the frchet derivative of the matrix exponential or of other functions @xcite .    10    , _ norm estimates for inverses of toeplitz distance matrices _ ,",
    "j. approximation theory , 79 ( 1994 ) , pp .",
    "222242 .    ,",
    "_ decay properties of spectral projectors with applications to electronic structure _ , siam review , 55 ( 2013 ) , pp .  364 .    , _ norm inequalities related to the matrix geometric mean _ , lin . alg .",
    "appl . , 437 ( 2012 ) , pp .",
    "726733 .    , _ inexact matrix - vector products in krylov methods for solving linear systems : a relaxation strategy _ , siam j. matrix analysis and appl .",
    ", 26 ( 2005 ) , pp .",
    "660  678 .    , _ estimating norms of matrix functions using numerical ranges _ , phd thesis , university of washington , 2013 .",
    ", _ numerical range and functional calculus in hilbert space _ ,",
    "j.  functional analysis , 244 ( 2007 ) , pp .",
    "668690 .    , _ lanczos algorithms for large symmetric eigenvalue computations : vol . 1 : theory _ , vol .  41 , siam , 2002 .    ,",
    "_ extended krylov subspaces : approximation of the matrix square root and related functions _ , siam j. matrix anal .",
    "appl . , 19 ( 1998 ) , pp .  755771",
    ".    , _ solution of large scale evolutionary problems using rational krylov subspaces with optimized shifts _ , tech .",
    "rep .  5 , 2009 .    ,",
    "_ a restarted krylov subspace method for the evaluation of matrix functions _ , siam j. numer .",
    ", 44 ( 2006 ) , pp .  24812504 .    , _ convergence of restarted krylov subspace methods for stieltjes functions of matrices _ , siam j. matrix anal .",
    "appl , ( 2014 ) .    , _ matrix functions _ , tech .",
    "rep . , dipartimento di matematica , bologna , i , march 2006 . to appear on siam j. scient .",
    "computing .",
    ", _ numerical solution of ordinary differential equations : is there anything left to do ? _ , siam rev .",
    ", 23 ( 1981 ) , pp .  1024 .    ,",
    "_ perturbation of functions of diagonalizable matrices _ , electronic j. of linear algebra , 20 ( 2010 ) , pp .",
    "303313 .    , _ matrix computations _ , the john hopkins university press , baltimore , london , 3rd  ed . , 1996 .    , _ numerical range : the field of values of linear operators and matrices _ , universitext , springer , new york , ny , usa , 1997 .    , _ rational krylov approximation of matrix functions : numerical methods and optimal pole selection _ , gamm mitteilungen , 36 ( 2013 ) , pp",
    "831 .    , _ estimating the condition number of the frechet derivative of a matrix function _ , siam j. sci .",
    "comput . , ( 2014 ) .    ,",
    "_ matrix functions  theory and applications _ , siam , philadelphia , usa , 2008 .    , _ exponential integrators for quantum - classical molecular dynamics _ , bit , numerical mathematics , 39 ( 1999 ) , pp .  620645 .    , _ exponential integrators _ , acta numerica , 19 ( 2010 ) , pp",
    ".  209286 .    ,",
    "_ topics in matrix analysis _ , cambridge university press , cambridge , 1991 .    height 2pt depth -1.6pt width 23pt , _ matrix analysis _ , cambridge university press , cambridge , ii  ed . , 2013 .    ,",
    "_ on the condition number and perturbation of matrix functions for hermitian matrices_. arxiv:1206.1762v1 , june 2012 .    ,",
    "_ a new investigation of the extended krylov subspace method for matrix function evaluations _ , numerical linear algebra with applications , 17 ( 2010 ) , pp .",
    "615638 .    ,",
    "_ lanczos bidiagonalization with partial reorthogonalization _ , tech .",
    "daimi pb-357 , department of computer science , aarhus university , 1998 .    ,",
    "_ a visual repository of test data for use in comparative studies of algorithms for numerical linear algebra , mathematical and computational sciences division , national institute of standards and technology_. online at http://math.nist.gov/matrixmarket .    ,",
    "algorithms for the computation of the pseudospectral radius and the numerical radius of a matrix _ , i m a j. num . an . , 25 ( 2005 ) , pp .  648669 .    , _ controlling errors in recursive fermi - dirac operator expansions with applications in electronic structure theory _ , siam j. sci .",
    ", 34 ( 2012 ) , pp .",
    "b1b23 .    , _ norm bounds for rational matrix functions _ , numerische mathematik , 42 ( 1983 ) , pp .",
    "379389 .    , _ variable accuracy of matrix - vector products in projection methods for eigencomputation _ , siam j. numer .",
    ", 43 ( 2005 ) , pp .",
    "11551174 .    , _ theory of inexact krylov subspace methods and applications to scientific computing _",
    ", siam j. sci .",
    ", 25 ( 2003 ) , pp .",
    "454477 .    ,",
    "_ matrix perturbation theory _ , computer science and scientific computing , academic press inc . , boston , ma , ( 1990 )",
    ", _ spectra and pseudospectra . the behavior of non - normal matrices and operators _ , princeton university press , 2005 .    , _ computing the numerical radius _ , lin .",
    ". appl . , 234 ( 1996 ) ,",
    "define the submatrix of @xmath124 of size @xmath196 as @xmath250 define the vector @xmath251 $ ] , where the @xmath206-vectors have length @xmath207 .",
    "let @xmath252 $ ] be such that @xmath210 is unitary , where @xmath253 $ ] .",
    "this implies that @xmath254 , @xmath255 and @xmath256 .",
    "now , write @xmath257 here @xmath258 further , since @xmath259 , we have @xmath260 now , by ( * ? ? ?",
    "* theorem 2.1 , p.230 ) , @xmath261 then there exists a vector @xmath262 satisfying @xmath263 , such that the unit norm vector @xmath264 is an eigenvector of @xmath124 .",
    "moreover , @xmath265 further , this same theorem states that @xmath266 ."
  ],
  "abstract_text": [
    "<S> given a large square matrix @xmath0 and a sufficiently regular function @xmath1 so that @xmath2 is well defined , we are interested in the approximation of the leading singular values and corresponding singular vectors of @xmath2 , and in particular of @xmath3 , where @xmath4 is the matrix norm induced by the euclidean vector norm . </S>",
    "<S> since neither @xmath2 nor @xmath5 can be computed exactly , we introduce and analyze an _ inexact _ golub - kahan - lanczos bidiagonalization procedure , where the inexactness is related to the inaccuracy of the operations @xmath5 , @xmath6 . </S>",
    "<S> particular outer and inner stopping criteria are devised so as to cope with the lack of a true residual . </S>",
    "<S> numerical experiments with the new algorithm on typical application problems are reported . </S>"
  ]
}