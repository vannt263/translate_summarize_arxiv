{
  "article_text": [
    "a lead - lag effect is a phenomenon where one asset ( called a `` leader '' ) is correlated with another asset ( called a `` lagger '' ) at later times .",
    "investigation of such a phenomenon has a long history in the economics literature ; it is measured at various time scales mostly dailies or longer than daily , but relatively less for intra - daily data .",
    "it is not surprising that different lead - lag effects can be observed at different time scales in the financial markets , for there are a variety of participants in financial markets : they have different views for the economy and markets , different risk attitudes , with different sources of money and information , which makes them have different investment / trading horizons ( cf .",
    "the aim of this paper is to capture such multi - scale structures of lead - lag effects inherent in high - frequency financial data .",
    "the wavelet analysis provides a canonical framework to accomplish this purpose .",
    "the application of the wavelet analysis to finance has recently been expanded in various ways .",
    "we refer to the book @xcite for an introduction of such applications .",
    "the application of the wavelet analysis to investigating lead - lag relationships in the financial markets has also been investigated by many researchers _ with middle or low - frequency data _ ; see @xcite as well as chapter 7 of @xcite for example . on the other hand , there are few articles applying it to the investigation of lead - lag effects in the high - frequency domain .",
    "one exception is the paper by @xcite , which explores the lead - lag relation between the returns , durations and volumes of high - frequency transaction data of the ibm .    to our knowledge ,",
    "all the existing studies on the wavelet analysis of lead - lag effects have their theoretical basis on discrete - time process modeling , which is mainly pioneered in @xcite and @xcite .",
    "this is presumably because few results are available for statistical modeling of lead - lag effects in discretely observed continuous - time processes , even without taking their multi - scale structure into account . in the meantime , the modern , continuous - time finance theory is based on semimartingale processes , especially driven by brownian motions ( cf .",
    "also , it has been getting recognized that modeling high - frequency financial data as discrete observations of continuous - time processes is quite effective for the statistical analysis ( cf .",
    "@xcite ) . from these perspectives",
    "it is desirable to develop a class of multivariate models to incorporate lead - lag relationships between coordinates for brownian motion driven models , which is the primary goal of this study .",
    "we shall remark that some authors have recently developed statistical modeling of lead - lag effects in the continuous - time framework .",
    "@xcite have introduced a simple model to describe lead - lag effects between two continuous it semimartingales and developed a statistical estimation method for the lead - lag effects from ( possibly asynchronous ) discrete observation data .",
    "a similar model is studied in @xcite with different methodology .",
    "empirical applications of @xcite s methodology are found in @xcite .",
    "apart from brownian motion driven models , the hawkes processes would be a credible candidate to describe lead - lag effects in the continuous - time framework ; see @xcite and @xcite for example . however , none of them takes account of potential multi - scale structure of lead - lag effects .",
    "this paper attempts to fill in this gap .",
    "based on the proposed continuous - time model , we also aim at developing a statistical theory for the scale - by - scale analysis of lead - lag effects from discrete observation data .",
    "our paper is virtually the first attempt to bridge the gap between the two distinct areas of research , namely wavelet analysis and continuous - time stochastic processes .",
    "the paper is organized as follows .",
    "section [ section : model ] presents two frameworks for scale - by - scale modeling of lead - lag effects between two brownian motions .",
    "section [ theory ] develops an asymptotic theory for the framework presented in section [ section : model ] .",
    "we illustrate the numerical performance of the proposed approach on simulated data in sections [ simulation ] and on real data in section [ empirical ] , respectively .",
    "most of the proofs are given in section [ proofs ] .",
    "for any function @xmath0 , we denote by @xmath1 and @xmath2 its fourier transform and inverse fourier transform , respectively . specifically , they are defined by the following formulae : @xmath3 the above definition can also be applied to a function @xmath4 by understanding that the convergences of the integrals take in @xmath5 .",
    "the fourier inversion formula then reads @xmath6 for all @xmath4 . also , the parseval identity and the convolution theorem read @xmath7 and @xmath8 for all @xmath9",
    "in this section we propose two frameworks to introduce multiple lead - lag relationships between two brownian motions @xmath10 and @xmath11 on a scale - by - scale basis .",
    "we also present sensible cross - covariance estimators constructed from discrete observations of the processes @xmath10 and @xmath11 on a fixed interval , which can be used for identifying lead - lag effects scale - by - scale . specifically",
    ", we assume that @xmath12 is observed at the time points @xmath13 for @xmath14 . here , the unit time @xmath15 corresponds to the finest observable resolution , while @xmath16 is the number of the unit times contained in the sampling period .",
    "so , the interval @xmath17 $ ] corresponds to the sampling period .",
    "we take @xmath18 to make the interpretation of wavelet analysis easier .",
    "we denote by @xmath19 the probability space where @xmath20 is defined .",
    "we first revisit the classical lvy - ciesielski construction of brownian motion ( see @xcite for a review on this topic ) . for each @xmath21 ,",
    "let @xmath22 be a standard normal variable .",
    "also , let @xmath23 be i.i.d .",
    "standard normal variables independent of @xmath22 .",
    "then we define the process @xmath24}$ ] by @xmath25 where @xmath26 s are the haar functions defined by @xmath27 , where @xmath28 it is well - known that the infinite sum in the right side of has the limit in @xmath29 $ ] a.s .  as the function of @xmath30 $ ] , and",
    "the limit process @xmath31 is a standard brownian motion .",
    "the convergence is also valid in @xmath32 for any @xmath30 $ ] .",
    "decomposition naturally suggests that we could think that the process @xmath33 as a `` brownian component at the level @xmath34 '' . here",
    ", the level @xmath34 has the unit resolution @xmath35 .",
    "this suggests that we could assess the lead - lag effect at the resolution @xmath36 by measuring that between @xmath37 and @xmath38 in some sense .",
    "a standard way to measure the lead - lag effect between two processes is assessing the cross - covariance function of their returns , provided that they are jointly stationary .",
    "however , this approach can not be applied to the processes @xmath37 and @xmath38 directly because they are not of stationary increments .",
    "instead , we propose assessing the cross - covariance function between @xmath39 and @xmath40 , provided that their joint ( weak ) stationarity .",
    "specifically , the objectives are given by @xmath41 here , we write the cross - covariance between @xmath42 and @xmath43 with respect to the lag @xmath44 instead of @xmath45 alone to emphasize that their physical time difference is @xmath44 .",
    "since we can reproduce @xmath46 s for @xmath47 via the identity @xmath48 we can naturally use the following estimator for @xmath49 : @xmath50 where @xmath51 .",
    "this class of estimators has an advantage in terms of computation , for the variables @xmath52 are known as the _ discrete wavelet transform _ ( dwt ) of @xmath53 ( ignoring the boundary variables ) and fast computation algorithms for them are known ( `` pyramid algorithm '' , cf",
    ".  section 7.3.1 of @xcite ) . on the other hand ,",
    "the main disadvantage of this approach is that we can only evaluate the cross - covariance function at a lag of the form @xmath54 for some @xmath55 and @xmath47 , which causes undesirable restriction on lead - lag analyses . in the next subsection",
    "we propose another framework to deal with this issue .",
    "0    * * * @xmath56 only contains the information from @xmath37 and @xmath38 ( brownian components at the level @xmath34 ) . *",
    "* the variables @xmath52 are known as the _ discrete wavelet transform _",
    "( dwt ) of @xmath53 ( ignoring the boundary variables ) and fast computation algorithms for them are known ( `` pyramid algorithm '' , cf .",
    "section 7.3.1 of @xcite ) * * * we can only evaluate cross - covariances at a lag of the form @xmath54 for some @xmath55 and @xmath47 .",
    "the major drawback of the first approach is that we can not define the cross - covariance at all the discrete grid points generated for the finest observation resolution @xmath15 . to overcome this issue",
    ", we introduce an alternative decomposition to .",
    "for this purpose we reinterpret the lvy - ciesielski construction of brownian motion as follows .",
    "since @xmath57 and @xmath26 ( @xmath58 ) constitute an orthonormal basis of @xmath59 $ ] , we have the following expansion for any @xmath60 $ ] : @xmath61,\\ ] ] where @xmath62 denotes the inner product of @xmath59 $ ] .",
    "this implies that @xmath63 for @xmath21 . substituting @xmath64}$ ] in the above equation ,",
    "we recover the lvy - ciesielski construction with @xmath65 and @xmath66 .",
    "this suggests that we could obtain a decomposition of brownian motion analogous to the lvy - ciesielski construction once we have a `` canonical '' decomposition for any @xmath60 $ ] such as .",
    "motivated by this idea , we consider alternative wavelet decomposition for functions which is suitable for our purpose .",
    "we begin by recalling that decomposition can be considered as a discretization of caldern s reproducing identity for @xmath4 ( cf .",
    "sections 3.13.2 of @xcite ) : @xmath67\\frac{1}{a^2}da\\quad\\text{in } l^2(\\mathbb{r}),\\ ] ] where @xmath68 denotes convolution and we set @xmath69 as well as we define the function @xmath70 , which is called the _ continuous wavelet transform _ of @xmath71 , by @xmath72 in fact , decomposition is obtained by discretizing formula in both the scale parameter @xmath73 and the shift parameter @xmath74 .",
    "now , what is unsuitable for us in is that we can only consider discretized time shifts of the forms @xmath44 ( @xmath55 )",
    ". a natural solution of this issue is to only discretize the scale parameter @xmath73 .",
    "this leads to the following expansion for @xmath4 : @xmath75 here , for any function @xmath76 on @xmath77 we define the functions @xmath78 and @xmath79 ( @xmath80 ) on @xmath77 by setting @xmath81 and @xmath82 for @xmath83 .",
    "note that @xmath84 .",
    "decomposition is indeed valid for any @xmath4 by theorem 5.11 from @xcite , for we can deduce @xmath85 from the proof of theorem 5.13 from @xcite .",
    "the corresponding lvy - ciesielski type construction is given as follows :    [ prop : dyadic ] let @xmath86 be a two - sided brownian motion .",
    "suppose that real - valued functions @xmath87",
    "satisfy @xmath88 .",
    "then we have @xmath89 for any @xmath83 , where @xmath90    a proof is given in section [ proof : dyadic ] .",
    "this decomposition suggests that we might think that the process @xmath91 as an alternative `` brownian component at the level @xmath34 '' .",
    "however , unlike the original lvy - ciesielski construction , we do not generally have the independence of brownian components across different levels , i.e.  the processes @xmath91 and @xmath92 are not independent for @xmath93 , especially when we adopt the haar wavelets as @xmath94 and @xmath95 .",
    "the lack of such independence makes it challenging to model / interpret lead - lag effects at different levels .",
    "we can avoid this issue by alternatively adopting band - limited wavelets ( i.e.  wavelets having compactly supported fourier transforms ) .",
    "specifically , we take the littlewood - paley wavelets as follows : @xmath96 we may regard the littlewood - paley wavelets as the `` representative '' band - limited wavelets because any band - limited function can be recovered from its discrete samples with interpolation based on the littlewood - paley scaling function @xmath97 , according to the shannon - whittaker sampling theorem ( cf .",
    "theorem 3.2 of @xcite ) .",
    "now , since we have @xmath98}(\\lambda),\\qquad ( \\mathcal{f}\\psi^{lp})(\\lambda)=1_{[-2\\pi,-\\pi)\\cup(\\pi,2\\pi]}(\\lambda),\\ ] ] condition is satisfied .",
    "moreover , for any @xmath99 and any @xmath100 , the parseval identity yields @xmath101 = \\int_{-\\infty}^\\infty\\psi^{lp}_j(s - u)\\psi^{lp}_{j'}(s - v)ds = \\frac{1}{2^{\\frac{j+j'}{2}+1}\\pi}\\int_{\\lambda_j\\cap\\lambda_{j ' } } e^{\\sqrt{-1}(u - v)\\lambda}d\\lambda,\\ ] ] where @xmath102,\\qquad j\\in\\mathbb{z}.\\ ] ] since @xmath103 if @xmath93 , we have the independence of brownian components across different levels because they are gaussian .",
    "now , analogously to the first approach , we measure the lead - lag effect at the level @xmath34 by assessing the cross - covariance function between the processes @xmath104 and @xmath105 . here",
    ", we note that @xmath106 and @xmath107 are jointly stationary if the process @xmath108 is of stationary increments , i.e.   @xmath109 = e\\left[\\left(b^1_{t_1}-b^1_{s_1}\\right)\\left(b^2_{t_2}-b^2_{s_2}\\right)\\right]\\ ] ] for any @xmath110 .",
    "as shown in the next subsection , the latter assumption is not restrictive .",
    "consequently , we propose assessing the cross - covariance function : @xmath111,\\qquad\\theta\\in\\mathbb{r},\\ ] ] provided their joint ( weak ) stationarity .",
    "the `` coefficients '' @xmath112 in decomposition are called the _ ( translation - invariant ) dyadic wavelet transform _ of @xmath71 in the wavelet literature ( cf .",
    "section 5.2 of @xcite ) . in conjunction with this terminology",
    ", the processes in might be called the dyadic wavelet transform of @xmath113 .",
    "applications of dyadic wavelet transform based decomposition are found in pattern recognition and denoising with translation - invariant thresholding estimators ; see chapter 6 and section 11.3.1 of @xcite .    0",
    "the advantages and the disadvantages of this approach are listed in the following :    * * * cross - covariances at _ any _ lags can be evaluated . *",
    "* * @xmath114 possibly contains the information from brownian components at different scales from @xmath34 because @xmath115 and @xmath116 are correlated for @xmath93 .",
    "* * it is computationally less efficient than the first estimator .      for ease of interpretation ,",
    "it is desirable that @xmath117 has the unique maximum at some @xmath118 for each @xmath34 .",
    "so we presuppose such a situation and introduce the following specification into our model .",
    "we first note that implies that @xmath119 has the spectral density @xmath120 , hence its spectrum is concentrated on @xmath121 .",
    "we also remark that if @xmath122 ( @xmath83 ) is a bivariate two - sided brownian motion with correlation parameter @xmath123 , then for any @xmath124 the process @xmath125 ( @xmath83 ) is of stationary increments and has the cross - spectral density @xmath126 , @xmath127 .",
    "motivated by these facts , let us suppose that the bivariate process @xmath108 is of stationary increments and its cross - spectral density is of the form @xmath128 with @xmath129 $ ] and @xmath118 for @xmath130 , @xmath131 .",
    "namely , the function @xmath132 , which is defined by @xmath133 satisfies 0 @xmath134=\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty\\frac{(e^{-\\sqrt{-1}\\lambda t}-1)(e^{\\sqrt{-1}\\lambda s}-1)}{\\lambda^2}f(\\lambda)d\\lambda\\ ] ] for any @xmath135 . note that implies that @xmath136=\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty(\\mathcal{f}u)(\\lambda)\\overline{(\\mathcal{f}v)(\\lambda)}f(\\lambda)d\\lambda\\ ] ] for any @xmath137 .",
    "therefore , noting that @xmath138 for @xmath139 , in this situation we have for each @xmath34 @xmath140}{2^j\\pi(\\theta-\\theta_j)}(2\\cos[2^{j}\\pi(\\theta-\\theta_j)]-1)\\end{aligned}\\ ] ] by the fourier inversion formula , hence @xmath117 has the unique maximum @xmath141 at @xmath142 as long as @xmath143 .",
    "now the question of matter is whether we can construct a bivariate process @xmath108 having the pre - described properties such that both @xmath144 and @xmath145 are respectively one - dimensional standard brownian motions .",
    "the following proposition gives an affirmative answer :    [ characterization ] suppose that a measurable function @xmath132 satisfies @xmath146 and @xmath147 then there is a bivariate gaussian process @xmath108 ( @xmath83 ) with stationary increments such that    1 .",
    "both @xmath144 and @xmath145 are two - sided brownian motions , 2 .",
    "@xmath71 is the cross - spectral density of @xmath20 , i.e.  @xmath71 satisfies for any @xmath135 .",
    "conversely , if a bivariate process @xmath108 ( @xmath83 ) with stationary increments satisfies condition ( i ) , there is a measurable function @xmath132 satisfying  and condition ( ii ) .",
    "we prove this result in section [ proof : characterization ] .    in the next section",
    "we will consider an asymptotic theory when the unit length @xmath15 shrinks to zero , or equivalently , when @xmath148 tends to infinity , which is a standard approach for theoretical analyses of statistics for high - frequency data ( cf .",
    "in such a situation it is convenient to relabel indices of the parameters @xmath149 and @xmath150 so that the finest resolution @xmath15 corresponds to the level @xmath151 .",
    "this suggests that we should model the cross - spectral density of @xmath108 as @xmath152 where we set @xmath153 . here",
    ", we omit all the components finer than @xmath15 from the model because they are not identifiable .      if continuous - time observation data of the process @xmath154 on the whole real line were available , we could reproduce @xmath155 s via @xmath156 for @xmath21 and construct estimators for @xmath157 as in section [ section : levy ] . since we only have discrete observation data of @xmath154 on @xmath17 $ ]",
    ", one natural way is to approximate the above integral by discretization .",
    "this is however problematic because discretization of @xmath158 is unstable due to oscillation and @xmath158 is not compactly supported . for these reasons",
    "we adopt another approach that using daubechies compactly supported wavelets .",
    "daubechies wavelets generate finite - length filters whose gain functions well approximate those of the littlewood - paley wavelets ( cf .",
    "@xcite ) .",
    "specifically , we denote by @xmath159 daubechies wavelet filter of length @xmath160 .",
    "its squared gain function @xmath161 is given by @xmath162 ( note that @xmath160 is always an even integer ) .",
    "the associated scaling filter @xmath163 is determined by the quadrature mirror relationship denotes the wavelet filter and @xmath164 denotes the scaling filter .",
    "note that many authors adopt the reverse usage : @xmath165 denotes the scaling filter and @xmath164 denotes the wavelet filter .",
    "see @xcite for instance . ] : @xmath166 hence its squared gain function @xmath167 satisfies @xmath168 see chapters 68 of @xcite and section 3.4.5 of @xcite for more details",
    ".    using the filters @xmath163 and @xmath159 as low - pass and high - pass filters , we can construct scale - by - scale band - pass filters .",
    "we denote by @xmath169 the level @xmath34 wavelet filters associated with the filters @xmath163 and @xmath159 for every @xmath34 , where @xmath170 .",
    "see section 2 of @xcite for the precise definition . for our analysis",
    "the form of its squared gain function @xmath171 is important , which is given by @xmath172 we also remark that the filter @xmath169 has unit energy @xmath173    now we approximates @xmath174 by @xmath175 for each @xmath21 .",
    "we remark that the transformation of @xmath53 in is the so - called _ maximal overlap discrete wavelet transform _ ( modwt ) up to multiplication of constants , and that the resulting @xmath176 s are the corresponding wavelet coefficients .",
    "see section 3 of @xcite and section 4.5 of @xcite for details .",
    "then we define the cross - covariance estimators at the level @xmath34 by @xmath177 in the next section we will show that these are asymptotically sensible cross - covariance estimators while both @xmath148 and @xmath160 tend to infinity with appropriate rates",
    ".    the above estimators are formally the same as the _ wavelet cross - covariance estimators _ used in discrete - time modeling framework up to multiplication of constants ( cf .",
    "section 7.4 of @xcite ) .",
    "therefore , the results presented in the next section ensure the validity of using such estimators in the continuous - time modeling framework proposed in this paper .",
    "0    if we were in a situation where the finite - dimensional distributions of @xmath178 do not depend on @xmath16 , asymptotic theories developed in @xcite and @xcite could be applied to our estimator @xmath179 .",
    "the situation considered here is the so - called infill asymptotics and different from the above one , i.e.  the finite - dimensional distributions of @xmath178 depend on @xmath16 .",
    "asymptotic theories under such a situation are rather different and we investigate this topic in the next section .",
    "this section presents an asymptotic theory for the estimators constructed in the previous section .",
    "we also generalize the setting therein .",
    "first we assume that @xmath180 as @xmath181 for some @xmath182 .",
    "this means that we observe data on a _ fixed _ interval ( e.g.  one day ) .",
    "next , @xmath12 ( @xmath83 ) denotes a bivariate gaussian process with stationary increments such that both @xmath144 and @xmath145 are respectively one - dimensional two - sided standard brownian motions and its cross - spectral density is given by .",
    "we denote by @xmath19 the probability space where the process @xmath20 is defined .",
    "now , we assume that for each @xmath21 we have a filtration @xmath183 such that the process @xmath184 is an @xmath185-brownian motion .",
    "then , the @xmath186-th log - price process @xmath187 is given by @xmath188 where @xmath189 is an @xmath185-adapted cdlg process ( hence the above stochastic integral is well - defined in the usual sense ) .",
    "we assume that the processes @xmath190 and @xmath191 are observed at time stamps of the form @xmath192 for some @xmath193 .",
    "unlike the previous section , we allow that observation data at some time points are missing .",
    "for each @xmath21 we denote by @xmath194 the indicator variable which is unity when @xmath195 is not observed at the time @xmath192 and zero otherwise .",
    "so the observation data for @xmath195 are given by @xmath196 .",
    "for simplicity we assume that the initial value @xmath197 is observed , i.e.  @xmath198 . to construct our estimators we create ( pseudo ) complete observation data at all the points @xmath192 s by use of the previous - tick interpolation scheme .",
    "then we construct our estimators based on this observation data as in the previous section . to derive the mathematical expression of the estimators constructed so , it is convenient to introduce @xcite s notation . for each @xmath21 , setting @xmath199 for @xmath200 , we can write the pseudo observed returns for @xmath195 based on the interpolated data as @xmath201 where @xmath202 .",
    "therefore , we have @xmath203 for @xmath131 and @xmath204 . the estimator @xmath205 is then constructed by . here ,",
    "for the construction of asymptotic results in a general form we additionally consider a functional version of @xmath205 .",
    "we define the process @xmath206 by @xmath207 for @xmath208 . if @xmath209 by convention . ]",
    "since we have @xmath210 , it is enough to investigate the asymptotic properties of @xmath211 .    regarding the mechanism of missing observations , we focus on the following simple situation as in @xcite ( known as _ missing completely at random _ ) :    1 .",
    "the observation for @xmath195 can be missing at each @xmath13 with probability @xmath212 for @xmath21 , 2 .   missing observations occur independently .",
    "under this situation , for each @xmath21 @xmath213 is a sequence of i.i.d .",
    "bernoulli variables with provabilities @xmath212 and @xmath214 of taking variables 1 and 0 . also , @xmath215 and @xmath216 are mutually independent .    to avoid boundary issues , we assume that the true lag parameters @xmath217 for all @xmath34 with some constant @xmath218 , and evaluate the cross - covariance function on the finite grid set @xmath219 for processes @xmath220 ( @xmath221 ) and a process @xmath222 , we write @xmath223 to express @xmath224 as @xmath181 for any @xmath225 .    [ theorem : main ] let @xmath226 be fixed .",
    "suppose that @xmath227 and @xmath228 as @xmath181 .",
    "let @xmath229 be a sequence of real numbers such that @xmath230 for every @xmath148 .    1 .",
    "if @xmath231 as @xmath181 , then @xmath232 as @xmath181 .",
    "2 .   if @xmath233 as @xmath181 for some @xmath234 ,",
    "then @xmath235 as @xmath181 , where @xmath236 and @xmath237    the proof of theorem [ theorem : main ] is given in section [ proof : theorem1 ] .    the first part of theorem [ theorem : main ] claims that our cross - covariance estimator @xmath238 is close to zero if @xmath239 is sufficiently far from the true lag parameter @xmath150 .",
    "the second part of the theorem claims that our cross - covariance estimator @xmath238 tends to the quantity @xmath149 multiplied by some ( random ) constant .",
    "this constant consists of four sources : @xmath240 comes from the presence of volatility .",
    "@xmath241 represents a discretization error caused by @xmath242 being replaced by @xmath243 s .",
    "@xmath244 is caused by previous - tick interpolation .",
    "@xmath245 comes from the bias due to the discrepancy between @xmath239 and @xmath150 .",
    "theorem [ theorem : main ] suggests that we could estimate the lag parameter @xmath150 by maximizing @xmath246 over the finite grid @xmath247 as in @xcite .",
    "consequently , we choose the random variable @xmath248 such that @xmath249 as an estimator for @xmath150 .",
    "[ hry ] let @xmath226 be fixed .",
    "suppose that @xmath227 and @xmath250 as @xmath181 for some @xmath251 .",
    "0 suppose also that there is a constant @xmath252 $ ] such that for any @xmath253 there is a constant @xmath254 such that @xmath255 \\leq c_a\\eta^{a\\gamma}\\ ] ] for any @xmath256 and @xmath257 .",
    "suppose also that both @xmath258 and @xmath259 almost surely have @xmath260-hlder continuous paths for some @xmath261 .",
    "then , if a sequence @xmath262 of positive numbers satisfies @xmath263 as @xmath181 , then @xmath264 as @xmath181 , provided that @xmath143 and @xmath265 a.s . in particular ,",
    "we have @xmath266 as @xmath181 .",
    "we prove theorem [ hry ] in section [ proof : hry ] .",
    "the hlder continuity assumption on the paths of the volatilities @xmath258 and @xmath259 is satisfied by a number of stochastic volatility models .",
    "in fact , it is satisfied if @xmath267 is a continuous it semimartingale ( with respect to the filtration @xmath185 ) for every @xmath21 .",
    "it is worth mentioning that the assumption is also satisfied by the so - called rough fractional stochastic volatility models introduced in @xcite which have pointed out the practicality of such models .",
    "theorem [ hry ] is a counterpart of theorem 1 from @xcite in our framework .",
    "our results are applicable for separating multiple lead - lag effects on a scale - by - scale basis . on the other hand ,",
    "the convergence rate is slower than the estimator of @xcite by the factor @xmath268 , which might be regarded as a cost to separate multiple lead - lag effects .",
    "0      in empirical applications returns of financial assets often contain exceptionally large variations , which are usually modeled as discontinuities of the paths , i.e.  jumps .",
    "such jumps are quite harmful for lead - lag analyses . for examples , returns of mutually independent poisson processes are cross - correlated once they are realized .",
    "a simple solution to handle this issue is to eliminate jumps from returns by setting some threshold value .",
    "such a thresholding technique has extensively been studied in the literature of statistics for high - frequency data ; see @xcite and @xcite for example .",
    "specifically , let us consider the following model : @xmath269 here , @xmath270 is a positive constant , @xmath271 is a point process and @xmath272 is a sequence of non - zero random variables .",
    "we eliminate all returns such that @xmath273 where @xmath274 is a positive number denoting the threshold value for the @xmath186-th process .",
    "the problem is how to select this threshold value .",
    "although several sophisticated approaches have been proposed in the literature ( e.g.  @xcite , @xcite , @xcite ) , we here adopt the following heuristic idea for brevity .",
    "let us recall that the following classical result on the asymptotic behavior of the maximum of standard normal variables ( cf .",
    "@xcite ) : @xmath275 this motivates us to take the following threshold value : @xmath276 where @xmath277 is a robust estimator for the standard deviation of @xmath278 s .",
    "this type of threshold is known as the _ universal threshold _ in the literature , cf .",
    "consequently , we replace @xmath279 by @xmath280 and construct the subsequent estimators .",
    "in this section we implement a monte carlo experiment to evaluate finite sample performance of our scale - by - scale lead - lag parameter estimators @xmath281 s defined in the previous section .",
    "we set @xmath282 and @xmath283 .",
    "as the search grid @xmath247 , we use @xmath284    we simulate model with constant volatilities @xmath285 for @xmath21 . the parameters for the spectral density are chosen as in table [ parameters ] . to simulate the process @xmath20 at the time points @xmath192 , @xmath193 , it is enough to generate bivariate variables @xmath286 , @xmath193 .",
    "since they are stationary and gaussian , we can use the multivariate version of the circulant embedding method from @xcite once we compute the cross - covariance function @xmath287 $ ] , @xmath55 .",
    "it can be computed by using and the fourier inversion formula as @xmath288=\\sum_{j=0}^jr_{(j)}\\int_0^{\\tau_j}\\int_0^{\\tau_j}\\psi^{lp}(2^j(u - v+l\\tau_j-\\theta_{(j)}))dudv,\\quad l\\in\\mathbb{r},\\ ] ] hence we approximate it by @xmath289    l|*10c@xmath34 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 914 + @xmath149 & 0.3 & 0.5 & 0.7 & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 0 + @xmath290 & @xmath291 & @xmath291 & @xmath292 & @xmath292 & @xmath293 & @xmath294 & @xmath295 & @xmath296 & 0 +    regarding the parameters @xmath297 and @xmath298 which controls the probabilities of missing observations , we consider two situations where @xmath299 and @xmath300 . in the first situation",
    "no missing observation occurs , so the observation times are equidistant and synchronous . in the meantime , in the second situation the observation times are non - equidistant and asynchronous .    as the wavelet filter @xmath159 to construct our estimator , we examine the following three choices of daubechies wavelets :    1 .",
    "haar wavelets ( @xmath301 ) , 2 .",
    "least asymmetric wavelet with length @xmath302 , 3 .",
    "least asymmetric wavelet with length @xmath303 .",
    "see chapter 8 of @xcite for details on the least asymmetric wavelets .",
    "we run 1,000 monte carlo iterations for each experiment .",
    "we report the sample median and median absolute deviation ( mad ) of the estimates for each experiment in tables [ table : results ] . as the table reveals , at the finest resolution levels @xmath304 all the estimates are very precise , while at coarser resolution levels @xmath305 the la(8 ) and la(20 ) based estimators tend to perform better than the haar based estimators .",
    "this is not surprising because the consistency of our estimator is ensured in the asymptotics as @xmath160 tends to infinity .",
    "the la(20 ) based estimator shows an excellent performance at moderate resolution levels @xmath306 even in the presence of missing observations . at the coarsest resolution levels @xmath307 , the precisions of all the estimators fall",
    "this would be due to the following reason : according to the proofs of theorems [ theorem : main][hry ] , the convergence rate of our estimator @xmath281 is proportional to the square root of @xmath170 , hence it is declined as @xmath34 increases .",
    "l|*8c @xmath34 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 + true & -1 & -1 & -2 & -2 & -3 & -5 & -7 & -10 + & + haar & -1 & -1 & -1 & -1 & -1 & -1 & -2 & -2 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) + la(8 ) & -1 & -1 & -2 & -2 & -3 & -4 & -6 & -8 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 3 ) & ( 10 ) + la(20 ) & -1 & -1 & -2 & -2 & -3 & -5 & -6 & -9 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 4 ) & ( 15 ) + & + haar & -1 & -1 & -2 & -2 & -2 & -2 & -2 & -2 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) + la(8 ) & -1 & -1 & -2 & -2 & -3 & -4 & -6 & -8 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 3 ) & ( 10 ) +",
    "la(20 ) & -1 & -1 & -2 & -2 & -3 & -5 & -6 & -9 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 4 ) & ( 15 ) +     +    0    l|*8c @xmath34 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 + true & -1 & -1 & -2 & -2 & -3 & -5 & -7 & -10 + & + haar & -1 & -1 & -1 & -1 & -1 & -1 & -2 & -2 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) + la(8 ) & -1 & -1 & -2 & -2 & -3 & -4 & -6 & -8 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 3 ) & ( 9 ) + la(20 ) & -1 & -1 & -2 & -2 & -3 & -4 & -6 & -10 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 4 ) & ( 15 ) + & + haar & -1 & -1 & -2 & -2 & -2 & -2 & -2 & -2 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) + la(8 ) & -1 & -1 & -2 & -2 & -3 & -4 & -6 & -8 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 3 ) & ( 10 ) +",
    "la(20 ) & -1 & -1 & -2 & -2 & -3 & -5 & -6 & -9 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 4 ) & ( 16 ) +     +    0    l|*8c @xmath34 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 + true & -1 & -1 & -2 & -3 & -4 & -5 & -7 & -10 + & + haar & -1 & -1 & -1 & -1 & -2 & -2 & -2 & -2 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) + la(8 ) & -1 & -1 & -2 & -3 & -3 & -4 & -6 & -8 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 3 ) & ( 9 ) + la(20 ) & -1 & -1 & -2 & -3 & -4 & -5 & -6 & -10 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 4 ) & ( 15 ) + & + haar & -1 & -1 & -2 & -2 & -2 & -2 & -3 & -3 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 1 ) + la(8 ) & -1 & -1 & -2 & -3 & -3 & -4 & -6 & -8 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 3 ) & ( 10 ) + la(20 ) & -1 & -1 & -2 & -3 & -4 & -5 & -6 & -9 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 4 ) & ( 16 ) +     +    l|*8c@xmath34 & @xmath308 & @xmath309 & @xmath310 & @xmath311 & @xmath312 & @xmath313 & @xmath314 & @xmath315 + true & @xmath291 & @xmath291 & @xmath292 & @xmath293 & @xmath316 & @xmath294 & @xmath295 & @xmath296 + haar & @xmath291 & @xmath291 & @xmath291 & @xmath291 & @xmath292 & @xmath292 & @xmath292 & @xmath292 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 1 ) & ( 1 ) & ( 0 ) & ( 1 ) + la(8 ) & @xmath291 & @xmath291 & @xmath292 & @xmath293 & @xmath293 & @xmath316 & @xmath317 & @xmath318 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 1 ) & ( 1 ) & ( 4 ) & ( 15 ) + la(20 ) & @xmath291 & @xmath291 & @xmath292 & @xmath293 & @xmath316 & @xmath294 & @xmath317 & @xmath319 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 2 ) & ( 6 ) & ( 21 ) +     +    l|*8c@xmath34 & @xmath308 & @xmath309 & @xmath310 & @xmath311 & @xmath312 & @xmath313 & @xmath314 & @xmath315 + true & @xmath291 & @xmath291 & @xmath292 & @xmath293 & @xmath316 & @xmath294 & @xmath295 & @xmath296 + haar & @xmath291 & @xmath291 & @xmath292 & @xmath292 & @xmath292 & @xmath292 & @xmath293 & @xmath293 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 1 ) & ( 1 ) + la(8 ) & @xmath291 & @xmath291 & @xmath292 & @xmath293 & @xmath293 & @xmath316 & @xmath317 & @xmath320 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 1 ) & ( 1 ) & ( 4 ) & ( 14 ) + la(20 ) & @xmath291 & @xmath291 & @xmath292 & @xmath293 & @xmath316 & @xmath294 & @xmath317 & @xmath320 + & ( 0 ) & ( 0 ) & ( 0 ) & ( 0 ) & ( 1 ) & ( 2 ) & ( 6 ) & ( 20 ) +     +",
    "in this section we apply our new method to evaluate lead - lag effects on a scale - by - scale basis in real financial data .",
    "specifically , we analyze the lead - lag relationships between the log - prices of the s&p 500 index and the e - mini s&p500 futures in april 2016 , containing 21 trading days .",
    "we have obtained our data set from the bloomberg .",
    "the price data of the s&p 500 index are recorded with the second - by - second basis from 9:30 am edt to 16:00 edt each trading day .",
    "we use the transaction data of the e - mini s&p500 futures recorded between 9:30 am edt and 16:00 edt each trading day with the accuracy in the timestamp values being one second .    before presenting the result , we remark that there are many researches examining the lead - lag effect between the s&p 500 index and index futures : see @xcite for example .",
    "these studies have reported that the futures lead the index .",
    "we regard the log - price process of the s&p 500 index as @xmath190 and the log - price process of the e - mini s&p 500 futures as @xmath191 .",
    "we set @xmath321 as the search grid .",
    "we use la(20 ) ( daubechies least asymmetric wavelet filter with length 20 ) as the wavelet filter @xmath159 .",
    "table [ empirical1 ] reports the estimated values of @xmath281 for @xmath322 on april 1 , 2016 .",
    "we also depict the function @xmath238 evaluated for @xmath323 in figure [ figure : wccf ] .",
    "the table shows that all the estimated lags are negative , which indicates that @xmath191 ( futures ) lead @xmath190 ( index ) .",
    "this is consistent with the preceding studies . in figure",
    "[ theta - all ] we depict the time series of @xmath281 s evaluated every trading day .",
    "we find that the estimated values of @xmath281 s are quite stable in this period , especially at finer resolutions @xmath306 .",
    "this suggests that there might be a stable multi - scale structure in lead - lag effects between the s&p 500 index and the e - mini s&p500 futures .",
    ".estimated values of @xmath281 for april 1 , 2016 ( in seconds ) [ cols=\"^,^,^,^,^,^,^,^,^,^ \" , ]        for april 1 , 2016 ]     in april , 2016 ( @xmath324 ) ]",
    "in this paper , we have proposed a new framework to model potential multi - scale structures of lead - lag relationships between financial assets .",
    "our framework has accommodated traditional wavelet methods for analyzing lead - lag relationships to continuous - time modeling by establishing an explicit connection between wavelet and the lvy - ciesielski construction of brownian motion from a statistical viewpoint .",
    "we have also developed a statistical methodology to estimate lead - lag times on a scale - by - scale basis in the proposed framework .",
    "an associated asymptotic theory has been shown in order to ensure the validity of our methodology . to complement the theory ,",
    "we have conducted a simulation study which demonstrates the finite sample performance of our asymptotic theory .",
    "we have reported an empirical application as well to illustrate how the proposed framework performs in practice .",
    "a drawback of the presented estimation method is that it requires us to interpolate data onto the grid with the finest observable resolution . in some cases",
    "this is computational challenging .",
    "for example , if the finest observable resolution is one micro - second , then the method requires us to store one million observations per one second .",
    "a solution to this issue is currently under investigation and will be presented in future work .",
    "by theorem 5.11 from @xcite we have @xmath325}=(1_{[0,t]}*\\underline{\\tilde{\\phi}})*\\tilde{\\phi}+\\sum_{j=0}^\\infty 2^j(1_{[0,t]}*\\underline{\\tilde{\\psi}_j})*\\tilde{\\psi}_j \\qquad\\text{in } l^2(\\mathbb{r}).\\ ] ] theorem 5.11 from @xcite also implies that @xmath326}*\\underline{\\tilde{\\phi}})*\\tilde{\\phi},(1_{[0,t]}*\\underline{\\tilde{\\psi}_j})*\\tilde{\\psi}_j\\in l^2(\\mathbb{r})$ ] .",
    "therefore , we obtain @xmath327}*\\underline{\\tilde{\\phi}})*\\tilde{\\phi}(s)db_s+\\sum_{j=0}^\\infty 2^j\\int_{-\\infty}^\\infty ( 1_{[0,t]}*\\underline{\\tilde{\\psi}_j})*\\tilde{\\psi}_j(s)db_s\\ ] ] in @xmath5 .",
    "now , we show that @xmath328}*\\underline{g})*g(s)db_s = \\int_{-\\infty}^\\infty du(1_{[0,t]}*\\underline{g})(u)\\int_{-\\infty}^\\infty g(s - u)db_s\\ ] ] for @xmath329 .",
    "we have @xmath330}*\\underline{g})(u)g(s - u)du\\right|^2ds & \\leq\\int_{-t}^tds\\int_{|u|>a}(1_{[0,t]}*\\underline{g})(u)^2du\\int_{-\\infty}^\\infty g(s - u)^2du\\\\ & \\leq2t\\|g\\|_{l^2(\\mathbb{r})}\\int_{|u|>a}(1_{[0,t]}*\\underline{g})(u)^2du\\end{aligned}\\ ] ] by the schwarz inequality .",
    "since @xmath326}*\\underline{g})(u)\\in l^2(\\mathbb{r})$ ] by the young inequality , we conclude that @xmath331}*\\underline{g})(u)g(s - u)du\\right|^2ds=0.\\end{aligned}\\ ] ] therefore , we have @xmath332}*\\underline{g})*g(s)db_s = \\lim_{t\\to\\infty}\\lim_{a\\to\\infty}\\int_{-t}^tdb_s\\int_{-a}^a(1_{[0,t]}*\\underline{g})(u)g(s - u)du\\end{aligned}\\ ] ] in @xmath32 . applying stochastic fubini s theorem ( cf .  theorem 5.26 from @xcite ) , we obtain @xmath332}*\\underline{g})*g(s)db_s = \\lim_{t\\to\\infty}\\lim_{a\\to\\infty}\\int_{-a}^adu(1_{[0,t]}*\\underline{g})(u)\\int_{-t}^tg(s - u)db_s\\end{aligned}\\ ] ] in @xmath32 . now , by an analogous argument to the above we deduce . since we have @xmath333}*\\underline{g})(u)\\int_{-\\infty}^\\infty g(s - u)db_s = \\int_0^tdv\\int_{-\\infty}^\\infty g(v - u)\\left(\\int_{-\\infty}^\\infty g(s - u)db_s\\right)du\\end{aligned}\\ ] ] by fubini s theorem , we obtain the desired result.@xmath334      we use some concepts on schwartz s generalized functions and refer to chapters 67 of @xcite for details about them .",
    "let us denote by @xmath335 the set of all ( complex - valued ) rapidly decreasing functions on @xmath77 .",
    "define the function @xmath336 by @xmath337 for @xmath338 , which can be defined thanks to .",
    "@xmath339 is obviously a tempered generalized function on @xmath77 . moreover , if @xmath338 is real - valued , then @xmath340 .",
    "in fact , we have @xmath341 by .",
    "now , for any @xmath338 we have @xmath342 in @xmath335 , hence @xmath343 . therefore , @xmath344 and @xmath345 by the parseval identity and .",
    "hence , there is a ( unique ) continuous function @xmath346 such that @xmath347 for any @xmath338 . by continuity @xmath348",
    "is real - valued as long as @xmath349 is real - valued .",
    "similarly , we define the function @xmath350 by @xmath351 for @xmath338 .",
    "then , by an analogous argument to the above there is a ( unique ) continuous function @xmath352 such that @xmath353 for any @xmath338 and that @xmath354 is real - valued as long as @xmath349 .",
    "now let @xmath355 and @xmath356 be two independent two - sided standard brownian motions .",
    "then we define the processes @xmath357 and @xmath358 by @xmath359 and @xmath360})(s)dw^1_s+\\int_{-\\infty}^\\infty\\mathbf{g}(1_{(0,t]})(s)dw^2_s   & \\text{if } t\\geq0 ,   \\\\",
    "-\\int_{-\\infty}^\\infty\\mathbf{f}(1_{(t,0]})(s)dw^1_s-\\int_{-\\infty}^\\infty\\mathbf{g}(1_{(t,0]})(s)dw^2_s   & \\text{otherwise}.   \\end{array } \\right.\\ ] ] @xmath145 is obviously real - valued and continuous . moreover , noting that @xmath361 and @xmath362 in @xmath5 for any @xmath349 , we can easily check that @xmath145 is a two - sided standard brownian motion due to the parseval identity .",
    "hence @xmath144 and @xmath145 satisfy condition ( i ) .",
    "condition ( ii ) also follows from the parseval identity .",
    "this especially implies that the bivariate process @xmath12 is of stationary increments .",
    "@xmath154 is evidently gaussian by construction , hence we complete the proof of the first part of the proposition .",
    "conversely , suppose that a bivariate process @xmath108",
    "( @xmath83 ) with stationary increments satisfies condition ( i )",
    ". then , by the spectral representation theorem for the structural function of a process with stationary increments ( see e.g.  theorem 4 from chapter i , section 4 of @xcite ) there is a function @xmath363 of bounded variation such that 0 @xmath364=\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty\\frac{(e^{-\\sqrt{-1}\\lambda t}-1)(e^{\\sqrt{-1}\\lambda s}-1)}{\\lambda^2}df(\\lambda)\\ ] ] for any @xmath135 and @xmath365=\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty(\\mathcal{f}u)(\\lambda)\\overline{(\\mathcal{f}v)(\\lambda)}df(\\lambda)\\ ] ] for any @xmath137 and @xmath366 .",
    "implies that @xmath367 is absolutely continuous , so @xmath367 is differentiable almost everywhere on @xmath77 and @xmath368 by theorem 7.20 from @xcite .",
    "this @xmath71 satisfies due to . moreover , follows from and theorem 1.40 from @xcite .",
    "finally , by we have @xmath369\\\\ & = 2\\pi e\\left[\\left(\\int_{-\\infty}^\\infty \\overline{u(s)}db_s^1\\right)\\overline{\\left(\\int_{-\\infty}^\\infty \\overline{u(s)}db^2_s\\right)}\\right ] = \\int_{-\\infty}^\\infty\\left|(\\mathcal{f}\\overline{u})(\\lambda)\\right|^2f(\\lambda)d\\lambda\\\\ & = \\int_{-\\infty}^\\infty\\left|(\\mathcal{f}u)(-\\lambda)\\right|^2f(\\lambda)d\\lambda = \\int_{-\\infty}^\\infty\\left|(\\mathcal{f}u)(\\lambda)\\right|^2f(-\\lambda)d\\lambda\\end{aligned}\\ ] ] for any @xmath349 .",
    "therefore , for any bounded borel set @xmath370 , we have @xmath371 by taking @xmath372 . consequently ,",
    "@xmath71 satisfies due to theorem 1.40 from @xcite.@xmath334      throughout the discussions , for sequences @xmath373 and",
    "@xmath374 , @xmath375 means that there exists a constant @xmath376 such that @xmath377 for large @xmath148 .",
    "also , for @xmath378 @xmath379 denotes the @xmath380-norm of random variables , i.e.  @xmath381)^{1/r}$ ] for a random variable @xmath382 .",
    "first we note that , without loss of generality , the volatility processes @xmath258 and @xmath259 may be assumed to be bounded by a standard localization argument presented in e.g.  section 3 of @xcite .",
    "in fact , for each @xmath383 and each @xmath21 , let us define @xmath384 .",
    "we have @xmath385 as long as @xmath386 .",
    "now define the process @xmath387 by @xmath388 for @xmath256 .",
    "@xmath387 is obviously cdlg and @xmath185-adapted because @xmath389 is an @xmath185-stopping time .",
    "so we can define the process @xmath390 by @xmath391 for @xmath208 .",
    "we associate @xmath392 with @xmath393 and @xmath394 .",
    "now since we have @xmath395 and @xmath396 because both @xmath258 and @xmath259 are cdlg , the results of theorem [ theorem : main ] hold true once they hold true for @xmath392 . consequently , in the following we assume that both @xmath258 and @xmath259 are bounded .",
    "we use the notation @xmath397 we start by proving the c - tightness of the target quantity .    [",
    "lemma : c - tight ] under the assumptions of theorem [ theorem : main ] , the process @xmath398 is c - tight as @xmath181 .",
    "since @xmath230 , it can be written as @xmath399 for some @xmath400 .",
    "for the simplicity of presentation we assume that @xmath401 for all @xmath148 ( this assumption can easily be removed ) .",
    "according to proposition 3.26 from chapter vi of @xcite , it suffices to prove @xmath402 for any @xmath403 and any @xmath404 . here for a function @xmath405 @xmath406 denote the modulus of continuity of @xmath76 on @xmath407 $ ] : @xmath408,|s - t|\\leq\\eta\\}.\\ ] ]    first we show that there is a constant @xmath409 such that @xmath410 for any @xmath411 and @xmath21 .",
    "since we can rewrite @xmath279 as @xmath412 the minkowski and the burkholder - davis - gundy inequalities as well as yield @xmath413 hence holds true .",
    "next , and the schwarz inequality imply that @xmath414\\lesssim \\sum_{k = l_j-1}^{\\lfloor \\tau_j^{-1}m\\rfloor - l}e\\left[\\left|\\mathcal{w}^1_{jk}\\mathcal{w}^2_{jk+l}\\right|\\right]\\lesssim m,\\end{aligned}\\ ] ] hence holds true by the markov inequality .",
    "finally , for @xmath415 , the schwarz inequality yields @xmath416 hence we have @xmath417\\\\ & \\lesssim\\varepsilon^{-1}(\\eta+\\tau_j)m\\end{aligned}\\ ] ] by the markov and schwarz inequalities as well as . this yields .",
    "this completes the proof .",
    "next we assess the errors induced by interpolation .",
    "[ lemma : lm - term ] under the assumptions of theorem [ theorem : main ] , we have @xmath418\\right\\|_r = o\\left(\\sqrt{\\tau_j}l_j\\right)\\ ] ] as @xmath181 for any @xmath419 , any @xmath383 and any even integer @xmath420 .    by symmetry it is enough to prove @xmath421\\right\\|_r = o\\left(\\sqrt{\\tau_j}l_j\\right).\\ ] ] set @xmath422 $ ] . for any @xmath423",
    ", we can rewrite @xmath424 $ ] as @xmath425\\\\ & = \\frac{\\tau_j^{-1}}{n - l - l_j+1}\\sum_{p , q=0}^{l_j-1}\\sum_{\\alpha=0}^{\\lfloor \\tau_j^{-1}t\\rfloor - l - p}\\sum_{\\beta=0}^{\\lfloor \\tau_j^{-1}t\\rfloor - q}h_{j , p}h_{j , q}\\\\ & \\qquad\\times\\sum_{k=(l_j-1)\\vee(\\alpha+p)\\vee(\\beta+q - l)}^{\\lfloor \\tau_j^{-1}t\\rfloor - l}\\mathcal{x}_{k , l , p , q}(\\alpha,\\beta)\\delta_{k - p-\\alpha}x^1\\delta_{k+l - q-\\beta}x^2.\\end{aligned}\\ ] ] therefore , the minkowski inequality yields @xmath426\\right\\|_r\\\\ & \\lesssim\\sum_{p , q=0}^{l_j-1}\\sum_{\\alpha,\\beta=0}^\\infty|h_{j , p}h_{j , q}|\\left\\|\\sum_{k=(l_j-1)\\vee(\\alpha+p)\\vee(\\beta+q - l)}^{\\lfloor \\tau_j^{-1}t\\rfloor - l}\\mathcal{x}_{k , l , p , q}(\\alpha,\\beta)\\delta_{k - p-\\alpha}x^1\\delta_{k+l - q-\\beta}x^2\\right\\|_r.\\end{aligned}\\ ] ] now , by construction @xmath427 and @xmath428 are independent if @xmath429 , and we have @xmath430\\lesssim\\pi_1^\\alpha\\pi_2^\\beta$ ] by construction and @xmath431+e[|\\delta_{k+l - q-\\beta}x^2|^a]\\lesssim\\tau_j^{a/2}$ ] by the burkholder - davis - gundy inequality for any @xmath253 .",
    "therefore , by theorem 2 from @xcite we obtain @xmath432 hence we conclude that @xmath433\\right\\|_r \\lesssim\\sqrt{\\tau_j}\\sum_{p , q=0}^{l_j-1}|h_{j , p}h_{j , q}|\\leq\\sqrt{\\tau_j}l_j,\\end{aligned}\\ ] ] where we use the inequality @xmath434 thus we complete the proof .",
    "now we investigate the asymptotic behavior of @xmath435 $ ] . for @xmath21 and @xmath436",
    ", we define the variables @xmath437 by @xmath438 = ( 1-\\pi_\\nu)\\sum_{p=0}^{l_j-1}\\sum_{\\alpha=0}^{k - p}h_{j , p}\\pi_\\nu^\\alpha\\delta_{k - p-\\alpha}x^\\nu.\\end{aligned}\\ ] ] thanks to the independence between @xmath439 s and @xmath440 s , we have @xmath441=\\frac{\\tau_j^{-1}}{n - l - l_j+1}\\sum_{k = l_j-1}^{\\lfloor \\tau_j^{-1}t\\rfloor -l}z^\\nu_kz^\\nu_{k+l}\\ ] ] for @xmath442 . to analyze the asymptotic behavior of this quantity , we introduce the `` de - volatilized '' version of @xmath437 as follows : @xmath443 since @xmath444 s are centered gaussian variables , their distribution is completely determined by their covariance structure . to investigate their covariance structure we introduce the following auxiliary quantity for each @xmath124 : @xmath445    in the following @xmath446 denotes a positive integer such that @xmath447 for some @xmath448 and @xmath449 .    [ covariance ]    1 .",
    "we have @xmath450\\right| \\leq\\tau_j(1-\\pi_\\nu)^2\\sum_{\\alpha,\\beta=0}^\\infty\\pi_\\nu^{\\alpha+\\beta}\\sum_{p=0}^{l_j-1}|h_{j , p}|1_{\\{|k'-k-\\beta+\\alpha|<l_j\\}}\\end{aligned}\\ ] ] for any @xmath21 and any @xmath451 .",
    "we have @xmath452-\\tau_j\\bar{\\rho}_j((k'+l - k)\\tau_j)\\right|=o(\\tau_jl_j^2(\\pi_1^n+\\pi_2^n))\\ ] ] as @xmath181 .",
    "first , claim ( a ) follows from the following identity @xmath453 = \\tau_j(1-\\pi_\\nu)^2\\sum_{\\alpha=0}^k\\sum_{\\beta=0}^{k'}\\sum_{\\begin{subarray}{c } p=0\\\\ 0\\leq k'-\\beta-(k - p-\\alpha)\\leq l_j-1 \\end{subarray}}^{(l_j-1)\\wedge(k-\\alpha)}h_{j , p}h_{j , k'-\\beta-(k - p-\\alpha)}\\pi_\\nu^{\\alpha+\\beta}\\ ] ] and the inequality @xmath454 .",
    "next , using the identity @xmath455=\\tau_j\\int_{-\\infty}^\\infty d(\\lambda)e^{\\sqrt{-1}l}f_{j}(\\tau_j^{-1}\\lambda)d\\lambda,\\ ] ] we have @xmath456\\\\ & = ( 1-\\pi_1)(1-\\pi_2)\\sum_{p , q=0}^{l_j-1}\\sum_{\\alpha=0}^{k - p}\\sum_{\\beta=0}^{k'+l - q}h_{j , p}h_{j , q}\\pi_1^\\alpha\\pi_2^\\beta e\\left[\\delta_{k - p-\\alpha}b^1\\delta_{k'+l - q-\\beta}b^2\\right]\\\\ & = \\tau_j(1-\\pi_1)(1-\\pi_2)\\sum_{p , q=0}^{l_j-1}\\sum_{\\alpha=0}^{k - p}\\sum_{\\beta=0}^{k'+l - q}h_{j , p}h_{j , q}\\pi_1^\\alpha\\pi_2^\\beta\\int_{-\\infty}^\\infty d(\\lambda)e^{\\sqrt{-1}(k'+l - q-\\beta - k+p+\\alpha)\\lambda}f_{j}(\\tau_j^{-1}\\lambda)d\\lambda.\\end{aligned}\\ ] ] then , noting that the identity @xmath457 we obtain @xmath458 & = \\tau_j\\int_{-\\infty}^\\infty d(\\lambda)h_{j , l}(\\lambda)\\pi(\\lambda)e^{\\sqrt{-1}(k'+l - k)\\lambda}f_{j}(\\tau_j^{-1}\\lambda)d\\lambda + o(\\tau_jl^2(\\pi_1^n+\\pi_2^n))\\nonumber\\\\ & = \\tau_j\\bar{\\rho}_j((k'+l - k)\\tau_j ) + o(\\tau_jl^2(\\pi_1^n+\\pi_2^n))\\end{aligned}\\ ] ] uniformly in @xmath459 and @xmath460 , where we use . hence claim ( b ) also holds true .    from now on we investigate the asymptotic behavior of @xmath461 .",
    "we need the following auxiliary result .",
    "[ dh - bound ] it holds that @xmath462}\\left|\\frac{d}{d\\lambda}h_{j , l}(\\lambda)\\right| \\leq(2^j-1)c_l,\\text { where } c_l=\\binom{l-2}{l/2 - 1}\\frac{l-1}{2^{l-1}}.\\ ] ] moreover , @xmath463 as @xmath227 .    from the proof of theorem 3 from",
    "@xcite we have @xmath464 where we use the double angle formula for the sine function . since we have @xmath465 , the first part of the lemma follows from and the leibniz rule .",
    "the latter part is a consequence of stirling s formula .",
    "we can rewrite @xmath461 as @xmath466    [ lemma : rl ] there is a constant @xmath467 such that @xmath468 for any positive integers @xmath469 , any even positive integer @xmath160 and any non - zero real number @xmath73 .",
    "integration by parts yields @xmath470_{\\pi/2^i}^{\\pi/2^{i-1}}\\\\ -\\frac{1}{\\sqrt{-1}a}\\int_{\\pi/2^i}^{\\pi/2^{i-1}}\\frac{d}{d\\lambda}\\left\\{d(\\lambda)h_{j , l}(\\lambda)\\pi(\\lambda)\\right\\}e^{\\sqrt{-1}a\\lambda}d\\lambda.\\end{gathered}\\ ] ] we can easily see that @xmath471 hence the desired result follows from lemma [ dh - bound ] .    [ lemma : zero ] under the assumptions of theorem [ theorem : main](a ) , we have @xmath472 as @xmath181 .",
    "since we have @xmath473 for every @xmath474 , it is enough to prove @xmath475 as @xmath181 for any fixed @xmath474 due to the dominated convergence theorem . by theorem 1 from @xcite , we have @xmath476 .",
    "\\end{array } \\right.\\ ] ] therefore , holds true if @xmath477 due to the bounded convergence theorem . on the other hand ,",
    "if @xmath478 , lemma [ lemma : rl ] yields @xmath479 hence we obtain the desired result by assumption and @xmath463 .",
    "[ lemma : wccf ] under the assumptions of theorem [ theorem : main](b ) , we have @xmath480 as @xmath181 .    from the above argument it suffices to prove @xmath481 which follows from and the bounded convergence theorem .    since @xmath230",
    ", it can be written as @xmath399 for some @xmath400 .",
    "for the simplicity of presentation we assume that @xmath401 for all @xmath148 .",
    "since @xmath482 for every @xmath483 , all the subsequence of the sequence @xmath484 has converging subsequences .",
    "therefore , without loss of generality we may assume that @xmath485 as @xmath181 for some @xmath486 $ ] .",
    "note that @xmath142 for case ( b ) by assumption .",
    "set @xmath487 for case ( a ) and @xmath488 for case ( b ) .",
    "we need to prove @xmath489 as @xmath181 . by lemma [ lemma : c - tight ] it is enough to show that @xmath490 as @xmath181 for any fixed @xmath225 .",
    "we decompose @xmath491 as @xmath492\\right)\\\\ & \\qquad+\\left(e\\left[\\widehat{\\boldsymbol{\\rho}}_{(j)}(l\\tau_j)_{t}|x\\right]-\\frac{\\tau_j^{-1}}{n - l - l_j+1}\\sum_{k = l_j-1}^{\\lfloor t\\tau_j^{-1}\\rfloor - l}\\sigma^1_{(k - l_j - n)_+\\tau_j}\\sigma^2_{\\left\\{(k - l_j - n)_++l\\right\\}\\tau_j}\\zeta^1_k\\zeta^2_{k+l}\\right)\\\\ & \\qquad+\\frac{\\tau_j^{-1}}{n - l - l_j+1}\\sum_{k = l_j-1}^{\\lfloor t\\tau_j^{-1}\\rfloor - l}\\sigma^1_{(k - l_j - n)_+\\tau_j}\\sigma^2_{\\left\\{(k - l_j - n)_++l\\right\\}\\tau_j}\\zeta^1_k\\zeta^2_{k+l}\\\\ & = : \\mathbf{i}_j+\\mathbf{ii}_j+\\mathbf{iii}_j.\\end{aligned}\\ ] ]    first , since @xmath493 as @xmath181 by lemma [ lemma : lm - term ] , we obtain @xmath494 .",
    "next , noting , we decompose @xmath495 as @xmath496 we have @xmath497 since we have @xmath498 it holds that @xmath499 by the triangle inequality and . on the other hand ,",
    "since we can rewrite @xmath500 as @xmath501 we have @xmath502 by the triangle inequality , the boundedness of @xmath259 and .",
    "hence we obtain @xmath503 by the schwarz inequality . since @xmath258 is cdlg and bounded , the bounded convergence theorem yields @xmath504 , hence @xmath505 . by an analogous argument",
    "we can prove @xmath506 , hence we obtain @xmath507 .",
    "finally we prove @xmath508 .",
    "it suffices to prove @xmath509 define the process @xmath510 by @xmath511\\right).\\ ] ] @xmath512 is obviously of ( locally ) bounded variation .",
    "moreover , since it holds that @xmath513 by the triangular inequality and , we have @xmath514\\right|\\right]=o(1)\\end{aligned}\\ ] ] for any @xmath515 by the schwarz inequality .",
    "hence @xmath512 is p - ut by 6.6 from chapter vi of @xcite .",
    "moreover , the process @xmath516 converges in probability to the process @xmath517 for the skorokhod topology by proposition 6.37 from chapter vi of @xcite .",
    "therefore , according to theorem 6.22 from chapter vi of @xcite , follows once we show that @xmath518 by lemma [ lemma : c - tight ] it is enough to prove @xmath519 for any fixed @xmath520 .",
    "moreover , by lemmas [ covariance ] and [ lemma : zero][lemma : wccf ] this follows from @xmath521\\right)\\to^p0.\\ ] ] to prove , let us define the random vector @xmath522 by @xmath523 then we have @xmath524\\right)=\\boldsymbol{\\zeta}^\\top a_j\\boldsymbol{\\zeta}-e\\left[\\boldsymbol{\\zeta}^\\top a_j\\boldsymbol{\\zeta}\\right],\\ ] ] where @xmath525 therefore , the proof of is completed once we show that @xmath526\\to0 $ ] as @xmath181 .",
    "since @xmath522 is centered gaussian , we have @xmath526=2\\operatorname{tr}[(\\sigma_ja_j)^2]$ ] from the discussion in section 3.2.1 of @xcite , where @xmath527 denotes the covariance matrix of @xmath522 . since @xmath528\\leq\\|\\sigma_ja_j\\|_f^2\\leq\\|\\sigma_j\\|_f^2 $ ] by appendix",
    "ii(ii)(iii ) from @xcite , it is enough to prove @xmath529 , where @xmath530 denote the frobenius norm of matrices .    first , by lemma [ covariance](a ) and we have @xmath531\\right|^2+\\left|e\\left[\\zeta^1_{k+l}\\zeta^1_{k'+l}\\right]\\right|^2\\right ) = o\\left(\\tau_j^{-1}l_j\\cdot\\tau_j^2l_j\\right)=o\\left(\\tau_jl_j^2\\right)=o(1).\\end{aligned}\\ ] ] next , by lemma [ covariance](b ) we have @xmath532\\right|^2=\\tau_j^2\\sum_{k , k'=l_j+n}^{\\lfloor s\\tau_j^{-1}\\rfloor - l}\\bar{\\rho}_j((k'+l - k)\\tau_j)^2+o(1).\\end{aligned}\\ ] ] therefore , to complete the proof of @xmath529 , it is enough to show that @xmath533 we rewrite the target quantity as @xmath534 since we have @xmath535 , we obtain by the dominated convergence theorem once we prove @xmath536 for any fixed @xmath537 . by lemma [ lemma : rl ]",
    "we have @xmath538 since @xmath463 , we conclude that @xmath539 .    consequently , we complete the proof of the theorem .",
    "similarly to section [ proof : theorem1 ] , a localization procedure allows us to assume that both @xmath258 and @xmath259 are bounded as well as there is a constant @xmath383 such that @xmath540 .",
    "0    [ lemma : qf ] for any @xmath541 there is a constant @xmath542 such that @xmath543\\right|^r\\right]\\leq k_rm^{\\frac{r}{2}-1}\\|\\sigma^{\\frac{1}{2}}a\\sigma^{\\frac{1}{2}}\\|_\\mathrm{sp}^{r-2}\\|\\sigma^{\\frac{1}{2}}a\\sigma^{\\frac{1}{2}}\\|_f^2\\ ] ] for any @xmath544-dimensional centered normal variable @xmath522 with non - singular covariance matrix @xmath545 and any @xmath544-by-@xmath544 symmetric matrix @xmath467 of order @xmath544 .    set @xmath546 . since @xmath547 is symmetric , there is an @xmath544-by-@xmath544 orthogonal matrix @xmath548 and @xmath544-by-@xmath544 diagonal matrix @xmath549 such that @xmath550 .",
    "now let @xmath522 be an @xmath544-dimensional standard normal variable .",
    "then , @xmath522 and @xmath551 has the same distribution , hence we have @xmath543\\right|^r\\right ] = e\\left[\\left|\\boldsymbol{\\zeta}^\\top d\\boldsymbol{\\zeta}-e\\left[\\boldsymbol{\\zeta}^\\top d\\boldsymbol{\\zeta}\\right]\\right|^r\\right].\\ ] ] let @xmath552 and let @xmath553 be the diagonal component of @xmath549 .",
    "then we have @xmath554=\\sum_{i=1}^md_i(\\zeta_i^2 - 1).\\ ] ] therefore , the burkholder - davis - gundy and jensen inequalities yield @xmath555\\right|^r\\right ] & \\lesssim e\\left[\\left\\{\\sum_{i=1}^md_i^2(\\zeta_i^2 - 1)^2\\right\\}^{r/2}\\right ] \\leq m^{r/2 - 1}e\\left[\\sum_{i=1}^m|d_i|^r|\\zeta_i^2 - 1|^r\\right]\\\\ & \\lesssim m^{r/2 - 1}\\sum_{i=1}^m|d_i|^r.\\end{aligned}\\ ] ] since @xmath556 and @xmath557 , we obtain the desired result .    the following result is a counterpart of proposition 3 from @xcite :    [ lemma : ld ] under the assumptions of theorem [ hry ] , we have @xmath558 as @xmath181 for any @xmath404 .    by symmetry and the triangular inequality , it suffices to prove the following equations : @xmath559\\right|\\to^p0,\\label{ld-1}\\\\ & \\max_{l\\in\\mathcal{l}^+_{j}:v_{j}^{-1}|l\\tau_j-\\theta_j| > \\varepsilon}\\left|e\\left[\\widehat{\\rho}_{(j)}(l\\tau_j)|x\\right]\\right|\\to^p0.\\label{ld-2}\\end{aligned}\\ ] ]    first we show .",
    "take @xmath404 arbitrarily .",
    "then , for any even integer @xmath420 the markov inequality yields @xmath560\\right|>\\varepsilon\\right)\\\\ & \\leq\\varepsilon^{-r}e\\left[\\max_{l\\in\\mathcal{l}^+_{j}:v_{j}^{-1}|l\\tau_j-\\theta_j| > \\varepsilon}\\left|\\widehat{\\rho}_{(j)}(l\\tau_j)-e\\left[\\widehat{\\rho}_{(j)}(l\\tau_j)|x\\right]\\right|^r\\right]\\\\ & \\leq\\varepsilon^{-r}\\sum_{l\\in\\mathcal{l}^+_{j}}e\\left[\\left|\\widehat{\\rho}_{(j)}(l\\tau_j)-e\\left[\\widehat{\\rho}_{(j)}(l\\tau_j)|x\\right]\\right|^r\\right ] \\leq\\varepsilon^{-r}\\#\\mathcal{l}^+_{j}\\max_{l\\in\\mathcal{l}^+_{j}}e\\left[\\left|\\widehat{\\rho}_{(j)}(l\\tau_j)-e\\left[\\widehat{\\rho}_{(j)}(l\\tau_j)|x\\right]\\right|^r\\right].\\end{aligned}\\ ] ] we can take sufficiently large @xmath420 such that @xmath561 . then we have @xmath562\\right|^r\\right ] = o\\left(\\left(\\tau_j^{1 - 2/r}l^2\\right)^{r/2}\\right)=o(1)\\end{aligned}\\ ] ] by lemma [ lemma : lm - term ] .",
    "this yields the desired result .",
    "next we show .",
    "we adopt an analogous strategy to the one used in the proof of theorems 34 from @xcite . set",
    "@xmath563 and @xmath564 we decompose @xmath565 $ ] as @xmath566\\\\ & = \\frac{\\tau_j^{-1}}{n - l - l_j+1}\\left\\{\\sum_{k = l_j-1}^{l_j+n-1}z^1_kz^2_{k+l } + \\sum_{k=2^{j - m}m_j}^{n-1-l}z^1_kz^2_{k+l } + \\sum_{i=0}^{m_j-1}\\sum_{k\\in i_m(i)}\\left(z^1_k-\\sigma^1_{i\\tau_m}\\zeta^1_k\\right)z^2_{k+l}\\right.\\\\ & \\qquad+\\sum_{i=0}^{m_j-1}\\sum_{k\\in i_m(i)}\\sigma^1_{i\\tau_m}\\zeta^1_k\\left(z^2_{k+l}-\\sigma^2_{i\\tau_m+l\\tau_j}\\zeta^2_{k+l}\\right ) + \\sum_{i=0}^{m_j-1}\\sigma^1_{i\\tau_m}\\sigma^2_{i\\tau_m+l\\tau_j}\\sum_{k\\in i_m(i)}\\left(\\zeta^1_k\\zeta^2_{k+l}-e\\left[\\zeta^1_k\\zeta^2_{k+l}\\right]\\right)\\\\ & \\left.\\qquad+\\sum_{i=0}^{m_j-1}\\sigma^1_{i\\tau_m}\\sigma^2_{i\\tau_m+l\\tau_j}\\sum_{k\\in i_m(i)}e\\left[\\zeta^1_k\\zeta^2_{k+l}\\right]\\right\\}\\\\ & = : \\mathbb{i}_j(l)+\\mathbb{ii}_j(l)+\\mathbb{iii}_j(l)+\\mathbb{iv}_j(l)+\\mathbb{v}_j(l)+\\mathbb{vi}_j(l),\\end{aligned}\\ ] ] where @xmath567 .",
    "first we prove @xmath568 .",
    "since we have @xmath569 by the minkowski and burkholder - davis - gundy inequalities as well as , we obtain @xmath570 by the triangle and schwarz inequalities .",
    "therefore , the markov inequality yields @xmath571 for any @xmath404 , hence @xmath568 .    noting that @xmath228",
    ", we can prove @xmath572 in an analogous manner to the above .",
    "next we prove @xmath573 . for any @xmath574 we have 0 @xmath575\\ ] ] @xmath576 hence it holds that @xmath577 for any @xmath578 by the minkowski and burkholder - davis - gundy inequalities as well as",
    ". hence we obtain @xmath579 for any @xmath404 .",
    "we can take large enough @xmath578 such that @xmath580 , hence we obtain @xmath573",
    ".    we can prove @xmath581 in an analogous manner .",
    "now we prove @xmath582 .",
    "let @xmath583 be the covariance matrix of the random vector @xmath584 for every @xmath474 , and set @xmath585 , where @xmath586 we first prove the following equations : @xmath587 where @xmath588 denotes the spectral norm of matrices . for any @xmath423 we have @xmath589 ^ 2+\\sum_{k , k'\\in i_m(i)}e\\left[\\zeta^2_{k+l}\\zeta^2_{k'+l}\\right]^2 + 2\\sum_{k , k'\\in i_m(i)}e\\left[\\zeta^1_{k}\\zeta^2_{k'+l}\\right]^2\\end{aligned}\\ ] ] by appendix ii(ii)(iii ) from @xcite , while we have @xmath590\\right|,\\max_{k\\in i_m(i)}\\sum_{k'\\in i_m(i)}\\left|e\\left[\\zeta^2_{k+l}\\zeta^2_{k'+l}\\right]\\right|\\right\\ } + \\max_{k\\in i_m(i)}\\sum_{k'\\in i_m(i)}\\left|e\\left[\\zeta^1_k\\zeta^2_{k'+l}\\right]\\right|\\end{aligned}\\ ] ] by corollary 4.5.11 and theorem 5.6.9 from @xcite .",
    "now lemma [ covariance](a ) implies that @xmath591 ^ 2+\\sum_{k , k'\\in i_m(i)}e\\left[\\zeta^2_{k+l}\\zeta^2_{k'+l}\\right]^2\\right\\ } \\lesssim\\tau_j^2\\ # i_m(i)l_j^2 = o\\left(\\tau_j\\tau_ml_j^2\\right),\\end{aligned}\\ ] ] and @xmath592\\right|,\\max_{k\\in i_m(i)}\\sum_{k'\\in i_m(i)}\\left|e\\left[\\zeta^2_{k+l}\\zeta^2_{k'+l}\\right]\\right|\\right\\ } \\lesssim\\tau_jl_j^{3/2}.\\end{aligned}\\ ] ] moreover , by lemma [ covariance](b ) we have @xmath593 ^ 2 = \\tau_j^2\\sum_{k , k'\\in i_m(i)}\\bar{\\rho}_j((k'+l - k)\\tau_j)^2+o(\\tau_j\\tau_ml_j^2)\\end{aligned}\\ ] ] and @xmath594\\right| = \\max_k\\tau_j\\sum_{k'\\in i_m(i)}\\left|\\bar{\\rho}_j((k'+l - k)\\tau_j)\\right|+o(\\tau_jl_j^{3/2})\\end{aligned}\\ ] ] uniformly in @xmath595 and @xmath596 .",
    "since it holds that @xmath597 and @xmath598 the proof of is completed once we show that @xmath599 by lemma [ lemma : rl ] we have @xmath600 hence we obtain .",
    "analogously we can prove .",
    "hence we complete the proof of .",
    "now for any @xmath404 we have @xmath601\\right)\\right|>\\frac{\\varepsilon}{m_jk^2}\\right)\\end{aligned}\\ ] ] with some constant @xmath383 .",
    "the markov inequality yields @xmath602\\right)\\right|>\\frac{\\varepsilon}{m_jk^2}\\right)\\\\ & \\leq \\exp\\left(-\\frac{\\varepsilon u_j}{m_jk^2}\\right)\\sum_{\\varsigma\\in\\{-1,1\\}}e\\left[\\exp\\left(\\varsigma u_j\\sum_{k\\in i_m(i)}\\left(\\zeta^1_k\\zeta^2_{k+l}-e\\left[\\zeta^1_k\\zeta^2_{k+l}\\right]\\right)\\right)\\right],\\end{aligned}\\ ] ] where @xmath603 .",
    "now , from the discussion in section 3.2.1 of @xcite , we have @xmath604\\right)\\right)\\right]=-\\frac{1}{2}\\log\\det(e-2\\varsigma u_jc_{m , l}(i))-\\operatorname{tr}[\\varsigma u_jc_{m , l}(i)]\\end{aligned}\\ ] ] for sufficiently large @xmath148 uniformly in @xmath423 and @xmath596 due to the first equation of .",
    "therefore , by appendix ii-(v ) from @xcite we obtain @xmath604\\right)\\right)\\right ] \\leq\\frac{u_j^2}{2}\\|c_{m , l}(i))\\|_f^2+\\frac{u_j^3}{3}\\frac{\\|c_{m , l}(i))\\|_\\mathrm{sp}\\|c_{m , l}(i))\\|_f^2}{(1-\\|c_{m , l}(i))\\|_\\mathrm{sp})^3}\\end{aligned}\\ ] ] for sufficiently large @xmath148 uniformly in @xmath423 and @xmath596 due to the first equation of .",
    "consequently , implies that 0 @xmath605\\right)\\right)\\right]<\\infty.\\end{aligned}\\ ] ] @xmath606\\right)\\right|>\\frac{\\varepsilon}{m_jk^2}\\right ) \\lesssim \\tau_j^{-1}m_j\\exp\\left(-\\frac{\\varepsilon u_j}{m_jk^2}\\right ) . \\ ] ] since we have @xmath607 , it holds that @xmath608 as @xmath181 for some @xmath609 because @xmath610 .",
    "so we obtain @xmath611 this is the desired result .    finally , by lemmas [ covariance](b ) and [ lemma : zero ] we have @xmath612 .",
    "since @xmath613 , we obtain @xmath614 .",
    "this completes the proof of the lemma . 0 from lemma [ lemma : variance ] it suffices to prove that the fourth cumulant of @xmath615 $ ] is of order @xmath616 . by lemma 3.2b.2 from @xcite ,",
    "it is bounded by @xmath617\\right]$ ] multiplied by some constant , where @xmath588 denotes the spectral norm of a matrix .",
    "therefore , again by lemma [ lemma : variance ] it is enough to prove @xmath618 . by theorem 5.6.9 from",
    "@xcite we have @xmath619\\right| + \\max_{k}\\sum_{k'}\\left|e\\left[z^1_kz^2_{k'+l}\\right]\\right|.\\end{aligned}\\ ] ] now , from we have @xmath620\\right| \\lesssim\\tau_j\\sum_{k'}\\sum_{\\alpha,\\beta=0}^\\infty\\sum_{p=0}^{l_j-1}\\left|h_{j , p}\\right|\\pi_\\nu^{\\alpha+\\beta}1_{\\{|k'-k-\\beta+\\alpha|<l_j\\ } } \\lesssim\\tau_jl_j^{3/2}=o(\\sqrt{\\tau_j}l_j).\\end{aligned}\\ ] ] 0 @xmath621d\\lambda\\right|\\\\ & \\lesssim\\tau_j+\\tau_j\\sum_{\\begin{subarray}{c } k'=n+l_j\\\\ \\theta_{i}\\neq ( k'+l - k)\\tau_j \\end{subarray}}^{\\lfloor \\tau_j^{-1}t\\rfloor - l}\\frac{c_l}{\\left|k'+l - k-\\theta_{i}\\tau_j^{-1}\\right|}\\end{aligned}\\ ] ] moreover , we can prove @xmath622 by an analogous argument to the proof of , hence we obtain @xmath623\\right|=o(\\sqrt{\\tau_j}l_j)\\ ] ] by .",
    "this completes the proof .",
    "[ nondegenerate ] @xmath624 for any @xmath226 and @xmath625 $ ] .    since we have @xmath626d\\lambda\\ ] ] and @xmath627 for any @xmath127 , it is enough to prove @xmath628>0 $ ] for any @xmath629 .",
    "we have @xmath630 = \\frac{(1-\\pi_1)(1-\\pi_2)}{|(1-\\pi_1e^{\\sqrt{-1}\\lambda})(1-\\pi_2e^{-\\sqrt{-1}\\lambda})|^2}\\mathfrak{c},\\ ] ] where @xmath631 .",
    "hence it suffices to prove @xmath632 .",
    "since we have @xmath633 , by symmetry we may assume @xmath634 .",
    "first we note that @xmath635 because @xmath636 .",
    "next , we can rewrite @xmath637 as @xmath638 since @xmath639 due to @xmath640 , we have @xmath641 because @xmath642 is increasing on @xmath643 $ ] . also , if @xmath644 , we have @xmath645 , hence @xmath646 .",
    "so @xmath647 .",
    "otherwise , we have @xmath648 , hence we have @xmath647 because @xmath642 is decreasing on @xmath649 $ ] .",
    "consequently , we have @xmath650 this completes the proof .",
    "suppose that there is a number @xmath404 such that @xmath651 does not converge to 0 as @xmath181 .",
    "then there is a sequence @xmath652 of positive integers such that @xmath653 as @xmath654 and @xmath655 as @xmath654 for some @xmath609 .",
    "moreover , for every @xmath544 we can take an integer @xmath656 such that @xmath657 . in particular , the sequence @xmath658 has a converging subsequence . without loss of generality",
    "we may assume that @xmath659 as @xmath654 for some @xmath625 $ ] .",
    "now since @xmath660 implies that @xmath661 , we have @xmath662 where @xmath663 @xmath664 as @xmath654 by lemma [ lemma : wccf ] .",
    "moreover , @xmath665 because of lemma [ nondegenerate ] and assumption .",
    "therefore , by lemma [ lemma : ld ] we obtain @xmath666 this contradicts @xmath667 .",
    "takaki hayashi s research was supported by jsps grant - in - aid for scientific research ( c ) grant number jp16k03601 .",
    "yuta koike s research was supported by jst , crest and jsps grant - in - aid for young scientists ( b ) grant number jp16k17105 ."
  ],
  "abstract_text": [
    "<S> we propose a novel framework to investigate lead - lag relationships between two financial assets . </S>",
    "<S> our framework bridges a gap between continuous - time modeling based on brownian motion and the existing wavelet methods for lead - lag analysis based on discrete - time models and enables us to analyze the multi - scale structure of lead - lag effects . </S>",
    "<S> we also present a statistical methodology for the scale - by - scale analysis of lead - lag effects in the proposed framework and develop an asymptotic theory applicable to a situation including stochastic volatilities and irregular sampling . </S>",
    "<S> finally , we report several numerical experiments to demonstrate how our framework works in practice .    </S>",
    "<S> _ keywords _ : high - frequency data ; lead - lag effect ; wavelet . </S>"
  ]
}