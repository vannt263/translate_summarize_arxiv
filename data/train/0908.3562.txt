{
  "article_text": [
    "between information theory and statistical physics have been widely recognized in the last few decades , from a wide spectrum of aspects . these include conceptual aspects , of parallelisms and analogies between theoretical principles in the two disciplines , as well as technical aspects , of mapping between mathematical formalisms in both fields and borrowing analysis techniques from one field to the other .",
    "one example of such a mapping , is between the paradigm of random codes for channel coding and certain models of magnetic materials , most notably , ising models and spin glass models ( cf .",
    "e.g. , @xcite and many references therein ) . today",
    ", it is quite widely believed that research in the intersection between information theory and statistical physics may have the potential of fertilizing both disciplines .",
    "this paper is more related to the former aspect mentioned above , namely , the relationships between the two areas in the conceptual level . in particular , we revisit results of a recent work @xcite , and propose a somewhat different perspective , which as we believe , has certain advantages , that will be explained and shown in the sequel .",
    "more specifically , in @xcite , an identity between two forms of the rate function of a certain large deviations event was established , with several applications in information theory .",
    "inspired by a few earlier works ( cf .",
    "e.g. , @xcite , @xcite , @xcite ) , this identity was interpreted as _ thermal equilibrium _ between several many  particle physical systems that are brought in contact . in particular , the parameter that undergoes optimization of the chernoff bound , henceforth referred to as the _ chernoff parameter _ , plays a role that is intimately related to the equilibrium temperature : in fact , it is the reciprocal of the temperature , called the _",
    "inverse temperature_. the corresponding large deviations rate function is then identified with the entropy of the system .    while this physical interpretation is fairly reasonable , it turns out , as we show in this paper , that it leaves quite some room for improvement , and we will mention here just two points .",
    "the first , is that this interpretation does not generalize to rate functions of combinations of two or more rare events , where the number of chernoff parameters is as the number of events .",
    "this is because there is only one temperature parameter in physics .",
    "the other point , which is on a more technical level , is the following ( more details and clarifications will follow in subsection 2b below ) : while the log  moment generating function , pertaining to the large deviations rate function , naturally includes weighting by probabilities , its physical analogue , which is the _ partition function _ , does not .",
    "if these probabilities are subjected to optimization ( e.g. , optimization of random coding distributions ) , they may depend on the chernoff parameter , i.e. , on the temperature , in a rather complicated manner , and then the resulting expression can no longer really be viewed as a partition function .    in this paper , we propose to interpret the above  mentioned identity of rate functions as an instance of _ mechanical equilibrium _",
    "( i.e. , balance between mechanical forces ) , rather than thermal equilibrium , and then the chernoff parameter plays the physical role of an external _ force _ , or _ field _ , applied to the physical system in consideration . in this paradigm ,",
    "the large deviations rate function has a natural interpretation as the ( helmholtz ) _ free energy _ of the system , rather than as entropy .",
    "accordingly , since the rate  distortion function ( and similarly , also channel capacity ) can be thought of as a large deviations rate function , it can also be interpreted as the free energy of a certain system .",
    "this interpretation has several advantages .",
    "first , it is consistent with the analogy between the free energy in physics and the kullback ",
    "leibler divergence in information theory ( see , e.g. , @xcite,@xcite ) , which is well known to play a role as a rate function when the large deviations analysis is approached by the method of types @xcite .",
    "second , it is free of the limitations mentioned in the previous paragraph , as we will see in the sequel .",
    "third , it serves as a trigger to develop certain representations of the rate  distortion function ( and analogously , the channel capacity ) , which are new to the best knowledge of the author .    since the rate ",
    "distortion function can be thought of as free energy , as mentioned above , one of the representations of the rate  distortion function expresses it as ( the minimum achievable ) mechanical work carried out by the aforementioned external force , along a ` distance ' that is measured in terms of the distortion .",
    "another representation , which follows from the first one , is as an integral that involves the single ",
    "letter minimum mean square error ( mmse ) in estimating the distortion given the source symbol , according to a certain joint distribution of these two random variables .",
    "the latter representation may suggest a new route to the derivation of upper and lower bounds on the rate  distortion function and channel capacity , using the plethora of upper and lower bounds on mmse , available from estimation theory .",
    "in particular , for upper bounds , one may examine the mean squared error of an arbitrary estimator , e.g. , the best linear estimator .",
    "lower bounds , like the bayesian cramr  rao bound and numerous others are available in the literature ( cf .",
    "e.g. , @xcite,@xcite and references therein ) .",
    "we have not explored these directions , however , in the framework of the work presented herein .",
    "an additional byproduct of the proposed perspective is the following : given a source distribution and a distortion measure , we can describe ( at least conceptually ) a concrete physical system that emulates the rate  distortion problem in the following manner ( see fig .",
    "[ rd ] ) : when no force is applied to the system , its total length is @xmath0 , where @xmath1 is the number of particles in the system ( and also the block length in the rate ",
    "distortion problem ) , and @xmath2 is the distortion corresponding to zero coding rate . if one applies to the system a contracting force , that increases from zero force to some final force @xmath3 , such that the length of the system shrinks to @xmath4 ,",
    "where @xmath5 is analogous a prescribed distortion level , then the following two facts hold true : ( i ) an _ achievable lower bound _ on the total amount of mechanical work that must be carried out by the contracting force in order to shrink the system to length @xmath4 , is given by @xmath6 where @xmath7 is boltzmann s constant , @xmath8 is the temperature , and @xmath9 is the rate  distortion function .",
    "( ii ) the final force @xmath3 is related to @xmath10 according to @xmath11 , where @xmath12 is the derivative of @xmath13 .",
    "thus , we observe that @xmath9 plays a role of a fundamental limit , not only in information theory , but also in physics .",
    "the outline of the paper is as follows . in section 2 , we provide some background in physics ( subsection 2a ) and give a brief description of the physical interpretation proposed in @xcite ( subsection 2b ) .",
    "then , we develop the new proposed physical interpretation , first for a generic large deviations rate  function ( section 3 ) , and then , in the context of the rate  distortion problem ( section 4 ) . in section 5 ,",
    "we present the above mentioned alternative representations of the rate",
    " distortion function .",
    "finally , in section 6 , we summarize this work and conclude .",
    "consider a physical system with a large number @xmath1 of particles , which can be in a variety of microscopic states ( ` microstates ' ) , defined by combinations of , e.g. , positions , momenta , angular momenta , spins , etc .",
    ", of all @xmath1 particles . for each such microstate of the system , which we shall designate by a vector @xmath14 , there is an associated energy , given by an hamiltonian ( energy function ) , @xmath15 .",
    "for example , if @xmath16 , where @xmath17 is the momentum vector of particle number @xmath18 and @xmath19 is its height , then classically , @xmath20 where @xmath21 is the mass of each particle and @xmath22 is the gravitation constant .",
    "one of the most fundamental results in statistical physics ( based on the law of energy conservation and the basic postulate that all microstates of the same energy level are equiprobable ) is that when the system is in thermal equilibrium with its environment , the probability of a microstate @xmath23 is given by the _ boltzmann ",
    "distribution @xmath24 where @xmath25 , @xmath8 being temperature , @xmath7 being boltzmann s constant , and @xmath26 is the normalization constant , called the _ partition function _ , which is given by @xmath27 or @xmath28 depending on whether @xmath23 is discrete or continuous .",
    "the role of the partition function is by far deeper than just being a normalization factor , as it is actually the key quantity from which many macroscopic physical quantities can be derived , for example , the helmholtz free energy is @xmath29 , the average internal energy ( i.e. , the expectation of @xmath15 where @xmath23 drawn is according ( [ bd ] ) ) is given by the negative derivative of @xmath30 , the heat capacity is obtained from the second derivative , etc .",
    "one of the ways to obtain eq .",
    "( [ bd ] ) , is as the maximum entropy distribution under an energy constraint ( owing to the second law of thermodynamics ) , where @xmath31 plays the role of a lagrange multiplier that controls this energy level .    under certain assumptions on the hamiltonian function , the following relations are well  known to hold and can be found in any textbook on elementary statistical physics ( see , e.g. , @xcite,@xcite,@xcite ) : defining the per  particle entropy , @xmath32 , associated with per  particle energy @xmath33 , as @xmath34/n$ ] , , which we will omit in this discussion , thus considering @xmath32 as the per  particle entropy in units of @xmath7 . ]",
    "( provided that the limit exists ) , where @xmath35 is the number of microstates @xmath36 with energy level @xmath37 , then similarly as in the method of types , one can evaluate @xmath26 defined above , as @xmath38 ( in the discrete case ) , which is of the exponential order of @xmath39\\}.\\ ] ] defining @xmath40 and the helmholtz free  energy per  particle as @xmath41 we obtain the legendre relation @xmath42,\\ ] ] where here @xmath43 is the maximizer of @xmath44 $ ] . for a given @xmath31 , the boltzmann ",
    "gibbs distribution has a sharp peak ( for large @xmath1 ) at the level of @xmath45 joules per  particle . assuming that @xmath46 is concave ( which is normally the case ) , the above legendre relation can be inverted to obtain @xmath47,\\ ] ] and both relations can be identified with the thermodynamical definition of the helmholtz free energy as @xmath48 in the latter relation , the minimizing @xmath49 ( the inverse function of @xmath45 ) is the equilibrium inverse temperature associated with energy level @xmath50 .",
    "the second law of thermodynamics asserts that in an isolated system ( which does not exchange energy with its environment ) , the total entropy can not decrease , and hence in equilibrium , it reaches its maximum . when the system is allowed to exchange heat with the environment ( at constant volume and temperature ) , this maximum entropy principle is replaced by the _ minimum free energy _ principle : the helmholtz free energy can not increase , and it reaches its minimum in equilibrium .    when the hamiltonian is additive , that is , @xmath51 then @xmath52 has a product form ( the particles do not interact ) , and then the above mentioned physical quantities per particle can be extracted from the case @xmath53 . in this additive case ,",
    "the legendre transform , that takes @xmath54 to @xmath32 , is similar to the legendre transform that defines the rate function ( the exponent of the chernoff bound ) pertaining to the probability of the event @xmath55 thus the parameter to be optimized in the chernoff bound plays the role of inverse temperature in the corresponding statistical  mechanical system .",
    "another look at this correspondence between large deviations rate functions and thermal equilibrium is the following : if @xmath56 is the above mentioned boltzmann  gibbs distribution and @xmath57 is another probability distribution on the micorstates @xmath36 , then , as is shown e.g. , in @xcite , the kullback ",
    "leibler divergence between @xmath57 and @xmath56 is given by @xmath58 where @xmath59 and @xmath60 are , respectively , the helmholtz free energies pertaining to @xmath56 and @xmath57 .",
    "the rate function pertaining to a large deviations event is normally given by the minimum divergence under the constraints corresponding to this event ( see , e.g. , ( * ? ? ?",
    "11 ) ) , and so , it is equivalent to minimum free energy , i.e. , thermal equilibrium by the second law .    consider next a system of @xmath1 non  interacting particles as before , except that now the hamiltonian is shifted by a quantity that is proportional to some parameter @xmath3 , i.e. , the hamiltonian is redefined as @xmath61 where we have changed the notation of the ( original ) hamiltonian to @xmath62 , and where @xmath63 are some additional variables used to describe the microstate .",
    "these new variables may either be dependent or independent of the original microstate variables @xmath64 ( both cases are demonstrated in example 1 below ) and their number , @xmath1 , is here taken to be the same as the number of @xmath64 , primarily , for reasons of convenience .. ] the parameter @xmath3 is thought of as an external control parameter , i.e. , a _ driving force _ ( or a field ) that acts on the system via the state variables @xmath63 . the parameter @xmath3 can be a mechanical force ( e.g. , pressure , elastic extraction / contraction force , gravitational force ) , an electric field ( acting on an a charged particle or an electric dipole ) , a magnetic field ( acting on a magnet or spin ) , or even a chemical driving force ( chemical potential ) .",
    "+ _ example  1 _ ( may be skipped without loss of continuity ) .",
    "consider the following two systems .",
    "the first is the same example as in the first paragraph of this subsection , namely , non  interacting particles in motion under gravitation .",
    "the hamiltonian , @xmath65 can be thought of as being composed of the ` original ' hamiltonian @xmath66 ( with @xmath67 replacing @xmath68 ) , and the ` shifting ' term , @xmath69 , whose force parameter is @xmath70 ( gravitational force ) , acting on the height variables @xmath71 . in this example , the variables @xmath72 and @xmath73 are independent .",
    "the second system consists of @xmath1 one  dimensional harmonic oscillators ( e.g. , springs or pendulums ) , where the hamiltonian is @xmath74 @xmath75 being the ( one  dimensional ) momentum , @xmath76  the displacement of each oscillator from its equilibrium position , and @xmath77 is the elasticity constant . now , suppose that an external force @xmath3 is applied to each spring , so the hamiltonian becomes @xmath78 in this case , the variables of the original hamiltonian @xmath79 contain the variables @xmath63 , of the shifting term , as a subset .",
    "we also see that the modified hamiltonian is , within an immaterial additive constant , identical to @xmath80.\\ ] ] this means that the force @xmath3 shifts the common mean of the rv s @xmath63 , which is equilibrium point of all oscillators , by @xmath81 , as expected .",
    "this concludes example 1 .",
    "@xmath82    consider next the partition function @xmath83}.\\ ] ] the _ gibbs free energy _",
    ", in an isothermal process with fixed @xmath3 , in the passage between these two points .",
    "] per particle is defined as @xmath84 and the asymptotic gibbs free energy per particle is @xmath85 what is the relation between between the helmholtz free energy and the gibbs free energy ?",
    "let @xmath86 denote the number of microstates @xmath87 for which @xmath88 then , defining the partial partition function @xmath89 the normalized helmholtz free energy for a given @xmath90 @xmath91 and the corresponding asymptotic normalized helmholtz free energy , @xmath92 we have ( similarly as in the method of types ) : @xmath93}\\nonumber\\\\ & = & \\sum_{e , y}\\omega(e , y)e^{-\\beta(ne-\\lambda ny)}\\nonumber\\\\ & { \\stackrel{\\cdot } { = } } & \\sum_{e , y}e^{n[s(e , y)-\\beta(e-\\lambda y)]}\\nonumber\\\\ & = & \\sum_{y}e^{n\\beta\\lambda y}\\sum_e e^{n[s(e , y)-\\beta e]}\\nonumber\\\\ & = & \\sum_{y}e^{n\\beta\\lambda y}z_n(\\beta , y)\\nonumber\\\\ & = & \\sum_{y}e^{n\\beta\\lambda y}\\cdot e^{-\\beta nf_n(\\beta , y)}\\nonumber\\\\ & { \\stackrel{\\cdot } { = } } & \\exp\\{n\\beta\\cdot\\max_y[\\lambda y - f(\\beta , y)\\}\\end{aligned}\\ ] ] where @xmath94 denotes asymptotic equivalence in the exponential scale . , for two positive sequences @xmath95 and @xmath96 , means that @xmath97 , as @xmath98 . ]",
    "this results in the legendre relation @xmath99.\\ ] ] assuming that @xmath100 is convex in @xmath90 for fixed @xmath31 , the inverse legendre relation is @xmath101\\nonumber\\\\ & = & \\max_{\\lambda}\\left[\\lambda y - kt\\times\\right.\\nonumber\\\\ & & \\left.\\lim_{n\\to\\infty}\\frac{1}{n}\\ln\\left(\\sum_{{\\mbox{\\boldmath $ x$}},{\\mbox{\\boldmath $ y$ } } } e^{-\\beta[{{\\cal e}}_0({\\mbox{\\boldmath $ x$}})-\\lambda\\sum_iy_i]}\\right)\\right]\\nonumber\\\\ & = & kt\\cdot\\max_{\\lambda}\\left[\\beta\\lambda y-\\right.\\nonumber\\\\ & & \\left.\\lim_{n\\to\\infty}\\frac{1}{n}\\ln\\left(\\sum_{{\\mbox{\\boldmath $ x$}},{\\mbox{\\boldmath $ y$ } } } e^{-\\beta{{\\cal e}}_0({\\mbox{\\boldmath $ x$}})}\\cdot e^{\\beta\\lambda\\sum_iy_i}\\right)\\right]\\nonumber\\\\ & = & kt\\cdot\\max_{s}\\left[sy-\\right.\\nonumber\\\\ & & \\left.\\lim_{n\\to\\infty}\\frac{1}{n}\\ln\\left(\\sum_{{\\mbox{\\boldmath $ x$}},{\\mbox{\\boldmath $ y$ } } } e^{-\\beta{{\\cal e}}_0({\\mbox{\\boldmath $ x$}})}\\cdot e^{s\\sum_iy_i}\\right)\\right]\\end{aligned}\\ ] ] where in the last step , we changed the optimization variable @xmath3 to @xmath102 for fixed @xmath31 . since @xmath103 is proportional to @xmath3 for fixed @xmath31 , and @xmath3 designates force , we will henceforth refer to @xmath103 also as ` force ' ( although its physical units are different ) .",
    "we will get back to eq .",
    "( [ flegendre ] ) soon .",
    "first , recall that in the previous subsection , we mentioned that the legendre relation @xmath104\\ ] ] is similar to the rate function of the large deviations event @xmath105 for i.i.d .",
    "rv s @xmath64 , governed by a given distribution @xmath56 .",
    "the difference is that in the latter , the log  moment generating function @xmath106 that undergoes the legendre transform , contains weighting by the probabilities @xmath107 , unlike the log ",
    "partition @xmath108 which does not .",
    "in @xcite it was proposed to interpret the weights @xmath107 as being proportional to a factor of the multiplicity of states @xmath109 having the same energy @xmath110 , i.e. , as the _ degeneracy _ in the physics terminology . as part of the hamiltonian , but then the hamiltonian becomes temperature  dependent , but this does not comply with the common paradigm in statistical mechanics . ]",
    "when considering applications of large deviations theory to information theory , one can view the rate  distortion function ( and analogously , also channel capacity ) as the large  deviations rate function of the event @xmath111 , where @xmath14 is a given typical source sequence ( i.e. , its empirical distribution agrees with the source @xmath56 ) and @xmath112 are i.i.d .",
    "rv s drawn by a certain random coding distribution @xmath57 . as was observed in @xcite , there are two ways to express the large deviations rate function of this event , which is also the rate  distortion function , @xmath113 , for the given random distribution @xmath57 : the first is by considering all distortion variables @xmath114 together , on the same footing , resulting in the expression @xmath115,\\ ] ] which can also be obtained ( see , e.g. , ( * ? ? ?",
    "* , corollary 4.2.3 ) ) using different considerations .",
    "the second way is to separate the distortion contributions , @xmath116 , allocated to the various source letters @xmath109 , which results in @xmath117.\\nonumber\\end{aligned}\\ ] ] the identity between these two expressions , as was proved in @xcite , means that the outer maximum in the second expression ( maximum entropy ) is achieved when @xmath116 are allocated in such a way that the minimizing temperature parameters @xmath118 are all the same , namely , thermal equilibrium between all subsystems indexed by @xmath119 .",
    "once again , @xmath120 can be interpreted as degeneracy , which is fine as long as @xmath57 is fixed .",
    "however , the real rate  distortion function , @xmath121 , is obtained by optimization ( of either expression ) over @xmath57 and the optimum @xmath57 may , in general , depend on @xmath31 ( or equivalently , on @xmath10 ) .",
    "in this situation , @xmath57 can no longer be given the meaning of degeneracy , because in physics , degeneracy has nothing to do with temperature .",
    "another limitation of interpreting @xmath31 as temperature , is that it does not extend to two or more rare events at the same time .",
    "for instance , the rate  distortion function @xmath122 w.r.t .  two simultaneous distortion constraints , with distortion measures @xmath123 and @xmath124 , is given by the two  dimensional legendre transform @xmath125.\\end{aligned}\\ ] ] but this does not have any apparent physical interpretation because there is only one temperature in physics .",
    "the main idea in this paper is that in order to give a physical interpretation to the rate function as the legendre transform of the log  moment generating function , we use the legendre transform that relates the helmholtz free energy to the gibbs free energy , @xmath126 ( cf .",
    "( [ flegendre ] ) ) , rather than the one that relates the helmholtz free energy to the entropy , @xmath32 .",
    "thus , the chernoff variable would be the force @xmath3 ( or @xmath103 ) rather than the inverse temperature @xmath31 .",
    "also , considering the temperature as being fixed throughout , we can view the weights @xmath120 ( in the rate  distortion application ) as part of the hamiltonian @xmath127 , which now may depend on the control parameter @xmath3 .",
    "this also allows combinations of two or more large deviations events since one may consider a system that is subjected to more than one force , e.g. , two or three components of same force , or a superposition of different types of forces .",
    "specifically , let us first compare the helmholtz free energy expression ( [ flegendre ] ) to the rate function @xcite of the simple large deviations event @xmath128 w.r.t .",
    "some probability distribution @xmath56 : @xmath129\\ ] ] which in the case where @xmath63 are i.i.d .",
    "( @xmath130 ) , boils down to @xmath131.\\ ] ] fixing the temperature @xmath8 to some @xmath132 , taking @xmath133 and @xmath134 , we readily see that @xmath135 coincides with @xmath136 up to the multiplicative constant factor of @xmath137 , which is immaterial .",
    "we observe then that the large deviations rate function has a natural interpretation as the helmholtz free energy ( in units of @xmath137 ) of a system with hamiltonian @xmath138 and temperature @xmath139 .",
    "as said , the chernoff parameter @xmath103 has ( again , within the factor @xmath140 ) the meaning of a driving force that acts on the displacement variables @xmath63 ( cf .",
    "e.g. , the above example of the one  dimensional harmonic oscillator , which makes it explicit ) .",
    "for example , in the i.i.d .",
    "case , the driving force @xmath103 required to shift the expectation of each @xmath76 ( and hence also of @xmath141 ) towards @xmath90 , which is the solution to the equation @xmath142 or equivalently , @xmath143 the legendre transform relation between the log  partition function and @xmath135 induces a one  to ",
    "one mapping between @xmath90 and @xmath103 which is defined by the above equation . to emphasize this dependency",
    ", we henceforth denote the value of @xmath90 , corresponding to a given @xmath103 , by @xmath144 , which symbolizes the fact that it is the expectation to denote other moments of @xmath145 w.r.t .",
    "@xmath146 as well . ] of each @xmath76 , denoted generically by @xmath145 , w.r.t .  the probability distribution @xmath147 , where @xmath148,\\ ] ] i.e.",
    ", @xmath149 on substituting @xmath144 instead of @xmath90 in the expression defining @xmath135 , we can re - define the rate function as a function of ( the maximizing ) @xmath103 , i.e. , @xmath150 note that @xmath151 can be represented in an integral form as follows : @xmath152 now observe that the integrand is a product of the force , @xmath153 , and an infinitesimal displacement that it works upon , @xmath154 ( which in turn is the response of the system to a corresponding infinitesimal change in the force from @xmath155 to @xmath153 ) . in physical terms",
    ", @xmath156 is therefore an infinitesimal contribution of the average _ work _ ( in units of @xmath137 ) done by the driving force @xmath153 on the displacement variables @xmath63 .",
    "thus , the integral , @xmath157 is the total amount of work ( again , in units of @xmath137 ) carried out by the force @xmath153 , as it increases from zero to @xmath103 during a slow process that allows the system to equilibrate after every infinitesimally small change in @xmath153 . in the language of physics , this is a _ reversible process _ , or a _ quasi - static process_. using the concavity of @xmath158 as a function of @xmath103 ,",
    "it is easy to show that any protocol of changing @xmath153 from @xmath159 to @xmath103 , in a way that includes abrupt changes in @xmath153 , would always yield an amount of work larger than or equal to @xmath151 ( which is consistent with the operative meaning of @xmath151 as the free energy of the system  see footnote no .  1 ) .",
    "thus , for any sequence , @xmath160 , of numbers between @xmath159 and @xmath103 , we can sandwich @xmath151 between two bounds @xmath161 which become tighter and tighter as the partition of the interval @xmath162 $ ] , defined by @xmath163 , becomes more refined .",
    "for an alternative integral expression , one observes that @xmath164 , namely , the variance of @xmath145 w.r.t .  the probability distribution @xmath146 .",
    "thus , @xmath165 and @xmath166 note that , by the same token , in the interpretation of @xcite , where the chernoff parameter was the inverse temperature @xmath31 , that is conjugate to the hamiltonian @xmath167 , the corresponding integral could have been represented as @xmath168 , @xmath57 being heat , which is the change of entropy along a reversible process .",
    "the corresponding variance expressions would then be related to the heat capacity at constant volume . in the more general context considered here , this is a special case of the fluctuation ",
    "dissipation theorem in statistical physics ( cf .",
    "e.g. , ( * ? ? ?",
    "* , eq .  ( 2.44 ) ) ) .",
    "we next discuss a physical example which will be directly relevant for the rate  distortion problem .    _",
    "example  2 _ ( * ? ? ?",
    "* , problem 13 ) : consider a physical system , modeled as a one  dimensional array of @xmath1 elements ( depicted as small springs in fig",
    ".  [ chain ] ) , that are arranged along a straight line .",
    "each element may independently be in one of two states , @xmath169 or @xmath170 ( e.g. , in state @xmath169 the element is stretched and in state @xmath170 , it is contracted , according to fig .  [ chain ] ) .",
    "the state of the @xmath18th element , @xmath171 , is labeled @xmath172 .",
    "when an element is at state @xmath173 , its length is @xmath174 and its internal energy is @xmath175 .",
    "a stretching force @xmath176 ( or a contracting force , if @xmath177 ) is applied to one edge of the array , whereas the other edge is fixed to a wall .",
    "what is the expected ( and most probable ) total length @xmath178 of the array at temperature @xmath139 ?",
    "since the elements are independent , @xmath179\\right\\}\\nonumber\\\\ & = & [ e^{-\\beta_0(\\epsilon_a-\\lambda y_a)}+e^{-\\beta_0(\\epsilon_b-\\lambda y_b)}]^n,\\end{aligned}\\ ] ] and so , @xmath180.\\nonumber\\end{aligned}\\ ] ] the expected length is @xmath181 } { e^{-\\beta_0(\\epsilon_a-\\lambda y_a)}+ e^{-\\beta_0(\\epsilon_b-\\lambda y_b)}}.\\end{aligned}\\ ] ] in terms of the foregoing discussion , @xmath182 , the force scaled by @xmath140 , controls the expected length per element which is @xmath183 the free energy per element is then @xmath184+kt_0sy\\ ] ] where @xmath103 is related to @xmath90 according to second to the last equation , which is also the value of @xmath103 that maximizes the last expression .",
    "consider now two arrays as above , labeled by @xmath185 , which consist of two different types of elements .",
    "array @xmath119 has @xmath186 elements , and as before , each element of this array may be in one of two states , @xmath169 or @xmath170 .",
    "when an element of array @xmath119 is at state @xmath173 , its length is @xmath187 and its internal energy is @xmath188 .",
    "the two arrays are connected together to form a larger system with a total of @xmath189 elements , and this larger system is stretched ( or shrinked ) so that its edges are fixed at two points which are at distance @xmath190 far apart .",
    "what is the contribution of each individual array to the total length , @xmath191 , and what is the force ` felt ' by each one of them ?    denoting @xmath192 and @xmath193 , the total free energy per element is given by @xmath194 where @xmath195 and @xmath196 are the helmholtz free energies per element ( cf .",
    "above ) pertaining to the two arrays , respectively , and @xmath197 and @xmath198 are their normalized lengths . at equilibrium",
    ", @xmath199 minimizes this expression , and the minimizing @xmath199 solves the equation : @xmath200 but the left ",
    "hand side is @xmath201 , the force felt by array ( a ) , and similarly , the right  hand side is @xmath202 , the force felt by array ( b ) .",
    "the last equation tells us that in mechanical equilibrium they are equal , which makes sense , as otherwise the boundary point between the two arrays would keep moving in either direction . in other words , the equilibrium values of @xmath197 and @xmath198",
    "are adjusted in a way that @xmath203\\ ] ] and @xmath204\\ ] ] would be both maximized by the _",
    "same _ value of @xmath3 ( or , equivalently , @xmath103 ) .",
    "in this situation , the same value of @xmath3 would also achieve the maximum of the weighted sum : @xmath205,\\ ] ] which treats the entire system as a whole .",
    "the maximizing value of @xmath3 is the one that corresponds to total length @xmath206 .",
    "this concludes example  2 .",
    "@xmath82    in the next section , we will see how example 2 ( especially , it second part , with two connected arrays of elements ) is directly applicable to the rate  distortion setting .",
    "let us consider now the rate  distortion coding problem . we are given a source sequence @xmath14 to be compressed , whose letters @xmath64 take on values in a finite alphabet @xmath207 of size @xmath77 .",
    "we assume that the source has a given empirical distribution @xmath208 ( typically , close to the real distribution ) , i.e. , each letter @xmath209 appears @xmath210 times in @xmath23 .",
    "next consider a random selection of a reproduction codeword @xmath211 , where each reproduction symbol @xmath212 is drawn i.i.d .  from a distribution @xmath213 , where @xmath214 is a finite reproduction alphabet of size @xmath215 .",
    "for the most part of our discussion , it will be assumed that even if the desired distortion level varies , the random coding distribution @xmath57 is nevertheless kept fixed , for the sake of simplicity . may depend on @xmath103 , or equivalently on @xmath10 . in the sequel",
    ", we describe certain processes along which the distortion level varies , starting from a very high distortion level @xmath2 , and ending at a given , desired distortion level , @xmath10 . to make a statement concerning the rate  distortion function , computed at the latter distortion level , @xmath9 , we can always pick the optimum @xmath57 for this target value of @xmath10 and keep it fixed , even when considering the above  mentioned higher distortion levels .",
    "thus , in these processes , for distortion levels above @xmath10 , we will , in general , ` move ' along the curve @xmath216 , which is the rate ",
    "distortion function with an output distribution constrained to @xmath57 , rather than the curve @xmath13 .",
    "of course , the two curves intersect at distortion @xmath10 . the analysis can be modified to allow @xmath57 depend on @xmath103 along the process ( see comment no .  4 on this in section 6 ) . ]",
    "it is well known that the rate  distortion function of the source @xmath56 , w.r.t.a given distortion measure @xmath217 , is given by the rate function of the large deviations event @xmath218 .    occasionally , instead of working with the reproduction symbols as our rv s , we will sometimes work directly with the distortions",
    "@xmath114 incurred , which will be denoted by @xmath219 ( playing the same role as @xmath63 thus far ) .",
    "accordingly , we define @xmath220 thus , we think of the distortion @xmath221 as a rv drawn from a distribution @xmath222 indexed by the corresponding source symbol @xmath119 , rather than as a function of @xmath119 and a rv @xmath173 , whose distribution @xmath223 does not depend on @xmath119 .",
    "the large deviations event under consideration is then @xmath224 , where @xmath219 are still independent , but no longer identically distributed . for each @xmath209 ,",
    "@xmath210 of these rv s are drawn from @xmath222 .",
    "the large deviations rate function , obtained when all @xmath219 are handled as a whole , is given by @xmath225.\\ ] ] in analogy to the results of @xcite ( see also subsection 2a ) , another look is the following : consider the partial distortions , sorted according to the underlying source symbols , i.e. , for each @xmath209 , @xmath226 is the total distortion contributed by @xmath119 . clearly , the large deviations event under discussion occurs iff there exists a distortion allocation @xmath227 with @xmath228 such that @xmath229 for all @xmath209 .",
    "thus , it can be thought of as the union ( over all possible distortion allocations ) of the intersections ( over @xmath207 ) of the independent events @xmath230 . as shown in @xcite ,",
    "since the effective number of distortion allocations is polynomial in @xmath1 , the probability is dominated by the worst allocation , which yields @xmath231.\\end{aligned}\\ ] ] we argue that @xmath232 and hence both coincide with the rate ",
    "distortion function @xmath113 w.r.t .",
    "the random coding distribution @xmath57 .",
    "before we prove it formally , we comment that the intuition comes from interpreting the expressions of the rate functions in the framework of the above example of stretching / contracting concatenated one dimensional arrays of elements . here",
    ", we have @xmath233 different arrays at temperature @xmath139 , concatenated together to form one larger system with a total of @xmath1 elements .",
    "each individual array is labeled by @xmath209 and it contains @xmath210 elements .",
    "each such element may be in one of @xmath215 states , labeled by @xmath234 .",
    "the ` length ' and the internal energy of an element of array @xmath119 at state @xmath173 are @xmath235 and @xmath236 ( independent of @xmath119 ) , respectively . upon identifying this mapping between the rate  distortion problem and the physical example , we immediately see that their mathematical formalisms , and hence also their properties , are precisely the same . indeed , the expression of @xmath237 is the helmholtz free energy ( in units of @xmath137 ) per element ( pertaining to the entire system as a whole ) when the total length is shrinked to @xmath4 . on the other hand ,",
    "the expression of @xmath238 describes the _ minimum _ helmholtz free energy ( again , in units of @xmath137 ) across all partial length allocations @xmath239 that comply with a total length not exceeding @xmath4 .",
    "but this minimum free energy is achieved when all individual arrays ` feel ' the same force , i.e. , the same value of @xmath240 .",
    "hence , the two expressions should coincide .",
    "this means , among other things , that the typical relative contribution of each source symbol @xmath119 to the distortion behaves exactly like the relative lengths of the individual arrays when they lie in mechanical equilibrium .",
    "formally , the following proof is similar to that of ( * ? ? ?",
    "* theorem 1 ) , but for completeness , we provide it here too .",
    "we first prove that @xmath241 and then the reversed inequality .",
    "@xmath242\\nonumber\\\\ & = & \\min_{\\{{{\\cal d}}:~\\sum_{x\\in{{\\cal x}}}p(x)\\delta_x\\le \\delta\\}}\\sum_{x\\in{{\\cal x}}}\\max_{s_x\\le 0}\\left[s_xp(x)\\delta_x-\\right.\\nonumber\\\\ & & \\left.p(x)\\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s_x\\delta}\\right)\\right]\\nonumber\\\\ & \\ge&\\min_{\\{{{\\cal d}}:~\\sum_{x\\in{{\\cal x}}}p(x)\\delta_x\\le \\delta\\}}\\max_{s\\le 0}\\sum_{x\\in{{\\cal x}}}\\left[sp(x)\\delta_x-\\right.\\nonumber\\\\ & & \\left.p(x)\\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s\\delta}\\right)\\right]\\nonumber\\\\ & \\ge&\\min_{\\{{{\\cal d}}:~\\sum_{x\\in{{\\cal x}}}p(x)\\delta_x\\le \\delta\\}}\\max_{s\\le 0 } \\left[s\\sum_{x\\in{{\\cal x}}}\\delta_xp(x)-\\right.\\nonumber\\\\ & & \\left.\\sum_{x\\in{{\\cal x}}}p(x ) \\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s\\delta}\\right)\\right]\\nonumber\\\\ & \\ge&\\min_{\\{{{\\cal d}}:~\\sum_{x\\in{{\\cal x}}}p(x)\\delta_x\\le \\delta\\}}\\max_{s\\le 0 } \\left[s\\delta-\\right.\\nonumber\\\\ & & \\left.\\sum_{x\\in{{\\cal x}}}p(x ) \\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s\\delta}\\right)\\right]\\nonumber\\\\ & = & \\max_{s\\le 0 } \\left[s\\delta-\\sum_{x\\in{{\\cal x}}}p(x)\\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s\\delta}\\right)\\right]\\nonumber\\\\ & = & i(\\delta),\\end{aligned}\\ ] ] where we have used the fact that the sum of maxima is can not be smaller than the maximum of a sum , as well as the fact that the optimum @xmath103 is to be sought in the range @xmath243 , and so , @xmath244 implies @xmath245 .    in the other direction ,",
    "let @xmath246 be the achiever of @xmath237 , namely , the solution @xmath103 to the equation @xmath247 and consider the distortion allocation @xmath248_{s = s^*}\\ ] ] which obviously complies with the overall distortion constraint .",
    "thus , @xmath249\\nonumber\\\\ & \\le & \\sum_{x\\in{{\\cal x}}}p(x)\\cdot\\max_{s_x\\le 0}\\left[s_x\\delta_x^*- \\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s_x\\delta}\\right)\\right]\\nonumber\\\\ & = & \\sum_{x\\in{{\\cal x}}}p(x)\\left[s^*\\delta_x^*- \\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s^*\\delta}\\right)\\right]\\nonumber\\\\ & = & s^*\\delta- \\sum_{x\\in{{\\cal x}}}p(x)\\ln\\left(\\sum_{\\delta}q(\\delta|x)e^{s^*\\delta}\\right)\\nonumber\\\\ & = & i(\\delta).\\end{aligned}\\ ] ] this completes the proof that @xmath232 .",
    "@xmath82 + _ comment : _ as noted in @xcite , our discussion in this section , as well as in the next section , applies to channel capacity too , provided that @xmath250 is understood as the channel output distribution , @xmath251 is the random ( channel ) coding distribution , the distortion measure is taken to be @xmath252 , where @xmath253 is the transition probability matrix associated with the memoryless channel , and the `` distortion level '' is set to @xmath254 . in this case",
    ", the maximizing @xmath103 is always @xmath255 .",
    "in view of the observations made in section 3 , it is interesting to represent the rate  distortion function as mechanical work carried out on the distortion variable along a reversible process , as well as in terms of the integrated variance of the distortion : @xmath256 where @xmath103 is related to @xmath10 via the relation @xmath257 and where @xmath258 and @xmath259 are defined in the spirit of the earlier definitions of @xmath144 and @xmath260 except that @xmath145 is replaced by @xmath221 and @xmath146 now includes conditioning on @xmath119 .",
    "i.e. , @xmath261 and @xmath262 upper and lower bounds can be obtained from @xmath263 the integrated variance formula above can also be represented as @xmath264 where @xmath265 is the minimum mean squared error ( mmse ) in estimating the rv @xmath221 based on @xmath119 , when they are jointly distributed according to @xmath266 , with @xmath267 being defined as @xmath268 at the same time , the distortion itself , @xmath269 , which we also denote by @xmath10 , can be represented using similar integrals , but without the factor @xmath153 at the integrand : @xmath270\\nonumber\\\\ & = & \\delta_0 + \\int_0^s\\mbox{d}{\\hat{s}}\\cdot\\mbox{mmse}({\\hat{s}}).\\end{aligned}\\ ] ]    _ example  3 . _",
    "consider the binary symmetric source ( bss ) and the hamming distortion measure . in this case , the optimum @xmath57 is also symmetric . here",
    "@xmath221 is a binary rv with @xmath271 independently of @xmath119 .",
    "thus , the mmse estimator of @xmath221 based on @xmath119 is @xmath272 regardless of @xmath119 , and so the resulting mmse is easily found to be @xmath273 accordingly , @xmath274 and @xmath275 where @xmath276 is the binary entropy function .",
    "this concludes example  3 .",
    "@xmath82    the integrated variance expression can be generalized as follows : let @xmath277 be a given function of @xmath119 and @xmath173 and let @xmath278 denote the expectation of @xmath279 w.r.t .  the joint distribution of @xmath119 and @xmath173 defined by @xmath280 this characterizes the expected ( and typical ) value of @xmath281 , where @xmath282 continues to be the codeword that encodes @xmath23 from a rate  distortion code designed and operated with the metric @xmath283 .",
    "is another distortion measure  although the codebook is designed and operated relative to the metric @xmath283 , its performance can also be judged relative to an additional metric @xmath284 .",
    "if @xmath279 depends on @xmath173 only , it may serve as a transmission power function @xmath285 ( in joint source  channel coding ) or it can be the length function @xmath286 ( in bits ) of lossless compression for the individual reproduction symbols . ] then , @xmath287 where @xmath288 is the covariance between @xmath277 and @xmath289 , induced by @xmath290 for fixed @xmath119 .",
    "this is integral form is a somewhat more general version of the fluctuation ",
    "dissipation theorem , mentioned above .",
    "in this work , we have proposed another look at large deviations rate functions ( or chernoff functions ) , where the chernoff parameter is viewed as ` force ' rather than as temperature .",
    "this leads to the interpretation of fundamental quantities in information theory , like the rate ",
    "distortion function and channel capacity , as free energies of certain physical systems .",
    "this interpretation has the following advantages relative to the one proposed in @xcite : + 1 ) as explained in subsection 2b , there is no need to interpret random coding distributions as degeneracy .",
    "+ 2 ) as a consequence of 1 ) , we are able to construct an example of a physical system whose behavior is analogous to that of the rate  distortion coding problem .",
    "the properties of this system were described in the second to the last paragraph of the introduction .",
    "+ 3 ) this interpretation generalizes to rate functions of combinations of rare events . in this case , the rate function involves several chernoff variables ( one per each event ) , which may correspond to a system with several forces , each one acting on its own variable ( cf.@xmath291 in subsection 2b ) .",
    "our earlier physical example of a one  dimensional array can now be extended to two dimensions , where the elements are arranged in a rectangular lattice , and each element has both a length and a width associated with each state .",
    "the sum @xmath292 $ ] can be viewed as the inner product between a two dimensional force vector and a two  dimensional displacement vector .",
    "alternatively , @xmath293 and @xmath294 may designate two different types of forces ( e.g. , a mechanical force and a magnetic force ) . either way",
    ", our derivations extend quite straightforwardly to this setting .",
    "+ 4 ) as mentioned before , we assumed throughout the derivation that the random coding distribution is fixed , independently of the distortion level , that is , independently of @xmath103 .",
    "this is why we described @xmath9 as a process along the curve @xmath216 with the understanding that @xmath57 is chosen to be optimum for the target distortion @xmath10 .",
    "one can modify the analysis to correspond to a process along @xmath13 .",
    "as mentioned earlier , however , in most cases , the optimum @xmath57 depends on @xmath103 , and this dependency requires correction terms that depend on the expected values of some derivatives of @xmath295 w.r.t .  @xmath103 . in the analogous physical interpretation proposed here , @xmath103 continues to be an external control parameter that affects the hamiltonian .",
    "the dependence of the hamiltonian on @xmath103 would now be non  linear , but this may still be physically relevant .",
    "+ 5 ) this interpretation as free energy opens the door to new points of view on the rate ",
    "distortion function , e.g. , as work done on the distortion variable along a slow process , or as integrated variance ( or mmse ) .",
    "n.  merhav , `` an identity of chernoff bounds with an interpretation in statistical physics and applications in information theory , '' _ ieee trans .",
    "theory _ , vol .",
    "54 , no .  8 , pp.37103721 , august 2008"
  ],
  "abstract_text": [
    "<S> we revisit and extend the physical interpretation recently given to a certain identity between large  deviations rate  functions ( as well as applications of this identity to information theory ) , as an instance of thermal equilibrium between several physical systems that are brought into contact . our new interpretation , of mechanical equilibrium between these systems , </S>",
    "<S> is shown to have several advantages relative to that of thermal equilibrium . </S>",
    "<S> this physical point of view also provides a trigger to the development of certain alternative representations of the rate  distortion function and channel capacity , which are new to the best knowledge of the author .    </S>",
    "<S> large deviations theory , chernoff bound , statistical physics , free energy mechanical equilibrium , rate  distortion theory . </S>"
  ]
}