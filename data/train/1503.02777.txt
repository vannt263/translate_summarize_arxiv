{
  "article_text": [
    "gamma oscillations are rhythmic patterns of neural activity in the 30 - 80hz frequency range that have been measured in the extracellular fields of multiple brain areas across many species  @xcite .",
    "they have been associated with attention  @xcite , working memory@xcite , and the execution of cognitive tasks  @xcite .",
    "local rhythmic inhibition is a fundamental feature of gamma oscillations  @xcite that acts to modulate the firing rate of the local circuit as well as its sensitivity to external input  @xcite .",
    "although many studies have elucidated several aspects of the biophysical mechanisms underlying gamma - band rhythmic inhibition  @xcite , its computational and functional role is still a matter of debate  @xcite .    in this paper",
    ", we investigate the functional role of local gamma - band rhythmic inhibition in rate - based networks of neurons configured as coupled winner - take - all ( wta ) circuits .",
    "the wta circuits are used as models of local cortical circuit motifs  @xcite .",
    "the strength of the effective connectivity between a pair of coupled wtas is continuously modulated by the phase difference between their local rhythms .",
    "higher coherence between these rhythms leads to more reliable communication between the wta pair in line with the `` communication through coherence '' hypothesis  @xcite . on a global level",
    ", we show that oscillatory inhibition drastically alters the dynamics of coupled wta networks and allows them to search for activity states that best satisfy the constraints encoded in the network connectivity while being consistent with the externally applied inputs .",
    "we show that rhythmic inhibition effectively allows neural networks to solve constraint satisfaction problems which are among the most difficult classes of computational problems .",
    "this result is particularly relevant to neural models of sensory processing .",
    "a long theoretical tradition casts sensory processing as being a process of inferring the maximally consistent interpretations of imperfect sensory input where consistency is judged according to an internal model of the environment constructed from prior experience  @xcite .",
    "there are two fundamental questions that arise when considering the neural substrate underlying the search for consistent interpretations : ( 1 ) how to _ learn and represent _ the consistency model ; ( 2 ) how to use the consistency model to obtain _ plausible interpretations _ of ambiguous inputs . the networks we describe address these two questions within a biologically realistic framework .",
    "several neural architectures have been proposed whose dynamics execute a search for configurations that maximally satisfy a set of constraints .",
    "one such architecture uses hopfield networks that are engineered so that their energy functions have the deepest minimum at the maximally consistent state  @xcite which thus becomes a stable point of the network dynamics . in general , however , there are other non - optimal network states that are also dynamically stable states .",
    "there is no guarantee that the network will not get stuck in these sub - optimal states  @xcite .",
    "moreover , in the case of ambiguous input , the network does not explore all the best , equally consistent states or input interpretations .",
    "a network model for solving constraint satisfaction problems using multi - stable wta - based oscillators has been described in  @xcite . in this model as well , there is no guarantee that the network will not get stuck at locally optimal solutions and the model does not address how the internal consistency model can be learned .",
    "alternative architectures sidestep the issue of getting stuck at locally optimal states or input interpretations by making use of stochastic networks that continuously explore the state space  @xcite .",
    "such networks can be configured to visit more consistent states with higher probability . however , for an unambiguous input , such networks can not search for , and stabilize at , the fully consistent state , but would only transiently visit this optimum state  @xcite .    we show that the issues inherent in these architectures can be avoided by using rhythmic inhibition to drive the search for maximally consistent input interpretations .",
    "the networks we describe never get stuck at non - optimal input interpretations ; if a fully consistent interpretation of an unambiguous input exists , the network will find and stabilize at that interpretation ; if the input is ambiguous or the set of constraints irreconcilable , the network will continuously switch between the most consistent states or input interpretations . in the latter case ,",
    "we show that the network trajectory can be well approximated by a stochastic markov chain monte carlo ( mcmc ) sampler which is remarkable considering that the network trajectory is deterministic .",
    "we use this continuous switching between equally consistent interpretations to model perceptual multi - stability phenomena . unlike the majority of previous models though , we start with a naive network and allow it to learn by example , through hebbian plasticity in the network connections , what constitutes consistent inputs .",
    "the multi - stability phenomenon emerges when the network receives ambiguous input that does not admit a consistent interpretation according to the previously seen examples .",
    "the network architecture we describe can be used as a biologically motivated neural substrate on which to ground various `` perception as inference '' theories .",
    "the networks we describe in this paper are composed of a number of local neural circuits that interact through long range excitatory connections and that each receive local oscillatory inhibition .",
    "the properties of the oscillatory inhibition model the salient features of the rhythmic inhibition that underlies gamma oscillations .",
    "the following are biological justifications for the various modeling assumptions we use :    1 .",
    "_ wta circuits are local neural circuit motifs _ : wta circuits are potential cortical circuit motifs  @xcite .",
    "the wta circuits can be replaced by any neural circuit as long as this circuit displays a number of distinct firing patterns based on external input and a memory of past firing patterns .",
    "some distinct part of each firing pattern should be characterized by a high enough firing rate so that it can influence the firing pattern in another neural circuit when the two are coupled .",
    "oscillatory inhibition is local to each wta _ : gamma oscillations typically have a local origin  @xcite .",
    "gamma oscillations in local field potential typically arise from the rhythmic firing of basket cells that have predominantly local arborization  @xcite .",
    "it is a general phenomenon that faster rhythms tend to develop locally  @xcite .",
    "local oscillatory inhibition is strong enough to shut down the activity in the local circuit _ : there is strong evidence for the involvement of interneurons containing the calcium binding protein parvalbumin in the oscillatory discharge underlying gamma oscillations  @xcite .",
    "interneurons expressing parvalbumin , such as basket cells and chandelier cells , mainly target the soma , the axon initial segment , and the proximal dendrites of the excitatory principal cells  @xcite making them particularly effective in rhythmically silencing their target neurons .",
    "the local oscillatory inhibition waveforms have different frequencies _ : there is evidence that gamma oscillations recorded from even nearby regions in the same cortical area have significantly different frequencies  @xcite .",
    "phase relations between gamma oscillations recorded from nearby points in the cortex are continuously changing  @xcite , and the phases of local cortical gamma rhythms vary in an irregular manner  @xcite .",
    "different oscillation frequencies is one simple way to obtain continuously changing phase relations .",
    "the different local rhythms can be highly coherent and we investigate the effect of this coherence on the model behavior .",
    "the only requirement of our model is that the space of possible phase relations is continuously explored with no perfect and persistent phase lock between any of the local rhythms .",
    "we simulate and analyze rate - based population - level networks . each neural population in a wta is modeled as a linear threshold unit ( ltu ) following a mean - field approach  @xcite ( see methods section ) .",
    "all excitatory connections have a slow and fast component to capture the effects of the different time constants of the synaptic currents mediated by slow @xmath0 receptors and fast @xmath1 receptors .",
    "the network architecture and example simulation results are shown in fig .",
    "[ fig : arch_desc ] .",
    "when a wta is released from oscillatory inhibition , the excitatory population receiving the largest external input wins and suppresses the activity in the other excitatory populations in the wta .",
    "the @xmath0-mediated recurrent synaptic current has a time constant that is longer than the oscillatory inhibition period .",
    "since this current is always larger in the winning population , it is able to bias the competition so that the winning population keeps on winning in subsequent inhibition cycles after the external input is removed as shown in fig .",
    "[ fig : arch_desc_c ] .    0.8 .",
    "( ) simulation results of the network in ( ) when the frequency of the oscillatory inhibition is slightly different in the two wta circuits . vertical lines",
    "are visual guides to the end of the high phase of oscillatory inhibition in the wta circuit.,title=\"fig : \" ] [ fig : arch_desc_a ]     +    0.4 .",
    "( ) simulation results of the network in ( ) when the frequency of the oscillatory inhibition is slightly different in the two wta circuits . vertical lines",
    "are visual guides to the end of the high phase of oscillatory inhibition in the wta circuit.,title=\"fig : \" ] [ fig : arch_desc_b ]    0.475 .",
    "( ) simulation results of the network in ( ) when the frequency of the oscillatory inhibition is slightly different in the two wta circuits . vertical lines",
    "are visual guides to the end of the high phase of oscillatory inhibition in the wta circuit.,title=\"fig : \" ] [ fig : arch_desc_c ]     +    0.4 .",
    "( ) simulation results of the network in ( ) when the frequency of the oscillatory inhibition is slightly different in the two wta circuits . vertical lines",
    "are visual guides to the end of the high phase of oscillatory inhibition in the wta circuit.,title=\"fig : \" ] [ fig : arch_desc_d ]    0.5 .",
    "( ) simulation results of the network in ( ) when the frequency of the oscillatory inhibition is slightly different in the two wta circuits .",
    "vertical lines are visual guides to the end of the high phase of oscillatory inhibition in the wta circuit.,title=\"fig : \" ] [ fig : arch_desc_e ]    figure  [ fig : arch_desc_d ] shows two coupled wta circuits in which the coupling connections encode a consistency condition .",
    "each wta circuit represents a discrete variable with two states : and and the coupling connections dictate that when population is winning in one wta circuit then population should be winning in the other .",
    "the activity of one wta circuit , however , is able to influence the state of the other wta only when its interval of heightened activity coincides with the winner selection interval ( the interval just after oscillatory inhibition goes low ) in the other wta circuit .",
    "this effect is illustrated in fig .",
    "[ fig : arch_desc_e ] where we choose slightly different frequencies for the oscillatory inhibition in the two wta circuits . in the supplementary material ,",
    "we describe how arbitrary consistency conditions involving more than two wtas can be realized .",
    "this example shows how the effective strength of the inter - wta coupling connections depends on the phase difference between their rhythmic inhibition cycles .",
    "this is compatible with the hypothesis that the effective strength of the fixed anatomical connections in the brain is modulated by the dynamical state of the communicating neural circuits which allows the quick formation and removal of effective `` communication '' links  @xcite .",
    "the phase difference between the rhythms of two neural groups is a potential marker for the strength of the effective link between them  @xcite .",
    "this view is particularly appealing in the case of gamma oscillations due its rhythmic modulation of excitability and firing rate  @xcite .",
    "a wta circuit can be involved in a number of different consistency conditions .",
    "as the rhythmic inhibition wears off in one wta circuit , other wta circuits that are coupled to it can influence its state so as to satisfy the consistency conditions encoded in the pattern of coupling connections ( see fig .",
    "[ fig : arch_desc_d ] for example ) .",
    "exactly which consistency condition , if any , gets satisfied by the new state / winner of the wta circuit depends on the level of activity in the wta circuits connected to it , which in turn depends on the phase of the inhibition cycle in these wta circuits . since the phase relations between the wta circuits are continuously changing , the relative strengths of the different consistency conditions are also continuously changing .",
    "if we consider each wta as a discrete - valued variable whose value is the identity of the last winning population , we can enumerate all possible configurations of a network of interacting oscillatory wta circuits ; for example , a network of @xmath2 coupled wta circuits with two excitatory populations each can have @xmath3 possible configurations .",
    "define @xmath4 as the discrete - valued , continuous - time , dynamical variable that denotes the configuration of the network at time @xmath5 .",
    "this variable is updated each time the local oscillatory inhibition shuts down the activity in a wta circuit to reflect the identity of the wta circuit s last winning population at that time .",
    "we can prove the following two results about the trajectory of @xmath4 :    the only fixed points of @xmath4 are the configurations that satisfy all consistency conditions [ prop : fixedpoint ]    [ prop : aperiodic ] @xmath4 is not periodic as long as it has not reached a fixed point    the proofs are given in the supplementary material .",
    "the network thus traverses the space of possible wta configurations in an irregular , aperiodic manner until it finds a fully consistent configuration .",
    "external inputs can clamp the states of some wtas , i.e , force particular populations to win the competition in each inhibition cycle .",
    "in this case , the rest of the network would search for configurations that satisfy the consistency conditions , given the states of the input - clamped wtas .",
    "we illustrate this behavior using a hard 9 * 9 sudoku instance ( with one unique solution ) that is shown in fig .",
    "[ fig : sud_a ] . the network embodying",
    "this problem uses a wta circuit with 9 excitatory populations to represent each square .",
    "the index of the winning population in each wta encodes the number in the underlying square .",
    "the sudoku constraints are implemented by coupling each square / wta to every other square / wta in the same row , column , or 3 * 3 block with a pair - wise connection scheme that encodes an inequality constraint : each excitatory population in one square / wta is connected to all the excitatory populations in the other square / wta _ except _ the excitatory population having the same index ( fig .  [",
    "fig : arch_desc_d ] shows an inequality constraint in the binary wta case ) .",
    "each wta will then try to force all the other wtas in the same row , column , and 3 * 3 block to encode a different number .",
    "external input forces every wta that represents a pre - filled square to always encode the pre - filled number .",
    "for example , the top left wta / square receives external input so that population @xmath6 always wins in each inhibition cycle .",
    "figures  [ fig : sud_c ] ,  [ fig : sud_d ] show that the network quickly yields reasonably good solutions that only violate a few constraints , and on average tends to occupy better configurations the longer it is allowed to run .",
    "the network is able to escape from locally optimal configurations and in all trials , it manages to find and stabilize at the solution to the sudoku problem .",
    "[ fig : sud_b ] shows the convergence times when using oscillatory inhibition rhythms with an average frequency of @xmath7 .    0.4   [ fig : sud_a ]    0.6   [ fig : sud_b ]     +    0.5   [ fig : sud_c ]    0.5   [ fig : sud_d ]      0.5 seconds and the relative frequencies of occurrence of these configurations in a sequence of @xmath8 samples generated by a stochastic mcmc operator constructed to approximate the network trajectory .",
    "the configuration index is the decimal value of the binary string encoding the states of @xmath9 to @xmath10 .",
    "( ) trajectory of the dynamical variable @xmath4 for the network in for the first @xmath11 seconds ( on the left ) , with the normalized duration of time spent in the different configurations during those @xmath11 seconds ( on the right , blue bars ) .",
    "as the simulation progresses , the normalized time spent in the different configurations approaches the normalized duration results of ( reproduced on the right , in light red).,title=\"fig : \" ] [ fig : sampling_a ]    0.47 seconds and the relative frequencies of occurrence of these configurations in a sequence of @xmath8 samples generated by a stochastic mcmc operator constructed to approximate the network trajectory .",
    "the configuration index is the decimal value of the binary string encoding the states of @xmath9 to @xmath10 .",
    "( ) trajectory of the dynamical variable @xmath4 for the network in for the first @xmath11 seconds ( on the left ) , with the normalized duration of time spent in the different configurations during those @xmath11 seconds ( on the right , blue bars ) .",
    "as the simulation progresses , the normalized time spent in the different configurations approaches the normalized duration results of ( reproduced on the right , in light red).,title=\"fig : \" ] [ fig : sampling_b ]     +    0.47 seconds and the relative frequencies of occurrence of these configurations in a sequence of @xmath8 samples generated by a stochastic mcmc operator constructed to approximate the network trajectory .",
    "the configuration index is the decimal value of the binary string encoding the states of @xmath9 to @xmath10 .",
    "( ) trajectory of the dynamical variable @xmath4 for the network in for the first @xmath11 seconds ( on the left ) , with the normalized duration of time spent in the different configurations during those @xmath11 seconds ( on the right , blue bars ) .",
    "as the simulation progresses , the normalized time spent in the different configurations approaches the normalized duration results of ( reproduced on the right , in light red).,title=\"fig : \" ] [ fig : sampling_c ]    0.52 seconds and the relative frequencies of occurrence of these configurations in a sequence of @xmath8 samples generated by a stochastic mcmc operator constructed to approximate the network trajectory .",
    "the configuration index is the decimal value of the binary string encoding the states of @xmath9 to @xmath10 .",
    "( ) trajectory of the dynamical variable @xmath4 for the network in for the first @xmath11 seconds ( on the left ) , with the normalized duration of time spent in the different configurations during those @xmath11 seconds ( on the right , blue bars ) .",
    "as the simulation progresses , the normalized time spent in the different configurations approaches the normalized duration results of ( reproduced on the right , in light red).,title=\"fig : \" ] [ fig : sampling_d ]    according to proposition 1 , if the consistency conditions encoded in the coupling connections can not all be simultaneously satisfied , the network will never settle in one configuration .",
    "this is the case for the network shown in fig .",
    "[ fig : sampling ] .",
    "figure  [ fig : sampling_b ] shows that the network tends to spend more time in configurations that violate fewer consistency conditions .",
    "figure  [ fig : sampling_c ] shows the relative duration of time the network spends in each configuration .",
    "the plot in fig .",
    "[ fig : sampling_c ] can be interpreted as the plot of a probability distribution over the possible configurations of the network .",
    "we take this stochastic interpretation further by approximating the network dynamics by a markov chain monte carlo ( mcmc ) sampling process .",
    "based on the network topology , we construct a stochastic markovian transition operator @xmath12 that approximates the network trajectory ( see methods section ) .",
    "we compare the normalized duration of time the trajectory of @xmath4 spends in a particular configuration to the normalized frequency of occurrence of this particular configuration in the sequence of samples generated by the stochastic transition operator @xmath12 .",
    "the results are shown in fig .",
    "[ fig : sampling_c ] for the example network .",
    "the two sets of statistics are similar even though they were generated by two widely different classes of systems : one that is deterministic , continuous - valued and running in continuous time , and the other stochastic , discrete - valued and running in discrete time steps .",
    "the sampling analogy is reinforced by the aperiodicity of @xmath4 which yields an irregular trajectory of the network state that is akin to a truly stochastic trajectory as shown in fig .",
    "[ fig : sampling_d ] .",
    "the difference between two probability distribution @xmath13 and @xmath14 can be quantified using kullback - leibler(kl ) divergence : @xmath15 for the network shown in fig .",
    "[ fig : sampling ] , @xmath16 . in the supplementary material , we show that the stochastic approximation is still good for various network sizes and inter - wta connection densities ( see supplementary fig .",
    "s1 ) and analyze the properties of the mcmc operator as well as discuss in more detail the assumptions underlying the stochastic approximation .    of course",
    ", given the statistics of the network trajectory , it is trivial to construct an mcmc operator that has these statistics as a stationary distribution using any of the standard sampling methods such as gibbs sampling .",
    "the mcmc operator described in this section , however , was constructed a - priori , i.e , before simulating the network , as an approximation of the network trajectory .",
    "0.5   in the non - noisy , low noise , and high noise cases .",
    "( ) mean square coherence between the oscillatory inhibition in variables v0 and v3 in the high noise case when their phases are coupled and when they are uncoupled .",
    "( ) statistics in the high noise case when v0 and v3 are phase coupled and when they are uncoupled .",
    "( ) change in the relative ( normalized ) duration of each network configuration when v0-v3 become phase coupled .",
    "data was obtained from .",
    "blue bars indicate configurations in which the v0-v3 consistency condition is satisfied while red bars indicate configurations in which the consistency condition is violated.,title=\"fig : \" ] [ fig : coh_a ]    0.5   in the non - noisy , low noise , and high noise cases .",
    "( ) mean square coherence between the oscillatory inhibition in variables v0 and v3 in the high noise case when their phases are coupled and when they are uncoupled .",
    "( ) statistics in the high noise case when v0 and v3 are phase coupled and when they are uncoupled .",
    "( ) change in the relative ( normalized ) duration of each network configuration when v0-v3 become phase coupled .",
    "data was obtained from .",
    "blue bars indicate configurations in which the v0-v3 consistency condition is satisfied while red bars indicate configurations in which the consistency condition is violated.,title=\"fig : \" ] [ fig : coh_b ]     +    0.5   in the non - noisy , low noise , and high noise cases .",
    "( ) mean square coherence between the oscillatory inhibition in variables v0 and v3 in the high noise case when their phases are coupled and when they are uncoupled .",
    "( ) statistics in the high noise case when v0 and v3 are phase coupled and when they are uncoupled .",
    "( ) change in the relative ( normalized ) duration of each network configuration when v0-v3 become phase coupled .",
    "data was obtained from .",
    "blue bars indicate configurations in which the v0-v3 consistency condition is satisfied while red bars indicate configurations in which the consistency condition is violated.,title=\"fig : \" ] [ fig : coh_c ]    0.5   in the non - noisy , low noise , and high noise cases .",
    "( ) mean square coherence between the oscillatory inhibition in variables v0 and v3 in the high noise case when their phases are coupled and when they are uncoupled .",
    "( ) statistics in the high noise case when v0 and v3 are phase coupled and when they are uncoupled .",
    "( ) change in the relative ( normalized ) duration of each network configuration when v0-v3 become phase coupled .",
    "data was obtained from .",
    "blue bars indicate configurations in which the v0-v3 consistency condition is satisfied while red bars indicate configurations in which the consistency condition is violated.,title=\"fig : \" ] [ fig : coh_d ]    the deterministic networks we present exploit the continuously shifting phase relations between different wtas in order to explore the space of possible network configurations .",
    "we added white gaussian noise to the input of all ltus and random fluctuations to the phases of all inhibitory rhythms ( see methods section ) .",
    "figure  [ fig : coh_a ] shows that noise ` smears out ' the distribution of relative durations by biasing the trajectory towards low - duration states and away from high - duration states .",
    "this smearing out effect is more pronounced for larger random fluctuations .",
    "this is reminiscent of how higher noise / temperature in a thermodynamical system acts to increase the system entropy by making the probability distribution over the system states more uniform .",
    "there is a crucial difference between these networks and thermodynamical systems , however : at the zero noise ( zero temperature ) level , a thermodynamical system quickly freezes at a single state while our networks will continue to explore the configuration space .",
    "gamma rhythms in distant neural assemblies often exhibit non - zero but still imperfect ( non - unity ) coherence  @xcite .",
    "we model this phenomenon by coupling the phases of the inhibitory rhythms in different wtas according to the kuramoto model  @xcite in order to realize phase relations that are consistently near zero .",
    "this phase coupling was introduced between variables / wtas v0 and v3 in the network in fig .",
    "[ fig : sampling_a ] and all network components were perturbed by random fluctuations .",
    "figure  [ fig : coh_d ] shows that v0-v3 coherence increases the duration of all configurations in which the v0-v3 consistency condition is satisfied and decreases the duration of all configurations in which it is not .",
    "increased coherence between two wtas thus leads to stronger interaction and makes it more difficult to violate the consistency conditions between them .      like any connectionist architecture ,",
    "the knowledge in the networks we describe is encoded in the inter - wta connections .",
    "these connections represent the consistency conditions which , through the network dynamics , induce a `` probability distribution '' over the network configurations .",
    "if made plastic , the strengths of these connections will be continuously modulated by the changing network state . by forcing a particular configuration on the network , external input",
    "can thus reorganize the pattern of these inter - wta connections so as to maximize the consistency of the input - imposed configurations as interpreted according to the pattern of inter - wta connections . a central question in such a learning scheme",
    "is how the plasticity rule can distinguish between configurations that are input - imposed , and thus should be learned , and configurations that arise naturally when the network is running freely .",
    "this central question also arises in stochastic , sampling - based connectionist architectures that learn probability distributions by example such as restricted boltzmann machines  @xcite .    to distinguish an input - imposed configuration as a configuration that should be learned , i.e , that should serve as a model for consistent configurations , we have external input synchronize the activity of the wta circuits it targets so that the oscillatory inhibition in these wta circuits has a common frequency and a zero phase difference .",
    "synchronization is thus a dynamical marker for configurations that should be learned .",
    "we use a bistable hebbian plasticity rule that acts on the weights of the inter - wta coupling connections .",
    "a drift term pushes the synaptic weight to one of two stable values : high or low ( see methods section ) .    in a rate based network ,",
    "we are unable to capture the way gamma - band synchronization enhances plasticity by forcing neurons in multiple wta circuits to spike within narrow time windows  @xcite . however , the plasticity rule we use results in the same functional effect . in order for a depressed connection to potentiate ,",
    "both pre- and postsynaptic rates need to be large at the same time for many consecutive inhibition cycles in order to overcome the bistability drift .",
    "this will only reliably happen if the oscillatory inhibition in the pre- and post - synaptic wta circuits have a measure of synchrony where their phase difference is around zero for many cycles so that the peaks of excitatory activity in the wta circuits coincide .",
    "in this section , we describe a network that is able to learn a consistency model by example and then reproduces a perceptual multi - stability phenomenon when faced with ambiguous inputs .",
    "the particular form of perceptual multi - stability we consider is binocular rivalry which has been well studied experimentally @xcite as well as in theory @xcite . in binocular rivalry experiments , each eye is shown a differently oriented grating .",
    "the subject s perception then continuously switches between the two orientations  @xcite .",
    "[ [ network - model ] ] network model + + + + + + + + + + + + +    the network is composed of @xmath17 hidden and @xmath18 input wta circuits that each undergo oscillatory inhibition .",
    "each wta has six competing excitatory populations , @xmath19 , and can take one of six different states ( orientations ) .",
    "@xmath19 implies that each excitatory population codes for a range of orientations of @xmath20 .",
    "the full network connectivity is illustrated in fig .",
    "[ fig : multinet ] . input and",
    "hidden wta circuits are set up in pairs .",
    "each input wta connects to one hidden wta so that populations of similar orientations are bidirectionally coupled .",
    "the connectivity between hidden wta circuits is all - to - all and initialized using random weights : @xmath21 $ ] that are _ plastic _ and follow a bistable hebbian plasticity rule(see methods section for more details ) .    [ [ training - and - testing ] ] training and testing + + + + + + + + + + + + + + + + + + + +    the simulations we run have two distinct phases , a training phase in which we cycle through consistent inputs by clamping the input wtas to the same orientation , and a testing phase in which we clamp a subset ( or all ) of the input wtas at various orientation patterns and decode the activity of the hidden wta circuits . during the two phases we use _ the same synaptic rule and parameters _ ; learning is effectively enabled / disabled by providing / withholding a synchronizing oscillatory input to the inhibitory oscillators of all wtas ( see methods for further details ) .",
    "[ fig : bistab ]    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction .",
    "`` low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_st ]    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction .",
    "`` low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_sr ]     +    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction . ``",
    "low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_2 t ]    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction .",
    "`` low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_2r ]     +    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction .",
    "`` low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_bt ]    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction .",
    "`` low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_br ]     +    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction .",
    "`` low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_6 t ]    0.33   under different conditions .",
    "black dots indicate states that can be encoded by the network , and blue empty circles indicate visited states .",
    "the area of the filled red circle at each visited location is proportional to the time spent at that state ( scale differs between plots ) .",
    "the inset gabor patches indicate the stimuli presented to the left and right eye in analogous experimental settings .",
    "( ) a network trained on consistent inputs propagates the clamped angle of one input wta to the other wta circuits and stably represents that angle .",
    "( , , , ) an untrained network spends most of the time in `` low confidence states '' where the hidden wta circuits encode different angles in all input cases .",
    "( ) the trained network switches between two interpretations of an ambiguous input .",
    "( ) increasing the number of input wta circuits encoding @xmath22 to two makes that interpretation more probable compared to the @xmath23 interpretation ( ) the trained network under fully conflicting input preferentially visits consistent states , where all populations represent the same direction .",
    "`` low confidence '' states are also visited .",
    ", title=\"fig : \" ] [ fig : bistab_6r ]     +    to visualize the network behavior , we sum the preferred orientation vectors of the winning excitatory populations in the hidden wtas to obtain a vector whose angle represents the current guess of the network at the true orientation which it ` senses ' through the input wta circuits .",
    "the vector s magnitude represents the confidence of the network in this orientation estimate ( see methods section for more details ) .",
    "[ fig : bistab ] illustrates the trained and untrained network responses in various input cases : unambiguous input in figs .",
    "[ fig : bistab_st ] and  [ fig : bistab_sr ] ( one input wta clamped at @xmath23 orientation ) , ambiguous input in figs .",
    "[ fig : bistab_2t],[fig : bistab_2r],[fig : bistab_bt ] , and  [ fig : bistab_br ] ( one input wta clamped at @xmath23 and one or two other input wtas clamped at @xmath22 ) , and a fully conflicting input in figs .  [",
    "fig : bistab_6 t ] and [ fig : bistab_6r ] ( each input wta is clamped at a different angle ) .    to be able to make a quantitative comparison to human experiments , we investigated the perceptual switching times our model produces when presented with an ambiguous stimulus .",
    "we added an ` integrative ' component to the system based on @xcite in which a bistable decision task for random dot stimuli is modelled : a bistable readout attractor network receives time - varying inputs and settles into one attractor state . the time varying input is produced by the hidden wtas and is slowly integrated by the readout attractor network",
    "the bistable attractor s population with the higher activity corresponds to the current percept , see fig .",
    "[ fig : switchstats ] .    0.33   [ fig : readout ]    0.4   [ fig : dt ]",
    "several theories postulate that the key computational machinery of sensory and association cortices is devoted to solving best - match problems  @xcite where a number of interacting areas try to agree on a global interpretation that best explains sensory data while being consistent with an internal model , or a prior , of the environment  @xcite .",
    "we showed that oscillatory inhibition that gives rise to rhythmic modulation of firing rate and sensitivity to external inputs in the local circuitry allows a neural network to solve best - match problems .",
    "if no fully consistent network configuration exists , the network trajectory wanders aperiodically and can be approximated by a stochastic sampling process .",
    "we have shown that deterministic networks can reproduce effects that were commonly modeled using stochastic networks such as perceptual multi - stability and the explaining away effect ( see supplementary fig .",
    "our results show that physical noise mechanisms are not strictly necessary for networks to explore complex configuration spaces without being trapped by locally optimal configurations .    increased gamma - band coherence between distant neural groups",
    "has been found to increase the strength of their mutual influence  @xcite making the coherence level of the gamma oscillations a candidate mechanism for quickly modulating the effective strength of anatomical connections ( the `` communication through coherence '' hypothesis ) . in agreement with this effect",
    ", we have shown that if oscillatory inhibition in the wta circuits were forced to exhibit some coherence which leads to consistent and favorable phase relations ( phase differences that are around zero ) , communication between the coherent wta circuits would be more effective as the consistency conditions inside the coherent set would be more difficult to violate(see fig .",
    "[ fig : coh_d ] ) .",
    "we have used synchronization as a way to trigger learning .",
    "there is evidence that long - range synchronization is required for effective learning and memory formation  @xcite and that it is a candidate mechanism for establishing associations between disparate neural groups  @xcite .",
    "gamma band synchronization in particular is well - suited for establishing associations through stdp mechanisms  @xcite as neurons fire preferentially at a particular phase of the gamma cycle ( when the oscillatory inhibition is low ) , thereby aligning their spikes to a precision of a few milliseconds which is a suitable window for inducing synaptic potentiation or depression  @xcite .",
    "our perceptual multistability model is , to our knowledge , the first model that reproduces perceptual multistability phenomena without making use of explicit stochastic dynamics .",
    "an experiment that could provide evidence as to whether our model does underlie multi - stable perception would investigate the relationship between perceptual switching times and how fast gamma - band phase differences between fields measured at different points on the visual cortex change : faster changes in phase relations translates to a more exploratory behavior in our model as the effective network connectivity changes more rapidly and should translate to faster switching times between the different percepts .",
    "the basic building block of all networks is the linear threshold unit ( ltu ) .",
    "ltus together with an oscillatory inhibitory population make up an oscillatory wta as shown in figs .",
    "[ fig : arch_desc_a ] and  [ fig : arch_desc_b ] . the excitatory populations in different wta circuits are coupled together to implement consistency conditions as shown in fig .",
    "[ fig : arch_desc_d ] .",
    "the full description of a network having @xmath24 wta circuits , with @xmath25 excitatory population in wta @xmath26 is :              @xmath32 and @xmath33 are the the activities of the @xmath34 excitatory population , and the inhibitory population in wta @xmath35 respectively .",
    "@xmath36 is the linear threshold function : @xmath37 .",
    "@xmath38 is the phase of the oscillatory inhibition in wta @xmath35 .",
    "@xmath38 automatically wraps around to stay in the range @xmath39 .",
    "@xmath40 is the actual oscillatory inhibition waveform in wta @xmath35 which , within each period , is high ( with amplitude @xmath41 ) for a fraction @xmath42 of the oscillation cycle .",
    "@xmath32 is low - pass filtered with time constant @xmath43 to yield @xmath44 which is used to model slowly decaying currents mediated by @xmath0 receptors .",
    "@xmath45 , @xmath46 and @xmath47 , @xmath48 are the time constants and thresholds of the excitatory and inhibitory populations respectively . @xmath49 and @xmath50 are the inter - wta @xmath1- and @xmath0-mediated connections respectively which connect population @xmath51 to population @xmath52 .",
    "these inter - wta coupling weights are fixed in all simulations except the simulations of the perceptual multi - stability model where they are plastic and obey the plasticity rule given in eq .",
    "[ eq : plasticity ] .",
    "the remaining weights are the intra wta weights .",
    "@xmath53 , @xmath54 are informally treated as derivatives of independent , zero mean , unity variance wiener processes .",
    "we could thus use the euler - maruyama method to carry out the noise simulations where in each time step @xmath55 , the random processes @xmath53 , @xmath54 generate independent gaussian increments with zero mean and variance @xmath55 .",
    "@xmath56 is a zero mean , unity variance gaussian random variable .",
    "the term @xmath57 in eq .",
    "[ eq : phase ] indicates that at the beginning of each oscillation cycle , @xmath58 , a random increment @xmath59 is added to the oscillation phase .",
    "this increment is only added once per cycle so the phase has to cross the @xmath60 point and reset before another increment is added . @xmath61 and @xmath62 are noise scaling factors .",
    "@xmath63 is the phase coupling strength between oscillatory inhibition in wtas @xmath26 and @xmath35 .",
    "we always use symmetric phase coupling : @xmath64 .",
    "the phase coupling model follows the kuramoto model  @xcite .",
    "in mcmc sampling , a stochastic markovian transition operator @xmath65 defined over a space @xmath66 is used to generate a stochastic sequence of points , or samples , in * x * : @xmath67 , where @xmath68 is a sample drawn from the conditional probability distribution : @xmath69 @xmath70 is the probability that the next point in the sequence is @xmath71 given that the current point is @xmath72 .",
    "if @xmath65 is irreducible ( for any two states , @xmath73 and @xmath74 , @xmath74 will with non - zero probability appear in the random sequence started from @xmath73 after a finite number of steps ) , and @xmath65 is aperiodic ( starting from any state @xmath75 , the indices of the positions in the sequence where @xmath75 has a non - zero probability of occurring do not have a common divisor other than 1 ) then for any starting point @xmath76 , @xmath77 approaches the quantity @xmath78 as @xmath79 gets large for all @xmath80 .",
    "in other words , the points @xmath81 are samples drawn from the probability distribution @xmath82 , called the stationary or invariant distribution of the transition operator @xmath65 , for large enough @xmath79 .",
    "given a network of interacting wta circuits , our goal is to find a markovian stochastic transition operator , @xmath12 , that is defined over the space of all network configurations and which approximates the way the network trajectory moves through this configuration space .",
    "we here describe how , given a particular network configuration @xmath83 , the next configuration @xmath68 is evaluated .",
    "this evaluation procedure implicitly defines the transition operator @xmath12 and it attempts to approximate the way the configuration of the actual network changes .    1 .",
    "choose at random a wta @xmath84 to be updated .",
    "this corresponds to a wta which has just been released from oscillatory inhibition and is now selecting a winner .",
    "2 .   choose at random a subset of the consistency conditions that involve the wta @xmath84 .",
    "denote this subset as @xmath85 .",
    "the wta circuits involved in this subset are assumed to have the proper phase relations to @xmath84 that enable them to affect the winner selection in @xmath84 .",
    "3 .   for each possible state @xmath86 of wta @xmath84 (",
    "the number of possible states is the number of excitatory populations in the wta ) , attach a number @xmath87 that counts the number of consistency conditions in @xmath85 that are satisfied if @xmath84 is in state @xmath86 .",
    "the states of the other wta circuits are fixed and encoded in @xmath83 .",
    "find the maximum of @xmath87 across all states @xmath86 and denote it as @xmath79 .",
    "define @xmath88 .",
    "@xmath89 is thus the set of possible states for wta @xmath84 that are favored by the majority of the consistency conditions in @xmath85 .",
    "if the current state of @xmath84 is in @xmath89 , then the state of @xmath84 remains unchanged and @xmath90 .",
    "this reflects the hysteresis mechanism mediated by the slow @xmath0 current that favors the wta population that won in the previous inhibition cycle .",
    "if the current state of @xmath84 is not in @xmath89 , then a new state for @xmath84 is selected randomly from @xmath89 and @xmath68 is updated accordingly . note that at most one wta changes its state between @xmath83 and @xmath68 .",
    "we use the following bi - stable plasticity rule to modulate the inter - wta connection strengths : @xmath91 \\cdot \\left[r_{post}(t ) - \\theta \\right ] \\nonumber \\\\ & - & \\eta_{-}(r_{pre},r_{post } ) \\cdot [ r_{pre}(t ) -\\theta ] \\cdot [ \\theta - r_{post}(t ) ] \\nonumber\\end{aligned}\\ ] ] where @xmath92 @xmath93 @xmath94    @xmath95 is the weight . @xmath96 and @xmath97 are the firing rates of the source ( presynaptic ) and target ( postsynaptic ) populations respectively .",
    "this rule is a variation of the bienenstock - cooper - munro ( bcm ) rule  @xcite with hard weight bounds @xmath98 and @xmath99 ( not shown in the equation ) and the requirement that @xmath96 has to exceed a threshold , @xmath100 , in order to induce any change in the weight @xmath95 .",
    "if this requirement is met , potentiation is induced if the postsynaptic activity , @xmath97 , is above the threshold @xmath100 , and depression is induced if the postsynaptic activity is below the threshold .",
    "the rates of potentiation and depression induction are controlled by @xmath101 and @xmath102 respectively .",
    "the rule captures the way potentiation and depression induction depend on the pre- and post - synaptic firing rates  @xcite .",
    "the rule contains a second component that slowly forces the connection weight to either @xmath98 or @xmath99 depending on whether the weight is below or above @xmath103 respectively .",
    "the rule is thus bistable .",
    "the strength of the bistability drift is controlled by @xmath104 and @xmath105 .",
    "bistable plasticity is computationally less powerful than its counterpart with continuous stable weights @xcite , but can be argued to be more biologically realistic , due to noise - tolerance and finite synaptic information content .      to decode the network activity , we first scale the angles of the normalized preferred directions of the excitatory populations in the hidden wtas from the @xmath106 range to the @xmath107 range",
    "we then perform a vector addition of the modified preferred directions of all active populations of the hidden wta circuits to obtain the two quantities : @xmath108 @xmath109 where @xmath110 is the two argument quadrant adjusted inverse of the tangent , @xmath111 ( @xmath112 ) is the x - coordinate ( y - coordinate ) of the modified preferred direction of population @xmath35 and @xmath113 is the indicator of the activity of population @xmath35 .",
    "the summation runs over all excitatory populations in the hidden wta circuits .",
    "the factor @xmath114 in eq .",
    "[ eq : decode1 ] puts the decoded angle back in the @xmath106 range .",
    "@xmath115 , the magnitude of the decoded activity vector , can be understood as the confidence of the system in its current angle estimate .",
    "when all hidden wta circuits encode a different angle , @xmath115 takes a value close to zero , when they all encode the same angle , it takes the maximal value @xmath116 .",
    "`` training '' the network refers to the following procedure : for 30seconds , we provide input that clamps the states of all input wta circuits so that they are all encoding the same orientation , while enabling the global synchronizing oscillation . within these 30seconds , we cycle through the @xmath117 directions each wta can encode .",
    "the configuration of the input wta circuits is thus forced to represent an unambiguous orientation which would act to influence the hidden wta circuits so that they are also encoding the same unambiguous orientation .",
    "the connections between the hidden wta circuits change to represent the prior that all hidden wta circuits usually encode the same orientation .    during testing",
    ", we provide inputs that clamp the states of a subset , or of all , input wta circuits to certain orientations for 4 minutes while withholding the global synchronizing oscillation .",
    "we record the activity of the hidden wta circuits and decode it into an angle and a magnitude as outlined in eqs  [ eq : decode1 ] and  [ eq : decode2 ] .",
    "we interpret the normalized time histogram of this decoded signal as the probability the network assigns to a given @xmath115 , @xmath100 pair .    *",
    "rhythmic inhibition allows neural networks to search for maximally consistent states - supplementary material *   + hesham mostafa@xmath118 , lorenz k. mller , giacomo indiveri .",
    "+ institute for neuroinformatics , university of zurich and eth zurich , switzerland + e - mail : \\{hesham , lorenz , giacomo}@ini.uzh.ch      the frequencies of the local oscillatory inhibition in the wta circuits are different and are not rational multiples of each other . having one oscillation frequency that is a rational multiple of another is statistically impossible in a physical system with real - valued frequencies .",
    "let @xmath119 $ ] be the vector of the phases of the oscillatory inhibition in the @xmath79 wta circuits in the network at time @xmath5 where @xmath120 . by virtue of the incommensurability of the oscillatory inhibition frequencies ,",
    "@xmath121 follows a quasi - periodic trajectory . for any initial phase vector @xmath122 , and any @xmath123^n$ ] and @xmath124",
    ", there is a time @xmath125 such that @xmath126 .",
    "the vector of phases @xmath121 thus densely fills up the n - dimensional hyper - torus of all possible phases which implies that @xmath121 can not have a periodic trajectory .",
    "since it is the phase relations between the wta circuits that determine the effectiveness of the different consistency conditions , the ergodicity of the phase vector @xmath121 ensures that all possible combinations of the strengths of the consistency conditions are eventually explored . in a wta circuit @xmath127 ,",
    "the oscillatory inhibition is high for @xmath128 seconds and low for @xmath129 seconds during each cycle . in order to prove some useful results about the trajectory of @xmath4 , we require that @xmath130 . this condition , together with the ergodicity of the phase vector , @xmath131 ,",
    "guarantees that for any wta circuit @xmath132 , there is bound to come an oscillation cycle where the winner selection is unaffected by the activity in any other wta , because during that cycle , @xmath132 is released from oscillatory inhibition , selects a winner , and gets shut down again by oscillatory inhibition within @xmath133 seconds , while all other wta circuits are quiescent .",
    "assume @xmath4 has a fixed point @xmath134 which encodes a particular non - changing configuration and that this configuration violates one or more consistency conditions .",
    "let @xmath135 and @xmath136 be two wta circuits that are part of a violated consistency condition . due to the ergodicity of the phase vector , @xmath121 , there is bound to come an oscillation cycle for @xmath136 which has the following properties : during the part of the cycle when oscillatory inhibition is low in @xmath136 ,",
    "oscillatory inhibition is high in all other wta circuits except @xmath135 and the peak of activity in the excitatory populations in @xmath135 occurs at the time in which it can dictate the winner in @xmath136 .",
    "the influence of @xmath135 on @xmath136 is thus unopposed by any other wta and this influence acts to enforce the violated consistency condition by changing the identity of the winner in @xmath136 .",
    "thus , a configuration that violates one or more consistency conditions is unstable .",
    "assume @xmath4 has reached a point @xmath137 which encodes a configuration that satisfies all consistency conditions .",
    "the currently winning population in each wta circuit will receive from other wtas either a stronger or an equal input as compared to the other populations in the wta . in both cases , and due to the hysteresis mechanism mediated by the slow recurrent @xmath0 current , the winning population in each wta circuit keeps on winning and the global configuration @xmath137 remains unchanged hence @xmath137 is a fixed point .",
    "since @xmath4 has not reached a fixed point , @xmath4 alternates between a number of configurations .",
    "let @xmath84 be a wta in which the identity of the winning population changes between these configurations .",
    "assume @xmath4 has period @xmath12 .",
    "fix @xmath138 , at some @xmath139 where @xmath140 , wta @xmath84 changes its state , i.e , it selects a winning population that is different from the winning population in the previous cycle .",
    "this change is reflected in @xmath4 at @xmath139 when the oscillatory inhibition goes high in @xmath84 .",
    "@xmath84 has to change its state in the same way at @xmath141 where @xmath142 by the periodicity assumption of @xmath4 .",
    "so @xmath12 has to be a multiple of the oscillation period of @xmath84 .",
    "since the frequencies of oscillatory inhibition in the wta circuits are incommensurable , @xmath12 is incommensurable with the oscillation periods of all wta circuits except @xmath84 .",
    "hence , there is bound to come an oscillation cycle for @xmath84 with the following two properties : during the part of the cycle when oscillatory inhibition is low in @xmath84 , oscillatory inhibition is high in all other wta circuits ; and the cycle terminates at @xmath143 when the inhibition in @xmath84 goes high where @xmath26 is an integer .",
    "so it is impossible for @xmath84 to select a winner in this cycle that is different from the winner it selected in the previous cycle ( in the absence of external influence throughout this cycle , the hysteresis mechanism mediated by the slow @xmath0 recurrent connections yields the same winner as the previous cycle ) .",
    "this contradicts the initial assumptions about @xmath84 ( that it selects a different winner at @xmath143 ) and establishes the aperiodicity of @xmath4 .",
    "0.4   and node degrees in the range @xmath144 .",
    "there are 5 graph instances for each size - degree combination . in ( )",
    "the kl - divergence is plotted as a function of the number of nodes in the graph ( 15 data points per item ) and in ( ) , it is plotted as a function of degree ( 20 data points per item ) . the red line indicates the median , the box outlines the 1st and 3rd quartile and the whiskers show the full range of the data.,title=\"fig : \" ] [ fig : klnode ]    0.4   and node degrees in the range @xmath144 .",
    "there are 5 graph instances for each size - degree combination . in ( )",
    "the kl - divergence is plotted as a function of the number of nodes in the graph ( 15 data points per item ) and in ( ) , it is plotted as a function of degree ( 20 data points per item ) . the red line indicates the median , the box outlines the 1st and 3rd quartile and the whiskers show the full range of the data.,title=\"fig : \" ] [ fig : kldeg ]    based on the topology of the network , an mcmc operator can be constructed that approximates the network trajectory ( see methods section ) .",
    "the stationary probability distribution of this mcmc operator does not exactly reproduce the relative durations of the different configurations in the actual network .",
    "there are many reasons for this discrepancy :    * the state of a wta ( the identity of the winning population ) in one oscillation cycle is not only affected by its state in the preceding cycle but also by its state in cycles further in the past .",
    "that is because the time constant of the slow recurrent @xmath0 current is @xmath145 and the mean period of the oscillatory inhibition in the wta circuits is @xmath146 .",
    "when a population wins in one inhibition cycle , its increased recurrent @xmath0 current takes many cycles to decay which might affect the winner selection process many cycles later .",
    "the markovity property which is fundamental to the construction of @xmath12 is thus not exact . *",
    "some wta circuits ( those that have a higher oscillation frequency ) update more often than others .",
    "this violates the assumption inherent in step 1 in the mcmc update scheme which is that wta circuits update equally often on average . in sampling algorithms like gibbs sampling , differences in the variables update frequencies do not affect the stationary distribution , but in our case it does .",
    "one can show that this is a consequence of the fact that the transition operator @xmath12 does not obey the detailed balance equation while the transition operator for the gibbs sampler does . * in comparing the statistics of @xmath4 and those of the sequence generated by @xmath12",
    ", we are comparing the time durations of the different configurations in @xmath4 to their relative frequencies of occurrence in the mcmc sequence .",
    "this way , we are in essence assigning an equal time duration to each mcmc sample which exposes another assumption of the mcmc scheme , namely , that the wta circuits update their states at equal intervals ( the updated state might be the same as the previous one ) . in the actual network , there is no clear - cut update cycle . the wta circuits might update their states in very quick succession so the intermediate configurations might have very short duration , or one configuration might persist for a relatively long time before a wta updates its state ( i.e , the inhibition goes high in this wta and the winner is evaluated ) .",
    "to further investigate the difference between the network statistics and those of the mcmc operator , we constructed random regular graphs of different sizes and node degrees . from each graph we constructed a network in the following way : each node in the graph is a binary wta and each edge represents a consistency condition which could either be an equality or inequality condition .",
    "we then used kullback - leibler(kl ) divergence to quantify the difference between the `` probability distribution '' generated by the network and the stationary distribution of the equivalent mcmc operator .",
    "the results are shown in fig  [ fig : kl ] for different graph / network sizes and node degrees .",
    "the above - mentioned points of discrepancy lead to a more pronounced difference in the two sets of statistics in larger networks / graphs . to verify that this is not an effect of finite sample size",
    ", we generated a larger number of mcmc samples and ran the network for longer durations ; the kl - divergence between the two sets of statistics remained virtually unchanged .",
    "the match between the two sets of statistics does not seem to depend on the network / graph degree .",
    "the transition operator @xmath12 for an arbitrary network constructed as outlined above is aperiodic as there is always a non - zero probability that any configuration persists for an arbitrary number of steps in the sequence . unlike transition operators used in typical mcmc applications",
    ", @xmath12 does not obey detailed balance so the generated markov chain of samples is irreversible .",
    "also , @xmath12 is not irreducible in general .",
    "this means that in general , for networks of interacting wta circuits , the space of possible configurations can be decomposed into a number of non - communicating sets and one set of transient configurations .",
    "starting the chain from a configuration from the transient set , there is a non - zero probability that this configuration will never be visited again .",
    "if started in one of the non - communicating sets , the network trajectory will always stay in this set of configurations .",
    "hence , the long - term frequency of occurrence , or the `` probability distribution '' , over the network configurations will in general depend on the initial configuration of the network .",
    "the reducibility of @xmath12 is a desirable property in some circumstances .",
    "for example , @xmath12 is reducible for a network where there is a configuration that satisfies all consistency conditions as this configuration persists forever .",
    "having fully consistent configurations as absorbing states enables this kind of networks to be used for solving constraint satisfaction problems .",
    "this behavior is useful in the perceptual multi - stability model as it allows the network to form stable percepts if the input is unambiguous .",
    "@xmath12 is also reducible for a network where there is a configuration that violates all consistency conditions as this configuration will never be visited .",
    "this could be beneficial as it reduces the space of configurations explored by the network by discarding fully inconsistent states for which there is no evidence , either from external input , or from the consistency conditions in the network .",
    "more elaborate networks can be constructed that do not fall into these two categories but that map to a reducible stochastic transition operator by virtue of having two or more non - communicating sets of recurrent states ( i.e non - transient states ) .",
    "external input can switch the network configuration from one subset to another .",
    "the network can thus explore different parts of the configuration space based on external input .",
    "the reducibility of @xmath12 is , however , undesirable if the goal is to generate samples from a unique probability distribution irrespective of initial conditions which is a typical requirement in many mcmc applications .",
    "we consider a general consistency condition , @xmath85 , that involves @xmath147 wta circuits : @xmath148 , where the number of distinct states in wta @xmath35 ( the number of excitatory populations ) is @xmath149 .",
    "@xmath85 is simply the set of allowed configurations of the @xmath147 wta circuits .",
    "we require @xmath85 to be non - empty .",
    "@xmath85 can be implemented in the following way :    1 .",
    "define @xmath150 . introduce a `` hub '' wta , @xmath151 , which has @xmath152 excitatory populations in its wta .",
    "2 .   for each of the @xmath152 possible configurations of @xmath153 , connect each of the excitatory populations that are active in this configuration bidirectionally to one distinct excitatory population in @xmath151 .",
    "we have thus associated one population in @xmath151 to each configuration of the wta circuits @xmath153 .",
    "3 .   connect the excitatory populations of wta @xmath154 to the excitatory populations of @xmath151 bidirectionally so that the excitatory populations that are active in each of the allowed ( consistent ) configurations of @xmath85 connect to an excitatory population in @xmath151 bidirectionally .",
    "4 .   remove all populations in @xmath151 that are not bidirectionally connected to a population in @xmath154 .",
    "these populations encode the configurations of the first @xmath155 wta circuits that are not part of any consistent configurations .",
    "we can show in a way that is analogous to the proofs of propositions 1 and 2 that the described scheme will lead to dynamics that keep flipping the states of wta circuits @xmath156 in an aperiodic manner as long as @xmath157 are inconsistent according to @xmath85 .",
    "the only stable state is one in which @xmath157 satisfy @xmath85 and the state of @xmath151 reflects the configuration of wtas @xmath153 .    0.6 seconds .",
    "( ) normalized duration of the configurations in which is 1 under the three aforementioned conditions .",
    "we interpret this as the marginal probability of = 1 under the three conditions.,title=\"fig : \" ] [ fig : explainingaway_a ]      0.44 seconds .",
    "( ) normalized duration of the configurations in which is 1 under the three aforementioned conditions .",
    "we interpret this as the marginal probability of = 1 under the three conditions.,title=\"fig : \" ] [ fig : explainingaway_b ]    0.44 seconds .",
    "( ) normalized duration of the configurations in which is 1 under the three aforementioned conditions .",
    "we interpret this as the marginal probability of = 1 under the three conditions.,title=\"fig : \" ] [ fig : explainingaway_c ]    high - order consistency conditions can capture complex dependencies between the states of multiple wta circuits that can not be captured by pairwise connections between the wta circuits .",
    "one example is the dependencies that give rise to the `` explaining away '' phenomenon which is believed to underlie several aspects of visual perception .",
    "explaining away occurs in situations where many causes can give rise to a particular outcome .",
    "when this particular outcome is observed , the individual likelihood of each cause increases as at least one of the causes is needed to explain the outcome .",
    "if in addition , one of the causes is observed to have taken place , the likelihood of the other causes goes down again .",
    "the observed cause explains away the other causes as they are no longer needed to justify the outcome .",
    "this form of inter - causal reasoning establishes a dependency between the different causes of a particular outcome when this outcome is observed .",
    "[ fig : explainingaway_a ] shows a network used to model the dependencies that give rise to the explaining away effect .",
    "two causes , and , can each give rise to an outcome .",
    "the causes and the outcome are binary and they are represented by one wta each .",
    "the causes and the outcome are coupled to a hub wta so that the binary outcome is effectively an @xmath158 function of the two causes . for each cause , we introduce three unitary wta circuits where two unitary wta circuits project to the @xmath159 population and one projects to the @xmath160 population of the cause wta . that in effect introduces a `` prior '' over the states of the two causes that assigns a higher likelihood to them being @xmath159 .",
    "each wta oscillates at a slightly different frequency .",
    "the network as a whole can not have a consistent state as each cause can not simultaneously satisfy the contradictory requirements of the unidirectional consistency conditions coming from the unitary wta circuits .",
    "figure  [ fig : explainingaway_b ] shows the durations of time the network spends in the eight possible configurations of the two causes and the outcome . in the free - running network",
    ", there are four configurations that satisfy the high - order consistency condition ( the @xmath158 relation ) . due to the action of the `` prior '' ,",
    "configurations that satisfy the high - order consistency condition have a higher `` probability '' if more of the causes are @xmath159 .",
    "the strong `` prior '' can override the high - order consistency condition and assign a high `` probability '' to a configuration in which the two causes are @xmath159 and which does not satisfy the high - order consistency condition .",
    "similar trends can be seen when the wta is clamped to @xmath160 and when both the wta and the wta are clamped to @xmath160 .",
    "figure  [ fig : explainingaway_c ] highlights the explaining away effect . in the free running network ,",
    "the normalized duration of time in which is equal to @xmath160 is @xmath161 .",
    "this can be interpreted as the `` marginal probability '' of = 1 . when the outcome is clamped to @xmath160 ,",
    "this marginal probability increases as one of the causes is needed to explain the outcome ( it can now be interpreted as the marginal probability conditioned on = 1 ) . when in addition is clamped to @xmath160 ,",
    "the probability of = 1 goes down again as is not needed to explain the outcome when is @xmath160 .",
    "table  [ tab : parameters ] contains the parameter values for the network simulations in figs.1 , 3 , and 4 in the main text and supplementary figs .",
    "[ fig : kl ] and [ fig : explainingaway ] .",
    "the noise and phase coupling terms are only non - zero in the simulations in fig .  4 . table  [ tab : parameterssud ] contains the parameter values used in the sudoku network in fig.2 .",
    "table  [ tab : parameters2 ] contains the parameter values used in the simulations of the perceptual multi - stability model ( figs .",
    "6 and 7 ) .",
    "parameter values are only shown in tables  [ tab : parameterssud ] and  [ tab : parameters2 ] if they differ from those in table  [ tab : parameters ] .",
    "@xmath162 & 0.6 & fraction of oscillation cycle with active inhibitory output + @xmath163 & uniform(45,46)hz & distribution of oscillation frequencies + @xmath41 & 40 hz & amplitude of oscillatory inhibition + @xmath164 & -3 & weight oscillatory inhibition to excitatory populations + @xmath165 & -1 & weight oscillatory inhibition to inhibitory populations +   + @xmath45 & 0.3 ms & excitatory population time constant + @xmath47 & 0.2 ms & inhibitory population time constant + @xmath43 & 80 ms & @xmath0 time constant + @xmath48 & 8 & inhibitory population threshold + @xmath46 & -18 & excitatory population threshold + @xmath166 & 1.2 & recurrent intra - wta non-@xmath0 excitatory weight + @xmath167 & 0.004 & recurrent intra - wta @xmath0 excitatory",
    "weight + @xmath168 & 0.5 & intra - wta non-@xmath0 excitatory to inhibitory weight + @xmath169 & 0.3 & intra - wta @xmath0 excitatory to inhibitory weight + @xmath170 & -1 & intra - wta inhibitory to excitatory weight + @xmath171 & 0.06 & weight of inter - wta non-@xmath0 coupling connection from @xmath172 to @xmath173 + @xmath174 & 0.005 & weight of inter - wta @xmath0 coupling connection from @xmath172 to @xmath173 +   + @xmath61 & 200 & noise scaling factor in the high noise case + @xmath61 & 50 & noise scaling factor in the low noise case + @xmath62 & 0.7 & phase perturbation per cycle for both the low - noise and high - noise case + @xmath175,@xmath176 & 5 & phase coupling strength between v0-v3 +     @xmath162 & 0.17 & fraction of oscillation cycle with active inhibitory output + @xmath163 & uniform(40,60)hz & distribution of oscillation frequencies + @xmath41 & 40 hz & amplitude of oscillatory inhibition +   + @xmath45 & 0.5 ms & excitatory population time constant + @xmath48 & 6 & inhibitory population threshold + @xmath46 & -2 & excitatory population threshold + @xmath166 & 1.8 & recurrent intra - wta non-@xmath0 excitatory weight + @xmath167 & 0.0001 & recurrent intra - wta @xmath0 excitatory",
    "weight + @xmath168 & 0.6 & intra - wta non-@xmath0 excitatory to inhibitory weight + @xmath170 & -1.6 & intra - wta inhibitory to excitatory weight + @xmath171 & 0.002 & weight of inter - wta non-@xmath0 coupling connection from @xmath172 to @xmath173 + @xmath174 & 0.0 & weight of inter - wta @xmath0 coupling connection from @xmath172 to @xmath173 +     @xmath162 & 0.27 & fraction of oscillation cycle with active inhibitory output + @xmath177 & 45hz & oscillation frequency to which oscillators couple , when synchronized + @xmath163 & uniform(43,53)hz & distribution of oscillation frequencies +   + @xmath45 & 0.5 ms & excitatory population time constant + @xmath46 & -2 & excitatory population threshold + @xmath167 & 0.005 & recurrent intra - wta @xmath0 excitatory weight + @xmath170 & -1.1 & intra - wta inhibitory to excitatory weight +   + @xmath99 & 0.03 & maximal weight of plastic synapse + @xmath98 & 0 & minimal weight of plastic synapse + @xmath100 & 38 hz & learning threshold + @xmath101 & @xmath178/s & potentiation rate + @xmath102 & @xmath179/s & depression rate + @xmath104&0.002/s & upward drift rate + @xmath105&0.0005/s & downward drift rate +   + @xmath180 & 0.000216 & weight from hidden wta to readout wta + @xmath166 & 1 & recurrent intra - wta non-@xmath0 excitatory weight + @xmath167 & 0.001 & recurrent intra - wta @xmath0 excitatory",
    "weight + @xmath168 & 0.3 & intra - wta non-@xmath0 excitatory to inhibitory weight +        thilo womelsdorf , jan - mathijs schoffelen , robert oostenveld , wolf singer , robert desimone , a.k .",
    "engel , and pascal fries .",
    "modulation of neuronal interactions through neuronal synchronization . , 316(5831):16091612 , 2007 .",
    "cardin , marie carln , konstantinos meletis , ulf knoblich , feng zhang , karl deisseroth , li - huei tsai , and c.i .",
    "moore . driving fast - spiking cells",
    "induces gamma rhythm and controls sensory responses .",
    ", 459(7247):663667 , 2009 .",
    "bosman , jan - mathijs schoffelen , nicolas brunet , robert oostenveld , a.m. bastos , thilo womelsdorf , birthe rubehn , thomas stieglitz , peter de weerd , and pascal fries .",
    "attentional stimulus selection through selective synchronization between monkey visual areas .",
    ", 75(5):875888 , 2012 .",
    "h.  mostafa , l.  k. mller , and g.  indiveri .",
    "recurrent networks of coupled winner - take - all oscillators for solving constraint satisfaction problems . in c.j.c .",
    "burges , l.  bottou , m.  welling , z.  ghahramani , and k.q .",
    "weinberger , editors , _ advances in neural information processing systems ( nips ) _ , volume  26 , pages 719727 , 2013 .",
    "matthew ainsworth , shane lee , m.o .",
    "cunningham , a.k .",
    "roopun , r.d .",
    "traub , and n.j .",
    "kopelland  m.a .",
    "dual gamma rhythm generators control interlaminar synchrony in auditory cortex .",
    ", 31(47):1704017051 , 2011 .",
    "burns , p.  samuel , d.  xing , m.j .",
    "shelley , and r.m .",
    "searching for autocoherence in the cortical network with a time - frequency analysis of the local field potential .",
    ", 30(11):40334047 , 2010 ."
  ],
  "abstract_text": [
    "<S> gamma - band rhythmic inhibition is a ubiquitous phenomenon in neural circuits yet its computational role still remains elusive . we show that a model of gamma - band rhythmic inhibition allows networks of coupled cortical circuit motifs to search for network configurations that best reconcile external inputs with an internal consistency model encoded in the network connectivity . </S>",
    "<S> we show that hebbian plasticity allows the networks to learn the consistency model by example . </S>",
    "<S> the search dynamics driven by rhythmic inhibition enable the described networks to solve difficult constraint satisfaction problems without making assumptions about the form of stochastic fluctuations in the network . </S>",
    "<S> we show that the search dynamics are well approximated by a stochastic sampling process . </S>",
    "<S> we use the described networks to reproduce perceptual multi - stability phenomena with switching times that are a good match to experimental data and show that they provide a general neural framework which can be used to model other perceptual inference phenomena . </S>"
  ]
}