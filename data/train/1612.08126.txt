{
  "article_text": [
    "in this paper we present a new brain machine interface for a human user to control a swarm of robots , which we call a brain - swarm interface ( bsi ) .",
    "the bsi uses an off - the - shelf electroencephalogram ( eeg ) headset to record brain and muscle activity from the user s scalp .",
    "we use both signals from brain neuron activity , as well as signals from contracting muscles due to eye movement , to generate control signals for the robot swarm .",
    "we allow the user to control the dispersion / aggregation of the swarm , as well as the direction of motion of the swarm .",
    "the dispersion / aggregation is determined from the user s brain neuronal signals , and is decoded using an hmm - based method .",
    "the direction of motion is decoded from the user s eye movements with a multi - step signal processing algorithm .",
    "the robots maintain a cohesive swarm using a potential - field based swarm controller , and the dispersion / aggregation and direction of motion commands influence the motion of the robots through parameters in their swarm controller .",
    "brain computer interfaces hold great promise for enabling people with various forms of disabilities , from restricted motion due to injury or old age , to severe disabilities like the als ( locked - in syndrome ) , tetraplegia , and paralysis .",
    "several works have investigated using bcis for controlling prosthetics @xcite , @xcite , and for medical rehabilitation .",
    "if implemented effectively , bci technology may allow people with disabilities the power to manipulate their environment , and to move themselves within their environment @xcite .",
    "researchers have also developed brain interfaces for controlling single mobile robot platforms .",
    "for example bin he et al .",
    "@xcite have demonstrated 3d control of a quadcopter , and tim bredtl et al . @xcite",
    "have remotely teleoperated a uav , both using motor imagery bci .",
    "c j bell et al .",
    "@xcite have controlled a humanoid with a non invasive bci using p300 signals .",
    "however , brain computer interfaces for controlling swarms have received little attention in the literature .    whereas the motivation for a bci operated prosthetic or wheelchair is evident , the applications for a brain swarm interface may be less obvious .",
    "we envision several applications for this technology .",
    "firstly , people who are mobility - impaired may use a swarm of robots to manipulate their environment using a brain - swarm interface .",
    "indeed , a swarm of robots may offer a greater range of possibilites for manipulation than what is afforded by a single mobile robot or manipulator .",
    "for example a swarm can reconfigure to suit different sizes or shapes of objects , or to split up and deal with multiple manipulation tasks at once .",
    "another motivation for our work is that using a brain interface may unlock a new , a more flexible , way for people to interact with swarms .",
    "currently human swarm interfaces are largely restricted to gaming joysticks with limited degrees of freedom .",
    "however , swarms typically have many degrees of freedom , and the brain has an enormous potential to influence those degrees of freedom beyond the confines of a traditional joystick .",
    "we envision that the brain can eventually craft shapes and sizes for swarm , split a swarm into sub swarms , aggregate or disperse the swarm , and perhaps much more . in this work ,",
    "we take a small step toward this vision .",
    "the user generates brain and eye movement signals .",
    "@xmath0 the emotiv epoc headset records these signals from the scalp and wirelessly transmits them to the computer . @xmath1",
    "the computer receives the pose of the robots .",
    "@xmath2 the computer decodes the eye movements and thoughts , and transmits control signals to the robots . @xmath3",
    "the optitrack captures pose of robots . @xmath4",
    "the user receives visual feedback . ]",
    "the brain is arguably the most complex organ in the human body .",
    "brain activity occurs mainly in the chemical and electromagnetic domain .",
    "different areas of the brain are responsible for different thoughts and actions .",
    "the eeg is one of the few ways in which brain activity can be monitored in a non - invasive manner .",
    "an eeg measures the electrical signals generated by the brain , but it also measures electrical noise and artifacts generated by eye movements and other muscle activity .",
    "we use the concept of hybrid bci or hbci popularized by pfurtscheller et al . @xcite and utilize the `` artifacts '' generated by eye movements , which are usually discarded in bci systems , as control input to modulate the position and size of a robotic swarm .",
    "a survey of other hbci systems , which do not include application to robotic swarms , can be found in @xcite .",
    "one of the key components of a typical bci paradigm is the machine learning and pattern recognition pipeline . a survey by f lotte et al .",
    "@xcite surveys the various types of classifiers that have been used in the literature . in our work",
    ", we adopt a hidden markov model ( hmm ) technique to estimate the user s thought state , as the dynamic nature of the technique is well - suited to online estimation and control input generation .",
    "we use outputs from an emotiv epoc eeg headset as observations for the hmm algorithm .",
    "the hmm algorithm then maps these continuous observations to discrete thought states which in turn generate the control inputs for the swarm .",
    "the control inputs are converted to motor speeds for the respective robots and transmitted through zigbee protocol wirelessly .",
    "the user receives visual feedback from the ground robots , either by directly observing the robots , or from a live visual feed rendered on a video screen .",
    "the main interacting components in our system are illustrated in fig .",
    "[ control_loop ] .",
    "the rest of this paper is organized as follows . in section [ sec : problemformulation ] we introduce notation and formally state the problem . in section [ sec : system ]",
    "we describe the signal processing and control components that go into our system .",
    "section [ sec : experiments ] presents the results of simulation and hardware experiments , and conclusions are given in section  [ sec : conclusions ] .",
    "let the position of the swarm be described by the vector @xmath5^t \\in \\mathbb{r}^{nm}$ ] where @xmath6 denotes the number of agents in an @xmath7 dimensional euclidean space .",
    "the position of the @xmath8 individual at time @xmath9 is described by @xmath10 .",
    "suppose the user has an intended trajectory for the swarm , which we denote @xmath11 .",
    "when thinking about this trajectory , the user s eeg headset produces signals at time @xmath9 , denoted by @xmath12 , where @xmath13 is the number of sensors on the eeg headset .",
    "let @xmath14 be a vector of control parameters of the system given by @xmath15 where @xmath16 , @xmath17 @xmath18 denote the attraction and repulsion gains , respectively , which are used to control the size of the swarm , and @xmath19 denotes the displacement vector for controlling the movement of the swarm .",
    "we state our problem as follows .",
    "[ prob : bsi ] design a signal processing pipeline to determine the swarm control parameters @xmath20 from the eeg signals @xmath21 , so that the swarm trajectory approaches the user s intended swarm trajectory , @xmath22 .",
    "to control the swarm , we adapt a potential field based swarm controller of a type that is common in controlling swarms of ground robots . with this type of controller ,",
    "the system dynamics are given by @xmath23 where @xmath24 and @xmath25 is a function which depends on pairwise interactions between agents @xmath26 and @xmath27 , and has parameters @xmath28 , @xmath29 , and @xmath30 . in our proposed solution ,",
    "we first train an hmm , and use it to determine the `` thought state '' of the user @xmath31 , where for example , @xmath32 indicates `` aggregation '' and @xmath33 indicates `` dispersion . ''",
    "then we map this though state @xmath34 to values for @xmath35 to control the aggregation / dispersion of the swarm .",
    "secondly , we design an eye movement classifier which takes eeg signals @xmath36 , where @xmath37 with @xmath38 , as input to determine the user s intended motion of the swarm , producing a control parameter @xmath39 for the swarm .",
    "this pipeline is shown graphically in fig .",
    "[ control_flow ] , and its components are described in more detail in the following section .",
    "in the previous section we stated the problem , and introduced the main elements of our solution as shown in fig [ control_flow ] . the following paragraphs will describe the hmm , eye movement detection , and formation control strategies in detail .",
    "based on a survey by f. lotte et al .",
    "@xcite we adopted hidden markov models to train and classify eeg data .",
    "previously , researchers have used hmms for bcis .",
    "pfurtscheller et al .",
    "@xcite used an hmm to classify eeg data , and hmms have been used in conjunction with other techniques @xcite , as well .",
    "our novel hmm implementation uses performance metrics generated by the emotiv software suite as observations and maps them to discrete thoughts .",
    "we observe that each thought will corresponds to different signatures of these metrics .",
    "however , these signatures vary greatly across different trials and experimental conditions , so a heuristic approach to classify them is not effective .",
    "instead we implement a training phase to train the hmm to detect the users though signatures and transition probabilities . using standard terminology and notation for hmms , @xcite , @xcite ,",
    "here we will describe our system in detail .",
    "a hidden markov model is a joint probabilistic model of a collection of discrete random variables @xmath40 described by : @xmath41 many algorithms exist for both learning the transition probabilities and observation probabilities of such a system from data , and determining a likely sequence of states hidden @xmath42 from data .",
    "the observations of these states @xmath43 can be discrete or continuous .",
    "the main components of the model from equation [ hmm_equation ] are :    * @xmath44 which is the initial state probability distribution and is represented by @xmath45 where @xmath46 , * @xmath47 is the state transition probability represented by the matrix @xmath48 where @xmath49 * @xmath50 is the observation probability represented by the gaussian distribution @xmath51 with means @xmath52 and covariance matrix @xmath53 .",
    "the model can be completely described by parameters @xmath54 .",
    "the initial phase involves learning these parameters @xmath55 to generate the model using training data consisting of observations of the expected state space .",
    "we employ the baum - welch algorithm ( a version of expectation maximization ( em ) ) to train the model parameters . after the training phase we use the forward algorithm to estimate the state of the model online using the current observations .",
    "we are use a two state hmm which represents two distinct thoughts of the user , so @xmath56 in our case .",
    "the observation space consists of the eeg output @xmath21 . in this case , the signal @xmath21 is derived from performance metrics provided by the manufacturer of the eeg headset , emotiv .",
    "emotiv provides six metrics :  engagement \" ,  meditation \" ,  excitement \" ,  frustration \" ,  valence \" and  long - term excitement \" out of which we use the first three metrics , which makes @xmath57 and also @xmath58 $ ] for all metrics .",
    "training data consisting of the three metrics mentioned before is recorded in a single trial . during the training period",
    "the user repeats two thoughts through a pre - defined switching sequence .",
    "we enforced this thought sequence using a timed slide presentation which the user observed during training .",
    "this training data is fed into the baum - welch algorithm which estimates the parameters @xmath55 for the system .",
    "the em algorithm is a two step iterative process ( expectation followed by maximization ) , which can be expressed in the single expression @xmath59 ,   \\label{em_eqn}\\ ] ] where @xmath60 is the log likelihood function , @xmath61 is the unobserved state , @xmath55 is the unknown parameters of the model , and @xmath62 is the observed variable .",
    "the expectation step can be summarized by calculating the following quantities : @xmath63 where @xmath64 is known as the forward variable , and is the probability of ending in state @xmath26 and seeing the partial observations @xmath65 given the model parameters @xmath55 , and @xmath66 where @xmath67 is known as the backward variable , and is the probability of observing partial sequences @xmath68 given the model parameters and state at time @xmath9 . with @xmath69 and @xmath70 we can compute @xmath71 where @xmath72 is the probability of being in state @xmath26 given the model parameters and observations , as well as @xmath73 where @xmath74 is the probability of being in state @xmath26 at time @xmath9 and state @xmath27 at time @xmath75 .",
    "using the above defined quantities in the expectation step we can estimate the parameters @xmath55 in the maximization step of our system as follows :    @xmath76    naturally , for this procedure to start we need @xmath77 which is the set of initial model parameters from which recursion begins according to eqn .",
    "( [ em_eqn ] ) .",
    "we adopt a k - means clustering approach to initialize the model parameters , specifically the mean matrix @xmath78 .",
    "we used a two class k - means approach with the observations @xmath62 as inputs , which give us the centroids of the two classes that we used to initialize @xmath78 .",
    "the other parameters of @xmath55 are initialized randomly .",
    "we stop the iterative process when we observe only minute changes ( order of @xmath79 ) in the estimated parameters from their previous estimations .",
    "a typical training signal from our experiments is shown in fig .",
    "[ observation_data ] and the resulting state sequence after training is shown in fig .",
    "[ state_estimation ] .",
    "the user visited the two states ( thoughts ) twice each during the training period . from fig .",
    "[ state_estimation ] one can see that the baum - welch algorithm detects the switching sequence between the thoughts , since at each all times the state is found to be decisively in either one or the other state with high probability .",
    "that is , at all times one state is red ( meaning the probability that the user is in that thought state is nearly one ) , while the other is blue ( meaning probability that the user is in that thought state is almost zero ) .      after the model parameters @xmath55 have been estimated we can employ the hmm for online estimation of the state",
    "however , we can not immediately proceed to online estimation .",
    "first , we have to relate the hmm states back to the original thoughts .",
    "specifically , we do not know whether @xmath32 means an `` aggregate '' thought and @xmath33 means a `` disperse '' thought , or visa versa .",
    "we assign the abstract states to meaningful thoughts by examining the order of thoughts visited by the user during training to the @xmath80 value calculated during the training .",
    "which ever assignment makes the @xmath81 sequence best match the thought sequence is the chosen assignment .",
    "online estimation of state is now a straightforward application of the forward algorithm for hmms using the learn parameters from the training phase .",
    "this allows us to find the most likely sequence of thought states on line as a streaming signal arrives from the eeg .",
    "all we need for this phase is to calculate the value of @xmath64 from eqn.[alpha_eqn ] for the current time @xmath9 for all the states @xmath26 and determine the most probable state at that time .",
    "so we can describe the control output from the hmm at time @xmath9 given by @xmath82 as @xmath83 the output @xmath84 is used to determine the the control parameters @xmath85 for aggregation and dispersion of the swarm , as described in sec .",
    "[ sec : formationcontrol ] below .      in traditional eeg research ,",
    "eye movement signals are considered as artifacts and are removed .",
    "in contrast , we use these signals as inputs for our system to command the direction of travel for the robots . there are various available methods in the literature for detecting and tracking eye movements , which vary considerably @xcite .",
    "these methods can be broadly categorized into ( i ) contact based tracking which offer high accuracy and sophistication , ( ii ) non - contact based optical tracking methods which measure relative positioning remotely with sensors such as cameras , and ( iii ) measuring surface electrical potentials from skin , also known as electrooculogram ( eog ) , near the eyes .",
    "our eeg headset detects these eog signals related to eye movement , hence we can detect eye movement with no additional hardware .      the human eye can be modeled as an electrical dipole whose axis is roughly collinear to the axis of the human eye .",
    "the electrical dipole rotates with the rotation of the eye causing small differences ( in microvolts ) between the electrical potential at the skin surface depending on eye position .",
    "the order of magnitude of these signals are much larger than signals due to brain activity evident from fig .",
    "[ u_d_detection ] and fig.[l_r_detection ] , hence they can be measured and contrasted easily .",
    "eog typically uses exclusive electrodes around the eyes to measure movements .",
    "but our electrode positions are fixed so we employ the four closest electrodes to the eyes : ` af3',`af4',`f7 ' and ` f8 ' , according to the 10 - 20 eeg sensor placement system , as shown in the diagram in fig .",
    "[ sensor_placement ] .",
    "previous methods to detect eye motion have relied on complex classification based algorithms .",
    "in contrast , our method uses a simple statistical calculation .",
    "the spatio - temporal signals from these electrodes near the eyes can be described by @xmath86 where @xmath87 denoting the electrodes used .",
    "we first normalize the signal by subtracting its mean for each electrode to center the signals about zero .",
    "this can be described by @xmath88 where @xmath89 denotes the number of samples used for the baseline removal .",
    "electrodes f7 and f8 are chosen for horizontal eye movement detection as they are the farthest apart in the horizontal plane while being closest to the eyes .",
    "our algorithm for decoding horizontal directional movement depicted in fig .",
    "[ l_r_detection ] is described in algorithm [ l_r_algo ] . in fig .",
    "[ l_r_detection ] the green ellipses indicate the signal for leftward eye movement and the blue ellipses indicate rightward eye movement .",
    "the red ellipse represents blinks which are filtered out .",
    "+ remove baseline with @xmath90 samples .",
    "+ window the data with window size @xmath91 @xmath92 where @xmath93 represents the window number .",
    "we use @xmath94 samples corresponding to 1 second of data with no overlap .",
    "+ apply @xmath95 order 4 hz low pass butterworth filter to the windowed data to isolate the eye movement signals .",
    "+ subtract the resulting signals from both electrodes @xmath96 + detect peaks and troughs with threshold magnitude of @xmath97 and minimum seperation of @xmath98 samples in @xmath99 .",
    "+ assign peaks to eye movements to the left @xmath100 and troughs to eye movements to the right @xmath101 .",
    "electrodes af3 and af4 are chosen for vertical eye movement detection .",
    "the method used is different from horizontal eye movement detection since we do not have any electrode below the eyes to detect the dipoles in the vertical plane of the head .",
    "eye movement upwards results in a positive deflection in both electrodes whereas eye movement downwards has negative deflection for both electrodes .",
    "our algorithm for decoding vertical eye movement is depicted in fig [ u_d_detection ] and described in algorithm [ u_d_algo ] . in fig [ u_d_detection ] ,",
    "the green ellipses indicate the signal for vertical eye movement , and the blue ellipses indicate horizontal movement .",
    "the red ellipse represents blinks which are filtered out .",
    "+ remove baseline with @xmath90 samples . + window the data similar to equation [ window ] + same as step 3 in algorithm 1 .",
    "+ add the signals from both the electrodes to get @xmath102 + find peaks and troughs with minimum seperation of @xmath98 and a signal level of @xmath103 - @xmath104 from @xmath105 .",
    "+ assign peaks to upward eye movements @xmath106 and troughs to downward eye movements @xmath107 .",
    "it should be noted that both the algorithms above also filter out blinks , which look quite similar to the eye movements ( see figs .",
    "[ u_d_detection ] and [ l_r_detection ] ) . in the case of horizontal eye movements , the f7 and f8 electrodes both record blinks with almost equal magnitude since they are located approximately at the same distance from the eyes .",
    "hence the signal @xmath99 is automatically devoid of blinks ( eqn [ af3+af4 ] ) , as evident from fig [ l_r_detection ] .",
    "for the vertical eye movement detection , we introduce an upper threshold to filter out the blinks , which typically are much larger than eye movement signals , as can be seen in fig .",
    "[ u_d_detection ] .",
    "hence , our algorithm effectively discards blinks and measures only the user s intentional eye movements .",
    "finally , after the left - right and up - down signals have been extracted form the user s eye movements , these signals are used to control the left - right and forward - backward motion of the robot swarm through the control parameter @xmath39 , as described below in sec .",
    "[ sec : formationcontrol ]         are shown graphically from top to bottom .",
    "the bottom plots show the final extracted left and right eye movements.,width=288,height=480 ]     are shown graphically from top to bottom .",
    "the bottom plots show the final extracted up and down eye movements.,width=288,height=480 ]      we described the general form of the potential field based formation controller above in sec  [ sec : problemformulation ] .",
    "we refer the reader to for details and proofs about stability and convergence properties . here",
    "we describe how we control the size and motion of the swarm through the parameters @xmath108 .",
    "recall that the system is described by the two dimensional state space equation for the @xmath8 agent @xmath109 we let the interaction between robots @xmath26 and @xmath27 be given by @xmath110 where @xmath111 is the radius of the robot .",
    "we can see that the left term provides the attracting field , and the right the repelling field .",
    "the @xmath111 term introduces a safety region around the robots so collision can be avoided .",
    "there is an equilibrium inter - robot distance for this system , in which attraction and repulsion forces balance .",
    "let that equilibrium distance be denoted @xmath112 , so that @xmath113 .",
    "this @xmath112 is governed by the attraction and repulsion gains @xmath28 and @xmath29 respectively . in our method",
    "we vary the gains to achieve different equilibrium formation .",
    "we map the two state output from the hmm to two distinct sets of gains in order to achieve the aggregation and dispersion of the swarm .      now to control the motion of the swarm we rely on the output from the eye movement detection which gives us four possible motion commands : forward , backward , left , and right .",
    "we use these command to assign values to the vector @xmath30 , which drives every robot in the swarm in the same direction [ potential_function_eqn ] . depending on the eye movement the vector @xmath30",
    "is assigned preset values which makes all the agents in the swarm move locally in the direction of @xmath30 independent of the swarms aggregation or dispersion .",
    "to demonstrate our brain - swarm interface , we developed a simulation environment in matlab .",
    "we chose a section of the boston university campus , with a rectangular path around a campus building , as shown in [ centroid_sim ] .",
    "the path is divided into 4 edges and the swarm has to be driven starting from the left of edge 1 and end on the top of edge 4 following a clockwise motion . at edge 3 ( purple path ) due to the narrow passageway , the user has to make the swarm aggregate into a tighter swarm by switching thoughts , while in edges 1 , 2 and 4 ( blue path ) the user makes the swarm disperse .    for the training phase",
    ", the user switched between two thoughts at least twice over a period of 60 seconds , during which the eeg signals were recorded and fed into the baum - welch algorithm ( fig .",
    "[ fig : baum_welch ] ) to get the model parameters as described in sec .",
    "[ sec : hmm ] .",
    "the thoughts used for simulations and experiment were distinct and repeatable : the disperse state was invoked with a relaxed neutral thought , while the aggregate state was invoked by a mentally challenging task ( in this case calculating the fibonacci series ) .",
    "then eeg signals were streamed live and processed as discussed previously to generate the control inputs @xmath14 .    the simulated swarm consisted of 128 point sized holonomic robots .",
    "the attraction gain @xmath28 was fixed at @xmath114 and the repulsion gain @xmath29 was calculated according to @xmath115 , where @xmath116 is the estimated state sequence from ( [ forward_eqn ] ) . in our @xmath117 state hmm case according to the previous formula the user s thought corresponding to state @xmath114 causes the robots to disperse and increase swarm size , and for state @xmath117 causes the robots to converge and aggregate to a smaller size .",
    "the swarm reaches its equilibrium size for a particular thought state and stays at that size until the user switches thoughts .",
    "the results of the simulation exercise is summarized in figs .",
    "[ sim_results ] and [ centroid_sim ] .",
    "[ sim_results ] shows the time history of eye movement detection and the mental thought estimation during the motion of the swarm along the 4 legs of the path .",
    "it can be seen that the thought estimation remains mostly in the disperse state during legs 1 , 2 , and 4 , and is mostly in the aggregate state in sector 3 , as intended .",
    "minor inaccuracies can be attributed not only to the stochastic nature of the hmm , but also to the quality of user s thoughts and noise in the eeg headset . from fig .",
    "[ centroid_sim ] which shows the path of the centroid of the swarm , we can see the eye movement detection is successful in steering the swarm , with a few misclassifications due to the nature of the noisy eeg signals and non - intentional eye movements .",
    "we refer the reader to the accompanying video .        for the hardware experiments we used the m3pi platform with an mbed controller for mobile swarming robots , and zigbee radios for communication .",
    "the experiments were carried out in an environment with an optitrack motion capture system to track the motion of the robots ( see fig .  [ m3pi_robots ] ) .",
    "the control parameters used were @xmath118 and @xmath119 for aggregation , and @xmath120 and @xmath119 for dispersion .",
    "these two wheeled differential drive robots receive individual motor speeds as control inputs from the computer .",
    "a proportional point - offset controller is used to generate the motor speeds from the potential function controller ( the details of which can be found in @xcite ) .",
    "the control commands for the robots were computed off board the robots , and set to the robots over zigbee at an update rate of 30 hz . due to computational and hardware complexities",
    "the computations were divided among 3 computers ( one for optitrack data acquisition , one for controller implementation , and another other for eeg signal processing and video recording ) as shown in the experimental setup in fig .",
    "[ exp_setup ] .",
    "the tcp / ip protocol was used for communication among them . the experimental area ( fig .  [ centroid_exp ] )",
    "was chosen to be a rectangular area divided into 4 legs , similarly to the simulation . in sector 3",
    "the user again must make the swarm aggregate , and in the other legs the swarm should disperse , while navigating in a clockwise manner starting from sector 1 .",
    "the user obtained visual feedback of the position of the swarm by viewing a live feed of the experimental area from a gopro camera on a mobile device .",
    "the experimental results are summarized in figs .",
    "[ exp_result ] and [ centroid_exp ] .",
    "[ exp_result ] shows the time history of eye movement detection and the thought state estimation throughout the motion of the swarm along the 4 legs . from fig .",
    "[ centroid_sim ] which shows the path of the robots and their centroid , we can see the eye movement detection is successful in steering the swarm .",
    "the color map for the thought state estimation again shows that the hmm is able to reliably determine the user s intention .",
    "the system remains in the disperse state with high confidence during legs 1 , 2 , and 4 , and in the aggregate state with high confidence during sector 3 .",
    "we again refer the reader to the accompanying experiment video .",
    "the biggest challenge in this work is in the integration of this complex system with interacting hardware , communication , software , and human components .",
    "we used holonomic dynamics during simulation whereas the m3pis are nonholonomic robots with inefficient actuation and communication .",
    "in addition , it was quite a mental challenge for the user to concentrate on thoughts , eye movement , and system monitoring simultaneously . despite these challenges ,",
    "we were able to successfully demonstrate the proposed method .",
    "in this paper we propose and successfully demonstrate an online brain swarm interface to control a swarm of ground vehicles in simulation and experiments using off - the - shelf hardware .",
    "we integrate a variety of engineering and scientific techniques in neuroscience , signal processing , machine learning , control theory , and swarm robotics to construct and implement our system .",
    "we successfully navigate a robot swarm in simulation and experiment on a given path .",
    "the techniques developed in this paper are a proof of concept to demonstrate that a swarm of robots can be controlled by the thoughts and eye movements of a human user .",
    "these techniques can be applied to create an intuitive interface especially for people to control multiple objects in their environment simultaneously .",
    "however , there is significant room for improvement . in the future",
    "we plan to develop a richer hmm algorithm that can detect a larger range of user intentions for the swarm , including the ability to induce a range of different shapes and motions for the swarm .",
    "we also plan to extend the algorithm to control a swarm of quadrotors robots in 3 dimensional space .",
    "we thank alyssa pierson for her help in developing the point offset controller to control individual m3pi robots .",
    "niels birbaumer ,  breaking the silence : brain  computer interfaces ( bci ) for communication and motor control\",_psychophysiology _ , 43 ( 2006 ) , 517532 .",
    "karl lafleur et al . ,  quadcopter control in three - dimensional space using a noninvasive motor imagery - based brain  computer interface \" ,",
    "_ j. neural eng.10(2013 ) _ 046003 ( 15pp ) .",
    "abdullah akce , miles johnson and timothy bretl,remote teleoperation of an unmanned aircraft with a brain - machine interface : theory and preliminary results \" _ ieee international conference on robotics and automation_,2010,alaska , usa .",
    "christian j bell , pradeep shenoy , rawichote chalodhorn , and rajesh pn raocontrol of a humanoid robot by a noninvasive brain  computer interface in humans\",_journal of neural engineering _ ( 2008 ) 214220 .",
    "robert leeb , doron friedman , gernot r. muller - putz , reinhold scherer , mel slater , gert pfurtscheller ,  self - paced ( asynchronous ) bci control of a wheelchair in virtual environments : a case study with a tetraplegic \" _ computational intelligence and neuroscience_,volume 2007 , article i d 79642,hindawi publishing corporation .",
    "gernot r. muller - putz and gert pfurtscheller,control of an electrical prosthesis with an ssvep - based bci\",_ieee transactions on biomedical engineering_,vol .",
    "1 , january 2008 .",
    "pfurtscheller g , allison bz , brunner c , bauernfeind g , solis - escalante t , scherer r , zander to , mueller - putz g , neuper c , birbaumer n,the hybrid bci\",_frontiers in neuroscience _",
    "setare amiri , reza fazel - rezai , and vahid asadpour,a review of hybrid brain - computer interface systems\",_advances in human - computer interaction_,hindawi publishing corporation , volume 2013 , article i d 187024 .",
    "fabien lotte , marco congedo , anatole lecuyer , fabrice lamarche , bruno arnaldi ,  a review of classification algorithms for eeg - based brain  computer interfaces , \" _ journal of neural engineering_,iop publishing , 2007 .",
    "l. r. rabiner ,  a tutorial on hidden markov models and selected applications in speech recognition , \" _ proceedings of the ieee _ , vol 77 , no 2 , 257287 .",
    "j.a bilmes ,  a gentle tutorial of the em algorithm and its application to parameter estimation for gaussian mixture and hidden markov models,\"_icsi uc berkeley _",
    "ca tr-97 - 021 .",
    "b obermaier , c guger , c neuper , g pfurtscheller.hidden markov models for online classification of single trial eeg data \" , _ pattern recognition letters _",
    ". h. lee and s. choi , ",
    "pca+hmm+svm for eeg pattern classification,\"_proceedings of 7th international symposium on signal processing and its applications _ , vol . 1 , 2003 , pp .",
    "thomas eggert ,  eye movement recordings : methods\",_neuro - opthalmology , neuronal control of eye movements _ , karger , 2007 , vol 40 , pp 1534 .",
    "gazi and passino(2004 ) : a class of attractions / repulsion functions for stable swarm aggregations , _ international journal of control_,2004,vol .",
    "18 , 15671579 .",
    "olfati - saber , r. , and murray , r. m. , distributed cooperative control of multiple vehicle formations using structural potential functions .",
    "_ proceedings of ifac world congress _ , 2002,barcelona , spain .",
    "a. howard and m. j. matari and g. s. sukhatme , `` mobile sensor network deployment using potential fields : a distributed , scalable solution to the area coverage problem , '' _ proceedings of the 6th international symposium on distributed autonomous robotic systems ( dars02 ) _ , fukuoka , japan , june 2002 .",
    "alyssa pierson and mac schwager ,  bio - inspired non cooperative herding\",_proc ieee icra 2015_,may 2015 , 1843 - 1869 ."
  ],
  "abstract_text": [
    "<S> this work presents a novel marriage of swarm robotics and brain computer interface technology to produce an interface which connects a user to a swarm of robots . </S>",
    "<S> the proposed interface enables the user to control the swarm s size and motion employing just thoughts and eye movements . </S>",
    "<S> the thoughts and eye movements are recorded as electrical signals from the scalp by an off - the - shelf electroencephalogram ( eeg ) headset . </S>",
    "<S> signal processing techniques are used to filter out noise and decode the user s eye movements from raw signals , while a hidden markov model technique is employed to decipher the user s thoughts from filtered signals . </S>",
    "<S> the dynamics of the robots are controlled using a swarm controller based on potential fields . </S>",
    "<S> the shape and motion parameters of the potential fields are modulated by the human user through the brain - swarm interface to move the robots . </S>",
    "<S> the method is demonstrated experimentally with a human controlling a swarm of three m3pi robots in a laboratory environment , as well as controlling a swarm of 128 robots in a computer simulation . </S>"
  ]
}