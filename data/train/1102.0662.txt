{
  "article_text": [
    "we consider numerical integration of stochastic differential equations ( sdes ) in the it s sense @xmath1.\\ ] ] here @xmath2 .",
    "we assume that @xmath3 is an @xmath4-dimensional wiener process defined on the complete probability space @xmath5 with an increasing filtration @xmath6 satisfying the usual conditions . and the initial data @xmath7 is independent of the wiener process .",
    "( [ sdes ] ) can be interpreted mathematically as a stochastic integral equation @xmath8 , \\mathbb{p}-a.s.,\\ ] ] where @xmath9 for @xmath10 and the second integral is the it integral .",
    "this article is concerned with the strong approximation problem ( see , e.g. , section 9.3 in kloeden and platen @xcite ) of the sdes ( [ itsde ] ) . more precisely , on a uniform mesh with stepsize @xmath11 defined by @xmath12 , we want to compute a numerical approximation @xmath13 with @xmath14 such that @xmath15 for a given precision @xmath16 with the least possible computational effort .",
    "the strong convergence problem becomes very important because efficient multi - level monte carlo ( mlmc ) simulations rely on the strong convergence properties @xcite .    the simplest and most obvious idea",
    "to solve the strong approximation problem ( [ err ] ) is to apply the explicit euler scheme @xcite @xmath17 where @xmath18 .",
    "the method is strongly convergent with order one half if the coefficients @xmath19 satisfy the global lipschitz condition ( see , for instance , @xcite ) .",
    "unfortunately , it has recently been shown in @xcite that the explicit euler scheme fails to provide strong convergent solution to the sdes with super - linearly growing drift coefficient .",
    "it is well - known that the backward euler method can promise strong convergence in this situation , see e.g.,@xcite .",
    "but the backward euler method is an implicit method , which requires additional computational effort to solve an implicit system .",
    "recently in @xcite , the authors proposed an explicit method , called tamed euler method , for ( [ itsde ] ) @xmath20 here @xmath21 is a modification of @xmath22 .",
    "this tamed euler scheme is proved to converge strongly with the standard convergence order 0.5 to the exact solution of ( [ itsde ] ) if the drift coefficient function is globally one - sided lipschitz continuous and has an at most polynomially growing derivative .    on the one hand , the explicit milstein scheme is another numerical scheme for sdes that achieves a strong order of convergence higher than that of the explicit euler scheme .",
    "in fact the explicit milstein scheme has strong convergence order of one if the coefficient functions of stochastic taylor expansions satisfy both the global lipschitz condition and the linear growth condition(see @xcite ) . the explicit milstein method @xcite applied to reads @xmath23 where @xmath24 since the explicit milstein scheme and the explicit euler scheme coincide when applied to the sdes with additive noise",
    ", we can deduce from the results in @xcite that the explicit milstein scheme generally does not converge in the mean - square sense to the exact solution solution of the sdes with super - linearly growing drift coefficient .",
    "accordingly , we follow the idea from @xcite and replace @xmath25 in ( [ milstein ] ) with @xmath26 to derive a tamed milstein method @xmath27 which we expect to be strongly convergent with order one in the non - globally lipschitz case .    on the other hand , although milstein - type schemes may achieve a strong convergence order higher than that of euler type schemes , additional computational effort is required to approximate the iterated it integrals @xmath28 for every time step @xcite . this will enable the milstein - type schemes to lose their advantage over the euler - type schemes in computational efficiency . in this article",
    "we restrict our attention to sdes with commutative noise , in which case the milstein scheme can be easily implemented without simulating the iterated it integrals .",
    "in this situation , milstein - type method is much more computational efficient than euler - type method .",
    "more precisely , let the diffusion matrix @xmath29 fulfill the so - called commutativity condition : @xmath30 in many applications the considered sde systems possess commutative noise ( see @xcite ) .",
    "thanks to the property @xmath31 , in this case the tamed milstein method ( [ tamedmilstein ] ) takes a simple form as @xmath32 where @xmath33 for @xmath34 and @xmath35 for @xmath36 , @xmath21 is the modification of @xmath22 as defined in .",
    "the main result of this article shows that the tamed milstein scheme ( [ milsteinc ] ) converges strongly with the standard convergence order one to the exact solution of sdes with commutative noise if the drift coefficient @xmath22 is globally one - sided lipschitz continuous and has at most polynomially growing first and second derivatives .",
    "the diffusion coefficient @xmath29 and the coefficient function of stochastic taylor expansion @xmath37 are assumed to be globally lipschitz continuous .",
    "it is worthwhile to mention that a similar approach as used in @xcite is evoked to obtain uniform boundedness of @xmath38-th moments of numerical solutions produced by the tamed milstein method .",
    "we also introduce similar stochastic processes @xmath39 that dominate the tamed milstein approximation on appropriate subevents @xmath40 ( see section 2 for more details ) . with bounded @xmath38-th moments at hand , our main effort is to show for the time continuous tamed milstein methods there exists a family of real numbers @xmath41 for @xmath42 such that @xmath43}\\big\\|x_t -\\bar{y}_t\\big\\|^p\\big]\\big)^{1/p } \\leq c_{p , t}\\cdot h , \\quad h \\in ( 0 , 1].\\ ] ] the key difficulty is that relative to previous analysis @xcite a sharper estimate of the term @xmath44 ( see ) must be obtained to get the strong convergence order one . to overcome this difficulty , a certain kind of bootstrap argument is exploited ( see the estimate of @xmath44 for more details ) . to the best of our knowledge ,",
    "this is the very first paper to successfully recover the strong convergence order one for the milstein - type method under non - globally lipschitz condition .",
    "the rest of this paper is arranged as follows . in the next section ,",
    "uniform boundedness of @xmath38-th moments are obtained .",
    "and then the strong convergence order of the tamed milstein method is established in section 3 . finally , an illustrative example confirms the strong convergence order of one and the computational efficiency of this scheme compared to the tamed euler scheme .",
    "throughout this article , @xmath45 is the step number of the uniform mesh defined in the previous section .",
    "moreover , we use the notation @xmath46 , @xmath47 for all @xmath48 , and @xmath49 for all @xmath50 .",
    "furthermore , we make the following assumptions .",
    "[ lcmc ] let @xmath51 and @xmath52 be continuously differentiable and there exist positive constants @xmath53 and @xmath54 , such that @xmath55 @xmath56    note that the globally one - sided lipschitz condition ( [ olc1 ] ) on the drift @xmath22 and the globally lipschitz condition ( [ olc3 ] ) on the diffusion @xmath29 have been widely used in the literatures , e.g. , @xcite .    to prove uniform boundedness of @xmath38-th moments of the numerical solution , we follow the ideas in @xcite to introduce the appropriate subevents @xmath40 and dominating stochastic processes @xmath39",
    "@xmath57 @xmath58\\big ) , \\end{split}\\ ] ] where @xmath59 and @xmath60 the following lemmas are needed in order to prove uniform boundedness of @xmath38-th moments .",
    "[ domlem ] let @xmath61 and @xmath40 be given by ( [ milsteinc]),([dn ] ) and ( [ omega ] ) , respectively .",
    "then @xmath62    _ proof .",
    "_ first of all , note that @xmath63 on @xmath64 for all @xmath65 and @xmath66 .",
    "the globally lipschitz continuity of @xmath29 and @xmath67 , and the polynomial growth bound on @xmath68 imply that , on @xmath69 for all @xmath65 , @xmath70 moreover , the cauchy - schwarz inequality and the inequality @xmath71 for all @xmath72 give that @xmath73 on @xmath74 and @xmath75 .",
    "here we denote @xmath76 additionally , the global lipschitz continuity of @xmath77 implies that for @xmath78 @xmath79 and @xmath80 and the globally one - sided lipschitz continuity of @xmath22 gives that @xmath81 furthermore , the polynomial growth bound on @xmath68 implies that @xmath82 on @xmath83 . combining ( [ es1])-([es4 ] )",
    ", we get from ( [ es0 ] ) that @xmath84 on @xmath85 since @xmath86 implies @xmath63 , on @xmath87 , we derive from ( [ m_n ] ) and ( [ es2 ] ) that @xmath88\\|y_n\\|^2 , \\end{split}\\ ] ] where the fact that @xmath89 was used .",
    "inserting ( [ es6 ] ) into ( [ es5 ] ) shows that @xmath90 \\\\ & + \\frac{3m^3}{2}\\big(k+\\max_{1\\leq j_1,j_2\\leq m}\\|l^{j_1}\\sigma_{j_2}(0)\\|\\big)^2\\ , \\big(\\|\\delta w_n\\|^2 + h^2\\big)\\|y_n\\|^2 + 2\\langle y_n , \\sigma(y_n)\\delta w_n \\rangle + 2\\langle y_n , m_n\\rangle \\\\ \\leq&\\|y_n\\|^2\\left[1 + \\frac{2}{n}\\left(\\frac{3}{2}(2tk+t\\|\\mu(0)\\|)^2 + t(k+\\|\\mu(0)\\| ) + \\frac{3m^3t^2}{4}\\big(k+\\max_{1\\leq j_1,j_2\\leq m}\\|l^{j_1}\\sigma_{j_2}(0)\\|\\big)^2\\right ) \\right .",
    "\\\\ & + \\left.2\\left(\\frac{3}{2}(k+\\|\\sigma(0)\\|)^2 + \\frac{3m^3}{4}\\big(k+\\max_{1\\leq j_1,j_2\\leq m}\\|l^{j_1}\\sigma_{j_2}(0)\\|\\big)^2\\right)\\|\\delta w_n\\|^2 + 2 \\alpha_n\\right ] \\\\",
    "\\leq & \\|y_n\\|^2 \\exp\\big[\\frac{2\\lambda}{n } + 2\\lambda \\|\\delta w_n\\|^2 + 2\\alpha_n \\big ] \\end{split}\\ ] ] on @xmath91 . now combining ( [ yn1 ] ) and",
    "( [ yn2 ] ) , and using mathematical induction method as used in the proof of lemma 2.1 in @xcite finish the proof .",
    "@xmath92    [ lemma0 ] for all @xmath93 @xmath94 < \\infty.\\ ] ]    _ proof .",
    "_ this result is identical to lemma 2.3 in @xcite with only different @xmath95 . @xmath92",
    "[ lemma1 ] let @xmath96 be given by ( [ alpha ] ) .",
    "then for all @xmath93 @xmath97 < \\infty.\\ ] ]    _ proof .",
    "_ we set @xmath98 @xmath99 then we have @xmath100 .",
    "hence hlder s inequality shows that @xmath101 note that lemma 2.4 in @xcite has proved that @xmath102 consequently it remains to prove the boundedness of the second term on the right - hand side of ( [ alphab1 ] ) .",
    "one can easily verify that the discrete stochastic process @xmath103 is an @xmath104-martingale for every @xmath105 .",
    "since the exponential function is convex , the discrete stochastic process @xmath106 is a positive @xmath104-submartingale for every @xmath107 .",
    "therefore , the doob s maximal inequality gives that @xmath108 the cauchy - schwarz inequality , ( [ es2 ] ) and lemma [ lemma0 ] give that @xmath109 this together with ( [ dr1 ] ) completes the proof .",
    "@xmath92    [ lemma2 ]",
    "let @xmath39 be given by ( [ dn ] ) .",
    "then for all @xmath110 and @xmath93 @xmath111 < \\infty.\\ ] ]    _ proof .",
    "_ note that @xmath39 here takes the same form as @xmath112 in @xcite , with only different @xmath96 .",
    "with lemma [ lemma0 ] and lemma [ lemma1 ] at hand , one can follow the proof of lemma 2.5 in @xcite to derive the desired result . @xmath92    [ lemma3 ] let @xmath113 be given by ( [ omega ] ) with @xmath114 . then for all @xmath93 @xmath115\\right ) < \\infty.\\ ] ]    _ proof .",
    "_ the proof is identical to the proof of lemma 2.6 in @xcite . @xmath92 before establishing the main result of this section , we also need two burkholder - davis - gundy type inequalities .",
    "[ bdg - continuous ] let @xmath116 and let @xmath117 \\times \\omega \\rightarrow \\mathbb{r}^{k \\times m}$ ] be a predictable stochastic process satisfying @xmath118 .",
    "then for all @xmath119 $ ] and all @xmath120 @xmath121}\\big\\|\\int_0^s z_u d w_u\\big\\|\\big\\|_{l^p(\\omega;\\mathbb{r } ) } \\leq p \\big(\\int_0^t \\sum_{i=1}^m \\|z_s e_i\\|_{l^p(\\omega;\\mathbb{r}^k)}^2 ds\\big)^{\\frac{1}{2}}.\\ ] ] here the vectors @xmath122 , @xmath123 @xmath124 are orthogonal basis of vector space @xmath125 .",
    "_ combining doob s maximal inequality and lemma 7.7 of da prato , g. , and zabczyk @xcite gives the desired assertion . @xmath92",
    "the following is a discrete version of the burkholder - davis - gundy type inequality ( [ bdgc ] ) .",
    "[ bdg - discrete ] let @xmath116 and let @xmath126 be a family of mappings such that @xmath127 is @xmath128-measurable .",
    "then for all @xmath129 and @xmath120 @xmath130    [ lemma4 ] let @xmath131 be given by ( [ milsteinc ] ) . then for all @xmath132 @xmath133 < \\infty.\\ ] ]    _ proof .",
    "_ from ( [ milsteinc ] ) we have @xmath134 where the notation @xmath135 comes from ( [ m_n ] ) .",
    "using , the triangle inequality and the burkholder - davis - gundy type inequality in lemma [ bdg - discrete ] we have @xmath136\\delta w_k\\big\\|_{l^p(\\omega;\\mathbb{r}^d ) } + \\big\\|\\sum_{k=0}^{n-1 } \\sigma ( 0 ) \\delta w_k\\big\\|_{l^p(\\omega;\\mathbb{r}^d ) } \\\\ \\leq &   p\\big(\\sum_{k=0}^{n-1}\\sum_{i=1}^{m } \\left\\|\\sigma_i(y_k)-\\sigma_i(0)\\right\\|^2_{l^p(\\omega;\\mathbb{r}^d)}h\\big)^{1/2 } + p\\big(\\frac{nt}{n}\\sum_{i=1}^{m } \\left\\|\\sigma_i(0)\\right\\|^2\\big)^{1/2 } \\\\ \\leq &   p \\big(mk^2h \\sum_{k=0}^{n-1 } \\left\\|y_k\\right\\|^2_{l^p(\\omega;\\mathbb{r}^d)}\\big)^{1/2 } + p\\sqrt{tm } \\|\\sigma(0)\\| .",
    "\\end{split}\\ ] ] for the fourth term on the right - hand side of ( [ mb1 ] ) , the estimate in the second inequality of ( [ es2 ] ) and the independence of @xmath137 and @xmath138 imply that @xmath139 .",
    "\\end{split}\\ ] ] using burkholder - davis - gundy type inequality and mutual independence of @xmath138 gives @xmath140 where @xmath141 . inserting ( [ mb4 ] ) into ( [ mb3 ] )",
    "we obtain that @xmath142 combining ( [ mb1]),([mb2 ] ) and ( [ mb5 ] ) , and using @xmath143 give @xmath144 thus taking square of both sides shows that @xmath145 in the next step gronwall s lemma gives that @xmath146 where @xmath147 due to the @xmath148 on the right - hand side of ( [ le3 ] ) , ( [ le3 ] ) does not complete the prove . however , exploiting ( [ le3 ] ) in an appropriate bootstrap argument will enable us to establish ( [ d4 ] ) .",
    "first , hlder s inequality , lemma [ lemma3 ] and the estimate ( [ le3 ] ) show that @xmath149\\big)^{\\frac{1}{2p}}\\big(\\sup_{n\\in\\mathbb{n}}\\sup_{0\\leq n \\leq n } \\left(n^{-1}\\cdot\\|y_n\\|_{l^{2p}(\\omega;\\mathbb{r}^d)}\\right)\\big ) \\\\",
    "< & \\infty . \\end{split}\\ ] ] in addition , lemma [ domlem ] and lemma [ lemma2 ] imply that @xmath150 combining ( [ le4 ] ) and ( [ le5 ] ) finally completes the proof .",
    "in order to recover the strong convergence order one for the tamed milstein method , we additionally need the following assumptions . throughout this section @xmath151 is a generic constant that might vary from one place to another and depends on @xmath19 , the initial data @xmath7 , and the interval of integration @xmath152 $ ] , but is independent of the discretisation parameter .",
    "[ scc ] assume that @xmath51 and @xmath153 are two times continuous differentiable and there exist positive constants @xmath154 , such that @xmath155 @xmath156    here , for a two times continuous differentiable function @xmath157 we use the notation @xmath158 .",
    "the bilinear operator @xmath159 is defined by ( [ derivative ] ) . in the following convergence analysis",
    ", we prefer to write the tamed milstein method in the form of ( [ tamedmilstein ] ) , rather than .",
    "we now introduce appropriate time continuous interpolations of the time discrete numerical approximations .",
    "more accurately , we define the time continuous approximation @xmath160 such that for @xmath161 @xmath162 where we use the notation @xmath163 it is evident that @xmath164 , that is , @xmath165 coincides with the discrete solutions at the grid - points .",
    "we can rewrite @xmath165 as an integral form in the whole interval @xmath152 $ ] @xmath166d w_s^{i } , \\end{split}\\ ] ] where @xmath167 is the greatest integer number such that @xmath168 .",
    "combining ( [ itsde ] ) and ( [ milcon ] ) gives @xmath169ds+ \\sum_{i=1}^{m}\\int_{0}^{t}\\big[\\sigma_{i}(x_s)-\\sigma_{i}(y_{n_s})-\\sum_{j=1}^{m}l^{j}\\sigma_{i}(y_{n_s})\\delta",
    "w_{s}^{j}\\big]d w_s^{i}. \\end{split}\\ ] ]    in what follows , we also use deterministic taylor formula frequently .",
    "if a function @xmath170 is twice differentiable , the following taylor s formula holds @xcite @xmath171 where @xmath172 is the remainder term @xmath173 here for arbitrary @xmath174 the derivatives have the following expression @xmath175 replacing @xmath176 in with and rearranging lead to @xmath177 where @xmath178    by the definitions ( [ lj ] ) and ( [ derivative ] ) , it can be readily checked that @xmath179 therefore replacing @xmath180 in by @xmath181 and taking into account show that @xmath182    [ conthm ] let conditions in assumptions [ lcmc ] and [ scc ] and ( [ cc ] ) be fulfilled .",
    "then there exists a family of real numbers @xmath183 , @xmath184 such that @xmath185}\\|x_t -\\bar{y}_t\\|^p\\big]\\right)^{1/p } \\leq c_{p , t}\\cdot h , \\quad h \\in ( 0 , 1].\\ ] ]    the following five lemmas are used in the proof of theorem [ conthm ] .",
    "[ mblem0 ] let conditions in assumptions [ lcmc ] be fulfilled .",
    "then for all @xmath186 the following estimates hold @xmath187 < \\infty.\\ ] ]    _ proof .",
    "_ it immediately follows from theorem [ lemma4 ] by considering ( [ olc5 ] ) and ( [ es1])-([es4 ] ) .",
    "@xmath92    [ mblem ] let conditions in theorem [ conthm ] be fulfilled .",
    "then for all @xmath93 @xmath188 } \\big[\\|x_t \\|_{l^p(\\omega;\\mathbb{r}^d ) } \\bigvee \\|\\mu(x_t ) \\|_{l^p(\\omega;\\mathbb{r}^d ) } \\bigvee   \\|\\sigma(x_t ) \\|_{l^p(\\omega;\\mathbb{r}^{d\\times m } ) } \\bigvee   \\|\\bar{y}_t \\|_{l^p(\\omega;\\mathbb{r}^d)}\\big ] < \\infty.\\ ] ]    _ proof_. conditions ( [ olc1])-([olc3 ] ) ensure that the exact solution @xmath189 satisfies @xmath190}\\mathbb{e } \\|x_t \\|^{p } < \\infty$ ] ( see , e.g. , ( * ? ? ?",
    "* theorem 4.1 ) ) .",
    "polynomial growth condition on @xmath22 as ( [ es4 ] ) and linear growth condition on @xmath29 give the second and the third estimates . taking the definition ( [ milstein2 ] ) and lemma [ mblem0 ] into account , we can easily obtain the last estimate .",
    "@xmath92    [ yd ]",
    "let conditions in theorem [ conthm ] be fulfilled .",
    "then there exists a family of constants @xmath183 such that for @xmath93 @xmath191}\\|\\bar{y}_t - y_{n_t}\\|_{l^{p}(\\omega;\\mathbb{r}^d ) } \\bigvee   \\sup_{t\\in[0,t]}\\|\\mu(x_t ) - \\mu(x_{t_{n_t}})\\|_{l^{p}(\\omega;\\mathbb{r}^d ) } \\leq c_{p , t}\\ , h^{\\frac{1}{2}}.\\ ] ]    _ proof_. let @xmath192 be the greatest integer number such that @xmath193 . from ( [ milstein2 ] )",
    "we have @xmath194 following the same line as estimating ( [ mb1 ] ) , one can readily derive the first estimate .",
    "for the second estimate , we use and hlder s inequality to obtain @xmath195 where @xmath196 taking lemma [ mblem ] into account and using the same argument as in the previous section , one can obtain @xmath197 , and then complete the proof easily by considering and lemma [ mblem ] .",
    "@xmath92    [ rlem ] let @xmath93 and let conditions in theorem [ conthm ] be fulfilled . then for @xmath198 @xmath199",
    "_ proof_. to estimate @xmath200 , we need to estimate @xmath201 first . due to theorem [ lemma4 ] and lemma [ mblem ] we can find some suitable constant @xmath151 such that @xmath202 where the polynomial growth condition ( [ olc6 ] ) on @xmath203 , lemma [ yd ] , hlder s inequality and jensen",
    "s inequality were also used .",
    "now we return to @xmath200 .",
    "replacing @xmath180 in with @xmath22 gives @xmath204 following the same line as estimating ( [ mb4 ] ) and noticing that @xmath205 , one can similarly arrive at @xmath206 further , using hlder s inequality we derive from lemma [ mblem0 ] that for @xmath207 @xmath208 now , using the independence of @xmath209 and @xmath210 , and combining ( [ r1mu ] ) , ( [ r1p ] ) , and ( [ con8 ] ) , one can show @xmath211 in a similar way as estimating @xmath212 , one can derive that @xmath213 our proof of theorem [ conthm ] also needs the following burkholder - davis - gundy type inequality for discrete - time martingale ( see theorem 3.28 in @xcite and lemma 5.1 in @xcite ) .",
    "[ bdg ] let @xmath214 be @xmath215-measurable mappings with @xmath216 for all @xmath217 and with @xmath218 = 0 $ ] for all @xmath217 .",
    "then @xmath219 for every @xmath220 , where @xmath221 are constants dependent of @xmath38 , but independent of @xmath222 .",
    "_ proof of theorem [ conthm ] .",
    "_ applying it s formula to gives @xmath223 for the integrand of the first term in , we use and the cauchy - schwarz inequality to arrive at @xmath224 for the integrand of the third term in , one can use an elementary inequality , the notation and to get @xmath225 inserting and into and using the notation show @xmath226 hence @xmath227 and thus for @xmath228 @xmath229 for the last term on the right - hand side of , we use , , the cauchy - schwarz inequality and elementary inequalities to derive @xmath230    at the same time , replacing @xmath180 in by @xmath22 and using the cauchy - schwarz inequality and elementary inequalities give @xmath231 where we denote @xmath232 inserting and to yields @xmath233 therefore it remains to estimate @xmath44 as . using , and shows @xmath234 dw^i_r \\\\ = & \\int_{t_{n_u}}^u \\big[\\mu(x_r)-\\mu(x_{t_{n_u}})\\big ] dr + \\sum_{i=1}^m \\int_{t_{n_u}}^u \\big [ \\sigma_{i}(x_r)- \\sigma_{i}(\\bar{y}_r ) \\big ] dw^i_r + \\sum_{i=1}^m \\int_{t_{n_u}}^u \\tilde{r}_1(\\sigma_i )   dw^i_r \\\\ & + ( u - t_{n_u } ) \\,\\mu(x_{t_{n_u } } ) - ( u - t_{n_u } ) \\,\\tilde{\\mu}(y_{n_u } ) + x_{t_{n_u } } - y_{n_u}. \\end{split}\\ ] ] thus @xmath235 dr ,   \\mu'(y_{n_u})\\sigma(y_{n_u})\\delta w_u \\big\\rangle du \\big\\|_{l^{\\frac{p}{2}}(\\omega ; \\mathbb{r } ) } \\nonumber \\\\ & + 2 \\big\\|\\sup_{0\\leq s \\leq t } \\int_0^s \\big\\langle \\sum_{i=1}^m \\int_{t_{n_u}}^u \\big [ \\sigma_{i}(x_r)- \\sigma_{i}(\\bar{y}_r)\\big ]   dw^i_r ,   \\mu'(y_{n_u})\\sigma(y_{n_u})\\delta w_u \\big\\rangle du \\big\\|_{l^{\\frac{p}{2}}(\\omega ; \\mathbb{r } ) } \\nonumber \\\\ & + 2 \\big\\|\\sup_{0\\leq s \\leq t } \\int_0^s \\big\\langle \\sum_{i=1}^m \\int_{t_{n_u}}^u \\tilde{r}_1(\\sigma_i )   dw^i_r ,   \\mu'(y_{n_u})\\sigma(y_{n_u})\\delta w_u \\big\\rangle du \\big\\|_{l^{\\frac{p}{2}}(\\omega ; \\mathbb{r } ) } \\nonumber \\\\ & + 2 \\big\\|\\sup_{0\\leq s \\leq t } \\int_0^s \\big\\langle \\zeta_{n_u } ,   \\mu'(y_{n_u})\\sigma(y_{n_u})\\delta w_u \\big\\rangle du \\big\\|_{l^{\\frac{p}{2}}(\\omega ; \\mathbb{r } ) } \\nonumber \\\\ & + 2 \\big\\|\\sup_{0\\leq s \\leq t } \\int_0^s \\big\\langle x_{t_{n_u } } - y_{n_u } ,   \\mu'(y_{n_u})\\sigma(y_{n_u})\\delta w_u \\big\\rangle du \\big\\|_{l^{\\frac{p}{2}}(\\omega ; \\mathbb{r } ) } , \\nonumber \\\\ : = & j_{1 } + j_{2 } + j_{3 } + j_{4 } + j_{5 } , \\label{eq : bj}\\end{aligned}\\ ] ] where @xmath236 is defined by @xmath237    to begin with , we establish the estimate @xmath238 which is frequently used later . using hlder s inequality , lemma [ mblem0 ] and lemma [ bdg - continuous ] , we know that for @xmath239 @xmath240 and @xmath241 combining and one can readily obtain by hlder s inequality .",
    "concerning @xmath242 , we use hlder s inequality , and to arrive at @xmath243 for @xmath244 , using hlder s inequality , , , elementary inequalities and gives @xmath245   dw^i_r \\big\\|_{l^{p}(\\omega ; \\mathbb{r}^d ) } \\cdot \\big\\| \\mu'(y_{n_u})\\sigma(y_{n_u})\\delta w_u \\big\\|_{l^{p}(\\omega ; \\mathbb{r}^d ) } du \\nonumber \\\\ & \\leq & \\int_0^t \\frac{1}{h}\\,\\big\\|\\sum_{i=1}^m \\int_{t_{n_u}}^u \\big [ \\sigma_{i}(x_r)- \\sigma_{i}(\\bar{y}_r ) \\big ] dw^i_r \\big\\|^2_{l^{p}(\\omega ; \\mathbb{r}^d ) } du + \\int_0^t h\\ , \\big\\| \\mu'(y_{n_u})\\sigma(y_{n_u})\\delta w_u \\big\\|^2_{l^{p}(\\omega ; \\mathbb{r}^d ) } du \\nonumber \\\\ & \\leq & \\frac{p^2}{h}\\ , \\int_0^t \\int_{t_{n_u}}^u \\sum_{i=1}^m   \\big\\| \\sigma_{i}(x_r)- \\sigma_{i}(\\bar{y}_r ) \\big\\|^2_{l^{p}(\\omega ; \\mathbb{r}^d)}dr du + c_{p , t } h^2",
    "\\nonumber \\\\ & \\leq & mp^2 k^2\\ , \\int_0^t \\sup_{0\\leq r\\leq u }   \\big\\| x_r - \\bar{y}_r \\big\\|^2_{l^{p}(\\omega ; \\mathbb{r}^d ) } du + c_{p , t } h^2 .",
    "\\label{eq : j2}\\end{aligned}\\ ] ] for @xmath246 , similarly as above we obtain that @xmath247 where and were also used .",
    "now , it remains to estimate @xmath248 and @xmath249 .",
    "we split @xmath248 into two terms as follows : @xmath250    recall that @xmath251 for @xmath252 .",
    "it can be readily verified that the discrete time process @xmath253 is an @xmath104-martingale . with the aid of doob s maximal inequality , lemma [ bdg ] and hlder s inequality",
    "we obtain that for @xmath228 @xmath254 where by , lemma [ mblem0 ] and lemma [ mblem ] @xmath255    hence , taking and into account , we derive from ( [ supcon4 ] ) that @xmath256 for the second term @xmath257 , hlder s inequality , and give that for @xmath228 @xmath258 which implies that for @xmath228 and @xmath259 $ ] there exists a suitable constant @xmath151 such that @xmath260 gathering ( [ supcon005 ] ) and ( [ supcon7 ] ) we derive from that for @xmath228 @xmath261 similarly , we split @xmath262 as follows : @xmath263 with regard to @xmath264 , following the same line as yields @xmath265 where the fact @xmath266 , elementary inequalities and were used . for @xmath267 ,",
    "we follow the same way as to obtain @xmath268 thus @xmath269 note that @xmath270 for @xmath228 and that @xmath271 . plugging and into yields @xmath272 inserting , , , and",
    "into leads to @xmath273 hence , using estimates in lemma [ mblem0 ] and lemma [ rlem ] we derive from that @xmath274 thus @xmath275 is finite by lemma [ mblem ] and @xmath276 the gronwall inequality gives the desired result for @xmath228 .",
    "using hlder s inequality gives the assertion for @xmath277 and the proof is complete .",
    "in @xcite , the authors have demonstrated the computational efficiency of the tamed euler scheme , compared to the implicit euler method . in this section",
    "we compare computational efficiency of the tamed milstein scheme and the tamed euler scheme . to this end",
    "we choose a simple sde ( [ sdes ] ) @xmath278 for @xmath279 $ ] .",
    "figure [ fig1 ] depicts the root mean - square errors ( [ err ] ) as a function of the stepsize @xmath280 in log - log plot , where the expectation is approximated by the mean of 5000 independent realizations .",
    "as expected , the tamed milstein scheme gives an error that decreases proportional to @xmath280 , whereas the tamed euler scheme gives errors that decrease proportional to @xmath281 . to show the efficiency of the tamed milstein method clearly",
    ", we present in figure [ fig2 ] the root mean - square errors of both methods as function of the runtime when @xmath282 and the mean of 1000 independent paths are used to approximate the expectation in ( [ err ] ) .",
    "suppose that the strong approximation problem ( [ err ] ) of the sde ( [ test ] ) should be solved with the precision @xmath283 . from figure [ fig2 ] , one can detect that @xmath284 in the case of the tamed milstein method ( [ milsteinc ] ) and that @xmath285 in the case of the tamed euler method ( [ tamedeuler ] ) achieves the desired precision @xmath283 in ( [ err ] ) .",
    "moreover , the tamed milstein scheme requires 8.1860 seconds while the tamed euler scheme requires 147.9230 seconds to achieve the precision @xmath283 in ( [ err ] ) .",
    "the tamed milstein method is for the sde ( [ test ] ) with commutative noise thus much faster than the tamed euler method .",
    "y. hu , semi - implicit euler - maruyama scheme for stiff stochastic equations , in stochastic analysis and related topics v : the silvri workshop , progr .",
    "38 ( 1996 ) , h. koerezlioglu , ed . , birkhauser , boston , pp .",
    "183 - 202 .",
    "m. hutzenthaler , a. jentzen , and p.e .",
    "kloeden , strong and weak divergence in finite time of euler s method for sdes with non - globally lipschitz continuous coefficients , proc .",
    "a 467 ( 2011 ) , pp .",
    "1563 - 1576 ."
  ],
  "abstract_text": [
    "<S> for stochastic differential equations ( sdes ) with a superlinearly growing and globally one - sided lipschitz continuous drift coefficient , the classical explicit euler scheme fails to converge strongly to the exact solution . </S>",
    "<S> recently , an explicit strongly convergent numerical scheme , called the tamed euler method , is proposed in [ hutzenthaler , jentzen , @xmath0 kloeden ( 2010 ) ; strong convergence of an explicit numerical method for sdes with non - globally lipschitz continuous coefficients , arxiv:1010.3756v1 ] for such sdes . motivated by their work , we here introduce a tamed version of the milstein scheme for sdes with commutative noise . the proposed method is also explicit and easily implementable , but achieves higher strong convergence order than the tamed euler method does . in recovering the strong convergence order one of the new method , </S>",
    "<S> new difficulties arise and kind of a bootstrap argument is developed to overcome them . </S>",
    "<S> finally , an illustrative example confirms the computational efficiency of the tamed milstein method compared to the tamed euler method .   </S>",
    "<S> + * ams subject classification : * 65c20 , 60h35 , 65l20 . + </S>",
    "<S> * key words : * tamed milstein method , superlinearly growing coefficient , one - sided lipschitz condition , commutative noise , strong convergence </S>"
  ]
}