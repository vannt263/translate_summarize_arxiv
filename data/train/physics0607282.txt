{
  "article_text": [
    "in recent years , physicists have enlarged the research area to many interdisciplinary fields .",
    "econophysics is one of the active research areas where many statistical methods are applied to investigate financial systems .",
    "many analytic methods are introduced , such as the correlation function , multifractality , minimal spanning tree , and spin models @xcite .",
    "the empirical time series in financial markets have also been investigated by using various methods such as rescaled range ( r / s ) analysis to test the presence of correlations @xcite and detrended fluctuation analysis to detect long - range correlations embedded in seemingly non - stationary time series @xcite .    in this paper",
    "we focus on how to find a specific time scale in which a pattern in a time series is revealed most .",
    "since pattern can be interpreted as the repetitive structure inside the time series we will be referring to that specific scale as _",
    "structure scale_. to find this structure scale we introduce the minimum entropy density method , which will be elaborated in detail and exemplified with the cases of finite periodic time series with corruption in section [ sect : model ] .",
    "it is because the periodic time series is simple and has a repetitive structure among it definitely .",
    "however , our method can be applied to the other time series as well as the other processes , such as configurations of spin chain , if they have any certain structures . as an example of empirical analysis",
    "we apply this method to the time series of s&p500 index in section [ sect : anal ] .",
    "the temporal behavior of the structure scale of the index is obtained and the implications of the result is analyzed in relation to the information delivery time and efficient market hypothesis .",
    "since our new method for finding the structure scale of a finite time series is based on the information theory , we start with briefly explaining the concepts in the information theory according to ref . @xcite .",
    "firstly , we consider a process given by an infinitely consecutive discrete random variables , @xmath0 , where each @xmath1 may take the value @xmath2 drawn from a finite countable set @xmath3 of size @xmath4 .",
    "the probability distribution of a block of @xmath5 consecutive random variables @xmath6 is taken as the set of joint probabilities of @xmath5 consecutive values @xmath7 for all @xmath8 possibilities .",
    "then the shannon entropy for the above @xmath5-block variable @xmath9 is defined as @xmath10 which measures the uncertainty or randomness in the process .",
    "@xmath11 is a monotonically increasing function of @xmath5 because the more relevant information can be extracted from the time series for the larger @xmath5 .",
    "we can measure the entropy of the infinite process @xmath12 by taking @xmath13 .",
    "however , @xmath11 may diverge as @xmath5 goes to infinity , so an entropy density is introduced as follows : @xmath14 equivalently @xmath15    if the process @xmath12 contains a periodic structure , for a sufficiently large @xmath5 ( larger than the period ) increasing @xmath5 does not give us any more information . in this case the entropy density becomes @xmath16 . on the other hand , if the process has been generated totally randomly , @xmath17 for all @xmath8 possibilities , then @xmath18 and consequently @xmath19 , which is the maximum value of the entropy density .",
    "therefore the repetitive structure embedded in the process makes the entropy density lower than that of a more random process .",
    "in addition the entropy density can be interpreted as the uncertainty of a given variable when all the preceding variables are known . if there exists a repetitive structure in the process , the knowledge of all the previous information will greatly decrease the uncertainty of the next variable .    since the finite size of the empirical data sets directly a limit to the block size @xmath5 , we need the finite-@xmath5 approximation to the thermodynamic entropy density @xmath20 as follows : @xmath21 where @xmath22 is set to @xmath16",
    ". actually all the processes we deal with through this paper are finite , hence only @xmath23 matters other than @xmath20 . by the way ,",
    "unless @xmath5 is large enough to fully detect the structure in the process , @xmath23 would overestimate the randomness of the process .",
    "therefore , as @xmath5 increases @xmath23 converges to @xmath20 .      for the entropy density analysis we coarse - grain the data with an appropriate scale and then digitize the continuous amplitudes into discrete values .",
    "let us consider a temporal data set @xmath24 as a function of discrete time steps @xmath25 .",
    "once the scale @xmath26 to grain the data is given , then the resulting time series has @xmath27 equally spaced measurements . for the digitization we set a countable set @xmath3 to the smallest and simplest set of size @xmath28 , such as @xmath29 , among the various alternatives .",
    "in other words the original data set @xmath24 changes into the binary time series @xmath30 by the following process : @xmath31 where @xmath32 is a heaviside step function . @xmath30 gets the value of @xmath16 if the value of measurement has decreased after the interval @xmath26 and does the value of @xmath33 otherwise . to make clear the effect of choosing @xmath26 on the coarse - grained data set , consequently on the entropy density we define @xmath34 as the entropy density of the process coarse - grained with scale @xmath26 , which plays a key role in our method .    the minimum entropy density method ( medm )",
    "is based on the assumption that the pattern in the time series is revealed most when the time series is coarse - grained with the structure scale defined as the scale minimizing the entropy density .",
    "most empirical time series for the complex systems are usually contaminated by the high frequency noise and we want to get the noiseless signal or intrinsic structure from the scratches . provided that a time series can be described by a characteristic time scale @xmath35 , if the smaller scale than @xmath35 is used for the analysis the time series looks more random due to the high frequency noise . on the other hand",
    "if the larger scale than @xmath35 is used we overlook the time series so that we fail to get the structure , hence the time series looks more random too . in short , by finding the scale minimizing the entropy density we can get the characteristic scale @xmath35 .    for the first step of medm",
    "we decide the range of coarse - graining scale , usually set to @xmath36 $ ] .",
    "then , before finding the structure scale @xmath37 minimizing @xmath34 by tuning @xmath26 we should determine the appropriate value of @xmath5 .",
    "the first of two criteria for choosing @xmath5 sets the upper bound of @xmath5 : @xmath38 where @xmath39 is the number of data points @xmath40 and @xmath4 is the size of the set @xmath3 . as @xmath5 increases , the more relevant information can be extracted from the process while the average number of realizations for each possibility of @xmath5-block variable decreases fast as @xmath41 for finite @xmath39 .",
    "therefore , for the significant analysis @xmath5 should be limited by a condition that the average number of realizations for each possibility of @xmath5-block variable should be at least one : @xmath42 , equivalent to eq .",
    "( [ eq : logkn ] ) . for the mathematically rigorous arguments",
    "@xcite .",
    "the second criterion is to determine the convergence range of @xmath5 in which @xmath34 for some @xmath26 converges to @xmath20 .",
    "however , without the knowledge of @xmath20 it is not clear to see whether @xmath34 converges to @xmath20 or not .",
    "if the value of @xmath37 does not depend on @xmath5 we can determine the structure scale @xmath37 even though @xmath34 does not converge yet .",
    "on the other hand , if the value of @xmath37 varies according to @xmath5 in general we have to find the convergence range of @xmath5 , which can be practically defined as the range where the landscape of @xmath34 is approximately flat .",
    "once such a convergence range exists for any @xmath26 , it would be enough to determine @xmath37 for that range of @xmath5 because the aim of this paper is to compare the entropy densities for different scales for a fixed value of @xmath5 , not to get the better approximation of entropy densities .",
    "the medm that we have discussed so far can be summarized into four main steps including how to choose an appropriate value of @xmath5 :    1 .",
    "decide the range of coarse - graining scale , usually set to @xmath36 $ ] .",
    "2 .   for each @xmath26 in that range , transform the given time series @xmath24 into @xmath4-ary time series , for example , by eq .",
    "( [ eq : fn ] ) .",
    "3 .   choose the appropriate value of @xmath43 : 1 .",
    "@xmath5 should be lower than @xmath44 , where @xmath45 .",
    "@xmath5 should be chosen inside the convergence range where the landscape of @xmath34 is flat for the whole range of @xmath26 .",
    "4 .   find the structure scale @xmath37 minimizing the entropy density @xmath46 by tuning @xmath26 .",
    "for the last step of medm there may be more than one minimum in the landscape of @xmath46 , which will be discussed with the examples in the next subsection .",
    "the medm is applied to the finite periodic time series with corruption because the periodic time series is simple and has a repetitive structure among it definitely .",
    "we consider the following series : for each time step @xmath47 , @xmath48 where @xmath49 is the period of @xmath24 , @xmath50 is a random number uniformly drawn from @xmath51 $ ] , and @xmath52 represents the fraction of corrupted data points .",
    "we set the data size @xmath53 to @xmath54 , @xmath49 to @xmath55 , @xmath4 to @xmath56 , and @xmath57 to @xmath58 , _",
    "i.e. _ the @xmath58 different sets of binary time series are constructed by eq .",
    "( [ eq : fn ] ) .",
    "then for a few cases of @xmath52 the entropy densities for the whole range of @xmath26 and for @xmath59 are calculated , as partly shown in fig .",
    "[ fig1 ] .    when there is no corrupted data , _",
    "i.e. _ @xmath60 , for @xmath61 the global minima of @xmath34 turn out to be @xmath16 for the multiples of @xmath62 .",
    "as @xmath5 increases there appears the additional global minima for the other values of @xmath26 .",
    "finally the entropy densities @xmath34 for the multiples of @xmath63 become the global minima when @xmath64 and even when @xmath65 .",
    "this implies that @xmath66 is the convergence range of @xmath5 as shown in fig .",
    "one can criticize that for the case of @xmath67 , where the binary time series becomes @xmath68 , the pattern @xmath69 can be completely revealed by taking @xmath5 larger than @xmath55 .",
    "but it is contradictory to the first criterion in eq .",
    "( [ eq : logkn ] ) when given the finite time series . instead of taking @xmath5 as large as",
    "possible , we can get more relevant results by tuning the scale @xmath26 even for the small values of @xmath5 guaranteeing the significance of analysis .    if the corruption is taken into account , _",
    "i.e. _ in cases of @xmath70 and @xmath71 , the local minima for the odd multiples of @xmath72 become distinctive among other minima ( fig . [ fig1 ] ( b ) and ( c ) ) .",
    "moreover , the values of distinctive local minima in the landscape of @xmath34 turn out to be independent of @xmath5 so that the structure scales @xmath37 are successfully determined and hence it is not necessary to specify the convergence range of @xmath5 as well as @xmath43 .",
    "then why do the entropy densities for the odd multiples of @xmath72 remain minimized ?",
    "the corruption definitely destroys the periodicity of time series and increases the randomness , therefore the overall values of local minima of @xmath34 get larger than those for the case of @xmath60 .",
    "however , the effect of corruption is not uniform . at first , without corruption @xmath73 in eq .",
    "( [ eq : fn ] ) for the odd multiples of @xmath72 take the extreme values of @xmath24 , precisely @xmath74 for @xmath75 even and @xmath76 for @xmath75 odd .",
    "therefore the flip probability , defined as the probability that the sign of argument @xmath77 in eq .",
    "( [ eq : fn ] ) is flipped due to the corruption , is the least among for the other values of @xmath26 .",
    "for example , if @xmath78 remains unchanged as either @xmath16 or @xmath33 while @xmath79 is replaced by a random number in @xmath51 $ ] , the flip probability is @xmath16 . on the other hand , for the case of @xmath80 ,",
    "if @xmath81 remains unchanged as @xmath33 while @xmath82 is replaced by a random number in @xmath51 $ ] , the flip probability is @xmath33 . as a result",
    "one can expect that when the periodic function is corrupted by noise , the most robust scale is not the period @xmath49 and its multiples but @xmath83 and its odd multiples .",
    "based on this argument one can say that the existence of more than one distinctive local minimum naturally comes from the repetitive structure of the original function @xmath24 , and that the patterns can appear in the different scales simultaneously .    for more general application to a continuous time series we can take the finer scales to increase the precision of measuring the structure scale .",
    "to show an efficient way to fine - tune @xmath26 we consider a corrupted periodic function with non - integer period , for example , for a continuous time @xmath47 , @xmath84 to measure the structure scales ( the odd multiples of @xmath72 for the case of discrete periodic functions ) , @xmath26 should be smaller than @xmath85 . instead of scanning the whole range of @xmath26 , such as from @xmath85 to @xmath86 , by the increment of @xmath85 we tune @xmath26 in a larger scale first and then move down to the smaller scales .",
    "the value of @xmath5 is set to @xmath87 according to the medm .",
    "figure [ fig3](a ) shows the entropy densities for various @xmath26 in the order of @xmath88 .",
    "the minimum of the entropy density occurs at @xmath89 .",
    "we narrow the variation of @xmath26 down to @xmath33 around @xmath90 .",
    "then the minimum of the entropy density occurs at @xmath91 in fig . [",
    "fig3](b ) and we repeat the same process again .",
    "finally , in fig .",
    "[ fig3](c ) we obtain @xmath92 minimizing the entropy density , which is exactly a half period ( @xmath83 ) .",
    "finally , the medm can be applied to a periodic function with varying period by dividing the given time series into several regions and applying medm to each of them . here",
    "we consider a periodic function with linearly decreasing period : for a continuous time @xmath47 , @xmath93 where the period continuously decreases from @xmath94 to @xmath95 .",
    "we set @xmath94 to @xmath55 , @xmath95 to @xmath90 , and @xmath53 to @xmath54 , respectively .",
    "the total time series is divided into @xmath88 regions and the medm is applied to each of them .",
    "for all the regions we tune @xmath26 in an order of @xmath33 and set @xmath5 to @xmath87 after testing in a way we described before .",
    "figure [ fig4 ] shows that the smallest structure scale @xmath37 decreases from @xmath96 in the first region to @xmath97 in the last one .",
    "these @xmath37s are exactly the half periods of the starting and ending parts of the original function .",
    "if we divide the time series into more regions and use the finer scales , then the resultant temporal behavior of structure scale gets closer to @xmath98 , where @xmath99 is defined in eq .",
    "( [ eq : ytcorrpt ] ) , than before .",
    "now we apply the medm to analyze the financial time series of the s&p500 index from year 1983 to 2006 .",
    "we used the tick - by - tick data .",
    "it is reasonable to think that the structure scale of s&p500 index for @xmath100 years would change from time to time .",
    "hence the formalism of the last example in the previous section is used .",
    "it should be noted that although the time series of the s&p500 index is not periodic , we can always measure the structure scale using medm whenever the series has patterns .",
    "the total time span of the index data from february 1983 to april 2006 is divided into @xmath101 regions , _",
    "i.e. _ each region for each month . for each region",
    "the structure scale is obtained then the temporal behavior of it will be analyzed .",
    "the unit of coarse - graining scale @xmath26 is set to @xmath33 tick , the finest resolution of the empirical s&p500 index data . on average",
    "there are @xmath102 ticks in one minute though the real time intervals between adjacent ticks are not equally distributed .",
    "one reasonable way to fix this problem is to obtain the structure scale @xmath103 in a unit of tick for each month and multiply it by the average real time interval @xmath104 between ticks within that month .",
    "the resulting value @xmath105 will be the structure scale in a unit of time for each month .",
    "then we follow the four main steps of the medm to measure the structure scale of tick every month . for the first step the range of @xmath106",
    "is set to @xmath33 tick to @xmath107 ticks .",
    "the tick series with @xmath108 has less than @xmath109 data points each month . by eq .",
    "( [ eq : logkn ] ) the upper bound of @xmath5 is @xmath110 .",
    "considering the second criterion of choosing @xmath5 , we set @xmath43 to @xmath111 by finding the convergence region of @xmath5 for the whole range of @xmath106 .",
    "figure [ fig5 ] shows the landscapes of entropy densities @xmath112 only for the regions of february 1983 and april 2006 . for the third step the structure scale @xmath103 minimizing @xmath113",
    "is determined for each month .",
    "three examples are shown in fig .",
    "[ fig6 ] , where @xmath113 is minimized at @xmath114 for january 1987 , at @xmath115 for january 1996 , and at @xmath116 for january 2001 , respectively . unlike the case with the periodic time series , for each region there is only one structure scale over the range of @xmath26 . after finding all",
    "the @xmath103 we convert them into the real time scales by multiplying the average time interval between ticks for each month .",
    "finally we get the temporal behavior of the structure length @xmath37 as shown in fig .",
    "[ fig7 ] . during 1980",
    "s and 1990 s @xmath37 decreases slowly but declines fast after late 1990 s .",
    "we analyze the meaning of this result by considering the time scale by which the information flows among interacting agents in the stock market .",
    "the stock market price changes only when the agents in the stock market buy or sell .",
    "since the agents make decisions based on the information they get , the information delivery time can be one of the most important factors for the changing rate of price .",
    "the information delivery time ( idt ) , defined as the time taken for the delivery of information from sources to agents , is assumed to be proportional to the average price change cycle .",
    "if the entropy density of the time series is measured with scale @xmath26 smaller than the idt , it would be relatively high because the coarse - grained time series looks more random due to the high frequency noise .",
    "on the other hand , if @xmath26 is larger than idt , we overlook the pattern embedded in the time series so fail to detect the structure scale and the coarse - grained time series looks more random too .",
    "therefore , if the optimally closest scale to the idt is used to detect the patterns in the time series , the entropy density for that scale would be minimized due to the repetitive structure of the price change . consequently , @xmath117    the long - term decrease of @xmath37 from year 1986 to 2006 in fig .",
    "[ fig7 ] can be interpreted as the decrease of the information delivery time .",
    "the value of @xmath37 suddenly jumps down around year 1997 , when the internet was starting to spread widely , the fraction of online traders increased exponentially .",
    "these influenced the idt of the stock market to become much shorter .",
    "since there does not exist any standardized way to measure the information delivery time , we suggest @xmath37 as one of candidates to measure it .",
    "idt can be also used to measure the efficiency of the stock market : if the market is idealized with efficient market hypothesis ( emh ) @xcite , then idt will become @xmath16 .",
    "in addition from our quantitative analysis idt of the s&p500 index is about @xmath118 seconds in year 2006 .",
    "in this paper we have developed the minimum entropy density method ( medm ) to detect the structure scale of a given time series .",
    "this method is based on the assumption that the pattern in the time series is revealed most when the time series is coarse - grained with the structure scale defined as the scale minimizing the entropy density .",
    "we also showed that the medm is useful to detect the repetitive structures in the various time series if they have certain patterns .    additionally , by applying the medm to the financial time series of s&p500 index we identified that the time scale with the most patterns showing , has decreased for the last twenty years . in other words",
    "the information flows faster than before .",
    "the medm has also been applied to korea composite stock price index ( kospi ) from april 1992 to june 2003 with @xmath33 minute time interval @xcite .",
    "the structure scale of the kospi index , which can be interpreted as the idt , had also decreased for ten years similar to s&p500 index .",
    "we believe this effect is real , considering that the internet trading has become popular recently , which we think is one of the main factors of decreasing the idt , in both u.s . and",
    "korean stock market .",
    "also , yang and colleagues @xcite used the microscopic spin model to investigate the financial market and identified that the change of log - return distributions of financial stock markets can result from the increasing velocity of information flow , which implies that the idt becomes shorter than before .",
    "since idt measures the efficiency of the stock market , by quantitative analysis we conclude that the efficiency of the u.s .",
    "stock market dynamics became close to emh .                            c. r. shalizi and k. l. shalizi , preprint : cs.lg/0406011 ; in _ proceedings of the 20th annual conference on uncertainty in artificial intelligence ( uai-04 ) _ , edited by m. chickering and j. halpern ( auai press , virginia , 2004 ) , pp .",
    "504 - 511 .           of the periodic time series as functions of scale @xmath26 with block size @xmath119 ( black circles ) , @xmath102 ( red crosses ) , and @xmath87 ( blue plus signs ) , respectively .",
    "the fraction of corrupted data points @xmath52 is @xmath16 ( a ) , @xmath85 ( b ) , and @xmath71 ( c ) , respectively . for ( b ) and ( c )",
    "each point is averaged over @xmath55 realizations and for a clear view we plotted @xmath26 to @xmath120 not to @xmath121 . ]",
    "of the time series coarse - grained with scales @xmath122 ( plus signs ) , @xmath123 ( crosses ) , @xmath124 ( circles ) , and @xmath58 ( squares ) when the fraction of corrupted data points is @xmath85 . each point",
    "is averaged over @xmath55 realizations .",
    "there exists a convergence range of @xmath5 in @xmath125 $ ] . ]"
  ],
  "abstract_text": [
    "<S> the entropy density is an intuitive and powerful concept to study the complicated nonlinear processes derived from physical systems . </S>",
    "<S> we develop the minimum entropy density method ( medm ) to detect the structure scale of a given time series , which is defined as the scale in which the uncertainty is minimized , hence the pattern is revealed most . </S>",
    "<S> the medm is applied to the financial time series of standard and poor s 500 index from february 1983 to april 2006 . </S>",
    "<S> then the temporal behavior of structure scale is obtained and analyzed in relation to the information delivery time and efficient market hypothesis . </S>"
  ]
}