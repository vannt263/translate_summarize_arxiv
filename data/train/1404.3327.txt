{
  "article_text": [
    "we are interested in providing _ computable absolute bounds in @xmath10 norm _ on the convergence of a mildly asynchronous version of successive overrelaxation ( sor ) applied to problems of the form @xmath11 , where @xmath0 is a nonnegative real matrix and @xmath12 . a matrix of the form @xmath13 under these hypotheses",
    "is called a _ nonsingular m - matrix _  @xcite .",
    "we stress from the start that there are no other hypotheses on @xmath0 such as irreducibility , symmetry , positive definiteness or ( weak ) 2-cyclicity , and that @xmath0 is assumed to be very large ",
    "so large that computing @xmath8 ( or performing a sor iteration ) is feasible ( maybe streaming over the matrix entries ) , but estimating @xmath14 is not .",
    "our main motivation is the parallel computation with arbitrary guaranteed precision of various kinds of _ spectral rankings with damping _",
    "@xcite , most notably katz s index  @xcite and pagerank  @xcite , which are solutions of problems of the form above with @xmath0 derived from the adjacency matrix of a very large graph , the only relevant difference being that the rows of @xmath0 are @xmath15-normalized in the case of pagerank .    by `` computable '' we mean that there must be a finite computational process that provides a bound on @xmath16 , where @xmath17 is the solution and @xmath18 is the @xmath19-th approximation .",
    "such a bound would make it possible to claim that we know the solution up to some given number of significant fractional digits .",
    "for example , without further assumptions on @xmath0 convergence results based on the spectral radius are not computable in this sense and results concerning the residual are not applicable because of the unfeasibility of estimating @xmath14 .",
    "we are also interested in highly parallel versions for modern multicore systems .",
    "while sor and other iterative methods are apparently strictly sequential algorithms , there is a large body of literature that studies what happens when updates are executed in arbitrary order , mixing old and new values .",
    "essentially , as long as old values come from a finite time horizon ( e.g. , there is a finite bound on the `` oldness '' of a value ) convergence has been proved for all major standard sequential hypothesis of convergence ( for the main results , see the sections about _ partial asynchrony _ in bertsekas and tsitsiklis s encyclopedic book  @xcite ) .",
    "again , however , results are always stated in terms of convergence in the limit , and the speed of convergence , which decays as the time horizon gets larger , often can not be stated explicitly .",
    "moreover , the theory is modeled around message - passing systems , where processor might actually use very old values due to transmission delays . in the multicore ,",
    "shared - memory system application we have in mind it is reasonable to assume that after each iteration memory is synchronized and all processors have the same view",
    ".    our main motivation is obtaining ( almost ) `` noise - free '' scores to perform accurate comparisons of the induced rankings using kendall s @xmath20  @xcite : @xmath21 computational noise can be quite problematic in evaluating kendall s @xmath20 because the signum function has no way to distinguish large and small differences  they are all mapped to @xmath22 or @xmath23  @xcite .",
    "suppose , for example , that we have a graph with a large number @xmath24 of nodes , and some centrality index that assigns score @xmath25 the first @xmath26 nodes and score @xmath22 the remaining nodes .",
    "suppose we have also another index assigning the same scores , and that this new index is defined by an iterative process , which is stopped at some point ( e.g. , an iterative solver for linear systems ) .",
    "if the computed values include computational random noise and evaluate @xmath20 on the two vectors , we will obtain a @xmath20 close to @xmath27 , even if the ranks are perfectly correlated . on the other hand , with a sufficiently small guaranteed absolute error",
    "we can proceed to truncate or round the second set of scores , obtaining a result closer to the real correlation .",
    "this scenario is not artificial : when comparing , for instance , indegree with an index computed iteratively ( e.g. , katz s index , pagerank , etc . )",
    ", we have a similar situation .",
    "surprisingly , the noise from iterative computations can even _ increase _ correlation ( e.g. , between the dominant eigenvector of a graph that is not strongly connected and katz s index , as the residual score in nodes whose actual score is zero induces a ranking similar to that induced by katz s index ) .    in this paper",
    ", we provide convergence bounds in @xmath10 norm for sor iterations for the problem @xmath28 , where @xmath0 is a nonnegative real matrix and @xmath29 , in conditions of mild asynchrony , without any additional hypothesis on @xmath0 .",
    "our main result are theorem  [ teo : conv ] , which shows that given a @xmath30 and a vector @xmath2 such that @xmath3 sor iterations reduce geometrically the @xmath6-norm of the error ( with a computable contraction factor ) , and theorem  [ teo : suitable ] , which shows how to compute such a @xmath6 using only iterated products of @xmath0 with a vector",
    ". the two results can be viewed as a constructive and computable version of the standard convergence results on sor iteration based on the spectral radius .",
    "we remark that sor is actually not useful for pagerank , as shown recently by greif and kurokawa  @xcite .",
    "the author has found experimentally that the same phenomenon plagues the computation of katz s index . however , since generalizing from gau ",
    "seidel to sor does not bring any significant increase in complexity in the proof , we decided to prove our results in the more general setting .",
    "we now define _ step - asynchronous _",
    "sor for the problem @xmath31 . in general , _ asynchronous _ sor computes new values using arbitrarily old values ; in this case , the hypotheses for convergence are definitely stronger . in the _",
    "partially asynchronous _",
    "case , instead , there is a finite limit on the `` oldness '' of the values used to compute new values , and while there is a decrease in convergence speed , the hypotheses for convergence are essentially the same of the sequential case  ( see @xcite for more details ) .",
    "step - asynchronous sor uses the strictest possible time bound : one step .",
    "we thus perform a sor - like update in arbitrary order : @xmath32 the only constraint is that for each iteration an _ _ update total preorder _ _ @xmath33 of the indices is given : @xmath34 iff @xmath35 is updated before ( or at the same time of ) @xmath36 at iteration @xmath19 , and the set @xmath37 of the indices for which we use the _ previous _ values is such that for all @xmath38 we have @xmath39 , whereas @xmath40 is the set indices for which we use the _ next _ values .",
    "essentially , we _ must _ use previous values for all variables that are updated at the same time of @xmath35 or after @xmath35 , but we make no assumption on the remaining variables . in this way we take into account cache incoherence , unpredictable scheduling of multiple threads , and so on .",
    "parallel updates at the same time we would have , in fact , a jacobi iteration : in that case , @xmath41 for all @xmath42 . ]",
    "matrixwise , the set @xmath43 induces a nonnegative matrix @xmath44 given by @xmath45a_{ij}\\ ] ] and a _",
    "regular splitting _",
    "@xmath46 where @xmath47 and @xmath48 is nonnegative with zeros on the diagonal .",
    "then , equation  ( [ eq : gs ] ) can be rewritten as @xmath49 there is of course a permutation of row and columns ( depending on @xmath19 ) such that @xmath44 is strictly lower triangular , but the only claim that can be made about @xmath48 is that its diagonal is zero : actually , we could have @xmath50 and @xmath51 .    in particular , independently from the choice of @xmath44 , if @xmath52 is a solution we have as usual @xmath53 and @xmath54",
    "we now define suitability of a vector for a matrix , which will be the main tool in proving our results .",
    "the idea is implicitly or explicitly at the core of several classical proofs of convergence , and is closely related to that of _ generalized diagonal dominance _ :    a vector @xmath2 is _",
    "@xmath55-suitable _ for @xmath0 if @xmath3 .",
    "the usefulness of suitable vectors is that they induce norms norms in which the decrease of the error caused by a sor iteration for of the problem @xmath56 can be controlled if @xmath57 .",
    "if @xmath0 is irreducible , for instance , the dominant eigenvector is suitable for the spectral radius , but it is exactly this kind of hypotheses that we want to avoid .    given a vector @xmath2 , the @xmath6-norm is defined by @xmath58    the notation @xmath59 is used also for the operator norm induced in the usual way .",
    "we note a few useful properties  many others can be found in  @xcite :    [ prop : wnorm ] given a vector @xmath6 that is @xmath55-suitable for a nonnegative matrix @xmath0 , the following statements are true for all vectors @xmath60 :    1 .   [ en : coord ] @xmath61 ; 2 .   [ en : min ] @xmath62 ; 3 .   [ en : max ] @xmath63 ; 4 .   [ en : unit ] @xmath64 ; 5 .   [ en : aw ] @xmath65 ; 6 .   [ en : mindef ] if @xmath66 , @xmath67",
    "[ en : suitable ] @xmath68 ; in particular , @xmath69 .    the first claims are immediate from the definition of @xmath6-norm . for the last claim ,",
    "@xmath70    the next theorem is based on the standard proof by induction of convergence for sor , but we make induction on the update time of a component rather than on its index , and we use suitability to provide bounds to the norm of the error .",
    "[ teo : conv ] let @xmath0 be a nonnegative matrix and let @xmath6 be @xmath55-suitable for @xmath0 . then , given @xmath57 step - asynchronous sor for the problem @xmath71 converges for @xmath72 and letting @xmath73 we have @xmath74 where @xmath75",
    "moreover , @xmath76    let @xmath33 be a sequence of update orders , and @xmath77 a sequence of previous - value sets , one for each step @xmath19 and variable index @xmath42 , compatible with the respective update orders .",
    "we work by induction on the order @xmath33 , proving the statement @xmath78 where @xmath79 , assuming it is true for all @xmath80 .",
    "note that for all @xmath42 @xmath81 so for @xmath82 @xmath83 and analogously for @xmath84 we have @xmath85    writing explicitly  ( [ eq : err ] ) for the @xmath42-th coordinate , we have @xmath86 since @xmath87 implies by definition @xmath88 , we can apply the induction hypothesis on @xmath89 to state that @xmath90 .",
    "the same bound applies to @xmath91 using the first statement of proposition  [ prop : wnorm ] .",
    "we now notice that @xmath55-suitability implies @xmath92 which in coordinates tells us that @xmath93 thus , @xmath94 by the very definition of @xmath6-norm ,  ( [ eq : ind ] ) yields @xmath95    for the second statement , we have @xmath96 whence @xmath97    we remark that the smallest contraction factor is obtained when @xmath98 , that is , with no relaxation .",
    "this does not mean , however , that relaxation is not useful : convergence might be faster with @xmath99 ; it is just that the error bound we provide features the best constant when @xmath98 .",
    "[ cor : bound ] with the same hypotheses and notation of theorem  [ teo : conv ] , step - asynchronous gau ",
    "seidel iterations converge and @xmath100    [ cor : bound ] let @xmath0 be an irreducible nonnegative matrix and @xmath6 its dominant eigenvector .",
    "then the statement of theorem  [ teo : conv ] is true in @xmath6-norm with @xmath101 .",
    "a simple consequence is that if we know a @xmath55-suitable vector @xmath6 for @xmath0 we can just behave as if the step - asynchronous sor is converging in the standard supremum norm , but we have a reduction in the strength of the bound given by the ratio between the maximum and the minimum component of @xmath6 :    [ cor : bound ] with the same hypotheses and notation of theorem  [ teo : conv ] , step - asynchronous gau  seidel iterations converge and @xmath102    an application of proposition  [ prop : wnorm].[en : min ] and  [ prop : wnorm].[en : max ] .",
    "we remark that @xmath103 so it is possible to restate all results in a simplified ( but less powerful ) form .",
    "in principle it is always better to compute the actual @xmath6-norm , rather than using the rather crude bound of corollary  [ cor : bound ] . is close to @xmath104 . ] on the other hand , computing the @xmath6-norm requires storing and accessing @xmath6 , which could be expensive .    in practice , it is convenient to restrict oneself to vectors @xmath6 satisfying @xmath105 , as in that case @xmath106 , and for some @xmath60 we actually have equality . then , we can store in few bits an approximate vector @xmath107 , which can be used to estimate @xmath108 , as we have , using the notation of theorem  [ teo : conv ] , @xmath109 a reasonable choice is that of keeping in memory @xmath110 . using a byte of storage",
    "we can keep track of @xmath111 s no smaller than moreover , during the evaluation of the norm we just have to multiply by a power of two , which can be done very quickly in ieee 754 format .",
    "we now come to the main result : given a nonnegative matrix @xmath0 and a @xmath7 , it is possible ( constructively ) to compute a vector @xmath6 that is @xmath55-suitable for @xmath0 .",
    "in essence , the computation of a @xmath55-suitable vector for @xmath0 `` tames '' the non - normality of the iterative process , at the price of a reduction of the convergence range .",
    "[ teo : suitable ] let @xmath0 be nonnegative and @xmath7 .",
    "let @xmath112 and @xmath113 then , @xmath114 .",
    "in particular , @xmath115 is @xmath55-suitable for @xmath0 , and there is a @xmath116 such that @xmath117 so @xmath118 is @xmath55-suitable for @xmath0 .    consider the matrix @xmath119 , where @xmath120 . since it is strictly positive , the perron ",
    "frobenius theorem tells us that there is a dominant eigenvector @xmath121 .",
    "moreover , since for @xmath122 we have @xmath123 , and the spectral radius is continuous in the matrix entries , there must be a @xmath124 such that @xmath125 we have @xmath126 we now observe that the scaling factor is irrelevant : @xmath127 is an eigenvector , so it is defined up to a multiplicative constant .",
    "we can thus just write @xmath128 and state that @xmath129 which implies @xmath130 thus , as @xmath131 when @xmath132 , for some @xmath116 we must have @xmath133    the previous theorem suggests the following procedure . under the given hypotheses , start with @xmath134 , and iterate @xmath135 note that this is just a jacobi iteration for the problem @xmath136 , which is natural , as @xmath115 is just its solution .",
    "the iteration stops as soon as @xmath137 and at that point @xmath138 is by definition @xmath55-suitable for @xmath0 , so we can apply theorem  [ teo : conv ] .    in practice , it is useful to keep the current vector @xmath138 normalized : just set @xmath139 at the start , and then iterate @xmath140    we remark that , albeit used for clarity in the statement of theorem  [ teo : suitable ] , the ( exact ) knowledge of @xmath104 is not strictly necessary to apply the technique above : indeed , if the procedure terminates @xmath1 by proposition  [ prop : wnorm ] .",
    "there are a few useful observations about the behavior of the normalized version of the procedure .",
    "first , if @xmath141 necessarily @xmath142 as @xmath143 .",
    "second , by collatz s classical bound  @xcite , the maximum in  ( [ eq : norm ] ) is an upper bound to @xmath104 .",
    "this happens without additional hypotheses on @xmath0 because whenever @xmath144 with @xmath145 we have @xmath146 if , moreover , we compute also the minimum ratio @xmath147 this is a lower bound to @xmath104 , again without additional hypotheses on @xmath0 . indeed , note that whenever @xmath148 with @xmath149 , for every @xmath120 if @xmath6 is a positive eigenvector of @xmath119 we have @xmath150 the last inequality implies @xmath151 by proposition  [ prop : wnorm].[en : mindef ] , and since the inequality is true for every @xmath152 it is true by continuity also for @xmath153 .",
    "these properties suggest that in practice iteration should be stopped if @xmath154 goes below the minimum representable floating - point number : in this case , either @xmath155 , or the finite precision at our disposal is not sufficient to compute a suitable vector because we can not represent correctly a transient behavior of the powers of @xmath0 .",
    "if instead the minimum  ( [ eq : min ] ) becomes larger than @xmath55 , we can safely stop : unfortunately , the latter event can not be guaranteed to happen when @xmath155 without additional hypotheses on @xmath0 ( e.g. , irreducibility ) : for instance , if @xmath0 has a null row the minimum  ( [ eq : min ] ) will always be equal to zero .",
    "of course , there ai nt no such thing as a free lunch .",
    "the termination of the process above is guaranteed if @xmath7 , but we have no indication of how many step will be required . moreover , in principle some of the coordinates of the suitable vector could be so small to make theorem  [ teo : conv ] unusable . for @xmath55 close to @xmath104 convergence can be very slow , as it is related to the convergence of collatz s lower and upper bounds for the dominant eigenvalue .",
    "nonetheless , albeit all of the above must happen in pathological cases , we show on a few examples that , actually , in real - world cases computing a @xmath55-suitable vector is not difficult .",
    "we remark that in principle any dyadic product @xmath156 such that @xmath157 is irreducible will do the job in the proof of theorem  [ teo : suitable ] . there might be choices ( possibly depending on @xmath0 ) for which the computation above terminates more quickly .",
    "if @xmath0 is nonnegative matrix with @xmath159 , then @xmath160 is invertible and the problem @xmath158 has a unique solution , and in the limit we have convergence geometric in @xmath104 .",
    "however , if we choose a @xmath161 ( say , @xmath162 ) and a @xmath55-suitable vector @xmath6 , the bounds of theorem  [ teo : conv ] will be valid , so we will be able to control the error in @xmath6-norm .",
    "let @xmath163 be a nonnegative matrix ( in the standard formulation , the adjacency matrix of a graph ) .",
    "then , given @xmath164 katz s index is defined by @xmath165 where @xmath166 is a _ preference vector _ , which is just @xmath167 in katz s original definition  @xcite .. this additional multiplication by @xmath163 is somewhat common in the literature ; it is probably a case of _ horror vacui_. ] .",
    "if we want to apply theorem  [ teo : conv ] , we must choose a @xmath7 and a @xmath55-suitable vector @xmath6 for @xmath0 .",
    "the vector can then be used to accurately estimate the computation of katz s index for all @xmath168 .",
    "this property is particularly useful , as it is common to estimate the index for different values of @xmath169 , and to that purpose it is sufficient to compute once for all a @xmath55-suitable vector for a @xmath55 chosen sufficiently close to @xmath104 .",
    "the case of pagerank is similar to katz s index .",
    "we have @xmath170 where @xmath166 is the preference vector , and @xmath171 is a stochastic matrix ; @xmath172 is the adjacency matrix of a graph @xmath173 , normalized so that each nonnull row adds to one , @xmath174 is the characteristic vector of _ dangling nodes _ ( nodes without outlinks , i.e. , null rows ) , and @xmath175 is the dangling - node distribution , used to redistribute the rank lost through dangling nodes .",
    "it is common to use a uniform @xmath175 , but most often @xmath176 , and in that case we speak of _ strongly preferential _",
    "pagerank  @xcite .",
    "we remark that in the latter case it is well known that the _ pseudorank _ @xmath177 satisfies @xmath178 that is , pagerank and the pseudorank are parallel vectors .",
    "this is relevant for the computation of several strongly preferential pagerank vectors : just compute a @xmath55-suitable vector for @xmath172 ( rather than one for each @xmath179 , depending on @xmath166 ) , and compute pseudoranks instead of ranks .",
    "the case of pagerank is however less interesting because , as david gleich made the author note , assuming the notation of section  [ sec : sor ] and @xmath98 @xmath180 since @xmath181 , we can @xmath15-bound the residual @xmath182 we conclude that @xmath183 it is thus possible , albeit wasteful , to bound the supremum norm of the error using its @xmath15 norm .",
    "in this section we discuss some computational experiments involving the computation of pagerank and katz s index on real - world graphs .",
    "we focus on a snapshot of the english version of wikipedia taken in 2013 ( about four million nodes and one hundred million arcs ) and a snapshot of the ` .uk ` web domain taken in may 2007 ( about one hundred million nodes and almost four billion arcs ) .",
    "these two graphs have some structural differences , which we highlight in table  [ tab : datasets ] .",
    ".[tab : datasets]basic structural data about our two datasets . [ cols= \" <",
    ", > , > \" , ]     we applied the procedure described in section  [ sec : choosing ] to the system associated with pagerank and katz s index , with @xmath184 for pagerank and @xmath185 for katz s index .",
    "number of iterations that are necessary to compute a @xmath186-suitable vector . ]    in figure  [ fig : iter ] we report the number of iterations that are necessary to compute the @xmath42-th suitable vector .",
    "the two datasets show the same behavior in the case of pagerank  an exponential increase in the number of iterations as we get exponentially closer to the limit value .",
    "the case of katz is more varied : whereas wikipedia has a significant growth in the number of iterations ( but clearly slower than the pagerank case ) , ` .uk ` has a minimal variation across the range ( from @xmath187 to @xmath188 ) .",
    "exponentially binned frequency plots of the values of @xmath186-suitable vectors , @xmath189 , @xmath190 , @xmath191 and @xmath192.,title=\"fig:\"]exponentially binned frequency plots of the values of @xmath186-suitable vectors , @xmath189 , @xmath190 , @xmath191 and @xmath192.,title=\"fig : \" ] + exponentially binned frequency plots of the values of @xmath186-suitable vectors , @xmath189 , @xmath190 , @xmath191 and @xmath192.,title=\"fig:\"]exponentially binned frequency plots of the values of @xmath186-suitable vectors , @xmath189 , @xmath190 , @xmath191 and @xmath192.,title=\"fig : \" ] +    in figure  [ fig : norm ] we draw the ( exponentially binned ) distribution of values of suitable vectors for a choice of four equispaced values of @xmath42 .",
    "the vectors are normalized in @xmath10 norm , that is , the largest value is one .",
    "the shape of the distribution depends both on the graph and on the type of centrality computed , but two features are constant : first , as we approach @xmath193 the distribution contains smaller and smaller values ; second , the smallest value in the pagerank case is several orders of magnitude smaller .",
    "smaller values imply a larger @xmath6-norm : indeed , one can think of the elements of an @xmath10-normalized suitable vector @xmath6 as weights that `` slow down '' the convergence of problematic nodes by inflating their raw error .",
    "the intuition we gather from the distribution of values is that bounding the convergence of pagerank is more difficult .",
    "we have presented results that make it possible to bound the supremum norm of the absolute error of sor iterations an @xmath163-matrix @xmath194 even when estimating @xmath14 is not feasible . rather than relying on additional hypotheses such as positive definiteness , irreducibility and so on ,",
    "our results suggest to compute first a @xmath55-_suitable _ positive vector @xmath6 with the property that sor iterations converge geometrically in @xmath6-norm by a computable factor .",
    "while we can not bound without additional hypotheses the resources ( number of iterations and precision ) that are necessary to compute @xmath6 , in practice the computation is not difficult , and given an @xmath163-matrix @xmath194 the associated @xmath55-suitable @xmath6 can be used for all @xmath57 .",
    "paolo boldi , roberto posenato , massimo santini , and sebastiano vigna .",
    "traps and pitfalls of topic - biased pagerank . in william aiello ,",
    "andrei broder , jeannette janssen , and evangelos milios , editors , _",
    "fourth workshop on algorithms and models for the web - graph _ , volume 4936 of _ lecture notes in computer science _ , pages 107116 .",
    "verlag , 2008 .",
    "lawrence page , sergey brin , rajeev motwani , and terry winograd . the pagerank citation ranking : bringing order to the web . technical report sidl - wp-1999 - 0120 , stanford digital library technologies project , stanford university , 1998 ."
  ],
  "abstract_text": [
    "<S> step - asynchronous successive overrelaxation updates the values contained in a single vector using the usual gau  </S>",
    "<S> seidel - like weighted rule , but arbitrarily mixing old and new values , the only constraint being temporal coherence  </S>",
    "<S> you can not use a value before it has been computed . </S>",
    "<S> we show that given a nonnegative real matrix @xmath0 , a @xmath1 and a vector @xmath2 such that @xmath3 , every iteration of step - asynchronous successive overrelaxation for the problem @xmath4 , with @xmath5 , reduces geometrically the @xmath6-norm of the current error by a factor that we can compute explicitly . </S>",
    "<S> then , we show that given a @xmath7 it is in principle always possible to compute such a @xmath6 . </S>",
    "<S> this property makes it possible to estimate the supremum norm of the absolute error at each iteration without any additional hypothesis on @xmath0 , even when @xmath0 is so large that computing the product @xmath8 is feasible , but estimating the supremum norm of @xmath9 is not .    * </S>",
    "<S> mathematical subject classification : * 65f10 ( iterative methods for linear systems )    * keywords : * successive overrelaxation ; m - matrices ; asynchronous iterative solvers </S>"
  ]
}