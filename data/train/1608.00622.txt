{
  "article_text": [
    "in the last two decades , the concept of _ hybrid control system _ has provided a sound mathematical framework for treating control systems in which continuous and discrete control actions mix together , and this framework has also been successfully adapted to optimal control problems . among the various systems covered by this theory , we mention economic models with restocking , multigear and hybrid vehicles , and , more in general , systems with switchings in the dynamics and/or impulsive changes in the state . in this work ,",
    "we study efficient numerical methods for applying dynamic programming techniques to hybrid optimal control problems of infinite horizon type .    among the various mathematical formulations of optimal control problems for hybrid systems",
    ", we will adopt here the one given in @xcite .",
    "let @xmath0 , and consider the controlled system @xmath1 satisfying : @xmath2 where @xmath3 , and @xmath4 . here ,",
    "@xmath5 and @xmath6 denote respectively the continuous and the discrete component of the state .",
    "the function @xmath7 is the continuous dynamics , for a set of continuous controls given by : @xmath8 the trajectory undergoes discrete transitions when it enters two predefined sets @xmath9 ( the _ autonomous _ jump set ) and @xmath10 ( the _ controlled _ jump set ) , both of them subsets of @xmath11 . more precisely :    * on hitting @xmath9 , the trajectory jumps to a predefined destination set @xmath12 .",
    "the jump driven by a transition map @xmath13 , where @xmath14 is a discrete finite control set . denoting by @xmath15 a time at which the trajectory hits @xmath9 ,",
    "the new state will be @xmath16 , for a control @xmath17 .",
    "* entering the set @xmath10 , the controller can choose either to jump or not .",
    "if the controller chooses to jump , then the continuous trajectory is moved to a new point in @xmath18 . denoting by @xmath19 one such time of jump , we will have @xmath20 and @xmath21 .",
    "the trajectory starting from @xmath22 with discrete state @xmath4 is therefore composed of branches of continuous evolution given by between two discrete jumps at the transition times @xmath15 or @xmath19 .",
    "now , considering an optimal control problem in the infinite horizon form , and including all control actions in a control strategy @xmath23 we associate to @xmath24 a cost defined by : @xmath25 where @xmath26 is the discount factor , @xmath27 is the running cost , @xmath28 is the autonomous transition cost and @xmath29 is the controlled transition cost .",
    "the value function @xmath30 of the problem is then defined as : @xmath31 we point out that , in this generality , the problem requires strong assumptions to be mathematically well - posed . in particular , it should be ensured that the value function is continuous , and that the so - called `` zeno executions '' ( i.e. , the occurrence of an infinite number of transitions in a finite time interval ) are avoided .",
    "we will give in the next section a precise set of assumptions , whereas in the examples we will apply the numerical technique under consideration in more general situations , showing that the recipe is robust enough to handle them .    to the best of our knowledge",
    ", the first rigorous theoretical study of the convergence of numerical schemes for the approximation of the value function of  has been given in @xcite . here ,",
    "solvability of the scheme by value iteration is proved , along with a convergence result based on the barles  souganidis theorem @xcite . in spite of its robustness",
    ", however , value iteration is a relatively inefficient technique to compute the numerical solution , and an acceleration strategy would be highly desirable .",
    "+ from the very start of dynamic programming techniques @xcite , policy iteration ( pi ) has been recognized as a viable , usually faster alternative to value iteration in computing the fixed point of the bellman operator . among the wide literature on policy iteration ,",
    "we quote here the pioneering theoretical analysis of puterman and brumelle @xcite , which have shown that the linearization procedure underlying policy iteration is equivalent to a newton - type iterative solver .",
    "more recently , the abstract setting of @xcite has been adapted to computationally relevant cases @xcite , proving superlinear ( and , in some cases , quadratic ) convergence of policy iteration .",
    "moreover , we mention that an adaptation of policy iteration to large sparse problems has been proposed as `` modified policy iteration '' ( mpi ) in @xcite , and has also become a classical tool .    in the present paper ,",
    "we intend to study the construction and numerical validation of a sl scheme with pi / mpi sover for hybrid optimal control . to this end",
    ", we will recall the general algorithm , sketch some implementation details for the simple case of one - dimensional dynamics , and test the scheme on some numerical examples in dimension @xmath32 .",
    "the outline of the paper is the following . in section [ costruz ] we will review the main results about the bellman equation characterizing the value function , and construct a semi - lagrangian ( sl ) approximation for @xmath30 in the form of value iteration . in section [ policy ]",
    "we will improve the algorithm by a policy iteration technique .",
    "finally , section [ tests ] will present some numerical examples of approximation of the value function and construction of the optimal control .",
    "first , we recall some basic analytical results about the value function . to this end , we start by making a precise set of assumptions on the problem .      in the product space @xmath11 , we consider sets ( and in particular the sets @xmath33 and @xmath18 ) of the form @xmath34 in which @xmath35 represents the subset of @xmath36 in which @xmath37 .",
    "we assume that :    * for each @xmath38 , @xmath39 , @xmath40 , and @xmath41 are closed subsets of @xmath42 , and @xmath41 is bounded . @xmath43 and @xmath44 are @xmath45 . *",
    "the function @xmath46 is bounded .",
    "moreover , it is lipschitz continuous in the state variable @xmath47 and uniformly continuous in the control variable @xmath48 . *",
    "the map @xmath49 is bounded and uniformly lipschitz continuous with respect to @xmath47 .",
    "* @xmath50 is a compact set , and for some @xmath51 , the following transversality condition : @xmath52 holds for all @xmath53 , and all @xmath54 , where @xmath55 denotes the unit outward normal to @xmath43 at @xmath47 .",
    "we also assume similar transversality conditions on @xmath56 .",
    "* we assume that , for all @xmath57 , @xmath58 and @xmath59 , where @xmath60 is the euclidean distance . * the control set @xmath61 is a compact metric space , and @xmath14 is a finite discrete set .",
    "* @xmath62 is a bounded and non - negative function , lipschitz continuous w.r.t .",
    "the @xmath47 variable , and uniformly continuous w.r.t . the @xmath48 variable . *",
    "@xmath63 and @xmath64 are uniformly lipschitz continuous in the variables @xmath47 and @xmath65 , and bounded with a strictly positive infimum . moreover , for any @xmath47 and @xmath66 , the function @xmath67 satisfies ( for some @xmath68 ) the inequality @xmath69    via a suitable generalization of the dynamic programming principle , it can be proved that the bellman equation of the problem is in the form of a quasi - variational inequality , and more precisely , once defined the hamiltonian by @xmath70 and the transition operators @xmath71 and @xmath72 by : @xmath73 we have the following    assume ( a1)(a8 ) .",
    "then , the function @xmath30 is the unique bounded and hlder continuous viscosity solution of : @xmath74    note that uniqueness follows from a strong comparison principle , which also allows to use the barles  souganidis theorem @xcite for proving convergence of stable and monotone schemes .      in order to set up a numerical approximation for",
    ", we construct a discrete grid of nodes @xmath75 in the state space and fix the discretization parameters @xmath76 and @xmath77 . in what follows",
    ", we will denote the discretization steps in compact form by @xmath78 and the approximate value function by @xmath79 .    following @xcite , we write the fixed point form of the scheme at @xmath80 as @xmath81 in which @xmath82 , @xmath83 and @xmath84 are consistent and monotone numerical approximations for respectively the operators @xmath72 , @xmath71 and the hamiltonian @xmath85 .",
    "more compactly , could be written as @xmath86 we recall that , for @xmath26 , under the basic assumption which ensure continuity of the value function , the right - hand side of is a contraction @xcite and can therefore be solved by fixed - point iteration , also known as _ value iteration _ ( vi ) : @xmath87 to define more explicitly the scheme , as well as to extend the approximate value function to all @xmath88 and @xmath38 , we use an interpolation @xmath89 constructed on the node values , and denote by @xmath90 ( x , q)$ ] the interpolated value of @xmath79 computed at @xmath91 . with this notation ,",
    "a natural definition of the discrete jump operators @xmath83 and @xmath82 is given by @xmath92\\big(g(x , q , w)\\big ) + c_a(x , q , w)\\big\\}\\label{m } \\\\",
    "n v_\\delta(x , q ) & : = \\min_{(x',q')\\in d}\\big\\{\\mathcal{i}[v_\\delta](x',q ' ) + c_c(x , q , x',q')\\big\\ } \\label{n}\\end{aligned}\\ ] ] on the other hand , a standard semi - lagrangian discretization of the hamiltonian related to continuous control is provided ( see @xcite ) by @xmath93 \\big(x_i+\\delta t \\",
    "q,\\alpha ) , q\\big)\\big\\}.\\ ] ] in the sl form , the value iteration might then be recast at a node @xmath80 as @xmath94\\big(g(x_i , q , w)\\big ) + c_a(x_i , q , w)\\big\\ } & ( x_i , q)\\in a \\\\ \\displaystyle\\min \\big\\ { \\min_{(x',q')\\in d}\\big\\{\\mathcal{i}[v_{\\delta , j}](x',q ' ) + c_c(x_i , q , x',q')\\big\\ } , \\sigma(x_i , q , v_{\\delta , j } ) \\big\\ } & ( x_i , q)\\in c \\\\ \\displaystyle\\sigma(x_i , q , v_{\\delta , j } ) & \\text{else } \\end{cases}\\ ] ] with @xmath84 given by , and @xmath95 denoting the iteration number .    convergence of the scheme can be proved by using the arguments in @xcite ) if the interpolation @xmath89 is monotone ( e.g. , a @xmath96 or @xmath97 finite element interpolation ) :    assume ( a1)(a8 ) . assume in addition that @xmath26 , and that the interpolation @xmath89 is monotone and invariant for the sum of constants .",
    "then , @xmath98 for @xmath99 .",
    "moreover , the approximate solution @xmath79 converges to @xmath30 locally uniformly in @xmath11 for @xmath100 .",
    "following @xcite , we give now an even more explicit form of the scheme , which is the one applied to the one - dimensional examples of sec .",
    "[ tests ] .",
    "once we set up a 1-d space grid of evenly spaced nodes @xmath101 with space step @xmath76 , the discrete solution may be given the vector structure @xmath102 in which @xmath103 denotes the discretized value function associated to the @xmath66-th component of the state space .",
    "within the vector @xmath104 , the element @xmath105 appears with the index @xmath106 .    keeping the same notation for all vectors",
    ", @xmath107 will denote the vector of controls of the system , @xmath108 being the value of the control at the space node @xmath109 while the @xmath110-th dynamics is active .",
    "we also define the vector @xmath111 representing the switching strategy , so that @xmath112 means that if the trajectory is in @xmath109 and the active dynamics is @xmath110 , the system commutes from @xmath110 to @xmath113 .",
    "note that , in the numerical examples of sec .",
    "[ tests ] , discontinuous jumps will always appear only on the discrete component of the state space , so that , for example , we have @xmath114 and this data need not be kept in memory ( we will use the term _ switch _ to denote a state transition of this kind ) .    in the general case , we would also need to keep memory of the arrival point of the jump and/or of the discrete control @xmath115 in the case of an autonomous jump . in general , the arrival point is not a grid point , so that we also need to perform an interpolation in . therefore , the details for the general case can be recovered by mixing the basic arguments used in what follows .    the endpoint of this construction is to put the problem in the standard form used in policy iteration , @xmath116 with explicitly defined matrix @xmath117 and vector @xmath118 . note that , in , we have made clear the fact that a policy is composed of both a feedback control @xmath119 and a switching strategy @xmath120 .",
    "define now the matrices @xmath121 as permutations of the array @xmath104 .",
    "these matrices represent changes in the state due to the switching strategy : @xmath122 corresponds to autonomous jumps and @xmath123 to controlled jumps .",
    "note that , in our case , the elements of @xmath122 and @xmath123 will be in @xmath124 , that there exists at most one nonzero element on each row , and that the two matrices can not have a nonzero element in the same position .",
    "+ in order to determine the positions of the nonzero elements @xmath125 in the matrix @xmath122 , we apply the following rule . for",
    "all @xmath126 , if the following conditions hold : @xmath127 then , @xmath128 similarly , the nonzero elements of the matrix @xmath123 , @xmath129 , follow a slightly less strict rule .",
    "for all @xmath130 , if the following conditions hold : @xmath131 then , @xmath128 last , we define the matrix @xmath132 which accounts for changes in the state related to the switching strategy , both autonomous and controlled .",
    "we turn now to the continuous control part .",
    "first , we write @xmath84 in vector form as @xmath133 where the matrix @xmath134 is defined so as to have @xmath135 \\big(\\bm x+\\delta t\\ >",
    "f(\\bm x , k,\\bm\\alpha^{(k ) } ) , k \\big)\\ ] ] and @xmath136 \\big(\\bm x+\\delta t \\",
    "> f(\\bm x , k,\\bm\\alpha^{(k ) } ) , k\\big)$ ] and @xmath137 denote vectors which collect respectively all the values @xmath90",
    "\\big(x_i+\\delta t\\ > f(x_i , k,\\alpha_i^{(k ) } ) , k\\big)$ ] and @xmath138 .    at internal points , using a monotone @xmath139 interpolation for the values of @xmath104 results in a convex combination of node values . on the boundary of the domain ,",
    "the well - posedness of the problem requires either to have an invariance condition ( which implies that @xmath140 always points inwards ) or to perform an autonomous jump or switch when the boundary is reached .",
    "therefore , we should not care about defining a space reconstruction outside of the computational domain , although this could be accomplished by extrapolating the internal values .",
    "the matrix @xmath141 is then constructed in the block diagonal form : @xmath142 assuming for simplicity that we work at courant numbers below the unity ( although this is not necessary for the stability of sl schemes ) , each block @xmath143 is a sparse matrix with non - zero elements @xmath144 determined so as to implement a @xmath139 space interpolation , in the following way : for every @xmath126 , define @xmath145 and @xmath146 else , @xmath147 note that , if a switching strategy @xmath148 does nt perform any switch ( i.e. @xmath149 for all @xmath150 ) , by definition of the matrix @xmath151 we would obtain , for all @xmath152 , @xmath153 whereas , in the general case , if a switch occurs at @xmath109 , then the corresponding element of the matrix @xmath154 is zero . finally , we define the vector @xmath155 with a block structure of the form : @xmath156 with @xmath157 such that , for every @xmath158 in @xmath130 , @xmath159 where @xmath160 denotes the switching cost ( @xmath161 or @xmath67 ) from dynamics @xmath110 to @xmath113 .    with these notations ,",
    "we can write the sl scheme in vector form as @xmath162\\bm v - c(\\bm\\alpha,\\bm s)\\big\\},\\ ] ] or , defined the matrix @xmath163 as @xmath164 once we have reformulated the semi - lagrangian scheme for the hybrid control problem in the standard form , we can solve it using algorithm [ how ] .",
    "the only difference with a standard pi algorithm is to include the switching strategy in the control policy .",
    "@xmath165 stop @xmath166 false @xmath167 @xmath168 stop @xmath166 true @xmath169 solution of @xmath170 ( _ policy evaluation _ )",
    "@xmath171 ( _ policy improvement _ ) @xmath172    we remark that some theoretical result obtained in the `` classical '' setting is also true in the hybrid setting .",
    "in particular , convergence might still be obtained by monotonicity ( see , e.g. , @xcite ) with minor changes in the proof , since the right - hand side of is still in the form of a minimum :    let @xmath104 be the solution of , and @xmath173 be defined by algorithm [ how ] . if @xmath174 then the sequence @xmath173 is monotone decreasing , and @xmath175 .      a different iterative solver for the numerical scheme has been first proposed and analysed in @xcite , and is known as _ modified policy iteration_. it consists in performing the minimization in only once every @xmath176 iterations . in other terms , the policy evaluation step is replaced by @xmath176 iterations of linear advection ( in which , however , the transport may occur among different components of the state space ) .",
    "for @xmath177 we obtain the value iteration , whereas for @xmath178 the transport steps converge to an exact policy evaluation , and the algorithm coincides with the previous `` exact '' pi algorithm .",
    "the pseudo - code in algorithm [ inexact ] shows the mpi algorithm in one - dimensional matrix form , for a comparison with the exact algorithm ( algorithm [ how ] ) .",
    "@xmath165 stop @xmath166 false @xmath167 @xmath168 stop @xmath166 true @xmath171 ( _ policy improvement _ )",
    "@xmath179 @xmath180\\bm v_{j } - \\bm c(\\bm\\alpha_{j+1},\\bm s_{j+1})$ ] ( _ inexact policy + evaluation _ ) @xmath172    note that , in the numerical test section , the mpi algorithm has been applied to the two - dimensional examples . although the formulation in dimension @xmath181 could be accomplished by a suitable redefinition of the vectors and matrices , in practice the mpi algorithm does not need such a formalism .    concerning convergence , the hybrid case can again be treated with the same theoretical tools of the original proof in @xcite , which relies on the monotonicity of the ( discretized ) bellman operator , as well as on giving an upper and a lower bound on the sequence @xmath173 by means of two converging sequences ( one of which generated by value iteration ) . more precisely , the sequence considered in the convergence proof for the mpi is the sequence of approximations obtained after each policy improvement . in our notation , this is the subsequence @xmath182 corresponding to @xmath183 .",
    "we have therefore the following    let @xmath104 be the solution of , and @xmath173 be defined by algorithm [ inexact ] . if @xmath174 then , for any @xmath184 , the subsequence @xmath182 obtained for @xmath183 is monotone decreasing , and @xmath185 for @xmath186 .",
    "we give in this section some numerical examples in one and two space dimensions , comparing the performances of value and policy iteration  exact pi algorithm in one dimension , and mpi in two dimensions .",
    "the comparison shows a substantial improvement in the convergence of the solver for the exact pi algorithm , whereas the mpi performs roughly the same number of iterations as the vi . here , the bottleneck is apparently the contraction coefficient of the bellman operator",
    "nevertheless , the mpi allows to avoid the minimization step in a large majority of the iterates , thus reducing the cpu time .",
    "note that in both two - dimensional examples the control appears only as a switching strategy , and the complexity of policy evaluation steps is reduced by a factor @xmath187 . for more complex control actions",
    "the improvement in computing time would be even greater .",
    "we now apply this technique to a stabilization problem : we consider a system with two dynamics : one `` strong and expensive '' and the other `` weak and cheap '' . only the former is able to keep the state of the system within the given set over time .",
    "the state equation @xmath188 is defined by @xmath189 where @xmath190 and @xmath191 for every @xmath192 in @xmath193 .",
    "switching is mandatory only when the dynamics @xmath194 is active and @xmath195 , which implies that the state of the system belongs to the interval @xmath196 $ ] for all @xmath192 in @xmath193 .    here and in what follows",
    ", @xmath197 denotes a constant switching cost from @xmath37 to @xmath198 , and the cost functional is defined as @xmath199 the values assigned to all the parameters are summed up in table [ tab : ws_par ] , whereas table [ tab : ws ] reports the number of iterations required for given stopping tolerances . in the first three examples ,",
    "the stopping criterion reads @xmath200 note that , according to table [ tab : ws ] , squaring the tolerance makes the number of iteration @xmath201 of the pi algorithm increase linearly , which indicates roughly quadratic convergence , while the number @xmath202 for vi has a geometric behaviour as expected .",
    ".number of iterations ( vi and pi ) for a given tolerance @xmath203 , weak - strong test [ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]      for the dc / ac inverter.,title=\"fig : \" ]   for the dc / ac inverter.,title=\"fig : \" ]     for the dc / ac inverter.,title=\"fig : \" ]   for the dc / ac inverter.,title=\"fig : \" ]     for the dc / ac inverter . ]",
    "we have constructed and validated a semi - lagrangian scheme for hybrid dynamic programming problems in infinite horizon form .",
    "the numerical scheme has been made more efficient by a policy iteration type solver .",
    "numerical tests performed on examples of varying complexity show that the scheme is robust and that the approximate optimal control policy obtained is stable and accurate , although the complexity remains critical with respect to the dimension of the state space ."
  ],
  "abstract_text": [
    "<S> the mathematical framework of hybrid system is a recent and general tool to treat control systems involving control action of heterogeneous nature . in this paper , we construct and test a semi - lagrangian numerical scheme for solving the dynamic programming equation of an infinite horizon optimal control problem for hybrid systems . in order to speed up convergence </S>",
    "<S> , we also propose an acceleration technique based on policy iteration . </S>",
    "<S> finally , we validate the approach via some numerical tests in low dimension .    </S>",
    "<S> 0.5cm*keywords : * hybrid control , dynamic programming , semi - lagrangian schemes , policy iteration 0.5cm*ams subject classification 2010 : * 34a38 , 49l20 , 65b99 , 65n06 </S>"
  ]
}