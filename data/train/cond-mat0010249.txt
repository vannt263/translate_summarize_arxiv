{
  "article_text": [
    "the purpose of the work is to study the information properties of an analogue communication channel , constructed by a two - layer neural network , receiving data from a gaussian source .",
    "this data is corrupted with gaussian noise with a known variance and the output signals are affected by some random uncorrelated output noise .",
    "contrarily to what happens in the case of a linear gaussian channel , which can be easily solved even in presence of noise @xcite , @xcite , the exact calculation in the case of analogue channel requires some assumptions on the relation between the non - linear term and the level of noise .",
    "in particular , we suppose a small non - linearity , compared to the output noise .",
    "this corresponds to the case where the sigmoidal transfer function is relatively flat and the channel is noisy . under this assumption",
    ", the mutual information between the output and the input of the channel can be evaluated analytically .",
    "the perturbative approach by means of feynman diagrams , @xcite , developed in this paper , allows to represent in a direct and elegant way the perturbative corrections in first order of perturbation theory for every kind of non - linearity .",
    "comparing with the extreme case of the binary transfer function , where special mathematical techniques @xcite , @xcite , @xcite are introduced for the calculation of the mutual information , the present analysis deals mainly with the effect of the non - linearity on the mutual information and the rational way of investigating it .",
    "the problem of its maximization with respect to the coupling matrix @xcite will be considered elsewhere @xcite .",
    "the paper is organized as follows : in section 2 we introduce the model and in section 3 the mutual information is derived in the case of a general non - linear function . in section 4",
    "we present the results for the typical case of cubic non - linearities . in section 5",
    "we develop the rules to express the perturbative series in terms of feynman diagrams in the case of the same cubic non - linearity . in section 6",
    "we discuss the case of a general non - linearity . in section 7",
    "we present shortly the calculation of the mutual information in the case of a generic non - local cubic nonlinearity and explain how the diagram technique is modified .",
    "we conclude with some final remarks and with future developments of this work .",
    "we consider a two layer network with @xmath0 continuous inputs @xmath1=@xmath2 which are gaussian distributed and correlated trough the matrix @xmath3 :    @xmath4_{ij } , \\,\\,\\,\\",
    ", \\forall i , j\\in 1,2, .. n . \\label{input}\\end{aligned}\\ ] ]    the signals are corrupted by uncorrelated gaussian input noise @xmath5=\\{@xmath6 , with    @xmath7    the output vector is a function of the noisy input @xmath8 transformed via the couplings @xmath9 :    @xmath10    we also assume that the output signals are affected by some random uncorrelated output noise @xmath11=\\{@xmath12 , with the following gaussian distribution :    @xmath13    the transfer function @xmath14 is a smooth continuous function , which typically has a sigmoidal shape in the case of analogue neuronal devices @xcite , @xcite , @xcite .",
    "one possible choice is :    @xmath15    where the parameter @xmath16 modulates the steepness of the curve .",
    "a linear input - output relationships has already been considered in the context of the mutual information in previous works @xcite . here",
    "we examine the contribution to information transmission given by a small non - linear term in the channel transfer function .    assuming that the argument of the transfer function is small , a taylor expansion of eq.([gain ] ) gives :    @xmath17    where the higher order terms are all odd powers of @xmath18 .",
    "thus the output of the channel can be written as :    @xmath19    where @xmath20 is a generic non - linear term .",
    "for example it could be the cubic term or a higher order term in the expansion of the @xmath21 ) in terms of @xmath22=@xmath23 .",
    "we are interested on the mutual information @xcite between the input and the output signals :    @xmath24    it is easy to show that @xmath25 can be written as the difference between the output entropy and the `` equivocation '' between the output and the input :    @xmath26    where    @xmath27    and @xmath28    in the next section we present the calculation of the mutual information separately for the output entropy @xmath29 and for the equivocation @xmath30 , in the considered case of a non - linear channel .",
    "let us consider the probability for the output signals @xmath31 in eq .",
    "( [ entropy ] ) . if the non - linear term @xmath20 , present in eq .",
    "( [ output ] ) , were equal to zero , the evaluation of @xmath29 would be trivial , as @xmath32 would be a linear combination of gaussian variables . in order to extract explicitely the dependence of @xmath31 on the non - linear term @xmath20",
    ", we introduce the conditioned probability @xmath33 :    @xmath34    expanding @xmath31 to the first order in @xmath35 , assuming a small non - linearity , compared to the variance of the output noise , we obtain :    @xmath36 , \\label{pi_0}\\ ] ]    where    @xmath37    and we have assumed that higher order terms in the ratio @xmath38 are negligible .    substituting eq .",
    "( [ pi_0 ] ) in the expression for the output entropy @xmath29 we obtain at the first order in @xmath35 :    @xmath39    here @xmath40 is the output entropy in the case of a linear channel @xcite , @xcite .",
    "we remind that @xmath41 is the probability for the output @xmath32 when @xmath20=@xmath42 . in this case",
    "@xmath32 is a linear combination of zero mean gaussian variables and its distribution is a gaussian centered in @xmath42 with a covariance matrix given by :    @xmath43_{ij}=[a+bi]_{ij } , \\label{amatrix}\\ ] ]    where we have set @xmath44 .",
    "@xmath45 in the definition of @xmath46 whenever we change basis from @xmath46 to @xmath47 .",
    "] can be explicitely written also in the following way :    @xmath48^{-1 } ( { \\mbox{\\boldmath $ v$}}- { \\mbox{\\boldmath $ h$}})+ { \\mbox{\\boldmath $ h$}}^t [ a+bi]^{-1 } ( { \\mbox{\\boldmath $ v$}}-{\\mbox{\\boldmath $ h$}})\\nonumber\\\\                    & & + ( { \\mbox{\\boldmath $ v$}}- { \\mbox{\\boldmath $ h$}})^t[a+bi]^{-1}{\\mbox{\\boldmath $ h$}}^t- { \\mbox{\\boldmath $ h$}}^t [ a+bi]^{-1 } { \\mbox{\\boldmath $ h$}},\\end{aligned}\\ ] ]    which now can be easily integrated over the gaussian distributions @xmath49 and @xmath50 .",
    "since @xmath20 is an odd power function of @xmath22 like any term in the expansion of the transfer function ( [ gain ] ) , only the second and the third term in the sum in eq.([i1trick ] ) give non zero contributions .",
    "thus , the expression of the integral in the expression for the output entropy eq.([outfin ] ) becomes :    @xmath51^{-1 } ( { \\mbox{\\boldmath $ v$}}-{\\mbox{\\boldmath $ h$}})+ ( { \\mbox{\\boldmath $ v$}}- { \\mbox{\\boldmath $ h$}})^t[a+bi]^{-1}{\\mbox{\\boldmath $ h$}}^t\\right ] .",
    "\\label{diagentropy}\\ ] ]    the integration over @xmath32 leads to the final expression for the output entropy in terms of a general non - linearity @xmath52 :    @xmath53    @xmath54^{-1}{\\mbox{\\boldmath $ h$}}. \\label{outentropy}\\ ] ]    the evaluation of the integral in @xmath55 requires a specific choice for the non - linearity . before introducing it ,",
    "we show how to obtain a similar expression for the equivocation term @xmath56 .",
    "we remind the expression of the equivocation term :    @xmath57    the evaluation of this term can be carried out in a very similar way to the output entropy .",
    "we use the equivalence :    @xmath58    then , expanding @xmath33 in powers of @xmath59 up to the first order as in eq.([pi_0 ] ) we obtain :    @xmath60 , \\label{pi_0_x}\\ ] ]    where    @xmath61    substituting eq.([pi_0_x ] ) in the expression of the equivocation term , we obtain :    @xmath62    here the conditional probability @xmath63 is :    @xmath64}}\\cdot e^{-({\\bf v}- j{\\bf x})^t[b+bi]^{-1}({\\bf v}- j{\\bf x})/2},\\ ] ]    where @xmath65 is the correlation matrix between the outputs in absence of signals at @xmath66 . from eq .",
    "( [ output]),([inputnoise]),([outputnoise ] ) one can derive :    @xmath67_i)(v_j- [ j{\\mbox{\\boldmath $ x$}}]_j)\\rangle= [ b+bi]_{ij}\\nonumber\\\\ & & b = b_0jj^t \\label{bmatrix}\\end{aligned}\\ ] ]    the expression for the equivocation term becomes :    @xmath68    where    @xmath69^{-1}({\\mbox{\\boldmath $ v$}}\\!-\\ !",
    "j{\\mbox{\\boldmath $ x$ } } ) .\\ ] ]    the integration over @xmath70 is carried easily as @xmath71 is gaussian and by using the replacement :    @xmath72    the final expression to be integrated over @xmath32,@xmath22 and @xmath1 becomes :    @xmath73^{-1 } ( { \\mbox{\\boldmath $ h$}}- j{\\mbox{\\boldmath $ x$}})+({\\mbox{\\boldmath $ h$}}-j { \\mbox{\\boldmath $ x$}})^t[b+bi]^{-1}({\\mbox{\\boldmath $ v$}}- { \\mbox{\\boldmath $ h$}})\\right ] .",
    "\\label{diagequiv } \\end{aligned}\\ ] ]    the integration over @xmath70 gives for the equivocation term :    @xmath74^{-1}{\\mbox{\\boldmath $ h$ } } , \\label{equivoc}\\ ] ]    where we have changed variable from @xmath75 .",
    "this expression is our final result for the equivocation term in the case of a general non - linear function @xmath52 .    combining eqs.([outentropy ] ) and",
    "( [ equivoc ] ) , the mutual information reads :    @xmath76^{-1}{\\mbox{\\boldmath $ h$ } } -\\int\\!\\ ! d{\\mbox{\\boldmath $ h$}}\\!\\!\\int\\!\\ ! d{\\mbox{\\boldmath $ x$ } } p({\\mbox{\\boldmath $ h$ } } ) p({\\mbox{\\boldmath $ x$ } } ) { \\mbox{\\boldmath $ g$}}({\\mbox{\\boldmath $ h$}}+j{\\mbox{\\boldmath $ x$}})^t[b+bi]^{-1}{\\mbox{\\boldmath $ h$ } } , \\label{finalinfo}\\ ] ]    where @xmath77 is the mutual information in absence of non - linearities .",
    "is different from @xmath78 : both distributions are gaussian , but with different variances , as @xmath79 ; @xmath80 , while @xmath81 .",
    "matrices @xmath82 and @xmath83 are given respectively in eq.([amatrix ] ) and ( [ bmatrix ] ) . ]",
    "the final expression for the mutual information has been obtained in the case of a generic non - linearity @xmath20 . to carry further on the calculation , we have to specify its shape .",
    "let us consider the first non - linear term in the expansion of the sigmoidal transfer function ( [ gain ] ) :    @xmath84    where we have set @xmath85=@xmath86 . by using the wick theorem @xcite , and @xmath80 , the integration over @xmath87 in eq.([finalinfo ] )",
    "can be carried out quite easily and the final expression for the output entropy @xmath29 for this special choice of @xmath35 is :    @xmath88^{-1}_{i j } a_{i j } .\\ ] ]    the evaluation of the integrals over @xmath1 and @xmath89 in eq.([finalinfo ] ) for the equivocation term can be carried out with the same procedure . as only even powers of both variables",
    "give non zero contribution , only the terms @xmath90_i[j{\\mbox{\\boldmath $ x$}}]_i$ ] in the expansion of @xmath91 remain .",
    "the integration over @xmath1 and @xmath89 gives :    @xmath92^{-1}_{i j } [ b_{i j } b_{j j } + b_{i j } [ jcj^{t}]_{j j } ] .\\ ] ]    from eqs .",
    "( [ i1cub ] ) and ( [ i2cub ] ) we derive the expression for the mutual information :    @xmath93^{-1}_{i j}a_{i j } - [ b+bi]^{-1}_{i j}b_{ij } ] , \\ ] ]    where we have used that @xmath94 from eq.([amatrix ] ) , ( [ bmatrix ] ) .",
    "an interesting issue to investigate is whether the contribution to the mutual information given by higher order non - linear terms in the transfer function ( [ gain ] ) is positive or negative varying the level of noise and the strength of the correlations .",
    "here we just mention the case where the synaptic connections are positive and the inputs units are independent . in this very simple case",
    "it is easy to see from equation ( [ icub ] ) that the contribution to the mutual information is negative .",
    "this makes sense as the information carried by independent units is found to be additive;it is reasonable to think that a small negative non - linearity in the transfer function , which takes into account the saturation of the output to a given threshold , depresses the information",
    ". a more detailed study of the effect of a non - linearity with respect to an enhancement or depression of the mutual information will be the object of future investigations .    in the limit of vanishing output noise , @xmath95 , by using the    fact that @xmath82 and @xmath83 are invertible matrices",
    ", we get :    @xmath96_{i i } + o(b^2 ) .\\ ] ]",
    "it s well known from perturbation theory @xcite that a series of gaussian integrals can be expressed as a diagrammatic expansion , which makes the evaluation of high order contributions faster and elegant .",
    "we show here how the evaluation of integrals ( [ diagentropy ] ) and ( [ diagequiv ] ) can be expressed in terms of feynman diagrams .",
    "even if the formalism we develop is specific to our case , this is the first attempt to introduce a diagrammatic technique to take into account high order effects in information transmission in a progressive controlled way .",
    "we summarize here the definitions and the rules which allow to build the diagrams .",
    "the general formalism can be found in @xcite .    to evaluate the output entropy in eq .",
    "( [ diagentropy ] ) we introduce the following components of the graphs and rules to connect them :    diag8    1 .",
    "each term @xmath97 is represented by a wiggly line   + ( 20,1 ) 2 .",
    "each term @xmath98 is represented by a solid line   + ( 20,1 ) 3 .",
    "each matrix element @xmath99_{i j}^{-1}$ ] is represented by a dashed square   + ( 20,5 ) 4 .",
    "the integration over @xmath98,@xmath100 corresponds to the contraction of two solid lines coming out of vertices @xmath101,@xmath102 , which produces the matrix element @xmath103 + ( 20,1 ) + .",
    "the integration over @xmath104,@xmath105 corresponds to the contraction of two wiggly line coming out of vertices @xmath101,@xmath102 , which produces a term @xmath106   + ( 20,1 ) + .",
    "let us consider the case of the cubic non - linearity and let us set @xmath107 .",
    "following the rules listed above we can identify each factor in the integrand as a diagram :    @xmath108^{-1}_{ij}h_j\\nonumber\\\\ \\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{shaded , tension=0.5}{k1,k2,k3,k4}\\fmf{plain , label=$i$,l.side = right}{i1,k1 } \\fmf{photon , label=$j$,label.side = right}{k3,o1}\\end{fmfgraph*}}\\,\\,\\ , & \\longrightarrow & h_i[a+bi]^{-1}_{ij}(v_j - h_j)\\nonumber\\end{aligned}\\ ] ]    the result of the integrations is expressed as a series of diagrams obtained connecting the lines in the first diagram with the lines in the second and in the third diagram in order to construct all the topologically distinct and connected diagrams :    @xmath109\\left[\\parbox{20 mm } { \\begin{fmfgraph*}(20,10)\\fmfpen{thin}\\fmfleft{i1 } \\fmfright{o1}\\fmfpoly{shaded , tension=0.5}{k1,k2,k3,k4}\\fmf{photon , label=$j$,label.side = right } { i1,k1}\\fmf{plain , label=$k$,label.side = right}{k3,o1}\\end{fmfgraph*}}+ \\parbox{20mm}{\\begin{fmfgraph*}(20,10)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{shaded , tension=0.5}{k1,k2,k3,k4}\\fmf{plain , label=$j$,label.side = right } { i1,k1}\\fmf{photon , label=$k$,label.side = right}{k3,o1}\\end{fmfgraph*}}\\right]\\right>_{c}\\ ] ]    each of the three solid lines coming out from the first diagram can be connected with the solid line coming out from the second diagram and similarly from the third diagram , while the remaining two solid lines are contracted in a loop ; thus we have at the end 6 times the same diagram :    @xmath110    diag7    it s easy to check that applying the rules for the contractions of wiggly and solid lines one obtains the expression of the output entropy which coincides with eq.([i1cub ] ) .",
    "now we introduce analogous graphic rules for the evaluation of the equivocation ( [ diagequiv ] ) ; some rules are the same as the ones listed , but we need a new element in the graph to represent the vector @xmath111 .",
    "the full prescription is given below :    1 .",
    "each term @xmath97 is represented by a wiggly line   + ( 20,1 ) 2 .",
    "each term @xmath112 is represented by a solid line   + ( 20,1 ) 3 .",
    "each term @xmath113_i$ ] is represented by a dashed line   + ( 20,1 ) 4 .",
    "each matrix element @xmath114_{i j}^{-1}$ ] is represented by an empty square   + ( 20,5 ) 5 .",
    "the integration over @xmath112,@xmath115 corresponds to the contraction of two solid lines coming out of vertices @xmath101,@xmath102 , which gives the matrix element @xmath116   + ( 20,1 ) 6 .",
    "the integration over @xmath104,@xmath105 corresponds to the contraction of two wiggly lines coming out of vertices @xmath101,@xmath102 , which gives the term @xmath117   + ( 20,1 ) 7 .",
    "the integration over @xmath118 corresponds to the contraction of two dashed lines coming out of vertices @xmath101,@xmath102 , which gives the matrix element @xmath119^t_{ij}$ ] + ( 20,1 )    let us consider the case of the cubic non - linearity .",
    "moreover let us set @xmath112=@xmath120_i$ ] .",
    "then    @xmath121_i)^3\\rightarrow h_{i}^{3 } + 3h_{i}[j{\\mbox{\\boldmath $ x$}}]_i[j{\\mbox{\\boldmath $ x$}}]_i\\ ] ]    as odd powers of @xmath89 and @xmath1 give zero contribution to the integral .",
    "as in the case of the output entropy we can identify the different factors multiplied in the integrand in eq.([diagequiv ] ) with different diagrams :    @xmath122_i[j{\\mbox{\\boldmath $ x$}}]_i(v_i - h_i)\\nonumber\\\\ \\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4}\\fmf{photon , label=$i$,l.side = right}{i1,k1}\\fmf{plain , label=$j$,l.side = right}{k3,o1}\\end{fmfgraph*}}&\\longrightarrow & ( v_i - h_i)[b+bi]^{-1}_{ij}h_j\\nonumber\\\\ \\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4}\\fmf{plain , label=$i$,l.side = right}{i1,k1 } \\fmf{photon , label=$j$,l.side = right}{k3,o1}\\end{fmfgraph*}}&\\longrightarrow & h_i[b+bi]^{-1}_{ij}(v_j - h_j)\\nonumber\\end{aligned}\\ ] ]    thus the expression for the equivocation can be written in the following way :    @xmath123 \\left[\\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1 } \\fmfright{o1}\\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4}\\fmf{photon , label=$j$,label.side = right } { i1,k1}\\fmf{plain , label=$k$,label.side = right}{k3,o1}\\end{fmfgraph * } } +   \\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4}\\fmf{plain , label=$j$,label.side = right } { i1,k1}\\fmf{photon , label=$k$,label.side = right}{k3,o1}\\end{fmfgraph*}}\\right ] \\right>_{c}\\nonumber . \\end{aligned}\\ ] ]    now we have to connect both the first and the second diagram to the third and to the fourth diagram in all possible ways to obtain fully connected diagrams .",
    "it s easy to see that the contraction of the first diagram with the third and the fourth ones gives @xmath124 times the diagram already obtained in the case of the output entropy ( [ i1cub ] ) .",
    "the contraction of the second diagram with the third and with the fourth diagrams gives a new contribution :    @xmath125    writing together the two contributions we obtain the expression for the equivocation , which is equal to eq .",
    "( [ i2cub ] ) as it was expected .",
    "we show here how to obtain the diagrammatic expansion and the final expression for the mutual information in the case of higher order non - linearities .",
    "this allows eventually to evaluate the contribution given by each term in the expansion of the transfer function ( [ gain ] ) .",
    "let us consider a generic term @xmath126 .",
    "the constants depending on parameter @xmath16 not to introduce too many parameters ]    the evaluation of the integrals ( [ diagentropy ] ) and ( [ diagequiv ] ) can be carried out in a very similar way .",
    "we make the following substitutions :    diag6    @xmath127_i)^3&\\rightarrow & ( h_i+[j{\\mbox{\\boldmath $ x$}}]_i)^{2n+1 } \\rightarrow \\sum_{l=0}^{n}\\left(\\begin{array}{c}2n+1\\\\2l\\end{array}\\right ) ( h_i)^{2n+1 - 2l } ( [ j{\\mbox{\\boldmath $ x$}}]_i)^{2l } .",
    "\\label{rep}\\end{aligned}\\ ] ]    here the binomial expansion of @xmath128_i)^{2n+1}$ ] contains only even powers of @xmath113_i$ ] because odd powers give zero contribution when integrated over @xmath1 .",
    "these changes correspond to analogous replacements in the basic diagrams :    @xmath129    the double solid line in the upper diagram on the rhs is a short notation for a set of @xmath130 solid lines .    in the lower diagram on",
    "the rhs the double dotted line stands for a set of @xmath131 single dotted lines and the double solid line represents a set of @xmath132 single solid lines .",
    "then the diagrammatic equation for the output entropy and for the equivocation in the case of a generic @xmath133 order non - linearity can be written as follows :    @xmath134 \\left[\\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{shaded , tension=0.5}{k1,k2,k3,k4 } \\fmf{photon , label=$j$,label.side = right}{i1,k1}\\fmf{plain , label=$k$,label.side = right } { k3,o1}\\end{fmfgraph*}}+ \\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{shaded , tension=0.5}{k1,k2,k3,k4 } \\fmf{plain , label=$j$,label.side = right}{i1,k1}\\fmf{photon , label=$k$,label.side = right } { k3,o1}\\end{fmfgraph*}}\\right]\\right>_{c}\\ ] ]    @xmath135 \\left[\\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4 } \\fmf{photon , label=$j$,label.side = right}{i1,k1}\\fmf{plain , label=$k$,label.side = right } { k3,o1}\\end{fmfgraph * } } +   \\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4}\\fmf{plain , label=$j$,label.side = right}{i1,k1 } \\fmf{photon , label=$k$,label.side = right}{k3,o1}\\end{fmfgraph*}}\\right ] \\right>_{c}\\nonumber \\end{aligned}\\ ] ]    constructing all the topologically distinct diagrams , according to the rules given above , one can derive the final expression for the mutual information :    @xmath136^{-1}_{i j}a_{i j}\\nonumber\\\\ & + & g_0 \\sum_{l=0}^{2n+1 } ( \\begin{array}{c}2n+1\\\\2l\\end{array } )   ( 2n+1 - 2l)\\frac{1}{n}(\\begin{array}{c}2n\\\\2\\end{array})\\frac{1}{l } ( \\begin{array}{c}2l\\\\2\\end{array } ) \\sum_{i j } [ b+b]_{i j}^{-1 } b_{i j } b_{i i}^{n - l}[jcj^{t}]^{l}_{i j}.\\end{aligned}\\ ] ]    eq .",
    "( [ igenfull ] ) is the final expression in the case of a generic non - linear function of the type @xmath137 , for which the diagrammatic techniques provide an easy and direct way to calculate the mutual information .",
    "since in the case of the sigmoidal function ( [ gain ] ) the expansion includes only odd powers in @xmath98 , the derivation of the diagrammatic series for the whole taylor expansion is straightforward , at least up to the first order in @xmath35/b .",
    "this shows how the diagrammatic technique provides a compact and easily readable expression for the mutual information in the case of a non - linear noisy analogue channel .",
    "let us now investigate the case of a non local non - linearity which depends on the local fields of all outputs .",
    "this could correspond to the case where , for example , the global output of the network is constrained in such a way that the local outputs of the single units depend on the total structure of the connectivities .",
    "the general case of @xmath130-order non - linearities is quite complex , but the analysis can be carried out quite easily in the case of a cubic non local non - linearity .",
    "the most general third order term can be written as :    @xmath138    substituting eq.([gencub ] ) in eqs.([diagentropy ] ) and ( [ diagequiv ] ) it s easy to check that the output entropy @xmath29 and the equivocation @xmath30 can be written as diagrammatic equations .",
    "the definitions for lines and vertices given in the previous section remain valid in this more complex case as well .",
    "it s enough to replace the basic diagrams derived for the cubic local non - linearity :    @xmath139    the diagrammatic equations for the output entropy and for the equivocation become :    @xmath140\\left[\\parbox{20 mm } { \\begin{fmfgraph*}(20,10)\\fmfpen{thin}\\fmfleft{i1 } \\fmfright{o1}\\fmfpoly{shaded , tension=0.5}{k1,k2,k3,k4}\\fmf{photon , label=$\\varrho$,label.side = right } { i1,k1}\\fmf{plain , label=$\\sigma$,label.side = right}{k3,o1}\\end{fmfgraph*}}+ \\parbox{20mm}{\\begin{fmfgraph*}(20,10)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{shaded , tension=0.5}{k1,k2,k3,k4}\\fmf{plain , label=$\\varrho$,label.side = right } { i1,k1}\\fmf{photon , label=$\\sigma$,label.side = right}{k3,o1}\\end{fmfgraph*}}\\right]\\right>_{c}\\ ] ]    @xmath141 \\left[\\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1 } \\fmfright{o1}\\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4}\\fmf{photon , label=$\\varrho$,label.side = right } { i1,k1}\\fmf{plain , label=$\\sigma$,label.side = right}{k3,o1}\\end{fmfgraph * } } +   \\parbox{20mm}{\\begin{fmfgraph*}(20,15)\\fmfpen{thin}\\fmfleft{i1}\\fmfright{o1 } \\fmfpoly{empty , tension=0.5}{k1,k2,k3,k4}\\fmf{plain , label=$\\varrho$,label.side = right } { i1,k1}\\fmf{photon , label=$\\sigma$,label.side = right}{k3,o1}\\end{fmfgraph*}}\\right ] \\right>_{c}\\nonumber \\end{aligned}\\ ] ]    following the rules for the contraction of the wiggly and solid lines it s easy to derive the final expression for the mutual information :    @xmath142^{-1}_{m \\varrho}a_{\\varrho i } - [ b+bi]^{-1}_{m \\varrho}b_{\\varrho i}]\\ ] ]    we list some specific cases arising from this generic nonlinearity and the correspondent final expression for the mutual information : + 0.5 cm * case 1 * @xmath143 leading to the case already analyzed:@xmath144 .",
    "the expression for the mutual information is given by eq.([icub ] ) .",
    "+ 0.5 cm * case 2 * @xmath145    @xmath146\\ ] ]    where @xmath147^{-1 } - [ i+bb^{-1}]^{-1}$ ] .",
    "+ 0.5 cm * case 3 *    @xmath148    @xmath149     + 0.5 cm * case 4 * @xmath150    @xmath151     + 0.5 cm * case 5 * @xmath152    @xmath153_{m i } + [ da]_{m i})\\right).\\ ] ]     + 0.5 cm * case 6 * @xmath154    @xmath155",
    "in the present paper we have developed a perturbative approach for the calculation of the mutual information in the case of a generic non - linear channel by means of feynman diagrams .",
    "as far as we know , this is the first attempt to use this techniques in the context of the mutual information .",
    "we show systematically how the consecutive steps to calculate the mutual information can be easily performed introducing proper diagrammatic rules , in analogy to other standard perturbative approaches @xcite .",
    "we investigate more in detail the case of _ local _ non - linear transfer functions , when the output of each unit depends only on its local field .",
    "previous works have shown that this regime provides an optimal information transfer @xcite .",
    "then we apply the same techniques to the more general case of _ non - local _ non - linearities , restricted to cubic powers of @xmath22 , where the output of each unit depends on the total structure of the connectivities .",
    "this regime corresponds to the case where the total output of the network is constrained in such a way that the state of each output unit can be modified by any pair interaction .",
    "further developments of this analysis include the maximization of the mutual information with respect to the coupling matrix @xmath156 in order to find the optimal structure of the connectivities .",
    "this should hopefully provide more interesting results , compared to the linear case , @xcite , and it will be the object of future investigations @xcite",
    ".    0.5 cm * acknowledgments * e.k .",
    "warmly thanks for hospitality and support the abdus salam international center for theoretical physics , trieste , italy , where this work was completed .",
    "v.d.p . thanks a.treves , stefano panzeri , giuseppe mussardo and ines samengo for useful discussions . the work is also supported by the spanish dges grant pb97 - 0076 and partly by contract f608 with the bulgarian scientific foundation .    99 j.h.van herten , j.comp.physiology , * a171*(1992)157 .",
    "a.campa , p.del giudice , n. parga and j .- p.nadal , network * 6*(1995)449 .",
    "a.abrikosov , l.gorkov and i.dzyaloshinskij , _ quantum field theoretical methods in statistical physics .",
    "_ , oxford , pergamon press , 1965 .",
    "p.nadal and n.parga , network , * 4*(3)(1993)295 .",
    "e.korutcheva , j.p.nadal and n.parga , network * 8*(1997)405 .",
    "a.turiel , e.korutcheva and n.parga , j. phys.a : math.gen . * 32*(1999)1875 .",
    "r.linsker , advances in neural information processing systems * 5*(1993)953 .. e.korutcheva and v.del prete , in preparation .",
    "d.amit _ modelling brain function _ , cambridge univ.press , 1989 . j. hertz , a. krogh and r. palmer , _ introduction to the theory of neural computation _",
    ", santa fe institute , lecture notes vol.1 , 1991 .",
    "c.marcus and r. westervelt , phys . rev .",
    "* a40*(1989)501 .",
    "j.p.nadal and n.parga , network * 4*(1994)295 .",
    "r. blahut , _ principles and practice of information theory _ , addison - wesley , cambridge ma , 1988 ."
  ],
  "abstract_text": [
    "<S> we evaluate the mutual information between the input and the output of a two layer network in the case of a noisy and non - linear analogue channel . in the case where the non - linearity is small with respect to the variability in the noise </S>",
    "<S> , we derive an exact expression for the contribution to the mutual information given by the non - linear term in first order of perturbation theory . </S>",
    "<S> finally we show how the calculation can be simplified by means of a diagrammatic expansion . </S>",
    "<S> our results suggest that the use of perturbation theories applied to neural systems might give an insight on the contribution of non - linearities to the information transmission and in general to the neuronal dynamics .    </S>",
    "<S> pacs : 05.20 ; 87.30    keywords : information theory , mutual information , infomax , feynman diagrams    miramare , september 2000 </S>"
  ]
}