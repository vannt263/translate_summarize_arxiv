{
  "article_text": [
    "principal components analysis ( pca ) is a popular technique for dimension reduction that has a wide range of applications involving multivariate data , in both science and engineering ; see , for example , @xcite .",
    "the first principal component ( pc ) of a @xmath1-dimensional random variable @xmath8 is the direction in which the variance of @xmath9 is maximal , or equivalently , the leading eigenvector of its population covariance matrix @xmath10 $ ] where @xmath11 $ ] . in practice",
    ", one typically does not have explicit access to @xmath12 , but rather is given @xmath2 samples from @xmath9 , from which one computes the sample covariance matrix @xmath13 and its leading eigenvectors .    in contemporary applications where variables are plentiful ( large @xmath1 ) but samples are relatively scarce ( small @xmath2 ) , pca suffers from two major limitations : ( 1 ) the principal components are typically a linear combination of all variables , which hinders their interpretation and subsequent use , and ( 2 ) while pca is consistent in the classical setting ( @xmath1 is fixed and @xmath14 ) @xcite , it is generally inconsistent in high - dimensions .",
    "indeed , as shown , for example , in @xcite , when @xmath1 is comparable to , or significantly larger than @xmath2 , the sample covariance matrix @xmath13 may be a poor approximation to the population s covariance matrix @xmath12 , and its leading eigenvectors may be far from the population s principal components .    to address the first drawback",
    ", one can consider a _",
    "pca problem , in which for some appropriate parameter @xmath15 , we search for a direction with at most @xmath15 nonzero coefficients and with maximal variance . formally , the @xmath0-sparse pca problem is defined by @xmath16 we note that other notions of sparsity were considered in the literature , for example , a population covariance matrix that has only a few large eigenvalues , whose corresponding eigenvectors are sparse in @xmath17-norm for @xmath18 @xcite .    while standard ( nonrestricted ) pca can be efficiently solved by computing the eigenvectors of a symmetric matrix , sparse",
    "pca is a difficult combinatorial problem , and in fact solving @xmath19 is np - hard .- clique problem in a @xmath1-vertex graph , and considering @xmath20 where @xmath21 is the graph s adjacency matrix . ]",
    "nevertheless , various computationally efficient approaches were developed to deal with the problem .",
    "these include greedy or nonconvex optimization procedures @xcite , methods based on @xmath22-regularization @xcite , regularized singular - value - decomposition @xcite , an augmented lagrangian method @xcite , a simple diagonal thresholding ( dt ) algorithm @xcite , and sophisticated semidefinite programming ( sdp ) methods @xcite . the latter approach , and in particular its ability to recover an @xmath0-sparse pc , are the focus of the current paper .    _ sdp - based algorithm_. we study the following concrete sdp relaxation of ( [ eq : lp ] ) , which was suggested by daspremont et al .",
    "@xcite : @xmath23 where for two matrices @xmath24 we denote by @xmath25 their frobenius inner - product , @xmath26 is the `` absolute - sum norm , '' and @xmath27 is the cone of symmetric positive semidefinite ( psd ) matrices . as sdp ( [ eq : sdp ] ) returns a symmetric matrix rather than a vector , daspremont et al .",
    "@xcite suggested to output its leading eigenvector as an estimate for the first sparse - pc .",
    "this algorithm is summarized as follows .",
    "[ alg : sdp ]    let @xmath28 + compute a solution @xmath29 of sdp ( [ eq : sdp ] ) + let @xmath30 be the leading ( unit - length ) eigenvector of @xmath31    _ single - spike input model_. we examine algorithm [ alg : sdp ] under the single - spike multivariate gaussian model introduced in @xcite , where the samples @xmath32 are of the form @xmath33 here , the parameter @xmath34 is the _ signal strength _ , @xmath35 is the _ planted spike _ assumed to be a @xmath15-sparse unit - length vector , @xmath36 is a noise vector whose entries are all i.i.d . @xmath37 and @xmath38 .",
    "furthermore , all the @xmath39 s and @xmath40 s are independent of each other .",
    "the corresponding population covariance matrix is @xmath41 and its largest eigenvalue is @xmath42 , with associated eigenvector @xmath43 . we consider throughout the scenario @xmath44 , and mention additional assumptions ( e.g. , @xmath45 is fixed or @xmath46 tends to @xmath47 ) as needed .",
    "_ information versus computational limits_. amini and wainwright @xcite studied this single - spike input model , under the additional assumption that the nonzero entries of @xmath43 are exactly of the form @xmath48 , which represents the hardest type of @xmath15-sparse vectors .",
    "they proved that up to sparsity level @xmath49 where @xmath50 , algorithm [ alg : sdp ] outputs a vector @xmath30 whose support coincides with that of @xmath43 ; , which they conjecture can be removed .",
    "] they further showed , using a simple second moment calculation , that up to the same order of sparsity level @xmath51 , the diagonal thresholding algorithm @xcite also recovers the support of @xmath43 and fails whenever @xmath52 .",
    "in contrast , amini and wainwright @xcite showed that for @xmath53 , if @xmath54 for some absolute positive constant @xmath55 and all sufficiently large @xmath2 .",
    "similarly , @xmath56 means @xmath57 . ]",
    "_ every _ method [ including exhaustive search over all @xmath58 subsets of size @xmath15 ] will err with probability at least @xmath60 .",
    "in fact , even the simpler task of _ detecting _ the presence of a spike is not possible for this range of parameters , as recently proved in @xcite .",
    "for further results including minimax rates , under more general sparsity models , see @xcite .",
    "the following question thus remained open : does algorithm [ alg : sdp ] , which is more sophisticated and computationally heavy , outperform the simple dt algorithm ?",
    "specifically , are there intermediate sparsity levels @xmath61 ( such that @xmath52 , and ignoring multiplicative constants ) for which @xmath30 still approximates @xmath43 in some useful sense ?",
    "while not answering this question , amini and wainwright proved that for sparsity level up to @xmath62 , _ if _ the solution to ( [ eq : sdp ] ) remains rank one , _ then _ the support of @xmath30 coincides with that of @xmath43 .",
    "they then suggested that for this @xmath0-sparse pca problem , the information and computational limits coincide , both are equal @xmath63 , and algorithm [ alg : sdp ] is optimal . in their words , `` under the rank - one condition , the sdp is in fact statistically optimal , that is , it requires only the necessary number of samples ( up to a constant factor ) to succeed '' @xcite , page 2880 .    our results , formally stated below ,",
    "prove that unfortunately this is _ not _ the case  in fact , when @xmath15 slightly exceeds @xmath64 , namely @xmath65 , the solution @xmath31 of sdp ( [ eq : sdp ] ) _ does not _ have rank one and is not close to @xmath66 .",
    "furthermore , if @xmath31 has a low rank , then the output @xmath30 of algorithm [ alg : sdp ] is at best weakly correlated with @xmath43 . in section  [ sec : experimental ] we present empirical simulation results showing that indeed algorithm [ alg : sdp ] and dt perform similarly .    given that the sdp algorithm does not seem to significantly improve over dt under the single spike model , the following question arises : is there a simple algorithm which outperforms both ?",
    "motivated by the work of bickel and levina @xcite , we suggest a light - weight greedy algorithm called covariance thresholding ( ct ) , which can be seen as a generalization of diagonal thresholding .",
    "we provide experimental results suggesting that ct is consistent for @xmath67 ; see section  [ sec : experimental ] for details .",
    "recently , following our work , deshpande and montanari @xcite rigorously proved that a variant of our ct algorithm indeed asymptotically recovers the support of @xmath43 up to these sparsity levels .",
    "finally , we note that despite our results , there are other settings , such as estimating sparse eigenvectors of correlation matrices , where sdp - based methods are provably better than diagonal thresholding , possibly even achieving the relevant minimax rates @xcite .",
    "we consider the single - spike model defined in ( [ eq : defofdist ] ) in high - dimensional settings whereby @xmath44 and @xmath68 for positive constants @xmath69 .",
    "we further assume that the @xmath15-sparse vector @xmath43 has @xmath15 nonzero entries of the form @xmath70 . in what follows",
    ", we denote by @xmath71 the set @xmath72 . in the analysis , we assume without loss of generality that the nonzero coordinates of the spike @xmath43 are exactly its first @xmath15 coordinates , that is , @xmath73 .    for the case",
    "@xmath74 , that is , @xmath75 , we focus on weak signal strengths @xmath76 , whereas when @xmath77 , the signal strength may grow to infinity provided it still satisfies @xmath78 ; see assumption ( b ) below .",
    "the reason is that when @xmath74 and @xmath79 , as the next theorem shows , recovering the support of @xmath43 is computationally easy , almost up to the information limit .",
    "as before , we let @xmath80 .",
    "[ thm : largesignal ] fix @xmath81 and @xmath82 , and",
    "let @xmath44 such that @xmath75 and @xmath83 .",
    "let @xmath84 be the leading eigenvector of @xmath85 , and denote by @xmath86 its @xmath15 largest entries in absolute value .",
    "then @xmath87 with probability tending to one as @xmath88 .",
    "our next results , stated in the three theorems below , refer to the following assumptions :    fix positive @xmath69 , and let @xmath44 such that @xmath89 .",
    "the signal strength , either fixed or growing with @xmath90 , satisfies @xmath91 .    the sparsity level @xmath15 satisfies @xmath92 , and @xmath93 .",
    "we next analyze the quality of the output @xmath30 of algorithm [ alg : sdp ] , as measured by its cosine - similarity to the planted spike @xmath43 .",
    "[ thm : main1 ] assume",
    ". then there exists @xmath94 , such that if @xmath31 is a solution of sdp ( [ eq : sdp ] ) , and @xmath95 is its largest eigenvalue , then with probability tending to one as @xmath44 , the output @xmath30 of algorithm  [ alg : sdp ] satisfies @xmath96    the following corollary of theorem  [ thm : main1 ] shows that the sdp solution is far from @xmath66 . for a matrix @xmath21",
    "we denote its spectral norm by @xmath97 .",
    "[ cor : noclosesolutions ] assume , and further that @xmath98 .",
    "let @xmath31 be a solution of sdp ( [ eq : sdp ] ) .",
    "then @xmath99 with probability tending to one as @xmath44",
    ".    assume for contradiction that the matrix @xmath100 has a small spectral norm @xmath101 .",
    "using weyl s inequality @xcite , @xmath102 .",
    "since @xmath103 , the largest eigenvalue of @xmath31 is thus lower bounded by @xmath104 .",
    "let @xmath30 be a ( unit - length ) eigenvector of @xmath31 corresponding to this largest eigenvalue @xmath105 .",
    "recalling the variational definition of the largest eigenvector of a matrix , we obtain @xmath106 using our assumption , @xmath107 . by theorem  [ thm : main1 ] @xmath108 plugging @xmath109 , @xmath110 and @xmath111 into equation ( [ cor : eq2 ] ) gives that its right - hand side is at most @xmath112 .",
    "since by theorem  [ thm : main1 ] , @xmath113 as @xmath114 , ( [ cor : eq2 ] ) is strictly smaller than @xmath115 for a sufficiently large @xmath2 . combining ( [ cor : eq1 ] ) and ( [ cor : eq2 ] ) we arrive at the following contradictory set of inequalities : @xmath116    note that the constant 23 appearing in equation ( [ eq : dot_product ] ) , and consequently the factor @xmath117 in the corollary , are not necessarily optimal . both may be further reduced at the expense of more involved proofs .",
    "further note that if @xmath118 is bounded away from zero as @xmath119 , then for @xmath77 , equation ( [ eq : dot_product ] ) implies that @xmath120 .",
    "namely , in this case the output of algorithm [ alg : sdp ] is nearly orthogonal to @xmath121 .",
    "such an empirical behavior of @xmath95 was observed in our experimental results ; see figure  [ fig : alg1 ] .",
    "we prove theorem  [ thm : main1 ] using the next result , which itself may be of interest as it bounds the value of sdp ( [ eq : sdp ] ) .",
    "recall that the sdp solution is highly nonlinear in its inputs , and therefore no closed - form explicit expression is known for the solution @xmath31 or the sdp value @xmath122 .",
    "[ thm : main2 ] assume",
    ". then there exists @xmath123 such that with probability tending to one as @xmath44 , every solution @xmath31 of sdp ( [ eq : sdp ] ) satisfies @xmath124    for @xmath125 , the ratio between the upper and lower bounds in ( [ eq : bounds_sdp ] ) is at most @xmath126 and tends to one as @xmath127 .    for the important regime @xmath74 , we can use theorem  [ thm : main2 ] to sharpen our conclusion from theorem  [ thm : main1 ] and show that with probability tending to one , not only @xmath128 , but @xmath31 is not even rank one .",
    "we arrive at this conclusion by combining theorem  [ thm : main2 ] with the next theorem .",
    "[ thm : main3 ] assume , and in addition @xmath129 , @xmath130 and @xmath131 . then with probability tending to one as @xmath44",
    ", every rank - one matrix @xmath132 that is feasible for sdp ( [ eq : sdp ] ) satisfies @xmath133    to see that the solution @xmath31 of sdp ( [ eq : sdp ] ) is indeed not rank one , we compare the upper bound in ( [ eq : bound_rank_one ] ) with the ( larger ) lower bound in ( [ eq : bounds_sdp ] ) , namely , @xmath134 .",
    "was proved in @xcite , proposition  6.1 , in a setting similar to theorem  [ thm : main2 ] , but we can not use it to derive @xmath135 because @xmath136 could be larger than @xmath42 . ]    in conclusion , theorems [ thm : main1][thm : main3 ] suggest that the standard sdp - based approach ( provided by algorithm [ alg : sdp ] ) is not significantly more effective than the simpler , light - weight diagonal thresholding . in particular , for weak signal strengths , algorithm [ alg : sdp ]",
    "does not yield a rank - one solution and hence can not provably solve sparse pca up to the information limit , as previously suspected .",
    "our conclusion is in line with a recent , independently obtained result of berthet and rigollet @xcite , which asserts that the existence of a polynomial - time computable statistic for reliably _ detecting _ the presence of a single spike of @xmath0-sparsity @xmath15 for @xmath137 , implies a polynomial - time algorithm for reliably detecting the presence of a planted clique of size @xmath138 , for @xmath139 , in an otherwise random graph @xmath140 .",
    "the latter problem , known as the _ hidden clique problem _ in the computer science literature , is believed to be a computationally hard task , and polynomial - time algorithms known to date can only find a planted clique whose size @xmath138 is at least of order @xmath141 @xcite .",
    "furthermore , wang et al .",
    "@xcite showed that under the hidden clique hardness assumption , in certain sparsity regimes no randomized polynomial time algorithms can estimate the leading spiked eigenvector with optimal rate .",
    "our result differs from @xcite in several respects .",
    "first , our results are unconditional ; that is , theorems [ thm : main1][thm : main3 ] are not based on any computational hardness assumptions , and thus remain valid even if future developments will yield a polynomial - time algorithm for finding a hidden clique of size @xmath142 .",
    "second , our focus is on estimation and not on detection , which in general are different problems .",
    "-sparsity ( assuming @xmath143 and omitting constant factors ) . ]",
    "we summarize in figure  [ fig : ranges ] the picture emerging from the results of amini and wainwright @xcite , berthet and rigollet @xcite , deshpande and montanari @xcite and our work . based on these results and the fact that even a sophisticated sdp - based algorithm fails to estimate @xmath43 for @xmath144",
    ", we conclude with the following conjecture .    in the single - spike model with @xmath145 , fixed signal strength @xmath146 and @xmath147-sparsity @xmath148 for fixed @xmath149 , no polynomial - time algorithm can recover the support of @xmath43 with probability tending to one as @xmath44 .    _",
    "organization_. in section  [ sec : covarthresh ] we describe our covariance thresholding algorithm , followed by experimental results in section  [ sec : experimental ] . in section  [ sec : proofthmlargebeta ] we give a short proof of theorem  [ thm : largesignal ] . in section  [ sec : prelims ]",
    "we assert preliminary facts that will be later used in the proofs of theorem  [ thm : main1 ] in section  [ sec : profofthm1 ] , theorem  [ thm : main2 ] in section  [ sec : profofthm2 ] and theorem  [ thm : main3 ] in section  [ sec : profofthm3 ] .",
    "motivated by the work of bickel and levina @xcite , we suggest algorithm [ alg2 ] for the @xmath0-sparse pca problem , which we call _ covariance thresholding _ , or ct for short .",
    "compute @xmath150 + compute @xmath151 by thresholding the entries of @xmath152 , namely , @xmath153 + let @xmath154 be the leading eigenvector of @xmath155 + let @xmath156 $ ] contain the @xmath15 coordinates of largest absolute value in @xmath157    we present some intuition as to why we expect this algorithm to work . from the definition of @xmath13 in ( [ eq : defofdist ] ) , it follows easily that the off - diagonal noise entries have expected value zero and standard deviation @xmath158 , while for signal entries the expected value is @xmath159 with s.d .",
    "@xmath160 . consider , for example , a signal strength @xmath161 , sparsity @xmath162 ( where 10 is rather arbitrary ) , and choose @xmath163 .",
    "then for a noise entry to survive thresholding , it must deviate from its mean by @xmath164 s.d . and an analogous deviation for a signal entry to be zeroed out .",
    "both events happen with small constant probability ; hence most noise entries are zeroed and a constant fraction of signal entries survive .",
    "in fact , when @xmath165 one can easily show that ct , similar to dt , recovers the support of @xmath43 .",
    "recently , deshpande and montanari @xcite proved that a variant of our algorithm is consistent up to sparsity levels @xmath7 .",
    "their proof method is not directly applicable to our algorithm , but simulation results , detailed below , suggest that our algorithm is also able to recover the correct support up to @xmath7 .",
    "hence , covariance thresholding is thus far the only algorithm , with polynomial run - time , that can _ provably _ recover the support up to sparsity levels @xmath166 .",
    "we compare a few algorithms under the following setup . we generate",
    "@xmath167 i.i.d .",
    "samples @xmath32 from the single - spike model ( [ eq : defofdist ] ) with a spike @xmath43 of the form @xmath168 .",
    "we assume the sparsity level @xmath15 is a priori known , and say that an execution of an algorithm is _ successful _ if it returns the support of @xmath43 exactly , that is , if the output is the set @xmath169 .",
    "the _ success rate _ of an algorithm in @xmath170 independent executions is the number of times it is successful divided by @xmath170 . in each experiment",
    "we fix @xmath171 and for various values of @xmath15 we measure the success rate averaged over @xmath172 independent executions .",
    "figure  [ fig : ctvsdt ] compares the performance of our ct algorithm to dt .",
    "it is evident from this figure that in our setting , ct outperforms dt .",
    "figure  [ fig : ctscaled ] shows the success rate of ct as a function of the sparsity level @xmath15 scaled by @xmath141 , plotted for five different values of @xmath2 .",
    "these results reinforce our prediction that ct works up to sparsity levels proportional to @xmath141 ( perhaps even slightly more ) .    .",
    "@xmath173-axis is the success rate averaged over 500 runs , with signal strength @xmath174 , and ct parameterized with threshold @xmath175 . ]",
    "( depicted for different @xmath15 and @xmath2 ) .",
    "@xmath173-axis is the success rate averaged over 500 runs , with signal strength @xmath174 , and ct parameterized with threshold @xmath175 . ]",
    "we run algorithm [ alg : sdp ] with parameters @xmath176 and @xmath177 , averaging over @xmath178 runs . we solve the sdp in line 2 of algorithm [ alg : sdp ] using sedumi 1.2.1 @xcite .",
    "figure  [ fig : alg1 ] plots the dot - product ( in absolute value ) between @xmath30 , the output of algorithm [ alg : sdp ] and the planted spike @xmath43 .",
    "as expected , the dot - product gets smaller as the sparsity @xmath15 increases . for comparison , the figure plots also the recovery rate of dt , which also deteriorates as @xmath15 increases .",
    "the figure also shows the largest eigenvalue of the sdp solution @xmath31 ; we remark that this value is rather close to one , even when the output of algorithm  [ alg : sdp ] is far from @xmath43 , and is certainly bounded away from @xmath179 , as assumed in the discussion following theorem  [ thm : main1 ] .    ) for @xmath180 , averaged over 100 runs .",
    "the blue dots represent the success rate of dt .",
    "the filled circles are the average of the dot product @xmath181 of the sdp leading eigenvector , whereas the triangles are the largest eigenvalue of the sdp solution , @xmath118 . ]",
    "let @xmath84 be the leading eigenvector of @xmath85 , and write it as a linear combination of the spike @xmath43 and some unit vector @xmath182 , namely , @xmath183 .",
    "we may assume @xmath184 $ ] by negating @xmath84 , if necessary . according to @xcite , theorem  4 , for our setting of @xmath185 , @xmath186    furthermore , according to debashis ( @xcite , theorem  6 ) , the vector @xmath187 is distributed uniformly on the unit sphere of dimension @xmath188 of vectors in @xmath189 orthogonal to @xmath121 .",
    "using this fact we prove below the following property of the entries of  @xmath190 .",
    "[ lem : sphere ] with probability tending to one , all entries of @xmath190 are bounded in absolute value by @xmath191 for a suitable constant @xmath192 .",
    "lemma  [ lem : sphere ] implies that with probability tending to one , for all @xmath193 $ ] we have @xmath194 , and for all @xmath195 $ ] we have @xmath196 . to correctly identify the support of @xmath43",
    ", it suffices to require a gap between signal and nonsignal coordinates , namely , @xmath197 solving for @xmath15 and using ( [ eq : largebeta ] ) , this inequality holds whenever @xmath198 for suitable @xmath199 , which in turn holds with probability tending to one , because our assumption @xmath200 implies @xmath201 .",
    "this completes the proof of theorem  [ thm : largesignal ] .",
    "proof of lemma  [ lem : sphere ] let @xmath202 be an orthonormal basis for the subspace of vectors in @xmath203 orthogonal to @xmath43 . since @xmath204 is uniformly distributed in this subspace , it can be represented as @xmath205 , where @xmath206 is a vector of i.i.d .",
    "standard gaussians .",
    "fix a coordinate @xmath207 , and write its corresponding standard basis vector as @xmath208 for a unit vector @xmath209 and @xmath210 $ ] . then @xmath211 , which implies @xmath212 are both unit vectors in @xmath213 , our task reduces to estimating the inner - product between the uniformly distributed _ random",
    "_ vector @xmath190 on the @xmath214-dimensional unit sphere and a _ fixed",
    "_ vector @xmath215 on the sphere .",
    "since @xmath190 is random , we may replace @xmath215 with another fixed vector , say @xmath216 .",
    "namely , @xmath217 has the same distribution as @xmath218 .",
    "standard tail bounds for the gaussian and @xmath219 distributions ( note that @xmath220 ) imply that @xmath221 with probability at least @xmath222 , for a suitable constant @xmath192 .",
    "the lemma follows by a union bound over all @xmath1 coordinates of @xmath190 .",
    "in this section we record a few standard results that will be used later in the proofs .",
    "the first is a large deviation result for a chi - square random variable .",
    "[ lem : xisquare ] let @xmath223 . for all @xmath224 , @xmath225 \\leq e^{-x } \\quad\\mbox{and}\\quad \\operatorname{pr}[x \\leq n-2\\sqrt{nx } ] \\leq e^{-x}.\\ ] ]    the second lemma records a well - known argument about the inner - product of two high - dimensional gaussians .    [ cl : clt ] let @xmath226 be standard i.i.d .",
    "gaussian random variables .",
    "then @xmath227 is distributed like the product of two independent random variables @xmath228 , where @xmath229 , @xmath230 and @xmath231 is a standard gaussian .    for every fixed realization of @xmath9 , we have @xmath232 and by the independence of the @xmath233 s , @xmath234 the lemma follows by observing that @xmath235 .",
    "the next proposition establishes an upper bound on @xmath236 , the maximal eigenvalue of the sample covariance matrix @xmath13 , in the single - spike model , in two regimes : ( i ) @xmath89 for positive @xmath69 and ( ii ) @xmath237 .",
    "the spectrum of the covariance matrix has been studied extensively in the literature . specifically , both baik and silverstein @xcite , theorem  1.2 and johnstone @xcite , theorem  1.1 , provide the limiting behavior of @xmath238 for @xmath239 ( i.e. , @xmath129 ) .",
    "the regime of a fixed @xmath1 with @xmath14 which implies @xmath240 was analyzed in @xcite , chapter  3 , for example . since we could not locate a reference for the case @xmath89 and @xmath125 , or for @xmath237 and @xmath1 not necessarily fixed , we provide the following proposition .",
    "the proof uses standard arguments and is given in section  [ sec : prelimproofs ] .",
    "[ prop : largesteig ] let @xmath13 be a @xmath241 sample covariance matrix of @xmath2 samples in the @xmath15-sparse single - spike model with signal strength @xmath242 , arbitrary @xmath15 and either : @xmath237 or @xmath89 for positive constants @xmath69 .",
    "then there exists an @xmath243 such that with probability tending to one as @xmath244 , @xmath245    [ cor : trsighatzz ] let @xmath13 be a @xmath246 sample covariance matrix of @xmath2 samples and a @xmath15-sparse spike @xmath43 with signal strength @xmath242 .",
    "further assume that @xmath247 .",
    "then there exists an @xmath243 such that with probability tending to one as @xmath244 , for every rank - one trace - one @xmath246 matrix @xmath248 with @xmath249 , @xmath250    consider @xmath251 where @xmath252 ranges over all matrices @xmath252 as stated above . for each such @xmath248",
    ", we have @xmath253 .",
    "let @xmath254 be the projection of @xmath255 on the coordinates of @xmath256 , then @xmath257 .",
    "similarly , let @xmath258 be the @xmath259 submatrix of @xmath260 corresponding to @xmath256 , namely , restricting it to the first @xmath15 rows and first @xmath15 columns .",
    "observe that we can write @xmath261 hence @xmath262 .",
    "now the desired upper bound on @xmath263 follows using the fact @xmath247 from proposition  [ prop : largesteig ] , that is , plugging @xmath264 into ( [ eq : proplargesteig ] ) .",
    "our next proposition estimates @xmath265 and @xmath266 for the case @xmath267 ( no signal ) .",
    "these estimates were derived in @xcite , proposition  1 , for example , but again only for @xmath268 . for lack of reference",
    "we reprove it for @xmath269 in section  [ sec : prelimproofs ] .",
    "[ fact : ledoit ] let @xmath13 be a @xmath270 sample covariance matrix of @xmath2 multivariate gaussian observations whose population covariance matrix is the identity",
    ". assume that @xmath271 as @xmath272 .",
    "then there exists an @xmath273 such that with probability tending to one as @xmath14 , @xmath274",
    "let @xmath31 be a solution to sdp  ( [ eq : sdp ] ) , with eigenvalues @xmath275 and a corresponding orthonormal set of eigenvectors @xmath276 .",
    "we can then write @xmath277 , and by linearity of the frobenius inner - product , @xmath278 . using the simple observations @xmath279 ( by the variational characterization of eigenvalues ) and @xmath280",
    ", we get @xmath281    let us first provide a high - level description of the proof idea .",
    "we can bound @xmath122 from below ( using theorem  [ thm : main2 ] , which we prove in section  [ sec : profofthm2 ] , and as mentioned earlier is used here ) and @xmath282 from above ( using proposition  [ prop : largesteig ] ) both by roughly @xmath283 .",
    "now suppose @xmath95 is not too small ; then on the right - hand side of ( [ eq : peexopt ] ) , a large contribution must come from the first term @xmath284 .",
    "but the quadratic form @xmath285 has small value in the direction @xmath286 ( using corollary  [ cor : trsighatzz ] ) , and thus @xmath30 and @xmath43 can not be too close to each other .",
    "we now proceed to the detailed proof , starting with a lower bound on @xmath284 .",
    "assume henceforth that the high - probability event asserted by theorem  [ thm : main2 ] indeed occurs ; namely , inequality ( [ eq : bounds_sdp ] ) holds .",
    "similarly corollary  [ cor : trsighatzz ] implies that inequality ( [ eq : proplargesteig ] ) holds .",
    "plugging these two bounds into ( [ eq : peexopt ] ) and using @xmath287 , we get @xmath288 observe that @xmath289 for suitable @xmath290 and sufficiently large @xmath90 .",
    "in addition , assumption ( b ) yields that @xmath291 . for suitable @xmath292",
    ", we get @xmath293    next , we analyze the quadratic form @xmath294 in terms of @xmath295 $ ] .",
    "write @xmath296 , where @xmath297 is a unit vector orthogonal to @xmath43 , and recall that our goal is to upper bound @xmath298 . using cauchy ",
    "schwarz and the triangle inequality , @xmath299 \\\\[-8pt ] \\nonumber & \\le&\\vert\\gamma\\vert\\cdot\\|{\\hat{\\sigma}}\\mathbf{z}\\|+\\sqrt { 1- \\gamma^2}\\|{\\hat{\\sigma } } \\mathbf{s}\\|.\\end{aligned}\\ ] ] since @xmath13 is psd , it can be written as @xmath300 for some matrix @xmath301 whose spectral norm is @xmath302 .",
    "assume henceforth that the high - probability event asserted by corollary  [ cor : trsighatzz ] indeed occurs , and we have @xmath303 for suitable @xmath304 . using proposition  [ prop : largesteig ] similarly yields @xmath305 for suitable @xmath306 .",
    "together , for suitable @xmath307 , @xmath308 and similarly @xmath309 plugging these into ( [ eq : dotprodupper1 ] ) and using @xmath310 and @xmath311 , we have @xmath312    now combining this upper bound ( [ eq : dotprodupper2 ] ) with our lower bound [ eq : dotprodlower ] ( after dividing by @xmath105 ) , gives @xmath313 and by further manipulation , @xmath314 for sufficiently large @xmath90 , this yields the bound on @xmath315 asserted in ( [ eq : dot_product ] ) , and completes the proof of theorem  [ thm : main1 ] .",
    "we start with the upper bound on @xmath122 . the idea is to drop the constraint @xmath316 from sdp ( [ eq : sdp ] ) , and show that the value of the resulting sdp , which can only be bigger , is actually @xmath282 , and is thus bounded by proposition  [ prop : largesteig ] .",
    "formally , let @xmath31 be a solution to sdp ( [ eq : sdp ] ) , and let us argue that ( with probability  @xmath317 ) @xmath318 indeed , the inequality holds because we have just relaxed sdp ( [ eq : sdp ] ) .",
    "the equality holds by the following standard argument . writing @xmath319 , where @xmath320 are the eigenvectors of @xmath252 and @xmath321 is a corresponding orthonormal eigenbasis , we have @xmath322 and equality is achieved when maximizing over all relevant @xmath252 , by taking @xmath323 to be a rank - one matrix where @xmath324 is a leading eigenvector of @xmath13 .    to conclude the upper bound asserted in the theorem , we combine the above with proposition  [ prop : largesteig ] , and get that for a suitable @xmath94 with probability tending to one as @xmath244 , @xmath325    we turn to proving the lower bound on @xmath326 .",
    "the idea is to consider a specific @xmath327 which is feasible ( but not necessarily optimal ) for sdp ( [ eq : sdp ] ) , and compute its objective value @xmath328 .",
    "our @xmath327 is based on taking the nonsignal part of @xmath13 [ which is a @xmath329 submatrix ] , padded with zeros elsewhere , and `` forcing '' it to satisfy the constraints of sdp ( [ eq : sdp ] ) by scaling it to be trace - one .",
    "formally , let @xmath330 , where the matrix @xmath331 is given by @xmath332 we prove below that with probability tending to one , the following inequalities hold for a suitable @xmath333 : @xmath334 combining this with @xmath335 and @xmath336 , which hold by construction , will prove that with probability tending to one , @xmath327 is feasible and has a high - objective value .    before proceeding to prove ( [ eq : normoneofx ] ) and ( [ eq : trsighatx ] ) , we observe that the nonzeroed part of @xmath337 satisfies the conditions of proposition  [ fact : ledoit ] , as it is a @xmath338 sample covariance matrix of @xmath2 multivariate gaussian observations whose population covariance matrix is the identity , and furthermore @xmath339 .",
    "the concrete bounds that we get hold for a suitable @xmath340 and with probability tending to one as @xmath244 , and roughly say that @xmath341 and @xmath342 .",
    "let us now prove inequality ( [ eq : trsighatx ] ) .",
    "first , using cauchy ",
    "schwarz , @xmath343 by the above bounds from proposition  [ fact : ledoit ] , with probability tending to one , @xmath344 which together imply that @xmath345 .",
    "we next prove inequality ( [ eq : normoneofx ] ) .",
    "first , we expand @xmath346 by the above bounds from proposition  [ fact : ledoit ] , with probability tending to one , @xmath347 for a suitable @xmath333 , where we used here that @xmath93 by assumption  ( c ) .",
    "altogether , we conclude that @xmath348 .",
    "having proved inequalities ( [ eq : normoneofx ] ) and ( [ eq : trsighatx ] ) , we conclude that with probability tending to one , @xmath327 is feasible and has a high objective value , which establishes a lower bound on the optimal sdp value @xmath349 , and completes the proof of theorem  [ thm : main2 ] .",
    "let @xmath350 be the set of all vectors @xmath351 whose corresponding rank - one matrix @xmath248 is feasible for sdp ( [ eq : sdp ] ) , formally , @xmath352 we need to prove that with probability tending to one as @xmath244 , every @xmath248 such that @xmath353 satisfies @xmath354 .",
    "at a high level , @xmath355 is continuous , and thus a standard approach is to discretize @xmath350 with an @xmath356-net , analyze every single point in @xmath350 separately and apply a union bound argument .",
    "the size of an @xmath356-net for the unit @xmath357-ball in @xmath1 dimensions is proportional to @xmath358 . on the other hand ,",
    "our upper bound on the probability that a fixed @xmath359 violates @xmath360 is larger than @xmath361 ; see lemma  [ lem : bounonquotient ]",
    ". therefore , a naive discretization of @xmath350 fails , and we need to reduce the size of the net by using the additional constraint @xmath362 . to this end , we approximate @xmath350 by a set @xmath363 , whose definition uses an @xmath0-constraint ; the idea is that an @xmath0-bound is technically more convenient than @xmath364 .",
    "we apply an @xmath356-net argument to @xmath363 , which indirectly yields a bound for all of @xmath350 .",
    "specifically , we define @xmath365 to formalize the notion of one set approximating another one , we define the _ @xmath366-neighborhood _ of a set @xmath367 to be @xmath368 .",
    "[ lem : epsnet ] the sets @xmath369 defined above satisfy @xmath370 .",
    "fix @xmath353 , and let @xmath371\\dvtx\\vert\\mathbf { y}_i\\vert\\geq 1/(40\\sqrt { p})\\}$ ] . since @xmath372 ,",
    "the size of @xmath373 is at most @xmath374 .",
    "now define @xmath375 as follows : @xmath376 if @xmath377 , and @xmath378 otherwise . by construction , @xmath379 and @xmath380 .",
    "we proceed to the discretization of @xmath363 , which uses the following notation . for @xmath381 and a subset of the coordinates @xmath382 $ ] , let @xmath383 denote the vectors in @xmath301 whose support is contained in @xmath373 .",
    "recall that an _ @xmath356-net _ of @xmath381 is a subset @xmath384 satisfying @xmath385 and that for all @xmath386 , @xmath387 . setting @xmath388\\dvtx |i| = 40\\sqrt{pk}\\}$ ] , clearly @xmath389 .",
    "let @xmath390 be an @xmath356-net of @xmath391 with @xmath392 , and let @xmath393 be the union of all these nets , that is , @xmath394 then @xmath395 . now using lemma  [ lem : epsnet ] and the triangle inequality , we get that @xmath396 .",
    "the key to completing the proof is to show that for all sufficiently large @xmath2 , @xmath397 \\ge1-e^{-n/10}.\\ ] ]    before proving this inequality , let us rely on it to complete the proof of theorem  [ thm : main3 ] .",
    "assume the high - probability event in ( [ eq : maxpoverk ] ) indeed occurs , and similarly for proposition  [ prop : largesteig ] , hence @xmath398 .",
    "now because @xmath399 , for every @xmath353 there exists @xmath400 such that @xmath401 is of length @xmath402 , and therefore for @xmath248 , @xmath403 the assumption we made using ( [ eq : maxpoverk ] ) implies that @xmath404 . to bound the two summands ,",
    "observe that for all @xmath405 we have @xmath406 . plugging all these into ( [ eq : sdpvalueofy ] ) , we get @xmath407 recall that @xmath408 and that for sufficiently large @xmath90 we have @xmath409 .",
    "hence by straightforward manipulations , we conclude that as @xmath44 , with probability tending to one @xmath354 , which proves theorem  [ thm : main3 ] .    it remains to prove ( [ eq : maxpoverk ] ) , which we do via a union bound argument , using the two lemmas below . the first lemma estimates the probability that an arbitrary fixed @xmath410 violates the inequality @xmath411 , and the second one bounds the size of the @xmath356-net @xmath393 .",
    "[ lem : bounonquotient ] under the conditions of theorem  [ thm : main3 ] , there exists an integer @xmath412 , such that for every @xmath413 and every @xmath255 of length at most @xmath317 ( in particular , every @xmath414 ) , @xmath415 \\leq e^{-n/9}.\\ ] ]    fix @xmath416 with @xmath417 , and expand @xmath418 recall from ( [ eq : defofdist ] ) that @xmath419 , where @xmath420 is a vector of independent standard gaussian random variables , and @xmath39 is also a standard gaussian .",
    "therefore , @xmath421 the first term @xmath422 has distribution @xmath423 .",
    "since @xmath39 is independent of @xmath420 , the distribution of @xmath424 is just @xmath425 .",
    "furthermore , since @xmath351 is fixed and the @xmath420 s and @xmath39 s are all independent , the random variables @xmath424 for @xmath426 are i.i.d . ,",
    "and thus @xmath427 lemma  [ lem : xisquare ] with @xmath428 implies that @xmath429 \\le e^{-n/9}$ ] .",
    "we conclude that with probability at least @xmath430 , @xmath431 where the second inequality uses the cauchy  schwarz inequality .",
    "[ lem : bounonk ] the @xmath356-net @xmath393 has size @xmath432 .    by the definition of @xmath393 and the fact that @xmath433 is the same for all @xmath373 , we can fix arbitrary @xmath434 and write @xmath435 we thus need to bound @xmath433 . by definition , @xmath390",
    "is contained in an axis - aligned subspace of @xmath203 of dimension @xmath436 , and we can use the following standard volume argument . ignoring henceforth all coordinates outside @xmath373 ,",
    "let @xmath437 be a closed ball ( in @xmath438 ) of radius @xmath439 centered at @xmath9 . since @xmath390 is an @xmath356-net ( of @xmath391 ) , for every two distinct points in it , @xmath440 , the corresponding balls @xmath441 and @xmath442 are disjoint ( as otherwise @xmath443 ) .",
    "in addition , the union of these balls @xmath444 over all @xmath445 is contained in @xmath446 ( because all @xmath447 have length at most 1 ) .",
    "recalling that the euclidean volume of a ball of radius @xmath439 in dimension @xmath448 grows with @xmath366 proportionally to @xmath449 , and plugging in @xmath450 , we obtain @xmath451 plugging into ( [ eq : boundonk ] ) , we get @xmath452 .",
    "finally , observe that ( [ eq : maxpoverk ] ) indeed follows from lemmas [ lem : bounonquotient ] and [ lem : bounonk ] by a union bound , @xmath453 \\leq p^{20\\sqrt{pk}}\\cdot e^{-n/9 } \\leq e^{-n/10},\\ ] ] where the last inequality follows from the assumption in theorem  [ thm : main3 ] that @xmath454 and that @xmath75 .",
    "this completes the proof of ( [ eq : maxpoverk ] ) and of theorem  [ thm : main3 ] .",
    "proof of proposition  [ prop : largesteig ] let us rotate @xmath203 so that the spike @xmath43 becomes the first standard basis vector @xmath455 .",
    "obviously , @xmath282 would not change at all , and since the normal distribution is rotation invariant , the noise would still be normally distributed . in effect , we may assume henceforth that @xmath456 .",
    "recalling from ( [ eq : defofdist ] ) that the samples are given by @xmath457 , we can write @xmath150 as @xmath458 where @xmath459 is a @xmath460 matrix whose first row is @xmath461 and the remaining rows are zero ( recall @xmath456 ) , and @xmath462 is an @xmath460 matrix whose @xmath463th column is @xmath420 .",
    "let @xmath464 be the spectral norm of a matrix @xmath21 .",
    "using also @xmath465 and the triangle inequality , @xmath466    the matrix @xmath467 follows a wishart distribution ( note that the roles of @xmath1 and @xmath2 are reversed )",
    ". therefore by @xcite , theorem  2 , which applies to the regime @xmath237 and @xmath468 , and by @xcite , theorem  1.1 , which applies to @xmath469 , we know that with probability tending to one , @xmath470 for some @xmath471 . since @xmath472 has rank one , @xmath473 .",
    "lemma  [ lem : xisquare ] with @xmath474 implies that with probability at least @xmath475 , @xmath476 and thus with probability tending to one , @xmath477 for some @xmath478 .    plugging these bounds into ( [ eq : eigeq1 ] ) , we conclude that with probability tending to one as @xmath244 , @xmath479 ^ 2 \\\\ & \\le & \\biggl [ ( 1+{\\varepsilon}_1+{\\varepsilon}_2 ) \\biggl(\\sqrt{\\beta } + 1+\\sqrt { \\frac{p}{n } } \\biggr ) \\biggr]^2 , \\end{aligned}\\ ] ] which completes the proof of proposition  [ prop : largesteig ] .",
    "proof of proposition  [ fact : ledoit ] starting with @xmath265 , observe that @xmath480 .",
    "lemma  [ lem : xisquare ] with @xmath481 implies that with probability at least @xmath482 , @xmath483 for @xmath484 . taking a union bound over @xmath485 , we obtain that with probability at least @xmath222 , all entries @xmath486 $ ] , which implies @xmath487.\\ ] ]    we now turn to bound @xmath488 by the preceding paragraph , with probability at least @xmath222 , @xmath489 $ ] . using the notation of ( [ eq : defofdist ] ) , we write off - diagonal entries in @xmath13 as @xmath490 , where @xmath491 , and notice that @xmath492 are independent .",
    "now fix @xmath463 and condition on @xmath493",
    ". then lemma  [ cl : clt ] implies that each off - diagonal entry along row @xmath463 is distributed @xmath494 , @xmath495 ) .",
    "moreover the @xmath496 s ( for different @xmath497 ) are independent , hence , @xmath498 .",
    "using lemma  [ lem : xisquare ] with @xmath499 , with probability at least @xmath222 , @xmath500,\\ ] ] for @xmath501 .",
    "next , remove the conditioning on @xmath493 ( still for a fixed @xmath463 ) , observing that @xmath502 .",
    "lemma  [ lem : xisquare ] with @xmath499 then implies that with probability at least @xmath222 , we have @xmath503 $ ] for @xmath504 .    finally , taking the union bound over rows @xmath485 and also the sum along the diagonal , with probability at least @xmath505 , @xmath506 for a suitably chosen @xmath507 .",
    "similarly , @xmath508 for @xmath509 . to complete the proof of proposition  [",
    "fact : ledoit ] , set @xmath510 ."
  ],
  "abstract_text": [
    "<S> estimating the leading principal components of data , assuming they are sparse , is a central task in modern high - dimensional statistics . </S>",
    "<S> many algorithms were developed for this sparse pca problem , from simple diagonal thresholding to sophisticated semidefinite programming ( sdp ) methods . </S>",
    "<S> a  key theoretical question is under what conditions can such recover the sparse principal components ? we study this question for a single - spike model with an @xmath0-sparse eigenvector , in the asymptotic regime as dimension @xmath1 and sample size @xmath2 both tend to infinity . </S>",
    "<S> amini and wainwright [ _ ann . statist . _ * 37 * ( 2009 ) 28772921 ] proved that for sparsity levels @xmath3 , no algorithm , efficient or not , can reliably recover the sparse eigenvector . </S>",
    "<S> in contrast , for @xmath4 , diagonal thresholding is consistent . </S>",
    "<S> it was further conjectured that an sdp approach may close this gap between computational and information limits . </S>",
    "<S> we prove that when @xmath5 , the proposed sdp approach , at least in its standard usage , can not recover the sparse spike . </S>",
    "<S> in fact , we conjecture that in the single - spike model , no computationally - efficient algorithm can recover a spike of @xmath0-sparsity @xmath6 . finally , we present empirical results suggesting that up to sparsity levels @xmath7 , recovery is possible by a simple covariance thresholding algorithm .    ./style / arxiv - general.cfg    , </S>"
  ]
}