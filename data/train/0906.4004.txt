{
  "article_text": [
    "we will call a point @xmath1 _ heavy for @xmath2 $ ] relative to rotation by @xmath0 _ if the sequence @xmath3 modulo one for @xmath4 contains in every initial finite portion as many values in @xmath2 $ ] as it does in its complement .",
    "our interest is in describing the set of heavy points , given some specified @xmath0 .",
    "all values considered herein should be considered modulo one .",
    "heaviness may be viewed as recurrence of the set @xmath5 back to itself ( under rotation by @xmath0 in the @xmath6-torus ) in terms of schnirelmann density : @xmath7 is heavy if @xmath8}\\left(x+n{\\alpha}\\right ) \\right\\ } \\right ) = \\inf_{n \\in { \\mathbb{n } } } \\frac{1}{n } \\left(\\sum_{k=0}^{n-1 } \\chi_{[0,1/2]}(x+k{\\alpha})\\right ) \\geq \\frac{1}{2}.\\ ] ]    heaviness is generally expressed in the context of dynamical systems : set @xmath9 , @xmath10 , and @xmath11}(x)-\\chi_{\\left(\\frac{1}{2},1\\right)}(x)$ ] .",
    "then by defining @xmath12 we have @xmath13 , and the sums increase when @xmath14 , and decrease when @xmath15 .",
    "the _ heavy set for @xmath5 relative to @xmath16 _",
    ", @xmath17 is nonempty @xcite@xcite . for an overview of heavy sets in general ,",
    "see @xcite .",
    "heaviness in the case @xmath18 involves the study of periodic systems , appropriately viewed as heaviness in finite systems . in this context ,",
    "heaviness may also be viewed as a generalization of _ lyndon words _",
    ", an object of study in combinatorics and computer science ( see @xcite ) .",
    "we abbreviate @xmath19 . at a few points",
    ", we will be concerned with heaviness relative to a different set @xmath20 , in which case we consider the function @xmath21 , and we write @xmath22 .",
    "the structure of the heavy set depends on the parameter @xmath0 .",
    "specifically , we will see that the structure of @xmath23 is given by a constructive procedure based on the continued fraction expansion of @xmath0 .",
    "we define the function @xmath24 \\rightarrow [ 0,1]$ ] by : @xmath25 where @xmath26 is hausdorff dimension",
    ". then we have the following :    given any open @xmath27 , @xmath28 $ ] is surjective .    for lebesgue almost -",
    "every @xmath29 $ ] , @xmath30 , where @xmath31 is an explicit constant which is independent of @xmath0 .    in general ,",
    "we can define heaviness for a sequence of points @xmath32 , we let @xmath33 and define the sequence to be heavy for @xmath34 if @xmath35 for all @xmath36 . by definition ,",
    "the sequence @xmath37 is heavy for @xmath34 if and only if @xmath38 .",
    "see @xcite for one investigation of the sequence @xmath39 relative to the interval @xmath40 $ ] ; this situation will be revisited in appendix [ appendix - connect to heavy sequences ] .",
    "the following lemma will indispensable , and the simple proof may be found in @xcite :    [ lemma - word reduction ] let @xmath41 be a probability measure preserving system ( meaning @xmath42 is a probability space , and @xmath16 a transformation on @xmath43 which preserves @xmath44 ) , and let @xmath45 and @xmath46 be of mean zero .",
    "assume that for some @xmath47 : @xmath48 then @xmath38 if and only if the sequence @xmath49 is heavy for @xmath34 .",
    "in our situation , a ` hit ' to @xmath5 followed by a ` miss ' can be ignored . letting @xmath5 represent a hit to @xmath5 and @xmath50 a miss , the sequence @xmath51 for example ,",
    "may be reduced to @xmath52 by successive removal of the pair @xmath53 .",
    "consider the clear relation to the catalan numbers ( when considered as the number of nested sets of parentheses ) for our situation ; heaviness in general may be considered a dynamical - systems interpretation of the _ ballot counting problem _ @xcite .",
    "recall the following standard definition :    [ definition - induced map ] let @xmath41 be a probability measure preserving system , and let @xmath54 be measurable . then by the poincar recurrence theorem , for almost all @xmath55",
    ", we may define @xmath56 and the _ induced map _ on @xmath5 is given by @xmath57      the function @xmath58 will be seen to be highly dependent on the continued fraction expansion of @xmath0 , so we present here a brief overview of the theory of continued fractions and fractal dimension .",
    "we use _ standard continued fraction notation _ , where @xmath59 and @xmath60 for @xmath61 : @xmath62=a_0+\\cfrac{1}{a_1+\\cfrac{1}{a_2+\\cfrac{1}{\\cdots + \\frac{1}{a_n}}}}=\\frac{p_n}{q_n},\\ ] ] @xmath63 = \\lim_{n \\rightarrow \\infty } [ a_0 ; a_1 , a_2 , \\ldots , a_n].\\ ] ] for a comprehensive coverage of the theory of continued fractions , see @xcite .",
    "every irrational @xmath0 has a unique infinite continued fraction representation , and @xmath64 , @xmath65 .",
    "we define the _ integer _ and _ fractional _ parts of @xmath66 , respectively , as @xmath67}=\\max\\{n \\in { \\mathbb{z}}{\\textrm { : } } n \\leq x\\ } , \\hspace{.2 in } { \\left\\ { x \\right\\}}=x-{\\left [ x \\right]}.\\ ] ] as we are only concerned with @xmath68 , the term @xmath69 is always zero , so we abbreviate @xmath70=[a_1,a_2,\\ldots].\\ ] ]     let @xmath71 $ ] . then : @xmath72 , \\vspace{.1 in}\\\\    \\textit{if } 1 \\neq a_1=2n+1 : \\frac{1}{2n+1 } < 1 - 2n{\\alpha}<\\frac{2}{2n+2 } , \\vspace{.1 in}\\\\    \\left\\{\\frac{1}{{\\alpha}}\\right\\ } = [ a_2,a_3,\\ldots],\\\\    p_2={\\left [ \\frac{{\\alpha}}{1-q_1 { \\alpha } } \\right]},\\\\    { \\left\\ { q_2 { \\alpha}\\right\\}}=q_2 { \\alpha}- p_2 .",
    "\\end{array}\\ ] ] [ lemma - cont frac properties for induced maps ]    only the last two merit discussion ; the first five are elementary properties of continued fractions . note that @xmath73 , @xmath74 , and use the first two inequalities to see : @xmath75 and reduce the fractions to yield the first equality .    for the last equality",
    ", we also use that @xmath76 :    @xmath77 @xmath78 @xmath79    for every @xmath80 , the following limit exists and is a finite constant for lebesgue almost - all @xmath0 ( * ? ? ?",
    "* theorem 35 ) : @xmath81 where @xmath82 is _",
    "khinchin s constant_. we state the following : @xmath83 we omit the tedious work in establishing these bounds ; the persistent reader may use elementary techniques in summation and standard software packages to obtain the desired error control .",
    "we notate the hausdorff and lower box dimensions of a set @xmath5 by @xmath84 and @xmath85 , respectively .",
    "see @xcite for a more complete treatment of this material .",
    "let @xmath86 be a closed , connected interval , and define @xmath87 by requiring that each @xmath88 be a disjoint union of closed intervals , such that each interval of @xmath88 contains at least two intervals of @xmath89 , and the maximal length of an interval in @xmath88 tends to zero as @xmath90 tends to infinity .",
    "set @xmath91 .",
    "suppose that each interval of @xmath92 contains at least @xmath93 intervals of @xmath88 , and that the intervals of @xmath88 are all separated by at least @xmath94 , where @xmath95 .",
    "then @xmath96    we may combine with the fact that @xmath97 in general to derive the following :    [ theorem - nice hausdorff dimension computation ] if each interval of @xmath88 contains _ exactly _ @xmath93 intervals of @xmath89 , each of which is of length @xmath98 times the length of the intervals in @xmath99 , and furthermore the intervals of @xmath89 are separated by gaps at least as large as the intervals of @xmath89 , and the @xmath93 grow ` sub - factorially ' ( meaning ` slower than factorially , ' not ` like the subfactorial numbers ' ) : @xmath100 then @xmath101    first , note that the growth condition on @xmath93 implies that @xmath102 which in turn implies that @xmath103    each @xmath89 may be exactly covered by @xmath104 intervals of length @xmath105 , and so : @xmath106    for those @xmath71 $ ] for which the geometric mean of the @xmath107 exist , the @xmath107 must grow subfactorially , and for almost all @xmath0 , the geometric mean of the @xmath107 is @xmath82 .",
    "a demonstration of the explicit difference between the two rotations @xmath110 $ ] and @xmath111 $ ] will make the general process clearer in  [ section - four cases ] . while @xmath112 and @xmath113 have very similar continued fraction expansions , we will see that the corresponding heavy sets have radically different structure .",
    "@xmath114 is a perfect set ( closed with no isolated points ) of hausdorff dimension @xmath115[example - nice fractal heavy set ]    we provide a rough plot of the heavy set @xmath114 ( see figure [ figure - sample fractal pic ] ) .    as we are only concerned with rotation modulo one , set @xmath116=\\sqrt{2}-1 $ ] and @xmath117 .",
    "first , consider the interval @xmath118 .",
    "one may verify that the induced transformation ( recall definition [ definition - induced map ] ) @xmath119 , after rescaling by a factor of @xmath120 , is again rotation by @xmath0 ( see figure [ figure - root two induced ] ) .    on this subinterval @xmath121",
    ", one may also verify that the points in the interval @xmath122 $ ] return with the orbit segment @xmath123 ( by which we mean @xmath124 , @xmath125 , and @xmath126 ) , while the points in the intervals @xmath127 and @xmath128 return with @xmath129 and @xmath130 , respectively .",
    "let @xmath122=a'$ ] . by applying lemma [ lemma - word reduction ]",
    "we see that @xmath131 is in @xmath132 if and only if it is also in @xmath133 , because by freely removing the pair @xmath53 , the orbits reduce to @xmath5 on @xmath20 and @xmath50 on @xmath134 .",
    "so we have in fact shown that within the subinterval @xmath20 , _ being heavy for @xmath5 under @xmath16 is equivalent to being heavy for @xmath20 under @xmath119 _ , because the characteristic function of @xmath5 under first return map reduces via lemma [ lemma - word reduction ] to the characteristic function of @xmath20 .",
    "also , @xmath135 , after rescaling , so we in fact see that @xmath136 = \\delta h_{t}^{a}$ ] , where @xmath137 .",
    "furthermore , the interval @xmath138 takes @xmath139 steps to orbit into @xmath140 with segment @xmath53 , and the interval @xmath141 orbits into @xmath140 in @xmath142 steps with segment @xmath143 .",
    "again by lemma [ lemma - word reduction ] , we have that @xmath144 , and similarly for the interval @xmath145 , where we note that the portion @xmath146 will not be heavy ( as it is not in @xmath5 ) , but the corresponding portion inside @xmath140 is also not heavy ( it is not in @xmath147 $ ] , the scaled down copy of @xmath5 ) .",
    "also , the entire interval @xmath148 fails to be heavy .",
    "overall , therefore , the heavy set @xmath114 consists of three evenly spaced copies of itself scaled by a factor of @xmath149 .",
    "now we apply theorem [ theorem - nice hausdorff dimension computation ] , with @xmath150 and @xmath151 .",
    "fix @xmath152 $ ] , @xmath153=(2-\\sqrt{2})/2 $ ] , and @xmath154 ( modulo one )",
    ". then @xmath23 is countably infinite , with only one accumulation point , given by @xmath155 .",
    "the set @xmath23 is therefore of hausdorff dimension zero.[example - bad nonfractal heavy set ]    we will use many of the same tricks as in the previous example , but with very different results . see figure [ figure - sample bad fractal pic ] for a picture of @xmath23 lying inside the interval @xmath156 $ ] .",
    "we will again consider the induced map on the interval @xmath157 .",
    "however , as @xmath158 , the return times are much smaller : the interval @xmath159 returns in one step with orbit @xmath5 , the interval @xmath160 $ ] returns in three steps with orbit @xmath123 , and @xmath161 returns in three steps with orbit @xmath129 ( see figure [ figure - induced map for bad sample alpha ] ) .",
    "lemma [ lemma - word reduction ] applies again , then , to say that @xmath162}.\\ ] ] however , in the previous example , we were able to use the fact that @xmath163 to show that the heavy set in the induced map was a rescaled copy of the original heavy set . in this case , however , @xmath164 , so we instead get @xmath165}=-\\delta h_{t}^{a}+\\left(\\frac{1}{2}-{\\alpha}\\right),\\ ] ] where @xmath149 again .",
    "this fact results from considering rotation by @xmath166 to be equivalent to reversing orientation on our interval @xmath121 , and rotating by @xmath0 . in this manner ,",
    "whatever happens to a point @xmath7 under @xmath167 is duplicated in the behavior of @xmath168 under rotation by @xmath166 .",
    "another crucial difference with the previous example concerns the fact that in example [ example - nice fractal heavy set ] , we were able to find a total of three copies of the heavy set . in this case , however , the smaller interval @xmath169 $ ] orbits into @xmath170 $ ] with orbit segment @xmath53 , so @xmath171=h_{{\\alpha}}\\cap\\left[0,\\frac{1}{2}-\\delta \\right]+\\delta$ ] . however , the entire interval @xmath172 is clearly not heavy , so we only have a single  complete \" heavy island , and then a  broken , \" smaller heavy island .",
    "see figure [ figure - broken island in bad example ] .",
    "the behavior of that broken heavy island is dependent on the behavior of the interval @xmath170 $ ] , because it orbits into it with initial segment @xmath53 , which we may freely ignore .",
    "however , recall that @xmath164 , so the induced map will create the same picture , _ but with reversed orientation_. therefore , the induced map will create a broken heavy island on the interval @xmath173 $ ] . furthermore",
    ", the behavior in @xmath174 $ ] reduces to only considering this smaller interval , as @xmath175 , so the interval @xmath170 $ ] does not contain any of the unbroken heavy island formed in the induced map .    each time we pass to an induced map",
    ", we create a broken heavy island scaled down by a factor of @xmath176 ; any given broken heavy island will decay to an isolated point .",
    "furthermore , since we only create one unbroken island at each stage , scaled down by @xmath177 , there is only a single heavy point which results from intersecting the unbroken islands . the exact value of @xmath155 as the value of this accumulation point is not difficult to compute as the limit point of the endpoints of the unbroken islands .",
    "in the following four cases , we investigate how the structure of @xmath23 is affected by the initial terms of the continued fraction expansion of @xmath0 . recall that @xmath178 , @xmath152 $ ] . regardless of whether @xmath179 or @xmath180",
    ", we also write @xmath181 $ ] , @xmath182 $ ] ( so @xmath183}$ ] ) , and we will be building the induced map @xmath119 . our process will always consider which subintervals of @xmath5 maintain nonnegative sums for larger times @xmath184 . in  [ section - explicit dimension comps ] and  [ section - bounds for hausdim ] , we will employ this process to compute @xmath58 .",
    "[ [ subsection - a1 is 1 ] ]    the simplest case to consider is that of @xmath185 . in this event , @xmath186 , and",
    "@xmath187 $ ] . as rotation by @xmath0",
    "is symmetric with rotation by @xmath166 , we see that a point @xmath188 is heavy for @xmath5 relative to rotation by @xmath0 if and only if @xmath189 is heavy for @xmath5 relative to rotation by @xmath166 .",
    "so , as in example [ example - bad nonfractal heavy set ] , by reversing our orientation , we may consider rotation by @xmath190 $ ] without generating any subintervals .",
    "[ [ subsection - nicest case ] ]    in the event that @xmath179 and @xmath191 , the following order of elements is verifiable by direct computation : @xmath192 @xmath193    note that @xmath20 is exactly the closed bottom half of @xmath121 , just as @xmath5 is the closed bottom half of @xmath194 .",
    "now , let @xmath195 , so that @xmath196 , and let @xmath197 $ ] , so that @xmath198 .",
    "[ lemma - above critical cutoff definitely fails ] if @xmath199 , then @xmath200 .",
    "furthermore , if @xmath201 , then @xmath7 is heavy for @xmath5 if and only if @xmath202 is heavy for @xmath5 .",
    "first , assume that @xmath203 .",
    "the orbit of @xmath7 begins with no more than @xmath204 hits to @xmath5 ( as @xmath199 ) , followed by at least @xmath184 hits to @xmath205 ( as @xmath206 ) , so that @xmath7 is not heavy for @xmath5 . if @xmath207 , then @xmath7 fails to be heavy for @xmath5 trivially .",
    "now , if @xmath201 , we see that the first @xmath208 points in the orbit of @xmath7 are @xmath184 consecutive hits to @xmath5 , followed by @xmath184 consecutive hits to @xmath209 . by lemma [ lemma - word reduction ] , we may ignore this string of the orbit when determining heaviness , so we see that @xmath7 is heavy for @xmath5 if and only if @xmath210 is heavy for @xmath5 . note also that as @xmath211 was assumed , we know that @xmath212 .",
    "[ lemma - first island breaks in half nicely ] if @xmath213 , then @xmath7 remains heavy for @xmath5 until it returns to @xmath121 , at which point it returns with a net weight of @xmath214 .",
    "conversely , those @xmath215 fail to be heavy for @xmath5 , and they return to @xmath121 with a net weight of @xmath216 , and they at no point through their return have a net weight of less than @xmath216 .",
    "let @xmath213 .",
    "then as @xmath217 , the orbit of @xmath7 begins with an @xmath5 , and then @xmath218 . by lemma",
    "[ lemma - above critical cutoff definitely fails ] , we may now apply @xmath167 a total of @xmath208 times to the point @xmath219 , producing the orbit segment @xmath220 ; the initial string of @xmath184 hits to @xmath5 is due to @xmath221 , itself due to @xmath222 .",
    "now , if @xmath223 , we apply @xmath167 another @xmath208 times , again using lemma [ lemma - above critical cutoff definitely fails ] .",
    "we continue to apply @xmath167 in blocks of @xmath208 applications until we land back in @xmath121 , at which point we may not apply the same lemma again .",
    "however , we have shown the desired conclusion ; the orbit of @xmath7 contains an initial @xmath5 , and then @xmath219 has an orbit consisting of repetitions of the block @xmath224 ( which we may ignore by lemma [ lemma - word reduction ] ) until it returns to @xmath121 .    for those @xmath215 ,",
    "the only difference is that @xmath225 .",
    "so the orbit begins with @xmath226 , but after that produces the same blocks @xmath220 .",
    "so by applying lemma [ lemma - word reduction ] , this orbit segment may be reduced to the single extra ` miss , ' so that those @xmath215 fail to be heavy , but also return to @xmath121 with a net weight of @xmath216 , and this net loss of one is the most extra misses accumulated at any time .",
    "overall , we may decompose the set @xmath5 ( those points which remain heavy for @xmath5 through at least one step ) into @xmath227 equally spaced subintervals of length @xmath228 , the intervals @xmath229 for @xmath230 ; the string of inequalities at the beginning of this case includes the fact that @xmath231 is the last @xmath229 before the cutoff value of @xmath232 , which does not interrupt this subinterval . the heaviness behavior in each ` subisland ' @xmath229 reduces to the behavior in the interval @xmath20 . as we know that @xmath20 remains heavy for @xmath5 until it returns to @xmath121 ,",
    "we now compute the induced transformation on the interval @xmath121 :    [ lemma - induced transforamtion on nicest case ] the induced transformation on @xmath121 is rotation by @xmath233 $ ] .",
    "it follows from the elementary theory of continued fractions that the minimal @xmath234 such that @xmath235 is @xmath236 . from this observation ,",
    "one may quickly deduce that the induced transformation on @xmath121 is given by figure [ figure - induced map for good alpha ] :    after rescaling , then , the induced transformation is rotation by the amount @xmath237 . using lemma [ lemma - cont frac properties for induced maps ] :    @xmath238}\\\\      & = { \\left\\ { \\frac{{\\alpha}}{1-q_1{\\alpha } } \\right\\ } }     = { \\left\\ { \\frac{1}{\\frac{1}{{\\alpha}}-q_1 } \\right\\}}\\\\      & = { \\left\\ { \\frac{1}{{\\left\\ { \\frac{1}{{\\alpha } } \\right\\ } } } \\right\\ } } = [ a_3,a_4,\\ldots ] .",
    "\\qquad \\qedhere\\end{aligned}\\ ] ]    to summarize , then , the interval @xmath5 may be decomposed into @xmath227 equally spaced subintervals , each of whose heaviness behavior is controlled by the interval @xmath121 and its induced transformation .",
    "this induced transformation is another rotation , and as the interval @xmath20 represents a net @xmath214 and the interval @xmath239 represents a net @xmath216 , heaviness in @xmath5 is mirrored on each of these subintervals @xmath229 by heaviness for @xmath20 _ under the induced rotation by _ @xmath240 .",
    "this point deserves repetition , as it is the central observation for deducing the structure of our heavy set : heaviness for @xmath5 each interval @xmath229 is now controlled by heaviness for @xmath20 under the induced rotation @xmath241 on the interval @xmath121 . as @xmath20 is again half of @xmath121 , we have returned to the original problem of describing heaviness for a closed half - interval , except that we now rotate by @xmath233 $ ] , and the manner in which @xmath20 decomposes into heavy sub - intervals will be mirrored on each @xmath229 .    [ [ subsection - even a1 , a3 is 1 ] ]    in the case when @xmath242 , but @xmath243 is still even , the exact same argument applies , with one crucial adjustment . in this case",
    ", we have : @xmath244 so , the interval @xmath245 $ ] would be another heavy subinterval , but it is interrupted by that critical cutoff value of @xmath232 .",
    "so , the same arguments will show that the intervals @xmath229 behave the same way as in the case @xmath242 for @xmath230 , but in @xmath246 , only the ` broken island ' @xmath247 $ ] will remain heavy for @xmath5 .",
    "letting @xmath248 be the length of this partial subinterval , we note that @xmath249 , and that heaviness in this partial subinterval will mirror heaviness in the interval @xmath250",
    "\\subset a'$ ] . the induced map on @xmath121 is again given by rotation by @xmath251 $ ] .    [ [ subsection - odd a1 ] ]    the only case remaining is when @xmath180 , @xmath252 .",
    "we state the following easily verifiable inequalities : @xmath253 the same techniques as in  [ subsection - nicest case ] and  [ subsection - even a1 , a3 is 1 ] show that heaviness for @xmath5 reduces to considering heaviness for @xmath254 $ ] in @xmath255 , under the induced transformation on @xmath121 .",
    "now , however , @xmath256 , so the return times are much smaller .",
    "see figure [ figure - induced map for bad alpha ] . as @xmath257 ,",
    "the induced transformation is given by rotation by @xmath258 :    @xmath259 - 2n}\\\\    & = [ 1,a_2,a_3,\\ldots].\\end{aligned}\\ ] ]    so , in this case , we have produced a single complete heavy island scaled in length by @xmath260 , as well as a single broken heavy island if intermediate length , and the new rotation to consider is given by @xmath261 $ ] .      refer to table [ table - table of stuff ] to summarize the decomposition of the heavy set , where @xmath71 $ ] .",
    "this process of producing a nested sequence of subintervals nicely follows the construction needed in  [ theorem - nice hausdorff dimension computation ] , so we may begin explicit computation of @xmath58 .      recall",
    "that if @xmath179 , @xmath263 , we produce evenly spaced subintervals of constant size , each of which will behave exactly as the others , and then apply a rotation by @xmath251 $ ] .",
    "so , when the odd - indexed partial quotients of @xmath0 are all even , the process is particularly nice , as @xmath251 $ ] will obey the same condition : @xmath264 , @xmath265 . among such @xmath0 , the easiest to consider are those whose continued fraction expansion is of period two .",
    "[ lemma - explicit hdim comp for nice alpha ] @xmath266=\\frac{-nm+\\sqrt{nm(nm-2)}}{2n}.\\ ] ] @xmath267    that @xmath268 is a quadratic irrational of the prescribed form is a simple computation . to determine the value @xmath269",
    ", we note that in applying the techniques of  [ section - four cases ] , we will always have @xmath179 , @xmath270 , @xmath271 .",
    "therefore , our heavy set may be represented as an intersection of a nested sequence of intervals , where each interval breaks into @xmath272 subintervals of length @xmath273 , each of which is separated by gaps of the same length , and by theorem [ theorem - nice hausdorff dimension computation ] , @xmath274    [ corollary - dense values of varphi ] the values @xmath269 as @xmath275 are dense in @xmath276 $ ] .",
    "consider the function @xmath277 for @xmath278 .",
    "of course , @xmath279 for @xmath280 .",
    "the following may all be verified with elementary ( if tedious ) methods :    * for fixed @xmath281 , @xmath282 .",
    "+ * for fixed @xmath283 , @xmath284 . + * @xmath285 , @xmath286 .",
    "now , fix @xmath287 , and pick @xmath288 large enough so that @xmath289",
    ". then the sequence @xmath290 as @xmath291 monotonically decreases towards zero , with the gaps between successive elements shrinking , thereby forming an @xmath292-dense subset of @xmath276 $ ] . as @xmath292 was arbitrary , the result is proved .",
    "[ theorem - varphi is surjective ] the function @xmath262 maps every open subset of @xmath194 surjectively onto @xmath194 .",
    "let @xmath293 $ ] , and by corollary [ corollary - dense values of varphi ] , pick @xmath294 , @xmath295 such that @xmath296 .",
    "then let @xmath297 $ ] where each pair @xmath294 , @xmath295 is repeated @xmath298 times .",
    "@xmath298 is chosen to be large enough so that the entries of @xmath0 satisfy the sub - factorial growth condition , so that the hausdorff dimension of the resulting heavy set is equal to its lower box dimension .",
    "furthermore let @xmath298 be large enough so that as we remove successive pairs by applying our inductive process on @xmath0 , the resulting rotations remain within @xmath299 of @xmath300 for at least @xmath301 successive iterations , so that the @xmath302 in the box dimension computation is equal to the limit of our chosen @xmath269 .",
    "carefully tracking the values @xmath298 would be cumbersome , and would obscure the only relevant fact ; they exist and are finite , so that for any @xmath293 $ ] we may construct @xmath0 with @xmath303 .    to see that for any open @xmath304 , @xmath262 surjectively maps @xmath304 onto @xmath194 , note that for any open @xmath305 $ ] , there is some string @xmath306 such that all numbers whose continued fraction expansion begins with @xmath307 $ ] belong to @xmath304 .",
    "while we can not control how the heavy set decomposes as a result of these first @xmath184 values , we may clearly control the rest of the entries to achieve any desired result .",
    "if we define @xmath308 , where @xmath7 and @xmath309 are the lower and upper box dimensions of the heavy set , then @xmath310 surjectively maps every open subset of the unit interval onto the entire possible image @xmath311 .    by choosing two targets @xmath7 and @xmath309 , where @xmath312",
    ", we may alternate long stretches of the continued fraction expansion of @xmath0 , again beginning arbitrarily deep in the expansion , so that the @xmath313 and @xmath302 of the dimension computation achieve our desired amounts .",
    "two inherent problems prevent us from directly computing @xmath58 , but we may address each issue to derive a meaningful lower bound .",
    "first , the lengths of the produced intervals will vary depending on the rotation amounts at each stage , which will require computing the exact form of a given continued fraction .",
    "we may easily find an lower bound on the length , however , relying on no more than two terms of the continued fraction expansion of @xmath0 .",
    "second , there is the possibility of ` broken intervals ' being produced , of intermediate length , which may or may not disappear or decay to a single point ( as in example [ example - bad nonfractal heavy set ] ) in later steps",
    ". we will skirt this problem by ignoring such broken intervals completely , still maintaining a lower bound .    letting @xmath314",
    "be a lower bound on the number of subintervals produced after @xmath315 applications of the cases in  [ section - four cases ] , and letting @xmath316 be a lower bound on the lengths of the intervals , we consider our starting @xmath0 to be represented by a sequence of natural numbers - the continued fraction expansion .",
    "set @xmath317 , and apply the following process , derived from the results of  [ section - four cases ] :    1 .",
    "if @xmath179 and @xmath191 , let @xmath318 and @xmath319 .",
    "now consider the sequence @xmath320 .",
    "if @xmath179 and @xmath242 , let @xmath321 , and @xmath319 . now consider the sequence @xmath322 .",
    "if @xmath180 and @xmath252 , let @xmath323 and @xmath324 .",
    "now consider the sequence @xmath325 .",
    "we will refer to the preceding events as case 1 , 2 , and 3 , respectively .",
    "note that we have ignored the possibility that our sequence ever begins with one . without loss of generality ,",
    "we consider only those @xmath326 , and we have already noted that we can safely ignore the possibility of changing orientation for these estimates ; we automatically consider any sequence @xmath327 to be @xmath328 .    by theorem [ theorem - nice hausdorff dimension computation ] ,",
    "if our @xmath314 grow sub - factorially ( which is true for lebesgue almost - every @xmath0 , as previously remarked ) , then : @xmath329    given a fixed irrational @xmath71 $ ] , let @xmath330 $ ] be the number associated with applying cases 1 - 3 ( as appropriate ) @xmath315 times to @xmath0 .",
    "note that @xmath331 : if case 3 is applied , we remove only a single terms from the list , while if case 2 is applied , we remove three ( case 1 removes two terms ) , and @xmath332 .    [ lemma - last bit for positive dimension ] almost surely , we have both @xmath333 @xmath334 for finite positive constants @xmath335 and @xmath336 ( the constants are independent of @xmath0 ) .    first , note that @xmath337 , where @xmath338 is the number of times out of the first @xmath315 applications of cases 1 - 3 that either case 1 or 2 was applied .",
    "so , we need only prove that almost - surely , @xmath339 we apply one of these cases when an even @xmath243 is followed by an even @xmath340 or when an odd @xmath243 is followed by an odd @xmath341 , where we are testing along an increasing subsequence of the natural numbers .",
    "our inequality follows from the following fact ( * ? ? ?",
    "12 ) : @xmath342 @xmath343 so , regardless of what has happened in the previous steps , the probability of encountering case 1 or 2 is at least @xmath344 .",
    "overall , then , @xmath345 .    for the inequality involving @xmath316 , we note that @xmath346 is the logarithm of the geometric mean of a certain subsequence of the @xmath347 with gaps between successive entries at most two . as the geometric mean of _ all _",
    "@xmath348 is almost - surely the constant @xmath349 , the limsup of the logarithm of the geometric mean along a syndetic subset of gap bounded by two is almost - surely no larger than @xmath350 .",
    "we immediately arrive at our second major claim :    [ theorem - positive hausdorff dimension ] for lebesgue almost - every @xmath29 $ ] : @xmath351      now consider the set @xmath352 of those points for which a _ strict _ inequality is maintained . in each of the four cases ( @xmath179 , etc )",
    "there was exactly _ one _ subinterval which maintained a strict inequality ; recall that when more than one heavy island was produced ( as happened in all cases except @xmath185 ) , only the least island maintained a strict inequality , while all other complete or partial islands began their orbit with @xmath224 ( where @xmath179 or @xmath353 ) .",
    "therefore , by intersecting the unique closed island which maintains a sum of at least @xmath214 , we see that for every @xmath354 , the set @xmath355 is a single point . as a corollary to this observation",
    ", we also note that for all @xmath354 , the set @xmath23 is infinite",
    ". if @xmath281 is the unique ` strictly heavy ' point , then there must be infinitely many @xmath288 such that @xmath356 ; if not , the final such time would produce another strictly heavy point . because the sums never return to zero",
    ", however , each such time @xmath234 corresponds to a ( non - strcitly ) heavy point .",
    "similarly , the orbit of any heavy point must contain infinitely many other heavy points .",
    "however , it is worth noting that while the set of strictly heavy points is very small , a single point , the set of heavy points is generally fairly large , of positive hausdorff dimension , so that ` most ' heavy points do not belong to the orbit of this unique strictly heavy point . in appendix [ appendix - connect to heavy sequences ] , we investigate one special case of identifying this unique strictly heavy point , first investigated in @xcite .",
    "we also note that for almost every @xmath0 , @xmath23 contains arbitrarily long arithmetic progressions . for any fixed @xmath288 , one must merely notice that proceeding through the four cases of  [ section - four cases ] will yield @xmath357 $ ] for some @xmath184 at least once ( in fact , infinitely many times ) for almost every @xmath0 , and at this stage , the heavy set will decompose into @xmath358 equally spaced subislands , all of which will decompose identically in further steps , easily producing infinitely many arithmetic progressions of length @xmath358 in the heavy set .",
    "we may also construct some @xmath0 for which the heavy set is countably infinite , with any fixed @xmath359 accumulation points organized in @xmath349 clusters , each with @xmath360 subclusters , each with @xmath361 subclusters , etc , where each @xmath362 : set @xmath363.\\ ] ] then we create @xmath349 islands , each with @xmath360 subislands , etc , until finally reaching a rotation by @xmath364 $ ] , which we have already seen in example [ example - bad nonfractal heavy set ] will cause each remaining island to decay to exactly one accumulation point .",
    "however , the set @xmath23 always contains exactly one solution to the equation @xmath365 .",
    "if both @xmath366 , and @xmath367 , we see that @xmath309 must be a strictly heavy point , of which there is only one .",
    "similarly , the unique strictly heavy point @xmath281 always has @xmath368 , so one solution always exists .    in conclusion",
    ", we present a picture ( figure [ figure - manyplots ] ) .",
    "for @xmath369 , the set @xmath23 is a finite collection of closed intervals . with the aid of a computer , we present a plot of @xmath370 along the @xmath7-axis for various @xmath371 along the @xmath309-axis in figure [ figure - manyplots ] . included",
    "are all @xmath371 with @xmath372 , @xmath373 . besides the obvious relation between @xmath23 and @xmath374 , the structure of this set is not clear . by theorem [ theorem - positive hausdorff dimension ] , the hausdorff dimension of this set is positive , but thus far there are only visual suggestions of self - similarity .",
    "we now mention a slight extension of the results of  [ subsection - nicest case ] and  [ subsection - odd a1 ] . for this section only , let @xmath375 $ ] for some fixed @xmath376 , @xmath377 $ ] , and @xmath378 $ ] .",
    "it is now necessary to let @xmath379 .",
    "the proofs may be carried out exactly as in the original version ( where lemma [ lemma - word reduction ] now allows us to remove the block @xmath380 ) , and we omit them :    [ lemma - extension for heavy sequences ] let @xmath381 .",
    "then for @xmath213 , heaviness under induced map @xmath119 with respect to @xmath20 is equivalent to heaviness under @xmath16 with respect to @xmath5 , as in ",
    "[ subsection - nicest case ] . @xmath119 rescales to rotation by @xmath251 $ ] . if @xmath382 , where @xmath252 and @xmath383 , then heaviness under @xmath16 relative to @xmath5 is again equivalent to heaviness under @xmath119 relative to @xmath20 , and @xmath119 rescales to rotation by @xmath384 $ ] .",
    "we are now in a position to claim the following theorem :    [ theorem - heavy sequences result ] the sequence @xmath39 ( @xmath385 ) is heavy for @xmath40 $ ] if and only if @xmath386 for all @xmath315 .",
    "one direction is immediate from lemma [ lemma - extension for heavy sequences ] .",
    "assume that @xmath71 $ ] where @xmath386 .",
    "then 0 remains heavy for @xmath5 until it returns to @xmath121 and maintains one extra ` hit , ' at which point heaviness is equivalent to heaviness under the induced transformation with respect to @xmath20 , but the induced transformation is rotation by @xmath251 $ ] , which still has @xmath386 .",
    "it follows that @xmath387 , or that the sequence @xmath388 is heavy for @xmath5 .",
    "we have been tracking the orbit of zero , but it follows that as the orbit of zero always maintains one extra ` hit , ' the orbit of @xmath0 itself is heavy .",
    "now , let some @xmath389 .",
    "we may assume without loss of generality that @xmath390 ; the inductive process from lemma [ lemma - extension for heavy sequences ] will maintain heaviness until the first odd - indexed @xmath107 which is not zero modulo @xmath90 , at which point if it is larger than @xmath90 , it will induce a rotation by an amount whose first partial quotient is less than @xmath90 .",
    "so , let @xmath391 $ ] , where @xmath392",
    ". then @xmath393 , and the sequence is clearly not heavy .    in @xcite , the same condition on @xmath0 is shown to be equivalent to heaviness of the sequence @xmath394 @xmath395 .",
    "the only difference is that for the sequence beginning at @xmath396 , a strict inequality will be maintained .",
    "also , in @xcite , rational @xmath0 are considered as well as irrational , and the interval is open on the right ( which will only affect the sequence for rational @xmath0 ) , both of which are minor variations .",
    "let @xmath354 as before , and let @xmath397 , where @xmath398 $ ] again , and continue to let @xmath399 consider the function @xmath400 given by @xmath401 . in his book @xcite",
    ", d. hensley noted that when @xmath402 , the sequence @xmath403 has very regular structure .",
    "see figure [ figure - hensley conjecture ] for four images for several @xmath288 , where @xmath404 .",
    "our techniques allow us to explain this structure , as well as describe an inductive process for producing these sums for all @xmath354 .",
    "continuing with the specific case of @xmath402 , note that we can just as well consider @xmath405 $ ] .",
    "we have already noted in example [ example - nice fractal heavy set ] that through the first @xmath406 steps , this sum remains nonnegative , and then returns to the interval @xmath20 , and that the induced map @xmath119 will again be rotation by @xmath407 .",
    "each successive iteration of the induced map produces a string of either length @xmath406 or @xmath408 , with overall changes of @xmath409 .",
    "these sums remain positive for all time ( the sequence @xmath410 is heavy for @xmath5 by theorem [ theorem - heavy sequences result ] ) , but also contain a nicely iterated structure .",
    "whatever blocks of up / down movement corresponds to the different possibilities represented by the induced map @xmath119 ( @xmath406 steps with a net @xmath214 , @xmath408 steps with a net @xmath216 , etc ) , these blocks will themselves be placed according to the map @xmath119 , which is our original rotation by @xmath411 .",
    "this observation generalizes for arbitrary @xmath0 , with the caveat that when @xmath0 is not of the form @xmath412 $ ] , we will need to consider the situation of some step involving @xmath413 $ ] where @xmath252 . in this case , recall that our induced map @xmath119 involved small return times ( 1 and @xmath414 , specifically ) , so that the process of pasting together blocks at this stage will produce proportionately large changes in the value @xmath403 ; the overall change for each block is still @xmath409 , but we have not enlarged the size of the blocks compared to the previous step .",
    "this generic situation explains the lack of such neatly arranged sequences @xmath403 in general .",
    "still , it is not difficult to see that for almost - all @xmath0 , this process will result in considering @xmath415 $ ] infinitely many times , so there are arbitrarily long segments which will have this highly ordered structure .",
    "the developing structure first noticed for @xmath402 in @xcite will certainly generalize to @xmath416 $ ] .",
    "in fact , the process will apply to any quadratic @xmath0 for which @xmath417 is heavy for @xmath5 , but a small period and small values of @xmath418 allow the structure to be clear within a reasonably small window of time",
    ". see figure [ figure - fractal discrepancy sums ] for the discrepancy sums for @xmath419 $ ] .",
    "the role of @xmath420 corresponds to a height in each small peak of @xmath421 , while @xmath422 accounts for producing a sequence of three peaks before considering the induced structure .",
    "the author wishes to thank m. boshernitzan for providing many of the questions answered herein , and for initiating the study of heavy sequences and heaviness in general .",
    "m. embree provided valuable assistance with efficient calculation of @xmath423 .",
    "furthermore , y. peres pointed out that the set @xmath424 would almost - surely be of zero hausdorff dimension ( see @xcite ) , prompting an investigation into the relation between the sets @xmath23 and @xmath424 .",
    "finally , the author appreciates everyone who expressed any interest in the topic of heaviness ."
  ],
  "abstract_text": [
    "<S> we are concerned with describing the structure of the set of points in the unit interval which , when subjected to rotation by irrational @xmath0 modulo one , for all finite portions of the orbit contain at least as many points in the bottom half of the interval as in the top half . specifically , an inductive procedure for describing the set based on the continued fraction expansion of @xmath0 </S>",
    "<S> is developed , leading into a discussion of the hausdorff dimension of this set . </S>",
    "<S> depending on the parameter @xmath0 , all possible dimensions may be achieved , and the essential infimum ( with respect to @xmath0 ) of this dimension is positive .    1 </S>"
  ]
}