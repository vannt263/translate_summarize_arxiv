{
  "article_text": [
    "large dense covariance matrices arise in a wide range of applications in computational statistics and data analysis .",
    "storing and performing numerical computations on such large dense matrices is computationally intractable .",
    "however , most of these large dense matrices are structured ( either in exact arithmetic or finite arithmetic ) , which can be exploited to construct fast algorithms .",
    "one such class of data sparse matrices are semi - separable matrices , which have raised a lot of interest and have been studied in detail across a wide range of applications including integral equations  @xcite and computational statistics  @xcite . for a detailed bibliography on semi - separable matrices ,",
    "the reader is referred to vandebril et al .",
    "@xcite . throughout the literature ,",
    "there are slightly different definitions of semi - separable matrices . in this article",
    ", we will be working with the following definition :    @xmath0 is termed a semi - separable matrix with semi - separable rank @xmath1 , if it can be written as @xmath2 where @xmath3 is a diagonal matrix , @xmath4 are rank @xmath1 matrices , @xmath5 denotes the upper triangular part of @xmath6 and @xmath7 denotes the lower triangular part of @xmath8 .",
    "fast algorithms for solving semi - separable linear systems exists and the reader is referred to some of these references  @xcite and the references therein . in this article , we propose a new @xmath9 direct solver and determinant computation for semi - separable matrices .",
    "the main contributions of this article include :    * a new @xmath9 direct solver for semi - separable matrices is obtained by embedding the semi - separable matrix into a larger banded matrix . *",
    "the determinant of these semi - separable matrix is shown to equal to the determinant of the larger banded matrix , thereby enabling computing determinants of these semi - separable matrices at a computational cost of @xmath9 .",
    "this is the first algorithm for computing the determinants for a general semi - separable matrix . *",
    "a numerically stable generalized rybicki press algorithm is derived using these ideas . to be specific , fast , stable",
    ", direct algorithms are derived for solving and computing determinants ( both scaling as @xmath9 ) for covariance matrices of the form : @xmath10 where @xmath11 , the points @xmath12 are distinct and are distributed on an interval .",
    "the covariance matrix in equation   is frequently encountered in computational statistics in the context of continuous time autoregressive - moving - average ( abbreviated as carma ) models  @xcite . *",
    "another advantage of this algorithm from a practical view - point is that the algorithm relies only on sparse linear algebra and thereby can easily use the existing mature sparse linear algebra libraries .",
    "the algorithm discussed in this article has been implemented in c++ and the implementation is made available at https://github.com/sivaramambikasaran/ess  @xcite under the license provided by new york university .    *",
    "acknowledgements * : the author would like to thank christopher s. kochanek for initiating the conversation on generalized rybicki press algorithm and david w. hogg for putting in touch with christopher s. kochanek .",
    "the author would also like to thank the anonymous referee for his careful , detailed review and insightful comments .",
    "the research was supported in part by the nyu - aig partnership on innovation for global resilience under grant number a2014 - 005 .",
    "the author was also supported in part by the applied mathematical sciences program of the u.s .",
    "department of energy under contract defgo288er25053 , office of the assistant secretary of defense for research and engineering and afosr under nsseff program award fa9550 - 10 - 1 - 0180 .",
    "to motivate the general idea , we will first look at the sparse embedding for a @xmath14 semi - separable matrix , whose semi - separable rank is @xmath13 .",
    "the matrix @xmath15 is as shown in equation  .",
    "@xmath16    and the corresponding linear system is @xmath17 , where @xmath18    introduce the following variables : @xmath19 @xmath20    introducing the variables the linear system @xmath17 is now of the form @xmath21    the extended linear system ( after appropriate ordering of equations and unknowns ) is then of the form @xmath22 note that equation   is a banded matrix of bandwidth @xmath23 and has a sparsity structure even within the band . in general ,",
    "let @xmath15 be an @xmath24 semi - separable matrix , with the semi - separability rank @xmath13 as written in equation  .",
    "@xmath25 where @xmath26 .",
    "one would then need to add the variables @xmath27 and @xmath28 , where @xmath29 , @xmath30 and @xmath31 where @xmath32 .",
    "hence , we have a total of @xmath33 variables and @xmath33 equations .",
    "therefore , the extended matrix will be a @xmath34 banded matrix , whose bandwidth is @xmath23 .",
    "this is illustrated pictorially for a @xmath35 matrix in figure  [ fig_rank1_semiseparable ] .",
    "semi - separable matrix where @xmath36 .",
    "the color code is as shown below . ]",
    "semi - separable matrix where @xmath36 .",
    "the color code is as shown below . ]",
    "[ fig_rank1_semiseparable ]",
    "let @xmath15 be a @xmath24 matrix , whose semi - separable rank is @xmath1 , i.e. , we have @xmath37 where @xmath26 .",
    "we then add the following variables @xmath38 and @xmath39 as before .",
    "however , not surprisingly , these new variables @xmath40 s and @xmath41 s will be vectors of length @xmath1 .",
    "let @xmath42 and @xmath43 .",
    "we then have the following relations for the additional vector variables . @xmath44 and @xmath45 where @xmath32 .",
    "hence , we now have @xmath46 variables ( this includes the @xmath47 @xmath48 s , @xmath49 vector variables @xmath50 and @xmath51 of length @xmath1 ) and @xmath46 equations relating them .",
    "therefore , we end up with a @xmath52 extended sparse matrix , whose bandwidth is @xmath53 .",
    "this is illustrated in figure  [ fig_rankm_semiseparable ] for @xmath54 semi - separable matrix , whose semi - separable rank is @xmath55 .     and @xmath56 .",
    "the color code is as shown below . ]     and",
    "the color code is as shown below . ]",
    "[ fig_rankm_semiseparable ]    the computational complexity of the algorithm clearly scales as @xmath9 , since the extended sparse matrix has a bandwidth of @xmath57 and the matrix of size @xmath58 .",
    "it is also possible to analyze the scaling with respect to the semi - separable rank @xmath1 , though this is of little practical relevance since @xmath59 for most interesting semi - separable matrices .",
    "a detailed analysis shows that the computational complexity of the algorithm is @xmath60 .",
    "numerical benchmarks presented in section  [ section_nb ] validate the scaling of the algorithm .",
    "the determinant of the extended sparse matrix is the same as the determinant of the original dense matrix up to a sign .",
    "the extended system , denoted by @xmath61 on appropriate reordering of rows and columns can be written as @xmath62 where @xmath63 , @xmath64 are permutation matrices , the matrix @xmath65 is a highly sparse lower - triangular matrix with @xmath13 s on the diagonal and @xmath66 s at a few places in the lower - triangular part ( the precise location is unimportant for determinant computations as we will see later ) , the matrix @xmath67 is a highly sparse upper - triangular matrix with @xmath13 s on the diagonal and @xmath66 s at a few places in the upper - triangular part and @xmath3 is a diagonal matrix with @xmath68 .",
    "the first set of rows , i.e. , @xmath69 , correspond to adding the variables @xmath51 , i.e. , @xmath70 .",
    "the next set of rows , i.e. , @xmath71 , correspond to adding the variables @xmath50 , i.e. , @xmath72 .",
    "the last set of rows , i.e. , @xmath73 , correspond to the initial set of equations with the @xmath51 s and @xmath50 s introduced .",
    "we then have @xmath74 now note that @xmath75 , due to the fact that @xmath65 and @xmath67 are triangular matrices with @xmath13 s on the diagonal .",
    "hence , @xmath76 further , note that the matrix @xmath77 is the schur complement obtained by eliminating the variables @xmath78 , @xmath40 and hence is the initial dense matrix @xmath15 we began with , i.e. , @xmath79 hence , we have @xmath80 which gives us that @xmath81 where the ambiguity in the sign arises due to the determinant of the permutation matrices .",
    "we will first naively reinterpret the rybicki press algorithm in terms of the extended sparse matrix algebra . recall that the rybicki press algorithm  @xcite inverts a correlation matrix @xmath15 given by equation  .",
    "@xmath82 where @xmath12 s lies on an interval and are monotone .",
    "the original rybicki press algorithm relies on the fact that the inverse of @xmath15 happens to be a tridiagonal matrix .",
    "the key ingredient of their algorithm is the following property of exponentials : @xmath83 in our sparse interpretation as well , we will use this property to recognize that the matrix @xmath15 is a semi - separable matrix , whose semi - separable rank is @xmath13 .",
    "this can be seen by setting @xmath84 and @xmath85 .",
    "this then gives us ( @xmath86 ) that @xmath87 and similarly for @xmath88 .",
    "this shows that the matrix @xmath15 is semi - separable with semi - separable rank @xmath13 .",
    "hence , we can mimic the same approach as in the earlier sections to obtain an @xmath9 algorithm .",
    "however , there is an issue that needs to be addressed from a numerical perspective .",
    "if the @xmath12 s are spread over a large interval , then @xmath89 is exponentially large , while @xmath90 is exponentially small , and hence embedding into a sparse matrix as such could prove to be a catastrophic leading to underflow and overflow of the relevant entries .",
    "this issue though can be circumvented by a suitable analytic preconditioning , by an appropriate change of variables .",
    "this is illustrated for a @xmath14 linear system .",
    "we will use the notation @xmath91 to denote @xmath92 .",
    "the linear equation is @xmath93 now lets introduce the additional variables as follows : @xmath94 @xmath95 the equations then become @xmath96 embedding this in an extended sparse matrix , we obtain @xmath97    note that the sparsity pattern of the matrix is the same as before , which is to be expected , since all we have done essentially is to scale elements appropriately and hence the zero fill - ins remain the same .",
    "the same idea carries over the generalized rybicki press algorithm , i.e. , if we consider a carma(@xmath1,@xmath98 ) process which has the covariance matrix given by @xmath99 then it immediately follows that that the matrix is semi - separable with semi - separable rank being @xmath1 . to avoid numerical overflow and underflow , as shown in the previous section , appropriate sets of variables need to be introduced",
    "let @xmath100 and @xmath101 now introduce the variables @xmath102 @xmath103 where @xmath104 , with @xmath105 and @xmath106 is a @xmath107 diagonal matrix , with its diagonal being @xmath108 .",
    "the initial equations become @xmath109 where @xmath110 .",
    "now form the extended sparse matrix using the variables @xmath111 and @xmath112 , with the equations being equations  ,  ,  .",
    "the sparsity pattern of the extended sparse matrix is the same and hence the computational complexity scales as @xmath9 .",
    "we present a few numerical benchmarks illustrating the scaling of the algorithm and the error . in all these benchmarks ,",
    "the semi - separable matrix is of the form @xmath113 where the @xmath12 s lie on a on - dimensional manifold and are sorted in increasing fashion . apart from the time taken for the assembly , factorization and solve , the infinity norm of the residual , i.e. , @xmath114 and the relative error in the log determinant are also presented . for the purposes of benchmark , @xmath12 s are chosen at random from the interval @xmath115 $ ] and then sorted ; @xmath116 s , @xmath117 s are chosen at random from the interval @xmath118 $ ] ; and @xmath119 is set equal to @xmath120 . throughout the benchmarks the original dense matrix will be referred to as @xmath15 , while the corresponding extended sparse matrix will be referred to as @xmath61 .",
    "the extended sparse linear system , i.e. , @xmath121 , is solved using the sparse lu factorization ( sparselu ) in eigen  @xcite .",
    "this relies on the sequential superlu package  @xcite , which performs sparse lu decomposition with partial pivoting .",
    "the preordering of the unknowns is performed using the colamd method  @xcite .",
    "it is to be noted that despite the preordering and partial pivoting , which inturn affects the banded structure , the computational cost as shown in figures  [ figure_benchmark1 ] ,  [ figure_benchmark2 ] for the extended sparse system scales linearly in the number of unknowns . the extended sparse matrix is stored using a triplet list in eigen  @xcite , which internally converts it into compressed column / row storage format .",
    "the exact implementation can be found at https://github.com/sivaramambikasaran/ess  @xcite .      in this benchmark",
    ", we illustrate the linear scaling of the algorithm with the number of unknowns @xmath47 for different choices of @xmath1 .",
    "the solution obtained using the sparse lu factorization is compared with the partial pivoted lu algorithm ( partialpivlu ) in eigen  @xcite , which is used to solve the initial dense linear system @xmath17 .",
    "table  [ table_n_scaling ] shows the scaling of the algorithm and the maximum error in the residual for a fixed semi - separable rank of @xmath122 .",
    ".scaling of the algorithm with system size @xmath47 for a fixed semi - separable rank @xmath122 . the time taken is reported in milliseconds . [ cols=\"^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     [ table_n_scaling ]    * assembly time - time taken to assemble the dense matrix versus extended sparse matrix .",
    "* factorization time - time taken to factorize the dense matrix versus extended sparse matrix . *",
    "solve time - time taken to solve the dense linear system versus the extended sparse linear system ( once the factorization has been obtained ) .",
    "* error in residual - comparision of @xmath123 and @xmath124 .",
    "* error in log - det - relative error of the log of the absolute value of the determinant of the dense matrix and the extended sparse matrix .",
    "figure  [ figure_benchmark1 ] illustrates the scaling of the assembly , factorization and solve time with system size .",
    "the different components of the algorithm , i.e. , assembly , factorization and solve , scale linearly in the number of unknowns .",
    "also , as expected the pre - factor infront of the linear scaling increases with the semi - separable rank @xmath1 , i.e. , in our case the number of exponentials .      in this benchmark",
    ", we illustrate the scaling of the time taken ( assembly , factorization and solve ) for algorithm with @xmath1 , the number of exponentials added ( equivalently the semi - separable rank ) .",
    "figure  [ figure_benchmark2 ] illustrates the scaling of different parts of the algorithm with the semi - separable rank @xmath1 .",
    "note that the assembly time scales linearly with the semi - separable rank , while the factorization time scales quadratically with the semi - separable rank as expected .",
    "the error in the solution seems to be more or less independent of the semi - separable rank .",
    "the article discusses a numerically stable , generalized rybicki press algorithm , which relies on the fact that a semi - separable matrix can be embedded into a larger banded matrix .",
    "this enables @xmath9 inversion and determinant computation of covariance matrices , whose entries are sums of exponentials .",
    "this also immediately provides a fast matrix vector product for semi - separable matrices .",
    "this publication also serves to formally announce the release of the implementation of the extended sparse semi - separable factorization and the generalized rybicki press algorithm .",
    "the implementation is in c++ and is made available at https://github.com/sivaramambikasaran/ess  @xcite under the license provided by new york university .",
    "jitesh jain , hong li , cheng - kok koh , and venkataramanan balakrishnan .",
    "o(n ) algorithms for banded plus semi - separable matrices . in _ numerical methods for structured matrices and applications _ , pages 347358 .",
    "springer , 2010 ."
  ],
  "abstract_text": [
    "<S> this article discusses a more general and numerically stable rybicki press algorithm , which enables inverting and computing determinants of covariance matrices , whose elements are sums of exponentials . </S>",
    "<S> the algorithm is true in exact arithmetic and relies on introducing new variables and corresponding equations , thereby converting the matrix into a banded matrix of larger size . </S>",
    "<S> linear complexity banded algorithms for solving linear systems and computing determinants on the larger matrix enable linear complexity algorithms for the initial semi - separable matrix as well . benchmarks provided illustrate the linear scaling of the algorithm .    </S>",
    "<S> semi - separable matrices , rybicki press algorithm , fast direct solver , fast determinant computation , exponential covariance , carma processes    15a23 , 15a15 , 15a09 </S>"
  ]
}