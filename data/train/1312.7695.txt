{
  "article_text": [
    "farfield narrowband source localization based on observed snapshots of a sensor array is a major problem in array signal processing @xcite , known also as direction of arrival ( doa ) estimation .",
    "the difficulty of the problem arises from the fact that the observed snapshots are nonlinear functions of the directions of interest . according to estimation schemes adopted",
    ", existing methods for the doa estimation can be classified into three categories : parametric , nonparametric and semiparametric , which are described as follows .",
    "_ parametric _ methods explicitly carry out parameter estimation using optimization or other methods .",
    "a prominent example is the nonlinear least squares ( nls ) method ( see , e.g. , @xcite ) , which adopts the least squares criterion and has a strong statistical motivation .",
    "however , nls admits the following two shortcomings : 1 ) it requires the knowledge of the source number which is typically unavailable , and 2 ) its global optimum can not be guaranteed with a practically efficient algorithm due to nonconvexity caused by the nonlinearity nature .",
    "either of them may greatly degrade the parameter estimation performance .",
    "music @xcite does the parameter estimation by studying the subspace of the data covariance matrix and is a large - snapshot realization of the maximum likelihood ( ml ) method in the case of uncorrelated sources .",
    "but it also requires the source number and does not have reliable performance when the number of snapshots is small or correlation exists between the sources .",
    "other subspace - based methods include esprit and their variants ( see @xcite for a complete review ) .",
    "in contrast , a _",
    "nonparametric _ method typically produces a _",
    "dense _ spectrum whose peaks are interpreted as source directions .",
    "so an alternative name _",
    "dense _ is also used .",
    "examples include conventional beamformer and mvdr ( or capon s method ) ( see e.g. , @xcite ) and recently introduced iterative adaptive approach ( iaa ) @xcite which eliminates to a large extent leakage of the beamformer and is robust to correlation of the sources . but it will be shown in this paper that iaa suffers from resolution limit , especially in the moderate / low snr regime . while the classification above is consistent with @xcite , music",
    "is sometimes categorized in the literature as a nonparametric / dense method by interpreting the plot of its objective function as its power spectrum whose peaks are the optima of the directions .",
    "_ semiparametric _ methods have been popular in the past decade which remove the direction variables in the observation model by parameter discretization and transform the nonlinear parameter estimation problem into a sparse signal recovery problem under a linear model , followed by some sparse signal recovery technique and support detection of the sparse solution . in particular , the continuous direction range is approximated by a set of discrete grid points under the assumption that the grid is fine enough such that any of the true sources lies on ( practically , close to ) some grid point .",
    "after that , the knowledge is exploited that each of the expanded vector of source signals [ composed of ( virtual ) source signals from candidate directions on the grid ] is a sparse signal since the grid size is greatly larger than the source number , and a sparse solution is sought after .",
    "finally , the directions are retrieved from the support of the sparse solution .",
    "consequently , the semiparametric methods are also named as _ sparse _ methods in contrast to _ dense_. in principle , a source will be detected once the estimated source signal / source power from some direction is nonzero . following from the literature of sparse signal representation ( ssr ) and later developed compressed sensing ( cs ) @xcite , @xmath0 norm minimization and other sparse signal recovery techniques",
    "have been widely used in the semiparametric methods ( see , e.g. , @xcite ) .",
    "however , their theoretical support based on ssr and cs can not be applied due to dense discretization . moreover ,",
    "the sparse recovery techniques usually require one or more practically unknown parameters , e.g. , the noise statistics , the source number or regularization parameters , etc .",
    "the semiparametric iterative covariance - based estimation ( spice ) method @xcite is a breakthrough of the semiparametric methods , in which covariance fitting criteria are adopted with sound statistical motivation , the source power and noise variance(s ) are estimated in a natural manner , no user - parameters are required and a connection to the @xmath0 norm minimization is shown . in principle , the semiparametric methods are approximation methods due to the discretization scheme adopted . furthermore , grid selection remains a major problem since 1 ) a coarse grid leads to a high modeling error and 2 ) too dense a grid is computationally prohibitive and might result in computational instability ( see , e.g. , @xcite ) . to alleviate the drawbacks of the discretization",
    ", preliminary results have been obtained in @xcite .",
    "overall , because of the inherent discretization scheme , the performance of semiparametric methods is dependent on the trade off between the discretization grid size and the computational workload .",
    "this paper aims at developing discretization - free techniques for doa estimation with an affordable computational workload in a common scenario of linear arrays , more specifically , uniform linear arrays ( ulas ) and sparse linear arrays ( slas ) .",
    "we consider stochastic source signals and the same covariance fitting criteria as in spice . by exploiting the hermitian toeplitz structure in the data covariance matrix",
    ", the covariance fitting problem is cast as semidefinite programming ( sdp ) and solved using off - the - shelf sdp solvers , e.g. , sdpt3 @xcite , in a polynomial time .",
    "a postprocessing technique is presented in this paper to retrieve , from the data covariance estimate , the parameters of interest including source locations , source powers and noise variance(s ) .",
    "the proposed method is a _ sparse _ method because it utilizes the same covariance fitting criteria of the semiparametric spice method and guarantees to produce a sparse parameter estimate . at the same time",
    ", it is a _ parametric _ method since it is proven to be equivalently solving a covariance fitting problem parameterized by the aforementioned parameters .",
    "therefore , the proposed method is named as sparse and parametric approach ( spa ) .",
    "the spa method differs from the existing sparse / semiparametric methods by no need of discretization . unlike the existing parametric methods ,",
    "spa is based on convex optimization and does not require the source number .",
    "theoretical analysis shows that spa is a large - snapshot realization of the ml estimation and is statistically consistent ( in the number of snapshots ) under uncorrelated sources .",
    "other merits of spa include improved resolution , applicability to arbitrary number of snapshots , robustness to correlation of the sources and no requirement of user - parameters .",
    "numerical simulations are carried out to verify our theoretical results and demonstrate the superior performance of spa compared to existing methods .",
    "though most , if not all , of the existing sparse methods can be applied to sensor arrays with arbitrary geometry , problems may occur when applied to the ula and sla cases as studied in this paper .",
    "in particular , their parameter estimates might suffer from some identifiability problem and not be truly sparse as demonstrated in this paper , which conflicts with the name _ sparse _ and decreases their resolution considerably . as a byproduct , a modified spice method , named as spice - pp , is presented to rectify the problem by incorporating the postprocessing technique presented in this paper .    in the single - snapshot case ,",
    "the parameter estimation problem studied in this paper is mathematically equivalent to spectral analysis @xcite , for which discretization - free methods have been developed recently in @xcite .",
    "it is noted that the results of @xcite are based on very different techniques .",
    "furthermore , @xcite and @xcite are mainly focused on the noise - free case ( the former on the ula case and the latter on the sla case in the language of this paper ) .",
    "@xcite studies the ula case in the presence of i.i.d .",
    "gaussian noise with known noise statistics .",
    "the spa method proposed in this paper can deal with all of the above scenarios without the knowledge of noise statistics . while this paper is focused on the array processing applications in which the multisnapshot case is of the main interest , it is still not clear whether the techniques in @xcite specialized for the single - snapshot case can be extended to other cases .",
    "notations used in this paper are as follows .",
    "@xmath1 , @xmath2 and @xmath3 denote the sets of real numbers , nonnegative real numbers and complex numbers , respectively .",
    "boldface letters are reserved for vectors and matrices . for an integer @xmath4 ,",
    "@xmath5 $ ] is defined as the set @xmath6 .",
    "@xmath7 denotes the absolute value of a scalar or cardinality of a set .",
    "@xmath8 , @xmath9 and @xmath10 denote the @xmath0 , @xmath11 and frobenius norms , respectively .",
    "@xmath12 , @xmath13 and @xmath14 are the matrix transpose , conjugate transpose and complex conjugate of @xmath15 , respectively .",
    "@xmath16 is the @xmath17th entry of a vector @xmath15 and @xmath18 is the @xmath19th entry of a matrix @xmath20 .",
    "unless otherwise stated , @xmath21 is a subvector of @xmath15 with the index set @xmath22 . for a vector @xmath15",
    ", @xmath23 is a diagonal matrix with @xmath15 being its diagonal .",
    "@xmath24 means @xmath25 for all @xmath17 .",
    "@xmath26 denotes the trace of a matrix @xmath20 . for positive semidefinite matrices @xmath20 and @xmath27 , @xmath28 means that @xmath29 is positive semidefinite .",
    "@xmath30 denotes expectation and @xmath31 is an estimator of @xmath32 . for notational simplicity",
    ", a random variable and its numerical value will not be distinguished .",
    "the rest of this paper is organized as follows .",
    "section [ sec : problem ] describes the problem of array processing with linear arrays .",
    "section [ sec : spa_ula ] presents the proposed spa method in the ula case followed by section [ sec : spa_sla ] on the sla case .",
    "section [ sec : property ] introduces theoretical properties of spa .",
    "section [ sec : connectionprior ] discusses its connections to existing methods .",
    "section [ sec : simulation ] presents our numerical simulations .",
    "section [ sec : conclusion ] concludes this paper .",
    "consider @xmath33 narrowband farfield sources @xmath34 , @xmath35 , impinging on a linear array of omnidirectional sensors from directions @xmath36 , @xmath35 .",
    "we are interested in estimation of the direction vector @xmath37 , known as the direction of arrival ( doa ) estimation problem @xcite .",
    "denote @xmath38 , @xmath35 .",
    "then we can equivalently estimate @xmath39 since the relation @xmath40 is one - to - one .",
    "@xmath41 is called the frequency parameter and its meaning will be clarified later . in this paper , we concern only with the estimation of @xmath41 for convenience . according to @xcite , the time delays at different sensors can be represented by simple phase shifts , leading to the observation model : where @xmath42 indexes the snapshot and @xmath4 is the snapshot number , @xmath43 , @xmath44 and @xmath45 denote the observed snapshot , the vector of source signals and the vector of measurement noise at snapshot @xmath42 , respectively , and @xmath46 is the number of sensors ( some notations will be redefined in the sla case ) .",
    "@xmath47 is the so - called array manifold matrix and @xmath48 is the steering vector of the @xmath49th source which is determined by the geometry of the sensor array and will be given later .",
    "more compactly , ( [ formu : observation_model1 ] ) can be written into where @xmath50 , and @xmath51 and @xmath52 are similarly defined .",
    "the number of sources @xmath33 is assumed unknown in this paper .",
    "so , the objective of the array processing is to estimate the unknown parameter @xmath41 ( or equivalently , the vector of doas @xmath53 ) given the sensor measurements @xmath54 and the mapping @xmath55 .",
    "we introduce some standard assumptions for the problem formulation and solution .",
    "@xmath56 , @xmath57 , are assumed to be spatially and temporarily white , i.e. , where @xmath58 is the noise variance parameter and @xmath59 is a delta function that equals @xmath60 if @xmath61 or @xmath62 otherwise .",
    "the source signals and the noise are assumed to be uncorrelated with each other .",
    "moreover , assume that the source signals are uncorrelated spatially and temporarily , i.e. , where @xmath63 denotes the source power parameter .",
    "under the assumptions above , the data snapshots @xmath64 are uncorrelated with each other and have the covariance matrix it is worthy noting that the spatial uncorrelatedness of the sources may not be satisfied in practice , i.e. , two sources @xmath65 and @xmath66 can be correlated or even coherent ( i.e. , completely correlated ) .",
    "however , the method proposed in this paper will be shown to be robust to this assumption .",
    "both uniform and sparse linear arrays will be studied in this paper . in the ula case ,",
    "the sensors are uniformly spaced with a spacing of @xmath67 , where @xmath68 denotes the wavelength of the sources . for an @xmath46-element ula , the steering vector @xmath48 of source @xmath49 has the following form with @xmath69 : it is clear that @xmath70 is the frequency of the uniformly sampled complex sinusoid @xmath48 , a reason for why @xmath41 is called the frequency parameter .",
    "a well - known result is that up to @xmath71 sources can be detected using an @xmath46-element ula ( see , e.g. , @xcite ) .",
    "an sla can be considered as a ula with `` missing '' sensors , i.e. , an sla takes only a subset , say @xmath72 , of the sensors of a ula . thus an sla",
    "can be represented by its sensor index set @xmath73 . without loss of generality , we assume that @xmath72 is sorted ascendingly with @xmath74 and @xmath75 , where @xmath76 denotes the array size ( otherwise , we can redefine @xmath72 , say @xmath77 , such that @xmath78 , @xmath79 $ ] , and let @xmath80 ) . then the steering vector of the sla @xmath72 for source @xmath49 , denoted by @xmath81 , is denote @xmath82 a selection matrix such that the @xmath17th row of @xmath83 contains all @xmath62s but a single @xmath60 at the @xmath84th position .",
    "it is clear that let an sla defined by @xmath85 is called the coarray of @xmath72 .",
    "@xmath72 is called a redundancy array if @xmath85 defines a ula , i.e. , @xmath86 .",
    "it is obvious that a ula is a redundancy array .",
    "the maximum number of sources detectable using the array @xmath72 is determined by its coarray @xmath85 @xcite . in particular",
    ", a redundancy array can detect up to @xmath71 sources like a ula . for a non - redundancy sla",
    ", the maximum number of sources detectable will be less than @xmath71 .",
    "it is noted that redundancy slas are quite common and there generally exists such an array satisfying that @xmath87 according to @xcite .",
    "the sla @xmath88 is a redundancy array , where @xmath89 and @xmath90 .",
    "so maximally @xmath91 sources can be detected using this @xmath92-element array .",
    "since a ula can detect up to @xmath71 sources , the condition @xmath93 can be considered as _ a priori _ knowledge while the exact value of @xmath33 is unavailable .",
    "the covariance of the data snapshots @xmath54 is given in ( [ formu : ycovariance ] ) under the assumptions specified in subsection [ sec : assmptions ] .",
    "denote by @xmath94 the sample covariance .",
    "when @xmath95 and @xmath96 are both invertible we consider the following covariance fitting criterion for the purpose of parameter estimation ( see @xcite and the references therein ) : @xmath97 exists in the presence of noise , i.e. , @xmath98 for @xmath99 . then @xmath100 exists with probability one if @xmath101 .",
    "according to @xcite , the minimization of the criterion in ( [ formu : criterion1 ] ) is a large - snapshot realization of the ml estimator . in the case where @xmath95 is singular ( it happens when @xmath102 ) we consider an alternative criterion : which has been studied in @xcite .",
    "we defer the latter case to subsection [ sec : tlessm ] .",
    "the covariance fitting criteria above exploit the assumption that the sources are uncorrelated which results in the expression of @xmath96 in ( [ formu : ycovariance ] ) .",
    "however , a theoretical explanation is provided in @xcite to show that the criteria are robust to correlations of the sources . moreover , according to @xcite they are connected to the @xmath0 norm minimization which is known to be robust to the correlations .",
    "consequently , such robustness property is maintained in the method proposed in this paper which utilizes the same criteria .",
    "a simple calculation shows that it is challenging to minimize @xmath103 with respect to the unknown parameters @xmath41 , @xmath104 and @xmath105 due to their nonlinear relation to @xmath96 by ( [ formu : ycovariance ] ) .",
    "we propose to estimate @xmath96 firstly by reparameterization and then determine the parameters of interest .",
    "let it is easy to see that @xmath106 and @xmath107 .",
    "moreover , @xmath108 is thus a ( hermitian ) toeplitz matrix which is determined by @xmath46 complex numbers and can be written as @xmath109 for some @xmath110 , where      it follows from ( [ formu : toeplitz ] ) that the characterization captures the structure of @xmath96 under the constraints @xmath112 and @xmath113 .",
    "further observations reveal that @xmath96 is inherently determined by @xmath114 numbers ( @xmath46 for the diagonal and the other @xmath71 for the off diagonal ) .",
    "however , @xmath115 numbers ( @xmath46 in @xmath116 and the other @xmath46 in @xmath105 ) have been used in the above expression of @xmath96 ( @xmath117 for the diagonal and @xmath71 for the off diagonal ) . as a result ,",
    "redundancy exists along the diagonal of @xmath96 .",
    "the effect of the redundancy is twofold . on one hand",
    ", it will cause an identifiability problem , which will be tackled in subsection [ sec : postproc ] , that in general @xmath116 , @xmath105 can not be uniquely identified from @xmath96 without accounting for additional information except @xmath112 and @xmath113 .",
    "it means that the solution @xmath118 of the sdps to be presented can not be directly used as the final estimate of the noise variance . on the other hand ,",
    "the adoption of one redundant variable enables us not to impose the nonconvex rank - deficiency constraint on @xmath119 to characterize @xmath96 ( it will be clarified in subsection [ sec : postproc ] ) .",
    "however , the redundancy problem will not affect the estimation of @xmath96 which is our current focus .      with the characterization of @xmath96 in ( [ formu : r_in_u ] ) the minimization of @xmath103 is equivalent to then we can show the following equivalences : so the problem in ( [ formu : problem_tlarge ] ) can be formulated as an sdp and thus is convex . as the result , @xmath96 can be estimated by solving the sdp with its estimate given by @xmath120 , where @xmath121 is the solution of the sdp .",
    "when @xmath102 , @xmath95 ceases to be nonsingular and the criterion in ( [ formu : criterion2 ] ) is used which can be written into hence , an sdp similar to ( [ formu : sdp_nlarge ] ) can be formulated as follows :      it is reasonable to assume that the noise variances @xmath122 , @xmath99 , are equal in some scenarios .",
    "though the formulations in the last subsection can be applied to such a case by imposing the constraint @xmath123 , simpler formulations in fact exist .",
    "in such a case , @xmath124 with @xmath125 . therefore , the covariance @xmath96 has a toeplitz structure and the characterization captures its structure without redundancy under the constraint @xmath112 for some @xmath110 . note that the @xmath119 here is the same as that in ( [ formu : r_in_u ] ) off the diagonal but different on the diagonal , i.e. , the two @xmath116 s are the same except the first entry . following from the similar procedures as in the last subsection , similar sdps can be formulated . in particular , when @xmath101 we have when @xmath102 , note that the constraint @xmath112 has been implicitly included in the constraints in ( [ formu : sdp_nlarge_identical ] ) and ( [ formu : sdp_nsmall_identical ] ) .",
    "the simplified sdp formulations will lead to faster computations in practice . by solving one of the sdps",
    ", @xmath126 is obtained as @xmath127 given the solution @xmath128 . for notational convenience ,",
    "we say @xmath129 in this case .",
    "in fact , note that ( [ formu : r_equalvar ] ) , ( [ formu : sdp_nlarge_identical ] ) and ( [ formu : sdp_nsmall_identical ] ) can be obtained from ( [ formu : r_in_u ] ) , ( [ formu : sdp_nlarge ] ) and ( [ formu : sdp_nsmall ] ) , respectively , by setting @xmath130 .      after obtaining @xmath126 ,",
    "the following task is to estimate the parameters @xmath41 , @xmath104 and @xmath105 by writing it back into the form of ( [ formu : ycovariance ] ) . to do this",
    ", we decompose @xmath126 into where @xmath131 is the estimate of @xmath132 in ( [ formu : c ] ) and @xmath133 is the noise covariance estimate .",
    "such @xmath134 always exists according to the way @xmath126 is given , however , it is generally not unique . in particular , for any @xmath135 satisfying that @xmath136 , @xmath137 leads to one realization of the decomposition , which in fact also enumerates all possible realizations .",
    "we utilize the prior knowledge that @xmath93 to make the decomposition unique as follows .",
    "it follows from @xmath93 that @xmath107 .",
    "therefore , it is natural to impose that @xmath138 , i.e. , @xmath139 is rank - deficient .",
    "a direct result is that @xmath140 is an eigenvalue of @xmath141 .",
    "then by @xmath136 we see that and thus the decomposition is unique , where @xmath142 denotes the minimum eigenvalue . )",
    "can be done if we have only @xmath126 rather than @xmath128 and @xmath118 . to see this ,",
    "let @xmath143 be the transpose of the first row of @xmath126 .",
    "then @xmath144 and @xmath145 is obtained as the diagonal of @xmath126 minus @xmath146 . ]    the postprocessing is used to separate sources and noise in the estimated covariance matrix such that the source part can be represented by as few sources as possible based on the minimum description length principle @xcite ( see the next subsection for clarity ) .",
    "in fact , the idea of postprocessing has been studied in the literature for a special case where @xmath126 is a toeplitz matrix as in the case of equal @xmath111 ( see , e.g. , ( * ? ? ? * section 4.9.2 ) ) .",
    "it is noted that the postprocessing is very important in spa , without which the final parameter estimate is generally not unique and does not have the statistical properties that will be shown in section [ sec : property ] .",
    "even worse , the frequency estimate of spa can cease to be sparse . to see this ,",
    "suppose that @xmath141 has full rank ( this is generally the case in the presence of noise ) .",
    "choose @xmath147 arbitrarily and let @xmath148 .",
    "it follows that the residue @xmath149 which still has the toeplitz structure .",
    "then we can choose @xmath150 and @xmath151 similarly based on the residue .",
    "the process can be repeated infinitely many times and results in infinitely long vectors @xmath41 and @xmath104 .",
    "[ rem : postproc ]      the remaining task is to retrieve the frequency estimate @xmath152 and the power estimate @xmath153 given @xmath154 , which is based on the following classical vandermonde decomposition lemma for positive semidefinite toeplitz matrices ( see , e.g. , @xcite ) .",
    "any positive semidefinite toeplitz matrix @xmath155 can be represented as where @xmath156 , @xmath157 for @xmath158 $ ] , and @xmath159 . moreover , the representation is unique up to permutation of elements of @xmath41 and @xmath104 if @xmath160 . @xmath161",
    "[ lem : toeplitz ]    it follows from lemma [ lem : toeplitz ] that @xmath152 and @xmath153 can be uniquely determined given @xmath154 since @xmath138 . in practice , @xmath152 and @xmath153 can be obtained as follows .",
    "given @xmath162 , it is easy to show that since @xmath163 , where @xmath164 takes all but the first rows of the matrix @xmath165 which denotes the complex conjugate of @xmath166 .",
    "so we build a system of @xmath114 equations that is linear in @xmath153 whose length is maximally @xmath71 , where each column of the coefficient matrix corresponds to a uniformly sampled sinusoid ( after permutation of rows ) .",
    "according to @xcite , prony s method can be applied to this type of systems to efficiently solve @xmath152 and @xmath153 .",
    "in particular , @xmath152 is firstly obtained from zeros of a polynomial which is obtained by solving a linear system involving only @xmath167 .",
    "after that , @xmath153 is solved from ( [ formu : linsys ] ) .",
    "readers are referred to @xcite for the detailed procedure .",
    "the proposed spa algorithm for the array processing with a ula is presented in algorithm [ alg : spa ] .",
    "the covariance matrix @xmath96 is firstly estimated by solving an sdp .",
    "then the postprocessing procedure is carried out for @xmath126 to resolve an identifiability problem that exists in the solution of the sdp ( the noise variance is estimated at this step ) .",
    "finally , the frequency and the power are solved using prony s method . to carry out the parameter estimation , spa requires only the data snapshots @xmath54 of the sensor array without any other user parameters .",
    "more properties of spa will be presented in section [ sec : property ] .",
    "input : observed snapshots @xmath54 .    1 .",
    "estimate @xmath96 by solving the solution @xmath121 of an sdp ; 2 .",
    "postprocess @xmath126 to obtain @xmath167 and @xmath145 via @xmath168 and @xmath169 ; 3 .",
    "solve @xmath152 and @xmath153 from ( [ formu : linsys ] ) using prony s method .",
    "output : parameter estimator @xmath170 .",
    "[ alg : spa ]    in general , spa can not correctly determine the true number of sources @xmath33 but provides additionally spurious sources .",
    "this is because that we do not assume in spa any knowledge of the source number or the noise variance(s ) .",
    "consequently , spa solves the problem as in the worst case where up to @xmath71 sources can be present . in fact , the source number estimation problem itself is very difficult which is known as model order selection @xcite , and lacking guarantees on the estimated source number seems to be a common feature of sparse methods , especially when no prior knowledge mentioned above is available ( see , e.g. , @xcite ) .",
    "a positive side of spa is that it has strong statistical properties which will be shown in section [ sec : property ] , and theoretically the powers of the spurious sources can be very close to zero under sufficient snapshots or appropriately low snr , which enables the spurious sources to be distinguished from the real ones .",
    "currently , methods have been proposed to remove spurious sources by modifying the solution of a sparse method .",
    "for example , intuitive thresholding is used in @xcite and information criteria - based methods are presented in @xcite . in future studies , we may seek to incorporate model order selection in spa such that the source number can be estimated automatically together with the parameters but it is beyond the scope of this paper .",
    "in this section we extend spa to the sla case . with respect to an sla @xmath72 , denote the steering matrix by @xmath171 , the data snapshots by @xmath172 , the covariance matrix by @xmath173 and the sample covariance by @xmath174 , where @xmath175 denotes the noise variance parameter .",
    "it follows from ( [ formu : steervector_sla ] ) that @xmath176 and then @xmath177 , where the toeplitz matrix @xmath178 for some @xmath110 .",
    "a careful study of @xmath179 reveals that i.e. , the entries of @xmath179 are specified by the coarray @xmath85 defined in ( [ formu : coarray ] ) .",
    "in this paper we are mainly interested in the case where the sla @xmath72 is a redundancy array . as in the ula case , @xmath93 is considered as _ a priori _ knowledge according to subsection [ sec : lineararray ] .",
    "the matrix @xmath179 contains all elements of @xmath116 explicitly by ( [ formu : entry_sla ] ) .",
    "it implies that the relation @xmath180 is one - to - one .    given a redundancy sla @xmath88",
    ", we have @xmath181 and @xmath182 , where all elements of @xmath116 are contained .",
    "it follows that the covariance matrix @xmath183 can be characterized as under the constraints @xmath112 and @xmath184 .",
    "consider similar covariance fitting criteria as in the ula case , i.e. , the minimization of @xmath185 when @xmath186 and @xmath187 otherwise .",
    "then spa can be extended to the sla case .",
    "in particular , when @xmath186 we obtain the following sdp : when @xmath188 , it is    in the case of equal noise variances , @xmath183 can be characterized as @xmath189 .",
    "then similar sdps can be formulated as in ( [ formu : sdp_nlarge_miss ] ) and ( [ formu : sdp_nsmall_miss ] ) by simply setting @xmath190 .",
    "note that the problem dimension in such a case can not be further reduced as in the ula case since @xmath191 does not imply @xmath112 .",
    "note that the same identifiability problem exists in the solution @xmath192 of the sdps above . to resolve the problem ,",
    "the same procedures can be carried out as in the ula case by exploiting that @xmath138 . then the parameter estimate @xmath193 can be obtained .",
    "when the sla @xmath72 is not a redundancy array , i.e. , the coarray @xmath85 is not a ula , spa presented above can be applied straightforwardly . in such a case ,",
    "it is natural to require that @xmath194 , where @xmath195 denotes the maximum number of sources detectable using the non - redundancy sla .",
    "however , the introduced implementation of spa can only use the information up to @xmath93 , which should be a waste of knowledge . a thorough study on exploitation of the full information",
    "should be investigated in the future but is beyond the scope of this paper .",
    "as its name suggests , spa is a _ sparse _ and _ parametric _ method .",
    "it carries out the optimization by reparameterization and thus is a parametric method .",
    "the length of its frequency estimator @xmath152 is maximally @xmath71 .",
    "since this is an important result of this paper , we state it formally in the following theorem .",
    "the length of the frequency estimator @xmath152 of spa is maximally @xmath71 .",
    "@xmath161      we consider ulas and redundancy slas in this subsection , or collectively , redundancy arrays .",
    "notice that dimensions of the parameter estimators @xmath152 and @xmath153 may be different from the true dimension @xmath33 . to discuss statistical properties of the spa estimator",
    ", the dimension problem should be resolved first .",
    "notice that the proposed spa is equivalently assuming @xmath196 ( the worst case ) with the knowledge @xmath93 .",
    "then we expand both the true parameter and its estimator to the same dimension .",
    "define for a vector @xmath197 of dimension no more than @xmath71 , where @xmath198 is arbitrary .",
    "it is easy to see that @xmath199 and @xmath200 are physically equivalent since all of the added virtual sources have zero powers .",
    "then we have the following results .",
    "assume that @xmath201 and @xmath202 are uncorrelated , @xmath203 and @xmath204 for @xmath205 .",
    "moreover , assume that the sensor array is a redundancy array and @xmath93 .",
    "then the parameter estimator @xmath170 of spa is statistically consistent ( in @xmath4 ) . and",
    "@xmath105 denote respectively @xmath206 and @xmath207 in the sla case , or @xmath208 and @xmath209 in the case of equal noise variances .",
    "it is the same for theorems [ thm : aml ] and [ thm : efficiency ] . ]",
    "[ thm : consistency ]    without loss of generality , we consider only the ula case .",
    "the proof is based on the observation that the parameter estimator @xmath170 can be uniquely determined given the covariance estimator @xmath126 .",
    "suppose that the true parameter value is @xmath210 .",
    "as @xmath211 , @xmath95 approaches the true covariance @xmath212 . then by ( [ formu : criterion1 ] ) the sdp of spa admits a unique minimizer @xmath213 of @xmath96 , which determines the unique parameter estimate @xmath210 given @xmath93 .",
    "assume that @xmath201 and @xmath202 are uncorrelated and both are i.i.d .",
    "circular gaussian with means zero and covariance matrices @xmath214 and @xmath215 , respectively .",
    "moreover , assume that the sensor array is a redundancy array and @xmath93 .",
    "then @xmath216 is asymptotically an ml estimator of @xmath217 .",
    "[ thm : aml ]    consider first the ula case .",
    "since @xmath170 can be uniquely determined given @xmath126 , the spa estimator is equivalent to solving the following ( nonconvex ) optimization problem : are removed in spa as well as the corresponding entries of the solution of @xmath41 . ] on the other hand , the data snapshots @xmath218 are i.i.d .",
    "gaussian with mean zero and covariance @xmath96 under the assumptions .",
    "according to the extended invariance principle ( exip ) @xcite and the derivations in @xcite , the global minimizer of ( [ formu : spa_nonconvex ] ) is a large - snapshot realization of the ml estimator of @xmath217 .",
    "similarly , the spa estimator in the redundancy sla case is the global minimizer of the following problem : then the same result follows .",
    "theorem [ thm : aml ] states that @xmath216 is asymptotically an ml estimator of @xmath217 under some technical assumptions .",
    "theorem [ thm : consistency ] shows that this estimator is also consistent . since",
    ", asymptotically , the power estimator @xmath219 may lie on the boundary of @xmath220 and thus the asymptotic normality of @xmath216 does not hold directly .",
    "however , it indeed holds in the case of @xmath196 where the true parameter @xmath221 is an interior point of @xmath220 .",
    "so we have the following theorem .    under the assumptions of theorem [ thm : aml ] and @xmath196 with @xmath222 and @xmath223 , the spa estimator @xmath170 is asymptotically normal with asymptotic unbiased mean @xmath210 and covariance @xmath224 , where @xmath225 denotes the fisher information matrix of the parameter .",
    "it follows that @xmath170 is statistically asymptotically efficient .",
    "[ thm : efficiency ]    the result follows from theorems [ thm : consistency ] and [ thm : aml ] and the properties of consistent ml estimators .",
    "the asymptotic covariance matrix @xmath224 is usually referred to as the crammer - rao lower bound ( crlb ) , which can be computed following from @xcite and will be omitted in this paper . alternatively , its numerical results will be presented in section [ sec : simulation ] .",
    "the spa method proposed in this paper is closely connected to spice in @xcite .",
    "the two methods adopt the same covariance fitting criteria . roughly speaking",
    ", spice can be considered as a discretized version of spa when applied to ulas and slas .",
    "however , the following two main differences make their performances very different .",
    "one is that spa is a parametric method while spice is a semiparametric method . in particular ,",
    "the covariance @xmath96 is approximated in spice by discretizing the continuous range @xmath226 of the frequency .",
    "consider the ula case as an example .",
    "denote @xmath227 the discretized sampling grid of the frequency and @xmath228 the corresponding power vector , where @xmath229 denotes the grid size",
    ". then @xmath96 is expressed as which is a linear function of @xmath230 . with ( [ formu : rgrid ] ) , the covariance fitting criterion ( [ formu : criterion1 ] ) or ( [ formu : criterion2 ] ) becomes a convex function of @xmath230 and is optimized in @xcite via an iterative algorithm , named as spice .",
    "note that the characterization of @xmath96 in ( [ formu : rgrid ] ) is only an approximation since there is no guarantee that the true frequencies lie on the grid @xmath231 .",
    "thus the approximation error ( or modeling error ) , which depends on the grid density , is one potential reason causing estimation inaccuracy of spice .",
    "the other difference is that the parameter estimate of spice is obtained directly from the solution @xmath232 of the covariance fitting optimization problem while an additional postprocessing procedure is carried out in spa . in particular ,",
    "a source at @xmath233 is detected in spice once @xmath234 and the frequency estimate is constrained on the grid , which will be referred to as the on - grid issue hereafter and becomes a second potential reason causing inaccuracy of spice .",
    "furthermore , the parameter estimate without the postprocessing is generally not unique according to remark [ rem : postproc ] due to an identifiability problem which also exists in the solution @xmath232 of spice .",
    "this can be a third potential reason causing inaccuracy of spice .",
    "in fact , the spice estimate might not be _ sparse _ since the support of @xmath235 can be as large as its dimension @xmath229 according to remark [ rem : postproc ] , which will be numerically verified in section [ sec : simulation ] .",
    "in summary , there are three potential reasons that may cause inaccuracy to the parameter estimation of spice , including the modeling error , the on - grid issue and the identifiability problem , rendering that spice does not possess the sparse and the statistical properties of spa presented in section [ sec : property ] .",
    "the first reason corresponds to the first difference and is introduced by the discretization , which can be alleviated by adopting a dense sampling grid but at the cost of more expensive computations .",
    "the last two are related to the second difference .",
    "inspired by spa , we present spice - pp to resolve them using the postprocessing technique in the next subsection .",
    "before proceeding to spice - pp , we compare computational costs of spice and spa .",
    "we consider only the dominant part in the following comparison , i.e. , the computation of @xmath236 or @xmath237 is excluded for both spice and spa which takes @xmath238 or @xmath239 flops , respectively , and the postprocessing and parameter solving are also excluded for spa which take @xmath240 flops .",
    "spice is an iterative algorithm whose computational complexity equals the complexity per iteration times the number of iterations , i.e. , @xmath241 in the ula case and @xmath242 in the sla case , where @xmath22 denotes the number of iterations which is hard to quantify and empirically observed to vary in different scenarios . for spa",
    "we adopt an off - the - shelf sdp solver , sdpt3 @xcite , where the interior - point method is implemented to solve the sdp .",
    "denote by @xmath243 and @xmath244 the variable size and dimension of the positive semidefinite matrix in the semidefinite constraint of an sdp , respectively .",
    "then the sdp can be solved in @xmath245 flops in the worst case according to @xcite . in the ula case",
    ", @xmath243 is on the order of @xmath246 and @xmath247 is proportional to @xmath46 .",
    "it follows that the complexity of spa is @xmath248 . in the sla case ,",
    "@xmath243 and @xmath247 are on the order of @xmath249 and @xmath250 , respectively .",
    "then the complexity is @xmath251 since @xmath252 . without surprise , the order on @xmath46 or @xmath253 for spa is higher than that for spice . but",
    "the positive side is that the complexity of spa does not depend on the grid size @xmath229 which is typically much greater than @xmath46 in array processing . as a result",
    ", spa can be possibly faster than spice if a dense sampling grid ( large @xmath229 ) is adopted in spice for obtaining high accuracy , and vise versa .",
    "note that the order on @xmath46 or @xmath253 might be decreased in the future for both spa and spice if there are more sophisticated algorithms but the linear dependence on @xmath229 for spice probably can not due to the discretization ( similar results hold for other discretization - based methods ) .",
    "like spa , we modify spice and obtain the parameter estimate within three steps .",
    "firstly , @xmath96 is estimated as given the solution @xmath232 of the original spice .",
    "then the postprocessing is applied to decompose @xmath126 into @xmath254 by exploiting @xmath93 .",
    "finally , the parameter estimate is obtained via the vandermonde decomposition of @xmath154 .",
    "the modified spice algorithm is named as spice with the postprocessing , abbreviated as spice - pp .",
    "note that the frequency estimate of spice - pp is no long constrained on the grid .",
    "it is also noted that this postprocessing technique can be possibly applied to other covariance - based methods .      in the limiting single - snapshot case ,",
    "i.e. , when @xmath255 , the array processing problem is mathematically equivalent to spectral analysis @xcite . for the latter topic ,",
    "discretization - free techniques have been recently proposed in @xcite based on atomic norm minimization ( see @xcite ) which , also called total variation norm in @xcite , is a continuous version of the @xmath0 norm .",
    "it is noted that the spa method proposed in this paper can also be applied to the single - snapshot case .",
    "in fact , the sdps in ( [ formu : sdp_nsmall ] ) and ( [ formu : sdp_nsmall_identical ] ) can be further simplified in such case . given ( [ formu : sdp_nsmall_identical ] ) as an example .",
    "it follows from @xmath256 that @xmath257 .",
    "so , an alternative formulation of ( [ formu : sdp_nsmall_identical ] ) will be it is interesting to note that , though obtained from a very different technique , ( [ formu : sdp_n1 ] ) is quite similar to the sdp formulations in @xcite .",
    "a detailed investigation of the relation is beyond the scope of this paper and will be posed as a future work since this paper is focused on the array processing applications in which the multisnapshot case is of the main interest .",
    "in this section we illustrate the performance of the proposed spa method and compare it with existing methods via numerical simulations .",
    "the methods that we consider include spice @xcite , spice - pp , iaa @xcite , music and ogsbi - svd @xcite .",
    "spice is a semiparametric method which can be roughly considered as a discretized version of spa as described in subsection [ sec : connectionspice ] .",
    "spice - pp is a modified version of spice by incorporating the postprocessing technique presented in this paper .",
    "iaa is an enhanced nonparametric method .",
    "music is a classical subspace - based parametric method .",
    "ogsbi - svd is a semiparametric method for off - grid doa estimation .",
    "the information of source number , @xmath33 , is required in music but not in the other methods . since spa and",
    "spice operate in different manners in the cases of equal / different noise variances , ` + ' is used to indicate the case when the equal noise variances assumption is imposed .",
    "for example , spa+ refers to spa with the assumption . without ambiguity",
    ", `` spa '' can refer to either the collectively called spa technique or the spa method with different noise variances ( in contrast to spa+ ) hereafter ( similarly for the use of `` spice '' ) .",
    "some setups of the algorithms above are as follows .",
    "the sdps of spa are implemented using cvx with the sdpt3 solver @xcite .",
    "spice is implemented as in @xcite and terminated when the relative change of the objective function value in two consecutive iterations falls below @xmath258 or the maximum number of iterations , set to 500 , is reached .",
    "iaa is terminated if the relative change of the @xmath11 norm of the power vector in two consecutive iterations falls below @xmath258 or the maximum number of iterations , set to 500 , is reached .",
    "ogsbi - svd is implemented as in @xcite except that the source number is unknown ( see details in @xcite ) .",
    "we compare spectra of the aforementioned methods in this subsection . in our simulation , we consider @xmath259 uncorrelated / coherent sources with power @xmath260 from directions specified by the frequency vector @xmath261 . a ula with @xmath262",
    "is used to receive the signals .",
    "each of the source signals is randomly generated with constant amplitude and random phase , which is usually the situation in communications applications @xcite .",
    "zero - mean white circular gaussian noise is added with the noise variance @xmath263 . the signal to noise ratio ( snr ) is defined as the ratio of the minimum source power to the noise variance ( in db ) , i.e. , @xmath264 .",
    "the grid number is set to 500 for spice and iaa .",
    "our simulation results of uncorrelated sources are presented in fig .",
    "[ fig : spectra ] with respect to different settings of @xmath265 , where some curves are omitted for better visual effects . in the case of large snapshots , e.g. , @xmath266 as shown in figs .",
    "[ fig : spectra1 ] and [ fig : spectra2 ] , we observe the following phenomena .",
    "iaa produces a dense spectrum and exhibits significant resolution degradation in the moderate / low snr regime .",
    "it can not separate the first two sources in fig . [",
    "fig : spectra2 ] .",
    "spice+ produces a sparse spectrum which contains only a few spikes in the high snr regime , e.g. , @xmath267db .",
    "however , it produces a dense spectrum due to the identifiability problem as addressed in subsection [ sec : connectionspice ] in the moderate / low snr regime , e.g. , @xmath268db , where it returns a zero estimate of the noise variance . unlike spice+ , spice always produces a dense spectrum whenever the snr is ( its spectra are omitted in fig .",
    "[ fig : spectra ] ) . without surprise ,",
    "the spa method proposed in this paper always produces a sparse spectrum .",
    "small spurious spikes exhibit due to the presence of noise and absence of the knowledge of source number and the noise level . by using the postprocessing technique presented in this paper",
    "both spice+-pp and spice - pp produce sparse spectra , and their differences from spa+ ( or spa ) are caused by the modeling error of spice as described in subsection [ sec : connectionspice ] . moreover , spice+ and spice+-pp have the same spectrum in the high snr regime since the postprocessing does not alter the spectrum when spice+ has already produced a sparse spectrum .",
    "this point will be revisited later .",
    "the limiting case @xmath269 with a very low snr ( @xmath270db ) is studied in fig .",
    "[ fig : spectra3 ] , where the true covariance matrix is adopted to implement spa , spice and music .",
    "iaa is not considered in this scenario .",
    "it is shown that spa ( similarly for music ) can exactly localize the three sources , which verifies the conclusion of theorem [ thm : consistency ] that spa is statistically consistent .",
    "spice+ has low resolution in the low snr regime due to the identifiability problem and can not separate the first two sources . due to the modeling error of spice ,",
    "spice+-pp is not consistent as well .",
    "though this paper is mainly focused on the case of moderate / large snapshots , it is noted that spa can be applied to the case of small or even a single snapshot as shown in fig .",
    "[ fig : spectra4 ] where music fails .",
    "[ fig : spectra_coh ] presents simulation results of coherent sources , where source 3 is exactly a replica of source 1 .",
    "it is shown that the proposed spa method has consistently good performance in the presence of complete correlation due to the adopted covariance fitting criterion as shown in @xcite .",
    "in contrast , iaa has low resolution as in the case of uncorrelated sources .",
    "music typically misses coherent sources .",
    "spice tends to miss coherent sources as well in the moderate / low snr regime .",
    "finally , note that the power estimates of the coherent sources are attenuated in spa , the reason of which should be investigated in the future .",
    "quantitative comparisons will be carried out in this subsection to demonstrate advantages of our discretization - free spa method compared to spice .",
    "readers are referred to @xcite for performance comparisons of spice with iaa and music . unlike spa",
    ", spice might produce a dense spectrum as the nonparametric methods .",
    "the frequency estimate of spice is obtained using the peaks of the spectrum following from @xcite . to illustrate effects of the discretization adopted in spice ,",
    "three discretization levels are considered with the grid size @xmath271 , respectively . for convenience ,",
    "the spice algorithm adopting the three discretization schemes will be referred to as spice1 , spice2 and spice3 , respectively .",
    "the ` + ' symbol will be used as before .",
    "metrics recorded include mean squared error ( mse ) and cpu time usage .",
    "the mse of the frequency estimation is computed as @xmath272 and then averaged over a number of monte carlo runs , where @xmath273 denotes the frequency estimate which is obtained by keeping the associated largest @xmath33 entries of the power estimate @xmath153 .",
    "the crlb is commonly used as a benchmark when evaluating the performance of various estimators though it is a lower bound for only unbiased estimators .",
    "note also that to compute the crlb requires the knowledge of @xmath33 which is not used in spa and spice .",
    "so , there might exist a gap between the crlb and the performance of spa or spice that we study .",
    "the simulations study both the ula and sla cases and are focused on uncorrelated sources .      _ experiment 1 _ studies performance variation with respect to the snr .",
    "we consider a ula with @xmath262 . without loss of generality ,",
    "@xmath274 uncorrelated sources impinge on the array with ( off - grid ) frequencies @xmath275 and @xmath276 and unit powers .",
    "notice that each frequency is a third grid interval away from the nearest grid point for spice",
    ". since the best frequency estimate for a given source is the nearest grid point , the mse of the frequency estimation of spice is lower bounded by @xmath277 regardless of the snr .",
    "the number of snapshots is set to @xmath266 and the snr varies in @xmath278db .",
    "200 monte carlo runs are used for each algorithm to obtain the metrics , where the source signals and the noise are both i.i.d .",
    "[ fig : mse_ula ] plots mses of the simulation results , where the two cases of equal and different noise variances are separately presented to provide a better illustration .",
    "spice has a better performance with a finer discretization but lower bounded by some constant as mentioned above .",
    "to the contrary , the mses of the spa methods improve constantly with the snr and gradually approach the crlbs .",
    "both the spa methods and the spice methods have similar performance trends in the two cases of equal and different noise variances .",
    "however , spice - pps perform differently . in the former case , spice+-pps and spice+s coincide in the high snr regime since they produce the same sparse spectra as shown in subsection [ sec : spectra ] . in the latter case , spice - pps outperform the associated spices when the snr is larger than some threshold thanks to the postprocessing technique presented in this paper .",
    "but when the snr is sufficiently high , the modeling error caused by the discretization dominates the total uncertainties and further performance improvement is impossible . on the other hand , in the moderate / low snr regime where the measurement noise dominates the uncertainties , spice - pp coincides with spa as expected .",
    "note that the bad performances of spice2 + -pp and spice3 + -pp at @xmath279db are caused by very few outliers ( 1 and 4 trials , respectively , out of 200 ) , where spice+ might not converge within 500 iterations and result in a less accurate @xmath126 that is used for parameter estimation .",
    "finally , notice that spice can possibly outperform spa in the snr range @xmath280db ( depending on the discretization level ) , which will be discussed in subsection [ sec : discussion ] .    , @xmath274 uncorrelated sources with @xmath281 and @xmath282 , and @xmath266 .",
    "the horizontal dashed lines are lower bounds of the spices due to the discretization.,title=\"fig:\",width=336 ] , @xmath274 uncorrelated sources with @xmath281 and @xmath282 , and @xmath266 .",
    "the horizontal dashed lines are lower bounds of the spices due to the discretization.,title=\"fig:\",width=336 ]    fig .",
    "[ fig : time_ula ] presents cpu times of _ experiment 1_. since the postprocessing can be applied efficiently , the time usage of spice - pp is slightly longer than spice and is omitted .",
    "both spice+s and spices have similar performance trends with different discretization levels because the number of iterations used is approximately the same . as a result ,",
    "the time usage of spice is proportional to the grid size @xmath229 while the proposed discretization - free spa does not depend on @xmath229 .",
    "[ fig : time_ula ] shows that when @xmath283 spice+ and spice are constantly slower than spa+ and spa , respectively . when @xmath284 , spice+ is also slower than spa+ sometimes .     uncorrelated sources .",
    "some settings include : ula with @xmath262 , @xmath281 , @xmath282 and @xmath266.,width=336 ]    _ experiment 2 _ studies the performance with respect to the array length @xmath46 .",
    "we repeat _ experiment 1 _ but set @xmath285db and vary @xmath46 in @xmath286 .",
    "moreover , we consider only the case @xmath283 for spice .",
    "only the case where @xmath287 is considered for spa ( excluding spa+ ) due to time consideration .",
    "the simulation results are presented in fig .",
    "[ fig : ula_varym ] . since crlb+ and crlb are slightly different and almost undistinguishable , only crlb+ is plotted .",
    "as before , spice3 + , spice3 and spice3 + -pp share the same lower bound due to discretization and the property of the spice+ estimator , while spa+ , spa and spice3-pp can outperform this bound .",
    "as @xmath46 increases , e.g. , when @xmath288 , the performances of spa and spice3-pp hardly improve and the gaps between the algorithms and crlb+ become larger .",
    "two possible reasons are as follows : 1 ) unlike crlb+ , spa does not use the knowledge of @xmath33 but @xmath93 , which becomes rougher when @xmath46 increases and @xmath33 keeps unaltered , and 2 ) the modeling error of spice increases as @xmath46 increases .",
    "the figure at the bottom indicates that the speed of spa+ scales well with @xmath46 in our considered scenario and is faster than spice3 + as @xmath289 and constantly faster than spice3 . the number of iterations of spice3 + is empirically observed to decrease with increasing array length in our considered scenario , leading to a seeming strange result that spice3 + gets faster when @xmath46 increases .",
    "-element ula compared with spice .",
    "some settings include : @xmath274 uncorrelated sources with @xmath290 and @xmath282 , @xmath291 and @xmath266.,title=\"fig:\",width=336 ] -element ula compared with spice .",
    "some settings include : @xmath274 uncorrelated sources with @xmath290 and @xmath282 , @xmath291 and @xmath266.,title=\"fig:\",width=336 ]      _ experiment 3 _ studies the sla case where a 4-element redundant array @xmath88 is considered .",
    "we try to verify theorem [ thm : efficiency ] and attempt to locate maximally @xmath292 uncorrelated sources with the frequency vector @xmath293 and power vector @xmath294 .",
    "moreover , we set @xmath285db and vary the number of snapshots @xmath4 in @xmath295 .",
    "1000 monte carlo runs are used to obtain the metrics for each @xmath4 . to evaluate the performance , we calculate the ratio @xmath296 for each algorithm at each @xmath4 . for an unbiased estimator , the ratio is called its efficiency .",
    "the larger the ratio is ( @xmath297 for an unbiased estimator ) , the more accurate the estimator will be .",
    "[ table : sla_frequency ] presents the simulation results .",
    "remarkably , spa+ ( or spa ) can outperform the crlb+ ( or crlb ) when @xmath298 since the ratios are larger than 1 ( or 0.9281 ) .",
    "though spice+ ( or spice ) can outperform the crlb+ ( or crlb ) as well at @xmath266 , its gap to the crlb+ ( or crlb ) becomes larger as @xmath4 increases .",
    "moreover , spice+-pp ( or spice - pp ) is consistently better than spice+ ( or spice ) and worse than spa+ ( or spa ) .",
    "notice that as @xmath4 gets larger , the gap between spa+ ( or spa ) and 1 ( or 0.9281 ) becomes smaller , which is consistent with the conclusions of theorem [ thm : efficiency ] that @xmath299 , as @xmath300 .",
    "it is also noted that the source power and noise variance estimates of the proposed spa method have similar performances and their metrics are omitted .",
    "the frequency and power estimates of spa+ at @xmath266 are plotted in fig .",
    "[ fig : sla_n200 ] .",
    ".mses of frequency estimates of spa compared with spice and crlb . each of the presented values is the ratio @xmath301 ( the larger the better ) . [",
    "cols=\"<,>,>,>,>\",options=\"header \" , ]     [ table : sla_frequency ]     uncorrelated sources with a 4-element sla @xmath88 when @xmath266 and @xmath291 ( 1000 monte carlo runs ) .",
    "black circles indicate the true frequencies and corresponding powers.,width=336 ]      we compare spa with the off - grid method ogsbi - svd in @xcite in this subsection .",
    "ogsbi - svd utilizes the sparse bayesian learning ( sbl ) technique @xcite , which mimics the ml estimation according to @xcite , and is based on an off - grid observation model which is a first - order approximation of the exact model with continuous frequencies and has a reduced modeling error ( recall that the observation model of spice and many others is a zeroth - order approximation while spa relies on the exact model ) . in ogsbi - svd",
    "the grid offset ( the distance from a true frequency location to its nearest grid point ) is estimated jointly with the sparse signal and singular value decomposition ( svd ) is used for reducing dimension of the observed data and faster convergence . since the covariance @xmath96 is also involved in ogsbi - svd as in spice which can not be appropriately separated into the source and noise parts , ogsbi - svd usually produces a dense spectrum like spice .    in _ experiment 4",
    "_ , we repeat _ experiment 1 _ for spa+ and ogsbi - svd and consider two discretization levels , @xmath302 , for ogsbi - svd ( denoted by ` 1 ' , ` 2 ' respectively ) . the mses are plotted in fig .",
    "[ fig : mse_ogsbi ] .",
    "as expected , ogsbi - svd can exceed the lower bounds of on - grid methods ( horizontal dashed lines ) .",
    "as snr increases , e.g. , at @xmath303db , the modeling error of ogsbi - svd becomes nonnegligible .",
    "then spa is more accurate than ogsbi - svd .",
    "note also that spa is more robust to noise .",
    "for example , spa can produce satisfactory results at @xmath304db while ogsbi - svd can not . in computational speed , spa is slightly slower than ogsbi - svd with @xmath305 and about 3 times faster with @xmath306 .",
    "uncorrelated sources using spa compared with ogsbi - svd and the crlb , with @xmath266 .",
    "the horizontal dashed lines refer to lower bounds of on - grid methods with @xmath302.,width=336 ]    in _ experiment 5 _ , we repeat the simulation by fixing @xmath291 and varying the number of snapshots @xmath4 from 1 to 200 at a step of 3 .",
    "simulation results presented in fig .",
    "[ fig : mse_ogsbi_varyn ] show that spa has consistently satisfactory performance though it is slightly worse than ogsbi - svd ( the mses of spa are less than @xmath307 times those of ogsbi - svd in most of the scenarios ) . since ogsbi - svd mimics",
    "the ml estimation and spa is a large - snapshot realization of the ml , the performance gap between them vanishes as @xmath4 increases .",
    "uncorrelated sources using spa compared with ogsbi - svd and the crlb , with @xmath291 .",
    "the horizontal dashed lines refer to lower bounds of on - grid methods with @xmath302.,width=336 ]      if an infinitely fine discretization scheme is allowed in spice ( to eliminate the modeling error ) , then spice and spa will produce the same covariance matrix estimate @xmath126 .",
    "however , spa always has a sparse spectrum while spice may produce a dense one .",
    "the two spectra can be considered as two different decomposition schemes applied to @xmath126 to estimate the source powers .",
    "the sparse decomposition of spa has good statistical properties as presented in subsection [ sec : statproperty ] while the dense decomposition of spice does not .",
    "moreover , as shown in figs .",
    "[ fig : spectra3 ] and [ fig : spectra_coh2 ] , the dense decomposition of spice has potentially inferior resolution .",
    "however , the simulation results of fig . [ fig : mse_ula ] show that spice can outperform spa in terms of mse in the middle range of the snr ( similar results are presented in figs .",
    "[ fig : mse_ogsbi ] and [ fig : mse_ogsbi_varyn ] for ogsbi - svd ) .",
    "it is because that 1 ) spa is empirically observed to produce a more heavy - tailed frequency estimator than spice since the frequency of a source is determined by a single point unlike spice for which the frequency estimate is given by the peaks of the spectrum , and 2 ) the mse metric is sensitive to heavy - tailed estimators ( in fact , a careful study reveals that spa+ is more accurate than spice3 + in over half of the monte carlo runs in the snr range @xmath308db in fig .",
    "[ fig : mse_ula ] ) .",
    "in this paper , the linear array signal processing problem was studied and a discretization - free technique named as spa was proposed .",
    "the new method adopts the covariance fitting criteria of spice and was formulated as an sdp followed by a postprocessing technique .",
    "spa is a parametric method and guarantees to produce a sparse parameter estimate and in the mean time enjoys several other merits .",
    "its asymptotic statistical properties were analyzed and practical performance was demonstrated via simulations compared to existing methods .",
    "the following directions should be investigated in the future , some of which have been mentioned in the main context of this paper : 1 ) connection of the proposed spa method to the atomic norm - based discretization - free methods in @xcite for spectral analysis , 2 ) postprocessing techniques for general but not redundancy slas to utilize the full information of the range of the source number , 3 ) performance analysis of spa in the finite - snapshot case while this paper is mainly on its asymptotic statistical properties , 4 ) fast implementations of the spa method via developing more computationally efficient algorithms for solving the sdps involved , 5 ) modified spa methods with automatic source number estimation , and 6 ) discretization - free methods for array processing with general array geometries .",
    "t.  yardibi , j.  li , p.  stoica , m.  xue , and a.  b. baggeroer , `` source localization and sensing : a nonparametric iterative adaptive approach based on weighted least squares , '' _ ieee transactions on aerospace and electronic systems _ , vol .",
    "46 , no .  1 ,",
    "pp . 425443 , 2010 .",
    "d.  malioutov , m.  cetin , and a.  willsky , `` a sparse signal reconstruction perspective for source localization with sensor arrays , '' _ ieee transactions on signal processing _",
    "53 , no .  8 , pp . 30103022 , 2005 .",
    "a.  c. gurbuz , v.  cevher , and j.  h. mcclellan , `` bearing estimation via spatial sparsity using compressive sensing , '' _ ieee transactions on aerospace and electronic systems _",
    "48 , no .  2 , pp . 13581369 , 2012 .",
    "h.  abeida , q.  zhang , j.  li , and n.  merabtine , `` iterative sparse asymptotic minimum variance based approaches for array processing , '' _ ieee transactions on signal processing _ ,",
    "61 , no .  4 , pp . 933944 , 2013 .",
    "p.  stoica , p.  babu , and j.  li , `` new method of sparse parameter estimation in separable models and its use for spectral analysis of irregularly sampled data , '' _ ieee transactions on signal processing _ ,",
    "59 , no .  1",
    ", pp . 3547 , 2011 .",
    "c.  d. austin , r.  l. moses , j.  n. ash , and e.  ertin , `` on the relation between sparse reconstruction and parameter estimation with model order selection , '' _ selected topics in signal processing , ieee journal of _ , vol .  4 , no .  3 , pp .",
    "560570 , 2010 .",
    "z.  yang , c.  zhang , and l.  xie , `` robustly stable signal recovery in compressed sensing with structured matrix perturbation , '' _ ieee transactions on signal processing _",
    "60 , no .  9 ,",
    "pp . 46584671 , 2012 .",
    "l.  hu , z.  shi , j.  zhou , and q.  fu , `` compressed sensing of complex sinusoids : an approach based on dictionary refinement , '' _ ieee transactions on signal processing _ , vol .",
    "60 , no .  7 ,",
    "38093822 , 2012 .",
    "p.  stoica and a.  nehorai , `` performance study of conditional and unconditional direction - of - arrival estimation , '' _ ieee transactions on acoustics , speech and signal processing _ , vol .",
    "38 , no .",
    "10 , pp . 17831795 , 1990 .",
    "z.  yang , `` analysis , algorithms and applications of compressed sensing , '' ph.d .",
    "dissertation , nanyang technological university , available online at https://dl.dropboxusercontent.com/u/34897711/thesis_yangzai.pdf , 2013 ."
  ],
  "abstract_text": [
    "<S> direction of arrival ( doa ) estimation in array processing using uniform / sparse linear arrays is concerned in this paper . while sparse methods via _ approximate _ parameter discretization have been popular in the past decade , the discretization may cause problems , e.g. , modeling error and increased computations due to dense sampling . in this paper , </S>",
    "<S> an _ </S>",
    "<S> exact _ discretization - free method , named as sparse and parametric approach ( spa ) , is proposed for uniform and sparse linear arrays . </S>",
    "<S> spa carries out parameter estimation in the continuous range based on well - established covariance fitting criteria and convex optimization . </S>",
    "<S> it guarantees to produce a sparse parameter estimate without discretization required by existing sparse methods . </S>",
    "<S> theoretical analysis shows that the spa parameter estimator is a large - snapshot realization of the maximum likelihood estimator and is statistically consistent ( in the number of snapshots ) under uncorrelated sources . </S>",
    "<S> other merits of spa include improved resolution , applicability to arbitrary number of snapshots , robustness to correlation of the sources and no requirement of user - parameters . </S>",
    "<S> numerical simulations are carried out to verify our analysis and demonstrate advantages of spa compared to existing methods .    </S>",
    "<S> array processing , doa estimation , sparse and parametric approach ( spa ) , continuous parameter estimation , compressed sensing . </S>"
  ]
}