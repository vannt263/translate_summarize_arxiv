{
  "article_text": [
    "maximum entropy principle is a well - known selection principle under uncertainty .",
    "this is an idea that dates back to l.  boltzmann , was popularized by e.  t.  jaynes @xcite , and has its foundation in the theory of large deviation .",
    "suppose that an ensemble average measurement ( say sample mean , sample second moment , or any other similar linear statistic ) is made on the realization of a sequence of iid random variables .",
    "the realization must then have an empirical distribution that obeys the constraint placed by the measurement  the empirical distribution must belong to an appropriate convex set , say @xmath3 .",
    "large deviation theory tells us that a special member of @xmath3 , denoted @xmath4 , is overwhelmingly more likely than the others .",
    "if the alphabet @xmath5 is finite ( with cardinality @xmath6 ) , and the prior probability distribution ( before measurement ) is the uniform distribution @xmath7 on @xmath5 , then @xmath4 is the one that minimizes the relative entropy with respect to @xmath8 is defined as @xmath9 and the shannon entropy of @xmath10 is defined as @xmath11 the usual convention is @xmath12 if @xmath13 and @xmath14 if @xmath15 . ] @xmath16 which is the same as the one that maximizes ( shannon ) entropy , subject to @xmath17 . in jaynes words , _ ``",
    "... it is maximally noncommittal to the missing information '' _ @xcite .    as a physical example , let us tag a particular molecule in the atmosphere .",
    "let @xmath18 denote the height of the molecule in the atmosphere .",
    "then the potential energy of the molecule is @xmath19 .",
    "let us suppose that the average potential energy is held constant , that is , @xmath20",
    "= c$ ] , a constant . then the probability distribution of the height of the molecule is taken to be the exponential distribution @xmath21 , where @xmath22 .",
    "this is also the maximum entropy probability distribution subject to first moment constraint @xcite .    more generally ,",
    "if the prior probability distribution ( before measurement ) is @xmath8 , then @xmath4 minimizes @xmath23 subject to @xmath17 .",
    "something more specific can be said : @xmath4 is the limiting conditional probability distribution of a `` tagged '' particle under the conditioning imposed by the measurement .",
    "this is called _ the conditional limit theorem _ or the _ gibbs conditioning principle _ ; see for example campenhout and cover @xcite or csiszr @xcite for a more general result .",
    "it is well - known that @xmath24 behaves like `` squared euclidean distance '' and has the `` pythagorean property '' ( csiszr @xcite ) . in view of this and",
    "since @xmath4 minimizes @xmath23 subject to @xmath17 , one says that @xmath4 is `` closest '' to @xmath8 in the relative entropy sense amongst the probability distributions in @xmath3 , or in other words , `` @xmath4 is the @xmath25-projection of @xmath8 on @xmath3 '' .",
    "motivated by the above maximum entropy and gibbs conditioning principles , @xmath25-projection was extensively studied by csiszr @xcite , @xcite , and csiszr and mat @xcite .",
    "this paper is on the projection problem associated with a parametric generalization of relative entropy . to see how this parametric generalization arises",
    ", we return to our remark on how relative entropy arises in shannon theory . for this",
    ", we must first recall how rnyi entropies are a parametric generalization of the shannon entropy .",
    "rnyi entropies @xmath26 for @xmath27 play the role of shannon entropy when the _ normalized cumulant _ of compression length , @xmath28,\\ ] ] is considered instead of expected compression length @xmath29 $ ] , where @xmath30 is the cumulant parameter .",
    "campbell @xcite showed that the minimum normalized cumulant subject to all compression strategies that satisfy the kraft inequality is @xmath31 where @xmath32 .",
    "we also have @xmath33 , so that rnyi entropy may be viewed as a generalization of shannon entropy .    if the compressor assumed that the true probability distribution is @xmath8 , instead of @xmath10 , then the gap in the normalized cumulant s optimal value is an analogous parametric divergence quantity , which we shall denote @xmath1 @xcite .",
    "the same quantity also arises when we study the gap from optimality of mismatched guessing exponents .",
    "see arikan @xcite and hanawal and sundaresan @xcite for general results on guessing , and see sundaresan @xcite and @xcite on how @xmath1 arises in the context of mismatched guessing .",
    "recently , bunte and lapidoth @xcite have shown that the @xmath1 also arises as redundancy in a mismatched version of the problem of coding for tasks .",
    "@xmath2 may be expressed as @xmath34 - \\frac{1}{1-\\alpha}\\log \\sum_x p(x)^{\\alpha}\\nonumber\\\\ & & + \\log \\sum_x q(x)^{\\alpha}.\\end{aligned}\\ ] ] for each @xmath35 , @xmath36 with equality iff @xmath37 ( * ? ? ?",
    "also , @xmath38 only when either    * @xmath39 and @xmath40 . ] or * @xmath41 and @xmath42 .    for @xmath43 , @xmath1 turns out to be relevant in a robust parameter estimation problem of statistics @xcite .",
    "as one might expect , it is known that ( see for example , sundaresan ( * ? ? ?",
    "v-5 ) ) or johnson and vignat ( * ? ? ?",
    "* a.1 ) ) @xmath44 , so that we may think of relative entropy as @xmath45 .",
    "thus @xmath2 is a generalization of relative entropy , i.e. , a _",
    "_ relative @xmath0-entropy__.    not surprisingly , the maximum rnyi entropy principle has been considered as a natural alternative to the maximum entropy principle of decision making under uncertainty .",
    "this principle is equivalent to another principle of maximizing the so - called tsallis entropy which happens to be a monotone function of the rnyi entropy .",
    "rnyi entropy maximizers under moment constraints are distributions with a power - law decay ( when @xmath39 ) .",
    "see costa et al .",
    "@xcite or johnson and vignat @xcite .",
    "many statistical physicists have studied this principle in the hope that it may `` explain '' the emergence of power - laws in many naturally occurring physical and socio - economic systems , beginning with tsallis @xcite . based on our explorations of the vast literature on this topic",
    ", we feel that our understanding , particularly one that ought to involve a modeling of the _ dynamics _ of such systems with the observed power - law profiles as equilibria in the asymptotics of large time , is not yet as mature as our understanding of the classical boltzmann - gibbs setting .",
    "but , by noting that @xmath46 , we see that both the maximum rnyi entropy principle and the maximum tsallis entropy principle are particular instances of a `` minimum relative @xmath0-entropy principle '' : @xmath47 we shall call the minimizing @xmath4 as the @xmath2-projection of @xmath8 on @xmath3 .",
    "the objective of this paper is to characterize the @xmath2-projection on a particular convex family called _ linear family _ which we shall define now .",
    "[ defn : linear - family ] a linear family characterized by @xmath48 functions @xmath49 , @xmath50 , is the set of probability distributions given by @xmath51    we will show that the @xmath2-projection on a linear family comes from an @xmath0-power law family analogous to the fact that the @xmath52-projection on such a family comes from an exponential family @xcite .",
    "in this section , we find the structure of the @xmath2-projection on a linear family @xmath53 and prove a necessary and sufficient condition for a @xmath54 to be the @xmath2-projection on @xmath53 .",
    "we consider the cases @xmath41 and @xmath39 separately in the two subsections .",
    "the proof for the @xmath55 case is similar to csiszr and shields proof for @xmath56 case @xcite . for the proof of @xmath43 case",
    ", we will resort to the lagrange multiplier technique .",
    "the result for @xmath55 is the following .",
    "[ thm : projection_alpha<1 ] let @xmath55 .",
    "let @xmath53 be a linear family characterized by @xmath57 .",
    "let @xmath8 be a probability distribution with @xmath58 . then the following hold .",
    "* @xmath8 has an @xmath2-projection on @xmath53 . call it @xmath4 .",
    "* @xmath59 is defined to be the union of supports of members of @xmath53 . ] and the pythagorean equality holds ( see figure [ fig : pythagorean ] ) : @xmath60 * the @xmath2-projection @xmath4 satisfies @xmath61^{\\frac{1}{\\alpha -1}}\\\\ \\forall x \\in \\mathbb{x},\\end{gathered}\\ ] ] where @xmath62 are scalars and @xmath63 is the normalization constant that makes @xmath4 a probability distribution . *",
    "the @xmath2-projection is unique .",
    "@xmath64    \\(a ) from ( [ eqn : i - alpha ] ) , it is clear that the mapping @xmath65 is continuous as each of the terms in ( [ eqn : i - alpha ] ) is continuous in @xmath10 .",
    "also @xmath53 is compact .",
    "hence the @xmath2-projection exists .",
    "\\(b ) let @xmath66 and let @xmath67 , @xmath68 .",
    "since @xmath69 , the mean value theorem says that for each @xmath70 , there exists @xmath71 such that @xmath72 = \\frac{d}{ds}\\mathscr{i}_{\\alpha}(p_{s},q)|_{s=\\tilde{t}}.\\end{aligned}\\ ] ] the first inequality follows from the fact that @xmath4 is the projection . using ( [ eqn : i - alpha ] ) , we see that @xmath73.\\end{aligned}\\ ] ] as @xmath74 , from ( [ derivative2 ] ) and the inequality in ( [ derivative1 ] ) , we get @xmath75 that is , @xmath76 which , using ( [ eqn : i - alpha ] ) , can be seen to be equivalent to ( [ eqn : pythagorean_equality ] ) , but with inequality `` @xmath77 '' in place of equality .",
    "suppose @xmath78 for an @xmath79 .",
    "then @xmath80 implies that right - hand side of ( [ derivative2 ] ) goes to @xmath81 as @xmath74 , which contradicts the nonnegativity requirement in ( [ derivative1 ] ) .",
    "hence @xmath82 .",
    "since @xmath10 was arbitrary , we have @xmath59 .",
    "we will now establish equality in ( [ eqn : pythagorean_equality ] ) .",
    "once again let @xmath66 .",
    "since @xmath59 , we can find a new @xmath83 such that @xmath84 is a valid probability distribution for all @xmath85 .",
    "hence @xmath86 for all @xmath85 .",
    "since @xmath87 , we have @xmath88 \\quad \\forall t\\in ( \\tilde t , 0).\\ ] ] an argument similar to the one that led to ( [ pythagorean_inequality_equivalent ] ) now proves that ( [ pythagorean_inequality_equivalent ] ) holds with `` @xmath89 '' as well .",
    "this proves ( [ eqn : pythagorean_equality ] ) and completes the proof of ( b ) .",
    "\\(c ) this follows the proof of csiszr and shields for case @xmath56 ( * ? ? ?",
    "3.4 ) .    from ( [ eqn :",
    "linear_family ] ) , it is clear that the probability distributions @xmath66 , when considered as @xmath90-dimensional vectors , belong to the orthogonal complement @xmath91 of the subspace @xmath92 of @xmath93 spanned by the vectors @xmath94 , restricted to @xmath95 .",
    "these @xmath66 actually span @xmath91 .",
    "( this follows from the fact that if a subspace of @xmath93 contains a vector all of whose components are strictly positive , here @xmath4 , then it is spanned by the probability vectors of that space . ) using ( [ eqn : pythagorean_equality ] ) , which is the same as ( [ pythagorean_inequality_equivalent ] ) with equality , we have @xmath96 consequently , the vector @xmath97 belongs to @xmath98 , that is , @xmath99 for some scalars @xmath100 .",
    "this verifies ( [ eqn : power_law ] ) for obvious choices of @xmath63 and @xmath101 .",
    "\\(d ) let @xmath102 and @xmath103 be two projections of @xmath8 on @xmath53",
    ". then @xmath104 . by ( c )",
    ", we have @xmath105 canceling @xmath106 and @xmath107 , we get @xmath108 which implies @xmath109",
    ".    one can also have a converse .",
    "[ thm : projection_alpha<1_converse ] let @xmath55 .",
    "let @xmath110 be a probability distribution of the form ( [ eqn : power_law ] )",
    ". then @xmath4 satisfies ( [ eqn : pythagorean_equality ] ) and @xmath4 is the @xmath2-projection @xmath8 on @xmath53 .",
    "@xmath64    if @xmath111 is of the stated form , then since every @xmath66 satisfies @xmath112 we have from ( [ eqn : power_law ] ) that @xmath113 and @xmath114 combining the above two equations to eliminate @xmath115 , we get @xmath116 which , using ( [ eqn : i - alpha ] ) , can be seen to be equivalent to ( [ eqn : pythagorean_equality ] ) .",
    "thus , for any @xmath66 , we have @xmath117 which implies that @xmath4 is the @xmath2-projection of @xmath8 on @xmath53 .    when @xmath43 , in general , @xmath118 as shown by the following counterexample .    take @xmath119 and @xmath120 .",
    "take @xmath121 .",
    "consider the linear family , @xmath122 thus @xmath123 where @xmath124 .",
    "we claim that the @xmath2-projection of @xmath8 on @xmath53 is @xmath125 .",
    "to check this claim , first note that @xmath111 . also , with @xmath126 and @xmath127 , we can check that @xmath128 hence , for any @xmath66 , @xmath129\\nonumber\\\\   & = & \\sum\\limits_{x=1}^4 p(x ) q(x)\\nonumber\\\\   & = & \\sum\\limits_{x=1}^4 p(x ) q(x)^{\\alpha-1},\\end{aligned}\\ ] ] where the penultimate equality follows because @xmath66 .",
    "similarly , one can show that @xmath130 combining this with ( [ eqn : inequality ] ) to eliminate @xmath131 , we get @xmath132 which , using ( [ eqn : i - alpha ] ) , can be seen to be equivalent to @xmath133 thus , @xmath4 is the @xmath2-projection of @xmath8 on @xmath53 .",
    "clearly @xmath134 . also for @xmath135 , numerical calculations yield a strict inequality in ( [ eqn : pythagorean_inequality1 ] ) since the left - hand side and the right - hand side of ( [ eqn : pythagorean_inequality1 ] ) evaluate to @xmath136 and @xmath137 , respectively .    as a consequence of this ,",
    "the proof of theorem [ thm : projection_alpha<1 ] for the case @xmath55 can not be carried forward to establish the structure of @xmath138-projection for the case @xmath43 .",
    "we will resort to the usual lagrange multiplier technique for this case .",
    "we now establish the form of the @xmath2-projection on a linear family when @xmath43 .",
    "[ thm : projection_alpha>1 ] let @xmath43 .",
    "let @xmath53 be a linear family characterized by @xmath139 .",
    "let @xmath8 be a probability distribution with @xmath58 .",
    "then the following hold .",
    "* @xmath8 has an @xmath2-projection on @xmath53 .",
    "call it @xmath4 . *",
    "the @xmath2-projection @xmath4 satisfies @xmath140_{+}^{\\frac{1}{\\alpha - 1}}\\\\ \\forall x \\in \\mathbb{x},\\end{gathered}\\ ] ] where @xmath62 are scalars and @xmath63 is the normalization constant that makes @xmath4 a probability distribution and @xmath141_{+ } = \\max\\{u,0\\}$ ] . *",
    "the pythagorean inequality holds : @xmath142 * the @xmath2-projection is unique . *",
    "if @xmath59 , then ( [ eqn : pythagorean_inequality2 ] ) holds with equality .",
    "@xmath64    \\(a ) same as proof of theorem [ thm : projection_alpha<1]-(a ) .",
    "\\(b ) the optimization problem for the @xmath2-projection is @xmath143 we will proceed in a sequence of steps .",
    "* observe that @xmath144 , in addition to being continuous , is also continuously differentiable .",
    "indeed , we have @xmath145.\\end{aligned}\\ ] ] both denominators are bounded away from zero because for any @xmath146 , we have @xmath147 , and therefore @xmath148 and @xmath149 consequently , the partial derivative ( [ eqn : partial_derivative ] ) exists everywhere on @xmath150 , and is continuous because the terms involved are continuous .",
    "( the numerator of the second term in ( [ eqn : partial_derivative ] ) is continuous because @xmath43 ) . * since the equality constraints in ( [ eqn : linear_constraints ] ) and ( [ eqn : probability_constraint ] ) arise from affine functions , and the inequality constraints in ( [ eqn : positivity_constraints ] ) arise from linear functions , we may apply ( * ? ? ?",
    "3.3.7 ) to conclude that there exist lagrange multipliers",
    "( @xmath100 ) , @xmath151 , and @xmath152 associated with the constraints ( [ eqn : linear_constraints ] ) , ( [ eqn : probability_constraint ] ) , and ( [ eqn : positivity_constraints ] ) , respectively , that satisfy : @xmath153}\\nonumber\\\\ & &   \\hspace{1.5 cm } = \\sum\\limits_{i=1}^k \\lambda_i f_i(x ) - \\mu(x ) + \\nu \\quad \\forall x\\\\   \\label{eqn : feasibility_condition } & & \\hspace{0.7 cm } \\mu(x ) \\ge 0 \\quad \\forall x\\\\ \\label{eqn : slackness_condition } & & \\mu(x)p^*(x ) = 0 \\quad \\forall x.\\end{aligned}\\ ] ] in writing ( [ eqn : lagrange1 ] ) , we have substituted ( [ eqn : partial_derivative ] ) for @xmath154 . * multiplying ( [ eqn : lagrange1 ] ) by @xmath155 , summing over all @xmath156 , using @xmath111 , and ( [ eqn : slackness_condition ] ) , we see that @xmath157 . *",
    "if @xmath158 , we must have @xmath159 from ( [ eqn : slackness_condition ] ) , and its substitution in ( [ eqn : lagrange1 ] ) yields , for all such @xmath160 , @xmath161 if @xmath162 , ( [ eqn : lagrange1 ] ) implies that @xmath163 where the last inequality holds because of ( [ eqn : feasibility_condition ] ) and @xmath43 .",
    "therefore , ( [ eqn : lagrange2 ] ) and ( [ eqn : lagrange3 ] ) may be combined as @xmath164_{+}\\\\ \\forall x \\in \\mathbb{x},\\end{gathered}\\ ] ] for obvious choices of @xmath63 and @xmath165 .",
    "this verifies ( [ eqn : power_law_with+ ] ) and completes the proof of ( b ) .",
    "\\(c ) using ( [ eqn : power_law_with+ ] ) , for any @xmath146 , we have @xmath166\\nonumber\\\\   & & = z^{1-\\alpha } \\sum\\limits_x p(x)q(x)^{\\alpha -1},\\end{aligned}\\ ] ] where the first inequality follows because the terms on the right - hand side corresponding to @xmath160 with @xmath78 are nonpositive , and the last equality follows because @xmath66 .",
    "similarly , @xmath167 combining the above and ( [ eqn : expected_value1 ] ) we get @xmath168 which , using ( [ eqn : i - alpha ] ) , is equivalent to ( [ eqn : pythagorean_inequality2 ] ) .",
    "this completes the proof of ( c ) .",
    "\\(d ) same as proof of theorem [ thm : projection_alpha<1]-(d ) .",
    "\\(e ) if @xmath59 , then we have equality in ( [ eqn : expected_value1 ] ) , hence equality in ( [ eqn : pyth_ineq_simplified ] ) , and hence equality in ( [ eqn : pythagorean_inequality2 ] ) .",
    "this concludes the proof of ( e ) and the theorem .    as in the @xmath55 case ,",
    "one has a converse .",
    "[ thm : projection_alpha>1_converse ] let @xmath43 .",
    "let @xmath110 be a probability distribution of the form ( [ eqn : power_law_with+ ] )",
    ". then @xmath4 satisfies ( [ eqn : pythagorean_inequality2 ] ) for every @xmath66 , and @xmath4 is the @xmath2-projection @xmath8 on @xmath53 .",
    "@xmath64    the proof of theorem [ thm : projection_alpha>1]-(c ) shows that ( [ eqn : pythagorean_inequality2 ] ) holds .",
    "now , for any @xmath66 , we have @xmath169 which implies that @xmath4 is the @xmath2-projection @xmath8 on @xmath53 .",
    "motivated by the maximum entropy principle , we studied minimization of a parametric extension of relative entropy , where the minimization was with respect to the first argument .",
    "we recognize that the minimizer on a set determined by linear statistical constraints belongs to the @xmath0-power - law family .",
    "this is analogous to the fact that the minimizer of relative entropy ( @xmath56 ) belongs to the exponential family .",
    "a complementary minimization problem , where the minimization is with respect to the second argument of @xmath2 , is relevant in robust statistics ( @xmath43 ) and in constrained compression settings ( @xmath55 ) .",
    "this problem and the connection between the two minimization problems will be the subject matter of our forthcoming work .",
    "m. ashok  kumar was supported by a council for scientific and industrial research ( csir ) fellowship and by the department of science and technology .",
    "r. sundaresan was supported in part by the university grants commission by grant part ( 2b ) ugc - cas-(ph.iv ) and in part by the department of science and technology ."
  ],
  "abstract_text": [
    "<S> we study minimization of a parametric family of relative entropies , termed relative @xmath0-entropies ( denoted @xmath1 ) . </S>",
    "<S> these arise as redundancies under mismatched compression when cumulants of compressed lengths are considered instead of expected compressed lengths . </S>",
    "<S> these parametric relative entropies are a generalization of the usual relative entropy ( kullback - leibler divergence ) . just like relative entropy , </S>",
    "<S> these relative @xmath0-entropies behave like squared euclidean distance and satisfy the pythagorean property . </S>",
    "<S> minimization of @xmath1 over the first argument on a set of probability distributions that constitutes a linear family is studied . </S>",
    "<S> such a minimization generalizes the maximum rnyi or tsallis entropy principle . the minimizing probability distribution ( termed @xmath2-projection ) for a linear family </S>",
    "<S> is shown to have a power - law . </S>"
  ]
}