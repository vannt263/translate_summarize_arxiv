{
  "article_text": [
    "in quantum computing , elementary operations are operations that act on only a few ( usually one or two ) qubits .",
    "for example , cnots and one - qubit rotations are elementary operations .",
    "a quantum compiling algorithm is an algorithm for decomposing (  compiling \" ) an arbitrary unitary matrix into a sequence of elementary operations ( seo ) .",
    "a quantum compiler is a software program that implements a quantum compiling algorithm .",
    "henceforth , we will refer to ref.@xcite as tuc99 .",
    "tuc99 gives a quantum compiling algorithm , implemented in a software program called qubiter .",
    "the tuc99 algorithm uses a matrix decomposition called the cosine - sine decomposition ( csd ) that is well known in the field of computational linear algebra .",
    "tuc99 uses csd in a recursive manner .",
    "it decomposes any unitary matrix into a sequence of diagonal unitary matrices and something called uniformly controlled u(2 ) gates .",
    "tuc99 then expresses these diagonal unitary matrices and uniformly controlled u(2 ) gates as seos of short length .",
    "more recently , two other groups have proposed quantum compiling algorithms based on csd . one group , based at the univ . of michigan and nist ,",
    "has published ref.@xcite , henceforth referred to as mich04 .",
    "another group based at helsinki univ . of tech.(hut ) , has published refs.@xcite . and @xcite , henceforth referred to as hut04a and hut04b , respectively .",
    "one way of measuring the efficiency of a quantum compiler is to measure the number of cnots it uses to express an unstructured unitary matrix ( a unitary matrix with no special symmetries ) .",
    "we will henceforth refer to this number as @xmath0 .",
    "although good quantum compilers will also require optimizations that deal with structured matrices , unstructured matrices are certainly an important case worthy of attention .",
    "minimizing the number of cnots is a reasonable goal , since a cnot operation ( or any 2-qubit interaction used as a cnot surrogate ) is expected to take more time to perform and to introduce more environmental noise into the quantum computer than a one - qubit rotation .",
    "ref.@xcite proved that for unitary matrices of dimension @xmath1 ( @xmath2 number of bits ) , @xmath3 .",
    "this lower bound is achieved for @xmath4 by the 3 cnot circuits first proposed in ref.@xcite .",
    "it is not known whether this bound can always be achieved for @xmath5 .",
    "the mich04 and hut04b algorithms try to minimize @xmath0 . in this paper , we propose a modification of the tuc99 algorithm which will henceforth be referred to as tuc04 .",
    "tuc04 comes in two flavors , tuc04(nr ) without relaxation process , and tuc04(r ) with relaxation process .",
    "as the next table shows , the most efficient algorithm known at present is mich04 .",
    "hut04b performs worse than mich04 .",
    "tuc04(r ) and mich04 are equally efficient .    [ cols=\"<,<\",options=\"header \" , ]     caveat : strictly speaking , the efficiency of tuc04(r ) as listed in this table is only a conjecture .",
    "the problem is that tuc04(r ) uses a relaxation process .",
    "this paper argues , based on intuition , that the relaxation process converges , but it does not prove this rigorously .",
    "a rigorous proof of the efficiency of tuc04(r ) will require theoretical and numerical proof that its relaxation process converges as expected .",
    "this paper is based heavily on tuc99 and assumes that the reader is familiar with the main ideas of tuc99 .",
    "furthermore , this paper uses the notational conventions of tuc99 .",
    "so if the reader ca nt follow the notation of this paper , he / she is advised to consult tuc99 . the section on notation in ref .",
    "@xcite is also recommended .",
    "contrary to tuc99 , in this paper we will normalize hadamard matrices so that their square equals one .    as in tuc99 , for a single qubit with number operator @xmath6 , we define @xmath7 and @xmath8 .",
    "if @xmath9 labels @xmath10 distinct qubits and @xmath11 , then we define @xmath12 .",
    "when we say @xmath13 ( ditto , @xmath14 ) is @xmath15 ( ditto , @xmath16 ) , we mean @xmath13 is @xmath15 and @xmath14 is @xmath16 .    for any complex number @xmath17 ,",
    "we will write @xmath18 . thus , @xmath19 and @xmath20 are the magnitude and phase angle of @xmath17 , respectively .",
    "@xmath21 will denote the unit vectors along the x , y , z axes , respectively .",
    "for any 3d real unit vector @xmath22 , @xmath23 , where @xmath24 is the vector of pauli matrices .",
    "we define a * @xmath25-subset * to be an ordered set @xmath26 of @xmath27 dimensional unitary matrices .",
    "let the index @xmath28 take values in a set @xmath29 with @xmath30 elements . in this paper ,",
    "we are mostly concerned with the case that @xmath31 , and @xmath28 is represented by @xmath32 .",
    "suppose a qubit array with @xmath33 qubits is partitioned into @xmath34 target qubits and @xmath10 control qubits .",
    "thus , @xmath35 are positive integers such that @xmath36 .",
    "let @xmath9 denote the control qubits and @xmath37 the target qubits .",
    "thus , if @xmath38 and @xmath39 are considered as sets , they are disjoint and their union is @xmath40 .",
    "let @xmath41 be an ordered set of operators all of which act on the hilbert space of the target qubits .",
    "we will refer to any operator @xmath42 of the following form as a * uniformly controlled @xmath43-subset * , or , more succinctly , as a * @xmath43-multiplexor * :    x = _ bool^ p _ ( ) u _ ( ) = _",
    "bool^ u_()^p _ ( ) .",
    "(  multiplexor \" means  multi - fold \" in latin . a special type of electronic device is commonly called a multiplexor or multiplexer ) .",
    "note that @xmath42 is a function of : a set @xmath39 of control bits , a set @xmath38 of target bits , and a @xmath43-subset @xmath41 .",
    "fig.[fig - multiplexor ] shows two possible diagrammatic representations of a multiplexor , one more explicit than the other .",
    "the diagrammatic representation with the  half moon \" nodes was introduced in ref.@xcite .    for a given @xmath44-subset @xmath26 ( and for any multiplexor with that @xmath44-subset ) , it is useful to define as follows what we shall call the optimal axis of the @xmath44-subset .",
    "suppose that we express each @xmath45 in the form    u_b = e^i_b e^i_b e^i(_b + _ b ) ( i)^f(b ) , [ eq - parametri - left - diag ] where @xmath46 are real parameters , where the vectors @xmath47 , and @xmath48 are orthonormal , and where @xmath49 is an indicator function which maps the set of all possible @xmath28 into @xmath50 .",
    "of course , @xmath51 .",
    "appendix [ app - param ] shows how to find the parameters @xmath52 for a given @xmath53 .",
    "appendix [ app - mini ] solves the following minimization problem . if the value of the parameters @xmath52 and the vectors @xmath54 are allowed to vary , while keeping the vectors @xmath54 orthonormal and keeping all @xmath45 fixed , find vectors @xmath54 that are optimal , in the sense that they minimize a cost function .",
    "the cost function penalizes deviations of the diagonal matrices @xmath55 away from the 2d identity matrix @xmath56 .",
    "any choice of orthonormal vectors @xmath47 will be called * strong directions * and @xmath48 will be called a * weak direction * , or an * axis of the @xmath44-subset*. an axis that minimizes the cost function will be called the * optimum axis of the @xmath44-subset*. ( an axis of goodness ) .",
    "it is also possible to define an optimum axis of a @xmath44-subset in the same way as just discussed , except replacing eq.([eq - parametri - left - diag ] ) by    u_b = e^i_b ( i)^f(b ) e^i(_b + _ b)e^i_b .",
    "[ eq - parametri - right - diag ] in eq.([eq - parametri - left - diag ] ) , the diagonal matrix @xmath57 is on the left hand side , so we will call this the * diagonal - on - left ( dol ) parameterization*. in eq.([eq - parametri - right - diag ] ) , the diagonal matrix @xmath57 is on the right hand side , and we will call this the * diagonal - on - right ( dor ) parameterization*.",
    "the cosine sine decomposition ( csd ) expresses an @xmath27 dimensional unitary matrix @xmath58 as a product @xmath59 , where @xmath60 , @xmath61 , @xmath62 , where @xmath63 are unitary matrices of dimension @xmath64 , and @xmath65 is a diagonal real matrix whose entries can be interpreted as angles between subspaces .",
    "note that the matrices @xmath66 and @xmath67 are all multiplexors .",
    "fig.[fig - csd ] depicts the csd graphically , using the multiplexor symbol of fig.[fig - multiplexor ] . in fig.[fig - csd ] , a @xmath44-multiplexor whose @xmath44-subset consists solely of rotations around the y axis , is indicated by putting the symbol @xmath68 in its target box .",
    "we will call this type of multiplexor an * @xmath69-multiplexor*.    lets review the tuc99 algorithm .",
    "it decomposes an arbitrary unitary matrix into a seo by applying the csd in a recursive manner .",
    "the beginning of the tuc99 algorithm for @xmath70 is illustrated in fig.[fig - qubiter-4bits ] .",
    "an initial unitary matrix @xmath71 is decomposed via csd into a product of 3 multiplexors @xmath72 .",
    "the @xmath73 and @xmath67 multiplexors on each side of @xmath74 are in turn decomposed via csd .",
    "the @xmath73 and @xmath67 multiplexors generated via any application of csd are in turn decomposed via csd . in fig.[fig - qubiter-4bits ] , we have stopped recursing once we reached multiplexors whose target box acts on a single qubit . note that at this stage , @xmath71 is decomposed into a product of @xmath44-multiplexors .",
    "there are @xmath75 of these @xmath44-multiplexors ( 15 for @xmath70 ) .",
    "half of these @xmath44-multiplexors have @xmath68 in their target boxes and the other half do nt .",
    "furthermore the @xmath68 type multiplexors and non-@xmath68 ones alternate .",
    "furthermore , the non-@xmath68 @xmath44-multiplexors have their target box at qubit 0 , so , according to the conventions of tuc99 , they are direct sums of @xmath44 matrices . the tuc99 algorithm deals with these direct sums of @xmath44 matrices by applying csd to each @xmath44 matrix in the direct sum .",
    "this converts each direct sum of @xmath44 matrices into a product @xmath59 , where @xmath67 and @xmath73 are diagonal unitary matrices and @xmath74 is an @xmath69-multiplexor .",
    "thus , tuc99 turns the last operator sequence shown in fig.[fig - qubiter-4bits ] into a sequence of alternating diagonal unitary matrices and @xmath69-multiplexors .",
    "then tuc99 gives a prescription for decomposing any diagonal unitary matrix into a seo with @xmath76 cnots and any @xmath69-multiplexor into a seo with @xmath77 cnots .",
    "tuc99 considers what it calls a @xmath74-matrix :    [ eq - gen - d - def ] d = ( _ bool^-1 i _ p _ ) = _",
    "bool^-1 u_p _ , with    u_= ( i _ ) ,    where    _ = _ . here",
    "@xmath78 is a real parameter . in the nomenclature of this paper",
    ", @xmath74 is an @xmath69-multiplexor with a single target qubit at @xmath79 and @xmath79 control qubits at @xmath80 .",
    "tuc99 shows how to decompose @xmath74 into a seo with @xmath77 cnots .",
    "tuc99 also discusses how , by permuting qubits via the qubit exchange operator , one can move the target qubit to any position @xmath40 to get what tuc99 calls a direct sum of @xmath74 matrices . in the nomenclature of this paper ,",
    "a  direct sum of @xmath74 matrices \" is just an @xmath69-multiplexor with a single target qubit at any position out of @xmath40 . in conclusion",
    ", tuc99 gives a complete discussion of @xmath69-multiplexors and how to decompose them into a seo with @xmath77 cnots .",
    "next , let us consider how to generalize tuc99 .",
    "we begin by proving certain facts about @xmath44-multiplexors that are generalizations of similar facts obtained in tuc99 for @xmath69-multiplexors .",
    "suppose @xmath47 and @xmath81 are orthonormal vectors .",
    "suppose we generalize the @xmath74 matrices of tuc99 by using eqs.([eq - gen - d - def ] ) with :    _ = _ , 1 + _ , 2 .",
    "[ eq - phi - def - sw ] here @xmath82 and @xmath83 are real parameters . in tuc99 , we define @xmath84 to be a column vector whose components are the numbers @xmath78 lined up in order of increasing @xmath85 . here",
    ", we use the same rule to define vectors @xmath86 and @xmath87 from @xmath82 and @xmath83 , respectively . in analogy with tuc99 , we then define @xmath88 and @xmath89 via a hadamard transform :    _ j = h_-1 _ j for @xmath90 .",
    "( @xmath91 has been normalized so its square equals one ) .",
    "= _ , 1 + _ , 2 . as in tuc99 , @xmath74 can be expressed as    d = _",
    "bool^-1 a _ , where the operators @xmath92 mutually commute , and can be expressed as    a_= ( i _ ( -1 ) _",
    "j=0^r-1(_j ) ) .",
    "[ eq - a - in - exp - form ] next we will use the following cnot identities . for any two distinct bits @xmath93 ,    ( ) ^n ( ) ( )",
    "= ( ) ( ) , and    ( ) ^n ( ) ( ) = ( ) ( ) .",
    "these cnot identities are easily proven by checking them separately for the two cases @xmath94 and @xmath95 . by virtue of these cnot identities ,",
    "eq.([eq - a - in - exp - form ] ) can be re - written as    a_= [ ( -1)^n(_r-1 )  ( -1)^n(_1 ) ( -1)^n(_0 ) ] .",
    "[ eq - ab - def - basis ]    as shown in tuc99 , if we multiply the @xmath96 matrices ( given by eq.([eq - ab - def - basis ] ) ) in a gray order in @xmath97 , many @xmath98 cancel .",
    "we end up expressing @xmath74 as a seo wherein one - qubit rotations ( of bit @xmath79 ) and @xmath98 type operators alternate , and there is the same number ( @xmath77 ) of each . at this point",
    ", the @xmath98 operators may be converted to cnots using :    ( -1)^n()= e^i(-1)_wx ( -1)^n ( ) , where @xmath99 is a one - qubit rotation that takes direction @xmath100 to direction @xmath101 .",
    "even for the generalized @xmath74 discussed here ( i.e. , for the @xmath74 with @xmath102 defined by eq.([eq - phi - def - sw ] ) ) , it is still true that , by permuting qubits via the qubit exchange operator , one can move the target qubit to any position @xmath40 .",
    "as we have shown , our generalized @xmath74 matrix can be decomposed into an alternating product of one - qubit rotations and cnots .",
    "the product contains @xmath77 ( one factor of 2 for each control qubit ) cnots and the same number of one - qubit rotations . this product expression for",
    "@xmath74 will contain a cnot at the beginning and a one - qubit rotation at the end , or vice versa , whichever we choose .",
    "suppose we choose to have a cnot at the beginning of the product , and that this cnot is @xmath103 , for some @xmath104 .",
    "then the matrix @xmath105^{n(\\mu)}$ ] can be expressed with one cnot less than @xmath74 , as a product which starts and ends with a one - qubit rotation .",
    "and @xmath105^{n(\\mu)}$ ] is a @xmath44-multiplexor just as much as @xmath74 is . indeed ,    ^n()&= & i(-1)n ( ) + ( ) + & = & i(-1)p_0 ( ) + p_1 ( ) ,    so    d[i(-1)]^n()&= & [ _ e^i_p_][i(-1)]^n ( ) + & = & _ s_0 ( ) ( e^i _ i)p_+ _ s_1 ( ) e^i_p _ + & = & _ p _ ,    where @xmath106 and @xmath107 is the complement of @xmath108 .",
    "thus , the @xmath44-subset of @xmath105^{n(\\mu)}$ ] is the same as that of @xmath74 except that half of the @xmath109 matrices are multiplied by @xmath110 .    in conclusion ,",
    "we have pointed out a convenient type of @xmath44-multiplexor .",
    "the @xmath44-subset of a * convenient @xmath44-multiplexor * consists of matrices of the form @xmath111 , where @xmath102 is given by eq.([eq - phi - def - sw ] ) and @xmath112 is an indicator function that maps the set of all @xmath97 into @xmath113 . a convenient @xmath44-multiplexor can be expressed as a seo with @xmath114 cnots .",
    "next we will give an algorithm that converts a @xmath44-multiplexor sequence such as the last operator sequence in fig.[fig - qubiter-4bits ] into a sequence of convenient @xmath44-multiplexors .",
    "for definiteness , we will describe the algorithm assuming @xmath70 . how to generalize the algorithm to arbitrary @xmath33 will be obvious .    1",
    "as in fig.([fig - qubiter-4bits ] ) , let @xmath71 be the matrix to which csd is initial applied .",
    "we assume that before we start applying csd , @xmath71 has been normalized so that @xmath115 .",
    "2 .   apply csd recursively , as show in fig.[fig - qubiter-4bits ] .",
    "let @xmath116 , where @xmath117 , denote the 15 @xmath44-multiplexors labelled 0 thru 14 in fig.[fig - qubiter-4bits ] .",
    "thus , @xmath118 .",
    "[ step - axis ] for now , let @xmath26 denote the @xmath44-subset of the multiplexor @xmath119 .",
    "find the optimum axis of @xmath26 when the @xmath45 are expressed in the dol form : @xmath120 .",
    "note that @xmath121 , where @xmath122 is a convenient @xmath44-multiplexor , and @xmath123 is a diagonal unitary matrix that incorporates the diagonal matrix factor @xmath124 of each @xmath28 .",
    "now define the  intermediate \" matrix @xmath125 .",
    "note that @xmath126 is a @xmath44-multiplexor .",
    "in general , the product of a @xmath44-multiplexor times a diagonal unitary matrix is again a @xmath44-multiplexor .",
    "4 .   for @xmath127 , process",
    "@xmath128 in the same way that @xmath119 was processed . in other words , find the optimum axis ( for a dol parametrization ) of the @xmath44-subset of @xmath128 . note that @xmath129 , where @xmath130 is a convenient @xmath44-multiplexor , and @xmath131 is a diagonal unitary matrix .",
    "now define the matrix @xmath132 .",
    "after applying the previous steps , we will be able to write @xmath133 . in this expansion of @xmath71 ,",
    "all except the last multiplexor are of the convenient type .    1 .   one possibility at this point is to process @xmath134 and then stop .",
    "that is , express @xmath134 as a product of a diagonal unitary matrix @xmath135 and a convenient multiplexor @xmath136 . then express each of the 15 convenient multiplexors @xmath130 for @xmath137 as a seo with @xmath114 cnots . finally , expand the diagonal unitary matrix @xmath135 as a seo with @xmath76 cnots , using the technique given in tuc99 for doing this .    1 .",
    "a second possibility is to repeat the previous steps in the reverse direction , this time going from left to right , and using dor parameterizations .",
    "continue to sweep back and forth across the sequence of multiplexors .",
    "we conjecture that after a few sweeps , we will start producing diagonal matrices @xmath131 that are closer and closer to unity . when the latest @xmath131 matrix is acceptably close to unity , the process can be stopped . at this point",
    ", the axes of the multiplexors will have reached a kind of equilibrium , and we will have expressed @xmath71 as a product of convenient @xmath44-multiplexors .",
    "sweeping only once ( ditto , many times ) is what we called the tuc04(nr ) algorithm ( ditto , the tuc04(r ) algorithm ) in the introduction section of this paper .    for tuc04(r )",
    ", @xmath71 is expressed as product of @xmath138 convenient @xmath44-multiplexors , each of which is expressed as @xmath114 cnots , so @xmath139 .    for tuc04(nr ) , finding the optimum axis of each @xmath44-multiplexor is unnecessary . doing so changes the final diagonal matrix @xmath135 , but does not cause it to vanish .",
    "the lady does not vanish .",
    "thus , for tuc04(nr ) , it is best to simply use @xmath140 throughout .",
    "the tuc04(nr ) algorithm is essentially the same as the hut04b algorithm .",
    "tuc04(nr ) , compared with tuc04(r ) , has the penalty of having to expand the final diagonal matrix @xmath135 .",
    "this produces an extra @xmath1 cnots .",
    "so for tuc04(nr ) , @xmath141",
    ".    note that for tuc04(r ) , it is not necessary to find very precisely the optimum axis of each @xmath44-multiplexor .",
    "any errors in finding such an axis do not increase the numerical errors of compiling @xmath71 .",
    "it may even be true that the axes equilibrate as long as one provides , each time step [ step - axis ] above calls for an axis of a u(2)-multiplexor , an axis that has a better than random chance of decreasing the cost function defined in appendix [ app - mini ] .",
    "in this appendix , we will show how , given orthonormal vectors @xmath47 and @xmath48 , and given any su(2 ) matrix @xmath58 , one can find real parameters @xmath142 such that @xmath143 .",
    "we will use the well known identity e^i = + i ( ) , [ eq - funda - id]where @xmath24 , @xmath144 is a real 3d vector of magnitude @xmath145 , and @xmath146 .    note that given a matrix @xmath147 , if we express its transpose @xmath148 in the form @xmath149 , then this gives an expression for @xmath58 of the form @xmath150 where for @xmath151 , @xmath152 , @xmath153 , and @xmath154 .",
    "( this follows from the fact that @xmath155 , @xmath156 , @xmath157 . ) likewise , given a matrix @xmath147 , if we express @xmath158 in the form @xmath159 , then this gives an expression for @xmath58 of the form @xmath160 .    in the general case ,",
    "the triad @xmath161 is an oblique ( not orthogonal ) basis of real 3d space . as warm up practice ,",
    "consider first the simpler case when the triad is orthogonal ; that is , when @xmath162 , @xmath163 .",
    "any @xmath147 can be expressed as @xmath164 $ ] , where @xmath165 are complex numbers such that @xmath166 .",
    "thus , we want to express @xmath142 in terms of @xmath167 , where : = e^i e^i ( + ) .",
    "[ eq - left - diag - ort ] let @xmath168 . using eq.([eq - funda - id ] ) , it is easy to show that    [ eq - left - diag - ort - xy ] x = e^i , and    y = e^i .    if we assume that @xmath169 , then eqs.([eq - left - diag - ort - xy ] ) can be easily inverted .",
    "one finds    [ eq - left - diag - ort - abc ] = ( x ) ,    = |x| , and    + i = .",
    "next , we consider the general case when the triad @xmath161 is oblique .",
    "one has    = e^i e^i ( + ) .",
    "define @xmath144 by    = _ 1 + _ 2 = _ x _ x + _ y _ y + _ z _ z .",
    "thus ,    = = . using eq.([eq - funda - id ] ) , it is easy to show that    [ eq - left - diag - obl ] x = e^i ( + i ) , and    y = e^i ( ) .",
    "we want to express @xmath142 in terms of @xmath165 .",
    "unlike when the triad was orthogonal , now expressing @xmath170 in terms of @xmath167 is non - trivial ; as we shall see below , it requires solving numerically for the root a non - linear equation .",
    "the good news is that if we know @xmath170 , then @xmath171 and @xmath172 follow in a straightforward manner from :    = ( x e^-i ) , and    _",
    "y+i_x = ( y e^-i ) .",
    "given @xmath173 , one can find @xmath93 using eq.([eq - ab - fun - theta ] ) .",
    "since @xmath166 , eqs.([eq - left - diag - obl ] ) are equivalent to the following 3 equations :    [ eq - abc - theta - xyz - contraints ] |x|^2 = ^2 + ( ) ^2 ^2 ,    ( x)= + ( ) , and    ( y)= + ( ) . as stated previously ,    = _ 1 + _ 2 . [ eq - def - vec - theta ]    next , we will solve the 6 equations given by eqs.([eq - abc - theta - xyz - contraints ] ) for the 6 unknowns @xmath174 .    from eq.([eq - def - vec - theta ] ) , it follows that    = .",
    "thus ,    = .",
    "[ eq - ab - fun - theta ] the determinant @xmath175 is given by    = s_1x s_2y - s_1ys_2x= _ 1_2 _ z = w_z . substituting the expressions for @xmath93 given by eq.([eq - ab - fun - theta ] ) into the z component of eq.([eq - def - vec - theta ] ) now yields    _ z & = & s_1z + s_2z + & = & ( ) s_1z + ( ) s_2z + & = & -k_x _ x - k_y _ y ,    where    k_= for @xmath176 .    at this point , we have reduced our problem to the following 4 equations for the 4 unknowns @xmath177 :    [ eq - gamma - theta - xyz - eqs ] |x|^2 = ^2 + ( ) ^2 ^2 , [ eq - gamma - theta - xyz - eq - a ]    ( ( x)- ) = , [ eq - gamma - theta - xyz - eq - b ]    ( ( y)- ) = , [ eq - gamma - theta - xyz - eq - c ] and    _ z = -k_x _ x - k_y _ y .",
    "[ eq - gamma - theta - xyz - eq - d ]    define the following two shorthand symbols    t_x = ( ( x)- ) , t_y = ( ( y)- ) .",
    "eqs.([eq - gamma - theta - xyz - eq - c ] ) and ( [ eq - gamma - theta - xyz - eq - d ] ) yield    = . thus ,    = .",
    "[ eq - theta - xy - in - z ] substituting the values for @xmath178 and @xmath179 given by eq.([eq - theta - xy - in - z ] ) into the definition of @xmath145 yields :    = .",
    "[ eq - theta - z - in - kt ] eqs.([eq - gamma - theta - xyz - eq - a ] ) and ( [ eq - gamma - theta - xyz - eq - b ] ) yield    = .",
    "thus ,    = .",
    "consider the two components of the vector on the right hand side of the last equation .",
    "they must sum to one :    = 1 .",
    "[ eq - pre - final - non - lin - gamma ] substituting the value for @xmath180 given by eq.([eq - theta - z - in - kt ] ) into eq.([eq - pre - final - non - lin - gamma ] ) finally yields    ( k_y + k_x t_y)^2 ( 1 + t_x^2 ) |y|^2= ( 1+t_y^2 ) t_x^2 |x|^2 .",
    "[ eq - final - non - lin - gamma ] as foretold , in order to find @xmath170 in terms of @xmath181 , we must solve for the root @xmath170 of a nonlinear equation , eq.([eq - final - non - lin - gamma ] ) .",
    "let @xmath26 be a @xmath44-subset .",
    "suppose that we express each @xmath45 in the form    u_b = e^i_b e^i_b e^i(_b + _ b)(i)^f(b ) , where @xmath46 are real parameters , where the vectors @xmath47 , and @xmath48 are orthonormal , and where @xmath49 is an indicator function which maps the set of all possible @xmath28 into @xmath50 .",
    "of course , @xmath51 .",
    "appendix [ app - param ] shows how to find the parameters @xmath52 for a given @xmath53 .",
    "the goal of this appendix is to solve the following minimization problem .",
    "if the value of the parameters @xmath52 and the vectors @xmath182 are allowed to vary , while keeping the vectors @xmath54 orthonormal and keeping all @xmath45 fixed , find vectors @xmath54 that are optimal , in the sense that they minimize a cost function .",
    "the cost function penalizes deviations of the diagonal matrices @xmath55 away from the 2d identity matrix @xmath56 .",
    "any choice of orthonormal vectors @xmath47 will be called * strong directions * and @xmath48 will be called a * weak direction * , or an * axis of the @xmath44-subset*. an axis that minimizes the cost function will be called the * optimum axis of the @xmath44-subset*.                x_b,1 ^ 2 + x_b,2 ^ 2 = 1 .",
    "eq.([eq - vec - thetab ] ) expresses @xmath186 in terms of the  fundamental \" variables @xmath187 .",
    "likewise , @xmath183 , @xmath184 , and @xmath185 can be expressed in terms of these fundamental variables as follows :                _ b = e^i _ b .",
    "we will use the simple matrix norm @xmath189",
    "( i.e. , the sum of the absolute value of each @xmath13 entry ) .",
    "we define the cost function ( lagrangian ) @xmath190 for our minimization problem to be the sum over @xmath28 of the distance between @xmath188 and the 2d identity matrix @xmath56 .",
    "thus ,        = 4 _ b ( _ b ) _ b .",
    "[ eq - dl - in - dgamma ] the variations @xmath191 represent @xmath30 degrees of freedom ( * dof s * ) , but they are not independent dofs , as they are subject to the following constraints . for all @xmath28 , @xmath45 is kept fixed during the variation of @xmath190 , so    [ eq - vari - contr ] u_b = ( i _ b)u_b + e^i_be^i_b ( p_b + i _",
    "b)(i)^f(b ) + u_b ( i f(b))=0 .",
    "[ eq - vari - contr - ub ] ( we ve used the fact that @xmath192 ) .",
    "the vectors @xmath193 and @xmath194 are kept orthonormal ( i.e. , @xmath195 for all @xmath196 ) during the variation of @xmath190 , so          eq.([eq - vari - contr - ub ] ) represents @xmath199 constraints .",
    "eq.([eq - vari - contr - ortho ] ) represents 3 constraints .",
    "eq.([eq - vari - contr - pb ] ) and eq.([eq - vari - contr - xb ] ) together represent @xmath200 constraints .",
    "thus , eqs.([eq - vari - contr ] ) altogether represent @xmath201 ( scalar ) equations in terms the @xmath202 ( scalar ) unknowns ( the unknowns are : 3 components of @xmath203 , 3 components of @xmath204 , and , for all @xmath28 , @xmath205 )",
    ". therefore , there are really only 3 independent dofs within these @xmath202 variations .",
    "next , we will express @xmath206 in terms of only 3 independent variations ( for independent variations , we will find it convenient to use @xmath207 and @xmath208 ) .",
    "once @xmath206 is expressed in this manner , we will be able to set to zero the coefficients of the 3 independent variations .              _",
    "b= f(b)(p_b-_b ) .",
    "eqs.([eq - du - expanded ] ) constitute 4 constraints , but only 3 are independent . indeed ,",
    "if one dot - multiplies eq.([eq - du - expanded - trio ] ) by @xmath210 , one gets eq.([eq - du - expanded - singlet ] ) .",
    "so let us treat eq.([eq - du - expanded - singlet ] ) as a redundant statement and ignore it .",
    "dot - multiplying eq.([eq - du - expanded - trio ] ) by @xmath47 and @xmath211 separately , yields the following 3 constraints :                            we have succeeded in expressing @xmath219 in term of the 9 variations @xmath220 of the strong and weak directions . but not all of these 9 variations are independent due to the orthonormality of @xmath54 .",
    "our next goal is to express these 9 variations in terms of 3 that can be taken to be independent .",
    "b_b =- q_b w_z_j x_bj_j -f(b)p_b_j s_jz_j . substituting this expression for @xmath228 into eq.([eq - del - l - in - b ] ) for @xmath219",
    "gives a new expression for @xmath219 . in the new expression for @xmath219",
    ", we may set the coefficients of @xmath229 separately to zero .",
    "this yields :              suppose we denote the two constraints of eq.([eq - fruit - of - optimiz ] ) by @xmath233 .",
    "these two constraints depend on the set of variables @xmath234 . using eqs.([eq - strong - in - kxy ] ) and the results of appendix [ app - param ] , the variables @xmath235 can all be expressed in terms of @xmath236 and @xmath26 .",
    "thus what we really have is @xmath237 for @xmath151 .",
    "these two equations can be solved numerically for the two unknowns @xmath236 ."
  ],
  "abstract_text": [
    "<S> a quantum compiler is a software program for decomposing (  compiling \" ) an arbitrary unitary matrix into a sequence of elementary operations ( seo ) . </S>",
    "<S> the author of this paper is also the author of a quantum compiler called qubiter . </S>",
    "<S> qubiter uses a matrix decomposition called the cosine - sine decomposition ( csd ) that is well known in the field of computational linear algebra . </S>",
    "<S> one way of measuring the efficiency of a quantum compiler is to measure the number of cnots it uses to express an unstructured unitary matrix ( a unitary matrix with no special symmetries ) </S>",
    "<S> . we will henceforth refer to this number as @xmath0 . in this paper , </S>",
    "<S> we show how to improve @xmath0 for qubiter so that it matches the current world record for @xmath0 , which is held by another quantum compiling algorithm based on csd . </S>"
  ]
}