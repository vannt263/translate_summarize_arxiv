{
  "article_text": [
    "many phenomena in nature and in particular fluid dynamics exhibit a dominant spatial direction along which the essential dynamics occur .",
    "examples are blood flow problems or the flow in river beds which can be both modeled by the incompressible navier - stokes equations ( cf .",
    "@xcite ) or groundwater flow in unsaturated soils which may be described by the richards equation ( cf .  @xcite ) . this feature can be exploited to derive a dimensionally reduced model for the dominant direction , which should however include information on the transverse dynamics to improve the accuracy of the approximation .",
    "this paper is devoted to the derivation of an efficient dimensional reduction approach for steady nonlinear partial differential equations ( pdes ) of the general type @xmath0 here @xmath1 is a bounded domain with lipschitz boundary , @xmath2 is a given right hand side , @xmath3 denotes a nonlinear elliptic operator and @xmath4 is the dual pairing of @xmath5 and @xmath6 .",
    "note that the steady richards equation is a pde of type .",
    "moreover , treating the steady incompressible navier - stokes equations just requires to replace @xmath6 in by a divergence - free space , which we forego in this paper to simplify the presentation . for the same reason we also restrict to @xmath7 and assume that the domain @xmath8 is given as a tensor product , i.e. @xmath9 with @xmath10 .",
    "+ we use the term ` dimensional reduction ' in the sense of vogelius and babuka @xcite , which means that a dimensional reduction method reduces the space dimension of the considered pde by at least one .",
    "needless to say that a dimensional reduction method may therefore be also seen as a model order reduction procedure .",
    "+ there is a large variety of dimensional reduction methods and low rank tensor based approximations . the asymptotic expansion technique @xcite is based on an expansion of the solution dependent on the presumed small ratio between the length of the domain in transverse and dominant direction .",
    "this method neglects the transverse dynamics and is only valid if the considered domain is very thin , or equivalently , the solution is constant along the vertical direction , which is often not the case .",
    "+ to overcome this difficulty in the work by vogelius and babuka @xcite the hierarchical model reduction ( hmr ) approach has been introduced in the context of heat conduction in plates and shells .",
    "the idea of hmr is to perform a galerkin projection of the full variational problem onto a reduced , @xmath11-dimensional space , which combines the full solution space in the dominant direction with a @xmath11-dimensional reduction space in the transverse direction , spanned by modal orthonormal basis functions .",
    "this yields a ( possibly nonlinear ) system of @xmath11 equations in one space dimension .",
    "the application and applicability of the hmr approach for linear advection - diffusion problems that exhibit a dominant flow direction has been studied and demonstrated by perotto , ern and veneziani in @xcite in a more general geometric setting . exploiting that hmr yields a hierarchy of reduced models determined by the reduction space , the dimension of the models",
    "is chosen adaptively in different subdomains of @xmath8 , employing an iterative substructuring method to couple the local models @xcite . in all these contributions",
    "the reduction space is spanned by a priori chosen boundary - adapted legendre or trigonometric polynomials .",
    "+ the key idea of the hierarchical model reduction method based on reduced basis techniques ( rb - hmr ) introduced in @xcite is to use a highly nonlinear approximation in the sense of @xcite for the construction of the reduction space .",
    "this is realized by first deriving a parametrized one - dimensional problem in the transverse direction from the full problem where the parameters reflect the influence from the unknown solution in the dominant direction . in a second step",
    "reduced basis ( rb ) methods are used to generate a snapshot set from the solution manifold of the parametrized transverse problems and to choose the reduction space from these snapshots by a proper orthogonal decomposition ( pod ) . in this way both in the construction of the solution manifold and the subsequent choice of the basis functions , information on the full solution is included , and the rb - hmr approach benefits from the good approximation properties of rb methods @xcite .",
    "this yields often an exponentially fast convergence of the rb - hmr method even for non - smooth functions and a more rapid convergence of the rb - hmr method than the classical hmr approach based on polynomials @xcite .",
    "it has also been demonstrated in @xcite for linear problems that thanks to its rapid convergence and the fact that the parametrized problems are of lower dimension than the full problem , the rb - hmr approach yields in many cases a very accurate approximation at a smaller cpu time , including the costs for the construction of the reduction space , than a corresponding full dimensional finite element method ( fem ) solve .",
    "for these reasons , we consider the rb - hmr approach in this paper .",
    "+ while hmr constitutes an interpolation between the full model and the lower dimensional model via the dimension of the reduction space , in the geometrical multiscale approach models in one space dimension or lumped models as say electronic network models are locally enhanced with the full dimensional model by a domain decomposition scheme ( cf .",
    "@xcite ) . finally ,",
    "similar to hmr also the proper generalized decomposition method ( cf .",
    "@xcite and references therein ) is a tensor based approximation , but the tensor products in the expansion are computed iteratively by solving the euler - lagrange equations corresponding to the considered problem .",
    "+ the key challenge in applying dimensional reduction to nonlinear pdes is the efficient evaluation of the nonlinear operator which requires in principle computations that scale with the degrees of freedom of the full system and not the reduced one as in the linear case .",
    "this is a general issue for projection - based model order reduction methods for nonlinear pdes or nonlinear systems and several ways to tackle this problem have been proposed .",
    "common to all these approaches is a first step in which an additional basis  a so - called collateral basis  is constructed say via a pod or a greedy algorithm to approximate the range of the nonlinear operator .",
    "the methods then differ in the way the coefficients are computed .",
    "+ the gauss - newton with approximated tensors method @xcite is based on the gappy pod @xcite and therefore employs a projection via a gappy inner product defined as a linear combination of evaluations in certain points in the spatial domain . the discrete empirical interpolation method ( deim ) @xcite or the slightly more general empirical operator interpolation method ( eoim ) @xcite employ the empirical interpolation method ( eim ) @xcite .",
    "the latter allows for the interpolation of a parametrized function via lagrangian interpolants , where both the collateral basis and the interpolation points are constructed by a greedy algorithm .",
    "it has been applied for the approximation of parametrized nonlinear pdes within the framework of rb methods for instance in @xcite . a rigorous a posteriori error estimator for parametrically smooth functions has been introduced in @xcite .",
    "moreover , a ( non - rigorous ) hierarchical a posteriori error estimator which compares the solution with an approximation obtained by employing a richer collateral basis space has been derived in @xcite for the eim , in @xcite for the eoim , and in @xcite for the deim . a rigorous a posteriori error estimator for the deim is presented in @xcite but the constant in the estimate depends on the underlying discretization . to facilitate an approximation of functions of low regularity both in the eoim and the recently introduced generalized empirical interpolation method ( geim ) @xcite",
    "the eim is generalized by considering ( also ) the evaluation of linear functionals .",
    "a priori error analysis for the geim as introduced in @xcite has been provided in @xcite . in this paper",
    "we apply the pod to construct the collateral basis as the pod is optimal in an @xmath12-sense and use the geim to select interpolating functionals . +",
    "as the dependency of the range of the nonlinear operator on the parameter and the spatial variables is in general non - smooth , we expect that we need many collateral basis functions and interpolating functionals to obtain an accurate approximation .",
    "to speed up the ( online ) computations often localized approximations are considered for instance by constructing ( offline ) a partition of the parameter space @xcite or the time domain @xcite and computing local collateral bases associated with each element of the partition .",
    "online the correct basis is chosen following a certain criterion .",
    "recently , it has been proposed to employ machine learning techniques to form clusters of similar snapshots and compute a collateral basis for each cluster in the offline stage for the gauss - newton with approximated tensors method @xcite and the deim @xcite .",
    "the appropriate local collateral space is then chosen in the online stage either by a distance measure @xcite or classification strategies based on machine learning @xcite .",
    "+ however , in all partitioning methods based on the eim @xcite the number of interpolating points equals the number of ( local ) collateral basis functions , which may lead to an insufficient resolution of the ( non - smooth ) collateral basis functions and thus a considerably less accurate approximation .",
    "therefore , we propose to perform an adaptive partitioning of the spatial domain driven by a suitable error indicator until a certain tolerance is reached and define the global interpolant as a sum of the local interpolants .",
    "we employ this adaptive ( generalized ) empirical interpolant to approximate the nonlinear term in the inner products of the coefficients of the orthogonal projection on the collateral basis .",
    "this yields an automatic numerical integration program based on the ( g)eim which we call the adaptive empirical projection method ( epm ) .",
    "we emphasize that in case of a nonlinear term which is smooth with respect to the spatial variable this higher regularity is maintained as we project onto the global collateral basis and employ the localized interpolants only within the inner products of the coefficients .",
    "we prove rigorous a priori and a posteriori error estimators for the adaptive epm which do not require additional regularity of the nonlinear operator and are independent of the underlying finite element discretization .",
    "note that we do not propose to employ the adaptive epm instead of the above mentioned partitioning or clustering methods but rather suggest to combine them .",
    "+ to extend the rb - hmr approach to nonlinear pdes of type , we therefore propose to proceed in the following way . also for the construction of the collateral basis , we employ a highly nonlinear approximation . to generate a manifold of parametrized one - dimensional operator evaluations we use the solutions of the parametrized dimensionally reduced problem , derived as in the linear case , and the associated parametrization . during an adaptive training set extension procedure the sets of solution and operator snapshots are simultaneously generated .",
    "the collateral basis space is constructed by applying a pod to the operator snapshots and to compute the coefficients we employ the adaptive epm .",
    "+ the rigorous a priori and a posteriori error estimators for the adaptive epm are employed for the derivation of a rigorous a posteriori error estimator based on the brezzi - rappaz - raviart theory @xcite which estimates both the error contribution caused by model reduction and by the approximation of the nonlinear operator .",
    "hence another contribution of this paper is the extension of the results in @xcite and particularly @xcite from quadratically nonlinear to general nonlinear pdes of type .",
    "this a posteriori error estimator is used within the context of the adaptive snapshot generation procedure .",
    "numerical experiments for the elliptic nonlinear diffusion equation show that due to an unfavorable inf - sup constant the brezzi - rappaz - raviart condition is rather restrictive and that the effectivities of the error estimator are rather high .",
    "however , the numerical experiments demonstrate a fast convergence of the rb - hmr approach and a linear scaling in the number of finite elements used in the dominant direction .",
    "+ the article is organized as follows . in section [ epm ]",
    "we introduce the adaptive epm for the approximation of parametrized functions in @xmath13 .",
    "the approximation properties of the adaptive epm are discussed and rigorous a priori and a posteriori error estimates are derived . in the subsequent section [ sect - hmr - nonlin ]",
    "the problem adapted rb - hmr framework @xcite is generalized to nonlinear problems , using the approximation properties of the adaptive epm .",
    "the resulting model reduction algorithm is discussed in detail and analyzed rigorously based on the brezzi - rappaz - raviart theory @xcite .",
    "next , we analyze the convergence behavior and the computational efficiency of the rb - hmr approach numerically for an elliptic nonlinear diffusion problem in section [ numerics_nonlin ] . furthermore , we investigate the reliability and effectivity of the proposed error estimators and test the applicability of the a priori and a posteriori bounds for the adaptive epm . in section [ conclusion ]",
    "we provide some conclusions and final remarks .",
    "in this section we introduce the adaptive epm which aims at approximating all elements of a manifold @xmath14 , where @xmath15 equals for instance the evaluation of a nonlinear differential operator in the solution of a pde parametrized by @xmath16 . here",
    "@xmath17 and @xmath18 denotes the @xmath19-dimensional parameter domain .",
    "needless to say that we may identify the manifold @xmath20 with a ( target ) function @xmath21 for which we assume @xmath22 .",
    "moreover , we require that we have a snapshot set @xmath23 of the function @xmath24 at our disposal , where @xmath25 is a finite dimensional training set of size @xmath26 .",
    "the space @xmath27 with @xmath28 is then defined through a pod , i.e. @xmath29    geim(@xmath30 , @xmath31 , @xmath32 ) + set @xmath33 + @xmath34 , @xmath35 , @xmath36    we approximate the function @xmath37 in the integrals of the orthogonal projection @xmath38(\\mu , y ) : = \\sum_{l = 1}^{k } \\int_{{\\omega } } u(\\mu , z)\\ , \\kappa_{l}({z})\\ ,   d{z}\\,\\ , \\kappa_{l}(y)\\ ] ] by a ( generalized ) empirical interpolant @xmath39 $ ] .",
    "the key idea of the adaptive epm is that we adaptively decompose the domain @xmath40 into subdomains , construct local interpolants on each subdomain and then define the ( global ) interpolant @xmath39 $ ] as the sum of all local interpolants . to construct the latter we employ the set of functions @xmath41 , restrict them to the respective subdomain , apply a local pod to obtain a localized linear independent set of functions , and apply the geim @xcite locally to select the evaluating linear functionals from a ( given ) dictionary . before we describe the adaptive epm in detail we recall the geim and adapt some theoretical findings for the geim to our setting .",
    "+ we suppose that we have given a dictionary @xmath42 of linear functionals @xmath43 of the form @xmath44 for @xmath45 whose ( unique ) riesz representation @xmath46 satisfies @xmath47 . for @xmath48 and @xmath46 , @xmath49",
    "we then define localized functionals @xmath50 as @xmath51 and denote the corresponding localized dictionary with @xmath31 .",
    "note that the functions @xmath46 are the same for the functional @xmath52 and its localized version @xmath50 .",
    "additionally , we assume that the dictionaries @xmath31 are unisolvent in the sense that if we have for any @xmath53 that @xmath54 for all @xmath55 this implies @xmath56 almost everywhere in @xmath32 . the selection of the interpolating functionals @xmath57 for a given set of linear independent functions @xmath58 is described in algorithm [ eim ] . for a function @xmath59",
    "we then define the local interpolant @xmath60(\\mu , y):= \\sum_{j=1}^{k_{i } } \\alpha_{j}^{k_{i}}(\\mu ) q_{j}^{i}(y)$ ] , where the coefficients are the solutions of : @xmath61 , @xmath62 and @xmath63 .",
    "the following lemma adapts some results for the geim to our setting .",
    "[ prop - eim ] let the set of interpolating functionals @xmath34 be selected by algorithm [ eim ] and let the assumptions from the previous paragraph be fulfilled .",
    "then we have    1 .",
    "the matrix @xmath36 is lower triangular with unity diagonal and hence invertible .",
    "moreover , there holds @xmath64 , @xmath65 .",
    "the set of functions @xmath66 forms a basis for the space @xmath67 and the selection of the interpolating functionals is well - defined .",
    "the interpolation is exact for all @xmath68 .",
    "3 .   there exist unique functions @xmath69 , that satisfy @xmath70 , @xmath65 .    to prove ( i ) we adapt the argumentation in @xcite to our setting .",
    "we proceed by induction . by definition",
    "we have that @xmath71 .",
    "let us assume that @xmath72 .",
    "the construction of @xmath73 is well - defined if @xmath74 is invertible and @xmath75 .",
    "the properties of the matrix @xmath74 can be proved as in @xcite , exploiting the definition of the linear functionals @xmath76 in line [ selection_functional ] of algorithm [ eim ] . to show @xmath75 we argue by contradiction .",
    "assume @xmath77 .",
    "thanks to the unisolvence property of the dictionary @xmath31 we infer that @xmath78 almost everywhere in @xmath32 . exploiting the induction hypothesis",
    "we can express the functions @xmath79 and thus @xmath80 in the basis @xmath81 which is contradictory to the requirement that the set of functions @xmath82 is linear independent .",
    "assertion ( ii ) can be proved as in @xcite and assertion ( iii ) follows from the invertibility of @xmath36 .",
    "adaptive epm(@xmath83 , @xmath42 , @xmath84 , @xmath85 , @xmath86 , @xmath87 ) + * initialize * @xmath88 , @xmath89 , @xmath90 ; define @xmath91 as the partition consisting of one element @xmath32 .",
    "+ compute @xmath92$]= geim(@xmath83,@xmath31,@xmath32).[ori - eim ] + @xmath93 , @xmath94 , @xmath95 , @xmath96 .    to formulate the adaptive empirical projection method [ adapt - epm ] and hence an adaptive integration algorithm based on geim",
    ", we introduce a non - uniform partition @xmath91 of @xmath97 with elements @xmath32 .",
    "@xmath98 and @xmath99 denote the left and right interval boundary of @xmath32 . in algorithm",
    "[ adapt - epm ] we first apply the standard geim on the whole domain @xmath97 in line [ ori - eim ] to the set @xmath100 .",
    "if the integration error @xmath101 as defined in for @xmath102 is smaller than the prescribed tolerance @xmath85 we stop without refining .",
    "otherwise we bisect in each iteration those intervals for which @xmath103 holds .",
    "note that the error @xmath101 is computable as it only requires the knowledge of @xmath24 for @xmath104 , which can be accessed via @xmath84 . on the new intervals we first define the localized dictionaries as described above and apply a pod in line [ local_pod ] to generate linear independent localized sets of functions @xmath105 and @xmath106 such that @xmath107 , @xmath108 .",
    "note that we may alternatively define @xmath109 as a linear independent subset of @xmath110 with @xmath107 , @xmath108 .",
    "subsequently we perform a localized geim to select sets of localized interpolating functionals @xmath111 and @xmath112 which are employed to define the local interpolants @xmath113 $ ] and @xmath114 $ ] for @xmath115 and @xmath116 , respectively .",
    "we stop either if @xmath117 or if the maximal number of iterations @xmath86 is reached .",
    "the empirical projection of @xmath118 is then defined as @xmath119(\\mu , y ) : = \\sum_{n = 1}^{k } \\int_{{\\omega } } \\mathcal{i}_{l}[u](\\mu , z)\\ , \\kappa_{n}(z)\\ ,   dz\\,\\ , \\kappa_{n}(y ) , \\quad \\mathcal{i}_{l}[u](\\mu , y ) : = \\sum_{i \\in \\mathfrak{i } } \\mathcal{i}^{i}_{k_{i}}[u](\\mu , y ) = \\sum_{i \\in \\mathfrak{i } } \\sum_{j=1}^{k_{i } } \\sigma^{i}_{j}(u(\\mu,\\cdot ) ) \\vartheta_{j}^{i}({y } ) , \\end{aligned}\\ ] ] where the functions @xmath120 , @xmath121 , have been defined in lemma [ prop - eim ] and @xmath122 .",
    "finally , we remark that @xmath86 has been introduced for security purposes , as , so far , we could only prove the convergence of the adaptive epm under certain assumption which are relatively mild , though .",
    "this issue as well as rigorous a priori and a posteriori bounds are addressed in the following subsection .",
    "to control the projection error @xmath123 \\|_{l^{2}(\\mathcal{d}\\times\\omega)}$ ] by the pod error on the snapshot set , we interpret the discrete @xmath12-norm occurring in the definition of the pod - space as a numerical approximation of the corresponding integral with the monte carlo method , which is one new contribution of the proof , and subsequently use ideas of kunisch and volkwein @xcite .",
    "the main new contribution of theorem [ apriori - epm ] is the control of the term @xmath124 - p_{k}^{l}[u]\\|_{l^{2}(\\mathcal{d}\\times\\omega)}$ ] , which is possible due to the design of the adaptive epm , using the monte carlo quadrature . to assess the integration error of the latter , we introduce the following notion @xcite : for sequences @xmath125 of random variables we write @xmath126 , if for any @xmath127 there exists @xmath128 such that @xmath129 for all @xmath130 , where @xmath131 denotes the probability of the event @xmath132 .",
    "+ we also introduce the operator @xmath133 , defined as @xmath134 note that @xmath135 is a bounded , self - adjoint , and nonnegative operator and further compact thanks to its finite dimensional image .",
    "we denote with @xmath136 the eigenvalues that satisfy the eigenvalue problem : find @xmath137 such that @xmath138 and assume that the eigenvalues @xmath136 are listed in non - decreasing order of magnitude , i.e. @xmath139 and @xmath140 for @xmath141 .",
    "note that we have added the superscript @xmath142 at the eigenvectors @xmath143 to highlight their dependency on @xmath142 and @xmath87 .",
    "[ apriori - epm ] we assume that the parameter values @xmath104 are sampled from the uniform distribution over @xmath144 .",
    "then for every @xmath145 there exists an @xmath146 such that for all @xmath147 @xmath148 \\|_{l^{2}(\\mathcal{d}\\times\\omega ) } \\leq \\left(\\underset{l = k + 1}{\\overset{d(n)}{\\sum } } \\lambda_{l}^{n}\\right)^{1/2}+ e_{\\text{{\\tiny int}}}^{1/2 } + \\varepsilon.\\ ] ] if furthermore @xmath149 there exists an @xmath146 such that for all @xmath147 @xmath150 \\|_{l^{2}(\\mathcal{d}\\times\\omega ) } \\leq   \\sqrt{2 } \\left(\\underset{l = k + 1}{\\overset{\\infty}{\\sum } } \\lambda_{l}^{\\infty}\\right)^{1/2 } + e_{\\text{{\\tiny int}}}^{1/2 } + \\varepsilon,\\ ] ] and @xmath151 for @xmath152 as @xmath153 and @xmath154 strongly in @xmath13 for @xmath152 and @xmath155 , where @xmath156 are the eigenvalues and @xmath157 are the eigenfunctions of the operator @xmath158 , defined as @xmath159 regarding the rate of convergence in @xmath142 , we have that @xmath160 \\|_{l^{2}(\\mathcal{d}\\times\\omega ) } & \\leq \\left(\\underset{l = k + 1}{\\overset{d(n)}{\\sum } } \\lambda_{l}^{n}\\right)^{1/2}+ e_{\\text{{\\tiny int}}}^{1/2 } + \\mathcal{o}_{p}(n^{-1/4})\\\\ \\text{and } \\quad   \\label{train_size_inf_rate}\\| u - p_{k}^{l}[u ] \\|_{l^{2}(\\mathcal{d}\\times\\omega ) } & \\leq   \\sqrt{2 } \\left(\\underset{l = k + 1}{\\overset{\\infty}{\\sum } } \\lambda_{l}^{\\infty}\\right)^{1/2 } + e_{\\text{{\\tiny int}}}^{1/2 } + \\mathcal{o}_{p}(n^{-1/4}).\\end{aligned}\\ ] ] if algorithm [ adapt - epm ] converges , i.e. @xmath161 , the estimates  hold with @xmath162 replaced by @xmath163 .",
    "we begin with splitting the error into a projection error and an integration error : @xmath164 \\|_{l^{2}(\\mathcal{d}\\times\\omega ) } \\leq \\| u - p_{k}[u ] \\|_{l^{2}(\\mathcal{d}\\times\\omega ) }   + \\| p_{k}[u ] - p_{k}^{l}[u]\\|_{l^{2}(\\mathcal{d}\\times\\omega ) } .\\ ] ] thanks to the assumptions on @xmath87 we can interpret for an arbitrary function @xmath165 , the term @xmath166 as a numerical approximation of the integral @xmath167 with the monte carlo method .",
    "thus , the strong law of large numbers ( see for instance @xcite ) yields that for every @xmath168 there exists an @xmath169 such that for all @xmath170 @xmath171 \\|_{l^{2}(\\mathcal{d}\\times\\omega)}^{2 }    = \\left(\\frac{1}{n } \\sum_{\\mu \\in \\xi }   \\| u(\\mu,\\cdot ) - \\sum_{l=1}^{k } \\int_{{\\omega}}u(\\mu,{z } ) \\kappa_{l}({z } ) \\,d{z } \\,\\kappa_{l}\\|_{l^{2}({\\omega})}^{2}\\right )   + \\delta \\leq \\left(\\underset{l = k + 1}{\\overset{d(n)}{\\sum } } \\lambda_{l}^{n}\\right ) + \\delta,\\end{aligned}\\ ] ] where we have used the classical estimate for the pod error . approximating also the integral of the second term in with a monte carlo method and using the outcome of algorithm [ adapt - epm ] , we obtain that for every @xmath168 there exists an @xmath172 such that for all @xmath173 @xmath174 - p_{k}^{l}[u ] \\|_{l^{2}(\\mathcal{d}\\times\\omega)}^{2 }    = \\left(\\frac{1}{n } \\sum_{\\mu \\in \\xi }   \\| \\sum_{l=1}^{k } \\int_{{\\omega}}u(\\mu,{z } ) \\kappa_{l}({z } )   \\,d{z } \\,\\kappa_{l } - \\sum_{l=1}^{k } \\int_{{\\omega}}\\mathcal{i}_{l}[u](\\mu,{z } )   \\kappa_{l}({z } ) \\,d{z } \\,\\kappa_{l}\\|_{l^{2}({\\omega})}^{2}\\right )   + \\delta\\\\ & \\qquad = \\left(\\frac{1}{n } \\sum_{\\mu \\in \\xi }   \\| \\sum_{l=1}^{k } \\int_{{\\omega}}(u(\\mu,{z } ) -   \\mathcal{i}_{l}[u](\\mu,{z } ) )   \\kappa_{l}({z } )   \\,d{z } \\,\\kappa_{l}\\|_{l^{2}({\\omega})}^{2}\\right ) + \\delta   \\leq e_{\\text{{\\tiny int } } } + \\delta.\\end{aligned}\\ ] ] choosing @xmath175 and @xmath176 yields .",
    "+ to show we first note that the operator @xmath177 , defined as @xmath178 is a hilbert - schmidt integral operator and thus compact .",
    "boundedness of the operator @xmath179 , defined as @xmath180 yields that @xmath181 is a compact operator as well .",
    "the estimate , @xmath151 for @xmath152 as @xmath153 and @xmath154 strongly in @xmath13 for @xmath152 can then be proved completely analogous to the argumentation in section 3.2 of @xcite .",
    "note that the convergence of @xmath182 to @xmath157 strongly in @xmath13 for @xmath152 and @xmath155 leads to the well - definedness of the interpolating functionals @xmath34 , @xmath183 also for @xmath184 and thus to the boundedness of the term @xmath185 independent of @xmath142 .",
    "+ finally , the ( probabilistic ) convergence rate in @xmath142 is a direct consequence of the central limit theorem ( see for instance @xcite ) .",
    "we remark that the assumptions on @xmath87 can be weakened in the sense that also an adaptive sampling strategy can be considered .",
    "this may change the convergence rate of the monte carlo method , but does not affect the proof of theorem [ apriori - epm ] .",
    "alternatively , a quasi - monte carlo method may be used , which has an improved convergence rate of approximately @xmath186 for some constant @xmath187 @xcite .",
    "+ next , we prove under certain assumptions that the integration error @xmath185 converges to @xmath188 if @xmath189 and thus that the adaptive integration algorithm [ adapt - epm ] converges .",
    "the main ingredients of the proof are the classical pod error bound , the exploitation of the properties of the geim as recalled in lemma [ prop - eim ] on the elements @xmath190 , and the bounds of the interpolation error of the localized geim .",
    "+ to this end we introduce for each @xmath190 the lebesgue constant with respect to the @xmath191-norm @xcite as @xmath192(\\mu,\\cdot)\\|_{l^{2}(i)}}{\\| g(\\mu,\\cdot ) \\|_{l^{2}(i)}}.\\ ] ]    based on that we obtain the following bound for @xmath185 .    [ apriori - epm - convergence ]",
    "we assume that the parameter values @xmath104 are sampled from the uniform distribution over @xmath144 . then there holds @xmath193    let @xmath32 be an arbitrary interval in @xmath91 . exploiting @xmath28 twice , we obtain @xmath194(\\mu,{y } ) ) \\kappa_{l}({y } ) \\,d{y } \\right ) ^{2 } \\leq   \\frac{1}{n } \\sum_{\\mu \\in \\xi } k \\|u(\\mu,\\cdot ) - \\mathcal{i}_{l}[u](\\mu,\\cdot )   \\|_{l^{2}({\\omega})}^{2}. \\end{aligned}\\ ] ] for each @xmath104 we can further estimate : @xmath195(\\mu,\\cdot )   \\|_{l^{2}({\\omega})}\\leq \\underset{(i)}{\\underbrace{\\| u(\\mu,\\cdot ) - \\mathcal{i}_{l}[p_{k}[u]](\\mu,\\cdot ) \\|_{l^{2}({\\omega } ) } } } + \\underset{(ii)}{\\underbrace{\\| \\mathcal{i}_{l}[p_{k}[u]](\\mu,\\cdot ) - \\mathcal{i}_{l}[u ] ( \\mu,\\cdot)\\|_{l^{2}({\\omega})}}}.\\end{aligned}\\ ] ] as the geim is exact for all @xmath196 ( see lemma [ prop - eim ] ) , we obtain for @xmath197 :",
    "@xmath198(\\mu,\\cdot ) \\|_{l^{2}({\\omega})}^{2 } = \\sum_{i \\in \\mathfrak{i } } \\| u(\\mu,\\cdot ) - \\mathcal{i}_{l}[p_{k}[u]](\\mu,\\cdot ) \\|_{l^{2}(i)}^{2 }   = \\sum_{i \\in \\mathfrak{i } } \\| u(\\mu,\\cdot ) - p_{k}[u](\\mu,\\cdot ) \\|_{l^{2}(i)}^{2}.\\end{aligned}\\ ] ] using the definition of the lebesgue constant we get for @xmath199 : @xmath200(\\mu,\\cdot ) - \\mathcal{i}_{l}[u ] ( \\mu,\\cdot)\\|_{l^{2}({\\omega})}^{2 } & =   \\sum_{i \\in \\mathfrak{i } } \\| \\mathcal{i}_{l}[p_{k}[u]](\\mu,\\cdot ) - \\mathcal{i}_{l}[u ] ( \\mu,\\cdot)\\|_{l^{2}(i)}^{2 } \\\\[-1.5ex ] \\label{est200}\\\\[-1.5ex ] \\nonumber & \\leq \\sum_{i \\in \\mathfrak{i } } ( \\lambda_{k_{i}}^{i})^{2 } \\| p_{k}[u](\\mu,\\cdot ) - u(\\mu,\\cdot ) \\|_{l^{2}(i)}^{2}.\\end{aligned}\\ ] ] by combining the estimates and we obtain @xmath201(\\mu,\\cdot ) \\|_{l^{2}({\\omega } ) } \\leq \\left\\{1 + \\left(\\sum_{i \\in \\mathfrak{i } } ( \\lambda_{k_{i}}^{i})^{2}\\right)^{1/2 } \\right\\ } \\| u(\\mu,\\cdot ) - p_{k}[u](\\mu,\\cdot ) \\|_{l^{2}({\\omega})}.\\end{aligned}\\ ] ] the estimates and together with the classical estimate of the pod - error yield the desired result @xmath202(\\mu,\\cdot ) \\|_{l^{2}({\\omega})}^{2}\\right\\ } \\\\ & \\qquad\\qquad\\leq k \\left(1 + \\left(\\sum_{i \\in \\mathfrak{i } } ( \\lambda_{k_{i}}^{i})^{2}\\right)^{1/2 } \\right)^{2 } \\left(\\underset{l = k + 1}{\\overset{d(n)}{\\sum } } \\lambda^{n}_{l}\\right).\\end{aligned}\\ ] ]    to obtain convergence of the adaptive epm we thus need that the lebesgue constant increases rather moderately for growing @xmath203 . exploiting the properties of the entries of the matrices",
    "@xmath95 it can be proved ( see @xcite ) that the lebesgue constants @xmath204 , @xmath190 can be bounded as follows : @xmath205 therefore the pod - error @xmath206 has to converge exponentially fast so that yields convergence of the adaptive epm .",
    "however , numerical results ( see @xcite ) show that the lebesgue constant increases much slower than anticipated by and in many cases even linear .",
    "very recently it has been demonstrated in @xcite that for @xmath49 the localized generalized empirical interpolant @xmath60 $ ] can be interpreted as a petrov - galerkin approximation of @xmath207 where the approximation space is @xmath208 and the test space is spanned by the riesz representations of the functionals @xmath209 in @xmath191 .",
    "the lebesgue constant @xmath210 then equals the reciprocal of the inf - sup constant associated with those approximation and trial spaces @xcite .",
    "this relates the lebesgue constant to the considered dictionary @xmath42 and allows some guidance on how to choose @xmath42 .",
    "+ we remark that the proofs for the convergence rates of the eim @xcite and for the geim @xcite crucially depend on the fact that the set of functions passed to algorithm 2.1 are chosen by a greedy algorithm .",
    "hence these results do not apply in our setting where we apply a pod .",
    "+ note also that proposition [ apriori - epm - convergence ] yields an upper bound for the ( computable ) integration error @xmath185 .",
    "therefore , we employ the a priori bounds in theorem [ apriori - epm ] to derive a rigorous a posteriori estimator by comparing with a superior approximation @xmath211 $ ] .",
    "we emphasize that due to the usage of the monte carlo method the a posteriori error estimate will be a probabilistic estimate . to determine the number of samples @xmath142 needed to ensure an integration error due to the monte carlo approximation of at most @xmath212 with a confidence level @xmath213 we introduce the empirical variances @xmath214(\\mu,\\cdot)\\|_{l^{2}(\\omega)}^{2 } - \\left\\{\\frac{1}{n } \\sum_{\\mu \\in \\xi}\\|u(\\mu,\\cdot ) - p_{k}[u](\\mu,\\cdot)\\|_{l^{2}(\\omega)}^{2}\\right\\}\\right)^{2}\\right]^{1/2},\\\\[-1.5ex ] & \\text{and }   \\label{empirical variances}\\\\[-1.5ex ] \\nonumber   & \\qquad\\quad \\varsigma_{2 } = \\left[\\frac{1}{n } \\sum_{\\mu \\in \\xi}\\left(\\|p_{k}[u](\\mu,\\cdot ) - p_{k}^{l}[u](\\mu,\\cdot)\\|_{l^{2}(\\omega)}^{2 } - \\left\\{\\frac{1}{n }",
    "\\sum_{\\mu \\in \\xi}\\|p_{k}[u](\\mu,\\cdot ) - p_{k}^{l}[u](\\mu,\\cdot)\\|_{l^{2}(\\omega)}^{2}\\right\\}\\right)^{2}\\right]^{1/2}.\\end{aligned}\\ ] ] then , we obtain the following result .",
    "[ apost - epm ] let the assumptions of theorem [ apriori - epm ] be fulfilled and let @xmath215 be a given tolerance",
    ". then the error estimate @xmath216 \\|_{l^{2}(\\mathcal{d}\\times \\omega ) } \\leq   \\varepsilon_{\\text{{\\tiny tol } } } + \\delta^{\\text{{\\tiny epm } } } + e_{\\text{{\\tiny int}}}^{1/2 } + \\mathcal{o}_{p}(n^{-1/4 } ) \\\\",
    "\\label{delta_epm } \\text{holds with } \\qquad \\delta^{\\text{{\\tiny epm } } } : = \\| p_{k'}^{l'}[u ] - p_{k}^{l}[u ] \\|_{l^{2}(\\mathcal{d}\\times \\omega)},\\end{aligned}\\ ] ] where @xmath217 is defined as the minimal number in \\{k+1, ...",
    ",d(n ) } , such that @xmath218 and @xmath219 is determined by algorithm [ adapt - epm ] , requiring @xmath220 .",
    "+ let @xmath212 be a given tolerance for the error caused by the monte carlo approximation , @xmath213 a given confidence level , and let @xmath142 satisfy @xmath221 . let in turn @xmath222 and @xmath223 fulfill @xmath224 , @xmath225 , and @xmath226 satisfy @xmath227 , where @xmath228 denotes the error function",
    ". then the estimate @xmath229 \\|_{l^{2}(\\mathcal{d}\\times \\omega ) } \\leq   \\varepsilon_{\\text{{\\tiny tol } } } + \\delta^{\\text{{\\tiny epm } } } + e_{\\text{{\\tiny int}}}^{1/2 } + \\varepsilon_{mc}\\ ] ] holds true with the confidence level @xmath213 .",
    "we apply the a priori bound to obtain @xmath230 \\|_{l^{2}(\\omega ) } \\leq \\left(\\underset{l = k + 1}{\\overset{d(n)}{\\sum } } \\lambda_{l}^{n}\\right)^{1/2}+ e_{\\text{{\\tiny int}}}^{1/2 } + \\mathcal{o}_{p}(n^{-1/4}).\\end{aligned}\\ ] ] with the definition of @xmath217 , the estimates in theorem [ apriori - epm ] and by computing @xmath231 $ ] with algorithm [ adapt - epm ] we get the result @xmath232 \\|_{l^{2}(\\omega ) } \\leq   \\varepsilon_{\\text{{\\tiny tol } } } + \\| p_{k'}^{l'}[u ] - p_{k}^{l}[u ] \\|_{l^{2}(\\omega ) }   + e_{\\text{{\\tiny int}}}^{1/2 } + \\mathcal{o}_{p}(n^{-1/4}).\\ ] ] estimate then follows directly from the central limit theorem and slutsky s theorem ( see for instance @xcite ) .",
    "note that there might be cases where choosing @xmath233 results in a situation , in which algorithm [ adapt - epm ] bisects an interval for @xmath203 but not for @xmath217 . to ensure that @xmath231 $ ] yields a better approximation than @xmath234 $ ]",
    ", we require @xmath235 . +      if we have @xmath236 one might want to consider point evaluations instead of evaluating functionals as the former might be easier to implement within a programming code .",
    "to this end we present in this subsection the changes that have to be made if we employ the eim as introduced in @xcite instead of the geim .",
    "+ first , for a function @xmath237 we replace the evaluation by a functional @xmath238 as @xmath239 by the point evaluation @xmath240 , @xmath241 for @xmath190 . apart",
    "from that no changes are required in algorithm [ eim ] and this algorithm becomes the construction of the ` magic points ' @xcite .",
    "then , we apply the eim in line [ local geim1 ] and [ local geim2 ] in algorithm [ adapt - epm ] to the localized function sets @xmath105 and @xmath106 , where the latter have been defined in line [ local_pod ] of algorithm [ adapt - epm ] .",
    "note that the statements for the geim in lemma [ prop - eim ] analogously hold true for the eim .",
    "we emphasize that if we do not refine @xmath40 in algorithm [ adapt - epm ] , the latter reduces to the application of the eim to a pod basis as considered also for instance in @xcite . in this paper",
    "it has also been demonstrated that this yields the same approximation as the deim .",
    "+ theorem [ apriori - epm ] remains valid for the adaptive epm based on the eim and can be proved analogously as in the previous subsection .",
    "we just note that thanks to the assumption @xmath236 we have that the eigenfunctions @xmath182 are bounded with respect to the @xmath242-norm on @xmath40 for all @xmath243 .",
    "therefore , we may extract a weakly-@xmath244 converging subsequence in @xmath245 and obtain that the limit eigenfunctions satisfy @xmath246 , @xmath152 .",
    "hence , the selection of the interpolation points with the eim is well - defined also in the limit @xmath184 , which in turn yields the uniform boundedness of @xmath185 .",
    "one may then proceed as in proposition [ apost - epm ] to derive an a posteriori error estimator for the adaptive epm based on the eim .",
    "we emphasize that by running algorithm [ adapt - epm ] with @xmath247 and additionally computing @xmath101 in for @xmath248 , we obtain in this way rigorous a priori and a posteriori bounds for the deim @xcite .",
    "+ regarding the proof of the convergence of the adaptive epm we note that the lebesgue constant @xmath249 @xmath250(\\mu,\\cdot)\\|_{l^{\\infty}(i)}/\\| g(\\mu,\\cdot ) \\|_{l^{\\infty}(i ) } ) $ ] can in general not be bounded by the @xmath12-based operator norm of the interpolation operator . here",
    ", the @xmath251 indicates that the respective quantities are defined for the adaptive epm based on the eim .",
    "however , if we restrict to a discrete setting an analogous result to proposition [ apriori - epm - convergence ] may be obtained . to this end",
    "we introduce a partition @xmath252 of @xmath97 with elements @xmath253 of width @xmath254 and maximal step size @xmath255 , and a conforming finite element space @xmath256 of dimension @xmath257 .",
    "then we may exploit the inverse estimate @xmath258 , @xmath259 to obtain @xmath260(\\mu,\\cdot)\\|_{l^{2}(\\omega)}}{\\| g(\\mu,\\cdot ) \\|_{l^{2}(\\omega ) } } \\leq \\left(\\sum_{i \\in \\mathfrak{i}}|i| ( \\tilde{\\lambda}_{k}^{i})^{2}\\right)^{1/2}h^{-1/2}.\\ ] ] replacing the estimate in by the one in yields the convergence of the adaptive epm for a fixed mesh size @xmath261 for @xmath262 under certain assumptions as stated in the following corollary .",
    "[ apriori - epm - disc ] we assume that the parameter values @xmath104 are sampled from the uniform distribution over @xmath144",
    ". then there holds @xmath263    for the lebesgue constant @xmath264 , @xmath190 it can been shown as in @xcite that @xmath265 .",
    "although this bound can be actually reached @xcite , @xmath266 is a very pessimistic result and in numerical experiments a very moderate behavior is observed ( cf .",
    "note that only yields convergence of the epm if the pod - error converges faster than @xmath267 .",
    "we emphasize the dependence on @xmath268 in . therefore using the eim within the adaptive epm seems reasonable for moderate mesh sizes , whereas for @xmath269 we should rely on the geim .",
    "+ note that theoretically also the a posteriori bound for the eim derived in @xcite can be employed to obtain an a posteriori estimate for the adaptive epm . as the theory developed in @xcite however requires that the considered functions are parametrically smooth , it is not applicable within our context .",
    "the goal of this section is the efficient construction of a low - dimensional reduction space and a collateral basis space , which yield a fast convergence of the rb - hmr approximation to the full solution .",
    "we recall that the reduction space is used to define the reduced space in which we search our reduced rb - hmr solution .",
    "in contrast the collateral basis space is constructed for the approximation of the range of nonlinear operator and therefore facilitates the evaluation of the nonlinear term at low cost . following the approach in @xcite",
    ", we derive in ",
    "[ 1dproblem - nonlin ] a parametrized nonlinear 1d pde whose solution is employed for the definition of parametrized 1d operator evaluations in the transverse direction in  [ gen - snap - nonlin ] .",
    "the sets of solution and operator snapshots are generated simultaneously by an adaptive training set extension algorithm in ",
    "[ adapt - rb - hmr - epm ] .",
    "the principal components of the snapshot sets then form the reduction space and the collateral basis space .",
    "we begin with formulating the rb - hmr approach with the adaptive epm in  [ formulate_hmrrb_epm ] .",
    "[ hmrrb - epm ]    we follow the hierarchical model reduction ( hmr ) framework introduced in @xcite and extended to the rb - hmr setting in @xcite .",
    "we recall our assumption that the considered domain is a tensor product , i.e. @xmath270 , where @xmath271 denotes the computational domain in the dominant direction , and @xmath272 the domain in the transverse direction . in more general situations a mapping to such a reference domain",
    "needs to be employed ( cf .",
    "@xcite ) . for @xmath3 and @xmath273",
    "we consider the nonlinear problem @xmath274 problem is denoted the full problem , and existence and uniqueness of a solution @xmath275 of is assumed . following the hmr framework",
    ", we introduce a set of @xmath12-orthonormal basis functions @xmath276 . at this point",
    "we assume that the basis functions @xmath277 are given to us .",
    "possible choices are trigonometric or boundary - adapted legendre polynomials @xcite or a posteriori determined basis functions , whose construction will be detailed in this section .",
    "we combine the reduction space @xmath278 with @xmath279 and define the reduced space @xmath280 where @xmath281 the reduced solution @xmath282 may then be obtained by galerkin projection , i.e. @xmath283 based on this reduced problem , fully discrete reduced approximations can be derived by replacing @xmath279 in the definition of @xmath284 by some suitable one - dimensional finite element subspace .",
    "+ we emphasize that in contrast to the case of linear pdes @xcite , the integrals in the transverse direction in can not be precomputed due to the nonlinear operator @xmath285 .",
    "this implies that is still of full dimension . to overcome this difficulty and",
    "hence perform a dimensional reduction of we apply the adaptive epm introduced in  [ epm ] . + we suppose that a set of collateral basis functions @xmath286 is given to us .",
    "the reduced problem based on the adaptive epm then reads @xmath287 , v_{m } \\rangle   & = \\langle f , v_{m } \\rangle \\quad \\forall v_{m } \\in v_{m } , \\qquad \\text{where } \\\\",
    "p_{k}^{l}[a(p_{m , k})](x , y ) & = \\sum_{n = 1}^{k } \\int_{{\\omega } } \\mathcal{i}_{l}[a(p_{m , k})](x , z)\\ , \\kappa_{n}({z})\\ ,   d{z}\\,\\ , \\kappa_{n}(y)\\\\ \\nonumber & = \\sum_{n = 1}^{k } \\sum_{i \\in \\mathfrak{i } } \\sum_{j=1}^{k_{i}}\\int_{{\\omega } } \\sigma^{i}_{j}(a(p_{m , k}(x,\\cdot)))\\,\\vartheta_{j}^{i}({z})\\ , \\kappa_{n}({z})\\ ,   d{z}\\,\\ , \\kappa_{n}(y).\\end{aligned}\\ ] ] note that for some nonlinear operators it might be necessary to apply the adaptive epm component - wise , exploiting that for any @xmath288 there exist functions @xmath289 such that @xmath290 note also , that for the major part of problems which fall in the category of , we expect that for @xmath291 , @xmath288 we actually have @xmath292 thanks to the lemma of j.  l. lions , which states that for distributions @xmath207 on @xmath8 which are in @xmath5 and whose all partial derivatives are in @xmath5 there holds @xmath293 ( see @xcite and references therein ) . to simplify notations we do not introduce a separate notion for the cases where the adaptive epm has to be applied component - wise but instead assume that such cases are covered by the formulation in . +",
    "rewriting @xmath294 as @xmath295 we obtain : find @xmath296 , such that @xmath297 to compute an approximation of @xmath294 we introduce a partition @xmath298 of @xmath299 with elements @xmath300 of width @xmath301 and maximal step size @xmath302 .",
    "moreover , we introduce a conforming finite element space @xmath303 of dimension @xmath304 and basis @xmath305 , @xmath306",
    ". then the corresponding discrete reduced problem reads : find @xmath307 , @xmath308 , such that @xmath309 for @xmath310 , @xmath311 , which is equivalent to the short notation @xmath312 , \\xi^h_{i } \\phi_{j } \\rangle   = 0 \\quad \\text{for } \\enspace i = 1, ... ,n_{h } \\enspace \\mbox{and } \\enspace j = 1, ... ,m , \\end{aligned}\\ ] ] where @xmath313 , \\xi^h_{i } \\phi_{j } \\rangle   = \\langle p_{k}^{l}[a(p_{m , k}^{h } ) ] , \\xi^h_{i } \\phi_{j } \\rangle - \\langle f , \\xi^h_{i } \\phi_{j } \\rangle$ ] , @xmath310 , @xmath314 .",
    "we emphasize that thanks to the application of the adaptive epm we can now precompute the integrals in the transverse direction in and and as a result the computation of @xmath315 and @xmath316 reduces to the solution of a coupled system of nonlinear one - dimensional pdes of size @xmath11 or @xmath317 .",
    "+ problem can be efficiently solved by newton s method .",
    "it is possible to reuse the collateral basis for a nonlinear operator also for the approximation of its frchet derivative @xcite . to obtain a better approximation of @xmath318 and thus ideally a faster convergence of the newton scheme solving for @xmath319",
    ", we propose to use a second collateral basis space @xmath320 for this approximation . assuming that @xmath321 is given",
    ", the newton scheme is defined as follows : @xmath322\\ ,   \\delta ( p_{m , k}^{h})^{j } , v_{m}^{h } \\rangle & = & - \\langle p_{k}^{l}[f((p_{m , k}^{h})^{j } ) ] , v_{m}^{h } \\rangle \\quad   \\forall v_{m}^{h } \\in v_{m}^{h } , \\quad j = 0,1,2 , ...",
    "\\\\[-1.5ex ] \\label{newton_epm}&&\\\\[-1.5ex ]   \\nonumber   \\qquad ( p_{m , k}^{h})^{j+1 } & = & ( p_{m , k}^{h})^{j } + \\delta ( p_{m , k}^{h})^{j},\\end{aligned}\\ ] ] where @xmath323 is a suitable initial datum and @xmath324 $ ] is computed analogous to @xmath325 $ ] with the adaptive epm . for well - posedness of the newton scheme for nonlinear pdes in general",
    "we refer to @xcite and for this particular framework to @xcite .",
    "+ for future reference we finally introduce a two - dimensional finite element solution which will serve as a reference for our approximation . to this end",
    "we introduce the subdivision @xmath326 of @xmath327 with elements @xmath328 , @xmath329 and @xmath330 , and the reference fe - space @xmath331 here , @xmath332 is defined as @xmath333 and @xmath334 denotes the space of polynomials of order @xmath335 in one variable .",
    "we will see in section [ 1dproblem - nonlin ] and [ adapt - rb - hmr - epm ] that we have for the rb - hmr approach @xmath336 and as a consequence @xmath337 .",
    "the reference fe approximation of problem reads : @xmath338 where @xmath339 for all @xmath340 .      to derive a lower dimensional parametrized pde in the transverse direction we proceed as in @xcite and",
    "assume that @xmath341 where the function @xmath342 represents the unknown behavior of the full solution in the dominant direction .",
    "using the test functions @xmath343 for all @xmath344 yields the reduced problem with quadrature @xmath345 here , we denote by @xmath346 the approximation obtained by substituting the integral @xmath347 in @xmath4 by the quadrature formula @xmath348 where @xmath349 , @xmath350 , @xmath351 denote quadrature weights and points respectively .",
    "note that we require @xmath352 to facilitate point evaluations of @xmath353 and thus obtain the well - definedness of .",
    "note also that this assumption is reasonable in the sense that in many cases we have indeed that the solution @xmath19 belongs to a sobolev space of higher order ( see for instance @xcite ) . to include the unknown dynamics in dominant direction @xmath353 in the lower - dimensional problem in transverse direction and to find optimal locations of the quadrature points with rb methods ( see  [ adapt - rb - hmr - epm ] below ) ,",
    "we parametrize by introducing a parameter vector @xmath354 .",
    "the @xmath355-dimensional parameter space @xmath144 containing all admissible parameter values of @xmath16 , is defined as @xmath356^{q}$ ] , where the intervals @xmath357 contain the ranges of @xmath358 , @xmath359 .",
    "compared to the linear setting , we expect a greater sensitivity of the rb - hmr approach with respect to the choice of the intervals @xmath357 , @xmath360 , as the nonlinearity of @xmath285 also applies to the parameter via the term @xmath361 .",
    "this can indeed be observed in the numerical experiments provided in  [ numerics_nonlin ] . to get a rough estimate on the possible ranges of @xmath358 , @xmath359 , and",
    "therefore obtain an optimal convergence rate of the rb - hmr approach , we may for instance compute a coarse approximation of the solution @xmath19 of .",
    "using the definition of @xmath16 , problem ( [ 1d_prob_quad_nonlin ] ) can be recast into a parametrized 1d nonlinear pde in transverse direction as follows : @xmath362 possible choices for the quadrature formula are a modified rectangle formula or a standard composite trapezoidal rule .",
    "the number of quadrature points is chosen automatically by an adaptive algorithm , described in  [ adapt - rb - hmr - epm ] . to compute snapshots we use the subdivision @xmath252 of @xmath97 and",
    "the associated conforming fe space @xmath363 with basis @xmath364 as introduced in section [ sect : epm_eim ] .",
    "we obtain the parameter dependent discrete 1d problem : @xmath365 which can be solved by newton s method .",
    "well - posedness of and the conditions for the convergence of newton s method may be verified a posteriori ( cf .",
    "we may then define the solution manifold @xmath366 as @xmath367 finally , we remark that instead of the heuristic assumption in one might alternatively consider a linear combination of tensor products . note that we would then have to consider a system of nonlinear equations in and that the number of parameters would of course increase .",
    "how this change affects the approximation properties of the rb - hmr approach is subject of future research .      in this subsection",
    "we define a manifold of operator evaluations which is formed by parametrized 1d operator evaluations of the nonlinear operator @xmath285 in the transverse direction . for this purpose",
    "we consider and and define parametrized 1d operator evaluations @xmath368 and @xmath369 of the operators @xmath370 and @xmath371 as @xmath372 here , @xmath373 denotes the length of the interval @xmath299 , @xmath374 , @xmath375 is the solution of and @xmath376 solves .",
    "provided that @xmath375 is able to capture the behavior of the full solution @xmath19 in the transverse direction , we expect that @xmath368 is a good approximation of the range of @xmath370 in that direction , which will be validated in  [ numerics_nonlin ]",
    ". moreover , we define parametrized 1d operator evaluations of the respective fr@xmath377chet derivatives @xmath378 and @xmath379 as @xmath380 finally , we define a manifold of operator evaluations @xmath381 through @xmath382      in this subsection we introduce the adaptive - rb - hmr algorithm which simultaneously constructs the reduction space @xmath383 and the collateral basis space @xmath384 using sampling strategies from the rb framework .",
    "first , the snapshot sets @xmath385 are efficiently constructed in algorithm [ adapt - train ] by an adaptive training set extension which generalizes the algorithm proposed in @xcite .",
    "subsequently , we apply a pod to determine the principal components of @xmath386 and @xmath387 which in turn span the reduction space @xmath388 and the collateral basis space @xmath389 , respectively .",
    "+    [ [ algorithm - adapt - train - adaptivetrainextension ] ] algorithm [ adapt - train ] ( adaptivetrainextension ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath390 denote a hyper - rectangular possibly non - conforming grid in the parameter space @xmath144 , @xmath391 a cell of @xmath390 and @xmath392 the number of cells in @xmath390 .",
    "the parameter values in the training set @xmath393 are sampled from the uniform distribution over the cell @xmath391 , where @xmath393 has the same size @xmath394 for all cells @xmath391 and @xmath395 . as in @xcite and",
    "originally in @xcite we use a local mesh adaptation with a @xmath396 strategy for the generation of @xmath390 and @xmath397 beginning with a given coarse partition @xmath398 and an associated initial training set @xmath399 . in ",
    "[ sect - apostest ] we derive an a posteriori error estimate @xmath400 for the error between the solution @xmath401 of and the reference solution @xmath402 defined in which takes into account both the model error and the error due to the approximation of the nonlinear operator . for the latter we use the a posteriori bound for the epm derived in proposition [ apost - epm ] .",
    "a richer collateral basis space @xmath403 with associated interpolating functionals @xmath404 has thus to be provided before starting the @xmath396-loop .",
    "therefore , we initially compute the snapshots @xmath405 and @xmath406 for a coarse train sample @xmath407 of @xmath398 with @xmath408 in line [ coarse_snapshots ] in algorithm [ adapt - train ] . to compute @xmath403 and the functionals @xmath404 with algorithm [ k_strich ] epm - indicator , we first use a pod to find the principal components @xmath409 such that the pod - error @xmath410 , where @xmath411 .",
    "note that @xmath412 has to be chosen rather small to obtain an a posteriori error estimate for the epm which is as accurate as possible .",
    "next , we apply algorithm [ adapt - epm ] adaptive epm for the computation of the interpolating functionals @xmath413 , the basis @xmath414 and the matrix @xmath415 , where the computation of the interpolant in necessitates the solution of and thus the computation of @xmath416 in line [ basis_line ] . as the error bound is only employed during the adaptive training set extension , it is sufficient to restrict to @xmath417",
    ". then we use the a priori bound for the epm from theorem [ apriori - epm ] to compute @xmath217 , which yields @xmath403 and apply again algorithm [ adapt - epm ] to determine @xmath404 . here",
    ", @xmath418 denotes the tolerance for the pod employed to compute the collateral basis of size @xmath419 within algorithm [ adapt - train ] .",
    "the factor @xmath420 results in a smaller tolerance @xmath421 for the pod which is used to compute the collateral basis of size @xmath217 solely for error estimator purposes and ensures @xmath422 .",
    "@xmath403 and @xmath404 are updated at the end of each loop over @xmath11 in line [ update_kstrich ] to include the information from the snapshots generated during lines [ snap1 ] and [ snap2 ] .",
    "+    epm - indicator@xmath423 , @xmath424 + @xmath425[basis_line ] + @xmath426:= \\mbox{pod}(\\mathcal{a}_{g}^{h } , \\varepsilon_{\\mbox{{\\scriptsize tol}}}^{err})$ ] + @xmath427 : = $ ] adaptive epm@xmath428,@xmath429 , @xmath430 , @xmath397 , @xmath431 + @xmath432epm - aposteriori - bound@xmath433 + @xmath434 +",
    "@xmath435adaptive epm@xmath436 , @xmath42 , @xmath437 , @xmath429 , @xmath430 , @xmath397 , @xmath438 + @xmath439    adaptivetrainextension@xmath440 + @xmath441 + * initialize * @xmath442 + compute @xmath443 , @xmath444 [ coarse_snapshots ] + @xmath445=$]epm - indicator@xmath446 , @xmath447 + @xmath448qp - indicator@xmath449[qp1 ] + possibly adapt @xmath390 and @xmath397 if @xmath450 has changed .",
    "+ @xmath451    a main difference to the algorithm in @xcite is the usage of the qp - indicator , which chooses the number of quadrature points @xmath450 used in . to decide whether @xmath450 has to be increased or",
    "not we apply a pod to @xmath405 in line [ qp1 ] ( @xmath452 in line [ qp2 ] ) and compare the convergence rates of the eigenvalues of the pod with @xmath453 , @xmath454 , where the coefficients @xmath455 solve . if we observe that the decay rate of the coefficients is worse than the rate of the eigenvalues by at least @xmath456 on @xmath457 consecutive values , and @xmath450 is smaller than @xmath458 , we increment @xmath450 by one . note that we want to increment @xmath450 only if we observe a significant deviation of the coefficients from the eigenvalues , which is why we proceed rather conservatively .",
    "note also that the qp - indicator thus enforces the adaptation of the reduction space @xmath388 and the collateral basis space @xmath389 to the reference solution @xmath459 and the nonlinear operator @xmath460 by increasing the amount of information on the dynamics in the dominant direction in the spaces @xmath388 and @xmath389 , if necessary .",
    "the initial value @xmath461 is usually set to @xmath462 . note that the fact that @xmath390 is a product - like hyper - rectangular grid prevents the applicability of algorithm [ adapt - train ] to high parameter dimensions .",
    "however , if @xmath463 we may instead consider an anisotropic adaptive refinement strategy or use a clustering algorithm ( cf .",
    "+ apart from the just stated differences and the additional computation of the snapshots @xmath464 in line [ snap1 ] and [ snap2 ] , and the pod for the computation of the small collateral basis @xmath465 in line [ pod - op ] , algorithm [ adapt - train ] follows the lines of the corresponding algorithm in @xcite .",
    "thus , we use the cell indicators @xmath466 and @xmath467 , where @xmath468 counts the number of loops in which the cell @xmath391 has not been refined , since its last refinement .",
    "we mark for fixed @xmath469 $ ] in each iteration the @xmath470 cells @xmath391 with the smallest indicators @xmath471 and additionally the cells for which @xmath472 lies above a certain threshold @xmath473 .",
    "then , all cells marked for refinement are bisected in each direction .",
    "finally , we note that for each parameter value in @xmath397 we compute the snapshots @xmath474 and @xmath369 , add these snapshots to the already computed small bases @xmath475 and @xmath476 , compute the ( coarse ) solution @xmath477 of , and use the a posteriori error estimator to assess whether the span of the small bases and the current snapshots yields a good approximation . note",
    "that both for the computation of @xmath477 and the error estimator within the adaptive refinement procedure we employ a coarser discretization in the dominant direction with a mesh size @xmath478 and an associated coarser finite element space @xmath479 of dimension @xmath480 .",
    "+    [ [ algorithm - adapt - rb - hmr - adaptive - rb - hmr ] ] algorithm [ adapt - rb - hmr ] ( adaptive - rb - hmr ) + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    at first , the training sets @xmath399 and @xmath407 are formed by sampling @xmath394 or @xmath481 parameter values from the uniform distribution over each @xmath482 , where @xmath483 . subsequently algorithm [ adapt - train ] is called to generate the discrete manifolds @xmath386 and @xmath387 .",
    "finally , we apply a pod to determine the principal components @xmath484 and @xmath485 of @xmath386 and @xmath387 , which then span the reduction space @xmath388 and the collateral basis space @xmath389 .",
    "+ finally , we point out that the spaces @xmath388 and @xmath389 approximate the discrete manifolds @xmath386 and @xmath387 .",
    "however , thanks to the design of the parametrized 1d problem and the parametrized operator evaluations we expect that our choices of @xmath388 and @xmath389 also allow for a good approximation of the reference solution @xmath459 and the range of the operator @xmath460 .",
    "this is demonstrated in  [ numerics_nonlin ] . for details on the choice of the input parameters @xmath486 , @xmath473 and @xmath487 we refer to @xcite .    adaptive - rb - hmr@xmath488 + @xmath489 + * initialize * @xmath399 , @xmath490 + @xmath491=$ ] adaptivetrainextension@xmath492 + @xmath493 + @xmath494 , such that @xmath495",
    ". + @xmath496 , such that @xmath497 .",
    "+ @xmath498adaptive epm@xmath499 + @xmath388 , @xmath389 , @xmath500      [ subsect - brr][subsect_constants ] we apply the brezzi - rappaz - raviart ( brr ) theory @xcite to derive a rigorous a posteriori error bound for the error between the reduced solution @xmath319 of and a reference solution @xmath459 , which takes into account both the contributions of the model reduction and the approximation of the nonlinear operator . to this end",
    "we first define the inf - sup stability factor and the continuity and the lipschitz constant : @xmath501 where @xmath502 and the index @xmath19 comes from the space @xmath503 .",
    "note that we compute the lipschitz constant only on @xmath504 both in order to obtain a sharper estimate and to include nonlinear operators whose frchet derivative is not lipschitz continuous on the whole space @xmath505 .",
    "we comment in section [ subsubsect : estimate constants ] on how we may obtain estimates for the constants defined in - .",
    "now we may define a proximity indicator @xcite @xmath506 \\|_{w^{-1,p}(\\omega ) } + \\| p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{w^{-1,p}(\\omega ) } ) $ ] and obtain the following result .",
    "[ error_bound ] if @xmath507 then there exists a unique solution @xmath508 of and the following a posteriori error estimate holds @xmath509 of the error bound .",
    "[ eff ] let us assume that @xmath510 \\|_{w^{-1,p}(\\omega ) } \\leq c_{\\text{{\\tiny err } } } \\| p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{w^{-1,p}(\\omega)}\\ ] ] for @xmath511 and set @xmath512 if @xmath513 we have @xmath514    we simplify notations by setting @xmath515 .",
    "it is easy to see ( cf .",
    "@xcite ) that implies @xmath516 & \\|_{w^{-1,p}(\\omega ) } + \\| f(p_{m , k}^{h } ) - p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{w^{-1,p}(\\omega ) } \\\\[-1.5ex ] \\label{mo_ei_verh}\\\\[-1.5ex ] \\nonumber \\qquad \\qquad & \\leq c_{\\text{{\\tiny err}}}^{-1 } \\bigl ( \\| p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{w^{-1,p}(\\omega ) } - \\| f(p_{m , k}^{h } ) - p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{w^{-1,p}(\\omega ) } \\bigr ) .",
    "\\end{aligned}\\ ] ] the following estimate differs from @xcite , as in @xcite a quadratic nonlinear pde in a hilbert space is considered and the proof of the effectivity of the error bound heavily relies on these two assumptions . as @xmath517",
    "we may apply proposition [ error_bound ] to obtain @xmath518 , & v^{h\\times h } \\bigr { \\rangle}+ \\left{\\langle}p_{k}^{l}[f(p_{m , k}^{h } ) ] , v^{h\\times h } \\right { \\rangle}= - { \\langle}f^{\\prime}(p_{m , k}^{h } ) ( p^{h\\times h } - p_{m , k}^{h } ) , v^{h\\times h }   { \\rangle}\\\\ & + \\left { \\langle}\\int_{0}^{1 } \\left \\ { f^{\\prime}(p_{m , k}^{h } ) - f^{\\prime}(p_{m , k}^{h } + t(p^{h\\times h } - p_{m , k}^{h } ) ) \\right \\ }   ( p^{h\\times h } - p_{m , k}^{h } ) \\ , dt , v^{h\\times h } \\right { \\rangle}.\\end{aligned}\\ ] ] exploiting , , and then yields @xmath519 \\|_{w^{-1,p}(\\omega ) } + \\|   f(p_{m , k}^{h } ) - p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{w^{-1,p}(\\omega ) } \\\\[-1.5ex ] \\label{est2 } \\\\[-1.5ex ] \\nonumber & \\qquad \\qquad \\qquad\\leq c_{\\text{{\\tiny err}}}^{-1 } \\bigl(\\gamma_{p } \\ , |p^{h\\times h } - p_{m , k}^{h}|_{w^{1,p}(\\omega ) } + \\frac{l_{p}}{2 } |p^{h\\times h } - p_{m , k}^{h}|_{w^{1,p}(\\omega)}^{2}\\bigr ) .",
    "\\end{aligned}\\ ] ] thanks to @xmath520 we have @xmath521 and may thus estimate @xcite @xmath522 \\|_{w^{-1,p}(\\omega ) } + \\|   f(p_{m , k}^{h } ) - p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{w^{-1,p}(\\omega ) } \\right).\\end{aligned}\\ ] ] following the ideas in @xcite we invoke , and proposition [ error_bound ] to get @xmath523 finally , we employ again and @xmath513 to obtain @xmath524    note that the terms @xmath525 \\|_{w^{-1,p}(\\omega)}$ ] and @xmath526 \\|_{w^{-1,p}(\\omega ) } $ ] are computable as @xmath505 is a finite dimensional space .",
    "alternatively , the dual norms may be further estimated by a localized residual type estimator ( cf .",
    "@xcite ) . to obtain the required interpolation estimate for the terms @xmath527 we propose to replace @xmath528 in the latter term by @xmath529 with @xmath530 .",
    "+ note that the formulation in also includes nonlinear operators which have to be considered as a mapping from @xmath503 onto @xmath531 for @xmath532 for instance because they are not @xmath533-mappings with respect to the space @xmath534 .",
    "therefore we also derive an error bound for @xmath535 for problems with @xmath536 . as in @xcite",
    "we assume that for all @xmath537 , @xmath538 can be continuously extended as an operator in @xmath539 .",
    "in general this can be achieved by applying the hahn - banach theorem .",
    "furthermore , we require that @xmath540 and that there exist constants @xmath541 and @xmath542 such that @xmath543 here , the subscript @xmath544 indicates that the argument of @xmath545 has to be in @xmath546 , @xmath536 . by transferring ideas of @xcite",
    "we obtain under the assumptions of proposition [ error_bound ] @xmath547 \\|_{h^{-1}(\\omega ) } + \\| p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{h^{-1}(\\omega ) } \\bigr).\\end{aligned}\\ ] ] note that this bound requires the computation or estimation of the dual norms and the appearing constants both for the @xmath548- and the @xmath549-norm .",
    "thus , we employ the inverse estimate @xmath550 with @xmath551 and a constant @xmath187 which is independent of @xmath552 , @xmath261 , @xmath19 , and @xmath553 @xcite .",
    "note that the equivalence of norms on the finite dimensional space of polynomials on an element @xmath554 of the partition @xmath555 of @xmath8 can be used to obtain an estimate for @xmath187 .",
    "note also that thanks to exponent in @xmath556 we expect that @xmath556 depends only very weakly on @xmath261 and @xmath552 .",
    "based on that we introduce the proximity indicator @xmath557 \\|_{h^{-1}(\\omega ) } + \\| p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{h^{-1}(\\omega ) } ) \\ ] ] to derive the following computationally more feasible @xmath558-error bound .",
    "[ h1_bound ] let @xmath559 and , and be fulfilled .",
    "then there exists a unique solution @xmath560 of . if we further assume that @xmath561 \\|_{h^{-1}(\\omega ) } \\leq c_{\\text{{\\tiny err } } } \\| p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{h^{-1}(\\omega)}\\ ] ] for @xmath511 and @xmath562 , where @xmath563 the error estimator @xmath564 satisfies @xmath565 and [ eff ] .    to further estimate @xmath400 we invoke the a posteriori error bound for the epm in proposition [ apost - epm ] to replace @xmath566 by @xmath567 $ ] .",
    "then we define the riesz representations @xmath568 and @xmath569 as the solutions of @xmath570 , v^{h \\times h})_{h^{1}(\\omega ) } \\quad & \\forall v^{h \\times h } \\in v^{h \\times h},\\\\ \\text{and } \\qquad \\qquad ( \\mathcal{e}_{k}^{h \\times h } , v^{h \\times h})_{h^{1}(\\omega ) } & = ( p_{k'}^{l'}[f(p_{m , k}^{h } ) ] - p_{k}^{l}[f(p_{m , k}^{h } ) ] , v^{h \\times h})_{h^{1}(\\omega ) } \\quad & \\forall v^{h \\times h } \\in v^{h \\times h}.\\end{aligned}\\ ] ] here , @xmath571 denotes the inner product associated with the @xmath549-semi norm .",
    "we thus obtain @xmath572 \\|_{h^{-1}(\\omega ) }   \\quad \\text{and } \\quad   |\\ , \\mathcal{e}_{k}^{h \\times h } \\ , |_{h^{1}(\\omega ) } =    \\| p_{k'}^{l'}[f(p_{m , k}^{h } ) ] - p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|_{h^{-1}(\\omega)}.\\end{aligned}\\ ] ] note that due to the definition of the snapshot set @xmath387 , the a priori bound for the epm is only applicable , if @xmath387 is a good approximation of @xmath573 .",
    "this may be verified by comparing the convergence rates of the eigenvalues @xmath574 of the pod applied to @xmath387 and the coefficients @xmath575 \\kappa_{l } \\|_{l^{2}(\\omega_{1d})}^{2}$ ] , @xmath576 .",
    "if the convergence rates do not coincide one may either increase the number of quadrature points in as discussed in section [ adapt - rb - hmr - epm ] or replace @xmath574 by @xmath575 \\kappa_{l}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] , @xmath576 , in the a priori bound for the epm .",
    "the latter requires only the computation of @xmath577 additional integrals in @xmath578-direction .",
    "as the behavior of the coefficients @xmath579 \\kappa_{l}$ ] strongly influences the convergence behavior of @xmath580 $ ] for increasing @xmath203 we expect that remains a reliable a priori bound when substituting @xmath574 by @xmath575 \\kappa_{l}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] , @xmath576 .",
    "this is demonstrated by the numerical experiments in  [ numerics_nonlin ] .",
    "+      [ subsect_constants ] we close this section by addressing the computation or estimation of the constants @xmath581 , @xmath582 , and @xmath583 for @xmath584 .",
    "as the constants - are in general not computable for @xmath536 or only at unfeasible costs , we rely on estimating these constants in this case .",
    "for instance in the case of the nonlinear diffusion equation considered in the numerical examples an estimate of @xmath541 and @xmath542 relies on estimates for friedrich s inequality @xmath585 and the constant in the sobolev inequality @xmath586 . to obtain an upper bound for the constant @xmath587 we suggest to proceed as in @xcite .",
    "a bound for the constant @xmath588 in the inequality @xmath589 can be found for instance in @xcite , theorem 2.d . to obtain an estimate for @xmath590 we to multiply @xmath591 with a cut - off function @xmath592 defined as @xmath593 for @xmath594 , @xmath595 outside @xmath8 and with @xmath596 and @xmath597 , @xmath225 for a given constant @xmath598 .",
    "then we expect that @xmath599 as @xmath591 .",
    "moreover , we have that @xmath600 and therefore propose to employ the constant @xmath601 as an estimate for @xmath590 , where @xmath598 should be adapted to the considered domain . + to derive a lower bound for @xmath581 we suggest to proceed as in @xcite where a finite element approximation of the nonlinear diffusion equation is considered and a lower bound of the occurring inf - sup constant is derived .",
    "however , such an estimate is beyond the scope of this paper and therefore subject of future work . for other nonlinear operators we expect the estimates also to rely on the above inequalities .",
    "+ as we have continuously extended @xmath602 to an operator in @xmath603 for @xmath537 an upper bound for @xmath542 follows directly from the estimate for @xmath583 .",
    "if we consider @xmath604 the lipschitz constant @xmath605 depends in general on a sobolev embedding constant ( see for instance @xcite ) .",
    "a simple procedure to obtain an upper bound for this sobolev embedding constant is described in @xcite .",
    "+ finally , we propose a method for approximating @xmath606 and @xmath607 .",
    "we present the approach for @xmath606 but it is identically applicable to @xmath607 . inspired by the idea in @xcite to employ a matrix - deim approximation of the jacobian for the computation of the lipschitz constant of the considered nonlinear operator , we propose to use the adaptive epm to approximate @xmath606 .",
    "precisely , we use the a posteriori error bound for the epm derived in proposition [ apost - epm ] , to find @xmath217 such that @xmath608 $ ] approximates @xmath609 up to a given tolerance and define @xmath610 w^{h\\times h } , v^{h\\times h } \\rangle}{| w^{h\\times h}|_{h^{1}(\\omega ) } | v^{h\\times h}|_{h^{1}(\\omega)}}.\\end{aligned}\\ ] ] @xmath611 equals the smallest singular value of the jacobian associated with @xmath612 w^{h\\times h } , v^{h\\times h } \\rangle$ ] .",
    "thus , we determine the latter to compute @xmath611 .",
    "theorem [ apriori - epm ] yields the convergence of @xmath608 $ ] to @xmath609 as @xmath613 , which implies @xmath614 as @xmath613 . although we therefore expect @xmath611 to be a very good approximation of @xmath606 , which is demonstrated by the numerical experiments in ",
    "[ numerics_nonlin ] , we note that it is not clear that @xmath611 is indeed a lower bound of @xmath606 .",
    "in this section we demonstrate the applicability of the rb - hmr approach using the adaptive epm to nonlinear pdes by verifying both its good approximation properties and computational efficiency .",
    "moreover , we analyze the effectivity of the a posteriori error estimator derived in  [ sect - apostest ] and validate the a priori and a posteriori bounds for the epm stated in theorem [ apriori - epm ] and proposition [ apost - epm ] . for this purpose",
    "we consider the following model problem , which is inspired by the model for immiscible two - phase flow in porous media studied in @xcite . @xmath615 as @xmath616 ensures uniform ellipticity and @xmath617 , @xmath618 and @xmath619 are bounded in the relevant regions , we have that problem is well - posed @xcite .",
    "existence of a ( discrete ) reduced rb - hmr solution follows from brouwer s fixed point theorem .",
    "we note that the structure of necessitates to consider @xmath620 for @xmath536 which in turn requires that the hmr basis functions fulfill @xmath621 , @xmath622 .",
    "this improved regularity for solutions of can be proved with standard arguments ( see for instance @xcite ) . for further details on well - posedness issues of problem in the context of rb - hmr and the corresponding parameter dependent lower dimensional",
    "problem we refer to @xcite .",
    "+ in the first test case we prescribe the analytical solution of test case 1 in @xcite to compare the convergence rates of the rb - hmr approach for linear and nonlinear problems .",
    "also in the nonlinear case the rb - hmr approach converges exponentially fast in the model order @xmath11 , regardless whether the epm is applied or not .",
    "however , the convergence rate is worse than for the linear problem . in the other test case",
    "we prescribe a discontinuous source term @xmath623 resulting in a solution with little spatial regularity both in the dominant and transverse direction .",
    "still , we observe an exponential convergence rate of the rb - hmr approach using the epm in the model order @xmath11 .",
    "both test cases have been computed employing linear fe in @xmath624- and @xmath578-direction , i.e. @xmath625 and @xmath626 using equidistant grids in @xmath624- and @xmath578-direction .",
    "we have used the following quadrature weights in @xmath627 where the quadrature points @xmath628 , @xmath351 are expected to be sorted in ascending order .",
    "we have only applied a simplified version of algorithm [ adapt - rb - hmr ] adaptive - rb - hmr in the numerical experiments , as we have chosen the number of quadrature points employed in the parameter dependent 1d problem a priori . however , a comparison of the performance of the rb - hmr approach using @xmath462 or @xmath553 quadrature points in is provided for the second test case .",
    "furthermore , we have applied the adaptive epm [ adapt - epm ] based on the eim with @xmath629 and we thus obtain @xmath630 in . to simplify notations",
    "we omit the @xmath631 as introduced in section [ sect : epm_eim ] .",
    "we have employed the estimate @xmath632 to obtain an estimate for the lipschitz constant @xmath542 , where @xmath633 , @xmath634 , for @xmath635 , @xmath537 , and @xmath587 and @xmath590 have been introduced above .",
    "since @xmath636 is only locally bounded for some choices of @xmath637 , we computed local approximations of @xmath638 and @xmath639 by evaluating @xmath640 and @xmath641 in the discrete reduced solution @xmath319 of .",
    "moreover , we have estimated the constants @xmath187 in @xmath556 , @xmath642 , and @xmath590 by @xmath462 , which seems to be a reasonable estimate as for instance the procedure proposed in @xcite yields a bound of @xmath643 for @xmath642 and the value of the sharp bound @xmath588 stated in @xcite is about @xmath644 .    setting @xmath645 , where @xmath459 solves and @xmath319 , we define the relative model error in the @xmath549-semi norm or @xmath12-norm as @xmath646 the relative total error @xmath647 is either defined as @xmath648 if the full solution @xmath19 of is available as in test case 1 or as @xmath649 , where @xmath650 denotes a very finely resolved bilinear fe solution .",
    "we denote the pod - error associated with the hmr by @xmath651 and the pod - error corresponding to the epm by @xmath652 .",
    "moreover , we set @xmath653 and @xmath654 \\kappa_{k } \\|^{2}_{l^{2}(\\omega_{1d})})^{1/2}$ ] , where @xmath655 , @xmath656 , and @xmath657 $ ] has been defined in . furthermore , @xmath658 and @xmath659 denote the relative error estimator @xmath660 and the relative proximity indicator @xmath661 , where @xmath400 and @xmath662 have been defined in and , respectively . for the validation of the effectivity of the error bounds",
    ", we finally shorten the notation by setting @xmath663 \\|$ ] , @xmath664 - p_{k}^{l}[f(p_{m , k}^{h } ) ] \\|$ ] and @xmath665 \\|$ ] either for the @xmath666- or the @xmath12-norm .",
    "the implementation of algorithm [ adapt - rb - hmr ] adaptive - rb - hmr has been realized in matlab .",
    "all computations have been performed on a computer with an intel core i7 ( 4 cores ) with 2.8 ghz .",
    "+      first , we investigate the convergence behavior of the rb - hmr approach for an analytical solution @xmath667 which has already been considered in test case 1 in @xcite and originally in @xcite solving the poisson problem .",
    "we choose @xmath668 and @xmath669 and @xmath670 in .",
    "we compare the convergence behavior of the relative model error @xmath671 for the linear case where @xmath672 solves a poisson problem with the nonlinear case , where @xmath672 is the solution of the discrete reduced problem ( discretization of ) .",
    "we observe an exponential convergence rate of @xmath673 also for the nonlinear problem , which is worse than the one for the poisson problem ( fig .",
    "[ fig4.2a ] ) .",
    "nevertheless , also for the nonlinear case still @xmath674 basis functions are sufficient to achieve @xmath675 ( fig .",
    "[ fig4.2a ] ) . taking also into account the discretization error and hence considering the relative total error @xmath676 we observe that at least for the considered mesh sizes the effects of the detoriation of the convergence rate of the rb - hmr due to the nonlinearity on the behavior of the total error are rather small ( fig .  [ fig4.2b ] ) .",
    "that is because the discretization error is dominating over the model error in this example already for an rb - hmr approximation using only a small number of basis functions ( fig .",
    "[ fig4.2b ] ) . applying",
    "the epm preserves the convergence rate of the model error @xmath673 ( fig .",
    "[ fig4.2c ] ) until a so - called epm - plateau ( see @xcite for the eim - plateau ) is reached .",
    "the model error enters an epm - plateau if the approximation properties of the collateral basis space @xmath389 prevent a further reduction of the model error , i.e. @xmath203 is chosen too small compared to @xmath11 , and the nonlinear operator is hence not approximated accurate enough .",
    "our experiments showed that the tolerance of the pod for the epm @xmath677 should be set to @xmath678 with @xmath679 $ ] , to ensure that @xmath203 is chosen large enough .",
    "however , even if @xmath389 is spanned by all linear independent functions @xmath680 , a small error and thus a epm plateau can not be avoided due to the necessary projection of the snapshots onto a discrete space and other numerical constraints .",
    "note that the level of the epm - plateau becomes smaller for decreasing @xmath552 and lies for all considered mesh sizes well below the total error @xmath647 ( fig .",
    "[ fig4.2b],[fig4.2c ] ) .",
    "finally , we remark that in all computations for the plots in fig .",
    "[ fig4.2 ] we used the exact error in the application of the algorithm [ adapt - rb - hmr ] adaptive - rb - hmr ( fig .  [ fig4.2c ] ) to assess only the influence of the nonlinearity in fig .",
    "[ fig4.2a ] and fig .",
    "[ fig4.2b ] or the application of the epm in fig .",
    "[ fig4.2c ] .",
    "+ comparing the convergence behavior of @xmath681 for different pod - tolerances for the epm in fig .",
    "[ fig4.3a ] , we observe that for @xmath682 the error can even increase when entering the epm - plateau . for @xmath683",
    "the error stagnates in the epm - plateau and the level of the plateau decreases uniformly for dropping mesh sizes ( fig .",
    "[ fig4.3a ] ) .",
    "[ fig4.3e ] illustrates the error convergence of @xmath681 for a simultaneous increase of the model order @xmath11 and collateral basis size @xmath203 for @xmath684 .",
    "again we see that for small @xmath203 the scheme might even get unstable if @xmath11 exceeds a certain limit , which is however not the case for higher values of @xmath203 .",
    "moreover , we observe that if the approximation of the nonlinear operator is good enough , a further increase of @xmath203 does not reduce @xmath681 if @xmath11 is kept fixed . choosing @xmath683 and thereby ensuring that the approximation properties of @xmath389 are sufficient , we finally see that for the considered mesh sizes the epm - plateau has no effect on the relative total error @xmath685 ( fig .  [ fig4.3b ] ) . if we compare @xmath686 and @xmath687 for @xmath688 in fig",
    ".  [ fig4.3c ] , we detect that all three quantities exhibit the same exponential convergence rate until @xmath689 reaches the epm - plateau . as also the convergence behavior of the eigenvalues of the pod @xmath690 and of the coefficients @xmath691 coincide ( fig .",
    "[ fig4.3d ] ) , we conclude that for the present test case the convergence behavior of the pod transfers to the coefficients @xmath691 , @xmath687 and to the model error @xmath692,@xmath681 .",
    "thus , we infer that the discrete solution manifold @xmath386 and the reference solution @xmath459 are approximated with the same approximation accuracy by the reduction space @xmath388 .",
    "note that thanks to the coincidence of the convergence rates of @xmath690 and @xmath691 ( fig .",
    "[ fig4.3d ] ) , the qp - indicator introduced in  [ adapt - rb - hmr - epm ] would not have increased the number of quadrature points used in .",
    "+    to assess the approximation quality of the collateral basis spaces , we finally compare in fig .  [ fig4.4 ] the convergence rates of the respective pod - error @xmath693 and @xmath694 .",
    "we observe that the rates for the approximation of @xmath695 , @xmath696 and @xmath697 coincide perfectly .",
    "the deviation for the other two might be explained by the fact , that we have projected the snapshots corresponding to @xmath698 and @xmath699 onto the space of piecewise constant functions to account for the structure of the nonlinear operator .",
    "this yields a worse convergence behavior for decreasing @xmath261 as the projection onto the space @xmath700 we have employed for the others . as apart from this deviation the convergence rates coincide , we nevertheless conclude that the nonlinear operator @xmath460 , its frchet derivative @xmath701 , and the discrete manifolds of operator evaluations are approximated with the same quality .",
    "+    .test case 1 : comparison of the exact inf - sup stability factor ( ex ) with its approximate value ( app ) for @xmath702 and different tolerances @xmath677 in the epm and increasing model order @xmath11.[compare - inf - sup ] [ cols=\"^,^,^,^,^\",options=\"header \" , ]      +    next , we investigate the effectivity of the a posteriori error estimators derived in ",
    "[ sect - apostest ] .",
    "for the present test case we obtained the following approximate values of the inf - sup stability factor @xmath703 , @xmath704 , @xmath705 which indicates that @xmath706 , as @xmath707 . a comparison of the approximate values with the exact inf - sup stability factor in tab .",
    "[ compare - inf - sup ] shows that the approximation procedure proposed in  [ subsect_constants ] yields indeed a lower bound for the inf - sup stability factor and moreover a very accurate approximation .",
    "due to the very small inf - sup stability factor , @xmath559 is not fulfilled .",
    "nevertheless , it can be seen in fig .",
    "[ fig4.5a ] that @xmath708 bounds the error @xmath709 , albeit the effectivity constants are very high due to the small inf - sup stability factor .",
    "[ fig4.5c ] shows the scaling of @xmath659 for decreasing mesh sizes .",
    "we see in fig .",
    "[ fig4.5a]-[fig4.5c ] that for @xmath710 , @xmath711 captures the convergence behavior of @xmath681 in @xmath11 .",
    "for @xmath712 the behavior of @xmath681 until @xmath713 ( @xmath714 ) or @xmath715 ( @xmath716 ) is reproduced .",
    "the deviation for higher model orders for @xmath712 can be explained by the fact that @xmath717 lies above @xmath718 ( see fig .  [ fig4.5d ] ) , as the former also takes discretization errors into account which are not included in the latter . for @xmath710 , @xmath718 and @xmath717",
    "nearly coincide ( see fig .  [ fig4.5d ] ) .",
    "we therefore conclude that the a posteriori bound for the epm yields a very good approximation of @xmath719 and thus @xmath717 if the discretization error is not dominant .",
    "a ( standard ) term which estimates this discretization error may be added to error estimator but this is beyond the scope of this paper . here",
    ", we have set the tolerance for the pod determining the richer collateral basis space @xmath403 to @xmath720 with @xmath721 (  [ adapt - rb - hmr - epm ] ) .",
    "this yielded on average @xmath722 for @xmath712 and @xmath723 for @xmath710 .",
    "we recall that we have assumed @xmath724 to prove the effectivity of @xmath400 .",
    "[ fig4.5e ] illustrates the convergence behavior of @xmath725 and @xmath726 for increasing @xmath11 and @xmath688 .",
    "we observe that even if is violated , i.e. @xmath727 , we maintain effectivity of the error bounds ( see fig .  [ fig4.5a],[fig4.5e ] ) for this test case . however , as @xmath727 indicates that the epm - plateau is reached ( fig .",
    "[ fig4.5a ] , [ fig4.5e ] ) , the adherence of is necessary to avoid the plateau .",
    "finally , we investigate the a priori bound of the epm derived in theorem [ apriori - epm ] . as the convergence behavior of @xmath728 and @xmath729\\kappa_{k}\\|_{l^{2}(\\omega_{1d})}^{2}$ ]",
    "coincides ( see fig .",
    "[ fig4.4 ] ) we may apply theorem [ apriori - epm ] as an error estimator . note that is a probabilistic result and that the term @xmath730 does not provide an upper bound for the integration error due to the application of the monte - carlo method @xcite .",
    "however , fig  [ fig4.5f ] shows that apart from some deviations due to the epm - plateau the error @xmath731 and the pod - error have approximately the same convergence rate .",
    "the integration error can thus be estimated by the pod - error .",
    "hence , we employed the pod - error @xmath652 as an a priori bound in our numerical experiments and decreased the tolerance @xmath215 in by @xmath732 to account for the integration error . + for the sake of completeness we note that the input arguments of algorithm [ adapt - rb - hmr ] adaptive - rb - hmr , have been chosen as @xmath733\\times[-0.5,0.5]\\times[-1,1]$ ] , @xmath734 , @xmath735 , @xmath736 , @xmath737 , @xmath738 , @xmath739 for an element @xmath482 and @xmath740 , @xmath741 , @xmath742 for all computations for this test case .",
    "the average sample size has been @xmath743      in this test case we investigate the convergence behavior and computational efficiency of the rb - hmr approach for the approximation of non - smooth solutions of .",
    "we choose @xmath744 , @xmath745 and unless otherwise stated @xmath746 .",
    "we prescribe as a source term the characteristic function @xmath747 , where @xmath748 , @xmath749 and @xmath750 and thus have that the solution @xmath19 of is in @xmath751 for @xmath752 @xcite .",
    "the reference solutions @xmath459 for @xmath753 and @xmath746 are depicted at the top of fig .",
    "[ fig4.7 ] for @xmath754 and @xmath755 , where a convergence study has been done to ensure that @xmath459 contains all essential features of the exact solution .",
    "the strengthened nonlinear effects for decreasing @xmath756 can nicely be observed by means of the increased range of @xmath459 for @xmath746 and the much more localized peaks for @xmath753 . comparing the reference solutions with its rb - hmr approximations",
    ", we see that for both @xmath753 and @xmath746 already @xmath757 contains the three peaks and that the contour lines of @xmath758 and @xmath459 coincide ( fig .  [ fig4.7 ] ) .",
    "+     +    the input arguments of algorithm [ adapt - rb - hmr ] ( adaptive - rb - hmr ) have been chosen as @xmath759 $ ] @xmath760\\times[-1,1]$ ] , @xmath734 , @xmath735 , @xmath736 , @xmath737 , @xmath738 , @xmath739 for an element @xmath482 and @xmath761 , @xmath683 , @xmath741 for all computations for this test case employing one quadrature point in and thus setting @xmath762 in .",
    "this resulted in an average sample size of @xmath763 . for two quadrature points in or @xmath764 in we have chosen @xmath759\\times[0,2]\\times[-0.5,0.5]$],@xmath734 , @xmath765 , @xmath766 , @xmath767 , @xmath768 , @xmath769 , and @xmath770 , which yielded on average @xmath771 . fig .",
    "[ fig4.8a ] illustrates the training set @xmath87 generated with algorithm [ adapt - train ] adaptivetrainextension for @xmath772 .",
    "it can be seen that  against expectations  the train sample is not refined around the peaks but at the boundary of @xmath299 . using two quadrature points in we observe a refinement of the training set in the expected regions , namely around the peaks at @xmath773 and @xmath774 ( fig .",
    "[ fig4.8b ] ) .",
    "this might be a reason that for the present test case the error convergence of the rb - hmr approach improves significantly , if @xmath450 is increased from @xmath462 to @xmath553 . analyzing the convergence behavior of @xmath681",
    ", we detect an exponential convergence rate , which is much better for @xmath764 ( fig .",
    "[ fig4.9d ] ) .",
    "furthermore , we have observed for @xmath762 a much stronger increase of @xmath681 when entering the epm - plateau especially for coarser mesh sizes .",
    "note that additionally @xmath144 has been shrunk when passing from @xmath762 to @xmath764 , which further improved the rates .",
    "however , shrinking @xmath144 without increasing @xmath450 had no effect . a comparison of @xmath689 and @xmath775 in fig .",
    "[ fig4.9e ] shows that for @xmath764 the convergence rates coincide until @xmath689 approaches the epm - plateau , but clearly differ for @xmath772 .",
    "regarding @xmath690 and @xmath691 we observe in fig .",
    "[ fig4.9f ] that their convergence rates significantly differ for @xmath762 , but coincide for @xmath776 for @xmath777 .",
    "the rise of @xmath691 for @xmath778 might be caused by the epm - plateau .",
    "thus , we conclude that for the present test case for @xmath764 the discrete solution manifold @xmath386 and the reference solution @xmath459 are approximated with the same approximation quality by the reduction space @xmath388 .",
    "note that the qp - indicator would have detected in line [ qp1 ] of algorithm [ adapt - train ] that an increase of @xmath450 is necessary , but would not have raised @xmath450 further in line [ qp2 ] due to the coincidence of the rates of @xmath690 and @xmath691 for @xmath779 .",
    "[ fig4.10a ] shows the error convergence of @xmath681 for a simultaneous growth of @xmath11 and @xmath203 for @xmath684 .",
    "we see on the one hand a strong increase of the error if @xmath11 exceeds @xmath203 but on the other hand a nice error decay and only a small increase in the epm - plateau if @xmath780 is satisfied .",
    "we suppose that the worse behavior of @xmath319 in the epm - plateau compared to the previous test case ( compare fig .",
    "[ fig4.3e ] and fig .",
    "[ fig4.10a ] ) is due to the fact that the full solution of the present test case is non - smooth .",
    "an investigation of the convergence behavior of the relative total error demonstrates that for @xmath764 the epm - plateau has no effect on @xmath685 ( cf .",
    "[ fig4.10b ] ) , whereas for @xmath772 the epm - plateau influences the convergence of @xmath685 . comparing the convergence rates of @xmath728 with @xmath729\\kappa_{k}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] for the employed collateral basis spaces , we see in fig .",
    "[ fig4.11 ] that they are comparable for @xmath781 for @xmath762 and @xmath782 for @xmath764 , but clearly differ for higher values .",
    "this is due to the behavior of @xmath691 ( cf .",
    "[ fig4.9f ] ) , which stagnate exactly for @xmath783 ( @xmath762 ) and @xmath784 ( @xmath764 ) .",
    "however , we have observed that the level of the plateau of the coefficients @xmath785 and @xmath786\\kappa_{k}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] reduces for decreasing mesh sizes which might indicate that their stagnation is related to the epm - plateau .",
    "we hence suppose that since the solution of the present test case is non - smooth , in contrast to the previous example , the behavior of @xmath319 in the epm - plateau ( compare fig .  [ fig4.3e ] and fig .  [ fig4.10a ] ) also affects the coefficients @xmath785 and @xmath786\\kappa_{k}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] . +    next , we analyze the a posteriori error bounds derived in  [ subsect - brr ] .",
    "the approximate values of the inf - sup stability factor @xmath611 obtained with the method proposed in ",
    "[ subsect_constants ] are @xmath787 and @xmath788 and imply that @xmath706 , as @xmath707 . as in the previous test case",
    "the small values of @xmath611 prevent that @xmath559 is fulfilled and instead we may use @xmath708 as an error bound for @xmath709 ( cf .",
    "[ fig4.12a ] ) . while the convergence behavior of @xmath681 in @xmath11 is reproduced perfectly by @xmath711 for @xmath789 and @xmath790 , and @xmath764 ( fig .",
    "[ fig4.12b ] ) , for coarser mesh sizes the error estimator is not efficient for @xmath791 ( fig .  [ fig4.12c ] ) .",
    "this is due to the fact that for @xmath792 there holds @xmath793 , as @xmath794 is dominated by discretization errors ( fig .",
    "[ fig4.12d ] ) .",
    "thus , assumption is violated , which demonstrates that for the present test case satisfying is crucial to maintain the effectivity of the error estimator for @xmath764 .",
    "[ fig4.12d ] also shows that for moderate values of @xmath203 , @xmath794 and @xmath725 coincide perfectly , which numerically proves that also for the present test case for a non - dominant discretization error , the a posteriori bound for the epm results in a very good approximation of @xmath719 and thus @xmath717 . as in the previous test case",
    "we have set @xmath795 with @xmath721 (  [ adapt - rb - hmr - epm ] ) , which yielded on average @xmath723 .",
    "note that for @xmath762 in the effectivity of the error bounds is maintained even for @xmath796 ( fig .",
    "[ fig4.12a ] ) and that @xmath794 and @xmath725 mainly coincide even for high values of @xmath203 due to the higher level of the epm - plateau . comparing @xmath797 and @xmath725 for @xmath798 in fig .",
    "[ fig4.12e ] we observe that @xmath725 has improved much more than @xmath797 due to the increase of @xmath450 .",
    "hence , increasing @xmath450 seems to significantly reduce the level of the epm - plateau which in turn considerably improves the error behavior as has already been assessed in the analysis of fig .",
    "[ fig4.9 ] .",
    "in contrast to the previous test case , also for small tolerances @xmath677 a stagnation of @xmath797 can be observed ( compare fig .",
    "[ fig4.5e ] and fig .",
    "[ fig4.12e ] ) .",
    "thus , we suppose that due to the worse behavior of @xmath319 in the epm - plateau compared to the previous test case , the epm - plateau affects the convergence behavior of the model error for the present example . as the convergence behavior of @xmath728 and @xmath729\\kappa_{k}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] does not coincide ( see fig .  [ fig4.11 ] ) , we replace , as proposed in  [ subsect - brr ] , @xmath728 by @xmath729\\kappa_{k}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] in the a priori bound of theorem [ apriori - epm ] . fig .",
    "[ fig4.12f ] shows that @xmath694 captures the behavior of @xmath799 and @xmath717 perfectly for @xmath800 .",
    "the deviations for @xmath801 are due to the epm - plateau .",
    "although the snapshots set @xmath387 and @xmath460 are not approximated with the same approximation quality due to the epm - plateau ( fig .",
    "[ fig4.11 ] ) , we observe that @xmath799 and @xmath717 coincide for @xmath802 .",
    "thus , we conclude that for the present test case the modified version of the a priori bound of theorem [ apriori - epm ] , obtained by substituting @xmath728 by @xmath729\\kappa_{k}\\|_{l^{2}(\\omega_{1d})}^{2}$ ] , can be applied to obtain a robust and efficiently computable a posteriori error estimator @xmath803 .",
    "+ finally , we compare the total computational costs of the rb - hmr approach using the epm to compute @xmath319 , with the costs of the 2d bilinear fem for the computation of @xmath804 . here , by the term `` total computational costs '' we mean all costs that are required to compute an approximation .",
    "thus the total computational costs for the rb - hmr method comprise the costs for the construction of the reduction space and the collateral basis space by algorithm [ adapt - rb - hmr ] . amongst others",
    "the costs for the rb - hmr approach therefore include the costs for the adaptive generation of the snapshot sets by algorithm [ adapt - train ] and the within this algorithm employed a posteriori error estimator .",
    "they also comprise the costs for the pods which ultimately yield the reduction space and the collateral basis space .",
    "finally , the total computational costs for the rb - hmr approximation also include the costs for the assembling and solution of the nonlinear system of equations .",
    "+ for the solution of the nonlinear system of equations within newton s method we employed in both cases a bicgstab method with the same settings .",
    "also the tolerance for newton s method has been chosen identically . in fig .",
    "[ fig4.15a ] we see that the bilinear fem scales quadratically in @xmath805 , while the rb - hmr approach with the epm scales linearly in @xmath805 both for @xmath762 and @xmath764 in . in fig .",
    "[ fig4.15b ] the total computational costs of the bilinear fem and the rb - hmr approach are plotted versus the respective relative total error @xmath685 . due to the epm - plateau",
    "the total error @xmath685 for @xmath762 lies well above the one of the bilinear fem for the same mesh size , while only minimal deviations can be observed for @xmath764 .",
    "however , the run - time required to achieve a certain error tolerance is very much smaller for the rb - hmr approach than for the bilinear fem .",
    "to generalize the rb - hmr approach introduced in @xcite to nonlinear pdes we expanded the nonlinear operator in an orthonormal ( collateral ) basis in the transverse direction . both for the construction of the reduction space in the rb - hmr approach and the collateral basis space we used a highly nonlinear approximation",
    ". a manifold of parametrized lower dimensional operator evaluations has been generated by using the solutions of a parametrized dimensionally reduced problem and the corresponding parametrization .",
    "solution and operator snapshot sets have been simultaneously generated with an adaptive training set extension , and by applying a pod the reduction and collateral basis space are constructed . in this way we included both in the construction of the manifold of operator evaluations and the selection of the collateral basis information on the evaluation of the nonlinear operator in the unknown full solution .",
    "the coefficients of the operator approximation have been computed with the newly introduced adaptive epm , which is an adaptive integration algorithm based on the ( g ) eim @xcite . while for the basis selection with the greedy algorithm and the pod several convergence results are already proved , to the best of our knowledge",
    "no result that could have been employed , has been proved until now for the approximation of the range of a nonlinear operator .",
    "this has been realized in this article by the introduction of the adaptive empirical projection method and the proved rigorous a priori and a posteriori error bounds .",
    "we used these bounds to derive a rigorous a posteriori error estimator based on the brezzi - rappaz - raviart theory , which is employed for the construction of the snapshot sets . here , we extended the results on the effectivity of the error estimator in @xcite from quadratically nonlinear pdes to general nonlinear pdes of type .",
    "we emphasize that the proposed procedures for estimating the constants within this a posteriori error bound may be improved .",
    "+ the numerical experiments for the nonlinear diffusion equation show that the reference solution and the set of solution snapshots are approximated by the reduction space with the same approximation quality . here",
    ", a quadrature formula of higher accuracy had to be employed for a test case with a non - smooth solution .",
    "the evaluation of the nonlinear operator in the reference solution and the set of operator snapshots are approximated by the collateral basis space with the same approximation accuracy for a problem with an analytic solution and a comparable quality for a problem with a non - smooth solution .",
    "hence , we conclude that by employing the suggested ansatz for the generation of the solution manifold and the manifold of operator manifolds we are able to transfer the relevant features of the reference solution and the operator evaluation to the respective manifolds to a great extent .",
    "furthermore , the numerical experiments demonstrate an exponential convergence behavior of the rb - hmr approach both for a problem with an analytical solution and a test case with a non - smooth solution also for small ellipticity constants .",
    "the applicability of the theoretical results including the bounds for the adaptive epm is demonstrated , too . however , due to an unfavorable inf - sup constant the brezzi - rappaz - raviart conditions seems to be very restrictive .",
    "another consequence of the small inf - sup constant is the high effectivity of the a posteriori error estimator , which admits of improvements .",
    "run - time experiments show a linear scaling of the rb - hmr approach in the number of degrees of freedom used for the computations in the dominant direction , while the respective finite element reference approximation scales quadratically .",
    "this demonstrates the computational efficiency of the proposed method also in the nonlinear setting .",
    "+ * acknowledgements : * we would like to thank the anonymous reviewers very much for their careful review and their helpful remarks which have significantly improved the presentation of the paper .",
    "+ [ 2 ] http://www.ams.org/mathscinet-getitem?mr=#1[#2 ] [ 2]#2      a.  ammar , b.  mokdad , f.  chinesta , and r.  keunings , _ a new family of solvers for some classes of multidimensional partial differential equations encountered in kinetic theory modeling of complex fluids _ , journal of non - newtonian fluid mechanics * 139 * ( 2006 ) , no .  3 , 153176 .",
    "m.  barrault , y.  maday , n.c .",
    "nguyen , and a.t .",
    "patera , _ an empirical interpolation method : application to efficient reduced - basis discretization of partial differential equations _ , c. r. math .",
    "paris series i * 339 * ( 2004 ) , 667672 .",
    "h.  berninger , m.  ohlberger , o.  sander , and k.  smetana , _ unsaturated subsurface flow with surface water and nonlinear in- and outflow conditions _ , math .",
    "models methods appl .",
    "* 24 * ( 2014 ) , no .  5 , 901936 .",
    "k.  carlberg , c.  bou - mosleh , and c.  farhat , _ efficient non linear model reduction via a least - squares petrov - galerkin projection and compressive tensor approximations .",
    ". j. numer .",
    "methods eng .",
    "* 86 * ( 2011 ) , no .  2 , 155181 .",
    "k.  carlberg , c.  farhat , j.  cortial , and d.  amsallem , _ the gnat method for nonlinear model reduction : effective implementation and application to computational fluid dynamics and turbulent flows _ , journal of computational physics * 242 * ( 2013 ) , 623647 .",
    "f.  chinesta , a.  ammar , and e.  cueto , _ recent advances and new challenges in the use of the proper generalized decomposition for solving multidimensional models _",
    "methods eng .",
    "* 17 * ( 2010 ) , no .  4 , 327350 .      j.  e. dennis , jr . and r.  b. schnabel , _ numerical methods for unconstrained optimization and nonlinear equations _ , classics in applied mathematics , vol .  16 ,",
    "society for industrial and applied mathematics ( siam ) , philadelphia , pa , 1996 .",
    "m.  drohmann , b.  haasdonk , and m.  ohlberger , _ adaptive reduced basis methods for nonlinear convection  diffusion equations _ , finite volumes for complex applications vi problems & perspectives , springer , 2011 , pp .",
    "369377 .",
    "a.  ern , s.  perotto , and a.  veneziani , _ hierarchical model reduction for advection - diffusion - reaction problems _ , numerical mathematics and advanced applications ( karl kunisch , gnther of , and olaf steinbach , eds . ) , springer berlin heidelberg , 2008 , pp .",
    "703710 .",
    "l.  formaggia , j.  f. gerbeau , f.  nobile , and a.  quarteroni , _ on the coupling of 3d and 1d navier - stokes equations for flow problems in compliant vessels _ , comput .",
    "methods appl .",
    "* 191 * ( 2001 ) , no .",
    "6 - 7 , 561582 .",
    "m.  a. grepl , y.  maday , n.  c. nguyen , and a.  t. patera , _ efficient reduced - basis treatment of nonaffine and nonlinear partial differential equations _ , m2an math .",
    "41 * ( 2007 ) , no .  3 , 575605 .",
    "b.  haasdonk , m.  dihlmann , and m.  ohlberger , _ a training set and multiple bases generation approach for parameterized model reduction based on adaptive grids in parameter space _ , math .",
    "* 17 * ( 2011 ) , no .  4 , 423442 .            y.  maday and o.  mula , _ a generalized empirical interpolation method : application of reduced basis techniques to data assimilation _ ,",
    "analysis and numerics of partial differential equations , springer indam series , vol .  4 , springer milan , 2013 , pp .  221235 .",
    "y.  maday , o.  mula , and g.  turinici , _ a priori convergence of the generalized empirical interpolation method .",
    "_ , 10th international conference on sampling theory and applications ( sampta 2013 ) , 2013 , pp .  168171 .",
    "m.  ohlberger and k.  smetana , _ a new hierarchical model reduction - reduced basis technique for advection - diffusion - reaction problems _ , proceedings of the v international conference on adaptive modeling and simulation ( admos 2011 ) held in paris , france , 6 - 8 june 2011 ( barcelona ) ( d.  aubry , p.  dez , b.  tie , and n.  pars , eds . ) , 2011 , pp .",
    "343354 .",
    "k.  urban and b.  wieland , _ affine decompositions of parametric stochastic processes for application within reduced basis methods _ , accepted for publication in proceedings",
    "mathmod 2012 , 7th vienna international conference on mathematical modelling , 2012 .",
    "k.  veroy and a.  t. patera , _ certified real - time solution of the parametrized steady incompressible navier - stokes equations : rigorous reduced - basis a posteriori error bounds _",
    ", internat .",
    "methods fluids * 47 * ( 2005 ) , no .",
    "8 - 9 , 773788 ."
  ],
  "abstract_text": [
    "<S> in this paper we extend the hierarchical model reduction framework based on reduced basis techniques recently introduced in @xcite for the application to nonlinear partial differential equations . the major new ingredient to accomplish </S>",
    "<S> this goal is the introduction of the adaptive empirical projection method , which is an adaptive integration algorithm based on the ( generalized ) empirical interpolation method @xcite . </S>",
    "<S> different from other partitioning concepts for the empirical interpolation method we perform an adaptive partitioning of the spatial domain . </S>",
    "<S> we project both the variational formulation and the range of the nonlinear operator onto reduced spaces . </S>",
    "<S> those combine the full dimensional space in an identified dominant spatial direction and a reduction space or collateral basis space spanned by modal orthonormal basis functions in the transverse direction . </S>",
    "<S> both the reduction and the collateral basis space are constructed in a highly nonlinear fashion by introducing a parametrized problem in the transverse direction and associated parametrized operator evaluations , and by applying reduced basis methods to select the bases from the corresponding snapshots . </S>",
    "<S> rigorous a priori and a posteriori error estimators which do not require additional regularity of the nonlinear operator are proven for the adaptive empirical projection method and then used to derive a rigorous a posteriori error estimator for the resulting hierarchical model reduction approach . </S>",
    "<S> numerical experiments for an elliptic nonlinear diffusion equation demonstrate a fast convergence of the proposed dimensionally reduced approximation to the solution of the full - dimensional problem . </S>",
    "<S> run - time experiments verify a linear scaling of the reduction method in the number of degrees of freedom used for the computations in the dominant direction .    </S>",
    "<S> * keywords : * dimensional reduction , hierarchical model reduction , reduced basis methods , a posteriori error estimation , nonlinear partial differential equations , empirical interpolation , finite elements + * ams subject classification : * 65n15,65n30,65y20,35j60,65d05,65d30 + </S>"
  ]
}