{
  "article_text": [
    "compressed sensing ( cs ) @xcite is an emerging sparse sampling theory which received a large amount of attention in the area of signal processing recently . consider a @xmath1-sparse signal @xmath3 which has at most @xmath1 nonzero entries .",
    "let @xmath4 be a measurement matrix with @xmath5 and @xmath6 be a measurement vector .",
    "compressed sensing deals with recovering the original signal @xmath7 from the measurement vector @xmath8 by finding the sparsest solution to the undetermined linear system @xmath6 , i.e. , solving the the following _ @xmath9-optimization _ problem @xmath10 where @xmath11 denotes the @xmath9-norm or ( hamming ) weight of @xmath7 .",
    "unfortunately , it is well - known that the problem ( [ l0 ] ) is np - hard in general @xcite . in compressed sensing , there are essentially two methods to deal with it .",
    "the first one pursues greedy algorithms for @xmath9-optimization , such as the orthogonal matching pursuit ( omp ) @xcite and its modifications @xcite .",
    "the second method considers a convex relaxation of ( [ l0 ] ) , or the _ @xmath12-optimization _ ( basis pursuit ) problem , as follows @xcite @xmath13 where @xmath14 denotes the @xmath12-norm of @xmath7 .",
    "note that the problem ( [ l1 ] ) could be turned into a linear programming ( lp ) problem and thus tractable .",
    "the construction of measurement matrix @xmath15 is one of the main concerns in compressed sensing . in order to select an appropriate matrix ,",
    "we need some criteria . in their earlier and fundamental works ,",
    "donoho and elad @xcite introduced the concept of _ spark_. the spark of a measurement matrix @xmath15 , denoted by @xmath16 , is defined to be the smallest number of columns of @xmath15 that are linearly dependent , i.e. , @xmath17 where @xmath18 furthermore , @xcite obtained several lower bounds of @xmath16 and showed that if @xmath19 then any @xmath1-sparse signal @xmath7 can be exactly recovered by the @xmath9-optimization ( [ l0 ] ) .",
    "in fact , we will see in the appendix that the condition ( [ proeq1 ] ) is also necessary for both the @xmath9-optimization ( [ l0 ] ) and the @xmath12-optimization ( [ l1 ] ) .",
    "hence , the spark is an important performance parameter of the measurement matrix .",
    "other useful criteria include the well - known restricted isometry property ( rip ) @xcite and the nullspace characterization @xcite .",
    "although most known constructions of measurement matrix rely on rip , we will use spark instead in this paper since the spark is simpler and easier to deal with in some cases .    generally , there are two main kinds of constructing methods for measurement matrices : random constructions and deterministic constructions .",
    "many random matrices , e.g. , fourier matrices @xcite , gaussian matrices , rademacher matrices @xcite , _ etc _ , have been verified to satisfy rip with overwhelming probability .",
    "although random matrices perform quite well on average , there is no guarantee that a specific realization works .",
    "moreover , storing a random matrix may require lots of storage space .",
    "on the other hand , a deterministic matrix is often generated on the fly , and some properties , e.g. , spark , girth and rip , could be verified definitely .",
    "there are many works on deterministic constructions @xcite . among these , constructions from coding theory @xcite",
    "attract many attentions , e.g. , amini and marvasti @xcite used bch codes to construct binary , bipolar and ternary measurement matrices , and li _ et al . _ @xcite employed algebraic curves to generalize the constructions based on reed - solomon codes . in this paper , we usually use @xmath15 to denote a real measurement matrix and @xmath20 a binary measurement matrix .",
    "recently , connections between ldpc codes @xcite and cs excite interest .",
    "dimakis , smarandache , and vontobel @xcite pointed out that the lp decoding of ldpc codes is very similar to the lp reconstruction of cs , and further showed that parity - check matrices of good ldpc codes can be used as _ provably _ good measurement matrices under basis pursuit .",
    "ldpc codes are a class of linear block codes , each of which is defined by the nullspace over @xmath21 of a binary sparse @xmath22 parity - check matrix @xmath20 .",
    "let @xmath23 and @xmath24 denote the sets of column indices and row indices of @xmath20 , respectively .",
    "the _ tanner graph _",
    "@xmath25 @xcite corresponding to @xmath20 is a bipartite graph comprising of @xmath26 variable nodes labeled by the elements of @xmath27 , @xmath28 check nodes labelled by the elements of @xmath29 , and the edge set @xmath30 , where there is an edge @xmath31 if and only if @xmath32 . the _ girth _",
    "@xmath33 of @xmath25 , or briefly the girth of @xmath20 , is defined as the minimum length of circles in @xmath25 .",
    "obviously , @xmath33 is always an even number and @xmath34 .",
    "@xmath20 is said to be @xmath35-_regular _ if @xmath20 has the uniform column weight @xmath36 and the uniform row weight @xmath37 .",
    "the performance of an ldpc code under iterative / lp decoding over a binary erasure channel is completely determined by certain combinatorial structures , called stopping sets . a _ stopping set _",
    "@xmath38 of @xmath20 is a subset of @xmath27 such that the restriction of @xmath20 to @xmath38 , say @xmath39 , does nt contain a row of weight one .",
    "the smallest size of a nonempty stopping set , denoted by @xmath40 , is called the stopping distance of @xmath20 . lu _ et al . _",
    "@xcite verified that binary sparse measurement matrices constructed by the well - known peg algorithm @xcite significantly outperform gaussian random matrices by a series of experiments .",
    "similar to the situation in constructing ldpc codes , matrices with girth 6 or higher are preferred in the above two works @xcite . in this paper",
    ", we manage to establish more connections between ldpc codes and cs .",
    "our main contributions focus on the following two aspects .",
    "* _ lower bounding the spark of a binary measurement matrix @xmath20 .",
    "_ as an important performance parameter for ldpc codes , the stopping distance @xmath40 plays a similar role that the spark does in cs .",
    "firstly , we show that @xmath41 , which again verifies the fact that good parity - check matrices are good measurement matrices . a special case of the lower bound is the binary corollary of the lower bound for real matrices in @xcite .",
    "then , a new general lower bound of @xmath42 is obtained , which improved the previous one in most cases .",
    "furthermore , for a class of binary matrices from finite geometry , we give two further improved lower bounds to show their relatively large spark . * _ constructing binary measurement matrices with relatively large spark .",
    "_ ldpc codes based on finite geometry could be found in @xcite . with similar methods ,",
    "two classes of deterministic constructions based on finite geometry are given , where the girth equals 4 or 6 .",
    "the above lower bounds on spark ensure that the proposed matrices have relatively large spark .",
    "simulation results show that the proposed matrices perform well and in many cases significantly better than the corresponding gaussian random matrices under the omp algorithm . even in the case of girth 4 ,",
    "some proposed constructions still manifest good performance . moreover ,",
    "most of the proposed matrices could be put in either cyclic or quasi - cyclic form , and thus the hardware realization of sampling becomes easier and simpler .",
    "the rest of the paper is organized as follows . in section [ fgldpc ]",
    "we give a brief introduction to finite geometries and their parallel and quasi - cyclic structures , which result in the two classes of deterministic constructions naturally .",
    "section [ mainresults ] obtains our main results , or the two lower bounds of spark for general binary matrices and two further improved lower bounds for the proposed matrices from finite geometry .",
    "simulation results and related remarks are given in section [ simulation ] .",
    "finally , section [ conclusion ] concludes the paper with some discussions .",
    "finite geometry was used to construct several classes of parity - check matrices of ldpc codes which manifest excellent performance under iterative decoding @xcite @xcite .",
    "we will see in the later sections that most of these structured matrices are also good measurement matrices in the sense that they often have considerably large spark and may manifest better performance than the corresponding gaussian random matrices under the omp algorithm . in this section ,",
    "we introduce some notations and results of finite geometry @xcite@xcite .",
    "let @xmath43 be a finite field of @xmath44 elements and @xmath45 be the @xmath46-dimensional vector space over @xmath43 , where @xmath47 .",
    "let @xmath48 be the @xmath46-dimensional euclidean geometry over @xmath43 .",
    "@xmath48 has @xmath49 points , which are vectors of @xmath45 .",
    "the @xmath50-flat in @xmath48 is a @xmath50-dimensional subspace of @xmath45 or its coset .",
    "let @xmath51 be the @xmath46-dimensional projective geometry over @xmath43 .",
    "@xmath51 is defined in @xmath52 .",
    "two nonzero vectors @xmath53 are said to be equivalent if there is @xmath54 such that @xmath55 .",
    "it is well known that all equivalence classes of @xmath52 form points of @xmath51 . @xmath51",
    "has @xmath56 points .",
    "the @xmath50-flat in @xmath51 is simply the set of equivalence classes contained in a @xmath57-dimensional subspace of @xmath58 . in this paper , in order to present a unified approach , we use @xmath59 to denote either @xmath48 or @xmath51 .",
    "a point is a @xmath60-flat , a _ line _ is a @xmath61-flat , and a @xmath62-flat is called a _",
    "hyperplane_.      for @xmath63 , there are @xmath64 @xmath65-flats contained in a given @xmath66-flat and @xmath67 @xmath68-flats containing a given @xmath69-flat , where for @xmath48 and @xmath51 respectively @xcite @xmath70 @xmath71 let @xmath72 and @xmath73 be the numbers of @xmath69-flats and @xmath66-flats in @xmath59 respectively .",
    "the @xmath69-flats and @xmath66-flats are indexed from @xmath61 to @xmath26 and @xmath61 to @xmath74 respectively .",
    "the incidence matrix @xmath75 of @xmath66-flat over @xmath69-flat is a binary @xmath76 matrix , where @xmath32 for @xmath77 and @xmath78 if and only if the @xmath79th @xmath66-flat contains the @xmath80th @xmath69-flat .",
    "the rows of @xmath20 correspond to all the @xmath66-flats in @xmath59 and have the same weight @xmath64 .",
    "the columns of @xmath20 correspond to all the @xmath69-flats in @xmath59 and have the same weight @xmath67 .",
    "hence , @xmath20 is a @xmath35-regular matrix , where @xmath81    the incidence matrix @xmath20 or @xmath82 will be employed as measurement matrices and called respectively the _ type i or type ii finite geometry measurement matrix_. moreover , by puncturing some rows or columns of @xmath20 or @xmath82 , we could construct a large amount of measurement matrices with various sizes . to obtain submatrices of @xmath20 or @xmath82 with better performance ,",
    "the property of parallel structure in euclidean geometry are often employed as follows .      in this class of constructions , an important rule of puncturing the rows or columns of @xmath20 or @xmath82",
    "is to make the remained submatrix as regular as possible .",
    "a possible explanation may come from theorem [ preth ] in the next section .",
    "this rule can be applied since the euclidean geometry has the parallel structure and all @xmath66-flats ( or @xmath69-flat ) can be arranged by a suitable order .    since a projective geometry",
    "does not have the parallel structure , we concentrate on @xmath48 only . recall that a @xmath50-flat in @xmath48 is a @xmath50-dimensional subspace of @xmath45 or its coset .",
    "a @xmath50-flat contains @xmath83 points .",
    "two @xmath50-flats are either disjoint or they intersect on a flat with dimension at most @xmath84 .",
    "the @xmath50-flats that correspond to the cosets of a @xmath50-dimensional subspace of @xmath45 ( including the subspace itself ) are said to be parallel to each other and form a parallel bundle .",
    "these parallel @xmath50-flats are disjoint and contain all the points of @xmath48 with each point appearing once and only once .",
    "the number of parallel @xmath50-flats in a parallel bundle is @xmath85 .",
    "there are totally @xmath86 @xmath87-flats which consist of @xmath88 parallel bundles in @xmath48 .",
    "we index these parallel bundles from @xmath89 .",
    "consider the @xmath76 incidence matrix @xmath20 of @xmath87-flat over @xmath90-flat .",
    "all @xmath74 rows of @xmath20 could be divided into @xmath91 bundles each of which contain @xmath92 rows , i.e. , by suitable row arrangement , @xmath20 could be written as @xmath93 where @xmath94 ( @xmath95 ) is a @xmath96 submatrix of @xmath20 and corresponds to the @xmath80-th parallel bundles of @xmath66-flat .",
    "clearly , the row weight of @xmath94 remains unchanged and its column weight is 1 or 0 .",
    "similar to the ordering of rows , the columns of @xmath20 can also be ordered according to the parallel bundles in @xmath97 .",
    "hence , by deleting some row parallel bundles or column parallel bundles from @xmath20 , and transposing the obtained submatrix if needed , we could construct a large amount of measurement matrices with various sizes .",
    "these will be illustrated by several examples in section iv .    in this paper , we call @xmath20 or @xmath82 the first class of binary measurement matrices from finite geometry , and their punctured versions the second class of binary measurement matrices from finite geometry .      apart from the parallel structure of euclidean geometry , most of the incidence matrices in euclidean geometry and projective geometry also have cyclic or quasi - cyclic structure @xcite .",
    "this is accomplished by grouping the flats of two different dimensions of a finite geometry into cyclic classes .",
    "for a euclidean geometry , only the flats not passing through the origin are used for matrix construction .",
    "based on this grouping of rows and columns , the incidence matrix in finite geometry consists of square submatrices ( or blocks ) , and each of these square submatrices is a circulant matrix in which each row is a cyclic shift of the row above it and the first row is the cyclic shift of the last row .",
    "note that by puncturing the row blocks or column blocks of the incidence matrices , the remained submatrices are often as regular as possible . in other words , this skill is compatible with the parallel structure of euclidean geometry .",
    "hence , the sampling process with these measurement matrices is easy and can be achieved with linear shift registers . for detailed results and discussions ,",
    "we refer the readers to ( * ? ? ?",
    "* appendix a ) .",
    "the definition of spark was introduced by donoho and elad @xcite to help to build a theory of sparse representation that later gave birth to compressed sensing . as we see from ( [ proeq1 ] ) , spark of the measurement matrix",
    "can be used to guarantee the exact recovery of @xmath1-sparse signals . as a result , while choosing measurement matrices , those with large sparks are prefered . however , the computation of spark is generally np - hard @xcite . in this section ,",
    "we give several lower bounds of the spark for general binary matrices and the binary matrices constructed in section ii by finite geometry .",
    "these theoretical results guarantee the good performance of the proposed measurement matrices under the omp algorithm to some extent .",
    "firstly , we give a relationship between the spark and stopping distance of a general binary matrix .    for a real vector @xmath98",
    ", the support of @xmath7 is defined by the set of non - zero positions , i.e. , @xmath99 . clearly , @xmath100 .",
    "traditionally , a easily computable property , _ coherence _ , of a matrix is used to bound its spark . for a matrix @xmath4 with column vectors",
    "@xmath101 , the coherence @xmath102 or the matrix @xmath15 has a all - zero column . ]",
    "is defined by @xcite : @xmath103 where @xmath104 denotes the inner product of vectors .",
    "furthermore , it is shown in @xcite that @xmath105 note that this lower bound applies to general real matrices .    for the general binary matrix @xmath20",
    ", the next theorem shows that the spark could be lower bounded by the stopping distance .",
    "[ preth0 ] let @xmath20 be a binary matrix .",
    "then , for any @xmath106 , the support of @xmath107 must be a stopping set of @xmath20 .",
    "moreover , @xmath108    assume the contrary that @xmath109 is not a stopping set .",
    "by the definition of stopping set , there is one row of @xmath20 containing only one ` 1 ' on @xmath109 .",
    "then the inner product of @xmath110 and this row will be nonzero , which contradicts with the fact that @xmath111 .",
    "hence , @xmath112 according to the definitions of stopping distance and spark .",
    "let @xmath20 be the @xmath113 parity - check matrix of a binary @xmath114 $ ] hamming code @xcite , which consists of all @xmath28-dimensional non - zero column vectors .",
    "it is easy to check that @xmath115 , which implies that the lower bound ( [ lbpre ] ) could be achieved .",
    "this lower bound verifies again the conclusion that good parity - check matrices are also good measurement matrices .",
    "in particular , consider a binary @xmath22 matrix @xmath20 .",
    "suppose the minimum column weight of @xmath20 is @xmath116 , and the maximum inner product of any two different columns of @xmath20 is @xmath117 . by ( [ defcoh ] ) , we have @xmath118 thus the lower bound ( [ generalspark ] ) from @xcite implies @xmath119 on the other hand , it was proved that @xmath120 @xcite .",
    "hence , the bound ( [ binarysparkold ] ) is a natural corollary of theorem [ preth0 ] .    as a matter of fact , for the general binary matrix @xmath20",
    ", we often have a tighter lower bound of its spark .    [ preth ]",
    "let @xmath20 be a binary @xmath22 matrix @xmath20 .",
    "suppose the minimum column weight of @xmath20 is @xmath116 , and the maximum inner product of any two different columns of @xmath20 is @xmath117 .",
    "then @xmath121    for any @xmath122 , we split the non - empty set @xmath123 into two parts @xmath124 and @xmath125 , @xmath126 without loss of generality , we assume that @xmath127 . for fixed @xmath128 , by selecting the @xmath79-th column of @xmath20 and all the columns in @xmath125 of @xmath20 , we get a submatrix @xmath129",
    ". since the column weight of @xmath20 is at least @xmath36 , we could select @xmath36 rows of @xmath129 to form a @xmath130 submatrix of @xmath20 , say @xmath131 , where the column corresponds to @xmath79 is all 1 column .",
    "now let s count the total number of 1 s of @xmath131 in two ways .",
    "* from the view of columns , since the maximum inner product of any two different columns of @xmath20 is @xmath132 , each of the columns of @xmath131 corresponds to @xmath125 has at most @xmath132 1 s .",
    "so the total number is at most @xmath133 . * from the view of rows , we claim that there is at least two 1 s in each row of @xmath131 , which implies the total number is at least @xmath134 1 s .",
    "the claim is shown as follows .",
    "let @xmath135 be a row of @xmath131 and @xmath136 be its corresponding row in @xmath20 .",
    "note that @xmath137 . since @xmath138 , @xmath139 which implies that @xmath140 so there are at least one 1 s in @xmath141 and @xmath135 has at least two 1 s .",
    "therefore , @xmath142 , which implies that @xmath143 . since @xmath144 , @xmath145 and the conclusion follows .",
    "note that the matrix in theorem [ preth ] has girth at least 6 if @xmath146 .",
    "when @xmath147 , it is clear that the lower bound ( [ thgeneral ] ) of theorem [ preth ] is tighter than ( [ binarysparkold ] ) .",
    "combining theorem [ preth ] with ( [ proeq1 ] ) , we have that any @xmath1-sparse signal @xmath7 can be exactly recovered by the @xmath9-optimization ( [ l0 ] ) if @xmath148 .",
    "consider a complete graph on 4 vertices .",
    "the incidence matrix is @xmath149 clearly , @xmath150 and the lower bound ( [ thgeneral ] ) is 4 .",
    "moreover , it is easy to check that @xmath151 and @xmath152 is a stopping set , which implies that @xmath153 and @xmath154 .",
    "this result could be generalized to the complete graph on @xmath26 nodes . then spark and stopping distance are also 4 and 3 respectively , which implies that the lower bound ( [ thgeneral ] ) of theorem [ preth ]",
    "could be achieved and may be tighter than one in theorem [ preth0 ] .",
    "clearly , the lower bound of theorem [ preth ] for general binary matrices applies to all ones constructed in section ii by finite geometry . in this subsection",
    ", we will show that for these structured matrices based on finite geometry , more tighter lower bound could be obtained .",
    "let @xmath20 be the @xmath76 incidence matrix of @xmath87-flats over @xmath90-flats in @xmath155 , where @xmath156 , @xmath157 and @xmath158 .",
    "recall that @xmath20 or @xmath82 are called respectively the type - i or tyep - ii finite geometry measurement matrix .",
    "the following lemma is needed to establish our results .",
    "@xcite[lem1 ] let @xmath159 and @xmath160 .",
    "given any @xmath161 different @xmath69-flats @xmath162 in @xmath59 and for any @xmath163 , there exists one @xmath164-flat @xmath165 such that @xmath166 and @xmath167 for all @xmath168 .",
    "[ thm1 ] let @xmath169 be integers , @xmath170 and @xmath20 be the type - i finite geometry measurement matrix .",
    "then @xmath171 where @xmath172    let @xmath173 and assume the contrary that @xmath174 select a @xmath122 such that @xmath175 . by ( [ split1 ] ) and ( [ split2 ] ) , we split the non - empty set @xmath123 into two parts @xmath124 and @xmath125 , and assume @xmath127 without loss of generality .",
    "thus by the assumption @xmath176 for fixed @xmath128 , by selecting @xmath79-th column of @xmath20 and all the columns in @xmath125 of @xmath20 , we get a submatrix @xmath129 .",
    "the number of columns in @xmath129 is @xmath177 and not greater than @xmath178 .",
    "let @xmath179 and @xmath180 be the @xmath69-flats corresponding to the columns of @xmath129 . by lemma [ lem1 ]",
    ", there exists one @xmath164-flat @xmath165 such that @xmath166 and @xmath167 for all @xmath181 .",
    "there are exactly @xmath178 @xmath68-flats containing @xmath165 .",
    "note that among these @xmath66-flats , any two distinct @xmath66-flats have no other common points except those points in @xmath165 ( see @xcite ) .",
    "hence , each of these @xmath178 @xmath68-flats contains the @xmath69-flat @xmath179 and for any @xmath181 , there exist at most one of these @xmath178 @xmath68-flats containing the @xmath69-flat @xmath182 . in other words ,",
    "there exist @xmath178 rows in @xmath129 such that each of these rows has component @xmath61 at position @xmath79 and for any @xmath183 , there exists at most one row that has component @xmath61 at position @xmath80 .",
    "let @xmath184 be the @xmath185 submatrix of @xmath129 by choosing these rows , where the column corresponds to @xmath79 is all 1 column .",
    "now let s count the total number of 1 s of @xmath184 in two ways .",
    "the column corresponds to @xmath79 has @xmath178 @xmath61 s while each of the other columns has at most one @xmath61 .",
    "thus from the view of columns , the total number of @xmath61 s in @xmath184 is at most @xmath186 . on the other hand ,",
    "suppose @xmath187 is the number of rows in @xmath184 with weight one . then , there are @xmath188 rows with weight at least two .",
    "thus from the view of rows , the total number of @xmath61 s in @xmath184 is at least @xmath189 .",
    "hence , @xmath190 , which implies that @xmath191 by the assumption . in other words , @xmath129 contains a row with value @xmath61 at the position corresponding to @xmath79 and @xmath60 at other positions .",
    "denote this row by @xmath135 and let @xmath136 be its corresponding row in @xmath20 .",
    "note that @xmath137 and @xmath192 . since @xmath138 , @xmath193 which leads to a contradiction",
    "therefore , the assumption is wrong and the theorem follows by ( [ fg3 ] ) .",
    "combining theorem [ thm1 ] with ( [ proeq1 ] ) , we have that when the type - i finite geometry measurement matrix is used , any @xmath1-sparse signal @xmath7 can be exactly recovered by the @xmath9-optimization ( [ l0 ] ) if @xmath194 .",
    "[ remark2 ] for the type - i finite geometry measurement matrix @xmath20 , it is known that @xmath195 @xcite .",
    "thus , by theorem [ preth0 ] , @xmath196 obviously , @xmath20 has uniform column weight @xmath197 .",
    "the inner product of two different columns equals to the number of @xmath87-flats containing two fixed @xmath90-flats .",
    "it is easy to see that the maximum inner product is @xmath198 .",
    "thus , by theorem [ preth ] , @xmath199 it is easy to verity by ( [ fg3 ] ) that @xmath200 where the last inequality always holds because of @xmath201 and @xmath202 .",
    "this implies that the lower bound ( [ lb2 ] ) is strictly tighter than the lower bound ( [ lb1 ] ) . on the other hand ,",
    "the lower bound ( [ eqthm1 ] ) of theorem [ thm1 ] is tighter than the lower bound ( [ lb2 ] ) .",
    "this is because @xmath203 in other words , for @xmath201 , the three lower bounds ( [ eqthm1 ] ) , ( [ lb2 ] ) , ( [ lb1 ] ) satisfies @xmath204 where the inequality becomes an equality if and only if @xmath205 .",
    "similarly , for the type - ii finite geometry measurement matrix , we obtain the following results .",
    "@xcite [ lem2 ] let @xmath206 and @xmath207 .",
    "given any @xmath161 different @xmath66-flats @xmath162 in @xmath59 and for any @xmath163 , there exists one @xmath208-flat @xmath165 such that @xmath209 and @xmath210 for all @xmath168 .",
    "[ thm2 ] let @xmath169 be integers , @xmath170 and @xmath82 be the type - ii finite geometry measurement matrix .",
    "then @xmath211 where for euclidean geometry ( eg ) and projective geometry ( pg ) respectively @xmath212    note that the columns of @xmath82 are rows of @xmath20 .",
    "let @xmath213 and assume the contrary that @xmath214 select a @xmath215 such that @xmath216 .",
    "we split @xmath123 into @xmath124 and @xmath125 , and assume @xmath127 without loss of generality .",
    "thus @xmath176 for fixed @xmath128 , by selecting @xmath79-th column of @xmath82 and all the columns in @xmath125 of @xmath82 , we get a submatrix @xmath217 .",
    "the number of columns in @xmath217 is @xmath177 and not greater than @xmath178 .",
    "let @xmath179 and @xmath180 be the @xmath66-flats corresponding to the columns of @xmath217 . by lemma [ lem2 ]",
    ", there exists one @xmath208-flat @xmath165 such that @xmath218 and @xmath210 for all @xmath181 .",
    "there are exactly @xmath178 @xmath65-flats contained in @xmath165 .",
    "now , we claim that @xmath179 contains these @xmath178 @xmath65-flats and @xmath182 ( @xmath181 ) contains at most one @xmath69-flat among these @xmath178 @xmath65-flats .",
    "otherwise , if @xmath182 ( @xmath181 ) contains at least two distinct @xmath69-flats among these @xmath178 @xmath65-flats , then @xmath182 must contain @xmath165 since @xmath165 is the only @xmath208-flat containing these two distinct @xmath69-flats .",
    "this contradicts to the fact that @xmath165 is not contained in @xmath182 .",
    "hence , there exist @xmath178 rows in @xmath217 such that each of these rows has component 1 at position @xmath79 and for any @xmath181 , there exists at most one row that has component 1 at position @xmath80 .    using the same argument in the proof of theorem [ thm1 ]",
    ", it leads to a contradiction .",
    "therefore , the assumption is wrong and the theorem follows by ( [ fg1 ] ) and ( [ fg2 ] ) .    combining theorem [ thm2 ] with ( [ proeq1 ] ) , we have that when the type - ii finite geometry measurement matrix is used , any @xmath1-sparse signal @xmath7 can be exactly recovered by the @xmath9-optimization ( [ l0 ] ) if @xmath219 .    [ remark3 ] for the type - ii finite geometry measurement matrix @xmath82",
    ", it is known that @xmath220 @xcite .",
    "thus , by theorem [ preth0 ] , @xmath221 obviously , @xmath82 has uniform column weight @xmath222 .",
    "the inner product of two different columns equals to the number of @xmath90-flats contained in two fixed @xmath87-flats at the same time .",
    "it is easy to see that the maximum inner product is @xmath223 .",
    "thus , by theorem [ preth ] , @xmath224 using the same argument in remark [ remark2 ] , we have that for @xmath201 , the three lower bounds ( [ eqthm2 ] ) , ( [ lb2 t ] ) , ( [ lb1 t ] ) satisfies @xmath225 where the inequality becomes an equality if and only if @xmath205 or @xmath226 for euclidean geometry and @xmath205 for projective geometry , respectively .",
    "in this section , we will give some simulation results on the performances for the proposed two classes of binary measurement matrices from finite geometry .",
    "the theoretical results on the sparks of these matrices in last section could explain to some extent their good performance .",
    "afterwards , we will show by examples how to employ the parallel structure of euclidean geometry to construct measurement matrices with flexible parameters .",
    "all the simulations are performed under the same conditions as with @xcite .",
    "the upcoming figures show the percentage of perfect recovery ( snr@xmath227db ) when different sparsity orders are considered . for the generation of the @xmath1-sparse input signals , we first select the support uniformly at random and then generate the corresponding values independently by the standard normal distribution @xmath228 . the omp algorithm is used to reconstruct the @xmath1-sparse input signals from the compressed measurements and the results are averaged over 5000 runs for each sparsity @xmath1 . for the gaussian random matrix each entry is chosen _ i.i.d . _ from @xmath228 .",
    "the percentages of perfect recovery of both the proposed matrix ( red line ) and the corresponding gaussian random matrix ( blue line ) with the same size are shown in figures for comparisons .      from theorem",
    "[ thm1 ] and theorem [ thm2 ] , the two types of finite geometry measurement matrices have relatively large sparks and thus we expect them to perform well under the omp . for the type - i finite geometry measurement matrix , we expect to recover at least @xmath229-sparse signals ; while for the type - ii finite geometry measurement matrix , we expect to recover at least @xmath230-sparse signals .",
    "[ example1 ] let @xmath231 and @xmath232 .",
    "the @xmath233 consists of @xmath234 3-flats and @xmath235 1-flats .",
    "let @xmath20 be the incidence matrix of 3-flat over 1-flat in @xmath233 .",
    "then @xmath20 is a @xmath236 type - i euclidean geometry measurement matrix .",
    "@xmath20 has girth 4 and is @xmath35-regular , where @xmath237 and @xmath238 .",
    "moreover , @xmath239 according to theorem [ thm1 ] . from fig .",
    "[ figeg4213 ] , it is easy to find that the performance of the proposed matrix is better than that of the gaussian random matrix . in particular , for all signals with sparsity order @xmath240 the recovery are perfect .",
    "this example shows that some girth 4 matrices from finite geometry could also perform very well .     with @xmath241 and the corresponding gaussian random matrix.,scaledwidth=50.0% ]     with @xmath242 and the corresponding gaussian random matrix.,scaledwidth=50.0% ]    [ example2 ]",
    "let @xmath243 and @xmath244 .",
    "the @xmath245 consists of @xmath246 lines and @xmath247 points and @xmath20 is the @xmath248 incidence matrix of line over point in @xmath245 .",
    "then @xmath82 is an @xmath249 type - ii projective geometry measurement matrix .",
    "@xmath82 has girth 6 and is @xmath35-regular , where @xmath250 and @xmath251 .",
    "moreover , @xmath252 by theorem [ thm2 ] . it is observed from fig .",
    "[ figpg3401 ] that @xmath82 performs better than the gaussian random matrix , and the sparsity order with exact recovery may exceed the one ensured by the proposed lower bound .",
    "for @xmath253 , exact recovery is obtained and the corresponding points are not plotted for clear comparisons , and the similar methods are used in the following figures .     with @xmath242 and the corresponding gaussian random matrix .",
    "the step size of @xmath1 is 4.,scaledwidth=50.0% ]    let @xmath254 , @xmath255 , @xmath256 , and @xmath226 .",
    "the @xmath257 consists of @xmath258 lines and @xmath259 points , and @xmath20 is the @xmath260 incidence matrix of line over point in @xmath257 .",
    "then @xmath82 is a type - ii euclidean geometry measurement matrix .",
    "@xmath82 has girth 6 and is @xmath35-regular , where @xmath261 and @xmath262 .",
    "moreover , @xmath263 by theorem [ thm2 ] . note that the step size of sparsity order @xmath1 is 4 .     with @xmath264 and the corresponding gaussian random matrix .",
    "the step size of @xmath1 is 6.,scaledwidth=50.0% ]    let @xmath254 , @xmath265 , @xmath266 , and @xmath267 .",
    "the @xmath268 consists of @xmath269 2-flats and @xmath270 1-flats .",
    "let @xmath20 be the @xmath271 incidence matrix of 2-flat over 1-flat in @xmath268 .",
    "then @xmath20 is a type - i euclidean geometry measurement matrix .",
    "@xmath20 has girth 6 and is @xmath35-regular , where @xmath272 and @xmath273 .",
    "moreover , @xmath274 by theorem [ thm1 ] .",
    "[ figeg3812 ] shows that some matrices from finite geometry have very good performance for the moderate length of input signals ( about 5000 ) .",
    "parallel structure of euclidean geometry is very useful to obtain various measurement matrices .",
    "next , we show how to puncture rows or columns from the incidence matrix @xmath20 or @xmath82 by several examples .",
    "[ example - parallel-256 ] let @xmath275 and @xmath244 .",
    "the euclidean plane @xmath276 consists of @xmath277 points and @xmath278 lines .",
    "let @xmath20 be the @xmath76 incidence matrix . since @xmath74 is close to @xmath26 , both @xmath20 and @xmath279 are not suitable to be measurement matrices directly .",
    "however , according to the the parallel structure of @xmath20 described in section [ fgldpc ] , all the 272 lines can be divided into @xmath280 parallel bundles and each bundle consists of 16 lines . by ( [ hpara ] ) , @xmath281 , where for @xmath282 , @xmath94 consists of the 16 lines in the @xmath80-th parallel bundle . by choosing the first @xmath36 submatrices @xmath94 , we get an @xmath22 measurement matrix with uniform column weight @xmath36 .    fig .",
    "[ figpara256 ] shows the performance of the @xmath283 , @xmath284 , @xmath285 , @xmath286 submatrices of @xmath20 which correspond to the first 4 , 5 , 6 and 7 parallel bundles of lines in @xmath287 , respectively .     with @xmath242 and their corresponding gaussian random matrices .",
    "the rows of the 4 submatrices from left to right are chosen according to the first 4 , 5 , 6 and 7 parallel bundles of lines in @xmath287 , respectively .",
    "the step size of @xmath1 is 2.,scaledwidth=50.0% ]    from fig .",
    "[ figpara256 ] we can see that all of the proposed submatrices perform better than their corresponding gaussian random matrices , and the more parallel bundles are chosen , the better the submatrix performs , and its gain over the corresponding gaussian random matrix becomes larger .",
    "[ example - parallel-1024 ] let @xmath288 and @xmath244 .",
    "the euclidean plane @xmath289 consists of @xmath290 points and @xmath291 lines .",
    "let @xmath20 be the @xmath76 incidence matrix .",
    "all the 1056 lines can be divided into @xmath292 parallel bundles and each bundle consists of 32 lines . by ( [ hpara ] ) , @xmath293 , where @xmath94 consists of the 32 lines in the @xmath80-th parallel bundle . by choosing the first @xmath36 parallel bundles , we get an @xmath22 measurement matrix with uniform column weight @xmath36 .",
    "[ figpara1024 ] shows the performance of the @xmath294 , @xmath295 , @xmath296 , @xmath297 submatrices of @xmath20 which correspond to the first 6 , 8 , 10 and 12 parallel bundles of lines in @xmath298 , respectively . from fig .",
    "[ figpara1024 ] it is observed that all of the submatrices perform better than their corresponding gaussian random matrices , and the more parallel bundles are chosen , the better the submatrix performs , and its gain over the corresponding gaussian random matrix becomes larger .     with @xmath242 and their corresponding gaussian random matrices .",
    "the rows of the 4 submatrices from left to right are chosen according to the first 6 , 8 , 10 and 12 parallel bundles of lines in @xmath298 , respectively .",
    "the step size of @xmath1 is 8.,scaledwidth=50.0% ]     and their corresponding gaussian random matrices , where @xmath299 is the @xmath300 submatrix of @xmath20 in example 6 .",
    "the 4 submatrices ( the red lines from left to right ) are obtained by deleting 0 , 128 , 256 , 384 columns of @xmath299 , respectively .",
    "the step size of @xmath1 is 4.,scaledwidth=50.0% ]    [ example - parallel-1024-del ] consider the @xmath300 submatrix in @xmath301 , say @xmath299 , in the last example .",
    "we will puncture its columns to obtain more measurement submatrices . recall that @xmath293 and the first 10 submatrices are chosen to obtain @xmath302 . for the fixed submatrix @xmath303 ,",
    "its corresponding 32 lines are paralleled to each other and partition the geometry .",
    "hence , when selecting the first @xmath79 lines from @xmath303 , the points on these @xmath79 lines are different pairwise and the total number of points is @xmath304 since each line contains 32 points . by deleting the @xmath304 columns corresponding to these @xmath304 points from @xmath299",
    ", we obtain a @xmath305 submatrix , where is still regular .    the 4 red lines from left to right in fig .",
    "[ figpara1024-del ] show the performance of the @xmath296 , @xmath306 , @xmath307 , @xmath308 submatrices of @xmath299 which correspond that @xmath309 , respectively .",
    "it is observed that all of the submatrices perform better than their corresponding gaussian random matrices ( the 4 blue lines from left to right ) , but its gain becomes slightly smaller when more columns are deleted .",
    "in this paper , by drawing methods and results from ldpc codes , we study the performance evaluation and deterministic constructions of binary measurement matrices .",
    "the spark criterion is used because its similarity to the stopping distance of an ldpc code and the fact that a matrix with large spark may perform well under the approximate algorithms of @xmath2-optimization , e.g. , the well - known omp algorithm .",
    "lower bounds of spark were proposed for real matrices in @xcite many years ago . when the real matrices are changed to binary matrices , better results may emerge .",
    "firstly , two lower bounds of spark are obtained for general binary matrices , which improve the one derived from @xcite in most cases .",
    "then , we propose two classes of deterministic binary measurement matrices based on finite geometry .",
    "one class is the incidence matrix @xmath20 of @xmath66-flat over @xmath69-flat in finite geometry @xmath59 or its transpose @xmath82 , which are called respectively the type i or type ii finite geometry measurement matrix .",
    "the other class is the submatrices of @xmath20 or @xmath82 , especially those obtained by deleting row parallel bundles or column parallel bundles from @xmath20 or @xmath82 in euclidean geometry . in this way",
    ", we could construct a large amount of measurement matrices with various sizes .",
    "moreover , most of the proposed matrices have cyclic or quasi - cyclic structure @xcite which make the hardware realization convenient and easy . for the type i or ii finite geometry measurement matrix , two further improved lower bounds of spark are given to show their relatively large spark .",
    "finally , a lots of simulations are done according standard and comparable procedures .",
    "the simulation results show that in many cases the proposed matrices perform better than gaussian random matrices under the omp algorithm .",
    "the future works may include giving more lower or upper bounds of sparks for general binary measurement matrices , determining the exact value of sparks for some classes of measurement matrices , and constructing more measurement matrices with large sparks .",
    "we only need to show the necessity .",
    "clearly , the measurement matrix @xmath15 does not have an all-0 column , which implies that @xmath311 .",
    "assume the contrary that @xmath312 .",
    "select a @xmath313 such that @xmath314 .",
    "let @xmath315 , where @xmath316 is the floor function .",
    "then @xmath317 let @xmath318 be the @xmath319-th non - zero position of @xmath110 and set @xmath320 let @xmath321 . clearly , @xmath322 in other words , both @xmath7 and @xmath323 are @xmath1-sparse vectors , and @xmath323 may be sparser .",
    "however , since @xmath324 , we have that @xmath325 which implies that @xmath7 can not be exactly recovered by the @xmath9-optimization ( [ l0 ] ) .",
    "this finishes the proof .",
    "it is known @xcite that any @xmath1-sparse signal @xmath7 can be exactly recovered by the @xmath12-optimization ( [ l1 ] ) if and only if @xmath15 satisfies the so - called _ nullspace property _ , or for any @xmath111 and any @xmath326 with @xmath327 , @xmath328 where @xmath329 .",
    "assume the contrary that @xmath312 . by selecting a @xmath313 such that @xmath314",
    ", it is easy to see that @xmath107 does not satisfy ( [ kspcon1 ] ) for some @xmath1-subset @xmath91 , e.g. , letting @xmath91 be the set of positions with the largest @xmath1 @xmath330 s .",
    "this leads to a contradiction , which implies the conclusion .",
    "99 e. j. cand@xmath331s , j. romberg , and t. tao , `` robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information , '' _ ieee trans .",
    "inf . theory _ ,",
    "2 , pp . 489509 , feb . 2006 .",
    "w. xu and b. hassibi , `` compressed sensing over the grassmann manifold : a unified analytical framework , '' in _ proc .",
    "46th allerton conf .",
    "commun . , control , comput .",
    "_ , monticello , il , sep .",
    "2008 , pp . 562567 .",
    "m. stojnic , w. xu , and b. hassibi , `` compressed sensing - probabilistic analysis of a null - space characterization , '' in _ proc .",
    "acoust . , speech signal process _ , lasvegas , nv , mar.31-apr.4 , 2008 , pp .",
    "33773380 .",
    "l. applebauma , s. d. howardb , s. searlec , and r. calderbank , `` chirp sensing codes : deterministic compressed sensing measurements for fast recovery , '' _ appl .",
    "2 , pp . 283290 , mar .",
    "m. a. iwen , `` simple deterministically constructible rip matrices with sublinear fourier sampling requirements , '' in _ proc .",
    "information sciences and systems _ , baltimore , md , usa , 2009 , pp . 870875 .",
    "s. d. howard , a. r. calderbank , and s. j. searle , `` a fast reconstruction algorithm for deterministic compressive sensing using second order reed - muller codes , '' in _ proc .",
    "information sciences and systems _ , princeton , nj , usa , 2008 , pp . 1115 .                        n. kashyap and a. vardy , `` stopping sets in codes from designs , '' in _ proc .",
    "inf . theory _",
    ", yokohama , japan , june 29-july 4 , 2003 , p. 122 .",
    "the full version is available online via http://www.mast.queensu.ca/  nkashyap / papers / stopsets.pdf ."
  ],
  "abstract_text": [
    "<S> for a measurement matrix in compressed sensing , its spark ( or the smallest number of columns that are linearly dependent ) is an important performance parameter . the matrix with spark greater than @xmath0 guarantees the exact recovery of @xmath1-sparse signals under an @xmath2-optimization , and the one with large spark may perform well under approximate algorithms of the @xmath2-optimization . </S>",
    "<S> recently , dimakis , smarandache and vontobel revealed the close relation between ldpc codes and compressed sensing and showed that good parity - check matrices for ldpc codes are also good measurement matrices for compressed sensing . by drawing methods and results from ldpc codes </S>",
    "<S> , we study the performance evaluation and constructions of binary measurement matrices in this paper </S>",
    "<S> . two lower bounds of spark are obtained for general binary matrices , which improve the previously known results for real matrices in the binary case . </S>",
    "<S> then , we propose two classes of deterministic binary measurement matrices based on finite geometry . </S>",
    "<S> two further improved lower bounds of spark for the proposed matrices are given to show their relatively large sparks . </S>",
    "<S> simulation results show that in many cases the proposed matrices perform better than gaussian random matrices under the omp algorithm .    compressed sensing ( cs ) , measurement matrix , @xmath2-optimization , spark , binary matrix , finite geometry , ldpc codes , deterministic construction . </S>"
  ]
}