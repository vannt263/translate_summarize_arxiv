{
  "article_text": [
    "the last twenty years have witnessed a rapid growth of _ graphical models _ in the fields of artificial intelligence and statistics .",
    "these models combine graphs and probability to address complex multivariate problems in a variety of domains , such as medicine , finance , risk analysis , defence , and environment , to name just a few .",
    "much has been done also on the front of imprecise probability . in particular , _ credal nets _ @xcite",
    "have been and still are the subject of intense research .",
    "a credal net creates a global model of a domain by combining local uncertainty models using some notion of independence , and then uses this to do inference .",
    "the local models represent uncertainty by closed convex sets of probabilities , also called _",
    "credal sets_.    the notion of independence used with credal nets in the vast majority of cases is that of _ strong independence _ ( with some exceptions in @xcite ) .",
    "loosely speaking , two variables @xmath0 are strongly independent if the credal set for @xmath1 can be regarded as originating from a number of precise models in each of which @xmath2 and @xmath3 are stochastically independent .",
    "strong independence is closely related to the _ sensitivity analysis _",
    "interpretation of credal sets , which regards an imprecise model as arising out of partial ignorance of a precise one .    in the particular case of credal nets ,",
    "strong independence leads to a mathematical equivalence : a credal net model is equivalent to a model consisting of a set of bayesian nets , each with the same graph but with different values for the parameters .",
    "the sensitivity analysis interpretation is then that there is some ( kind of ideal ) bayesian net model of the problem under consideration , and the graph of such a net is known .",
    "but , for some reason , the net s parameters are not known precisely , and that is why one considers the set of all the bayesian nets that are consistent with the partial specification of the parameters .",
    "common causes for the existence of partial knowledge are the cost of , and time constraints on , eliciting parameters , and disagreement amongst a group of experts consulted for that purpose .",
    "non - ignorable missing data can be another reason , in case the parameters are inferred from a data set @xcite .",
    "the sensitivity analysis interpretation of imprecise - probability models , and hence strong independence , is not always applicable .",
    "a notable case arises when one wishes to model an expert s beliefs : it is then not always tenable that there should be some ideal bayesian net that models these beliefs , and that it is only because of our limited resources that we can not define it precisely .",
    "rather , it seems more reasonable to concede that expert knowledge may be _ inherently _ imprecise to some extent .",
    "this simple observation makes the sensitivity analysis interpretation fail , and hence it makes strong independence an inadequate model , in general , for such a situation .",
    "an alternative and attractive approach to expressing irrelevance that is not committed to the sensitivity analysis interpretation is offered by _ epistemic irrelevance _",
    "@xcite : we say that @xmath2 is epistemically irrelevant to @xmath3 if observing @xmath2 does not affect our beliefs about @xmath3 .",
    "in other words , by making an epistemic irrelevance assessment , a subject states that her belief model about @xmath3 does ( or will ) not change after receiving information about @xmath2 .",
    "when the belief model is a precise probability , both epistemic irrelevance and strong independence reduce to the usual ( stochastic ) independence .",
    "but when the model is a set of probabilities , this is no longer the case , because in contradistinction with strong independence , epistemic irrelevance is a property _ of this set _ that can not be explained using properties of the precise probabilities in the set .",
    "epistemic irrelevance is defined directly in terms of a subject s belief model ( the set of probabilities ) .",
    "for this reason , it is very well suited for a behavioural theory of imprecise probability .",
    "contrary to strong independence , it is not a symmetrical notion : generally speaking , the epistemic irrelevance of @xmath2 to @xmath3 does not entail the epistemic irrelevance of @xmath3 to @xmath2 .",
    "it is also weaker than strong independence , in the sense that strong independence implies epistemic irrelevance : sets of probabilities that correspond to assessments of epistemic irrelevance usually include those related to strong independence assessments .",
    "it therefore does not lead to overconfident inferences when the sensitivity analysis interpretation is not justified .    at this point",
    ", the question we address in this paper should be clear : can we define credal nets based on epistemic irrelevance , and moreover create an exact algorithm to perform efficient inferences with them ?",
    "we give a fully positive answer to this question in the special case that    the graph under consideration is a directed tree , and    the related variables assume finitely many values .    the intuitions that showed us the way towards this result originated in previous work done by some of us on imprecise probability trees @xcite and imprecise markov chains @xcite .",
    "how do we address this problem ?    in section  [ sec :",
    "markov - trees ] , we discuss some preliminary graph - theoretic notions , and define the local uncertainty models that will be used at each node of a tree .",
    "these models are formalised through the language of _ coherent lower previsions _",
    "we discuss how such local models will give rise to a global uncertainty model , which plays the same role as the joint mass function built by the chain rule in a bayesian net .",
    "based on the global model , we state the markov condition that defines the imprecise - probability interpretation of our credal trees . as announced before",
    ", this markov condition involves epistemic irrelevance rather than strong independence .    in section  [ sec : independent - natural - extension ] , we take a brief detour to discuss in general terms how to combine marginal models into joint ones using irrelevance assessments , in a way that is as conservative as possible .",
    "we do so because the notion of so - called _ epistemic independence _ , which arises out of a symmetrisation of epistemic irrelevance , has so far been defined in the literature only for the case of two variables .",
    "we define and discuss the _ independent natural extension _ of a number of marginals .",
    "this is the most conservative joint model that arises out of the marginals and epistemic independence alone .",
    "moreover , we show that the independent natural extension has a very important _ strong factorisation _ property , which has a crucial part in our algorithm for updating credal trees under epistemic irrelevance .    in section  [ sec : joint ]",
    ", we turn to the problem of constructing the most conservative global model based only on the local models in the tree and our markov condition .",
    "we show that this task can be achieved by a recursive construction that proceeds from the leaves to the root of the tree using two operations : the _ independent natural extension _ discussed in section  [ sec : independent - natural - extension ] , and the _ marginal extension _ , defined and studied in @xcite .",
    "we also show that all uncertainty models we consider , the local ones as well as the global ones that we create , satisfy a consistency criterion that generalises ( and is based on the same ideas as ) the usual consistency criterion in bayesian nets : they are ( separately and jointly ) _ coherent _ @xcite ( see in particular ( * ? ? ?",
    "* section  8.1 ) ) .",
    "this is an important rationality requirement .",
    "we briefly comment on some of the graphical separation criteria induced by epistemic irrelevance in section  [ sec : separation ] .",
    "we then go on to develop and justify an algorithm for making inferences on credal trees under epistemic irrelevance in section  [ sec : algorithm ] .",
    "the algorithm is used to _ update _ the tree : it computes posterior beliefs about a _ target _",
    "variable in the tree conditional on the observation of other variables , which are called _ instantiated _ , meaning that their value is determined .",
    "it can in particular be used for treating the model as an expert system .",
    "our algorithm is based on message passing , as are the traditional algorithms that have been developed for precise graphical models .",
    "it has some remarkable properties :    it works in time linear in the number of nodes in the tree ;    it natively computes posterior lower and upper _ previsions _ ( or expectations ) rather than probabilities ;    it is the first algorithm developed for credal nets that exclusively uses the formalism of coherent lower previsions ; and    it is shown that , under very mild conditions , using the tree for updating beliefs can not lead to inferences that are inconsistent with the local models we have started from , nor with one another .    we give a step - by - step example of the way inferences can be done using our algorithm in section  [ sec : example ] .",
    "we also comment there on the intriguing relationship between the failure of certain classical separation properties in our framework , and dilation @xcite .",
    "the last part of the paper focuses on numerical simulations . in section  [ sec : comparison ]",
    "we empirically measure the amount of imprecision introduced by using epistemic irrelevance rather than strong independence in a credal tree , when propagating inferences backwards ( towards the root ) from instantiated nodes to the target node .",
    "indeed , it can be shown @xcite that there is _ no difference _ between inferences that go forward from instantiated nodes to the target node under strong independence and epistemic irrelevance . in section  [ sec : application ] we present an application of our algorithm to on - line character recognition .",
    "we learn the probabilities from data and compare the predictions of our approach with those of its precise probability counterpart .",
    "the results are encouraging : they show that the tree can be used for real applications , and that the imprecision it originates is justified .    in order to keep this paper reasonably short",
    ", we have to assume the reader has a good working knowledge of the basics of peter walley s @xcite theory of coherent lower previsions .",
    "this is needed in particular for the most important proofs , collected in the appendix . for a fairly detailed discussion of the coherence notions and results needed in the context of this paper",
    ", we refer to recent work by enrique miranda @xcite .",
    "we consider a rooted and directed discrete tree with finite width and depth .",
    "we call @xmath4 the set of its nodes @xmath5 , and we denote the _ root _ , or initial , node by @xmath6 . for any node @xmath5 , we denote its _ mother node _ by @xmath7 .",
    "of course , @xmath6 has no mother node , and we use the convention @xmath8 .",
    "also , for each node @xmath5 , we denote the set of its _ children _ by @xmath9 , and the set of its _ siblings _ by @xmath10 . clearly , @xmath11 , and if @xmath12 then @xmath13 . if @xmath14 , then we call @xmath5 a _ leaf _ , or _ terminal node_. we denote by @xmath15 the set of all non - terminal nodes .    for nodes @xmath5 and @xmath16 , we write @xmath17 if _",
    "@xmath5 precedes @xmath16 _ , i.e. , if there is a directed segment in the tree from @xmath5 to @xmath16 .",
    "the relation @xmath18 is a special partial order on the set @xmath4 .",
    "@xmath19 denotes the chain of _ ancestors _ of @xmath5 , and @xmath20 its set of _",
    "descendants_. here @xmath21 means that @xmath17 and @xmath22 .",
    "we also use the notation @xmath23 for the chain ( segment ) connecting @xmath6 and @xmath5 , and @xmath24 for the sub - tree with root @xmath5 .",
    "similarly , we let @xmath25 and @xmath26 for any subset @xmath27 . for any node @xmath5 ,",
    "its set of non - parent non - descendants is given by @xmath28 .    with each node @xmath5 of the tree ,",
    "there is associated a variable @xmath29 assuming values in a non - empty finite set @xmath30 .",
    "we denote by @xmath31 the set of all real - valued maps ( also called _ gambles _ ) on @xmath30 .",
    "we extend this notation to more complicated situations as follows .",
    "if @xmath32 is any subset of @xmath4 , then we denote by @xmath33 the tuple of variables whose components are the @xmath29 for all @xmath34 .",
    "this new joint variable assumes values in the finite set @xmath35 , and the corresponding set of gambles is denoted by @xmath36 . for any subset @xmath32 of @xmath4 , @xmath37",
    "is defined formally as the set of all maps @xmath38 of @xmath32 to @xmath39 , such that @xmath40 for all @xmath34 .",
    "so when @xmath41 , the empty product @xmath42 is defined as the set of all maps from @xmath43 to @xmath43 , which is a singleton . the corresponding variable @xmath44 can then only assume this single value , so there is no uncertainty about it .",
    "@xmath45 can be identified with the set @xmath46 of real numbers . ]",
    "generic elements of @xmath30 are denoted by @xmath47 or @xmath48 .",
    "similarly for @xmath38 and @xmath49 in @xmath37 . also ,",
    "if we mention a tuple @xmath49 , then for any @xmath50 , the corresponding element in the tuple will be denoted by @xmath51 .",
    "we assume all variables in the tree to be logically independent , meaning that the variable @xmath33 may assume _ all _ values in @xmath37 , for all @xmath52 .",
    "we will frequently use the simplifying device of identifying a gamble @xmath53 on @xmath37 with its _ cylindrical extension _ to @xmath54 , where @xmath55 .",
    "this is the gamble @xmath56 on @xmath54 defined by @xmath57 for all @xmath58 . to give an example , if @xmath59 , this trick allows us to consider @xmath60 as the set of those gambles in @xmath61 that depend only on the variable @xmath33 . as another example",
    ", this device allows us to identify the gambles @xmath62 and @xmath63 , and therefore also the events @xmath64 and @xmath65 .",
    "more generally , for any event @xmath66 , we can identify the gambles @xmath67 and @xmath68 , and therefore also the events @xmath69 and @xmath70 . in the same spirit ,",
    "a lower prevision on all gambles in @xmath36 can be identified with a lower prevision defined on the set of corresponding gambles on @xmath71 , a subset of @xmath72 .    throughout the paper ,",
    "we consider ( conditional ) lower previsions as models for a subject s beliefs about the values that certain variables in the tree may assume .",
    "we use a systematic notation for such ( conditional ) lower previsions .",
    "let @xmath73 be _ disjoint _ sets of nodes with @xmath74 , then we generically , we will also use the letters @xmath75 , @xmath76 and @xmath77 . ] denote by @xmath78 a _ conditional lower prevision _ , defined on the set of gambles @xmath79 . , we also allow @xmath80 , which means conditioning on the variable @xmath81 , which can only assume one single value .",
    "this means that @xmath82 effectively becomes an unconditional lower prevision on @xmath83 .",
    "this a very useful device that allows us to use the same generic notation for both conditional and unconditional lower previsions . ] for every gamble @xmath84 on @xmath85 and every @xmath86 , @xmath87 is the lower prevision ( or lower expectation , or a subject s supremum buying price ) for / of the gamble @xmath84 , conditional on the event that @xmath88 .",
    "we interpret @xmath89 as a real - valued map ( gamble ) on @xmath90 that assumes the value @xmath87 in the element @xmath91 of @xmath90 .",
    "the conjugate _",
    "conditional upper prevision _",
    "@xmath92 is defined on @xmath79 by @xmath93 for all gambles @xmath84 on @xmath85 .",
    "we will always implicitly assume that all conditional models @xmath78 we use are _ separately coherent _ , meaning that :    1 .",
    "[ item : separate : coherence : apg ] @xmath94 for all @xmath95 and all @xmath86 [ accepting partial gains ] ; 2 .   [",
    "item : separate : coherence : superadd ] @xmath96 for all @xmath97 and all @xmath86 [ super - additivity ] ; 3 .",
    "[ item : separate : coherence : nnhom ] @xmath98 for all @xmath95 , all non - negative real @xmath99 and all @xmath86 [ non - negative homogeneity ] .    by combining sc[item : separate : coherence : apg]sc[item : separate : coherence : nnhom ] , it follows that for all @xmath95 , @xmath86 and @xmath100 : @xmath101 if we let @xmath84 be the indicator @xmath102 of the set @xmath103 in these inequalities , they reduce to the following , intuitively obvious , property : , we denote @xmath104 also as @xmath105 and call this real number the ( conditional ) lower _ probability _ of @xmath69 . similarly @xmath106 is the ( conditional ) upper _ probability _ of @xmath69 . ]    1 .",
    "[ item : separate : coherence ] @xmath107 for all @xmath108 .    from sc[item",
    ": separate : coherence : apg ] , sc[item : separate : coherence : superadd ] and sc[item : separate : coherence ] we can also derive that , with obvious notations : @xmath109 where @xmath110 is a partial map defined on @xmath111 . this implies that @xmath78 is completely determined by its behaviour on ( cylindrical extensions of maps in ) @xmath112 .",
    "hereafter , we will frequently introduce conditional lower previsions of the type @xmath78 as if they are defined on @xmath112 , simply because that is a very natural thing to do : such a conditional lower prevision is usually interpreted as representing beliefs about the variable @xmath113 , conditional on values of the variable @xmath114 .",
    "but the reader should keep in mind that , by the separate coherence property  , @xmath78 can ( and should ) always be uniquely extended to the larger domain @xmath79 .",
    "as soon as we consider a number of such conditional lower previsions @xmath115 , @xmath116 , they should satisfy more stringent consistency criteria than that each of them should be separately coherent : they should also be consistent with one another in the sense of walley s _ ( joint ) coherence _ ( * ? ? ?",
    "* section  7.1.4(b ) ) . for more details about this much more involved type of coherence",
    ", we refer also to @xcite .",
    "finally , let us introduce one of the most important concepts for this paper , that of epistemic irrelevance .",
    "we describe the case of conditional irrelevance , as the unconditional version of epistemic irrelevance can easily be recovered as a special case .. as we indicated in footnote  [ fn : empty - product ] , this makes sure the variable @xmath117 has only one possible value , so conditioning on that variable amounts to not conditioning at all . ]    consider three disjoint subsets @xmath118 , @xmath119 , and @xmath120 of @xmath121 , where both @xmath119 and @xmath120 are non - empty .",
    "when a subject judges @xmath114 to be _ epistemically irrelevant to @xmath113 conditional on @xmath117 _ , he assumes that if he knows the value of @xmath117 , then learning in addition which value @xmath114 assumes in @xmath90 will not affect his beliefs about @xmath113 .",
    "more formally , assume that a subject has a separately coherent conditional lower prevision @xmath122 on @xmath112 .",
    "if he assesses @xmath114 to be epistemically irrelevant to @xmath113 conditional on @xmath117 , this implies that he can infer from his model @xmath122 a conditional model @xmath123 on @xmath112 given by @xmath124      we now add a _ local uncertainty model _ to each of the nodes @xmath5 .",
    "if @xmath5 is not the root node , i.e.  has a mother @xmath7 , then this local model is a ( separately coherent ) conditional lower prevision @xmath125 on @xmath31 : for each possible value @xmath126 of the variable @xmath127 associated with its mother @xmath7 , we have a coherent lower prevision @xmath128 for the value of @xmath29 , conditional on @xmath129 . in the root",
    ", we have an unconditional local uncertainty model @xmath130 for the value of @xmath131 .",
    "@xmath130 is a ( separately ) coherent lower prevision on @xmath132 .",
    "we use the common generic notation @xmath125 for all these local models .",
    "has only one possible value , so conditioning on that variable amounts to not conditioning at all . ]",
    "we intend to show in section  [ sec : joint ] how all these local models @xmath125 can be combined into _",
    "global uncertainty models_. we generically denote such global models using the letter @xmath75 .",
    "more specifically , we want to end up with an unconditional joint lower prevision @xmath133 on @xmath72 for all variables in the tree , as well as conditional lower previsions @xmath134 on @xmath135 for all non - terminal nodes @xmath5 and all non - empty @xmath136 .    in this list , the only item that needs more explanation concerns the markov - type conditions that the tree structure encodes .",
    "this is what we turn to now .      in classical bayesian nets ,",
    "the graphical structure is taken to represent the following assessments : for any node @xmath5 , conditional on its parent variables , its non - parent non - descendant variables are epistemically irrelevant to it ( and therefore also independent ) .    in the present context",
    ", we assume that the tree structure embodies the following conditional irrelevance assessment , which turns out to be equivalent with the conditional independence assessment above in the special case of a bayesian tree .    1 .",
    "consider any node @xmath5 in the tree , any subset @xmath32 of its set of children @xmath9 , and the set @xmath137 of their common non - parent non - descendants . then _",
    "conditional on the mother variable @xmath29 , the non - parent non - descendant variables @xmath138 are assumed to be epistemically irrelevant to the variables @xmath139 associated with the children in @xmath32 and their descendants . _",
    "this interpretation turns the tree into a _ credal tree under epistemic irrelevance _ , and we also introduce the term _ imprecise markov tree _ ( imt ) for it . for the global models we are considering here , ci has the following consequences .",
    "it implies that for all @xmath140 , all non - empty @xmath136 and all @xmath141 , we can infer from @xmath134 a model @xmath142 , where for all @xmath143 , with obvious notations : , the corresponding irrelevance condition is trivial , as the set @xmath9 of children of @xmath5 is empty . ]",
    "@xmath144 where @xmath145 denotes a partial map of @xmath84 , defined on @xmath146 .",
    "we discuss some of the separation properties that accompany this interpretation in section  [ sec : separation ] . for",
    "now , we focus on two immediate consequences that will help us go from local to global models in section  [ sec : joint ] .",
    "first , consider some node @xmath5 .",
    "then ci tells us that for any two children @xmath147 of @xmath5 , the variable @xmath148 is epistemically irrelevant to the variable @xmath149 , conditional on @xmath29 .",
    "+ = [ ->,semithick ] [ grow = down , level distance=30,sibling distance=25 ] child node @xmath148 child node @xmath150 child node @xmath149 ;    it even tells us that for any two disjoint non - empty sets @xmath151 and @xmath152 of children of @xmath5 , the variable @xmath153 is epistemically irrelevant to @xmath154 , conditional on @xmath29 . we conclude that , conditional on a node , all its children @xmath155 ( and the variables associated with their sub - trees @xmath156 ) are _ epistemically independent _",
    "* chapter  9 ) , in the specific sense to be discussed in the next section .",
    "next , consider some non - terminal node @xmath5 different from @xmath6 , and its mother variable @xmath127 .",
    "we infer from ci that this mother variable @xmath127 is epistemically irrelevant to the variable @xmath157 conditional on @xmath29 :    + = [ ->,semithick ] at ( 0,0 ) @xmath127 [ grow = down , level distance=30,sibling distance=25 ] child node @xmath29 child node @xmath148 child node @xmath150 child node @xmath158 ; at ( 3,-1 ) or equivalently , ; at ( 6,0 ) @xmath127 [ grow = down , level distance=30 ] child node @xmath29 child node @xmath157 ;",
    "let us make a small digression on epistemic independence , which will help us in our discussion further on .",
    "the material in this section is based on work that some of us have published elsewhere @xcite , and we refer to that paper for more details and proofs for the results mentioned in this section .",
    "suppose we have a number of ( separately ) coherent marginal lower previsions @xmath159 on @xmath160 representing beliefs about the values that each of a finite number of ( logically independent ) variables @xmath161 assume in the respective non - empty finite sets @xmath162 , @xmath163 , where @xmath121 is some non - empty finite set .",
    "we want to construct a joint lower prevision @xmath164 on @xmath165 , where @xmath166 , that coincides with the marginals @xmath159 on their respective domains @xmath160 , and such that this @xmath164 reflects the following structural assessments : for any disjoint proper subsets @xmath120 and @xmath119 of @xmath121 , the variables @xmath114 are epistemically irrelevant to the variables @xmath113 . in other words , learning the value of any number of these variables would not affect beliefs about the remaining variables .",
    "we then call the variables @xmath161 , @xmath163 , _ epistemically independent_.    generally speaking , such irrelevance assessments are useful because they allow us to turn unconditional into conditional lower previsions .",
    "in particular , for any disjoint proper subsets @xmath120 and @xmath119 of @xmath121 , we can use the epistemic irrelevance assessment of @xmath114 to @xmath113 to infer from the joint lower prevision @xmath164 a conditional lower prevision @xmath167 on @xmath168 given by : @xmath169 so we can use the symmetrised assessment of epistemic independence of the variables @xmath161 , @xmath163 to infer from @xmath164 the following family of conditional lower previsions : @xmath170 this idea leads to the definition of an independent product , which generalises the existing notion for ( precise ) probability models .",
    "[ def : independent : product ] a ( separately ) coherent lower prevision @xmath164 on @xmath165 that coincides with the marginal lower previsions @xmath159 on their domains @xmath160 , @xmath163 and that is coherent with the family of conditional lower previsions @xmath171 is called an _ _ independent product _ _ of these marginals @xmath159 .",
    "it turns out that there always is a point - wise smallest independent product :    [ prop : independent - factorising ] any collection of ( separately ) coherent lower previsions @xmath159 on @xmath160 , @xmath163 , has a point - wise smallest independent product .",
    "we call it their _ independent natural extension _ and denote it by @xmath172 .",
    "moreover , @xmath172 is a strongly factorising coherent lower prevision on @xmath165 .",
    "strong factorisation is strongly linked with independent products , and will play a crucial part in our development of an algorithm for updating an imprecise markov tree in section  [ sec : algorithm ] .",
    "it is defined as follows :    we call a ( separately ) coherent lower prevision @xmath164 on @xmath165 _ strongly factorising _ if for all disjoint proper subsets @xmath120 and @xmath119 of @xmath121 , all @xmath173 and all non - negative @xmath174 , @xmath175 .    as another important example , the so - called _ strong product",
    "_ @xmath176 @xcite of marginal lower previsions @xmath159 is strongly factorising .    as a consequence of the separate coherence of the joint lower prevision @xmath164 ,",
    "the right - hand side of the equality in this definition can be rewritten as : @xmath177 which explains where the term ` factorising ' comes from .",
    "in particular , for any ( separately ) coherent strongly factorising joint lower prevision @xmath164 , we see that for any partition @xmath178 ,  , @xmath179 of @xmath121 : @xmath180 where @xmath181 for @xmath182 .",
    "the independent natural extension has very interesting and non - trivial _ marginalisation and associativity properties_. consider any non - empty subset @xmath77 of @xmath121 , then the independent natural extension @xmath183 of the marginals @xmath184 , @xmath185 coincides with the restriction of @xmath172 to the set of gambles @xmath186 : @xmath187 moreover , for any partition @xmath178 and @xmath188 of @xmath121 , we have that @xmath189 so @xmath172 is the independent natural extension of its @xmath190-marginal @xmath191 and its @xmath192-marginal @xmath193 .      as a next step ,",
    "suppose we want to condition a separately coherent and strongly factorising joint @xmath164 on observations of the type @xmath194 , where @xmath119 is some proper subset of @xmath121 . in other words , we want to find conditional lower previsions @xmath167 on @xmath195 that are ( jointly ) coherent with the joint lower prevision @xmath164 .",
    "to this end , we calculate the so - called _ regular extension _ as follows .",
    "consider @xmath196 in @xmath90 .",
    "when @xmath197 , @xmath198)\\geq0\\}},\\ ] ] where @xmath120 is any non - empty subset of @xmath199 and @xmath200 is any gamble on @xmath201 .",
    "when @xmath202 , @xmath203 is _ vacuous _ , meaning that @xmath204 for all gambles @xmath200 on @xmath201 .    generally speaking , coherence only determines @xmath205 uniquely if @xmath206 , and in that case regular extension yields this uniquely coherent conditional lower prevision : @xmath207 .",
    "when @xmath208 , regular extension is still coherent , and it even still characterises the coherent @xmath205 , because these all lie between the vacuous lower prevision and @xmath209 . for more details about this regular extension , we refer to ( * ? ? ?",
    "* appendix  j ) and ( * ? ? ?",
    "* section  4 ) .",
    "if the joint @xmath164 is strongly factorising , we get : @xmath210 )    & = { \\underline{p}_{n}}({{\\mathbb{i}_{\\{{x_{i}}\\}}}}{\\underline{p}_{n}}(h({x_{i}},\\cdot)-\\mu))\\\\    & =    \\begin{cases }      { \\underline{p}_{n}}({{\\{{x_{i}}\\}}})[{\\underline{p}_{n}}(h({x_{i}},\\cdot))-\\mu ]      & \\text { if $ { \\underline{p}_{n}}(h({x_{i}},\\cdot))\\geq\\mu$}\\\\      { \\overline{p}_{n}}({{\\{{x_{i}}\\}}})[{\\underline{p}_{n}}(h({x_{i}},\\cdot))-\\mu ]      & \\text { if $ { \\underline{p}_{n}}(h({x_{i}},\\cdot))\\leq\\mu$ } ,    \\end{cases}\\end{aligned}\\ ] ] so we conclude that , quite interestingly , @xmath211 in other words , the conditional lower previsions found by regular extension of a strongly factorising joint satisfy all epistemic irrelevance conditions present in an assessment of epistemic independence . we shall have occasion to use this idea several times in the course of this paper , especially in the proofs .      to end this section , we generalise the notion of an independent product to that of a conditionally independent product . in this case",
    "we have a number of ` marginal ' conditional lower previsions @xmath212 on @xmath160 representing beliefs ( conditional on a variable @xmath213 in a finite set @xmath214 ) about the values that each of a finite number of ( logically independent ) variables @xmath161 assume in the respective non - empty finite sets @xmath162 , @xmath163 .",
    "we want to construct a conditional lower prevision @xmath215 on @xmath165 , where @xmath166 , that coincides with the marginal conditional lower previsions @xmath212 on their respective domains @xmath160 , and such that this @xmath215 reflects the following structural assessments : for any disjoint proper subsets @xmath120 and @xmath119 of @xmath121 , the variables @xmath114 are epistemically irrelevant to the variables @xmath113 , _ conditional on @xmath213_. in other words , if the value of @xmath213 was known , then learning the value of any number of these variables would not affect beliefs about the remaining variables .",
    "we then call the variables @xmath161 , @xmath163 _ epistemically independent , conditional on @xmath213_.    generally speaking , such conditional irrelevance assessments are useful because they allow us to turn lower previsions conditional on @xmath213 alone into other , more involved conditional lower previsions . in particular , for any disjoint proper subsets @xmath120 and @xmath119 of @xmath121 , we can use the epistemic irrelevance assessment of @xmath114 to @xmath113 conditional on @xmath213 to infer from the joint lower prevision @xmath215 a conditional lower prevision @xmath216 on @xmath168 [ or equivalently on @xmath217 given by : @xmath218 so we can use the symmetrised assessment of epistemic independence of the variables @xmath161 , @xmath163 conditional on @xmath213 to infer from the @xmath215 the following family of conditional lower previsions : @xmath219 this idea leads to the definition of a conditionally independent product .",
    "[ def : conditionally : independent : product ] a ( separately ) coherent conditional lower prevision @xmath215 on @xmath165 that coincides with the ` marginal ' conditional lower previsions @xmath212 on their domains @xmath160 , @xmath163 and that is coherent with the family of conditional lower previsions @xmath220 is called a _ conditionally independent product _ of these marginals @xmath212 .",
    "it turns out that there always is a point - wise smallest conditionally independent product :    [ prop : conditionally : independent - factorising ] any collection of ( separately ) coherent conditional lower previsions @xmath212 on @xmath160 , @xmath163 , has a point - wise smallest conditionally independent product .",
    "we call it their _ conditionally independent natural extension _ and denote it by @xmath221 .",
    "the notation we use for the conditionally independent natural extension is appropriately suggestive : for each @xmath222 in @xmath214 , @xmath223 is indeed the independent natural extension of the marginal lower previsions @xmath224 .",
    "this implies that each @xmath223 is a strongly factorising coherent lower prevision on @xmath165 .",
    "we are now ready to go back to our discussion of imprecise markov trees .",
    "let us show how to construct specific global models for the variables in the tree , and argue that these are the most conservative coherent models that extend the local models and express all conditional irrelevancies  , encoded in the imprecise markov tree . in section  [ sec : algorithm",
    "] , we will use these global models to construct and justify an algorithm for updating the imprecise markov tree .",
    "the crucial step lies in the recognition that any tree can be constructed recursively from the leaves up to the root , by using basic building blocks of the following type :    + = [ ->,semithick ] = [ ->,thick , dotted , draw = blue!50 ] ( xm ) @xmath127 [ grow = down , level distance=30,sibling distance=25 ] child node ( xs ) @xmath29 child node ( xc1 ) @xmath148 child node ( xc2 ) @xmath149 child node ( dots ) @xmath150 child node ( xcn ) @xmath158 ; ( xsmodel ) @xmath125 ; ( xckmodel ) @xmath225 ; ( xs )  ( xsmodel ) ; ( xcn )  ( xckmodel ) ;    the global models are then also constructed recursively , following the same pattern . in",
    "what follows , we first derive the recursion equations for these global models in a heuristic manner . the real justification for using the global models thus derived is then given in theorem  [ theo : global - models ] .",
    "consider a node @xmath5 and suppose that , in each of its children @xmath226 , we already have a global conditional lower prevision @xmath227 on @xmath228 [ or equivalently , on @xmath229 .    given that , conditional on @xmath29 , the variables @xmath230",
    ", @xmath226 are epistemically independent [ see section  [ sec : graphical : interpretation ] , condition  ci ] , the discussion in section  [ sec : independent - natural - extension ] leads us to combine the ` marginals ' @xmath227 , @xmath226 into their point - wise smallest conditionally independent product ( conditionally independent natural extension ) @xmath231 , which is a conditional lower prevision @xmath232 on @xmath233 [ or equivalently , on @xmath234 :    + = [ ->,semithick ] = [ ->,thick , dotted , draw = blue!50 ] ( xm ) @xmath127 [ grow = down , level distance=30,sibling distance=25 ] child node ( xs ) @xmath29 child node ( xc ) @xmath157 ; ( xsmodel ) @xmath125 ; ( xcmodel ) @xmath235 ; ( xs )  ( xsmodel ) ; ( xc )  ( xcmodel ) ;    next , we need to combine the conditional models @xmath125 and @xmath232 into a global conditional model about @xmath236 . given that , conditional on @xmath29 , the variable @xmath127 is epistemically irrelevant to the variable @xmath157 [ see section  [ sec : graphical : interpretation ] , condition  ci ] , we expect @xmath237 and @xmath232 to coincide [ this is a special instance of eq .  ] .",
    "the most conservative ( point - wise smallest ) coherent way of combining the conditional lower previsions @xmath237 and @xmath125 consists in taking their _ _ marginal extension _ _ @xmath238 ;",
    "see @xcite for more details .",
    "graphically :    + = [ ->,semithick ] = [ ->,thick , dotted , draw = blue!50 ] ( xm ) @xmath127 [ grow = down , level distance=30,sibling distance=25 ] child node ( xs ) @xmath236 ; ( xsmodel ) @xmath239 ; ( xs )  ( xsmodel ) ;    summarising , and also accounting for the case @xmath240 , we can construct a global conditional lower prevision @xmath241 on @xmath242 by backwards recursion : @xmath243 for all @xmath140 .",
    "if we start with the ` boundary conditions ' @xmath244 then the recursion relations   and   eventually lead to the global joint model @xmath245 , and to the global conditional models @xmath232 for all non - terminal nodes  @xmath5 .",
    "for any subset @xmath136 , the global conditional model @xmath134 can then be defined simply as the restriction of the model @xmath232 on @xmath233 to the set @xmath135 : @xmath246 it follows from the discussion in section  [ sec : independent - natural - extension ] that , alternatively [ see eq .  ] , @xmath247 for easy reference , we will in what follows refer to this collection of global models as the _ family of global models @xmath248 , _ so @xmath249    we end this section by discussing a number of interesting properties for the family of global models @xmath248 we can derive in this way .",
    "let us call any real functional @xmath250 on @xmath251 _ strictly positive _ if @xmath252 for all @xmath253 .",
    "[ prop : global : positivity ] if all the local models @xmath254 , @xmath255 are strictly positive , then so are all the global models in @xmath248 .",
    "[ prop : global : positivity : too ] consider any non - empty subset @xmath256 of @xmath4 and any @xmath257 .",
    "if @xmath258 then also @xmath259 for all @xmath260 and all @xmath261 .",
    ", because then @xmath262 is a singleton [ see footnote  [ fn : empty - product ] ] whose upper probability should be @xmath263 by separate coherence . ]    before we formulate the most important result in this section ( and arguably , in this paper ) , we provide some motivation .",
    "suppose we have some family of global models @xmath264 associated with the tree .",
    "how do we express that such a family is compatible with the assessments encoded in the tree ?",
    "first of all , we require that our global models should extend the local models :    1 .",
    "[ item : global : local ] for each @xmath255 , @xmath125 is the restriction of @xmath265 to @xmath31 .",
    "the second requirement is that our models should satisfy the rationality requirement of coherence :    1 .",
    "[ item : global : coherence ] the ( conditional ) lower previsions in @xmath266 are jointly coherent .",
    "the third requirement requires more explanation : the global models should reflect all epistemic irrelevancies encoded in the graphical structure of the tree .",
    "naively , we would want condition   to be satisfied .",
    "the problem is that only the right - hand side in eq .",
    ", involving the model @xmath267 is directly available to us . to get to the left - hand side involving the model @xmath268 , one naive approach would be to ` condition the joint model @xmath269 on the variable @xmath270 ' .",
    "but we have seen in section  [ sec : indnatex ] that given a joint model , coherence in general only determines the conditional models uniquely , provided that the _ lower probability _ of the conditioning event is non - zero .",
    "this is a fairly strong condition , and in what follows we would generally prefer to work with the much weaker condition that the _ upper probability _ of the conditioning event is non - zero . with no positivity restrictions on the local models .",
    "we leave this as an avenue for future research , however . ] since in that case the left - hand side of eq .",
    "need not be uniquely determined from the joint @xmath271 by coherence , this approach becomes unfeasible .",
    "nevertheless , as soon as we realise that all we can reasonably require from our models is that they should be coherent , the right approach readily suggests itself : , as well as the one used in @xcite .",
    "it coincides with the usual , naive approach as soon as all the relevant conditional models are uniquely determined from the joint by coherence .",
    "] we should require that if we use the available models @xmath267 to _ define _ the models @xmath268 through the epistemic irrelevance condition  , then the result should still be coherent :    1 .",
    "[ item : global : irrelevance ] if we define the conditional lower previsions @xmath268 , @xmath140 , @xmath136 and @xmath272 through the epistemic irrelevance requirements @xmath273 then all these models together should be ( jointly ) coherent with all the available models in the family @xmath266 .",
    "and there is a final requirement , which guarantees that all inferences we make on the basis of our global models are as conservative as possible , and are therefore based on no other considerations than what is encoded in the tree :    1 .",
    "[ item : global : smallest ] the models in the family @xmath266 are dominated ( point - wise ) by the corresponding models in all other families satisfying requirements  t[item : global : local]t[item : global : irrelevance ] .    it turns out that the family of models @xmath248 we have been constructing above satisfy all these requirements .",
    "[ theo : global - models ] if all local models @xmath254 on @xmath31 , @xmath255 are strictly positive , then the family of global models @xmath248 , obtained through eqs .",
    " , constitutes the point - wise smallest family of ( conditional ) lower previsions that satisfy t[item : global : local]t[item : global : irrelevance ] .",
    "it is therefore the unique family to also satisfy t[item : global : smallest ] .",
    "finally , consider any non - empty set of nodes @xmath274 and the corresponding conditional lower prevision derived by applying regular extension : for any finite collection @xmath275 , @xmath116 of sets of nodes . ]",
    "@xmath276)\\ge0\\ } }      \\text { for all $ f\\in{\\mathcal{l}({\\mathcal{x}_{t}})}$ and all $ { x_{e}}\\in{\\mathcal{x}_{e}}$}.\\ ] ] then the conditional lower prevision @xmath277 is ( jointly ) coherent with the global models in the family @xmath248 .",
    "the last statement of this theorem guarantees that if we use regular extension to _ update the tree _",
    "given evidence @xmath278 , i.e. , derive conditional models @xmath279 from the joint model @xmath280 , such inferences will always be coherent .",
    "this is of particular relevance for the discussion in section  [ sec : algorithm ] , where we derive an efficient algorithm for updating the tree using regular extension .",
    "it implies in particular that our algorithm produces coherent inferences .",
    "without going into too much detail , we would like to point out some of the more striking differences between the separation properties in imprecise markov trees under epistemic irrelevance , and the more usual ones that are valid for bayesian nets @xcite , which , by the way , are also inherited from bayesian nets by credal nets under strong independence @xcite .",
    "it is clear from the interpretation of the graphical model described in section  [ sec : graphical : interpretation ] that we have the following simple separation results :    + = [ ->,semithick ] ( xi1 ) @xmath281 [ grow = right , sibling distance=25 ] child node ( xi2 ) @xmath282 child node ( xt ) @xmath283 ;    + = [ ->,semithick ] ( xi2 ) @xmath282 child[grow = left , sibling distance=25 ] node ( xi1 ) @xmath281 child[grow = right , sibling distance=25 ] node ( xt ) @xmath283 ;    where in both cases , _ @xmath282 separates @xmath283 from @xmath281 _ : when the value of @xmath282 is known , additional information about the value of @xmath281 does not affect beliefs about the value of @xmath283 . in this figure , between @xmath284 and @xmath285 , and between @xmath285 and @xmath16",
    ", there may be other nodes , but the arrows along the path segment through these nodes should all point in the indicated directions .",
    "the underlying idea is that @xmath16 is a ( descendant of some ) child @xmath155 of @xmath285 , and conditional on the mother @xmath285 of @xmath155 , the non - parent non - descendant @xmath284 of @xmath155 is epistemically irrelevant to @xmath155 and all of its descendants .    on the other hand , and in contradistinction with what we are used to in bayesian nets",
    ", we will not generally have separation in the following configuration :    + = [ < -,semithick ] ( xi1 ) @xmath281 [ grow = right , sibling distance=25 ] child node ( xi2 ) @xmath282 child node ( xt ) @xmath283 ;    where _",
    "@xmath282 does not necessarily separate @xmath283 from @xmath281_. we will come across a simple counterexample in section  [ sec : example ] .",
    "where does this difference with the case of bayesian nets originate ?",
    "it is clear from the reasoning above that @xmath282 separates @xmath281 from @xmath283 : conditional on @xmath282 , @xmath283 is epistemically irrelevant to @xmath281 . for precise probability models ,",
    "irrelevance generally implies symmetrical independence , and therefore this will generally imply that conditional on @xmath282 , @xmath281 is epistemically irrelevant to @xmath283 as well .",
    "but for imprecise probability models no such symmetry is guaranteed @xcite , and we therefore can not infer that , generally speaking , @xmath282 will separate @xmath281 from @xmath283 . _ as a general rule , we can only infer separation if the arrows point from the ` separating ' variable @xmath282 towards the ` target ' variable @xmath283 . _",
    "we now consider the case where we are interested in making inferences about the value of the variable @xmath283 in some _",
    "target node _ @xmath16 , when we know the values @xmath286 of the variables @xmath287 in a set @xmath288 of _ evidence nodes _ ; see for instance fig  [ fig : mtree ] .",
    "if we assume that the values of the remaining variables are _ missing at random _ , then we can do this by conditioning the joint @xmath289 obtained above on the available evidence ` @xmath278 ' ; see for instance @xcite .",
    "we will address this problem by updating the lower prevision @xmath289 to the lower prevision @xmath290 on @xmath291 using _ regular extension _",
    "* appendix  j ) : @xmath292)\\geq0\\}}\\ ] ] for all gambles @xmath293 on @xmath294 , _ assuming that @xmath258_. theorem  [ theo : global - models ] guarantees that such inferences are coherent .",
    "sufficient conditions on the local models for this positivity assumption to hold are given in proposition  [ prop : global : positivity ] .",
    "consider the map @xmath295).\\ ] ] we can infer from the separate coherence of @xmath289 that @xmath296 for all @xmath297 , which implies that @xmath298 is ( lipschitz ) continuous .",
    "separate coherence of @xmath289 also guarantees that @xmath298 is concave and non - increasing .",
    "hence @xmath299 $ ] , which shows that the supremum that we should have _ a priori _ used in   is indeed a maximum .",
    "@xmath300 is the right - most zero of @xmath298 , and it is , again by separate coherence of @xmath289 , guaranteed to lie between the smallest value @xmath301 and the largest value @xmath302 of @xmath293 .",
    "if moreover @xmath303 , then separate coherence of @xmath289 implies that @xmath300 is the unique zero of @xmath298 .",
    "if on the other hand @xmath304 , then @xmath305 $ ] is the set of all zeros of @xmath298 .",
    "it appears that any algorithm for calculating @xmath300 will benefit from being able to calculate the values of @xmath298 , or even more simply check their signs , efficiently .",
    "we now recall from section  [ sec : joint ] that the joint @xmath289 can be constructed recursively from leaves to root .",
    "the idea we now use is that calculating @xmath306)$ ] becomes easier if we graft the structure of the tree onto the argument @xmath307 $ ] as follows .",
    "define @xmath308 then @xmath309 and @xmath310 . also define , for any @xmath255 , the gamble @xmath311 on @xmath312 by @xmath313 . then @xmath314 and @xmath315 where we use the convention that any product over an empty set of indices equals one .",
    "is the argument counterpart of eq .  . also ,",
    "if @xmath316 then @xmath317 and @xmath311 do not depend on @xmath318 , nor on @xmath293 . indeed ,",
    "in that case @xmath319      we define the _ messages _ @xmath320 and @xmath321 recursively by @xmath322 we summarise such a pair by the notation : @xmath323 .",
    "then there are two possibilities : @xmath324{s }      & \\text { if $ s\\notin e$}.    \\end{cases}\\ ] ] the messages @xmath320 and @xmath321 are gambles on @xmath325 , and can therefore be seen as tuples of real numbers , with as many components @xmath326 as there are elements @xmath327 in @xmath325 .",
    "they are all non - negative .",
    "as their notation suggests , they do not depend on the choice of @xmath293 or @xmath318 , but only ( at most ) on which nodes are _ instantiated _ , i.e. , belong to @xmath256 , and on which value @xmath286 the variable @xmath287 for these instantiated nodes assumes .",
    "it then follows from eqs .   and   and the strong factorisation propertythis , together with the course of reasoning leading to eq .",
    ", shows that the results of updating the tree ( and the algorithm we are deriving ) in this way will be exactly the same _ for any way _ of forming a product of the local models for the children of @xmath5 , _ provided only that this product is strongly factorising_. for instance , replacing the conditionally independent natural extension with the strong product in eq .",
    "will lead to exactly the same inferences .",
    "of course , this should not be taken to mean that our algorithm also works for updating credal trees under strong independence . ]",
    "that [ see the appendix for a proof ] @xmath328      define the messages @xmath329 by @xmath330 where the gambles @xmath331 on @xmath30 are given by the recursion relations : @xmath332 and for each @xmath333 , so @xmath7 exists , @xmath334    g^\\mu_{{m(s)}}.\\ ] ] the messages @xmath329 are again tuples of real numbers , with one component @xmath335 for each of the possible values @xmath327 of @xmath127 .",
    "is the root node , then @xmath336 and @xmath329 is a single real number , which by eq .",
    "is equal to @xmath337 .",
    "see also footnote  [ fn : empty - product ] .",
    "] they do depend on the choice of @xmath293 or @xmath318 , as well as on which nodes are instantiated and on which value @xmath286 the variable @xmath287 for these instantiated nodes assumes .",
    "it then follows from eqs .",
    "and   and the strong factorisation property of the local independent products that [ see the appendix for a proof ] @xmath338 we conclude that we can find the value of @xmath337 by a backwards recursion method consisting in passing messages up to the root of the tree , and in transforming them in each node using the local uncertainty models ; see eqs .   and  .",
    "there is a further simplification , because we are not necessarily interested in the actual value of @xmath337 , but rather in its sign .",
    "it arises whenever there are instantiated nodes above the target node : @xmath339 .",
    "let in that case @xmath340 be the greatest element of the chain @xmath341 , i.e. , the instantiated node closest to and preceding the target node @xmath16 , and let @xmath342 be its successor in the chain @xmath343 ; see for instance fig .",
    "[ fig : mtree ] .",
    "if we let @xmath344 then it follows from eq .",
    "[ with @xmath345 and @xmath346 that @xmath347 .",
    "if we now continue to use eqs .",
    "and   until we reach the root of the tree , we eventually find that , where @xmath348 and @xmath349 are real constants that do not depend on @xmath293 and @xmath318 . letting @xmath350 then allows us to identify the constants @xmath348 and @xmath349 . ]",
    "@xmath351 since we assumed from the outset that @xmath352 , we gather from eq .",
    "that @xmath353 .",
    "moreover , by combining eqs .   and   with proposition  [ prop : global :",
    "positivity : too ] , we find that @xmath354 for all @xmath355 , and therefore @xmath356 .",
    "hence @xmath357 .",
    "we conclude that in order to update the tree in the situation described above , we can perform all calculations on the sub - tree @xmath358 , where the new root @xmath342 has local model @xmath359 .",
    "this is also borne out by the discussion of the separation properties in section  [ sec : separation ] .      at ( 7,-2 ) ; & ; + ; & ; + ; & ; + ; ( root ) at ( 0,0 ) @xmath6 ; ( x1 ) at ( @xmath360 ) @xmath361 ; ( x2 ) at ( @xmath362 ) @xmath363 ; ( x3 ) at ( @xmath364 ) @xmath365 ; ( x4 ) at ( @xmath366 ) @xmath367 ;    ( x5 ) at ( @xmath368 ) @xmath369 ; ( x15 ) at ( @xmath370 ) @xmath371 ; ( x6 ) at ( @xmath372 ) @xmath373 ; ( x7 ) at ( @xmath374 ) @xmath375 ; ( x8 ) at ( @xmath376 ) @xmath377 ; ( x9 ) at ( @xmath378 ) @xmath379 ; ( x16 ) at ( @xmath380 ) @xmath381 ;    ( x10 ) at ( @xmath382 ) ; ( x11 ) at ( @xmath383 ) @xmath384 ; ( x12 ) at ( @xmath385 ) @xmath386 ; ( x14 ) at ( @xmath387 ) @xmath388 ; ( x13 ) at ( @xmath389 ) @xmath390 ; ( root )  ( x1 ) ; ( root ) ",
    "( x2 ) ; ( x2 )  ( x3 ) ; ( x3 )  ( x4 ) ; ( x4 )  ( x5 ) ; ( x5 )  ( x6 ) ; ( x5 )  ( x7 ) ; ( x7 )  ( x8 ) ; ( x7 )  ( x9 ) ; ( x6 )  ( x16 ) ; ( x4 )  ( x15 ) ; ( x4 )  ( x10 ) ; ( x10 )  ( x11 ) ; ( x10 )  ( x12 ) ; ( x12 )  ( x13 ) ; ( x12 )  ( x14 ) ;    we now convert these observations into a workable algorithm .    using regular extension and message passing ,",
    "we are able to compute @xmath300 : we    choose any @xmath391 $ ] ;    calculate the value of @xmath392 by sending messages from the terminal nodes towards the root ; and    repeat this in some clever way to find the maximal @xmath318 that will make this @xmath392 zero .",
    "but we have seen above that this naive approach can be sped up by exploiting    the separation properties of the tree , and    the independence of @xmath318 ( and @xmath293 ) for some of the messages , namely those associated with nodes that do not precede the target node @xmath16 .    for a start , as we are only interested in the sign of @xmath393 [ or equivalently , that of @xmath392 ] , which we have seen is determined by the sign of @xmath395 , we only have to take into consideration nodes that strictly follow @xmath340",
    ".    the next thing a smarter implementation of the algorithm can do , is determine the _ trunk _ @xmath396 of the tree : those nodes that precede the queried node @xmath16 and strictly follow the greatest observed node @xmath340 preceding @xmath16 .",
    "we can define the trunk more formally as follows : @xmath397 . for the tree in fig .",
    "[ fig : mtree ] for instance , where the darker @xmath398 is the queried variable and the lighter nodes @xmath399 are instantiated , the trunk is given by @xmath400 , and indicated by bolder arrows .",
    "( x4s ) at ( 2,-10 ) @xmath367 ; ( pi ) at ( @xmath401 ) @xmath402 ; ( x5s ) at ( @xmath403 ) @xmath369 ; ( x14s ) at ( @xmath404 ) @xmath388 ; ( x6s ) at ( @xmath405 ) @xmath373 ; ( x7s ) at ( @xmath406 ) @xmath375 ; ( x8s ) at ( @xmath407 ) @xmath377 ; ( x9s ) at ( @xmath408 ) @xmath379 ; ( x16s ) at ( @xmath409 ) @xmath381 ; ( x4s )  ( x5s ) ; ( x4s )  ( x14s ) ; ( x5s )  ( x6s ) ; ( x5s )  ( x7s ) ; ( x7s )  ( x8s ) ; ( x7s )  ( x9s ) ; ( x6s )  ( x16s ) ;     ; at ( @xmath410 ) @xmath411 ; ; at ( @xmath412 ) @xmath413 ; ; at ( @xmath414 ) @xmath415 ; ; at ( @xmath416 ) @xmath417 ; ; at ( @xmath418 ) @xmath419 ; ; at ( @xmath420 ) @xmath421 ; ; at ( @xmath422 ) @xmath423 ;    ( x4s )  ( pi.south west ) ;    we have a special interest in the nodes that constitute the trunk , because only they will send messages to their mother nodes that actually depend on @xmath318 . as a consequence , all other nodes ( all descendants of the trunk that are not in the trunk themselves )",
    "send messages that have to be calculated only once .",
    "this implies that we can summarise all the @xmath318-independent messages by propagating all of them until they reach the trunk .",
    "the @xmath318-independent messages @xmath424 that arrive in a trunk node @xmath5 can be represented more succinctly by their point - wise products @xmath425 , because eqs .   and   only depend on them through on these products .",
    "this means that for every trunk node @xmath426 , we have to find the lower ( upper ) messages of every child @xmath155 of @xmath5 that is not in the trunk itself .",
    "both @xmath427 and @xmath428 can be calculated recursively using eq .  , where the recursion starts at the leaves and moves up to ( but stops right before ) the trunk . in the leaves , the local lower and upper previsions of the indicator of the evidence",
    "are sent upwards if the leaf is instantiated ; if not the constant 1 is sent up , which is equivalent to deleting the node from the tree",
    ". we could envisage removing _ barren nodes _ (",
    "all of whose descendants are uninstantiated , such as @xmath361 , @xmath390 , @xmath381 in the example tree above ) from the tree beforehand , but we believe the computational overhead created by the search for them will void the gain .",
    "( x2b ) at ( 4,2 ) @xmath429 ; ( x3b ) at ( @xmath430 ) @xmath431 ; ( x4b ) at ( @xmath432 ) @xmath367 ; ( x10b ) at ( @xmath433 ) ; ( x3b )  ( x4b ) ; ( x4b )  ( x10b ) ; ; at ( @xmath434 ) @xmath435 ; ; at ( @xmath436 ) @xmath437 ; ; at ( @xmath438 ) @xmath439 ;    the only recursion that is still left to do , is the calculation of the @xmath318-dependent messages @xmath329 along the trunk . as demonstrated in fig .  [",
    "fig : joint ] , we can calculate @xmath440 using the following recursion formula : @xmath441 these formulas are reformulations of eqs .   , where the influence of the @xmath442 has been made explicit .    since we now know how to calculate @xmath440",
    ", we can tackle the final problem : find the maximal @xmath318 for which @xmath443 . in principle",
    ", a secant root - finding method could be used , but using the concavity and non - increasing character of @xmath440 as a function of @xmath318 , we can speed up the calculation of the maximal root drastically as shown in fig .",
    "[ fig : rootfinding ] .",
    "( -0.1,0 )  ( 1.5,0 ) node[right ] @xmath318 ; ( -0.08,-0.4 )  ( -0.08,0.5 ) node[left ] @xmath337 ; plot ( , 0.4-exp(4*)/60 ) ; ( 0.1,0.4-exp(4 * 0.1)/60 )  ( 0.65,0.4-exp(4 * 0.65)/60 )  ( ( ( 24-exp(4 * 0.65))*0.1-(24-exp(4 * 0.1))*0.65)/(exp(4 * 0.1)-exp(4 * 0.65)),0 ) ; ( 1.0,0.4-exp(4 * 1.0)/60 )  ( 0.95,0.4-exp(4 * 0.95)/60 )  ( ( ( 24-exp(4))*0.95-(24-exp(4 * 0.95)))/(exp(4 * 0.95)-exp(4)),0 ) ; ( 0.65,0.4-exp(4 * 0.65)/60 )  ( ( ( 24-exp(4 * 0.65))*0.95-(24-exp(4 * 0.95))*0.65)/(exp(4 * 0.95)-exp(4 * 0.65)),0 )  ( 0.95,0.4-exp(4 * 0.95)/60 ) ; ( ln(24)/4,0 ) circle ( 0.3pt ) node[above , xshift=4pt ] @xmath16 ; ( 0.1,0.4-exp(4 * 0.1)/60 ) circle ( 0.3pt ) node [ above ] @xmath444 ; ( 0.65,0.4-exp(4 * 0.65)/60 ) circle ( 0.3pt ) node [ above right ] @xmath445 ; ( 0.95,0.4-exp(4 * 0.95)/60 ) circle ( 0.3pt ) node [ right , yshift=2pt ] @xmath446 ; ( 1.0,0.4-exp(4 * 1.0)/60 ) circle ( 0.3pt ) node [ right , yshift=-0pt ] @xmath447 ; ( ( ( 24-exp(4 * 0.65))*0.95-(24-exp(4 * 0.95))*0.65)/(exp(4 * 0.95)-exp(4 * 0.65)),0 ) circle ( 0.2pt ) node [ below left ] @xmath448 ; ( ( ( 24-exp(4))*0.95-(24-exp(4 * 0.95)))/(exp(4 * 0.95)-exp(4)),0 ) circle ( 0.2pt ) node [ below right , xshift=+4pt ] @xmath449 ; ( ( ( 24-exp(4 * 0.65))*0.1-(24-exp(4 * 0.1))*0.65)/(exp(4 * 0.1)-exp(4 * 0.65)),0 ) circle ( 0.2pt ) node [ below right ] @xmath450 ; at ( 2.5,0 )    @xmath451 ; + @xmath452;@xmath453 ; + * while * @xmath454 * and * @xmath455 + @xmath456 + @xmath457 ; + @xmath458 ; + @xmath459 + @xmath460 ; + @xmath461 ; + @xmath462 ; + @xmath463;@xmath453 ;    ;    let us briefly discuss the complexity of our algorithm .",
    "consider for a start that for a fixed @xmath318 each node makes a single local computation and then propagates the result to its mother node : this implies that , with @xmath318 fixed , the algorithm is linear in the number of nodes .",
    "iterating on @xmath318 then amounts to multiplying such a linear complexity with the number of iterations .",
    "this number depends on the function @xmath293 , as the iterations are made to compute the root of a function that is known to belong to the real interval @xmath464 $ ] .",
    "if we assume that the bisection algorithm is employed to find the root  for the sake of simplicity  and let @xmath465 be the range of the function , then the number of iterations is bounded by @xmath466 , where @xmath467 is some fixed tolerance .",
    "in other words , the number of iterations is linear in the number @xmath349 of bits needed to represent @xmath450 in base 2 .",
    "this means that the overall complexity of the algorithm is @xmath468 , taking into account that the computational complexity of our root - finding algorithm must be lower than for the bisection ( and actually also for the secant ) algorithm .",
    "since @xmath349 will be a small number should be bounded given the finiteness of a computer s way to represent numbers .",
    "] in most cases ( e.g.  when the focus is on probabilities ) , we simply refer to the complexity of our algorithm as linear in the number of nodes .",
    "we present a very simple example that allows us to    follow the inference method discussed above in a step - by - step fashion ;    see that there are separation properties for credal nets under strong independence that fail for credal trees under epistemic irrelevance ; and    see that in that case we will typically observe dilation .",
    "consider the following imprecise markov chain :    + = [ ->,semithick ] = [ ->,thick , dotted , draw = blue!50 ] ( x1 ) @xmath361 [ grow = right , level distance=35 ] child node ( x2 ) @xmath363 child node ( x3 ) @xmath365 ; ( x1info ) ? ; ( x2info ) @xmath469 ; ( x3info ) @xmath470 ; ( x1 ) ",
    "( x1info ) ; ( x2info )  ( x2 ) ; ( x3info )  ( x3 ) ;    to make things as simple as possible , we suppose that @xmath471 and that @xmath472 is a linear ( or precise , or expectation - like ) model @xmath473 with mass function @xmath474 .",
    "we also assume that @xmath475 is a linear model @xmath476 with conditional mass function @xmath477 .",
    "we make no such restrictions on the local model @xmath478 .",
    "we also use the following simplifying notational device : if we have three real numbers @xmath479 , @xmath480 and @xmath481 , we let @xmath482 we observe @xmath483 and @xmath484 , and want to make inferences about the target variable @xmath361 : for any @xmath485 , we want to know @xmath486 . letting @xmath487 and @xmath488 ,",
    "we infer from the separate coherence of @xmath489 that it suffices to calculate @xmath490 and @xmath491 , because @xmath492 we let @xmath493{{\\mathbb{i}_{\\{{x_{2}}\\}}}}{{\\mathbb{i}_{\\{{x_{3}}\\}}}}$ ] , and apply the approach of the previous section .",
    "we see that the trunk @xmath494 , and the instantiated leaf node @xmath495 sends up the messages @xmath496 to the instantiated node @xmath497 , which transforms them into the messages @xmath498 where we let @xmath499 and @xmath500 .",
    "these messages are sent up to the ( target ) root node @xmath501 , which transforms them into the message @xmath502 with @xmath503 . if we also use that @xmath504 , this leads to @xmath505    + { q}(b){q}({x_{2}}\\vert b){\\overline{{q}}}[-\\mu],\\ ] ] so we find after applying regular extension that @xmath506 when @xmath507 , which happens for instance if the local model for @xmath365 is precise , then we see that , with obvious notations , @xmath508 and therefore @xmath363 indeed separates @xmath365 from @xmath361 .",
    "but in general , letting @xmath509 and @xmath510 , we get @xmath511 as soon as @xmath512 , @xmath363 no longer separates @xmath365 from @xmath361 , and we witness _",
    "@xcite because of the additional observation of @xmath365 !",
    "strong independence implies epistemic irrelevance , and hence inferred ( lower - upper ) probability intervals for imprecise markov trees with epistemic irrelevance will include those obtained assuming strong independence .",
    "this suggests that our algorithm could also be used also as a tool to make conservative ( also called outer ) approximations of the computations made in a credal tree under strong independence .",
    "this could be an important application of our algorithm since at the moment it is unclear whether or not updating probabilities in a tree is a polynomial task under strong independence .",
    "if it were not , addressing the problem would definitely benefit from the availability of fast approximations .    with this idea in mind",
    ", we make a preliminary empirical exploration of the quality of the approximation . as noted in section  [ sec : separation ] , the two models have different separation properties : this is particularly important when evidence is back - propagated from leaves to root .",
    "for this reason , we compare posterior probability intervals for the root variable of a _ chain _ where only the leaf node is instantiated .",
    "[ fig : strvsepi ] reports the results of this comparison for chains with binary nodes , randomly generated local models , and variable length ( from 5 up to 100 nodes ) .",
    "the algorithm in section  [ sec : algorithm ] has been used to compute the posterior probability intervals in the chains under epistemic irrelevance , while the _ 2u algorithm _ @xcite was used for updating in the chains under strong independence .",
    "the inferred probability intervals for the former turn out to be clearly wider , and the mean difference between the two intervals is about @xmath513 irrespective of the length of the chain , at least for chains with more than ten nodes .    for non - binary nodes",
    "there are no efficient algorithms known for updating chains with strong independence .",
    "we used the procedure in @xcite to update chains with less than seven ternary nodes and credal sets with three randomly generated extreme points in the strong independence case . a similar difference between the posterior intervals",
    "was observed also in these cases . for longer chains , updating for the chain under strong independence",
    "is too slow and no comparison can be made . in summary , there is a non - negligible difference between inferences based on the two notions of ` independence ' .",
    "this means that the epistemic approximations to the strong case could be quite crude in practise .",
    "however , their being outer ( that is , safe ) approximations together with their light complexity could still make of them very useful tools , whenever the strong independence approach is deemed necessary or appropriate .",
    "( 0.0,0 ) ",
    "( 105,0 ) node[right ] ; ( 0.0,0.0 )  ( 0.0,45 ) node[left ] ; /in 0/0 , 25/25 , 50/50 , 75/75 , 100/100 ( 0pt,4pt )  ( 0pt,-4pt ) node[below ] @xmath514 ; /in 10/.10 , 20/.20 , 30/.30 , 40/.40 ( 4pt,0pt )  ( -4pt,0pt ) node[left ] @xmath515 ; plot[xscale=1.0/1.0,yscale=1.0/1.0,smooth , mark = x , mark size=10pt ] file data.table ;",
    "the tree topology of the graphs considered in this paper is expressive enough to model useful and interesting problems .",
    "these problems can then be solved efficiently by means of the algorithm described in the previous sections .",
    "we make this point clearer with an example application about character recognition .",
    "this is also an opportunity to illustrate the differences between the traditional , precise - probability , approach to the problem and the imprecise - probability one .",
    "most notably , these differences arise because the imprecise - probability methods come with the inherent ability to suspend judgement when the information available is deemed insufficient to reliably recognise a character , whereas the precise - probability ones do not .",
    "hidden markov models ( hmms ) @xcite are popular tools for modelling a sequence of hidden variables that generate a related sequence of observable variables .",
    "these are respectively referred to as the _ generative _ and _ observable _ sequences .",
    "hmms have applications in many areas of signal processing , and more specifically in speech and text recognition .",
    "both the generative and the observable sequence are described by sets of variables over the same domain @xmath516 , denoted respectively by @xmath517 ,  ,",
    "@xmath518 and @xmath519 ,  , @xmath520 .",
    "the independence assumptions between these variables , which characterise hmms , are those corresponding to the tree structure below .",
    "informally , this topology states that every element of the generative sequence depends only on its predecessor , while each observation depends only on the corresponding element of the generative sequence .",
    "+ = [ ->,semithick ] = [ draw,->,semithick ] ( x1 ) @xmath517 [ grow = right , level distance=40 ] child node ( x2 ) @xmath521 child node ( x ) @xmath150 child node ( xn ) @xmath518 ; ( o1 ) @xmath519 ; ( o2 ) @xmath522 ; ( o ) @xmath150 ; ( on ) @xmath520 ; ( x1 )  ( o1 ) ; ( x2 )  ( o2 ) ; ( xn )  ( on ) ; ; ;    a local uncertainty model should be defined for each variable . in the case of precise probabilistic assessments , this corresponds to linear ( precise , or expectation - like ) versions of the local models @xmath523 , @xmath524 and @xmath525 , @xmath116 , where the conditional models are assumed to be _ stationary _ , i.e. , independent of @xmath526 . these model , respectively , beliefs about the first state in the generative sequence , the transitions between adjacent states , and the observation process",
    ".    bayesian techniques for learning from multinomial data are usually employed for identifying these models .",
    "but , especially if only few data are available , other methods leading to imprecise assessments , such as the _ imprecise dirichlet model _ ( idm , @xcite ) , might offer a more realistic model of the local uncertainty .",
    "for example , for the unconditional local model @xmath523 , applying the idm leads to the following simple identification : @xmath527 where @xmath528 counts the units in the sample for which @xmath529 , and @xmath5 is a ( positive real ) hyper - parameter that expresses the degree of caution in the inferences . for the conditional local models",
    ", we can proceed similarly .",
    "this leads to the identification of an _ imprecise hmm _",
    ", a special credal tree under epistemic irrelevance , like the ones introduced in section  [ sec : markov - trees ] .    generally speaking",
    ", the algorithm described in section  [ sec : algorithm ] can be used for computing inferences with such imprecise hmms .",
    "below , we address the more specific problem of _ on - line recognition _ , which consists in the identification of the most likely value of @xmath518 , given the evidence for the whole observational sequence @xmath530 ,  , @xmath531 . for precise local models ,",
    "this problem requires the computation of the state @xmath532 that is most probable after the observation . for imprecise local models",
    "different criteria can be adopted ; see @xcite for an overview .",
    "we consider _ maximality _ : we order the states by @xmath533 if and only if @xmath534 , and we look for the _ undominated _ or _ maximal _ states under this order .",
    "this may produce _ indeterminate _ predictions : the set of undominated states may have more than one element .      as a very first application of the imprecise hmm",
    ", we have considered a _",
    "character recognition _ problem .",
    "a written text was regarded as a generative sequence , while the observable sequence was obtained by artificially corrupting the text .",
    "this is a model for a not perfectly reliable observation process , such as the output of an ocr device .",
    "the local models were identified using the idm , as in , by counting the occurrences of single characters and the ` transitions ' from one character to another in the generative sequence , and by matchings between the elements of the two sequences . by modelling text as a generative sequence",
    ", we obviously ignore any dependence there might be between a character and its @xmath535-th predecessor , for any @xmath536 .",
    "a better , albeit still not completely realistic , model would resort to using @xmath535-grams ( i.e. , clusters of @xmath535 characters with @xmath537 ) instead of monograms .",
    "such models might lead to higher accuracy , but they need larger data sets for their quantification , because of the exponentially larger number of possible transitions for which probabilities have to be estimated .",
    "the figure below depicts how on - line recognition through hmm might apply to this setup .",
    "+ = [ ed ] ( x1 ) @xmath517 [ level distance=35 ] child[grow = down ] node[observed ] ( o1 ) @xmath519 child[grow = right ] node[nd ] ( x2 ) @xmath521 child[grow = down ] node[observed ] ( o2 ) @xmath522 child[grow = right ] node[target ] ( x3 ) child[grow = down ] node[observed ] ( o3 ) @xmath538 ; ( xi ) * i * ; ; ; ( xv ) * v * ; ; ( oi ) * i * ; ; ; ( ov ) * v * ; ;    the performance of the precise model can be characterised by its _",
    "( the percentage of correct predictions ) alone .",
    "the imprecise hmm requires more indicators .",
    "we follow @xcite in using the following :    determinacy : :    percentage of determinate predictions , set - accuracy : :    percentage of indeterminate predictions containing the right state , single accuracy : :    percentage of correct predictions computed considering only    determinate predictions , and indeterminate output size : :    average number of states returned when the prediction is indeterminate    over number of possible states .",
    ".precise vs.  imprecise hmms .",
    "test results obtained by twofold cross - validation on the first two chants of dante s _ divina commedia _ and @xmath539 .",
    "quantification is achieved by idm with @xmath540 and perks prior modified as suggested in ( * ? ? ?",
    "* section  5.2 ) .",
    "the single - character output by the precise model is then guaranteed to be included in the set of characters the imprecise hmm identifies .",
    "[ cols= \" < , > , > \" , ]     the recognition using our algorithm is fast : it never takes more than one second for each character .",
    "table  [ tab : results ] reports descriptive values for a large set ( @xmath541 ) of simulations , and a comparison with precise model performance .",
    "imprecise hmms guarantee quite accurate predictions .",
    "in contrast with the precise model , there are ` indeterminate ' instances for which they do not output a single state . yet",
    ", this happens rarely , and even then we witness a remarkable reduction in the number of undominated states ( from the @xmath542 letters of the italian alphabet to less than @xmath495 ) .",
    "interestingly , the instances for which the imprecise probability model returns more than one state appear to be ` difficult ' for the precise probability model : the accuracy of the precise models displays a strong decrease if we focus only on these instances , while the imprecise models here display basically the same performance as for other instances , by returning about three characters instead of a single one .",
    "we have defined imprecise - probability ( or credal ) trees using walley s notion of epistemic irrelevance .",
    "credal trees generalise tree - shaped bayesian nets in two ways : by allowing the parameters of the tree to be imprecisely specified , and moreover by replacing the notion of stochastic independence with that of epistemic irrelevance .",
    "our focusing on epistemic irrelevance is the most original aspect of this work , as this notion has received limited attention so far in the context of credal nets .",
    "we have focused in particular on developing an efficient exact algorithm for updating beliefs on the tree .",
    "like the algorithms developed for precise graphical models , our algorithm works in a distributed fashion by passing messages along the tree .",
    "it computes lower and upper conditional previsions ( expectations ) with a complexity that is linear in the number of nodes in the tree .",
    "this is remarkable because until now it was unclear whether an algorithm with the features described above was at all feasible : in fact , epistemic irrelevance is most easily formulated using coherent lower previsions , which have never before been used as such in practical applications of credal nets .",
    "moreover , it is at this point not clear that epistemic irrelevance is as ` well - behaved ' as strong independence is with respect to the graphoid axioms for propagation of probability in graphical models @xcite . that such is not the case . ]",
    "our results therefore appear very encouraging , and seem to have the potential to open up new avenues of research in credal nets .    on a more theoretical side",
    ", we have also shown that our credal trees satisfy the important rationality requirement of coherence .",
    "this has been established under the assumption that the _ upper _ probability of any possible observation in the tree is positive , which is a very mild requirement .",
    "the same assumption also allowed us to show that all inferences made by updating the tree will be coherent with each other as well as with the local uncertainty models in the nodes of the tree .",
    "on the applied side , we have presented an application of the credal tree model to the problem of character recognition , where the parameters of the model are inferred from data .",
    "the empirical results are positive , especially because they show that our credal trees are able to make more reliable predictions than their precise - probability counterparts .    where to go from here",
    "? there are many possible avenues for future research",
    ".    it would be very useful to be able to extend the algorithm at least to so - called _ polytrees _ , which are substantially more expressive graphs than trees are .",
    "this could be a difficult task to achieve .",
    "in fact , updating credal nets based on strong independence is an np - hard task when the graph is more general than a tree @xcite .",
    "similar problems might affect the algorithms for credal nets based on irrelevance .    for applications",
    ", it would be very important to develop statistical methods specialised for credal nets under irrelevance that avoid introducing excessive imprecision in the process of inferring probabilities from data .",
    "this could be achieved , for instance , by using a single global idm over the variables of the tree rather than many local ones , as we did in our experiments .",
    "another research direction could be concerned with trying to strengthen the conclusions that epistemic trees lead to",
    ". there might be cases where our markov condition based on epistemic irrelevance is too weak as a structural assessment .",
    "we have discussed situations where this type of markov condition systematically leads to a dilation of uncertainty when updating beliefs with observations , and indicated that this dilation is related to the ( lack of ) certain separation properties induced by epistemic irrelevance on a graph .",
    "dilation might not be desirable in some applications , and we could be called upon to strengthen the model in order to rule out such behaviour .",
    "one way to address the issue of dilation  but not necessarily the easiest",
    " could consist in adding additional irrelevance statements to the model , other than those derived from the markov condition .",
    "an easier avenue could be based on designing assumptions that together with the markov condition lead to some stronger separation properties , while not necessarily requiring them to match the common ones used in bayesian nets .",
    "research by de cooman and hermans was supported by flemish bof project  01107505 and sbo project  060043 of the iwt - vlaanderen .",
    "research by antonucci and zaffalon has been partially supported by the swiss nsf grants n.  200020 - 116674/1 and n.  200020 - 121785/1 .",
    "this paper has benefited from discussions with serafn moral , fabio g.  cozman and cassio p.  de campos , and from the generous comments provided by two anonymous referees .    10    alessandro antonucci , alessio benavoli , marco zaffalon , gert de cooman , and filip hermans .",
    "multiple model tracking by imprecise markov trees . in _ proceedings of the 12th international conference on information fusion ( seattle , wa , usa ,",
    "july 69 , 2009 ) _ , pages 17671774 , 2009 .",
    "giorgio corani and marco zaffalon . learning reliable classifiers from small or incomplete data sets : the naive credal classifier 2 .",
    ", 9:581621 , 2008 .",
    "ins couso , serafn moral , and peter walley . a survey of concepts of independence for imprecise probabilities .",
    ", 5:165181 , 2000 .",
    "fabio  g. cozman .",
    "credal networks . , 120:199233 , 2000 .",
    "fabio  g. cozman and peter walley .",
    "graphoid properties of epistemic irrelevance and independence . , 45(12):173195 , 2005 .",
    "cassio  p. de campos and fabio  g. cozman .",
    "inference in credal networks using multilinear programming . in _ proceedings of the second starting ai researcher symposium _ , pages 5061 , valencia , 2004 .",
    "ios press .",
    "cassio  p.",
    "de  campos and fabio  g. cozman",
    ". the inferential complexity of bayesian and credal networks . in _ proceedings of the international joint conference on artificial intelligence _ , pages 13131318 , edinburgh , 2005 .",
    "cassio  p.",
    "de campos and fabio  g. cozman .",
    "computing lower and upper expectations under epistemic independence .",
    ", 44(3):244260 , 2007 .",
    "gert de cooman and filip hermans .",
    "imprecise probability trees : bridging two theories of imprecise probability . , 172(11):14001427 , 2008 .",
    "gert de cooman , filip hermans , and erik quaeghebeur .",
    "imprecise markov chains and their limit behaviour . , 23(4):597635 , 2009 .",
    "gert de cooman , enrique miranda , and marco zaffalon .",
    "independent natural extension .",
    "2010 . in preparation .",
    "gert de cooman and marco zaffalon . updating beliefs with incomplete observations . , 159(1 - 2):75125 , 2004 .",
    "enrico fagiuoli and marco zaffalon .",
    "2u : an exact interval propagation algorithm for polytrees with binary variables .",
    ", 106:77107 , 1998 .",
    "timothy herron , teddy seidenfeld , and larry wasserman .",
    "divisive conditioning : further results on dilation .",
    ", 64:411444 , 1997 .",
    "enrique miranda .",
    "a survey of the theory of coherent lower previsions .",
    ", 48(2):628658 , 2008 .",
    "enrique miranda .",
    "updating coherent lower previsions on finite spaces .",
    ", 160(9):12861307 , 2009 .",
    "enrique miranda and gert de cooman .",
    "marginal extension in the theory of coherent lower previsions .",
    ", 46(1):188225 , 2007 .    enrique miranda and marco zaffalon .",
    "coherence graphs . , 173:104144 , 2009 .",
    "serafn moral .",
    "epistemic irrelevance on sets of desirable gambles .",
    ", 45:197214 , 2005 .",
    "judea pearl . .",
    "morgan kaufmann , san mateo , ca , 1988 .",
    "lawrence  r. rabiner . a tutorial on hmm and selected applications in speech recognition .",
    ", 77(2):257286 , 1989 .    teddy seidenfeld and larry wasserman .",
    "dilation for sets of probabilities .",
    ", 21:113954 , 1993 .",
    "matthias c.  m. troffaes .",
    "decision making under uncertainty using imprecise probabilities .",
    ", 45(1):1729 , 2007 .    peter walley . .",
    "chapman and hall , london , 1991 .",
    "peter walley .",
    "inferences from multinomial data : learning about a bag of marbles . , 58:357 , 1996 . with discussion .",
    "peter  m. williams .",
    "notes on conditional previsions .",
    "technical report , school of mathematical and physical science , university of sussex , uk , 1975 .",
    "revised journal version : @xcite .",
    "peter  m. williams .",
    "notes on conditional previsions . , 44:366383 , 2007 .",
    "revised journal version of @xcite .",
    ". statistical inference of the naive credal classifier . in gert de  cooman , terrence .",
    "l. fine , and teddy seidenfeld , editors , _",
    "isipta 01  proceedings of the second international symposium on imprecise probabilities and their applications _ , pages 384393 .",
    "shaker publishing , maastricht , 2000 .",
    "marco zaffalon and enrique miranda .",
    "conservative inference rule for uncertain reasoning under incompleteness .",
    ", 34:757821 , 2009 .",
    "in this appendix , we justify formulas   and  , and give proofs for propositions  [ prop : global : positivity ] and  [ prop : global : positivity : too ] , and theorem  [ theo : global - models ] .",
    "let us define the gambles @xmath543 and , with obvious notations , @xmath544 let the chain @xmath343 be given by @xmath545 , where @xmath546 , @xmath547 and @xmath548 for @xmath549 .",
    "if we apply the recursion equation   in @xmath550 and take into account the separate coherence and the strong factorisation of the conditionally independent natural extension @xmath551 , we see that @xmath552 where [ provided that @xmath553 and therefore @xmath554 @xmath555{t_1}\\notag\\\\      & = g^\\mu_{t_1}{{\\underline{{p}}}_{{{\\downarrow}{c_{}(t_2)}}}\\bigg({{{{\\underline{{p}}}_{{{\\downarrow}t_1}}({\\phi^\\mu_{t_2}}\\big\\vert{x_{t_2}}\\bigg)}{t_1 }        \\smashoperator{\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}}}\\phi^\\mu_c}}\\vert{x_{=}})}g^\\mu_{t_1}{{\\underline{{p}}}_{{{\\downarrow}{c_{}(t_1)}}}\\bigg({{{{\\varpi}_{t_2}^{\\mu } }        \\smashoperator{\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}}}\\phi^\\mu_c}}\\big\\vert{x_{t_1}}\\bigg)}\\notag\\\\      & = \\bigg [      \\max\\{{{\\varpi}_{t_2}^{\\mu}},0\\ }      { { \\underline{{p}}}_{{{\\downarrow}{c_{}(\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}})}}}\\bigg({{\\smashoperator[r}\\big\\vert{x_{\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}}}}\\bigg)}\\phi^\\mu_c}]{t_1 }      + \\min\\{{{\\varpi}_{t_2}^{\\mu}},0\\ }      { { \\overline{{p}}}_{{{\\downarrow}{c_{}(\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}})}}}\\bigg({{\\smashoperator[r}\\big\\vert{x_{\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}}}}\\bigg)}\\phi^\\mu_c}]{t_1 }      \\bigg]g^\\mu_{t_1}\\notag\\\\      & = \\bigg [      \\max\\{{{\\varpi}_{t_2}^{\\mu}},0\\ }      \\smashoperator{\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}}}{{\\underline{{\\varpi}}}_{c } }      + \\min\\{{{\\varpi}_{t_2}^{\\mu}},0\\ }      \\smashoperator{\\prod_{c\\in{c_{}(t_1)}\\setminus{\\{t_2\\}}}}{{\\overline{{\\varpi}}}_{c } }      \\bigg]g^\\mu_{t_1}. \\label{eq : justification : two }    \\end{aligned}\\ ] ] similarly , we find that @xmath556 where [ provided that @xmath557 and therefore @xmath558 in a completely similar way as above @xmath559g^\\mu_{t_2}.\\ ] ] we can go on in this way until we come to @xmath560 : @xmath561 where , using the separate coherence and the strong factorisation of the conditionally independent natural extension @xmath562 , @xmath563{t_r}\\notag\\\\      & = \\max\\{g-\\mu,0\\}{{\\underline{{p}}}_{{{\\downarrow}{c_{}(\\prod_{c\\in{c_{}(t_r)}})}}}\\bigg({{\\smashoperator[r}\\big\\vert{x_{\\prod_{c\\in{c_{}(t_r)}}}}\\bigg)}\\phi^\\mu_c}]{t_r }      + \\min\\{g-\\mu,0\\}{{\\overline{{p}}}_{{{\\downarrow}{c_{}(\\prod_{c\\in{c_{}(t_r)}})}}}\\bigg({{\\smashoperator[r}\\big\\vert{x_{\\prod_{c\\in{c_{}(t_r)}}}}\\bigg)}\\phi^\\mu_c}]{t_r}\\notag\\\\      & = \\max\\{g-\\mu,0\\}\\smashoperator{\\prod_{c\\in{c_{}(t)}}}{{\\underline{{\\varpi}}}_{c } }      + \\min\\{g-\\mu,0\\}\\smashoperator{\\prod_{c\\in{c_{}(t)}}}{{\\overline{{\\varpi}}}_{c}}.\\label{eq : justification : six }    \\end{aligned}\\ ] ] clearly , if we can prove that @xmath564 for all @xmath316 , it will follow from the considerations above that also @xmath565 for all @xmath17 , and then the proof is complete .",
    "this is what we now set out to do .",
    "consider any @xmath316 . then applying the recursion equation   and taking into account the separate coherence and the strong factorisation of the conditionally independent natural extension @xmath232",
    ", we see that , provided @xmath5 is not a terminal node , and with obvious notations , @xmath566 where @xmath567{s}\\notag\\\\     & = g^\\mu_s\\smashoperator{\\prod_{c\\in{c_{}(s ) } } }     { { \\overline{\\underline{{p}}}}_{{{\\downarrow}c}}({\\phi^\\mu_c}\\vert{x_{s } } ) }     = g^\\mu_s\\smashoperator{\\prod_{c\\in{c_{}(s)}}}{{\\underline{\\overline{{\\varpi}}}}_{c}}.\\label{eq : justification : eight }    \\end{aligned}\\ ] ] if on the other hand @xmath5 is a terminal node , then we can use eq .   to find that @xmath568 where the last equality follows from eq .  .",
    "now combine eqs .   and",
    "use recursion to complete the proof .    fix any @xmath569 in @xmath71 .",
    "we need to prove that @xmath570 and that @xmath571 for all @xmath140 , non - empty @xmath136 and @xmath572 .",
    "our argumentation is similar to a special case of the one in section  [ sec : calculating - rho ] .",
    "we use the notation established there , but with in particular @xmath573 , @xmath574 and @xmath575 .",
    "this implies that @xmath576 , @xmath577 and @xmath578 . in accordance with eq .",
    ", we define the messages @xmath579 and @xmath580 recursively by : @xmath581 with , as before by convention @xmath582 in all leaves @xmath5 .",
    "the last equality follows from the separate coherence of the local models @xmath254 and the fact that all messages  @xmath321 and  @xmath583 are non - negative .",
    "it is clear from the recursion equations   and   [ see also eq .  , the proof is completely similar to that of eqs .   and   given above ] that @xmath584 , for all @xmath255 , and that @xmath585 for all @xmath140 .",
    "similarly , it follows from eq .  ,",
    "conjugacy and the strong factorisation property of the conditionally independent natural extension that @xmath586 for all @xmath140 and all non - empty @xmath136 .",
    "so we have to prove that all values ( all components ) of all messages @xmath321 , @xmath255 are ( strictly ) positive .",
    "this follows at once from the recursion equation   and the assumed strict positivity of the local models @xmath254 .",
    "our argumentation is similar to a special case of the one in section  [ sec : calculating - rho ] .",
    "we also use notation similar to that established there , with in particular @xmath573 and @xmath574 . in accordance with eq .",
    ", we define the messages @xmath579 and @xmath580 recursively by : @xmath587 and @xmath588 with , as before by convention @xmath582 in all leaves @xmath5 .",
    "all these messages are non - negative by construction .",
    "it is clear from the recursion equations   and   [ see also eq .",
    ", the proof is completely similar to that of eqs .   and   given above ] that @xmath589 for all @xmath255 .",
    "now it follows from the recursion equations   and   and the assumption @xmath590 that @xmath591 for all @xmath260 . again applying eq .  , we find that indeed @xmath592 for all @xmath261 .",
    "our proof of theorem  [ theo : global - models ] relies heavily on a very convenient coherence result proved by enrique miranda ( * ? ? ?",
    "* theorem  6 ) , which we relate here to make the paper more self - contained .",
    "we use the notations established in the context of section  [ sec : independent - natural - extension ] .",
    "[ theo : blessyouquique ] let @xmath289 be a ( separately ) coherent lower prevision on @xmath165 , and consider @xmath593 disjoint pairs of subsets @xmath594 and @xmath595 of @xmath121 , @xmath182 .",
    "assume that @xmath596 for all @xmath597 , @xmath182 and use regular extension to define the conditional lower previsions @xmath598 on @xmath599 , for @xmath182 .",
    "then the ( conditional ) lower previsions @xmath289 , @xmath600 , ",
    ", @xmath601 are ( jointly ) coherent .      to prove  t[item : global : local ] , consider any @xmath255 , and any @xmath602 , then it follows from separate coherence that @xmath603 , and therefore we infer from the recursion equation   that indeed @xmath604 .",
    "next , we turn to the proof of  t[item : global : coherence ] and  t[item : global : irrelevance ] .",
    "consider any @xmath140 , @xmath136 and @xmath272 .",
    "let @xmath605 and @xmath606 .",
    "we calculate the following regular extension of the joint : @xmath607)\\geq0\\}}.\\ ] ] consider that @xmath608={{\\mathbb{i}_{\\{{x_{s}}\\}}}}{{\\mathbb{i}_{\\{{x_{r}}\\}}}}[g-\\mu],\\ ] ] where @xmath609 .",
    "let @xmath610 be the unique child of @xmath546 such that @xmath611 [ assuming of course that @xmath612 . by using separate coherence , recursion equations  , and  , and the strong factorisation property [ see proposition  [ prop : independent - factorising ] ] of the conditionally independent natural extension , in a way similar to the argumentation in section  [ sec : calculating - rho ]",
    ", we see that @xmath613 )      & = { { \\underline{{q}}}_{t_1}}({{\\underline{{p}}}_{{{\\downarrow}}}}({{{{\\mathbb{i}_{\\{{x_{r\\setminus{{\\downarrow}t_2}}}\\}}}}{{\\underline{{p}}}_{{{\\downarrow}}}}({{{{\\mathbb{i}_{\\{{x_{s}}\\}}}}{{\\mathbb{i}_{\\{{x_{r\\cap{{\\downarrow}t_2}}}\\}}}}[g-\\mu}\\vert{x_{}}\\vert{x _ { ) } } ) } }        { { c_{}(t_1)}}{t_1}}]{{c_{}(t_1)}}{t_1})\\\\      & = { { \\underline{{q}}}_{t_1}}({{\\underline{{p}}}_{{{\\downarrow}}}}({{h_2{{\\underline{{p}}}_{{{\\downarrow}}}}({{{{\\mathbb{i}_{\\{{x_{s}}\\}}}}{{\\mathbb{i}_{\\{{x_{r\\cap{{\\downarrow}t_2}}}\\}}}}[g-\\mu}\\vert{x_{}}\\vert{x_{)}})}}{t_2}{t_1 } } ]      { { c_{}(t_1)}}{t_1})\\\\      & = { { \\underline{{p}}}_{{{\\downarrow}t_1}}}(h_2{{\\underline{{p}}}_{{{\\downarrow}}}}({{{{\\mathbb{i}_{\\{{x_{s}}\\}}}}{{\\mathbb{i}_{\\{{x_{r\\cap{{\\downarrow}t_2}}}\\}}}}[g-\\mu}\\vert{x_{]}})}{t_2}{t_1}),\\end{aligned}\\ ] ] where @xmath614 .",
    "similarly , let @xmath615 be the unique child of @xmath610 such that @xmath616 [ assuming of course that @xmath617 .",
    "then we see in the same way as above that @xmath618}})}{t_2}{t_1 }     = { { \\underline{{p}}}_{{{\\downarrow}}}}({{h_3{{\\underline{{p}}}_{{{\\downarrow}}}}({{{{\\mathbb{i}_{\\{{x_{s}}\\}}}}{{\\mathbb{i}_{\\{{x_{r\\cap{{\\downarrow}t_3}}}\\}}}}[g-\\mu}\\vert{x_{}}\\vert{x_{)}})}}{t_3}{t_2}}]{t_2}{t_1},\\ ] ] where @xmath619 . continuing in this way",
    ", we eventually come to the conclusion that @xmath620 )      = \\underline{g}({{\\underline{{p}}}_{{{\\downarrow}{c_{}()}}}}({{h{{\\mathbb{i}_{\\{{x_{s}}\\}}}}[g-\\mu}\\vert{x_{}}})}]{s}),\\ ] ] where @xmath621 , and where the real functional @xmath622 on @xmath31 is essentially constructed as follows .",
    "consider the segment @xmath623 connecting @xmath6 and @xmath5 , i.e.  @xmath624 , @xmath625 ,  , @xmath626 ,  , @xmath627 .",
    "then there are non - negative @xmath628 on @xmath629 such that for all @xmath602 , @xmath630 , where @xmath631 and @xmath632 , @xmath549 .",
    "[ if @xmath633 , or in other words @xmath634 , just let @xmath635 .",
    "] in other words , the functional @xmath622 results from recursively multiplying with non - negative maps and applying global conditional lower previsions . as such , @xmath622 is non - negatively homogeneous and super - additive [ because the successive multiplication and composition preserves these properties ] .",
    "in addition , it does not depend on @xmath293 nor @xmath318 .",
    "if we use the separate coherence of @xmath232 , the strong factorisation , associativity and marginalisation properties of the conditionally independent natural extension @xmath232 [ see proposition  [ prop : independent - factorising ] , eqs .   and  , and the recursion equations   and  ] , and the separate coherence of the conditional lower prevision @xmath636 , we get : @xmath637}})}{{c_{}(s)}}{s }      & = { { \\mathbb{i}_{\\{{x_{s}}\\}}}}{{\\underline{{p}}}_{{{\\downarrow}}}}({{h[g-\\mu}\\vert{x_{]}})}{{c_{}(s)}}{s}\\notag\\\\      & = { { \\mathbb{i}_{\\{{x_{s}}\\ } } } }      \\begin{cases }        { { \\underline{{p}}}_{{{\\downarrow}{c_{}(s)}}}({h}\\vert{x_{s}})}[{{\\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}-\\mu ]        & \\text{if $ { { \\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}\\geq\\mu$}\\\\        { { \\overline{{p}}}_{{{\\downarrow}{c_{}(s)}}}({h}\\vert{x_{s}})}[{{\\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}-\\mu ]        & \\text{if $ { { \\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}\\leq\\mu$}.      \\end{cases }      \\label{eq : coherence - new - two }    \\end{aligned}\\ ] ] combining eqs .   and  , and invoking the non - negative homogeneity of the real functional @xmath622 , this leads to : @xmath638 )       =       \\begin{cases }         \\underline{g}({{\\mathbb{i}_{\\{{x_{s}}\\}}}}){{\\underline{{p}}}_{{{\\downarrow}{c_{}(s)}}}({h}\\vert{x_{s}})}[{{\\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}-\\mu ]         & \\text{if $ { { \\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}\\geq\\mu$}\\\\         \\overline{g}({{\\mathbb{i}_{\\{{x_{s}}\\}}}}){{\\overline{{p}}}_{{{\\downarrow}{c_{}(s)}}}({h}\\vert{x_{s}})}[{{\\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}-\\mu ]         & \\text{if $ { { \\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}\\leq\\mu$ } ,       \\end{cases}\\ ] ] where we let @xmath639 . by letting @xmath640 [ and therefore also @xmath641 in this expression",
    ", we derive in particular that @xmath642 and therefore also @xmath638)\\\\       =       \\begin{cases }         { \\underline{{p}}}({{\\{{x_{{\\{s\\}}\\cup r}}\\}}})[{{\\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}-\\mu ]         & \\text{if $ { { \\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}\\geq\\mu$}\\\\         { \\overline{{p}}}({{\\{{x_{{\\{s\\}}\\cup r}}\\}}})[{{\\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}-\\mu ]         & \\text{if $ { { \\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}\\leq\\mu$}.       \\end{cases}\\ ] ] since we have assumed that all local models @xmath254 are strictly positive , we gather from proposition  [ prop : global : positivity ] that @xmath643 , and therefore @xmath638)\\geq0      { \\leftrightarrow}{{\\underline{{p}}}_{{{\\downarrow}s}}({g}\\vert{x_{s}})}\\geq\\mu.\\ ] ] this allows us to infer from eq .",
    "that @xmath644 if we now combine eq .   with theorem  [ theo : blessyouquique ]",
    ", we see that both t[item : global : coherence ] and t[item : global : irrelevance ] hold .    to complete the proof , we consider t[item : global : smallest ] .",
    "consider any family of models @xmath266 that satisfies conditions  t[item : global : local]t[item : global : irrelevance ] . then we want to show that @xmath645 and @xmath646 the proof proceeds in a recursive ( inductive ) fashion .",
    "since the @xmath647 satisfy t[item : global : local ] , we infer in particular that @xmath648 it is therefore clearly sufficient to prove the following statement for all non - terminal nodes @xmath649 : @xmath650 this is what we now set out to do .",
    "fix any non - terminal node @xmath649 and any non - empty @xmath651 , and assume that @xmath652 for all @xmath653 .",
    "first of all , define for any disjoint proper subsets @xmath119 and @xmath120 of @xmath32 , the conditional lower previsions @xmath654 through : @xmath655 then we infer from t[item : global : irrelevance ] [ with @xmath656 , @xmath657 and @xmath658 that all these conditional lower previsions are in particular ( jointly ) coherent with the conditional lower prevision @xmath659 .",
    "if we recall definition  [ def : conditionally : independent : product ] [ with @xmath660 and @xmath661 , we conclude that @xmath662 is a conditionally independent product of the ` marginals ' @xmath663 , @xmath664 , which therefore dominates the smallest such independent product : @xmath665 and therefore , using the assumption , we infer from this inequality that @xmath666 where we have also used , successively , the monotonicity property of the conditionally independent natural extension [ see @xcite for a proof ] and the recursion equations   and  .    next ,",
    "define the conditional lower prevision @xmath667 on @xmath668 through : @xmath669 then we infer from t[item : global : irrelevance ] [ with @xmath657 , @xmath670 and @xmath671 that this conditional lower prevision @xmath667 is in particular ( jointly ) coherent with the conditional lower prevision @xmath647 defined on @xmath668 .",
    "we then see that for all @xmath672 : @xmath673 the first equality follows from eq .",
    ", the second one holds because the global models @xmath647 satisfy t[item : global : local ] , and the third one follows from recursion equation  .",
    "the first inequality follows if we apply walley s marginal extension theorem ( * ? ? ?",
    "* theorem  6.7.2 ) in the formulation of ( * ? ? ? * theorem  4 ) .",
    "the second inequality follows from the inequality   and the non - decreasing character of @xmath674 , which follows from separate coherence .",
    "this completes our proof that t[item : global : smallest ] is also satisfied ."
  ],
  "abstract_text": [
    "<S> we focus on credal nets , which are graphical models that generalise bayesian nets to imprecise probability . </S>",
    "<S> we replace the notion of strong independence commonly used in credal nets with the weaker notion of epistemic irrelevance , which is arguably more suited for a behavioural theory of probability . focusing </S>",
    "<S> on directed trees , we show how to combine the given local uncertainty models in the nodes of the graph into a global model , and we use this to construct and justify an exact message - passing algorithm that computes updated beliefs for a variable in the tree . </S>",
    "<S> the algorithm , which is linear in the number of nodes , is formulated entirely in terms of coherent lower previsions , and is shown to satisfy a number of rationality requirements . </S>",
    "<S> we supply examples of the algorithm s operation , and report an application to on - line character recognition that illustrates the advantages of our approach for prediction . </S>",
    "<S> we comment on the perspectives , opened by the availability , for the first time , of a truly efficient algorithm based on epistemic irrelevance . </S>"
  ]
}