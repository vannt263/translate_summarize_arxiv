{
  "article_text": [
    "as the most luminous electromagnetic explosions , gamma - ray bursts ( grbs ) offer a unique probe into the distant universe  but only if their rapidly fading afterglows are observed before dimming beyond detectability ( e.g. , * ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) . since the launch of the _ swift _ satellite in november 2004 @xcite , more than 170 long duration _",
    "swift _ gamma - ray bursts have had measured redshifts , but only a handful fall into the highest redshift range that allow for the probing of the earliest ages of the universe , up to less than a billion years after the big bang ( fig .",
    "[ fig : reddist ] ) . with a limited budget of large - aperture telescope time accessible for deep follow - up",
    ", it is becoming increasingly important to rapidly identify these grbs of interest in order to capture the most interesting events without spending available resources on more mundane events .",
    "along with quasars ( e.g. , * ? ? ?",
    "* ) and nir - dropout lyman - break galaxies ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , grbs have been established as among the most distant objects detectable in the universe , with a spectroscopically confirmed event at @xmath4 ( grb 090423 ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) and a photometric candidate at @xmath5 ( grb 090429b ; * ? ? ?",
    "such observations can provide valuable constraints on star formation in the early universe , illuminate the locations and properties of some of the earliest galaxies and stars , and probe the epoch of reionization .",
    "( e.g. , * ? ? ?",
    "* and references therein ) .",
    "further , the relatively simple spectra of grb afterglows compared to other cosmic lighthouses makes it easier to both identify their redshifts and extract useful spectral features such as neutral hydrogen absorption signatures for the study of cosmic reionization .",
    "( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "however , such benefits can only be realized if spectra are obtained with large - aperture telescopes before the afterglow fades beyond the level required to obtain a useful signal , typically within a day after the grb .    as such",
    ", there has been a long - standing effort to extract a measure of a grb s redshift from its early time , high - energy signal , with a primary goal of the rapid identification of high-@xmath0 candidates .",
    "this might appear in principle to be a straightforward exercise ; for instance , distant grbs should on average appear fainter and longer - duration than nearby events due to distance and cosmological time dilation , respectively . in practice , however , the large intrinsic diversity of grbs , as well as thresholding effects , confounds the straightforward use of early - time observations in divulging redshift and other important properties . while much effort has gone into tightening the correlations between high - energy properties in order to homogenize the sample for use as a luminosity ( and hence distance / redshift ) predictor ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , there has been significant debate as to whether some of these relations are actually due to thresholding effects specific to the detectors rather than intrinsic physical properties of the grbs ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "regardless , whether or not these inferred relationships are actually physical or simply detector effects would not affect their utility as a _ detector - specific _ parameter prediction tool . by restricting ourselves to _ swift _ events only , we avoid the uncertainty of whether certain correlations remain when using different detectors .    with this in mind , we set out to search for indications of high - redshift grbs in the rich , mostly homogeneous dataset provided by 6 + years of grb observations by the three telescopes onboard _ swift _",
    "( bat ; @xcite , xrt ; @xcite , uvot ; @xcite ) .",
    "past studies exploring high-@xmath0 indicators have used hard cuts on certain features such as uvot afterglow detection , burst duration , and inferred hydrogen column density ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , regression on such features @xcite , and combinations of potential grb luminosity indicators @xcite . in this work , we take a different approach by utilizing supervised machine learning algorithms , specifically random forest classification , to make follow - up recommendations for each event automatically and in real time .",
    "particular attention is paid to careful treatment of performance evaluation by using cross - validation (  [ sec : results ] ) , a robust methodology to guard against over - fitting and the circular practice of testing hypotheses using the same data that suggested ( and constrained ) them .",
    "the primary driving force of this study is simple : _ _ given limited follow - up time available on telescopes , we want to maximize the time spent on high-@xmath0 grbs _ _ : a compromise between only keeping the most interesting events and having enough data to train on .",
    "however , we have explored performance of different redshift cuts ; see  [ sec : finalclassifier ] . ] . to this end",
    ", we provide a deliverable metric , explained in ",
    "[ sec : deliverables ] , to assist in the decision making process on whether to follow up a new grb .",
    "real - time distribution of this metric is available for each new _ swift _ trigger via website and rss feed .",
    "the structure of this paper is as follows : in  [ sec : obs ] we outline the collation of the data , and describe the particular grb features utilized in redshift classification . in ",
    "[ sec : methods ] , the random forest algorithm is detailed , along with some specific challenges posed by this particular data set .",
    "performance metrics of the classifiers are presented in  [ sec : results ] , and in  [ sec : application ] we discuss the results of testing the classifiers on additional grbs , both with and without known redshifts . finally , our conclusions are given in ",
    "[ sec : conclusions ] .",
    "the _ swift _ bat constantly monitors 1.4 steradians on the sky over the energy range @xmath6 kev .",
    "grb triggering can occur either by a detection of a large gamma - ray rate increase in the bat detectors ( `` rate trigger '' ) , or a fainter , long - duration event recovered after on - board source reconstruction reveals a new significant source ( `` image trigger '' ) . a rough ( @xmath2 3 arcmin ) position is determined , and if there are no overriding observing constraints , the spacecraft slews to allow the xrt and uvot to begin observations , typically between 1 and 2 minutes after the trigger .",
    "the xrt observes between the energy range of @xmath7 kev and detects nearly all of the grbs it can observe rapidly enough , providing positional accuracies of @xmath8 arcseconds within minutes .",
    "the uvot is a 30 cm aperture telescope that can observe in the range of @xmath9 nm . due to the relatively blue response of this telescope ,",
    "it can not detect highly reddened sources due to either dusty environments or ( more relevant to this analysis ) high - redshift origins .    at each stage in the data collection process , information is sent to astronomers on the ground via the gamma - ray bursts coordinates network ( gcn ) providing rapid early - time metrics .",
    "the more detailed full data are sent to the ground in @xmath2 90 minute intervals starting between roughly @xmath10 hours after the burst .",
    "for our dataset , we have collected data after various levels of processing directly from gcn notices , online tables and automated pipelines @xcite that process and refine the data into more useful metrics .",
    "tens of attributes and their estimated uncertainties ( when available ) are parsed from the various sources and collated into a common format .    in order to evaluate our full dataset in an unbiased way",
    ", we restricted ourselves to using features which have been generated for all possible for how our algorithm treats missing values . ] past events and are automatically generated for future events .",
    "this is the primary reason we do not include potentially useful features such as relative spectral lag ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* and references therein ) which has been utilized as a redshift indicator with smaller and pre-_swift _ datasets @xcite but requires a larger spectral coverage than _ swift _ alone can provide . however , our technique is easily extendable to include additional useful features should they be homogeneously determined for past grbs and automatically available in real - time for new events , and therefore we strongly encourage the automated distribution of any such data products .    because the addition of too many features causes a decrease in classifier performance ( see  [ sec : comparesets ] ) ,",
    "a total of 12 features were kept for our final classifier ( table [ tab : features ] ) , 10 of which were derived from bat gamma - ray measurements , one from xrt observations , and one from uvot observations . of the 10 bat features ,",
    "4 were parsed directly from gcn notices , the most rapidly available ( and thus unrefined ) source of information on grbs .",
    "the parameter @xmath11 is a rough measurement of the duration of the bat trigger event and thus a lower limit on the total duration of the grb .",
    "the binary feature of whether or not the event was a rate trigger is an indicator of the signal - to - noise of an event , for only the brighter events are detected as rate triggers , while those on the threshold of detection are image triggers .",
    "the final two gcn features are also rough indicators of brightness : @xmath12 is the significance ( in sigma ) of the detected source in the on - board reconstruction of the bat image , and @xmath13 is the peak count rate observed during the duration of the event .",
    "lll bat rate trigger ? & bat prompt & gcn notices + @xmath12 & bat prompt & gcn notices + @xmath13 & bat prompt & gcn notices + @xmath11 & bat prompt & gcn notices + uvot detection ? & nfi prompt & gcn notices + @xmath14 & processed & @xcite + @xmath15 & processed & @xcite + @xmath16 & processed & @xcite + @xmath17 & processed & @xcite + @xmath18 & processed & @xcite + @xmath19 & processed & @xcite + @xmath20 & processed & @xcite    [ tab : features ]    five higher - level bat - derived attributes were pulled from online tables automatically updated by the pipeline described in @xcite .",
    "the feature @xmath15 is the power - law index before the peak of the band - function fit to the gamma - ray spectrum ( typically clustered around @xmath21 ) .",
    "another parameter in the band - function fit , @xmath16 , is the energy at which most of the photons are emitted .",
    "the fluence , @xmath17 , is the total gamma - ray flux ( 15350 kev ) integrated over the duration of the burst .",
    "@xmath18 is simply the maximum signal - to - noise achieved over the duration of the light curve .",
    "finally , @xmath19 is a measure of the burst duration , defined to be the time interval over which the middle 90% of the total background - subtracted flux is emitted .",
    "one additional `` metafeature '' is derived from the bat data . in principle , if we knew in detail the intrinsic distributions of grb observables ( fluence , hardness , duration ; see * ? ? ?",
    "* ) as a function of redshift , measurements of these observables for a new event could be used to directly evaluate the expected redshift .",
    "a detailed fitting of the intrinsic distributions for swift is presented in @xcite , and we use the parametrized intrinsic distributions there to calculate the posterior probability redshift distributions for each grb in our sample ( see , e.g. , figure 8 in * ? ? ?",
    ", we further condense this distribution into one useful feature : @xmath20 , the fraction of posterior probability at @xmath22 .",
    "finally , two features are extracted from data taken by the two narrow - field instruments onboard _ swift _ , one each from the xrt and uvot .",
    "the feature @xmath14 is the excess neutral hydrogen column ( above the galactic value ) inferred from the xrt pc ( photon - counting mode ) data , obtained from the @xcite pipeline .",
    "the last feature is simply a binary measure of whether or not the grb afterglow was detected by the uvot .",
    "while most of these features have associated uncertainties , the proper treatment of uncertainties in attributes is an area of ongoing research in machine learning ( e.g. * ? ? ?",
    "some methods call for the uncertainties to be treated as attributes in and of themselves , but we found that the addition of these relatively weak features were actually detrimental for our small dataset ( see , e.g. , fig .",
    "[ fig : useless ] ) .",
    "we also considered an approach by which features with large uncertainties were considered poor measurements and were instead marked as missing values .",
    "however , this had a negligible effect on our final classifier performance , so for simplicity we treat all values as precisely known .",
    "we collated data on all _ swift _ grbs with rapidly available bat data up to and including grb 100621a - 471 in total .",
    "specifically , this excludes bursts which were not identified in real - time due to the event being below the standard triggering threshold or occurring while the satellite was slewing to a new location . of these , 39 are short grbs ( defined for the purposes of this study to be those with @xmath23 s alone is not a strong enough discriminator to definitively assign a particular grb to one class or another ( `` short '' versus `` long '' ; see @xcite for discussion ) . in this study",
    ", we will accept the few errant bursts from the `` short '' class included in our sample as additional noise in our method . ] ) , which are believed to arise from a different physical process and are thus removed from the sample .",
    "for further uniformity in the sample , bursts without rapid ( @xmath24 hour ) xrt / uvot follow - up are also removed , leaving 347 events were removed because of this . ] . of the remaining long bursts in our sample ,",
    "135 had reliable redshifts ( table [ tab : trainingredshifts ] ) and were thus included in our training data set ( table [ tab : training ] ) .",
    "the additional 212 long bursts without secure redshift determinations are explored further in ",
    "[ sec : unknownz ] .",
    "exploratory data analysis shows preliminary indications of which of these features will be most useful for classification .",
    "figure [ fig : featuresvfeatures ] shows several 2d slices of the feature space , with the high-@xmath0 bursts highlighted .",
    "llll 050223 & 4.30e-01 & 0.5915 & @xcite + 050315 & 3.57e-01 & 1.949 & @xcite + 050318 & 6.86e-01 & 1.44 & @xcite + 050319 & 5.90e-01 & 3.2425 & @xcite + 050416a & 7.68e-01 & 0.6535 & @xcite [ tab : trainingredshifts ]    lllllllllllll 050223 & -1.74e+00 & 6.70e+01 & 8.75e-07 & 1.34e+01 & -2.37e-01 & 1.74e+01 & 9.00e+00 & 7.26e+02 & yes & 8.19e+00 & no & 1.74e-01 + 050315 & ?",
    "& 4.33e+01 & 4.32e-06 & 4.37e+01 & 9.60e-02 & 9.46e+01 & 8.00e+00 & 2.60e+02 & yes & 1.02e+00 & no & 9.27e-02 + 050318 & -1.22e+00 & 5.01e+01 & 1.41e-06 & 4.90e+01 & 1.80e-02 & 3.10e+01 & 9.00e+00 & 2.05e+02 & yes & 5.12e-01 & yes & 6.29e-02 + 050319 & -2.00e+00 & 4.47e+01 & 1.87e-06 & 1.82e+01 & 1.50e-02 & 1.54e+02 & 1.00e+01 & 2.63e+02 & yes & 1.02e+00 & yes & 1.48e-01 + 050416a & -7.24e-01 & 1.50e+01 & 3.40e-07 & 1.75e+01 & 2.34e-01 & 2.91e+00 & 1.10e+01 & 1.65e+02 & yes & 5.12e-01 & yes & 4.35e-03 [ tab : training ]",
    "the resource allocation approach we have taken here naturally manifests itself as a classification problem : deciding whether or not to follow up a new event is simply a two - class problem of `` observe '' or `` do not observe , '' and the methodology presented here can be applied to any problem that can be broken up in this way .",
    "this was the primary motivation of using classification instead of a regression or `` pseudo-@xmath0 '' approach for this study .",
    "the primary disadvantage of classification for the particular problem of high - redshift identification is that all instances above and below the class division ( chosen here to be @xmath25 ) are treated equally ; e.g. , a burst with @xmath26 has the same influence on our inference about `` high '' bursts as a burst with @xmath27 .",
    "however , classification has advantages over regression in that it is a conceptually much simpler problem , and most of the difficulties encountered due to the unbalanced , small dataset of interest here would only be aggravated by an extension to regression .",
    "further , our approach capitalizes on the fact that one of our predictors ( lack of uvot detection ) is itself a binary feature with an understood physical connection to redshift due to the lyman cutoff .",
    "this is due to the fact that photons with wavelengths smaller ( thus higher energy ) than the lyman limit of @xmath28 would be almost completely absorbed by neutral gas in the host galaxy and intergalactic star forming regions .",
    "a redshift of @xmath29 might therefore be considered a natural cutoff point for the high-@xmath0 class , but due to so few training events at this high redshift ( @xmath30 ) , we opted for the more conservative cutoff point of @xmath25 ( @xmath31 ) . ] .",
    "a supervised classification algorithm uses a set of training data of known class to estimate a function for assigning data points to classes based on their features .",
    "the statistics and machine learning communities have developed many classification algorithms , including support vector machines ( svm ) , nave bayes , neural networks , and gaussian mixture models .",
    "we use random forest ( rf * ? ? ?",
    "* ) for its ability to select important features , resist overfitting the data , model nonlinear relationships , handle categorical variables , and produce probabilistic output .",
    "these strengths , along with a record of attaining very high classification accuracy relative to other algorithms have led to widespread use of random forest in the astronomy community   ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) . in this work , we utilized custom ` r ` software built around the ` randomforest ` package to generate classifiers and evaluate performance .",
    "random forest is an ensemble classifier that averages together the outputs from many decision trees , a common example of which is classification and regression trees ( cart , * ? ? ?",
    "* ) . in rf ,",
    "the decision trees are constructed by recursive binary splitting of the high - dimensional feature space , where each split is performed with respect to a particular feature .",
    "for example , the decision tree might split the data on feature @xmath18 using value @xmath32 , in which case all observations with @xmath33 are placed in one group and the rest placed in the second group . as these are binary splits , for convenience we henceforth refer to observations going `` left '' or `` right '' of each split as an analogue for the decision made at that split .    for each split , the feature and specific split - point are chosen so as to best separate the observations into the classes , by using some objective function .",
    "we use the gini index , a standard objective function for classification @xcite . at",
    "any given node in a tree and some proposed split @xmath34 , let @xmath35 number of high - priority ( in our case , high-@xmath0 ) events that go to the left of the split , @xmath36 number of low - priority events that go left . define @xmath37 and @xmath38 similarly , replacing left with right .",
    "let @xmath39 , the total number of observations that go left . similarly define , @xmath40 , for the total number of observations that go right . the gini criterion is defined as @xmath41 and the split that minimizes this value over the random subset of features considered at each node features",
    "were considered , guided by the default practice in the ` randomforest ` routine of @xmath42 , where @xmath43 is the total number of features . ]",
    "is chosen .",
    "for instance , in the ideal case where the split on a particular feature completely separates all the instances of the two classes from each other , the gini index reaches a minimum of 0 .",
    "the splitting is done recursively , continuing down each subgroup until all of the observations in each final group ( `` terminal node '' ) are of a single class .",
    "the process is known as `` growing a tree '' because each split can be visualized as generating two branches from a single branch to produce a tree - like structure .",
    "once a tree is constructed from the training data , each new observation starts at the root node ( the top split in the tree ) and , recursively , the splitting rules determine the terminal node to which the observation belongs .",
    "the observation is assigned to the class of the terminal node .    to create the rf classifier ,",
    "a sufficiently large number of decision trees are constructed , resulting in a `` forest '' .",
    "each decision tree is generated from an independent bootstrap sample @xcite ; samples are drawn with replacement from the original data set , resulting in a new data set of the same size as the original , with on average 2/3 of the original observations present at least once .",
    "additionally , only a random subset of the features is eligible for splitting at each node .",
    "many decision trees are grown with each tree slightly different due to the bootstrap sampling and random selection of features at each split .",
    "rf classifies new observations by averaging the outputs of each tree in the ensemble .",
    "training observations can be classified by using all trees where that observation was not used in the bootstrap sampling stage .",
    "this produces estimates of error rates and class probabilities for each observation that are not overfit to the training data .",
    "error rates and probabilities computed using this method are known as `` out - of - bag '' estimates .      as mentioned in ",
    "[ sec : obs ] , certain features , namely @xmath15 and @xmath14 , were occasionally unable to be determined from model fits to the data and are thus missing for certain observations .",
    "we handle missing values by imputation , where missing values for features are assigned estimated values . for missing values of continuous features , we assigned the median of all observations for which that feature is non - missing . missing categorical features",
    "are assigned the mode of all observations for which the feature is non - missing .",
    "this is one of the simplest imputation methods and has the advantage of being transparent and computationally cheap .",
    "we experimented with a more sophisticated imputation method , ` missforest ` , that iteratively predicts the missing values of each feature given all the other features @xcite , but as it produced similar error rates to median imputation , we opted for latter , simpler approach in our final classifier .",
    "a further challenge in this data set is the imbalance between classes .",
    "we are training on 135 bursts , only 18 of which are in the high-@xmath0 class  an asymmetry present in many resource allocation problems where the goal is to prioritize the rarer events . without modification , standard machine",
    "learning classification algorithms applied to imbalanced data sets attain notoriously suboptimal performance @xcite , and often result in simply classifying all unknown events as the more common class .",
    "as we care more about correctly classifying the rarer events , misclassifications of high-@xmath0 events must be punished more strongly than vice versa .",
    "in random forest , classes may be weighted in order to overcome the imbalance by altering the splits chosen by gini and the probabilities assigned to classes in the terminal nodes of each tree @xcite .",
    "we utilized the ` classwt ` option in the ` randomforest ` package , which accounts for class weights in the gini index calculation ( eq . [ eqn : gini ] ) when splitting at the nodes ( liaw 2011 , private communication ) , similar to weighting techniques used in single cart trees @xcite .",
    "if we are weighting high - priority observations ( e.g. @xmath1 grbs ) by @xmath44 and low - priority observations by @xmath45 , we let , @xmath46 let @xmath47 , the weighted total number of observations that go left . similarly define , @xmath48 , for the weighted total number of observations that go right .",
    "the gini criterion ( eq . [ eqn : gini ] ) is evaluated with the weighted values , and the split that minimizes this value is chosen .",
    "we tested a variety of weight choices by fixing @xmath45 to be unity and varying @xmath44 over a range of values .",
    "the results of this test are presented in  [ sec : weights ] , which demonstrates the effects of class weight choice on classifier performance .",
    "with the background above in hand , we now describe our resource allocation algorithm and its utility for the prioritization of high-@xmath0 grb follow - up . in our application ,",
    "the data are described in  [ sec : obs ] and the classes are high- and low - redshift grbs , with @xmath25 as the boundary between the classes .",
    "our primary goal is to provide a decision for each new grb : should we devote further resources to this event or not ?",
    "this decision may be different for each astronomer , as it is dependent on the amount of follow - up time available .",
    "implicit in this goal is the desire to follow up on as many truly high - redshift bursts as possible , under a set of given telescope time constraints . directly using the results of an off - the - shelf classifier for this task ( i.e.",
    ", strictly following - up on events labeled as `` high - priority '' ) is suboptimal .",
    "if too few events are labeled as high - priority , there would be an under - utilization of available resources .",
    "if too many are being labeled as high priority , simply following up on the first ones available would preclude any prioritization of events within this high - priority class .",
    "these issues can be avoided by instead tailoring the follow - up decision to the resources available ( in this case , the available telescope time devoted to high-@xmath0 grb observations ) .",
    "the rate method works as follows : let @xmath49 be the fraction of events one has resources to follow up on can always be adjusted without penalty as available resources change . ] .",
    "first we construct a random forest classifier using the training data with known response ( in this case redshift ) .",
    "we compute the probability of each training event being high - priority using out - of - bag probabilities ( see  [ sec : rf_class ] ) . for each new event",
    ", we obtain a probability of it being high priority using the random forest classifier , and compute the fraction of training bursts that received a higher probability of being high - priority than this new burst .",
    "a new burst is assigned rank @xmath50 , with @xmath51 training events having a lower probability of being high priority .",
    "then , for @xmath52 total training bursts , we obtain a learned probability rank for the new event of @xmath53 .",
    "this leads to a simple decision metric for each new event : if @xmath54 is less than the desired fraction of events a particular observer wishes to follow up ( @xmath55 ) , follow - up observations are recommended .",
    "for instance , if one can afford to follow up on @xmath56 of all observable grbs , then the desired follow - up fraction is @xmath57 , and follow - up would be recommended for all events assigned a @xmath58 .",
    "an illustration of this process in action is shown in figure [ fig : ratesample ] .",
    "the desired fraction of follow - up events @xmath49 can be dynamically changed without penalty ; if the amount of available resources changes , one simply needs to raise or lower this cut - off value accordingly .",
    "our training data consist of 135 bursts , 18 of which are high - redshift ( @xmath59 ) .",
    "our primary measure of performance is efficiency , defined here as the fraction of high bursts that we that we follow up on relative to the number of total high - z grbs that occurred ( @xmath60 ) .",
    "a secondary performance measure is purity , the number of followed - up events that were actually high-@xmath0 ( @xmath61 ) .",
    "we measure performance using 10-fold cross - validation  @xcite , where 90% of the data is used to construct a classifier and predict on the remaining 10% of events .",
    "each line in the following performance plots is the cross - validated performance averaged across 100 trials of 10-fold cross - validation in order to reduce variability due to randomness in training / test subset selection .      as described in ",
    "[ sec : imbalance ] , one of the primary challenges in learning on this dataset is the simple fact that there are comparatively few high-@xmath0 events on which to train .",
    "if simply getting the most classifications correct were the primary performance metric , as it is in many classification problems , classifying _ all _ new events as low - redshift would be considered a strong classifier since so few events are in the high-@xmath0 class . however , since our objective is to identify the best candidates of this rare class , we punish misclassifications of high-@xmath0 grbs more heavily to achieve higher efficiency and purity ( outlined above ) for a given fraction of followed - up events .",
    "thus , in selecting the best weight for our classifier , we compared the efficiency and purity of high - z classification for various choices of the weight @xmath44 using the feature set shown in table [ tab : features ] . while the relative probability ranking of the grbs stayed relatively stable over weight choices ( figure [ fig : bumps ] ) ,",
    "a clear trend emerges when comparing classification performance ( figure [ fig : weightsefficiency ] ) .",
    "as expected , punishing misclassifications of the smaller , more desirable high-@xmath0 class cause more of these rare events to be correctly identified . beyond a weight of  10 ,",
    "however , a ceiling is reached where further weight increases show zero change in classification performance .",
    "this is therefore the weight chosen for all subsequent performance comparisons .            as mentioned in ",
    "[ sec : obs ] , early testing indicated that the addition of too many features rapidly degraded the predictive power of the final classifier .",
    "this is due to a manifestation of the so - called `` curse of dimensionality '' known as hughes phenomenon @xcite , where for a fixed number of training instances , the predictive power decreases as the dimensionality increases .",
    "this appears to contradict the conventional wisdom that random forest does not overfit , and thus it is better to use many features .",
    "however , we note that resistance to overfitting is different from signal being drowned in noise . with enough noisy features",
    ", correlations between class and a useless feature will happen purely by chance , preventing true relationships from being found .    to visualize this effect for our data",
    ", we took our nominal feature set and continually added features with no predictive power ( random samples from the uniform distribution ) to quantify the degradation in performance of the resultant classifiers .",
    "the random features were re - generated for each of the 100 trials , and the cross - validated results are shown in figure [ fig : useless ] . the fact that even a small number of useless features causes a noticeable decrease in performance highlights the importance of attribute selection .",
    "however , we note that too much fine tuning of attribute feature selection choices  such as testing all combinations of features and seeing which one gives the best performance  would overfit to the data and give an underestimate of the true error .         taking into account the above issues of multiple feature set choices , the deleterious effect of useless features , and the performance with various weight choices to help with imbalance , we have developed a classifier which we believe to be robust and powerful .",
    "the full feature set utilized is shown in table [ tab : features ] , and the weight chosen is described in  [ sec : weights ] .",
    "the final cross - validated estimates of @xmath54 for the training data are shown alongside the corresponding redshifts in table [ tab : trainingredshifts ] . by referencing a particular point on the @xmath62-axis of figure [",
    "fig : efficiencypurity4 ] ( left panel ) one can determine what fraction of high bursts can be detected for a particular amount of telescope follow - up time .",
    "for example , if we are able to follow up on 20% of all grbs detected by _ swift _",
    ", then the bursts recommended for follow - up by our classifier will contain on average @xmath63 of all grbs with redshift greater than 4 that occur .",
    "following - up on @xmath64 of all bursts will yield @xmath65 of all grbs with redshift",
    "greater than 4 , and following - up on the top @xmath66 of candidates will result in nearly all of the high-@xmath0 events being observed ( @xmath67 ) .",
    "purity is shown in the right panel of figure [ fig : efficiencypurity4 ] , which describes how many of the followed - up bursts will actually be high - redshift .",
    "following up on 20% of all bursts would result in @xmath68 of the followed - up events being high - redshift , and @xmath69 of followed up bursts would be high - redshift if @xmath70 of grbs were followed - up on .",
    "as the high / low class division of @xmath25 was relatively arbitrary , for completeness we also re - trained the classifier and calculated performance results using cutoff values of @xmath71 ( fig .",
    "[ fig : efficiencypurity35 ] ) and @xmath72 ( fig .",
    "[ fig : efficiencypurity3 ] ) .",
    "note that while the sample size of ` high ' events more than doubles by lowering the cutoff value to @xmath72 , the resultant efficiency decreases significantly .",
    "we attribute this effect to a decrease in the predictive power of certain attributes at lower redshift .",
    "for instance , the @xmath73 population has proportionally many more instances of uvot detections in its ` high-@xmath0 ' class than the @xmath1 population , which reduces its effectiveness as a discriminating feature .",
    "there are several complications in identifying the relative importance of features in contributing to selecting high-@xmath0 candidates .",
    "to an extent , simple scatter plots such as those in figure [ fig : featuresvfeatures ] can give an indication as to what features are best at separating the classes , but these fail to account for the complex interactions between features occurring within the rf classification .",
    "the effects of removing features from the dataset and then re - constructing the classifier give another indication of feature importance , but fail to account for redundancy in the features ; if two features have similar predictive properties , removing one will just cause the other to take its place .",
    "nevertheless , such an experiment can be illustrative , and the results are shown in figure [ fig : featurecompare ] . in general , the removal of an individual feature does not cause a significant change in performance , and the small changes that do occur trend toward a degradation in the number of high-@xmath0 bursts identified , implying that few if any of the features in the dataset are useless .",
    "the features that cause the largest degradation in performance upon their removal are @xmath74 and @xmath75 indicating that these features are both useful predictors and are not fully redundant with other features .",
    "note that the slight improvement in performance from the removal of the temporal features @xmath19 and @xmath11 is consistent with these values having little - to - no predictive power , in agreement with the recent findings of @xcite showing a lack of time dilation signatures in grb light curves .",
    "a natural application of our methodology is to use it to predict the follow - up metric @xmath54 for the remaining majority of long - duration _ swift _ grbs with no known redshift , providing a list of the top candidates predicted to be high-@xmath0 .",
    "this application is precisely how rate grb-@xmath0 could be used in practice on new events , albeit one - at - a - time rather than on many at once .",
    "we caution that due to the natural selection effect of grbs with measured redshifts having a higher likelihood of being brighter events , the bursts with unknown redshifts are likely to comprise a somewhat different redshift distribution than our training dataset .",
    "the primary consequence of this is the interpretation of the user - desired follow - up fraction @xmath49 and the prioritization parameter @xmath54 . in principle",
    ", the classifier was calibrated such that , over time , a fraction @xmath49 of new events will have affirmative follow - up recommendations ( that is , events such that @xmath76 ) . however",
    ", this will not necessarily be the case if the full redshift distribution of grbs makes up a different population than our training data .    to test this , we calculated @xmath54 for each of the remaining 212 grbs with unknown redshift that met our culling criteria outlined in ",
    "[ sec : obs ] . from this",
    "we could calculate the fraction of grbs followed up ( @xmath76 ) for each cutoff value of @xmath49 .",
    "the results of this test are shown in figure [ fig : popcompare_unknownz ] .",
    "for the chosen weight of 10 ( see  [ sec : weights ] ) , the @xmath49-values are well calibrated with the final follow - up recommendations .",
    "the resultant @xmath54 priorities are listed in table [ tab : unknown ] .",
    "these values can be interpreted as a ranking of which of these past events without secure redshift determinations are most likely to be at high - redshift .",
    "llllllllllllll 050215a & 3.19e-01 & -1.29e+00 & 4.14e+02 & 1.34e-06 & 1.02e+01 & ? & 6.65e+01 & 9.00e+00 & 6.94e+02 & yes & 8.19e+00 & no & 9.81e-02 + 050215b & 1.78e-01 & ? & 3.01e+01 & 2.86e-07 & 1.44e+01 & 5.70e-02 & 8.50e+00 & 8.00e+00 & 3.00e+02 & yes & 2.05e+00 & no & 1.06e-01 + 050219a & 4.22e-01 & 1.87e-02 & 1.00e+02 & 4.91e-06 & 5.08e+01 & 9.10e-02 & 2.50e+01 & 8.00e+00 & 1.93e+02 & yes & 1.02e+00 & no & 1.12e-01 + 050219b & 7.33e-01 & -8.94e-01 & 1.12e+02 & 1.94e-05 & 7.19e+01 & 8.80e-02 & 2.09e+01 & 1.70e+01 & 4.09e+02 & yes & 1.02e+00 & no & 2.73e-02 + 050326 & 7.04e-01 & -1.04e+00 & 3.41e+02 & 1.70e-05 & 1.33e+02 & 3.80e-02 & 3.02e+01 & 2.10e+01 & 1.84e+04 & yes & 5.12e-01 & no & 5.67e-02 [ tab : unknown ]         since the cutoff date in our training set ( june 21 , 2010 ) until sept . 1 , 2011 ,",
    "there have been 15 long duration _",
    "swift _ grbs with reliable redshifts from which we constructed an independent validation set to test our method .",
    "the feature values for these grbs are presented in table [ tab : validation ] .",
    "while none of these events were over our high - redshift cutoff value of @xmath25 , it is still possible , though challenging , to use low-@xmath0 events ( either by direct redshift measurement or by the identification of a coincident blue host galaxy ) as a consistency test .",
    "we would expect that the purity at a given @xmath49 would be lower than the fraction of recommended follow - up events ( @xmath76 ) _ without _ a secure low-@xmath0 determination .",
    "for instance , @xmath77 has a purity of @xmath68 , so no more than @xmath78 of events with @xmath79 should be definitively low - redshift .",
    "the validation grbs were run through the rate grb-@xmath0 classifier , and their resultant @xmath54 values are shown in table [ tab : validationredshifts ] along with their corresponding redshifts .",
    "the smallest @xmath54 value of these events is @xmath80 , meaning that none of these events would have been recommended for high-@xmath0 follow - up for anyone wishing to observe fewer than 30% of events . while these values are certainly consistent with our expected purity , it is not particularly constraining , as it would have been very unlikely for this almost - random selection of grbs to violate this constraint by chance alone , even if the classifier had no predictive power .",
    "a more constraining test is the identification of high-@xmath0 events with high @xmath54 for comparison with the expected efficiency .",
    "two events not included in our training set have had recent high-@xmath0 identifications : grb 090429b with strong photometric evidence for being @xmath81 @xcite , and the spectroscopic identification of grb 111008a at @xmath82 @xcite .",
    "the former has a @xmath54 value of @xmath83 , consistent with the expected efficiency .",
    "however , grb 111008a has a @xmath54 of @xmath84 , a value above which we would have expected to find no more than @xmath85 of high-@xmath0 events .",
    "this outlier seems likely due to the extreme brightness of the event ( among the brightest @xmath86 of _ swift _ bursts in the observer frame , and top @xmath87 in the rest frame ) .",
    "indeed , compared to all 18 high-@xmath0 events in the training set , grb 111008a has the most extreme values towards the ` wrong ' end of three of the highly important features identified in  [ sec : importance ] ( @xmath88 , and @xmath13 ) and also has the fourth largest @xmath89 . in later iterations of rate grb-@xmath0",
    ", this event ( and all new grbs with secure redshifts ) will be added to the training data to re - generate the classifier and further improve its robustness against such outliers .",
    "llllllllllllll 100728b & 6.07e-01 & -1.64e+00 & 8.19e+01 & 2.54e-06 & 2.06e+01 & 3.90e-02 & 1.15e+01 & 9.07e+00 & 1.47e+02 & yes & 1.02e+00 & yes & 1.01e-01 + 100814a & 6.81e-01 & -1.11e+00 & 1.35e+02 & 9.33e-06 & 9.80e+01 & ? & 1.77e+02 & 1.91e+01 & 8.34e+02 & yes & 1.02e+00 & yes & 1.80e-01 + 100816a & 9.33e-01 & -5.71e-01 & 1.42e+02 & 2.71e-06 & 5.80e+01 & 1.13e-01 & 2.50e+00 & 2.29e+01 & 1.42e+03 & yes & 1.02e+00 & yes & 5.55e-02 + 100901a & 4.00e-01 & -1.55e+00 & 1.28e+02 & 3.41e-06 & 1.78e+01 & 4.00e-02 & 4.59e+02 & 7.70e+00 & 4.50e+02 & yes & 8.19e+00 & yes & 2.25e-01 + 100906a & 1.00e+00 & -1.66e+00 & 1.57e+02 & 1.37e-05 & 1.36e+02 & ? & 1.17e+02 & 1.05e+01 & 1.91e+02 & yes & 5.12e-01 & yes & 7.39e-02 + 101219b & 6.30e-01 & -1.89e+00 & 4.97e+01 & 3.75e-06 & 1.00e+01 & -8.00e-03 & 4.18e+01 & 7.63e+00 & 8.44e+02 & no & 6.40e+01 & yes & 1.07e-01 + 110205a & 3.19e-01 & -1.39e+00 & 9.75e+01 & 1.98e-05 & 1.50e+02 & 1.10e-02 & 2.77e+02 & 1.00e+01 & 1.48e+03 & no & 6.40e+01 & yes & 1.45e-01 + 110213a & 9.33e-01 & -1.82e+00 & 6.70e+01 & 8.77e-06 & 3.10e+01 & 4.00e-02 & 4.31e+01 & 1.21e+01 & 2.05e+02 & yes & 1.02e+00 & yes & 5.32e-02 + 110422a & 1.00e+00 & -6.23e-01 & 1.11e+02 & 5.17e-05 & 2.10e+02 & 1.58e-01 & 2.67e+01 & 7.19e+00 & 8.20e+01 & yes & 1.28e-01 & yes & 2.49e-02 + 110503a & 9.33e-01 & -8.18e-01 & 1.42e+02 & 1.43e-05 & 6.27e+01 & 2.60e-02 & 9.31e+00 & 2.04e+01 & 1.26e+03 & yes & 1.02e+00 & yes & 1.89e-02 + 110715a & 9.33e-01 & -1.06e+00 & 8.94e+01 & 1.40e-05 & 2.02e+02 & 1.64e-01 & 1.31e+01 & 1.19e+01 & 1.47e+02 & yes & 1.28e-01 & yes & 9.70e-03 + 110726a & 5.04e-01 & -2.97e-01 & 4.27e+01 & 2.07e-07 & 1.51e+01 & -4.90e-02 & 5.40e+00 & 8.60e+00 & 2.24e+02 & yes & 1.02e+00 & yes & 1.14e-01 + 110731a & 1.00e+00 & -1.19e+00 & 4.06e+02 & 1.25e-05 & 1.30e+02 & 7.20e-02 & 4.66e+01 & 2.46e+01 & 2.32e+03 & yes & 1.02e+00 & yes & 5.09e-02 + 110801a & 9.33e-01 & -1.84e+00 & 6.07e+01 & 6.85e-06 & 3.56e+01 & 2.90e-02 & 4.00e+02 & 7.83e+00 & 3.50e+02 & yes & 4.10e+00 & yes & 1.98e-01 + 110808a & 5.56e-01 & ? & 2.59e+01 & 4.27e-07 & 1.01e+01 & 2.17e-01 & 3.94e+01 & 7.19e+00 & 4.26e+02 & yes & 8.19e+00 & yes & 1.06e-01 [ tab : validation ]    llll 100728b & 5.63e-01 & 2.106 & @xcite + 100814a & 7.04e-01 & 1.44 & @xcite + 100816a & 9.33e-01 & 0.8035 & @xcite + 100901a & 4.22e-01 & 1.408 & @xcite + 100906a & 9.19e-01 & 1.727 & @xcite + 101219b & 6.07e-01 & 0.5519 & @xcite + 110205a & 3.19e-01 & 2.22 & @xcite + 110213a & 8.89e-01 & 1.46 & @xcite + 110422a & 9.33e-01 & 1.770 & @xcite + 110503a & 9.33e-01 & 1.613 & @xcite + 110715a & 8.89e-01 & 0.82 & @xcite + 110726a & 5.56e-01 & 1.036 & @xcite + 110731a & 9.33e-01 & 2.83 & @xcite + 110801a & 8.67e-01 & 1.858 & @xcite + 110808a & 5.63e-01 & 1.348 & @xcite [ tab : validationredshifts ]      extracting indications of redshift from promptly available information has been a continuing goal of grb studies since their cosmological origins were discovered nearly 15 years ago .",
    "several potential luminosity indicators were pursued with the optimistic goal of using grbs as standard candles for cosmological studies .",
    "the efficacy of individual indicators toward this goal proved to be limited , and a physical origin of the relations has been contested , with authors attributing them instead to detector thresholding or other selection effects @xcite . while these studies have ruled out the majority of such relations as intrinsic to grbs themselves , prompt properties can still be used as redshift indicators if the systematics are properly accounted for .",
    "several recent studies have attempted to use combinations of features to determine `` pseudo - redshifts '' for grbs . in an extension of work by @xcite",
    ", @xcite used a combination of six purported luminosity relations .",
    "further , @xcite has explored linear regression as a tool for predicting grb redshifts using the dataset from @xcite . as data derived from multiple satellites were used , these studies are particularly vulnerable to the detector selection effects mentioned above .",
    "some works avoided the complications of regression and instead focused upon the simple selection of high-@xmath0 candidates for follow - up purposes .",
    "@xcite utilized a sample of _ swift_-only bursts ( thus avoiding detector effect biases ) and used hard cuts on three features ( @xmath19 , lack of uvot detection , and high - galactic latitude ) for high-@xmath0 candidate selection .",
    "@xcite extended upon this work with the additional feature of peak photon flux .",
    "several issues prevent a direct comparison among the various methods of the effectiveness at separating high-@xmath0 events .",
    "these include the usage of different features from each study , which is complicated by the lack of uniformity of features being created for each .",
    "further , the techniques above strictly constrain the manner in which each feature influences the output , whereas our method is fully non - parametric and therefore more flexible . however , the largest concern is accurate reporting of predictive performance . in particular , we caution against the circular practice of measuring the performance of methods by applying them to the same events from which the luminosity relations were formed . in order to prevent over - estimating the accuracy of a predictive model , one needs to test on data independent from the training set , such as with cross - validation .",
    "finally , the rate method differs from previous efforts in that it casts the problem as one of optimal resource allocation under limited follow - up time .",
    "prior techniques are not explicitly calibrated to suit this purpose .",
    "direct classification methods will either under or over - utilize available resources .",
    "past regression or `` pseudo-@xmath0 '' methods are not explicitly calibrated to a particular follow - up decision ( i.e. , at what `` pseudo-@xmath0 '' does one decide to follow up ? ) , though it would be possible in principle to correct for this using a transformation which ensures that the desired follow - up fraction corresponds to the actual fraction of bursts followed up ( e.g. , figure [ fig : popcompare_unknownz ] ) .",
    "in contrast , the rate technique is by design applicable to any available resource reserves , and is generally extendable to any transient follow - up prioritization problem .",
    "in this paper , we presented the rate grb-@xmath0 method for allocating follow - up telescope resources to high - redshift grb candidates using random forest classification on early - time _ swift _ metrics .",
    "the rate method is generalizable to any prioritization problem that can be parameterized as `` observe '' or `` do nt observe '' , and accommodates statistical challenges such as small datasets , imbalanced classes , and missing feature values .",
    "the issue of resource allocation is becoming increasingly important in the era of data - driven transient surveys such as ptf , pan - starrs , and lsst which provide extremely high discovery rates without a significant increase in follow - up resources .",
    "with enough training instances of any object of interest for a given transient survey , the rate method can be applied to prioritize follow - up of future high - priority candidates .    in the rate grb-@xmath0 application , our robust , cross - validated performance metrics",
    "indicate that by observing just 20% of bursts , one can capture @xmath63 of @xmath1 events with a sample purity of @xmath68 .",
    "further , following up on half of all events will yield nearly all ( @xmath67 ) of the high-@xmath0 events .",
    "the method provides a simple decision point for each new event : if the prioritization value @xmath54 is smaller than the percent of events a user wishes to allocate resources to , then follow - up is recommended .",
    "these rapid predictions , combined with the more traditional photometric dropout technique from simultaneous multi - filter nir observatories ( such as pairitel , grond , and the upcoming ratir ) , offer a robust tool in more efficiently informing grb follow - up decisions . to facilitate the dissemination of high - redshift grb predictions to the community",
    ", we have set up a website ( http://rate.grbz.info ) with @xmath54 values for past bursts , and an rss feed ( http://rate.grbz.info/rss.xml ) to provide real - time results from our classifier on new events .                                                                                                                                                                                                                                                                                                                                                                                                                          , t.  n. , sakamoto , t. , dhuga , k.  s. , parke , w.  c. , barthelmy , s.  d. , gehrels , n. , stamatikos , m. , & tueller , j. 2009 , in american institute of physics conference series , vol . 1133 , american institute of physics conference series , ed .",
    "c.  meegan , c.  kouveliotou , & n.  gehrels , 437439        , d.  e. , grupe , d. , racusin , j. , roming , p. , & koch , s. 2008 , in american institute of physics conference series , vol .",
    "1000 , american institute of physics conference series , ed .",
    "m.  galassi , d.  palmer , & e.  fenimore , 8083"
  ],
  "abstract_text": [
    "<S> as the number of observed gamma - ray bursts ( grbs ) continues to grow , follow - up resources need to be used more efficiently in order to maximize science output from limited telescope time . as such </S>",
    "<S> , it is becoming increasingly important to rapidly identify bursts of interest as soon as possible after the event , before the afterglows fade beyond detectability . </S>",
    "<S> studying the most distant ( highest redshift ) events , for instance , remains a primary goal for many in the field .   </S>",
    "<S> here we present our random forest automated triage estimator for grb redshifts ( rate grb-@xmath0 ) for rapid identification of high - redshift candidates using early - time metrics from the three telescopes onboard _ </S>",
    "<S> swift_. while the basic rate methodology is generalizable to a number of resource allocation problems , here we demonstrate its utility for telescope - constrained follow - up efforts with the primary goal to identify and study high-@xmath0 grbs . for each new grb , </S>",
    "<S> rate grb-@xmath0 provides a recommendation  based on the available telescope time  of whether the event warrants additional follow - up resources . </S>",
    "<S> we train rate grb-@xmath0 using a set consisting of 135 _ swift _ bursts with known redshifts , only 18 of which are @xmath1 . </S>",
    "<S> cross - validated performance metrics on this training data suggest that @xmath256% of high-@xmath0 bursts can be captured from following up the top 20% of the ranked candidates , and @xmath284% of high-@xmath0 bursts are identified after following up the top @xmath240% of candidates . </S>",
    "<S> we further use the method to rank @xmath3 _ swift _ bursts with unknown redshifts according to their likelihood of being high-@xmath0 . </S>"
  ]
}