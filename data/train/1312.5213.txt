{
  "article_text": [
    "quantum computers are sensitive to the effects of noise due to unwanted interactions with the environment . to overcome this ,",
    "fault - tolerant protocols that utilize error correction codes have been developed .",
    "these schemes allow arbitrary quantum gates to be performed in spite of the noise that is ubiquitous in current models of quantum computing .",
    "recent progress has been made towards experimental implementations of quantum error correcting codes using small numbers of qubits realized using photonic systems , trapped ions and nmr techniques @xcite .",
    "superconducting qubits are another promising experimental technique for scalable fault - tolerant quantum computing @xcite , including surface code architectures @xcite .",
    "the surface code @xcite is one of a family of topological codes , and is the basis for an approach to fault - tolerant quantum computing for which high thresholds have been reported @xcite .",
    "the toric code @xcite is among the most extensively studied of this family of codes , revealing much insight into related topologically ordered systems .",
    "a great deal of work has concentrated on calculating thresholds for various error models @xcite , and on the discovery and implementation of new classical decoding algorithms @xcite .",
    "the toric code performs well , with high thresholds for some commonly studied noise models .",
    "a high threshold is a very desirable property of an error correcting code since for all error rates below the threshold , increasing the number of physical qubits encoding the quantum information reduces the logical error rate . in a realistic setting",
    "the code must be operating at an error rate below the threshold .",
    "other quantities then become important to characterize the performance of a quantum computer , for example the _ code overhead _ , the number of physical qubits comprising the code that are required to adequately protect the encoded quantum information .",
    "this is an important consideration for the practical implementation of fault - tolerant quantum computation and has recently begun to draw some attention @xcite .",
    "the logical failure rate of the error correction , denoted here as @xmath0 , is a key metric of the performance of a code , since it describes the likelihood of failing to protect the encoded quantum information . in this work",
    "we seek the logical failure rate of the toric code for fixed code distance and physical error rate , @xmath1 .",
    "the code distance is the minimum length of a string - like operator that has a non - trivial effect on the code space , and in the case of the toric code such operators have a length equal to the lattice size @xmath2 .",
    "the toric code is a simple model that is closely related to other , more physically realistic systems .",
    "we expect therefore that results for the logical error rate scaling of the toric code could be applied in a range of other physical systems ",
    "most obviously the planar code ( with open , rather than periodic , boundary conditions ) and with noisy syndrome measurements . the techniques to determine the scaling of the logical error rate",
    "should be analogous although the numerics would be expected to differ from the toric code case @xcite .",
    "furthermore , once the scaling has been determined it can be used to calculate the fault - tolerant overhead for the planar code using the methods presented in this paper .    below the threshold ,",
    "the logical failure rate of a topological code is expected to reduce exponentially as we increase the code distance @xcite .",
    "although the code performance improves rapidly with increasing @xmath2 , in the lattice of the toric code the total number of physical qubits scales as @xmath3 .",
    "manufacturing , storing , and manipulating resources with such a scaling is a non - trivial task with technology available at present .",
    "we should then ask not simply how large we can make the code , but how many physical qubits are required to achieve a desired error correction performance .    in order to answer this question , we examine the behavior of the toric code in the presence of uncorrelated bit - flip and phase - flip noise .",
    "we numerically simulate the error correction procedure and use this to find the failure rate as a function of the input parameters @xmath2 and @xmath1 and find two operating regimes .",
    "the first of these , which we will call the _",
    "universal scaling hypothesis _ , extends ideas by wang _",
    "_ @xcite and uses rescaling arguments based on a mapping to a well - studied model in statistical physics ( the 2-dimensional random - bond ising model , or rbim ) .",
    "this approach provides a good estimate for @xmath0 when the error weight ( the number of qubits an operator acts on non - trivially ) is high and code distance is large .",
    "rescaling arguments apply in the thermodynamic limit , and close to criticality , where the correlation length of the rbim also diverges and the appropriate length scale is the ratio of the lattice size to the correlation length , @xmath4 . as @xmath1 decreases there is a point at which finite - size effects begin to dominate and we no longer expect the universal scaling hypothesis to apply .",
    "this limit corresponds to low physical error rates , as well as small lattices .",
    "the second approach extends ideas by raussendorf _",
    "_ @xcite and fowler _ et al .",
    "_ @xcite to find an analytic expression for @xmath0 in the limit @xmath5 .",
    "when the error weight is low and the code distance is small this expression gives a good estimate of the logical failure rate .",
    "we will refer to this as the _ low _",
    "@xmath1 _ expression_.",
    "although we know the limits in which each of these approaches is valid , we would like to make some quantitative statements about the range of parameters for which each is applicable .",
    "we shall present a heuristic argument for the range of @xmath2 and @xmath1 for which each regime gives a good approximation to the numerical data .",
    "the structure of the paper is as follows . in sec .",
    "[ sec : toric_code ] we review the toric code and its properties .",
    "readers familiar with this material may wish to skip to sec .",
    "[ sec : us ] which discusses the universal scaling regime , in which rescaling arguments are used to estimate the logical failure rate .",
    "[ sec : low_p ] describes the regime in which finite - size effects dominate the logical failure rate and the failure rate is dominated by spanning errors . in sec .",
    "[ sec : validity ] we present our conjectures regarding the ranges of validity of each of the two regimes described . in sec .",
    "[ sec : results ] we use these results to demonstrate techniques to determine the overhead as a function of the single qubit error rate and the logical error rate .",
    "we conclude in sec .",
    "[ sec : conclusion ] .",
    "in the toric code , physical qubits reside on the edges of an @xmath6 square lattice , as shown in fig .",
    "[ fig : stabilizers ] . there are @xmath7 physical qubits comprising the code .",
    "periodic boundary conditions are imposed and the lattice can be imagined to be embedded on the surface of a torus .",
    "the toric code is described by a set of two types of commuting _",
    "stabilizer generators _  the so - called _ vertex _ , @xmath8 , and _ plaquette _ , @xmath9 , operators , defined as @xmath10 where @xmath11 and @xmath12 are the conventional single - qubit pauli operators , @xmath13 indicates a vertex and @xmath1 a plaquette of the lattice .",
    "the @xmath8 operators therefore act on the four qubits surrounding a vertex of the lattice , and the @xmath9 operators act on the four qubits surrounding a plaquette , see fig .",
    "[ fig : stabilizers ] .",
    "these four - body measurements can be decomposed into four two - qubit cnot gates with the addition of an ancilla @xcite .",
    "( color online ) .",
    "representation of stabilizer generators on an @xmath14 toric code lattice .",
    "qubits , shown as yellow circles , are placed on the links of the lattice .",
    "note that the periodic boundaries are indicated by the dashed lines .",
    "the dual lattice is shown using grey lines . _",
    "top : _ a vertex operator on the primal lattice ( left ) and the dual lattice ( right ) .",
    "_ bottom : _ a plaquette operator on the primal lattice . ]",
    "we denote the logical encoded state of the toric code by @xmath15 . in the absence of noise , measuring",
    "any element of @xmath16 on this state will yield a @xmath17 eigenvalue : @xmath18 where @xmath19 .",
    "the stabilizer group is generated by @xmath20 with multiplication being the group action .",
    "all elements of the stabilizer group act trivially on the code space .",
    "the code - space of the toric code is four - dimensional and hence can encode two logical qubits .",
    "this is independent of @xmath21 , hence the toric code protects a constant number of logical qubits regardless of its lattice size .    the symmetry between the _ primal lattice _ and the _ dual lattice _ ( constructed by replacing plaquettes of the primal lattice by vertices and vice versa ) shown in fig .",
    "[ fig : stabilizers ] , reveals a useful symmetry in the stabilizers of the toric code . on the dual lattice",
    "the @xmath8 operators act on the qubits surrounding a plaquette , as shown in fig .",
    "[ fig : stabilizers ] . by considering both the primal and dual lattices we can view all stabilizers as closed loops , meaning that all plaquette - type operators on the primal lattice have an analogous vertex - type operator on the dual lattice .",
    "it follows that all results calculated for either bit - flip or phase - flip errors are interchangeable with results for the other type .    in the language of algebraic topology ,",
    "all of the stabilizers correspond to _ homologically trivial cycles_. in fig .",
    "[ fig : cycles ] we show an example of a homologically trivial cycle that is generated by multiplying two adjacent stabilizer generators together .",
    "we see that all homologically trivial cycles act trivially on the code - space .",
    "the _ logical operators _ are also represented by cycles of pauli operators . however , these cycles wrap around the torus and are not homologically equivalent to stabilizers .",
    "the logical operators correspond to _ homologically non - trivial cycles _ and have a non - trivial effect on the code - space . the minimum weight of a logical operator is @xmath2 .",
    "there are two sets of @xmath22 and @xmath23 logical operators addressing the two encoded qubits ( overbar indicates a logical operation ) .",
    "one of these , labeled @xmath24 , is shown in fig .",
    "[ fig : cycles ] spanning the lattice vertically .",
    "the corresponding @xmath25 is also shown , and forms a closed horizontal loop on the dual lattice . by multiplying a logical operator by a subset of stabilizers",
    "we can continuously deform the minimum - weight cycle @xmath24 into any other operator spanning the lattice vertically .",
    "the set of operators that are equivalent up to stabilizer operations belong to the same _ homology class _ @xcite .",
    "( color online ) . _",
    "@xmath24 is a minimum - weight homologically non - trivial cycle , equivalent to a logical operator acting on the encoded information . _",
    "top : _ the @xmath25 operator , drawn as a cycle on the dual lattice ( lattice not shown ) .",
    "the @xmath25 logical operator shares a single physical qubit with @xmath24 and hence they anticommute . _",
    "right : _ an example of a homologically trivial cycle generated by multiplication of two adjacent plaquette operators . ]",
    "errors are detectable if they anticommute with at least one element of the set of stabilizer generators @xmath20 . in this work",
    "we assume that stabilizers are measured perfectly .",
    "it follows that if any non - trivial eigenvalues are observed , this indicates the presence of errors with certainty .",
    "the pattern of stabilizers that anticommute with a given error reveals some information about the location and most likely type of error , although it can not uniquely identify the error .",
    "this ambiguity is due to the code degeneracy .",
    "the set of all errors on the lattice is called a _ chain _ , @xmath26 .",
    "we use notation from algebraic topology to indicate the boundary of the chain of errors as @xmath27 .",
    "( a good introduction to algebraic topology can be found in many textbooks , for example see ref .",
    "the errors commute with the stabilizers except at the boundary of the chain where the measured eigenvalues are non - trivial .",
    "the full set of stabilizer eigenvalues is called the _",
    "syndrome_. fig .",
    "[ fig : error_detection ] shows a string of @xmath11 errors and the two plaquette operators that anticommute with it .",
    "once the syndrome has been established we employ a classical algorithm called a _ decoder _ to decide which correction chain , @xmath28 , to apply .",
    "the goal of the decoder is to pair the non - trivial syndromes such that the total operator @xmath29 has the highest probability of being a homologically trivial cycle and thus a member of the stabilizer group .",
    "failure of the decoding algorithm corresponds to the creation of a homologically non - trivial cycle .",
    "the decoder used in this work , the minimum - weight perfect matching algorithm , is described in the next section .",
    "( color online ) .",
    "a string of @xmath11 errors is shown as a dashed line on the dual lattice .",
    "measuring the two @xmath9 generators indicated yields @xmath30 eigenvalues because the stabilizer and error chain anticommute at these locations . note that if the @xmath11 error chain forms a cycle then it will not be detectable . ]      the optimal threshold for the independent noise model that we consider here has been calculated using numerical techniques to be @xmath31 @xcite . however , there are no known _ efficient _ decoding algorithms that can obtain this threshold for the independent noise model on the toric code .",
    "several classes of sub - optimal efficient decoding algorithm exist @xcite .",
    "the one used in this work is a version of edmonds minimum - weight perfect matching algorithm ( mwpma ) @xcite .",
    "this algorithm pairs the non - trivial syndromes via a correction chain that has the least weight possible while satisfying the condition that its boundary matches the error chain boundary , i.e. @xmath32 .",
    "this ensures that the total operator , @xmath33 , is a cycle .",
    "we denote the threshold for the mwpma by @xmath34 .",
    "numerical simulations suggest that @xmath35 @xcite .",
    "although this algorithm gives a high threshold @xcite , we shall consider a heuristic modification described in detail by stace and barrett @xcite , that includes the effects of the degeneracy of @xmath36 and can give thresholds up to @xmath37 .",
    "degeneracy counts the number of possible paths that the chain can take , given that its boundary and weight are fixed .",
    "matchings with higher degeneracy have a higher probability of arising so they may be _ a priori _ more likely than some matchings with a lower weight .",
    "the degeneracy itself is simple to calculate for a given ( minimum - weight ) matching .",
    "for instance , for a path @xmath38 between two non - trivial syndromes , @xmath39 and @xmath40 , the degeneracy of that path @xmath41 is given by the number of different combinations of the links in the matching .",
    "the product of all individual @xmath41 is the total degeneracy of the matching , @xmath42 .    to take degeneracy into account",
    "we compute the matching using the mwpma , where the edge weights @xmath43 are modified by the effect of the degeneracy of that path .",
    "then the weight passed to the algorithm becomes @xmath44 . here",
    "@xmath45 is a weighting that we assign to the degeneracy term .",
    "the degeneracy is added in such a way due to entropic considerations , see ref .",
    "@xcite for details .",
    "the decoding algorithm minimizes this quantity globally and this has been shown to lead to an improved threshold @xcite .",
    "we refer to this enhanced version of the minimum - weight perfect matching simply as the pma decoder .",
    "an important tool in this work is the numerical simulation of the detection and correction of errors on a toric code .",
    "repeating random trials allows us to examine the failure probability of the code over a wide range of parameters .",
    "as stated earlier , we consider uncorrelated bit - flip and phase - flip errors arising at a rate @xmath1 .",
    "it suffices to perform simulations for only one of these types of error since the results will be equivalent for the other .",
    "the behavior of the toric code is simulated by placing an error with probability @xmath1 on each individual qubit of the toric code lattice of linear dimension @xmath2 , giving rise to a ( usually disjoint ) error chain @xmath26 .",
    "the syndromes are measured and the pma decoder is used to determine the correction chain @xmath36 .",
    "these correction chains are added , modulo 2 , to @xmath26 and a parity check with each of the appropriate logical operators is used to determine the homology class of the total operator @xmath46 .",
    "the result of this random sample indicates whether the error correction succeeds or fails .",
    "the outcome of the bernoulli trial ( a single simulation of error correction ) is assigned the value @xmath47 if @xmath46 is in the trivial homology class and @xmath48 if it is in any of the non - trivial homology classes . to gather statistics we repeat this procedure @xmath49 times for the same input parameters @xmath50 . of these @xmath49 trials",
    ", @xmath51 will have failed to perform error correction successfully .",
    "we therefore estimate the error correction failure probability as @xmath52 and the variance of such a distribution is @xmath53 .",
    "the resulting data @xmath54 characterizes the toric code performance .",
    "in ref . @xcite , wang _ et al . _ used ideas from the theory of critical phenomena in finite - sized systems to show that there is a critical point in the failure probability of the toric code . to do this",
    ", they used the 2-dimensional random - bond ising model ( rbim ) which is a model of ferromagnetism in which antiferromagnetic couplings arise at random .",
    "the probability distribution of antiferromagnetic couplings in this model matches the probability distribution of errors in the toric code , hence a mapping between the two models can be constructed @xcite . the rbim has been extensively studied and it is known to undergo a phase transition from an ordered to a disordered phase as the concentration of antiferromagnetic bonds is increased .",
    "this implies a phase transition in the corresponding quantity of the toric code : its logical failure rate .",
    "wang _ et al .",
    "_ demonstrated that for the regime where @xmath55 , where @xmath56 is the rbim _ correlation length _ , we expect scale - invariant behavior .",
    "this argument leads to the conjecture that in this regime the failure probability of the toric code is a function only of @xmath4 @xcite .",
    "below the threshold the failure rate is expected to depend exponentially on the system size @xcite , and also more generally in the fault - tolerant case @xcite . @xmath57 numerical evidence for this",
    "will be provided later , in fig .",
    "[ fig : exp_l ] .    together , the exponential dependence on @xmath2 and the scaling hypothesis fix the functional form of @xmath0 .",
    "@xmath58 in this expression @xmath59 and @xmath39 are constants that can be determined using numerical fitting techniques , see sec .",
    "[ sec : testing_us_validity ] and appendix [ sec : threshold_calc ] .    in practice",
    "the toric code will be operating in the correctable ( @xmath60 ) regime so we use the rescaled variable @xmath61 ( alternatively this may be written as @xmath62 ) and we can rewrite the universal scaling hypothesis as @xmath63    we determine the values of @xmath59 , @xmath34 and @xmath64 from a fit to data close to the threshold . in the remainder of this section we give evidence that the numerical data meets the two conditions required for the universal scaling hypothesis , namely an exponential decay of the failure rate as @xmath2 increases and scale invariance .      to observe the dependence of @xmath0 on @xmath2 and @xmath1 we have generated a set of monte carlo data for @xmath65 and odd lattice sizes in the range @xmath66 .",
    "we use the simulation method outlined in sec .",
    "[ sec : simulating_tc ] with each simulation repeated @xmath67 times using kolmogorov s blossom v minimum - weight perfect matching algorithm implementation @xcite .",
    "we pass modified weights to the algorithm to account for degeneracy as described in sec .",
    "[ sec : error_correction ] .    in fig .",
    "[ fig : exp_l ] we plot the logical failure rate on a logarithmic scale , as a function of the lattice size .",
    "the shaded portion of the figure indicates the region where this exponential relationship is not expected to hold according to a conjecture that will be explained in sec .",
    "[ sec : validity ] .",
    "( color online ) .",
    "dependence of the logical failure rate @xmath0 on the size of the lattice .",
    "each data point represents @xmath67 runs .",
    "the data is plotted on a logarithmic scale and linear fits to a selected set of the data between @xmath68 and @xmath69 are shown .",
    "the four data sets shown in in the lower part of the plot ( dashed lines ) are examples of data with @xmath70 for which linear fits could not be identified . in the grey region the linear relationship is expected to break down according to our validity conjecture , see sec . [ sec : validity ] . ]",
    "each set of data in fig .",
    "[ fig : exp_l ] is fitted using a quadratic ansatz in @xmath2 : @xmath71 for data in the range @xmath72 and @xmath66 the quadratic coefficient @xmath73 is typically 23 orders of magnitude smaller than the linear coefficient @xmath74 .",
    "this is strong evidence for a linear fit to the ( logarithmic ) data , suggesting a fit of the form @xmath75 , matching equation ( [ eqn : expl ] ) . for data with values of @xmath76",
    "the quadratic coefficient was comparable in magnitude to the linear coefficient . a selection of this data is also shown in fig .",
    "[ fig : exp_l ] , demonstrating that the behavior of the data for these values of physical error rate is ambiguous . nevertheless , fig .",
    "[ fig : exp_l ] establishes an exponential dependence of the logical failure probability on @xmath2 for a wide range of the data .",
    "( color online ) .",
    "data obtained from numerical simulations of the toric code failure rate close to threshold , rescaled using @xmath77 .",
    "each data point represents @xmath78 runs .",
    "the finite - size correction @xmath79 is subtracted from @xmath0 .",
    "all of the data collapses to a single curve and the threshold can be extracted as a fit parameter .",
    "_ inset : _ the data prior to rescaling . ]",
    "the universal scaling hypothesis in equation ( [ eqn : us_hypoth ] ) also requires the system to be scale invariant which implies that the behaviour of @xmath0 should depend only on the length scale @xmath4 .",
    "this is demonstrated in fig .",
    "[ fig : threshold ] which shows the results of numerical simulations of the toric code failure rate close to threshold .",
    "the plot will be explained in detail in appendix [ sec : threshold_calc ] but now we simply note that rescaling the numerical data using the variable @xmath80 leads to _ data collapse_. this phenomenon describes the situation when data generated in different systems , in this case different lattice sizes , falls onto the same curve after an appropriate rescaling has been applied .",
    "the universal scaling hypothesis is a good model for the logical failure rate when the lattice size is large and when there are sufficiently many errors . for a fixed lattice size , as @xmath1",
    "is reduced the universal scaling behavior should not be expected to hold indefinitely . indeed the numerical evidence suggests that when @xmath1 becomes sufficiently small the scaling hypothesis fails . in the @xmath5",
    "limit the behavior is given by the low @xmath1 analytic approximation : @xmath81    this is justified by considering the uncorrectable error configurations in the @xmath5 limit and calculating @xmath0 directly . restricting ourselves to low single qubit error rates we consider the minimum number of errors that can cause the error correction to fail , @xmath82 .",
    "to cause the error correction to fail these errors must lie along a single minimum - weight homologically non - trivial cycle of the toric code .",
    "if they fall in this way the pma will certainly apply the remaining @xmath83 single qubit operators required to ensure @xmath33 is a logical operator .",
    "[ fig : logical_fail ] shows a sketch of how this happens .",
    "( color online ) .",
    "one way in which @xmath84 errors lying along a minimum weight homologically non - trivial cycle will result in a logical error .",
    "the pma decoder applies a correction chain that results in a non - trivial cycle , causing a logical failure .",
    "( a ) the errors are distributed arbitrarily along one minimum - weight homologically non - trivial cycle of the lattice .",
    "( b ) the syndromes that arise as a result of the error configuration are shown .",
    "( c ) the minimum - weight perfect matching returns the correction chain @xmath28 with certainty .",
    "( d ) the resultant cycle @xmath33 is homologically non - trivial , which means that the error correction has failed . ]",
    "thus the expression in equation ( [ eqn : low_p_approx ] ) for the failure rate is constructed via a counting argument .",
    "the first factor , @xmath85 , is the number of minimum - weight homologically non - trivial cycles of the code that exist .",
    "the second is the binomial coefficient which counts the possible combinations of @xmath82 errors along a cycle of weight @xmath2 .",
    "finally we include a factor that accounts for the likelihood of exactly @xmath82 errors occurring on a lattice constructed from @xmath86 qubits , which is @xmath87 .",
    "the single qubit error rate is small so we can neglect the final factor of @xmath88 to obtain equation ( [ eqn : low_p_approx ] ) . in the low @xmath1 limit the @xmath2 dependence is @xmath89 and we see that it is quantitatively different to the universal scaling regime , @xmath75 .",
    "the range of parameters we consider in our numerical simulations encompasses both the small @xmath1 limit and the universal scaling limit . for small single qubit error rates",
    "the weight of the errors is typically much smaller than the code distance and the low @xmath1 analytic expression is applicable .",
    "conversely , for large @xmath2 the number of errors can be much larger than the code distance and we expect a universal scaling hypothesis to apply .",
    "these regimes are distinct , as we see from their differing dependence on the code distance .",
    "each of the two regimes will provide a good approximation to the numerical data over some region of parameter space .",
    "we shall now make a heuristic argument to quantify those regions .    in order to make a conjecture about the validity of the regimes we consider the distribution of the number of errors that arise on a lattice of fixed size , at a known physical error rate .",
    "we will relate this distribution to @xmath84 , half the code distance .",
    "this number is significant to the pma decoder because if the weight of the error chain , @xmath90 , is less than this number then the error is certainly correctable . in the case when @xmath91 a subset of the possible error configurations will lead to an incorrect pairing of syndromes , causing a logical failure .",
    "these are the spanning errors illustrated in fig .",
    "[ fig : logical_fail ] .",
    "the typical weight of errors on the lattice can be shown to be @xmath92 .",
    "if @xmath93 then the expected number of errors is less than half the code distance and logical errors are dominated by spanning chains , see fig .",
    "[ fig : logical_fail ] . for a fixed @xmath1 , as @xmath2 increases this inequality is violated .",
    "when the number of errors is much greater than @xmath2 but they are typically correctable , this is the universal scaling limit .",
    "requiring @xmath94 ( up to a numerical factor ) leads to a relationship between @xmath2 and @xmath1 that determines a minimum single qubit error rate for a given lattice size below which the universal scaling hypothesis breaks . we make the arbitrary but natural choice that the mean number of errors on the lattice must be two standard deviations above @xmath84 , leading to the expression @xmath95 this expression , derived fully in appendix [ sec : p_break ] , determines whether the behavior can be considered to be within the universal scaling regime .",
    "we can find an equivalent expression for @xmath96 , when the single qubit error rate above which the low @xmath1 expression no longer provides a good approximation to the numerical data .",
    "this can be shown to be @xmath97 when @xmath98 there is a ` crossover ' region , in which the logical failure rate can not be considered to be well approximated by either regime .",
    "( color online ) .",
    "data satisfying the condition @xmath99 , plotted on a logarithmic scale and colored according to lattice size .",
    "each data point represents @xmath67 runs .",
    "also shown in black is the fit of the ansatz , equation ( [ eqn : us_hypoth ] ) with all values taken from the threshold fit ( see appendix [ sec : threshold_calc ] ) except for @xmath39 which was extracted using a fit to the data set shown . ]    substituting @xmath100 given by equation ( [ eqn : p_min ] ) into the universal scaling hypothesis in equation ( [ eqn : us_hypoth ] ) yields an expression for the minimum @xmath0 , for a fixed @xmath2 , that belongs to the universal scaling regime .",
    "this expression is plotted as a grey line in fig .",
    "[ fig : exp_l ] and hence the grey region indicates the region of parameter space where we do not expect the universal scaling hypothesis to hold .",
    "this supports the previous observation that most of the data we have obtained for @xmath70 would lie outside the universal scaling region and therefore be poorly fit by equation ( [ eqn : func_form ] ) .",
    "we have fitted the universal scaling ansatz , equation ( [ eqn : us_hypoth ] ) to the data that falls outside this grey region .",
    "( the values of @xmath59 , @xmath34 and @xmath64 are all determined from the fit to the data around threshold . ) from the fit to the data in the universal scaling regime we find @xmath101 .",
    "the data obeying the validity condition and the fit are shown in fig .",
    "[ fig : us_fit ] .",
    "let us now fix the code distance @xmath2 and vary the single qubit error rate to see how the full set of data behaves in relation to the universal scaling limit .",
    "for each fixed @xmath2 in fig .",
    "[ fig : varyp ] , reducing @xmath102 corresponds to reducing @xmath1 .",
    "when @xmath1 becomes sufficiently small the scaling hypothesis fails and as expected the failure rate deviates below the universal scaling law .",
    "( color online ) . logarithmic plot of all numerical data following the rescaling transformation @xmath103 .",
    "the universal scaling fit is also shown in black .",
    "the data is plotted on a logarithmic scale and colored according to lattice size @xmath2 . for fixed @xmath2 ,",
    "decreasing @xmath102 corresponds to reducing @xmath1 . as we do this the universal scaling hypothesis breaks at a point predicted by equation ( [ eqn : p_min ] )",
    "this is indicated for a single lattice size ( @xmath104 ) as a vertical line . ]",
    "( color online ) .",
    "the full set of renormalized data , colored by lattice size . the low @xmath1 analytic expression , equation ( [ eqn : low_p_approx ] )",
    "is shown for some small lattice sizes .",
    "as @xmath102 decreases the analytic expression tends towards the data .",
    "this numerical evidence suggests that the analytic expression is an underestimate of the failure rate for this range of parameters . ]",
    "we have proposed that , in the low @xmath1 limit , spanning errors of the type illustrated in fig .",
    "[ fig : logical_fail ] dominate when @xmath93 .",
    "this is the validity condition we use for the low @xmath1 regime , see equation ( [ eqn : p_max ] )",
    ".    we can rewrite equation ( [ eqn : low_p_approx ] ) in terms of @xmath2 and the rescaling variable , @xmath102 .",
    "[ fig : low_p ] shows this analytic expression plotted for some small values of @xmath2 along with the numerical data .",
    "as the probability of errors decreases on a fixed lattice the mean number of errors will approach @xmath82 .",
    "as expected , the low @xmath1 expression gives a good approximation for small lattice sizes and low physical qubit error rates .",
    "the data and low @xmath1 analytic expression converge as @xmath102 decreases , so for fixed lattice size as the physical error rate decreases the approximation improves .",
    "so far we have concentrated on determining the logical error rate as a function of the lattice size and single qubit error rate .",
    "now we wish to demonstrate that it is possible to invert these relationships to find the overhead , @xmath105 . this will be a function of the experimentally determined single qubit error rate , @xmath1 , and maximum tolerable logical failure rate @xmath0 .    in this work",
    "we demonstrate the calculation for the toric code with perfect stabilizer measurements .",
    "however the same techniques shown here will also be applicable to more physically realistic settings , for example a planar code with noisy stabilizer measurements .",
    "although the numerics will differ from those presented here , the methods used are expected to be directly analogous .",
    "the first step in calculating the overhead is to determine which of the two regimes ( universal scaling or low @xmath1 ) the code is operating within .",
    "to do this we use the expression for @xmath100 in equation ( [ eqn : p_min ] ) , to find the minimum error rate for which the universal scaling hypothesis holds .",
    "similarly we find @xmath106 , the maximum error rate for which the low @xmath1 expression holds , using equation ( [ eqn : p_max ] ) . in fig .",
    "[ fig : validity ] we plot these two bounds , and the regions of validity that they indicate . fig .",
    "[ fig : validity ] therefore shows the region of ( @xmath0 , @xmath1 ) parameter space for which each of the regimes is expected to give a good approximation to the logical error rate .",
    "once the correct regime has been identified , the overhead can be calculated .",
    "( color online ) .",
    "the range of validity of each of the regimes is indicated as a function of the independent variables @xmath1 and @xmath0 . the uncolored part of the plot is the crossover region between the two regimes . ]    in the universal scaling region the logical failure rate is @xmath107 . by using this to find the lattice size @xmath2 as a function of @xmath0 and @xmath1 , and recalling that there are @xmath86 physical qubits comprising the toric code",
    ", we find the overhead in the universal scaling regime is given by : @xmath108 ^ 2,\\end{aligned}\\ ] ] where the constant @xmath39 has been determined from fits to the data in this work , see sec .",
    "[ sec : testing_us_validity ] .",
    "the remaining parameters , @xmath59 , @xmath34 and @xmath64 , can be determined from a fit to data generated close to threshold , see appendix [ sec : threshold_calc ] for this calculation and for their numerical values .    the analytic expression for the low @xmath1 regime , equation ( [ eqn : low_p_approx ] )",
    ", can be simplified by assuming that @xmath109 and using stirling s approximation @xmath110 . inverting this simplified expression",
    "we obtain a solution for @xmath2 that uses the lambert @xmath111 function @xcite .",
    "we can simplify this using the approximate form for the lower branch of the function @xcite .",
    "it follows that an approximate expression for the overhead in this regime is given by : @xmath112 ^ 2 .",
    "\\label{eqn : low_p_overhead}\\end{aligned}\\ ] ]    ( color online ) . a 3-d plot of the overhead , on a logarithmic scale , in each of the two regimes for @xmath113 and @xmath114 .",
    "this plot reveals the gap between the two regimes over the whole region of parameter space considered .",
    "it also reveals drop in overhead as the single qubit error rate is reduced , which is particularly striking for the low @xmath1 regime . ]",
    "[ fig : oh3d ] shows a 3-d plot of the overhead as a function of @xmath0 and @xmath1 .",
    "there is a significant gap between the two plots for most of parameter space ( see fig .",
    "[ fig : overhead ] ) and an increase in overhead is seen as both @xmath1 and @xmath0 are increased .",
    "allowing a higher logical failure rate will naturally reduce the overhead required , as will reducing the single qubit error probability .",
    "( a )     for desired fidelities @xmath115 .",
    "( b ) the overhead for logical failure rate @xmath116 and @xmath113 .",
    "the plots can be considered to be practical bounds on the overhead for the parameters considered . ]",
    "( b )     for desired fidelities @xmath115 .",
    "( b ) the overhead for logical failure rate @xmath116 and @xmath113 .",
    "the plots can be considered to be practical bounds on the overhead for the parameters considered . ]",
    "[ fig : overhead ] shows the difference between the required overhead in the two different regimes . for",
    "the range of parameters considered the low @xmath1 expression always gives an estimate of the overhead that lies below the value given by the universal scaling hypothesis .",
    "the low @xmath1 expression tends to underestimate the logical failure rate for the range of numerical data simulated .",
    "hence this may be considered to be a practical lower bound on the overhead required for those parameters .",
    "conversely , the universal scaling hypothesis is an overestimate of the logical failure rate for most of the numerical data , and hence can be considered to be a practical upper bound to the resources required .",
    "we have found two distinct operating regimes of the toric code . in one ,",
    "the data can be rescaled and an ansatz based on this scaling and the exponential dependence of the failure rate on @xmath2 can be used to find an empirical expression for @xmath0 . in the other ,",
    "a counting argument gives rise to an analytic expression for the failure rate in the @xmath117 limit .",
    "we propose , using the probability distribution of the error weight for fixed @xmath50 , heuristic conditions for the range of validity of each expression .",
    "the expressions describing the two regimes have been inverted to calculate the system size required to achieve a desired logical success rate for a given single qubit error rate .",
    "we have used the expressions for the logical failure rate to demonstrate techniques to calculate the overhead , @xmath118 .",
    "we expect that the techniques we have demonstrated in this work will be applicable in a wide range of settings .",
    "in particular , more physically realistic geometries such as the planar code , whose logical failure rate is expected to higher than that of the toric code @xcite .",
    "furthermore , we expect that the methods we have demonstrated can be used to calculate the overhead of a fault - tolerant quantum memory , in which the stabilizer measurements are imperfect .",
    "since all topological codes are based on similar principles the techniques outlined in this work can be expected to be directly applicable despite the fact that the numerics in these cases will differ from those presented here .",
    "based on the numerical evidence , we claim that for most practical purposes the two regimes bound the required overhead .",
    "the numerical results presented in this work are dependent on the choice of the decoder .",
    "similar scaling relationships would be expected for other decoding algorithms , particularly renormalization group - based decoders such as @xcite .",
    "this work raises several open questions .",
    "it has been shown that the mwpma decoder has a quadratically lower logical failure rate than the renormalization group algorithm @xcite . however , we still believe that a comprehensive comparison of all existing decoders over the whole region of ( relevant ) parameter space would be interesting and worthwhile .",
    "a possible scenario is that the size of the topological code that can be realized will be fixed by technological limitations . in that case , a comparison of the analysis presented in this work for all known decoders below threshold would reveal which should be implemented to minimize the logical failure rate",
    ".    decoders with high thresholds usually require a longer running time than those with more modest thresholds .",
    "we expect a tradeoff between time and space resources , suggesting that those decoders with longer running times may have smaller physical qubit overheads .",
    "this is interesting , because although a high threshold is desirable , for practical implementations the running time and physical overhead are also important constraints .",
    "therefore it seems that a balance between these three figures of merit may be of interest for practical quantum computation .",
    "several of the limitations we faced have been addressed by bravyi and vargo in @xcite during the preparation of this manuscript .",
    "the first of these addresses the crossover region between the two regimes we have identified .",
    "bravyi and vargo have constructed a heuristic ansatz that interpolates between the dependence on @xmath2 of the low @xmath1 regime , @xmath119 , and the dependence expected for larger physical error rates , @xmath75 .",
    "these functional forms match the two regimes we have identified so the ansatz by bravyi and vargo could lead to a method for interpolating between them .",
    "another benefit of the technique by bravyi and vargo is that it provides a fit to the numerical data in the small and moderate @xmath1 regimes .",
    "a significant limitation we faced was the availability of resources to run the monte carlo simulations of the error correction procedure .",
    "for example , it was impossible to obtain data for @xmath120 due to the running time of the decoder .",
    "bravyi and vargo have discovered a new technique for probing very low error rates on surface codes @xcite .",
    "obtaining data for very low logical error rates using this algorithm would help us to verify the conjecture of the range of validity of the low @xmath1 expression , particularly for larger lattice sizes than we were able to test .    while heuristic approaches are very flexible , our universal scaling hypothesis has the following advantages .",
    "it addresses the large @xmath2 limit and gives particularly good approximations to the numerical data for moderately large single qubit error rates .",
    "the functional form for the universal scaling hypothesis , given in equation ( [ eqn : us_hypoth ] ) is derived from the phase transition of the random - bond ising model , which is a model of statistical physics that the toric code error correction can be mapped to , meaning that it is not a heuristic expression .",
    "it is also easily invertible and its pre - factor , @xmath59 , does not depend on the code distance .",
    "ultimately the implementation of universal quantum computing that is found will set the input parameters that determine which of the regimes it operates within .",
    "i would like to thank tom stace for many valuable discussions in the early stages of this work and his idea of considering universal scaling in such an analysis , as well as for his careful reading of and comments on this manuscript .",
    "i would like to thank dan browne for his help in preparing this paper , and thank david jennings and hussain anwar for useful discussions and helpful comments on this manuscript .",
    "we acknowledge the imperial college high performance computing service for computational resources .",
    "fhew was supported by epsrc ( grant number : ep / g037043/1 ) .",
    "in sec . [ sec : us ] we rescaled the numerical data using the variable @xmath121 . in order to do this",
    ", we must first establish the values of the threshold , @xmath34 , and critical exponent , @xmath64 .",
    "the universal scaling hypothesis , equation ( [ eqn : us_hypoth ] ) , also relies on knowing the failure rate at threshold in the large @xmath2 limit . in this appendix",
    "we show how these quantities are obtained from a fit to data close to the threshold .",
    "the threshold for the stand - alone mwpma decoding has been calculated previously as @xmath122 @xcite . since we allow the degeneracy of the matching to affect the choice of correction chain , we repeat the calculation in this work to obtain the threshold for our enhanced pma decoder .    to find the logical failure rate @xmath0 we numerically simulate the error correction protocol , enhanced minimum - weight perfect matching ( pma ) , using the same method described in sec .",
    "[ sec : exp_l ] .",
    "we performed @xmath78 simulations of the error correction procedure for @xmath1 close to @xmath123 and for odd lattice sizes in the range @xmath124 .",
    "this set of data was only used for the purpose of finding the threshold and critical exponent , and is not the main data set used in this work .",
    "the lattice sizes we use are far from the large @xmath2 limit , so following the method from wang _ et al . _",
    "the fitting ansatz was constructed by taking a quadratic expansion in @xmath102 around the threshold @xmath125 and accounting for finite - size effects by adding a single non - universal term that is dependent on the lattice size @xcite .",
    "the ansatz is : @xmath126 where @xmath59 , @xmath127 and @xmath46 are expansion coefficients , @xmath128 is the coefficient of the non - universal term , and @xmath129 here @xmath64 is the critical exponent and @xmath34 is the threshold error rate for our pma decoder .",
    "[ fig : threshold ] shows the rescaled data with finite - size effects subtracted , and the fit to the data .",
    "the relevant parameters were found to be : @xmath130    the threshold for our modified decoding algorithms was found to be in agreement with the value found by wang _",
    "et al . _ for the unmodified mwpma @xcite .",
    "this does not achieve the maximum threshold of @xmath131 that is possible when the degeneracy of the matching is included @xcite .",
    "this is because in the simulations performed for this paper we allow only a weak dependence of the choice of matching on the degeneracy in our modified pma decoder .",
    "this means that the choice of matching is only weakly dependent on the degeneracy of the matching and the effect on the threshold is small .",
    "the value of the critical exponent @xmath64 found here is in agreement with the value found by merz and chalker when calculating the optimal threshold value @xcite , although it does not agree with value found by wang _",
    "for the mwpma decoder .",
    "the analysis presented in this appendix establishes the validity of the rescaling approach to the analysis for this choice of decoder by demonstrating that the scaling asatz , equation ( [ eqn : threshfit ] ) provides a good fit to the collapsed data close to the threshold .",
    "in this appendix we outline the derivation of the validity condition for the universal scaling hypothesis , @xmath100 given in equation ( [ eqn : p_min ] ) . the validity condition for the low @xmath1 expression , @xmath106 given in ( [ eqn : p_max ] )",
    "is not explicitly shown , but can be reproduced using a similar argument .",
    "the single qubit errors occur independently and at a rate @xmath1 . the weight of the error that arises",
    ", @xmath90 , obeys a binomial distribution with a mean that coincides with the typical error weight , @xmath132 and a variance of : @xmath133 according to the central limit theorem the binomial distribution can be approximated by a normal distribution for large enough lattice size .    for the universal scaling hypothesis",
    ", the condition we have proposed is that @xmath134 , the mean of the probability distribution , is large with respect to @xmath84 .",
    "this implies that the weight of the error chain that results is larger than @xmath84 with high probability .",
    "we can write this as @xmath135 , or @xmath136 where @xmath21 is the number of standard deviations above @xmath84 we require the mean to lie .",
    "we have chosen @xmath137 for both the universal scaling hypothesis and corresponding condition for the low @xmath1 expression .",
    "substituting equations [ eqn : binomial_mean ] and [ eqn : binomial_variance ] into equation [ eqn : usbreak ] we obtain @xmath138 solving for @xmath1 and taking only the highest order terms , we arrive at the expression for @xmath100 in equation ( [ eqn : p_min ] ) .",
    "k. chen , c - m .",
    "li , q. zhang , y - a .",
    "chen , a. goebel , s. chen , a. mair , and j - w .",
    "pan , _ phys .",
    "lett . _ * 99 * , 120503 ( 2007 ) .",
    "lu , w - b .",
    "gao , o. ghne , x - q .",
    "zhou , z - b .",
    "chen , and j - w .",
    "pan , _ phys .",
    "_ * 102 * , 030502 ( 2009 ) .",
    ". yao et al . , _ nature _ * 482 * , 489494 ( 2012 ) .",
    "p. schindler , j.t .",
    "barreiro , t. monz , v. nebendahl , d. nigg , m. chwalla , m. hennrich , and r. blatt , _ science _ * 332 * , 10591061 ( 2011 ) . j. zhang , d. gangloff , o. moussa , and r. laflamme , _ phys . rev . a _ * 84 * , 034303 ( 2011 ) . h.",
    "paik et al . , _ phys .",
    "lett . _ * 107 * , 240501 ( 2011 ) . c. rigetti et al . , _ phys .",
    "b _ * 86 * , 100506 ( 2012 ) .",
    "s.e . nigg and s.m .",
    "girvin , _ phys .",
    "_ * 110 * , 243604 ( 2013 ) .",
    "divincenzo , _ phys .",
    "scripta _ * 2009 * , 014020 ( 2009 ) .",
    "kitaev , _ ann . physics _ * 303 * , 230 ( 2003 ) .",
    "s.b . bravyi and a.yu .",
    "kitaev , arxiv : quant - ph/9811052 .",
    "r. raussendorf , j. harrington , and k. goyal , _ new j. phys . _ * 9 * , 199 ( 2007 ) .",
    "r. raussendorf and j. harrington , _ phys .",
    "lett . _ * 98 * , 190504 ( 2007 ) .",
    "s.d . barrett and t.m .",
    "stace , _ phys .",
    "lett . _ * 105 * , 200502 ( 2010 ) .",
    "a.g . fowler , m. mariantoni , j.m .",
    "martinis , and a.n .",
    "cleland , _ phys .",
    "a _ * 86 * , 032324 ( 2012 ) .",
    "e. dennis , a. kitaev , a. landahl , and j. preskill , _ j. math .",
    "phys . _ * 43 * , 4452 ( 2002 ) .",
    "stace , s.d .",
    "barrett , and a.c .",
    "doherty , _ phys .",
    "lett . _ * 102 * , 200501 ( 2009 ) .",
    "wang , a.g .",
    "fowler , a.m. stephens , and l.c.l .",
    "hollenberg , arxiv:0905.0531 .",
    "a. hutter , j.r .",
    "wootton , and d. loss , arxiv:1302.2669 .",
    "fowler , arxiv:1310.0863 .",
    "harrington , phd thesis , _",
    "california institute of technology _ , ( 2004 ) .",
    "g. duclos - cianci and d. poulin , _ phys .",
    "lett . _ * 104 * , 050504 ( 2010 ) .",
    "g. duclos - cianci and d. poulin , _ ieee itw _ 15 ( 2010 ) .",
    "h. bombin , r.s .",
    "andrist , m. ohzeki , h.g .",
    "katzgraber , and m.a .",
    "martin - delgado , _ phys .",
    "x _ * 2 * , 021004 ( 2012 ) .",
    "wootton and d. loss , _ phys .",
    "lett . _ * 109 * , 160503 ( 2012 ) .",
    "s. bravyi and a. vargo , arxiv:1308.6270 .",
    "d. gottesman , arxiv:1310.2984 .",
    "m. suchara , a. faruque , c - y .",
    "lai , g. paz , f.t .",
    "chong , and j. kubiatowicz , arxiv:1312.2316 .",
    "fowler , _ phys .",
    "a _ * 87 * , 062320 ( 2013 ) . c. wang , j. harrington , and j. preskill , _ ann . physics _ * 303 * , 3158 ( 2003 ) .",
    "a. hatcher , algebraic topology , _ cambridge university press _",
    "m. henle , a combinatorial introduction to topology , _ dover ( new york ) _ ( 1994 ) .",
    "a. honecker , m. picco , and p. pujol , _ phys .",
    "lett . _ * 87 * , 047201 ( 2001 ) .",
    "f. merz and j.t .",
    "chalker , _ phys .",
    "b _ * 65 * , 054425 ( 2002 )",
    ". m. ohzeki , _ phys .",
    "e _ * 79 * , 021129 ( 2009 ) .",
    "de queiroz , _ phys .",
    "b _ * 79 * , 174408 ( 2009 ) .",
    "s. bravyi and j. haah , _ phys .",
    "lett . _ * 111 * , 200501 ( 2013 ) .",
    "j. edmonds , _ canad .",
    "j. math . _",
    "* 17 * , 449467 ( 1965 ) .",
    "w. cook and a. rohe , _ informs j. comput .",
    "_ * 11 * , 138148 ( 1999 ) . t.m .",
    "stace and s.d .",
    "barrett , _ phys . rev .",
    "a _ * 81 * , 022317 ( 2010 ) . a.g .",
    "fowler , _ phys .",
    "lett . _ * 109 * , 180502 ( 2012 ) .",
    "v. kolmogorov , _ math .",
    "compu . _ * 1 * , 4367 ( 2009 ) .",
    "corless , g.h .",
    "gonnet , d.e.g .",
    "hare , d.j .",
    "jeffrey , and d.e .",
    "knuth , _ adv .",
    "_ * 5 * , 329359 ( 1996 ) .",
    "d. veberic , arxiv:1003.1628 .",
    "fowler , a.c .",
    "whiteside , and l.c.l .",
    "hollenberg , _ phys .",
    "_ * 108 * , 180501 ( 2012 ) ."
  ],
  "abstract_text": [
    "<S> to date , a great deal of attention has focused on characterizing the performance of quantum error correcting codes via their thresholds , the maximum correctable physical error rate for a given noise model and decoding strategy . </S>",
    "<S> practical quantum computers will necessarily operate below these thresholds meaning that other performance indicators become important . in this work we consider the scaling of the logical error rate of the toric code and </S>",
    "<S> demonstrate how , in turn , this may be used to calculate a key performance indicator . </S>",
    "<S> we use a perfect matching decoding algorithm to find the scaling of the logical error rate and find two distinct operating regimes . </S>",
    "<S> the first regime admits a universal scaling analysis due to a mapping to a statistical physics model . </S>",
    "<S> the second regime characterizes the behavior in the limit of small physical error rate and can be understood by counting the error configurations leading to the failure of the decoder . </S>",
    "<S> we present a conjecture for the ranges of validity of these two regimes and use them to quantify the overhead  the total number of physical qubits required to perform error correction . </S>"
  ]
}