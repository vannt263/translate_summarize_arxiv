{
  "article_text": [
    "nonlinear mixed effects models are widely used in population pharmacology for pharmacokinetics & pharmacodynamics ( pk / pd ) modelling .",
    "such models can be seen as special cases of repeated measurement data , for which the asymptotics concern the number of individuals rather than the number of measures per individual , see for instance @xcite and references therein . in this article , we show that for nonlinear mixed effects models with gaussian random effects , expectation maximization ( em ) like algorithms for the computation of the maximum likelihood estimator ( mle ) can be coupled with iterative conditional fitting ( icf ) like algorithms in order to take into account a prescribed pattern of zeros ( ppz ) in the variance matrix of the random effect .",
    "the icf algorithm has been developed very recently @xcite in the context of directly observed gaussian graphical models .",
    "finding an adequate approach for generic ppz in the context of nonlinear mixed effects models is a long standing problem .",
    "our approach provides a true solution for the m step of em in this context , for any ppz .",
    "it is thus far more satisfactory than the standard approaches used in the existing software packages such as nlmixed ( sas ) , nonmem , nlme ( s - plus and gnu - r ) , or monolix .",
    "for instance , a traditional model used in population pk / pd is of the form @xmath0 where @xmath1 is the vector of concentrations / effects observed on the @xmath2 individual for the drug of interest . here",
    "@xmath3 is a known function , often nonlinear .",
    "the @xmath4-vectors @xmath5 represent the unobserved individual parameters assumed independent and identically distributed @xmath6 , the @xmath7 are @xmath8 , unobserved , independent of the @xmath5 and independent .",
    "the matrix @xmath9 is the cholesky transform of a positive definite matrix that depends on a parameter @xmath10    for instance , figure [ fig : cortisol ] represents the maximum concentrations of cortisol ( @xmath1 ) obtained after giving fixed doses of acth to @xmath11 horses .",
    "each individual has its own curve described by the parameter @xmath5 .",
    "the @xmath9 matrix defines the variance heterogeneity of concentrations obtained with different doses .",
    "this matrix is often assumed to be equal to @xmath12 the reader will later find a study of a model like for this cortisol data set .",
    "one of the main goals in population pk / pd is to describe the distribution of the @xmath5 s by observation of the @xmath1 s .",
    "this amounts to the estimation of @xmath13 from the @xmath1 s .",
    "recall that the @xmath14 s are not observed .",
    "a natural approach is to compute the mle by maximizing @xmath15 where @xmath16 is the probability density function of the @xmath17 distribution and @xmath18 denotes the determinant of the matrix @xmath18 . except for specific models , such as _ gaussian linear _",
    "mixed effects models , maximum likelihood estimators have no closed form .",
    "several methods have been proposed for estimation of the parameter @xmath13 in these models .",
    "the methods suggested by beal and sheiner @xcite or lindstrom and bates @xcite are based on a linearization of the conditional model with respect to the vector @xmath5 about @xmath19 or about a posterior mode .",
    "pinheiro and bates @xcite , vonesh and carter @xcite , and wolfinger @xcite proposed laplacian approximations of the likelihood .",
    "importance sampling approximations @xcite , gaussian quadratures @xcite , and pseudo - likelihood methods @xcite have also been investigated .",
    "the reader will find a detailed analysis of these methods in the book by davidian and giltinan @xcite .",
    "more recently , stochastic versions of the em algorithm have been proposed , see for instance @xcite and @xcite .",
    "these em like algorithms converge to the mle under some regularity and identifiability conditions .    in many real situations ,",
    "the kineticist s knowledge of the drug mechanism imposes a specific independence pattern on some components of @xmath5 .",
    "this means that the variance matrix @xmath20 contains a ppz .",
    "the estimation of @xmath13 in the presence of a ppz in @xmath20 is problematic due to the positive definiteness constraint in the optimization .",
    "pinheiro and bates @xcite studied different parameterizations of @xmath20 that ensure the definite positiveness of the estimate . in particular",
    "they suggested the usage of a cholesky like parameterization .",
    "unfortunately , except for the case where @xmath20 is a block diagonal matrix up to coordinates permutation , cholesky like parametrizations do not preserve the structure of the ppz and are thus useless .",
    "kuhn and lavielle proposed estimating @xmath20 in two steps in the implementation of their em like algorithm .",
    "first , @xmath20 is estimated without any constraint , then zeros are plugged according to the ppz into the estimate provided by the first step .",
    "this method is widely used in practice .",
    "unfortunately , by `` forcing the zeros '' in this way , nothing guarantees that the obtained estimate is still a positive matrix , and even when it is positive definite , it is not the maximum likelihood in general .    for _ gaussian linear _",
    "mixed effects models , the algorithm of anderson @xcite deals with any linear hypothesis on the variance matrix of the random effect ( a ppz for instance ) .",
    "unfortunately , the estimate is not necessarily positive definite , see for instance @xcite . to our knowledge",
    ", no method is available for mle of _ nonlinear _ models such as when the variance matrix @xmath20 of the random effect has a ppz .",
    "the aim of this article is to propose a general method for the estimation of @xmath13 in the presence of a ppz in @xmath20 .",
    "the method uses the icf algorithm to perform the maximization step of the em algorithm .",
    "in other words , we couple em and icf in order to compute the mle ( or at least a stationary point of the likelihood ) of @xmath13 when @xmath20 has a ppz .",
    "the icf algorithm was developed recently by chaudhuri _",
    "_ in @xcite to estimate a variance matrix with ppz of _ observed gaussian",
    "_ random variables . in contrast , the random effects @xmath14 s in are gaussian but _ not observed _ , and that is why we couple icf with em .",
    "the icf converges towards positive definite saddle - points or local maxima of the likelihood function irrespective of the ppz .",
    "the idea behind icf is not new in the framework of graphical models , and is inspired by the famous iterative proportional fitting ( ipf ) algorithm .",
    "we refer to @xcite for a review .",
    "some alternative algorithms to icf are available for specific ppz , such as chain graph models @xcite or non - chordal graph models @xcite .",
    "the icf algorithm is attractive because it does not rely on a specific structure of the ppz .",
    "the rest of the article is organized as follows . in section 2 ,",
    "we give some of the properties and drawbacks of the popular `` zero forced '' estimator , that consists of plugging zeros according to the ppz into a full variance matrix . in section 3 ,",
    "we recall the main properties of the em algorithm for models such as .",
    "section 4 is devoted to the icf algorithm , and to the coupling of icf with em .",
    "section 5 contains the step by step analysis of a model like for the cortisol data set depicted in figure [ fig : cortisol ] . in the last section ,",
    "we perform a simulation study that quantifies the benefit of our em+icf approach on the model used for the cortisol data set .",
    "assume for example that for some specific model we get the following mle for  @xmath20 : @xmath21 without taking into account the ppz in @xmath20 .",
    "we will refer to this as the _ unconstrained _ estimation .",
    "if the ppz consists of @xmath22 , the `` zero forced '' estimation of @xmath20 is simply given by @xmath23 the unconstrained estimate @xmath24 is a positive definite matrix but the `` zero forced '' estimate @xmath25 is not .",
    "however we know that for a regular model , the unconstrained mle is consistent .",
    "therefore @xmath24 converges componentwise towards the true matrix @xmath20 with ppz .",
    "consequently , there exists a random sample size from which the `` zero forced '' estimator is a positive definite matrix but this sample size is somewhat difficult to obtain .    a possible ploy allowing to build a positive definite consistent estimator of @xmath20 could be as follows .",
    "compute the unconstrained estimator and denote it by @xmath25 , the corresponding `` zero forced '' estimator .",
    "nothing guarantees that its lower eigenvalue @xmath26 is positive but since @xmath25 is a consistent estimator of @xmath20 , the quantity @xmath27 is a random sequence of positive numbers that converges almost - surely to zero .",
    "now , consider some auxiliary sequence of positive real numbers @xmath28 that goes to zero with the sample size @xmath29 ( e.g. @xmath30 ) , then , for any sample size @xmath29 , the matrix @xmath31 is a positive definite consistent estimator of @xmath20 , and features the same ppz .",
    "its main drawback is that its diagonal terms are biased and that the choice of the @xmath28 sequence is arbitrary .",
    "a better way to proceed is to directly consider the mle of @xmath20 with ppz , which is precisely our aim in the next sections .",
    "the em algorithm @xcite is a popular method to estimate parameters of a model with non - observed or incomplete data .",
    "let us briefly recall how its general form works as introduced by dempster et al .",
    "the em algorithm consists of iterations of an expectation and a maximization step . at the @xmath32 iteration",
    ", the e step computes the conditional expectation of the log - likelihood of the complete data @xmath33 with respect to the distribution of the missing , or non - observed , data @xmath34 given the observed data @xmath35 at the current estimated parameter value @xmath36 : @xmath37.\\ ] ] the m step finds @xmath38 so that for all @xmath39 in the parameter space @xmath40 @xmath41 these two - step iterations are repeated until convergence .",
    "the essential property of the em algorithm is that the likelihood increases monotonically along the iterations . under some identifiability and regularity conditions",
    ", this algorithm converges to a stationary point of the likelihood , see for instance @xcite .",
    "let us now describe more precisely this algorithm for model .",
    "we need first to define the parameter space on which the m step is to be performed . in this model ,",
    "the parameter to be estimated is @xmath42 .",
    "the variance matrix @xmath20 lives in a subset of the set @xmath43 of @xmath44 symmetric positive definite matrices .",
    "more precisely , let @xmath45 be the set of subsets of @xmath46 .",
    "for any @xmath47 , the set @xmath48 is formed by the symmetric positive definite matrices that have zeros located in @xmath49 .",
    "the ppz in @xmath20 is represented by an element @xmath49 of @xmath45 .",
    "we thus assume that for some @xmath47 , @xmath50 where @xmath51 and @xmath52 are open subsets of @xmath53 and @xmath54 respectively .    at the @xmath32 iteration the expectation step consists of the computation of @xmath55    the maximization step computes @xmath56 for model , the integral that appears in the e step can be split into two parts .",
    "the e step reduces to calculate @xmath57 where @xmath58 and @xmath59 it follows that the m step can also be decomposed into two parts @xmath60 note that in the @xmath51 step the maximization with respect to @xmath61 is separated from that of @xmath62 .",
    "the function @xmath63 depends only on @xmath62 via @xmath64 .    in most applications ,",
    "@xmath65 is the probability density function of a standard gaussian distribution , and @xmath62 is a variance matrix that can possibly contain a ppz . in that case , its maximization can be performed using the icf method , as for @xmath20 , as described hereafter .",
    "maximization of @xmath66 leads to @xmath67 and @xmath68 where @xmath69 the matrix @xmath70 is an empirical conditional variance matrix .",
    "the random vectors @xmath5 are not observed , however , the matrix @xmath70 can be evaluated at each iteration of the algorithm .",
    "when @xmath71 , that is when @xmath20 has no ppz , @xmath72 reduces to @xmath70 . when @xmath73 the maximum of @xmath74 must be sought in @xmath75 . the next section deals with this problem",
    "we have seen in the previous section that the m step of the em algorithm involves a maximization problem such as @xmath76 the difficulty here is that the optimization is not performed on the entire cone of symmetric definite matrices but only on a sub - cone that contains the matrices with ppz .",
    "it is clear that a standard gradient - like algorithm does not fit these constraints .",
    "the usual method to get rid of the definite - positiveness constraint is to use a cholesky like decomposition .",
    "unfortunately , these decompositions do not preserve the ppz when @xmath20 is not a block diagonal matrix up to a permutation of the coordinates . the algorithm described",
    "hereafter allows one to move within @xmath75 whatever @xmath49 may be .",
    "first , note that in the absence of ppz in @xmath20 , _",
    "i.e. _ when @xmath71 , the solution of ( [ eq : opti ] ) is @xmath77 .",
    "we assume from now on that @xmath78 the case @xmath79 is trivial since the only possible zero is @xmath80 . in this case",
    ", the `` zero forced '' estimator is always positive definite and is the solution of ( [ eq : opti ] ) .",
    "we assume in the sequel that @xmath81 and that @xmath82 .",
    "the method we propose is the core of the icf algorithm presented in @xcite .",
    "even if chaudhuri & al . did not express it at such , it is mainly based on the specific properties of the schur complement of a matrix .",
    "let us recall the following classical result , which can be found in @xcite or @xcite for instance .",
    "let @xmath83 be an integer in @xmath84 .",
    "consider two vectors @xmath85 and @xmath86 that respectively belong to @xmath87 and @xmath88 , the q - vector @xmath89 and a matrix @xmath90 that admits the following block decomposition @xmath91 where @xmath92 , @xmath93 is a @xmath94 matrix and @xmath95 .",
    "the schur complement of @xmath96 is the matrix @xmath97 it belongs to @xmath98 and moreover    * @xmath99 , * @xmath100    the schur complement appears naturally when the random vector @xmath101 described in the previous theorem is distributed according to @xmath102 .",
    "more precisely we have : @xmath103    note that properties i ) and ii ) remain true after permutation of the rows of @xmath20 . in the particular case",
    "where @xmath104 , we can easily derive the following property .",
    "we keep the same notations as in the previous proposition . for any @xmath105 ,",
    "let @xmath106 be the submatrix of @xmath20 obtained by removing its @xmath107 row and column , @xmath108 the @xmath107 column vector of @xmath20 in which the @xmath107 row has been removed , @xmath109 . the column vector @xmath85 and the positive real number @xmath86 are respectively obtained by removing the @xmath107 row of @xmath101 and as @xmath110 . then , using these notations , the schur complement of @xmath106 is the real positive number @xmath111 given by the previous proposition and properties i ) and ii ) hold .",
    "we are now able to solve the optimization problem ( [ eq : opti1 ] ) by running iteratively the decomposition of the corollary over the columns of @xmath20 .",
    "set @xmath112 and note that from ( [ eq : opti ] ) the function that has to be minimized can be rewritten as latexmath:[\\[\\label{eq : vrais } k(\\sigma , t_{1},\\ldots , t_{n } ) = \\frac{1}{n } \\sum_{i}\\mathbf{e}\\left ( t_{i}'\\sigma^{-1 } t_{i}|y_{i},m_{k},\\sigma_{k}\\right ) + \\log     for the @xmath107 column of @xmath20 we set @xmath106 , @xmath108 , @xmath109 and @xmath114 so that we can now write ( [ eq : vrais ] ) as @xmath115 where @xmath116 is the @xmath107 component of @xmath117 and @xmath118 is obtained by removing the @xmath107 component of @xmath117 .",
    "therefore , if @xmath96 is fixed , the partial optimization of @xmath119 with respect to @xmath120 can be reduced to the global optimization of @xmath121 which is a standard least - squares problem .",
    "the optimization with respect to @xmath93 and @xmath111 leads to @xmath122^{-1 }    \\sum_{i}\\mathbf{e}\\left ( v_{i}a^{-1}u_{i}|y_{i},m_{k},\\sigma_{k}\\right ) \\\\    & = & a\\left [ \\sum_{i}\\mathbf{e}\\left ( u_{i}u_{i}'|y_{i},m_{k},\\sigma_{k}\\right ) \\right ] ^{-1 }    \\sum_{i}\\mathbf{e}\\left ( v_{i}u_{i}|y_{i},m_{k},\\sigma_{k}\\right ) .\\end{aligned}\\ ] ] and @xmath123 the vector @xmath108 may contain some ppz .",
    "these components are not optimized and are thus left at zero .",
    "this only decreases the dimension of the optimization problem .",
    "we deduce that after this step on the @xmath107 column of @xmath20 , @xmath109 and @xmath108 must be respectively updated with @xmath124 the striking property of this step is that it allows us to move within @xmath125 without affecting the prescribed null components of @xmath20 : @xmath106 and the null components of @xmath108 are left unchanged .",
    "since @xmath20 is assumed positive definite @xmath109 can not be zero .",
    "as already mentioned , iterations of these steps converge to a local maximum of @xmath119 , see for instance @xcite .",
    "in this section , we use a practical example to illustrate the implementation of an em algorithm coupled with the icf algorithm . in order to explore the endocrine function of horse ,",
    "a sample of horses ( @xmath11 ) was given eight doses of acth by intravenous route .",
    "the acth stimulates the adrenal gland that produces cortisol .",
    "the concentration profiles of cortisol in plasma were summarized by the maximal concentration reached after the acth administration ( see figure [ fig : cortisol ] ) .",
    "the seven doses of acth given to each animal were ( in mg / kg ) @xmath126 the production of cortisol is modelled as @xmath127 where @xmath128 is the maximal cortisol concentration observed in the @xmath2 horse after administration of a dose @xmath129 of acth , @xmath130 is a random vector that contains the individual parameters for the @xmath2 animal .",
    "we assume that the random vectors @xmath5 are independent and identically distributed @xmath6 and that the residual terms @xmath131 are independent and identically distributed @xmath132 .",
    "moreover , the @xmath5 s and @xmath7 s are assumed to be mutually independent . in this example , @xmath133 , @xmath134 and @xmath135 according to the kineticist , the correlations between @xmath136 and @xmath137 and @xmath138 and @xmath137 should be zero and thus @xmath20 has the following structure @xmath139 in some problems , no _ a priori _ information is available for the possible zero correlation between the components of @xmath5 .",
    "the method of multiple testing of correlation , as described in drton and perlman @xcite , may be used in such cases to reveal the structure of @xmath20 .",
    "the estimation of model parameters requires evaluation of the conditional expectations of functions such as @xmath140 a standard approach is to use a stochastic version of em that consists of the simulation of a markov chain @xmath141 with @xmath142 as unique stationary distribution by using a metropolis - hastings algorithm and the approximation of the conditional expectation by @xmath143 for the analysis of the cortisol data we chose @xmath144 we simulated the markov chain with the metropolis - hastings algorithm with @xmath145 as the proposal distribution . in this case",
    ", the acceptance probability of the metropolis - hastings algorithm reduces to @xmath146 which only depends on the conditional distribution of the observation .",
    "the algorithm to estimate the model parameters can be summarized in the following scheme :    1 .",
    "start from some initial guess @xmath147 and set @xmath148 ; 2 .   compute @xmath149 from ( [ eq : moyenne ] ) and @xmath150 where @xmath151 is a diagonal matrix whose @xmath107 term is @xmath152 .",
    "3 .   set @xmath153 and and set @xmath154 4 .",
    "for j:=1 to @xmath155 + increment @xmath83 + compute @xmath156 and @xmath157 where @xmath158 and @xmath159 are respectively defined by and  ; 5 .",
    "if @xmath160 and @xmath161 are not close enough go to step 4 .",
    "otherwise set @xmath162 ; 6 .",
    "stop if @xmath163 and @xmath164 are close enough .",
    "otherwise increment @xmath165 and go to step 2 .    for standard em algorithms , _",
    "i.e. _ when no constraint is imposed on the structure of @xmath20 , steps 3 ) , 4 ) and 5 ) of the previous algorithm should be replaced by the update of @xmath166 according to equation .",
    "it is well known that standard em algorithms go quickly to a stationary point of the likelihood during the first iterations and then take time to converge . since for stochastic em algorithms the criterion being optimized changes randomly at each iteration , it is somewhat difficult to achieve and check convergence even when the length @xmath167 of the simulated markov chain is large .",
    "improvements have been proposed to overcome these problems . in particular kuhn and lavielle",
    "@xcite suggested updates of the following form  : @xmath168 where @xmath169 is a decreasing sequence of positive numbers , @xmath170 is defined as in the previous algorithm and @xmath171 is the update of @xmath163 .",
    "note that this update scheme forces the algorithm to converge and preserves the ppz as well as the positive definiteness of @xmath20 .    the sequence @xmath169 should satisfy @xmath172 and @xmath173 .",
    "these two conditions are fulfilled when @xmath174 with @xmath175 and @xmath176 .",
    "choosing @xmath177 speeds - up convergence of the algorithm but the choice of @xmath178 has to be made sample by sample .",
    "choosing the same @xmath178 for all samples can lead to poor estimations .",
    "as practical advice , we suggest choosing @xmath179 .",
    "the algorithm takes more time to converge but a fine tuning of @xmath178 is unnecessary .",
    "a well known drawback of the em algorithm is that it does not produce standard errors as a by - product .",
    "we implemented the method proposed by jamshidian and jennrich @xcite .",
    "this method relies on numerical derivation and seems well - suited to the method we propose .",
    "even if standard errors are helpful for comparing the results obtained with these two models , the fisher information matrix gives pertinent quantitative information only when the sample size is large enough .",
    "however , @xmath11 is probably not a large sample size . in the next section",
    "we use simulations to weight the performance of the estimation proposed for the cortisol data .",
    "the estimation of the model parameters for the cortisol data requires some initial estimates to be provided .",
    "thanks to the model parametrization , we can directly read reasonable values for @xmath180 on figure  [ fig : cortisol ] . since the four components of @xmath34 respectively represent the basal value of cortisol , the maximal increase , the  slope \" of the sigmoid and the acth dose for which half the maximal increase is obtained we roughly get @xmath181 .",
    "we initialize @xmath20 with the following diagonal matrix : @xmath182 .",
    "finally , for this heteroscedastic model , @xmath183 can be interpreted as the coefficient of variation of the cortisol for a given dose .",
    "we set it at @xmath184 that is @xmath185 we estimated @xmath20 with em alone ( no constraint was imposed ) and with em+icf that preserves the ppz . in this example , the algorithm seems to converge in less than 400 iterations .",
    "we implemented this algorithm in c++ with a matrix library .",
    "estimates of the parameters obtained with em alone were : @xmath186 the figures between brackets are the standard errors for the variances .",
    "we have chosen to give only some standard errors to lighten the presentation .",
    "@xmath187 , @xmath188 , @xmath189 and @xmath190 .",
    "estimates of the parameters obtained with the em+icf algorithm were : @xmath191 @xmath192 , @xmath193 and @xmath194 and @xmath195 .",
    "we can see that these likelihoods are about the same and a likelihood ratio test would not reject the ppz proposed by the kineticist .",
    "the residual variance estimates are also very close . surprisingly , there are quite large differences between the estimates of the third component of @xmath196 and the non null components of @xmath20 .",
    "the general problem of mean and variance modelling for longitudinal data is delicate , and several choices are possible , see for instance @xcite , @xcite , @xcite , @xcite , and @xcite .",
    "our model belongs to a standard family of models in pk / pd and was chosen with the kineticist .",
    "this relatively simple model is heteroscedastic with a constant coefficient of variation .",
    "an examination of the `` individual '' residuals shows that they are centered , which is quite satisfactory .",
    "the aim of this section is to quantify the potential benefit of directly estimating a variance matrix with ppz .",
    "we simulated 100 data sets using model with parameters close to the estimate found in the cortisol data analysis : @xmath11,@xmath197 , @xmath198 both em and em+icf estimates were calculated .",
    "results are given in table [ tab : tab1 ] .",
    ".empirical mean , standard error and square root of mean - quadratic - error of the estimates ( m.q.e . ) obtained with em and em+icf .",
    "the mean quadratic - error is defined as bias@xmath199 variance . [ cols=\"<,^,^,^,^,^,^,^\",options=\"header \" , ]     as expected , the standard errors given in the example are smaller than those of table [ tab : tab1 ] . for such sample sizes , which are often encountered in practice , asymptotic statistics should be interpreted with care .",
    "the mean parameter @xmath196 seems to be well estimated . at least on these simulations",
    ", the @xmath20 structure influences the estimation of @xmath196 .",
    "however , we notice that the estimates obtained with em+icf have a smaller standard error and mean quadratic error ( m.q.e . ) than those obtained without any constraint . on the whole em+icf also gives estimates with lower bias .",
    "this suggests that the mean and variance estimations are heavily dependent .",
    "this sheds light on approaches , such as the ` zero forced' method , that rely on estimating the full variance matrix first and modify it by forcing the ppz : since all the non zero entries are estimated with the assumption that the variance matrix does not have prescribed zeros , they could be poorly estimated .",
    "this is consistent with the results obtained by ye and pan @xcite who concluded , in a different context , that misspecification of the working variance structure could lead to a large loss in efficiency of the estimators of the mean parameters .",
    "likelihood ratio tests were performed to test @xmath200 for @xmath201 .",
    "note that whatever the value of @xmath49 , @xmath202 is not on the boundary of @xmath203 .",
    "consequently , the likelihood ratio statistics follow asymptotically a chi - square distribution under @xmath202 .",
    "since the data have been simulated under @xmath202 , the p - values distribution should be close to a uniform law on @xmath204 at least for large @xmath29 .",
    "the q - qplot of the p - values is represented in figure [ fig : qq ] .",
    "this figure shows that the p - values are not distributed according to a uniform distribution and thus the distribution of the likelihood ratio statistics is not close to a @xmath205 distribution .",
    "consequently , @xmath11 is probably not large enough to trust asymptotic statistics .",
    "we have proposed a method for the estimation of the variance matrix with ppz in nonlinear mixed effects models .",
    "this method , which consists of coupling an icf like algorithm with an em like algorithm gives more efficient estimates than standard em that ignore the ppz . for the sake of simplicity",
    ", we have only presented the estimation algorithm for independent and identically distributed observations .",
    "extension to different numbers of observations per individual is straightforward .",
    "we also restricted our study to models with gaussian @xmath206 .",
    "more general models in which the distribution of @xmath206 is not gaussian and depends on a parameter @xmath207 can also be considered .",
    "this simply requires the metropolis - hastings chain to be chosen accordingly .",
    "we deliberately chose to show in section 2 a columnwise icf implementation that can be extended using theorem 1 to blocks of @xmath20 .",
    "of course , our approach can be adapted without much effort to many versions of em and many alternatives to icf . for pedagogical reasons",
    ", we presented our em+icf coupling on a low dimensional example .",
    "the method of course is particularly suited to large variance matrices with a high percentage of prescribed zero entries .",
    "* acknowledgements . *",
    "we thank dr .",
    "alain  bousquet - mlou who provided the cortisol data set and for valuable advice regarding the model and the specific structure of @xmath20 .",
    "we also thank dr .",
    "mathias  drton for interesting discussions on the icf algorithm and for providing the last version of @xcite before publication",
    ". the final form of this article has greatly benefited from the questions and suggestions of two anonymous reviewers .",
    "didier  concordet , d.concordet(at)envt.fr + djalil  chafa , d.chafai(at)envt.fr ( corresponding author ) + umr181 , inra , envt , + 23 , chemin des capelles , b.p .",
    "87614 , f-31076 toulouse cedex 3 , france + * and * + umr cnrs 5219 , institut de mathmatiques de toulouse , + universit paul sabatier , 118 route de narbonne , f-31062 , toulouse cedex 9 , france ."
  ],
  "abstract_text": [
    "<S> we propose a new method for the maximum likelihood estimator ( mle ) of nonlinear mixed effects models when the variance matrix of gaussian random effects has a prescribed pattern of zeros ( ppz ) . </S>",
    "<S> the method consists of coupling the recently developed iterative conditional fitting ( icf ) algorithm with the expectation maximization ( em ) algorithm . </S>",
    "<S> it provides positive definite estimates for any sample size , and does not rely on any structural assumption concerning the ppz . </S>",
    "<S> it can be easily adapted to many versions of em .    </S>",
    "<S> * keywords : * nonlinear mixed effects models ; maximum likelihood ; expected maximisation algorithm ; logitudinal data analysis ; repeated measurements ; iterated proportional fitting algorithm ; gaussian graphical models ; stochastic inverse problems ; pharmacokinetic / pharmacodynamics analysis . </S>"
  ]
}