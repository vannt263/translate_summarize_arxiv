{
  "article_text": [
    "the laws of thermodynamics describe the transport of heat and work in macroscopic ( _ i.e. _ , large scale ) processes and play a fundamental role in the physical sciences .",
    "the theory of thermodynamics is primarily an intellectual achievement of the @xmath1 century .",
    "the first analysis of heat engines was given by the french engineer sadi carnot in his seminal 1824 publication ( ` _ _ reflections on the motive power of fire and on machines fitted to develop that power _ _ '",
    "@xcite ) , laying the foundations to the @xmath0 law of thermodynamics .",
    "this paper marks the start of thermodynamics as a modern science  @xcite .",
    "the classical theory of thermodynamics was formulated in consistent form by giants like joule , clausius , lord kelvin , gibbs and others .",
    "the atomic , or microscopic ( _ i.e. _ , small scale ) approach to statistical thermodynamics was mainly developed through the pioneering work of clausius , maxwell , boltzmann and gibbs , laying the foundations to the more general discipline of statistical mechanics  @xcite .",
    "in particular , the @xmath0 thermodynamic law , for quasi - static processes , linearly relates the change in the entropy , @xmath2 , to the amount of heat , @xmath3 , absorbed to a system at equilibrium , @xmath4 , where @xmath5 is the temperature of the system .",
    "however , the @xmath0 law , in its classical formulation , is suited only for systems with energy hamiltonian ( function ) , @xmath6 , which is _ not _ an explicit function of the temperature and fails to capture the physical behavior of systems with temperature - dependent energy levels . while such temperature - dependent energy function is uncommon in the study of natural and artificial systems in physics , it surprisingly does arise in modeling communication channels , like the popular gaussian - noise communication channel  @xcite , as a ( quasi - static ) thermal system  @xcite .    in this contribution",
    ", we generalize the @xmath0 thermodynamic law to encompass systems with temperature - dependent hamiltonian and obtain the generalized law , where @xmath7 denotes averaging over the standard boltzmann distribution .",
    "consequently , it allows for an alternative physical description to the shannon - theoretic notions of information entropy and mutual information  @xcite via the thermodynamic quantities of energy and temperature . as an example , the correct expressions for the mutual information of a gaussian channel with bernoulli-1/2 input and gaussian input are computed from the thermodynamic representation , where the latter corresponds to the shannon capacity .",
    "guo , shamai and verd  @xcite have recently revealed a simple , yet powerful relationship ( hereinafter termed gsv theorem ) between information and estimation theories .",
    "this cross - theory theorem bridges over the notions of shannon s mutual information and minimum mean - squre error ( mmse ) for the common additive white gaussian noise channel . based on the thermodynamic expression of mutual information , the gsv theorem is naturally re - derived .",
    "this directly links the gsv theorem to the most profound laws of nature and gives the physical origin to this remarkable formula .",
    "the paper is organized as follows .",
    "the thermodynamic background is discussed in sections  [ sec_classical ] and  [ sec_statistical ] . in section  [ sec_gaussian ]",
    "the gaussian channel is represented through an equivalent thermal system giving a thermodynamic expression to the notions of information entropy and mutual information . in section  [ sec_gsv ] the gsv theorem is proven via thermodynamics .",
    "we conclude the paper in section  [ sec_conclusion ] .    we shall use the following notations .",
    "@xmath8 is used to denote either a probability mass function ( pmf ) , @xmath9 , or a probability density function ( pdf ) , @xmath10 , depending on the random variable having either discrete or continuous support , respectively .",
    "random variables are denoted by upper case letters and their values denoted by lower case letters .",
    "the symbol @xmath11 denotes expectation of the random object within the brackets with respect to the subscript random variable .",
    "the natural logarithm , @xmath12 , is used .",
    "the support of a variable @xmath13 is denoted by @xmath14 .",
    "in this section we concisely summarize the fundamental results of classical thermodynamics , essential to our discussion .",
    "the interested reader is strongly encouraged to find a thorough introduction to thermodynamics in one of numerous textbooks ( _ e.g. _ ,  @xcite ) .",
    "a thermodynamic system is defined as the part of the universe under consideration , separated from the rest of the universe , referred to as environment , surroundings or reservoir , by real or imaginary boundary .",
    "a non - isolated thermodynamic system can exchange energy in the form of heat or work with any other system .",
    "heat is a process by which energy is added to a system from a high - temperature source , or lost to a low - temperature sink .",
    "work refers to forms of energy transfer which can be accounted for in terms of changes in the macroscopic physical variables of the system ( _ e.g. _ , volume or pressure ) .",
    "for example , energy which goes into expanding the volume of a system against an external pressure , by driving a piston - head out of a cylinder against an external force .",
    "hereinafter we consider a thermal system which does not perform work , mechanical or other .",
    "this thermal system is assumed to be in equilibrium , that is all the descriptive macroscopic parameters of the system are time - independent .",
    "we also assume that the process of exchanging heat is infinitesimally quasi - static , _",
    "i.e. _ , it is carried out slowly enough that the system remains arbitrarily close to equilibrium at all stages of the process .",
    "the underlying laws of thermodynamics consist of purely macroscopic statements which make no reference to the microscopic properties of the system , _",
    "i.e. _ , to the molecules or particles of which they consist . in the following statements we present the thermodynamic laws in a form relevant to the thermal system under consideration .",
    "law s statement is omitted . ]",
    "( conservation of energy ) a system in equilibrium can be characterized by a quantity @xmath15 , called the ` internal energy ' .",
    "if the system is not isolated , interact with another system and no work is done by it , the resulting change in the internal energy can be written in the form du = d-6mu26q , where @xmath3 is the amount of heat absorbed by the system . rather than @xmath16 because , in mathematical terms , it is not an exact differential .",
    "the integral of an inexact differential depends upon the particular path taken through the space of ( thermodynamic ) parameters while the integral of an exact differential depends only upon the initial and final states . ]",
    "( definition of temperature ) a system in equilibrium can be characterized by a quantity @xmath17 , called the ` thermodynamic entropy ' . if the system is not isolated and undergoes a quasi - static infinitesimal process in which it absorbs heat @xmath3 , then [ eq_second_law ] ds=,where @xmath5 is a quantity characteristic of the system and is called the ` absolute temperature ' of the system .",
    "( zero entropy ) the thermodynamic entropy @xmath17 of a system has a limiting property that t0_+,ss_0 , where @xmath18 is a constant ( usually @xmath19 in case of non - degenerate ground state energy ) independent of all parameters of the particular system .    incorporating the three laws of thermodynamics together ,",
    "a combined law describing the thermodynamic entropy as an integration function over the temperature is obtained [ eq_s ] s(t)=_0^tdu()=_0^td=_0^td , where c_v(t ) is known as the heat capacity ( at constant volume @xmath20 ) .",
    "the heat capacity is a non - negative temperature - dependent measurable quantity describing the amount of heat required to change the system s temperature by an infinitesimal degree .",
    "let us now define the inverse temperature , where the constant @xmath21 is the boltzmann constant . in this contribution we arbitrarily set @xmath22 , thus .",
    "hence , the entropy integral  ( [ eq_s ] ) can be rewritten in terms of the inverse temperature as [ eq_s_beta ] s()=-_^c_v()d , where c_v()=-t^2c_v(t ) .",
    "moving to the microscopic perspective of statistical thermodynamics  @xcite , the probability , @xmath23 , of finding the system in any one particular microstate , @xmath24 , of energy level @xmath25 is dictated according to the canonical boltzmann distribution  @xcite [ eq_boltzmann ] p(x = x)= , where is the partition ( normalization ) function , and the sum extends over all possible microstates of the system .    applying the boltzmann distribution ,",
    "the macroscopic quantities of internal energy and entropy can be described microscopically as the average energy and the average @xmath26 , respectively .",
    "explicitly , u&=&_x\\{(x)}[eq_u ] , + s&=&_x\\{-p(x ) } , and it can be easily verified that the following relation holds [ eq_identity ] = -u+s .",
    "consider a real - valued channel with input and output random variables @xmath13 and @xmath27 , respectively , of the form [ eq_channel ] y = x+n , where is a gaussian noise independent of @xmath13 , and @xmath28 is the channel s signal - to - noise ratio ( snr ) .",
    "the input is taken from a probability distribution @xmath29 that satisfies @xmath30 .",
    ", @xmath31 follows the usual notion of snr . for @xmath32",
    ", @xmath31 can be regarded as the gain in the output snr due to the channel . ]    the gaussian channel  ( [ eq_channel ] ) ( and any other communication channel ) can be also viewed as a physical system , operating under the laws of thermodynamics .",
    "the microstates of the thermal system are equivalent to the hidden values of the channel s input @xmath13 . a comparison of the channel s a - posteriori probability distribution , given by p(x = x|y = y)&= & + & = & + & = & [ eq_denom ] , with the boltzmann distribution law  ( [ eq_boltzmann ] ) yields the following mapping of the inverse temperature and energy of the equivalent thermal system [ eq_snr_map ] & & , + -xy+- & & ( x = x|y = y;).[eq_energy_map ]    note that the temperature ( _ i.e. _",
    ", the noise variance according to the mapping  ( [ eq_snr_map ] ) ) can be increased gradually from the absolute zero to its target value @xmath33 in infinitesimally small steps , thus the gaussian channel system can remain arbitrarily close to equilibrium at all stages of this process .",
    "hence , the equivalent thermal system exhibits a quasi - static infinitesimal process .",
    "interestingly , the notion of quasi - statics is reminiscent to the concept of gaussian pipe in the snr - incremental gaussian channel approach taken by guo  _ et al . _",
    "* section ) .",
    "thus , we can apply the entropy integral  ( [ eq_s_beta ] ) obtained from thermodynamics to the thermal system being equivalent to the gaussian channel , yielding [ eq_s_final ] s()=s(x|y = y;)=-_^c_v()d=-_^d , where following  ( [ eq_u ] ) the internal energy , @xmath34 , is the energy averaged over all possible values of @xmath13 , given @xmath35 .",
    "the posterior information ( shannon ) entropy , @xmath36 , ( in nats ) of the channel can be expressed via the thermodynamic entropy conditioned on @xmath37 , @xmath38  ( [ eq_s_final ] ) , as [ eq_s_xgiveny ] h(x|y;)=_y\\{s(x|y = y;)}=-_y\\{_^d}. the input s entropy can also be reformulated in a similar manner , since @xmath39 ) .",
    "hence , h(x)&=&-_y\\{_0^d}.    now , the input - output mutual information can be described via thermodynamic quantities , namely the energy , @xmath6 , and inverse temperature , @xmath40 , as [ eq_i ] i(x;y)&=&i()h(x)-h(x|y ; ) + & = & -_y\\{_0^d } + & = & -_0^+_y\\{_0^u(y;)d}[eq_rhs ] , [ eq_mi_integral]where  ( [ eq_rhs ] ) is obtained using integration by parts .",
    "note that this thermodynamic interpretation to the mutual information holds not only for the gaussian channel , but also for any channel which can be described by a thermal system exhibiting quasi - static heat transfer . in the following",
    "we illustrate the utilization of  ( [ eq_rhs ] ) by re - deriving the correct expression for the mutual information of a gaussian channel with bernoulli-1/2 input .",
    "+    * _ example : gaussian channel with bernoulli-@xmath41 input _ *    since the input @xmath13 in this case is binary and equiprobable ,",
    "_ i.e. _ @xmath42 , the @xmath43 and @xmath44 terms of the gaussian channel s energy  ( [ eq_energy_map ] ) are independent of @xmath13 and can be dropped ) . ] , leaving us with the expression , independent of @xmath40 , ( x = x|y = y)=-xy .",
    "the a - posteriori probability mass function gets the form ( x = x|y = y)=,x1 .",
    "hence , the internal energy is u(y = y;)=_x|y\\{(x|y = y)}=-y(y ) .",
    "the marginal pdf of the output is then given by p(y = y)=(+ ) .",
    "thus , -_y\\{u(y;)}&=&-_-^y(y)p(y = y)dy + & = & -_-^y ( -)dy + & = & ( 1-(-1))=and _ y\\{_0^u(y;)d}&=&_-^p(y=",
    "y)_0^u(y = y;)ddy + & = & -_-^dy giving , based on  ( [ eq_rhs ] ) , i()=-_-^dy , which is identical to the known shannon - theoretic result ( see , _ e.g. _ ,  ( * ? ? ?",
    "* eq . ( 18 ) ) and  @xcite ) .      when trying to repeat this exercise for a gaussian input one finds that  ( [ eq_mi_integral ] ) fails to reproduce @xmath45 , which is the celebrated formula for the shannon capacity of the gaussian channel .",
    "this observation can be explained as follows .",
    "the @xmath0 thermodynamic law , as stated above , holds only for systems with an energy function , @xmath6 , which is _ not _ a function of the temperature .",
    "while the temperature - independence of @xmath6 is a well - known conception in the investigation of both natural and artificial systems in thermodynamics , and physics at large , such independence does not necessarily hold for communication channels and particularly for the gaussian channel .",
    "actually , one can easily observe that the gaussian channel s energy  ( [ eq_energy_map ] ) is indeed an explicit function of the temperature via the @xmath44 term , unless this term can be dropped by absorbing it into the partition function , as happens for equiprobable input distributions , like the discrete bernoulli-1/2 or the continuous uniform distributions .",
    "this is exactly the reason why  ( [ eq_mi_integral ] ) does succeed to compute correctly the mutual information for the particular case of a bernoulli-@xmath41 input source .    in order to capture the temperature - dependent nature of the energy in systems like the communication channel",
    ", we generalize the formulation of the @xmath0 law of thermodynamics @xmath46 .",
    "( redefinition of temperature ) if the thermal system is not isolated and undergoes a quasi - static infinitesimal process in which it absorbs heat @xmath3 , then [ eq_g_second_law ] ds=-_x\\{}dt .",
    "the differential of the partition function s logarithm , @xmath47 , can be written as d = d . utilizing the identity  ( [ eq_identity ] ) , one obtains ds = d(u)+d . since for @xmath5-dependent energy = -u-_x\\ { } , we get ds = d(u)-ud-_x\\{}d = du-_x\\{}d , where the r.h.s .",
    "results from leibniz s law ( product rule ) .",
    "recalling that according to the @xmath48 law @xmath49 concludes the proof .",
    "the generalized @xmath0 law of thermodynamics  ( [ eq_g_second_law ] ) has a clear physical interpretation . for simplicity ,",
    "let us assume that the examined system is characterized by a comb of discrete energy levels @xmath50 .",
    "the heat absorbed into the @xmath5-dependent system has the following dual effect : a first contribution of the heat , @xmath51 , increases the temperature of the system while the second contribution , @xmath52 , goes for shifting the energy comb .",
    "however , the shift of the energy comb does _ not _ affect the entropy , since the occupation of each energy level remains the same , and the entropy is independent of the energy values which stand behind the labels @xmath50 .",
    "the change in the entropy can be done only by moving part of the occupation of one tooth of the energy comb to the neighboring teeth , and this can be achieved only by changing the temperature .",
    "hence , the effective heat contributing to the entropy is @xmath53 , and this is the physical explanation to the generalized @xmath0 law  ( [ eq_g_second_law ] ) .",
    "note that for @xmath5-independent energy , the classical @xmath0 law  ( [ eq_second_law ] ) is immediately obtained .",
    "note also , that the @xmath48 law remains unaffected , @xmath49 , since both ways of heat flow absorption into the system are eventually contributing to the average internal energy @xmath15 .",
    "the generalized @xmath0 law specifies the trajectory , the weight of each one of the two possible heat flows , at a given temperature .",
    "the temperature , originally defined by the @xmath0 law as @xmath54 , is redefined now as==. this redefinition has a more complex form and involves an implicit function of @xmath5 since the temperature appears on both sides of the equation .",
    "based on the generalized @xmath0 law , the thermodynamic expression for the mutual information  ( [ eq_i ] ) of quasi - static ( _ e.g. _ , gaussian ) communication channels can be reformulated as [ eq_i2 ] i(x;y)&=&-_y\\{_0^(du(y;)+_x|y\\{}d ) } + & = & -_y\\{_0^(+_x|y\\{})d}[eq_i_beta ] + & = & -_0^ + _ y\\{_0^(u(y;)+_x|y\\{})d}. [ eq_mi_integral2]again , the example of a gaussian channel with , this time , standard gaussian input is used to illustrate the utilization of  ( [ eq_mi_integral2 ] ) for the correct derivation of the mutual information .",
    "+    * _ example : gaussian channel with @xmath55 input _ *    since in this case @xmath56 , the energy  ( [ eq_energy_map ] ) of the gaussian channel system becomes an explicit function of @xmath40 , given by ( x = x|y = y;)=-xy+ ( ) , and the derivative of this function with respect to @xmath40 yields = - .",
    "the a - posteriori probability density function is p(x = x|y = y;)= ( , ) .",
    "hence , the internal energy is u(y = y;)=_x|y\\{(x|y = y;)}=-+ , and the derivative of the energy averaged over all possible inputs is _ x|y\\{}=-(+ ) .",
    "the marginal pdf of the output is given by p(y = y)=(0 , ) .",
    "thus , & & -_0^=--(-)= , and & & _ y\\{_0^(u(y;)+_x|y\\{})d } + & & = _ y\\{_0^ } + & & = _ y\\{-+(1+)-+(1+)-(1+)-+ } +   + & & = -+ giving , based on  ( [ eq_mi_integral2 ] ) , i(x;y)= and the shannon capacity  @xcite is derived from the perspective of thermodynamics .",
    "in this section we prove the guo - shamai - verd ( gsv ) theorem from the @xmath0 law of thermodynamics for systems with @xmath5-dependent energy and the resulting thermodynamic representation of the mutual information .",
    "thus , we show that this fascinating relation between information theory and estimation theory is actually an evolution of the most profound laws of nature .    to start with ,",
    "let us restate the gsv theorem .",
    "consider a gaussian channel of the form [ eq_channel_gsv ] y = x+n , where is a standard gaussian noise independent of @xmath13 . the mutual information , @xmath57  ( [ eq_i ] ) , and the minimum mean - square error , defined as ( x|x+n)&=&()=_x , y\\{(x-_x|y\\{x|y;})^2 } , are both a function of @xmath31 and maintain the following relation .",
    "* theorem 1 ) for every input distribution @xmath29 that satisfies @xmath30 , [ eq_gsv1 ] i(x;x+n)=(x|x+n ) .",
    "note that the gsv - based expression of the mutual information , [ eq_i_gsv ] i(x;x+n)=_0^(x|x+n)d , resembles its thermodynamic expression  ( [ eq_i_beta ] ) in the sense that both are an outcome of integration with respect to snr ( or inverse temperature , @xmath40 ) .",
    "hence , the roots of this integration in the gsv theorem may be attributed to the @xmath0 law of thermodynamics .",
    "note however to the opposite order of integration in the two expressions , where in the gsv expression  ( [ eq_i_gsv ] ) the inner integration ( within the definition of mmse ) is over @xmath35 and the outer integration is over snr , and vice versa for the thermodynamic expression  ( [ eq_i_beta ] ) . exchanging the order of integration in the latter ( which is not trivial since @xmath58 is itself a function of @xmath40 ) yields , as we shall see , an integrand of @xmath59 which is equal to @xmath60 . in the following proof lemma",
    "@xmath61 from  @xcite , which underlines the main proof of the gsv theorem in  @xcite , is proven directly from the thermodynamic description of the mutual information  ( [ eq_i2 ] ) .    adopting the snr - incremental channel approach  (",
    "* eq . ( 30)-(41 ) ) and mapping again @xmath62 = = = , where @xmath63 is the mutual information of the incremental gaussian channel [ eq_inc_channel ] y_1=x+n , where @xmath64 is a standard gaussian noise , @xmath13 is taken from the conditional probability @xmath65 , @xmath66 and [ eq_y2 ] y_2=x+(0,1/ ) with @xmath67 .",
    "hence , we have to prove = ( ) . now , the principles of thermodynamics come into action . for this incremental channel  ( [ eq_inc_channel ] ) , the energy and its derivative are given by ( x = x|y_1=y_1,y_2=y_2;,)&=&-+-and & & ( x = x|y_1=y_1,y_2=y_2;,)=+ . using the thermodynamic expression for the mutual information  ( [ eq_i2 ] ) and recalling that @xmath66 , one gets i(x;y_1|y_2=y_2)&=&-_y_1|y_2\\{_0^(du(y_1|y_2=y_2;,)+_x|y_1,y_2\\{(x|y_1,y_2=y_2;,)}d ) } +   + & = & -_y_1|y_2\\ { _ x|y_1,y_2\\{(x|y_1,y_2=y_2;,)+^2(x|y_1,y _ 2=y_2 ; , ) } } + & = & -_y_1|y_2\\{-+ } + & = & -_y_1|y_2\\{-y_1_x|y_2\\{x|y_2=y_2}+_x|y_2\\{x^2|y_2=y_2 } } [ eq_move1 ] + & = & ( -_x|y_2 ^ 2\\{x|y_2=y_2}+_x|y_2\\{x^2|y_2=y_2})[eq_move2 ] + & = & _ x|y_2\\{(x-_x|y_2\\{x|y_2=y_2})^2|y_2=y_2 } , where  ( [ eq_move1 ] ) is based on the fact that for an infinitesimal @xmath31 , @xmath66 , the expectation , while  ( [ eq_move2 ] ) results from the independence of @xmath64  ( [ eq_inc_channel ] ) with @xmath68  ( [ eq_y2 ] )  ( * ? ? ? * section ii - c ) .",
    "averaging over @xmath68 on both sides of the equation , we obtain the desired result i(x;y_1|y_2)=_x , y_2\\{(x-_x|y_2\\{x|y_2})^2 } = ( ) .",
    "in this paper , the mutual information of gaussian channels is described via thermodynamic terminology . as a byproduct , an intimate link is revealed between the gsv theorem and the basic laws of thermodynamics .",
    "more generally , the revised @xmath0 law for thermal systems with temperature - dependent energy levels enables to quantitatively bridge between the realm of thermodynamics and information theory for quasi - static systems .",
    "it is anticipated that this substantial theoretical connection between the foundation laws of thermodynamics and information theory will open a horizon for new discoveries and development in the study of both artificial and natural systems , towards a possibly more synergetic foundation to these two vital disciplines ."
  ],
  "abstract_text": [
    "<S> in this contribution , the gaussian channel is represented as an equivalent thermal system allowing to express its input - output mutual information in terms of thermodynamic quantities . </S>",
    "<S> this thermodynamic description of the mutual information is based upon a generalization of the @xmath0 thermodynamic law and provides an alternative proof to the guo - shamai - verd theorem , giving an intriguing connection between this remarkable theorem and the most fundamental laws of nature - the laws of thermodynamics .    </S>",
    "<S> * index terms : * thermodynamics , mutual information , gaussian channel , guo - shamai - verd theorem , minimum mean - square error . </S>"
  ]
}