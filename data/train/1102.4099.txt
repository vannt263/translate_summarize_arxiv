{
  "article_text": [
    "the shannon coding theorem @xcite states that for a variety of channels with a given capacity @xmath0 , if the information transmission rate @xmath1 over the channel is below @xmath0 , there exists a coding scheme for which the information can be transmitted with an arbitrarily low probability of error . for discrete memoryless channels ( dmc ) , it has been shown @xcite that the probability of error can be bounded between two exponentially decaying functions of the codeword block length , @xmath2 . in this theorem , there is no constraint on the codes in terms of linearity . in @xcite ,",
    "a simpler proof of the shannon theorem has been provided .",
    "the existence of capacity achieving linear codes over the binary symmetric channel ( bsc ) was shown by elias @xcite where it was also proved that linear codes have the same error exponent as random codes .",
    "a similar result has been obtained in @xcite .",
    "it was recently shown in @xcite that the error exponent of a typical random linear code can , in fact , be larger than a typical random code , implying a faster decaying of error as @xmath2 increases .",
    "some bounds on the decoding error probability of linear codes have been derived in @xcite .",
    "the result reported in @xcite-@xcite are all based on the fact that the elements of generating matrices of the capacity achieving linear codes should be one or zero with equal probability ; therefore the generating matrix of such approaches are not sparse .",
    "moreover , most papers on capacity achieving sparse linear codes are concentrated on codes with sparse parity - check matrices . in particular , an important class of codes called low - density parity - check ( ldpc ) codes @xcite have been of major interest in the past decade .",
    "while these codes have sparse parity - check matrices , they do not necessarily exhibit sparse generating matrices which are the focus of this paper . in @xcite-@xcite , some low - density generating - matrix ( ldgm ) schemes",
    "have been proposed which have performance approaching the capacity . some other related literature on the codes with sparse generating matrices having performance close to capacity includes @xcite-@xcite ; in @xcite ,",
    "a capacity - achieving scheme has been proposed based on serially concatenated codes with an outer ldpc code and an inner ldgm code . however , the generating matrix corresponding to the concatenation is not necessarily sparse . on the other hand ,",
    "rateless codes have been proposed in @xcite and @xcite which have sparse generating matrices but are only proved to be capacity achieving over the binary erasure channel ( bec ) .    in this paper , using a novel approach , we prove the existence of capacity achieving linear codes with _ sparse generating matrices _ that can provide reliable communications over two important classes of dmc channels ; namely , bec and bsc at rates below the channel capacity .",
    "the proof is accomplished by first deriving a lower bound on the probability of correct detection for a given generating matrix and then by taking the expectation of that lower bound over all possible generating matrices with elements 1 and 0 with probability @xmath3 and @xmath4 , respectively . by showing that this expectation goes to one as @xmath2 approaches infinity",
    ", we prove the existence of linear capacity achieving codes .",
    "to show the sparsity , we extend this result by taking the expectation over a subset of matrices for which the density of ones could be made arbitrarily close to any target @xmath3 .",
    "we then prove a stronger result that indicates the existence of capacity achieving linear codes with the same low density of ones in each row of the generating matrix .",
    "in addition to proving the existence of capacity achieving sparse codes , we also show that for a sufficiently large code length , no search is necessary in practice to find the desired deterministic matrix .",
    "this means that any randomly chosen code can have the desired error correcting property with high probability .",
    "this is done by proving that the error probability of a sequence of codes , corresponding to a randomly selected sequence of sparse generating matrices tends to zero as @xmath2 approaches infinity , in probability .",
    "this important result is then extended to generating matrices with low density rows for the case of bsc .",
    "although in reality the bloclength of codes is finite , in order to prove that a class of codes is capacity achieving , we assume that the blocklength goes to infinity .",
    "an intersting question is that for a given error probability and blocklength , how close the rate of the code can be to the capacity .",
    "an upper bound for the channel coding rate achievable at a given blocklength and error probability is derived in @xcite . in our paper",
    "we use yuri s upper bound @xcite and other well - known results to compare to our numerically derived results .    an interesting trade - off between the sparsity of the generating matrix and the error exponent",
    "is demonstrated such that the sparser the matrix , the smaller the error exponent becomes .",
    "it is important to note that for the case of bsc , we rigorously prove the existence of capacity achieving linear codes for a constant @xmath3 resulting in a non - vanishing density of ones on the generating matrix as @xmath2 tends to infinity .",
    "however , we have made a conjecture that if we choose @xmath5 ; where @xmath6 , the resulting codes can still be capacity achieving , which implies a vanishing density of ones .",
    "this signifies that the number of ones in the generating matrix can be as low as @xmath7 . for the case of bec",
    ", we have been able to prove that to have capacity achieving generating matrices , @xmath8 can be of @xmath9 .",
    "this implies that the number of ones in the generating matrix is about @xmath10 which is asymptotically less than @xmath7 , the number of ones in the case of bsc . as opposed to the existing results in the literature , which are based on maximum a posteriori ( map ) decoders , the proposed proofs",
    "are based on a suboptimal decoder , which makes our approach also novel from decoder point of view .",
    "the organization of the paper is as follows : in the next section , some preliminary definitions and notations are presented .",
    "in sections [ sec : bsc ] and [ sec : bec ] , we present our theorems for bsc and bec , respectively , and section [ sec : con ] concludes the paper .",
    "consider a dmc which is characterized by @xmath11 and @xmath12 as its input and output alphabet sets , respectively , and the transition probability function @xmath13 , where @xmath14 is the input , and @xmath15 is the output of the channel . in this paper , we consider the binary case where @xmath16 .",
    "a binary code @xmath17 of rate @xmath1 is a mapping from the set of @xmath18 @xmath19-tuples @xmath20 to @xmath2-tuples @xmath21 , @xmath22 , where @xmath23 , @xmath24 , and the code rate @xmath1 is defined as the ratio of @xmath19 by @xmath2 .",
    "since we are only interested in _ linear codes _ , the mapping is fully specified by an @xmath25 binary matrix @xmath26 ( the generating matrix ) , and encoding is accomplished by a left multiplication by @xmath27 : @xmath28 where the calculations are in @xmath29 .",
    "the vector @xmath21 is then transmitted through the dmc .",
    "decoding is defined as recovering the vector @xmath20 from the possibly corrupted received version of @xmath21 . in this paper",
    "the employed decoding scheme relies on the a posteriori probability distribution .",
    "let @xmath27 be the generating matrix .",
    "for a received vector @xmath30 , the decoder allocates a random vector such as @xmath31 as the original transmitted message with the conditional probability @xmath32 . clearly , the probability of correct detection using @xmath27 as the generating matrix is @xmath33 where @xmath34 depends on @xmath27 .",
    "note that the optimal decoder is a map decoder which allocates @xmath35 and that the probability of correct detection using map is more than or equal to the probability of correct detection in ( [ eq : pc ] ) . throughout the paper , the index @xmath36 in @xmath20 and @xmath21 may be dropped for more clarity . for the sake of convenience ,",
    "the following notations are used for the remainder of the paper .",
    "let @xmath37 be the set of all binary @xmath25 matrices .",
    "the density of an @xmath38 is defined as the total number of ones within the matrix divided by the number of its elements ( @xmath39 ) .",
    "a matrix with a density less than @xmath40 is called sparse ; the smaller the density , the sparser the matrix becomes .",
    "let each entry of each element of @xmath37 has a bernoulli(@xmath3 ) distribution , @xmath41 . )",
    "distribution if it is equal to @xmath42 with probability of @xmath3 and equal to @xmath43 with probability of @xmath4 .",
    "] this scheme induces a _ probability distribution _ on the set @xmath37 , denoted by bernoulli(@xmath44 ) . for the rest of paper",
    ", we consider this distribution on the set @xmath37 .",
    "note that as @xmath2 approaches infinity , the typical matrices of @xmath37 have a density close to @xmath3 .",
    "consider a bsc with cross - over probability @xmath45 .",
    "the capacity of this channel is given by @xmath46 , where @xmath47 .",
    "we suppose that @xmath1 , the rate of the code , is less than @xmath0 . in this section",
    ", we prove the existence of capacity achieving linear codes with arbitrarily sparse generating matrices over the bsc .",
    "we prove the existence by showing that the average error probability over such generating matrices tends to zero as @xmath2 approaches infinity .",
    "assume that we encode a message vector @xmath48 to generate the codeword @xmath49 .",
    "note that @xmath48 is chosen uniformly from the set @xmath50 .",
    "due to the effect of error in the bsc , each entry of the transmitted codeword @xmath49 can be changed from @xmath43 to @xmath42 and vice versa .",
    "these changes can be modeled by adding @xmath42 to erroneous entries of @xmath49 ( in @xmath51 ) .",
    "therefore , the error of a bsc with cross - over probability @xmath45 can be modeled by a binary @xmath2-dimensional error vector @xmath52 with i.i.d .",
    "entries with bernoulli(@xmath45 ) distribution . thus , if the output of the channel is shown by @xmath53 , the following equation models the channel : @xmath54 note that @xmath48 and @xmath52 are independent .      in the following theorem , a lower bound for the average probability of correct detection over the set @xmath37 , is obtained .",
    "[ th : aveerror ] consider a bsc with cross - over probability @xmath45 . a lower bound for the average probability of correct detection over all @xmath55 generating matrices with bernoulli@xmath56 distribution is given by @xmath57    _ proof",
    "_ : see appendix ii .",
    "an important result of this theorem is that we can fix the error probability and find the maximal achievable rate for a given blocklength .",
    "see the following figures .",
    "[ fig00 ] ) , @xmath58 , capacity=0.5 , error probability=@xmath59.,title=\"fig:\",width=377 ]    .",
    "figure @xmath42 is a plot of the coding rate versus @xmath2 for @xmath3 equal to @xmath60 , @xmath61 and @xmath40 .",
    "this plot is numerically evaluated from theorem [ th : aveerror ] .",
    "an interesting observation of this figure is that when the blocklength @xmath2 increases , the coding rate becomes independent of the density @xmath3 .",
    "this observation can be shown to be true from ( [ eq : approx1term ] ) of lemma [ lem : asymptotic ] , where the parameter @xmath3 disappears on the right hand side .",
    "the significance of this observation is that sparse generating matrices can replace non - sparse ones for large block coding sizes , which implies simpler encoder design .",
    "this observation is the dual of ldpc codes where large sparse parity check matrices simplifies the decoder design , while the performance remains the same .",
    "[ fig0 ] , capacity=0.5 , error probability=@xmath62.,title=\"fig:\",width=377 ]    .",
    "figure @xmath63 is a comparison of our result to that of gallager result and yuri upper bound @xcite .",
    "this figure shows that our results are within the yuri upper bound and the gallager result .",
    "this figure also shows that for the probability of error equal to @xmath62 when @xmath2 becomes greater than @xmath64 , the performance of the sparse genearting matrices with @xmath65 becomes the same as the non - sparse matrices with @xmath66 .",
    "+ in the following theorem , we will show that the expected value of the correct detection probability over all generating matrices from @xmath37 approaches @xmath42 .",
    "this proves the existence of at least one linear capacity achieving code .",
    "+    [ th : bscgeneral ] for any @xmath67 , for a bsc we have @xmath68    _ proof : _ see lemmas 1 and 2 and the proof in appendix iii .",
    "the performance of linear codes is determined by the error exponent which is defined as follows :    the error exponent of a family of codes @xmath69 of rate @xmath1 is defined as @xmath70 where @xmath71 is the average probability of decoding error .",
    "[ fig1 ] , @xmath72,title=\"fig:\",width=377 ]    .",
    "if the limit is greater than zero , the average error probability of the proposed codes decreases exponentially to zero as @xmath2 increases .",
    "the error exponent is an index such that the larger the error exponent , the faster the probability of error decays as @xmath2 increases .",
    "based on our observation , there is an interesting relation between the error exponent of the codes constructed by generating matrices with bernoulli@xmath56 distribution and the values of @xmath3 . in fig .",
    "3 , we have plotted the average probability of error versus @xmath2 for various values of @xmath3 .",
    "as it can be seen , the error exponent which is equal to the slope of the curves , increases as @xmath3 increases ( the generating matrix become less sparse ) .",
    "in other words , although the probability of error for sparse codes goes to to zero exponentially as @xmath2 increases ; this decrease is not as fast as high density codes .",
    "[ d6 ] let @xmath73 be the number of ones in a given binary matrix @xmath74 and @xmath75 be an arbitrary positive constant .",
    "@xmath76 is defined as a subset of @xmath37 for which @xmath77 . by choosing a sufficiently small @xmath75 ,",
    "the set @xmath76 is in fact a subset of @xmath78 which contains matrices having density of ones arbitrarily close to any given @xmath3 .",
    "note that the probability distribution on @xmath76 is induced from the probability distribution on @xmath78 .    in theorems",
    "[ th : aveerror ] and [ th : bscgeneral ] , we proved the existence of capacity achieving codes for any value of @xmath3 .",
    "we did not explicitly prove the existence of sparse capacity achieving codes .",
    "however , using concentration theory @xcite , we can see that for a sufficiently large @xmath2 , a randomly chosen matrix from @xmath78 is in the subset @xmath76 with high probability .",
    "in other words , we can state the following proposition which implies the existence of capacity achieving codes which are sparse .",
    "[ cor : typicalcol ] let @xmath76 be the set of typical matrices defined in definition ( [ d6 ] ) .",
    "we then have @xmath79    we define @xmath80 as the set of all binary @xmath25 matrices with rows that have @xmath81 ones . we also consider a uniform distribution on the set @xmath80 for the rest of the paper .    in the next theorem , we will prove a stronger result on capacity achieving sparse codes .",
    "we show the existence of capacity achieving matrices with rows containing exactly @xmath81 ones .",
    "in other words , the density of ones in each row is exactly equal to @xmath3 .",
    "this also implies that the generating matrix has a density of ones exactly equal to @xmath3 .",
    "in theorem [ th : aveerrorrow ] , we shall derive a lower bound on the average probability of correct detection and in theorem [ th : bscgenerrow ] we will prove that this lower bound tends to one .",
    "this shows that the average probability of error over the set @xmath80 approaches zero , implying the existence of capacity achieving codes with generating matrices taken from @xmath80 .",
    "[ th : aveerrorrow ] for a binary symmetric channel with cross - over probability @xmath45 , a lower bound for the expected value of the probability of correct detection over all generating matrices in @xmath82 is given by @xmath83 where @xmath84    _ proof _ : see appendix iv .",
    "[ th : bscgenerrow ] for each @xmath67 , we have @xmath85    _ proof : _ see lemma 3 and the proof in appendix iv .    in theorems",
    "[ th : aveerror ] and [ th : bscgeneral ] , we proved the existence of capacity achieving linear codes with generating matrices having bernoulli@xmath56 distribution by showing that the average probability of error over all generating matrices tends to zero as @xmath2 approaches infinity .",
    "this implies that we may have to perform a search over @xmath37 to find such a matrix .",
    "assume that we simply pick matrices randomly for each @xmath2 from the set @xmath37 .",
    "this constitutes a sequence of @xmath86 matrices .",
    "now consider the resulting sequence of error probabilities corresponding to the sequence of generating matrices . in the following proposition",
    ", we shall prove that the limit of this sequence is zero in probability , i.e. , a sequence of randomly chosen matrices is capacity achieving with high probability .",
    "this suggests that for sufficiently large @xmath2 , no search is necessary to find a desired deterministic generating matrix .",
    "[ cor : coninpro ] let @xmath87 be the sequence of matrices , where @xmath88 is selected randomly from @xmath89 . if we denote the error probability of the generating matrix @xmath88 over bsc by @xmath90 , then @xmath90 converges in probability to zero as @xmath2 tends to infinity .",
    "_ proof : _ see appendix v.    if we use the result of theorem [ th : bscgenerrow ] , we can extend proposition [ cor : coninpro ] to the case where we construct the matrix sequence by choosing the matrices from the set @xmath80 . in other words , in order to have capacity achieving sequences of generating matricescfor bsc with arbitrarily low density rows , we can simply pick generating matrices randomly from @xmath80 .    at this stage",
    ", we have been able to rigorously prove the existence of capacity achieving sparse linear codes over the bsc .",
    "however for a given @xmath3 , although the density of ones can be made arbitrarily small , it does not go to zero even when @xmath2 approaches infinity .",
    "let us assume the case where @xmath3 is a decreasing function of @xmath2 such that @xmath91 , resulting in zero density of ones as @xmath2 goes to infinity . in the following conjecture , we will propose a result indicating that this assumption can in fact be true .",
    "although , we have not been able to rigorously prove the conjecture , a sketch of the proof has been presented in the appendix .",
    "[ con : bscgengen ] let @xmath92 be an arbitrary number from interval @xmath93 . for @xmath94 by assuming the bernoulli@xmath95 distribution on the set @xmath37 , we have @xmath96    see appendix v for the sketch of the proof .",
    "a binary erasure channel is identified by erasure probability @xmath45 and the capacity of this channel is given by @xmath97 .",
    "we use the decoder proposed in section ii . through the channel ,",
    "some entries of the coded vector @xmath49 , shown by @xmath98 , may be erased . according to the position of the erased entries ,",
    "the error of the channel can be modeled as a subset @xmath99 of @xmath100 .",
    "therefore , we employ a decoder which decides about the transmitted vector by observing only the non - erased entries denoted by @xmath101 . for each @xmath102 , the @xmath103 row of @xmath27",
    "is removed to derive @xmath104 .",
    "therefore , the encoding and channel operation can be written as @xmath105 .",
    "the decoder chooses @xmath106 , the estimation of @xmath48 , randomly from the set @xmath107 . in this case",
    ", the decoder is equivalent to the map decoder . from linear algebra",
    ", it can be shown that @xmath108 , where @xmath109 is the maximum number of independent rows of a matrix calculated in @xmath51 . since",
    "@xmath106 is chosen uniformly from @xmath110 , the probability of the correct detection of @xmath48 is equal to @xmath111 .",
    "thus , we have @xmath112 , where @xmath113 represents the probability of correct detection when @xmath48 is transmitted and the position of erased entries are given in @xmath99 .    [ becgeneral ]",
    "let @xmath0 be the capacity of a bec and @xmath38 is a generating matrix corresponding to a code of rate @xmath114 .",
    "for any @xmath8 of @xmath9 , the expected value of @xmath115 over all matrices with bernoulli@xmath116 distribution tends to @xmath42 as @xmath2 approaches infinity .",
    "@xmath68    _ proof",
    "_ : see appendix vi .    from the concentration theory @xcite ,",
    "similar to the case of the bsc , we can state the following proposition .    for a bec with capacity @xmath0 , codes of rate @xmath114 and generating matrix from @xmath117 , we have : @xmath118    [ fig2 ]   for different values of @xmath3 for bec , @xmath119,title=\"fig:\",width=377 ]    .    in the following proposition",
    "we show that similar to proposition [ cor : coninpro ] for bsc , a sequence of randomly chosen generating matrices from @xmath89 , results in a capacity achieving coding scheme with high probability .",
    "this suggests that for sufficiently large @xmath2 , no search is necessary to find a desired deterministic generating matrix .",
    "[ cor : coninpro2 ] let @xmath87 be the sequence of matrices , where @xmath88 is selected randomly from @xmath89 . if we denote the error probability of the generating matrix @xmath88 over bec by @xmath90 , then @xmath90 converges in probability to zero as @xmath2 tends to infinity .",
    "_ proof : _ the proof is similar to the proof of proposition [ cor : coninpro ] and thus omitted . in fig .",
    "2 , we have shown the error exponent as a function of @xmath120 for different values of @xmath3 . as it can be seen , a similar trade - off to bsc exists between sparsity and the error exponent . the smaller @xmath3 results in a smaller error exponent",
    "the following theorem is similar to theorem [ th : bscgenerrow ] .",
    "[ th : becrow ] for each @xmath67 , for a bec we have @xmath85    _ proof _ : see appendix vii .",
    "if we use the result of theorem [ th : becrow ] , we can extend proposition [ cor : coninpro2 ] to the case where we construct the matrix sequence by choosing the matrices from the set @xmath80 .",
    "in this paper , a novel approach to prove the existence of capacity achieving sparse linear codes over the bsc and bec was proposed . for the bsc , in theorem [ th : aveerror ] ,",
    "we derived a lower bound on the average probability of correct detection over the set @xmath37 . in theorem [ th : bscgeneral ] , we proved that the average probability of error over @xmath37 tends to zero .",
    "then we proved the existence of sparse capacity achieving codes in proposition 2 . in theorem",
    "[ th : aveerrorrow ] , we derived a lower bound on the average probability of correct detection over the set @xmath80 . using this lower bound in theorem [ th : bscgenerrow ]",
    ", we proved the existence of capacity achieving codes with generating matrices with the same density @xmath121 in each row . in proposition",
    "[ cor : coninpro ] and its preceding note , we showed that the error probability of codes corresponding to any randomly chosen sequence of generating matrices tends to zero in probability .",
    "this implies that for sufficiently large @xmath2 , a randomly chosen matrix from @xmath37 and @xmath80 will have the average error correcting capability .",
    "in addition , we conjectured that theorem [ th : bscgeneral ] can hold for the case where @xmath3 is a function of @xmath2 , i.e. @xmath122 .",
    "this implies that for a capacity achieving code over a bsc , the density of the generating matrix can approach zero .",
    "in theorem [ becgeneral ] and proposition 3 , we proved the existence of sparse codes for the case of bec with generating matrices having bernoulli distribution with @xmath8 of @xmath9 . a similar result to proposition [ cor : coninpro ] and theorem [ th : bscgenerrow ]",
    "was shown for bec in proposition [ cor : coninpro2 ] and theorem [ th : becrow ] , respectively .",
    "we demonstrated an interesting trade - off between the sparsity of the generating matrix and the error exponent indicating that a sparser generating matrix results in a smaller error exponent .",
    "we also observed that for small block sizes , generating matrices with higher densities have better performances while for large block sizes , the performance of the random generating matrices become independent of the density . in our proofs , we have used a suboptimal decoder while previous works in the literature were based on a map decoder .",
    "this implies that we can get stronger results if we use the optimal map decoder .    for future work",
    ", one can try to rigorously prove conjecture 1 and possibly extend it to the case of matrices in the set @xmath80 .",
    "the improvement in the bounds using a map decoder can be an interesting topic to investigate .",
    "the extension of the results to dmc s is another challenging topic to be explored .",
    "a very interesting work is to analytically derive the error exponent to prove the trade - off between error exponent and sparsity of the generating matrix .",
    "we need the following definitions in order to prove our theorems .    any two functions @xmath123 and @xmath124 are referred to as _ proportionally equivalent _ and written as @xmath125 if @xmath126 .    any two functions @xmath127 and @xmath128 are referred to as _ differentially equivalent _ and written as @xmath129 if @xmath130",
    "* _ proof of theorem [ th : aveerror ] _ * : according to ( [ eq : pc ] ) , bayes rule , and the independency of @xmath48 and @xmath52 , we have @xmath131 taking expectation over all matrices @xmath132 , we get @xmath133 where in the last equality , the independency among @xmath27 , @xmath52 and @xmath48 is used . using the jensen s inequality ( see @xcite , chapter 2 , page 25 ) , we have @xmath134})\\right)}\\right)\\nonumber \\nonumber\\\\ = & \\mathbb{e}_{x , n}\\left(\\frac{\\mathbb{p}(n)\\mathbb{p}(x)}{\\mathbb{e}_{x'}(\\mathbb{p}_{\\mathbf{a},n'}(\\mathbf{a}(x - x')+(n - n')=0))}\\right),\\end{aligned}\\ ] ] where @xmath135 and @xmath136 have the same distributions as the input and error vectors , respectively . in the above equation ,",
    "the expected value over @xmath137 is a function of binary subtraction @xmath138 and as a result does not depend on @xmath48 .",
    "thus we can assume any binary vector x such as the all zero vector , @xmath139 ; from the independency of the rows of @xmath27 in ( [ eq : lowpc ] ) and the uniformity of the vectors @xmath48 , we have    @xmath140    where @xmath141 and @xmath142 are the @xmath143 entry of @xmath52 and @xmath136 , respectively , and @xmath144 is the @xmath143 row of @xmath27 . note that here all the operations are performed in @xmath145 . in order to evaluate the right side of the above inequality ,",
    "assume that vector @xmath52 has @xmath36 ones . without loss of generality and for convenience , we assume that the first @xmath36 elements of @xmath52 are @xmath42 . thus , the argument of the expected value in ( [ eq : prooflowbound ] ) is equal to @xmath146    to evaluate the expected value in the above expression , note that since @xmath147 with probability @xmath97 and @xmath148 with probability @xmath45 , we have @xmath149 now assume @xmath150 elements of @xmath137 are equal to @xmath42 .",
    "also consider the entries of @xmath144 with the same indices as the entries of @xmath137 that are equal to one .",
    "it is easy to see that in the above equation , @xmath151 is equal to the probability of having an odd number of ones in the considered indices of @xmath144 .",
    "thus , we have @xmath152 the same argument results in @xmath153 and therefore we have @xmath154 the expectation of the above expression over @xmath137 results in @xmath155 substituting ( [ eq : prooftemp ] ) in ( [ eq16 ] ) and taking expected value with respect to @xmath52 , we obtain the following lower bound for @xmath156 : @xmath157 this completes the proof . @xmath158",
    "[ cramergen ] let @xmath159 be a bounded sequence .",
    "for any @xmath160 and @xmath161 the summation @xmath162 is differentially equivalent to @xmath163 .    _",
    "proof : _ according to the chernoff - hoeffding theorem @xcite the proof is straightforward .",
    "@xmath158 +   +    [ lem : asymptotic ] consider a code with rate @xmath1 over a bsc with cross - over probability of @xmath45 where @xmath164 .",
    "there exists a @xmath165 for which for any @xmath166 , we have @xmath167    _ proof : _ to prove the lemma , note that the first term of the summation @xmath168 in the left hand side of ( [ eq : approx1term ] ) is equal to the right hand side .",
    "therefore , to prove ( [ eq : approx1term ] ) , it is sufficient to show that @xmath169 let @xmath170 and @xmath171",
    ". thus , we have @xmath172 by using a straightforward calculation , it can be shown that for @xmath173 , the maximum of @xmath174 is equal to @xmath42 .",
    "the maximum of @xmath174 occurs for @xmath175 or equivalently @xmath176 .",
    "thus , for @xmath177 we have @xmath178 also , since @xmath179 , we have @xmath180 it is easy to see that @xmath174 is a uniformly continuous function of @xmath36 and @xmath150 .",
    "thus from ( [ eq : fiinep ] ) , we conclude that there is a @xmath181 for which for any @xmath182 and @xmath177 , we have @xmath183 . and also from ( [ eq : inep ] ) , we conclude that there is a @xmath184 for which for any @xmath185 , we have @xmath186 .",
    "let @xmath187 and fix @xmath188 ; there exist an integer @xmath189 and a real number @xmath190 , for which we have @xmath191 for all @xmath192 . by using this @xmath189 , the left hand side of ( [ eqmid ] )",
    "can be written as @xmath193 since @xmath191 for @xmath192 , we have @xmath194 therefore , @xmath195 .",
    "+ to see that the first term at the right hand side of ( [ eq26 - 1 ] ) also tends to zero , let @xmath196 .",
    "therefore , we can write @xmath197 where @xmath198 . now",
    "the right hand side of the above inequality tends to zero because @xmath199 tends to infinity as @xmath19 approaches infinity .",
    "this proves that the left hand side should also tend to zero .",
    "therefore , both summations at the right hand side of ( [ eq26 - 1 ] ) tend to zero .",
    "this proves ( [ eqmid ] ) and consequently ( [ eq : approx1term ] ) . @xmath158    * _ proof of theorem [ th : bscgeneral ] _ * : + let @xmath200 .",
    "the first term of the summation of the denominator is equal to the numerator , and the other terms in the summation are positive .",
    "thus , the elements of the sequence @xmath201 are less than @xmath42 and subsequently bounded",
    ". therefore , we can apply lemma 1 .",
    "now note that based on theorem [ th : aveerror ] , we have @xmath202 let @xmath203 be as in lemma 1 . since @xmath204 , to prove the theorem , it is enough to show that the right hand side of the above inequality is differentially equivalent to @xmath42 . to see this ,",
    "we write @xmath205 @xmath206 @xmath207 where we used lemma 1 in the first and third equality which is not mathematically precise but we use it throughout the paper for the ease of explanation . ] and we replaced the summation in the denominator based on lemma 2 .",
    "this proves the theorem.@xmath158",
    "* _ proof of theorem [ th : aveerrorrow ] _ * : + we follow steps similar to that of theorem [ th : aveerror ] . equations ( [ eq : probcor ] ) to ( [ eq16 ] ) in theorem [ th : aveerror ] still hold here .",
    "it can be easily seen that @xmath208 and @xmath209 .",
    "thus equation ( [ eq : diff - proof ] ) is modified as @xmath210 the expectation of the above expression over @xmath137 results in @xmath211 substituting ( [ eq : proof3temp ] ) into ( [ eq16 ] ) and taking the expectation with respect to @xmath52 , we obtain @xmath212 this completes the proof .",
    "@xmath158    * _ proof of theorem [ th : bscgenerrow ] _ * : + first we prove a lemma similar to lemma [ lem : asymptotic ] .",
    "[ lem : asymptoticrow ] suppose that @xmath213 .",
    "there exists a @xmath165 for which for any @xmath166 , we have @xmath214    _ proof : _ let @xmath215 and @xmath216 since @xmath217 , we have @xmath218 by employing the same approach as the proof of lemma [ lem : asymptotic ] , it is sufficient to show that @xmath219    it is easy to see that @xmath220 . as a result , we have @xmath221 this completes the proof of lemma . @xmath158    now to prove this theorem , it is enough to replace the denominator in summation of ( [ eq : lowpcrow1 ] ) with the right hand side of ( [ eq : lemma3 ] ) according to lemma [ lem : asymptoticrow ] .",
    "* _ proof of proposition [ cor : coninpro ] _ * : + in order to show that @xmath222 in probability , we have to show that for any given @xmath165 , @xmath223 for a given @xmath224 , define @xmath225 . according to theorem [ th : bscgeneral ]",
    ", we have @xmath226 .",
    "thus , there exists an @xmath227 for which for any @xmath228 , @xmath229 .",
    "therefore , due to the fact that @xmath230 , for @xmath228 , we obtain @xmath231 .",
    "hence , for @xmath228 , since @xmath232 , we have @xmath233 thus , for @xmath228 , we have @xmath234 and the proof is complete .",
    "@xmath158    *",
    "_ sketch of proof of conjecture [ con : bscgengen ] _ * : + the lower bound of theorem [ th : aveerror ] still holds for the case where @xmath3 is a function of @xmath2 where @xmath235 . if we can show that for @xmath213 , there exists a @xmath165 for which for any @xmath166 , we have @xmath236    from the approach similar to that of the proof of theorem [ th : bscgeneral ] , the proof will be straightforward .",
    "although , we have numerical evidence suggesting that the above equality holds , we have not been able to prove it rigorously .",
    "the rest of the proof is as follows .",
    "let @xmath237 since , the first term of the summation in the denominator is equal to the numerator , the sequence @xmath201 are less than @xmath42 and subsequently bounded . from lemma [ cramergen ]",
    "we get @xmath238 now we have @xmath239 in other words , @xmath240 which is the desired result.@xmath158",
    "* _ proof of theorem [ becgeneral ] _ * : + we first present a lemma from @xcite .",
    "+    [ lem : ref ] suppose @xmath241 and let bernoulli@xmath242 be the probability distribution on the @xmath243 matrices where @xmath8 is of @xmath244",
    ". then @xmath245 .",
    "since @xmath246 , it can be concluded that there exists a @xmath165 for which @xmath247 . by using the proposed decoding scheme and by decomposing @xmath248",
    "according to the position of the erased entries @xmath99 , we get @xmath249 therefore , @xmath248 is the same for all @xmath48 s .",
    "thus @xmath250 .",
    "by evaluating the expected value of @xmath115 over all matrices and using jensen inequality , we have @xmath251 applying lemma [ cramergen ] , we obtain @xmath252 where @xmath253 is chosen such that @xmath254 . for each @xmath255",
    ", there is an @xmath256 for which @xmath257 .",
    "therefore , @xmath258 .",
    "now , according to lemma [ lem : ref ] , if we substitute @xmath19 for @xmath259 , as @xmath260 , we can write @xmath261 therefore , @xmath262 . @xmath158",
    "* _ proof of theorem [ th : becrow ] _ * :    according to the proof of theorem [ becgeneral ] it is sufficient to show the following lemma .",
    "suppose @xmath241 and consider @xmath263 with its previoiusly defined distribution .",
    "then for @xmath264 we have @xmath265 .",
    "note that here rank is calculated in @xmath51 .",
    "_ proof : _ in order to prove the lemma it is sufficient to show that @xmath266 which is equivalent to show that the probability of having a matrix @xmath267 with linear dependent rows goes to zero as n approaches inifinity , i.e. , @xmath268 where @xmath269 represents the @xmath103 row of the matrix .",
    "suppose @xmath270 be a positive number such that @xmath271 .",
    "the summation of equation ( [ eq : tem1 ] ) can be written as @xmath272 we first prove that the first term tends to zero . in order to have @xmath273 , @xmath274 should be equal to the sum of @xmath275 to @xmath276 .",
    "thus , conditioning on @xmath275 to @xmath276 , it is easy to see that @xmath277 .",
    "thus , @xmath278 since @xmath279 , we have @xmath280 where in the last equality we used the fact that @xmath281 .    in order to complete the proof it is sufficient to show that the second term of equation ( [ eq : tem2 ] ) also goes to zero . in this",
    "regard we show that for sufficiently large @xmath2 and any @xmath282 we have @xmath283 this will prove the lemma because we would have @xmath284    in order to prove equation ( [ eq : randomwalk ] ) we employ coupling method from random walk theory .",
    "consider a random walk on the @xmath2-dimensional cubic in @xmath51 with the set of directions @xmath285 , consists of all @xmath2-dimentional vectors with @xmath286 ones .",
    "suppose this random walk starts from the origin , and each time selects its next direction randomly from @xmath285 with uniform distribution .",
    "therefore , @xmath287 represents the probability of returning back to the origin after @xmath19 steps .",
    "denote this random walk by the sequence @xmath288 of @xmath2-dimentional vectors where @xmath289 represents the position of the random walk after @xmath290 steps .",
    "note that the stationary distribution of this random walk is uniform distribition , which means as @xmath290 tends to infinity the probability of being at any points of the cubic is almost @xmath291 .",
    "thus , for large values of @xmath19 , @xmath287 is almost @xmath291 .",
    "now consider another random walk denoted by @xmath292 , which its starting point is selected randomly with the uniform distribution .",
    "the idea of coupling is to couple two random walks @xmath288 and @xmath292 with the dependency between the directions selected by them such that both of them remain random walks that select their directions in each step uniformly form @xmath285 .",
    "suppose @xmath20 and @xmath293 are the positions of the two random walks after @xmath36 steps and @xmath294 be the @xmath295 direction which is selected uniformly from @xmath285 by the random walk @xmath288 .",
    "suppose @xmath296 entries of the vectors @xmath20 and @xmath293 are the same and denote the positions of these entries by the set @xmath297 .",
    "let @xmath298 be the subset of @xmath285 consists of vectors that their @xmath296 entries with positions from @xmath299 are same as @xmath294 .",
    "the random walk @xmath292 select the direction @xmath300 uniformly from the set @xmath298 .",
    "note that due to the fact that @xmath292 starts with its stationary distribution the probability of being at any point remains uniform for all @xmath290 for this random walk .",
    "also note that according to the dependency between @xmath294 and @xmath300 , @xmath301 is a non - decreasing sequence .",
    "thus , we expect that the two random walk meet each other at a point .",
    "let @xmath302 be the first time that @xmath288 and @xmath292 meet .",
    "note that after @xmath302 the rest of the two random walks would be the same .",
    "conditioning on the @xmath302 , @xmath303 can be written as @xmath304 now if we can prove that for @xmath282 , @xmath305 goes to zeros as n tends to infinity , then we would have @xmath306 which proves the equation ( [ eq : randomwalk ] ) .",
    "note that @xmath307 tends to 1 as k approaches infinity . therefore to complete the proof it remains to show that @xmath308    for @xmath309 , suppose @xmath310 represents the first time that the @xmath311 entries of @xmath289 and @xmath312 become the same .",
    "thus we have @xmath313    suppose that after @xmath36 steps the first entries of @xmath20 and @xmath293 are not the same and let @xmath296 and the set @xmath299 be as defined previously .",
    "let @xmath314 .",
    "the first entry of @xmath294 is equal to one with probability @xmath3 .",
    "now due to the fact that @xmath314 , less that @xmath315 entries of @xmath294 which are not from @xmath299 are equal to one with a probability more than @xmath316 .",
    "this means that the first enrty of @xmath300 is equal to zero with a probability more than @xmath317 .",
    "thus , the first entries of @xmath294 and @xmath300 are not the same with a probability more than @xmath318 .",
    "a similar approach for the case @xmath319 shows that there is a positive probability @xmath320 independent from @xmath2 and @xmath36 such that the first entries of @xmath294 and @xmath300 differ , i.e. , the first entries of @xmath321 and @xmath322 are the same .",
    "thus we have @xmath323    this completes the proof .",
    "the authors would like to thank professor g. d. forney for his valuable comments and suggestions and mr .",
    "r. farhoudi for his comments about proof of theorems",
    ".    1 c.  e.  shannon , a mathmatical theory of communicatrions , _ bell systems technical journal _ ,",
    "379 - 429 , 1948 .",
    "r.  m.  fano , _ transmisson of information _ , the m.i.t . press ,",
    "cambridge , 1961 .",
    "r.  gallager , `` a simple derivation of the coding theorem and some applications , '' _ ieee transactions information theory _ , vol . 11 , no . 1 , pp . 3 - 18 ,",
    "jan . 1965 .",
    "y. polyanskiy , h. vincent poor , s. verdu , `` channel coding rate in the finite blocklength regime , '' _ ieee transactions information theory _ ,",
    "56 , issue 5 , pp .",
    "2307 - 2359 , may 2010 .",
    "r. g. gallager , _ information theory and reliable communication _ , john wiley and sons inc .",
    "new york , ny , usa 1968 , p. 204 .",
    "m. mezard and a. montanari , _ information , physics , and computation , _ oxford university press , usa , 2009 , pp .",
    "105 - 128 .",
    "a.  barg and g. d. forney , `` random codes : minimum distances and error exponents , '' _ ieee transactions information theory _",
    "9 , pp . 2568 - 2573 , sept .",
    "g.  poltyrev , `` bounds on the decoding error probability of linear binary codes via their spectra , '' _ ieee transactions information theory _ ,",
    "1284 - 1292 , jul . 1994 .",
    "r.  g.  gallager , `` low density parity check codes , '' _ ire transactions information theory _ ,",
    "it-8 , pp .",
    "d.  j.  c.  mackay and r.  m.  neal , `` near shannon limit performance of low density parity check codes , '' _ iee electronics letters _ , vol .",
    "33 , no . 6 , pp . 457 - 458 , jul .",
    "f. j. vazquez - araujo , m.  gonzalez - lopez , l.  castedo , and j.  garcia - frias , `` capacity approaching low - rate ldgm codes , '' _ ieee transactions communications _ , vol .",
    "2 , pp . 352 - 356 , feb 2011 .",
    "j.  garcia - frias and z. wei , `` approaching shannon performance by iterative decoding of linear codes with low - density generator matrix , '' _ ieee communications letters _",
    ", vol . 7 , no . 6 , pp . 266 - 268 , june 2003",
    ". h.  chun - hao and a.  anastasopoulos , `` capacity - achieving codes with bounded graphical complexity and maximum likelihood decoding , '' _ ieee transactions information theory _ , vol .",
    "992 - 1006 , march 2010 .",
    "m.  luby , `` lt codes , '' in proc .",
    "_ ieee symposium on foundations of computer science _ , pp .",
    "271 - 280 , 2002 .",
    "a.  shokorollahi , `` raptor codes , '' _ ieee transactions information theory _ , vol .",
    "52 , no . 6 , pp . 2551 - 2567 , june 2006 .",
    "a.  dembo and o. zeitouni , _ large deviation techniques and application _ , springer , 2009 . t. m. cover and j. a. thomas , _ elements of information theory _ , wiley , 1991 , p. 25 . c. cooper ,",
    "`` on the rank of random matrices , '' _ random structures algorithms _ , vol .",
    "209 - 232 , feb . 2000 .",
    "w. hoeffding , `` probability inequalities for sums of bounded random variables , '' _ journal of the american statistical association _ , vol .",
    "13 - 30 , 1963"
  ],
  "abstract_text": [
    "<S> in this paper , we prove the existence of capacity achieving linear codes with random binary sparse generating matrices . </S>",
    "<S> the results on the existence of capacity achieving linear codes in the literature are limited to the random binary codes with equal probability generating matrix elements and sparse parity - check matrices . moreover , </S>",
    "<S> the codes with sparse generating matrices reported in the literature are not proved to be capacity achieving .    </S>",
    "<S> as opposed to the existing results in the literature , which are based on optimal maximum a posteriori decoders , the proposed approach is based on a different decoder and consequently is suboptimal . </S>",
    "<S> we also demonstrate an interesting trade - off between the sparsity of the generating matrix and the error exponent ( a constant which determines how exponentially fast the probability of error decays as block length tends to infinity ) . </S>",
    "<S> an interesting observation is that for small block sizes , less sparse generating matrices have better performances while for large blok sizes , the performance of the random generating matrices become independent of the sparsity . </S>",
    "<S> moreover , we prove the existence of capacity achieving linear codes with a given ( arbitrarily low ) density of ones on rows of the generating matrix . </S>",
    "<S> in addition to proving the existence of capacity achieving sparse codes , an important conclusion of our paper is that for a sufficiently large code length , no search is necessary in practice to find a deterministic matrix by proving that any arbitrarily selected sequence of sparse generating matrices is capacity achieving with high probability . </S>",
    "<S> the focus in this paper is on the binary symmetric and binary erasure channels . </S>"
  ]
}