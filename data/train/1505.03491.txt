{
  "article_text": [
    "distributed storage ( ds ) uses a network of interconnected inexpensive storage devices ( referred to as storage nodes or simply nodes ) to store data reliably over long periods of time .",
    "reliability against node failures ( commonly referred to as _ fault tolerance _ ) is achieved by means of erasure correcting coding .",
    "furthermore , when a node fails , a new node needs to be added to the ds network and populated with data to maintain the initial state of reliability .",
    "the problem of _ repairing _ a failed node is known as the _ repair problem_.    classical maximum distance separable ( mds ) codes are optimal in terms of the fault tolerance / storage overhead tradeoff .",
    "however , the repair of a failed node requires the retrieval of large amounts of data from a large subset of nodes .",
    "therefore , in the recent years , the design of erasure correcting codes that reduce the cost of repair has attracted a great deal of attention .",
    "pyramid codes @xcite were one of the first code constructions that addressed this problem . in particular , they aim at reducing the number of nodes that need to be contacted to repair a failed node , known as the repair access",
    ". other codes that reduce the repair access are the local reconstruction codes ( lrcs ) @xcite , and the locally repairable codes @xcite .",
    "other code constructions aim at reducing the repair bandwidth , defined as the amount of information that needs to be read from the ds network to repair a failed node . among them",
    ", we can mention minimum disk i / o repairable ( mdr ) codes @xcite , zigzag codes @xcite and piggyback codes @xcite .",
    "piggybacking consists of adding carefully chosen linear combinations of data symbols ( called piggybacks ) to the parity symbols of a given erasure correcting code .",
    "this results in a lower repair bandwidth at the expense of a lower erasure correcting capability with respect to the original code .    in this paper",
    ", we propose a family of erasure correcting codes that achieve low repair bandwidth and low repair complexity .",
    "in particular , we propose a systematic code construction based on two classes of parity symbols .",
    "correspondingly , there are two classes of parity nodes . the first class of parity nodes , whose primary goal is to provide erasure correcting capability ,",
    "is constructed using an mds code modified by applying specially designed piggybacks to some of its code symbols .",
    "the second class of parity nodes is constructed using a block code whose parity symbols are obtained with simple additions .",
    "this class of parity nodes does not have the purpose to bring any additional erasure correcting capability , but to facilitate node repair at low repair bandwidth and low repair complexity . in the paper",
    ", we compare the proposed codes with mdr codes , zigzag codes , piggyback codes and lrcs @xcite , in terms of repair bandwidth and repair complexity .",
    "notation : we define the operator @xmath0 .",
    "the galois field of order @xmath1 is denoted by @xmath2 .",
    "we consider the distributed storage system depicted in fig .",
    "[ fig : systemmodel ] .",
    "there are @xmath3 data nodes , each containing a very large number of data symbols over @xmath2 . as we shall see in the sequel , the proposed code construction works with blocks of @xmath3 data symbols per node .",
    "thus , without loss of generality , we assume that each node contains @xmath3 data symbols .",
    "we denote by @xmath4 , @xmath5 , the @xmath6th data symbol in the @xmath7th data node .",
    "we say that the data symbols form a @xmath8 _ data array _",
    "@xmath9 , where @xmath10_{i , j}$ ] . for later use",
    ", we also define the set of data symbols @xmath11 .",
    "further , there are @xmath12 parity nodes each storing @xmath3 parity symbols .",
    "we denote by @xmath13 , @xmath14 , @xmath15 , the @xmath6th parity symbol in the @xmath7th parity node , and define the set @xmath16 as the set of parity symbols in the @xmath7th parity node .",
    "the set of all parity symbols is denoted by @xmath17 .",
    "we say that the data and parity symbols form a @xmath18 _ code array _",
    "@xmath19 , where @xmath20_{i , j}$ ] .",
    "note that @xmath21 for @xmath22 and @xmath23 for @xmath14 , @xmath15 .    our main goal is to construct codes that yield low repair bandwidth and low repair complexity of a single failed systematic node . to this purpose",
    ", we construct a family of systematic @xmath24 codes consisting of two different classes of parity symbols . correspondingly , there are two classes of parity nodes , referred to as class @xmath25 and class @xmath26 parity nodes , as shown in fig .",
    "[ fig : systemmodel ] .",
    "class @xmath25 and class @xmath26 parity nodes are built using an @xmath27 code and an @xmath28 code , respectively , such that @xmath29 .",
    "in other words , the parity nodes of the @xmath24 code correspond to the parity nodes of class @xmath25 and class @xmath26 codes .",
    "the primary goal of class @xmath25 parity nodes is to achieve good erasure correcting capability , while the purpose of class @xmath26 nodes is to yield low repair bandwidth and low repair complexity . in particular",
    ", we focus on the repair of data nodes .",
    "the repair bandwidth ( in bits ) per node , denoted by @xmath30 , is proportional to the average number of symbols ( data and parity ) that need to be read to repair a data symbol , denoted by @xmath31 .",
    "more precisely , let @xmath32 be the number of symbols per node , but this is not the case in general . ] .",
    "then , @xmath33 where @xmath34 is the size ( in bits ) of a symbol .",
    "@xmath31 can be interpreted as the repair bandwidth normalized by the size ( in bits ) of a node .",
    "therefore , in the rest of the paper we will use @xmath31 to refer to the normalized repair bandwidth .",
    "the main principle behind our code construction is the following .",
    "the repair is performed one symbol at a time .",
    "after the repair of a data symbol is accomplished , the symbols read to repair that symbol are cached in the memory .",
    "therefore , they can be used to repair the remaining data symbols at no additional read cost .",
    "the proposed codes are constructed in such a way that the repair of a new data symbol requires a low additional read cost ( defined as the number of additional symbols that need to be read to repair the data symbol ) , so that @xmath31 ( hence @xmath30 ) is reduced . since we will often use the concepts of read cost and additional read cost in the remainder of the paper , we define them in the following .",
    "the _ read cost _ of a symbol is the number of symbols that need to be read to repair the symbol .",
    "the _ additional read cost _ of a symbol is the additional number of symbols that need to be read to repair the symbol , considering that other symbols are already cached in the memory ( i.e. , have been read to recover some other data symbols previously ) .",
    "class @xmath25 parity nodes are constructed using a modified @xmath35 mds code , @xmath36 , over @xmath2 . in particular , we start from an @xmath35 mds code and apply piggybacks @xcite to some of the parity symbols .",
    "the construction of class @xmath25 parity nodes is performed in two steps as follows .    1 .",
    "encode each row of the data array using an @xmath27 mds code ( the same for each row ) .",
    "the parity symbol @xmath37 is to indicate that the parity symbol is stored in a class @xmath25 parity node . ]",
    "@xmath38 where @xmath39 denotes a coefficient in @xmath2 .",
    "store the parity symbols in the corresponding row of the code array .",
    "overall , @xmath40 parity symbols are generated .",
    "2 .   modify some of the parity symbols by adding piggybacks .",
    "let @xmath41 , @xmath42 , be the number of piggybacks introduced per row .",
    "the parity symbol @xmath43 is obtained as @xmath44 where @xmath45 and the second term in the summation is the piggyback .    the _ fault tolerance _ ( i.e. , the number of node failures that can be tolerated ) of class @xmath25 codes is given in the following theorem .",
    "an @xmath27 class @xmath25 code with @xmath41 piggybacks per row can correct a minimum of @xmath46 node failures .",
    "[ th : ecc ]    the proof is given in the appendix .",
    "class @xmath25 code with @xmath47 constructed from a @xmath48 mds code . @xmath49 and @xmath50 are the parity nodes . for each row @xmath7 , colored symbols belong to @xmath51 . ]",
    "when a failure of a data node occurs , class @xmath25 parity nodes are used to repair @xmath52 of the @xmath3 failed symbols .",
    "the class @xmath25 parity symbols are constructed in such a way that , when node @xmath7 is erased , @xmath52 data symbols in this node can be repaired reading the ( non - failed ) @xmath53 data symbols in the @xmath7th row of the data array and @xmath52 parity symbols in the @xmath7th row of class @xmath25 nodes ( see also section  [ sec : decoding ] ) . for later use , we define the set @xmath54 as follows .    for @xmath55 ,",
    "define the set @xmath51 as @xmath56 .",
    "the set @xmath51 is the set of @xmath53 data symbols that are read from row @xmath7 to recover @xmath52 data symbols of node @xmath7 using class @xmath25 parity nodes .",
    "an example of class @xmath25 code is shown in fig .",
    "one can verify that the code can correct any 2 node failures . for each row @xmath7 , the set rj is indicated in red color .",
    "for instance , @xmath57 .",
    "the main purpose of class @xmath25 parity nodes is to provide good erasure correcting capability .",
    "however , the use of piggybacks helps also in reducing the number of symbols that need to be read to repair the @xmath52 symbols of a failed node that are repaired using class @xmath25 code , as compared to mds codes .",
    "the remaining @xmath58 data symbols of the failed node can also be recovered from class @xmath25 parity nodes , but at a high symbol read cost .",
    "hence , the idea is to add another class of parity nodes , namely class @xmath26 parity nodes , in such a way that these symbols can be recovered with lower read cost .",
    "class @xmath26 parity nodes are obtained using an @xmath59 linear block code over @xmath2 to encode the @xmath8 data symbols of the data array , i.e. , we use the @xmath59 code @xmath3 times .",
    "this generates @xmath60 class @xmath26 parity symbols , @xmath61 , @xmath14 , @xmath62 .    for @xmath55 , define the set @xmath63 as @xmath64    assume that data node @xmath7 fails .",
    "it is easy to see that the set @xmath65 is the set of @xmath58 data symbols that are not recovered using class @xmath25 parity nodes .",
    "[ ex : q0r0 ] for the example in fig .",
    "[ fig2 ] , the set @xmath63 is indicated by hatched symbols for each column @xmath7 , @xmath66 . for instance , @xmath67 .    for later use",
    ", we also define the following set .    for @xmath55 , define the set @xmath68 as @xmath69    note that @xmath70 .",
    "[ ex : x0 ] for the example in fig .",
    "[ fig2 ] , the set @xmath71 is indicated by hatched symbols for each row @xmath6 .",
    "for instance , @xmath72 .",
    "the purpose of class @xmath26 parity nodes is to allow recovering of the data symbols in @xmath63 , @xmath55 , at a low additional read cost .",
    "note that after recovering @xmath52 symbols using class @xmath25 parity nodes , the data symbols in @xmath51 are already stored in the decoder memory , therefore they are accessible for the recovery of the remaining @xmath58 data symbols using class @xmath26 parity nodes without the need of reading them again .",
    "the main idea is based on the following proposition .",
    "[ prep : mainidea ] if a class @xmath26 parity symbol @xmath73 is the sum of one data symbol @xmath74 and a number of data symbols in @xmath68 , then the recovery of @xmath75 comes at the cost of one additional read ( one should read parity symbol @xmath73 ) .",
    "this observation is used in the construction of class @xmath26 parity nodes ( see section  [ sec : big - example ] below ) to reduce the normalized repair bandwidth , @xmath31 .",
    "in particular , we add @xmath58 class @xmath26 parity nodes which allow to reduce the additional read cost of all @xmath76 data symbols in all @xmath63 s to @xmath77 .",
    "( the addition of a single class @xmath26 parity node allows to recover one new data symbol in each @xmath63 , @xmath55 , at the cost of one additional read ) .    0.4     0.4     0.4     0.4     0.2     in order to describe the code construction",
    ", we define the function @xmath78 as follows .",
    "[ def : read ] consider a class @xmath26 parity node and let @xmath79 denote the set of parity symbols in this node .",
    "also , let @xmath74 for some @xmath7 and @xmath80 be @xmath81 , where @xmath82 , i.e. , the parity symbol @xmath73 is the sum of @xmath75 and a subset of other data symbols .",
    "then , @xmath83 where @xmath84 .    for a given data symbol @xmath75",
    ", the function @xmath85 gives the additional number of symbols that need to be read to recover @xmath75 ( considering the fact that some symbols are already cached in the memory ) .      in the following ,",
    "we propose a recursive algorithm for the construction of class @xmath26 parity nodes . to ease understanding",
    ", we introduce the algorithm through an example .",
    "[ sec : big - example ] we construct a @xmath86 code starting from the @xmath87 class @xmath25 code in fig .",
    "in particular , we construct @xmath88 class @xmath26 parity nodes , so that the additional number of reads to repair each of the remaining failed @xmath88 symbols ( after recovering @xmath89 symbols using class @xmath25 parity nodes ) is @xmath77 . with some abuse of notation",
    ", we denote these parity nodes by @xmath90 , @xmath91 , and @xmath92 .",
    "denote by @xmath93 , @xmath94_{i , j}$ ] , a temporary matrix of read values for the respective data symbols @xmath4 . after class @xmath25 decoding , @xmath95 where @xmath96 .",
    "for our example , @xmath93 after class @xmath25 decoding is given in fig .",
    "[ fig3](a ) .",
    "our algorithm operates on the @xmath97s whose initial value is @xmath98 and aims to obtain the lowest possible values for these @xmath97s under the given number of class @xmath26 parity nodes .",
    "this is done in a recursive manner as follows .    * * construct the first parity node , @xmath90 . *    1 .   for each symbol @xmath4 define the set @xmath99 .",
    "2 .   start with the elements in @xmath100 .",
    "pick an element @xmath101 such that @xmath102 , and @xmath103 .",
    "for instance , we take @xmath104 .",
    "3 .   for @xmath96 compute @xmath105 and",
    "update the respective @xmath106 and @xmath107 , @xmath108 the resulting matrix @xmath93 is shown in fig .",
    "[ fig3](b ) .",
    "there are still entries @xmath109 that need to be handled .",
    "4 .   for @xmath96 update @xmath110 where @xmath111 and @xmath112 after step 1b . update @xmath93 accordingly ( see fig .",
    "[ fig3](c ) ) .",
    "note that the read values @xmath113 have not worsened .",
    "this comes from the fact that the new added data symbol belongs to the corresponding set @xmath114 and is already cached in the memory .",
    "thus , the additional read cost is @xmath115 . on the other hand , the values @xmath116 increase .    * * construct the second parity node , @xmath91 .",
    "*    1 .   pick an element @xmath101 such that the corresponding @xmath97 is maximal . in our example , this is @xmath117 because @xmath118 .",
    "2 .   for @xmath96 , do the following . pick an element @xmath119 such that for all @xmath120 , @xmath121 , where @xmath73 is set to @xmath122 . for our example , we choose @xmath123 .",
    "note that the only other option , @xmath124 , is not a good choice as the new additional read cost would increase from 1 to 2 .",
    "if such @xmath125 does not exist , set @xmath126 .",
    "+ update @xmath93 .",
    "the updated matrix is shown in fig .",
    "[ fig3](d ) .    * * construct @xmath92 .",
    "*    1 .   pick an element @xmath101 such that the corresponding @xmath106 is maximal . in our example , this is @xmath127 .",
    "2 .   for @xmath96 ,",
    "do the following .",
    "@xmath128 . update @xmath93 .",
    "the resulting @xmath93 has value @xmath3 for all diagonal elements and @xmath77 elsewhere ( fig .",
    "[ fig3](e ) ) .",
    "parity nodes for the data nodes in fig .",
    "[ fig2 ] . ]",
    "[ fig : classb ]    the class @xmath26 parity nodes @xmath90 , @xmath91 , and @xmath92 are shown in fig .",
    "[ fig : classb ] .    a general version of the algorithm to construct class @xmath26 parity nodes is given in appendix  [ app : algorithm ] .",
    "the construction of class @xmath26 parity nodes starts by selecting an element @xmath4 of a given @xmath63 such that @xmath109 and @xmath129 ( for simplicity , as in the example , we can start with @xmath130 ) .",
    "the first parity symbol of @xmath131 after step 1c is therefore @xmath132 , and the remaining parity symbols are obtained as in ( [ eq : pt7 ] ) . by proposition",
    "[ prep : mainidea ] the additional read cost of @xmath4 ( after step 1c ) is @xmath77 .",
    "the reason for selecting @xmath129 is due to the fact that , again by proposition  [ prep : mainidea ] , its additional read cost is also @xmath77 .",
    "we remark that for each @xmath133 it is not always possible to select @xmath129 and set @xmath134 .",
    "this is the case when @xmath135 .",
    "if @xmath129 does not exist , then we select @xmath136 ( see appendix  [ app : algorithm ] ) . in this case",
    ", the additional read cost of @xmath137 ( after step 1c ) is @xmath138 .",
    "in general , step 1d has to be performed @xmath139 times , corresponding to the number of entries @xmath109 per column of @xmath93 .    adding @xmath58 class @xmath26 nodes allows to reduce the additional read cost for all data symbols in all @xmath63 to @xmath77 ( see fig .",
    "[ fig3](e ) ) .",
    "however , this comes at the expense of a reduction in the code rate , i.e. , the storage overhead is increased . in the example , @xmath88 class @xmath26 parity nodes need to be introduced , which reduces the code rate from @xmath140 to @xmath141 .",
    "if a lower storage overhead is required , class @xmath26 parity nodes can be _ punctured _ , starting from the last parity node ( for the example , nodes @xmath92 , @xmath91 , and @xmath90 are punctured in this order ) , at the expense of an increased repair bandwidth .",
    "if all class @xmath26 parity nodes are punctured , we would remain only with class @xmath25 parity nodes and the repair bandwidth corresponds to that of the class @xmath25 code .",
    "thus , our code construction gives a family of rate - compatible codes which trades off between repair bandwidth and storage overhead : adding more class @xmath26 nodes reduces the repair bandwidth but increases the storage overhead .",
    "the repair of a failed systematic node , proceeds as follows .",
    "first , @xmath52 symbols are repaired using class @xmath25 parity nodes .",
    "then , the remaining symbols are repaired using class @xmath26 parity nodes . with a slight abuse of language",
    ", we will refer to the repair of symbols using class @xmath25 and class @xmath26 parity nodes as the decoding of class @xmath25 and class @xmath26 codes , respectively .",
    "suppose that node @xmath7 fails .",
    "decoding is as follows .",
    "* * decoding of class @xmath25 code*. to reconstruct the failed data symbol in the @xmath7th row of the code array , @xmath3 symbols ( @xmath53 data symbols and @xmath142 ) in the @xmath7th row are read .",
    "these symbols are now cached in the memory .",
    "we then read the @xmath41 piggybacked symbols in the @xmath7th row . by construction",
    "( see ( [ eq : piu ] ) ) , this allows to repair @xmath41 failed symbols , at the cost of an additional read each . *",
    "* decoding of class @xmath26 code*. each remaining failed data symbol @xmath143 is obtained by reading a class @xmath26 parity symbol whose corresponding set @xmath144 ( see definition  [ def : read ] ) contains @xmath4 .",
    "in particular , if several class @xmath26 parity symbols @xmath145 contain @xmath4 , we read the parity symbol with largest index @xmath146 .",
    "this yields the lowest additional read cost .",
    "@p1.9 cmcp2.0 cmccc@ & @xmath32 & * fault tolerance * & * norm . repair band . * & * norm .",
    "repair compl .",
    "* & * enc .",
    "complexity * +   + mds & @xmath77 & @xmath12 & @xmath3 & @xmath147 & @xmath148 + lrc @xcite & @xmath77 & @xmath149 & @xmath150 & @xmath151 & + mdr @xcite & @xmath152 & @xmath153 & @xmath154 & @xmath155 & @xmath155 + zigzag @xcite & @xmath156 & @xmath12 & @xmath157 & @xmath147 & @xmath148 + piggyback @xcite & @xmath153 & @xmath77 & &  &  + proposed codes & @xmath3 & @xmath158 & & @xmath159 & @xmath160 +    in this section we characterize some different properties of the codes presented in sections  [ sec : classa ] and [ sec : classb ] .",
    "the fault tolerance of the class @xmath25 code depends on the mds code used in its construction and @xmath41 , as stated in theorem [ th : ecc ] .",
    "hence , our proposed code has also fault tolerance @xmath161 .",
    "since @xmath162 , our codes have a fault tolerance of at least @xmath153 .      according to section [ sec : decoding ] , to repair the first @xmath52 symbols in a failed node",
    "requires that @xmath53 data symbols plus @xmath52 class @xmath25 parity symbols are read .",
    "the remaining @xmath58 data symbols in the failed node are repaired by reading the class @xmath26 parity symbols . as seen in section [ sec : classb ] , the parity symbols in the first class @xmath26 parity node are constructed from sets of data symbols of cardinality @xmath163 .",
    "therefore , to repair each of the @xmath58 data symbols in this set requires to read at most @xmath58 symbols . the remaining class @xmath26 parity nodes are constructed from fewer symbols than @xmath58 .",
    "an upper bound on the normalized repair bandwidth is therefore @xmath164 .",
    "it is observed that when @xmath41 increases , the fault tolerance reduces while @xmath31 improves .",
    "we first consider the complexity of elementary arithmetic operations of elements of size @xmath34 in @xmath2 .",
    "an addition requires @xmath165 and multiplication requires @xmath166 .",
    "the term inside @xmath167 denotes the number of elementary binary additions . to repair",
    "the first symbol requires @xmath3 multiplications and @xmath53 additions . to repair the following @xmath41 symbols require an additional @xmath168 multiplications and additions .",
    "the final @xmath58 symbols require at most @xmath169 additions , since class @xmath26 parity symbols are constructed as the sum of at most @xmath58 data symbols .",
    "the repair complexity of one failed node is therefore @xmath170 the first two terms correspond to the class @xmath25 code while the last term corresponds to the class @xmath26 code .",
    "the encoding complexity of the @xmath24 code , @xmath160 , is the sum of the encoding complexities of the two codes .",
    "the generation of each of the @xmath171 class @xmath25 parity symbols in one row of the code array , @xmath37 in , requires @xmath3 multiplications and @xmath53 additions . adding data symbols to @xmath41 of these parity symbols according to requires an additional @xmath41 additions .",
    "the encoding complexity of the class @xmath25 code is therefore @xmath172    according to section [ sec : classb ] , the parity symbols in the first class @xmath26 parity node are constructed as the sum of @xmath58 data symbols , and each parity symbol in the subsequent parity nodes uses one less data symbol .",
    "therefore , the encoding complexity of the class @xmath26 code is @xmath173 finally , @xmath174 .",
    "table  [ tab : summary ] provides a summary of the characteristics of different codes proposed in the literature as well as the codes constructed in this paper . and",
    "@xmath175 in table  [ tab : summary ] are defined in @xcite and @xcite respectively .",
    "the definition of @xmath176 comes directly from @xmath175 that is defined in @xcite . ] in the table , column 2 reports the value of @xmath32 ( see ) for each code construction . for our code , @xmath177 , unlike for mdr and zigzag codes , for which @xmath32 grows exponentially with @xmath3 .",
    "this implies that our codes require less memory to cache data symbols during repair .",
    "the fault tolerance @xmath178 , the normalized repair bandwidth @xmath31 , the normalized repair complexity , and the encoding complexity , discussed in the previous subsections , are reported in columns 3 , 4 , 5 , and 6 , respectively .    in fig .",
    "[ fig5 ] , we compare our codes with other codes in the literature .",
    "in particular , the figure plots the normalized repair complexity of @xmath179 codes over @xmath180 ( @xmath181 ) versus their normalized repair bandwidth @xmath31 .",
    "in contrast to the bounds for the repair bandwidth and complexity reported in table [ tab : summary ] , fig .",
    "[ fig5 ] contains the exact number of integer additions .    the best codes for a ds system should be the ones that achieve the lowest repair bandwidth and have the lowest repair complexity . as seen in fig .",
    "[ fig5 ] , mds codes have both high repair complexity and repair bandwidth , but they are optimal in terms of fault tolerance for a given @xmath182 and @xmath3 . zigzag codes achieve the same fault tolerance and high repair complexity as mds codes , but at the lowest repair bandwidth . at the other end ,",
    "lrcs yield the lowest repair complexity but a higher repair bandwidth and worse fault tolerance than zigzag codes .",
    "piggyback codes have a repair bandwidth between that of zigzag and mds codes , but with a higher repair complexity and worse fault tolerance . for a given storage overhead ,",
    "our proposed codes have better repair bandwidth than mds codes , piggyback codes and lrcs , and equal or similar repair bandwidth than zigzag codes .",
    "furthermore , they yield lower repair complexity as compared to mds , piggyback and zigzag codes . however , the benefits in terms of repair bandwidth and/or repair complexity with respect to mds and zigzag codes come at a price of a lower fault tolerance .     with @xmath181 . ]",
    "in this paper , we constructed a new class of codes that achieve low repair bandwidth and low repair complexity for a single node failure .",
    "the codes are constructed from two smaller codes , class @xmath25 and @xmath26 , where the former focuses on the fault tolerance of the code , and the latter focuses on reducing the repair bandwidth and complexity .",
    "our proposed codes achieve better repair complexity than zigzag codes and piggyback codes and better repair bandwidth than lrcs , but at the cost of slightly lower fault tolerance .",
    "a side effect of such a construction is that the number of symbols per node that needs to be encoded grows linearly with the code dimension .",
    "this implies that our codes are suitable for memory constrained ds systems as compared to zigzag and mdr codes , for which the number of symbols per node increases exponentially with the code dimension .",
    "each row in the code array contains @xmath183 parity symbols based on the mds construction ( i.e. , parity symbols without piggybacks ) . using these symbols",
    ", one can recover @xmath183 data symbols in that row and , thus , @xmath183 failures of systematic nodes . in order to prove the theorem",
    ", we need to show that by using piggybacked parity symbols @xmath43 , @xmath184 , in some parity node , @xmath185 , it is possible to correct one arbitrary systematic node failure . to do this ,",
    "let us consider the system of linear equations @xmath186 , representing the set of parity equations to compute @xmath43s where @xmath187 .",
    "in other words , @xmath188 , @xmath189 , and @xmath190 is given by @xmath191 where @xmath192 , @xmath193 is a vector of length @xmath3 with one at position @xmath6 and zeros elsewhere , and @xmath194 is the all - zero vector of size @xmath3 .",
    "now , assume a systematic node @xmath175 has failed . in order to repair it ,",
    "we need to solve the following subsystem of linear equations @xmath195 , in which @xmath196 and @xmath197 is a @xmath198 submatrix of @xmath190 such that : a ) its diagonal elements are all @xmath199 ; b ) it has 1 at row @xmath175 and column @xmath200 ; c ) all other entries are 0 .",
    "note that @xmath201 is full rank .",
    "therefore , one arbitrary data symbol can be corrected and , hence , the erasure correcting capability of class @xmath25 code is at least @xmath46 , which completes the proof .",
    "( + ) @xmath202 @xmath203 choose @xmath101 s.t .",
    "@xmath106 is max @xmath204 @xmath205 + @xmath206 + @xmath207    we give an algorithm to construct @xmath58 class @xmath26 parity nodes in the order @xmath208 . this results in the construction of @xmath209 parity symbols @xmath210 .",
    "the algorithm is given in algorithm  [ alg : algorithm1 ] .",
    "consider the construction of the parity symbols of parity node @xmath211 .",
    "the algorithm constructs first the parity symbol @xmath212 as the sum of an element @xmath213 and @xmath214 elements in @xmath215 .",
    "then , the other parity symbols @xmath216 , @xmath217 , are constructed as the sum of an element @xmath218 and @xmath214 elements in @xmath219 , i.e. , following a specific pattern .",
    "the remaining parity nodes are constructed in a similar way , with the only difference that the number of elements added from the sets @xmath219 , @xmath214 , varies for each parity node .",
    "the construction of the parity symbols @xmath220 depends on the choice of the symbols in the sets @xmath221 and @xmath219 .",
    "assume that a parity symbol @xmath222 is constructed .",
    "the data symbols involved in @xmath222 are picked as follows .",
    "* choice of a data symbol in @xmath100 : select a symbol @xmath101 such that the corresponding @xmath106 is maximum and there exists @xmath223 ( lines 2 and 3 in the algorithm ) .",
    "if the latter does not exists , then select @xmath224 such that @xmath106 is maximum .",
    "such a @xmath224 always exist .",
    "* choice of @xmath214 data symbols in @xmath215 : select @xmath214 symbols @xmath225 such that @xmath226 and its additional read cost does not increase ( line 20 in the algorithm ) .",
    "if such a condition is not met , then the symbol @xmath227 is not used in the construction of the parity symbol .        c.  huang , m.  chen , and j.  li , `` pyramid codes : flexible schemes to trade space for access efficiency in reliable data storage systems , '' in _ proc .",
    "network computing and applications _ , jul"
  ],
  "abstract_text": [
    "<S> we present the construction of a new family of erasure correcting codes for distributed storage that yield low repair bandwidth and low repair complexity . </S>",
    "<S> the construction is based on two classes of parity symbols . </S>",
    "<S> the primary goal of the first class of symbols is to provide good fault tolerance , while the second class facilitates node repair , reducing the repair bandwidth and the repair complexity . </S>",
    "<S> we compare the proposed codes with other codes proposed in the literature . </S>"
  ]
}