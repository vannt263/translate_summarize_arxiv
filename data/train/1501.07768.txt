{
  "article_text": [
    "evaluating complex web systems and their impact on user behavior is a challenge of growing importance .",
    "data - driven tools have become very popular in the last decades to help in deciding which algorithm , which website home page , which user interface , etc , provides the best results in terms of some relevant criteria such as the generated revenue , the click - through rate ( ctr ) , the number of visits , or any other business metric .",
    "a detailed description of the general data - driven paradigm is available in @xcite .",
    "different experimention methods are available , ( * ? ? ?",
    "* for a primer ) , and ab - testing , aka split or bucket testing , is wide - spread . for examples and best practices , we refer the reader to @xcite and references therein .",
    "this method compares two versions , @xmath0 and @xmath1 , of a system by splitting the users randomly into two independent populations to which systems @xmath0 and @xmath1 are respectively applied .",
    "we use the word _ system _ in a broad sense here as it can range from being the design of a web page @xcite to more complex algorithms such as a bidder on a real time bidding ad server @xcite .",
    "relevant metrics are then computed on each population and compared to decide which system performs better .",
    "such comparisons rely on statistical tests to evaluate their significance , see for example @xcite , among which z - tests assess if the neutral hypothesis can be rejected or not at a fixed level of certainty .",
    "the simplest example is the one measuring a click - through rate , or any other rate that can only lead to binary values .",
    "the click - through rate can be written as the empirical average of bernoulli random variables equal to @xmath2 if the user has clicked and to @xmath3 otherwise .",
    "then , the central limit theorem provides confidence intervals for both the click - through rate in each population and its absolute increment between the two populations ( see * ? ? ? * for an example ) . in this case , the asymptotic variance is directly derived from the estimated click - through rate @xmath4 as @xmath5 where @xmath6 is the number of users .    in practice",
    ", a user might click several times .",
    "then the random variables that are averaged are no longer distributed under the bernoulli law and the asymptotic variance can not be computed in the same way .",
    "we show that using such an approximation can even be dangerous through a numerical application to ctr .",
    "as stated in @xcite , we need to use the variance of the number of clicks per user .",
    "they also provide confidence intervals for their relative increment using an approximation for the ratio adapted from @xcite but estimators for the involved variances are not provided for non bernoulli random variables .",
    "furthermore , these confidence intervals do not take into account the randomness of the number of displays made to users .",
    "the litterature lacks of a formal modeling of the ab - test process .",
    "previous works such as @xcite mainly focus on applications of this method and do not provide a well - defined statistical framework for the results analysis .",
    "most available sources for the practitioner are online calculators only dedicated to the bernoulli case . a primer of the underlying theory applied to ab - test analysis is only given in online references such as @xcite but they do not go deeply into the statistical modeling and do not cover more general metrics than simple sums of independent bernoulli random variables . in this paper , we introduce a formal framework for the ab - test process modeling only involving assumptions consistent with the data - driven paradigm .",
    "it allows us to prove some statistical properties of the involved estimators , including those based on ratios , and to get numerical methods to approximate the variances involved in the related central limit theorems .",
    "we also go beyond that by justifying the use of the bootstrap algorithm @xcite to compute confidence intervals for absolute and relative increments .",
    "the mathematical formalization of the ab - test framework is given in section [ sec : framework ] . in section [ sec : mainresults ] , we provide exact asymptotic confidence intervals for any kind of metric that is obtained by summing quantities over the users , and for any metric computed as the ratio of such sums .",
    "we also get exact asymptotic confidence intervals for both their absolute and relative increments under few assumptions , most of them directly related to the ab - test process .",
    "explicit estimators for the related asymptotic variances are provided .",
    "we additionaly show how to use bootstrapping to get confidence intervals when the data can not be grouped by user , as is commonly the case in the big - data field .",
    "section [ sec : experiments ] numerically validates our assumptions and the proposed algorithms , while appendices [ appendix : proofs ] and [ appendix : proofs - clt ] give formal proofs of the technical results of section [ sec : mainresults ] .",
    "in order to translate the ab - test process into a mathematical framework , we introduce some random variables modeling the metrics that one wants to evaluate and the way in which the users are separated into two populations .",
    "more precisely , let @xmath7 be a probability space and @xmath8 $ ] the expectation operator under @xmath9 .",
    "we define a sequence of random vectors on @xmath10 @xmath11 for each user @xmath12 , @xmath13 and @xmath14 indicate the population that has been selected for this user : @xmath15 ( resp .",
    "@xmath16 ) if and only if the user @xmath17 is in population @xmath0 of size ratio @xmath18 $ ] ( resp .",
    "@xmath1 of size ratio @xmath19 $ ] ) .",
    "note that in general we will have @xmath20 but this is not required and our analysis also applies to tests involving more than two populations .",
    "the other variables model metrics of interest for the ab - tester . @xmath21 and @xmath22 are the same metric generated by the user @xmath17 if he was applied to systems @xmath0 and @xmath1 respectively .",
    "the same stands for @xmath23 and @xmath24 which model another metric .",
    "[ ex : revenue ] when the ab - tester wants to compare the revenue generated by algorithms @xmath0 and @xmath1 , he compares the total revenue of each population , normalized by their ratio .",
    "they can be written : @xmath25 if @xmath21 and @xmath22 are the revenues generated by user @xmath17 under systems @xmath0 and @xmath1 respectively .",
    "note that , in practice , we can also normalize the total revenues by the real population sizes instead of their ratios and the quantities to compare become : @xmath26    [ ex : ctr ] when the ab - tester wants to compare the ctr generated by algorithms @xmath0 and @xmath1 , he compares the ctr of each population .",
    "they can be written : @xmath27 if @xmath21 and @xmath22 are the clicks generated by user @xmath17 , and @xmath23 and @xmath24 the number of displays shown to the same user under systems @xmath0 and @xmath1 respectively .",
    "we introduce the following assumptions that will be easily followed in an ab - test setting .",
    "[ hypa : iid ] the random vectors @xmath28 are independent and identically distributed .    [ hypa : abtest - independence ] the random vectors @xmath29 and @xmath30 are independent .",
    "[ hypa : moment ] the random variables @xmath29 are @xmath31-integrable and we define @xmath32}{\\ ; } , { \\;}{m_{{y^{\\refpop}\\ifthenelse{\\equal { } { } } { } { _ { } } } } } { \\ensuremath{\\stackrel{\\mathrm{def}}{=}}}{\\mathbb{e}\\left[{y^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}\\right]}{\\ ; } , { \\;}{m_{{x^{\\testpop}\\ifthenelse{\\equal { } { } } { } { _ { } } } } } { \\ensuremath{\\stackrel{\\mathrm{def}}{=}}}{\\mathbb{e}\\left[{x^{\\testpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}\\right]}{\\ ; } , { \\;}{m_{{y^{\\testpop}\\ifthenelse{\\equal { } { } } { } { _ { } } } } } { \\ensuremath{\\stackrel{\\mathrm{def}}{=}}}{\\mathbb{e}\\left[{y^{\\testpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}\\right]}{\\;},\\ ] ] @xmath33 @xmath34    [ hypa : non - negative ] the random variables @xmath29 are almost surely non - negative and not almost surely zero , that is @xmath35    [ hypa : epsilon - law ] the random variables @xmath36 satisfies :    1 .",
    "[ hypa : epslion - law : marginal ] @xmath37 and @xmath38 follow bernoulli laws of respective parameters @xmath39 and @xmath40 .",
    "[ hyp1:epsilon - law : joint ] @xmath41    a user can only be assigned to one population , which is ensured by assumption a[hypa : epsilon - law]-[hyp1:epsilon - law : joint ] .",
    "assumption a[hypa : epsilon - law]-[hypa : epslion - law : marginal ] sets the ratio of populations @xmath0 and @xmath1 to be respectively @xmath39 and @xmath40 .",
    "assumption a[hypa : abtest - independence ] reflects the fact that the population attribution process does not affect the user reaction to the applied system while assumption a[hypa : moment ] is purely technical .",
    "this is the only assumption that is not implied by the ab - test process but it will guarantee the convergence of the estimators .",
    "assumption a[hypa : non - negative ] is consistent with the metrics that we are studying",
    ". they will typically be zero with a high probability and positive otherwise ( for example , the number of clicks ) .",
    "finally , assumption a[hypa : iid ] models the un - identifiability of the users .",
    "they are all independent and , without prior knowledge , identically distributed .",
    "the whole ab - test process relies on this assumption by randomly splitting the users into two populations .",
    "it is worthwhile to note that the metrics of interest @xmath42 are defined for each user and for each system , independently of the population split",
    ". the ab - test process will give access to only @xmath21 or @xmath22 for a given user @xmath17 , but they can still both be defined even when they are not observed .",
    "this is the main interest of this modeling that allows us to write those variables independently of the population .",
    "furthermore , we circumvent the issue of having hidden variables by introducing a new set of variables that will always be observed . to that purpose",
    ", we simply set @xmath21 to @xmath3 when it is not observed , i.e. when the user @xmath17 is not in population @xmath0 .",
    "this is formalized in the following definition .",
    "[ def : tilde ] for each user @xmath12 , we define @xmath43    [ rem : iid ] we trivially obtain from assumption a[hypa : iid ] that the random vectors @xmath44 are independent and identically distributed .",
    "using definition [ def : tilde ] , sums of the form @xmath45 can by re - written in a more appealing way as @xmath46 where the random variables @xmath47 are summed on _ all _ the users independently of their population , which leads to the following sum definitions for any number of users @xmath48 : @xmath49 in the case of example [ ex : revenue ] , we will have to compare either two sums over the same indices @xmath50 and @xmath51 when the normalization is done by the population ratios ; or two ratios of sums over the same indices @xmath52 and @xmath53 , where @xmath54 and @xmath55 , when the normalization is done by the real population sizes",
    ". in the case of example [ ex : ctr ] , the ratios to compare become similarly @xmath52 and @xmath53 .",
    "writting the estimators this way validates the use of the bootstrap technique @xcite to get confidence intervals . for the relative increments of the metrics of interest ,",
    "this can be done through the study of ratio : @xmath56 three algorithms will be derived in the following section to get confidence intervals on such quantities .",
    "the previous modeling has been designed to translate ab - test metrics into functions of sums of i.i.d .",
    "variables as in . the i.i.d .",
    "property allows us to design and validate a bootstrap technique to get confidence intervals , and dealing only with sums adds the ability to derive central limit theorems for all the metrics and their increments ( both absolute and relative ) .",
    "according to remark [ rem : iid ] , the random vectors @xmath57 are i.i.d . , and by definition [ def : tilde ] we have for @xmath12 @xmath58 assumption a[hypa : moment ] then shows that @xmath57 are @xmath59 integrable .",
    "we thus can apply the law of large numbers to the sums of interest @xmath60 and show that they converge to @xmath61 .",
    "we then get that for any continuous function @xmath62 , the quantity @xmath63 is a consistent estimator of @xmath64 .",
    "the case of a ratio is dealt with by introducting the following transformation .",
    "[ def : nonzero ] we define the function @xmath65 from @xmath66 to @xmath67 defined by @xmath68    we will apply @xmath65 to all the denominators in the following theorems , and , according to the positiveness ensured by assumption a[hypa : non - negative ] , the ratios are continuous functions of the non - zero sums .",
    "it is only a technical point , as in practice we would not define the ratio for a null denominator . in theoretical applications ,",
    "lemma [ lem : nonzero - probaconv ] in appendix [ appendix : proofs ] allows us to replace the sums by their non - zero versions obtained by applying the operator @xmath65 , but for the sake of simplicity we will not use it when describing the bootstrap .",
    "if we denote by @xmath69 the distribution of @xmath70 , then all the quantities that we are estimating can be written as a functional @xmath71 , and their estimators are asymptotically normal as shown in the relevant propositions of section [ subsec : clt ] .",
    "the link between estimators , @xmath62 , @xmath72 , and their central limit theorem result is summarized in table [ tab : link - estimators ] .",
    ".different estimators of interest [ cols=\"^,^,^,^\",options=\"header \" , ]      in order to validate assumption a[hypa : iid ] and to show that it can not be approximated by an independence of the displays , @xmath73 blank ab - tests were simulated and @xmath74 blank ab - tests and the results were very similar . ] . for each ab - test",
    ", confidence intervals at different levels ( from @xmath75 to @xmath76 ) were computed for the absolute ctr increment @xmath77 using two methods .",
    "the first one assumes that the _ displays _ are independent implying an asymptotic variance of @xmath78 this is the formula usually given when describing ab - test analysis .",
    "the second method assumes that the _ users _ are independent and is described in algorithm [ alg : clt - ci ] . if the variables @xmath79 model the following quantities    * @xmath21 : number of clicks from user @xmath17 if system @xmath0 is applied , * @xmath23 : number of displays shown to user @xmath17 if system @xmath0 is applied , * @xmath22 : number of clicks from user @xmath17 if system @xmath1 is applied , * @xmath24 : number of displays shown to user @xmath17 if system @xmath1 is applied ,    then the ctr of each population can be written @xmath80 and the asymptotic variance of @xmath77 is given in proposition [ prop : clt - ratio - absolute - diff ] .    the true value of the absolute increment is known to be @xmath3 and , for each confidence level",
    ", we give the percentage of ab - tests for which the confidence interval contained @xmath3 .",
    "the closer this percentage to the target confidence level , the better the underlying method .",
    "results for both assumptions are shown in figure [ fig : display - vs - user - iid ] .",
    "assuming independence of displays leads to under - estimating the ab - test noise , and increments appear significant much more often than they should be .",
    "for example , a @xmath81-confidence interval includes the true value in only @xmath82 of ab - tests which contradicts the definition of a confidence interval . on the contrary",
    ", the assumption of user independence leads to the expected conclusion of having almost @xmath81 of @xmath81-confidence intervals including @xmath3 and it remains true for all other tested levels .",
    "this under - estimation is explicitly illustrated in figure [ fig : nbclicks - distribution ] where the empirical distribution of the number of clicks ( obtained by bootstrapping ) is compared to the binomial distribution implied by the display independence assumption .",
    "it shows that the empirical standard deviation is much higher than the binomial one ( twice as big in this example ) .",
    "the assumption of independence by user having been validated , we can now focus on the comparison of the proposed algorithms .",
    "the method using only the central limit theorem will be given as a reference but is not of practical interest here as the dataset is not grouped by user ( see section [ subsec : bootstrap ] ) .",
    "we are thus more interested in comparing algorithms [ alg : ci - bootstrap ] and [ alg : fast - ci ] as they can be implemented in a such a way that the dataset is read only once .",
    "each algorithm uses bootstrapping , having a computational cost linear in the number of bootstraps @xmath83 . similarly to section [ subsec : assumption - validation ] , @xmath73 blank ab - tests were simulated from the dataset described in [ subsec : dataset ] to compute confidence intervals for ctr relative increment @xmath84 where @xmath79 are defined in section [ subsec : assumption - validation ] . according to proposition [ prop : clt - ratio - relative - diff ] ,",
    "this estimator is asymptotically normal and its average should be @xmath3 for a blank ab - test .",
    "the frequency of confidence intervals including the true value @xmath3 is displayed in figure [ fig : bootstrap - levels ] for different levels of confidence and for both the pure bootstrap technique with @xmath85 ( algorithm [ alg : ci - bootstrap ] ) and the technique using the bootstrap variance in the clt ( algorithm [ alg : fast - ci ] ) again with @xmath85 .    ]    as expected , for a small number of bootstraps @xmath85 , the pure bootstrap algorithm performs poorly and is able to get an acceptable confidence intervals for only a few confidence levels , while the algorithm using both clt and bootstrapping shows good results for all confidence levels for the same computational cost . in figure",
    "[ fig : bootstrap - number ] , we show the influence of the number of bootstraps @xmath83 in the ability of each algorithm to compute reliable @xmath81 confidence intervals .    ]",
    "the pure bootstrap algorithm converges more slowly to the target @xmath81 value and requires twice the computational cost as the mixed algorithm .",
    "we have translated the ab - test process into a statistical framework , providing three algorithms for the computation of confidence intervals . each of them are useful for different practical cases :    1 .",
    "if the number of users @xmath6 is small , pure bootstrapping is the best choice ( see algorithm [ alg : ci - bootstrap ] ) , and a large number of bootstraps @xmath83 is tractable ; 2 .",
    "if the number of users @xmath6 is large and the dataset is grouped by user , then one should use one of the relevant central limit theorems ( see algorithm [ alg : clt - ci ] ) ; 3 .",
    "if the number of users @xmath6 is large and the dataset is not grouped by user , the algorithm using the bootstrap variance in the central limit theorem will result in the smallest computational cost ( see algorithm [ alg : fast - ci ] ) .",
    "numerical experiments allowed us to check that our assumptions were valid .",
    "we focused on the ctr computation , but , as stated in the theoretical parts , the proposed algorithms apply to any metric that can be written as a sum or a ratio of sums , e.g. , to the sales amount spend per user as well as the revenue generated per user .",
    "similar numerical results allowed us to validate the algorithms .",
    "it is worthwhile to note that the provided algorithms lead to results valid only during the ab - test but do not extend to the future .",
    "this is known as the _ long term effect _ as discussed in @xcite .",
    "addressing this issue would require additional assumptions on the metrics of interest , such as time series modeling , and is out of the scope of this paper .",
    "the notations used here are independent from the ones defined in the other sections as the following propositions are general results on random variable convergence .",
    "we only keep the definition of @xmath65 given in definition [ def : nonzero ] that is widely used when dealing with ratios .",
    "all the random variables will be assumed to be defined on a probability space @xmath7 and the expectation operator under @xmath9 will be denoted by @xmath86}$ ] .",
    "[ lem : nonzero - probaconv ] let @xmath87 be a sequence a real random variables converging in probability to a real constant @xmath88 .",
    "then the sequence @xmath89 also converges in probability to @xmath90 where @xmath65 is defined in definition [ def : nonzero ] .    by the triangle inequality",
    ", we have , for each @xmath91 @xmath92 implying that for each @xmath93 @xmath94 where the second probability converges to @xmath3 by definition of @xmath95 and the first one is bounded by @xmath96 where the last probability converges to @xmath3 by definition of @xmath95 .",
    "[ lem : nonzero - clt ] let @xmath97 be a sequence a random variables in @xmath98 such that    1 .",
    "[ lem : ass : probaconv ] @xmath95 where @xmath90 is real constant such that @xmath99 , 2 .",
    "[ lem : ass : nonzerospeed ] there exists @xmath100 such that @xmath101 , 3 .",
    "[ lem : ass : clt ] there exist @xmath102 and a random variable @xmath103 in @xmath98 @xmath104    then the assertions [ lem : ass : probaconv ] and [ lem : ass : clt ] are satisfied with @xmath105 where @xmath65 is defined in definition [ def : nonzero ] .    assumption [ lem : ass : probaconv ] and lemma [ lem : nonzero - probaconv ] directly give @xmath106 .    in order to proove the distribution convergence",
    ", we use the portemanteau lemma by showing that for all bounded lipschitz function @xmath62 , @xmath107}$ ] converges to @xmath108}$ ] .",
    "let @xmath62 be a bounded and lipschitz function , we have @xmath109 } - { \\mathbb{e}\\left[f(v)\\right]}\\right| \\\\ \\leq { \\mathbb{e}\\left[\\left|f(\\sqrt{n}(x_n^1-x_1 , \\cdots , x_n^d - x_d , { \\varphi\\ifthenelse{\\equal{y_n}{}}{}{\\left(y_n\\right)}}-y))-f(v)\\right|\\right ] } { \\ ; } , \\\\",
    "\\leq { \\mathbb{e}\\left[\\left|f(\\sqrt{n}(x_n^1-x_1 , \\cdots , x_n^d - x_d , { \\varphi\\ifthenelse{\\equal{y_n}{}}{}{\\left(y_n\\right)}}-y)-f(\\sqrt{n}(x_n^1-x_1 , \\cdots , x_n^d - x_d , y_n - y))\\right|\\right ] } \\\\+ { \\mathbb{e}\\left[\\left|f(\\sqrt{n}(x_n^1-x_1 , \\cdots , x_n^d - x_d , y_n - y))-f(v)\\right|\\right]}{\\;}.\\end{gathered}\\ ] ] according to assumption [ lem : ass : clt ] , the second term of the right hand side of converges to @xmath3 .",
    "the first term is handled using the lipschitz property of @xmath62 : there exists a constant k such that for all @xmath110 , @xmath111 so that @xmath112 }   \\\\",
    "\\leq k\\sqrt{n } { \\mathbb{e}\\left[\\left|\\left|(x_n^1-x_1 , \\cdots , x_n^d - x_d , { \\varphi\\ifthenelse{\\equal{y_n}{}}{}{\\left(y_n\\right)}}-y)-(x_n^1-x_1 , \\cdots , x_n^d - x_d , y_n - y)\\right|\\right|_{l_1}\\right ] } { \\ ; } , \\\\ = k\\sqrt{n } { \\mathbb{e}\\left[\\left|{\\varphi\\ifthenelse{\\equal{y_n}{}}{}{\\left(y_n\\right)}}- y_n\\right|\\right ] } = k\\sqrt{n } { \\mathbb{e}\\left[\\one_{y_n=0}\\right ] } = k\\sqrt{n } { \\mathbb{p}\\left\\{y_n=0\\right\\ } }   { \\;},\\\\ \\leq k\\sqrt{n } c^n { \\ ; } , \\quad \\mbox{according to assumption \\ref{lem : ass : nonzerospeed},}\\end{gathered}\\ ] ] which shows that the first term of the right hand side of converges to @xmath3 and that @xmath113 .",
    "[ prop : multiratio - clt ] let @xmath114 be a sequence a random variables in @xmath115 , @xmath116 and @xmath117 a @xmath118 covariance matrix such that    1 .   [",
    "prop : ass : nonzeroy ] @xmath88 and @xmath119 , 2 .",
    "[ prop : ass : probaconv ] @xmath95 and @xmath120 , 3 .",
    "[ prop : ass : nonzerospeed ] there exists @xmath100 such that @xmath101 and @xmath121 , 4 .",
    "[ prop : ass : clt ] the sequence @xmath114 satisfies the following central limit theorem @xmath122    then the ratio sequence @xmath123 satisfies the following central limit theorem @xmath124    we first rewrite @xmath125 as @xmath126 and simarly @xmath127 so that @xmath128 where @xmath129 by applying lemma [ lem : nonzero - probaconv ] , @xmath106 and @xmath130 so that @xmath131",
    ". furthermore , using lemma [ lem : nonzero - clt ] twice , we successively get that @xmath132 and then @xmath133 satisfy the clt stated in assumption [ prop : ass : clt ] .",
    "we then only need to apply the slutsky lemma to conclude .",
    "[ cor : ratio - clt ] let @xmath134 be a sequence a random variables in @xmath135 , @xmath136 and @xmath117 a @xmath137 covariance matrix such that    1 .",
    "@xmath88 , 2 .",
    "@xmath95 , 3 .",
    "there exists @xmath100 such that @xmath101 , 4 .",
    "@xmath134 satisfies the following central limit theorem @xmath138    then the ratio sequence @xmath139 satisfies the following central limit theorem @xmath140    this is a direct consequence of proposition [ prop : multiratio - clt ] by keeping only the first marginal of the ratio couple .",
    "the vector @xmath60 is made of empirical means of random variables @xmath44 . according to definition [ def : tilde ] and to assumption a[hypa : iid ] , these variables are i.i.d . and by the same definition they are centered on @xmath141 .",
    "furthermore , one directly sees that @xmath142 which , combined with assumption a[hypa : moment ] , shows that @xmath143 is @xmath31-integrable .",
    "we then can apply a multi - dimensional version of the central limit theorem to get the announced convergence in distribution result .",
    "it now only remains to calculate the related variances and covariances . by definition[def : tilde ] , we have @xmath144 } - { \\mathbb{e}\\left[{\\varepsilon^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}{x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}\\right]}^2 \\right\\ } { \\ ; } , \\\\      & = \\frac{1}{\\ratioa^2 }   \\left\\ { { \\mathbb{e}\\left[{\\varepsilon^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}\\right]}{\\mathbb{e}\\left[({x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}})^2\\right ] } - { \\mathbb{e}\\left[{\\varepsilon^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}\\right]}^2{\\mathbb{e}\\left[{x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}\\right]}^2 \\right\\ } { \\ ; } , \\quad \\mbox{by assumption a\\ref{hypa : abtest - independence},}\\\\      & = \\frac{1}{\\ratioa}{\\mathbb{e}\\left[({x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}})^2\\right ] }",
    "- { m_{{x^{\\refpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}^2 { \\ ; } , \\\\      & = \\frac{1}{\\ratioa } \\left[{\\sigma_{{x^{\\refpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}^2 + { m_{{x^{\\refpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}^2\\right ] - { m_{{x^{\\refpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}^2 { \\ ; } , \\quad \\mbox{according to assumation a\\ref{hypa : moment},}\\\\      & = \\dfrac{1}{\\ratioa}{\\sigma_{{x^{\\refpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}^2 + \\dfrac{1-\\ratioa}{\\ratioa } { m_{{x^{\\refpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}^2 { \\;}.\\end{aligned}\\ ] ] the same stands for @xmath145 , @xmath146 , and @xmath147 , and very similar steps allows to get the values of @xmath148 and @xmath149 .    using again definition [ def : tilde ] and assumption a[hypa : epsilon - law ] , one gets @xmath150 } - { \\mathbb{e}\\left[{\\widetilde{{x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}}}\\right]}{\\mathbb{e}\\left[{\\widetilde{{x^{\\testpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}}}\\right ] } { \\ ; } , \\\\      & = -{m_{{x^{\\refpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}{m_{{x^{\\testpop}\\ifthenelse{\\equal{}{}}{}{_{}}}}}{\\ ; } , \\quad \\mbox{as } { \\varepsilon^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1}}}{\\varepsilon^{\\testpop}\\ifthenelse{\\equal{1}{}}{}{_{1 } } } = 0 { \\;},\\end{aligned}\\ ] ] and the same formula can be derived for @xmath151 , @xmath152 and @xmath153 .",
    "define a continuous function @xmath154 from @xmath115 to @xmath66 by @xmath155 so that @xmath156 = g\\left(\\sqrt{\\numuid } \\left (      \\begin{array}{c }          \\sumxtildea - { m_{{x^{\\refpop}\\ifthenelse{\\equal { } { } } { } { _ { } } } } } \\\\",
    "\\sumytildea - { m_{{y^{\\refpop}\\ifthenelse{\\equal { } { } } { } { _ { } } } } } \\\\",
    "\\sumxtildeb - { m_{{x^{\\testpop}\\ifthenelse{\\equal { } { } } { } { _ { } } } } } \\\\          \\sumytildeb - { m_{{y^{\\testpop}\\ifthenelse{\\equal { } { } } { } { _ { } } } } }      \\end{array } \\right ) \\right ) { \\;}.\\ ] ] then , by the continuous mapping theorem and theorem [ th : clt ] , @xmath157 $ ] converges in distribution to a normal random variable of mean @xmath3 and variance @xmath158        according to assumpation a[hypa : non - negative ] , @xmath160 almost surely , which implies that @xmath161 } \\geq 0 $ ] . furthermore , by the markov inequality , for any @xmath91 we have : @xmath162 if @xmath163 then for any @xmath91 , @xmath164 and thus @xmath165 which is in contradiction with assumption a[hypa : non - negative ] .",
    "we have @xmath167^{\\numuid}{\\ ; } , \\\\      &     = \\left[1-{\\mathbb{p}\\left\\{{\\varepsilon^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1 } } } > 0 , { x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1 } } } > 0\\right\\}}\\right]^{\\numuid}{\\ ; } , \\\\      &     = \\left[1-{\\mathbb{p}\\left\\{{\\varepsilon^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1 } } } > 0\\right\\}}{\\mathbb{p}\\left\\{{x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1 } } } > 0\\right\\}}\\right]^{\\numuid}{\\ ; } ,   \\quad \\mbox{by assumption a\\ref{hypa : abtest - independence},}\\\\      &     = \\left[1-\\ratioa{\\mathbb{p}\\left\\{{x^{\\refpop}\\ifthenelse{\\equal{1}{}}{}{_{1 } } } > 0\\right\\}}\\right]^{\\numuid}{\\ ; } ,   \\quad \\mbox{by assumption a\\ref{hypa : epsilon - law},}\\end{aligned}\\ ] ] where @xmath168 by assumption a[hypa : non - negative ] .",
    "the same steps applied to @xmath169 , @xmath50 and @xmath169 achieve the proof by setting @xmath170 { \\;}.\\ ] ]            1 .",
    "@xmath183 and @xmath184 by lemma [ lem : positive - means ] , 2 .   according to the weak law of large numbers , @xmath185 and @xmath186 , 3 .",
    "@xmath187 and @xmath188 by lemma [ lem : proba - sum-0 ] , 4 .",
    "according to theorem [ th : clt ] , the clt condition is satisfied .          1 .",
    "@xmath194 by lemma [ lem : positive - means ] , 2 .   by the weak law of large numbers",
    ", we have @xmath174 and @xmath185 .",
    "then by lemma [ lem : nonzero - probaconv ] , @xmath195 and we can apply the continuous mapping theorem to get @xmath196 , 3 .   according to lemma [ lem : proba - sum-0 ] , we have @xmath197 , 4 .",
    "the central limit theorem is stated in proposition [ prop : clt - ratio ] .",
    "thomas crook , brian frasca , ron kohavi , and roger longbotham .",
    "seven pitfalls to avoid when running controlled experiments on the web . in _ proceedings of the 15th acm sigkdd international conference on knowledge discovery and data mining _ ,",
    "pages 11051114 .",
    "acm , 2009 .",
    "frederica darema .",
    "dynamic data driven applications systems : a new paradigm for application simulations and measurements . in marian bubak , geertdick van albada , peterm.a .",
    "sloot , and jack dongarra , editors , _ computational science - iccs 2004 _ , volume 3038 of _ lecture notes in computer science _ , pages 662669 .",
    "springer berlin heidelberg , 2004 .",
    "isbn 978 - 3 - 540 - 22116 - 6 .",
    "doi : 10.1007/978 - 3 - 540 - 24688 - 6_86 .",
    "url http://dx.doi.org/10.1007/978-3-540-24688-6_86 .",
    "ron kohavi , alex deng , brian frasca , roger longbotham , toby walker , and ya  xu .",
    "trustworthy online controlled experiments : five puzzling outcomes explained . in _ proceedings of the 18th acm sigkdd international conference on knowledge discovery and data mining _ , pages 786794 .",
    "acm , 2012 .",
    "nikunj  c oza and stuart russell .",
    "experimental comparisons of online and batch versions of bagging and boosting . in _ proceedings of the seventh acm sigkdd international conference on knowledge discovery and data mining _",
    ", pages 359364 .",
    "acm , 2001 .",
    "weinan zhang , shuai yuan , and jun wang .",
    "optimal real - time bidding for display advertising . in _ proceedings of the 20th acm sigkdd international conference on knowledge discovery and data mining_. acm , 2014 ."
  ],
  "abstract_text": [
    "<S> ab - testing is a very popular technique in web companies since it makes it possible to accurately predict the impact of a modification with the simplicity of a random split across users . </S>",
    "<S> one of the critical aspects of an ab - test is its duration and it is important to reliably compute confidence intervals associated with the metric of interest to know when to stop the test . in this paper , we define a clean mathematical framework to model the ab - test process . </S>",
    "<S> we then propose three algorithms based on bootstrapping and on the central limit theorem to compute reliable confidence intervals which extend to other metrics than the common probabilities of success . </S>",
    "<S> they apply to both absolute and relative increments of the most used comparison metrics , including the number of occurrences of a particular event and a click - through rate implying a ratio .    </S>",
    "<S> ab - test , confidence interval , central limit theorem , ratio of normal variables , bootstrapping </S>"
  ]
}