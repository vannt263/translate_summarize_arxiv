{
  "article_text": [
    "in this section we derive the relation @xmath13 , first given in @xcite .",
    "first , we define the phenotype robustness @xmath11 as a weighted average over genotype robustness ; second , we define it as the extent to which mutation off the neutral network does not deplete the growth due to fitness .",
    "readers who are less interested in the biological motivation may skip this section .",
    "_ genotype and phenotype robustness .",
    "_ consider a neutral network @xmath22 , and let its adjacency matrix be @xmath23 .",
    "the genotype robustness @xmath24 @xcite of a genotype @xmath25 is the probability of a mutation being neutral : the number of neutral edges incident to @xmath25 ( i.e. edges which do not lead to a different phenotype ) divided by the total number of incident edges @xmath26 . the genotype robustness can therefore be written as @xmath27 for a neutral network , let @xmath28 be its population vector at time @xmath29 , with the @xmath30th component @xmath31 corresponding to the population on genotype @xmath25 . the normalized population is distributed according to @xmath32 .",
    "suppose for now that in the limit @xmath33 , the normalized population is distributed according to a unique distribution .",
    "then we define the phenotype robustness @xmath11 to be the long - time population - weighted average of the genotype robustnesses @xmath24 : @xmath34 it is the fraction of the population flux that is neutral .",
    "we will now determine this limit .",
    "_ mutational flux and fitness .",
    "_ mutation induces a population flux across neighbouring genotypes .",
    "if the mutation rate per letter is @xmath35 , the mutational flux is @xmath36 for @xmath37 .",
    "it is the fraction of a population that mutates per generation",
    ". some of this mutational flux will also cross phenotypic boundaries when neighbouring genotypes lie in two different phenotypes .",
    "that which does not cross phenotypic boundaries is neutral .",
    "the fitness @xmath38 is the raw reproductive rate of the phenotype .",
    "after @xmath29 generations , the total population of a neutral network will have changed by a factor of @xmath39 , in the absence of mutations .",
    "_ mutation matrix_. the action of mutation on the population distribution over a single generation can be expressed by the mutation matrix @xmath40 : @xmath41 the first term is the probability that no mutation occurs and the second the probability of mutating .",
    "being symmetric , @xmath23 can be diagonalised by an orthonormal set of eigenvectors @xmath42 : @xmath43 where the @xmath42 satisfy the eigenvalue equation @xmath44 .",
    "the population vector @xmath28 is obtained by transforming an initial vector @xmath45 by @xmath46 and multiplying it by @xmath39 : @xmath47 let @xmath48 be the largest ( principal ) eigenvalue of @xmath23 , denoted hereafter @xmath12 . since @xmath49 , all terms @xmath50 decay exponentially with respect to the first for @xmath51 . in the large time limit",
    "the sum is dominated by the first term , whose eigenvalue @xmath52 is largest : @xmath53 we now show that defining the robustness as @xmath54 agrees with the definition of phenotype robustness in ( [ pheno ] ) .",
    "indeed , plugging ( [ geno ] ) into ( [ pheno ] ) , @xmath55 the quantity @xmath11 therefore measures how well the shape of the neutral network can reduce the rate of deleterious mutation acting on the population as a whole .",
    "we see from ( [ n_t_large_time_limit ] ) that at large time @xmath29 at every generation , a fraction @xmath56 of the population mutates off the neutral network , and the growth rate @xmath57 is the fitness that can be usefully employed to increase the population and not spent replenishing population lost to deleterious mutations incurred at the boundary .",
    "the steady state distribution of the population depends only on the shape of the neutral network and on neither the mutation rate @xmath35 nor the fitness @xmath38 .",
    "_ bricklayer s graphs .",
    "_ just how robust a phenotype can be  or how large an eigenvalue a neutral network can have  has remained an open question . for short sequences ( @xmath58 ) , we found from exhaustive enumeration that the most robust neutral networks are themselves hypercubes or interpolations between them , illustrated in figure 1 .",
    "computational sampling for slightly longer sequences ( @xmath59 ) agrees with this .",
    "we generalize the sequence of graphs and interpolations between them in figure 1 for @xmath60 as follows : suppose all vertices @xmath61 in @xmath10 are labelled as integers from 0 to @xmath62 , and two vertices share an edge if their base @xmath0 representations differ in exactly one digit",
    ". then @xmath63 is the subgraph induced by the vertices @xmath64 .",
    "we call these graphs @xmath63 `` bricklayer s graphs '' because they form the sequence by which a bricklayer would instinctively fill in the hamming graph @xmath10 . for the remainder of this note we set the alphabet size @xmath2 , so we are only concerned with hypercubes and their subgraphs . for simplicity",
    "we denote @xmath65 by @xmath66 .",
    "we conjecture an extension of our main result for general @xmath0 in the conclusion .    for neutral networks on sequences of short length @xmath1 ,",
    "the bricklayer s graphs @xmath66 are the most robust ; they have maximal principal eigenvalues . for longer lengths @xmath1 , however ,",
    "a surprise is in store : the @xmath66 are _ not _ the most robust neutral networks . in particular , we discovered the following counterexamples for @xmath14 and above .",
    "let @xmath67 be the star graph : a tree with one internal vertex and @xmath17 leaf vertices .",
    "the principal eigenvalue of @xmath67 is readily found to be @xmath68 .",
    "now let us compare the eigenvalue of a star of @xmath17 vertices , @xmath69 , to the eigenvalue @xmath16 of @xmath66 .",
    "as we prove below , @xmath15 .",
    "for the bricklayer s graphs @xmath66 to win , we need @xmath70 , implying @xmath71 however , this not true for @xmath72 .",
    "it is an open question as to what shape does maximize the eigenvalue for larger graphs . in the concluding remarks of @xcite",
    ", the authors consider the possibility that hamming balls ( graphs consisting of all points that are most a given distance from a point ) are asymptotic maximizers of hypercube subgraphs , but then provide some evidence that they are not . _ our main result .",
    "_ in this note we prove that the principal eigenvalue @xmath73 of the bricklayer s graph @xmath74 satisfies @xmath15 .",
    "our general approach is to show by a geometric staircase argument that for @xmath75 , a slightly stronger inequality ( @xmath76 ) holds for most @xmath17 ; it will then suffice to examine the cases where @xmath77 , using polynomials that have @xmath19 as roots .",
    "[ bricklayerclustertheorem ] for all graphs @xmath66 , we have @xmath15 , with equality if and only if @xmath17 is a power of 2 .",
    "equality is attained in the theorem if @xmath17 is a power of @xmath78 since @xmath16 must lie between the mean and maximum vertex degree @xcite , and for @xmath17 a power of 2 , all vertices are of degree @xmath79 .",
    "we wish to show that if @xmath17 is not a power of @xmath78 , there is strict inequality .",
    "we make two observations .",
    "observation 1 : since the principal eigenvalue of a proper subgraph of a connected graph is less than the principal eigenvalue of the graph itself , it follows that if @xmath80 then @xmath81 .",
    "observation 2 : since @xmath82 , and the spectrum of a cartesian product of graphs is the sum of their individual spectra @xcite , it follows that if @xmath83 then @xmath84 . using these observations",
    ", we claim :    [ reducetoedgecases ] the theorem is true for all @xmath17 if for some @xmath85 , @xmath86 and also @xmath87    the  staircase \" argument is illustrated in figure [ staircase_figure ] .",
    "we verify numerically that the theorem is true for @xmath88 and ( [ strongercondition ] ) holds for @xmath89 . now",
    "if ( [ strongercondition ] ) is true for some @xmath85 , then by observation 2 , @xmath90 by observation 1 we have the expansion @xmath91 for @xmath92 , so that @xmath93 for @xmath94 . conditions ( [ minusapointtheorem ] ) and ( [ plusapointtheorem ] ) then ensure that @xmath93 for @xmath95 and @xmath96 as well , proving the theorem for @xmath97 . finally , note that ( [ overlappinginequalitiesexpansion ] ) together with ( [ minusapointtheorem ] ) and ( [ plusapointtheorem ] ) imply that ( [ strongercondition ] ) holds with @xmath85 replaced by @xmath98 , so we may repeat our induction indefinitely .     the  staircase \" argument for the proof of lemma [ reducetoedgecases ] . because each bricklayer s graph is a subgraph of its successor , knowing the principal eigenvalue of a bricklayer s graph immediately places restrictions on higher - dimensional bricklayer s graphs ( as demonstrated by the staircase figures of each color ) . ]",
    "therefore , the theorem reduces to ( [ minusapointtheorem ] ) and ( [ plusapointtheorem ] ) , which we will prove by looking at polynomials that have the eigenvalues of our desired graphs as roots .",
    "we will make use of the following standard theorem in linear algebra :    @xmath99 ( cauchy s interlacing theorem @xcite ) .",
    "_ let @xmath23 be an @xmath100 symmetric nonnegative matrix with eigenvalues @xmath101 , and let @xmath102 be an @xmath103 principal submatrix of @xmath23 with eigenvalues @xmath104 . then for all @xmath105 , @xmath106 . _",
    "let @xmath107 be the characteristic polynomial of the adjacency matrix of @xmath74 . enumerating the hypercube spectrum , we find @xmath108 so we may define the polynomial @xmath109    by applying cauchy s interlacing theorem to the adjacency matrices of @xmath110 and @xmath111 ( thus  sandwiching \" the spectrum of @xmath112 by that of @xmath113 ) , we see from the multiplicity of the eigenvalues ( of @xmath114 ) that @xmath115 has the factor @xmath116 .",
    "a similar argument shows that @xmath117 has the same factor .",
    "so we may define the polynomials @xmath118 furthermore , we see that @xmath119 has at most @xmath1 simple roots , all of which are also roots of the @xmath1-degree polynomial @xmath120 .",
    "the reason we use the polynomials @xmath22 is related to the fact that @xmath121 is a hamming ball of radius @xmath122 in @xmath123 .",
    "we define @xmath124 , the @xmath1-dimensional ball of radius @xmath11 , as the set of points in @xmath123 that are hamming distance at most @xmath11 from the `` origin '' ( the point labelled `` 0 '' according to the labelling scheme specified in the first paragraph of section 2 ) .",
    "we determine recursive equations that give @xmath12 , the principal eigenvalue of @xmath124 .",
    "consider the corresponding eigenvector @xmath125 , and note that by symmetry the component of @xmath125 corresponding to a given vertex depends only on the distance of the vertex from the origin .",
    "therefore , let @xmath126 be the value of the component of @xmath125 corresponding to a vertex of distance @xmath85 from the origin . by matrix multiplication",
    ", we find that @xmath127 by setting @xmath128 and following the equations above for each fixed @xmath11 , we find that the principal eigenvalue of @xmath124 is a root of the polynomial @xmath129 , where @xmath130 , @xmath131 , and @xmath132    applying this to @xmath133 , we can generate polynomials in @xmath12 with coefficients in @xmath1 ( say @xmath134 ) such that when @xmath85 is substituted for @xmath1 , the resulting polynomial in @xmath12 has @xmath133 as a root .",
    "then @xmath135 , @xmath136 and , in general , @xmath137 and @xmath138 has @xmath133 as a root .",
    "in fact , @xmath138 has every simple eigenvalue of @xmath139 as a root ( by the reasoning of the derivation ) .",
    "since the degree of @xmath138 as a polynomial in @xmath12 is @xmath1 , and we have from above that @xmath119 has at most @xmath1 simple roots ( all of which are also roots of the @xmath1-degree polynomial @xmath120 ) , it must be the case that @xmath140",
    "rewriting the right side of ( [ minusapointtheorem ] ) by applying the taylor expansion with lagrange remainder gives @xmath141 therefore , for @xmath142 , @xmath143    now we deal with the left side of ( [ minusapointtheorem ] ) .",
    "[ minusapointnonexplicitbound ] @xmath144 .",
    "note that the function @xmath145 is convex on @xmath146 . to see this ,",
    "let @xmath147 be any monic polynomial with all real roots and observe that @xmath148,\\end{aligned}\\ ] ] which is always nonnegative if @xmath149 is at least the largest root of @xmath38 .",
    "now since the tangent linear approximation of a convex function is an underestimate , we obtain @xmath150 , which implies the lemma .",
    "we evaluate the desired values of @xmath120 and its derivative using ( [ pequalsf ] ) and the recursive relation in ( [ frecursiverelation ] ) .",
    "[ minusapointp ] @xmath151    recall the definition of @xmath152 from the previous section and the fact that @xmath153 .",
    "we seek to prove that @xmath154 , and to do this we will prove a stronger claim that for @xmath155 , @xmath156 where @xmath157 is the pochhammer symbol .",
    "we use induction on @xmath85 .",
    "for @xmath158 we have @xmath159 and @xmath160 .",
    "supposing the claim is true for @xmath161 and @xmath162 , we find from ( [ frecursiverelation ] ) that @xmath163    [ minusapointpderivative ] @xmath164    with respect to the polynomials @xmath134 , let @xmath165 denote @xmath166 .",
    "then @xmath167 , and @xmath168 , @xmath169 , and for @xmath170 , from ( [ frecursiverelation ] ) , @xmath171 we seek to prove that @xmath172 , and to do this we will prove a stronger claim that for integers @xmath173 , @xmath174    we use induction on @xmath85 .",
    "for the base cases @xmath158 and @xmath175 we find that @xmath176 and @xmath177 , as desired .",
    "now supposing the claim is true for @xmath178 and @xmath179 , it follows that    @xmath180 { \\textstyle \\frac{2^{j}}{j+1 } } -(k-1)(k-2 ) { \\textstyle \\frac{(k+i-1)!}{(i+1 ) ! } } - \\sum_{j=2}^{k-2 } \\textstyle \\frac{(k-1)!}{(k - j-2 ) ! } \\frac{2^{j-1}}{j } \\frac{(k - j+i)!}{(i+1 ) ! } \\\\ & = { \\textstyle \\frac{(k+i)!}{(i+1 ) ! } + ( k-1 ) \\textstyle \\frac{(k+i)!}{(i+1 ) ! } + ( k-1)(k-2)\\frac{(k+i-1)!}{(i+1 ) ! } } + \\sum_{j=2}^{k-2 } \\left [ \\textstyle \\frac{(k-1)!}{(k - j-2 ) ! } \\frac{2^j}{j+1 } + ( j-1 )   \\frac{(k-1)!}{(k - j-1 ) ! } \\frac{2^{j-1}}{j } \\right ] { \\textstyle \\frac{(k - j+i)!}{(i+1 ) ! } } \\\\ & \\phantom{= } + ( k-2)(k-1 ) ! { \\textstyle \\frac{2^{k-2}}{k-1 } -(k-1)(k-2)\\frac{(k+i-1)!}{(i+1 ) ! } } - \\sum_{j=2}^{k-2 } { \\textstyle \\frac{(k-1)!}{(k - j-2 ) ! } \\frac{2^{j-1}}{j } \\frac{(k - j+i)!}{(i+1 ) ! } } \\\\ & = k { \\textstyle \\frac{(k+i)!}{(i+1 ) ! } } + \\sum_{j=2}^{k-2 } \\textstyle \\left [ \\textstyle \\frac{(k-1)!}{(k - j-2 ) ! } \\left ( \\frac{2^j}{j+1 } - \\frac{2^{j-1}}{j } \\right ) + ( j-1 )   \\frac{(k-1)!}{(k - j-1 ) ! } \\frac{2^{j-1}}{j } \\right ] \\frac{(k - j+i)!}{(i+1 ) ! } + [ 2(k-1)(k-1 ) ! - k ! ] \\textstyle \\frac{2^{k-2}}{k-1 } \\\\ & = k { \\textstyle \\frac{(k+i)!}{(i+1 ) ! } } + \\sum_{j=2}^{k-2 } \\textstyle \\frac{k!}{(k - j-1 ) ! } \\left ( \\frac{2^j}{j+1 } - \\frac{2^{j-1}}{j } \\right ) \\frac{(k - j+i)!}{(i+1 ) ! } + k ! \\left ( \\frac{2^{k-1}}{k } - \\frac{2^{k-2}}{k-1 } \\right ) \\\\ & = k ! \\sum_{j=0}^{k-1 } \\left [ \\textstyle \\frac{(k - j+i)!}{(i+1)!(k - j-1 ) ! } \\frac{2^j}{j+1 } - \\frac{(k - j-1)(k - j+i-1)!}{(i+1)!(k - j-1 ) ! } \\frac{2^j}{j+1 } \\right ] \\\\ & = k ! \\sum_{j=0}^{k-1 } \\textstyle \\frac{(k - j+i-1)!}{i!(k - j-1 ) ! } \\frac{2^{j}}{j+1}. \\qedhere\\end{aligned}\\ ] ]    now substituting the results of lemmas [ minusapointp ] and [ minusapointpderivative ] into lemma [ minusapointnonexplicitbound ] , @xmath181 a simple induction with base cases @xmath182 shows that the sum in the denominator of the second term of ( [ minusapointbound ] ) on the right - hand side can be bounded by @xmath183 therefore , @xmath184 since we may combine the bounds ( [ minusapointsumbound ] ) and ( [ minusapointlogbound ] ) for @xmath142 , we have proved ( [ minusapointtheorem ] ) .",
    "rewriting the right side of ( [ plusapointtheorem ] ) in much the same way as the previous section , we find that for @xmath185 , @xmath186 as for the left side of ( [ plusapointtheorem ] ) , we have a computational shortcut :    [ ge ] let @xmath187 be a graph , and let @xmath188 be a bridge of @xmath187 ( i.e. , @xmath188 is an edge such that removing it would increase the number of connected components of @xmath187 ) .",
    "let @xmath189 be the graph @xmath187 with @xmath188 removed , and @xmath190 be the graph @xmath187 with @xmath188 and its endpoints removed .",
    "then @xmath191 , where @xmath192 is the characteristic polynomial of the adjacency matrix of @xmath187 .",
    "this is an extension of lemma 1 in @xcite , which states the result when @xmath187 is a forest and @xmath188 is any edge , and is also theorem 1.3 in @xcite .",
    "the proof involves expanding the matrix whose determinant is @xmath192 , using laplacian expansion and linearity of the determinant .",
    "[ prelation ] @xmath193 , and so dividing by @xmath116 , @xmath194    [ plusapointnonexplicitbound ] @xmath195 .    from the preceding corollary , @xmath196",
    "we wish to show that this is nonnegative on @xmath197 . from the argument of the proof of lemma [ minusapointnonexplicitbound ] , @xmath198 for @xmath197 , and from the equation for the second derivative of a polynomial there , @xmath199 for @xmath197 since the roots of @xmath120 interlace those of @xmath200 by cauchy s interlacing theorem .",
    "so @xmath201 is convex on @xmath197 , and so by linear approximation , @xmath202 , which implies the lemma .",
    "now as in the previous section , we evaluate the desired values of @xmath203 and its derivative .",
    "[ plusapointp ] @xmath204 .    using corollary [ prelation ] and lemma [ minusapointp ] , @xmath205 .",
    "[ plusapointpderivative ] @xmath206    differentiating ( [ p2ddefinition ] ) and then plugging in @xmath1 gives @xmath207 .",
    "then using corollary [ prelation ] and lemma [ minusapointpderivative ] , @xmath208    substituting the results of lemmas [ plusapointp ] and [ plusapointpderivative ] into lemma [ plusapointnonexplicitbound ] , @xmath209 from ( [ sumbound ] ) , we obtain that for @xmath210 , @xmath211 since we may combine the bounds ( [ plusapointsumbound ] ) and ( [ plusapointlogbound ] ) for @xmath142 , we have proved ( [ plusapointtheorem ] ) .",
    "this concludes the proof of the theorem .",
    "as an additional remark , if we bound @xmath212 for general @xmath213 in the manner of ( [ minusapointlogbound ] ) , we can deduce an asymptotic result : for any @xmath213 , there exists @xmath214 so large that @xmath215 for all @xmath216 .",
    "similarly generalizing ( [ plusapointlogbound ] ) leads to the result that for any @xmath217 , there exists @xmath214 so large that @xmath218 for all @xmath216 .",
    "there are several interesting and potentially important questions that we have not considered here , which merit further investigation .",
    "we prove that the form of the hypercube subgraph with maximal eigenvalue is a bricklayer s graph for small @xmath1 but the general form of the maximizers is unknown . indeed it is an open avenue of study to find even non - trivial bounds on the eigenvalue of a hypercube subgraph in terms of its number of vertices . while for small dimension @xmath1 the bricklayer s graphs are optimal , for @xmath220 and @xmath221 , hamming balls of radius 1 are superior . for large @xmath222 and @xmath223 ,",
    "hamming balls of larger radius may eventually dominate , but this is unproven .",
    "how these transitions extend to larger values of alphabet size @xmath0 is also an open question , though it seems that the critical dimension separating bricklayer s graphs and balls grows with @xmath0 .",
    "we hope that further research by others will shed light on these questions .",
    "a. wagner , `` robustness and evolvability : a paradox resolved , '' _ proc .",
    "b _ * 275 * , 91 - 100 ( 2008 ) .",
    "j. draghi , t. parsons , g. wagner and j. plotkin , `` mutational robustness can facilitate adaptation , '' _ nature _ * 463 * , 353 - 355 ( 2010 ) .",
    "e. van nimwegen , j. p. crutchfield and m. huynen , `` neutral evolution of mutational robustness , '' _ proc .",
    "sci usa _ * 96 * , 9716 - 9720 ( 1999 ) .",
    "r. hammack , w. imrich and s. klavar , _ handbook of product graphs _",
    "( 2nd edition ) , p. 267",
    "j. friedman and j .- p .",
    "tillich , `` generalized alon - boppana theorems and error - correcting codes , ''",
    "_ siam j. discrete math . _ * 19*(3 ) , 700 - 718 ( 2005 ) .",
    "a.e . brouwer and w.h .",
    "haemers , _ spectra of graphs _ ,",
    "hwang , `` cauchy s interlace theorem for eigenvalues of hermitian matrices , '' _ am .",
    "monthly _ * 111 * , 157 - 159 ( 2004 ) .",
    "l. lovsz and j. pelikn , `` on the eigenvalues of trees , '' _ periodica mathematica hungarica _ * 3 * , 175 - 182 ( 1973 ) .",
    "d. stevanovi , _ spectral radius of graphs _ , p. 7"
  ],
  "abstract_text": [
    "<S> a neutral network is a subgraph of a hamming graph , and its principal eigenvalue determines its robustness : the ability of a population evolving on it to withstand errors . </S>",
    "<S> here we consider the most robust small neutral networks : the graphs that interpolate pointwise between hypercube graphs of consecutive dimension ( the point , line , line and point in the square , square , square and point in the cube , and so on ) . </S>",
    "<S> we prove that the principal eigenvalue of the adjacency matrix of these graphs is bounded by the logarithm of the number of vertices , and we conjecture an analogous result for hamming graphs of alphabet size greater than two .    </S>",
    "<S> 05c50 , graph eigenvalue , hypercube , neutral networks , evolvability    the eigenvalues of neutral networks  </S>",
    "<S> subgraphs of hamming graphs  is a fascinating subject , yet one which seems to have received little attention from the mathematics community . </S>",
    "<S> a recent surge of scientific interest has been motivated by advances in the theory of neutral evolution @xcite , in which the evolution of a mutating population is captured by spectral properties of its underlying neutral network @xcite .    </S>",
    "<S> a _ genome _ is the set of all genotypes , or @xmath0-ary strings , of length @xmath1 and alphabet size @xmath0 . </S>",
    "<S> typically @xmath0 is small : @xmath2 ( hydrophilic and hydrophobic ) , @xmath3 ( nucleic acids ) or @xmath4 ( amino acids ) . on the other hand </S>",
    "<S> , @xmath1 can range from 3 ( codons ) to @xmath5 ( chromosomes ) . </S>",
    "<S> we represent the genome by a @xmath1-dimensional _ hamming graph _ </S>",
    "<S> @xmath6 , where @xmath7 is the complete graph on @xmath0 vertices and @xmath8 is the cartesian product @xcite . </S>",
    "<S> each of the @xmath9 vertices in the hamming graph corresponds to a genotype , and two vertices share an edge if the genotypes differ by a single mutation ( hamming distance one ) . </S>",
    "<S> a _ </S>",
    "<S> neutral network _ is the set of genotypes with the same phenotype ( observable characteristics ) ; it is just a subgraph of @xmath10 . in this note </S>",
    "<S> we use neutral network and phenotype interchangably .     the first 16  </S>",
    "<S> bricklayer s graphs , \" which are the hamming graphs and the interpolations between them . below each </S>",
    "<S> is the principal eigenvalue of its adjacency matrix . ]    </S>",
    "<S> assuming the phenotype has achieved high fitness , adjoining phenotypes will have a relatively negligible growth rate and act as effective absorbing boundaries . </S>",
    "<S> now consider a mutating population on the neutral network . </S>",
    "<S> that portion which mutates off of it will be lost , whereas that portion which stays on will survive . </S>",
    "<S> the _ robustness _ @xmath11 of a neutral network is the long - term probability that a randomly selected individual mutating in a random direction survives . </S>",
    "<S> it is the principal eigenvalue @xmath12 of the adjacency matrix of the neutral network divided by the number of directions for mutation : @xmath13 . </S>",
    "<S> this note is about the maximum robustness that a neutral network can have , which for small neutral networks are themselves hamming graphs and interpolations between them , shown for @xmath2 in figure 1 . </S>",
    "<S> surprisingly , this ceases to be true for larger neutral networks on longer sequences ( @xmath14 and above ) , which we demonstrate by way of counterexamples in the form of star graphs .    </S>",
    "<S> this note is divided into six parts . in the first part </S>",
    "<S> , we derive the relation between the robustness @xmath11 of a neutral network and its principal eigenvalue @xmath12 : @xmath13 . in the second part </S>",
    "<S> , we present our main result , @xmath15 , where @xmath16 is the eigenvalue of the @xmath17th bricklayer s graph ( see figure 1 ) . </S>",
    "<S> we prove it for all values of @xmath17 apart from @xmath18 using a geometric staircase argument . in the third part , we set the stage for the remainder of the proof by constructing polynomials with eigenvalues @xmath19 as roots . in the fourth and fifth parts , we bound the eigenvalues @xmath20 and @xmath21 . in the sixth part </S>",
    "<S> we conjecture a generalisation of our main result for higher @xmath0 and conclude with some extensions .    </S>",
    "<S> a secondary motivation of this paper is to introduce mathematicians to the connection between neutral networks and spectral graph theory and to encourage them to extend this work . </S>"
  ]
}