{
  "article_text": [
    "producing fault - free devices such as computer processors so costly that only a few large companies can afford building and running new facilities .",
    "but even devices known to be fully working initially may fail a posteriori .",
    "fault - tolerant computing tries to minimize the consequences of component failure by designing computer systems that continue to operate satisfactorily even in the presence of faults @xcite .",
    "the majority of fault - tolerant designs involves partitioning a computer system into modules that act as fault - containment regions .",
    "redundancy of these modules is then considered , so if one fails others can assume its function , optimizing reliability availability or efficiency .",
    "while redundancy is expensive , components known to be imperfect are classified as useless and become cheap if not free , even though they can still be of some use .",
    "for instance , some devices with minor defects are still profitable , as faulty memory chips in answering machines @xcite .",
    "another example is the massive parallel computer teramac @xcite , designed with devices with unknown status but connected with adaptive wiring so as to avoid the defects .",
    "a third strategy was presented in @xcite by one of us , where it was noticed that devices are most often only partly defective and therefore one may combine them in such a way that their imperfections cancel .",
    "this is the essence of the defect combination problem ( dcp ) , which applies to both analog and binary components .",
    "while the analog problem was already addressed mathematically in @xcite , the aim of the present paper is to solve its binary counterpart .",
    "the paper is organized as follows : in the following section , section [ sec : problem_definition ] , we present the problem and discuss briefly how to treat it by tools and concepts of statistical mechanics of disordered systems .",
    "the canonical ensemble approach is used in section [ sec : canonical ] to analyze the typical properties of the model . in section [ sec : simulations ] we compare the analytical work with numerical simulations .",
    "section [ sec : recycling ] is devoted to the flux recycling problem .",
    "we assume that each device is able to perform @xmath0 different functions , numbered by @xmath1 .",
    "the manufacturing process is such that each function is either permanently defective with probability @xmath2 or working with probability @xmath3 .. the dcp consists in extracting from an ensemble of @xmath4 devices a subset such that the defects compensate optimally .",
    "more precise , let us denote with ising variables @xmath5 whether the function @xmath6 of the component @xmath7 is defective ( @xmath8 ) or not ( @xmath9 ) .",
    "this means that the manufacturing process is summarized by @xmath10 which assumes that the state of the functions is determined independently at the time at which the device is being made . to identify whether a component @xmath7 belongs to a specific subset",
    "we introduce the boolean variables @xmath11 such that if @xmath12 the component belongs to a given subset of zero otherwise .",
    "every possible subset out of the ensemble is fully determined by a vector @xmath13 .",
    "the binary dcp is defined as the search for a combination such that the majority of its components gives the correct answer for all the functions , in which case @xmath14 conditions ( [ condition ] ) are also called majority vote in the fault - tolerant computer literature .",
    "a simple inspection of the set of inequalities ( [ condition ] ) indicates that a phase transition is expected .",
    "indeed , it is clear that when @xmath15 there is a large number of subsets out of the possible @xmath16 satisfying the above conditions . when @xmath0 increases the number of these subsets decreases and finding configurations that satisfy the majority vote ( [ condition ] ) is increasingly difficult ; at some point finding perfect subsets is not possible any more",
    ". therefore , one expects the existence two phases : a fault - free one where perfect subsets exist ( @xmath17 ) and a imperfect one where conditions ( [ condition ] ) @xmath18 where the best one can do is minimizing the number of unsatistifed conditions , that is , the number of faulty functions , denoted by @xmath19 .",
    "we define @xmath20 , the number of unsatisfied conditions in subset @xmath21 as @xmath22 where @xmath23 is a confidence threshold ( @xmath24 corresponds to the majority vote ) . if one rewrites the default distribution function as @xmath25 the similarity between the binary dcp and the optimal capacity problem of ising neural networks @xcite is evident .",
    "more precisely , the binary dcp is equivalent to the optimal capacity problem with @xmath26 synaptic couplings and biased patterns introduced in @xcite while the diagonal part of the spin glass overlap gives @xmath27 , thus having essentially the same parameter but scaling differently with the system size",
    ". it may be even possible that this was the source of discrepancy between different models in the sparse coding limit @xcite .",
    "a forthcoming work will address this question in details @xcite .",
    "we note here that this inconsistency is cured as soon as one rescales the bias parameter with the system size as in ( [ probxis ] ) . ] .",
    "whereas any combination can be considered in the above problem , the constrained dcp restricts the choice of combinations to those comprising a fixed number @xmath28 of components .",
    "the technological justification for this is that an actual implementation of the dcp would be made easier by building in advance boards designed for receiving a fixed number of components .",
    "we shall proceed similarly as in @xcite . in the canonical ensemble",
    "the typical properties of the unconstrained dcp are fully described by the partition function @xmath29 with @xmath30 the inverse temperature .",
    "the free energy @xmath31 then reads @xmath32 where @xmath33{\\big>\\hspace{-1mm}\\big>}_{{\\mbox{\\boldmath $ { \\xi}$}}}$ ] denotes the average with respect to @xmath34 .",
    "we are interested in the zero temperature limit where the free energy @xmath31 corresponds to the fraction of erroneously implemented functions whilst the entropy , defined as @xmath35 is the logarithm of the number of solutions to the dcp .",
    "nevertheless it is interesting to point out the behavior of this model with the temperature , similar to the random energy model @xcite . in the faulty - free regime ( @xmath36 )",
    "the entropy is positive at any temperature while the free energy vanishes at zero temperature since there are perfect subsets . in this regime",
    "the replica symmetric ( rs ) approximation is indeed a very good approximation ( if not exact ) at any temperature .",
    "the critical point @xmath37 coincides with the cancellation of the entropy at zero temperature , because there are no more perfect subsets .",
    "however for @xmath18 there exists a critical temperature @xmath38 , called freezing temperature , below which rs is broken ( the entropy becomes negative ) .",
    "a one - step replica symmetry breaking ( rsb ) calculation reveals that for @xmath39 the rs entropy becomes zero while the rs internal energy ( fraction of errors ) freezes to its value at @xmath38 for @xmath39 .",
    "starting from the expression ( [ free_energy ] ) and following standard procedures @xcite we write the free energy as @xmath40 where we have used the replica approach based on the equivalence @xmath41 , consisting in substituting the logarithm appearing in the equation ( [ free_energy ] ) by an object much easier to average over the disorder .",
    "the @xmath42-th power in the partition function indicates that the same system has been replicated @xmath42 times , thus the name of replica .",
    "after some straightforward manipulations , the replicated and averaged partition function becomes @xmath43e^{n(g_1+g_2+g_3)}\\ , , \\label { replicated_average_numberofsol}\\ ] ] where we have defined the following macroscopic order parameters @xmath44 and with the functions @xmath45 , @xmath46 and @xmath47 given by @xmath48\\exp\\left(i\\sum_{\\alpha=1}^n\\widehat{h}_\\alpha h_\\alpha+im\\sum_{\\alpha=1}^n\\widehat{h}_\\alpha m_\\alpha\\nonumber\\right.\\\\ & & \\left.-\\frac{1}{2}\\sum_{\\alpha,\\beta=1}^n\\widehat{h}_\\alpha \\widehat{h}_\\beta q_{\\alpha\\beta}\\right)\\prod_{\\alpha=1}^n\\left[e^{-\\beta}+(1-e^{-\\beta})\\theta\\left(h_\\alpha-\\kappa\\right)\\right]\\label { g2}\\\\ g_3&=&\\log\\sum_{\\{\\sigma^\\alpha\\}}\\exp\\left(-\\frac{1}{2}\\sum_{\\alpha,\\beta=1}^n\\widehat{q}_{\\alpha\\beta}\\sigma^\\alpha\\sigma^\\beta\\right)\\label { g3}\\,.\\end{aligned}\\ ] ] in the thermodynamic limit ( @xmath4 , @xmath49 at fixed @xmath50 ) the expression ( [ replicated_average_numberofsol ] ) is evaluated by the steepest descent method and the free energy @xmath31 simply reads @xmath51 within the rs ansatz the overlap parameters with two replica indexes are assumed to be invariant under the interchange of all replica indexes .",
    "we then write @xmath52 evaluation of the free energy @xmath53 and the entropy @xmath54 in the rs ansatz gives @xmath55 \\label { free_energy_rs}\\end{aligned}\\ ] ] and @xmath56 with @xmath57 and @xmath58 , @xmath59 being the complementary of the error function .",
    "the previous free energy ( [ free_energy_rs ] ) must be stationary with respect to @xmath60 .",
    "for the constraint model , stationary with respect to @xmath61 must not be imposed , and @xmath61 becomes a parameter that controls the relative size of the subset .",
    "the saddle - point equations read @xmath62 with @xmath63}{\\sqrt{2\\pi(m - q)^3}}e^{-\\frac{(\\kappa+mm+t\\sqrt{q})^2}{2(m - q)}}\\label { h , m}\\\\ h_{,q}\\left(\\frac{\\kappa+mm+t\\sqrt{q}}{\\sqrt{m - q}}\\right)&=&-\\frac{1}{2}\\frac{[tm+\\sqrt{q}(\\kappa+mm)]}{\\sqrt{2\\pi q(m - q)^3}}e^{-\\frac{(\\kappa+mm+t\\sqrt{q})^2}{2(m - q)}}\\label { h , q}\\,\\,.\\end{aligned}\\ ] ] we remark that equation ( [ fe3 ] ) is not present in the constraint case .",
    "we will now study the different regimes .      at zero temperature",
    "the fraction of errors @xmath64 becomes zero in this regime , while the entropy @xmath65 is different from zero indicating that there exists perfect subsets .",
    "we have solved the saddle - point equations ( [ fe1])- ( [ fe4 ] ) numerically at zero temperature ( analytically this limit is calculated trivially ) and for different values of the parameters @xmath66 .     versus @xmath67 .",
    "left panel : @xmath24 and @xmath68 @xmath24 a@xmath69 ( left to right ) .",
    "right panel @xmath70 and @xmath71 and @xmath69 ( left to right).,scaledwidth=70.0%,scaledwidth=40.0% ]    at @xmath72 the entropy is simply @xmath73 , that is , there are @xmath16 perfect combinations .",
    "when @xmath67 increases , the relative number of inequalities ( [ condition ] ) increases and the number of perfect subsets decreases accordingly , diminishing the entropy as well . note that as long as the entropy is finite , there is still an exponential number of perfect combinations .",
    "this behavior appears in figure [ fig : unconstraint_anyalpha ] where we have plotted the entropy against @xmath67 for different values of @xmath74 and @xmath23 for the unconstraint case ( the constraint case presents a similar behavior ) .",
    "we have also plotted how the typical size @xmath61 varies with @xmath67 .",
    "it presents typically a monotonic behavior depending on the value of @xmath74 , but there is an interval where @xmath61 is non - monotonic ( see inset in figure [ fig : m_unconstraint_anyalpha ] ) .     versus @xmath67 for @xmath24 and @xmath75 and @xmath76 ( bottom to top ) . in the inset the case @xmath77.,scaledwidth=50.0%,scaledwidth=40.0% ]",
    "a nave explanation of this monotonic behavior would be as follows : let us first assume that with the same probability we may find defects or not ( @xmath78 ) . at @xmath72 , there are no constraints , hence all combinations have the same probability to be perfect and therefore @xmath79 .",
    "as @xmath67 increases it becomes more difficult to find perfect subsets and larger subsets are less likely to satisfy the majority vote .",
    "consequently , the average size @xmath61 is reduced as @xmath67 increases .",
    "now for fixed @xmath67 and as @xmath74 increases there are more defects and the large subsets are even less likely to satisfy the set of constraints ( [ condition ] ) and consequently the average size @xmath61 becomes more reduced . for negative @xmath74 the opposite effect",
    "is observed for obvious reasons .      from figure",
    "[ fig : unconstraint_anyalpha ] we see that the critical point is reached when the entropy becomes zero , _",
    "i.e. _ there exists no more perfect subsets but one .     versus biased parameter @xmath74 for different values of the threshold @xmath81 and @xmath82 ( from top to bottom).right panel : the typical critical size @xmath83 of the subset as a function of @xmath74 for different values of the threshold @xmath81 and @xmath82 ( from bottom to top).,title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ] versus biased parameter @xmath74 for different values of the threshold @xmath81 and @xmath82 ( from top to bottom).right panel : the typical critical size @xmath83 of the subset as a function of @xmath74 for different values of the threshold @xmath81 and @xmath82 ( from bottom to top).,title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ]    we also studied the behavior of the system at @xmath80 .",
    "the zero entropy condition ( at zero temperature ) gives the following equation for @xmath37 @xmath84\\\\ & & \\times\\left[\\int dt\\log h\\left(\\frac{\\kappa+mm+t\\sqrt{q}}{\\sqrt{m - q}}\\right)\\right]^{-1}\\label { sp5}\\,\\,.\\end{aligned}\\ ] ] adding this to the previous saddle - point equations ( [ fe1])- ( [ fe4 ] ) and solving them numerically allows the study of the critical behavior for both the unconstraint and constraint case .",
    "figure [ fig : unconstraintze ] reports @xmath37 for the unconstraint case and figure [ fig : constraintze ] for the constraint one .",
    "this figure can be used in principle in order to determine @xmath4 in order to be in the fault - free phase , since @xmath0 is given by the component and @xmath74 by the manufacturing process .     versus relative size @xmath61 for @xmath24 and for @xmath85 and @xmath86 ( top to bottom ) .",
    "right panel : @xmath37 versus relative size @xmath61 for @xmath78 and for @xmath81 and @xmath82 ( top to bottom),title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ]   versus relative size @xmath61 for @xmath24 and for @xmath85 and @xmath86 ( top to bottom ) .",
    "right panel : @xmath37 versus relative size @xmath61 for @xmath78 and for @xmath81 and @xmath82 ( top to bottom),title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ]      in this regime the entropy decreases with the temperature until @xmath39 where it becomes zero , with @xmath38 the freezing temperature .",
    "the fraction of errors is held constant in this interval , _",
    "i.e. _ @xmath87 .",
    "the freezing temperature @xmath38 is therefore given by the zero entropy condition @xmath88 and the fraction of errors @xmath31 then reads @xmath89 adding then this condition to the saddle - point equations ( [ fe1])- ( [ fe4 ] ) fixes the temperature to @xmath38 and their numerical solution allows to evaluate the expression ( [ fraction_of_errors ] ) for the fraction of faulty functions .",
    "notice that for @xmath80 the freezing temperature @xmath90 and therefore @xmath91 .",
    "figure [ fig : error_unconstraint ] shows the fractions of errors @xmath64 versus @xmath67 for different values of @xmath23 and @xmath74 , while in figure [ fig : error_constraint ] we have fixed @xmath67 and plotted the fraction of faulty functions against the subset size @xmath61 .     as a function of @xmath67 for @xmath92 and @xmath93 and @xmath94 ( right to left ) .",
    "right panel : fraction of faulty functions @xmath31 as a function of @xmath67 for @xmath95 and @xmath96 and @xmath97 ( right to left).,title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ]   as a function of @xmath67 for @xmath92 and @xmath93 and @xmath94 ( right to left ) .",
    "right panel : fraction of faulty functions @xmath31 as a function of @xmath67 for @xmath95 and @xmath96 and @xmath97 ( right to left).,title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ]     as a function of @xmath61 for @xmath92 , @xmath98 and @xmath93 and @xmath94 ( bottom to top).,scaledwidth=50.0%,scaledwidth=40.0% ]",
    "versus @xmath74 . theoretical results ( continuous line ) , upper bound @xmath99 ( down triangles ) and lower bound @xmath100 ( up triangles ) ; @xmath101 , average over @xmath102 samples .",
    "inset : finite - size analysis of @xmath99 ( solid down triangles ) and @xmath100 ( up triangles ) as a function of @xmath4 and for @xmath78 ; average over @xmath102 samples.,scaledwidth=50.0%,scaledwidth=40.0% ]    we carried out extensive numerical simulations in order to check the above theoretical results .",
    "as in many similar neural network models , finite size effects are problematic in the binary dcp @xcite .",
    "figure [ fig : alphac_vs_m ] plots @xmath37 versus @xmath74 both for theoretical results , and numerical simulations .",
    "fixing @xmath4 at 20 , we enumerated all the combinations of components : starting with @xmath103 we added patterns , i.e. increased @xmath0 , increasing thereby the set of disorder until @xmath104 for which no perfect combination can be found .",
    "the estimate of the critical point @xmath105 is @xmath106 , which gives lower and upper bounds for @xmath37 , noted @xmath107 and @xmath108 respectively .",
    "the agreement between theory and simulations is qualitatively good as long as @xmath74 does not take large negative values .",
    "we checked that the discrepancy between the numerical simulations and the theory is probably a finite size effect ( see inset of figure [ fig : alphac_vs_m ] for @xmath78 ) : fitting @xmath109 first without imposing any asymptotic value @xmath110 , i.e. with @xmath111 yields @xmath112 with errors of @xmath113 , @xmath114 and @xmath115 respectively .",
    "the error on @xmath116 is very large , while that on @xmath117 gives a surprisingly precise estimate of the theoretical value @xmath118 .",
    "fitting our data with @xmath119 gives @xmath120 with much smaller errors of @xmath121 and @xmath122 respectively .",
    "the lower bound @xmath123 barely increases with @xmath4 and stays at around 0.55 .. many other quantities have the same kind of finite size scaling as @xmath124 , as , for instance , the fraction of used components @xmath83 at @xmath37 ( figure [ fig : mc_vs_m ] ) and the fraction of faulty functions @xmath31 in the optimal combination ( figure [ fig : f_vs_alpha ] ) .",
    "a notable exception is that of the fraction of faulty functions in the constrained case .",
    "the integer nature of the problem causes notable variations depending on @xmath61 and @xmath4 . despite relatively large finite size effects ,",
    "the numerical simulations confirm the validity of the theory .     of used components in the optimal combination at @xmath37 .",
    "@xmath101 , average over 10000 samples .",
    "inset : finite - size analysis of @xmath83 for @xmath78 ; average over @xmath102 samples.,scaledwidth=50.0%,scaledwidth=40.0% ]     of working functions as a function of @xmath67 .",
    "@xmath101 , average over 10000 samples .",
    "inset : finite - size analysis of @xmath31 at @xmath125 ; average over @xmath102 samples.,scaledwidth=50.0%,scaledwidth=40.0% ]",
    "the dcp studied above is static in nature , and does not address the whole complexity of component recycling , as in real life manufacturers produce a flux of faulty devices . how to recycle a flux is therefore a relevant problem .",
    "let us start with some simple theoretical considerations .",
    "the central quantity of interest is the average quality of the components in the optimal combination ( whose sense will be defined below ) , defined as the fraction of working functions of the components included in a combination @xmath21 , i.e. @xmath126 note that equation ( [ condition ] ) implies that the quality of a working combination is always greater than @xmath127 if @xmath23 is fixed to 0 .",
    "let us assume that we have @xmath128 components initially and that @xmath128 and @xmath23 are fixed so as to be in the fault - free region ( @xmath36 ) . in the following , we shall neglect fluctuations .",
    "the typical fraction of working functions is @xmath129 .",
    "if we now remove the optimal subset @xmath130 with , on average , @xmath131 components of quality @xmath132 , we have a new ensemble of @xmath133 components with quality @xmath134 if new @xmath135 fresh components taken from the flux of imperfect components are added , one has instead that the next iteration has @xmath136 components with @xmath137 and @xmath138 generalizing this equation to the @xmath42-th step yields @xmath139 and @xmath140 flux recycling requires that the trajectory of @xmath141 and @xmath142 stays in the fault - free region .",
    "the flux problem can be solved at constant @xmath143 , that is , @xmath144 , in which case eq ( [ w_n+1 ] ) becomes @xmath145     in the set of imperfect components ( red line ) and quality @xmath146 of the optimal perfect combination ( left graph : black line ; right graph : circles ) in dynamical flux recycling for @xmath147 , @xmath148 and @xmath149 ( left graph ) and @xmath78 ( right graph).,title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ] in the set of imperfect components ( red line ) and quality @xmath146 of the optimal perfect combination ( left graph : black line ; right graph : circles ) in dynamical flux recycling for @xmath147 , @xmath148 and @xmath149 ( left graph ) and @xmath78 ( right graph).,title=\"fig:\",scaledwidth=40.0%,scaledwidth=40.0% ]    whereas @xmath150 .",
    "we propose two main ingredients .",
    "first of all , in the faulty - free region , there is an exponentially large number of perfect combinations ; which one is it best to select ? in a static view ,",
    "the one with the least number of components is the most economical .",
    "however , as suggested by equation ( [ w_n+1_ncst ] ) , @xmath151 should be minimized so as to make more probable that @xmath152 does not decrease as a function of time , which would inevitably lead the system out of the faulty - free region . therefore , we define the optimal perfect combination as the one with the smallest @xmath146 .",
    "a remarkable consequence of this choice is that this actually _ increases _ @xmath142 beyond @xmath153 , as expected from the above discussion , and hence ensures that a perfect combination is found at each time step if @xmath154 is sufficiently far from @xmath37 ( see figure [ fig : qw_vs_n - m-1.5 ] ) .",
    "note as well that _ no component is wasted _",
    ", hence the efficiency of this recycling scheme is 100% .",
    "if @xmath67 is smaller but close to @xmath37 , @xmath23 can be adjusted dynamically ( i.e. lowered if needed ) to compensate for adverse fluctuations of @xmath142 .    when @xmath67 is either close or above @xmath37 and @xmath155 and @xmath23",
    "are kept constant , a new ingredient is needed . if no perfect combination is found , a simple but effective idea is to replace the worst component by a fresh one , until a perfect combination can be found .",
    "this keeps the recycling process going on forever , and makes it possible even for @xmath18 .",
    "the price to pay is that some of the worst components will be wasted .",
    "interestingly , the value of @xmath142 such that perfect combinations with average quality @xmath146 can be found is entirely determined by @xmath67 , i.e. independent from @xmath74 .",
    "if we start at @xmath18 , eliminating the worst components increases @xmath156 until @xmath157 ( see figure [ fig : qw_vs_n - m-1.5 ] ) .",
    "note however that @xmath18 can usually be avoided by lowering @xmath23 , unless the manufacturing process is really poor .",
    "figure [ fig : alpha_vs_k ] shows what @xmath23 to choose for given @xmath67 and @xmath74 .",
    "( continuous line ) , @xmath158 ( dashed line ) and @xmath159 ( dot - dashed line),scaledwidth=40.0%,scaledwidth=40.0% ]",
    "in this paper we have solved the binary dcp at one - step of rsb .",
    "the system is characterized by a phase transition similar to random energy model @xcite or the gardner capacity problem with ising couplings @xcite from a faulty - free regime with an exponential number of perfect subsets to an imperfect regime where no perfect combinations are available .",
    "we have contrasted our analytical findings with extensive numerical simulations based on exact enumeration .",
    "even though they present strong finite size effects as in other models @xcite , they show the validity of the theory qualitatively , but we can not rule out that in some regions further steps in the rsb are needed .    we have also addressed the dynamic problem of flux recycling and have proposed efficient methods that lead to no wastage at all .",
    "the authors thank the abdus salam ictp for hospitally during the starting stages of this work . dc",
    "thanks wadham college for support .",
    "ipc thanks the fund for scientific research - flanders , belgium for financial support and r. heylen for a careful reading of the manuscript .",
    "100 johnson b w , _ design and analysis of fault tolerant digital systems _ , addison - wesley , new york , 1989 ; kandellakis p ch and shvartsman a a , _ fault - tolerant parallel computation _ , kluwer , boston , 1997 ; siewiorek d p and swarz r s , _ reliable computer systems _ , digital press , burlington , 1992 ."
  ],
  "abstract_text": [
    "<S> the binary defect combination problem consists in finding a fully working subset from a given ensemble of imperfect binary components . </S>",
    "<S> we determine the typical properties of the model using methods of statistical mechanics , in particular , the region in the parameter space where there is almost surely at least one fully - working subset . </S>",
    "<S> dynamic recycling of a flux of imperfect binary components leads to zero wastage . </S>"
  ]
}