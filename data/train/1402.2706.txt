{
  "article_text": [
    "scientific studies are often evaluated by correcting for multiple comparisons .",
    "several methods published in the literature are used to correct for multiple tests , for instance the @xcite correction or the @xcite procedure .",
    "often , for instance in studies involving biological data , p - values can not be computed analytically .",
    "they are approximated using monte carlo tests such as permutation tests or bootstrap tests @xcite .",
    "permutation tests are widely used in practice as underlying models for biological phenomena are rarely known .",
    "the evaluation of multiple hypotheses by applying a multiple testing procedure to monte carlo based p - value estimates is the focus of this article .",
    "we are interested in evaluating multiple hypotheses using monte carlo samples while ensuring the reproducibility and objectivity of all findings .",
    "@xcite called this the _ first law of applied statistics _ : `` two individuals using the same statistical method on the same data should arrive at the same conclusion . ''",
    "we measure this reproducibility in the following way .",
    "we generate a set of fixed p - values for all hypotheses as underlying truth and consider methods approximating the p - value of each hypothesis using independent monte carlo samples under the null .",
    "using the approximated p - values , we aim to reproduce the test result obtained by applying a multiple testing correction to the fixed p - values .",
    "we are interested in minimising the number of _ switched classifications _ , that is the number of decisions of individual hypotheses based on estimates which differ from the ones obtained with the fixed p - values .",
    "algorithms achieving a low number of switched classifications lead to consistent results even when applied repeatedly and thus ensure reproducibility of their decisions , a feature desired in practice . moreover , we aim to achieve a high power in multiple testing in order to obtain meaningful test results , especially for low computational effort . the algorithm developed in this article outperforms many existing methods in both regards .",
    "a simple and widely used method to implement a multiplicity correction in the aforementioned scenario is to draw a constant number of samples per hypothesis , approximate all p - values using a conservative p - value estimator and finally use these estimates as input for the multiple testing procedure , thus treating them as if they were the p - values @xcite .",
    "the naive approach does not take into account that hypotheses whose p - values clearly lie in the rejection or non - rejection area of the multiple testing procedure should be allocated less samples than hypotheses whose p - values are closer to the testing threshold and whose decision is thus more difficult to compute .",
    "this leaves considerable scope to improve upon the accuracy of the naive method .",
    "we introduce a sampling algorithm based on thompson sampling @xcite to compute decisions on multiple hypotheses .",
    "our approach , called ` quickmmctest ` , uses a beta - binomial model on each p - value to adaptively decide which hypotheses need to receive more and which need less samples to obtain fairly clear decisions ( rejections and non - rejections ) on all tests .",
    "it avoids computing discrete p - value estimates at any stage , thus circumventing imprecisions observed in methods using such discrete estimates .",
    "the algorithm works with a variety of commonly used multiple testing procedures at both constant testing thresholds as well as variable testing thresholds , that is thresholds which are functionals of the unknown p - values underlying the tests .",
    "the article is organised as follows .",
    "section [ section_thompson ] introduces the set - up we consider and presents ` quickmmctest ` . in section [ section_example ]",
    "we discuss a real - data application using gene expression data .",
    "we show that rejections computed with existing methods can lead to high uncertainty concerning the significance of individual hypotheses .    a simulation study ( section [ section_simulation_study ] ) demonstrates that in comparison to the naive approach , ` quickmmctest ` yields considerably less switched classifications for popular multiple testing procedures @xcite .    as highlighted in a second simulation study ( included in section [ subsection_simulation_methods_constant_threshold ] )",
    ", the main advantage of ` quickmmctest ` in comparison to existing methods @xcite is its better finite sample behaviour , thus achieving the same accuracy with less computational effort .",
    "however , in contrast to ` mmctest ` of @xcite , it does not provide any guarantees on the correctness of its results .",
    "section [ subsection_simulation_power ] conducts power studies .",
    "we show for selected multiple testing procedures that ` quickmmctest ` yields a higher power than the naive method and than the aforementioned existing methods , especially for low sample sizes .",
    "we conclude with a discussion in section [ section_thompson_discussion ] .",
    "supplementary material is available for this article which contains further simulation studies for a variable testing threshold as well as an assessment of the dependence of ` quickmmctest ` on its parameters .",
    "the ` quickmmctest ` algorithm is implemented in an @xmath0 package ( ` simctest ` , available on cran , the comprehensive r archive network ) .",
    "we would like to test @xmath1 hypotheses @xmath2 for statistical significance , for each of which we have a statistical test ( and some data ) available .",
    "the hypotheses are evaluated using a multiple testing procedure given by a mapping @xcite @xmath3^m \\times [ 0,1 ] \\rightarrow \\mathcal{p}(\\ { 1,\\ldots , m \\})\\end{aligned}\\ ] ] which takes a vector of @xmath1 p - values @xmath4^m$ ] and a threshold @xmath5 $ ] and returns the set of indices of hypotheses to be rejected , where @xmath6 denotes the power set . amongst others ,",
    "the procedures of @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite as well as @xcite fit into this framework .",
    "we assume that the p - values @xmath7 of the tests for @xmath2 are not available analytically .",
    "instead , we assume that it is possible to draw samples under each null hypothesis . for each of the samples",
    ", we can compute the test statistic and compare it to the observed test statistic , thus enabling us to approximate the p - values .",
    "we denote the total number of samples drawn for @xmath8 by @xmath9 and the total number of exceedances of the sampled test statistic over the observed test statistic among these @xmath9 samples by @xmath10 , where @xmath11 .",
    "moreover , the threshold @xmath12 is allowed to either be constant @xmath13 or a functional @xmath14 of the p - values @xmath15 . in the latter case , @xmath16 is itself unknown .",
    "` quickmmctest ` ( algorithm [ algorithm_quickmmctest ] ) is based on an idea related to thompson sampling @xcite and updates a beta - binomial model for each p - value in each iteration .    starting with a beta@xmath17 prior on each p - value , observing @xmath10 exceedances among @xmath9 samples results in a beta@xmath18 posterior . in each iteration of the algorithm",
    ", all @xmath1 p - values are resampled from the posterior distributions , the multiple testing procedure is evaluated on the @xmath1 resampled p - values and the decision of each hypothesis is recorded .",
    "repeating the above a fixed number of @xmath0 times allows to compute an empirical probability that each @xmath8 , @xmath11 , is rejected ( @xmath19 ) and non - rejected ( @xmath20 ) .",
    "the quantity @xmath21 can then be viewed as a stability measure for the current decision on @xmath8 , where @xmath11 .",
    "we weight rejections and non - rejections equally when computing the weights @xmath22 in line @xmath23 of algorithm [ algorithm_quickmmctest ] .",
    "however , one might be interested in weighting the rejections @xmath24 and non - rejections @xmath25 differently and incorporate this into the computation of the weights .    `",
    "quickmmctest ` sequentially draws samples for all hypotheses .",
    "the number of further samples drawn for each @xmath8 is proportional to @xmath22 in each iteration , where @xmath11 .",
    "this ensures that hypotheses already having a very stable decision only receive few new samples .    `",
    "quickmmctest ` has two parameters chosen by the user , the total number of samples @xmath26 the algorithm is allowed to spend and the total number of iterations @xmath27 ( and thus the number of posterior updates ) .",
    "these two parameters determine @xmath28 , the number of samples allocated in each iteration .",
    "alternative approaches in which @xmath29 varies over time are possible .",
    "@xmath30 , @xmath31 , @xmath32 for all @xmath11    ` quickmmctest ` uses residual sampling @xcite to guarantee a deterministic minimal allocation of samples to each hypothesis .",
    "after normalising the weights @xmath22 , we first draw @xmath33 samples for each @xmath8 , @xmath11 .",
    "the remaining @xmath34 samples are then allocated one sample at a time with weights proportional to @xmath35 .",
    "alternatively , one could replace the residual sampling by simple multinomial sampling or other methods used in , for instance , particle filters .",
    "calculating the weights is computationally fast as it only requires @xmath0 draws from each of the @xmath1 beta distributions as opposed to drawing samples from the data ( for instance via permutations which can be costly ) .",
    "decisions on all hypotheses can be obtained in various ways with ` quickmmctest ` .",
    "naively , one could compute @xmath36 , where @xmath37 is a vector of estimates @xmath38 , @xmath11 , computed with a pseudo - count @xcite .    we do not consider unbiased p - value estimates @xmath39 , @xmath11 , computed without a pseudo - count as such estimates lead to tests not keeping the prescribed error level @xcite .    a more sophisticated approach to obtain final rejections and non - rejections is to recompute decisions on all hypotheses @xmath0 times using draws from the final beta posteriors after termination of algorithm [ algorithm_quickmmctest ] . recording the number of rejections @xmath24 per hypothesis allows to compute empirical rejection probabilities as done for the computation of the weights @xmath22 in lines @xmath40 to @xmath41 of algorithm [ algorithm_quickmmctest ] , where @xmath11 .",
    "each hypothesis @xmath8 , @xmath11 , is rejected if and only if @xmath42 , that is if @xmath8 was predominantly rejected based on resampled p - values . the cutoff of @xmath43 is arbitrary and can be replaced by higher ( lower ) values to make ` quickmmctest ` more ( less ) conservative .",
    "we recommend computing decisions for all hypotheses using the latter approach based on empirical rejection probabilities as such test results contain less switched classifications and hence ensure a higher degree of reproducibility than the ones based on p - value estimates .",
    "we demonstrate this in section @xmath44 of the supplementary material . moreover , ` quickmmctest ` with empirical rejection probabilities has a higher power than its variant with point estimates ( section @xmath45 of the supplementary material ) .    in the simulation studies of section [ section_simulation_study ] we employ ` quickmmctest ` with parameters @xmath46 and @xmath47 and",
    "determine decisions on all hypotheses using empirical rejection probabilities computed with a cutoff of @xmath43 . in sections",
    "@xmath48 and @xmath49 of the supplementary material we investigate the choice of these parameters , showing that there is no strong case to increase @xmath27 and @xmath0 further as it does not considerably improve performance .    for an example run on",
    "generated p - values , section @xmath50 of the supplementary material visualises how the sample allocation computed by ` quickmmctest ` compares to the p - values and the testing threshold .",
    "for each hypothesis ordered by the rank of their p - value @xmath51from outside to inside : naive method with @xmath52 permutations @xmath53 and @xmath54 permutations @xmath55 per hypothesis , ` quickmmctest ` with total effort @xmath56 @xmath57 and @xmath58 @xmath59 .",
    "top shows all hypotheses , bottom shows a zoomed - in region around the last significant hypothesis occuring at rank @xmath60.,scaledwidth=50.0% ]    we consider the evaluation of @xmath61 genes using real gene expression data from yeast chemostat cultivations @xcite .    for each gene",
    ", this dataset contains @xmath62 microarrays of yeast cultivations , divided into two classes : aerobically grown yeast and anaerobically grown yeast . as suggested in @xcite , the sam statistic ( significance analysis of microarrays ) of @xcite is used as the test statistic in connection with a permutation test .",
    "further details on the statistic are included in section @xmath40 of the supplementary material .",
    "for each gene , we identify one null hypothesis as the one expressing no difference in response between the two groups of aerobically and anaerobically grown yeast .",
    "we are interested in the probability of a random decision , meaning the probability that a single hypothesis switches between being significant and non - significant in repeated test results . for this",
    ", we generated both @xmath52 (  low effort  ) and @xmath54 (  high effort  ) permutations per hypothesis , approximated its p - value with a pseudo - count in both the numerator and denominator ( the precise estimate is given in section @xmath63 of the supplementary material ) and then tested all hypotheses by applying the @xcite procedure with threshold @xmath64 .",
    "this was repeated @xmath65 times . as done in section [ subsection_quickmmctest_algorithm ]",
    "we quantify the uncertainty in these @xmath66 test results by computing empirical probabilities @xmath67 ( @xmath68 ) that hypothesis @xmath69 is rejected ( non - rejected ) among the @xmath66 repetitions .",
    "we define @xmath70 $ ] as the probability of a random decision .",
    "we repeat this experiment with ` quickmmctest ` on the same dataset an equal number of times and compute probabilities of a random decision . to ensure a fair comparison , we allow at most the same total number of samples the naive method had used , thus @xmath56 for low effort and @xmath58 for high effort , where @xmath1 is the number of hypotheses .",
    "figure [ fig : intro ] displays the probabilities @xmath71 of a random decision for the entire range of genes ( top ) in the @xcite dataset as well as for a zoomed - in region around the last significant hypothesis ( bottom ) occuring at rank @xmath60 .",
    "these curves correspond to the following methods ( from outside to inside ) : the naive method with @xmath52 permutations @xmath53 and @xmath54 permutations @xmath55 per gene as well as the ` quickmmctest ` algorithm with a total effort @xmath56 @xmath57 and @xmath58 @xmath72 .",
    "hypotheses are ordered according to the rank of their p - value estimate computed with @xmath54 permutations . due to the finite computational effort the ordering of the hypotheses exhibits a certain noise .",
    "figure [ fig : intro ] ( bottom ) shows that ` quickmmctest ` yields test results at a low effort ( @xmath56 ) which are considerably more stable and contain less random decisions than the ones of the naive method over the entire range of hypotheses  even when compared to the naive method at a high effort ( @xmath54 permutations per hypothesis ) .",
    "we evaluate ` quickmmctest ` on a simulated dataset in three ways .",
    "first , the performance of ` quickmmctest ` is compared to the one of the naive method using a variety of commonly used multiple testing procedures at a constant testing threshold ( section [ subsection_simulation_study_naive ] ) .",
    "second , we fix the procedures of @xcite and @xcite as multiple testing procedures and compare ` quickmmctest ` to a variety of common methods published in the literature ( section [ subsection_simulation_methods_constant_threshold ] ) .",
    "third , we conduct power studies for ` quickmmctest ` and the naive method for selected multiple testing procedures , showing that ` quickmmctest ` yields a higher power even for low samples sizes .      in order to be able to compute numbers of switched classifications we need to simulate exceedances of the sampled test statistic over the observed test statistic . for this",
    "it suffices to fix a set of p - values and simulate exceedances for the tests by sampling independent bernoulli random variables with success probability being equal to the p - value of each test .    in sections [ subsection_simulation_study_naive ] and [ subsection_simulation_methods_constant_threshold ] we use one fixed set of @xmath73 p - values .",
    "these p - values are independent realisations from a mixture distribution with a proportion @xmath74 coming from a uniform@xmath75 $ ] distribution and the remaining proportion @xmath64 coming from a beta@xmath76 distribution . a large proportion of p - values coming from the null",
    "would also be expected in practice .",
    "this model was used in @xcite .",
    "comparing the test result returned by any algorithm to the result obtained by applying the multiple testing procedure to the fixed set of @xmath1 p - values allows to compute numbers of switched classifications ( see section [ subsection_setting ] ) with respect to the fixed p - values .    in section [ subsection_simulation_power ] , in each repetition of the experiment , we draw @xmath1 bernoulli random variables with probability @xmath64 .",
    "these random variables serve as indicators for the falseness of the null hypothesis .",
    "we then draw the p - value for each false null hypothesis from a beta@xmath76 distribution , and all remaining p - values from a uniform distribution in @xmath75 $ ] . comparing the decisions on all hypotheses computed by any algorithm to the falseness indicators",
    "thus allows to compute averages of type i error and power . in our multiple testing setting",
    ", we compute the _ per - pair power _ , defined as the average probability of rejecting a false null hypothesis .",
    "all results are based on @xmath52 repetitions .",
    "the error of the simulations is less than the least significant digit we report in the tables presented in this section .",
    "[ cols= \" > , > , > , > , > \" , ]     for a low effort , table [ tab : comparison_methods_fixed_threshold ] demonstrates that due to the very low threshold of the @xcite correction , all methods except for ` quickmmctest ` are unable to compute p - value estimates with a resolution sufficient to detect any rejections .",
    "they are thus unable to compute meaningful decisions , leading to switched classification numbers equal to the @xmath77 rejections observed when applying the @xcite correction to the fixed p - values .",
    "` quickmmctest ` does not suffer from this problem and yields roughly @xmath78 ( out of @xmath73 ) switched classifications with a very low number of false findings . if the computation of weights in ` quickmmctest ` was replaced by alternative approaches relying on discrete p - value estimates , ` quickmmctest ` would be susceptible again to not being able to record any rejections like the other methods considered in table [ tab : comparison_methods_fixed_threshold ] .    at a high effort",
    ", most methods compute acceptable test results with around @xmath50 switched classifications with the exception of the naive method which is still unable to detect any rejections . `",
    "quickmmctest ` yields a slightly lower average of switched classifications than the other methods .",
    "table [ tab : comparison_methods_fixed_threshold_bh ] repeats the previous comparison using the @xcite procedure controlling the false discovery rate .",
    "due to the less conservative nature of the @xcite procedure , all methods are able to compute meaningful test results at both a low and a high effort .",
    "the naive method and the one of @xcite perform poorly in this new scenario .",
    "the method of @xcite performs very well and is only outperformed by ` quickmmctest ` at a low effort ( yielding half as many switched classifications as @xcite and a multiple fold decrease compared to all other methods ) . at a high effort , @xcite perform comparably to ` quickmmctest ` .",
    "these results are again consistent for a variable testing threshold as demonstrated in section @xmath23 in the supplementary material ( using the threshold of @xcite , see section [ subsection_simulation_study_naive ] ) .",
    "the similar performance of the algorithms of @xcite , @xcite as well as ` quickmmctest ` is not a coincidence .",
    "both @xcite as well as @xcite use a monotonicity property of step - up and step - down procedures of @xcite to stop the sampling process for certain hypotheses in order to allocate the remaining samples equally to hypotheses whose decisions are computationally more demanding to compute .",
    "neither of them uses any weights to fine - tune this equal allocation .    `",
    "quickmmctest ` is able to both concentrate available samples on hypotheses whose decisions are harder to compute as well as to fine - tune this allocation to individual hypotheses using weights , a feature which yields another improvement in accuracy compared to the other two methods .",
    "we compare the power of ` quickmmctest ` to the one of the naive method and selected algorithms used in section [ subsection_simulation_methods_constant_threshold ] as a function of the number of samples per hypothesis . for this",
    "we use the simulation setting described in section [ subsection_simulation_setting ] . as in section [ subsection_simulation_study_naive ] , ` quickmmctest ` is applied with a matched total effort .",
    "figure [ fig : power_b_ss ] shows the average ( per - pair ) power of both the naive method and ` quickmmctest ` as a function of the number of samples . as seen previously in table [ tab : comparison_methods_fixed_threshold ] , due to the very low threshold of the @xcite correction , the naive method is not able to detect any rejections even for large numbers of samples ( left plot in figure [ fig : power_b_ss ] ) .",
    "its power is therefore zero . `",
    "quickmmctest ` initally suffers from the same problem , but is able to gain power when using an effort equivalent to @xmath79 samples per hypothesis onwards . for the less conservative @xcite procedure ( right plot in figure [ fig : power_b_ss ] ) , the naive method gains power from @xmath80 samples per hypothesis onwards . `",
    "quickmmctest ` achieves the same power as the naive method a lot faster with less samples : for instance , the power of ` quickmmctest ` with @xmath81 samples per hypothesis is comparable to the one of the naive method with @xmath52 samples .",
    "figure [ fig : power_methods ] repeats the power study for two fixed multiple testing procedures and compares ` quickmmctest ` to four selected existing methods already considered in section [ subsection_simulation_methods_constant_threshold ] .    figure [ fig : power_methods ] ( left ) shows that for the @xcite correction , ` quickmmctest ` yields a much earlier incease in power for low samples sizes than the algorithms of @xcite and @xcite , which in table [ tab : comparison_methods_fixed_threshold ] both performed comparably well to ` quickmmctest ` .",
    "figure [ fig : power_methods ] ( right ) repeats this comparison for the fdr analogue of the power , precisely @xmath82__fnp _ _ , where _ fnp _ is the false non - discovery rate , defined as the proportion of false negatives among the accepted null hypotheses .",
    "the plot shows that when controlling the false discoveries using the @xcite procedure , both the algorithm of @xcite as well as ` quickmmctest ` achieve a higher power than the naive approach for low samples sizes , with a slight advantage for @xcite .    in all comparisons presented in this section",
    ", the procedures kept the familywise error rate or the false discovery proportion at the @xmath83 level , respectively .    the plots for power comparison of the naive method to `",
    "quickmmctest ` using the other multiple testing procedures considered in section [ subsection_simulation_study_naive ] are qualitatively similar to the ones in figure [ fig : power_b_ss ] .",
    "similar to the left plot in figure [ fig : power_methods ] , ` quickmmctest ` also outperforms all other methods considered in section [ subsection_simulation_methods_constant_threshold ] in terms of the per - pair power when controlling the familywise error . with the exception of @xcite , the same holds true when comparing ` quickmmctest ` to the methods considered in section [ subsection_simulation_methods_constant_threshold ] in terms of @xmath82__fnp _ _ similar to the right plot in figure [ fig : power_methods ] .",
    "all comparisons in this article use ` quickmmctest ` with empirical rejection probabilities to determine decisions .",
    "section @xmath45 of the supplementary material repeats the power studies of figures [ fig : power_b_ss ] and [ fig : power_methods ] when employing ` quickmmctest ` with both empirical rejection probabilities as well as point estimates to obtain decisions on all hypotheses after stopping .",
    "we show that empirical rejection probabilities lead to a higher power , especially for low computational effort .",
    "we considered multiple testing in a realistic scenario in which it is not possible to compute p - values analytically for all tests .",
    "instead , we assumed that it is possible to draw independent samples under the null for each hypothesis in order to approximate its p - value .",
    "our aim is to use monte carlo samples to approximate the analytical test result ( rejections and non - rejections ) , obtained if all p - values were known , as accurately as possible .",
    "this article proposed to use an idea based on @xcite sampling to efficiently allocate samples to multiple hypotheses .",
    "our iterative ` quickmmctest ` algorithm is based on this principle and adaptively allocates more samples to hypotheses whose decisions are still unstable at the expense of allocating less samples to hypotheses whose decision can easily be computed .",
    "the algorithm works for a variety of common multiple testing procedures for both a constant as well as a variable testing threshold .    `",
    "quickmmctest ` has two main features : first , it never computes any p - value estimates during its run , thus avoiding to incur consistently non - rejecting all hypotheses as observed in other methods published in the literature .",
    "second , its final decisions are based on empirical rejection probabilities instead of p - value estimates .    `",
    "quickmmctest ` was evaluated in a simulation study . by comparing its performance to both a widely used naive sampling method for a variety of commonly used multiple testing procedures as well as to a variety of algorithms published in the literature",
    ", we demonstrated that ` quickmmctest ` yields meaningful test results even at a low computational effort and up to a multiple fold decrease in the number of switched classifications at a high effort .",
    "for a low computational effort , ` quickmmctest ` yields a higher per - pair power across all methods considered in this study and , apart from the algorithm of @xcite , a lower false non - discovery proportion when employed with various multiple testing procedures .",
    "the supplementary material compares the performance of both ` quickmmctest ` variants using p - value estimates and empirical rejection probabilities .",
    "moreover , it contains further simulation studies assessing the dependence of ` quickmmctest ` on its two parameters : the number of updates @xmath27 and the parameter @xmath0 controlling the accuracy with which weights are computed .",
    "it also contains a detailed review of the sam statistic , the permutation test p - value used in section [ section_example ] and it repeats the simulation studies conducted in section [ section_simulation_study ] for the variable testing threshold of @xcite .",
    "the authors would like to thank dr theo knijnenburg for providing the yeast chemostat cultivation dataset ."
  ],
  "abstract_text": [
    "<S> multiple hypothesis testing is widely used to evaluate scientific studies involving statistical tests . however , for many of these tests , p - values are not available and are thus often approximated using monte carlo tests such as permutation tests or bootstrap tests . </S>",
    "<S> this article presents a simple algorithm based on thompson sampling to test multiple hypotheses . </S>",
    "<S> it works with arbitrary multiple testing procedures , in particular with step - up and step - down procedures . </S>",
    "<S> its main feature is to sequentially allocate monte carlo effort , generating more monte carlo samples for tests whose decisions are so far less certain . </S>",
    "<S> a simulation study demonstrates that for a low computational effort , the new approach yields a higher power and a higher degree of reproducibility of its results than previously suggested methods . </S>"
  ]
}