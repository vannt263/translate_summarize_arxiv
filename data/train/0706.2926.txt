{
  "article_text": [
    "a new era has begun in coding theory with the discovery of graphical codes  low - density parity check codes ( ldpc ) @xcite and turbo codes@xcite .",
    "these codes are special , not only because they can virtually achieve the error - free shannon limit , but mainly because a family of computationally efficient approximate decoding schemes is readily available .",
    "this family includes iterative belief propagation ( bp ) , or simply message - passing , decoding @xcite and linear programming ( lp ) decoding @xcite .    when operating at moderate noise values these decoding algorithms show performance comparable to the ideal , but computationally not feasible , maximum likelihood ( ml ) and maximum - a - posteriori decodings .",
    "however sub - optimality of the approximate decodings becomes a handicap at large snr , in the so - called error - floor regime @xcite .",
    "an error - floor typically emerges due to the low - weight fractional pseudo - codewords @xcite , or if one uses a noise space description , due to the instantons @xcite  the most probable erroneous configurations of the noise .",
    "much effort has been invested in recent years on understanding the pseudo - codewords / instantons and thus the error floor behavior of the graphical codes .",
    "also , there were a few attempts at decoding improvement .",
    "the facet - guessing ( fg ) algorithm of @xcite and the loop erasure algorithm of @xcite constitute two recent advances in this direction .",
    "let us review these * relevant prior results : *    @xmath1 lp decoding can be considered as an asymptotic , large snr , version of the bp decoding @xcite where the latter is understood as the absolute minimum of the bethe free energy @xcite .",
    "the lp decoding minimizes the linear functional of beliefs , called the energy functional , under a set of non - strict inequality and equality constraints @xcite .",
    "( one can also consider a small polytope formulation of the problem , where all constraints are non - strict inequalities . )",
    "@xmath1 the error - floor of an ldpc code is typically due to dangerous low - weight pseudo - codewords which are fractional , i.e. which are not codewords @xcite .",
    "@xmath1 the dangerous pseudo - codewords are rare and the pseudo - codeword search algorithm @xcite is an efficient heuristic for finding the troublemakers .",
    "this algorithm is based on lp decoding .",
    "@xmath1 the loop calculus of @xcite introduces the loop series , which is an explicit finite expression for the map decoding partition function in terms of loop contributions defined on the graphical representation of the respective inference / decoding problem .",
    "each loop contribution is calculated explicitly from a solution of the bp equations and it is represented as a product of terms along the loop .",
    "the lp limit of the loop calculus is well defined .",
    "@xmath1 one experimentally verifies , and otherwise conjectures , that all the dangerous pseudo - codewords are explained in terms of a small number of critical loops @xcite .",
    "typically , the respective partition function can be well approximated in terms of the bare lp / bp term and one critical term associated with a single connected critical loop .",
    "the bare term and the critical terms are comparable while all other terms in the loop series are much smaller .",
    "an efficient heuristic algorithm for finding the critical loop has been constructed .",
    "it is based on representing the loop contribution as a product of terms along the loop , each smaller than or equal to unity in absolute value , and pre - selecting elements of the critical loop to be larger than a threshold close to unity .",
    "@xmath1 bp , corrected by accounting for the critical loop , and its simplified lp version , coined the lp - erasure @xcite , are algorithms improving bp / lp . these algorithms , applied when lp / bp fails , consist of modifying bp / lp along the critical loop .",
    "thus lp - erasure modifies log - likelihoods everywhere along the critical loop ( lowering log - likelihoods in absolute value ) .",
    "it was shown experimentally ( on the example of the test @xmath0 $ ] code introduced in @xcite ) that the lp - erasure is capable of correcting all the dangerous fractal pseudo - codewords , previously found with the pseudo - codeword search algorithm @xcite .",
    "@xmath1 the facet guessing ( fg ) algorithm @xcite is a graph local improvement of the lp algorithm .",
    "it applies if lp decoding does not succeed . a non - active facet / inequality , i.e. the one with the vertex / solution lying in the strict inequality domain , is selected .",
    "the original lp problem is modified so that the selected facet is enforced to be in its active ( equality ) state .",
    "the number of non - active facets for a dangerous fractional pseudo - codeword is typically small .",
    "( it is provably small for the expander codes . )",
    "one constructs a full set of the single - facet modified lp problems ( where the number of problems is thus equal to the number of active facets ) or otherwise selects a random subset of the lp problems . running lp decoding for the set of the modified problems , one chooses solution with the lowest energy functional and calls it the outcome of the facet guessing algorithm .",
    "it was shown experimentally in @xcite that the facet guessing algorithm improves the bare lp decoding .    * results reported in this paper : *    @xmath1 we introduce the bit guessing ( bg ) algorithm , which is a simplified version of the facet guessing algorithm of @xcite , enforcing single bits to be in @xmath2 or @xmath3 state .",
    "we apply the algorithm to the set of pseudo - codewords found for the bare lp decoding of the test @xmath0 $ ] code .",
    "it was found that all the fractional dangerous pseudo - codewords are corrected by the bg algorithm .",
    "@xmath1 for each of the dangerous pseudo - codewords , we identify the set of bits where local bg leads to correct decoding and compare this set with the set of bits forming a critical loop found via the critical loop search algorithm of @xcite .",
    "the comparison shows very strong correlations between the two sets : fixing a bit from the critical loop almost always leads to correct decoding .",
    "this suggests that , since the critical loop is relatively small , it is advantageous to use the loop series and the critical loop analysis to pre - select the set of single - bit corrected lp schemes in the bg algorithm .",
    "( one will only need to consider fixing bits along the critical loop . )",
    "moreover , we consider the loop guided guessing ( lgg ) algorithm built on top of the bare lp with only one or two modified lp runs . the modified lp scheme is constructed by adding to the bare lp scheme an equality fixing the value of a randomly selected bit from the critical loop .",
    "@xmath1 we test the lgg algorithm on the set of the lp - erroneous configurations of the @xmath0 $ ] code for the additive white gaussian noise ( awgn ) channel found in the finite signal - to - noise ratios ( snr ) monte carlo simulations of @xcite .",
    "we show that the lgg algorithm greatly improves the bare lp algorithm and it also performs significantly better than the lp - erasure algorithm of @xcite .",
    "we consider a generic linear code , described by its parity check @xmath4 sparse matrix , @xmath5 , representing @xmath6 bits and @xmath7 checks . the codewords are these configurations , @xmath8 , which satisfy all the check constraints : @xmath9 , @xmath10 ( mod  @xmath11 ) .",
    "a codeword sent to the channel is polluted and the task of decoding becomes to restore the most probable pre - image of the output sequence , @xmath12 .",
    "the probability for @xmath13 to be a pre - image of @xmath14 is @xmath15 where one writes @xmath16 if @xmath17 ; @xmath18 is the normalization coefficient ( so - called partition function ) ; the kronecker symbol , @xmath19 , is unity if @xmath20 and it is zero otherwise ; and @xmath21 is the vector of log - likelihoods dependent on the output vector @xmath14 . in the case of the awgn channel with the snr ratio , @xmath22 ,",
    "the bit transition probability is @xmath23 , and the log - likelihood becomes @xmath24 .",
    "the optimal block - map ( maximum likelihood ) decoding maximizes @xmath25 over @xmath13 , @xmath26 and symbol - map operates similarly , however in terms of the marginal probability at a bit @xmath27 .",
    "one can also think formally about ml in terms of map , i.e. in terms of summation over all possible configurations of @xmath13 however with the weight and the partition function in eqs .",
    "( [ psx1],[psx ] ) transformed according to @xmath28    bp and lp decodings should be considered as computationally efficient but suboptimal substitutions for map and ml .",
    "both bp and lp decodings can be conveniently derived from the so - called bethe - free energy approach of @xcite which is briefly reviewed below . in this",
    "approach trial probability distributions , called beliefs , are introduced both for bits and checks , @xmath29 and @xmath30 , respectively .",
    "the set of bit - beliefs , @xmath31 , satisfy equality and inequality constraints that allow convenient reformulation in terms of a bigger set of beliefs defined on checks , @xmath32 , where , @xmath33 , is a local codeword associated with the check @xmath34 .",
    "the equality constraints are of two types , normalization constraints ( beliefs , as probabilities , should sum to one ) and compatibility constraints : @xmath35 additionally , all the beliefs should be non - negative and smaller than or equal to unity .",
    "the bethe free energy is defined as the difference of the self - energy and the entropy , @xmath36 : @xmath37 optimal configurations of beliefs minimize the bethe free energy subject to the equality constraints ( [ comp ] ) . introducing the constraints as the lagrange multiplier terms to the effective lagrangian and looking for the extremum with respect to all possible beliefs",
    "leads to @xmath38 where the set of @xmath39 fields ( which are lagrange multipliers for the compatibility constraints ) satisfy @xmath40 these are the bp equations for ldpc codes written in its standard form . these equations are often described in the coding theory literature as stationary point equations for the bp ( also called the sum product ) algorithm and then @xmath39 variables are called messages .",
    "the bp algorithm , initialized with @xmath41 , solves eqs .",
    "( [ eta ] ) iterating it sequentially from right to left .",
    "possible lack of the iterative algorithm convergence ( to the respective solution of the bp equation ) is a particular concern , and some relaxation methods were discussed to deal with this problem @xcite .",
    "lp is a close relative of bp which does not have this unpleasant problem with convergence .",
    "originally , lp decoding was introduced as a relaxation of ml decoding @xcite .",
    "it can thus be restated as @xmath42 , where @xmath43 is the polytope spanned by all the codewords of the code . looking for @xmath13 in terms of a linear combination of the codewords , @xmath44 : @xmath45 , where @xmath46 and @xmath47",
    ", one observes that the block - map turns into a linear optimization problem .",
    "the lp - decoding algorithm of @xcite proposes to relax the polytope , expressing @xmath13 in terms of a linear combination of local codewords associated with checks , @xmath48 .",
    "we will not give details of this original formulation of lp here because we prefer an equivalent formulation , elucidating the connection to bp decoding .",
    "one finds that the bp decoding , understood as an algorithm searching for a stationary point of the bp equations , turns into lp decoding in the asymptotic limit of large snr . indeed in this special limit , the entropy terms in the bethe free energy can be neglected and the problem turns into minimization of a linear functional with a set of linear constraints .",
    "the relation between bp and lp was noticed in @xcite and it was also discussed in @xcite . stated in terms of beliefs ,",
    "lp decoding minimizes the self - energy part ( [ e_bethe ] ) of the full bethe free energy functional under the set of linear equality constraints ( [ comp ] ) and also linear inequalities guaranteeing that all the beliefs are non - negative and smaller than or equal to unity .",
    "this gives us a full definition of the so - called large polytope lp decoding .",
    "one can run it as is in terms of bit- and check- beliefs , however it may also be useful to re - formulate the lp procedure solely in terms of the bit beliefs .      the goal of decoding is to infer the original message from the received output , @xmath14 . assuming that coding and decoding are fixed and aiming to characterize the performance of the scheme , one studies the frame - error - rate ( fer ) @xmath49 , where @xmath50 if an error is detected and @xmath51 otherwise . in a symmetric channel ,",
    "fer is invariant with respect to the original codeword , thus the all-@xmath2 codeword can be assumed for the input . when snr is large , fer , as an integral over output configurations , is approximated by @xcite , @xmath52 , where @xmath53 are the special instanton configurations of the output maximizing @xmath54 under the @xmath50 condition , and @xmath55 combines combinatorial and phase - volume factors",
    "generally , there are many instantons that are all local maxima of @xmath54 in the noise space .",
    "for the awgn channel , the instanton estimate for fer at the high snr , @xmath56 , is @xmath57 . in the instanton - amoeba numerical scheme ,",
    "suggested in @xcite , instantons with the small effective distances , @xmath58 , were found by a downhill simplex method also called `` amoeba '' , with accurately tailored ( for better convergence ) annealing .",
    "instantons are closely related to the so - called pseudo - codewords @xcite : decoding applied to the instanton configuration results in the respective pseudo - codeword .",
    "the effective distance , @xmath58 , characterizing an instanton and its respective pseudo - codeword , should be compared with the hamming distance of the code , @xmath59 .",
    "instanton / pseudo - codewords with @xmath60 will completely screen contribution of the respective codeword to the fer at @xmath61 .    in the case of lp decoding , one can actually develop a discrete computational scheme , coined the pseudo - codeword - search ( pcs ) algorithm @xcite , which allows very efficient calculation of the low weight pseudo - codewords and the respective instantons .",
    "it was shown in @xcite that the pcs algorithm converges in a relatively small number of iterations .",
    "the pcs algorithm , repeated many times picking the initial noise configuration randomly , generates a set of low - weight pseudo - codewords .",
    "thus , for the model @xmath0 $ ] code studied in @xcite some @xmath62 pseudo - codewords with the effective weight lower than the hamming distance of the code were found .",
    "loop calculus is a technique which allows one to express explicitly the partition function of the statistical inference problem associated with eq .",
    "( [ psx ] ) in terms of the so - called loop series @xcite : @xmath63 where @xmath32 and @xmath31 are the beliefs defined on checks and bits according to eqs .",
    "( [ ba],[bi ] ) and @xmath64 with self - energy and entropy expressed in terms of the beliefs according to eqs .",
    "( [ e_bethe],[s_bethe ] ) .",
    "the loop series holds for the bp / map relation and it is also well defined for the lp / ml relation , where transition from the former one to the later one is according to eq .",
    "( [ rho ] ) .",
    "notice that in the lp / ml version of the loop series @xmath65 can be singular , i.e. @xmath66 when @xmath67 and @xmath68 , however the resulting @xmath69 is always finite , because in this case the corresponding @xmath70 contribution approaches zero .",
    "moreover , the construction of the loop series is such that any individual @xmath71 is always smaller than unity in absolute value , both in the bp and lp cases .",
    "if bp / lp performs well one expects that the loop corrections , @xmath71 , are all significantly smaller than the bare unity .",
    "failure of the bp / lp decoding signals the importance of some loop corrections .",
    "even though the number of loops grows exponentially with the size of the code , not all loops gives comparable contributions to the loop series .",
    "thus , an important conjecture of @xcite was that for the case of the low - weight pseudo - codewords ( i.e. for the values of log - likelihoods corresponding to the instanton configuration decoded into the pseudo - codewords ) there exists a relatively simple loop contribution ( or a very few simple contributions ) , dominating corrections to bare unity in the loop series .",
    "this conjecture was verified in @xcite for the example of the ( @xmath62 ) instantons found for the lp decoding of the @xmath0 $ ] code performing over the additive - white - gaussian - noise ( awgn ) channel .",
    "it was demonstrated in @xcite that for each of the instantons , one can indeed identify the corresponding critical loop , @xmath72 , giving an essential contribution to the loop series ( [ z_loop ] ) comparable to the bare lp contribution .    the search for the critical loop suggested in @xcite was heuristic .",
    "one searches for a single - connected contribution associated with a critical loop consisting of checks and bits with each check connected to only two bits of the loop . according to eqs .",
    "( [ z_loop ] ) this contribution to the loop series is the product of all the triads , @xmath73 , along the loop , @xmath74 where for any check @xmath34 that belongs to @xmath72 , @xmath75 is the only pair of @xmath34 bit neighbors that also belongs to @xmath72 . by construction , @xmath76 .",
    "we immediately find that for the critical loop contribution to be exactly equal to unity ( where unity corresponds to the bare bp term ) , the critical loop should consist of triads with all @xmath77 equal to unity in absolute value .",
    "even if degeneracy is not exact one still anticipates the contributions from all the triads along the critical loop to be reasonably large , as an emergence of a single triad with small @xmath77 will make the entire product negligible in comparison with the bare bp term .",
    "this consideration suggests that an efficient way to find a single connected critical loop , @xmath72 , with large @xmath78 consists of , first , ignoring all the triads with @xmath79 below a certain @xmath80 threshold , say @xmath81 , and , second , checking if one can construct a single connected loop out of the remaining triads . if no critical loop is found , we lower the threshold until a leading critical loop emerges",
    ".    applied to the set of instantons of the tanner @xmath0 $ ] code with the lowest effective distances this , triad - based search scheme generates an @xmath82 that is exactly unity in absolute value .",
    "this is the special degenerate case in which the critical loop contribution and the bp / lp contribution are equal to each other in absolute value .",
    "thus , only the sixth of the first dozen of instantons has @xmath83 while all others yield @xmath84 . to extend the triad - based search scheme to the instantons with larger effective distance",
    ", one needs to decrease the threshold . for the dangerous pseudo - codewords of the @xmath0 $ ] code",
    "this always resulted in the emergence of at least one single connected loop with @xmath85 .",
    "accounting for a single loop effect ( when it is comparable to a bare ( bp ) contribution ) can be improved through the effective free energy approach explained in @xcite .",
    "this approach resulted in the formulation of renormalized bp equations and the respective loop - corrected bp algorithm aimed at solving the renormalized equations .",
    "modification of the bare bp equations are well localized along the critical loop .",
    "this observation led to the suggestion an lp counterpart of the loop - corrected bp , coined the :    @xmath1 * 1 . *",
    "run the lp algorithm . terminate if lp succeeds ( i.e. a valid code word is found ) .",
    "@xmath1 * 2 . *",
    "if lp fails , find the most relevant loop @xmath72 that corresponds to the maximal amplitude @xmath82 .",
    "@xmath1 * 3 . *",
    "modify the log - likelihoods ( factor - functions ) along the loop @xmath72 introducing a shift towards zero , i.e. introduce a complete or partial erasure of the log - likelihoods at the bits .",
    "run lp with modified log - likelihoods .",
    "terminate if the modified lp succeeds .",
    "@xmath1 * 4 .",
    "* return to * step 2 * with an improved selection principle for the critical loop .",
    "this lp - erasure algorithm was tested in @xcite on the @xmath0 $ ] example .",
    "the results of the test are remarkable : all @xmath62 low - weight instantons were actually corrected already with the roughest version of the lp - erasure algorithm , corresponding to the full erasure of the information ( log - likelihoods ) along the critical loop .",
    "the facet guessing ( fg ) is an improvement of the lp decoder suggested in @xcite .",
    "this algorithm applies when the bare lp fails .",
    "failure of lp means that some of the non - strict inequality constraints in the lp formulation remain inactive for the lp solution , i.e. the respective strict equalities are not satisfied . considering expander codes and the small - polytope version of the lp decoding , the authors of @xcite proved that the set of active constraints of any fractional pseudo - codeword is smaller by a constant factor than the number of active constraints of any codeword .",
    "this fact was exploited in @xcite to devise a decoding algorithm that provably outperforms the lp decoder for finite blocklengths .",
    "the fg algorithm proceeds by guessing the facets of the polytope , i.e. enforcing the respective inactive facets to be active with a new equality constraint , and resolving the linear program on these facets . in its full version , the algorithm thus consists of the set of modified lp algorithms .",
    "the number of the modified schemes is equal to the number of inactive facets in the fractional pseudo - codeword solution of the bare lp algorithm .",
    "the configurational output of the fg algorithm is the output of one modified lp from the set giving the lowest value of the self - energy ( optimization functional ) .",
    "the randomized version of the fg algorithm consists of picking some fixed fraction of the modified lp schemes at random from the full set , and then finding the configuration minimizing the result on the subset .",
    "@xcite also discussed experimental test of the theory done for couple of codes , of which one is the @xmath0 $ ] code also considered in this paper .",
    "it was experimentally demonstrated that the randomized version of the fg algorithm improves the bare lp decoding .",
    "we introduce a bit guessing ( bg ) procedure , which is a simplified version of the fg algorithm .",
    "the simplification comes with a restriction imposed on the facet - activation ( fixing ) procedure . in bg ,",
    "one only allows activation ( fixing ) of the inequalities associated with bit beliefs , @xmath31 , and not check beliefs , @xmath32 . considering values of the log - likelihoods resulting in a fractional lp pseudo - codeword , one creates a set of single bit corrected lp schemes , each different from the bare lp schemes by only one extra equality condition , enforcing the value of a bit to be @xmath3 or @xmath2 .",
    "( if the value of the marginal probability in the bare pseudo - codeword of lp is fractional , we include two bit - modified lps in the set , corresponding to enforcing @xmath2 and @xmath3 values for the bit respectively .",
    "if the marginal probability of a bit is integer we only includes one bit - modified lp in the set corresponding to fixing the value of the bit to the integer opposite to the one observed in the bare pseudo - codeword for the bit . )",
    "we run consequently all the modified lp schemes , forming the bg set , and choose the result with the lowest energy functional as the outcome of the bit guessing procedure .",
    "the fg algorithm was tested on the set of dangerous fractional pseudo - codewords described in @xcite .",
    "we found that all of the pseudo - codewords were successfully corrected by fg ! in other words , the output of a corrected lp - scheme with the minimum self - energy is the right codeword ( the all - zero one in the simulations ) .",
    "one also finds that there always exists a number of successful lp - corrected schemes , each associated with a different pinned bit .",
    "this number was actually relatively large for the fractional pseudo - codewords with the lowest weight , @xmath86 , but smaller values were also observed for some of the fractional pseudo - codewords with effective distance from the dangerous range , @xmath87 $ ] .",
    "next for any of the lp - dangerous , but fg - correctable , pseudo - codewords , one creates the list of  successful \" bits and compares this list with the list of bits forming the respective critical loop found in @xcite with the thresholding of the @xmath77 values .",
    "one finds that the set of bits forming the critical loop forms a relatively small sub - set of the  successful \" set .",
    "in other words , fixing any bit of the critical loop describing a dangerous fractional pseudo - codewords leads to correct decoding .",
    "one draws a couple of useful conclusions from this simple experiment .",
    "1 ) one finds that the fg algorithm offers a very successful strategy for decoding in accordance with the main claim of @xcite .",
    "it corrects all the dangerous pseudo - codewords of the model @xmath0 $ ] code .",
    "2 ) the fg correction can be made with the help of the critical loop procedure of @xcite .",
    "finding the critical loop helps to reduce the complexity of the operation beacause it requires adding only one equality constraint to the bare lp decoding by fixing the value of the marginal probability to zero or one at any point of the critical loop .",
    "these observations suggest the following decoding algorithm , coined * loop guided guessing * ( lgg ) :    @xmath1 * 1 .",
    "* run the lp algorithm . terminate if lp succeeds ( i.e. a valid code word is found ) .",
    "@xmath1 * 2 . *",
    "if lp fails , find the critical loop , @xmath72 , the one with maximal value of @xmath78 in the loop series .",
    "@xmath1 * 3 . *",
    "pick any bit along the critical loop at random and form two corrected lp schemes , different from the bare lp schemes by only one extra equality condition , enforcing the value of a bit to be @xmath3 or @xmath2 respectively .",
    "@xmath1 * 4 . *",
    "run both lp - corrected schemes and choose the output which corresponds to the smallest self - energy .",
    "terminate if the modified lp succeeds .",
    "@xmath1 * 5 .",
    "* return to * step 3 * selecting another bit along the critical loop or to * step 2 * for an improved selection principle for the critical loop if the list of all the bits along the previously selected loop is exhausted .",
    "notice that main advantage of the lgg algorithm , in comparison with the loop erasure algorithm of @xcite , is in the locality of the bare algorithm ( lp ) modification .",
    "one finds that breaking a loop , instead of modifying the algorithm along the loop , is sufficient for successful decoding .",
    "frame error rate vs snr for the @xmath0 $ ] code and the awgn channel .",
    "diamonds represent data of the lp - decoding simulations from @xcite .",
    "stars stand for the lgg ( loop guided guessing)-decoding described in the text . dashed and",
    "dashed - dotted lines show the map and bp / lp decodings @xmath61 asymptotes , @xmath88 and @xmath89 respectively , where @xmath90 is the minimal ( hamming ) distance of the code and the effective distance of the lowest weight lp pseudo - codeword found for the code is @xmath91.,width=340 ]    we tested the performance of the lgg algorithm using monte carlo ( mc ) simulations .",
    "our starting point was the set of configurations whose bare lp failed in the mc - lp simulations for the @xmath0 $ ] code discussed in @xcite .",
    "we apply the lgg algorithm to these erroneous configurations and observed essential improvement .",
    "thus for @xmath92 , only one out of every ten lp - invalid configurations is not correctable by lgg .",
    "the results of the simulations are shown in fig .",
    "( [ fig1 ] ) .",
    "( note that performance of the lp - erasure algorithm of @xcite was worse with only a few bare lp failures corrected . )    for some of these individual configurations , we also run an exhaustive bg algorithm ( checking bit by bit if the respective bit - corrected lp decodes correctly ) and compare the resulting set of  successful \" bits with the set of bits forming the critical loop .",
    "very much like the case of the respective dangerous pseudo - codewords test , we found strong correlations between the two sets : bits of the critical loop typically belong to the  successful \" set .",
    "this justifies our decision to select the special bit along the critical loop at random , thus supporting the conjecture that a pin - point bit - local correction of lp is sufficient for breaking the loop and successful decoding .",
    "notice that configurations accessable at snrs from fig .",
    "[ fig1 ] via mc simulations are typically those with relatively large effective distances , @xmath93 , while the hamming distance of the code is @xmath90 and the effective distance of the most dangerous pseudo - codeword of the bare lp is @xmath94 .",
    "we expect , however , that majority of these configurations are from valleys of the bethe free energy functional with local minima correspondent to effective distances from the @xmath87 $ ] range .",
    "see @xcite for a related discussion of why the fer asymptote at moderate snr shows behavior controlled by pseudo - codewords with much smaller effective distance than those representing a given snr .",
    "let us conclude listing some future problems / challenges :      @xmath1 the lgg performance can be improved if a better algorithm for finding the critical loop is implemented .",
    "an ldpc code can be replaced by its map - equivalent dendro - counterpart @xcite .",
    "then , the problem of finding the single - connected loop with the largest value of @xmath95 is reduced to finding the shortest path on the undirected graph with possibly negative weights , however with a guarantee that all loop contributions over the graph are positive .",
    "one may hope to develop an efficient graph algorithm for solving this problem .",
    "@xmath1 modern schemes of ldpc ensemble optimization @xcite are very successful in dealing with the water - fall domain , where performances of almost all codes from the given ensemble are identical .",
    "it is known however that different codes from the same ensemble show big performance variations in the error - floor domain if a standard , not yet optimized , decoding is utilized .",
    "this problem is a serious handicap for the successful use of random ldpc codes in the demanding high snr regime .",
    "we plan to apply the decoding improvement strategy to the optimized lpdc ensembles , with the hope that the algorithm improvement may be capable in lowering the error - floor for a majority of codes from the ensemble .",
    "the author acknowledge very useful , inspiring and fruitful discussions with v. chernyak , a. dimakis , m. stepanov and m. wainwright .",
    "this work was carried out under the auspices of the national nuclear security administration of the u.s .",
    "department of energy at los alamos national laboratory under contract no .",
    "de - ac52 - 06na25396 .              c. berrou , a. glavieux , p. thitimajshima , _ near shannon limit error - correcting coding and decoding : turbo codes _ , proceedings ieee international conference on communications , 23 - 26 may 1993 , geneva , switzerland ; p.1064 - 70 vol.2        g.d .",
    "forney , jr .",
    ", r. koetter , f.r .",
    "kschischang , and a. reznik , _ on the effective weights of pseudocodewords for codes defined on graphs with cycles _ , in codes , systems , and graphical models ( minneapolis , mn , 1999)(b .",
    "marcus and j. rosenthal , eds . ) vol .",
    "1233 of i m a vol .",
    "appl .. , pp . 101 - 112",
    "springer verlag , new york , inc . , 2001 .",
    "m. chertkov , v. chernyak , _ loop calculus helps to improve belief propagation and linear programming decodings of low - density - parity - check codes _",
    ", invited talk at 44th allerton conference ( september 27 - 29 , 2006 , allerton , il ) , arxiv : cs.it/0609154 . m. j. wainwright and m. i. jordan , _ graphical models , exponential families , and variational inference _ , no .",
    "649/2003 uc berkeley , department of statistics ;",
    "wainwrig / papers / waijorvariational03.pdf        m. chertkov , m. stepanov , _ an efficient pseudo - codeword - search algorithm for linear programming decoding of ldpc codes _ , arxiv : cs.it/0601113 , to appear in ieee it 2007 .",
    "m. chertkov , m. stepanov , _ pseudo - codeword landscape _ ,",
    "isit 2007 , june 2007 , nice , cs.it/0701084 .",
    "m. chertkov , v.y .",
    "chernyak , loop calculus in statistical physics and information science , phys .",
    "e * 73 * , 065102(r ) ( 2006 ) ; cond - mat/0601487 .",
    "m. chertkov , v. chernyak , _ loop series for discrete statistical models on graphs _ , j. stat .",
    "( 2006 ) p06009 , cond - mat/0603189 .",
    "m. stepanov , m. chertkov , _ improving convergence of belief propagation decoding _ , cs.it/0607112 , proceedings of 44th allerton conference ( september 27 - 29 , 2006 , allerton , il ) .",
    "m. stepanov , m. chertkov , _ the error - floor of ldpc codes in the laplacian channel _ , proceedings of 43rd allerton conference ( september 28 - 30 , 2005 , allerton , il ) , arxiv : cs.it/0507031 .",
    "a. amraoui , a. montanari and r. urbanke , _ how to find good finite - length codes : from art towards science _ , in proc .",
    "of 4-th international symposium on turbo codes and related topics , munich 3 - 7 apr 2006 ; cs.it/0607064 ."
  ],
  "abstract_text": [
    "<S> we discuss how the loop calculus approach of [ chertkov , chernyak 06 ] , enhanced by the pseudo - codeword search algorithm of [ chertkov , stepanov 06 ] and the facet - guessing idea from [ dimakis , wainwright 06 ] , improves decoding of graph based codes in the error - floor domain . </S>",
    "<S> the utility of the new , linear programming based , decoding is demonstrated via analysis and simulations of the model @xmath0 $ ] code . </S>"
  ]
}