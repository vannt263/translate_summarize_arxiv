{
  "article_text": [
    "consider a system of discrete - time random walks on a graph @xmath4 with two walkers .",
    "each time , they each independently move to a nearby vertex or stay still with given probabilities .",
    "denote the transition matrix of a single walker by @xmath5 , where @xmath6 is the probability that one walker moves from @xmath7 to @xmath8 in a time slot .",
    "this process is assumed to start at steady state ( i.e. uniform distribution ) for each walker , and terminates when they meet at the same vertex .",
    "we denote this meeting time by @xmath9 , which is a random variable with the expectation * * e**@xmath10 $ ] .",
    "our objective is to analyze this quantity on @xmath11-regular graphs .",
    "it is instructive to consider the problem on the one - dimensional circle first .",
    "we study a circle with @xmath0 nodes , denoted by @xmath12 .",
    "the two walkers start from arbitrary position according to the initial distribution .",
    "every step , the walker on @xmath13 chooses to move to @xmath14 ( for simplicity of notation , assume that if @xmath15 , then @xmath16 and similarly that if @xmath17 then @xmath18 ) or stay still at @xmath13 with probability @xmath19 respectively .",
    "since we are only concerned about the meeting time , the relative position of the two walkers is enough to describe that random variable .",
    "so we fix one walker at @xmath20. then in this new equivalent model , the transition matrix of the other walker before the encounter is @xmath21",
    ".    a similar equivalent model can be defined for a @xmath2 torus .",
    "let @xmath22 .",
    "every step , the walker on @xmath23 moves to @xmath24 or stay still at @xmath23 with given probability .",
    "define the index of @xmath23 to be * * ind**@xmath25 , we can get a @xmath26-order matrix @xmath5 .",
    "let @xmath27 denote the indices of two vertex @xmath28 .",
    "then @xmath6 denotes the probability that one walker moves from @xmath29 to @xmath30 each step .",
    "@xmath5 is a  block - circulant matrix \" defined in 3.1.2 .",
    "similar to the 1-d case , we fix one walker at the lower - right cell , the transient matrix of the other walker before the encounter here is also given as @xmath21 , which is symmetric .        our main result is as follows : by suitably defining a laplacian matrix @xmath31 , the expected meeting time of the two walkers * * e**@xmath32 $ ] ( i.e. , the expectation of the first time that they meet on the same cell starting from the steady state uniform distribution ) on a ring or torus could be explicitly expressed as the sum of the reciprocals of non - zero eigenvalues of @xmath31 .",
    "we further conjecture based on empirical evidence that the result holds more generally for simple random walks ( i.e. , with equal transition probabilities ) on arbitrary regular graphs .",
    "recall the standard definition of a circulant matrix :    a circulant matrix is a matrix where each row vector is rotated one element to the right relative to the preceding row vector .",
    "a circulant matrix @xmath33 is fully specified by one vector , @xmath34 , which appears as the first row of @xmath33 .      for arbitrary real , circulant matrix @xmath33 generated by @xmath35with order @xmath36",
    ", we can find its eigenvalue in a general way following the approach indicated in  @xcite .",
    "first define vector @xmath37 whose @xmath38 component is    @xmath39    we can prove the following properties :    \\(a ) @xmath40    \\(b ) @xmath41 + ( a ) shows that@xmath42 are the orthogonal eigenvectors of @xmath33 .",
    "@xmath43 is the eigenvalue of @xmath33 , which can be calculated by    @xmath44    let @xmath45 , then we have the property ( b ) .    if @xmath33 is a @xmath46-order partitioned circulant matrix generated by @xmath47 where the @xmath48 are all @xmath36-order circulant matrices generated by @xmath49 ( see illustration below for a 9-order block - circulant matrix ) .",
    "then @xmath33 is called a block - circulant matrix .",
    "@xmath50      given index @xmath13 , the coordinates of @xmath13 is @xmath51then we need to modify the definition of @xmath37 by    @xmath52    the properties given above in section 3.1.1 still hold , and we have + @xmath53 is the @xmath54 eigenvalue of @xmath33 .",
    "let us first discuss the problem on the simplest graph , a 1-d circle .",
    "if two particles make independent random walks on a circle with an uniform initial distribution , then the expected meeting time is @xmath55 , where @xmath43 is the @xmath54 eigenvalue of @xmath56 , and @xmath5 is the transition matrix for a single walker .",
    "put the transition probabilities in @xmath57 as the weight of edges",
    ". then we get the laplacian matrix ,    @xmath58    which is a circulant matrix generated by @xmath59 , where @xmath60 .",
    "let @xmath61,which is the @xmath54 component of vector @xmath62 , denote the expected meeting time with starting vertex @xmath13 .",
    "obviously , @xmath63 .",
    "the initial distribution is @xmath64 . then * * e**@xmath10 = \\bm{\\pi}^t \\bm{t}$ ] .",
    "we can obtain a set of equations by recurrence :    @xmath65    notice that the coefficients @xmath66 . by summing up the above equations",
    ", we have :    @xmath67    thus , the laplacian matrix @xmath31 is the coefficient matrix of ( 4),(5 ) .",
    "@xmath68    since l is a real , circulant matrix , we can use the conclusion in section 3.1.1 . taking the inner product of ( 9 ) with @xmath69 on both sides , from the symmetry of @xmath31 we have    @xmath70    @xmath71    notice that @xmath72 for @xmath73 .",
    "combined with ( 9 ) , for @xmath73 ,    @xmath74    summing up by @xmath13 , we have :    @xmath75    @xmath76    changing the order of summation ,    @xmath77    @xmath78    we assume the steady state distribution is the initial distribution . for any arbitrary regular graph , this is the uniform distribution .",
    "the expected meeting time is then given as :    @xmath79 = \\bm{\\pi}^t \\bm{t } = \\frac{1}{n}\\sum_{k=1}^{n-1}t_k   = \\sum_{i=1}^{n-1 } \\lambda_i^{-1}\\ ] ]    note that this is the sum of the reciprocals of non - zero eigenvalues of @xmath31 .      for simplicity , we estimate the order of @xmath80 $ ] for simple random walk ( i.e. , @xmath81 ) : @xmath82=&\\sum_{i \\ne 0}^n \\frac{1}{3}(2-\\frac{4}{3}\\cos{\\frac{\\pi i}{n}}-\\frac{2}{3}\\cos{\\frac{2 \\pi i}{n}})^{-1}\\\\ = & \\sum_{i=1}^n \\frac{2}{9}(2-\\cos{\\frac{\\pi i}{n}}-(\\cos{\\frac{\\pi i}{n}})^2)^{-1}\\\\ = & \\frac{2}{9}\\sum_{i=1}^n \\frac{1}{(2+t_i)(1-t_i)}\\\\ \\end{split}\\ ] ]    where @xmath83 .",
    "thus @xmath84 $ ] , which is bounded by constants . from  @xcite",
    ", we have that summation @xmath85 is @xmath86 .",
    "thus @xmath80 $ ] is @xmath86 . on the other side , for @xmath87 ,",
    "applying the taylor theorem we have    @xmath88    thus @xmath80 $ ] is also @xmath89 , yielding that in fact for the 1-d circle , @xmath80 $ ] grows with the size of the graph as @xmath1 .",
    "if two particles make independent random walks on a torus with an uniform initial distribution , then the expected meeting time is @xmath55 , where @xmath43 is the @xmath54 eigenvalue of @xmath56 , and @xmath5 is the transition matrix for a single walker .",
    "similarly , put the probabilities of transition in @xmath57 as the weight of edges .",
    "then we get the laplacian matrix .",
    "@xmath90    let @xmath61 denotes the expected encounter time with starting point with index @xmath13 , which is the @xmath54 component of vector @xmath62 .",
    "obviously , @xmath91 . if the initial distribution is @xmath64 , then * * e**@xmath10 = \\bm{\\pi}^t \\bm{t}$ ] .",
    "we can get a set of equations by recurrence ( for a more readable notation here we write that @xmath92 ) .    for ease of exposition , we illustrate below this recurrence equation for a simple random walk , that means the walker in the original model moves to its neighbour or stay still with the same probability @xmath93 :    @xmath94    note that such a recurrence equation for @xmath95 could also be written for any random walk that moves to neighboring nodes with different probabilities .",
    "we also have :    @xmath96    with the same approach in 3.2 , we have    @xmath97    @xmath98    combined with ( 20 ) and @xmath99 , summing up by @xmath13 for @xmath73 , we have    @xmath100    @xmath101    change the sequence of summation , finally we have    @xmath102    note that we get actually the same expression as 1-d circle . given the uniform initial distribution , the expected time @xmath80 $ ] is the sum of the reciprocals of non - zero eigenvalues of @xmath31 .      applied ( 6 ) to ( 25 ) , we have    @xmath79= \\sum_{\\begin{subarray}{l } i , j=0 \\\\",
    "( i , j)\\ne(0,0)\\end{subarray}}^{n-1 } \\left ( \\frac{1}{25 } ( 20 - 2(\\cos{\\frac{4\\pi i}{n}}+\\cos{\\frac{4\\pi j}{n}})-4(\\cos{\\frac{2\\pi i}{n}}+\\cos{\\frac{2\\pi j}{n } } ) -8\\cos{\\frac{2\\pi i}{n}}\\cos{\\frac{2\\pi j}{n } } ) \\right)^{-1}\\ ] ]    which can be rewritten as @xmath79\\equiv \\sum_{\\begin{subarray}{l } i , j=0 \\\\",
    "( i , j)\\ne(0,0)\\end{subarray}}^{n-1 } \\frac{1}{2t_{ij}s_{ij}+3}\\frac{1}{1-t_{ij}s_{ij}}\\ ] ]    where @xmath103 . by applying the lemma(proved in * appendix",
    "a * ) :    if @xmath104 $ ] , then    @xmath105    we can separate the summation into @xmath106 parts , and prove that each part is @xmath1 . thus finally we obtain that    @xmath79~is~\\theta(n^2 log n)\\ ] ]    the complete proof is given in the * appendix a*.",
    "we have proved that on the circle and the torus , the sum of the reciprocals of non - zero eigenvalues of @xmath56 is the expected meeting time of two walkers .",
    "in fact , if the graph has a strong symmetry properties which guarantees @xmath107 and @xmath31 is ( block-)circulant , then the proof still holds .",
    "the simulation results shown in figure  [ fig:4 ] match the conclusion in section 3 .      moreover",
    ", we find empirically that the expression even works for simple random walks on arbitrary regular graphs .",
    "this is not a trivial observation , since the symmetry of vertices does nt hold for arbitrary regular graph , see the examples for 4-regular graphs in figure  [ fig:5 ] . in this case , the equivalent model approach of fixing one of the walkers at a particular location and defining the transition matrix of the other walker does not work .",
    "if two particles make independent * simple * random walks on a connected @xmath11-regular graph , and the initial distribution is uniform , then the expected meeting time @xmath80 $ ] is @xmath55 , where @xmath43 is the @xmath54 eigenvalue of @xmath56 , and @xmath5 is the transition matrix for a single walker",
    ".    our conjecture is supported by empirical evidence which we present here .",
    "figure  [ fig:6 ] shows simulation results as well as relevant numerical calculations for simple random walks over arbitrary regular graphs .",
    "the left figure shows the results on 10-regular graphs , while the right one on graphs with 30 vertices . for each horizontal point ,",
    "a single random graph is generated and fixed for averaging over multiple random initial conditions drawn from a uniform distribution .",
    "each blue mark indicates the average meeting time when doing the experiment independently for 500 times , and green mark for 10000 times .",
    "the red mark indicates the conjectured value of the expected meeting time ( i.e. the sum of the reciprocals of non - zero eigenvalues of @xmath31 ) . the black mark indicates the exact value of @xmath80 $ ] which could be calculated by the definition of expectation once given transition probabilities ( see appendix b ) . in each case",
    "we see that the conjecture is valid .",
    "where @xmath119 is the kronecker product of p. then from@xmath120 , we have the eigenvalue of @xmath5 is @xmath121 .",
    "thus from the properties of kronecker product , the eigenvalue and eigenvector of @xmath117 is @xmath122 and @xmath123 .",
    "we can similarly construct a recursive function of @xmath124 , which indicates the expected meeting time with walkers on vertex @xmath13 and @xmath114 . obviously , @xmath125 .",
    "we can prove that @xmath126 , where @xmath127 if @xmath128 , else @xmath129 .",
    "then                            robert kleinberg , lecture notes for computer science 6822 advanced topics in theory of computing : flows , cuts , and sparsifiers , fall 2011 , online at www.cs.cornell.edu/courses/cs6822/2011fa/scribenotes/lec_2.pdf                  let @xmath148 , since if @xmath149 is fixed , @xmath150 attains its maximum at @xmath151 .",
    "thus , it remains to show @xmath152 , which is @xmath153 , this inequality is correct and we complete the proof .",
    "+ recall the equation ( 26 ) which can be obtained by some trigonometric identities .",
    "@xmath157 are uniformly distributed within the grid @xmath158\\times[0,n]$ ] ( except the origin ) , then @xmath159 are uniformly distributed in a diamond area in @xmath160\\times[-n , n]$ ] , by the symmetry of cosine function and omitting a constant coefficient , it s equivalent to estimate                    for all @xmath168 , @xmath169 , and every term @xmath170 in @xmath48 corresponds to @xmath171 in @xmath172 .",
    "then applying the * lemma 1 * and the cosine function is non - negative and monotone decreasing in @xmath173 $ ] , we can prove that               + the exact value of expected meeting time could be calculated in the following way : suppose there are two walkers @xmath182 and @xmath183 .",
    "we denote the state that @xmath182 is at vertex @xmath13 while @xmath183 is at vertex @xmath114 by @xmath184 , with index @xmath185 .",
    "thus if the transition matrix for a single walker is @xmath5 , then the transition matrix for the states of two walkers is @xmath186 except for the @xmath187 rows(the absorbing states ) , which are all zeros expect the the @xmath188 component .",
    "let @xmath189 , and @xmath190 is the set of absorbing states .",
    "@xmath191 indicates the state at time @xmath9 .",
    "@xmath82 = & \\sum_{\\tau = 0}^{\\infty } \\tau \\sum_{k \\in s_\\lambda } \\sum_{l \\notin s_\\lambda }",
    "pr[s(\\tau ) = k , s(\\tau - 1 ) = l]\\\\ = & \\sum_{\\tau = 0}^{\\infty } \\tau \\sum_{k \\in s_\\lambda } \\sum_{l \\notin s_\\lambda } pr[s(\\tau ) = k|s(\\tau - 1)=l]pr[s(\\tau - 1 ) = l]\\\\ = & \\sum_{\\tau = 0}^{\\infty } \\tau \\sum_{k \\in s_\\lambda } \\sum_{l \\notin s_\\lambda } pr[s(\\tau ) = k|s(\\tau - 1 ) = l]\\bm{p_0}\\cdot q^{\\tau-1 } \\cdot \\bm{e_l}\\\\ = & \\bm{p_0 } \\sum_{\\tau = 0}^{\\infty}(\\tau \\cdot q^{\\tau-1 } ) \\cdot \\bm{b } \\end{split}\\ ] ]        where @xmath197 is the sub - matrix of @xmath198 deliminating the rows and columns with index in @xmath199 , @xmath200 is the sub - vector of @xmath183 deliminating the rows and columns with index in @xmath199 ."
  ],
  "abstract_text": [
    "<S> we provide an analysis of the expected meeting time of two independent random walks on a regular graph . for 1-d circle and 2-d torus graphs , </S>",
    "<S> we show that the expected meeting time can be expressed as the sum of the inverse of non - zero eigenvalues of a suitably defined laplacian matrix . </S>",
    "<S> we also conjecture based on empirical evidence that this result holds more generally for simple random walks on arbitrary regular graphs . </S>",
    "<S> further , we show that the expected meeting time for the 1-d circle of size @xmath0 is @xmath1 , and for a 2-d @xmath2 torus it is @xmath3 . </S>"
  ]
}