{
  "article_text": [
    "consider the problem of sequential multi - user channel allocation in a cognitive radio network ( see , e.g. , @xcite ) . in this problem ,",
    "a network operator sequentially matches a set of @xmath4 _ secondary users _ to a set of @xmath5 _ channels _ , with the goal of maximizing the overall quality of service ( qos ) provided for the secondary users , while not interfering with the quality provided to _",
    "primary users_. due to different qos preferences of users and geographic dispersion , different users might perceive the quality of the same channel differently . furthermore , due to uneven traffic on the channels and other external conditions , the quality of each matching may change over time in a way that is very difficult to model by statistical assumptions .",
    "formally , the _ loss _ associated with user @xmath6 being matched to channel @xmath7 in the @xmath8@xmath9  decision - making round is @xmath10 $ ] , and the goal of the network operator is to sequentially select matchings @xmath11 so as to minimize its total loss @xmath12 after @xmath1 rounds .",
    "it is realistic to assume that the operator learns about the instantaneous losses of the allocated user - channel pairs after making each decision , but counterfactual losses are never revealed .    among many other sequential optimization problems of practical interest such as sequential routing or online advertising ,",
    "the above problem can be formulated in the general framework of _ online combinatorial optimization _",
    "this learning problem can be formalized as a repeated game between a _ learner _ and an _ environment_. in every round @xmath13 , the learner picks a decision @xmath11 from a combinatorial decision set @xmath14 .",
    "simultaneously , the environment fixes a loss vector @xmath15^d$ ] and the learner suffers a loss of @xmath16 .",
    "we assume that @xmath17 holds for all @xmath18 , entailing @xmath19 . at the end of the round",
    ", the learner observes some feedback based on @xmath11 and @xmath20 .",
    "the simplest setting imaginable is called the _ full - information _ setting where the learner observes the entire loss vector @xmath20 . in most practical situations",
    ", however , the learner can not expect such rich feedback . in this paper",
    ", we focus on a more realistic and challenging feedback scheme known as _ semi - bandit _ : here the learner observes the subset of components @xmath21 of the loss vector with @xmath22 .",
    "note that this precise feedback scheme arises in our cognitive - radio example .",
    "the performance of the learner is measured in terms of the _ regret _ @xmath23 that is , the gap between the total loss of the learner and that of the best fixed action . the interaction history up to time @xmath8 is captured by @xmath24 . in the current paper , we focus on _ oblivious _ environments who are only allowed to pick each loss vector @xmath20 independently of @xmath25 .",
    "the learner is allowed to ( and , by standard arguments , should ) randomize its decision @xmath11 based on the observation history @xmath25 . with these remarks in mind",
    ", we will focus on the _ expected regret _",
    "@xmath26}$ ] from now on , where the expectation integrates over the randomness injected by the learner .",
    "most of the literature is concerned with finding algorithms for the learner that guarantee that the regret grows as slowly as possible with @xmath1 .",
    "of equal importance is establishing lower bounds on the learner s regret against specific classes of environments .",
    "both of these questions are by now very well - studied , especially in the simple case where @xmath27 is the set of @xmath28-dimensional unit vectors ; this setting is known as _ prediction with expert advice _ when considering full feedback ( e.g. , @xcite ) and the _ multi - armed bandit _ problem when considering semi - bandit feedback ( e.g. , @xcite ) .",
    "in these settings , the minimax regret is known to be of @xmath29 and @xmath30 , respectively .",
    "several learning algorithms are known to achieve these regret bounds , at least up to logarithmic factors in the bandit case , with the notable exception of the polyinf algorithm proposed by @xcite .",
    "the minimax regret for the general combinatorial setting was studied by @xcite , who show that no algorithm can achieve better regret than @xmath31 in the full - information setting , or @xmath32 in the semi - bandit setting . @xcite  also propose algorithms that achieve these guarantees under both of the above feedback schemes .",
    "furthermore , they show that a natural ( although not always efficient ) extension of the exp3strategy of @xcite guarantees a regret bound of @xmath33 in the semi - bandit setting ( see also @xcite ) . a computationally efficient strategy for the same setting",
    "was proposed by @xcite , who show that an augmented version of the fpl algorithm of @xcite achieves a regret of @xmath34 , essentially matching the bound of exp3 .    even though the above guarantees can not be substantially improved under the worst possible realization of the loss sequence ,",
    "certain improvements are possible for specific types of loss sequences . arguably , one of the most fundamental of these improvements are bounds that replace the number of rounds @xmath1 with the loss of the best action @xmath35 , thus guaranteeing a regret of @xmath2{l_t^*}})$ ] .",
    "such improved bounds , often called _ first - order _ regret bounds , are abundant in the online learning literature _ when assuming full feedback _ : the key for obtaining such results is usually a clever tuning rule for otherwise standard learning algorithms such as hedge@xcite or fpl @xcite . the intuitive advantage of such first - order bounds that they can effectively take advantage of `` easy '' learning problems where there exists an action with superior performance . in our cognitive - radio example",
    ", this corresponds to the existence of a user - channel matching that tends to provide high quality of service .",
    "one obvious question is whether such improvements are possible under partial - information constraints .",
    "we can answer this question in the positive , although such bounds are far less common than in the full information case . in fact , we are only aware of three algorithms that achieve such bounds : exp3light described in section  4.4 of @xcite , greenby @xcite and by @xcite , as shown by @xcite .",
    "these algorithms guarantee regret bounds of @xmath36{l_t^*\\log d}})$ ] , @xmath37{l_t^*\\log   d}})$ ] and @xmath38{l_t^*\\log ( dt)}})$ ] in the multi - armed bandit problem , respectively .",
    "these results , however , either do not generalize to the combinatorial setting ( see section  [ sec : close ] for a discussion on green ) or already scale poorly with the problem size in the simplest partial - information setting . furthermore , implementing these algorithms is also not straightforward for combinatorial decision sets .    in this paper",
    ", we propose a computationally efficient algorithm that guarantees similar improvements for combinatorial semi - bandits .",
    "our approach is based on the follow - the - perturbed - leader ( fpl ) algorithm of @xcite , as popularized by @xcite .",
    "we show that an appropriately tuned variant of our algorithm guarantees a regret bound of @xmath39{dl_t^*\\log(d / m)}}\\bigr)$ ] , largely improving on the minimax - optimal bounds whenever @xmath40 . in the case of multi - armed bandits",
    "where @xmath41 , the bound becomes @xmath42{dl_t^*\\log d}})$ ] .",
    "notice however that when @xmath43 , @xmath3 can be as large as @xmath44 in the worst case , making our bounds inferior to the best known bounds concerning fpland exp3 . to circumvent this problem , as well as the need to know a bound on @xmath3 to tune our parameters",
    ", we also propose an adaptive variant of our algorithm that guarantees a regret of @xmath39{\\min\\{dl_t^*,dt\\}\\log ( d / m)}}\\bigr)$ ] .",
    "thus , our performance guarantees are in some sense the strongest among known results for non - stochastic combinatorial semi - bandits .    besides first - order bounds , there are several other known ways of improving worst - case performance guarantees of @xmath0 for non - stochastic multi - armed bandits .",
    "a common improvement is replacing @xmath1 by the _ gain _ of the best action , @xmath45 ( see , e.g. , @xcite ) .",
    "such bounds , while helpful in some cases where _ all _ actions tend to suffer large losses ( e.g. , in online advertising where even the best ads have low clickthrough rates ) , are not as satisfactory as our bounds : these bounds get worse and worse as one keeps increasing the gain of the best action , even if all other losses are kept constant , despite the intuition that this operation actually makes the learning problem much easier .",
    "that is , bounds of the above type fail to reflect the `` hardness '' of the learning problem at hand .",
    "the work of @xcite considers a much more valuable type of improvement : they provide regret bounds of @xmath46{q_t}})$ ] , where @xmath47 is the _",
    "quadratic variation _ of the losses .",
    "such bounds are very strong in situations where the sequence of loss vectors `` stays close '' to its mean in all rounds .",
    "notice however that , unlike our first - order bounds , this improvement requires a condition to hold for _ entire loss vectors _ and not just the loss of the best action .",
    "this implies that first - order bounds are more robust to loss variations of obviously suboptimal actions . on the other hand ,",
    "it is also easy to construct an example where @xmath3 grows linearly while @xmath48 is zero . in summary",
    ", we conclude that first - order bounds and bounds depending on the quadratic variation are not comparable in general , as they capture very different kinds of regularities in the loss sequences . for further discussion of higher - order and variation - dependent regret bounds , see @xcite and @xcite .",
    "we also mention that several other types of improvements exist for full - information settings  we refer to recent works of @xcite , @xcite and the references therein .",
    "finally , let us comment on related work on the so - called _ stochastic _ bandit setting where the loss vectors are drawn i.i.d .  in every round .",
    "in this setting , combinatorial semi - bandits have been studied under the name `` combinatorial bandits '' @xcite , giving rise to a bit of confusion after round @xmath8 . ] .",
    "this line of work focuses on proving bounds on the _ pseudo - regret _ defined as @xmath49 , where @xmath50 is the mean of the random vector @xmath51 .",
    "we highlight the result of @xcite , who have very recently proposed an algorithm that guarantees bounds on the pseudo - regret of @xmath52 for some distribution - dependent constant @xmath53 and a worst - case bound of @xmath54 .",
    "note however that comparing these pseudo - regret bounds to bounds on the expected regret can be rather misleading .",
    "in fact , a simple argument along the lines of section  9 of @xcite shows that even algorithms with _",
    "zero _ pseudo - regret can actually suffer an expected regret of @xmath55 , when permitting multiple optimal actions .",
    "a more refined argument shows that this bound can be tightened to @xmath56{l_t^*}})$ ] when assuming non - negative losses , suggesting that first - order bounds on the expected regret are in some sense unbeatable even in a distribution - dependent setting .",
    "we now explain the key idea underlying our analysis .",
    "our approach is based on the observation that regret bounds for many known bandit algorithms ( such as exp3by @xcite , osmdwith relative - entropy regularization by @xcite , and the bandit fpl analysis of @xcite ) take the form @xmath57 where @xmath58 is an estimate of the loss @xmath21 , @xmath59 , @xmath60 is a tuning parameter , and @xmath61 is a constant that depends on the particular algorithm and the decision set .",
    "the standard approach is then to design the loss estimates to be _ unbiased _ so that the above bound becomes @xmath62 after taking expectations .",
    "unfortunately , this form does not permit proving first - order bounds as @xmath63 may very well be @xmath64 for either @xmath6 even in very easy problem instances  that is , even an optimized setting of @xmath65 gives a regret bound of @xmath66 at best .",
    "applying a similar line of reasoning , one can replace @xmath1 in the above bound by @xmath67 , the largest total _ gain _",
    "associated with any component , but , as already discussed in the introduction , this improvement is not useful for our purposes .    in this paper , we take a different approach to optimize bounds of the form  .",
    "the idea is to construct a loss - estimation scheme that keeps every @xmath68 `` close '' to @xmath69 , the estimate of the optimal action in the sense that @xmath70 observe that this property allows rewriting the bound   as @xmath71 .",
    "of course , a loss - estimation scheme guaranteeing the above property has to come at the price of a certain bias . guaranteeing that the bias satisfies certain properties and is _ optimistic _ in the sense that @xmath72 , we can arrive at a first - order bound by choosing @xmath73 .",
    "the remaining challenge is to come up with an adaptive learning - rate schedule that achieves such a bound without prior knowledge of @xmath3 .",
    "our approach is not without a precedent : @xcite derive a first - order bound for multi - armed bandits based on very similar principles .",
    "their algorithm , called green , relies on a clever trick that prevents picking arms that seem suboptimal .",
    "specifically , greenmaintains a set of weights @xmath74 over the arms and computes an auxiliary probability distribution @xmath75 .",
    "the true sampling distribution over the arms is computed by setting @xmath76 for all arms such that @xmath77 is below a certain threshold @xmath78 , and then redistributing the removed weight among the remaining arms proportionally to @xmath74 .",
    "the intuitive effect of this thresholding operation is that poorly performing arms are eliminated , which harnesses the further growth of their respective estimated losses .",
    "specifically , @xcite  show that property   and @xmath79 simultaneously hold for their algorithm , paving the way for their first - order bound .",
    "while providing strong technical results , @xcite give little intuition as to why this approach is key to obtaining first - order bounds and how to generalize their algorithm to more complicated problem settings such as ours . even if one is able to come up with a generalization on a conceptual level , efficient implementation of such a variant",
    "would only be possible on a handful of decision sets where exp3can be implemented in the first place ( see , e.g. , @xcite ) .",
    "the probabilistic nature of the approach of @xcite does not seem to mix well with the mirror - descent type algorithms of @xcite either , whose proofs rely on tools from convex analysis . in the current paper",
    ", we propose an alternative way to restrict sampling of suboptimal actions that leads to property   in a much more transparent and intuitive way .",
    "our algorithm is a variant of the well - known follow - the - perturbed - leader ( fpl ) learning algorithm @xcite , equipped with a perturbation scheme that will enable us to prove first - order bounds through guaranteeing property  . in every round @xmath8 ,",
    "fplchooses its action as @xmath80 where @xmath81 is a parameter of the algorithm , @xmath82 is a vector serving as an estimate of the cumulative loss vector @xmath83 and @xmath84 is a vector of random perturbations .",
    "fplis very well - studied in the full - information case where one can choose @xmath85 ; several perturbation schemes are known to work well in this setting @xcite . in what follows ,",
    "we focus on _ exponentially distributed _ perturbations , which is the only scheme known to achieve near - optimal performance guarantees under bandit feedback @xcite .    in order to guarantee that the condition   is satisfied",
    ", we propose to suppress suboptimal actions by using _",
    "bounded - support _ perturbations .",
    "specifically , we propose to use a _ truncated exponential distribution _ with the following density function : @xmath86 $ }    \\\\    0 & \\mbox { otherwise . }",
    "\\end{cases}\\ ] ] here , @xmath87 is the bound imposed on the perturbations . in each round @xmath8 , our fplvariant draws components of the perturbation vector @xmath88 independently from an exponential distribution truncated at @xmath89 , another tuning parameter of our algorithm . to define our loss estimates ,",
    "let us define @xmath90}$ ] and the vector @xmath91 with components @xmath92 where @xmath93 is the so - called _ implicit exploration _ ( or ix ) parameter of the algorithm controlling the bias of the loss estimates .",
    "notice that @xmath94 holds by construction for all @xmath6 .",
    "then , @xmath95 is simply defined as @xmath96 . in",
    "what follows , we refer to our algorithm as fpl - trix , standing for `` fplwith truncated perturbations and implicit exploration '' .",
    "pseudocode for fpl - trixis presented as algorithm  [ alg ] .",
    "* parameters : * learning rates @xmath97 , implicit exploration parameters @xmath98 , truncation parameters @xmath99 . + * initialization : * @xmath100 .",
    "+ * for @xmath13 , repeat *    1 .   draw perturbation vector @xmath88 with independent components @xmath101 .",
    "2 .   play action @xmath102 3 .   for all @xmath6 , observe losses @xmath103 and compute @xmath104 .",
    "4 .   set @xmath105 .",
    "it will also be useful to introduce the notations @xmath106 and @xmath107 . for technical reasons , we are going to assume that the sequence of learning rates @xmath108 , exploration parameters @xmath109 and truncation parameters @xmath110 are all nonincreasing .    before proceeding ,",
    "a few comments are in order .",
    "first , note that the probabilities @xmath111 are generally not efficiently computable in closed form .",
    "this issue can be circumvented by the simple and efficient loss - estimation method proposed by @xcite that produces equivalent estimates on expectation ; we resort to the loss estimates   to preserve clarity of presentation . otherwise , similarly to other fpl - based methods , fpl - trixcan",
    "be efficiently implemented as long as the learner has access to an efficient linear - optimization oracle over @xmath27 .",
    "second , we remark that loss estimates of the form   were first proposed by @xcite as an effective way to trade off the bias and variance of importance - weighted estimates . finally , one may ask if the truncations we introduce are essential for our algorithm to work . answering",
    "this question requires a little deeper technical understanding of fpl - trixthan the reader might have at this point , and thus we defer this discussion to section  [ sec : why ] .",
    "( for the impatient reader , the short answer is that one can get away without truncations at the price of an additive @xmath112 term in the bounds .",
    "note however that the proof of this result still relies on the analysis of fpl - trixthat we present in this paper . )      in this section , we present some key properties of our algorithm .",
    "we first relate the predictions of fpl - trixto those of an fplinstance that employs standard ( non - truncated ) exponential perturbations .",
    "specifically , we study the relation between the expected performance of fpl - trixthat selects the action sequence @xmath113 and an auxiliary algorithm that uses a _ fixed _ exponentially - distributed perturbation vector @xmath114 , and plays @xmath115 in round @xmath8 .",
    "in particular , we are interested in the relation between the quantities @xmath116 } , & { { \\widetilde}{p}}_t({\\boldsymbol{v } } ) = { \\mathbb{p}\\left[\\left.{\\widetilde{{\\boldsymbol{v}}}}_t={\\boldsymbol{v}}\\right|{\\mathcal{f}}_{t-1}\\right ] } ,   \\\\   & q_{t , i } = { \\mathbb{e}\\left[\\left.v_{t , i}\\right|{\\mathcal{f}}_{t-1}\\right ] } , & { { \\widetilde}{q}}_{t , i } = { \\mathbb{e}\\left[\\left.{\\widetilde{v}}_{t , i}\\right|{\\mathcal{f}}_{t-1}\\right]}\\end{aligned}\\ ] ] defined for all @xmath8 , @xmath6 and @xmath117 .",
    "the following lemma establishes a bound on the total variation distance between the distributions induced by @xmath118 and @xmath114 , and thus relates the above quantities to each other .",
    "[ lem : ptrunc ] let the components of @xmath118 and @xmath114 be drawn independently from @xmath119 and @xmath120 , respectively . then , for any function @xmath121 $ ] , we have @xmath122 . in particular",
    ", this implies that @xmath123 for all @xmath8 and @xmath117 and @xmath124 for all @xmath8 and @xmath6 .    for ease of notation ,",
    "define @xmath125 , @xmath126 and @xmath127 .",
    "we first prove @xmath128 . to this end , observe that by the definition of @xmath119 , @xmath129^d } g({\\boldsymbol{z } } ) f_{b_t}({\\boldsymbol{z } } ) \\,d{\\boldsymbol{z}}\\le \\frac{1}{{\\left(1-e^{-b_t}\\right)}^d } \\cdot\\int\\limits_{{\\boldsymbol{z}}\\in[0,\\infty]^d } g({\\boldsymbol{z } } ) f({\\boldsymbol{z } } ) \\,d{\\boldsymbol{z}}= \\frac{{{\\widetilde}{g}}}{{\\left(1-e^{-b_t}\\right)}^d}. \\end{split}\\ ] ] after reordering and using the inequality @xmath130 that holds for all @xmath131 and all @xmath132 , we obtain @xmath133 .",
    "the upper bound on @xmath134 follows from reordering again and using @xmath135 .    to prove the lower bound on @xmath134",
    ", we can use a similar argument as @xmath129^d } g({\\boldsymbol{z } } ) f_{b_t}({\\boldsymbol{z } } ) \\,d{\\boldsymbol{z}}= \\frac{1}{{\\left(1-e^{-b_t}\\right)}^d } \\cdot\\int\\limits_{{\\boldsymbol{z}}\\in[0,b_t]^d } g({\\boldsymbol{z } } ) f({\\boldsymbol{z } } ) \\,d{\\boldsymbol{z}}\\\\ & \\ge \\frac{1}{{\\left(1-e^{-b_t}\\right)}^d } \\cdot\\biggl({{\\widetilde}{g}}- \\int\\limits_{{\\boldsymbol{z}}\\in[b_t,\\infty)^d } f({\\boldsymbol{z } } ) \\,d{\\boldsymbol{z}}\\biggr ) = \\frac{{{\\widetilde}{g}}}{{\\left(1-e^{-b_t}\\right)}^d } - \\frac{1 - { \\left(1-e^{-b_t}\\right)}^d}{{\\left(1-e^{-b_t}\\right)}^d}. \\end{split}\\ ] ] after reordering and using @xmath130 again , we obtain @xmath136 concluding the proof .",
    "the other important property of fpl - trixthat we highlight in this section is that the loss estimates generated by the algorithm indeed satisfy property  .",
    "[ lem : lossbound ] assume that the sequences @xmath97 , @xmath98 and @xmath137 are nonincreasing .",
    "then for any @xmath6 and @xmath18 , we have @xmath138    fix an arbitrary @xmath6 and @xmath117 and let @xmath139 denote the last round in which @xmath140 .",
    "this entails that @xmath141 holds almost surely , as @xmath142 for all @xmath143 . by the construction of the algorithm and the perturbations",
    ", @xmath144 implies that there exists a @xmath145 with @xmath146 and @xmath147 .",
    "thus , @xmath148 where the first inequality follows from the fact that @xmath147 , the second one follows from @xmath149 and the last one from the definition of @xmath150 . after integrating both sides with respect to the distribution of @xmath114 and bounding @xmath151 , we obtain the result as @xmath152 where we used the fact that @xmath153 is nonnegative for all @xmath7 , @xmath154 , and @xmath155\\le   m{\\left(\\log(d / m ) + 1\\right ) } = md$ ] , which follows from lemma  [ lem : expbound ] stated and proved in the appendix .",
    "this section presents our main results concerning the performance of fpl - trixunder various parameter settings .",
    "we begin by stating a key theorem .",
    "[ thm : key ] assume that the sequences @xmath97 , @xmath98 and @xmath137 are nonincreasing and @xmath156 holds for all @xmath8 .",
    "then for all @xmath18 , the total loss suffered by fpl - trixsatisfies @xmath157    the proof of the theorem is deferred to section  [ sec : analysis ] .",
    "armed with this theorem , we are now ready to prove our first main result : a first - order bound on the expected regret of fpl - trix .",
    "[ cor : nonadapt ] consider fpl - trixrun with the time - independent parameters @xmath158 and @xmath159 ( and thus @xmath160 ) . the expected regret of the resulting algorithm satisfies @xmath161 } \\le & \\frac{md}{\\eta } + 3 \\eta m d l_t^ * + 3m^2 d(d+b )    + 3 d.   \\end{split}\\ ] ] in particular , setting @xmath162 guarantees @xmath161 } \\le 5.2m\\sqrt{dl_t^*{\\left(\\log ( d / m)+1\\right ) } } + 1.5 m^2 d \\max{\\left\\{\\log(dl_t^*),0\\right\\ } } + { \\mathcal{o}}{\\left(m^2 d   \\log(d / m)\\right)}.   \\end{split}\\ ] ]    let @xmath163 .",
    "the proof of the first statement follows directly from combining the bounds of theorem  [ thm : key ] and lemma  [ lem : lossbound ] for @xmath164 , taking expectations and noticing that @xmath165\\le l_t^*$ ] . for the second statement , first consider the case when @xmath166 and thus @xmath167 , giving @xmath168 . now notice that the setting of @xmath65 implies @xmath169 and thus @xmath170 .",
    "then , substituting the value of @xmath65 into the first bound of the theorem gives @xmath161 }    \\le & 3 m\\sqrt{3 dl_t^ * d}+ md + 3m^2 d\\bigl(2\\log ( d / m ) + 1\\bigr )     + 3 d ,   \\end{split}\\ ] ] proving the statement as @xmath171 .",
    "for the case @xmath172 , the bound follows from substituting the value of @xmath65 as @xmath161 }    \\le & 2 m\\sqrt{3 dl_t^ * d } + \\frac 32 m^2 d \\log(dl_t^ * ) + 3m^2 d\\bigl(2\\log ( d / m ) + 1\\bigr )    + 3 d ,   \\end{split}\\ ] ] where we used that @xmath173 and @xmath174 .",
    "notice that achieving the above bounds requires _ perfect _ knowledge of @xmath3 , which is usually not available in practice .",
    "while one could use a standard doubling trick to overcome this difficulty , we choose to take a different path to circumvent this issue , and propose a modified version of fpl - trixthat is able to tune its learning rate and other parameters solely based on observations .",
    "we note that our tuning rule has some unorthodox qualities and might be of independent interest .    similarly to the parameter choice suggested by corollary  [ cor : nonadapt ] ,",
    "we will use a single sequence of decreasing non - negative learning rates @xmath97 and set @xmath175 and @xmath176 for all @xmath8 . for simplicity ,",
    "let us define the notations @xmath177 and @xmath178 , with @xmath179 . with these notations ,",
    "we define our tuning rule as @xmath180 notice that @xmath181 , and thus @xmath182 , ensuring that @xmath183 and the algorithm is well - defined .",
    "this follows from the inequality @xmath184 that holds for all @xmath185 .",
    "the delicacy of the tuning rule   is that the terms @xmath186 are themselves bounded in terms of the random quantity @xmath187 , and not some problem - dependent constant . to the best of our knowledge ,",
    "all previously known analyses concerning adaptive learning rates apply a deterministic bound on @xmath186 at some point , largely simplifying the analysis . as we will see below , treating this issue requires a bit more care than usual .",
    "the following theorem presents the performance guarantees of the resulting variant of fpl - trix .",
    "the regret of fpl - trixwith the adaptive learning rates defined in equation   simultaneously satisfies @xmath161 } \\le & 13 m\\sqrt{dl_t^ * { \\left(\\log(d / m ) + 1\\right ) } }    + { \\mathcal{o}}{\\left(m^2 d \\log(dt)\\right ) }   \\end{split}\\ ] ] and @xmath161 } \\le & 13 m\\sqrt{dt { \\left(\\log ( d / m ) + 1\\right ) } } + 9.49 m .",
    "\\end{split}\\ ] ]    let @xmath163 .",
    "first , notice that the learning - rate sequence defined by equation   is nonincreasing as required by theorem  [ thm : key ] . also note that @xmath186 is nonnegative and is bounded by @xmath188 for all @xmath8 , and @xmath189 holds since @xmath190 for all @xmath8 .",
    "these facts together imply that @xmath191 as @xmath192 combining the above bound with lemma  3.5 of @xcite , we get @xmath193 using @xmath194 again , the right - hand side can be further bounded as @xmath195 and the bound of theorem  [ thm : key ] applied for @xmath196 becomes @xmath197    now , we are ready to prove the second bound in the theorem .",
    "notice that @xmath198 holds by the tuning rule and @xmath199 } = \\frac 1d + \\sum_{i=1}^d { \\mathbb{e}\\left[{{\\widehat}{l}}_{t , i}\\right ] } \\le 1 + dt,\\ ] ] where we used that @xmath200 .",
    "the statement then follows from plugging this bound into equation  , taking expectations and using jensen s inequality .",
    "proving the first bound requires a bit more care .",
    "first , an application of lemma  [ lem : lossbound ] gives @xmath201 now recall that @xmath202 holds by the tuning rule .",
    "bounding @xmath203 as above , this implies @xmath204 solving the resulting quadratic equation for the largest possible value of @xmath205 gives @xmath206 the first term can be directly bounded by using jensen s inequality as @xmath207 \\le   \\sqrt{{\\boldsymbol{v}}_*{^\\mathsf{\\scriptscriptstyle t}}{\\boldsymbol{l}}_t } = \\sqrt{l_t^*}$ ] . finally , we bound @xmath208 } \\le \\log(dt + 1)$ ] by using the inequality  @xmath209 .",
    "the statement of the theorem now follows from substituting into equation   and taking expectations .",
    "finally , let us turn to proving our key theorem . for the proof",
    ", we recall the auxiliary forecaster defined in equation   that uses a fixed non - truncated perturbation vector @xmath114 and also define a variant that also allowed to peek one step into the future : @xmath210 we will use the notation @xmath211}$ ] for all @xmath18 .",
    "we start with the following two standard statements concerning the performance of the auxiliary forecaster @xcite .",
    "note that the first of these lemmas slightly improves on the result of @xcite in replacing their @xmath212 factor by @xmath213 . for completeness",
    ", we provide the proof of this improved bound in the appendix .",
    "[ lem : cheat ] for any @xmath18 , @xmath214    [ lem : price ] for all @xmath8 , @xmath215    the following lemma bounds the term on the right - hand side of the above bound .",
    "[ lem : quad ] assume that @xmath216 .",
    "then for all @xmath8 , @xmath217    the statement is proven as @xmath218 } \\le \\sum_{i=1}^d \\frac{v_{t , i } { { \\widetilde}{q}}_{t , i}}{q_{t , i } + \\gamma_t } \\cdot   \\sum_{j=1}^d { { \\widehat}{\\ell}}_{t , j } \\\\&\\le \\sum_{i=1}^d v_{t , i } \\frac{q_{t , i } + \\beta_t d}{q_{t , i } + \\gamma_t } \\cdot   \\sum_{j=1}^d { { \\widehat}{\\ell}}_{t , j } \\le m\\sum_{j=1}^d { { \\widehat}{\\ell}}_{t , j } , \\end{split}\\ ] ] where the first inequality follows from the definitions of @xmath91 and @xmath219 and bounding @xmath220 , the second one follows from using lemma  [ lem : ptrunc ] and the last one from @xmath221 and @xmath222 .",
    "our final lemma quantifies the bias of the learner s estimated losses .    for all @xmath8 , @xmath223",
    "first , note that by lemma  [ lem : ptrunc ] , we have @xmath224 then , the proof is concluded by observing that @xmath225    the statement of theorem  [ thm : key ] follows from piecing the lemmas together .",
    "we conclude by discussing some implications and possible extensions of our results .",
    "[ [ why - truncate ] ] why truncate ? + + + + + + + + + + + + +    one might ask whether truncating the perturbations is really necessary for our bounds to hold .",
    "we now provide an argument that shows that it is possible to achieve similar results _ without _ explicit truncations , if we accept an additive @xmath226 term in our bound . in particular , consider fplwith non - truncated exponential perturbations .",
    "it is easy to see that with probability at least @xmath227 , all perturbations remain bounded by @xmath228 .",
    "one can then analyze fplunder this condition along the same lines as the proof of corollary  [ cor : nonadapt ] , the main difference being that we also have to account for the regret arising from the low - probability event that not all perturbations are bounded . bounding the regret in this case by the trivial bound @xmath229 , this additional term becomes @xmath230 . setting @xmath231 makes the total regret @xmath232however , notice that this gives @xmath233 , which shows up additively in the bound . a similar argument",
    "can be shown to work for the adaptive version of fpl - trix .",
    "we note that the implicit exploration induced by the bias parameter @xmath78 and other techniques developed in this paper are still essential to prove these results .",
    "[ [ high - probability - bounds . ] ] high - probability bounds .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    another interesting question is whether our results can be extended to hold with high probability .",
    "luckily , it is rather straightforward to extend corollary  [ cor : nonadapt ] to achieve such a result by replacing @xmath58 with @xmath234 for an appropriately chosen @xmath235 , as suggested by @xcite .",
    "while such a result would also enable us to handle adaptive environments , it has the same drawback as corollary  [ cor : nonadapt ] : it requires perfect knowledge of @xmath3 . proving high - confidence bounds for the adaptive variant of fpl - trix , however ,",
    "is far less straightforward ; we leave this investigation for future work .",
    "this work was supported by inria , the french ministry of higher education and research , and by fui project herms .",
    "the author wishes to thank the anonymous reviewers for their valuable comments that helped to improve the paper .",
    "31 [ 1]#1 [ 1]`#1 ` urlstyle [ 1]doi : # 1    j.  abernethy , e.  hazan , and a.  rakhlin .",
    "interior - point methods for full - information and bandit online learning .",
    "_ information theory , ieee transactions on _ , 580 ( 7):0 41644175 , july 2012 .",
    "j.  abernethy , c.  lee , a.  sinha , and a.  tewari .",
    "online linear optimization via smoothing . in m .- f . balcan and cs .",
    "szepesvri , editors , _ proceedings of the 27th conference on learning theory _ ,",
    "volume  35 of _ jmlr proceedings _ , pages 807823 .",
    "jmlr.org , 2014 .    c.  allenberg , p.  auer , l.  gyrfi , and .",
    "hannan consistency in on - line learning in case of unbounded losses under partial monitoring . in j.",
    "l. balczar , p.  m. long , and f.  stephan , editors , _ proceedings of the 17th international conference on algorithmic learning theory ( alt 2006 ) _ , volume 4264 of _ lecture notes in computer science _",
    ", pages 229243 , berlin , heidelberg , october 710 2006 .",
    "isbn 978 - 3 - 540 - 46649 - 9 .",
    "audibert and s.  bubeck .",
    "minimax policies for adversarial and stochastic bandits . in _ proceedings of the 22nd annual conference on learning theory ( colt )",
    "_ , 2009 .",
    "audibert and s.  bubeck . regret bounds and minimax policies under partial monitoring .",
    "_ journal of machine learning research _ , 11:0 26352686 , 2010 .",
    "audibert , s.  bubeck , and g.  lugosi .",
    "regret in online combinatorial optimization .",
    "_ mathematics of operations research _ , 39:0 3145 , 2014 .",
    "p.  auer , n.  cesa - bianchi , y.  freund , and r.  e. schapire .",
    "the nonstochastic multiarmed bandit problem .",
    "_ siam j. comput .",
    "_ , 320 ( 1):0 4877 , 2002 .",
    "issn 0097 - 5397 .",
    "p.  auer , n.  cesa - bianchi , and c.  gentile .",
    "adaptive and self - confident on - line learning algorithms . _ journal of computer and system sciences _ , 64:0 4875 , 2002 .",
    "doi : doi:10.1006/jcss.2001.1795 .",
    "n.  cesa - bianchi and g.  lugosi .",
    "_ prediction , learning , and games_. cambridge university press , new york , ny , usa , 2006 .",
    "n.  cesa - bianchi and g.  lugosi .",
    "combinatorial bandits . in s.",
    "dasgupta and a.  klivans , editors , _ proceedings of the 22nd annual conference on learning theory _ , pages 237246 .",
    "omnipress , june 1821 2009 .    n.  cesa - bianchi and g.  lugosi .",
    "combinatorial bandits .",
    "_ journal of computer and system sciences _ , 78:0 14041422 , 2012 .",
    "n.  cesa - bianchi , y.  mansour , and g.  stoltz .",
    "improved second - order bounds for prediction with expert advice . in _ proceedings of the 18th annual conference on learning theory ( colt-2005 )",
    "_ , pages 217232 .",
    "springer , 2005 .",
    "w.  chen , y.  wang , and y.  yuan .",
    "combinatorial multi - armed bandit : general framework and applications . in s.",
    "dasgupta and d.  mcallester , editors , _ proceedings of the 30th international conference on machine learning ( icml 2013 ) _ , volume  28 of _ jmlr workshop and conference proceedings _ , pages 151159 , 2013 .",
    "l.  devroye , g.  lugosi , and g.  neu .",
    "prediction by random - walk perturbation . in s.",
    "i. shalev - shwartz , s. , editor , _ proceedings of the 25th annual conference on learning theory _ , pages 460473 , 2013 .",
    "y.  gai , b.  krishnamachari , and r.  jain .",
    "combinatorial network optimization with unknown variables : multi - armed bandits with linear rewards and individual observations .",
    "_ ieee / acm transactions on networking _ , 200 ( 5):0 14661478 , oct 2012 .",
    "a.  gyrgy , t.  linder , g.  lugosi , and gy ..  ottucsk .",
    "the on - line shortest path problem under partial monitoring .",
    "_ journal of machine learning research _ , 8:0 23692403 , 2007 .",
    "issn 1532 - 4435 .",
    "j.  hannan .",
    "approximation to bayes risk in repeated play .",
    "_ contributions to the theory of games",
    "_ , 3:0 97139 , 1957 .",
    "e.  hazan and s.  kale .",
    "extracting certainty from uncertainty : regret bounded by  variation in  costs . _ machine learning _",
    ", 800 ( 2 - 3):0 165188 , 2010 .",
    "e.  hazan and s.  kale .",
    "better algorithms for benign bandits . _ the journal of machine learning research _ , 12:0 12871311 , 2011 .",
    "m.  hutter and j.  poland .",
    "prediction with expert advice by following the perturbed leader for general weights . in s.",
    "ben - david , j.  case , and a.  maruoka , editors , _ proceedings of the 15th international conference on algorithmic learning theory ( alt ) _ , volume 3244 of _ lecture notes in computer science _ , pages 279293 .",
    "springer , 2004 .",
    "a.  kalai and s.  vempala .",
    "efficient algorithms for online decision problems . _",
    "journal of computer and system sciences _ , 71:0 291307 , 2005 .",
    "t.  kock , g.  neu , m.  valko , and r.  munos .",
    "efficient learning by implicit exploration in bandit problems with side observations . in z.",
    "ghahramani , m.  welling , c.  cortes , n.  lawrence , and k.  weinberger , editors , _ advances in neural information processing systems 27 _ , pages 613621 , 2014 .",
    "w.  m. koolen , m.  k. warmuth , and j.  kivinen .",
    "hedging structured concepts . in _ proceedings of the 23rd annual conference on learning theory ( colt )",
    "_ , pages 93105 , 2010 .",
    "b.  kveton , z.  wen , a.  ashkan , and cs .",
    "tight regret bounds for stochastic combinatorial semi - bandits . in _ aistats _ , 2015 .",
    "g.  neu and g.  bartk .",
    "an efficient algorithm for learning with semi - bandit feedback . in s.",
    "jain , r.  munos , f.  stephan , and t.  zeugmann , editors , _ proceedings of the 24th international conference on algorithmic learning theory _",
    ", volume 8139 of _ lecture notes in computer science _ , pages 234248 .",
    "springer , 2013 .",
    "j.  poland .",
    "analysis for adaptive bandits . in _ in 3rd symposium on stochastic algorithms , foundations and applications ( saga05 ) _ , pages 5869 , 2005 .",
    "a.  rakhlin and k.  sridharan .",
    "online learning with predictable sequences . in s.",
    "i. shalev - shwartz , s. , editor , _ proceedings of the 25th annual conference on learning theory _ , pages 9931019 , 2013 .",
    "s.  rakhlin , o.  shamir , and k.  sridharan .",
    "relax and randomize : from value to algorithms . in _ advances in neural information processing systems 25 _ ,",
    "pages 21502158 . 2012 .",
    "a.  sani , g.  neu , and a.  lazaric .",
    "exploiting easy data in online optimization . in z.",
    "ghahramani , m.  welling , c.  cortes , n.  lawrence , and k.  weinberger , editors , _ advances in neural information processing systems 27 _ , pages 810818 , 2014 .",
    "g.  stoltz .",
    "_ incomplete information and internal regret in prediction of individual sequences_. phd thesis , universit paris - sud , 2005 .",
    "t.  van erven , m.  warmuth , and w.  kotowski .",
    "follow the leader with dropout perturbations . in m .-",
    "balcan and cs .",
    "szepesvri , editors , _ proceedings of the 27th conference on learning theory _ ,",
    "volume  35 of _ jmlr proceedings _ , pages 949974 .",
    "jmlr.org , 2014 .",
    "we first prove a statement regarding the mean of the sum of top @xmath236 out of @xmath28 independent exponential random variables .",
    "[ lem : expbound ] let @xmath237 be i.i.d .  exponential random variables with unit expectation and let @xmath238 be their permutation such that @xmath239 . then",
    ", for any @xmath240 , @xmath241 } \\le m{\\left(\\log{\\left(\\frac dm\\right ) } + 1\\right)}.\\ ] ]    let us define @xmath242 . then , as @xmath243 is nonnegative , we have for any @xmath244 that @xmath245 } = & \\int_0^\\infty { \\mathbb{p}\\left[y > y\\right]}\\,dy      \\\\",
    "\\le & a + \\int_a^\\infty { \\mathbb{p}\\left[\\sum_{i=1}^m z_i^*>y\\right]}\\,dy     \\\\",
    "\\le & a + \\int_a^\\infty { \\mathbb{p}\\left[z_1^*>\\frac ym\\right]}\\,dy     \\\\",
    "\\le & a + d\\int_a^\\infty { \\mathbb{p}\\left[z_1>\\frac ym\\right]}\\,dy      \\\\     = & a + d e^{-a / m } ,    \\end{split}\\ ] ] where the last inequality follows from the union bound . setting @xmath246 minimizes the above expression over the real line , thus proving the statement .      to enhance readability ,",
    "define @xmath247 for @xmath248 and @xmath249 .",
    "we start by applying the classical follow - the - leader / be - the - leader lemma ( see , e.g. , ( * ? ? ?",
    "* lemma  3.1 ) ) to the loss sequence defined as @xmath250 to obtain @xmath251 after reordering and observing that @xmath252 , we get @xmath253 where we used that the sequence @xmath254 is nondecreasing and @xmath255 for all @xmath256 .",
    "the result follows from integrating both sides with respect to the distribution of @xmath114 and applying lemma  [ lem : expbound ] to obtain @xmath257}\\le m{\\left(\\log(d / m)+1\\right)}$ ] ."
  ],
  "abstract_text": [
    "<S> we consider the problem of online combinatorial optimization under semi - bandit feedback , where a learner has to repeatedly pick actions from a combinatorial decision set in order to minimize the total losses associated with its decisions . after making each decision </S>",
    "<S> , the learner observes the losses associated with its action , but not other losses . for this problem , </S>",
    "<S> there are several learning algorithms that guarantee that the learner s expected regret grows as @xmath0 with the number of rounds @xmath1 . in this paper </S>",
    "<S> , we propose an algorithm that improves this scaling to @xmath2{l_t^*}})$ ] , where @xmath3 is the total loss of the best action . </S>",
    "<S> our algorithm is among the first to achieve such guarantees in a partial - feedback scheme , and the first one to do so in a combinatorial setting .    </S>",
    "<S> online learning , online combinatorial optimization , semi - bandit feedback , follow the perturbed leader , improvements for small losses , first - order bounds </S>"
  ]
}