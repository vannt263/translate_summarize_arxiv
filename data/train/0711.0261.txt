{
  "article_text": [
    "bit - flipping ( bf ) algorithms for decoding low - density parity - check ( ldpc ) codes @xcite have been investigated extensively and many variants of bf algorithms such as weighted bf ( wbf ) @xcite , modified weighted bf ( mwbf ) @xcite , and other variants @xcite have been proposed .",
    "the first bf algorithm was developed by gallager @xcite . in a decoding process of gallager s",
    "algorithm , some unreliable bits ( in a binary quantized received word ) corresponding to unsatisfied parity checks are flipped for each iteration .",
    "the successors of gallager s bf algorithm inherits the basic strategy of gallager s algorithm , namely , find unreliable bits and then flip them .",
    "although the bit error rate ( ber ) performance of the bf algorithm is inferior to that of the sum - product algorithm or the min - sum algorithm , in general , the bf algorithm enables us to design a much simpler decoder , which is easier to implement .",
    "thus , bridging the performance gap between bf decoding and bp decoding is an important technical challenge .    in the present paper , a novel class of bf algorithms for decoding ldpc codes",
    "is presented .",
    "the proposed algorithm , which are called _ gradient descent bit flipping ( gdbf ) algorithms _ , can be regarded as bit - flipping gradient descent algorithms .",
    "the proposed algorithms are naturally derived from a simple gradient descent formulation .",
    "the behavior of the proposed algorithm can be explained from the viewpoint of the optimization of a non - linear objective function .",
    "let @xmath2 be a binary @xmath3 parity check matrix , where @xmath4 .",
    "the binary linear code @xmath5 is defined by @xmath6 where @xmath7 denotes the binary galois field . in the present paper , a vector",
    "is assumed to be a column vector . for convention , we introduce the bipolar codes @xmath8",
    "corresponding to @xmath5 as follows : @xmath9 namely , @xmath8 , which is a subset of @xmath10 , is obtained from @xmath5 by using binary @xmath11 to bipolar @xmath12 conversion .",
    "the binary - input awgn channel is assumed in the paper , which is defined by @xmath13 ( @xmath14 ) .",
    "the vector @xmath15 is a white gaussian noise vector where @xmath16)$ ] is an i.i.d .",
    "gaussian random variable with zero mean and variance @xmath17 .",
    "the notation @xmath18 $ ] denotes the set of consecutive integers from @xmath19 to @xmath20 .",
    "let @xmath21 and @xmath22 , j \\in [ 1,n])$ ] be @xmath23 : h_{ij } = 1    \\}$ ] and @xmath24 : h_{ij } = 1    \\}$ ] where @xmath25 is the @xmath26-element of the parity check matrix @xmath2 . using this notation , we can write the parity condition as : @xmath27 ) $ ] which is equivalent to @xmath28 .",
    "the value @xmath29 is called the @xmath30-th _ bipolar syndrome _ of @xmath31 .      a number of variants of bf algorithms have been developed .",
    "we can classify the bf algorithms into two - classes : single bit flipping ( single bf ) algorithms and multiple bits flipping ( multi bf ) algorithms . in the decoding process of the single bf algorithm ,",
    "only one bit is flipped according to its bit flipping rule . on the other hand ,",
    "the multi bf algorithm allows multiple bit flipping per iteration in a decoding process . in general , although the multi bf algorithm shows faster convergence than the single bf algorithm , the multi bf algorithm suffers from the oscillation behavior of a decoder state , which is not easy to control .",
    "the framework of the single bf algorithms is summarized as follows :    the function @xmath32 is defined by @xmath33 in a decoding process of the single bf algorithm , hard decision decoding for a given @xmath34 is first performed , and @xmath31 is initialized to the hard decision result .",
    "the minimum of the inversion function @xmath35 for @xmath36 $ ] is then found is an integer - valued function , we need a tie - break rule to resolve a tie . ] .",
    "an inversion function @xmath35 can be seen as a measure of the invalidness of bit assignment on @xmath37 .",
    "the bit @xmath38 , where @xmath39 gives the smallest value of the inversion function , is then flipped .",
    "the inversion functions of wbf @xcite are defined by @xmath40 the values @xmath41)$ ] is the _ reliability _ of bipolar syndromes defined by @xmath42 in this case , the inversion function @xmath43 gives the measure of invalidness of symbol assignment on @xmath37 , which is given by the sum of the weighted bipolar syndromes .",
    "the inversion functions of mwbf @xcite has a similar form of the inversion function of wbf but it contains a term corresponding to a received symbol . the inversion function of mwbf is given by @xmath44 where the parameter @xmath45 is a positive real number .",
    "it seems natural to consider that the dynamics of a bf algorithm as a minimization process of a hidden objective function .",
    "this observation leads to a gradient descent formulation of bf algorithms .",
    "the maximum likelihood ( ml ) decoding problem for the binary awgn channel is equivalent to the problem of finding a ( bipolar ) codeword in @xmath8 , which gives the largest correlation to a given received word @xmath34 .",
    "namely , the mld rule can be written as @xmath46    based on this correlation decoding rule , we here define the following objective function : @xmath47 the first term of the objective function corresponds to the correlation between a bipolar codeword and the received word , which should be maximized .",
    "the second term is the sum of the bipolar syndromes of @xmath31 . if and only if @xmath48 , then the second term has its maximum value @xmath49 thus , this term can be considered as a _ penalty term _ , which forces @xmath31 to be a valid codeword .",
    "note that this objective function is a non - linear function and has many local maxima .",
    "these local maxima become a major source of sub - optimality of the gdbf algorithm presented later .      for the numerical optimization problem for a differentiable function such as ( [ gdbfobjective ] ) , the gradient descent method @xcite is a natural choice for the first attempt .",
    "the partial derivative of @xmath50 with respect to the variable @xmath51)$ ] can be immediately derived from the definition of @xmath50 : @xmath52    let us consider the product of @xmath37 and the partial derivative of @xmath37 in @xmath31 , namely @xmath53 for a small real number @xmath54 , we have the first - order approximation : @xmath55 when @xmath56 , we need to choose @xmath57 in order to have @xmath58 on the other hand , if @xmath59 holds , we should choose @xmath60 to obtain the inequality ( [ larger ] ) .",
    "therefore , if @xmath61 , then flipping the @xmath62th symbol ( @xmath63 ) may increase the objective function value .    one reasonable way to find a flipping position is to choose the position at which the absolute value of the partial derivative is largest .",
    "this flipping rule is closely related to the steepest descent algorithm based on @xmath64-norm ( also known as the _ coordinate descent algorithm _ ) @xcite . according to this observation",
    ", we have the following rule to choose the flipping position .    the single bf algorithm based on the inversion function @xmath65",
    "is called the gradient descent bf ( gdbf ) algorithm .",
    "thus , the decoding process of the gdbf algorithm can be seen as the minimization process of @xmath66 ( it can be considered as the _ energy _ of the system ) based _ bit - flipping _ gradient descent method .",
    "it is interesting to see that the combination of the objective function @xmath67 defined by @xmath68 and the argument on gradient descent presented above gives the inversion functions of conventional algorithms such as the wbf algorithm ( [ invwbf ] ) and the mwbf algorithm ( [ invmwbf ] ) .",
    "however , this objective function ( [ wbfobj ] ) looks less meaningful compared with the objective function ( [ gdbfobjective ] ) . in other words , the inversion function @xmath69 defined in ( [ eqconv ] ) has a more natural interpretation than those of the conventional algorithms : @xmath43 in ( [ invwbf ] ) and @xmath70 in ( [ invmwbf ] ) .",
    "actually , the new inversion function @xmath69 is not only natural but also _ effective _ in terms of bit error performance and convergence speed .",
    "a decoding process of the gdbf algorithm can be regarded as a maximization process of the objective function ( [ gdbfobjective ] ) in a gradient ascent manner .",
    "thus , we can utilize the objective function value in order to observe the convergence behavior .",
    "for example , it is possible to monitor the value of the objective function for each iteration .",
    "in the first several iterations , the value increases as the number of iterations increases .",
    "however , the value eventually ceases to increase when the search point arrives at the nearest point in @xmath71 to the local maximum of the objective function .",
    "we can easily detect such convergence to a local maximum by observing the value of the objective function .",
    "both the bf algorithms reviewed in the previous section and the gdbf algorithm flip only one bit for each iteration . in terms of the numerical optimization , in these algorithms , a search point moves towards a local maximum with a very small step ( i.e. , 1 bit flip ) in order to avoid oscillation around the local maximum ( see fig.[localmax ] ( a ) ) .",
    "however , the small size step leads to slower convergence to a local maximum . in general , compared with the min - sum algorithm , bf algorithms ( single flip / iteration ) require a larger number of iterations to achieve the same bit error probability .    the multi bit flipping algorithm",
    "is expected to have a faster convergence speed than that of the single bit flipping algorithm because of its larger step size .",
    "if the search point is close to a local maximum , a fixed large step is not suitable to find the ( near ) local maximum point ; it leads to oscillation behavior of a multi - bit flipping bf algorithm ( fig.[localmax](b ) ) .",
    "we need to adjust the step size dynamically from a large step size to a small step size in an optimization process ( fig.[localmax](c ) ) .     + ( a )",
    "converging but slow , ( b ) not converging but fast , ( c ) converging and fast    the objective function is a useful guideline for adjusting the step size ( i.e. , number of flipping bits ) .",
    "the _ multi gdbf algorithm _ is a gdbf algorithm including the multi - bit flipping idea . in the following , we assume the inversion function @xmath69 defined by ( [ eqconv ] ) ( the inversion function for the gdbf algorithm ) .",
    "the flow of the multi gdbf algorithm is almost the same as that of the previously presented gdbf algorithm . when it is necessary to clearly distinguish two decoding algorithms , the gdbf algorithm presented in the previous sub - subsection is referred to as the single gdbf algorithm .",
    "in order to define the multi gdbf algorithm , we need to introduce new parameters @xmath72 and @xmath73 .",
    "the parameter @xmath72 is a negative real number , which is called the _",
    "inversion threshold_. the binary ( 0 or 1 ) variable @xmath73 , which is called the _ mode flag _ , is set to 0 at the beginning of the decoding process .",
    "step 3 of the bf algorithm should be replaced with the following multi - bit flipping procedure .",
    "usually , at the beginning of a decoding process , the objective function value increases as the number of iterations increases in the multi - bit mode , namely , @xmath74 holds for the first few iterations .",
    "when the search point eventually arrives at the point satisfying @xmath75 , the bit flipping mode is changed from the multi - bit mode ( @xmath76 ) to the single - bit mode ( @xmath77 ) .",
    "this mode change means adjustment of the step size , which helps a search point to converge to a local maximum when the search point is located close to the local maximum .",
    "in this section , the behavior and decoding performance of ( single and multi ) gf - bf algorithms obtained from computer simulations are presented .",
    "figure [ regular - objval ] presents objective function values ( [ gdbfobjective ] ) as a function of the number of iterations in the single and multi gdbf processes . throughout the present paper , a regular ldpc code with @xmath78 ( called pegreg504x1008 in @xcite )",
    "is assumed .",
    "the column weight of the code is 3 . in both cases ( single and multi )",
    ", we tested the same noise instance , and both algorithms output the correct codeword ( i.e. , successful decoding ) .    in the case of the single gdbf - algorithm ,",
    "the objective function value gradually increases as the number of iterations grows in the first 5060 iterations . after the slope , the increment of the objective function value eventually stops , and a flat part that corresponds to a local maximum appears . in the flat part of the curves ,",
    "the oscillation behavior of the objective function value can be seen . due to the constraint",
    "such that a search point @xmath31 must lie in @xmath79 , a gdbf process can not find a true local maximum point ( the point where the gradient of the objective function becomes a zero vector ) of the objective function .",
    "thus , a search point moves around the local maximum point .",
    "this move causes the oscillation behavior observed in a single gdbf process .",
    "the curve corresponding to the multi gdbf algorithm shows much faster convergence compared with the single gdbf algorithm .",
    "it takes only 15 iterations for the search point to come very close to the local maximum point .",
    "+ snr=4 db    figure [ regular - single ] presents the bit error curves of single and multi gdbf algorithms ( @xmath80 ) . as references ,",
    "the curves for the wbf algorithm ( @xmath81 ) , the mwbf algorithms ( @xmath82 ) , and the normalized min - sum algorithm ( @xmath83 , scale factor 0.8 ) are included as well .",
    "the parameter @xmath84 denotes the maximum number of iterations for each algorithm .",
    "we can see that the gdbf algorithms perform much better than the wbf and mwbf algorithms .",
    "for example , at ber @xmath85 , the multi gdbf algorithm offers a gain of approximately 1.6 db compared with the mwbf algorithm .",
    "compared with the single gdbf algorithm , the multi gdbf algorithm has a steeper slope in its error curve .",
    "unfortunately , there is still a large performance gap between the error curves of the normalized min - sum algorithm and the gdbf algorithms .",
    "the gdbf algorithm fails to decode when a search point is attracted to an undesirable local maximum of the objective function .",
    "this large performance gap suggests the existence of some local maxima relatively close to a bipolar codeword , which degrades the ber performance .",
    "+    figure [ irregular - single ] shows error curves for an irregular ldpc code .",
    "the code used in the simulation is an irregular code ( called pegirreg504x1008 in @xcite ) constructed based on peg construction . the same decoding algorithms ( with same parameter ) appeared in fig.[regular - single ] have been tested . as well as the regular case , the error curves of gd - bf algorithms come bellow those of wbf and mwbf algorithms",
    ". however , the improvement is relatively small compared with the regular case .",
    "this observation may imply that the advantage of gd - bf algorithm in ber depends on type of the code .     +    in order to evaluate the convergence speed of bf algorithms ,",
    "the average number of iterations is an appropriate measure .",
    "figure [ regular - aveitr ] shows the average number of iterations ( as a function of snr ) of the gdbf algorithms ( single and multi ) , the wbf algorithm , and the mwbf algorithms .",
    "note that the multi gdbf algorithm certainly have a fast convergence property .",
    "large gaps can be observed between the curve of the multi gdbf algorithm and the other curves",
    ".     + @xmath81",
    "as we have discussed , a decoding failure occurs when a search point is captured by a local maximum , which is not a transmitted codeword .",
    "thus , it is desirable to know the effect of such local maxima .",
    "figure [ trajectory ] presents three trajectories of weight and syndrome weight of a search point in three decoding processes corresponding to decoding failure .",
    "the weight of a search point @xmath31 is defined by @xmath86 : x_j = -1 \\}| .",
    "$ ] in a similar way , the syndrome weight of @xmath31 is given by @xmath87 :   \\prod_{j \\in n(i ) } x_j = -1 \\right\\ } \\right| .",
    "$ ] we assume that the all-1 bipolar codeword ( i.e. , all - zero binary codeword ) is transmitted without loss of generality .",
    "we can obtain the following observation from fig.[trajectory ] : ( i ) the decoding process starts from the position at which both @xmath88 and @xmath89 are large , ( ii ) @xmath88 and @xmath89 decreases as the iteration proceeds , and ( iii ) the final states of the search point have a relatively small value of @xmath88 and @xmath89 .",
    "+    based on these observations , we may be able to conjecture that a search point is finally trapped by a local maximum close to a _ near codeword _ in high probability .",
    "near codewords @xcite are bipolar codewords of @xmath8 that have both small weight and small syndrome weight .",
    "the sub - optimality of bf - algorithms compared with sum - product and min - sum algorithms comes from the effect of these numerous local maxima .",
    "since the weight of the final position of a search point is so small , a small perturbation of a captured search point appears to be helpful for the search point to escape from an undesirable local maximum .",
    "we can expect that such a perturbation process improves the ber performance of bf algorithms .",
    "one of the simplest ways to add a perturbation on a trapped search point is to switch the flip mode from the single - bit mode to the multi - bit mode with an appropriate threshold forcibly when the search point arrives at a non - codeword local maximum .",
    "this additional process is called the _",
    "escape process_. in general , the escape process reduces the object function value , i.e. , the search point moves downwards in the energy landscape . after the escape process , the search point again begins to climb a hill , which may be different from the trapped point .",
    "we here modify the multi gdbf algorithm by incorporating two thresholds : @xmath90 and @xmath91 .",
    "the threshold @xmath90 is the threshold constant used in the multi - bit mode at the beginning of the decoding process .",
    "after several iterations , the multi - bit mode is changed to single - bit mode and then the search point may eventually arrive at the non - codeword local maximum .",
    "in such a case , the decoder changes its mode to the multi - bit mode ( i.e. , @xmath76 ) with threshold @xmath91 .",
    "thus , the threshold @xmath91 can be regarded as the threshold for _ downward movement_. although @xmath91 can be a constant value , in terms of the ber performance , it is advantageous to choose randomly . in other words , @xmath91 can be a random variable .",
    "after the downward move ( just one iteration ) , the decoder changes the threshold to @xmath90 again .",
    "the above process continues until the parity check condition holds or the number of iterations becomes @xmath84 .",
    "figure [ escapeprocess ] illustrates the idea of the escape process .",
    "+      figure [ escape ] shows the ber curve of such a decoding algorithm ( labeled multi gdbf with escape ) . in this simulation",
    ", we used the parameters : @xmath92 where @xmath45 is a gaussian random number with mean zero and variance 0.01 .",
    "these parameters have been obtained an ad hoc optimization at snr = 4db .",
    "we can see that the ber curve of multi gdbf with escape ( with @xmath93 ) is much steeper than that of the naive multi gdbf algorithm .",
    "at ber = @xmath94 , multi gdbf with escape achieves a gain of almost 1.5 db compared with the naive multi gdbf algorithm .",
    "the average number of iterations of multi gdbf with escape is approximately 25.6 at snr = 4 db .",
    "this result implies that the perturbation can actually save some trapped search points to converge to the desirable local maximum corresponding to the transmitted codeword .",
    "it is an interesting open problem to optimize the flipping schedule to narrow the gap between the min - sum ber curve and the gdbf ber curve .",
    "this paper presents a class of bf algorithms based on the gradient descent algorithm .",
    "gdbf algorithms can be regarded as a maximization process of the object function using bit - flipping gradient descent method ( i.e. , bit - flipping dynamics which minimizes the energy @xmath66 ) .",
    "the gradient descent formulation naturally introduces an energy landscape of the state - space of the bf - decoder . the viewpoint obtained by",
    "this formulation brings us a new way to understand convergence behaviors of bf algorithms .",
    "furthermore this viewpoint is also useful to design improved decoding algorithms such as the multi gdbf algorithm and the gdbf algorithm with escape process from an undesired local maximum .",
    "the gdbf algorithm with escape process performs very well compared with known bf algorithms .",
    "one lesson we have learned from this result is that fine control on flipping schedule is indispensable to improve decoding performance of bf algorithms .",
    "the present study was supported in part by the ministry of education , science , sports , and culture of japan through a grant - in - aid for scientific research on priority areas ( deepening and expansion of statistical informatics ) 180790091 and by a research grant from the storage research consortium ( src ) ."
  ],
  "abstract_text": [
    "<S> a novel class of bit - flipping ( bf ) algorithms for decoding low - density parity - check ( ldpc ) codes is presented . </S>",
    "<S> the proposed algorithms , which are called _ gradient descent bit flipping ( gdbf ) algorithms _ , can be regarded as simplified gradient descent algorithms . based on gradient descent formulation , </S>",
    "<S> the proposed algorithms are naturally derived from a simple non - linear objective function .    </S>",
    "<S> @xmath0 : nagoya institute of technology , @xmath1 : meijo university . </S>"
  ]
}