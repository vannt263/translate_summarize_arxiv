{
  "article_text": [
    "in the era of big data analytics , cloud computing and internet of things , the growing demand of massive data processing challenges existing network resource allocation approaches .",
    "huge volumes of data acquired online with distributed sensors in the presence of operational uncertainties caused by , e.g. , renewable energy sources , call for scalable and adaptive network control schemes",
    ". scalability of a desirable approach refers to low complexity and amenability to distributed implementation , while adaptivity implies capability of online adjustment to dynamic environments .",
    "allocation of network resources can be traced back to the seminal work of @xcite . since then , popular allocation algorithms operating in the dual domain are first - order methods based on dual gradient ascent , either deterministic @xcite or stochastic @xcite . due to the simplicity in computation and implementation , these approaches have attracted a great deal of recent interest and have been successfully applied to cloud , transportation and power grid networks ; see , e.g. , @xcite .",
    "however , their major limitation is slow convergence , which results in high network delay . here",
    ", the delay can be viewed as workload queuing time in a cloud network , traffic congestion in a transportation network , or energy level of batteries in a power network . to address this issue",
    ", recent attempts aim at accelerating first- and second - order optimization algorithms @xcite .",
    "specifically , momentum - based accelerations over first - order methods were investigated using nesterov @xcite , or , heavy - ball iterations @xcite .",
    "though these approaches work well in static settings , their performance degrades with online scheduling , as evidenced by the increase in accumulated steady - state error @xcite . on the other hand ,",
    "second - order methods such as decentralized quasi - newton approach and its dynamic variant developed in @xcite and @xcite , incur high overhead to compute and communicate the decentralized hessian approximations .    capturing prices of resources ,",
    "lagrange multipliers play a central role in stochastic resource allocation algorithms @xcite . given abundant historical data in an online optimization setting , a natural question arises : _ is it possible to learn the optimal prices from past data , so as to improve the quality of online resource allocation strategies ? _",
    "the rationale here is that past data contains statistics of network states , and learning from them can aid coping with the stochasticity of future resource allocation .",
    "a recent work attempting to address this question is @xcite , which considers resource allocation with a _ finite _ number of possible network states and allocation actions .",
    "the learning procedure , however , involves constructing a histogram to estimate the underlying distribution of the network states and explicitly solves an empirical dual problem . while constructing a histogram is feasible for a probability distribution with finite support , quantization errors and prohibitively high complexity are inevitable for a continuous distribution with infinite support .    in this context",
    ", the present paper aims to design a novel online resource allocation algorithm that leverages online learning from historical data for stochastic optimization of the ensuing allocation stage .",
    "the resultant approach , which we term `` learn - and - adapt '' stochastic dual gradient ( la - sdg ) method , only doubles computational complexity of the classic stochastic dual gradient ( sdg ) method . with this minimal cost",
    ", la - sdg mitigates steady - state oscillation , which is common in stochastic first - order acceleration methods @xcite , while avoiding computation of the hessian approximations present in the second - order methods @xcite .",
    "specifically , la - sdg only requires one more past sample to compute an extra stochastic dual gradient , in contrast to constructing costly histograms and solving the resultant large - scale problem @xcite .",
    "the main contributions of this paper are summarized next .",
    "1 .   targeting a low - complexity online solution , la - sdg only takes an additional dual gradient step relative to the classic sdg iteration .",
    "this additional dual gradient step plays the role of adapting the future resource allocation strategy through learning from historical data .",
    "meanwhile , la - sdg is linked with the stochastic heavy - ball method , nicely inheriting its fast convergence in the initial stage , while reducing its steady - state oscillation .",
    "2 .   we analytically establish that the novel la - sdg approach , parameterized by a positive constant @xmath0 , yields a very attractive cost - delay tradeoff @xmath1 $ ] , which is better than the standard tradeoff @xmath2 $ ] of the classic sdg method @xcite .",
    "numerical tests further corroborate the performance gain of la - sdg over existing resource allocation schemes .",
    "_ outline_. the rest of the paper is organized as follows .",
    "the stochastic network resource allocation problem is formulated in section ii , along with the standard sdg approach introduced in section iii .",
    "the la - sdg method is the subject of section iv .",
    "performance analysis of la - sdg is carried out in section v. numerical tests are provided in section vi , followed by concluding remarks in section vii .    _",
    "notation_. @xmath3 denotes the expectation operator , @xmath4 stands for probability ; @xmath5 stands for vector and matrix transposition , and @xmath6 denotes the @xmath7-norm of a vector @xmath8 .",
    "inequalities for vectors , e.g. , @xmath9 , are defined entry - wise .",
    "the positive projection operator is defined as @xmath10^+:=\\max\\{a,0\\}$ ] , also entry - wise .",
    "in this section , we start with a generic network model and its resource allocation task in section [ subsec.pf ] , and then introduce a specific example of resource allocation in cloud networks in section [ subsec.exp ] .",
    "the proposed approach is applicable to more general network resource allocation tasks such as geographical load balancing in cloud networks @xcite , traffic control in transportation networks @xcite , and energy management in power networks @xcite .",
    "consider discrete time @xmath11 , and a network represented as a directed graph @xmath12 with nodes @xmath13 and edges @xmath14 .",
    "collect the workloads across edges @xmath15 in a resource allocation vector @xmath16 .",
    "the @xmath17 node - incidence matrix is formed with the @xmath18-th entry @xmath19 we assume that each row of @xmath20 has at least one @xmath21 entry , and each column of @xmath20 has at most one @xmath21 entry , meaning that each node has at least one outgoing link , and each link has at most one source node . with @xmath22 collecting the random workload arrival rates of all nodes per slot @xmath23 , the aggregate ( endogenous plus exogenous ) workloads of all nodes are @xmath24 . if the @xmath25-th entry of @xmath24 is positive , there is service residual queued at node @xmath25 ; otherwise , node @xmath25 over - serves the current arrival . with a workload queue per node ,",
    "the queue length vector @xmath26^{\\top}\\in \\mathbb{r}_+^{i}$ ] obeys the recursion @xmath27^{+}\\!,~\\forall t.\\ ] ] defining @xmath28 as the aggregate network cost parameterized by the random vector @xmath29 , the local cost per node @xmath25 is @xmath30 , and @xmath31 .",
    "the model here is quite general .",
    "the duration of time slots can vary from ( micro-)seconds in cloud networks , minutes in road networks , to even hours in power networks ; the nodes can present the distributed front - end mapping nodes and back - end data centers in cloud networks , intersections in traffic networks , or , buses and substations in power networks ; the links can model wireless / wireline channels , traffic lanes , and power transmission lines ; while the resource vector @xmath32 can include the size of data workloads , the number of vehicles , or the amount of energy .",
    "vector @xmath33 can represent user requests in data queues , cars waiting at road intersections , and amounts of energy in batteries .    concatenating the random parameters into a random state vector @xmath34^{\\top}$ ] , the resource allocation task is to determine the allocation @xmath32 in response to the observed ( realization ) @xmath35 `` on the fly , '' so as to minimize the _ long - term average _ network cost subject to queue stability at each node , and operation feasibility at each link .",
    "concretely , we have      where @xmath37 is the optimal objective of problem given all the future information ; @xmath3 is taken over @xmath35 as well as possible randomness of optimization variables @xmath32 and @xmath33 ; constraints ensure the queue stability ; and constrains the instantaneous allocation variables to be within a time - invariant box constraint set @xmath38 , which is specified by , e.g. , link capacities , or , server / generator capacities .",
    "the queue dynamics in couple the optimization variables over an infinite time horizon , which implies that the decision variable at current slot will have effect on all the future decisions .",
    "therefore , finding an optimal solution to calls for dynamic programming @xcite , which is known to suffer from the `` curse of dimensionality '' and intractability in an online setting . in section [ subsec.reform ] , we will circumvent this obstacle by relaxing - to limiting average constraints , and employing dual decomposition techniques .",
    "the geographic load balancing task in cloud networks @xcite takes the form of with @xmath39 being the set of mapping nodes ( e.g. , dns servers ) , @xmath40 data centers , and @xmath41 links connecting mapping nodes with data centers . per time",
    "@xmath23 , each mapping node @xmath42 collects the amount of user data requests @xmath43 , and forwards the amount @xmath44 to data center @xmath45 constrained by the bandwidth availability . each data center @xmath45 schedules workload processing @xmath46 according to its resource availability . to match the definition of node - incidence matrix in , we assume a virtual outgoing node from each data center @xmath45 , so that @xmath46 is the amount of resources on this outgoing link .",
    "the bandwidth limit of link @xmath47 is @xmath48 , and the resource capability of data center @xmath45 is @xmath49 . in this case",
    ", we have @xmath50^{\\top}$ ] , @xmath51^{\\top}$ ] , and @xmath52^{\\top}$ ] . at each mapping node and data center ,",
    "undistributed or unprocessed workloads are buffered in queues obeying ; see fig .",
    "[ fig : system ] for a system diagram .",
    ", mapping node @xmath42 has an exogenous workload @xmath43 plus that stored in the queue @xmath53 , and schedules workload @xmath44 to data center @xmath45 .",
    "data center @xmath45 serves an amount of workload @xmath46 out of the assigned @xmath44 as well as that stored in the queue @xmath54 .",
    "the thickness of each edge is proportional to its capacity.,scaledwidth=49.0% ]    [ fig : system ]    performance is characterized by the aggregate cost of power consumed at the data centers plus the bandwidth costs at the mapping nodes , namely @xmath55 the power cost @xmath56 , parameterized by the random vector @xmath57 , captures the local marginal price and the renewable generation at data center @xmath45 during time period @xmath23 .",
    "the bandwidth cost @xmath58 , parameterized by the random vector @xmath59 , characterizes the heterogeneous cost of data transmission due to spatio - temporal differences . with the goal of minimizing the time - average of",
    ", geographical load balancing fits the formulation in .",
    "in this section , the dynamic problem is reformulated to a tractable form , and classical stochastic dual gradient ( sdg ) approach is revisited , along with a brief discussion of its online performance .",
    "recall in section [ subsec.pf ] that the main challenge of solving resides in time - coupling constraints and unknown distribution of the underlying random processes .",
    "regarding the first hurdle , combining with , it can be shown that in the long term , workload arrival and departure rates must satisfy the following necessary condition ( * ? ? ? * theorem 2.8 ) @xmath60\\leq \\mathbf{0}\\ ] ] given that the initial queue length is finite , i.e. , @xmath61 .",
    "in other words , on average all buffered delay - tolerant workloads should be served .",
    "using , a relaxed version of is @xmath62 ~~ \\text{s.t.}~ \\eqref{eq.probl}~\\text{and}~\\eqref{queue - relax}\\end{aligned}\\ ] ] where @xmath63 is the optimal objective for the relaxed problem .",
    "compared to , problem eliminates the time coupling across variables @xmath64 by replacing and with .",
    "since is a relaxed version of with the optimal objective @xmath65 , if one solves instead of , it will be prudent to derive an optimality bound on @xmath37 , provided that the sequence of solutions @xmath66 obtained by solving is feasible for the relaxed constraints and . regarding the relaxed problem , using arguments similar to those in ( * ? ? ?",
    "* theorem 4.5 ) , it can be shown that if the random state @xmath35 is independent and identically distributed ( i.i.d . ) over time @xmath23 , there exists a _",
    "stationary _ control policy @xmath67 , which is a pure ( possibly randomized ) function of the realization of random state @xmath35 ( or the _ observed _ state @xmath35 ) ; i.e. , it satisfies , as well as guarantees that @xmath68 = \\tilde{\\psi}^{*}$ ] and @xmath69\\leq \\mathbf{0}$ ] .",
    "as the optimal policy @xmath67 is time invariant , it implies that the _ dynamic _ problem is equivalent to the following time - invariant _ ensemble _ program      where @xmath71 , @xmath72 , and @xmath73 ; set @xmath74 is the sample space of @xmath35 , and the constraint holds almost surely .",
    "observe that the index @xmath23 in can be dropped , since the expectation is taken over the distribution of random variable @xmath35 , which is time - invariant .",
    "leveraging the equivalent form , the remaining task boils down to finding the optimal policy that achieves the minimal objective in and obeys the constraints and .",
    ", which can be time - independent ( * ? ? ?",
    "* theorem 4.5 ) . ]",
    "note that the optimization in is with respect to a stationary policy @xmath75 , which is an infinite dimensional problem in the primal domain .",
    "however , there is a finite number of expected constraints [ cf . ] .",
    "thus , the dual problem contains a finite number of variables , hinting to the effect that solving is tractable in the dual domain @xcite .      with @xmath76 denoting the lagrange multipliers associated with , the lagrangian of is @xmath77\\ ] ] where the instantaneous lagrangian is @xmath78 and constraint remains implicit .",
    "notice that the instantaneous objective @xmath79 and the instantaneous constraint @xmath24 are both parameterized by the observed state @xmath34^{\\top}$ ] at time @xmath23 ; thus , the instantaneous lagrangian can be written as @xmath80 , so that @xmath81 $ ] .    correspondingly , the lagrange dual function is defined as the minimum of the lagrangian over the all feasible primal variables @xcite , given by    [ eq.dual-func ] @xmath82.\\end{aligned}\\ ] ] due to the linearity of the expectation operator and the separability of the instantaneous lagrangian defined by the realization @xmath35 , we can interchange the minimization and the expectation , and re - write the dual function in the following form @xmath83\\!=\\!\\mathbb{e}\\!\\left[\\min_{\\mathbf{x}_t \\in { \\cal x}}{\\cal l}_t(\\mathbf{x}_t,\\bm{\\lambda})\\right]\\!.\\!\\!\\end{aligned}\\ ] ]    likewise , for the instantaneous dual function @xmath84 , the dual problem of is @xmath85.\\end{aligned}\\ ] ] in accordance with the ensemble primal problem , we will henceforth refer to as the _ ensemble _ dual problem .",
    "if the optimal lagrange multiplier @xmath86 associated with were known , then optimizing and consequently would be equivalent to minimizing the lagrangian @xmath87 or infinitely many instantaneous @xmath88 , over the set @xmath38 ( * ? ? ?",
    "3.3.4 ) and @xcite .",
    "we restate this assertion as follows .",
    "[ prop.closedform ] consider the optimization problem in .",
    "given a realization @xmath35 , and the optimal lagrange multiplier @xmath86 associated with the constraints , the optimal instantaneous resource allocation decision is @xmath89 where @xmath90 accounts for possibly multiple minimizers of @xmath91 .",
    "when the realizations @xmath92 are obtained sequentially , one can generate a sequence of optimal solutions @xmath93 correspondingly for the dynamic problem . to obtain the optimal allocation in however , @xmath86 must be known .",
    "this fact motivates our novel `` learn - and - adapt '' stochastic dual gradient ( la - sdg ) method in section [ sec.la-sdg ] . to this end",
    ", we will first outline the celebrated stochastic dual gradient iteration ( a.k.a .",
    "lyapunov optimization ) .      to solve",
    ", a standard gradient iteration involves sequentially taking expectations over the distribution of @xmath35 to compute the gradient .",
    "this is challenging because the distribution of @xmath35 is usually unknown in practice .",
    "even if the joint probability distribution functions were available , finding the expectations is not scalable as the dimensionality of @xmath35 grows .",
    "a common remedy to this challenge is stochastic approximation @xcite , which corresponds to the following sdg iteration    @xmath94^{+},\\;\\forall t\\end{aligned}\\ ] ]    where @xmath0 is a positive ( and typically pre - selected constant ) stepsize .",
    "the stochastic gradient @xmath95 is an unbiased estimate of the true gradient ; that is , @xmath96=\\nabla{\\cal d}(\\bm{\\lambda}_t)$ ] .",
    "hence , the primal @xmath32 can be found by solving the following instantaneous sub - problems , one per @xmath23 @xmath97    the iterate @xmath98 in depends only on the probability distribution of @xmath35 through the stochastic gradient @xmath99 .",
    "consequently , the process @xmath100 is markov with invariant transition probability when @xmath35 is stationary .",
    "an interesting observation is that since @xmath101 , the dual iteration can be written as [ cf . ]",
    "@xmath102^{+},\\ ; \\forall t\\end{aligned}\\ ] ] which coincides with for @xmath103 ; see also @xcite for the virtual queue interpretation of this parallelism .",
    "thanks to its low complexity and robustness to non - stationary scenarios , sdg is widely used in various areas , including adaptive signal processing @xcite , stochastic network optimization @xcite , and energy management in power grids @xcite . for network management in particular",
    ", this iteration entails a cost - delay tradeoff as summarized next ; see e.g. , @xcite .",
    "[ prop.sdg ] if @xmath104 is the optimal cost in under any feasible control policy with the state distribution available , and if the sdg recursions in - achieve an @xmath105-optimal solution in the sense that    @xmath106 \\leq { \\psi}^*+{\\cal o}(\\mu)\\ ] ]    where @xmath107 denotes the decisions obtained from , then it necessarily incurs a steady - state queue length @xmath108 , namely @xmath109={\\cal o}\\left(\\frac{1}{\\mu}\\right).\\ ] ]    proposition [ prop.sdg ] asserts that sdg will asymptotically yield an @xmath110-optimal solution , and have steady - state queue length @xmath111 inversely proportional to @xmath0 . intuitively , sdg iteration with a constant stepsize @xmath0 will converge to a neighborhood of the optimum @xmath86 @xcite . under mild conditions ,",
    "the optimal multiplier is bounded , i.e. , @xmath112 , so that the steady - state queue length @xmath113 naturally scales with @xmath114 ; see . as a consequence however , to achieve the near optimality ( sufficiently small @xmath0 ) , sdg suffers large average queue lengths , thus undesired average delay by little s law @xcite . to overcome this limitation",
    ", we will develop next an _ online _ approach , which can improve sdg s cost - delay tradeoff , while still preserving its affordable complexity and adaptability .",
    "our main approach is derived in this section , by nicely leveraging both learning and optimization tools .",
    "its decentralized implementation is also developed .      the intuition behind our learn - and - adapt stochastic dual gradient ( la - sdg ) approach is to incrementally learn network state statistics from observed data while adapting resource allocation driven by the learning process .",
    "a key element of la - sdg could be termed as `` foresighted '' learning because instead of myopically learning the exact optimal argument from empirical data , la - sdg maintains the capability to hedge against the risk of `` future non - stationarities . ''",
    "* initialize : * dual iterate @xmath115 , empirical dual iterate @xmath116 , queue length @xmath117 , control variable @xmath118 , and proper stepsizes @xmath0 and @xmath119 .",
    "* resource allocation ( 1st gradient ) : * construct the effective dual variable via , observe  the current state @xmath35 , and obtain resource allocation @xmath120  by minimizing online lagrangian . update the instantaneous queue length @xmath121 via @xmath122^{+},\\;\\forall t.\\ ] ] * sample recourse ( 2nd gradient ) : * obtain variable @xmath123 by solving online lagrangian  minimization with sample @xmath35 via . update the empirical dual variable @xmath124 via .",
    "the proposed la - sdg is summarized in algorithm [ algo1 ] .",
    "it involves the queue length @xmath33 and an empirical dual variable @xmath125 , along with a bias - control variable @xmath126 to ensure that la - sdg will attain near optimality in the steady state [ cf .",
    "theorems [ the.queue-stable ] and [ gap - onlinela - sdg ] ] . at each time slot @xmath23 , la - sdg obtains two stochastic gradients using the current @xmath35 : one for online resource allocation , and another one for sample learning / recourse . for the first gradient ( lines 3 - 5 ) , contrary to sdg that relies on the stochastic multiplier estimate @xmath127 [ cf . ]",
    ", la - sdg minimizes the instantaneous lagrangian    @xmath128    which depends on what we term _ effective _ multiplier @xmath129 , given by @xmath130    variable @xmath129 also captures the effective price , which is a linear combination of the empirical @xmath125 and the queue length @xmath33 , where the control variable @xmath0 tunes the weights of these two factors , and @xmath126 controls the bias of @xmath129 in the steady state @xcite . as a single pass of sdg `` wastes '' valuable online samples , la - sdg resolves this limitation in a learning step by evaluating a second gradient ( lines 6 - 8 )",
    "; that is , la - sdg simply finds the stochastic gradient of at the previous empirical dual variable @xmath125 , and implements a gradient ascent update as    @xmath131^{+},\\;\\forall t\\ ] ]    where @xmath132 is a proper diminishing stepsize , and the `` virtual '' allocation @xmath123 can be found by solving @xmath133    notice that the multiplicative constant @xmath0 in allows for adaptation even in the steady state ( i.e. , @xmath134 ) , but the diminishing @xmath132 is for online learning , as we shall discuss below .    for a better illustration of the effective price , we call @xmath125 the statistically learnt price to obtain the exact optimal argument of the expected problem",
    ". we also call @xmath135 ( which is exactly @xmath127 as shown in ) the online adaptation term since it can track the instantaneous change of system statistics",
    ". intuitively , a large @xmath0 will allow the effective policy to quickly respond to instantaneous variations so that the policy gains improved control of queue lengths , while a small @xmath0 puts more weight on statistical learning from historical samples so that the allocation strategy will incur less variance in the steady state .",
    "in this sense , the proposed la - sdg can attains both statistical efficiency and adaptability . distinctly different from sdg with constant stepsize that involves a pure adaptation step ,",
    "la - sdg takes an additional learning step [ cf .",
    "] , which adopts gradient ascent with diminishing stepsize to find the `` best empirical '' dual variable from all observed network states .",
    "this pair of complementary gradient steps endows la - sdg with its attractive properties . in its transient stage",
    ", the extra gradient evaluations and empirical dual variables accelerate the convergence speed of sdg ; while in the steady stage , the empirical dual variable approaches the optimal multiplier , which significantly reduces the steady - state queue lengths .    readers familiar with algorithms on statistical learning and stochastic network optimization can recognize their similarities and differences with la - sdg .",
    "( p1 ) sdg in @xcite involves only the first part of la - sdg ( @xmath136st gradient ) , where the allocation policy purely relies on stochastic estimates of lagrange multipliers or instantaneous queue lengths , i.e. , @xmath137 .",
    "in contrast , la - sdg further leverages statistical learning from streaming data .",
    "( p2 ) several schemes have been developed recently for statistical learning at scale to find @xmath125 , namely , sag in @xcite and saga in @xcite .",
    "however , directly applying @xmath138 to allocate resources causes infeasibility . for a finite time @xmath23",
    ", @xmath125 is @xmath139-optimal is @xmath139-optimal if @xmath140 , and likewise for @xmath139-feasibility . ] for , and the primal variable @xmath123 in turn is @xmath139-feasible with respect to that is necessary for . since @xmath33 essentially accumulates online constraint violations of , it will grow linearly with @xmath23 and eventually become unbounded .",
    "the heavy - ball iteration belongs to the family of momentum - based first - order methods , and has well - documented acceleration merits in the deterministic setting @xcite .",
    "motivated by its convergence speed in solving deterministic problems , stochastic heavy - ball methods have been also pursued recently @xcite .",
    "the stochastic version of the heavy - ball iteration is @xcite @xmath141 where @xmath142 is an appropriate constant stepsize , @xmath143 denotes the momentum factor , and the stochastic gradient @xmath99 can be found by solving using heavy - ball iterate @xmath127 .",
    "this iteration exhibits attractive convergence rate during the initial stage , but its performance degrades in the steady state .",
    "recently , the performance of momentum iterations ( heavy - ball or nesterov ) with constant stepsize @xmath0 and momentum factor @xmath144 , has been proved equivalent to sdg with constant @xmath145 per iteration @xcite . since sdg with a large stepsize converges",
    "fast at the price of considerable loss in optimality , the momentum methods naturally inherit these attributes .",
    "to see the influence of the momentum term , consider expanding the iteration as @xmath146\\nonumber\\\\ & = \\bm{\\lambda}_t+\\underbrace{\\mu \\textstyle\\sum_{\\tau=1}^t\\beta^{t-\\tau}\\nabla{\\cal d}_{\\tau}(\\bm{\\lambda}_{\\tau})}_{\\rm accumulated~gradient}+\\underbrace{\\beta^t(\\bm{\\lambda}_1\\!-\\!\\bm{\\lambda}_0)}_{\\rm initial~state}.\\end{aligned}\\ ] ] the stochastic heavy - ball method will accelerate convergence in the initial stage thanks to the accumulated gradients , and it will gradually forget the initial state . as @xmath23 increases however , the algorithm also incurs a worst - case oscillation @xmath147 , which degrades performance in terms of objective values when compared to sdg with stepsize @xmath0 .",
    "this is in agreement with the theoretical analysis in ( * ? ? ?",
    "* theorem 11 ) .",
    "different from standard momentum methods , la - sdg nicely inherits the fast convergence in the initial stage , while reducing the oscillation of stochastic momentum methods in the steady state . to see this ,",
    "consider two consecutive iterations    [ eq.dual-effect1 ] @xmath148    and subtract them , to arrive at @xmath149 here the equalities in follows from @xmath150 in @xmath33 recursion , and with a sufficiently large @xmath126 , the projection in rarely ( with sufficiently low probability ) takes effect since the steady - state @xmath33 will hover around @xmath151 ; see the details of theorem [ the.queue-stable ] and the proof thereof .",
    "comparing the la - sdg iteration with the stochastic heavy - ball iteration , both of them correct the iterates using the stochastic gradient @xmath152 or @xmath153 .",
    "however , la - sdg incorporates the variation of a learning sequence ( also known as a reference sequence ) @xmath154 into the recursion of the main iterate @xmath129 , other than heavy - ball s momentum term @xmath155 .",
    "since the variation of learning iterate @xmath125 eventually diminishes as @xmath23 increases , keeping the learning sequence enables la - sdg to enjoy accelerated convergence in the initial ( transient ) stage compared to sdg , while avoiding large oscillation in the steady state compared to the stochastic heavy - ball method .",
    "we formally remark this obervation next .",
    "la - sdg offers a fresh approach to designing stochastic optimization algorithms in a dynamic environment .",
    "while directly applying the momentum - based iteration to a stochastic setting may lead to unsatisfactory steady - state performance , it is promising to carefully design a reference sequence that exactly converges to the optimal argument .",
    "therefore , algorithms with improved convergence ( e.g. , the second - order method in @xcite ) can also be incorporated as a reference sequence to further enhance the performance of la - sdg .",
    "this section introduces a fully distributed implementation of la - sdg by exploiting the problem structure of network resource allocation .",
    "for notational brevity , collect the variables representing outgoing links from node @xmath25 in @xmath156 with @xmath157 denoting the index set of outgoing neighbors of node @xmath25 .",
    "let also @xmath158 $ ] denote the random state at node @xmath25 .",
    "it will be shown that the learning and allocation decision per time slot @xmath23 is processed locally per node @xmath25 based on its local state @xmath159 .    to this end , rewrite the lagrangian minimization for a general dual variable @xmath76 at time @xmath23 as [ cf . and ]",
    "@xmath160 where @xmath161 is the @xmath25-th entry of vector @xmath162 , and @xmath163 denotes the @xmath25-th row of the node - incidence matrix @xmath20 .",
    "clearly , @xmath163 selects entries of @xmath32 associated with the in- and out - links of node @xmath25 .",
    "therefore , the subproblem at node @xmath25 is @xmath164 where @xmath165 is the feasible set of primal variable @xmath166 . in the case of , the feasible set @xmath38 can be written as a cartesian product of sets @xmath167 , so that the projection of @xmath32 to @xmath38 is equivalent to separate projections of @xmath166 onto @xmath165 .",
    "note that @xmath168 will be available at node @xmath25 by exchanging information with the neighbors per time @xmath23 .",
    "hence , given the effective multipliers @xmath169 ( @xmath42-th entry of @xmath129 ) from its outgoing neighbors in @xmath170 , node @xmath25 is able to form an allocation decision @xmath171 by solving the convex programs with @xmath172 ; see also .",
    "needless to mention , @xmath173 can be locally updated via , that is @xmath174^{+}\\ ] ] where @xmath175 are the local measurements of arrival ( departure ) workloads from ( to ) its neighbors .    likewise , the tentative primal variable @xmath176 can be obtained at each node locally by solving using the current sample @xmath177 again with @xmath178 . by sending @xmath176 to its outgoing neighbors ,",
    "node @xmath25 can update the empirical multiplier @xmath179 via @xmath180^{+}\\ ] ] which , together with the local queue length @xmath181 , also implies that the next @xmath182 can be obtained locally .    compared with the classic sdg recursion - , the distributed implementation of la - sdg incurs only a factor of two increase in computational complexity .",
    "next , we will further analytically establish that it can improve the delay of sdg by an order of magnitude with the same order of optimality gap .",
    "this section presents performance analysis of la - sdg , which will rely on the following four assumptions .",
    "[ assp.iid ] the state @xmath35 is bounded and i.i.d . over time @xmath23 .",
    "[ assp.primal ] @xmath79 in is @xmath183-strongly convex , and has @xmath184-lipschitz continuous gradient . also , @xmath79 is non - decreasing w.r.t .",
    "all entries of @xmath32 over a convex set @xmath38 .",
    "[ assp.slater ] there exists a stationary policy @xmath75 satisfying @xmath185 for all @xmath35 , and @xmath186\\leq -\\bm{\\zeta}$ ] , where @xmath187 is a slack vector constant .",
    "[ assp.dualgrad ] for any time @xmath23 , the magnitude of the constraint is bounded , that is , @xmath188 .",
    "assumption [ assp.iid ] is typical in stochastic network resource allocation @xcite , and can be relaxed to an ergodic and stationary setting following @xcite .",
    "assumption [ assp.primal ] ensures uniqueness of the optimal solution .",
    "non - decreasing costs with increased resources are easily guaranteed with exponential and quadratic functions .",
    "in addition , assumption 2 ensures that the dual function has favorable properties , which are important to ensure stability .",
    "assumption [ assp.slater ] is slater s condition , which guarantees the existence of a bounded optimal lagrange multiplier @xcite , and is also necessary for queue stability @xcite .",
    "assumption [ assp.dualgrad ] guarantees boundedness of the gradient of the instantaneous dual function , which is common in performance analysis of stochastic gradient - type algorithms @xcite .",
    "building upon the desirable properties of the primal problem , we next show that the corresponding dual function satisfies both smoothness and quadratic growth properties @xcite , which will be critical to the subsequent analysis .",
    "[ lemma.qg ] under assumption 2 , the dual function @xmath189 in is @xmath190-smooth , where @xmath191 , and @xmath192 denotes the spectral radius of @xmath193 .",
    "in addition , if the dual variable @xmath162 lies in a compact set , there always exists a small constant @xmath194 such that @xmath195 satisfies the following quadratic growth property @xmath196 where @xmath86 is the optimal multiplier for the dual problem",
    ".    see appendix a.    we start with the convergence of the empirical dual variables @xmath125 .",
    "note that the update of @xmath125 is a classical learning process from historical data , and it is not affected by future resource allocation strategies .",
    "therefore , the theoretical result on sdg with diminishing stepsize is directly applicable ( * ? ? ?",
    "[ error - emp ] let @xmath125 denote the empirical dual variable in algorithm [ algo1 ] , and @xmath86 the optimal argument for the dual problem .",
    "if the stepsize is chosen as @xmath197 , with a constant @xmath198 , a sufficient large constant @xmath199 , and @xmath200 as in assumption [ assp.dualgrad ] , then it holds that @xmath201\\leq      \\max\\{\\alpha,\\alpha^{-1}\\}\\,\\frac{dm}{\\sqrt{t}}\\ ] ] where the expectation is over all the random states @xmath35 up to @xmath23 .",
    "lemma [ error - emp ] asserts that using a diminishing stepsize , the dual function value converges sub - linearly to the optimal value in expectation . in principle , @xmath202 is the radius of the feasible set for the dual variable @xmath162 ( * ? ? ?",
    "2.2 ) . however , as the optimal multiplier @xmath86 is bounded according to assumption [ assp.slater ] , one can always estimate a large enough @xmath202 , and the estimation error will only affect the constant of the sub - optimality bound through the scalar @xmath203 .",
    "the sub - optimality bound in lemma [ error - emp ] holds in expectation , which averages over all possible sample paths @xmath204 .    as a complement to lemma [ error - emp ] ,",
    "the almost sure convergence of the empirical dual variables is established next to characterize the performance of each individual sample path .",
    "[ emp - dual ] for the sequence of empirical multipliers @xmath154 in algorithm [ algo1 ] , if the stepsizes are chosen as @xmath205 , with constants @xmath206 defined in lemma [ error - emp ] , it holds that @xmath207 where @xmath86 is the optimal dual variable for the expected dual function minimization .",
    "the proof follows the steps in ( * ? ? ?",
    "* proposition 8.2.13 ) , which is omitted here .",
    "building upon the asymptotic convergence of empirical dual variables for statistical learning , it becomes possible to analyze the online performance of la - sdg .",
    "clearly , the online resource allocation @xmath32 is a function of the effective dual variable @xmath129 and the instantaneous network state @xmath35 [ cf . ] .",
    "therefore , the next step is to show that the effective dual variable @xmath129 also converges to the optimal argument of the expected problem , which would establish that the online resource allocation @xmath32 is asymptotically optimal .",
    "however , directly analyzing the trajectory of @xmath129 is nontrivial , because the queue length @xmath208 is coupled with the reference sequence @xmath154 in @xmath129 . to address this issue ,",
    "rewrite the recursion of @xmath129 as @xmath209 where the update of @xmath129 depends on the variations of @xmath125 and @xmath33 .",
    "we will first study the asymptotic behavior of queue lengths @xmath33 , and then derive the analysis of @xmath129 using the convergence of @xmath125 in , and the recursion .",
    "define the time - varying target @xmath210 , which is the optimality residual of statistical learning @xmath211 plus the bias - control variable @xmath126 . per theorem",
    "[ emp - dual ] , it readily follows that @xmath212 . by showing that @xmath33 is attracted towards the time - varying target @xmath213",
    ", we will further derive the stability of queue lengths .",
    "[ lem.drift ] with @xmath33 and @xmath0 denoting queue length and stepsize , there exists a constant @xmath214 , and a finite time @xmath215 , such that for all @xmath216 , if @xmath217 , it holds in la - sdg that @xmath218\\leq \\left\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\right\\|-\\sqrt{\\mu},\\ ; { \\rm w.p.1}.\\ ] ]    [ pf.queue-drift ] see appendix b.    lemma [ lem.drift ] reveals that when @xmath33 is large and deviates from the time - varying target @xmath213 , it will be bounced back towards the target in the next time slot . upon establishing this drift behavior of queues , we are on track to establish queue stability .",
    "[ the.queue-stable ] with @xmath219 defined in , there exists a constant @xmath220 such that the queue length under la - sdg converges to a neighborhood of @xmath151 as    @xmath221    in addition , if we choose @xmath222 , the long - term average expected queue length satisfies @xmath223={\\cal o}\\left(\\frac{\\log^2(\\mu)}{\\sqrt{\\mu}}\\right),~{\\rm w.p.1}.\\ ] ]    [ pf.queue-stable ] see appendix c.    theorem [ the.queue-stable ] in asserts that the sequence of queue iterates converges ( in the infimum sense ) to a neighborhood of @xmath224 , where the radius of neighborhood region scales as @xmath225 .",
    "in addition to the sample path result , demonstrates that with a specific choice of @xmath126 , the queue length averaged over all sample paths will be @xmath226 .",
    "together with theorem [ emp - dual ] , it suffices to have the effective dual variable converge to a neighborhood of the optimal multiplier @xmath86 ; that is , @xmath227 . notice that the sdg iterate @xmath127 in will also converge to a neighborhood of @xmath86 .",
    "therefore , intuitively la - sdg will behave similar to sdg in the steady state , and its asymptotic performance follows from that of sdg .",
    "however , the difference is that through a careful choice of @xmath126 , for a sufficiently small @xmath0 , la - sdg can improve the queue length @xmath228 under sdg by an order of magnitude .",
    "in addition to feasibility , we formally establish in the next theorem that la - sdg is asymptotically near - optimal .",
    "[ gap - onlinela - sdg ] let @xmath104 be the optimal objective value of under any feasible policy with distribution information about the state fully available .",
    "if the control variable is chosen as @xmath222 , then with a sufficiently small @xmath0 , the proposed la - sdg algorithm yields a near - optimal solution for in the sense that @xmath229 \\leq { \\psi}^*+{\\cal o}(\\mu),\\;{\\rm          w.p.1}\\ ] ] where @xmath120 denotes the real - time operations obtained from the lagrangian minimization .",
    "see appendix d.    combining theorems [ the.queue-stable ] and [ gap - onlinela - sdg ] , we are ready to state that by setting @xmath230 , la - sdg is asymptotically @xmath110-optimal with an average queue length @xmath231 .",
    "this result implies that la - sdg is able to achieve a near - optimal cost - delay tradeoff @xmath232 $ ] ; see @xcite . comparing with the standard tradeoff",
    "@xmath2 $ ] under sdg , the learn - and - adapt design of la - sdg markedly improves the online performance in terms of delay .",
    "note that a better tradeoff @xmath233 $ ] has been derived in @xcite under the so - termed local polyhedral assumption .",
    "observe though , that the considered setting in @xcite is different from the one here . while the network state set @xmath234 and the action set @xmath235 in @xcite",
    "are discrete and countable , la - sdg allows continuous @xmath234 and @xmath235 with possibly infinite elements , and still be amenable to efficient and scalable online operations .    )",
    ".,scaledwidth=31.0% ]    ) .,scaledwidth=31.0% ]    ) .,scaledwidth=31.0% ]    ) .,scaledwidth=31.0% ]",
    ") .,scaledwidth=32.0% ]    this section presents numerical tests to confirm the analytical claims and demonstrate the merits of the proposed approach .",
    "we consider the geographical load balancing network of section [ subsec.exp ] with @xmath236 data centers , and @xmath237 mapping nodes .",
    "performance is tested in terms of the time - averaged instantaneous network cost in , namely @xmath238 where the energy price @xmath239 is uniformly distributed over @xmath240 $ ] ; samples of the renewable supply @xmath241 are generated uniformly over @xmath242 $ ] ; and the per - unit bandwidth cost is set to @xmath243 , with bandwidth limits @xmath244 generated from a uniform distribution within @xmath245 $ ] .",
    "the capacities at data centers @xmath246 are uniformly generated from @xmath245 $ ] .",
    "the delay - tolerant workloads @xmath247 arrive at each mapping node @xmath42 according to a uniform distribution over @xmath242 $ ] . clearly , the cost and the state @xmath35 here satisfy assumptions 1 and 2 . finally , the stepsize is @xmath248 , the trade - off variable is @xmath249 , and the bias correction vector is chosen as @xmath250 by default , but manually tuned in figs .",
    "[ fig.obj-all]-[fig.delay-all ] .",
    "we introduce two benchmarks : sdg in ( see e.g. , @xcite ) , and the projected stochastic heavy - ball in and @xmath251 by default ( see e.g. , @xcite ) .",
    "slots).,scaledwidth=31.0% ]     slots).,scaledwidth=31.0% ]    performance is compared in terms of the time - averaged cost , and the instantaneous queue length in figs .",
    "[ fig.obj ] and [ fig.queue ] . for the network cost ,",
    "the three algorithms converge to almost the same value .",
    "la - sdg and heavy - ball exhibit faster convergence than sdg as their running - average costs quickly arrive at the optimal operating phase by leveraging the learning process or the momentum acceleration . under this parameter configuration ( @xmath252 )",
    ", la - sdg exhibits a much lower delay as its aggregated queue length is only 10% of that for heavy - ball and 4% of that for sdg .",
    "clearly , our learn - and - adapt procedure improves the delay performance .",
    "the same metrics are also compared by setting @xmath253 ; see figs .",
    "[ fig.obj2 ] and [ fig.queue2 ] . with a larger momentum factor @xmath254 ,",
    "the heavy - ball method exhibits a pronounced optimality loss relative to sdg in fig .",
    "[ fig.obj2 ] , while la - sdg still converges to a time - average cost similar to that of sdg . however , by using a larger @xmath144 , the heavy - ball method incurs a much lower queue length relative to that in fig .",
    "[ fig.queue ] . comparing to the la - sdg s queue length however , it is still much larger in the steady state .",
    "recall that the instantaneous resource allocation can be viewed as a function of the dual variable ; see proposition [ prop.closedform ] . hence , the performance differences in figs .",
    "[ fig.obj]-[fig.queue ] and [ fig.obj2]-[fig.queue2 ] can be also anticipated by the different behavior of dual variables . in fig .",
    "[ fig.dual ] , the evolution of stochastic dual variables are plotted under two considered settings ; that is the dual iterate in for sdg , the momentum iteration in for the heavy - ball method , and the effective multiplier in for la - sdg .",
    "as illustrated in , the performance of momentum iterations is similar to sdg with larger stepsize @xmath145 .",
    "this is corroborated by fig .",
    "[ fig.dual ] , where the stochastic momentum iterate with @xmath251 behaves similar to the dual iterates of sdg and la - sdg , but its oscillation becomes prohibitively high with a larger factor @xmath254 , which nicely explains the higher cost in fig .",
    "[ fig.obj2 ] .",
    "since the cost - delay performance is sensitive to the choice of parameters @xmath0 and @xmath144 , extensive experiments are further conducted among three algorithms using different values of @xmath0 and @xmath144 in figs .",
    "[ fig.obj-all ] and [ fig.delay-all ] .",
    "the steady - state performance is evaluated by running algorithms for sufficiently long time , up to @xmath255 slots .",
    "the steady - state costs of all three algorithms increase as @xmath0 becomes larger , and the costs of la - sdg and the heavy - ball with small momentum factor @xmath256 are close to that of sdg , while the costs of the heavy - ball with larger momentum factors @xmath257 and @xmath254 are much larger than that of sdg .",
    "considering steady - state queue lengths ( network delay ) , la - sdg exhibits an order of magnitude lower amount than those of sdg and the heavy - ball with small @xmath144 , under all choices of @xmath0 .",
    "note that the heavy - ball with a sufficiently large factor @xmath254 also has a very low queue length , but it incurs a much higher cost than la - sdg in fig .",
    "[ fig.obj-all ] due to a higher steady - state oscillation observed in fig .",
    "[ fig.dual ] .",
    "fast convergent resource allocation and low service delay are highly desirable attributes of stochastic network management approaches . leveraging recent advances in online learning and momentum - based optimization , a novel online approach termed la - sdg was developed in this paper .",
    "la - sdg learns the network state statistics through an additional sample recourse procedure .",
    "the associated novel iteration can be nicely interpreted as a modified heavy - ball recursion with an extra correction step to mitigate steady - state oscillations .",
    "it was analytically established that la - sdg achieves a near - optimal cost - delay tradeoff @xmath1 $ ] , which is better than @xmath258 $ ] of sdg , at the cost of only one extra gradient evaluation per new datum .",
    "our future research agenda includes novel approaches to further hedge against non - stationarity , and improved learning schemes to uncover other valuable statistical patterns from historical data .",
    "the authors would like to thank profs .",
    "xin wang , longbo huang and jia liu for helpful discussions .      [ prop.primal-dual ] under assumptions 1 - 3 , for the constrained optimization with the optimal policy @xmath67 and its optimal lagrange multiplier @xmath86 , it holds that @xmath259=\\mathbf{0}$ ] with @xmath260 , and accordingly that @xmath261 .",
    "@xmath262+\\mathbf{a}^{\\top}\\bm{\\lambda}^*\\right)^{\\top}(\\mathbb{e}[\\mathbf{x}_t-\\mathbf{x}_t^*])&\\geq 0,\\;\\forall \\mathbf{x}_t\\in { \\cal x}\\label{eq.kkt1}\\\\          ( \\bm{\\lambda}^*)^{\\top}\\mathbb{e}[\\mathbf{a}\\mathbf{x}_t^*+\\mathbf{c}_t]&=0\\label{eq.kkt2}\\\\          \\mathbb{e}[\\mathbf{a}\\mathbf{x}_t^*+\\mathbf{c}_t]\\leq \\mathbf{0};\\;\\bm{\\lambda}^*&\\geq \\mathbf{0}\\label{eq.kkt3 }      \\end{aligned}\\ ] ]      to establish the claim , let us first assume that there exists entry @xmath45 that the inequality constraint is not active ; i.e. , @xmath263=-\\zeta$ ] with the constant @xmath264 , and @xmath265 denoting the @xmath45-th row of @xmath20 .",
    "as each row of @xmath20 has at least one entry equal to @xmath21 , we collect all indices of entries at @xmath45-th row with value @xmath21 in set @xmath266 so that @xmath267 .",
    "since @xmath268 is feasible , we have @xmath269 , and thus @xmath270=\\mathbb{e}\\left[\\sum_{e\\in { \\cal e}}\\mathbf{a}_{(k , e)}(x_t^e)^*+c_t^k\\right]=-\\zeta\\end{aligned}\\ ] ] which implies that @xmath271\\!=\\!\\zeta+\\mathbb{e}[c_t^k\\!+\\!\\textstyle\\sum_{e\\in { \\cal e}\\backslash{\\cal e}_{k}^{-1}}\\mathbf{a}_{(k , e)}(x_t^e)^*]>0.\\!\\!\\!\\ ] ] according , it further follows that @xmath272 since @xmath273=-(\\lambda^k)^*\\cdot\\zeta=0 $ ] .",
    "now we are on track to show that it contradicts with .",
    "since @xmath274>0 $ ] , there exists at least an index @xmath42 such that @xmath275>0,\\,j \\in { \\cal e}_{k}^{-1}$ ] . choose @xmath276 $ ] with @xmath277=\\mathbb{e}[(x_t^{\\tilde{j}})^*],\\forall { \\tilde{j}}\\neq j$ ] and @xmath278=0 $ ] , to have @xmath279=[0,\\ldots,-\\mathbb{e}[(x_t^j)^*],\\ldots,0]^{\\top}$ ] .",
    "hence , we arrive at ( with @xmath280 denoting @xmath42-th entry of gradient ) @xmath281+\\mathbf{a}^{\\top}\\bm{\\lambda}^*\\right)^{\\top}\\mathbb{e}[(\\mathbf{x}_t-\\mathbf{x}_t^*)]\\nonumber\\\\",
    "= & -\\mathbb{e}\\big[\\nabla_j\\psi_t(\\mathbf{x}_t^*)(x_t^j)^*-\\sum_{i\\in{\\cal i } } ( \\lambda^i)^*\\mathbf{a}_{(i , j)}(x_t^j)^*\\big]\\nonumber\\\\      \\stackrel{(a)}{=}&\\underbrace{-\\mathbb{e}[\\nabla_j\\psi_t(\\mathbf{x}_t^*)(x_t^j)^*]}_{<0}-\\!\\!\\sum_{i\\in{\\cal i}\\backslash k } \\underbrace{(\\lambda^i)^*\\mathbf{a}_{(i , j)}\\mathbb{e}[(x_t^j)^*]}_{\\geq 0}<0\\end{aligned}\\ ] ] where ( a ) uses @xmath272 ; the first bracket follows from assumption [ assp.primal ] since @xmath280 is monotonically increasing and @xmath282 , thus for @xmath275>0 $ ] it follows @xmath283>0 $ ] ; and the second bracket follows that @xmath284 and each column of @xmath20 has at most one @xmath21 and @xmath285 .",
    "the proof is then complete since contradicts .",
    "* proof of lipschitz continuity : * under assumption [ assp.primal ] , the primal objective @xmath79 is @xmath183-strongly convex , and the smooth constant of the dual function @xmath189 , or equivalently , the lipschitz constant of gradient @xmath286 directly follows from ( * ? ? ?",
    "* lemma ii.2 ) , which equals to @xmath191 , with @xmath192 denoting the maximum eigenvalue of @xmath193 .",
    "we omit the derivations of this result , and refer readers to that in @xcite .",
    "[ lemma.errorbd ] ( * ? ? ?",
    "* lemma 2.3 ) consider the dual function in and the feasible set @xmath38 in with only linear constraints .",
    "for any @xmath162 satisfying @xmath287 and @xmath288 , we have@xmath289 where the scalar @xmath290 depends on the matrix @xmath20 as well the constants @xmath183 , @xmath184 and @xmath190 introduced in assumption [ assp.primal ] .",
    "lemma [ lemma.errorbd ] states a _",
    "local _ error bound for the dual function @xmath195 .",
    "the error bound is `` local '' since it holds only for @xmath162 close enough to the optimum @xmath86 , i.e. , @xmath288 . following the arguments in @xcite however , if the dual iterate @xmath162 is artificially confined to a compact set @xmath291 such that @xmath292 with @xmath202 denoting the radius of @xmath291 ,",
    ", one can safely find a large set @xmath291 with radius @xmath202 to project dual iterates during optimization .",
    "] then for the case @xmath293 , the ratio @xmath294 , which implies the existence of @xmath290 satisfying for any @xmath295 .",
    "lemma [ lemma.errorbd ] is important for establishing linear convergence rate without strong convexity @xcite .",
    "remarkably , we will show next that this error bound is also critical to characterize the steady - state behavior of our la - sdg scheme .",
    "[ lemma.pl ] under assumption [ assp.primal ] , the local error - bound in implies the following pl condition , namely @xmath296 where @xmath190 is the lipschitz constant of the dual gradient and @xmath290 is as in .    using the @xmath190-smoothness of the dual function @xmath195 , we have for any @xmath162 and @xmath297 that @xmath298 choosing @xmath299 , and using proposition [ prop.primal-dual ] such that @xmath261 , we have @xmath300 where inequality ( a ) uses the local error - bound in .",
    "* proof of quadratic growth : * the proof follows the main steps of that in @xcite . building upon lemma [ lemma.pl ] , we next prove lemma [ lemma.qg ] . define a function of the dual variable @xmath162 as @xmath301 . with the pl condition in , and @xmath302 denoting the set of optimal multipliers for , we have for any @xmath303 that @xmath304 which implies that @xmath305 .          which describes the continuous trajectory of @xmath307 starting from @xmath308 along the direction of @xmath309 .",
    "by using @xmath305 , it follows that @xmath310 is bounded below ; thus , the differential equation guarantees that we sufficiently reduce the value of function @xmath311 , and @xmath312 will eventually reach @xmath302 .    in other words ,",
    "there exists a time @xmath313 such that @xmath314 .",
    "formally , for @xmath315 , we have @xmath316 since @xmath317 , we have @xmath318 , which implies that there exists a finite time @xmath313 such that @xmath319 . on the other hand ,",
    "the path length of trajectory @xmath307 will be longer than the projection distance between @xmath320 and the closest point in @xmath302 denoted as @xmath86 , that is , @xmath321 and thus we have from that @xmath322 where ( b ) follows from . choosing @xmath313 such that @xmath323 , we have @xmath324 squaring both sides of , the proof is complete , since @xmath194 is defined as @xmath325 and @xmath320 can be any point outside the set of optimal multipliers .",
    "since @xmath125 converges to @xmath326 according to theorem [ emp - dual ] , there exists a finite time @xmath327 such that for @xmath328 , we have @xmath329 . in such case , it follows that @xmath330 , since @xmath331 .",
    "therefore , we have @xmath332^+-[\\tilde{\\bm{\\theta}}_t/\\mu]^+\\|^2\\\\      \\stackrel{(a)}{\\leq}&\\|\\mathbf{q}_t+\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|^2\\nonumber\\\\      \\stackrel{(b)}{\\leq } & \\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|^2 + 2(\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu)^{\\top}(\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t)+m^2\\nonumber      \\end{aligned}\\ ] ] where ( a ) comes from the non - expansive property of the projection operator , and ( b ) is due to the upper bound @xmath200 in assumption [ assp.dualgrad ] .",
    "the rhs of can be upper bounded by @xmath333 where ( c ) uses the definitions @xmath334 , and @xmath335 . since @xmath24 is the stochastic subgradient of the concave function @xmath195 at @xmath336 [ cf .",
    "] , we have @xmath337\\leq { \\cal d}(\\bm{\\gamma}_t)-{\\cal d}(\\bm{\\lambda}^*).\\ ] ]    taking expectations on - over the random state @xmath35 conditioned on @xmath33 and using , we arrive at @xmath338\\!\\leq\\!\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|^2\\!+\\frac{2}{\\mu}\\left({\\cal d}(\\bm{\\gamma}_t)-{\\cal d}(\\bm{\\lambda}^*)\\right)+m^2\\ ] ] where we use the fact that @xmath339 $ ] in . using the quadratic growth property of @xmath195 in of lemma [ lemma.qg ]",
    ", the recursion further leads to @xmath340 \\leq\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|^2\\!-\\frac{2\\epsilon}{\\mu}\\|\\bm{\\gamma}_t-\\bm{\\lambda}^*\\|^2+m^2\\nonumber\\\\      \\stackrel{(d)}{\\leq } & \\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|^2 - 2\\mu\\epsilon\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|^2+m^2\\end{aligned}\\ ] ] where equality ( d ) uses the definitions @xmath334 and @xmath335 , implying that @xmath341 .    now considering ( cf . )",
    "@xmath342 and plugging it back into yields @xmath343 & \\leq \\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|^2 - 2\\sqrt{\\mu}\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|+\\mu\\nonumber\\\\      & = \\big(\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|-\\sqrt{\\mu}\\big)^2.\\end{aligned}\\ ] ] by the convexity of @xmath344 , we further arrive at @xmath345 ^ 2&\\leq \\mathbb{e}\\big[\\|\\mathbf{q}_{t+1}- \\tilde{\\bm{\\theta}}_t/\\mu\\|^2\\big]\\nonumber\\\\      & \\leq\\left(\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\|-\\sqrt{\\mu}\\right)^2\\end{aligned}\\ ] ] which directly implies the argument in the lemma . by checking vieta s formulas for second - order equations , there exists @xmath346 such that for @xmath217 , inequality holds , and thus the lemma follows readily .",
    "* proof of in theorem [ the.queue-stable ] : * theorem [ emp - dual ] asserts that @xmath125 eventually converges to the optimum @xmath347 . hence , there always exists a finite time @xmath348 and an arbitrarily small @xmath349 such that for @xmath350 , it holds that @xmath351 . using the definition @xmath210",
    ", it then follows by the triangle inequality that @xmath352 which also holds for @xmath121 .    using and the conditional drift in lemma [ lem.drift ] , for @xmath353 and @xmath354",
    ", it holds that",
    "@xmath355\\leq   \\mathbb{e}\\left[\\left\\|\\mathbf{q}_{t+1}-\\tilde{\\bm{\\theta}}_t/\\mu\\right\\|\\big|\\mathbf{q}_t\\right]+\\rho\\nonumber\\\\       \\leq & \\left\\|\\mathbf{q}_t-\\tilde{\\bm{\\theta}}_t/\\mu\\right\\|-\\sqrt{\\mu } + \\rho\\leq \\left\\|\\mathbf{q}_t-\\bm{\\theta}/\\mu\\right\\|-\\sqrt{\\mu } + 2\\rho.\\end{aligned}\\ ] ] choosing @xmath349 such that @xmath356 , then for @xmath353 and @xmath357 , we have @xmath358\\leq \\left\\|\\mathbf{q}_t-\\bm{\\theta}/\\mu\\right\\|-\\sqrt{\\tilde{\\mu}}.\\ ] ]        clearly , @xmath359 tracks the distance between @xmath33 and @xmath151 until the distance becomes smaller than @xmath363 for the first time ; and @xmath361 stops until @xmath364 for the first time as well .    with the definitions of @xmath359 and @xmath361",
    ", one can easily show that the recursion implies @xmath365\\leq a_t - b_t\\ ] ] where @xmath366 is the so - termed sigma algebra measuring the history of two processes .",
    "as @xmath359 and @xmath361 are both nonnegative , allows us to apply the super - martingale convergence theorem ( * ? ? ?",
    "* theorem e7.4 ) , which almost surely establishes that : ( i ) the sequence @xmath359 converges to a limit ; and ( ii ) the summation @xmath367 .",
    "note that ( ii ) implies that @xmath368 , @xmath369 . since @xmath370",
    ", it follows that the indicator function of @xmath361 eventually becomes null and thus @xmath371 which establishes that @xmath33 will eventually visit and then hover around a neighborhood of the reference point @xmath151 .        defining the lyapunov drift as @xmath374 and taking expectations on over @xmath35 conditioned on @xmath33 , we have @xmath375\\leq \\mathbb{e}\\big[(\\bm{\\gamma}_t-\\bm{\\lambda}^*)^{\\!\\top}\\!(\\mathbf{a}\\mathbf{x}_t\\!+\\!\\mathbf{c}_t)\\big]\\nonumber\\\\      & \\qquad\\qquad\\qquad\\qquad~+\\mathbb{e}\\big[(\\bm{\\theta}\\!-\\!\\hat{\\bm{\\lambda}}_t)^{\\!\\top}\\!(\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t)\\big]\\!+\\!{\\mu m^2}/{2}\\nonumber\\\\      & \\stackrel{(b)}{\\leq } { \\cal d}(\\bm{\\gamma}_t)\\!-\\!{\\cal d}(\\bm{\\lambda}^*)\\!+\\mathbb{e}\\big[(\\bm{\\theta}\\!-\\!\\hat{\\bm{\\lambda}}_t)^{\\!\\top}\\!(\\mathbf{a}\\mathbf{x}_t\\!+\\!\\mathbf{c}_t)\\big]\\!+\\!{\\mu m^2}/{2 }      \\end{aligned}\\ ] ] where",
    "( b ) follows from .",
    "summing both sides over @xmath376 , taking expectations over all possible @xmath33 , and dividing both sides by @xmath313 , we arrive at @xmath377-\\mathbb{e}\\left[\\|\\mathbf{q}_{1}-\\bm{\\lambda}^*/\\mu\\|^2\\right]\\right)\\leq\\\\      & \\frac{1}{t}\\!\\sum_{t=1}^t\\mathbb{e}[{\\cal d}(\\bm{\\gamma}_t)]\\!-\\!{\\cal d}(\\bm{\\lambda}^*)\\!+\\!\\frac{1}{t}\\!\\sum_{t=1}^t\\mathbb{e}\\big[(\\bm{\\theta}\\!-\\!\\hat{\\bm{\\lambda}}_t)^{\\!\\top}\\!(\\mathbf{a}\\mathbf{x}_t\\!+\\!\\mathbf{c}_t)\\big]\\!\\!+\\!\\frac{\\mu m^2}{2}.\\nonumber\\end{aligned}\\ ] ]    first , it is easy to show that @xmath378-\\mathbb{e}\\left[\\left\\|\\mathbf{q}_{1}-{\\bm{\\lambda}^*}/{\\mu}\\right\\|^2\\right]\\right)\\nonumber\\\\      \\stackrel{(c)}{\\geq } & - \\lim_{t\\rightarrow\\infty } \\frac{\\mu}{2t}\\mathbb{e}\\left[\\left\\|\\mathbf{q}_{1}-{\\bm{\\lambda}^*}/{\\mu}\\right\\|^2\\right]\\stackrel{(d)}{=}0\\end{aligned}\\ ] ] where ( c ) holds since @xmath379 , and ( d ) follows from the boundedness of @xmath380 .",
    "we next argue that the following equality holds @xmath381={\\cal o}(\\mu).\\ ] ] rearranging terms in leads to @xmath382\\\\ = & \\lim_{t\\rightarrow \\infty }     \\frac{1}{t } \\sum_{t=1}^{t}\\mathbb{e}\\left[\\left(\\bm{\\theta}-\\bm{\\lambda}^*+(\\bm{\\lambda}^*\\!-\\!\\bm{\\theta}\\!-\\!\\hat{\\bm{\\lambda}}_t\\!+\\!\\bm{\\theta})\\right)^{\\top}(\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t)\\right].\\nonumber \\ ] ] since @xmath125 converges to @xmath383 according to theorem [ emp - dual ] , there always exists a finite time @xmath348 such that for @xmath350 , which implies that @xmath384 .",
    "hence , together with the cauchy - schwarz inequality , we have @xmath385 where ( d ) follows since @xmath386 and constant @xmath200 is as in assumption [ assp.dualgrad ] .",
    "plugging into , it follows that @xmath387\\\\ \\leq&\\lim_{t\\rightarrow \\infty }      ( { 1}/{t})\\ ; \\textstyle \\sum_{t=1}^{t } \\mathbb{e}\\left[(\\bm{\\theta}-\\bm{\\lambda}^*)^{\\top}(\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t)\\right]+{\\cal o}(\\rho)\\nonumber\\\\ \\stackrel{(e)}{\\leq}&\\|\\bm{\\lambda}^*-\\bm{\\theta}\\|\\cdot \\left\\|\\lim_{t\\rightarrow \\infty }   ( { 1}/{t})\\ ; \\textstyle \\sum_{t=1}^{t } \\mathbb{e}\\left[-\\mathbf{a}\\mathbf{x}_t-\\mathbf{c}_t\\right]\\right\\|+{\\cal o}(\\rho)\\nonumber\\end{aligned}\\ ] ] where ( e ) simply follows from the cauchy - schwarz inequality .    building upon",
    ", one can follow the arguments in ( * ? ? ? * theorem 4 ) to show that there exist constants @xmath388 , and @xmath389 , for any @xmath390 , to obtain a large deviation bound as @xmath391 where @xmath220 as in . intuitively speaking , upper bounds the probability that the steady - state @xmath33 deviates from @xmath151 , and implies that the probability that @xmath392 is exponentially decreasing in @xmath393 .    using the large deviation bound in",
    ", it follows that @xmath394\\\\      & \\stackrel{(g)}{\\leq}\\!\\lim_{t\\rightarrow \\infty } \\frac{1}{t } \\sum_{t=1}^{t}\\mathbf{1}\\!\\cdot\\!{m}\\,\\mathbb{p}\\left(\\mathbf{q}_t < m\\right)\\stackrel{(h)}{\\leq}\\ !",
    "md_1 e^{-d_2(\\bm{\\theta}/\\mu-\\tilde{b}-m)}\\nonumber\\end{aligned}\\ ] ] where ( f ) holds because taking expectation in over all @xmath390 implies that the expected queue length is finite [ cf .",
    "] , which implies the necessary condition in ; ( g ) follows from ( * ? ?",
    "* lemma 4 ) which establishes that negative accumulated service residual @xmath395 $ ] may happen only when @xmath396 and the maximum value is bounded by @xmath397 in assumption [ assp.dualgrad ] ; and ( h ) uses the bound in by choosing @xmath398 .",
    "setting @xmath399 in , there exists a sufficiently small @xmath0 such that @xmath400 .",
    "together with and @xmath388 , the latter implies that @xmath401\\right\\|\\leq \\|\\mathbf{1}\\cdot md_1\\mu^2\\|={\\cal o}(\\mu).\\ ] ] plugging into , setting @xmath402 in , and using @xmath403 , we arrive at . letting @xmath404 in",
    ", it follows from and that @xmath405\\!-\\!{\\cal d}(\\bm{\\lambda}^*)\\!+{\\cal o}(\\mu)+\\!\\frac{\\mu m^2}{2}\\nonumber\\\\          & \\stackrel{(h)}{\\leq } { \\cal d}\\left(\\lim_{t\\rightarrow \\infty}\\frac{1}{t}\\!\\sum_{t=1}^t\\mathbb{e}[\\bm{\\gamma}_t]\\right)\\!-\\!{\\cal d}(\\bm{\\lambda}^*)\\!+{\\cal o}(\\mu)+\\!\\frac{\\mu m^2}{2}.\\end{aligned}\\ ] ] where inequality ( h ) uses the concavity of the dual function @xmath195 .",
    "defining @xmath406 $ ] , and using @xmath407 in lemma [ lemma.qg ] , implies that @xmath408 where ( i ) follows since constants @xmath200 and @xmath194 are independent of @xmath0 . from",
    ", we can further conclude that @xmath409 .    recalling the definition @xmath335",
    ", we have that @xmath410\\!-\\!\\frac{\\bm{\\lambda}^*}{\\mu}\\!=\\!\\lim_{t\\rightarrow \\infty}\\!\\frac{1}{t}\\!\\sum_{t=1}^t\\mathbb{e}\\!\\left[\\mathbf{q}_t\\!+\\!\\frac{\\hat{\\bm{\\lambda}}_t}{\\mu}\\right]\\!-\\!\\frac{\\bm{\\lambda}^*}{\\mu}\\!-\\!\\frac{\\bm{\\theta}}{\\mu}\\nonumber\\\\      \\stackrel{(j)}{=}&\\lim_{t\\rightarrow \\infty}\\frac{1}{t}\\!\\sum_{t=1}^t\\mathbb{e}\\left[\\mathbf{q}_t\\right]\\!-\\!\\frac{\\bm{\\theta}}{\\mu}\\stackrel{(k)}{\\leq } \\frac{1}{\\mu}\\|\\bm{\\lambda}^*-\\bm{\\varphi}\\|={\\cal o}\\left(\\frac{1}{\\sqrt{\\mu}}\\right)\\end{aligned}\\ ] ] where ( j ) follows from the convergence of @xmath125 in theorem [ emp - dual ] , and inequality ( k ) uses the definition of @xmath411 and @xmath412 .",
    "recalling that @xmath399 in completes the proof .      defining the lyapunov drift as @xmath413 , and squaring the queue update",
    ", we obtain @xmath414 where ( a ) follows from the definition of @xmath200 in assumption [ assp.dualgrad ] .",
    "multiplying by @xmath415 and adding @xmath79 , yields @xmath416 where ( b ) uses the definition of @xmath129 , and ( c ) is the definition of the instantaneous lagrangian . taking expectations on the both sides of over @xmath35 conditioned on @xmath33",
    ", it holds that @xmath417+\\mathbb{e}\\left[\\psi_t(\\mathbf{x}_t)\\big|\\mathbf{q}_t\\right]\\nonumber\\\\      \\stackrel{(d)}{=}&{\\cal d}(\\bm{\\gamma}_t)+\\mathbb{e}\\left[(\\bm{\\theta}-\\hat{\\bm{\\lambda}}_t)^{\\top}(\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t)\\big|\\mathbf{q}_t\\right]+{\\mu m^2}/{2}\\nonumber\\\\        \\stackrel{(e)}{\\leq}&{\\psi}^{*}+\\mathbb{e}\\left[(\\bm{\\theta}-\\hat{\\bm{\\lambda}}_t)^{\\top}(\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t)\\big|\\mathbf{q}_t\\right]+{\\mu m^2}/{2}\\end{aligned}\\ ] ] where ( d ) follows from the definition of the dual function , while ( e ) uses the weak duality that @xmath418 , and the fact that @xmath419 ( cf . the discussion after ) .",
    "taking expectations on both sides of over all possible @xmath33 , summing over @xmath376 , dividing by @xmath313 , and letting @xmath404 , we arrive at @xmath420\\nonumber\\\\      \\!\\!\\ !",
    "\\stackrel{(f)}{\\leq}&{\\psi}^{*}\\!\\!+\\!\\!\\lim_{t\\rightarrow \\infty } \\!\\frac{1}{t } { \\sum_{t=1}^{t}\\mathbb{e}\\!\\left[(\\bm{\\theta}\\!-\\!\\hat{\\bm{\\lambda}}_t)\\!^{\\top}\\!(\\mathbf{a}\\mathbf{x}_t\\!+\\!\\mathbf{c}_t)\\right]}\\!\\!+\\!\\frac{\\mu m^2}{2}\\!+\\!\\!\\lim_{t\\rightarrow \\infty}\\!\\!\\!\\frac{\\mu\\|\\mathbf{q}_{1}\\|^2}{2t}\\nonumber\\\\   \\!\\!\\!\\stackrel{(g)}{\\leq } & { \\psi}^{*}\\!+\\!\\lim_{t\\rightarrow \\infty } \\frac{1}{t } { \\sum_{t=1}^{t}\\mathbb{e}\\left[(\\bm{\\theta}-\\hat{\\bm{\\lambda}}_t)^{\\top}(\\mathbf{a}\\mathbf{x}_t+\\mathbf{c}_t)\\right]}\\!+\\!\\frac{\\mu m^2}{2}\\!\\end{aligned}\\ ] ] where ( f ) comes from @xmath421\\geq 0 $ ] , and ( g ) follows because @xmath422 is bounded .",
    "one can follow the derivations in - to show , which is the second term in the rhs of .",
    "therefore , we have from that @xmath423-{\\psi}^ { * } \\leq \\!{\\cal o}(\\mu)+\\frac{\\mu m^2}{2}={\\cal o}(\\mu)\\end{aligned}\\ ] ] which completes the proof .",
    "l.  tassiulas and a.  ephremides , `` stability properties of constrained queueing systems and scheduling policies for maximum throughput in multihop radio networks , '' _ ieee trans .",
    "_ , vol .",
    "37 , no .  12 , pp .",
    "19361948 , dec . 1992 .",
    "t.  chen , x.  wang , and g.  b. giannakis , `` cooling - aware energy and workload management in data centers via stochastic optimization , '' _",
    "ieee j. sel .",
    "topics signal process . _ ,",
    "10 , no .  2 ,",
    "402415 , mar .",
    "2016 .",
    "j.  gregoire , x.  qian , e.  frazzoli , a.  de  la  fortelle , and t.  wongpiromsarn , `` capacity - aware backpressure traffic signal control , '' _ ieee trans .",
    "control of network systems _ , vol .  2 , no .  2 ,",
    "pp . 164173 , june 2015 .",
    "a.  beck , a.  nedic , a.  ozdaglar , and m.  teboulle , `` an @xmath424 gradient method for network resource allocation problems , '' _ ieee trans .",
    "control of network systems _ , vol .  1 , no .  1 ,",
    "6473 , mar .",
    "j.  liu , a.  eryilmaz , n.  b. shroff , and e.  s. bentley , `` heavy - ball : a new approach to tame delay and convergence in wireless network optimization , '' in _ proc .",
    "ieee infocom _",
    ", san francisco , ca , apr .",
    "2016 .",
    "a.  g. marques , l.  m. lopez - ramos , g.  b. giannakis , j.  ramos , and a.  j. caamao , `` optimal cross - layer resource allocation in cellular networks using channel - and queue - state information , '' _ ieee trans . veh .",
    "_ , vol .",
    "61 , no .  6 , pp . 27892807 , jul",
    ". 2012 .",
    "n.  l. roux , m.  schmidt , and f.  r. bach , `` a stochastic gradient method with an exponential convergence rate for finite training sets , '' in _ proc .",
    "advances in neural information processing systems _ , lake tahoe , nv , dec . 2012 , pp . 26632671",
    ".    a.  defazio , f.  bach , and s.  lacoste - julien , `` saga : a fast incremental gradient method with support for non - strongly convex composite objectives , '' in _ advances in neural info . process .",
    "_ , montral , canada , dec .",
    "2014 , pp . 16461654 ."
  ],
  "abstract_text": [
    "<S> network resource allocation shows revived popularity in the era of data deluge and information explosion . </S>",
    "<S> existing stochastic optimization approaches fall short in attaining a desirable cost - delay tradeoff . recognizing the central role of lagrange multipliers in network resource allocation , a novel learn - and - adapt stochastic dual gradient ( la - sdg ) method is developed in this paper to learn the empirical optimal lagrange multiplier from historical data , and adapt to the upcoming resource allocation strategy . </S>",
    "<S> remarkably , it only requires one more sample ( gradient ) evaluation than the celebrated stochastic dual gradient ( sdg ) method . </S>",
    "<S> la - sdg can be interpreted as a foresighted learning approach with _ an eye on the future _ , or , a modified heavy - ball approach from an optimization viewpoint . </S>",
    "<S> it is established - both theoretically and empirically - that la - sdg markedly improves the cost - delay tradeoff over state - of - the - art allocation schemes .    </S>",
    "<S> first - order method , stochastic approximation , statistical learning , network resource allocation . </S>"
  ]
}