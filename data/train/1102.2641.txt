{
  "article_text": [
    "among shannon s many observations in the seminal paper on information theory was that , by increasing block size , the compression rate of a block code for a memoryless source can get arbitrarily close to the source entropy rate . in particular , given a block of shannon entropy @xmath0 bits , prefix coding methods such as huffman coding can code the block with an expected length @xmath1 , where @xmath2 . if @xmath3 is the probability of the @xmath4th item , which has a codeword of length @xmath5 , then @xmath6 where @xmath7 and the sum is , without loss of generality , taken over the @xmath8 possible items .",
    "a constant absolute difference translates into an arbitrarily close - to - entropy compression ratio as blocks grow in size without bound .",
    "the lower bound is fundamental to the definition of entropy , while the upper bound is easily seen by observing the suboptimal shannon code .",
    "this code , that in which an event of probability @xmath9 is coded into a codeword of length @xmath10 , will always have expected length less than @xmath11 and never have expected length less than  @xmath1 .",
    "this _ unit - sized bound _",
    "is preserved even for many nonlinear optimization criteria .",
    "such criteria are encountered in a variety of lossless compression problems in which expected length is no longer the value to minimize . in particular , consider @xmath12 minimizing this utility solves several problems involving compression for queueing@xcite , compression with uncertainty@xcite , one - shot communications@xcite , and unreliable communications@xcite .",
    "it is closely related to rnyi entropy @xmath13 in the sense that , for @xmath14 , @xmath15 limits define rnyi entropy for @xmath16 , @xmath17 , and @xmath18 , so that @xmath19 ( the logarithm of the number of events in @xmath9 ) , @xmath20 ( the shannon entropy of @xmath9 ) , and @xmath21 ( the min - entropy ) . over a constant @xmath9 ,",
    "entropy is nonincreasing over  @xmath22@xcite .",
    "@xmath23 is also closely related to _ exponential - average redundancy _ or _ exponential redundancy _",
    "@xmath24 if we substitute @xmath25 and @xmath26 we find @xmath27 this transformation  shown previously in @xcite  provides a reduction from @xmath23 to @xmath28 , allowing bounds for the former to apply  with the addition of the entropy term  to the latter .    for both the traditional and exponential utilities",
    ", we can improve on the unit - sized bound given the probability of one of the source events .",
    "this was first done with the constraint that the given probability be the most probable of these events@xcite , but here , as in some subsequent work@xcite , we drop this constraint . without loss of generality ,",
    "we call the source symbols @xmath29 ( from most to least probable ) , and call the symbol with known probability  @xmath30 ; that is , @xmath31 is known , but not necessarily @xmath30 itself .    in traditional linear optimization , upper and lower bounds for @xmath28",
    "are known such that probability distributions can be found achieving or approaching these bounds@xcite ; i.e. , they are _",
    "tight_. in the exponential cases , @xcite took @xmath32 ( @xmath33 ) and @xmath34 ( @xmath35 ) , using inequality relations to find not - necessarily - tight bounds on these problems in terms of tight bounds for the limit cases .",
    "the goal here is to improve the bounds .",
    "we seek to find an upper bound @xmath36 and lower bound @xmath37 such that , for every probability distribution @xmath9 , optimal codeword lengths @xmath38 satisfy : @xmath39 for any  @xmath30 . for such values , ( [ trans ] )",
    "results in : @xmath40 where @xmath41 and @xmath42 denotes the utility for optimal lengths given @xmath9 and  @xmath43 .",
    "thus we can restrict ourselves to exponential redundancy , which is more amenable to the analysis used here .",
    "most applications of the exponential length utility concern only @xmath45 ( @xmath44 for the redundancy equivalent ) .",
    "the first known application , introduced in humblet s dissertation@xcite , is in a queueing problem originally posed by jelinek@xcite .",
    "codewords coding a random source are temporarily stored in a finite buffer ; these are chosen such that overflow probability is minimized .",
    "another application considers a source with uncertain probabilities , one in which we only know that the relative entropy between the actual probability mass function and @xmath9 is within a known bound@xcite .",
    "a third , more recent application , omitted in the interest of brevity but described in @xcite , is a modified case of the application in the next paragraph .      an application for @xmath47 involves single - shot communications with a communication channel having a window of opportunity of geometrically - distributed length ( in bits)@xcite .",
    "if the distribution has parameter @xmath43 , the probability of successful transmission is @xmath48 = a^{l_a(p,{\\mbox{\\boldmath \\scriptsize $ l$ } } ) } = \\sum_{i=1}^n p_i a^{l_i}.\\ ] ] maximizing this is equivalent to minimizing ( [ one ] ) .",
    "the solution is trivial for @xmath49 ( @xmath50 ) , a case not covered by rnyi entropy , and thus not applicable here .",
    "the variation of the huffman algorithm which finds an optimal code for exponential redundancy differs as follows : while huffman coding inductively pairs the two lowest probabilities ( weights ) @xmath51 and @xmath52 , combining them into an item _ weighted _ @xmath53 , optimizing exponential redundancy requires the combined item to be weight @xmath54 the optimality of this is shown in @xcite and can illustrated with an exchange argument ( e.g. , @xcite for the linear case ) .",
    "an exchange argument also inductively illustrates that such an algorithm , depending on how ties are broken , can achieve _ any _ optimal set of codeword lengths : clearly the only optimal code is obtained for @xmath55 .",
    "let @xmath56 be the smallest @xmath8 for which there is a set of @xmath57 that is optimal but can not be obtained via the algorithm . since @xmath57 is optimal ,",
    "consider the two smallest probabilities , @xmath58 and @xmath59 . in this optimal code ,",
    "two items having these probabilities ( although not necessarily items @xmath60 and @xmath56 ) must have the longest codewords and must have the same codeword lengths .",
    "otherwise , we could exchange the codeword with a longer codeword corresponding to a more probable item and improve the utility function , showing nonoptimality .",
    "merge these two items into one with probability @xmath61 , as per the algorithm .",
    "because of the nature of @xmath62 , this is a reduced problem , i.e. , an equivalent optimization to the original problem .",
    "this means that there is a set of lengths optimal for this problem such that all non - merged items are identical to the corresponding @xmath5 , while the merged item is simply one shorter than the longest  @xmath5 .",
    "since we inductively assumed all optimal length sets could be produced for @xmath60 , the assumption is verified for all  @xmath8 .        1 .   for @xmath44 ,",
    "items are always merged by nondecreasing weight and the total probability of any subtree is no greater than the weight of the ( root of the ) subtree . for @xmath46 , the total probability of any subtree",
    "is no less than the weight of the subtree .",
    "the weight of the root of the coding tree is @xmath65 .",
    "if @xmath66 , then an optimal code can be represented by a _",
    "complete tree _ ,",
    "that is , a tree with leaves at depth @xmath67 and @xmath68 only ( with @xmath69 ) .",
    "again we use induction , this time using trivial base cases of sizes @xmath17 and @xmath70 , and assuming the propositions true for sizes @xmath71 and smaller .",
    "we assume without loss of generality that , for size @xmath8 , items @xmath71 and @xmath8 are the first to be merged .",
    "we use weight terminology ( @xmath72 ) instead of probabilities ( @xmath9 ) because reduced problems need not have weights sum to  @xmath17 .",
    "the subtree part of the first property considers subtrees of size @xmath8 , not necessarily the whole coding tree .",
    "all we need to have a successful reduction to size @xmath71 is to show the following : @xmath73 for @xmath74 , and @xmath75 for @xmath76 , with equality in either case if and only if @xmath77 . the inequalities are due to the identical property of the generalized mean in @xcite : @xmath78 with , in this case , @xmath79 , @xmath80 , @xmath81 , and @xmath82 as @xmath83 in ( [ lhs ] ) ( left - hand side of ( [ rhs2 ] ) ) and @xmath17 on ( [ rhs ] ) ( right - hand side of  ( [ rhs2 ] ) ) .",
    "it immediately follows in the @xmath44 case that @xmath84 .",
    "thus , the first two weights of the entire tree merge form a weight no less than either original weight , and all remaining weights are also no less that those two weights .",
    "call the resulting lengths  @xmath85 .    to prove the second property , note that , after merging the aforementioned two least weighted items , we have @xmath71 weights , and thus a conforming reduced problem .",
    "call the combined weight @xmath86 .",
    "then @xmath87 where the third equality is due to @xmath88 and ( [ mmprcomb ] ) .",
    "the third property is shown via the operation of the algorithm from start to finish : first note that @xmath89 for any tree created using the huffman - like procedure , since all internal nodes have two children",
    ". now think of the procedure as starting with a priority queue of input items , ordered by nondecreasing weight from head to tail . after merging two items , obtained from the head , into one compound item",
    ", that item is placed back into the queue . since we are using a priority queue ,",
    "the merged item is placed such that its weight is no smaller than any item ahead of it and is smaller than any item behind it .    in keeping items",
    "ordered , we obtain an optimal coding tree .",
    "a first derivative test shows that @xmath62 is nondecreasing on both inputs for any @xmath90 .",
    "thus merged items are created in nondecreasing weight .",
    "if @xmath66 , the first merged item can be inserted to the tail of the queue ; since merged items are created in nondecreasing weight , subsequent items are as well .",
    "this is a sufficient condition for a complete tree being optimal ( * ? ? ?",
    "* lemma  2 ) .          making transitions between @xmath94 and @xmath95 at @xmath96 and @xmath97 with transitions between @xmath98 and @xmath99 at @xmath100 these improve bounds on the optimal code , and",
    "the upper bound is a strict inequality , in that @xmath101 moreover , the lower bounds are achievable given @xmath102 and the upper bounds are approachable given @xmath103 .",
    "in addition , for @xmath104 and @xmath46 , we have the following secondary upper bound : @xmath105      the lower bound calculation is : @xmath106 the first equality is due to the definition , while the other equalities follow from algebra .",
    "the summation following ( a ) is a sum of the @xmath107 power of @xmath108 positive terms which sum to  @xmath17 .",
    "consider these values , which include @xmath109 repetitions of each @xmath110 for @xmath111 , as a probability distribution called  @xmath112 .",
    "then the summation is related to the @xmath107-rnyi entropy of @xmath112 ; substituting using its definition ( [ entropy ] ) leads to ( [ qentropy ] ) below . furthermore , because @xmath113 and @xmath114 is nonincreasing with @xmath22 , ( [ qentropy ] ) is bounded as follows : @xmath115 this results in inequality ( b ) , completing the lower bound by substituting minimizing @xmath98 for  @xmath116 .",
    "the transitions follow from algebraically finding where there are two minimizing values .",
    "a code achieving this lower bound , for @xmath117 for some @xmath98 , is @xmath118 by theorem  [ complete ] , this has a complete coding tree  recall @xmath119  in this case with @xmath120 one bit shorter than the other lengths .",
    "this is easily calculated as achieving the lower bound .",
    "since @xmath94 is arbitrary , the bound is obtained by choosing the value offering the strictest bound .",
    "this upper bound is approached for any @xmath91 over @xmath123 for @xmath124 ( i.e. , @xmath125 and @xmath126 ) .",
    "now consider @xmath46 and @xmath104 . as noted in @xcite , an application of lyapunov s inequality for moments@xcite yields @xmath127 for @xmath128 , and , in particular , @xmath129 in this case , where @xmath130 via limits .",
    "since this is true for all values , it is true over the minimization , and bounds for the usual linear case apply here . in particular , as found in @xcite and noted in @xcite , if we define @xmath131 where @xmath132 is the root of the equality of the two terms , then this serves as an upper bound ( given most probable @xmath102 ) on optimal redundancy ( linear , and thus also @xmath46 ) in @xmath133 .",
    "since this never exceeds the bound we seek here , we can now consider only @xmath134 .",
    "consider first those cases in which ( [ tightupper ] ) is greater than @xmath135 . in these cases , we use the fact that @xmath136 $ ] to note that the maximum upper bound over this range  using ( [ p1b1 ] ) and ( [ p1b2 ] )  is @xmath137 at @xmath138 , thus supplying the upper bound for the range @xmath139 , where @xmath140 is the first root of the equality of the two terms in the maximization at ( [ tightupper ] ) .",
    "over @xmath141 , we first note that @xmath135 is an upper bound via similar logic : if @xmath142 , we already know that this is an upper bound .",
    "otherwise @xmath143 , and ( [ p1b1 ] ) using @xmath144 provides an upper bound not exceeding  @xmath135 .",
    "[ fig ] illustrates these bounds at a handful of values , and at limits @xmath145 , @xmath16 , and  @xmath18 . for @xmath146 ,",
    "lhpital s rule reveals the lower bound to be the optimal one of theorem  2 of @xcite for @xmath125 and theorem  4 of @xcite for arbitrary  @xmath30 .",
    "if one replaces optimal @xmath94 with ( possibly suboptimal ) @xmath147 , the upper bound becomes the suboptimal one of lemma  1 of @xcite .",
    "taking @xmath148 using , for any positive @xmath149 , @xmath150 yields the optimal bounds of @xcite , which are both tight .",
    "the approach here is similar to @xcite .",
    "consider the coding step at which item @xmath17 gets combined with other items ; we wish to prove that this is the last step . at the beginning of this step the ( possibly merged )",
    "items left to combine are @xmath154 , where we use @xmath155 to denote the set of ( individual ) items combined into a ( possibly ) compound item , and @xmath156 to denote its weight . at this step , @xmath102 is smaller than all but possibly one of @xmath155 , so @xmath157 is less than the sum of weights , which in turn is less than or equal to  @xmath17 .",
    "thus @xmath158 is at most three .",
    "consider items @xmath159 , @xmath160 , and  @xmath161 .",
    "assume without loss of generality that @xmath162 . if @xmath163 is not compound , @xmath159 has the greatest weight and we are finished .",
    "if it is compound , call its two subtrees @xmath164 and @xmath165 , in order of nonincreasing weight .",
    "clearly @xmath166 due to the combination order , so @xmath167 .",
    "thus @xmath168 , so @xmath169 , and we can combine these two items to achieve the optimal code .",
    "this is tight in the sense that @xmath170 has @xmath171 for @xmath172 .    as an example of the improvement these bounds offer",
    ", we revisit the examples of @xcite , which consider minimizing @xmath23 over benford s",
    "distribution@xcite : @xmath173 for @xmath174 and @xmath175 given  @xmath102 .",
    "the bounds of @xcite show that optimal @xmath176 for such a @xmath102 must lie in @xmath177 .",
    "this is identical to the application of the current result , which should not surprise , as the prior bounds apply and are tight in cases where we can show  as in this case  that @xmath153 .",
    "a more interesting case is that of @xmath175 , for which the prior bounds , @xmath178 $ ] , are superseded by the tighter @xmath179 ; optimal @xmath180 ."
  ],
  "abstract_text": [
    "<S> we present new lower and upper bounds for the compression rate of binary prefix codes optimized over memoryless sources according to two related exponential codeword length objectives . </S>",
    "<S> the objectives explored here are exponential - average length and exponential - average redundancy . </S>",
    "<S> the first of these relates to various problems involving queueing , uncertainty , and lossless communications , and it can be reduced to the second , which has properties more amenable to analysis . </S>",
    "<S> these bounds , some of which are tight , are in terms of a form of entropy and/or the probability of an input symbol , improving on recently discovered bounds of similar form . </S>",
    "<S> we also observe properties of optimal codes over the exponential - average redundancy utility . </S>"
  ]
}