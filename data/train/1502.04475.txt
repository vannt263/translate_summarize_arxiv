{
  "article_text": [
    "a significant and persistent problem has emerged concerning models for high - energy nucleus - nucleus (  ) collision data from the relativistic heavy ion collider ( rhic ) and the large hadron collider ( lhc ) .",
    "distinct classes of data models with divergent physics implications are invoked to support two narratives : a high - energy physics ( hep)/jets narrative in which the essential phenomenon is dijet production  @xcite and a quark - gluon plasma ( qgp)/flow narrative in which the essential phenomenon is a flowing dense qcd medium or qgp and dijets play no significant role  @xcite .",
    "the hep / jets narrative emerges spontaneously from an analysis program based on spectrum and correlation data models derived from the observed differential structure of available data  @xcite .",
    "in contrast , models emerging from the qgp / flow narrative tend to rely on theoretical motivations coupled with data and information selection ( e.g.  cuts , preferred   centralities , ratio measures )  @xcite .",
    "a comparison of rhic results and interpretations is presented in ref .",
    "@xcite .",
    "for example , 2d angular correlations from high - energy nuclear collisions include only a few structures common to all collisions from  to central  at rhic energies .",
    "a simple mathematical model of those structures describes almost all data accurately with no significant residual structure  @xcite .",
    "no theoretical assumptions motivated the data model .",
    "three of the four principal model elements have been interpreted _ post facto _ as representing dijet production and projectile - nucleon dissociation  @xcite .",
    "interpretation of the fourth element , an independent azimuth quadrupole , remains in question  @xcite .",
    "differential analysis of hadron  spectra reveals two components modeled by simple functions  @xcite .",
    "one component is identified with fragments from dijets described quantitatively by qcd calculations  @xcite .",
    "most spectrum and correlation structures appear to be consistent with the hep / jets narrative .",
    "alternative models motivated by the qgp / flow narrative include quantity @xmath4 [ fourier coefficient of function @xmath0 fitted to 1d projections of 2d angular correlations ] interpreted to represent elliptic flow  @xcite , a blast - wave spectrum model interpreted to measure radial flow  @xcite , spectrum ratio @xmath5 interpreted to indicate jet quenching within a dense qcd medium  @xcite , and dihadron correlation analysis via background subtraction interpreted to represent jet structure  @xcite . ``",
    "higher harmonic '' flows have been inferred recently from azimuth distributions via fourier - series models  @xcite .",
    "the same underlying particle data are therefore characterized and interpreted with competing mathematical models applied to different data selections , variables and measured quantities .",
    "judgments on the validity and relative merits of competing data models have relied historically on comparisons of minimum-@xmath6 values and qualitative arguments based on consistency of a given narrative across selected measured quantities .",
    "while such an approach might suffice when the underlying physical processes and models are simple , the complexity of   phenomenology and lack of consistent quantitative criteria have impeded progress in resolving conflicts .    to address this problem we require a formal context in which competing data models are evaluated on a statistically sound basis , and a `` best '' model may be selected that either does not rely on unspoken _ a priori _ physics assumptions or renders such assumptions quantifiable .",
    "we suggest that this context exists in the form of bayesian inference ( bi ) which provides both a formal mathematical framework and the necessary concepts to represent prior knowledge , evaluate candidate models for different parameter values and thereby establish value judgments on models as a whole  @xcite .",
    "each data model is rated not only by how well it describes some data or how much data it describes well , but also by the `` cost '' of the model in terms of complexity and parameter number ( occam penalty ) and associated physical assumptions .    in this study",
    "we focus on 1d projections onto azimuth @xmath7 of 2d angular correlations reported in ref .",
    "@xcite , currently one of the most contentious areas of rhic / lhc data analysis .",
    "we consider several popular data models and evaluate them according to bi methods to determine whether a uniquely preferred data model can be established without recourse to _ a priori _ physics assumptions .",
    "this article is arranged as follows : section  [ bayes1 ] presents the basics of bayesian inference .",
    "section  [ fourier ] describes fourier power spectra ( ps ) and their properties .",
    "section  [ meths ] summarizes analysis methods applied to correlation data .",
    "section  [ corr ] introduces the correlation data used for this study .",
    "sections  [ bin10a ] , [ bin8a ] and [ bin0 ] apply bi and ps methods to azimuth projections from three centralities of 200 gev  collisions .",
    "section  [ system ] presents systematic - uncertainty estimates .",
    "sections  [ disc ] and  [ summ ] present discussion and summary . appendices",
    "a and b consider the geometry of bi analysis and periodic peak arrays respectively .",
    "bayesian inference addresses the problem of relating parametrized model functions to available data in an optimal manner .",
    "given specific data values the best set of parameter values for each model is determined based on the _ likelihood _ function .",
    "several models are then compared based on each model s _ evidence _ , an integral measure defined below .",
    "the most plausible and therefore preferred data model produces the largest evidence value .      in the present study we focus on aspects of bayesian inference that correspond directly with the methodology of @xmath6 minimization .",
    "given a set of @xmath9 data points @xmath10 with experimentally determined standard errors @xmath11 on @xmath12 the conventional @xmath6 statistic evaluating the goodness of fit of model function @xmath13 with @xmath14 parameters @xmath15 is @xmath16 as stated in ref .",
    "@xcite the @xmath6 measure assumes a gaussian distribution of data - sample fluctuations about mean values which we accept as a reasonable approximation for 1d rhic / lhc data projections . in what follows model functions",
    "are represented by @xmath17 , a vector function mapping parameter space @xmath18 to data space @xmath19 .",
    "most model comparisons are based on @xmath6/dof , where the number of _ fit _ degrees of freedom ( dof ) is assumed to be the number of data points @xmath9 minus the number of free model parameters @xmath14 .",
    "minimizing @xmath6 without considering the fit dof is clearly misleading since there are infinitely many models with @xmath20 free parameters that might describe the same @xmath9 data points with @xmath21 @xcite .",
    "we require a mechanism to penalize excess model parameters such that a simple few - parameter model that describes the data well may be favored over more - complex models .",
    "that mechanism exists in the form of bayesian inference .",
    "distinction may be drawn between logical inference on the one hand , in which nominally - valid conclusions are drawn via a logical chain of argument from premises assumed to be true and rational inference on the other , in which patterns or events ( i.e.  data ) are used to improve our understanding of the physical system , either augmenting or displacing previous understanding .",
    "both the acquired data and the modified understanding may be uncertain to some degree as measured by probabilities .",
    "rational inference includes induction , in which newly - acquired data are employed to formulate or refine a model , and deduction in which a fixed model is used to predict values of data not yet acquired  @xcite .",
    "bayesian inference is a formal recipe for rational inference based on bayes theorem  @xcite .",
    "`` understanding '' in this context means that reality in the form of data or data - derived quantities is well described by a parametrized model .",
    "a given set of parameter values predicts a specific set of _ possible _ data values .",
    "previous understanding including uncertainties is represented by the _",
    "prior _ , a probability distribution function ( pdf ) on possible parameter values .",
    "as new data are acquired bi provides a means to update the pdf on model parameters to effect improved understanding in the form of the posterior pdf , thereby refining the model by reducing the volume of its parameter space or falsifying the model altogether if the new data fall outside the model s predicted data volume .",
    "bayesian inference is based on relations among joint , conditional and marginal pdfs and related unnormalized functions distributed on data and model - parameter spaces  @xcite .",
    "external factors common to all models that may influence the inference process are represented by a comprehensive parameter set @xmath22 suppressed below .",
    "our notation follows that in refs .",
    "@xcite and @xcite .    a model @xmath23 is defined by a joint pdf @xmath24 , where @xmath18 and @xmath19 are multidimensional spaces representing model - parameter values and data values .",
    "the corresponding conditional pdfs are @xmath25 and @xmath26 , and the marginal pdfs are @xmath27 and @xmath28 .",
    "the probability chain rule provides factorizations in the form @xmath29 .",
    "bayes theorem ( bt ) can then be expressed in either of two forms @xmath30 both of which are valid descriptions of a joint pdf .",
    "however , only the first line is applicable to bi analysis that proceeds from specific data values to improved parametrized data model , a unique bt application .      as applied to bi analysis some quantities in the first line of eq .",
    "( [ bayes ] ) must be defined more specifically . in this application quantity",
    "@xmath19 is not a variable on the space of all possible data ; it is a specific set of data values @xmath31 with uncertainties or errors @xmath32 .",
    "factor @xmath26 , a normalized conditional pdf on data space @xmath19 , is redefined as the _ likelihood _ function @xmath33 on parameter space @xmath18 for model @xmath23 given specific data @xmath31 and model function @xmath17 .",
    "@xmath27 is the _ prior _ pdf on model parameters @xmath18 determined before data @xmath31 are available .",
    "@xmath34 is the _ posterior _ pdf on parameters @xmath18 given the new data .",
    "denominator @xmath28 , also a pdf on space @xmath19 , is redefined as the _ evidence _ ( a number ) for model @xmath23 given specific data @xmath31 which we denote by the symbol @xmath35 . with those more - specific definitions the version of bayes theorem used for bi is @xmath36 which can be read as `` a posterior pdf on @xmath18 is derived from a prior pdf given data @xmath31 , likelihood l and evidence e. '' any change between prior and posterior represents _ information _ acquired by the model from the data .",
    "the result is an updated pdf on model parameters determined by newly - acquired specific data values @xmath31 .",
    "the posterior pdf on parameters @xmath18 provides considerably more information about the model than the best - fit parameter set @xmath37 and uncertainties @xmath38 derived from conventional @xmath6 model fits to data .      beyond determining posterior pdfs on parameters",
    "@xmath18 bayes theorem can be used on a higher level for comparisons among competing data models in the form @xmath39 where @xmath40 is the _ plausibility _ of model @xmath23 given data values @xmath31 and @xmath41 is the prior model probability within some assumed context represented by @xmath22 ( suppressed ) .",
    "the main goal of this study is comparison of competing model functions @xmath17 with all other bi elements maintained as similar as possible .",
    "evidence @xmath42 is just a normalization parameter in eq .",
    "( [ inference ] ) , but its absolute numerical value is important for model comparisons . because the likelihood is usually a peaked function on @xmath18 with single mode near some optimal parameter values @xmath37 the evidence defined in the first line below can be represented by laplace s approximation in the second line  @xcite @xmath43 where @xmath44 is the maximum likelihood and @xmath45 is the covariance matrix for model function @xmath17 with @xmath14 parameters .",
    "the negative log evidence is @xmath46 with usual @xmath6 parameter , and information @xmath47 is defined by @xmath48,\\end{aligned}\\ ] ] the information gained by model @xmath23 from specific data @xmath31 .",
    "information is the log of a volume ratio as discussed in the next subsection . in general",
    "@xmath6 decreases and @xmath47 increases as parameter - number index @xmath14 increases .",
    "the sum @xmath49 should then have a minimum corresponding to the maximum evidence for a specific model .",
    "for an optimized _ predictive _ model ( e.g.  a theory ) @xmath50 and @xmath51 fit dof (= data dof @xmath52 minus model dof @xmath14 ) .",
    "quick and easy comparisons between two models @xmath53 and @xmath54 can be obtained by calculating the evidence ratio @xmath55 , also known as an odds ratio .",
    "assuming equal model priors @xmath56 the _ bayes factor _ is @xcite @xmath57 comparisons among more than two models indexed by @xmath58 are effected by @xmath59 where @xmath60 replaces @xmath61 in eq .",
    "( [ phd ] ) .",
    "the model priors @xmath62 could be set equal assuming ignorance , but in practice assigned model priors may differ sharply among competing models , possibly reflecting strong prejudices .",
    "our use of differences in log evidence ( bayes factors ) rather than isolated values is consistent with the use of likelihood ratios ( e.g.neyman-pearson approach ) .",
    "evidence ratios are an improvement on likelihood ratios because the latter assume delta - function priors .",
    "information is generally defined as the logarithm of a volume ratio , the volumes being subsets of some space of alternatives before and after a message ( data ) is received conveying information .",
    "for instance , if a message reduces the number of possible alternatives by factor 2 then the amount of information received is @xmath63 : one `` bit '' of information is provided by the message .",
    "several definitions of information have been formulated ( e.g.shannon , rnyi ) , and the precise correspondence to a volume ratio varies from case to case . in some cases the terms `` information '' and `` entropy '' may be used interchangeably such that for example `` information gain '' may represent the difference between two entropies .    in eq .",
    "( [ infoeq1 ] ) factor @xmath64 is related to the prior volume @xmath65 of a model parameter space and @xmath66 approximates the posterior volume @xmath67 .",
    "thus , information @xmath68 is defined here as the natural log of the prior volume over the posterior volume . a prior pdf based on ignorance ( uniform or translation - invariant probability within some assumed boundaries for each parameter )",
    "is estimated by the product @xmath69 where the estimated @xmath70 for amplitude parameters may be based on differences of data extreme values , but the prior for angle parameters depends on circumstances .",
    "in this study the condition @xmath71 $ ] is based on the definition of the _ same - side _ peak at the azimuth origin .    since typical correlation - structure amplitudes ( e.g.  peak - to - peak excursions )",
    "are generally @xmath72 and given the assumed constraint on the gaussian width we assign @xmath73 for those cases .",
    "given certain algebraic relations it is reasonable to assume that cosine coefficients and uncertainties may be substantially smaller on average than the gaussian amplitude and width .",
    "for all cosine components in any model we assign @xmath74 .",
    "given those assignments the _ basic model _",
    "( defined below ) is somewhat disadvantaged ( smaller prior probability ) compared to models based only on cosine terms .",
    "further discussion of prior construction is found in ref .",
    "@xcite .",
    "the posterior volume is obtained from the determinant of the covariance matrix @xmath75 which , in the absence of significant covariances , is the product of the variances for the several model parameters .",
    "its square root is then the product of r.m.s .",
    "widths on parameters , the posterior volume . in this study the hessian ( matrix of second - order derivatives at maximum of the likelihood function derived from data @xmath31 ) is obtained , and the covariance matrix is constructed from the hessian elements .",
    "the information defined in eq .",
    "( [ infoeq1 ] ) permits a quantitative expression of occam s razor in two ways : ( a ) for a model with a large prior volume in parameter space ( representing many `` causes '' , some possibly unnecessary ) a substantial reduction in the parameter volume on encountering data @xmath31 automatically incurs an occam penalty by means of larger @xmath47 .",
    "( b ) the @xmath14-dependence of @xmath47 implies that while models with more parameters may have a smaller @xmath6 and larger likelihood , the extra parameters are also penalized by increased @xmath47 resulting in reduced overall model plausibility .",
    "the fourier power spectrum ( ps ) is an alternative information measure well understood in the context of signal processing .",
    "comparison of ps results with bi analysis may better convey the technical details and interpretations of the latter .",
    "the wiener - khinchin theorem  @xcite states that the fourier transform of a two - particle autocorrelation is the corresponding power spectrum of an underlying single - particle distribution .",
    "data autocorrelations @xmath76 with @xmath9 elements are periodic , symmetrized about 0 and @xmath77 and described by a ps with @xmath78 $ ] and @xmath79 . the ps expansion of autocorrelation data @xmath80 might be viewed as a model function from which the power - spectrum elements @xmath81 could be determined by model fitting . however , in this study the ps elements are obtained directly by integrating the data @xmath82 note that @xmath83 is the `` total power '' @xmath84 ( with @xmath85 independent elements ) , and @xmath86 is the mean value of the 1d autocorrelation ( which , for data histograms introduced below and used in this study , is set to zero ) .    the power spectrum for a sample sequence may contain a deterministic `` signal '' component and a random ( white ) noise component .",
    "the signal may be localized at smaller wave number ( index @xmath87 ) , while an approximately flat white - noise spectrum is revealed at larger index values if the sample rate or bin number ( resolution ) is large enough ( see nyquist frequency limit below ) .",
    "the white - noise amplitude should correspond to the estimated statistical ( poisson ) error used in @xmath6 fits to a sample sequence and to the r.m.s .",
    "error inferred from fit residuals .",
    "the nyquist limit applied to periodic azimuth implies that the power spectrum must be symmetric about the bin on @xmath87 containing @xmath88 . for @xmath89",
    "there are then @xmath90 independent ps elements ( including @xmath91 ) and 13 unique autocorrelation data bins whose contents may be correlated by one or more parent processes . for the broader correlation structures considered here",
    "the bin number , and therefore the nyquist limit , is adequate . for the narrower",
    "be / electron peak ( defined below ) the bin number ( hence angle resolution ) is insufficient , but that structure is not important for this analysis .",
    "power spectra ps should be distinguished from fourier series ( fs - only ) fit models .",
    "a ps consisting of elements @xmath81 evaluated for all index values @xmath92 $ ] completely characterizes a data autocorrelation .",
    "fs - only models have a varying number of elements indexed by @xmath93 , @xmath94 $ ] being the number of parameters for a model .",
    "high - energy nuclear collisions at the rhic and lhc produce hadrons in each collision ranging in number from a few to thousands ( depending on collision centrality ) via several physical mechanisms . by studying properties of hadron yields , spectra and correlations",
    "we seek to identify and characterize the various underlying mechanisms . in this study",
    "we apply bi methods to evaluate several mathematical models of 2d angular correlations projected to 1d azimuth . in this section",
    "we summarizes basic analysis methods that produce the angular correlation data and our strategy for bi evaluation of the data models .",
    "high - energy nuclear collisions are described efficiently within a cylindrical coordinate system @xmath95 where ( relative to the collision axis ) @xmath96 is the transverse momentum , @xmath7 is the azimuth angle from a reference direction and pseudorapidity @xmath97 \\approx \\cos(\\theta)$ ] is a measure of polar angle @xmath98 , the approximation being valid near @xmath99 ( @xmath100 ) . a bounded detector angular acceptance is denoted by intervals ( @xmath101 ) on the primary single - particle space @xmath102 .    in general , two - particle correlations are measured on the 6d space @xmath103",
    "-integral angular correlations are measured on the 4d space @xmath104 . within a limited @xmath105 acceptance and over @xmath106",
    "azimuth the angular correlation structure may be approximately invariant along a sum axis @xmath107 ( stationarity ) . in that case",
    "averages along @xmath108 for each value of the corresponding difference variable @xmath109 comprise an _ autocorrelation _ @xmath110 .",
    "angular correlations on @xmath102 are then measured as 2d densities @xmath111 without significant loss of information  @xcite .",
    "  collision centrality is measured by comparing a measured minimum - bias ( mb ) event distribution on charge multiplicity @xmath112 within some fiducial angular acceptance with a glauber monte carlo model of   collisions producing mb distributions on nucleon participant number @xmath113 and  binary - collision number @xmath114  @xcite .",
    "the intermediary is the   fractional cross section @xmath115 . for the data employed in this study centrality",
    "is designated by fractional cross section in percent , where 100% refers to extreme peripheral collisions and 0% refers to head - on collisions . for the data employed in this study collision events",
    "were sorted into eleven centrality bins : ten equal 10% centrality bins with the most - central 10% bin split into two 5% bins .",
    "the bins are numbered 0 ( most peripheral ) through 10 ( most central ) . the three ( corrected ) centrality intervals used in this study are 0 - 5% ( bin 10 ) , 9 - 18% ( bin 8) and 83 - 94% ( bin 0 ) .",
    "correlation structure is identified by comparing a 2d pair density @xmath116 with a reference density @xmath117 representing no significant correlations or some uninteresting background structure .",
    "@xmath117 can be based for instance on a factorization assumption ( @xmath118 ) or a distribution of mixed pairs formed from different but similar sample events ( @xmath119 ) .",
    "the difference @xmath120 should reveal correlation structure of interest .",
    "correlation structure may have several components arising from different collision mechanisms .",
    "correlation amplitudes may vary with collision conditions in characteristic ways , for instance proportional to @xmath112 , @xmath113 , @xmath114 or some combination . as a placeholder",
    "we define a _ per particle _",
    "measure @xmath121 since @xmath122 according to a factorization assumption , and @xmath123 is the mean single - particle charge density near the angular origin . practically speaking the correlation measure",
    "is obtained as @xmath124\\end{aligned}\\ ] ] where the ratio inside the square brackets reduces certain instrumental effects  @xcite . in what follows",
    "we refer to symbol @xmath125 to simplify notation .    a 2d autocorrelation in the form @xmath126 is a density defined with the prefactor @xmath127 .",
    "when integrated over @xmath128 the autocorrelation is a density on @xmath129 defined by prefactor @xmath130 .",
    "integration of @xmath131 over the azimuth acceptance should then give @xmath132 since @xmath133 has the same pair number as @xmath134 by construction .",
    "for each 1d data histogram we construct a ps as a reference for bi analysis and identify within the ps the signal and noise components .",
    "ps structure can be related 1-to-1 with bi elements , helping to clarify interpretation of the latter . based on results from ref .",
    "@xcite we compare the ps for a fitted 1d gaussian with each data ps .    for each model function @xmath17 we obtain the minimum @xmath6 ( maximum likelihood describing fit quality ) and information @xmath47 ( derived from priors and covariance matrix ) from fits to data histograms .",
    "we obtain evidence @xmath42 for each model from a combination of minimum @xmath6 and information @xmath47 .",
    "competition between @xmath6 and @xmath47 contrasts goodness of fit ( via @xmath6 ) with quantitative assessment of model - parameter `` cost '' or _ occam penalty _ ( via @xmath47 ) .",
    "one model function may achieve a quantitatively better fit to data than another model , but at the cost of extra model parameters that may favor the second model overall .",
    "we emphasize that the number of data dof in this study is small , only 11 for the projected 1d histograms analyzed here compared to the original 2d histograms with 169 dof .",
    "the small number of data dof presents unique challenges for data modeling and bi evaluation .",
    "the data we consider were published in the form of 2d binned histograms ( autocorrelations ) derived from 1.2 m 200 gev collision events sorted into eleven centrality classes based on charged - particle multiplicity  @xcite .",
    "depending on centrality each collision event may include from a few to more than a thousand charged particles within the detector acceptance @xmath135 .    in the present study we consider 1d projections of the 2d histograms onto azimuth difference @xmath129 represented as @xmath7 to simplify notation .",
    "the histogram bin size on azimuth is @xmath136 ( @xmath137 24 bins ) .",
    "the position variable is then @xmath138 with @xmath139 $ ] .",
    "the conjugate index for a ps ( sec .  [ fourier ] ) is @xmath140 $ ] .",
    "the argument of ps cosines is @xmath141 .",
    "the bin size has been optimized to match the observed correlation structure and provides sufficient resolution to retain all information in the data , as indicated for instance by the power spectrum in fig .",
    "[ power1 ] .",
    "the 2d data are symmetrized on both @xmath128 and @xmath129 .",
    "thus , only one quadrant of each 2d histogram is unique .",
    "the statistical errors on @xmath129 are uniform except for bins at 0 and @xmath77 where they are @xmath142 larger .",
    "the errors on @xmath128 are strongly varying due to the triangular pair acceptance on @xmath128 , with the largest errors at the acceptance edges @xmath143 .",
    "as noted , the 2d correlation histograms sum to zero by construction .",
    "we also adjust the 1d projections onto @xmath129 to zero sum leading to one less data dof ( 12 ) .",
    "figure  [ fig1 ] ( left panels ) shows 200 gev  2d angular correlations for centrality bin 0 ( 83 - 94% , @xmath144  collisions ) and bin 10 ( 0 - 5% ) . within the star tpc acceptance",
    "the -integral correlation data from  collisions include four principal components : ( a ) a same - side ( ss ) 2d peak at the origin on @xmath145 well approximated by a 2d gaussian for all -integral data , ( b ) an away - side ( as ) 1d peak on azimuth well approximated by an as dipole @xmath146/2 $ ] for all data and uniform to a few percent on @xmath128 ( having negligible curvature ) , ( c ) an azimuth quadrupole @xmath147 also uniform on @xmath128 to a few percent over the full angular acceptance of the star tpc , and ( d ) a narrow 1d peak on @xmath128 .",
    "there is also a sharp 2d exponential peak at ( 0,0 ) .",
    "that phenomenological description does not rely on physical interpretations of the components .",
    "( color online ) left : 2d angular autocorrelations from 200 gev  collisions for ( a ) 83 - 94% ( @xmath148  collisions ) and ( c ) 0 - 5% centralities .",
    "right : two - dimensional model fits to the histograms in the left panels obtained with eq .",
    "( [ 2dmodel ] ) .",
    ", title=\"fig:\",width=158,height=151 ] ( -90,99 ) * ( a ) *   ( color online ) left : 2d angular autocorrelations from 200 gev  collisions for ( a ) 83 - 94% ( @xmath148  collisions ) and ( c ) 0 - 5% centralities .",
    "right : two - dimensional model fits to the histograms in the left panels obtained with eq .",
    "( [ 2dmodel ] ) .",
    ", title=\"fig:\",width=158,height=151 ] ( -90,99 ) * ( b ) * +   ( color online ) left : 2d angular autocorrelations from 200 gev  collisions for ( a ) 83 - 94% ( @xmath148  collisions ) and ( c ) 0 - 5% centralities .",
    "right : two - dimensional model fits to the histograms in the left panels obtained with eq .",
    "( [ 2dmodel ] ) .",
    ", title=\"fig:\",width=158,height=151 ] ( -90,99 ) * ( c ) *   ( color online ) left : 2d angular autocorrelations from 200 gev  collisions for ( a ) 83 - 94% ( @xmath148  collisions ) and ( c ) 0 - 5% centralities .",
    "right : two - dimensional model fits to the histograms in the left panels obtained with eq .",
    "( [ 2dmodel ] ) . , title=\"fig:\",width=158,height=151 ] ( -90,99 ) * ( d ) *    based on subsequent comparisons of observed data systematics with theory the components ( a ) and ( b ) together are interpreted to represent minimum - bias dijets  @xcite .",
    "component ( c ) has been conventionally attributed to elliptic flow  @xcite .",
    "component ( d ) is attributed to projectile - nucleon dissociation . and the 2d exponential is attributed to bose - einstein ( quantum ) correlations and charge - neutral electron pairs from photoconversions ( denoted as the be / electron peak ) .",
    "the fit methods employed here are based on the the non - fisherian ansatz that data can be represented as the sum of a hypothesis ( any competing data parametrization ) plus noise .",
    "2d histograms from ref .",
    "@xcite [ e.g.  fig .",
    "[ fig1 ] ( a ) and ( c ) ] were fitted with a data model including several elements applicable to higher rhic energies and all  centralities . the 11-parameter model is @xmath149 \\right\\ } \\\\",
    "\\nonumber & + & a_{\\rm d } [ \\cos(\\phi_\\delta -    \\pi ) + 1]/2 + a_0 \\\\ \\nonumber & + & a_{\\rm q } 2\\cos(2\\ , \\phi_\\delta )    \\hspace{-.03 in } + \\hspace{-.03 in } a_\\text{soft}\\ ,    \\exp\\left\\{-\\frac{1}{2 } \\left ( \\frac{\\eta_{\\delta } } { \\sigma_{0 } }      \\right)^2 \\right\\ } \\\\",
    "\\nonumber & + & a_\\text{be } \\exp\\left\\{-      \\left [ \\left ( \\frac{\\phi_{\\delta}}{w_{\\phi_{\\delta } } } \\right)^2        \\hspace{-.08 in } + \\hspace{-.03 in } \\left(\\frac{\\eta_{\\delta } } {            w_{\\eta_{\\delta } } } \\right)^2 \\right]^{1/2 } \\right\\}.~~\\end{aligned}\\ ] ] the definitions of two parameters in that expression ( @xmath150 and @xmath151 ) are modified from those in ref .",
    "@xcite .",
    "figure  [ fig1 ] ( right panels ) shows typical 2d model fits with eq .",
    "[ 2dmodel ] compared to corresponding data histograms in the left panels .",
    "the fit residuals are consistent with bin - wise statistical errors .",
    "the general evolution with centrality is monotonic increase of the ss 2d peak and as dipole amplitudes ( dijet structure ) , substantial increase of the ss peak @xmath128 width , rapid decrease to zero of the 1d gaussian on @xmath128 ( soft component )  @xcite and non - monotonic variation of the quadrupole amplitude  @xcite .    for the present 1d study we develop simplified versions of the 11-parameter model . in more - central  collisions",
    "the soft component ( @xmath152 ) falls to zero amplitude , and the be / electron component ( @xmath153 ) becomes very narrow  @xcite .",
    "a 2d model applicable to more - central collisions then has 6 parameters @xmath154 \\right\\ }     \\nonumber \\\\    & + & a_{\\rm d } [ \\cos(\\phi_\\delta - \\pi)+1]/2     \\nonumber \\\\    & + & a_0     + a_{\\rm q } 2\\cos(2\\ , \\phi_\\delta ) .",
    "\\hspace{-.03 in } \\end{aligned}\\ ] ] the be / electron component remains significant in a few bins near the origin that can be removed from the fits .",
    "projection onto 1d azimuth represents large information reduction .",
    "the full 2d histogram with @xmath155 bins includes 169 independent bins ( one independent quadrant due to symmetrization ) , whereas 1d projections include at most 13 independent bins . a simplified model derived from the 2d data model but applicable to projected 1d azimuth correlations in more - central   collisions includes 5 parameters defined to be consistent with the ps introduced in sec .",
    "[ fourier ] @xmath156    \\nonumber \\\\    & - & a'_{\\rm d } 2\\cos(\\phi_\\delta )    \\nonumber \\\\    & + & a_0 + a_{\\rm q } 2\\cos(2\\ , \\phi_\\delta ) .",
    "\\hspace{-.03in}\\end{aligned}\\ ] ]    a further simplification is possible for the most - central ( 0 - 5% ) bin . the quadrupole amplitude @xmath151 for that centrality is observed to be consistent with zero  @xcite .",
    "the 1d model then includes only 4 parameters @xmath157    \\nonumber \\\\    & + & a_0 - a_{\\rm d } ' 2\\cos(\\phi_\\delta ) .",
    "\\hspace{-.03 in } \\end{aligned}\\ ] ] integrating eqs .",
    "( [ simpmod ] ) and ( [ wiener1 ] ) with differential factor @xmath158 gives @xmath159 the 1d data histograms have been adjusted to insure @xmath160 .",
    "a fit to bin-10 data with eq .",
    "[ simpmod ] determines an offset value @xmath161 . with other fitted parameter values",
    "we obtain @xmath162 the four - parameter 1d model can then be further reduced to a three - parameter model defined by @xmath163 - \\sigma_{\\phi_{\\delta } } / \\sqrt{2\\pi } \\right\\ }   \\nonumber \\\\ & - & a_{\\rm d } ' 2\\cos(\\phi_\\delta ) , \\hspace{-.03 in } \\end{aligned}\\ ] ] where each of two model components integrates to zero over @xmath106 .",
    "we therefore replace eq .",
    "( [ simpmod ] ) with eq .",
    "( [ simpmod2 ] ) referred to below as the `` basic model . ''    since all data histograms are corrected to @xmath160 to remove the offset dof the adjusted 13-bin 1d data histograms have 12 independent dof . but the bin at @xmath164 is removed from all model fits to exclude the be / electron component , reducing the effective data dof to 11 .",
    "the as dipole component is the limiting case of an as gaussian peak array ( see app .",
    "[ periodpeak ] for details ) . the r.m.s .",
    "peak width ( @xmath165 ) is large enough that only the @xmath166 as dipole term of the ps representation survives .",
    "we define alternative data models by adding to the basic model of eq .",
    "( [ simpmod2 ] ) successive cosine terms of the form @xmath167 , where @xmath168 for quadrupole , sextupole and octupole ( @xmath169 ) .",
    "we also define independent `` fs - only '' models as truncated fourier series with @xmath14 cosine terms and no other components .",
    "we first apply bi methods to the 1d azimuth projection from 0 - 5% central 200 gev  collisions .",
    "we fit the data with the basic model and obtain the data ps .",
    "we determine @xmath6 and information @xmath47 for fs - only models vs parameter number @xmath14 .",
    "we then evaluate evidence @xmath42 for several competing models and determine the posterior model probabilities .",
    "figure  [ 1ddata ] shows a projection of the 2d data histogram from 0 - 5% central 200 gev  collisions onto 1d @xmath129 ( points ) .",
    "24 bins are shown but only 13 are unique due to symmetrization about zero and @xmath77 .",
    "estimated statistical errors have been multiplied by factor 2 to make them visible ( extend outside the points ) .",
    "errors are a factor @xmath142 larger for the bins at 0 and @xmath77 because of symmetrization of the data about those bins .",
    "the bin at zero also includes a significant contribution from be / electrons not included in the models used for this exercise and is therefore excluded from all fits .",
    "the bin at @xmath77 includes a small excess due to a tracking - geometry distortion accommodated in some model fits by addition of a `` delta function . ''",
    "( color online ) 1d projection onto azimuth ( points ) from the 2d data histogram for 0 - 5% central 200 gev collisions in fig .",
    "[ fig1 ] ( c ) .",
    "statistical errors at 0 and @xmath77 are @xmath142 larger than the others due to symmetrization of data on the periodic variable .",
    "the bin - wise statistical errors 0.0037 have been multiplied by 2 to make them visible outside the data points .",
    "the ( red ) dashed curve is obtained from a fit to the data with the basic model of eq .",
    "( [ simpmod2 ] ) .",
    "a fit with an fs - only model including four or more terms would appear identical on the scale of this plot .",
    "a similar remark applies to corresponding data plots for two other centrality bins . ]",
    "a fit of the basic model to data is shown by the dashed ( red ) curve .",
    "the fitted model parameters are @xmath170 , @xmath171 and @xmath172 with @xmath173 for @xmath174 fit dof .",
    "figure  [ power1 ] shows the ps ( points and blue solid curve ) as a fourier transform of the data autocorrelation in fig .",
    "[ 1ddata ] using eq .",
    "( [ coef ] ) .",
    "the general structure includes a signal component at smaller wave number @xmath175 and a flat ( on average ) white - noise spectrum at larger wave number corresponding to the r.m.s .  statistical error in the data histogram .",
    "the noise - spectrum mean is about 0.001 ( dotted line ) .",
    "( color online ) power spectrum values @xmath81 ( points ) derived from the data in fig .",
    "[ 1ddata ] via eq .",
    "( [ coef ] ) .",
    "the ( red ) dashed curve is the gaussian ps described by eq .",
    "( [ fmm ] ) with width and amplitude corresponding to the fitted gaussian in fig .",
    "[ 1ddata ] .",
    "interval @xmath176 is consistent with a `` white - noise '' power spectrum ( dotted line ) representing the statistical noise in fig .",
    "[ 1ddata ] . ]    to aid interpretation of the data ps we include the predicted ps for a 1d gaussian ( red dashed curve ) with amplitude and width derived from the basic - model fit in fig .",
    "[ 1ddata ] .",
    "the ps amplitudes for a _ unit - amplitude _ periodic gaussian peak array on @xmath129 are given by ( app .",
    "[ periodpeak ] ) @xmath177 as the gaussian peak width @xmath178 increases the number of significant signal terms in the ps decreases .",
    "the gaussian ps coincides with the data ps for @xmath179 $ ] , and the data ps for @xmath176 is consistent with statistical noise .",
    "the data ps element for @xmath166 includes a negative contribution @xmath180 from the as peak ( dipole ) .",
    "we can assess the quality of the basic - model data description by determining the ps of the residuals , not of ( data @xmath181 model ) but of ( data @xmath181 gaussian ) only .",
    "the ps of the residuals should be equal to the ps difference in fig .",
    "[ power1 ] according to the linearity of eq .",
    "( [ coef ] ) .",
    "( color online ) the ps for residuals in the form ( data @xmath181 gaussian ) from fig .  [ 1ddata ] consistent with the white - noise part of the ps in fig .",
    "[ power1 ] , with mean approximately 0.001 .",
    "the negative ps value for @xmath166 ( not shown ) corresponds to the as dipole amplitude @xmath182 from the basic - model fit in fig .",
    "[ 1ddata ] . ]",
    "figure  [ noise ] shows the ps for ( data @xmath181 gaussian ) referring to the fitted gaussian in fig .",
    "[ 1ddata ] .",
    "the ps values for @xmath183 are consistent with the white - noise spectrum .",
    "the value for @xmath166 ( not shown ) is consistent with the fitted dipole amplitude . from this ps study",
    "we have a first indication that the @xmath184 basic model is _ sufficient _ to describe the bin-10 1d azimuth projection .",
    "we next apply bi methods to fs - only models of the data histogram in fig .",
    "[ 1ddata ] to establish a bi reference . in this application",
    "the number of parameters @xmath14 represents the largest value of fs index @xmath185 for a given fs - only model .",
    "varying @xmath14 represents different fs data models .",
    "we obtain the @xmath6 and information @xmath47 for each fs - only model .",
    "( color online ) @xmath6 ( upper solid curve and points ) and information @xmath186 ( dashed curve and points with uncertainty band ) vs number of parameters @xmath14 for fourier - series ( fs - only ) models .",
    "the sum ( log evidence , @xmath49 , dotted curve ) is also included .",
    "the lower solid curve is @xmath6 values for fits to residuals ( data @xmath181 basic model ) from fig .",
    "[ 1ddata ] consistent with the trend @xmath187 expected for no signal ( noise only ) in the data . ]",
    "figure  [ basicfit ] shows the basic elements of bi model fits .",
    "the upper ( blue ) solid curve and points represent the log likelihood ( ll ) in the form @xmath188 or @xmath6 .",
    "the ( red ) dashed curve shows information @xmath186 representing the parameter cost ( occam penalty , sec .",
    "[ occam ] ) .",
    "the ( black ) dotted curve represents the sum @xmath49 ( negative log evidence ) .",
    "the minimum for @xmath49 ( and maximum for evidence @xmath42 ) occurs at @xmath189 indicating the fs - only model preferred by the data .",
    "that result is consistent with fig .",
    "[ power1 ] indicating a @xmath189 fs - only model should exhaust the ps signal .",
    "the @xmath6 trend indicates that the fs model components are ideally ordered on index @xmath190 $ ] for the signal in these specific data , and is similar to the idealized trend suggested in fig .",
    "5.1 of ref .",
    "the largest decreases occur for the smallest index values .",
    "the interval with larger ( negative ) slope at smaller @xmath14 corresponds to accommodation of the data signal with increasing @xmath14 .",
    "the interval with smaller slope at larger @xmath14 indicates that additional fourier terms only accommodate statistical noise .",
    "the overall @xmath6 trend then matches the power - spectrum trend in fig .",
    "[ power1 ] .",
    "@xmath6 must go to zero when @xmath191 the number of data dof ( 11 in this case ) .",
    "the lower solid curve represents the @xmath6 for fits to the residuals ( data @xmath181 basic model ) from fig .",
    "[ 1ddata ] ( no signal present ) .",
    "the @xmath6 values are then consistent with the fit dof @xmath192 .",
    "we next extend bi methods to several data models with different combinations of elements and parameters compared to the previous fs - only exercise .",
    "we first compare @xmath6 alone , simulating a conventional model - fit exercise , then extend to comparisons of evidence @xmath35 .",
    "( color online ) @xmath6 values vs number of parameters @xmath14 for several data models .",
    "the general trend is monotonic decrease with increasing number of model parameters , responding only to statistical noise with @xmath193 for @xmath194 . ]",
    "figure  [ chi2 ] shows @xmath6 values for various model fits to data . the fs - only description ( blue points and line ) achieves a substantial decrease for @xmath189 but no significant improvement with additional terms . the basic model with three parameters ( red solid square ) has @xmath195 , somewhat in excess of the number of fit dof @xmath196",
    "addition of more cosines ( quadrupole , sextupole , octupole ) to the basic model keeps pace with the fs noise trend with its reduced slope . in this conventional context the extra cosines _ seem _ to be required for competitive data description because they reduce the fitted @xmath6 , but at what cost ?",
    "the basic model + quadrupole + sextupole + octupole with @xmath197 ( open diamond ) has the same @xmath6 as the @xmath189 fs - only model .",
    "as explained below in connection with table  [ paramx ] the additional cosine terms effectively displace the gaussian part of the basic model . the composite model then functions as a fs - only model with @xmath198 , but with increased cost in the occam penalty .",
    "( color online ) negative log evidence @xmath49 vs number of parameters @xmath14 for several models .",
    "the basic model ( solid square ) is strongly favored over all others ( lowest @xmath199 ) . the hatched band indicates the common uncertainty of priors assigned to cosine terms in all models .",
    "fs - only models for all @xmath14 ( solid dots and line ) are strongly rejected by the evidence . ]",
    "figure  [ modelcomp ] shows negative log evidence @xmath200 for several models . adding an occam penalty in the form of information @xmath47 gained by each model reveals a different picture .",
    "the basic model with @xmath184 has substantially smaller -2le ( larger evidence @xmath42 ) than other models where the cost of extra parameters is not justified by a compensating reduction in @xmath6 .",
    "the hatched band reflects the estimated uncertainty in @xmath47 ( for the fs - only model ) arising from the estimated priors .",
    "given that @xmath6 values for various models are similar ( @xmath201 ) the large differences in @xmath199 among models must be dominated by information @xmath47 which depends on the covariance matrix and prior pdfs . it might be suggested that such differences arise mainly from the assignment of prior probabilities , but that is not the case .",
    "we apply the same prior to a given parameter or parameter class consistently across all models , so that uncertainties in i are strongly correlated across competing models and largely cancel when odds ratios are taken ( see sec .",
    "[ oddsys ] ) .",
    "the @xmath202 trend vs @xmath14 for fs - only models arises from @xmath203 , whereas the @xmath202 trend for the basic model plus additional cosine terms corresponds to @xmath204 .",
    "the difference in @xmath205 of 2.5 corresponds to a factor @xmath206 difference in parameter errors for the two models .",
    "parameter errors for fs - only models are @xmath207 whereas errors for the basic model plus cosine terms are @xmath208 , accounting for the factor 10 - 15 difference . as discussed in sec .",
    "[ why ] the large occam penalty for fs - only models is mainly owing to smaller covariance - matrix elements ( parameter errors ) .",
    "( color online ) normalized @xmath209 from eq .",
    "( [ plaus ] ) for several models indexed by @xmath58 . as in fig .",
    "[ modelcomp ] the basic model ( solid square ) is strongly favored over all other models while fs - only models for all @xmath14 are strongly rejected . ]",
    "figure  [ xxxx ] shows the _ plausibility _ ( relative evidence ) for each competing model in the form @xmath210 that reveals the full selectivity of the bi method . for this exercise",
    "we assume that model prior probabilities @xmath62 are all equal ( and therefore irrelevant ) . however , implicit @xmath62 assumptions do play a role in rhic / lhc data modeling and physics interpretations .",
    "the most plausible models are the basic model ( 80% ) and basic model + quadrupole ( 15% ) .",
    "large occam penalties reduce competing additional multipole elements to a few percent or less . the model including an octupole ( open diamond ) leads to major fit instabilities and",
    "is rejected . with plausibilities of less than 1% fs - only models",
    "are also rejected . in terms of odds",
    "the basic model is preferred over model + quadrupole by @xmath211:1 , over model + sextupole by @xmath212:1 and over all fs - only models by @xmath213:1 .",
    "as noted in section ii - e bayesian comparisons among models are effected by taking ratios of evidences ( odds ratios ) .",
    "comparisons are visualized efficiently by corresponding differences on a log - evidence scale ( bayes factors ) as in fig .",
    "[ modelcomp ] and subsequent equivalent figures .",
    "isolated absolute numbers are not relevant to our method .      table  [ paramx ] summarizes the best - fit model - parameter values @xmath37 obtained from model fits ( minimum @xmath6 ) emphasizing the basic model ( column 2 ) and successive additions of quadrupole , sextupole and octupole components , as well as a delta function at @xmath77 to accommodate a data artifact .",
    "the parameters are as defined in sec .",
    "[ models ] . also shown are @xmath6 and the bi parameters @xmath186 and @xmath49 .    .",
    "[ paramx ] bin-10 model parameters ( minimum @xmath6 ) for several fit models : ( a ) basic model , ( b ) basic model plus quadrupole term @xmath151 , ( c ) previous plus sextupole term @xmath214 , ( d ) previous plus octupole term @xmath215 , ( e ) basic model plus delta function at @xmath77 .",
    "the fit parameters are as defined in sec .",
    "[ models ] .",
    "[ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     results for the basic model are in good agreement with the published values from 2d model fits  @xcite . for this centrality",
    "the best - fit 2d parameters from the model of eq .",
    "( [ 2dmodel ] ) are @xmath216 , @xmath217 , @xmath218 ( consistent with the gaussian integral ) , @xmath219 ( @xmath220 ) , @xmath221 with @xmath6 / dof = 2.6 .",
    "note that @xmath222 must be less than @xmath223 because of the curvature on @xmath128 of the ss 2d peak .",
    "the @xmath6/dof = 2.8 of the 2d model fit is substantially higher than that for the 1d fit with the basic model [ 12.5 / ( 11 - 3 ) = 1.6 ] because of significant structure on @xmath128 ( @xmath105-modulated dipole ) not described by the standard 2d data model of eq .",
    "( [ 2dmodel ] ) .    as cosine terms",
    "are added to the basic model a conflict develops between the explicit gaussian component and a sum of cosines approximating a competing gaussian .",
    "the large parameter differences for `` @xmath224 '' vs `` basic model '' columns are discussed further in sec .  [ compete ] .",
    "the @xmath225 column refers to the basic model plus a free amplitude in the bin at @xmath77 ( `` delta function '' ) .",
    "compared to the basic model alone there is reduction of @xmath6 by 1.5 but increase of information @xmath186 by 8 leading to overall increase of negative log evidence @xmath49 by 6.5 .",
    "the additional model dof is rejected by @xmath226 25:1 .",
    "in this second of three examples the statistical errors of the wider centrality bin are reduced by factor @xmath142 compared to the 0 - 5% centrality bin .",
    "the be / electron peak is still narrow enough to remain within the single bin at zero .",
    "the quadrupole component is significant and positive , shifting the plausibility order of competing models .",
    "figure  [ 1ddata2 ] shows a projection of the 2d data histogram from 9 - 18% central 200 gev  collisions onto 1d @xmath129 ( points ) . as for the previous centrality",
    "the bin at zero also includes a significant contribution from be / electrons not included in the data models and is therefore excluded from the fits .",
    "the typical data r.m.s .",
    "statistical error is 0.0026 , not visible outside the points on this scale .",
    "( color online ) 1d projection onto azimuth ( points ) from the 2d data histogram for 9 - 18% central 200 gev  collisions .",
    "the ( red ) dashed curve is a fit to the data with the basic model of eq .",
    "( [ simpmod2 ] ) plus independent quadrupole component @xmath227 .",
    "the bin - wise statistical errors are 0.0026 , not visible outside the points . ]    a fit of the basic model + quadrupole to data is shown by the dashed ( red ) curve .",
    "the fitted model parameters are @xmath228 , @xmath229 , @xmath230 and @xmath231 with @xmath232 for 11 - 4 = 7 fit dof .",
    "figure  [ power2 ] shows the power spectrum ( points and blue solid curve ) derived from the data in fig .",
    "[ 1ddata2 ] . as for the 0 - 5% centrality bin we include the predicted power spectrum ( red dashed curve ) for a 1d gaussian ( ss peak ) with amplitude and width parameters derived from the fit to data in fig .",
    "[ 1ddata2 ] .",
    "the data ps is again consistent with statistical noise for @xmath176 .",
    "the ps element for @xmath166 includes a negative contribution from the as dipole .",
    "the element for @xmath233 includes a significant positive contribution from a quadrupole component not associated with the ss peak  @xcite .",
    "( color online ) power spectrum values @xmath81 ( points ) derived from the data in fig .",
    "[ 1ddata2 ] via eq .",
    "( [ coef ] ) .",
    "the ( red ) dashed curve is the gaussian ps described by eq .",
    "( [ fmm ] ) with amplitude and width from the basic model + quadrupole fitted to data in fig .",
    "[ 1ddata2 ] .",
    "the interval @xmath176 is consistent with a `` white - noise '' power spectrum ( dotted line ) representing the statistical noise in fig .",
    "[ 1ddata2 ] . ]",
    "just as for bin 10 we assess the quality of the basic - model data description by determining the ps of the residuals of ( data @xmath181 gaussian ) only , where gaussian is the fitted gaussian in fig .",
    "[ 1ddata2 ] .",
    "the ps for ( data @xmath181 gaussian ) is consistent with a white - noise spectrum with mean value @xmath234 for @xmath2 .",
    "the values for @xmath235 2 are consistent with the fitted positive quadrupole and negative dipole amplitudes .",
    "the basic model augmented by quadrupole component @xmath147 fully exhausts the data signal and is therefore a sufficient model .",
    "the log - likelihood ll trend in the form @xmath6 for @xmath236 for fs - only model fits to data from bin 8 ( not shown ) is similar to that for bin-10 data in fig .",
    "[ basicfit ] .",
    "information @xmath186 representing the parameter cost is also similar .",
    "the minimum of @xmath49 occurs at @xmath237 , consistent with fig .",
    "[ power2 ] where we again find that a @xmath237 fs - only model should completely describe the signal in the bin-8 data .",
    "the fs - only model should then be competitive with the @xmath189 basic model + quadrupole in terms of fit quality and parameter number , two elements of bi evaluation .",
    "figure  [ chi22 ] shows @xmath6 values from conventional data modeling .",
    "the fs - only model achieves a substantial reduction for @xmath198 but no significant improvement for additional terms .",
    "the basic model with @xmath184 ( solid red square ) has a @xmath6 much elevated from the number of fit dof = 8 and is rejected on that basis .",
    "addition of a quadrupole component ( solid green diamond ) brings @xmath6 down to an acceptable value .",
    "addition of more cosines ( sextupole , octupole ) to the basic model + quadrupole tracks the fs - only noise accommodation .",
    "( color online ) @xmath6 values vs number of parameters @xmath14 for several data models .",
    "the general trend is again monotonic decrease with increasing parameter number . ]",
    "the basic model + sextupole ( solid red triangle ) has the same @xmath6 value as that for basic model + quadrupole .",
    "the gaussian + dipole + sextupole combination can interact to accommodate the independent quadrupole component in the data , since the octupole component of the gaussian is only a few sigma above the statistical noise .",
    "interactions among the basic model gaussian and additional cosine terms are discussed in sec .",
    "[ compete ] .",
    "( color online ) negative log evidence @xmath49 vs number of parameters @xmath14 for several models .",
    "the basic model + quadrupole ( solid diamond ) is strongly favored over others ( lowest @xmath199 , largest evidence ) .",
    "the basic model alone ( solid square ) is strongly rejected by the evidence , as are fs - only models for all @xmath14 ( blue points and line ) . ]",
    "figure  [ modelcomp2 ] shows negative log evidence @xmath49 for various models .",
    "the basic model + quadrupole ( solid green diamond ) corresponding to @xmath189 model dof has substantially smaller -2le ( larger evidence @xmath42 ) than other model combinations .",
    "it is clearly preferred over the basic model alone by @xmath238:1 odds .",
    "for other models the cost of extra parameters is not justified by reductions in @xmath6 .",
    "the quadrupole model component is preferred over a sextupole by @xmath239:1 due to differences in the fit covariance matrix for the two models .",
    "all fs - only models are again rejected by large factors .",
    "in this third of three cases , essentially representing  ( ) collisions , we encounter a major challenge for bi analysis from several sources : ( a ) the ss peak on azimuth contains two contributions that can not be separated easily by discarding the bin at the origin as they were for bins 8 and 10 , ( b ) the signal amplitude is much smaller relative to statistical noise ( 15:1 ) than it was for more - central collisions ( 200:1 ) , and ( c ) the ss peak is substantially broader on azimuth .      figure  [ 1ddata3 ] shows a projection of the 2d data histogram from 83 - 94% central 200 gev  collisions ( points ) . unlike previous cases the ss peak includes a significant contribution from be / electrons that is not included in the models ( conversion electron pairs do fall mainly within the single bin at the origin ) .",
    "a fit of the basic model to data is shown by the dashed ( red ) curve .",
    "the fitted model parameters are @xmath240 , @xmath241 and @xmath242 with @xmath243 for 11 - 3 = 8 fit dof .",
    "( color online ) 1d projection onto azimuth ( points ) from the 2d data histogram for 83 - 94% central 200 gev  collisions in fig .",
    "[ fig1 ] ( a ) .",
    "the ( red ) dashed curve is a fit to the data with the basic model of eq .",
    "( [ simpmod2 ] ) .",
    "the statistical errors are 0.0026 . ]",
    "figure  [ power3 ] shows the power spectrum ( points and blue solid curve ) derived from the data in fig .",
    "[ 1ddata3 ] . as for previous centrality bins",
    "we include a predicted power spectrum ( red dashed curve ) for a 1d gaussian ( ss peak ) with amplitude and width parameters derived from the basic model fitted to data in fig .",
    "[ 1ddata3 ] .",
    "( color online ) power spectrum values @xmath81 ( points ) derived from the data in fig .",
    "[ 1ddata3 ] via eq .",
    "( [ coef ] ) .",
    "the ( red ) dashed curve is the gaussian ps described by eq .",
    "( [ fmm ] ) with gaussian width and amplitude corresponding to the basic model fitted to data in fig .",
    "[ 1ddata3 ] .",
    "the interval @xmath2 is consistent with a `` white - noise '' power spectrum ( dotted line ) representing the statistical noise in fig .",
    "[ 1ddata3 ] . ]",
    "because the bin-0 ss peak is broader on azimuth ( thus narrower on index @xmath87 ) and the s / n is much smaller the ps signal is not significant at @xmath244 or even @xmath245",
    ". a @xmath246 fs - only model in the form of dipole + quadrupole should be sufficient to displace the basic model . for bins 10 and 8 fs - only models",
    "are clearly excluded in favor of the basic model , but for bin 0 the @xmath247 basic model and a @xmath248 fs can both describe the two data dof .",
    "thus , we expect bi analysis to prefer the fs - only model .",
    "figure  [ basicfit3 ] shows the fs - only @xmath6 trend for bin-0 data ( upper solid blue curve and points ) .",
    "as expected , @xmath6 drops to the noise trend ( lower solid curve ) by @xmath246 .",
    "additional terms accommodate statistical noise .",
    "information @xmath186 follows the expected monotonic increase @xmath249 .",
    "negative log evidence @xmath49 has a minimum for @xmath246 .",
    "thus , an fs - only model with @xmath246 is preferred by the data , as expected from the ps in fig .",
    "[ power3 ] .",
    "( color online ) @xmath6 ( upper solid curve and points ) and information @xmath186 ( dashed curve and points ) vs number of parameters @xmath14 for fs - only models .",
    "the sum @xmath49 ( dotted curve and points ) is also included .",
    "the @xmath6 trend for basic - model fit residuals ( lower solid curve ) is approximately consistent with the expected noise trend @xmath187 . ]",
    "figure  [ chi23 ] shows @xmath6 trends for several competing models applied to the bin-0 data in fig .",
    "[ 1ddata3 ] .",
    "the @xmath247 basic model and fs - only model describe the data equally well , and we expect the simpler @xmath246 fs - only model to be preferred when an occam penalty is included . for these bin-0 data",
    "the addition of a `` delta '' component at @xmath77 ( open square ) leads to substantial improvement in the fit quality , consistent with fig .",
    "[ 1ddata3 ] .",
    "( color online ) @xmath6 values vs number of parameters @xmath14 for several data models . the basic model ( solid square )",
    "is equivalent to the fs - only model with @xmath184 ( solid dot ) . ]",
    "figure  [ modelcomp3 ] shows the log evidence @xmath49 trend . that the @xmath184 basic model ( solid red square ) is preferred over the @xmath248 fs - only model ( lowest blue point ) despite the cost of the extra model parameter is a major surprise .",
    "the evidence ratio ( odds ) is @xmath250:1 @xmath251 .",
    "that result prompted a detailed study reported in sec .",
    "[ why ] on how information @xmath47 is related to model priors and data , with supporting material provided in app .",
    "[ structure ] .",
    "( color online ) negative log evidence @xmath49 vs number of parameters @xmath14 for several models .",
    "the @xmath184 basic model ( solid square ) is favored over all others ( lowest @xmath199 , largest evidence ) , especially over the @xmath246 fs - only model expected to prevail for this centrality ( lowest solid dot ) . ]    the ability in this case to discriminate between the basic model and fs models , despite 1d data with low s / n ratio , is a significant achievement for bi analysis .",
    "the correctness of the basic - model preference is confirmed by analysis of 2d data histograms . from the 2d analysis of ref .",
    "@xcite we learn that the ss 2d peak is _ necessary _ for all centralities .",
    "in contrast , a 1d fs - only model would fail dramatically for any 2d data , but that is not apparent from 1d projections alone .",
    "bayesian inference methods provide a powerful system for discriminating among competing complex data models with a consistent set of evaluation rules .",
    "close examination of method details and evaluation of uncertainties is required to insure confidence in the results .      for 2d histograms from ref .",
    "@xcite the angular acceptance was divided into 25 bins on the @xmath252 axis and 25 bins on @xmath253 , a trade off between statistical error magnitude and angular resolution .",
    "the histograms are by construction symmetric about @xmath254 and @xmath255",
    ". the 25 bins on @xmath129 actually span @xmath256 to insure centering of major peaks on azimuth bin centers .",
    "2d binwise statistical errors are @xmath257 for 200  gev data near @xmath258 . because of the @xmath128 dependence of the pair acceptance statistical errors increase with @xmath259 as @xmath260 with @xmath105 acceptance @xmath261 .",
    "errors are uniform on @xmath253 except that errors are larger by factor @xmath142 for angle bins with @xmath262 and @xmath263 because of reflection symmetries .",
    "statistical errors are approximately independent of centrality for the per - particle statistical measure @xmath264 over nine 10% centrality bins ( 0 - 8 ) .",
    "an additional factor @xmath142 increase applies to the two most - central centrality bins ( 9 , 10 ) which split the top 10% of the total cross section .",
    "after projection onto 1d azimuth for this study the centrality bin 10 errors are about 0.0037 except for the azimuth bins at 0 and @xmath77 .",
    "errors for the other centrality bins ( 0 , 8) are a factor @xmath265 less or 0.0026 .",
    "@xmath6 values for optimized models in this study determined with those statistical errors are generally consistent with the number of fit dof = data dof @xmath181 k ( number of model parameters ) , as demonstrated in fig .",
    "[ basicfit ] .",
    "thus , the statistical and systematic uncertainties for data histograms used in this study are both small and well understood .",
    "information uncertainty is largely related to the choice of prior pdfs for various model parameters and the fitted - parameter uncertainties .",
    "we repeat the information definition in eq .",
    "( [ infoeq1 ] ) @xmath266,\\end{aligned}\\ ] ] the natural log of prior volume @xmath65 over posterior volume @xmath67 in the model parameter space .",
    "the covariance matrix @xmath267 for a @xmath14-parameter model is obtained from the hessian describing the curvatures of the likelihood function near its maximum .",
    "the likelihood function is in turn determined by model @xmath23 in combination with specific data @xmath31 . if the model and prior are defined and data specified the posterior volume is also well defined .",
    "assuming translation invariance within a parameter - space volume where the likelihood is significantly nonzero the prior pdf for parameter @xmath15 is taken to be uniform across a bounded interval @xmath268 into which the corresponding fitted parameter value should almost certainly fall .",
    "the prior volume for @xmath14 parameters is then @xmath269 in principle , a prior is defined before data @xmath31 are obtained and thus should not depend on specific data .",
    "however , it is fair to invoke general knowledge ( @xmath22 ) about the typical amplitudes of structures in such data .",
    "we know from experience that typical structure amplitudes ( e.g.  peak - to - peak excursions ) are generally @xmath72 .",
    "that applies for example to the gaussian amplitude in the basic model , and to the gaussian width based on the definition of the ss peak , implying that @xmath270 in those cases .    what matters more than absolute estimates of @xmath70 is the relations among different models and model parameters .",
    "if prior - interval estimates are excessive for a particular model it may be unduly penalized .",
    "given the above assignment for a gaussian amplitude , what is a fair assignment for cosine coefficients ? to that end we examine eq .",
    "( [ wiener1 ] ) .",
    "the autocorrelation to be modeled on the left receives contributions at the origin from several fs components @xmath81 including factors 2 .",
    "thus , it is reasonable to assume that cosine coefficients and uncertainties may be substantially smaller on average than the gaussian amplitude and uncertainty . for all cosine components we assign @xmath74 and indicate prior - related uncertainties by including @xmath271 and @xmath272 as limiting cases for cosines ( e.g.  curve @xmath47 and hatched band in fig .",
    "[ basicfit ] ) .",
    "if we assume equal prior intervals @xmath268 and equal variances @xmath273 for @xmath14 model parameters and negligible covariances among parameters information @xmath47 simplifies to @xmath274 \\right\\rangle + \\text{constant}.\\end{aligned}\\ ] ] in fits with fs - only models we observe @xmath275 .",
    "given @xmath270 we have @xmath276 , while if we reduce to @xmath277 ( assumed for all cosine terms ) @xmath278 .",
    "if we further reduce @xmath279 with @xmath280 the fitted parameter values in some cases contradict the prior , implying that the chosen prior interval is too small .",
    "we can then state that for all fs - only models @xmath281 .",
    "for the basic model with added cosines the parameter uncertainties are more typically @xmath282 . in that case",
    "we obtain @xmath283 .",
    "those results imply that addition of a model parameter is justified ( @xmath284 is significantly reduced ) if the resulting decrease in @xmath6 is significantly greater than @xmath285 for fs - only models and @xmath286 for the basic model plus optional cosines .      as noted in sec .",
    "[ modcompare ] odds ratios can be used to state quantitatively the bi relation between two models in the form of a probability ratio @xmath287 , where equality to the second ratio assumes equal _ model _ priors @xmath41 for the two cases . in terms of log evidence @xmath202",
    "the bayes factor is @xmath288 $ ] , and the odds is then @xmath289 .",
    "the uncertainty ( error ) in an odds ratio is determined by the uncertainties in the compared evidences in turn dominated by uncertainties in the covariance matrix / hessian and the prior pdfs .",
    "uncertainties for the hessian matrix are discussed in app .",
    "[ hesserror ] and serve as the sole basis for the odds errors stated in the text .",
    "uncertainties for the prior pdfs are discussed in the previous subsection .",
    "the priors for ss gaussian amplitude and width are set to the minimum values consistent with experience , _ disfavoring the basic model a priori _ and implying that any odds favoring the basic model is a lower limit .",
    "a common uncertainty of a factor 2 either way is assumed for a cosine coefficient in any model . because an odds estimate is a probability ratio systematic errors correlated between numerator and denominator cancel in first order , whereas uncorrelated random errors should combine quadratically . that property can be seen as an advantage for odds as a basis for model comparisons and minimizes the uncertainty contribution from cosine elements common to two compared models .    if models with different @xmath14 values ( parameter number ) are compared the unpaired systematic error is not canceled .",
    "for instance , the odds between the basic model ( @xmath184 ) vs fs - only model ( @xmath290 ) for bin 10 includes a linear dependence on the fs - only prior uncertainty for one additional cosine term .",
    "however , the comparison of basic model plus quadrupole vs fs - only model for bin 8 ( both @xmath189 ) eliminates that uncertainty contribution .",
    "we consider several issues that have arisen in application of bi methods to azimuth - correlation data models , including surprising performance of the 1d basic model in peripheral collisions , consistent strong preference for the basic model by bi analysis , competition between gaussian and cosine terms in data models , and implications from this study for two theoretical narratives .      the data structure for centrality bin 10 in fig .  [ 1ddata ]",
    "could be modeled as ( a ) two peaks at 0 and @xmath77 , ( b ) as a fourier series only , or ( c ) as a combination of such elements .",
    "the two peaks described by the basic model are expected in a hep / jets narrative describing high - energy nuclear collisions .",
    "fs models are expected in a qgp / flow narrative and are capable of describing any structure on periodic azimuth .",
    "competition among data models thus reflects competition between theoretical narratives .    in fig .",
    "[ power1 ] we learn that all information in the data ps is confined to @xmath291 $ ] . higher terms in an fs model describe only statistical noise . comparing a ps gaussian model with the data ps",
    "we find that four points are predicted by a gaussian fitted to data , and one point corresponds to the fitted dipole within the basic model .",
    "the @xmath184 basic model fully represents the data signal as demonstrated in fig .",
    "[ noise ] , but so does a @xmath189 fs - only model .",
    "intermediate combinations of gaussian + cosines also describe the data well .",
    "models with more parameters continue to reduce @xmath6 as in fig .",
    "[ chi2 ] , and might be preferred on that basis .    however , when an occam penalty is introduced in the form of information @xmath47 dramatic differences among models appear , as in figs .",
    "[ modelcomp ] and [ xxxx ] . in the latter figure",
    "the basic - model probability is @xmath292% , the next highest being basic model + quadrupole with @xmath293% . adding more cosine components may reduce @xmath6 , but not to an extent that compensates large occam penalties ( increase in @xmath47 ) .",
    "the additions are essentially `` fitting the noise '' and are strongly rejected by bi analysis .",
    "a different situation emerges for bin 0 . in fig .",
    "[ power3 ] the data signal is confined to @xmath294 $ ] for two reasons : ( a ) the s / n ratio is reduced by a factor 13 and ( b ) the ss peak azimuth width is increased by 30% so the conjugate ps signal peak width is reduced by that factor .",
    "consequently the `` bandwidth '' of the data ps signal is reduced from @xmath291 $ ] to @xmath295 $ ] . a @xmath248 fs - only model with two parameters",
    "should then be strongly preferred by bi analysis over the @xmath247 basic model , given equivalent priors for the two models .    however , that is not what we find in fig .",
    "[ modelcomp3 ] .",
    "the basic model maintains a significant advantage over a @xmath248 fs - only model , the odds ratio being @xmath296 in favor of the basic model , even with one more parameter .",
    "that surprising result led to the detailed comparisons in the next subsection and the study in app .",
    "[ structure ] .",
    "the 1d projection is not the only information we have about the source of these data .",
    "the unprojected 2d histogram in fig .",
    "[ fig1 ] ( a ) clearly indicates that a ss 2d peak model is required by bin-0 data , and a 2d fs - only model would be rejected by a large factor  @xcite .",
    "the 2d observations contribute a larger bayesian context ( @xmath22 ) applicable to this 1d bi study .",
    "the fs - only model is ruled out for all 2d histograms as shown in previous studies  @xcite .      the basic model alone ( for near - central collisions ) or the basic model plus quadrupole ( for noncentral collisions ) is strongly preferred by bi analysis over fs - only models , even for the most - peripheral collisions where the 1d data include only two significant dof .",
    "the choice of priors is not the reason ; priors are applied consistently for each parameter type within any model .",
    "the large difference in evidence values is dominated by differences in the fit covariance matrix .",
    "the r.m.s .",
    "parameter errors for fs models are consistently 10 - 15 times smaller than for the basic model .",
    "evidence differences correspond to differences in model _",
    "predictivity _ , as illustrated in the following comparison and app .",
    "[ structure ] .",
    "figure  [ pairpanel ] shows sketches of joint data - parameter spaces for an fs - only model ( left ) and the basic model ( right ) corresponding to bin-10 data .",
    "the parameter errors for the fs - only model are typically @xmath297 .",
    "the parameter errors for the basic model in table  [ paramx ] are 0.007 for ss peak amplitude and width and 0.002 for dipole amplitude , but with added cosine terms the errors increase to @xmath298 .",
    "the data errors for bin 10 are @xmath299 . in terms of angles",
    "@xmath300 defined in eq .",
    "( [ angles ] ) @xmath301 1/3 for the basic model ( 20 ) and 5 for the fs - only model ( 80 ) .",
    "the errors and @xmath302 are represented by the dashed rectangles and the angles of the diagonals ( solid lines ) in the two panels , as in fig .",
    "[ bayessp ] .",
    "joint parameter - data space for two data models .",
    "these panels are zoomed out from the scale of fig .",
    "[ bayessp ] to reveal the pdfs distributed over the entire parameter and data spaces . given prior intervals @xmath268 the model angles @xmath300",
    "determine the magnitudes of the predicted data intervals @xmath303 , the predicted data volume @xmath304 , and therefore the evidence @xmath305 .",
    "the @xmath300 , and hence the jacobian of a model function , largely determine the predictivity of a model .",
    "for these two models the typical @xmath302 differ by factor 12 . ]    in fig .",
    "[ pairpanel ] the prior pdfs are represented by the vertical dash - dotted lines in each panel and the arrows labeled @xmath268 . for all cosine",
    "amplitudes the prior is @xmath306 . for the ss peak amplitude and width",
    "the priors are @xmath270 .",
    "we can estimate the evidences or predicted data volumes based on the argument in app .",
    "[ structure ] where the relation between data - space volume and parameter - space volume is determined by angle factors @xmath302 . for the basic model ( right panel ) even the larger priors ( @xmath270 ) are mapped to smaller data intervals ( @xmath307 ) , whereas for fs - only models ( left panel ) smaller priors ( @xmath306 ) are mapped to larger data intervals ( @xmath308 ) .",
    "the result is _ much smaller predicted data volumes _",
    "@xmath304 for the basic model , and consequently much higher evidence and plausibility compared to fs - only models .",
    "the same argument applies to changes in evidence or information with increasing parameter number ( e.g.  added cosine terms ) . from eq .",
    "( [ edh ] ) ( assuming comparable @xmath6 values for competing models ) @xmath309 +    \\text{constant}.\\end{aligned}\\ ] ] with @xmath306 for all cosine terms , @xmath310 for fs - only models and @xmath298 for basic model + cosines the typical increment per cosine term is @xmath311 for fs - only models and 2.5 for basic model + cosines , e.g.  consistent with fig .",
    "[ modelcomp ] .",
    "thus , evidence and information trends are determined mainly by the relative parameter errors reflecting the jacobians and model algebra .",
    "the fitted - parameter errors reflect the algebraic structure of the model , as discussed in app .",
    "a. because a fourier series is orthogonal each coefficient is determined independently . since the fourier model elements individually do not resemble the data there is required a very `` fragile '' assembly of terms that easily overfits the data ( treats noise as signal ) .",
    "only a small range of fs - only parameter values can reproduce a given data set , and the parameter variances are consequently very small .",
    "in contrast , the basis model includes a gaussian ( motivated by the data structure ) with nonlinear parameter @xmath312 that covaries with other parameters .",
    "thus , larger ranges of basic - model parameters can reproduce the data adequately , and the parameter variances are correspondingly larger .",
    "the basic model is more `` robust '' because on average the model elements _ individually _ look more like isolated data components .",
    "if both models give the same chi - squared fit the basic model is preferred by bi analysis because on average it is far more likely to describe the data accurately ( a larger fraction of the prior - delimited parameter space provides an acceptable description for the given data ) .",
    "we conclude that the key issue for bayesian model comparisons is model predictivity .",
    "the basic model is highly predictive ( therefore falsifiable ) , describing two peaks ( fixed at 0 and @xmath77 ) , with one peak as wide as possible and the other somewhat narrower .",
    "two peak amplitudes and a width are the only parameters .",
    "the basic model is consistent with the hep / jets narrative but was inferred from data without any theory assumptions . in contrast , fs - only models can describe any structure on azimuth , have no predictivity ( are not falsifiable ) and are therefore strongly rejected by bi analysis .",
    "model predictivity [ smallness of predicted data volume @xmath304 ] is determined largely by the algebraic structure of the data model ( jacobian ) as revealed by fitted - parameter errors compared to data errors via the @xmath302 elements .",
    "the bin-10 results in table  [ paramx ] can be used to examine the consequences of adding one or more cosine terms to the basic model when there is no corresponding data signal .",
    "the @xmath6 is reduced in general , suggesting an improved data description . however , in some cases the model parameters undergo large changes seeming to indicate that model parameters are very uncertain . to understand the apparent contradiction we consider the bin-10 `` worst case '' model ( basic model + quadrupole + sextupole + octupole ) appearing in the next - to - last column of table  [ paramx ] .    the model difference ( `` @xmath314 '' @xmath181 basic model ) for each cosine coefficient is @xmath315 , @xmath316 , @xmath317 and @xmath318 for @xmath291 $ ] .",
    "the differences correspond to the predicted gaussian ps values in fig .",
    "[ power1 ] ( red dashed curve ) . in effect , changes in the cosine coefficients of the fs - only model are equivalent to the fitted gaussian already describing the data signal correctly in the basic model . the ss gaussian required by the data is effectively excluded from the data model by the added cosine terms , reduced to a minor role  @xcite .",
    "the bin-10 result reveals a competition between the basic model and a truncated fs to describe signal + noise .",
    "the competing truncated fs offers more flexibility in accommodating noise compared to the monolithic gaussian .",
    "the fs may `` win '' in terms of @xmath6 , but a well - chosen model element ( gaussian ) describes only the signal and excludes the noise . referring to fig .",
    "[ chi2 ] the @xmath197 ( `` + @xmath215 '' ) model ( open diamond ) has the same @xmath6 value as the @xmath189 fs - only model ( solid point ) because the former is effectively a @xmath189 fs .",
    "the gaussian , with two parameters , has been excluded from the fit model owing to noise competition , but its two parameters still contribute to the occam penalty .",
    "bi analysis then rejects the unnecessary cosine terms in favor of the basic model .",
    "a model may describe data from some   centralities well but others poorly .",
    "nevertheless , the model may be retained by convention because of desirable features ( such as flow interpretations ) .",
    "other forms of data selection (  cuts , 1d projections , ratio measures ) present similar issues . in response",
    "we propose to extend bi methods beyond single data histograms , combining results into one comprehensive evaluation for competing data models .",
    "the mechanism is suggested by the nature of bayesian evidence @xmath42 .",
    "the evidence is a _ probability _ , and by the rules governing probabilities the _ joint _ evidence for several cases should be the _ product of elementary evidences _",
    "( assuming approximate independence ) .",
    "for instance , the evidence for a model of 200 gev  collisions should be the product of evidences for individual centralities .",
    "if a model claiming to describe all data components is falsified for one component then it is falsified for all .",
    "more generally , a model that provides an adequate description for all cases may be preferred over a model that is favored for some cases but strongly disfavored for others .    that principle extends not only to   centralities but to different collision energies ,  collision systems , spectrum and correlation measures and data cuts .",
    "evidence @xmath42 as a _ product measure _ introduces an `` and '' condition for data description . a candidate model",
    "_ must _ address all available data within its parameter space or be rejected .      as noted in the introduction hep / jets and qgp / flow narratives",
    "currently compete to describe and interpret high - energy nuclear - collision data through choices of data model and emphasis on specific data and measured quantities .",
    "the hep / jets narrative predicts two dijet - related peaks on 1d azimuth , just what the basic model describes .",
    "almost all 1d azimuth correlation data from the rhic are described by the basic model + quadrupole with modest parameter variations .",
    "the qgp / flow narrative prefers various forms of the fs - only data model interpreted physically in a flow context , from a single cosine ( @xmath4 , index @xmath319 ) to several cosines interpreted to include `` higher harmonic '' flows ( index @xmath320 $ ] ) .    in the present study",
    "we apply bi methods to 1d azimuth data models associated with the two narratives .",
    "bi analysis strongly favors the basic model in all cases , combined with an additional quadrupole @xmath0 term except for the most - central data .",
    "the fs - only model is strongly rejected in all cases . as discussed in sec .",
    "[ why ] and app .",
    "[ structure ] the main reason for bi rejection is lack of predictivity for fs - only models , whereas the basic model is strongly predictive and therefore falsifiable .",
    "the present bi analysis thus seems to support the hep / jets narrative and reject the qgp / flow narrative per their data models .",
    "it could be argued that application of bi methods to data models represents an arbitrary choice motivated by interest in a specific outcome .",
    "however , we are faced with the requirement to evaluate conflicting data models according to some neutral criteria .",
    "@xmath6 minimization always prefers more - complex data models that may reveal little about data structure and possible physical mechanisms .",
    "flow interpretations are always possible for fs - only models , but such models _ can not exclude a dijet interpretation _ since they are able to describe any data configuration .",
    "additional criteria are therefore required to test data models .",
    "guidance as to choice is provided by the role of rational inference within the scientific method .",
    "it is recognized that physical theories can not be _ proven _ , can only be _ falsified _ by data , requiring that candidate theories be _",
    "predictive_. unpredictive theories are not falsifiable and are therefore rejected as candidates . in a bayesian context predictivity is measured by information @xmath47 and evidence @xmath42 as demonstrated in this study . for a well - tested physical theory @xmath23 encountering new data @xmath31 the information @xmath321 , and",
    "the predicted data - space volume @xmath304 is small . if @xmath322 the theory is falsified but @xmath323 results in plausibility @xmath324 : dramatically different results    in the present analysis we encounter not competing physical theories but competing data models serving as proxies .",
    "bi analysis evaluates data models according to predictivity , i.e.  the degree of restriction on allowed data configurations .",
    "we conclude that the basic model with optional quadrupole component is very predictive , corresponding to small information gain from newly - received data and consequent small predicted data - space volume .",
    "fs - only models are not predictive , can accommodate any data configuration , and are therefore rejected .",
    "based on data from the relativistic heavy ion collider ( rhic ) and large hadron collider ( lhc ) claims have been made for formation in high - energy nucleus - nucleus (  ) collisions of a strongly - coupled quark - gluon plasma ( sqgp ) with small viscosity  a `` perfect liquid . ''",
    "such claims are based mainly on measurements of fourier coefficients @xmath325 of cosine terms @xmath1 used to describe two - particle correlations on azimuth @xmath7 and interpreted to represent flows , especially @xmath4 representing elliptic flow . in",
    "the flow context dijets play a comparatively negligible role in final - state correlation structure .",
    "modeling azimuth correlations by truncated fourier series or individual cosine terms is not unique .",
    "other model functions can describe the same data equally well and do suggest alternative physical interpretations , especially substantial contributions from dijet production . in effect , two physics narratives compete to describe and interpret the same data . in one narrative collision dynamics",
    "is dominated by dijet production . in the other narrative collision dynamics",
    "is dominated by a dense , flowing qcd medium .",
    "opposing narratives appear to be supported by their respective data models . to break the deadlock a method",
    "is required to evaluate model functions according to neutral criteria and identify a preferred model .    in this study",
    "we introduce _ bayesian inference _ ( bi ) to evaluate competing model functions .",
    "bi analysis relies on a combination of the usual @xmath6 goodness - of - fit parameter and _ information _ @xmath47 derived from the fit covariance matrix .",
    "@xmath47 quantifies changes in the data model arising from acquisition of new data and represents an _ occam penalty _ for excessive model complexity .",
    "combination @xmath326 leads to _ evidence _",
    "parameter @xmath42 that determines the _ plausibility _ of each model when confronted with new data values .",
    "the goal is to rank data models according to bi criteria without resorting to _ a priori _ physics assumptions .",
    "we apply several representative model functions to angular correlation data and evaluate the model performance with bi methods .",
    "the data are published 2d angular correlations from three centrality classes of 200 gev  collisions on @xmath102 .",
    "2d histograms are projected onto periodic azimuth @xmath7 by integration over pseudorapidity @xmath105 .",
    "the three collision centralities include the centrality extremes ( most central and most peripheral ) and an intermediate centrality that requires a separate azimuth - quadrupole model element in the data model .",
    "model functions include ( a ) a `` basic model '' consisting of a same - side ( ss ) peak modeled by a gaussian at @xmath327 and an away - side ( as ) peak at @xmath77 modeled by a cylindrical dipole @xmath328 , ( b ) the basic model plus one or more additional cosine terms and ( c ) several fourier - series ( fs - only ) models consisting only of one or more cosine terms .    for each model - data combination",
    "we obtain the best - fit @xmath6 and information @xmath47 and combine them to form _ evidence _ @xmath329 $ ] interpreted in a bi context as the probability of data @xmath31 given model @xmath23 .",
    "information @xmath47 is the logarithm of a volume ratio .",
    "the numerator is a `` prior '' volume on the space of model parameters determined consistently from model to model based on the nature of the parameters .",
    "the denominator is the volume on model parameters determined by the fit covariance matrix .",
    "thus , @xmath47 measures information received by the model from new data and is interpreted in the bi context as an _ occam penalty _ , with reference to occam s razor .",
    "with increasing model complexity ( degrees of freedom ) @xmath6 typically decreases but @xmath47 increases , leading to a maximum in evidence @xmath42 for some model configuration .    for each centrality we rank models according to evidence @xmath42 which can vary over several orders of magnitude .",
    "the following systematics emerge : fs - only models ( c ) are rejected in all cases by at least a factor 100 . the basic model ( a ) representing peaks at 0 and @xmath77 is preferred in all cases .",
    "a cylindrical quadrupole @xmath0 is required to accompany the basic model in some cases but is rejected for most - central  collisions .",
    "`` higher harmonics '' @xmath1 for @xmath2 appended to the basic model are rejected in all cases .",
    "a model consisting of gaussian + dipole @xmath3 + quadrupole @xmath0 provides good data descriptions in all cases .",
    "those results are generally consistent with a _ power spectrum _ analysis of data histograms in which signal and noise components are identified .    a detailed study of the geometric structure of bayesian analysis reveals that given comparable fit quality ( @xmath6 ) for various data models the dominant factor in determining @xmath42 is the ratios of data errors to parameter errors .",
    "those ratios estimate elements of the jacobian matrix characterizing the model function as a map from parameters to data .",
    "smaller error ratios indicate smaller predicted volumes in the data space : the data model is more predictive .",
    "_ predictivity _ is then the determining factor in bayesian model evaluation .",
    "fs - only models have no predictivity , can describe any data configuration and are strongly rejected by bayesian analysis .",
    "the basic model is very predictive and is therefore strongly favored .",
    "we conclude from this study that qgp / flow narratives based on fs - only models or models with multiple cosine terms are disfavored because the requisite data models are rejected by bayesian analysis .",
    "fs - only models are not predictive , in particular can not exclude dijets as a dominant collision mechanism .",
    "dijet - based narratives are favored in that the basic model , with peaks at 0 and @xmath77 that may represent dijet structure expected in such narratives , is strongly preferred by bayesian analysis .",
    "this conclusion should of course be tested more generally with other data and contexts such as unprojected 2d angular - correlation histograms and their corresponding more - complex model parametrizations .",
    ".1 in    * acknowledgments * : this work is supported in part by a consolidoc fellowship , the national institute for theoretical physics and the national research foundation of south africa .",
    "section ii indicates that bi analysis provides two important results : ( a ) an improved posterior pdf on model parameters given newly - acquired data and ( b ) a quantitative method for comparing data models to identify the model function that achieves the best compromise between accurate data description and minimum occam penalty . in this appendix",
    "we examine the geometric structure of bi analysis on the joint parameter - data space to better understand how the bi method works .",
    "we find that evidence @xmath35 is a measure of the _ predictivity _ of a model : bi analysis prefers the most predictive model that also describes the data with a satisfactory @xmath6 .",
    "bi analysis is based on the relation between parameter space @xmath18 and data space @xmath19 .",
    "the data space is an n - dimensional space with axes @xmath330 .",
    "the model - parameter space is a k - dimensional space with axes @xmath15 .",
    "data model @xmath23 is defined in part by model function @xmath331 that relates a specific set of parameter values ( point @xmath332 in @xmath18 ) to a specific set of data values ( point @xmath31 in @xmath19 ) .",
    "note that data @xmath19 and data errors @xmath32 are vectors with elements @xmath330 and @xmath11 .",
    "similarly , parameters @xmath18 and parameter errors @xmath38 are vectors with elements @xmath15 and @xmath333 .    as set out in sec .",
    "[ chain ] , a joint parameter - data pdf @xmath334 representing model @xmath23 can be defined on the joint space @xmath335 . if data values originate as random samples from some parent distribution related to model @xmath23 with specific parameter values @xmath332 the resulting data distribution may be described by a localized conditional pdf @xmath336 on @xmath19 with estimated means @xmath337 and standard deviations @xmath11 .",
    "conversely , for a specific set of data values @xmath31 the resulting parameter distribution may be described by a localized conditional pdf @xmath34 on @xmath18 with estimated means @xmath338 and standard deviations @xmath333 .",
    "whereas conditional pdfs @xmath339 and @xmath34 may be localized near their respective modes @xmath340 and @xmath37 , marginal pdfs @xmath27 and @xmath28 ( dash - dotted lines in fig .  [ bayessp ] ) may be nearly uniform over the local intervals relevant to the peaked functions . in what follows we",
    "extend the bi methodology to obtain a _",
    "global _ geometric relation between parameter space and data space pursuant to model comparisons .",
    "we refer to conditional pdfs @xmath26 and @xmath25 as local and marginal pdfs @xmath27 and @xmath28 as global .      for each data model",
    "@xmath23 the primary bi elements are model function @xmath17 , prior pdf @xmath27 ( assuming a uniform prior on parameters @xmath15 ) , some specific data @xmath31 and their uncertainties @xmath32 .",
    "a joint pdf @xmath341 determined by function @xmath17 _ and errors _ @xmath32 is then implicit . in a model fit to some specific data",
    "@xmath31 the data errors @xmath32 and model function @xmath17 are combined to determine the most - probable model parameters @xmath37 and their uncertainties @xmath38 , or preferably a posterior pdf @xmath34 on space @xmath18 ( as in sec .",
    "[ bayes1 ] ) .     schematic representation of the local relation in space @xmath342 between data @xmath19 and model parameters @xmath18 with specific elements @xmath330 and @xmath15 , especially the errors .",
    "the solid diagonal represents model function @xmath17 .",
    "the hatched band arises from data errors , specifically @xmath11 , corresponding then to parameter errors , specifically @xmath333 .",
    "angle @xmath300 relating data and model errors is approximately a jacobian element characterizing the algebraic structure of the data model .",
    "the dash - dotted lines represent parameter - prior and data pdfs . ]",
    "figure  [ bayessp ] provides a schematic of data - model correspondence , with model parameter @xmath15 and data element @xmath330 in the local neighborhood of specific data values @xmath31 .",
    "the diagonal line represents the model function @xmath17 .",
    "the data values @xmath343 have estimated standard deviations @xmath11 ( data errors ) .",
    "the model function with data errors determines the gray band representing joint pdf @xmath341 .",
    "the likelihood function @xmath344 on @xmath15 determines the most - probable parameter values @xmath338 and their standard deviations @xmath333 corresponding to data values @xmath31 and data errors @xmath32 . as indicated by the bold vertical arrow in fig .",
    "[ bayessp ] the likelihood function , with specific data errors , in effect probes the local algebraic structure of model function @xmath17 near data @xmath31 by relating data errors @xmath11 to parameter errors @xmath333 .",
    "the geometric relation between data and parameters is characterized by angles @xmath300 defined by @xmath345 that relate data and parameter spaces .",
    "if the hessian matrix for this application is diagonal ( i.e.  correlations among model parameters are small ) those angles correspond to elements of the model - function jacobian @xmath346 @xmath347 in the following sense : if the diagonal elements of the hessian are approximated by @xmath348 the partial derivative in eq .",
    "( [ angles ] ) represents an r.m.s.quantity derived by averaging squared jacobian elements over all data elements ( weighted by the data errors ) . the same jacobian structure may determine the relation between global structures ( pdfs ) on @xmath18 and on @xmath19 by extrapolation , as discussed in the next subsection .",
    "we can define effective volumes ( generalized concept including lengths , areas , etc . ) in spaces @xmath18 and @xmath19 in relation to the key pdfs associated with bi . by volume",
    "we mean the result of integrating a unit - amplitude ( at the mode ) function over some bounded subspace including all points where the function is significantly nonzero .",
    "for example the `` volume '' of unit - amplitude 1d gaussian @xmath349 is @xmath350 . dividing a unit - amplitude function by its volume results in a normalized pdf .",
    "the marginal pdf on data @xmath19 is obtained by integrating @xmath341 over space @xmath18 using the chain rule @xmath351 the ( assumed uniform ) prior pdf @xmath27 defines an effective boundary surface for the integral over @xmath18 , represented schematically by the second line where each parameter @xmath15 is integrated over a prior interval @xmath268 and @xmath352 as in eq .",
    "( [ priordelt ] ) .",
    "for some values of @xmath19 the integrand may be nonzero only outside the volume @xmath65 , in which case @xmath353 .",
    "if @xmath28 is nonzero and approximately uniform within limiting intervals @xmath303 then @xmath354 with @xmath355 , and eq .",
    "( [ pdh ] ) represents a relation between the two global volumes @xmath65 and @xmath304 .",
    "the dual role of @xmath26 as conditional pdf on @xmath19 and as likelihood function on @xmath18 is a central issue . with @xmath332 as",
    "a specific condition @xmath336 is a _ unit - normal _ peaked distribution on @xmath19 approximated by a gaussian @xmath356 where @xmath357 $ ] . as the likelihood function @xmath344 it is an unnormalized peaked distribution on parameter space @xmath18 which in the laplace approximation is proportional to gaussian @xmath358 with its integral @xmath359,\\end{aligned}\\ ] ] where @xmath67 approximates @xmath360 appearing in eq .",
    "( [ evid ] ) .",
    "we have thus defined four volumes , two each on w and d : two local and two global .      using the laplace approximation the bi evidence as defined in eq . ( 5 ) can be written in terms of volumes as @xmath361 from eq .",
    "( [ pdw ] ) the maximum likelihood @xmath44 is @xmath362 with @xmath363 .",
    "if @xmath31 falls outside @xmath304 evidence @xmath364 ( the data model is falsified ) . if not @xmath365 and we then have @xmath366,\\end{aligned}\\ ] ] ( with information @xmath47 as defined in sec .",
    "[ modcompare ] ) relating the four volumes , where factor @xmath367 is a property of the data only , common to all models .",
    "we can relate that result to the model angles ( jacobian ) from sec .",
    "[ anglex ] . assuming data errors @xmath11 are approximately equal",
    "the local - volume ratio is factorized as @xmath368}{\\prod_{n=1}^n [ \\sqrt{2\\pi}\\sigma_n ] }     \\\\",
    "\\nonumber    & \\approx & \\frac{1}{v_d(\\tilde w|h)^{(n - k)/n } } \\prod_{k=1}^k\\frac{1}{\\tan(\\theta_{kn})},\\end{aligned}\\ ] ] where the first factor in the second line depends only on data  common to all models with parameter number @xmath14 , and the second factor is unique to a specific model .",
    "rearranging eq .",
    "( [ edh ] ) ( without gaussian factor ) as @xmath369 we note that the local - volume ratio on the right , obtained from the likelihood function and equivalent to the model - function jacobian , estimates the global - volume ratio on the left by extrapolation .",
    "@xmath304 is then the data volume _ predicted _ by a combination of prior pdf on model parameters and the model function .",
    "if the specific data values @xmath31 fall outside @xmath304 then @xmath370 and the model is falsified . the smaller the predicted data volume the larger the evidence and the more favored the model . _ predictivity _ is then any essential feature of data models .",
    "the occam penalty central to bi analysis represents not only excess parameter number and prior volume as a cost but also model predictivity as a benefit . two models with the same parameter number and priors may have very different plausibilities because of differences in their algebraic structure and therefore predictivity . a model with substantially greater predictivity",
    "may even be favored over one with fewer parameters ( sec .",
    "[ bin0 ] ) .",
    "since comparisons among data models in this bi study rely critically on fitted - parameter errors it is important to establish the degree of uncertainty in the estimated errors .",
    "parameter variances are determined by the curvatures ( second derivatives ) of the log - likehood function at the likelihood maximum .",
    "the hessian is defined by @xmath371 for linear parameters such as the coefficients of a fourier series the second derivatives are independent of the parameter values @xmath18 .",
    "specifically , for @xmath372 if the model functions are orthogonal we have @xmath373 and the hessian matrix is diagonal . in other words , for linear parameters such as the coefficients of a fourier series the parameter variances depend only on the sample points ( positions ) and the algebraic structure of the model function . for a fourier series",
    "there is little flexibility  since there is no uncertainty in the model function the only uncertainty in the hessian arises from the uncertainty in the sample positions . labeling the uncertainties in the @xmath374",
    "coordinate due to bin width @xmath375 as @xmath376 , the uncertainty in the diagonal hessian elements is @xmath377 ^ 2\\frac{(\\delta x)^2}{12}.\\end{aligned}\\ ] ] there is only one nonlinear parameter , namely the width @xmath378 of the ss gaussian in the basic model , but a similar formula should apply to that case as well .    for bin 8",
    "the diagonals of hessian and errors for the fs - only model are @xmath379 the relative errors thus vary from 0.5 percent up to five percent . for the basic - model fit in bin 8",
    "we obtain @xmath380 implying relative errors from 5 percent to 22 percent .",
    "thus the hessian matrix elements ( likelihood curvatures ) , and therefore the error estimates for fitted model parameters , are determined to a few percent in this study .",
    "use of the laplace approximation for the likelihood function in this study may be questioned due to possible inaccuracies .",
    "the laplace approximation for the likelihood function @xmath381 $ ] is @xmath382 & \\approx & \\sum_{n=1}^n \\frac{1}{2}\\left(\\frac{y_n - \\sum_k f_k(\\bm{w},x_n)}{\\sigma_n}\\right)^2 \\\\    & & \\hspace{-.5 in } = \\hspace{.05 in }   g[\\tilde{w } ] + ( w-\\tilde{w})\\frac{\\partial g[\\tilde{w}]}{\\partial w }     + \\frac{(w-\\tilde{w})^2}{2}\\frac{\\partial^2g[\\tilde{w}]}{\\partial w^2 } \\\\",
    "\\nonumber    & &   \\hspace{-.5 in } + \\hspace{.05 in } \\frac{(w-\\tilde{w})^3}{6}\\frac{\\partial^3g[\\tilde{w}]}{\\partial w^3 }   + \\cdots,\\end{aligned}\\ ] ] where the first - derivative term in the taylor series is zero by definition .",
    "the approximation then implies @xmath383 }     & \\approx & \\int_{-\\infty}^\\infty dw\\ , e^{-g[\\tilde{w}]-\\frac{(w-\\tilde{w})^2}{2}\\frac{\\partial^2g[\\tilde{w}]}{\\partial w^2 } } \\\\",
    "\\nonumber    & \\times &   \\left(1-\\frac{(w-\\tilde{w})^4}{24}\\frac{\\partial^4 g[\\tilde{w}]}{\\partial w^4 } + \\cdots \\right ) \\\\ \\nonumber    & & \\hspace{-.2 in } \\approx \\hspace{.05 in } e^{-g[\\tilde{w}]}\\sqrt{\\frac{2\\pi}{\\frac{\\partial^2g[\\tilde{w}]}{\\partial w^2 } } }    \\left(1 - \\frac{\\frac{\\partial^4 g[\\tilde{w}]}{\\partial w^4}}{8\\left(\\frac{\\partial^2g[\\tilde{w}]}{\\partial w^2}\\right)^2}\\right),\\end{aligned}\\ ] ] where we have carried the first correction term . for linear parameters , including all of the parameters except @xmath378 , there is no fourth derivative as we have pointed out .",
    "the laplace approximation is then exact ( except for sub - exponential corrections caused by replacing the truncated gaussian by a non - truncated version ) . for the single non - linear parameter in the basic model the fourth derivative @xmath384",
    "must be divided by @xmath385 squared , implying that corrections are of the order @xmath386  of the same order as the fit - model hessian .",
    "the effective number of data points is @xmath387 and any corrections are of inverse order .",
    "due to a large primary - data volume [ more than a million  collisions with ( on average ) hundreds of particles per collision ] the laplace method as applied in the present study is very accurate .",
    "because azimuth @xmath7 is a periodic variable any 1d structure on @xmath129  can be described by a discrete fourier cosine series fs . but representing an arbitrary 1d projection by a few terms of a 1d fourier series can be misleading .",
    "we should acknowledge the possibility that specific peak structures may be part of the azimuth distribution . in this appendix",
    "we consider the fs representation of a periodic gaussian peak array on 1d azimuth .",
    "the peaks observed at @xmath164 ( ss , same - side ) and @xmath388 ( as , away - side ) in all 1d azimuth histograms from high - energy nuclear collisions are actually elements of separate periodic peak arrays described by cosine series .",
    "the ss array is centered on even multiples of @xmath77 , the as array on odd multiples .",
    "nearest array elements outside a @xmath106 interval ( image peaks ) produce significant structure within the observed interval and must be included in fit models to insure valid data descriptions .",
    "each peak array ( ss or as ) may be represented by a fs of the form @xmath389),\\end{aligned}\\ ] ] where the @xmath390 are functions of r.m.s .",
    "peak width @xmath178 defined below . since @xmath391 is even for ss peak arrays ( @xmath392 ) and odd for as arrays ( @xmath181 ) odd multipoles must be explicitly labeled as ss or as .",
    "the terms represent @xmath393 poles , e.g. dipole ( @xmath394 ) , quadrupole ( @xmath395 ) , sextupole ( @xmath396 ) and octupole ( @xmath244 ) , referring to cylindrical multipoles",
    ".     left : periodic arrays of ss ( dash - dotted ) and as ( dashed ) peaks .",
    "the ss peaks are gaussians .",
    "the as peaks are described by a dipole .",
    "the dotted sinusoid corresponds to the @xmath395 fourier component of the ss peaks .",
    "right : evaluation of eq .",
    "( [ fm ] ) for four values of @xmath87 , with @xmath397 .",
    ", title=\"fig:\",width=158,height=158 ]   left : periodic arrays of ss ( dash - dotted ) and as ( dashed ) peaks .",
    "the ss peaks are gaussians .",
    "the as peaks are described by a dipole .",
    "the dotted sinusoid corresponds to the @xmath395 fourier component of the ss peaks .",
    "right : evaluation of eq .",
    "( [ fm ] ) for four values of @xmath87 , with @xmath397 .",
    ", title=\"fig:\",width=158,height=155 ]    the fourier amplitudes @xmath398 of a unit - amplitude gaussian peak array are defined ( for @xmath399 ) as functions of the r.m.s .",
    "peak width by @xmath400 as peak width @xmath178 increases , the width on index @xmath87 decreases and the number of significant terms in the series eq .",
    "( [ fourier1 ] ) decreases .",
    "the limiting case is @xmath401 , for which the peak array is approximated by a constant plus dipole term . for narrower ( ss ) peaks",
    "fourier terms with @xmath183 become significant , and a gaussian function is the more efficient peak model , as demonstrated in this study .",
    "[ ortho ] ( left panel ) shows peak arrays ( solid points ) for ss and as peaks extending beyond one @xmath106 period .",
    "the ss gaussian peak array with @xmath402 ( typical value for all but peripheral   collisions ) is the dash - dotted curve , the as array with @xmath403 is the dashed curve ( approximately dipole in this case ) .",
    "the dotted curve represents the quadrupole term of the ss peak array .",
    "figure  [ ortho ] ( right panel ) shows eq .",
    "( [ fm ] ) for @xmath402 with the first few multipole coefficients marked for reference ( open circles ) . for that width",
    "the jet - related quadrupole amplitude is @xmath404 . if the ss peak is not separately described by a gaussian peak model @xmath405 represents the dominant jet - related nonflow contribution to @xmath406 data in the form @xmath407 .",
    "similarly , other fourier components of the ss jet peak and the dipole component of the as peak could be misidentified as flow components , including `` higher harmonic '' flows  @xcite .",
    "wang , m. gyulassy , phys .",
    "d * 44 * , 3501 ( 1991 ) .",
    "d.  kharzeev and m.  nardi , phys .",
    "b * 507 * , 121 ( 2001 ) .",
    "m.  gyulassy and l.  mclerran , nucl .",
    "a * 750 * , 30 ( 2005 ) .",
    "b.  muller , acta phys .",
    "b * 38 * , 3705 ( 2007 ) .",
    "j. adams _ et al . _",
    "( star collaboration ) , phys .",
    "c * 73 * , 064907 ( 2006 ) .",
    "g.  agakishiev , _ et al . _",
    "( star collaboration ) , phys .",
    "c * 86 * , 064902 ( 2012 ) .",
    "j.  adams _ et al . _",
    "( star collaboration ) , phys .",
    "d * 74 * , 032006 ( 2006 ) .",
    "t.  a.  trainor , int .",
    "j.  mod .",
    "e * 17 * , 1499 ( 2008 ) .",
    "r.  j.  porter and t.  a.  trainor ( star collaboration ) , j.  phys .",
    "* 27 * , 98 ( 2005 ) .",
    "r.  j.  porter and t.  a.  trainor ( star collaboration ) , pos c * frnc2006 * , 004 ( 2006 ) . a.  m.  poskanzer and s.  a.  voloshin , phys .  rev .",
    "c * 58 * , 1671 ( 1998 ) .",
    "j.  adams _ et al . _",
    "( star collaboration ) , phys .",
    "c * 72 * , 014904 ( 2005 ) .",
    "j.  adams _ et al . _",
    "( star collaboration ) , phys .",
    "lett .   *",
    "92 * , 112301 ( 2004 ) . c.  adler _ et al . _",
    "( star collaboration ) , phys .",
    "lett .   * 89 * , 202301 ( 2002 ) .",
    "t.  a.  trainor , int .",
    "j.  mod .",
    "e * 23 * , 1430011 ( 2014 ) .",
    "t.  a.  trainor , phys .",
    "d * 87 * , 054005 ( 2013 ) .",
    "t.  a.  trainor and d.  t.  kettler , phys .",
    "c * 83 * , 034903 ( 2011 ) .",
    "t.  a.  trainor , phys .",
    "d * 89 * , no . 9 , 094011 ( 2014 ) .",
    "t.  a.  trainor and d.  t.  kettler , int .",
    "j.  mod .",
    "e * 17 * , 1219 ( 2008 ) .",
    "t.  a.  trainor , mod .",
    "a * 23 * , 569 ( 2008 ) .",
    "t.  a.  trainor , phys .",
    "c * 78 * , 064908 ( 2008 ) t.  a.  trainor , j.  phys .",
    "g * 37 * , 085004 ( 2010 ) .",
    "t.  a.  trainor , d.  t.  kettler , d.  j.  prindle and r.  l.  ray , j.  phys .",
    "g * 42 * , 025102 ( 2015 ) .",
    "d.  t.  kettler ( star collaboration ) , eur .",
    "j.   c * 62 * , 175 ( 2009 ) .",
    "d.  kettler ( star collaboration ) , j.  phys .",
    "ser .   * 270 * , 012058 ( 2011 ) .",
    "t.  a.  trainor , phys .",
    "c * 80 * , 044901 ( 2009 ) .",
    "t.  a.  trainor , phys .",
    "c * 81 * , 014905 ( 2010 ) .",
    "b.  alver and g.  roland , phys .",
    "c * 81 * , 054905 ( 2010 ) .",
    "m.  luzum , phys .",
    "b * 696 * , 499 - 504 ( 2011 ) .",
    "s.  chatrchyan",
    "_ et al . _",
    "( cms collaboration ) , phys .",
    "c * 89 * , 044906 ( 2014 ) .",
    "g.  box and g.  tiao , _ bayesian inference in statistical analysis _ , wiley , reading ,",
    "ma ( 1973 ) .",
    "a.  stuart and j.  keith ord , _",
    "kendall s advanced theory of statistics _ volume 2 , 5th edition , oxford university press ( new york ) 1991 .",
    "s.  laplace , _ memoires de mathmatique et de physique , tome sixime _ ( 1774 ) .",
    "c. chatfield , _ the analysis of time series  an introduction _",
    "( fourth ed . ) . chapman and hall , london ( 1989 ) .",
    "trainor , r.j .",
    "porter and d.j .",
    "prindle , j. phys .",
    "g : nucl . part .",
    "phys . * 31 * 809 ( 2005 ) .",
    "t. a. trainor and d. j. prindle , hep - ph/0411217 ."
  ],
  "abstract_text": [
    "<S> analysis and interpretation of spectrum and correlation data from high - energy nuclear collisions is currently controversial because two opposing physics narratives derive contradictory implications from the same data  </S>",
    "<S> one narrative claiming collision dynamics is dominated by dijet production and projectile - nucleon fragmentation , the other claiming collision dynamics is dominated by a dense , flowing qcd medium . </S>",
    "<S> opposing interpretations seem to be supported by alternative data models , and current model - comparison schemes are unable to distinguish between them . </S>",
    "<S> there is clearly need for a convincing new methodology to break the deadlock . in this study </S>",
    "<S> we introduce bayesian inference ( bi ) methods applied to angular correlation data as a basis to evaluate competing data models . for simplicity </S>",
    "<S> the data considered are projections of 2d angular correlations onto 1d azimuth from three centrality classes of 200 gev  collisions . </S>",
    "<S> we consider several data models typical of current model choices , including fourier series ( fs ) and a gaussian plus various combinations of individual cosine components . </S>",
    "<S> we evaluate model performance with bi methods and with power - spectrum ( ps ) analysis . </S>",
    "<S> we find that the fs - only model is rejected in all cases by bayesian analysis which always prefers a gaussian . </S>",
    "<S> a cylindrical quadrupole @xmath0 is required in some cases but rejected for 0 - 5%-central  collisions . </S>",
    "<S> given a gaussian centered at the azimuth origin `` higher harmonics '' @xmath1 for @xmath2 are rejected . </S>",
    "<S> a model consisting of gaussian + dipole @xmath3 + quadrupole @xmath0 provides good 1d data descriptions in all cases . </S>"
  ]
}