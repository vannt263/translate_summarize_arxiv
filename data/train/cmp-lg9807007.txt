{
  "article_text": [
    "the word _ chunking _ ( also _ partial _ or _ shallow parsing _ ) refers to techniques used for the recognition of relatively simple syntactic structures , such as nps , pps , verb complexes etc .",
    "np chunkers typically rely on fairly simple and efficient processing tools such as finite automata or ( in stochastic approaches ) markov models ( mms ) .",
    "the output consists of structures recognised with a high degree of certainty ; such structures are used for further processing .      the main motivation for the work reported in this paper was the development of nlp software for creating language resources , especially syntactically annotated corpora ( treebanks ) .",
    "a disadvantage of symbolic tools supporting corpus annotation is that they are language specific and have to be developed prior to actual annotation . for english",
    ", this is not a problem since there are many such tools , yet for other languages , serious difficulties may arise here .    as an alternative , a bootstrapping approach can be taken in which , after a short phase of purely manual annotation , more and more automatic procedures are implemented using statistical nlp methods .",
    "the already annotated sentences serve as training data .",
    "this approach is highly independent of the annotation format , which is simply learned from training data .    with these prerequisites ,",
    "we have developed a stochastic parser ( _ chunker _ ) that recognises syntactic structures of limited depth .",
    "the tool is language - independent and can be used for parsing unrestricted text provided some minimal amount of annotated data is available .      in the following ,",
    "we describe our stochastic approach to np chunking based on a generalisation of standard pos tagging techniques ( hence the name _ chunk tagger _ ) .",
    "first , we show how a simple bracketing method can be extended to recognise more complex structures and several types of phrases ( sections  [ sec : bracketing ] and [ sec : cats ] ) .",
    "accuracy for different applications and tasks is reported in section  [ sec : results ] . in section  [ sec : related ] , we discuss the similarities and differences between our approach and related research .",
    "the idea of using statistics for np chunking goes back to , who used corpus frequencies to determine the boundaries of simple non - recursive np s . for each pair of pos tags @xmath0 , the probability of an np boundary ( ` [ ' or ` ] ' ) occurring between @xmath1 and @xmath2 is computed .",
    "on the basis of these context probabilities , the program inserts the symbols ` [ ' and ` ] ' into sequences of pos tags , yielding output of the following form :    @xmath3a / at former / ap top / nn aide / nn@xmath4 $ ] to / in @xmath3attorney / np  general / np  edwin / np meese / np@xmath4 $ ] interceded / vbd to / to extend / vb @xmath3an / at aircraft / nn company / nn ",
    "the accuracy of this approach is impressive . on the other hand ,",
    "the task is not too difficult since recursive structures are not recognised .",
    "it is interesting whether this simple technique can be used for the recognition of more complex phrases .",
    "we have modified church s approach in a way permitting efficient and reliable recognition of structures of limited depth , including complex prenominal adjectival and participial phrases , postnominal pp s and genitives , appositions , etc .",
    "we encode the structure in such a way that it can be recognised by a part - of - speech tagger , so the process runs in time linear to the length of the input string .    the basic idea is simple enough : structures of limited depth are encoded using a finite number of flags .",
    "we employ flags standing not just for bracketing , but for structural relations between adjacent words .",
    "given a sequence of words @xmath5 , we consider the structural relation @xmath6 holding between @xmath7 and @xmath8 for @xmath9 . for the recognition of most  even fairly complex  nps , pps , and aps , it is sufficient to distinguish the following seven values of @xmath6 which uniquely identify sub - structures of limited depth .",
    "@xmath10 if more than one of the conditions above are met , the first of the corresponding tags in the list is assigned .",
    "the depth of structures is limited to 3 . for convenience ,",
    "we give the graphical representation of the structural tags in figure [ fig : str ] . a structure tagged with these symbols",
    "is shown in figure [ fig : chunks ] .    ' '' ''    # 1 @xmath11@xmath12@xmath13 +    # 1 @xmath14@xmath15@xmath16 ` = ' +    ' '' ''    ' '' ''    # 1 aintelavivlivingpainter +    _ ` a painter living in tel aviv ' _    = adpositional case marker , hd = head , mo = modifier , mpn = multi - token proper noun , nk = noun phrase kernel , pnc = proper noun constituent    ' '' ''    instead of the simple context frequencies used by church , we employ a generalisation of the standard mm - based pos tagging method . the task of the chunker is to assign the most probable sequence of structural tags @xmath17 to a sequence of pos tags @xmath18 .",
    "this can be done exactly in the same way as the assignment of the optimal pos sequence to a sequence of words in pos tagging , and the task is to calculate    under this perspective , a standard part - of - speech tagger can be trained on a syntactically annotated corpus with structures converted into structural tags ( the @xmath6 s ) .",
    "however , in this case the corresponding markov model has only 7 tags ( the possible values of @xmath6 ) , which is obviously too coarse - grained .",
    "the precision of the tagger is rather disappointing : only about 77% of all structures are recognised correctly .    to cope with this problem",
    ", we enrich the mm state with information about the pos tag @xmath1 assigned to @xmath7 .",
    "now we can define _ structural tags _ as pairs @xmath19 .",
    "such tags constitute a finite alphabet of symbols describing structures of depth @xmath20 .",
    "the tagger s task is thus to assign the most probable sequence of structural tags @xmath21 to a sequence of part - of - speech tags @xmath22 , hence the part - of - speech tags are encoded in the structural tag ( the @xmath1 dimension ) , so @xmath23 uniquely determines @xmath24 . therefore , we have @xmath25 if @xmath26 and 0 otherwise , which simplifies calculations .",
    "the contexts are smoothed by linear interpolation of unigrams , bigrams , and trigrams .",
    "their weights are calculated by deleted interpolation .",
    "a simple extension of the chunk tagger can assign phrasal categories in addition to structures .",
    "we enrich the state @xmath27 of the markov model with information about the category @xmath28 of the node immediately dominating word @xmath7 .",
    "thus @xmath27 becomes a triple @xmath29 .",
    "for example , the adjective _ lebender _ in figure [ fig : chunks ] is assigned the tag @xmath30 .",
    "this extension also slightly improves the recognition of structures , cf .",
    "section [ sec : results ] .",
    "further precision gain can be achieved if we also add some information @xmath31 about the category of the grandparent node . however , only few symbols can be used to encode this dimension .",
    "otherwise , the tagset ( all @xmath32 ) becomes too large .",
    "we achieved the best results with just three flags @xmath33 , @xmath34 and @xmath35 , which indicate that @xmath36 is an ap , an np / pp and a coordinated constituent , respectively . in this format , the word _ aviv _ in figure [ fig : chunks ] is assigned the tag @xmath37 .",
    "in this section , we compare results achieved for different applications and types of structures .",
    "we use the dependency - oriented negra treebank @xcite as training data .",
    "the current size of the corpus is 12,000 sentences , or 210,000 tokens .",
    "all of these sentences have been annotated without the help of the chunk tagger .",
    "the annotation scheme distinguishes 24 phrasal categories .",
    "the pos tagset @xcite consists of 54 tags . for tagging purposes",
    ", it has been adjusted by merging tags irrelevant to the chunking task and adding simple morphological and lexical information . due to this adjustment",
    ", 1.5% more words are assigned the correct structural tag .",
    "structures are encoded according to the method presented in section  [ sec : cats ] .",
    "we vary the number of tag dimensions ( 1  4 ) .",
    "the results given in the following sections have been computed by spliting the corpus into disjoint training and test parts ( 90% and 10% , respectively ) .",
    "this procedure was repeated ten times , and the results were averaged .",
    "the accuracy measures employed are explained as follows .",
    "tags : : :    the percentage of structural tags with the correct value of the    @xmath6 attribute , bracketing : : :    the percentage of correctly recognised nodes , labelled bracketing : : :    the percentage of nodes recognised correctly including their syntactic    category , top - level chunks : : :    the percentage of correctly parsed `` maximal '' chunks , i.e. , phrases    not contained in a larger chunk of depth @xmath38 3 .",
    "we present figures concerning the _ precision _ of the chunker .",
    "_ recall _ is slightly lower for all applications ( 0.5%  1.5% ) .      as we already mentioned , the primary application of the chunk tagger is corpus ( treebank ) annotation .",
    "the treebank is being created in an interactive annotation mode : automatic and manual annotation steps are closely interleaved to ensure optimal control of the predictions made automatically ( for a precise description of this interactive approach to treebank annotation see @xcite ) .    as for the chunker",
    ", the interactive annotation mode means that the annotator specifies the boundaries of a complex np or pp , and the tool recognises its category and internal structure .",
    "note that the disambiguation of pp attachment is significantly easier than in the general case .",
    "correct structural tags are assigned to more than @xmath39 of all words , which means that approx .",
    "@xmath40 of all chunks ( np s , pp s , ap s ) are assigned the correct syntactic structure .",
    "precise results for different chunk encoding methods are given in table  [ table : res0 ] .",
    "the training corpus was created by extracting all nps , pps and aps occurring in the negra treebank ( 34,000 chunks , 130,000 tokens ) . in other words",
    ", the program had to perform the annotator s task : find a labelled structure that spans a given sequence of words .    ' '' ''    .precision of the chunk tagger in the interactive annotation mode for different chunk encoding methods .",
    "the symbols in brackets denote : @xmath41 structural relation ( 7 values ) , @xmath42 pos tag ( 54 values ) , @xmath43 parent node category ( 24 values ) , @xmath44 grandparent node category ( 3 values ) . [",
    "cols=\"<,^,^,^\",options=\"header \" , ]     ' '' ''    if we ignore errors concerning the internal structure of the chunks ( i.e. , we measure only the recognition of external boundaries , which corresponds to the precision measurement in some other approaches ) , 93.4% of all chunks are assigned the correct part of the input string .      ' '' ''    units < .01mm,2 mm > x from 100 to 12000 , y from 75 to 97 (    ' '' ''    ) bottom ticks numbered from 0 to 12000 by 2000 / left ticks numbered at 80 85 90 95 / / left ticks short from 75 to 96 by 1 / [ l ] at 12100 75 [ lb ] at 95 97.5 (    ' '' ''    ) 200 75.8 500 81.1 1000 83.0 2000 84.6 4000 86.2 6000 87.0 8000 87.7 10000 88.3 12000 88.8 / at 200 75.8 500 81.1 1000 83.0 2000 84.6 4000 86.2 6000 87.0 8000 87.7 10000 88.3 12000 88.8 / [ l ] at 12100 90.2 [ l ] at 5500 84    (    ' '' ''    ) 200 81.8 500 84.5 1000 86.7 2000 90.4 4000 92.2 6000 92.6 8000 92.8 10000 93.1 12000 93.3 / at 200 81.8 500 84.5 1000 86.7 2000 90.4 4000 92.2 6000 92.6 8000 92.8 10000 93.1 12000 93.3 /    [ l ] at 12100 93.7 [ l ] at 5500 95.5    ' '' ''",
    "an important advantage of the chunker is that it is independent of theory - internal representations and can be used to recognise structures of any language .",
    "of course , the availability of a training corpus is a prerequisite .",
    "now we shall see how much data is necessary to achieve reliable results .",
    "figure  [ fig : results ] shows precision ( measured as the percentage of top - level chunks recognised correctly ) for the interactive annotation mode .",
    "we consider two encoding schemes .",
    "the _ depth 3 _ scheme is the one described in section  [ sec : chunking ] , which uses all the 7 possible values of the @xmath6 dimension .",
    "the _ depth 2 _ scheme is its slightly simplified version in which @xmath6 can take only four values : * 1 , 0 , + , - * , so that only depth - two trees are recognised by the chunker .",
    "while for the depth 3 encoding a training corpus of 10002000 sentences is needed , the simpler encoding requires only about 500 sentences .",
    "thus the chunk tagger can be successfully used in treebank annotation at quite an early stage , with only a few hundred annotated sentences available .",
    "in section [ sec : bracketing ] , we sketched the simple bracketing technique described by , which provided motivation for our chunking method . as far as other approaches are concerned ,",
    "our work is most closely related to that of , who use markov models in a preprocessing step to reduce the number of tree segments ( called _ supertags _ ) that can be assigned to a word in a lexicalised tree adjoining grammar .",
    "this approach makes parsing more efficient , but it needs a large training corpus , has to fight a large amount of ambiguity and needs a subsequent parsing step ( also see @xcite for the use of explanation - based learning for this purpose ) .",
    "symbolic np chunkers usually rely on finite automata and/or pattern matching , cf .",
    "@xcite , @xcite . presents a partial parsing technique based on cascaded finite automata .",
    "describe a pos tagger and shallow parser combining symbolic and stochastic processing via _",
    "relaxation labelling_.    the precision of the abovementioned approaches is often measured by the number of correct labels assigned to words .",
    "the figures range from 85% to 98% .",
    "our results ( 89%  95% ) fit into this interval , yet it should be kept in mind that the coverage of the approaches and the precision measuring methods are often only roughly comparable . for instance , several shallow parsing methods are restricted to pos tagging and grammatical function labelling without explicitly specifying attachments and phrase boundaries .",
    "furthermore , the notion of ` phrase ' varies in these investigations , and usually these studies concentrate on simple , non - recursive structures . by contrast",
    ", our chunker is capable of recognizing complex , even recursive , nps , pps , and aps .",
    "compared to the symbolic techniques , an important advantage of the stochastic approach taken in our project is its independence of external lexical resources . as a result , the chunker trained with the pos - tags and structures of the current corpus is fairly domain - independent .",
    "of course , our tool would benefit from the use of lexical knowledge ; this issue has to be addressed in the near future .    since our approach is restricted to a small number of structurally different tags , it has the great advantage of requiring only a small amount of training data ( cf .",
    "section [ sec : results ] ) and the recognition of these phrases is of high accuracy .",
    "we have presented a stochastic partial parser ( _ chunker _ ) that recognises the boundaries , internal structure and syntactic category of simple as well as fairly complex np s , pp s and ap s .",
    "the chunker is a straightforward application of a stochastic part - of - speech tagger .",
    "we use it to model a mapping from lexical categories to syntactic structures .",
    "the type of the structural encoding is crucial in this approach , and better encodings increase the accuracy of structural assignment .",
    "the use of markov model processing techniques guarantees that the process runs in time linear to the length of the input string .",
    "kenneth  ward church .",
    "1988 . a stochastic parts program and noun phrase parser for unrestricted text . in _ proc .",
    "second conference on applied natural language processing _ , pages 136143 , austin , texas , usa .          b.  srinivas .",
    "explanation - based learning and finite state transducers : applications to parsing lexicalised tree adjoining grammars . in _ proceedings of the workshop on finite - state models of language , ecai 96 _ , budapest ."
  ],
  "abstract_text": [
    "<S> we describe a stochastic approach to _ partial parsing _ , i.e. , the recognition of syntactic structures of limited depth . the technique utilises markov models , but goes beyond usual bracketing approaches , since it is capable of recognising not only the boundaries , but also the internal structure and syntactic category of simple as well as complex np s , pp s , ap s and adverbials . </S>",
    "<S> we compare tagging accuracy for different applications and encoding schemes .    </S>",
    "<S> # 1 </S>"
  ]
}