{
  "article_text": [
    "social products and services  from fax machines and cell phones to online social networks  inherently exhibit ` network effects ' with regard to their value to users .",
    "the value of these products to a user is inherently non - local , since it typically grows as members of the user s social neighborhood use the product as well . yet randomized experiments ( or ` a / b tests ' ) , the standard machinery of testing frameworks including the rubin causal model @xcite , critically assume what is known as the ` stable unit treatment value assumption ' ( sutva ) , that each individual s response is affected only by their own treatment and not by the treatment of any other individual . addressing",
    "this tension between the formalism of a / b testing and the non - local effects of network interaction has emerged as a key open question in the analysis of on - line behavior and the design of network experiments @xcite .    under ordinary randomized trials where the stable unit treatment value assumption is a reasonable approximation  for example when a search engine a / b tests the effect of their color scheme upon the visitation time of their users  the population is divided into two groups : those in the ` treatment ' group who see the new color scheme a and those in the control group who see the default color scheme b. assuming there are negligible interference effects between users , each individual in the treated group responds",
    "just as he or she would if the entire population were treated , and each individual in the control group responds just as he or she would if the entire population were in control . in this manner , we can imagine that we are observing results from samples of two distinct ` parallel universes ' at the same time  ` universe a ' in which color scheme a is used for everyone , and ` universe b ' in which color scheme b is used for everyone  and we can make inferences about the properties of user behavior in each of these universes .    this tractable structure changes dramatically when the behavior of one user @xmath1 can have a non - trivial effect on the behavior of another user @xmath2  as is the case when the feature or product being tested has any kind of social component .",
    "now , if @xmath1 is placed in universe a and @xmath2 is placed in universe b , then our analysis of @xmath1 s behavior in a is contaminated by properties of @xmath2 s behavior in b , and vice versa ; we no longer have two parallel universes .    [",
    "[ average - treatment - and - network - exposure ] ] * average treatment and network exposure * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our goal is to develop techniques for analyzing the average effect of a treatment on a population when such interaction is present . as our basic scenario ,",
    "we imagine testing a service by providing it to a subset of an underlying population ; the service has a ` social ' component in that @xmath1 s reaction to the service depends on whether a neighbor @xmath2 in the social network also has the service .",
    "we say that an individual is in the _ treatment group _ if the individual is provided with the service for the test , and in the _ control group _ otherwise .",
    "there is an underlying numerical response variable of interest ( for example , the user s time - on - site in each condition ) , and we want to estimate the average of this response in both the universe where everyone has the service , and the universe where no one has the service , despite the fact that  since the population is divided between treatment and control  we do nt have direct access to either universe .",
    "we express this question using a formalism introduced by aronow and samii for causal inference without this stable unit treatment value assumption @xcite , with strong similarities to similar formalism introduce by manski @xcite , and adapt it to the problem of interference on social networks .",
    "let @xmath3 be the treatment assignment vector , where @xmath4 means that user @xmath1 is in the treatment group and @xmath5 means the user is in the control .",
    "let @xmath6 be the potential outcome of user @xmath1 under the treatment assignment vector @xmath7 .",
    "the fundamental quantity we are interested in is the average treatment effect , @xmath8 , between the two diametrically opposite universes @xmath9 and @xmath10 , @xmath11}. \\label{eq : avg - effect}\\end{aligned}\\ ] ] this formulation contains the core problem discussed in informal terms above : unlike ordinary a / b testing , no two users can ever truly be in opposing universes at the same time .    a key notion that we introduce for evaluating ( [ eq : avg - effect ] ) is the notion of _ network exposure_. we say that @xmath1 is ` network exposed ' to the treatment under a particular assignment @xmath12 if @xmath1 s response under @xmath12 is the same as @xmath1 s response in the assignment @xmath13 , where everyone receives the treatment .. ] we define network exposure to the control condition analogously .    with this definition in place , we can investigate several possible conditions that constitute network exposure .",
    "for example , one basic condition would be to say that @xmath1 is network exposed to the treatment if @xmath1 and all of @xmath1 s neighbors are treated . another would be to fix a fraction @xmath14 and say that @xmath1 is network exposed if @xmath1 and at least a @xmath15 fraction of @xmath1 s neighbors are treated .",
    "the definition of network exposure is fundamentally a modeling decision by the experimenter , and in this work we introduce several families of exposure conditions , each specifying the sets of assignment vectors in which a user is assumed to be ` network exposed ' to the treatment and control universes , providing several characterizations of the continuum between the two universes .",
    "choosing network exposure conditions is crucial because they specify when we can observe the potential outcome of a user as if they were in the treatment or control universe , without actually placing all users into the treatment or control universe .",
    "[ [ graph - cluster - randomization ] ] * graph cluster randomization * + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    following the formulation of network exposure , a second key notion that we introduce is a generic graph randomization scheme based on graph clustering , which we call _ graph cluster randomization_. at a high level , graph cluster randomization is a technique in which the graph is partitioned into a set of _ clusters _ , and then randomization between treatment and control is performed at the cluster level .",
    "the probability that a vertex is network exposed to treatment or control will then typically involve a graph - theoretic question about the intersection of the set of clusters with the local graph structure near the vertex .",
    "we show how it is possible to precisely determine the non - uniform probabilities of entering network exposure conditions under such randomization . using inverse probability weighting @xcite , we are then able to derive an unbiased estimator of the average treatment effect @xmath8 under any network exposure for which we can explicitly compute probabilities .",
    "we motivate the power of graph cluster randomization by furnishing conditions under which graph cluster randomization will produce an estimator with asymptotically small variance .",
    "first , we observe that if the graph has bounded degree and the sizes of all the clusters remain bounded independent of the number of vertices @xmath0 , then the estimator variance is @xmath16 , a simple but illustrative sufficient condition for smallness .",
    "the key challenge is the dependence on the degrees  in general , a collection of bounded - size clusters can produce a variance that grows exponentially in the vertex degrees .",
    "more precisely , when performing graph cluster randomization with single - vertex clusters , the variance of the estimator admits a _ lower bound _ that depends _ exponentially _ on the degrees .",
    "this raises the important algorithmic question of how to choose the clustering : bounded - size clusters provide asymptotically small variance in the number of vertices @xmath0 , but if the clusters are not chosen carefully then we get an exponential dependence on the vertex degrees which could cause the variance to be very large in practice .",
    "[ [ cluster - randomization - in - restricted - growth - graphs ] ] * cluster randomization in restricted - growth graphs * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we identify an important class of graphs , which we call _ restricted - growth graphs _ , on which a non - trivial clustering algorithm admits an _ upper bound _ on the estimator variance that is _ linear _ in the degrees of the graph .",
    "the restricted - growth condition that we introduce for graphs is an expansion of the bounded - growth condition previously introduced for studying nearest - neighbor algorithms in metric spaces @xcite , designed to include low - diameter graphs in which neighborhoods can grow exponentially .",
    "formally , let @xmath17 be the set of vertices within @xmath18 hops of a vertex @xmath19 ; our restricted - growth condition says that there exists a constant @xmath20 , independent of the degrees of the graph , such that for all vertices @xmath19 and all @xmath21 , we have @xmath22 .",
    "note the comparison to the standard bounded - growth definition , which requires @xmath23 , a much stronger condition and not necessary for our results to hold .    for restricted - growth graphs ,",
    "we provide a clustering algorithm for which the estimator variance grows only linearly in the degree .",
    "the challenge is that the variance can grow exponentially with the number of clusters that intersect a vertex s neighborhood ; our approach is to form clusters from balls of fixed radius grown around a set of well - separated vertices .",
    "the restricted growth condition prevents balls from packing too closely around any one vertex , thus preventing vertex neighborhoods from meeting too many clusters .",
    "we note that for the special case of restricted - growth graphs that come with a uniform - density embedding in euclidean space , one can use the locations of vertices in the embedding to carve up the space into clusters directly ; the point , as in work on the nearest - neighbor problem @xcite , is to control this carving - up at a graph - theoretic level rather than a geometric one , and this is what our technique does .",
    "our class of restricted - growth graphs provides an attractive model for certain types of real - world graphs .",
    "restricted - growth graphs include graphs for which there exists an embedding of the vertices with approximately uniform density in a euclidean space of bounded dimension , such as lattices or random geometric graphs , where edges connect neighbors within some maximal metric distance .",
    "[ [ summary ] ] * summary * + + + + + + + + +    our work thus occupies a mediating perch between recent work from the statistical literature on causal inference under interference @xcite , as well as recent work from the computer science literature on network bucket testing @xcite .",
    "our contribution extends upon the ordinary inference literature by developing exposure models and randomization schemes particularly suited for experiments on large social graphs , also showing how previous approaches are intractable .",
    "meanwhile , we show that reducing estimator variance involves non - trivial graph - theoretic considerations , and we introduce a clustering algorithm that improves exponentially on baseline randomization schemes .",
    "our contribution also connects to existing work on network bucket testing by contributing an exposure framework for the full graph and a randomization scheme that is capable of considering multiple exposure conditions at once , a necessity for true concurrent causal experimentation .    in section 2",
    "we describe our models of network exposure . in section 3",
    "we present our graph cluster randomization scheme , an algorithm for efficiently computing exposure probabilities , and an unbiased estimator of average treatment effects under graph cluster randomization . in section 4",
    "we introduce restricted - growth graphs , and show how the estimator has a variance that is linearly bounded in degree for such graphs .",
    "section 5 concludes .",
    "for a / b randomized experiments , the _ treatment condition _ of an individual decides whether or not they are subject to an intervention .",
    "this typically takes two values : ` treatment ' or ` control ' . in most randomized experiments ,",
    "the experimenter has explicit control over how to randomize the treatment conditions , and generally individuals are assigned independently .",
    "meanwhile , the _ exposure condition _ of an individual determines how they experience the intervention in full conjunction with how the world experiences the intervention . without the stable unit treatment value assumption ,",
    "at worst each of the @xmath24 possible values of @xmath25 define a distinct exposure condition for each user .",
    "aronow and samii call this `` arbitrary exposure '' @xcite , and there would be no tractable way to analyze experiments under arbitrary exposure .",
    "consider the potential outcomes for user @xmath1 . in the  arbitrary exposure \" case",
    ", @xmath26 is completely different for every possible @xmath7 .",
    "this means that we will never be able to observe @xmath26 for either @xmath27 or @xmath28 without putting all users into the treatment or control universes .",
    "thus , to make progress on estimating the average treatment effect under any other conditions , we require further assumptions . we do this here by assuming that multiple treatment vectors @xmath7 can map to the same potential outcomes : essentially , as long as treatment vectors @xmath7 and @xmath12 are `` similar enough '' from the perspective of a vertex @xmath1 , in a sense to be made precise below , then @xmath1 will have the same response under @xmath7 and @xmath12 .",
    "specifically , let @xmath29 be the set of all assignment vectors @xmath7 for which @xmath1 experiences outcome @xmath30 .",
    "we refer to @xmath29 as an _ exposure condition _ for @xmath1 ; essentially , @xmath29 consists of a set of assignment vectors that are `` indistinguishble '' from @xmath1 s point of view , in that their effects on @xmath1 are the same .",
    "our interest is in the particular exposure conditions @xmath31 and @xmath32 , which we define to be the sets that contain @xmath33 and @xmath34 respectively . in this way",
    ", we are assuming that for all @xmath35 , we have @xmath36 , and for all @xmath37 , we have @xmath38.-sized bins , and define the `` exposure conditions '' as all assignment vectors that produce a potential outcome in that @xmath39 bin . in cases where no other potential outcomes correspond to the outcomes for @xmath40 or @xmath9 , it may be more appropriate to manage bias using @xmath39 distances on potential outcomes this way . ]",
    "note that it is possible that @xmath41 and @xmath42 belong to the same exposure condition and that @xmath43 , which corresponds to a treatment that has no effects .",
    "we define an _ exposure model _ for user @xmath1 as a set of exposure conditions that completely partition the possible assignment vectors @xmath7 .",
    "the set of all models , across all users , is the exposure model for an experiment . for our purposes though , it is unnecessary to entirely specify an exposure model , since we are only trying to determine the average treatment effect between the extreme universes .",
    "we only care about the exposure conditions @xmath31 and @xmath32 for which each user @xmath1 experiences exposure to the treatment or control universe and @xmath32 could become relevant . ] .",
    "of course , the _ true _ exposure conditions @xmath31 and @xmath32 for each user are not known to the experimenter a priori , and analyzing the results of an experiment requires choosing such conditions in our framework . if the wrong exposure conditions are chosen by the experimenter , what happens to the estimate of the average treatment effect ?",
    "if users are responding in ways that do not correspond to @xmath41 and @xmath42 , we will be introducing bias into the average treatment effect .",
    "the magnitude of this bias depends on how close the outcomes actually observed are to the outcomes at @xmath41 and @xmath42 that we wanted to observe",
    ". it may even be favorable to allow such bias in order to lower variance in the results of the experiment .",
    "[ [ neighborhood - exposure ] ] * neighborhood exposure * + + + + + + + + + + + + + + + + + + + + + + +    we now describe some general exposure conditions that we use in what follows . in particular , we focus primarily on _ local exposure conditions _ , where two assignments are indistinguishable to @xmath1 if they agree in the immediate graph neighborhood of @xmath1 .",
    "we consider absolute and fractional conditions on the number of treated neighbors .",
    "note we are not asserting that these possible exposure conditions are the _ actual _ exposure conditions with respect to the actual potential outcomes in an experiment , but rather that they provide useful abstractions for the analysis of an experiment , where again the degree of bias introduced depends on how well the exposure conditions approximate belonging to the counterfactual universes .",
    "* _ full neighborhood exposure : _",
    "vertex @xmath1 experiences full neighborhood exposure to a treatment condition if @xmath1 and all @xmath1 s neighbors receive that treatment condition . *",
    "_ absolute @xmath44-neighborhood exposure : _",
    "vertex @xmath1 of degree @xmath45 , where @xmath46 , experiences absolute @xmath44-neighborhood exposure to a treatment condition if @xmath1 and @xmath47 neighbors of @xmath1 receive that treatment condition . *",
    "_ fractional @xmath15-neighborhood exposure : _ vertex @xmath1 of degree @xmath45 experiences fractional @xmath15-neighborhood exposure to a treatment condition if @xmath1 and @xmath48 neighbors of @xmath1 receive that treatment condition .",
    "the @xmath44-absolute and @xmath15-fractional neighborhood exposures can be considered relaxations of the full neighborhood exposure for vertex @xmath1 in that they require fewer neighbors of @xmath1 to have a fixed treatment condition for @xmath1 to be considered as belonging to that exposure condition . in fact , the set of assignment vectors that correspond to @xmath44-absolute and @xmath15-fractional neighborhood exposures are each nested under the parameters @xmath44 and @xmath15 respectively .",
    "increasing @xmath44 or @xmath15 decreases the set of assignment vectors until reaching full neighborhood exposure for vertex @xmath1 .",
    "it is natural to consider heterogeneous values @xmath44 or @xmath15  values that differ for each user  but we limit our discussion to exposure conditions that are homogeneous across users as much as possible . we do incorporate a mild heterogeneity in the definition of @xmath44-neighborhood exposure when vertices have degree @xmath49 : for these vertices we consider full neighborhood exposure instead .",
    "fractional exposure does not require this adjustment .",
    "[ [ core - exposure ] ] * core exposure * + + + + + + + + + + + + + + +    full neighborhood exposure is clearly only an approximation of full immersion in a universe . beyond local exposure conditions",
    ", we also consider exposure condition with global dependence .",
    "as one approach , consider individuals as exposed to a treatment only if they are sufficiently surrounded by sufficiently many treated neighbors who are in turn also surrounded by sufficiently many treated neighbors , and so on .",
    "this recursive definition may initially appear intractable , but such recursive exposure can in fact be characterized precisely by analyzing the @xmath44-core  and more generally the heterogeneous @xmath44-core  on the induced graph of treatment and control individuals .",
    "recall that the @xmath44-core of a graph @xmath50 is the maximal subgraph of @xmath51 in which all vertices have degree at least @xmath44 @xcite .",
    "similarly , the heterogeneous @xmath52-core of a graph @xmath50 , parameterized by a vector @xmath53 , is the maximal subgraph @xmath54 of @xmath51 in which each vertex @xmath55 has degree at least @xmath56 @xcite . using the definition of heterogeneous @xmath52-core",
    ", we introduce the following natural fractional analog .    the fractional @xmath15-core is the maximal subgraph @xmath54 of @xmath50 in which each vertex @xmath55 is connected to at least a fraction @xmath15 of the vertices it was connected to in @xmath51 .",
    "thus , for all @xmath55 , @xmath57 .",
    "equivalently , if @xmath58 is the degrees of vertex @xmath1 , the fractional @xmath15-core is the heterogenous @xmath52-core of @xmath51 for @xmath59 .    since the heterogeneous @xmath52-core is a well - defined object , so is the fractional @xmath15-core . using this definition , we now define exposure conditions that are all stricter versions of corresponding earlier neighborhood conditions .    * _ component exposure : _",
    "vertex @xmath1 experiences component exposure to a treatment condition if @xmath1 and all of the vertices in its connected component receive that treatment condition .",
    "* _ absolute @xmath44-core exposure : _ vertex @xmath1 with degree @xmath46 experiences absolute @xmath44-core exposure to a treatment condition if @xmath1 belongs to the @xmath44-core of the graph @xmath60 $ ] , the subgraph of @xmath51 induced on the vertices @xmath61 that receive that treatment condition . * _ fractional @xmath15-core exposure : _",
    "vertex @xmath1 experiences fractional @xmath15-core exposure to a treatment condition if @xmath1 belongs to the fractional @xmath15-core of the graph @xmath60 $ ] , the subgraph of @xmath51 induced on the vertices @xmath61 that receive that treatment condition .",
    "component exposure is perhaps the strongest requirement for network exposure imaginable , and it is only feasible if the interference graph being studied is comprised of many disconnected components .",
    "we include it here specifically to note that the fractional @xmath15-core exposure for @xmath62 reduces to component exposure .",
    "again like the neighborhood exposure case , absolute core exposure requires heterogeneity in @xmath44 across users for it to be a useful condition for all users . a parsimonious solution analogous to the solution for @xmath44-neighborhood exposure may be to consider heterogeneous max(degree , @xmath44)-core exposure .",
    "fractional @xmath15-core exposure , like fractional @xmath15-neighborhood exposure , is again free from these parsimony problems .",
    "core exposure conditions are strictly stronger than the associated neighborhood exposure conditions above . in fact",
    ", every assignment vector in which a vertex @xmath1 would be component or core exposed corresponds to neighborhood exposure , but not vice versa .",
    "so the assignment vectors of core and component exposure are entirely contained in those of the associated neighborhood exposure .",
    "[ [ other - exposure - conditions ] ] * other exposure conditions * + + + + + + + + + + + + + + + + + + + + + + + + + + +    other exposure conditions may prove relevant to particular applications .",
    "in particular , we draw attention to the intermediate concept of placing absolute or fractional conditions on the population of vertices within @xmath63 hops , where @xmath64 is the neighborhood exposure conditions above",
    ". we also note that on social networks with very high degree , for many applications it may be more relevant to define the exposure conditions in terms of a lower degree network that considers only stronger ties .",
    "using the concept of network exposure , we can now consider estimating the average treatment effect @xmath8 between the two counterfactual universes using a randomized experiment . recall that @xmath25 is the treatment assignment vector of an experiment . to randomize the experiment ,",
    "let @xmath25 be drawn from @xmath65 , a random vector that takes values on @xmath66 , the range of @xmath25 .",
    "the distribution of @xmath65 over @xmath66 given by @xmath67 is what defines our randomization scheme , and it is also exactly what determines the relevant probabilities of network exposure . for a user @xmath1",
    ", @xmath68 is the probability of network exposure to treatment and @xmath69 is the probability of network exposure to control .    in general",
    ", these probabilities will be different for each user and each treatment condition , and knowing these probabilities makes it possible to correct for allocation bias during randomization .",
    "in particular , it becomes possible to use the horvitz - thompson estimator , @xmath70 , to obtain an unbiased estimate of @xmath8 , here given by @xmath71}{\\pr(z \\in \\sigma^1_i ) } -\\frac{y_i(z)\\mathbf{1}[z \\in \\sigma^0_i]}{\\pr(z \\in \\sigma^0_i)}\\right)},\\end{aligned}\\ ] ] where @xmath72 $ ] is the indicator function .",
    "assuming the probabilities are positive , the expectation over @xmath65 clearly gives @xmath8 , though note that this does assume that the exposure conditions are not misspecified .",
    "let us examine the exposure probabilities for the simplest network exposure condition , full neighborhood exposure , and under the simplest randomization scheme  independent vertex randomization , in which each vertex is independently assigned to treatment or control .",
    "if all vertices are treated independently with probability @xmath73 then the probability of full neighborhood exposure to treatment for a user @xmath1 of degree @xmath58 is simply given by @xmath74 , and the probability of full neighborhood exposure to control is given by @xmath75 .",
    "this highlights the main challenge of network exposure : the chance that a vertex with high degree manages to reach full neighborhood exposure , or anywhere near it , can be exponentially small in @xmath58 .",
    "intuitively , such small exposure probabilities will dramatically increase the variance of the horvitz - thompson estimator , and it indicates the necessity of using more intelligent randomization .    to reduce the variance of this horvitz - thompson estimator",
    ", we introduce a general _ graph cluster randomization _ approach , creating graph clusters and randomizing assignment at the cluster level rather than at the vertex level , with clusters assigned independently .",
    "connected vertices will then be assigned to the same treatment condition more often than would happen with independent assignment , increasing the expected number of users who are network exposed to a condition at the cost of increased correlations between users exposure conditions .    for clarity",
    "when discussing clustering , we introduce some notation .",
    "let the vertices be partitioned into @xmath76 clusters @xmath77 .",
    "let @xmath78 denote the neighbors of @xmath1 in the graph @xmath51 , and let @xmath79 denote the set of clusters that contain @xmath1 or a neighbor of @xmath1 ; we call @xmath80 the set of clusters to which @xmath1 is _ connected_. using this notation , we will now examine the probabilities of different network exposures .    for the general creation of clusters we defer to the literature on algorithms for graph partitioning and community detection @xcite . in section [ s : growth ]",
    "we describe a particular algorithm for clustering graphs that satisfy a restricted - growth condition .",
    "the remainder of this section , however , describes the behavior of an arbitrary clustering on an arbitrary graph .",
    "we now examine how the probabilities of network exposure can be computed given a clustering . as a simple example , for the full neighborhood exposure condition",
    ", the probability of network exposure to treatment simply becomes @xmath81 and to control becomes @xmath82 .",
    "we now show that computing the exposure probabilities for absolute and fractional neighborhood exposure conditions is tractable as well .",
    "consider the challenge of computing the probability that vertex @xmath1 with degree @xmath58 is treated and more than @xmath44 of its neighboring vertices are treated under cluster randomization .",
    "this applies when considering both absolute and fractional neighborhood exposures .",
    "first , let us reindex the clusters such that if @xmath1 is connected to @xmath83 clusters , @xmath1 itself resides on cluster @xmath84 , and we let @xmath85 denote the other connected clusters .",
    "let @xmath86 be the number of connections @xmath1 has to each cluster , and let the bernoulli@xmath87 random variables @xmath88 denote the independent coin tosses associated with each cluster .",
    "then : @xmath89 = & \\pr \\left [ x_s = 1 \\right ] \\cdot \\pr \\left [ \\textstyle{\\sum_{j=1}^{s-1 } } w_{ij } x_j \\ge k - w_{is } \\right ] , \\\\",
    "\\pr [ z \\in \\sigma^0_i ]   = & \\pr \\left [ x_s = 0 \\right ] \\cdot \\pr \\left [ \\textstyle{\\sum_{j=1}^{s-1 } } w_{ij } x_j \\le d_i - k \\right ] .\\end{aligned}\\ ] ] here the random quantity @xmath90 obeys a weighted equivalent of a poisson - binomial distribution , and the probabilities in question can be computed explicitly using a dynamic program defined by the following recursion @xmath91 =   & p \\pr \\left [ \\textstyle{\\sum_{j=1}^{s-1 } } w_{ij } x_j \\ge t - w_{is } \\right ] + \\\\   & ( 1-p ) \\pr \\left [ \\textstyle{\\sum_{j=1}^{s-1 } } w_{ij } x_j \\ge t \\right ] .\\end{aligned}\\ ] ] note that @xmath92 is bounded by the maximum vertex degree @xmath93 , making this a polynomial time dynamic program with runtime @xmath94 .",
    "we formalize this computation into the following proposition .",
    "the probability that vertex @xmath1 is treated and @xmath47 neighboring vertices are treated under independent cluster randomization is given by @xmath95 = pf(s{-}1,k{-}w_{is};p,\\vec w)\\ ] ] where @xmath96 , \\\\",
    "f(j , t ; p,\\vec w_i ) & = & p f(j-1,t - w_{ij } ; p , \\vec w_i   ) \\\\ & & + ( 1-p ) f(j-1,t;p , \\vec w_i).\\end{aligned}\\ ] ] the probability that vertex @xmath1 is in control and @xmath47 neighboring vertices are in control under independent cluster randomization is given by @xmath97 = ( 1-p)[1-f(s - 1,d_i - k+1;p,\\vec w)].\\ ] ]    recall that these partial neighborhood exposure conditions ( absolute and fractional ) are nested .",
    "in fact , for a given vertex @xmath1 the recursion can be used to derive the probability for every possible threshold value under consideration in a single @xmath94 double for - loop .",
    "such a computation in fact returns the probability distribution over the exposure space for each individual .",
    "see figure [ f : personal ] for illustrations of what this distribution can look like .",
    "the dynamic program above only provides a means of exactly computing exposure probabilities for absolute and fractional neighborhood exposure conditions .",
    "unfortunately , how to efficiently compute the exact probability of @xmath44-core and fractional @xmath15-core exposure conditions is unclear , but recall that these exposure conditions were formally nested subsets of the corresponding neighborhood exposure conditions .",
    "this at least allows us to upper bound the core exposure probabilities , and we formalize this connection via the following proposition .",
    "because we are generally concerned about exposure probabilities being too small , this upper bound can be useful in identifying vertices with problematically small probabilities already under neighborhood exposure .",
    "the probability vertex @xmath1 is network exposed to a treatment condition under core exposure is less than or equal to the probability under the analogous neighborhood exposure : @xmath98    it is possible that a useful direct estimate of the core exposure probabilities can be obtained via monte carlo sampling of the randomization , but we do not explore that possibility here .",
    "the variance of the horvitz - thompson estimator under interference has been studied by aronow and samii @xcite , where they also present several variance reduction schemes . estimating the variance under their approach requires knowledge of joint exposure conditions , the joint probability that vertex @xmath1 is network exposed to treatment / control and vertex @xmath2 is network exposed to treatment / control .",
    "this is the probability that the random vector @xmath65 is in the exposure condition for vertex @xmath1 and for vertex @xmath2 simultaneously , i.e. @xmath99 for joint network exposure to treatment .",
    "if one is interested in computing the variance of the estimator analytically then there is nothing fundamentally different about this probability computation when compared to the single vertex exposure probability , aside from the fact that the intersection of the two sets can be empty .",
    "aronow and samii observe that an empty intersection makes it impossible to derive an unbiased estimate of the variance ( though they show how the variance can still be upper bounded ) , but it does not bias the effect estimator itself .",
    "the variance of the effect estimator where @xmath100/\\pr(z \\in \\sigma^{x}_i)\\right]\\ ] ] is given by @xmath101&=   \\left [   { { \\text{var}}}[\\hat{y}^1(z ) ] + { { \\text{var}}}[\\hat{y}^0(z ) ] \\right .",
    "-   \\\\ & \\left . 2 { { \\text{cov}}}[\\hat{y}^1(z ) , \\hat{y}^0(z ) ] \\right ]",
    ".\\end{aligned}\\ ] ] assuming the exposure conditions are properly specified , namely assuming that @xmath102 is constant for all @xmath103 , we can introduce the notation @xmath104 . using the further notation",
    "@xmath105 $ ] and @xmath106 $ ] we obtain @xmath107 & = & \\frac{1}{n^2 }    \\bigg [ \\sum_{i=1}^{n } \\frac{1-\\pi_i^x}{\\pi_i^x } y_i(\\sigma^x_i)^2 + \\\\ & & \\sum_{i=1}^{n } \\sum_{\\substack{j=1 \\\\ j\\ne i}}^n \\frac { \\pi_{ij}^{xx } - \\pi_i^x \\pi_j^x}{\\pi_i^x \\pi_j^x } y_i(\\sigma^x_i ) y_j(\\sigma^x_j ) \\bigg ] , \\end{aligned}\\ ] ] and @xmath108   = \\frac{1}{n^2 } \\bigg [ \\sum_{i=1}^{n } \\sum_{\\substack{j=1 \\\\ j\\ne i}}^n   \\frac { \\pi_{ij}^{10 } - \\pi_i^1 \\pi_j^0}{\\pi_i^1 \\pi_j^0 } y_i(\\sigma^1_i ) y_j(\\sigma^0_j ) -   & \\\\",
    "\\sum_{i=1}^n y_i(\\sigma^1_i)y_i(^0_i ) \\bigg ] . \\hspace{1",
    "cm } & \\label{eq : covar}\\end{aligned}\\ ] ]    the above expressions make it evident that the variance is very tightly controlled by the probabilities of exposure , and in order to upper bound the variance we will require lower bounds on the probabilities @xmath109 and also upper bounds on the joint probabilities @xmath110 , for all vertex pairs and all combinations of @xmath30 and @xmath111 . for neighborhood exposure , we can now write basic sufficient conditions under which the variance of the estimator is asymptotically @xmath16 in @xmath0 for graph cluster randomization",
    ".    assume the potential outcomes @xmath112 are all @xmath113 in @xmath0 .",
    "if @xmath51 has maximum degree @xmath113 and the size of each cluster is @xmath113 , then the variance of the horvitz - thompson estimator for full , @xmath44-neighborhood , and @xmath15-fractional neighborhood exposure under graph cluster randomization is @xmath16 .",
    "assume @xmath51 has maximum degree @xmath113 and the size of each cluster is @xmath113 .",
    "all of the single sums are clearly @xmath114 : @xmath115 is o@xmath116 since all vertices have bounded degree . for the double sums , note that @xmath117 if and only if @xmath1 and @xmath2 have no common cluster neighbors , @xmath118 .",
    "whenever @xmath119 , @xmath120 for full , @xmath44-neighborhood , and @xmath15-fractional neighborhood exposure .",
    "further , @xmath121 if @xmath119 and @xmath122 otherwise .",
    "so the terms of the double sums are zero whenever @xmath123 and when the terms are not zero ( @xmath119 ) , they are all positive and bounded above @xmath113 due to the bounded degrees .",
    "we now bound the number of vertices @xmath2 for which @xmath119 .",
    "vertex @xmath1 at most connects to @xmath113 clusters and therefore @xmath124 . for all @xmath125",
    ", we have that @xmath119 for any @xmath126 and for any vertex @xmath2 that is adjacent to a vertex in cluster @xmath127 . both of these contributions is @xmath113 , giving an @xmath113 contribution of vertices for each @xmath125 .",
    "since there are @xmath113 such clusters , this is still @xmath113 vertices @xmath2 in total for vertex @xmath1 such that @xmath119 .",
    "thus for each vertex , at most @xmath113 of the terms in the double sum are positive , making the total variance @xmath16 .",
    "the strength of this general result is that it achieves an @xmath16 bound on the variance when the maximum degree is bounded .",
    "the problem is that the variance can grow exponentially in the degrees of the graph . in this next section",
    "we address this issue , introducing a condition on a graph that ensures we can find a clustering into sets of size @xmath113  consistent with the above result  for which the variance grows as @xmath16 but is also linear rather than exponential in the maximum degree .",
    "in order to measure average treatment effects under interference on large - scale graphs , it is necessary to design a randomization scheme capable of containing the estimator variance for high - degree vertices . in this section",
    "we show that any graph satisfying our restricted - growth condition admits a clustering that can produce an unbiased effect estimate that is both @xmath16 and linear in the degrees of the graph .",
    "in contrast , we show that with less careful clustering , it is easy for the variance to grow exponentially in the degrees .",
    "let us first define restricted - growth graphs .",
    "let @xmath17 be the set of vertices within @xmath18 hops of a vertex @xmath19 .",
    "a graph @xmath50 is a restricted - growth graph if for all vertices @xmath128 and all @xmath129 , we have @xmath22 .    as mentioned in the introduction , graphs derived from a uniform - density embedding in a euclidean space of dimension @xmath130 exhibit restricted growth , with growth constant @xmath131 independent of degree . to develop intuition for the restricted - growth assumption",
    ", we first analyze the variance using graph cluster randomization on a family of particularly tractable restricted - growth graphs , @xmath44th powers of the cycle .",
    "we follow this analysis by proving bounds on the variance for general restricted - growth graphs .",
    "first we will consider a simple graph consisting of a single cycle with @xmath0 vertices .",
    "for this graph , we consider the full neighborhood exposure model , where we are interested in the average treatment effect between @xmath31 , when a vertex is treated and both of their neighbors are treated , and @xmath32 , when a vertex is not treated and neither of their neighbors are treated . for the fixed responses of the vertices to treatment and control , we assume that all vertices uniformly respond @xmath132 to network exposure to the treatment and @xmath133 to network exposure to the control .",
    "the cycle graph clearly admits an intuitively obvious clustering using the cycle structure , with contiguous blocks of @xmath134 vertices randomized together . as a last assumption ,",
    "assume that clusters are selected under a balanced randomization with @xmath135 .",
    "our goal is to determine how the variance of the horvitz - thompson average treatment effect estimator depends on the size @xmath134 of these clusters . for this basic combination of graph , exposure condition , responses , and clustering",
    ", one can derive the asymptotic variance exactly .",
    "consider the variance presented in above . since all vertices respond zero to the control condition in our example , as long as the exposure probability for the control condition is strictly positive then both @xmath136 and @xmath137 are zero .",
    "since our calculations will rely only on probabilities @xmath138 for the exposure to treatment condition , we omit the superscript .",
    "the variance is then : @xmath139 = \\frac{\\bar y^2}{n^2 }    \\bigg [ \\sum_{i=1}^{n}\\left   ( \\frac{1}{\\pi_i}-1 \\right ) +   \\sum_{i=1}^{n } \\sum_{\\substack{j=1 \\\\ j\\ne i}}^n \\left ( \\frac { \\pi_{ij}}{\\pi_i \\pi_j } -1 \\right ) \\bigg ] .\\end{aligned}\\ ] ] notice that the terms of the double sum are only non - zero for vertex pairs where @xmath140 .",
    "first , consider the case of each vertex being its own cluster .",
    "the probability of being exposed and both of one s neighbors being exposed is equal to the probability of seeing three independent coins come up heads .",
    "when the randomization is balanced ( e.g. @xmath135 ) , we obtain @xmath141 .",
    "note that the co - assignment probabilities depend on whether vertices @xmath1 and @xmath2 are neighbors or share a neighbor . from this",
    "we derive @xmath142 if @xmath143 and @xmath144 if @xmath145 , and if @xmath146 , the probabilities are independent .",
    "we obtain @xmath147 .    now , consider randomizing blocks of @xmath148 vertices , where @xmath134 does not depend on @xmath0 .",
    "the calculations for this case are expansive but straight - forward .",
    "we consider a single one of the equivalent cyclically shifted possibilities .",
    "the calculation requires handling @xmath149 and @xmath150 separately , but the expression for @xmath150 as a function of @xmath134 holds for @xmath149 as well , so we omit the special case for brevity .",
    "the variance calculation depends on distance @xmath151 up to @xmath152 , and for @xmath153 this evaluates to : @xmath154   = \\frac{\\bar y^2}{n^2 } \\bigg [ \\left ( n + \\frac{4n}{c } \\right ) +   \\underbrace { \\frac{2n}{c } ( c+2 ) } _ { \\delta=1 } + \\hspace{2 cm } \\\\",
    "\\underbrace { \\frac{2n}{c } \\sum_{k=2}^{c-2 } ( c - k + 2 ) } _ { 1<\\delta < c-1 } +   \\underbrace { \\frac{2n}{c } 3   } _ { \\delta = c-1 } +   \\underbrace { \\frac{2n}{c } 2 } _",
    "{ \\delta = c } +   \\underbrace { \\frac{2n}{c } } _ { \\delta = c+1 } \\bigg ] + o\\left ( \\frac{1}{n^2 } \\right ) .\\end{aligned}\\ ] ] this reduces to @xmath155 , which holds for all @xmath156 .    combining these calculations , the asymptotic variance of the estimator for all @xmath134",
    "is plotted in figure 2 .",
    "notice that the variance is minimized when randomizing clusters of size @xmath157 , which corresponds exactly to the size of neighborhoods on the simple cycle .    to build upon this observation",
    ", we now examine the simulated variance for higher degree extensions of the cycle , the so - called @xmath44th power of the cycle , where analytic derivation is already unwieldy .",
    "thus , we use a simulation of the cluster randomization procedure to examine how the variance of the effect size estimator depends on the cluster size for these higher degree graphs .    the @xmath44th power of a cycle graph consists of a cycle where each vertex is connected to the @xmath44 nearest neighbors on each side , yielding a regular graph where all vertices have degree @xmath158 . by sampling one million cluster randomizations on graphs with @xmath159 vertices , we can compute the sample variance of the estimator across these samples .",
    "the results are shown in figure 2 , for @xmath160 through @xmath161 .",
    "the simulations for @xmath160 agree precisely with the overlaid asymptotic calculations .",
    "notice how the optimal cluster size @xmath134 appears to scale approximately linearly in degree , and also notice how the variance at the optimal clustering size , the minimum value of each curve as @xmath44 increases , appears to scale linearly in @xmath44 . while the exact variance as a function of cluster size @xmath134 is unwieldy to derive ,",
    "we are able to provide the following upper bound , showing how the variance of the estimator for clusters of size @xmath162 scales linearly in the degree @xmath45 of the graph .",
    "this suggests that one should treat contiguous blocks of the cycle attuned to the size of the neighborhood of the vertices .",
    "when deriving this upper bound , it is no longer necessary to assume a uniform response @xmath132 , and instead we simply assume that the responses are upper bounded by some value @xmath163 .",
    "when clusters have size @xmath164 , each vertex can be connected to at most @xmath165 clusters , meaning that @xmath166 for all @xmath1 .",
    "so @xmath167 & \\le &   \\frac{y_m^2}{n^2 }   \\bigg [ \\sum_{i=1}^{n } ( p^{-2}-1 ) +   \\sum_{i=1}^{n } \\sum_{\\substack{j=1 \\\\ j\\ne i}}^n ( \\frac { \\pi_{ij}}{\\pi_i \\pi_j } - 1 ) \\bigg ] .\\end{aligned}\\ ] ] now each vertex has a non - independent joint assignment probability ( such that @xmath168 ) with at most @xmath169 other vertices : up to @xmath170 other vertices when they are adjacent to two clusters , the @xmath171 to the left of the left cluster , and the @xmath171 to the right of the right cluster .",
    "the joint assignment probability @xmath172 is at most @xmath173 , since two vertices can not both be at the center of a cluster . for each @xmath1 ,",
    "the sum indexed by @xmath2 then can be bounded , producing @xmath174 \\le y_m^2 ( p^{-2 } - 1)(3d+2)\\frac{1}{n } .\\end{aligned}\\ ] ]    this result tells us that it is possible to experimentally measure network effects on a cycle graph of very high degree @xmath45 with a variance that is only linear in @xmath45 , provided that the vertices are clustered in contiguous blocks of @xmath175 vertices .",
    "we now show how this strategy of bounding the variance applies to a much more general class of graphs , using a clustering algorithm that does not require knowledge of any geometric structure .",
    "we now begin developing the main result of this section , a cluster randomization scheme for the class of restricted - growth graphs .",
    "the first component is a clustering algorithm for such graphs in which each vertex is connected to at most a constant number of clusters , independent of the degree of the vertex .",
    "this will then imply that the variance on any restricted - growth graph can be upper bounded by a function linear in the degree .",
    "our clustering shows that the nice decomposition of the cycle by contiguous regions can be generalized to arbitrary graphs in our class . in other words ,",
    "the geometry is nt crucial ; the restricted - growth property is enough .",
    "consider a restricted - growth graph @xmath176 ; we will present the case in which @xmath51 is @xmath45-regular , but as we note below , the regularity can be relaxed to arbitrary degree distributions at the cost of a weaker but still constant bound on the number of connected clusters .",
    "recall that the restricted - growth condition says there exists @xmath20 so that for all @xmath19 and all @xmath129 , we have @xmath22 .",
    "importantly , @xmath177 is different : @xmath178 is the singleton set @xmath179 , while @xmath180 is the neighborhood of @xmath19 and hence has size @xmath175 .",
    "thus @xmath181 , potentially much larger than the bound of @xmath20 on the ratio @xmath182 for @xmath129 .",
    "this is the crux of the restricted - growth condition : from radius 0 to 1 we have unrestricted growth ( a factor of @xmath175 ) , but then the growth slows to factors of @xmath20 which can be bounded separately from @xmath45 .    in the language of metric spaces",
    ", we will cluster the graph using a _",
    "3-net _ for the shortest - path metric of @xmath51 @xcite .",
    "formally , in a metric space @xmath183 , an @xmath18-net @xmath184 is a collection of points that are mutually at distance at least @xmath18 from each other , but the union of all their @xmath18-balls covers the space , @xmath185 .",
    "accordingly , we call our construction a _ 3-net clustering _ of the graph . to build a 3-net clustering , we will iteratively identify vertices @xmath186 , ` marking ' vertices as we do this .",
    "afterwards we will identify clusters @xmath187 to go with these vertices .",
    "more explicitly , we perform the following procedure consisting of two principle stages :    * initially all vertices are unmarked . * while there are unmarked vertices , in step @xmath2 find an arbitrary unmarked vertex @xmath19 , selecting @xmath19 to be vertex @xmath188 and marking all vertices in @xmath189 .",
    "* suppose @xmath44 such vertices are defined , and let @xmath190 .",
    "* for every vertex @xmath191 of @xmath51 , assign @xmath191 to the closest vertex @xmath192 , breaking ties consistently ( e.g. in order of lowest index ) . * for every @xmath188 ,",
    "let @xmath193 be the set of all vertices assigned to @xmath188 .",
    "the sets @xmath194 are then our 3-net clustering .",
    "the key property of this clustering is the following result , which establishes that each vertex is connected to a number of clusters that can be bounded by a function of @xmath20 , independent of the degree .",
    "[ claim2 ] consider any 3-net clustering of a graph @xmath50 .",
    "for all @xmath195 , the neighborhood @xmath196 has a non - empty intersection with at most @xmath197 distinct clusters .",
    "we first claim that for all @xmath198 , we have @xmath199 .",
    "indeed , consider any vertex @xmath200 in @xmath193 .",
    "we have @xmath201 , since otherwise @xmath191 would belong to the cluster identified with itself .",
    "now , consider the iteration @xmath1 in which @xmath191 was marked ; we have @xmath202 .",
    "since @xmath203 and it is assigned to the closest vertex in @xmath204 , it follows that @xmath205 .",
    "thus @xmath199 .",
    "next , we claim that for all @xmath206 , the sets @xmath207 and @xmath208 are disjoint",
    ". suppose by way of contradiction that @xmath209 .",
    "it would follow that @xmath210 and vice versa .",
    "but then if we consider the vertex among @xmath211 and @xmath188 that was added to @xmath204 first , the other of @xmath211 or @xmath188 would have been marked in that iteration , and hence it could not have been added to @xmath204 as well .",
    "this contradiction establishes that @xmath207 and @xmath208 are disjoint .    to complete the proof ,",
    "suppose by way of contradiction that @xmath196 has a non - empty intersection with more than @xmath197 distinct clusters : for some @xmath212 , let @xmath213 be distinct vertices in @xmath196 and @xmath214 be distinct vertices in @xmath204 such that @xmath215 for @xmath216 .",
    "since @xmath217 , and @xmath218 contains a vertex adjacent to @xmath191 ( or contains @xmath191 itself ) , we have @xmath219 , and hence @xmath220 .",
    "the neighborhoods @xmath221 are all pairwise disjoint as argued above , and they are all contained in @xmath222 , which implies that @xmath223 . but applying the bounded growth inequality @xmath224 three times we have @xmath225 , a contradiction .",
    "this establishes that @xmath196 can have a non - empty intersection with at most @xmath197 distinct clusters .",
    "the above result is formulated for @xmath45-regular graphs .",
    "but in fact one can show a weaker bound depending only on @xmath20 as in proposition [ claim2 ] even for arbitrary restricted - growth graphs , without any requirement on the degrees .",
    "this weaker bound of @xmath226 can be established by observing that any restricted - growth graph exhibits a `` bounded gradient '' on the vertex degrees , whereby vertices that are near each other in the graph must have similar degrees .",
    "combining this fact with proof of proposition [ claim2 ] leads to the desired bound .",
    "we now apply the above results to bound the variance of the effect estimator @xmath227 . throughout this section",
    "we assume that all responses obey upper bounds and positive lower bounds , @xmath228 $ ] for both exposure to treatment and control , @xmath229 .",
    "the reason for the positive lower bounds is that without them the users could all be responding zero to all treatments , making the variance zero regardless of the treatment scheme .",
    "we also assume the randomization probability @xmath230 is not degenerate , i.e. @xmath73 .",
    "we present the results for @xmath45-regular graphs to keep expressions manageable , but analogous results can be derived for arbitrary degrees .",
    "we first establish an exponential lower bound for the variance under vertex - level randomization , and then we show a contrasting linear upper bound for the variance under our 3-net cluster randomization scheme .",
    "the variance of the ht estimator under full neighborhood exposure for vertex randomization of a graph with @xmath0 vertices is lower bounded by an exponential function in the degree @xmath45 of the graph , @xmath231 \\ge o(1/n ) ( p^{-(d+1)}+(1-p)^{-(d+1)}-1)$ ] .      for graphs with arbitrary degree distributions , this bound",
    "becomes @xmath238 \\ge o(1/n ) \\sum_{i=1}^n ( p^{-(d_i+1)}+(1-p)^{-(d_i+1)}-2 )   $ ] , which is exponential in the degree of each vertex , meaning that even a single high degree vertices can easily explode the variance .",
    "we now turn to our linear upper bound for growth - restricted graphs when using our 3-net clustering .",
    "the variance of the ht estimator under full , @xmath15-fractional , or @xmath44-absolute neighborhood exposure for a 3-net cluster randomization of a restricted - growth graph is upper bounded by a function linear in the degree @xmath45 of the graph .",
    "recall that the variance of the estimator is given by : @xmath239 we begin by upper bounding the variance of @xmath240 , and the upper bound for @xmath241 follows the same principle .",
    "we conclude by bounding the covariance term . by proposition [ claim2 ] , each vertex is connected to at most @xmath197 clusters .",
    "thus we have the lower bound @xmath242 , for both full and fractional neighborhood exposure .",
    "@xmath243 \\le \\frac{y_m^2}{n^2 }    \\bigg [ n(\\frac{1}{p^{\\kappa^3}}-1 ) +   \\sum_{i=1}^{n } \\sum_{\\substack{j=1 \\\\ j\\ne i}}^n ( \\frac { \\pi^1_{ij}}{\\pi^1_i \\pi^1_j } - 1 ) \\bigg ] .\\end{aligned}\\ ] ] for each vertex @xmath1 , the inner of the two sums is only nonzero at those vertices @xmath2 for which the assignments are dependent . if the assignments for @xmath1 and @xmath2 are dependent , then they must each have neighbors in the same cluster @xmath244 associated with a vertex @xmath245 in the set of cluster centers . since the proof of proposition [ claim2 ] established that @xmath246 , it follows that @xmath1 and @xmath2 are each within distance 3 of @xmath245 and hence within distance 6 of each other .",
    "thus , any @xmath2 whose assignment is dependent on @xmath1 s must lie within @xmath247 , and so by the restricted - growth condition , there can be at most @xmath248 such vertices @xmath2 .",
    "thus the sum over such @xmath2 has at most @xmath249 terms .",
    "also , @xmath250 applies , since the two vertices must depend on at least one cluster .",
    "we obtain @xmath243 \\le y_m^2    [ ( p^{-\\kappa^3}-1 ) +   \\kappa^5 ( d+1 ) ( p^{-2\\kappa^3 - 1 } - 1 )   ] \\frac{1}{n}.\\end{aligned}\\ ] ]    now , consider the contribution of the covariance term to the variance , @xmath251 , a positive quantity . starting from equation ( [ eq : covar ] ) , we apply the upper bound for the responses @xmath252 to obtain @xmath253   \\le - \\frac{2y_m^2}{n^2 }   \\sum_{i=1}^{n } \\sum_{\\substack{j=1 \\\\ j\\ne i}}^n \\left ( \\frac{\\pi_{ij}^{10}}{\\pi_i^1 \\pi_j^0 } - 1 \\right ) + \\frac{2y_m^2}{n}.\\end{aligned}\\ ] ] as with the previous analogous expression , for each @xmath1 the inner sum is non - zero for at most @xmath254 other vertices @xmath2 . for the remaining terms ,",
    "the quantity @xmath255 is trivially upper bounded by @xmath256 .",
    "thus we obtain @xmath257   \\le \\frac{2y_m^2}{n }   [ \\kappa^5(d+1 ) + 1].\\end{aligned}\\ ] ] combining the upper bounds , we obtain a total upper bound that is linear in degree , as desired .",
    "the restricted - growth condition we used was derived for regular graphs , but as we noted earlier , for restricted - growth graphs with arbitrary degree distributions we can apply a weaker but still constant bound on the cluster dependencies to obtain a variance bound that is still linear in the degree .",
    "the design of online experiments is a topic with many open directions ( see e.g. @xcite ) ; in this work we have focused on the open question of a / b testing when treatment effects can spill over along the links of an underlying social network .",
    "we introduced a basic framework for reasoning about this issue , as well as an algorithmic approach  graph cluster randomization  for designing a / b randomizations of a population when network spillover effects are anticipated .",
    "appropriate clustering can lead to reductions in variance that are exponential in the vertex degrees .",
    "we emphasize that beyond the class of graphs where we prove bounds , graph cluster randomization is a technique that can be applied to arbitrary graphs using arbitrary community detection or graph partitioning algorithms , though we do not provide any variance bound guarantees for these scenarios .",
    "there are many further directions for research suggested by the framework developed here .",
    "a first direction is to formulate a computationally tractable objective function for minimizing the variance of the horvitz - thompson estimator .",
    "one approach would be via minimizing an adversarial variance , as in @xcite .",
    "another problem that may be relevant is to find a clustering that minimizes a / a variance for full neighborhood exposure under the assumption of known control potential outcomes .",
    "can good clusterings for a / a variance lead to good solutions for a / b testing ?",
    "we note that a / a variance minimization would not be useful when the treatment is expected to be dominated by heterogeneous responses .    adding further structure to the potential treatment responses is another interesting direction .",
    "we currently have a discrete notion of network exposure to treatment and control , but one could ask about responses that depend continuously on the _ extent _ of exposure . as one simple example , we could consider a response that was linear in @xmath44 , when a vertex had @xmath44 exposed neighbors . how could we properly take advantage of such structure to get better estimates",
    "? methods for analyzing bias under network exposure condition misspecification would also be a natural addition to the framework .",
    "8 e.  airoldi , e.  kao , p.  toulis , d.  rubin . causal estimation of peer influence effects . in _",
    "icml _ , 2013 .",
    "p.  aronow and c.  samii .",
    "estimating average causal effects under general interference . ,",
    "september 2012 .",
    "b.  bollobs . .",
    "cambridge univ . press , 2001 .",
    "d.  cellai , a.  lawlor , k.  dawson , j.  gleeson .",
    "critical phenomena in heterogeneous k - core percolation . , 87(2):022134 , 2013 .",
    "s.  fienberg .",
    "a brief history of statistical models for network analysis and open challenges . , 2012 .",
    "s.  fortunato .",
    "community detection in graphs .",
    ", 486(3):75174 , 2010 .",
    "d.  horvitz , d.  thompson .",
    "a generalization of sampling without replacement from a finite universe .",
    ", 1952 d. karger , m.  ruhl .",
    "finding nearest neighbors in growth - restricted metrics . in _ stoc _ , 2002 .",
    "l.  katzir , e.  liberty , o.  somekh .",
    "framework and algorithms for network bucket testing . in _",
    "www _ , 2012 .",
    "r.  kohavi , a.  deng , b.  frasca , r.  longbotham , t.  walker , y.  xu .",
    "trustworthy online controlled experiments : five puzzling outcomes explained . in _",
    "kdd _ , 2012 . c.  manski .",
    "identification of treatment response with social interactions .",
    ", 16(1):s1s23 , 2013 .",
    "d.  rubin . estimating causal effects of treatments in randomized and nonrandomized studies . , 1974 .",
    "e.  tchetgen , t.  vanderweele . on causal inference in the presence of interference . , 2012 .",
    "j.  ugander , l.  backstrom .",
    "balanced label propagation for partitioning massive graphs . in _ wsdm _ , 2013 ."
  ],
  "abstract_text": [
    "<S> a / b testing is a standard approach for evaluating the effect of online experiments ; the goal is to estimate the ` average treatment effect ' of a new feature or condition by exposing a sample of the overall population to it . </S>",
    "<S> a drawback with a / b testing is that it is poorly suited for experiments involving social interference , when the treatment of individuals spills over to neighboring individuals along an underlying social network . in this work , </S>",
    "<S> we propose a novel methodology using graph clustering to analyze average treatment effects under social interference . to begin , we characterize graph - theoretic conditions under which individuals can be considered to be ` network exposed ' to an experiment . </S>",
    "<S> we then show how graph cluster randomization admits an efficient exact algorithm to compute the probabilities for each vertex being network exposed under several of these exposure conditions . using these probabilities as inverse weights , a horvitz - thompson estimator </S>",
    "<S> can then provide an effect estimate that is unbiased , provided that the exposure model has been properly specified .    </S>",
    "<S> given an estimator that is unbiased , we focus on minimizing the variance . </S>",
    "<S> first , we develop simple sufficient conditions for the variance of the estimator to be asymptotically small in @xmath0 , the size of the graph </S>",
    "<S> . however , for general randomization schemes , this variance can be _ lower bounded _ by an _ </S>",
    "<S> exponential _ function of the degrees of a graph . </S>",
    "<S> in contrast , we show that if a graph satisfies a _ restricted - growth condition _ on the growth rate of neighborhoods , then there exists a natural clustering algorithm , based on vertex neighborhoods , for which the variance of the estimator can be _ upper bounded _ by a _ linear _ </S>",
    "<S> function of the degrees . </S>",
    "<S> thus we show that proper cluster randomization can lead to exponentially lower estimator variance when experimentally measuring average treatment effects under interference . </S>"
  ]
}