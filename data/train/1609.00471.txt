{
  "article_text": [
    "turbulence is governed by the nonlinear equations of fluid dynamics , but those equations are too complex to be solved analytically .",
    "an understanding of the behavior of turbulent flows is better approached using statistical ideas , while also taking into account the few exact results derived by considering isotropic , homogeneous and incompressible turbulence @xcite . in all cases",
    "one must invoke statistical averaging , even if the starting point is the navier - stokes equations themselves .    in this study statistics and probabilities alone appear ; the underlying equations of fluid dynamics do not enter at all .",
    "although a probabilistic approach is taken , it is clear that `` ... turbulent does not mean random .",
    "the complex motion of the fluid contains characteristic patterns , events and structures that show through all the randomness '' @xcite .",
    "our aim is to unveil this structure of turbulence using tools from information theory @xcite .",
    "nevertheless one obtains results that are consistent with those deduced using the traditional approach .",
    "these include the existence of a cascade , implying the correlation between eddies of differing sizes .",
    "let the velocity of the fluid @xmath0 be a random variable and @xmath1 be one of its possible values .",
    "for simplicity of discussion we consider only a single component .",
    "there is an associated probability density function @xmath2 , which is determined experimentally by counting occurrences . instead of the velocity we could also consider the vorticity measured at a point or a velocity difference measured between two nearby points in a homogeneous fluid .",
    "it will be assumed that the turbulent fluid is in a steady state , making the absolute observation time @xmath3 of little interest .",
    "once @xmath2 is in hand , we could proceed to calculate such quantities as the velocity moments @xmath4 .",
    "when @xmath1 is replaced with the velocity difference over a scale @xmath5 : @xmath6 , these moments are called the structure functions @xcite .",
    "they play an important role in turbulence theory , with particular prominence given to kolmgorov s famous exact solution @xmath7 , where @xmath8 is the energy injection rate @xcite .    instead of moving in this traditional direction ,",
    "we proceed in another .",
    "we ask what the probability density function itself has to say .",
    "completely random systems have flat distributions , where all possible values have equal weight : @xmath9 constant . in the other extreme ,",
    "the distribution is a delta function @xmath10 , with only one possible value @xmath11 .",
    "this latter scenario corresponds to the ideal laminar state with no fluctuations .",
    "the former case is not seen even when the flow is turbulent , because constraints on the energy of the flow force it to be closer to gaussian .",
    "now we ask whether there is a way to make this description more quantitative .    at the center of information theory",
    "is a quantitative measure of the  broadness \" of probability distributions @xcite .",
    "shannon called this the entropy , apocryphally encouraged to do so by von neumann because he could safely hide inside the confusion this term evokes in the physics community @xcite .",
    "the most basic form of the entropy , which we shall later revise , is simply @xmath12 where @xmath13 can be thought of as a measure of surprise at observing any particular @xmath1 .",
    "the form of eq .",
    "[ eq : h ] is the same as for the energy states in , @xmath14 the canonical ensemble of statistical mechanics @xcite .",
    "the astute reader will notice we have used a sum @xmath15 instead of an integral @xmath16 .",
    "shannon s original work was on messages with discrete variables ( like the letters in the english language ) , and while there is a generalization to continuous variables @xcite , we will switch to the discrete form here .",
    "( the discretization of continuous variables needs to be done carefully , and we leave this issue for later . )    clearly @xmath17 is large when @xmath2 is broad and small if it is narrow .",
    "large uncertainty means large @xmath17 . if we are measuring the velocity @xmath1 in a laboratory and adopt the interpretation that the readout on our instrument is the fluid system s  message \" to us , then @xmath17 is the amount information we obtain from our measurement .",
    "we are told nothing new by repeatedly making measurements of laminar flow , since it never changes , but we are always getting new information from turbulent flow .",
    "r. s. shaw was the first to recognize this information production as a general feature of chaotic systems @xcite .",
    "an analogous observation outside of fluid dynamics is an image taken from a newspaper .",
    "the image is created by varying the local density of black dots of ink . just as some images are characterized by wild variations in paint color ( a jackson pollock painting is a good example ) ,",
    "others , such as many mondrian paintings , show small variations , and have simple geometrical forms .",
    "the information or @xmath18 is larger in the first of these . it is closer to high reynolds number flows and the mondrian painting is akin to flow at moderate or low reynolds number .",
    "this visual link is displayed in a juxtaposition of these paintings with the velocity field in a pipe in fig .",
    "[ pollock ] .    if information theory s utility were limited to the above quantification of uncertainty through @xmath18 , it would indeed be of limited use . however , @xmath18 is the basis for extracting other quantities , like the mutual ( or shared ) information @xmath19 between two quantities @xmath20 and @xmath21 @xcite .",
    "these quantities will be introduced in the forthcoming examples as the need arises .",
    "the emphasis here is on the application of these tools to real data taken in the laboratory or calculated on a computer .",
    "we turn first to demonstrating experimentally the assertion made earlier about the entropy of laminar and turbulent flow .",
    "we perform measurements of the axial velocity @xmath1 at the centerline of a long ( @xmath22 cm ) , cylindrical pipe as a function of time using a dantec laser doppler velocimeter ( ldv ) and hollow glass , silver - coated 10 @xmath23 m particles for scattering .",
    "the reynolds number here is defined as @xmath24 , where @xmath0 is the cross - sectionally averaged velocity , and @xmath25 cm is the diameter , with @xmath26 the kinematic viscosity of water .",
    "a schematic of the setup is shown in fig .",
    "[ pipe_setup ] . in pipes , as in many other shear flows , the system can in principle remain laminar to infinite @xmath27 @xcite .",
    "however , turbulence can be triggered by a finite perturbation , such as an obstacle .",
    "doing so results in an intermittent time series of turbulent and laminar patches @xcite .",
    "[ slug ] shows an interval of time when the flow at a point is transitioning between the two states .",
    "the higher value is the laminar state and the lower is the turbulent .",
    "the pdfs to the right of the time series confirm that even the laminar flow has some fluctuations ( either instrumental or from the setup ) , although they are smaller than the turbulent ones .",
    "while the entropy is theoretically zero for laminar flow , since there is only one value of the velocity , the presence of noise hinders a direct experimental confirmation of this .",
    "we begin by determining @xmath2 . binning data to make a histogram of inevitably finite experimental or numerical data is a familiar procedure . in fig .",
    "[ slug ] , very fine bin sizes were used so that to the naked eye the curve looks continuous .",
    "there is no problem using these same bin sizes for calculating @xmath17 , but it should not come as a surprise that the bin size choice affects @xmath17 .",
    "figure [ partition ] shows how this binning works .",
    "calling @xmath8 the bin size , a continuous stream of data is converted to discrete data or symbols , each representing a range of values . if @xmath8 is small , then the number of symbols , the alphabet size , @xmath28 is large and vice - versa . to be examined is the effect of varying @xmath8 on the pdf , and hence @xmath18 .",
    "figure [ pdfs ] shows @xmath1 for several values of @xmath8 .",
    "the general shape is the same , but the gaussian character is not clear but for small @xmath8 .    what value of @xmath8 should be used ?",
    "this is not an easy question to answer .",
    "it is tempting to try the limit @xmath29 , as is done when calculating @xmath14 the kolmogorov - sinai entropy @xcite , but it should be clear that this is not an option for real data .",
    "an additional complication is noise , as highlighted by the laminar portion of fig .",
    "if @xmath8 is below the noise , one gets a different value from the theoretical @xmath30 .",
    "it turns out that it may not matter , depending on the question one is trying to answer .",
    "arbitrarily , we choose @xmath31 , the standard deviation for the laminar noise and the turbulent slugs respectively ( separately ) and proceed to see how information theory can distinguish between the two .",
    "this corresponds to the coarsest pdf in fig .",
    "if we use a different @xmath8 , the results are qualitatively the same .",
    "the pdfs of both of the noisy laminar data and the turbulent data are nearly gaussian and will nearly collapse when normalized @xmath32 . as a result ,",
    "the two values of @xmath18 are nearly identical .",
    "true noise ( often called shot noise @xcite ) is uncorrelated with itself at all finite lag times .",
    "an even stronger statement is to say that it is statistically independent of itself at different times .",
    "we can take advantage of this fact by considering finite blocks of the velocity time series : @xmath33 $ ] , where @xmath34 is the inverse mean sampling rate of the ldv .",
    "the probabilities of these blocks directly relate to the inter - relationships between its members .",
    "consider the so - called block entropy @xcite : @xmath35 if there is no statistical dependence between any of the data points inside the blocks ( no correlations ) then @xmath36 . by an application of jensen s inequality @xcite ,",
    "this is the maximum value : @xmath37 .",
    "it is lowered by any statistical dependence between the @xmath0 s inside of @xmath38 , @xmath39 temporal or spatial correlations .",
    "this observation can be exploited to distinguish the shot noise , seen even in laminar flows .",
    "the above definition is applied to @xmath40 for laminar and turbulent data from the pipe measurements .",
    "it is divided by @xmath41 , so that if the data is truly random , it will return to the value @xmath42 .",
    "as expected , the random noise in the laminar flow has no correlations , so it is hardly reduced at all by this division , while the correlations inherent in the kolmogorov picture of turbulence @xcite reduce the entropy for the turbulent flow , as shown in fig .",
    "[ slug_h ] .",
    "it is instructive to examine how @xmath40 depends on @xmath41 .",
    "this function is not well - behaved at very large @xmath41 .",
    "let @xmath43 be the total number of velocity data points in a typical run ( typically , @xmath43 is of order @xmath44 . )",
    "when the number @xmath45 is too small , there are too few blocks to determine the occurrence probabilities needed to evaluate @xmath40 , resulting in the data appearing to be _ less _ random than it really is . this effect is compounded if velocities are correlated , as in turbulence , where the correlation length can be large and a large @xmath41 is needed to capture the physics .",
    "figure [ slug_h ] , shows @xmath46 @xmath47 @xmath41 for the turbulent fluctuations in slugs and the shot noise in the laminar flow .",
    "the laminar measurements show a dependence on @xmath41 for the physically uninteresting reason described above that the data are not collected for a long enough time interval to accurately measure probabilities appearing in @xmath40 .",
    "this same phenomenon plagues the slug curve , and so researchers typically identify the inflection point as being important @xcite",
    ". if @xmath46 did not drop off , it would remain constant and this limit is called the entropy rate or density @xcite : @xmath48 there are three equivalent ways to define @xmath49 .",
    "the first is described above , and the second is @xmath50 while the third is @xmath51 here @xmath52 is the conditional entropy ( @xmath20 conditioned on @xmath21 )",
    ". the entropy density converges to a finite value because less and less information is gained on increasing @xmath41 by one unit .",
    "the utility of @xmath49 in elucidating turbulence will be explored further in the soap film experiments to be described next .",
    "the gravity - driven soap film is a mixture of soap detergent and water , with small density - matched glass spheres added for the velocity measurements . fig .",
    "[ setup ] is a diagram of the experimental setup .",
    "a laser doppler velocimeter ( ldv ) is used to measure the velocity components in the streamwise @xmath1 direction . by adjusting the flow rate and the channel width , several decades of reynolds number @xmath27",
    "can be explored .",
    "here @xmath53 , where @xmath54 is the rms velocity and @xmath55 is the channel width . for more experimental details ,",
    "we refer the reader to ref .",
    "@xcite .    using eq .",
    "[ entropydensity ] , we go on to calculate the entropy rate for turbulence in a soap film . here , depending on the forcing , three entirely different kinds of behavior can be generated .",
    "if the soap film travels between rough walls , the perturbation they steadily create an inverse cascade of energy from smaller to larger eddies @xcite .",
    "if , instead , the film is penetrated by a comb , a row of @xmath56 1 mm rods , a different type of cascade is created ; the rods create vortices which cascade downscale to the smallest sustainable size : the direct enstrophy cascade @xcite .",
    "the accompanying energy spectra @xmath57 are as seen in fig .",
    "[ spectra ] . here",
    "@xmath58 is wavenumber in inverse cm and @xmath57 has units of kinetic energy per kg per unit wave number .",
    "a final case is when the perturbations of the comb are too weak to initiate a cascade at all , resulting in a flat @xmath57 .    besides @xmath49 ,",
    "another quantity is also plotted in fig .",
    "this is an alternative method for estimating the information and in the limit of infinite data the two coincide .",
    "computer memory is necessarily limited , making it useful to store and transmit information in as compact a form as possible .",
    "the total amount of memory necessary to send or store a message can be shortened by ( re-)coding the words to minimize their length .",
    "one example is using a coding scheme that assigns a small number symbols to words that appear with high frequency , as in morse code where @xmath59 is coded with the shortest symbol , a dot. in turbulence the probability distribution like in fig .",
    "[ pdfs ] suggests something similar might be done .",
    "remarkably , shannon proved that the limit on @xmath60 compression scheme is given by the entropy of the message @xcite .",
    "if the original length or size of a message is @xmath61 , then after the compression algorithm does its work , the new size @xmath62 satisfies the inequality @xmath63 while shannon provided no hints as to how equality might be approached , substantial work has been done in his wake to satisfy the equality in the limit @xmath64 .",
    "these coding schemes are called optimal , an example being the lempel - ziv algorithm @xcite . as expected , the compression ratio @xmath65 in fig .",
    "[ h_l ] is equal to or greater than @xmath49 ; it should not be smaller . binarizing the data gives a rough description , so it is not surprising that the difference between @xmath65 and @xmath49 is revealed only when the data is segmented into ten values .",
    "why does @xmath49 decrease as @xmath27 increases ? presumably this because increasing the strength of the turbulence increases the correlations between different spatial scales , and correlations always @xmath66 the surprise element in all observations @xcite . but a puzzle remains : when @xmath27 is decreased sufficiently , the flow must become laminar , in which case @xmath49=0",
    ". therefore @xmath49 must go through a maximum - at a value that these experiments can not measure .    a strange prediction",
    "is suggested by fig .",
    "[ h_l ] . if we treat @xmath67 as a state function in thermodynamics , then changing @xmath27 simply moves the system along this unique curve .",
    "consider the case of decaying turbulence , as with a comb in a soap film . near the comb the flow exhibits the enstrophy cascade and @xmath27 as defined here",
    "measurements made progressively further away from the comb have a lower energy due to the decay , and so a lower @xmath27 . at the same time",
    ", @xmath49 will increase until there is a transition , apparently continuous with respect to @xmath49 , from an enstrophy cascade to an inverse energy cascade .",
    "this remarkable transition has , in fact , been observed in soap films , although the mechanism has been attributed to wall shear effects @xcite .",
    "to further illustrate some of the tools of information theory in practice , we turn to a toy model of turbulence designed to mimic the essential properties of turbulence .",
    "the gledzer - ohkitani - yamada ( goy ) shell model is the simplest model with a cascade of energy @xcite , but it still yields to theoretical analysis and can easily be numerically integrated even on a laptop computer . herein lies its utility . as long as its limits are kept in mind , the goy model can be a useful playground for new ideas that can later be applied to full - blown navier - stokes turbulence .",
    "this approach has led to the discovery of intermittency in the helicity cascade of 3d turbulence @xcite .",
    "as kadanoff quipped , `` models are fun , and sometimes even instructive '' @xcite .    in the goy model ,",
    "each variable ( shell ) corresponds to velocity fluctuations on a different spatial scale .",
    "these shells , however , live in fourier space , and so the independent variable is the wavenumber @xmath58 .",
    "( this is also why the velocity of the shells are complex ) .",
    "it is useful to think of this model as a truncation of the navier - stokes equation in fourier space .",
    "there are a finite number ( @xmath68 ) of shells and we denote by @xmath69 any particular shell ( from 1 to @xmath68 ) .",
    "following custom , @xmath68 is set to 22 @xcite .",
    "the wavenumbers @xmath70 are picked to be a fixed logarithmic distance apart : @xmath71 , where here @xmath72 and @xmath73 .",
    "large @xmath69 corresponds to small scales , while small @xmath69 refers to large scales .",
    "the governing set of equations is @xmath74 where @xmath75 is the forcing , @xmath76 , and @xmath77 denotes the complex conjugate",
    ". the variables @xmath78 , @xmath79 and @xmath80 are shell dependent but constant in time .",
    "these determine the strength of energy flow between scales .",
    "we refer the reader to the accessible review by kadanoff @xcite or the detailed review by biferale @xcite for more particulars . following the numerical scheme outlined in ref .",
    "@xcite , the viscosities are assigned the values @xmath81 , @xmath82 , @xmath83 , where the reynolds number @xmath84 .",
    "the equations are integrated using matlab .",
    "the energy spectra are shown below in fig .",
    "[ goy_spectra ] .",
    "as the viscosity decreases ( @xmath27 increases ) , the kolmogorov -5/3 scaling is present at higher and higher wavenumbers .    what sort of questions can be address with the tools of information theory ?",
    "consider one of the most fundamental concepts in turbulence phenomenology , the universality of small scales . in the traditional picture of the turbulent cascade",
    ", energy is injected at some large scale and then transferred to smaller and smaller scales . in order for the scaling of the velocity differences to depend only on the local scale @xmath85 and the energy injection rate",
    ", it must `` forget '' about the large scales . or , as kadanoff puts it",
    ", the system remembers as little as it possibly can about the conditions at which energy is added or dissipated @xcite .",
    "this forgetfulness is readily quantified using information theory , in particular through the mutual information .",
    "if one scale forgets about the other , then the mutual information between them will be small ( identically zero if statistically independent ) : @xmath86 where @xmath87 is the energy at @xmath58 and @xmath88 is the spacing between adjacent shells .",
    "figure [ forcing_mutinfo ] is a plot the instantaneous mutual information between the energy each scale and at the forcing scale ( @xmath69 = 4 shell ) .",
    "apart from the peak at @xmath69 = 4 , where the mutual information is now equal to the self - information ( the entropy ) , the shared information falls off algebraically as -1/4 until the dissipative scales are reached .",
    "thus the inertial scales do not completely forget the details of the forcing , although the shared information becomes very small .",
    "indeed , the goy model is well known to exhibit the same intermittency phenomenon ( deviations from kolmogorov and violations of the universality assumption ) as fluid turbulence @xcite .",
    "while the entropy plays the most fundamental role , that of a measure , in shannon s information theory , it is the mutual information that has proved the most useful in the field of communications . in any causal physical relationship , or interaction , one system or subsystem",
    "will exchange with another not only energy or momentum but also information .",
    "( indeed , it is well known that the speed of light restriction of special relativity is most properly formulated in terms of information transfer , albeit not explicitly in the shannon sense . )",
    "it is reasonable to consider whether the cascade may also be a communication channel .",
    "to do so , let us now consider the local transfer of information between adjacent shells using the mutual information . since the information source , just like the energy , must be at the forcing scale , we expect information to flow downscale .",
    "however , it is well known that there is `` backscatter '' of energy ( enstrophy ) even in the 3d energy ( 2d enstrophy ) cascade . with this in mind , we also consider the transfer of information upscale , as done in @xcite .",
    "the cascade is a dynamical process .",
    "an amount of energy at a wavenumber @xmath58 at time @xmath3 is transferred to wavenumber @xmath89 in a time @xmath34 . to reflect this ,",
    "we introduce a time lag into the mutual information . a large shell (  eddy \" ) at an arbitrary time @xmath3 will share information forward in time to a small shell , so @xmath90 will be large if information is going downscale , whereas the following will be large if information is going upscale @xmath91 the use of this time lag is similar to its use in @xcite . subtracting the transfer upscale from that downscale , in fig .",
    "[ info_transfer ] we indeed find a net downscale transfer that is positive only in the inertial range and increases in magnitude as @xmath27 increases .",
    "thus there exists a companion information cascade along with the energy cascade in the goy model",
    ". it would be interesting to determine if the same is true for 3d and 2d turbulence .",
    "the presence of an information flux is not only related to intermittency , but suggests a further useful constraint on the physics of turbulence .",
    "while information theory was created to characterize messages coded in the form of words , it applies equally well to experimental observations in which the words of a text are replaced by measured quantities . in this work ,",
    "information is applied to three - dimensional turbulent flow in a long pipe , to two - dimensional turbulence in a gravity - driven soap film , and to a mathematical model that takes into account the turbulent cascade of energy from larger to smaller eddy sizes .",
    "the goal of the work is to demonstrate that information theory can illuminate physical observations , even when the equations governing the system s behavior are intractable or may not even be known . in this study",
    ", no appeal is made to the navier - stokes equations , which govern the fluid flows under observation .",
    "even when true velocity fluctuations are absent , as in laminar flows , shot noise ( also called poisson noise ) , can appear as a confounding effect .",
    "the goal of the work is to introduce the reader to the information theory approach , and to demonstrate its usefulness .",
    "durst , f. , nsal , b. : forced laminar - to - turbulent transition of pipe flows .",
    ". mech . * 560 * , 449 - 464 ( 2006 ) mullin , t. : experimental studies of transition to turbulence in a pipe .",
    "* 43*(1 ) , 1 - 24 ( 2011 ) frigg , r. : brit .",
    "sci . * 55 * , 411 ( 2004 )            adrian , r.j .",
    ", yao , c.s .",
    ": power spectra of fluid velocities measured by laser doppler velocimetry .",
    "fl . * 5*(1 ) , 17 - 28 ( 1986 ) schrmann , t. , grassberger , p. : entropy estimation of symbol sequences . chaos * 6*(3 ) , 414 - 415 ( 1996 ) ziv , j. , lempel , a. : compression of individual sequences via variable - rate coding .",
    "ieee trans .",
    "* 24 * , 530 ( 1978 )          chen , q. , chen , s. , eyink , g.l . ,",
    "holm , d.d .",
    ": intermittency in the joint cascade of energy and helicity .",
    "lett . * 90*(21 ) , 214503 ( 2003 ) materassi , m. , consolini , g. , smith , n. , de marco , r. : information theory analysis of cascading process in a synthetic model of fluid turbulence .",
    "entropy * 16 * , 1272 - 1286 ( 2014 )    kadanoff , l. , lohse , d. , wang , j. , benzi , r. : scaling and dissipation in the goy shell model .",
    "phys . fl . * 7*(3 ) , 617 - 629 ( 1995 ) biferale , l. : shell models of energy cascade in turbulence .",
    ". mech . * 35*(1 ) , 441 - 468 ( 2003 ) vastano , j.a . ,",
    "swinney , h.l . : information transport in spatiotemporal systems .",
    "lett . * 60 * , 1773 - 1776 ( 1988 )"
  ],
  "abstract_text": [
    "<S> a message of any sort can be regarded as a source of information . </S>",
    "<S> claude . </S>",
    "<S> e. shannon showed in the last century that information ( `` what we do nt already know '' @xcite ) is equivalent to the entropy as defined in statistical mechanics @xcite . </S>",
    "<S> a string of experimental observations is like a succession of words ; they both convey information and can be characterized by their entropy . for the fluid flow measurements and simulations to be discussed here ( pipe and soap film flow , goy model ) , </S>",
    "<S> the entropy depends on controllable parameters such as the reynolds number . </S>",
    "<S> the information theory approach is applicable to measurements of any type including those governed by intractable equations or systems where the governing equations are not known . </S>",
    "<S> this contribution is dedicated to the memory of leo kadanoff , an inspiring teacher and one of the most important scientific leaders of the last half century . </S>"
  ]
}