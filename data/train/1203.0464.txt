{
  "article_text": [
    "sequential monte carlo ( smc ) methods are a generic class of simulation - based algorithms to sample approximately from any sequence of probability distributions .",
    "these methods are now extensively used in engineering , statistics and physics ; see @xcite for many applications .",
    "sequential monte carlo  methods approximate the target probability distributions of interest by a large number of random samples , termed particles , which evolve over time according to a combination of importance sampling and resampling steps .    in the resampling steps , new particles are sampled with replacement from a weighted empirical measure associated to the current particles ; see section [ adaptsec ] for more details .",
    "these resampling steps are crucial and , without them , it is impossible to obtain time uniform convergence results for smc  estimates .",
    "however , resampling too often has a  negative effect as it decreases the number of distinct particles .",
    "hence , a resampling step should only be applied when necessary .",
    "consequently , in most practical implementations of smc , the times at which resampling occurs are selected by monitoring a criterion that assesses the quality of the current particle approximation .",
    "whenever this criterion is above or below a given threshold , a resampling step is triggered .",
    "this approach was originally proposed in @xcite and has been widely adopted ever since @xcite , section  7.3.2 .    for this class of adaptive smc  methods ,",
    "the resampling times are computed online using our current smc approximation and thus are random . however , most of the theoretical results on smc algorithms assume resampling occurs at deterministic times ; see  @xcite for an exception discussed later .",
    "the objective of this paper is to provide convergence results for this type of adaptive smc  algorithm .",
    "this is achieved using a coupling argument . under some assumptions ,",
    "the random resampling times converge almost surely as the number of particles goes to infinity toward some deterministic ( but not explicitly known ) resampling times .",
    "we show here that the difference , in probability , between the reference smc algorithm based on these deterministic but unknown resampling times and the adaptive smcalgorithm is exponentially small in the number of particles .",
    "this allows us to straightforwardly transfer the convergence results of the reference smcalgorithm to the adaptive smc  algorithm .",
    "in particular , we establish functional central limit theorems and new exponential concentration estimates that improve over those presented in @xcite , section 7.4.3 .",
    "note that some exponential concentration estimates have also been established in @xcite , theorem 9.4.12 , using different techniques and a weaker assumption .",
    "the constants appearing in cappe2005 , theorem 9.4.12 , are not explicit so the comparison between these two results is difficult . in a specific example",
    ", we found our bound to be significantly tighter but have not established it in a general case .",
    "the rest of the paper is organized as follows . in section sec : mainresult , we present the class of adaptive smc  algorithms studied here and our main coupling result . a  precise description of the sequence of distributions approximated by the reference smc  algorithm is given in section  [ dmosec ] and a theoretical analysis of the reference smcalgorithm is presented in section  [ adpative ] . in particular , we propose an original concentration analysis to obtain exponential estimates for smcapproximations .",
    "these results are used to obtain a concentration result for the empirical criteria around their limiting values .",
    "the results above are used , in section [ asymptsec ] , to bound the differences between the deterministic resampling times and their empirical approximations , up to an event with an exponentially small probability .",
    "finally , we analyze the fluctuations of adaptive smc algorithms in section [ functtclsec ] .",
    "let @xmath0 , @xmath1 and @xmath2 denote , respectively , the set of bounded and signed measures , the subset of all probability measures on some measurable space @xmath3 and the banach space of all bounded and measurable functions @xmath4 on @xmath5 when equipped with norm @xmath6 .",
    "@xmath7 is the set of @xmath8-measurable functions @xmath4 with oscillations @xmath9 .",
    "@xmath10 is the integral of a  function @xmath11 , w.r.t .",
    "a measure @xmath12 .",
    "@xmath13 with @xmath14 and @xmath15 the indicator of @xmath16 .",
    "@xmath17 is the dirac measure . a bounded integral operator @xmath18 from a  measurable space @xmath3 into another @xmath19 is an operator @xmath20 from @xmath21 into  @xmath2 such that the functions @xmath22 are measurable and bounded for any @xmath23 .",
    "a bounded integral operator @xmath18 from @xmath3 into @xmath19 also generates a  dual operator @xmath24 from @xmath0 into @xmath25 defined by @xmath26 .",
    "if constants are written with an argument , then they depend only on this given argument .",
    "the tensor product of functions is written @xmath27 . for any generic sequence @xmath28",
    ", we denote @xmath29 for @xmath30 .",
    "smc methods are a popular class of methods for sampling random variables distributed approximately according to the feynman ",
    "kac path measures @xmath31 where @xmath32 is a markov chain on @xmath33 with transition kernels @xmath34 , @xmath35 is a sequence of non - negative potential functions on @xmath36and the importance weight function is defined by @xmath37    the basic smc  method proceeds as follows . given @xmath38 particles distributed approximately according to @xmath39 , these particles first evolve according to the transition kernel  @xmath40 . in a second stage ,",
    "particles with low relative @xmath41-potential value are killed and those with a larger relative potential are duplicated . however , as noted in section sec : intro , resampling at each time step is wasteful and should only be performed when necessary .",
    "this has motivated researchers to introduce new resampling strategies where the resampling step is only triggered when a criterion is satisfied ; this is typically computed via the current particle approximation ( see section sec : adaptivecriteria ) .",
    "such adaptive smc  algorithms proceed as follows .",
    "let @xmath42 denote the @xmath43th resampling time of the adaptive smc  algorithm .",
    "after the @xmath43th resampling step , assume we have the following empirical measure approximation of @xmath44 denoted @xmath45 where @xmath46 .",
    "we propagate forward these @xmath38 paths by generating @xmath47 according to the transition kernel @xmath48 of the reference markov chain initialized at @xmath49 , up to the first time ( @xmath50 ) the importance weights of the @xmath38 path samples given by @xmath51 become , in some sense , degenerate .    at time @xmath50 the weighted occupation measure of the system @xmath52 is a particle approximation of @xmath53 where @xmath54 . after the resampling step ,",
    "this measure is replaced by an empirical measure @xmath55 associated with @xmath38 path particles @xmath56 that are resampled from @xmath57 ; see , for example , @xcite for alternative resampling schemes .",
    "[ sec : adaptivecriteria ]    two well - known criteria used in the smc  literature to trigger the resampling mechanism are now discussed . in both cases ,",
    "the resampling times @xmath58 are random variables that depend on the current smc  approximation .",
    "@xmath59 _ squared coefficient of variation_. after the resampling step at time @xmath42 , the particles explore the state space up to the first time @xmath60 ) the squared coefficient of variation of the unnormalized weights is larger than some prescribed threshold @xmath61 @xmath62 this is equivalent to resampling when the effective sample size ( ess ) , defined as @xmath63 , is below a prescribed threshold as proposed in @xcite .",
    "@xmath59 _ entropy_. after the resampling step at time @xmath42 , the particles explore the state space up to the first time @xmath60 ) the relative entropy of the empirical particle measure w.r.t .",
    "its weighted version is larger than some threshold @xmath61 @xmath64      the following section provides a guide of the major definitions and results in this paper ; these will be repeated at the relevant stages in the paper .",
    "[ sec : limiting ]    let @xmath65 be the deterministic sequence of time steps obtained by replacing the empirical criteria @xmath66 by their limiting values @xmath67 as @xmath68 , that is , @xmath69 in all situations , set @xmath70 . for the criterion ( [ eq : empiricalvariance ] ) , the limiting criterion @xmath67 is given by @xmath71 whereas for ( [ eq : empiricalentropy ] ) it is given by @xmath72 here , @xmath73 is the expectation w.r.t .",
    "the law @xmath74 of the random path of variables that starts at time @xmath75 at the end point @xmath76 of @xmath77 distributed according to  @xmath78 and evolves according to the markov kernels @xmath79 . in @xcite , the limiting expression for the normalized effective sample size",
    "@xmath80 has been established .",
    "an alternative entropy criterion has also been proposed that can be applied when the potential functions  @xmath35 are not strictly positive on @xmath81 .",
    "we give our main results , which hold under the following regularity condition : @xmath82 we refer the reader to @xcite , chapter 3 , for a thorough discussion in the case where @xmath83 does not apply . to state our results",
    ", we first require the following definition .",
    "let @xmath84 and @xmath85 denote the @xmath38 particles associated to the adaptive smc  algorithm resampling at times @xmath86 and let @xmath87 and @xmath88 denote the @xmath38 particles associated to the reference smc  algorithm resampling at times @xmath89 .",
    "we also suppose that @xmath90 and @xmath91 coincide on every time interval @xmath92 , once @xmath93 , for every @xmath92 .",
    "this condition corresponds to the coupling of the two processes on the event @xmath94 .",
    "the first result is a non - asymptotic exponential concentration estimate .",
    "the probability measures @xmath95 and @xmath96 are introduced below .",
    "they can be thought of as analogues of  @xmath97 and @xmath98 ; see section [ dmosec ] for formal definitions .    [ theo2 ] for any @xmath99 , @xmath100 , any @xmath101 and any @xmath102 , there exist @xmath103 , @xmath104 such that we have the exponential concentration estimate @xmath105 ( f_{n } ) \\vert\\geq\\epsilon \\bigr ) \\leq c_{1}\\exp\\{-{n\\epsilon^{2}}/{c_{2}(n)}\\}\\vadjust{\\goodbreak}\\ ] ] for the empirical measures @xmath106 in addition , under appropriate regularity conditions on @xmath107 and @xmath108 given in section [ introconcc ] the above estimates are valid for the marginal measures associated to the time parameters @xmath109 for some constant @xmath110 .",
    "the second result is an exponential coupling theorem .",
    "[ theo1 ] assume the threshold parameters @xmath111 are sampled realizations of a collection of absolutely continuous random variables @xmath112 .",
    "then , for almost every realization of the sequence @xmath113 , @xmath114 and @xmath115 are such that , for every @xmath116 and any @xmath101 , there exist @xmath117 and almost surely @xmath118 such that @xmath119    up to an event having an exponentially small occurrence probability , theorem [ theo1 ] allows us to transfer many estimates of the reference smc algorithm @xmath120 resampling at deterministic times to the adaptive smc  algorithm @xmath115 .",
    "the proofs of theorems  [ theo2 ] and  [ theo1 ] are detailed , respectively , in sections [ conctheo ] and  [ randomizedr ] .",
    "we consider a sequence of measurable state spaces @xmath121 , a probability measure @xmath122 and a sequence of markov transitions @xmath123 from @xmath124 into @xmath125 for @xmath126 .",
    "let @xmath127 be a markov chain with initial distribution @xmath128 and elementary transitions @xmath129 let @xmath130 be a sequence of non - negative and bounded potential functions on @xmath125 . to simplify the presentation , and to avoid unnecessary technicalities , it is supposed @xmath131 for @xmath126 with @xmath132 the boltzmann  gibbs transformation @xmath133 associated to @xmath134 is the mapping @xmath135 notice that @xmath136 can be rewritten as a nonlinear markov transport equation @xmath137 with @xmath138    let @xmath139 be the flow of probability measures , both starting at @xmath140 , and defined for any @xmath126 by the following recursion @xmath141 it can be checked that the solution @xmath142 of these recursive updating prediction equations have the following functional representations : @xmath143 with the unnormalized feynman  kac measures @xmath144 and @xmath145 defined by the formulae @xmath146\\quad   \\mbox{and}\\quad   \\widehat{\\gamma}_{n}(f_{n})=\\gamma_{n}(f_{n}\\mathcal{g}_{n}).\\ ] ]      to analyze smc  methods , we introduce the feynman  kac semigroup associated to the flow of measures @xmath147 and @xmath148 .",
    "let us start by denoting by @xmath149 the bounded integral operator from @xmath125 into @xmath150 defined by @xmath151 let @xmath152 be the corresponding linear semigroup defined by @xmath153 with the convention @xmath154 , the identity operator .",
    "note that @xmath155 is alternatively defined by @xmath156.\\ ] ] using the markov property , it follows that @xmath157\\prod_{0<k < p}\\mathcal{g}_{k}(\\mathcal{x}_{k } ) \\biggr]=\\gamma_{p } ( \\mathcal{q}_{p , n}(f_{n } ) ) .\\ ] ] the last assertion shows that @xmath152 is the semigroup associated with the unnormalized measures @xmath158 .",
    "denote its normalized version by@xmath159 finally , denote by @xmath160 the nonlinear semigroup associated to the flow of normalized measures @xmath148 : @xmath161 with the convention , the identity operator and @xmath162 , @xmath163 .",
    "note that @xmath160 can be alternatively defined in terms of @xmath152 using @xmath164      let @xmath165 be a markov chain taking values in some measurable state spaces @xmath166 with elementary transitions @xmath167 and initial distribution @xmath168 .",
    "in addition , introduce a sequence of non - negative potential functions @xmath169 on the state spaces  @xmath81 . to simplify the presentation",
    ", it is assumed that @xmath170 @xmath171 .",
    "we associate to an increasing sequence of time parameters @xmath65 the excursion - valued random variables @xmath172 for @xmath173 and @xmath174 for @xmath126 .",
    "we also define the random path sequences@xmath175 with the convention @xmath176 .",
    "note that @xmath177 forms a markov chain @xmath178 taking values in the excursion spaces @xmath179 . now adopting the potential functions @xmath180 in ( [ unn ] ) , we readily find that @xmath181=\\mathbb{e } [ f_{n}(x_{0:t_{n}})w_{0:t_{n-1 } } ( x_{1:t_{n-1 } } ) ] .\\ ] ]    by definition of the potential functions @xmath182 of the excursion feynman  kac model ( [ laformm ] ) , it is easily proved that the condition @xmath183 ( equation  ( [ condg ] ) ) is satisfied as soon as @xmath83 introduced in ( [ condgprime ] ) holds true .",
    "more precisely , it holds that @xmath83 implies @xmath183 with @xmath184 where the essential supremum @xmath185 is taken over all admissible paths @xmath186 and @xmath187 of the underlying markov chain @xmath32 .      in section [ secexc ] , we have assumed that an increasing sequence of time parameters @xmath65 was available .",
    "we now introduce the functional criteria used to build this sequence . to connect the empirical criteria with their limiting functional versions ,",
    "the latter need to satisfy some weak regularity conditions that are given below .",
    "we consider a sequence of functional criteria @xmath188 satisfying the following lipschitz type regularity condition @xmath189 ( h )    @xmath190 on @xmath191 such that @xmath192    we illustrate this construction with the pair of functional criteria discussed in section  [ sec : limiting ] . when we consider ( eq : limitingvariance ) , the functional @xmath193 ^{2 } \\biggr)\\ ] ] coincides with the squared coefficient of variation of the weights w.r.t .",
    "@xmath194 . when we consider ( [ eq : limitingentropy ] ) , the functional latexmath:[\\[\\label{eq : limitentropy } \\mathcal{h}_{p , q}^{(n ) } ( \\mu ) = \\operatorname{ent } ( \\mathrm{d}\\mu    relative entropy distance between @xmath194 and the updated weighted measure . under the condition",
    "@xmath183 stated in ( [ condg ] ) , it is an elementary exercise to check that the above pair of criteria satisfy ( [ lipsh ] ) . in the first case ( [ eq : limitvariance ] ) , we can take for some constant @xmath196 sufficiently large . in the second case ( [ eq : limitentropy ] ) , we can take @xmath197 , again for some @xmath196 large enough .",
    "we now explain how to define the sequence of resampling times @xmath65 .",
    "this requires introducing the measure @xmath198 defined for any pair of integers @xmath199 and any @xmath200 by @xmath201 where @xmath202 denotes an infinitesimal neighborhood of a path sequence @xmath203 .",
    "[ adpttt ] given @xmath204 , with @xmath99 and @xmath205 , we define an increasing sequence of deterministic time steps @xmath206 and a flow of feynman  kac measures @xmath207 by induction as follows .",
    "suppose that the resampling time @xmath208 is defined as well as @xmath209 .",
    "the resampling time @xmath210 is defined as the first time ( @xmath211 ) the quantity @xmath212 hits the set @xmath213 ; that is , @xmath214 .",
    "given @xmath210 , we set @xmath215 with the boltzmann  gibbs transformation @xmath216 associated with the potential function @xmath217 .    by definition of the markov transition @xmath218 of the excursion model @xmath219 defined in section  [ secexc ]",
    ", it can be checked that @xmath220 this yields the recursion ( ( [ propprod ] ) and ( [ propprod2 ] ) ) @xmath221 hence the flow of measures @xmath96 and @xmath222 coincide with the feynman ",
    "kac flow of distributions defined in  ( [ qf ] ) with the markov chain and potential function @xmath223 on excursion spaces defined in  ( [ refxa ] ) and ( [ laformm ] ) .",
    "the smc  approximation of these distributions is studied in section  [ adpative ] .      in this section ,",
    "we examine the inductive construction of the deterministic resampling times @xmath89 introduced in section  adpttt for the criteria ( [ eq : limitingvariance ] ) and ( eq : limitingentropy ) .",
    "@xmath59 _ squared coefficient of variation_. in this case , we have @xmath224 the mappings @xmath225 are generally increasing .",
    "one natural way to control these variances is to choose an interval @xmath226 , with @xmath227 , then @xmath228{\\mathbb{e}_{n,\\widehat{\\eta}_{n } } ( w_{t_{n},s } ( x_{t_{n}+1:s } ) ) ^{2 } } \\}.\\ ] ]    @xmath59 _ entropy_.",
    "this criterion allows us to control an entropy - like distance between the free motion trajectories and the weighted feynman ",
    "kac measures . to be more precise , set @xmath229 with the weighted measures @xmath230 defined by @xmath231 if we choose an interval @xmath226 , with @xmath227 , then the resampling time @xmath210 coincides with the first time the entropy distance goes above the level @xmath61 ; that is , @xmath232",
    "the smc interpretation of the evolution equation ( [ predeq ] ) is the markov chain @xmath233 with elementary transitions @xmath234 where @xmath235 for every @xmath236 and @xmath237 this integral decomposition shows that the smc  algorithm has a similar updating / prediction nature as the one of the ` limiting ' feynman  kac model .",
    "more precisely , the deterministic two - step updating / prediction transitions in distribution spaces @xmath238 have been replaced by a two - step resampling / mutation transition in a product space @xmath239 in our context , the smc algorithm keeps track of all the paths of the sampled particles and the corresponding ancestral lines are denoted by @xmath240 and @xmath241 , where we recall that @xmath242 . by definition of the reference markov model  @xmath219 given in ( [ refxa ] ) , every path particle  @xmath243 keeps track of the selected excursion  @xmath244 and it evolves from its terminal state @xmath245 with @xmath246 elementary moves using the markov transition @xmath247 .",
    "more formally , we have that @xmath248 from this discussion , it is worth mentioning a further convention that the particle empirical measures @xmath249 are the terminal values at time @xmath250 of the flow of random measures @xmath251      [ conccsecc ]      [ introconcc ]    this section is concerned with the concentration analysis of the empirical measures @xmath95 associated with ( empiricalreferencesmc ) around their limiting values @xmath96 defined in ( [ qf ] ) .",
    "our concentration estimates are expressed in terms of @xmath252 with @xmath155 as in ( [ qpnref ] ) and @xmath253 in equation  ( [ qnormref ] ) .",
    "these parameters can be expressed in terms of the mixing properties of the markov transitions @xmath254 ; see @xcite , chapter 4 . under appropriate mixing type properties",
    "we can prove that the series @xmath255 is uniformly bounded w.r.t . the final time horizon @xmath43 for any parameter @xmath256 .",
    "most of the results presented in this section are expressed in terms of these series . as a result , these non - asymptotic results can be converted into time uniform convergence results . to get a flavor of these uniform estimates , assume that the markov transitions @xmath257 satisfy the following regularity property .",
    "@xmath258 there exists an @xmath259 and a sequence @xmath260 such that @xmath261 with @xmath262 .",
    "we also introduce the following quantities : @xmath263 with the collection of constants @xmath264 introduced in ( [ condg ] ) . in the above displayed formula , the supremum is taken over all admissible pairs of paths with elementary transitions  @xmath265 .    under the condition @xmath258 we have for any @xmath266 , and @xmath267 , @xmath268 the proof of these estimates relies on semigroup techniques ; see @xcite , chapter 4 , for details .",
    "several contraction inequalities can be deduced from these results . to understand",
    "this more closely , assume that @xmath258 is satisfied with @xmath269 , @xmath270 and @xmath271 . in this case ,",
    "@xmath272 and @xmath273 imply that @xmath274    more generally , assume @xmath258 is satisfied for some @xmath275 and that the parameters @xmath276 and @xmath277 are such that @xmath278 in this situation , @xmath279 and @xmath280 and therefore @xmath281 see @xcite , chapter 3 , for a discussion of when @xmath258 holds .",
    "we also mention that this mixing condition is never met for @xmath282 on @xmath242 discussed in section  [ secexc ] . nevertheless , under appropriate conditions on the markov transitions @xmath283 , it is satisfied for the time marginal model associated with the excursion valued markov chain model on @xmath284 .",
    "for instance , if @xmath285 , @xmath286 , @xmath287 for some @xmath288 , then condition @xmath289 is met with @xmath269 and @xmath290 .      at this point",
    ", it is convenient to observe that the local sampling errors induced by the mean field particle model are expressed in terms of the collection of local random field models defined below .    for any @xmath99 and any @xmath101 , let @xmath292 be the collection of random fields defined by the following stochastic perturbation formulae @xmath293 \\bigr ) .\\ ] ] for @xmath173 ,",
    "the conventions @xmath294 and @xmath295 are adopted .    in order to quantify high - order @xmath291-mean errors we need the following khinchine type inequality for martingales with symmetric and independent increments .",
    "this is a well - known result .",
    "[ lemp ] let @xmath296 be a real - valued martingale with symmetric and independent increments @xmath297 . for any integer @xmath275 and any @xmath99 , we have@xmath298 _ { n}^{m^{\\prime } /2",
    "} ) ^{{1}/{m^{\\prime } } } \\qquad \\mbox{with } [ l^{\\delta } ] _ { n}:=\\sum_{0\\leq p\\leq n}\\delta_{p}^{2},\\ ] ] where @xmath299 stands for the smallest even integer @xmath300 and @xmath301 is the collection of constants given below : @xmath302 with @xmath303 .",
    "[ lmvp ] for any @xmath101 , @xmath275 , @xmath99 and any test function @xmath304 we have the almost sure estimate @xmath305 where @xmath306 is the filtration generated by the @xmath307-particle system .    by construction",
    ", we have @xmath308 .\\end{aligned}\\ ] ] given @xmath309 , let @xmath310 be an independent copy of @xmath311 .",
    "it can be checked that @xmath312 \\big|\\mathcal { f}_{n}^{(n ) } \\biggr).\\ ] ] this yields the formula @xmath313 where @xmath314 is the terminal value of the martingale sequence defined by @xmath315 .\\ ] ] then as @xmath316 one may apply khinchine s inequality to conclude .",
    "the proof of the following lemma is rather technical and is provided in the .",
    "[ keydec ] for any @xmath199 , any @xmath317 and any @xmath318 , we have the first - order decomposition for the nonlinear semigroup @xmath319 defined in ( [ phiq ] ) : @xmath320 ( f_{n})=2q_{p , n}\\beta(\\mathcal{p}_{p , n } ) [ \\mu-\\eta ] ( \\mathcal{u}_{p , n,\\eta } ( f_{n } ) ) + \\mathcal{r}_{p , n}(\\mu,\\eta)(f_{n}),\\ ] ] where @xmath321 ( \\mathcal{v}_{p , n,\\eta}(f ) ) \\vert\\times \\vert [ \\mu-\\eta ] ( \\mathcal{w}_{p , n,\\eta}(f_{n } ) ) \\vert\\ ] ] with @xmath322 a collection of functions in @xmath323 whose values only depend on the parameters @xmath324 .",
    "we now present a bias estimate and some @xmath291 bounds of independent interest .",
    "[ interm ] for any @xmath99 , @xmath325 and any @xmath101 , @xmath326 in addition , for any @xmath275 we have @xmath327 ( f_{n } ) \\vert^{m } \\bigr ) ^{{1}/{m}}\\leq\\frac{1}{\\sqrt{n}}b(2m)^{2}\\sigma_{1,n}+b(m)\\sigma_{2,n}\\ ] ] with @xmath328    using lemma [ keydec ] , we have the telescoping sum decomposition @xmath329 \\\\ & \\hspace*{3pt}=&\\sqrt{n}\\sum_{p=0}^{n } [ \\phi_{p , n}(\\eta_{p}^{n})-\\phi _ { p , n } ( \\phi_{p}(\\eta_{p-1}^{n } ) ) ] = \\mathcal{i}_{n}^{n}+\\mathcal{j}_{n}^{n}\\end{aligned}\\ ] ] with @xmath330 and the pair of random measures @xmath331 given for any @xmath325 by @xmath332 now , observe that @xmath333 using proposition  [ lmvp ] , for any @xmath318 it can be checked that @xmath334 in a similar way , we find that @xmath335 the first part of the proof then follows from ( [ eq : wneqin ] ) and ( [ lmi ] ) ; the remainder of the proof is now clear .",
    "the following concentration theorem is the main result of this section .",
    "[ theoexpoc ] for any @xmath99 , @xmath325 , @xmath101 and any @xmath102 , @xmath336 ( f_{n } ) \\vert\\geq\\epsilon\\bigr ) \\leq6\\exp { \\biggl ( -\\frac{n\\epsilon^{2}}{8\\sigma_{1,n } } \\biggr ) , } \\ ] ] where the constant @xmath337 is as in theorem  [ interm ] .",
    "in addition , suppose @xmath258 is satisfied for some @xmath338 and condition ( [ hyprref ] ) holds true for some @xmath339 and some finite constants @xmath340 .",
    "in this situation , for any value of the time parameter @xmath43 , for any @xmath318 , @xmath101 and for any @xmath341 the probability that @xmath342 ( f_{n } ) \\vert\\leq \\frac{4\\overline{r}}{\\delta^{2}}\\sqrt{\\frac{2m\\underline { r}\\overline{r}}{n\\delta}\\log { \\biggl ( \\frac{6}{\\rho } \\biggr ) } } \\ ] ] is greater than @xmath343 .",
    "we use the same notation as in the proof of theorem  [ interm ] . recall that @xmath344 for every centered gaussian random variable with @xmath345 and @xmath346 using ( [ lmi ] ) , for any @xmath318 and @xmath347 it follows that @xmath348 to simplify the presentation , set @xmath349 where @xmath350 was introduced in lemma [ keydec ] . by the definition of @xmath351 @xmath352 recalling that @xmath353 for every real - valued and centered random variable @xmath354 with ( e.g. , @xcite , lemma 7.3.1 )",
    ", we prove that @xmath355 & & \\quad = \\prod_{i=1}^{n } \\int_{s_{p}}\\mathcal{k}_{p,\\eta _ { p-1}^{n } } \\bigl ( \\mathcal{x}_{p-1}^{(n , i)},\\mathrm{d}x \\bigr ) \\mathrm{e}^{(t\\alpha _ { p , n}/{\\sqrt{n } } ) ( f_{p , n}^{n}(x)-\\mathcal{k}_{p,\\eta _ { p-1}^{n}}(f_{p , n}^{n})(\\mathcal{x}_{p-1}^{(n , i ) } ) ) } \\leq\\exp { ( { t^{2}\\alpha_{p , n}^{2}}/{2 } ) } .\\ ] ] iterating the argument , we find that @xmath356 with @xmath357    from these upper bounds , the proof of the exponential estimates now follows standard arguments . indeed , for any @xmath358 and any @xmath359 , by ( [ eqs1n ] ) we have @xmath360 replacing @xmath361 by @xmath362 and choosing @xmath363 yields @xmath364 to estimate the probability tails of @xmath365 , we use ( [ eqs22 ] ) and the fact that @xmath359 and @xmath366 @xmath367 now , choosing @xmath368 and replacing @xmath361 by @xmath369 , we obtain @xmath370 using the decomposition @xmath371 = \\mathcal{i}_{n}^{n}/\\sqrt{n}+\\mathcal{j}_{n}^{n}/\\sqrt{n}\\ ] ] we find that for any parameter @xmath372 $ ] @xmath373 ( f_{n})\\geq\\epsilon \\bigr ) \\leq\\mathbb{p } \\bigl ( \\mathcal{i}_{n}^{n}(f_{n})/\\sqrt{n}\\geq \\alpha\\epsilon \\bigr ) + \\mathbb{p } \\bigl ( \\mathcal{j}_{n}^{n}(f_{n})/\\sqrt{n}\\geq(1-\\alpha)\\epsilon \\bigr ) .\\ ] ] from previous calculations , @xmath374 ( f_{n})\\geq\\epsilon \\bigr ) \\leq\\exp { \\biggl ( -\\frac{n\\epsilon^{2}\\alpha^{2}}{2\\sigma_{n}^{2}}\\biggr ) } + 2\\exp { \\biggl ( -\\frac{n\\epsilon(1-\\alpha)}{3\\sigma_{1,n}}\\biggr ) } .\\ ] ] now , choose @xmath375 , then @xmath376 and @xmath377 ( f_{n})\\geq\\epsilon \\bigr ) & \\leq&\\exp { \\biggl ( -\\frac{n\\epsilon^{2}}{8\\sigma_{n}^{2 } } \\biggr ) } + 2\\exp { \\biggl ( -\\frac{n\\epsilon^{2}}{3\\sigma_{1,n } } \\biggr ) } \\\\ & \\leq&3\\exp { \\biggl ( -\\frac{n\\epsilon^{2}}{8 ( \\sigma_{1,n}\\vee \\sigma_{n}^{2 } ) } \\biggr ) } .\\end{aligned}\\ ] ] it remains to observe that @xmath378 and @xmath379 and @xmath380 ( f_{n } ) \\vert\\geq \\epsilon&\\quad   \\longleftrightarrow\\quad   & [ \\eta_{n}^{n}-\\eta_{n } ] ( f_{n})\\geq\\epsilon \\quad \\mbox{or}\\quad   [ \\eta_{n}^{n}-\\eta_{n } ] ( f_{n})\\leq-\\epsilon\\\\ & \\quad   \\longleftrightarrow\\quad &   [ \\eta_{n}^{n}-\\eta_{n } ] ( f_{n})\\geq \\epsilon \\quad \\mbox{or}\\quad   [ \\eta_{n}^{n}-\\eta_{n } ] ( -f_{n})\\geq\\epsilon\\end{aligned}\\ ] ] so that @xmath381 ( f_{n } ) \\vert\\geq\\epsilon \\bigr ) \\leq\\mathbb{p } \\bigl ( [ \\eta _ { n}^{n}-\\eta_{n } ] ( f_{n})\\geq\\epsilon \\bigr ) + \\mathbb{p } \\bigl ( [ \\eta_{n}^{n}-\\eta_{n } ] ( -f_{n})\\geq\\epsilon \\bigr ) .\\ ] ] the end of the proof of ( [ conccineg ] ) is now easily completed .",
    "we now assume that the mixing condition @xmath258 is satisfied for some @xmath275 and condition ( [ hyprref ] ) holds true for some @xmath339 and some finite constants @xmath340 . by ( [ sumcv ] )",
    "the following uniform concentration estimate holds @xmath382 ( f_{n } ) \\vert\\geq\\epsilon \\bigr ) \\leq6\\exp { \\biggl ( -\\frac{n\\epsilon^{2}\\delta^{5}}{32m\\underline{r}\\overline{r}^{3}}\\biggr ) } .\\ ] ] the proof of the theorem is concluded by choosing @xmath383 .    returning to the end of the proof of theorem  [ theoexpoc ]",
    ", the exponential concentration estimates can be marginally improved by choosing , in ( [ optim ] ) , the parameter @xmath384 $ ] such that @xmath385 , with @xmath386 , @xmath387 and @xmath388 elementary manipulations yield @xmath389 and therefore @xmath390 for small values of @xmath361 , this bound improves that in section 7.4.3 of  @xcite , which is of the form @xmath391 with @xmath392      by construction , the particle occupation measures  @xmath393 approximate the measures  @xmath394 introduced in ( [ eq : measureetathenmarkov ] ) ; that is , in some sense , @xmath395 @xmath396 .",
    "conversely , observe that @xmath397 , respectively @xmath394 , are the marginals of the measures  @xmath398 , respectively @xmath399 , w.r.t",
    ". the @xmath400 first coordinates . in other words , the measures @xmath401 , respectively @xmath394 , are the projections of the measures @xmath398 , respectively @xmath399 , on the state space @xmath402    for instance , the following proposition is essentially a direct consequence of theorem  [ theoexpoc ] .",
    "[ propreff ] for any @xmath101 , @xmath99 , @xmath403 and any @xmath359 , the concentration inequality : @xmath404 holds for some finite constant @xmath405 whose values only depend on the time parameter .",
    "in addition , when the measures @xmath406 have a finite support , the concentration inequality @xmath407 also holds , with a pair of finite constants @xmath408 .    by @xcite ,",
    "theorem 7.4.4 , for any @xmath101 , @xmath267 , @xmath99 and any test function @xmath409 @xmath410 with some finite constant @xmath405 and with the collection of constants @xmath411 defined in  ( [ collec ] ) .",
    "these estimates clearly imply that for any @xmath403 , and any test function @xmath412 @xmath413 under ( [ lipsh ] ) on the criteria type functionals @xmath414 and using the generalized integral minkowski inequality , it can be concluded that @xmath415 the proof of the exponential estimate follows exactly the same lines of arguments as the ones used in the proof of corollary 7.4.3 in  @xcite ; thus it is omitted .",
    "the last assertion is a  direct consequence of theorem  [ theoexpoc ] .",
    "the above proposition shows that the functional criteria @xmath416 can be approximated by @xmath417 , up to an exponentially small probability .",
    "therefore , as we can not compute the deterministic resampling times @xmath418 , it is necessary to approximate the reference particle model :    [ defonline ] the particle systems @xmath419 , @xmath420 , @xmath421 and  @xmath422 are defined as @xmath423 , @xmath424 , and @xmath425 and @xmath426 by replacing in the inductive construction of the deterministic sequence @xmath65 the measures @xmath394 by their current @xmath38-particle approximation measures @xmath427 here @xmath428 denotes the updated occupation measure of the particle system @xmath429 .",
    "we also assume that both models are constructed in such a way that they coincide on every time interval @xmath92 , once the random times @xmath93 , for every @xmath92 .",
    "it is emphasized that the measures @xmath430 differ from the reference empirical measures @xmath395 in ( [ empiref ] ) .",
    "indeed , the reference measures @xmath395 are built using the deterministic times @xmath75 based on the functional criteria @xmath431 , whilst the empirical measures @xmath432 are inductively constructed using random times @xmath42 based on @xmath433 .    by construction , for the pair of functional criteria discussed in section  [ applisec ]",
    ", we have that @xmath434 , where @xmath66 are the empirical criteria discussed in section  [ sec : adaptivecriteria ] .",
    "to go one step further in our discussion , it is convenient to introduce the following collection of events .    for any @xmath435 , @xmath116 , @xmath436 and @xmath101 ,",
    "we denote by  @xmath437 , the collection of events defined by : @xmath438    the proof of the following result is straightforward and hence omitted .",
    "[ lemke ] on the event @xmath439 , for any @xmath440 and for any @xmath441 , we have @xmath442    [ propke ] assume that the threshold parameters @xmath61 are chosen so that @xmath443 , for any @xmath99 .",
    "in this situation , for any @xmath435 , @xmath116 and @xmath101 , we have @xmath444    this result is proved by induction on @xmath116 . under our assumptions , for @xmath445 we have @xmath70 .",
    "thus , by our coupling construction the pair of particle models coincide up to the time @xmath446 .",
    "therefore , we have @xmath447 by lemma  [ lemke ] , on the event @xmath448 we have @xmath449 .",
    "this proves the inclusion for @xmath445 and @xmath269 .",
    "suppose the result is true at rank @xmath450 .",
    "thus , on the event @xmath451 it is the case that @xmath93 , for any @xmath92 . by our coupling construction ,",
    "the pair of particle models coincide up to @xmath452 ; that is , @xmath453 once again , by lemma  [ lemke ] , on the event @xmath454 it also follows that @xmath455 .",
    "[ randomizedr ]    the situation where the threshold parameters coincide with the adaptive criteria values @xmath456 can not be dealt with using our analysis .",
    "this situation is more involved since it requires us to control both the empirical approximating criteria and the particle approximation .",
    "it should be noted , however , that this is not a  difficulty in many applications where the probability of this event is zero .",
    "nonetheless , to avoid this technical problem , one natural strategy is to introduce randomized criteria thresholds .",
    "we further assume that the parameters @xmath111 are sampled realizations of a collection of absolutely continuous random variables @xmath113 .",
    "the main simplification of these randomized criteria comes from the fact that the parameters @xmath457 are strictly positive for almost every realization @xmath458 of the threshold parameters .    for almost every realization of the random threshold parameters , and for any @xmath459",
    ", we have the following exponential estimates : @xmath460 for some constants @xmath461 .",
    "in addition , when the measures @xmath406 have a finite support , for any @xmath462 , @xmath463 holds for a possibly different pair of finite constants @xmath461 .    using proposition  [ propreff ]",
    ", we obtain the rather crude estimate @xmath464 for a pair of finite constants @xmath461 .",
    "the final line is a direct consequence of proposition  [ propreff ] and an application of proposition  [ propke ] completes the proof .    we conclude that for almost every realization @xmath465 the pair of particle models @xmath466 and @xmath467 only differ on events @xmath468 with exponentially small probabilities : @xmath469",
    "in this section some direct consequences of the exponential coupling estimates are discussed . for almost every realization @xmath470 and for any test function @xmath471 the following decomposition holds ( writing @xmath472 for the online adaptive approximation introduced in definition  [ defonline ] ) : @xmath473 = \\sqrt{n } [ \\eta_{n}^{n}-\\eta_{n } ] + \\sqrt{n } [ \\overline{\\eta}_{n}^{n}-\\eta_{n}^{n } ] 1_{\\omega-\\omega_{m}^{n}(\\delta , ( a_{n})_{0\\leq n\\leq m})}\\ ] ] with @xmath474 ( f_{n})1_{\\omega-\\omega_{m}^{n}(\\delta,(a_{n})_{0\\leq n\\leq m } ) } \\bigr ) \\leq\\underbrace{\\sqrt{n}\\mathbb{p } ( \\omega-\\omega _ { m}^{n}(\\delta,(a_{n})_{0\\leq n\\leq m } ) ) } _ { \\stackrel{n\\uparrow \\infty}{\\longrightarrow}0}.\\ ] ] thus we can conclude directly that , for almost every realization @xmath475 , the random fields @xmath476 \\quad \\mbox{and}\\quad   w_{n}^{n}:=\\sqrt{n } [ \\eta _ { n}^{n}-\\eta_{n } ] \\vspace*{-2pt}\\ ] ] converge in law , as @xmath68 , to the same centered gaussian random field @xmath477 .      to demonstrate the impact of this functional fluctuation result we provide a brief discussion on the proof of the multivariate central limit theorem .",
    "we first recall the functional fluctuation theorem of the local errors associated with the mean field particle approximation introduced in ( defvn ) .",
    "this result was initially presented in  @xcite and extended in  @xcite .",
    "[ keyth ] for any fixed time horizon @xmath99 , the sequence @xmath478 converges in law , as @xmath38 tends to infinity , to a sequence of @xmath43 independent , gaussian and centered random fields @xmath479 with , for any @xmath480 , and @xmath481 , @xmath482[g_{p}-\\mathcal { k}_{p,\\eta _ { p-1}}(g_{p})]\\bigr).\\vspace*{-3pt}\\ ] ]    using arguments similar to those in the proof of lemma  [ keydec ] , we obtain the decomposition formula : @xmath483(f)=(\\mu-\\eta)\\mathcal { d}_{n,\\eta } ( f)+\\mathcal{r}_{n}(\\mu,\\eta)(f)\\vspace*{-2pt}\\ ] ] with the signed measure @xmath484 given by@xmath485^{\\otimes2}\\bigl(\\mathcal{g}_{n,\\eta}\\otimes\\mathcal { d}_{n,\\eta } ( f)\\bigr)\\qquad   \\mbox{with } \\mathcal{g}_{n,\\eta}:=\\mathcal{g}_{n-1}/\\eta(\\mathcal{g}_{n-1 } ) , \\\\[-2pt ] \\mathcal{d}_{n,\\eta}(f)(x ) & : = & \\mathcal{g}_{n,\\eta } ( x)\\times\\mathcal{m}_{n } \\bigl ( f-\\phi_{n}(\\eta)(f )",
    "\\bigr ) ( x).\\vspace*{-3pt}\\end{aligned}\\ ] ]    denote by @xmath486 the semi - group associated to the integral operators @xmath487 ; that is , @xmath488 for @xmath489 , we use the convention @xmath490 , the identity operator .",
    "the semigroup @xmath486 can be explicitly described in terms of the semigroup @xmath491 via @xmath492    the next lemma provides a first - order decomposition of the random fields @xmath493 in terms of the local fluctuation errors .",
    "its proof is in the .",
    "note that @xmath494 can be understood in the proof .",
    "[ lemdecomp ] for any @xmath101 and any @xmath199 , we have @xmath495    using the @xmath291-mean error estimates presented in section  lmbounds , it is easily proved that the sequence of remainder random fields @xmath496 in ( [ ran ] ) converge in law , in the sense of finite distributions , to the null random field as @xmath68 .",
    "therefore the fluctuations of @xmath497 follow from theorem  [ keyth ] .",
    "[ lecor ] for any fixed time horizon @xmath99 , the sequence of random fields @xmath498 converges in law , as @xmath499 , to a sequence of gaussian and centered random fields @xmath500 , where @xmath501 @xmath502      we end this article with some comments on the fluctuations of weighted occupation measures on path spaces . returning to the online adaptive particle model , given @xmath503 the @xmath38-particle measures @xmath504 can be used to approximate the flow of updated feynman ",
    "kac path distributions @xmath505 given for any bounded test function @xmath506 by @xmath507\\mapsto\\widehat{\\eta } _ { n+1,s}(f_{n+1})\\propto \\mathbb{e } [ f_{n+1}(x_{0:t_{n+1}})w_{0:s } ( x_{1:s } )   ] .\\ ] ] indeed , if we choose @xmath508 then in some sense @xmath509 where @xmath399 is the flow of feynman  kac measures on path spaces introduced in section  [ secexc ] .",
    "since the adaptive interaction time is taken such that @xmath510 , it holds that @xmath511 in other words , if the marginal type functions are chosen such that @xmath512 so @xmath513 , \\\\ \\overline{\\eta}_{n+2}^{n } \\bigl ( t_{n+1}^{(0)}(f_{n+1 } ) \\bigr ) & = & \\frac{1}{n}\\sum_{i=1}^{n}f_{n+1 } \\bigl ( \\widehat{\\mathcal{y}}_{n+1}^{(n , i ) } \\bigr ) \\simeq_{n\\uparrow\\infty}\\eta_{n+2 } \\bigl ( t_{n+1}^{(0)}(f_{n+1 } ) \\bigr ) .\\end{aligned}\\ ] ] from the previous discussion , for almost every realization @xmath514 , a  central limit theorem ( clt ) is easily derived for the collection of random fields @xmath515 , \\\\",
    "\\widehat{w}_{n+1,s}^{n,(1)}(f_{n+1})&:= & \\sqrt{n } [ \\widehat{\\eta}_{n+1,s}^{n}(f_{n+1})-\\widehat{\\eta}_{n+1,s}(f_{n+1 } ) ] \\end{aligned}\\ ] ] as well as for the mixture of random field sequences @xmath516    the fluctuation analysis of these random fields relies on the functional clt stated in corollary  [ lecor ] .",
    "in particular , the fluctuations of the random fields ( [ mixfield ] ) depend on those of a pair of random fields .",
    "reference @xcite is the only published paper discussing a convergence result for an adaptive smc  scheme .",
    "the authors establish a clt using an inductive proof w.r.t . deterministic time periods .",
    "they avoid the degenerate situation where the threshold parameter coincides with the limiting functional criterion .",
    "more recently , this problem has also been addressed in @xcite , chapter 4 . however",
    ", the author does not account for the randomness of the resampling times in his analysis .",
    "proof of lemma  [ keydec ] via ( [ phiq ] ) , for any @xmath517 we find that @xmath518(f ) & \\hspace*{3pt}= & \\frac{1}{\\mu ( \\mathcal{g}_{p , n,\\eta})}(\\mu-\\eta)\\mathcal{d}_{p , n,\\eta}(f ) , \\\\",
    "\\mathcal{d}_{p , n,\\eta}(f)(x ) & : = & \\mathcal{g}_{p , n,\\eta}(x)\\times \\mathcal{p}_{p , n } \\bigl ( f-\\phi_{p , n}(\\eta)(f ) \\bigr ) ( x),\\end{aligned}\\ ] ] where @xmath519 and @xmath520 . now , since , it follows that @xmath518&\\hspace*{3pt}=&(\\mu-\\eta)\\mathcal { d}_{p , n,\\eta}+\\mathcal{r}_{p , n}(\\mu,\\eta ) , \\\\ \\mathcal{r}_{p , n}(\\mu,\\eta)(f)&:=&-\\frac{1}{\\mu(\\mathcal { g}_{p , n,\\eta})}[\\mu-\\eta]^{\\otimes2}\\bigl(\\mathcal{g}_{p , n,\\eta}\\otimes\\mathcal { d}_{p , n,\\eta } ( f)\\bigr).\\end{aligned}\\ ] ] using the fact that @xmath521 \\mathcal{g}_{p , n,\\eta}(y)\\eta(\\mathrm{d}y)\\ ] ] we find @xmath522    finally , for any @xmath523 observe that @xmath524^{\\otimes2}\\bigl ( \\overline{\\mathcal{g}}_{p , n,\\eta}\\otimes\\overline{\\mathcal{d}}_{p , n,\\eta}(f ) \\bigr ) \\bigr\\vert\\ ] ] with @xmath525 and @xmath526    proof of lemma  [ lemdecomp ] the lemma is proved by induction on @xmath43 . for @xmath173",
    ", it follows that @xmath527 $ ] , with @xmath528 . assuming the formula at @xmath43 @xmath529 \\\\ & = & v^{n}_{n+1}+w^{n}_{n}d_{n+1}+\\sqrt{n}r_{n+1 } ( \\eta^{n}_{n},\\eta_{n } ) \\\\ & = & v^{n}_{n+1}+\\sum_{p=0}^{n } v^{n}_{p } d_{p , n+1 } + \\sqrt{n}\\sum_{p=0}^{n-1 } r_{p+1 } ( \\eta^{n}_{p},\\eta_{p } ) d_{p+1,n+1}+\\sqrt{n}r_{n+1 } ( \\eta^{n}_{n},\\eta_{n } ) .\\end{aligned}\\ ] ] letting @xmath530",
    ", it follows that ( [ ran ] ) is satisfied at rank @xmath531 due to @xmath532",
    "we would like to thank the associate editor and the three referees for many helpful comments that vastly improved the paper ."
  ],
  "abstract_text": [
    "<S> sequential monte carlo ( smc ) methods are a class of techniques to sample approximately from any sequence of probability distributions using a combination of importance sampling and resampling steps . </S>",
    "<S> this paper is concerned with the convergence analysis of a class of smc methods where the times at which resampling occurs are computed online using criteria such as the effective sample size . </S>",
    "<S> this is a popular approach amongst practitioners but there are very few convergence results available for these methods . by combining semigroup techniques with an original coupling argument , we obtain functional central limit theorems and uniform exponential concentration estimates for these algorithms .    , </S>"
  ]
}