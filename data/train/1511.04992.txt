{
  "article_text": [
    "consider a bayesian model where the likelihood of the observations @xmath4 is denoted by @xmath5 and the prior for @xmath6 admits a density @xmath7 with respect to lebesgue measure @xmath8 .",
    "then the posterior density of interest is @xmath9 .",
    "we slightly abuse notation by using the same symbols for distributions and densities .    for complex models , a standard approach to sample from @xmath10",
    "consists of using the metropolis  hastings ( mh )  algorithm which generates , under weak assumptions , an ergodic markov chain of invariant density @xmath11 .",
    "given the current state @xmath12 of the markov chain , one generates a candidate value @xmath13 according to a proposal density which is accepted with a probability that is a function of the likelihood ratio @xmath14 . when the likelihood can not be computed , as for many latent variable models , it is thus impossible to implement this algorithm . in this context ,",
    "a common approach consists of using markov chain monte carlo ( mcmc ) techniques to explore the joint posterior density of the parameter and latent variables .",
    "however , the resulting markov chains can mix very poorly as the posterior distribution of the latent variables given @xmath12 can be high - dimensional , multimodal and exhibit complex dependencies .",
    "moreover , there are important applications where it is possible to sample the latent variables according to their prior distribution but we do not have access to the analytical expression of this distribution ( e.g. , @xcite , @xcite and @xcite ) . in these cases , standard mcmc  algorithms are either non applicable or very inefficient ; see ( * ? ? ?",
    "* section 2.3 ) for a discussion .",
    "contrary to these approaches , the pseudo - marginal ( pm ) algorithm directly mimicks the mh scheme targetting the marginal @xmath11 by substituting an estimator of the likelihood ratio @xmath15 to the true likelihood ratio in the mh  acceptance probability @xcite , @xcite .",
    "this estimator is obtained by computing a non - negative unbiased estimator of @xmath16 and dividing it by the estimator of @xmath5 computed when the value @xmath12 was accepted . the use of unbiased estimators within the  mh was first suggested in @xcite .",
    "ever since its introduction in bayesian statistics in @xcite , this simple yet powerful idea has become very popular as it is often possible to obtain a non - negative unbiased estimator of intractable likelihoods and it provides state - of - the - art performance in many scenarios .",
    "many theoretical results have been obtained for the pm algorithm .",
    "qualitative properties of this procedure have been established in @xcite and @xcite and quantitative results in @xcite , @xcite and @xcite .",
    "assuming that the likelihood estimator is evaluated using importance sampling or particle filters with @xmath0 particles , it has been shown under various assumptions that @xmath0 should be selected such that the variance of the log - likelihood ratio estimator should be of order 1 to minimize the computational resources necessary to achieve a specific asymptotic variance for a particular pm average .",
    "as the number @xmath2 of data @xmath17 increases , this implies that @xmath0 should be proportional to @xmath2 ( * ? ? ?",
    "* theorem 1 ) and the computational cost of the resulting procedure is thus of order @xmath18 at each iteration .",
    "the pm algorithm scales rather poorly with @xmath2 because it is based on an estimator of @xmath14 which is obtained by dividing estimators of @xmath16 and @xmath5 which are independent given @xmath12 and @xmath13 ; the likelihood estimators being typically obtained using importance sampling for i.i.d .",
    "latent variable models and particle filtering for state - space models .",
    "we propose an original method to correlate these estimators so as to reduce the variance of the resulting ratio .",
    "the proposed methodology , termed the correlated pseudo - marginal ( cpm ) method , can be applied to many problems where the pm algorithm is currently being used .",
    "correlation between the estimators is introduced by correlating the auxiliary random variates used to obtain the unbiased estimators . in a state - space model scenario ,",
    "we use a scheme based upon the particle filter with hilbert sort proposed in @xcite .",
    "when the likelihood is estimated using importance sampling for i.i.d .",
    "data , we show that the resulting log - likelihood ratio estimator satisfies a central limit theorem ( clt ) of asymptotic variance of order @xmath3 when @xmath0 grows sublinearly with @xmath2 . if the posterior is asymptotically normal , this clt  can be used to show that the cpm chain converges weakly to a discrete - time markov chain as @xmath19 , allowing to provide guidelines on the parameter settings of the cpm  scheme .",
    "experimentally , the cpm algorithm improves performance over the pm algorithm in our examples from 20-fold when @xmath2 is a few hundreds to more than 100-fold when @xmath2 is a few thousands in i.i.d .",
    "scenarios and scalar state - space models . for multivariate state - space models ,",
    "the benefits of this method are less impressive for large datasets but remain substantial .",
    "the rest of the paper is organized as follows . in section [ ss : sim likelihood ] , we introduce the cpm algorithm and detail its implementation for latent variable models . in section [ sec :",
    "scaling ] , we present various clts for the log - likelihood estimator and the log - likelihood ratio estimators for the pm  and cpm  algorithms when @xmath19 . in section [ sec : optimisation ] , we exploit these asymptotic results to analyze the cpm kernel in this large data regime .",
    "we demonstrate experimentally the efficiency of this methodology in section  [ sec : applications ] and discuss various potential extensions in section [ sec : discussion ] .",
    "all the proofs are given in the appendix .",
    "the transition kernel @xmath20 of the standard mh scheme to sample from @xmath11 using a proposal distribution @xmath21 is given by @xmath22 where @xmath23 and@xmath24 implementing this mh  scheme requires being able to evaluate the likelihood ratio @xmath14 appearing in the expression of @xmath25 .",
    "assume @xmath26 is a non - negative unbiased estimator of the intractable likelihood @xmath5 when @xmath27 . here",
    "@xmath28 corresponds to the @xmath29valued auxiliary random variables used to obtain the estimator .",
    "we introduce the joint density @xmath30 on @xmath31 , where @xmath32 as @xmath26 is unbiased , @xmath33 admits @xmath11 as marginal density .",
    "the cpm  algorithm is a mh scheme targeting ( [ eq : pseudomarginaltarget ] ) with proposal density @xmath34 where @xmath35 is a @xmath36-reversible transition kernel , i.e. @xmath37 simple calculations show that this yieds the following acceptance probability @xmath38 hence , the cpm  algorithm admits @xmath39 as an invariant density by construction and its transition kernel @xmath40 is given by@xmath41 where @xmath42 for @xmath43 , we recover the pm algorithm .",
    "let @xmath44 be the multivariate normal density of argument @xmath45 , mean @xmath46 and covariance @xmath47 and @xmath48 denotes a draw from this distribution . henceforth , we assume the likelihood estimator is computed using @xmath49 standard normal random variables so @xmath50,@xmath51 where @xmath52 , @xmath53 is the @xmath54 vector with zero entries and @xmath55 the @xmath56 identity matrix .",
    "it is straightforward to check that @xmath57 is reversible with respect to @xmath58 .",
    "there is no loss of generality to select @xmath58 as a  normal density as inversion techniques can be used to form any random variable of interest and section [ ss : ar plus noise ] , it is necessary to generate uniform random variates and these may be constructed as @xmath59 where @xmath60 is a scalar element of @xmath61 and @xmath62 the cumulative distribution function of the standard normal . ] while the kernel @xmath57 has the advantage that it can be regarded as a discretized ornstein  uhlenbeck process .",
    "this property is exploited to establish the main result of section [ sec : scaling ] . in practice",
    ", we will select @xmath63 close to @xmath3 to introduce strong positive correlations between @xmath26 and @xmath64 where @xmath65 .",
    "we examine how to select this parameter in section [ sec : optimisation ] .",
    "to summarize , the cpm algorithm proceeds as follows to sample from @xmath66 .    * correlated pseudo - marginal algorithm *    1 .   sample @xmath67 .",
    "2 .   sample @xmath68 and set @xmath69 3 .",
    "compute the estimator @xmath70 of @xmath71 4 .   with probability @xmath72 output @xmath73 .",
    "otherwise , output @xmath74 .",
    "contrary to the pm method , we need to store the vector @xmath61 instead of @xmath75 as @xmath76 is not a markovian sequence for the cpm method when @xmath77 . in the applications considered , this overhead is mild .",
    "the rationale behind the cpm  scheme is that we can expect the likelihood ratio @xmath78 to have a small variance if both @xmath79 and @xmath80 are close to each other and @xmath81 is a regular enough function . in many situations , the posterior @xmath11 will be approximately normal for large data sets with a covariance scaling in @xmath82 so an appropriately scaled mh random walk proposal will ensure that @xmath12 and @xmath13 are closed while we explain in section [ sec : scaling ]  how the correlation parameter @xmath63 should be selected to ensure that @xmath28 and @xmath83 are close enough to guarantee that the variance of the estimated log - likelihood ratio will be indeed of order 1 .",
    "consider the following model@xmath84 where @xmath85 are @xmath86-valued latent variables and @xmath87 are @xmath88-valued observations .",
    "let @xmath89 for any @xmath90 for a realization @xmath91 , the likelihood factorizes @xmath92 where each term @xmath93 is given by @xmath94    if these integrals are intractable , an importance sampling estimator of the log - likelihood is given by@xmath95 where @xmath96 the importance weights  @xmath97 being given by @xmath98 where we assume that @xmath99 with @xmath100 a deterministic map and @xmath101 . in this case , we have @xmath102 @xmath103 so @xmath104 where @xmath105 .      consider a generalization of the model ( [ eq : independentlatentvariablemodels ] ) where the latent variables @xmath106 arise from a homogeneous @xmath86-valued markov process of initial density @xmath107 and markov transition density @xmath108 , i.e. for @xmath109 @xmath110 in this context , the likelihood does not factorize as in ( [ eq : likelihoodpaneldata ] ) but satisfies the following predictive decomposition @xmath111 with @xmath112 where @xmath113 denotes the posterior density of @xmath114 given the observations @xmath115 .",
    "importance sampling estimators of the likelihood have a relative variance scaling typically exponentially with @xmath2 and so the likelihood is usually estimated using particle filters @xcite .",
    "particle filters propagate @xmath0 random samples , termed particles , over time using a sequence of resampling steps and importance sampling steps , where the importance densities are @xmath116 at time @xmath3 and @xmath117 for @xmath118 . if we assume that @xmath119 and @xmath120 for @xmath118 where @xmath121 for @xmath109 and we parameterize the resampling step in function of normal random variables then we obtain an unbiased estimator @xmath122 of the likelihood which could be used within the cpm  scheme .",
    "however , if @xmath0 is moderate , the resampling steps introduce discontinuities in the particles that are selected when @xmath12 and @xmath28 are modified , even slightly .    to reduce the variability of the difference between the likelihood estimates @xmath123 and @xmath124 when @xmath79 is close to @xmath125",
    ", we modify the resampling scheme to induce significant correlation amongst the selected particles using the hilbert sort procedure introduced in @xcite .",
    "the hilbert space - filling curve is a continuous fractal map @xmath126   \\rightarrow\\left [   0,1\\right ]   ^{n}$ ] whose image is @xmath127   ^{n}$ ] .",
    "it admits a pseudo - inverse @xmath128 ^{n}\\rightarrow\\left [   0,1\\right ]   $ ] , that is @xmath129 for all @xmath130   ^{n}$ ] . although there exist points @xmath131  close in @xmath127   ^{n}$ ] such that @xmath132 and @xmath133 are far apart , @xmath132 and @xmath133 tend to be close for most points @xcite .",
    "this property can be used to build a sorted  resampling procedure which will ensure that when the parameter or auxiliary variables change slightly the particles that are selected are close .",
    "practically , this resampling procedure proceeds as follows : 1 ) the @xmath134valued particles are projected in the hypercube @xmath127",
    "^{n}$ ] using a bijection @xmath135   ^{n}$ ] , 2 ) the resulting @xmath136   ^{n}-$]valued particles are projected on @xmath127   $ ] using the pseudo - inverse @xmath137 , 3 ) these projected @xmath127   -$]valued particles are sorted , 4 )  the systematic resampling scheme proposed in @xcite is used on the sorted points .",
    "let us introduce the importance weights @xmath138 and @xmath139 for @xmath118 .",
    "the only difference between the resulting particle filter presented below and the algorithm proposed in @xcite is that we use normal random variates instead of randomized quasi - monte carlo points in @xmath127   ^{n}$ ] . for the mapping @xmath140",
    ", we adopt the logistic transform used in @xcite .",
    "* particle filter algorithm using hilbert sort *    @xmath141 @xmath142 @xmath143@xmath144    @xmath141 @xmath145@xmath146 @xmath144 .",
    "@xmath141 @xmath147@xmath148 @xmath149@xmath150 @xmath151 .",
    "@xmath141 @xmath152@xmath153@xmath154 @xmath155 @xmath156 @xmath144@xmath157 @xmath158 .",
    "@xmath141 @xmath159@xmath160@xmath144 .",
    "@xmath141 @xmath161@xmath162 @xmath144 .    in this description",
    ", the variable @xmath163 corresponds to the index of the parent  at time @xmath164  of particle @xmath165 .",
    "the systematic resampling procedure only requires sampling one single uniform random variate denoted @xmath166 which can be obtained from @xmath167 using @xmath168 .",
    "sorted  marginally uniforms are then calculated as @xmath154 @xmath155 @xmath156 for @xmath169 and dependent samples @xmath170 marginally satisfying @xmath171 are then obtained . if we denote by @xmath172 the vector of all the standard normal variables used to sample the particles and the ancestors , the corresponding unbiased likelihood estimator is given by @xmath173 we now directly use this algorithm within the cpm  method .",
    "ideas related to the cpm  scheme have previously been proposed : @xcite suggest combining pm steps with updates where @xmath28 is held fixed and only @xmath12 is updated while @xcite propose combining them with steps where @xmath12 is held fixed and correlation between @xmath174 and @xmath175 is introduced by sampling @xmath83 using a @xmath176reversible markov kernel @xmath177 . however , these schemes will scale poorly with @xmath2 as they still use pm  steps and the selection of @xmath177 was not discussed in @xcite .    as we have adopted a parametrisation where @xmath28 follows under the proposal a distribution independent of @xmath12 ,",
    "it might be argued that a gibbs algorithm sampling alternately from @xmath178 and @xmath179 could mix well and that it is not necessary to update the parameter and auxiliary variables jointly as in the cpm  scheme . in the context of hierarchical and latent variable models ,",
    "related ideas have been fruitfully explored in @xcite . however , in the applications considered here , such a gibbs strategy is usually not implementable .",
    "sophisticated particle gibbs samplers have been proposed to mimick it but their computational complexity is of the order @xmath180 per iteration for state - space models @xcite ,  ( * ? ? ? * section 6.2 ) .",
    "thus they are not even competitive to the standard pm  algorithm whose cost per iteration is of order @xmath18 while hybrid monte carlo techniques , another state - of - the - art class of methods , could not be applied as @xmath181 is not a continuous function .",
    "to understand the quantitative properties of the cpm scheme , it is key to establish the statistical properties of the likelihood ratio estimator appearing in its acceptance probability ( [ eq : acceptanceprobabilitycpm ] ) . in the i.i.d .",
    "latent variable model context introduced in section [ subsec : panel ] , we establish clts for the  log - likelihood estimators ( [ eq : likelihoodestimator ] ) and the corresponding log - likelihood ratio estimators used by the pm  and the cpm  algorithms when @xmath182 . here",
    "@xmath0 will be a deterministic function of @xmath2 denoted @xmath183 .",
    "we show that these estimators exhibit very different behaviours .    for a sequence of random variables @xmath184 defined on a common probability space @xmath185 and sub-@xmath186-algebras @xmath187 of @xmath188 ,",
    "we write subsequently @xmath189 if , for any continuous bounded function @xmath190 , we have @xmath191   \\rightarrow\\mathbb{e}\\left [ f\\left (   m\\right )   \\right ]   $ ] in probability where @xmath192 .      to state our results , we need to introduce more precise notation and , in particular , we now write @xmath193 @xmath194 and @xmath195 instead of @xmath196 @xmath197 and @xmath198 .",
    "we shall explicitly denote  probability , expectation and variance w.r.t @xmath199 and @xmath200 as @xmath201 @xmath202 and @xmath203 ; see appendix [ appendix : notation ] for a rigorous definition .",
    "let @xmath204 be the conditional variance and @xmath205 the unconditional variance under @xmath206 of the normalized importance weight@xmath207 the variances @xmath208 and @xmath209 are independent of @xmath2 as @xmath210 under @xmath206",
    ".    henceforth , we denote by @xmath211 the @xmath186-field spanned by @xmath212 for @xmath213  we present conditional clts for the log - likelihood error @xmath214 when @xmath215 arises from the proposal @xmath58 or is distributed according to@xmath216 where @xmath33 is given in ( [ eq : pseudomarginaltarget ] ) .",
    "the density @xmath217 depends upon @xmath183 as the estimator of @xmath218 is obtained using @xmath183 samples .",
    "[ theorem : cltmarginal]let @xmath219 with @xmath220 , @xmath221 and @xmath222 .    1 .",
    "if @xmath223 and @xmath224 then @xmath225 2 .",
    "if @xmath226 @xmath227 and @xmath228 then @xmath229    an examination of these proofs shows that to establish ( [ eq : cltexpressionmarginalproposal ] ) , respectively ( [ eq : cltexpressionmarginalequilibrium ] ) , for @xmath230 , it is only necessary to satisfy the weaker assumption @xmath231 , respectively @xmath232 .",
    "this implies that for @xmath220 and large @xmath2 we expect that , under the proposal , @xmath233 is approximately normal with mean @xmath234 and variance @xmath235 , whereas at equilibrium it follows approximately a gaussian with the same variance and an opposite mean .",
    "the distribution of @xmath233 is empirically examined in the examples of sections [ sec : app_re ] and [ ss : ar plus noise ] and shown to closely match these normal distributions .    for particle filters , a clt for @xmath233 of the form ( [ eq : cltexpressionmarginalproposal ] ) has already been established for the case @xmath236 in @xcite for multinomial under strong mixing assumptions and when the importance weights are bounded above and away from zero .",
    "we conjecture that both ( [ eq : cltexpressionmarginalproposal ] ) and ( [ eq : cltexpressionmarginalequilibrium ] ) can be generalized to scenarios where @xmath237 and to more general resampling schemes , although the systematic resampling scheme introduces substantial technical difficulties @xcite .",
    "assume we are at state @xmath238 and propose @xmath239 using @xmath240 , @xmath241 as in the pm algorithm or @xmath67 , @xmath242 as in the cpm algorithm . in both cases , the acceptance ratio depends on the log - likelihood ratio error @xmath243 we examine the limiting distribution of @xmath244 for fixed @xmath12 and @xmath245 at @xmath19 in two scenarios .",
    "the rationale for examining this ratio is that the posterior typically concentrates at a @xmath82 rate when @xmath2 increases so a correctly scaled random walk proposal will be of the form @xmath246 for @xmath245 a random variable of distribution independent of @xmath2 .",
    "we first examine this limiting distribution for the pm algorithm .",
    "[ theorem : cltlikelihoodratiostandardpseudomarginal]let @xmath12 and @xmath245 be fixed .",
    "assume that @xmath247is continuous at @xmath12 for any @xmath248 , that @xmath249 , @xmath250   < \\infty$ ] , @xmath251 is continuous at @xmath12 and @xmath252 is continuously differentiable at @xmath12 . for @xmath253 with @xmath254 @xmath255 @xmath256 , @xmath257 and @xmath258",
    "where @xmath28 and @xmath83 are independent , we have @xmath259    this result shows that the log - likelihood ratio error in the pm case can only have a limiting variance of order 1 if @xmath236 , we could also obtain such a clt but this still requires rescaling @xmath244 by @xmath260 . ] , that is @xmath183 has to be proportional to @xmath2 .",
    "the log - likelihood ratio estimator used by the cpm  exhibits a markedly different behaviour if we consider @xmath261 where @xmath262 for some @xmath263 .",
    "let us denote by @xmath264 the @xmath186-field spanned by @xmath265 and @xmath266 where @xmath267 and @xmath144 .",
    "we also denote the euclidean norm by @xmath268 and @xmath269 for a real - valued function @xmath270 .    [ theorem : conditionalcltthetathetacand]let @xmath12 and @xmath245 be fixed .",
    "let @xmath256 , @xmath271 and @xmath272 where @xmath273 is given by ( [ eq : correlationscaling ] ) then under assumptions [ ass : momentsofw]-[ass : dusteinfourthmoment ] in appendix [ subsec : assumptionstheoremconditionalclt ] and if @xmath274 as @xmath19 with @xmath275 , we have @xmath276 where @xmath277 .",
    "\\label{eq : varianceloglikelihoodratiocorrelated}%\\ ] ] hence we also have @xmath278    in this scenario , the limiting variance of the log - likelihood ratio is of order 1 even @xmath183 grows sublinearly with @xmath2 , e.g. @xmath279 with @xmath280 or @xmath281 .",
    "moreover , the conditional clt ( [ eq : conditionalcltloglikelihoodratioestimatorcpmh ] ) shows that as @xmath19 the distribution of the log - likelihood ratio error becomes independent of @xmath215 , this is a robustness  property which is not satisfied under the assumptions of theorem [ theorem : cltlikelihoodratiostandardpseudomarginal ] .",
    "this property is key to establish in the next  section weak convergence of the cpm  chain .",
    "we have not established this conditional clt  for particle filters .",
    "however , we have observed experimentally on various state - space models that the asymptotic distribution given in theorem [ theorem : conditionalcltthetathetacand ]  is a very good approximation of the empirical distribution ; i.e. , we find indeed in this application that there exists @xmath282 such that approximately @xmath283 at equilibrium .",
    "the use of weak convergence techniques to analyze and optimize mcmc schemes was pioneered in @xcite and has found numerous applications ever since ; see e.g. , @xcite for a recent application to the pm algorithm . to the best of our knowledge ,",
    "all these contributions consider the asymptotic regime where the parameter dimension @xmath284 increases without bound while @xmath2 is fixed as assumed in @xcite . in these scenarios ,",
    "a time rescaling is introduced and the limiting markov process is usually a diffusion process .",
    "we analyze here the cpm  scheme under a different asymptotic regime where @xmath284 is fixed while @xmath2 increases without bound , i.e. the large sample regime standard in asymptotic statistics .",
    "our analysis assumes the conditional clt of theorem [ theorem : conditionalcltthetathetacand ] holds and the statistical model is regular enough to ensure that the posteriors @xmath285 , interpreted here as random measures dependent on @xmath87 , can be approximated by normal densities which concentrate .",
    "[ ass : bvm]the sequence of posteriors @xmath286 satisfies @xmath287 in probability where @xmath288 is a sequence such that @xmath289 in probability and @xmath290 is a positive definite matrix .",
    "this assumption will be satisfied if a berstein - von  mises theorem holds ; see ( * ? ? ?",
    "* section 10.2 ) for sufficient conditions .",
    "consider the cpm chain @xmath291 started in the stationary regime , i.e. @xmath292 where we denote by @xmath293 the random measure ( [ eq : pseudomarginaltarget ] ) associated to observations @xmath294 .",
    "let @xmath295 be the sequence which arises from rescaling the component @xmath12 of this stationary sequence ; that is we consider the markov chain @xmath296 of initial distribution @xmath297 , where @xmath298 with @xmath299 and the proposal density @xmath300 is thus @xmath301 we will assume that the proposal is scaled appropriately .",
    "[ assumption : proposal]the proposal @xmath302 is a properly scaled random walk , i.e. @xmath303 where @xmath304 is a probability density on @xmath305 .    our result can also be easily extended to appropriately scaled autoregressive random walks .  under assumption [ assumption : proposal ] , the proposal @xmath306 defined in ( [ eq : rescaledproposal ] ) is independent of @xmath2 and we will denote it @xmath307 . the corresponding transition kernel of the rescaled cpm chain is given @xmath308 with acceptance probability@xmath309 and corresponding rejection probability @xmath310 .",
    "the non - markovian stationary sequence @xmath311 defines a random probability measure @xmath312 with finite dimensional distributions given by @xmath313 for any @xmath314 , any @xmath315 and borel sets @xmath316 .",
    "the following result shows that @xmath312 converges weakly to the measure of a stationary markov chain generated by the penalty method @xcite , @xcite ; this scheme  being an ideal  monte carlo technique which can not be practically implemented .",
    "[ theorem : weakconvergence]let assumptions [ ass : bvm ] and [ assumption : proposal ] hold .",
    "if the conditional clt  of theorem [ theorem : conditionalcltthetathetacand ] holds for all @xmath12 in a neighborhood of @xmath317 and the limiting standard deviation @xmath318 is continuous at @xmath317 then @xmath319 converges weakly to a stationary markov chain @xmath320 with invariant density @xmath321 and transition kernel @xmath322 @xmath323 of acceptance probability@xmath324 with @xmath325 , @xmath326 being the corresponding rejection probability .",
    "this means that the finite dimensional distributions of @xmath312 defined in ( [ eq : fddcpm ] ) converge weakly in probability to the finite dimensional distributions of @xmath327 given by @xmath328 for any @xmath314 , any @xmath315 and borel sets @xmath316 .    for large @xmath2 and a proposal of the form specified in assumption [ assumption : proposal ]",
    ", we thus expect some quantitative properties of the cpm kernel @xmath40 to be captured by the markov kernel @xmath329 where @xmath330 we have obtained ( [ eq : cpmkernelapproximation ] ) by using the change of variables @xmath331 and substituting the true target to its normal approximation in ( [ eq : penaltykernel ] ) , hence removing a level of approximation .",
    "we analyze here the kernel @xmath332 using an auxiliary kernel @xmath333 which admits a simpler structure . to state our results , we need the following notation .",
    "for any measurable real - valued function @xmath190 , probability measure @xmath46 and markov kernel @xmath334 we write @xmath335 , @xmath336 and @xmath337 , with @xmath338 .",
    "we introduce the hilbert spaces@xmath339 equipped with the inner product @xmath340 for any @xmath341 , the autocorrelation at lag @xmath342 is  thus @xmath343 where @xmath344 . the integrated autocorrelation time associated to a function @xmath190 under a markov kernel @xmath35",
    "is @xmath345 , and will be referred to as the inefficiency .",
    "we provide here an upper bound on @xmath346 that only depends on @xmath347 and the standard deviation @xmath348 of the log - likelihood ratio error at @xmath317 .",
    "to proceed , we introduce an auxiliary markov kernel @xmath333 given by @xmath349 where @xmath350 @xmath351 being the cumulative distribution of a standard normal . the kernel @xmath333 is a lazy  version of @xmath20 which satisfies the following properties .",
    "[ prop : qstarproperties]the kernel @xmath333 is reversible w.r.t @xmath352 and @xmath353 for any @xmath354 with @xmath355 moreover , @xmath333 is geometrically ergodic if @xmath20 is geometrically ergodic .",
    "we are interested in minimizing the computing time w.r.t .",
    "the parameter @xmath356 associated to the estimation of @xmath357 .",
    "the computing time function involves the integrated autocorrelation time ( iact ) , @xmath358 , whilst the computing time takes into account the computational efforts required to form an estimator .",
    "typically the expense of forming a likelihood estimator is proportional to @xmath0 , the number of samples .",
    "whilst , in general , it is not possible to compute @xmath358 it is possible to obtain a closed expression for @xmath359 and , by proposition [ prop : qstarproperties ] , @xmath353 .",
    "we now consider the relative inefficiency of the chain @xmath333 to the known likelihood chain @xmath20 .",
    "this is referred to as @xmath360 . following @xcite and @xcite",
    ", we define the relative computing time as @xmath361 .",
    "this is because @xmath362 and @xmath363 trades off the two concerns of the inefficiency @xmath364 and the computational cost of obtaining an estimator .",
    "[ cor : rif]the following results hold :    1 .   if @xmath365 then@xmath366 and @xmath367 is minimised at @xmath368 , at which point @xmath369 , @xmath370 and @xmath371 .",
    "2 .   as @xmath372@xmath373 and @xmath374",
    "is minimised at @xmath375 , at which point @xmath376 , @xmath377 and @xmath378 .",
    "3 .   @xmath364 and @xmath379 are decreasing functions of @xmath380 .",
    "the minimizing argument @xmath381 rises monotonically from @xmath382 to @xmath383 as @xmath347 increases from @xmath3 to @xmath384 .",
    "figure [ fig : rct_limit ] displays the acceptance probability @xmath385 , the relative inefficiency @xmath386 and the relative computing time @xmath387 against @xmath356 .",
    "the two scenarios displayed are for @xmath388 , for example in the perfect  proposal case where @xmath389 , and for the limiting case where @xmath390 .",
    "these are parts ( i ) and ( ii ) of proposition [ cor : rif ] . from figure",
    "[ fig : rct_limit ] , it is clear that @xmath363 , for both scenarios , is fairly flat as a function of @xmath356 .",
    "the function only approximately doubles relative to the minimum at @xmath391 or @xmath392 .      the weak convergence result presented in theorem [ theorem : weakconvergence ]",
    "should be interpreted cautiously . in particular",
    ", this result does not imply that @xmath393 as @xmath19 where @xmath394 @xmath395 for @xmath2 large enough .",
    "in the cpm  context , the auxiliary variables @xmath215 evolve according to the kernel @xmath396 where @xmath273 is given by ( [ eq : correlationscaling ] ) .",
    "when @xmath183 grows too slowly with @xmath2 , the decay of correlation of the cpm chain is too slow and results in an increasing inefficiency .",
    "for the i.i.d .",
    "latent variable model of section [ subsec : panel ] , we present here an argument suggesting that it is necessary to have @xmath397 to ensure that the inefficiency @xmath398 remains finite as @xmath2 increases .    as @xmath2 increases ,",
    "the auxiliary variables @xmath399 evolve at a much slower scale than @xmath400 .",
    "heuristically , over a time scale @xmath401 long enough so that @xmath402 has evolved significanly but @xmath403 has not , we expect that roughly @xmath404\\ ] ] and that the total inefficiency will be dominated by the inefficiency of @xmath405 \\right\\ }   _ { n\\geq1}$ ] .",
    "now for large @xmath2 , we have under regularity conditions ( * ? ? ?",
    "* lemma 2 ) @xmath406 = h(\\widehat{\\theta}^{t})+\\frac{1}{2t}\\sum_{i=1}^{d}\\sum_{j=1}^{d}% \\{\\partial_{ij}h(\\widehat{\\theta}^{t})+2\\partial_{i}h(\\widehat{\\theta}% ^{t})\\partial_{j}\\log w(\\widehat{\\theta}^{t},u_{1}^{t})\\}{\\overline{\\sigma}% } _ { i , j}+o_{p}\\left (   \\frac{1}{t^{2}}\\right )   , \\ ] ] where @xmath407 denotes the partial derivative w.r.t the @xmath408 component of @xmath12 . to simplify presentation , we assume further on that @xmath409 .",
    "in particular , the inefficiency is driven by the inefficiency of @xmath410 which is only a function of the auxiliary variables satisfying the following result .",
    "[ proposition : slowdown]let @xmath411 for @xmath412 @xmath255 then @xmath413 for @xmath2 large enough in probability under regularity conditions .",
    "here we use ` @xmath414 ' to mean that @xmath415 for some constant @xmath416 .",
    "we can not claim generally that the inefficiency of @xmath417   \\right\\ }   _ { n\\geq1}$ ] is smaller than the inefficiency of @xmath418 for all functions @xmath419 as established in @xcite .",
    "however , from the discussion within @xcite , it is clear that there are functions @xmath137 such that this holds true .",
    "let @xmath137 be such a function , then from proposition [ proposition : slowdown]@xmath420 as @xmath421 under regularity conditions in probability ( * ? ? ?",
    "* proposition 3 ) and @xmath422 .",
    "hence a necessary condition for the inefficiency to remain finite is @xmath397 .",
    "we illustrate the performance of  the standard mh , the pm scheme and the cpm  scheme applied to a simple gaussian random effects model@xmath423 we keep @xmath424 fixed at a true value of one , estimating only @xmath12 ( which has a true value of @xmath425 ) to which we assign a zero mean gaussian prior with large variance . in this case , we have @xmath426 .",
    "hence , as the likelihood is known in this scenario , this allows for detailed experimental analysis of the log - likelihood error and the log - likelihood ratio error .",
    "the same autoregressive metropolis proposal ( with correlation @xmath427 ) is used for all three schemes and the following unbiased estimator of the likelihood is used for the pm and cpm schemes .",
    "the likelihood is estimated unbiasedly using@xmath428    we first consider @xmath429 data points .",
    "the inefficiency is calculated for all three schemes for @xmath430 as@xmath431 where @xmath432 is the correlogram for @xmath12 at lag @xmath314 and the cutoff value @xmath433 is chosen to be large and dependent on the number of markov chain iterations .",
    "the mh  scheme results in an average acceptance probability of @xmath434 and an inefficiency of @xmath435 . the pm algorithm is then implemented .",
    "the number of samples , @xmath436 , is chosen so that the variance of the log - likelihood estimator , evaluated at a central value @xmath437 is approximately one , see @xcite and @xcite .",
    "the variance of @xmath438 is @xmath439 over the pm draws .",
    "this scheme has @xmath440 and @xmath441 .",
    "the output from the standard pm is displayed in the top four panels of figure [ fig : ret256_simple ] .",
    "the accepted and proposed values for @xmath442 are displayed together with their histograms .",
    "the two theoretical gaussian densities , see @xcite and @xcite for a detailed explanation , are also displayed showing close correspondence with the corresponding histograms .",
    "the output for @xmath12 and the corresponding correlogram indicate good mixing .    for the cpm scheme , the number of samples is set to @xmath443 and a range of values of @xmath63",
    "are considered going from @xmath444 to @xmath445 .",
    "the output corresponding to the extreme case of @xmath446 is displayed in the bottom four panels of figure [ fig : ret256_simple ] .",
    "the proposed and accepted values of @xmath442 move very slowly through the space and the histogram of the accepted values of @xmath442 shows a large positive mean and a large variance relative to the standard pm scheme .",
    "the plot of the path of @xmath12 and the corresponding correlogram indicate long range dependence .",
    "this indicates that taking such a high value for @xmath63 may not be advisable .",
    "the inefficiency @xmath447 for range of different values for @xmath63 is shown in the top of figure [ fig : ifversus_rho ] .",
    "the computing time relative to the standard pm  algorithm is also displayed ( middle panel ) .",
    "this relative computing time measure is calculated as @xmath448 ( for each value of @xmath63 where @xmath443 ) divided by the corresponding quantity for the standard pm ( @xmath449 ) .",
    "the shape is exactly the same as simply plotting @xmath447 but the interpretation is that a value less than one means that the correlated scheme is outperforming the standard pm scheme .",
    "finally the probability of acceptance ( bottom panel ) is shown in figure [ fig : ifversus_rho ] .",
    "it is immediately apparent that taking values of @xmath63 very close to one is problematic leading to poor mixing despite high probabilities of acceptance .",
    "taking values of @xmath63 which are too low is also problematic as the probability of accepting the proposals becomes small .",
    "it is notable , however , that in all cases the cpm  outperforms the pm  scheme .",
    "we now consider what happens when @xmath2 is large with @xmath0 and @xmath63 scaled with @xmath2 using the results of section [ sec : scaling ] . for the scaling @xmath450 and @xmath451 where @xmath452 is taken as @xmath425 .",
    "the results are shown in table [ table_ge_diift ] .",
    "the marginal probabilities of acceptance and the associated inefficiency associated with the mh scheme for the known likelihood case are recorded , for differing @xmath2 , as @xmath453 and @xmath454 respectively .",
    "the variance @xmath455 is also recorded and varies very little ( around @xmath456 ) as @xmath2 changes .",
    "the marginal acceptance probabilities , the inefficiencies and relative inefficiencies are also shown in table [ table_ge_diift ] for the cpm  scheme .",
    "it is clear again that these do not vary greatly and appear to converge as @xmath2 becomes large .",
    "we note that for the large dataset , where @xmath457 the number of particles necessary for the pm scheme would be prohibitive as @xmath0 would need to rise linearly with @xmath2 . for the cpm  algorithm ,",
    "it is clear that the results are robust despite taking small values of @xmath0 , in absolute terms , and increasing the sample size as @xmath458 .    to examine the theoretical assumptions and results of section [ sec : scaling ]",
    ", we analyse the case where @xmath459 in more detail .",
    "a range of values of @xmath0 are considered where , as before , @xmath460 with @xmath461 resulting in a value of @xmath462 .",
    "the results are summarized in table [ tab_ge_8k_varyn ] and the corresponding figure [ analysere ] .",
    "the inefficiency and marginal probability of acceptance are shown for the mh , pm and for the cpm schemes . by varying @xmath0 ,",
    "different values are achieved for @xmath455 .",
    "for all values of @xmath0 , the number of mcmc steps is greater than @xmath463 .",
    "for both the pm and cpm schemes , the relative inefficiency @xmath464 has been calculated as the ratio of the inefficiency to the inefficiency of the mh scheme ( which is @xmath465 ) .",
    "the relative computing time is calculated as @xmath466 and is reported for both the pm and cpm schemes .",
    "the corresponding figure [ analysere ] displays the values of @xmath464 and @xmath467 against both @xmath0 and @xmath356 .",
    "the two theoretical limits , see figure [ fig : rct_limit ] , are overlaid on the results for the plots against @xmath356 .",
    "the bottom two plots show that @xmath468 descends linearly with @xmath469 as expected ( right ) and that the marginal probability of acceptance in the cpm  scheme is very close to the theoretical lower bound ( left ) .    from table [ tab_ge_8k_varyn ] and",
    "figure [ analysere ] , it is clear that for all values of @xmath0 considered , the gains of the cpm scheme over the pm method in terms of relative computing time , @xmath467 , are very significant .",
    "the optimal value of @xmath0 for the cpm scheme is @xmath470 ( @xmath471 ) gives @xmath467 @xmath472 @xmath473 against a value of @xmath474 @xmath475 for the pm  scheme . as a consequence",
    ", the pm scheme would take @xmath476 times as long ( in computational time ) to produce the same accuracy in estimating the posterior mean of @xmath12 . even when @xmath477 or @xmath478 , it is apparent that the cpm  leads to order of magnitude improvements over the pm  scheme .    the results ( again with @xmath459 ) for the case when @xmath479 , so that @xmath480 in table [ tab_ge_8k_varyn ] , are examined in more detail in figure [ fig_ge_8k_n80 ] .",
    "only the first @xmath481 draws of the cpm scheme , again with @xmath462 , are displayed for brevity .",
    "the draws of @xmath482 and @xmath442 are displayed , together with @xmath483 .",
    "it is clear that the posterior distribution for the accepted values of @xmath442 has a high mean and a high variance .",
    "this is to be expected as marginally we expect @xmath484 where @xmath424 is the marginal variance .",
    "the draws of @xmath483 appears uncorrelated ( in unreported tests ) and the histogram , displayed , is virtually indistinguishable from the theoretical density which is @xmath485 .",
    "these results confirm what we would expect from the theoretical results .",
    "the resulting draws and correlogram ( bottom of panel ) of @xmath12 demonstrate low persistence .",
    "a linear scalar state - space model is now considered .",
    "the true likelihood is again known in this case and can be computed via the kalman filter .",
    "this again allows the direct examination of the log - likelihood estimator .",
    "we analyse the performance of the cpm  scheme ( for varying @xmath0 and @xmath63 ) and compare this with the pm  scheme .",
    "we consider observations generated by a first order autoregression ( ar(1 ) ) plus noise model as a simple example and apply the one step fully adapted particle filter with sorted resampling , see @xcite .",
    "the model is@xmath486 where @xmath487 and @xmath488 are standard normal and independent . in this case",
    "the likelihood for the pm and cpm schemes is estimated using the output of the particle filter .",
    "the random variates , for both the state innovations and the resampling steps , used in the pf are moved according to the scheme described in section [ sec : pf ] .    for the generation of the time series data , we use parameters @xmath489 @xmath490 @xmath491 , so that the marginal variance @xmath492 of the state @xmath114 is 1 .",
    "the parameter vector for the purposes of inference is @xmath493 where the measurement variance is assumed known at the true value @xmath494 .",
    "we simulate a single series of length @xmath495 and , in a similar manner to section [ sec : app_re ] , compare the mh , pm and cpm  algorithms .",
    "the same autoregressive metropolis proposal ( with correlation @xmath496 ) is used for all three schemes .    as in section",
    "[ sec : app_re ] , the results are summarized , in table [ tab : ar1_difft ] , for different values of @xmath2 and @xmath0 , where again the scaling is chosen so that @xmath497 and @xmath498 where @xmath452 is taken as @xmath425 .",
    "the marginal probabilities of acceptance and the associated inefficiency associated with the mh are recorded , for differing @xmath2 , as @xmath499 and @xmath500 respectively .",
    "the variance @xmath455 is also recorded and varies very little ( around @xmath501 ) as @xmath2 changes .",
    "the marginal acceptance probabilities @xmath502 , the inefficiencies @xmath503 and relative inefficiencies @xmath504 are also shown in table [ table_ge_diift ] for the cpm  scheme .",
    "the values for the inefficiencies and relative inefficiencies are averaged over the three parameters @xmath493 .",
    "we analyse the case where we set @xmath505 in greater detail considering a range of values of @xmath0 where as before @xmath506 with @xmath461 resulting in a value of @xmath507 .",
    "the results are summarized in table [ tab : ar_16k_varyn ] .",
    "the inefficiency and marginal probability of acceptance are shown for the mh and for the cpm schemes are shown . by varying @xmath0",
    "different values are achieved for @xmath455 . for the cpm scheme ,",
    "the relative inefficiency @xmath464 is calculated as the ratio of the inefficiency to the inefficiency of the mh scheme ( which is @xmath508 ) .",
    "the relative computing time is calculated as @xmath509 . for the pm scheme it is necessary to take @xmath510 to achieve @xmath511 to be around one which results in a relative inefficiency of approximately @xmath512 .",
    "hence the computational gains of the cpm  over the pm  are approximately 100-fold in this scenario .",
    "the pm  inefficiency relative to the mh scheme is around @xmath513 for all parameters and so the relative computing time , @xmath514@xmath515 , is around @xmath516 .",
    "it is clear that the cpm scheme is dramatically more efficient again than the pm scheme and the computing time varies very little for values of @xmath517 ( @xmath518 ) to @xmath519 ( @xmath520 ) .",
    "the cpm method is an extension of the pm  method relying on the introduction of a correlation scheme .",
    "we have provided theory and practical guidelines to perform an efficient implementation of this novel methodology .",
    "experimentally , the efficiency of computations is increased relative to the pm method by up to several orders of magnitude for large data sets .    from a methodological point of view",
    ", there are several possible extensions to this approach to investigate",
    ". it could be beneficial to use the sequential randomised quasi monte carlo ( qmc ) algorithm proposed @xcite within the cpm  scheme by correlating the single uniform used to randomize the qmc  grid .",
    "a sequential extension of the particle marginal metropolis ",
    "hastings algorithm @xcite , a pm  method , has been proposed in @xcite and it would also be interesting to develop an efficient sequential version of the cpm scheme . finally , alternatives over the hilbert resampling sort have been suggested in the literature @xcite , @xcite , @xcite and might scale better with the dimension @xmath314 of the latent states .    from a theoretical point of view",
    ", the cpm  chain converges weakly to an appropriate discrete - time markov chain whenever the number of monte carlo samples @xmath274 as @xmath19 and @xmath521 .",
    "however , this result has to be interpreted cautiously as this does not imply that the iact of the cpm chain converges to the iact of the limiting markov chain .",
    "we have shown that a necessary condition to ensure finiteness of the iact  of the cpm  chain is to ensure that @xmath522 .",
    "we conjecture that this condition is also sufficient for a large class of functions and that the computational complexity of the cpm  scheme is thus @xmath523 versus @xmath524 for the pm in the i.i.d . case .",
    "it would be interesting to establish this result and to identify what the scaling is for state - space models .",
    "99 andrieu , c. , doucet , a. and holenstein , r. ( 2010 ) .",
    "particle markov chain monte carlo methods ( with discussion ) .",
    "_ journal of the royal statistical society , series _ b * 72 * , 269342 .",
    "andrieu , c. , doucet , a. and lee , a. ( 2012 ) .",
    "discussion of constructing summary statistics for approximate bayesian computation : semi - automatic approximate bayesian computation  by p. fearnhead and d. prangle . _ journal of the royal statistical society , series _ b * 72 * , 451452 .",
    "andrieu , c. and roberts g.o .",
    "the pseudo - marginal approach for efficient monte carlo computations . _ the annals of statistics _ * 37 * , 697725 .",
    "andrieu , c. and vihola , m. ( 2015 ) .",
    "convergence properties of pseudo - marginal markov chain monte carlo algorithms . _",
    "the annals of applied probability _ * 25 * , 10301077 .",
    "beaumont , m. ( 2003 ) .",
    "estimation of population growth or decline in genetically monitored populations",
    ". _ genetics _ * 164 * , 11391160 .",
    "brard , j. , del moral , p. and  doucet , a. ( 2014 ) . a lognormal central limit theorem for particle approximations of normalizing constants . _ electronic journal of probability _ * 19 * , 128 .",
    "berti , p. , pratelli , l. and rigo , p. ( 2006 ) .",
    "almost sure weak convergence of random probability measures .",
    "_ stochastics _ * 78 * , 9197 .",
    "billingsley , p. ( 1968 ) .",
    "_ convergence of probability measures_. wiley :  new york .",
    "capp , o. , moulines , e. and ryden , t. ( 2005 ) .",
    "_ inference in hidden markov models_. springer - verlag :  new york .",
    "carpenter , j. , p. clifford and fearnhead , p. ( 1999 ) . improved particle filter for nonlinear problems .",
    "_ ieee proceedings - f _ * 146 * , 27 .",
    "ceperley , d.m . and dewing , m. ( 1999 ) .",
    "the penalty method for random walks with uncertain energies .",
    "_ journal of chemical physics _",
    "* 110 * , 98129820 .",
    "chopin , n. , jacob , p.e . and papaspiliopoulos , o. ( 2013 ) .",
    "smc@xmath525 : an efficient algorithm for sequential analysis of state space models .",
    "_ journal of the royal statistical society , series _ b * 75 * , 397426 .",
    "del moral , p. ( 2004 ) .",
    "_ feynman - kac formulae : genealogical and interacting particle systems with applications_. springer - verlag :  new york .",
    "doucet , a. , p.e .",
    "jacob and s. rubenthaler ( 2013 ) . derivative - free estimation of the score vector and observed information matrix with applications to state - space models .",
    "arxiv:1304:5768 .",
    "doucet , a. , pitt , m.k . ,",
    "deligiannidis , g. and  kohn , r. ( 2015 ) .",
    "efficient implementation of markov chain monte carlo when using an unbiased likelihood estimator .",
    "_ _  biometrika  _ _ * * 102 * * , 295 - 313 .",
    "flury , t. and  shephard , n. ( 2011 ) .",
    "bayesian inference based only on simulated likelihood : particle filter analysis of dynamic economic models .",
    "_ econometric theory _ * 27 * , 933956 .",
    "gentil , i. and rmillard , b. ( 2008 ) . using systematic sampling selection for monte carlo solutions of feynman - kac equations .",
    "_ advances in applied probability _ * 40 * , 454 - 472 .",
    "gerber , m. and chopin , n. ( 2015 ) .",
    "sequential quasi monte carlo ( with discussion ) . _ journal of the royal statistical society , series _ b * 77 * , 509 - 579 .",
    "geyer , c.j .",
    "conditioning in markov chain monte carlo .",
    "_ journal of computational and graphical statistics _ * 4 * , 148 - 154 .",
    "gordon , n. j. , salmond , d. and smith , a.f.m .",
    "novel approach to nonlinear / non - gaussian bayesian state estimation .",
    "_ iee proceedings f _ , * 140 * , 107113 .",
    "hall , j. , pitt , m.k . and",
    "kohn , r. ( 2014 ) .",
    "bayesian inference for nonlinear structural time series models .",
    "_ journal of econometrics _ * 179 * , 134151 .",
    "ionides , e.l .",
    ", breto ,  c. and king , a.a .",
    "( 2006 ) .",
    "inference for nonlinear dynamical systems .",
    "_ proceedings of the national academy of science usa _ * 103 * , 1843818443 .",
    "kipnis , c. and varadhan s. r. ( 1986 ) .",
    "central limit theorem for additive functionals of reversible markov processes and applications to simple exclusions .",
    "_ communications in mathematical physics _ * 104 * , 1 - 19 .",
    "lee , a. ( 2008 ) . towards smooth particle filters for likelihood estimation with multivariate latent variables .",
    "thesis , department of computer science , university of british columbia .",
    "lee , a. and  holmes , c.c .",
    "( 2010 ) .",
    "discussion of particle markov chain monte carlo methods  by c. andrieu , a. doucet and r. holenstein . _ journal of the royal statistical society , series _ b * 72 * , 327 .",
    "lin , l. , liu , k.f . , sloan , j. ( 2000 ) .",
    "a noisy monte carlo algorithm . _ physical review d _ * 61 * , 074505 .",
    "lindsten , f. and doucet , a. ( 2016 ) .",
    "pseudo - marginal hamiltonian monte carlo .",
    "forthcoming .",
    "lindsten , f. , jordan , m.i . and schn , t.b .",
    "particle gibbs with ancestor sampling .",
    "_ journal of machine learning research _ * 15 * , 21452184 .",
    "liu , j.s .",
    "_ monte carlo strategies in scientific computing_. springer - verlag , new york .",
    "malik , s. and pitt , m.k .",
    "particle filters for continuous likelihood evaluation and maximisation . _ journal of econometrics _ * 165 * , 190 - 209 .    moon , b. , jagadish , h. v. , faloutsos , c. and saltz , j. h. ( 2001 )",
    ". analysis of the clustering properties of the hilbert space - filling curve .",
    "_ ieee transactions on knowledge and data engineering _ , * 13 * , 124141 .",
    "murray , l. m. , jones , e. m. and parslow , j. ( 2013 ) . on disturbance state - space models and the particle marginal metropolis ",
    "hastings sampler .",
    "_ siam / asa journal of uncertainty quantification _ * 1 * , 494521",
    ".    nicholls , g.k . , fox , c. and  watt , a.m. ( 2012 ) . coupled mcmc  with a randomized acceptance probability .",
    "arxiv preprint arxiv:1205.6857 .",
    "papaspiliopoulos , o. , roberts , g.o . and",
    "skld , m. ( 2007 ) . a general framework for the parametrization of hierarchical models .",
    "_ statistical science _ * 22 * , 5973 .",
    "peskun , p.h .",
    "optimum monte ",
    "carlo sampling using markov chains .",
    "_ biometrika _ * 60 * , 607612 .",
    "pitt , m.k . and",
    "shephard , n. ( 1999 ) .",
    "filtering via simulation : auxiliary particle filters . _ journal of the american statistical association _ * 94 * , 590 - 599 .",
    "pitt , m.k . , silva , r. , giordani , p. and kohn , r. ( 2012 ) . on some properties of markov chain monte carlo simulation methods based on the particle filter .",
    "_ journal of econometrics _ * 171 * , 134151 .",
    "roberts , g.o . , gelman , a. and gilks , w.r . ( 1997 ) .",
    "weak convergence and optimal scaling of random walk metropolis algorithms . _",
    "the annals of applied probability _ * 7 * , 110120 .",
    "sherlock , c. , thiery , a. , roberts , g.o . and",
    "rosenthal , j.s .",
    "( 2015 ) . on the efficiency of pseudo - marginal random walk metropolis algorithms . _",
    "the annals of statistics _ * 43 * , 238275 .",
    "stein , c.m .",
    "estimation of the mean of a multivariate normal distribution . _",
    "the annals of statistics _ * 9 * , 11351151 .",
    "tierney , l. ( 1998 ) . a note on metropolis ",
    "hastings kernels for general state spaces . _",
    "the annals of applied probability _ * 8 * , 19 .",
    "van der vaart , a.w .",
    "_ asymptotic statistics_. cambridge university press .",
    "whiteley , n. , andrieu , c. and doucet , a. ( 2010 ) efficient bayesian inference for switching state - space models using discrete particle markov chain monte carlo methods .",
    "arxiv preprint arxiv:1011.2437 .",
    "zakai , m. ( 1967 ) . some moment inequalities for stochastic integrals and for solutions of stochastic differential equations .",
    "_ israel journal of mathematics _ * 5 * , 170176 .",
    "we define a reference probability space @xmath526 which supports the following random variables :    1 .",
    "@xmath528 independent and identically distributed @xmath529 random variables ; 3 .",
    "@xmath530 where the @xmath531 are mutually independent , @xmath532dimensional standard brownian motions .",
    "we set @xmath533 and @xmath534 where @xmath535 denotes the wiener measure on @xmath536 where @xmath536 is the space of @xmath537- valued continuous paths on @xmath538 .",
    "let @xmath539 where @xmath540 where @xmath541 is @xmath88-valued and @xmath542 the associated borel @xmath186-algebra .",
    "then we consider the product space @xmath543 where @xmath544 and @xmath545 the product measure .    in most cases we will be working with the probability measure @xmath546 capturing the stationary regime , which is defined as follows .",
    "for every @xmath547 and sequence of observations @xmath548 , we define the probability measure @xmath549 by @xmath550 and let @xmath551 let @xmath552 , @xmath553 and @xmath202 , @xmath203 will denote expectation and variance under @xmath546 and @xmath206 respectively .",
    "when @xmath554 is understood fixed , allowing some abuse of notation , we will write @xmath206 to denote the measure @xmath555 and similarly@xmath556 to ease notation , we will often drop the superscript @xmath2 , since we will always be considering variables belonging to the same row .",
    "in addition we will write @xmath0 for @xmath183 in the proofs , omitting the explicit dependence of @xmath183 on @xmath2 . in the proofs of theorem [",
    "theorem : cltmarginal ] and theorem [ theorem : cltlikelihoodratiostandardpseudomarginal ] , we also write @xmath557 and @xmath198 instead of @xmath558 and @xmath195 .",
    "notice that @xmath559 is independent of @xmath2 as @xmath560 under @xmath206 .",
    "the starting point of our analysis is the following decomposition@xmath561 with @xmath562 we will denote by @xmath563 the @xmath408 order cumulant of the normalized importance weight @xmath564 given in ( [ eq : normalisedisweight ] ) under @xmath206 and by @xmath565 its variance , so that @xmath566.@xmath1these expressions are indeed independent of @xmath2 as @xmath567 under @xmath206 .",
    "we first establish three preliminary lemmas .",
    "[ lemma : momentsofepsilonunderproposal]the terms @xmath568 are independent with for any @xmath4 , @xmath569 and @xmath570 where @xmath571 denotes the @xmath572th - order cumulant of @xmath573 and @xmath574 .",
    "the proof of lemma [ lemma : momentsofepsilonunderproposal ] follows from direct calculations so it is omitted .",
    "[ lemma : marcinkiewicz]for any @xmath575 @xmath576 implies @xmath577 .    _ proof of lemma [ lemma : marcinkiewicz ] . _",
    "it follows from the marcinkiewicz - zygmund and jensen inequalities that there exists a constant @xmath578 such that@xmath579 \\\\ &   \\leq b\\left (   k\\right )   \\widetilde{\\mathbb{e}}\\left [   \\left\\vert \\frac { 1}{n}\\sum_{i=1}^{n}\\left\\ {   \\varpi\\left (   y_{1},u_{1,i};\\theta\\right ) -1\\right\\ }   ^{2}\\right\\vert ^{k/2}\\right ] \\\\ &   \\leq b\\left (   k\\right )   \\frac{1}{n}\\sum_{i=1}^{n}\\widetilde{\\mathbb{e}% } \\left [   \\left\\vert \\varpi\\left (   y_{1},u_{1,i};\\theta\\right )   -1\\right\\vert ^{k}\\right ] \\\\ &   = b\\left (   k\\right )   \\widetilde{\\mathbb{e}}\\left [   \\left\\vert \\varpi\\left ( y_{1},u_{1,1};\\theta\\right )   -1\\right\\vert ^{k}\\right]\\end{aligned}\\ ] ] and by the c@xmath580 inequality there exists @xmath581 such that @xmath582   \\leq c\\left (   k\\right )   \\left [ \\widetilde{\\mathbb{e}}\\left (   \\varpi\\left (   y_{1},u_{1,1};\\theta\\right ) ^{k}\\right )   + 1\\right ]   .\\ ] ]    [ lemma : wlln]consider the triangular array @xmath583 and let @xmath584 . if for some @xmath585 , @xmath586 then we have@xmath587 if @xmath588 then for any @xmath589 we have @xmath590    _ _ proof of lemma [ lemma : wlln ] .",
    "_ _ the results ( [ eq : wlln1 ] ) follows directly from the weak law of large numbers ( wlln )  applied to the triangular array @xmath591 ; see e.g. ( * ? ? ?",
    "* proposition 9.5.5 . ) .",
    "this results holds as @xmath592 so , from lemma [ lemma : marcinkiewicz ] , we have @xmath593 . for the second result ( [ eq : wlnnscale1 ] ) , we have for any @xmath594 @xmath595   \\right ) ^{2}\\right ]   } { t^{(1+\\lambda)}\\epsilon^{2}}\\\\ &   = \\frac{\\widetilde{\\mathbb{e}}\\left (   \\left [   \\varepsilon_{n}\\left ( y_{1};\\theta\\right )   ^{k}-\\widetilde{\\mathbb{e}}\\left (   \\varepsilon_{n}\\left ( y_{1};\\theta\\right )   ^{k}\\right )   \\right ]   ^{2}\\right )   } { t^{\\lambda}% \\epsilon^{2}}\\\\ &   \\rightarrow0.\\end{aligned}\\ ] ]    we can now give the proof of theorem [ theorem : cltmarginal ] part 1 .    _ _ proof of theorem [ theorem : cltmarginal ] part 1 .  _",
    "_ we first perform a fourth order taylor expansion of each term appearing in ( [ eq : loglikelihooderror ] ) , i.e. @xmath596 where@xmath597 with @xmath598 we need to ensure that these taylor expansions are valid for @xmath267 so we control the probability of the event @xmath599 .",
    "we have for any @xmath594 @xmath600 because @xmath223 under assumption , then the complementary event satisfies for @xmath601 @xmath602 on the event @xmath603 , the taylor expansion ( [ eq : taylor ] ) holds for all @xmath267 so we can write @xmath604 where the @xmath605 arises from substituting @xmath606 to @xmath607 .",
    "we first control the remainder ( [ eq : remainder ] ) , using the fact that ( [ eq : remainderexpression ] ) can be controlled on the event @xmath608 , as follows@xmath609 the wlln for triangular arrays holds by a similar argument to lemma [ lemma : wlln ] so we have @xmath610 hence as @xmath601 , we have @xmath611    the term on the r.h.s . of ( [ eq : firstterm ] ) satisfies a conditional clt  for triangular arrays ; see lemma [ lem : conditionallindebergclt ] .",
    "indeed , we have for any @xmath594 @xmath612    &   = \\widetilde{\\mathbb{e}}\\left [   \\epsilon^{2}\\sum_{t=1}% ^{t}\\widetilde{\\mathbb{e}}\\left (   \\left .   \\frac{\\varepsilon_{n}\\left ( y_{t};\\theta\\right )   ^{2}}{\\epsilon^{2}t}\\mathbb{i}_{\\left\\ {   \\left\\vert \\varepsilon_{n}\\left (   y_{t};\\theta\\right )   \\right\\vert \\geq\\sqrt{t}% \\epsilon\\right\\ }   } \\right\\vert \\mathcal{y}^{t}\\right )   \\right ] \\label{eq : checkinglindeberg}\\\\ &   \\leq\\epsilon^{2}\\sum_{t=1}^{t}\\widetilde{\\mathbb{e}}\\left (   \\frac { \\varepsilon_{n}\\left (   y_{t};\\theta\\right )   ^{4}}{\\epsilon^{4}t^{2}}\\right ) \\nonumber\\\\ &   = \\frac{1}{t\\epsilon^{2}}\\widetilde{\\mathbb{e}}\\left (   \\varepsilon _ { n}\\left (   y_{t};\\theta\\right )   ^{4}\\right ) \\nonumber\\\\ &   = \\frac{1}{t\\epsilon^{2}}\\left\\ {   3\\gamma^{4}\\left (   \\theta\\right ) + \\frac{\\rho_{4}\\left (   \\theta\\right )   } { n}\\right\\ } \\nonumber\\\\ &   \\rightarrow0,\\nonumber\\end{aligned}\\ ] ] so the following conditional lindeberg condition holds@xmath613 as ( [ eq : secondordermoment ] ) holds , by the strong law of large numbers ( slln ) , the limiting variance is given by @xmath614    lemma [ lemma : wlln ] shows that the second term ( [ eq : secondterm ] ) satisfies @xmath615 while the third term ( [ eq : thirdterm ] ) satisfies @xmath616 hence it vanishes for @xmath617 . similarly , lemma [ lemma : wlln ] and ( [ eq : fourthordermoment ] )",
    "show that @xmath618 where @xmath619 for any @xmath620    the term @xmath621 is asymptotically equivalent in distribution to the sum of the terms ( [ eq : firstterm ] ) , ( [ eq : secondterm ] ) , ( [ eq : thirdterm ] ) , ( [ eq : fourthterm ] ) and ( [ eq : remainder ] ) . by combining ( [ eq : probataylorvalid ] ) to the fact that ( [ eq : firstterm ] ) satisfies a conditional clt , ( [ eq : cvsecondterminproba ] ) , ( [ eq : cvthirdterminproba ] ) , ( [ eq : cvfourthterminproba ] ) , ( [ eq : remaindergoestozero ] ) hold and lemma [ propn1 ] , the result follows .",
    "it follows directly from our proof that for @xmath622@xmath623      [ lemma : relationshipmomentproposalequilibrium]for any @xmath4 and integer @xmath624 , if @xmath625   < \\infty$ ] then @xmath626   < \\infty$ ] and @xmath627 = \\widetilde{\\mathbb{e}}\\left [   \\varepsilon_{n}\\left (   y;\\theta\\right ) ^{k}\\right ]   + \\frac{1}{\\sqrt{n}}\\widetilde{\\mathbb{e}}\\left [   \\varepsilon _ { n}\\left (   y;\\theta\\right )   ^{k+1}\\right ]   .\\ ] ]    _ proof of lemma [ lemma : relationshipmomentproposalequilibrium ] .",
    "_ we have @xmath628    & = \\frac{1}{n^{k/2}}% % tcimacro{\\didotsint } % % beginexpansion { \\displaystyle\\idotsint } % endexpansion \\left [   \\sum_{i=1}^{n}\\left\\ {   \\varpi\\left (   y , u_{1,i};\\theta\\right ) -1\\right\\ }   \\right ]   ^{k}\\overline{\\pi}(\\mathrm{d}u_{1,1:n}|\\theta)\\\\ &   = \\frac{1}{n^{1+k/2}}% % tcimacro{\\didotsint } % % beginexpansion { \\displaystyle\\idotsint } % endexpansion \\left [   \\sum_{i=1}^{n}\\left\\ {   \\varpi\\left (   y , u_{1,i};\\theta\\right ) -1\\right\\ }   \\right ]   ^{k}\\left [   n+\\sum_{i=1}^{n}\\left\\ {   \\varpi\\left ( y , u_{1,i};\\theta\\right )   -1\\right\\ }   \\right ] % tcimacro{\\dprod \\nolimits_{j=1}^{n}}% % beginexpansion { \\displaystyle\\prod\\nolimits_{j=1}^{n } } % endexpansion \\varphi\\left (   \\mathrm{d}u_{1,j};0_{p},i_{p}\\right ) \\\\ &   = \\frac{1}{n^{k/2}}% % tcimacro{\\didotsint } % % beginexpansion { \\displaystyle\\idotsint } % endexpansion \\left [   \\sum_{i=1}^{n}\\left\\ {   \\varpi\\left (   y , u_{1,i};\\theta\\right ) -1\\right\\ }   \\right ]   ^{k}% % tcimacro{\\dprod \\nolimits_{j=1}^{n}}% % beginexpansion { \\displaystyle\\prod\\nolimits_{j=1}^{n } } % endexpansion \\varphi\\left (   \\mathrm{d}u_{1,j};0_{p},i_{p}\\right ) \\\\ &   + \\frac{1}{n^{1+k/2}}% % tcimacro{\\didotsint } % % beginexpansion { \\displaystyle\\idotsint } % endexpansion \\left [   \\sum_{i=1}^{n}\\left\\ {   \\varpi\\left (   y , u_{1,i};\\theta\\right ) -1\\right\\ }   \\right ]   ^{k+1}% % tcimacro{\\dprod \\nolimits_{j=1}^{n}}% % beginexpansion { \\displaystyle\\prod\\nolimits_{j=1}^{n } } % endexpansion \\varphi\\left (   \\mathrm{d}u_{1,j};0_{p},i_{p}\\right ) \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\varepsilon_{n}\\left (   y;\\theta\\right ) ^{k}\\right ]   + \\frac{1}{\\sqrt{n}}\\widetilde{\\mathbb{e}}\\left [   \\varepsilon _ { n}\\left (   y;\\theta\\right )   ^{k+1}\\right ]   .\\end{aligned}\\ ] ]    in particular , by combining lemma [ lemma : momentsofepsilonunderproposal ] and lemma [ lemma : relationshipmomentproposalequilibrium ] , we obtain @xmath629    & = \\frac{\\gamma^{2}\\left (   y;\\theta\\right )   } { \\sqrt{n}},\\text { } % \\label{eq : equilibriumfirstordermoment}\\\\ \\mathbb{e}\\left [   \\varepsilon_{n}\\left (   y;\\theta\\right )   ^{2}\\right ]    & = \\gamma^{2}\\left (   y;\\theta\\right )   + \\frac{\\rho_{3}\\left (   y;\\theta\\right ) } { n},\\label{eq : equilibriumsecondordermoment}\\\\ \\mathbb{e}\\left [   \\varepsilon_{n}\\left (   y;\\theta\\right )   ^{3}\\right ]    & = \\frac{3\\gamma^{4}\\left (   y;\\theta\\right )   + \\rho_{3}\\left (   y;\\theta\\right ) } { \\sqrt{n}}+\\frac{\\rho_{4}\\left (   y;\\theta\\right )   } { n\\sqrt{n}}% ,",
    "\\label{eq : equilibriumthirdordermoment}\\\\ \\mathbb{e}\\left [   \\varepsilon_{n}\\left (   y;\\theta\\right )   ^{4}\\right ]    & = 3\\gamma^{4}\\left (   y;\\theta\\right )   + \\frac{\\rho_{4}\\left (   y;\\theta\\right ) + 10\\rho_{2}\\left (   y;\\theta\\right )   \\rho_{3}\\left (   y;\\theta\\right )   } % { n}+\\frac{\\rho_{5}\\left (   y;\\theta\\right )   } { n^{2}}. \\label{eq : equilibriumfourthordermoment}%\\end{aligned}\\ ] ] similarly , we have @xmath630   = \\gamma^{2}\\left (   \\theta\\right )   /\\sqrt{n},$ ] @xmath631 = \\gamma^{2}\\left (   \\theta\\right )   + \\rho_{3}\\left (   \\theta\\right )   /n$ ] , etc .    we can now give the proof of theorem [ theorem : cltmarginal ] part 2 . for @xmath236 ,",
    "it is possible to combine theorem _ [ theorem : cltmarginal ] _ part 1 to a uniform integrability argument to establish this result but this argument does not extend to @xmath237 .",
    "_ _ proof of theorem [ theorem : cltmarginal ] part 2 .",
    "_ _ the proof of this clt is very similar to the proof of theorem [ theorem : cltmarginal ]  part 1 so we skip some details .",
    "we again first perform a fourth order taylor expansion of each term appearing in ( [ eq : loglikelihooderror ] ) , i.e. see ( [ eq : taylor ] ) and ( [ eq : remainderexpression ] ) . we also need to ensure that these taylor expansions are valid for @xmath267 so we need to control the probability of the event @xmath632 .",
    "we have for any @xmath594 @xmath633 because @xmath634 holds and lemma [ lemma : relationshipmomentproposalequilibrium ] then @xmath635 for @xmath601 . on the event @xmath636 , the taylor expansion ( [ eq : taylor ] ) holds for all @xmath267",
    "so we can similarly decompose @xmath637 as the sum of the terms ( [ eq : firstterm ] ) , ( [ eq : secondterm ] ) , ( [ eq : thirdterm ] ) , ( [ eq : fourthterm ] ) , ( [ eq : remainder ] ) and an additional @xmath638 term .",
    "we can show that as @xmath601 the remainder vanishes @xmath639 because the wlln for triangular arrays holds so we have @xmath640 using ( [ eq : equilibriumfirstordermoment ] ) , we can rewrite the first term ( [ eq : firstterm ] ) as follows@xmath641 the r.h.s . of ( [ eq : firsttermdecomposition1 ] ) satisfies a conditional clt ,",
    "see lemma [ lem : conditionallindebergclt ] , as the conditional lindeberg condition holds using arguments similar to ( [ eq : checkinglindeberg ] ) as @xmath642 .",
    "by lemma [ lemma : relationshipmomentproposalequilibrium ] and the slln , the limiting variance is given by @xmath643 almost surely , ( [ eq : equilibriumfirstordermoment])-([eq : equilibriumsecondordermoment ] ) and using the assumption @xmath644   < \\infty$ ] .",
    "the term ( [ eq : firsttermdecomposition2 ] ) satisfies @xmath645 by the slln , the assumption @xmath250   < \\infty$ ] and chebyshev s inequality .",
    "finally we have for ( [ eq : firsttermdecomposition3])@xmath646 for the second term ( [ eq : secondterm ] ) , using ( [ eq : equilibriumsecondordermoment ] ) , we obtain using lemma [ lemma : wlln ] @xmath647 where the third term on the l.h.s .",
    "vanishes for @xmath648 for the third term ( [ eq : thirdterm ] ) , we obtain using ( [ eq : equilibriumthirdordermoment ] ) and lemma [ lemma : wlln ] @xmath649 so the third term ( [ eq : thirdterm ] ) on the r.h.s . vanishes for @xmath650 . finally for the fourth term ( [ eq : fourthterm ] ) , we obtain using ( [ eq : equilibriumfourthordermoment ] ) and lemma [ lemma : wlln ] @xmath651 where @xmath652 and @xmath653 for any @xmath620    the term @xmath621 is asymptotically equivalent in distribution to the sum of the terms ( [ eq : firstterm ] ) , ( [ eq : secondterm ] ) , ( [ eq : thirdterm ] ) , ( [ eq : fourthterm ] ) and ( [ eq : remainder ] ) . by combining ( [ eq : probataylorvalid2 ] ) to the fact that ( [ eq : firsttermdecomposition1 ] ) satisfies a conditional clt , ( [ eq : firsttermdecomposition2converges ] ) , ( [ eq : remainderfirstterm ] ) , ( [ eq : cvsecondterminproba2 ] ) , ( [ eq : cvthirdterminproba2 ] ) , ( [ eq : cvfourthterminproba2 ] ) , ( [ eq : remaindergoestozero2 ] ) and lemma [ propn1 ] , the result follows .",
    "it follows directly from our proof that for @xmath622@xmath654    we also note that if we assume that higher order moments of @xmath655 under @xmath206 are finite then we obtain different expressions in the clt for @xmath656 where @xmath657 .",
    "for ease of presentation , we only give the proof when @xmath12 is a scalar parameter , the multivariate extension is straightforward .",
    "we have @xmath658 with @xmath659 .",
    "we define @xmath660 with @xmath258 .",
    "the result will follow by the arguments used in the proof of theorem  [ theorem : cltmarginal ] , replacing @xmath661   , \\ ] ] with @xmath662 we make here the dependence of @xmath663 on @xmath197 or @xmath664 explicit .",
    "we need to check that the moment conditions used for @xmath663 carry over to @xmath665 .",
    "we have by the @xmath666 inequality and lemma  [ lemma : relationshipmomentproposalequilibrium ] @xmath667 as @xmath668 and @xmath669 are continuous by assumption , it is straightforward to check that lower order moments are also continuous . therefore for all @xmath2 large enough @xmath670 and similar results hold for lower order moments .",
    "we use a taylor expansion similarly to theorem  [ theorem : cltmarginal ] part 1 and part 2 , @xmath671 \\\\ &   -\\frac{1}{2\\beta t^{\\left (   1+\\alpha\\right )   /2}}\\sum_{t=1}^{t}\\left [ \\varepsilon_{n}\\left (   y_{t},v_{t};\\theta+\\xi/\\sqrt{t}\\right )   ^{2}% -\\varepsilon_{n}\\left (   y_{t},u_{t};\\theta\\right )   ^{2}\\right ] \\\\ &   + \\frac{1}{3\\beta^{3/2}t^{\\left (   1 + 2\\alpha\\right )   /2}}\\sum_{t=1}% ^{t}\\left [   \\varepsilon_{n}\\left (   y_{t},v_{t};\\theta+\\xi/\\sqrt{t}\\right ) ^{3}-\\varepsilon_{n}\\left (   y_{t},u_{t};\\theta\\right )   ^{3}\\right ] \\\\ &   -\\frac{1}{4\\beta^{2}t^{\\left (   1 + 3\\alpha\\right )   /2}}\\sum_{t=1}^{t}\\left [ \\varepsilon_{n}\\left (   y_{t},v_{t};\\theta+\\xi/\\sqrt{t}\\right )   ^{4}% -\\varepsilon_{n}\\left (   y_{t},u_{t};\\theta\\right )   ^{4}\\right ] \\\\ &   + \\frac{1}{t^{\\left (   1-\\alpha\\right )   /2}}\\sum_{t=1}^{t}r_{t , n}^{\\prime } \\left (   y_{t};\\theta,\\xi\\right )   + o_{\\overline{\\mathbb{p}}}\\left (   1\\right ) , \\end{aligned}\\ ] ] where @xmath672 denotes the probability over @xmath673 @xmath674 and @xmath256 and @xmath675 the associated expectation . by inspecting the proofs of theorem  [ theorem :",
    "cltmarginal ] part 1 and part 2 , we can rewrite this as @xmath676 \\label{eq : clttermtheorem3}\\\\ &   \\qquad-\\frac{1}{2\\beta t^{\\left (   1+\\alpha\\right )   /2}}\\sum_{t=1}% ^{t}\\left [   \\varepsilon_{n}\\left (   y_{t},v_{t};\\theta+\\xi/\\sqrt{t}\\right ) ^{2}-\\varepsilon_{n}\\left (   y_{t},u_{t};\\theta\\right )   ^{2}\\right ] + o_{\\overline{\\mathbb{p}}}\\left (   1\\right )   .",
    "\\label{eq : constanttermtheorem3}%\\end{aligned}\\ ] ] the term ( [ eq : clttermtheorem3 ] ) satisfies a conditional clt  for triangular arrays ( lemma [ lem : conditionallindebergclt ] ) as the conditional lindeberg condition is verified @xmath677 \\\\ &   = \\overline{\\mathbb{e}}\\left [   \\epsilon^{2}\\sum_{t=1}^{t}\\overline { \\mathbb{e}}\\left (   \\left .",
    "\\frac{\\left\\ {   \\varepsilon_{n}\\left (   y_{t}% , v_{t};\\theta+\\xi/\\sqrt{t}\\right )   -\\varepsilon_{n}\\left (   y_{t},u_{t}% ; \\theta\\right )   \\right\\ }   ^{2}}{\\epsilon^{2}t}\\mathbb{i}_{\\left\\ {   \\left\\vert \\varepsilon_{n}\\left (   y_{t};\\theta\\right )   -\\varepsilon_{n}\\left ( y_{t},u_{t};\\theta\\right )   \\right\\vert \\geq\\sqrt{t}\\epsilon\\right\\ } } \\right\\vert \\mathcal{y}^{t}\\right )   \\right ] \\\\ &   \\leq\\frac{1}{t\\epsilon^{2}}\\overline{\\mathbb{e}}\\left (   \\left\\ { \\varepsilon_{n}\\left (   y_{t},v_{t};\\theta+\\xi/\\sqrt{t}\\right )   -\\varepsilon _ { n}\\left (   y_{t},u_{t};\\theta\\right )   \\right\\ }   ^{4}\\right ) \\\\ &   \\leq\\frac{c}{t\\epsilon^{2}}\\left\\ {   \\mathbb{e}\\left (   \\varepsilon _ { n}\\left (   y_{t},u_{t};\\theta\\right )   ^{4}\\right )   + \\widetilde{\\mathbb{e}% } \\left (   \\varepsilon_{n}\\left (   y_{t},v_{t};\\theta+\\xi/\\sqrt{t}\\right ) ^{4}\\right )   \\right\\ } \\\\ &   \\rightarrow0,\\end{aligned}\\ ] ] so @xmath678 and the limiting variance is given by @xmath679 as @xmath680   = 0 $ ] .",
    "now we have @xmath681 by the slln as @xmath682   < \\infty$ ] .",
    "we also have by the wlln  for triangular arrays that @xmath683 and @xmath684   } \\left\\vert \\frac{\\partial \\gamma^{2}\\left (   \\vartheta\\right )   } { \\partial\\vartheta}\\right\\vert \\rightarrow0 .",
    "\\label{eq : remainderingammavanishes}%\\ ] ] now we have already seen in the proof of theorem  [ theorem : cltmarginal ] , equation ( [ eq : cvsecondterminproba ] ) , that @xmath685 and using a similar argument as the one used in the proof of ( [ eq : cltexpressionmarginalequilibrium ] ) in theorem [ theorem : cltmarginal ] , equation ( [ eq : cvsecondterminproba2 ] ) , we have @xmath686 as @xmath617 and ( [ eq : remainderingammavanishes ] ) holds .",
    "hence ( [ eq : clttermtheorem3 ] ) satisfies a conditional clt  of limiting variance @xmath687 as ( [ eq : variationingamma])-([eq : remainderingammavanishes ] ) hold while ( [ eq : constanttermtheorem3 ] ) plus @xmath688 converges to zero in probability so the result follows from lemma [ propn1 ] .        for @xmath689",
    ", we have @xmath690 and we can write for @xmath144 and @xmath267 @xmath691 it will prove convenient for our proof to embed this discrete - time autoregressive process within the following the following ornstein - uhlenbeck process @xmath692 where @xmath557 are independent @xmath532dimensional standard brownian motions for @xmath144 and @xmath267 . it is easy to check that we can set equivalently @xmath693 as the value of the ornstein - uhlenbeck process at time @xmath694 which has been initialized at time @xmath695 using @xmath696    whenever it is clear , we will drop the @xmath2 index to keep the notation reasonable .",
    "we define@xmath697 where the full notation shall be retained when evaluating at the proposal @xmath698 .",
    "@xmath699 let @xmath700 be the sigma - algebra spanned by @xmath701 where @xmath702 and @xmath703 .",
    "let @xmath704   $ ] denotes the expectation w.r.t @xmath705 and the brownian motions @xmath706 where @xmath707 is given by ( [ eq : posteriorpanelfactorizes ] ) whereas @xmath708   $ ] denotes the expectation w.r.t @xmath709 and the brownian motions @xmath710 . finally , we define the stein operator @xmath711 for a real - valued function @xmath712@xmath713      [ ass : momentsofw ] there exists @xmath594 such that @xmath714   < \\infty.\\ ] ]    [ ass : dthetafubini]there exists @xmath715 such that @xmath716 is continuous at @xmath717 @xmath718 for all @xmath719 , and@xmath720   < \\infty.\\ ] ]    [ ass : dustein ] we have@xmath721   < \\infty.\\ ] ]    [ ass : steindu ] we have @xmath722",
    "< \\infty.\\ ] ]    [ ass : du4moments ] there exists @xmath723 such that@xmath724   < \\infty.\\ ] ]    [ ass : dusteinfourthmoment ] we have@xmath725   < \\infty.\\ ] ]      to simplify the presentation of the proof , we only consider the case where @xmath12 is a scalar parameter , the dimension of @xmath195 is @xmath726 and @xmath727 , the multivariate extension is straightforward although much more tiedous .",
    "let @xmath246 . notice that by definition of @xmath728 and a taylor expansion we have @xmath729^{2}+\\sum_{t=1}^{t}h(\\eta_{t}^{t})[\\eta_{t}^{t}]^{2},\\end{aligned}\\ ] ] as @xmath730 with @xmath731 as @xmath732 .",
    "the proof proceeds through several auxiliary lemmas in three main steps .",
    "first , we prove that @xmath733 converges to a zero - mean normal conditional upon @xmath734 .",
    "second , we show that @xmath735 converges in probability towards a constant .",
    "third , we show that high - order terms vanish in probability .",
    "the result then follows from proposition [ propn1 ] .",
    "using it s formula , we decompose further @xmath736 as follows @xmath737 where @xmath738 the following preliminary lemmas establish various properties of @xmath739 @xmath740 @xmath741 and @xmath736 .",
    "[ lem : jt ] the sequence @xmath742 defined in ( [ eq : jtdef ] ) satisfies @xmath743   &   = 0,\\label{eq : meanofjt}\\\\ \\mathbb{v}\\left [   \\sum_{t=1}^{t}j_{t}^{t}\\right ]    &   = t\\mathbb{v}[j_{t}% ^{t}]\\rightarrow0 \\label{eq : sumofvarofjt}%\\end{aligned}\\ ] ] and @xmath744 , @xmath745 .",
    "[ lem : lt ] the sequence @xmath746 defined in ( [ eq : ltdef ] ) satisfies @xmath747   &   = 0,\\label{eq : meanlt}\\\\ \\mathbb{v}\\left [   \\sum_{t=1}^{t}l_{t}^{t}\\right ]    &   = t\\mathbb{v}[l_{t}% ^{t}]\\rightarrow0 , \\label{eq : varlt}%\\end{aligned}\\ ] ] and @xmath748 .",
    "[ lem : mt ] the sequence @xmath749 defined in ( [ eq : mtdef ] ) satisfies @xmath750   &   = o(1/t ) .",
    "\\label{eq : varmt}%\\end{aligned}\\ ] ]    [ lem : zsquared ] the sequence @xmath751 defined in ( [ eq : definitionetat ] ) satisfies @xmath752    armed with the above results we can now prove theorem  [ theorem : conditionalcltthetathetacand ] .",
    "_ proof of theorem  [ theorem : conditionalcltthetathetacand ] . _ combining lemmas  [ lem : jt ] , [ lem : lt ] , [ lem : mt ] and [ lem : zsquared ] with proposition  [ propn1 ] we immediately have that @xmath753   ^{2}\\left\\vert \\mathcal{f}^{t}\\right .",
    "\\rightarrow\\mathcal{n}\\left (   -\\frac{\\kappa^{2}\\left ( \\theta\\right )   } { 2},\\kappa^{2}\\left (   \\theta\\right )   \\right )   .\\ ] ] it remains to control the remainder from the taylor expansion @xmath754^{2}+\\sum_{t=1}^{t}h\\left ( \\eta_{t}^{t}\\right )   [ \\eta_{t}^{t}]^{2},\\ ] ] where @xmath755 .",
    "we can easily bound this using lemma  [ lem : zsquared ] by @xmath756    without loss of generality we can assume that @xmath757 where @xmath758 is increasing on @xmath759 and @xmath760 so that @xmath761 and @xmath762 by using the decomposition of @xmath736 , we have @xmath763 \\\\ &   = o_{p}(1),\\end{aligned}\\ ] ] where for the terms involving @xmath764 , @xmath765 we have used ( [ eq : sumofvarofjt ] ) and ( [ eq : varlt ] ) . the term involving @xmath766 vanishes by uniform integrability of the family @xmath767 , the proof of which can be found in the proof of lemma  [ lem : mt ] where the lindeberg condition is verified .",
    "therefore overall we have @xmath768 and thus @xmath769 hence we have @xmath770 and the result follows .",
    "_ proof of lemma  [ lem : jt ] .",
    "_  we note that @xmath771 . by assumption  [",
    "ass : dthetafubini ] , we can rewrite @xmath772 as follows @xmath773 then we obtain@xmath774 ^{4}\\right )   ^{1/2}\\\\ &   = \\frac{t}{n^{2}}\\widetilde{\\mathbb{e}}\\left (   ( \\widehat{w}_{t}^{t}% ) ^{-2}\\right )   ^{1/2}\\widetilde{\\mathbb{e}}\\left (   \\left [   \\sum_{i=1}^{n}% \\int_{\\theta}^{\\vartheta}\\partial_{\\theta}\\varpi(y_{t},u_{t , i}(\\delta _ { t});\\theta^{\\prime})\\mathrm{d}\\theta^{\\prime}\\right ]   ^{4}\\right )   ^{1/2}\\\\ &   \\leq b\\frac{tn}{n^{2}}\\widetilde{\\mathbb{e}}\\left (   ( \\widehat{w}_{t}% ^{t})^{-2}\\right )   ^{1/2}\\widetilde{\\mathbb{e}}\\left (   \\left [   \\int_{\\theta } ^{\\vartheta}\\partial_{\\theta}\\varpi(y_{1},u_{1,1}(\\delta_{t});\\theta^{\\prime } ) \\mathrm{d}\\theta^{\\prime}\\right ]   ^{4}\\right )   ^{1/2}%\\end{aligned}\\ ] ] since by assumption  [ ass : dthetafubini ] we can interchange derivative and integration , the integrals over @xmath775 are mean zero and under @xmath206 the terms are i.i.d . over index @xmath572",
    "hence , we have using assumptions  [ ass : momentsofw ] and [ ass : dthetafubini ] that for @xmath2 large enough that @xmath776 for @xmath777   $ ] .",
    "when @xmath12 is multidimensional , this can be established using the fundamental theorem of calculus for line integrals .",
    "@xmath778^{4}\\big)^{1/2}\\\\ &   \\leq c\\frac{tn}{n^{2}}\\widetilde{\\mathbb{e}}\\big(\\big[\\int_{\\theta } ^{\\vartheta}\\chi(y_{1},u_{1,1}(\\delta_{t}))\\mathrm{d}\\theta^{\\prime}% \\big]^{4}\\big)^{1/2}\\\\ &   = c\\frac{tn}{n^{2}}\\frac{\\xi^{2}}{t}\\widetilde{\\mathbb{e}}\\big(\\chi ( y_{1},u_{1,1})^{4}\\big)^{1/2}=o\\big(\\frac{1}{n}\\big).\\end{aligned}\\ ] ] _ proof of lemma  [ lem : lt ] .",
    "_ we have @xmath779 where @xmath711 is the stein operator defined in ( [ eq : steinoperator ] ) . by assumption  [ ass : dustein ] , we can apply fubini s theorem to interchange the order of integration , and stein s lemma ( * ? ? ? * lemma 1 ) shows that @xmath780 = \\frac{1}{n}\\sum_{i=1}^{n}\\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\int% _ { 0}^{\\delta_{t}}\\mathcal{s}\\left\\ {   \\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\theta\\right )   \\right\\ }   \\mathrm{d}s\\right\\vert \\mathcal{y}% ^{t}\\right ]   = 0,\\ ] ] so in particular @xmath781   = 0 $ ] .",
    "we have@xmath782 \\\\",
    "&   = \\mathbb{e}\\left [   \\left\\ {   \\int_{0}^{\\delta_{t}}\\frac{1}{n\\widehat{w}% _ { t}^{t}}\\sum_{i=1}^{n}\\mathcal{s}\\left\\ {   \\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\theta\\right )   \\right\\ }   \\mathrm{d}s\\right\\ } ^{2}\\right ] \\\\ &   = \\mathbb{e}\\left [   \\frac{1}{\\left (   n\\widehat{w}_{t}^{t}\\right )   ^{2}}% \\int_{0}^{\\delta_{t}}\\int_{0}^{\\delta_{t}}\\left (   \\sum_{i=1}^{n}% \\mathcal{s}\\left\\ {   \\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\right\\ }   \\right )   \\left (   \\sum_{j=1}^{n}\\mathcal{s}\\left\\ { \\varpi\\left (   y_{t},u_{t , j}^{t}\\left (   r\\right )   ; \\theta\\right )   \\right\\ } \\right )   \\mathrm{d}r\\mathrm{d}s\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\frac{1}{n^{2}\\widehat{w}_{t}^{t}}\\int% _ { 0}^{\\delta_{t}}\\int_{0}^{\\delta_{t}}\\left (   \\sum_{i=1}^{n}\\mathcal{s}% \\left\\ {   \\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right ) \\right\\ }   \\right )   \\left (   \\sum_{j=1}^{n}\\mathcal{s}\\left\\ {   \\varpi\\left ( y_{t},u_{t , j}^{t}\\left (   r\\right )   ; \\theta\\right )   \\right\\ }   \\right ) \\mathrm{d}r\\mathrm{d}s\\right]\\end{aligned}\\ ] ] now we have @xmath783 \\\\ &   = \\int_{0}^{\\delta_{t}}\\int_{0}^{\\delta_{t}}\\widetilde{\\mathbb{e}}\\left [ \\frac{1}{\\widehat{w}_{t}^{t}}\\left (   \\frac{1}{n}\\sum_{i=1}^{n}\\mathcal{s}% \\left\\ {   \\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right ) \\right\\ }   \\right )   \\left (   \\frac{1}{n}\\sum_{j=1}^{n}\\mathcal{s}\\left\\ { \\varpi\\left (   y_{t},u_{t , j}^{t}\\left (   r\\right )   ; \\theta\\right )   \\right\\ } \\right )   \\right ]   \\mathrm{d}r\\mathrm{d}s\\\\ &   \\leq\\int_{0}^{\\delta_{t}}\\int_{0}^{\\delta_{t}}\\widetilde{\\mathbb{e}}\\left [ \\left (   \\widehat{w}_{t}^{t}\\right )   ^{-2}\\right ]   ^{1/2}\\widetilde{\\mathbb{e}% } \\left [   \\left (   \\frac{1}{n}\\sum_{i=1}^{n}\\mathcal{s}\\left\\ {   \\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\right\\ }   \\right ) ^{2}\\left (   \\frac{1}{n}\\sum_{j=1}^{n}\\mathcal{s}\\left\\ {   \\varpi\\left ( y_{t},u_{t , j}^{t}\\left (   r\\right )   ; \\theta\\right )   \\right\\ }   \\right ) ^{2}\\right ]   ^{1/2}\\mathrm{d}r\\mathrm{d}s\\\\ &   \\leq\\int_{0}^{\\delta_{t}}\\int_{0}^{\\delta_{t}}\\widetilde{\\mathbb{e}}\\left [ \\left (   \\widehat{w}_{t}^{t}\\right )   ^{-2}\\right ]   ^{1/2}\\widetilde{\\mathbb{e}% } \\left [   \\left (   \\frac{1}{n}\\sum_{i=1}^{n}\\mathcal{s}\\left\\ {   \\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\right\\ }   \\right ) ^{4}\\right ]   ^{1/4}\\widetilde{\\mathbb{e}}\\left [   \\left (   \\frac{1}{n}\\sum _ { j=1}^{n}\\mathcal{s}\\left\\ {   \\varpi\\left (   y_{t},u_{t , j}^{t}\\left (   r\\right ) ; \\theta\\right )   \\right\\ }   \\right )   ^{4}\\right ]   ^{1/4}\\mathrm{d}r\\mathrm{d}s\\\\ &   = \\int_{0}^{\\delta_{t}}\\int_{0}^{\\delta_{t}}\\widetilde{\\mathbb{e}}\\left [ \\left (   \\widehat{w}_{t}^{t}\\right )   ^{-2}\\right ]   ^{1/2}\\widetilde{\\mathbb{e}% } \\left [   \\left (   \\frac{1}{n}\\sum_{i=1}^{n}\\mathcal{s}\\left\\ {   \\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\right\\ }   \\right ) ^{4}\\right ]   ^{1/2}\\mathrm{d}r\\mathrm{d}s\\\\ &   \\leq o\\left (   \\frac{\\delta_{t}^{2}}{n}\\right )   , \\end{aligned}\\ ] ] by assumption  [ ass : dusteinfourthmoment ] , @xmath784   = 0 $ ] , and the fact that @xmath785 are stationary and independent over @xmath572 under @xmath206 .",
    "therefore we have @xmath786   = t\\mathbb{v}\\left [ l_{1}^{t}\\right ]   = o\\left (   \\frac{\\delta_{t}^{2}}{n}t\\right )   = o\\left ( \\frac{n}{t}\\right )   .\\ ] ]    _ proof of lemma  [ lem : mt ] .",
    "_  we now consider the term @xmath787 given by ( [ eq : mtdef ] ) which can be decomposed as@xmath788 where @xmath789 we will exploit the fact that conditionally on @xmath264 all the terms appearing in this double sum are independent under @xmath206 .",
    "it is straightforward to see that @xmath790 = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\frac{\\sqrt{2}}{n}\\sum_{i=1}^{n}% \\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\theta\\right )   \\mathrm{d}b_{t , i}\\left (   s\\right )   \\right\\vert \\mathcal{f}^{t}\\right ]   = 0\\ ] ] and that @xmath791 = \\sum_{t=1}^{t}\\mathbb{v}\\left [   \\left .",
    "m_{t}^{t}\\right\\vert \\mathcal{f}% ^{t}\\right ]   .",
    "\\label{eq : definitionstsquared}%\\ ] ] we first analyse @xmath792   $ ] which satisfies @xmath793    & = \\sum_{i=1}^{n}\\mathbb{v}\\left [   \\left .",
    "m_{t , i}^{t}\\right\\vert \\mathcal{f}% ^{t}\\right ] \\\\ &   = \\sum_{i=1}^{n}\\frac{2}{n^{2}\\left (   \\widehat{w}_{t}^{t}\\right )   ^{2}}% \\int_{0}^{\\delta_{t}}\\mathbb{e}\\left [   \\left .",
    "\\left\\ {   \\partial_{u}% \\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\right\\ } ^{2}\\right\\vert \\mathcal{f}^{t}\\right ]   \\mathrm{d}s.\\end{aligned}\\ ] ] letting @xmath794 and using it s formula , we obtain @xmath795 where @xmath796 therefore @xmath797 to show that the term ( [ eq : identitystsquared2 ] ) vanishes in probability we show that it vanishes in absolute mean @xmath798 \\\\ &   = \\frac{1}{n^{2}}\\sum_{t=1}^{t}\\sum_{i=1}^{n}\\mathbb{e}\\left [   \\frac { 2}{\\left (   \\widehat{w}_{t}^{t}\\right )   ^{2}}\\int_{0}^{\\delta_{t}}\\int_{0}% ^{s}\\left\\vert \\mathbb{e}\\left (   \\left .",
    "\\mathcal{s}\\left\\ {   g(y_{t}% , u_{t , i}^{t}\\left (   r\\right )   ; \\theta)\\right\\ }   \\right\\vert \\mathcal{f}% ^{t}\\right )   \\right\\vert \\mathrm{d}r\\mathrm{d}s\\right ] \\\\ &   = \\frac{1}{n^{2}}\\sum_{t=1}^{t}\\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\int% _ { 0}^{s}\\mathbb{e}\\left [   \\mathbb{e}\\left\\ {   \\left .",
    "\\frac{2}{\\left ( \\widehat{w}_{t}^{t}\\right )   ^{2}}\\left\\vert \\mathcal{s}\\left\\ {   g(y_{t}% , u_{t , i}^{t}\\left (   r\\right )   ; \\theta)\\right\\ }   \\right\\vert \\right\\vert \\mathcal{f}^{t}\\right\\ }   \\right ]   \\mathrm{d}r\\mathrm{d}s\\\\ &   = \\frac{2}{n^{2}}\\sum_{t=1}^{t}\\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\int% _ { 0}^{s}\\widetilde{\\mathbb{e}}\\left [   \\frac{1}{\\widehat{w}_{t}^{t}}\\left\\vert \\mathcal{s}\\left\\ {   g(y_{t},u_{t , i}^{t}\\left (   r\\right )   ; \\theta)\\right\\ } \\right\\vert \\right ]   \\mathrm{d}r\\mathrm{d}s\\\\ &   = \\frac{2}{n^{2}}\\sum_{t=1}^{t}\\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\int% _ { 0}^{s}\\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left (   \\widehat{w}_{t}% ^{t}\\right )   ^{-2}\\right ]   \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left\\vert \\mathcal{s}\\left\\ {   g(y_{t},u_{t , i}^{t}\\left (   r\\right )   ; \\theta)\\right\\ } \\right\\vert ^{2}\\right ]   \\mathrm{d}r\\mathrm{d}s\\\\ &   = \\delta_{t}^{2}\\frac{nt}{n^{2}}\\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left ( \\widehat{w}_{t}^{t}\\right )   ^{-2}\\right ]   \\widetilde{\\mathbb{e}}^{1/2}\\left [ \\left (   \\mathcal{s}\\left\\ {   g(y_{1},u_{1,1}^{t};\\theta)\\right\\ }   \\right ) ^{2}\\right ] \\\\ &   = \\delta_{t}\\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left (   \\widehat{w}_{t}% ^{t}\\right )   ^{-2}\\right ]   \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left ( \\mathcal{s}\\left\\ {   g(y_{1},u_{1,1}^{t};\\theta)\\right\\ }   \\right )   ^{2}\\right ] = o(\\delta_{t}),\\end{aligned}\\ ] ] by assumption  [ ass : steindu ] and the fact that @xmath785 are stationary and i.i.d . over @xmath799 under @xmath800 . going back to our calculation of @xmath801",
    ", we now treat the term ( [ eq : identitystsquared1])@xmath802 where @xmath803 in order to apply the wlln we have to check that@xmath804 = \\mathbb{e}\\left [   \\left\\vert g_{t}\\left (   y_{1},u_{1}^{t}\\right )   \\right\\vert \\mathbb{i}\\left\\ {   \\left\\vert g_{t}\\left (   y_{1},u_{1}^{t}\\right )   \\right\\vert \\geq\\epsilon t\\right\\ }   \\right ]   \\rightarrow0,\\ ] ] or equivalently that @xmath805 is uniformly integrable .",
    "we use the de la valle - poussin theorem which says that @xmath806 is uniformly integrable if and only if there exists a non - negative increasing convex function @xmath758 such that @xmath807 as @xmath808 and @xmath809 < \\infty$ ] .    if @xmath758 is convex then by jensen s inequality@xmath810    &   \\leq\\mathbb{e}\\left [   \\frac{1}% { n}\\sum_{i=1}^{n}g\\left (   \\left (   \\widehat{w}_{1}^{t}\\right )   ^{-2}\\left\\ { \\partial_{u}\\varpi(y_{1},u_{1,i}^{t};\\theta)\\right\\ }   ^{2}\\right )   \\right ] \\\\ &",
    "= \\mathbb{e}\\left [   g\\left (   \\left (   \\widehat{w}_{1}^{t}\\right ) ^{-2}\\left\\ {   \\partial_{u}\\varpi(y_{1},u_{1,1}^{t};\\theta)\\right\\ } ^{2}\\right )   \\right]\\end{aligned}\\ ] ] since the variables @xmath811 are exchangeable under @xmath812 .",
    "therefore it will suffice to assume that for some non - negative , increasing convex function @xmath758 such that @xmath807 @xmath813   < \\infty\\ ] ] or equivalently that the family@xmath814 is uniformly integrable .",
    "this will be satisfied if there exists @xmath815 such that@xmath816   = \\lim\\sup_{t}\\widetilde{\\mathbb{e}% } \\left [   \\left (   \\widehat{w}_{1}^{t}\\right )   ^{-1-\\varepsilon}\\left\\ { \\partial_{u}\\varpi(y_{1},u_{1,1}^{t};\\theta)\\right\\ }   ^{2 + 2\\varepsilon } \\right ]   < \\infty.\\ ] ] by cauchy - schwarz , this is guaranteed by assumptions  [ ass : momentsofw ] and [ ass : du4moments ] . by applying now the wlln ,",
    "we have@xmath817   \\right\\ } \\overset{\\mathbb{p}}{\\rightarrow}0,\\ ] ] where @xmath818    & = \\mathbb{e}\\left [   \\frac{1}{n}\\sum_{i=1}^{n}\\left (   \\widehat{w}_{1}% ^{t}\\right )   ^{-2}\\left\\ {   \\partial_{u}\\varpi(y_{1},u_{1,i}^{t};\\theta ) \\right\\ }   ^{2}\\right ] \\\\ &   = \\mathbb{e}\\left [   \\frac{\\left\\ {   \\partial_{u}\\varpi(y_{1},u_{1,1}% ^{t};\\theta)\\right\\ }   ^{2}}{\\left (   \\widehat{w}_{1}^{t}\\right )   ^{2}}\\right ] = \\widetilde{\\mathbb{e}}\\left [   \\frac{\\left\\ {   \\partial_{u}\\varpi(y_{1}% , u_{1,1}^{t};\\theta)\\right\\ }   ^{2}}{\\widehat{w}_{1}^{t}}\\right]\\end{aligned}\\ ] ] by cauchy - schwarz @xmath819   ^{1+\\epsilon}\\right\\ }   \\leq\\widetilde{\\mathbb{e}}\\left\\ {    ^{1/2}\\times\\lim\\sup_{t}\\widetilde{\\mathbb{e}}\\left\\ {   \\left [   \\widehat{w}% _ { 1}^{t}\\right ]   ^{-(2 + 2\\epsilon)}\\right\\ }   ^{1/2}<\\infty,\\ ] ] by assumptions  [ ass : momentsofw ] and [ ass : du4moments ] again .",
    "therefore the family @xmath820 is also uniformly integrable and , since @xmath821 , we have @xmath822 \\rightarrow\\widetilde{\\mathbb{e}}\\left [   \\left\\ {   \\partial_{u}\\varpi ( y_{1},u_{1,1}^{t};\\theta)\\right\\ }   ^{2}\\right ]   = \\frac{\\kappa^{2}\\left ( \\theta\\right )   } { 2}.\\ ] ] hence , it follows that @xmath823 .",
    "[ [ lindeberg - condition . ] ] lindeberg condition .",
    "+ + + + + + + + + + + + + + + + + + + +    let @xmath824 .",
    "we have to check that @xmath825 and since we have shown previously that @xmath826 in probability , we only need to check that @xmath827 in probability .",
    "since it is positive , it is enough to show that its expectation vanishes .",
    "we have@xmath828 \\\\",
    "&   = \\frac{2t}{n^{2}}\\mathbb{e}\\left [   \\left\\ {   \\frac{\\mathbb{i}\\left\\ { \\left\\vert m_{1}^{t}\\right\\vert \\geq\\varepsilon s_{t}\\right\\ }   } { \\left ( \\widehat{w}_{1}^{t}\\right )   ^{3/2}}\\right\\ }   \\frac{1}{\\left (   \\widehat{w}% _ { 1}^{t}\\right )   ^{1/2}}\\left\\ {   \\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}% \\partial_{u}\\varpi\\left (   y_{1},u_{1,i}^{t}\\left (   s\\right )   ; \\theta\\right ) \\mathrm{d}b_{1,i}\\left (   s\\right )   \\right\\ }   ^{2}\\right ] \\\\ &   \\leq\\frac{2t}{n^{2}}\\mathbb{e}^{1/2}\\left [   \\frac{\\mathbb{i}\\left\\ { \\left\\vert m_{1}^{t}\\right\\vert \\geq\\varepsilon s_{t}\\right\\ }   } { \\left ( \\widehat{w}_{1}^{t}\\right )   ^{3}}\\right ]   \\mathbb{e}^{1/2}\\left [   \\frac { 1}{\\left (   \\widehat{w}_{1}^{t}\\right )   } \\left\\",
    "{   \\sum_{i=1}^{n}\\int% _ { 0}^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{1},u_{1,i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\mathrm{d}b_{1,i}\\left (   s\\right )   \\right\\ }   ^{4}\\right]\\end{aligned}\\ ] ] by cauchy - schwartz and@xmath829    &   = \\widetilde{\\mathbb{e}}\\left [   \\left\\ {   \\sum _ { i=1}^{n}\\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{1},u_{1,i}% ^{t}\\left (   s\\right )   ; \\theta\\right )   \\mathrm{d}b_{1,i}\\left (   s\\right ) \\right\\ }   ^{4}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\widetilde{\\mathbb{e}}\\left [   \\left . \\left\\ {   \\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left ( y_{1},u_{1,i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\mathrm{d}b_{1,i}\\left ( s\\right )   \\right\\ }   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ]   \\right ] \\\\ &   \\leq cn^{2}\\widetilde{\\mathbb{e}}\\left [   \\left (   \\int_{0}^{\\delta_{t}% } \\partial_{u}\\varpi\\left (   y_{1},u_{1,1}^{t}\\left (   s\\right )   ; \\theta\\right ) \\mathrm{d}b_{1,1}\\left (   s\\right )   \\right )   ^{4}\\right ] \\\\ &   \\leq cn^{2}\\left\\ {   3\\int_{0}^{\\delta_{t}}\\widetilde{\\mathbb{e}}% ^{1/2}\\left\\vert \\partial_{u}\\varpi\\left (   y_{1},u_{1,1}^{t}\\left (   s\\right ) ; \\theta\\right )   \\right\\vert ^{4}\\mathrm{d}s\\right\\ }   ^{2}\\\\ &   = 9cn^{2}\\delta_{t}^{2}\\widetilde{\\mathbb{e}}\\left\\ {   \\left\\vert \\partial_{u}\\varpi\\left (   y_{1},u_{1,1};\\theta\\right )   \\right\\vert ^{4}\\right\\ }   < \\infty,\\end{aligned}\\ ] ] where the penultimate inequality follows from ( * ? ? ?",
    "* theorem 1 ) and the last one by assumption  [ ass : du4moments ] .",
    "therefore @xmath830    & \\leq3c^{1/2}\\frac{2t}{n^{2}}n\\delta_{t}\\widetilde{\\mathbb{e}}^{1/2}\\left\\ { \\left\\vert \\partial_{u}\\varpi\\left (   y_{1},u_{1,1};\\theta\\right )   \\right\\vert ^{4}\\right\\ }   \\mathbb{e}^{1/2}\\left [   \\frac{\\mathbb{i}\\left\\ {   \\left\\vert m_{1}^{t}\\right\\vert \\geq\\varepsilon s_{t}\\right\\ }   } { \\left (   \\widehat{w}% _ { t}^{t}\\right )   ^{3}}\\right ] \\\\ &   \\leq b\\widetilde{\\mathbb{e}}^{1/2}\\left\\ {   \\left\\vert \\partial_{u}% \\varpi\\left (   y_{1},u_{1,1};\\theta\\right )   \\right\\vert ^{4}\\right\\ } \\mathbb{e}^{1/2}\\left [   \\frac{\\mathbb{i}\\left\\ {   \\left\\vert m_{1}% ^{t}\\right\\vert \\geq\\varepsilon s_{t}\\right\\ }   } { \\left (   \\widehat{w}_{t}% ^{t}\\right )   ^{3}}\\right ]   .\\end{aligned}\\ ] ] using holder s inequality we have @xmath831    &   \\leq{\\mathbb{e}}\\left [   \\left (   \\widehat{w}_{t}^{t}\\right ) ^{-3 - 3\\epsilon}\\right ]   ^{1/(1+\\epsilon)}{\\mathbb{p}}\\left [   |m_{1}^{t}%    &   \\leq c{\\mathbb{p}}\\left [   |m_{1}^{t}|\\geq\\epsilon s_{t}\\right ] ^{\\epsilon/(1+\\epsilon)},\\end{aligned}\\ ] ] by assumption  [ ass : momentsofw ] .",
    "we continue by estimating@xmath832   + \\mathbb{p}% \\left (   |s_{t}|^{2}<\\frac{\\kappa^{2}\\left (   \\theta\\right )   } { 2}\\right ) \\\\ &   = \\mathbb{p}\\left [   \\left\\vert m_{1}^{t}\\right\\vert \\geq\\frac{\\varepsilon \\kappa\\left (   \\theta\\right )   } { \\sqrt{2}}\\right ]   + o(1)\\\\ &   \\leq2\\frac{\\mathbb{e}\\left [   \\left\\vert m_{1}^{t}\\right\\vert ^{2}\\right ] } { \\left (   \\varepsilon\\kappa\\left (   \\theta\\right )   \\right )   ^{2}}+o(1).\\end{aligned}\\ ] ] to proceed we control the second moment of @xmath766 @xmath833    & = \\mathbb{e}\\left [   \\left\\vert \\frac{\\sqrt{2}}{n\\widehat{w}_{1}^{t}}\\sum _ { i=1}^{n}\\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{1},u_{1,i}% ^{t}\\left (   s\\right )   ; \\theta\\right )   \\mathrm{d}b_{1,i}\\left (   s\\right ) \\right\\vert ^{2}\\right ] \\nonumber\\\\ &   = \\frac{2}{n^{2}}\\widetilde{\\mathbb{e}}\\left [   \\frac{1}{\\widehat{w}_{1}^{t}% } \\left\\vert \\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left ( y_{1},u_{1,i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\mathrm{d}b_{1,i}\\left ( s\\right )   \\right\\vert ^{2}\\right ] \\nonumber\\\\ &   \\leq\\frac{2}{n^{2}}\\widetilde{\\mathbb{e}}\\left [   ( \\widehat{w}_{1}^{t}% ) ^{-2}\\right ]   ^{1/2}\\widetilde{\\mathbb{e}}\\left [   \\left (   \\sum_{i=1}^{n}% \\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{1},u_{1,i}^{t}\\left ( s\\right )   ; \\theta\\right )   \\mathrm{d}b_{1,i}\\left (   s\\right )   \\right ) ^{4}\\right ]   ^{1/2}\\nonumber\\\\ &   \\leq\\frac{2}{n^{2}}\\widetilde{\\mathbb{e}}\\left [   ( \\widehat{w}_{1}^{t}% ) ^{-2}\\right ]   ^{1/2}\\widetilde{\\mathbb{e}}\\left [   \\widetilde{\\mathbb{e}% } \\left\\ {   \\left .",
    "\\left (   \\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\partial _ { u}\\varpi\\left (   y_{1},u_{1,i}^{t}\\left (   s\\right )   ; \\theta\\right ) \\mathrm{d}b_{1,i}\\left (   s\\right )   \\right )   ^{4}\\right\\vert \\mathcal{y}% ^{t}\\right\\ }   \\right ]   ^{1/2}\\nonumber\\\\ &   \\leq\\frac{cn}{n^{2}}\\widetilde{\\mathbb{e}}\\left [   ( \\widehat{w}_{1}% ^{t})^{-2}\\right ]   ^{1/2}\\widetilde{\\mathbb{e}}\\left [   \\widetilde{\\mathbb{e}% } \\left\\ {   \\left .",
    "\\left [   \\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left ( y_{1},u_{1,i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\mathrm{d}b_{1,i}\\left ( s\\right )   \\right ]   ^{4}\\right\\vert \\mathcal{y}^{t}\\right\\ }   \\right ] ^{1/2}\\nonumber\\\\ &   \\leq\\frac{c}{n}\\widetilde{\\mathbb{e}}\\left [   ( \\widehat{w}_{1}^{t}% ) ^{-2}\\right ]   ^{1/2}\\widetilde{\\mathbb{e}}\\left [   \\left (   \\int_{0}% ^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{1},u_{1,1}^{t}\\left (   s\\right ) ; \\theta\\right )   \\mathrm{d}b_{1,1}\\left (   s\\right )   \\right )   ^{4}\\right ] ^{1/2}\\nonumber\\\\ &   \\leq\\frac{c}{n}\\widetilde{\\mathbb{e}}\\left [   ( \\widehat{w}_{1}^{t}% ) ^{-2}\\right ]   ^{1/2}\\delta_{t}\\widetilde{\\mathbb{e}}\\left\\ {   \\left\\vert \\partial_{u}\\varpi\\left (   y_{1},u_{1,1};\\theta\\right )   \\right\\vert ^{4}\\right\\ }   ^{1/2}=o(1/t)\\rightarrow0 , \\label{eq : variancemt}%\\end{aligned}\\ ] ] by ( * ? ? ? * theorem 1 ) and assumptions  [ ass : momentsofw ] and [ ass : du4moments ] .",
    "this completes the proof that@xmath834 \\rightarrow0,\\ ] ] and in turn that holds .",
    "therefore by the lindeberg central limit theorem applied conditionally on @xmath264 we have that@xmath835 and as @xmath836 @xmath837    _ proof of lemma  [ lem : zsquared ] . _  notice that @xmath838   ^{2}+\\left [   h_{t}^{t}\\right ] ^{2}+2j_{t}^{t}h_{t}^{t}\\right\\ }   .\\ ] ] we know from lemma  [ lem : jt ] that @xmath839 vanishes in probability .",
    "the @xmath840 terms are given by@xmath841 the first term vanishes in probability since by lemma  [ lem : lt ] @xmath842 for the product term notice that by two applications of the cauchy - schwartz inequality @xmath843 by lemmas  [ lem : lt ] and [ lem : mt ] .",
    "finally , we have @xmath844   ^{2}\\right )   = o\\left (   1\\right)\\ ] ] by lemma [ lem : mt ] .    for the term involving the product @xmath845 , we have similarly by two applications of the cauchy - schwartz inequality@xmath846   \\mathbb{e}^{1/2}\\left [ % tcimacro{\\tsum \\nolimits_{t=1}^{t}}% % beginexpansion { \\textstyle\\sum\\nolimits_{t=1}^{t } } % endexpansion \\left (   h_{t}^{t}\\right )   ^{2}\\right ]   .\\end{aligned}\\ ] ] by lemmas  [ lem : jt ] , [ lem : lt ] and [ lem : mt ] , the first factor vanishes , while we have just shown that the second factor is @xmath847 .    [",
    "[ term - sum_t1tleft - m_ttright-2 . ] ] term @xmath848   ^{2}$ ] .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    conditionally on @xmath849 the terms @xmath850   ^{2}% $ ] are independent .",
    "we want to apply the conditional wlln to show that @xmath851 as we have already shown that lemma [ lem : mt ] holds , we only need to check that for any @xmath594 @xmath852 this follows from similar arguments as the lindeberg condition ( [ eq : lindebergmt ] ) .      from assumption [ ass : bvm ] and the change of variables @xmath853 , we obtain @xmath854 in probability .",
    "hence , we have @xmath855 in probability .",
    "we recall that to check that a sequence of probability measures @xmath856 on @xmath857 converges weakly to another probability measure @xmath327 it is enough to check convergence of the finite dimensional distributions ( see @xcite ) , which itself can be established if we can show that for any @xmath342 , any @xmath858 and any uniformly continuous bounded functions @xmath859 such that @xmath860 , we have @xmath861   &   \\rightarrow\\mathbb{e[}% % tcimacro{\\tprod \\nolimits_{j=0}^{n}}% % beginexpansion { \\textstyle\\prod\\nolimits_{j=0}^{n } } % endexpansion f_{j}(\\widetilde{\\theta}_{k_{j}})]\\\\ &   = \\int\\varphi(\\mathrm{d}x_{0};0,\\overline{\\sigma})f_{0}(x_{0})\\int p^{k_{1}-k_{0}}(x_{0},\\mathrm{d}x_{1})f_{1}(x_{1})\\\\ &   \\qquad\\times\\int p^{k_{2}-k_{1}}(x_{1},\\mathrm{d}x_{2})f_{2}(x_{2}% ) \\times\\cdots\\times\\int p^{k_{n}-k_{n-1}}(x_{n-1},\\mathrm{d}x_{n})f_{n}% ( x_{n}).\\end{aligned}\\ ] ] we will check the above condition for @xmath862 where @xmath863 is the space of real - valued measurable and bounded functions on @xmath305 .",
    "our result is based on the following proposition .",
    "[ proposition : kernelcvplusbvmequalweakcv]if for any @xmath864@xmath865   = 0 \\label{eq : kernelconv}%\\ ] ] and @xmath866 in probability then @xmath312 converges weakly to @xmath327 .    to establish this proposition ,",
    "we first establish the following lemma .",
    "[ lemma : cvofpimpliescvofpk]if for any @xmath867 , we have @xmath868 q_{t}f(\\widetilde{\\theta},u^{t})-pf(\\widetilde{\\theta})\\right\\vert \\right ] = 0\\ ] ] then we also have for any @xmath624 and any @xmath867 @xmath869 q_{t}^{k}f(\\widetilde{\\theta},u^{t})-p^{k}f(\\widetilde{\\theta})\\right\\vert \\right ]   = 0.\\ ] ]    _ proof of lemma [ lemma : cvofpimpliescvofpk ] .",
    "_ we prove the result by induction . for @xmath870 ,",
    "this follows by the assumption .",
    "now we have@xmath871 and therefore@xmath872 \\\\ &   \\leq\\mathbb{e}_{\\widetilde{\\pi}^{t}}\\left [   \\left\\vert q_{t}^{k+1}% f(\\widetilde{\\theta}_{0},u_{0}^{t})-q_{t}(p^{k}f)(\\widetilde{\\theta}_{0}% , u_{0}^{t})\\right\\vert \\right ]   + \\mathbb{e}_{\\widetilde{\\pi}^{t}}\\left [ \\left\\vert q_{t}(p^{k}f)(\\widetilde{\\theta}_{0},u_{0}^{t})-p^{k+1}% f(\\widetilde{\\theta}_{0})\\right\\vert \\right ] \\\\ &   \\leq\\mathbb{e}_{\\widetilde{\\pi}^{t}}\\left [   \\left\\vert q_{t}^{k}% f(\\widetilde{\\theta}_{0},u_{0}^{t})-p^{k}f(\\widetilde{\\theta}_{0},u_{0}% ^{t})\\right\\vert \\right ]   + \\mathbb{e}_{\\widetilde{\\pi}^{t}}\\left [   \\left\\vert q_{t}(p^{k}f)(\\widetilde{\\theta}_{0},u_{0}^{t})-p(p^{k}f)(\\widetilde{\\theta } _ { 0})\\right\\vert \\right ]   , \\end{aligned}\\ ] ] since @xmath873 leaves the distribution of @xmath874 invariant .",
    "we can now apply the induction hypothesis to the functions @xmath190 and @xmath875 , @xmath875 being measurable and bounded .    _",
    "proof of proposition [ proposition : kernelcvplusbvmequalweakcv ] .",
    "_ we prove the claim by induction on @xmath314 . for @xmath876 ,",
    "the result follows directly from ( [ eq : bvm ] ) while we have for @xmath151 @xmath877   -\\mathbb{e}\\left [ f_{0}(\\widetilde{\\theta}_{k_{0}})f_{1}(\\widetilde{\\theta}_{k_{0}})\\right ] \\right\\vert } \\\\ &   = \\left\\vert \\int f_{0}(\\widetilde{\\theta}_{0})\\widetilde{\\pi}% ^{t}(\\widetilde{\\theta}_{0},u_{0}^{t})q_{t}^{k_{1}-k_{0}}f_{1}% ( \\widetilde{\\theta}_{0},u_{0}^{t})\\mathrm{d}\\widetilde{\\theta}_{0}% \\mathrm{d}u_{0}^{t}-\\int f_{0}(\\widetilde{\\theta}_{0})\\varphi ( \\widetilde{\\theta}_{0};0,\\overline{\\sigma})p^{k_{1}-k_{0}}f_{1}% ( \\widetilde{\\theta}_{0})\\mathrm{d}\\widetilde{\\theta}_{0}\\right\\vert \\\\ &   \\leq\\left\\vert \\int f_{0}(\\widetilde{\\theta}_{0})\\widetilde{\\pi}% ^{t}(\\widetilde{\\theta}_{0},u_{0}^{t})\\{q_{t}^{k_{1}-k_{0}}f_{1}% ( \\widetilde{\\theta}_{0},u_{0}^{t})-p^{k_{1}-k_{0}}f_{1}(\\widetilde{\\theta}% _ { 0})\\}\\mathrm{d}\\widetilde{\\theta}_{0}\\mathrm{d}u_{0}^{t}\\right\\vert \\\\ &   + \\left\\vert \\int f_{0}(\\widetilde{\\theta}_{0})\\{\\widetilde{\\pi}% ^{t}(\\widetilde{\\theta}_{0})-\\varphi(\\widetilde{\\theta}_{0};0,\\overline { \\sigma})\\}p^{k_{1}-k_{0}}f_{1}(\\widetilde{\\theta}_{0})\\mathrm{d}% \\widetilde{\\theta}_{0}\\right\\vert \\\\ &   \\leq\\mathbb{e}_{\\widetilde{\\pi}^{t}}\\left [   \\left\\vert q_{t}^{k_{1}-k_{0}% } f_{1}(\\widetilde{\\theta}_{0}^{t},u_{0}^{t})-p^{k_{1}-k_{0}}f_{1}% ( \\widetilde{\\theta}_{0}^{t})\\right\\vert \\right ]   + \\int\\left\\vert \\widetilde{\\pi}^{t}(\\widetilde{\\theta}_{0})-\\varphi(\\widetilde{\\theta}% _ { 0};0,\\overline{\\sigma})\\right\\vert \\mathrm{d}\\widetilde{\\theta}_{0}\\text{.}%\\end{aligned}\\ ] ] hence from lemma [ lemma : cvofpimpliescvofpk ] , the result follows .",
    "now for any @xmath878 , we have @xmath879    &   = \\mathbb{e}\\left [ % tcimacro{\\tprod \\nolimits_{j=0}^{n}}% % beginexpansion { \\textstyle\\prod\\nolimits_{j=0}^{n } } % endexpansion f_{j}(\\widetilde{\\theta}_{k_{j}}^{t})q_{t}^{k_{n+1}-k_{n}}f_{n+1}% ( \\widetilde{\\theta}_{k_{n}}^{t},u_{k_{n}}^{t})\\right ] \\nonumber\\\\ &   = \\mathbb{e}\\left [ % tcimacro{\\tprod \\nolimits_{j=0}^{n}}% % beginexpansion { \\textstyle\\prod\\nolimits_{j=0}^{n } } % endexpansion f_{j}(\\widetilde{\\theta}_{k_{j}}^{t})p^{k_{n+1}-k_{n}}f_{n+1}% ( \\widetilde{\\theta}_{k_{n}}^{t})\\right ] \\label{eq : firsttermweakcv}\\\\ &   \\qquad+\\mathbb{e}\\left [ % tcimacro{\\tprod \\nolimits_{j=0}^{n}}% % beginexpansion { \\textstyle\\prod\\nolimits_{j=0}^{n } } % endexpansion f_{j}(\\widetilde{\\theta}_{k_{j}}^{t})\\{q_{t}^{k_{n+1}-k_{n}}f_{n+1}% ( \\widetilde{\\theta}_{k_{n}}^{t},u_{k_{n}}^{t})-p^{k_{n+1}-k_{n}}% f_{n+1}(\\widetilde{\\theta}_{k_{n}}^{t})\\}\\right ]   .",
    "\\label{eq : secondtermweakcv}%\\end{aligned}\\ ] ] by the induction hypothesis the first term ( [ eq : firsttermweakcv ] ) converges to @xmath880    &   = \\mathbb{e}\\left [ % tcimacro{\\tprod \\nolimits_{j=0}^{n}}% % beginexpansion { \\textstyle\\prod\\nolimits_{j=0}^{n } } % endexpansion f_{j}(\\widetilde{\\theta}_{k_{j}})\\mathbb{e(}\\left .",
    "f_{n+1}(\\widetilde{\\theta } _ { k_{n+1}})\\right\\vert \\widetilde{\\theta}_{k_{n}})\\right ] \\\\ &   = \\mathbb{e}\\left [ % tcimacro{\\tprod \\nolimits_{j=0}^{n+1}}% % beginexpansion { \\textstyle\\prod\\nolimits_{j=0}^{n+1 } } % endexpansion f_{j}(\\widetilde{\\theta}_{k_{j}})\\right ]   .\\end{aligned}\\ ] ] so it remains to show that the remainder ( [ eq : secondtermweakcv ] ) vanishes .",
    "we have@xmath881   \\right\\vert \\\\ &   \\leq\\mathbb{e}\\left [   \\left\\vert q_{t}^{k_{n+1}-k_{n}}f_{n+1}% ( \\widetilde{\\theta}_{k_{n}}^{t},u_{k_{n}}^{t})-p^{k_{n+1}-k_{n}}% f_{n+1}(\\widetilde{\\theta}_{k_{n}}^{t})\\right\\vert \\right ]   .\\end{aligned}\\ ] ] so using lemma [ lemma : cvofpimpliescvofpk ] , this term vanishes and the result follows .",
    "[ proposition : kernelconverges]for any @xmath867 , we have @xmath882   = 0 \\label{eq : kernelconvprop}%\\ ] ] in probability",
    ".    _ proof of proposition [ proposition : kernelconverges ] . _",
    "writing @xmath883 for @xmath884 , we have @xmath885 \\nonumber\\\\ &   = \\iint\\widetilde{q}(\\widetilde{\\theta}_{0},\\mathrm{d}\\widetilde{\\theta}% _ { 1})f(\\widetilde{\\theta}_{1})k_{\\rho_{t}}\\left (   u_{0},\\mathrm{d}% u_{1}\\right )   \\min\\left (   1,\\frac{\\widetilde{\\pi}^{t}(\\widetilde{\\theta}% _ { 1})\\widetilde{q}(\\widetilde{\\theta}_{1},\\widetilde{\\theta}_{0}% ) } { \\widetilde{\\pi}^{t}(\\widetilde{\\theta}_{0})\\widetilde{q}(\\widetilde{\\theta } _ { 0},\\widetilde{\\theta}_{1})}\\frac{\\widehat{p}(y\\mid\\theta_{1},u_{1}% ) /p(y\\mid\\theta_{1})}{\\widehat{p}(y\\mid\\theta_{0},u_{0})/p(y\\mid\\theta_{0}% ) } \\right ) \\nonumber\\\\ &   \\qquad+f(\\widetilde{\\theta}_{0})\\left [   1-\\iint\\widetilde{q}% ( \\widetilde{\\theta}_{0},\\mathrm{d}\\widetilde{\\theta}_{1})k_{\\rho_{t}}\\left ( u_{0},\\mathrm{d}u_{1}\\right )   \\min\\left (   1,\\frac{\\widetilde{\\pi}% ^{t}(\\widetilde{\\theta}_{1})\\widetilde{q}(\\widetilde{\\theta}_{1}% , \\widetilde{\\theta}_{0})}{\\widetilde{\\pi}^{t}(\\widetilde{\\theta}% _ { 0})\\widetilde{q}(\\widetilde{\\theta}_{0},\\widetilde{\\theta}_{1})}% \\frac{\\widehat{p}(y\\mid\\theta_{1},u_{1})/p(y\\mid\\theta_{1})}{\\widehat{p}% ( y\\mid\\theta_{0},u_{0})/p(y\\mid\\theta_{0})}\\right )   \\right ] \\nonumber\\end{aligned}\\ ] ] while @xmath886   .\\nonumber\\end{aligned}\\ ] ] hence , it follows that @xmath887   -pf(\\widetilde{\\theta}% _ { 0})\\right\\vert \\right ]   } \\\\ &   \\leq\\iiint\\widetilde{\\pi}^{t}(\\mathrm{d}\\widetilde{\\theta}_{0}% , \\mathrm{d}u_{0})\\widetilde{q}(\\widetilde{\\theta}_{0},\\mathrm{d}% \\widetilde{\\theta}_{1})\\left\\vert f(\\widetilde{\\theta}_{1})\\right\\vert \\left\\vert \\int k_{\\rho_{t}}\\left (   u_{0},\\mathrm{d}u_{1}\\right )   \\min\\left ( 1,\\frac{\\widetilde{\\pi}^{t}(\\widetilde{\\theta}_{1})\\widetilde{q}% ( \\widetilde{\\theta}_{1},\\widetilde{\\theta}_{0})}{\\widetilde{\\pi}% ^{t}(\\widetilde{\\theta}_{0})\\widetilde{q}(\\widetilde{\\theta}_{0}% , \\widetilde{\\theta}_{1})}\\frac{\\widehat{p}(y\\mid\\theta_{1},u_{1}% ) /p(y\\mid\\theta_{1})}{\\widehat{p}(y\\mid\\theta_{0},u_{0})/p(y\\mid\\theta_{0}% ) } \\right )   \\right . \\\\ &   \\quad\\qquad-\\left .",
    "\\int\\varphi(\\mathrm{d}r;-\\frac{\\kappa^{2}}{2}% , \\kappa^{2})\\min\\left (   1,\\frac{\\varphi(\\widetilde{\\theta}_{1};0,\\overline { \\sigma})\\widetilde{q}(\\widetilde{\\theta}_{1},\\widetilde{\\theta}_{0})}% { \\varphi(\\widetilde{\\theta}_{0};0,\\overline{\\sigma})\\widetilde{q}% ( \\widetilde{\\theta}_{0},\\widetilde{\\theta}_{1})}\\exp\\left (   r\\right )   \\right ) \\right\\vert \\\\ &   \\qquad+\\iiint\\widetilde{\\pi}^{t}(\\mathrm{d}\\widetilde{\\theta}% _ { 0},\\mathrm{d}u_{0})\\widetilde{q}(\\widetilde{\\theta}_{0},\\mathrm{d}% \\widetilde{\\theta}_{1})\\left\\vert f\\left (   \\widetilde{\\theta}_{0}\\right ) \\right\\vert \\left\\vert \\int k_{\\rho_{t}}\\left (   u_{0},\\mathrm{d}u_{1}\\right ) \\min\\left (   1,\\frac{\\widetilde{\\pi}^{t}(\\widetilde{\\theta}_{1})\\widetilde{q}% ( \\widetilde{\\theta}_{1},\\widetilde{\\theta}_{0})}{\\widetilde{\\pi}% ^{t}(\\widetilde{\\theta}_{0})\\widetilde{q}(\\widetilde{\\theta}_{0}% , \\widetilde{\\theta}_{1})}\\frac{\\widehat{p}(y\\mid\\theta_{1},u_{1}% ) /p(y\\mid\\theta_{1})}{\\widehat{p}(y\\mid\\theta_{0},u_{0})/p(y\\mid\\theta_{0}% ) } \\right )   \\right . \\\\ &   \\qquad\\quad\\left .",
    "-\\int\\varphi(\\mathrm{d}r;-\\frac{\\kappa^{2}}{2}% , \\kappa^{2})\\min\\left (   1,\\frac{\\varphi(\\widetilde{\\theta}_{1};0,\\overline { \\sigma})\\widetilde{q}(\\widetilde{\\theta}_{1},\\widetilde{\\theta}_{0})}% { \\varphi(\\widetilde{\\theta}_{0};0,\\overline{\\sigma})\\widetilde{q}% ( \\widetilde{\\theta}_{0},\\widetilde{\\theta}_{1})}\\exp\\left (   r\\right )   \\right ) \\right\\vert \\\\ &   \\leq2\\iiint\\widetilde{\\pi}^{t}(\\mathrm{d}\\widetilde{\\theta}_{0}% , \\mathrm{d}u_{0})\\widetilde{q}(\\widetilde{\\theta}_{0},\\mathrm{d}% \\widetilde{\\theta}_{1})\\left\\vert \\int k_{\\rho_{t}}\\left (   u_{0}% , \\mathrm{d}u_{1}\\right )   \\min\\left (   1,\\frac{\\widetilde{\\pi}^{t}% ( \\widetilde{\\theta}_{1})\\widetilde{q}(\\widetilde{\\theta}_{1},\\widetilde{\\theta } _ { 0})}{\\widetilde{\\pi}^{t}(\\widetilde{\\theta}_{0})\\widetilde{q}% ( \\widetilde{\\theta}_{0},\\widetilde{\\theta}_{1})}\\frac{\\widehat{p}(y\\mid \\theta_{1},u_{1})/p(y\\mid\\theta_{1})}{\\widehat{p}(y\\mid\\theta_{0}% , u_{0})/p(y\\mid\\theta_{0})}\\right )   \\right . \\\\ &   \\qquad-\\left .   \\int\\varphi(\\mathrm{d}r;-\\frac{\\kappa^{2}}{2},\\kappa ^{2})\\min\\left (   1,\\frac{\\varphi(\\widetilde{\\theta}_{1};0,\\overline{\\sigma } ) \\widetilde{q}(\\widetilde{\\theta}_{1},\\widetilde{\\theta}_{0})}{\\varphi ( \\widetilde{\\theta}_{0};0,\\overline{\\sigma})\\widetilde{q}(\\widetilde{\\theta } _ { 0},\\widetilde{\\theta}_{1})}\\exp\\left (   r\\right )   \\right )   \\right\\vert .\\end{aligned}\\ ] ] we have @xmath888 for the first term given in ( [ eq : firsttermofdecomposition ] ) , using the inequality @xmath889 we obtain the bound@xmath890 the term  ( [ eq : firsttermequality ] ) satisfies @xmath891 in probability by ( [ eq : bvm ] ) . since @xmath892 then the term ( [ eq : secondtermequality ] ) is equal to @xmath893 in probability by assumption [ ass : bvm ] .    going back to the term given by ( [ eq : secondtermofdecomposition ] )",
    ", we notice that@xmath894 where ( [ eq : secondtermofsecondterm ] ) satisfies @xmath895 which goes to zero in probability by assumption [ ass : bvm ] .",
    "the term ( [ eq : firsttermofsecondterm ] ) is equal to @xmath896 we can rewrite ( [ eq : firsttermofsecondterm ] ) as@xmath897 the functions @xmath898 are bounded above by @xmath3 and lipschitz , with lipschitz constants bounded by @xmath3 uniformly in all parameters .",
    "therefore , @xmath899 where @xmath900 is defined in ( [ def : blfunction ] ) . for any fixed @xmath901 theorem [ theorem : conditionalcltthetathetacand ] ,",
    "lemma [ lem : conditionallindebergclt ] and dominated convergence shows that the term above goes to zero in probability w.r.t the observations .",
    "also notice that @xmath902 similarly to above , the functions @xmath903 are bounded above by 1 and lipschitz , with lipschitz constants bound by 1 uniformly in all parameters .",
    "therefore@xmath904 hence for any @xmath245 , ess - sup@xmath905 is continuous at @xmath317 since @xmath318 is continuous at @xmath317 and @xmath906 .",
    "it is also uniformly bounded w.r.t @xmath245,@xmath2 by 2 and @xmath907 in probability under @xmath908 thus dominated convergence yields @xmath909",
    "_ proof of proposition [ prop : qstarproperties ] . _",
    "it is straightforward to check that @xmath333 is reversible w.r.t @xmath10 as it follows from ( [ eq : boundingchainkernel ] ) that @xmath910 given @xmath911 is reversible w.r.t @xmath11 .",
    "now , we can also rewrite @xmath333 as @xmath912 so the acceptance probability of a proposal is given by @xmath913 for any @xmath914 as @xmath915 for @xmath916 . hence",
    ", we have @xmath917 from ( * ? ? ?",
    "* theorem 4 ) , which is a general state - space version of the main result in @xcite.to establish the expression of @xmath918 , we first note that there exists a probability measure @xmath919 on @xmath920   $ ] such that @xmath921 from the standard spectral representation of reversible markov chains ; see e.g. @xcite . from the expression ( [ eq : boundingchainkernel ] ) of @xmath333 , we have@xmath922{c}% n\\\\ k \\end{array } \\right )   \\varrho_{\\text{\\textsc{u}}}^{k}\\left (   \\kappa\\right )   \\left\\ { 1-\\varrho_{\\text{\\textsc{u}}}\\left (   \\kappa\\right )   \\right\\ }   ^{n - k}% q_{\\textsc{ex}}^{k}%\\ ] ] and therefore @xmath923 since the number of acceptances from @xmath924 to @xmath314 , @xmath925 .",
    "hence , we have @xmath926    assume@xmath20 is geometrically ergodic ,",
    "then @xmath927 where @xmath928 is the spectral gap . then , from ( [ eq : spectralrepresentationautocorrpstar ] ) , a simple change of variables yields@xmath929   ^{n}e(h , q_{\\textsc{ex}})(\\mathrm{d}% \\lambda)=\\int_{1 - 2\\varrho_{\\text{\\textsc{u}}}\\left (   \\kappa\\right ) + \\epsilon\\varrho_{\\text{\\textsc{u}}}\\left (   \\kappa\\right )   } ^{1-\\epsilon \\varrho_{\\text{\\textsc{u}}}\\left (   \\kappa\\right )   } \\widetilde{\\lambda}% ^{n}\\widetilde{e}(h , q^{\\ast})(\\mathrm{d}\\widetilde{\\lambda}).\\ ] ] thus @xmath333 is also geometrically ergodic .",
    "_ proof of proposition [ cor : rif]_. parts ( i ) and ( ii ) are immediate .",
    "the first remark of part ( iii )  may be verified by observing that @xmath930 is negative . for the second remark of part ( iii ) , @xmath931 where @xmath932 .",
    "this can be verified to be convex as@xmath933 so that @xmath934 since it is easy to show that @xmath935 . similarly @xmath936 is convex as a function of @xmath356 , @xmath937 so that @xmath938 if @xmath939 .",
    "we now show that the minimising value of @xmath356 for @xmath940 increases as @xmath347 increases from one .",
    "we note that when @xmath365 @xmath941 which is minimised at @xmath368 .",
    "we also note that at the optimal value , in general , @xmath942 then @xmath943 so that @xmath944 then@xmath945 since @xmath946 when @xmath947 .",
    "hence the optimal value @xmath381 increases with @xmath380 .",
    "let @xmath948 the space of bounded continuous functions and @xmath949 the space of bounded lipschitz functions @xmath190 with @xmath950 where @xmath951 for sake of completeness , we present a version of the conditional clt for triangular arrays which allows us to conclude that the expectations of any function @xmath952 converge in probability .",
    "we have not been able to find this precise statement in the literature so we present a proof mimicking the proof of theorem 7.2 in @xcite without any claim of originality .",
    "[ lem : conditionallindebergclt ] let @xmath953 be a triangular array of real - valued random variables on a common probability space @xmath954 and @xmath955 a sequence of sub-@xmath186-algebras of @xmath956 such that @xmath957 are conditionally independent given @xmath958 , @xmath959=0 $ ] , and @xmath960<\\infty$ ] .",
    "suppose also that for some @xmath961 , as @xmath962 @xmath963 and that for all @xmath594 , @xmath964 both limits holding in probability .",
    "then @xmath965 where @xmath966 in the sense that for all @xmath952 @xmath967   \\rightarrow\\mu\\left (   f\\right )   , \\ ] ] in probability .",
    "in particular , the random measures @xmath968 defined by @xmath969 converge weakly to @xmath46 in probability in the sense that @xmath970 in probability .",
    "_ proof of lemma [ lem : conditionallindebergclt ] .",
    "_ we first prove the result for @xmath190 bounded and infinitely differentiable , with bounded derivatives of all orders . without loss of generality",
    ", we can assume that the probability space also supports a triangular array of independent standard normal random variables @xmath971 , independent of @xmath972 and of @xmath958 for all @xmath314 .",
    "for all @xmath314 and @xmath973 define @xmath974 .    then using the standard lindeberg approach , as employed in the proof of theorem 7.2 in billingsley ( 1968 ) ,",
    "we telescope @xmath975 writing @xmath442 for a standard normal , independent of all other variables and @xmath958 and @xmath976 , notice first that in probability @xmath977   = \\mathbb{e}\\left [   f\\left (   s_{n}z\\right ) \\big|\\mathcal{f}_{n}\\right ]   \\rightarrow\\mathbb{e}f(\\sigma z).\\ ] ] therefore @xmath967   = o_{p}(1)+\\mathbb{e}f(\\sigma z)+\\sum \\nolimits_{i=1}^{k_{n}}\\mathbb{e}[\\mathcal{e}_{n , i}|\\mathcal{f}_{n}],\\ ] ] where @xmath978   &   : = \\mathbb{e}\\left [   f\\left ( \\sum\\nolimits_{j=1}^{i}x_{n , j}+\\sum\\nolimits_{j = i+1}^{k_{n}}\\eta_{n , j}\\right ) \\big|\\mathcal{f}_{n}\\right ]   -\\mathbb{e}\\left [   f\\left (   \\sum\\nolimits_{j=1}% ^{i-1}x_{n , j}+\\sum\\nolimits_{j = i}^{k_{n}}\\eta_{n , j}\\right )   \\big|\\mathcal{f}% _ { n}\\right ] \\\\ &   = \\mathbb{e}\\left [   f\\left (   \\sum\\nolimits_{j=1}^{i-1}x_{n , j}+\\sum \\nolimits_{j = i+1}^{k_{n}}\\eta_{n , j}+x_{n , i}\\right )   \\big|\\mathcal{f}% _ { n}\\right ]   -\\mathbb{e}\\left [   f\\left (   \\sum\\nolimits_{j=1}^{i-1}x_{n , j}% + \\sum\\nolimits_{j = i+1}^{k_{n}}\\eta_{n , j}+\\eta_{n , i}\\right )   \\big|\\mathcal{f}% _ { n}\\right ]   .\\end{aligned}\\ ] ] letting @xmath979 we have by the mean value theorem , and the fact that @xmath190 has bounded derivative of order two that @xmath980 and the last term can be bounded above by @xmath981 therefore @xmath982    let us then look at one of these remainder terms .",
    "write @xmath983 where @xmath984 taking conditional expectations we observe that @xmath985   } \\\\ &   = \\mathbb{e}\\left [   f^{\\prime}\\left (   \\sum\\nolimits_{j=1}^{i-1}x_{n , j}% + \\sum\\nolimits_{j = i+1}^{k_{n}}\\eta_{n , j}\\right )   \\big|\\mathcal{f}_{n}\\right ] \\times\\mathbb{e}\\left [   ( x_{n , i}-\\eta_{n , i})\\big|\\mathcal{f}_{n}\\right ]   = 0,\\end{aligned}\\ ] ] by independence , conditional independence and the fact that @xmath986 are conditionally centred .",
    "similarly @xmath987   } \\\\ &   = \\mathbb{e}\\left [   f^{\\prime}\\left (   \\sum\\nolimits_{j=1}^{i-1}x_{n ,",
    "j}% + \\sum\\nolimits_{j = i+1}^{k_{n}}\\eta_{n , j}\\right )   \\big|\\mathcal{f}_{n}\\right ] \\times\\mathbb{e}\\left [   ( x_{n , i}^{2}-\\eta_{n , i}^{2})\\big|\\mathcal{f}% _ { n}\\right ]   = 0,\\end{aligned}\\ ] ] since @xmath988=\\sigma_{n , i}^{2}\\mathbb{e}% [ \\xi_{n , i}^{2}|\\mathcal{f}_{n}]=\\sigma_{n , i}^{2}.\\ ] ] it remains to control the term.@xmath989+\\mathbb{e}% [ g(\\eta_{n , i})|\\mathcal{f}_{n}].\\ ] ] for the first term , letting @xmath594 we have @xmath990   & = \\sum\\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   g(x_{n , i})\\mathbf{1}% \\{|x_{n , i}|<\\epsilon\\}\\big|\\mathcal{f}_{n}\\right ]   + \\sum\\nolimits_{i=1}% ^{k_{n}}\\mathbb{e}\\left [   g(x_{n , i})\\mathbf{1}\\{|x_{n , i}|\\geq\\epsilon \\}\\big|\\mathcal{f}_{n}\\right ] \\\\ &   \\leq k\\sum\\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   |x_{n , i}|^{3}% \\mathbf{1}\\{|x_{n , i}|<\\epsilon\\}\\big|\\mathcal{f}_{n}\\right ]   + k\\sum \\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   |x_{n , i}|^{2}\\mathbf{1}% \\{|x_{n , i}|\\geq\\epsilon\\}\\big|\\mathcal{f}_{n}\\right ] \\\\ &   \\leq k\\epsilon\\sum\\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   |x_{n , i}%    + k\\sum\\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   |x_{n , i}|^{2}\\mathbf{1}% \\{|x_{n , i}|\\geq\\epsilon\\}\\big|\\mathcal{f}_{n}\\right ] \\\\ &   \\leq k\\epsilon\\sum\\nolimits_{i=1}^{k_{n}}\\sigma_{n , i}^{2}+k\\sum \\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   |x_{n , i}|^{2}\\mathbf{1}% \\{|x_{n , i}|\\geq\\epsilon\\}\\big|\\mathcal{f}_{n}\\right ]   \\rightarrow0,\\end{aligned}\\ ] ] because @xmath594 is arbitrary , and the second term vanishes in probability by hypothesis .    similarly @xmath991   &   \\leq k\\epsilon\\sum\\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   |\\eta_{n , i}%    + k\\sum\\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   |\\eta_{n , i}|^{2}\\mathbf{1}% \\{|\\eta_{n , i}|\\geq\\epsilon\\}\\big|\\mathcal{f}_{n}\\right ] \\\\ &   \\leq kc\\epsilon\\sum\\nolimits_{i=1}^{k_{n}}\\sigma_{n , i}^{2}+k\\sum \\nolimits_{i=1}^{k_{n}}\\mathbb{e}\\left [   \\sigma_{n , i}^{2}|z|^{2}% \\mathbf{1}\\{\\sigma_{n , i}|z|\\geq\\epsilon\\}\\big|\\mathcal{f}_{n}\\right ]   .\\end{aligned}\\ ] ] the second term is at most @xmath992   \\leq\\frac{k}{\\epsilon}\\sum\\nolimits_{i=1}% ^{k_{n}}\\mathbb{e}\\left [   \\sigma_{n , i}^{3}|z|^{3}\\big|\\mathcal{f}_{n}\\right ] = \\frac{k}{\\epsilon}\\sum\\nolimits_{i=1}^{k_{n}}\\sigma_{n , i}^{3}\\mathbb{e}% [ |z|^{3}].\\ ] ] since @xmath993\\\\ &   = \\mathbb{e}\\left [   x_{n , i}^{2}\\mathbf{1}\\left\\ {   |x_{n , i}|\\leq \\epsilon\\right\\ }   \\big|\\mathcal{f}_{n}\\right ]   + \\mathbb{e}\\left [   x_{n , i}% ^{2}\\mathbf{1}\\left\\ {   |x_{n , i}|>\\epsilon\\right\\ }   \\big|\\mathcal{f}_{n}\\right ] \\\\ &   = \\epsilon^{2}+\\mathbb{e}\\left [   x_{n , i}^{2}\\mathbf{1}\\left\\ {    we have that @xmath994   .\\ ] ] since @xmath594 is arbitrary , @xmath995 in probability , and therefore @xmath996 in probability .    to complete the proof",
    "let @xmath952 , continuous and bounded and let @xmath997 .",
    "let @xmath998 be arbitrary and notice that @xmath999    & = \\mathbb{e}\\left [   \\left .",
    "f_{k}(z_{n})\\right\\vert \\mathcal{f}_{n}\\right ] + e_{1},\\\\    \\mathcal{f}_{n}\\right ]   -\\mathbb{e}\\left [   \\left .",
    "f(z_{n})\\right\\vert \\mathcal{f}_{n}\\right ]   \\right\\vert \\\\ &   \\leq\\mathbb{e}\\left [   \\left .",
    "\\left\\vert f_{k}(z_{n})-f(z_{n})\\right\\vert \\right\\vert \\mathcal{f}_{n}\\right ] \\\\ &   \\leq(2\\vert f\\vert_{\\infty}+1)\\mathbb{p}\\left (   \\left .",
    "|z_{n}|\\geq k\\right\\vert \\mathcal{f}_{n}\\right )   .\\end{aligned}\\ ] ] since @xmath1000 is continuous and compactly supported , for any @xmath594 we can find @xmath1001 , the space of continuous functions with continuous bounded derivatives of all orders , such that @xmath1002 .",
    "therefore we also have that @xmath1003 = \\mathbb{e}\\left [   \\left .   g_{k,\\epsilon}(z_{n})\\right\\vert \\mathcal{f}% _ { n}\\right ]   + e_{2},\\ ] ] where @xmath1004   -\\mathbb{e}\\left [   \\left .",
    "g_{k,\\epsilon}% ( z_{n})\\right\\vert \\mathcal{f}_{n}\\right ]   \\right\\vert < \\epsilon.\\ ] ] since @xmath1001 we know by the first result that @xmath1005   \\rightarrow\\mathbb{e}\\left [   g_{k,\\epsilon}(\\sigma z)\\right ]   , \\ ] ] in probability , or",
    "@xmath1005   = \\mathbb{e}\\left [   g_{k,\\epsilon}(\\sigma z)\\right ]   + e_{3}(n),\\ ] ] where @xmath1006 in probability .",
    "on the other hand we also have that @xmath1007    &   = \\mathbb{e}\\left [   g_{k,\\epsilon } ( \\sigma z)\\right ]   + d_{1}+d_{2},\\\\ \\left\\vert d_{1}\\right\\vert   &   \\leq\\mathbb{p}\\left (   \\left\\vert \\sigma z\\right\\vert \\geq k\\right )   , \\\\ \\left\\vert d_{2}\\right\\vert   &   \\leq\\epsilon.\\end{aligned}\\ ] ] thus , overall we get that , for any @xmath998 and @xmath594 @xmath1008   -\\mathbb{e}\\left [   f(\\sigma z)\\right ]   \\right\\vert } \\\\ &   \\leq2\\epsilon+e_{3}(n)+(2\\vert f\\vert_{\\infty}+1)\\mathbb{p}\\left (   \\left .",
    "\\sigma z\\right\\vert \\geq k\\right )   .\\end{aligned}\\ ] ] we know that for any @xmath1009 , @xmath1006 in probability .",
    "it is clear that as @xmath1010 the last term vanishes , while we also have that @xmath1011 in probability as @xmath962 by assumption . letting @xmath1012 we have the result .",
    "result ( [ eq : convergencerandommeasures ] ) follows from corollary 2.4 in @xcite while ( [ eq : convergencerandommeasuresboundedlipschitz ] ) follows from the discussion after eq .",
    "( 3 ) in this paper since @xmath968 and @xmath46 are measures on @xmath1013 .",
    "[ propn1]suppose that @xmath1014 , and @xmath958 are as in lemma [ lem : conditionallindebergclt ] . if @xmath1015 in probability , then @xmath1016 in probability .",
    "_ proof of lemma [ propn1 ] .",
    "let @xmath952 .",
    "let @xmath998 be arbitrary , and let @xmath1000 be continuous so that @xmath1017 for @xmath1018 , @xmath1019 for @xmath1020 and @xmath1021 .",
    "then @xmath1000 is continuous , and compactly supported , so also bounded and uniformly continuous . then @xmath1022 &   = \\mathbb{e}\\left [   \\left .",
    "f_{k}(z_{n}+t_{n})\\right\\vert \\mathcal{f}% _ { n}\\right ]   + e_{1}(n),\\\\     then @xmath1023   -\\mathbb{e}\\left [   f_{k}(\\sigma z+c)\\right ] \\right\\vert } \\\\ &   \\leq\\left\\vert \\mathbb{e}\\left [   \\left",
    ".   f_{k}(z_{n}+t_{n})\\right\\vert \\mathcal{f}_{n}\\right ]   -\\mathbb{e}\\left [   \\left .",
    "f_{k}(z_{n}+c)\\right\\vert \\mathcal{f}_{n}\\right ]   \\right\\vert + \\left\\vert \\mathbb{e}\\left [   \\left .",
    "f_{k}(z_{n}+c)\\right\\vert \\mathcal{f}_{n}\\right ]   -\\mathbb{e}\\left [ f_{k}(\\sigma z+c)\\right ]   \\right\\vert .\\end{aligned}\\ ] ] for the first term notice that since @xmath1000 is uniformly continuous , for any @xmath594 , we can find @xmath1024 , so that @xmath1025 implies that @xmath1026 . therefore @xmath1023   -\\mathbb{e}\\left [   \\left .",
    "f_{k}(z_{n}+c)\\right\\vert \\mathcal{f}_{n}\\right ]   \\right\\vert } \\\\ &   \\leq2\\vert f\\vert_{\\infty}\\mathbb{p}\\left (   \\left .",
    "|t_{n}-c|\\geq \\epsilon^{\\prime}\\right\\vert \\mathcal{f}_{n}\\right )   + \\mathbb{e}\\left [ \\left .",
    "|f_{k}(z_{n}+t_{n})-f_{k}(z_{n}+c)|\\mathbf{1}\\left\\ {   |t_{n}% -c|\\leq\\epsilon^{\\prime}\\right\\ }   \\right\\vert \\mathcal{f}_{n}\\right ] \\\\ &   \\leq2\\vert f\\vert_{\\infty}\\mathbb{p}\\left (   \\left .",
    "|t_{n}-c|\\geq \\epsilon^{\\prime}\\right\\vert \\mathcal{f}_{n}\\right )   + \\epsilon.\\end{aligned}\\ ] ] we know that @xmath1027   \\rightarrow0,\\ ] ] and thus @xmath1028 in probability .",
    "this proves that the first term vanishes in probability .",
    "for the second term notice that , @xmath1029 is continuous and bounded , and therefore the second term also vanishes in probability .",
    "we want to study @xmath1030 where @xmath1031 is only a function of the auxiliary variables .",
    "the kernel @xmath873 has been designed as a pseudo - marginal - like algorithm targetting @xmath1032 while @xmath1033 are auxiliary variables .",
    "however , we can also think of @xmath873 as a pseudo - marginal algorithm targetting @xmath1034 while @xmath12 is an auxiliary variable . for presentation brevity",
    ", we drop the index @xmath2 whenever there is no possible confusion .",
    "the cpm kernel is given @xmath1035 where @xmath1036 with @xmath1037 let us consider the following mh  algorithm @xmath1038 where @xmath1039 this kernel admits the same invariant distribution as @xmath40 and we have @xmath1040 where @xmath1041 is the ` ideal ' marginal mh  algorithm .",
    "the following lemma is an adaptation from ( * ? ? ?",
    "* proposition 2 ) .",
    "_ proof of lemma [ proposition : deltadifference ] .",
    "_ we can write for a bounded function @xmath758 @xmath1045   .\\ ] ] now we have by jensen s inequality @xmath1046 hence @xmath1047 for bounded @xmath758 . monotone convergence and",
    "a truncation argument shows this is true for general @xmath758 .",
    "armed with proposition [ proposition : inequalitymattidrieu ] , we will show that @xmath1052 which implies that @xmath1053 .",
    "let @xmath1054 denote the spectral measure of @xmath1055 w.r.t @xmath873 . recall that @xmath1056 is supported on @xmath1057   $ ] and @xmath1058",
    "we will show that @xmath1059 where the l.h.s .",
    "is the expected square jump distance ( esjd ) of @xmath1055 normalised by its variance . by applying jensen s inequality w.r.t the probability measure @xmath1060",
    ", the above inequality will imply that @xmath1061 notice that this also implies that the right spectral gap of @xmath1062 , if it exists , is less than @xmath1063 .",
    "we now show that ( [ eq : esjdclaim ] ) holds , at least under severe regularity conditions listed in the proof which however make the calculations tractable .",
    "we postulate that this result holds under much weaker assumptions .",
    "we will be working on the sequence of events @xmath1075 which satisfies @xmath1076 for any @xmath594 by assumption [ ass : bvm ] .",
    "for presentation brevity , we will only prove the result for @xmath409 and @xmath726 .",
    "recall that we have to prove that @xmath1077 as mentioned before , under regularity conditions ( * ? ? ?",
    "* proposition 3 ) , @xmath1078 .",
    "thus it is enough to prove that @xmath1079 since @xmath1080 is reversible w.r.t .",
    "@xmath1081 the quantity on the left hand side is equal to the expected square jump distance , and thus we have to show that @xmath1082 = o(1).\\ ] ]    recall that @xmath1083 .",
    "using the notation of section [ section : proofcltnightmare ] and a similar continuous - time embedding approach , we have for @xmath1084 @xmath1085 where @xmath1086 because of assumption [ assumption : taylor ] .",
    "to simplify notation , we write drop the dependence on @xmath2 when no confusion is possible .",
    "the expected squared jump distance is then given by@xmath1087 \\\\ &   = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\frac{\\overline{\\pi}\\left (   u\\left (   0\\right )   \\right ) } { \\overline{\\pi}\\left (   \\left .",
    "u\\left (   0\\right )   \\right\\vert \\widehat{\\theta } \\right )   } \\left (   \\frac{\\nabla w\\left (   \\widehat{\\theta},u\\left (   0\\right ) \\right )   } { w\\left (   \\widehat{\\theta},u\\left (   0\\right )   \\right )   } % -\\frac{\\nabla w\\left (   \\widehat{\\theta},u\\left (   \\delta\\right )   \\right ) } { w\\left (   \\widehat{\\theta},u\\left (   \\delta\\right )   \\right )   } \\right ) ^{2}\\cdot1\\wedge\\left (   \\frac{\\overline{\\pi}\\left (   u\\left (   \\delta\\right ) \\right )   } { m\\left (   u\\left (   \\delta\\right )   \\right )   } \\right )   /\\left",
    "( \\frac{\\overline{\\pi}\\left (   u\\left (   0\\right )   \\right )   } { m\\left (   u\\left ( 0\\right )   \\right )   } \\right )   \\right ] \\\\ &   \\leq\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\frac{\\overline{\\pi}\\left (   u\\left ( 0\\right )   \\right )   } { \\overline{\\pi}\\left (   \\left .   u\\left (   0\\right ) \\right\\vert \\widehat{\\theta}\\right )   } \\left (   \\frac{\\nabla w\\left ( \\widehat{\\theta},u\\left (   0\\right )   \\right )   } { w\\left (   \\widehat{\\theta } , u\\left (   0\\right )   \\right )   } -\\frac{\\nabla w\\left (   \\widehat{\\theta } , u\\left (   \\delta\\right )   \\right )   } { w\\left (   \\widehat{\\theta},u\\left ( \\delta\\right )   \\right )   } \\right )   ^{2}\\right ]   .\\\\ &   \\lesssim\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\sum_{t=1}^{t}\\nabla\\eta_{t}% ^{t}+\\nabla\\eta_{t}^{t}.f(\\eta_{t}^{t})\\right )   ^{2}\\right ] \\\\ &   \\lesssim\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\sum_{t=1}^{t}\\nabla\\eta_{t}% ^{t}\\right )   ^{2}\\right ]   + \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\sum_{t=1}% ^{t}\\nabla\\eta_{t}^{t}.f(\\eta_{t}^{t})\\right )   ^{2}\\right]\\end{aligned}\\ ] ] where we have used assumption [ assumption : boundedeverywhere ] .",
    "it is important to also notice that , although the contribution of several terms is @xmath1090 , there are terms with non - vanishing contributions .",
    "if the contribution was @xmath1090 then the same argument as that given in the end of section  [ sec : limitations ] would imply a stronger necessary condition for the inefficiency to remain finite .",
    "it is trivial to see that @xmath1096 \\\\ &   \\lesssim\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\sum_{t=1}^{t}\\nabla l_{t,1}% ^{t}\\right )   ^{2}\\right ]   + \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\sum_{t=1}% ^{t}\\nabla l_{t,2}^{t}\\right )   ^{2}\\right ]   + \\mathbb{e}_{\\overline{\\pi}\\left ( \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\sum _ { t=1}^{t}\\nabla m_{t}^{t}\\right )   ^{2}\\right ]   .\\end{aligned}\\ ] ]      we have @xmath1098   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla l_{t,1}% ^{t}\\right )   ^{2}\\right ]   + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi } \\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla l_{t,1}^{t}.\\nabla l_{s,1}^{t}\\right ]   .\\ ] ] we have for @xmath1099 @xmath1100 = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\nabla l_{t,1}^{t}.\\nabla l_{s,1}^{t}\\right ] = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\nabla l_{t,1}^{t}\\right ]   \\mathbb{e}_{\\overline{\\pi } \\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla l_{s,1}^{t}\\right ]   = 0.\\ ] ] now we have @xmath1101 \\\\ &   = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\left (   \\int_{0}^{\\delta_{t}}\\frac{1}{n\\widehat{w}_{t}% ^{t}\\left (   \\widehat{\\theta}\\right )   } \\sum_{i=1}^{n}\\left\\ {   -\\partial _ { u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta } \\right )   u_{t , i}^{t}\\left (   s\\right )   + \\partial_{u , u,\\theta}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ } \\mathrm{d}s\\right )   ^{2}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\left ( % tcimacro{\\dprod \\nolimits_{r\\neq t}}% % beginexpansion { \\displaystyle\\prod\\nolimits_{r\\neq t } } % endexpansion \\widehat{w}_{r}^{t}\\left (   \\widehat{\\theta}\\right )   \\right )   \\left ( \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   \\right )   ^{-1}.\\left ( \\int_{0}^{\\delta_{t}}\\frac{1}{n}\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u,\\theta } \\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right ) u_{t , i}^{t}\\left (   s\\right )   + \\partial_{u , u,\\theta}\\varpi\\left (   y_{t}% , u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ } \\mathrm{d}s\\right )   ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}% } ^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left (   \\theta\\right ) \\right )   ^{-2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}% \\frac{1}{n}\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u,\\theta}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   u_{t , i}^{t}\\left ( s\\right )   + \\partial_{u , u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\theta\\right )   \\right\\ }   \\mathrm{d}s\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\lesssim\\frac{\\left (   \\delta_{t}\\right )   ^{2}}{n}b\\left (   y_{t}\\right ) ^{1/14 + 1/4}\\\\ &   \\lesssim\\frac{n^{3}}{t^{2}}b\\left (   y_{t}\\right )   ^{1/14 + 1/4}.\\end{aligned}\\ ] ]",
    "we will write further on terms of this form as @xmath1102 , understanding that  the constant is a power of @xmath1103 assumed to have a finite expectation under the distribution @xmath46 of the observations .    we use @xmath1104    &   = \\delta_{t}^{4}\\mathbb{e}_{m}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}f\\left (   u^{t}\\left (   s\\right )   \\right ) \\frac{\\mathrm{d}s}{\\delta_{t}}\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\leq\\delta_{t}^{4}\\mathbb{e}_{m}\\left [   \\left .",
    "(   u^{t}\\left (   s\\right )   \\right )   \\frac{\\mathrm{d}s}{\\delta_{t}% } \\right\\vert \\mathcal{y}^{t}\\right ] \\\\",
    "&   = \\delta_{t}^{4}\\mathbb{e}_{m}\\left [   \\left .",
    "f^{4}\\left (   u^{t}\\left ( 0\\right )   \\right )   \\right\\vert \\mathcal{y}^{t}\\right ]   \\text",
    "{ ( by stationarity).}%\\end{aligned}\\ ] ]      now we have @xmath1106   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla l_{t,2}% ^{t}\\right )   ^{2}\\right ]   + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi } \\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla l_{t,2}^{t}.\\nabla l_{s,2}^{t}\\right ]   .\\ ] ] we have for @xmath1099 @xmath1107 = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\nabla l_{t,2}^{t}\\right ]   \\mathbb{e}_{\\overline{\\pi } \\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla l_{s,2}^{t}\\right]\\ ] ] and @xmath1108 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "{ \\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   \\right\\ }   \\nabla\\log\\widehat{w}_{t}^{t}\\left ( \\widehat{\\theta}\\right )   } { n}\\mathrm{d}s\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\frac{1}{n}\\widetilde{\\mathbb{e}}\\left [   \\left .",
    "-\\nabla\\log \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   \\int_{0}^{\\delta_{t}}% \\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   \\right\\ }   \\mathrm{d}s\\right\\vert \\mathcal{y}% ^{t}\\right ] \\\\ &   \\leq\\frac{1}{n}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .   \\left (   \\nabla\\log\\widehat{w}% _ { t}^{t}\\left (   \\theta\\right )   \\right )   ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}% \\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\theta\\right )   u_{t , i}^{t}\\left (   s\\right )   + \\partial_{u , u}% ^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\right\\ } \\mathrm{d}s\\right )   ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\frac{1}{n}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\frac{\\left (   \\nabla \\widehat{w}_{t}^{t}\\left (   \\theta\\right )   \\right )   ^{2}}{\\left ( \\widehat{w}_{t}^{t}\\left (   \\theta\\right )   \\right )   ^{2}}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}% \\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   \\right\\ }   \\mathrm{d}s\\right )   ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\frac{1}{n}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/4}\\left [   \\left .",
    "\\left (   \\nabla\\widehat{w}_{t}% ^{t}\\left (   \\theta\\right )   \\right )   ^{4}\\right\\vert y_{t}\\right ]   \\sup _ { \\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}}% ^{1/4}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left (   \\theta\\right ) \\right )   ^{-4}\\right\\vert y_{t}\\right ] \\\\ &   \\times\\sqrt{n}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}% } \\left\\",
    "{   -\\partial_{u}\\varpi\\left (   y_{t},u_{t,1}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left (   s\\right )   + \\partial_{u , u}% ^{2}\\varpi\\left (   y_{t},u_{t,1}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right ) \\right\\ }   \\mathrm{d}s\\right )   ^{2}\\right\\vert y_{t}\\right ] \\\\ &   \\lesssim\\frac{1}{n\\sqrt{n}}\\sqrt{n}\\delta_{t}=o\\left (   t^{-1}\\right )   .\\end{aligned}\\ ] ] we have@xmath1109 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .   w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   .\\left (   -\\int_{0}^{\\delta_{t}}\\frac{\\sum_{i=1}^{n}\\left\\ { -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta } \\right )   u_{t , i}^{t}\\left (   s\\right )   + \\partial_{u , u}^{2}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ } \\nabla\\widehat{w}_{t}^{t}}{n\\left (   \\widehat{w}_{t}^{t}\\right )   ^{2}% } \\mathrm{d}s\\right )   ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\frac{\\left (   \\nabla\\log \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   \\right )   ^{2}}% { \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   } .\\left (   -\\int% _ { 0}^{\\delta_{t}}\\frac{1}{n}\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   u_{t , i}% ^{t}\\left (   s\\right )   + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ }   \\mathrm{d}s\\right ) ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}% } ^{1/2}\\left [   \\left .   \\frac{\\left (   \\nabla\\log\\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{4}}{\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{2}}\\right\\vert y_{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   -\\int_{0}^{\\delta_{t}% } \\frac{1}{n}\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t}% , u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\right\\ }   \\mathrm{d}s\\right )   ^{4}\\right\\vert y_{t}\\right ] \\\\ &   \\lesssim\\frac{n}{t^{2}}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/4}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}% ^{t}\\left (   \\theta\\right )   \\right )   ^{-12}\\right\\vert y_{t}\\right ] \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}% } ^{1/4}\\left [   \\left .",
    "\\left (   \\nabla\\widehat{w}_{t}^{t}\\left (   \\theta\\right )",
    "\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   \\lesssim\\frac{n}{t^{2}}.\\end{aligned}\\ ] ]      we have @xmath1111   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla m_{t,1}% ^{t}\\right )   ^{2}\\right ]   + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi } \\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla m_{t,1}^{t}.\\nabla m_{s,1}^{t}\\right ]   .\\ ] ] we have for @xmath1099 @xmath1112 = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\nabla m_{t,1}^{t}\\right ]   \\mathbb{e}_{\\overline{\\pi } \\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla m_{s,1}^{t}\\right ]   = 0.\\ ] ] now we have @xmath1113 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .   w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   .\\left (   \\int_{0}^{\\delta_{t}}\\frac{\\sqrt{2}}% { n\\widehat{w}_{t}^{t}}\\sum_{i=1}^{n}\\partial_{u,\\theta}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\mathrm{d}% b_{t , s}^{i}\\right )   ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .   \\left (   \\int_{0}^{\\delta_{t}}% \\frac{\\sqrt{2}}{n\\sqrt{\\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   } % } \\sum_{i=1}^{n}\\partial_{u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   \\mathrm{d}b_{t , s}^{i}\\right ) ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\frac{2}{n^{2}}\\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\widetilde{\\mathbb{e}% } \\left [   \\left .   \\frac{1}{\\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right ) } \\left\\ {   \\partial_{u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   \\right\\ }   ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\mathrm{d}s\\\\ &   \\lesssim\\frac{\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .   \\left (   \\widehat{w}_{t}% ^{t}\\left (   \\theta\\right )   \\right )   ^{-2}\\right\\vert y_{t}\\right ]   } { n^{2}% } \\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\sup_{\\theta\\in b\\left (   \\overline{\\theta } \\right )   } \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .   \\left\\ {   \\partial _ { u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right ) \\right\\ }   ^{4}\\right\\vert y_{t}\\right ]   \\mathrm{d}s\\\\ &   = o\\left (   1/t\\right )   .\\end{aligned}\\ ] ]      we have @xmath1115   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla m_{t,2}% ^{t}\\right )   ^{2}\\right ]   + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi } \\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla m_{t,2}^{t}.\\nabla m_{s,2}^{t}\\right ]   .\\ ] ] we have for @xmath1099 @xmath1116 = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\nabla m_{t,2}^{t}.\\nabla m_{s,2}^{t}\\right ] = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\nabla m_{t,2}^{t}\\right ]   \\mathbb{e}_{\\overline{\\pi } \\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\nabla m_{s,2}^{t}\\right]\\ ] ] where @xmath1117 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "-\\int_{0}^{\\delta_{t}}\\frac{\\sqrt { 2}\\nabla\\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   } { n\\widehat{w}% _ { t}^{t}\\left (   \\widehat{\\theta}\\right )   } \\left (   \\sum_{i=1}^{n}\\partial",
    "_ { u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right ) \\right )   \\mathrm{d}b_{t , s}^{i}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = 0.\\end{aligned}\\ ] ]    we have @xmath1118 &   = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\left (   \\sum_{i=1}^{n}\\frac{\\sqrt{2}\\nabla\\widehat{w}% _ { t}^{t}\\left (   \\widehat{\\theta}\\right )   } { n\\left (   \\widehat{w}_{t}^{t}\\left ( \\widehat{\\theta}\\right )   \\right )   ^{2}}\\int_{0}^{\\delta_{t}}\\partial_{u}% \\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right ) \\mathrm{d}b_{t , s}^{i}\\right )   ^{2}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .   \\left (   \\sum_{i=1}^{n}\\frac{\\sqrt { 2}\\nabla\\widehat{w}_{t}^{t}}{n\\left (   \\widehat{w}_{t}^{t}\\right )   ^{3/2}}% \\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   \\mathrm{d}b_{t , s}^{i}\\right ) ^{2}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\frac{1}{n}\\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\frac{2\\left ( \\nabla\\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )",
    "\\right )   ^{2}% } { \\left (   \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   \\right )   ^{3}% } \\int_{0}^{\\delta_{t}}\\left\\ {   \\partial_{u}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ }   ^{2}\\mathrm{d}% s\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\frac{1}{n}\\int_{0}^{\\delta_{t}}\\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\frac{2\\left (   \\nabla\\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right ) \\right )   ^{2}}{\\left (   \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right ) \\right )   ^{3}}\\left\\ {   \\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ }   ^{2}\\right\\vert \\mathcal{y}% ^{t}\\right ]   \\mathrm{d}s\\\\ &   \\leq\\frac{\\delta_{t}}{n}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\frac{\\sqrt{2}\\left ( \\nabla\\widehat{w}_{t}^{t}\\left (   \\theta\\right )   \\right )   ^{2}}{\\left ( \\widehat{w}_{t}^{t}\\left (   \\theta\\right )   \\right )   ^{3}}\\right ) ^{2}\\right\\vert y_{t}\\right ]   \\sup_{\\theta\\in b\\left (   \\overline{\\theta } \\right )   } \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left\\ {   \\partial _ { u}\\varpi\\left (   y_{t},u_{t,1}^{t}\\left (   0\\right )   ; \\theta\\right )   \\right\\ } ^{4}\\right\\vert y_{t}\\right ] \\\\ &   = o\\left (   1/t\\right )   .\\end{aligned}\\ ] ]      we have @xmath1120    &   \\leq\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\sum_{t=1}^{t}\\left ( \\nabla\\eta_{t}^{t}\\right )   ^{2}.\\sum_{t=1}^{t}f(\\eta_{t}^{t})^{2}\\right ] \\\\ &   \\lesssim\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\sum_{t=1}^{t}\\left (   \\nabla\\eta_{t}% ^{t}\\right )   ^{2}.\\sum_{t=1}^{t}\\eta_{t}^{t}{}^{2}\\right ] \\\\ &   \\lesssim\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } ^{1/2}\\left [   \\left (   \\sum_{t=1}^{t}\\left ( \\nabla\\eta_{t}^{t}\\right )   ^{2}\\right )   ^{2}\\right ]   \\mathbb{e}_{\\overline { \\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } ^{1/2}\\left [ \\left (   \\sum_{t=1}^{t}\\left (   \\eta_{t}^{t}\\right )   ^{2}\\right )   ^{2}\\right ]   .\\end{aligned}\\ ] ]      we have @xmath1122 &   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla\\eta_{t}^{t}\\right ) ^{4}\\right ]   + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla\\eta_{t}% ^{t}\\right )   ^{2}\\left (   \\nabla\\eta_{s}^{t}\\right )   ^{2}\\right ] \\\\ &   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla\\eta_{t}^{t}\\right ) ^{4}\\right ]   + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla\\eta_{t}% ^{t}\\right )   ^{2}\\right ]   \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla\\eta_{s}% ^{t}\\right )   ^{2}\\right ]   .\\end{aligned}\\ ] ]    we have @xmath1123 \\\\ &   = \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta } \\right )   } \\left [   \\left (   \\nabla l_{t,1}^{t}+\\nabla l_{t,2}^{t}+\\nabla m_{t,1}^{t}+\\nabla m_{t,2}^{t}\\right )   ^{4}\\right ] \\\\ &   \\lesssim\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla l_{t,1}^{t}\\right ) ^{4}\\right ]   + \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla l_{t,2}^{t}\\right ) ^{4}\\right ]   + \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla m_{t,1}^{t}\\right ) ^{4}\\right ]   + \\mathbb{e}_{\\overline{\\pi}\\left (   \\left",
    ".   \\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\nabla m_{t,2}^{t}\\right ) ^{4}\\right ]   .\\end{aligned}\\ ] ] and now @xmath1124 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   .\\left (   \\nabla l_{t,1}^{t}\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\widehat{\\theta}\\right )   \\right )   ^{-3}.\\left (   \\int_{0}^{\\delta_{t}}\\frac { 1}{n}\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u,\\theta}\\varpi\\left (   y_{t}% , u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left ( s\\right )   + \\partial_{u , u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ }   \\mathrm{d}s\\right ) ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .   \\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .   \\left (   \\int_{0}^{\\delta_{t}}% \\frac{1}{n}\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u,\\theta}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   u_{t , i}^{t}\\left ( s\\right )   + \\partial_{u , u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\theta\\right )   \\right\\ }   \\mathrm{d}s\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   = o\\left (   n^{2}/t^{4}\\right )   .\\end{aligned}\\ ] ] we also have @xmath1125 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .   w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   .\\left (   \\nabla l_{t,2}^{t}\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   .\\left (   \\int_{0}^{\\delta_{t}}\\frac{\\sum_{i=1}^{n}\\left\\ { -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta } \\right )   u_{t , i}^{t}\\left (   s\\right )   + \\partial_{u , u}^{2}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\right\\ } \\nabla\\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   } { n\\left ( \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta}\\right )   \\right )   ^{2}}% \\mathrm{d}s\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\nabla\\widehat{w}_{t}^{t}\\left ( \\widehat{\\theta}\\right )   \\left (   \\widehat{w}_{t}^{t}\\left (   \\widehat{\\theta } \\right )   \\right )   ^{-3}.\\left (   \\int_{0}^{\\delta_{t}}\\frac{\\sum_{i=1}% ^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left (   s\\right )   + \\partial_{u , u}% ^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right ) \\right\\ }   } { n}\\mathrm{d}s\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\nabla\\widehat{w}_{t}% ^{t}\\left (   \\theta\\right )   \\right )   ^{2}\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}% \\frac{\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\theta\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\right\\ }   } { n}\\mathrm{d}s\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/4}\\left [   \\left .",
    "\\left (   \\nabla\\widehat{w}_{t}% ^{t}\\left (   \\theta\\right )   \\right )   ^{4}\\right\\vert y_{t}\\right ]   \\sup _ { \\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}}% ^{1/4}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left (   \\theta\\right ) \\right )   ^{-12}\\right\\vert y_{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}% \\frac{\\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\theta\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\right\\ }   } { n}\\mathrm{d}s\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   = o\\left (   \\frac{n^{2}}{t^{4}}\\right )   .\\end{aligned}\\ ] ] we have @xmath1126    & = \\widetilde{\\mathbb{e}}\\left [   \\left .   w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   .\\left (   \\int_{0}^{\\delta_{t}}\\frac{\\sqrt{2}}% { n\\widehat{w}_{t}^{t}}\\sum_{i=1}^{n}\\partial_{u,\\theta}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\mathrm{d}% b_{t , s}^{i}\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .   \\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ]   \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}}^{1/2}\\left [ \\left .",
    "\\left (   \\frac{\\sqrt{2}}{n}\\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}% \\partial_{u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\mathrm{d}b_{t , s}^{i}\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   \\lesssim\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ]   \\frac{1}{n^{2}}% \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}% } ^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}\\partial_{u,\\theta}% \\varpi\\left (   y_{t},u_{t,1}^{t}\\left (   s\\right )   ; \\theta\\right ) \\mathrm{d}b_{t , s}^{i}\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   \\lesssim\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ]   \\frac{1}{n^{2}}\\left [ \\int_{0}^{\\delta_{t}}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/4}\\left (   \\left .",
    "\\left (   \\partial_{u,\\theta}% \\varpi\\left (   y_{t},u_{t,1}^{t}\\left (   0\\right )   ; \\theta\\right )   \\right ) ^{8}\\right\\vert y_{t}\\right )   \\mathrm{d}s\\right ]   ^{2}\\\\ &   = o\\left (   1/t^{2}\\right)\\end{aligned}\\ ] ] and @xmath1127 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   .\\left (   \\int_{0}^{\\delta_{t}}\\frac{\\sqrt{2}\\nabla \\widehat{w}_{t}^{t}}{n\\left (   \\widehat{w}_{t}^{t}\\right )   ^{2}}\\left ( \\sum_{i=1}^{n}\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   \\right )   \\mathrm{d}b_{t , s}^{i}\\right ) ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .   \\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-14}\\right\\vert y_{t}\\right ]   \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}}^{1/2}\\left [ \\left .",
    "\\left (   \\frac{\\sqrt{2}\\nabla\\widehat{w}_{t}^{t}\\left (   \\theta\\right ) } { n}\\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}\\left (   \\partial_{u}\\varpi\\left ( y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right )   \\right )   \\mathrm{d}% b_{t , s}^{i}\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   \\lesssim\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-14}\\right\\vert y_{t}\\right ]   \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}}^{1/4}\\left [ \\left .",
    "\\left (   \\nabla\\widehat{w}_{t}^{t}\\left (   \\theta\\right )   \\right ) ^{16}\\right\\vert y_{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/4}\\left [   \\left .",
    "\\left (   \\frac{1}{n}\\sum_{i=1}% ^{n}\\int_{0}^{\\delta_{t}}\\left (   \\partial_{u}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\theta\\right )   \\right )   \\mathrm{d}b_{t , s}^{i}\\right ) ^{16}\\right\\vert y_{t}\\right ] \\\\ &   \\lesssim\\frac{1}{n^{2}}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/4}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}% } \\partial_{u,\\theta}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\mathrm{d}b_{t , s}^{i}\\right )   ^{16}\\right\\vert y_{t}\\right ] \\\\ &   = o\\left (   \\frac{n^{2}}{t^{4}}\\right )   .\\end{aligned}\\ ] ]      we have @xmath1129   &   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\eta_{t}^{t}\\right )   ^{4}\\right ] + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\eta_{t}% ^{t}\\right )   ^{2}\\left (   \\eta_{s}^{t}\\right )   ^{2}\\right ] \\\\",
    "&   = \\sum_{t=1}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\eta_{t}^{t}\\right )   ^{4}\\right ] + \\sum_{t , s : t\\neq s}^{t}\\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\eta_{t}% ^{t}\\right )   ^{2}\\right ]   \\mathbb{e}_{\\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right )   } \\left [   \\left (   \\eta_{s}% ^{t}\\right )   ^{2}\\right]\\end{aligned}\\ ] ] where @xmath1130   \\mathbb{e}% _ { \\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right ) } \\left [   \\left (   \\eta_{s}^{t}\\right )   ^{2}\\right ]   \\leq\\mathbb{e}% _ { \\overline{\\pi}\\left (   \\left .",
    "\\cdot\\right\\vert \\widehat{\\theta}\\right ) } ^{1/2}\\left [   \\left (   \\eta_{t}^{t}\\right )   ^{4}\\right ]   \\mathbb{e}% _ { \\overline{\\pi}\\left (   \\left .   \\cdot\\right\\vert \\widehat{\\theta}\\right ) } ^{1/2}\\left [   \\left (   \\eta_{t}^{t}\\right )   ^{4}\\right ]   , \\ ] ] with @xmath1131    now we have @xmath1132 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .   w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   \\left (   l_{t}^{t}\\right )   ^{4}\\right\\vert \\mathcal{y}% ^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   \\left (   \\int_{0}^{\\delta_{t}}\\frac{1}{n\\widehat{w}_{t}^{t}% } \\sum_{i=1}^{n}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   \\right\\ }   \\mathrm{d}s\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\widehat{\\theta}\\right )   \\right )   ^{-3}\\left (   \\frac{1}{n}\\sum_{i=1}^{n}% \\int_{0}^{\\delta_{t}}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\widehat{\\theta}\\right )   \\right\\ }   \\mathrm{d}s\\right )   ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\lesssim\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ] \\\\ &   \\times\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\frac{1}{n}\\sum_{i=1}% ^{n}\\int_{0}^{\\delta_{t}}\\left\\ {   -\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\theta\\right )   u_{t , i}^{t}\\left (   s\\right ) + \\partial_{u , u}^{2}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right ) ; \\theta\\right )   \\right\\ }   \\mathrm{d}s\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   = o\\left (   \\frac{n^{2}}{t^{4}}\\right)\\end{aligned}\\ ] ] and @xmath1133 \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   \\left (   m_{t}^{t}\\right )   ^{4}\\right\\vert \\mathcal{y}% ^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "w\\left (   \\widehat{\\theta},u\\left ( 0\\right )   \\right )   \\left (   \\int_{0}^{\\delta_{t}}\\frac{\\sqrt{2}}{n\\widehat{w}% _ { t}^{t}}\\sum_{i=1}^{n}\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left ( s\\right )   ; \\widehat{\\theta}\\right )   \\mathrm{d}b_{t , s}^{i}\\right ) ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   = \\widetilde{\\mathbb{e}}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\widehat{\\theta}\\right )   \\right )   ^{-3}\\left (   \\frac{\\sqrt{2}}{n}\\sum _ { i=1}^{n}\\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left (   y_{t},u_{t , i}% ^{t}\\left (   s\\right )   ; \\widehat{\\theta}\\right )   \\mathrm{d}b_{t , s}^{i}\\right ) ^{4}\\right\\vert \\mathcal{y}^{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ]   \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}}^{1/2}\\left [ \\left .",
    "\\left (   \\frac{\\sqrt{2}}{n}\\sum_{i=1}^{n}\\int_{0}^{\\delta_{t}}% \\partial_{u}\\varpi\\left (   y_{t},u_{t , i}^{t}\\left (   s\\right )   ; \\theta\\right ) \\mathrm{d}b_{t , s}^{i}\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ]   \\frac{1}{n^{2}}% \\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } \\widetilde{\\mathbb{e}% } ^{1/2}\\left [   \\left .",
    "\\left (   \\int_{0}^{\\delta_{t}}\\partial_{u}\\varpi\\left ( y_{t},u_{t,1}^{t}\\left (   s\\right )   ; \\theta\\right )   \\mathrm{d}b_{t ,",
    "s}% ^{i}\\right )   ^{8}\\right\\vert y_{t}\\right ] \\\\ &   \\leq\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right )   } % \\widetilde{\\mathbb{e}}^{1/2}\\left [   \\left .",
    "\\left (   \\widehat{w}_{t}^{t}\\left ( \\theta\\right )   \\right )   ^{-6}\\right\\vert y_{t}\\right ]   \\frac{1}{n^{2}}\\left ( \\int_{0}^{\\delta_{t}}\\sup_{\\theta\\in b\\left (   \\overline{\\theta}\\right ) } \\widetilde{\\mathbb{e}}^{1/4}\\left [   \\left .",
    "\\left (   \\partial_{u}\\varpi\\left ( y_{t},u_{t,1}^{t}\\left (   0\\right )   ; \\theta\\right )   ^{8}\\right )   \\right\\vert y_{t}\\right ]   \\mathrm{d}s\\right )   ^{2}\\\\ &   = o\\left (   \\frac{\\delta_{t}^{2}}{n^{2}}\\right )   = o\\left (   \\frac{1}{t^{2}% } \\right )   .\\end{aligned}\\ ] ]     observations .",
    "the pm  algorithm is applied ( top four plots ) with @xmath436 .",
    "the bottom four graphs display the output for the cpm  algorithm with @xmath1134 . in order , for each algorithm the path of @xmath442 , the histogram of @xmath442 ( both the proposed and accepted values for the pm  scheme ) , the path of the sampled @xmath12 and the associated correlogram are displayed.,width=480,height=316 ]     observations .",
    "top : the integrated autocorrelation time @xmath1135 is plotted against @xmath63 where @xmath443 .",
    "middle : the relative computing time ( relative to the standard pm scheme with @xmath436 ) @xmath1136 against @xmath63 .",
    "bottom : the probability of acceptance in the cpm  scheme against @xmath63.,width=480,height=316 ]     results of corollary [ cor : rif ] for the cpm  scheme .",
    "top : acceptance probability @xmath1137 against the conditional standard deviation @xmath356 .",
    "middle : relative inefficiency @xmath364 against @xmath356 ( solid line @xmath1138 , dashed line @xmath1139 ) .",
    "bottom : relative computing time @xmath1140 against @xmath356 ( solid line @xmath1141 , dashed line @xmath1139 ) .",
    ", width=480,height=316 ]    [ c]lllllllll@xmath2 & @xmath0 & @xmath63 & @xmath1142 & @xmath1143 & if@xmath1144 & @xmath1145 & if@xmath1146 & rif@xmath1146 + @xmath1147 & @xmath1148 & @xmath1149 & @xmath1150 & @xmath1151 & & @xmath1152 & @xmath1153 & + @xmath1154 & @xmath1155 & @xmath1156 & @xmath1157 & @xmath1158 & & @xmath1159 & @xmath1160 & + @xmath1161 & @xmath1162 & @xmath1163 & @xmath1164 & @xmath1165 & & @xmath1166 & @xmath1167 & + @xmath1168 & @xmath1169 & @xmath1170 & @xmath1171 & @xmath1172 & & @xmath1173 & @xmath1174 & + @xmath1175 & @xmath1176 & @xmath1177 & @xmath1178 & @xmath1179 & & @xmath1180 & @xmath1181 & +    [ c]lllllmh ( @xmath1182 ) & & if(@xmath12 ) & & pr(a ) + & & @xmath1183 & & @xmath1172 + & & & & + pm ( @xmath1184 ) & & & & + @xmath0 & & rif(@xmath12 ) & rct(@xmath12 ) & pr(a ) + @xmath1185 & & @xmath1186 & @xmath1187 & @xmath1188 + & & & & + cpm ( @xmath462 ) & & & & + @xmath0 & @xmath356 & rif(@xmath12 ) & rct(@xmath12 ) & pr(a ) + @xmath1189 & @xmath1190 & @xmath1191 & & @xmath1192 + @xmath1193 & @xmath1194 & @xmath1195 & & @xmath1196 + @xmath1197 & @xmath1198 & @xmath1199 & & @xmath1200 + @xmath1201 & @xmath1202 & @xmath1203 & & @xmath1204 + @xmath1205 & @xmath1206 & @xmath1207 & & @xmath1208 + @xmath470 & @xmath1209 & @xmath1210 & & @xmath1211 + @xmath1169 & @xmath1212 & @xmath1213 & & @xmath1214 + @xmath1215 & @xmath1216 & @xmath1217 & & @xmath1218 + @xmath1219 & @xmath1220 & @xmath1221 & & @xmath1222 + @xmath1223 & @xmath1224 & @xmath1225 & & @xmath1226 +     corresponding to table [ tab_ge_8k_varyn ] .",
    "the relative inefficiencies , @xmath1227 , are plotted against @xmath0 ( top left ) and against @xmath356 ( top right ) where @xmath356 is the standard deviation of @xmath1228 .",
    "the relative computing time @xmath1229 for all three parameters against @xmath0 ( middle left ) and against @xmath356 ( middle right ) .",
    "the acceptance rate of the @xmath1230 and the theoretical lower bound , of ( [ eq : lower_prob ] ) , and against @xmath356 ( bottom left ) .",
    "the log of @xmath1142 against the log of @xmath0 ( bottom right ) .",
    "the theoretical expected values , see corollary [ cor : rif ] for @xmath1231 and @xmath1232 are also plotted against @xmath356 ( top and middle right , solid black lines).,width=480,height=316 ]     @xmath479 corresponding to table [ tab_ge_8k_varyn ] .",
    "top : the first @xmath481 iterations of @xmath1233 and @xmath45 ( left ) , the difference @xmath1234 ( right ) .",
    "middle : the histograms of @xmath45 ( left ) and the histogram and theoretical gaussian density , in black , for @xmath1234 ( right ) .",
    "bottom : the draws of @xmath12 ( left ) and the corresponding correlogram ( right ) .",
    ", width=480,height=316 ]    [ c]lllllllll@xmath2 & @xmath0 & @xmath63 & @xmath1142 & @xmath1235 & @xmath1236 & @xmath1145 & @xmath1237 & @xmath1238 + @xmath1239 & @xmath1240 & @xmath1241 & @xmath1242 & @xmath1243 & @xmath1244 & @xmath1245 & @xmath1246 & @xmath1247 + @xmath1248 & @xmath1249 & @xmath1250 & @xmath1251 & @xmath1252 & @xmath1253 & @xmath1254 & @xmath1255 & @xmath1256 + @xmath1257 & @xmath1197 & @xmath1258 & @xmath1259 & @xmath1260 & @xmath1261 & @xmath1262 & @xmath1263 & @xmath1264 + @xmath1265 & @xmath1266 & @xmath1267 & @xmath1268 & @xmath1269 & @xmath1270 & @xmath1271 & @xmath1272 & @xmath1273 +    [ c]lllllmh ( @xmath505 ) & & @xmath1274(@xmath12 ) & & pr(a ) + & & @xmath508 & & @xmath1269 + & & & & + cpm ( @xmath507 ) & & & & + @xmath0 & @xmath1142 & @xmath1275 & @xmath1276 & pr(a ) + @xmath1277 & @xmath1278 & @xmath1279 & @xmath1280 & @xmath1281 + @xmath1282 & @xmath1283 & @xmath1284 & @xmath1285 & @xmath1286 + @xmath1193 & @xmath1287 & @xmath1288 & @xmath1289 & @xmath1290 + @xmath1197 & @xmath1291 & @xmath1292 & @xmath1293 & @xmath1294 + @xmath1266 & @xmath1295 & @xmath1273 & @xmath1296 & @xmath1271 + @xmath1205 & @xmath1297 & @xmath1298 & @xmath1299 & @xmath1300 + @xmath1301 & @xmath1302 & @xmath1303 & @xmath1304 & @xmath1305 + @xmath470 & @xmath1306 & @xmath1307 & @xmath1308 & @xmath1309 + @xmath1310 & @xmath1311 & @xmath1312 & @xmath1313 & @xmath1314 +     @xmath1315 , @xmath1316 . left : the first @xmath481 iterations of @xmath482 and @xmath442 ( top ) , the difference @xmath1228 ( middle ) and the histogram for @xmath1228 together with theoretical gaussian density , in black ( bottom ) .",
    "right : the correlograms of the three parameters from top to bottom .",
    ", width=480,height=316 ]"
  ],
  "abstract_text": [
    "<S> the pseudo - marginal algorithm is a variant of the metropolis  </S>",
    "<S> hastings scheme which samples asymptotically from a target probability density when we are only able to estimate unbiasedly an unnormalized version of it . </S>",
    "<S> it has found numerous applications in bayesian statistics as there are many scenarios where the likelihood function is intractable but can be estimated unbiasedly using monte carlo samples . </S>",
    "<S> several recent contributions have shown that , to optimise the trade off between computational complexity and statistical efficiency , the variance of the log - likelihood ratio estimator appearing in the acceptance probability of this algorithm should be of order 1 . </S>",
    "<S> this typically requires scaling the number @xmath0 of monte carlo samples linearly with@xmath1the number @xmath2 of data points .  </S>",
    "<S> we propose a modification of the pseudo - marginal algorithm , termed the correlated pseudo - marginal algorithm , which is based on a novel log - likelihood ratio estimator computed using the difference of two positively correlated log - likelihood estimators . </S>",
    "<S> we show that the parameters of this algorithm can be selected such that the variance of this estimator is of order @xmath3 when @xmath0 scales sublinearly with @xmath2 and establish weak convergence of the correlated pseudo - marginal chain to an appropriate discrete - time markov process . </S>",
    "<S> this allows us to provide guidelines on the parameter settings of this algorithm . in our numerical examples , </S>",
    "<S> the efficiency of computations is increased relative to the pseudo - marginal method by up to several orders of magnitude for large data sets .    </S>",
    "<S> some key words :  asymptotic posterior normality ; correlated random numbers ; intractable likelihood ; metropolis  hastings algorithm ; particle filter ; state - space model ; weak convergence . </S>"
  ]
}