{
  "article_text": [
    "two - player games on graphs have many applications in computer science , such as the synthesis problem  @xcite , and the model - checking of open reactive systems  @xcite .",
    "games are also fundamental in logics , topology , and automata theory  @xcite",
    ". games with quantitative objectives have been used to design resource - constrained systems  @xcite , and to support quantitative model - checking and robustness  @xcite .    in a two - player game on a graph ,",
    "a token is moved by the players along the edges of the graph .",
    "the set of states is partitioned into player-1 states from which player  @xmath0 moves the token , and player-2 states from which player  @xmath1 moves the token .",
    "the interaction of the two players results in a play , an infinite path through the game graph . in qualitative zero - sum games , each play is winning for one of the player ; in quantitative games , a payoff function assigns a value to every play , which is paid by player  @xmath1 to player  @xmath0 .",
    "therefore , player  @xmath0 tries to maximize the payoff while player  @xmath1 tries to minimize it .",
    "typically , the edges of the graph carry a reward , and the payoff is computed as a function of the infinite sequences of rewards on the play .",
    "two payoff functions have received most of the attention in literature : the _ mean - payoff _ function ( for example , see  @xcite ) and the _ discounted - sum _ function ( for example , see  @xcite ) .",
    "the mean - payoff value is the long - run average of the rewards .",
    "the discounted sum is the infinite sum of the rewards under a discount factor @xmath2 . for an infinite sequence of rewards @xmath3",
    ", we have : @xmath4 while these payoff functions have a simple , intuitive , and mathematically elegant definition , it is natural to ask why they are playing such a central role in the study of quantitative games .",
    "one answer is perhaps that _ memoryless _ optimal strategies exist for these objectives .",
    "a strategy is memoryless if it is independent of the history of the play and depends only on the current state .",
    "related to this property is the fact that the problem of deciding the winner in such games is in np @xmath5 conp , while no polynomial time algorithm is known for this problem .",
    "the situation is similar to the case of parity games in the setting of qualitative games where it was proved that the parity objective is the only prefix - independent objective to admit memoryless winning strategies  @xcite , and the parity condition is known as a canonical way to express @xmath6-regular languages  @xcite .    in this paper",
    ", we prove a similar result in the setting of quantitative games .",
    "we consider a general class of payoff functions which compute an infinite weighted average of the rewards .",
    "the payoff functions are parameterized by an infinite sequence of rational coefficients @xmath7 , and defined as follows : @xmath8 we consider this class of functions for its simple and natural definition , and because it generalizes both mean - payoff and discounted - sum which can be obtained as special cases , namely for @xmath9 for all . ] @xmath10 , and @xmath11 respectively .",
    "we study the problem of characterizing which payoff functions in this class admit memoryless optimal strategies for both players .",
    "our results are as follows :    1 .",
    "if the series @xmath12 converges ( and is finite ) , then discounted sum is the _ only _ payoff function that admits memoryless optimal strategies for both players .",
    "if the series @xmath12 does not converge , but the sequence @xmath7 is bounded , then for memoryless optimal strategies the payoff function is equivalent to the mean - payoff function ( equivalent for the optimal value and optimal strategies of both players ) .",
    "thus our results show that the discounted sum and mean - payoff functions , beside their elegant and intuitive definition , are the only members from a large class of natural payoff functions that are simple ( both players have memoryless optimal strategies ) .",
    "in other words , there is essentially no other simple payoff functions in the class of weighted infinite average payoff functions .",
    "this further establishes the canonicity of the mean - payoff and discounted - sum functions , and suggests that they should play a central role in the emerging theory of quantitative automata and languages  @xcite .    in the study of games on graphs",
    ", characterizing the classes of payoff functions that admit memoryless strategies is a research direction that has been investigated in the works of  @xcite which give general conditions on the payoff functions such that both players have memoryless optimal strategies , and  @xcite which presents similar results when only one player has memoryless optimal strategies .",
    "the conditions given in these previous works are useful in this paper , in particular the fact that it is sufficient to check that memoryless strategies are sufficient in one - player games  @xcite .",
    "however , conditions such as sub - mixing and selectiveness of the payoff function are not immediate to establish , especially when the sum of the coefficients @xmath7 does not converge .",
    "we identify the necessary condition of boundedness of the coefficients @xmath7 to derive the mean - payoff function .",
    "our results show that if the sequence is convergent , then discounted sum ( specified as @xmath13 , for @xmath14 ) is the only memoryless payoff function ; and if the sequence is divergent and bounded , then mean - payoff ( specified as @xmath13 with @xmath15 ) is the only memoryless payoff function .",
    "however we show that if the sequence is divergent and unbounded , then there exists a sequence @xmath13 , with @xmath16 , that does not induce memoryless optimal strategies .",
    "* game graphs . * a two - player _ game graph _ @xmath17 consists of a finite set @xmath18 of states partitioned into states @xmath19 and player-2 states @xmath20 ( i.e. , @xmath21 ) , and a set @xmath22 of edges such that for all @xmath23 , there exists ( at least one ) @xmath24 such that @xmath25 .",
    "the weight function @xmath26 assigns a reward to each edge . for a state @xmath23",
    ", we write @xmath27 for the set of successor states of  @xmath28 .",
    "player-@xmath0 game _ is a game graph where @xmath29 and @xmath30 .",
    "player-@xmath1 games are defined analogously .",
    "* plays and strategies . * a game on @xmath31 starting from a state @xmath32 is played in rounds as follows .",
    "if the game is in a player-1 state , then player  @xmath0 chooses the successor state from the set of outgoing edges ; otherwise the game is in a player-@xmath1 state , and player @xmath1 chooses the successor state .",
    "the game results in a _ play _ from  @xmath33 ,",
    "i.e. , an infinite path @xmath34 such that @xmath35 for all @xmath10 .",
    "we write @xmath36 for the set of all plays .",
    "the prefix of length @xmath37 of @xmath38 is denoted by @xmath39 .",
    "a strategy for a player is a recipe that specifies how to extend plays .",
    "formally , a _ strategy _ for player  @xmath0 is a function @xmath40 such that @xmath41 for all @xmath42 and @xmath43 .",
    "the strategies for player  2 are defined analogously .",
    "we write @xmath44 and @xmath45 for the sets of all strategies for player  1 and player  2 , respectively",
    ". an important special class of strategies are _ memoryless _ strategies which do not depend on the history of a play , but only on the current state .",
    "each memoryless strategy for player  1 can be specified as a function @xmath46 : @xmath47 such that @xmath48 for all @xmath43 , and analogously for memoryless player  2 strategies .",
    "given a starting state @xmath23 , the _ outcome _ of strategies @xmath49 for player  1 , and @xmath50 for player  2 , is the play @xmath51 such that : @xmath52 and for all @xmath53 , if @xmath54 , then @xmath55 , and if @xmath56 , then @xmath57 .    * payoff functions , optimal strategies .",
    "* the objective of player  @xmath0 is to construct a play that maximizes a _ payoff function _",
    "@xmath58 which is a measurable function that assigns to every value a real - valued payoff .",
    "the value for player  @xmath0 is the maximal payoff that can be achieved against all strategies of the other player .",
    "formally the value for player  1 for a starting state @xmath28 is defined as @xmath59 a strategy @xmath60 is _ optimal _ for player  1 from @xmath28 if the strategy achieves at least the value of the game against all strategies for player  2 , i.e. , @xmath61 the values and optimal strategies for player  2 are defined analogously .    the mean - payoff and discounted - sum functions are examples of payoff functions that are well studied , probably because they are simple in the sense that they induce memoryless optimal strategies and that this property yields conceptually simple fixpoint algorithms for game solving  @xcite . in an attempt to construct other simple payoff functions",
    ", we define the class of _ weighted average payoffs _ which compute ( infinite ) weighted averages of the rewards , and we ask which payoff functions in this class induce memoryless optimal strategies .",
    "we say that a sequence @xmath62 of rational numbers has _ no zero partial sum _ if @xmath63 for all @xmath64 .",
    "given a sequence @xmath62 with no zero partial sum , the _ weighted average payoff function _ for a play @xmath65 is @xmath66    note that we use @xmath67 in this definition because the plain limit may not exist in general .",
    "the behavior of the weighted average payoff functions crucially depends on whether the series @xmath68 converges or not .",
    "in particular , the plain limit exists if @xmath69 converges ( and is finite ) .",
    "accordingly , we consider the cases of converging and diverging sum of weights to characterize the class of weighted average payoff functions that admit memoryless optimal strategies for both players .",
    "note that the case where @xmath9 for all @xmath10 gives the mean - payoff function ( and @xmath69 diverges ) , and the case @xmath11 for @xmath2 gives the discounted sum with discount factor @xmath70 ( and @xmath69 converges ) .",
    "all our results hold if we consider @xmath71 instead of @xmath67 in the definition of weighted average objectives .    in the sequel , we consider payoff functions @xmath72 with the implicit assumption that the value of a play @xmath73 according to @xmath74 is @xmath75 since the sequence of rewards determines the payoff value .",
    "we recall the following useful necessary condition for memoryless optimal strategies to exist  @xcite .",
    "a payoff function @xmath74 is _ monotone _ if whenever there exists a finite sequence of rewards @xmath76 and two sequences @xmath77 such that @xmath78 , then @xmath79 for all finite sequence of rewards @xmath80 .",
    "[ prefc ] if the payoff function @xmath74 induces memoryless optimal strategy for all two - player game graphs , then @xmath74 is monotone .",
    "the main result of this section is that for converging sum of weights ( i.e. , if @xmath81 ) , the only weighted average payoff function that induce memoryless optimal strategies is the discounted sum .",
    "[ thm : disc ] let @xmath82 be a sequence of real numbers with no zero partial sum such that @xmath83 .",
    "the weighted average payoff function defined by @xmath82 induces optimal memoryless strategies for all @xmath1-player game graphs if and only if there exists @xmath84 such that @xmath85 for all @xmath10 .    to prove theorem  [ thm : disc ] , we first use its assumptions to obtain necessary conditions for the weighted average payoff function defined by @xmath82 to induce optimal memoryless strategies . by",
    "_ assumptions of theorem  [ thm : disc ] _ , we refer to the fact that @xmath82 is a sequence of real numbers with no zero partial sum such that @xmath83 , and that it defines a weighted average payoff function that induces optimal memoryless strategies for all @xmath1-player game graphs .",
    "all lemmas of this section use the the assumptions of theorem  [ thm : disc ] , but we generally omit to mention them .",
    "let @xmath86 , @xmath87 and @xmath88 .",
    "the assumption that @xmath83 implies that @xmath89 .",
    "note that @xmath90 since @xmath82 is a sequence with no zero partial sum .",
    "we can define the sequence @xmath91 which defines the same payoff function @xmath74 .",
    "therefore we assume without loss of generality that @xmath92 .    ' '' ''    ' '' ''    [ lem:0ll1 ] if the weighted average payoff function defined by @xmath82 induces optimal memoryless strategies for all @xmath1-player game graphs , then @xmath93 .",
    "consider the one - player game graph @xmath94 shown in  [ fig : g1 ] . in one - player games",
    ", strategies correspond to paths .",
    "the two memoryless strategies give the paths @xmath95 and @xmath96 with payoff value  @xmath97 and  @xmath0 respectively .",
    "the strategy which takes edge with reward @xmath0 once , and then always the edge with reward @xmath97 gets payoff @xmath98 .",
    "similarly , the path @xmath99 has payoff @xmath100 = @xmath101 . since all such payoffs must be between the payoffs obtained by the only two memoryless strategies , we have @xmath102 and @xmath103 , and the result follows ( @xmath104 follows from their definition ) .",
    "[ lem : ckdk ] there exists @xmath105 such that @xmath106 and the following inequalities hold , for all @xmath53 : @xmath107 and @xmath108 .    since @xmath109 ( by lemma  [ lem:0ll1 ] ) , we can choose @xmath105 such that @xmath106 . consider the game graph @xmath110 shown in  [ fig : g1 ] and the case when @xmath111 .",
    "the optimal memoryless strategy is to stay on the starting state forever because @xmath112 . using lemma [ prefc ] ,",
    "we conclude that since @xmath113 , we must have @xmath114 i.e. @xmath115 which implies @xmath116 .",
    "now consider the case when @xmath117 in  [ fig : g1 ] .",
    "the optimal memoryless strategy is to choose the edge with reward @xmath118 from the starting state since @xmath119 . using lemma [ prefc ] ,",
    "we conclude that since @xmath120 , we must have @xmath121 i.e. @xmath122 which implies @xmath108 .    from the inequalities in lemma  [ lem : ckdk ] , it is easy to see that since @xmath123 we must have @xmath124 for all @xmath125 .",
    "[ coro : positive ] assuming @xmath92 , we have @xmath124 for all @xmath126",
    ".    it follows from corollary  [ coro : positive ] that the sequence @xmath127 is increasing and bounded from above ( if @xmath128 was not bounded , then there would exist a subsequence @xmath129 which diverges , implying that the sequence @xmath130 converges to @xmath97 in contradiction with the fact that @xmath131 ) .",
    "therefore , @xmath128 must converge to some real number say @xmath132 ( since @xmath92 ) .",
    "we need a last lemma to prove theorem  [ thm : disc ] .",
    "recall that we have @xmath133 for all @xmath134 and @xmath135 .",
    "given a finite game graph  @xmath31 , let @xmath136 be the largest reward in absolute value . for any sequence of rewards @xmath137 in a run on @xmath31 ,",
    "the sequence @xmath138 is increasing and bounded from above by @xmath139 and thus by @xmath140 . therefore , @xmath141 is a convergent sequence and @xmath142 converges as well .",
    "now , we can write the payoff function as @xmath143 . we decompose @xmath144 into @xmath145 and @xmath146 , i.e. @xmath147 .",
    "note that @xmath148 and @xmath149 are well defined .",
    "[ lem : s0s1 ] if there exist numbers @xmath150 such that @xmath151 , then @xmath152 for all @xmath10 .",
    "consider the game graph @xmath153 as shown in  [ fig : g1 ] .",
    "the condition @xmath151 implies that the optimal memoryless strategy is to always choose the edge with reward  @xmath154 .",
    "this means that @xmath155 hence @xmath156 , i.e. @xmath157 for all @xmath10 .",
    "we are now ready to prove the main theorem of this section .",
    "first , we show that @xmath158 . by contradiction , assume that @xmath159 .",
    "choosing @xmath160 , @xmath161 , and @xmath162 in lemma  [ lem : s0s1 ] , and since @xmath163 , we get @xmath164 for all @xmath10 which implies @xmath165 for all @xmath37 , which contradicts that @xmath166 converges to @xmath167 .",
    "now , we have @xmath158 and let @xmath168 . consider a sequence of rational numbers @xmath169 converging to @xmath70 from the right , i.e. , @xmath170 for all @xmath37 , and @xmath171 .",
    "taking @xmath160 , @xmath172 , and @xmath173 in lemma  [ lem : s0s1 ] , and since the condition @xmath174 is equivalent to @xmath175 which holds since @xmath170 , we obtain @xmath176 for all @xmath64 and all @xmath10 , that is @xmath177 and in the limit for @xmath178 , we get @xmath179 for all @xmath10 .    similarly , consider a sequence of rational numbers @xmath180 converging to @xmath70 from the left . taking @xmath181 , @xmath182 , and @xmath183 in lemma  [ lem : s0s1 ] , and",
    "since the condition @xmath184 is equivalent to @xmath185 which holds since @xmath186 , we obtain @xmath187 for all @xmath64 and all @xmath10 , that is @xmath188 and in the limit for @xmath178 , we get @xmath189 for all @xmath10 .",
    "the two results imply that @xmath190 for all @xmath10 where @xmath84 .",
    "note that @xmath191 because @xmath166 converges .",
    "since it is known that for @xmath11 , the weighted average payoff function induces memoryless optimal strategies in all two - player games , theorem [ thm : disc ] shows that discounted sum is the only memoryless payoff function when the sum of weights @xmath192 converges .",
    "in this section we consider weighted average objectives such that the sum of the weights @xmath192 is divergent .",
    "we first consider the case when the sequence @xmath82 is bounded and show that the mean - payoff function is the only memoryless one .",
    "we are interested in characterizing the class of weighted average objectives that are memoryless , under the assumption the sequence @xmath193 is _ bounded _ , i.e. , there exists a constant @xmath194 such that @xmath195 for all @xmath37 .",
    "the boundedness assumption is satisfied by the important special case of regular sequence of weights which can be produced by a deterministic finite automaton .",
    "we say that a sequence @xmath196 is _ regular _ if it is eventually periodic , i.e. there exist @xmath197 and @xmath198 such that @xmath199 for all @xmath200 . recall that we assume the partial sum to be always non - zero , i.e. , @xmath201 for all @xmath37 .",
    "we show the following result .",
    "[ thm : mean ] let @xmath82 be a sequence of real numbers with no zero partial sum such that @xmath202 ( the sum is divergent ) and there exists a constant @xmath194 such that @xmath203 for all @xmath10 ( the sequence is bounded ) .",
    "the weighted average payoff function @xmath74 defined by @xmath82 induces optimal memoryless strategies for all @xmath1-player game graphs if and only if @xmath74 coincides with the mean - payoff function over regular words .      from theorem  [ thm :",
    "mean ] , it follows that all mean - payoff functions  @xmath74 over bounded sequences that induce optimal memoryless strategies are equivalent to the mean - payoff function , in the sense that the optimal value and optimal strategies for  @xmath74 are the same as for the mean - payoff function .",
    "this is because memoryless strategies induce a play that is a regular word .",
    "we also point out that it is not necessary that the sequence @xmath204 consists of a constant value to define the mean - payoff function .",
    "for example , the payoff function defined by the sequence @xmath205 also defines the mean - payoff function .",
    "\\1 . if the subsequence @xmath210 diverges to @xmath211 , assume without loss of generality that each @xmath213 .",
    "consider the one - player game graph @xmath214 shown in figure  [ fig : g1 ] .",
    "we consider the run corresponding to taking the edge with weight @xmath215 for the first @xmath216 steps followed by taking the @xmath97 edge forever .",
    "the payoff for this run is given by @xmath217 since we assume existence of memoryless optimal strategies this payoff should lie between @xmath215 and @xmath97 .",
    "this implies that @xmath218 for all @xmath125 . since @xmath219 and the sequence @xmath220 is unbounded",
    ", we must have @xmath221 .",
    "if the subsequence @xmath210 diverges to @xmath212 , assume that each @xmath222 .",
    "consider the one - player game graph @xmath94 shown in figure [ fig : g1 ] .",
    "we consider the run corresponding to taking the edge with weight @xmath0 for the first @xmath216 steps followed by taking the @xmath97 edge forever .",
    "the payoff for this run is given by @xmath223 this payoff should lie between @xmath97 and @xmath0 ( optimal strategies being memoryless ) , and this implies @xmath221 as above .    since @xmath224 ,",
    "lemma [ lem : sup0 ] concludes that the sequence @xmath225 converges to @xmath97 i.e. @xmath226 .",
    "it also gives us the following corollaries which are a simple consequence of the fact that @xmath227 if @xmath228 converges to @xmath229 .        by corollary [ cor : preind ]",
    ", we have @xmath234 for all @xmath235 . for @xmath236 , consider the payoff @xmath237 for the infinite repetition of the finite sequence of @xmath125 rewards in which all rewards are @xmath97 except the @xmath238th which is @xmath0 .",
    "we show that @xmath239 is independent of @xmath134 .      if @xmath241 then by prefixing by the single letter word @xmath97 and using lemma  [ prefc ] we conclude that @xmath242 .",
    "we continue this process until we get @xmath243 . after applying this step again we get @xmath244 hence , we have @xmath245 .",
    "thus we have @xmath239 is a constant irrespective of the value of @xmath134 .",
    "a similar argument works in the other case when @xmath246 .",
    "we now show that @xmath251 must eventually have always the same sign , i.e. , there exists @xmath252 such that @xmath253 for all @xmath254 .",
    "note that by the assumption of non - zero partial sums , we have @xmath255 for all @xmath37 .",
    "let @xmath256 be such that @xmath257 for all @xmath37 .",
    "since @xmath251 is unbounded , there exists @xmath252 such that @xmath258 for all @xmath259 and then if there exists @xmath260 such that @xmath261 and @xmath262 , we must have @xmath263 and @xmath264 .",
    "thus we have @xmath265 , and hence @xmath266 which contradicts the boundedness assumption on @xmath193 .",
    "if the @xmath128 s are eventually negative then we use the sequence @xmath267 to obtain the same payoff and in this case @xmath268 will be eventually positive .",
    "therefore we assume that there is some @xmath252 such that @xmath269 for all @xmath270 .",
    "let @xmath271 .",
    "we replace @xmath272 by 1 and all @xmath273 s with @xmath274 for @xmath275 . by corollary [ cor : cchange ]",
    "we observe that the payoff function will still not change .",
    "hence , we can also assume that @xmath269 for all @xmath64 .",
    "consider the game graph @xmath284 which consists of state @xmath33 in which the player can choose among @xmath125 cycles of length @xmath125 where in the @xmath134th cycle , all rewards are @xmath97 except on the @xmath238th edge which has reward @xmath0 ( see  [ game : gr_k ] ) .",
    "consider the strategy in state @xmath33 where the player after every @xmath285 steps ( @xmath286 ) chooses the cycle which maximizes the contribution for the next @xmath125 edges .",
    "let @xmath287 be the index such that @xmath288 and @xmath289 for @xmath286 .",
    "the payoff for this strategy is @xmath290 where @xmath291 for @xmath292 .",
    "note that @xmath293 ( the maximum is greater than the average ) , and we get the following ( where @xmath194 is a bound on @xmath294 ) : @xmath295   \\text{hence } \\displaystyle { \\liminf_{n \\rightarrow \\infty}}t_{n } & \\geq & \\displaystyle \\frac{1}{k } - { \\liminf_{n \\rightarrow \\infty}}\\frac{c}{d_{n } } = \\frac{1}{k}. \\end{array}\\ ] ] by lemma  [ lemm : sk0 ] , the payoff of all memoryless strategies in @xmath284 is @xmath296 , and the fact that memoryless optimal strategies exist entails that @xmath297 , and thus @xmath298 for all @xmath236 .      from lemma  [ lem : all - equal ] , it follows that @xmath300 } c_{kr+i } } { d_n } = \\frac{1}{k}\\ ] ] and hence , @xmath301 } c_{kr+i } } { d_n } \\right )   = \\sum_{i=0}^{k-1 } \\left ( a_i \\cdot { \\lim_{n \\rightarrow \\infty}}\\frac{\\sum_{r=0}^{\\left[\\frac{n}{k}\\right ] } c_{kr+i } } { d_n } \\right ) \\\\[2ex ] & = & \\displaystyle \\frac{\\sum_{i=0}^{k-1 } a_i } { k}. \\end{array}\\ ] ] we show that the payoff of a regular word @xmath302 matches the mean - payoff value .",
    "let @xmath306 be such that @xmath307 .",
    "if @xmath308 then using lemma [ prefc ] we obtain @xmath309 . applying the lemma again and again , we get , @xmath310 . from corollary [ cor : preind ]",
    "we obtain @xmath311 and @xmath312 .",
    "therefore , @xmath305 . the same argument goes through for the case @xmath313 .",
    "in lemma  [ lemm : final ] we have shown that the payoff function @xmath74 must match the mean - payoff function for regular words , if the sequence @xmath7 is bounded .",
    "since memoryless strategies in game graphs result in regular words over weights , it follows that the only payoff function that induces memoryless optimal strategies is the mean - payoff function which concludes the proof .",
    "let @xmath82 be a regular sequence of real numbers with no zero partial sum such that @xmath202 ( the sum is divergent ) .",
    "the weighted average payoff function @xmath74 defined by @xmath82 induces optimal memoryless strategies for all two - player game graphs if and only if @xmath74 is the mean - payoff function .",
    "the results of section  [ sec : converging ] and section  [ sec : bounded ] can be summarized as follows : ( 1 ) if the sum of @xmath273 s is convergent , then the sequence @xmath314 , with @xmath14 ( discounted sum ) , is the only class of payoff functions that induce memoryless optimal strategies ; and ( 2 ) if the sum is divergent but the sequence @xmath193 is bounded , then the mean - payoff function is the only payoff function with memoryless optimal strategies ( and the mean - payoff function is defined by the sequence @xmath314 , with @xmath15 ) .",
    "the remaining natural question is that if the sum is divergent and unbounded , then is the sequence @xmath314 , with @xmath16 , the only class that has memoryless optimal strategies .",
    "below we show with an example that the class @xmath315 , with @xmath16 , need not necessarily have memoryless optimal strategies .",
    "we consider the payoff function given by the sequence @xmath316 .",
    "it is easy to verify that the sequence satisfies the partial non - zero assumption .",
    "we show that the payoff function does not result into memoryless optimal strategies . to see this",
    ", we observe that the payoff for a regular word @xmath317 is given by @xmath318 i.e. , the payoff for a regular word is the least possible weighted average payoff for its cycle considering all possible cyclic permutations of its indices ( note that the addition in indices is performed modulo @xmath125 ) .            now , consider the game graph @xmath319 shown in figure [ game:1024 ] . the payoffs for both the memoryless strategies ( choosing the left or the right edge in the start state ) are @xmath320 and @xmath321 which are both equal to @xmath322 .",
    "although , if we consider the strategy which alternates between the two edges in the starting state then the payoff obtained is @xmath323 which is less than payoff for both the memoryless strategies .",
    "hence , the player who minimizes the payoff does not have a memoryless optimal strategy in the game @xmath319 .",
    "the example establishes that the sequence @xmath324 does not induce optimal strategies .",
    "_ open question .",
    "_ though weighted average objectives such that the sequence is divergent and unbounded may not be of the greatest practical relevance , it is an interesting theoretical question to characterize the subclass that induce memoryless strategies .",
    "our counter - example shows that @xmath325 with @xmath16 is not in this subclass ."
  ],
  "abstract_text": [
    "<S> in two - player games on graph , the players construct an infinite path through the game graph and get a reward computed by a payoff function over infinite paths . </S>",
    "<S> over weighted graphs , the typical and most studied payoff functions compute the limit - average or the discounted sum of the rewards along the path . beside their simple definition , </S>",
    "<S> these two payoff functions enjoy the property that memoryless optimal strategies always exist .    in an attempt to construct other simple payoff functions </S>",
    "<S> , we define a class of payoff functions which compute an ( infinite ) weighted average of the rewards . </S>",
    "<S> this new class contains both the limit - average and discounted sum functions , and we show that they are the only members of this class which induce memoryless optimal strategies , showing that there is essentially no other simple payoff functions . </S>"
  ]
}