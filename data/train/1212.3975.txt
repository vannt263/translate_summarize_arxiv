{
  "article_text": [
    "monte carlo simulations are an important tool to investigate a wide range of theoretical models with respect to their statistical properties such as phase transitions , structure formation and more . throughout the last two decades , umbrella sampling algorithms like the multicanonical  @xcite or the wang - landau  @xcite algorithm",
    "have been proven to be very powerful for investigations of statistical phenomena , especially first - order phase transitions , for lattice and off - lattice models .",
    "they have been applied to a variety of systems with rugged free - energy landscapes in physics , chemistry and structural biology  @xcite .",
    "due to the fact that computer performance increases mainly in terms of parallel processing on multi - core architectures , a parallel implementation is of great interest , if the additional cores bring a benefit to the required simulation time .",
    "we present the scaling properties of a simple and straightforward parallelization of the multicanonical method , which has been reported in a similar way in @xcite without much detail to the performance .",
    "this parallelization considers independent markov chains , keeping communication to a minimum .",
    "thus , it can be added on top of the multicanonical algorithm without much modification or system - dependent considerations and is also suitable for systems with simple energy calculation .",
    "similar to this parallelization , there have been previous reports for the wang - landau algorithm  @xcite , which needed a little more adaption to the algorithm .",
    "the multicanonical method allows to sample a system over a range of canonical ensembles at the same time .",
    "this is possible , because the statistical weights are modified in such a way that the simulation reaches each configuration energy of a chosen interval with equal probability , resulting in a flat energy histogram . to this end , the canonical partition function , in terms of the density of states @xmath1 ,",
    "is modified in the following way : @xmath2 in order that each energy state occurs with the same probability , as requested above , the statistical weights have to equal the inverse density of states @xmath3 . after an equilibrium simulation with those weights ,",
    "it is possible to reweight to all canonical ensembles with a boltzmann energy distribution covered by the flat histogram .",
    "this can be done for example by time - series reweighting , where in the average each measured observable is multiplied with its desired weight and divided by the weight with which it was measured : @xmath4    of course , the density of states and consequently the weights that yield a flat energy histogram are not known in advance . therefore the weights have to be obtained iteratively . in the most simple way consecutive weights",
    "are obtained from the last weights and the current energy histogram , @xmath5 .",
    "more sophisticated methods exist , where the full statistics of previous iterations is used for a stable and efficient approximation of the density of states  @xcite .",
    "all our simulations use this recursive version with logarithmic weights in order to avoid numerical problems .",
    "the idea of this parallel implementation , similar to @xcite , is to distribute the time consuming generation of statistics on @xmath6 independent processes .",
    "all processes perform equilibrium simulations with identical weights @xmath7 , @xmath8 , but with different random number seeds , resulting in similar but independent energy histograms @xmath9 .",
    "the histograms are merged after each iteration and one ends up with @xmath10 . according to the weight modification of choice , the collected histogram is processed together with the previous weights in order to estimate the consecutive weights @xmath11 .",
    "the new weights are distributed onto all processes , which run equilibrium simulations again .",
    "that way , the computational effort may be distributed on several cores , allowing to generate the same amount of statistics in a fraction of the time . important",
    "to notice is that a modification of the program only influences the histogram merging and the distribution of the new weights , see fig .",
    "[ fig : pmuca ] .",
    "the iterations are independent copies run in parallel and the weight modification is performed on the master process as in the non - parallelized case .",
    "cores . after each iteration with independent markov chains but identical weights ,",
    "the histograms are merged , the new weights are estimated and the weights are distributed onto all processes again . ,",
    "we consider two discrete two - dimensional spin systems , namely the well known ising model and the @xmath12-state potts model with @xmath13 , where the ising model can be mapped onto the @xmath14 potts model .",
    "the ising model exhibits a second - order phase transition at @xmath15 and the @xmath0-state potts model exhibits a first - order phase transition at @xmath16 .",
    "the spins are located on a square lattice with side length @xmath17 and interact only between nearest neighbors . in case of the ising model ,",
    "the interaction is described by the hamiltonian @xmath18 where @xmath19 is the coupling constant and @xmath20,@xmath21 can take the values @xmath22 . for the @xmath12-state potts model , where each site assumes values from @xmath23 ,",
    "the nearest - neighbors interaction is described by @xmath24 where @xmath25 is the kronecker - delta function which is only non - zero in case @xmath26 .    in those two cases",
    "the number of discrete energy states is equal to the number of lattice sites @xmath27 , such that the width of the energy range increases quickly with system size .",
    "the simulations in this study start at infinite temperature , i.e. , @xmath28 with quite narrow energy histograms . because an estimation of successive weights is only possible for energies with non - zero histogram entries",
    ", the number of iterations may be very large for wide energy ranges . in order to ensure faster convergence ,",
    "our implementation includes after each estimation of weights a correction function , which linearly interpolates the logarithmic weights at the boundaries of the sampled region ( with a range of @xmath17 bins ) , allowing the next iteration to sample a larger energy region .",
    "the muca weights are converged if the last iteration covered the full energy range and all histogram entries are within half and twice the average histogram entry . between convergence of the weights and the final production run",
    ", the systems are thermalized again in order to yield correct estimates of the observables . in both cases ,",
    "each sweep includes @xmath29 number of spin updates .",
    "in order to estimate the performance and the speedup of the parallel algorithm appropriately , we performed the analysis in two steps .",
    "first , we estimated the optimal number of sweeps per iteration and core , which we will refer to as @xmath30 . to this end",
    ", we performed parallel muca simulations over a wide range of @xmath30 for different lattice sizes @xmath17 and number of cores @xmath6 .",
    "the simulations were thermalized once in the beginning on every core , continuing the next iteration with the last state of the previous iteration on that core .",
    "this violates the equilibrium condition a little , as no intermediate thermalization phase was applied and part of the iteration was needed to reach equilibrium .",
    "this is accepted in order to compare the performance equally without an additional parameter to optimize next to @xmath30 .",
    "furthermore , the physical results were not influenced , because each markov chain was thermalized before the final production run .",
    "we determined the mean number of iterations until convergence to a flat histogram @xmath31 as the average over @xmath32 simulations at different initial seeds . plotting the total number of sweeps @xmath33 versus @xmath30",
    ", we can estimate the optimal number of sweeps per iteration and core @xmath34 as the minimum of this function [ see fig .  [",
    "fig : scalingoptimalm](left ) ] . for a small number of cores ,",
    "this curve has a rather broad minimum , introducing a rough estimate .",
    "if , on the other hand , we stretch the curves along the @xmath35-axis with the number of cores , the outcomes look quite similar .    at ( 0,0 ) ; ( -3.10cm,2.65cm)(-3.10cm,-2.1cm)(-2.80cm,-2.1cm)(-2.80cm,2.65 cm ) ; ( -0.60cm,2.65cm)(-0.60cm,-2.1cm)(+1.30cm,-2.1cm)(+1.30cm,2.65 cm ) ;        selected results of the estimation of @xmath34 are shown in fig .",
    "[ fig : scalingoptimalm](right ) . we see that for different lattice sizes and spin models the dependence on the number of cores may be described by a @xmath36 power law , where the amplitudes seem to depend on the system size and the number of states ( notice that the potts model curves nearly coincide with those of the ising model with @xmath37 times system size ) . in order to measure the performance equally , it is convenient to describe @xmath34 by a function of system size @xmath17 and number of cores @xmath6 , @xmath38 , where @xmath39 is the interpolated optimal @xmath30 for one core . therefore , we estimated @xmath34 for the square lattice sizes @xmath0 , @xmath40 , @xmath41 , @xmath42 , @xmath43 , @xmath44 , @xmath45 ( latter two only for ising ) with @xmath46 and fitted for fixed size @xmath47 .",
    "the obtained @xmath48 were plotted over @xmath17 and fitted with a power law ( see fig .",
    "[ fig : scalingoptimalm_sizedependence ] ) .     together with its fit .",
    "each data point is interpolated by fitting @xmath49 to the estimated @xmath34 for @xmath46 . ]    in the end , the optimal number of sweeps per core and iteration were systematically described by the functions @xmath50 which can be justified , considering that a random walk through energy space has to depend on the total system size and the number of spin states .",
    "this power - law behavior corresponds roughly to the scaling of the multicanonical tunneling times in previous works @xcite .",
    "the explicit functional dependence is characteristic for our specific implementation and will be the basis for our performance study ( including larger lattice sizes ) .",
    "interesting to notice is the prefactor ratio between @xmath0-state potts and ising ( which is a @xmath51-potts model ) of about @xmath37 , corresponding to the increase in the number of spin states .",
    "afterwards , we performed parallel muca simulations with different number of cores for each system size , using @xmath52 in order to compare the optimal performance at each degree of parallelization . to this end",
    ", we considered the speedup for @xmath6 cores , defined in terms of real time @xmath53 until convergence of the muca weights , @xmath54 as well as the time - independent statistical speedup , defined in terms of total number of sweeps on each core until convergence @xmath55 , @xmath56_{1 } } { [ \\bar{n}_{\\rm iter } m_{\\rm opt}(l , p)]_{p}},\\ ] ] where the subscript indicates the number of cores used . in order to estimate the mean performance , we averaged the required time and number of sweeps over @xmath42 independent pmuca simulations for each data point .",
    "the results for the ising model are shown in fig .",
    "[ fig : performance_ising ] , revealing that the parallel implementation of muca results in a linear speedup up to @xmath44 cores already for system sizes @xmath57 . in case of",
    "small system sizes @xmath58 , the small @xmath59 leads to convergence of muca weights within milliseconds , which is difficult to measure precisely .",
    "in addition , it can be seen that the statistical speedup scales linearly for all system sizes investigated .",
    "this means that the total required number of sweeps until convergence does not increase with the number of cores ( compare also fig .",
    "[ fig : scalingoptimalm](left ) ) .",
    "this indicates no slowdown of the parallelization other than from communication , which is kept to a minimum . in case of the @xmath0-state potts model ,",
    "the performance does not scale as linearly with the number of cores , see fig .",
    "[ fig : performance_8potts ] , but is still satisfying .",
    "the reason for the drop in performance may be found in the first - order aspect  @xcite of the potts model . in the transition from the disordered to an ordered phase the model undergoes a droplet - strip transition  @xcite .",
    "previous work on multimagnetic simulations of the ising model  @xcite showed that such a transition ( and also the droplet - condensation transition ) is accompanied by `` hidden '' barriers , which are not directly reflected in the multimagnetic or multicanonical histograms and hence are difficult to overcome .",
    "we applied the parallel version of the multicanonical method also to a multimagnetic simulation of the ising model at @xmath60 , determined @xmath61 for the lattice sizes @xmath62 and measured the speedup factor .",
    "the result can be seen in fig .",
    "[ fig : performance_isingmuma ] and shows the same drop in performance as we can observe for the @xmath0-state potts model . with this picture in mind , the drop in performance may be explained by the fact that with increasing @xmath6 we decreased the number of sweeps per iteration and thus decreased the chance to efficiently cross emerging barriers .",
    "when reducing the number of sweeps per iteration as a consequence of parallelization , this reaches a point where the number of sweeps are of the order of the integrated autocorrelation time @xmath63 and each markov chain is strongly correlated , see also fig .",
    "[ fig : limit ] .",
    "exemplary measurements of @xmath63 in the @xmath0-state potts model for different lattice sizes revealed that it was of the order of @xmath64 to @xmath65 , verifying the drop in performance for @xmath66 .",
    "this gives a limit of parallelization depending on the barriers and the associated autocorrelation times of the system .    .",
    "if the number of sweeps per core gets smaller than the integrated autocorrelation time of the markov chain , the convergence of the muca weights gets worse and the performance drops . , width=302 ]    from a practical point of view , when simulating complex systems , it may be advantageous to introduce short thermalization phases between iterations .",
    "exemplary investigations of the @xmath0-state potts model with intermediate thermalization showed that the number of iterations can be reduced significantly while introducing additional computation time .",
    "the parallel muca weight recursion can be extended by a parallel production run , acquiring data with independent markov chains .",
    "this allows equally good estimation of observables for a constant number of total measurements , if it is ensured that each markov chain samples the desired phase space appropriately . for the ising model ,",
    "we considered the relative deviation from the exact result @xmath67  @xcite and averaged over a temperature range around the critical temperature @xmath68 in this case the range was chosen to be @xmath69 $ ] with @xmath70 steps .",
    "figure  [ fig : quality_ising ] shows the average deviation of the specific heat @xmath71 ( @xmath72 ) for different sizes of the ising model .",
    "the error was estimated by averaging over @xmath40 independent runs . in each simulation",
    "there was an additional thermalization phase after the muca - weight convergence and the final production run was performed with @xmath73 measurement points and @xmath74 sweeps between measurements .",
    "the decrease of the relative deviation with increasing lattice size comes from this choice . from fig .",
    "[ fig : quality_ising](right ) it can be seen that , for a given system size , the relative deviations remain constant within the statistical error for all @xmath6 .        in order to verify the quality of the parallel simulation of the @xmath0-state potts model",
    ", we estimated the scaling of the order - disorder interface tension @xmath75 and compared it to analytic results  @xcite .",
    "the interface tension can be approximated in terms of the probability density of the histograms at the transition temperature  @xcite , @xmath76 this requires to first find the temperature for which the reweighted energy histogram shows two equally high peaks [ see fig .",
    "[ fig : quality_potts](left ) ] and then to estimate the ratio between the maximum and minimum . figure  [ fig : quality_potts](right ) shows a rough scaling of the order - disorder interface tension for several system sizes up to @xmath77 , simulated with @xmath44 cores .",
    "the fit to the larger system sizes yields an infinite lattice limit , which is consistent with the exact result  @xcite and verifies that the parallel implementation yields correct results .",
    "we presented a straightforward parallel implementation of the multicanonical algorithm and showed that its scaling properties with the number of cores are very good for the ising model and adequate for the @xmath0-state potts model .",
    "the latter one suffers from emerging barriers at the first - order phase transition , resulting in large integrated autocorrelation times .",
    "the parallelization profits from a minimal amount of communication because histograms are merged at the end of each iteration .",
    "this is the main reason why it is difficult to adapt this method to weight recursions of the wang - landau type where the weights are changed after each spin update .",
    "since it would be interesting to find a similar approach for those weight recursions , not relying on shared memory , we are currently investigating this problem .",
    "the major advantage of the implementation employed here lies in the fact , that no greater adjustment to the usual implementation is necessary and that additional modifications may be carried along .",
    "thus , it can be easily generalized to complex systems , e.g. ( spin ) glasses or ( bio ) polymers , and allows good convergence if it is ensured that the number of sweeps per core is greater than the integrated autocorrelation times .",
    "we are grateful for support from the leipzig graduate school of excellence gsc185 `` buildmona '' and the deutsch - franzsische hochschule ( dfh - ufa ) under grant no .  cdfa-02 - 07 .",
    "this project was funded by the european union and the free state of saxony .",
    "10 b.  a. berg , t. neuhaus , phys .",
    "b 267 ( 1991 ) 249 ; + b.  a. berg , t. neuhaus , phys .",
    "68 ( 1992 ) 9 . w. janke , physica a 254 ( 1998 ) 164 .",
    "f. wang , d.  p. landau , phys .",
    "( 2001 ) 2050 ; + f. wang , d.  p. landau , phys .",
    "e 64 ( 2001 ) 056101 .",
    "w. janke ( ed . ) , rugged free - energy landscapes , lect .",
    "notes phys . 736 ( 2008 )",
    "203 ; + a. mitsutake , y. sugita , y. okamoto , biopolymers ( peptide science ) 60 ( 2001 ) 96 . v. v. slavin , low temp .",
    "36 ( 2010 ) 243 ; + a. ghazisaeidi , f. vacondio , l.  a. rusch , j. lightwave technol . 28",
    "( 2010 ) 79 .",
    "l. zhan , comput .",
    "phys . comm . 179",
    "( 2008 ) 339 .",
    "j. yin , d.  p. landau , comput .",
    "( 2012 ) 1568 .",
    "w. janke , b.  a. berg , m. katoot , nucl .",
    "b 382 ( 1992 ) 649 .",
    "w. janke , in : computer simulations of surfaces and interfaces , ed .",
    "b.  dnweg , d.  p. landau , a.  i. milchev ( kluwer , dordrecht , 2003 ) p.  111 . v. martin - mayor , phys .",
    "98 ( 2007 ) 137207 .",
    "a. nubaumer , e. bittner , t. neuhaus , w. janke , europhys .",
    "75 ( 2006 ) 716 ; + a. nubaumer , e. bittner , t. neuhaus , w. janke , physics procedia 7 ( 2010 ) 52 ; + a. nubaumer , e. bittner , w. janke , phys .",
    "e 77 ( 2008 ) 041109 ; + a. nubaumer , e. bittner , w. janke , prog .",
    "184 ( 2010 ) 400 .",
    "b. kaufman , phys .",
    "76 ( 1949 ) 1232 . c. borgs , w. janke , j. phys .",
    "i france 2 ( 1992 ) 2011 .",
    "k. binder , phys .",
    "a 25 ( 1982 ) 1699 ; + w. janke , nucl",
    "b ( proc . suppl . ) 63a - c ( 1998 ) 631 ."
  ],
  "abstract_text": [
    "<S> the multicanonical method has been proven powerful for statistical investigations of lattice and off - lattice systems throughout the last two decades . </S>",
    "<S> we discuss an intuitive but very efficient parallel implementation of this algorithm and analyze its scaling properties for discrete energy systems , namely the ising model and the @xmath0-state potts model . </S>",
    "<S> the parallelization relies on independent equilibrium simulations in each iteration with identical weights , merging their statistics in order to obtain estimates for the successive weights . with good care , </S>",
    "<S> this allows faster investigations of large systems , because it distributes the time - consuming weight - iteration procedure and allows parallel production runs . </S>",
    "<S> we show that the parallel implementation scales very well for the simple ising model , while the performance of the @xmath0-state potts model , which exhibits a first - order phase transition , is limited due to emerging barriers and the resulting large integrated autocorrelation times . </S>",
    "<S> the quality of estimates in parallel production runs remains of the same order at same statistical cost .    </S>",
    "<S> parallel , multicanonical , ising , potts </S>"
  ]
}