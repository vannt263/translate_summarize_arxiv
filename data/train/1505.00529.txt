{
  "article_text": [
    "as one of the most fundamental preprocessing methods in various document analysis work @xcite , document binarization aims to convert a color or grayscale document image into a monotonic image , where all text pixels of interest are marked in black with a white background . mathematically , given a document image @xmath0 , j\\in[1,h]}$ ] of size @xmath1",
    ", image binarization assigns each pixel @xmath2 a binary class label @xmath3 according to a decision function @xmath4 in a meaningful way , namely @xmath5 a successful document binarization process discards irrelevant and noisy information while preserving meaningful information in the binary image @xmath6 .",
    "this process reduces the space to represent a document image , and largely simplifies the complexity of advanced document analysis tasks @xcite .",
    "although human do not often face many difficulties in identifying texts even on some low - quality document images , is indeed subjective and ill - posed @xcite , and it involves many different challenges and combinations of challenges .",
    "for example , several of the well - known ones are 1 ) how to handle document degradations like ink blob , fade text etc . ;",
    "2 ) how to deal with uneven lighting ; and 3 ) how to differentiate bleed - through text from normal text . in such difficult scenarios ,",
    "human actually uses high - level knowledge that might not be easily captured by low - level features  such as a script character set and background texture analysis  to help decide which pixel is foreground text .",
    "classic solutions more or less seek heuristic thresholds in simple feature spaces .",
    "this can be further grouped into the so - called _ global thresholding _ and _ local thresholding _",
    "methods @xcite according to whether this threshold is location independent or not .",
    "for example , otsu s method @xcite binarizes a pixel @xmath2 by comparing its _ pixel intensity _",
    "@xmath7 to an optimal global threshold @xmath8 derived from _ intensity histogram _ @xcite",
    "as shown in @xmath9 in contrast niblack s method @xcite uses the decision function @xmath10 where @xmath11 is a parameter below 0 , and @xmath12 and @xmath13 denote the mean and standard deviation of pixel intensities within a region @xmath14 of size @xmath15 .",
    "although heuristic solutions are very efficient  may only requiring a constant number of operations per pixel , and work fairly well on many well - conditioned document images , it is clear that simple features and decision functions are insufficient for handling difficult cases .    to achieve robust document binarization",
    ", many efforts are being made in the areas of 1 ) image normalization / adaptation , 2 ) discriminative feature space , and 3 ) more complicated decision functions .",
    "for example , lu @xcite proposes a local thresholding approach that mainly relies on background estimation and stroke estimation .",
    "su @xcite finds that otsu s thresholding helps attain more discriminative power in a local contrast feature space .",
    "sauvola @xcite adds the parameter @xmath16 to allow a non - linear decision plane .",
    "@xmath17 although many of these attempts work well when method assumptions are satisfied and method parameters are appropriate , adapting a heuristic binarization method to a new domain is often not easy . indeed , lazzara et al .",
    "@xcite show that the original sauovla method might fail even for well - scanned document images because of text fonts of different sizes .",
    "unsupervised learning recently dominates document binarization area . in @xcite ,",
    "a document image is first clustered into three classes , namely foreground , background and uncertain , and pixels in the uncertain class will be further classified into either the foreground or background class according to their distances from these two classes . in @xcite , an image",
    "is first transformed into a laplacian feature space , and a global energy function is constructed to ensure that resulting binary labels are optimal in the sense of a predefined markov random field . in @xcite , an unsupervised ensemble of expert frameworks is used to combine multiple binarization candidates .",
    "although these methods do not require a training stage , some rely on theoretical models or heuristic rules whose assumptions may not be necessarily satisfied , some require expensive iterative tuning and optimizations , and thus no surprise to see they are not reliable for certain types of degradations @xcite .",
    "although image binarization is clearly a classification problem , supervised learning - based binarization solutions are still rare in the community . in this letter we discuss our initial attempts to solve the using supervised learning .",
    "the remainder of our paper is organized as follows : section ii overviews our solution and discusses all used features .",
    "section iii provides implementation details related to training and testing .",
    "section iv shows our experimental results , and section v concludes this paper .",
    "our goal is to develop a generic solution without preset parameters and pre- or post - processing .",
    "specifically , we are interested in learning a decision function @xmath18 that maps a @xmath19d feature vector @xmath20 extracted around a pixel @xmath2 to a binary space @xmath21 in a meaningful way , i.e. @xmath22 detailed feature engineering discussions are given below .      since",
    "a number of simple tasks can be accomplished just by applying otsu s method .",
    "we thus include a pixel intensity @xmath7 and its deviation from the otsu s threshold as features below @xmath23 @xmath24 in addition , we also use local statistics of eqs . and , but with respect to different scales , i.e. , @xmath25 @xmath26 where we make the size @xmath27 of local window @xmath14 be associated with scales @xmath28 $ ] , and estimate stroke width @xmath29 using su s method @xcite .",
    "inspired by the success of the su @xcite and howe methods @xcite , we include their contrast and laplacian features shown in and .",
    "@xmath30 @xmath31      to include niblack s decision function in our considerations , we first rearrange terms in according to @xmath32 , as shown below @xmath33 and then compute a so - called exponential truncated niblack index ( etni ) feature as follows .",
    "@xmath34 fig .",
    "[ fig.etni ] compares an image in the original form and its corresponding etri feature space .     of size @xmath35 . ,",
    "title=\"fig:\"](a )   of size @xmath35 .",
    ", title=\"fig:\"](b )      similarly , we rearrange terms in sauvola s decision function according to @xmath36 for its key parameter @xmath37 as follows , @xmath38 since @xmath39 could be @xmath40 , we normalize this index by using the logistic function shown in eq . , and call it the logistic truncated sauvola index ( ltsi ) , @xmath41 where the range of @xmath42 is @xmath43 $ ] , and the condition @xmath44 ensures the sign consistency of @xmath39 .",
    "ltsi thus reflects the sauvola decision surface .",
    "a sample result of the ltsi feature is given in fig .",
    "[ fig.ltsi ] .     of size @xmath45 . ,",
    "title=\"fig:\"](a )   of size @xmath45 . ,",
    "title=\"fig:\"](b )      intuitively , the darkness of a pixel is related to whether it is a text pixel . given a region @xmath46 , the percentile of the pixel s intensity can be computed as @xmath47 where @xmath48 denotes the indicator function whose value is 1 when @xmath49 and 0 otherwise , and @xmath50 denotes the cardinality function .",
    "it is clear that this percentile is a type of rank feature , and thus is invariant to any monotonic transform on the original intensity space . to give a higher resolution for lower percentiles",
    ", we use the logarithm version of as shown in , and call it logarithm intensity percentile ( lip ) feature . here",
    "@xmath51 is a threshold ( = .01 in this paper ) . @xmath52    with regard to @xmath46 , we make parallelogram @xmath46 cover multiple rows , columns , diagonals , and inverse diagonals .",
    "the number of rows , columns , diagonals and inverse diagonals in @xmath46 is made to be @xmath53 times the estimated stroke width @xmath29 . finally , we also compute the lip features with respect to the entire image and the maximum percentile among all previously extracted lip features .",
    "[ fig.lip ] shows the original document with its corresponding features in the lip spaces .",
    "as one can see , the lip space indeed provides more discriminative powers .",
    "@c@m.05cm@c@m.05cm@c@m.05cm@c@m.05cm@c@m.05cm@c@ & & & & & & & & & &   + ( a ) & & ( b ) & & ( c ) & & ( d ) & & ( e ) & & ( f ) +      inspired by the great success of local ternary patterns(ltp ) @xcite in face recognition , we borrow their essences here .",
    "ltp relies on the comparison of a center pixel s intensity with each pixel in a set of neighbors @xmath54 that are on a radius @xmath55 circle , and the @xmath56th code in a length-@xmath53 code string is defined as @xmath57 where @xmath58 and @xmath59 denote the relative coordinates of a neighbor @xmath60 w.r.t .",
    "a center pixel , and @xmath61 is a preset tolerance .",
    "however , the number of possible ltp codes is often huge to effectively encode .",
    "though one may reduce this number by considering all shift - equivalent codes as one , or separating a ternary code into two binary codes , we find that the simple frequency count of each code in a code string has already revealed many intrinsic properties of pixels , and we call them the relative darkness index ( rdi ) features .",
    "precisely , given the code @xmath62 and neighbors on a radius @xmath55 circle , the rdi feature can be defined as below @xmath63 as one can see from fig.[fig.rdi](c - e ) , most of the nearly homogeneous background parts are of high code 0 indices ; pixels close to strong edges are dominated by code+1 indices , and foreground text pixels have high response on code-1 indices . to further enhance rdi s discriminative power , we compute the ratios of one code to the sum of itself and another code as well ( see fig.[fig.rdi](f - h ) ) .    for @xmath64 , respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](a ) for @xmath64 , respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](a ) for @xmath64 , respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](c ) for @xmath64 , respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](d ) for @xmath64 ,",
    "respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](e ) for @xmath64 , respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](f ) for @xmath64 , respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](g ) for @xmath64 , respectively ; ( f ) @xmath65 ; ( g)@xmath66 ; and ( h ) @xmath67 .,title=\"fig:\"](h )      besides of features discussed above , we extract features from the global image statistics , including the mean and standard deviation of the entire image intensities , the mean and standard deviation of the percentile image , the 32 bins of normalized histogram ( sum to 1 ) for image intensities , and the 32 bins of a normalized logarithmed histogram .",
    "in experiments , we use the widely accepted document image binarization contest ( dibco ) from 2009 to 2014 as our training and testing data ; it totals 76 images .",
    "we adopt the leave - one - out strategy where we first pick a dibco image set of a particular year as our testing set , and use the rest as our training set .",
    "we summarize all used features with dimensions and corresponding normalization considerations in table [ tab.feat ] . here",
    ", the stroke width @xmath29 can be estimated via various methods ; we use su s method @xcite .",
    "` scale ' indicates the side of local square region @xmath14 .",
    ".used features [ cols= \" > , > , > , > \" , ]",
    "in this paper we investigate the document binarization solution via supervised learning . unlike previous efforts , this solution is parameter - free and fully trainable .",
    "our experimental results showed that one can learn a reasonably well binarization decision function from a small set of carefully selected training data .",
    "such a learned decision function not only works well for in - domain data , but can also apply to out - of - domain data . in future work , we will explore several interesting aspects such as discriminative features ( e.g. , image moments and connected component attributes ) and classifier adaptation on the fly .",
    "b.  su , s.  lu , and c.  l. tan , `` binarization of historical document images using the local maximum and minimum , '' in _ proceedings of the 9th iapr international workshop on document analysis systems_.1em plus 0.5em minus 0.4emacm , 2010 , pp . 159166 .",
    "b.  gatos , k.  ntirogiannis , and i.  pratikakis , `` icdar 2009 document image binarization contest ( dibco 2009 ) , '' in _ document analysis and recognition ( icdar ) , 2009 international conference on _ , vol .  9 , 2009 , pp .",
    "13751382 .",
    "i.  pratikakis , b.  gatos , and k.  ntirogiannis , `` h - dibco 2010-handwritten document image binarization competition , '' in _ frontiers in handwriting recognition ( icfhr ) , 2010 international conference on_.1em plus 0.5em minus 0.4emieee , 2010 , pp .",
    "727732 .",
    " , `` icdar 2013 document image binarization contest ( dibco 2013 ) , '' in _ document analysis and recognition ( icdar ) , 2013 international conference on_.1em plus 0.5em minus 0.4emieee , 2013 , pp .",
    "14711476 .",
    "k.  ntirogiannis , b.  gatos , and i.  pratikakis , `` icfhr2014 competition on handwritten document image binarization ( h - dibco 2014 ) , '' in _",
    "2014 14th international conference on frontiers in handwriting recognition _ , 2014 , pp .",
    "809813 .",
    "x.  peng , h.  cao , r.  prasad , and p.  natarajan , `` text extraction from video using conditional random fields , '' in _ document analysis and recognition ( icdar ) , 2011 international conference on _ , sept 2011 , pp . 10291033 .",
    "j.  sauvola , t.  seppanen , s.  haapakoski , and m.  pietikainen , `` adaptive document binarization , '' in _ document analysis and recognition , 1997 .",
    ", proceedings of the fourth international conference on _ , vol .",
    "1.1em plus 0.5em minus 0.4emieee , 1997 , pp .",
    "147152 .",
    "b.  su , s.  lu , and c.  l. tan , `` a learning framework for degraded document image binarization using markov random field , '' in _ pattern recognition ( icpr ) , 2012 21st international conference on_.1em plus 0.5em minus 0.4emieee , 2012 , pp . 32003203 .",
    "r.  f. moghaddam , f.  f. moghaddam , and m.  cheriet , `` unsupervised ensemble of experts ( eoe ) framework for automatic binarization of document images , '' in _ document analysis and recognition ( icdar ) , 2013 12th international conference on_.1em plus 0.5em minus 0.4emieee , 2013 , pp .",
    "703707 .",
    "m.  a. ramrez - ortegn , e.  tapia , l.  l. ramrez - ramrez , r.  rojas , and e.  cuevas , `` transition pixel : a concept for binarization based on edge detection and gray - intensity histograms , '' _ pattern recognition _ , vol .",
    "43 , no .  4 , pp . 12331243 , 2010 .",
    "f.  pedregosa , g.  varoquaux , a.  gramfort , v.  michel , b.  thirion , o.  grisel , m.  blondel , p.  prettenhofer , r.  weiss , v.  dubourg , j.  vanderplas , a.  passos , d.  cournapeau , m.  brucher , m.  perrot , and e.  duchesnay , `` scikit - learn : machine learning in python , '' _ journal of machine learning research _ , vol .",
    "12 , pp . 28252830 , 2011 .",
    "h.  z. nafchi , r.  f. moghaddam , and m.  cheriet , `` historical document binarization based on phase information of images , '' in _ computer vision - accv 2012 workshops_.1em plus 0.5em minus 0.4emspringer , 2013 , pp ."
  ],
  "abstract_text": [
    "<S> in this paper we present a fully trainable binarization solution for degraded document images . unlike previous attempts that often used simple features with a series of pre- and post - processing , our solution encodes all heuristics about whether or not a pixel is foreground text into a high - dimensional feature vector and learns a more complicated decision function . in particular , we prepare features of three types : 1 ) existing features for binarization such as _ intensity _ </S>",
    "<S> @xcite , _ contrast _ @xcite , and _ </S>",
    "<S> laplacian _ </S>",
    "<S> @xcite ; 2 ) reformulated features from existing binarization decision functions such those in @xcite and @xcite ; and 3 ) our newly developed features , namely the logarithm intensity percentile ( lip ) and the relative darkness index ( rdi ) . </S>",
    "<S> our initial experimental results show that using only selected samples ( about 1.5% of all available training data ) , we can achieve a binarization performance comparable to those fine - tuned ( typically by hand ) , state - of - the - art methods . </S>",
    "<S> additionally , the trained document binarization classifier shows good generalization capabilities on out - of - domain data . </S>"
  ]
}