{
  "article_text": [
    "we represent word - meaning and meaning - meaning relations uncovered by translation dictionaries between each language in the unbiased sample and major modern european languages by constructing a network structure . two meanings ( represented by a set of english words )",
    "are linked if they are translated from one to another and then back , and the link is weighted by the number of paths of the translation , or the number of words that represent both meanings ( see methods for detail ) .",
    "figure [ fig : schematic ] illustrates the construction in the case of two languages , lakhota ( primarily spoken in north and south dakota ) and coast tsimshian ( mostly spoken in northwestern british columbia and southeastern alaska ) .",
    "translation of sun in lakhota results _ w _ and _ @xmath0paw_. while the later picks up no other meaning , _ w _ is a polysemy that possesses additional meanings of moon and month , hence they are linked to sun .",
    "such polysemy is also observed in coast tsimshian where _ gyemk _ , translated from sun , covers additional meanings including , thus additionally linking to , heat .",
    "each language has its own way of partitioning meanings by words , captured in a semantic network of the language .",
    "it is conceivable , however , that a group of languages bear structural resemblance perhaps because the speakers share historical or environmental features .",
    "a link between sun and moon , for example , reoccurs in both languages , but does not appear in many other languages .",
    "sun is instead linked to divinity and time in japanese , and to thirst and day / daytime in !",
    "the question then is the degree to which the observed polysemy patterns are general or sensitive to the environment inhabited by the speech community , phylogenetic history of the languages , and intrinsic linguistic factors such as literary tradition .",
    "we test such question by grouping the individual networks in a number of ways according to properties of their corresponding languages .",
    "we first analyze the networks of the entire languages , and then of sub - groups .    in fig .",
    "[ fig : connectance_graph ] , we present the network of the entire languages exhibiting the broad topological structure of polysemies observed in our data .",
    "it reveals three almost - disconnected clusters , groups of concepts that are indeed more prone to polysemy within , that are associated with a natural semantic interpretation .",
    "the semantically most uniform cluster , colored in blue , includes concepts related to water . a second , smaller cluster , colored in yellow , associates solid natural substances ( centered around stone / rock ) with their topographic manifestation ( mountain ) .",
    "the third cluster , in red , is more loosely connected , bridging a terrestrial cluster and a celestial cluster , including less tangible substances such as wind , sky , and fire , and salient time intervals such as day and year . in keeping with many traditional oppositions between earth and sky / heaven , or darkness , and light , the celestial , and terrestrial components form two sub - clusters connected most strongly through cloud , which shares properties of both .",
    "the result reveals a coherent set of relationships among concepts that possibly reflects human cognitive conceptualization of these semantic domains @xcite .",
    "we test whether these relationships are universal rather than particular to properties of linguistic groups such as physical environment that human societies inhabit .",
    "we first categorized languages by nonlinguistic variables such as geography , topography , climate , and the existence or nonexistence of a literary tradition ( table  [ tab : groups ] in appendix ) and constructed a network for each group . a spectral algorithm",
    "then clusters swadesh entries into a hierarchical structure or dendrogram for each language group . using standard metrics on trees @xcite , we find that the dendrograms of language groups are much closer to each other than to dendrograms of randomly permuted leaves : thus the hypothesis that languages of different subgroups share no semantic structure in common is rejected ( @xmath1 , see methods)sea / ocean and salt are , for example , more related than either is to sun in every group we tried . in addition , the distances between dendrograms of language groups are statistically indistinguishable from the distances between bootstrapped languages ( @xmath2 ) .",
    "figure 3 shows a summary of the statistical tests of 11 different groups .",
    "thus our data analyses provide consistent evidences that all languages share semantic structure , the way concepts are clustered in fig .",
    "2 , with no significant influence from environmental or cultural factors .",
    "another structural feature apparent in fig .",
    "[ fig : connectance_graph ] is the heterogeneity of the node degrees and link weights .",
    "the numbers of polysemies involving individual meanings are uneven , possibly toward a heavy - tailed distribution ( fig .",
    "[ fig : word_degree_rank ] ) .",
    "this indicates concepts not only form clusters within which they are densely connected , but also exhibit different levels of being polysemous .",
    "for example , earth / soil has more than hundreds of polysemes while salt has only a few .",
    "having shown that some aspects of the semantic network are universal , we next ask whether the observed heterogeneous degrees of polysemy , possibly a manifestation of varying densities of near conceptual neighbors , arise as artifacts of language family structure in our sample , or if they are inherent to the concepts themselves .",
    "simply put , is it an intrinsic property of the concept , earth / soil , to be extensively polysemous , or is it a few languages that happened to call the same concept in so many different ways .",
    "suppose an underlying `` universal space '' relative to which each language @xmath3 randomly draws a subset of polysemies for each concept @xmath4",
    ". the number of polysemies @xmath5 should then be linearly proportional to both the tendency of the concept to be polysemous for being close to many other concepts , and the tendency of the language to distinguish word senses in basic vocabulary .",
    "in our network representation , a proxy for the former is the weighted degree @xmath6 of node @xmath4 , and a proxy for the latter is the total weight of links @xmath7 in language @xmath3 .",
    "then the number of polysemies is expected ( see methods ) : @xmath8 this simple model indeed captures the gross features of the data very well ( fig .",
    "[ fig : productmodel_matrix ] in the appendix ) . nevertheless , the kullback - leibler divergence between the prediction @xmath9 and the empirical data @xmath10 identifies deviations beyond the sampling errors in three concepts  moon , sun and ashes  that display nonlinear increase in the number of polysemies ( @xmath11 ) with the tendency of the language distinguish word senses as fig .",
    "[ fig : saturating_words ] in the appendix shows . accommodating saturation parameters ( table  [ tab : fitvalue ] in the appendix ) enables the random sampling model to reproduce the empirical data in good agreement keeping the two parameters independent , hence retain the universality over language groups .",
    "the similarity relations between word meanings through common polysemies exhibit a universal structure , manifested as intrinsic closeness between concepts , that transcends cultural or environmental factors .",
    "polysemy arises when two or more concepts are fundamental enough to receive distinct vocabulary terms in some languages , yet similar enough to share a common term in others .",
    "the highly variable degree of these polysemies indicates such salient concepts are not homogeneously distributed in the _ conceptual _ space , and the intrinsic parameter that describes the overall propensity of a word to participate in polysemies can then be interpreted as a measure of the local density around such concept .",
    "our model suggests that given the overall semantic ambiguity observed in the languages , such local density determines the degree of polysemies .",
    "universal structures in lexical semantics would greatly aid another subject of broad interest , namely reconstruction of human phylogeny using linguistic data @xcite .",
    "much progress has been made in reconstructing the phylogenies of word forms from known cognates in various languages , thanks to the ability to measure phonetic similarity and our knowledge of the processes of sound change .",
    "however , the relationship between semantic similarity and semantic shift is still poorly understood .",
    "the standard view in historical linguistics is that any meaning can change to any other meaning @xcite , and that no constraint is imposed on what meanings can be compared to detect cognates @xcite .",
    "it is , however , generally accepted among historical linguists that language change is gradual , and that words in transition from having one meaning to being extended to another meaning should be polysemous .",
    "if this is true , then the weights on different links reflect the probabilities that words in transition over these links will be captured in `` snapshots '' by language translation at any time .",
    "such semantic shifts can be modeled as diffusion in the conceptual space , or along a universal polysemy network where our constructed networks can serve an important input to methods of inferring cognates .    .",
    "entries from the initial swadesh list are distinguished with capital letters .",
    "( a ) in - strengths of concepts : sum of weighted links to a node .",
    "( b ) out - strengths of swadesh entries : sum of weighted links from a swadesh entry .",
    "( c ) degree of the concepts : sum of unweighted links to a node ( d ) degree of swadesh entries : sum of unweighted links to a node .",
    "a node strength in this context indicates the total number of polysemies associated with the concept in 81 languages while a node degree means the number of other concepts associated with the node regardless of the number of synonymous polysemies associated with it .",
    "heaven , for example , has the largest number of polysemies , but most of them are with sun , so that its degree is only three .",
    "[ fig : word_degree_rank ] ]    the absence of significant cladistic correlation with the patterns of polysemy suggests a possibility to extend the constructed conceptual space by utilizing digitally archived dictionaries of the major languages of the world with some confidence that their expression of these features is not strongly biased by correlations due to language family structure .",
    "large - corpus samples could be used to construct the semantic space in as yet unexplored domains using automated means .",
    "high - quality bilingual dictionaries between the object language and the semantic metalanguage for cross - linguistic comparison are used to identify polysemies .",
    "the 81 object languages were selected from a phylogenetically and geographically stratified sample of low - level language families or _ genera _ , listed in tab .",
    "[ tab : languages ] in the appendex @xcite .",
    "translations into the object language of each of the 22 word senses from the swadesh basic vocabulary list were first obtained ( see appendix-[subsec : meanings ] ) ; all translations ( that is , all synonyms ) were retained .",
    "polysemies were identified by looking up the metalanguage translations ( back - translation ) of each object - language term .",
    "the selected swadesh word senses , and the selected languages are listed in the appendix .",
    "we use modern european languages as a semantic metalanguage , _",
    "i.e. , _ bilingual dictionaries between such languages and the other languages in our sample . this could be problematic if these languages themselves display polysemies ; for example , english _ day _ expresses both daytime , and 24hr period .",
    "in many cases , however , the lexicographer is aware of these issues , and annotates the translation of the object language word accordingly . in the lexical domain chosen for our study ,",
    "standard lexicographic practice was sufficient to overcome this problem .      a hierarchical spectral algorithm clusters the swadesh word senses .",
    "each sense @xmath12 is assigned to a position in @xmath13 based on the @xmath12th components of the @xmath14 eigenvectors of the weighted adjacency matrix .",
    "each eigenvector is weighted by the square of its eigenvalue , and clustered by a greedy agglomerative algorithm to merge the pair of clusters having the smallest squared euclidean distance between their centers of mass , through which a binary tree or _ dendrogram _ is constructed we construct a dendrogram for each subgroup of languages according to nonlinguistic variables such as geography , topography , climate , and the presence or absence of a literary tradition ( table [ tab : groups ] in appendix ) .    the structural distance between the dendrograms of each pair of language subgroups",
    "is measured by two standard tree metrics . the triplet distance @xmath15 @xcite is the fraction of the @xmath16 distinct triplets of senses that are assigned a different topology in the two trees : that is , those for which the trees disagree as to which pair of senses are more closely related to each other than they are to the third .",
    "the robinson - foulds distance @xmath17 @xcite is the number of `` cuts '' on which the two trees disagree , where a cut is a separation of the leaves into two sets resulting from removing an edge of the tree .    for each pair of subgroups ,",
    "we perform two types of bootstrap experiments .",
    "first , we compare the distance between their dendrograms to the distribution of distances we would see under a hypothesis that the two subgroups have no shared lexical structure .",
    "were this null hypothesis true , the distribution of distances would be unchanged under the random permutation of the senses at the leaves of each tree ( for simplicity , the topology of the dendrograms are kept fixed . ) comparing the observed distance against the resulting distribution gives a @xmath18-value , called @xmath19 in figure  [ fig : bootstrap ] .",
    "these @xmath18-values are small enough to decisively reject the null hypothesis . indeed , for most pairs of groups the robinson - foulds distance is smaller than that observed in any of the 1000 bootstrap trials ( @xmath20 ) marked as @xmath21 in the table .",
    "this gives overwhelming evidence that the semantic network has universal aspects that apply across language subgroups : for instance , in every group we tried , sea / ocean , and salt are more related than either is to sun .    in the second bootstrap experiment ,",
    "the null hypothesis is that the nonlinguistic variables have no effect on the semantic network , and that the differences between language groups simply result from random sampling : for instance , the similarity between the americas and eurasia is what one would expect from any disjoint subgroups of the 81 languages of given sizes 29 and 20 respectively . to test this null hypothesis",
    ", we generate random pairs of disjoint language subgroups with the same sizes as the groups in question , and measure the distribution of their distances .",
    "the @xmath18-values , called @xmath22 in figure  [ fig : bootstrap ] , are not small enough to reject this null hypothesis .",
    "thus , at least given the current data set , there is no statistical distinction between random sampling and empirical data further supporting our thesis that it is , at least in part , universal .",
    "the model treats all concepts as independent members of an unbiased sample that the aggregate summary statistics of the empirical data reflects the underlying structure .",
    "the simplest model perhaps then assumes no interaction between concept and languages : the number of polysemies of concept @xmath4 in language @xmath3 , that is @xmath23 , is linearly proportional to both the tendency of the concept to be polysemous and the tendency of the language to distinguish word senses ; and these tendencies are estimated from the marginal distribution of the observed data as the fraction of polysemy associated with the concept , @xmath24 , and the fraction of polysemy in the language , @xmath25 , respectively .",
    "the model can , therefore , be expressed as , @xmath26 , a product of the two . to test the model ,",
    "we compare the kullback - leibler ( kl ) divergence of ensembles of the model with the observation @xcite .",
    "ensembles are generated by the multinominal distribution according to the probability @xmath27 .",
    "the kl divergence is an appropriate measure for testing typicality of this random process because it is the leading exponential approximation ( by stirling s formula ) to the log of the multinomial distribution produced by poisson sampling ( see appendix  [ sec : model ] ) .",
    "the kl divergence of ensembles is @xmath28 where @xmath29 is the number of polysemies that the model generates divided by @xmath30 , and the kl divergence of the empirical observation is @xmath31 .",
    "note that @xmath32 is @xmath33 and it is a different value from an expected value of the model , @xmath34 .",
    "the @xmath18-value is the cumulative probability of @xmath35 to the right of @xmath36 .",
    "hy acknowledges support from cabdyn complexity centre , and the support of research grants from the national science foundation ( no .",
    "sma-1312294 ) .",
    "wc and ls acknowledge support from the university of new mexico resource allocation committee .",
    "tb , jw , es , cm , and hy acknowledge the santa fe institute , and the evolution of human languages program .",
    "authors thank ilia peiros , george starostin , and petter holme for helpful comments .",
    "w.c . and t.b",
    ". conceived of the project and participated in all methodological decisions .",
    "l.s . and w.c .",
    "collected the data , h.y . , j.w .",
    ", e.s . , and t.b .",
    "did the modeling and statistical analysis .",
    "i.m . and w.c .",
    "provided the cross - linguistic knowledge .",
    ", e.s . , and c.m .",
    "did the network analysis .",
    "the manuscript was written mainly by h.y .",
    ", c.m . , and t.b . , and all authors agreed on the final version .",
    "99 whorf bl , _ language , thought and reality : selected writing .",
    "_ ( mit press , cambridge , 1956 ) .",
    "fodor ja , _ the language of thought . _",
    "( harvard univ . , new york , 1975 ) .",
    "wierzbicka , a. , _ semantics : primes and universals . _",
    "( oxford university press .",
    "1996 )    lucy ja , _ grammatical categories and cognition : a case study of the linguistic relativity hypothesis . _",
    "( cambridge university press , 1992 ) .",
    "levinson sc , _ space in language and cognition : explorations in cognitive diversity .",
    "_ ( cambridge university press , 2003 )    choi s , bowerman m ( 1991 ) learning to express motion events in english and korean : the influence of language - specific lexicalization patterns .",
    "_ cognition _ * 41 * , 83 - 121 .",
    "majid a , boster js , bowerman m ( 2008 ) _ cognition _ * 109 * , 235 - 250 .",
    "croft w ( 2010 ) relativity , linguistic variation and language universals .",
    "_ cognitextes _ * 4 * , 303 .",
    "evans n , levinson sc ( 2009 ) the myth of language universals : language diversity and its importance for cognitive science .",
    "brain sci . _",
    "* 21 * 429 - 492 .",
    "comrie b _ language universals and linguistic typology , 2nd ed .",
    "_ ( university of chicago press . , 1989 ) .",
    "croft w , _ typology and universals , 2nd ed . _ ( cambridge university press .",
    "2003 ) .",
    "henrich j , heine sj , norenzayan a ( 2010 ) the weirdest people in the world ? _ behav .",
    "brain sci . _ * 33 * 1 - 75 ( 2010 ) .",
    "shopen t ( ed . ) , _ language typology and syntactic description _ , 2nd ed .",
    "( 3 volumes ) ( cambridge university press , cambridge , 2007 ) .",
    "croft w , cruse da , _ cognitive linguistics . _",
    "( cambridge university press .",
    "2004 ) .",
    "koptjevskaja - tamm m , vanhove m ( 2012 ) new directions in lexical typology .",
    "_ linguistics _ * 50 * , 3 .",
    "brown ch ( 1976 ) general principles of human anatomical partonomy and speculations on the growth of partonomic nomenclature .",
    "ethnol . _ * 3 * , 400 - 424 ( 1976 ) .",
    "witkowski sr , brown ch ( 1978 ) lexical universals , _ ann . rev . of anthropol . _ * 7 * 427 - 51 .",
    "brown ch ( 1983 ) where do cardinal direction terms come from ?",
    "_ anthropological linguistics _ * 25 * , 121 - 161 .",
    "viberg ( 1983 ) the verbs of perception : a typological study .",
    "_ linguistics _ * 21 * , 123 - 162 .",
    "evans n , multiple semiotic systems , hyperpolysemy , and the reconstruction of semantic change in australian languages . in _",
    "diachrony within synchrony : language history and cognition _",
    "( peter lang .",
    "frankfurt , 1992 ) .",
    "derrig s ( 1978 ) metaphor in the color lexicon .",
    "chicago linguistic society , the parasession on the lexicon _",
    "85 - 96 .",
    "swadesh m ( 1952 ) lexico - statistical dating of prehistoric ethnic contacts .",
    "_ p. am . philos .",
    "soc . _ * 96 * , 452 - 463 .",
    "vygotsky l , thought and language .",
    "( mit press , cambridge , ma , 2002 ) .",
    "critchlow de , pearl dk , qian cl ( 1996 ) the triples distance for rooted bifurcating phylogenetic trees .",
    "biol . _ * 45 * , 323334 .",
    "dobson aj , comparing the shapes of trees , _",
    "combinatorial mathematics iii _ , ( springer - verlag , new york 1975 ) .",
    "robinson df , foulds lr ( 1981 ) comparison of phylogenetic trees .",
    "biosci . _ * 53 * , 131147 .",
    "dunn m , _ et al . _",
    "( 2011 ) evolved structure of language shows lineage - specific trends in word - order universals .",
    "_ nature _ * 473 * , 79 - 82 .",
    "bouckaert r , _ et al . _",
    "( 2012 ) mapping the origins and expansion of the indo - european language family .",
    "_ science _ * 337 * , 957 .",
    "fox a , _ linguistic reconstruction : an introduction to theory and method . _",
    "( oxford university press .",
    "1995 ) .",
    "hock hh _ principles of historical linguistics .",
    "_ ( mouton de gruyter , berlin , 1986 ) .",
    "nichols j , the comparative method as heuristic . in _",
    "the comparative method reviewed : regularity and irregularity in language change _",
    "( oxford university press , 1996 ) .",
    "dryer ms ( 1989 ) large linguistic areas and language sampling .",
    "_ studies in language _ * 13 * , 257 - 292 .",
    "cover tm , and thomas ja , elements of information theory , ( wiley , new york , 1991 ) .",
    "brown ch , a theory of lexical change ( with examples from folk biology , human anatomical partonomy and other domains ) .",
    "_ anthropol . linguist .",
    "_ * 21 * , 257 - 276 ( 1979 ) .",
    "brown ch & witkowski sr , figurative language in a universalist perspective .",
    "_ * 8 * 596 - 615 ( 1981 ) .",
    "our translations use only lexical concepts as opposed to grammatical inflections or function words . for the purpose of universality and stability of meanings across cultures ,",
    "we chose entries from the swadesh 200-word list of basic vocabulary . among these , we have selected categories that are likely to have single - word representation for meanings , and for which the referents are material entities or natural settings rather than social or conceptual abstractions .",
    "we have selected 22 words in domains concerning natural and geographic features , so that the web of polysemy will produce a connected graph whose structure we can analyze , rather than having an excess of disconnected singletons .",
    "we have omitted body parts  which by the same criteria would provide a similarly appropriate connected domain  because these have been considered previously  @xcite .",
    "the final set of 22 words are as follows :    * celestial phenomena and related time units : + star , sun , moon , year , day / daytime , night * landscape features : + sky , cloud(s ) , sea / ocean , lake , river , mountain * natural substances : + stone / rock , earth / soil , sand , ash(es ) , salt , smoke , dust , fire , water , wind      the languages included in our study are listed in tab .",
    "[ tab : languages ] .",
    "notes : oceania includes southeast asia ; the papuan languages do not form a single phylogenetic group in the view of most historical linguists ; other families in the table vary in their degree of acceptance by historical linguists . the classification at the genus level , which is of greater importance to our analysis , is generally agreed upon .       to accommodate such characteristic , we revise the model eq .",
    "( [ seq : product ] ) to the following function : @xmath37 where degree numbers @xmath38 for each swadesh @xmath4 is proportional to @xmath39 and language size , but is bounded by @xmath40 , the number of proximal concepts .",
    "the corresponding model probability for each language then becomes @xmath41 as all @xmath42 we recover the product model , with @xmath43 and @xmath44 . a first - level approximation to fit parameters @xmath39 and @xmath40",
    "is given by minimizing the weighted mean - square error @xmath45 the function  ( [ eq : error_sat ] ) assigns equal penalty to squared error within each language bin @xmath46 , proportional to the variance expected from poisson sampling .",
    "the fit values obtained for @xmath39 and @xmath40 do not depend sensitively on the size of bins except for the swadesh entry moon in the case where all 81 single - language bins are used .",
    "moon has so few polysemies , but the moon / month polysemy is so likely to be found , that the language itelman , with only one link , has this polysemy .",
    "this point leads to instabilities in fitting @xmath47 in single - language bins . for bins of size 39",
    "the instability is removed .",
    "representative fit parameters across this range are shown in table  [ tab : fitvalue ] .",
    "examples of the saturation model for two words , plotted against the 9-language binned degree data in fig .",
    "[ fig : saturating_words ] , show the range of behaviors spanned by swadesh entries .    ) and the saturation model  ( [ eq : sat2 ] ) .",
    "parameters @xmath39 and @xmath40 have been adjusted ( as explained in the text ) to match the word- and language - marginals . from 10,000 random samples",
    "@xmath48 , ( green ) histogram for the product model ; ( blue ) histogram for the saturation model ; ( red dots ) data .",
    "the product model rejects the 9-language joint binned configuration at the at @xmath49 level ( dark shading ) , while the saturation model is typical of the same configuration at @xmath50 ( light shading ) .",
    "[ fig : sample_kl_hist_data_9_joint ] ]    the least - squares fits to @xmath39 and @xmath40 do not directly yield a probability model consisent with the marginals for language size that , in our data , are fixed parameters rather than sample variables to be explained .",
    "they closely approximate the marginal n @xmath51 ( deviations @xmath52 link for every @xmath4 ) but lead to mild violations @xmath53 .",
    "we corrected for this by altering the saturation model to suppose that , rather than word properties interacting with the exact value @xmath54 , they interact with a ( word - independent but language - dependent ) multiplier @xmath55 , so that the model for @xmath56 in each language becomes becomes @xmath57 in terms of the least - squares coefficients @xmath39 and @xmath40 of table  [ tab : fitvalue ] .",
    "the values of @xmath58 are solved with newton s method to produce @xmath59 , and we checked that they preserve @xmath60 within small fractions of a link .",
    "the resulting adjustment parameters are plotted versus @xmath54 for individual languages in fig .",
    "[ fig : varphis_vs_nls ] .",
    "although they were computed individually for each @xmath3 , they form a smooth function of @xmath54 , possibly suggesting a refinement of the product model , but also perhaps reflecting systematic interaction of small - language degree distributions with the error function  ( [ eq : error_sat ] ) .     versus @xmath54 for individual languages in the probability model used in text , with parameters",
    "@xmath40 and @xmath61 shown in table  [ tab : fitvalue ] .",
    "although @xmath58 values were individually solved with newton s method to ensure that the probability model matched the whole - language link values , the resulting correction factors are a smooth function of @xmath54 .",
    "[ fig : varphis_vs_nls ] ]     is now marginally plausible for the joint configuration of 27 three - language bins in the data , at the @xmath62 level ( light shading ) . for reference",
    ", this fine - grained joint configuration rejects the null model of independent sampling from the product model at @xmath63 ( dark shading in the extreme tail ) .",
    "4000 samples were used to generate this test distribution .",
    "the blue histogram is for the saturation model , the green histogram for the product model , and the red dots are generated data .",
    "[ fig : sample_kl_hist_data_27_joint ] ]    with the resulting joint distribution @xmath64 , tests of the joint degree counts in our dataset for consistency with multinomial sampling in 9 nine - language bins are shown in fig .  [",
    "fig : sample_kl_hist_data_9_joint ] , and results of tests using 27 three - language bins are shown in fig .",
    "[ fig : sample_kl_hist_data_27_joint ] .",
    "binning nine languages clearly averages over enough language - specific variation to make the data strongly typical of a random sample ( @xmath65 ) , while the product model ( which also preserves marginals ) is excluded at the @xmath49 level .",
    "the marginal acceptance of the data even for the joint configuration of three - language bins ( @xmath66 ) suggests that language size @xmath54 is an excellent explanatory variable and that residual language variations cancel to good approximation even in small aggregations .",
    "the preceding subsection showed intermediate scales of aggregation of our language data are sufficiently random that they can be used to refine probability models for mean degree as a function of parameters in the globally - aggregated graph .",
    "the saturation model , with data - consistent marginals and multinomial sampling , is weakly plausible by bins of as few as three languages .",
    "down to this scale , we have therefore not been able to show a requirement for deviations from the independent sampling of links entailed by the use of the aggregate graph as a summary statistic . however , we were unable to find a further refinement of the mean distribution that would reproduce the properties of single language samples . in this section",
    "we characterize the nature of their deviation from independent samples of the saturation model , show that it may be reproduced by models of non - independent ( clumpy ) link sampling , and suggest that these reflect excess synonymous polysemy .",
    "+ * power tests and uneven distribution of single - language @xmath18-values *    to evaluate the contribution of individual languages versus language aggregates to the acceptance or rejection of random - sampling models , we computed @xmath18-values for individual languages or language bins , using the kl - divergence  ( [ eq : d_kl_l ] ) .",
    "a plot of the single - language @xmath18-values for both the null ( product ) model and the saturation model is shown in fig .  [",
    "fig : one_lang_p_vals ] .",
    "histograms for both single languages ( from the values in fig .",
    "[ fig : one_lang_p_vals ] ) and aggregate samples formed by binning consecutive groups of three languages are shown in fig .",
    "[ fig : p_dists_marg_sat ] . for samples from a random model",
    ", @xmath18-values would be uniformly distributed in the unit interval , and histogram counts would have a multinomial distribution with single - bin fluctuations depending on the total sample size and bin width .",
    "therefore , fig .",
    "[ fig : p_dists_marg_sat ] provides a power test of our summary statistics .",
    "the variance of the multinomial may be estimated from the large-@xmath18-value body where the distribution is roughly uniform , and the excess of counts in the small-@xmath18-value tail , more than one standard deviation above the mean , provides an estimate of the number of languages that can be confidently said to violate the random - sampling model .    from the upper panel of fig .",
    "[ fig : p_dists_marg_sat ] , with a total sample of 81 languages , we can estimate a number of @xmath67 excess languages at the lowest @xmath18-values of 0.05 and 0.1 , with an additional 23 languages rejected by the product model in the range @xmath18-value @xmath68 .",
    "comparable plots in fig .",
    "[ fig : p_dists_marg_sat ] ( lower panel ) for the 27 three - language aggregate distributions are marginally consistent with random sampling for the saturation model , as expected from fig .",
    "[ fig : sample_kl_hist_data_27_joint ] above .",
    "we will show in the next section that a more systematic trend in language fluctuations with size provides evidence that the cause for these rejections is excess variance due to repeated attachment of links to a subset of nodes .",
    "by kl divergence , relative to 4000 random samples per language , plotted versus language rank in order of increasing @xmath54 . product model ( green )",
    "shows equal or lower @xmath18-values for almost all languages than the saturation model ( blue ) .",
    "three languages  basque , haida , and yorb  had value @xmath69 consistently across samples in both models , and are removed from subsequent regression estimates .",
    "a trend toward decreasing @xmath18 is seen with increase in @xmath54 .",
    "[ fig : one_lang_p_vals ] ]    -values from the 81 languages plotted in fig .",
    "[ fig : one_lang_p_vals ] . the saturation model ( blue )",
    "produces a fraction @xmath70 languages in the lowest @xmath18-values @xmath71 above the roughly - uniform background for the rest of the interval ( shaded area with dashed boundary ) .",
    "a further excess of 23 languages with @xmath18-values in the range @xmath72 $ ] for the product model ( green ) reflects the part of the mismatch corrected through mean values in the saturation model .",
    "( lower panel ) corresponding histogram of @xmath18-values for 27 three - language aggregate degree distributions .",
    "saturation model ( blue ) is now marginally consistent with a uniform distribution , while the product model ( green ) still shows slight excess of low-@xmath18 bins .",
    "coarse histogram bins have been used in both panels to compensate for small sample numbers in the lower panel , while producing comparable histograms .",
    "[ fig : p_dists_marg_sat ] , title=\"fig : \" ] -values from the 81 languages plotted in fig .",
    "[ fig : one_lang_p_vals ] . the saturation model ( blue )",
    "produces a fraction @xmath70 languages in the lowest @xmath18-values @xmath71 above the roughly - uniform background for the rest of the interval ( shaded area with dashed boundary ) .",
    "a further excess of 23 languages with @xmath18-values in the range @xmath72 $ ] for the product model ( green ) reflects the part of the mismatch corrected through mean values in the saturation model .",
    "( lower panel ) corresponding histogram of @xmath18-values for 27 three - language aggregate degree distributions .",
    "saturation model ( blue ) is now marginally consistent with a uniform distribution , while the product model ( green ) still shows slight excess of low-@xmath18 bins .",
    "coarse histogram bins have been used in both panels to compensate for small sample numbers in the lower panel , while producing comparable histograms .",
    "[ fig : p_dists_marg_sat ] , title=\"fig : \" ] +      if we define the size - weighted relative variance of a language analogously to the error term in eq .",
    "( [ eq : error_sat ] ) , as @xmath73 fig .",
    "[ fig : one_lang_pval_relvar_corr ] shows that @xmath74 has high rank correlation with @xmath75 and a roughly linear regression over most of the range . )",
    "that the leading quadratic term in the kl - divergence differs from @xmath76 in that it presumes poisson fluctuation with variance @xmath77 at the level of each _ word _ , rather than uniform variance @xmath78 across all words in a language .",
    "the relative variance is thus a less specific error measure . ]",
    "two languages ( itelmen and hindi ) , which appear as large outliers relative to the product model , are within the main dispersion in the saturation model , showing that their discrepency is corrected in the mean link number .",
    "we may therefore understand a large fraction of the improbability of languages as resulting from excess fluctuations of their degree numbers relative to the expectation from poisson sampling .",
    "plotted versus relative variance @xmath79 from eq .",
    "( [ eq : rel_var ] ) for the 78 languages with non - zero @xmath18-values from fig .",
    "[ fig : one_lang_p_vals ] . ( blue ) saturation model ; ( green ) product model . two languages ( circled ) which appear as outliers with anomalously small relative variance in the product model  itelman and hindi  disappear into the central tendency with the saturation model .",
    "( lower panel : ) an equivalent plot for 26 three - language bins .",
    "notably , the apparent separation of individual large-@xmath54 langauges into two groups has vanished under binning , and a unimodal and smooth dependence of @xmath80 on @xmath79 is seen .",
    "[ fig : one_lang_pval_relvar_corr ] , title=\"fig : \" ] +   plotted versus relative variance @xmath79 from eq .",
    "( [ eq : rel_var ] ) for the 78 languages with non - zero @xmath18-values from fig .",
    "[ fig : one_lang_p_vals ] . ( blue ) saturation model ; ( green ) product model .",
    "two languages ( circled ) which appear as outliers with anomalously small relative variance in the product model ",
    "itelman and hindi  disappear into the central tendency with the saturation model .",
    "( lower panel : ) an equivalent plot for 26 three - language bins .",
    "notably , the apparent separation of individual large-@xmath54 langauges into two groups has vanished under binning , and a unimodal and smooth dependence of @xmath80 on @xmath79 is seen .",
    "[ fig : one_lang_pval_relvar_corr ] , title=\"fig : \" ]    fig .",
    "[ fig : variance_test_sat_p_value_excludes ] then shows the relative variance from the saturation model , plotted versus total average link number for both individual languages and three - language bins .",
    "the binned languages show no significant regression of relative variance away from the value unity for poisson sampling , whereas single languages show a systematic trend toward larger variance in larger languages , a pattern that we will show is consistent with `` clumpy '' sampling of a subset of nodes .",
    "the disappearance of this clumping in binned distributions shows that the clumps are uncorrelated among languages at similar @xmath54 .     for 78 languages excluding basque , haida , and yorb .",
    "least - squares regression are shown for three - language bins ( green ) and individual languages ( blue ) , with regression coefficients inset .",
    "three - language bins are consistent with poisson sampling at all @xmath54 , whereas single languages show systematic increase of relative variance with increasing @xmath54 .",
    "[ fig : variance_test_sat_p_value_excludes ] ]      we may retain the mean degree distributions , while introducing a systematic trend of relative variance with @xmath54 , by modifying our sampling model away from strict poisson sampling to introduce `` clumps '' of links . to remain within the use of minimal models , we modify the sampling procedure by a single parameter which is independent of word @xmath4 , language - size @xmath54 , or particular language @xmath3 .",
    "we introduce the sampling model as a function of two parameters , and show that one function of these is constrained by the regression of excess variance .",
    "( the other may take any interior value , so we have an equivalence class of models . ) in each language , select a number @xmath81 of swadesh entries randomly . let the swadesh indices be denoted @xmath82 .",
    "we will take some fraction of the total links in that language , and assign them only to the swadeshes whose indices are in this privileged set .",
    "introduce a parameter @xmath83 that will determine that fraction .",
    "we require correlated link assignments be consistent with the mean determined by our model fit , since binning of data has shown no systematic effect on mean parameters .",
    "therefore , for the random choice @xmath84 , introduce the normalized density on the privileged links @xmath85",
    "if @xmath86 and @xmath87 otherwise . denote the aggregated weight of the links in the priviledged set by @xmath88 then introduce a modified probability distribution based on the randomly selected links , in the form @xmath89 multinomial sampling of @xmath54 links from the distribution @xmath90 will produce a size - dependent variance of the kind we see in the data .",
    "the expectated degrees given any particular set @xmath91 will not agree with the means in the aggregate graph , but the ensemble mean over random samples of languages will equal @xmath92 , and binned groups of languages will converge toward it according to the central - limit theorem .",
    "the proof that the relative variance increases linearly in @xmath54 comes from the expansion of the expectation of eq .",
    "( [ eq : rel_var ] ) for random samples , denoted @xmath93       } ^2     \\right > \\nonumber \\\\ & = &     \\left <       \\frac{1}{n^l }      \\sum_s       {        \\left (           { \\hat{n}}_s^l -           n^l          { \\tilde{p}}_{s \\mid l }         \\right )      } ^2     \\right > + \\nonumber\\\\ & & \\qquad    n^l    \\left <       \\sum_s       {        \\left (           { \\tilde{p}}_{s \\mid l } -           p_{s \\mid l}^{\\mbox{\\scriptsize model } }         \\right )      } ^2     \\right > .",
    "\\label{eq : rel_var_clumpy}\\end{aligned}\\ ] ]    the first expectation over @xmath48 is constant ( of order unity ) for poisson samples , and the second expectation ( over the sets @xmath91 that generate @xmath90 ) does not depend on @xmath54 except in the prefactor .",
    "cross - terms vanish because link samples are not correlated with samples of @xmath94 .",
    "both terms in the third line of eq .",
    "( [ eq : rel_var_clumpy ] ) scale under binning as @xmath95 .",
    "the first term is invariant due to poisson sampling , while in the second term , the central - limit theorem reduction of the variance in samples over @xmath90 cancels growth in the prefactor @xmath54 due to aggregation .    because the linear term in eq .",
    "( [ eq : rel_var_clumpy ] ) does not systematically change under binning , we interpret the vanishing of the regression for three - language bins in fig .",
    "[ fig : variance_test_sat_p_value_excludes ] as a consequence of fitting of the mean value to binned data as sample estimators . ) , fitting a saturation model to binned sample configurations using the same algorithms as we applied to our data , and then performing regressions equivalent to those in fig .",
    "[ fig : variance_test_sat_p_value_excludes ] . in about @xmath96 of cases the fitted model showed regression coefficients consistent with zero for three - language bins .",
    "the typical behavior when such models were fit to random sample data was that the three - bin regression coefficient decreased from the single - language regression by @xmath97 .",
    "] therefore , we require to choose parameters @xmath81 and @xmath83 so that regression coefficients in the data are typical in the model of clumpy sampling , while regressions including zero have non - vanishing weight in models of three - bin aggregations .    fig .",
    "[ fig : multinom_samp_hists_78_26_words ] compares the range of regression coefficients obtained for random samples of languages with the values @xmath98 in our data , from either the original saturation model @xmath99 , or the clumpy model @xmath90 randomly re - sampled for each language in the joint configuration .",
    "parameters used were ( @xmath100 , @xmath101 ) . ranging from 317 .",
    "@xmath100 was chosen as an intermediate value , consistent with the typical numbers of nodes appearing in our samples by inspection . ] with these parameters , @xmath97 of links were assigned in excess to @xmath97 of words , with the remaining @xmath102 of links assigned according to the mean distribution .",
    "either generated by poisson sampling from the saturation model @xmath103 fitted to the data ( blue ) , or drawn from clumped probabilities @xmath90 defined in eq .",
    "( [ eq : p_tilde_def ] ) , with the set of privileged words @xmath104 independently drawn for each language ( green ) .",
    "solid lines refer to joint configurations of 78 individual languages with the @xmath54 values in fig .",
    "[ fig : variance_test_sat_p_value_excludes ] .",
    "dashed lines are 26 non - overlapping three - language bins .",
    "[ fig : multinom_samp_hists_78_26_words ] ]    the important features of the graph are : 1 ) binning does not change the mean regression coefficient , verifying that eq .",
    "( [ eq : rel_var_clumpy ] ) scales homogeneously as @xmath95 .",
    "however , the variance for binned data increases due to reduced number of sample points ; 2 ) the observed regression slope 0.012 seen in the data is far out of the support of multinomial sampling from @xmath99 , whereas with these parameters , it becomes typical under @xmath105 while still leaving significant probability for the three - language binned regression around zero ( even without ex - post fitting ) ."
  ],
  "abstract_text": [
    "<S> how universal is human conceptual structure ? </S>",
    "<S> the way concepts are organized in the human brain may reflect distinct features of cultural , historical , and environmental background in addition to properties universal to human cognition . </S>",
    "<S> semantics , or meaning expressed through language , provides direct access to the underlying conceptual structure , but meaning is notoriously difficult to measure , let alone parameterize . here </S>",
    "<S> we provide an empirical measure of semantic proximity between concepts using cross - linguistic dictionaries . across languages carefully selected from a phylogenetically and geographically stratified sample of genera , </S>",
    "<S> translations of words reveal cases where a particular language uses a single polysemous word to express concepts represented by distinct words in another . </S>",
    "<S> we use the frequency of polysemies linking two concepts as a measure of their semantic proximity , and represent the pattern of such linkages by a weighted network . </S>",
    "<S> this network is highly uneven and fragmented : certain concepts are far more prone to polysemy than others , and there emerge naturally interpretable clusters loosely connected to each other . </S>",
    "<S> statistical analysis shows such structural properties are consistent across different language groups , largely independent of geography , environment , and literacy . </S>",
    "<S> it is therefore possible to conclude the conceptual structure connecting basic vocabulary studied is primarily due to universal features of human cognition and language use .    </S>",
    "<S> the space of concepts expressible in any language is vast . </S>",
    "<S> this space is covered by individual words representing semantically tight neighborhoods of salient concepts . </S>",
    "<S> there has been much debate about whether semantic similarity of concepts is shared across languages @xcite . on the one hand , </S>",
    "<S> all human beings belong to a single species characterized by , among other things , a shared set of cognitive abilities . on the other hand , </S>",
    "<S> the 6000 or so extant human languages spoken by different societies in different environments across the globe are extremely diverse  @xcite and may reflect accidents of history as well as adaptations to local environments . </S>",
    "<S> most psychological experiments about this question have been conducted on members of `` weird '' ( western , educated , industrial , rich , democratic ) societies , yet there is reason to question whether the results of such research are valid across all types of societies @xcite . </S>",
    "<S> thus , the question of the degree to which conceptual structures expressed in language are due to universal properties of human cognition , the particulars of cultural history , or the environment inhabited by a society , remains unresolved .    </S>",
    "<S> the search for an answer to this question has been hampered by a major methodological difficulty . </S>",
    "<S> linguistic meaning is an abstract construct that needs to be inferred indirectly from observations , and hence is extremely difficult to measure ; this is even more apparent in the field of lexical semantics . </S>",
    "<S> meaning thus contrasts both with phonetics , in which instrumental measurement of physical properties of articulation and acoustics is relatively straightforward , and with grammatical structure , for which there is general agreement on a number of basic units of analysis @xcite . </S>",
    "<S> much lexical semantic analysis relies on linguists introspection , and the multifaceted dimensions of meaning currently lack a formal characterization . to address our primary question , </S>",
    "<S> it is necessary to develop an empirical method to characterize the space of lexical meanings .    </S>",
    "<S> we arrive at such a measure by noting that translations uncover the alternate ways that languages partition meanings into words . </S>",
    "<S> many words have more than one meaning , or sense , to the extent that word senses can be individuated @xcite . </S>",
    "<S> words gain meanings when their use is extended by speakers to similar meanings ; words lose meanings when another word is extended to the first word s meaning , and the first word is replaced in that meaning . to the extent that words in transition across similar , or possibly contiguous , meanings account for </S>",
    "<S> the polysemy ( multiple meanings of a single word form ) revealed in cross - language translations , the frequency of polysemies found across an unbiased sample of languages can provide a measure of semantic similarity among word meanings . </S>",
    "<S> the unbiased sample of languages is carefully chosen in a phylogenetically and geographically stratified way , according to the methods of typology and universals research @xcite . </S>",
    "<S> this large , diverse sample of languages allows us to avoid the pitfalls of research based solely on `` weird '' societies and to separate contributions to the empirically attested patterns in the linguistic data , arising from universal language cognition versus those from artifacts of the speaker - groups history or way of life .    </S>",
    "<S> there have been several cross - linguistic surveys of lexical polysemy , and its potential for understanding semantic shift @xcite , in the domains such as body parts @xcite , cardinal directions @xcite , perception verbs @xcite , concepts associated with fire @xcite , and color metaphors @xcite . </S>",
    "<S> we add a new dimension to the existing body of research by providing a comprehensive mathematical method using a systematically stratified global sample of languages to measure degrees of similarity . </S>",
    "<S> our cross - linguistic study takes the swadesh lists as basic concepts @xcite as most languages have words for them . among those concepts </S>",
    "<S> , we chose 22 meanings associated with two domains : celestial objects ( e.g. ` sun , moon , star ` ) and landscape objects ( e.g. ` fire , water , mountain , dust ` ) . </S>",
    "<S> for each word expressing one of these meanings , we examined what other concepts were also expressed by the word . </S>",
    "<S> since the semantic structures of these two domains are very likely to be influenced by the physical environment that human societies inhabit , any claim of universality of lexical semantics needs to be demonstrated here . </S>"
  ]
}