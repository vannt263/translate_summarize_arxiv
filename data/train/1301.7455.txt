{
  "article_text": [
    "individuals who participate in social networks form their opinions through synthesis and contrast of different viewpoints they encounter in their social circles .",
    "such processes manifest themselves more strongly in online social networks and social media where opinions and ideas propagate faster through virtual connections between social - network individuals .",
    "opinion dynamics have been of considerable interest to marketing and opinion - formation agencies , which are interested in raising public awareness on important issues ( e.g. , health , social justice ) , or increasing the popularity of person or an item ( e.g. , a presidential candidate , or a product ) .    today , social - networking platforms and social media take up a significant amount of any promotion campaign budget .",
    "it is not uncommon to see activist groups , political parties , or corporations launching campaigns primarily via facebook or twitter .",
    "such campaigns interfere with the opinion - formation process by influencing the opinions of appropriately selected individuals , such that the overall favorable opinion about the specific information item is strengthened .",
    "the idea of leveraging social influence for marketing campaigns has been studied extensively in data mining .",
    "introduced by the work of domingos and richardson  @xcite , and kempe et al .",
    "@xcite the problem of _ influence maximization _ asks to identify the most influential individuals , whose adoption of a product or an action will spread maximally in the social network .",
    "this line of work employs probabilistic propagation models , such as the _ independent - cascade _ or the _ linear - threshold _ model , which specify how actions spread among the individuals of the social network . at a high level ,",
    "such propagation models distinguish the individuals to either _ active _ or _ inactive _ , and assume that active individuals influence their neighbors to become active according to certain probabilistic rules , so that activity spreads in the network in a _ cascading _ manner .    in this paper , we are interested in the process of how individuals form opinions , rather than how they adopt products or actions .",
    "we find that models such as the independent cascade and the linear threshold are not appropriate for modeling the process of forming opinions in social networks .",
    "first , opinions can not be accurately modeled by binary states , such as being either active or inactive , but they can take continuous values in an interval .",
    "second , and perhaps more importantly , the formation of opinions does not resemble a discrete cascading process ; it better resembles a social game in which individuals constantly influence each other until convergence to an equilibrium .",
    "accordingly , we adopt the opinion - formation model of friedkin and johnsen  @xcite , which assumes that each node @xmath0 of a social network @xmath1 has an internal opinion @xmath2 and an expressed opinion @xmath3 . while the internal opinions of individuals are fixed and not amenable to external influences , the expressed opinions can change due to the influence from their neighbors .",
    "more specifically , people change their expressed opinion @xmath3 so that they minimize their _ social cost _ , which is defined as the disagreement between their expressed opinion and the expressed opinion of their social neighbors , and the divergence between the expressed opinion and their true internal belief .",
    "it can be shown that the process of computing expressed opinion values by repeated averaging leads to a nash equilibrium of the game where the utilities are the node social costs  @xcite .",
    "armed with this opinion - formation model , we introduce and study a problem similar to the influence - maximization problem , introduced by kempe et al .",
    "we consider a social network of individuals , each holding an opinion value about an information item .",
    "we view an opinion as a numeric value between zero ( negative ) and one ( positive ) .",
    "we then ask to identify @xmath4 individuals , so that once their expressed opinions becomes 1 , the opinions of the rest of the nodes  at an equilibrium state  are , on average , as positive as possible .",
    "we call this problem campaign",
    ".    note that there is a fundamental qualitative difference between our framework and existing work on influence maximization : in contrast to other models used in influence - maximization literature , our work views the nodes as rational individuals who wish to optimize their own objectives .",
    "thus , we assume that the opinions of individuals get formed through best - response dynamics of a social game , which in turn is inspired by classical opinion - dynamics models studied extensively in economics  @xcite .",
    "furthermore , from a technical point of view , the maximization problem that results from our framework requires a completely different toolbox of techniques than the standard influence - maximization problem . to this end",
    ", we exploit an interesting connection between our problem and absorbing random walks in order to establish our technical results , including the complexity and the approximability of the problem .",
    "interestingly , as with the influence - maximization problem , we show that the objective function of the campaign problem is submodular , and thus , it can be approximated within factor @xmath5 using a greedy algorithm .",
    "in addition , motivated by the properties of the greedy algorithm , we propose scalable heuristics that can handle large datasets .",
    "our experiments show that in practice the heuristics have performance comparable to the greedy algorithm , and that are scalable to very large graphs .",
    "finally , we discuss two natural variants of the campaign problem . our discussion reveals a surprising property of the opinion formation process on _ undirected _ graphs : the average opinion of the network depends only on the internal opinions of the individuals and not on the network structure .",
    "to the best of our knowledge , we are the first to formally define and study the campaign problem . however , our work is related to a lot of existing work in economics , sociology and computer science .    in his original work in 1974 , degrout  @xcite was the first to define a model where individuals organized in a social network @xmath1 have a starting opinion ( represented by a real value ) which they update by repeatedly adopting the average opinion of their friends .",
    "this model and its variants , has been subject of recent studies in social sciences and economics  @xcite .",
    "most of these studies focus on identifying the conditions under which such repeated - averaging models converge to a consensus . in our work",
    ", we also adopt a repeated averaging model . however , our focus is not the characterization or the reachability of consensus .",
    "in fact , we do not assume consensus is ever reached .",
    "rather , we assume that the individuals participating in the network reach a stable point , where everyone has crystallized a personal opinion . as has been recently noted by social scientist davide krackhardt  @xcite , studies of such non - consensus states",
    "are much more realistic since consensus states are rarely reached .",
    "key to our paper is the work by bindel et al .",
    "in fact , we adopt the same opinion - dynamics model as in  @xcite , where individuals selfishly form opinions to minimize their personal cost . however , bindel et al .  focus on quantifying the social cost of this lack of central coordination between individuals , i.e. , the _ price of anarchy _ , and they consider a network - design problem with the objective of reducing the social cost at equilibrium .",
    "our work on the other hand , focuses on designing a promotion campaign so that , at equilibrium , the overall positive inclination towards a particular opinion is maximized .",
    "recently , there has been a lot of work in the computer - science literature on identifying a set of individuals to advertise an item ( e.g. , a product or an idea ) so that the spread of the item in the network is maximized .",
    "different assumptions about how information items propagate in the network has led to a rich literature of targeted - advertisement methods ( e.g. , see  @xcite ) .",
    "although at a high level our work has the same goal as all of these methods , there are also important differences , as we have already discussed in the introduction .",
    "we consider a social graph @xmath1 with @xmath6 nodes and @xmath7 edges .",
    "the nodes of the graph represent people and the edges represent social affinity between them .",
    "we refer to the members of the social graph by letters such as @xmath0 and  @xmath8 , and we write @xmath9 to denote the edges of the graph . with each edge",
    "@xmath9 we associate a weight @xmath10 , which expresses the strength of the social affinity or influence from person  @xmath0 to person  @xmath8 .",
    "we write @xmath11 to denote the _ social neighborhood _ of person  @xmath0 , that is , @xmath12 . unless explicitly mentioned , we do not make an assumption whether the graph @xmath13 is directed or undirected ; most of our results and our algorithms carry over for both types of graphs .",
    "the directed - graph model is more natural as in many real - world situations the influence @xmath14 from person @xmath0 to person @xmath8 is not equal to  @xmath15 .    following the framework of bindel et al .",
    "@xcite we assume that person @xmath0 has a _ persistent internal opinion _",
    "@xmath2 , which remains unchanged from external influences .",
    "person @xmath0 has also an _ expressed opinion _",
    "@xmath3 , which depends on their internal opinion @xmath2 , as well as on the expressed opinions of their social neighborhood @xmath11 .",
    "the underlying assumption is that individuals form opinions that combine their internal predisposition with the opinions of those in their social circle .",
    "we model the internal and external opinions @xmath2 and @xmath3 as real values in the interval  @xmath16 $ ] .",
    "the convention is that 0 denotes a negative opinion , and 1 a positive opinion .",
    "the values in - between capture different shades of positive and negative opinions . given a set of expressed opinion values for all the people in the social graph , represented by an _ opinion vector _ @xmath17 , and the vector of internal opinions @xmath18",
    ", we consider that the _ personal cost _ for individual @xmath0 is @xmath19 this cost models the fact that the expressed opinion @xmath3 of an individual @xmath0 is a `` compromise '' between their own internal belief @xmath2 and the opinions of their neighbors . as the individual @xmath0 forms an opinion @xmath3 , their internal opinion @xmath2 and the opinions @xmath20 of their neighbors @xmath21 may have different importance .",
    "the relative importance of those opinions is captured by the weights  @xmath14 .",
    "now assume that , as a result of social influence and conflict resolution , every individual @xmath0 is selfishly minimizing their own cost @xmath22 .",
    "if the internal opinions are _ persistent _ and can not change ( an assumption that we carry throughout ) , minimizing the cost @xmath23 implies changing the expressed opinion @xmath3 to the weighted average among the internal opinion @xmath2 and the expressed opinions of the neighbors of  @xmath0 . in other words , @xmath24 in fact , it can be shown that if every person @xmath0 iteratively updates their expressed opinion using equation  ( [ equation : averaging ] ) , then the iterations converge to a unique _ nash equilibrium _ for the game with utilities of players expressed by equation  .",
    "that is , the stationary vector of opinions @xmath25 is such that no node @xmath0 has an incentive to change their opinion to improve their cost @xmath23 .",
    "the selfish optimization process we described above guarantees that we reach an equilibrium , but it does not guarantee that we minimize globally the overall disagreements within the social network . given an opinion vector @xmath25 , we define the _ global cost _",
    "@xmath26 to be the sum of the individual costs @xmath22 . a natural question addressed by bindel et al .",
    "@xcite is the relationship between the cost @xmath27 achieved by the nash - equilibrium opinion vector @xmath25 , and the globally optimum cost @xmath28 .",
    "bindel et al .",
    "show that for undirected graphs @xmath29 , indicating that the selfish - optimization cost is very close to the optimum cost . on the other hand , for directed graphs",
    "the nash cost @xmath27 can be as large as  @xmath30 times the optimum cost @xmath28 .",
    "the goal of a promotion campaign is to improve the overall opinion about a product , person , or idea in a social network . given an opinion vector @xmath25 , we define the _ overall opinion _ @xmath31 as @xmath32 which is also proportional to the _ average expressed opinion _ of the individuals in @xmath13 .",
    "the goal of a campaign is to maximize @xmath31 . following the paradigm of kempe et al .",
    "@xcite , we assume that such a campaign relies on selecting a set of _ target nodes _ @xmath33 , which are going to be convinced to change their expressed opinions to @xmath34 . for the rest of the discussion , we will use @xmath35 to denote the overall opinion in the network , when vector @xmath25 is the nash - equilibrium vector obtained under the constraint that the expressed opinions of all nodes in @xmath33 are fixed to 1 . given this notation",
    ", we can define the campaign problem as follows .",
    "[ problem : expressed ] given a graph @xmath1 and an integer @xmath4 , identify a set @xmath33 of @xmath4 nodes such that fixing the expressed opinions of the nodes in @xmath33 to @xmath34 , maximizes the overall opinion @xmath35 .",
    "we emphasize that fixing @xmath36 for all @xmath37 means that equation   is only applied for the @xmath20 s such that @xmath38 , while for the nodes @xmath37 the values @xmath3 remain @xmath34 .",
    "the definition of the campaign problem reflects our belief of what constitutes a feasible and effective campaign strategy .",
    "expressed opinions are more amenable to change , and have stronger effect on the overall opinion in the social network .",
    "thus , it is reasonable for a campaign to target these opinions .",
    "we note that other campaign strategies are also possible , resulting in different problem definitions .",
    "for example , one can define the problem where the campaign aims at changing the fundamental beliefs of people by altering their internal opinions @xmath2 .",
    "it is also conceivable to ask whether it is possible to improve the overall opinion @xmath31 by introducing a number of new edges in the social graph , e.g. , via a link - suggestion application .",
    "we discuss both of these variants at the end of the paper .",
    "it turns out that from the algorithmic point of view , both these problems are relatively simple . for instance , we can show that for undirected graphs , surprisingly , it is not possible to improve the overall opinion @xmath31 by introducing new edges in the graph .",
    "we now show the connection between computing the nash - equilibrium opinion vector @xmath25 and a random walk on a graph with absorbing nodes .",
    "this connection is essential in the analysis of the campaign problem .    *",
    "absorbing random walks : * let @xmath39 be a graph with a set of @xmath40 nodes @xmath41 , and a set of edges @xmath42 .",
    "the graph is also associated with the following three @xmath43 matrices : ( @xmath0 ) the _ weight matrix _",
    "@xmath44 with entries @xmath45 denoting the weight of the edges ; ( @xmath46 ) the _ degree matrix _ @xmath47 , which is a diagonal matrix such that @xmath48 ; ( @xmath49 ) the _ transition matrix _ @xmath50 , which is a row - stochastic matrix ; @xmath51 expresses the probability of moving from node @xmath0 to node @xmath8 in a random walk on the graph @xmath52 .",
    "in such a random walk on the graph @xmath52 , we say that a node @xmath53 is an _ absorbing node _ , if the random walk can only transition into that node , but not out of it ( and thus , the random walk is absorbed in node @xmath54 ) .",
    "let @xmath55 denote the set of all absorbing nodes of the random walk .",
    "the set of the remaining nodes @xmath56 are non - absorbing , or _",
    "transient _ nodes . given this partition of the states in @xmath41 , the transition matrix of this random walk can be written as follows : @xmath57 in the above equation , @xmath58 is an @xmath59 identity matrix and @xmath60 a matrix with all its entries equal to @xmath61 ; @xmath62 is the @xmath63 sub - matrix of @xmath64 with the transition probabilities between transient states ; and @xmath65 is the @xmath66 sub - matrix of @xmath64 with the transition probabilities from transient to absorbing states .",
    "an important quantity of an absorbing random walk is the expected number of visits to a transient state @xmath8 when starting from a transient state @xmath0 before being absorbed .",
    "the probability of transitioning from @xmath0 to @xmath8 in exactly @xmath67 steps is the @xmath9-entry of the matrix @xmath68 .",
    "therefore , the probability that a random walk starting from state  @xmath0 ends in @xmath8 without being absorbed is given by the @xmath9 entry of the @xmath63 matrix @xmath69 which is known as the _ fundamental matrix _ of the absorbing random walk .",
    "finally , the matrix @xmath70 is an @xmath66 matrix , with @xmath71 being the probability that a random walk which starts at transient state @xmath0 ends up being absorbed at state @xmath72 .",
    "assume that each absorbing node @xmath73 is associated with a fixed value @xmath74 .",
    "if a random walk starting from transient node @xmath75 gets absorbed in an absorbing node @xmath72 , then we assign to node @xmath0 the value @xmath74 .",
    "the probability of the random walk starting from node @xmath0 to be absorbed in @xmath8 is @xmath71 .",
    "therefore , the expected value of @xmath0 is @xmath76 .",
    "if @xmath77 is the vector with the expected values for all @xmath75 , and @xmath78 keeps the values @xmath79 for all @xmath72 , then we have that @xmath80    a fundamental observation , which highlights the connection between our work and random walks with absorbing states , is that the expected value @xmath81 of node @xmath75 can be computed by repeatedly averaging the values of the neighbors of @xmath0 in the graph  @xmath52 .",
    "therefore , the computation of the nash - equilibrium opinion vector @xmath25 can be done using equation   on an appropriately constructed graph  @xmath52 .",
    "we discuss the construction of @xmath52 below .",
    "more details on absorbing walks can be found in the excellent monograph of doyle and snell  @xcite .    * the augmented graph .",
    "* we will now show how the theory of absorbing random walks described above can be leveraged for solving the campaign problem .",
    "this connection is achieved by performing a random walk with absorbing states on an _ augmented graph _",
    "@xmath39 , whose construction we describe below .    given a social network @xmath1 where every edge @xmath82 is associated with weight @xmath14 , we construct the augmented graph @xmath39 of @xmath13 as follows :    * the set of vertices @xmath41 of @xmath52 is defined as @xmath83 , where @xmath84 is a set of @xmath6 new nodes such that for each node @xmath85 there is a copy @xmath86 ; * the set of edges @xmath42 of @xmath52 includes all the edges @xmath87 of @xmath13 , plus a new set of edges between each node @xmath88 and its copy @xmath86 .",
    "that is , @xmath89 , and @xmath90 ; * the weights of all the new edges @xmath91 are set to 1 , i.e. , @xmath92 . for @xmath93 ,",
    "the weight of the edge @xmath94 is equal to the weight of the corresponding edge in @xmath13 , i.e. , @xmath95 .",
    "for the augmented graph @xmath52 , we can instantiate the matrices @xmath64 , @xmath96 , and @xmath97 defined in the previous paragraph .",
    "the augmented graph @xmath52 is a construction that we are going to use throughout the paper .",
    "our main observation is that we can compute the opinion vector @xmath25 that corresponds to the nash equilibrium defined by equation   by performing an absorbing random walk on the graph @xmath52 . in this random walk , we set @xmath98 and @xmath99 , that is , we make all copy nodes in @xmath84 to be absorbing .",
    "we also set @xmath100 , that is , we assign value @xmath2 to each absorbing node @xmath101 .",
    "the nash - equilibrium opinion - vector @xmath25 can be computed using equation  , that is , @xmath102 .",
    "the opinion @xmath103 is the expected internal opinion value at the node of absorption for a random walk that starts from node @xmath88 .",
    "given the vector @xmath25 we can compute the overall opinion @xmath31 .",
    "the campaign problem can be naturally defined in this setting . selecting a set of nodes",
    "@xmath33 is equivalent to adding the nodes in @xmath33 into the set of absorbing nodes @xmath104 , and assigning them value 1 .",
    "that is , we have @xmath105 and @xmath106 . for the vector @xmath78 , we have @xmath107 for all @xmath108 , and @xmath109 for all @xmath110 .",
    "we use equation   to compute vector @xmath25 and using this @xmath25 , we can then compute the overall opinion @xmath35 . hence , the campaign problem becomes the problem of selecting a set of @xmath4 nodes @xmath111 to make absorbing with value 1 , such that @xmath35 is maximized .",
    "in this section , we establish the complexity of the campaign problem by showing that it is an @xmath112-hard problem .",
    "we also discuss properties of the objective function @xmath35 , which give rise to a constant - factor approximation algorithm for the campaign problem .",
    "[ theorem : np ] problem campaign  is @xmath112-hard .    we prove the theorem by reducing an instance of the vertex cover on regular graphs problem ( vcrg )  @xcite to an instance of the decision version of the campaign problem .",
    "we remind that a graph is called regular if all its nodes have the same degree .",
    "given a regular graph @xmath113 and an integer @xmath114 the vcrg problem asks whether there exists a set of nodes @xmath115 such that @xmath116 and @xmath117 is a vertex cover ( i.e. , for every @xmath118 it is @xmath119 or  @xmath120 ) .",
    "an instance of the decision version of the campaign problem consists of a social graph @xmath1 , internal opinions @xmath121 , an integer @xmath4 and a number  @xmath122 .",
    "the solution to the decision version is `` yes ''",
    "iff there exists a set @xmath123 such that @xmath124 and @xmath125 .",
    "given an instance of the vcrg problem , we will construct an instance of the decision version of campaign by setting @xmath1 to be equal to @xmath113 , @xmath126 for every @xmath88 , @xmath127 and @xmath128 .",
    "then , we show that @xmath123 is a solution to the campaign problem with value @xmath129 if and only if @xmath33 is a vertex cover of the input instance of vcrg .    in order to show this , we use the absorbing random walk interpretation for the campaign problem . recall that by the definition of the campaign problem , every node @xmath37 becomes an absorbing node with value @xmath36 . for every other node",
    "@xmath38 we compute a value @xmath20 . since @xmath130 for all @xmath131 and @xmath132 for all @xmath133 , the value @xmath20 represents the probability that the random walk starting from @xmath8 will be absorbed in some node in @xmath33 .",
    "now suppose that @xmath33 is a vertex cover for @xmath134 .",
    "then , for every non - absorbing vertex @xmath135 , for each one of the @xmath136 edges @xmath137 incident on @xmath8 , it must be that @xmath133 ; otherwise edge @xmath138 is not covered , and @xmath33 is not a vertex cover .",
    "therefore , in the augmented graph @xmath52 , node @xmath8 is connected to @xmath136 nodes in @xmath33 , and to node @xmath139 , all of them absorbing . a random walk starting from @xmath8",
    "will be absorbed and converge in a single step .",
    "the probability of it being absorbed in a node in @xmath33 is @xmath140 .",
    "there are @xmath141 nodes in @xmath142 , therefore , @xmath143 .",
    "if @xmath33 is not a vertex cover for @xmath134 , then there is an edge @xmath144 , such that @xmath145 . as we noted before , @xmath20 is the probability of being absorbed in some node in @xmath33 .",
    "the transition probability of the edge @xmath146 is @xmath147 , therefore , node @xmath8 has probability at least @xmath147 of being absorbed in @xmath139 .",
    "since there is a path from @xmath8 to @xmath148 with non - zero probability , the probability of @xmath8 being absorbed in node @xmath148 is strictly greater than zero .",
    "therefore , the probability of being absorbed in some node not in @xmath33 is strictly greater than @xmath147 , and thus @xmath149 .",
    "it follows that @xmath150 .",
    "the proof of the theorem appears in the appendix  [ appendix : np - hard ] .",
    "the proof relies on a reduction from the vertex cover on regular graphs problem ( vcrg )  @xcite .    since the campaign problem is @xmath112-hard , we are content with algorithms that approximate the optimal solution in polynomial time .",
    "fortunately , we can show that the function @xmath151 is monotone and submodular , and thus a simple greedy heuristic yields a constant - factor approximation to the optimal solution .",
    "[ theorem : submodular ] the function @xmath151 is monotone and submodular .    we only give here a proof sketch . a detailed proof is given in appendix  [ appendix : submodularity ] .",
    "recall that @xmath152 . in the absorbing random walk interpretation of the opinion formation process",
    ", we have shown that the expressed opinion of node @xmath0 is the expected opinion value at the point of absorbtion for a random walk that starts from node @xmath0 .",
    "that is , @xmath153 , where @xmath104 is the set of absorbing nodes , @xmath154 is the probability of the random walk starting from node @xmath0 to be absorbed at node @xmath54 , and @xmath155 the opinion value at node @xmath54 .",
    "when we add a node @xmath156 to @xmath33 , and hence to the set @xmath104 , some of the probability mass of the random walk will be absorbed at @xmath156 .",
    "since @xmath156 has the maximum possible opinion value , @xmath157 , if follows that @xmath3 can only increase , and thus @xmath151 is monotone .",
    "furthermore , the less competition there is for @xmath156 ( i.e. , the smaller the size of @xmath104 ) , the more mass of the random walk will be absorbed in @xmath156 , and the larger the increase of @xmath151 .",
    "hence @xmath151 is submodular .",
    "recall that @xmath152 , where the values of vector @xmath25 are computed using equation  . as we have already described , we can view the computation of the vector @xmath25 as performing a random walk with absorbing nodes on the augmented graph @xmath158 .",
    "assume that @xmath104 is the set of absorbing nodes , and that each @xmath159 is associated with value @xmath155 .",
    "let @xmath160 be the probability that a random walk that starts from @xmath0 gets absorbed at node @xmath54 , when the set of absorbing nodes is @xmath104 .",
    "the expressed opinion of node @xmath161 is @xmath162 since this value depends on the set @xmath104 , we will write @xmath163 to denote the value of @xmath3 when the set of absorbing nodes is @xmath104 .    initially , the set of absorbing nodes is @xmath164 and @xmath165 for all @xmath166 .",
    "when we select a subset of nodes @xmath111 such that their expressed opinions are fixed to 1 , we have that @xmath167 , @xmath165 for all @xmath168 and @xmath169 for all @xmath170 .",
    "since the set of nodes @xmath84 is always part of the set @xmath104 , and the parameter that we are interested in for this proof is the target set of nodes @xmath33 , we will use @xmath171 to denote @xmath163 where @xmath167 .",
    "we thus have @xmath172 note that the summation is over all nodes in @xmath173 including the nodes in @xmath33 . if @xmath133 , then @xmath174 , and @xmath175 for all @xmath176 .",
    "therefore , @xmath177 for all @xmath133 .",
    "we now make the following key observation .",
    "let @xmath8 be a node in @xmath142 .",
    "we have that @xmath178 the equation above follows from the observation that we can express the probability of a random walk starting from @xmath0 to be absorbed in some node @xmath166 as the sum of two terms : ( i ) the probability @xmath179 that the random walk is absorbed in @xmath54 , while avoiding passing through @xmath8 ( thus we add @xmath8 in the absorbing set ) ; ( ii ) the probability @xmath180 that the random walk is absorbed in @xmath8 while avoiding the nodes in @xmath104 ( that is , the probability of all paths that go from @xmath0 to @xmath8 of arbitrary length , without passing through @xmath8 or @xmath104 ) , times the probability @xmath181 of starting a new random walk from @xmath8 and getting absorbed in @xmath54 ( being able to revisit @xmath8 and any node in @xmath142 ) .",
    "if we add node @xmath8 into the set @xmath33 we have that @xmath182    hence , @xmath183 therefore , we can conclude that function @xmath151 is monotone with respect to the set of target nodes @xmath33 .",
    "we now need to show that @xmath151 is submodular , that is for any @xmath184 such that @xmath185 , and for any node @xmath186 , we have that @xmath187 .",
    "for this we will use two random walks : one with absorbing states @xmath188 and the other with absorbing states @xmath189 . following reasoning and notation similar to the one we used for monotonicity we have that @xmath190 from the monotonicity property we have that @xmath191 also , as the number of absorbing nodes increases",
    ", the probability of being absorbed in a specific node @xmath8 decreases , since the probability of the random walk to be absorbed in a node other than @xmath8 increases .",
    "therefore , we also have that @xmath192 combining these last two observations we conclude that @xmath187 which shows that the function is submodular .",
    "interestingly , the i - campaign problem , where the advertising campaign aims to change the internal rather than the expressed opinions of individuals , is solvable in polynomial time .",
    "we prove this fact below .",
    "[ theorem : poly ] there is a polynomial time algorithm for problem i - campaign .",
    "let @xmath1 be the input to the i - campaign problem .",
    "we form the augmented graph @xmath158 and compute @xmath25 using equation   for @xmath98 and @xmath99 . in this case",
    ", the vector @xmath194 has values corresponding to the input @xmath2 s , and the vector @xmath195 has values corresponding to @xmath3 s .",
    "thus , we have @xmath196 where @xmath197 is a fixed matrix .",
    "if @xmath198 is the @xmath8-th column sum of the matrix  @xmath199 , then our objective function becomes @xmath200 since we want to maximize the previous quantity by selecting a set @xmath201 of size @xmath4 and setting @xmath202 for every @xmath203 , it is sufficient to select the @xmath4 nodes in @xmath173 that have the largest column sums  @xmath204 .",
    "note that a property similar to the one used in the above proof has also been used by even - dar and shapira  @xcite.for the rest of the discussion , we will refer to the above algorithm as the ` i - campaign ` algorithm .",
    "a central component in all the algorithms presented in this section is the estimation of the the opinion function @xmath35 . in section  [ sec : background ] , we have already discussed that this can be done by evaluating equation  . for appropriately defined sets @xmath206 and @xmath104 ,",
    "this requires computing the matrix @xmath207 .",
    "hence , this calculation involves a matrix inversion , which is very inefficient .",
    "the reason is that despite the fact that the social graph is typically sparse , matrix inversion does not preserve sparseness .",
    "thus , it may be too expensive to even store the matrix  @xmath199 .",
    "instead , we resort to the power - iteration method implied by equation  : at each iteration we update the opinion @xmath3 of a node @xmath88 by averaging the opinions of its neighbors @xmath21 and its own internal opinion @xmath2 . during the iterations we do not update the values of opinions that are fixed .",
    "this power - iteration method is known to converge to the equilibrium vector @xmath25 , and it is highly scalable , since it only involves multiplication of a sparse matrix with a vector . for a graph with @xmath6 nodes , @xmath7 edges , and",
    "thus , average degree @xmath208 , the algorithm requires @xmath209 operations per iterations .",
    "therefore , the overall running time is @xmath210 , where @xmath58 is the total number of iterations . in our experiments we found the the method converges in around 50 - 100 iterations , depending on the dataset .",
    "our algorithms for the campaign  problem , include a constant - factor approximation algorithm as well as several efficient and effective heuristics .",
    "* the ` greedy ` algorithm . * it is known that the greedy algorithm is a @xmath211-approximation algorithm for maximizing a submodular function @xmath212 subject to cardinality constraints , i.e. , finding a set @xmath213 that maximizes @xmath214 such that @xmath215  @xcite .",
    "consequently , the ` greedy ` algorithm constructs the set @xmath33 by adding one node in each iteration . in the @xmath216-th iteration",
    "the algorithm extends the set @xmath217 by adding the node @xmath0 that maximizes @xmath218 when setting @xmath36 .",
    "the computational bottleneck of ` greedy ` is due to the fact that we need to compute the nash - equilibrium opinion vector @xmath205that results from setting @xmath219 for all @xmath220 , and we need to do such a computation for all candidate nodes @xmath221 .",
    "overall , for a solution @xmath33 of size @xmath222 ` greedy ` needs to perform @xmath223 computations of finding the optimal vector  @xmath205 .",
    "as we saw , each of these computations is performed by a power - iteration in time @xmath210 , yielding an overall running time @xmath224 .",
    "such a running time is super - quadratic and therefore the algorithm is not scalable to very large datasets .",
    "one way to speedup the algorithm is by storing , for each node that it is not yet selected , its marginal improvement on the score , at the last time it was computed .",
    "this speedup , which is commonly used in optimization problems with submodular functions  @xcite , is not adequate to make the greedy algorithm applicable for large data , at least for the version of the algorithm described here .",
    "the reason is that in the very first iteration there is no pruning and therefore we need to make @xmath225 power - iteration computations , yielding again a quadratic algorithm . to overcome these scalability limitations",
    ", we present a number of scalable heuristics .      to characterize the nodes selected by ` greedy `  we execute the algorithm on small datasets , and we compute a number of measures for each node selected by ` greedy ` . in particular , for each node we compute measures such as its degree , the average degree of its neighbors , the maximum degree of its neighbors , the value of its internal opinion @xmath2 , the average value of @xmath2 over its neighbors , and so on .",
    "three of the features with the most clear signal are shown in figure  [ figure : newman - order ] for the * karate club * dataset ( described in detail in section  [ section : experimental - evaluation ] ) .",
    "we obtain similar behavior on all the datasets we tried .    in figure  [",
    "figure : newman - order ] we plot measures of nodes in the order selected by the ` greedy ` .",
    "a good measure would be one that is monotonic with respect to this order . in the first panel ,",
    "we show the degree of a node in the selection order of ` greedy ` , and we see that ` greedy `  tends to select first high degree nodes . as shown in the second panel , this dependence is even more clear for the _ free degree _",
    ", i.e. , the number of neighbors that are not already selected by ` greedy ` . finally , in the third panel of figure",
    "[ figure : newman - order ] we see the internal opinion @xmath2 of nodes in the order selected by the ` greedy ` .",
    "we see that the ` greedy `  tends to select first nodes with low internal opinion .",
    "there are a few exceptions of nodes with high internal opinion @xmath2 selected at the initial steps of greedy .",
    "such nodes are nodes with high degree , connected to many nodes with small values of  @xmath2 .",
    "armed with intuition from this analysis we now proceed to describe our heuristics .    * the ` degree `  algorithm .",
    "* this algorithm simply sorts the nodes of @xmath1 in decreasing order of their in degree and forms the set of target nodes @xmath33 by picking the top-@xmath4 nodes of the ranking .",
    "the running time of ` degree ` is @xmath226 , i.e. , the time required for sorting .    *",
    "the ` freedegree `  algorithm .",
    "* this algorithm is a `` greedy '' variant of ` degree ` ; ` freedegree ` forms the set @xmath33 iteratively by choosing at every iteration the node with the highest free degree",
    ". the free degree of a node is the sum of the weights of the edges that are incident to it and are are connected to nodes not already in @xmath33 .",
    "when the set @xmath33 consists of @xmath4 nodes , the running time of ` freedegree ` is @xmath227 .    *",
    "the ` rwr `  algorithm . *",
    "as we saw in figure  [ figure : newman - order ] , a good choice for nodes to be added in the solution are not only the nodes of high degree but also the nodes of small value of internal opinion  @xmath2 .",
    "the ` rwr `  algorithm combines both of these features : selecting nodes with high degree and with small  @xmath2 .",
    "this is done by performing a random walk with restart ( ` rwr ` ) , where the probability of restarting at a node  @xmath0 is proportional to @xmath228 , where @xmath229 , and ordering the nodes according to the resulting stationary distribution .",
    "the intuition is that a random walk favors high - degree nodes , and using the specific restart probabilities favors nodes with low value of  @xmath2 .",
    "for the restart probability , we use the parameter @xmath230 , which has been established as a standard parameter of the pagerank algorithm  @xcite .",
    "making one ` rwr `  computation can be achieved by the power - iteration method , which similarly to computing the optimal vector  @xmath205 , has running time @xmath210 .",
    "therefore , the overall running time of the algorithm for selecting a set @xmath33 of size @xmath4 is @xmath231 .    *",
    "the ` min - s ` and ` min - z ` algorithms . * the ` min - s ` algorithm simply selects the @xmath4 nodes with the smallest value @xmath2 .",
    "this heuristic is motivated by the observation that the ` greedy ` algorithm tends to select nodes with small value @xmath2 . for completeness",
    ", we also experiment with the ` min - z ` algorithm , which greedily selects and add in the solution set @xmath33 the node that at the current iteration has the smallest value of expressed opinion  @xmath3 .",
    "the objective of our experiments is to compare the proposed heuristics against ` greedy ` , the algorithm with the approximation guarantee , and demonstrate their scalability .",
    "we experiment with a number of publicly available small networks .",
    "we evaluate our algorithms by reporting the value of the objective function @xmath31 as a function of the solution set size @xmath222 .",
    "our results for three small networks are shown in figure  [ figure : newman ] .",
    "the datasets shown in the figure are the following : ( @xmath0 ) * karate club * : a social network of friendships between 34 members of a karate club at a us university in the 1970s  @xcite ; ( @xmath46 ) * les miserables * : co - appearance network of characters in the novel _ les miserables _  @xcite ; and ( @xmath49 ) * dolphins * : an undirected social network of frequent associations between 62 dolphins  @xcite .",
    "for this set of experiments we set the internal opinions @xmath2 to be a uniformly - sampled value in @xmath16 $ ] .",
    "we see that the difference between all the algorithms is relatively small but their relative performance is consistent . the `",
    "greedy `  algorithm achieves the best results , while the three heuristics , ` degree ` , ` freedegree ` , and ` rwr `  come close together . `",
    "min - s ` and ` min - z ` have the poorest performance , even though for larger values of @xmath4 they improve and slightly outperform some of the heuristics . between the two , ` min - s ` performs best , outperforming ` min - z ` , especially for small values of @xmath4 .",
    "both of those trends are expected : the three heuristics ` degree ` , ` freedegree ` , and ` rwr ` , are better motivated than ` min - s ` , which in turn , is better motivated than ` min - z ` .",
    "we obtain similar results for other small networks , although we do not provide the plots for lack of space .",
    "we also evaluate our algorithms on two large social networks , derived from bibliographic data .",
    "the first dataset , * bibsonomy * , is extracted from bibsonomy  @xcite , a social - bookmarking and publication - sharing system . from the available data , we extract a social graph of @xmath232 nodes representing authors and @xmath233 edges representing co - authorship relations . for each author",
    "we also keep the set of tags that have been used for the papers of that author .",
    "the second dataset , * dblp * , is also a co - authorship graph among computer scientists extracted from the dblp site .",
    "the dataset is a large graph containing @xmath234 nodes and @xmath235 edges .",
    "again , for each author we keep the set of terms they have been used in the titles of the papers they have co - authored .    in this experiment",
    ", we generate the internal opinion vectors by identifying keywords related to data mining ( e.g. , we picked _ data _ , _ mining _ , _ social _ , _ networks _ , _ graph _ , _ clustering _ , _ learning _ , and _ community _ ) . for each author",
    "@xmath88 we then set @xmath2 to be the fraction of the above keywords present in his set of terms .",
    "this setting corresponds to a hypothetical scenario of designing a campaign to promote the `` data mining '' topic among all computer - science researchers .",
    "performance of the algorithms on the * bibsonomy *  network for the topic `` semantic web''.,scaledwidth=47.0% ]    the results of the heuristics for the two datasets are shown in figure  [ figure : bibsonomydblp ] .",
    "for the * bibsonomy *  dataset ( left ) , there is a clear distinction between the three heuristics ; ` rwr ` clearly performs better than both ` degree ` and ` freedegree ` .",
    "this superior performance of ` rwr `  is expected as this algorithm takes into account both the degrees and the values of the internal opinions  @xmath2 .",
    "also the better performance of ` freedegree`compared with the performance of ` degree `  is consistent with the results obtained for smaller networks . on the other hand , on the * dblp *  dataset ( right part of figure  [ figure : bibsonomydblp ] )",
    "the behavior of the three heuristics is more surprisingly , as all three perform almost identical .",
    "finally , for both datasets , the difference of the three best heuristics ` degree ` , ` freedegree ` , and ` rwr `  with the other two heuristics , ` min - s ` and ` min - z ` is more pronounced .",
    "in fact , the performance of ` min - s ` and ` min - z ` is very poor .",
    "we investigate the difference on the relative performance of the best three heuristics , ` degree ` , ` freedegree ` , and ` rwr ` , on the two datasets by plotting the degrees of the nodes versus their @xmath2 value .",
    "this is shown in figure  [ figure : degree - vs - si ] .",
    "recall that our intuition for selecting nodes that is to choose nodes that have large degree and small value of  @xmath2 . figure",
    "[ figure : degree - vs - si ] demonstrates that in the * dblp * dataset , large degree correlates well with small @xmath2 values , while this is not the case for the * bibsonomy * dataset . therefore , for * dblp * all three heuristics pick high - degree nodes , which makes their performance almost identical .",
    "scatter plot of degrees vs.  internal opinion values @xmath2 in the two datasets , * bibsonomy *  and * dblp*.,title=\"fig:\",scaledwidth=23.0% ]   scatter plot of degrees vs.  internal opinion values @xmath2 in the two datasets , * bibsonomy *  and * dblp*.,title=\"fig:\",scaledwidth=23.0% ]",
    "the campaign problem we studied in this paper focuses on campaigns that aim to alter the expressed opinions of individuals . however , other campaign strategies are also possible",
    ". for example one could aim at altering the internal opinions of individuals such that the overall opinion is improved as much as possible .",
    "formally , the goal would be to select a set of nodes @xmath236 , which are going to be convinced to change their _ internal opinions _",
    "@xmath2 to @xmath34 , such that the resulting overall opinion  @xmath237 is maximized .",
    "we call this problem the i - campaign problem .",
    "the difference between the campaign and i - campaign problems is that in the former we are asking to fix the expressed opinions @xmath3 for @xmath4 individuals , while in the latter we are asking to fix the internal opinions @xmath2 .",
    "even though the difference is seemingly small , the problems are computationally very different .",
    "algorithmically , the problem of selecting @xmath236 individuals to change their internal opinions , so that we maximize @xmath237 is much simpler .",
    "in fact , we can show that for an undirected social graph @xmath1 , where each node @xmath85 has internal opinion @xmath2 and expressed opinion @xmath3 , the following invariant holds , independently of the structure of the graph ( the set of edges @xmath87 ) : @xmath238 consequently , the goal of maximizing @xmath31 by modifying @xmath4 values @xmath2 can be simply achieved by selecting the @xmath4 smallest values @xmath2 and setting them to  1 .",
    "we note that the above observation does not hold once the expressed opinions of some individuals are fixed , as is the case in the campaign problem .",
    "the proof of the invariant , and its implications are discussed in the appendix  [ appendix : invariant ] .",
    "the graph invariant has obvious implications for the other variant of the campaign problem , where we seek to maximize @xmath31 by adding or removing edges to the graph . from equation  ( [ equation : invariant ] )",
    "it follows that for undirected social graphs this problem variant is meaningless ; the overall opinion @xmath31 does not depend on the structure of the graph .",
    "this observation has important implications for opinion formation on social networks .",
    "it shows that although the network structure has an effect on the individual opinions of network participants , it does not affect the average opinion in the network . for the campaign problem",
    ", this says that you can not create more goodwill by altering the network . for the study of social dynamics , this implies that the collective wisdom of the crowd remains unaffected by the social connections between individuals .",
    "we considered a setting where opinions of individuals in a social network evolve through processes of social dynamics , reaching a nash equilibrium . adopting a standard social and economic model of such dynamics we addressed the following natural question : given a social network of individuals who have their own internal opinions about an information item , which are the individuals that need to be convinced to adopt a positive opinion so that in the equilibrium state , the network ( as a whole ) has the maximum positive opinion about the item ?",
    "we studied the computational complexity of this problem and proposed algorithms for solving them exactly or approximately .",
    "our theoretical analysis and the algorithm design relied on a connection between opinion dynamics and random walks with absorbing states .",
    "our experimental evaluation on real datasets demonstrated the efficacy of our algorithms and the effect of the structural characteristics of the underlying social networks on their performance .    10    benchmark folksonomy data from bibsonomy .",
    "technical report , knowledge and data engineering group , university of kassel , 2007 .",
    "d.  acemoglu and a.  ozdaglar .",
    "opinion dynamics and learning in social networks . , 2011 .",
    "d.  bindel , j.  m. kleinberg , and s.  oren .",
    "how bad is forming your own opinion ? in _ focs _ , 2011 .",
    "s.  brin and l.  page .",
    "the anatomy of a large - scale hypertextual web search engine . in _",
    "www _ , 1998 .",
    "n.  chen . on the approximability of influence in social networks . in _ soda _",
    ", 2008 .    m.  h. degrout .",
    "reaching consensus .",
    ", 1974 .",
    "p.  m. demarzo , d.  vayanos , and j.  zweibel .",
    "persuasion bias , social influence , and unidimensional opinions . , 2003 .",
    "p.  doyle and j.  snell . .",
    "mathematical association of america , 1984 .",
    "e.  even - dar and a.  shapira . a note on maximizing the spread of influence in social networks . in _ wine",
    "_ , 2007 .",
    "u.  feige .",
    "vertex cover is hardest to approximate on regular graphs . , 2003 .",
    "n.  e. friedkin and e.  johnsen . social influence and opinions . , 1990 .",
    "b.  golub and m.  o. jackson .",
    "naive learning in social networks : convergence , influence and the wisdom of the crowds .",
    ", 2010 .",
    "m.  o. jackson . .",
    "princeton university press , 2008 .",
    "d.  kempe , j.  m. kleinberg , and  .",
    "tardos . maximizing the spread of influence through a social network . in _",
    "kdd _ , 2003 .",
    "d.  e. knuth . .",
    "addison - wesley , 1993 .",
    "d.  krackhardt . a plunge into networks . , 2009 .",
    "j.  leskovec , a.  krause , c.  guestrin , c.  faloutsos , j.  m. vanbriesen , and n.  s. glance . cost - effective outbreak detection in networks . in _",
    "kdd _ , 2007 .",
    "d.  lusseau , k.  schneider , o.  j. boisseau , p.  haase , e.  slooten , and s.  m. dawson .",
    ", 54:396405 , 2003 .",
    "g.  nemhauser , l.  wolsey , and m.  fisher .",
    "an analysis of the approximations for maximizing submodular set functions . , 1978 .",
    "m.  richardson and p.  domingos . mining knowledge - sharing sites for viral marketing . in _",
    "kdd _ , 2002 .",
    "w.  w. zachary .",
    "an information flow model for conflict and fission in small groups .",
    ", 33:452473 , 2003 .",
    "we prove the theorem by reducing an instance of the vertex cover on regular graphs problem ( vcrg )  @xcite to an instance of the decision version of the campaign problem .",
    "we remind that a graph is called regular if all its nodes have the same degree .",
    "given a regular graph @xmath113 and an integer @xmath114 the vcrg problem asks whether there exists a set of nodes @xmath115 such that @xmath116 and @xmath117 is a vertex cover ( i.e. , for every @xmath118 it is @xmath119 or  @xmath120 ) .",
    "an instance of the decision version of the campaign problem consists of a social graph @xmath1 , internal opinions @xmath121 , an integer @xmath4 and a number  @xmath122 .",
    "the solution to the decision version is `` yes ''",
    "iff there exists a set @xmath123 such that @xmath124 and @xmath125 .",
    "given an instance of the vcrg problem , we will construct an instance of the decision version of campaign by setting @xmath1 to be equal to @xmath113 , @xmath126 for every @xmath88 , @xmath127 and @xmath128 .",
    "then , we show that @xmath123 is a solution to the campaign problem with value @xmath129 if and only if @xmath33 is a vertex cover of the input instance of vcrg .    in order to show this , we use the absorbing random walk interpretation of the campaign problem . recall that by the definition of the campaign problem , every node @xmath37 becomes an absorbing node with value @xmath36 .",
    "for every other node @xmath38 we compute a value @xmath20 , which is the expected value at the absorption point of a random walk that starts from @xmath8 . since @xmath130 for all @xmath85 and @xmath132 for all @xmath133 , the value @xmath20 represents the probability that the random walk starting from @xmath8 will be absorbed in some node in @xmath33 .",
    "now suppose that @xmath33 is a vertex cover for @xmath134 .",
    "then , for every non - absorbing vertex @xmath135 , for each one of the @xmath136 edges @xmath137 incident on @xmath8 , it must be that @xmath133 ; otherwise edge @xmath138 is not covered , and @xmath33 is not a vertex cover .",
    "therefore , in the augmented graph @xmath52 , node @xmath8 is connected to @xmath136 nodes in @xmath33 , and to node @xmath139 , all of them absorbing . a random walk starting from @xmath8",
    "will be absorbed and converge in a single step .",
    "the probability of it being absorbed in a node in @xmath33 is @xmath140 .",
    "there are @xmath141 nodes in @xmath142 , therefore , @xmath143 .",
    "if @xmath33 is not a vertex cover for @xmath134 , then there is an edge @xmath144 , such that @xmath145 . as we noted before , @xmath20 is the probability of being absorbed in some node in @xmath33 .",
    "the transition probability of the edge @xmath146 is @xmath147 , therefore , node @xmath8 has probability at least @xmath147 of being absorbed in @xmath139 .",
    "since there is a path from @xmath8 to @xmath148 with non - zero probability , the probability of @xmath8 being absorbed in node @xmath148 is strictly greater than zero .",
    "therefore , the probability of being absorbed in some node not in @xmath33 is strictly greater than @xmath147 , and thus @xmath149 .",
    "it follows that @xmath150 .",
    "recall that @xmath152 , where the values of vector @xmath25 are computed using equation  . as we have already described , we can view the computation of the vector @xmath25 as performing a random walk with absorbing nodes on the augmented graph @xmath158 .",
    "assume that @xmath104 is the set of absorbing nodes , and that each @xmath159 is associated with value @xmath155 .",
    "let @xmath160 be the probability that a random walk that starts from @xmath0 gets absorbed at node @xmath54 , when the set of absorbing nodes is @xmath104 .",
    "the expressed opinion of node @xmath161 is @xmath162 since this value depends on the set @xmath104 , we will write @xmath163 to denote the value of @xmath3 when the set of absorbing nodes is @xmath104 .    initially , the set of absorbing nodes is @xmath164 and @xmath165 for all @xmath166 .",
    "when we select a subset of nodes @xmath111 such that their expressed opinions are fixed to 1 , we have that @xmath167 , @xmath165 for all @xmath168 and @xmath169 for all @xmath170 .",
    "since the set of nodes @xmath84 is always part of the set @xmath104 , and the parameter that we are interested in for this proof is the target set of nodes @xmath33 , we will use @xmath171 to denote @xmath163 where @xmath167 .",
    "we thus have @xmath172 note that the summation is over all nodes in @xmath173 including the nodes in @xmath33 . if @xmath133 , then @xmath174 , and @xmath175 for all @xmath176 .",
    "therefore , @xmath177 for all @xmath133 .",
    "we now make the following key observation .",
    "let @xmath8 be a non - absorbing node in @xmath142 .",
    "we have that @xmath178 the equation above follows from the observation that we can express the probability of a random walk starting from @xmath0 to be absorbed in some node @xmath166 as the sum of two terms : ( i ) the probability @xmath179 that the random walk is absorbed in @xmath54 , while avoiding passing through @xmath8 ( thus we add @xmath8 in the absorbing set ) ; ( ii ) the probability @xmath180 that the random walk is absorbed in @xmath8 while avoiding the nodes in @xmath104 ( that is , the probability of all paths that go from @xmath0 to @xmath8 of arbitrary length , without passing through @xmath8 or @xmath104 ) , times the probability @xmath181 of starting a new random walk from @xmath8 and getting absorbed in @xmath54 ( being able to revisit @xmath8 and any node in @xmath142 ) .",
    "if we add node @xmath8 into the set @xmath33 we have that @xmath182    hence , @xmath183 therefore , we can conclude that function @xmath151 is monotone with respect to the set of target nodes @xmath33 .",
    "we now need to show that @xmath151 is submodular , that is for any @xmath184 such that @xmath185 , and for any node @xmath186 , we have that @xmath187 . for this",
    "we will use two random walks : one with absorbing states @xmath188 and the other with absorbing states @xmath189 . following reasoning and notation similar to the one we used for monotonicity we have that @xmath190 from the monotonicity property we have that @xmath191 also , as the number of absorbing nodes increases",
    ", the probability of being absorbed in a specific node @xmath8 decreases , since the probability of the random walk to be absorbed in a node other than @xmath8 increases .",
    "therefore , we also have that @xmath192 combining these last two observations we conclude that @xmath187 which shows that the function is submodular .",
    "in this section we prove a graph invariant related to the sum of the values @xmath3 and  @xmath2 .",
    "this invariant has repercussions in the following scenarios :    * maximize @xmath31 by modifying only the internal opinions @xmath2 of the users ( problem i - campaign in section  [ section : variants ] ) ; and * maximize @xmath31 by adding edges in the social graph , for instance , recommend friendships or certain accounts for users to connect and follow .",
    "we prove the invariant in a slightly more general setting than the one we consider in the paper .",
    "we then formulate the more special case of the invariant for our exact problem setting , and we discuss its implications in the above - mentioned scenarios ( @xmath0 ) and  ( @xmath46 ) .",
    "consider an undirected graph @xmath239 .",
    "we use @xmath14 to denote the weight of edge @xmath9 and @xmath240 to denote the total weight of all edges incident on node @xmath0 .",
    "we assume that the vertices in @xmath173 are partitioned in two sets @xmath206 and @xmath104 .",
    "the nodes in @xmath104 are _ absorbing _ nodes for the random walk .",
    "each node @xmath73 is associated with a value @xmath241 .",
    "the value @xmath241 can be either the internal opinion of node @xmath8 ( in which case @xmath242 ) , or the fixed expressed opinion of node  @xmath8 ( in which case @xmath243 ) .",
    "for each node @xmath244 we will compute a value @xmath3 which is the expected value at the node of absorption for a random walk that starts from node @xmath0 , as given by equation  ( [ equation : equilibrium ] ) .",
    "we further make the assumption that the set of absorbing nodes can be partitioned into @xmath245 disjoint subsets @xmath246 , one for each node @xmath244 , such that the nodes in @xmath247 are connected _ only _ with the node @xmath0 .",
    "we can make this assumption without loss of generality , since in the case that a node @xmath73 is connected to @xmath4 nodes @xmath248 in @xmath206 , we can create @xmath4 copies of @xmath8 , each with value @xmath241 , and connect each copy with a single node in @xmath206 with an edge of the same weight , while removing the original node @xmath8 from the graph . in the resulting graph",
    "the @xmath3 values computed by the absorbing random walk are the same as in the original graph .    to introduce some additional notation let @xmath249 denote the set of edges between non - absorbing nodes , and let @xmath250 denote the set of edges between nodes in @xmath206 and in @xmath104 .",
    "note that by the construction above there are no edges between the nodes in @xmath104 .",
    "such edges would not have any effect anyway , since the nodes in @xmath104 are absorbing .",
    "given a node @xmath244 , let @xmath11 denote the set of neighbors of @xmath0 , let @xmath251 denote the set of non - absorbing neighbors of @xmath0 , and let @xmath247 denote the set of absorbing neighbors of @xmath0 .    from the definition of the absorbing random",
    "walk we have that @xmath252 and thus @xmath253 summing over all @xmath244 we get @xmath254 the left - hand side can also be written as : @xmath255 by equations  ( [ equation : invariant_1 ] ) and  ( [ equation : invariant_2 ] ) we obtain @xmath256 equation  ( [ eq : general : z - s ] ) is the most general form of our invariant .",
    "the equation relates the values of @xmath3 and @xmath241 via the weights @xmath14 across the edges @xmath250 , i.e. , only the edges between absorbing and non - absorbing nodes .",
    "the set of edges @xmath249 between the non - absorbing nodes does not play any role .",
    "we now consider the special case in which equation  ( [ eq : general : z - s ] ) is applied to graphs considered in this paper , that is , in augmented graphs of type @xmath257 , as defined in section  [ section : notation ] . in that case",
    ", each node @xmath85 is connected to a single absorbing node @xmath258 , which has value @xmath107 .",
    "furthermore , for each edge @xmath259 , we have @xmath260 , namely , all edges to absorbing nodes have the same weight . in this case , the invariant becomes @xmath261 as already discussed in section  [ section : variants ] , equation  ( [ equation : invariant ] ) has the following implications .    * regarding the problem i",
    "- campaign , that is , when we ask to maximize @xmath31 by modifying only the internal opinion values @xmath2 , it is easy to see that the maximum increase occurs when selecting the @xmath4 smallest values @xmath2 and setting them to  1",
    ". this observation motivates the algorithm ` min - s ` described in section  [ section : algorithms ] . *",
    "consider the following problem : we want to maximize @xmath31 by only adding or removing edges in the social graph and without modifying any of the values @xmath2 or @xmath3 .",
    "equations  ( [ eq : general : z - s ] ) and  ( [ equation : invariant ] ) provide an expression for @xmath31 that is independent on the structure of the graph defined by the edges in @xmath249 , and thus , show that it is not possible to change @xmath31 by adding or removing edges ."
  ],
  "abstract_text": [
    "<S> the process of opinion formation through synthesis and contrast of different viewpoints has been the subject of many studies in economics and social sciences . </S>",
    "<S> today , this process manifests itself also in online social networks and social media . </S>",
    "<S> the key characteristic of successful promotion campaigns is that they take into consideration such opinion - formation dynamics in order to create a overall favorable opinion about a specific information item , such as a person , a product , or an idea .    in this paper </S>",
    "<S> , we adopt a well - established model for social - opinion dynamics and formalize the campaign - design problem as the problem of identifying a set of target individuals whose positive opinion about an information item will maximize the overall positive opinion for the item in the social network . </S>",
    "<S> we call this problem campaign . </S>",
    "<S> we study the complexity of the campaign problem , and design algorithms for solving it . </S>",
    "<S> our experiments on real data demonstrate the efficiency and practical utility of our algorithms . </S>"
  ]
}