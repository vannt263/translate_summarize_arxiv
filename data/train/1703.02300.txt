{
  "article_text": [
    "today we are in an era , the so - called _ data - driven _ era , in which the size of data has reached dimensions so huge that often it is humanly impossible to handle them in an efficient and comprehensible way .",
    "dealing with petabytes of data will be the standard in a not far future and this will require that data analysis techniques and facilities must quickly evolve to face such amount of information .",
    "in particular , in astrophysics , the data volumes from the ongoing and next generation multi - band and multi - epoch surveys are expected to be so huge and diversified that analyzing , cross - correlating , visualizing and extracting knowledge from such data will represent a not trivial challenge for astronomers and computer engineers .",
    "the massive multi - band and multi - epoch information , foreseen to be available from the on - going and future surveys , will require efficient techniques and software solutions to be directly integrated into the reduction pipelines , making possible to cross - correlate in real time a large variety of parameters for billions of sky objects .",
    "one of main core steps of any standard modern pipeline of astronomical data reduction / analysis is the cross - matching technique , consisting in associating and comparing sources belonging to different catalogues .",
    "the cross - matching among modern astronomical catalogues is a challenge for two main reasons : first , it is particularly sensible to the growing of the datasets size , if performed in a naive way ; second ,",
    "multi - band data , even if referred to a same sky region , are archived and reduced in different ways , so that the resulting catalogues may differ each other in formats , resolution , data structure , etc , thus requiring the highest generality of cross - matching features .    in this work we describe the features of c@xmath1 , _ command - line catalogue cross - match _ , ( @xcite ) tool and the user guide are available at the page : http://dame.dsf.unina.it/c3.html . ] , a tool to perform efficient cross - matching among heterogeneous catalogues from modern astronomical surveys . it can be easily integrated into an automatic data analysis pipeline and its high performance capabilities are ensured by the use of a multi - core parallel processing paradigm and a sky partitioning algorithm .",
    "furthermore , this tool has been tailored on the specific user needs , giving the maximum flexibility to the end - user in terms of portability , parameter configuration , catalogue formats , angular resolution , region shapes , coordinate units and cross - matching types .",
    "c@xmath1 , a command - line python tool designed and developed to cross - match modern astrophysical catalogues , can be run as a stand - alone process or integrated within any generic data reduction / analysis pipeline . in order to ensure high performance in terms of computational time ,",
    "it is based on a sky partitioning algorithm and on the multi - core parallel processing paradigm .",
    "moreover , c@xmath2 is aimed to meet the needs of a community as wide as possible by providing the maximum flexibility to the end - user , in terms of catalogue formats and parameters , coordinates systems and cross - matching functions ; finally , it is very simple to configure through filling of a configuration file .",
    "summarizing , the main features of the c@xmath2 tool are :    * _ command line _ : it can be used as stand - alone process or integrated within complex data analysys pipelines ; * _ python compatibility _ : up to the version 3.4 ; * _ standard libraries and facilities _ : it makes use of the standard astronomical tool stilts ( ( * ? ? ?",
    "* taylor 2006 ) ) and two common python libraries , _ numpy _ ( ( * ? ? ?",
    "* van der walt et al . 2011 ) ) , and _",
    "_ pyfits _ _ ; * _ multi - platform _ : c@xmath1 is compatible with ubuntu linux ( from rel.14.04 ) , windows 7/10 , mac os and fedora ; * _ multi - process _ :",
    "a multi - core parallel processing paradigm is used to improve performance in terms of computational time ; * _ sky partitioning _ :",
    "a sky partitioning algorithm is used to reduce computational time ; * _ astronomical i / o formats compliant _ :",
    "the tool works with the most common i / o formats : fits , ascii , csv , votable ; * _ standard astronomical coordinate systems compliant _ : c@xmath2 works with equatorial ( icrs , fk4 , fk5 ) and galactic coordinate systems , expressed in degrees , radians or sexagesimal ; * _ user - friendliness _ : only a simple configuration file is required to configure and use it .",
    "c@xmath1 provides three different use cases , according to the most common cross - matching criteria used by the astronomical community :    1 .",
    "_ sky _ : two objects from two different catalogues match if they fall within the same elliptical or rectangular sky area defined by the catalogue parameters .",
    "it is defined _ positional crossmatch _ ; 2 .",
    "_ exact value _ : two objects are matched if they have the same value for a pair of columns ( one for each catalogue ) defined by the user ; 3 .   _ row - by - row _ : the cross - match is performed on a same row - id of the two catalogues .",
    "the idea at the basis of the c@xmath2 positional cross - matching method for the _ sky _ use case is the same of the q - fulltree approach , an our tool designed and developed in the fp7 vialactea project framework , introduced in @xcite and @xcite : the coordinates of each object of the first catalogue identify the centre of an elliptical ( circular as special case ) or rectangular region having fixed dimensions or defined by catalogue parameters ( for example , the two fwhms can be used as semi - axis of the ellipse or as width and height of the rectangle ) . by calculating the distance of each object of the second catalogue from the centre of region",
    ", it is possible to evaluate if it falls into such region . in the affermative case ,",
    "the two objects are matching ( fig .",
    "[ fig : crossmatch ] ) .",
    "+    the parameters characterizing the matching region can be defined by the user in the configuration file . in particular , it is possible to set : the shape of the matching area , which can be elliptical or rectangular ( circular is a special elliptical case ) ; the dimensions of the area , which can be defined by a fixed value or extracted by specific columns of the catalogues multiplied by a user - defined factor ; its orientation , characterized by a positional angle ( defined by a fixed value or by catalogue parameters ) and two additional parameters , to opportunely set the zero - point and the direction of rotation ( fig .",
    "[ fig : pa ] ) .",
    "the user has also to specify which matches must be included in the output file ( _ all _ the matches or only the _",
    "best _ pairs , in the sense of closest objects ) , according to the logical rule they have to satisfy :    @xmath3 and @xmath4 : :    , only rows having an entry in both input catalogues ; @xmath3 or @xmath4 : :    , all rows , matched and unmatched , from both input catalogues ; all from @xmath3 ( all from @xmath4 ) : :    , all matched rows from catalogue @xmath3 ( or    @xmath4 ) , together with the unmatched rows from catalogue    @xmath3 ( or @xmath4 ) ; @xmath3 not @xmath4 ( @xmath4 not @xmath3 ) : :    , all the rows of catalogue @xmath3 ( or @xmath4 )    without matches in the catalogue @xmath4 ( or @xmath3 ) ; @xmath3 xor @xmath4 : :    , the `` exclusive or '' of the match - i.e. only rows from the    catalogue @xmath3 not having matches in the catalogue    @xmath4 and viceversa .      in order to have high performance in terms of computational time , c@xmath2 makes use of two different methods : _",
    "i ) _ the application of multi - core parallel processing paradigm , through the definition of the number of parallel processes to run ; _ ii ) _ a sky partitioning algorithm to reduce the number of comparisons between the sources of the two catalogues .    in order to apply the two methods",
    ", c@xmath1 performs a series of preparatory manipulations on input data : the first input catalogue is splitted into a number of subsamples such that each of them is assigned to a concurrent process ; then , the sky is divided into _ cells _ , whose dimensions are defined by the maximum dimension that the matching regions can assume , namely the _ minimum cell size _ , ( fig .",
    "[ fig : partitioning]a ) .",
    "each object is then assigned to a cell according to its coordinates .",
    "this choice of the unit cell dimensions has the result that a match between two objects can happen only if a source of the second catalogue lies in the nine cells surrounding the object of the first one ( also known as moore s neighborhood , @xcite , see also fig .",
    "[ fig : partitioning]b ) , so avoiding the so - called _ block - edge problem _ ( ( * ? ? ?",
    "* du et al . 2015 ) ) .",
    "sky partitioning method .",
    "the sky is divided in cells whose dimensions are determined by the maximum value assumed by the main dimension of the matching area or by the _ minimum partition cell size _",
    "parameter ( panel a ) .",
    "each object of the second catalogue is assigned to a cell : a match between a source and the ellipse associated to the first catalogue object can take place only in the nine cells surrounding it ( panel b).,title=\"fig:\",width=302 ] +    in order to have the best performance for the specific computer used in the experiments , the user can manage both the number of concurrent processes and the dimension of the unit cell by setting their value in the configuration file .",
    "in order to evaluate the c@xmath2 performance in terms of computational time efficiency , we performed an intensive test campaign on real data .",
    "we used two catalogues extracted from the ukidss gps public data , ( ( * ? ? ?",
    "* lucas et al . 2008 ) ) , and the glimpse spitzer data , ( @xcite , @xcite ) , in the range of galactic coordinates @xmath5 $ ] , @xmath6 $ ] .",
    "the tests have been performed by varying the dimensions of subsets and combining each subsample of the first catalogue with all the subsamples of the second one . in particular , datasets with , respectively , @xmath7 , @xmath8 , @xmath9 , @xmath10 and @xmath11 objects have been created from the ukidss catalogue , while , from the glimpse catalogue , datasets with @xmath7 , @xmath8 , @xmath9 and @xmath10 rows have been extracted .",
    "the computer used for the tests is equipped with an intel(r ) core(tm ) @xmath12 , with one @xmath13 , @xmath14 cpu , @xmath15 gb of ram and hosting ubuntu linux @xmath16 as operative system on a standard hard disk drive .",
    "the results of the tests are reported in fig .  [",
    "fig : c3test ] .",
    "each line in the figure represent the trend of computational time of the c@xmath1 cross - matching phase as function of the incremental number of objects in the first catalogue for a fixed number of rows of the second catalogue ( from @xmath7 to @xmath10 rows as previously described ) .",
    "the results are in a perfect agreement with other publicly available cross - matching tools , as shown in ( * ? ? ?",
    "* riccio et al . ( 2016 ) ) .",
    "rows ( diamonds ) , @xmath8 rows ( squares ) , @xmath9 rows ( triangles ) , @xmath10 rows ( circles).,title=\"fig:\",width=510 ] +",
    "in this paper we have described a new scalable tool , named c@xmath2 , designed and developed to perform the cross - matching between astronomical datasets . it is a multi - platform command - line python script , executable as a stand - alone software or as a module in a generic data reduction / analysis pipeline , whose high performance capabilities are guaranteed by the use of the multi - core parallel processing paradigm and an indexing function to partionate the sky .",
    "the tool provides a number of use cases and parameter choice ( i / o formats , coordinates systems , shape and dimensions of matching area and cross - matching type ) in order to meet the needs of a scientific community as wide as possible .",
    "finally , c@xmath2 requires only a configuration file to run , making it easy to use ."
  ],
  "abstract_text": [
    "<S> in the current data - driven science era , it is needed that data analysis techniques has to quickly evolve to face with data whose dimensions has increased up to the petabyte scale . in particular , being modern astrophysics based on multi - wavelength data organized into large catalogues , it is crucial that the astronomical catalog cross - matching methods , strongly dependant from the catalogues size , must ensure efficiency , reliability and scalability . </S>",
    "<S> furthermore , multi - band data are archived and reduced in different ways , so that the resulting catalogues may differ each other in formats , resolution , data structure , etc , thus requiring the highest generality of cross - matching features . </S>",
    "<S> we present @xmath0 ( command - line catalogue cross - match ) , a multi - platform application designed to efficiently cross - match massive catalogues from modern surveys . </S>",
    "<S> conceived as a stand - alone command - line process or a module within generic data reduction / analysis pipeline , it provides the maximum flexibility , in terms of portability , configuration , coordinates and cross - matching types , ensuring high performance capabilities by using a multi - core parallel processing paradigm and a sky partitioning algorithm . </S>"
  ]
}