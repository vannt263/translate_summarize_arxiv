{
  "article_text": [
    "the einstein equations are typically solved in what is called free or unconstrained evolutions .",
    "the equations are split into a set of evolution equations and another one of constraints .",
    "the standard procedure is to use initial data that satisfy the constraints and later solve only for the set of evolution equations .",
    "the logic is that by virtue of bianchi identities the constraints should be satisfied at all times if they do so initially and the evolution equations are solved .",
    "this is actually true only in the absence of boundaries , or in the future domain of dependence of the initial data ; in the presence of boundaries appropriate boundary conditions have to given in such a way that the associated initial - boundary value problem is well posed , a highly non - trivial issue on its own ( see @xcite for related work ) .",
    "however , problems arise in free evolutions even neglecting the presence of boundaries .",
    "although the constraints should be exactly satisfied at the continuum level , in typical , fixed resolution , numerical simulations of strong fields the constraints quickly grow and eventually the code crashes . for a numerically stable scheme",
    "( throughout this paper , the term _ numerical stability _ is used as equivalent to convergence , in the sense of lax s theorem ) this growth should go away with resolution , but very high resolutions are usually needed if one wants to keep these errors under control by just adding more points to the simulation . therefore this procedure is not practical and it might not be even feasible .",
    "sometimes it happens there are no growing modes at the continuum , but the discretization one is using , even if numerically stable , can introduce errors that grow quickly in time .",
    "examples of this potential source of instabilities are shown in ref .",
    "@xcite ; it is there also explained how to rearrange the semidiscrete equations in order to prevent this when there is a `` conserved '' quantity at the continuum ( for example , in the case of wave propagation on a stationary spacetime the physical energy would play this role ) .",
    "the picture that has emerged in other cases is that rapidly growing discrete constraint violating modes are numerical excitations of unstable continuum modes . in other words , solutions of einstein s evolution equations that are initially slightly off the constraint surface , but then deviate from it very quickly .",
    "the standard approach is then to seek formulations that are as stable as possible under continuum constraint violations .",
    "a trivial observation here is that when rapidly growing discrete constraint violations appear it is because the given numerical method allows for them .",
    "therefore , i argue that it is desirable to control the _ discretized _ constraints , taking into account possible growth introduced both by the formulation of the equations , _ and _ by the numerical method .",
    "the purpose of this paper is to present a method for doing so .    as one is interested in solutions that satisfy the constraints ,",
    "the einstein evolution equations can be written in infinitely different ways by changing the system s behavior off of the constraint surface .",
    "for definiteness i will now concentrate on first order ( both in space and time ) formulations , though the ideas of this paper clearly do not depend on this and can be applied to second order formulations as well .",
    "beginning with any formulation , e.g. a symmetric hyperbolic one , one can add to the right hand side ( rhs ) terms proportional to the constraints .",
    "that is @xmath0 where @xmath1 and @xmath2 are a vector valued functions ( containing the metric and related variables ) , @xmath3 with @xmath4 , is a vector valued constraint ( containing the hamiltonian , momentum , and perhaps other non - physical constraints that appear as integrability conditions when the system is written in first order form ) , and @xmath5 are matrix - valued functions .",
    "the constraints ( [ constraints ] ) in einstein s equations are quasilinear .",
    "that is , nonlinear in the field variables @xmath2 , but linear in the spatial derivatives , @xmath6 . adding the constraints in a linear way , as in equation ( [ linearc ] ) , yields a quasilinear system of hyperbolic partial differential equations , for which many results from the mathematical literature apply .    the freedom in choosing @xmath7 was originally used to cast einstein s equations in symmetric hyperbolic form , later to obtain `` physical '' characteristic speeds ( see @xcite for reviews ) , and more recently to improve the stability properties of formulations around fixed backgrounds ( the number of papers in the area is too large to be reviewed here ; see @xcite and references therein ) .",
    "typically @xmath7 is chosen as a constant matrix ; however , it does not appear to be the most effective way of controlling deviations off the constraint surface in a generic case for two reasons : i ) some information about the solution ( typically , the assumption that it will be close -or actually identical - to some known background ) is usually needed in order to choose an optimal @xmath7 .",
    "however , this kind of information will generically not be available .",
    "ii ) in principle , constants do not seem the best way to control varying fields .",
    "choosing constant values for @xmath7 seems to be favored for historical reasons , and it is actually not required .",
    "symmetric hyperbolicity and physical characteristic speeds , for example , can be achieved even if using functions of spacetime , provided they are a priori given .",
    "see @xcite for one example .",
    "consider the constraints @xmath8 , where the operator @xmath9 may be either a continuum or discrete derivative . later",
    "@xmath9 will represent discrete derivatives , since the motivation is to control not only continuum constraint violations , but also violations that arise in the discrete equations . for any slicing of spacetime @xmath10 , define a norm @xmath11 for the constraints .",
    "note i will always refer to this norm , not the norm associated with the main field variables ( will comment on this in the last section ) . for simplicity",
    "i choose the @xmath12 norm , @xmath13 where integration is on the spatial hypersurface @xmath14 .",
    "one wants this norm either not to grow during an evolution , or least to grow as slowly as possible .",
    "as @xmath15 is a function of the field variables , any solution to the evolution equations automatically determines the rate growth for @xmath16 , independent of whether one is considering the fully discrete , semidiscrete or continuum systems .",
    "i will concentrate on the last two cases ( i.e. , with continuous time ) . in principle",
    "the dependence of @xmath16 on the evolution equations is complicated .",
    "however , given that @xmath17 is added linearly to the right hand side of the evolution equations , as in eq.[linearc ] , the time derivative of @xmath16 can be written as @xmath18\\end{aligned}\\ ] ] using the evolution equations eq.([linearc ] ) and allowing @xmath17 to depend only on time ( not on space ) , the time derivative of the norm can then be written as @xmath19 where @xmath20 \\times   \\nonumber \\\\ & &   \\left[\\sum_l(a^ld_lu_j ) + b_j\\right ]   \\label{split1 }   \\\\ i^{(2)}_{jl } & = & \\int \\sum_{i } c_i\\left[\\frac{\\partial c_i}{\\partial u_j}+ \\sum_k\\frac{\\partial c_i}{\\partial d_k u_j}d_k \\right]c_l \\label{split2}\\end{aligned}\\ ] ] the quantities @xmath21 depend only on time , in the case of @xmath7 by assumption and in the others because spatial integration is carried out .",
    "the splitting ( [ split ] ) is a crucial step in the method presented here , since one gains analytical control on the norm growth as a function of @xmath7 .",
    "more explicitly : @xmath22 is a linear function of @xmath7 ( because the constraints are added linearly to the evolution equations ) .",
    "the idea now is to choose @xmath7 such that @xmath22 has some desired behavior within the freedom allowed by a given formulation of the evolution equations . as a simple example , consider a single scalar equation .",
    "one could choose @xmath23 by defining @xmath24 . or one could choose the norm to decay at a constant or exponential rate by defining @xmath25 or @xmath26 , respectively , with @xmath27 some constant . on the other hand ,",
    "if the different components of the @xmath7 matrix are restricted to some sets ( this is a restriction that appears quite often when requiring symmetric hyperbolicity , physical characteristic speeds , or both ) one could define @xmath28 as the one that gives the `` smallest '' growth of @xmath29 in those sets , etc .",
    "this could be done at the continuum . however , the problem is that @xmath7 would then depend on the constraints , which in turn depend on the derivatives of the field variables . as a consequence ,",
    "the resulting evolution equations would not be quasilinear , and it is far from clear that they would define a well posed initial , or initial - boundary , value problem . indeed , in section iv",
    "i present numerical evidence that strongly suggests that the resulting system would be ill posed .",
    "therefore , i propose to define @xmath17 through a single resolution run and interpolate the obtained discrete function in order to have it defined at all times . in an actual computation",
    "one would choose a fixed resolution and dynamically compute @xmath30 and thus a @xmath7 that gives the desired norm behavior , making sure that the resulting @xmath28 is within the range allowed by symmetric hyperbolicity ( symmetric hyperbolicity is not a requirement of the method , but ensures well posedness of the initial - boundary value problem , provided appropriate boundary conditions are given ) . in order to ensure numerical stability this @xmath17 matrix valued function",
    "has to be kept fixed at other resolutions .",
    "@xmath7 will depend on the original resolution used to define it , but this is not a problem .",
    "the important thing is to keep the constraints under control for a given resolution .",
    "they will also remain under control for better resolutions if one is in the convergence regime .",
    "@xmath17 will also depend on the given problem of interest , and on the numerical method used to solve the equations .",
    "that is , for any chosen desired behaviour for @xmath31 , there will be one @xmath7 , and one well posed formulation of the problem for each physical situation one wants to solve for with a given numerical method .",
    "this is not a practical problem and , in fact , it seems difficult to find a formulation that has optimum stability properties for all possible solutions and all possible numerical methods .",
    "if possible , one might want the constraints norm growth to be identically zero at all times @xmath23 .",
    "a potential problem with this approach is that the resulting @xmath7 might have large values , rapid variations in time , or both .",
    "the resulting set of pde s would then be stiff , having equivalent short timescales , in which case a very small courant factor would be required . in the next section",
    "i show an example where this happens and argue that better results may be obtained by not enforcing @xmath23 .",
    "even if one has enough freedom to enforce @xmath23 , it appears that allowing @xmath16 for some fluctuations around the initial value gives evolutions with better stability .",
    "i now elaborate on one way of doing so , assuming one has enough freedom in @xmath7 .",
    "this approach is highly non unique , and many variations of the fundamental idea presented in this paper seem possible , and worth further exploration .",
    "if one chooses @xmath32 with @xmath33 , any violation in the constraints will decay exponentially @xmath34 choosing a constant @xmath35 makes the constraints decay for all times , i will discuss this in the last section . here",
    "i take a different approach .",
    "i choose a a tolerance value for the norm , @xmath36 , and solve for @xmath7 such that the constraints decay to this tolerance value after a given relaxation time .",
    "more precisely , i choose @xmath35 such that after time @xmath37 the constraints will have the value @xmath38 . replacing @xmath39 by @xmath38 in equation ( [ decay ] ) and",
    "solving for @xmath35 gives @xmath40 i now solve @xmath41 for @xmath7 .",
    "one solution ( non unique , since the equation is scalar and @xmath7 is a matrix ) is , assuming @xmath42 is invertible , and ommiting all the indexes , @xmath43^{-1}\\left(an_c + i^{(1)}\\right)}{\\dim{\\left[i^{(2)}\\right ] } } \\ ; , \\label{mu}\\ ] ] with @xmath44 given by eq.([a ] ) .",
    "thus , for any value of @xmath16 at time @xmath45 , at time @xmath46 the value will be @xmath38 . later in this paper @xmath47",
    "will be the discrete time step and , in particular , if @xmath48=1 , then @xmath36 at each time step .",
    "it must be emphasized that these results hold in the semidiscrete case .",
    "i.e. , for _ any _ - not necessarily high - spatial resolution .",
    "but since time has been assumed continuous , the courant factor must be such that the fully discrete simulation faithfully represents the above semidiscrete calculations ( another option would be to perform a fully discrete analysis ) . in the next section i present some numerical experiments to study , among other issues , the extent to which the fully discrete system represents the semidiscrete analysis .",
    "as we will see , at least in the examples here considered , standard values of the courant factor already yield good results .",
    "in these numerical experiments i use the method of lines and finite differencing .",
    "the difference operator chosen is the simplest one that satisfies summation by parts ( second order in the interior , and first order in the boundaries ) , numerical dissipation is introduced taken into account modifications at boundaries , and third order runge kutta is used as time integrator ( see @xcite ) .",
    "i use the standard adm equations in spherical symmetry with the exact lapse - area locking choices for the lapse and shift @xcite to illustrate and study the method presented here .",
    "this choice of lapse and shift amounts to specifying in an arbitrary , but a priori , way the lapse as a function of spacetime , and the shift as @xmath49 .",
    "this choice of shift implies that the radial area does not change in time , @xmath50 , and one can choose @xmath51 as a coordinate . the 3-metric and extrinsic curvature in coordinates @xmath52",
    "then take the form @xmath53 , @xmath54 .",
    "the evolution equations , with the product of the hamiltonian constraint and @xmath55 added to the time derivative of the @xmath56 equation , are @xmath57 \\label{adot}\\\\ % % % % % % % % % \\dot{k_a } & = & ( \\alpha ' r + 2\\alpha)a^{-3}r^{-1}a '   - a^{-2}\\alpha^ { '' } + \\nonumber \\\\   & & \\alpha\\left[rk_bk_a ' + k_a(k_a+2k_b ) \\right ] + \\mu h \\label{kadot }",
    "\\\\ % % % % % % % % % % % % \\dot{k_b } & = & \\alpha \\left(a^{-3}ra ' + rk_bk_b '   \\right ) -a^{-2}r^{-1}\\alpha ' + \\nonumber \\\\ & & \\alpha \\left[k_b(k_a+2k_b)+r^{-2}(1-a^{-2})\\right ] \\label{kbdot}\\end{aligned}\\ ] ] these equations constitute a strongly hyperbolic system , and the characteristic speeds are `` physical''(along the light cone or normal to the spatial hypersurfaces ) : @xmath58 , for any function @xmath59 .",
    "that is , the equations are strongly hyperbolic even for @xmath60 , i.e. , the standard adm equations in spherical symmetry with this choice of gauge are strongly hyperbolic .",
    "the hamiltonian and momentum constraints are , respectively , @xmath61 i perform these experiments with the painlev - gullstrand ( pg ) slicing of the schwarzschild black hole spacetime , @xmath62 @xmath63 this is a stationary , exact solution , of the evolution and constraint equations , ( [ adot],[kadot],[kbdot ] ) , and ( [ ham],[mom ] ) , respectively .    as boundary conditions i set the time derivative of the incoming characteristic modes to zero .",
    "this will define a well posed initial - boundary value problem but in general will violate the constraints .",
    "one possibility would be to derive constraint - preserving boundary conditions for this problem",
    ". however , this is not the purpose of this paper but , rather , to devise a mechanism to control the constraint growth having fixed , among other things , the boundary conditions .",
    "this is not meant to be a replacement for constraint - preserving boundary conditions but , instead , complementary to them .",
    "evolutions of the pg spacetime with equations ( [ adot],[kadot],[kbdot ] ) can give rise to errors that grow fast in time , even with a stable numerical method .",
    "figure 1 shows @xmath16 vs. time for evolutions of pg initial data , at different resolutions .",
    "typical numerical parameters are chosen : courant factor @xmath64 , inner and outer boundaries at @xmath65 , respectively , and dissipation parameter @xmath66 .",
    "the constraints converge to zero with resolution , but at fixed resolution they grow very fast in time .",
    "this is not a peculiarity of this formulation and this numerical method but , indeed , is typical for free evolutions of einstein s equations in the strong field regime .",
    "one could attempt to modify the numerics in order to minimize the growth of the constraints , but i do not pursue this approach here .",
    "an interesting feature of the instabilities of the simulations shown in figure 1 is that the norm growth is initially negative , but it becomes positive after a single time step , triggering the instability , see ( [ fluc ] ) ( there , as in the rest of the paper , @xmath31 is computed through the semidiscrete expression ( [ split ] ) ) .",
    "@xmath67    a static choice of @xmath7 can not account for these fluctuations . in particular , choosing @xmath7 using only the growth rate around the background solution , which in this case would be the initial data , and not the errors introduced during numerical integration , in general will not be able to correct these kind of fluctuations in @xmath31 .",
    "i now discuss some numerical experiments using a dynamically calculated @xmath28 such that @xmath68 in the semidiscrete case . for a chosen resolution",
    ", @xmath7 is defined at each time step by @xmath69 and @xmath70 is in turn used to compute the rhs needed to advance @xmath71 .",
    "figure [ strict_energy ] shows the resulting norm as a function of time , for evolutions enforcing @xmath23 at different resolutions .",
    "the code blows up rather fast , and this happens at earlier times when resolution is increased .",
    "this last feature should not be seen as an indication of ill - posedness of the method , since figure [ strict_energy ] should _ not _ be seen as a convergence test .",
    "for such a test one should dynamically define @xmath28 with a given resolution and then keep that @xmath7 fixed for all other runs .",
    "figure [ strict_convergence ] shows the result of doing so , defining @xmath28 through a run with @xmath72 and then keeping it fixed for a convergence test .",
    "is obtained for the coarsest resolution used in the convergence test , some interpolation procedure is needed in order to have this function defined at intermediate time steps .",
    "the simple procedure i have followed here is to define the needed intermediate values of @xmath7 between time steps @xmath73 and @xmath74 just as @xmath75 , though better ( e.g. trigonometric ) interpolation could be used .",
    "another option would be to define @xmath7 through the finest resolution that is going to be used for the convergence test and later coarsen the obtained discrete @xmath7 function . ] as expected , and in contrast to figure [ strict_energy ] , the norm does decrease as the resolution is increased .",
    "figure [ strict_energy ] strongly suggests that if one insisted in dynamically defining @xmath7 at each resolution , instead of fixing it at a single resolution , one would end up with an ill - posed problem . on the other hand",
    ", fixing @xmath7 leads to a strongly hyperbolic problem and no convergence problems appear .",
    "considering these runs with @xmath23 , it appears that enforcing semidiscrete norm preservation is `` too rigid '' ( recall the discussion at the beginning of section iii ) .",
    "figure [ strict_mu ] shows the @xmath7 functions obtained through the runs of figure [ strict_energy ] .",
    "notice that when increasing resolution the @xmath7 that is needed in order to preserve the norm increases quite fast in absolute value .",
    "for example , with @xmath76 the initial values of @xmath7 are of order @xmath77 .",
    "since @xmath7 appears in the principal part of the equations , having a large value implies the need of a small courant factor to follow the simulation ; while figures [ strict_energy ] and [ strict_mu ] , on the other hand , where obtained using the same courant factor when changing resolution . a fourier decomposition of the numerical solution , or an explicit von - neumann analysis of a linear , constant coefficient problem could give further insight into this question .",
    "a second possibility would be to perform a fully discrete analysis ( as opposed to the semidiscrete one used in this paper ) , and to enforce strict conservation of the fully discrete norm , but these issues are not pursued here .",
    "i now set a tolerance value @xmath38 , and choose @xmath7 such that @xmath36 after a given number of timesteps .",
    "in doing so i use the semidiscrete expressions ( [ a],[mu ] ) . if @xmath42 is zero , @xmath7 will be copied from its previous value , or set to zero if this happens in the first iteration .",
    "figure [ mu_conv ] shows results with a dynamically defined @xmath7 , using the same resolution , domain , courant and dissipation factors as before .",
    "@xmath48 is chosen to be one , corresponding to the norm returning to the specified tolerance value after every time step .",
    "the discretized constraints are , of course , not zero initially , even when the initial data is analytic , because computing them involves finite differencing the initial data .",
    "the initial value for the norm for this resolution is @xmath78 .",
    "therefore i choose a tolerance value @xmath79 , to keep the constraints close to its initial value .",
    "figure [ convergence ] shows the resulting norms for a convergence test performed with the same resolutions used in figure [ unstable ] , and the @xmath7 shown in figure [ mu_conv ] .",
    "the code runs for @xmath80 without any sign of instabilities , even with the coarse resolution that was used to define @xmath7 .",
    "it could happen that one controls the constraints at the price of introducing other errors .",
    "this does not happen , at least in the numerical experiments here considered . in these experiments , not only does the norm associated with the constraints remains close to its initial , truncation value , but the same happens with the norm associated with the main field variables , @xmath81 .",
    "since the exact solution is stationary , @xmath82 being close to its initial value means that the method does not introduce new errors .",
    "figure [ norms2 ] shows @xmath83 and @xmath84 for the run used to define @xmath7 .      in the previous examples i chose the tolerance value , @xmath38 , to be roughly the initial , truncation error for @xmath16 .",
    "although this seems the natural thing to do , i will now discuss sensitivity of the stability method with respect to the chosen value of @xmath38 .",
    "figure [ fenergy ] shows results when choosing different tolerance values to define @xmath7 , but keeping all other numerical parameters ( in particular , the resolution , i.e. figure [ fenergy ] _ is not _ a convergence test ) fixed . when @xmath38 is much larger than the initial truncation value of @xmath16 , large errors allow triggering of nonlinear instabilities . on the other hand , values of @xmath38 considerably smaller than the initial truncation one forces @xmath7 to change very fast , and to large values . in either case",
    "the code crashes .",
    "the @xmath7 functions for two such cases are shown in figure [ mu_bad ] .",
    "figure [ energy_zoom ] shows the details of figure [ fenergy ] near @xmath85 .",
    "notice that not only all the runs begin with the same ( truncation ) value for @xmath16 ( this is expected , since the same resolution is used ) , but @xmath16 is also the same in the very first timestep .",
    "the reason for this is that @xmath60 initially for all the runs , because @xmath86 in the initial data . this is a coincidence of the initial data being evolved in this example : the only discretization error in the computation of the hamiltonian constraint in this model comes from the finite differencing of @xmath35 , which in this example is initially @xmath87 for all grid points .      as a final numerical example , now i consider initial data that violates the constraints at the continuum .",
    "the equations still use the exact lapse and area - locking shift given by eq.([gauge ] ) , but now the initial data are given by @xmath88 when @xmath89 , this data reduces to that of the pg black hole .",
    "the constants @xmath90 are used to introduce an `` asymmetry '' in the perturbations of the pg initial data .",
    "the perturbations are rather large , with @xmath91 or order unity . in this example , @xmath92 .",
    "when @xmath93 the code crashes before @xmath94 at a resolution @xmath95 . at this resolution @xmath16 for the initial data",
    "is @xmath96 ( one order of magnitude larger than the associated truncation error for the case @xmath89 , which for this resolution is @xmath97 ) .",
    "thus , i choose a tolerance value of @xmath98 , @xmath99 in order to avoid fast variations , and rerun , dynamically obtaining @xmath28 .",
    "results for the unmodified equations ( @xmath60 ) , and with a dynamical @xmath7 are shown in figures [ violation ] , [ violation_mu ] .",
    "the difference in stability is quite striking , especially considering that the perturbation of the pg initial data is so large .",
    "there is a lot of interest in finding formulations of einstein s equations with good stability properties off of the constraint surface . so far , most , if not all , of the work has been concentrated in stability properties around known solutions .",
    "the purpose of this paper has been to introduce new ideas that hopefully will be helpful in generic evolutions , where one has no a priori knowledge of the solution .",
    "this is one fundamental difference with previous approaches .",
    "another difference is that previous work has concentrated on stability properties at the continuum .",
    "although this is an important issue , controlling constraint violating modes introduced by the numerical method is also crucial .",
    "thus , this proposal aims to control discrete constraint violations introduced both by the underlying formulation of equations at the continuum , and whatever numerical method one has chosen .",
    "sometimes it seems that one would ideally want the constraints to decay exponentially to zero @xcite,@xcite .",
    "although this might be attractive at the continuum , in what concerns the discrete constraints it might be better to maintain them around the initial , truncation error . for example , beginning with initial data corresponding to a stationary spacetime , it seems difficult to imagine that by making the constraints decrease in time through numerical integration ( keeping resolution fixed ) , one would end up with a numerical solution that has smaller errors than the initial data , which was computed by just numerically evaluating the exact solution at given gridpoints .",
    "thus , i have concentrated here on keeping the discrete constraints at some tolerance value , instead of forcing them to decay to zero",
    ". however , there may be other scenarios where it is preferable to make them decay to values smaller than the initial one , and the method here presented allows for this as well .",
    "along these lines , an extension of the work presented here is to use the evolution equations applied to initial data off the constraint surface to produce solutions of the constraints as an alternative to relaxing the constraints themselves .    in some other approaches @xcite ,",
    "a norm for the main variables , say @xmath100 , is minimized with respect to constraint violating perturbations ( around a given , known background ) .",
    "i could have here chosen to dynamically minimize this quantity .",
    "one potential problem with this is that it is not clear how much minimization makes the solution closer to the `` exact '' one .",
    "for example , in the spherically symmetric example here considered the time derivative of the norm for the main variables has the form @xmath101 since @xmath7 is completely free in this model , one is able to make @xmath102 , for some chosen but arbitrary resolution , as negative as one wants .",
    "what happens then is that all the field variables decay to zero ( numerical experiments that i have done do confirm this ) .",
    "clearly this is not what one wants , since the `` exact '' solution is not identically zero . on the other hand , one could also attempt to keep @xmath82 close to its initial , truncation value .",
    "however , this would be a good idea only if the solution is stationary , since otherwise there is no reason for the exact @xmath84 to be close to @xmath103 for all times .",
    "thus i have here considered a norm associated with the constraints , since they are analytically zero , regardless of the solution .",
    "i would like to thank oscar bruno , gioel calabrese , luis lehner , david neilsen , jorge pullin , oscar reula , olivier sarbach , ed seidel and jonathan thornburg for very helpful discussions , comments and suggestions .",
    "this work was supported in part by nsf grant phy9800973 , the horace hearne jr .",
    "institute for theoretical physics , and fundacin antorchas .",
    "g. calabrese and o. sarbach , gr - qc/0303040 ; b. szilagyi and j. winicour , gr - qc/0205044 ; b. szilagyi , b. schmidt , and j. winicour , phys . rev .",
    "d * 65 * , 064015 ( 2002 ) ; g. calabrese , j. pullin , o. reula , o. sarbach , and m. tiglio , gr - qc/0209017 , to appear in communications in mathematical physics ; g. calabrese , l. lehner , and m. tiglio , phys .",
    "d * 65 * , 104031 ( 2002 ) ; j. m. stewart , class .",
    "quantum grav . * 15 * , 2865 ( 1998 ) .",
    "h. friedrich and a. rendall , in _",
    "einstein s field equations and their physical implications , lecture notes in physics _ , edited by b. g. schmidt ( springer verlag , berlin , 2000 ) , p. 127 - 223 ; o.",
    "reula , living rev . rel . * 1 * , 3 ( 1998 ) .",
    "b. kelly , p. laguna , k. lockitch , j. pullin , e. schnetter , d. shoemaker , and m. tiglio , phys .",
    "d * 64 * , 084013 ( 2001 ) ; l. lehner , m. huq , m. anderson , e. bonning , d. schaefer , r. matzner , phys .",
    "d * 62 * , 044037 ( 2000 ) ; d. garfinkle and c. gundlach , class .",
    "* 16 * , 4111 ( 1999 ) ."
  ],
  "abstract_text": [
    "<S> i present a new , simple method to dynamically control the growth of the discretized constraints during a free evolution of einstein s equations . during an evolution , any given family of formulations </S>",
    "<S> is adjusted off the constraints surface in a way such that , for any chosen numerical method and arbitrary but fixed resolution , the constraints growth can be minimized with respect to the freedom allowed by the formulation . in particular , provided there is enough freedom , the discretized constraints can be maintained close to its initial truncation value for all times , or decay from it .    </S>",
    "<S> no a priori knowledge of the solution is needed , and the method can be applied to any formulation of einstein s equations without affecting hyperbolicity . </S>",
    "<S> this method is independent of the numerical algorithm and accounts for constraint violating modes introduced both by continuum instabilities of the formulation and by the numerical method . </S>"
  ]
}