{
  "article_text": [
    "the study of the internal dynamics of stellar systems plays an essential role in astronomy . from the observed positions and velocities of the stars in galaxies and globular clusters it is possible to infer their total ( dark+luminous ) mass distribution , which , in particular , provides information on the presence and properties of dark halos and massive black holes . in turn",
    ", this structural knowledge constrains theories for the formation and evolution of these systems .",
    "the dynamical state of a stellar system is determined by its phase space distribution function , @xmath3 , which counts the stars as a function of position @xmath4 and velocity @xmath5 . typically , however , only three of the six phase - space coordinates are available observationally : the projected sky position @xmath6 , and the velocity @xmath7 along the line of sight ( los ) .",
    "proper motion observations can provide the additional velocities @xmath8 , but such data are generally not available ( with the notable exception of some galactic globular clusters ) . to make progress with the limited information available , the dynamical theorist is often forced to make simplifying assumptions about geometry ( e.g. , that the system is spherical ) or about the velocity distribution ( e.g. , that it is isotropic ) .",
    "such assumptions can have strong effects on the inferred mass distribution ( @xcite ) . to obtain the most accurate results",
    "it is therefore important to make models that are as general as possible .",
    "of particular importance for collisionless , unrelaxed systems such as galaxies is to constrain the velocity anisotropy using available data , rather than to assume it a priori .    in a collisionless system",
    "the distribution function satisfies the collisionless boltzmann equation .",
    "analytical methods to find solutions of this equation usually rely on the jeans theorem , which states that the distribution function must depend on the phase - space coordinates through integrals of motion ( quantities that are conserved along a stellar orbit ) . in a spherical system",
    "all integrals are known analytically , namely , the energy @xmath9 and the components of the angular momentum vector @xmath10 .",
    "analytical models for spherical systems are therefore fairly easily constructed . in an axisymmetric system things",
    "are more complicated ( e.g. , @xcite ) .",
    "only two integrals are known analytically , @xmath9 and the vertical component @xmath11 of the angular momentum vector denote the coordinates intrinsic to the axisymmetric stellar system , with the plane @xmath12 being the equatorial plane , and @xmath13 the symmetry axis .",
    "these relate via the inclination @xmath14 to the observable coordinates @xmath6 on the plane of the sky ( aligned , respectively , along the projected major and minor axes of the stellar system ) , and @xmath15 the line - of - sight direction , positive in the direction away from us .",
    "] , but there is generally a third integral for which no analytical expression exists .",
    "therefore , it is not generally possible to construct an axisymmetric model analytically .",
    "the special class of so - called ` two - integral ' ( @xmath16 ) models ( e.g. , @xcite ) has its uses ( e.g. , @xcite ) , but these have an isotropic velocity distribution in their meridional plane , which need not be a good fit to real dynamical systems .    the most practical way to model",
    "a general axisymmetric system is to do it numerically .",
    "while a few methods exist to do this ( e.g. , @xcite ) , the most common approach uses schwarzschild s ( 1979 ) method .",
    "one starts with a trial guess for the gravitational potential @xmath17 and then numerically calculates an orbit library that samples integral space in some complete and uniform way .",
    "the orbits are integrated for several hundred orbital periods , and the time - averaged intrinsic and projected properties ( density , los velocity , etc . )",
    "are stored as the integration progresses .",
    "the construction of a model consists of finding a weighted superposition of the orbits that : ( 1 ) reproduces the observed stellar or surface brightness distribution on the sky ; and ( 2 ) reproduces all available kinematical data to within the observational error bars .",
    "additional constraints can be added to enforce that the distribution function in phase space be smooth and reasonably well behaved , e.g. , through regularization or by requiring maximum entropy .",
    "several axisymmetric schwarzschild codes have been developed in the last decade ( e.g. , @xcite ) .",
    "these codes deal with the situation in which information on the line - of - sight velocity distribution ( losvd ) is available for a set of positions on the projected plane of the sky .",
    "this is the case , e.g. , when the kinematical data are from long - slit or integral - field spectroscopic observations of unresolved galaxies .",
    "the optimization problem for such data can be reduced to a linear matrix equation for which one needs to find the least - squares solution with non - negative weights @xcite .",
    "one dimension of the matrix corresponds to the number of orbits in the library , while the other corresponds to the number of ( luminosity , kinematical and regularization ) constraints that must be reproduced .",
    "both dimensions are typically in the range @xmath18@xmath19 .",
    "nonetheless , efficient numerical algorithms exist to find the solution , which yield the orbital and the velocity distribution of the model , as well as the @xmath20 of the fit to the kinematical data .",
    "the procedure must then be iterated with different gravitational potentials , to determine the potential that provides the overall best @xmath20 .",
    "the existing codes have been used and tested extensively ( e.g. , @xcite ) .",
    "some questions remain , e.g. , about the importance of smoothing in phase space , the exact meaning of the confidence regions determined using @xmath21 contours , and , in some situations , valid concerns have been raised regarding whether the available data contain enough information so as to warrant the conclusions of the schwarzschildmodeling @xcite .",
    "nevertheless , on the whole schwarzschild codes have now been established as an accurate and versatile tool to study a wide range of dynamical problems .",
    "a disadvantage of the existing codes is that they can not be easily applied to the large class of problems in which the kinematical observations come in the form of discrete velocity measurements , rather than as losvds .",
    "this is encountered , e.g. , when modeling the dynamics of galaxies at large radii , where the low - surface brightness prevents integrated - light spectroscopy .",
    "the only available data are then often of a discrete nature , e.g. , via the los velocities of individual stars in galaxies of the local group ( e.g. , @xcite ) , or via planetary nebulae ( e.g. , @xcite ) and globular clusters ( e.g. , @xcite ) surrounding giant ellipticals .",
    "the kinematical data available for clusters of galaxies , consisting of redshifts for individual galaxies , are of a similarly discrete nature ( e.g. , @xcite ) .",
    "the typical datasets in all these cases consist of tens to hundreds of los velocities .",
    "galactic globular clusters constitute another class of object for which kinematical data is often available only as discrete measurements , rather than in the form of losvds . from ground - based observations , data sets of individual los velocities",
    "can be available for up to thousands of stars in these systems ( e.g. , @xcite ) , and for @xmath22 cen it has been possible to assemble large samples of proper motions as well @xcite . with the capabilities of _ hst _ , accurate proper motion data sets with up to @xmath23 stars are now becoming available for several more galactic globular clusters ( e.g. , @xcite ) .",
    "note that discrete datasets do not necessarily provide better or worse information than datasets obtained from integrated - light measurements .",
    "both types of data have their advantages and disadvantages . for discrete datasets , for example",
    ", interloper contamination can be a problem ( see also the end of section  [ sec : logl ] below ) .",
    "by contrast , for integrated - light measurements , it is often difficult to constrain the wings of the losvd due to uncertainties associated with continuum subtraction .",
    "which type of data is most appropriate and most easily obtained depends on the specific object under study .",
    "this is therefore not a question that we address in this paper .",
    "instead , we focus on the issue of how to best analyze discrete data , if that happens to be what is available",
    ".    analyses of discrete datasets have often been more simplified than the analyses that are now common for integrated - light data .",
    "for example , the observations are analyzed using the jeans equations ( e.g. , @xcite ) , often with the help of data binning to calculate rotation velocity and velocity dispersion profiles ( see , however , the `` spherical '' schwarzschild models of m87 of @xcite ) .",
    "the disadvantage of such an approach is that not all the information content of the data is used , including information on deviations of the velocity histograms from a gaussian .",
    "such deviations are important because they constrain the velocity dispersion anisotropy of the system ( e.g. , @xcite ) .",
    "this anisotropy is an important ingredient in some existing controversies , e.g. regarding the presence of dark halos around elliptical galaxies @xcite .",
    "loss of information can be avoided when large numbers of datapoints are available , as is often the case for globular clusters .",
    "it is then possible to create velocity histograms for binned areas on the projected plane of the sky , after which analysis can be done with existing schwarzschild codes ( e.g. , @xcite ) .",
    "while this is possible for large datasets , such an approach is not viable for the more typical , smaller datasets that are often available .",
    "the availability of schwarzschild codes that can fully exploit the information content of such smaller datasets would therefore be valuable to advance this subject .",
    "motivated by these considerations we set out to adapt our existing schwarzschild code @xcite to deal with discrete datasets .",
    "this does not constitute a trivial change , since it changes the constrained superposition procedure from a linear matrix problem to a more complicated maximum likelihood one .",
    "for each observed velocity of a particle in the system the question becomes : what is the probability that this velocity would have been observed if the model is correct ?",
    "the overall likelihood of the data , given a trial model , is the product of these probabilities for all observations .",
    "such likelihood problems have previously been solved for spherical systems @xcite and the special class of axisymmetric @xmath24 systems @xcite . however , for the axisymmetric schwarzschild modeling approach the problem corresponds to finding the minimum of a function in a space with a dimension of @xmath18@xmath19 .",
    "we show in this work , via the schwarzschildmodeling of simulated datasets , that this problem can indeed be solved successfully and efficiently .",
    "moreover , we follow @xcite and implement in our new code the ability to calculate and fit proper motions in addition to los velocities .",
    "applications of the code to real datasets will be presented in forthcoming papers .",
    "the structure of the paper is as follows . in section [ sec : logl ]",
    "we phrase the new problem of fitting a schwarzschildmodel to a dataset of discrete velocities ( of one , two , or three dimensions ) of individual kinematic tracers in terms of a likelihood formalism .",
    "section [ sec : code ] describes the implementation of the discrete fitting procedure into our existing schwarzschildcode . at the same time , we summarize here the major steps involved in the construction of the probability matrix that describes the likelihood of a given kinematic data point belonging to some particular orbit of the library .",
    "we then present in section [ sec : tools ] sets of simulated data that we use for the purpose of testing the performance of the discrete schwarzschildcode .",
    "we also describe the known input distribution functions from which these data were drawn .",
    "the application of the code to the simulated datasets is presented in section [ sec : tests ] .",
    "we present a thorough analysis of the accuracy with which our discrete schwarzschildcode recovers the known distribution function , mass - to - light ratio and inclination used to generate the simulated data .",
    "finally , in section [ sec : end ] we summarize our findings and present our conclusions .",
    "in the schwarzschildscheme the properties of every orbit @xmath25 in the orbit library are computed and stored .",
    "the modeling consists in finding the superposition of orbital weights @xmath26 , i.e. , the fraction of particles in the system residing in each orbit , that best reproduces some set of constraints .",
    "the weights are written as squares to ensure that they never become negative .",
    "linear constraints are of the form @xmath27 here @xmath28 is a constraint value that needs to be reproduced , @xmath29 is its uncertainty , and @xmath30 is its model prediction @xmath31 the matrix @xmath32 represents here , for orbit @xmath25 , the probability distribution corresponding to the constraint @xmath33 .",
    "the constraints are generally one of the following : ( a ) the integrated light ( surface brightness ) of a stellar population in some aperture number in the projected plane of the sky , necessary to reproduce an observational measurement of the surface brightness ; ( b ) the mean los velocity , velocity dispersion , or for data of sufficient quality , a higher - order gauss - hermite moment in some aperture number in the projected plane of the sky , necessary to reproduce an observational measurement of the stellar kinematics ; ( c ) the integrated mass in some meridional @xmath34 plane grid point , necessary to provide a consistent model ; ( d ) a combination of distribution function moments in some meridional @xmath34 plane grid point , if a model with a particular dynamical structure is desired ( e.g. , one may want a model with @xmath35 equal to zero in order to simulate a two - integral @xmath24 model ) ; ( e ) a combination of orbit weights , if regularization constraints are desired to enforce smoothness of the model in phase space ( e.g. , one can set the n - th order divided difference of adjacent orbit weights to zero , with an uncertainty @xmath36 that measures the desired amount of smoothing ) .",
    "it is natural to choose the best - fitting model to be the one that produces the maximum likelihood . to determine the likelihood we need to write down an expression for the probability of measuring @xmath33 among all its possible values",
    ". to do this , we recall that any model is not an attempt to reproduce a set of observations to infinite accuracy , but instead to do it within the uncertainty @xmath37 . for observational constraints , such as those in ( a ) and ( b ) above , @xmath37 is equal to the measurement uncertainty . for other constraints , such as those in ( c)-(e ) above",
    ", @xmath37 can be used as a forcing parameter that compels how accurately the likelihood needs to peak around a particular value of @xmath33 . if one assumes that these uncertainties have a normal ( gaussian ) distribution , then the probability we are interested in is given by @xmath38 . \\ ] ] the combined probability for the simultaneous occurrence of all @xmath39 linear constraints is then given by the product of the single probabilities , @xmath40 .",
    "using equation ( [ eq.non.linear.term ] ) , the logarithm of this linear part of the likelihood is therefore    @xmath41    the first sum on the right - hand side of this expression does not depend on the orbital weights @xmath26 and , therefore , does not affect the likelihood maximization .",
    "the second term has the exact form of the @xmath20 statistic .",
    "maximizing the likelihood is therefore equivalent to the minimization of this @xmath20 .",
    "this can be done by finding the solution of the set of equations  ( [ eq.constraint ] ) and ( [ eq.gamma.def ] ) , which can be rewritten as an overdetermined matrix equation . this matrix equation can be solved with the use of standard non - negative least - squares ( nnls ) algorithms ( see @xcite for a detailed description ) .    in the case of discrete data",
    ", however , the introduction of constraints of a `` non - linear '' type is inevitable in order to adequately exploit the entire information content available , avoiding restrictive simplifications and loss of information due to binning .",
    "this occurs because the individual probabilities do not necessarily have the simple , gaussian form of equation ( [ eq.non.linear.term ] ) .",
    "the procedure for finding the maximum likelihood then can not be cast as the solution of a linear matrix equation anymore .",
    "suppose we have a kinematic dataset consisting of discrete measurements which we are trying to model using the schwarzschildtechnique .",
    "let @xmath42 be the phase - space probability distribution of any given orbit , properly averaged azimuthally , and normalized such that @xmath43 .",
    "we use @xmath44 to denote a vector of up to six euclidean spatial and velocity coordinates .",
    "whenever @xmath44 is shorter than 6 elements , it is understood that the distribution has been marginalized over the missing dimensions .",
    "then the total probability of drawing a particle from a superposition of orbits representing the whole system is @xmath45    we now need to consider the total probability of the ensemble of @xmath46 particles with kinematic information that constitute our discrete dataset . before this , however , it is necessary to make the distinction , in the language of probabilities , between the possible modes of sampling of the tracers available in a system of particles .",
    "the two main possibilities depend on whether the particles are randomly or non - randomly drawn from their spatial distribution , and we may refer to these , respectively , as random positional sampling and incomplete positional sampling . additionally , particles may be drawn with or without velocity information , thus adding up to a total of four possibilities .",
    "the case with incomplete positional sampling and no velocity information , however , does not provide any useful constraint to the analysis and therefore we restrict the discussion to the remaining three cases .    for particles drawn randomly from the spatial distribution with no velocity information ,",
    "the probability @xmath47 is    @xmath48    where * r * represents a 2 or 3 dimensional position .",
    "this type of dataset could result from imaging of the resolved populations of a stellar system , where the positional information could be used as actual constraints .",
    "this would force the model to fit the underlying spatial distribution of discrete tracers , instead of making use of a parametrization of the ( continuous ) brightness profile of the system .",
    "of course , a dataset without velocity information can not by itself constrain the dynamical state or the mass of the system .    in the case of random positional sampling",
    "including velocity information , particles are randomly drawn from both the spatial and velocity distributions . in this case , @xmath47 has the form    @xmath49    where @xmath50 is the same as above and @xmath51 represents a general 1 , 2 , or 3 dimensional velocity",
    ". this would be the case when being able to obtain the velocities of particles in a given field without introducing any spatial or velocity bias , such as the proper motions of all stars ( brighter than some magnitude limit ) in a sufficiently sparse stellar cluster , or when los velocities are obtained for a complete ( or possibly magnitude - limited ) set of globular clusters or planetary nebulae in a galaxy .",
    "in contrast , having _ incomplete _ positional sampling means that the particles are drawn from a velocity distribution , with _ a priori _ fixed positions .",
    "this can occur , for example , when because of the usually limited availability of telescope time and resources , los velocities are measured only for stars within some distance from the photometric major or minor axes of a galaxy , or when because of the finite size of fibers in a fiber - fed spectrograph , not all the potentially observable kinematic tracers in the field can be actually acquired .",
    "incomplete positional sampling also arises when , even though particles can be randomly drawn spatially , this is the case only for a limited area .",
    "this occurs , for example , when the observations have to avoid the innermost regions of a galaxy or globular cluster , where , because of crowding , stars can not be individually resolved . in these case",
    ", @xmath47 has the form    @xmath52    where , rather than just @xmath26 , the effective weights when summing together the individual orbital distributions are @xmath53 .",
    "once the individual probabilities for all possible cases of spatial sampling that comprise the data have been properly assigned , we can proceed to the construction of the total probability of observing the entire dataset .",
    "let @xmath54 and @xmath55 be the number of observational data points obtained under the mode of random positional sampling without and with velocity information , respectively , and @xmath56 the number of data points obtained with incomplete positional sampling with kinematic information .",
    "then , the total probability is simply the product of the individual probabilities , with logarithm given by @xmath57 .",
    "using equations ( [ eq.prob.r ] ) to ( [ eq.prob.rfix ] ) , and adopting the abbreviated notation @xmath58 , @xmath59 , and @xmath60 ( all known for each orbit @xmath25 and particle @xmath14 from the orbit library calculation ; see  3 ) , the quantity to maximize becomes @xmath61 joining the results in equations ( [ eq : loglinear ] ) and ( [ eq.total.likelihood.1 ] ) , the complete log - likelihood for a general application of the schwarzschildmethod , which is the full expression to be maximized with respect to the orbital weights @xmath62 , is the sum of the log - likelihoods for linear and discrete constraints @xmath63 finding the maximum likelihood corresponds to finding the solution of @xmath64 = 0 , for all @xmath65 . denoting @xmath66 ,",
    "the expression for the first derivative is @xmath67    one important question that remains is regarding the estimation of confidence regions around the parameters of the best - fitting model , i.e. , the ( statistical ) uncertainties around the likelihood maximum in the case of non - linear constraints . recalling that maximizing @xmath68 is equivalent to minimizing the quantity @xmath69 , it is easy to realize that , if the probabilities involved in equation ( [ eq.total.likelihood.1 ] ) were all of gaussian form , then @xmath70 would simply reduce to the well known @xmath20 statistic , as we have already seen for the case with linear constraints in equation ( [ eq : loglinear ] ) .",
    "when dealing with non - linear constraints , however , the likelihood does not reduce to a simple @xmath20 form .",
    "nevertheless , one still can use another well known theorem of statistics which , used before by @xcite and @xcite , states that the `` likelihood - ratio '' statistic @xmath71 does tend to a @xmath20 statistic in the limit of large @xmath46 , with the number of degrees of freedom equal to the number of free parameters that have not yet been varied and chosen so as to optimize the fit .",
    "therefore , the likelihood - ratio statistic reduces to the @xmath72 statistic for @xmath73 , even though the probabilities in equation ( [ eq.total.likelihood.1 ] ) are not all individually gaussian .",
    "since in the present work we explore datasets consisting of 100 kinematic measurements or more , the condition of large @xmath46 should be reasonably fulfilled .",
    "therefore , following the likelihood - ratio statistic , we assume @xmath74 , and compute the confidence regions around the best - fit parameters in the usual way ( e.g. , @xcite ) , i.e. , with the @xmath75 error for a single parameter corresponding to wherever @xmath76 , and so forth . other approaches to quantify the uncertainties exist as well , e.g. , using bayesian statistics , but these are generally more difficult to implement ( e.g. , @xcite ) .",
    "the equations described above assume that any possible `` interloper '' contaminants have already been removed , and that the targets with observed velocities that enter the likelihood equations all belong to the system under study . for realistic datasets , contamination by interlopers can certainly be a problem @xcite ; i.e. , targets that happen to lie close to the line - of - sight of the stellar system under study and are difficult to reject from the sample .",
    "however , efficient interloper rejection schemes do exist for various types of samples and these have been well - described in the literature @xcite .",
    "moreover , the use of empirically - calibrated selection criteria ( independent of the measured velocity ) can produce extraordinarily clean samples for kinematic analysis @xcite .",
    "either way , interloper rejection is best discussed in the context of specific data sets .",
    "we therefore do not discuss it further in the present paper .",
    "interloper rejection for discrete data sets can also be built in as part of the likelihood analysis @xcite , so a simple modification of the likelihood equations given above could deal with interlopers explicitly .",
    "however , we have not yet explored this in the present context .",
    "given equations ( [ eq.logl ] ) and ( [ eq.1st.deriv ] ) , fitting a schwarzschildmodel to the data requires the following two steps : ( a ) determination of all the individual probabilities @xmath77 and matrix elements @xmath32 , so that the only unknowns in equation ( [ eq.1st.deriv ] ) are the coefficients @xmath78 ; and ( b ) performing the maximization of the total likelihood ,",
    "i.e. , finding the set of orbital weights @xmath78 that satisfies @xmath64 = 0 , for all @xmath65 , and therefore best fits the available constraints .",
    "the elements of the matrix @xmath32 , corresponding to the linear constraints discussed in  [ sec : logl ] , are calculated in the same way as in the old ( continuous ) implementation of the code , and for them we refer to @xcite , @xcite and @xcite . in what follows",
    "we concentrate on the probabilities @xmath77 associated with the discrete treatment that is the subject of this work .",
    "the matrix elements @xmath77 in equation ( [ eq.1st.deriv ] ) , which keep track of the probability that orbit @xmath25 of the library would have produced the measurement @xmath14 of the dataset ( each @xmath25 corresponding to some combination of the three integrals of motion @xmath9 , @xmath79 , and @xmath1 ) , are stored as the orbit in question is being computed .",
    "that is , at every time step during the orbit integration , we check whether the position and velocity along the orbit is consistent with any of the observational datapoints . to accomplish this , it is necessary to implement some degree of _ smoothing _ , both in position and velocity space , since otherwise the probability of having a particle on an orbit at exactly the observed position and velocity would be infinitesimally small .    smoothing in the spatial coordinates",
    "is accomplished through the definition of an _ aperture _ around the position of each particle in the dataset , with the size of the aperture controlling the amount of smoothing .",
    "the optimal aperture size will be somewhat dependent on the sampling characteristics of the data .",
    "in general , apertures should not be too small , or otherwise few time steps during orbit integration will fall on any one of them .",
    "this would lead to large shot noise in the computed probabilities @xmath77 , unless the orbits are integrated for very long times .",
    "nor should the apertures be too large , so that information on the orbital structure of the model is not erased by excessive spatial smoothing .",
    "the choice of aperture shape is arbitrary and a matter of numerical convenience .",
    "we adopt square apertures as in previous implementations of the code ( long - slit observations naturally produce data for rectangular apertures ) , and set their sizes to a user - supplied fraction of @xmath80 , the radius in the projected plane at the aperture s position .    once the spatial apertures are defined , and every time the projected position along the orbit being integrated falls within an aperture , we need to keep track of whether the orbital velocity matches the observed velocity . in the old ( continuous ) implementation ,",
    "the losvd was computed and stored for every orbit @xmath25 at each aperture @xmath14 , with the size of the bins in the histogram determining the amount of smoothing in velocity space . in our discrete treatment of the problem , @xmath77 would simply be the histogram value for the bin that contains the observed velocity",
    ". a direct , though information ally incomplete , generalization of this implementation to kinematical data in three - dimensions would be to keep track of two additional histograms at each aperture to account for @xmath81 and @xmath82 .",
    "this has been done by @xcite and @xcite , who calculated moments of the three model velocity distributions and fitted them to those obtained from binning los and proper - motion observations of stars in @xmath22 cen and m15 , respectively ( note that these studies still handle the data in a continuous fashion , by reducing the initially discrete datasets to binned velocity distributions at a number of apertures on the sky , an approach only possible thanks to the very large number of stars with measured velocities in these systems ) .    while reproducing the three - dimensional mean velocities and dispersions of the stars in a stellar system",
    "is already an improvement over all previous implementations of the schwarzschildtechnique , doing so is nevertheless a simplification of the problem .",
    "the reason is that it implicitly assumes that the three velocity components are independent of each other , i.e. , it does not account for the fact that there is a velocity ellipsoid whose cross terms are , in the most general case , not identical to zero .",
    "the most complete treatment would be to store a cube with entries for all possible combinations of @xmath83 , and do this at each spatial aperture where there is kinematical data available .",
    "this implementation would be , however , expensive in terms of memory storage and , moreover , not absolutely necessary , simply because we are not interested in the entire probability cube .",
    "instead , we only need probabilities in the cases when the model velocities are close to the observed ones . thus , in the framework of velocity histograms or full velocity cubes , and because of the discrete nature of the data ,",
    "the large majority of the bins or entries would be filled with weights that do not affect the likelihood in equation ( [ eq.logl ] ) .",
    "therefore , we adopt an approach in which , instead of storing velocity histograms or cubes , every time an orbit @xmath25 passes through an aperture @xmath14 with kinematical data , we add a gaussian contribution to @xmath77 .",
    "this contribution is centered on the observed ( any - dimensional ) velocity and has a dispersion that reflects the measurement errors , and if desired , any amount of extra velocity smoothing .",
    "thus , denoting the actually measured components of the particle s velocity in aperture @xmath14 as @xmath84 and their associated uncertainties as @xmath85 , with @xmath86 corresponding to @xmath87 , @xmath88 , and @xmath89 , the multiplicative contribution @xmath90 to the probability has the form @xmath91},\\end{aligned}\\ ] ] where @xmath92 is the component @xmath93 of the velocity of a test particle on orbit @xmath25 .",
    "the quantity @xmath94 is the numerical smoothing assigned to velocity component @xmath93 .",
    "whenever a particular component @xmath93 of the velocity is not available , we set @xmath95 .",
    "finally , in order to account for the fact that we represent a continuous orbit by a discrete sequence of time steps , we weigh this gaussian factor by multiplying it by the timestep @xmath96 . therefore , for every orbit @xmath25 , and every time the orbit integration falls within an aperture , the probability is increased according to @xmath97 when the integration of orbit @xmath25 is done , the @xmath77 elements for all datapoints ( apertures ) are written to a file for later use by the algorithm that performs the maximization of the likelihood .    in most practical applications one can set @xmath98 , since the error bars @xmath85 on the data already provide sufficient natural smoothing for numerical efficiency .",
    "we do this throughout the rest of this paper . however , we note that there may be situations in which non - zero @xmath94 may be beneficial . for example , if the observational errors @xmath85 are much smaller than the velocity dispersions @xmath37 of the system .",
    "it then takes very long integrations to beat down the shot noise in the orbital distributions @xmath77 .",
    "addition of a numerical smoothing @xmath94 with @xmath99 can then speed up the calculations without affecting the accuracy of the results .",
    "the approach of equations ( [ eq.weights ] ) and ( [ eq.pij ] ) assumes that the errors @xmath85 for the different datapoints are uncorrelated .",
    "sometimes this is not true , as in the case of the proper motions of stars in the globular cluster @xmath22 cen , where relative rotation between the old photographic plates used in their derivation produce an artifact overall rotation of the cluster @xcite .",
    "if problems like these can not be removed before modeling , a more complicated treatment than the one described here will be necessary .",
    "the non - linear nature of the discrete problem addressed in this paper requires the use of a non - linear optimizer , and there is no guarantee of a unique optimum .",
    "after experimentation with various optimization algorithms , we settled on the toms 500 conjugate gradient optimizer of @xcite .",
    "this code uses the function value and gradient to optimize along successive vectors ( lines ) in the space of the orbital weights , choosing the optimization direction at every pass in a manner that attempts to minimize the number of such line minimizations needed ( see chapter 10 of @xcite for details on conjugate gradient methods ) .    in our code",
    ", we rely on the fact that the majority of orbits do not contribute to any particular linear constraint , or to the likelihood of any particular observational datum . in the notation of equation ( [ eq.1st.deriv ] ) , the linear constraints @xmath100 , and also the @xmath101 , are sparse matrices .",
    "accordingly , the code to evaluate the gradient in equation ( [ eq.1st.deriv ] ) is written to store and evaluate only non - zero terms of @xmath100 and @xmath102 , reducing the computational burden by a factor of four or five .    to evaluate convergence and estimate the proximity of our final likelihood maximum to the true ( possibly local ) maximum",
    ", we plot the magnitude of the improvement of the likelihood @xmath103 as a function of the number of function evaluations @xmath46 .",
    "see figure [ fig : mkfitin ] .",
    "we find that @xmath103 is well represented by an exponential relation @xmath104 , where @xmath105 .",
    "therefore , the future change in the likelihood if the optimizer were allowed to run forever would be @xmath106 , where @xmath107 is the current change in likelihood at step @xmath108 . in practice",
    ", we terminate the optimization at @xmath109 , so that we expect to be within an additive factor of @xmath110 of the true likelihood maximum .",
    "this typically occurs after a number @xmath111 of function evaluations .",
    "the final accuracy is merely linear in the exponential coefficient @xmath112 , so that this accuracy estimate should be reasonably robust .",
    "we ran a variety of tests in order to establish whether the algorithm has a tendency of finding local extrema as opposed to global ones .",
    "in particular , for some of the test cases to be discussed later in ",
    "[ sec : tests ] , we started the iterative algorithm from different initial conditions , to verify that the solutions thus obtained were always in ( statistical ) agreement . also , as will be shown in ",
    "[ sec : tests ] , we find that the algorithm recovers the properties of known input models with reasonable accuracy . while this does not prove that the schwarzschildcode can not end up in a local maximum , at least it shows that the code does not end up in ( potential ) local maxima that are far from the correct solution .    in practice",
    "we usually start the maximization procedure from a homogeneous set of initial mass weights .",
    "we also investigated whether the convergence to a solution can be sped up by starting the iterative process from initial conditions that may already be reasonably close to the final solution .",
    "for example , we ran tests starting from a set of weights corresponding to a two - integral df of the form @xmath24 that already fit the light ( surface brightness ) profile followed by the input data .",
    "such a solution is easily obtained as the nnls solution of a matrix equation .",
    "we found that the same final answer was reached in essentially the same number of iterations .",
    "in order to test the performance of our discrete schwarzschildcode , we generate sets of simulated data drawn from a known phase - space distribution function ( df ) .",
    "unlike the case of using actual observations of a real stellar system , this approach offers the advantage of unambiguously knowing in advance the input properties underlying the data , which an optimally - working code should be able to `` recover '' .",
    "it also provides flexibility by allowing the possibility of adapting the input data at will in order to test different aspects of the code (  [ sec : tests ] ) .",
    "we discuss here the construction of various sets of pseudo - data and the properties of the underlying models .",
    "our simulated input data are obtained from a set of @xmath24 dfs derived by @xcite , with the methodology for drawing n - body initial conditions from these dfs described in @xcite .",
    "the models have a constant mass - to - light ratio @xmath113 , and have neither a central black hole or extended dark halo .",
    "they provide good fits to available photometric and kinematic observations of the galaxy m32 over the radial range from @xmath114 arcsec . however , this property has no bearing on the present analysis .",
    "we only use the fact that there is a known df , and not that this df resembles any realistic stellar system .",
    "a two - integral @xmath24 df provides a useful test case ( see also @xcite , @xcite ) , and does not mean that the model results would be less valid for more general dfs . also , the use of a constant @xmath113 is motivated only to simplify the test environment .",
    "central black holes ( e.g. , @xcite ) and extended dark halos ( e.g. , @xcite ) can be easily implemented in any schwarzschildcode .",
    "the luminous mass density is assumed to be axisymmetric and is parameterized according to    @xmath115^{\\beta}[1+(m / c)^2]^{\\gamma},\\ ] ]    with @xmath116 . here",
    ", @xmath117 is the ( constant ) intrinsic axis ratio , related to the projected ( observed ) axis ratio @xmath118 via the inclination angle @xmath14 , @xmath119 .",
    "the parameters in equation ( [ eq : light ] ) are set to @xmath120 , @xmath121 , @xmath122 , @xmath123 , @xmath124 , @xmath125 , and @xmath126 , with the @xmath127-band luminosity density @xmath128@xmath129pc@xmath130 , and @xmath131 the mass - to - light ratio in the @xmath127-band and in solar units .",
    "the adopted distance is 0.7 mpc .",
    "the models share the property of appearing the same in projection on the sky , but correspond to different intrinsic axis ratios as determined by the inclination angle @xmath14 .",
    "the even part @xmath132 of the df @xmath24 is uniquely determined by the mass density @xmath133 ( e.g. , @xcite ) .",
    "to specify the odd part @xmath134 of the df we follow @xcite and write @xmath135,\\ ] ] with @xmath136 being the angular momentum of a circular orbit of energy @xmath9 in the equatorial plane ( @xmath137 ) , and the auxiliary function @xmath138 defined by @xmath139 &   \\mbox{$(u < 0)$}.   \\end{array}\\right.\\ ] ] the choice of the parameters @xmath140 and @xmath141 determines the degree of streaming of the dataset .",
    "these free parameters can have values in the ranges @xmath142 and @xmath143 , with @xmath140 controlling the fraction of stars in the equatorial plane with clock - wise rotation , and @xmath141 controlling the behavior of the stellar streaming with orbital shape .",
    "the family of functions @xmath138 is shown in figure 1 of @xcite",
    ". combinations of @xmath144 that fit data for m32 are also discussed in that paper . here",
    "we explore a variety of input datasets with different amounts of mean streaming and test the recovery of these properties by our discrete schwarzschildcode .",
    "we generated 6 different datasets to test our discrete schwarzschildcode .",
    "by dataset we mean a number of particle @xmath6 positions on the sky with corresponding proper motions @xmath145 and los velocities @xmath146 .",
    "for two chosen inclinations on the sky , @xmath147 and @xmath148 , we produced three datasets resembling systems with varying degrees of rotation : a non - streaming system ( @xmath149 and @xmath150 ) , a maximally - streaming system ( @xmath151 and @xmath152 ) , and a third system with intermediate streaming ( @xmath151 and @xmath153 ) .",
    "we label our different datasets as 90ns , 90is , and 90ms to indicate the non - streaming , intermediate - streaming , and maximally - streaming cases of @xmath147 , respectively .",
    "similarly , for the @xmath148 case , we have the 55ns , 55is , and 55ms datasets .",
    "the mass - to - light ratio used to generate the datasets is @xmath154 for @xmath147 and @xmath155 for @xmath148 , in units of @xmath156/@xmath157 .",
    "although we examined the performance of our schwarzschildcode with tests that involve all of the six simulated datasets introduced above , we chose to use the 55is dataset to show most of our results .",
    "figure [ fig : data55is ] shows some projections of the phase - space coordinates for the 55is dataset .      in order to quantitatively",
    "judge the performance of the three - integral schwarzschildcode , it is desirable to make a comparison between the properties of the input df ( i.e. , that from which the pseudo - data were obtained ) and those of the fitted df ( i.e. , that found as the solution to the fitting or minimization problem ) . it is important to note in this context that the direct output of our schwarzschildcode is not in the form of a proper df @xmath158 , but rather in the form of `` mass weights '' @xmath159 associated to each set of integrals of motion @xmath160 that uniquely define an orbit .",
    "the relation between the df and the orbital mass weights is through a volume element dependent on the three integrals and an integration over the 3-dimensional space associated to the particular orbit ( see @xcite for a detailed discussion ) .",
    "such a conversion can be done in schwarzschild codes ( e.g. , @xcite ) , but this is not necessary for the goals of the present paper .",
    "we therefore limit ourselves to the comparison between the input and the fitted orbital mass weight distributions , which from now on we denote by @xmath161 and @xmath162 , respectively .",
    "to validate the weights @xmath162 returned by the schwarzschildcode , we need to know the weights @xmath161 for the model df @xmath24 .",
    "this is not a simple problem in the absence of an analytic expression for @xmath1 .",
    "however , two related functions are more easily accessible .",
    "the first is @xmath163 , defined as the projection of @xmath161 over the @xmath164 plane ( i.e. , integrated over @xmath1 ) . having the means of drawing n - body initial conditions from the df @xcite , we know that the energy and z - component of the angular momentum of each particle are given by @xmath165 and @xmath166 , respectively .",
    "therefore , @xmath163 is easily obtained by binning a large n - body dataset @xmath167 in @xmath9 and @xmath79 .",
    "the second related function that is easily accessible is @xmath168 , the distribution of mass weights for an @xmath24 model of axial ratio @xmath117 and a power - law density profile with logarithmic slope @xmath70 in a spherical kepler potential .",
    "this function is calculated analytically in de bruijne et al .",
    "( 1996 ; their equation ( 38 ) ) , and has the form @xmath169.\\ ] ] here , @xmath70 is the logarithmic slope of the mass distribution and @xmath170 is a known function .",
    "the spherical kepler potential is of course only an accurate approximation to our model at asymptotically large radii .",
    "nonetheless , we can combine @xmath163 and @xmath168 to obtain a reasonable approximation for @xmath161 throughout the system , namely @xmath171 with @xmath172}{\\int j_{\\lambda}\\left[l_z / l_{z,{\\rm max}}(e),i_3\\right]{\\rm d } i_3}.\\ ] ] for @xmath70 we take the slope of the mass distribution of equation ( [ eq : light ] ) at @xmath173 , the radius of the circular orbit of energy @xmath9 in the equatorial plane @xmath174 .",
    "the function @xmath175 in equation ( [ eq : zetain ] ) is correct ( i.e. , reduces to @xmath176 ) when projected on the @xmath164 plane , and has approximately the correct distribution over @xmath1 at fixed @xmath177 .",
    "in this way , we construct sets of orbital mass weights for each of our 6 simulated datasets described in  [ sec : data ] .",
    "using all the kinematic ( pseudo ) datasets and their corresponding input dfs described in  [ sec : tools ] we now proceed to examine how accurately the discrete schwarzschildcode can recover the properties of the galaxy models used to generate the input datasets . by _ recovery _ we mean to determine how close or how far is the obtained solution from the known df , known mass - to - light ratio @xmath113 , and known inclination @xmath14 of the galaxy model corresponding to the simulated dataset that was provided as input to the code . at the same time",
    ", we investigate the reliability of the uncertainties provided by the code on each of these properties .    in the general case of modeling real observations of an actual stellar system , the true radial mass density profile is not known a priori and is typically described following some parameterization . since mass may not necessarily follow light , or may do so in some complicated way , different plausible mass models should be attempted , as well as allowing for possible variations of the mass - to - light ratio with position . for the purposes of the present tests , however , the underlying mass distribution is assumed to be perfectly known from equation ( [ eq : light ] ) , except for the value of @xmath113 .",
    "therefore , the assumed parameterization for the mass distribution is only a 1-parameter family , and includes the `` correct '' distribution @xmath178 . in applications to real data , higher - parameter families may be necessary , and there is no guarantee that any member of the family would provide a good approximation to the true underlying distribution .",
    "the results of our tests are examined via three different exercises , which can be performed on each of the 6 different input datasets , providing a good baseline to judge the performance of our discrete schwarzschildcode .",
    "first , we explore the recovery of the internal orbital structure of the input dataset ( i.e. , the input df , or more specifically , the input mass weights @xmath179 ) by feeding the code with the correct inclination and mass - to - light ratio @xmath113 (  [ sec : getdf ] ) .",
    "second , we fix the inclination to the correct value of the input dataset and study whether the code finds the minimum of the @xmath21 function at the correct value of @xmath113 (  [ sec : getml ] ) . and",
    "third , we explore grids of schwarzschildmodels with different ( @xmath14,@xmath113 ) combinations to study how well these two properties are recovered when they are both assumed unknown (  [ sec : grids ] ) .",
    "we run all the above exercises for various subsets of each of our 6 datasets in order to explore the results as a function of relevant observational variables , particularly the size of the input dataset and the type of kinematical constraints available ( i.e. , only los velocities , only proper motions , or the complete three - dimensional velocities ) .",
    "this adds even more elements for a thorough assessment of the code s performance .",
    "it also provides insights into the types of datasets that will be necessary to constrain @xmath14 or @xmath113 to some given uncertainty in realistic situations .",
    "our schwarzschildcode has the capability of computing and storing , during a single orbit integration , the orbital properties for a series of different values of @xmath113 .",
    "thus , during the construction of the orbit library , different values of @xmath113 are converted into a dimensionless factor @xmath180 that multiplies all our original velocities , thus with @xmath113 scaling simply as @xmath181 .",
    "we stress that this allows us to explore several values of @xmath113 while computing only one orbit library . in our tests ,",
    "we explore models for velocity factors in the range @xmath182 . given that our galaxy models with different inclinations have slightly different mass - to - light ratios @xmath131",
    ", the use of this dimensionless representation also facilitates the visualization of the results in  [ sec : getml ] and  [ sec : grids ] .",
    "the correct ( input ) value of @xmath113 is always at @xmath183 .      at each of its different steps ,",
    "the schwarzschildcode requires the user to specify several settings ( or dials ) that control a corresponding number of tasks and functions of the modeling procedure .",
    "here we list the settings that we use for our standard run .",
    "we concentrate on the settings that are new to the discrete implementation .",
    "all other settings that are needed to fit a schwarzschildmodel ( e.g. , the resolution and limits of the polar grids used to compute the gravitational potential @xmath17 ; the required numerical accuracies in the fitting of the mass in the meridional plane and/or the projected plane of the sky ; etc . )",
    "are identical to previous implementations of the code , so for those we refer to @xcite and @xcite .    at the heart of the schwarzschildmethod",
    "lies the generation of a comprehensive library of orbits that should be representative of all types of orbits possible in the gravitational potential under study .",
    "this is achieved by adequately sampling the ranges of values that the three integrals of motion @xmath160 can acquire , each set of values uniquely determining one possible orbit . in this work",
    "we build models using two libraries that only differ in their size .",
    "most of our runs consist of the generation of initial conditions and libraries with @xmath184 orbits , obtained by sampling the available integral space with 20 energies @xmath9 , 14 angular momenta @xmath79 ( 7 positive and 7 negative ) , and 7 third integrals @xmath1 . in order to study the dependency of the results on the size of the orbit library ,",
    "we also compute schwarzschildmodels using a much larger orbit library , with @xmath185 combinations of @xmath160 .",
    "the energy @xmath9 is sampled via the corresponding radius @xmath186 of the circular orbit of that energy ( that with maximum angular momentum ) in the equatorial plane @xmath174 .",
    "this radius is logarithmically sampled from a minimum value that we choose to be much smaller than the spatial resolution of the data , to a maximum value set much beyond the point at which most of the mass of the input distribution is actually encompassed .",
    "since totally unconstrained by the data , therefore , the few first and last energy bins will mostly be of no interest ( i.e. , no mass gets assigned to them in the process of optimization ) .",
    "the vertical component of the angular momentum , @xmath79 , is linearly sampled using the variable @xmath187 , where @xmath188 and @xmath189 is the angular momentum of the circular orbit with energy @xmath9 .",
    "while orbits with both positive and negative @xmath79 are included in the library , the latter need not be individually integrated because they are simply obtained by reversing the velocity vector at each point along the orbit .",
    "the third integral @xmath1 is sampled via an angle @xmath190 , where @xmath191 determines the position at which the `` thin tube '' orbit at the given @xmath177 touches its zero - velocity curve ( defined by the equation @xmath192 , where @xmath193 is the effective gravitational potential ; see @xcite for a detailed presentation ) .",
    "finally , in order to help alleviate the discrete nature of the numerical orbit library , some extra radial smoothing of the orbits is performed by randomly generating a small variation to the energy and computing and storing the contribution to the probabilities from the `` new '' orbit with integrals @xmath194 .",
    "it is possible to implement similar smoothing in @xmath79 and @xmath1 as well ( e.g. , @xcite ) , but we leave this for a future version of our code .",
    "this energy smoothing is repeated , at each timestep , for 7 random @xmath195 values .",
    "azimuthal averaging is also performed by randomly drawing 7 @xmath196 values at each timestep .    smoothing in phase - space",
    "is accomplished with the use of apertures (  [ sec : pij ] ) .",
    "the size of the ( squared - shaped ) spatial apertures are defined as a fraction of @xmath80 , the distance to the center of the stellar system in the projected plane , and we set this fraction to 10% . in velocity space , and for most practical applications ,",
    "the measurement errors @xmath85 themselves will provide sufficient `` natural '' smoothing for numerical purposes .",
    "thus , we set the factors @xmath94 in equation [ eq.weights ] to zero for all our tests ( see also discussion in ",
    "[ sec : pij ] ) . in practice ,",
    "the optimal value of @xmath94 will depend on the characteristics of the data ( particularly the size of the velocity errors ) as well as the stellar system under study .",
    "when dealing with actual data , therefore , at least a few different values should be tried in order to explore their impact on the results .",
    "additionally , the extra smoothing provided by @xmath94 can also be useful to explore the validity of the quoted errors in any given application .",
    "the uncertainties @xmath85 in the los velocities and/or proper motions are in practice determined by the details of the observations and , since obtained by different techniques ( spectroscopy versus astrometry ) , are of different size in general .",
    "furthermore , the uncertainties in the velocities tangential to the plane of the sky are affected by the uncertainty in the distance to the stellar system under study . here",
    ", however , since we deal with simulated data , we assume kinematical data of nowadays typical good quality , and simply set all these errors to a moderate and arbitrary value of @xmath197@xmath198 .",
    "the large majority of our tests were done on the simulated datasets as described in ",
    "[ sec : data ] _ without _ the addition of simulated observational errors ( i.e. , random gaussian deviates with dispersion @xmath85 ) .",
    "this simplification was made early on in our project , based on the fact that the velocity errors should not matter much as long they are much smaller than the average one - dimensional velocity dispersion of the system under study .",
    "however , we realized later that this does induce a slight bias in our estimated mass - to - light ratios .",
    "our typical simulated datasets have dispersions of 48.4@xmath198and 46.3@xmath198 , for the 55is and 90is cases , respectively .",
    "therefore , by not adding any random velocity errors , the one - dimensional velocity dispersion of the pseudo - data that we actually analyzed is too small by a factor @xmath199 . as a consequence of the virial theorem , it follows that we should expect to infer a mass - to - light ratio that is too small by a factor of @xmath200 , corresponding to about 2.2% and 2.4% for the 55is and 90is datasets , respectively . instead of rerunning all our calculations , which would have been computationally expensive , we therefore simply corrected for this bias _",
    "so when studying the recovery of the mass - to - light ratio in  [ sec : getml ] and  [ sec : grids ] , instead of comparing the inferred values to the value @xmath131 of the input model , we compare to the slightly smaller @xmath201 .",
    "this quantity is @xmath202 for @xmath203 and @xmath204 for @xmath205 .",
    "the sizes of currently existing kinematic datasets of discrete nature range from a few hundred datapoints ( red giants in local group dwarf galaxies , planetary nebulae in the outskirts of giant ellipticals ) to a few thousands ( stars in galactic globular clusters , systems of globular clusters around giant ellipticals ) .",
    "for our standard tests we adopt datasets with 1000 kinematic observational points , although we also study the consequences of studying datasets with sizes ranging from 100 to 2000 datapoints . in these tests ,",
    "the small-@xmath46 datasets are subsets of the largest dataset ( @xmath206 ) , which means that there will be some correlation between the results of experiments done as a function of the number of available observations .",
    "this approach , we note , is of no substantial difference than having all the datasets of different @xmath46 but within the same simulation to be completely disjoint . the progression with @xmath46",
    "should still follow the expected @xmath207 statistical - convergence behavior ( see fig .  [",
    "fig : errors_ml ] and  [ sec : getml ] ) .",
    "the generation of one of our smaller @xmath208 orbit libraries , simultaneously storing discrete probabilities for a set of 1000 observational points with both los velocities and proper motions , takes 2.5 hours on a 3.6 ghz , pentium 4 , 64-bit cpu with 2 gb memory .",
    "an additional 0.5 hours are needed to find the maximum likelihood fit to the data . in practice",
    ", these steps must be iterated over a grid of gravitational potential parameterizations .      in order to determine whether the best - fitting solution obtained by the discrete schwarzschildcode actually resembles the properties of the input data , we start by making detailed comparisons between the input and fitted dfs . to do this",
    ", we feed the code with the correct inclination and mass - to - light ratio @xmath113 used to generate the input datasets , and compare the fitted mass weights @xmath209 to those corresponding to the input data , @xmath161 , approximated using equation ( [ eq : zetain ] ) .",
    "we use datasets with 1000 los velocities and proper motions , and present results for both the small and big orbit libraries detailed in  [ sec : settings ] .",
    "the comparison is best achieved via the analysis of corresponding one- and two - dimensional projections of the cubes of mass weights @xmath162 and @xmath161 , obtained by integrating over two and one of the integrals of motion , respectively ( figs .",
    "[ fig:1dplots ] to [ fig:2dplot55is ] ) . also , we make comparisons of two - dimensional @xmath210 slices of both cubes at selected values of the energy ( fig . [",
    "fig : ebins55is ] ) . for al of these projections",
    "we quantify the agreement between fits and input data by computing the rms and median absolute deviation of the quantity @xmath211 , i.e. , the difference between fit and input mass weights normalized by the input mass weights .",
    "these statistics are listed for schwarzschildmodels run on all our input datasets in table 1 .",
    "since the rms can be biased disproportionately by a small number of large outliers , in our discussion below we use preferentially the median absolute residual .",
    "figure [ fig:1dplots ] shows , for the 55is case , the integrated mass weights as a function of each of the three integrals of motion , for both the input dataset and the discrete schwarzschildfit . inside the region actually constrained by kinematic data ( containing 99.83% of the total mass ) , the mean absolute deviations between the fitted and input distributions of mass weights are 3% , 16% , and 18% , for the integrated distributions as a function of @xmath9 , @xmath11 , and @xmath1 , respectively . as listed in table 1 , similar numbers are obtained for the other 5 simulated datasets , with the agreement between both distributions as a function of energy always better than 5% . as a function of @xmath79",
    ", the largest disagreement actually corresponds to the one shown in figure [ fig:1dplots ] , the 55is case .",
    "it goes down to 7% for our case of closest agreement , the case labeled 55ns .",
    "the net rotation inherent to the 55is dataset ( reflected in the middle panel by all the mass weights with positive @xmath79 being larger than those with negative @xmath79 ) is clearly reproduced by the schwarzschildfit . as a function of the third integral ,",
    "the median absolute deviation varies from 16% for the 55ns case to up to 25% for the 90ns case .",
    "note that , since we are showing orbital mass weights instead of the actual df , the @xmath1 distributions are not expected to be constant over @xmath1 , even though the input df underlying all simulated datasets is of the form @xmath24 .",
    "next , integrating only over @xmath1 , we show in figures [ fig:2dplot55ns ] and [ fig:2dplot55is ] the agreement between the fitted and input sets of mass weights as a function of @xmath9 and @xmath79 , for the 55ns and 55is cases , respectively .",
    "the upper panels of these figures show the results of the schwarzschildfit ( @xmath209 ) and the lower panels the original input distributions ( @xmath175 ) .",
    "the left - hand panels show the results for a @xmath160 library of @xmath212 orbits , 8 times larger ( i.e. , finer ) than that of the right - hand panels , which correspond to our standard case of @xmath208 orbits . only the energy range constrained by the respective sets of data is shown .",
    "black corresponds to zero weight , and the white ( brightest ) color in each pair of panels ( fit and model , or upper and lower ) has been assigned to the maximum orbital weight among the two panels , so that the comparison between fits and models is made using the same color scale . both figures",
    "[ fig:2dplot55ns ] and [ fig:2dplot55is ] show that the main features of the input @xmath164 distributions of mass weights are well reproduced by the 3-integral schwarzschildfits . in particular , the mean streaming properties of both datasets are satisfactorily recovered . in figure",
    "[ fig:2dplot55ns ] , the two prominent phase - space blobs occupying symmetrical locations on the negative and positive sides of the @xmath79-axis correspond well with the non - rotating overall nature of the 55ns dataset .",
    "moreover , this is recovered by both the models with standard and large orbit libraries ( right- versus left - hand panels ) .",
    "similarly , in figure [ fig:2dplot55is ] , the single phase - space blob at positive @xmath79 with a pronounced elongation towards negative @xmath79 ( in light blue and blue ) , indicative of the rotating nature of the 55is case , is reproduced by the schwarzschildfit as well .",
    "the median absolute deviations between the fitted and input @xmath164 distributions , always restricted to the energy range constrained by the data , are 14% and 19% for the 55ns and 55is cases , respectively ( table 1 ) .    in figure",
    "[ fig : ebins55is ] we show the 3-dimensional distributions of mass weights of our 55is case in the form of a series of @xmath210 planes at different energies . here again , the upper panels show the results of the discrete schwarzschildfit ( @xmath209 ) , the lower panels the distribution of mass weights corresponding to the input data ( @xmath179 ) , and the color scale is set up in the same way as in the @xmath164 figures . as the energy @xmath9 is sampled via the radius @xmath186 of the circular orbit ( its value in arcmin indicated at the top of each pair of panels )",
    ", this series of planes shows the variation of the @xmath210 distribution with increasing distance from the center of the galaxy .",
    "the fraction of the total mass at each energy slice is given as a percentage at the bottom of each panel .",
    "the bottom panels of figure [ fig : ebins55is ] indicate that , in the inner regions ( inside 0.2 arcmin ) , most of the mass in the 55is dataset is concentrated in orbits with @xmath79 near zero .",
    "the corresponding upper panels show that the schwarzschildfit recovers this @xmath213 component , but it distributes more weight than the input model into orbits with positive @xmath79 .",
    "these inner regions , nevertheless , have a relatively low mass content in comparison with regions at larger radii . as the radius increases",
    ", the @xmath214 region of phase - space gets progressively depleted of stars in favor of orbits with high @xmath79 .",
    "this transition is reasonably well reproduced by the schwarzschildsolution , and the agreement between fit and input data becomes better at large radii , at which point most of the mass at each energy is concentrated in orbits of high @xmath79 .",
    "note also that a common characteristic of figures [ fig:2dplot55ns ] , [ fig:2dplot55is ] , and [ fig : ebins55is ] is that schwarzschildfits typically present mass weight distributions that appear broader ( more extended ) and less peaked than the corresponding distributions displayed by the pseudo - data .",
    "the effect is most obvious among the right - most panels of figure [ fig : ebins55is ] , where one can see that the @xmath210 mass - weight distributions of the input data ( lower panels ) have higher peaks and overall sharper features than the corresponding fitted distributions ( upper panels ) .",
    "this is an expected effect and is due to the combined smoothing of the fitted distribution introduced both by the ( necessary ) use of velocity apertures for the computation of likelihoods ( see  [ sec : pij ] ) , and by the regularization constraints imposed in order to enforce smoothness in phase space .",
    "while the first smoothing is particular to our discrete implementation , the second is a well - known procedure common to most schwarzschildcodes .",
    "models without regularization tend to be unrealistically noisy @xcite and unreliable for parameter estimation @xcite .",
    "thus , although we choose to plot the input distribution of mass weights as they actually are , the most fair of comparisons would be one in which the schwarzschildfit is compared with a smoothed version of the original mass weight distribution describing the input data .",
    "we explored this by convolving the input distribution of mass weights with a ( circular ) gaussian kernel , and then computing the same statistics shown in table 1 ( but this time using the smoothed version of the input distribution ) for different widths of the gaussian kernel .",
    "we have verified that indeed it is possible to find a kernel width for which the agreement between fit and input data is best , improving both the rms and mean absolute deviations of table 1 by factors between 1.2 and 1.5 .",
    "finally , we also note that the comparison in figure [ fig : ebins55is ] might be affected by the accuracy of the approximation in equation ( [ eq : zetain ] ) , which means that the values in table 1 are actually upper limits to the true accuracy of the schwarzschildfits .    from these tests",
    "we conclude that our discrete schwarzschildcode can successfully recover the original df inside the region constrained by the kinematic data , at least for the case in which the inclination and mass - to - light ratio are assumed known .      for a large range of potential applications of a schwarzschildcode , such as investigating dark matter halos in galaxies , the most important property",
    "that one is interested in measuring with confidence is the mass - to - light ratio . in the present tests ,",
    "this quantity is a scalar , @xmath113 , although in more general applications it could be a function of radius . in this section",
    "we study in detail the capacity of our code to infer the correct @xmath113 when the inclination of the system is assumed known .",
    "tests were performed for a number of input datasets in order to investigate the dependence of the results on key observational variables such as the number of kinematic measurements and the type of kinematic constraints available ( i.e. , only - los velocities , only proper motions , as well as both los velocities and proper motions ) .",
    "all models in this section were computed using our small orbit library , with @xmath208 combinations of @xmath160 .",
    "the results of these experiments are summarized in figures [ fig : mlparabn]-[fig : errors_ml ] .    for the 90is and 55is cases and using full 3-dimensional velocity information , figure [ fig : mlparabn ]",
    "shows the @xmath21 parabolae obtained when applying the discrete schwarzschildcode with a number of @xmath113 values , distributed around the correct one ( @xmath215 ) , for datasets of varying sizes .",
    "the quantity @xmath216 along the ordinate denotes the velocity scaling ; @xmath217 corresponding to a schwarzschildmodel with the input value @xmath215 , defined in  [ sec : settings ] .",
    "the zero point of the vertical axis ( both in figures [ fig : mlparabn ] and [ fig : mlparab2 ] ) is arbitrary , but the difference @xmath72 between points on the same curve has its usual statistical meaning , and indeed we compute the ( random ) uncertainties on the determination of @xmath113 directly from them .",
    "figure [ fig : mlparabn ] shows that the difference @xmath72 between points on the same curve becomes larger ( the parabolae become narrower ) as the number of available kinematic measurements increases .",
    "the determination of the best - fit @xmath113 also depends on the type of available kinematic measurements .",
    "this is illustrated in figure [ fig : mlparab2 ] , where we plot the @xmath21 parabolae obtained when considering only los velocities , only proper - motions , or the full 3-dimensional velocity information .",
    "all cases are for the 55is dataset with 1000 kinematic measurements . in this case , the @xmath72 parabolae become narrower as the number of available velocity components increases .",
    "furthermore , the statistical errors are generally smaller for larger datasets , as well as when more velocity components are available .",
    "this is shown in figure [ fig : errors_ml ] , where we plot the behavior of the best - fit @xmath113 and its uncertainties as a function of @xmath218 , where @xmath46 is the number of datapoints .",
    "the uncertainties @xmath219 displayed in the upper panel of figure [ fig : errors_ml ] represent the @xmath75 intervals around the minimum of the parabolae in figures [ fig : mlparabn ] and [ fig : mlparab2 ] , and are defined as half the distance between the points on the curve where @xmath220 with respect to the minimum .",
    "the statistical errors scale roughly as @xmath207 over an interval of 1.3 dex in @xmath221 .",
    "also , the errors in the best - fit @xmath113 associated to datasets with only proper - motions ( triangles ) are smaller than those associated to only - los datasets ( open circles ) for any value of @xmath46 . in other words ,",
    "our discrete schwarzschildcode satisfies the fundamental statistical expectation that it should become easier for the method to distinguish between models with different @xmath113 when the amount of observational information is larger . in the case of datasets with the full 3-d velocity information",
    ", the 55is uncertainties do not quite seem to follow the @xmath207 behavior expected from statistics .",
    "we attribute this to our tests having reached a fundamental floor due to the discrete nature of the models , a limit that can not be overcome by increasing the number @xmath46 of available measurements .",
    "this can cause an apparent flattening with respect to the regular @xmath207 behavior at large @xmath46 .    to test the robustness of the errors estimated as above , we performed the following exercise . selecting 10 different ( disjoint ) realizations of the n - body data ( for the 55is case with 1000 measurements of only line - of - sight velocities , the case most often found in practice ) , we repeated the exercise of figures [ fig : mlparabn ] and [ fig : mlparab2 ] and computed discrete schwarzschildmodels for a set of different @xmath113 values distributed around the correct input one .",
    "this was done using our small orbit library .",
    "we obtained an average best - fit @xmath113 of 2.46 ( less than @xmath75 away from the input value , @xmath222 ) , with an rms of 0.074 ( corresponding to about 3% ) .",
    "when computing the statistical uncertainties using the @xmath223 parabolae as described above , the average @xmath75 error in the best - fit @xmath113 of the set of experiments turns out to be 0.204 , equivalent to a fractional error of 8% .",
    "this is a factor of 2.5 larger than the scatter in the results from multiple independent realizations of the pseudo - data .",
    "this gap is smaller when additional information about the individual kinematics of the tracers is available . indeed , repeating the above exercise for the same datasets but now using two - dimensional proper - motions instead of only line - of - sight velocities , the average error in @xmath113 computed from our @xmath21 parabolae is 0.112 , a factor of 1.7 larger than the scatter of the best - fit values , which was 0.067 .",
    "therefore , we conclude that our error estimation using @xmath72 is conservative .    despite the smaller statistical errors for the case with proper - motions alone",
    ", the bottom panel of figure [ fig : errors_ml ] indicates that the best - fit @xmath113 is closer to the real value , @xmath215 , for the case with only - los velocities .",
    "while the best - fit @xmath113 from datasets with only los velocities are well within @xmath75 of @xmath215 for any @xmath46 , this is not the case for the datasets with only proper - motions , with best - fit @xmath113 values that are @xmath224 away from @xmath215 .",
    "still , the formal best - fit @xmath113 for the case of full 3-d velocities ( thick squares ) is on average within @xmath225 of the real value , @xmath215 , corresponding to better than @xmath226% accuracy .",
    "one contribution to the small systematic bias in @xmath113 may come from the fundamental nature of inverse problems in general ( of which schwarzschildmodeling is an example ) , namely , that there may not necessarily be a unique solution : it may be possible to change the mass profile and the df without appreciably changing the model predictions .",
    "if such is the case and there are multiple solutions , we do not necessarily expect a flat @xmath223 profile ( i.e. , with a number of equally acceptable solutions containing the correct one ) , most likely because of numerical noise and discretization effects . while we can not rule this out",
    ", our results do show that this probably does not affect the recovered mass - to - light ratio at more than the @xmath227% level ( based on figure [ fig : errors_ml ] , built with models using our smaller orbit library ) . unless superb data are available , random uncertainties are likely larger than such systematic errors .",
    "currently , the only exception to this are some galactic globular clusters , for which thousands of proper motions are being measured .",
    "however , such systems are often closer to spherical than galaxies , and hence one expects any theoretical degeneracies to be smaller .",
    "alternatively , numerical noise in the orbit library may be the cause of this systematic bias in @xmath113 seen in the bottom panel of figure [ fig : errors_ml ] .",
    "numerical noise may be reduced in part by the use of larger orbit libraries .",
    "indeed , we show in  [ sec : grids ] below that a substantially larger orbit library tends to produce more accurate results overall .",
    "the likelihood ratio statistic @xmath21 in figures  [ fig : mlparabn ] and [ fig : mlparab2 ] allows us to find the best - fit model parameters and their confidence intervals .",
    "however , it does not shed light on the question whether the best - fit model is actually statistically consistent with the data .",
    "the likelihood @xmath68 of the best - fit model also can not be used for this purpose .",
    "there is no theorem of mathematics that states what the value of @xmath68 should be for a statistically acceptable model , given that the underlying velocity distributions from which the particles are drawn are not known a priori ( and are not generally gaussian ) .",
    "nonetheless , many other statistics can be defined to address this issue once the best - fit model has been found .",
    "for example , the velocity moments of the best - fit model can be calculated ( as a function of position on the sky ) , and statistics can be defined that assess whether these moments are consistent with the observed data .",
    "alternatively , one can draw random realizations of the data from the best - fit model and use a kolmogorov - smirnov test to assess whether the data and the realization are consistent with being drawn from the same underlying distribution .",
    "we have explored a subset of these approaches and these suggested that the best - fit models are indeed statistically consistent with the pseudo - data they were designed to fit .      in general",
    "neither the mass - to - light ratio nor the inclination of a stellar system under study are known in advance , and thus one has to explore models with several combinations of both parameters in a search for those values that provide the best fit to the data . in this section we present and discuss the results of running the discrete schwarzschildcode on grids of @xmath228 values to study whether the correct input combination is recovered . as in  [ sec : getml ] , we perform tests on datasets with different types of kinematic constraints ( los velocities and/or proper motions ) .    the results of tests are presented in figures [ fig:55is_los_mu ] and [ fig : grid_55_90 ] .",
    "they show @xmath72 contours that result when computing discrete schwarzschildmodels on a grid of @xmath228 values , including the correct input combination , for a variety of input datasets of the 55is and 90is cases .",
    "the goodness - of - fit parameter @xmath72 shown in these plots is obtained by first rebinning with a much finer grid the @xmath228 space explored by the models actually calculated ( indicated by small dots ) , and then computing the values on this new grid via interpolation between the nearest calculated models .",
    "we then determine the minimum on the finer grid ( whose location is indicated by the star ) and subtract it from all grid points to obtain the @xmath72 parameter , for which contours are shown .",
    "as in the case of figures [ fig : mlparabn ] and [ fig : mlparab2 ] , the mass - to - light ratio is parameterized by the dimensionless velocity scaling @xmath229 , so that the input value corresponds to @xmath230 .",
    "we start by showing in figure [ fig:55is_los_mu ] the results of running grids of models for input datasets composed of only - los velocities and only proper motions , in both cases for the 55is case with 1000 observational datapoints , and using our small orbit library with @xmath208 combinations of @xmath160 .",
    "overall , and in agreement with the results of figure [ fig : mlparab2 ] discussed in ",
    "[ sec : getml ] , the @xmath72 contours indicate that proper motions ( bottom panel ) better constrain the best - fit @xmath228 combination than a dataset with only - los velocities ( upper panel ) .",
    "the @xmath231 uncertainties ( thick contours ) obtained from the only - los dataset are twice as large than those from the proper motions alone ( 31% and 16% , respectively ) . the input mass - to - light ratio @xmath215 is adequately recovered by both datasets ( to within the @xmath75 confidence region ) .",
    "the best - fit inclination , however , is offset from the actual input value @xmath148 for both datasets , although somewhat closer to the correct value in the case of proper motions only .",
    "the @xmath231 uncertainties in the best - fit inclination are @xmath232 and @xmath233 for the only proper motions and only los cases , respectively .",
    "difficulties in constraining the inclination using schwarzschildmodeling of stellar kinematics have been encountered in the past .",
    "a good recent example is that of @xcite who , based on integrated stellar los velocity profiles and ionized gas observations of the e4 galaxy ngc 2974 , carried out a study analogous to the present one by constructing simulated observations of this galaxy , which they feed to their `` continuous '' ( as opposed to discrete ) schwarzschildcode in order to study the recovery of the input mass - to - light ratio and inclination .",
    "they find that even with artificially perfect input kinematics the inclination is very poorly constrained . the same conclusion is reached when attempting to fit the actually observed los velocity profiles with schwarzschildmodels , so stellar los velocity profiles provide weak constraints on the inclination of this system , a statement they are confident about because the actual inclination of ngc 2974 is known from observations of its extended disc of neutral and ionized gas in rapid rotation .",
    "while one could expect that the availability of proper motion measurements in addition to los velocities would enhance the ability of the models to obtain useful constraints on the inclination of a stellar system in general , the reality is that the current state - of - the - art of schwarzschildmodeling does not have a definitive answer on this issue yet .",
    "as recent studies of the kinematics of stars in globular clusters seem to indicate , the chances of success are highly dependable on the quality and quantity of available data on the system under study ( compare , for example , the results of @xcite and @xcite regarding the best - fit inclinations of @xmath22 cen and m15 , respectively ) .",
    "there are at least two factors that may contribute to the difficulty in recovering the inclination from stellar kinematics : degeneracies inherent to schwarzschildmodels , and numerical noise .",
    "first , there is no guarantee that inclinations other than the correct one must fit the data worse .",
    "indeed , in their modeling of high signal - to - noise integral - field data of ngc 2974 , @xcite already observe that the differences between schwarzschildmodels with different inclinations are smaller than the differences between the best - fitting model and the data , which they interpret as indication of a fundamental degeneracy in the recovery of the inclination with three - integral models .",
    "numerical noise , on the other hand , is a consequence of schwarzschildmodels being in the end only discrete representations of a smooth , continuous distribution of possible orbits , and it could be argued that this discreteness might have a more negative effect for high inclinations .",
    "for example , even a simple and smooth circular orbit presents cusps or discontinuities when viewed close to edge - on .",
    "the turning points of such an orbit may get smoothed out differently for different inclinations .",
    "the issue of degeneracy , nevertheless , can be avoided in those cases where the inclination is known to be uniquely determined by the data .",
    "this is the case , e.g. , in the situations where the following conditions are met : ( 1 ) the kinematical dataset consists of proper motion measurements and los velocities , ( 2 ) the stellar system is reasonably close to axisymmetric , and ( 3 ) there exists an independent measurement of the distance @xmath234 to the system .",
    "as first used in practice by @xcite , the inclination then follows directly from the following relationship between the mean los velocity ( in units of @xmath198 ) and the mean proper motion along the short axis ( in units of masyr@xmath235 ) , @xmath236 where @xmath234 is the distance in kpc , and the brackets denote an integration along the line - of - sight .",
    "this relation is true at each projected position @xmath6 in any axisymmetric system , and has been successfully applied to the galactic globular clusters @xmath22 cen and m15 @xcite .    here , in order to explore the applicability of this simple relationship , we take advantage of our a priori knowledge of the correct inclination for our simulated datasets , and study the circumstances under which the use of equation ( [ eq : inclination ] ) provides an accurate result . unlike the case of integrated light measurements ( where @xmath237 is simply the average of the losvd at",
    "any given projected position on the sky ) , in the context of discrete datasets neither @xmath237 nor @xmath238 are quantities that can be rigorously obtained from the data at any given @xmath6 .",
    "both quantities may , nevertheless , be approximated by averaging a number of kinematic measurements that fall within one or more apertures of a given size around projected positions @xmath6 . following this , we applied equation ( [ eq : inclination ] ) to a series of subsets of our 6 simulated datasets with varying number of kinematic measurements , and verified that indeed the correct inclination is reproduced provided : ( a ) the system is rotating ( otherwise , while the relation is still valid , both averages are nearly zero and hence the inclination is not really constrained ) ; ( b ) most of the datapoints are not located close to the minor axis ( where rotation velocities are too small ) ; and ( c ) the averages are computed from a sufficiently large number of kinematical measurements ( so that the error in @xmath239 is not too large )",
    ". these are conditions that are certainly fulfilled by datasets on some galactic globular clusters , currently the only class of stellar system for which there are 3-dimensional kinematic information available .",
    "therefore , in those cases , equation ( [ eq : inclination ] ) can be safely applied .",
    "the schwarzschildmodeling can then concentrate on recovering the more interesting properties such as the orbital structure and mass - to - light ratios , which we have shown are successfully recovered when the inclination is assumed known .    to better understand the problem of numerical noise , we explored the dependence of the results on the size of the orbit library used to construct the schwarzschildmodels .",
    "we did this for cases with 1000 datapoints with complete three - dimensional velocities , so that because of equation ( [ eq : inclination ] ) we know that there is no theoretical degeneracy in inclination . figure [ fig : grid_55_90 ] shows the @xmath72 contours resulting from fits of schwarzschildmodels using our standard library of @xmath208 orbits ( upper panels ; same library size as in figure  [ fig:55is_los_mu ] ) in comparison with fits that use a library 8 times larger , i.e. , one with @xmath212 orbits ( lower panels ) .",
    "we show results for the 55is ( left - hand panels ) and 90is ( right - hand panels ) cases .    in all four panels of figure [ fig : grid_55_90 ] ,",
    "the best - fit mass - to - light ratio is always within @xmath75 of the input value @xmath215 , with the exception of the 55is case with the bigger library ( lower left ) , where they agree at the @xmath225 level .",
    "the size of the confidence regions on the mass - to - light ratio does not change significantly when the orbit library is increased in size .",
    "therefore , we conclude that libraries of @xmath208 orbits are large enough to properly constrain the mass - to - light ratio ( provided that one uses regularization as we do here ; see @xcite ) .",
    "this provides further justification for our use of this library size in section  [ sec : getml ] .",
    "the top left panel in figure [ fig : grid_55_90 ] is directly comparable to the two panels of figure [ fig:55is_los_mu ] , but now with three components of velocities observed , instead of just one or two , respectively .",
    "consistent with the results in figures  [ fig : errors_ml ] and  [ fig:55is_los_mu ] , we see that the addition of an extra component of velocity decreases the size of the confidence regions .",
    "more interestingly , a secondary minimum in @xmath223 appears close to the @xmath228 values for the correct input model .",
    "this suggests that indeed all three components of velocity may be necessary to uniquely constrain the inclination of an axisymmetric stellar system .",
    "the bottom left panel shows the effect of increasing the orbit library size .",
    "there is now only a single minimum , centered at an inclination that agrees with the input value at the @xmath240 level .",
    "the right panels in figure [ fig : grid_55_90 ] show the situation for the 90is case . with the small library ( top right ) ,",
    "the best - fit inclination is at @xmath241 , substantially far from the input value . when the orbit library size is increased ( lower right ) , the best - fit shifts to @xmath242 .",
    "this is only @xmath243 from the correct input value , which may well be acceptable for many realistic applications . on the other hand , the best fit and the input value are inconsistent at the many sigma level , which is certainly reason for some concern .",
    "a possible cause for this is that the turning points of orbits in edge - on systems have very sharp edges in projection .",
    "therefore , larger grid sizes than we have used may be necessary to correctly represent them in all the necessary detail . however , we have not explored this further for two reasons .",
    "first , information on all three velocity components may be necessary to be able to uniquely constrain the inclination .",
    "if that is available , then use of equation  ( [ eq : inclination ] ) will be more accurate and efficient than use of schwarzschild modeling .",
    "second , in practice one is generally much more interested in the mass distribution than in the inclination .",
    "figure [ fig : grid_55_90 ] shows that the mass - to - light ratio is correctly recovered , even when the inclination is systematically biased .    in conclusion ,",
    "our tests demonstrate that the recovery of the most important properties of the system ( its orbital structure and the mass - to - light ratio ) by our discrete schwarzschildmodels is robust .",
    "correct recovery of the inclination appears to be the most complicated aspect of the modeling .",
    "sufficient observational data must be available and a large enough orbit library must be used .",
    "our code can then adequately recover the inclination of sufficiently inclined systems .",
    "however , for edge - on systems there remains a systematic inclination bias of @xmath244 that we have been unable to resolve .",
    "this is the primary shortcoming of our new approach that was unearthed by the pseudo - data tests that we have presented .",
    "this may be a generic property of schwarzschild codes , since other authors have also reported difficulties in recovering inclinations .",
    "either way , this is not believed to be a significant limitation for most potential practical applications of our code .",
    "discrete kinematic datasets , composed of velocities of individual tracers ( e.g. , red giants , planetary nebulae , globular clusters , galaxies , etc . ) , are routinely being assembled for a variety of stellar systems of all scales (  [ sec.intro ] ) .",
    "these include not only los - velocity surveys .",
    "high - quality proper - motion databases already exist for galactic globular clusters , and future facilities hold the promise of providing the same for stars in the nearest galaxies .",
    "however , the most sophisticated tools typically being used in the modeling of these observations were actually developed for the analysis of kinematic data in the form of losvds , a rather different type of velocity information than the case of the velocities of kinematic tracers on a one - by - one basis . as a consequence ,",
    "the information content of any particular dataset of a discrete nature is likely not being fully exploited .",
    "we thus have developed a specific tool for the modeling of discrete datasets , which we have presented in this paper along with detailed tests of its performance based on the modeling of simulated data .",
    "the new tool consists of a schwarzschildorbit - superposition code that , adapted from the implementation of @xcite , can handle any number of ( one- , two- , or three - dimensional ) velocities of individual kinematic tracers without relying on any binning of the data . under the only assumptions that the system is in steady - state equilibrium ( i.e.",
    ", the gravitational potential is not changing in time ) and may be well approximated as axisymmetric , the code finds the distribution function ( a function of the three integrals of motion @xmath9 , @xmath79 , and @xmath1 ) that best reproduces the observations ( the velocities of the tracers as well as the overall light distribution ) in a given potential .",
    "the fact that the distribution function is free to have any dependence on the three integrals of motion allows for a very general description of the orbital structure , thus avoiding common restrictive assumptions about the degree of ( an)isotropy of the orbits .",
    "unlike previous implementations of the schwarzschildtechnique , we cast the problem of finding the best superposition of orbits using a probabilistic approach , i.e. , by building a likelihood function representing the probability that the entire set of measurements would have been observed assuming a particular form for the gravitational potential (  [ sec : logl ] ) . in this case , and in contrast with the old continuous versions , the dependence of the likelihood function on the orbital weights is non - linear , and the optimization problem can not be reduced to a linear matrix equation .",
    "instead , it becomes a problem of the maximization of a likelihood with respect to the set of weights associated to all possible combinations of the integrals @xmath160 that comprise the orbit library (  [ sec : logl ] ) , and which accounts for the observed positions and ( any - dimensional ) velocities of all particles in the dataset , including their uncertainties (  [ sec : pij ] ) .",
    "after extensive testing , a conjugate gradient algorithm was found to converge satisfactorily to the correct solution and was adopted for the remaining tests of the code s overall performance (  [ sec.mkfitin ] ) .    in order to assess the reliability of our discrete schwarzschildcode",
    ", we applied it to several sets of simulated data , i.e. , artificially generated kinematic observations obtained from a model of an axisymmetric galaxy of which the orbital structure , mass distribution , and inclination are known in advance .",
    "pseudo - datasets were generated from a two - integral phase - space distribution function with varying degrees of overall rotation , types of velocity information ( only - los , only proper motions , and both ) , total number of particles , and for two different inclinations on the plane of the sky (  [ sec : data ] ) .    using the various simulated datasets , we studied the recovery of the input orbital structure or df , mass - to - light ratio , and inclination . for the purposes of these tests",
    ", we assumed complete knowledge of the radial profile of the underlying mass distribution and a mass - to - light ratio that remains constant as a function of radius .",
    "these restrictions are easily ( and must be ) lifted when modeling data on real systems , in which case one needs to explore a range of plausible underlying potentials and allow for variations of the mass - to - light ratio to properly account for the possibility of central black holes and dark halos .    inside the region",
    "constrained by data , we find that the distribution function ( represented by the corresponding distributions of orbital mass weights ) and streaming characteristics of the input datasets are satisfactorily recovered by the schwarzschildfits when the correct inclination and mass - to - light ratio are known ( figs .",
    "[ fig:1dplots ] to [ fig : ebins55is ] ) .",
    "as measured by the mean absolute deviations between the integrated weight distributions , the agreement between the fitted and the input orbital weight distributions as a function of @xmath9 , @xmath79 , and @xmath1 is typically of the order of 3% , 10% , and 20% , respectively ( the numbers for our worst case being 5% , 16% , and 25% ) . when eliminating the dependence on @xmath1 , the agreement between the fitted and input @xmath164 distributions is of the order of 15% , with the net rotational behavior of the input datasets cleanly recovered ( figs .",
    "[ fig:2dplot55ns ] and [ fig:2dplot55is ] ) .",
    "thus , we conclude that the discrete schwarzschildcode can successfully recover the orbital structure of the system under study .",
    "assuming that the inclination of the system on the plane of the sky is known , we quantified the recovery of the input mass - to - light ratio as a function of the size of the input dataset ( fig .",
    "[ fig : mlparabn ] ) and of the type of kinematic information available ( fig .",
    "[ fig : mlparab2 ] ) .",
    "we studied both the best - fit value as well as the uncertainty in its determination ( fig .",
    "[ fig : errors_ml ] ) .",
    "the statistical expectation of better results when the amount of observational information is larger ( either regarding the number of datapoints or the number of velocity components ) is clearly reproduced by our discrete schwarzschildmodels .",
    "for the smallest datasets used in our testing ( @xmath245 ) , and regardless of whether using only - los velocities , only proper motions , or both , the best - fit mass - to - light ratio is within 5 - 10% of the input value , with formal @xmath75 uncertainties of the order of 15% . when increasing either the number of available measurements or the number of measured velocity components , the mass - to - light ratio is always recovered to better than @xmath246 accuracy , with the corresponding random ( @xmath75 ) uncertainties in the range of 5 - 10% .",
    "the discrete schwarzschildcode , therefore , recovers the mass - to - light ratio of the input datasets to satisfactory levels of accuracy .",
    "the recovery of both the mass - to - light ratio and inclination when neither of these quantities are known in advance ( as is usually the case with real observations ) was studied using a grid of discrete schwarzschildmodels , exploring also the dependence on the type of velocity components available ( fig .",
    "[ fig:55is_los_mu ] ) .",
    "we find that the mass - to - light ratio was again successfully recovered , but the best - fit inclination was not identified correctly using small orbit libraries .",
    "we found that this was remedied by better sampling the available @xmath160 integral space using a larger orbit library ( fig .",
    "[ fig : grid_55_90 ] ) . for our input datasets with @xmath148 ,",
    "the best - fit inclination obtained by our models with a large orbit library is @xmath247 , while for input datasets with @xmath147 we obtain a best - fit model with @xmath242 .",
    "given the known difficulty of schwarzschildmodels in general for determining the inclination of stellar systems , and considering the low relative importance of this parameter compared to other properties such as the orbital structure and the mass - to - light ratio , we regard this small disagreement for the high inclination datasets as acceptable .    in summary , we have shown that our new schwarzschildcode , designed to adequately handle modern datasets composed of discrete measurements of kinematic tracers , doing this without any loss of information due to data binning or restrictive assumptions on the distribution function , is able to constrain satisfactorily the orbital structure , mass - to - light ratio , and inclination of the system under study",
    ". applications to data for galactic globular clusters and nearby de galaxies will be presented in future papers .",
    "these are only two examples of a large range of dynamical problems in astronomy to which a discrete schwarzschildcode like ours can be applied , so we expect this new tool will contribute to the better understanding of stellar systems in general .    we are happy to thank marla geha and raja guhathakurta for their continued interest in the present work and its extension to the study of actual galaxies using their unique data on dwarf ellipticals",
    ". we also thank glenn van de ven for very useful discussions , his interest in the progress of this project and , last but not least , for his invaluable help with idl routines .",
    "this paper also benefited by comments from davor krajnovic , aaron romanowsky , and david merritt .",
    "thanks also to george meylan for his help with the writing of the hst theory proposal specified below , and to the anonymous referee , whose comments and suggestions improved the presentation of the paper .",
    "this work was carried out as part of hst theory project # 9952 and was supported by nasa through a grant from stsci , which is operated by aura , inc .",
    ", under nasa contract nas 5 - 26555 .",
    "batsleer , p. , & dejonghe , h.  1993 , , 271 , 104 batsleer , p. , & dejonghe , h.  1995 , , 294 , 693 bender , r. , et al .",
    "2005 , , 631 , 280 binney , j. , & mamon , g.  a.  1982 , , 200 , 361 binney , j. , & tremaine , s.  1987 , princeton , nj , princeton university press , 1987 cappellari , m. , verolme , e.  k. , van der marel , r.  p. , kleijn , g.  a.  v. , illingworth , g.  d. , franx , m. , carollo , c.  m. , & de zeeuw , p.  t.  2002 , , 578 , 787 cappellari , m. , et al .  2006 , , 366 , 1126 ct , p. , et al .  2001 , , 559 , 828 ct , p. , mclaughlin , d.  e. , cohen , j.  g. , & blakeslee , j.  p.  2003",
    ", , 591 , 850 cretton , n. , de zeeuw , p.  t. , van der marel , r.  p. , & rix , h .- w .  1999 , , 124 , 383 cretton , n. , rix , h .- w . ,",
    "& de zeeuw , p.  t.  2000 , , 536 , 319 cretton , n. , & emsellem , e.  2004 , , 347 , l31 davies , r.  i. , et al .",
    "2006 , , 646 , 754 dehnen , w. , & gerhard , o.  e.  1994 , , 268 , 1019 dekel , a. , stoehr , f. , mamon , g.  a. , cox , t.  j. , novak , g.  s. , & primack , j.  r.  2005 , , 437 , 707 de bruijne , j.  h.  j. , van der marel , r.  p. , & de zeeuw , p.  t.  1996 , , 282 , 909 de lorenzi , f. , debattista , v.  p. , gerhard , o. , & sambhus , n.  2007 , , 376 , 71 douglas , n.  g. , et al .",
    "2002 , , 114 , 1234 douglas , n.  g. , et al .",
    "2007 , arxiv : astro - ph/0703047 gebhardt , k. , pryor , c. , williams , t.  b. , hesser , j.  e. , & stetson , p.  b.  1997 , , 113 , 1026 gebhardt , k. , et al .",
    "2000 , , 119 , 1157 gebhardt , k. , et al .  2003 , , 583 , 92 geha , m. , guhathakurta , p. , rich , r.  m. , & cooper , m.  c.  2006 , , 131 , 332 gerhard , o.  e.  1993 , , 265 , 213 gerhard , o. , jeske , g. , saglia , r.  p. , & bender , r.  1998 , , 295 , 197 gerssen , j. , van der marel , r.  p. , gebhardt , k. , guhathakurta , p. , peterson , r.  c. , & pryor , c.  2002 , , 124 , 3270 gilbert , k.  m. , et al .",
    "2006 , , 652 , 1188 gilbert , k.  m. , et al .",
    "2007 , , 668 , 245 kleyna , j.  t. , wilkinson , m.  i. , evans , n.  w. , & gilmore , g.  2001 , , 563 , l115 kleyna , j. , wilkinson , m.  i. , evans , n.  w. , gilmore , g. , & frayn , c.  2002 , , 330 , 792 krajnovi , d. , cappellari , m. , emsellem , e. , mcdermid , r.m . , & de zeeuw , p.t .",
    "2005 , , 357 , 1113 kunkel , w.  e. , demers , s. , irwin , m.  j. , & albert , l.  1997 , , 488 , l129 kunkel , w.  e. , demers , s. , & irwin , m.  j.  2000 , , 119 , 2789 okas , e.  l.  2002 , , 333 , 697 okas , e.  l. , & mamon , g.  a.  2003 , , 343 , 401 okas , e.  l. , mamon , g.  a. , & prada , f.  2005 , , 363 , 918 magorrian , j.  2006 , , 373 , 425 magorrian , j. , et al .",
    "1998 , , 115 , 2285 mayor , m. , et al .",
    "1997 , , 114 , 1087 mclaughlin , d.  e. , anderson , j. , meylan , g. , gebhardt , k. , pryor , c. , minniti , d. , & phinney , s.  2006 , , 166 , 249 mcnamara , b.  j. , harrison , t.  e. , & anderson , j.  2003 , , 595 , 187 merritt , d.  1993 , , 413 , 79 merritt , d. , & saha , p.  1993",
    ", , 409 , 75 merritt , d. , meylan , g. , & mayor , m.  1997 , , 114 , 1074 merritt , d.  1999 , , 111 , 129 press , w.  h. , teukolsky , s.  a. , vetterling , w.  t. , & flannery , b.  p.  1992",
    ", cambridge university press , 1992 , 2nd ed .",
    "reijns , r.  a. , seitzer , p. , arnold , r. , freeman , k.  c. , ingerson , t. , van den bosch , r.  c.  e. , van de ven , g. , & de zeeuw , p.  t.  2006 , , 445 , 503 richstone , d.  o. , & tremaine , s.  1984 , , 286 , 27 richtler , t. , et al .",
    "2004 , , 127 , 2094 rix , h .- w . , de zeeuw , p.  t. , cretton , n. , van der marel , r.  p. , & carollo , c.  m.  1997 , , 488 , 702 romanowsky , a.  j. , & kochanek , c.  s.  2001 , , 553 , 722 romanowsky , a.  j. , douglas , n.  g. , arnaboldi , m. , kuijken , k. , merrifield , m.  r. , napolitano , n.  r. , capaccioli , m. , & freeman , k.  c.  2003 , science , 301 , 1696 schwarzschild , m.  1979 , , 232 , 236 shanno , d.f .",
    ", & phua , k.h .  1980 , acm transactions on mathematical software , 6 , 618 simon , j.  d. , & geha , m.  2007 , , 670 , 313 suntzeff , n.  b. , & kraft , r.  p.  1996",
    ", , 111 , 1913 syer , d. , & tremaine , s.  1996 , , 282 , 223 teodorescu , a.  m. , mndez , r.  h. , saglia , r.  p. , riffeser , a. , kudritzki , r .-",
    "p . , gerhard , o.  e. , & kleyna , j.  2005 , , 635 , 290 thomas , j. , saglia , r.  p. , bender , r. , thomas , d. , gebhardt , k. , magorrian , j. , & richstone , d.  2004 , , 353 , 391 valluri , m. , merritt , d. , & emsellem , e.  2004 , , 602 , 66 van de ven , g. , van den bosch , r.c.e . ,",
    "verolme , e.k .",
    ", & de zeeuw , p.t .  2006 , , 445 , 513 van den bosch , r. , de zeeuw , t. , gebhardt , k. , noyola , e. , & van de ven , g.  2006 , , 641 , 852 van der marel , r.  p. , & franx , m.  1993 , , 407 , 525 van der marel , r.p . , evans , n.w . ,",
    "rix , h .- w . ,",
    "white , s.d.m .",
    ", & de zeeuw , p.t .  1994 , , 271 , 99 van der marel , r.  p. , de zeeuw , p.  t. , & rix , h .- w .",
    "1997 , , 488 , 119 van der marel , r.p . ,",
    "sigurdsson , s. , & hernquist , l.  1997 , , 487 , 153 van der marel , r.p . ,",
    "cretton , n. , de zeeuw , p.t . , & rix , h .- w .",
    "1998 , , 493 , 613 van der marel , r.  p. , magorrian , j. , carlberg , r.  g. , yee , h.  k.  c. , & ellingson , e.  2000 , , 119 , 2038 van der marel , r.  p. , alves , d.  r. , hardy , e. , & suntzeff , n.  b.  2002 , , 124 , 2639 van der marel , r.  p. , & van dokkum , p.  g.  2006 , astro - ph/0611571 vandervoort , p.o .  1984 , , 287 , 475 van leeuwen , f. , le poole , r.  s. , reijns , r.  a. , freeman , k.  c. , & de zeeuw , p.  t.  2000 , , 360 , 472 verolme , e.  k. , & de zeeuw , p.  t.  2002 , , 331 , 959 walker , m.  g. , mateo , m. , olszewski , e.  w. , bernstein , r. , wang , x. , & woodroofe , m.  2006 , , 131 , 2114 wilkinson m.i . ,",
    "kleyna , j.t . ,",
    "evans , n.w . , gilmore g. , 2001 , mnras , 330 , 778 wilkinson , m.  i. , kleyna , j.  t. , evans , n.  w. , gilmore , g.  f. , irwin , m.  j. , & grebel , e.  k.  2004 , , 611 , l21 wojtak , r. , & okas , e.  l.  2007 , , 377 , 843 wojtak , r. , okas , e.  l. , mamon , g.  a. , gottlber , s. , prada , f. , & moles , m.  2007 , , 466 , 437 wu , x.  2007 , astro - ph/0702233 wu , x. , & tremaine , s.  2006 , , 643 , 210    ccrlcrlcrlcrlcrl 55ns & & 4.5138 & 0.4531 & & 0.2207 & 0.1404 & & 0.0908 & 0.0359 & & 0.1080 & 0.0719 & & 0.2634 & 0.1591 + 55is & & 6.6525 & 0.5630 & & 0.3677 & 0.1915 & & 0.0939 & 0.0309 & & 0.1912 & 0.1598 & & 0.2460 & 0.1855 + 55ms & & 3.1524 & 0.4208 & & 0.2123 & 0.1207 & & 0.0884 & 0.0334 & & 0.1845 & 0.0903 & & 0.2505 & 0.1122 + 90ns & & 3.7560 & 0.5939 & & 0.2683 & 0.1633 & & 0.1419 & 0.0425 & & 0.2202 & 0.1365 & & 0.2361 & 0.2491 + 90is & & 2.7956 & 0.6410 & & 0.6253 & 0.1629 & & 0.1366 & 0.0347 & & 0.4826 & 0.1178 & & 0.2566 & 0.2364 + 90ms & & 1.4893 & 0.4927 & & 0.2298 & 0.1714 & & 0.1216 & 0.0384 & & 0.1456 & 0.1149 & & 0.2953 & 0.2333 +"
  ],
  "abstract_text": [
    "<S> we present a new schwarzschildorbit - superposition code that is designed to model discrete datasets composed of velocity measurements of individual kinematic tracers in a dynamical system . </S>",
    "<S> this constitutes an extension of previous implementations that can only address continuous data in the form of ( the moments of ) velocity distributions , thus avoiding potentially important losses of information due to data binning . </S>",
    "<S> furthermore , the code can handle any combination of available velocity components , i.e. , only line - of - sight velocities , only proper motions , or a combination of both . </S>",
    "<S> it can also handle a combination of discrete and continuous data . </S>",
    "<S> the code determines the combination of orbital mass weights ( representing the distribution function ) as a function of the three integrals of motion @xmath0 and @xmath1 that best reproduces , in a maximum - likelihood sense , the available kinematic and photometric observations in a given axisymmetric gravitational potential . </S>",
    "<S> the overall best fit is the one that maximizes the likelihood over a parameterized set of trial potentials . </S>",
    "<S> the fully numerical approach ensures considerable freedom on the form of the distribution function @xmath2 . </S>",
    "<S> this allows a very general modeling of the orbital structure , thus avoiding restrictive assumptions about the degree of ( an)isotropy of the orbits . </S>",
    "<S> we describe the implementation of the discrete code and present a series of tests of its performance based on the modeling of simulated ( i.e. , artificial ) datasets generated from a known distribution function . </S>",
    "<S> we explore pseudo - datasets with varying degrees of overall rotation and different inclinations on the plane of the sky , and study the results as a function of relevant observational variables such as the size of the dataset and the type of velocity information available . </S>",
    "<S> we find that the discrete schwarzschildcode recovers the original orbital structure , mass - to - light ratio , and inclination of the input datasets to satisfactory accuracy , as quantified by various statistics . </S>",
    "<S> the code will be valuable , e.g. , for modeling stellar motions in galactic globular clusters , and modeling the motions of individual stars , planetary nebulae , or globular clusters in nearby galaxies . </S>",
    "<S> this can shed new light on the total mass distributions of these systems , with central black holes and dark matter halos being of particular interest . </S>"
  ]
}