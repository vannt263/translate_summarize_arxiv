{
  "article_text": [
    "the nature of the dark energy is one of greatest enigmas of modern cosmology . at stake is the fate of the universe as well as a key insight into fundamental physics .",
    "a wide variety of theories explaining the dark energy have been proposed - but all of them phenomenological as opposed to fundamental . in the absence",
    "an explanation driven by fundamental theory , our understanding must be driven by the observational data . the coming years will provide a tremendous amount of this data , but because the dark energy interacts weakly with the visible sector and clumps minimally at best , elucidating its nature will be hard work .",
    "no single set of observations can do the job alone . successfully determining",
    "if the dark energy is dynamical , and if so , what those dynamics are will require the inclusion of every relevant observation into the analysis to break parameter degeneracies , control systematics and establish a concordance .",
    "a unified data analysis framework is crucial .",
    "observables that depend on the dark energy also depend on visible - sector cosmological parameters - thus the need for a global analysis , utilizing all data to jointly estimate all resolvable parameters .",
    "the analysis and resolution of dark - sector attributes ( arda ) project is such a unified framework - which will be used to estimate cosmological parameters jointly from all relevant present and future experimental datasets .",
    "the cosmological parameter space has been selected to allow testing for a wide variety of classes of dark energy behavior .",
    "the total dimensionality of the cosmological parameter space will be large by current standards ( @xmath1 ) , but the parameterization will be physically motivated , general but economical , and involve minimal assumptions ( such as stress - energy conservation ) so that a wide range of dark energy models are admitted .",
    "those dark energy models whose background and perturbation behavior are not contained in the parameter space still should be detectable by looking for model signatures : apparent disagreements between classes of observations that drive the addition of the missing parameters ( for example see  @xcite ) .",
    "using an archive of pre - computed information , one will be able to determine the confidence regions from an arbitrary set of experiments - without significant new computational cost .",
    "furthermore , one can continue adding resolution to the likelihood function by sampling more points indefinitely , and the parameterization can be adapted as the incoming observational data dictates - allowing for addition and removal of parameters without discarding work already done .",
    "thus the parameter space map resulting from this project will grow and evolve with the data , never becoming redundant .",
    "a fisher matrix analysis suggests that these parameters may perhaps be resolvable by foreseeable future experiments .",
    "several fiducial models were selected , and a joint covariance matrix was calculated for this parameter space using cmb , supernovae luminosity distance and cluster survey data that could conceivably be available in about 10 years . of course it is well known that a fisher matrix analysis can drastically underestimate the error ( confidence region ) , particularly in the presence of parameter degeneracy and non - gaussianity . however , the result that the parameters in this case appear to be able to be resolved well is probably reliable on a qualitative level .",
    "the parameters are physically distinct , as are the types of experimental data .",
    "the low level of correlation in the error may suggest there is not much degeneracy between the parameters when data of this quality is used .",
    "the most important factor in how much we will ultimately be able to learn about the nature of the dark energy is how dynamical it is . as will be shown by the fisher matrix analysis in section 3 , other than late - time parameters @xmath2 and @xmath3",
    ", the parameter error will be much greater for something like a cosmological constant than a tracking quintessence model in which the dark energy has always been a significant fraction of the total energy density .",
    "with such a large dimensionality of cosmological parameter space it is important to maximize the efficiency of the sampling algorithm that will explore this space and determine its likelihood function .",
    "a traditional markov chain approach could be used , but recent results  @xcite suggest that an importance sampling with kernel density estimation algorithm may be superior .",
    "two advantages of importance sampling over markov chains is that independence of points in the former allow for arbitrarily massive parallelism , and no step decorrelation length .",
    "section  2 describes the motivation for pursuing a general and comprehensive approach to elucidating the nature of the dark energy and its physical basis .",
    "section  3 describes the parameter space and physical models to be encompassed by the arda project .",
    "section  4 discusses the computational algorithms to be employed and the advantages they provide .",
    "section  5 describes how experimental data will be modularized .",
    "section  6 summarizes the implications of arda for study of the dark energy and cosmological parameter extraction .",
    "a cosmological constant fits the current data well , but so do many different models of dynamical dark energy .",
    "even if it were determined that the dark energy today is behaving as a cosmological constant , it is reasonable to expect this would merely be an effective model - in the same way that fermi theory , with dimension - full constant @xmath4 , was only an effective theory of the weak interactions .",
    "we must dig deeper to gain an understanding of the underlying physics . because any observation that depends on dark energy parameters necessarily also depends on imperfectly determined parameters of the visible sector",
    ", all cosmological parameters must be estimated simultaneously .",
    "we will need to combine every available piece of cosmological data in a universal joint analysis .",
    "crucially important data will be provided by present ( wmap  @xcite , sdss  @xcite , scp  @xcite , etc ) and future experiments ( planck  @xcite , lsst  @xcite , spt  @xcite , des  @xcite , duo  @xcite , snap  @xcite , jdem , beyond einstein observatories / probes , etc ) .",
    "arda is an ambitious project to create a framework for joint analysis of all cosmological data which will simultaneously yield values for the standard cosmological parameters as well as reveal the nature of the dark energy .",
    "the approach used will automatically make best use of information contained in the correlation of different types of observables ( for example , cmb late isw effect and large scale structure evolution ) .    through joint analysis of all cosmological data",
    ", the arda project will lay the framework to extract the standard cosmological parameters and answer key questions concerning the dark energy :    1 .",
    "what is the value of the dark energy equation of state now ? 2 .",
    "what is the evolutionary history of the dark energy equation of state ? did the dark energy ever track the other energy components ?",
    "if so , did it track like a scalar field ? 3 .",
    "is the background evolution fully characterized by the equation of state ? or does some mechanism transfer energy to or from the dark energy , altering its decay rate ?",
    "4 .   are there measurable dark energy perturbations ?",
    "if so , how have they evolved ?",
    "how do these dark energy perturbations vary with scale ? how are they correlated with matter perturbations ? with metric perturbations ? 6 .",
    "what is the sound speed and anisotropic stress of the dark energy ?",
    "this paper describes a parameter space selected to be economical enough that parameter values may be extracted in the foreseeable future , general enough that a wide variety of classes of dark energy models and types of behavior are encompassed , and physical enough that when we do extract the dark energy parameter values they will teach us about the ( possibly rich ) structure of the dark sector . though the experimental data that will conclusively answer the above questions may be 10 or 20 years away ,",
    "the arda project can begin to explore parameter space immediately , and continue to adapt and improve indefinitely as the volume of data grows .",
    "the arda exploration algorithms and parameterization will be adapted as the data demands .",
    "answers to the above questions will not come easily or quickly , but a systematic joint global approach such as what is outlined here makes maximal use of the data while making minimal theoretical assumptions .",
    "the arda project will allow data from current and future cosmological experiments to be used in a joint fashion to complement one another , constraining a concordance model of the dark energy in cosmological parameter space .",
    "the wide range of different dark energy theories will require a parameter space with a large number of dimensions .",
    "the parameterization should be general , physical , allow one to smoothly vary between different models of the dark energy , and be extensible ( that is , in the course of the analysis the removal or addition of parameters can be done as warranted by the data ) .",
    "arda is adaptable and open - ending - it can be improved indefinitely .",
    "as future observational data becomes available it will incorporated , continually refining the concordance parameter region .",
    "as the concordance model begins to be resolved there will be a natural suggestion of additional parameters to be added to the analysis for further refinement - this is expected and will not render the previous work obsolete .",
    "this project will produce a map from the space of cosmological parameters to the space of `` cosmological results '' .",
    "the term `` results '' means quantities that are observable or determine observables - for example the background expansion rate as a function of redshift , linear perturbation amplitudes of all components as a function of scale and redshift , the cross correlation between those perturbations , the cosmic microwave background anisotropy ( cmb ) , and the likelihood with respect to select experimental data .",
    "such results can be used to predict experiment observations ( exp : supernovae luminosity distances , matter power spectrum , etc ) as a function of point in parameter space . thus with little new computational cost one can transform an arbitrary set of observations into a likelihood function over parameter space .",
    "one can find bounds imposed by all of the data , or by subclasses of the data ( high or low z , large or small scale , etc ) .",
    "there are well - defined statistical tests that can detect if subclasses of the data produce inconsistent parameter bounds .",
    "for example , if one assumed the dark energy equation of state @xmath5 was constant , but then found high - z data favored a value inconsistent with that favored by low - z data , one would be forced to change that assumption and introduce a parameter to describe the evolution of @xmath5 .",
    "the arda parameter space has been chosen according to the following considerations :    1 .",
    "the parameters describing the dark energy must be general enough to encompass the widest range of models that is practical .",
    "the parameter space may include a model as a subspace , or instead it may permit tests for signatures of a model .",
    "minimal assumptions are made with respect to the dark energy - such as stress - energy conservation .",
    "2 .   one should be able to continuously vary the cosmology between dark energy models .",
    "an allowed region will ultimately bound the correct model as a concordance between multiple experimental data sets .",
    "3 .   the parameters should be physically motivated .",
    "physical motivation is important to avoid unphysical parameter combinations , and additionally when a parameter is measured one will learn something about the underlying physics .",
    "4 .   the parameters space should be economical .",
    "a balance must be kept between having a parameter space general enough to contain or allow tests for signatures of the maximum variety of dark energy models , while keeping it small enough enough so that one can obtain meaningful parameter bounds from observable data in the foreseeable future .",
    "the solution is a data - driven approach : allow enough parameters to resolve general classes of effects as the data becomes good enough , but not to allow for time or scale variation of quantities when we can not yet determine their average values .",
    "however , as improved data suggests additional parameters , they are added - a new dimension opens in parameter space .    note that in the assumption of conservation of the dark energy stress - energy tensor , interactions with other components of the universe is not allowed for .",
    "however , one can compare a dark energy ( matter ) decay rate determined from data on background evolution with dark energy ( matter ) pressure determined from data on perturbation growth .",
    "an inconsistency would be a signature for stress - energy non - conservation of a component - energy transfer through an interaction .",
    "although dark energy perturbation data will be weak at best , evidence for dark energy - matter interactions may be extracted from dark matter perturbations .",
    "one may also treat interacting dark energy - matter as a single fluid , which would then have significant perturbations .",
    "the cosmological parameters to be used in arda are as follows :    general cosmological parameters : hubble constant ( @xmath6 ) , baryon density ( @xmath7 ) , cold dark matter density ( @xmath8 ) , neutrino energy density ( @xmath9 ) , reionization optical depth ( @xmath10 ) , helium-4 density ( @xmath11 ) , number of massless neutrinos ( @xmath12 ) , number of massive neutrinos ( @xmath13 ) , spatial curvature ( @xmath14 ) , primordial scalar perturbation amplitude ( @xmath15 ) , scalar perturbation spectral index ( @xmath16 ) , tensor spectral index ( @xmath17 ) , tensor to scalar perturbation ratio ( @xmath18 ) , scalar index running with scale ( @xmath19 ) , tensor index running with scale ( @xmath20 ) ,    dark energy parameters :    1 .",
    "fraction of critical density in dark energy today : @xmath21 ( dependent parameter ) 2 .",
    "equation of state today : @xmath3 ( @xmath3 may be > , = or < -1 ) 3 .",
    "number of expansion e - folds since tracking behavior ceased , and @xmath5 started to change to present value : @xmath22 . note that @xmath5 may pass through @xmath0 .",
    "4 .   rate of transition of @xmath5 from the tracking value to @xmath3 : @xmath23 5 .",
    "log of the ratio of the dark energy fraction during radiation domination to the fraction during matter domination : @xmath24 6 .",
    "dark energy rest - frame sound speed : @xmath25 7 .",
    "dark energy anisotropic stress : @xmath26    the parameter space will be modified in a data - driven fashion .",
    "for example , we allow the dark energy perturbation rest - frame sound speed ( @xmath25 ) to vary away from unity ( allowing non - scalar field dark energy ) but do not allow it to vary with time or scale . if in the future the data is good enough to resolve @xmath25 , one may observe a disagreement in the favored value between early and late - time data ( there are well - established statistical tests for such a purpose ) .",
    "one then has reason to add new parameters that describe the variation of @xmath25 with time , and the data will good enough to start to resolve those parameters .",
    "furthermore , tracking behavior for the dark energy is allowed , but not required .",
    "it may be eliminated by making @xmath27 large enough so that dark energy fraction before @xmath27 is negligible .",
    "tracking does not assume the dark energy is a scalar field , as @xmath25 and @xmath24 are allowed to vary away from scalar field values ( @xmath28 , @xmath29 ) , and @xmath3 may be @xmath30 .",
    "the following are examples of degrees of freedom not present in the parameter space , but may be added when and if called for by the observational data :    1 .",
    "variation of @xmath25 , @xmath26 with scale or time . 2 .",
    "non - adiabatic initial conditions 3 .   arbitrary splined time dependence of @xmath5 4 .   measurable non - tracking behavior of the dark energy density before @xmath27 .",
    "a standard cosmological constant may be specified , for example , by taking @xmath27 large .",
    "the following list is a sample of dark energy models that can be tested for within the framework of this parameter space .",
    "if their background and perturbation behavior are contained within the parameter space then the test is direct .",
    "otherwise one may test for signatures of those types of behavior not explicitly contained .    1",
    ".   cosmological constant ( constant @xmath31 ) 2 .",
    "simplified quintessence ( constant @xmath32 ) 3 .   simplified quintessence ( like above , but with a constant parameter describing the time variation of @xmath5 , @xmath33 ) 4 .",
    "general tracking quintessence  @xcite : dark energy to background energy density ratio @xmath34 until @xmath27 , then @xmath5 changes to present value @xmath3 .",
    "`` general '' means that a scalar field is not assumed .",
    "general creeping quintessence  @xcite : a dynamical degree of freedom is mimicking a cosmological constant in terms of background behavior now and in the recent past .",
    "because it is dynamical it may have perturbations .",
    "hybrid quintessence potentials : with varying degrees of naturalness , a more complicated scalar field potential yields tracking at high energy and quintessence domination at late times when the field encounters a feature in the potential ( for example albrecht & skordis constructed a model using only planck - scale parameters where a potential is exponential at high energy , but has a low energy minimum  @xcite ) .",
    "these models track at early times and have @xmath35 , @xmath36 , @xmath37 , @xmath38 .",
    "7 .   phantom dark energy ( @xmath39 )  @xcite : the underlying physics of the dark energy causes it to possess or develop a current equation of state @xmath39 .",
    "this violates the dominant energy condition , but perturbation evolution in such models is not necessarily pathological .",
    "cardassian model modifications to general relativity  @xcite : the background is modeled by a possibly time - varying @xmath5 , large @xmath27 ( it is a non - tracker ) .",
    "perturbation evolution is modeled by a non - unity @xmath25 and zero @xmath26  @xcite .",
    "vacuum - driven metamorphosis  @xcite : non - perturbative physics of the vacuum cause a transition to a cosmology that will eventually resemble a cosmological constant with continuous production of radiation .",
    "the background would evolve as dark energy with a @xmath5 that has only recently ( redshift@xmath40 ) become @xmath0 .",
    "quantum effects of a massless , minimally coupled scalar field with quartic self - interaction can cause the field to develop an average equation of state @xmath39  @xcite .",
    "however , current estimates of the magnitude of @xmath41 suggest the background evolution of such a model may be indistinguishable from a cosmological constant .",
    "it is not yet clear how perturbations would behave - this may provide a critical means of distinguishability .",
    "interacting quintessence - dark matter models  @xcite : the quintessence field interacts with one component of the dark matter , causing it to decay at a slower rate .",
    "the interaction also suppresses the kinetic energy of the quintessence field , causing it to drive cosmic acceleration .",
    "because a component of the dark matter clumps like matter but decays like quintessence , one signature of such a model is non - concordance of cmb , supernovae and large scale structure data in terms of the parameters ( @xmath42 , @xmath5 ) ( that is , if one makes the mistaken assumption that everything that clumps like matter decays like matter , then one finds there can be no agreement between the above three classes of observations ) .      an general way to model",
    "the dark energy fluid is as a general , non - interacting fluid that is covariantly conserved within the framework of general relativity .",
    "the background density evolves according to@xmath43 while the perturbations evolve as@xmath44 where @xmath45 is the energy density perturbation , @xmath46 is the momentum perturbation , in ( synchronous , conformal ) gauges the metric perturbations @xmath47@xmath48 , and the dot denotes a derivative with respect to conformal time .",
    "these perturbation equations are based on those appearing in  @xcite , but modified to allow @xmath5 to vary from @xmath32 to @xmath49 smoothly .",
    "the symbols @xmath50 have the same definitions as in  @xcite . for numerical convenience the perturbations",
    "are usually evolved in the dark matter rest frame .",
    "the dark energy sound speed @xmath51 in terms of its value in the dark energy rest frame @xmath25 is approximately  @xcite:@xmath52\\label{eq : cs2_xform}\\ ] ] this is nothing more than a frame transformation .",
    "it is the quantity @xmath25 that we take to be a constant parameter , independent of time and scale .",
    "normally one would take @xmath53 .",
    "however , as a changing @xmath5 passes through @xmath0 the velocity perturbation @xmath54 associated with a finite @xmath55 diverges , and the sound speed transform equation becomes invalid .",
    "physically , there is nothing pathological - @xmath56 and @xmath55 remain finite .",
    "thus we impose an ad - hoc cutoff @xmath57 in @xmath58:@xmath59 testing with several sample models show no observable effect as @xmath57 is varied around @xmath60 . however , a more sophisticated prescription for determining an appropriate value of @xmath57 may be developed as needed .",
    "the reason the sound speed transformation goes singular as @xmath5 passes through @xmath0 is that the dark energy density has reached a minimum value and will start increasing with expansion .",
    "one does not have freedom one otherwise would to decrease the energy density perturbation at given coordinate value on a constant - time hypersurface by deforming that hypersurface point to a later time .",
    "thus eq  [ eq : cs2_xform ] is valid outside of a small interval around @xmath31 .",
    "eq  [ eq : cs2_xcutoff ] is a way of replacing the behavior of the transform inside this interval with an interpolation that matches the transform outside of the interval .",
    "as with the sound speed @xmath51 , without explicit euler - lagrange equations of motion for the dark energy there is some freedom in specifying the anisotropic stress @xmath61 .",
    "one possible choice is to assign a scale and time dependence to @xmath61 that is consistent with viscous damping of velocity perturbations in shear - free frames .",
    "the dependence is further specified by imposing a special boundary condition on the highest mode in the angular moment hierarchy  @xcite .",
    "this boundary condition - inspired by photons and neutrinos - allows the angular moment hierarchy to be truncated at the quadrupole in numerical simulations .",
    "we adopt a slightly modified form of this relation , which allows the perturbation evolution to be continued into the regime where @xmath62:@xmath63 where @xmath64 , @xmath26 is the constant parameter that was above called anisotropic stress and in the ( synchronous , conformal ) gauges the metric perturbation @xmath65 . in the limit",
    "@xmath66 the above relation is identical to equation  12 of  @xcite .",
    "this would apply if the dark energy is tracking during matter - domination . when @xmath67 the above is equivalent to a rescaling of @xmath68 of  @xcite , changing the sign for @xmath62 .",
    "different choices for the anisotropic stress certainly are possible , but any alternate prescription should preserve the physical effect of damping of velocity perturbations for @xmath69 .",
    "a point worth noting is that these equations show a fluid with @xmath31 can have density and momentum perturbations - they simply are not sourced by metric perturbations .",
    "the perturbations may be primordial , or may be sourced in an earlier epoch before @xmath70 . in the case of scalar field quintessence @xmath5 may go to @xmath0 at late times , for example , if the potential becomes flat or the field is caught in a minimum .",
    "these decoupled perturbations then decay away , but could perhaps be measurable today .",
    "in such a way we might hope to distinguish between a fundamental and effective cosmological constant .",
    "a fisher matrix analysis suggests that the arda cosmological parameters may be resolvable by foreseeable future experiments .",
    "five flat fiducial models consistent with current cmb ( wmap  @xcite + other high-@xmath71 data ) , sloan  @xcite and supernovae  @xcite data were selected :    1 .",
    "cosmological constant : @xmath72 , @xmath73 2 .",
    "tracking quintessence : radiation domination : @xmath74 , @xmath75 , matter domination : @xmath76 , @xmath77 , transition to dark energy domination now : @xmath78 , @xmath79 3 .",
    "phantom dark energy : @xmath80 , @xmath81 4 .",
    "tracking quintessence : radiation domination : @xmath74 , @xmath82 , matter domination : @xmath76 , @xmath75 , transition to dark energy domination now as an effective cosmological constant : @xmath72 , @xmath79 5 .",
    "tracking phantom dark energy : radiation domination : @xmath74 , @xmath82 , matter domination : @xmath76 , @xmath75 , transition to phantom dark energy domination now @xmath83 , @xmath79 at late times    all of the tracking models have @xmath84 , @xmath38 and @xmath85 .",
    "none of these fiducial models have any interactions ( other than gravitational ) within the dark sector or between the dark and visible sectors .",
    "models 1 and 3 tracked at very early times , but then ceased tracking at @xmath86 and then begin to behave as a cosmological constant or phantom energy respectively .",
    "while tracking , the fractional energy density of the dark energy ( @xmath87 ) is so small as to make the models effectively a cosmological constant or phantom energy with respect to observations .",
    "a joint covariance matrix was calculated for this parameter space via fisher matrix analysis using data that could conceivably become available within about 10 years :    1 .",
    "cmb : @xmath88 , cosmic variance of @xmath89sky with a minimum noise contribution to the @xmath90 of @xmath91 2 .",
    "supernovae luminosity distance : 8000 , 3% @xmath92 error , @xmath93 3 .",
    "cluster survey : volume - limited , analyzed as @xmath94 independent redshift bands out to @xmath95 as discussed in  @xcite    as can be seen in figure  1 , other than late - time parameters @xmath2 and @xmath3 , the error is much greater for something like a cosmological constant than a tracking quintessence model in which the dark energy has always been a significant fraction .",
    "for the dark energy to be a significant fraction in the early universe a dynamical model such as tracking quintessence seems likely .",
    "for this reason , the more similar the dark energy is to a non - dynamical cosmological constant , the less we will learn about the underlying physics . our ultimate success in understanding the physical nature of the dark energy will most directly depend on how fortunate we are .",
    "of course the usual fisher matrix caveats apply - the true confidence region can be significantly underestimated , particularly in the presence of parameter degeneracy and non - gaussianity .",
    "however , it should be noted that this analysis treated the experiments as independent and hence discarded information from the correlation between the experiments - arda will automatically incorporate this information .",
    "still , the proper way to determine the confidence region would be to perform an analysis such as what arda will ultimately do - were such a result available now something like arda would already have been completed .",
    "however , the three types of experimental data are the product of very different physical processes and the data is very precise , leading one to expect they are unlikely to share degeneracies .",
    "additionally , the parameters are very distinct physically . within the tracking models , for which the parameters are best resolved",
    ", the fisher matrix analysis indicates a low level of correlation between parameters , which may suggest there is not much degeneracy . though one should not trust the fisher matrix results quantitatively , it is probably qualitatively reliable that the parameters will ultimately be accurately resolved - particularly for tracking models .",
    "figure 1 : shown are the fisher matrix 1@xmath61 error ellipses ( with means subtracted ) of the independent dark energy parameters .",
    "the hypothetical observational data is cmb , deep volume - limited cluster survey power spectra , and supernovae luminosity - distances .",
    "the cosmological constant model is black , phantom energy violet , tracking with @xmath78 red , tracking with @xmath96 green , and tracking with @xmath80 blue .",
    "the parameter symbols are as follow : @xmath97 is current dark energy equation of state , @xmath27 is the number of expansion e - folds since tracking ceased , @xmath98 is the rate of change of the dark energy equation of state to its current value ( @xmath99 ) , @xmath100is the dark energy sound speed , and @xmath24is the log of the radiation domination dark energy density fraction multiple .",
    "figure 1 ( cont )",
    "the likelihood function in the @xmath101 dimensional parameter space will be constructed by sampling the space over a large number of points .",
    "a markov chain sampling algorithm could be used for this purpose .",
    "recent results - described in detail in  @xcite - suggest that importance sampling may be a superior algorithm for cosmological parameter estimation .",
    "importance sampling draws a large number of points from an ( estimated ) proposal distribution , and calculates the actual ( unnormalized ) likelihood at each point . the proposal distribution for the next iteration",
    "is constructed by kernel density estimation ( kde ) as a sum of gaussian distributions ( kernels ) - each point of the previous iteration is replaced by a gaussian kernel of weight determined by the ratio of the previous proposed and actual likelihoods .",
    "a convergence test is the correlation between the proposed and actual likelihoods .",
    "thus ultimately the underlying distribution in parameter space is approximated by a large number of overlapping gaussian distributions .",
    "the final proposal likelihood function agrees with the underlying likelihood , and the fact that it is a smooth and continuous function is very useful for further analysis .",
    "even if a markov chain algorithm is used for sampling , kernel density estimation will still be used for analysis purposes .    in the case of arda , the underlying distribution - hereafter referred to as the arda base distribution - will be that of recent cmb experiments ( wmap and others ) .",
    "the current plan is that no non - cmb data will used for the base distribution . for each point",
    "the following will be archived : the parameter values , proposed & actual likelihoods , the cmb spectra , and density power spectra & transfer functions of all components over a wide range of redshift and scale .",
    "thus for each parameter space point , a hypothetical observation for a given experiment can be computed later with minimal cost .",
    "the set of parameter space points will converge to the likelihood function of the current cmb data .",
    "this likelihood can be multiplied by the likelihood function of any arbitrary set of other cosmological experiments .",
    "conceptually , this can be done by re - weighting the parameter space points or kernels - each point is assigned a weight equal to the product of its likelihood in each of the set of experiments . in this way",
    "any set of experiments can be added as if they were a prior , but after the fact .",
    "it is important to be able to find the confidence regions in parameter space for many different combinations of observational datasets .",
    "one reason is to test for disagreement between large vs. small scale observational data , and high vs. low z - an indication that a presumed constant parameter in fact varies .",
    "thus it is desirable to compute the arda base likelihood distribution with the minimal amount of data that will still result in an accurate resolution of the structure of the likelihood function .",
    "removal of a dataset from the base distribution ( by necessity through deconvolution - that is , positive re - weighting ) should be avoided because the tails of the distribution may not be as well covered ( sampled ) .",
    "thus , experiments used in the base distribution should be those that one would rarely - preferably never - want to remove .",
    "however , the base distribution should be sufficiently constrained so that it is well sampled - particularly the degeneracies need to be resolved well . for arda the choice of cmb - only data as the data determining the base distribution",
    "is thought to be fairly optimal , but as the project develops this presumption will be tested and changed if necessary .    as an example of the potential of alternate methods for exploring parameter space ,",
    "consider importance sampling algorithms .",
    "with importance sampling the points drawn from the proposal distribution in a single iteration are statistically independent - meaning they may be computed massively in parallel . in recent testing , with surplus time on a retiring ncsa cluster ( 200 - 600",
    "pentium iiis used at a time ) , it was shown that rates in excess of @xmath102 points per day are possible .",
    "as a comparison , the wmap cmb - only parameter extraction was done with somewhat more than 30,000 markov chain points  @xcite .",
    "a markov chain must proceed sequentially because the coordinates of the next point can not be determined until the likelihood of the current point has been computed .",
    "a contingency set of points can be simultaneously precomputed , but this is inefficient : for @xmath103 steps of precomputation @xmath104 points are computed , @xmath103 are used and the rest discarded .",
    "with an importance sampling algorithm , massive numbers of cheap , slow computers can be used for unlimited parallelism . additionally , there is no correlation length in the point sample .",
    "depending on the dimensionality and other factors , cosmological parameter estimation markov chains typically need to be thinned by a factor of order @xmath105 to obtain a truly uncorrelated sample of the underlying distribution - yielding @xmath28% efficiency .",
    "importance sampling does not have this problem because the entire sample is drawn from a distribution that does not depend on any of the points in that sample .",
    "further investigation may show that these features , coupled with the availability of cpu time on cheap and slow computers , expedite the convergence of the arda base distribution and thus are significant advantages of importance sampling over markov chains .",
    "however , if no sampling algorithm can be found that yields convergence of the arda base distribution in a reasonable amount of time , additional observational data can be used along with the cmb to reduce parameter degeneracy and shrink confidence regions .",
    "a disadvantage is that the additional prior may not be able to be removed ( ie : deconvolved ) while keeping good point coverage of parameter space with a fixed number of points ( were this possible , one would not need the additional prior ) . initially this project will primarily use standard dedicated supercomputer time .",
    "this may be supplemented by cpu from otherwise idle workstations .",
    "a server - client model is being developed that will allow a user to donate their idle workstation cpu time to this project by running the client in the background - much in the same way as seti@home works . though it is not relied upon ,",
    "there is a potential to tap a vast quantity of unused cpu time",
    ". such a scenario might not be feasible if the sampling algorithm is a markov chain , however it would be ideally suited to importance sampling .",
    "a principle concern with such a large dimensionality of parameter space is whether the sampling algorithm can resolve degeneracies in the base distribution .",
    "there will be parameter space degeneracies in the cmb - the concern is that the degeneracies might not be `` found '' or sufficiently well sampled by the sampling algorithm due to them having a large volume and complicated structure .",
    "note that a poorly constrained but uncorrelated parameter is not a problem - this will simply result in the kernel size being large in this direction , and resolution of the other parameters will not be degraded .",
    "clearly a definite answer to this degeneracy issue requires knowing the nature and extent of the parameter degeneracies - which in turn requires that one has fully explored the likelihood function of current cmb experiments in this parameter space .",
    "thus , at the beginning of the arda project there is no definite answer .",
    "however , one can pick physically distinct parameters , hope that the degeneracies do not prove problematic , and adjust one s strategy to compensate if they do . one could argue that fewer number of parameters would yield more predictive power .",
    "however , if the parameter space considered does not contain the true model nor a `` signature '' model , the joint analysis may never converge to physically meaningful result .",
    "the additional `` predictive power '' is then an illusion - in reality there is less predictive power .",
    "furthermore , the goal is not to rule out or rule in a particular model , but rather to lay down a framework for looking for signatures of classes of behavior ( for example , the dark energy tracking the other components ) .",
    "given that we do not know what the dark energy is , it would be unwise to risk incorrect assumptions implicit in the choice of parameter space that artificially prevent interesting behavior from being sampled .",
    "for example , if one used a parameter space limited to minimally coupled scalar field models of dark energy , and the dark energy had some characteristics consistent with this assumption ( tracking ) and some inconsistent with this ( present equation of state @xmath30 ) one might falsely rule out the tracking - and in the end be entirely mislead in understanding the underlying physics .",
    "another key aspect of arda is its flexibility : at a given moment a variety of different analysis procedures can be performed ( mixing different observational datasets , parameter restrictions with various theoretical priors ) and it can also evolve over time to adapt to changes in our understanding of cosmology and questions concerning the dark energy ( addition of new observational data , addition / removal of parameter space dimensions , continually improving sampling , etc ) .",
    "the entire parameter space need not be used in an analysis - one can instead operate on theoretically - constrained subsurface .",
    "for example , a running tensor index will not be strongly constrained alone . however",
    ", if one assumes a theoretical framework that relates the running of the scalar and tensor indexes , then one constrains the analysis to a sub - surface of the full parameter space .",
    "though no points will likely reside exactly on this surface , kernel density estimation gives a continuous , smooth , analytic functional form for the likelihood function over the full space .",
    "every sub - space will therefore have an induced likelihood distribution on it .",
    "this induced likelihood distribution will be used when theoretical priors or constraints reduce the dimensionality of the full parameter space .",
    "if the induced kernel density on a parameter subsurface does not sufficiently sample the underlying distribution , the sampling algorithm can be run on that subsurface alone .",
    "also , as observations improve and quantity and quality , more will be discovered about the dark energy and the nature of the current questions will change .",
    "some parameters will be resolved to the extent that they can be fixed and their range removed from the analysis , while some new parameters will need to be added",
    ". a new dimension can easily be added as a new importance sampling iteration begins by `` puffing '' the distribution into the new parameter dimension : one simply a - priori assigns a kernel size centered on the previous assumed value of that parameter .",
    "points in the following iterations will drift into the new direction and increasingly reflect the underlying distribution . in this way it is expected that the arda system will never become redundant - instead continuing to be an invaluable tool into the indefinite future .",
    "the arda point dataset ( parameter values plus cosmological `` result '' of each point ) will be made available to the scientific community .",
    "ultimately this will develop into an analysis software tool that will allow the user to select an arbitrary set of experiments , and optionally a subsurface of parameter space .",
    "as new experiments are conducted , the experimental groups will be encouraged to provide their results in a format suitable for inclusion into this analysis tool and shared with the rest of the community . for an experiment to be added ,",
    "one only needs a function to be provided that maps a point in cosmological parameter space ( possibly using the associated cmb , power spectra , etc ) to an ( unnormalized ) likelihood for that experiment",
    ". the analysis software can be distributed , or made available as a webpage . a working proof - of - concept prototype , can be viewed at _ .",
    "_ the parameter space point set is several markov chains that were created to show how cmb data , with and without additional observational data and a theoretical bbn constraint , can resolve the primordial abundance of @xmath106  @xcite .",
    "the parameter space and available experiments are much more limited than arda , but this website demonstrates the working concept for what will be developed .",
    "additionally , a public outreach component is planned as a front - end for the arda analysis webpage : a series of webpages will act as a tutorial on cosmological parameter extraction for the interested general public . a visitor will be able to read the tutorial to gain an understanding of cosmology , the significance of the cosmological parameters , the cosmological experiments and the statistical methods used to extract allowed ranges of the parameters .",
    "finally the visitor will be able to use the actual parameter extraction website .",
    "this will educate the general public about cosmology and cosmological parameter extraction , as well as build an appreciation for experiments and encourage donation of cpu time .",
    "a key feature of arda will be that it will allow likelihood functions to be determined for an arbitrary set of experiments with little or insignificant re - computational cost .",
    "in addition to performing parameter extraction with every available dataset , the user will be able to mix and match datasets .",
    "this is useful to determine the influence of real and hypothetical experiments , as well as measure tension between competing datasets .",
    "for example , apparent inconsistency between large vs small scales , or early vs late time data could suggest that an assumption of scale / time independence of a parameter is incorrect .",
    "in such a case one could attempt to relax the tension by introducing a new parameter to describe the scale / time variation .",
    "such tests are key to furthering our understanding of the dark sector , and it must not be computationally prohibitive to perform a wide variety of such tests with different parameters and parameter combinations . in the arda system there",
    "will already be precomputed spectra and measured quantities for each parameter space point .",
    "thus when a dataset is applied most of the computational work is already done .",
    "the author envisions each experimental dataset available in arda will be a module - at the core will be a likelihood functional which will take as input cosmological parameters and associated precomputed spectra , and as output produce an unnormalized likelihood for that experiment . the arda user can make any choice of which experiment modules to use for a given run .",
    "a working example of this modularity can been seen in cosmomc  @xcite - it is distributed with some experimental datasets included .",
    "the user can choose any of these as additional weighting of the markov chain point likelihood .",
    "initially the dataset modules will be created by the arda maintainers , but eventually it is hoped that the research group running an experiment will provide them .",
    "arda will be an important framework for combining all cosmological data to do the best possible job of parameter extraction - maximizing what experimental data can teach us about our universe , the dark energy and the physics underlying it .",
    "also , the hypothetical datasets of a future experiment can be analyzed to determine how to maximize it s impact in conjunction with existing data .",
    "parameter confidence regions can be determined for an arbitrary set of observational datasets without significant recomputation cost .",
    "if the correct model of dark energy is contained in the arda parameter space , improved data will tighten the concordance region about it .",
    "otherwise , as the data improves signatures of the correct model will become apparent - such as tension between classes of observations - which will direct us how to enlarge parameter space to include the correct model .",
    "one possible sampling algorithm to be used by arda , importance sampling / kernel density estimation , may prove to possess significant improvements over traditional markov chain algorithms in flexibility , parallelism and efficiency .",
    "arda will be economical ( new experiments can added with minimal computational cost ) , general ( experiments can be mixed and matched in an arbitrary manner ) , extensible ( new points can be added indefinitely ) , adaptable ( new parameters can be added ) , reducible ( theoretical priors can be used to study parameter constraints on lower dimensional subspaces ) and the parameter range is well motivated and physical ( a wide range of cosmological models are allowed ) . there is no reason for this analysis tool to ever become obsolete - it can continue to be used indefinitely , be adapted , and grow in predictive power as each new experiment is incorporated .",
    "the scientific community can assist the development of arda in two ways : by creating experiment modules , and by donating cpu from otherwise idle computers .",
    "interested parties should email .",
    "the author wishes to thank benjamin wandelt and david larson for useful discussions , and as collaborators in a more detailed treatment of is / kde as a cosmological parameter extraction tool  @xcite , antony lewis , anthony challinor and anthony lasenby for useful discussions and the camb code  @xcite , joe mohr and sarah bridle for useful discussions , and uiuc for support .",
    "10 t. d. saini , j. weller and s. l. bridle , mon.not.roy.astron.soc . 348",
    "( 2004 ) 603 a. e. raftery , j. amer .",
    "assoc . , 91 : 132 - 41 .",
    "( 1996 ) d. larson , g. huey and b. wandelt , in preparation d. n. spergel et al .",
    ", astrophys.j.suppl . 148 ( 2003 ) 175 m. tegmark et al .",
    ", astrophys.j .",
    "606 ( 2004 ) 702 - 740 r. a. knop et al .",
    ", astrophys.j . 598",
    "( 2003 ) 102 planck collaboration , http://www.rssd.esa.int/index.php?project=planck j. a. tyson et al .",
    ", 5th international ucla symposium on sources and detection of dark matter proceedings ; astro - ph/0209632 j. e. ruhl et al . , proceedings of the spie v5498 des collaboration , http://cosmology.astro.uiuc.edu/des/ duo collaboration , http://duo.gsfc.nasa.gov/ snap collaboration , astro - ph/0405232 , http://snap.lbl.gov/ e. j. copeland , a. r. liddle , and d. wands , phys .",
    "d 57 ( 1998 ) 4686 - 4690 ; g. farrar and j. peebles , astrophys.j . 604 ( 2004 ) 1 - 11",
    "p. j. steinhardt , l. wang , and i. zlatev , phys .",
    "d 59 ( 1999 ) 123504 g. huey , j. e. lidsey , phys . lett .",
    "b514 ( 2001 ) 217 - 225 a. albrecht and c. skordis , phys .",
    "84 ( 2000 ) 2076 - 2079 robert r. caldwell , phys .",
    "b 545 ( 2002 ) 23 - 29 ; robert r. caldwell , marc kamionkowski and nevin n. weinberg , phys .",
    "91 ( 2003 ) 071301 k. freese and m. lewis , phys .",
    "b 540 ( 2002 ) 1 - 8 p. gondolo and k. freese , phys . rev .",
    "d * 68 * 063509 ( 2003 ) l. parker and a. raval , phys .",
    "86 , 749 ( 2001 ) v. k. onemli and r. p. woodard , class .",
    "( 2002 ) ; v. k. onemli and r. p. woodard , phys . rev .",
    "d 70 ( 2004 ) 107301 ; t. brunier , v. k. onemli and r. p. woodard , class .",
    "( 2005 ) g. huey and b. d. wandelt , astro - ph/0407196 , submitted to prl s. m. carroll , m. b. hoffman , and m. trodden , phys .",
    "d 68 , 023509 ( 2003 ) ; g. w. anderson , s. m. carrol , astro - ph/9711288 ; j. a. casas , j. garcia - bellido , and m. quiros , class . quantum grav .",
    "9 , 1371 ( 1992 ) ; l. amendola , phys .",
    "d 62 , 043511 ( 2000 ) ; l. amendola , d. tocchini - valentini , phys . rev .",
    "d 64 , 043509 ( 2001 ) ; l. amendola , mon . not .",
    "342 , 221 ( 2003 ) ; m. pietroni , phys . rev .",
    "d 67 , 103523 ( 2003 ) ; d. comelli , m. pietroni , and a. riotto , phys . lett .",
    "b 571 , 115 ( 2003 ) ; urbano franca , rogerio rosenfeld , astro - ph/0308149 g. huey , l. wang , r. dave , r. r. caldwell , p. j. steinhardt , phys.rev . d59 ( 1999 ) 063005 g. huey , r. tavakol , phys.rev.d * 65 *",
    "043504 ( 2002 ) g. huey , s. alexander , l. pogosian , phys.rev.d * 65 * 083001 ( 2002 ) g. huey , r. h. cyburt , b. d. wandelt , phys.rev.d * 69 * 103503 ( 2004 ) c. ma and e. bertschinger , astrophys.j .",
    "455 7 - 25 ( 1995 ) j. weller , a. m. lewis , mon.not.roy.astron.soc .",
    "346 987 - 993 ( 2003 ) w. hu , d. scott , n. sugiyama , and m. white , phys.rev.d * 52 * , 5498 ( 1995 ) w. hu and z. haiman , phys.rev.d * 68 * , 063004 ( 2003 ) l. verde et al .",
    ", astrophys.j.suppl .",
    "148 195 ( 2003 ) a. lewis and s. bridle , phys.rev .",
    "d66 103511 ( 2002 ) ; http://cosmologist.info/cosmomc/ a. lewis , a. challinor and a. lasenby , astrophys.j .",
    "538 473 - 476 ( 2000 )"
  ],
  "abstract_text": [
    "<S> a data - driven approach to elucidating the nature of the dark energy , in the form of a joint analysis of a full set of cosmological parameters , utilizing all available observational data is proposed . </S>",
    "<S> a parameterization of a generalized dark energy is developed with the extension of fluid perturbation theory to models which cross through an equation of state of @xmath0 . </S>",
    "<S> this parameterization is selected to be general enough to admit a wide variety of behavior , while still being physical and economical . a fisher matrix analysis with future high - precision cmb , cluster survey , and snia data suggests the parameters will probably be resolvable in the foreseeable future . </S>",
    "<S> how accurately the parameters can be determined depends sensitively on the nature of the dark energy - particularly how significant of a fraction of the total energy density it has been in the past . </S>",
    "<S> parameter space will be sampled at a large number of points , with cosmological information such as cmb , power spectra , etc of each point being archived . </S>",
    "<S> thus the likelihood functions of an arbitrary set of experiments can be applied to parameter space with insignificant new computational cost , making a wide variety of analyses possible . </S>",
    "<S> the resulting tool for analysis and resolution of dark - sector attributes , arda , will be highly versatile and adaptable . </S>",
    "<S> arda will allow the scientific community to extract parameters with an arbitrary set of experiments and theoretical priors , test for tension between classes of observations and investigate the effectiveness of hypothetical experiments , while evolving in a data - driven manner . a proof - of - concept prototype web - tool , , is already available . </S>"
  ]
}