{
  "article_text": [
    "data management systems , like database , information retrieval ( ir ) , information extraction ( ie ) or learning systems , store , organize , index , retrieve and rank information units , like tuples , objects , documents , items .",
    "a wide range of applications of these systems have emerged that require the management of uncertain or imprecise data .",
    "important examples of data are sensor data , webpages , newswires , imprecise attribute values . what is common to all these applications is uncertainty and then that they have to deal with decision and statistical inference .",
    "ranking is perhaps the most crucial task performed by the data management systems which have to deal with uncertainty . in many applications , ranking aims at deciding or inferring , for example ,",
    "the class assigned to a unit or the order by relevance , usefulness , or utility of the units delivered to another application or to an end user .",
    "in addition , ranking is performed to decide whether a unit is placed at a given rank .",
    "the management of imprecise data require means for ranking information units by probability .",
    "ranking places information units in a list ordered by a measure of utility , cost , relevance , etc .. a probability theory measures the uncertainty of the decision . to this end , the definition of an event space and the estimation of probabilities are necessary steps for representing imprecise data and making predictions within many contexts of data management like machine learning , information retrieval or probabilistic databases .",
    "the measurement of the imprecision and the uncertainty in the data leads to the definition of regions of acceptance of a predefined set of hypotheses , thus bringing many decision problems to the calculation of a probability of detection and of a probability of false alarm .",
    "although the data management systems reach good results thanks to classical probability theory and parameter tuning , ranking is far from being perfect because useless units are often ranked at the top or useful units are missed .",
    "classical probability theory describes events and probability distributions using sets and set measures , respectively , according to kolmogorov s axioms  @xcite .",
    "in contrast , quantum probability theory describes events and probability distributions using hermitian operators in the complex hilbert vector space .",
    "whereas parameter tuning is performed within a fixed probability theory , the adoption of quantum probability entails a radical change . furthermore , whereas classical probability is based on sets such that the regions of acceptance or rejection are set - based detectors ( i.e. , indicator functions ) , quantum probability is based on subspace - based detectors and the detectors are projector - based .",
    "note that the use of quantum probability does not imply that quantum phenomena are investigated in the paper ; we are interested in the formalism based the hilbert vector spaces instead .",
    "the main question asked in the paper is whether further improvement may be obtained if the classical probability theory is replaced by the quantum probability theory .",
    "the paper shows that ranking information units by quantum probability yields different outcomes which are in principle more effective than ranking them by classical probability given the same data available for parameter estimation .",
    "the effectiveness is measured in terms of probability of detection ( also known as recall or power ) and probability of false alarm ( also known as fallout or size ) .",
    "we structure the paper as follows .",
    "section  [ sec : class - prob - quant ] illustrates the basics of the probability theory through a view that encompasses both theories .",
    "section  [ sec : quant - prob - detect ] compares quantum detection with classical detection .",
    "section  [ sec : optim - rank - quant ] shows that the ranking by quantum probability more effective than the ranking by classical probability .",
    "section  [ sec : interpr - quant - proj ] provides an interpretation of the projectors which define the regions of acceptance and rejection .",
    "section  [ sec : impl - rank ] describes the algorithm for ranking information units by quantum probability .",
    "section  [ sec : related - work ] provides an overview of the related work .     onto @xmath0 . ]",
    "in this section , we introduce a special view of probability distributions for the classical theory of probability .",
    "the same view is also introduced for quantum probability , which is a non - classical theory and does not admit the distributive law , to provide a general framework for quantum and classical probabilities ; the view is depicted in figure  [ fig : correspondence ] .    before introducing the view of probability theory ,",
    "some basic definitions are provided .",
    "a probability space is a set of mutually exclusive events such that each event is assigned a probability between @xmath1 and @xmath2 and the sum of the probabilities over the set of events is @xmath2 .",
    "for the sake of clarity , we introduce the case of binary event spaces because it is the simplest and most common in data management  ",
    "keyword occurrence in webpages , binary features in sample records or binary attribute values in relational tables are some examples .",
    "the case of binary event spaces are usually represented by mutually exclusive scalars like @xmath1 and @xmath2 .",
    "if binary scalars are used , the mutual exclusiveness is given by the scalar product , for example , @xmath3 ( see  @xcite ) .    whereas the scalars @xmath4 is a possible representation of events , the vectors of a complex finite - dimensional",
    "are another option .",
    "when using vectors , an event is @xmath5 and its complement is @xmath6 .",
    "the representation of the events must encode the mutual exclusiveness .",
    "if binary vectors are used , the mutual exclusiveness is given by the inner product , i.e. , @xmath7 .",
    "when the event space is not binary ( e.g. , when the events are represented by @xmath8 natural numbers @xmath9 ) , a binary representation can again be used .",
    "the vector @xmath10 is assigned to symbol @xmath1 , the vector @xmath11 is assigned to symbol @xmath2 , and so on until @xmath12 is assigned to symbol @xmath13 .",
    "whatever the representation is used , the inner product between two vectors must be @xmath1 and their norm must be @xmath2 .",
    "the mapping between the probabilities and the events is called `` probability distribution '' which is a function mapping a mathematical object which represents an event to a real number ranging between @xmath1 and @xmath2 . the difference between classical probability and quantum probability ; the difference is due to the way the event space and the probability distribution are represented .",
    "the starting point of the view of probability used in the paper is the algebraic form of the probability space . to this end , hermitian ( or self - adjoint ) linear operators are used . in quantum mechanics , `` operator '' is preferred to `` matrix '' yet in the paper , for the sake of clarity , `` matrix '' is preferred because , for a fixed basis , the matrices are isomorphic to the operators .",
    "a matrix is hermitian when it is equal to its conjugate transpose .",
    "hermitian matrices are important because their eigenvalues are always real .",
    "in particular , hermitian matrices with trace @xmath2 is the key notion in quantum probability because the sum of the eigenvalues is @xmath2 and , thus , the eigenvalues can be viewed as a probability distribution .",
    "the projector is an idempotent hermitian matrix .",
    "every subspace has one projector and then the projectors are 1:1 correspondence with the subspaces .",
    "each vector corresponds to one projector with rank one defined as the outer product of the vector by its conjugate transpose .",
    "there are two main instructions for representing events using projectors :    * the projectors must be mutually orthogonal for representing the mutual exclusiveness of the events , and * the projectors must have trace @xmath2 for making probability calculation consistent with the probability axioms .    an event space and a probability function defined over it are represented using hermitian matrices with trace @xmath2 . in particular , a projector represents an event and an event space is modeled by a collection of projectors . as the union of the events results in the whole event space , the sum of the projectors of a collection corresponding to an event space results in the unity . more specifically ,",
    "if @xmath14 is a collection of mutually orthogonal projectors , @xmath15 the latter being termed `` resolution to the unity '' .",
    "for example , using the dirac notation introduced in appendix  [ sec : dirac - notation ] , the projector of two events are represented by @xmath16 0      \\end{array }    \\right )    \\qquad    { |0\\rangle } =    \\left (      \\begin{array}{c }        0 \\\\ [ 5pt ] 1      \\end{array }    \\right)\\ ] ] and @xmath17        0 & 0      \\end{array }    \\right )    \\qquad    { |0\\rangle\\langle0| } =    \\left (      \\begin{array}{cc }        0 & 0 \\\\ [ 5pt ]        0 & 1      \\end{array }    \\right)\\ ] ] however , there is not a unique representation of an event space .",
    "for example , the following vectors are also representing mutually exclusive events : @xmath18         \\frac{1}{\\sqrt{2 } }       \\end{array }    \\right )    \\qquad    \\left (      \\begin{array}{r }        \\frac{1}{\\sqrt{2 } } \\\\ [ 5pt ]         -\\frac{1}{\\sqrt{2 } }       \\end{array }    \\right)\\ ] ] thus leading to a different resolution to the unity given by the following projectors @xmath19        \\frac{1}{2 } & \\frac{1}{2 }      \\end{array }    \\right )    \\qquad    \\left (      \\begin{array}{rr }        \\frac{1}{2 } & -\\frac{1}{2 } \\\\ [ 5pt ]        -\\frac{1}{2 } & \\frac{1}{2 }      \\end{array }    \\right)\\ ] ] the second kind of hermitian matrix of a probability space is the density matrix ; the density matrix encapsulates the probability values assigned to the events . in physics",
    ", a density matrix represents the _ state _ of a microscopic system , such as a particle , a photon , etc .. the structure of a microscopic system is unknown . yet",
    "a device can measure the system to obtain some information .",
    "a microscopic system is similar to a urn of colored balls .",
    "the internal composition of the urn is always unknown even if opened and observed because the device disturbs the state ( i.e. , the distribution of the colors ) of the urn .    in data management and in other domains different from particle physics , a system is macroscopic instead .",
    "examples of macroscopic systems in data management are webpages , customers , queries , clicks , tuples , attributes , and so on .",
    "the states of these systems correspond to the probability densities according to which keywords , reviews , attribute values are observables to be measured from such systems .",
    "density matrices are a powerful formalism in the macroscopic worlds too because they allow us to introduce the algebraic approach adopted for incorporating the more powerful probability space and decision rule suggested in the paper .    to the end of introducing the way density matrices",
    "are defined , consider two equiprobable events , e.g. , the occurrence of a feature or a positive / negative customer review .",
    "the probability distribution is @xmath20 where each value refers to an event . as an alternative to a list",
    ", the probability distribution can be arranged along the diagonal of a two - dimensional matrix and the other matrix elements are zeros .",
    "for example , the matrix corresponding to the probability distribution of two equally probable events is @xmath21        0 & \\frac{1}{2 }      \\end{array }    \\right)\\ ] ] in general , the probability distribution @xmath22 of a @xmath8-event space can be written as @xmath23        0      & p_2    & \\cdots     & 0      \\\\ [ 5pt ]        \\vdots     & \\vdots & \\ddots     & \\vdots\\\\ [ 5pt ]        0      & 0 & \\cdots     & p_k    \\\\ [ 5pt ]    \\end{array }    \\right)\\ ] ] a probability distribution is _ pure _ when the density matrix is a projector , otherwise , the distribution is _",
    "mixed_. a distribution is mixed when the density matrix is a mixture of density matrices ; a pure distribution is an instance of mixture with one matrix .",
    "the density matrix representing a pure distribution is 1:1 correspondence with a density vector such that the projector is the outer product between the vector and its conjugate transpose .",
    "a classical probability distribution is pure when the probability is concentrated on a single elementary event which is the certain event and then has probability @xmath2 .    given a density matrix , the spectral theorem helps find the underlying events and the related probabilities .",
    "because of the importance of the spectral theorem , we provide its definition below :    [ sec : class - prob - quant-1 ] to every hermitian matrix @xmath24 on a finite - dimensional complex inner product space there correspond real numbers @xmath25 and rank - one projectors @xmath26 so that the @xmath27 s are pairwise distinct , the @xmath28 are mutually orthogonal , @xmath29 , @xmath30 and @xmath31 .    see  @xcite .",
    "the eigenvalues are the spectrum and @xmath26 are the projectors of the spectrum of @xmath24 . from theorem  [ sec : class - prob - quant-1 ] , thus , a pure distribution is always a rank - one projector .",
    "the spectral theorem says that any hermitian matrix corresponding to a distribution can be decomposed as a linear combination of projectors ( i.e. pure distributions ) where the eigenvalues are the probability values associated to the events represented by the projectors .",
    "the eigenvalues are real because the decomposed matrix is hermitian , are non - negative and sum to @xmath2 . for example",
    ", when the matrix corresponding to the distribution of two equally probable events is considered , the spectral theorem says that @xmath21        0 & \\frac{1}{2 }     \\end{array }    \\right )    =    \\frac{1}{2 }    \\left (      \\begin{array}{cc }        1 & 0 \\\\ [ 5pt ]        0 & 0     \\end{array }    \\right )    +    \\frac{1}{2 }    \\left (      \\begin{array}{cc }        0 & 0 \\\\ [ 5pt ]        0 & 1     \\end{array }    \\right)\\ ] ] a mixed distribution have more non - zero eigenvalues , a pure distribution has a single eigenvalue @xmath2 .    in classical probability , every pure distribution represented by a diagonal density matrix corresponds to a projector .",
    "however , in general , a density matrix is not necessarily diagonal , yet the matrix is necessarily hermitian .",
    "for example ,   are trace - one projectors and correspond to pure distributions , thus there is a certain event ( with probability @xmath2 ) and an impossible event ( with probability @xmath1 , of course ) . yet , they are not diagonal .",
    "when , for example , keyword occurrence in webpages is represented , the first projector may be assigned eigenvalue @xmath2 and the other is assigned eigenvalue @xmath1 .",
    "thus the former represents the certain event and the latter represents the impossible event in the probability space .",
    "when using the algebraic form to represent probability spaces , the function for computing a probability is the trace of the matrix obtained by multiplying the density matrix by the projector corresponding to the event .",
    "the usual notation for the probability of the event represented by projector @xmath32 when the distribution is represented by density matrix @xmath33 is @xmath34 also known as born s rule  @xcite .",
    "for example , when @xmath35 @xmath36      0 & \\frac{1}{2 }    \\end{array } \\right ) \\qquad \\mathbf{e } =   \\left (    \\begin{array}{cc }      1 & 0 \\\\ [ 5pt ]      0 & 0    \\end{array } \\right)\\ ] ] the probability is @xmath37        0 & \\frac{1}{2 }      \\end{array }    \\right )    \\left (      \\begin{array}{cc }        1 & 0 \\\\ [ 5pt ]        0 & 0      \\end{array }    \\right ) \\right ) = { \\mathrm{tr}}\\left (    \\left (      \\begin{array}{cc }        \\frac{1}{2 } & 0 \\\\ [ 5pt ]        0 & 0      \\end{array }    \\right ) \\right ) = \\frac{1}{2}\\ ] ] when @xmath38 is a rank - one projector , the trace - based probability function can be written as @xmath39 when @xmath33 is a rank - one projector @xmath40 , then @xmath41 from the example , the definition of a function that computes the probability of an event when the probability is already allocated in the diagonal of the density matrix may be odd .",
    "however , we have shown that not all the density matrices corresponding to a distribution need to be diagonal matrices and the diagonal elements do not necessarily correspond to probability values , although they do have to sum to @xmath2 .",
    "a density matrix encapsulate the values assigned to the events by a probability function because of gleason s theorem stated below and proved in  @xcite .    to every probability distribution on the set of all projectors in a complex vector space with dimension greater than @xmath42",
    "there corresponds a unique density matrix @xmath33 on the same vector space for which the probability of the event represented by a projector @xmath43 is @xmath44 for every unit vector @xmath45 in the vector space .",
    "basically , the theorem tells us that corresponding to a probability distribution is one density matrix such that the probability of any event represented as a projector is calculated by the trace function .    the probability of an event when computed using a mixture differs from the probability computed using a pure state , yet they share the classical probability term whereas the difference is called _ interference term_. using a mixture , @xmath46        0 & |a_0|^2         \\end{array }    \\right)\\ ] ] using superposition , @xmath47 where @xmath48 and @xmath49 is the angle of the polar representation of the complex number @xmath50 .",
    "suppose , as an example , that @xmath51 represents the event `` the keyword occurs '' and the density matrix represents the probability distribution of keyword occurrence in useful webpages .",
    "the common factor ( i.e.  ) is the sum of two probabilities ; the probability that the webpage is not useful ( @xmath52 ) multiplied by the probability that the keyword occurs in a useless webpage ( @xmath53 ) , and the probability that the webpage is useful ( @xmath54 ) multiplied by the probability that the keyword occurs in a useful webpage ( @xmath55 ) .",
    "the sum is nothing but an application of the law of total probability .",
    "the quantity @xmath56 is the interference term .",
    "as the interference term ranges between @xmath57 and @xmath58 , the probability of keyword occurrence computed when usefulness is superposed with uselessness becomes different from the common factor in which usefulness and uselessness are mutually exclusive and their probability distribution is described by a mixture .",
    "the interference term can be so large that the law of total probability is violated and any probability space obeying kolmogorov s axioms can not admit the probability values @xmath54 and @xmath55 , thus requiring the adoption of a quantum probability space  .",
    "in general , the information stored in the data is acquired and delivered through information unit representation and ranking , these processes are described in terms of decision and estimation , and they are therefore affected by error . the error could be eliminated only if precise and exhaustive methodological tools and computer systems were developed .",
    "nevertheless , there is a trade - off between precision , exhaustivity and the computation cost because high level of the former can be achieved only if a high computation cost is devoted .",
    "thus , a certain amount of error is unavoidable yet can be controlled and limited below a given threshold .    either a set of statements , or hypotheses , must be decided to best describe the information unit insofar as data permit to judge ( e.g. , the best topic(s ) to which a webpage is assigned ) , or the values of certain quantities ( also known as parameters ) characterizing the information unit must be estimated , the probability of detection and the probability of false alarm related to a decision must be calculated . in the paper , a great deal of attention is paid to decision whereas estimation is set apart not because estimation is little important , but because estimation would require another research stream had it to be addressed to the appropriate level of exhaustivity .",
    "many tasks in data management are decision problems , examples are the classification of images with respect to predefined patterns , the categorization of webpages to topics , contextual advertising ( i.e. , the decision whether an ad has to displayed in a search engine result page ) , the retrieval and ranking of webpages ( i.e. , the decision as to whether a webpage has to put at rank @xmath59 of a search engine result page ) , probabilistic databases ( i.e. , the decision about the correct value of an attribute and then the computation of the associated probability ) .",
    "our illustration of decision theory is necessarily brief and confined to its simplest aspects and examples .",
    "the illustration is also organized in such a way as to bring out most clearly the parallels between classical probability - based decision and quantum probability - based decision .",
    "the examples are chosen from elementary information retrieval or machine learning theory and perhaps provide a basis for comparison with the quantum case .",
    "a certain information unit ( e.g. , a webpage or an store item ) is observed in such a way as to obtain numbers ( e.g. , the pagerank or the number of positive reviews ) on the basis of which a decision has to be made about its state",
    ". the numbers observed are , for example , the frequency of a feature in the information unit , the simplest example being the frequency of a keyword in a webpage used for calculating search engine statistical ranking functions . for the sake of clarity",
    ", we use the binary frequency and the feature presence / absence case in the paper .",
    "the state might be , for example , the relevance of the webpage to the search engine user s interests or the customer s willingness to buy the store item .",
    "the use of the term `` state '' is not coincidental because the numbers are observed depending upon the density matrix , which is indeed the mathematical notion implementing the state of a system .",
    "thus , quantum probability ascribes the decision about the state of an information unit to testing the hypothesis that the density matrix has generated the observed numbers .    consider the hypothesis that the state of the system is the density matrix @xmath60 and the alternative hypothesis that the state of the system is the density matrix @xmath61 .",
    "the two hypotheses can be labeled @xmath62 and @xmath63 , respectively . in data management ,",
    "hypothesis @xmath63 asserts , for example , that a customer does not buy an item or that a webpage shall be irrelevant to the search engine user whereas hypothesis @xmath62 asserts that an item shall be bought by a customer or that a webpage shall be relevant to the user .",
    "therefore , the probability that , say , a feature occurs in an item which shall not be bought by a customer or a keyword occurs in a webpage which shall be irrelevant to the search engine user depends on the state ( i.e. , the density matrix ) .",
    "statistical decision theory is a old topic and neyman - pearson s lemma is by now one out of the most important results which provides a criterion for deciding upon hypotheses instead of the bayesian approach .",
    "the lemma provides the rule to govern the decider s behaviour and decide the true hypothesis without hoping to know whether it is true .",
    "given an information unit and an hypothesis about the unit , such a rule calculates a specified number ( e.g. , a feature ) and , if the number is greater than a threshold reject the hypothesis , otherwise , accept it .",
    "such a rule tells nothing whether , say , the item shall be bought by the customer , but the lemma proves that , if the rule is followed , then , in the long run , the hypothesis shall be accepted at the highest probability of detection ( or power ) possible when the probability of false alarm ( or size )   is not higher than a threshold .",
    "the set of the pairs given by size and power is the power curve which is also known as the receiver operating characteristic ( roc ) curve .",
    "neyman - pearson s lemma implies that the set of the observable numbers ( e.g. , features ) can be partitioned into two distinct regions ; one region includes all the numbers for which the hypothesis shall be accepted and is termed acceptance region , the other region includes all the numbers for which the hypothesis shall be rejected and is termed rejection region . for example , if a keyword is observed from webpages and only presence / absence is observed , the set of the observable numbers is @xmath64 and each region is one out of possible subsets , i.e. , @xmath65 .",
    "the paper reformulates neyman - pearson s lemma in terms of subspaces instead of subsets to utilize quantum probability .",
    "therefore , the region of acceptance and the region of rejection must be defined in terms subspaces . in the following ,",
    "we illustrate the algorithm for calculating the most efficient test in hilbert spaces .",
    "the following result holds :    [ the : helstrom ] let @xmath66 be the density matrices under @xmath67 , respectively .",
    "the region of acceptance at the highest power at every size is given by the projectors of the spectrum of @xmath68 whose eigenvalues are positive .",
    "see  @xcite .",
    "an optimal projector is a projector which identifies the region of acceptance and the region of rejection according to theorem  [ the : helstrom ] .",
    "we define the _ discriminant function _ as @xmath69 where @xmath32 is a projector . if the discriminant function is positive , the observed event represented by @xmath32 is placed in the region of acceptance .",
    "suppose that the density matrix that corresponds to @xmath62 is a mixed , classical probability distribution .",
    "the mixed case is the usual method for dealing with uncertainty in data management , even though more than one feature may exist or the feature may not be binary ; however , the number of features or the number of values of a feature is not essential in the paper .",
    "let @xmath70 be such a mixed distribution and @xmath71        0 & 1-p_1      \\end{array }    \\right)\\ ] ] where @xmath72        0 & 0      \\end{array }    \\right )    \\qquad     \\mathbf{p}_0 =     \\left (      \\begin{array}{cc }        0 & 0 \\\\ [ 5pt ]        0 & 1      \\end{array }    \\right)\\ ] ] similarly , @xmath73        0 & 1-p_0      \\end{array }    \\right)\\ ] ] when @xmath74 is observed , the power and the size are , respectively , @xmath75 in the classical case , @xmath76 represents the absence and the presence , respectively , of a feature .",
    "hence , the possible acceptance or rejection regions are @xmath77 which correspond respectively to `` never accept '' , `` accept when the feature does not occur '' , `` accept when the feature occurs '' and `` always accept '' .",
    "thus , the decision on , say , webpage classification , topic categorization , item suggestion , can be made upon the occurrence of one or more features because @xmath76 represent `` physical '' events .",
    "furthermore , the discriminant function in the mixed case is @xmath78 the power curve can be built as follows .",
    "suppose , as an example , that a keyword describes webpage content and that that webpage either includes ( @xmath79 ) or does not include ( @xmath80 ) the keyword .",
    "@xmath81 only if @xmath82 and this point corresponds to the event represented by @xmath83 .",
    "let @xmath84 be the probability that the keyword occurs in a relevant webpage or in a non - relevant webpages , respectively .",
    "when the keyword is the unique observed feature , the webpage is presented to the user if @xmath85 and the keyword occurs , or @xmath86 and the keyword does not occur .",
    "the power curve includes the points @xmath87 and @xmath88 .",
    "the key point is that a mixture is not the unique way to implement the probability distributions .",
    "as we illustrate in section  [ sec : class - prob - quant ] , the superposed vectors@xmath89        \\sqrt{1-p_1 }     \\end{array }    \\right )    \\qquad    { |\\varphi_0\\rangle } =    \\left (      \\begin{array}{c }        \\sqrt{p_0}\\\\ [ 5pt ]        \\sqrt{1-p_0 }      \\end{array }    \\right)\\ ] ] yield the pure densities @xmath90",
    "\\sqrt{p_1(1-p_1 ) } & 1-p_1      \\end{array }    \\right )    = { |\\varphi_1\\rangle\\langle\\varphi_1|}\\ ] ] @xmath91        \\sqrt{p_0(1-p_0 ) } & 1-p_0      \\end{array }    \\right )    = { |\\varphi_0\\rangle\\langle\\varphi_0|}\\ ] ] which replace the mixed densities .",
    "theorem  [ the : helstrom ] instructs us to define the optimal projectors as those of the spectrum of   whose eigenvalues are positive , the spectrum being @xmath92 where the @xmath93 s are eigenvalues , @xmath94 and @xmath95 ( see  @xcite ) .",
    "@xmath96 is the distance between densities defined in  @xcite ; @xmath96 is the squared cosine of the angle between the subspaces corresponding to the density vectors .",
    "the justification of viewing @xmath96 as a distance comes from the fact that `` the angle in a hilbert space is the only measure between subspaces , up to a costant factor , which is invariant under all unitary transformations , that is , under all possible time evolutions . ''",
    "@xcite    @xmath97 are the optimal projectors in the pure case and @xmath76 are the optimal projectors in the mixed case .",
    "the probability of detection ( i.e. , the power ) @xmath98 and the probability of false alarm ( i.e. , the size ) @xmath99 in the pure case are defined as follows : @xmath100 finally , @xmath98 can be defined as function of @xmath99 : @xmath101        1 & { |x|^2 } < q_0 \\leq 1      \\end{array }    \\right.\\ ] ] so that the power curve is obtained ( see  @xcite ) .",
    "expressions   and   have no counterpart in classical probability and are among the essential points of the paper because they allow us to improve ranking yet using the same amount of evidence as the evidence used in the classical probability distribution   and  .",
    "at this point , there are three main issues :    * the numerical difference between the classical and the quantum probabilities of detection at every given probability of false alarm , * the interpretations of @xmath76 and @xmath97 and whether the interpretations can be tied together , * how the optimal projectors @xmath97 in the pure case can be used for ranking information units in a data management system .",
    "the issues are addressed in section  [ sec : optim - rank - quant ] ,  [ sec : interpr - quant - proj ] and  [ sec : impl - rank ] , respectively .",
    "the following lemma shows that the power of the decision rule in quantum probability is greater than , or equal to , the power of the decision rule in classical probability with the same amount of information available from the training set to estimate @xmath102 .",
    "[ sec : optim - rank - quant-2 ] @xmath103 at every given false alarm probability .",
    "the equality holds only if @xmath104 : @xmath105 0       \\end{array }     \\right )     =      p_1     = { \\mathrm{tr}}(\\mu_1\\mathbf{p}_1)\\ ] ] + @xmath106 0        \\end{array }      \\right )      = p_0      = { \\mathrm{tr}}(\\mu_0\\mathbf{p}_1)\\ ] ] let @xmath107 be a certain false alarm probability and let @xmath108 be the real , continuous functions yielding the detection probabilities at @xmath45 .",
    "@xmath98 admits the first and the second derivatives in the range @xmath109 $ ] .",
    "in particular , @xmath110 in @xmath109 $ ] .",
    "@xmath111 is a continuous function .",
    "consider the polynomial @xmath112 of order @xmath2 passing through the points @xmath113 and @xmath87 at which @xmath114 intersects @xmath98 .",
    "then , the lagrange interpolation theorem can be used so that @xmath115 the latter being non negative because @xmath110 and @xmath116 .",
    "the number @xmath117 $ ] exists due to the rolle theorem . as @xmath118 $ ] , hence , @xmath119 $ ] .",
    "similarly , consider the polynomials @xmath120 and @xmath121 of order @xmath2 passing through the points @xmath87 , @xmath88 and @xmath122 , @xmath123 at which @xmath124 and @xmath125 intersect @xmath98 , respectively .",
    "then , the lagrange interpolation theorem can again be used so that @xmath126 @xmath127 then , @xmath128 for all @xmath129 $ ] .    the power @xmath98 can plotted against the size @xmath99 , thus producing the power curve of the classical decision rule and the power curve of the quantum decision .",
    "a graphical representation is provided in figure  [ fig : roc ] .",
    "is the curve above the polygonal curve depicting @xmath111 .",
    "the classical probability roc curve intercepts the quantum probability roc curve at @xmath87 , @xmath88 and @xmath88 , @xmath123 where @xmath130 are observed .",
    "@xmath131 for @xmath132 and @xmath103 for all @xmath99 s . ]",
    "[ sec : optim - proj - quant ] suppose that ten information units have been used for training a data management system .",
    "each unit has been indexed using one binary feature and has been marked as useful ( 1 ) or useless ( 0 ) .",
    "the training set is summarized by table  [ tab : example ] :    @xmath133     + therefore , @xmath134 the computation of @xmath135 follows from   and the computation of @xmath136 follows from  . when @xmath137 , we have that @xmath138 .",
    "in this section , some interpretations of the optimal projectors representing the region of acceptance are provided .",
    "the optimal projectors @xmath97 in the pure case have a more difficult interpretation than @xmath76 because the latter represent `` physical '' observations ( e.g. , a customer review does exist or does not ) whereas @xmath97 can not be expressed in terms of @xmath139 and we can not explain the @xmath140 s by saying that , for example , they represent the presence and/or the absence of a feature . in quantum theory , the impossibility of expressing a projectors as functions of other projectors is termed incompatibility which is expressed mathematically as @xmath141 .",
    "the interpretation of the optimal projectors reflects on the interpretation of what means that they are `` observed '' in an information unit ; for example , if the information unit is a commercial item suggested to a customer , what does the `` observation '' of @xmath142 mean ?",
    "what should we observe from an information unit so that the observation outcome corresponds to the projector ?",
    "the question is not a futile because the answer(s ) would effect the algorithms ( e.g. , automatic indexing ) used for representing the informative content of the unit .",
    "specifically , the interpretation of @xmath143 provides what the retrieval algorithm must do when a feature is observed .",
    "either the interpretation of an optimal projector is implemented at indexing time or at query time , an internal memory representation in terms of data structures is necessary for automatic processing and the representation needs the observation of physical properties which are then converted into numbers . in the mixed case ,",
    "the answer is quite straightforward because the optimal projectors correspond to the feature occurrence and separate the units indexed by the feature from those not indexed . in the pure case , the answer is not straightforward at all . if @xmath76 represent feature occurrence , the @xmath144 s can not be a feature occurrence , but they are something new which can not be described in convential way .",
    "indicate the angles between the vectors . ]",
    "geometrically , each vector is a superposition of other two independent vectors .",
    "figure  [ fig : geometry ] depicts the way the vectors and the spanned subspaces ( i.e. , projectors ) interact and shows that @xmath145 are placed symmetrically `` around '' the density vectors and the probability of error is minimized  @xcite .",
    "the observation of a binary feature places the observer upon either @xmath146 or @xmath147 and there is no way to move upon @xmath148 or @xmath149 .",
    "probabilistically , the optimal projectors and the density vectors are related as follows : @xmath150 where @xmath151 logically , the projectors are assertions , thus a parallel can be established with assertions and subsets    an assertion defines the elements of the universe ( e.g. , an event space ) which belong to a subset .",
    "the basic difference between subspaces and subsets is that the vectors belong to a subspace if and only if they are spanned by a basis of the subspace .",
    "a containment relationship can be established between subspaces such that if a subspace ( e.g. , a line ) includes a point , then every subspace ( e.g. , a plane ) containing the line includes the point too .",
    "the subspace spanned by the projector @xmath24 is termed as @xmath152 and the containment relationship between @xmath152 and @xmath153 can be encoded as @xmath154 such that for every vector @xmath51 , @xmath155  ( * ? ? ?",
    "* ch . 5 ) .",
    "the paper considers the information units relevant , useful or interesting when they are included by the subspace @xmath156 spanned by @xmath157 .",
    "suppose that a subspace @xmath152 is given and that @xmath158 is the metric defined on the whole space to which @xmath152 belongs .",
    "@xmath159    see  @xcite .    as @xmath160",
    ", @xmath161 maximizes the probability @xmath162 note that when @xmath51 is in @xmath163 ,   is the distance between the @xmath163 s defined in  @xcite .",
    "the result establishes a connection between the geometric , probabilistic and logical interpretation of the projectors even though they seems different . in the next section",
    ", these interpretations are tied together , thus allowing us to look for a criterion for assigning an information unit to the best region as explained .",
    "the problem is to decide whether an information unit represented by a binary feature is considered relevant , useful , interesting , etc .. an algorithm implementing such a decision rule should perform as follows .",
    "it reads the feature occurrence symbol ( i.e. , either @xmath1 or @xmath2 ) ; check whether the feature is included by the region of acceptance . if the feature is not included , the hypothesis of relevance , usefulness , interest , etc . is rejected .",
    "another view of the preceding decision rule is the ranking of the information units .",
    "when ranking information units , the system returns the units whose features lead to the highest probability of detection , then those whose features lead to the second highest probability of detection , and so on . when a binary feature is considered , the ranking ends up to placing the units whose features lead to the highest probability of detection whereas the other units are not retrieved .    as we point out in section  [ sec : interpr - quant - proj ] , the observation of features corresponding to @xmath130 can not give any information about the observation of the events corresponding to @xmath164 due to the incompatibility between these pairs of events .",
    "thus , we can not design an algorithm implementing the decision rule so that the observation of a feature can be translated into the observation of the events corresponding to @xmath143 .",
    "a possible approach can be based on the probabilistic interpretation of the optimal projectors .",
    "according to such an approach , the probability that the event corresponding to an optimal projector occurs provided that a feature occurs can provide a measure of the degree to which the event had occurred if it could have been observed .",
    "when the subspaces represent these events , the probability that the event corresponding to an optimal projector is observed if the state is described by @xmath60 is @xmath111 .",
    "such an approach is partially satisfactory because @xmath165 .    as an alternative approach ,",
    "consider the geometric interpretation depicted in  figure  [ fig : geometry ] .",
    "note that the asymmetry of @xmath166 with respect to the densities causes the suboptimality of @xmath167 .",
    "indeed , if @xmath166 coincided with @xmath168 , the power and the size would be the same in both cases .",
    "we propose a method which reaches the optimality without neither resorting to probabilistic approximations nor undergoing high computational costs .",
    "the density vectors @xmath169 are a superposition of both @xmath166 and @xmath168 which are two different bases and induce different coordinates .",
    "when @xmath166 is the basis , the coordinates of @xmath170 are @xmath171 . when @xmath168 is the basis , the coordinates of @xmath170 are @xmath172 such that @xmath173 and @xmath174 as @xmath175 is often assumed when ranking information units , the coordinates have a quite simple and intuitive meaning provided by the following expressions : @xmath176 where @xmath177 .    as the asymmetry of @xmath166 with respect",
    "the density vectors is due to @xmath178 which summarize the statistics observed from the training set , we leverage them for improving the ranking . in particular , in the paper",
    "we show that changing the estimation of @xmath84 is sufficient to reach the optimality .",
    "then , we wonder how we should define the density vectors or matrices so that @xmath179 were obtained instead of @xmath135 .",
    "the basis vectors ( i.e. , @xmath166 or @xmath168 ) are rotated , thus changing the coordinates .",
    "therefore , we define the density vectors @xmath180 in @xmath181 according to   in such a way that if a feature is observed under @xmath62 , the probability of detection is @xmath98 and , if a feature is observed under @xmath63 , the probability of false alarm is @xmath99 .",
    "the simple solution is defining the new density vectors as follows : @xmath182 thus obtaining @xmath183    at first sight , the increase of the probability of detection is due to the higher probability values assigned to the region of acceptance in the pure case than those assigned to the region of acceptance in the mixed case , and not to a different ranking . in the following , we show that the superiority of the discriminant function in the pure case is due to the different ranking induced by a different partition of the event space into region of acceptance and region of rejection .",
    "we state the problem as follows .",
    "are there @xmath184",
    "such that the region of acceptance in the pure case differs from that in the mixed case ?",
    "consider theorem  [ the : helstrom ] to answer the question .",
    "the region of acceptance in the mixed case is defined through table  [ tab : region - of - acceptance - mixed ] whereas the region of acceptance in the pure case is defined through table  [ tab : region - of - acceptance - pure ] .",
    "furthermore , the discriminant function derived from   is @xmath185 where @xmath186    .the regions of acceptance corresponding to the sign of the eigenvalues of the spectrum of the discriminant function in the mixed case .",
    "the equality case is addressed in  @xcite . [ cols=\"<,^,^ \" , ]     suppose that @xmath187 .",
    "thus , @xmath188 and the region of acceptance in the mixed case is represented by @xmath189 , whereas the region of acceptance in the pure case is represented by @xmath74 .",
    "the counter - example just mentioned proves the following    [ sec : impl - optim - rank ] the discriminant function   ranks information units in a different way from the discriminant function   because an alternative ranking is computed .    in   the densities that are considered",
    "are those associated to a mixed state , while   in the densities are the one associated to a pure state .",
    "so the equations look like the same , what differs is the type of densities that are used in the two cases .",
    "we have shown that the improvement of ranking measured in terms of probability of detection given a probability of false alarm is due to the ranking induced by @xmath190 .    hence ,",
    "we state the problem of finding @xmath97 into the problem of defining the coordinates of the representation of the density vectors in @xmath181 .",
    "the problem of defining the new coordinates for the density vectors might be viewed as a problem of feature weighting .",
    "in such a context , the traditional estimations of the probability of feature occurrence ( i.e. , @xmath84 ) under two different hypothesis are replaced by the @xmath191 s .",
    "feature re - weighting is explored in ir whose state - of - the - art is given by the bm25 weighting scheme surveyed , for example , in  .",
    "the main drawback of the weighting schemes like bm25 is the parameter tuning necessary for optimizing the effectiveness with a given database or query , thus making the understanding of how and why a scheme is more effective than others rather problematic .",
    "in contrast , the paper illustrate the decision rule in such a way that if the decision rule is followed , then @xmath62 shall be accepted when it is true at a higher probability of detection than @xmath111 when the probability of false alarm is not more than a given threshold .",
    "the formulation of the decision rule provided in this section allows us to design an efficient algorithm for indexing and retrieving ( or classifying ) information units .",
    "the algorithm is just an instance of those employed currently in ir ( see   for example ) where the maximum likelihood or bayesian estimations of @xmath102 are replaced by   and  .",
    "the foundations of quantum mechanics and theory has been illustrated in plenty of books such as  @xcite and  @xcite .",
    "quantum probability , for example , has been introduced in  @xcite . in particular ,",
    "the interference term is addressed in  @xcite .",
    "the view of probability illustrated in section  [ sec : class - prob - quant ] is based on  @xcite .",
    "the utilization of quantum theory in computation , information processing and communication is described in  .",
    "recently , investigations have started in other research areas , for example , in ir  .",
    "the paper is inspired by helstrom s book  @xcite which provides the foundations and the main results in quantum detection ; an example of the exploitation of the results in quantum detection is reported   within communication theory .",
    "this paper links to  @xcite as far it concerns density matrices and projectors ; however , the paper develops quantum detection for data management .",
    "this paper departs from the probability ranking principle ( pr ) proposed in the context of classical probability ; we propose quantum probability to improve ranking in a principled way . in information retrieval ,",
    "the probability ranking principle ( prp ) states that `` if a reference retrieval system s response to each request is a ranking of the documents in the collection in order of decreasing probability of relevance to the user who submitted the request , where the probabilities are estimated as accurately as possible on the basis of whatever data have been made available to the system for this purpose , the overall effectiveness of the system to its user will be the best that is obtainable on the basis of those data . ''",
    "@xcite . however , some assumptions undermine the general applicability of the prp .",
    "we state a similar principle yet replace classical probability , which is implied in  @xcite , with quantum probability  ",
    "parameter estimation data are kept the same , bu we instead use subspaces to define alternative regions of acceptance and rejection .    to our knowledge",
    ", the use of quantum probability for ranking information units has not yet been addressed in the same way of this paper although a few papers that are somehow comparable can be found .",
    "perhaps , the closest paper is  . that paper proposes to rank documents by quantum probability and suggests that interference ( which must be estimated ) might model dependencies in relevance judgements such that documents ranked until position @xmath192 interfere with the degree of relevance of the document ranked at position @xmath193",
    "this means , the optimal order of documents under the prp differs from that of the quantum prp .",
    "note that they empirically show that quantum probability is more effective that classical one in specific rankings tasks .",
    "in contrast , in this paper , we do not need to address interference because quantum probability can be estimated using the same data used to estimate classical probability .",
    "we rather show that not only ranking by quantum probability provides a different optimal ranking , it is also more effective than classical probability . with this regard , the effectiveness of quantum probability measured in   stems from the estimation of classical probability and that of interference .",
    "but , the regions of acceptance and rejection are still based on sets .",
    "it follows that the optimality of the quantum prp strongly depends on the optimality of the prp and on the interference estimantion effectiveness . in this paper , on the contrary , ranking optimality only depends on the region of acceptance defined upon subspaces .",
    "another paper somewhat related to ours is  .",
    "the authors discuss how to emply quantum formalisms for encompassing various information retrieval tasks within a single framework . from an experimental point of view",
    ", what that paper demonstrates is that ranking functions based on quantum formalism are computationally feasible .",
    "the best experimental results of rankings driven by quantum formalism are comparable to bm25 , that is , to prp , thus limiting the contribution within a classical probability framework .",
    "probabilistic databases systems manage imprecise data and provide tools for structured complex queries .",
    "a survey is provided in  . beside scalability and query plan execution ,",
    "these systems do probabilistic inference which may be defined upon classical or quantum probability and they concentrate on top-_k _ query answering where the tuples are assigned a probability distribution . the results of this paper may be applied to probabilistic databases systems too .",
    "the main result of the paper is the demonstration that quantum probability can be incorporated into a data management system for ranking information units .",
    "as ranking by quantum probability is more effective than ranking by classical probability when it has been used in other domains , it is our belief that an analogous improvement can be achieved within data management .",
    "the future developments are threefold .",
    "first , we will work on the intepretation of the optimal projectors in the pure case because the detection of them in an information unit may open further insights .",
    "second , feature classical correlation and quantum entanglement will be investigated .",
    "third , evaluation is crucial to understand whether the results of the paper can be confirmed by the experiments .    10    l.  accardi . on the probabilistic roots of the quantum mechanical paradoxes . in s.",
    "diner and l.  de broglie , editors , _ the wave - particle dualism _ , pages 297330 .",
    "d. reidel pub .",
    "co. , 1984 .",
    "l.  accardi . .",
    "il saggiatore , 1997 . in italian .",
    "l.  accardi and a.  fedullo . on the statistical meaning of complex numbers in quantum mechanics .",
    ", 34(7):161172 , june 1982 .",
    "g.  boole . .",
    "walton and maberly , 1854 .",
    "p.  bruza , d.  sofge , w.f .",
    "lawless , c.j .",
    "van rijsbergen , and m.  klusch , editors . ,",
    "volume 5494 of _ lecture notes in computer science _ ,",
    "saarbrcken , germany , 2009 .",
    "springer .",
    "g.  cariolaro and g.  pierobon .",
    "performance of quantum data transmission systems in the presence of thermal noise .",
    ", 58:623630 , february 2010 .",
    "croft , d.  metzler , and t.  strohman . .",
    "addison wesley , 2009 .",
    "n.  dalvi , c.  r , and d.  suciu .",
    "probabilistic databases : diamonds in the dirt . ,",
    "52:8694 , july 2009 .",
    "r.  b. griffiths . .",
    "cambridge university press , 2002 .",
    "undergraduate texts in mathematics .",
    "springer , 1987 .",
    "helstrom . .",
    "academic press , 1976 .",
    "harvard university press , 1989 .",
    "kolmogorov . .",
    "chelsea publishing company , new york , second edition , 1956 .",
    "m.  melucci . a basis for information retrieval in context .",
    ", 26(3 ) , 2008 .",
    "j.  neyman and e.s .",
    "pearson . on the problem of the most efficient tests of statistical hypotheses .",
    ", 231:289337 , 1933 .",
    "m.  nielsen and i.l .",
    "cambridge university press , 2000 .",
    "parthasarathy . .",
    "birkhuser , 1992 .",
    "b.  piwowarski , i.  frommholz , m.  lalmas , and k.  van rijsbergen .",
    "what can quantum theory bring to information retrieval ? in _ proc .",
    "19th international conference on information and knowledge management _",
    ", page 5968 , 2010 .",
    "e.  rieffel .",
    "certainty and uncertainty in quantum information processing . in _ proceedings of the quantum interaction symposium _ , 2007 .",
    "the probability ranking principle in information retrieval .",
    ", 33(4):294304 , 1977 .",
    "robertson and h.  zaragoza .",
    "the probabilistic relevance framework : bm25 and beyond .",
    ", 3(4):333389 , 2009 .",
    "keith van rijsbergen . .",
    "cambridge university press , uk , 2004 .",
    "j.  von neumann . .",
    "princeton university press , 1955 .",
    "w.  k. wootters . statistical distance and hilbert space . , 23(2):357362 , jan 1981 .",
    "g.  zuccon , l.  azzopardi , and c.j .",
    "van rijsbergen .",
    "the quantum probability ranking principle for information retrieval . in _ proceedings of the international conference on the theory of information retrieval ( ictir ) _ , pages 232240 , 2009 .",
    "a complex vector @xmath45 is represented as @xmath51 and is called `` ket '' .",
    "the conjugate transpose of @xmath45 is represented as @xmath194 and is called `` bra '' ( therefore , the dirac notation is called the bra(c)ket notation ) .",
    "moreover , @xmath202 and the properties of trace allow us to write @xmath203 . in general ,",
    "if @xmath204 are trace-1 hermitian operators , and @xmath205 is a projector , @xmath206 is the probability that the event represented by @xmath205 occurs given a density operator @xmath24 ."
  ],
  "abstract_text": [
    "<S> data management systems , like database , information extraction , information retrieval or learning systems , store , organize , index , retrieve and rank information units , such as tuples , objects , documents , items to match a pattern ( e.g. classes and profiles ) or meet a requirement ( e.g. , relevance , usefulness and utility ) . to this end , these systems rank information units by probability to decide whether an information unit matches a pattern or meets a requirement . </S>",
    "<S> classical probability theory represents events as sets and probability as set measures . </S>",
    "<S> thus , distributive and total probability laws are admitted . </S>",
    "<S> quantum probability is a non - classical theory nor does admit distributive and total probability laws . </S>",
    "<S> although ranking by probability is far from being perfect , it is optimal thanks to statistical decision theory and parameter tuning .    </S>",
    "<S> the main question asked in the paper is whether further improvement over the optimality provided by probability may be obtained if the classical probability theory is replaced by quantum probability theory . whereas classical probability ( and detection theory ) is based on sets such that the regions of acceptance / rejection are set - based detectors , quantum probability is based on subspace - based detectors .    </S>",
    "<S> the paper shows that ranking information units by quantum probability differs from ranking them by classical probability provided the same data used for parameter estimation . as probability of detection ( </S>",
    "<S> also known as recall or power ) and probability of false alarm ( also known as fallout or size ) measure the quality of ranking , we point out and show that ranking by quantum probability yields higher probability of detection than ranking by classical probability provided a given probability of false alarm and the same parameter estimation data .    as quantum probability </S>",
    "<S> provided more effective detectors than classical probability within other domains that data management , we conjencture that , the system that can implement subspace - based detectors shall be more effective than a system which implements a set - based detectors , the effectiveness being calculated as expected recall estimated over the probability of detection and expected fallout estimated over the probability of false alarm .    [ 1]*proof of # 1 * </S>"
  ]
}