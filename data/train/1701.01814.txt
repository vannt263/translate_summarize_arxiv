{
  "article_text": [
    "gestures are naturally performed by humans , produced as part of deliberate actions , signs or signals , or subconsciously revealing intentions or attitude  @xcite . while they may involve the motion of all parts of the body , the studies of gestures usually focus on arms and hands which are essential in gesture communication .",
    "recognition of gestures has recently attracted increasing attention due to its indubitable importance in many applications such as human computer interaction ( hci ) , human robot interaction ( hri ) and assistive technologies for the handicapped and the elderly .",
    "gestures are one type of actions and many action recognition methods can be applied to gesture recognition .",
    "recognition of human actions from depth / skeleton data is one of the most active research topics in multimedia signal processing in recent years due to the advantages of depth information over conventional rgb video , e.g. being insensitive to illumination changes . since the first work of such a type  @xcite reported in 2010 ,",
    "many methods  @xcite have been proposed based on specifical hand - crafted feature descriptors extracted from depth / skeleton . with the recent development of deep learning ,",
    "a few methods have been developed based on convolutional neural networks ( convnets )  @xcite and recurrent neural networks ( rnns )  @xcite .",
    "however , it remains unclear how video could be effectively represented and fed to deep neural networks for classification .",
    "for example , one can conventionally consider a video as a sequence of still images with some form of temporal smoothness , or as a subspace of images or image features , or as the output of a neural network encoder .",
    "which one among these and other possibilities would result in the best representation in the context of gesture recognition is not well understood .",
    "inspired by the recent work in  @xcite , this paper proposes for gesture recognition three simple , compact and effective representations of depth sequences which effectively decribe a short depth sequence with images .",
    "such representations make it possible to use a standard convnet architecture to learn suitable  dynamic \" features from the sequences by utilizing the convnet models trained from image data .",
    "consequently , it avoids training millions of parameters from scratch and is especially valuable in the cases that lack sufficient annotated training video data .",
    "for instance , the large - scale isolated gesture recognition challenge  @xcite has on average only 144 video clips per class compared to 1200 images per class in imagenet .",
    "the proposed three representations are dynamic depth image ( ddi ) , dynamic depth normal image ( ddni ) and dynamic depth motion normal image ( ddmni ) .",
    "they are all constructed from a sequence of depth maps based on bidirectional rank pooling to encode the spatial ( i.e. posture ) and temporal ( i.e. motion ) information at different levels and are complementary to each other .",
    "experimental results have shown that the three representations can improve the recognition accuracy substantially .",
    "the rest of this paper is organized as follows .",
    "section ii briefly reviews the related works on gesture / action recognition based on depth and deep learning .",
    "details of the proposed method are described in section iii .",
    "experimental results are presented in section iv .",
    "section v concludes the paper .",
    "with microsoft kinect sensors researchers have developed methods for depth map - based action recognition .",
    "li et al . @xcite sampled points from a depth map to obtain a bag of 3d points to encode spatial information and employ an expandable graphical model to encode temporal information @xcite .",
    "yang et al . @xcite stacked differences between projected depth maps as a depth motion map ( dmm ) and then used hog to extract relevant features from the dmm .",
    "this method transforms the problem of action recognition from spatio - temporal space to spatial space . in @xcite ,",
    "a feature called histogram of oriented 4d normals ( hon4d ) was proposed ; surface normal is extended to 4d space and quantized by regular polychorons . following this method , yang and tian @xcite cluster hypersurface normals and form the polynormal which can be used to jointly capture the local motion and geometry information .",
    "super normal vector ( snv ) is generated by aggregating the low - level polynormals . in @xcite ,",
    "a fast binary range - sample feature was proposed based on a test statistic by carefully designing the sampling scheme to exclude most pixels that fall into the background and to incorporate spatio - temporal cues .",
    "exiting deep learning approach can be generally divided into four categories based on how the video is represented and fed to a deep neural network .",
    "the first category views a video either as a set of still images  @xcite or as a short and smooth transition between similar frames  @xcite , and each color channel of the images is fed to one channel of a convnet .",
    "although obviously suboptimal , considering the video as a bag of static frames performs reasonably well . the second category is to represent a video as a volume and extends convnets to a third , temporal dimension  @xcite replacing 2d filters with 3d ones .",
    "so far , this approach has produced little benefits , probably due to the lack of annotated training data .",
    "the third category is to treat a video as a sequence of images and feed the sequence to a rnn  @xcite .",
    "a rnn is typically considered as memory cells , which are sensitive to both short as well as long term patterns .",
    "it parses the video frames sequentially and encode the frame - level information in their memory .",
    "however , using rnns did not give an improvement over temporal pooling of convolutional features  @xcite or over hand - crafted features .",
    "the last category is to represent a video in one or multiple compact images and adopt available trained convnet architectures for fine - tuning  @xcite .",
    "this category has achieved state - of - the - art results of action recognition on many rgb and depth / skeleton datasets .",
    "the proposed method in this paper falls into the last category .",
    "the proposed method consists of three stages : construction of the three sets of dynamic images , convnets training and score fusion for classification , as illustrated in fig .  [ fig : framework ] .",
    "details are presented in the rest of this section .",
    "the three sets of dynamic images , dynamic depth images ( ddis ) , dynamic depth normal images ( ddnis ) and dynamic depth motion normal images ( ddmnis ) are constructed from a sequence of depth maps through rank pooling  @xcite .",
    "they aim to capture both posture and motion information for gesture recognition .",
    "let @xmath1 denote the frames in a sequence of depth maps , and @xmath2 be a representation or feature vector extracted from each individual frame @xmath3 .",
    "let @xmath4 be time average of these features up to time @xmath5 .",
    "the ranking function associates to each time @xmath5 a score @xmath6 , where @xmath7 is a vector of parameters .",
    "the function parameters @xmath8 are learned so that the scores reflect the rank of the frames in the video . in general , later times are associated with larger scores , @xmath9 .",
    "learning @xmath8 is formulated as a convex optimization problem using ranksvm  @xcite :    @xmath10    the first term in this objective function is the usual quadratic regular term used in svms .",
    "the second term is a hinge - loss soft - counting how many pairs @xmath11 are incorrectly ranked by the scoring function .",
    "note in particular that a pair is considered correctly ranked only if scores are separated by at least a unit margin , @xmath12 .",
    "optimizing the above equation defines a function @xmath13 that maps a sequence of @xmath14 depth video frames to a single vector @xmath15 . since this vector contains enough information to rank all the frames in the video , it aggregates information from all of them and can be used as a video descriptor .",
    "this process is called rank pooling .      given a sequence of depth maps , the ranking pooling method  @xcite described above is employed to generate a dynamic depth image ( ddi ) .",
    "the ddi is fed to the three channel of a convnet .",
    "different from  @xcite the rank pooling is applied in a bidiretional way to convert one depth map sequence into two ddis . as shown in fig .",
    "[ fig : dis ] , ddis effectively capture the posture information , similar to key poses .      in order to simultaneously exploit the posture and motion information in depth sequences , it is proposed to extract normals from depth maps and construct the so called ddnis ( dynamic depth normal images ) . for each depth map , the surface normal @xmath16 at each location is calculated .",
    "thus , three channels @xmath17 , referred to as a depth normal image ( dni ) , are generated from the calculated normals , where @xmath17 represents normal images for the three components @xmath16 respectively .",
    "the sequence of dnis goes through bidirectional rank pooling to generate two ddnis , one being from forward ranking pooling and the other from backward rank pooling .    to minimise the interference of the background",
    ", it is assumed that the background in the histogram of depth maps occupies the last peak representing far distances .",
    "specifically , pixels whose depth values are greater than a threshold defined by the last peak of the depth histogram minus a fixed tolerance ( 0.1 was set in our experiments ) are considered as background and removed from the calculation of ddnis by re - setting their depth values to zero . through this simple process ,",
    "most of the background can be removed and has much contribution to the ddnis .",
    "samples of ddnis can be seen in fig .",
    "[ fig : dis ] .",
    "the purpose of construction of a ddmni is to further exploit the motion in depth maps .",
    "gaussian mixture models ( gmm ) is applied to depth sequences to detect moving foreground .",
    "the same process as the construction of a ddni ( but without using histogram - based foreground extraction ) is employed to the moving foreground .",
    "this process generates two ddmnis , which specifically capture the motion information as illustrated in fig .",
    "[ fig : dis ] .      after the construction of ddis , ddnis and ddmnis , there are six dynamic images , as illustrated in fig .",
    "[ fig : dis ] , for each depth map sequence .",
    "six convnets were trained on the six channels individually .",
    "different layer configurations were used for the validation and testing sets provided by the challenge . for validation",
    ", the layer configuration of six convnets follows the one in  @xcite .",
    "for testing , vgg-16  @xcite was adopted for fine - tuning .",
    "the implementation is derived from the publicly available caffe toolbox  @xcite based on three nvidia tesla k40 gpu cards for both validation and testing .",
    "the training procedure for validation is similar to the one in  @xcite .",
    "the network weights were learned using the mini - batch stochastic gradient descent with the momentum being set to 0.9 and weight decay being set to 0.0005 .",
    "all hidden weight layers use the rectification ( relu ) activation function . at each iteration",
    ", a mini - batch of 256 samples is constructed by sampling 256 shuffled training samples .",
    "all the images are resized to 256 @xmath18 256 .",
    "the learning rate was set to @xmath19 for fine - tuning with pre - trained models on ilsvrc-2012 , and then it is decreased according to a fixed schedule , which is kept the same for all training sets . for each convnet",
    "the training undergoes 20k iterations and the learning rate decreases every 5k iterations . for all experiments ,",
    "the dropout regularisation ratio was set to 0.5 in order to reduce complex co - adaptations of neurons in the nets .    for testing",
    ", the training procedure is similar to the one in  @xcite .",
    "the network weights were learned using the mini - batch stochastic gradient descent with the momentum being set to 0.9 and weight decay being set to 0.0005 .",
    "all hidden weight layers use the rectification ( relu ) activation function . at each iteration ,",
    "a mini - batch of 32 samples was constructed by sampling 256 shuffled training samples .",
    "all the images are resized to 224 @xmath18 224 .",
    "the learning rate was set to @xmath19 for fine - tuning with pre - trained models on ilsvrc-2012 , and then it is decreased according to a fixed schedule , which is kept the same for all training sets . for each convnet",
    "the training undergoes 50k iterations and the learning rate decreases every 20k iterations . for all experiments ,",
    "the dropout regularisation ratio was set to 0.9 in order to reduce complex co - adaptations of neurons in the nets .      given a testing depth video sequence ( sample )",
    ", three pairs of dynamic images ( ddis , ddnis , ddmnis ) are generated and fed into six different trained convnets .",
    "for each image pair , multiply - score fusion was used .",
    "the score vectors outputted by the two pair convnets are multiplied in an element - wise way and then the resultant score vectors are normalized using @xmath20 norm .",
    "the three normalized score vectors are then multiplied in an element - wise fashion and the max score in the resultant vector is assigned as the probability of the test sequence being the recognized class .",
    "the index of this max score corresponds to the recognized class label .",
    "[ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]",
    "this paper presented three simple , compact yet effective representations of depth sequences for gesture recognition using convolutional neural networks .",
    "they are all based on bidirectional rank pooling method converting the depth sequences into images .",
    "such representations enables the use of existing convnets models directly on video data with fine - tuning without introducing large parameters to learn .",
    "the three representations represent the posture and motion in different levels and they are complementary to each other and improve the recognition accuracy largely .",
    "experimental results on chalearn lap isogd dataset verified the effectiveness of the proposed method .",
    "the authors would like to thank nvidia corporation for the donation of a tesla k40 gpu card used in this challenge .",
    "w.  li , z.  zhang , and z.  liu , `` action recognition based on a bag of 3d points , '' in _ proc .",
    "ieee computer society conference on computer vision and pattern recognition workshops ( cvprw ) _ , 2010 , pp .",
    "j.  wang , z.  liu , y.  wu , and j.  yuan , `` mining actionlet ensemble for action recognition with depth cameras , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2012 , pp .",
    "12901297 .",
    "x.  yang , c.  zhang , and y.  tian , `` recognizing actions using depth motion maps - based histograms of oriented gradients , '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , 2012 , pp .",
    "10571060 .",
    "o.  oreifej and z.  liu , `` hon4d : histogram of oriented 4d normals for activity recognition from depth sequences , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2013 , pp .",
    "716723 .",
    "m.  a. gowayyed , m.  torki , m.  e. hussein , and m.  el - saban , `` histogram of oriented displacements ( hod ) : describing trajectories of human joints for action recognition , '' in _ proc . international joint conference on artificial intelligence ( ijcai ) _",
    ", 2013 , pp . 13511357 .",
    "x.  yang and y.  tian , `` super normal vector for activity recognition using depth sequences , '' in _ proc .",
    "ieee international conference on computer vision and pattern recognition ( cvpr ) _",
    ", 2014 , pp . 804811 .",
    "h.  rahmani , a.  mahmood , d.  q. huynh , and a.  mian , `` hopc : histogram of oriented principal components of 3d pointclouds for action recognition , '' in _ proc .",
    "european conference on computer vision ( eccv ) _ , 2014 , pp .",
    "742757 .",
    "wang , w.  li , p.  ogunbona , z.  gao , and h.  zhang , `` mining mid - level features for action recognition based on effective skeleton representation , '' in _ proc . international conference on digital image computing : techniques and applications ( dicta ) _ , 2014 , pp .",
    "18 .",
    "p.  wang , w.  li , z.  gao , c.  tang , j.  zhang , and p.  o. ogunbona , `` convnets - based action recognition from depth maps through virtual cameras and pseudocoloring , '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , 2015 , pp .",
    "11191122 .    p.",
    "wang , w.  li , z.  gao , j.  zhang , c.  tang , and p.  ogunbona , `` action recognition from depth maps using deep convolutional neural networks , '' _ human - machine systems , ieee transactions on _ , vol .",
    "46 , no .  4 ,",
    "pp . 498509 , 2016 .",
    "p.  wang , z.  li , y.  hou , and w.  li , `` action recognition based on joint trajectory maps using convolutional neural networks , '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , 2016 , pp",
    ". 15 .",
    "y.  hou , z.  li , p.  wang , and w.  li , `` skeleton optical spectra based action recognition using convolutional neural networks , '' in _ circuits and systems for video technology , ieee transactions on _ , 2016 , pp .",
    "y.  du , w.  wang , and l.  wang , `` hierarchical recurrent neural network for skeleton based action recognition , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2015 , pp .",
    "11101118 .",
    "w.  zhu , c.  lan , j.  xing , w.  zeng , y.  li , l.  shen , and x.  xie , `` co - occurrence feature learning for skeleton based action recognition using regularized deep lstm networks , '' in _ the 30th aaai conference on artificial intelligence ( aaai ) _ , 2016 .",
    "j.  wan , s.  z. li , y.  zhao , s.  zhou , i.  guyon , and s.  escalera , `` chalearn looking at people rgb - d isolated and continuous datasets for gesture recognition , '' in _ proc .",
    "ieee computer society conference on computer vision and pattern recognition workshops ( cvprw ) _ , 2016 , pp . 19 .",
    "w.  li , z.  zhang , and z.  liu , `` expandable data - driven graphical modeling of human actions based on salient postures , '' _ circuits and systems for video technology , ieee transactions on _ , vol .",
    "18 , no .  11 , pp . 14991510 , 2008 .",
    "j.  yue - hei  ng , m.  hausknecht , s.  vijayanarasimhan , o.  vinyals , r.  monga , and g.  toderici , `` beyond short snippets : deep networks for video classification , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _",
    ", 2015 , pp . 46944702 .",
    "s.  ji , w.  xu , m.  yang , and k.  yu , `` 3d convolutional neural networks for human action recognition , '' _ pattern analysis and machine intelligence , ieee transactions on _ , vol .",
    "35 , no .  1 ,",
    "pp . 221231 , 2013 .",
    "d.  tran , l.  bourdev , r.  fergus , l.  torresani , and m.  paluri , `` learning spatiotemporal features with 3d convolutional networks , '' in _ proc .",
    "ieee international conference on computer vision ( iccv ) _ , 2015 , pp .",
    "44894497 .",
    "j.  donahue , l.  anne  hendricks , s.  guadarrama , m.  rohrbach , s.  venugopalan , k.  saenko , and t.  darrell , `` long - term recurrent convolutional networks for visual recognition and description , '' in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2015 , pp .",
    "26252634 .",
    "a.  krizhevsky , i.  sutskever , and g.  e. hinton , `` imagenet classification with deep convolutional neural networks , '' in _ proc .",
    "annual conference on neural information processing systems ( nips ) _ , 2012 , pp .",
    "11061114 .",
    "y.  jia , e.  shelhamer , j.  donahue , s.  karayev , j.  long , r.  b. girshick , s.  guadarrama , and t.  darrell , `` caffe : convolutional architecture for fast feature embedding . '' in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , 2014 , pp . 675678 .",
    "h.  j. escalante , v.  ponce - lpez , j.  wan , m.  a. riegler , b.  chen , a.  claps , s.  escalera , i.  guyon , x.  bar , p.  halvorsen , h.  mller , and m.  larson , `` chalearn joint contest on multimedia challenges beyond visual analysis : an overview , '' in _ proceedings of icprw _ , 2016 .",
    "j.  wan , g.  guo , and s.  z. li , `` explore efficient local features from rgb - d data for one - shot learning gesture recognition , '' _ ieee transactions on pattern analysis and machine intelligence _",
    "38 , no .  8 , pp .",
    "16261639 , aug 2016 ."
  ],
  "abstract_text": [
    "<S> this paper proposes three simple , compact yet effective representations of depth sequences , referred to respectively as dynamic depth images ( ddi ) , dynamic depth normal images ( ddni ) and dynamic depth motion normal images ( ddmni ) . </S>",
    "<S> these dynamic images are constructed from a sequence of depth maps using bidirectional rank pooling to effectively capture the spatial - temporal information . </S>",
    "<S> such image - based representations enable us to fine - tune the existing convnets models trained on image data for classification of depth sequences , without introducing large parameters to learn . upon the proposed representations , a convolutional neural networks ( convnets ) based method is developed for gesture recognition and evaluated on the large - scale isolated gesture recognition at the chalearn looking at people ( lap ) challenge 2016 . </S>",
    "<S> the method achieved 55.57% classification accuracy and ranked @xmath0 place in this challenge but was very close to the best performance even though we only used depth data .    </S>",
    "<S> gesture recognition ; depth map sequences ; convolutional neural networks </S>"
  ]
}