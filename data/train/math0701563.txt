{
  "article_text": [
    "for the purposes of the discussion in this section , we assume that appropriate approximate marginal distributions are available .",
    "as discussed in a later section , they may be provided by coarse models of the physical problem as in the examples below , or they may be calculated via the methods in @xcite and @xcite .",
    "assume that the @xmath0 dimensional system of interest has a probability density , @xmath1 , where @xmath2 .",
    "suppose further that , by the metropolis - hastings or any other method ( see @xcite ) , we can construct a markov chain , @xmath3 , which has @xmath4 as its stationary measure .",
    "that is , for two points @xmath5 @xmath6 where @xmath7 is the probability density of a move to @xmath8 given that @xmath9 .",
    "here , @xmath10 is the algorithmic step . under appropriate conditions ( see @xcite ) , averages over a trajectory of @xmath11 will converge to averages over @xmath4 , i.e. for an objective function @xmath12 @xmath13\\ ] ] the size of the error in the above limit decreases as the rate of decay of the time autocorrelation @xmath14 = \\\\ \\frac{\\mathbf{e}\\left [ \\left(g\\left(y_0^n\\right)-\\mathbf{e}\\left[g\\left(x_0\\right)\\right]\\right ) \\left(g\\left(y_0",
    "^ 0\\right)-\\mathbf{e}\\left[g\\left(x_0\\right)\\right]\\right)\\right ] } { \\mathbf{var}\\left[g\\left(x_0\\right)\\right]}\\end{gathered}\\ ] ] increases . in this formula , @xmath15 is assumed to be drawn from @xmath4 .    it is well known that judicious elimination of variables by renormalization can reduce long range spatial correlations ( see e.g. @xcite ) .",
    "the variables are removed by averaging out their effects on the full distribution . if the original density is @xmath16 and we wish to remove the @xmath17 variables , the distribution of the remaining @xmath18 variables is given by the marginal density ( see @xcite ) @xmath19 the full distribution can be factored as @xmath20 where @xmath21 is the conditional density of @xmath17 given @xmath18 . because they exhibit shorter correlation lengths , the marginal distributions are useful in the acceleration of markov chain monte carlo methods .    with this in mind",
    "we consider a collection of lower dimensional markov chains @xmath22 which have stationary distributions @xmath23 where @xmath24 .",
    "for each @xmath25 let @xmath26 be the transition probability density of @xmath27 , i.e. @xmath28 is the probability density of @xmath29 given that @xmath30 .",
    "the @xmath31 are approximate marginal distributions .",
    "for example , divide the @xmath32 variables into two subsets , @xmath33 and @xmath34 , so that @xmath35 .",
    "the @xmath36 variables represent the variables of @xmath32 that are removed by marginalization , i.e. @xmath37    after arranging these chains in parallel we have the larger process @xmath38 the probability density of a move to @xmath39 given that @xmath40 for @xmath41 is given by @xmath42 since @xmath43 the stationary distribution of @xmath44 is @xmath45    the next step in the construction is to allow interactions between the chains @xmath46 and to thereby pass information from the rapidly equilibrating chains on the lower dimensional spaces ( large @xmath47 ) down to the chain on the original space ( @xmath48 ) .",
    "this is accomplished by swap moves . in a swap move between levels @xmath47 and @xmath49 , we take a @xmath50 dimensional subset , @xmath51 , of the @xmath32 variables and exchange them with the @xmath52 variables .",
    "the remaining @xmath53 @xmath36 variables are resampled from the conditional distribution @xmath54 . for the full chain , this swap takes the form of a move from @xmath40 to @xmath39 where @xmath55 and @xmath56 the ellipses represent components of @xmath44 that remain unchanged in the transition and @xmath57 is drawn from @xmath54 .    if these swaps are undertaken unconditionally , the resulting chain with equilibrate rapidly , but will not , in general , preserve the product distribution @xmath58 . to remedy this",
    "we introduce the swap acceptance probability @xmath59 in this formula @xmath60 is the function on @xmath61 resulting from marginalization of @xmath62 as in equation [ def : marginal ] .",
    "given that @xmath40 , the probability density of @xmath39 , after the proposal and either acceptance with probability @xmath63 or rejection with probability @xmath64 , of a swap move , is given by @xmath65 for @xmath66 .",
    "@xmath67 is the dirac delta function .",
    "we have the following lemma .",
    "the transition probabilities @xmath68 satisfy the detailed balance condition for the measure @xmath69 i.e. @xmath70 where @xmath71    the detailed balance condition stipulates that the probability of observing a transition @xmath72 is equal to that of observing a transition @xmath73 and guarantees that the resulting markov chain preserves the distribution @xmath58 .",
    "therefore , under general conditions , averages over a trajectory of @xmath74 will converge to averages over @xmath58 . since @xmath75",
    "we can calculate averages over @xmath4 by taking averages over the trajectories of the first @xmath0 components of @xmath44 .",
    "notice that the formula [ def : a_i ] for @xmath63 requires the evaluation of @xmath60 at the points @xmath76 while the approximation of @xmath60 by functions on @xmath61 is in general a very difficult problem , its evaluation at a single point is often not terribly demanding . in fact , in many cases , including the examples in this paper , the @xmath51 variables can be chosen so that the remaining @xmath36 variables are conditionally independent given @xmath77    despite these mitigating factors , the requirement that we evaluate @xmath60 before we accept any swap is a little onerous . fortunately , and somewhat",
    "surprisingly , this requirement is not necessary .",
    "in fact , standard strategies for approximating the point values of the marginals yield markov chains that themselves preserve the target measure . thus even a poor estimate of the ratio appearing in [ def : a_i ] can give rise to a method that is exact in the sense that the resulting markov chain will asymptotically sample the target measure .    to illustrate this point , we consider the following example of a swap move .",
    "assume that the current position of the chain is @xmath40 where @xmath55 the following steps will result in either @xmath78 or @xmath39 where @xmath79 and @xmath80 .    1 .",
    "let @xmath81 and let @xmath82 for @xmath83 be independent samples from @xmath84 where @xmath85 is a reference density conditioned by @xmath51 .",
    "for example , @xmath85 could be a gaussian approximation of @xmath86 .",
    "how @xmath87 is chosen depends on the problem at hand ( see numerical examples below ) . in general @xmath85 should be easily evaluated and independently sampled , and it should `` cover '' @xmath88 in the sense that areas of @xmath89 where @xmath88 is not negligible should be contained in areas where @xmath85 is not negligible . 2 .",
    "let @xmath90 for @xmath91 be independent random variables sampled from @xmath92 ( recall that we are considering a swap of @xmath51 and @xmath93 which live in the same space ) .",
    "notice that the @xmath94 variables depend on @xmath52 while the @xmath95 variables depend on @xmath51 .",
    "3 .   define the weights @xmath96 the choice of @xmath87 made above affects the variance of these weights , and therefore the variance of the acceptance probability below .",
    "4 .   choose @xmath57 from among the @xmath94 according to the multinomial distribution with probabilities @xmath97 notice that @xmath57 is an approximate sample from @xmath98 5",
    ".   set @xmath99 with probability @xmath100 and @xmath101 with probability @xmath102 .    the transition probability density for the above swap move from @xmath72 for @xmath66is given by @xmath103 where @xmath104 and @xmath67 is again the dirac delta function . in other words",
    ", @xmath105 dictates that the markov chain accepts the swap with probability @xmath106 and rejects it with probability @xmath107 .",
    "while the preceding swap move corresponds to a method for approximating the ratio @xmath108 appearing in the formula for @xmath63 above , it also has some similarities with the multiple - try metropolis method presented in @xcite which uses multiple suggestion samples to improve acceptance rates of standard mcmc methods .",
    "the following lemma is suggested by results in @xcite .",
    "the transition probabilities @xmath105 satisfy the detailed balance condition for the measure @xmath109    as before the detailed balance condition guarantees that averages over trajectories of the first @xmath0 dimensions of @xmath44 will converge to averages over @xmath4 .",
    "the @xmath110 contain an approximation to the ratio of marginals in [ def : a_i ] @xmath111{a.s .",
    "} & \\frac{\\mathbf{e}_{p_i}\\left[\\frac{\\pi_i\\left(x_{i+1},\\widetilde{x}_i\\right ) } { p_i\\left(\\widetilde{x}_i\\vert x_{i+1}\\right)}\\ \\vert \\left\\{\\widehat{x}_i = x_{i+1}\\right\\}\\right ] } { \\mathbf{e}_{p_i}\\left[\\frac{\\pi_i\\left(\\hat{x}_i,\\widetilde{x}_i\\right ) } { p_i\\left(\\widetilde{x}_i\\vert \\hat{x}_i\\right)}\\ \\vert \\left\\{\\widehat{x}_i=\\hat{x}_i\\right\\}\\right]}\\\\ = & \\frac{\\overline{\\pi}_i(x_{i+1})}{\\overline{\\pi}_i(\\hat{x}_i)}\\end{aligned}\\ ] ] where @xmath112 denotes expectation with respect to the density @xmath113 when @xmath114<\\infty$ ] , the convergence above follows from the strong law of large numbers and the fact that @xmath115   = \\int \\frac{\\pi_i(\\hat{x}_i,\\tilde{x}_i)}{p_i(\\tilde{x}_i\\vert\\hat{x}_i ) } p_i(\\tilde{x}_i\\vert\\hat{x}_i)\\ d\\tilde{x}_i\\\\ = \\int \\pi_i(\\hat{x}_i,\\tilde{x}_i)\\ d\\tilde{x}_i = \\overline{\\pi_i}(\\hat{x}_i)\\end{gathered}\\ ] ] for small values of @xmath116 in [ def : a^m_i ] , calculation of the swap acceptance probabilities is very cheap .",
    "however , higher values of @xmath116 may improve the acceptance rates .",
    "for example , if the @xmath117 are exact marginals of @xmath118 then @xmath119 while @xmath120 results similar to lemma 2 hold when more general approximations replace the one given above ; for example when the @xmath94 and @xmath95 are generated by a metropolis - hastings rule .",
    "in practice one has to balance the speed of evaluating @xmath121 for small @xmath116 with the possible higher acceptance rates for @xmath116 large .",
    "it is easy to see that a markov chain which evolves only by swap moves will only sample a finite number of configurations .",
    "these swap moves must therefore be used in conjunction with a transition rule that can reach any region of space , such as @xmath122 from expression [ def : t ] .",
    "more precisely , @xmath122 should be @xmath58-irreducible and aperiodic ( see @xcite ) .",
    "the the transition rule for parallel marginalization is @xmath123 where @xmath124 and @xmath125 is the probability that a swap move occurs .",
    "@xmath126 dictates that , with probability @xmath127 , the chain attempts a swap move between levels @xmath128 and @xmath129 where @xmath128 is a random variable chosen uniformly from @xmath130 .",
    "next , each level of the chain evolves independently according to the @xmath131 . with probability @xmath132",
    "the chain does not attempt a swap move , but does evolve each level .",
    "the next result follows trivially from lemma 2 and guarantees the invariance of @xmath58 under evolution by @xmath126 .",
    "the transition probability @xmath126 satisfies the detailed balance condition for the measure @xmath69 i.e. @xmath133 where @xmath134    thus by combining standard mcmc steps on each component governed by the transition probability @xmath122 , with swap steps between the components governed by @xmath135 , an mcmc method results which not only uses information from rapidly equilibrating lower dimensional chains , but is also convergent .",
    "in the bridge path sampling problem we wish to approximate conditional expectations of the form @xmath136\\ ] ] where @xmath137 and @xmath138 is the real valued processes given by the solution of the stochastic differential equation @xmath139 @xmath140 , @xmath141 and @xmath142 are real valued functions of @xmath143 . of course we can also consider functions @xmath140 of more than one time .",
    "this problem arises , for example , in financial volatility estimation . because in general we can not sample paths of [ sde1 ] we must first approximate @xmath138 by a discrete process for which the path density is readily available . let @xmath144 be a mesh on which we wish to calculate path averages .",
    "one such approximate process is given by the linearly implicit euler scheme ( a balanced implicit method , see @xcite ) , @xmath145 the @xmath146 are independent gaussian random variables with mean 0 and variance 1 , and @xmath147 @xmath148 is assumed to be a power of 2 .",
    "the choice of this scheme over the euler scheme ( see @xcite ) is due to its favorable stability properties as explained later . without the condition @xmath149 above , generating samples of @xmath150 is a relatively straitforward endeavor .",
    "one simply generates a sample of @xmath151 , then evolves the system with this initial condition .",
    "however , the presence of information about @xmath152 complicates the task . in general ,",
    "some sampling method which requires only knowlege of a function proportional to conditional density of @xmath153 must be applied .",
    "the approximate path density associated with discretization [ def : lie ] is @xmath154 where @xmath155 ^ 2 } { 2\\sigma^2\\left(x\\right)\\triangle}\\ ] ]    at this point we wish to apply the parallel marginalization sampling procedure to the density @xmath4 .",
    "however , as indicated above , a prerequisite for the use of parallel marginalization is the ability to estimate marginal densities . in some important problems homogeneities in the underlying system yield simplifications in the calculation of these densities by the methods in @xcite .",
    "these calculations can be carried out before implementation of parallel marginalization , or they can be integrated into the sampling procedure .    in some cases , the numerical estimation of the @xmath117 can be completely avoided .",
    "the examples presented here are two such cases .",
    "let @xmath156 .",
    "decompose @xmath68 as @xmath157 where @xmath158 and @xmath159 in the notation of the previous sections , @xmath35 where @xmath160 and @xmath161 in words , the hat and tilde variables represent alternating time slices of the path . for all @xmath47 fix @xmath162 and @xmath163 .",
    "we choose the approximate marginal densities @xmath164 where for each @xmath47 , @xmath165 is defined by successive coarsenings of [ def : lie ] .",
    "that is , @xmath166 since @xmath62 will be sampled using a metropolis - hastings method with @xmath167 and @xmath168 fixed , knowlege of the normalization constants @xmath169 is unnecessary .",
    "notice from [ def : pi_0:ex1 ] that , conditioned on the values of @xmath170 and @xmath171 , the variance of @xmath172 is of order @xmath173 .",
    "thus any perturbation of @xmath172 which leaves @xmath174 fixed for @xmath175 and which is compatible with joint distribution [ def : pi_0:ex1 ] must be of the order @xmath176 .",
    "this suggests that distributions defined by coarser discretizations of [ def : pi_0:ex1 ] will allow larger perturbations , and consequently will be easier to sample .",
    "however , it is important to choose a discretization that remains stable for large values of @xmath173 .",
    "for example , while the linearly implicit euler method performs well in the experiments below , similar tests using the euler method were less successful due to limitations on the largest allowable values of @xmath173 .    in this numerical example",
    "bridge paths are sampled between time 0 and time 10 for a diffusion in a double well potential @xmath177 the left and right end points are chosen as @xmath178 .",
    "@xmath179 is the @xmath180 level of the parallel marginalization markov chain at algorithmic time @xmath10 .",
    "there are 10 chains ( @xmath181 in expression [ def : t ] ) .",
    "the observed swap acceptance rates are reported in table 1 .",
    "let @xmath182 denote the midpoint of the path defined by @xmath183 ( i.e. an approximate sample of the path at time 5 ) . in fig .",
    "1 the autocorrelation of @xmath184 @xmath185\\ ] ] is compared to that of a standard metropolis - hastings rule . in the figure ,",
    "the time scale of the autocorrelation for the metropolis - hastings method has been scaled by a factor of 1/10 to more than account for the extra computational time required per iteration of parallel marginalization .",
    "the relaxation time of the parallel chain is clearly reduced . in these numerical examples ,",
    "the algorithm in the previous section is applied with a slight simplification .",
    "first generate m independent gaussian random paths @xmath186 with independent components @xmath187 of mean 0 and variance @xmath188 .",
    "for each @xmath189 and @xmath190 let @xmath191 if in step 4 , @xmath192 , then in step 1 we set @xmath81 and for each @xmath190 @xmath193 all other steps remain the same .",
    "this change yields a slightly faster though less generally applicable swap step that also preserves the density @xmath58 .",
    "notice that this modification implies that the reference density @xmath87 is given by @xmath194 for this problem , the choice of @xmath116 in [ def : a^m_i ] , the number of samples of @xmath94 and @xmath95 , seems to have little effect on the swap acceptance rates . in the numerical experiment @xmath195 for swaps between levels @xmath47 and @xmath49 .",
    "in the non - linear smoothing and filtering problem we wish to approximate conditional expectations of the form @xmath196\\ ] ] where @xmath137 and the real valued processes @xmath138 and @xmath197 are given by the system @xmath198 @xmath140 , @xmath141 , @xmath142 , and @xmath199 are real valued functions of @xmath143 .",
    "the @xmath200 are real valued independent random variable drawn from the density @xmath201 and are independent of the brownian motion @xmath202 @xmath203 and @xmath204 the process @xmath205 is a hidden signal and the @xmath197 are noisy observations .",
    "again , the system must first be discretized .",
    "the linearly implicit euler scheme gives @xmath206 the @xmath146 are independent gaussian random variables with mean 0 and variance 1 , and @xmath147 the @xmath146 are independent of the @xmath200 .",
    "@xmath148 is again assumed to be a power of 2 .",
    "the approximate path measure for this problem is @xmath207 the approximate marginals are chosen as @xmath208 where @xmath209 , @xmath165 and @xmath68 are as defined in the previous section .    in this example , samples of the smoothed path are generated between time time 0 and time 10 for the same diffusion in a double well potential .",
    "the densities @xmath201 and @xmath210 are chosen as @xmath211 the observation times are @xmath212 with @xmath213 for @xmath214 and @xmath215 for @xmath216 .",
    "there are 8 chains ( @xmath217 in expression [ def : t ] ) .",
    "the observed swap acceptance rates are reported in table 1 .",
    "again , @xmath182 denotes the midpoint of the path defined by @xmath183 ( i.e. an approximate sample of the path at time 5 ) . in fig .",
    "2 the autocorrelation of @xmath184 is compared to that of a standard metropolis - hastings rule .",
    "the figure has been adjusted as in the previous example .",
    "the relaxation time of the parallel chain is again clearly reduced .",
    "the algorithm is modified as in the previous example . for this problem ,",
    "acceptable swap rates require a higher choice of @xmath116 in [ def : a^m_i ] than needed in the bridge sampling problem . in this numerical experiment @xmath218 for swaps between levels @xmath47 and @xmath49 .",
    "a markov chain monte carlo method has been proposed and applied to two conditional path sampling problems for stochastic differential equations .",
    "numerical results indicate that this method , parallel marginalization , can have a dramatically reduced equilibration time when compared to standard mcmc methods .",
    "note that parallel marginalization should not be viewed as a stand alone method .",
    "other acceleration techniques such as hybrid monte carlo can and should be implemented at each level within the parallel marginalization framework .",
    "as the smoothing problem indicates , the acceptance probabilities at coarser levels can become small .",
    "the remedy for this is the development of more accurate approximate marginal distributions by , for example , the methods in @xcite and @xcite .",
    "i would like to thank prof .",
    "a. chorin for his guidance during this research , which was carried out during my ph.d .",
    "studies at u. c. berkeley .",
    "i would also like to thank dr .",
    "p. okunev , and dr .",
    "p. stinis for very helpful discussions and comments .",
    "this work was supported by the director , office of science , office of advanced scientific computing research , of the u. s. department of energy under contract no .",
    "de - ac03 - 76sf00098 .",
    "chorin , a. ( 2003 ) _ multiscale model .",
    "simul . _ * 1 * , 105118 .",
    "stinis , p. ( 2005 ) _ j. comput",
    ". phys . _ * 208 * , 691703 .",
    "goodman , j. and sokal , a. ( 1989 ) _ physical review d _ * 40 * , 20352071 .",
    "brandt , a. and ron , d. ( 2001 ) _",
    "phys . _ * 102 * , 163 - 186 .",
    "okunev , p. ( 2005 ) _ renormalization methods with applications to spin systems and to finance _ _ ph.d .",
    "( u. c. berkeley ) liu , j. ( 2002 ) _ monte carlo strategies in scientific computing . _",
    "( springer ) binder , k. and heermann , d. ( 2002 ) _ monte carlo simulation in statistical physics . _ ( springer ) binney , j. , dowrick , n. , fisher , a. and newman , m. ( 1992 ) _ the theory of critical phenomena : an introduction to the renormalization group . _",
    "( oxford university press , usa ) kadanoff , l. ( 1966 ) _ physics _ * 2 * , 263 .",
    "liu , j. , liang , f. and wong , w. ( 2000 ) _",
    "assoc . _ * 95 * , 121 - 134 .",
    "tierney , l. ( 1994 ) _ annals of statistics _ * 22 * , 1701 - 1728 .",
    "milstein , g. , platen , e. and schurz , h. ( 1998 ) _ siam j. numer .",
    "* 35 * , 1010 - 1019 .",
    "kloeden , p. and platen , e. ( 1992 ) _ numerical solution of stochastic differential equations . _",
    "( springer ) apte , a. , hairer , h. , stuart , a. and voss , j. ( 2001 ) _ physica d _ to appear .",
    "chorin , a. and hald , o. ( 2005 ) _ stochastic tools for mathematics and science . _",
    "( springer ) .",
    "chorin , a. , hald , o. and kupferman , r. ( 2002 ) _ phys .",
    "d _ * 166 * , 239257 .",
    "e , w. , liu , d. and vanden - eijnden , e. ( 2005 ) _ comm .",
    "pure appl .",
    "_ * 11 * , 15441585 .",
    "e , w. , ren , w. and vanden - eijnden , e. ( 2003 ) _",
    "b _ * 109 * , 6688 - 6693 .",
    "efendiev , y. and hou , t. and luo , w. ( 2006 ) _ siam j. sci . comput _ * 28 * , 776803 .",
    "gear , c. and kevrekidis , i. ( 2003 ) _ siam j. sci .",
    "* 24 * , 10911106 .",
    "goldenfeld , n. ( 1992 ) _ lectures on phase transitions and the renormalization group . _",
    "( westview press ) kadanoff , l. ( 2000 ) _ statistical physics .",
    "statics , dynamics and renormalization . _",
    "( world scientific ) stinis , p. ( 2004 ) _ multiscale model .",
    "* 2 * , 580612 .",
    "stuart , a. , voss , j. and wiberg , p. ( 2004 ) _ commun .",
    "* 2 * , 685697 .",
    "@rrrrrrrrrrrrr 1clevels & 1c0/1&1c1/2 & 1c2/3&1c3/4 & 1c4/5&1c5/6 & 1c6/7&1c7/8 & 1c8/9 1cbs & 1c0.86&1c0.83 & 1c0.75&1c0.69 & 1c0.54&1c0.45 & 1c0.30&1c0.22 & 1c0.26 1cfs & 1c0.86&1c0.83 & 1c0.74&1c0.65 & 1c0.46&1c0.23 & 1c0.04&1cna & 1cna"
  ],
  "abstract_text": [
    "<S> markov chain monte carlo sampling methods often suffer from long correlation times . </S>",
    "<S> consequently , these methods must be run for many steps to generate an independent sample . in this paper </S>",
    "<S> a method is proposed to overcome this difficulty . </S>",
    "<S> the method utilizes information from rapidly equilibrating coarse markov chains that sample marginal distributions of the full system . </S>",
    "<S> this is accomplished through exchanges between the full chain and the auxiliary coarse chains . </S>",
    "<S> results of numerical tests on the bridge sampling and filtering / smoothing problems for a stochastic differential equation are presented .    </S>",
    "<S> n order to understand the behavior of a physical system it is often necessary to generate samples from complicated high dimensional distributions . </S>",
    "<S> the usual tools for sampling from these distributions are markov chain monte carlo methods ( mcmc ) by which one constructs a markov chain whose trajectory averages converge to averages with respect to the distribution of interest . for some simple systems it is possible to construct markov chains with independent values at each step . in general , however , spatial correlations in the system of interest result in long correlation times in the markov chain and hence slow convergence of the chain s trajectory averages . in this paper , a method is proposed to alleviate the difficulties caused by spatial correlations in high dimensional systems . </S>",
    "<S> the method , parallel marginalization , is tested on two stochastic differential equation conditional path sampling problems .    </S>",
    "<S> parallel marginalization takes advantage of the shorter correlation lengths present in marginal distributions of the target density . </S>",
    "<S> auxiliary markov chains that sample approximate marginal distributions are evolved simultaneously with the markov chain that samples the distribution of interest . by swapping their configurations , </S>",
    "<S> these auxiliary chains pass information between themselves and with the chain sampling the original distribution . </S>",
    "<S> as shown below , these swaps are made in a manner consistent with both the original distributions and the approximate marginal distributions . </S>",
    "<S> the numerical examples indicate that improvement in efficiency of parallel marginalization over standard mcmc techniques can be significant .    </S>",
    "<S> the design of efficient methods to approximate marginal distributions was addressed in @xcite by chorin and in @xcite by stinis . </S>",
    "<S> the use of monte carlo updates on coarse subsets of variables is not a new concept ( see @xcite and the references therein ) . </S>",
    "<S> the method presented in @xcite does not use marginal distributions . </S>",
    "<S> however , attempts have been made previously to use marginal distributions to accelerate the convergence of mcmc ( see @xcite ) . </S>",
    "<S> in contrast to parallel marginalization , the methods proposed in @xcite and @xcite do not preserve the distribution of the full system and therefore are not guaranteed to converge . </S>",
    "<S> the parallel construction used here is motivated by the parallel tempering method ( see @xcite ) , and allows efficient comparison of the auxiliary chains and the original chain . </S>",
    "<S> see references @xcite and @xcite for expositions of standard mcmc methods .    </S>",
    "<S> parallel marginalization for problems in euclidean state spaces is described in detail in the next two sections . in the final sections </S>",
    "<S> the conditional path sampling problem is described and numerical results are presented for the bridge sampling and smoothing / filtering problems . </S>"
  ]
}