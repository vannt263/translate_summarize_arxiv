{
  "article_text": [
    "let us start with a ( very rough ) scheme .",
    "imagine an experiment that produces some bit string @xmath1 .",
    "we know nothing about the device that produced this data , and can not repeat the experiment .",
    "still we want to suggest some statistical model that fits the data ( `` explains '' @xmath1 in a plausible way ) .",
    "this model is a probability distribution on some finite set of binary strings containing @xmath1 .",
    "what do we expect from a reasonable model ?",
    "there are , informally speaking , two main properties of a good model .",
    "first , the model should be `` simple '' .",
    "if a model contains so many parameters that it is more complicated than the data itself , we would not consider it seriously . to make this requirement more formal , one can use the notion of kolmogorov complexity .",
    "let us assume that measure @xmath2 ( used as a model ) has finite support and rational values .",
    "then @xmath2 can be considered as a finite ( constructive ) object , so we can speak about kolmogorov complexity of @xmath2 .",
    "the requirement then says that complexity of @xmath2 should be much smaller than the complexity of the data string @xmath1 itself .",
    "for example , if a data string @xmath1 contains @xmath3 bits , we may consider a model that corresponds to @xmath3 independent fair coin tosses , i.e. , the uniform distribution @xmath2 on the set of all @xmath3-bit strings .",
    "such a distribution is a constructive object that is completely determined by the value of @xmath3 , so its complexity is @xmath4 , while the complexity of most @xmath3-bit strings is close to @xmath3 ( and therefore is much larger than the complexity of @xmath2 , if @xmath3 is large enough ) .",
    "still this simple model looks unacceptable if , for example , the sequence @xmath1 consists of @xmath3 zeros , or , more generally , if the frequency of ones in @xmath1 deviates significantly from @xmath5 , or if zeros and ones alternate .",
    "this feeling was one of the motivations for the development of algorithmic randomness notions : why some bit sequences of length @xmath3 look plausible as outcomes of @xmath3 fair coin tosses while other do not , while all the @xmath3-bit sequences have the same probability @xmath6 according to the model ?",
    "this question does not have a clear answer in the classical probability theory , but the algorithmic approach to randomness says that plausible strings should be incompressible : the complexity of such a string ( the minimal length of a program producing it ) should be close to its length .",
    "this answer works for a uniform distribution on @xmath3-bit strings ; for arbitrary @xmath2 it should be modified .",
    "it turns out that for arbitrary @xmath2 we should compare the complexity of @xmath1 not with its length but with the value @xmath7 ( all logarithms are binary ) ; if @xmath2 is the uniform distribution on @xmath3-bit strings , the value of @xmath7 is @xmath3 for all @xmath3-bit strings @xmath1 .",
    "namely , we consider the difference between @xmath7 and complexity of @xmath1 as _ randomness deficiency _ of @xmath1 with respect to @xmath2 . we discuss the exact definition in the next section , but let us note here that this approach looks natural : different data strings require different models .",
    "_ disclaimer_. the scheme above is oversimplified in many aspects .",
    "first , it rarely happens that we have no a priori information about the experiment that produced the data .",
    "second , in many cases the experiment can be repeated ( the same experimental device can be used again , or a similar device can be constructed ) .",
    "also we often deal with a data stream : we are more interested , say , in a good prediction of oil prices for the next month than in a construction of model that fits well the prices in the past .",
    "all these aspects are ignored in our simplistic model ; still it may serve as an example for more complicated cases .",
    "one should stress also that algorithmic statistics is more theoretical than practical : one of the reasons is that complexity is a non - computable function and is defined only asymptotically , up to a bounded additive term .",
    "still the notions and results from this theory can be useful not only as philosophical foundations of statistics but as a guidelines when comparing statistical models in practice ( see , for example ,  @xcite )",
    ".    more practical approach to the same question is provided by machine learning that deals with the same problem ( finding a good model for some data set ) in the `` real world '' .",
    "unfortunately , currently there is a big gap between the algorithmic statistics and machine learning : the first one provides nice results about mathematical models that are quite far from practice ( see the discussion about `` standard models '' below ) , while machine learning is a tool that sometimes works well without any theoretical reasons .",
    "there are some attempts to close this gap ( by considering models from some class or resource - bounded versions of the notions ) , but much more remains to be done .",
    "_ a historical remark_. the principles of algorithmic statistics are often traced back to occam s razor principle often stated as `` do nt multiply postulations beyond necessity '' or in a similar way .",
    "poincare writes in his _ science and method _ ( chapter 1 , _ the choice of facts _ ) that `` this economy of thought , this economy of effort , which is , according to mach , the constant tendency of science , is at the same time a source of beauty and a practical advantage '' .",
    "still the mathematical analysis of these ideas became possible only after a definition of algorithmic complexity was given in 1960s ( by solomonoff , kolmogorov and then chaitin ) : after that the connection between randomness and incompressibility ( high complexity ) became clear .",
    "the formal definition of @xmath0-stochasticity ( see the next section ) was given by kolmogorov ( the authors learned it from his talk given in 1981  @xcite , but most probably it was formulated earlier in 1970s ; the definition appeared in print in  @xcite ) .",
    "for the other related approaches ( the notions of logical depth and sophistication , minimal description length principle ) see the discussion in the corresponding sections ( see also  ( * ? ? ?",
    "* chapter 5 ) . )",
    "preparing for the precise definition of @xmath0-stochasticity , we need to fix the version of complexity used in this definition .",
    "there are several versions ( plain and prefix complexities , different types of conditions ) , see ( * ? ? ?",
    "* chapter 6 ) . for most of the results",
    "the choice between these versions is not important , since the difference between the different versions is small ( at most @xmath4 for strings of length @xmath3 ) , and we usually allow errors of logarithmic size in the statements .",
    "we will use the notion of _ conditional prefix complexity _ , usually denoted by @xmath8 . here",
    "@xmath1 and @xmath9 are finite objects ; we measure the complexity of @xmath1 when @xmath9 is given .",
    "this complexity is defined as the length of the minimal prefix - free program that , given @xmath9 , computes @xmath1 . , but these sets may differ for different @xmath9 and the union is not required to be prefix - free . ]",
    "the advantage of this definition is that it has an equivalent formulation in terms of a priori probability  ( * ? ? ?",
    "* chapter 4 ) : if @xmath10 is the conditional a priori probability , i.e. , the maximal lower semicomputable function of two arguments @xmath1 and @xmath9 such that @xmath11 for every @xmath9 , then @xmath12 in particular , if a probability distribution @xmath2 with finite support and rational values ( we consider only distributions of this type ) is considered as a condition , we may compare @xmath13 with function @xmath14 and conclude that @xmath15 up to an @xmath16-factor , so @xmath17 .",
    "so if we define the randomness deficiency as @xmath18 we get a non - negative ( up to @xmath16 additive term ) function .",
    "one may also explain in a different way why @xmath19 : this inequality is a reformulation of a standard result from information theory ( shannon  fano code , kraft inequality ) .    why do we define the deficiency in this way ?",
    "the following proposition provides some additional motivation .",
    "the function @xmath20 is ( up to @xmath16-additive term ) the maximal lower semicomputable function of two arguments @xmath1 and @xmath2 such that @xmath21 for every @xmath2 .",
    "here @xmath1 is a binary string , and @xmath2 is a probability distribution on binary strings with finite support and rational values . by lower semicomputable functions we mean functions that can be approximated from below by some algorithm ( given @xmath1 and @xmath2 , the algorithm produces an increasing sequence of rational numbers that converges to @xmath20 ;",
    "no bounds for the convergence speed are required ) .",
    "then , for a given @xmath2 , the function @xmath22 can be considered as a random variable on the probability space with distribution @xmath2 .",
    "the requirement @xmath23 says that its expectation is at most @xmath24 . in this way we guarantee ( by markov inequality ) that only a @xmath2-small fraction of strings have large deficiency : the @xmath2-probability of the event @xmath25 is at most @xmath26 .",
    "it turns out that there exists a maximal function @xmath27 satisfying @xmath23 up to @xmath16 additive term , and our formula gives the expression for this function in terms of prefix complexity .",
    "the proof uses standard arguments from kolmogorov complexity theory .",
    "the function @xmath28 is upper semicomputable , so @xmath20 is lower semicomputable .",
    "we can also note that @xmath29 so the deficiency function satisfies  @xmath23 .    to prove the maximality , consider an arbitrary function @xmath30 that is lower semicomputable and satisfies @xmath23 . then consider a function @xmath31 ( the function equals @xmath32 if @xmath1 is not in the support of @xmath2 ) .",
    "then @xmath33 is lower semicomputable , @xmath34 for every @xmath2 , so @xmath35 up to @xmath16-factor ; this implies that @xmath36 .",
    "for the case where @xmath2 is the uniform distribution on @xmath3-bit strings , using @xmath2 as a condition is equivalent to using @xmath3 as the condition , so @xmath37 in this case , and small deficiency means that complexity @xmath38 is close to the length @xmath3 , so @xmath1 is incompressible . as `` randomness deficiency '' in this case , where @xmath39 stands for the plain ( not prefix ) complexity .",
    "one may also consider @xmath40 .",
    "but all three deficiency functions mentioned are close to each other for strings @xmath1 of length @xmath3 ; one can show that the difference between them is bounded by @xmath41 where @xmath27 is any of these three functions .",
    "the proof works by comparing the expectation and probability - bounded characterizations as explained in  @xcite . ]",
    "a string @xmath1 is called @xmath0-stochastic if there exists some probability distribution @xmath2 ( with rational values and finite support ) such that @xmath42 and @xmath43 .    by definition",
    "every @xmath0-stochastic string is @xmath44-stochastic for @xmath45 , @xmath46 .",
    "sometimes we say informally that a string is `` stochastic '' meaning that it is @xmath0-stochastic for some reasonably small thresholds @xmath47 and @xmath48 ( for example , one can consider @xmath49 for @xmath3-bit strings ) .",
    "let us start with some simple remarks .",
    "* every simple string is stochastic . indeed ,",
    "if @xmath2 is concentrated on @xmath1 ( singleton support ) , then @xmath50 and @xmath51 ( in both cases with @xmath16-precision ) , so @xmath1 is always @xmath52-stochastic . * on the other end of the spectrum : if @xmath2 is a uniform distribution on @xmath3-bit strings , then @xmath53 , and most strings of length @xmath3 have @xmath54 , so most strings of length @xmath3 are @xmath55-stochastic .",
    "the same distribution also witnesses that every @xmath3-bit string is @xmath56-stochastic .",
    "* it is easy to construct stochastic strings that are between these two extreme cases .",
    "let @xmath1 be an incompressible string of length @xmath3 .",
    "consider the string @xmath57 ( the first half is @xmath1 , the second half is zero string ) .",
    "it is @xmath55-stochastic : let @xmath2 be the uniform distribution on all the strings of length @xmath58 whose second half contains only zeros .",
    "* for every distribution @xmath2 ( with finite support and rational values , as usual ) a random sampling according to @xmath2 gives us a @xmath59-stochastic string with probability at least @xmath60 .",
    "indeed , the probability to get a string with deficiency greater than @xmath9 is at most @xmath26 ( markov inequality , see above ) .    after these observations",
    "one may ask whether non - stochastic strings exists at all  and how they can be constructed ? a non - stochastic string should have non - negligible complexity ( our first observation ) , but a standard way to get strings of high complexity , by coin tossing or other random experiment , can give only stochastic strings ( our last observation ) .",
    "we will see that non - stochastic strings do exist in the mathematical sense ; however , the question whether they appear in the `` real world '' , is philosophical .",
    "we will discuss both questions soon , but let us start with some mathematical results .",
    "first of all let us note that with logarithmic precision we may restrict ourselves to uniform distributions on finite sets .",
    "[ prop : models - to - sets-1 ] let @xmath1 be an @xmath0-stochastic string of length @xmath3 .",
    "then there exist a finite set @xmath61 containing @xmath1 such that @xmath62 and @xmath63 , where @xmath64 is the uniform distribution on @xmath61 .",
    "since @xmath65 ( with @xmath16-precision , as usual ) , this proposition means that we may consider only uniform distributions in the definition of stochasticity , and get an equivalent ( up to logarithmic change in the parameters ) definition .",
    "according to this modified definition , a string @xmath1 in @xmath0-stochastic if there exists a finite set @xmath61 such that @xmath66 and @xmath67 , where @xmath68 is now defined as @xmath69 .",
    "kolmogorov originally proposed the definition in this form ( but used plain complexity ) .",
    "let @xmath2 be the ( finite ) distribution that exists due to the definition of @xmath0-stochasticity of @xmath1",
    ". we may assume without loss of generality that @xmath70 ( as we have seen , all strings of length @xmath3 are @xmath56-stochastic , so for @xmath71 the statement is trivial ) . consider the set @xmath61 formed by all strings that have sufficiently large @xmath2-probability .",
    "namely , let us choose minimal @xmath72 such that @xmath73 and consider the set @xmath61 of all strings such that @xmath74",
    ". by construction @xmath61 contains @xmath1 .",
    "the size of @xmath61 is at most @xmath75 , and @xmath76 with @xmath16-precision . according to our assumption , @xmath77 , so @xmath78 .",
    "then @xmath79 since @xmath61 is determined by @xmath80 , and the additional information in @xmath72 is @xmath81 since @xmath82 by our assumption .",
    "so the deficiency may increase only by @xmath4 when we replace @xmath2 by @xmath64 , and @xmath83 for the same reasons .",
    "similar argument can be applied if @xmath2 is a computable distribution ( may be , with infinite support ) computed by some program @xmath84 , and we require @xmath85 and @xmath86 .",
    "so in this way we also get the same notion ( with logarithmic precision ) .",
    "it is important , however , that program @xmath84 _ computes _ the distribution @xmath2 ( given some point @xmath1 and some precision @xmath87 , it computes the probability of @xmath1 with error at most @xmath88 ) .",
    "it is _ not _ enough for @xmath2 to be an output distribution for a randomized algorithm @xmath84 ( in this case @xmath2 is called the semimeasure lower _ semicomputed _ by @xmath84 ; note that the sum of probabilities may be strictly less than @xmath24 since the computation may diverge with positive probability ) .",
    "similarly , it is very important in the version with finite sets @xmath61 ( and uniform distributions on them ) that the set @xmath61 is considered as a finite object : @xmath61 is simple if there is a short program that prints the list of all elements of @xmath61 .",
    "if we allowed the set @xmath61 to be presented by an algorithm that enumerates @xmath61 ( but never says explicitly that no more elements will appear ) , then situation would change drastically : for every string of complexity @xmath72 the finite set @xmath89 of strings that have complexity at most @xmath72 , would be a good explanation for @xmath1 , so all objects would become stochastic .",
    "we have defined stochasticity for binary strings .",
    "however , the same definition can be used for arbitrary finite ( constructive ) objects : pairs of strings , tuples of strings , finite sets of strings , graphs , etc .",
    "indeed , complexity can be defined for all these objects as the complexity of their encodings ; note that the difference in complexities for different encodings is at most @xmath16 .",
    "the same can be done for finite sets of these objects ( or probability distributions ) , so the definition of @xmath0-stochasticity makes sense .",
    "one can also note that computable bijection preserves stochasticity ( up to a constant that depends on the bijection , but not on the object ) .",
    "in fact , a stronger statement is true : every total computable mapping preserves stochasticity .",
    "for example , consider a stochastic pair of strings @xmath90 .",
    "does it imply that @xmath1 ( or @xmath91 ) is stochastic ?",
    "it is indeed the case : if @xmath2 is a distribution on pairs that is a reasonable model for @xmath90 , then its projection ( marginal distribution on the first components ) should be a reasonable model for @xmath1 .",
    "in fact , projection can be replaced by any _ total _ computable mapping .",
    "[ prop : stoch - cons ] let @xmath92 be a total computable mapping whose arguments and values are strings . if @xmath1 is @xmath0-stochastic , then @xmath93 is @xmath94-stochastic . here",
    "the constant in @xmath16 depends on @xmath92 but not on @xmath95 .",
    "let @xmath2 be the distribution such that @xmath96 and @xmath97 ; it exists according to the definition of stochasticity .",
    "let @xmath98 be the image distribution .",
    "in other words , if @xmath99 is a random variable with distribution @xmath2 , then @xmath100 has distribution @xmath101 .",
    "it is easy to see that @xmath102 , where the constant depends only on @xmath92 .",
    "indeed , @xmath101 is determined by @xmath2 and @xmath92 in a computable way .",
    "it remains to show that @xmath103 .    the easiest way to show",
    "this is to recall the characterization of deficiency as the maximal lower semicomputable function such that @xmath104 for every distribution @xmath105 .",
    "we may consider another function @xmath106 defined as @xmath107 it is easy to see that @xmath108(v)\\le 1\\ ] ] ( in the second equality",
    "we group all the values of @xmath109 with the same @xmath110 ) .",
    "therefore the maximality of @xmath27 guarantees that @xmath111 , so we get the required inequality .",
    "this proof can be also rephrased using the definition of stochasticity with a priori probability .",
    "we need to show that for @xmath112 and @xmath98 we have @xmath113 or @xmath114 it remains to note that the left hand side is a lower semicomputable function of @xmath1 and @xmath2 whose sum over all @xmath1 ( for every @xmath2 ) is at most @xmath24 . indeed , if we group all terms with the same @xmath93 , we get the sum @xmath115 , since the sum of @xmath116 over all @xmath1 with @xmath117 equals @xmath118 .    in this proof",
    "it is important that we use the definition with distributions .",
    "if we replace is with the definition with finite sets , the results remains true with logarithmic precision , but the argument becomes more complicated , since the image of the uniform distribution may not be a uniform distribution .",
    "so if a set @xmath61 is a good model for @xmath1 , we should not use @xmath119 as a model for @xmath93 .",
    "instead , we should look at the maximal @xmath72 such that @xmath120 , and consider the set of all @xmath121 that have at least @xmath75 preimages in @xmath61 .",
    "[ rem : non - total ] it is important in proposition  [ prop : stoch - cons ] that @xmath92 is a total function .",
    "if @xmath1 is some non - stochastic object and @xmath122 is the shortest program for @xmath1 , then @xmath122 is incompressible and therefore stochastic .",
    "still the interpreter ( decompressor ) maps @xmath122 to @xmath1 .",
    "we discuss the case of non - total @xmath92 below , see section  [ subsec : depth - appl ] .",
    "[ rem : cons - f ] a similar argument shows that @xmath123 ( for total @xmath92 ) , so both @xmath16-bounds in proposition  [ prop : stoch - cons ] may be replaced by @xmath124 where @xmath16-constant does not depend on @xmath92 anymore .",
    "note that up to now we have not shown that non - stochastic objects exist at all .",
    "it is easy to show that they exist for rather large values of @xmath47 and @xmath48 ( linearly growing with @xmath3 ) .",
    "[ prop : existence - nonstochastic ] for some @xmath9 and all @xmath3 :    ( 1 )  if @xmath125 , then there exist @xmath3-bit strings that are not @xmath0-stochastic ;    ( 2 )  however , if @xmath126 , then every @xmath3-bit string is @xmath0-stochastic .",
    "note that the term @xmath127 allows us to use the definition with finite sets ( i.e. , uniform distributions on finite sets ) instead of arbitrary finite distributions , since both versions are equivalent with @xmath4-precision .",
    "the second part is obvious ( and is added just for comparison ) : if @xmath128 , then all @xmath3-bit strings can be split into @xmath129 groups of size @xmath130 each",
    ". then the complexity of each group is @xmath131 , and the randomness deficiency of every string in the corresponding group is at most @xmath132 .",
    "it is slightly bigger than the bounds we need , but we have reserve @xmath127 , and @xmath47 and @xmath48 can be decreased , say , by @xmath133 before using this argument .    _",
    "the first part _ : consider all finite sets @xmath61 of strings that have complexity at most @xmath47 and size at most @xmath134 . since @xmath135 , they can not cover all @xmath3-bit strings .",
    "consider then the first ( say , in the lexicographical order ) @xmath3-bit string @xmath109 not covered by any of these sets .",
    "what is the complexity of @xmath109 ? to specify @xmath109 , it is enough to give @xmath136 and the program of size at most @xmath47 ( from the definition of kolmogorov complexity ) that has maximal running time among programs of that size .",
    "then we can wait until this program terminates and look at the outputs of all programs of size at most @xmath47 after the same number of steps , select sets of strings of size at most @xmath137 , and take the first @xmath109 not covered by these sets .",
    "so the complexity of @xmath109 is at most @xmath131 ( the last term is needed to specify @xmath136 ) .",
    "the same is true for conditional complexity with arbitrary condition , since it is bounded by the unconditional complexity .",
    "so the randomness deficiency of @xmath109 in every set @xmath61 of size @xmath134 is at least @xmath138 .",
    "we see that @xmath109 is not @xmath139-stochastic .",
    "again the @xmath4-term can be compensated by @xmath4-change in @xmath48 ( we have @xmath127 reserve for that ) .",
    "there is a gap between lower and upper bounds provided by proposition  [ prop : existence - nonstochastic ] . as we will see later , the upper bound  ( 2 ) is tight with @xmath4-precision , but we need more advanced technique ( properties of two - part descriptions , section  [ sec : two - part ] ) to prove this .",
    "proposition  [ prop : existence - nonstochastic ] shows that non - stochastic objects exist for rather large values of @xmath47 and @xmath48 ( proportional to @xmath3 ) .",
    "this , of course , is a mathematical existence result ; it does not say anything about the possibility to observe non - stochastic objects in the `` real world '' . as we have discussed , random sampling ( from a simple distribution ) may produce a non - stochastic object only with a negligible probability ; _ total _ algorithmic transformations ( defined by programs of small complexity ) also can not not create non - stochastic object from stochastic ones .",
    "what about non - total algorithmic transformations ?",
    "as we have discussed in remark  [ rem : non - total ] , a non - total computable transformation may transform a stochastic object into a non - stochastic one , but does it happen with non - negligible probability ?    consider a randomized algorithm that outputs some string .",
    "it can be considered as a deterministic algorithm applied to random bit sequence ( generated by the internal coin of the algorithm ) .",
    "this deterministic algorithm may be non - total , so we can not apply the previous result .",
    "still , as the following result shows , randomized algorithms also generate non - stochastic objects only with small probability .    to make this statement formal , we consider the sum of @xmath140 over all non - stochastic @xmath1 of length @xmath3 .",
    "since the a priori probability @xmath140 is the upper bound for the output distribution of any randomized algorithm , this implies the same bound ( up to @xmath16-factor ) for every randomized algorithm .",
    "the following theorem gives an upper bound for this sum :    [ prop : nonstochastic - counting ] @xmath141 for every @xmath3 and @xmath47 .",
    "consider the sum of @xmath140 over _ all _ strings of length @xmath3 .",
    "this sum is some real number @xmath142 .",
    "let @xmath143 be the number represented by first @xmath47 bits in the binary representation of @xmath144 , minus @xmath145 .",
    "we may assume that @xmath146 , otherwise all strings of length @xmath3 are @xmath147-stochastic .    now construct a probability distribution as follows .",
    "all terms in a sum for @xmath144 are lower semicomputable , so we can enumerate increasing lower bounds for them .",
    "when the sum of these lower bounds exceeds @xmath143 , we stop and get some measure @xmath2 with finite support and rational values .",
    "note that we have a measure , not a distribution , since the sum of @xmath116 for all @xmath1 is less than @xmath24 ( it does not exceed @xmath144 ) .",
    "so we normalize @xmath2 ( by some factor ) to get a distribution @xmath148 proportional to @xmath2 .",
    "the complexity of @xmath148 is bounded by @xmath131 ( since @xmath148 is determined by @xmath143 and @xmath3 ) .",
    "note that the difference between @xmath2 ( without normalization factor ) and a priori probability @xmath13 ( the sum of differences over all strings of length @xmath3 ) is bounded by @xmath149 .",
    "it remains to show that for @xmath13-most strings the distribution @xmath148 is a good model .",
    "let us prove that the sum of a priori probabilities of all @xmath3-bit strings @xmath1 that have @xmath150 is bounded by @xmath149 , if @xmath9 is large enough .",
    "indeed , for those strings we have @xmath151 the complexity of @xmath148 is bounded by @xmath131 and therefore @xmath152 exceeds @xmath153 at most by @xmath131 , so @xmath154 ( or @xmath155 ) for those strings , if @xmath9 is large enough ( it should exceed the constants hidden in @xmath4 notation ) .",
    "the difference @xmath24 is enough for the estimate below , but we could have arbitrary constant or even logarithmic difference by choosing larger value of  @xmath9 .    prefix complexity can be defined in terms of a priori probability , so we get @xmath156 for all @xmath1 that have deficiency exceeding @xmath157 with respect to @xmath148 .",
    "the same inequality is true for @xmath2 instead of @xmath148 , since @xmath2 is smaller .",
    "so for all those @xmath1 we have @xmath158 , or @xmath159 .",
    "recalling that the sum of @xmath160 over all @xmath1 of length @xmath3 does not exceed @xmath149 by construction of @xmath143 , we conclude that the sum of @xmath161 over all strings of randomness deficiency ( with respect to @xmath148 ) exceeding @xmath157 is at most @xmath149 .",
    "so we have shown that the sum of @xmath140 for all @xmath1 of length @xmath3 that are not @xmath162-stochastic , does not exceed @xmath149 .",
    "this differs from our claim only by @xmath4-change in @xmath47 .",
    "bruno bauwens noted that this argument can be modified to obtain a stronger result where @xmath147-stochasticity is replaced by @xmath163-stochasticity . instead of one measure @xmath2 , one should consider a family of measures .",
    "let us approximate @xmath144 and look when the approximations cross the thresholds corresponding to @xmath72 first bits of the binary expansion of @xmath144 .",
    "in this way we get @xmath164 , where @xmath165 has total weight at most @xmath166 , and complexity at most @xmath167 .",
    "let us show that all strings @xmath1 where @xmath116 is close to @xmath140 ( say , @xmath168 ) are @xmath169-stochastic , namely , one of the measures @xmath165 multiplied by @xmath170 is a good explanations for them .",
    "indeed , for such @xmath1 and some @xmath171 the value of @xmath172 coincides with @xmath140 up to polynomial ( in @xmath3 ) factor , since the sum of all @xmath165 is at least @xmath173 . on the other hand , @xmath174 , since the complexity of @xmath175 is at most @xmath167",
    ". therefore the ratio @xmath176 is polynomially bounded , and the model @xmath175 has deficiency @xmath4 .",
    "this better bound also follows from the levin s explanation , see below .",
    "this result shows that non - stochastic objects rarely appear as outputs of randomized algorithms .",
    "there is an explanation of this phenomenon ( that goes back to levin ) : non - stochastic objects provide a lot of information about halting problem , and the probability of appearance of an object that has a lot of information about some sequence @xmath47 , is small ( for any fixed @xmath47 ) .",
    "we discuss this argument below , see section  [ subsec : halting - information ] .",
    "it is natural to ask the following general question . for a given string @xmath1",
    ", we may consider the set of all pairs @xmath0 such that @xmath1 is @xmath0-stochastic . by definition ,",
    "this set is upwards - closed : a point in this set remains in it if we increase @xmath47 or @xmath48 , so there is some boundary curve that describes the trade - off between @xmath47 and @xmath48 .",
    "what curves could appear in this way ? to get an answer ( to characterizes all these curves with @xmath4-precision ) , we need some other technique , explained in the next section .",
    "now we switch to another measure of the quality of a statistical model .",
    "it is important both for philosophical and technical reasons .",
    "the philosophical reason is that it corresponds to the so - called `` minimal description length principle '' .",
    "the technical reason is that it is easier to deal with ; in particular , we will use it to answer the question asked at the end of the previous section .",
    "consider again some statistical model .",
    "let @xmath2 be a probability distribution ( with finite support and rational values ) on strings .",
    "then we have @xmath177 for arbitrary string @xmath1 ( with @xmath16-precision ) . here",
    "we use that ( with @xmath16-precision ) :    * @xmath17 , as we have mentioned ; * the complexity of the pair is bounded by the sum of complexities : @xmath178 ; * @xmath179 ( in our case , @xmath180 ) .",
    "if @xmath2 is a uniform distribution on some finite set @xmath61 , this inequality can be explained as follows .",
    "we can specify @xmath1 in two steps :    * first , we specify @xmath61 ; * then we specify the ordinal number of @xmath1 in @xmath61 ( in some natural ordering , say , the lexicographic one ) .    in this way we get @xmath181 for every element @xmath1 of arbitrary finite set @xmath61 .",
    "this inequality holds with @xmath16-precision .",
    "if we replace the prefix complexity by the plain version , we can say that @xmath182 with precision @xmath4 for every string @xmath1 of length at most @xmath3 : we may assume without loss of generality that both terms in the right hand side are at most @xmath3 , otherwise the inequality is trivial .",
    "the `` quality '' of a statistical model @xmath2 for a string @xmath1 can be measured by the difference between sides of this inequality : for a good model the `` two - part description '' should be almost minimal .",
    "we come to the following definition :    the _ optimality deficiency _ of a distribution @xmath2 considered as the model for a string @xmath1 is the difference @xmath183    as we have seen , @xmath184 with @xmath16-precision .",
    "if @xmath2 is a uniform distribution on a set @xmath61 , the optimality deficiency @xmath185 will also be denoted by @xmath186 , and @xmath187 the following proposition shows that we may restrict our attention to finite sets as models ( with @xmath4-precision ) :    [ prop : models - to - sets-2 ] let @xmath2 be a distribution considered as a model for some string @xmath1 of length  @xmath3 .",
    "then there exists a finite set @xmath61 such that @xmath188    this proposition will be used in many arguments , since it is often easier to deal with sets as statistical models ( instead of distributions ) .",
    "note that the inequalities  @xmath23 evidently imply that @xmath189 so arbitrary distribution @xmath2 may be replaced by a uniform one ( @xmath64 ) with a logarithmic - only change in the optimality deficiency .",
    "we use the same construction as in proposition  [ prop : models - to - sets-1 ] .",
    "let @xmath190 be the maximal power of @xmath191 such that @xmath73 , and let @xmath192 . then @xmath193 .",
    "we may assume that @xmath82 : if @xmath72 is much bigger than @xmath3 , then @xmath185 is also bigger than @xmath3 ( since the complexity of @xmath1 is bounded by @xmath194 ) , and in this case the statement is trivial ( let @xmath61 be the set of all @xmath3-bit strings ) .",
    "now we see that that @xmath61 is determined by @xmath2 and @xmath72 , so @xmath195 .",
    "note also that @xmath196 , so @xmath197 .",
    "let us note that in a more general setting  @xcite where we consider several strings as outcomes of the repeated experiment ( with independent trials ) and look for a model that explains all of them , a similar result is not true : not every probability distribution can be transformed into a uniform one .",
    "now we have two `` quality measures '' for a statistical model @xmath2 : the randomness deficiency @xmath20 and the optimality deficiency @xmath185 .",
    "they are related :    [ prop : randomness - optimality ] @xmath198 with @xmath16-precision .    by definition",
    "@xmath199 it remains to note that @xmath200 with @xmath16-precision .",
    "could @xmath185 be significantly larger than @xmath20 ?",
    "look at the proof above : the second inequality @xmath201 is an equality with logarithmic precision .",
    "indeed , the exact formula ( levin  gcs formula for the complexity of a pair with @xmath16-precision ) is @xmath202 here the term @xmath203 in the condition changes the complexity by @xmath204 , and we may ignore models @xmath2",
    "whose complexity is much greater than the complexity of @xmath1 .",
    "on the other hand , in the first inequality the difference between @xmath205 and @xmath152 may be significant .",
    "this difference equals @xmath206 with logarithmic accuracy and , if it is large , then @xmath185 is much bigger than @xmath20 .",
    "the following example shows that this is possible . in this example",
    "we deal with sets as models .    [",
    "ex : stochasticity - optimality ] consider an incompressible string @xmath1 of length @xmath3 , so @xmath207 ( all equalities with logarithmic precision ) .",
    "a good model for this string is the set @xmath61 of all @xmath3-bit strings .",
    "for this model we have @xmath208 , @xmath209 and @xmath210 ( all equalities have logarithmic precision ) .",
    "so @xmath51 , too .",
    "now we can change the model by excluding some other @xmath3-bit string .",
    "consider a @xmath3-bit string @xmath91 that is incompressible and independent of @xmath1 : this means that @xmath211 .",
    "let @xmath212 be @xmath213 .",
    "the set @xmath212 contains @xmath1 ( since @xmath1 and @xmath91 are independent , @xmath91 differs from @xmath1 ) .",
    "its complexity is @xmath3 ( since it determines @xmath91 ) .",
    "the optimality deficiency is then @xmath214 , but the randomness deficiency is still small : @xmath215 ( with logarithmic precision ) . to see why @xmath216 , note that @xmath1 and @xmath91 are independent , and the set @xmath212 has the same information as @xmath217 .",
    "one of the main results of this section ( theorem  [ th : deficiencies ] ) clarifies the situation : it implies that if optimality deficiency of a model is significantly larger than its randomness deficiency , then this model can be improved and another model with better parameters can be found .",
    "more specifically , the complexity of the new model is smaller than the complexity of the original one while both the randomness deficiency and optimality deficiency of the new model are not worse than the randomness deficiency of the original one .",
    "this is one of the main results of algorithmic statistics , but first let us explore systematically the properties of two - part descriptions .",
    "it is convenient to consider only models that are sets ( = uniform distribution on sets )",
    ". we will call them _ descriptions_. note that by propositions  [ prop : models - to - sets-1 ] and  [ prop : models - to - sets-2 ] this restriction does not matter much since we ignore logarithmic terms . for a given string @xmath1",
    "there are many different descriptions : we can have a simple large set containing @xmath1 , and at the same time some more complicated , but smaller one . in this section",
    "we study the trade - off between these two parameters ( complexity and size ) .",
    "[ def : px ] a finite set @xmath61 is an @xmath218-description and cardinality at most @xmath219 that we decided to introduce some short name and notation for them .",
    "] of @xmath1 if @xmath220 , complexity @xmath221 is at most @xmath171 , and @xmath222 . for a given @xmath1",
    "we consider the set @xmath223 of all pairs @xmath224 such that @xmath1 has some @xmath218-description ; this set can be called the _ profile _ of @xmath1 .",
    "informally speaking , an @xmath218-description for @xmath1 consists of two parts : first we spend @xmath171 bits to specify some finite set @xmath61 and then @xmath225 bits to specify @xmath1 as an element of @xmath61 .    what can be said about @xmath223 for a string @xmath1 of length @xmath3 and complexity @xmath226 ? by definition , @xmath223 is closed upwards and contains the points @xmath227 and @xmath228 . here we omit terms @xmath4 : more precisely , we have a @xmath229-description that consists of all strings of length @xmath3 , and a @xmath230-description @xmath231 . moreover , the following proposition shows that we can move the information from the second part of the description into its first part ( leaving the total length almost unchanged ) . in this way",
    "we make the set smaller ( the price we pay is that its complexity increases ) .",
    "[ prop : description - shift ] let @xmath1 be a string and @xmath61 be a finite set that contains @xmath1 .",
    "let @xmath232 be a non - negative integer such that @xmath233 .",
    "then there exists a finite set @xmath212 containing @xmath1 such that @xmath234 and @xmath235 .",
    "list all the elements of @xmath61 in some ( say , lexicographic ) order .",
    "then we split the list into @xmath236 parts ( first @xmath237 elements , next @xmath237 elements etc . ; we omit evident precautions for the case when @xmath238 is not a multiple of @xmath236 ) .",
    "then let @xmath212 be the part that contains @xmath1 .",
    "it has the required size .",
    "to specify @xmath212 , it is enough to specify @xmath61 and the part number ; the latter takes at most @xmath232 bits .",
    "( the logarithmic term is needed to make the encoding of the part number self - delimiting . )",
    "this statement can be illustrated graphically .",
    "as we have said , the set @xmath223 is `` closed upwards '' and contains with each point @xmath224 all points on the right ( with bigger @xmath171 ) and on the top ( with bigger @xmath225 ) .",
    "it contains points @xmath227 and @xmath239 ; proposition  [ prop : description - shift ] says that we can also move down - right adding @xmath240 ( with logarithmic precision ) .",
    "we will see that movement in the opposite direction is not always possible .",
    "so , having two - part descriptions with the same total length , we should prefer the one with bigger set ( since it always can be converted into others , but not vice versa ) .",
    "the boundary of @xmath223 is some curve connecting the points @xmath227 and @xmath228 .",
    "this curve ( introduced by kolmogorov in 1970s , see  @xcite ) never gets into the triangle @xmath241 and always goes down ( when moving from left to right ) with slope at least @xmath242 or more .     and its boundary curve ]",
    "this picture raises a natural question : which boundary curves are possible and which are not ? is it possible , for example , that the boundary goes along the dotted line on figure  [ mdl.1.eps ] ?",
    "the answer is positive : take a random string of desired complexity and add trailing zeros to achieve desired length .",
    "then the point @xmath243 ( the left end of the dotted line ) corresponds to the set @xmath61 of all strings of the same length having the same trailing zeros .",
    "we know that the boundary curve can not go down slower than with slope @xmath242 and that it lies above the line @xmath244 , therefore it follows the dotted line ( with logarithmic precision ) .    a more difficult question : is it possible that the boundary curve starts from @xmath245 , goes with the slope @xmath242 to the very end and then goes down rapidly to @xmath239 ( figure  [ mdl.2 ] , the solid line ) ?",
    "such a string @xmath1 , informally speaking , would have essentially only two types of statistical explanations : a set of all strings of length @xmath3 ( and its parts obtained by proposition  [ prop : description - shift ] ) and the exact description , the singleton @xmath231 .",
    "it turns out that not only these two opposite cases are possible , but also all intermediate curves ( provided they decrease with slope @xmath242 or faster , and are simple enough ) , at least with logarithmic precision .",
    "more precisely , the following statement holds :    [ stat - any - curve ] let @xmath246 be two integers and let @xmath247 be a strictly decreasing sequence of integers such that @xmath248 and @xmath249 ; let @xmath33 be the complexity of this sequence . then there exists a string @xmath1 of complexity @xmath250 and length @xmath251 for which the boundary curve of @xmath223 coincides with the line @xmath252@xmath253  @xmath254 with @xmath255 precision : the distance between the set @xmath223 and the set @xmath256",
    "is bounded by @xmath255 .",
    "( we say that the distance between two subsets @xmath257 is at most @xmath88 if @xmath2 is contained in the @xmath88-neighborhood of @xmath101 and vice versa . )    for every @xmath171 in the range @xmath258 we list all the sets of complexity at most @xmath171 and size at most @xmath259 . for a given @xmath171 the union of all these sets",
    "is denoted by @xmath260 .",
    "it contains at most @xmath261 elements .",
    "( here and later we omit constant factors and factors polynomial in @xmath3 when estimating cardinalities , since they correspond to @xmath4 additive terms for lengths and complexities . )",
    "since the sequence @xmath262 strictly decreases ( this corresponds to slope @xmath242 in the picture ) , the sums @xmath263 do not increase , therefore each @xmath260 has at most @xmath264 elements .",
    "the union of all @xmath260 therefore also has at most @xmath265 elements ( up to a polynomial factor , see above ) .",
    "therefore , we can find a string of length @xmath3 ( actually @xmath194 ) that does not belong to any @xmath260 .",
    "let @xmath1 be a first such string in some order ( e.g. , in the lexicographic order ) .    by construction ,",
    "the set @xmath223 lies above the curve determined by @xmath262 .",
    "so we need to estimate the complexity of @xmath1 and prove that @xmath223 follows the curve ( i.e. , that @xmath266 is contained in the neighborhood of @xmath223 ) .",
    "let us start with the upper bound for the complexity of @xmath1 .",
    "the list of all objects of complexity at most @xmath72 plus the full table of their complexities have complexity @xmath267 , since it is enough to know @xmath72 and the number of terminating programs of length at most  @xmath72 . except for this list ,",
    "to specify @xmath1 we need to know @xmath3 and the sequence @xmath268 , whose complexity is @xmath33 .",
    "the lower bound : the complexity of @xmath1 can not be less than @xmath72 since all the singletons of this complexity were excluded ( via @xmath89 ) .",
    "it remains to show that for every @xmath269 we can put @xmath1 into a set @xmath61 of complexity @xmath171 ( or slightly bigger ) and size @xmath259 ( or slightly bigger ) .",
    "for this we enumerate a sequence of sets of correct size and show that one of the sets will have the required properties ; if this sequence of sets is not very long , the complexity of its elements is bounded . here",
    "are the details .",
    "we start by taking the first @xmath259 strings of length @xmath3 as our first set @xmath61 .",
    "then we start enumerating all finite sets of complexity at most @xmath225 and of size at most @xmath270 for all @xmath271 , and get an enumeration of all sets @xmath272 . recall that all elements of all @xmath272 should be deleted ( and the minimal remaining element should eventually be @xmath1 ) .",
    "so , when a new set of complexity at most @xmath225 and of size at most @xmath270 appears , all its elements are included in @xmath272 and deleted .",
    "until all elements of @xmath61 are deleted , we have nothing to worry about , since @xmath61 is covering the minimal remaining element . if ( and when ) all elements of @xmath61 are deleted , we replace @xmath61 by a new set that consists of first @xmath259 undeleted ( yet ) strings of length @xmath3 .",
    "then we wait again until all the elements of this new @xmath61 are deleted , if ( and when ) this happens , we take @xmath259 first undeleted elements as new @xmath61 , etc",
    ".    the construction guarantees the correct size of the sets and that one of them covers @xmath1 ( the minimal non - deleted element ) .",
    "it remains to estimate the complexity of the sets we construct in this way .",
    "first , to start the process that generates these sets , we need to know the length @xmath3 ( actually something logarithmically close to @xmath3 ) and the sequence @xmath268 . in total",
    "we need @xmath273 bits . to specify each version of @xmath61 , we need to add its version number .",
    "so we need to show that the number of different @xmath61 s that appear in the process is at most @xmath170 or slightly bigger .    a new set @xmath61 is created when all the elements of the old @xmath61 are deleted .",
    "these changes can be split into two groups .",
    "sometimes a new set of complexity @xmath225 appears with @xmath274 .",
    "this can happen only @xmath275 times since there are at most @xmath275 sets of complexity at most @xmath171 .",
    "so we may consider the other changes ( excluding the first changes after each new large set was added ) .",
    "for those changes all the elements of @xmath61 are gone due to elements of @xmath272 with @xmath276 .",
    "we have at most @xmath277 elements in @xmath272 .",
    "since @xmath278 , the total number of deleted elements only slightly exceeds @xmath279 , and each set @xmath61 consists of @xmath259 elements , so we get about @xmath170 changes of @xmath61 .",
    "it is easy to modify the proof to get a string @xmath1 of length exactly @xmath3 .",
    "indeed , we may consider slightly smaller bad sets : decreasing the logarithms of their sizes by @xmath4 , we can guarantee that the total number of elements in all bad sets is less than @xmath265 .",
    "then there exists a string of length @xmath3 that does not belong to bad sets . in this way",
    "the distance between @xmath266 and @xmath223 may increase by @xmath4 , and this is acceptable .",
    "theorem  [ stat - any - curve ] shows that the value of the complexity of @xmath1 does not describe the properties of @xmath1 fully ; different strings of the same complexity @xmath1 can have different boundary curves of @xmath223 .",
    "this curve can be considered as an `` infinite - dimensional '' characterization of @xmath1 .",
    "strings @xmath1 with minimal possible @xmath223 ( figure  [ mdl.2 ] , the upper curve ) may be called _",
    "antistochastic_. they have quite unexpected properties .",
    "for example , if we replace some bits of an antistochastic string @xmath1 by stars ( or some other symbols indicating erasures ) leaving only @xmath152 non - erased bits , then the string @xmath1 can be reconstructed from the resulting string @xmath280 with logarithmic advice , i.e. , @xmath281 .",
    "this and other properties of antistochastic strings were discovered in  @xcite .      in this section",
    "we establish the connection between optimality and randomness deficiency .",
    "as we have seen , the optimality deficiency can be bigger than the randomness deficiency ( for the same description ) , and the difference is @xmath282 the levin ",
    "gcs formula for the complexity of pair ( @xmath283 with logarithmic precision , for @xmath16-precision one needs to add @xmath284 in the condition , but we ignore logarithmic size terms anyway ) shows that the difference in question can be rewritten as @xmath285",
    "so if the difference between deficiencies for some @xmath218-description @xmath61 of @xmath1 is big , then @xmath286 is big .",
    "all the @xmath218-descriptions of @xmath1 can be enumerated if @xmath1 , @xmath171 , and @xmath225 are given .",
    "so the large value of @xmath286 for some @xmath218-description @xmath61 means that there are many @xmath218-descriptions of @xmath1 , otherwise @xmath61 can be reconstructed from @xmath1 by specifying @xmath287 ( requires @xmath4 bits ) and the ordinal number of @xmath61 in the enumeration .",
    "we will prove that if there are many @xmath218-descriptions for some @xmath1 , then there exist a description with better parameters .",
    "now we explain this in more detail .",
    "let us start with the following remark .",
    "consider all strings that have @xmath218-descriptions for some fixed @xmath171 and @xmath225 .",
    "they can be enumerated in the following way : we enumerate all finite sets of complexity at most @xmath171 , select those sets that have size at most @xmath219 , and include all elements of these sets into the enumeration . in this construction    * the complexity of the enumerating algorithm is logarithmic ( it is enough to know @xmath171 and @xmath225 ) ; * we enumerate at most @xmath288 elements ; * the enumeration is divided into at most @xmath170 `` portions '' of size at most @xmath219 .",
    "it is easy to see that any other enumeration process with these properties enumerates only objects that have @xmath218-descriptions ( again with logarithmic precision ) .",
    "indeed , each portion is a finite set that can be specified by its ordinal number and the enumeration algorithm , the first part requires @xmath289 bits , the second is of logarithmic size according to our assumption .",
    "[ rem : portion ] the requirement about the portion size is redundant .",
    "indeed , we can change the algorithm by splitting large portions into pieces of size @xmath219 ( the last piece may be incomplete ) .",
    "this , of course , increases the number of portions , but if the total number of enumerated elements is at most @xmath288 , then this splitting adds at most @xmath170 pieces .",
    "this observation looks ( and is ) trivial , still it plays an important role in the proof of the following proposition .",
    "[ prop : improving - descriptions ] if a string @xmath1 of length @xmath3 has at least @xmath75 different @xmath224-descriptions , then @xmath1 has some @xmath290-description and even some @xmath291-description .",
    "again we omit logarithmic term : in fact one should write @xmath292 , etc .",
    "the word `` even '' in the statement refers to proposition  [ prop : description - shift ] that shows that indeed the second claim is stronger .",
    "consider the enumeration of all objects having @xmath218-descriptions in @xmath170 portions of size @xmath219 ( we ignore logarithmic additive terms and respective polynomial factors ) as explained above .",
    "after each portion ( i.e. , new @xmath218-description ) appears , we count the number of descriptions for each enumerated object and select objects that have at least @xmath75 descriptions . consider a new enumeration process that enumerates only these `` rich '' objects ( rich = having many descriptions ) .",
    "we have at most @xmath293 rich objects ( since they appear in the list of size @xmath288 with multiplicity @xmath75 ) , enumerated in @xmath170 portions ( new portion of rich objects may appear only when a new portion appears in the original enumeration ) .",
    "so we apply the observation above to conclude that all rich objects have @xmath290-descriptions .    to get the second ( stronger ) statement",
    "we need to decrease the number of portions ( while not increasing too much the number of enumerated objects ) .",
    "this can be done using the following trick : when a new rich object ( having @xmath75 descriptions ) appears , we enumerate not only rich objects , but also `` half - rich '' objects , i.e. , objects that currently have at least @xmath294 descriptions . in this way we enumerate more objects",
    " but only twice more . at the same time , after we dumped all half - rich objects , we are sure that next @xmath294 new @xmath218-descriptions will not create new rich objects , so the number of portions is divided by @xmath294 , as required .",
    "let us say more accurately how we deal with logarithmic terms .",
    "we may assume that @xmath295 , otherwise the claim is trivial .",
    "then we allow polynomial ( in @xmath3 ) factors and @xmath4 additive terms in all our considerations .",
    "if we unfold this construction , we see that new descriptions ( of smaller complexity ) are not selected from the original sequence of descriptions but constructed from scratch . in section  [ sec : restricted - type ] we deal with much more complicated case where we restrict ourselves to descriptions from some class ( say , hamming balls ) .",
    "then the proof given above does not work , since the description we construct is not a ball even if we start with ball descriptions .",
    "still some other ( much more ingenious ) argument can be used to prove a similar result for the restricted case .",
    "now we are ready to prove the promised results ( see the discussion after example  [ ex : stochasticity - optimality ] ) .",
    "[ thm : improving - descriptions ] if a string @xmath1 of length @xmath3 is @xmath0-stochastic , then there exists some finite set @xmath296 containing @xmath1 such that @xmath297 and @xmath298 .",
    "since @xmath1 is @xmath0-stochastic , there exists some finite set @xmath61 such that @xmath299 and @xmath67 .",
    "let @xmath300 and @xmath301 , so @xmath61 is an @xmath218-description of @xmath1 .",
    "we may assume without loss of generality that both @xmath47 and @xmath48 ( and therefore @xmath171 and @xmath225 ) are @xmath302 , otherwise the statement is trivial . the value @xmath186 may exceed @xmath68 , as we have discussed at the beginning of this section .",
    "so we assume that @xmath303 if not , we can let @xmath304 . then , as we have seen , @xmath305 , and there are at least @xmath306 different @xmath218-descriptions of @xmath1 . according to proposition  [",
    "prop : improving - descriptions ] , there exists some finite set @xmath296 that is an @xmath307-description of @xmath1 .",
    "its optimality deficiency @xmath308 is @xmath309-smaller ( compared to @xmath61 ) and therefore @xmath4-close to @xmath68 .    in this argument",
    "we used the simple part of proposition  [ prop : improving - descriptions ] . using the stronger statement about complexity decrease",
    ", we get the following result :    [ th : deficiencies ] let @xmath61 be a finite set containing a string @xmath1 of length @xmath3 and let @xmath310 .",
    "then there is a finite set @xmath296 containing @xmath1 such that @xmath311 and @xmath312 .    indeed , if @xmath296 is an @xmath291-description of @xmath1 ( up to logarithmic terms , as usual ) , then its optimality deficiency is again @xmath309-smaller ( compared to @xmath61 ) and therefore @xmath4-close to @xmath68 .",
    "note that the statement of the theorem implies that @xmath313 .",
    "theorem  [ thm : improving - descriptions ] and proposition  [ prop : randomness - optimality ] show that we can replace the randomness deficiency in the definition of @xmath0-stochastic strings by the optimality deficiency ( with logarithmic precision ) . more specifically , for every string @xmath1 of length @xmath3 consider the sets[def : qx ] @xmath314 and @xmath315 then these sets are at most @xmath4 apart ( each is contained in the @xmath4-neighborhood of the other one ) .",
    "this remark , together with the existence of antistochastic strings of given complexity and length , allows us to improve the result about the existence of non - stochastic objects ( proposition  [ prop : existence - nonstochastic ] ) .",
    "[ prop : existence - nonstochastic - strong ] for some @xmath9 and for all @xmath3 : if @xmath316 , there exist strings of length @xmath3 that are not @xmath0-stochastic .     with @xmath299 and @xmath317 .",
    "]    assume that integers @xmath136 are given such that @xmath316 ( where the constant @xmath9 will be chosen later ) .",
    "let @xmath1 be an antistochastic string of length @xmath3 that has complexity @xmath318 where @xmath27 is some positive number ( see below about the choice of @xmath27 ) .",
    "more precisely , for every given @xmath27 there exists a string @xmath1 whose complexity is @xmath319 , length is @xmath194 , and the set @xmath223 is @xmath4-close to the upper gray area ( figure  [ mdl-9 ] ) .",
    "assume that @xmath1 is @xmath0-stochastic .",
    "then ( theorem  [ thm : improving - descriptions ] ) the string @xmath1 has an @xmath218-description with @xmath320 and @xmath321 ( with logarithmic precision ) .",
    "the set of pairs @xmath224",
    "satisfying these inequalities is shown as the lower gray area .",
    "we have to choose @xmath9 in such a way that for some @xmath27 these two gray are disjoint and even separated by a gap of logarithmic size ( since they are known only with @xmath4-precision ) .",
    "note first that for @xmath322 with large enough @xmath323 we guarantee the vertical gap ( the vertical segments of the boundaries of two gray areas are far apart ) .",
    "then we select @xmath9 large enough to guarantee that the diagonal segments of the boundaries of two gray areas are far apart ( @xmath324 with logarithmic margin ) .    the transition from randomness deficiency to optimality deficiency ( theorem  [ thm : improving - descriptions ] )",
    "has the following geometric interpretation .",
    "[ thm : def - opt ] the sets @xmath325 and @xmath223 are related to each other via an affine transformation @xmath326 , as figure  [ mdl.8 ] shows .. for @xmath327 both sets contain all pairs with first component @xmath47 . ]     and the boundary of the set @xmath325 ( bold dotted line ) ; on every vertical line two intervals have the same length . ]    as usual , this statement is true with logarithmic accuracy : the distance between the image of the set @xmath325 under this transformation and the set @xmath223 is claimed to be @xmath4 for string @xmath1 of length @xmath3 .",
    "as we have seen , we may use the optimality deficiency instead of randomness deficiency , i.e. , use the set @xmath328 in place of @xmath325 .",
    "the preimage of the pair @xmath224 under our affine transformation is the pair @xmath329 .",
    "hence we have to prove that a pair @xmath224 is in @xmath223 if and only if the pair @xmath329 is in @xmath328 .",
    "note that @xmath330 and @xmath331 is equivalent to @xmath330 and @xmath332 just by definition of @xmath186 .",
    "( see figure  [ mdl.8 ] : the optimality deficiency of a description @xmath61 with @xmath330 and @xmath333 is the vertical distance between @xmath224 and the dotted line . )",
    "but there is some technical problem : in the definition of @xmath223 we used inequalities @xmath334 and @xmath222 , not the equalities @xmath330 and @xmath331 .",
    "the same applies to the definition of @xmath328 .",
    "so we have two sets that correspond to each other , but their @xmath335-closures could be different . obviously , @xmath334 and @xmath222 imply @xmath334 and @xmath336 , but not vice versa .",
    "in other words , the set of pairs @xmath337 satisfying the latter inequalities ( see the right set on figure  [ mdl-10 - 11 ] ) is bigger than the set of pairs @xmath337 satisfying the former inequalities ( see the left set on figure  [ mdl-10 - 11 ] ) .",
    "and @xmath225 ) the set of all pairs @xmath337 such that @xmath334 and @xmath222 ; the right picture shows the pairs @xmath337 such that @xmath334 and @xmath338.,title=\"fig : \" ]   and @xmath225 ) the set of all pairs @xmath337 such that @xmath334 and @xmath222 ; the right picture shows the pairs @xmath337 such that @xmath334 and @xmath338.,title=\"fig : \" ]    now proposition  [ prop : description - shift ] helps : we may use it to convert any set with parameters from the right region into a set with parameters from the left region .",
    "let us stress again that theorem  [ thm : improving - descriptions ] claims only that the _ existence _ of a set @xmath339 with @xmath299 and @xmath340 is equivalent to the existence of a set @xmath341 with @xmath342 and @xmath343 ( with logarithmic accuracy ) .",
    "the theorem does _ not _ claim that for _ every _ set @xmath339 with complexity at most @xmath47 the inequalities @xmath344 and @xmath345 are equivalent ( with logarithmic accuracy ) .",
    "indeed , the example  [ ex : stochasticity - optimality ] shows that this is not true : the first inequality does not imply the second one in general case .",
    "however , theorems  [ thm : improving - descriptions ] and  [ th : deficiencies ] show that this can happen only for non - minimal descriptions ( for which the description with smaller complexity and the same optimality deficiency ) exists",
    ". later we will see that all the minimal descriptions of the same ( or almost the same ) complexity have almost the same information . moreover , if @xmath61 and @xmath296 are minimal descriptions and the complexity of @xmath61 is less than that of @xmath296 then @xmath346 is small",
    ".    for the people with taste for philosophical speculations the meaning of theorems  [ thm : improving - descriptions ] and  [ th : deficiencies ] can be advertised as follows .",
    "imagine several scientists that compete in providing a good explanation for some data @xmath1 .",
    "each explanation is a finite set @xmath61 containing @xmath1 together with a program @xmath84 that computes @xmath61 .",
    "how should we compare different explanations ?",
    "we want the randomness deficiency @xmath68 of @xmath1 in @xmath61 to be negligible ( no features of @xmath1 remain unexplained ) . among these descriptions",
    "we want to find the simplest one ( with the shortest @xmath84 ) .",
    "that is , we look for a set @xmath61 corresponding to the point where the bold dotted line on fig .",
    "[ mdl.8 ] touches the horizontal axis .",
    "( in fact , there is always some trade - off between the parameters , not the specific exact point where the curve touches the horizontal axis , but we want to keep the discussion simple though imprecise . )    however , this approach meets the following obstacle : we are unable to compute randomness deficiency @xmath68 .",
    "moreover , the inventor of the model @xmath61 has no ways to convince us that the deficiency is indeed negligible if it is the case ( the function @xmath68 is not even upper semicomputable ) . what could be done ?",
    "instead , we may look for an explanation with ( almost ) minimal sum @xmath347 ( minimum description length principle ) . note that this quantity is known for competing explanation proposals .",
    "theorems  [ thm : improving - descriptions ] and  [ th : deficiencies ] provide the connection between these two approaches .    returning to mathematical language ,",
    "we have seen in this section that two approaches ( based on @xmath218-descriptions and @xmath0-stochasticity ) produce essentially the same curve , though in different coordinates .",
    "the other ways to get the same curve will be discussed in sections  [ sec : bcl ] and  [ sec : depth ] .",
    "the idea to consider @xmath218-descriptions with optimal parameters can be traced back to kolmogorov .",
    "there is a short record for his talk given in 1974  @xcite .",
    "here is the ( full ) translation of this note :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ for every constructive object @xmath1 we may consider a function @xmath348 of an integer argument @xmath349 defined as a logarithm of the minimal cardinality of a set of complexity at most @xmath72 containing @xmath1 . if @xmath1 itself has a simple definition , then @xmath350 is equal to one [ a typo : cardinality equals @xmath24 , and logarithm equals @xmath32 ] already for small @xmath72 . if such a simple definition does not exist , @xmath1 is `` random '' in the negative sense of the word `` random '' . but @xmath1 is positively `` probabilistically random '' only if the function @xmath352 has a value @xmath353 for some relatively small @xmath72 and then decreases approximately as @xmath354 .",
    "[ this corresponds to approximate @xmath355-stochasticity . ] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    kolmogorov also gave a talk in 1974  @xcite ; the content of this talk was reported by cover  ( * ? ? ?",
    "* section 4 , page 31 ) . here",
    "@xmath356 stands for the length of a binary string @xmath84 and @xmath357 stands for the cardinality of a set @xmath105 .    _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\4 .",
    "* kolmogorov s @xmath358 function *    consider the function @xmath359 , @xmath360 , where the minimum is taken over all subsets @xmath361 , such that @xmath362 , @xmath363 , @xmath364 .",
    "this definition was introduces by kolmogorov in a talk at the information symposium , tallinn , estonia , in 1974 .",
    "thus @xmath365 is the log of the size of the smallest set containing @xmath1 over all sets specifiable by a program of @xmath72 or fewer bits .",
    "of special interest is the value @xmath366 note that @xmath367 is the maximal number of bits necessary to describe an arbitrary element @xmath362 .",
    "thus a program for @xmath1 can be written in two stages : `` use @xmath84 to print the indicator function for @xmath105 ; the desired sequence is the @xmath171th sequence in a lexicographic ordering of the elements of this set '' .",
    "this program has length @xmath368 , and @xmath369 is the length of the shortest program @xmath84 for which this @xmath191-stage description is as short as the best @xmath24-stage description @xmath370 .",
    "we observe that @xmath1 must be maximally random with respect to @xmath105  otherwise the @xmath191-stage description could be improved , contradicting the minimality of @xmath371 .",
    "thus @xmath369 and its associated program @xmath84 constitute a minimal sufficient description for @xmath1 .",
    "@xmath372    arguments can be provided to establish that @xmath369 and its associated set @xmath373 describe all of the `` structure '' of @xmath1 .",
    "the remaining details about @xmath1 are conditionally maximally complex .",
    "thus @xmath374 , the program for @xmath373 , plays the role of a sufficient statistic . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in both places kolmogorov speaks about the place when the boundary curve of @xmath223 reaches its lower bound determined by the complexity of @xmath1 .",
    "later the same ideas were rediscovered and popularized by many people .",
    "koppel in  @xcite reformulates the definition using total algorithms . instead of a finite set @xmath61 he considered a total program @xmath2 that terminates on all strings of some length . the two - part description of some @xmath1 is then formed by this program @xmath2 and the input @xmath375 for this program that is mapped to @xmath1 . in our terminology",
    "this corresponds to the set @xmath61 of all values of @xmath2 on the strings of the same length as @xmath375 .",
    "he writes then  @xcite    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * definition 3 . * the @xmath9-sophistication of a finite string @xmath105 [ is defined as ] @xmath376 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    there is a typo in this paper : @xmath105 should be replaced by @xmath47 ( two times ) . before in definition 1 the description is called @xmath9-minimal if @xmath377 ( here @xmath2 and @xmath375 are the program and and its input , respectively , @xmath378 stands for complexity ) .",
    "though this paper ( as well as the subsequent papers  @xcite ) is not technically clear ( e.g. , it does not say what are the requirements for the algorithm @xmath379 used in the definition , and in  @xcite only universality is required , which is not enough : if @xmath379 is not optimal , the definition does not make sense ) , the philosophic motivation for this notion is explained clearly  @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the total complexity of an object is defined as the size of its most concise description .",
    "the total complexity of an object can be large while its `` meaningful '' complexity is low ; for example , a random object is by definition maximally complex but completely lacking in structure .",
    "@xmath372 the `` static '' approach to the formalization of meaningful complexity is `` sophistication '' defined and discussed by koppel and atlan [ reference to unpublished paper `` program - length complexity , sophistication , and induction '' is given , but later a paper of same authors  @xcite with a similar title appeared ] .",
    "sophistication is a generalization of the `` h - function '' or `` minimal sufficient statistic '' by cover and kolmogorov  @xmath372 the sophistication of an object in the size of that part of that object which describes its structure , i.e. the aggregate of its projectible properties . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    one can also mention the formulation of `` minimal description length '' principle by rissanen  @xcite ; the abstract of this paper says : `` estimates of both integer - valued structure parameters and real - valued system parameters may be obtained from a model based on the shortest data description principle '' ; here `` integer - valued structure parameters '' may correspond to the choice of a statistical hypothesis ( description set ) while `` real - valued system parameters '' may correspond to the choice of a specific element in this set .",
    "the author then says that `` by finding the model which minimizes the description length one obtains estimates of both the integer - valued structure parameters and the real - valued system parameters '' .",
    "we do not try here to follow the development of these and similar ideas .",
    "let us mention only that the traces of the same ideas ( though even more vague ) could be found in 1960s in the classical papers of solomonoff  @xcite who tried to use shortest descriptions for inductive inference ( and , as a side product , gave the definition of complexity later rediscovered by kolmogorov  @xcite ) .",
    "one may also mention a `` minimum message length principle '' that goes back to  @xcite ; the idea of two - part description is explained in  @xcite as follows :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ if the things are now classified then the measurements can be recorded by listing the following :    \\1 .",
    "the class to which each thing belongs .",
    "the average properties of each class .",
    "the deviations of each thing from the average properties of its parent class .",
    "if the things are found to be concentrated in a small area of the region of each class in the measurement space then the deviations will be small , and with reference to the average class properties most of the information about a thing is given by naming the class to which it belongs . in this case",
    "the information may be recorded much more briefly than if a classification had not been used .",
    "we suggest that the best classification is that which results in the briefest recording of all the attribute information . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    here the `` class to which thing belongs '' corresponds to a set ( statistical model , description in our terminology ) ; the authors say that if this set is small , then only few bits need to be added to the description of this set to get a full description of the thing in question .    the main technical results of this sections ( theorems  [ stat - any - curve ] ,  [ thm : improving - descriptions ] , and  [ th : deficiencies ] ) are taken from  @xcite ( where some historical account is provided ) .",
    "in this section we show one more classification of strings that turns out to be equivalent ( up to coordinate change ) to the previous ones : for a given string @xmath1 and @xmath380 we look how close @xmath1 is to the end in the enumeration of all strings of complexity at most @xmath33 . for technical reasons",
    "it is more convenient to use plain complexity @xmath381 instead of the prefix version @xmath152 . as we have mentioned , the difference between them is only logarithmic , and we mainly ignore terms of that size .",
    "consider some integer @xmath33 , and all strings @xmath1 of ( plain ) complexity at most @xmath33 .",
    "let @xmath382 be the number of those strings .",
    "the following properties of @xmath382 are well known and often used ( see , e.g. , @xcite ) .",
    "[ prop : omegas ]    * @xmath383 ( i.e. , @xmath384 for some positive constants @xmath385 and for all  @xmath33 ; * @xmath386 .",
    "the number of strings of complexity at most @xmath33 is bounded by the total number of programs of length at most @xmath33 , which is @xmath387 . on the other hand ,",
    "if @xmath382 is an @xmath388-bit number , we can specify a string of complexity greater than @xmath33 using @xmath389 bits : first we specify @xmath27 in a self - delimiting manner using @xmath41 bits , and then append @xmath382 in binary .",
    "this information allows us to reconstruct @xmath27 , then @xmath33 and @xmath382 , then enumerate strings of complexity at most @xmath33 until we have @xmath382 of them ( so all strings of complexity at most @xmath33 are enumerated ) , and then take the first string @xmath390 that has not been enumerated . as @xmath391 , the value of @xmath27 is bounded by a constant and hence @xmath382 is an @xmath392-bit number .    in this argument",
    "the binary representation of @xmath382 can be replaced by its program , so @xmath393 .",
    "the upper bound @xmath394 is obvious , since @xmath395 .",
    "given @xmath33 , we can enumerate all strings of complexity at most @xmath33 .",
    "how many steps needs the enumeration algorithm to produce all of them ?",
    "the answer is provided by the so - called _ busy beaver numbers _ ; let us recall their definition in terms of kolmogorov complexity ( see  @xcite for details ) .    by definition ,",
    "the number @xmath396 is the maximal integer of complexity at most @xmath33 .",
    "it is not hard to see that @xmath397 .",
    "indeed , @xmath398 by definition . on the other hand ,",
    "the complexity of the next number @xmath399 is greater than @xmath33 and at the same time is bounded by @xmath400 .",
    "note that @xmath396 can be undefined for small @xmath33 ( if there are no integers of complexity at most @xmath33 ) and that @xmath401 for all @xmath33 .",
    "for some @xmath33 this inequality may not be strict .",
    "this happen , for example , if the optimal algorithm used to define kolmogorov complexity is defined only on strings of , say , even lengths ; this restriction does not prevent it from being optimal , but then @xmath402 for all @xmath3 , since there are no objects of complexity exactly @xmath403",
    ". however , for some constant @xmath9 we have @xmath404 for all @xmath33 . indeed ,",
    "consider a program @xmath84 of length at most @xmath33 that prints @xmath396 .",
    "transform it to a program @xmath405 that runs @xmath84 and then adds @xmath24 to the result .",
    "this program witnesses that @xmath406 for some constant @xmath9 . hence @xmath407 .",
    "now we define @xmath408 as follows .",
    "as we have said , the set of all strings of complexity at most @xmath33 can be enumerated given @xmath33 .",
    "fix some enumeration algorithm @xmath61 ( with input @xmath33 ) and some computation model . then let @xmath408 be the number of steps used by this algorithm to enumerate all the strings of complexity at most @xmath33 .",
    "[ prop : busy - beavers ] the numbers @xmath396 and @xmath408 coincide up to @xmath16-change in @xmath33 .",
    "more precisely , we have @xmath409 for some @xmath9 and for all @xmath33 .    to find @xmath408 , it is enough to know @xmath33-bit binary string that represents @xmath382 ( this string also determines @xmath33 ) .",
    "therefore @xmath410 for some constant @xmath9 .",
    "as @xmath411 is the largest number of complexity @xmath412 or less , we have @xmath413 .",
    "on the other hand , if some integer @xmath414 exceeding both @xmath33 and @xmath408 is given , we can run the enumeration algorithm @xmath61 within @xmath414 steps for each input smaller than @xmath414 . consider the first string that has not been enumerated .",
    "its complexity is greater than @xmath33 , so @xmath415 for some constant @xmath9 .",
    "thus the complexity of every number @xmath414 starting from @xmath416 is greater than @xmath417 , which means that @xmath418 .",
    "it remains to note that for all large enough @xmath33 we have @xmath419 , as the complexity of @xmath33 is @xmath420 .",
    "thus for all large enough @xmath33 the number @xmath408 ( and not @xmath33 ) must be bigger than @xmath421 . replacing here @xmath33 by @xmath412 and increasing the constant @xmath9",
    "if needed , we conclude that @xmath422 for all @xmath33 .",
    "a similar argument shows that @xmath423 coincides ( up to @xmath16-change in the argument ) with the maximal computation time of the universal decompressor ( from the definition of plain kolmogorov complexity ) on inputs of size at most @xmath33 , see  @xcite    the next result says how many strings require long time to be enumerated .",
    "[ prop : enumeration - tail ] after @xmath424 steps of the enumeration algorithm on input @xmath33 there are @xmath425 strings that are not yet enumerated .",
    "we assume that the algorithm enumerates strings ( for every input @xmath33 ) without repetitions .",
    "note also that here @xmath426 can be replaced by @xmath296 , since they differ at most by a constant change in the argument .    to make the notation simpler we omit @xmath16- and @xmath420-terms in this argument .",
    "given @xmath427 , we can determine @xmath424 .",
    "if we also know how many strings of complexity at most @xmath33 appear after @xmath424 steps , we can wait until that many strings appear and then find a string of complexity greater than @xmath33 .",
    "if the number of remaining strings is smaller than @xmath428 , we get a prohibitively short description of this high complexity string .    on the other hand ,",
    "let @xmath1 be the last element that has been enumerated in @xmath424 steps .",
    "if there are significantly more than @xmath236 elements after @xmath1 , say , at least @xmath429 for some @xmath27 , we can split the enumeration in portions of size @xmath429 and wait until the portion containing @xmath1 appears . by assumption",
    "this portion is full .",
    "the number @xmath414 of steps needed to finish this portion is at least @xmath424 .",
    "this number @xmath414 and its successor @xmath430 can be reconstructed from the portion number that contains about @xmath431 bits .",
    "thus the complexity of @xmath430 is at most @xmath432 .",
    "hence we have @xmath433 by proposition  [ prop : busy - beavers ] we can replace @xmath426 by @xmath296 here : @xmath434 ( with some other constant in @xmath435-notation ) . since @xmath296 is a non - decreasing function , we get @xmath436 .",
    "g.  chaitin introduced the `` chaitin @xmath437-number '' @xmath438 it can also be defined as the probability of termination if the optimal prefix decompressor is applied to a random bit sequence  ( see  @xcite).$ ] , see  @xcite . ]",
    "the numbers @xmath439 are finite versions of chaitin s @xmath437-number . the information contained in @xmath439 increases as @xmath3 increases ; moreover , the following proposition is true . in this proposition",
    "we consider @xmath439 as a bit string ( of length @xmath440 ) identifying the number @xmath439 and its binary representation .",
    "[ prop : omega - equivalence ] assume that @xmath441 .",
    "consider the string @xmath442 consisting of the first @xmath72 bits of @xmath382 .",
    "it is @xmath420-equivalent to @xmath443 : both conditional complexities @xmath444 and @xmath445 are @xmath420 .",
    "this is essentially the reformulation of the previous statement ( proposition  [ prop : enumeration - tail ] ) .",
    "run the algorithm that enumerates strings of complexity at most @xmath33 .",
    "knowing @xmath442 , we can wait until less than @xmath446 strings are left in the enumeration of strings of complexity at most @xmath33 ; we know that this happens after more than @xmath447 steps , and in this time we can enumerate all strings of complexity at most @xmath72 and compute @xmath443 .",
    "( in this argument we ignore @xmath420-terms , as usual . )",
    "now the second inequality follows by the symmetry of information property .",
    "indeed , since @xmath448 and @xmath449 , the inequality @xmath450 implies the inequality @xmath451 .",
    "a direct argument is also easy .",
    "knowing @xmath443 and @xmath72 , we can find the list of all the strings of complexity at most @xmath72 and the number @xmath452 .",
    "then we make @xmath452 steps in the enumeration of the list of strings of complexity at most @xmath33 .",
    "proposition  [ prop : enumeration - tail ] then guarantees that at that moment @xmath382 is known with error about @xmath446 , so the first @xmath72 bits of @xmath382 can be reconstructed with small advice ( of logarithmic size ; we omit terms of that size in the argument ) .",
    "there is a more direct connection with chaitin s @xmath437-number : one can show that the number @xmath382 is @xmath420-equivalent to the @xmath33-bit prefix of chaitin s @xmath437-number .",
    "since in this survey we restrict ourselves to finite objects , we do not go into details of the proof here , see  @xcite .",
    "we discussed how much time is needed to enumerate all strings of complexity at most @xmath33 and how many strings remain not enumerated before this time .",
    "now we want to study _ which _ strings remain not enumerated .",
    "more precisely , let @xmath1 be some string of complexity at most @xmath33 , so @xmath1 appears in the enumeration of all strings of complexity at most @xmath33 .",
    "how close @xmath1 is to the end , that is , how many strings are enumerated after @xmath1 ?",
    "the answer depends on the enumeration , but only slightly , as the following proposition shows .",
    "[ prop : pos - def ] let @xmath61 and @xmath296 be algorithms that both for any given @xmath33 enumerate ( without repetitions ) the set of strings of complexity at most @xmath33 .",
    "let @xmath1 be some string and let @xmath453 and @xmath454 the number of strings that appear after @xmath1 in @xmath61- and @xmath296-enumerations .",
    "then @xmath455 .",
    "we may also assume that @xmath61 and @xmath296 are algorithms of complexity @xmath420 without input that enumerate strings of complexity at most @xmath33 .",
    "assume that @xmath453 is small : @xmath456 .",
    "why @xmath457 can not be much larger than @xmath72",
    "? given the first @xmath458 bits of @xmath382 and @xmath296 , we can compute a finite set of strings @xmath426 that contains @xmath1 and consists only of strings of complexity at most @xmath33 .",
    "then we can wait until all strings from @xmath426 appear in @xmath61-enumeration .",
    "after then at most @xmath75 strings are left , and we need @xmath72 bits to count them . in this way we can describe @xmath382 by @xmath459 bits ; however , proposition  [ prop : omegas ] says that @xmath386 .",
    "hence @xmath460 .",
    "the other inequality is proven by a symmetric argument .",
    "in this theorem @xmath61 and @xmath296 enumerate exactly the same strings ( though in different order ) . however , the complexity function is essentially defined with @xmath16-precision only : different optimal programming languages lead to different versions .",
    "let @xmath39 and @xmath461 be two ( plain ) complexity functions ; then @xmath462 for some @xmath9 and for all @xmath1 .",
    "then the list of all @xmath1 with @xmath463 is contained in the list of all @xmath1 with @xmath464 .",
    "the same argument shows that the number of elements after @xmath1 in the first list can not be much larger than the number of elements after @xmath1 in the second list .",
    "the reverse inequality is not guaranteed , however , even for the same version of complexity ( small increase in the complexity bound may significantly increase the number of strings after @xmath1 in the list ) .",
    "we will return to this question in section  [ subsec : rel - px ] , but let us note first that some increase is guaranteed .",
    "[ prop : tail - monotonicity ] if for a string @xmath1 there are at least @xmath236 elements after @xmath1 in the enumeration of all strings of complexity at most @xmath33 , then for every @xmath465 there are at least @xmath466 strings after @xmath1 in the enumeration of all strings of complexity at most @xmath467 .",
    "essentially the same argument works here : if there are much less than @xmath429 strings after @xmath1 in the bigger list , then this bigger list can be determined by @xmath468 bits needed to cover @xmath1 in the smaller list and less than @xmath469 bits needed to count the elements in the bigger list that follow the last covered element .",
    "the last proposition can be restated in the following way .",
    "let us fix some complexity function and and some algorithm that , given @xmath33 , enumerates all strings of complexity at most @xmath33 . then , for a given string @xmath1 , consider the function that maps every @xmath380 to the logarithm of the number of strings after @xmath1 in the enumeration with input @xmath33 .",
    "proposition  [ prop : tail - monotonicity ] says that @xmath27-increase in the argument leads at least to @xmath470-increase of this function ( but the latter increase could be much bigger ) .",
    "as we will see , this function is closely related to the set @xmath223 ( and therefore @xmath325 ) : it is one more representation of the same boundary curve .      to explain the relation , consider the following procedure for a given binary string @xmath1 . for every @xmath380 draw the line @xmath471 on @xmath224-plane .",
    "then draw the point on this line with second coordinate @xmath232 where @xmath232 is the logarithm of the number of elements after @xmath1 in the enumeration of all strings of complexity at most @xmath33 .",
    "mark also all points on this line on the right of ( = below ) this point . doing this for different @xmath33",
    ", we get a set ( figure  [ mdl - e-12 ] ) .     between @xmath152 and @xmath3 ( length of @xmath1 )",
    "we count elements after @xmath1 in the list of strings having complexity at most @xmath33 ; assuming there is about @xmath236 of them , we draw point @xmath472 and get a point on some curve .",
    "this curve turns out to be the boundary of @xmath223 ( with logarithmic precision ) . ]",
    "proposition  [ prop : tail - monotonicity ] guarantees that this set is upward closed with logarithmic precision : if some point @xmath224 belongs to this set , then the point @xmath473 is in @xmath474-neighborhood of this set .",
    "this implies that the point @xmath475 is also in the neighborhood , since our set is closed by construction in the direction @xmath476 .",
    "it turns out that this set coincides with @xmath223 ( definition  [ def : px ] ) with @xmath4-precision for a string @xmath1 of length @xmath3 ( this means , as usual , that each of the two sets is contained in the @xmath4-neighborhood of the other one ) :    [ thm : tail - characterization ] let @xmath1 be a string of length @xmath3",
    ". if @xmath1 has a @xmath218-description then @xmath1 is at least @xmath477-far from the end of @xmath478-list .",
    "conversely , if there are at least @xmath219 elements that follow @xmath1 in the @xmath479-list then @xmath1 has a @xmath480-description .",
    "we need to verify two things .",
    "first , assuming that @xmath1 has a @xmath218-description , we need to show that it is at least @xmath219-far from the end of @xmath479-list .",
    "( with error terms : in @xmath478-list there are at least @xmath477 elements after @xmath1 . ) indeed , knowing some @xmath218-description @xmath61 for @xmath1 , we can wait until all the elements of @xmath61 appear in @xmath479-list ( as usual , we omit @xmath4-term : all elements of @xmath61 have complexity at most @xmath481 , so we should consider @xmath478-list to be sure that it contains all elements of @xmath61 )",
    ". in particular , @xmath1 has appeared at that moment .",
    "if there are ( significantly ) less than @xmath219 elements after @xmath1 , then we can encode the number of remaining elements by ( significantly ) less than @xmath225 bits , and together with the description of @xmath61 we get less than @xmath482 bits to describe @xmath483 , which is impossible .",
    "second , assume that there are at least @xmath219 elements that follow @xmath1 in the @xmath479-list .",
    "then , splitting this list into @xmath219-portions , we get at most @xmath170 full portions , and @xmath1 is covered by one of them .",
    "each portion has complexity at most @xmath171 and log - size at most @xmath225 , so we get an @xmath218-description for @xmath1 .",
    "( as usual , logarithmic terms are omitted . )    now we can reformulate the properties of stochastic and antistochastic objects .",
    "every object of complexity @xmath72 appears in the list of objects of complexity at most @xmath484 for all @xmath485 .",
    "each stochastic object is far from the end of these lists ( except , may be , for some @xmath484-lists with @xmath484 very close to @xmath72 ) .",
    "each antistochastic object of length @xmath3 is maximally close to the end of all @xmath484-lists with @xmath486 ( there are about @xmath487 objects after @xmath1 ) , except , may be , for some @xmath484-lists with @xmath484 very close to @xmath3 .",
    "when @xmath484 becomes greater than @xmath3 , then even antistochastic strings are far from the end of the @xmath484-list .",
    "what we have said is just the description of the corresponding curves ( figure  [ mdl.2 ] ) using theorem  [ thm : tail - characterization ] .",
    "the lists of objects of bounded complexity provide a natural class of descriptions .",
    "consider some @xmath33 and the number @xmath382 of strings of complexity at most @xmath33 .",
    "this number can be represented in binary : @xmath488 where @xmath489 .",
    "the list itself then can be split into pieces of size @xmath490 , @xmath491 ,  , and these pieces can be considered as description of corresponding objects . in this way for each string @xmath1 and for each @xmath492 we get some description on @xmath1 , a piece than contains @xmath1 .",
    "descriptions obtained in this way will be called _ standard _ descriptions .",
    "note that for a given @xmath1 we have many standard descriptions ( depending on the choice of @xmath33 ) .",
    "one should have in mind also that the class of standard descriptions depends on the choice of the complexity function and the enumeration algorithm , and we assume in the sequel that they are fixed .",
    "the following results show that standard descriptions are in a sense universal . first let us note that the standard descriptions have parameters close to the boundary curve of @xmath223 ( more precisely , to the boundary curve of the set constructed in the previous section that is close to @xmath223 ) .",
    "and @xmath493 in @xmath494 are close to each other ( each is contained in the small neighborhood of the other one ) , this does not imply that their boundaries are close .",
    "it may happen that one set has a small `` hole '' and the other does not , so the boundary of the first set has points that are far from the boundary of the second one .",
    "however , in our case both sets are closed by construction in two different directions , and this implies that the boundaries are also close . ]    [ prop : std - pos ] consider the standard description @xmath61 of size @xmath219 obtained from the list of all strings of complexity at most @xmath33 .",
    "then @xmath495 , and the number of elements in the list that follow the elements of @xmath61 is @xmath496 .",
    "this statement says that parameters of @xmath61 are close to the point on the line @xmath471 considered in the previous section ( figure  [ mdl - e-12 ] ) .    to specify @xmath61 , it is enough to know the first @xmath497 bits of @xmath382 ( and @xmath33 itself ) .",
    "the complexity of @xmath61 can not be much smaller , since knowing @xmath61 and the @xmath225 least significant bits of @xmath382 we can reconstruct @xmath382 .",
    "the number of elements that follow @xmath61 can not exceed @xmath219 ( it is a sum of smaller powers of @xmath191 ) ; it can not be significantly less since it determines @xmath382 together with the first @xmath497 bits of @xmath437 .",
    "( in other words , since @xmath382 is an incompressible string of length @xmath33 , it can not have more that @xmath420 zeros in a row . )",
    "this result does _ not _ imply that every point on the boundary of @xmath223 is close to parameters of some standard description .",
    "if some part of the boundary has slope @xmath242 , we can not guarantee that there are standard descriptions along this part .",
    "for example , consider the list of strings of complexity at most @xmath33 ; the maximal complexity of strings in this list is @xmath417 for some @xmath498 ; if we take first string of this complexity , there are @xmath499 strings after it , so the corresponding point is close to the vertical axis , and due to proposition  [ prop : tail - monotonicity ] all other standard descriptions of @xmath1 are also close to the vertical axis .",
    "however , descriptions with parameters close to arbitrary points on the boundary of @xmath223 can be obtained from standard descriptions by chopping them into smaller parts , as in proposition  [ prop : description - shift ] . in that shopping",
    "it is natural to use the order in which the strings were enumerated . in other words , chop the list of strings of complexity at most @xmath33 into portions of size @xmath219 . consider all the full portions ( of size exactly @xmath219 ) obtained in this way ( they are parts of standard descriptions of bigger size ) .",
    "descriptions obtained in this way are `` universal '' in the following sense : if a pair @xmath224 is on the boundary of @xmath223 then there is a set @xmath339 of this type of complexity @xmath500 and log - cardinality @xmath501 .",
    "the following result says more : for every description @xmath61 for @xmath1 there is a `` better '' standard description that is simple given @xmath61 ( note that @xmath465 in the following proposition and that optimality deficiency of @xmath296 does not exceed that of @xmath61 up to logarithmic term ) .",
    "[ prop : better - std ] let @xmath61 be an @xmath218-description of a string @xmath1 of length @xmath3 .",
    "then there exists a standard description @xmath296 that has parameters @xmath502 and @xmath503 for some @xmath465 , and is simple given @xmath61 , i.e. , @xmath504 .    if @xmath61 has strings of length different from @xmath3 , remove all those strings . in this way",
    "@xmath61 becomes @xmath218-description for @xmath1 with slightly larger @xmath171 than before the removal and the same or smaller @xmath225 .",
    "now all the elements of @xmath61 have complexity at most @xmath505 , where the latter inequality holds , as after removal we have @xmath506 .",
    "consider the list of all strings of complexity at most @xmath33 and the standard description @xmath296 of @xmath1 obtained from this list .",
    "as we know from proposition  [ prop : std - pos ] , the sum of the parameters of this description is close to @xmath33 ( and therefore to @xmath482 ) .",
    "we need to show that the size of @xmath296 is large , at least @xmath477 ( recall that @xmath27 in the statement should be positive ) .",
    "why is this the case ?",
    "consider elements that appear after the last element of @xmath61 in the list .",
    "there are at least @xmath477 of them , otherwise the total number of elements in the list could be described in much less than @xmath33 bits ( that number can be specified by @xmath507 and the number of elements after the last element of @xmath61 ) .",
    "therefore there are at least @xmath477 elements in the list that appear after @xmath1 , so @xmath296 can not be small",
    ".    why @xmath296 is simple given @xmath61 ?",
    "denote the size of @xmath296 by @xmath508 . given @xmath61 and @xmath33",
    ", we can find the last element of @xmath61 , call it @xmath280 , in the list of strings of complexity at most @xmath33 . chop the list into portions of size @xmath508 .",
    "then @xmath296 is the last complete portion .",
    "if @xmath296 contains @xmath280 , we can find @xmath296 from @xmath33 , @xmath509 , and @xmath280 as the complete portion containing @xmath280 .",
    "otherwise , @xmath280 appears in the list after all the elements from @xmath296 . in this case",
    "we can find @xmath296 from @xmath33 and @xmath280 as the last complete portion before @xmath280 .",
    "thus in any case we are able to find @xmath296 from @xmath33 , @xmath509 , and @xmath280 plus one extra bit .",
    "for the same reason every standard description @xmath296 of some @xmath1 is simple given @xmath1 ( and this is not a surprise , since we know that all optimal descriptions of @xmath1 are simple given @xmath1 , see proposition  [ prop : improving - descriptions ] ) .",
    "proposition  [ prop : better - std ] has the following corollary which we formulate in an informal way .",
    "let @xmath61 be some @xmath218-description with parameters on the boundary of @xmath223 .",
    "assume that on the left of this point the boundary curve decreases fast ( with slope less than @xmath242 ) .",
    "then in proposition  [ prop : better - std ] the value of @xmath27 is small , otherwise the point @xmath510 would be far from @xmath223 .",
    "so the complexities of @xmath61 and the standard description @xmath296 are close to each other .",
    "we know also that @xmath61 is simple given @xmath296 , therefore @xmath296 is also simple given @xmath61 , and @xmath61 and @xmath296 have the same information ( have small conditional complexities in both directions ) .",
    "if [ discussion - minimal ] we have two different descriptions @xmath511 with approximately the same parameters on the boundary of @xmath223 , and the curve decreases fast on the left of the corresponding boundary point , the same argument shows that @xmath61 and @xmath212 have the same information .",
    "note that the condition about the slope is important : if the point is on the segment with slope @xmath242 , the situation changes .",
    "for example , consider a random @xmath3-bit string @xmath1 and two its descriptions .",
    "the first one consists of all @xmath3-bit strings that have the same left half as @xmath1 , the second one consists of all @xmath3-bit strings that have the same right half .",
    "both have the same parameters : complexity @xmath512 and log - size @xmath512 , so they both correspond to the same point on the boundary of @xmath223 .",
    "still the information in these two descriptions is different ( left and right halves of a random string are independent ) .",
    "these results sound as good news .",
    "let us recall our original goal : to formalize what is a good statistical model .",
    "it seems that we are making some progress .",
    "indeed , for a given @xmath1 we consider the boundary curve @xmath223 and look at the place when it first touches the lower bound @xmath513 ; after that it stays near this bound .",
    "in other terms , we consider models with negligible optimality deficiency , and select among them the model with minimal complexity .",
    "giving a formal definitions , we need to fix some threshold @xmath88 .",
    "then we say that a set @xmath61 is a _",
    "@xmath88-sufficient statistic _",
    "if @xmath514 , and may choose the simplest one among them and call it the _ minimal @xmath88-sufficient statistic_. if the curve goes down fast on the left of this point , we see that all the descriptions with parameters corresponding to minimal sufficient statistic are equivalent to each other .",
    "trying to relate these notion to practice , we may consider the following example .",
    "imagine that we have digitized some very old recording and got some bit string @xmath1 .",
    "there is a lot of dust and scratches on the recording , so the originally recorded signal is distorted by some random noise .",
    "then our string @xmath1 has a two - part description : the first part specifies the original recording and the noise parameters ( intensity , spectrum , etc . ) and the second part specifies the noise exactly .",
    "may be , the first part is the minimal sufficient statistic  and therefore sound restoration ( and lossy compression in general ) is a special case of the problem of finding a minimal sufficient statistic ?",
    "the uniqueness result above ( saying that all the minimal sufficient statistics contain the same information under some conditions ) seem to support this view : different good models for the same object contain the same explanation .",
    "still the following observation ( that easily follows from what we know ) destroys this impression completely .",
    "[ prop : std - omega ] let @xmath296 be some standard description of complexity @xmath171 obtained from the list of all strings of complexity at most @xmath33 . then @xmath296 is @xmath420-equivalent to @xmath515 .",
    "this looks like a failure .",
    "imagine that we wanted to understand the nature of some data string @xmath1 ; finally we succeed and find a description for @xmath1 of reasonable complexity and negligible randomness and optimality deficiencies ( and all the good properties we dreamed of ) . but",
    "proposition  [ prop : std - omega ] says that the information contained in this description is more related to the computability theory than to specific properties of @xmath1 .",
    "recalling the construction , we see that the corresponding standard description is determined by some prefix of some @xmath437-number , and is an interval in the enumeration of objects of bounded complexity .",
    "so if we start with two old recordings , we may get the same information , which is not what we expect from a restoration procedure .",
    "of course , there is still a chance that some @xmath437-number was recorded and therefore the restoration process indeed should provide the information about it , but this looks like a very special case that hardly should happen for any practical situation .",
    "what could we do with this ?",
    "first , we could just relax and be satisfied that we now understand much better the situation with possible descriptions for @xmath1 .",
    "we know that every @xmath1 is characterized by some curve that has several equivalent definitions ( in terms of stochasticity , randomness deficiency , position in the enumeration  as well as time - bounded complexity , see section  [ sec : depth ] below ) .",
    "we know that standard descriptions cover the parts of the curve where it goes down fast , and to cover the parts where the slope is @xmath242 one may use standard descriptions and their pieces ; all these descriptions are simple given @xmath1 .",
    "when curve goes down fast , the description is essentially unique ( all the descriptions with the same parameters contain the same information , equivalent to the corresponding @xmath437-number ) ; this is not true on parts with slope @xmath242 .",
    "so , even if this curve is of no philosophical importance , we have a lot of technical information about possible models .",
    "the other approach is to go farther and consider only models from some class ( section  [ sec : restricted - type ] ) , or add some additional conditions and look for `` strong models '' ( section  [ sec : strong - models ] ) .",
    "now we can explain in a different way why the probability of obtaining a non - stochastic object in a random process is negligible ( proposition  [ prop : nonstochastic - counting ] ) .",
    "this explanation uses the notion of mutual information from algorithmic information theory .",
    "the mutual information in two strings @xmath1 and @xmath91 is defined as @xmath516 all three expressions are @xmath4-close",
    "if @xmath1 and @xmath91 are strings of length @xmath3 ( see , e.g. , ( * ? ? ?",
    "* chapter 2 ) ) .",
    "consider an arbitrary string @xmath1 of length @xmath3 ; let @xmath72 be the complexity of @xmath1 .",
    "consider the list of all objects of complexity at most @xmath72 , and the standard description @xmath61 for @xmath1 obtained from this list .",
    "if @xmath61 is large , then @xmath1 is stochastic ; if @xmath61 is small , then @xmath1 contains a lot of information about @xmath443 and @xmath439 .",
    "more precisely , let us assume that @xmath61 has size @xmath517 ( i.e. , is @xmath236 times smaller than it could be ) .",
    "then ( recall proposition  [ prop : std - pos ] ) the complexity of @xmath61 is @xmath518 , since we can construct @xmath61 knowing @xmath72 and the first @xmath232 bits of @xmath443 ( before the bit that corresponds to @xmath61 ) .",
    "so we get @xmath519-description with optimality deficiency @xmath520 .    on the other hand , knowing @xmath1 and @xmath72 , we can find the ordinal number of @xmath1 in the enumeration , so we know @xmath443 with error at most @xmath517 , so @xmath521 , and @xmath522 ( recall that @xmath448 ) . in the last statement",
    "we may replace @xmath443 by @xmath439 ( where @xmath3 is the length of @xmath1 ) : we know from proposition  [ prop : omega - equivalence ] that @xmath443 is simple given @xmath439 , so if condition @xmath443 decreases complexity of @xmath1 by almost @xmath232 bits , the same is true for condition @xmath439 .    comparing arbitrary @xmath523 with this @xmath232",
    "( it can be larger than @xmath232 or smaller than @xmath232 ) , we get the following result :    [ prop : dilemma ] let @xmath1 be a string of length @xmath3 . for every @xmath523",
    "* either @xmath1 is @xmath524-stochastic , * or @xmath525 .",
    "now we may use the following ( simple and general ) observation : for every string @xmath109 the probability to generate ( by a randomized algorithm ) an object that contains a lot of information about @xmath109 is negligible :    [ prop : information - rare ] for every string @xmath109 and for every number @xmath27 , we have @xmath526    in this proposition the sum is taken over all strings @xmath1 that have the given property ( have a large mutual information with @xmath109 ) . note that we have chosen the representation of mutual information that makes the proposition easy ( in particular , we have used prefix complexity ) .",
    "as we mentioned , other definitions differ only by @xmath4 if we consider strings @xmath1 and @xmath109 of length at most @xmath3 , and logarithmic accuracy is enough for our purposes .    recall the definition of prefix complexity : @xmath527 , and @xmath528 .",
    "so @xmath529 implies @xmath530 , and it remains to note that @xmath531 for every @xmath109 .",
    "propositions  [ prop : dilemma ] and  [ prop : information - rare ] immediately imply the following improved version of proposition  [ prop : nonstochastic - counting ] ( page  ):    [ prop : nonstochastic - counting - improved ] @xmath532 for every @xmath47 .",
    "the improvement here is the better upper bound for the randomness deficiency : @xmath4 instead of @xmath131 .",
    "the relation between busy beaver numbers and kolmogorov complexity was pointed out in  @xcite ( see section 2.1 ) .",
    "the enumerations of all objects of bounded complexity and their relation to stochasticity were studied in  @xcite ( see section iii , e ) .",
    "in this section we reformulate the results of the previous one in terms of bounded - time kolmogorov complexity and discuss the various notions of computational and logical depth that appeared in the literature .",
    "( the impatient reader may skip this section ; it is not technically used in the sequel ) .",
    "the usual definition of kolmogorov complexity of @xmath1 as the minimal length @xmath356 of a program @xmath84 that produces @xmath1 does not take into account the running time of the program @xmath84 : it may happen that the minimal program for @xmath1 requires a lot of time to produce @xmath1 while other programs produce @xmath1 faster but are longer ( for example , program `` print @xmath1 '' is rather fast ) . to analyze this trade - off , the following definition is used .",
    "let @xmath375 be some algorithm ; its input and output are binary strings .",
    "for a string @xmath1 and integer @xmath533 , define @xmath534 the time - bounded kolmogorov complexity of @xmath1 with time bound @xmath533 with respect to @xmath375 .",
    "this definition was mentioned already in the first paper by kolmogorov  @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ our approach has one important drawback : it does not take into account the efforts needed to transform the program @xmath84 and object @xmath1 [ the description and the condition ] to the object @xmath91 [ whose complexity is defined ] . with appropriate definitions ,",
    "one may prove mathematical results that could be interpreted as the existence of an object @xmath1 that has simple programs ( has very small complexity @xmath371 ) but all short programs that produce @xmath1 require an unrealistically long computation . in another paper i plan to study the dependence of the program complexity @xmath535 on the difficulty @xmath533 of its transformation into  @xmath1 .",
    "then the complexity @xmath371 ( as defined earlier ) reappears as the minimum value of @xmath535 if we remove restrictions on  @xmath533 . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    kolmogorov never published a paper he speaks about , and this definition is less studied than the definition without time bounds , for several reasons .",
    "first , the definition is machine - dependent : we need to decide what computation model is used to count the number of steps .",
    "for example , we may consider one - tape turing machines , or multi - tape turing machine , or some other computational model .",
    "the computation time depends on this choice , though not drastically ( e.g. , a multi - tape machine can be replaced with a one - tape machine with quadratic increase in time , and most popular models are polynomially related  this observation is used when we argue that the class p of polynomial - time computable functions is well defined ) .",
    "second , the basic result that makes the kolmogorov complexity theory possible is the solomonoff ",
    "kolmogorov theorem saying that there exists an optimal algorithm @xmath375 that makes the complexity function minimal up to @xmath16 additive term .",
    "now we need to take into account the time bound , and get the following ( not so nice ) result .",
    "[ prop : time - bounded - optimal ] there exists an optimal algorithm @xmath375 for time - bounded complexity in the following sense : for every other algorithm @xmath536 there exists a constant @xmath9 and a polynomial @xmath537 such that @xmath538 for all strings @xmath1 and integers @xmath533 .    in this result , by `` algorithm '' we may mean a @xmath72-tape turing machine , where @xmath72 is an arbitrary fixed number . however , the claim remains true even when @xmath72 is not fixed , i.e. , we may allow @xmath536 to have more tapes than @xmath375 has .",
    "the proof remains essentially the same : we choose some simple self - delimiting encoding of binary strings @xmath539 and some universal algorithm @xmath540 and then let @xmath541 then the proof follows the standard scheme ; the only thing we need to note is that the decoding of @xmath542 runs in polynomial time ( which is true for most natural ways of self - delimiting encoding ) and that the universal algorithm simulation overhead is polynomial ( which is also true for most natural constructions of universal algorithms ) .",
    "a similar result is true for conditional decompressors , so the conditional time - bounded complexity can be defined as well .    for turing machines with fixed number of tapes",
    "the statement is true for some linear polynomial @xmath543 . for the proof",
    "we need to consider a universal machine @xmath379 that simulates other machines efficiently : it should move the program along the tape , so the overhead is bounded by a factor that depends on the size of the program and not on the size of the input or computation time .",
    ", see  ( * ? ? ?",
    "* section 1.3 , p.  21 ) ) where the program size and logarithm of the computation time are added : linear overhead in computation time matches the constant overhead in the program size .",
    "however , this is a different approach and we do not use the levin s notion of time bounded complexity in this survey . ]    let @xmath544 be an arbitrary total computable function with integer arguments and values ; then the function @xmath545 is a computable upper bound for the complexity @xmath381 ( defined with the same @xmath375 ; recall that @xmath546 stands for the length of @xmath1 ) . replacing the function @xmath547 by a bigger function",
    ", we get a smaller computable upper bound . an easy observation : in this way we can match every computable upper bound for kolmogorov complexity .    [ prop : any - upper - bound ] let @xmath548 be some total computable upper bound for kolmogorov complexity function based on the optimal algorithm @xmath375 from proposition  [ prop : time - bounded - optimal ] . then there exists a computable function @xmath533 such that @xmath549 for every @xmath1 .    given a number @xmath3 , we wait until every string @xmath1 of length at most @xmath3 gets a program that has complexity at most @xmath548 , and let @xmath544 be the maximal number of steps used by these programs .",
    "so the choice of a computable time bound is essentially equivalent to the choice of a computable total upper bound for kolmogorov complexity .    in the sequel",
    "we assume that some optimal ( in the sense of proposition  [ prop : time - bounded - optimal ] ) @xmath375 is fixed and omit the subscript @xmath375 in @xmath550 .",
    "similar notation @xmath551 is used for conditional time - bounded complexity .",
    "we use the extremely fast growing sequence @xmath552 as a scale for measuring time .",
    "this sequence grows faster than any computable function ( since the complexity of @xmath544 for any computable @xmath533 is at most @xmath553 , we have @xmath554 ) . in this scale",
    "it does not matter whether we use time or space as the resource measure : they differ at most by an exponential function , and @xmath555 ( in general , @xmath556 for every computable @xmath557 ) .",
    "so we are in the realm of general computability theory even if we technically speak about computational complexity , and the problems related to the unsolved p = np question disappear .",
    "let @xmath1 be a string of length @xmath3 and complexity @xmath72 .",
    "consider the time - bounded complexity @xmath558 as a function of @xmath533 .",
    "( the optimal algorithm from proposition  [ prop : time - bounded - optimal ] is fixed , so we do not mention it in the notation . )",
    "it is a decreasing function of @xmath533 . for small values of @xmath533",
    "the complexity @xmath558 is bounded by @xmath440 where @xmath3 stands for the length of @xmath1 .",
    "indeed , the program that prints @xmath1 has size @xmath440 and works rather fast . formally speaking , @xmath559 for @xmath560 . as @xmath533 increases , the value of @xmath558 decreases and reaches @xmath561 as @xmath562 .",
    "it is guaranteed to happen for @xmath563 , since the computation time for the shortest program for @xmath1 is determined by this program .",
    "we can draw a curve that reflects this trade - off using @xmath296-scale for the time axis .",
    "namely , consider the graph of the function @xmath564 and the set of points above this graph , i.e. , the set @xmath565    [ thm : depth ] the set @xmath566 coincides with the set @xmath325 with @xmath4-precision for a string @xmath1 of length  @xmath3 .    recall that the set @xmath325 consists of pairs @xmath0 such that @xmath1 is @xmath0-stochastic ( see p.  ) .    as we know from theorem  [ thm : def - opt",
    "] , the sets @xmath223 and @xmath325 are related by an affine transformation ( see figure  [ mdl.8 ] ) . taking this transformation into account , we need to prove two statements :    * if there exists an @xmath218-description @xmath61 for @xmath1 , then @xmath567 * if @xmath568 , then @xmath569    both statements are easy to prove using the tools from the previous section . indeed , assume that @xmath1 has an @xmath218-description @xmath61 .",
    "all elements of @xmath61 have complexity at most @xmath481 .",
    "knowing @xmath61 and this complexity , we can find the minimal @xmath533 such that @xmath570 for all @xmath280 from @xmath61 .",
    "this @xmath533 can be computed from @xmath61 , which has complexity @xmath171 , and an @xmath4-bit advice ( the value of complexity ) .",
    "hence @xmath571 and @xmath572 , as required .",
    "the converse : assume that @xmath573 .",
    "consider all the strings @xmath280 that satisfy this inequality .",
    "there are at most @xmath574 such strings .",
    "thus we only need to show that given @xmath171 and @xmath225 we are able to enumerate all those strings in at most @xmath275 portions .",
    "one can get a list of all those strings @xmath280 if @xmath575 is given , but we can not compute @xmath575 given  @xmath171 . recall that @xmath575 is the maximal integer that has complexity at most @xmath171 ; new candidates for @xmath575 may appear at most @xmath170 times .",
    "the candidates increase with time ; when this happens , we get a new portion of strings that satisfy the inequality @xmath573 .",
    "so we have at most @xmath574 objects including @xmath1 that are enumerated in at most @xmath170 portions , and this implies that @xmath1 has an @xmath480-description .",
    "indeed , we make all portions of size at most @xmath219 by splitting larger portions into pieces .",
    "the number of portions increases at most by @xmath275 , so it remains @xmath275 .",
    "each portion ( including the one that contains @xmath1 ) has then complexity at most @xmath167 since it can be computed with logarithmic advice from its ordinal number .",
    "this theorem shows that the results about the existence of non - stochastic objects can be considered as the `` mathematical results that could be interpreted as the existence of an object @xmath1 that has simple programs ( has very small complexity @xmath371 ) but all short programs that produce @xmath1 require an unrealistically long computation '' mentioned by kolmogorov ( see the quotation above ) , and the algorithmic statistics can be interpreted as an implementation of kolmogorov s plan `` to study the dependence of the program complexity @xmath535 on the difficulty @xmath533 of its transformation into  @xmath1 '' , at least for the simple case of ( unrealistically ) large values of @xmath533 .",
    "section  [ sec : depth ] has title `` logical and computational depth '' but we have not defined these notions yet . the name `` logical depth '' was introduced by c.  bennett in  @xcite .",
    "he explains the motivation as follows :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ some mathematical and natural objects ( a random sequence , a sequence of zeros , a perfect crystal , a gas ) are intuitively trivial , while others ( e.g. , the human body , the digits of @xmath576 ) contain internal evidence of a nontrivial causal history .",
    "we propose depth as a formal measure of value . from the earliest days of information theory",
    "it has been appreciated that information per se is not a good measure of message value .",
    "for example , a typical sequence of coin tosses has high information content but little value ; an ephemeris , giving the positions of the moon and the planets every day for a hundred years , has no more information than the equations of motion and initial conditions from which it was calculated , but saves its owner the effort of recalculating these positions .",
    "the value of a message thus appears to reside not in its information ( its absolutely unpredictable parts ) , nor in its obvious redundancy ( verbatim repetitions , unequal digit frequencies ) , but rather is what might be called its buried redundancy  parts predictable only with difficulty , things the receiver could in principle have figured out without being told , but only at considerable cost in money , time , or computation . in other words ,",
    "the value of a message is the amount of mathematical or other work plausibly done by its originator , which its receiver is saved from having to repeat . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    trying to formalize this intuition , bennett suggests the following possible definitions :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * tentative definition 0.1 * : a string s depth might be defined as the execution time of its minimal program . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this notion is not robust ( it depends on the specific choice of the optimal machine used in the definition of complexity ) .",
    "so bennett considers another version :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * tentative definition 0.2 * : a string s depth at significance level @xmath232 [ might ] be defined as the time required to compute the string by a program no more than @xmath232 bits larger than the minimal program .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    we see that definition 0.2 consider the same trade - off as in theorem  [ thm : depth ] , but in reversed coordinates ( time as a function of difference between time - bounded and limit complexities ) .",
    "bennett is still not satisfied by this definition , for the following reason :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ this proposed definition solves the stability problem , but is unsatisfactory in the way it treats multiple programs of the same length .",
    "intuitively , @xmath75 distinct @xmath577-bit programs that compute same output ought to be accorded the same weight as one @xmath3-bit program @xmath372 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in other language , he suggests to consider a priori probability instead of complexity :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * tentative definition 0.3 * : a string s depth at significance level @xmath232 might be defined as the time @xmath533 required for the string s time - bounded algorithmic probability @xmath578 to rise to within a factor @xmath579 of its asymptotic time - unbounded value @xmath116 . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    here @xmath580 is understood as a total weight of all self - delimiting programs that produce @xmath1 in time at most @xmath533 ( each program of length @xmath232 has weight @xmath579 ) . for our case ( when we consider busy beaver numbers as time scale ) the exponential time increase needed to switch from a priori probability to prefix complexity does not matter .",
    "still bennett is interested in more reasonable time bounds ( recall that in his informal explanation a polynomially computable sequence of @xmath576-digits was an example of a deep sequence ! ) , and prefers a priori probability approach .",
    "moreover , he finds a nice reformulation of this definition ( almost equivalent one ) in terms of complexity :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ although definition 0.3 satisfactorily captures the informal notion of depth , we propose a slightly stronger definition for the technical reason that it appears to yield a stronger slow growth property @xmath372    * definition 1 * ( depth of finite strings ) : let @xmath1 and @xmath581 be strings [ probably @xmath581 is a typo : it is not mentioned later ] and @xmath232 a significance parameter .",
    "a string s _ depth _ at significance level @xmath232 , denoted @xmath582 , will be defined as @xmath583 the least time required to compute it by a @xmath232-incompressible program .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    here @xmath370 is a shortest self - delimiting program for @xmath84 , so its length @xmath584 equals @xmath585 .",
    "actually , this _ definition 1 _ has a different underlying intuition than all the previous ones : a string @xmath1 is deep if _ all programs that compute @xmath1 in a reasonable time , are compressible_. note the before we required a different thing : that all programs that compute @xmath1 in a reasonable time are much longer than the minimal one .",
    "this is a weaker requirement : one may imagine a long incompressible program that computes @xmath1 fast .",
    "this intuition is explained in the abstract of the paper  @xcite as follows :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ [ we define ] an object s `` logical depth '' as the time required by a standard universal turing machine to generate it from an input that is algorithmically random . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    bennett then proves a statement ( called lemma 3 in his paper ) that shows that his _ definition 1 _ is almost equivalent to _ tentative definition 0.3 _ : the time remains exactly the same , while @xmath232 changes at most logarithmically ( in fact , at most by @xmath586 ) .",
    "so if we use bennett s notion of depth ( any of them , except for the first one mentioned ) with busy beaver time scale , we get the same curve as in our definition .",
    "a natural question arises : is there a direct proof that the output of an incompressible program with not too large running time is stochastic ?",
    "in fact , yes , and one can prove a more general statement : the output of a _",
    "stochastic _ program with reasonable running time is stochastic ( see section  [ subsec : depth - appl ] ) ; note that stochasticity is a weaker condition than incompressibility .",
    "let us mention also the notion of _ computational depth _ introduced in  @xcite .",
    "there are several versions mentioned in this paper ; the first one exchanges coordinates in the bennett s tentative definition 0.2 ( reproduced in  @xcite as definition 2.5 ) .",
    "the authors write : `` the first notion of computational depth we propose is the difference between a time - bounded kolmogorov complexity and traditional kolmogorov complexity '' ( definition 3.1 , where time bound is some function of input length ) .",
    "the other notions of computation depth are more subtle ( they use distinguishing complexity or levin complexity involving the logarithm of the computation time ) .",
    "the connections between computational / logical depth and sophistication were anticipated for a long time ; for example , koppel writes in  @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ @xmath372 the `` dynamic '' approach to the formalization of meaningful complexity is `` depth '' defined and discussed by bennett [ 1 ] .",
    "[ reference to an unpublished paper `` on the logical ` depth ' of sequences and their reducibilities to incompressible sequences '' . ]",
    "the depth of an object is the running - time of its most concise description .",
    "since it is reasonable to assume that an object has been generated by its most concise description , the depth of an object can be thought of as a measure of its evolvedness .",
    "although sophistication is measured in integers [ not clear what in meant here : sophistication of @xmath105 is also a function @xmath587 and depth is measured in functions , it is not difficult to translate to a common range . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    strangely , the direct connection between the most basic versions of these notions ( theorem  [ thm : depth ] ) seems to be noticed only recently in  ( * ? ? ?",
    "* section 3 ) , and @xcite .",
    "we have shown several equivalent ( with logarithmic precision and up to affine transformation ) ways to defined the same curve :    * @xmath0-stochasticity ( section  [ sec : stoch ] ) ; * two - part descriptions and optimality deficiency , the set @xmath223 ( section  [ sec : two - part ] ) ; * position in the enumeration of objects of bounded complexity ( section  [ sec : bcl ] ) ; * logical / computational depth ( resource - bounded complexity , section  [ sec : depth ] ) .",
    "one can add to this list a characterization in terms of split enumeration ( section  [ subsec : opt - rand ] ) : the existence of @xmath218-description for @xmath1 is equivalent ( with logarithmic precision ) to the existence of a simple enumeration of at most @xmath288 objects in at most @xmath588 portions ( see remark  [ rem : portion ] , p.  , and the discussion before it ) .",
    "why do we need so many equivalent definitions of the same curve ?",
    "first , this shows that this curve is really fundamental  almost as fundamental characterization of an object @xmath1 as its complexity .",
    "as koppel writes in  @xcite , speaking about ( some versions of ) sophistication and depth :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ one way of demonstrating the naturalness of a concept is by proving the equivalence of a variety of prime facie different formalizations @xmath372 . it is hoped that the proof of the equivalence of two approaches to meaningful complexity , one using static resources ( program size ) and the other using dynamic resources ( time ) , will demonstrate not only the naturalness of the concept but also the correctness of the specifications used in each formalization to ensure robustness and generality .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    another , more technical reason : different results about stochasticity use different equivalent definitions , and a statement that looks quite mysterious for one of them may become almost obvious for another .",
    "let us give two examples of this type ( the first one is stochasticity conservation when random noise is added , the second one is a direct proof of bennett s characterization mentioned above ) .",
    "the first example is the following proposition from  @xcite ( though the proof there is different ) .",
    "[ prop : add - noise ] let @xmath1 be some binary string , and let @xmath91 be another string ( `` noise '' ) that is conditionally random with respect to @xmath1 , i.e. , @xmath589",
    ". then the pair @xmath90 has the same stochasticity profile as @xmath1 : the sets @xmath325 and @xmath590 are logarithmically close to each other .    before giving a proof sketch ,",
    "let us mention that an interesting special case of this proposition is obtained if we consider a string @xmath109 and its description @xmath591 with small randomness deficiency : @xmath592 .",
    "let @xmath91 be the ordinal number of @xmath109 in @xmath591 .",
    "then the small randomness deficiency guarantees that @xmath91 is conditionally random with respect to @xmath1 .",
    "then the pair @xmath593 has the same stochasticity profile as @xmath591 .",
    "since this pair is mapped to @xmath109 by a simple total computable function , we conclude ( proposition  [ prop : stoch - cons ] ) that the stochasticity profile of @xmath591 is contained in the stochasticity profile of @xmath109 ( more precisely , in its @xmath594-neighborhood ) .",
    "( more simple and direct proof of this statement goes as follows : if @xmath595 is a description for @xmath591 that has small complexity and optimality deficiency , we can take the union of all elements of @xmath595 that have approximately the same cardinality as @xmath591 ; one can verify easily that this union also has small complexity and optimality deficiency as a description for @xmath109 . )    the full statement of proposition  [ prop : add - noise ] would introduce some bound for the difference @xmath596 that is allowed to appear in the final estimate for the distance between sets . recall also that we can speak about profiles of arbitrary finite objects , in particular , pairs of strings , using some natural encoding ( section  [ subsec : stoch - cons ] ) .    using the depth characterization of stochasticity profile ,",
    "we need to show that @xmath597 here `` approximately '' means that these two quantities may differ by a logarithmic term , and also we are allowed to add logarithmic terms to @xmath171 ( see below what does it mean ) .",
    "the natural idea is to rewrite this equality as @xmath598 the right hand side is equal to @xmath599 ( with logarithmic precision ) due to kolmogorov ",
    "levin formula for the complexity of a pair ( see , e.g. ,  ( * ? ? ?",
    "* chapter 2 ) ) , and @xmath599 equals @xmath600 , as @xmath91 is random and independent of @xmath1 . thus it suffices to show that the left hand side also equals @xmath600 . to this end",
    "we can prove a version of kolmogorov  levin formula for bounded complexity and show that the left hand side equals to @xmath601 .",
    "again , since @xmath91 is random and independent of @xmath1 , @xmath602 equals @xmath600 .",
    "this plan needs clarification .",
    "first of all , let us explain which version of kolmogorov  levin formula for bounded complexity we need .",
    "( essentially it was published by longpr in  @xcite though the statement was obscured by considering time bound as a function of the input length . )",
    "the equality @xmath603 should be considered as two inequalities , and each one should be treated separately .",
    "there exist some constant @xmath9 and some polynomial @xmath604 such that @xmath605 for all @xmath3 and @xmath533 and for all strings @xmath1 and @xmath91 of length at most @xmath3 .",
    "there exist some constant @xmath9 and some polynomial @xmath604 such that @xmath606 for all @xmath3 and @xmath533 and for all strings @xmath1 and @xmath91 of length at most @xmath3 .    the proof of this time - bounded version is obtained by a straightforward analysis of the time requirements in the standard proof .",
    "the first part says that if there is some program @xmath84 that produces @xmath1 in time @xmath533 , and some program @xmath537 that produces @xmath91 from @xmath1 in time @xmath533 , then the pair @xmath607 can be considered as a program that produces @xmath90 in time @xmath608 and has length @xmath609 ( we may assume without loss of generality that @xmath84 and @xmath537 have length @xmath302 , otherwise we replace them by shorter fast programs ) .",
    "the other direction is more complicated .",
    "assume that @xmath610 .",
    "we have to count for a given @xmath1 the number of strings @xmath121 such that @xmath611 .",
    "these strings ( @xmath91 is one of them ) can be enumerated in time @xmath612 , so if there are @xmath236 of them , then @xmath613 ( the program witnessing this inequality is the ordinal number of @xmath91 in the enumeration plus @xmath4 bits of auxiliary information .",
    "note that we do not need to specify @xmath533 in advance , we enumerate @xmath121 in order of increasing time , and @xmath91 is among first @xmath236 enumerated strings .    on the other hand , there are at most @xmath614 strings @xmath280 for which this number ( of different @xmath121 such that @xmath615 ) is at least @xmath616 , and these strings also could be enumerated in time @xmath612 , so @xmath617 ( again we do not need to specify @xmath533 , we just increase gradually the time bound ) .",
    "when these two inequalities are added , @xmath232 disappears and we get the desired inequality .    of course , the exponent in the lemma is disappointing ( for space bound it is not needed , by the way ) , but since we measure time in busy beaver units , it is not a problem for us : indeed , @xmath618 , and we allow logarithmic change in the argument anyway .",
    "now we should apply this lemma , but first we need to give a full statement of what we want to prove .",
    "there are two parts ( as in the lemma ) :    * for every @xmath171 there exists @xmath619 such that @xmath620 for all strings @xmath1 and @xmath91 of length at most @xmath3 such that @xmath621 ; * for every @xmath171 there exists @xmath619 such that @xmath622 for all strings @xmath1 and @xmath91 of length at most @xmath3 ;    both statements easily follow from the lemma .",
    "let us start with the second statement where the hard direction of the lemma is used . as planned , we rewrite the inequality as @xmath623 using the unbounded formula .",
    "our lemma guarantees that @xmath624 for some @xmath619 , and it remains to note that @xmath625 for the other direction the argument is similar : we rewrite the inequality as @xmath626 and note that @xmath627 , assuming that @xmath575 is greater than the time needed to print @xmath91 from its literary description ( otherwise the statement is trivial ) .",
    "so the lemma again can be used ( in the simple direction ) .    this proof used the depth representation of the stochasticity curve ; in other cases some other representation are more convenient .",
    "our second example is the change in stochasticity profile when a simple algorithmic transformation is applied .",
    "we have seen ( section  [ subsec : stoch - cons ] ) that a total mapping with a short program preserves stochasticity , and noted that for non - total mapping it is not the case ( remark  [ rem : non - total ] , p.  ) .",
    "however , if the time needed to perform the transformation is bounded , we can get some bound ( first proven by a.  milovanov in a different way ) :    [ prop : stoch - nontotal ] let @xmath92 be a computable mapping whose arguments and values are strings .",
    "if some @xmath3-bit string @xmath1 is @xmath0-stochastic , and @xmath93 is computed in time @xmath575 for some @xmath171 , then @xmath93 is @xmath628-stochastic .",
    "( the constant in @xmath4-notation depends on @xmath92 but not on @xmath629 . )",
    "let us denote @xmath93 by @xmath91",
    ". by assumption there exist a @xmath630-description of @xmath1 ( recall the definition with optimality deficiency ; we omit logarithmic terms as usual ) .",
    "so there exists a simple enumeration of at most @xmath631 objects @xmath280 in at most @xmath129 portions that includes @xmath1 .",
    "let us count @xmath280 in this enumeration such that @xmath632 and the computation uses time at most @xmath575 ; assume there are @xmath236 of them .",
    "then we can enumerate all @xmath91 s that have at least @xmath236 preimages in time @xmath575 , in @xmath633 portions . indeed , new portions appear in two cases : ( 1 )  a new portion appears in the original enumeration ; ( 2 )  candidate for @xmath575 increases .",
    "the first event happens at most @xmath129 times , the second at most @xmath170 times .",
    "the total number of @xmath91 s enumerated is @xmath634 ; it remains to note that @xmath635 .",
    "indeed , @xmath636 , and @xmath637 , since we can enumerate all the preimages of @xmath91 in the order of increasing time , and @xmath1 is determined by @xmath232-bit ordinal number of @xmath1 in this enumeration .",
    "a special case of this proposition is bennett s observation : if some @xmath27-incompressible program @xmath84 produces @xmath1 in time @xmath575 , then @xmath84 is @xmath638-stochastic , and @xmath84 is mapped to @xmath1 by the interpreter ( decompressor ) in time @xmath575 , so @xmath1 is @xmath639-stochastic .",
    "( for simplicity we omit all the logarithmic terms in this argument , as well as in the previous proof sketch . )",
    "one can combine remark  [ rem : cons - f ] ( page  ) with proposition  [ prop : stoch - nontotal ] and show that if a program @xmath92 of complexity at most @xmath225 is applied to an @xmath0-stochastic string @xmath1 of length @xmath3 and the computation terminates in time @xmath575 , then @xmath93 is @xmath640-stochastic , where the constant in @xmath4 notation is absolute ( does not depend on @xmath92 ) . to show this",
    ", one may consider the pair @xmath641 ; it is easy to show ( this can be done in different ways using different characterizations of the stochasticity curve ) that this pair is @xmath642-stochastic .",
    "let us note also that there are some results in algorithmic information theory that are true for stochastic objects but are false or unknown without this assumption .",
    "we will discuss ( without proofs ) two examples of this type .",
    "the first is epstein ",
    "levin theorem saying that for a stochastic set @xmath61 its total a priori probability is close to the maximum a priori probability of @xmath61 s elements ; see  @xcite for details . here",
    "the result is ( obviously ) false without stochasticity assumption .    in the next example  @xcite",
    "the stochasticity assumption is used in the proof , and it is not known whether the statement remains true without it : .",
    "this proposition is related to the following open question on `` irrelevant oracles '' : assume that the mutual information between @xmath90 and some @xmath643 is negligible .",
    "can an oracle @xmath643 ( an `` irrelevant oracle '' ) change substantially natural properties of the pair @xmath90 formulated in terms of kolmogorov complexity ?",
    "for instance , can such an oracle @xmath643 allow us to extract some common information of @xmath1 and @xmath91 ? in  @xcite a negative answer to the latter question is given , but only for stochastic pairs @xmath90 .",
    "in this section we consider the restricted case : the sets ( considered as descriptions , or statistical hypotheses ) are taken from some family @xmath644 that is fixed in advance .",
    "( elements of @xmath644 are finite sets of binary strings . ) informally speaking , this means that we have some _ a priori _ information about the black box that produces a given string : this string is obtained by a random choice in one of the @xmath644-sets , but we do not know in which one .    before we had no restrictions ( the family @xmath644 was the family of all finite sets ) .",
    "it turns out that the results obtained so far can be extended ( sometimes with weaker bounds ) to other families that satisfy some natural conditions .",
    "let us formulate these conditions .",
    "( 1 )  the family @xmath644 is enumerable .",
    "this means that there exists an algorithm that prints elements of @xmath644 as lists , with some separators ( saying where one element of @xmath644 ends and another one begins ) .",
    "( 2 )  for every @xmath3 the family @xmath644 contains the set @xmath645 of all @xmath3-bit strings .",
    "( 3 )  there exists some polynomial @xmath84 with the following property : for every @xmath646 , for every natural @xmath3 and for every natural @xmath647 the set of all @xmath3-bit strings in @xmath61 can be covered by at most @xmath648 sets of cardinality at most @xmath9 from @xmath644 .",
    "the last condition is a replacement for splitting : in general , we can not split a set @xmath646 into pieces from @xmath61 , but at least we can cover a set @xmath646 by smaller elements of @xmath644 ( of size at most @xmath9 ) with polynomial overhead in the number of pieces , compared to the required minimum @xmath649 ( more precisely , we have to cover only @xmath3-bit elements of @xmath61 ) .",
    "we assume that some family @xmath644 that has properties ( 1)(3 ) is fixed . for a string @xmath1",
    "we denote by @xmath650 the set of pairs @xmath651 such that @xmath1 has @xmath218-description _ that belongs to @xmath644_. the set @xmath650 is a subset of @xmath223 defined earlier ; the bigger @xmath644 is , the bigger is @xmath650 .",
    "the full set @xmath223 is @xmath650 for the family @xmath644 that contains all finite sets .    for every string @xmath1 the set @xmath650 has properties close to the properties of @xmath223 proved earlier .",
    "[ prop : a - family ] for every string @xmath1 of length @xmath3 the following is true :    1 .   [ a1 ] the set @xmath650 contains a pair that is @xmath4-close to @xmath245 .",
    "[ a2 ] the set @xmath650 contains a pair that is @xmath16-close to @xmath652 .",
    "[ a3 ] the adaptation of proposition  [ prop : description - shift ] is true : if @xmath653 , then @xmath654 also belongs to @xmath650 for every @xmath655 .",
    "( recall that @xmath3 is the length of @xmath1 . )",
    "the property ( 2 ) guarantees that the family @xmath644 contains the set @xmath645 that is an @xmath229-description of @xmath1 .",
    "the property ( 3 ) applied to @xmath656 and @xmath657 says that every singleton belongs to @xmath61 , therefore each string has @xmath658-description .",
    "assume that @xmath1 has @xmath218-description @xmath646 .",
    "for a given @xmath72 we enumerate @xmath644 until we find a family of @xmath659 sets of size @xmath660 ( or less ) in @xmath644 that covers all strings of length @xmath3 in @xmath61 .",
    "such a family exists due to ( 3 ) , and @xmath84 is the polynomial from  ( 3 ) .",
    "the complexity of the set that covers @xmath1 does not exceed @xmath661 , since this set is determined by @xmath61 , @xmath3 , @xmath72 and the ordinal number of the set in the cover .",
    "we may assume without loss of generality that @xmath246 , otherwise @xmath231 can be used as @xmath662-description of @xmath1 .",
    "so the term @xmath520 can be omitted .",
    "for example , we may consider the family that consists of all `` cylinders '' : for every @xmath3 and for every string @xmath109 of length at most @xmath3 we consider the set of all @xmath3-bit strings that have prefix @xmath109 .",
    "obviously the family of all such sets ( for all @xmath3 and @xmath109 ) satisfies the conditions ( 1)(3 ) .",
    "we may also fix some bits of a string ( not necessarily forming a prefix ) .",
    "that is , for every string @xmath643 in ternary alphabet @xmath663 we consider the set of all bit strings that can be obtained from @xmath643 by replacing stars with some bits .",
    "this set contains @xmath75 strings , if @xmath109 has @xmath72 stars . the conditions ( 1)(3 )",
    "are fulfilled for this larger family , too .",
    "a more interesting example is the family @xmath644 formed by all balls in hamming sense , i.e. , the sets @xmath664 . here",
    "@xmath665 is the length of binary string @xmath109 , and @xmath666 is the hamming distance between two strings @xmath1 and @xmath91 of the same length .",
    "the parameter @xmath667 is called the _ radius _ of the ball , and @xmath91 is its _",
    "center_. informally speaking , this means that the experimental data were obtained by changing at most @xmath667 bits in some string @xmath91 ( and all possible changes are equally probable )",
    ". this assumption could be reasonable if some string @xmath91 is sent via an unreliable channel .",
    "both parameters @xmath91 and @xmath667 are not known to us in advance .",
    "it turns out that the family of hamming balls satisfies the conditions ( 1)(3 ) .",
    "this is not completely obvious .",
    "for example , these conditions imply that for every @xmath3 and for every @xmath668 the set @xmath645 of @xmath3-bit strings can be covered by @xmath669 hamming balls of radius @xmath667 , where @xmath670 stands for the cardinality of such a ball ( i.e. , @xmath671 ) , and @xmath84 is some polynomial .",
    "this can be shown by a probabilistic argument : take @xmath414 balls of radius @xmath667 whose centers are randomly chosen in @xmath645 . for a given @xmath672 the probability that @xmath1 is not covered by any of these balls equals @xmath673 .",
    "for @xmath674 this upper bound is @xmath6 , so for this @xmath414 the probability to leave some @xmath1 uncovered is less than  @xmath24 .",
    "a similar argument can be used to prove ( 1)(3 ) in the general case .",
    "[ prop : hamming - balls ] the family of all hamming balls satisfies conditions ( 1)(3 ) above .",
    "let @xmath61 be a ball of radius @xmath675 and let @xmath9 be a number less than @xmath238 .",
    "we need to cover @xmath61 by balls of cardinality @xmath9 or less , using almost minimal number of balls , close to the lower bound @xmath649 up to a polynomial factor .",
    "let us make some observations .",
    "( 1 )  the set of all @xmath3-bit strings can be covered by two balls of radius @xmath512 .",
    "so we can assume without loss of generality that @xmath676 , otherwise we can apply the probabilistic argument above .",
    "( 2 )  clearly the radius of covering balls should be maximal possible ( to keep cardinality less than @xmath9 ) ; for this radius the cardinality of the ball equals @xmath9 up to polynomial factors , since the size of the ball increases at most by factor @xmath677 when its radius increases by @xmath24 .",
    "( 3 )  it is enough to cover spheres instead of balls ( since every ball is a union of polynomially many spheres ) ; it is also enough to consider the case when the radius of the sphere that we want to cover ( @xmath675 ) is bigger than the radius of the covering ball ( @xmath678 ) , otherwise one ball is enough .",
    "( 4 )  we will cover @xmath675-sphere by randomly chosen @xmath678-balls whose centers are uniformly taken at some distance @xmath557 from the center of @xmath675-sphere .",
    "( see below about the choice of @xmath557 . )",
    "we use the same probabilistic argument as before ( for the set of all strings ) .",
    "it is enough to show that for a @xmath678-ball whose center is at that distance , the polynomial fraction of points belong to @xmath675-sphere . instead of @xmath678-balls",
    "we may consider @xmath678-spheres , the cardinality ratio is polynomial .    ( 5 )  it remains to choose some @xmath557 with the following property : if the center of a @xmath678-sphere @xmath105 is at a distance @xmath557 from the center of @xmath675-sphere @xmath266 , then the polynomial fraction of @xmath105-points belong to @xmath266 .",
    "one can compute a suitable @xmath557 explicitly . in probabilistic terms",
    "we just change @xmath679-fraction of bits and then change random @xmath680 fraction of bits .",
    "the expected fraction of twice changed bits is , therefore , about @xmath681 , and the total fraction of changed bits is about @xmath682 .",
    "so we need to write an equation saying that this expression is @xmath683 and the find the solution @xmath557 .",
    "( then one can perform the required estimate for binomial coefficients . )",
    "however , one can avoid computations with the following probabilistic argument : start with @xmath678 changed bits , and then change all the bits one by one in a random order . at the end we hat @xmath684 changed bits , and @xmath675 is somewhere in between , so there is a moment where the number of changed bits is exactly @xmath675 . and if the union of @xmath3 events covers the entire probability space , one of these events has probability at least @xmath685 .",
    "when a family @xmath644 is fixed , a natural question arises : does the restriction on models ( when we consider only models in @xmath644 ) changes the set @xmath223 ?",
    "is it possible that a string has good models in general , but not in the restricted class ? the answer is positive for the class of hamming balls , as the following proposition shows .",
    "[ prop : hamming - gap ] consider the family @xmath644 that consists of all hamming balls . for some positive @xmath88 and for all sufficiently large @xmath3 there",
    "exists a string @xmath1 of length @xmath3 such that the distance between @xmath650 and @xmath223 exceeds @xmath686 .",
    "fix some @xmath47 in @xmath687 and let @xmath670 be the cardinality of the hamming ball of radius @xmath688 .",
    "find a set @xmath689 of cardinality @xmath690 such that every hamming ball of radius @xmath688 contains at most @xmath3 points from @xmath689 .",
    "this property is related to _",
    "list decoding _ in the coding theory .",
    "the existence of such a set can be proved by a probabilistic argument : @xmath414 randomly chosen @xmath3-bit strings have this property with positive probability .",
    "indeed , the probability of a random point to be in @xmath689 is an inverse of the number of points , so the distribution is close to poisson distribution with parameter  @xmath24 , and tails decrease much faster that @xmath6 needed .",
    "since @xmath689 with this property can be found by an exhaustive search , we can assume that @xmath691 and ignore the complexity of @xmath689 ( as well as other @xmath4 terms ) in the sequel .",
    "let @xmath1 be a random element in @xmath689 , i.e. , a string @xmath692 of complexity about @xmath693 .",
    "the complexity of a ball @xmath61 of radius @xmath688 that contains @xmath1 is at least @xmath381 , since knowing such a ball and an ordinal number of @xmath1 in @xmath694 , we can find @xmath1 .",
    "therefore @xmath1 does not have @xmath695-descriptions in @xmath696 . on the other hand",
    ", @xmath1 does have @xmath697-description if we do not require the description to be in @xmath696 ; the set @xmath689 is such a description . the point @xmath698 is above the line @xmath699 , so @xmath700 is significantly smaller than @xmath223 .",
    "this construction gives a stochastic @xmath1 ( @xmath689 is the corresponding model ) that becomes maximally non - stochastic if we restrict ourselves to hamming balls as descriptions ( figure  [ mdl - e-13 ] ) .",
    "can be used ( together with the argument above ) to show that the border of the set @xmath650 ( shown in gray ) consists of a vertical segment @xmath701 , @xmath702 , and the segment of slope @xmath242 defined by @xmath703 , @xmath704 .",
    "the set @xmath223 contains also the hatched part . ]",
    "our next goal is to extend some results proven for non - restricted descriptions to the restricted case .",
    "let @xmath644 be a family that has properties ( 1)(3 ) .",
    "we prove a version of theorem  [ stat - any - curve ] where the precision ( unfortunately ) is significantly worse : @xmath705 instead of @xmath4 .",
    "note that with this precision the term @xmath706 ( proportional to the complexity of the curve ) that appeared in theorem  [ stat - any - curve ] is not needed .",
    "indeed , if we draw the curve on the cell paper with cell size @xmath707 or larger , then it touches only @xmath708 cells , so it is determined by @xmath708 bits with @xmath708-precision , and we may assume without loss of generality that the complexity of the curve is @xmath708 .",
    "[ thm : family - curve ] let @xmath246 be two integers and let @xmath709 be a strictly decreasing sequence of integers such that @xmath248 and @xmath249 .. then there exists a string @xmath1 of complexity @xmath710 and length @xmath194 for which the distance between @xmath650 and @xmath711 is at most @xmath705 .",
    "we will see later ( theorem  [ thm : improving - descriptions-1-gen ] ) that for every @xmath1 the boundary curve of @xmath712 goes down at least with slope @xmath242 , as for the unrestricted case , so this theorem describes all possible shapes of the boundary curve .",
    "the proof is similar to the proof of theorem  [ stat - any - curve ] .",
    "let us recall this proof first .",
    "we consider the string @xmath1 that is the lexicographically first string ( of suitable length @xmath713 ) that is not covered by any `` bad '' set , i.e. , by any set of complexity at most @xmath171 and size at most @xmath219 , where the pair @xmath224 is at the boundary of the set @xmath266 .",
    "the length @xmath713 is chosen in such a way that the total number of strings in all bad sets is strictly less than @xmath714 .",
    "on the other hand , we need `` good sets '' that cover @xmath1 . for every boundary point",
    "@xmath224 we construct a set @xmath715 that contains @xmath1 , has complexity close to @xmath171 and size @xmath219 .",
    "the set @xmath715 is constructed in several attempts .",
    "initially @xmath715 is the set of lexicographically first @xmath219 strings of length @xmath713 .",
    "then we enumerate bad sets and delete all their elements from @xmath715 . at some step @xmath715 may become empty ; then we refill it with @xmath219 lexicographically first strings that are not in the bad sets ( at the moment ) . by construction",
    "the final @xmath715 contains the first @xmath1 that is not in bad sets ( since it is the case all the time ) . and",
    "the set @xmath715 can be described by the number of changes ( plus some small information describing the process as a whole and the value of @xmath225 ) .",
    "so it is crucial to have an upper bound for the number of changes .",
    "how do we get this bound ?",
    "we note that when @xmath715 becomes empty , it is refilled again , and all the new elements should be covered by bad sets before the new change could happen .",
    "two types of bad sets may appear : `` small '' ones ( of size less than @xmath219 ) and `` large ones '' ( of size at least @xmath219 ) .",
    "the slope of the boundary line for @xmath266 guarantees that the total number of elements in all small bad sets does not exceed @xmath288 ( up to a @xmath716-factor ) , so they may make @xmath715 empty only @xmath170 times . and",
    "the number of large bad sets is @xmath275 , since the complexity of each is bounded by @xmath171 .",
    "( more precisely , we count separately the number of changes for @xmath715 that are first changes after a large bad set appears , and the number of other changes . )",
    "can we use the same argument in our new situation ?",
    "we can generate bad sets as before and have the same bounds for their sizes and the total number of their elements .",
    "so the length @xmath713 of @xmath1 can be the same ( in fact , almost the same , as we will need now that the union of all bad sets is less than half of all strings of length @xmath713 , see below ) .",
    "note that we now may enumerate only bad sets in @xmath644 , since @xmath644 is enumerable , but we do not even need this restriction .",
    "what we can not do is to let @xmath715 to be the set of the first non - deleted elements : we need @xmath715 to be a set from @xmath644 .",
    "so we now go in the other direction . instead of choosing @xmath1 first and then finding suitable `` good '' @xmath715 that contain @xmath1",
    ", we construct the sets @xmath717 that change in time in such a way that ( 1 )  their intersection always contains some non - deleted element ( an element that is not yet covered by bad sets ) ; ( 2 ) each @xmath715 has not too many versions . the non - deleted element in their intersection ( in the final state )",
    "is then chosen as @xmath1 .",
    "unfortunately , we can not do this for all points @xmath224 along the boundary curve .",
    "( this explains the loss of precision in the statement of the theorem . ) instead , we construct `` good '' sets only for some values of @xmath225 .",
    "these values go down from @xmath3 to @xmath32 with step @xmath718 .",
    "we select @xmath719 points @xmath720 on the boundary of @xmath266 ; the first coordinates @xmath721 form a non - decreasing sequence , and the second coordinates @xmath722 split the range @xmath723 into ( almost ) equal intervals ( @xmath724 , @xmath725 )",
    ". then we construct good sets of sizes at most @xmath726 , and denote them by @xmath727 .",
    "all these sets belong to the family @xmath644 .",
    "we also let @xmath728 to be the set of all strings of length @xmath729 ; the choice of the constant in @xmath4 will be discussed later .",
    "let us first describe the construction of @xmath727 assuming that the set of deleted elements is fixed .",
    "( then we discuss what to do when more elements are deleted . )",
    "we construct @xmath730 inductively ( first @xmath731 , then @xmath732 etc . ) .",
    "as we have said , @xmath733 ( in particular , @xmath734 is a singleton ) , and we keep track of the ratio @xmath735 for @xmath736 this ratio is at least @xmath5 ; this is obtained by a suitable choice of @xmath713 ( the union of all bad sets should cover at most half of all @xmath713-bit strings ) .",
    "when constructing the next @xmath730 , we ensure that this ratio decreases only by @xmath716-factor .",
    "assume that @xmath737 is already constructed ; its size is at most @xmath738 . the condition @xmath739 for @xmath644 guarantees that @xmath737 can be covered by @xmath644-sets of size at most @xmath740 , and we need about @xmath741 covering sets ( up to @xmath716-factor ) .",
    "now we let @xmath730 be the covering set that contains maximal number of non - deleted elements in @xmath742 .",
    "the ratio can decrease only by the same @xmath716-factor . in this way",
    "we get @xmath743 where @xmath47 stands for the @xmath716-factor mentioned above . close to @xmath414 the right - hand side",
    "can be less than @xmath24 ; the inequality then claims just the existence of non - deleted elements .",
    "the induction step is still possible : non - deleted element is contained in one of the covering sets . ]    up to now we assumed that the set of deleted elements is fixed .",
    "what happens when more strings are deleted ?",
    "the number of the non - deleted in @xmath744 can decrease , and at some point and for some @xmath232 can become less than the declared threshold @xmath745",
    ". then we can find minimal @xmath232 where this happens , and rebuild all the sets @xmath746 ( for @xmath730 the threshold is not crossed due to the minimality of @xmath232 ) . in this way we update the sets @xmath730 from time to time , replacing them ( and all the consequent ones ) by new versions when needed .",
    "the problem with this construction is that the number of updates ( different versions of each @xmath730 ) can be too big .",
    "imagine that after an update some element is deleted , and the threshold is crossed again .",
    "then a new update is necessary , and after this update next deletion can trigger a new update , etc . to keep the number of updates reasonable ,",
    "we agree that after the update _ for all the new sets @xmath747 _ ( starting from @xmath730 ) _",
    "the number of non - deleted elements in @xmath748 is twice bigger than the threshold @xmath749_. this can be achieved if we make the factor @xmath47 twice bigger : since for @xmath737 we have not crossed the threshold , for @xmath730 we can guarantee the inequality with additional factor @xmath191 .",
    "now let us prove the bound for the number of updates for some @xmath730 .",
    "these updates can be of two types : first , when @xmath730 itself starts the update ( being the minimal @xmath232 where the threshold is crossed ) ; second , when the update is induced by one of the previous sets .",
    "let us estimate the number of the updates of the first type .",
    "this update happens when the number of non - deleted elements ( that was at least @xmath750 immediately after the previous update of any kind ) becomes less than @xmath751 .",
    "this means that at least @xmath751 elements were deleted .",
    "how can this happen ?",
    "one possibility is that a new bad set of complexity at most @xmath752 ( `` large bad set '' ) appears after the last update .",
    "this can happen at most @xmath753 times , since there is at most @xmath275 objects of complexity at most @xmath171 .",
    "the other possibility is the accumulation of elements deleted due to `` small '' bad sets , of complexity at least @xmath752 and of size at most @xmath740 .",
    "the total number of such elements is bounded by @xmath754 , since the sum @xmath755 may only decrease as @xmath756 , increases .",
    "so the number of updates of @xmath730 not caused by large bad sets is bounded by @xmath757 ( recall that @xmath758 , @xmath759 , and @xmath760 ) .",
    "this bound remains valid if we take into account the induced updates ( when the threshold is crossed for the preceding sets : there are at most @xmath761 these sets , and additional factor @xmath3 is absorbed by @xmath435-notation ) .",
    "we conclude that all the versions of @xmath730 have complexity at most @xmath762 , since each of them can be described by the version number plus the parameters of the generating process ( we need to know @xmath3 and the boundary curve , whose complexity is @xmath708 according to our assumption , see the discussion before the statement of the theorem ) .",
    "the same is true for the final version .",
    "it remains to take @xmath1 in the intersection of the final sets @xmath730 .",
    "( recall that @xmath734 is a singleton , so final @xmath734 is @xmath231 . ) indeed , by construction this @xmath1 has no bad @xmath218-descriptions where @xmath224 is on the boundary of @xmath266 . on the other hand",
    ", @xmath1 has good descriptions that are @xmath705-close to this boundary and whose vertical coordinates are @xmath718-apart .",
    "( recall that the slope of the boundary guarantees that horizontal distance is less than the vertical distance . )",
    "therefore the position of the boundary curve for @xmath650 is determined with precision @xmath705 , as required .",
    "was chosen to be @xmath763 : the bigger @xmath414 is , the more points on the curve we have , but then the number of versions of the good sets and their complexity increases , so we have some trade - off .",
    "the chosen value of @xmath3 balances these two sources of errors . ]    [ rem : family ] in this proof we may use bad sets not only from @xmath644 . therefore , the set @xmath223 is also close to @xmath266 ( and the same is true for for every family @xmath764 that contains @xmath644 )",
    ". it would be interesting to find out what are the possible combinations of @xmath223 and @xmath650 ; as we have seen , it may happen that @xmath223 is maximal and @xmath650 is minimal , but this does not say anything about other possible combinations",
    ".    for the case of hamming balls the statement of theorem  [ thm : family - curve ] has a natural interpretation . to find a simple ball of radius @xmath667 that contains a given string @xmath1 is the same as to find a simple string in a radius @xmath667 ball centered at @xmath1 .",
    "so this theorem show the possible behavior of the `` approximation complexity '' function @xmath765 where @xmath27 is hamming distance .",
    "one should only rescale the vertical axis replacing the log - sizes of hamming balls by their radii .",
    "the connection is described by the shannon entropy function : a ball in @xmath645 of radius @xmath667 has log - size about @xmath766 for @xmath767 , and has almost full size for @xmath768 .",
    "for example , error correcting codes ( in classical sense , or with list decoding ) are example of strings where this function is almost a constant for small values of @xmath667 : it is almost as easy to approximate a codeword as give it precisely ( due to the possibility of error correction ) .      not all the results proved for unrestricted descriptions have natural counterparts in the restricted case .",
    "for example , one hardly can relate the set @xmath650 with bounded - time complexity ( is completely unclear how @xmath644 could enter the picture ) .",
    "still some results remain valid ( but new and much more complicated proofs are needed ) .",
    "this is the case for proposition  [ prop : description - shift ] and  [ prop : improving - descriptions ] .",
    "let again @xmath644 be the class of descriptions that satisfies requirements ( 1)(3 ) .",
    "[ thm : improving - descriptions-1-gen ]    * if a string @xmath1 of length @xmath3 has an @xmath218-description in @xmath644 , then it has @xmath769-description in @xmath644 for every @xmath770 . *",
    "assume that @xmath1 is a string of length @xmath3 that has at least @xmath75 different @xmath218-descriptions in @xmath644 .",
    "then it has @xmath771-description in @xmath644 .",
    "in fact , the second part uses only condition ( 1 ) ; it says that @xmath644 is enumerable .",
    "the first part uses also ( 3 ) . it can be combined with the second part to show that @xmath1 has also @xmath772-description in @xmath644 .",
    "though theorem [ thm : improving - descriptions-1-gen ] looks like a technical statement , it has important consequences ; it implies that the two approaches based on randomness and optimality deficiencies remain equivalent in the case of bounded class of descriptions . the proof technique can be also used to prove epstein ",
    "levin theorem  @xcite , as explained in  @xcite ; similar technique was used by a.  milovanov in @xcite where a common model for several strings is considered .",
    "the first part is easy : having some @xmath218-description for @xmath1 , we can search for a covering by the sets of right size that exists due to condition  ( 3 ) ; since @xmath644 is enumerable , we can do it algorithmically until we find this covering .",
    "then we select the first set in the covering that contains @xmath1 ; the bound for the complexity of this set is guaranteed by the size of the covering .",
    "the proof of the second statement is much more interesting .",
    "in fact , there are two different proofs : one uses a probabilistic existence argument and the second is more explicit . but both of them start in the same way .",
    "let us enumerate all @xmath218-descriptions from @xmath696 , i.e. , all finite sets that belong to @xmath696 , have cardinality at most @xmath219 and complexity at most @xmath171 .",
    "for a fixed @xmath3 , we start a selection process : some of the generated descriptions are marked ( = selected ) immediately after their generation .",
    "this process should satisfy the following requirements : ( 1 )  at any moment every @xmath3-bit string @xmath1 that has at least @xmath75 descriptions ( among enumerated ones ) belongs to one of the marked descriptions ; ( 2 )  the total number of marked sets does not exceed @xmath773 for some polynomial  @xmath84 . note that for @xmath774 or @xmath775 the statement is trivial , so we may assume that @xmath171 , @xmath225 ( and therefore @xmath72 ) do not exceed @xmath3 ; this explains why the polynomial depends only on @xmath3 .",
    "if we have such a strategy ( of logarithmic complexity ) , then the marked set containing @xmath1 will be the required description of complexity @xmath776 and log - size @xmath225 .",
    "indeed , this marked set can be specified by its ordinal number in the list of marked sets , and this ordinal number has @xmath776 bits .",
    "so we need to construct a selection strategy of logarithmic complexity .",
    "we present two proofs : a probabilistic one and an explicit construction .",
    "probabilistic proof .",
    "first we consider a finite game that corresponds to our situation .",
    "two players alternate , each makes @xmath170 moves . at each move",
    "the first player presents some set of @xmath3-bit strings , and the second player replies saying whether it _ marks _ this set or not .",
    "the second player loses if after some moves the number of marked sets exceeds @xmath777 ( this specific value follows from the argument below ) or if there exists a string @xmath1 that belongs to @xmath75 sets of the first player but does not belong to any marked set .    since this is a finite game with full information ,",
    "one of the players has a winning strategy .",
    "we claim that the second player can win",
    ". if it is not the case , the first player has a winning strategy .",
    "we get a contradiction by showing that the second player has a _ probabilistic _ strategy that wins with positive probability against any strategy of the first player .",
    "so we assume that some ( deterministic ) strategy of the first player is fixed , and consider the following simple probabilistic strategy : every set @xmath61 presented by the first player is marked with probability @xmath778 .",
    "the expected number of marked sets is @xmath779 . by chebyshev",
    "s inequality , the number of marked set exceeds the expectation by a factor @xmath191 with probability less than @xmath5 .",
    "so it is enough to show that the second bad case ( after some move there exists @xmath1 that belongs to @xmath75 sets of the first player but does not belong to any marked set ) happens with probability at most @xmath5 .    for that",
    ", it is enough to show that for every fixed @xmath1 the probability of this bad event is at most @xmath780 , and then use the union bound .",
    "the intuitive explanation is simple : if @xmath1 belongs to @xmath75 sets , the second player had ( at least ) @xmath75 chances to mark a set containing @xmath1 ( when these @xmath75 sets were presented by the first player ) , and the probability to miss all these chances is at most @xmath781 ; the choice of @xmath84 guarantees that this probability is less than @xmath782 . indeed , using the bound @xmath783 , it is easy to show that @xmath784 .",
    "the pedantic reader would say that this argument is not formally correct , since the behavior of the first player ( and the moment when next set containing @xmath1 is produced ) depends on the moves of the second player , so we do not have independent events with probability @xmath785 each ( as it is assumed in the computation ) .",
    ", select some trials ( before they are actually performed , based on the information obtained so far ) , and ask for the probability of the event `` @xmath533 first selected trials were all unsuccessful '' .",
    "this probability does not exceed @xmath786 ; it can be smaller if the total number of selected trials is less than @xmath533 with positive probability .",
    "this scheme was considered by von mises when he defined random sequences using selection rules , so it should be familiar to algorithmic randomness people . ]",
    "the formal argument considers for each @xmath533 the event @xmath787 : `` after some move of the second player the string @xmath1 belongs to at least @xmath533 sets provided by the first player , but does not belong to any marked set ''",
    ". then we prove by induction ( over @xmath533 ) that the probability of @xmath787 does not exceed @xmath786 .",
    "indeed , it is easy to see that @xmath787 in a union of several disjoint subsets ( depending on the events happening until the first player provides @xmath788 sets containing @xmath1 ) , and @xmath789 is obtained by taking a @xmath790-fraction in each of them .",
    "constructive proof .",
    "we consider the same game , but now allow more sets to be marked ( replacing the bound @xmath777 by a bigger bound @xmath791 ) and also allow the second player to mark sets that were produced earlier ( not necessarily at the current move of the first player ) .",
    "the explicit winning strategy for the second player performs in parallel @xmath792 substrategies ( indexed by the numbers @xmath793 ) .",
    "the substrategy number @xmath232 wakes up once in @xmath236 moves ( when the number of moves made by the first player is a multiple of @xmath236 ) .",
    "it considers a family @xmath105 that consists of @xmath236 last sets produced by the first player , and the set @xmath266 that consists of all strings @xmath1 covered by at least @xmath794 sets from @xmath105 .",
    "then it selects and marks some elements in @xmath105 in such a way that all @xmath795 are covered by one of the selected sets .",
    "it is done by a greedy algorithm : first take a set from @xmath105 that covers maximal part of @xmath266 , then the set that covers maximal number of non - covered elements , etc .",
    "how many steps do we need to cover the entire @xmath266 ?",
    "let us show that @xmath796 steps are enough .",
    "indeed , every element of @xmath266 is covered by at least @xmath794 sets from @xmath105 .",
    "therefore , some set from @xmath105 covers at least @xmath797 elements , i.e. , @xmath798-fraction of @xmath266 . at the next step the non - covered part",
    "is multiplied by @xmath799 again , and after @xmath800 steps the number of non - covered elements is bounded by @xmath801 therefore all elements of @xmath266 are covered .",
    "( instead of a greedy algorithm one may use a probabilistic argument and show that randomly chosen @xmath800 sets from @xmath105 cover @xmath266 with positive probability ; however , our goal is to construct an explicit strategy . )    anyway , the number of sets selected by a substrategy number @xmath232 , does not exceed @xmath802 and we get at most @xmath803 for all substrategies .",
    "it remains to prove that after each move of the second player every string @xmath1 that belongs to @xmath75 or more sets of the first player , also belongs to some selected set . for @xmath533th move",
    "we consider the binary representation of @xmath533 : @xmath804 since @xmath1 does not belong to the sets selected by substrategies with numbers @xmath805 , the multiplicity of @xmath1 among the first @xmath806 sets is less than @xmath794 , the multiplicity of @xmath1 among the next @xmath807 sets is also less than @xmath794 , etc .",
    "for those @xmath225 with @xmath808 the multiplicity of @xmath1 among the respective portion of @xmath809 sets is obviously less than @xmath794 .",
    "therefore , we conclude that the total multiplicity of @xmath1 is less that @xmath810 sets of the first player and the second player does not need to care about  @xmath1 .",
    "this finishes the explicit construction of the winning strategy .",
    "now we can assume without loss of generality that the winning strategy has complexity at most @xmath811 .",
    "( in the probabilistic argument we have proved the existence of a winning strategy , but then we can perform the exhaustive search until we find one ; the first strategy found will have small complexity . )",
    "then we use this simple strategy to play with the enumeration of all @xmath644-sets of complexity less than @xmath171 and size @xmath219 ( or less ) .",
    "the selected sets can be described by their ordinal number ( among the selected sets ) , so their complexity is bounded by @xmath812 ( with logarithmic precision ) .",
    "every string that has @xmath75 different @xmath218-descriptions in @xmath644 , will also have one among the selected sets , and that is what we need .    as before ( for the unrestricted case )",
    ", this result implies that descriptions with minimal parameters are simple with respect to the data string :    [ thm : improving - descriptions-2-gen ] let @xmath696 be an enumerable family of finite sets . if a string @xmath1 of length @xmath3 has @xmath218-description @xmath646 such that @xmath813 , then @xmath1 has a @xmath814-description in @xmath644 .",
    "if the family @xmath644 satisfies the condition @xmath739 , then @xmath1 has also a @xmath292-description in  @xmath644 .",
    "this gives us the same corollaries as in the unrestricted case :    let @xmath644 be a family of finite sets that satisfies the conditions ( 1)(3 ) . then for every string @xmath1 of length @xmath3 three statements    * there exists a set @xmath646 of complexity at most @xmath47 with @xmath815 ; * there exists a set @xmath646 of complexity at most @xmath47 with @xmath317 ; * the point @xmath816 belongs to @xmath650    are equivalent with logarithmic precision ( the constants before the logarithms depend on the choice of the set @xmath644 ) .    if we are interested in the uniform statements true for every enumerable family @xmath644 , the same arguments prove the following result :    let @xmath644 be an arbitrary family of finite sets enumerated by some program @xmath84",
    ". then for every @xmath1 of length @xmath3 the statements    * there exists a set @xmath646 such that @xmath67 ; * there exists a set @xmath646 such that @xmath317    are equivalent up to @xmath817-change in the parameters .",
    "a possible way to bring the theory in accordance to our intuition is to change the definition of `` having the same information '' .",
    "although we have not given that definition explicitly , we have adopted so far the following viewpoint : @xmath1 and @xmath91 have the same ( or almost the same ) information if both conditional complexities @xmath818 are small .",
    "if only one complexity , say @xmath819 , is small , we said that all ( or almost all ) information contained in @xmath1 is present in @xmath91 .",
    "now we will adopt a more restricted viewpoint and say that @xmath1 and @xmath91 have the same information if there are short _ total _",
    "( everywhere defined ) programs mapping @xmath1 to @xmath91 and vice versa . from this viewpoint",
    "we can not say anymore that a string @xmath1 and its shortest program @xmath122 have the same information : for example , @xmath1 may be non - stochastic while @xmath122 is always stochastic , so there is no short total program that maps @xmath122 to @xmath1 because of proposition  [ prop : stoch - cons ] .",
    "there is an almost minimal program for @xmath1 that can be obtained from @xmath1 by a simple total algorithm  ( * ? ? ?",
    "* theorem 17 ) .",
    "] let us mention that if @xmath1 and @xmath91 have the same information in this new sense , then there exists a simple computable _ bijection _ that maps @xmath1 to @xmath91 ( so they have the same properties if the property is defined in the computability language ) , see  @xcite for the proof .",
    "formally , let us define the total conditional complexity with respect to a computable function @xmath375 of two arguments , as @xmath820 ( note that @xmath375 is not required to be total , but we consider only @xmath84 such that @xmath821 is defined for all @xmath121 . )    there is a computable function @xmath375 such that @xmath822 is minimal up to an additive constant .",
    "fixing any such @xmath375 we obtain the _ total conditional complexity _ @xmath823 . in other way",
    ", we may define @xmath823 as the minimal plain complexity of a total program that maps @xmath91 to @xmath1 .",
    "we will think that @xmath91 has all ( or almost all ) the information from @xmath1 if @xmath823 is negligible .",
    "formally , we write @xmath824 if @xmath825 and we call @xmath1 and @xmath91 _ @xmath88-equivalent _ and write @xmath826 , if both @xmath827 and @xmath823 are at most @xmath88 .    [ prop : equivalence ] if @xmath826 then the sets @xmath223 and @xmath828 are in @xmath829 neighborhood of each other .    indeed ,",
    "if @xmath61 is an @xmath218-description of @xmath1 and @xmath84 is a total program witnessing @xmath826 , then the set @xmath830 is an @xmath831-description of @xmath91 .",
    "( we need @xmath84 to be total , as otherwise we can not produce the list of @xmath296-elements from the list of @xmath61-elements and @xmath84 . )",
    "now we have more fine - grained classification of descriptions and can try to distinguish between descriptions that were equivalent in the former sense . for example , consider a string @xmath832 where @xmath91 is random conditionally to @xmath1 .",
    "let @xmath61 be a model for @xmath832 consisting of all extensions of @xmath1 ( of the same length ) .",
    "this model looks good ( in particular , it has negligible optimality deficiency ) . on the other hand",
    ", we may consider a standard model @xmath296 for @xmath832 of the same ( or smaller ) complexity .",
    "it also has negligible optimality deficiency but looks unnatural . in this section",
    "we are interested in the following question : how can we formally distinguish good models like @xmath61 from bad models like @xmath296 ?",
    "we will see that at least for some strings @xmath109 the value @xmath833 can be used to distinguish between good and bad models for @xmath109 .",
    "( indeed , in our example @xmath834 is small , while @xmath835 can be large . )",
    "a set @xmath339 is an _",
    "@xmath88-strong model _",
    "( or _ statistic _ ) for a string @xmath1 if @xmath836 .",
    "for instance , the model @xmath61 discussed above is an @xmath4-strong model for @xmath1 .",
    "on the other hand , we will see later that , if @xmath91 is chosen appropriately , then no standardbdescription @xmath296 of the same complexity and log - cardinality as @xmath61 is an @xmath88-strong model for @xmath1 , even for @xmath837 .",
    "strong models satisfy an analog of proposition  [ prop : description - shift ] ( the same proof works ) :    [ prop : description - shift-1 ] let @xmath1 be a string and @xmath61 be an @xmath88-strong model for @xmath1 .",
    "let @xmath171 be a non - negative integer such that @xmath838 .",
    "then there exists an @xmath839-strong model @xmath212 for @xmath1 such that @xmath840 and @xmath841 .    to take into account the strength of models",
    ", we may consider the set @xmath842 obviously , we have @xmath843 for all strings @xmath1 of length @xmath3 and for all @xmath88 .",
    "if the set @xmath844 is not much smaller than @xmath223 for a reasonably small @xmath88 , we will say that @xmath1 is a `` normal '' string and otherwise we call @xmath1 `` strange '' .",
    "more precisely , a string @xmath1 is called @xmath845-_normal _ if @xmath223 is in @xmath846-neighborhood of @xmath844 .",
    "otherwise , @xmath1 is called _",
    "it turns out that there are @xmath847-normal strings with any given set @xmath223 that satisfies the conditions of theorem  [ stat - any - curve ] . on the other hand ,",
    "there are @xmath848-strange strings of length @xmath3 .",
    "we are going to state these facts accurately .",
    "[ stat - any - curve-1 ] let @xmath246 be two integers and let @xmath247 be a strictly decreasing sequence of integers such that @xmath248 and @xmath249 .",
    "then there exists a string @xmath1 of complexity @xmath710 and length @xmath194 for which the distance between both sets @xmath223 and @xmath849 and the set @xmath850 is at most @xmath705 .",
    "consider the family @xmath696 of all cylinders , i.e. , the family of all the sets @xmath851 for different strings @xmath109 and natural numbers @xmath33 .",
    "sets from this family have the following feature : if @xmath339 then @xmath61 is an @xmath4-strong model for @xmath1 .",
    "hence for all strings @xmath1 we have @xmath852 .    by theorem  [ thm : family - curve ] and remark  [ rem : family ] there is a string @xmath1 of length @xmath194 and complexity @xmath710 such that all sets @xmath853 are @xmath705-close to each other .",
    "hence all the three sets are close to the set @xmath854 as well .",
    "as the set @xmath849 includes the latter set and is included in @xmath223 , all the three sets are close to the set @xmath849 as well .",
    "the next theorem  @xcite shows that `` strange '' strings do exist .",
    "[ t1 ] assume that natural numbers @xmath855 satisfy the inequalities @xmath856 then there is a string @xmath1 of length @xmath3 and complexity @xmath857 such that the sets @xmath223 and @xmath858 are @xmath4-close to the sets shown on fig .  .     and @xmath858 for the strange string from theorem  [ t1 ] , with @xmath4-precision .",
    "the set @xmath223 is to the right of the dashed line .",
    "the set @xmath858 is to the right of the solid line . ]",
    "let @xmath859 in theorem  [ t1 ] .",
    "then the sets @xmath223 and @xmath860 are almost @xmath512-apart , since the point @xmath861 is in the @xmath4-neighborhood of @xmath223 while all points from @xmath860 are @xmath862-apart from @xmath861 ( in @xmath863-norm ) .",
    "thus the string @xmath1 is @xmath864-strange .",
    "recall that we have introduced the notion of a strong model to separate good models from bad ones .",
    "indeed , there are some results that justify this approach . the following theorem by milovanov ( see  @xcite for the proof ) states , roughly speaking , that there exist a string @xmath1 of length @xmath3 and a strong model @xmath61 for @xmath1 such that the parameters ( complexity , log - cardinality ) of every strong _ standard _ model @xmath296 for @xmath1 are @xmath865-far from those of @xmath61 .",
    "[ thm : separation ] for all @xmath72 there is a string @xmath1 of length @xmath866 whose profile @xmath223 is @xmath4-close to the gray set shown on fig .      of a string @xmath1 from theorem [ thm :",
    "separation ] . ]",
    "such that    * there is an @xmath4-strong model @xmath61 for @xmath1 with complexity @xmath857 and log - cardinality @xmath867 ( that model witnesses the point @xmath868 on the border of @xmath223 ) , but * for every @xmath380 and for every simple enumeration of strings of complexity at most @xmath33 the standard model @xmath296 for @xmath1 obtained from that enumeration is either not strong for @xmath1 or its parameters are far from the point @xmath868 .",
    "more specifically , if @xmath296 is an @xmath88-strong model for @xmath1 obtained from an enumeration provided by some program @xmath537 , then @xmath869 .",
    "once we have decided that non - strong descriptions are bad , it is natural to restrict ourselves to strong descriptions with negligible randomness deficiency ( and hence negligible optimality deficiency ) .",
    "consider some @xmath3-bit string @xmath1 .",
    "assume that @xmath61 is an @xmath88-strong description of @xmath1 and the randomness deficiency of @xmath1 in @xmath61 is at most @xmath88 .",
    "let @xmath109 be the ordinal number of @xmath1 in @xmath61 with respect to some fixed order .",
    "then @xmath870 and @xmath871 ( the latter inequality holds since @xmath836 and @xmath109 can be easily found when @xmath1 and @xmath61 are known ) . as @xmath109 is random and independent of @xmath61 ( with precision @xmath88 ; note that @xmath872 ) , the sets @xmath873 and @xmath874 are @xmath875-close ( proposition  [ prop : add - noise ] ) . on the other hand , the sets @xmath876 and @xmath325 are @xmath877-close by proposition  [ prop : equivalence ] .",
    "thus we obtain the first property of strong models :    [ prop : upward ] if both @xmath878 and @xmath879 are at most @xmath88 , then the sets @xmath325 and @xmath874 are @xmath880-close .",
    "assume that @xmath61 is an @xmath88-strong model for @xmath1 with negligible randomness deficiency and  @xmath88 ; for simplicity we ignore these negligible quantities in the sequel .",
    "assume that @xmath61 is normal in the sense described above .",
    "then the string @xmath1 is normal as well .",
    "indeed , for every pair @xmath881 with @xmath882 the pair @xmath883 is in @xmath884 ( proposition  [ prop : add - noise ] ; note that @xmath1 is equivalent to @xmath885 and @xmath109 is random with condition @xmath61 ) and hence there is a strong @xmath886-description @xmath764 for @xmath61 . consider the `` lifting '' of @xmath764 , that is , the union of all sets from @xmath764 that have approximately the same size as @xmath61 .",
    "it is a strong @xmath218-description for @xmath1 .",
    "it remains to consider pairs @xmath881 where @xmath887 .",
    "then @xmath888 .",
    "hence the subset of @xmath61 consisting of all strings @xmath280 whose ordinal number in @xmath61 has the same @xmath889 leading bits as the ordinal number of @xmath1 , is a strong @xmath218-description for @xmath1 .",
    "it turns out that for minimal models the converse is true as well .",
    "a model @xmath61 for @xmath1 is called _",
    "@xmath890-minimal _ if there is no model @xmath296 for @xmath1 with @xmath891 and @xmath892 .    for some value @xmath893",
    "the following holds .",
    "assume that @xmath61 is an @xmath88-sufficient statistic for an @xmath894-normal string @xmath1 of length @xmath3 .",
    "assume also that @xmath61 is a @xmath895-minimal model for @xmath1 .",
    "then @xmath61 is @xmath896-normal .",
    "the next theorem states that the total conditional complexity of any strong , sufficient and minimal statistic for @xmath1 conditioned by any other sufficient statistic for @xmath1 is negligible .",
    "[ thm : step - wise ] for some value @xmath893 the following holds .",
    "assume that @xmath897 are @xmath88-sufficient statistics for a string @xmath1 of length @xmath3 .",
    "assume also that @xmath61 is an @xmath88-strong and a @xmath895-minimal statistic for @xmath1",
    ". then @xmath898 .",
    "this theorem can be interpreted as follows : assume that we have removed some noise from a given data string @xmath1 by finding its description @xmath296 with negligible optimality deficiency .",
    "let @xmath61 be any `` ultimately denoised '' model for @xmath1 , i.e. , a minimal model for @xmath1 with negligible optimality deficiency .",
    "then @xmath346 is negligible , as we have seen before .",
    "hence to obtain the `` ultimately denoised '' model for @xmath1 we do not need @xmath1 : any such model can be obtained from @xmath296 by a short program .",
    "theorem  [ thm : step - wise ] shows that any such _",
    "model @xmath61 can be obtained from @xmath296 by a short _ total _ program .",
    "\\1 . is the minimal strong sufficient statistic unique ( up to @xmath88-equivalence ) .",
    "more specifically , assume that @xmath897 are @xmath88-strong , @xmath88-sufficient statistics for a string @xmath1 of length @xmath3 .",
    "assume further that both @xmath897 are @xmath899-minimal models for @xmath1 .",
    "is it true that @xmath900 are small in this case ?",
    "\\2 . a similar question , but this time we do not assume that @xmath296 is minimal .",
    "is it true that @xmath901 is small ?",
    "( an affirmative answer to this question obviously implies the affirmative answer to the previous one . )",
    "note that if , in these two questions , we replace total conditional complexity with the plain conditional complexity then the answers are positive and moreover , we do not need to assume that @xmath897 are @xmath88-strong ( see proposition  [ prop : better - std ] and the last two paragraphs on page  ) .",
    "( merging strong sufficient statistics . )",
    "assume that @xmath897 are strong sufficient statistics for @xmath1 that have small intersection compared to the cardinality of at least one of them .",
    "then it is natural to conjecture that there is a strong sufficient statistic @xmath375 for @xmath1 of larger cardinality ( = of smaller complexity ) that is simple given both @xmath897 .",
    "formally , is it true ( for some constant @xmath9 ) that if @xmath897 are @xmath88-strong @xmath88-sufficient statistics for @xmath1 , then there is a @xmath902-strong @xmath902-sufficient statistic @xmath375 for @xmath1 with @xmath903 and @xmath904 at most @xmath905 ?",
    "( a motivating example : let @xmath1 be a random string of length @xmath3 , let @xmath61 consist of all strings of length @xmath3 that have the same prefix of length @xmath512 as @xmath1 , and let @xmath296 consist of all strings of length @xmath3 that have the same bits with numbers @xmath906 as @xmath1 . in this case",
    "it is natural to let @xmath375 consist of all strings of length @xmath3 that have the same bits @xmath907 as @xmath1 , so that @xmath908 . )",
    "we are grateful to several people who contributed and/or carefully read preliminary versions of this survey , in particular , to b. bauwens , p. gcs , a. milovanov , g. novikov , a. romashchenko , p. vitnyi , and to all participants of kolmogorov seminar in moscow state university and escape group in lirmm .",
    "we are also grateful to an anonymous referee for correcting several mistakes .                  in sect .",
    "4 they define coarse sophistication _ csoph_. to understand motivation of def",
    ".  4.1 , note that @xmath910 for any @xmath9-sufficient statistic .",
    "so the idea is to use the @xmath9 as a penalty in selecting the model .",
    "[ but then one can wonder why not have a penalty linear in @xmath9 .",
    "] they show that csoph can be large . [ the trivial upper bound is @xmath911 , and it is tight within logarithms . ]    in sect .",
    "5 they define something like coarse logical depth ( def .",
    "5.2 ) , which adds a similar penalty @xmath912 to the inverse busy beaver of the running time of @xmath84 .",
    "then they show that this depth equals coarse sophistication .",
    "the proof is similar to the proof in @xcite .",
    "l. antunes , l. fortnow , and d. van melkebeek . computational depth , _ proceedings of the 16th ieee conference on computational complexity _ , 266273 .",
    "ieee , new york , 2001 .",
    "journal version : computational depth : concept and applications , _ theoretical computer science _ , * 354*(3 ) , 391404 ( 2006 )      section 3 repeats bennett s lemma saying that two versions of logical depth are the same .",
    "section 4 has lemma 4.2 and the authors claim it follows directly from the definitions .",
    "the second part of the paper is about independence for infinite strings .          _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ some mathematical and natural objects ( a random sequence , a sequence of zeros , a perfect crystal , a gas ) are intuitively trivial , while others ( e.g. , the human body , the digits of @xmath576 ) contain internal evidence of a nontrivial causal history .",
    "we formalize this distinction by defining an object s `` logical depth '' as the time required by a standard universal turing machine to generate it from an input that is algorithmically random .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ we propose depth as a formal measure of value . from the earliest days of information theory",
    "it has been appreciated that information per se is not a good measure of message value .",
    "for example , a typical sequence of coin tosses has high information content but little value ; an ephemeris , giving the positions of the moon and the planets every day for a hundred years , has no more information than the equations of motion and initial conditions from which it was calculated , but saves its owner the effort of recalculating these positions .",
    "the value of a message thus appears to reside not in its information ( its absolutely unpredictable parts ) , nor in its obvious redundancy ( verbatim repetitions , unequal digit frequencies ) , but rather is what might be called its buried redundancy  parts predictable only with difficulty , things the receiver could in principle have figured out without being told , but only at considerable cost in money , time , or computation . in other words , the value of a message is the amount of mathematical or other work plausibly done by its originator , which its receiver is saved from having to repeat . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the notion of logical depth developed in the present paper was first described in [ chaitin 1977 ] , and at greater length on [ bennett 1982 ] and [ bennett 1985 ] ; similar notions have been independently introduces by [ adleman 1979 ] ( `` potential '' ) , [ levin and vjugin 1977 ] ( `` incomplete sequence '' ) , [ levin 1984 ] ( `` hitting time '' ) , and [ koppel , this volume ] ( `` sophistication '' ) .",
    "see also wolfram s work on `` computational irreducibility '' [ wolfram 1985 ] and hartmanis work on time- and space - bounded algorithmic information [ hartmanis 1983 ] .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    ( [ bennett 1982 ] is an unpublished manuscript , [ bennett 1985 ] : information , dissipation and the definition of organization . in _ emerging syntheses in science _",
    "d.  pines , 297313 , nm : santa fe institute , 1985 .",
    "[ adleman 1979 ] :  see  @xcite [ levin and vjugin 1977 ] : invariant properties of information bulks , lecture notes in computer science , * 53 * , 359364 ; only infinite sequences are considered there , and _ complete sequences _",
    "( = random with respect to some computable measure ) are considered .",
    "[ levin 1984 ] : randomness conservation inequalities : information and independence in mathematical theories . _ information and control _ , * 61 * , 1537 ( 1984 ) , based on draft report mit / lcs / tr-235 ( 1980 ) . here @xmath913 is defined ( length of the program plus logarithm of the computation time ) ; the rest of the paper is about infinite sequences . [ wolfram 1985 ] : undecidability and intractability in theoretical physics , _ phys .",
    "l. _ * 54 * , 735738 ( 1985 ) .",
    "[ hartmanis 1983 ] : generalized kolmogorov complexity and the structure of feasible computations . in : _ proceedings of the 25th ieee symposium on foundations of computer science _ , 1984 .",
    "[ definition of time - bounded complexity and relations to computational complexity . ]    considers self - delimiting machines of standard type , prefix complexity , algorithmic probability ( = a priori probability in standard terminology ) .",
    "compressible strings by @xmath232 bits : @xmath914 ( compares prefix complexity and length ) .",
    "time - bounded probability @xmath578 , if only program that terminate in time @xmath533 are considered .",
    "busy beaver @xmath423 , the prefix version .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * tentative definition 0.1 * : a string s depth might be defined as the execution time of its minimal program . @xmath372",
    "* tentative definition 0.2 * : a string s depth at significance level @xmath232 [ might ] be defined as the time required to compute the string by a program no more than @xmath232 bits larger than the minimal program .",
    "this proposed definition solves the stability problem , but is unsatisfactory in the way it treats multiple programs of the same length .",
    "intuitively , @xmath75 distinct @xmath577-bit programs that compute same output ought to be accorded the same weight as one @xmath3-bit program ; @xmath372    * tentative definition 0.3 * : a string s depth at significance level @xmath232 might be defined as the time @xmath533 required for the string s time - bounded algorithmic probability @xmath578 to rise to within a factor @xmath579 of its asymptotic time - unbounded value @xmath116 .",
    "@xmath372 although definition 0.2 satisfactorily captures the informal notion of depth , we propose a slightly stronger definition for the technical reason that it appears to yield a stronger slow growth property ( theorem 1 below ) .",
    "* definition 1 * ( depth of finite strings ) : let @xmath1 and @xmath581 be strings and @xmath232 a significance parameter .",
    "a string s depth at significance level @xmath232 , denoted @xmath582 , will be defined as @xmath915 , the least time required to compute it by a @xmath232-incompressible program @xmath372    the difference between this definition and the previous one is rather subtle philosophically and not very great quantitatively .",
    "philosophically , definition 1 says that each _ individual _ hypothesis for the rapid origin of @xmath1 is implausible at the @xmath579 confidence level , whereas the previous definition 0.3 requires only that a weighted average of all such hypotheses be implausible .",
    "the following lemma shows that the difference between definition 1 and definition 0.3 is also small quantitatively .",
    "* lemma 3 .",
    "* there exists constants @xmath916 and @xmath917 such that for any string @xmath1 , if programs running in time @xmath918 contribute a fraction between @xmath579 and @xmath919 of the string s total algorithmic probability , then @xmath1 has depth at most @xmath533 at significance level @xmath920 and depth at least @xmath533 at significance level @xmath921 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    here @xmath378 stands for prefix complexity .",
    "proof sketch : if programs that run in some time ( or have some other property ) provide a significant part of total probability , then one of the programs with this property is incompressible ( otherwise the probability would be greater ) . in other direction , if they provide only a small part of the total probability , they all can be compressed ( since they form a set of small measure ) .",
    "l.  bienvenu , d.  desfontaines , a.  shen , what percentage of programs halt ? _ proceedings of icalp 2015 , 42nd international colloquium , kyoto , japan , july 6 - 10 , 2015 _ , lecture notes in computer science , * 9134 * , 219230 . extended version : generic algorithms for halting problem and optimal machines revisited , `",
    "arxiv:1505.00731 ` .",
    "p.23 : `` special attention will be given to the so - called kolmogorov @xmath378 function , a function that has not yet made its appearance in the literature .",
    "we argue that it plays the role of a minimal sufficient statistics '' .",
    "there is an interpretation of learning some predicate as gambling against this predicate .",
    "theorem 1 on p.  28 says that if we know in advance that @xmath3-bit sequence is in some set @xmath92 , then we can bet ( sequentially in the prescribed order ) to win @xmath922 .",
    "strangely , cover writes then `` the proof will not be given here but can be found in [ 1 ] '' where [ 1 ] is kolmogorov 1965 paper ( that contains nothing related to betting ! )      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\4 .",
    "* kolmogorov s @xmath358 function *    consider the function @xmath359 , @xmath360 , where the minimum is taken over all subsets @xmath361 , such that @xmath362 , @xmath363 , @xmath364 .",
    "this definition was introduces by kolmogorov in a talk at the information symposium , tallinn , estonia , in 1974 .",
    "thus @xmath365 is the log of the size of the smallest set containing @xmath1 over all sets specifiable by a program of @xmath72 or fewer bits .",
    "of special interest is the value @xmath366 note that @xmath367 is the maximal number of bits necessary to describe an arbitrary element @xmath362 .",
    "thus a program for @xmath1 can be written in two stages : `` use @xmath84 to print the indicator function for @xmath105 ; the desired sequence is the @xmath171th sequence in a lexicographic ordering of the elements of this set '' .",
    "this program has length @xmath368 , and @xmath369 is the length of the shortest program @xmath84 for which this @xmath191-stage description is as short as the best @xmath24-stage description @xmath370 .",
    "we observe that @xmath1 must be maximally random with respect to @xmath105  otherwise the @xmath191-stage description could be improved , contradicting the minimality of @xmath371 .",
    "thus @xmath369 and its associated program @xmath84 constitute a minimal sufficient description for @xmath1 .",
    "@xmath372    arguments can be provided to establish that @xmath369 and its associated set @xmath373 describe all of the `` structure '' of @xmath1 .",
    "the remaining details about @xmath1 are conditionally maximally complex .",
    "thus @xmath374 , the program for @xmath373 , plays the role of a sufficient statistic . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _          a.n .",
    "kolmogorov , three approaches to the quantitative definition of information [ russian :     ",
    "< <   > > ] _ problems of information transmission _ [    ] , * 1*(1 ) , 411 ( 1965 ) .",
    "english translation published in : _ international journal of computer mathematics _ , * 2 * , 157168 ( 1968 ) .",
    "kolmogorov , the complexity of algorithms and the objective definition of randomness .",
    "summary of the talk presented april 16 , 1974 at moscow mathematical society .",
    "_    _",
    "( uspekhi matematicheskikh nauk , russian ) , * 29*(4[178 ] ) , 155 ( 1974 ) .",
    "see  http://mi.mathnet.ru/rus/umn/v29/i4/p153 . a short note in russian .",
    "   @xmath1      @xmath348    @xmath72       @xmath1  ,      @xmath72 .",
    "   @xmath1    ,   @xmath352       @xmath72 .",
    "     ,     ``  '' .",
    "   ``   ''    ,   @xmath352 ,      @xmath923  @xmath353 ,      @xmath354 .",
    "a.  kolmogorov .",
    "talk at the seminar at moscow state university mathematics department ( logic division ) , 26 november 1981 .",
    "[ the definition of @xmath0-stochasticity was defined in this talk , and the question about the fraction of non - stochastic objects was posed . ]      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ p.  1087 : the total complexity of an object is defined as the size of its most concise description . the total complexity of an object can be large while its `` meaningful '' complexity is low ; for example , a random object is by definition maximally complex but completely lacking in structure .",
    "@xmath372 the `` static '' approach to the formalization of meaningful complexity is `` sophistication '' defined and discussed by koppel and atlan [ 3 ] .",
    "[ reference to unpublished paper `` program - length complexity , sophistication , and induction '' is given , but later a paper of the same authors appeared : moshe koppel , henri atlan , an almost machine - independent theory of program - length complexity , sophistication , and induction . _",
    "journal of information sciences : an international journal _ , * 56*(13 ) , 2333 ( aug .",
    "1991 ) , http://www.sciencedirect.com/science/article/pii/002002559190021l .  as ] sophistication is a generalization of the `` h - function '' or `` minimal sufficient statistic '' by cover and kolmogorov [ 2 ] [ reference to cover 1985 paper  as ] , using the mo[no]tonic complexity of levin [ 4 ] [ on the notion of random sequence , 1973  as ] the sophistication of an object in the size of that part of that object which describes its structure , i.e. the aggregate of its projectible properties .",
    "@xmath372 the `` dynamic '' approach to the formalization of meaningful complexity is `` depth '' defined and discussed by bennett [ 1 ] .",
    "[ reference to an unpublished paper `` on the logical ` depth ' of sequences and their reducibilities to incompressible sequences '' . ]",
    "the depth of an object is the running - time of its most concise description .",
    "since it is reasonable to assume that an object has been generated by its most concise description , the depth of an object can be thought of as a measure of its evolvedness .",
    "although sophistication is measured in integers and depth is measured in functions , it is not difficult to translate to a common range .",
    "it has already been shown by schnorr and fuchs [ 5 ] [ c.p .",
    "schnorr , p.  fuchs , general random sequences and learnable sequences , _ journal of symbolic logic _ , * 42 * , 329340 ( 1977 ) . ]",
    "that the sophistication of an infinite string is infinite if and only if its depth is infinite . in this paper , we will prove that for all infinite strings sophistication and depth are essentially equal ( that is , they differ by at most some constant ) .",
    "thus , the more sophisticated an object the more time needed for its evolution .",
    "one way of demonstrating the naturalness of a concept is by proving the equivalence of a variety of prime facie different formalizations ( e.g. computability ) .",
    "it is hoped that the proof of the equivalence of two approaches to meaningful complexity , one using static resources ( program size ) and the other using dynamic resources ( time ) , will demonstrate not only the naturalness of the concept but also the correctness of the specifications used in each formalization to ensure robustness and generality .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the definition of sophistication is technical incomplete / incorrect : it uses turing machine with separate inputs for programs and data , but never specifies which machine is used .",
    "( 1988 paper  @xcite requires universality in the sense that it is not enough . )",
    "still the idea is quite clear ( p.  1089 ) :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * definition 3 . *",
    "the @xmath9-sophistication of a finite string @xmath105 [ is defined as ] @xmath376 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    ( probably the last symbol should be @xmath105 , not @xmath47 ; before in definition 1 the description is called @xmath9-minimal if @xmath377 ; here @xmath2 and @xmath375 and program and data inputs , @xmath378 stands for complexity . )",
    "then sophistication and depth are somehow defined for infinite sequences ( the exact meaning is hard to understand due to technical flaws ) . on p.  1090 : `` thus , the depth of an infinite string @xmath47 is the size of the smallest program which computes an upper - bound on the running time of minimal descriptions of segments of @xmath47 . ''",
    "theorem 1 and 2 ( p.  1090 and 1091 ) claim that depth coincides with sophistication up to a @xmath16-term ( where sophistication is also somehow defined for infinite sequences ) .",
    ": `` what is the sophistication of the string , that is , what is the minimal amount of planning which must go into the generation of the string ?",
    "more picturesquely , if the string is being broadcast by some unknown source , what is the minimum amount of intelligence we must attribute to this source ? ''      p.  436 : `` the minimal description of a string consists of two parts .",
    "one part is a description of the string s structure , and the other part specifies the string from among [ `` from among '' in the text  as ] the class of strings sharing that structure ( cover 1985 ) .",
    "the sophistication of a string is the size of that part of the description which description the string s structure .",
    "thus , for example , the description of the structure of a random string is empty and thus , though its complexity is high , its sophistication is low ''    then some technical approach is suggested based on a specific turing machines with separate tapes for data and program , but the definition is faulty ( there is no optimality requirement , only universality ) .",
    "l.  longpr , _ resource bounded kolmogorov complexity , a link between computational complexity and information theory_. ph .",
    "d. thesis , department of computer science , cornell university , tr  86 - 776 , 1986 .",
    "a.  milovanov , some properties of antistochastic strings . in : _",
    "computer science  theory and applications , 10th international computer science symposium in russia , russia , july 1317 , 2015 . _",
    "( csr 2015 ) , lecture notes in computer science , * 9139 * , 339349 . journal version : _ theory of computing systems _ , online first doi 10.1007/s00224 - 016 - 9695-z .",
    "a.  milovanov , algorithmic statistic , prediction and machine learning , _",
    "33rd symposium on theoretical aspects of computer science _ ( stacs 2016 ) ,",
    "leibnitz international proceedings in informatics ( lipics ) , * 47 * , 2016 , doi 10.4230/lipics.stacs.2016.54 , http://drops.dagstuhl.de/opus/volltexte/2016/5755/ , 54:154:13 .",
    "a.  milovanov , algorithmic statistics : normal objects and universal models , _ computer science  theory and applications _ , proceedings of csr  2016 conference , lecture notes in computer science , * 9691 * , 280293 .",
    "n.  vereshchagin , algorithmic minimal sufficient statistic revisited . in : _",
    "mathematical theory and computational practice , 5th conference on computability in europe _ , cie 2009 , heidelberg , germany , july 1924 , 2009 . proceedings .",
    "lncs 5635 ."
  ],
  "abstract_text": [
    "<S> algorithmic statistics has two different ( and almost orthogonal ) motivations . from the philosophical point of view , it tries to formalize how the statistics works and why some statistical models are better than others . after this notion of a `` good model '' </S>",
    "<S> is introduced , a natural question arises : it is possible that for some piece of data there is no good model ? </S>",
    "<S> if yes , how often these bad ( _ non - stochastic _ ) </S>",
    "<S> data appear `` in real life '' ?    </S>",
    "<S> another , more technical motivation comes from algorithmic information theory . in this theory </S>",
    "<S> a notion of complexity of a finite object ( = amount of information in this object ) is introduced ; it assigns to every object some number , called its _ algorithmic complexity _ ( or _ kolmogorov complexity _ ) . </S>",
    "<S> algorithmic statistic provides a more fine - grained classification : for each finite object some curve is defined that characterizes its behavior . </S>",
    "<S> it turns out that several different definitions give ( approximately ) the same curve . </S>",
    "<S> considers the notion of @xmath0-stochasticity ; section  [ sec : two - part ] considers two - part descriptions and the so - called `` minimal description length principle '' ; section  [ sec : bcl ] gives one more approach : we consider the list of objects of bounded complexity and measure how far some object is from the end of the list , getting some natural class of `` standard descriptions '' as a by - product ; finally , section  [ sec : depth ] establishes a connection between these notions and resource - bounded complexity . the rest of the paper deals with an attempts to make theory close to practice by considering restricted classes of description ( section  [ sec : restricted - type ] ) and strong models ( section  [ sec : strong - models ] ) . ]    in this survey we try to provide an exposition of the main results in the field ( including full proofs for the most important ones ) , as well as some historical comments . </S>",
    "<S> we assume that the reader is familiar with the main notions of algorithmic information ( kolmogorov complexity ) theory . </S>",
    "<S> an exposition can be found in  @xcite or  @xcite , see also the survey  @xcite .    </S>",
    "<S> a short survey of main results of algorithmic statistics was given in  @xcite ( without proofs ) ; see also the last chapter of the book  @xcite . </S>"
  ]
}