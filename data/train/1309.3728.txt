{
  "article_text": [
    "empirical random covariance matrices , whose probabilistic study may be traced back to wishart @xcite in the late twenties , play an important role in applied mathematics .",
    "after marenko and pastur s seminal contribution @xcite in 1967 , the large dimensional setting ( where the dimension of the observations is of the same order as the size of the sample ) has drawn a growing interest , and important theoretical contributions @xcite found many applications in multivariate statistics , electrical engineering , mathematical finance , etc .",
    "the aim of this paper is to describe the fluctuations for linear spectral statistics of large empirical random covariance matrices .",
    "it will complete the picture already provided by bai and silverstein @xcite and will hopefully provide a generic result of interest for practitionners .      consider a @xmath0 random matrix @xmath11 given by : @xmath12 where @xmath13 and @xmath2 is a @xmath14 nonnegative definite hermitian matrix with spectral norm uniformly bounded in @xmath9 .",
    "the entries @xmath15 of matrices @xmath16 are real or complex , independent and identically distributed ( i.i.d . ) with mean 0 and variance 1 .",
    "matrix @xmath17 models a sample covariance matrix , formed from @xmath10 samples of the random vector @xmath18 , with the population covariance matrix @xmath2 . in the asymptotic regime where @xmath19 ( a condition that will be simply referred as @xmath20 in the sequel ) , we study the fluctuations of linear spectral statistics of the form : @xmath21 where @xmath22 refers to the trace of @xmath23 and the @xmath24 s are the eigenvalues of @xmath17 .",
    "this subject has a rich history with contributions by arharov @xcite , girko ( see @xcite and the references therein ) , jonsson @xcite , khorunzhiy et al .",
    "@xcite , johansson @xcite , sinai and soshnikov @xcite , cabanal - duvillard @xcite , guionnet @xcite , bai and silverstein @xcite , anderson and zeitouni @xcite , pan and zhou @xcite , chatterjee @xcite , lytova and pastur @xcite , bai et al .",
    "@xcite , shcherbina @xcite , etc .",
    "there are also more recent contributions for heavytailed entries ( see for instance benaych - georges et al .",
    "@xcite ) .    in their 04",
    "article @xcite , bai and silverstein established a clt for the linear spectral statistics as the dimensions @xmath9 and @xmath10 grow to infinity at the same pace ( @xmath25 ) and under two important assumptions :    1 .",
    "[ ass1-bs ] the entries @xmath26 are centered with unit variance and a finite fourth moment equal to the fourth moment of a ( real or complex ) gaussian standard variable .",
    "[ ass2-bs ] function @xmath6 in is analytic in a neighbourhood of the asymptotic spectrum of @xmath17 .",
    "such a result proved to be highly useful in probability theory , statistics and various other fields .",
    "the purpose of this article is to establish a clt for linear spectral statistics for general entries @xmath27 with finite fourth moment and for non - analytic functions @xmath6 , sufficiently regular , hence to relax both assumptions and in @xcite .",
    "it is well known since the paper by khorunzhiy et al .",
    "@xcite that if the fourth moment of the entries differs from the fourth moment of a gaussian random variable , then a term appears in the variance of the trace of the resolvent , which is proportional to the fourth cumulant of the entries .",
    "this term does not appear if assumption holds true , because in this case , the fourth cumulant is zero .    in pan and zhou @xcite ,",
    "assumption has been relaxed under an additional assumption on matrix @xmath2 , which somehow enforces structural conditions on @xmath2 ( in particular , these conditions are satisfied if matrix @xmath2 is diagonal ) . in hachem et al .",
    "@xcite , clts have been established for specific linear statistics of interest in information theory , with general entries and ( possibly non - centered ) covariance random matrices with a variance profile . in bao",
    "@xcite , the clt is established for the white model ( where @xmath2 is equal to the identity matrix ) with general entries with finite fourth moment , featuring terms in the covariance proportional to the square of the second non - absolute moment and to the fourth cumulant .    in lytova and pastur @xcite and shcherbina @xcite ,",
    "both assumptions have been relaxed for the white model . in this case",
    ", it has been proved that mild integrability conditions over the fourier transform of @xmath6 was enough to establish the clt . in bai",
    "@xcite , fluctuations for the white model are addressed as well , for non - analytic functions @xmath6 .",
    "following shcherbina s ideas , gudon et al .",
    "@xcite establish a clt for linear statistics of large covariance matrices with vectors with log - concave distribution .",
    "following lytova and pastur , yao @xcite relaxes the analyticity assumption in @xcite by using interpolation techniques and fourier transforms .",
    "we follow here a different approach , inspired from bordenave @xcite .",
    "the presence of matrix @xmath2 yields interesting phenomena at the clt level when considering entries with non - gaussian fourth moment : terms proportionnals to the fourth cumulant and to @xmath28 appear in the asymptotic variance ( described in section [ sec : variance - breakdown ] ) ; however their convergence is not granted under usual assumptions ( roughly , under the convergence of @xmath2 s spectrum ) , mainly because these extra - terms also depend on the eigenvectors of @xmath2 . as a consequence , such terms may not converge unless some very strong structural assumption over @xmath2 ( such as @xmath2 diagonal ) is made .",
    "this lack of convergence has consequences on the description of the fluctuations .",
    "denote by @xmath29 the ( approximately ) centered version of the linear statistics , to be properly defined below . instead of expressing the clt in the usual way",
    ", i.e. ( @xmath30{\\mathcal d}}$ ] stands for the convergence in distribution ) : @xmath31{\\mathcal d } { \\mathcal n}({\\mathcal b}^f_\\infty , \\theta^f_\\infty)\\ , \\ ] ] for some well - defined parameters @xmath32 , we prove that the distribution of the linear statistics @xmath29 becomes close to a family of gaussian distributions , whose parameters ( mean and variance ) may not converge .",
    "more precisely , we establish that there exists a family of gaussian random variables @xmath33 , such that @xmath34 { } 0\\ , \\ ] ] where @xmath35 denotes the lvy - prohorov distance ( and in particular metrizes the convergence of laws ) .",
    "details are provided in section [ sec : convergence - preliminary ] and the fluctuation results are stated in theorem [ lemma : main ] ( for the resolvent @xmath36 ) and theorem [ th : non - analytic ] ( for @xmath6 of class @xmath7 , the space of functions with third continuous derivative ) .    from a technical point of view , the analysis of the extra - term proportionnal to the fourth cumulant requires to cope with quadratic forms of the resolvent ( counterpart of isotropic marenko - pastur law ) .",
    "we provide the needed results in section [ sec : proof ] .",
    "expressing the clt as in makes it possible to avoid any cumbersome assumption related to the joint convergence of @xmath2 s eigenvectors and eigenvalues ; the technical price to pay however is the need to get various uniform ( in @xmath37 ) controls over the sequence @xmath38 .",
    "this is achieved by introducing a matrix meta - model in section [ sec : meta - model ] .",
    "the case where matrix @xmath2 is diagonal is simpler and the fluctuations express in the usual way ; it is handled in section [ sec : diagonal - r ] .",
    "remarks on the white case ( @xmath39 ) are also provided in sections [ sec : white - case ] and [ sec : explicit - formulas ] .",
    "this framework may also prove to be useful for other interesting models such as large dimensional information - plus - noise type matrices @xcite and more generally mixed models combining large dimensional deterministic and random matrices .      in section [ section : main ]",
    ", we establish the clt for the trace of the resolvent @xmath40 in order to transfer the clt from the resolvent to the linear statistics of the eigenvalues @xmath41 , we will use ( dynkin-)helffer - sjstrand s representation formula for a function @xmath6 of class @xmath42 and with compact support @xcite . denote by @xmath43 the function : @xmath44 where @xmath45 is smooth , compactly supported , with value 1 in a neighbourhood of 0 .",
    "function @xmath46 coincides with @xmath6 on the real line and is an appropriate extension of @xmath6 to the complex plane .",
    "let @xmath47 , then helffer - sjstrand s formula writes : @xmath48 where @xmath49 stands for the lebesgue measure over @xmath50 .",
    "an elementary proof of formula can be found in ( * ? ? ?",
    "closest to our work are the papers by pizzo , orourke , renfrew and soshnikov @xcite where the fluctuations of the entries of regular functions of wigner and large covariance matrices are studied .",
    "we believe that representation formula provides a very streamlined way to handle non - analytic functions and in fact enables us to state the fluctuations for the linear statistics for functions of class @xmath7 , a lower regularity requirement than in @xcite .      beside the fluctuations , a substantial part of this article",
    "is devoted to the study of the bias that we describe hereafter . in order to center the linear spectral statistics",
    "@xmath51 , we consider the ( first order ) expansion of @xmath52 : @xmath53 where @xmath54 is @xmath55 and does not depend on the distribution of the entries of @xmath3 , and define @xmath29 as : @xmath56 a precise description of @xmath29 is provided in section [ sec : representation - ls ] . in order to fully characterize the fluctuations of @xmath29",
    ", we must study the second order expansion of @xmath57 : @xmath58 which will naturally yield the bias of @xmath29 , as @xmath59 .",
    "asymptotic expansions for various matrix ensembles have already been studied , see for instance pastur et al .",
    "@xcite , bai and silverstein @xcite , haagerup and thorbjrnsen @xcite , schultz @xcite , capitaine and donati - martin @xcite , vallet et al .",
    "@xcite , hachem et al .",
    "@xcite , etc .",
    "the asymptotic bias is expressed in theorem [ lemma : main ] for the resolvent . in order to lift asymptotic expansions from the resolvent to smooth functions ,",
    "we combine ideas from haagerup and thorbjrnsen @xcite and loubaton et al . @xcite together with some gaussian interpolation and the use of helffer - sjstrand s formula . for smooth functions ,",
    "the statement is given in theorem [ th : non - analytic - bias ] .",
    "somehow surprisingly , the condition over function @xmath6 is stronger for the asymptotic expansion to hold than for the clt as function @xmath6 needs to be of class @xmath60 ( cf .",
    "remark [ rem:18 ] ) .",
    "in section [ sec : background ] , we provide some general background ; we describe the covariance of the normalized trace of the resolvent of @xmath17 in section [ sec : variance - breakdown ] and its bias in section [ sec : representation - ls ] . in section [ section : main ] , we state the fluctuation theorem ( theorem [ lemma : main ] ) for the trace of the resolvent . in section [ sec : non - analytic ] , we state the fluctuation theorem ( theorem [ th : non - analytic ] ) for general linear statistics and describe its bias in theorem [ th : non - analytic - bias ] . sections [ sec : proof ] , [ sec : proof - non - analytic - i ] and [ proof : non - analytic - ii ] are respectively devoted to the proofs of theorems [ lemma : main ] , [ th : non - analytic ] and [ th : non - analytic - bias ] .      we are particularly indebted to charles bordenave who drew our attention to helffer - sjstrand s formula and related variance estimates , which substantially shorten the initial proof of fluctuations for non - analytic functions ; we would like to thank reinhold meise for his help to understand tillmann s article ; finally , we would also like to thank djalil chafa , walid hachem and philippe loubaton for fruitful discussions .",
    "recall the asymptotic regime where @xmath20 , cf . , and denote by @xmath61    [ ass : x ] the random variables @xmath62 are independent and identically distributed .",
    "they satisfy : @xmath63    [ ass : r ] consider a sequence @xmath64 of deterministic , nonnegative definite hermitian @xmath14 matrices , with @xmath13 .",
    "the sequence @xmath65 is bounded for the spectral norm as @xmath66 : @xmath67    in particular , we will have : @xmath68      denote by @xmath69 ( resp .",
    "@xmath70 ) the resolvent of matrix @xmath17 ( resp . of @xmath71 ) : @xmath72 and by @xmath73 and @xmath74 their normalized traces which are the stieltjes transforms of the empirical distribution of @xmath17 s and @xmath71 s eigenvalues : @xmath75 the following canonical equation admits a unique solution @xmath76 in the class of stieltjes transforms of probability measures ( see for instance @xcite ) : @xmath77 the function @xmath76 being introduced , we can define the following @xmath14 matrix @xmath78 matrix @xmath79 can be thought of as a _ deterministic equivalent _ of the resolvent @xmath69 in the sense that it approximates the resolvent in various senses . for instance , @xmath80 { } 0 \\ , \\quad z\\in \\mathbb{c}\\setminus \\mathbb{r}^+\\ , \\ ] ] ( in probability or almost surely )",
    ". otherwise stated , @xmath81 is the deterministic equivalent of @xmath73 .",
    "as we shall see later in this paper , the following property holds true : @xmath82 { } 0\\ ] ] where @xmath83 and @xmath84 are deterministic @xmath85 vectors with uniformly bounded euclidian norms in @xmath9 . as a consequence of ,",
    "not only @xmath86 conveys information on the limiting spectrum of the resolvent @xmath87 but also on the eigenvectors of @xmath87 .",
    "if @xmath39 , then @xmath76 is simply the stieltjes transform of marenko - pastur s distribution @xcite with parameter @xmath88 .      as in @xcite , we first study the clt for the trace of the resolvent .",
    "let @xmath89 be the second moment of the random variable @xmath90 and @xmath91 its fourth cumulant : @xmath92 if the entries are real or complex standard gaussian , then @xmath93 or 0 and @xmath94 .",
    "otherwise the fourth cumulant is a priori no longer equal to zero .",
    "this induces extra - terms in the computation of the limiting variance , mainly due to the following @xmath95-dependent identity : @xmath96 where @xmath97 stands for the first column ( of dimension @xmath85 ) of matrix @xmath3 and where @xmath98 are deterministic @xmath14 matrices . as a consequence",
    ", there will be three terms in the limiting covariance of the quantity ; one will raise from the first term of the right hand side ( r.h.s . ) of , a second one will be proportional to @xmath99 , and a third one to @xmath91 . in order to describe these terms , let : @xmath100 the quantity @xmath101 is the deterministic equivalent associated to @xmath102 .",
    "denote by @xmath103 the transpose matrix of @xmath2 ( notice that since @xmath2 is hermitian , @xmath104 and we shall use this latter notation ) and by @xmath105 , the transpose matrix is not the entry - wise conjugate of @xmath86 , due to the presence of @xmath106 .",
    "] of @xmath86 : @xmath107 notice that the definition of @xmath108 in does not change if @xmath2 is replaced by @xmath109 since the spectrum of both matrices @xmath2 and @xmath109 is the same .",
    "we can now describe the limiting covariance of the trace of the resolvent : @xmath110 where @xmath111 is a term that converges to zero as @xmath20 and @xmath112 with @xmath113 for alternative formulas for @xmath114 and @xmath115 , see remarks [ rem : altern - theta0 ] and [ rem : altern - theta2 ] .    at first sight",
    ", these formulas ( established in section [ sec : proof ] ) may seem complicated ; however , much information can be inferred from them .",
    "this term is familiar as it already appears in bai and silverstein s clt @xcite .",
    "notice that the quantities @xmath116 and @xmath117 only depend on the spectrum of matrix @xmath2 .",
    "hence , under the additional assumption that : @xmath118 { } c\\in ( 0,\\infty ) \\quad \\textrm{and}\\quad f^{r_n } \\xrightarrow[n , n\\rightarrow \\infty]{\\mathcal d } f^{\\bf r}\\ , \\ ] ] where @xmath119 denotes the empirical distribution of @xmath2 s eigenvalues and @xmath120 is a probability measure , it can easily be proved that @xmath121 { } \\theta_0(z_1,z_2 ) =   \\left\\ { \\frac { \\tilde t'(z_1 )   \\tilde t'(z_2)}{(\\tilde t(z_1 ) - \\tilde t(z_2))^2 }   - \\frac 1{(z_1 - z_2)^2}\\right\\ } \\ , \\ ] ] where @xmath122 are the limits of @xmath123 under .",
    "the interesting phenomenon lies in the fact that this term involves products of matrices @xmath125 and its conjugate @xmath126 .",
    "these matrices have the same spectrum but conjugate eigenvectors . if @xmath2 is not real , the convergence of @xmath124 is not granted , even under .",
    "if however @xmath2 and @xmath3 s entries are real , i.e. @xmath93 , then it can be easily proved that @xmath127 hence the factor 2 in @xcite between the complex and the real covariance .",
    "this term involves quantities of the type @xmath128 which not only depend on the spectrum of matrix @xmath2 but also on its eigenvectors . as a consequence , the convergence of such terms does not follow from an assumption such as , except in some particular cases ( for instance if @xmath2 is diagonal ) and any assumption which enforces the convergence of such terms ( as for instance in ( * ? ? ? * theorem 1.4 ) ) implicitely implies an asymptotic joint behaviour between @xmath2 s eigenvectors and eigenvalues . we shall adopt a different point of view here and will not assume the convergence of these quantities .",
    "recall that @xmath108 is the stieltjes transform of a probability measure @xmath129 : @xmath130 with support @xmath131 included in a compact set .",
    "the purpose of this article is to describe the fluctuations of the linear statistics @xmath132 as @xmath20 .    for a smooth enough function",
    "@xmath6 of class @xmath42 with bounded support , one can rely on helffer - sjstrand s formula and write : @xmath133 where @xmath46 is defined in and the last equality follows from the fact that @xmath134 based on , we shall first study the fluctuations of : @xmath135 for @xmath136 .",
    "the first difference in the r.h.s . will yield the fluctuations with a covariance @xmath137 described in while the second difference , deterministic , will yield the bias : @xmath138 where @xmath139 the previous discussion on the terms @xmath124 and @xmath115 also applies to the terms @xmath140 and @xmath141 ( whose expressions are established in section [ sec : proof ] ) which are likely not to converge for similar reasons .      a priori , the mean @xmath142 and covariance @xmath143 of @xmath144 do not converge .",
    "hence , we shall express the gaussian fluctuations of the linear statistics in the following way : we first prove the existence of a family @xmath145 of tight gaussian processes with mean and covariance : @xmath146 we then express the fluctuations of the centralized trace as @xmath147 { } 0 \\ .\\ ] ] with @xmath35 the lvy - prohorov distance between @xmath148 and @xmath149 probability measures over borel sets of @xmath150 or @xmath151 : @xmath152 where @xmath153 is an @xmath154-blow up of @xmath23 ( cf .",
    "* section 11.3 ) for more details ) .",
    "if @xmath155 is a random variable and @xmath156 its distribution , denote ( with a slight abuse of notation ) by @xmath157 .",
    "similarly , we will express the fluctuations of @xmath29 as : @xmath158 { } 0 \\ , \\ ] ] where @xmath159 is a well - identified gaussian random variable .      as we need to cope with a sequence of gaussian processes @xmath160 instead of a single one",
    ", it will be necessary to establish various properties uniform in @xmath161 such as :    1 .   the tightness of the sequence @xmath160 ( cf .",
    "section [ sec : gaussian - process ] ) ; 2 .",
    "a uniform bound over the variances of @xmath162 ( cf .",
    "section [ proof : non - analytic - i ] ) , needed to extend the clt to non - analytic functionals ; 3 .   a uniform bound over the biases of @xmath162 ( cf .",
    "section [ sec : mm - bias ] ) , needed to compute the bias for non - analytic functionals .",
    "a direct approach based on the mere definition of process @xmath163 s parameters seems difficult , mainly due to the definitions of @xmath143 and @xmath142 which rely on quantities ( @xmath76 and @xmath116 ) defined as solutions of fixed - point equations . since the previous properties will be established for the processes @xmath164 anyway , the idea is to transfer them to @xmath163 by means of the following matrix meta - model :    let @xmath9 , @xmath10 and @xmath2 be fixed and consider the @xmath165 matrix @xmath166 matrix @xmath167 is a block matrix with @xmath14 diagonal blocks equal to @xmath2 , and zero blocks elsewhere ; for all @xmath168 the spectral norm of @xmath167 is equal to the spectral norm of @xmath2 ( which is fixed ) .",
    "in particular the sequence @xmath169 with @xmath37 fixed satisfies assumption ( a-[ass : r ] ) with @xmath169 instead of @xmath64 .",
    "consider now the random matrix model : @xmath170 where @xmath171 is a @xmath172 matrix with i.i.d .",
    "random entries with the same distribution as the @xmath90 s and satisfying ( a-[ass : x ] ) .",
    "the interest of introducing matrix @xmath173 lies in the fact that matrices @xmath174 and @xmath17 have loosely speaking the same deterministic equivalents .",
    "denote by @xmath76 , @xmath86 and @xmath116 the deterministic equivalents of @xmath17 as defined in , and , and by @xmath175 , @xmath176 and @xmath177 their counterparts for the model @xmath174 .",
    "taking advantage of the block structure of @xmath167 , a straightforward computation yields ( @xmath37 fixed ) : @xmath178 similarly , denote by @xmath179 and @xmath180 the quantities given by formulas and when replacing @xmath9 , @xmath76 , @xmath86 and @xmath116 by @xmath181 , @xmath175 , @xmath176 and @xmath177 .",
    "straightforward computation yields : @xmath182 an interesting feature of this meta - model lies in the fact that all the quantities associated to @xmath183 converge as @xmath184 to the deterministic equivalents @xmath76 , @xmath116 , etc . as a consequence",
    ", one can easily transfer all the estimates obtained for @xmath185 to the process @xmath160 .",
    "if @xmath23 is a @xmath14 matrix with real eigenvalues , denote by @xmath186 the empirical distribution of the eigenvalues ( @xmath187 ) of @xmath23 , that is : @xmath188    recall the definitions of @xmath87 , @xmath76 , @xmath86 and @xmath116 ( cf .",
    ", , and ) .",
    "the following relations hold true ( see for instance @xcite ) : @xmath189    recall the definition of @xmath129 in and let similarly @xmath190 be the probability distribution associated to @xmath116 .",
    "the central object of study is the signed measure : @xmath191and its stieltjes transform @xmath192    denote by @xmath193 any random variable which converges to zero in probability .      in this section ,",
    "we closely follow bai and silverstein @xcite .",
    "we recall the framework developed there and introduce some additional notations .",
    "consider a sequence of positive numbers @xmath194 which satisfies : @xmath195 as @xmath20 .",
    "let @xmath196 where @xmath197 is a @xmath0 matrix having @xmath198th entry @xmath199 .",
    "this truncation step yields : @xmath200 { } 0\\ ] ] from which we deduce @xmath201{\\mathcal p } 0\\ , \\ ] ] where @xmath202{\\mathcal p}$ ] stands for the convergence in probability .",
    "define @xmath203 where @xmath204 is a @xmath0 matrix having @xmath198th entry @xmath205 , where @xmath206 .",
    "using the fact that @xmath207 is lipschitz with lipschitz constant @xmath208 , we obtain @xmath209{(a ) } 0\\ , \\ ] ] where @xmath210 , @xmath211 and @xmath212 follows from similar arguments as in ( * ? ? ?",
    "* section 9.7.1 ) .",
    "hence @xmath213{\\mathcal p } 0\\ , \\ ] ]    combining and , we obtain @xmath214{\\mathcal p } 0\\ .\\ ] ] moreover , the moments are asymptotically not affected by these different steps : @xmath215 { } 0\\ .\\ ] ] note in particular that the fourth cumulant of @xmath216 converges to that of @xmath90 .",
    "hence , it is sufficient to consider variables truncated at @xmath217 , centralized and renormalized .",
    "this will be assumed in the sequel ( we shall simply write @xmath90 and all related quantities with @xmath90 s truncated , centralized , renormalized with no superscript any more )",
    ".      we extend below bai and silverstein s master lemma ( * ? ? ?",
    "* lemma 1.1 ) .",
    "let @xmath23 be such that @xmath218 denote by @xmath219 , @xmath220 and @xmath221 the domains : @xmath222+{\\boldsymbol{i}}[0,1]\\ , \\nonumber \\\\",
    "& d^+&= [ 0,a]+{\\boldsymbol{i}}(0,1]\\ , \\nonumber\\\\ & d_{\\varepsilon}&= [ 0,a ] + { \\boldsymbol{i}}[\\varepsilon,1]\\quad ( \\varepsilon>0)\\ .\\label{def : sets - d}\\end{aligned}\\ ] ]    [ lemma : main ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true , then    1 .",
    "the process @xmath223 as defined in forms a tight sequence on @xmath221 , more precisely : @xmath224 2 .",
    "there exists a sequence @xmath225 of two - dimensional gaussian processes with mean @xmath226 where @xmath227 and @xmath228 are defined in and , and covariance : @xmath229 and @xmath230 with @xmath231 , and where @xmath114 , @xmath124 and @xmath115 are defined in , - .",
    "moreover @xmath232 is tight .",
    "+ 3 .   for any continuous functional @xmath233 from @xmath234 to @xmath235 , @xmath236 { } 0\\ ] ]    1 .",
    "the tightness of the process @xmath237 immediately follows from bai and silverstein s lemma as this result has been proved in ( * ? ? ?",
    "* lemma 1.1 ) under assumption ( a-[ass : x ] ) with no extra conditions on the moments of the entries .",
    "differences between theorem [ lemma : main ] and ( * ? ? ?",
    "* lemma 1.1 ) appear in the bias and in the covariance where there are respectively two terms instead of one and three terms instead of one in ( * ? ? ?",
    "* lemma 1.1 ) .",
    "3 .   since the extra terms",
    "do not converge , we need to consider a sequence of gaussian processes instead of a single gaussian process as in ( * ? ? ?",
    "* lemma 1.1 ) .",
    "4 .   in order to prove that the sequence of gaussian processes is tight , we introduce a meta - matrix model to transfer the tightness of @xmath237 to @xmath238",
    "( see for instance section [ sec : meta - matrix ] ) .",
    "5 .   following bai and silverstein @xcite",
    ", it is relatively straightforward with the help of cauchy s formula to describe the fluctuations of @xmath29 for @xmath6 analytic with theorem [ lemma : main ] at hand .",
    "we skip this step since we will directly extend the clt to non - analytic functions @xmath6 in section [ sec : non - analytic ] .",
    "[ rem : altern - theta0 ] a closer look to bai and silverstein s proof ( * ? ? ? * sec.2",
    "p.578 ) yields the following alternative expression for the term @xmath114 : @xmath239 with @xmath240 such an expression will be helpful in section [ proof : non - analytic - i ] . as an interesting consequence : in the case where @xmath2 and @xmath3 have real entries ( in particular @xmath241 ) then @xmath242 and @xmath243 .    [",
    "rem : altern - theta2 ] a closer look to the proof below ( see for instance ) yields the following formula for @xmath115 which will be of help in the sequel : @xmath244_{ii } \\ , \\frac { \\partial}{\\partial z_2 } \\left[z_2    t_n(z_2)\\right]_{ii}\\ .\\ ] ]",
    "proof of theorem [ lemma : main ] is postponed to section [ sec : proof ] .",
    "the end of the section is devoted to various specializations of theorem [ lemma : main ] in the case where matrix @xmath2 is diagonal . in this case , the results are simpler to express and comparisons can easily be made with related works .",
    "this case partially falls into the framework developed in pan and zhou @xcite ( note that the case @xmath245 and @xmath246 is not handled there ) .",
    "matrix @xmath2 being nonnegative definite hermitian , its entries are real positive if @xmath2 is assumed to be diagonal . in this case ,",
    "matrix @xmath86 is diagonal as well ( cf . ) , @xmath247 and simplifications occur for the following terms : @xmath248 as one may notice , all the terms in the variance and the bias now only depend on the spectrum of @xmath2 .",
    "hence , the following convergence holds true under the extra assumption : @xmath249 { }   & { \\mathcal a}(z_1,z_2 ) = c\\ ,   \\tilde t(z_1 ) \\tilde t(z_2 ) \\int \\frac{\\lambda^2f^{\\bf r}(d\\lambda)}{(1+\\lambda \\tilde t(z_1 ) ) ( 1+\\lambda \\tilde t(z_2))}\\ , \\\\",
    "\\theta_{1,n}(z_1,z_2 ) & \\xrightarrow[n , n\\rightarrow \\infty ] { } & \\theta _",
    "1(z_1,z_2 ) = \\frac \\partial { \\partial z_2 } \\left\\ { \\frac{\\partial { \\mathcal a}(z_1,z_2 ) } { \\partial   z_1 } \\frac1{1-|{\\mathcal v}|^2{\\mathcal a}(z_1,z_2 ) } \\right\\}\\ , \\\\",
    "\\theta_{2,n}(z_1,z_2 ) & \\xrightarrow[n , n\\rightarrow \\infty ] { } & \\theta _",
    "2(z_1,z_2 ) = c\\ , \\tilde t'(z_1 ) \\tilde t'(z_2 ) \\int \\frac{\\lambda^2f^{\\bf r}(d\\lambda)}{(1+\\lambda \\tilde t(z_1))^2 ( 1+\\lambda \\tilde t(z_2))^2}\\ , \\\\ { \\mathcal b}_{1,n}(z ) & \\xrightarrow[n , n\\rightarrow \\infty ] { } & { \\mathcal b}_1(z)= -\\frac{cz^3 \\tilde t^3(z ) } { ( 1-{\\mathcal a}(z , z))(1-{|\\mathcal v|^2}{\\mathcal a}(z , z ) ) }   { \\int \\frac{\\lambda^2f^{\\bf r}(d\\lambda)}{(1+\\lambda \\tilde t(z))^3 } }   \\ , \\\\ { \\mathcal b}_{2,n}(z ) & \\xrightarrow[n , n\\rightarrow \\infty ] { } & { \\mathcal b}_2(z)= -\\frac{cz^3 \\tilde t^3(z ) } { 1-{\\mathcal a}(z , z ) }   { \\int \\frac{\\lambda^2f^{\\bf r}(d\\lambda)}{(1+\\lambda \\tilde t(z))^3 } }   \\ .\\\\\\end{aligned}\\ ] ] where @xmath122 are the limits of @xmath123 under .",
    "this can be packaged into the following result :    [ coro : diag ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true .",
    "assume moreover that @xmath2 is diagonal and that the convergence assumption holds true .",
    "then @xmath250 converges weakly on @xmath221 ( defined in ) to a two - dimensional gaussian process @xmath251 satisfying : @xmath252 and @xmath253 and @xmath254 are defined above and covariance @xmath255 and @xmath256 defined in and @xmath257 defined above .      in this section , we assume that @xmath39 .      in this case , the quantity @xmath258 takes the simplified form @xmath259 where we denote @xmath260 .",
    "straightforward computations yield : @xmath261 and @xmath262 this formula is in accordance with ( * ? ? ?",
    "* formula ( 2.2 ) ) ( use ( * ? ? ?",
    "* ( 3.4 ) ) to equate both ) .",
    "if needed , one can then use the explicit expression of the stieltjes transform of marenko - pastur distribution ( cf . also proposition [ prop : new - variance - formula ] below ) .",
    "in order to lift the clt from the trace of the resolvent to a smooth function @xmath6 , the key ingredient is helffer - sjstrand s formula .",
    "let @xmath263 where @xmath129 in @xmath212 is defined in .",
    "we describe the fluctuations of @xmath264 for non - analytic functions @xmath6 in section [ sec : fluctuations - non - analytic ] and study the bias @xmath265 in section [ sec : bias - non - analytic ] .",
    "denote by @xmath266 ( resp .",
    "@xmath267 ) the set of infinitely differentiable ( resp .",
    "@xmath268 ) functions from @xmath269 to @xmath270 with compact support ; by @xmath271 the set of functions from @xmath272 to @xmath270 @xmath273 times differentiable with respect to the first coordinate and @xmath274 times with respect to the second one . as usual ,",
    "if the subscript @xmath275 is removed in the sets above , then the corresponding functions may no longer have a compact support .",
    "[ th : non - analytic ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true .",
    "let @xmath276 be in @xmath277 .",
    "consider the centered gaussian random vector @xmath278 with covariance @xmath279 for @xmath280 , where @xmath281 and @xmath282 are defined as in , and where @xmath143 is defined in ; let @xmath283 then , the sequence of @xmath284-valued random vectors @xmath285 is tight and the following convergence holds true : @xmath286 { } 0\\ , \\]]or equivalently for every continuous bounded function @xmath287 , @xmath288 { } 0 \\ .\\ ] ]    proof of theorem [ th : non - analytic ] is postponed to section [ sec : proof - non - analytic - i ] .",
    "we provide hereafter some information on the covariance operator .",
    "let @xmath289 and @xmath290 ; denote by @xmath291 , @xmath292 and let @xmath293 be defined as @xmath294 where @xmath45 is smooth , compactly supported with value 1 in a neighbourhood of the origin .",
    "denote by @xmath295 and @xmath296 .",
    "[ prop : identification - distribution ] for every @xmath297 , denote by @xmath298 then @xmath299 is a distribution ( in the sense of l. schwartz ) on @xmath300 .",
    "moreover @xmath301 admits the following boundary value representation : @xmath302 notice that for every @xmath303 then @xmath304 ( where @xmath305 ) and @xmath306    proof of proposition [ prop : identification - distribution ] is postponed to section [ proof : identification - distribution ] .    by relying on tillmann s results @xcite",
    ", one may prove that the support of @xmath301 ( as a distribution ) in included in @xmath307 .",
    "we provide a more direct approach in a slightly simpler case in section [ sec : explicit - formulas ] .",
    "we provide here more explicit formulas for the variance than those given in theorem [ th : non - analytic ] and proposition [ prop : identification - distribution ] ; we also verify that these formulas are in agreement with other formulas available in the literature .",
    "recall that by ( * ? ? ?",
    "* theorem 1.1 ) , the limit @xmath308 denoted by @xmath309 exists for all @xmath310 , @xmath311 ; the same holds true for @xmath76 .",
    "[ prop : new - variance - formula ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true and let @xmath303 ; assume moreover for simplicity that @xmath312 is either equal to 0 or 1 and that @xmath2 has real entries .",
    "then the covariance of @xmath313 in theorem [ th : non - analytic ] writes @xmath314    proof for proposition [ prop : new - variance - formula ] is postponed to section [ proof : new - variance - formula ] .",
    "notice that the first term in the r.h.s .",
    "matches with the expression provided in ( * ? ? ?",
    "* eq . ( 1.17 ) ) ( see also ( * ? ? ? * eq . ( 9.8.8 ) ) ) .",
    "concerning the cumulant term , we shall compare it with the explicit formula provided in @xcite ( see also @xcite ) in the case where @xmath315 . recall that in the context of marenko - pastur s theorem where @xmath39 , we have @xmath316 $ ] where @xmath317 , @xmath318 and @xmath319",
    ". we will prove hereafter that : @xmath320 notice that the l.h.s . of the equation above is the cumulant term as provided in if @xmath39 while the r.h.s .",
    "is the cumulant term as provided the quantities in @xcite and use the correspondance @xmath321 , @xmath322 and @xmath323 to check that the r.h.s .",
    "of equates the formula provided in @xcite . ] in @xcite .    in the case where @xmath39 , the stieltjes transform of marenko - pastur s distribution has an explicit form given by",
    "( see for instance ( * ? ? ?",
    "* chapter 7 ) ) : @xmath324 where the branch of the square root is fixed by its asymptotics : @xmath325 as @xmath326 .",
    "in particular , if @xmath327 $ ] then @xmath328 hence @xmath329 it remains to perform an integration by parts to get @xmath330 which yields .    as a corollary of proposition [ prop : new - variance - formula ]",
    ", we obtain the following extension of theorem [ th : non - analytic ] .    recall that @xmath131 is the support of the probability measure @xmath129 . due to assumption ( a-[ass : r ] )",
    ", it is clear that @xmath331\\ , \\ ] ] uniformily in @xmath10 .",
    "denote by @xmath332 a function whose value is 1 on a @xmath333-neighborhood @xmath334 of @xmath335 .",
    "[ coro : unbounded - f ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true and let @xmath336 with @xmath337 ; assume moreover that @xmath312 is either equal to 0 or 1 and that @xmath2 has real entries .",
    "let @xmath338 be as above .",
    "then - remain true with @xmath339 replaced by @xmath340 and with the gaussian random vector @xmath341 as in theorem [ th : non - analytic ] .",
    "+    proof of corollary [ coro : unbounded - f ] is postponed to section [ sec : proof - coro - unbounded - f ] .",
    "[ th : non - analytic - bias ] assume ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true and let @xmath342 .",
    "denote by @xmath343 where @xmath344 is defined in .",
    "then @xmath345 { } 0\\ .\\ ] ]    proof of theorem [ th : non - analytic - bias ] is postponed to section [ proof : non - analytic - ii ] .",
    "[ rem:18 ] a quick sketch of the proof of theorem [ th : non - analytic - bias ] provides some hints .",
    "let @xmath6 have a bounded support . by gaussian interpolation ( whose cost is @xmath346 ) , we only need to prove : @xmath347 where @xmath348 is the counterpart of @xmath5 with @xmath349 i.i.d .",
    "the proof of the latter is based on helffer - sjstrand s formula : @xmath350 where @xmath351 , and on the following estimate , stated in proposition [ prop : bias - hard ] : @xmath352 where @xmath353 denotes a polynomial with degree @xmath354 and positive coefficients . in view of proposition",
    "[ prop : compensation ] , @xmath6 needs to be of class @xmath60 .",
    "if one can improve estimate and decrease the powers of @xmath355 , then one will automatically lower the regularity assumption over @xmath6 .",
    "notice that in the case of the gaussian unitary ensemble , counterpart of features @xmath356 on its r.h.s .",
    "* lemma 6.1 ) ) hence the needed regularity is @xmath346 in this case .",
    "[ prop : bias - as - distribution ] let @xmath357 be defined as in , then @xmath358 is a distribution ( in the sense of l. schwartz ) on @xmath359 and @xmath360 moreover , the singular points of @xmath361 are included in @xmath131 and so is the support of @xmath358 ( as a distribution ) . in particular , one can extend @xmath358 to @xmath362 by @xmath363 where @xmath364 is the extension to @xmath362 and @xmath365 has value 1 on @xmath131 .",
    "proof of proposition [ prop : bias - as - distribution ] is postponed to section [ proof : prop - bias - distribution ] .",
    "[ coro : bias - unbounded ] assume ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true .",
    "let @xmath366 and @xmath367 be a function whose value is 1 on a neighborhood of @xmath335 , then the following convergence holds true : @xmath368 { } 0\\ .\\ ] ]    the proof is straighforward and is therefore omitted .",
    "recall that @xmath369",
    ". it will be convenient to decompose @xmath370 as : @xmath371 denote by @xmath372 the @xmath85 vector @xmath373 and by @xmath374 the conditional expectation with respect to @xmath375 , the @xmath376-field generated by @xmath377 ; by convention , @xmath378 .",
    "we split theorem [ lemma : main ] into intermediate results .",
    "recall the definitions of @xmath379 and @xmath219 in .",
    "let @xmath380    [ prop : convergence - martingale ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true ; let @xmath381 , then : @xmath382 where the @xmath383 s are martingale increments with respect to the @xmath376-field @xmath384 and @xmath385{\\mathcal p } & 0\\ , \\label{eq : conv - martingale}\\\\ \\sum_{j=1}^n \\mathbb{e}_{j-1 } z_j^n(z_1)\\overline{z_j^n(z_2 ) } - \\theta_n(z_1,\\overline{z_2 } ) & \\xrightarrow[n , n\\rightarrow \\infty]{\\mathcal p } & 0\\ , \\label{eq : conv - martingale - conjugate}\\end{aligned}\\ ] ] where @xmath143 is defined in .",
    "moreover , @xmath386{}0\\ , \\ ] ] where @xmath142 is defined in .",
    "[ prop : gaussian - process ] there exists a sequence @xmath387 of two - dimensional gaussian processes with mean @xmath388 and covariance @xmath389 moreover , @xmath390 is tight .",
    "the fact that @xmath391 is a tight sequence has already been established in @xcite ( regardless of the assumption @xmath94 and @xmath392 ) . in order to proceed ,",
    "we shall heavily rely on the proof of ( * ? ? ?",
    "* lemma 1.1 ) which is the crux of bai and silverstein s paper . in section [ sec : review ] we recall the main steps of bai and silverstein s computations of the variance / covariance . in sections [ section : variance - vartheta ] and [ sec : diagonal - terms - variance ] , we compute the extra terms in the limiting variance . in section [ sec : bias ] , we compute the limiting bias ( some details are postponed to appendix [ app : bias ] ) . in section",
    "[ sec : proof - lemma ] , we finally conclude the proof of theorem [ lemma : main ] and address various subtleties which appear due to the existence of a sequence of gaussian limiting processes .    in the sequel , we shall drop subscript @xmath10 and write @xmath149 and @xmath393 instead of @xmath87 and @xmath2 .",
    "denote by @xmath394 the resolvent of matrix @xmath395 , i.e. @xmath396 the following quantities will be needed : @xmath397      we briefly review in this section the main steps related to the computation of the variance / covariance as presented in @xcite .",
    "these standard steps will finally lead to eq . which will be the starting point of the computations associated to the @xmath99- and @xmath91-terms of the variance .",
    "let @xmath398 .",
    "@xmath399 denote by @xmath400 hence , @xmath401 the r.h.s",
    ". appears as a sum of martingale increments .",
    "such a decomposition is important since it will enable us to rely on powerful clts for martingales ( see ( * ? ? ?",
    "* theorem 35.12 ) , and the variations below in lemmas [ lemma : variations - martingales ] and [ lemma : martingales - multidim ] ) .",
    "these clts rely on the study of the terms : @xmath402 notice that since @xmath403 , we have @xmath404 .",
    "since the set @xmath405 is stable by complex conjugation , it is sufficient to study the limiting behavior of : @xmath406 in order to prove and .",
    "now , @xmath407 \\right\\}\\ .\\ ] ] following the same arguments as in @xcite , one can prove that it is sufficient to study the convergence in probability of @xmath408\\ .\\ ] ] moreover , @xmath409}\\nonumber \\\\ & = & \\sum_{j=1}^n b_n(z_1 ) b_n(z_2 ) { \\mathbb{e}}_{j-1 } \\left [ { \\mathbb{e}}_j   \\varepsilon_j(z_1 )   { \\mathbb{e}}_j    \\varepsilon_j(z_2 )   \\right ] + o_p(1)\\ , \\nonumber\\\\ & = & \\sum_{j=1}^n z_1\\tilde t_n(z_1 ) z_2 \\tilde t_n(z_2 ) { \\mathbb{e}}_{j-1 } \\left [ { \\mathbb{e}}_j   \\varepsilon_j(z_1 )   { \\mathbb{e}}_j    \\varepsilon_j(z_2 )   \\right ] + o_p(1)\\ .\\label{eq : decomposition-1}\\end{aligned}\\ ] ]    hence , it is finally sufficient to study the limiting behaviour ( in terms of convergence in probability ) of the quantity : @xmath410    denote by @xmath411 the transpose matrix of @xmath23 . applying yields : @xmath412 the limiting behaviour of the first term of the r.h.s . has been completely described in @xcite where it has been shown that : @xmath413 with @xmath414 defined in .",
    "we shall focus on the second and third terms .",
    "notice first that the value of @xmath76 and @xmath116 is the same whether @xmath393 is replaced by @xmath415 in and since @xmath76 and @xmath116 only depend on the spectrum of @xmath393 ( which is the same as the spectrum of @xmath415 ) .",
    "notice also that @xmath416 , hence : @xmath417 recall the definition of @xmath418 given by .",
    "taking into account the fact that for a deterministic matrix @xmath23 , @xmath419 and following closely ( * ? ? ?",
    "* section 2 ) , it is a matter of bookkeeping in the bias are outlined in appendix [ app : bias ] . ] to establish that : @xmath420 where @xmath421 finally ,",
    "@xmath422      we now handle the term proportional to @xmath91 in : @xmath423 the objective is to prove that @xmath424 can be replaced by @xmath79 in the formula above , which boils down to prove a convergence of quadratic forms of the type .",
    "such a convergence has already been established in @xcite for large covariance matrices based on a non - centered matrix model with separable variance profile .    by interpolating between the quantity and its counterpart when the entries are complex i.i.d .",
    "standard gaussian , we will be able to rely on the results in @xcite by using the unitary invariance of a gaussian matrix ( see proposition [ prop : approx - gaussienne ] and eq .",
    "below ) .",
    "let @xmath425 be the distance between the point @xmath426 and the real nonnegative axis @xmath427 : @xmath428    [ prop : variance - forme - quadra ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true and let @xmath429 be a deterministic @xmath85 vector , then : @xmath430 where @xmath431 and @xmath432 are fixed polynomials with coefficients independent from @xmath433 and @xmath83 .",
    "proof of proposition [ prop : variance - forme - quadra ] is an easy adaptation is centered here ; notice also the fact that @xmath393 not being diagonal has virtually no impact .",
    "] of ( * ? ?",
    "2.7 ) and is therefore omitted .",
    "denote by @xmath434 a @xmath0 matrix whose entries are independent standard complex circular gaussian r.v .",
    "( i.e. @xmath435 where @xmath436 are independent @xmath437 random variables ) ; denote accordingly @xmath438 , @xmath439 and @xmath440 we now drop subscripts @xmath9 and @xmath10 .",
    "[ prop : approx - gaussienne ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true and let , then : @xmath441 where @xmath429 is a deterministic @xmath85 vector and @xmath431 and @xmath432 are fixed polynomials with coefficients independent from @xmath433 .",
    "moreover , @xmath442 where @xmath443 is independent from @xmath433 .",
    "notice that is of direct use in this section while will be used in section [ proof : non - analytic - ii ] .",
    "we first prove .",
    "consider the resolvent @xmath444 defined for @xmath445 .",
    "denote by @xmath446 and by @xmath447 and write @xmath448 we shall evaluate the difference @xmath449 , the other ones being handled similarly .",
    "denote by @xmath450 , then : @xmath451    dropping the subscript @xmath246 to lighten the notations , we get : @xmath452    the second term in the r.h.s .",
    "above is zero ( simply compute the conditional expectation with respect to @xmath453 ) , the first and third term are of a similar nature ; we therefore only estimate the third one denoted by @xmath454 below .",
    "@xmath455    where the last inequality follows from cauchy - schwarz inequality plus the fact that both @xmath456 and @xmath457 are stieltjes transforms and hence upper - bounded in modulus by @xmath355 .",
    "a control for the first expectation in the above inequality directly follows from classical estimates ( see for instance ( * ? ? ? * lemma b.26 ) ) : @xmath458 where @xmath443 is a constant whose value may change from line to line but which remains independent from @xmath37 .",
    "the second expectation can be handled in the following way : @xmath459 it now remains to gather and to get : @xmath460 finally , the result follows by upper - bounding each term of the sum in and is proved .",
    "we now establish . using a similar decomposition as in ,",
    "we get : @xmath461 we focus on the first term , use and follow a similar notational convention by dropping subscript 1 .",
    "@xmath462 denote by @xmath463 with these notations at hand , we have : @xmath464 and @xmath465 notice that @xmath466 . by cauchy - schwarz inequality ,",
    "proof of prop .",
    "[ prop : approx - gaussienne ] will be completed as long as we establish the following estimates : @xmath467 estimates - can be established as . in order to establish ,",
    "we compute exactly the expectation @xmath468 writing @xmath469 which splits into 4 terms : @xmath470 using the independence of @xmath471 , @xmath472 and @xmath473 together with formula , lengthy but straightforward computations yield the estimate @xmath474 similar computations yield @xmath475 and - are established .",
    "estimate is established and proof of prop .",
    "[ prop : approx - gaussienne ] is completed .",
    "[ coro : cumulant ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true , then the following convergence holds true : @xmath476{\\mathcal p } 0\\ .\\end{gathered}\\ ] ]    we first transform the sum to be calculated : @xmath477 using proposition [ prop : variance - forme - quadra ] enables us to replace the conditional expectation @xmath478 by the true expectation in every term @xmath479 . now using the fact that @xmath480 and computations similar to those made in proposition [ prop : approx - gaussienne ]",
    ", one can replace @xmath481 by @xmath482 .",
    "finally , by proposition [ prop : approx - gaussienne ] , @xmath482 can be replaced by @xmath483 .",
    "we are led to study the sum : @xmath484 denote by @xmath485 the spectral decomposition of covariance matrix @xmath2 . since matrix @xmath486 is unitary , then @xmath487 has i.i.d .",
    "standard complex gaussian entries and the resolvent writes : @xmath488 denote by @xmath489 the matrix @xmath490 where @xmath108 is defined in ; notice that the definition of @xmath108 only depends on the spectrum of @xmath2 ( or equivalently @xmath491 ) ; notice also that @xmath492 it has been proved in ( * ? ? ?",
    "* theorem 1.1 ) that for every deterministic @xmath85 vector @xmath493 : @xmath494 hence , @xmath495 in particular , let @xmath496 be the i@xmath497 coordinate vector , then @xmath498 which completes the proof .    combining the result in corollary [ coro : cumulant ] together with and",
    ", we have proved so far that : @xmath499 taking into account and the matrix identity @xmath500 , we obtain : @xmath501_{ii } \\ , \\frac { \\partial}{\\partial z_2 } \\left[z_2    t_n(z_2)\\right]_{ii } + o_p(1 ) \\nonumber \\ , \\\\ & = &   \\frac { z_1 ^ 2 z_2 ^ 2\\ , \\tilde t'_n(z_1 ) \\tilde",
    "t'_n(z_2)}n \\sum_{i=1}^n \\left ( r_n^{1/2 } t^2_n(z_1 ) r_n^{1/2}\\right)_{ii}\\left ( r_n^{1/2 } t^2_n(z_2 ) r_n^{1/2}\\right)_{ii } + o_p(1)\\ , \\nonumber \\\\ & = & \\theta_{2,n}(z_1,z_2 ) + o_p(1)\\ ,   \\label{alternative - formula - cov2-bis}\\end{aligned}\\ ] ] where @xmath115 is given by formula .    now gathering , and , we have established so far : @xmath502 which is the first part of proposition [ prop : convergence - martingale ] .      in this section ,",
    "we are interested in the computation of @xmath503 . as @xmath504 we immediately obtain @xmath505 . combining and yields : @xmath506 following bai and silverstein (",
    "* section 4 ) , we introduce the quantity @xmath507 defined as : @xmath508 hence @xmath509 substracting to finally yields : @xmath510^{-1}\\ , \\ ] ] which is the counterpart of ( * ? ? ?",
    "* eq . ( 4.12 ) ) .",
    "the same arguments as in @xcite now yields : @xmath511^{-1 } + o(1)\\ .\\ ] ] it remains to study the behaviour of @xmath512 . following ( * ? ? ?",
    "* eq . ( 4.10 ) ) , we obtain : @xmath513 + o(1)\\ .\\end{gathered}\\ ] ]    applying to the right term to the r.h.s .",
    "of the previous equation ( recall that @xmath514 ) , we obtain : @xmath515 the first term of the r.h.s . has been fully analyzed in @xcite in the case where @xmath2 and @xmath3 are real matrices .",
    "we adapt these computations to the general case and outline in appendix [ app : bias ] the proof of the identity:@xmath516 where @xmath418 is defined in .",
    "the term proportional to the cumulant in can be analyzed as in section [ sec : diagonal - terms - variance ] , and one can prove that : @xmath517 we now plug and into to conclude .",
    "@xmath518 proof of proposition [ prop : convergence - martingale ] is completed .",
    "recall the meta - model introduced in section [ sec : meta - model ] .",
    "let @xmath519 applying proposition [ prop : convergence - martingale ] to the matrix model @xmath174 yields : @xmath520 where the @xmath521 s are martingale increments and @xmath522{\\mathcal p } &   \\theta_n(z_1,z_2)\\ , \\\\",
    "m_{n , m}^{\\ , 2 } ( z )   & \\xrightarrow[n , n\\ \\textrm{fixed}\\ , , m \\rightarrow \\infty ] { } &   { \\mathcal b}_n(z)\\ .\\end{aligned}\\ ] ]    notice that there is a genuine limit in the previous convergence . applying the central limit theorem for martingales ( * ? ? ?",
    "* theorem 35.12 ) plus the tightness argument for @xmath523 provided by proposition [ prop : convergence - martingale ] immediately yields the fact that @xmath524 converges in distribution to a gaussian process @xmath525 with mean @xmath361 and covariance function @xmath137 .      in order to prove that the sequence of gaussian processes @xmath160 is tight",
    ", we shall prove , according to prohorov s theorem , that it is relatively compact in distribution .",
    "consider the set of matrices : @xmath526 where @xmath167 is defined in .",
    "since @xmath527 for all @xmath168 , we have @xmath528 by assumption ( a-[ass : r ] ) . hence , by proposition [ prop : convergence - martingale ] , the family @xmath529 is tight , hence relatively compact in distribution .",
    "as the distribution @xmath530 of the gaussian process @xmath163 is the limit ( in @xmath531 ) of the distribution @xmath532 of @xmath524 , @xmath530 belongs to the closure of @xmath533 , which is compact .",
    "finally , @xmath534 is included in a compact set , hence is relatively compact . in particular , the family of gaussian processes @xmath160 is tight .",
    "the two propositions below are minor variations of known results",
    ". they will be helpful to conclude the proof of theorem [ lemma : main ] .",
    "[ lemma : variations - martingales ] suppose that for each @xmath10 @xmath535 is a real martingale difference sequence with respect to the increasing @xmath376-field @xmath536 having second moments .",
    "assume moreover that @xmath537 is a sequence of nonnegative real numbers , uniformly bounded .",
    "if @xmath538{\\mathcal p } 0\\ , \\ ] ] and for each @xmath539 , @xmath540 { } 0\\ , \\ ] ] then , for every bounded continuous function @xmath541 @xmath542 { } 0\\ , \\ ] ] where @xmath543 is a centered gaussian random variable with variance @xmath544 .",
    "hereafter is the multidimensional and complex extension of lemma [ lemma : variations - martingales ] we shall rely on in the sequel :    [ lemma : martingales - multidim ] suppose that for each @xmath10 @xmath545 is a @xmath151-valued martingale difference sequence with respect to the increasing @xmath376-field @xmath546 having second moments .",
    "write : @xmath547    assume moreover that @xmath548 and @xmath549 are uniformly bounded sequences of complex numbers , for @xmath550 .",
    "if @xmath551{\\mathcal p } & 0\\ , \\label{eq : conv - martingale - variance}\\\\ \\sum_{j=1}^{r_n } { \\mathbb{e}}\\left ( y^k_{nj } y_{nj}^\\ell \\mid { \\mathcal g}_{n , j-1}\\right ) - \\tilde \\theta_n(k,\\ell ) & \\xrightarrow[n\\rightarrow \\infty]{\\mathcal p } & 0\\ , \\label{eq : conv - martingale - covariance}\\end{aligned}\\ ] ] and for each @xmath539 , @xmath552 { } 0\\ , \\ ] ] then , for every bounded continuous function @xmath553 @xmath542 { } 0\\ , \\ ] ] where @xmath543 is a @xmath151-valued centered gaussian random vector with parameters @xmath554    lemmas [ lemma : variations - martingales ] and [ lemma : martingales - multidim ] are variations around the central limit theorem for martingales ( see billingsley ( * ? ? ?",
    "* theorem 35.12 ) ) which enables us to prove ( in the real case ) : @xmath555 and lvy theorem for the weak convergence criterion via characteristic functions ( see kallenberg ( * ? ? ?",
    "* theorem 5.3 and theorem 5.5 ) ) which yields from the above convergence .",
    "details of the proof are omitted .",
    "[ lemma : tightness ] let @xmath443 be a compact set in @xmath235 ; let @xmath556 and @xmath557 be random elements in @xmath558 .",
    "assume that for all @xmath559 , for all @xmath560 , for all @xmath561 we have : @xmath562 { } 0\\ .\\ ] ] assume moreover that @xmath16 and @xmath563 are tight , then for every continuous and bounded functional @xmath564 , we have : @xmath565 { } 0\\ .\\ ] ]    lemma [ lemma : tightness ] can be proved as ( * ? ? ?",
    "* lemma 16.2 ) ; the proof is therefore omitted .",
    "we are now in position to conclude .    in order to apply lemma [ lemma : martingales - multidim ] ,",
    "it remains to check that @xmath143 as defined in is uniformly bounded for @xmath566 fixed but this is an easy byproduct of proposition [ prop : gaussian - process ] .",
    "proposition [ prop : convergence - martingale ] together with lemma [ lemma : martingales - multidim ] ( notice that condition can be proved as in @xcite ) yield the fact that for every @xmath567 and for every bounded continuous function @xmath568 : @xmath569 { } 0\\ , \\ ] ] where @xmath163 is well - defined by proposition [ prop : gaussian - process ] .",
    "now the tightness of @xmath570 and @xmath163 together with lemma [ lemma : tightness ] yield the last statement of theorem [ lemma : main ] .",
    "in this section , we will assume that the random variables @xmath26 are truncated , centered and normalized , following section [ sec : truncation ] .",
    "recall that @xmath571 $ ] uniformily in @xmath10 .",
    "denote by @xmath367 a function whose value is 1 on a @xmath333-neighborhood @xmath334 of @xmath335 .",
    "[ prop : reduction ]    1 .",
    "assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true ; let the random variables @xmath26 be truncated as in section [ sec : truncation ] , function @xmath572 be defined as above and @xmath573 be a continuous function . then @xmath574{a.s . } 0\\ .\\ ] ] 2 .",
    "let @xmath575 be a smooth function on @xmath576 with compact support and whose value is 1 on a @xmath333-neighborhood @xmath577 of @xmath131 ; then : @xmath578    proof of proposition [ prop : reduction ] is straightforward and is based on the fact that almost surely , @xmath579 a fact that can be found in @xcite for instance .",
    "details are left to the reader .",
    "the following proposition underlines how a sufficient regularity of function @xmath6 compensates the singularity in @xmath580 near the real axis .",
    "[ prop : compensation ] let @xmath581 be two probability measures on @xmath270 and @xmath582 and @xmath583 their associated stieltjes transforms .",
    "assume that @xmath584 where @xmath585 is a continuous function over @xmath586 , the closure of @xmath50 .",
    "let @xmath573 be a function of order @xmath42 with bounded support ; recall the definition of @xmath46 in and denote by @xmath587 then @xmath588    write @xmath589 from this and the fact that @xmath590 is equal to 1 for @xmath591 small enough , we deduce that @xmath592 near the real axis .",
    "hence @xmath593 near the real axis , which yields .",
    "recall the definition of the sets @xmath219 , @xmath220 and @xmath221 given in and the fact that constant @xmath594 .",
    "[ lemma : abstract ] let @xmath595 and @xmath596 be centered complex - valued continuous random processes an such that @xmath597 and @xmath598 .",
    "assume that :    * the following convergence in distribution holds true : for all @xmath559 and @xmath599 , @xmath600 { } 0\\ ] ] * for all @xmath539 , @xmath601 and @xmath602 are tight on @xmath221 .",
    "+ * the process @xmath603 is gaussian with covariance matrix @xmath604 , @xmath605 . + * the following estimates hold true @xmath606 * let functions @xmath607 @xmath608 ) be @xmath42 and have compact support .",
    "then , @xmath609 { } 0\\ , \\ ] ] where @xmath610 with @xmath590 being smooth , compactly supported with value 1 in a neighbourhood of 0 .",
    "moreover , @xmath611 is centered gaussian with covariance matrix : @xmath612 for @xmath613 .",
    "proof of lemma [ lemma : abstract ] is provided in appendix [ proof : lemma : abstract ] .",
    "the strategy to prove theorem [ th : non - analytic ] closely follows this lemma .",
    "denote by @xmath614 the process @xmath163 being defined in theorem [ lemma : main ] , then conditions ( i ) , ( ii ) and ( iii ) are immediate consequences of theorem [ lemma : main ] . in order to check condition ( iv )",
    ", we establish the following proposition :    [ prop : variance - estimate - sharp ] assume that ( a-[ass : x ] ) and ( a-[ass : r ] ) hold true , then :    * ( bordenave @xcite , hachem et al .",
    "* lemma 6.3 ) , shcherbina @xcite ) for all @xmath136 , @xmath615 * for all @xmath136 , @xmath616    where @xmath617 is a constant that may depend polynomially on @xmath618 .",
    "proof of proposition [ prop : variance - estimate - sharp ] is postponed to appendix [ app : prop - variance - sharp ] .    taking into account the estimates established in proposition [ prop : variance - estimate - sharp ] immediatly yields the first part of theorem [ th : non - analytic ] in the case where functions @xmath619 have a bounded support and satisfy ( v ) with @xmath620 , i.e. are @xmath7 .",
    "it remains to prove the equivalence between and .",
    "but this immediately follows from :    [ prop : equiv : levy ] let @xmath16 and @xmath563 be @xmath151-valued random variables and assume that both sequences are tight , then the following are equivalent :    1",
    ".   the following convergence holds true : @xmath621 { } 0\\ .",
    "$ ] 2 .   for every continuous",
    "bounded function @xmath622 , @xmath623 { } 0\\ , $ ]    proposition [ prop : equiv : levy ] can be proved easily by contradiction using the fact that @xmath35 metrizes the convergence of laws ; its proof is hence omitted .",
    "let @xmath624 .",
    "a simple but lengthy computation yields the fact that @xmath625 for @xmath626 small enough .",
    "let now @xmath627 . since @xmath628 for any @xmath629 and @xmath630 in a compact set ( use cauchy - schwarz and apply proposition [ prop : variance - estimate - sharp ] ) , @xmath299 is well - defined .",
    "let @xmath443 be a compact set in @xmath272 and let @xmath631 with support included in @xmath443 , then one can easily prove that @xmath632 this in particular implies that @xmath301 is a distribution on @xmath633 , of finite order @xmath634 and hence uniquely extends as a distribution on @xmath635 .",
    "moreover , @xmath299 can be written as : @xmath636 where @xmath637 .",
    "taking into account the facts that : @xmath638 we can expand @xmath299 as : @xmath639 we now apply twice green s formula to each integral and obtain @xmath640 notice that the sign changes in the two last integrals follow from the contour orientations in green s formula .",
    "we now prove @xmath641 the three other integrals can be handled similarly and this will achieve the boundary value representation for @xmath299 .    using the mere definition of @xmath293 ( cf . ) and green s formula",
    "we get : @xmath642 we extract the first term of the r.h.s . from the equation above . taking into account and the fact that @xmath643 for @xmath630 in a compact set of @xmath644 , we obtain : @xmath645 by applying the same argument to the quantity @xmath646 for @xmath647 then @xmath648 and @xmath649 , we can similarly prove that @xmath650 we finally obtain @xmath651 expanding @xmath652 into and using the above estimate immediatly yields .",
    "proof of proposition [ prop : identification - distribution ] is completed .",
    "the covariance writes ( in short ) @xmath653 where @xmath654 and @xmath655 is the sign resulting from the product @xmath656 by @xmath657 .",
    "unfolding @xmath658 , we have three terms to compute . according to the assumptions of proposition [ prop : new - variance - formula ] , either @xmath99 equals 1 or 0 . in the latter case ,",
    "the term corresponding to @xmath124 vanishes ; if @xmath659 , then the quantities @xmath660 and @xmath661 ( respectively defined in and ) are equal , and so are @xmath114 and @xmath124 .",
    "we first establish @xmath662 the proof relies on formula and the following expression of @xmath661 @xmath663 which can be obtained using . using and performing a double integration by parts yields @xmath664 following ( * ? ? ?",
    "* section 5 ) , we need only to consider the logarithm term and show its convergence since the @xmath665 term will eventually disappear ( functions @xmath6 and @xmath666 being real , the covariance will be real as well ) . using , we obtain @xmath667 and the sum writes @xmath668 where @xmath212 follows from the fact that @xmath669 and @xmath670 .",
    "it is straightforward to prove that the first integral of the r.h.s .",
    "vanishes as @xmath671 . using similar arguments as in ( * ? ? ?",
    "* section 5 ) , one can prove that @xmath672 which is the desired result .",
    "we now establish @xmath673 due to formula , we only need to prove @xmath674_{ii }   \\ , dx = \\frac 1\\pi \\int_{{\\mathcal s}_n } f'(x)\\ , { \\mathrm{im}}\\left(x\\,t_n(x ) \\right ) _ { ii }   dx\\ .\\end{gathered}\\ ] ] performing an integration by parts and taking into account the fact that @xmath675 yields @xmath676_{ii }   \\ , dx}\\\\ & = & - \\frac{{\\boldsymbol{i}}}{2\\pi}\\lim_{\\varepsilon\\downarrow 0 } \\int f'(x )    2{\\boldsymbol{i}}\\ ,   { \\mathrm{im}}\\left [ ( x+ { \\boldsymbol{i}}\\varepsilon ) t_n(x+ { \\boldsymbol{i}}\\varepsilon ) \\right]_{ii } \\ , dx \\stackrel{(a)}= \\frac 1\\pi \\int_{{\\mathcal s}_n } f'(x )   { \\mathrm{im}}\\left ( x\\,t_n(x )   \\right)_{ii } \\ ,",
    "dx\\ , \\\\\\end{aligned}\\ ] ] where step @xmath212 follows from the fact that @xmath677\\times ( 0,b ] \\end{array } } \\left| ( 1+\\tilde t_n(z ) \\lambda_i)\\right| > 0\\ ] ] where the @xmath24 s stand for @xmath2 s eigenvalues .",
    "in fact , assume that holds true , then using the spectral decomposition of @xmath2 , the pointwise convergence of @xmath101 to @xmath309 as @xmath678 ( see for instance @xcite ) and formula , then one obtains the pointwise convergence @xmath679_{ii}\\xrightarrow[\\varepsilon \\to 0 ] { } { \\mathrm{im}}\\left [ x t_n(x)\\right]_{ii}\\ ] ] for @xmath680 .",
    "since @xmath681 outside @xmath131 , so is @xmath682_{ii}$ ] . finally , provides a uniform bound for @xmath683_{ii}$ ] and @xmath212 follows from the dominated convergence theorem .",
    "it remains to prove .",
    "assume that the infemum is zero , then there exists @xmath684 with @xmath685 and a sequence @xmath686 such that @xmath687 and @xmath688 .",
    "formula yields @xmath689 taking @xmath690 yields a contradiction since since the l.h.s .",
    "goes to infinity while the r.h.s . remains bounded .",
    "necessarily , holds true and is proved .",
    "proof of proposition [ prop : new - variance - formula ] is completed by gathering , and using the fact that @xmath127 .      in order to establish the fluctuations in the case",
    "where functions @xmath691 are @xmath7 in a neighborhood of @xmath692 but may not have a bounded support , we proceed as following : write @xmath693 by proposition [ prop : reduction ] , the vector @xmath694 almost surely converges to zero while the fluctuations for vector @xmath695 are described by theorem [ th : non - analytic ] with covariance given by proposition [ prop : new - variance - formula ] , where functions @xmath696 and @xmath697 must be replaced by @xmath698 and @xmath699 .",
    "the variance formula provided in this proposition shows that @xmath700 does not depend on function @xmath572 as long as @xmath572 has value 1 on @xmath131 .",
    "recall the notations @xmath701 , etc . introduced in section [ sec : proof ] .",
    "we split the bias into two terms @xmath702 we will prove the following .",
    "provided that function @xmath6 is of class @xmath703 with bounded support , then : @xmath704 { } 0\\ .\\ ] ] provided that function @xmath6 is of class @xmath60 with bounded support , then : @xmath705 { } 0\\ .\\ ] ] as one can check , it is much more demanding in terms of assumptions to prove than .",
    "convergence in should be compared to the results in haagerup and thrbjornsen @xcite ( counterpart in the gue case ) , schultz @xcite ( goe ) , capitaine and donati - martin @xcite , loubaton et al .",
    "@xcite ( signal plus noise model ) , etc .",
    "the heart of the proof lies in helffer - sjstrand s formula , in theorem [ lemma : main ] ( bias part ) and in a dominated convergence argument . by theorem [ lemma : main ] , @xmath706 { } 0\\ .\\ ] ] the same argument yields : @xmath707 { } 0\\ , \\ ] ] because in the later case @xmath708 , hence the bias is zero for the matrix model @xmath709 .",
    "substracting yields : @xmath710 { } 0\\ .\\ ] ] recall that by proposition [ prop : approx - gaussienne ] , @xmath711 in order to transfer this bound to @xmath361 , we invoke a meta - model argument ( cf .",
    "section [ sec : meta - model ] ) : consider matrix @xmath173 and its counterpart @xmath712 as defined in and recall that in this case , we have a genuine limit : @xmath713 { } { \\mathcal b}_n(z)\\ .\\ ] ] since the estimate remains true for all @xmath168 , we obtain : @xmath714    write @xmath715 in view of , we need a dominated convergence argument in order to prove ; such an argument follows from proposition [ prop : compensation ] , and as long as @xmath6 is of class @xmath703 with large but bounded support .",
    "this concludes the proof of .",
    "the gist of the proof lies in the following proposition whose proof is postponed to appendix [ app : prop - bias - hard ] :    [ prop : bias - hard ] denote by @xmath716 a polynomial in @xmath155 with degree @xmath717 and positive coefficients , then : @xmath718    using helffer - sjstrand s formula , proposition [ prop : bias - hard ] together with proposition [ prop : compensation ] immediately yield for any @xmath6 of class @xmath60 with large but bounded support .",
    "one can easily prove that @xmath358 is a distribution on @xmath719 following the lines of proof of proposition [ prop : identification - distribution ] .",
    "similarly , one can establish the boundary value representation .",
    "it remains to prove that the singular points of @xmath361 are included in @xmath131 .",
    "following the definitions of @xmath140 and @xmath141 cf . and , we simply need to prove that the quantities @xmath720 are invertible for @xmath721 .",
    "we focus on the first one .",
    "assume first that @xmath722 .",
    "using the inequality @xmath723 yields : @xmath724 since @xmath725 , we can assume without loss of generality that @xmath726 .",
    "@xmath727 where the last identity follows from .",
    "in order to extend the previous estimate to @xmath728 , let @xmath729 with @xmath730 ; then a direct computation yields : @xmath731 { } \\int\\frac{{\\tilde f}_n(d\\lambda)}{|\\lambda - x|^2}\\neq 0\\ .\\ ] ] therefore , by continuity @xmath732 does not vanish on @xmath733 and @xmath140 is analytic on this set .",
    "we can similarly prove that @xmath141 is also analytic on the same set .",
    "consider now a function @xmath734 whose support is disjoint from @xmath131 , then it is straightforward to check that @xmath735 and the proof of the proposition is completed .",
    "in this section , we outline the proof of identity which we recall below : @xmath736 the proof closely follows computations in ( * ? ? ? * section 4 ) and is essentially a matter of bookkeeping ; in particular , all the estimates established there remain valid in the context where @xmath2 and @xmath3 are not real .",
    "we shall focus here on the algebraic identities .",
    "we first replace @xmath737 by @xmath149 and approximate @xmath149 by ( cf .",
    "* eq . 4.13 ) ) : @xmath738 where @xmath739 the terms @xmath740 and @xmath741 will not contribute in the sequel .",
    "denote by @xmath742 we have : @xmath743 in order to compute @xmath744 , we approximate @xmath745 in the same way as in ; we take into account the fact that for some deterministic matrix @xmath405 , @xmath746 ; we also use the approximation @xmath747 and equation .",
    "the computation of @xmath744 then easily follows : @xmath748 we now focus on the term @xmath749 where @xmath750 will not contribute . using the rank - one perturbation identity for @xmath751 , we obtain : @xmath752 in order to pursue the computation of @xmath753 , we shall perform the following approximations : the quantity @xmath754 can be replaced by @xmath755 and the two remaining quadratic forms in the expectation can be decorrelated .",
    "now , using formulas , we obtain : @xmath756 we can now replace @xmath757 by @xmath149 with no loss and use equation to obtain : @xmath758 denote by @xmath759 we now extract @xmath753 from and plug it into .",
    "we finally obtain : @xmath760 multiplying @xmath761 by @xmath762 finally yields .      by proposition [",
    "prop : compensation ] , @xmath763 by ( iii ) and ( iv ) .",
    "hence @xmath764 is a well - defined a.s .",
    "finite random variable .",
    "this estimate , uniform in @xmath10 , readily implies the tightness of @xmath765 notice that the integrals with @xmath766 instead of @xmath767 are similarly well - defined and tight .",
    "let @xmath769 and @xmath770 be bounded and continuous . consider the following notations : @xmath771 we have @xmath772 given @xmath773 , we first prove that for all @xmath774 , @xmath775 for @xmath154 small enough .",
    "we have @xmath776+{\\boldsymbol{i}}[0,\\varepsilon ] }   |\\overline \\partial \\phi({\\bf g})(z)| { \\mathbb{e}}|\\varphi_n(z)| { \\ell_2}(dz ) \\right)\\ ] ] which can be made arbitrarily small if @xmath154 is small enough , independently from @xmath10 .",
    "now , @xmath777 first invoke the tightness of @xmath778 and choose @xmath443 large enough so that the second term of the r.h.s . is lower than @xmath779 ; then choose @xmath780 small enough so that @xmath6 being absolutely continuous over @xmath781 , the third term of the r.h.s . is lower that @xmath782 ; finally for such @xmath443 and @xmath333 , take advantage of and choose @xmath154 small enough so that the first term of the r.h.s . is lower than @xmath779 .",
    ". is proved .      in order to prove that @xmath784 is multivariate gaussian with prescribed covariance , we first consider @xmath785 . approximating the integral in @xmath785 by riemann sums and using the fact that weak limits of gaussian vectors are gaussian immediately yields that @xmath785 is a gaussian vector with covariance matrix : @xmath786_{k\\ell}\\ = \\",
    "\\frac 1{\\pi^2 } { \\mathbb{e}}\\left\\ { \\mathrm{re } \\int_{d^\\varepsilon } \\overline{\\partial } \\phi(g_k)(z ) \\psi_n(z ) { \\ell_2}(dz )   \\ , \\mathrm{re } \\int_{d^\\varepsilon } \\overline{\\partial } \\phi(g_\\ell)(z ) \\psi_n(z ) { \\ell_2}(dz ) \\right\\}\\ ] ] for @xmath613 . using the elementary identity : @xmath787",
    "we obtain : @xmath788_{k\\ell}&= & \\frac 1{2\\pi^2 } \\mathrm{re }   \\int_{(d^\\varepsilon)^2 } \\overline{\\partial } \\phi(g_k)(z_1 ) \\overline{\\overline{\\partial } \\phi ( g_\\ell)(z_2 ) } { \\mathbb{e}}\\psi_n(z_1)\\overline{\\psi_n(z_2 ) } { \\ell_2}(\\ , dz_1){\\ell_2}(\\ , dz_2)\\\\ & & + \\frac 1{2\\pi^2 } \\mathrm{re }   \\int_{(d^\\varepsilon)^2 } \\overline{\\partial } \\phi(g_k)(z_1 ) { \\overline{\\partial } \\phi(g_\\ell)(z_2 ) } { \\mathbb{e}}\\psi_n(z_1){\\psi_n(z_2 ) } { \\ell_2}(\\ , dz_1){\\ell_2}(\\ , dz_2)\\ .\\end{aligned}\\ ] ] using the fact that @xmath789 yields : @xmath788_{k\\ell}&= & \\frac 1{2\\pi^2 } \\mathrm{re }   \\int_{(d^\\varepsilon)^2 } \\overline{\\partial } \\phi ( g_k)(z_1 ) \\overline{\\overline{\\partial } \\phi ( g_\\ell)(z_2 ) } \\kappa_n(z_1,\\overline{z_2 } ) { \\ell_2}(\\ , dz_1){\\ell_2}(\\ , dz_2)\\\\ & & + \\frac 1{2\\pi^2 } \\mathrm{re }   \\int_{(d^\\varepsilon)^2 } \\overline{\\partial } \\phi ( g_k)(z_1 ) { \\overline{\\partial } \\phi(g_\\ell)(z_2 ) } \\kappa_n(z_1,z_2 ) { \\ell_2}(\\ , dz_1){\\ell_2}(\\ , dz_2)\\ .\\end{aligned}\\ ] ] in order to lift the gaussianity from @xmath785 to @xmath784 and to extend the covariance formula from the one above to formula , we rely on the approximation theorem ( * ? ? ?",
    "* theorem 4.28 ) and on assumptions ( iv ) and ( v ) on the variance estimates and on the regularity of functions @xmath790 in lemma [ lemma : abstract ] .",
    "recall the notations @xmath791 , @xmath792 introduced in section [ sec : proof ] .",
    "denote by @xmath793 where @xmath794 is an independent copy of @xmath791 .",
    "let @xmath795 be the associated resolvent : @xmath796 rank - one perturbation formulas yield : @xmath797 we are now in position to apply efron - stein s inequality ( cf .",
    "* theorem 3.1 ) ) : @xmath798\\ \\stackrel{(a)}\\le \\ \\sum_{i=1}^n { \\mathbb{e}}\\left [ { \\mathbb{e}}_{\\{i\\ } } \\left| \\frac{\\xi_i^ * q_i^2\\xi_i}{1 + \\xi_i^ * q_i \\xi_i } - \\frac{{\\mathbb{e}}_{\\{i\\ } } \\xi_i^ * q_i^2\\xi_i}{1 + { \\mathbb{e}}_{\\{i\\ } } \\xi_i^ * q_i \\xi_i } \\right|^2 \\right]\\\\end{aligned}\\ ] ] where @xmath799 is the variance under the expectation @xmath800 with respect to @xmath791 , and @xmath212 follows from the fact that @xmath801 .",
    "denote by @xmath802 we have @xmath803 notice that @xmath804 , hence @xmath805 now @xmath806    we first focus on the estimation of @xmath807 ; we have : @xmath808 before dividing by @xmath809 , notice that @xmath810 and that @xmath811 is the stieltjes transform of a probability measure and hence that @xmath812 we now divide and get : @xmath813 \\frac 1{|{\\mathbb{e}_{\\{i\\}}}(a)|}\\ \\le \\",
    "\\frac kn \\ , \\frac 1{{\\mathrm{im}}(z ) } \\frac { |z|}{{\\mathrm{im}}(z)}\\quad = \\quad   \\frac kn\\frac 1{{\\mathrm{im}}(z)^{2}}\\ .\\end{aligned}\\ ] ] similarly , one can prove that @xmath814 from this we get the desired estimate : @xmath815    in order to prove the second part of condition ( iii ) , we rely on a meta - model argument ( cf .",
    "section [ sec : meta - model ] ) .",
    "denote by @xmath816 then @xmath817 moreover @xmath818 converges in distribution to @xmath602 as @xmath184 , @xmath9 and @xmath10 being fixed ( see for instance the details in section [ sec : gaussian - process ] ) .",
    "consider the continuous bounded function @xmath819 , then @xmath820 now letting @xmath821 yields the desired bound by monotone convergence theorem : @xmath822        recall that @xmath826 , where @xmath827 .",
    "denote by @xmath828 let @xmath829 taking into account the definition of @xmath830 and @xmath116 , we get : @xmath831 similarly , @xmath832 + \\tilde \\varepsilon_n\\\\   & = & \\frac 1z { \\mathrm{tr}\\,}r_n   ( i_n + { \\mathbb{e}}\\tilde f_n r_n)^{-1 } r_n ( i_n + \\tilde t_n r_n)^{-1 } \\left ( { \\mathbb{e}}\\tilde f_n - \\tilde t_n\\right )    + \\tilde \\varepsilon_n\\ .\\\\   \\end{aligned}\\ ] ] gathering the two previous equations , we finally end up with the @xmath833 linear system : @xmath834 where @xmath835 from which we extract @xmath836 it remains to bound @xmath837 and @xmath838 and to lowerbound @xmath839 .",
    "the first task relies on standard gaussian calculus for random matrices ( poincar - nash inequality , integration by part formula , etc . -",
    "see for instance @xcite ) and yields : @xmath840 there exist @xmath780 , polynomials @xmath841 and @xmath842 and an integer @xmath843 such that for every @xmath106 in the set @xmath844 and for @xmath845 @xmath846 where @xmath443 is some constant independent from @xmath37 .",
    "assume for a while that proposition [ prop : haalou ] holds true , and let @xmath847 ; then taking into account - and the fact that @xmath848 , yields : @xmath849 if @xmath850 , then @xmath851 and @xmath852 proof of proposition [ prop : bias - hard ] is completed as long as proposition [ prop : haalou ] holds true .",
    "consider matrix @xmath854 in order to evaluate the determinant of matrix @xmath855 , we need to find an equation where such a matrix appears .",
    "one can easily prove that : @xmath856 from which we extract the determinant : @xmath857 recall that @xmath858 ; in order to lowerbound @xmath859 , recall that the associated probability measures @xmath190 form a tight family and in particular there exists @xmath780 such that @xmath860)>1/2 $ ] for every @xmath774 .",
    "write : @xmath861 plugging these estimates into yields the bound : @xmath862 consider now matrix @xmath863 in order to evaluate the determinant of matrix @xmath864 , we need to find an equation where such a matrix appears .",
    "recall the definition of @xmath837 and @xmath838 in - .",
    "taking their imaginary parts , we obtain : @xmath865 computing the imaginary part of @xmath830 and @xmath866 , we get : @xmath867 hence the system : @xmath868 this system is similar to with two extra error terms @xmath869 and @xmath870 ; but these terms are controled by - .",
    "it is well - known that for all @xmath136 , @xmath871 as @xmath872 . the mere definition of @xmath837 together with estimate yields @xmath873 ; therefore @xmath874 for @xmath136 as @xmath875 .",
    "this , together with yields : @xmath876 for @xmath10 large enough . taking into account the fact that @xmath877 , the first equation in yields : @xmath878 for @xmath10 large enough , where @xmath212 follows from the previous estimate over @xmath830 and .",
    "polynomials @xmath879 and @xmath880 being fixed as in the previous estimate , consider the set : @xmath881 then for @xmath10 large enough and @xmath882 , @xmath883 from , we have : @xmath884 taking into account the various estimates previously established ( recall that @xmath885 ) , we obtain : @xmath886 valid for @xmath10 large enough and @xmath882 . polynomials @xmath887 and @xmath888 being fixed as in the previous estimates , consider the set : @xmath889 then for @xmath10 large enough and @xmath847 , we have : @xmath890 we are now in position to lowerbound @xmath853 .",
    "notice that @xmath891 by ( * ? ? ?",
    "* proposition 6.1 ) .",
    "proof of proposition [ prop : haalou ] is completed .",
    "jamal najim , + institut gaspard monge labinfo , umr 8049 + universit paris est marne - la - valle + 5 , boulevard descartes , + champs sur marne , 77454 marne - la - valle cedex 2 , france + e - mail : najim@univ-mlv.fr +              z.  bai , y.  chen , and y - c .",
    "liang , editors . ,",
    "volume  18 of _ lecture notes series .",
    "institute for mathematical sciences .",
    "national university of singapore_. world scientific publishing co. pte . ltd . ,",
    "hackensack , nj , 2009 .",
    "multivariate statistics and wireless communications , papers from the workshop held at the national university of singapore , singapore , 2006 .",
    "o.  guedon , a.  lytova , a.  pajor , and l.  a. pastur .",
    "the central limit theorem for linear eigenvalue statistics of the sum of rank one projections on vectors with log - concave distribution .",
    "preprint , 2013 .",
    "b.  helffer and j.  sjstrand .",
    "quation de schrdinger avec champ magntique et quation de harper . in _ schrdinger operators ( snderborg , 1988 ) _ , volume 345 of _ lecture notes in phys .",
    "_ , pages 118197 .",
    "springer , berlin , 1989 ."
  ],
  "abstract_text": [
    "<S> consider a @xmath0 matrix @xmath1 where @xmath2 is a nonnegative definite hermitian matrix and @xmath3 is a random matrix with i.i.d . </S>",
    "<S> real or complex standardized entries . the fluctuations of the linear statistics of the eigenvalues : @xmath4 are shown to be gaussian , in the regime where both dimensions of matrix @xmath5 go to infinity at the same pace and in the case where @xmath6 is of class @xmath7 , i.e. has three continuous derivatives . the main improvements with respect to bai and silverstein s clt @xcite </S>",
    "<S> are twofold : first , we consider general entries with finite fourth moment , but whose fourth cumulant is non - null , i.e. whose fourth moment may differ from the moment of a ( real or complex ) gaussian random variable . as a consequence , </S>",
    "<S> extra terms proportional to @xmath8 appear in the limiting variance and in the limiting bias , which not only depend on the spectrum of matrix @xmath2 but also on its eigenvectors . </S>",
    "<S> second , we relax the analyticity assumption over @xmath6 by representing the linear statistics with the help of helffer - sjstrand s formula .    the clt is expressed in terms of vanishing lvy - prohorov distance between the linear statistics distribution and a gaussian probability distribution , the mean and the variance of which depend upon @xmath9 and @xmath10 and may not converge .    </S>",
    "<S> * ams 2000 subject classification : * primary 15a52 , secondary 15a18 , 60f15 . </S>",
    "<S> + * key words and phrases : * large random matrix , fluctuations , linear statistics of the eigenvalues , central limit theorem . + </S>"
  ]
}