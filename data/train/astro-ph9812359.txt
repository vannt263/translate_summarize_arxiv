{
  "article_text": [
    "image processing techniques are increasingly being employed to aid in the interpretation of data from x and @xmath0-ray astrophysics missions , both to suppress noise from low photon statistics and to invert instrumental responses when required .",
    "an excellent example of this is for compton telescopes , such as comptel ( @xcite ) , where directional information of detected photons has a complex relationship to the measured quantities , source count rates are relatively low , and background is high .    in kebede ( 1994 )",
    "( hereafter referred to as k94 ) , a method is presented for unfolding data from the instrumental response .",
    "further examination of k94 reveals certain mathematical and conceptual errors .",
    "i will review and correct these in this paper , show specific examples of the application of the proposed method and compare with other similar simple algorithms .",
    "some claims of kebede ( 1994 ) are discussed , and those which are incorrect are noted .",
    "interestingly , the claim that `` the method totally eliminates the possibility of any error amplification '' ( @xcite ) , while misleading , turns out to be true .",
    "however , we also show that while the method of k94 may not _",
    "amplify _ noise in the data , it also does nothing to suppress noise , rather passing it through to the estimate .",
    "whether or not this is considered a useful property may be a function of one s particular application , though it seems for most scientific studies that some suppression of the noise ( easily accomplished ) is desirable .    to facilitate direct comparison with k94",
    ", we shall adopt its somewhat non - standard notation and nomenclature .",
    "the transpose of a matrix @xmath1 ( termed the `` converse '' by kebede ) is denoted with a tilde , i.e. , @xmath2 .",
    "the matrix factors from the singular value decomposition of @xmath3 are instead given as @xmath4 .",
    "the problem under consideration is essentially that of inverting a discretized version of a linear integral equation , given an instrument response kernel and data perturbed by noise .",
    "this may be formulated as a matrix equation @xmath5 where @xmath1 is an @xmath6 matrix describing the discretized instrument response , @xmath7 is an @xmath8-vector representing the binned data , and @xmath9 is an @xmath10-vector respresenting the the source field flux distribution , usually specified as a set of pixels ( note that k94 uses @xmath11 and @xmath12 ; we have changed to lower case to avoid confusion between matrices and vectors ) .",
    "the approximate equality is a result of noise . if @xmath13 , then equality can potentially be achieved , but this is not usually a desirable goal , for reasons which are generally well - known ( @xcite ) .",
    "in particular , this leads to a serious overfit of the data , accounting for every little feature whether simply noise or not .",
    "the approach in k94 is to find constants @xmath14 and vectors @xmath15 and @xmath16 such that @xmath17 though k94 never refers to it as such , eqs .",
    "[ eq : svd ] define the singular value decomposition ( svd ) of the matrix @xmath1 , with @xmath14 being the singular values , @xmath15 the left singular vectors , and @xmath18 the right singular vectors .",
    "the @xmath15 form a complete orthonormal basis , as do the @xmath16 .",
    "k94 uses the rather confusing term `` eigenvalues '' for the @xmath14 , as opposed to the more standard `` singular values '' .",
    "the @xmath14 _ are _ the square roots of the eigenvalues of @xmath19 , but these are _ not _ the eigenvalues of @xmath1 , which are undefined for @xmath20 .",
    "k94 suggests least - squares solution of eqn .",
    "[ eq : lsqr ] , given schematically by @xmath21 note that this makes no reference to the data statistics .",
    "data bins with low expected counts will receive equal weight as those with high expected counts .",
    "we address this point later . for non - square @xmath1",
    "the standard matrix inverse is not defined ; however one can use the generalized left inverse ( @xcite ) .",
    "equation  [ eq : svd ] implies @xmath22 , with @xmath23 and @xmath24 orthonormal matrices whose columns are the @xmath15 and @xmath16 respectively , and @xmath25 . as is well - known ( @xcite ) , the generalized left inverse of @xmath1 is given by @xmath26 substituting this in eqn .",
    "[ eq : sol ] yields the least - squares solution for @xmath9 , i.e. , the @xmath9 which minimizes @xmath27 .",
    "if @xmath1 is singular , the least - squares solution is not unique , and @xmath28 contains zero elements on the diagonal .",
    "the svd inverse is computed by setting @xmath29 for @xmath30 , and 0 otherwise .",
    "the svd inverse then chooses the solution which minimizes the euclidean norm of @xmath9 ( given by @xmath31 ) .",
    "linear inverse theory tells us that the solution of eqn .",
    "[ eq : lsqr ] is almost inevitably unstable for the types of systems we encounter experimentally ( @xcite ) .",
    "this instability is related to the fact that our instrument has finite resolving power , and nearby pixels may have a high degree of potential confusion .",
    "the singular value spectrum reflects this , generally decaying rapidly , and such matrices are termed _ ill - conditioned _ ( @xcite ) . from eqn .",
    "[ eq : ginv ] we see that a small singular values makes a large contribution to the generalized inverse , and this tends to lead to noise amplification . to reduce these effects",
    ", one must _ regularize _ the inverse , which for our purposes means suppressing the effects of small singular values .",
    "this is the claim for the method of k94 which , as it turns out , actually achieves this in an odd fashion .",
    "the derivation of k94 is limited to the case @xmath32 and non - singular @xmath1 , for which the solution of eqn .",
    "[ eq : lsqr ] is @xmath33 k94 then notes that @xmath9 and @xmath34 can be related via a diagonal matrix ( @xmath9 and @xmath34 are both @xmath10-vectors ) .",
    "note that this is _ not _ the matrix @xmath35 , which is very definitely not diagonal for the cases of interest . to be more specific , one can relate @xmath9 and @xmath34 via a diagonal matrix , but this matrix necessarily depends on @xmath1 and @xmath7 . if we denote this matrix as @xmath36 , then a little algebra shows that for @xmath9 given by eqn .",
    "[ eq : sol2 ] , @xmath37 thus , finding @xmath36 and finding @xmath9 are equivalent operations when estimating the unregularized inverse .",
    "k94 asserts that @xmath36 is non - negative , but this will not be true in general , since the @xmath9 given by eqn .",
    "[ eq : sol2 ] is not non - negative . in fact , the noise amplification due to small singular values guarantees large positive and negative oscillations , which is exactly the problem one is trying to mitigate . as we shall see below , eqn .",
    "[ eq : t ] suggests an iteration for estimating @xmath36 ( or @xmath9 ) which under certain conditions _ does _ force @xmath36 ( @xmath9 ) to be non - negative , but in this case @xmath9 is no longer the least - squares solution to eqn .",
    "[ eq : sol2 ] .",
    "k94 goes on the suggest the following iteration on @xmath9 ( k94 , eqn .",
    "( 11 ) ) : @xmath38 the next question is how to compute @xmath39 from @xmath1,@xmath7 , and @xmath40 . equation ( 12 ) of k94 gives the answer as @xmath41 k94 does not elucidate on the meaning of @xmath42 , in particular what the superscript means , since @xmath34 is just given by @xmath1 and @xmath7 and has nothing to do with the iteration .",
    "referring to eqn .",
    "[ eq : t ] , we might guess that this is supposed to mean what @xmath34 would be if @xmath40 were the `` true '' image , in which case the iteration would be @xmath43    the next step in the derivation apparently contains an algebraic error .",
    "k94 ( eqn .",
    "13 ) gives the following expression : @xmath44 which is simply incorrect . referring to the svd of @xmath1 , and remembering that @xmath23 and @xmath24 are orthonormal matrices ( i.e.",
    ", @xmath45 is the identity ) , we actually find @xmath46 this difference then explains the form of eqn .",
    "( 14 ) of k94 , which gives the iteration as @xmath47 note that the denominator of eqn .",
    "[ eq : pieq14 ] is just @xmath48 . if one referred to eqn .",
    "[ eq : pieq13 ] , and incorrectly substituted @xmath49 into eqn .",
    "[ eq : better ] , eqn .",
    "[ eq : pieq14 ] would result .",
    "following the derivation of eqn .",
    "[ eq : pieq14 ] ( k94 , eqn .",
    "( 14 ) ) , the author makes the following statement : `` notice how the solution given in equation ( 14 ) virtually ignores the small eigenvalues '' ; remember that by `` eigenvalues '' kebede is actually referring to the singular values of @xmath1 .",
    "let us examine this statement further , especially in light of the errors leading to eqn .",
    "[ eq : pieq14 ] .",
    "we begin by considering the `` correct '' version of eqn .",
    "[ eq : pieq14 ] , given by @xmath50 where we ve simplified the notation a bit and havent bothered expanding @xmath51 in terms of its svd factors , since there s no compelling reason to do so .",
    "in fact , one encounters many cases where @xmath1 is too large to explicitly construct , but where matrix - vector products can be calculated via fast implicit algorithms .",
    "a simple example of this would be an imaging system with a translationally - invariant point - spread function ( psf ) , for which the products @xmath52 and @xmath53 can be calculated via the fft and convolution theorem . for a large number of image / data pixels",
    ", explicit calculation and use of the svd factors would involve massive computational overhead .    since we are not advocating use of eqn .",
    "[ eq : correct ] , we wo nt discuss the convergence properties , except to note that in numerical experiments it converges monotonically in the squared residual @xmath54 .",
    "of more interest is what it converges to .",
    "not surprisingly , the stable fixed point of the iteration is just the solution given by eqn .",
    "[ eq : sol2 ] ; proof of this is simple and follows directly from eqn .",
    "[ eq : correct ] .",
    "the iteration also has saddle points , the trivial example being @xmath55 , which does lead to an interesting point . for @xmath56 ( as is often the case for imaging systems ) , if the initial value @xmath57 is positive then eqn .  [ eq : correct ] converges to a saddle point for which @xmath9 is non - negative .",
    "this @xmath9 is _ not _ the solution to eqn .",
    "[ eq : sol2 ] , but that s a good thing , since the non - negativity constraint is not only physical , but also serves to stabilize the solution for ill - conditioned @xmath1 ( @xcite ) .",
    "let us now consider eqn .",
    "[ eq : pieq14 ] at face value , and see what it implies for the estimation of @xmath9 . from eqn .",
    "[ eq : pieq14 ] , the convergence condition @xmath58 gives the solution as @xmath59 where the superscript ( f ) denotes the value at convergence , i.e. , the fixed point .",
    "solving for @xmath60 , again using the svd factorization of @xmath1 and the orthonormality of @xmath24 , we find the stable fixed point to be @xmath61 interestingly , we see from eqn .  [ eq : fp ] that not only does the iteration of eqn .",
    "[ eq : pieq14 ] `` virtually ( ignore ) the small ( singular values ) '' , but in fact ignores them completely !",
    "so the claim of k94 that this `` method totally eliminates  error amplification '' is true , strictly speaking , since it is @xmath62 which leads to this phenomenon . on first glance",
    "a reader might take this statement to mean that noise itself is eliminated in the estimate , which is not the case .",
    "the orthonormality of @xmath23 and @xmath24 imply that noise is propagated through to the estimate .",
    "if the noise were white , this orthonormality implies that the noise in the estimate is also white and of the same magnitude as in the data .",
    "the situation is less clear for poisson noise , but generally one might expect the image pixel noise to be similar on average to that in the data pixels ; examples given below will illustrate this . note that the non - negativity implied by eqn .",
    "[ eq : pieq14 ] implies some noise suppression , but only for images where the average intensity level is somewhat larger than the noise level .",
    "equation  [ eq : fp ] represents a regularized estimate of @xmath9 , and might be considered a variant on the damped svd ( dsvd ) method ( @xcite ) . to obtain the dsvd estimate ,",
    "one purposely suppresses the effect of small singular values with a damping function . here",
    ", our damping function would be simply the singular values themselves , so they cancel out the inverse .",
    "naively this may sound like a good idea , but it actually ignores a lot of the information provided by the singular values ( @xcite ) . if nothing else , the regularization provided by use of eqn .",
    "[ eq : fp ] is always the same  we have no control over it .",
    "yet in actual situations , we need to control the amount of regularization , since we d apply more or less depending on the signal - to - noise of the data .",
    "dsvd methods in general allow such control via the specification of a cutoff value , where the damping function drops to zero ( or very small values ) .",
    "we might conceive of controlling the amount of regularization by stopping the iteration early .",
    "this is often employed in iterative schemes such as conjugate gradient ( @xcite ) , lsqr ( @xcite ) , expectation maximization ( @xcite ) , and maximum entropy ( @xcite ) , where it is found either empirically or rigorously that the early iterations tend to pick out the statistically interesting structure , while the later ones tend to just amplify the noise . for the iterations",
    "described herein and in k94 we do nt pursue this mathematically , but show examples of below .",
    "as we stated above , the formulation of k94 makes no reference to the data statistics , nor the statistical interpretation of the converged solution .",
    "the formulation is easily modified , though , so that eqn .",
    "[ eq : correct ] is directly related to maximum likelihood estimation of the pixel fluxes .",
    "consider modification of eqn .",
    "[ eq : lsqr ] to the following : @xmath63 where @xmath64 is the ( symmetric positive - definite ) covariance matrix of the noise in @xmath7 ; consider this to be a constant for the moment , with the noise gaussian distributed .",
    "least - squares solution of eqn .",
    "[ eq : gauss ] corresponds to @xmath65-minimization , i.e. , @xmath66 where we ve reverted to the superscript @xmath36 notation to denote the vector transpose . for independent observations in @xmath7 , @xmath64 is diagonal and eqn .",
    "[ eq : chisqr ] reduces to the more familiar form of the @xmath65 .",
    "minimization of eqn .",
    "[ eq : chisqr ] implies the solution given by the condition @xmath67 the iteration of eqn .",
    "[ eq : correct ] then becomes @xmath68 use of the iteration of k94 would require the calculation of the singular factors for the matrix @xmath69 , but it s not at all clear what the answer means statistically , since @xmath28 carries much of the statistical information in the svd estimate ( i.e. , if we consider the estimate as an expansion in @xmath16 , then the @xmath70 are the statistical variances of the corresponding coefficients ) . since @xmath28 is completely cancelled for k94 s approach , this statistical information is lost .",
    "let us now consider the case of poisson noise , encountered for photon counting experiments .",
    "it can be shown that maximizing the poisson likelihood function over the pixel fluxes @xmath9 yields also implies a condition of the form eqn .",
    "[ eq : sol3 ] ( @xcite ) , _ except _ that @xmath64 now has a dependence on the solution given by @xmath71 substituting the @xmath72th iterate @xmath40 and substituting into eqn .",
    "[ eq : cor2 ] , we find @xmath73 where the division of vectors above is taken to be element - by - element .",
    "this is simply the expectation maximization maximum likelihood ( emml ) algorithm ( @xcite ) , also known as richardson - lucy ( @xcite ) from a different derivation .",
    "this iteration does converge to the poisson maximum likelihood solution in terms of the pixel fluxes @xmath9 .",
    "to illustrate some aspects of the discussion above , we will show some results from an idealized scenario , as well as a more realistic simulation . as in k94",
    ", we employ a typical compton telescope response for a single compton scatter angle . the idealized psf is computed over a @xmath74 pixel grid , and shown in figure  [ fig : psf ] . for simplicity",
    ", we do nt worry about finite size or edge effects , and simply assume the psf is normalized to unity , and wrap it around the boundaries as appropriate .",
    "the response @xmath1 is computed from all possible translates of this psf .    .",
    "note that even though the data is noise - free , we have substantially underresolved the source . ]    . ]    . ]",
    "our first example is a unit source located at @xmath75 , shown in figure  [ fig : one ] .",
    "the `` dataset '' is simply the corresponding psf , with no background or noise added .",
    "solution via eqn .",
    "[ eq : sol2 ] gives , not surprisingly , the exact answer , i.e. figure  [ fig : one ] .",
    "the regularized solution of eqn .",
    "[ eq : fp ] is shown in figure  [ fig : fpone ] , while the answer after 100 iterations of eqs .",
    "[ eq : correct ] and [ eq : pieq14 ] are shown in figures [ fig : lsiterone ] and [ fig : fpiterone ] respectively .",
    "note that figure  [ fig : fpone ] is quite spread compared to figure  [ fig : one ] , despite the fact that there is no noise or background in the `` data '' .",
    "this is an admittedly extreme example , but a properly regularized technique would allow one to take the statistics into account by varying the degree of regularization .",
    "the cancellation of the singular values in eqn .",
    "[ eq : fp ] implies that the @xmath18 corresponding to small singular values get larger weight in the solution .",
    "since these @xmath18 typically correspond to large - scale or smooth functions , oversmoothing is not a surprising effect .",
    "comparison of figures [ fig : lsiterone ] and [ fig : fpiterone ] also demonstrate this limitation , since the results from eqn .",
    "[ eq : pieq14 ] are inherently limited to be no better than the solution of eqn .",
    "[ eq : fp ] in terms of resolving power .                .",
    "note that the solution in much more stable compared with figure  [ fig : lsmany ] , though noise roughly of the same magnitude as in the data is present , as expected from the orthonormality of @xmath23 and @xmath24 . ]    ) .",
    "note some regularization compared to figure  [ fig : fpmany ] , due solely to stopping the iteration before convergence .",
    "examination of figure  [ fig : fpmany ] indicates that non - negativity does not play a role , since due to the background level the stable fixed point solution is everywhere positive . ]    . ]    ) . ]",
    "term in the denominator of eqn .",
    "[ eq : pieq14 ] with @xmath76 . ]",
    "the second example uses several point sources of varying intensity , shown in figure  [ fig : many ] .",
    "we generate data by convolution with the psf and add a constant background such that the integrated source - to - background ratio is 10% ( which would be extremely good for existing compton telescopes , but useful for purposes of demonstration ) .",
    "poisson random numbers are then generated for these expected count levels , resulting in the simulated data shown in figure  [ fig : manydata ] .",
    "for these simple examples , we make no attempt to fit or otherwise subtract the background , so the estimates will include a uniform background level as well .",
    "the least - squares solution is shown in figure  [ fig : lsmany ] , and exhibits precisely the large oscillations we wish to suppress with regularization .",
    "the regularized direct solution of eqn .",
    "[ eq : fp ] is given in figure  [ fig : fpmany ] ; as we expect , the large oscillations are damped , since the small singular values have no effect , but plenty of noise is still evident .",
    "if we compare to figure  [ fig : fpitermany ] , computed via 100 iterations of of eqn .",
    "[ eq : pieq14 ] , we see better noise suppression . however , the result of 100 iterations of eqn .",
    "[ eq : correct ] in figure  [ fig : lsitermany ] is certainly qualitatively better in terms of noise suppression and source resolution .",
    "the result from 100 steps of the emml iteration of eqn .",
    "[ eq : em ] is shown in figure  [ fig : em ] , and appears comparable with figure  [ fig : lsitermany ] .",
    "just for fun , we also computed a result where we replaced the @xmath28 term in eqn .",
    "[ eq : pieq14 ] with @xmath76 ( there is a @xmath77 term implicit in eqn .",
    "[ eq : correct ] ) . shown in figure  [ fig : cube ]",
    ", this map seems qualitatively better yet .",
    "quantitatively , of course , only eqn .",
    "[ eq : correct ] will give correct photometry , since it corresponds to the case where we use the proper generalized inverse .",
    "i have shown above that the deconvolution method of kebede ( 1994 ) appears to be erroneously derived .",
    "kebede s final expression ( eqn .",
    "[ eq : pieq14 ] ) , however , does provide a regularized estimate of the inverse , where the regularization is caused by the exact cancellation of the singular values .",
    "it is left to the reader to decide if this is a positive characteristic of kebede s published algorithm , though the above discussion and examples would seem to indicate that it does not perform particularly well , even when compared with similar simple approaches .",
    "i have showed how to explicitly include statistical information , but also that much of this is lost due to the cancellation of the singular values .",
    "i close with one final comment on the efficiency of the method .",
    "k94 claims that ``  it takes very little computing time to run a program written based on this iterative method regardless of the size of the problem . '' however , this is clearly not true .",
    "the computational complexity of svd scales _ very _ badly with the problem size , going like the @xmath78 for an @xmath79 matrix ( @xcite ) . for square image and data with @xmath80 pixels , this would be @xmath81 , which is terrible . whether one uses eqn .",
    "[ eq : pieq14 ] or eqn .",
    "[ eq : fp ] , the svd must be calculated explicitly , which would impose a heavy computational burden for all but very small images .",
    "ddd thanks prof .",
    "allen zych for helpful comments .",
    "this work was partially supported by nasa grant nag5 - 5116 ."
  ],
  "abstract_text": [
    "<S> image processing is an increasingly important aspect for analysis of data from x and @xmath0-ray astrophysics missions . in this paper , </S>",
    "<S> i review a method proposed by kebede ( l. w. kebede 1994 , apj , 423 , 878 ) , and point out an error in the derivation of this method . </S>",
    "<S> it turns out that this error is not debilitating  the method still `` works '' in some sense  but as published is rather sub - optimal , as demonstrated both on theoretical grounds and via a set of examples . </S>"
  ]
}