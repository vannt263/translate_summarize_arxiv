{
  "article_text": [
    "crowd work is a term often adopted to identify networked systems that can be used for the solution of a wide range of complex problems by integrating a large number of human and/or computer efforts @xcite .",
    "alternative terms , each one carrying its own specific nuance , to identify similar types of systems are : collective intelligence , human computation , master - worker computing , volunteer computing , serious games , voting problems , peer production , citizen science ( and others ) .",
    "an entire host of general - purpose or specialized online platforms , such as information - sharing platforms for recommendations ( e.g. , tripadvisor , amazon ) , co - creation systems ( e.g. , wikipedia , gnu project ) , social - purpose communities for urban mobility ( e.g. , waze ) , microtask - based crowd work systems , etc .",
    ", can be defined under these terms .    in this paper",
    ", we specialize to microtask - based crowd work systems .",
    "the key characteristic of these systems is that a _ requester _ structures his problem in a set of _ tasks _ , and then assigns tasks to _ workers _ that provide _",
    "answers _ , which are then used to determine the correct task _ solution _ through a _ decision _ rule .",
    "a well - known example of such systems is amazon mechanical turk ( mturk ) , which allows the employment of large numbers of low - wage workers for tasks requiring human intelligence ( hit  human intelligence tasks ) .",
    "examples of hit are image classification , annotation , rating and recommendation , speech labeling , proofreading , etc . in the amazon",
    "mechanical turk , the workload submitted by the requester is partitioned into several microtasks , with a simple and strictly specified structure , which are then assigned to ( human ) workers .",
    "since task execution is typically tedious , and the economic reward for workers is pretty small , workers are not 100% reliable , in the sense that they may provide incorrect answers .",
    "hence , in most practical cases , the same task is assigned in parallel ( replicated ) to several workers , and then a majority decision rule is applied to their answers . a natural trade - off between reliability of the decision and cost arises",
    "; indeed , by increasing the replication factor of every task , we generally increase the reliability degree of the final decision about the task solution , but we necessarily incur higher costs ( or , for a given fixed cost , we obtain a lower task throughput ) .",
    "although the pool of workers in crowd work systems is normally large , it can be abstracted as a finite set of shared resources , so that the allocation of tasks to workers ( or , equivalently , of workers to tasks ) is of key relevance to the system performance .",
    "some believe that microtask - based crowd work systems will provide a significant new type of work organization paradigm , and will employ ever increasing  @xcite numbers of workers in the future , provided that the main challenges in this new type of organizations are correctly solved . in @xcite",
    "the authors identify a dozen such challenges , including i ) workflow definition and hierarchy , ii ) task assignment , iii ) real - time response , iv ) quality control and reputation .",
    "all these aspects can represent an interesting research subject and some of them have already stimulated a large bulk of literature , as it will be detailed in the next subsection .",
    "however , this paper deals mainly with task assignment and with the quantitative assessment of the gain ( in terms of increased decision reliability for a given cost ) that a coarse knowledge of worker quality can offer .",
    "indirectly , thus , we deal also with worker reputation , although we do not study mechanisms through which reputation is built upon time .",
    "indeed , we consider a one - shot approach in which the requester has to assign a bunch of tasks to a pool of workers that are statically divided into _ classes _ according to their probabilities of answering correctly .",
    "we highlight that the way this division into classes is built is out of the scope of this paper , although we will analyze the effect of errors in this classification on the decision reliability .      in current online platforms ,",
    "task assignment is either implemented through a simple first - come / first - served rule , or according to more sophisticated approaches . in mturk",
    ", the requester can specify the number of workers to be assigned to each task .",
    "mturk also gives requesters the possibility of dismissing low - quality answers , so that each experienced worker is characterized by an approval rating . as a consequence",
    ", the requester is also allowed to prescribe a given qualification level for workers to be able to access her tasks .",
    "an analysis of the correlation between mturk approval rating and worker quality is performed in  @xcite . in the scientific community ,",
    "the task assignment in crowdsourcing systems has recently been formalized  @xcite as a resource allocation problem , under the assumption that both tasks and workers are indistinguishable . on the worker side , this assumption is motivated by the fact that the implementation of reputation - tracing mechanisms for workers may be challenging , because the workers pool is typically large and highly volatile .",
    "a step ahead has been recently made in  @xcite , which proposes an adaptive online algorithm to assign an appropriate number of workers to every task , so as to meet a prefixed constraint on the problem solution reliability . like in this paper , in  @xcite workers are partitioned in different classes , with workers within each class meeting a specified reliability index .",
    "however , unlike this paper , the allocation algorithm of  @xcite is adaptive , i.e. , it is based on previous answers on the same set of microtasks : an assumption that , although certainly interesting , implies a time - consuming overall process of task accomplishment .",
    "the same adaptive approach is followed in  @xcite , where a bandit - based algorithm is adopted to allocate heterogeneous tasks to workers with task - dependent skills .",
    "given a pool of @xmath0 questions ,  @xcite investigates how @xmath1 questions therefrom should be assigned to a worker .",
    "most real - world crowdsourcing systems typically implement a majority - based decision rule to obtain task solutions . in the last few years , in the scientific literature",
    ", smarter decision rules have been proposed to improve the performance of crowdsourcing systems , for the case where no a - priori information about workers reputation is available ( i.e. workers are a - priori indistinguishable ) while tasks are homogeneously difficult  @xcite .",
    "essentially the same decision strategy was proposed in  @xcite and  @xcite for the case in which tasks require binary answers , and then recently extended in  @xcite and , independently , in  @xcite , to the case in which tasks require generic multiple - choice answers . in  @xcite it is shown that the improved decision rule can be efficiently implemented employing a message - passing technique . in  @xcite",
    ", an integrated estimation - allocation approach has been pursued with bayesian inference and entropy reduction as utility function .",
    "different methodologies based on the expectation - maximization algorithm have been proposed in  @xcite .",
    "all these algorithms exploit existing redundancy and correlation in the pattern of answers returned from workers to infer an a - posteriori reliability estimate for every worker .",
    "the derived estimates are then used to properly weigh workers answers . when there is a - priori information about workers reliability , to the best of our knowledge , the only decision rule proposed in the literature is weighted average , like , e.g. , in  @xcite .",
    "there is a wide literature about workers motivation and reputation .",
    "regarding motivation , many studies report experiments conducted on mturk as a paradigm of microtask - based crowd work platform .",
    "classical studies of offline work reveal that workers try to understand which activities are better rewarded and tend to prefer those , virtually excluding others  @xcite .",
    "however , in the context of crowdsourcing systems , mixed results have been shown about the effect of economic incentives on the quality of workers outputs  @xcite .",
    "these studies highlight the importance of intrinsically non - economical motivations such as the feeling of contributing towards a greater good , non - financial awards and recognitions , accomplishing tasks that appear meaningful .",
    "an attempt of a systematic model of crowdsourcing workers with respect to financial incentives is proposed by  @xcite , in which experiments carried out on mturk reveal that a monetary bonus is effective when it is large enough compared to the base payment , while it saves money with respect to a generalized increase of the latter , for the same answers quality .",
    "reputation mechanisms are an important tool for crowdsourcing systems amd are active already in many online platforms .",
    "for example , upwork implements a feedback system , which is bidirectional ( workers vote requesters and vice versa ) . while upwork distributes larger and more complex tasks , in microtask - based platforms , feedback is more limited .",
    "as already said , mturk characterizes the workers with an approval rating . in the scientific literature",
    ", examples of algorithms that incorporate auditing processes in a sequence of task assignments for worker reputation assessment can be found in @xcite . in  @xcite",
    ", a dynamical reputation mechanisms is devised for a crowd composed of three types of workers : altruistic , malicious and rational .",
    "it is shown in  @xcite that , with a proper dimensioning of the financial rewards and penalties , the probability of an audit ( where the requester herself executes the task ) tends to zero .",
    "more in general ,  @xcite studies the impact of malicious workers on the performance of crowdsourcing systems .",
    "it is recognized in  @xcite that the reputation of each worker must differentiate according to different types of task . in  @xcite",
    ", a task similarity graph is used to infer workers reliabilities for open tasks based on their performance on completed tasks . an aspect closely related to reputation is online workers quality control .",
    "some systems , such as upwork worker diary , make available to the requester periodic snapshots of workers computer screens , to increase visibility on how the employed workers are behaving .",
    "the impact of the so - called attention - check questions ( trick questions inserted in a task in order to test the worker s attention ) is analyzed in  @xcite , where it is concluded that such questions are useful only for low - reliability workers and may be counter - productive for high - reliability workers",
    ". workers quality control can be partly automated , and made more effective by employing machine - learning techniques like reinforcement learning  @xcite .",
    "finally , regarding workers organization ,  @xcite presents a comprehensive literature survey on human resource management in crowdsourcing systems .",
    "task assignment and reputation are central to this paper , where we discuss optimal task assignment with approximate information about the quality of answers generated by workers ( with the term `` worker reputation '' we generally mean the worker earnestness , i.e. , the credibility of a worker s answer for a given task , which we will quantify with an error probability ) .",
    "our optimization aims at minimizing the probability of an incorrect task solution for a maximum number of tasks assigned to workers , thus providing an upper bound to delay and a lower bound on throughput .",
    "a dual version of our optimization is possible , by maximizing throughput ( or minimizing delay ) under an error probability constraint .",
    "like in most analyses of crowd work systems , we assume no interdependence among tasks , but the definition of workflows and hierarchies is an obvious next step .",
    "both these issues ( the dual problem and the interdependence among tasks ) are left for further work .",
    "the goal of this paper is to provide the first systematic analysis of the potential benefits deriving from some form of a - priori knowledge about the reputation of workers , extending the results of our preliminary work  @xcite . with this goal in mind , first we define and analyze the task assignment problem when workers reputation estimates are available . in particular , we suppose that available workers are divided into classes , each of which represents a different reliability level . under this hypothesis",
    ", we show that in some cases , the task assignment problem can be formalized as the maximization of a monotone submodular function subject to matroid constraints . a greedy algorithm with performance guarantees",
    "is then devised .",
    "in addition , we propose a simple  maximum a - posteriori ",
    "( map ) decision rule , which is well known to be optimal when perfect estimates of workers reputation are available .",
    "moreover , we introduce a message - passing decision algorithm , which is able to encompass a - priori information about workers reputation , thus improving upon the one described in @xcite .",
    "finally , our proposed approach is tested in several scenarios , and compared to previous proposals .",
    "our main findings are :    * even largely inaccurate estimates of workers reputation can be effectively exploited in the task assignment to greatly improve system performance ; * the performance of the maximum a - posteriori decision rule quickly degrades as worker reputation estimates become inaccurate ; * when workers reputation estimates are significantly inaccurate , the best performance can be obtained by combining our proposed task assignment algorithm with the message - passing decision algorithm presented in this paper ; *   there is no need for a large number of refined classes , i.e. , a coarse quantization of individual reputations already achieves most of the related gain .",
    "we consider @xmath2 binary tasks @xmath3 , whose outcomes can be represented by i.i.d .",
    "uniform random variables ( rv s ) @xmath4 over @xmath5 , i.e. , @xmath6 , @xmath7 . in order to obtain a reliable estimate of task outcomes",
    ", a requester assigns tasks to workers selected from a given population of size @xmath8 , by querying each worker @xmath9 , @xmath10 a subset of tasks .",
    "each worker is modeled as a binary symmetric channel ( bsc ) @xcite .",
    "this means that worker @xmath9 , if queried about task @xmath11 , provides a wrong answer with probability @xmath12    , @xmath13 $ ] , and a correct answer with probability @xmath14 .",
    "the error probabilities @xmath12 are taken to be time - invariant and generally unknown to the requester .    *",
    "remark 1 * in practice , @xmath12 can be estimated by analyzing the workers performance during previous task assignments .",
    "however how to estimate @xmath12 is out of the scope of this work .",
    "* remark 2 * we assume that the task allocation process works in one - shot . more precisely , at time @xmath15 the allocation algorithm submits all tasks to workers on the basis of the reputation they have at that time .",
    "therefore , possible time variations of the workers reputation do not affect task allocation .",
    "also , tasks are assumed to be evaluated by workers in a short amount of time .",
    "therefore workers error probabilities , @xmath16 , are not expected to significantly vary during the process .",
    "an analysis of the system performance in the presence of time variations of workers reputations would require models and algorithms for building reputation on the basis of previously assigned tasks . however , our scope is not to investigate how these reputations can be built , rather to assess how reputation can be exploited by task allocation and decision algorithms .    by making these assumptions ,",
    "we avoid modeling the workers behaviour as driven by latent motivations , as in , e.g. ,  @xcite . in particular",
    ", we do not deal with malicious workers ( for which @xmath17 ) . as a matter of fact , a worker that always outputs the wrong answer provides as much information to the aware requester as a worker that answers correctly all the times .",
    "we also assume that @xmath18 depends on both the worker and the task , a fact that    reflects the realistic consideration that tasks may have different levels of difficulty , that workers may have different levels of accuracy , and may be more skilled in some tasks than in others  @xcite .",
    "similarly to @xcite , we assume in this paper that , thanks to a - priori information , the requester can group workers into _ classes _ , each one composed of workers with similar accuracy and skills . in practical crowd work systems , where workers are identified through authentication , such a - priori information can be obtained at no cost by observing the results of previous task assignments : this is the case of the approval rating in mturk , for example .",
    "more precisely , we suppose that each worker belongs to one of @xmath19 classes , @xmath20 , and that each class is characterized , for each task , by a different representative error probability , known to the requester .",
    "let @xmath21 be the representative error probability for class @xmath22 and task @xmath11 , @xmath23 , @xmath7 .",
    "in practice , classes may derive from a quantization of estimated individual error probabilities .",
    "the reason of dealing with classes , instead of individuals , stems from the fact that @xmath12 is estimated heuristically and thus it is affected by inaccuracy . because of that , sacrificing precision should not entail a major performance loss , while it simplifies the task allocation phase",
    ". this intuition will be confirmed in section  [ sec : results ] .",
    "most times , in the following , we will deal with a case where @xmath21 is the _ average _ error probability of workers belonging to class @xmath1 .",
    "this allows to abstract from the practical way in which classes are built .",
    "in particular our class characterization encompasses two extreme scenarios :    * full knowledge about the reliability of workers , i.e. , each worker belonging to class @xmath22 has error probability for task @xmath11 deterministically equal to @xmath21 , and * a hammer - spammer ( hs ) model  @xcite , in which perfectly reliable and completely unreliable users coexists within the same class .",
    "a fraction @xmath24 of workers in class @xmath22 , when queried about task @xmath11 , has error probability equal to @xmath25 ( the spammers ) , while the remaining workers have error probability equal to zero ( the hammers ) .",
    "note that this is an artificial scenario , where the variance within a single class is pushed to the limit , thus allowing to test the robustness of our task assignment algorithm to a very unfavorable class composition .",
    "suppose that class @xmath22 contains a total of @xmath26 workers , with @xmath27 . the first duty the requester has to carry out is the assignment of tasks to workers .",
    "we impose the following two constraints on possible assignments :    * a given task @xmath11 can be assigned at most once to a given worker @xmath9 , and * no more than @xmath28 tasks can be assigned to worker @xmath9 .",
    "notice that the second constraint arises from practical considerations on the amount of load a single worker can tolerate .",
    "we also suppose that each single assignment of a task to a worker has a _ cost _ , which is independent of the worker s class .",
    "in practical microtask - based crowdsourcing systems , such cost represents the low wages per task the requester pays the worker , in order to obtain answers to his queries . in this work",
    ", we assume the same cost for all workers , although it may appear more natural to differentiate wages among different classes , so as to incentivize workers to properly behave  @xcite . our choice , however , is mainly driven by the following two considerations : i ) while it would be natural to differentiate wages according to the individual reputation of workers ,",
    "when the latter information is sufficiently accurate , it is much more questionable to differentiate them according to only a collective reputation index , such as @xmath21 , especially when workers with significantly different reputation coexist within the same class ; ii ) since in this paper our main goal is to analyze the impact on system performance of a - priori available information about the reputation of workers , we need to compare the performance of such systems against those of systems where the requester is completely unaware of workers reputation , under the same cost model .",
    "finally , we wish to remark that both our problem formulation and proposed algorithms naturally extend to the case in which costs are class - dependent .",
    "let an _ allocation _ be a set whose elements are @xmath29 is also denoted by @xmath30 .",
    "] of assignments of tasks to workers .",
    "more formally , we can represents a generic allocation with a set @xmath31 of pairs @xmath32 with @xmath33 and @xmath34 , where every element @xmath35 corresponds to an individual task - worker assignment .",
    "let @xmath36 be the complete allocation set , comprising every possible individual task - worker assignment ( in other words @xmath36 is the set composed of all the possible @xmath37 pairs @xmath32 ) .",
    "of course , by construction , for any possible allocation @xmath31 , we have that @xmath38 .",
    "hence , the set of all possible allocations corresponds to the power set of @xmath36 , denoted as @xmath39 .",
    "the set @xmath31 can also be seen as the edge set of a bipartite graph where the two node subsets represent tasks and workers , and there is an edge connecting task node @xmath15 and worker node @xmath40 if and only if @xmath41 .",
    "it will be sometimes useful in the following to identify the allocation with the biadjacency matrix of such graph .",
    "such binary matrix of size @xmath42 will be denoted @xmath43 , @xmath44 and referred to as the _ allocation matrix_.    in this work , we suppose that the allocation is non - adaptive , in the sense that all assignments are made before any decision is attempted . with this hypothesis",
    ", the requester must decide the allocation only on the basis of the a - priori knowledge on worker classes .",
    "because of this one - shot assumption , both individual and class error probabilities are considered to be constant over time , as well as constant is the mapping between workers and classes .",
    "adaptive allocation strategies can be devised as well , in which , after a partial allocation , a decision stage is performed , and gives , as a subproduct , refined a - posteriori information both on tasks and on workers accuracy .",
    "this information can then be used to optimize further assignments . however , in @xcite it was shown that non - adaptive allocations are order optimal in a single - class scenario .    when all the workers answers are collected , the requester starts deciding , using the received information .",
    "let @xmath45 be a @xmath46 random matrix containing the workers answers and having the same sparsity pattern as @xmath47 .",
    "precisely , @xmath48 is nonzero if and only if @xmath49 is nonzero , in which case @xmath50 with probability @xmath51 and @xmath52 with probability @xmath16 . for every instance of the matrix @xmath53",
    "the output of the decision phase is an estimate vector @xmath54 $ ] for task values . in the following , for notation simplicity",
    "we will drop the dependence of the matrices @xmath55 and @xmath56 and of the estimates @xmath57 on the allocation set @xmath31 , except when needed for clarity of presentation .     as a final justification of the model described in this section ,",
    "we describe here a _ modus operandi _ for a microtask - based crowdsourcing system like mturk , that would be well modeled by our assumptions .",
    "suppose the platform first calls for a prequalification with respect to a given set of tasks .",
    "after the due number of workers have applied , this first phase is closed , and the crowd of potential workers is formed . in the second phase , such crowd is partitioned into classes according to reputation , and actual task assignment to ( a subset of ) applicants takes place .",
    "finally , answers are collected and decisions are taken .",
    "in this section , we formulate the problem of the optimal allocation of tasks to workers , with different possible performance objectives . we formalize such problem under the assumption that each worker in class @xmath22 has error probability for task @xmath11 deterministically equal to @xmath58 . by sorting the columns ( workers ) of the allocation matrix @xmath55",
    ", we can partition it as @xmath59\\ ] ] where @xmath60 is a binary matrix of size @xmath61 representing the allocation of tasks to class-@xmath1 workers .",
    "we define @xmath62 as the weight ( number of ones ) in the @xmath15-th row of matrix @xmath60 , which represents the number of times task @xmath15 is assigned to class-@xmath1 workers .",
    "such weights can be grouped into the @xmath63 matrix of integers @xmath64 . + * remark .",
    "* if the individual error probability of the workers within one class is not known to the scheduler , it becomes irrelevant which worker in a given class is assigned the task .",
    "what only matters is actually how many workers of each class is assigned each task . under this condition    1 .",
    "any performance parameter to be optimized can be expressed as a function of the weight matrix @xmath65 ; 2 .",
    "any two allocation sets @xmath66 and @xmath67 such that @xmath68 show the same performance ; 3 .   by optimizing the weight matrix @xmath69 we also optimize the set of allocations @xmath31 .",
    "we formulate the problem of optimal allocation of tasks to workers as a combinatorial optimization problem for a maximum overall cost .",
    "let @xmath70 be a given performance parameter to be maximized .",
    "we fix the maximum number of assignments ( i.e. , the maximum number of ones in matrix @xmath55 ) to a value @xmath71 , and we seek the best allocation @xmath31 as @xmath72 where @xmath62 are the ( integer ) elements of @xmath69 , @xmath73 and @xmath74 . the second constraint in",
    "expresses the fact that @xmath62 is the number of ones in the @xmath15-th row of @xmath60 , the third constraint derives from the maximum number of tasks a given worker can be assigned , and the last constraint fixes the maximum overall cost .",
    "note that it could also be possible to define a dual optimization problem , in which the optimization aims at the minimum cost , subject to a maximum admissible error probability ; this alternative problem is left for future work .",
    "we now denote by @xmath75 the family of all feasible allocations ( i.e. the collection of all the allocations respecting the constraints on the total cost and the worker loads ) .",
    "observe that by construction @xmath76 is composed of all the allocations @xmath31 satisfying : i ) @xmath77 , and ii ) @xmath78 @xmath79 , where @xmath80 represents the set of individual assignments in @xmath31 associated to @xmath40 .",
    "[ prop - matroid ] the family @xmath75 forms a matroid  @xcite .",
    "furthermore , @xmath75 satisfies the following property .",
    "let @xmath81 be the family of maximal sets in @xmath75 , then @xmath82 .",
    "the proof is reported in the appendix [ app : matroid ] .",
    "the complexity of the above optimal allocation problem heavily depends on the structure of the objective function @xmath70 ( which when specifying the dependence on the allocation set @xmath31 can be rewritten as @xmath70 ) . as a general property ,",
    "observe that necessarily @xmath70 is monotonic , in the sense that @xmath83 whenever @xmath84 .",
    "however , in general , we can not assume that @xmath70 satisfies any other specific property ( some possible definitions for @xmath70 are given next ) .",
    "for a general monotonic objective function , the optimal allocation of tasks to workers can be shown to be np - hard , since it includes as a special case the problem of the maximization of a monotonic submodular function , subject to a uniform matroid constraint ( see  @xcite ) is said to be submodular if : @xmath85 we have @xmath86 .",
    "the problem of the maximization of a monotonic submodular function subject to a uniform matroid constraint corresponds to : \\{@xmath87 for @xmath88 with @xmath89 submodular . } ] .",
    "when @xmath70 is submodular , the optimal allocation problem falls in the class of problems related to the maximization of a monotonic submodular function subject to matroid constraints . for such problems , it has been proved that a greedy algorithm yields a 1/(1+@xmath90)-approximation  @xcite ( where @xmath90 is defined as in proposition [ prop - matroid ] ) . in the next subsections",
    ", we consider different choices for the performance parameter @xmath70 .",
    "a possible objective of the optimization , which is most closely related to typical performance measures in practical crowd work systems , is the average task error probability , which ( except for the minus sign , which is due to the fact that we need to minimize , rather than maximize , error probability ) is defined as : @xmath91 where @xmath92 is the error probability on task @xmath15 and where the second equality in   follows from the fact that tasks are uniformly distributed in @xmath93 .",
    "note that the probabilities @xmath94 , @xmath95 depend on the allocation set @xmath31 through the vector of task estimates @xmath57 .",
    "of course , @xmath94 can be exactly computed only when the true workers error probabilities @xmath16 are available ; furthermore it heavily depends on the adopted decoding scheme . as a consequence , in general , @xmath94 can only be approximately estimated by the requester by confusing the actual worker error probability @xmath16 ( which is unknown ) with the corresponding average class error probability @xmath58 . assuming a maximum - a - posteriori ( map )",
    "decoding scheme , namely , @xmath96 , where @xmath97 is the @xmath15-th row of @xmath56 and @xmath98 is its observed value , we have @xmath99 it is easy to verify that the exact computation of this average task error probability estimate requires a number of operations growing exponentially with the number of classes @xmath19 . thus ,",
    "when the number of classes @xmath19 is large , the evaluation of ( [ eq : error_probability_task_i ] ) can become critical .    to overcome this problem , we can compare the performance of different allocations on the basis of a simple pessimistic estimate of the error probability , obtained by applying the chernoff bound to the random variable that is driving the maximum - a - posteriori ( map ) decoding ( details on a map decoding scheme are provided in the next section ) .",
    "we have : @xmath100 where @xmath101 .",
    "thus , the performance metric associated with an allocation becomes @xmath102 .",
    "the computation of @xmath103 requires a number of operations that scales linearly with the product @xmath104 .",
    "however , in practical cases , we expect the number of classes to be sufficiently small ( order of few units ) , so that the evaluation of ( [ eq : error_probability_task_i ] ) is not an issue .",
    "an alternative information - theoretic choice for @xmath70 is the mutual information between the vector of rvs associated with tasks @xmath105 and the answer matrix @xmath53 , i.e. , [ eq : mutual_info ] _",
    "3(g ) = i(*a * ; ) = _ t=1^t i(*a*_t ; _ t ) .",
    "it is well known that a tight relation exists between the mutual information and the achievable error probability , so that a maximization of the former corresponds to a minimization of the latter .",
    "we remark , however , that , contrary to error probability , mutual information is independent from the adopted decoding scheme , because it refers to an optimal decoding scheme .",
    "this property makes the adoption of mutual information as the objective function for the task assignment quite attractive , since it permits to abstract from the decoding scheme .",
    "the second equality in ( [ eq : mutual_info ] ) comes from the fact that tasks are independent and workers are modeled as bscs with known error probabilities , so that answers to a given task do not provide any information about other tasks . by definition [ eq : mutual_info_definition ] i(*a*_t ; _ t )",
    "= h(*a*_t ) - h(*a*_t | _ t ) = h(_t ) - h(_t |*a*_t ) where @xmath106 denotes the entropy of the rv @xmath107 , given by denotes the expectation with respect to rv @xmath107 . ]",
    "@xmath108 $ ] and for any two random variables @xmath109 , @xmath110 is the conditional entropy defined as @xmath111 $ ] . in what follows , we assume perfect knowledge of worker reliabilities , i.e. , we assume that each class-@xmath1 worker has error probability with respect to task @xmath112 exactly equal to @xmath58 , remarking that in the more general case , the quantities we obtain by substituting @xmath16 with the corresponding class average @xmath58 , can be regarded as computable approximations for the true uncomputable mutual information .",
    "since we have modeled all workers as bscs , each single answer is independent of everything else given the task value , so that [ eq : conditional_entropy_a_given_t ] h(*a*_t | _ t ) = _ a_tw 0 h(a_tw | _ t ) = _",
    "k=1^k d_tk h_b(_tk ) . where @xmath113 .",
    "for the second equality in , @xmath114 because @xmath112 is a uniform binary rv , and @xmath115 where @xmath98 runs over all possible values of @xmath116 .    by symmetry , for every @xmath98 such that @xmath117 , there is @xmath118 such that @xmath119 and @xmath120 .",
    "as a consequence , we can write @xmath121 notice the relationship of the above expression with .",
    "if in we substitute @xmath122 with @xmath123 , thanks to bayes rule , we obtain  .",
    "an explicit computation of @xmath124 can be found in appendix  [ app : mi_computation ] . like for the task error probability ,",
    "the number of elementary operations required to compute @xmath124 grows exponentially with the number of classes @xmath19 .",
    "an important property that mutual information satisfies is submodularity .",
    "this property provides some guarantees about the performance of the greedy allocation algorithm described in section  [ sec : greedy ] .",
    "[ prop - submodularity ] let @xmath31 be a generic allocation for task @xmath125 and let @xmath126 be a random vector of answers for task @xmath125 .",
    "then , the mutual information @xmath127 is a submodular function .    the proof is given in the appendix [ app : submodularity ] .",
    "the previous optimization objectives represent a sensible choice whenever the target is to optimize the _ average _ task performance .",
    "however , in a number of cases it can be more appropriate to optimize the worst performance among all tasks , thus adopting a max - min optimization approach .",
    "along the same lines used in the definition of the previous optimization objectives , we can obtain three other possible choices of performance parameters to be used in the optimization problem defined in , namely , the maximum task error probability , @xmath128 the chernoff bound on the maximum task error probability , @xmath129 and the minimum mutual information , @xmath130 .",
    "as we observed in section [ sec : pf ] , the optimization problem stated in is np - hard , but the submodularity of the mutual information objective function over a matroid , coupled with a greedy algorithm yields a 1/2-approximation  @xcite ( see proposition [ prop - matroid ] ) .",
    "we thus define in this section a greedy task assignment algorithm , to be coupled with the map decision rule which is discussed in the next section .",
    "the task assignment we propose to approximate the optimal performance is a simple greedy algorithm that starts from an empty assignment ( @xmath131 ) , and at every iteration @xmath132 adds to @xmath133 the individual assignment @xmath134 , so as to maximize the objective function .",
    "in other words ; @xmath135 the algorithm stops when no assignment can be further added to @xmath31 without violating some constraint .    to execute this greedy algorithm , at step @xmath132 , for every task @xmath15",
    ", we need to i ) find , if any , the best performing worker to which task @xmath15 can be assigned without violating constraints , and mark the assignment @xmath32 as a candidate assignment ; ii ) evaluate for every candidate assignment the performance index @xmath136 @xmath137 ; iii ) choose among all the candidate assignments the one that greedily optimizes performance .",
    "observe that , as a result , the computational complexity of our algorithm is @xmath138 where @xmath139 represents the number of operations needed to evaluate @xmath70 .",
    "note that in light of both propositions  [ prop - matroid ] and  [ prop - submodularity ] , the above greedy task assignment algorithm provides a @xmath140-approximation when the objective function @xmath141 ( i.e. , mutual information ) is chosen .",
    "furthermore , we wish to mention that a better @xmath142-approximation can be obtained by cascading the above greedy algorithm with the special local search optimization algorithm proposed in  @xcite ; unfortunately , the corresponding cost in terms of computational complexity is rather severe , because the number of operations requested to run the local search procedure is @xmath143 .",
    "is @xmath144 if @xmath145 for any positive constant @xmath146 . ]      here we briefly recall that @xcite proposed a simple task allocation strategy ( under the assumption that workers are indistinguishable ) according to which a random regular bipartite graph is established between tasks and selected workers .",
    "every selected worker is assigned the same maximal number of tasks , i.e. @xmath147 , @xmath79 , except for rounding effects induced by the constraint on the maximum total number of possible assignments @xmath71 .",
    "majority voting is the simplest possible task - decision rule and is currently implemented in all real - world crowd work systems .",
    "for every task @xmath11 , it simply consists in counting the @xmath148 and the @xmath149 in @xmath97 and then taking @xmath150 in accordance to the answer majority . more formally :",
    "[ eq : majority_decision_rule ] _",
    "t(*a*_t ) = ( _ w a_tw ) .      for the case where each class-@xmath1 worker has error probability with respect to task @xmath112 deterministically equal to @xmath58 , the optimal map decision rule can be derived analytically .",
    "indeed , given an observed value of @xmath97 , the posterior log - likelihood ratio ( llr ) for task @xmath112 is @xmath151 where the second equality comes from bayes rule and the fact that tasks are uniformly distributed over @xmath152 , and the third equality comes from modeling workers as bscs .",
    "let @xmath153 be the number of `` @xmath154 '' answers to task @xmath15 from class-@xmath1 workers .",
    "then [ eq : llraposteriori ] _",
    "t(*a*_t ) = _ k=1^k ( d_tk - 2 m_tk ) .",
    "the map decision rule outputs the task solution estimate @xmath155 if @xmath156 and @xmath157 if @xmath158 , that is , [ eq : map_decision_rule ] _",
    "t(*a*_t ) = ( _ t(*a*_t ) ) .    observe that the computation of has a complexity growing only linearly with @xmath19 , and that , according to , each task solution is estimated separately .",
    "note also that , whenever worker reputation is _ not _ known a - priori , the above decision rule is no more optimal , since it neglects the information that answers to other tasks can provide about worker reputation .",
    "the oracle - aided map decision rule is a non - implementable decision strategy which has direct access to the error probabilities @xmath16 of every individual worker for every task .    according to the oracle - aided map decision rule ,",
    "first we compute for every task @xmath11 : [ eq : ollraposteriori ] _",
    "t(*a*_t ) = _ w a_tw .",
    "then , the oracle - aided map decision rule outputs the task solution estimate @xmath155 if @xmath159 and @xmath157 if @xmath160 , that is , [ eq : omap_decision_rule ] _",
    "t(*a*_t ) = ( _ t(*a*_t ) ) .    observe that the oracle - aided map decision rule provides an upper bound to the performance of every implementable decision rule ( i.e. , it gives a lower bound on the error probability ) .",
    "for the sake of comparison , we briefly recall here the low - rank approximation decision rule proposed in  @xcite for the case when : i ) no a - priori information about the reputation of workers is available , ii ) the error probability of every individual worker @xmath40 is the same for every task , i.e. , @xmath161 @xmath162 .",
    "the lra decision rule was shown to provide asymptotically optimal performance under assumptions i ) and ii )  @xcite",
    ".    denote with @xmath163 the leading right singular vector of @xmath56 , the lra decision is taken according to : @xmath164 where @xmath165 the idea underlying the lra decision rule is that each component of the leading singular vector of @xmath56 , measuring the degree of coherence among the answers provided by the corresponding worker , represents a good estimate of the worker s reputation .",
    "another possible suboptimal decision algorithm is based on message passing ( mp ) .",
    "the fundamental idea behind mp is that , if the allocation matrix @xmath55 is sparse , the map algorithm can be well approximated by exchanging locally computed messages , between the nodes of the bipartite graph whose biadjacency matrix is @xmath55 , for a certain number of iterations .",
    "the algorithm is based on the hypothesis that a given worker behaves in the same way for all tasks , i.e. , @xmath166 for all @xmath15 and @xmath40 , so that @xmath167 for all @xmath15 and @xmath1 .",
    "our mp algorithm is an extension of the one described in @xcite , where we take into account the a - priori information about worker classes . in  @xcite it is shown that a particular mp algorithm can be seen as an efficient implementation of the lra decision rule . in such mp algorithm ,",
    "workers are seen as a statistical mixture of a hammer ( @xmath168 ) and a malicious worker ( @xmath169 ) .",
    "initially , the statistical mixture assigns the same weight to both hypotheses , while at each iteration the weights are corrected , strengthening or weakening the hammer hypothesis for each worker according to whether she has answered correctly most tasks or not .",
    "our implementation , instead , assumes a different statistical mixture for each class , and a more complex weight update rule , which is essentially locally optimal .",
    "the details of our implementation follow .    in the considered bipartite graph , nodes are either task nodes or worker nodes .",
    "an edge connects task node @xmath15 to worker node @xmath40 if and only if @xmath170 .",
    "messages are exchanged along the edges .",
    "let @xmath171 be the class which worker @xmath40 belongs to and @xmath172 be the a - priori pdf of the error probability for class @xmath171 .",
    "let @xmath173 and @xmath174 be the messages sent from task node @xmath15 to worker node @xmath40 ( resp . from worker node @xmath40 to task node @xmath15 ) in the @xmath175-th iteration , @xmath176 given the answer matrix @xmath177 , the mp algorithm reads as follows .",
    "* initial condition : * [ eq : initial_pi_mp ] p_tw^(0 ) = _ k(w ) for @xmath176    * output llr : * [ eq : outputllr_mp ] _",
    "t^(l ) = _ w a_tw    * task - to - worker message : * [ eq : task_to_worker_mp ] m_t w^(l ) = _ w w a_tw    * worker - to - task message : * [ eq : worker_to_task_mp ] m_w t^(l ) = p_tw^(l ) = _ 0 ^ 1 p f_tw^(l)(p ) dp , being [ eq : error_prob_pdf_mp ] f_tw^(l)(p ) f_k(w)^(0)(p ) _",
    "t t    it can be seen from   that , at each iteration , task nodes perform the llr computation as in the map decision rule for known workers reputation , similarly to , with the current estimates of workers error probabilities . because of the initialization in , the llr outputs at the first iteration are equal to .",
    "the task - to - worker message in is the _ extrinsic _ llr , i.e. , the one that does not consider the incoming message on the same edge .",
    "the worker - to - task message in is the updated estimate @xmath178 of the error probability @xmath179 of worker @xmath40 .",
    "it is computed as the average with respect to the current pdf @xmath180 for task @xmath15 of @xmath179 , given by .",
    "the details of the derivation of are given in appendix [ app : mp_equation ] .",
    "regarding the a - priori pdf , several choices are possible . in our implementation , we have considered as a - priori pdf @xmath181 the max - entropy distribution  ( * ? ? ?",
    "12 ) over @xmath182 $ ] with a mean equal to @xmath183 , namely [ eq : max_entropy_pdf ] f_k^(0)(p ) e^_k p where @xmath184 is a parameter that depends on the mean @xmath183 . if haldane priors are assumed for all workers , i.e. , [ eq : haldane_pdf ] f_k^(0)(p ) = 12 ( p ) + 12 ( p-1 ) where @xmath185 denotes dirac delta function , then we obtain the simplified mp algorithm whose description can be found in  @xcite .",
    "simulation results will show in many cases the advantage of using instead of , whose performance is essentially the same as the lra decision rule of section [ sec : lra ] .",
    "in this section , except stated otherwise , we evaluate the performance of a system where @xmath186 tasks are assigned to a set of workers , which are organized in @xmath187 classes .",
    "each worker can handle up to 20 tasks , i.e. , @xmath188 , @xmath189 .",
    "we compare the performance of the allocation algorithms and decision rules described in sections  [ sec : allocation ] and  [ sec : decision ] , in terms of achieved average error probability , @xmath190 .",
    "we study the performance of :    * the `` majority voting '' decision rule applied to the `` uniform allocation '' strategy , hereinafter referred to as `` majority uniform '' ; * the `` majority voting '' decision rule applied to the `` greedy allocation '' strategy , hereinafter referred to as `` majority greedy '' ; * the `` low rank approximation '' decision rule applied to the `` uniform allocation '' strategy , in the figures referred to as `` lra uniform '' ; * the `` low rank approximation '' decision rule applied to the `` greedy allocation '' strategy , in the figures referred to as `` lra greedy '' ; * the `` map '' decision rule applied to the `` greedy allocation '' strategy , in the following referred to as `` map greedy '' . * the `` message passing '' decision algorithm applied to the `` greedy allocation '' strategy , in the following referred to as `` mp greedy '' .",
    "* the `` oracle - aided map '' decision rule applied to the `` greedy allocation '' strategy , in the following referred to as `` omap greedy '' .",
    "specifically , for the greedy allocation algorithm , described in section  [ sec : greedy ] , we employed the overall mutual information @xmath141 as objective function .",
    "we consider 4 scenarios characterized by different number of workers , number of classes , and workers error probabilities .",
    "the main system parameters for all scenarios are summarized in table  [ table - param ] .",
    ".main parameters for the three considered scenarios [ table - param ] [ cols=\"<,<,<,<,<,<,<,<\",options=\"header \" , ]     for this reason , when @xmath191 the matrix @xmath56 turns out to have a block diagonal structure , which conflicts with the basic assumption made by lra that matrix @xmath192 $ ] can be well approximated by a rank-1 matrix .",
    "it follows that the rank-1 approximations are extremely inaccurate when applied to the whole matrix @xmath56 and thus provide high error probabilities . in such situations , by applying the lra algorithm separately on each block of tasks ( under the assumption that we have enough a - priori information to partitioning tasks into groups ) ,",
    "we achieve huge performance gains .",
    "finally , we want to remark that we have tested several versions of greedy algorithms under different objective functions , such as @xmath193 , @xmath103 , and @xmath141 , finding that they provide , in general , comparable performance . the version employing mutual information was often providing slightly better results , especially in the case of lra greedy and mp greedy .",
    "this can be attributed to the following two facts : i ) the mutual information was proved to be submodular ; ii ) being mutual information independent from the adopted decoding scheme , it provides a more reliable metric for comparing the performance of different task allocations under the lra decoding scheme with respect to the error probability @xmath193 ( which , we recall , is computed under the assumption that the decoding scheme is map ) .",
    "unfortunately , due to the lack of space , we can not include these results in the paper .",
    "now , we move to a different scenario in which @xmath186 identical tasks are assigned to a population of 90 workers , each one characterized by an individual reliability index @xmath194 .",
    "@xmath194 are uniformly and interdependently extracted in the range @xmath195 $ ] .",
    "parameters @xmath194 are assumed , in general , to be unknown to the system , which possesses just noisy estimates @xmath196 of them .",
    "such estimates are typically inferred from the analysis of past behavior of each worker , as better explained in the following . on the basis of @xmath196 , workers are grouped into @xmath19 classes .",
    "specifically , classes are obtained by uniformly partitioning the interval @xmath197 $ ] in @xmath19 subintervals and assigning to class @xmath198 all the workers whose estimated reliability index ( error probability ) @xmath196 falls in the range @xmath199 $ ] .",
    "then , the nominal error probability @xmath58 assigned to class @xmath1 , is set equal to the median point of he considered interval , i.e. , @xmath200 .",
    "fig  [ fig : figure4a ] reports the error probability achieved by the lra - greedy algorithm vs @xmath201 for different values of @xmath19 in a optimistic scenario , in which perfect estimates of reliability indices are known to the system , i.e. , @xmath202 .    as expected , by increasing @xmath19 , a reduction of the error probability is observed .",
    "however note that performance improvements are significant only for relatively small values of @xmath19 and @xmath201 .",
    "the marginal performance gain observed by increasing @xmath19 from 6 to 9 , is rather limited for all values of @xmath201 .",
    "even in this ideal case in which full information on workers characteristics is available to the systems , scheduling tasks just on the basis of a rough classification of the workers into few classes is not particularly penalizing !",
    "these results , therefore , provide an empirical justification of our approach of partitioning users into few classes .    to complement previous results , fig .  [ fig : figure4b ] reports the error probability for specific values of @xmath201 and @xmath203 when the reliability estimate @xmath196 is noisy . to keep things simple , we assume that all workers are tested on an initial number of tasks ( called training tasks ) and @xmath196 is derived accordingly , as the empirical estimate of @xmath194 on the training tasks .",
    "however , we wish to remark that @xmath196 can be , in principle , obtained by analyzing answer of workers on previously assigned tasks without the necessity of subjecting workers to an initial training phase . once again",
    ", we would like to highlight that a detailed investigation of how @xmath196 can be obtained goes beyond the scope of this paper .",
    "observe that when the number of training task is 0 , no information about @xmath196 is available and , therefore , workers are assigned to classes at random .",
    "instead , when the number of training tasks becomes arbitrarily large , the system can count on exact estimates of the workers reliability indices .",
    "i.e. , @xmath204 .    , in scenario 4 . ]",
    "figure  [ fig : figure4b ] shows that even rather imprecise estimates of @xmath196 ( i.e. , obtained through the analysis of relatively short sequences of training tasks ) can be effectively exploited to significantly improve the performance of the system .",
    "furthermore , observe that marginal gains significantly reduces as the length of training set increases .",
    "in particular , for moderate values of @xmath201 , performance obtained when the training set size is set to 100 is hardly distinguishable from that observed when arbitrarily long training sets are employed .",
    "this provides further support to the viability of our approach , which appears rather robust to possibly imprecise estimates of workers reliability indices .",
    "in this paper we have presented the first systematic investigation of the impact of information about workers reputation in the assignment of tasks to workers in crowd work systems , quantifying the potential performance gains in several cases .",
    "we have formalized the optimal task assignment problem when workers reputation estimates are available , as the maximization of a monotone ( submodular ) function subject to matroid constraints .",
    "then , being the optimal problem np - hard , we have proposed a simple but efficient greedy heuristic task allocation algorithm .",
    "we have also described a simple  maximum a - posteriori  decision rule and a well - performing message - passing decision algorithm .",
    "we have tested our proposed algorithms , and compared them to different solutions , which can be obtained by extrapolating the proposals for the cases when reputation information is not available , showing that the crowd work system performance can greatly benefit from even largely inaccurate estimates of workers reputation .",
    "our numerical results have shown that :    * even a significantly imperfect characterization of the workers reputation can be extremely useful to improve the system performance ; * the application of advanced joint task decoding schemes such as message passing can further improve the overall system performance , especially in the realistic case in which the a - priori information about worker reputation is largely affected by errors ; * the performance of advanced joint tasks decoding schemes such as lra applied naively may become extremely poor in adversarial scenarios . *   the results show that `` lra greedy '' and `` mp greedy '' algorithms perform well in most of the cases ; their difference in terms of performance is rather limited , therefore they can both be used equivalently in a real - world scenario .",
    "future work directions include the extension to time - varying workers behavior , non - binary tasks , and the desing of effective algorithms for estimating workers error probability .    99    m .- c .",
    "yuen , i. king , and k .- s .",
    "leung , `` a survey of crowdsourcing systems , '' ieee passat - socialcom , boston ( ma ) , usa , oct .",
    "911 , pp.766773 , 2011 .",
    "d. e. difallah , m. catasta , g. demartini , p. g. ipeirotis , and p. cudr - mauroux , `` the dynamics of micro - task crowdsourcing : the case of amazon mturk '' , _ proceedings of the 24th international conference on world wide web _ , pp . 238247 , 2015 .",
    "a. kittur , j. v. nickerson , m. bernstein , e. gerber , a. shaw , j. zimmerman , m. lease , and j. horton , `` the future of crowd work , '' _ acm cscw , _ san antonio , texas , usa , 2013 .",
    "e. peer , j. vosgerau , and a. acquisti , `` reputation as a sufficient condition for data quality on amazon mechanical turk , '' _ behavior research methods _ , v. 46 , pp .",
    "10231031 .",
    "d. r. karger , s. oh and d. shah , `` budget- optimal crowdsourcing using low - rank matrix approximations , '' _",
    "49th allerton conf . on communication , control , and",
    "computing , _ pp . 284291 , sept.2830 , 2011 .",
    "d. r. karger , s. oh , and d. shah ,  budget - optimal task allocation for reliable crowdsourcing systems ,  _ operations research , _",
    "vol.62 , no.1 , pp.124 , 2014 .",
    "d. r. karger , s. oh , and d. shah ,  efficient crowdsourcing for multi - class labeling ,  sigmetrics perform .",
    "vol.41 , no.1 , pp . 8192 , june 2013 .",
    "a. ghosh , s. kale , and p. mcafee , `` who moderates the moderators ? : crowdsourcing abuse detection in user - generated content , '' 12th acm conf . on electronic commerce , new york ,",
    "ny , usa , pp.167176 , 2011 .",
    "i. abraham , o. alonso , v. kandylas , and a. slivkins ,  adaptive crowdsourcing algorithms for the bandit survey problem , ",
    "http://arxiv.org/abs/1302.3268 .",
    "h. zhang , y. ma , and m. sugiyama , `` bandit - based task assignment for heterogeneous crowdsourcing '' , _ neural computation _ , 2015 .",
    "y. zheng , j. wang , g. li , r. cheng , and j. feng , `` qasca : a quality - aware task assignment system for crowdsourcing applications '' , _ proceedings of the 2015 acm sigmod international conference on management of data _ , pp . 1031 - 1046 , 2015 .",
    "y. bachrach , t. graepel , t. minka , and j. guiver , `` how to grade a test without knowing the answers  a bayesian graphical model for adaptive crowdsourcing and aptitude testing '' , _ arxiv preprint _ ,",
    "arxiv:1206.6386 , 2012 .",
    "v. c. raykar , s. yu , l. h. zhao , g. h. valadez , c. florin , l. bogoni , and l. moy , `` learning from crowds '' , _ the journal of machine learning research _ , v. 11 , pp .",
    "1297-1322 , 2010 .",
    "d. lee , j. kim , h. lee , and k. jung , `` reliable multiple - choice iterative algorithm for cs systems '' , _ in proc . of the 2015 acm sigmetrics international conference on measurement and modeling of computer systems",
    "_ , pp . 205216 , 2015 .",
    "j. whitehill , t .- f .",
    "wu , j. bergsma , j. r. movellan , and p. l. ruvolo , `` whose vote should count more : optimal integration of labels from labelers of unknown expertise '' , _ advances in neural information processing systems _ , pp . 2035-2043 , 2009 .",
    "s. kerr , `` on the folly of rewarding a , while hoping for b '' , _ academy of management journal _ , pp . 769783 , 1975 .",
    "d. chandler , and a. kapelner , `` breaking monotony with meaning : motivation in crowdsourcing markets '' , _ journal of economic behavior & organization _ , pp .",
    "123 - 133 , 2013 .",
    "a. kittur , e.h .",
    "chi , and b. suh , `` crowdsourcing user studies with mechanical turk '' , _ proceedings of the 26th annual sigchi conference on human factors in computing systems - chi 08 _ , pp . 453456 , 2008 .",
    "s. lewis , m. dontcheva , and e. gerber , `` affective computational priming and creativity '' , _ proceedings of the 2011 annual conference on human factors in computing systems - chi 11 _ , pp . 735744 , 2011 .",
    "w. mason , and d.j .",
    "watts , `` financial incentives and the performance of crowds '' , _ proceedings of the acm conference on human computation & crowdsourcing 2009 _ , 2009 .",
    "j. rogstadius , v. kostakos , a. kittur , b. smus , j. laredo , and m. vukovic , `` an assessment of intrinsic and extrinsic motivation on task performance in crowdsourcing markets '' , _ proceedings of the fifth international aaai conference on weblogs and social media _ , 2011 .",
    "shaw , j.j . , horton , and d.l .",
    "chen , `` designing incentives for inexpert human raters '' , _ proceedings of the acm 2011 conference on computer supported cooperative work _ , pp .",
    "275284 , 2011 .    c. j. ho , a. slivkins , s. suri , and j. w. vaughan , `` incentivizing high quality crowdwork '' , _ proceedings of the 24th international conference on world wide web _ , pp . 419429 , 2015 .",
    "e. christoforou , a. fernandez anta , c. georgiou , m. a. mosteiro , and a. sanchez , `` applying the dynamics of evolution to achieve reliability in master - worker computing , '' _ concurrency and computation : practice and experience _",
    "vol.25 , no.17 , pp.23632380 , 2013 .",
    "a. fernandez anta , c. georgiou , and m. a. mosteiro , `` algorithmic mechanisms for internet - based master - worker computing with untrusted and selfish workers , '' ieee ipdps 2010 , atlanta ( ga ) , april 2010 .",
    "a. fernandez anta , c. georgiou , l. lopez , and a. santos , `` reliable internet - based master - worker computing in the presence of malicious workers , '' _ parallel processing letters _ , vol.22 , no.1 , 2012 .",
    "a. singla and a. krause , `` truthful incentives in crowdsourcing tasks using regret minimization mechanisms , '' 22nd international conference on world wide web , rio de janeiro , brazil , may 2013 .",
    "e. kamar and e. horvitz , ",
    "incentives for truthful reporting in crowdsourcing ,  11th international conference on autonomous agents and multiagent systems , valencia , es , pp.1329 - 1330 , june 2012 .",
    "p. donmez , j. g. carbonell , and j. schneider , `` efficiently learning the accuracy of labeling sources for selective sampling , '' 15th acm sigkdd international conference on knowledge discovery and data mining , new york ( ny ) , usa , pp.259 - 268 , june 2009 .",
    "y. zheng , s. scott , and k. deng , `` active learning from multiple noisy labelers with varied costs , '' 2010 ieee 10th international conference on data mining , sydney , australia , dec.1317 , pp.639648 , 2010 .",
    "e. christoforou , a. fernndez anta , c. georgiou , m. a. mosteiro , `` reputation - based mechanisms for evolutionary master - worker computing , '' in _ principles of distributed systems : proc . of the 17th international conference , opodis 2013 ,",
    "nice , france , _ pp .",
    "98113 , 2013 .",
    "u. gadiraju , r. kawase , s. dietze , and g. demartini , `` understanding malicious behavior in crowdsourcing platforms : the case of online surveys '' , _ proceedings of chi _ , 2015 .",
    "m. kokkodis , and p. g. ipeirotis , `` reputation transferability in online labor markets '' , _ management science _ , 2015 .",
    "j. fan , g. li , b. c. ooi , k. l. tan , and j. feng , `` icrowd : an adaptive cs framework '' , _ proceedings of the 2015 acm sigmod international conference on management of data _ , pp . 10151030 , 2015 .",
    "rzeszotarski , and a. kittur , `` instrumenting the crowd : using implicit behavioral measures to predict task performance '' , _",
    "symposium on user interface software and technology - uist 11 _ , 2011 .",
    "rzeszotarski , and a. kittur , `` crowdscape : interactively visualizing user behavior and output '' , _ proc . of the 25th annual acm symposium on user interface software and technology - uist 12 _ , pp . 55-62 , 2012 .",
    "r. buettner , `` a systematic literature review of cs research from a human resource management perspective '' , _ ieee 48th hawaii international conference on system sciences ( hicss ) _ , pp . 46094618 , 2015 .",
    "a. tarable , a. nordio , e. leonardi , and m. ajmone marsan , `` the importance of being earnest in crowdsourcing systems '' , _ ieee infocom _ , hong kong , april 2015 .",
    "t. m. cover and j. m. thomas , `` elements of information theory , '' 2nd ed .",
    ", john wiley , 2005 .",
    "g. calinescu , c. chekuri , m. pl , j. vondrk , `` maximizing a monotone submodular function subject to a matroid constraint , '' _ siam journal on computing , _",
    "vol.40 , no.6 , pp.17401766 , 2011 .",
    "first we recall the definition of a matroid . given a family @xmath75 of subsets of a finite ground set @xmath36 ( i.e. , @xmath205 , @xmath75 is a matroid iff : i ) if @xmath206 , then @xmath207 whenever @xmath208 ; + ii ) if @xmath206 and @xmath207 with @xmath209 , then there exists a @xmath210",
    ".    now we can prove proposition 3.1 .",
    "first , observe that in our case property i ) trivially holds .",
    "then , we show that property ii ) holds too .",
    "given that @xmath209 and since by construction @xmath211 and @xmath212 , necessarily there exists an @xmath213 such that @xmath214 .",
    "this implies that @xmath215 .",
    "let @xmath216 be an individual assignment in @xmath217 .",
    "since by assumption @xmath218 , denoted with @xmath219 , we have that @xmath220 , therefore @xmath221 .    the fact that in our case @xmath222 descends immediately by the fact that necessarily @xmath223 iff either i ) @xmath224 when @xmath225 or ii ) @xmath226 when @xmath227 .",
    "the workers answers about the tasks @xmath228 are collected in the random @xmath229 matrix @xmath53 , defined in section ii of the main document .",
    "the information that the answers @xmath56 provide about the tasks @xmath228 is denoted by @xmath230 where the entropy @xmath106 and the conditional entropy @xmath110 have been defined in section  iii.c of the main document .",
    "we first compute @xmath231 and we observe that , given the tasks @xmath228 , the answer @xmath56 are independent , i.e. , @xmath232 , where @xmath233 is the vector of answers to task @xmath11 from users of class @xmath22 . since @xmath234 has a product form , we obtain @xmath235 .",
    "thanks to the fact that workers of the same class are independent and all have error probability @xmath58 , we can write @xmath236 where @xmath237 and @xmath62 is the number of allocations of task @xmath15 in class @xmath22 .",
    "in conclusion , we get : @xmath238    as for the entropy @xmath239 , we have : @xmath240 where @xmath97 is the vector of answers to task @xmath11 ( corresponding to the @xmath15-th row of @xmath56 ) .",
    "note that @xmath241 , hence @xmath242 and we immediately obtain @xmath243 . the probabilities @xmath244 and @xmath245 are easy to compute .",
    "indeed for @xmath246 we have @xmath247 where @xmath153 is the number of `` @xmath154 '' answers to task @xmath11 from class-@xmath1 workers .",
    "the above formula derives from the fact that workers of the same class are independent and have the same error probability @xmath58 .",
    "similarly @xmath248 the expressions   and   can compactly written as @xmath249 where @xmath250 . since , given @xmath112 , workers are independent , we obtain @xmath251 \\non & = &   \\frac{\\gamma_{tk}}{2 } \\left[\\prod_{k=1}^k b_{tk}^{-m_{tk } } + \\prod_{k=1}^k b_{tk}^{d_{tk}+m_{tk } } \\right ] =   \\frac{\\gamma_{tk}}{2 } f({{\\bf m}}_{t } ) \\nonumber\\end{aligned}\\ ] ] with @xmath252 $ ] and @xmath253 . finally , by using the definition of entropy",
    ", @xmath254 \\non & = & -\\log\\frac{\\gamma_{tk}}{2 } -{\\mathbb{e}}_{{{\\bf a}}_t}f({{\\bf m}}_{t } ) \\non & = & -\\log\\frac{\\gamma_{tk}}{2 } -\\frac{\\gamma_{tk}}{2 }   \\sum_{{{\\bf n } } } f({{\\bf n}})\\log f({{\\bf n}})\\prod_{k=1}^k\\binom{m_{tk}}{n_k}\\non \\label{eq : hat}\\end{aligned}\\ ] ] where @xmath255 $ ] and @xmath256 , @xmath257 .",
    "note that the computation of   is exponential in the number of classes @xmath19 .",
    "let @xmath66 and @xmath67 be two generic allocations for task @xmath125 , such that @xmath258 and @xmath259 . also let the pair @xmath260 .",
    "let @xmath126 be the random vector of answers corresponding to the allocation @xmath31 .",
    "for the sake of notation simplicity in the following we define @xmath261 , @xmath262 , and @xmath263 ( since @xmath264 is a single pair , the answer @xmath265 is scalar )",
    ".    then the mutual information @xmath127 is submodular if @xmath266 we first observe that @xmath267 where in @xmath268 we exploited the fact that the sets @xmath269 , @xmath67 , and @xmath264 are disjoint while in @xmath270 we applied the mutual information chain rule .",
    "similarly we can write @xmath271 by consequence   reduces to @xmath272 by applying to both sides of the above inequality the definition of the mutual information given in the main document , equation ( 7 ) , we obtain @xmath273 since workers are independent we now observe that @xmath274 since @xmath275 only depends on @xmath112 .",
    "therefore   reduces to @xmath276 which holds due to the fact that entropy is reduced by conditioning .",
    "in the @xmath175-th iteration of the mp algorithm , an updated pdf of the error probability of worker @xmath40 , @xmath277 , is computed given the answer matrix @xmath56 and the current posterior probability distribution of task solutions , used as a - priori .",
    "let @xmath278 be the posterior probability distribution for task @xmath15 at iteration @xmath175 .",
    "also , let @xmath172 be the a - priori distribution of the error probability for class @xmath171 which worker @xmath40 belongs to . in the computation of the pdf @xmath180 of @xmath277 , we use _ extrinsic _ information , i.e. , we only use @xmath279 for @xmath280 .",
    "we have , thanks to bayes rule , that [ eq : pr_appd_1 ] f_tw^(l)(p ) f_k(w)^(0)(p ) \\{*a*| p_w = p , \\{_t^(l)(1)}_t t } where [ eq : pr_appd_2 ] \\{*a*| p_w p , \\{_t^(l)(1)}_t t } _",
    "t t \\{a_tw | p_w p , _ t^(l)(1 ) } in both equations above , the omitted factors do not depend on @xmath281 .",
    "now [ eq : pr_appd_3 ]          finally , from the definition of llr , we have [ eq : pr_appd_5bis ] m_t w^(l ) = so that [ eq : pr_appd_6 ] _",
    "t^(l ) ( 1 ) = and [ eq : pr_appd_7 ] _",
    "t^(l ) ( 1 ) - _ t^(l)(- 1 ) = ( ) substituting into , and then back into and , we obtain equation ( 24 ) appearing in the main document ."
  ],
  "abstract_text": [
    "<S> this paper presents the first systematic investigation of the potential performance gains for crowd work systems , deriving from available information at the requester about individual worker reputation . in particular </S>",
    "<S> , we first formalize the optimal task assignment problem when workers reputation estimates are available , as the maximization of a monotone ( submodular ) function subject to matroid constraints . </S>",
    "<S> then , being the optimal problem np - hard , we propose a simple but efficient greedy heuristic task allocation algorithm . </S>",
    "<S> we also propose a simple `` maximum a - posteriori '' decision rule and a decision algorithm based on message passing . finally , we test and compare different solutions , showing that system performance can greatly benefit from information about workers reputation . </S>",
    "<S> our main findings are that : i ) even largely inaccurate estimates of workers reputation can be effectively exploited in the task assignment to greatly improve system performance ; ii ) the performance of the maximum a - posteriori decision rule quickly degrades as worker reputation estimates become inaccurate ; iii ) when workers reputation estimates are significantly inaccurate , the best performance can be obtained by combining our proposed task assignment algorithm with the message - passing decision algorithm .    human - centered computing , human information processing , systems and information theory </S>"
  ]
}