{
  "article_text": [
    "in the last 20 years the _ window _ on our universe has opened to an unprecedented level , allowing us to bridge a large fraction of the gap that existed between observational fields , like astrophysics and cosmology , and more experimental ones , like , for instance , high energy particle physics .",
    "a marked difference between observational and experimental disciplines which is often emphasized is that the former ones usually lack direct control on the object that we wish to study , which is usually not directly accessible to us .",
    "a consequence of this is that , contrary to experimental disciplines ( where we can mostly prepare the system under study to suit our needs and tackle the data acquisition and analysis under what we judge to be the most appropriate and fruitful conditions ) in cosmology and astrophysics we usually do not have this convenience .",
    "the lack of control on the systems under study and on their environments can then result in uncertainties which are usually higher than the ones obtained in experimental situations and make more challenging to single out discrepancies between models and data .",
    "although this stereotype is true to some extent , the situation has now radically changed , as witnessed , for instance , by precision measurements of the cosmic microwave background radiation , or by millisecond pulsar timing .",
    "if it is true that , in general , we have no direct control on the phenomena that take place in our universe , it has nevertheless to be recognized that they are often probing the laws of physics in such extreme situations , as we will never be able to realize in a human controlled experiment .",
    "so , while on the theoretical side we are still struggling to get a unified picture of fundamental interactions at the quantum level , it is undoubted that nowadays this understanding has to also , if not primarily , face the challenge to be consistent with astrophysical and cosmological data , in addition to those provided by human - scale experiments : in this sense , a synergic interplay between large and small scale physics is already a reality .    with this higher perspective in mind , we will more modestly present , in this contribution , an example of how current observations have the potential to constrain emission models for active galactic nuclei .",
    "our emphasis will be on the importance of a solid statistical analysis , a precious approach to obtain a quantitative insight and guide us in challenging and , hopefully , disproving existing models in favor of more refined and realistic ones .",
    "our presentation will try to be reasonably self - contained , in the sense that we will cover all the required topics in what follows : we will , however , not be able to cover them with the required depth , some of which can be obtained starting from the list of references .",
    "we will start in sec .",
    "[ sec : agn ] , summarizing some key facts about the sources that we will consider here , namely active galactic nuclei .",
    "some more details will be given for blazars and their emission models in subsec .",
    "[ sec : blazars ]",
    ". we will then continue with a concise presentation of algorithms for ( least square ) minimization in sec .",
    "[ sec : min ] , to finally introduce a solid standard , which is the levenberg - marquardt approach ( subsec .",
    "[ sec : levmar ] ) .",
    "the problem of statistical significance is then briefly addressed in sec .",
    "[ sec : stasig ] , where the kolmogorov - smirnov test is analyzed ( subsec .  [ sec : kolsmi ] ) : other methods to test how _ bad _ a fit is do exist , but will not be discussed here .",
    "following these prerequisites , sec .",
    "[ sec : mrk421 ] presents details of a recent analysis in which multi - wavelength datasets of the active galactic nucleus markarian  421 where fitted to a given emission model : this section contains three subsections , corresponding to each of the topics that are presented in the three background sections : subsec .",
    "[ sec : sou ] describes the source and the chosen datasets , subsec .",
    "[ sec : chi ] describes the fit algorithm and the fit results , subsec .",
    "[ sec : sta ] describes the statistical significance of the results .",
    "active galactic nuclei are galaxies characterized by a core that appears to be brighter and more energetic than that of other galaxies .",
    "it is , indeed , rather common that the core luminosity competes , or even exceeds , the one of the host galaxy : in some cases it seems that a luminosity of the order of @xmath0 times the one of a standard galaxy can be associated with a region with a linear size significantly smaller than @xmath1pc .",
    "in addition , non - thermal agns emission covers a very broad range of the spectrum .",
    "it is usually believed that the engine at the core of agns is a black - hole with a total mass of millions or billions of solar masses : such an object is called a supermassive black hole . although there is only indirect evidence that this supermassive core ( smc ) is a black hole , there is usually agreement about the fact that the energy necessary to sustain a luminosity as large as the one mentioned above is coming from the infall of surrounding matter onto the smc : this process is generically called accretion",
    ". the details of matter accretion onto the smc are still to be understood .",
    "another striking feature of agns is , in some cases , the presence of two powerful , highly collimated jets that shoot out in opposite directions . the way in which these jets are formed and other fundamental aspects , for instance related to their composition and to the details of the processes involved in the acceleration of particles inside these jets , are also subject of active research .    from this short , qualitative",
    ", introduction it appears that there is still a lot that we have to understand about agns .",
    "nevertheless , several important steps forward have been made and we will concentrate , in what follows , on what we think we do actually understand . from an historical perspective , it is important to recall that what nowadays we call agns comprises a very wide class of extragalactic objects , which observationally can ( and do ) appear very different one from the other .",
    "for this reason , we will report below a standard classification scheme@xcite .",
    "there are several characteristics that can be used to classify agns , and their common ground is that they are not usually found in standard galaxies .",
    "we already mentioned one of them , which is the _",
    "high luminosity_. agns can reach luminosities of the order of @xmath2 , which is @xmath3 times the average luminosity of a galaxy ( intended as the characteristic luminosity of the field galaxy distribution ) .",
    "this is , the apparent luminosity , which is what we see after the radiation emitted has been , for instance , absorbed by the circum - object medium : the intrinsic luminosity could then be even higher .",
    "the energy output is also distinctive , and characterized by a _ broadband continuum emission_. standard galaxies have a spectrum which , at zero - th order can be considered the sum of the black body spectra of all the stars composing the galaxy : since each star spectrum is _ approximately _ a black - body spectrum with characteristic temperature that equals the surface temperature of the star , and since the surface temperature of stars spans a range of about one decade , then a typical galaxy power output is emitted within about one decade of frequency . on the contrary , agns can have a spectrum ranging from the mid - infrared to the hardest x - rays , and such that a narrower frequency band dominating the emission is missing .",
    "agn emission can be moreover characterized by _ prominent emission lines _ , another element of contrast with most standard galaxies .",
    "the broadness of agns spectral lines can be both , i ) very sharp or ii ) present broad wings ( with variability spanning two orders of magnitudes , depending on the source ) .",
    "the emission also presents a marked _ variability _ at high frequencies ( whereas , in the optical band , variability is about 10% on human life timescale ) : there is , nevertheless , a small class of agns ( which will be mainly interested in what follows ) having a much more marked , i.e. with much shorter timescales , variability .",
    "although the _ polarization _ of agns emission is weak , it can be statistically appreciated when compared with that of a standard galaxy : a frequency dependence of polarization is also usually detected .",
    "finally , agns can also be characterized by a strong _ radio emission _ , a phenomenology that has been extensively studied since the beginning of radio astronomical observations .",
    "an agn is a source that presents some ( not necessarily all ) of the above properties .",
    "for instance , the vast majority of agns have a spectrum characterized by a broadband continuum emission , with strong emission lines , some variability and weak polarization .",
    "many of them also present a small angular size . finally , in some cases radio emission has been detected and , occasionally , the variability and the polarization are both strong .",
    "several objects fall within the above definitions and we will see later on that it is possible to devise a tentative unification scheme , the so called _ unified model_. we will come to it after a concise description of the diverse observational phenomenology .    a first kind of objects that shows properties typical of agns are the so - called quasi stellar sources , or _ _ quasar__s . quasars show two evident relativistic jets , but their main characteristic is a very luminous and unresolved nucleus with angular size smaller than the arc - second",
    ". radio emission may be also present , in which case they are called , _",
    "_ radio quasar__s .",
    "quasars without radio emission are instead called _ _ radio quiet quasar__s and they are about @xmath4 times more common than radio quasars .",
    "both radio and radio quiet quasars are found at high redshift and without signs of a surrounding galaxy .    a second kind of objects in the agn class are _ radio galaxies_. radio galaxies are characterized by a radio emission which is thousands times the radio emission of a standard galaxy : the radio emission is also apparent in two lobes , that extend in opposite directions outside a bright radio core , to which they appear to be connected by emission jets . in standard galaxies",
    "the radio emission can be traced to the production of relativistic electrons in supernovae explosions . in radio galaxies , instead",
    ", the radio emission , which is characteristically non - thermal , can be identified with synchrotron emission from ultra - relativistic particles .",
    "the spectrum , which is a broad continuum , is markedly non - thermal also in the optical range , where it especially features superimposed emission lines .    with some properties similar to those of radio quiet quasars , _ seyfert galaxies",
    "_ are also agns , but having a lower luminosity . a further classification within seyfert galaxies",
    "can be made based on their spectrum , that can feature i ) broad band regions as well as narrow lines ( these objects are called seyfert 1 galaxies ) or ii ) only broad lines ( these galaxies are named seyfert 2 ) .",
    "seyfert galaxies are so close to radio quiet quasars that most of the times it is the way in which they are discovered that makes them members of one class or the other : in particular , in presence of a high redshift and the absence of a surrounding galaxy the objects tends to be classified as a quasar , while broad emission cores in known galaxies are usually classified as seyfert galaxies .",
    "finally we come to the last group of objects in the agn family , namely _",
    "blazars_. blazars are the most energetic sources that can be observed in the sky .",
    "they are also characterized by two powerful jets shooting out in opposite directions at relativistic speed : their peculiarity is that we are able to view one of them at a small angle to the object axis ( which is also the jet emission direction ) , which means that the jet is practically pointed at us .",
    "the emission spectrum is extremely broad , from radio to @xmath5 frequencies and allows an additional distinction : i ) when the spectrum is completely missing emission lines we have the , so - called , _ bl lacertae _ ( _ bl lac _ ) _ objects _ , which are radio loud objects with marked variability and strong optical polarization ; ii ) when , instead , the spectrum also features strong broad emission lines in the optical range , we have what are called _ optical violent variable objects _ , which in the radio band look similar to radio quasars .",
    "we will discuss in more detail some features of agns emission , with particular emphasis on blazars , in subsection [ sec : blazars ] . before moving to this topic",
    ", we would like , however , remark that despite their apparent difference form the observational point of view , a unified model to interpret all these observational features has been proposed ; according to this unified model , all the different features of agns are related to the orientation of the source with respect to the observer@xcite .",
    "all agns would then be compact supermassive objects and they would be surrounded by an _ accretion disk _ composed of hot plasma emitting thermal radiation .",
    "the broad emission lines that are detected in some spectra , mostly in the optical range , would be caused by the presence of a toroidal shape region containing dense molecular clouds ( called the _ broad emission lines region _ ) : the broad emission lines region can obscure the view of the central part . at a larger distance from the central object",
    "there is also a _ narrow emission lines region _ also filled with molecular clouds but of density lower than the one present in the broad emission lines region . in a direction perpendicular to the plane of the accretion disk and in opposite directions ,",
    "two jest of ultra - relativistic particles emerge from the central object and extend several kilo - parsecs away from the core .",
    "as we anticipated this model allows for explanation of the agns phenomenology , once we consider the orientation of the object with respect to the line of sight of the observer .",
    "radio galaxies and seyfert galaxies have the jets nearly orthogonal to the line of sight of the observer : the torus surrounding the core of the object obscures it and reprocesses the radiation coming from the disk and from the broad emission lines region .",
    "the lobes define the region where the jets loose collimation , and both are responsible for a strong radio emission .",
    "a completely different picture of the same model is obtained if we change the orientation so that the jets now point in the direction of the observer s line of sight : now the boosted jet emission pointing directly to the observer is dominating over all the other components , and it is the physics of the jet that is mostly detected . at intermediate angles between the directions in which",
    "the line of sight is perpendicular or parallel to the jets direction , both the central objects and the surrounding regions are seen : these objects are quasars , and their characteristic emission lines are the result of the light coming from both the broad and narrow emission line regions .",
    "we will now provide more details on the emission model , with particular emphasis on blazars .      among the realizations of agns that we have briefly described above a very important role",
    "is played by blazars .",
    "although only in @xmath6 of the cases it is possible to detect a jet structure in agns , a lot of effort has been put in understanding the origin of the jets and the physical processes that allow for particle acceleration in such highly collimated beams .",
    "a full modelling of agns and agns features formation and evolution , is still one of the fundamental open problems in astrophysics ; however , it is currently accepted that jets consist of low entropy flows associated to regions of internal / external shocks , within which the jets dissipate part of their energy . since a relativistic jet that moves in a direction that forms a small angle with the line of sight of the observer",
    "is greatly amplified by _",
    "relativistic beaming _",
    ", blazars observations are an exceptional tool to investigate the nature and properties of agns relativistic jets : indeed blazars emission is dominated by the jet and makes these objects the major extragalactic source of @xmath5-rays , despite the fact that they represent only a minority of the agns population .",
    "two major subclasses can be identified within blazars of the bl lac type : while all of them show a spectral energy distribution ( sed ) with two pronounced bumps , these bumps peak i ) in the infrared the first and around gev frequencies the second or ii ) in the x - ray the first and around tev frequencies the second . in particular , bl lac objects of the first kind are called _ low frequency peaked _ bl lac , while bl lac objects of the second kind are called _ high frequency peaked _ bl lac ( _ hbl _ ) .",
    "it is generally agreed that the low energy peak is produced by synchrotron emission .",
    "models can differ , instead , in the description of the very high energy @xmath5-ray bump , and can be classified in two qualitative different groups : _ leptonic models _ and _ hadronic models_.    leptonic models : :    @xmath7 .",
    "these models explain the very high energy    @xmath5-ray radiation by inverse compton scattering of    photons off relativistic electrons / positrons .",
    "if the scattered photons    are synchrotron photons created by the electrons of the jet , the    models are called _ synchrotron self compton _ ( _ ssc _ ) models ( * ? ? ?",
    "* ;    * ? ? ?",
    "* ; * ? ? ?",
    "if , instead , the scattered photons are _ ambient _",
    "photons or photons coming from the environment , the models are called    _ external inverse compton _",
    "( _ eic _ ) models .",
    "the absence of emission    lines in the blazars spectra seems to favor ssc models .",
    "ssc models can    invoke one region in which the relevant interactions occur ( _ one - zone _    ssc models ) , or be refined to take into account more than one region .    in the following we are going to test a one zone ssc model on a set of    nine simultaneous multi - wavelength seds .",
    "hadronic models : :    @xmath7 . in this case",
    "the models take advantage from the    fact that a proton component in the jet would be subjected to less    synchrotron losses as compared to electrons and could then be    accelerated more efficiently@xcite .",
    "the low energy peak is again    explained by synchrotron radiation , so in these models there is an    electron components that is accelerated together with protons .",
    "the    higher energy bump is instead produced by the interaction of the    accelerated protons with matter and/or ambient photons and or magnetic    fields .",
    "proton induced cascades , that can in turn induce    electromagnetic cascades , and/or proton synchrotron models have also    been considered@xcite .",
    "it is also not excluded that both processes could coexist in the jet@xcite . in",
    "what follows we will be interested in a leptonic model , specifically a one zone ssc model@xcite .",
    "this model has shown a good agreement with hbl broadband emission in both , the ground and excited states@xcite . moreover , in one zone ssc models , since there is only one population of electrons that generates the doubly peaked emission , there is naturally a correlation between the x - ray and the very high energy @xmath5-ray variability .",
    "the emission zone is assumed to be a spherical blob of radius @xmath8 , moving with a bulk lorentz factor @xmath9 in a direction forming an angle @xmath10 with respect to the observer viewing direction .",
    "special relativistic effects can then be described by a single parameter @xmath11 .",
    "the model assumes that the spherical blob region is uniformly filled by electrons with density @xmath12 and by a uniform , tangled , magnetic field @xmath13 .",
    "five more parameters complete the model providing a description of the relativistic electrons spectrum .",
    "this is characterized by a smoothed , broken power - law in @xmath5 , the lorentz factor of the electrons , which is bounded by @xmath14 .",
    "the transition between the two power - laws takes place at @xmath15 .",
    "the energy slope at low and high energies are , respectively , @xmath16 and @xmath17 .",
    "altogether the model has nine free parameters : three of them ( @xmath18 , @xmath8 and @xmath13 ) describe the emitting blob ; the other six ( @xmath16 , @xmath17 , @xmath19 , @xmath20 , @xmath15 , @xmath12 ) describe the energy distribution of the electrons plasma .",
    "it is crucial to realize that only _ simultaneous _ , _ multi - wavelength _ observations allow the determination of all the parameters of the model .",
    "in particular , if we did not have the very high energy @xmath5-ray observations that became available with modern cherenkov telescopes , we would have only knowledge of the synchrotron peak .",
    "this would give us information about the electrons distribution , but not on the other parameters of the model , and certainly it would not help us to remove , for example , the residual degeneracy between the intensity of the magnetic field and the electron density .",
    "this simple example already gives an idea of the importance of simultaneous multi - wavelength observations across all the emission spectrum of the object .    to determine the parameters of the model that we just described",
    ", we will use a rigorous statistical approach , by fitting the ssc model to several simultaneous multi - wavelength datasets corresponding to different activity states of the source . in this way we will be able to constrain , within some significance level , the ssc model in each emission state",
    "( this is the primary goal of this contribution ) . in turn , this allows also an analysis of the behavior of the parameters of the model in different emission states , a point which is discussed in detail elsewhere@xcite .    before continuing with the analysis anticipated above",
    ", we will introduce in the following sections some basic ideas about non - linear fits and their significance .",
    "in this section we discuss a technique that allows to identify local minima of real valued functions and that we will use in the context of non - linear least squares problems : in particular , our final goal will be to use this technique to minimize the sum of the squares of the deviations between a given set @xmath22 of measured data points ( in which @xmath23 is the uncertainty in the measured quantity @xmath24 and uncertainties in @xmath25 are considered small enough to be neglected ) and a model function @xmath26 that depends from a set @xmath27 of @xmath28 parameters . under suitable assumptions it can be proved@xcite that the optimal values for the parameters according to the observed data can be obtained by minimizing the chi - square function , i.e. @xmath29 ^{2 }      .\\ ] ] when the function @xmath30 is a linear function of the parameters , a closed formula for the minimization of @xmath21 can be obtained .",
    "here we are instead interested in the situation in which @xmath30 is a non - linear function of the @xmath31 .",
    "the minimization process can then be performed numerically in several iterations , the goal of each iteration being to find a perturbation @xmath32 of the current values of the parameters @xmath31 that results in a lower value of @xmath21 .",
    "several methods can be developed to find the values of the parameters @xmath31 that minimize @xmath21 . in view of our final goal , we will concentrate on two of these methods , namely the _",
    "steepest descent method _ and the _ gau - newton _ or _ inverse hessian _ method .      the steepest descent method@xcite is based on the evaluation of the gradient of the objective function ( the @xmath21 in our case ) with respect to the parameters @xmath31 .",
    "the main idea of the method is that the most direct path in the direction of a local minimum is to descend in the direction opposite to the gradient of @xmath21 with respect to the @xmath31 .",
    "the components of the gradient of @xmath21 , i.e. @xmath33 turn out to be @xmath34      .\\ ] ] for later convenience we will set up a more compact matrix notation for the above relation , which is @xmath35 where the gradient is nothing but @xmath36 @xmath37 is the @xmath38-dimensional constant vector of the dependent variable observed data , @xmath39 @xmath40 is the @xmath38 dimensional vector of the dependent variable values estimated according to the model described by @xmath41 , @xmath42 @xmath43 is the @xmath44 diagonal matrix of the weights corresponding to the dependent variable uncertainties in the @xmath38 measurements @xmath45 , @xmath46 and , finally function can be written as @xmath47 ] , @xmath48 is the jacobean matrix of @xmath40 , i.e. , @xmath49 { \\scriptstyle{}j = 1 , \\dots , n } \\hfill \\end{matrix } }      .\\ ] ] a perturbation @xmath50 that updates the parameters in the direction of the steepest descent , i.e. in the direction opposite to the gradient of @xmath21 , can then be obtained as @xmath51 where we used the fact that , since @xmath43 is diagonal , @xmath52 .",
    "@xmath53 is a positive real number that determines the length of the step in the steepest descent direction .",
    "based on the above framework , the steepest descent method consists of a sequence of parameters updates that are always performed in the direction of the steepest descent until a minimum is found with the prescribed accuracy . for simple objective functions",
    "the steepest descent method is recognized as a highly convergent approach to minimization and , when the number of parameters is high or very high , it can be considered as the most reliable , if not the only viable , method .",
    "there are , nevertheless , weak points of this method , especially for complex models : these weak points are substantially related to the fact that the method does not take into account the curvature of the surface which , in our case , is the graphic of the @xmath21 . because of this , it is possible to make too large steps in steep regions or , too small steps in shallow regions : this clearly affects the convergence of the algorithm . at the same time",
    ", particular structures in the @xmath21 surface , as for instance narrow valleys , may also damage convergence . in the case of a narrow valley , for instance",
    ", we would need to move a large step in the direction that points along the flat base of the valley , but only a small one in the direction perpendicular to the valley walls . if it is true that second order information , i.e. the use of curvature information about the @xmath21 surface , would definitely help to improve the method , it is often ( and as we will see later on , in our case in particular ) computationally expensive to access this second order information .",
    "we will see that a good compromise can be found : to this end , we need to first analyze another approach to minimization , which we will do in the following subsection .",
    "another approach that can be used to determine a minimum ( in particular of the @xmath21 function described above ) is the inverse hessian ( or gauss  newton ) method . to give a sound motivation to this approach@xcite",
    "let us first consider a particular case , i.e. the one in which the dependence of the model function from the parameters is linear .",
    "the model function can then be written as @xmath54 where @xmath55 is the vector @xmath56 .",
    "for this linear model @xmath57 and @xmath58 so that @xmath59 the @xmath21 is then a quadratic function of the parameters , @xmath60 and the minimum can be obtained in closed form by algebraically solving for @xmath61 the linear equation @xmath62 which was obtained remembering that , since @xmath43 is diagonal , @xmath63 is an @xmath64 symmetric matrix .",
    "the final result is the minimum point @xmath65 , @xmath66 in this special case ( the model function is linear in the parameters and , thus , the @xmath21 is quadratic in @xmath61 ) we have that i ) @xmath67 is exactly the _ hessian _ of the @xmath21 , ii ) @xmath67 it is a constant matrix ( specifically , constant with respect to @xmath61 ) and iii ) it is possible to write in closed form an exact solution for the minimum .",
    "the inverse hessian method takes advantage of the above result , by using it to deal with the general case , in which the model function is generic .",
    "the way in which this is obtained is by iterating successive steps : in each of them a linear approximation of the model function around the current values of the parameters is used , which results in a quadratic approximation to the @xmath21 .",
    "the exact solution to this linearized model is given by the equation derived just above and will provide us with a new value of the model parameters ; of course , in the fully non - linear case these new values will unlikely realize the @xmath21 minimum , but they might turn out to be a much better approximation to it . by successive steps convergence to the minimum might eventually be achieved .",
    "the advantage of this method , as opposed to the steepest descent method described in the previous subsection , is that we are here using information related to the curvature of the @xmath21 surface that might allow us to reach more quickly the sought minimum . at the same time , if we are not close enough to the minimum , the linearized model will probably not be a good enough approximation of the fully non - linear model .",
    "several steps might be required to arrive close enough to the minimum , where the method is particularly efficient .      as we have discussed in the previous subsections , both the steepest descent method and the inverse hessian method have advantages and disadvantages .",
    "the first of the two , is iteratively trying to converge toward the minimum by updating the parameters as @xmath68 good convergence could be badly affected in situations in which the shape of the @xmath21 surface presents features that require an estimation of quantities related to the surface curvature , which could be the case in proximity of the minimum . the second method , was , also iteratively , trying to converge to the minimum by updating the parameters as @xmath69 good convergence is more likely achieved , in this case , close to the minimum , when a linear approximation to the model function is more appropriate , and the @xmath21 surface , locally , could be well approximated by a paraboloid .    a vantage element , common to both models ,",
    "is that they only require the calculation of the first derivatives of the model function ( out of which @xmath48 is made ) : no second derivatives appear in these methods , which would allow to spare computational time .",
    "also , from the qualitative analysis that we have done of the two methods , they appear to be more effective in complementary situations , the steepest descent being likely efficient far away from the minimum , while the inverse hessian could provide better convergence close to it .",
    "these considerations strongly motivate levenberg proposal@xcite , which is to iteratively update the parameters according to the following rule : @xmath70 where @xmath71 is the @xmath64 identity matrix .",
    "the positive real number @xmath72 is fixed at a small value at the beginning of the computation : it is , then , dynamically adjusted by the algorithm according to the estimated distance from the expected minimum .",
    "when the algorithm estimates to be far from the minimum , @xmath72 is progressively increased so that the contribution of @xmath67 to @xmath73 becomes negligible and the method behaves as the steepest descent one .",
    "on the contrary , when the algorithm estimates to be closer to the expected minimum , the value of the parameter @xmath72 is progressively reduced , until it will be so close to zero that the contribution of @xmath74 to @xmath73 will be negligible and , in all respect , the algorithm will be following an inverse hessian approach .",
    "the quantity that is computed to decide the decrease / increase in @xmath72 is the absolute difference between the value of @xmath21 and the value of its quadratic approximation , with the assumption that this approximation becomes better and better close to the minimum .",
    "following levenberg , marquardt proposed a further refinement of the model@xcite , hence the name of what can nowadays be considered a robust standard for @xmath21 minimization , i.e. the levenberg - marquardt method .",
    "the proposal of marquardt was to use , also during the steps closer to the steepest descent method , part of the information about the curvature of the @xmath21 surface encoded into @xmath67 ( we remark again that @xmath67 is not the hessian of the @xmath21 but it is the hessian of the quadratic approximation to the @xmath21 which is obtained by linearizing the model function ) .",
    "the update rule for the levenberg - marquardt algorithm is , therefore , @xmath75 it is this method that we will apply in the study discussed in section  [ sec : mrk421 ] .",
    "in this section we would like to discuss some selected topics about what are usually called _ goodness of fit tests_. in particular we will concentrate our attention on a particular test , the kolmogorov - smirnov ( ks ) test@xcite .",
    "the ks test can be used to decide if a data sample is coming from a population with a specific distribution , and will be thoroughly discussed in section  [ sec : kolsmi ] . as an introduction to this more specific topic",
    ", we will first recall the general problem . then , in the next subsection , we will describe a standard approach that can be used with binned data .",
    "this will give us the possibility to appreciate some crucial difference ( and advantages ) of the ks test , which will be presented in the last part of this section .",
    "let us consider the case in which we are given two sets of data , say @xmath76 and @xmath77 : we may be interested in quantifying our certainty about the fact that the two sets of data are coming from populations having the same distribution function . to be more precise ,",
    "let us consider the following statement , i.e. the _ null hypothesis _",
    "@xmath78 ,    @xmath78 : :    @xmath79:@xmath80the two sets of data    @xmath76 and    @xmath77 are coming from the same population    distribution function .",
    "we are interested in methods that allow us to _ disprove _ @xmath78 _ to a certain level of confidence _ ; if we can succeed in _ disproving _",
    "@xmath78 , then we will conclude that @xmath76 and @xmath77 are coming from different distributions .",
    "we remark that disproving @xmath78 _ to a certain level of confidence _ is as far as we can go from the statistical perspective and that failure in disproving @xmath78 only shows that at the given _ level of confidence _ it is _ consistent _ to consider the two sets of data as coming from the same distribution . in the general statement",
    "that we are discussing we did not make any assumption about @xmath76 and @xmath77 that , in general , can be coming from two different unknown distributions .",
    "later on , we will be interested in a particular case , namely the one in which one of the two distributions is known . in this case , the null hypothesis will be    @xmath81 : :    @xmath79:@xmath80the set of data    @xmath76 is coming from a population    distributed as @xmath82 .      the first approach that we will describe is an accepted standard to solve the above problem for _ binned _ data@xcite .",
    "let us then consider a binning of the sets of data @xmath83 , @xmath84 , in @xmath85 bins indexed by a set of integers @xmath86 , such data @xmath87 , @xmath84 , is the number of observed points of the @xmath83 data falling in the @xmath88-bin ( the binning intervals are the same for both sets of measurements ) .",
    "we can then construct the following estimator @xmath89      =      \\sum _ { i \\in i \\setminus \\bar{i } }          \\frac { ( r ^{(1 ) } n ^{(1 ) } _ { i } - r ^{(2 ) } n ^{(2 ) } _ { i } ) ^{2}}{n ^{(1 ) } _ { i } + n ^{(2 ) } _ { i } }      , \\label{eq : chisqutwodat}\\ ] ] where @xmath90 is used to exclude from the sum bins for which the corresponding term would not be well defined and the @xmath91 , @xmath92 , are defined according to the following relations : @xmath93 to consider the correct @xmath21 statistics , we also need the number of degrees of freedom , @xmath94 , that can be associated to the test .",
    "this number is @xmath95 , where @xmath85 , from above , is the number of bins , and @xmath96 is the number of independent constraints that have been imposed on the sets of data .    a similar test can be applied to the case in which we have only one set of data , say @xmath76 , and we would like to disprove if @xmath76 is coming from a given distribution @xmath82 .",
    "as before let us consider a binning of @xmath76 data in @xmath85 bins ; again @xmath97 will be the number of @xmath76 data falling in the @xmath88-bin",
    ". we will , moreover , define @xmath98 as the number of data expected in the @xmath88-bin if the data were distributed according to @xmath82 ( of course , @xmath98 does not need to be an integer ) .",
    "if @xmath99 is the set of integers indexing the binning and @xmath100 , we can define the following estimator @xmath101      =      \\sum _ { i \\in i \\setminus \\bar{i } }          \\frac { ( n ^{(1 ) } _ { i } - \\delta _ { i } ) ^{2}}{\\delta _ { i } }      .",
    "\\label{eq : chisquonedat}\\ ] ] we remark that , in this case , there are some potentially not well - defined terms in the sum , i.e. terms corresponding to bins in which @xmath102 and @xmath103 .",
    "these terms mean that , according to the distribution @xmath82 , there are no results expected in the given bin , whereas the observed data _ do _ have occurrences in the bin : this is a simple case in which _ it is disproved _ that the data can be obtained from the distribution @xmath82 . as in the former case the number of degrees of freedom is needed to have the correct @xmath21 statistics . if @xmath104 is the number of parameters required to know the distribution @xmath82 that have been determined from the data , and if the occurrences in each bin that are expected from the model , @xmath98 , are fixed ( and _ not _ renormalized to match the total number of observed points ) then @xmath105 .",
    "if , instead , the constraint @xmath106 is imposed , then @xmath107 .",
    "additional independent constraints that should be present , decrease accordingly the number of degrees of freedom .",
    "wether we are working in the first framework , with two sets of data , or in the second , with only one set of data and a comparison distribution , we end up with an estimator ( @xmath108 $ ] or @xmath109 $ ] respectively ) and an associated number of degrees of freedom @xmath94 . in",
    "what follows we will write briefly @xmath110 $ ] , since our considerations can be applied in the same way to both cases and we wish to explicitly emphasize the dependence from the binning that we had to perform . in both definitions of @xmath110",
    "$ ] the terms in the sums are not individually normal .",
    "however in the limit in which the number of bins , @xmath85 , is large enough , or the number of events in _ each _ bin is large enough , it is standard practice to consider the above defined @xmath110 $ ] as the sum of the squares of @xmath94 _ normal _ random variables of unit variance and zero mean ) is twice the average of @xmath97 and @xmath111 : indeed , since the variance of the difference of two normal variables is the sum of the two individual variances , twice of their average is what is required to obtain for each term of the sum a random variable with unit variance . ] .",
    "the chi - square probability function @xmath112 , i.e. the probability that the sum of the squares of @xmath94 random _ normal _ variables with unit variance and zero mean is greater than @xmath21 , can be used with @xmath113 $ ] to test our null hypothesis .",
    "@xmath112 is defined as @xmath114 and it is tabulated for convenience in statistics textbooks .",
    "the chi - square method we just recalled works with binned data ; although it is always possible to obtain binned data from continuous data , there is often a great deal of arbitrariness in the binning process and it is likely that the outcome of the test will depend on the binning ( a fact which we already emphasized in our notation by writing @xmath115 above ) . at the same time",
    "the chi - square method makes an assumption about the _ normality _ of the data : although this assumption is at the background of many statistical results , it might not be always satisfied and it would be desirable to obtain ways to test the null hypothesis without relying on this assumption .",
    "this turns out to be possible for continuous distribution , and an accepted standard is the kolmogorov - smirnov ( ks ) test , which is discussed in the next subsection .",
    "as we anticipated the ks test can be used for continuous distributions .",
    "it avoids binning , it does not assume normality , and it is based on the concept of empirical cumulative distribution function which we will soon introduce . we will start our analysis by considering the case of @xmath81 , assuming that the results in @xmath76 are the results obtained by sampling @xmath116 independent identically distributed random variables @xmath117 , @xmath118 , distributed according to some unknown distribution @xmath119 .",
    "we will denote by @xmath120 the cumulative distribution function associated with @xmath119 , i.e. @xmath121 .",
    "an _ empirical cumulative distribution function _ is a way to count how many of the observed points can be found below the value @xmath122 , and it is defined as @xmath123 where @xmath124 ` if ` @xmath125 ` is true`@xmath126 and @xmath127 otherwise .",
    "@xmath128 counts the proportion of @xmath76 that can be found below @xmath122 in steps of @xmath129 . by the law of large numbers",
    "it can be seen that the proportion of @xmath76 that can be found below @xmath122 tends to the cumulative distribution function @xmath120 , i.e. @xmath130 we will now prove a first result@xcite .    [ [ proposition . ] ] proposition .",
    "+ + + + + + + + + + + +    _ if @xmath131 is continuous then the distribution of _ @xmath132 _ does not depend on @xmath133_.    [ [ proof . ] ] proof .",
    "+ + + + + +    @xmath134 +    ' '' ''    we are interested in the behavior of the distribution of  ( [ eq : supempcumdisfun ] ) ,",
    "i.e. @xmath135 let us define the function @xmath136 , where @xmath137 because this is the range of @xmath133 , and preliminarily calculate @xmath138 the above expression , contains @xmath139 , which is a uniform distribution on the interval @xmath140 $ ] , because the cumulative distribution function @xmath141 is given by @xmath142 this implies that the random variables @xmath143 , @xmath118 , are independent and uniformly distributed on @xmath140 $ ] , so that we can continue the chain of equalities in  ( [ eq : kolsmipro001 ] ) to obtain @xmath144 in which the last term is independent from @xmath133 .",
    "+ the proof can now be quickly completed by performing a change of variable in  ( [ eq : kolsmipro000 ] ) and then using the result in  ( [ eq : kolsmipro002 ] ) ; we get @xmath145 which shows that  ( [ eq : kolsmipro000 ] ) is independent from p , _ q.e.d._. +    ' '' ''    the above results imply that _ uniformly over _ @xmath146 we have @xmath147 ( i.e. the largest difference between @xmath148 and @xmath133 goes to zero in probability ) and that the distribution of the above supremum does not depend on the _ unknown _ distribution of the sample @xmath76 , i.e. @xmath133 , whenever @xmath133 is continuous .",
    "the final step that motivates the ks test follows from the observation that , given @xmath122 , the central limit theorem implies that @xmath149 converges in distribution to a normal distribution with zero mean and variance @xmath150 ( because this is the variance of @xmath151 ) .",
    "moreover , @xmath152 also converges in distribution , as shown by the following proposition .",
    "[ [ proposition.-1 ] ] proposition .",
    "+ + + + + + + + + + + +    _ the cumulative distribution function of _",
    "@xmath152 is such that @xmath153 where @xmath154 is the cumulative distribution function of the kolmogorov - smirnov distribution .",
    "+    [ [ proof.-1 ] ] proof .",
    "+ + + + + +    @xmath134 +    ' '' ''    the proof of this result will not be given here@xcite .",
    "+    ' '' ''    the net result of the above analysis is that if @xmath155 is the cumulative distribution function of the distribution associated with @xmath81 , then we can consider the statistics @xmath156 which will depend only on @xmath38 and can then be tabulated@xcite .",
    "if @xmath38 is big enough the distribution of @xmath157 is approximated by the kolmogorov - smirnov distribution .",
    "we will now consider what happens if @xmath81 fails , which means that @xmath158 : in this case the empirical cumulative distribution function will converge to @xmath133 , it will then not approximate @xmath155 and for large @xmath38 we will have @xmath159 for some small enough , positive @xmath160 , i.e. @xmath161 this will allow to define a decision rule in the form @xmath162 , where the constant @xmath163 is defined by the significance level and the decision rule can be verified by tabulated values for @xmath157 .    the kolmogorov - smirnov test can also be applied to @xmath78 , where we are interested in understanding if the two sets of data @xmath76 and @xmath77 are coming from the same distribution .",
    "let @xmath164 be the sample of @xmath83 having cumulative distribution function @xmath165 , @xmath166 . if @xmath167 , @xmath166 , are the corresponding empirical cumulative distribution functions , then the two propositions above are also satisfied by the following statistics , @xmath168 to which a similar decision rule as the above can be applied .      in the following we will be interested in determining the statistical significance of fitting observed data points to a highly non - linear model function .",
    "in addition , the model function will depend from several parameters , and , although at the present level of knowledge these parameters are considered independent , the complexity of the physical situation makes it possible that , in more refined models , some of them might show correlations .",
    "in addition to the complex structure of the models , there is the fact that the data points will be spread across several decades ( range of the independent variable ) and will come from different instruments based , not only on different hardware / software , but also on different physical processes for their operation .",
    "it is important under these circumstances to have a check on the goodness of fit . because of the complexity of the situation , the approach that we propose is to perform a kolmogorov - smirnov test on the normality of the residuals obtained after the fitting procedure . in this case",
    "our null hypothesis will be    [ text : nulhyp002]@xmath169 : :    @xmath79:@xmath80the residuals of the non - linear fit    of multi - wavelength data to the spectral energy distribution function    obtained by implementing a given synchrotron self compton model are    normally distributed .    as a final remark",
    ", we remember that there are situations in which the critical values of the test statistics can be difficult to calculate : these include situations in which the samples are of small size and/or the parameters of the distribution are estimated with the same data that are being tested . for the second case a convenient solution is the inclusion of a correction factor , but , in general , the safest way to procede is to use monte carlo [ text : moncar ] methods , for instance to generate , under the fitted distribution , datasets of the same length as the tested one , and use these them to obtain the correct critical values .",
    "as a _ field test _ application of what we have seen in the previous sections , we will now apply the models and techniques introduced above to a concrete case , i.e. the study of the emission properties of the agn markarian  421 , following a recent publication@xcite .",
    "this section will be divided in subsections . in each of them",
    "we will discuss one of the aspects that we have introduced in the sections above and there will be a direct correlation with the subsection number and the section number in which the concepts exemplified in each subsection have been discussed in general .      markarian  421 ( mrk421 ) is the closest blazar ( at a redshift @xmath170 ) and the first extragalactic @xmath5-ray source with emission in the tev range detected by imaging air cherenkov telescopes .",
    "it is , nowadays , the most well known blazar , together with the , also close one , markarian  501 , and falls within the class of hbl objects .",
    "mrk  421 is a source that shows remarkable variability , both in flux variations ( that were observed to change by almost two orders of magnitude ) and time development ( flux doubling was detected on a time scale of the order of 15 minutes@xcite ) .    for our purpose mrk421",
    "is an excellent source , which has been extensively studied across over 19 decades in energy . in particular :    1 .",
    "the ssc emission dominates the detected spectrum , with correlated low - high energy fluctuations ; 2 .",
    "the compton peak is in the range where cerenkov observations are effective ; 3 .   the spectrum can be described as a single power - law .    for the above reasons ,",
    "the one - zone ssc model that we have described in the previous section is a good candidate to describe the sed of this source . at the same time",
    "simultaneous multi - wavelength observations are available , and , among them , it was possible to identify nine , good to very good quality , spectral energy distribution sets of simultaneous data corresponding to different emissions states . the detailed description of the datasets is reported below .",
    "state 1 and state 2 : :    @xmath7 .",
    "the first two datasets that we consider correspond    to multi - wavelength data obtained from campaigns triggered by a major    outburst of mrk421 that was detected by the @xmath171 m    _ whipple _ telescope in april 2006@xcite .",
    "it was unfortunately    impossible to promptly set - up a multi - wavelength campaign because of    some visibility constraints on _ xmm - newton _ ; for this reason    simultaneous observations at different wavelengths were taken during    the decaying phase of the flare .",
    "the optical monitor of xmm - newton was    used to collect optical and ultraviolet data , whereas the epic - pn    detector of the same telescope provided x - ray observations .",
    "very high    energy @xmath5-ray data were collected by _ magic _ and    whipple telescopes .",
    "altogether this resulted in more than 7 hours of    simultaneous observations , about 4 hours of which form the datasets    for state 1 and more than 3 hours the dataset for state 2 .",
    "state 3 : :    @xmath7 .",
    "a third dataset contains multi - wavelength    observations initiated after a detection by the all - sky monitor of the    _ rossi x - ray timing explorer _ and by the @xmath171 m whipple    telescope@xcite .",
    "the observation campaign continued during december    2002 and january 2003 .",
    "the very high energy data was obtained by    whipple between december 4 , 2002 and january 15 , 2003 and by the _",
    "high    energy gamma ray astronomy ct1 _ between november 3 , 2002 and december    12 , 2003 .",
    "however , since our analysis is centered on simultaneous    observations , we have used only the very high energy data taken at    nights during which simultaneous x - ray observations were available .",
    "optical information consists of the average flux obtained from the    _ boltwood observatory _ optical , _ kva _ and _ wiyn _ telescopes .",
    "state 4 and state 9 : :    @xmath7 .",
    "two more datasets are the result of a longer    campaign undertaken during 2003 and 2004@xcite .",
    "the rossi x - ray    timing explorer was used to collect the x - ray flux , that was then    classified into three sets , having low- , medium- and high - flux ,    respectively .",
    "x - ray observations where then complemented by whipple    very high energy @xmath5-ray data , taken within one hour    of the selected x - ray ones .",
    "whipple observatory @xmath172 m    telescope and boltwood observatory @xmath173 m telescope    provided optical data following the same grouping method : although it    was not possible to get optical data simultaneously with the remaining    multi - wavelength data , the fact that minor variations in the optical    flux were detected , allowed to consider its maximum and minimum values    as reliable approximations . in this way it was possible to obtain a    medium flux dataset , corresponding to state 4 , between march 8 and may    3 , 2003 and a high flux dataset , corresponding to state 9 , between    april 16 and 20 , 2004 .",
    "state 5 and state 7 : :    @xmath7 .",
    "another two datasets are the result of a    multi - wavelength campaign that took place between march 18 and march    25 , 2001@xcite .",
    "x - ray data are the results of rossi x - ray timing    explorer observations , whereas the very high energy    @xmath5-ray flux was obtained by the whipple telescope .",
    "state 5 corresponds to a post - flare state during march 22 and 23 , for    which optical information corresponds to the lowest flux detected by    the @xmath172 m harvard - smithsonian telescope on mt .",
    "hopkins .",
    "state 7 is , instead , the high - flux peak of march 19 , also complemented    by optical data from the same instrument as for state 5 , but using the    highest optical flux .",
    "state 6 : :    @xmath7 .",
    "this dataset were taken after an outburst in may    2008 and contains the results of about @xmath174 hours of    simultaneous observations@xcite . as for state 1 and state 2 the    optical monitor of xmm - newton was used to collect optical and    ultraviolet data , whereas the epic - pn detector of the same telescope    provided x - ray observations .",
    "the very high energy    @xmath5-ray flux was in this case obtained by _",
    "veritas_. state 8 : :    @xmath7 .",
    "the last dataset is the result of a dedicated    multi - wavelength campaign on june 6 , 2008@xcite .",
    "optical data was    obtained by _ webt _ , whereas x - ray observations were made by the rossi    x - ray timing explorer and by _ swift_/bat and , finally , very high    energy @xmath5-ray fluxes were taken by veritas .",
    "all sets of data present marked qualitative difference between the optical to x - ray and the very high energy @xmath5-ray ranges : the most striking one is the uncertainties in the measured flux , which is very small when not negligible at low energies , and much sizeable at very high energies .",
    "this observation will play a role in our future discussion on the statistical significance of the fit results . in what follows",
    "we will , first , show how to fit each of these datasets to the chosen ssc model and how to test the goodness of the fit .",
    "an in depth interpretation of the physical conclusions about the source is beyond the scope of this lecture and can be found in the literature@xcite .",
    "the fit algorithm will be an implementation of the levenberg - marquardt method discussed in subsection [ sec : levmar ] .",
    "as this is a standard approach in nonlinear minimization , it is possible to conveniently find code which is optimized and efficient for general problems .",
    "in particular we have used as a starting point the ` mrqmin ` function discussed in ref .  .",
    "this subroutines executes a single minimization step , which is an update step on the parameters as defined in ( [ eq : levmarupdalg ] ) .",
    "implementation details and additional functions called by ` mrqmin ` are described in in ref .   and will not be discussed here , except for the case of the code that is used to evaluate the sed , which we will analyze in more detail in a moment .",
    "the single minimization step performed by ` mrqmin ` ( or by any other implementation of the levenberg - marquardt method ) has to be iterated until convergence to the sought minimum is considered satisfactory .",
    "the flow - chart of the code that we used is reported in fig .",
    "[ fig : minflocha ] . after fixing some trial values for the parameters of the model ( @xmath155 point in parameter space ) and initializing to zero an integer variable , @xmath176 that will count how",
    "many consecutive individual minimization steps have been performed with a negligible improvement in decreasing the @xmath21 , we calculate @xmath177 , i.e. the value of @xmath21 at the initial point @xmath155 in parameter space .",
    "minimization iterations then start : at the beginning we fix the parameter corresponding to @xmath72 in ( [ eq : levmarupdalg ] ) so that we are performing a step in which the steepest descent contribution to the algorithm is dominant .",
    "the new value of @xmath21 at the new point in parameter space @xmath133 determined by the algorithm , @xmath178 , is calculated .",
    "if the @xmath21 did decrease in the step , we check if it decreased by a sizeable amount . if not we increment by one the @xmath176 counter , before increasing the weight of the inverse hessian method and moving to the next iteration . if , instead , the @xmath21 increased at @xmath133 , we increase the importance of the steepest descent method and reset the counter @xmath176 to zero .",
    "the exit condition from the loop is satisfied when @xmath179 .",
    "another crucial parameter that has to be fixed is the threshold , below which we consider negligible the decrease in @xmath21 ( this is called @xmath180 in the flow - chart ) .",
    "it is usually considered that it is unnecessary to determine to machine accuracy or to roundoff limit the minimum of the @xmath21 , as the result provides only a statistical estimation of the parameters anyway . however , in our experience , it is important to pay particular attention in setting the exit condition value of @xmath176 and the negligible @xmath21 increment , @xmath180 .",
    "our experience has shown that the best results were obtained with @xmath179 and @xmath181 . as a further test of the minimization algorithm",
    ", we implemented an additional step : after obtaining the minimum we perform a random change of the parameters and repeat the minimization from this new random point in parameter space .",
    "this could help to identify cases in which minimization remained stuck in a local minimum different from the absolute one , but we never faced this situation , i.e. the additional minimization step did always converge to the result of the first one .",
    "when we choose smaller / larger values for @xmath182 ( for instance , @xmath183 and @xmath184 ) the minimization occasionally provided a result which , on closer inspection , turned out to be a not good approximation to the @xmath21 minimum ( and in more consistent values for the obtained uncertainties on the parameters , a point which we will discuss in more detail later on ) . ] .",
    "this tendency was extremely more marked in presence of datasets having a larger or much larger number of data points : in our experience convergence is usually slower in these cases : a tentative visual representation of some steps in the minimization process is given in fig .",
    "[ fig : minste ] ( for details , please see the related caption ) .",
    "from the point of view of the computation time the levenberg - marquardt algorithm is quite efficient iterations that on a less than average pc ( with a intel core2 duo cpu ( e7500 , @xmath185ghz ) running a x@xmath186_@xmath187 gnu / linux with @xmath183 gb ram ) took about 20 minutes to run . ] and most of the time was required by the derivation of the seds corresponding to the current values of the parameters at each iteration . in our analysis , following a common assumption in the literature , we have fixed @xmath188 ; the redshift of the source is known , so high energy data points can be corrected to take into account interaction with the extragalactic background light .",
    "we are , then , left with eight parameters to be determined by the fit .",
    "according to ( [ eq : levmarupdalg ] ) at each step we need :    @xmath37 : :    @xmath7 : this is just the vector of the observed flux    values , which is clearly known ; @xmath43 : :    @xmath7 : this is the vector of the flux uncertainties , also    known ; @xmath40 : :    @xmath7 : this is the vector of the values of the model sed    evaluated at the observed energy / frequency ; @xmath48 : :    @xmath7 : this is a matrix which is known once the    derivatives of the model sed are known ; @xmath67 : :    @xmath7 : this matrix can be calculated knowing    @xmath43 and @xmath48 .",
    "it is clear that @xmath37 , @xmath43 and @xmath67 do not represent a problem . @xmath40 and @xmath48 in standard cases , where the model function has a known analytical expression , also do not . in our case ( and in several others ) , however , the model sed is not analytically known and what we have is just a discretized sample resulting from a numerical implementation of the ssc model ; it is this last numerical implementation that can be more computationally intensive .",
    "this is especially true since the estimation of @xmath48 requires the seds partial derivatives with respect to the parameters .",
    "then , for each minimization iteration , we have in principle to evaluate a number of seds equal to twice the number of varying parameters plus one . in our implementation",
    "we tried to reduce the load caused by this task by developing a bookkeeping mechanism that caches some of the numerically sampled seds used in the previous steps : this is especially useful when the iteration results in a @xmath21 increase , since in this case , when returning to the previous point in parameter space , the required seds are already available .",
    "_ caching _ optimizes the number of times at which the @xmath21 minimization executable needs to stop and wait for the completion of an external module that , independently , executes the seds evaluation .",
    "[ tab : results01 ]    [ tab : results02 ]    a first study obtained applying the @xmath21 minimization algorithm on the nine datasets described in subsec .  [",
    "sec : sou ] results in the seds plotted in fig .",
    "[ fig : fitsed ] and in the values of the parameters and related uncertainties listed in tables  [ tab : results01 ] and  [ tab : results02 ] .",
    "we are not interested here in a detailed report of the physical conclusions that can be drawn from these results , for which we refer the reader to ref .  .",
    "we will , instead , consider some elements relevant to the statistical analysis .",
    "first , reduced @xmath21 values are reasonable : a couple of cases ( states 5 and 8) might require some additional check , as values are slightly low .",
    "uncertainties in most cases allow to constrain parameters within physically meaningful and expected ranges .",
    "there are some exceptions , in which uncertainties tend to be larger than usually acceptable , like in the case of the magnetic field of state 3 or the blob radius of state 5 and , for most states , the blob electron density . in the cases in which the uncertainties appear to be too high , it is important to remember that these uncertainties are obtained by considering a quadratic approximation to the @xmath21 near the estimated minimum .",
    "this is a good approximation only when the uncertainties are relatively small , because we can not expect the @xmath21 surface to behave as the quadratic approximation far from the minimum .",
    "it might also happen that , because of the nature of the problem / model , the @xmath21 has a much more flat minimum in the direction of some of the parameters . in all these cases",
    "the quadratic approximation might overestimate the uncertainties and it would be preferable to use the criterion that gives the uncertainties as the absolute difference between the minimum value of each parameter at the estimated minimum and the value of the parameter at which the @xmath21 has increased by one .",
    "this definition of the uncertainty in the parameters gives , in general , asymmetric error bars , which can be an additional desirable features in situation in which the uncertainties make parameters that should be positive , compatible with zero or negative values .",
    "apart from the above considerations , the fitted parameters appear compatible with what is expected for this source .",
    "it is however important to consider in more detail the statistical significance of these results by applying some _ goodness of fit _ test , which we will discuss in the following section .      after obtaining the fit parameters ,",
    "we can now proceed with the last step , i.e. discuss their statistical significance . to this end",
    "we will consider , for each of the nine fitted seds , the residuals of the fit , i.e. the differences between the observed points and the value of the fitted sed at the frequency of the observed points .",
    "we then apply the ks test to verify if the residuals are normally distributed ( the @xmath189 null - hypothesis of page  ) .",
    "code for the calculation of the relevant statistics @xmath157 ( cf .",
    "( [ eq : kolsmista ] ) ) is available , for instance in ref .  .",
    "in this study , however , we used the functions that are included in mathematica since version @xmath190 : the reason for this is the fact that these functions already implement a method for the monte carlo approach that we briefly mentioned at the very end of sec .",
    "[ sec : stasig ] on pag .",
    ". a first application of the ks test at the @xmath191 confidence level , shows that the residuals are _ not _ normally distributed , i.e. the ks test fails .",
    "following this result , we applied the ks test again , this time at the @xmath192 confidence level : again the test failed in all cases , showing also at this confidence level that the residuals are not normally distributed    failure of the ks test shows that the statistical significance of the fits should be carefully re - considered . in this case",
    "it might be actually possible to explain the reason for this failure is applied separately to low- and high - energy data ) .",
    "surprisingly enough , in all these cases the ks test confirmed normality of the residuals . further discussion of this point can be found elsewhere@xcite . for our present purpose",
    "this further analysis is not necessary and we will ignore it here . ] , but we will not proceed here in this direction .",
    "we will instead draw a bold conclusion and emphasize the fact that , in absence of other explanations , the failure of the ks test could already bring us to the conclusion that the model might require improvements : existing observations , even in presence of a successful fit with reasonable values for the parameters and for the reduced @xmath21 , could be enough to show the inadequacy of the model .",
    "we could have never reached this result , had we not proceeded through a rigorous statistical approach and we recognize , in this way , the extreme importance of an in depth statistical analysis to put to the best use our models and the related observations .",
    "in this contribution we have discussed all the steps that are required to perform a rigorous statistical analysis on simultaneous multi - wavelength datasets of blazars . although it is challenging to obtain good datasets , because observations are often made difficult by the necessity to have several instruments simultaneously available in absence of observational constraints , we find really exciting to think that such observations ( which probe several order of magnitudes in the source spectrum with different instruments and techniques ) could be already at a good enough level to allow us to discriminate between different emission models .",
    "the importance of a statistical approach is , indeed , two - sided .",
    "on one side it can force us to improve our models , to make them compatible with the data . on the other ,",
    "it can help us to understand how to plan future instruments and observations and efficiently improve , where it is most needed , the quality and amount of the data .",
    "we have finally shown , in the specific case of mrk421 , how this analysis has been applied to a specific problem and how existing data could be already suggesting the need for refinements of the emission model for this source .",
    "the author would like to acknowledge partial support from icranet .",
    "99 recent reviews can be found , for instance , in the introductory parts of r. m. wagner , _ phd thesis _ ( 2006 ) `` measurement of vhe @xmath5-ray emission from four blazars using the magic telescope and a comparative blazar study '' [ also _ publ .",
    "pac . _ * 119 * ( 2007 ) 1201 ] , r. zanin , _ diploma thesis _ ( 2006 ) `` observation and analysis of vhe gamma emission from the agn 1es1959 + 650 with the magic telescope '' , d. mazin , _ phd thesis _ ( 2007 ) `` a study of very high energy gamma - ray emission from agns and constraints on the extragalactic background light '' , and references therein .",
    "c. urry and p. padovani , _ publ .",
    "pac . _ * 107 * ( 1995 ) 803 .",
    "a. p. marscher , w. k. gear , _ apj .",
    "_ * 298 * ( 1985 ) 114 .",
    "l. maraschi , g. ghisellini , a. celotti , _ apj . _",
    "* 397 * ( 1992 ) l5 .",
    "s. d. bloom , a. p. marscher , _ apj . _",
    "* 461 * ( 1996 ) 657 .",
    "f. m. rieger , p. duffy , _ chin .",
    "astroph . _ * 5 * ( 2005 ) 195 .",
    "k. mannheim , p. l. biermann , _ astron .",
    "* 253 * ( 1992 ) l21 .",
    "w. bednarek , _ apj .",
    "_ * 402 * ( 1993 ) l29 .",
    "k. mannheim , _ astron .",
    "astroph . _",
    "* 269 * ( 1993 ) 67 .",
    "a. dar , a. laor , _ apj . _",
    "* 478 * ( 1997 ) l5 .",
    "k. mannheim , _ science _ * 279 * ( 1998 ) 684 .",
    "f. a. aharonian , _ new astronom . _",
    "* 5 * ( 2000 ) 377 .",
    "m. pohl , r. schlickeiser , _ astron .",
    "_ * 354 * ( 2000 ) 395 .",
    "a. mcke , j. protheroe , _ astrop .",
    "* 15 * ( 2001 ) 121 .",
    "a. mcke , _ et al .",
    "_ , _ astrop .",
    "phys . _ * 18 * ( 2003 ) 593 .",
    "m. sikora , g. madejski , g. ghisellini , _ apj .",
    "_ * 534 * ( 2000 ) 109 .",
    "m. georganopoulos , _ et al .",
    "_ , _ apj .",
    "_ * 625 * ( 2005 ) 656 .",
    "f. tavecchio , l. maraschi , g. ghisellini , _ apj . _",
    "* 509 * ( 1998 ) 608 .",
    "f. tavecchio , _ et al .",
    "_ , _ mnras _ * 401 * ( 2010 ) 1570 .",
    "g. tagliaferri , _ et al .",
    "_ , _ apj .",
    "_ * 679 * ( 2008 ) 1029 .",
    "n. mankuzhiyil , _ et al .",
    "_ , _ apj . _",
    "* 733 * ( 2011 ) 14 .",
    "p. r. bevington , d. k. robinson , ( 2003 ) `` data reduction and error analysis for the physical sciences '' , third ed . ,",
    "mcgraw - hill .",
    "k. madsen , n. b. nielsen , o. tingleff , ( 2004 ) _ technical report _",
    ", `` methods for nonlinear least - squares problems '' , informatics and mathematics modelling , technical university of denmark . w. h. press , _ et al . _ , ( 1992 ) `` numerical recipies in c '' , second ed . , cambridge university press .",
    "a. bjrck , ( 1996 ) `` numerical methods for least square problems '' , _ siam _ , philadelfia .",
    "k. levenberg , _ quartely app .",
    "math _ * 2 * ( 1944 ) 164 .",
    "d. w. marquardt , _ siam j. appl",
    "_ * 11 * ( 1963 ) 431 .",
    "a. kolmogorov , _ giornale dellistituto italiano degli attuari _ ,",
    "* 4 * ( 1933 ) 1 .",
    "h. smirnov , _ matematiceskii sborni _",
    ", n.s.*6 * ( 1939 ) 3 .",
    "h. scheff , _ ann .",
    "_ , * 14 * ( 1943 ) 305",
    ". j. wolfowitz , ( 1949 ) in `` proceedings of the berkeley symposium of mathematical statistics and probability '' , berkley , _ university of california press _ , 93 .",
    "f. j. massey jr . , _ j. am .",
    "_ , * 46 * ( 1951 ) 68 .",
    "w. feller , _ ann .",
    "_ , * 19 * ( 1948 ) 177",
    ". j. l. doob , _ ann .",
    "_ , * 20 * ( 1949 ) 343",
    ". m. punch _ et al .",
    "_ , _ nature _ * 358 * ( 1992 ) 477 .",
    "d. petry _ et al .",
    "_ , _ astron",
    ". astroph . _",
    "* 311 * ( 1996 ) l13 .",
    "j. a. gaidos _",
    "_ , _ nature _ * 383 * ( 1996 ) 319 .",
    "v. a. acciari _",
    "_ , _ apj .",
    "_ * 703 * ( 2009 ) 169 .",
    "p. rebillot _",
    "_ , _ apj .",
    "_ * 641 * ( 2006 ) 740 .",
    "m. blazejowski _",
    "_ , _ apj . _",
    "* 630 * ( 2005 ) 130 .",
    "g. fossati _",
    "_ , _ apj .",
    "_ * 677 * ( 2008 ) 906 .",
    "i. donnarumma _",
    "_ , _ apj .",
    "_ * 691 * ( 2009 ) l13 ."
  ],
  "abstract_text": [
    "<S> we discuss the theory and implementation of statistically rigorous fits to synchrotron self compton models for datasets obtained from multi - wavelength observations of active galactic nuclei spectral energy distributions . </S>",
    "<S> the methods and techniques that we present are , then , exemplified reporting on a recent study of a nearby and well observed extragalactic source , markarian  421 </S>",
    "<S> .    statistical study of emission _ versus _ activity of agns    pure logical thinking can not yield us any knowledge of the empirical world : + all knowledge of reality starts from experience and ends in it . </S>",
    "<S> + _ albert einstein , 1954_. </S>"
  ]
}