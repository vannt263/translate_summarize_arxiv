{
  "article_text": [
    "a _ heap _ is a data structure consisting of a set of _ items _ , each with a key selected from a totally ordered universe . heaps support the following operations :    @xmath1",
    ": : :    return a new , empty heap . @xmath2 : :    return an item of minimum key in heap  @xmath3 .",
    "if  @xmath3 is empty , return null .",
    "@xmath4 : : :    return a heap formed from heap  @xmath3 by inserting    item  @xmath5 , with predefined key .",
    "item  @xmath5 must    be in no heap . @xmath6",
    ": : :    return a heap formed from non - empty heap @xmath3 by deleting    the item returned by +    @xmath7 . @xmath8 : : :    return a heap containing all items in item - disjoint heaps    @xmath9 and  @xmath10 . @xmath11 : : :    given that  @xmath5 is an item in heap  @xmath3 with key    no less than @xmath12 , return a heap formed from    @xmath3 by changing the key of  @xmath5    to  @xmath12 .",
    "@xmath13 : :    given that  @xmath5 is an item in heap  @xmath3 , return    a heap formed by deleting @xmath5 from  @xmath3 .",
    "the original heap  @xmath3 passed to @xmath14 , @xmath15 , @xmath16 , and @xmath17 , and the heaps  @xmath9 and  @xmath10 passed to @xmath18 , are destroyed by the operations .",
    "heaps do _ not _ support search by key ; operations  and  are given the location of item  @xmath5 in heap  @xmath3 as part of the input .",
    "the parameter  @xmath3 can be omitted from  and , but then to make  operations efficient one needs a separate disjoint set data structure to keep track of the partition of items into heaps . for further discussion of this see @xcite .",
    "fredman and tarjan @xcite invented the _ fibonacci heap _ , an implementation of heaps that supports  and  on  @xmath19-item heaps in @xmath20 amortized time and each of the other operations in @xmath0 amortized time .",
    "applications of fibonacci heaps include a fast implementation of dijkstra s shortest path algorithm @xcite and fast algorithms for undirected and directed minimum spanning trees @xcite .",
    "since the invention of fibonacci heaps , a number of other heap implementations with the same amortized time bounds have been proposed @xcite .",
    "notably , brodal @xcite invented a very complicated heap implementation that achieves the time bounds of fibonacci heaps in the worst case .",
    "brodal et al .",
    "@xcite later simplified this data structure , but it is still significantly more complicated than any of the amortized - efficient structures . for further discussion of these and related results , see @xcite .    in spite of the many competitors to fibonacci heaps ,",
    "the original data structure remains one of the simplest to describe and implement .",
    "we explore the design space of this data structure .",
    "our contributions are three .",
    "first we present a version of fibonacci heaps in which each heap is represented by a single heap - ordered tree instead of a set of trees , each  is implemented using cascading rank decreases instead of cascading cuts , and the outcome of each key comparison is explicitly represented in the data structure , so that no comparisons are wasted .",
    "second , we give an example to show that without cascading cuts or rank decreases , both the original data structure and ours fail to have the desired efficiency , solving an open problem of fredman  @xcite . finally , to illustrate the richness of the design space we propose several alternative ways to do cascading rank decreases , including a randomized method related to one previously proposed by karger @xcite .",
    "we leave the analysis of these alternatives as intriguing open problems .",
    "the remainder of our paper consists of six sections .",
    "section  [ sec : simple ] describes our data structure .",
    "section  [ sec : analysis ] analyzes it .",
    "section  [ sec : implementation ] presents an implementation .",
    "section  [ sec : cascading ] gives an example showing that cascading is necessary to make fibonacci heaps efficient , answering an open question of fredman  @xcite .",
    "section  [ sec : simpler ] explores alternative ways to do cascading rank decreases .",
    "section [ sec : remarks ] contains final remarks .",
    "we obtain our version of fibonacci heaps by refining a well - known generic heap implementation .",
    "we represent a heap by a rooted tree whose nodes are the heap items .",
    "we access the tree via its root .",
    "the tree is heap - ordered : each child has key no less than that of its parent .",
    "heap order implies that the root is an item of minimum key . to do a  on a heap , we return the root of its tree .",
    "we do the update operations using a primitive called _ linking_. given the roots of two trees , we link them by comparing their keys and making the root of smaller key the parent of the root of the larger key , breaking a tie arbitrarily .",
    "to make a heap , we create a new , empty tree . to meld two heaps ,",
    "if one is empty we return the other ; if both are non - empty , we link the roots of their trees and return the resulting tree . to insert an item into a heap ,",
    "we make it into a one - node tree and meld this tree with the tree representing the heap .",
    "we do  by repeated linking .",
    "first , we delete the root of the tree representing the heap , making each of its children into the root of a separate tree .",
    "if the root had no children , the heap is now empty .",
    "otherwise , we repeatedly link two roots until only one tree remains , and return this tree .    to decrease the key of an item  @xmath5 in a heap , we begin by replacing the key of  @xmath5 . if  @xmath5 is the root of its tree , this completes the operation . otherwise , we break the tree containing  @xmath5 into two trees , one containing all descendants of  @xmath5 ( including @xmath5 ) , the other containing the rest of the nodes in the tree .",
    "we call this a _ cut _ of  @xmath5 .",
    "we complete the operation by linking  @xmath5 with the root of the original tree .",
    "to delete an arbitrary item  @xmath5 from its heap , we decrease its key to a value less than all other keys , and then do a .",
    "the efficiency of this implementation depends on how links are done in .",
    "( this is the only flexibility in the implementation . ) to keep the number of links small , we give each node @xmath5 a non - negative integer rank , denoted by @xmath21 .",
    "we use ranks in a special kind of link called a _",
    "fair  link_. a fair  link of two roots can be done only if the roots have equal rank .",
    "such a link increases the rank of the root of smaller key by 1 and makes this root the parent of the root of larger key , breaking a tie arbitrarily .",
    "in contrast , a _ nave  link _ ignores the ranks and merely makes the root of smaller key the parent of the root of larger key , without changing any ranks .",
    "when linking two roots of the same rank , we have the choice of doing either a fair  link or a nave  link",
    ". we do fair  links only when necessary to guarantee efficiency , namely only in  operations , since they require the extra step of changing a rank .",
    "in addition to a rank , we give each node a state , either _ unmarked _ or _",
    "marked_. we represent the state of a node @xmath5 by a boolean variable @xmath22 that is true if and only if @xmath5 is marked .",
    "we use boolean constants _ unmarked _ and _ marked _ whose values are _ false _ and _ true _ , respectively .",
    "we refine the generic heap implementation as follows .",
    "each node added by an insertion has an initial rank of 0 and is initially unmarked .",
    "each link during an  or  is a nave  link . during a ,",
    "as long as there are two roots of the same rank , we do a fair  link of two such roots .",
    "once all remaining roots have different ranks , we link them in any order by nave  links .",
    "when decreasing the key of an item  @xmath5 in a heap with root @xmath23 , we unmark @xmath24 and then walk up the path in the tree from the parent of  @xmath5 through ancestors , unmarking each marked node reached and decreasing its rank by 1 if its rank is positive , until reaching an unmarked node .",
    "we mark this node and decrease its rank by 1 if its rank is positive .",
    "then we cut  @xmath5 , and link  @xmath5 and @xmath24 via a nave  link .    to make the cascading rank change process completely transparent",
    ", we give a fragment of pseudo - code that implements it .",
    "we denote the parent of a node  @xmath5 by @xmath25 .",
    "the following code does the rank and state changes , assuming @xmath26 :    we call this data structure the _ simple fibonacci heap_. there are three major differences between it and the original version of fibonacci heaps .",
    "first , the original does only fair  links , not nave  links .",
    "this makes each heap a set of trees rather than just one tree , accessed via a pointer to a root of minimum key .",
    "second , during the cascading process in a  operation , the original method cuts each marked node reached , as well as unmarking it and decreasing its rank . but",
    "except for cutting the node whose key decreases , these cuts are superfluous , as our analysis in the next section shows .",
    "third , our data structure maintains the outcomes of all key comparisons in the data structure itself , via fair and nave  links . in the original",
    ", maintenance of a pointer to the root of minimum key requires comparisons among root keys whose outcomes are not explicitly maintained .",
    "also , when decreasing the key of @xmath5 , @xmath5 is cut only if @xmath5 is not a root and its new key is less than that of its parent .",
    "the outcome of this extra comparison is also not explicitly maintained .",
    "our analysis uses the concept of _ active _ and _ passive _ children . a root that becomes a child by a fair  link is active ; one that becomes a child by a nave  link is passive .",
    "an active child that is marked and then unmarked becomes passive when it is unmarked ; it remains passive until it becomes a root and then a child by a fair link once again .",
    "we use active and passive children in the analysis only , not in the algorithm .",
    "[ lem : active ] for any node @xmath5 , @xmath5 has at least @xmath21 active children .",
    "the only way @xmath21 can increase is via a fair link , which adds an active child .",
    "when @xmath5 loses an active child , either by a cut or because a child becomes unmarked and hence passive , @xmath21 decreases by  1 unless it is already 0 .",
    "the lemma follows by induction on time .",
    "let the _ size _ of a node @xmath5 , denoted by @xmath27 , be its number of descendants , including itself .",
    "we prove that the rank of a node is at most logarithmic in its size .",
    "recall the definition of the fibonacci numbers : @xmath28 , @xmath29 , @xmath30 for @xmath31 .",
    "the fibonacci numbers satisfy @xmath32 , where @xmath33 is the _ golden ratio _ @xcite .",
    "[ lem : rank ] let @xmath34 be the minimum size of a node of rank at least @xmath35",
    ". then @xmath36 .",
    "clearly @xmath37 and @xmath38 .",
    "let @xmath5 be a node of rank at least @xmath31 such that @xmath39 .",
    "by lemma  [ lem : active ] , @xmath5 has at least @xmath35 active children .",
    "arrange these children in the order they were linked to @xmath5 , most recent first .",
    "fix @xmath40 .",
    "let @xmath41 be the @xmath42 active child of @xmath5 in this order .",
    "we claim that just after @xmath5 acquires @xmath41 as a child , @xmath43 .",
    "to prove the claim , we observe that after @xmath5 acquires @xmath41 as a child , @xmath21 increases only when it acquires an active child , and of the active children acquired after @xmath41 , only @xmath44 are currently active .",
    "for every other active child acquired after @xmath41 , @xmath21 first increases and then decreases by one , since each such child either becomes passive or is cut by a  operation .",
    "hence the net increase in @xmath21 from the time @xmath41 becomes a child of @xmath5 to the current time is at most @xmath44 .",
    "the claim follows .",
    "the claim implies that @xmath45 when @xmath41 becomes a child of @xmath5 .",
    "subsequently @xmath46 can decrease by at most 1 , or @xmath41 would become passive .",
    "hence @xmath47 , which implies @xmath48 .",
    "applying this bound to each of the first @xmath49 active children of @xmath5 and adding 2 for @xmath5 and its @xmath50 active child , we obtain @xmath51 .",
    "this implies @xmath52 for @xmath31 .",
    "it follows by induction on @xmath35 that @xmath53 .",
    "[ cor ] a node of size @xmath19 has rank at most @xmath54 .    to analyze the amortized efficiency of the heap operations , we use the standard potential - based framework @xcite",
    "we assign to each configuration of the data structure a real - valued _",
    "potential_. we define the amortized time of an operation to be its actual time ( possibly scaled by a constant factor ) plus the net increase in potential caused by the operation . with this definition ,",
    "the total time of a sequence of operations is equal to the sum of the amortized times of the operations plus the initial potential minus the final potential .",
    "if the initial potential is zero and the final potential is non - negative , then the total actual time of the operations is at most the sum of their amortized times ( times the scaling constant if any ) .    in our analysis",
    "we estimate the time of an operation other than a , , or  to be 1 ; that of a  to be @xmath55 , where @xmath56 is the number of iterations of the rank - decreasing loop ; and that of a  to be @xmath57 , where  @xmath19 is the number of items in the heap and @xmath58 is the number of links , both fair  and nave , done during the operation .",
    "we treat a  as a  followed by a . in the next section we present an implementation of the data structure that supports each operation except , , and  in @xmath0 actual time , each  in @xmath59 actual time , and",
    "each  in @xmath60 actual time , justifying our estimates .",
    "let the _ degree _ of a node @xmath5 , denoted by @xmath61 , be the number of children of @xmath5 .",
    "we use degrees in the analysis only ; they are not part of the algorithm .",
    "we define the potential of a node  @xmath5 to be @xmath62 , plus @xmath63 if @xmath5 is a root , plus @xmath64 if @xmath5 is marked . for any node @xmath5 , @xmath65 by lemma  [ lem : active ] , so every node has non - negative potential , and every root has potential at least @xmath63 .",
    "we define the potential of a set of heaps to be the sum of the potentials of their nodes .",
    "this potential is 0 initially ( there are no nodes ) and is always non - negative .",
    "thus in any sequence of heap operations the sum of the amortized times is an upper bound on the sum of their estimated times .",
    "[ lem : amortize ] the amortized time of a , , or  is @xmath63 , that of an  is @xmath64 , that of a  is at most @xmath66 , and that of a  on a heap of @xmath19 items is at most @xmath67 .",
    "a nave  link does not change the potential : the potential of the root that becomes a child decreases by 1 but that of the root that remains a root increases by 1 ( its degree increases and its rank does not change ) . a fair  link decreases the potential by 1 : in this case the potential of the root that remains a root does not change , since both its degree and its rank increase by 1 .",
    "a , , or  does not change the potential , so the amortized time of such an operation equals its estimated time of 1 .",
    "an insert creates a new root , of potential 1 , making its amortized time 2 whether or not it does a nave  link .",
    "a  of a root does not change the potential and hence has an amortized time of 1 .",
    "consider a  of a non - root  @xmath5 . if the root is marked , unmarking it decreases the potential .",
    "each iteration of the rank - decreasing loop except the last unmarks a node @xmath41 and may decrease its rank by 1 , decreasing the potential by at least @xmath68 .",
    "the last iteration marks a node and may decrease its rank by one , increasing the potential by at most 3 .",
    "cutting  @xmath5 from its parent does not change the potential : the potential of  @xmath5 increases by 1 since it becomes a root , but that of its parent decreases by 1 , since its degree decreases by 1 and its rank does not change .",
    "( its rank may have decreased by 1 earlier , but we have already accounted for this . ) combining these observations , we find that the  increases the potential by at most @xmath69 , making the amortized time of the operation at most @xmath70",
    ".    finally , consider a  on a heap of @xmath71 items .",
    "let @xmath24 be the root of the tree representing the heap . deleting @xmath24 increases the potential by at most @xmath72 : deletion of @xmath24 reduces the potential by at least @xmath73 , but each of the @xmath74 new roots increases in potential by 1 .",
    "by corollary  [ cor ] , @xmath75 , so deleting @xmath24 increases the potential by at most @xmath76 .",
    "each fair  link reduces the potential by 1 . also by corollary",
    "[ cor ] , at most @xmath54 of the links are nave , so at least @xmath77 are fair .",
    "we conclude that the entire  increases the potential by at most @xmath78 , making the amortized time of the operation at most @xmath79 .",
    "[ thm : amort ] the total estimated time of a sequence of heap operations starting with no heaps is @xmath0 per operation other than  and , and @xmath20 per  and , where  @xmath19 is the number of items currently in the heap .",
    "the theorem is immediate from lemma  [ lem : amortize ] .",
    "* remark : * the potential used in the proof of lemma  [ lem : amortize ] is like the original @xcite except that potential associated with children is moved to their parents .",
    "this is necessary because lemma  [ lem : active ] is an inequality , not an equality .",
    "alternatively , we can define a child @xmath41 of a node @xmath5 to be _ hyperactive _ if @xmath41 is one of the @xmath21 most recently linked active children of @xmath5 .",
    "then the number of hyperactive children of a node equals its rank ; and , if we give each node 1 unit of potential if it is not a hyperactive child , plus 2 if it is marked , then lemma  [ lem : amortize ] holds .",
    "( the potential of a tree is the same under both definitions . )",
    "our implementation of simple fibonacci heaps mimics the original implementation @xcite .",
    "we make each set of children a doubly - linked list : if  @xmath5 is a node , @xmath80 and @xmath81 are its next sibling and its previous sibling , respectively .",
    "we need double linking to do cuts in @xmath0 time .",
    "we also store with each node  @xmath5 pointers to its parent , @xmath25 , and to its first child on its list of children , @xmath82 . to find fair  links to do in , we use a global array @xmath83 of nodes indexed by rank .",
    "we assume that the array is initially empty . after deleting the root",
    ", we place each new root into the array location corresponding to its rank .",
    "if this location is already occupied , we do a fair  link . once all remaining roots have been successfully stored in the array , we scan the array , linking pairs of roots by nave  links , until only one root remains , and leave the array empty again .",
    "this implementation supports all the operations in the time bounds claimed in section  [ sec : analysis ] . since the rank of a node increases or decreases by only 1 at a time",
    ", we can replace the global array by a global doubly linked list to obtain an implementation on a pointer machine .",
    "see  @xcite .",
    "figure  [ fig : pseudo - main ] gives pseudo - code implementing the heap operations , as well as @xmath84 , which creates a heap item having key  @xmath12 and associated information  @xmath85 .",
    "figure  [ fig : pseudo - auxiliary ] gives pseudo - code implementing the auxiliary functions , , , and  used in figure  [ fig : pseudo - main ] .",
    "there are several generic changes that can be made to our implementation , or to an implementation of any similar data structure for heaps .",
    "one change is to reduce the number of pointers per node from 4 to 3 by replacing the _ before _ and _ after _",
    "pointers by one pointer whose meaning depends on the type of node : a first child points to the next sibling of its parent ; a child other than the first points to its previous sibling .",
    "( see @xcite . )",
    "this trades time for space .",
    "more complicated representations allow further space reductions .",
    "a second change is to modify the specification of the heap operations so that they update old heaps instead of returning new ones .",
    "one can do this by introducing separate heap objects . in a minimal implementation of this idea ,",
    "a heap object @xmath3 has a single field @xmath86 that is the root of the tree representing the heap , or null if the heap is empty . a less minimal implementation would store other useful information , such as the heap size , in each heap object .",
    "figure  [ fig : pseudo - alternative ] gives an implementation using heap objects .",
    "the operation @xmath87 replaces @xmath88 , and similarly for the other operations .",
    "a third change is to modify the implementation to do links lazily , only when needed to answer  queries . with this change ,",
    "a heap consists of a set of heap - ordered trees , represented by a list of roots . a  catenates the lists representing the two input heaps , without doing any links",
    ". a  of a non - root node @xmath5 adds to the list of roots instead of doing a link",
    ". a  does a , which converts the list of roots into a single root , and then deletes the root , leaving its list of children as the new list of roots . a  links roots as in the implementation of  in section  [ sec : simple ] , but without first deleting a node ; once all roots are linked , it returns the one remaining root .",
    "the @xmath0 time bound for  becomes amortized instead of worst - case . as mentioned in section [ sec : analysis ] , the original version of fibonacci heaps also represents the heap by a list of roots , but unlike the lazy implementation just described it maintains a pointer to a root of minimum key ( making the time for  @xmath0 worst - case ) . also , it does only fair  links , and it does all its links in , not .",
    "these three changes are independent of each other , so they can be combined arbitrarily .",
    "we conclude this section by mentioning three heuristics that can be added to  to reduce the number of iterations of the rank - decreasing loop in certain cases .",
    "these heuristics are independent and hence can be combined arbitrarily . whether they provide",
    "improved performance is a question for experiments ; none improves the @xmath0 amortized time bound for , and they all complicate the implementation at least slightly , but they do preserve the analysis of section  [ sec : analysis ] .",
    "furthermore , they provide ideas for actually simplifying the rank - decreasing process that we explore in section  [ sec : simpler ] .",
    "the _ heap - order heuristic _",
    "cuts @xmath5 in @xmath89 only if @xmath5 is not a root _ and _ its new key , @xmath12 , is less than that of its parent , violating heap order .",
    "as noted in section [ sec : simple ] , the original version of fibonacci heaps uses this heuristic . a possible disadvantage of this heuristic is that the outcomes of such comparisons are not encoded in the data structure .",
    "we can combine the two tests of whether @xmath5 is a child and whether @xmath5 violates heap order into a single test by defining the parent of a root to be itself .",
    "then @xmath90 if and only if @xmath5 is a child that violates heap order .",
    "maintaining parents of roots requires initializing them in  and updating them in .",
    "in contrast , the implementation in figures [ fig : pseudo - main ] and [ fig : pseudo - auxiliary ] does not need to maintain parents of roots , since it never uses them .",
    "the _ increasing - rank heuristic _ stops the rank - decreasing loop when it reaches a node whose old rank is no less than that of its parent .",
    "this heuristic reduces the worst - case time of  to @xmath20 , since nodes visited in the rank - decreasing loop strictly increase in old rank . to implement the heuristic , replace the implementations of  and  by the implementations in figure  [ fig : rank - increasing ] .",
    "the _ passive child heuristic _ stops the rank - decreasing loop when it reaches a passive child ( as defined in section  [ sec : analysis ] ) . to implement this heuristic , give each node one of three possible states : _ passive _ , _ unmarked _ ( and active ) , or _",
    "( and active ) . make roots implicitly passive .",
    "modify  to make the new child passive , modify  to make each child added by a fair  link unmarked , and replace the implementations of  and  by the implementations in figure [ fig : passive - child ] .",
    "the passive child heuristic provides a bridge from the simple fibonacci heaps of section  [ sec : simple ] to the original version @xcite .",
    "indeed , we originally included this heuristic in our data structure , and then omitted it to obtain the version in section  [ sec : simple ] .",
    "simple fibonacci heaps with the heap - order and passive - child heuristics correspond exactly to the original version of fibonacci heaps . to obtain the data structure of the latter from that of the former , cut each passive child , producing a forest .",
    "to map operations of the former to those of the latter , omit all the nave  links , and for each node  @xmath41 unmarked by , cut  @xmath41 . with the potential function redefined as in the remark at the end of section [ sec : analysis ] , the analysis of the former corresponds exactly to that of the latter .",
    "we have replaced the cascading cuts of fibonacci heaps with cascading rank decreases .",
    "fredman @xcite has asked whether one can avoid cascading altogether .",
    "specifically , consider the following simplification of our data structure : keep ranks but eliminate node marking . to decrease the key of a non - root  @xmath5 , merely cut  @xmath5 from its parent , decrease the rank of the parent by 1 if its rank is positive , and link  @xmath5 and the original root by a nave  link .",
    "we call this data structure a _ non - cascading heap_. we show how to build a non - cascading heap of  @xmath19 nodes on which one  followed by one  reproduces the original structure , with the  taking @xmath91 time .",
    "such pairs of  and  operations can be repeated indefinitely .",
    "the number of operations needed to build the heap is @xmath92 .",
    "it follows that a sequence of  @xmath93 operations starting with no heaps can take @xmath94 time .",
    "define  @xmath95 for a non - negative integer  @xmath35 to be a tree of @xmath96 nodes consisting of a root of rank  @xmath35 with  @xmath35 children .",
    "define @xmath97 for a positive integer @xmath35 and a non - negative integer @xmath98 to be a tree whose root has  @xmath35 children that are the roots of @xmath99 , with @xmath100 missing .",
    "thus @xmath97 for @xmath101 consists of a root whose @xmath35 children are the roots of @xmath102 .",
    "see figure  [ fig : tji ] . as a special case , @xmath103 consists of a root whose @xmath35 children are the roots of @xmath104 .",
    "tree @xmath103 has size @xmath105 .",
    "given a heap whose tree is  @xmath103 , one  of an item with key larger than that of the root but smaller than that of all other nodes in the tree , followed by one , will produce a new copy of  @xmath103 , the  having done  @xmath35 fair links and spent @xmath106 time . thus to get a bad example all we need to do is build a  @xmath103 for large  @xmath35 .",
    "[ htbp ]    , for @xmath107 .",
    "[ fig : tji ] ]    we can convert  @xmath108 into  @xmath109 by inserting a new item whose key is greater than that of the root .",
    "we can convert @xmath97 with @xmath110 into @xmath111 by doing two insertions , one , and @xmath44  operations , as follows .",
    "we insert two items whose keys are larger than that of the root",
    ". then we do a .",
    "after deletion of the original root , there are three roots of rank 0 : the two newly inserted items and the root of the original  @xmath112 .",
    "we link one of the newly inserted nodes with the root of the original  @xmath112 by a fair  link and then successively link the resulting tree with @xmath113 , @xmath114 , @xmath115 , @xmath116 by fair  links .",
    "we choose the keys so that among the roots linked , the root of @xmath116 has smallest key and one of the newly inserted nodes has second - smallest key .",
    "then the tree formed by the links is @xmath100 but with one of its leaves having children that are the roots of @xmath112 , @xmath113,@xmath115 , @xmath117 .",
    "we then combine the remaining trees , which include one singleton , by nave  links that make the singleton the final root and all the other roots its children .",
    "finally we do @xmath44  operations on the roots of @xmath112 , @xmath113,@xmath115 , @xmath117 , making their roots into children of the final root .",
    "this produces @xmath111 .",
    "see figure [ fig : tji - totji-1 ] .",
    "[ htbp ]     to @xmath118 , after two insertions and a .",
    "the last step , which is not shown , is to do @xmath44  operations on the roots of @xmath112 , @xmath113,@xmath115 , @xmath117 marked with a dot .",
    "[ fig : tji - totji-1 ] ]    by induction , we can convert @xmath103 into @xmath119 in @xmath120 heap operations , and we can build @xmath103 from scratch in @xmath121 heap operations .    for any  @xmath19 , there is a non - cascading heap of  @xmath19 nodes on which an  followed by a  can take @xmath91 time and reproduce the original structure .",
    "such a heap can be built from scratch in @xmath92 operations .",
    "for any  @xmath93 there is a sequence of @xmath93 operations starting from no heaps that takes @xmath94 time .",
    "the first two parts of the theorem are immediate from the construction above .",
    "to prove the third part , assume @xmath122 .",
    "let  @xmath35 be maximum such that  @xmath123 can be built in at most @xmath124 operations .",
    "then @xmath125 by the construction above .",
    "build  @xmath123 in at most @xmath124 operations and then alternate  and  operations , with each pair recreating  @xmath123 and taking @xmath106 time .",
    "essentially the same example shows that if cascading cutting is eliminated from the original version of fibonacci heaps , the resulting data structure can take fractional - polynomial time per operation .",
    "this shows that the answer to fredman s question is `` no '' .",
    "given that cascading rank decreases are necessary , it is natural to ask whether there is a simpler way to decide when to do them .",
    "we offer four possible methods , three deterministic and one randomized .",
    "we can not yet fully analyze any of these methods , and we leave doing so as intriguing open problems .",
    "two of our three deterministic methods simplify two of the heuristics in section 4 . _",
    "eager marking _ simplifies the passive child heuristic by making marked nodes and active nodes identical .",
    "roots are implicitly unmarked .",
    "a node that becomes a child by a fair link becomes marked .",
    "the rank - decreasing loop stops when it reaches an unmarked node , which it leaves unmarked . to implement this method ,",
    "modify  to make the new child unmarked , modify  to make each child added by a fair link marked , and replace the implementation of  by the implementation in figure  [ fig : eager - marking ] , given in the appendix .",
    "our other two deterministic methods eliminate marking entirely .",
    "the _ nave  increasing - rank method _ stops the rank - decreasing loop when it reaches a node whose old rank is no less than that of its parent .",
    "the _ zero - rank method _ stops the rank - decreasing loop when it reaches a node whose rank is  0 . to implement these methods , eliminate node states and replace the implementations of  and  by those in figures 9 and 10 , respectively , given in the appendix .",
    "it is straightforward to prove that with each of these methods , a node of size @xmath19 has rank at most @xmath126 .",
    "it follows that the worst - case time of  with the naive increasing - rank method is @xmath20 , and that the bounds of theorem  [ thm : amort ] hold for this method except that the amortized time per  is @xmath20 . for the other two methods we can not prove even this weaker result .",
    "we conjecture that theorem  [ thm : amort ] holds for none of these methods , but we have no counterexamples .",
    "another way to eliminate marking is to use _ randomized cascading _ , which at each iteration of the rank - decreasing loop stops with probability @xmath127 . to implement this method , eliminate node stated and",
    "replace the implementations of  and  by those in figure  [ fig : randomized ] , given in the appendix .",
    "randomized cascading is a variant of a method proposed by karger @xcite , _ randomized cutting _ , which applies to the original version of fibonacci heaps @xcite .",
    "it does not use marking ; instead , at each iteration of the cascading - cut loop it stops with probability @xmath127 . with either randomized cascading or randomized cutting",
    ",  takes @xmath0 expected time . in recent work",
    "independent of ours , li and peebles @xcite have given a tight analysis of randomized cutting .",
    "they showed that the expected amortized time of  is @xmath128 , where @xmath129 is the total number of  operations .",
    "thus randomized cutting does not provide the efficiency of fibonacci heaps .",
    "their lower bound example is similar to our example in section [ sec : cascading ] .",
    "their upper bound analysis applies in a straightforward way to randomized cascading , but their lower bound does not ( as far as we can tell ) .",
    "thus it remains open whether randomized cascading achieves the efficiency of fibonacci heaps ( in expectation ) .",
    "we have presented a one - tree version of fibonacci heaps in which each  requires only a single cut .",
    "ours is not the only heap structure with these properties .",
    "for example , rank - pairing heaps @xcite were specifically designed to need only one cut per , and there is a one - tree version of these heaps @xcite .",
    "but among all the known data structures that have the same amortized time bounds as fibonacci heaps , we think ours is the simplest .",
    "it has the additional nice property that the outcomes of all key comparisons are represented in the data structure ( via links ) .",
    "the pairing heap @xcite , a simpler self - adjusting structure , is faster in practice , but it does not support  in @xmath0 amortized time @xcite . indeed , obtaining a tight amortized time bound for  in pairing heaps is an interesting open problem @xcite .",
    "we have shown that without cascading rank changes , our data structure does not have the efficiency of fibonacci heaps , solving an open problem of fredman @xcite . we have proposed four simplified cascading methods .",
    "we leave the analysis of these methods as intriguing open problems ."
  ],
  "abstract_text": [
    "<S> the fibonacci heap is a classic data structure that supports deletions in logarithmic amortized time and all other heap operations in @xmath0 amortized time . </S>",
    "<S> we explore the design space of this data structure . </S>",
    "<S> we propose a version with the following improvements over the original : ( i ) each heap is represented by a single heap - ordered tree , instead of a set of trees . </S>",
    "<S> ( ii ) each decrease - key operation does only one cut and a cascade of rank changes , instead of doing a cascade of cuts . </S>",
    "<S> ( iii ) the outcomes of all comparisons done by the algorithm are explicitly represented in the data structure , so none are wasted . </S>",
    "<S> we also give an example to show that without cascading cuts or rank changes , both the original data structure and the new version fail to have the desired efficiency , solving an open problem of fredman . </S>",
    "<S> finally , we illustrate the richness of the design space by proposing several alternative ways to do cascading rank changes , including a randomized strategy related to one previously proposed by karger . </S>",
    "<S> we leave the analysis of these alternatives as intriguing open problems . </S>"
  ]
}