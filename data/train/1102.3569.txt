{
  "article_text": [
    "it is by now a classical result @xcite that linear network coding archives capacity for multicast and that even choosing a random linear code suffices with high probability @xcite .",
    "the rateless and self - adaptive nature of random linear network coding has been shown particularly beneficial in distributed settings with time - varying network topologies .",
    "for these settings , a distributed and packetized network coding ( pnc ) implementation has been proposed @xcite in which nodes keep received packets in memory and forward random linear combinations of these packets whenever they send a packet .",
    "the performance of pnc has since been studied in various network and communication models such as : static networks with losses @xcite , gossip networks @xcite or adversarial dynamic networks @xcite .",
    "these works feature new and interesting techniques such as connections to queuing networks and jackson s theorem @xcite , or other stochastic modeling@xcite and prove ( asymptotic ) order optimal stopping times that are tight in worst - case examples .",
    "we show that the optimality of pnc can be understood via a reduction to the classical memoryless setting @xcite .",
    "we prove that in _ any _ network model , whether it is static , stochastic or non - adaptively adversarial , pnc converges with high probability in _ optimal _ time : with high probability pnc delivers all information to all receivers at _ exactly _ the first time - step in which _ in hindsight _ it was possible to route this information from the sources to each receiver individually .",
    "our reduction shows that , for any network coding protocol , it is possible to describe a transformation that captures exactly how the memory of the nodes is used .",
    "the transformation , which is induced by a concrete protocol implementation , maps an execution of the protocol to an instance of the classical memoryless setting .",
    "this technique also applies to variants of pnc  @xcite in which each node only keeps a finite amount of packets in active memory .",
    "we show that , even in this setting , pnc stops exactly within the time in which in hindsight it was possible to route packets given the memory constraint , i.e. , that the buffer at each node never exceeds its active memory size .",
    "this shows that pnc , even without any feedback or explicit memory management  @xcite , optimally uses the limited buffers .",
    "this paper is organized as follows .",
    "we provide a short review of the memoryless network coding results and pnc in section [ sec : nc ] . in section [ sec :",
    "model ] , we introduce our network model . in section [ sec : results ] , we present our method to transform a protocol execution into a circuit that captures exactly how a given protocol implementation uses memory . using this",
    ", we prove that pnc and several of its variants are optimal in section [ sec : simulateandoptimality ] .",
    "finally , we summarize our contributions in section [ sec : conclusions ] .",
    "in the memoryless network coding setting @xcite , a directed acyclic circuit processes messages from a finite field @xmath0 ( or alternatively @xmath1 ) .",
    "a circuit is a directed acyclic hypergraph @xmath2 . for each node @xmath3 , we denote @xmath4 as the incoming hyperedges , and @xmath5 as the outgoing hyperedges . for each @xmath6",
    ", @xmath7 contains a coding vector @xmath8 .",
    "we assume that there is only one node with exclusively outgoing hyperedges , the source node @xmath9 .",
    "assuming an assignment of a message @xmath10 to each hyperedge @xmath11 , the circuit @xmath12 processes information as follows .",
    "each hyperedge can inductively be assigned a message in @xmath0 by using the rule that the vector associated with an outgoing hyperedge @xmath13 of @xmath7 is @xmath14 . in this way",
    ", @xmath12 defines a linear transform @xmath15 between the messages @xmath16 and the messages assigned to any subset of hyperedges @xmath17 .",
    "reference @xcite shows that if the field size @xmath18 is large enough , one can choose the @xmath19 such that the rank of @xmath20 is equal to the min - cut between @xmath21 and @xmath22 in @xmath12 .",
    "in such a case , any node @xmath7 with a min - cut of at least @xmath23 can invert @xmath24 and decode all messages @xmath16 .",
    "furthermore @xcite show that , with high probability , this remains true even if the coding coefficients are chosen uniformly at random .",
    "these are the classical results on ( random linear ) network coding that started this line of research .",
    "note that , in this model , timing is irrelevant and each node processes each message only once .",
    "references @xcite show that this setting can be extended to non - acyclic circuits with delays .",
    "nonetheless , nodes remain stateless and memoryless , which is why we refer to these networks as circuits .      in this section",
    ", we introduce the pnc protocol  @xcite in which , in contrast to the memoryless setting , nodes store received information in memory to later produce coded packets that reflect this information .",
    "assume that there are @xmath25 messages from @xmath1 distributed to the nodes .",
    "if the pnc protocol is used in a network , any node @xmath26 communicates by sending packets that contain vectors from @xmath27 and maintains a subset @xmath28 of received packets .",
    "initially , @xmath29 is empty for all nodes @xmath26 .",
    "when node @xmath26 initially knows the @xmath30 message @xmath31 , it adds the vector @xmath32 to @xmath29 , where @xmath33 is the @xmath30 unit vector in @xmath34 . if node @xmath26 is requested to send a packet it sends a random vector from the span of @xmath29 .",
    "note that this description is completely independent of any assumption on the network .",
    "if enough communication takes place among nodes for the system to `` mix '' , then for each node @xmath26 the subspace spanned by @xmath29 will converge to the @xmath25 dimensional subspace of @xmath27 given by the @xmath25 input vectors .",
    "each node can then use gaussian elimination to recover the input messages .",
    "references @xcite provide upper bounds on how quickly this `` mixing '' happens for specific ( stochastic ) communication models . in this work , we prove a stronger statement that the mixing happens with high probability in optimal time for _ any _ communication history .",
    "we consider discrete or continuous time dynamic network topologies where communication links are established synchronously and/or asynchronously .",
    "nodes can potentially send data at different and highly non - regular rates .",
    "links are assumed to have varying delays .",
    "we also incorporate broadcast constraints that arise in wireless settings .",
    "our model applies to any static or stochastic model , including arbitrary stochastic link failures , and to adversarial worst - case communication schedules chosen by an oblivious adversary .",
    "all these models specify a ( distribution over ) communication schedules that is independent from the randomness in the coding coefficients .",
    "we shall prove a point - wise optimality , i.e. , for any instance of a communication schedule , pnc achieves optimal performance .",
    "therefore , throughout the rest of the paper , we assume that there is a specific given communication schedule on which we have to give an optimality proof .",
    "each communication schedule can be specified as a sequence of _ events _ , where a node sends or receives packets .",
    "we assume that , at each time , a node either transmits or receives a packet .",
    "we capture these events using the following definition of a time expanded communication hypergraph .",
    "this notion of time expanded hypergraph has been previously used under different names , e.g. continuous trellis @xcite or adversarial schedule , their result requires at least @xmath35 additional capacity . in general",
    ", @xmath36 and @xmath37 can be of the order of @xmath25 or even larger making this bound quite loose . ]",
    "@xcite .",
    "consider a network with @xmath38 nodes , and denote this set of nodes as @xmath39 .",
    "a communication schedule from time @xmath40 to @xmath41 among nodes in @xmath39 is captured by the following time expanded hypergraph @xmath42 .",
    "let @xmath43 be a node in the network .",
    "we create a vertex copy @xmath44 for every time @xmath45 $ ] when the node @xmath7 receives or sends at least one packet .",
    "if @xmath7 is transmitting at time @xmath46 to nodes @xmath47 with associated delay @xmath48 respectively , we create a single hyperedge @xmath49 .",
    "given a network , we consider the following ( distributed ) many - to - many multicast problem .",
    "messages are generated at nodes in the network .",
    "a message can be generated at ( multiple ) different times at multiple nodes .",
    "the goal is to disseminate all the messages to all nodes ( or a subset of _ destination nodes _ @xmath50 ) as fast as possible .",
    "one example of an application of this problem could be a source distributing a large file ( which is divided into small parts ) to many receivers .",
    "another application is in sensor networks , where each sensor transmits its measurements at different times .    to formalize this problem",
    ", we assume that there are exactly @xmath25 messages that are vectors of @xmath1 .",
    "we assume that the nodes employ the pnc protocol of section [ sec : pnc ] .",
    "note that this requires each message to have a unique identifier that is known to every node at which the messages is generated .",
    "we incorporate the message generation in our network model using the following additional definition .",
    "let @xmath42 be a communication schedule of a network in which @xmath25 messages @xmath51 are generated .",
    "we alter @xmath52 by adding a supersource node @xmath21 to @xmath53 .",
    "furthermore for each message @xmath54 that is generated by nodes @xmath55 at time @xmath56 we add a hyperedge @xmath57 to @xmath58 .",
    "given an adversarial schedule and an initial message distribution , the network capacity between the source and any node at any time can be determined .",
    "to do so , one enriches the time expanded hypergraph by memory edges , which capture the possibility that nodes _ store _ knowledge over time .",
    "this is achieved by connecting each node @xmath59 in the time expanded hypergraph to its next copy in time @xmath60 with an edge with capacity equal to the amount of information that @xmath7 can store , i.e. , its buffer size @xmath61 ( in packets ) .",
    "we assume for simplicity that all nodes have the same amount of memory @xmath61 . if all nodes have unlimited buffers , we follow @xcite and set @xmath62 .",
    "we call this enriched time expanded hypergraph the _ ( natural ) information flow graph _ and denote it by @xmath63 .",
    "the next lemma confirms the intuition that the information flow graph indeed represents an upper - bound on the amount of information that can be transmitted by _ any _ algorithm .",
    "[ lemma : mincutbound ] let @xmath52 be the time expanded hypergraph for a communication schedule and let @xmath63 be its natural information flow graph .",
    "the the min - cut between the supersource @xmath21 and a node @xmath59 in @xmath63 is an upper bound on the amount of information that _ any _ algorithm can transmit from the sources to node @xmath7 by time @xmath41 if all nodes have an active memory of at most @xmath61 .",
    "while lemma  [ lemma : mincutbound ] provides a simple upper bound on the achievable point - to - point capacity , the more interesting question is whether a given protocol achieves this capacity . while one would hope that the optimality of random linear network coding carries over from the memoryless setting  @xcite , it is not difficult to find protocols that do not achieve this capacity , e.g. , the shift - register finite memory network coding protocol in @xcite . in the case of the pnc protocol ,",
    "several results have shown ( asymptotic ) order optimality in specific stochastic settings @xcite , or upper bounds on the stopping time in hypergraph theoretic parameters of the topology that are tight up to constant factors in worst - case examples @xcite . in the next section ,",
    "we provide a simpler and a more general approach that proves optimality in _ all _ the above cases ( albeit without providing any bound for concrete stopping times in specific models ) .",
    "we show that , for many network coding protocols , it is possible to systematically _ transform _ the time expanded hypergraph into a circuit that _ exactly captures _ how the protocol uses memory . given a protocol , a communication schedule , and the corresponding circuit ,",
    "we prove optimality in three steps .",
    "we first show that the circuit indeed simulates the execution of protocol ; then apply the results from @xcite for memoryless circuits to show that the protocol achieves the min - cut of this circuit with high probability ; and finally show that the min - cut of the circuit is equivalent to the min - cut in @xmath64 .    to describe our transforms",
    ", we note that many network coding protocol proposed so far  @xcite are composed of two elementary operations : 1 ) coding packets together by taking a random linear combination of them , and 2 ) storing packets in memory . while the coding operation is already naturally captured by the memoryless circuits we show that the storing operation can be simulated by extending a hyperedge ( representing a transmission ) to all future versions of the recipient(s ) . using this observation",
    ", we define a hypergraph transformation @xmath65 for any given protocol implementation @xmath66 .",
    "this transformation takes a time expanded hypergraph @xmath52 and transforms it to the hypergraph @xmath67 that exactly captures the execution of protocol @xmath66 on the communication schedule @xmath52 . note that the hypergraph transformation @xmath65 does not just depend on the amount of memory @xmath66 uses but has to be carefully designed to match the implementation details of protocol @xmath66 .      in this section",
    ", we describe the transforms for several protocols .",
    "we start with the pnc - protocol from section [ sec : pnc ] and then cover two network coding protocols described in @xcite : the @xmath61-recombinator and the @xmath61-accumulator protocols .",
    "both protocols are highly efficient variants of pnc , for which any node only stores @xmath61 packets in its buffer .",
    "besides reducing the required memory resources , this also improves the computational cost of network coding , because of the reduced amount of information each coding operation is performed over .",
    "the two protocols differ in the way the new set of @xmath61 packets is obtained after a reception of a new packet ( and/or generation of a new packet ) .",
    "the @xmath61-recombinator simply picks @xmath61 random packets from the span on the stored packets and the received packets while the more efficient @xmath61-accumulator randomly combines the incoming packet with each of the @xmath61 stored packet individually .",
    "the next two definitions present the transformations for the pnc protocol and the @xmath61-recombinator protocol .",
    "[ def : pnctransform ] the pnc - transform @xmath68 of a time expanded hypergraph @xmath69 is formed by replacing every hyperedge @xmath70 by it memory closure @xmath71 . here",
    "the memory - closure of a hyperedge @xmath72 is defined as @xmath73 where @xmath74 . in other words , we extend every hyperedge @xmath13 to include all future copies of the recipients .",
    "[ def : mutransform ] the @xmath61-recombinator transform @xmath75 of a time expanded hypergraph @xmath69 is formed by adding @xmath61 edges from every vertex @xmath76 to its next copy in time @xmath60 where @xmath46 is the smallest @xmath77 with @xmath78 .",
    "note that the two transforms , @xmath68 and @xmath79 , have an intuitive structure . extending a hyperedge in @xmath68 can be interpreted as changing the storage operation of nodes to requesting / receiving the exact same packet again whenever the `` stored '' packet is used . for @xmath79 , the @xmath61 memory",
    "edges represent that the @xmath61 `` stored '' packets are used to generate the next @xmath61 random packets to be stored .",
    "note that , in general , the network transforms are not necessarily as natural and straight - forward as suggested by definitions  [ def : pnctransform ] and [ def : mutransform ] .",
    "one has to be very careful to specify and map all implementation details .",
    "indeed , the transform presented in definition [ def : mutransform ] does not exactly capture the protocol described in @xcite but instead also recombines its stored packets whenever a packet is send . for simplicity",
    ", we consider this variant of the recombinator protocol here . as a final example for a slightly more complicated transformation ,",
    "we pictorially describe the @xmath61-accumulator transform .",
    "we consider the implementation described in @xcite in which a random multiple of the received packet(s ) is added to each stored packet .",
    "its network transform @xmath80 is formed by first taking the @xmath68 and then replacing each node according to the template in figure [ fig : acc1 ] .     with @xmath81 :",
    "the @xmath61 black nodes represent the memory and the gray nodes represent transmissions.,scaledwidth=35.0% ]      showing that a protocol implementation and its induced hypergraph transformation match is almost always a straight forward inductive proof :    [ theorem : simulate ] consider a network using the pnc protocol , and let @xmath52 be the corresponding time - expanded hypergraph with supersource @xmath21 .",
    "consider the pnc transform @xmath68 as a circuit as in section [ sec : classic ] .",
    "if the coding vectors for this circuit are selected independently and uniformly from @xmath82 then this simulates the behavior of the pnc protocol .",
    "the message associated with each circuit hyperedge @xmath73 in @xmath68 is the message sent by node @xmath7 at time @xmath41 .",
    "furthermore , the messages on the incoming hyperedges of @xmath59 in @xmath68 correspond to the messages stored in memory of node @xmath7 at time @xmath41",
    ".    for sake of space we present only a proof sketch : in order to prove that the circuit @xmath68 simulates the execution of the pnc protocol , we need to specify carefully how the randomness used on both sides . for the pnc protocol",
    "we assume that a node keeps all received packets ( and does not , e.g. , keep only innovative packets ) and creates any coded packet by drawing random coding coefficient for the packets in the order they were received .",
    "we similarly fix the process of choosing the random coding vectors for the circuit to make it match with the pnc protocol .    now using an inductive proof over the time ( or the topological depth of the nodes in @xmath83 )",
    ", we can show that @xmath68 simulates the pnc protocol .",
    "firstly , the messages associated with the outgoing hyperedges of the supersource @xmath21 are by definition the messages generated by the sources .",
    "now consider a node @xmath7 at time @xmath41 .",
    "we assume , without loss of generality , that no node sends a packet when it has not received or generated a message .",
    "thus , @xmath59 has at least one incoming hyperedge from another node @xmath84 where @xmath85 . by construction of @xmath68 ,",
    "the incoming hyperedges to @xmath59 are from all nodes that have sent a packet to @xmath7 before time @xmath41 . by induction hypothesis ,",
    "the incoming hyperedges of @xmath7 correspond to the messages stored in @xmath7 in the pnc protocol at time @xmath41 . since both the circuit @xmath68 and the pnc protocol linearly",
    "combine packets using the same random coefficients , the hypothesis holds for the packets created at node @xmath7 at time @xmath41 .    given @xmath67 as a representation of the execution of @xmath66 on the communication schedule @xmath52 it is easy to state and proof an equivalent of lemma [ lemma : mincutbound ] : the amount of source information transmitted from @xmath21 to @xmath7 at time @xmath41 via protocol @xmath66 is at most the @xmath86-min - cut in @xmath67 .",
    "more interestingly , since @xmath67 is memoryless , we can directly apply the results of @xcite to show the converse :    [ lemma : mincutboundprotocol ] let @xmath52 be the time expanded hypergraph for a communication schedule and let @xmath87 be its transform for the network coding protocol @xmath66 . with probability @xmath88 ,",
    "the amount of information transmitted from the sources to node @xmath7 by time @xmath41 is exactly the min - cut between the supersource @xmath21 and a node @xmath59 in @xmath87 .",
    "here @xmath89 is an arbitrarily small inverse polynomial probability given that the coefficient size @xmath90 used in @xmath66 is @xmath91 .",
    "all that is left to check is that for the protocols presented here this min - cut is indeed the same as the information theoretical optimum as given by @xmath64 in lemma [ lemma : mincutbound ] :    [ lemma : equivalent ] let @xmath52 be any time expanded hypergraph with supersource @xmath21 .",
    "the min - cut between the supersource @xmath21 and any node @xmath59 is the same in @xmath92 and @xmath68 .",
    "furthermore , the same is true for @xmath63 , @xmath93 , and @xmath80 .",
    "we begin with the equivalence of @xmath92 and @xmath68 . for this",
    "we transform any integral flow in @xmath92 to a valid flow in @xmath68 and vice versa .",
    "then , we use the min - cut max - flow theorem .",
    "the transformation operates on each path in a flow decomposition separately and repeatedly removes flow from @xmath94-edges .",
    "consider a flow - carrying unit - capacity hyperedge @xmath95 with an @xmath94-capacity memory - edge @xmath96 immediately following it ( @xmath97 ) .",
    "we eliminate such @xmath94-edges one - by - one by rerouting the flow directly through @xmath98 to @xmath99 using the extended hyperedges in @xmath68 .",
    "this process is flow preserving , respects capacities , and eliminates all @xmath94-edges since every flow path starts with an unit - capacity outgoing hyperedge of @xmath21 .",
    "it can be verified that this transformation is also reversible ; thus , gives a bijection between integral @xmath86-flows in @xmath92 and integral @xmath86-flows in @xmath68 .",
    "this finishes the proof for @xmath68 .    for @xmath93",
    ", one can use the same strategy , and re - route the flow over the @xmath61-capacity memory - edges in @xmath64 to the @xmath61 unit - capacity edges in @xmath93 .",
    "similary , for @xmath80 , we first re - route the flow over the @xmath61-capacity memory - edges in @xmath64 via the extended hyperedges in @xmath80 created by the pnc transformation . after the pnc transformation",
    ", @xmath80 is formed by replacing each node according to the template in figure [ fig : acc1 ] . in @xmath80",
    ", we can re - route the flows of each replaced node since each node @xmath59 in @xmath64 carries at most @xmath61-units of flow .",
    "this is true by construction : if a node @xmath7 is receiving at time @xmath41 , node @xmath59 has one out - going memory - edge with capacity @xmath61 ; if a node @xmath7 is transmitting at time @xmath41 , then node @xmath59 has only one in - coming memory - edge with capacity @xmath61 .",
    "putting everything together finishes our main theorem :    [ theorem : main ] assume a network and communication model in which the random coding coefficients are independent from the communication schedule . with high probability ,",
    "the @xmath100 , the @xmath61-recombinator , and the @xmath61-accumulator protocols disseminate exactly the maximum amount of information from the sources to every node that _ any _ protocol using @xmath61 memory could have disseminated .",
    "in this paper , we resolve the question of optimality for the well - studied pnc protocol and similar network coding protocols .",
    "these protocols use the memory of nodes to produce coded packets that reflect everything received so far .",
    "we show that an implementation of such a protocol induces a transformation that maps any execution to an instance of the classical memoryless setting .",
    "this shows that pnc solves the many - to - all multicast problem in _ any _ non - adaptive dynamic network model in _ optimal _ time .",
    "differently phrased , pnc makes on - the - fly the optimal decision of what information a node should send out without knowing anything about the network topology or even which other node will receive this information .    even more interestingly , this remains true if one restricts the nodes to use limited size buffers .",
    "we show that both the @xmath61-recombinator and the @xmath61-accumulator protocol@xcite achieve optimal performance in this setting : with high probability they stop exactly within the time in which in hindsight it was possible to route packets given the buffer constraint , i.e. , given that the buffer at each node never exceeds the limit . alternatively , one can interpret this result as pnc making on - the - fly optimal decisions on which information to keep in the limited memory .",
    "this shows that , even without any feedback@xcite or complicated explicit memory management , these pnc variants preserve the capacity achieving performance of pnc as long as minimal buffer sizes are available .",
    "this paper also implies that determining stopping times for pnc is equivalent to determining the connectivity of a network or , more generally , to determining the network capacity . for many settings , obtaining good bounds or characterizations for the network capacity remains an interesting open question .",
    "recently , significant progress was made in this direction for both the pnc protocol  @xcite and its finite memory variants  @xcite .",
    "we are hopeful that the insights provided here will be helpful in further advances .",
    "t.  ho , m.  mdard , r.  koetter , d.  karger , m.  effros , j.  shi , and b.  leong , `` a random linear network coding approach to multicast , '' _ transactions on information theory ( transinf ) _ , vol .",
    "52 , no .",
    "44134430 , 2006 .",
    "s.  deb , m.  mdard , and c.  choute , `` algebraic gossip : a network coding approach to optimal multiple rumor mongering , '' _ transactions on information theory ( transinf ) _ , vol .  52 , no .  6 , pp . 2486  2507 , 2006 .",
    "d.  s. lun , p.  pakzad , c.  fragouli , m.  mdard , and r.  koetter , `` an analysis of finite - memory random linear coding on packet streams , '' in _ proc . of the international symposium on modeling and optimization in mobile ,",
    "ad hoc and wireless networks ( wiopt ) _ , 2006 , pp ."
  ],
  "abstract_text": [
    "<S> we resolve the question of optimality for a well - studied packetized implementation of random linear network coding , called pnc . in pnc , in contrast to the classical memoryless setting , nodes store received information in memory to later produce coded packets that reflect this information . </S>",
    "<S> pnc is known to achieve order optimal stopping times for the many - to - all multicast problem in many settings .    </S>",
    "<S> we give a reduction that captures exactly how pnc and other network coding protocols use the memory of the nodes . </S>",
    "<S> more precisely , we show that any such protocol implementation induces a transformation which maps an execution of the protocol to an instance of the classical memoryless setting . </S>",
    "<S> this allows us to prove that , for _ any _ ( non - adaptive dynamic ) network , pnc converges with high probability in _ optimal _ time . in other words </S>",
    "<S> , it stops at _ exactly _ the first time in which _ in hindsight _ it was possible to route information from the sources to each receiver individually .    </S>",
    "<S> our technique also applies to variants of pnc in which each node uses only a _ </S>",
    "<S> finite _ buffer . </S>",
    "<S> we show that , even in this setting , pnc stops exactly within the time in which in hindsight it was possible to route packets given the memory constraint , i.e. , that the memory used at each node never exceeds its buffer size . </S>",
    "<S> this shows that pnc , even without any feedback or explicit memory management , allows to keep minimal buffer sizes while maintaining its capacity achieving performance . </S>"
  ]
}