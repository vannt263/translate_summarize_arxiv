{
  "article_text": [
    "testing is today s most commonly used method for finding defects and increase quality of software .",
    "it has been in focus for many years , since correcting defects is often the most substantial part of the software development budget @xcite . when developing business critical systems , it is particularly important to detect bugs in time .",
    "additionally , in this sector the release process is much stricter than usually , so detecting a bug only at a later phase of the release process can postpone the release date by months or years .",
    "while the fact that the system under test successfully passes a large number of tests does not prove correctness of the software , it nevertheless increases confidence in its correctness and reliability @xcite .",
    "in testing terminology , a _ test case _ for a software component refers to the combination of a single test input and the expected result .",
    "a _ test suite _ refers to a collection of individual test cases . evaluating a test suite",
    "is a process that can be automated by using a tool that runs the software component that is being tested once for each test input , compares the actual result with the expected result and reports those test cases that failed during the test ; the most well - known example of such a tool is junit for java @xcite .",
    "such an automation framework allows the repeated evaluation of a test suite , for example to perform so - called regression testing  in order to detect errors that are introduced by changing code that was previously working fine .",
    "there exist several test frameworks for declarative programming languages .",
    "for example , prolog unit tests @xcite  an integrated test framework for swi - prolog  , the basic ` test_util ` library for eclipse prolog , and hunit @xcite for haskell .",
    "the target of this work is to develop a test automation framework for the mercury language , which  to the best of our knowledge  has no such tool available yet . in our work",
    "we follow some principles from the mentioned tools , though we can not port any of those tools directly to mercury because of language specialities .",
    "for example , the strict type- and mode - checking mechanisms make it difficult to adopt most of the methods used in prolog , even if we can of course can re - use some of the ideas in the design phase .",
    "the main goal of an integrated test framework is to interpret a previously formalized test suite , execute the independent test cases , and finally produce a report about which test cases failed and why .",
    "however , a test framework can also have additional features , which are not necessarily needed for the testing itself ; a module could for example interact with an integrated debugger in order to try to identify the code fragment that caused the failure of a given test case @xcite .",
    "it can also provide a coverage tool , i.e. a tool which is able to produce a measure describing the degree to which the source code of the program has been exercised during the execution a given test suite .",
    "this measure is performed with respect to one or more _ coverage criteria _ @xcite .",
    "among the most used coverage criteria , the _ procedure _ coverage criterion aims at verifying if every procedure is called , while the _ entry / exit _ coverage criterion is similar to the latter but takes into account the success or failure of a procedure s execution  which makes it particularly appropriate when testing logic programs .",
    "the _ statement _ coverage @xcite criterion is relatively simple as it measures if every statement or instruction is reached during execution , whereas _ branch _ ( or block ) coverage criterion requires every condition of if - then - else statements to be evaluated to every possible value ( usually true and false ) ( a variant of this criteria is used in the emma coverage tool for java @xcite ) . the most general coverage criterion is the _ path _ coverage criterion , which requires every possible route through the code to be executed .",
    "note that full path coverage is in general impossible ; indeed , on the one hand loop constructs can result in an infinite number of paths , on the other hand the program under test can contain unreachable code fragments .",
    "[ [ section ] ]    in what follows , we first introduce some background knowledge about the mercury language ( section  [ prelim ] ) , then we present the unit testing tool and the interesting characteristics of its implementation ( section  [ unittest ] ) . in section  [ sec : covtool ] we present the details of the coverage tool , then we show and discuss the results of the evaluation of the prototype ( section  [ eval ] ) .",
    "mercury is a statically typed logic programming language @xcite .",
    "its type system is based on polymorphic many - sorted logic and is essentially equivalent to the mycroft - okeefe type system @xcite .",
    "a type definition defines a possibly polymorphic type by giving the set of function symbols to which variables of that type may be bound as well as the type of the arguments of those functors @xcite .",
    "take for example the definition of the well known polymorphic type @xmath0 :    .... : - type list(t ) --- > [ ] ; [ t|list(t ) ] .",
    "....    according to this definition , if @xmath1 is a type representing a given set of terms , values of type @xmath0 are either the empty list ` [ ] ` or a term @xmath2 $ ] where @xmath3 is of type @xmath1 and @xmath4 of type @xmath0 .",
    "in addition to these so - called _ algebraic types _ , mercury defines a number of primitive types that are builtin in the system . among these",
    "are the _ numeric types _ ` int ` ( integers ) and ` float ` ( floating point numbers ) .",
    "mercury programs are statically typed : the programmer declares the type of every argument of every predicate and from this information the compiler infers the type of every local variable and verifies that the program is well - typed .",
    "in addition , the mercury _ mode system _ describes how the instantiation of a variable changes over the execution of a goal .",
    "each predicate argument is classified as either input ( ground term before and after a call ) or output ( free variable at the time of the call that will be instantiated to a ground term ) .",
    "a predicate may have more than one mode , each mode representing a particular usage of the predicate .",
    "each such mode is called a _ procedure _ in mercury terminology .",
    "each procedure has a declared ( or inferred ) _ determinism _ stating the number of solutions it can generate and whether it can fail .",
    "determinisms supported by mercury include ` det ` ( a call to the procedure will succeed exactly once ) , ` semidet ` ( a call will either succeed once or fail ) , ` multi ` ( a call will generate one or more solutions ) , and ` nondet ` ( a call can either fail or generate one or more solutions ) . let us consider for example the definition of the well - known ` append/3 ` and ` member/2 ` predicates .",
    "we provide two mode declarations for each predicate , reflecting their most common usages :    .... : - pred append ( list(t ) , list(t ) , list(t ) ) .",
    ": - mode append(in , in , out ) is det .",
    ": - mode append(out , out , in ) is multi .",
    "append ( [ ] , y , y ) .",
    "append([e|es ] , y , [ e|zs]):- append(es , y , zs ) .",
    ": - pred member(t , list(t ) ) .",
    ": - mode member(in , in ) is semidet .",
    ": - mode member(out , in ) is nondet .",
    "member(x , [ x| _ ] ) .",
    "member(x , [ y|t ] ) : - not ( x = y ) , member(x , t ) . ....    for ` append/3 ` , either the first two arguments are input and the third one is output in which case the call is deterministic ( it will succeed exactly once ) , or the third argument is input and the first two are output in which case the call may generate multiple solutions . note that no call to ` append/3 ` in either of these modes can fail . for ` member/2 ` , either both arguments are input and the call will either succeed once or fail , or only the second argument is input , in which case the call can fail , or generate one or more solutions .",
    "note that unlike prolog , mercury does nt handle partially instantiated data structures .",
    "the goal of this work is to create a framework for mercury that lets the user define test cases through a simple language , and from that point on , automatically performs the whole testing process . in our implementation , the framework has two independent modules : one is responsible for executing a test suite , the other is a coverage tool , which is presented later in this paper .",
    "the two modules are loosely connected , each one being usable without the other .",
    "the generation process is completely independent from the tested code : one can write test cases without any knowledge of the source code , so the tool is even usable for test - driven development",
    ". a schematic diagram of the testing process is shown on figure  [ fig : testing - framework ] .",
    "the test cases are contained in the test suite file .",
    "the other ( optional ) input of the tool is a renaming information file , which is generated by the coverage tool .",
    "its usage is explained in section  [ sec : covtool ] . in general , a formal test case representation consists of a unique test case , i.e. the combination of a code fragment to be executed together with one or more assertions on the expected results . in our implementation",
    ", a test case is a triple , written as @xmath5 , where @xmath6 is the name of the test case ( a mercury string ) , @xmath7 is a mercury code fragment represented as a list of atoms , and @xmath8 is a list of assertions .",
    "an assertion can be either a condition on the variables of @xmath7 , or a specification of the expected behaviour of the execution .",
    "for the latter , the test framework provides three options : ` succeed ` , ` fail ` or ` exception ` .",
    "let s examine a simple example of the syntax of a test case :    [ ex : testcase ]   +    .... test(t1 , [ reverse([1,2],l ) ] , [ true(l=[2,1 ] ) ] ) .",
    "....    ` t1",
    "` is the name that will be used to refer to the test case in the report generated by the testing tool .",
    "the code fragment to test contains only one goal ( a call to the list reverse predicate ) , while the only assertion is a condition verifying whether the value computed for ` l ` is indeed the result of reversing the list ` [ 1,2 ] ` .",
    "testing framework ]      if only the features mentioned above are used then execution of the test code is limited to the first solution , even if the predicate under concern has possibly multiple solutions . in the latter cases , all the solutions but",
    "the first one are dropped .",
    "nevertheless , more extensive examination of ` multi ` or ` nondet ` predicates is also possible . in order to achieve this ,",
    "the following conditions can be used in the assertions part :    true(c ) : :    simple execution of c. only a single instantiation of the assertion c    is verified , namely the one obtained from the first answer returned by    the tested code in the test case .",
    "some_true(c ) : :    the given condition holds for at least one solution of the tested    code .",
    "all_true(c ) : :    the given condition holds for all solutions .",
    "true(n ,  c ) : :    the given condition holds for the nth solution .",
    "solutions_cardinality(n ) : :    n is equal to the number of solutions .",
    "n can be either a variable or a    constant .",
    "type(v ,  t ) : :    user defined type information of a variable .",
    "limit(n ) : :    limits the execution to n solutions",
    ". this can be useful when testing    predicates with a large number of solutions .",
    "example  [ ex : testcases2 ] shows the usage of some of these conditions .",
    "[ ex : testcases2 ]   +    .... test(t2 , [ member(x,[1,3,4,2 ] ) ] ,       [ limit(2),some_true(x>1 ) ] ) .",
    "test(t3 , [ member(x,[1,2,3,4 ] ) ] ,       [ solutions_cardinality(n),true(n>3 ) ,      all_true(x<5 ) ] ) . ....    the semantics of the assertions in ` t2 ` is there is a solution among the first 2 that is bigger than 1 , while the meaning of the assertions in ` t3 ` is there are at least 3 solutions , and all of the solutions are less than 5 .",
    "usage of input / output operations is not permitted in the assertions part , but they are allowed in the tested code fragment under the condition that all the goals are deterministic . in practice",
    "it means that there are two different execution modes of the test tool : `` multi '' and `` io '' . with `` multi '' , testing multi - solution predicates is possible , but usage of io is not . with `` io '' , it is the other way round .",
    "this execution mode of the tool can be chosen by a command line option .",
    "figure  [ fig : generated - code - det ] shows the generated code for the test case ` t1 ` defined in example  [ ex : testcase ] .",
    "since the expected behaviour is specified as success , if the ` reverse/2 ` predicate fails , the result of the test case will be `` failed because of failure ( instead of success ) '' .    ....",
    "... testcase(t1 , result ) : -    ( if      reverse([1,2 ] , l )    then      ( if         l = [ 2,1 ]      then        result = succeeded      else        result = condition_failed      )    else      result = failed(failure )    ) .",
    "....    testing multi - solution predicates needs some considerations .",
    "our implementation uses mercury s ` solutions ` library for handling predicates that can succeed more than once",
    ". however , this library has an important restriction , namely that the given predicate can have only one output argument .",
    "an easy solution to this problem is to wrap all the output variables into a compound term , then unwrap the variables after execution of the code and then perform the checks of the assertions part .",
    "unfortunately , for the generation of this compound type declaration , the type of each output variable should be known .",
    "the need of type analysis could strongly limit the usability of the tool since all the sources of used modules should be known in that case .",
    "this is usually not feasible , especially in case of built - in modules .",
    "the workaround we developed is to use the type analysis facility of the compiler itself .",
    "it is possible with the ` univ ` library , which allows to wrap any mercury type into a universal type . for the unwrap operation",
    ", the compiler must know the type of the wrapped object .",
    "usually , it can be inferred from the assertions , but if not , we have to give the type manually , as a help to the compiler .",
    "example  [ ex : testcases3 ] shows the usage of this feature .",
    "[ ex : testcases3 ]   +    .... test(t4 , [ append(l1,l2,[1,2,3 ] ) ] , [ type(l2,list(int ) ) ,       some_true((l1=[1,2],length(l2,1 ) ) ) ] ) .",
    "test(t5 , [ append(l1,l2,[1,2,3 ] ) ] ,       [ some_true((l1=[1,2],l2=[3 ] ) ) ] ) .",
    "....    the tested code fragment is the same in both test cases : the ` ( out , out , in ) ` mode of ` append/3 ` . in ` t4 ` , the compiler can infer the type of ` l1 ` , but the type of ` l2 ` must be given explicitly . in the other test case , the compiler does nt need any complementary information .",
    "notice that if there is no more than one common variable between the two code parts , then no wrapping is used , and thus no type information needs to be provided .",
    "generation of code for the ` some_true/1 ` , ` all_true/1 ` and ` true/2 ` conditions is based on the same principle .",
    "unwrap instructions of output variables are appended before the given condition if necessary , then this code fragment  a meta - predicate  is called in an appropriate way .",
    "for example in the case of ` true/2 ` , after selecting the required solution from the list , the constructed meta - predicate is called simply using the ` call/2 ` predicate .",
    "the optional solution number limitation is implemented with the help of ` do_while ` predicate in the ` solutions ` library .",
    "figure  [ fig : generated - code - nondet ] shows the generated code for the test case ` t4 ` , where we can see the declaration for the generated type .",
    "the two lines just after the call to ` append/3 ` wrap the output variables into a single compound term . the reverse operation is performed by the two lines just before the assertions .",
    "the combination of the latter together with the assertions themselves constitute the body of a meta - predicate .",
    "this meta - predicate must succeed for at least one solution for the test case to be considered as successful .",
    ".... ... : - type t4_type --- > t4_t(univ , list(int ) ) .",
    "testcase(t4 , result ) : -    solutions ( ( ( pred ( if1 : : out ) ) is nondet : -        append(l1 , l2 , [ 1,2,3 ] ) ,        type_to_univ(l1 , l1_u ) ,        if1 = t4_t(l1_u , l2 )      ) , vs ) ,    ( if      some_true ( ( ( pred ( if2 : : in ) ) is nondet : -           if2 = t4_t(l1_u , l2 ) ,          det_univ_to_type(l1_u , l1 ) ,          l1 = [ 1,2 ] , length(l2,1 )        ) , vs )    then      result = succeeded    else      result = condition_failed    ) .",
    "....      by default , every exception thrown by either the tested code or some of the assertions is caught by the framework .",
    "this is necessary , otherwise it could interrupt the execution of a large test suite with possibly a very large number of test cases . in special cases , the expected result can be exception too , which is a feature the framework can handle with a small restriction : exceptions can not be distinguished by their origin , one thrown by an assertion is handled in the same way as if it had been thrown by the tested code .",
    "currently it is impossible to make assertions on the exception itself , the only thing that can be declared in the assertion part is `` the code must throw an exception '' .",
    "nevertheless , it can happen that exceptions need to be left uncaught , especially when the user wants to know the exact source of an exception , usually to know where to find a given bug .",
    "if the exception is caught , the result will only be `` the test case threw an exception '' , but the real cause remains hidden . to help to identify these problems ,",
    "exception handling mechanism can be entirely switched off by a command line switch , so in that `` debug '' mode , the details of the problem become observable .",
    "this tool is a complementary module for the base framework that helps to detect parts of the tested code which are uncovered by a given set of test cases .",
    "logic programming languages have a few peculiarities that must be taken into account when constructing a coverage tool .",
    "the most important of these is nondeterminism , namely that statements can fail and/or have multiple solutions .",
    "most coverage tools for declarative languages transform the original program to an instrumented code and place some kind of execution counters before and after calls .",
    "this enables tracing calls to and exits from procedures .",
    "the counters are usually stored in a non - declarative way , like in the haskell program coverage tool @xcite , which records every increment into a file .",
    "this is unavoidable in case of logic programming languages , since after a backtracking , all changes made on pure declarative variables would be revoked .",
    "the same principle is used in the ` coverage ` library for eclipse prolog , the output of which is a simple html page , where the counter values are shown between the goals under concern .",
    "our tool follows the same principles as these tools , but needs to deal with some particularities of the mercury language .",
    "the most notable one is the mode - reordering mechanism of the mercury compiler , as it strongly affects coverage .",
    "another issue that is worth mentioning is the way that the mercury compiler treats switches . in the next section",
    ", we expose these different issues and present the solutions we developed .      in the remaining ,",
    "we assume that the programs are well - moded ; this condition is checked during compilation by the mercury compiler .",
    "the latter also re - orders the goals in such a way that they are executed from left to right . since",
    "different modes usually imply different orders , multi - moded predicates must be transformed into several different procedures .",
    "our implementation transforms the examined code into an instrumented one , compiles it and executes it in order to log execution information ; the process of coverage measuring is shown in figure  [ fig : coverage - tool ] .",
    "the base idea of the transformation is to add counters in the code , implemented by logging calls that write unique identifiers into a log file .",
    "the counters are placed with respect to the labelled superhomogenous form syntax defined in @xcite , with minor simplifications :    _ the syntax of a program in labelled superhomogenous form is defined as follows : _",
    "@xmath9    a counter is assigned to each label @xmath10 , denoted by @xmath11 .",
    "basically this means that counters are inserted into every possible place between goals .",
    "coverage tool ]    the first step of the transformation process is to get the code to be in superhomogeneous form .",
    "a part of this process can be achieved by the compiler ( goals reordering , duplication of predicates with multiple modes ) ; however all the multi - moded predicates need to be renamed , in such a way that every procedure is associated to a unique name .",
    "every call to the procedures must therefore be renamed consequently ; this can be done thanks to a simplified mode analysis , following the instantiations of variables throughout the code .",
    "the new name assignments are saved into a file , in order to provide names mapping information to the user at the end of the process .",
    "the second step of the transformation is the addition of logger calls between goals of the code ; these calls reify incrementing operations on counters : @xmath12 .",
    "unfortunately , this step can render the program not compilable if it contains _",
    "switches_. a switch is a special disjunction  with nothing visually distinguishing it from a `` regular '' disjunction  , in which `` each disjunct has near its start a unification that tests the same bound variable against a different function symbol '' @xcite . in the remaining , we call such unifications the _ switch conditions_. in a single switch ,",
    "the switch conditions are exclusive from each other ; that allows the compiler to consider the switch as being deterministic or semi - deterministic  depending on whether every possible condition value is covered  whereas regular disjunctions are , in general , non- or multi - deterministic .",
    "switches can be nested into each other and if they test the same variables , they are likely to be treated as a single switch .",
    "> p0.4>p0.03|>p0.03>p0.4    .... ... , (    x = f ,    p(out ) ;    y = x ,    (      y = g ,      intermediate = 42    ;      z = y ,      z = h(arg ) ,      q(arg , intermediate )    ) ,    r(intermediate , out ) ) , ... ....    & @xmath13 & @xmath13 &    .... (    log(\"label_1 \" ) ,    x = f ,    log(\"label_2 \" ) ,    p(out ) ,    log(\"label_3 \" ) ;    log(\"label_4 \" ) ,    y = x ,    log(\"label_5 \" ) ,    (      log(\"label_6 \" ) ,      y = g ,      log(\"label_7 \" ) ,      intermediate = 42 ,      log(\"label_8 \" )    ;      log(\"label_9 \" ) ,      z = y ,      log(\"label_10 \" ) ,      z = h(arg ) ,      log(\"label_11 \" ) ,      q(arg , intermediate ) ,      log(\"label_12 \" )    ) ,    log(\"label_13 \" ) ,    r(intermediate , out ) ,    log(\"label_14 \" ) ) ....     +    the reason switches are considered as particular structures is to allow the compiler to perform a determinism analysis ; no regular disjunction is allowed in predicates declared as _ det _ or _",
    "semidet_. only unifications can precede switch conditions in the different disjuncts ; if not , the compiler is not able to detect the switch conditions , and therefore considers the disjunction under concern as a regular ( _ nondet _ or _ multi _ ) disjunction .",
    "when logger calls are inserted at the beginning of a disjunct , a switch will therefore be considered as a regular disjunction . that can cause the compilation to fail if the enclosing predicate is ( semi-)deterministic .",
    "the example shown at the left side of figure  [ fig : instrumenting - a - switch ] is extracted from the mercury reference manual : it is a switch on x , provided x is ground . on the right side",
    ", there is the `` naively '' instrumented version with the logger calls ; this instrumented code would cause the program to fail at compiling if it is used in a ( semi- ) deterministic predicate .",
    "the solution we developed is to replace , in a disjunct , logger calls before each unification at the beginning of a disjunct by a single logger predicate call _ after _ the unifications  just before the first predicate call occurring in the disjunct .",
    "this single logger call should update all the counters in order to reflect success or failure of all the preceding disjuncts .",
    "unfortunately , this solution has a drawback : if one of the unifications preceding the logger call fails during execution , it is not possible to know which one it was ( since no counter was placed between them ) and then the coverage information is incomplete .",
    "however , we can recover this missing information by performing a small analysis since the values of the variables involved in these unifications are known before entering the disjunction . the algorithm that determines which counter needs to be updated at which point is presented below ( its basic steps are shown on figure  [ fig : switch - transformation ] ) .",
    "we model a switch under the form of a tree , since they can be nested into each other . nodes of the tree are the labels of the labelled superhomogenous form of the program , while its edges are the unifications between the labels .",
    "all the statements after the first predicate call of each disjunct are dropped from the model , so the leaves of the tree are the labels preceding the first predicate call in each disjunct .",
    "complex statements , like conditional structures , etc . are treated as if they were predicate calls , and are thus also dropped from the model .",
    "if there are only unifications in a disjunct , then the leaf of the corresponding branch is the last label of the disjunct .",
    "we can define a _ simplified execution path _ for a switch as a sequence of labels , which is the output of a depth - first search in the corresponding model graph .",
    "the model of the example of figure  [ fig : instrumenting - a - switch ] is shown in figure  [ fig : switch - execution - graph ] , while the corresponding simplified execution path is ( 1,2,4,5,6,7,8,9,10,11 ) .",
    "switch execution graph ]    before executing a switch , all edges of its model graph are examined .",
    "if a unification succeeds , then its successor node is marked , otherwise this part of the tree is left out from further examination .",
    "the first node of each branch is also marked , since they are not assigned to any unification .",
    "after this step , the nodes that are not marked correspond to program points that are not reached on the examined program state , and thus no counter update is applied there .",
    "the marked nodes are visited using a depth - first search ; when a leaf is reached , the sequence of marked nodes encountered on the path up to this leaf is stored and associated to the leaf s label .",
    "this process is repeated starting from the next unvisited marked node until no marked node is left unvisited .",
    "thanks to this method , a simplified execution path is split into sequences , whose last elements are mapped to program points that are reached on the examined program state .",
    "these are the sequences of labels that must be written out to the log file when the execution reaches the given label .    using the example from figure   [ fig : switch - execution - graph ] again , and assuming that every unification was successful ( which is of course impossible , since the value of ` x ` can not be ` f ` , ` g ` and ` h(arg ) ` at the same time ) , the sequences assigned to leaves would be @xmath14 for leaf @xmath15 , @xmath16 for leaf @xmath17 , and @xmath18 for leaf @xmath19 .",
    "if the unification ` x = f ` between the first two labels fails , then the assignments will be ( 1,4,5,6,7,8 ) for leaf 8 , and ( 9,10,11 ) for leaf 11 .",
    "the original logging statements can be removed from the code , and only one batch logging statement is needed at the `` leaves '' of the switch ( in each successful branch ) .    switch transformation ]    the last issue remaining using that technique is due to the last segment of the simplified execution path when the last node is not marked .",
    "it means that the last branch ( or the last few branches ) fails , and in this case we have no information about which unifications were executed .",
    "we decided to log these entries at the same time with the previous batch logging action , or if there is no successful branch , log them before the execution of the switch .",
    "for example , if the failing unifications are ` x = f ` and ` z = h(arg ) ` , then the only batch will be ( 1,4,5,6,7,8,9,10 ) associated to leaf 8 .",
    "once the code has been successfully instrumented , using the coverage tool as a part of the testing framework is easy : in the test suite file , we simply refer to this transformed code instead of the original one . for convenience ,",
    "it is nt necessary to rename multimode predicates in test cases , it is possible to pass the renaming information file  which is generated by the instrumentation step  to the test automation module . with this feature",
    ", the new predicates will be called on test execution .",
    "the direct output of executing instrumented code is a log file , which contains information about reached program points .",
    "however this information is not easily readable ; it should appear under a more `` user - friendly '' form in order to be useful .",
    "for this purpose there is a second execution phase in our implementation .",
    "it makes use of different information sources : the labelled source file ( the instrumented code just before switch transformation  possibly not compilable ) and a file containing meta - information about counters .",
    "this meta information consists of the correspondences between pairs of counters and the points of interest ( simple goals or complex structures such as disjunctions ) .",
    "one additional pair of counters is added for each predicate ; they are the first and the last counters of the predicate .",
    "it can be used to evaluate predicate or procedure coverage .",
    "the log file is generated at execution time , while the other two are created at the same time as the instrumentation .",
    "currently , the output of this coverage tool is a html file containing the source code in which colours have been added .",
    "only goal coverage is taken into account for the moment  this can be easily extended using information provided by the log file .",
    "three coverage degrees are distinguished :    covered  ( green ) : :    execution of the goal was successful ( at least once ) partially  covered  ( yellow ) : :    the goal was executed , but never succeeded not  covered  ( red ) : :    the goal was not executed    the tool also produces a detailed report which enumerates all the pairs of counters , and gives the coverage degree of the corresponding goal .",
    "although it is less visual than the html rendering , this report contains more information , since it also gives the coverage degree of complex structures ( disjunctions , switches ) and predicates ( procedure coverage ) .",
    "table  [ tab : performance - testing ] shows the results of a small evaluation of our tool .",
    "three different properties were examined : for a given testsuite , we measure the size of the generated code , the time needed for its generation by our tool , and the execution overhead of the generated code compared to the execution time of a script that executes the testsuite in an ad - hoc way .",
    "the testsuites for the first three procedures were automatically generated by @xcite , while the testsuite for the last procedure ( transpose ) was a manually written testsuite containing matrices up to a size of 3x3 .",
    "test cases & generated code size & code generation &   +   & & & ( lines ) & ( ms ) & gross & net +   & semidet & 6 & 169 & 12 & 40 & 2 +   & nondet & 4 & 189 & 12 & 40 & 11 +   & det & 24 & 475 & 16 & 60 & 50 +   & det & 11 & 288 & 12 & 40 & 8 +   & & & & & &   +    as one expects , the size and generation time of the code depends on the number and complexity of the given set of test cases .",
    "although the execution time also depends on the complexity of the test cases , the evaluation shows a rather constant overhead for the execution of the testcode generated by our framework .",
    "table  [ tab : performance - coverage ] illustrates the performance of the coverage tool .",
    "the examined properties are the size of the instrumented code compared to the size of the original source code , the time needed for instrumentation and the execution overhead caused by the transformation .",
    "the table also shows the execution times for both the instrumented and non - instrumented code .",
    "the tested procedures are the same as those in table  [ tab : performance - testing ] with the additionnal ` filter_list ` , the latter being a procedure from the code of the test framework itself that does list filtering by a given set of indices .",
    "the input parameters are chosen relatively large in order to produce measurable times ( lists of a few hundred to few thousand elements ) .      & original & instrumented & ( ms ) & original & instrumented +   & 19 & 124 & 32 & 13 & 2050 +   & & & & 42 & 4460 +   & 38 & 177 & 53 & 11 & 7130 +   & 58 & 340 & 96 & 3.3 & 1520 +   & 37 & 191 & 60 & 18 & 4760 +   & & & & &   +    since counter update occurs between goals , the size of the instrumented code ( in number of lines ) is approximately twice the size of the original code . however ,",
    "when the switch transformation is applied , additional lines are added for every switch test statement , but in any case the size of the instrumented code is limited to a few times the size of the original one . however , as can be seen from table  [ tab : performance - coverage ] , the execution time overhead of the instrumented code can be significant .",
    "this can be explained in part by the overhead due to the logging operations , in part by the fact that the compiler no longer can perform a number of optimisations .",
    "nevertheless , it should be noted that the execution overhead is only present when one is measuring test case coverage , and not when one is executing the testsuite .",
    "in this paper , we have presented a test evaluation framework for mercury .",
    "the framework is implemented , and allows one to write and execute a test suite for a mercury program , and to visualise the code that is ( not ) covered by the test suite .",
    "the implementation is published as open source software @xcite .",
    "although our implementation is usable for testing small to medium - size mercury programs , some features are missing in order to make our tool a full - fledged testing tool for mercury . in the current implementation , the coverage transformation is applied to one module at a time .",
    "consequently , when measuring the coverage of a multi - module program , the generated renaming information files should be merged manually . even with this workaround , incorrect results might be produced if two or more examined modules contain predicates having the same name .",
    "this is because the lightweight mode analysis that is performed by the tool is not sophisticated enough to choose the correct predicate from the several candidates in different modules .",
    "neither does the analysis handle partial instantiation of variables , a somewhat lesser problem given that the mercury compiler itself has only limited support for these partially instantiated structures .    also the framework definition itself could be extended .",
    "additional conditions could be introduced for the assertions part of test cases allowing , for example , to state conditions on the relation between the different solutions of a predicate .",
    "one example would be a condition that checks whether the solutions returned by a call are in ascending order .",
    "further improvements include changing the output format of the framework , for example to xml , in order to make postprocessing of the report easier",
    ". a more fundamental improvement would be the introduction of more sophisticated coverage levels into the tool .",
    "these improvements are subject to ongoing and further work .",
    "franois degrave , tom schrijvers , and wim vanhoof .",
    "automatic generation of test inputs for mercury . in michael",
    "hanus , editor , _ lopstr _ , volume 5438 of _ lecture notes in computer science _ , pages 7186 .",
    "springer , 2008 .",
    "m.  ducass and a .- m .",
    "emde . a review of automated debugging systems : knowledge , strategies and techniques . in _",
    "icse 88 : proceedings of the 10th international conference on software engineering _ ,",
    "pages 162171 , los alamitos , ca , usa , 1988 .",
    "ieee computer society press ."
  ],
  "abstract_text": [
    "<S> this paper presents a test automation framework for mercury programs . we developed a method that generates runnable mercury code from a formalized test suite , and which code provides a report on execution about the success of test cases . </S>",
    "<S> we also developed a coverage tool for the framework , which identifies and provide a visualization of the reached parts of the program when executing a given test suite . </S>"
  ]
}