{
  "article_text": [
    "supervised binary classification is arguably the most studied topic in machine learning , and yet there is still a gap between theory and practice .",
    "theoretical work has focused on convex formulations @xcite and various types of specialized algorithms @xcite . on the other hand , for practitioners",
    "the most exciting approach remains to minimize a non - convex empirical risk by some form of gradient descent @xcite .",
    "while models have become spectacularly more complex , the underlying algorithmic engine has changed relatively little over the last 20 years .",
    "gradient descent works ( according to practitioners ) because _ the landscape of empirical risk is not as complicated as one might expect _",
    "@xcite . in this paper",
    " rather than proposing yet another algorithm for binary classification  we take seriously the last point of view .",
    "namely , we carry out a detailed ( rigorous ) study of the landscape of empirical risk for the simplest possible model , binary linear classification .    in binary linear classification",
    "we are given @xmath6 pairs @xmath7,  @xmath8 with @xmath9 , @xmath10 , and would like to learn a model of the form @xmath11 with @xmath12 a parameter vector and @xmath13 $ ] a threshold function .",
    "empirical risk minimization is  by far  the most used approach for this problem @xcite .",
    "given a loss function @xmath14 , we use the estimator @xmath15 ( here @xmath16 is a bound on the maximum value of @xmath17 , which is introduced to eliminate technicalities . )    this approach is well understood when the loss @xmath18 is convex in its second argument ( logistic and hinge loss are prominent examples of this class ) .",
    "namely , by working on a suitable convex loss : @xmath19 efficient algorithms exist to solve the convex optimization problem ( [ eq : generalerm ] ) ; @xmath20 the resulting generalization error achieves the bayes optimal error under certain technical assumptions @xcite .    despite these successes , _ there are strong theoretical and empirical reasons _ for moving beyond the convex framework .",
    "first of all , several empirical studies @xcite demonstrate an improved classification error using non - convex losses .",
    "one crucial reason is that convex losses are unbounded and hence sensitive to outliers .",
    "second , non - convex models are often computationally more scalable , in that the prediction is only sensitive to examples that are close to the decision boundary , and hence uses a smaller number of support vectors @xcite .",
    "finally , and most importantly , convex losses do not generalize to more complex models such as multi - layer neural networks . in these settings ,",
    "the most common choice is the square loss that we adopt below , cf .",
    "( [ eqn : erm ] ) .",
    "[ fig : misunderstanding ]     of course , the main reason to be wary of non - convex methods is that no general algorithm exists to solve the optimization problem ( [ eq : generalerm ] ) for non - convex losses .",
    "our main result is that ( under a statistical model for the data ) non - convexity is surprisingly harmless . to illustrate our results , consider figure [ fig : misunderstanding ] , which present possible cartoons of the landscape of empirical risk . without any further information",
    ", a natural guess would be that the empirical risk behaves as in scenario @xmath21 : many local minima both far and close to the global minimum . as a consequence ,",
    "optimization algorithms are trapped away from the global minimum .",
    "a more optimistic outlook is provided by scenario @xmath22 : the empirical risk has many local minima , but only ` close ' to the global minimizer .",
    "hence , efficient algorithms converge close to the global minimum .",
    "this optimism is supported by recent results that establish this scenario in related non - convex statistical problems @xcite . while more encouraging than the previous one , this scenario is not entirely satisfactory .",
    "first of all , sub - optimal local minimizers are only ` roughly comparable ' ( in statistical performance ) to the global minimizer : this type of results does not rule out substantial loss in performance .",
    "second , optimization algorithms typically do not converge to a fixed point in a tractable number of iterations , but instead move between saddles .",
    "this makes it hard to find good stopping rules .",
    "surprisingly , for the present problem , scenario @xmath23 applies : with high probability , the empirical risk has a _ unique local minimum _ ( which is also the global minimum ) .",
    "further a simple gradient descent algorithm converges to this global minimizer _ from any initialization_.      we assume i.i.d .",
    "data @xmath24 , whereby , conditioning on @xmath25 , @xmath26 is a bernoulli random variable with @xmath27 for concreteness , the reader can keep in mind the logistic activation @xmath28 , although our analysis is general .",
    "we assume that the true parameter satisfies @xmath29 and we estimate @xmath30 via eq .",
    "( [ eq : generalerm ] ) with the following non - convex empirical risk : @xmath31 in other words , we use the quadratic loss @xmath32 , which is commonplace in learning neural networks .",
    "we also define the corresponding population risk @xmath33 ^ 2\\}$ ] .",
    "let us emphasize the model studied here is deliberately simple ( see section [ sec : discussion ] for pointers to the literature ) .",
    "more specifically , the noise is assumed to be random and the regression function @xmath34 is assumed to be known . on the other hand , we are highly constrained on the algorithmic side .",
    "we use plain gradient descent ( without special initialization ) and look for optimal sample size requirement and convergence rate .",
    "we establish that the following holds with high probability , for @xmath35 : @xmath3  the empirical risk @xmath36 has a _ unique local minimizer _ , which is the global minimizer @xmath37 ; @xmath4  gradient descent algorithm will converge exponentially fast to @xmath37 ; @xmath5  the global minimizer @xmath37 is an estimator with nearly optimal error guarantees .",
    "we next state our technical assumptions , in order to provide a formal statement .",
    "[ ass : activation ] the activation @xmath38 is three times differentiable with @xmath39 for all @xmath40 , and has bounded first , second and third derivatives .",
    "namely , for some constant @xmath41 : @xmath42    [ ass : subgaussian ] the feature vector @xmath43 has zero mean and is @xmath44-sub - gaussian , that is @xmath45 \\le e^{\\frac{\\tau^2\\|\\blambda\\|_2 ^ 2}{2}}\\ ] ] for all @xmath46 .",
    "[ ass : isotropic ] the feature vector @xmath43 spans all directions in @xmath47 , that is , @xmath48\\succeq c\\tau^2\\id_{d\\times d}$ ] for some @xmath49 .",
    "we denote by @xmath50 the ball of radius @xmath51 centered at @xmath52 .",
    "gradient descent is arguably the simplest algorithm for solving the optimization problem ( [ eq : generalerm ] ) .",
    "initializing @xmath53 , this proceeds by @xmath54    [ thm : main ] under assumptions [ ass : activation ] , [ ass : subgaussian ] , [ ass : isotropic ] there exist constants @xmath55 and @xmath56 independent of @xmath6 and @xmath1 , such that , if @xmath57 , the following hold with probability at least @xmath58    * the empirical risk function @xmath59 has a unique local minimizer in @xmath60 , that is the global minimizer @xmath37 .",
    "* gradient descent with step size @xmath61 converges exponentially fast to the global minimizer , for any initialization : @xmath62 .",
    "* we have @xmath63 .",
    "a few remarks are in order .",
    "first of all , the convergence rate of gradient descent ( at point @xmath4 ) is _ independent of the dimension @xmath1 and number of samples @xmath6_. in other words , @xmath64 iterations are sufficient to converge within distance @xmath65 from the global minimizer .",
    "classical theory of empirical risk minimization only concerns the statistical properties of the optimum , but does not provide efficient algorithms .    next note that our condition on the sample size @xmath6 is nearly optimal .",
    "indeed , it is information - theoretically impossible to estimate @xmath30 from less than @xmath66 binary samples .",
    "finally , the convergence rate at point @xmath5 also nearly matches the optimal ( parametric ) rate @xmath67 .",
    "this is , again , a result that can not be obtained on the basis of classical empirical risk minimization theory ( nor it holds without the smoothness assumptions on @xmath68 ) .      in the next section",
    "we discuss some numerical experiments that illustrate our main result .",
    "section [ sec : proof ] presents outlines of the proofs of the three parts of theorem [ thm : main ] , with technical details deferred to the supplementary material . finally , in section [",
    "sec : discussion ] we compare our results to earlier related work .",
    "it is interesting to carry out numerical simulations in order to verify how tight our bounds are .",
    "remarkably , these simulations suggest the possibility of a sharp _ phase transition _ phenomenon . when the number of samples @xmath6 crosses a critical threshold @xmath69 the landscape of empirical risk changes dramatically . while for @xmath70 the landscape is _ rough _ and has multiple local minima , for @xmath71 it becomes _ simple _ with a unique local minimum .",
    "our main theorem determines that indeed the landscape is simple for @xmath72 .",
    "it is a fascinating open question whether a sharp threshold actually exists .",
    "we consider i.i.d .",
    "predictors @xmath73 , and generate @xmath26 according to model ( [ eqn : model ] ) with @xmath74 .",
    "we perform gradient descent , cf",
    ". eq  ( [ eq : gradientdescent ] ) to minimize the empirical risk ( [ eqn : erm ] ) , with a minor revision in practice : we will project the iteration points back into @xmath75 if the iteration points fall out of the ball , with @xmath76 .",
    "the step size is fixed to be @xmath77 .    in order to test the hypothesis that the landscape is simple ,",
    "we run projected gradient descent starting from multiple random initializations @xmath78 . if the landscape is simple , we expect the projected gradient descent converging to the same global minimizer with no dependence on the initialization",
    ". if the landscape is rough , projected gradient descent will converge to different points depending on the initialization .",
    "given a maximum number of iterations @xmath79 , we define the following quantity , depending on the data @xmath80 , @xmath81 where the variance is taken over the random initializations @xmath82 . in words , @xmath83 is the spread of the limit points of gradient descent , for the instance @xmath84 .",
    "we then define the empirical success probability as @xmath85    0.45 .",
    "the ground truth @xmath86 is taken to be @xmath87 to make this problem hard enough .",
    "( b ) inverse of estimation error @xmath88 $ ] versus @xmath89 .",
    "the ground truth @xmath90 .",
    ", title=\"fig : \" ]    0.45 .",
    "the ground truth @xmath86 is taken to be @xmath87 to make this problem hard enough .",
    "( b ) inverse of estimation error @xmath88 $ ] versus @xmath89 .",
    "the ground truth @xmath90 .",
    ", title=\"fig : \" ]    in figure [ fig : sd ] we plot our results for the empirical success rate , for several values of @xmath6 , @xmath1 . in this experiment , we take @xmath91 ( when @xmath17 is small , the situation is qualitatively different because the model becomes nearly linear , and the optimization problem is easier ) . for each pair",
    "@xmath92 , we generate @xmath93 instances @xmath84 and run projected gradient descent from @xmath94 random initializations .",
    "we used @xmath95 iterations and tolerance @xmath96 though results seem to be fairly insensitive to these parameters . in the figure , the dash dot line is the original data and the heavy line is a smoothed version . for each dimension",
    "@xmath1 , the success rate goes rapidly from @xmath97 to @xmath98 as the number of samples @xmath6 crosses a threshold .",
    "we plot the success probability as function of the number of samples with dimension scale @xmath99 . on this scale , curves for different dimension collapse , and become steeper as @xmath1 increases .",
    "this suggests a sharp phase transition at @xmath69 which is roughly of order @xmath100 .",
    "this is consistent with theorem [ thm : main ] .",
    "figure [ fig : error ] illustrates the behavior of the estimation error @xmath101 achieved by gradient descent .",
    "in all the following experiments , we will take @xmath90 .",
    "we plot the inverse of the estimation error ( averaged over @xmath93 random instances ) @xmath102 $ ] versus @xmath89 .",
    "again , curves for several dimensions collapse , and are consistent with the optimal rate @xmath103 .    0.45   the logistic function , @xmath90 , and @xmath104 .",
    "( b ) the minimum number of iterations needed to achieve average distance @xmath105 from the global optimizer .",
    ", title=\"fig : \" ]    0.45   the logistic function , @xmath90 , and @xmath104 .",
    "( b ) the minimum number of iterations needed to achieve average distance @xmath105 from the global optimizer .",
    ", title=\"fig : \" ]    figure [ fig : gd ] shows the convergence of gradient descent for several values of @xmath6 and @xmath1 , for fixed @xmath104 .",
    "namely , we plot the distance from the global minimizer as a function of the number of iterations @xmath106 , estimated using @xmath93 instances @xmath84 .",
    "since there is a small probability that gradient descent fails to find unique minimizer , we average over the results between the @xmath107 quantiles of these @xmath93 instances . convergence to the global minimizer appears to be exponential as predicted by theorem [ thm : main ] .",
    "also , convergence is fairly independent of the dimension for fixed @xmath89 .",
    "finally , figure [ fig : iter ] shows the number of iterations needed to achieve the @xmath108 optimization error .",
    "we run @xmath93 instances , and due to the same reason , we plot the expected number of iteration , by averaging the results between the @xmath107 quantiles of these @xmath93 instances . as @xmath89 is small ,",
    "the landscape is not so smooth so that we need more iterations to converge .",
    "as @xmath89 grows , the number of iterations needed decreases first and finally goes to a constant .",
    "this is also predicted by theorem [ thm : main ] : the landscape of empirical risk will be as smooth as the landscape of population risk , as @xmath109 .",
    "this section presents an overview of the proof of theorem [ thm : main ] .",
    "we begin in subsection [ sec : population ] by discussing the qualitative features of the population ( @xmath110 ) risk .",
    "we then derive the necessary results on uniform convergence of gradient and hessian of the empirical risk in subsection [ sec : uniform ] .",
    "we finally discuss the analysis of gradient descent in subsection [ sec : gradient ] .    before proceeding ,",
    "let us review some of the notations used throughout the paper .",
    "we use normal font for scalars ( e.g. @xmath111 ) and boldface for vectors ( @xmath112 ) .",
    "we will typically reserve capital letters for random variables ( and capital bold for random vectors ) .",
    "given @xmath113 , their standard scalar product is denoted by @xmath114 .",
    "the @xmath115 identity matrix is denoted by @xmath116 . given a matrix @xmath117 , its operator norm is denoted by @xmath118 .",
    "recall that the population risk is defined as @xmath33 ^ 2\\}$ ] .",
    "the next theorem establishes that the population risk , although non - convex , is nicely ` bowl - shaped ' , as shown in figure [ fig : poprisk ] .",
    "[ thm : poprisk ] assume @xmath29 together with assumption [ ass : activation ] and assumption [ ass : isotropic ]",
    ". then we have the following :    1 .",
    "* unique minimizer . *",
    "the population risk @xmath119 is minimized at @xmath120 and has no other stationary points .",
    "* bounds on the hessian . *",
    "if assumption [ ass : subgaussian ] also holds , then there exists an @xmath121 and some constants @xmath122 such that @xmath123 3 .",
    "* bounds on the gradients . * for the same @xmath124 as in part ( b ) , there exists some constants @xmath125 and @xmath126 such that @xmath127 and for all @xmath128 , @xmath129    all constants @xmath130 are functions of @xmath131 but do not depend on @xmath1 and the actual distribution of @xmath43 .",
    "note the loss @xmath132 is smooth and therefore the upper bounds @xmath133 in theorem [ thm : poprisk ] can be obtained easily .",
    "however , it is surprising ( and plays a key role in our analysis ) that we obtain distribution - free lower bounds @xmath134 and @xmath135 on some properly defined regions .",
    "it is even more surprising that these bounds only require that @xmath43 is sub - gaussian and isotropic .",
    "for instance , these bounds also hold even if @xmath43 takes finitely many values .    as mentioned above",
    ", a bounded loss can not possibly be convex . in our case , this implies @xmath136 as a consequence , in order for the problem to be well - defined , we need to restrict it to @xmath137 ( or add a regularization term ) .    0.4 .",
    "( b ) an instance of empirical risk for @xmath138 , and @xmath104 .",
    ", title=\"fig : \" ]    0.4 .",
    "( b ) an instance of empirical risk for @xmath138 , and @xmath104 .",
    ", title=\"fig : \" ]      in order to prove theorem [ thm : main ] , we need to transfer the properties of the population risk ( established in theorem [ thm : poprisk ] ) to the empirical risk @xmath139 .",
    "classical empirical process theory can be used to bounds the deviation @xmath140 .",
    "this allows to prove that the global minimizer of @xmath141 is close to @xmath30 , but it is not sufficient to rule out the presence of many local minimizers , cf . fig .",
    "[ fig : misunderstanding ] , scenario @xmath21 .",
    "it is possible that the empirical risk is pointwise close to the population risk , but its gradient and hessian are significantly different from the population gradient and hessian .",
    "the following theorems prove that , for @xmath142 , the gradient @xmath143 , and the hessian @xmath144 converge uniformly to their population counterparts .",
    "[ thm : graduc ] under assumptions [ ass : activation ] and [ ass : subgaussian ] , there exists a constant @xmath145 ( which does not depend on @xmath1 ) , such that @xmath146    [ thm : hesuc ] under assumptions [ ass : activation ] and [ ass : subgaussian ] , there exists a constant @xmath147 ( which does not depend on @xmath1 ) such that @xmath148    the proof of these theorems does not follow from standard concentration of measure",
    ". the naive approach would be to bound the vector and operator norms in terms of the entries size , and then apply methods from empirical process theory .",
    "this yields a sub - optimal dependence on the dimension @xmath1 .",
    "we instead take a more direct route . considering , for instance ,",
    "theorem [ thm : hesuc ] , we need to bound @xmath149 with @xmath150 the centered hessian at @xmath151 .",
    "we rewrite this quantity as @xmath152 and then approximate it by using an @xmath65-net both for @xmath153 and @xmath151 . finally , we prove concentration bounds for each pair @xmath154 .",
    "using theorem [ thm : poprisk ] together with theorem [ thm : graduc ] and [ thm : hesuc ] , we obtain immediately the landscape of empirical risk @xmath139 is also ` bowl - shaped ' .",
    "a two dimensional empirical risk is as shown in figure [ fig : emprisk ] .",
    "[ thm : emprisk ] under assumptions [ ass : activation ] , [ ass : subgaussian ] , and [ ass : isotropic ] , let @xmath155 and @xmath156 be the constants defined in theorem [ thm : poprisk ] ( b ) , then there exists some large positive constants @xmath157 , @xmath158 , and @xmath159 depending on @xmath160 , such that as @xmath161 , the following hold with probability at least @xmath162 :    1 .   for any @xmath163 ,",
    "the gradient is lower bounded as @xmath164 , and further @xmath165 .",
    "the empirical risk is strongly convex in @xmath166 .",
    "namely @xmath167 for all @xmath168    points @xmath3 and @xmath5 of theorem [ thm : main ] follow immediately from the above theorem . indeed , in order to prove theorem [ thm : main].@xmath3 , note that",
    "by point @xmath3 in theorem [ thm : emprisk ] , there is no local minimizer in the interior of @xmath169 ( because otherwise , the gradient @xmath170 would vanish there ) .",
    "also , there is no local minimizer on the boundary of @xmath171 . indeed ,",
    "if @xmath151 was such a minimizer , we would gave @xmath172 for some @xmath173 , whence @xmath174 contradicting the above .",
    "hence any local minimizer of @xmath139 must be in @xmath175 . by strong convexity ( point @xmath4 above )",
    "there can be at most one such point .",
    "recall that @xmath176 denotes the unique local minimizer . in order to prove theorem [ thm : main].@xmath5 , note that , by the intermediate value theorem , there exists @xmath177 such that @xmath178 where the inequality follows by optimality of @xmath179 . using cauchy - schwarz and the lower bound on the hessian in point @xmath4 ,",
    "we get @xmath180 the claim then follows from theorem [ thm : graduc ] .",
    "the proof of part @xmath4 of theorem [ thm : main ] is somewhat longer , but conceptually straightforward in view of the previous analyses .",
    "we first prove that gradient descent converges exponentially fast to the small ball @xmath181 .",
    "this follows from theorem [ thm : emprisk].@xmath3 , which implies that gradient descent makes exponentially fast progress in reducing the distance @xmath182 .",
    "once @xmath183 , we use theorem [ thm : emprisk].@xmath4 to prove that @xmath184 converges exponentially fast to the minimizer in @xmath181 , which also coincides with the global minimizer .    a point - by - point derivation is provided in the supplementary material .",
    "learning binary linear classifiers ( a.k.a .",
    "noisy half - spaces ) is a very well - studied topic in machine learning , and many of its aspects have been investigated in depth , see for instance @xcite for readable introductions . within theoretical computer science ,",
    "an important line of work proves hardness results for a variety of models ( and under standard complexity - theoretic assumptions ) .",
    "in particular , @xcite prove that , if the joint distribution of @xmath185 is arbitrary , no polynomial time algorithm exists to construct a classifier that is better than random  even when a good approximate classifier exists .    at the other end of the spectrum ,",
    "polynomial - time algorithms are known to exist within random noise models .",
    "for instance , @xcite consider the same model as in the present paper , with @xmath186 , but @xmath43 distributed arbitrarily , and develop polynomial - time learning algorithms . in particular , the algorithm of @xcite outputs a single half - space ( proper learning ) and hence estimates @xmath30 by solving a suitable sequence of linear programs .",
    "both of these papers rely on the outliers removal method of @xcite to cope with arbitrary distributions of @xmath43 .",
    "our work advances this line of research from two points of view .",
    "first of all , we analyze an algorithm ( gradient descent for square loss ) that is the method of choice of practitioners , and is applicable to multi - layer networks as well .",
    "second , we establish nearly optimal scaling of the sample size and estimation error ( in contrast @xcite prove polynomial dependence ) .",
    "in addition , both of the results above are obtained as a consequence of the landscape properties of the empirical risk .",
    "a second line of research that is relevant to our work is concerned with non - convex optimization for high - dimensional statistical models .",
    "several problems have been studied from this point of view , including matrix factorization @xcite , phase retrieval @xcite , m - estimation @xcite , and many others .",
    "these papers typically provide two types of guarantees .",
    "some of them establish convergence of ( a version of ) gradient descent _ provided a special initialization is used _",
    ", see @xcite for examples . in other words , they prove that the cost function is locally well behaved around the global optimizer .",
    "others guarantee global convergence _ to a neighborhood of the population global optimizer _ , see e.g. @xcite . in other words ,",
    "the cost function is well behaved on large scales , but might have many local optima near the the population global optimum , cf .",
    "scenario @xmath22 in fig .",
    "[ fig : misunderstanding ] .    as already mentioned , the picture established in this paper is even more positive .",
    "the empirical risk is locally convex around the global optimum _ and _ gradient descent converges regardless of the initialization .",
    "recently we notice that an independent work @xcite studies the phase retrieval problem from a perspective similar to ours",
    ".    finally , our results are somewhat related to recent advances in one - bit compressed sensing @xcite .",
    "the observation model we use is indeed the same as in one - bit compressed sensing , and the feature vectors @xmath25 are gaussian or sub - gaussian also in those papers .",
    "of course , @xcite focuses on sparse parameter vectors @xmath30 , and on convex estimators .",
    "it would be interesting to carry out a detailed landscape analysis for the regularized case as well .",
    "a.m. was partially supported by the nsf grants ccf-1319979 .",
    "s.m . was supported by office of technology licensing stanford graduate fellowship .",
    "let us first recall the definition of ( not necessarily mean zero ) sub - gaussian and sub - exponential random variables in @xmath47 :    [ def : subgaussian ] a random variable @xmath187 is @xmath44-sub - gaussian if for any @xmath46 , @xmath188\\ > } ] \\le e^{\\frac{\\|\\blambda\\|_2 ^ 2\\tau^2}{2}}.\\ ] ]    [ def : subexponential ] a random variable @xmath187 is @xmath189-sub - exponential if for any @xmath46 , @xmath190\\>\\|_{\\psi_1}\\le k$ ] , where @xmath191 is the orlicz @xmath192-norm : @xmath193^{1/k}.\\ ] ]    note : we can also define sub - gaussian random variables via the orlicz @xmath194-norm . we choose to follow the more classic definition there so as to make sub - gaussian concentration inequalities clearer .",
    "proofs of our main theorems rely on some properties about sub - gaussian and sub - exponential random variables that are well known in the literature , for example @xcite .",
    "we summarize them here for reference .",
    "[ lem : subgaussian ] assume @xmath187 has mean zero and is @xmath44-sub - gaussian , then    1 .",
    "there exists numerical constants @xmath195 for all integers @xmath196 such that @xmath197 \\le c_{2k}\\|\\bu\\|_2^{2k}\\tau^{2k}\\ ] ] for all @xmath198 .",
    "in particular , @xmath199 , and we can take @xmath200 .",
    "higher moments of @xmath201 are controlled , that is , for all integers @xmath196 , @xmath202 \\le c_{2k } d^k\\tau^{2k},\\ ] ] where @xmath203 is the same as in ( a ) .",
    "@xmath204 is essentially sub - exponential : @xmath205 \\le 2^{\\frac{d}{2 } } < e^{\\frac{d}{2}}.\\ ] ] 4 .",
    "if @xmath206 is zero - mean and @xmath44-sub - gaussian and @xmath207 is a random variable ( that can depend on @xmath208 ) with @xmath209 , then there exists some absolute constant @xmath210 such that @xmath211 is @xmath212-sub - gaussian .",
    "if @xmath206 is zero - mean @xmath189-sub - exponential and @xmath213 is a random variable ( that can depend on @xmath208 ) with @xmath214 , then there exists some absolute constant @xmath215 such that @xmath216 is @xmath217-sub - exponential .    1 .",
    "this is known in the literature , for example theorem 2.1 in @xcite .",
    "this is a direct consequence of part ( a ) . from the generalized mean inequality , we have @xmath202 = \\e\\big [ ( \\sum_{j=1}^{d}x_j^2)^{k } \\big ] \\le d^{k-1 } \\e\\big [ \\sum_{j=1}^{d}x_j^{2k } \\big].\\ ] ] applying part ( a ) with the standard basis @xmath218",
    ", we get @xmath219\\le c_{2k}\\tau^k$ ] .",
    "summing over @xmath220 gives @xmath221\\le d^{k}c_{2k}\\tau^k$ ] .",
    "3 .   we can assume @xmath222 by scale invariance .",
    "the idea is to relate @xmath43 to a standard gaussian random vector @xmath223 whose squared 2-norm has a known moment generating function .",
    "let @xmath224 be independent of @xmath43 .",
    "it is known that @xmath225=\\frac{1}{\\sqrt{1 - 2\\lambda}}$ ] for @xmath226 and @xmath227 , so we have @xmath228 = \\prod_{i=1}^{d } \\e[e^{\\lambda w_i^2 } ] = \\frac{1}{(1 - 2\\lambda)^{d/2}}\\ ] ] for any @xmath227 .",
    "+ now , for @xmath229 , we evaluate the quantity @xmath230 $ ] in two ways .",
    "we have @xmath231 = \\e\\big [ \\e[e^{\\sqrt{2\\lambda}\\<\\bx,\\bw\\>}|\\bx ] \\big ] = \\e\\big [ e^{\\frac{\\|\\sqrt{2\\lambda}\\bx\\|_2 ^ 2}{2 } } \\big ] = \\e[e^{\\lambda\\|\\bx\\|_2 ^ 2}].\\ ] ] on the other hand , we have @xmath232 = \\e\\big [ \\e[e^{\\<\\sqrt{2\\lambda}\\bw , \\bx\\>}|\\bw ] \\big ] \\le \\e[e^{\\frac{\\|\\sqrt{2\\lambda}\\bw\\|_2 ^ 2}{2 } } ] = \\e[e^{\\lambda\\|\\bw\\|_2 ^ 2 } ] = \\frac{1}{(1 - 2\\lambda)^{d/2}},\\ ] ] the last equality holding for @xmath227 . combining ( [ eqn : x ] ) and ( [ eqn : w ] ) and taking @xmath233 , we get @xmath234 \\le 2^{d/2 } < e^{d/2}.\\ ] ] 4 .",
    "we utilize theorem 2.1 in @xcite .",
    "that theorem states that @xmath235\\le k!(4\\tau^2)^{k}$ ] .",
    "consequently , @xmath236\\le k!(4\\tau^2)^k$ ] , since @xmath209 .",
    "now we introduce @xmath237 that is an independent copy of @xmath238 , then @xmath239 \\le 2^{2k-1}\\e[|\\alpha x|^{2k } + |\\alpha'x'|^{2k } ] = 2^{2k}\\e[|\\alpha x|^{2k } ] \\le k!(16\\tau^2)^{k}.\\ ] ] we apply the converse statement in that theorem to conclude that @xmath240 is @xmath241-sub - gaussian .",
    "finally , as @xmath242 is convex in @xmath243 , we have @xmath244 ) } ] = \\e[e^{\\lambda(\\alpha x - \\e[\\alpha'x ' ] ) } ] \\le \\e[e^{\\lambda(\\alpha x - \\alpha'x')}],\\ ] ] and thus @xmath211 is also @xmath241-sub - gaussian .",
    "5 .   by remark 5.18 in @xcite",
    ", we have @xmath245\\|_{\\psi_1 } \\le 2\\|\\beta x\\|_{\\psi_1 } \\le 2\\|x\\|_{\\psi_1},\\ ] ] which is essentially a symmetrization argument .",
    "from direct calculations , the gradients and hessians of @xmath119 are @xmath246,\\ ] ] @xmath247.\\ ] ] for later convenience , we define random variables @xmath248 and @xmath249 as @xmath250 then @xmath251 $ ] and @xmath252 $ ] .",
    "we also use @xmath253 and @xmath254 to denote the sample versions of @xmath207 and @xmath213 .    the following proposition shows that both @xmath248 and @xmath249 are bounded and lipschitz .",
    "[ prop : loss ] @xmath255 and @xmath256 .",
    "also , regardless of the value of @xmath257 , @xmath248 and @xmath249 are lipschitz with respect to @xmath258 : @xmath259 with @xmath260 and @xmath261 .",
    "we will rely on the following basic fact of product of functions : if @xmath262 are two functions bounded by @xmath263 and are @xmath264-lipschitz , then @xmath265 is bounded by @xmath266 and is @xmath267-lipschitz .",
    "now , as @xmath268 and @xmath269 , @xmath255 .",
    "for @xmath249 it is similar : @xmath270 this also shows that @xmath248 is @xmath271-lipschitz .",
    "finally , from the above fact , the function @xmath272 is @xmath273-lipschitz and @xmath274 is @xmath275-lipschitz , so @xmath249 is @xmath276-lipschitz with respect to @xmath258 .",
    "_ all lipschitz constants @xmath277 are independent of dimension @xmath1 and sample size @xmath6 .",
    "they appear in later proofs only through a multiplication on some terms and do not affect the order of our results .",
    "hence , we suppress all these lipschitz constants to 1 for later simplicity . for the same reason , we also suppress the upper bounds of @xmath248 and @xmath249 and assume that they are bounded by 1 . _",
    "the proof consists of five parts .",
    "lower bounds of gradients and hessians are a little involved , and upper bounds are relatively easy to obtain .",
    "fix @xmath278 , then @xmath279 .",
    "let @xmath280 be an orthogonal transform ( @xmath281 ) from @xmath282 to @xmath283 whose row space contains @xmath284 .",
    "define the event @xmath285 .",
    "recall that @xmath286 . then on @xmath287 , we have @xmath288 .",
    "it is easily seen that @xmath119 is minimized at @xmath30 from the bias - variance decomposition .",
    "moreover , @xmath289\\rangle \\\\    & = & \\e[2(\\sigma(\\bw^{\\st}\\bx)-y)\\sigma'(\\bw^{\\st}\\bx)\\cdot \\langle \\bw-\\bw_0,\\bx\\rangle ] \\\\    & = & \\e[2(\\sigma(\\bw^{\\st}\\bx)-\\sigma(\\bw_0^{\\st}\\bx))\\sigma'(\\bw^{\\st}\\bx)\\cdot \\langle \\bw-\\bw_0,\\bx\\rangle].\\end{aligned}\\ ] ]    notice that @xmath290 for all @xmath291 , so the quantity inside the above expectation is always nonnegative .",
    "in addition , since by assumption [ ass : activation ] , @xmath292 is positive on @xmath293 , so for any @xmath294 there exists some @xmath295 such that @xmath296}\\sigma'(t)\\ge l(r)$ ] .",
    "hence , by the intermediate value theorem , @xmath297 \\\\    & \\ge & 2l^2(r ) \\e[\\langle \\bw-\\bw_0,\\bx\\rangle^2 \\ones_{a_r}].\\end{aligned}\\ ] ] from assumption [ ass : isotropic]@xmath298\\succeq c\\tau^2\\id_{d\\times d}$ ] , so @xmath299 \\ge c \\tau^2\\|\\bw-\\bw_0\\|_2 ^ 2 $ ] .",
    "hence , we can always find a sufficiently large @xmath51 such that @xmath300\\ge \\frac{c \\tau^2}{2}\\|\\bw-\\bw_0\\|_2 ^ 2 $ ] . for this @xmath51 ,",
    "the above lower bound is greater than 0 , so the gradient @xmath301 can not be zero . hence , the risk @xmath119 has no other stationary points .    since we used a limiting argument ,",
    "the lower bound of the gradients above depends on the actual distribution of @xmath43 , so it is not distribution - free .",
    "now we give a distribution free lower bound provided assumption [ ass : subgaussian ] is true in addition .",
    "we have @xmath302 - \\e[\\langle \\bw-\\bw_0,\\bx\\rangle^2 \\ones_{a_r^c } ] \\big ) \\\\    & \\ge & 2l^2(r)\\big ( c\\tau^2\\|\\bw-\\bw_0\\|_2 ^ 2 - \\big",
    "( \\e[\\langle \\bw-\\bw_0,\\bx\\rangle^4 ] \\cdot \\p(a_r^c ) \\big)^{1/2 } \\big ) \\\\    & \\ge & 2l^2(r ) \\|\\bw-\\bw_0\\|_2 ^ 2\\tau^2 \\big ( c - \\sqrt{c_4\\cdot \\p(a_r^c ) } \\big).\\end{aligned}\\ ] ] in addition",
    ", @xmath303 giving us @xmath304 so choosing @xmath305 for some constant @xmath306 and @xmath307 ensures that @xmath308 and also @xmath309 from the cauchy - schwarz inequality .    finally , for a fixed @xmath124 independent of @xmath1 ( where we will choose its value in studying the hessians of population risk ) , choosing @xmath310 ensures that @xmath311 for all @xmath312 .",
    "for any @xmath313 , we have @xmath314 \\|_2 = \\sup_{\\|\\bv\\|_2=1 } \\langle \\bv , \\e[\\alpha(\\bw)\\bx ] \\rangle = \\sup_{\\|\\bv\\|_2=1 } \\e[\\alpha(\\bw)\\langle \\bv,\\bx\\rangle ] \\\\    & \\le & \\sup_{\\|\\bv\\|_2=1 } \\e[|\\alpha(\\bw)| \\cdot |\\langle \\bv,\\bx\\rangle| ] \\le \\sqrt{c_2}\\tau = \\tau.\\end{aligned}\\ ] ] the last inequality follows from lemma [ lem : subgaussian](a ) and a cauchy - schwarz inequality .",
    "thus , @xmath315 upper bounds @xmath316 for all @xmath313 .",
    "recall when we lower bound the gradients , we did not choose the neighborhood size @xmath124 .",
    "in this section we will choose @xmath124 , such that the hessian behaves nicely in @xmath317 .",
    "recall that @xmath318 $ ] , in which @xmath319 ( note we changed @xmath257 to @xmath320 from the tower property . )",
    "our general strategy to lower bound the minimum eigenvalue of @xmath321 is to first lower bound the @xmath322 and then upper bound @xmath323 .",
    "let us first consider @xmath322 .",
    "we have that @xmath324 $ ] .",
    "fix any @xmath198 , @xmath325 .",
    "similar to part i , let @xmath326 , then @xmath327 \\\\    & \\ge & 2l^2(r)\\e[\\langle \\bu,\\bx\\rangle^2\\ones_{a_r } ] \\\\    & \\ge & 2l^2(r)\\big ( \\e[\\langle \\bu,\\bx\\rangle^2 ] - \\e[\\langle \\bu,\\bx\\rangle^2\\ones_{a_r^c } ] \\big).\\end{aligned}\\ ] ] note that @xmath328\\ge c\\tau^2 $ ] , @xmath329\\le c_4\\tau^4 $ ] , and @xmath330 . by the cauchy - schwarz inequality ,",
    "we have @xmath331 choosing @xmath332 for some constant @xmath333 gives us a lower bound @xmath334 on @xmath322 .",
    "now let s turn to the difference @xmath335 .",
    "observe that @xmath336.\\ ] ] since @xmath213 is 1-lipschitz with respect to @xmath258 , we have that , for any unit vector @xmath198 , @xmath337 \\\\    & \\le & 2\\big ( \\e[\\langle \\bw-\\bw_0,\\bx\\rangle^2 ] \\cdot \\e[\\langle \\bu,\\bx\\rangle^4 ] \\big)^{1/2 } \\\\    & \\le & 2\\big ( \\|\\bw-\\bw_0\\|_2 ^ 2\\tau^2 \\cdot c_4\\tau^4 \\big)^{1/2 } \\\\    & = & 2\\sqrt{c_4 } \\cdot \\|\\bw-\\bw_0\\|_2\\tau^3.\\end{aligned}\\ ] ]    hence , whenever @xmath338 for some constant @xmath339 guarantees that @xmath340 .",
    "consequenly , for all @xmath341 , @xmath342 we also take this @xmath124 in the proof of gradients to make them consistent .",
    "for any @xmath313 , we have @xmath343 \\|_\\op = \\sup_{\\|\\bv\\|_2=1 } \\big| \\langle \\bv , \\e[\\beta(\\bw)\\bx\\bx^{\\st}]\\cdot \\bv\\rangle \\big| = \\sup_{\\|\\bv\\|_2=1 } \\big| \\e[\\beta(\\bw)\\langle \\bv,\\bx\\rangle^2 ] \\big| \\\\    & \\le & \\sup_{\\|\\bv\\|_2=1 } \\e[|\\beta(\\bw)| \\cdot \\langle \\bv,\\bx\\rangle^2 ] \\le c_2\\tau^2 = \\tau^2.\\end{aligned}\\ ] ] the last inequality follows from lemma [ ass : subgaussian](a ) .",
    "hence , @xmath344 is a global upper bound for hessians .",
    "notice that all constants @xmath345 does not depend on @xmath1 and the actual distribution of @xmath43 .",
    "this completes the proof of all of our statements .",
    "we are going to use a standard @xmath65-covering argument .",
    "let @xmath353 be the @xmath65-covering number of the ball @xmath354 .",
    "it is known that @xmath355 .",
    "let @xmath356 be a corresponding @xmath65-cover with @xmath357 elements .",
    "for any @xmath278 , let @xmath358}\\|\\bw-\\bw_j\\|_2 $ ] ( breaking ties arbitrarily ) , then @xmath359 for all @xmath278 .",
    "observe that @xmath360 and @xmath361 $ ] .",
    "so for any @xmath278 , @xmath362 \\big\\|_2 \\\\    & & + \\big\\| \\e[(\\alpha(\\bw_{j(\\bw ) } ) - \\alpha(\\bw))\\bx ] \\big\\|_2.\\end{aligned}\\ ] ] hence , we have @xmath363 where the events @xmath364 are defined as @xmath365 } \\big\\| \\frac{1}{n}\\sum_{i=1}^{n } \\alpha_i(\\bw_{j})\\bx_i - \\e[\\alpha(\\bw_{j})\\bx ] \\big\\|_2 \\ge \\frac{t}{3 } \\big\\ } , \\\\    c_t & = & \\big\\ { \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\big\\| \\e[(\\alpha(\\bw_{j(\\bw ) } ) - \\alpha(\\bw))\\bx ] \\big\\|_2 \\ge \\frac{t}{3 } \\big\\}.\\end{aligned}\\ ] ]    let us look at the deterministic event @xmath366 first .",
    "using lemma [ prop : loss ] , we have @xmath367 \\big\\|_2 \\le \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\e\\big [ |\\alpha(\\bw_{j(\\bw ) } ) - \\alpha(\\bw)|\\cdot \\|\\bx\\|_2 \\big ] \\\\    & \\le & \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\e\\big [ |(\\bw-\\bw_{j(\\bw)})^{\\st}\\bx| \\cdot \\|\\bx\\|_2 \\big ] \\\\    & \\le & \\eps",
    "\\cdot \\e[\\|\\bx\\|_2 ^ 2 ] \\le \\eps d\\tau^2.\\end{aligned}\\ ] ] so @xmath368 ensures that the event @xmath366 can not happen .",
    "the event @xmath369 differs from @xmath366 only in that the expectation changes to the sample average on @xmath370 .",
    "hence we can parallel the argument above on the empirical distribution @xmath371 to obtain @xmath372 as each @xmath25 is @xmath44-sub - gaussian , from lemma [ lem : subgaussian](c ) we know that @xmath373\\le e^{\\frac{d}{2}}$ ] .",
    "so by chernoff s inequality , @xmath374",
    "\\le e^{-\\frac{nt}{12\\eps\\tau^2}+\\frac{nd}{2}}.\\ ] ] so @xmath375 ensures that @xmath376 .",
    "note that this requirement is more strict than @xmath377 , so it is also guarantees that @xmath366 can not happen .",
    "let @xmath378 be a @xmath379-cover of @xmath348 with @xmath380 .",
    "from lemma [ lem:2norm ] we know that @xmath381 \\big\\|_2 \\le 2\\sup_{\\bv\\in v_{1/2 } } \\big\\ { \\frac{1}{n}\\sum_{i=1}^{n}\\alpha_i(\\bw_j)\\langle \\bv,\\bx_i\\rangle - \\e[\\alpha(\\bw_j)\\langle \\bv,\\bx\\rangle ] \\big\\}.\\ ] ] taking union bounds over @xmath382 and @xmath383 yields @xmath384,\\bv\\in v_{1/2 } } \\big\\ { \\frac{1}{n}\\sum_{i=1}^{n}\\alpha_i(\\bw_j)\\langle \\bv,\\bx_i\\rangle - \\e[\\alpha(\\bw_j)\\langle \\bv,\\bx\\rangle ]   \\big\\ } \\ge \\frac{t}{6 } \\big ) \\\\",
    "& \\le & e^{d\\log\\frac{3b_0}{\\eps}+d\\log 6 } \\sup_{j\\in[n],v\\in v_{\\frac{1}{2 } } } \\p\\big ( \\frac{1}{n}\\sum_{i=1}^{n}\\alpha_i(\\bw_j)\\langle \\bv,\\bx_i\\rangle - \\e[\\alpha(\\bw_j)\\langle \\bv,\\bx\\rangle ] \\ge \\frac{t}{6 } \\big).\\end{aligned}\\ ] ]    fixing any @xmath220 and @xmath385 , @xmath386 is @xmath44-sub - gaussian and @xmath387 is bounded by 1 . from lemma [ lem : subgaussian](d ) , each @xmath388 is @xmath212-sub - gaussian . hence the sum @xmath389 is a @xmath390-sub - gaussian random variable .",
    "this gives @xmath391 \\ge \\frac{t}{6 } \\big ) \\le   e^{-\\frac{nt^2}{144{c_{sg}}\\tau^2}}.\\ ] ] as a result , @xmath392 so @xmath393 ensures that @xmath394 .",
    "it remains to choose @xmath395 to balance requirements ( [ eqn : gradt1 ] ) and ( [ eqn : gradt2 ] ) .",
    "indeed , @xmath396 satisfies both requirements for some sufficiently large @xmath2 .",
    "we can then choose @xmath397 sufficiently large so that @xmath398 is enough .",
    "in particular , when @xmath399 , we can choose @xmath400 for some numerical constant @xmath2 .",
    "this completes the proof .",
    "the proof is similar to that of theorem [ thm : graduc ] , so we borrow some notations from section [ sec : gradpf ] .",
    "let @xmath382 be the @xmath65-cover of @xmath354 and @xmath401 be the @xmath402-cover of @xmath348 .",
    "we have @xmath403 where the events @xmath364 are defined as @xmath404 } \\big\\| \\frac{1}{n}\\sum_{i=1}^{n}\\beta_i(\\bw_j)\\bx_i\\bx_i^{\\st } - \\e[\\beta(\\bw_j)\\bx\\bx^{\\st } ] \\big\\|_\\op \\ge \\frac{t}{3 } \\big\\ } , \\\\",
    "c_t & = & \\big\\ { \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\big\\| \\e[(\\beta(\\bw_{j(\\bw)})-\\beta(\\bw))\\bx\\bx^{\\st } ] \\big\\|_\\op \\ge \\frac{t}{3 } \\big\\}.\\end{aligned}\\ ] ]    let us look at the deterministic event @xmath366 first .",
    "we have @xmath405\\|_\\op \\ge \\frac{t}{3 } \\big\\ } \\\\    & \\subseteq & \\big\\ { \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\|\\e[(\\beta(\\bw_{j(\\bw ) } ) - \\beta(\\bw))\\bx\\bx^{\\st}]\\|_f^2 \\ge \\frac{t^2}{9 } \\big\\ } \\\\    & = & \\big\\ { \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\sum_{1\\le k , l\\le d } \\big ( \\e[(\\beta(\\bw_{j(\\bw ) } ) - \\beta(\\bw ) ) x_kx_l ] \\big)^2 \\ge \\frac{t^2}{9 } \\big\\ } \\\\    & \\subseteq & \\big\\ { \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\sum_{1\\le k , l\\le d } \\e[(\\beta(\\bw_{j(\\bw ) } ) - \\beta(\\bw))^2x_k^2x_l^2 ] \\ge \\frac{t^2}{9 } \\big\\ } \\\\    & = & \\big\\ { \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\e[(\\beta(\\bw_{j(\\bw ) } ) - \\beta(\\bw))^2\\|\\bx\\|_2 ^ 4 ] \\ge \\frac{t^2}{9 } \\big\\ } \\\\    & \\le & \\big\\ { \\sup_{\\bw\\in \\ball_d(\\bzero , b_0 ) } \\e[((\\bw_{j(\\bw)}-\\bw)^{\\st}\\bx)^2\\|\\bx\\|_2 ^ 4 ] \\ge \\frac{t^2}{9 } \\big\\ } \\\\    & \\le & \\big\\ { \\eps^2\\e[\\|\\bx\\|_2 ^ 6 ] \\ge \\frac{t^2}{9 } \\big\\}.\\end{aligned}\\ ] ] from lemma [ lem : subgaussian].@xmath3 we know that @xmath406\\le c_6d^3\\tau^6 $ ] , so @xmath407 ensures that the event @xmath366 can not happen .",
    "the event @xmath369 is a version of @xmath366 on the empirical distribution @xmath408 defined in section [ sec : gradpf ] , so we have @xmath409 we can use a chernoff s inequality to control @xmath410 .",
    "here we will use markov inequality for demonstration . let @xmath411 . since @xmath412\\le c_6d^3\\tau^6 $ ] and @xmath413\\le c_{12}d^6\\tau^{12}/n$ ] , we have that @xmath376 as long as @xmath414 hence , there exists some absolute constant @xmath415 such that @xmath416 guarantees that @xmath417 .    from lemma [ lem : opnorm ]",
    "we have @xmath418 \\big\\|_\\op \\le 2\\sup_{v\\in v_{\\frac{1}{4 } } } \\big\\ { \\big| \\frac{1}{n}\\sum_{i=1}^{n}\\beta_i(\\bw_j)\\langle v , \\bx_i\\rangle^2 - \\e[\\beta(\\bw_j)\\langle v , \\bx\\rangle^2 ] \\big| \\big\\}.\\ ] ] so a union bound over @xmath382 and @xmath419 gives us @xmath384,v\\in v_{\\frac{1}{4 } } } \\big| \\frac{1}{n}\\sum_{i=1}^{n}\\beta_i(\\bw_j)\\langle \\bv , \\bx_i\\rangle^2 - \\e[\\beta(\\bw_j)\\langle \\bv , \\bx\\rangle^2 ] \\big|",
    "\\ge \\frac{t}{6 } \\big ) \\\\    & \\le & \\exp\\big ( d\\log\\frac{3b_0}{\\eps } + d\\log 12 \\big ) \\sup_{j\\in[n],v\\in v_{\\frac{1}{4 } } } \\p\\big ( \\big| \\frac{1}{n}\\sum_{i=1}^{n}\\beta_i(\\bw_j)\\langle \\bv , \\bx_i\\rangle^2 - \\e[\\beta(\\bw_j)\\langle \\bv , \\bx\\rangle^2 ] \\big| \\ge \\frac{t}{6 } \\big).\\end{aligned}\\ ] ] fixing any @xmath220 and @xmath385 , define @xmath420 $ ] for shorthand . observing that @xmath421 is @xmath44-sub - gaussian , by lemma [ lem : subgaussian].@xmath422",
    ", we have that @xmath423 is @xmath424-sub - exponential for some absolute constant @xmath425 . applying a standard concentration bound @xcite for sub - exponential random variables",
    ", we get @xmath426 for some absolute constant @xmath427 .",
    "this gives us @xmath428 consequently , @xmath429 for some absolute constant @xmath430 ensures that @xmath394 .",
    "it remains to choose @xmath395 to balance requirements ( [ eqn : hest1 ] ) and ( [ eqn : hest2 ] ) .",
    "one can verify that for some @xmath431 , @xmath432 satisfies all of them .",
    "in particular , when @xmath433 and @xmath434 , for @xmath2 a sufficiently large constant , the square - root term dominates the other one , and we can take @xmath435 for some absolute constant @xmath436 .",
    "this completes the proof .",
    "let @xmath124 , @xmath437 , @xmath438 , @xmath135 , @xmath439 , and @xmath134 be the constants defined in theorem [ thm : poprisk ] .",
    "we take @xmath440 . due to the uniform convergence of the gradients and the hessians in theorem [ thm : graduc ] and [ thm : hesuc ] , as @xmath6 is large enough when @xmath441 , with probability at least @xmath58 , the following good event happens : @xmath442 since @xmath443 is an increasing function of @xmath6 as @xmath444 , there exists a large constant @xmath445 , such that @xmath72 implies @xmath441 .",
    "all the following arguments are deterministic results conditioning on the good event @xmath446 .",
    "first , we lower bound the empirical gradient @xmath447 in @xmath448 , @xmath449 note that this also implies @xmath450 in the same domain .",
    "second , we lower bound the least eigenvalue of empirical hessian in @xmath166 , @xmath451 this leads to the conclusion that , @xmath452 is strongly convex inside the region @xmath166 .",
    "in this section we present two technical lemmas that are useful for the proofs of theorem [ thm : graduc ] and [ thm : hesuc ] .",
    "their proofs can be found in @xcite .",
    "[ lem:2norm ] let @xmath346 and @xmath347 be an @xmath65-cover of @xmath348 , then @xmath349    [ lem : opnorm ] let @xmath350 be a symmetric @xmath351 matrix and @xmath347 be an @xmath65-cover of @xmath348 , then @xmath352",
    "throughout this section , we use the same notations as in theorem [ thm : poprisk ] .      let @xmath124 , @xmath437 , @xmath438 , @xmath135 , @xmath439 , and @xmath134 be the constants defined in theorem [ thm : poprisk ] .",
    "we take @xmath440 . due to the uniform convergence of the gradients and the hessians in theorem [ thm : graduc ] and [ thm : hesuc ] , as @xmath6 is large enough when @xmath441 , with probability at least @xmath58 , the following good event happens : @xmath442 since @xmath443 is an increasing function of @xmath6 as @xmath444 , there exists a large constant @xmath445 , such that @xmath72 implies @xmath441 .",
    "all the following arguments are deterministic results conditioning on the good event @xmath446 .",
    "note that we already proved that , conditioning on @xmath446 , there is a unique minimizer of empirical risk which is inside @xmath453 .",
    "first , we bound the difference of squared statistical error between two iteration points @xmath456 \\vert_2 ^ 2)\\\\ \\leq & - 2 h \\langle \\nabla   r(\\bw_n(k ) ) , \\bw_n(k ) - \\bw_0 \\rangle + 2 h\\eps \\vert \\bw_n(k ) -",
    "\\bw_0 \\vert_2 \\\\ & + h^2 [ \\vert \\nabla r(\\bw_n(k ) ) \\vert_2 ^ 2 + 2 \\eps \\vert \\nabla r(\\bw_n(k ) ) \\vert_2 + \\eps^2 ] .",
    "\\end{aligned}\\ ] ] in the above sequence of arguments , the second equality is a replacement of variables using the gradient descent iteration rule . in the third equality ,",
    "we replace empirical gradient with the population gradient plus the difference term . in the last inequality ,",
    "since we are conditioning on event @xmath446 , we upper bound the difference of the empirical gradient and the population gradient by @xmath65 .",
    "next , we bound the difference of statistical error between two iteration points @xmath457}{\\vert \\bw_n(k+1 ) - \\bw_0\\vert_2 + \\vert \\bw_n(k ) - \\bw_0 \\vert_2}\\\\ \\leq & - h \\frac { \\langle \\nabla   r(\\bw_n(k ) ) , \\bw_n(k ) -",
    "\\bw_0 \\rangle}{\\vert \\bw_n(k ) - \\bw_0 \\vert_2 } +   h\\eps + \\frac{h^2 [ \\vert \\nabla r(\\bw_n(k ) ) \\vert_2 ^ 2 + 2 \\eps \\vert \\nabla r(\\bw_n(k ) ) \\vert_2 + \\eps^2 ] } { 2 \\vert \\bw_n(k)-\\bw_0\\vert_2}\\\\ \\leq & - h { \\underline{t_0}}\\vert \\bw_n(k)-\\bw_0\\vert_2 +   h\\eps + \\frac{1}{2}h^2 [ { \\overline{l_0}}{\\overline{\\kappa_0}}+ 2 \\eps { \\overline{\\kappa_0}}+ \\frac{\\eps^2}{\\eps_0 } ] .",
    "\\end{aligned}\\ ] ] the first inequality above follows from the factorization of difference of squares .",
    "the second inequality used the fact that the error is decreasing as @xmath458 .",
    "the last inequality used property ( b ) and ( c ) of the gradient of population risk in theorem [ thm : poprisk ] .    then , we rearrange the above inequality in a form we can apply recursively , @xmath459h}{2 { \\underline{t_0 } } } ]   \\\\ \\leq & [ 1-h { \\underline{t_0 } } ] \\cdot \\ { \\vert \\bw_n(k ) -",
    "\\bw_0 \\vert_2 - [ \\frac{\\eps}{{\\underline{t_0 } } } + \\frac{[{\\overline{l_0}}{\\overline{\\kappa_0}}+ 2 \\eps { \\overline{\\kappa_0}}+ \\frac{\\eps^2}{\\eps_0}]h}{2 { \\underline{t_0}}}]\\}. \\end{aligned}\\ ] ] since we take @xmath460 , and take @xmath461},\\ ] ] the constant subtracted behind the statistical error in equation ( [ equ : recursive ] ) is bounded @xmath462h}{2 { \\underline{t_0 } } } \\leq \\frac{\\eps_0}{2}.\\ ] ] finally , applying equation ( [ equ : recursive ] ) recursively gives @xmath463^k [ \\vert \\bw_n(0 ) - \\bw_0\\vert_2 - \\frac{\\eps_0}{2 } ] + \\frac{\\eps_0}{2}.\\ ] ] this equation says that gradient descent converges exponentially to a @xmath464 neighbor of the true parameter @xmath30 .",
    "conditioning on the good event @xmath446 happens , we have the uniform convergence of the hessians @xmath465 in the meanwhile , due to property ( b ) of population risk in theorem [ thm : poprisk ] , we have @xmath466 and @xmath467 consequently , @xmath452 is strongly convex in @xmath166 . according to the theory of convex optimization , if we start from a point inside @xmath468 , and take @xmath469 , we have @xmath470^k \\cdot [ \\what r_n(\\bw_n(0 ) ) - \\what r_n(\\bw_n^*)].\\ ] ] strongly convexity ensures that optimization error of iteration points is bounded by @xmath471^{k}\\cdot \\vert \\bw_n(0 ) - \\bw_n^ * \\vert_2.\\ ] ]      now we have the exponential convergence of gradient descent as @xmath472 given by equation ( [ equ : gronwall ] ) , and exponential convergence in @xmath166 given by equation ( [ equ : gdinball ] ) .",
    "we concatenate these two stage convergence to get the exponential convergence of gradient descent to the global minimizer .",
    "note that the first exponential convergence ( [ equ : gronwall ] ) is about statistical error @xmath473 , we need to rewrite the first exponential convergence in terms of optimization error @xmath474 .",
    "since @xmath475 , as @xmath476 , we have @xmath477\\\\ \\leq & 3 ( 1-h { \\underline{t_0}})^k \\cdot \\vert \\bw_n ( 0 ) - \\bw_n^ * \\vert_2 . \\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> we revisit the problem of learning a noisy linear classifier by minimizing the empirical risk associated to the square loss . while the empirical risk is non - convex , we prove that its structure is remarkably simple . </S>",
    "<S> namely , when the sample size is larger than @xmath0 ( with @xmath1 the dimension , and @xmath2 a constant ) the following happen with high probability : @xmath3  the empirical risk has a unique local minimum ( which is also the global minimum ) ; @xmath4  gradient descent converges exponentially fast to the global minimizer , from any initialization ; @xmath5  the global minimizer approaches the true parameter at nearly optimal rate . </S>",
    "<S> the core of our argument is to establish a uniform convergence result for the gradients and hessians of the empirical risk . </S>"
  ]
}