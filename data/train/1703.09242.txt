{
  "article_text": [
    "photometric redshift ( or photo - z ) estimation is an indispensable tool of precision cosmology .",
    "the planners of current and future large - scale photometric surveys such as the dark energy survey ( @xcite ) and the large synoptic survey telescope ( @xcite ) , which combined will observe over one billion galaxies , require accurate and precise redshift estimates in order to fully leverage the constraining power of cosmological probes such as baryon acoustic oscillations and weak gravitational lensing .",
    "numerous estimators currently exist that achieve  good \" point estimates of photo - z redshifts at low redshifts ( @xmath3 ) , where  good \" means that photo - z and spectroscopic ( or spec - z ) estimates for the _ same galaxy _ largely match , with only a small percentage of catastrophic outliers .",
    "these estimators are conventionally divided into two classes : template fitters , oft - used examples of which include bpz ( @xcite ) and eazy ( @xcite ) , and empirical methods such as annz ( @xcite ) .",
    "the former utilize sets of galaxy sed templates that are redshifted until a best match with a galaxy s observed photometry is found , whereas the latter utilize spectroscopically observed galaxies to train machine learning methods to predict the redshifts of those galaxies that are only observed photometrically .",
    "less well established within the field of photo - z estimation , however , are methods that ( 1 ) produce conditional density estimates ( or error estimates ) of individual galaxy redshifts _ and at the same time _ ( 2 ) properly take into account the discrepancy between the populations of spectroscopically observed galaxies ( roughly closer and brighter ) and those observed via photometry only ( farther and fainter ) .    regarding point ( 1 ) : the error distributions of photo - z estimates are often asymmetric and/or multi - modal , so that single - number summary statistics such as the mean or median are insufficient to describe their shapes .",
    "furthermore , the use of such statistics leads to biased estimation of parameters in downstream cosmological analyses ( e.g.  @xcite ) ; for instance , @xcite demonstrate that the use of the conditional density estimate @xmath4 ( often denoted @xmath5 in the astronomical literature and often called the probability density estimate , or pdf ) reduces systematic error in galaxy - galaxy weak lensing analyses .",
    "( here , @xmath0 can represent magnitudes and/or colours and/or other ancillary information measured for a galaxy . )",
    "several other works have touted the use of @xmath4 as well , often as a step towards better estimates of ensemble redshift distributions ( usually denoted @xmath6 ) in tomographic studies ( e.g.  @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ) , and standard methods such as the aforementioned bpz , eazy , and annz provide @xmath4 as an available output .    regarding point ( 2 ) : it is a well - established truism that in large - scale surveys there is _ selection bias _ , wherein rare and bright galaxies are preferentially selected for spectroscopic observation .",
    "this bias induces a _ covariate shift _ , since the properties of these bright galaxies do not match those of more numerous dimmer galaxies ( see e.g.  figure [ fig : covshift ] ) .",
    "this shift affects the accuracy and precision of empirical photo - z estimates .",
    "one can mitigate covariate shift by estimating importance weights @xmath7 , the ratio of the density of galaxies without redshift labels to those observed spectroscopically .",
    "for instance , @xcite attempt to directly estimate @xmath6 in a covariate shift setting with a k - nearest - neighbor - based estimator of the importance weights , an estimator since utilized by @xcite , @xcite , and @xcite .",
    "@xcite , who propose a weighted kernel density estimator for @xmath8 , offer two other methods for computing the weights ( quantile regression forest and ordinal classification pdf ) .",
    "all these weight estimators feature parameters that one must tune for proper performance .",
    "one would generally tune estimators by minimizing an estimate of risk using a validation dataset , but the authors listed above skirt the issue of tuning by setting the number of nearest neighbors a priori , or , in the case of @xcite , by utilizing a plug - in bandwidth estimate via scott s rule ( see their equation 24 ) .    in this paper",
    ", we describe a principled and unified framework for generating conditional density estimates @xmath9 in a selection bias setting : specifically , we provide a suite of appropriate risk estimators , methods for tuning and assessing models , and diagnostic tests that allows one to create accurate density estimates from raw data @xmath0 . in ",
    "[ sect : pstate ] , we define both the problem and our notation . in  [ sect : iw]-[sect : cde ] we show that if we assume that the probability that a galaxy is labeled depends only on its photometry and not on its true redshift , which is a valid assumption within the redshift regime probed by shallow surveys such as the sloan digital sky survey ( sdss ; @xcite ) , we can write down risk functions that allow one to properly tune estimators of both @xmath10 and @xmath11 . these risk functions also allow us to choose from among competing estimators . in  [ sect : combine ] we show how one can combine estimators of conditional density to improve upon the results achieved by any one estimator alone . in  [ sect : diag ] we provide diagnostic tests that one may use to determine the absolute performance of conditional density estimators . in  [ sect : sdss ] we demonstrate our methods by applying them to sdss data . finally , in  [ sect : summary ] we summarize our results . in future works , we will provide methods for variable selection ( i.e.  the selection of the most informative colours , etc .",
    ", to retain from a large set of possible covariates ) and explore methods in which we relax the galaxy - labeling assumption stated above .",
    "the data in a conventional photometric redshift estimation problem consist of covariates @xmath12 ( photometric colours and/or magnitudes , etc . ) and redshifts @xmath13 . we have access to two data samples :",
    "an independent and identically distributed ( i.i.d . )",
    "sample @xmath14 consisting of photometric data without associated labels ( i.e.  redshifts ) , and an i.i.d .",
    "labeled sample @xmath15 constructed from follow - up spectroscopic studies .",
    "( for computational efficiency , in our analyses these datasets are samples taken from larger pools of available labeled and unlabeled data . )",
    "our goal is to construct a photo-@xmath13 conditional density estimator , @xmath16 , that performs well when applied to the unlabeled data ( where  well \" can be defined by its performance with respect to a number of metrics ; see e.g.   [ sect : diag ] for two examples ) .",
    "-band model magnitudes and @xmath17 colours for labeled ( i.e.  spectroscopic ; red dashed lines ) and unlabeled ( i.e.  photometric ; blue solid lines ) galaxies , primarily observed by the sloan digital sky survey ( see section [ sect : sdss ] ) .",
    "these distributions indicate the bias for selecting brighter galaxies for spectroscopic follow - up observations , which induces a covariate shift that is here manifested as mismatches in the distributions of colours between labeled and unlabeled data . ]",
    "an issue that arises when constructing @xmath16 via empirical techniques is that of selection bias . a standard assumption in statistics and machine learning",
    "is that labeled and unlabeled data are sampled from similar distributions , which we denote @xmath18 and @xmath19 respectively . however , as figure  [ fig : covshift ] demonstrates , these two distributions can differ greatly for sky surveys that mix spectroscopy and photometry ; brighter galaxies are more likely to be selected for follow - up spectroscopic observation . to model how selection bias affects learning methods",
    ", one needs to invoke additional assumptions about the relationship between @xmath18 and @xmath19 ( e.g.  @xcite , @xcite ) . in this work",
    ", we assume that the probability that a galaxy is labeled with a spectroscopic redshift depends only upon @xmath0 ( in accord with @xcite and @xcite ) ; i.e. @xmath20 where the random variable @xmath21 equals @xmath22 if a datum is labeled and @xmath23 otherwise .",
    "this assumption implies covariate shift , defined as @xmath24 and thus is , as shown below , critical for establishing the risk function estimators that ultimately allow us to estimate conditional density estimates @xmath4 .",
    "following the discussion of section 2.3 of @xcite , we point out that assuming @xmath25 can be problematic , for instance when only colours are used in analyses in which the training data are selected in limited magnitude regimes . in this work",
    "we apply our framework to galaxies at sdss depth using colours only ; for optimal performance , one should incorporate those covariates that act in concert with @xmath13 to affect selection , e.g. , morphology , size , surface brightness , environment , etc .",
    "nothing in the current framework prevents the incorporation of these covariates .    at first glance",
    ", it may seem that covariate shift would not pose a problem for density estimation ; if @xmath26 is the same for both labeled and unlabeled samples , one might infer that a good estimator of @xmath26 based on labeled data would also perform well for unlabeled data . however , this is generally untrue .",
    "the estimation of @xmath26 depends on the marginal distribution @xmath27 , so an estimator that performs well with respect to @xmath28 may not perform well with respect to @xmath29 .",
    "we can mitigate selection bias by preprocessing the labeled data so as to ensure that sufficient labeled data lay where the unlabeled data lay .",
    "this allows us to compute expected values with respect to the distribution @xmath19 using @xmath18 , similar to the idea of importance sampling in monte carlo methods .",
    "carrying this mitigation out in practice involves two steps : first , we estimate importance weights as a function of the predictors @xmath0 : @xmath30 and second , we utilize these weights when estimating conditional densities @xmath8 .",
    "there are a myriad of estimators both for importance weighting and for conditional density estimation ( see e.g.  @xcite , @xcite ) ; what we provide here are rigorous procedures for tuning their parameters and for choosing among them .",
    "we note here that our overall procedure can be qualitatively summarized by the following dictum : one needs good estimates of importance weights at labeled data points in order to achieve good conditional density estimates at unlabeled data points .",
    "( one can observe how this dictum plays out mathematically in equation [ eqn : cde_risk ] below : note how the importance weight estimates at labeled points enter into it , in the second term , whereas the importance weight estimates at unlabeled points do not enter into it at all . )",
    "a naive method for computing importance weights @xmath10 would involve estimating @xmath31 and @xmath32 separately and computing the ratio of these densities , but this approach can enhance errors in individual density estimates , particularly in regimes where @xmath33 @xcite .",
    "many authors have thus proposed direct estimators of the ratio @xmath10 ( e.g.  @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ) . as an example , the estimator of @xcite and @xcite is @xmath34 where @xmath35 is the region of covariate space containing points that are closer to @xmath0 then its @xmath36 nearest labeled neighbor , and @xmath37 is the indicator function .    to choose between importance weight estimators , one needs first to optimally tune the parameters of each using the training and validation data ( model selection ) , and then assess their performance using the test data ( model assessment ) .",
    "we determine optimal values of tuning parameters by minimizing a risk function ( equation [ eqn : beta_risk_int ] below ) . generating estimates @xmath38 ( and by extension @xmath4 , below )",
    "implicitly requires smoothing the observed data , with the smoothing bandwidth set such that estimator bias and variance are optimally balanced .",
    "( see e.g.  @xcite . ) for instance , too much smoothing ( e.g.  adopting a value of @xmath39 that is too large in nearest - neighbor - based methods ) yields estimates with low variance and high bias , i.e.  when applied to independent datasets sampled from the same distribution , the estimates will all look similar ( i.e.  will have low variance ) but will be offset from the truth ( i.e.  will have high bias ) . too little smoothing ( e.g.  @xmath39 too small ) conversely yields high - variance and low - bias estimates that overfit the training data .    *",
    "input : * pools of labeled ( i.e.  spectroscopic ) and unlabeled ( i.e.  photometric - only ) data , which we denote @xmath40 and @xmath41 . +    * randomly sample @xmath42 data from @xmath40 and @xmath43 data from @xmath41 . ( here , @xmath44 . ) * given number of nearest labeled neighbors @xmath39 and minimum number of unlabeled data in neighborhood @xmath45 , repopulate the labeled sample so as to increase the effective sample size , i.e. , to decrease the number of labeled data with estimated importance weight zero .",
    "such repopulation will result in photometric covariates distributions that more closely approximates that of the unlabeled sample .",
    "( see equation [ eqn : beta_nn ] and algorithm [ alg : preproc ] . ) * split @xmath40 and @xmath41 into training , validation , and test datasets .",
    "( here , @xmath46 , @xmath47 , and @xmath48 for both samples . )",
    "* apply training and validation data to generate importance weight esimates @xmath38 ( via equation [ eqn : beta_nn ] ) , tuning the estimator so as to minimize the estimated risk given in equation [ eqn : beta_risk ] . *",
    "apply importance weights @xmath38 to the estimation of conditional densities @xmath4 ( e.g.  equation [ eqn : cde_nn ] ) , tuning the estimator so as to minimize the risk function given in equation [ eqn : cde_risk ] .",
    "( here we apply the conditional density estimators dubbed nn - cs , kernn - cs , series - cs , and combined by @xcite , where cs stands for  covariate shift \" and combined stands for the combination of the kernn - cs and series - cs estimators .",
    "see section [ sect : combine ] for details on combining estimator output . )",
    "* use the test data to compute the estimated risk for each conditional density estimator ( equation [ eqn : cde_risk ] ) . choose the estimator with the minimum risk .",
    "* output : * estimated conditional densities @xmath49 and @xmath50 .",
    "[ alg : full ]    when estimating importance weights , we apply the risk function @xcite @xmath51 where @xmath52 and @xmath53 is a term that does not depend on the estimate @xmath54 .",
    "( we note that here the calculation of risk is with respect to the labeled dataset distribution @xmath18 ; this is in accord with the dictum stated above that we need good estimates of importance weights for the labeled data in order to achieve good estimates of conditional densities for the unlabeled data .",
    "see equation [ eqn : cde_risk ] below . ) while we utilize an @xmath55-loss function above in ( [ eqn : beta_risk_int ] ) and below in ( [ eqn : riskcde ] ) , one could in principle substitute other functions based on f - divergences , log - densities , or notions of @xmath56 loss .",
    "however , functions based on f - divergences and log - densities are overly sensitive to distribution tails and are generally not appropriate for density estimation ( see , e.g.  @xcite and @xcite ) , while estimating a risk based on @xmath56 loss requires knowledge of the true @xmath8 . since in model selection and assessment we can ignore @xmath53 , we rewrite the above as @xmath57 which we estimate as @xmath58 where the tildes indicate that the risk is evaluated using either validation data ( during model selection ) or test data ( during model assessment ) .",
    "( here we use @xmath59 to represent a risk function in which the constant term @xmath53 is ignored . ) among multiple estimators of @xmath38 , we choose the one that yields the smallest value of @xmath60 when applied to test data .",
    "given an estimate @xmath38 of the importance weight , the ratio of densities of the unlabeled and labeled data at the point @xmath0 , our next step is to compute estimates of the conditional density @xmath4 .",
    "conditional density estimators include those of @xcite and @xcite ; see e.g.  @xcite for more details . to build intuition here ,",
    "we write down the estimator of @xcite , as it is particularly simple : @xmath61 where @xmath62 denotes the @xmath63 neighbors nearest to @xmath0 among labeled data , and @xmath64 denotes the a priori defined bin to which @xmath13 belongs .",
    "this estimator ( up)down - weights labeled data in regions where @xmath65 is ( larger ) smaller than @xmath66 .    in a selection bias setting where @xmath67 , the goal of conditional density estimation is to minimize @xmath68 i.e.  the risk with respect to the unlabeled data . under the covariate shift assumption @xmath69 , one can rewrite the modified risk ( [ eqn : riskcde ] ) up to a constant as @xmath70 where the second equality follows from @xmath71 . again",
    ", this risk depends upon unknown quantities ; we ignore @xmath72 and estimate the other terms via the equation @xmath73 -\\frac{2}{{\\widetilde{n}}_l}\\sum_{k=1}^{{\\widetilde{n}}_l}{\\widehat{f}}\\left(\\widetilde{z}^l_k|\\widetilde{{\\boldsymbol{x}}}^l_k\\right){\\widehat{\\beta}}\\left(\\widetilde{{\\boldsymbol{x}}}^l_k\\right ) \\",
    ", , \\label{eqn : cde_risk}\\ ] ] where again the tildes indicate use of validation data in model selection and test data in model assessment .",
    "typical photometric redshift estimation methods utilize one method for computing @xmath74 or @xmath75 .",
    "however , one can improve upon the prediction performances of individual estimators by combining them .",
    "suppose that @xmath76 are @xmath77 separate estimators of @xmath26 .",
    "we define the weighted average to be @xmath78 where the weights minimize the empirical risk @xmath79 under the constraints @xmath80 and @xmath81 .",
    "one can determine the solution @xmath82_{i=1}^p$ ] by solving a standard quadratic programming problem : @xmath83 where @xmath84 is the @xmath85 matrix @xmath86_{i , j=1}^p \\label{eqn : bmatrix}\\end{aligned}\\ ] ] and @xmath87 is the vector @xmath88_{i=1}^p \\ , ; \\label{eqn : bvector}\\end{aligned}\\ ] ] the tildes here indicate use of the validation data .",
    "risk estimates , such as those given in equations [ eqn : beta_risk ] and [ eqn : cde_risk ] , allow us to tune estimators and to choose between estimators , but they do not ultimately convey how well the estimator performs in an absolute sense .",
    "below we describe diagnostic tests that one can use to more closely assess the quality of different models .",
    "similar tests can be found in the time series literature ( see , e.g. , @xcite ) .",
    "let @xmath89 denote the estimated conditional cumulative distribution function , i.e. , let @xmath90 if the chosen estimator performs well , then the empirical cumulative distribution function ( cdf ) of the values @xmath91 will be consistent with the cdf of the uniform distribution .",
    "we can test this hypothesis via , e.g. , the cramr - von mises , anderson - darling , and kolmogorov - smirnoff tests . if the @xmath77-value output by the test is @xmath92 , then we fail to reject the null hypothesis that the data @xmath93 are sampled from a uniform distribution .",
    "we can use the values @xmath91 defined above to build a quantile - quantile ( or qq ) plot , by determining the number of data in bins of width @xmath94 .",
    "let @xmath59 be the number of bins , each of which has midpoint @xmath95 and the fraction of data @xmath96 .",
    "the qq plot is that of the values @xmath96 against @xmath95 ; if the chosen estimators perform well , the points in this plot will approximately lie on the line @xmath97 .",
    "we assess consistency with uniformity via the chi - square goodness of fit ( gof ) test , which utilizes the chi - square statistic @xmath98 we conclude that the difference data are consistent with constancy if the @xmath77 value , the fraction of the time that a value of @xmath99 would be observed that is greater than @xmath100 if the null hypothesis of constancy is true , is @xmath92 . note that the off - the - shelf gof test , which allows one to compute the @xmath77 value by taking the tail integral of an appropriate chi - square distribution , requires that the number of expected counts in each bin be @xmath101 5 .",
    "when that condition is violated , one should use simulations to estimate @xmath77 values .      for every @xmath102 in a grid of values on @xmath103 $ ] of length @xmath59 , and for every observation @xmath104 in the labeled test sample , we determine the smallest interval @xmath105 $ ] such that @xmath106 then , for every @xmath102 , we determine the proportion of redshifts lie within @xmath107 , i.e.  we compute @xmath108 if the chosen estimators perform well , then @xmath109 . we plot the values of @xmath110 against corresponding values of @xmath111 and assess how close the plotted points are to the line @xmath112",
    "; we can test for consistency with that line using the chi - square gof test , as described above .",
    "note that the construction of coverage plots is also proposed by @xcite , who conclude that the @xmath4 produced by the template - based bpz and eazy codes are consistently too narrow and approximately correct , respectively .",
    "to demonstrate the efficacy of our conditional density estimation method , we apply it to @xmath110@xmath2 galaxies that are mostly from data release 8 of the sloan digital sky survey @xcite .",
    "to build our unlabeled ( i.e.  photometric ) dataset , we initially extract model magnitudes for 540,235 objects in the sky patch ra @xmath113 [ 168@xmath114,192@xmath114 ] and @xmath116 $ ] . after filtering these data in the manner of @xcite , namely limiting our selection to those data",
    "whose @xmath17 magnitudes were _ all _ between 15 and 29 , and then further limiting ourselves to data for which @xmath117 we obtain a sample of 538,974 objects .",
    "we use the labeled ( i.e.  spectroscopic ) dataset of @xcite ( e.  sheldon , private communication ) .",
    "this dataset includes 435,875 objects from sdss dr8 and 31,835 objects from eight other sources , or 467,710 objects in all .",
    "as noted by @xcite , this dataset contains a small number of stars .",
    "we remove these by excluding all data with spectroscopic redshift @xmath118 ; after this , we are left with 465,790 objects .",
    "the steps of our analysis are given in algorithms [ alg : full ] and [ alg : preproc ] .",
    "as noted in section [ sect : pstate ] , the labeled and unlabeled data that we analyse are samples from the larger pools of available data described immediately above .",
    "( in this work we set @xmath119 . )",
    "this is for computational efficiency , both from a standpoint of time and memory ; for instance , if we utilize matrices for storing distances between data points , we are currently limited to samples of size @xmath120 10@xmath121 when utilizing typical desktop computers .",
    "* input : * number of labeled and unlabeled data , @xmath42 and @xmath43 .",
    "+ labeled dataset @xmath122 and unlabeled dataset @xmath123 .",
    "+ number of nearest labeled neighbors , @xmath39 .",
    "+ minimum number of unlabeled data required for selection of new labeled datum , @xmath45 .",
    "* randomly permute all labeled data indices ( i.e.  those from the larger pool of all available labeled data ) . *",
    "loop over the permuted set of indices @xmath124 : + estimate @xmath125 within the volume containing the @xmath39 nearest neighbors among @xmath40 ( via e.g.  equation [ eqn : beta_nn ] ) + if @xmath126 , accept @xmath127 as a new labeled datum + if the number of new labeled data equals @xmath42 , terminate loop .",
    "* output : * new labeled dataset @xmath128 .",
    "+ the importance weights for these data are re - estimated and are applied to conditional density estimation ( e.g.  equation [ eqn : cde_nn ] , and equation [ eqn : cde_risk ] ) .",
    "[ alg : preproc ]      as shown in equation [ eqn : cde_nn ] , the estimation of conditional densities is partially a function of @xmath129 , so there is a distinction to be drawn between the stated labeled sample size ( e.g.  @xmath42 = 15000 , drawn from a pool of size 465,790 ) and the effective size ( the number of data that contribute to estimation , i.e.  the number for which @xmath130 ) .",
    "thus one important step of our method involves preprocessing the labeled data to increase their effective size .",
    "the preprocessing of the labeled data requires the specification of a threshold importance weight @xmath131 .",
    "given @xmath42 and @xmath43 labeled and unlabeled data , respectively , and having specified a minimum number of unlabeled data @xmath45 that would have to lie closer to a random labeled point @xmath132 ( drawn from the larger pool ) than the @xmath36 nearest labeled neighbor to that point , we keep @xmath132 as part of our _ new _ labeled dataset if @xmath133 the value @xmath131 is not tunable , per se , as different thresholds yield different labeled datasets , leading to estimated risks that are not directly comparable .",
    "one might conjecture that larger values of @xmath131 are better , in that the distribution of the labeled data will more closely resemble that of the unlabeled data ( see figures [ fig : covshift ] and [ fig : preproc ] ) .",
    "however , as we demonstrate below , our results are not highly sensitive to the choice of @xmath131 , so long as @xmath134 .",
    "once preprocessing is complete , we repeat the estimation of the importance weights @xmath129 and apply these values when estimating conditional densities ( e.g.  equation [ eqn : cde_nn ] , and equation [ eqn : cde_risk ] ) .    , except that here we construct the labeled data with the preprocessing scheme outlined in algorithm [ alg : preproc ] so as to increase the effective sample size ( i.e.  the number of labeled data with non - zero importance weights ) . the panels exhibit preprocessing with @xmath135 and @xmath136 , respectively from top to bottom ( see equation [ eqn : preproc ] ) .",
    "( for larger values of @xmath131 , we can not fully populate a labeled subsample of size @xmath137 from the pool of labeled data at our disposal . ) in all three cases , the distributions for the labeled data ( red dashed lines ) more closely resembles those for the unlabeled data ( blue solid lines ) , relative to the labeled distributions exhibited in figure [ fig : covshift ] .",
    "subsequent to preprocessing we re - estimate the importance weights @xmath129 and apply these values to the estimation of conditional densities ( e.g.  equation [ eqn : cde_nn ] , and equation [ eqn : cde_risk ] ) .",
    ", title=\"fig : \" ] , except that here we construct the labeled data with the preprocessing scheme outlined in algorithm [ alg : preproc ] so as to increase the effective sample size ( i.e.  the number of labeled data with non - zero importance weights ) .",
    "the panels exhibit preprocessing with @xmath135 and @xmath136 , respectively from top to bottom ( see equation [ eqn : preproc ] ) . ( for larger values of @xmath131 , we can not fully populate a labeled subsample of size @xmath137 from the pool of labeled data at our disposal . ) in all three cases , the distributions for the labeled data ( red dashed lines ) more closely resembles those for the unlabeled data ( blue solid lines ) , relative to the labeled distributions exhibited in figure [ fig : covshift ] .",
    "subsequent to preprocessing we re - estimate the importance weights @xmath129 and apply these values to the estimation of conditional densities ( e.g.  equation [ eqn : cde_nn ] , and equation [ eqn : cde_risk ] ) .",
    ", title=\"fig : \" ] , except that here we construct the labeled data with the preprocessing scheme outlined in algorithm [ alg : preproc ] so as to increase the effective sample size ( i.e.  the number of labeled data with non - zero importance weights ) . the panels exhibit preprocessing with @xmath135 and @xmath136 , respectively from top to bottom ( see equation [ eqn : preproc ] ) .",
    "( for larger values of @xmath131 , we can not fully populate a labeled subsample of size @xmath137 from the pool of labeled data at our disposal . ) in all three cases , the distributions for the labeled data ( red dashed lines ) more closely resembles those for the unlabeled data ( blue solid lines ) , relative to the labeled distributions exhibited in figure [ fig : covshift ] .",
    "subsequent to preprocessing we re - estimate the importance weights @xmath129 and apply these values to the estimation of conditional densities ( e.g.  equation [ eqn : cde_nn ] , and equation [ eqn : cde_risk ] ) .",
    ", title=\"fig : \" ]      once we generate our new labeled dataset , we split the labeled and unlabeled data into training ( @xmath46 ) , validation ( @xmath138 ) , and test ( @xmath48 ) sets .",
    "we forego model assessment for importance weight estimators in this work ; @xcite demonstrate that the estimator given in equation [ eqn : beta_nn ] consistently performs better than five other competing methods over a number of different levels of covariate shift .",
    "we apply equations [ eqn : beta_nn ] and [ eqn : beta_risk ] to the training and validation data to determine the optimal number of nearest neighbors @xmath39 and importance weights @xmath129 given @xmath39 .",
    "we then apply these importance weights and the estimated risk in equation [ eqn : cde_risk ] to the training and validation data within the context of three cde estimators detailed in @xcite : nn - cs , the estimator of @xcite ; kernn - cs , a kernelized variation of nn - cs ; and series - cs , the spectral series estimator of @xcite .",
    ": we note that any estimates @xmath38 and @xmath4 made near ( potentially sharp ) parameter - space boundaries will suffer from some amount of additional  boundary bias . \"",
    "mitigating boundary biases in photo - z estimation is an important topic that we will pursue in a future work .",
    "] in figure [ fig : preproc2 ] we demonstrate the importance of preprocessing to generate the labeled dataset : without it , the construction of conditional density estimates for the unlabeled data would be effectively limited to the regime @xmath139 .",
    "the fraction of unlabeled test set data with @xmath140 is approximately 7.5% ; in contrast , the fraction for @xmath141 is 88.5% . in figure",
    "[ fig : risk ] we demonstrate that for our particular sdss data , the kernn - cs estimator on average outperforms the other two .",
    "( note that the risk can be negative because we ignore the positive additive constant @xmath72 ; see equation [ eqn : cde_risk_int ] . )",
    "we use the method outlined in section [ sect : combine ] to optimally combine the conditional density estimates from kernn - cs and series - cs and we determine that combining these estimators , on average , indeed yields better estimates of the conditional densities @xmath142 .     before",
    "( red dashed line ) and after ( blue solid line ) application of the labeled data preprocessing scheme described in section [ sect : preproc ] and algorithm [ alg : preproc ] . without preprocessing ,",
    "there are effectively no data with which to learn a statistical model linking the covariates and redshift in the regime @xmath143 , a regime that contains @xmath144 90% of the unlabeled data . ]    ) .",
    "the four points in each group represent different values for the importance weight threshold @xmath131 in our scheme for preprocessing labeled data ; from left to right , @xmath145 and @xmath136 ( black , red , green , and blue respectively ) .",
    "the estimated risks for each @xmath131 were adjusted to have mean @xmath1462.2 . in all four cases ,",
    "we observe that combining the kernn - cs and series - cs estimators leads to better conditional density estimates than either yield themselves . ]",
    "made for a single labeled test - set galaxy via bootstrapping of the labeled training dataset .",
    "the solid red vertical line indicates the true redshift . as described in the text",
    ", we make a preliminary assessment of the noise properties of @xmath4 by computing the true redshift quantile for each curve ( i.e.  the integral of the curve between zero and the true redshift ) , computing the sample standard deviation of these quantiles , and determining the overall mean standard deviation . here",
    ", the standard deviation of the quantiles is @xmath1 0.13 ; on average the standard deviation is @xmath1 0.06 . ]",
    "we make a preliminary assessment of the noise properties of the estimates @xmath142 as follows .",
    "we create @xmath147 bootstrap samples of the labeled training data and use them to generate @xmath147 @xmath142 curves for each labeled test datum .",
    "( see figure [ fig : bootstrap ] . )",
    "then we compute the quantile of the true redshift given each curve , so that for each labeled test datum we have @xmath147 quantile values .",
    "we use the mean of the standard deviations of each set of quantile values as a metric of uncertainty . for our particular sdss data",
    ", we determine this mean uncertainty to be @xmath1 0.065 .",
    "we will examine the noise properties of the estimates @xmath142 at greater depth in a future work .    in figure",
    "[ fig : qqall ] we demonstrate the tradeoff that is inherent when mitigating covariate shift , via the incorporation of importance weights into estimation , using qq plots .",
    "if we do not mitigate covariate shift , we achieve good conditional density estimates within those portions of covariate space in which @xmath148 ( orange dashed - dotted line ) ; however , @xmath149 8% of the unlabeled data reside within these portions .",
    "mitigation of covariate shift leads to a worsening of the cdes within these portions of covariate space ( black dashed line ) , but allows one to make good estimates throughout the remaining space ( blue solid line ) .",
    "in figures [ fig : qq ] , [ fig : alpha ] and [ fig : unif ] we show the results of applying hypothesis tests based on qq plots ( section [ sect : qq ] ) , coverage plots ( section [ sect : cov ] ) and the assumption of uniformity ( section [ sect : unif ] ) . in the first two figures we show the results of using the gof test to determine the consistency of expected and observed quantiles at each unique value of @xmath129 , in the manner outlined in section [ sect : diag ] .",
    "these results are generated using the labeled test set data , assuming a preprocessing threshold @xmath150 .",
    "( the optimal number of nearest neighbors given this threshold is 20 , hence the unique values of @xmath129 are 0 , 0.05 , 0.1 , etc . ) in the middle and bottom panels , we observe that for @xmath151 , the chi - square values are much larger , and the @xmath77 values much smaller , than what we would expect if @xmath97 : we do not achieve good behavior in this regime .",
    "( this is consistent with the behavior of the qq plots shown in figure [ fig : qqall ] . ) for @xmath152 , on the other hand , the @xmath77 values are generally @xmath92 .",
    "we thus conclude that our method generates useful conditional density estimates in the regime @xmath152 .",
    "( we note that we come to similar conclusions if we use the preprocessing thresholds @xmath153 or @xmath154 instead . )     and @xmath155 ( black dashed and blue solid lines respectively ) , and labeled test data for the case where we do not mitigate covariate shift by incorporating importance weights into estimation ( orange dashed - dotted line , largely following the blue solid line ) , which effectively limits modeling to the regime @xmath148 ( see figure [ fig : preproc2 ] ) .",
    "this plot demonstrates that mitigating covariate shift leads to worse conditional density estimates in the portion of covariate space where @xmath148 and where @xmath149 8% of the unlabeled data are located ( orange line vs. black line ) , but yields good estimates throughout the remaining covariate space ( blue line vs. orange line ) . ]",
    "figure [ fig : unif ] shows the results of applying the cramr - von mises , anderson - darling , and kolmogorov - smirnov tests ( from top to bottom , respectively ) to the data @xmath41 generated from the cdfs of the conditional density estimates @xmath4 of the labeled test set data , again assuming @xmath150 .",
    "we observe similar behavior for the @xmath77 values here as observed in figure [ fig : qq ] , with two differences : ( 1 ) the @xmath77 values are generally above 0.05 for @xmath143 as opposed to 0.3 , and ( 2 ) there are more numerous deviations from uniformity in the regime @xmath143 than seen in the bottom panel of figure [ fig : qq ] , particularly in the case of the ad test ( middle panel , figure [ fig : unif ] ) .    )",
    "are constant across quantile bins , using the labeled test set data at each unique value of @xmath129 .",
    "our estimates of @xmath142 are generated via the combined estimator . in all panels , the blue dots / black crosses represent results generated with / without covariate shift mitigation ( i.e.  with / without the incorporation of importance weights into estimation ) , with the blue / black triangles specifying data points that fall outside the plot panels .",
    "( there are insufficient data above @xmath156 to generate results without mitigating covariate shift . )",
    "the top panel shows the fraction of data for each unique value , with the dashed red lines indicating 0.1% , 1% , and 10% respectively .",
    "the middle panel shows the chi - square statistic resulting from each test , with the red dashed line indicating the number of bins ( @xmath157 ) , the value to which chi square should converge if our estimator performs well in regions of covariate space with appreciable densities of unlabeled data .",
    "the bottom panel shows the @xmath77 value , estimated via simulation since the usual assumption of the chi - square goodness of fit test that there are at least five expected counts in each bin is usually violated ; the red dashed line indicates @xmath158 , with points above that line indicating that the observed quantile value differences are consistent with constancy across quantile bins .",
    "the middle and bottom panels demonstrate that our method achieves desired quantile - quantile behavior at @xmath152 , while also demonstrating the importance of assuming covariate shift with these data : without this assumption , we can only generate reasonable predictions for unlabeled data in the regime @xmath148 .",
    "we assume @xmath150 ; analogous plots for @xmath153 and @xmath154 , not shown , indicate similar results . ]    , except instead of quantile - quantile behavior we examine the differences between observed and expected coverage as a function of @xmath129 , and only for the case where we mitigate covariate shift .",
    "the top and bottom panels demonstrate that our method achieves good coverage for @xmath143 . ]",
    "are uniformly distributed , using the labeled test set data at each unique value of @xmath129 .",
    "our estimates of @xmath159 are generated via the combined estimator .",
    "the panels show @xmath77 values generated via the cramr - von mises ( cvm ) , anderson - darling ( ad ) , and kolmogorov - smirnov ( ks ) tests , from top to bottom respectively .",
    "the ks test statistic is the maximum deviation of the empirical cumulative distribution function ( cdf ) for @xmath41 from the uniform cdf , while the cvm and ad statistics are based on ( unweighted and weighted ) integrated distances between the empirical and uniform cdfs .",
    "these panels demonstrate that our method generally achieves good behavior with respect to uniformity at @xmath143 ( cf .  0.3 and 0.5 for tests based on qq and coverage plots ) .",
    "this plot shows results for the preprocessing threshold @xmath150 ; analogous plots for @xmath153 and @xmath154 , not shown , indicate similar results . ]",
    "in this paper , we provide a principled method for generating conditional density estimates @xmath142 ( elsewhere commonly denoted @xmath5 and dubbed the  photometric redshift pdf \" ) that takes into account selection bias and the covariate shift that this bias induces .",
    "( see figure [ fig : covshift ] for an example of both : a bias towards brighter galaxies leads to shifted distributions of colours between spectroscopic and photometric data samples .",
    "see also algorithms [ alg : full ] and [ alg : preproc ] . )",
    "if not mitigated , covariate shift leads to situations where models fit to labeled ( i.e.  spectroscopic ) data will not produce scientifically useful fits to the far more numerous unlabeled ( i.e.  photometric - only ) data , lessening the impact of photo - z estimation within the context of precision cosmology . here , we mitigate covariate shift by first estimating importance weights , the ratio @xmath10 between the densities of unlabeled and labeled data at point @xmath0 ( section [ sect : iw ] ) , and then applying these weights to conditional density estimates @xmath142 ( section [ sect : cde ] ) .    in order for our two - step procedure to succeed , ultimately , we require good estimates of @xmath10 at labeled data points in order for it to achieve good estimates @xmath142 at unlabeled ones .",
    "we thus need both rigorously defined risk functions that allow us to tune the free parameters of our importance weight and conditional density estimators , and diagnostic tests that allow us to determine the quality of the estimates @xmath142 .",
    "our method is based on the assumption that the probability that astronomers label a galaxy ( i.e.  determine its spectroscopic redshift ) depends only on its ( photometric and perhaps other ) properties @xmath0 and not on its true redshift , an assumption currently valid for redshifts @xmath1490.5 .",
    "this is equivalent to assuming that the conditional densities for labeled and unlabeled data match ( @xmath160 ) , even if the marginal distributions differ ( @xmath161 ) , which allows us ultimately to substitute out the true unknown quantities @xmath10 and @xmath11 in specifications of risk functions ( equations [ eqn : beta_risk ] and [ eqn : cde_risk ] ) .",
    "these risk functions , and their estimates ( equations [ eqn : beta_risk ] and [ eqn : cde_risk ] ) , are the backbone of our method : they allow us to tune parameters in a principled manner ( e.g.  what is the optimal number of nearest labeled neighbors when estimating @xmath10 via equation [ eqn : beta_nn ] ? ) , as well as choose between competing estimators ( e.g.  which is better : the nn - cs , kernn - cs or series - cs estimators of conditional density ? ) .",
    "an important question to answer in future work is whether we can relax our central assumption and still be able to write down estimated risks that lead to useful estimates of conditional densities in higher redshift regimes .    in section [",
    "sect : combine ] , we demonstrate that once we generate @xmath77 separate conditional density estimates @xmath162 ( e.g.  via the kernn - cs and series - cs estimators ) , tuned via the estimated risk given in equation [ eqn : cde_risk ] , we can combine them to achieve better predictions ( i.e.  smaller values of risk ) .",
    "the method we propose utilizes a weighted linear combination , with the weights determinable via quadratic programming , but this is not the only possible way to combine estimates ; see , e.g. , @xcite , who discuss three methods for combining estimates , including one ( method 2 ) that adds estimates together as we do , except that while we determine optimal coefficients by minimizing estimated risk , they combine estimates so that 68.3% of the spectroscopic redshifts in their sample fall within their final 1@xmath163 confidence intervals .    it is not sufficient to generate estimates @xmath142 by minimizing risk ; one also needs to demonstrate that the estimates are scientifically useful .",
    "there is no unique way to demonstrate the quality of conditional density estimates . in section [",
    "sect : diag ] , we provide alternatives that test ( 1 ) whether estimated cumulative densities , evaluated at actual redshifts , are distributed uniformly ; ( 2 ) whether observed quantiles match expectation via qq plots and the chi - square gof test ; and ( 3 ) testing uniformity as a function of interval coverage .",
    "the jury is still out as to which of these diagnostics will play a central role in future photo - z analyses ; for now , we consider it sufficient to demonstrate in any analysis that these diagnostics yield similar qualitative results .",
    "in section [ sect : sdss ] , we demonstrate our method using @xmath1500,000 galaxies with , and @xmath1500,000 without , spectroscopic redshifts , mostly from the sloan digital sky survey ( see @xcite for details ) . for computational efficiency , we sample 15,000 galaxies from both pools of data .",
    "while our initial labeled sample is chosen randomly from the larger pool of labeled data , we implement a preprocessing scheme ( see algorithm [ alg : preproc ] ) to generate a new labeled sample with a larger effective size , whose photometry also more closely resembles that of the unlabeled sample ( see figure [ fig : preproc ] ) .",
    "the preprocessing scheme requires the specification of an importance weight threshold ( @xmath131 ) whose value can not be optimized via tuning ( since different thresholds yield different labeled datasets , and thus yield not - directly comparable estimated risks ) .",
    "we demonstrate that our results are generally insensitive to the choice of threshold within the regime @xmath164 .",
    "those results include that ( 1 ) as expected , the conditional density of combined estimator , constructed from those of the kernn - cs and series - cs estimators , provide the best estimates as quantified via the risk estimate in equation [ eqn : cde_risk ] , and ( 2 ) via our diagnostic tests , we determine that our combined estimates exhibit good behavior in the regimes @xmath165 , for qq - based tests , and @xmath166 , for tests of coverage and cumulative densities .",
    "our results thus demonstrate that our method achieves good , i.e.  scientifically useful , conditional density estimates for unlabeled galaxies .",
    "the authors would like to thank jeff newman ( university of pittsburgh ) for helpful discussions about photometric redshift estimation .",
    "this work was partially supported by nsf dms-1520786 , and the national institute of mental health grant r37mh057881 .",
    "ri further acknowledges the support of the fundao de amparo  pesquisa do estado de so paulo ( 2014/25302 - 2 ) .    99 aihara h. , et al . , 2011 , apjs , 193(2):29 ball n.  m. , brunner r.  j. , 2010 , international journal of modern physics d , 19 , 1049 bentez n. , 2000 , apj , 536 , 571 bonnett c. , 2015 , mnras , 449 , 1043 brammer g. , von dokkum p. , coppi p. , 2008 ,",
    "apj , 686 , 1503 budavri t. , 2009 , apj , 695 , 747 carliles s. , budavri t. , heinis s. , priebe c. , szalay a.  s. , 2010 , apj , 712 , 511 carrasco kind m. , brunner r. , 2013 , mnras , 432 , 1483 carrasco kind m. , brunner r. , 2014 , mnras , 438 , 3409 collister a.  a. , lahav o. , 2004 , pasp , 116 , 345 corradi v. , swanson n.  r. , 2006 , in elliott g. , granger c. , timmermann a. , eds , handbook of economic forecasting .",
    "elsevier , amsterdam , p.  197",
    "csabai i. , dobos l. , trencsni m. , herczegh g. , jsza p. , purger n. , budavri t. , szalay a.  s. , 2007 , astronomische nachrichten , 328 , 852 cunha c.  e. , lima m. , oyaizu h. , frieman j. , lin h. , 2009 , mnras , 396 , 2379 dahlen t. , et al . , 2013 , apj , 775 , 93 de vicente j. , snchez e. , sevilla - noarbe i. , 2016 , mnras , 459 , 3078 flaugher b. , 2005 , int .",
    "j.  modern phys .  a , 20 , 3121 gretton a. , smola a. , huang j. , schmittfull m. , borgwardt k. , schlkopf b. , 2008 , in quionero - candela j. , sugiyama m. , schwaighofer a. , lawrence n.  d. , eds , dataset shift in machine learning . mit press , cambridge hall p. , 1987",
    ", the annals of statistics , 15 , 1491 hildebrandt h. , et al . , 2010 , a&a , 523 , a31 hoyle b. , rau m.  m. , bonnett c. , seitz s. , weller j. , 2015 , mnras , 450 , 305 ivezi  . , 2008 , arxiv:0805.2366 izbicki r. , lee a. , freeman p.  e. , 2016 , annals of applied statistics , submitted ( arxiv:1604.01339 ) izbicki r. , lee a.  b. , 2015 , journal of computational and graphical statistics izbicki r. , lee a. , schafer , c.  m. , 2014 , journal of machine learning research w&cp ( aistats track ) , 33 james g. , witten d. , hastie t. , tibshirani , r. , 2014 , an introduction to statistical learning : with applications in r , springer , new york kanamori t. , hido s. , sugiyama , m. , 2009 , journal of machine learning research , 10 , 1391 kanamori t. , suzuki t. , sugiyama , m. , 2012 , machine learning , 86(3 ) , 335 kremer j. , gieseke f. , steenstrup pedersen k. , igel c. , 2015 , astronomy and computing , 12 , 67 lima m. , cunha c.  e. , oyaizu h. , frieman j. , lin h. , sheldon e. , 2008 , mnras , 390 , 118 loog m. , 2012 , in 2012 ieee international workshop on machine learning for signal processing mandelbaum r. , 2008 , mnras , 386 , 781 moreno - torres j.  g. , raeder t. , alaz - rodrguez r. , chawla n.  v. , herrera f. , 2012 , pattern recognition , 45 , 521 rau m.  m. , seitz s. , brimiouelle f. , frank e. , friedrich o. , gruen d. , hoyle b. , 2015 , mnras , 452 , 3710 snchez c. , et al . , 2014 , mnras , 445 , 1482 sheldon e.  s. , cunha c.  e. , mandelbaum r. , brinkmann j. , weaver b.  a. , 2012 , apjs , 201(2):32 sugiyama m. , suzuki t. , nakajima s. , kashima h. , bnau p. , kawanabe m. , 2008 , annals of the institute of statistical mathematics , 60(4):699 wasserman l. , 2006 , all of nonparametric statistics , springer , new york wittman d. , 2009 , apj , 700 , l174 wittman d. , bhaskar r. , tobin r. , 2016 , mnras , 457 , 4005 york d. , et al . , 2000 ,",
    "aj , 120 , 1579"
  ],
  "abstract_text": [
    "<S> photometric redshift estimation is an indispensable tool of precision cosmology . </S>",
    "<S> one problem that plagues the use of this tool in the era of large - scale sky surveys is that the bright galaxies that are selected for spectroscopic observation do not have properties that match those of ( far more numerous ) dimmer galaxies ; thus , ill - designed empirical methods that produce accurate and precise redshift estimates for the former generally will not produce good estimates for the latter . in this paper </S>",
    "<S> , we provide a principled framework for generating conditional density estimates ( i.e.  photometric redshift pdfs ) that takes into account selection bias and the covariate shift that this bias induces . </S>",
    "<S> we base our approach on the assumption that the probability that astronomers label a galaxy ( i.e.  determine its spectroscopic redshift ) depends only on its measured ( photometric and perhaps other ) properties @xmath0 and not on its true redshift . with this assumption </S>",
    "<S> , we can explicitly write down risk functions that allow us to both tune and compare methods for estimating importance weights ( i.e.  the ratio of densities of unlabeled and labeled galaxies for different values of @xmath0 ) and conditional densities . </S>",
    "<S> we also provide a method for combining multiple conditional density estimates for the same galaxy into a single estimate with better properties . </S>",
    "<S> we apply our risk functions to an analysis of @xmath110@xmath2 galaxies , mostly observed by sdss , and demonstrate through multiple diagnostic tests that our method achieves good conditional density estimates for the unlabeled galaxies .    </S>",
    "<S> [ firstpage ]    galaxies : distances and redshifts  galaxies : fundamental parameters  galaxies : statistics  methods : data analysis  methods : statistical </S>"
  ]
}