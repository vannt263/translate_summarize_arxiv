{
  "article_text": [
    "there are many multi - epoch imaging surveys in progress or coming up , which will , among other things , deepen our image of the sky and provide information on source variability and proper motions .",
    "these surveys include the sdss southern stripe @xcite , the dark energy survey , panstarrs , lsst , and snap .",
    "these surveys promise proper - motion precisions for well - detected sources on the order of @xmath0 over large parts of the sky . for context , a typical halo star at a distance of @xmath1 moving at a transverse heliocentric speed of @xmath2 has a proper motion of @xmath3 , and a typical disk star at @xmath4 and @xmath5 has a proper motion of @xmath6 .",
    "these surveys therefore have the capability of revolutionizing our view of the galaxy and of the solar neighborhood .    in most conceptions of a proper - motion measurement",
    ", one imagines measuring the position of a source in each of several images , taken at different times .",
    "a linear trajectory is fitted to the positions , relative to some reference frame or set of fixed sources or sources with well measured proper motions . in its most straightforward form",
    ", this method only works for sources bright enough to be detected independently at every epoch  or at least most epochs . in a multi - epoch survey like the sdss southern stripe , which has @xmath7 epochs @xcite , this limits the sources with measured proper motions to a small subset of all sources detectable in the combined data , since the combined data reach @xmath8 fainter than any individual epoch ; for typical source populations this represents increases in population size by factors of @xmath9 to @xmath10 at any given signal - to - noise threshold . in this paper",
    "we present a methodology for measuring in multi - epoch imaging the proper motions of sources too faint to detect at any individual epoch .",
    "there are several different technical regimes for these faint - source proper - motion measurements . in the `` easy '' regime ,",
    "the sources of interest move a distance smaller than or comparable to the point - spread function width over the duration of the multi - epoch survey . in this regime ,",
    "the sources are easy to detect in the co - added image , even without taking account of their proper motions ; proper motions can be determined from processing the individual epoch images after detection in the co - added image .",
    "there is a `` difficult '' regime in which the sources of interest move substantially more than the width of the point - spread function over the duration of the survey . in this regime ,",
    "the source will not appear at high significance in the co - added image if it does not appear at high significance at any epoch , because its different appearances in the different individual - epoch images do not overlap . in principle , the difficult regime can be addressed by brute force with large computing resources . in the context of outer solar - system bodies ,",
    "brute - force search in the narrow range of expected motions is feasible ( for example , @xcite ) . in this paper , we consider only the easy regime .",
    "[ [ modeling - the - data ] ] modeling the data : + + + + + + + + + + + + + + + + + +    the traditional method for measuring a stellar proper motion with a set of images taken at different times is as follows : detect the star at each observed epoch ; measure its centroid ( by , for example , finding the peak or first moment of the flux ) at each observed epoch ; and fit a linear motion to the measured positions and times .",
    "this procedure obtains a proper motion , but it puts an unnecessary requirement on the data : that the star be detectable at every epoch .",
    "it also puts an unnecessary burden on the data analyst : it requires decision making about detection and centroiding of the stars at each epoch , decisions that matter at low signal - to - noise , or when faced with data issues such as bad pixels or strong variations in noise from pixel to pixel .",
    "our new approach is to _ model _ all individual - epoch images simultaneously with a single point source that is permitted to have a non - zero parallax and proper motion .",
    "this approach combines the individual - image positional measurement and the determination of the parallax and proper motion , and determines all of these simultaneously by making a statistically `` good '' model of the union of all the data .",
    "in any well - understood imaging survey , each image will have a per - pixel noise model , photometric calibration parameters , and a model of the point - spread function .",
    "in any sufficiently small patch of the sky , if the foreground - subtracted intensity in that patch is dominated by a small number of point sources , it is possible to make an accurate model of all of the pixels in the data set that contribute signal to that small patch . in this model of the patch , the fluxes , angular positions , parallaxes , and proper motions of the stars in the patch are simply parameter values in the well - fitted models . in other words , we are assuming that it is possible to model the set of pixels ( from all of the images ) that contribute to the patch with a @xmath11-dimensional model that consists of a set of @xmath12 moving point sources .",
    "the proper motions determined by image modeling have several advantages over those determined by the traditional method : they require fewer decisions about measurement techniques ( although they do require a good model of the data , including point - spread function ) ; they use all of the information in all of the pixels , not just those pixels involved in traditional centroiding ; they gracefully handle missing data due to bad pixels or cosmic rays ( assuming the bad pixels have been flagged ) ; they require the investigator to make explicit the assumptions about the physical properties of the image and the noise ; they can be made to properly propagate pixel - value uncertainties into parameter uncertainties ( in this case , proper motion uncertainties ) ; they are the result of optimization of a well - justified scalar objective function ( in this case the likelihood ) .",
    "most importantly for what follows , they can be determined in data sets in which the stars are not well detected at any individual epoch , but only appear in the _ combination _ of the images . in a data set with",
    "@xmath7 similar epochs ( such as the sdss southern stripe ) , this corresponds to an increase in the number of available targets by factors of @xmath9 to @xmath10 ( assuming source populations double to quadruple with each magnitude of depth ) .",
    "here we propose , build , test , and use an image - modeling system for the determination of stellar proper motions .",
    "we show that it can work down to low signal - to - noise ratios and that it makes measurements in real data that fully exploit the information available .",
    "we also use it to discover interesting new astrophysical sources .",
    "an approximation to the technique used here has been used previously in the solar system literature @xcite .",
    "[ [ proper - motion - and - parallax - uncertainties ] ] proper - motion and parallax uncertainties : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    consider a well - sampled image @xmath13 with a point - spread function of full width at half maximum @xmath14 .",
    "the signal - to - noise at which the flux of a point source can be measured , @xmath15}}_i$ ] , is the sum in quadrature of the signal - to - noise contributions from pixels within the point - spread function .",
    "a point source measured with signal - to - noise @xmath15}}_i$ ] in a single image can be centroided with ( rms ) uncertainty @xmath16 of @xmath17}}_i } \\quad ; \\ ] ] details such as the shape of the point - spread function introduce factors of order unity @xcite .",
    "if we have @xmath12 such images spanning some time interval , we might hope to obtain a proper motion estimate with uncertainty @xmath18 limited by the point - spread function , the time interval , and the total signal - to - noise @xmath19}}_{\\mathrm{total}}}^2=\\sum_{\\mathrm{images}\\ i}{{[s / n]}}_i^2    \\label{eq : sntotal}\\ ] ] in the combination of all the images ( we have assumed here that the images @xmath13 are all independent ) .",
    "the relevant time `` interval '' is not the total time spanned by the data but rather @xmath20 , the standard deviation ( root variance ) of the times ; the best possible proper - motion estimates will have uncertainties @xmath21}}_{\\mathrm{total } } } } \\quad ,    \\label{eq : muerror}\\ ] ] where properly @xmath22 is the square - signal - to - noise weighted mean point - spread function full width at half maximum , and @xmath23 is the square root of the square - signal - to - noise - weighted variance of the times at which the individual epoch images were taken .    by a similar argument , we hypothesize that the best possible parallax estimates will have uncertainties @xmath24}}_{\\mathrm{total } } } } \\quad , \\ ] ] where @xmath25 is the square root of the square - signal - to - noise - weighted variance of the trigonometric functions of the ecliptic longitude @xmath26 of the sun ( time of year in angle units ) : @xmath27 essentially , @xmath25 describes how well the parallactic ellipse is sampled ; an ideal survey for parallax measurements will have @xmath28 .",
    "disk stars move with respect to one another at velocities of @xmath29 @xcite , that is , on the same order as the velocity of the earth around the sun . in a multi - epoch survey spanning a small number of years ( such as the sdss southern stripe ) ,",
    "@xmath23 is of order unity , so for disk stars the parallax and proper motion signal - to - noise ratios ought to be comparable in magnitude .",
    "however , most surveys sample ecliptic longitude @xmath26 poorly , because of season and scheduling constraints ; therefore @xmath25 is usually substantially less than unity , so the signal - to - noise of parallax is smaller than that of proper motion .",
    "the goal is to measure the proper motions and parallaxes of sources detected in multi - epoch data .",
    "we start with a catalog of detections from a co - addition of the multi - epoch data ( co - added at zero lag or under an assumption that the sources are static ) .",
    "these detections serve as `` first - guess '' positions for sources in the imaging .",
    "we measure the properties of these sources by building models of all the individual images , at the pixel level , so that each model `` predicts '' every pixel value in every image at every epoch .    some of the candidate sources will not be point sources but rather resolved galaxies , and others will not be astronomical sources but will be caused by artificial satellites or imaging artifacts .",
    "we fit three qualitatively different models , described below .",
    "one is of a moving point source , one is of an extended galaxy , and one is of a general transient or artifact . for each model , `` fitting ''",
    "constitutes optimizing a scalar objective , which is the logarithm of the likelihood under the assumption that the per - pixel noise is gaussian with a known variance in each pixel . under the gaussian assumption",
    ", we can use the different values of the log likelihood to perform a hypothesis test based on likelihood ratios .",
    "this hypothesis test distinguishes point sources from extended galaxies and transients and artifacts .",
    "the parameters of the best - fitting model are the `` measurements '' of the source .",
    "nothing in what follows fundamentally depends on the assumption of gaussian noise .",
    "data with poisson errors , for example , can be analyzed the same way but with the objective function changed to the logarithm of the poisson likelihood .",
    "indeed , any noise model can be accomodated , though possibly at the expense of computational simplicity .    in detail , for each source , we have @xmath12 small images ( patches of what is presumed to be a much larger imaging data set ) @xmath13 taken at times @xmath30 , and we assume that each image has reasonable photometric calibration , a noise estimate in each pixel ( assumed gaussian , but that could be relaxed in what follows ) , and correct astrometric calibration or world coordinate system ( wcs ) fixed to an astrometric @xmath31 reference frame . from a co - added image made from all @xmath12 single - epoch images we",
    "have been given a candidate ( `` first - guess '' ) position @xmath32 for each source @xmath33 .",
    "[ [ point - source - model ] ] point - source model + + + + + + + + + + + + + + + + + +    the first of the three models is that of a point source , moving in space and a finite distance from the solar system .",
    "this point source is assumed to have a constant flux @xmath34 , a position @xmath32 at some standard epoch , a parallax @xmath35 and a proper motion @xmath36 . in this model and the models to follow",
    ", we assume that the sky level has been correctly fitted and subtracted from the images , or else that sky errors are not strongly covariant with errors in the model parameters . in fitting this model ,",
    "we find the six - dimensional quantity @xmath37 that optimizes the scalar objective .    given the times @xmath30 and wcs of the images , any point - source parameter set @xmath37 , specifies the pixel position of point source @xmath33 in each image @xmath13 . this position and the ( possibly position - dependent )",
    "point - spread function model for image @xmath13 permits construction of a pixel - for - pixel model of source @xmath33 as it ought to appear in image @xmath13 .",
    "if we had multi - band imaging ( the tests below are on are on single - band images ) , the flux @xmath34 becomes a set of fluxes @xmath38 , one for each bandpass @xmath39 . in principle , precise fitting is complicated by the existence of differential refraction for sources with extreme colors , so there are relationships among the fluxes @xmath38 , positional offsets , and the airmass or altitude of the observations . in the tests below",
    ", we are working far enough to the red that there are no differential refraction issues at the relevant level of precision .",
    "although we have assumed non - varying flux in our model , we should still be able to detect and measure moving sources with varying flux .",
    "we have not investigated this question , but we expect that our method would produce a flux estimate of approximately the mean flux measured at the available epochs , and that the point - source model would be preferred over the transient model , since the objective function is convex .    [ [ galaxy - model ] ] galaxy model + + + + + + + + + + + +    our model of a resolved galaxy is a gaussian distribution of flux with an elliptical covariance parameterized by its radius @xmath40 , eccentricity @xmath41 , angle @xmath42 and total flux @xmath34 . for each image , this gaussian model is convolved with that image s particular point - spread function to make a seeing - convolved galaxy model .",
    "this seeing - convolved gaussian galaxy model is not a realistic galaxy model , but it is good enough for distinguishing resolved and unresolved sources at the faint limit , which is sufficient here . again ,",
    "if we had multi - band imaging , the flux @xmath34 would be replaced by a set of fluxes @xmath43 .",
    "[ [ junk - model ] ] junk model + + + + + + + + + +    our model of a transient or imaging artifact is that there is nothing but noise in all but one of the images , and that one `` junk '' image contains many bright pixels .",
    "we compute this model trivially by computing the chi - squared ( @xmath44 ) contribution for each image under the assumption that there is no flux in the image at all . the image with the largest @xmath44 contribution",
    "is judged to be the `` junk '' image and is discarded . in order to keep the number of @xmath44 contributions constant , we replace the `` junk '' image @xmath44 by the median of the @xmath44 contributions of the remaining images .",
    "[ [ scalar - objective - optimization ] ] scalar objective optimization + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the choices of model , scalar objective , and optimization methodology can all be made independently .",
    "for the objective function the natural choice is the @xmath44 difference between the model and the data taken over all the pixels that are close to the first - guess position in all @xmath12 images .",
    "this objective is analogous to a logarithm of a likelihood ratio ; it is exact if the noise in the image pixels is gaussian and independent , with known variances ( which can vary from pixel to pixel ) . for optimizing this objective function",
    ", we use the levenberg - marquardt method @xcite .",
    "[ [ hypothesis - test ] ] hypothesis test + + + + + + + + + + + + + + +    in the approximation that the noise is gaussian , the best fits for each of the three models can be compared via the best - fit values of the @xmath44 scalar objective .",
    "if the three models are equally likely _ a priori _  and if they have the same number of degrees of freedom , then one model is confidently preferred over another if it has a best - fit @xmath44 value smaller by an amount @xmath45 .",
    "of course the models are not equally likely _ a priori _ , but for for the vast majority of sources , the differences in @xmath44 are so large that no reasonable prior would change the results of our hypothesis test .",
    "note that there is some degeneracy in our models : a galaxy model with zero radius and a star model with zero proper motion and parallax produce exactly the same predictions , and thus our hypothesis test can not distinguish them .",
    "this could be remedied by placing prior probabilies over the model parameters  for example , penalizing tiny galaxies  but since we are not concerned with the region of parameter space where this occurs , we have not done this .    rather than explicitly including a junk model , we could instead place a threshold on the likelihood of the star and galaxy models : junk data will be poorly fit by the star and galaxy models and thus will have tiny likelihood .",
    "in general we have found that image sets for which the junk model is preferred clearly contain artifacts or transients ; the method is not sensitive to the details of the junk model .",
    "[ [ jackknife - error - analysis ] ] jackknife error analysis + + + + + + + + + + + + + + + + + + + + + + + +    in principle , the region in parameter space around the best - fit point where @xmath44 is within unity of the minimum provides an estimate of the uncertainties in the fitted parameters .",
    "however , this estimate is only good when the model is a good fit ; many error contributions in real data come from source variability , poorly known data properties ( such as pixel uncertainty or point - spread - function estimates that are in error ) and unflagged artifacts in the data .",
    "for this reason , we use ( and advocate ) a `` jackknife '' technique for error analysis .",
    "the jackknife technique is to perform the analysis on the @xmath12 subsets of the @xmath12 images created by leaving one image out .",
    "the complete fit of the three models is performed on each of the @xmath12 leave - one - out subsets and parameters are measured .",
    "the uncertainty estimate @xmath46 for any fitted parameter @xmath47 is related to the @xmath12 leave - one - out measurements @xmath48 ( made leaving out image @xmath13 ) by @xmath49 where @xmath50 is the mean of the leave - one - out measurements @xmath48 .",
    "the jackknife technique automatically marginalizes the error estimates over the other parameters , and provides a properly marginalized estimate of any multi - parameter covariance matrix by the generalization of equation  ( [ eq : jackknife ] ) in which the square is changed into the @xmath51 matrix outer product of the `` vectors '' made from the @xmath52 parameters for which the covariance matrix is desired .",
    "of course when @xmath52 is large , the jackknife will not accurately sample all degrees of freedom available in the covariance matrix , but provided @xmath12 is large enough , it _ will _ sample the dominant eigenvectors ( the principal components ) .    [ [ implementation - notes ] ] implementation notes + + + + + + + + + + + + + + + + + + + +    our code is implemented in python and uses the django web framework , which provides powerful database and web server integration .",
    "this allows us to quickly and easily manage and visualize the data and results .",
    "combined with the scientific data analysis packages ` scipy ` and ` numpy ` and the plotting package ` matplotlib ` , this yielded a powerful software development environment .    for optimization",
    ", we use the levenberg - marquardt implementation ` levmar ` ( version 2.2 ; @xcite ) with python bindings ` pylevmar ` ( revision 313 ; @xcite ) . in this python environment , analysis takes on the order of seconds for each source ( 30 epochs , @xmath53 images ) , but this could be sped up substantially by implementing some of the core operations in ` c ` .",
    "for test data , we make use of the sdss southern stripe ( sdssss ) , a multi - epoch survey undertaken as part of sdss - ii @xcite .",
    "the sdssss data are part of the sloan digital sky survey @xcite ; it involves @xmath54 ccd imaging of @xmath55 on the equator in the southern galactic cap .",
    "all the sdssss data processing , including astrometry @xcite , source identification , deblending and photometry @xcite , and calibration @xcite are performed with automated sdss software .",
    "the sdssss data have been found to have a small astrometric drift @xcite , because astrometric calibration was performed at a single , slightly inappropriate epoch @xcite .",
    "this drift , for which we are making no correction , is at the @xmath56 level ; at the precision of this study it does not change any of the conclusions below .",
    "in general , the hypothesis test we perform requires that the variance of the noise be properly estimated on a pixel - by - pixel basis .",
    "these are based on an sdss imaging noise model , with the adjustment that pixels that have been corrupted by cosmic rays or other defects are given infinite variances ( vanishing contribution to @xmath44 ) .",
    "occasionally there are unidentified cosmic rays in the data .",
    "these lead to localized regions with very large contributions to @xmath44 .",
    "when one of these noise defects appears in the data near one of the targets , it sometimes causes a source which is truly a galaxy or a star to be assigned `` junk '' status .",
    "after by - eye inspection of cutouts , we estimate this rate to be on the order of @xmath57  percent for this data source ; the rate of such problems increases with the number of epochs and the image cut - out size ( the total number of pixels in the fit ) .    for some of the sources we have ukirt infrared deep sky survey ( ukidss ; @xcite ) data .",
    "ukidss uses the ukirt wide field camera @xcite with the infrared photometric system described by @xcite , and automated data processing and archiving @xcite .",
    "the ukidss data used here comes from the fourth data release .",
    "very red point sources in deep optical imaging  for example , @xmath58-band - only sources in the multi - epoch sdss southern stripe  include both very cool dwarfs and very high redshift quasars . in principle",
    "these can be distinguished with parallax and proper - motion estimates .",
    "for this reason , we performed a test on @xmath58-only point sources in the sdss southern stripe .",
    "the parent sample is point sources from the sdssss `` co - add catalog '' ( j.  annis _ etal .",
    "_ , in preparation ) that have @xmath59>2~{{\\mathrm{mag}}}$ ] and @xmath60>2~{{\\mathrm{mag}}}$ ] .",
    "this criterion selects quasars at @xmath61 as well as cool dwarfs with spectral types ranging from mid - l to t ( @xcite and references therein ) .",
    "hotter brown dwarfs , stars , and lower - redshift quasars have significant emission in the @xmath13 band , giving them bluer @xmath62 colours , while the emission features of cooler dwarfs and higher - redshift quasars lie mostly redwards of the sdss @xmath58 bandpass .",
    "the co - add catalog uses the asinh magnitude ( or `` luptitude '' ) scale @xcite , so it is possible to select objects based on color even for objects that are not detected in one of the bands .",
    "the version of the co - add catalog we are using is from sdss data release 7 ( dr7 ) , and includes @xmath63 to @xmath64 epochs over @xmath55 .",
    "since we are interested in distinguishing cool brown dwarfs from high - redshift quasars , we require @xmath18 to be small ( equation  [ eq : muerror ] ) .",
    "we therefore cut our parent sample to have @xmath65 , leaving roughly 150 sources .",
    "this cut allows us to reach , with moderate signal - to - noise , slightly fainter sources than are detectable in the single - epoch images . in a future paper",
    ", we plan to relax this cut , which should yield considerably more brown dwarf candidates at smaller signal - to - noise levels . of our 150 parent candidates ,",
    "some turn out to be caused by an imaging artifact or transient in one of the @xmath12 epochs , and some turn out to be galaxies or stars with mis - measured colors because of data artifacts or inaccuracies in deblending nearby objects .",
    "each of the catalog sources has a nominal position and a @xmath58-band magnitude in the co - add catalog . for each @xmath58-only source , we cut out @xmath66 patches of every sdss image at the nominal position .",
    "for each tiny image , we construct a tiny local world - coordinate - system description of the astrometric calibration of that patch using the sdss pipeline astrometric calibration .",
    "we subtract the local value of a smoothly fit sky level ( m.  blanton , in preparation ) and multiply each tiny image by a constant , based on the pipeline calibration information , to place it on a common photometric calibration scale in intensity units ( energy per unit solid angle per unit area per unit time per unit frequency ) . to the sdss pipeline - reconstructed point - spread function ( psf ) in each tiny image",
    "we fit a single - gaussian approximate model , which is not a good fit to the psf at high precision , but which is sufficient for modeling sources at low signal - to - noise .    in this work , we create the @xmath67 cutouts from the same @xmath63 to @xmath64 epochs that are used in the co - add catalog ; in future work we plan to use the @xmath7 epochs that have become available in dr7 .    we chose @xmath66 patches so that a source with proper motion of @xmath68 would remain in the patch .",
    "our method still works if the source leaves the patch  indeed , our fastest - moving candidate does this  but we gain no information from the epochs in which the source has left the patch , so the signal - to - noise of our parameter estimates will be less than optimal when this happens . we could choose to use larger cutouts ; the only difficulty is that if the patch contains more than one source , our model will try to explain the brightest source ( because this will decrease @xmath44 the most ) .",
    "this could perhaps be remedied by adding a prior on the source position , but since the sdssss data are from well below the galactic equator , stellar density is low and we have not found this to be necessary .",
    "alternatively , in cases where the source leaves the original patch we could produce new cutouts that track the source motion .",
    "s  [ fig : example ] through [ fig : examplecrap ] illustrate our approach by showing the results of the ( moving ) point - source and ( static ) galaxy model fits to four sources in the the sdssss data . in these figures",
    "we show all the individual @xmath69 images from the individual epochs , and the best - fit point - source and galaxy parameters . in these figures ,",
    "we visualize the distribution of acceptable parameters around the best - fit values through sampling .",
    "we also show mean images and mean residual maps in the static and moving coordinate systems .",
    "these figures demonstrate heuristically that the hypothesis test is effective at separating sources of different types , even when the source is not apparent at high signal - to - noise at any individual epoch .    in  [ fig : bubbles ]",
    "we show the overall results from application of our techniques to the @xmath59>2 $ ]  mag sources in the sdssss : we show proper - motion measurements and jackknife estimates of our uncertainties as a function of @xmath58-band magnitude .",
    "known quasars and brown dwarfs are marked .",
    "our measurements clearly separate the known quasars and brown dwarfs on the basis of proper motion alone .",
    "all known brown dwarfs in the sample obtain significant non - zero proper motion measurements , and all known high - redshift quasars in our sample obtain proper motion measurements consistent with zero .",
    "the sources in our sample that have significant motions and have not been previously identified as brown dwarfs are our new brown dwarf candidates . in  [ fig : colormag ] we show the ukidss and sdss @xmath70 $ ] colors of the sources for which we have ukidss @xmath71 measurements , with the known brown dwarfs and quasars and our new brown dwarf candidates marked .",
    "many of the sources in these s are undetectable ( or not detectable reliably ) at individual epochs ; the single - epoch @xmath9-sigma detection limit is roughly @xmath72 in good seeing conditions @xcite .    in  [ fig : info ] , our jackknife estimates of our measurement uncertainties are compared to approximate estimates of the total information content in each source s data set , made with an approximation to equation  ( [ eq : muerror ] ) . if our uncertainty estimates are correct ( as we demonstrate that they are , below ) , this shows that we come close to attaining the accuracy available .",
    "to demonstrate that our jackknife error estimates are reasonable , and that our code is optimizing the models correctly , we performed some tests on synthetic data .",
    "we selected a subset of the sdssss candidate objects for which we found reasonable fits to a moving point source model .",
    "for each candidate , we generated a stack of images by generating , for each image in the original stack , the image predicted by our point - source model , given the wcs , point - spread function , time , and noise amplitude of the image .",
    "this is a good test set because it has the same imaging properties as the original data and the same distribution of point - source parameters as the sources we want to be able to discover .",
    "since the synthetic images are generated using our image model , this test shows how our algorithm would perform if our modeling assumptions were exactly correct .    after running our optimization code on these synthetic images ,",
    "we compare our errors  the differences between the true and estimated moving - point - source parameters  to the jackknife estimates of our uncertainties . in  [ fig : fake ] we show that the errors are consistent with the uncertainty estimates .",
    "this shows that when our assumptions about the data are correct , we do measure the proper motions as accurately as our jackknife errors indicate .",
    "we have shown that straightforward image modeling permits the measurement of apparent motions , especially the proper motion and parallax of a source in multi - epoch data , even when the source is too faint to be reliably detected or centroided at any individual epoch .",
    "the results of this project are not surprising ; indeed what is surprising is how rarely the measurements of stellar motions are made by comprehensive data modeling .",
    "we demonstrated the technique on real and artificial data . in the process of performing these tests we showed that spectrosopically confirmed quasars and brown dwarfs can be perfectly distinguished with proper motions measured by this technique . working without proper motions , but",
    "with co - add catalog sources and a significant amount of near - infrared imaging follow - up , a group has followed up the @xmath58-only sources most likely to be high - redshift quasars @xcite .",
    "this project , even after infrared imaging , found  after expensive spectroscopic follow - up  that some of the high - redshift quasar candidates selected on the basis of visible and near - infrared imaging are in fact nearby brown dwarfs .",
    "we have shown that all of these spectroscopically confirmed brown dwarfs have significantly measured ( @xmath73  sigma ) non - zero proper motions by the technique shown here ( and are reported in  [ tab : movingsources ] ) .",
    "none of the spectroscopically confirmed high - redshift quasars do .",
    "use of this technique could have been used to substantially increase the efficiency of either quasar or brown - dwarf searches in this data set .    in performing this demonstration ,",
    "we have independently identified all 10 known brown dwarfs @xcite in our parent sample , and we have discovered 9 _ new _ candidate brown dwarfs , presented in  [ tab : movingsources ] . based on our analysis , these objects have a high probability of being brown dwarfs .",
    "it would be desirable to separate disk dwarfs from halo dwarfs  the fastest angular movers tend to be halo members ( for example , @xcite)but the time cadence of the sdssss data is such that parallaxes are not measured well .",
    "two of the dwarfs we rediscover2mass j010752.42 + 004156.3 and 2mass j020742.84 + 000056.4have previously measured parallaxes @xcite ; the measurements are consistent with our upper limits .",
    "our tests show that the uncertainty in the proper - motion measurement made by image modeling is consistent with the best possible uncertainties given the angular resolution and photometric sensitivity of the combination of all images in the multi - epoch data set .",
    "these tests effectively show that such measurements can be made for objects that are fainter than those available to traditional methods that require source detection at every epoch . in imaging with @xmath12",
    "equally sensitive epochs , we are able to measure objects that are fainter by @xmath74 magnitudes : @xmath75}}_i ) + \\log_{2.5}({{{[s / n]}}_{\\mathrm{total } } } ) \\\\   & = & \\log_{2.5}(\\sqrt{n } ) \\\\   & \\sim & 0.55\\,\\log n~{{\\mathrm{mag}}}\\quad .\\end{aligned}\\ ] ] this advantage amounts to @xmath76 for surveys with @xmath77 similar epochs , and @xmath78 to @xmath79 in data with @xmath63 to @xmath64 epochs ( such as the data used here ) . in the @xmath7 epochs available in sdss dr7",
    ", it reaches @xmath80 .",
    "several of the high - redshift quasars and brown dwarfs analyzed in this study were only detectable in the combination of all of the multi - epoch images .",
    "the depth advantage of image modeling is most dramatic in surveys with very large numbers of epochs , as is expected for lsst . in general",
    "the number of interesting sources is a strong function of depth ( factors of @xmath81 to @xmath82 per magnitude ) , so the `` reach '' of the image - modeling technique is a strong function of the number of epochs .",
    "one limitation of the work presented here is that we used the zero - proper - motion image `` stack '' for source detection and therefore will only have in the candidate list objects with small proper motions .",
    "faint stars and dwarfs with proper motions large enough that they move the width of the psf between epochs , or some significant fraction of that , are harder to find , because they do nt appear in the stack at much higher signal - to - noise than they appear in any individual - epoch image . in future work we hope to address the detection and measurement of these fast - moving but very faint sources .",
    "approximations have been executed in the search for solar system bodies ( for example , @xcite ) . certainly a reliable system for discovery in this regime would have a big impact on future surveys like panstarrs and lsst .",
    "we thank jon barron , mike blanton , bertrand goldman , linhua jiang , keir mierle , sam roweis , iain murray , ralf - dieter scholz , christopher kochanek , and rob fergus for help , comments , and software .",
    "we thank our anonymous reviewer for detailed and thoughtful comments which greatly improved this paper .",
    "this project was partially supported by the us national science foundation ( grant ast-0428465 ) and the us national aeronautics and space administration ( grants nag5 - 11669 and 07-adp07 - 0099 ) . during part of the period in which this research was performed ,",
    "dwh was a research fellow of the german alexander von humboldt foundation .",
    "this project made use of the sdss southern stripe co - add catalog , which was constructed by jim annis , huan lin , robert lupton , and others , who graciously made it available to us in advance of publication .",
    "funding for the sdss and sdss - ii has been provided by the alfred p. sloan foundation , the participating institutions , the national science foundation , the u.s .",
    "department of energy , the national aeronautics and space administration , the japanese monbukagakusho , the max planck society , and the higher education funding council for england .",
    "the sdss web site is http://www.sdss.org/.    the sdss is managed by the astrophysical research consortium for the participating institutions .",
    "the participating institutions are the american museum of natural history , astrophysical institute potsdam , university of basel , university of cambridge , case western reserve university , university of chicago , drexel university , fermilab , the institute for advanced study , the japan participation group , johns hopkins university , the joint institute for nuclear astrophysics , the kavli institute for particle astrophysics and cosmology , the korean scientist group , the chinese academy of sciences , los alamos national laboratory , the max - planck - institute for astronomy , the max - planck - institute for astrophysics , new mexico state university , ohio state university , university of pittsburgh , university of portsmouth , princeton university , the united states naval observatory , and the university of washington .",
    "this work is based in part on data obtained as part of the ukirt infrared deep sky survey .",
    "the united kingdom infrared telescope is operated by the joint astronomy centre on behalf of the science and technology facilities council of the u.k .",
    "this publication makes use of data products from the two micron all sky survey , which is a joint project of the university of massachusetts and the infrared processing and analysis center / california institute of technology , funded by the national aeronautics and space administration and the national science foundation .",
    "this research made use of the nasa astrophysics data system and the wfcam science archive .",
    "this research has benefitted from the m , l , and t dwarf compendium housed at ` dwarfarchives.org ` and maintained by chris gelino , davy kirkpatrick , and adam burgasser .",
    "this research made use of the ` idlutils ` and ` photoop ` software suites ( maintained by david schlegel , nikhil padmanabhan , doug finkbeiner , mike blanton , and others ) and the python programming language and python packages ` scipy ` , ` matplotlib ` and ` django ` .",
    "berriman ,  b. , kirkpatrick ,  d. , hanisch ,  r. , szalay ,  a. , & williams ,  r. 2003 , large telescopes and virtual observatory : visions for the future , 25th meeting of the iau , joint discussion 8 , 17 july 2003 , sydney , australia                                                                    .well - fit @xmath59>2 $ ]  mag sources in the sdss southern stripe with proper motions measured at high confidence ( @xmath83  sigma ) .",
    "ra , dec positions have equinox j2000.0 but are computed for mjd 53000 .",
    "the note `` 2 '' indicates that there is a nearby entry in the 2mass point - source catalog @xcite , while `` u '' indicates a nearby source in the ukidss catalog @xcite .",
    "`` bd '' indicates objects that are spectroscopically - confirmed brown dwarfs @xcite .",
    "the 9 sources in the lower part of the table ( not marked with `` bd '' ) are new brown - dwarf candidates.[tab : movingsources ] [ cols= \" > , > , > , > , > , > , > , < \" , ]            -band magnitude for @xmath59>2 $ ]  mag sources in the sdss southern stripe that are preferentially described as point sources ( by our @xmath44 hypothesis test ) .",
    "the uncertainty regions are shown as transparent ellipses .",
    "the spectroscopically confirmed high - redshift quasars @xcite and brown dwarfs @xcite are shown in color .",
    "every one of the brown dwarfs has a significantly measured proper motion ; none of the quasars do .",
    "other brown - dwarf candidates are clearly visible as significant movers ( see also  [ tab : movingsources ] ) .",
    "note that the single - epoch detection limit is approximately @xmath72 in good seeing conditions.[fig : bubbles ] ]    $ ] color plotted against sdssss @xmath58-band magnitude , for the sources in  [ fig : bubbles ] that are detected in the ukidss @xmath71 band .",
    "all of the significantly - moving objects have the very red @xmath70 $ ] colors of brown dwarfs ; the likely brown dwarfs could have been identified by their proper motions and sdssss coadd catalog colors alone .",
    "note that the @xmath58 magnitude is in the ab system , while the @xmath71 magnitude is vega - based.[fig : colormag ] ]"
  ],
  "abstract_text": [
    "<S> the near future of astrophysics involves many large solid - angle , multi - epoch , multi - band imaging surveys . </S>",
    "<S> these surveys will , at their faint limits , have data on large numbers of sources that are too faint to be detected at any individual epoch . here </S>",
    "<S> we show that it is possible to measure in multi - epoch data not only the fluxes and positions , but also the parallaxes and proper motions of sources that are too faint to be detected at any individual epoch . </S>",
    "<S> the method involves fitting a model of a moving point source simultaneously to all imaging , taking account of the noise and point - spread function in each image . by this method it is possible to measure the proper motion of a point source with an uncertainty close to the minimum possible uncertainty given the information in the data , which is limited by the point - spread function , the distribution of observation times ( epochs ) , and the total signal - to - noise in the combined data . </S>",
    "<S> we demonstrate our technique on multi - epoch sloan digital sky survey ( sdss ) imaging of the sdss southern stripe . </S>",
    "<S> we show that with our new technique we can use proper motions to distinguish very red brown dwarfs from very high - redshift quasars in these sdss data , for objects that are inaccessible to traditional techniques , and with better fidelity than by multi - band imaging alone . </S>",
    "<S> we re - discover all 10 known brown dwarfs in our sample and present 9 new candidate brown dwarfs , identified on the basis of significant proper motion . </S>"
  ]
}