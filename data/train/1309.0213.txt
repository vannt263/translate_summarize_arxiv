{
  "article_text": [
    "image quality assessment ( biqa ) aims to predict perceptual image quality scores without access to reference images .",
    "because reference images are usually unavailable in most practical applications , biqa is of great significance and has consequently received tremendous attention over the past decades . to date , a number of universal biqa methods that work well for various distortion types have been deployed @xcite-@xcite .",
    "these methods typically require subjects to score a large number of images to learn a robust model , but the acquisition of image quality scores in this way has several limitations .",
    "first , scores are not precise . in standard subjective studies @xcite-@xcite",
    ", the assessor assigns each image a number within a range , e.g. 0 to 100 , that reflects its perceived quality .",
    "there is usually uncertainty about which score most precisely represents the perceptual quality of a given image @xcite , however , and an arbitrary score from the selected range @xcite .",
    "consequently , this score may not capture subtle differences in the perceived quality of images @xcite .",
    "[ figure1 ] illustrates two images from the laboratory for image and video engineering ( live ) database @xcite .",
    "for each image , the difference mean opinion score ( dmos ) , @xmath2 , and the realigned dmos , @xmath3 , is listed .",
    "dmos is the difference between the mean opinion score ( mos ) and perfect quality @xcite .",
    "the realigned dmos is obtained by realigning the dmoss between different subjects and between different distortion types .",
    "a larger @xmath2 or @xmath3 value indicates poorer quality .",
    "it is notable that the left image is subjectively better than the right one , but the dmoss do not accurately reflect their relative quality .",
    "the success of @xmath3 implies the necessity for realignment .",
    "second , subjective judgments of quality may be biased by image content .",
    "images whose impairment scales are similar but whose content is different may be assigned different scores by observers as a result of personal image content preferences . fig .",
    "[ figure2 ] illustrates two undistorted images , both of which are of perfect quality .",
    "however , individuals may prefer the left image and evaluate its quality with a higher score because they find it aesthetically more pleasing than the right image .",
    "the content - dependent problem further decreases the reliability of subjective scores .",
    "third , the quality scales between different sessions are inconsistent . in subjective experiments ,",
    "the evaluation of all the test images is divided into several independent sessions with respect to the distortion type @xcite@xcite or image content @xcite@xcite to minimize the effects of observer fatigue @xcite .",
    "thus , images which have similar quality scores but are evaluated in different sessions may not be perceptually similar to each other . fig .",
    "[ figure3 ] shows two images included in the live database .",
    "[ figure3]a is an image distorted in a fast fading rayleigh ( wireless ) channel ( ff ) , with @xmath4 and @xmath5 .",
    "[ figure3]b is an image corrupted by the adaptive gaussian white noise ( wn ) , with @xmath6 and @xmath7 .",
    "although their realigned dmoss are almost the same , the impairment in fig .",
    "[ figure3]b is much more annoying than it is in fig .",
    "[ figure3]a .",
    "again , the raw dmos fails to reflect the relative quality .",
    "finally , it is challenging to obtain a large scale database or to extend existing databases , mainly for the following inconvenient reasons : 1 ) the test organizer has to collect sufficient images associated with each kind of distortion at diverse levels of degradation to yield a meaningful evaluation @xcite ; 2 ) one observer has to continuously evaluate many images in a single session to minimize the influence of contextual effects that the score to an image is highly biased by recently scored images @xcite@xcite ; 3 ) subjective experiments should be conducted in critical viewing conditions and in critical procedures , because judgments of perceptual quality scores are sensitive to the viewing environment @xcite@xcite ; 4 ) it is necessary to recruit many observers and train them before the experiment , to minimize quality scale mismatch errors @xcite@xcite@xcite ; and 5 ) the process of realigning raw human responses is complicated @xcite .",
    "these limitations constrain the reliability and extension of existing biqa methods which utilize subjective quality scores as the benchmark for learning a model .",
    "although there have been several biqa methods that do not require learning from subjectively evaluated images [ 23]-[25 ] , their performance is still inferior to state - of - the - art algorithms .    to combat the aforementioned limitations , this paper explores and exploits preference image pairs ( pips ) such as `` the quality of image @xmath0 is better than that of image @xmath1 '' for training a robust biqa model .",
    "the preference label , representing the relative quality of two images , is generally precise and consistent , and is not sensitive to image content , distortion type , viewing conditions , or subject identity @xcite@xcite , and such pips can be generated at very low cost @xcite .",
    "consider the image pairs derived from the images shown in figs .",
    "[ figure3 ] and [ figure4 ] .",
    "they are easy to discriminate in terms of perceived quality . moreover , different subjects may give consistent preference labels @xcite , even though the images in a certain pair may vary in the types of distortion afflicting them ( e.g. figs .",
    "[ figure4]a and [ figure4]b ) , or in image content ( e.g. figs .",
    "[ figure3]a and [ figure4]b ) , or both ( e.g figs .",
    "[ figure3]b and [ figure4]b ) .",
    "the proposed biqa method is one of learning to rank @xcite .",
    "we first formulate the problem of learning the mapping from the image features to the preference label as one of classification .",
    "in particular , we investigate using a multiple kernel learning algorithm based on group lasso ( mklgl ) @xcite to solve it . a simple but effective strategy is then presented to estimate perceptual image quality scores .",
    "thorough experiments conducted on the largest four standard databases show that the proposed biqa method is highly effective and achieves comparable performance to state - of - the - art biqa algorithms .",
    "moreover , the proposed method can be can be easily extended to new distortion categories by simply adding the corresponding pips into the training set .",
    "the rest of the paper is organized as follows . in section [ sec : related work ] , we briefly introduce standard iqa databases and learning to rank .",
    "section [ sec : generation of preference image pairs ] discusses how to generate pips with valid preference labels .",
    "the framework of the proposed biqa method is detailed in section [ sec : the proposed biqa method ] .",
    "our experiments are described and analyzed in section [ sec : iqa experiments ] , and an extensive subjective study of pips is presented in section [ subjective study pips ] . section [ sec : conclusion ] concludes this paper .",
    "subjective iqa studies are of fundamental importance for the development of iqa . over the years",
    ", many researchers have contributed significant research in this area through the construction of various iqa databases . in this section ,",
    "we introduce the composition of the four largest datasets , i.e. the live dataset @xcite , tampere image database 2013 ( tid2013 ) @xcite , categorical subjective image quality ( csiq ) database @xcite , and live multiple distorted ( livemd ) database @xcite .",
    "the live database includes 808 images , which are generated from 29 original images by corrupting them with five types of distortion , i.e. jpeg2000 compression ( jp2k ) , jpeg compression ( jpeg ) , wn , gaussian blur ( gblur ) , and ff .",
    "the dmos and realigned dmos of each image are available . because the realigned dmos is more precise than the dmos , we adopt the realigned dmos in our work .",
    "the realigned dmos ranges from -3 to 112 . for convenience",
    ", we refer to the realigned dmos as dmos in the remainder of this paper unless otherwise indicated .",
    "in addition , we refer to all the images associated with the same reference image as a `` group '' .",
    "the tid2013 includes 3,000 images in sum .",
    "these images are generated by corrupting 25 original images with 24 types of distortion at 5 different levels .",
    "the distortion types include : wn ( # 1 ) , additive white gaussian noise which is more intensive in color components than in the luminance component ( # 2 ) , additive gaussian spatially correlated noise ( # 3 ) , masked noise ( # 4 ) , high frequency noise ( # 5 ) , impulse noise ( # 6 ) , quantization noise ( # 7 ) , gblur ( # 8) , image denoising ( residual noise , # 9 ) , jpeg ( # 10 ) , jp2k ( # 11 ) , jpeg transmission errors ( # 12 ) , jpeg2000 transmission errors ( # 13 ) , non - eccentricity pattern noise ( # 14 ) , local block - wise distortion of different intensity ( # 15 ) , mean shift ( # 16 ) , contrast change ( # 17 ) , change of color saturation ( # 18 ) , multiplicative gaussian noise ( # 19 ) , comfort noise ( # 20 ) , lossy compression of noisy images ( # 21 ) , image color quantization with dither ( # 22 ) , chromatic aberrations ( # 23 ) , and sparse sampling and reconstruction ( # 24 ) .",
    "the mos of each image is available and ranges from 0.2 to 7.3 .",
    "the csiq database consists of 866 images which are derived from 30 original images .",
    "six types of distortion are considered in csiq , i.e. wn , jpeg , jp2k , additive gaussian pink noise ( pn ) , gblur , and global contrast decrements ( gcd ) .",
    "the dmos of each image is available and ranges from 0 to 1 .",
    "the livemd database includes images distorted by multiple types of distortion .",
    "there are two subsets , one of which is associated with the images corrupted by gblur followed by jpeg ( gblurjpeg ) , and one which is associated with images corrupted by gblur followed by wn ( gblurwn ) .",
    "each subset includes 225 images .",
    "the dmos of each image is released and ranges from 0 to 85 .      learning to rank",
    "@xcite involves learning a function that can predict the ranking list of a given set of stimuli .",
    "it is the central issue in web page ranking , document retrieval , image searching and other applications . of the existing methods ,",
    "the pairwise approach has been well deployed and successfully applied to information retrieval @xcite .    without loss of generality , we take document retrieval as an example to introduce the pairwise approach . in pairwise approaches , document pairs",
    "are adopted as instances for learning a ranking function .",
    "what is needed is to construct a training set by first collecting document pairs from the ranking lists , and then calculating the corresponding difference feature vector for each pair of documents and assigning a preference label that represents their relative relevance @xcite . in this way",
    ", the problem of learning - to - rank is reduced to a classification problem , also called _ preference learning _",
    "problem @xcite , and existing classification models , such as support vector machines ( svms ) and neural network , can be directly applied to solve it @xcite-@xcite .",
    "intuitively , the problem addressed in the pairwise approach is similar to the problem we aim to work out in this paper , and is our inspiration for thinking we may succeed in learning a robust biqa model from pips .",
    "the proposed biqa model is detailed in section [ subjective study pips ] .",
    "generating pips in an easy and efficient way is of fundamental significance in this research . in this section ,",
    "we investigate how to produce image pairs with valid preference labels through paired comparisons and from existing iqa databases , based on the quality scores .      in paired comparisons ,",
    "observers are asked to choose which image in a pair has better perceived quality @xcite .",
    "consider a pair of images .",
    "if the difference in perceived quality between them is large enough , observers can easily discriminate between them , regardless of any type of corruption through distortion , image content , or even viewing conditions . moreover , different observers may offer a unanimous judgment @xcite . in this case , we can obtain valid preference labels by arranging only one observer to assign each image pair .",
    "this is consistent with the samples illustrated in figs .",
    "[ figure3 ] and [ figure4 ] .    however , when the distortion strengths of the two images are similar , it becomes much more difficult for observers to judge their relative quality , especially when the image content of the two images is diverse ( e.g. figs .",
    "[ figure5]b and [ figure5]c ) , or because of the distortion type ( e.g. figs .",
    "[ figure5]c and [ figure5]d ) , or both ( e.g. figs .",
    "[ figure5]b and [ figure5]d ) , or because there is subtle difference between them ( e.g. figs .",
    "[ figure5]a and [ figure5]b ) .",
    "numbers are incorrect . in this case",
    ", it is unreasonable neither to force observers to choose a `` better '' image @xcite@xcite , nor to label the relative quality as `` the same '' @xcite .",
    "otherwise , discrepancies are caused and responses from many observers are needed @xcite so as to produce valid preference labels .",
    "the huge number of comparisons coupled with the need to recruit many observers @xcite@xcite lead to the same limitations as introduced previously .",
    "thus we propose to allow observers to only judge the image pairs that are easy to distinguish in terms of perceived quality in paired comparisons .",
    "since we aim to learn a biqa model from image pairs , we do not require a complete comparison , only to label a sample of all possible pairs .",
    "we conclude the procedures of generating pips through paired comparisons as follows :    first , collect @xmath8 images , @xmath9 , are diverse in the types of corrupting distortion , image content , and distortion strength .",
    "second , randomly construct @xmath10 , pairs from the collected images .",
    "the image pair set @xmath11 is given by    @xmath12    note that if @xmath13 , then @xmath14 , to reduce the number of comparisons .",
    "finally , recruit @xmath15 , subjects to assign preference labels for the image pairs .",
    "given an pair @xmath16 , if subject @xmath17 , considers @xmath18 to be better than @xmath19 in quality , then the corresponding preference label @xmath20 , @xmath21 , is set as @xmath22 ; if @xmath19 is subjectively better than @xmath18 , @xmath23 ; and if subject @xmath2 does not label the pair @xmath16 or is uncertain about the relative quality of the corresponding images , let @xmath24 .",
    "for simplicity , the final preference label for the pair @xmath16 is calculated as    @xmath25    if @xmath26 , it means @xmath18 and @xmath19 are difficult to discriminate in terms of perceived quality , and @xmath16 will not be adopted for training .",
    "the procedure of the paired comparison experiment is flexible @xcite .",
    "observers do not have to evaluate many pairs in a single session , because there is practically no contextual effect or scale mismatch problem , and pips evaluated in different sessions can be directly aggregated into a single dataset for future applications without complex processing . in this paper",
    ", we present an extensive subjective paired - comparison study which we detail in section [ subjective study pips ] .",
    "since many efforts have contributed to the construction of various iqa databases @xcite-@xcite , it is meaningful to find a method to generate reliable pips from existing databases .",
    "previous discussions imply that a small difference between two quality scores may not accurately reflect the corresponding relative quality ; thus , we recommend selecting the image pairs whose corresponding difference quality scores reach a threshold .",
    "the generation of pips from iqa databases is therefore formulated as below .",
    "assume that an iqa database comprises : 1 ) _",
    "n _ labeled images : @xmath27 ; 2 ) the subjective quality scores of the images @xmath28 , @xmath29 is the quality score of @xmath18",
    ". then we can construct @xmath30 image pairs from these labeled images .",
    "let @xmath11 be the pair set , we have    @xmath31    where , @xmath32 is the threshold of the difference quality score , and @xmath33 ; and@xmath34 denotes the absolute value of @xmath35 .",
    "because a greater mos value indicates better quality but a greater dmos value is associated with poorer quality , a preference label @xmath36 for each image pair @xmath37 _ _ is assigned as :    @xmath38[c]{l 's } { \\rm sign}\\left(q_i - q_j\\right ) , & if the quality score is mos \\\\ { \\rm -}{\\rm sign}\\left(q_i - q_j\\right ) , & if the quality score is dmos \\end{ieeeeqnarraybox}\\right.\\ ] ]    thus , @xmath39 indicates that @xmath18 is better than @xmath19 in terms of quality , but @xmath40 indicates that @xmath19 is better .",
    "let @xmath41 be the set of preference labels , such that    @xmath42    it is notable that the pips separately extracted from different iqa databases can be combined with no realignment .",
    "moreover , we can aggregate the pips produced through paired comparisons and those collected from iqa databases into one single dataset for training a biqa model . based on all the previous discussions , we conclude that the generation of pips is easy and convenient , avoiding the limitations in the acquisition of human quality scores .",
    "in this section , we present a biqa framework that learns to predict perceptual quality scores from pips . inspired by the pairwise learning - to - rank approaches , we first formulate the problem of learning the mapping from difference feature vectors to preference labels as one of classification .",
    "we utilize natural scene statistics ( nss ) @xcite - based features to represent an image and investigate using the mklgl approach @xcite to solve the classification problem .",
    "a simple but effective strategy is subsequently presented to estimate perceptual image quality scores .",
    "6 shows the diagram of the proposed biqa method , and details are introduced in the following subsection .",
    "[ figure6 ]      nss - based image features have been widely explored for iqa and have shown promising performance @xcite-@xcite .",
    "however , the features utilized in these methods are generally representative of some distortion categories but have relatively weaker correlation with others . in this paper , therefore , we adopt a fusion of the features that have been utilized in several state - of - the - art biqa methods , i.e. bliinds - ii @xcite , brisque - l @xcite , and srnss @xcite , to represent an image . for the integrity of this paper",
    ", we briefly introduce these features in this subsection . for detail",
    ", we refer to @xcite , @xcite , and @xcite .",
    "both the bliinds - ii features and brisque - l features are extracted over several scales , where the feature extraction is repeated after downsampling it by a factor of 2 .",
    "bliinds - ii extracts features over 3 scales and computes 8 features in the discrete cosine transform ( dct ) domain at each scale .",
    "the brisque - l features are exacted over 2 scales , and 18 spatial - domain features are extracted at each scale .",
    "the bliinds - ii and brisque - l features extracted at each scale are concentrated into a vector and denoted as @xmath43 , and @xmath44 , @xmath45 , respectively .",
    "in addition , let @xmath46and @xmath47 be all the bliinds - ii and brisque - l features , respectively .    in srnss",
    "_ @xcite employed the mean , variance , and entropy of wavelet coefficients in each sub - band to encode the generalized spectral behavior , the energy fluctuations , and the generalized information , respectively . in the implementation",
    ", an image is decomposed into 4 scales .",
    "the coefficients at lh ( low , high ) and hl ( high , low ) sub - bands at a particular scale are combined to calculate a group of features due to their similarity in statistics .",
    "let @xmath48 , @xmath49 , and @xmath50 respectively denote all the means , variances , and entropies extracted from an image , and @xmath51 be all the srnss features extracted from an image .",
    "finally we denote all the features extracted from an image as @xmath52 , such that    @xmath53 = \\left[{{\\mathbf f}}^{bld}_1,{{\\mathbf f}}^{bld}_2,{{\\mathbf f}}^{bld}_3,{\\mathbf \\ } { { \\mathbf f}}^{brl}_1,{{\\mathbf f}}^{brl}_2,{\\mathbf m},{\\mathbf \\ } { \\mathbf v},{\\mathbf \\ } { \\mathbf e}\\right].\\ ] ]    thus @xmath52 is of the dimension 84 ( 8@xmath543 of @xmath55 + 18@xmath542 of @xmath47 + 8@xmath543 of @xmath51 ) .",
    "we calculated _",
    "pearson s linear correlation coefficient _ ( plcc ) between each of these features and the quality score , and plotted the maximum plcc values of @xmath46 , @xmath47 , and @xmath51 , respectively , across all the images contained in each type of distortion and the whole image set ( all ) in the live , csiq , tid2013 , and livemd databases in fig .",
    "7 . as is clear , @xmath55 , @xmath47 , and @xmath51 do not correlate highly with all the distortion categories .",
    "it is therefore reasonable to combine these features as the representation of the image @xcite . in section [ sec : iqa experiments ] , we compare the performance of the biqa methods that utilize @xmath55 , @xmath47 , @xmath51 , and @xmath52 , respectively , to verify the effectiveness of this feature fusion strategy .",
    "[ feature ]      in line with the discussions in section [ sec : generation of preference image pairs ] , we first collect a number of pips with valid preference labels . we then calculate the features of each image and the difference feature vector of each pip . thus the training data comprises :    1 .   _",
    "n _ images : @xmath56 ; 2 .   for each image",
    "an integrated feature vector @xmath57 , @xmath58 is the dimension of the feature vector ; 3 .",
    "@xmath30 pips generated from the _",
    "n _ images .",
    "the pip set is denoted as @xmath11 : @xmath59 ; and 4 .   for each pip @xmath37 ,",
    "_ _ a difference feature vector @xmath60 _ _ and a preference label @xmath36 : + @xmath61 + and + @xmath62    considering that if an image pair @xmath63 corresponds to @xmath60 and @xmath64 , there is a pair @xmath65 associated with @xmath66 and @xmath67 , thus the classifier should take this symmetry into account",
    ". let @xmath68 * * be the set of difference vectors and @xmath41 * * the set of preference labels , such that    @xmath69    and    @xmath70    where @xmath71 , @xmath72 .",
    "the mapping from difference feature vectors to preference labels can then be realized by a binary classifier trained on @xmath73 .",
    "previous discussion in part a implies that the difference feature vector includes 8 portions in accordance with @xmath74 , @xmath75 , @xmath76 , @xmath77 , @xmath78 , @xmath48 , @xmath49 , and @xmath50 , each of which represents the image at a particular scale or captures one particular property .",
    "we therefore introduce multiple kernel learning ( mkl ) to measure the similarity of different portions of features using different kernels @xcite . of the various mkl algorithms ,",
    "the mklgl approach @xcite has shown its efficiency and effectiveness across a wide range of applications @xcite .",
    "thus we adopt mklgl to solve the preference learning problem in the proposed biqa framework .    the prediction function that maps the difference feature vector to the preference label",
    "can then be represented by    @xmath79}.\\ ] ]    where the optimal parameters @xmath80 , @xmath81 , and @xmath82 are learned from the training data @xmath73 ; @xmath83 , is a base kernel and defines a feature mapping from the original input space to a reproducing kernel hilbert space ( rkhs ) @xmath84 .",
    "base kernels may be diverse in the type or parameters of the kernel function , or in the portion of features on which the kernel function operates @xcite .",
    "in our research , we construct gaussian kernels with 5 different bandwidths ( @xmath85 ) on each portion of the difference feature vector .",
    "in addition , we exploit gaussian kernels with 5 different bandwidths ( @xmath85 ) using the entire difference feature vector to encode the potential correlations between different portions of features . in sum",
    ", we have 45 kernels ( 8 portions of features @xmath545 bandwidths gaussian kernels + 5 bandwidths gaussian kernels ) .",
    "we construct a kernel in this way according to @xcite@xcite to avoid using a large memory .",
    "the learned mklgl model can estimate the preference label of a given pair of images based on the corresponding difference feature vector @xmath86 .",
    "in addition , if @xmath87 , we consider the two images in the test pair to be of the same perceived quality , and assign * * the predicted preference label as 0 .",
    "consider a full round of comparisons of all the training images .",
    "we term the sum of the ideal preference labels @xmath88 associated with @xmath89 as the  _ gain _  of @xmath18 and denote it as @xmath90 , @xmath91 , such that    @xmath92    the gain of a training image is proportional to its perceived quality , because @xmath93 essentially reflects the quality of @xmath18 relative to @xmath19 , and @xmath94 indicates @xmath18 is better than @xmath19 in terms of quality . for simplicity , we assume a linear mapping between the gain value and the ideal perceived quality scores of the training images : @xmath95 , where @xmath29 is the quality score of @xmath18 . because neither all the ideal preference labels nor the ideal quality scores are available in the scenario of the proposed biqa framework",
    ", we investigate to estimate the parameters @xmath96 and @xmath97 based on the following two assumptions :    1 .",
    "the training images cover the full range of possible quality , from the poorest ( extremely annoying ) to the best ( undistorted ) , with small steps ; and 2 .",
    "the gain value @xmath98 corresponds to the greatest quality score , and @xmath99 corresponds to the lowest score .",
    "these assumptions are reasonable because it is easy to collect / generate sufficient images that diverse greatly in perceived quality , in which each pair includes an undistorted image and a heavily distorted one . without loss of generalization",
    ", we choose the continuous quality scale of [ 0 100 ] .",
    "@xmath96 and @xmath97 can then be estimated by solving the following linear equation :    @xmath100 \\left [ \\begin{array}{c } a \\\\ b \\end{array}\\right ] = \\left [ \\begin{array}{c } 100 \\\\ 0 \\end{array}\\right].\\ ] ]    we have @xmath101 and @xmath102 .",
    "given a test image @xmath103 , we then pair it with each training image , and calculate the corresponding difference feature vector :    @xmath104    where @xmath105 is the integrated feature vector of the test image , @xmath106 is the feature vector of the @xmath107 th training image @xmath18 , @xmath108 .",
    "the preference labels associated with the test pairs are estimated by the trained mklgl .",
    "let @xmath109 denote the predicted preference labels .",
    "finally , the gain of the test image is calculated by @xmath110 , and the quality score is then predicted by :    @xmath111    it is notable that @xmath112 ranges from @xmath113 to @xmath8 , thus @xmath114 may become less than 0 , which is a situation that occurs when the test image is perceptually worse than the poorest training image .",
    "conversely , when the test image is better than all the training images , the predicted quality score becomes greater than 100 , which is taken to indicate quality improvement .",
    "this is an interesting feature , albeit possibly controversial , since it is not clear whether this is due to the absence of the potentially most / least annoying image in the training set or a true improvement of the test image in terms of quality .",
    "even though this quality prediction approach seems rather ad - hoc at first sight , it correlates highly with human perceptions of quality , as verified by the thorough experiments presented in the following two sections .",
    "we conduct a series of experiments on the four largest datasets , i.e. the live dataset , tid2013 , csiq , and livemd databases , with four objectives .    1 .",
    "the first objective is to show how the performance of the proposed biqa method varies with the parameters included in it .",
    "this is illustrated through the experiment on the live database , as presented in part a. 2 .",
    "the second objective is to evaluate the effectiveness of our biqa model .",
    "this is verified by the experiments where we train and test the biqa models on two distinct subsets of each database .",
    "details are described in part b. 3 .",
    "the third objective is to show that the proposed biqa approach is database independent . in this case , we train the model on the whole live database and then test it on the other databases , as introduced in part c. 4 .   the fourth objective is to show that it is easy to extend the proposed biqa framework to emerging distortion categories .",
    "this is demonstrated by the experiment in which we aggregate the pips separately extracted from the live , csiq , and tid2013 databases into a single training set for learning a robust model .",
    "details are presented in part d.    we compare the performance of the proposed biqa method with state - of - the - art biqa algorithms which have been reported as having the best performance @xcite@xcite , i.e. , bliinds - ii @xcite , brisque @xcite , brisque - l @xcite , and cornia @xcite . in particular , we adopt the version of bliinds - ii that utilizes support vector regression ( svr ) with a radial basis function ( rbf ) kernel to model the relationship between @xmath55 and quality scores .",
    "all of these algorithms are implemented based on the codes provided by the authors and the corresponding literature .    to verify the efficacy of adopting a combination of nss features , we implement two biqa algorithms that use @xmath51 and @xmath52 to represent an image , respectively , and utilize svr with a rbf kernel to learn a quality prediction function . for convenience",
    ", we refer to them as @xmath115 and @xmath116 , respectively .",
    "it is worth declaring that the performance of @xmath117 is somewhat better than srnss @xcite , thus we do not report the results of srnss in this paper owing to space constraints .",
    "in addition , to verify the dependency between @xmath52 and the mklgl approach , we test the performance of the proposed framework using a support vector machine ( svm ) with a rbf kernel instead of mklgl .    in our experiments , the library for support vector machines ( libsvm ) package @xcite",
    "is used to implement the svr and svm algorithms .",
    "the optimal parameters of svr and svm algorithms are learned by 5-fold cross validation on the training set .",
    "mklgl is implemented by the mkl toolbox @xcite with default settings .",
    "to evaluate the performances of the proposed method , three indexes are adopted as the criteria between the predicted quality scores by the biqa algorithm and dmos / mos : _",
    "kendall s rank correlation coefficient _ ( krcc ) , _ pearson s linear correlation coefficient _ ( plcc ) , and _",
    "spearman s rank correlation coefficient _ ( srcc ) .",
    "greater krcc , plcc and srcc values indicate better consistency with human opinions of quality . we perform a nonlinear mapping using a logistic function as described in @xcite before computing these indexes .    in all the experiments",
    ", we conducted the train - test procedures 100 times to verify the robustness of the proposed method . in parts a , b , and d , the database in each train - test procedure was randomly split into distinct training and test subsets and @xmath30 pips were randomly generated from the training images for training the proposed biqa model . in part c , we randomly produced @xmath30 pips from the entire live database and used all the images contained in the tid2013 , csiq , and livemd databases as the test set in each train - test procedure .",
    "all the other biqa methods adopt the training images as the instances in learning , thus we only needed to run the train - test procedure once for them in part c. the median performance indexes across the 100 trials were reported for comparison .      in this subsection , we focus on the impact of choosing different algorithm parameters : 1 ) the threshold @xmath32 for generating pips from existing iqa databases , 2 ) the number of training images , @xmath8 , and 3 ) the number of pips , @xmath30 .",
    "we randomly choose @xmath118 , groups of images contained in the live database for training , and use the rest for testing .",
    "thus @xmath119 in the experiments , we considered the parameters of : @xmath120 @xmath121 , and @xmath122 .",
    "it is worth noting that the number of pips adopted for training is @xmath123 , where @xmath124 is the maximum number of pairs we can generate in accordance with certain @xmath32 and @xmath125 .",
    "we report the proximate @xmath124 in the live databases in table i. it is clear that in most cases , we only utilized a very small portion of all the possible pairs for training the proposed biqa model .",
    ".maximum number of pairs that can be generated ( @xmath126 ) .",
    "[ cols=\"^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     it is obvious that the proposed biqa method obtains almost the same performance by adopting the subjective preference labels or the labels derived from dmos , demonstrating the validity of the preference labels obtained through paired comparisons .",
    "it is also notable that the performance here is similar to that reported in section v.b .",
    "this corroborates the expectation that by choosing a proper threshold , we can generate valid pips from existing iqa databases for learning a robust biqa model .",
    "in addition , @xmath127 and @xmath128 are slightly greater than @xmath129 and @xmath130 .",
    "the reason is that more comparisons are performed on each test image in the quality prediction procedure , indicating the efficacy of the proposed quality prediction approach .",
    "in this paper , we presented a biqa framework that learns to predict perceptual image quality scores from preference image pairs .",
    "thorough experiments on the four largest standard databases demonstrate that our method correlates highly with human perceptions of quality and that the framework can be easily extended to emerging distortions .",
    "in addition , an extensive subjective study corroborates the efficiency and validity of generating pips through paired comparisons or from existing iqa databases . in our continued search for convenient but effective pip - generation methods and biqa metrics ,",
    "we have deployed the simplest operations in both the subjective study and the proposed biqa approach in this paper .",
    "there is still room for the optimization of the subjective study and the improvement of iqa performance .",
    "in addition , the low cost of the generation of pips , coupled with the efficacy of the proposed biqa approach , make the deployment of this framework to solve other quality assessment ( qa ) problems , e.g. other types of images , videos , etc .",
    ", a promising option . further research is needed to explore quality - relevant features and generate corresponding stimulus pairs with valid preference labels .",
    "m.  a. saad , a.  c. bovik , and c.  charrier , `` blind image quality assessment : a natural scene statistics approach in the dct domain , '' _ ieee transactions on image processing _",
    "21 , no .  8 ,",
    "pp . 33393352 , 2012 .",
    "a.  mittal , a.  k. moorthy , and a.  c. bovik , `` making image quality assessment robust , '' in _ ieee conference record of the forty sixth asilomar conference on signals , systems and computers ( asilomar ) _ , 2012 , pp .",
    "17181722 .      p.  ye ,",
    "j.  kumar , l.  kang , and d.  doermann , `` unsupervised feature learning framework for no - reference image quality assessment , '' in _ ieee conference on computer vision and pattern recognition ( cvpr ) _ , 2012 , pp .",
    "10981105 .",
    "h.  r. sheikh , m.  f. sabir , and a.  c. bovik , `` a statistical evaluation of recent full reference image quality assessment algorithms , '' _ ieee transactions on image processing _",
    "15 , no .  11 , pp .",
    "34403451 , 2006 .",
    "h.  r. sheikh , z.  wang , l.  cormack , and a.  c. bovik .",
    "( 2005 ) live image quality assessment database release 2 .",
    "[ online ] .",
    "available : http://live.ece.utexas.edu/research/quality/ subjective.htm[http://live.ece.utexas.edu/research/quality/ subjective.htm ]    n.  ponomarenko , o.  ieremeiev , v.  lukin , k.  egiazarian , l.  jin , j.  astola , b.  vozel , k.  chehdi , m.  carli , and f.  battisti , `` color image database tid2013 : peculiarities and preliminary results . '' in _",
    "4th european workshop on visual information processing ( euvip2013 ) _ , 2013 .",
    "e.  c. larson and d.  m. chandler , `` most apparent distortion : full - reference image quality assessment and the role of strategy , '' _ journal of electronic imaging _ , vol .",
    "19 , no .  1 ,",
    "011006011006 , 2010 .",
    "d.  jayaraman , a.  mittal , a.  k. moorthy , and a.  c. bovik , `` objective quality assessment of multiply distorted images , '' in _ ieee conference record of the forty sixth asilomar conference on signals , systems and computers ( asilomar ) _ , pp.16931697 , 2012 .",
    "n.  ponomarenko , v.  lukin , a.  zelensky , k.  egiazarian , m.  carli , and f.  battisti , `` tid2008-a database for evaluation of full - reference visual quality assessment metrics , '' _ advances of modern radioelectronics _ , vol .",
    "10 , no .  4 , pp . 3045 , 2009 .        d.  m. rouse , r.  ppion , p.  le  callet , and s.  s. hemami , `` tradeoffs in subjective testing methods for image and video quality assessment , '' in _",
    "is&t / spie electronic imaging_.1em plus 0.5em minus 0.4em international society for optics and photonics , 2010 , pp .",
    "75270f75270f .",
    "a.  parducci and d.  h. wedell , `` the category effect with rating scales : number of categories , number of stimuli , and method of presentation . ''",
    "_ journal of experimental psychology : human perception and performance _ , vol .",
    "12 , no .  4 , p. 496",
    ", 1986 .",
    "a.  mittal , g.  muralidhar , j.  ghosh , and a.  bovik , `` blind image quality assessment without human training using latent quality factors , '' _ ieee signal processing letters _ ,",
    "19 , no .  2 , pp . 7578 , 2012 .",
    "r.  halonen , s.  westman , and p.  oittinen , `` naturalness and interestingness of test images for visual quality evaluation , '' in _",
    "is&t / spie electronic imaging_. international society for optics and photonics , 2011 , pp .",
    "78670z78670z .",
    "z.  xu , r.  jin , h.  yang , i.  king , and m.  r. lyu , `` simple and efficient multiple kernel learning by group lasso , '' in _ proceedings of the 27th international conference on machine learning ( icml-10 ) _ , 2010 , pp . 11751182 .",
    "z.  cao , t.  qin , t .- y .",
    "liu , m .- f .",
    "tsai , and h.  li , `` learning to rank : from pairwise approach to listwise approach , '' in _ proceedings of the 24th international conference on machine learning _ , 2007 , pp .",
    "129136 .",
    "z.  zheng , h.  zha , t.  zhang , o.  chapelle , k.  chen , and g.  sun , `` a general boosting method and its application to learning ranking functions for web search , '' in _ advances in neural information processing systems _",
    ", 2007 , pp .",
    "16971704 .",
    "lee and c .- j .",
    "lin ,  large - scale linear ranksvm ,  tech .",
    "software available at : http://www.csie.ntu.edu.tw/~{}cjlin/papers/ranksvm/ ranksvml2exp-1.1.tar.gz.[http://www.csie.ntu.edu.tw/~\\{}cjlin/papers/ranksvm/ ranksvml2exp-1.1.tar.gz . ]",
    "chang and c .- j .",
    "lin , `` libsvm : a library for support vector machines , '' _ acm trans .",
    "intelligent systems and technology _ , vol .",
    "2 , pp . 27:1 - 27:27 , 2011 . software available at : http://www.csie.ntu.edu.tw/?cjlin/libsvm .",
    "final report from the video quality experts group on the validation of objective models of video quality assessment .",
    "[ online ] .",
    "available : http://www.vqeg.org/ , 2000 , video quality experts group ( vqeg ) ."
  ],
  "abstract_text": [
    "<S> blind image quality assessment ( biqa ) aims to predict perceptual image quality scores without access to reference images . </S>",
    "<S> state - of - the - art biqa methods typically require subjects to score a large number of images to train a robust model . </S>",
    "<S> however , the acquisition of image quality scores has several limitations : 1 ) scores are not precise , because subjects are usually uncertain about which score most precisely represents the perceptual quality of a given image ; 2 ) subjective judgments of quality may be biased by image content ; 3 ) the quality scales between different distortion categories are inconsistent , because images corrupted by different types of distortion are evaluated independently in subjective experiments ; and 4 ) it is challenging to obtain a large scale database , or to extend existing databases , because of the inconvenience of collecting sufficient images associated with different kinds of distortion that have diverse levels of degradation , training the subjects , conducting subjective experiments , and realigning human quality evaluations .    to combat these limitations </S>",
    "<S> , this paper explores and exploits preference image pairs ( pips ) such as `` the quality of image @xmath0 is better than that of image @xmath1 '' for training a robust biqa model . </S>",
    "<S> the preference label , representing the relative quality of two images , is generally precise and consistent , and is not sensitive to image content , distortion type , or subject identity ; such pips can be generated at very low cost . </S>",
    "<S> the proposed biqa method is one of learning to rank . </S>",
    "<S> we first formulate the problem of learning the mapping from the image features to the preference label as one of classification . </S>",
    "<S> in particular , we investigate the utilization of a multiple kernel learning algorithm based on group lasso ( mklgl ) to provide a solution . a simple but effective strategy to estimate perceptual image quality scores </S>",
    "<S> is then presented . </S>",
    "<S> experiments show that the proposed biqa method is highly effective and achieves comparable performance to state - of - the - art biqa algorithms . </S>",
    "<S> moreover , the proposed method can be easily extended to new distortion categories . </S>",
    "<S> +   +   +    gao : learning to rank for blind image quality assessment    image quality assessment , learning to rank , multiple kernel learning , learning preferences , universal blind image quality assessment . </S>"
  ]
}