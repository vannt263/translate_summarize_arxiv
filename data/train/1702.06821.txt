{
  "article_text": [
    "waveform / code design , as one of the major problems in radar signal processing @xcite , active sensing @xcite , and wireless communications @xcite , has attracted significant interests over the past several decades @xcite . in radar signal processing and active sensing applications",
    ", waveform design plays an essential role because `` excellent '' waveforms can ensure higher localization accuracy @xcite , enhanced resolution capability @xcite , and improved delay - doppler ambiguity of the potential target @xcite .",
    "moreover , designing waveforms with robustness or adaptiveness is also required for the scenarios with harsh environments that include heterogeneous clutter and/or active jammers @xcite .",
    "in addition , with the advance of multiple - input multiple - output ( mimo ) radar @xcite , the problem of joint multiple waveform design is gaining even more importance and tends to grow to large scale .    in order to obtain waveforms with desired characteristics ,",
    "existing approaches usually resort to manipulations with correlation properties , such as the auto- and cross - correlations between different time lags of waveforms , which serve as the determinant factors for evaluating the quality of designed waveforms @xcite .",
    "perfect auto- and cross - correlation properties indicate that the emitted waveforms are mutually uncorrelated to any time - delayed replica of them , meaning that the target located at the range bin of interest can be easily extracted after matched filtering , and the sidelobes from other range bins are unable to attenuate it .",
    "for example , in the applications such as the spot and barrage noise jamming suppression @xcite and synthetic aperture radar imaging @xcite , waveforms with deep notches towards the time lags ( or equivalently , frequency bands ) , where the jamming or clutter signals are located , are highly desired . on the other hand ,",
    "it is preferred from the hardware perspective that the waveforms maintain the constant - modulus property , which can reduce the cost of developing advanced amplifiers .",
    "there is a number of existing waveform design methods based on consideration of the correlation properties @xcite . the integrated sidelobe level ( isl ) , which serves as an evaluation metric for correlation levels of waveforms , or equivalently",
    ", the accumulated sidelobes at all time lags , is typically used .",
    "if the receiver is fixed to be the matched filter , the waveform design methods are focused on the waveform quality itself .",
    "corresponding waveform designs use the fact that the matched filter can be implemented in terms of the correlation between the waveform and its delayed replica . for example",
    ", the method of @xcite has proposed to design unimodular waveform in frequency domain using a cyclic procedure based on iterative calculations .",
    "a surrogate objective which is minimized by a cyclic algorithm has been introduced , and the methods associated with the isl and weighted isl ( wisl ) minimization therein have been named as can and wecan , respectively .",
    "these methods have been later extended to multiple waveform design in @xcite .    if the receiver is not fixed and therefore has to be jointly optimized with the transmitted waveforms , the focus typically shifts to the so - called mismatched filter ( also called instrumental variable filter @xcite ) design at the receiver .",
    "such designs add flexibility as they enable to consider constraints which are difficult to address otherwise . the receive filter is generally mismatched because it trades off the signal - to - noise ratio in order to improve the signal - to - interference - plus - noise ratio .",
    "the corresponding design techniques are typically based on alternating optimization where minimum variance distortionless response ( mvdr ) filter design is involved .",
    "given the waveforms , finding the optimal mvdr receive filter is typically a computationally simpler problem than the waveform design itself .",
    "therefore , our focus here is the development of computationally efficient algorithms for addressing the core problem of waveform design when the optimal receive filter is the matched filter .",
    "the computational complexity of algorithms is of crucial importance for the isl and wisl minimization - based unimodular waveform design problems .",
    "indeed , the corresponding optimization problems can quickly grow to large scale with increasing the code length and number of waveforms . however , such problems are non - convex , while classical large - scale optimization approaches are developed for convex problems with relatively simple objective functions and constraints @xcite .",
    "the isl and wisl objective functions as well as the unimodular constraint to the desired waveforms are in fact complex to deal with and the required accuracy of waveform design is high .",
    "the aforementioned can and wecan @xcite use a cyclic procedure based on iterative calculations . although large code length up to several thousands is allowed by",
    "can and wecan , the cost in terms of time for these algorithms can reach several hours or even days when the code length and required number of waveforms grow large .",
    "this is a significant limitation that restricts the design of waveforms in real time . in large - scale optimization ,",
    "the targeted computational complexity per iteration of an algorithm is linear in dimension of the problem or at most quadratic @xcite . to reduce the computational complexity to a reasonable one ,",
    "many relevant works resort to the majorization - minimization ( mami ) technique @xcite , which is the basic technique for addressing large - scale and/or non - convex optimization problems with complex objectives @xcite .",
    "for example , @xcite have dealt with multistatic radar waveform design , where an information - theoretic criterion has been utilized , while @xcite have been concerned with single- and @xcite multiple - waveform designs .",
    "in addition to the computational complexity , another important characteristic of large - scale optimization algorithms is the convergence speed / rate @xcite .",
    "although the analytic bounds on the convergence rate may be hard / impossible to derive even for some existing large - scale convex optimization algorithms , the design of algorithms with provably faster convergence speed to tolerance than that of the other algorithms is possible even for non - convex problems considered here .    in this paper , we focus on the isl and wisl minimization - based unimodular waveform designs for the matched filter receiver , aiming at developing fast algorithms that reduce the computational complexity and have faster convergence speed than the existing algorithms .",
    "the paper is based on a more detailed study of inherent algebraic structures of the objective functions , and concerning mami , also designing better majorization functions .",
    "the principal goal is to enable the real time waveform design even when the code length and number of waveforms are large .",
    "although our work also employs the mami approach , it differs from the previous works in many ways .",
    "different from @xcite , we formulate the isl minimization - based unimodular waveform design problem as a non - convex quartic problem by transforming the objective into frequency domain and rewriting it as a norm - based objective . moreover , we find out and use inherent algebraic structures in wisl expression that enable us to derive the corresponding quartic form into an alternative quartic form which in turns allows to apply the quartic - quadratic transformation .",
    "this equivalent form is based on eigenvalue decomposition , which we prove to be unnecessary to compute in our corresponding algorithm .",
    "then the isl and wisl minimization problems in the form of non - convex quartic optimization are simplified into quadratic forms .",
    "it allows us to utilize the mami technique where the majorization functions also differ from those of @xcite and @xcite .",
    "our algorithms have lower or comparable computational burden , faster convergence speed , and demonstrate better correlation properties than the existing state - of - the - art algorithms .",
    "the paper is organized as follows . in section  [ sec : sigmodel ] , the signal model and the isl and wisl minimization - based unimodular waveform design problems are presented . in section  [ sec : optviamm ] , new algorithms for the isl and wisl minimization problems are detailed .",
    "simulation results are presented in section  [ sec : simulation ] , while the paper is concluded in section  [ sec : conclu ] .",
    "_ notations _ : we use bold uppercase , bold lowercase , and italic letters to denote matrices , column vectors , and scalars , respectively .",
    "notations @xmath0 , @xmath1 , and @xmath2 are used for euclidean norm of a vector , frobenius norm of a matrix , and absolute value , respectively .",
    "similarly , @xmath3 , @xmath4 , and @xmath5 stand for conjugate , transpose , and conjugate transpose operations , respectively , while @xmath6 , @xmath7 , and @xmath8 respectively denote column - wise vectorization of a matrix , largest eigenvalue of a matrix , and maximization operations .",
    "notations @xmath9 and @xmath10 stand respectively for the floor function and modulo operation with the first argument being the dividend , while @xmath11 denotes the operation of constructing a hermitian toeplitz matrix from a vector that coincides with the first column of a matrix and @xmath12 is the operator that picks up diagonal elements from a matrix and writes them into a vector ( for matrix argument ) or forms a diagonal matrix with main diagonal entries picked up from a vector ( for vector argument ) . in addition , @xmath13 stands for the matrix trace , @xmath14 stands for the real part of a complex value , @xmath15_{i , j } $ ] denotes the @xmath16th element of a matrix , @xmath17 and @xmath18 respectively denote kronecker and hadamard product operations , @xmath19 is the @xmath20 identity matrix , and @xmath21 denotes an @xmath22 vector with all elements equal to 1 .",
    "consider a radar ( or communication ) system which emits @xmath23 unimodular and mutually orthogonal waveforms .",
    "each waveform is of code length @xmath24 .",
    "then the whole waveform matrix @xmath25 of size @xmath26 is defined as @xmath27 $ ] . here",
    "the @xmath28th column @xmath29 corresponds to the @xmath28th launched waveform .",
    "let the @xmath30th element of @xmath31 be @xmath32 where @xmath33 is an arbitrary phase value ranging between @xmath34 and @xmath35 . when the number of waveforms @xmath23 reduces to one , the waveform matrix @xmath25 shrinks to a column vector .",
    "the isl for the set of waveforms @xmath36 can be expressed as @xcite @xmath37 where @xmath38 is the cross - correlation between the @xmath28th and @xmath39th waveforms at the @xmath30th time lag .",
    "the first term on the right - hand side of is associated with the auto - correlations , while the second term represents the cross - correlations of the waveforms .    likewise , the wisl for the waveforms @xmath36 can be expressed as @xcite @xmath40 where @xmath41 are real - valued symmetric weights , i.e. , @xmath42 , used for controlling the sidelobe levels corresponding to different time lags .",
    "if @xmath43 takes zero value , it means that the sidelobe level associated with the @xmath30th time lag is not considered . if all the controlling weights @xmath41 take the value @xmath44 , then @xmath45 in coincides with @xmath46 in .    the basic unimodular waveform design problem is then formulated as the synthesize of unimodular and mutually orthogonal waveforms @xmath36 which have as good as possible auto- and cross - correlation or weighted correlation properties . using , the wisl minimization - based unimodular waveform design problem can be formally expressed as @xmath47 where the constraints ensure the modularity of waveforms , while the orthogonality between waveforms is guaranteed by the objective .",
    "obviously , if all the controlling weights @xmath41 take the value @xmath44 , the problem becomes the isl minimization - based unimodular waveform design problem .",
    "in this section , we develop fast algorithms for the isl and wisl minimization - based unimodular waveform designs .",
    "the algorithms make use of the mami technique and exploit inherent algebraic structures in the objective function , which allows to reduce the computational complexity .",
    "the isl @xmath46 in can be rewritten in the matrix form as @xmath48 where @xmath49 is the following @xmath50 waveform correlation matrix @xmath51 \\label{eq : rp}\\end{aligned}\\ ] ] and @xmath52 is the kronecker delta function .    transforming into frequency domain and performing some derivations ,",
    "the isl @xmath46 can be expressed as @xcite @xmath53 where @xmath54 with @xmath55 being the @xmath56th row of the waveform matrix @xmath25 , i.e. , @xmath57^ { \\mathrm t } $ ] .    expanding the norm in , after some elementary algebraic computations",
    ", the isl @xmath46 can be rewritten as @xmath58 moreover , introducing the @xmath59 vectorized version of the waveform matrix @xmath60 as @xmath61^ { \\mathrm t}$ ] and the @xmath62 matrix @xmath63 with @xmath64 defined as @xmath65^ { \\mathrm t}$ ] where @xmath66 , and using the facts that @xmath67 and @xmath68 , the isl expression can be further rewritten as @xmath69    noticing that @xmath70 and using the fact that the desired waveforms are orthogonal and have constant modulus , i.e. , @xmath71 , we can find that @xmath72 using and excluding the immaterial optimization terms from , the optimization problem can be rewritten as @xmath73 where the objective function takes a quartic form with respect to @xmath74 .",
    "introducing the @xmath75 and @xmath76 , respectively , matrices @xmath77 and @xmath78 and using the property that @xmath79 , which follows from the elementary properties of the trace and vectorization operations , the objective function in can be transformed from quartic into quadratic form as follows @xmath80 therefore , the problem can be further rewritten as    [ eq : optcanii ] @xmath81    since the objective function takes a quadratic form , a proper majorized function can be applied . before applying the majorant to , we present the following general result that will be used later .",
    "[ th : th1 ] if a real - valued function @xmath82 with complex variable @xmath83 is second - order differentiable , and there is a matrix @xmath84 satisfying the generalized inequality @xmath85 for all @xmath83 , then for each point @xmath86 , the following convex quadratic function @xmath87 majorizes @xmath82 at @xmath86",
    ". appears in @xcite as theorem 3.1 . ]    using taylor s theorem , the second - order expansion of @xmath82 at the point @xmath86 is given as @xmath88 where @xmath89 is a point on the line connecting @xmath90 and @xmath83 . due to the fact that @xmath91 , the inequality @xmath92 also holds true , where @xmath93 is given by .",
    "if @xmath94 is a quadratic form , i.e. , @xmath95 , as it is the case for the objective function in , by substituting @xmath96 in , the majorant can be obtained as @xmath97    let @xmath98 be the @xmath76 identity matrix magnified by the largest eigenvalue of the matrix @xmath99 , i.e. , @xmath100 . for such selection of @xmath98 , the generalized inequality @xmath101 is guaranteed to hold . then using",
    ", the function can be majorized by the following function @xmath102 where the matrix @xmath103 is obtained at the @xmath104th iteration with @xmath105 being the vectorized version of the waveform matrix @xmath106 at iteration @xmath107 .    using the elementary properties of the kronecker product and vectorization operations",
    ", we can find that @xmath108 furthermore , using and the fact that the desired waveforms are orthogonal and unimodular , we obtain @xmath109 moreover , using the definition of the matrix @xmath99 , the maximum eigenvalue of @xmath99 can be found as @xmath110 returning to and using the facts ",
    ", we can see that the first two terms on the right hand of are constant and therefore immaterial for optimization .",
    "thus , ignoring these two terms , the majorization problem for can be written as @xmath111    using the definition and the properties and also @xmath112 the objective function in , denoted hereafter as @xmath113 , can be expanded as @xmath114    applying the mixed - product property of the kronecker product to the right - hand side of the expansion , the objective in can be further derived as @xmath115 it is straightforward to check that the equality @xmath116 holds . applying this equality to ,",
    "the objective in can be rewritten as @xmath117 where the @xmath118 matrix @xmath119 and the @xmath120 matrix @xmath121 are defined as @xmath122 $ ] and @xmath123 , and the @xmath124 vector @xmath125 is defined as is applied to a matrix argument , which means that the magnitude is found for each element of the matrix , that is , the element - wise magnitude . ] @xmath126 via the @xmath127 matrix @xmath128 $ ] .",
    "using , the problem can be rewritten as @xmath129 where the objective function takes a quadratic form , to which the majorant can be applied again . substituting the @xmath120 matrix @xmath98 , defined as @xmath130 , into",
    ", we find that can be majorized by the following function @xmath131 where @xmath132 is the largest element of @xmath133 , equivalently , @xmath134 .",
    "this scaling factor guaranties that the generalized inequality @xmath135 holds . noticing that @xmath136 and using the fact that the desired waveforms are orthogonal and have constant modulus , i.e.",
    ", @xmath137 , we can see that the first two terms in are constant , and hence , immaterial for optimization",
    ". ignoring these terms , the optimization problem can be further majorized by the following problem @xmath138    using again the fact that the desired waveforms have constant modulus , the problem can be equivalently rewritten as @xmath139_{m , p }   { \\aftergroup\\egroup\\originalright}| = 1 , \\ ;",
    "m = 1 , \\ldots , m ; \\ , p = 1 , \\ldots , p \\label{eq : optcaneqv}\\end{aligned}\\ ] ] where the @xmath140 matrix @xmath141 is a hermitian toeplitz matrix constructed from the @xmath142 vector @xmath143 .",
    "the problem has the following closed - form solution @xmath144_{m , p } = \\exp { \\mathopen{}\\mathclose\\bgroup\\originalleft}\\ { j \\cdot \\mathrm { arg } { \\mathopen{}\\mathclose\\bgroup\\originalleft } ( { \\mathopen{}\\mathclose\\bgroup\\originalleft } [ \\mathbf { t } ^ { ( k ) } \\mathbf{y}^{(k ) } { \\aftergroup\\egroup\\originalright}]_{m , p }   { \\aftergroup\\egroup\\originalright } )    { \\aftergroup\\egroup\\originalright}\\ } , \\ ; \\forall m , \\ , \\forall p. \\label{eq : solcan}\\end{aligned}\\ ] ]     = < .75 < .25 @xmath145 , @xmath146 unimodular sequence matrix with random phases .",
    "= < .75 < .25 @xmath147 = < .75 < .25 @xmath148 = < .75 < .25 @xmath149 = < .75 < .25 @xmath150_{m , p } =                       e^ { j \\cdot \\mathrm { arg } { \\mathopen{}\\mathclose\\bgroup\\originalleft } ( { \\mathopen{}\\mathclose\\bgroup\\originalleft } [ \\mathbf { t } ^ { ( k ) } \\mathbf{y}^{(k ) } { \\aftergroup\\egroup\\originalright}]_{m , p }   { \\aftergroup\\egroup\\originalright } )    } ,                                          \\quad \\forall m , \\ , \\forall p                     \\end{aligned}$ ] = < .75 < .25 @xmath151 convergence    finally , according to the mami procedure and using the closed - form solution to the majorization problem , the isl minimization - based unimodular waveform design algorithm is summarized in algorithm  [ canmm ] . there",
    "exist accelerated schemes for mami , such as the squared iterative method ( squarem ) of @xcite , which can be straightforwardly applied to speed up algorithm  [ canmm ] .",
    "the squarem scheme is an extension of the scalar steffensen type method @xcite , @xcite to vector fixed - point iteration empowered with the idea of `` squaring '' @xcite .",
    "it is an `` off - the - shelf '' acceleration method that requires nothing extra to the parameter updating rules of an original algorithm , except possibly the computationally cheap projection to feasibility set , and it is guaranteed to converge @xcite .",
    "different stopping criteria can be employed in algorithm  [ canmm ] .",
    "for example , it can be the absolute isl difference between the current and previous iterations normalized by the initial isl , or it can be the norm of the difference between the waveform matrices obtained at the current and previous iterations . in terms of the per iteration computational complexity of algorithm  [ canmm ] , the straightforward calculation of @xmath125 according to requires @xmath152 operations , the calculation of @xmath153 costs @xmath154 operations , while the computational burden of the matrix to matrix product @xmath155 in is @xmath156 operations .",
    "therefore , the total computational complexity is @xmath157 operations .",
    "however , @xmath125 and @xmath158 can be computed by means of the fast fourier transform ( fft ) at the order of complexity @xmath159 and @xmath160 , respectively .",
    "similarly , using the toeplitz structure of @xmath161 , the product @xmath155 can also be calculated at a reduced complexity @xmath162 , which is the highest in algorithm  [ canmm ] .",
    "thus , the order of complexity of algorithm  [ canmm ] is @xmath162 , which is nearly linear in the dimension of the problem , as required in large - scale optimization .",
    "the wisl in can be written in a matrix form as @xmath163 where @xmath164 are defined in .    in the frequency domain",
    ", can be expressed as @xcite @xmath165 where @xmath166 is defined in and @xmath167 is the weighted spectral density matrix .",
    "let us also define the @xmath140 toeplitz matrix constructed by the weights @xmath41 as follows @xmath168 .",
    "\\label{eq : gamatrix}\\end{aligned}\\ ] ] then the matrix @xmath169 in can be rewritten in the vector - matrix form as @xmath170 substituting into , we arrive to the following wisl expression @xmath171 expanding the squared norm in the sum of yields @xmath172    using the facts that the desired waveforms are orthogonal and unimodular , i.e. , @xmath173 , and also that @xmath174 , we find that @xmath175 therefore , the second and third terms of are constant and immaterial for optimization . with this observation , the wisl minimization problem can be rewritten as    [ eq : wislfreopt ] @xmath176    the hadamard product of two matrices appears under the frobenius norm in , and the resulting matrix there is complex . as a result , we can not arrive to a proper quartic form with respect to @xmath74 by directly expanding the squared norm of .",
    "instead , we need to convert it into a proper one . towards this end , let us consider the eigenvalue decomposition of @xmath177 , which in general may be indefinite and can be expressed as @xmath178 where @xmath179 and @xmath180 are the @xmath107th eigenvalue and eigenvector , respectively , @xmath181 , @xmath182 equals @xmath183 when @xmath184 is negative , otherwise it is the same as @xmath185 , and @xmath186 is the rank of @xmath177 . substituting into and expanding the frobenius norm , the objective function , called hereafter as @xmath187 , can be rewritten as @xmath188 applying the property @xmath189 ( also holds when @xmath185 is replaced by @xmath190 ) to together with the mixed - product property of the kronecker product , the objective function can be rewritten as @xmath191 where the @xmath75 hermitian matrices @xmath192 and @xmath193 are defined as @xmath194 and @xmath195 . substituting to , the wisl minimization problem becomes    [ eq : optwecaniconstr2nd ] @xmath196 [ eq : optwecani ]    the objective function takes a proper quartic form with respect to @xmath74 that enables us to design an algorithm based on the mami approach .    by means of the trace and vectorization operations for matrices , and similar to the previous subsection , we can transform , denoted for brevity as @xmath197 , into the following form @xmath198 where @xmath199 has been defined before , @xmath200 is the @xmath201 matrix defined as @xmath202 with @xmath203    replacing the objective function with , the optimization problem can be rewritten as    [ eq : optwecanii ] @xmath204    where takes a quadratic form , to which a majorant can be applied . yet before applying the majorization procedure , we present the following result that will be used later .",
    "[ lemmaii ] given a set of @xmath205 arbitrary complex vectors @xmath206 and an @xmath207 arbitrary hermitian matrix @xmath208 , the following generalized inequality @xmath209 holds , where @xmath210 .",
    "let @xmath211 and @xmath212 be respectively the sets of eigenvalues ( in descending order ) and corresponding eigenvectors of the matrix @xmath213 , i.e. , @xmath214 . using this expression and elementary properties of the hadamard product ,",
    "the inequality can be derived as @xmath215 the proof is complete .",
    "applying lemma  [ lemmaii ] by taking @xmath216 , @xmath217 , and @xmath218 , we obtain the following inequality @xmath219 note that for a given matrix @xmath220 in , the largest eigenvalue of @xmath221 in , i.e. , @xmath222 , is fixed , and it can be found that @xmath223 .",
    "moreover , the diagonal elements of @xmath224 take values either zero or @xmath225 .",
    "therefore , we can replace the matrix @xmath226 in with an identity matrix magnified by @xmath225 without disobeying the inequality .",
    "using with @xmath227 @xmath228 that satisfies @xmath229 , the objective function can be majorized by the following function @xmath230 due to the property , the first and second terms in are constant and therefore immaterial for optimization . ignoring these terms ,",
    "can be majorized by the problem    [ eq : optwecaniii ] @xmath231    to further simplify , we will need the following result that relates hadamard and kronecker products .",
    "[ lemmaiii ] given two matrices @xmath232 and @xmath233 of the same size @xmath207 and the @xmath234 selection matrix @xmath235 $ ] with @xmath236 being the @xmath237th @xmath207 block matrix composed of all zeros except the @xmath56th element on the main diagonal equalling one , i.e. , @xmath238_{n , n } = 1 $ ] , the following equality @xmath239 holds . under the condition that @xmath240 is an integer ,",
    "@xmath236 can be decomposed as @xmath241 where the matrices @xmath242 and @xmath243 are constructed in the same way as @xmath244 but have the reduced size @xmath245 , and @xmath246 are respectively the column and row indices of the element in the @xmath247 matrix with linear ( column - wise ) index @xmath56 .    the proof of appears in lemma  1 of @xcite .",
    "the remaining results  are the elementary properties of the selection matrix .",
    "applying lemma  [ lemmaiii ] by taking @xmath248 , @xmath249 , and @xmath250 , and substituting into , the objective function , denoted for brevity as @xmath251 , can be rewritten as @xmath252_{n , n ' } \\mathbf { \\bar{e } } _ n \\boldsymbol{\\bar { \\phi } } \\mathbf { \\bar{e}}_{n'}^{\\mathrm{h } } { \\aftergroup\\egroup\\originalright } ) \\mathrm { vec } \\big ( \\mathbf { \\tilde{y}}^{(k ) } \\big ) \\nonumber \\\\      & \\quad\\ ; - \\tfrac{\\lambda_{\\boldsymbol{\\tilde{\\phi}}}}{2 } \\big ( \\mathrm{vec } \\big ( \\mathbf{\\tilde{y } } \\big ) \\big)^{\\mathrm{h } } \\mathrm{vec } \\big ( \\mathbf { \\tilde{y}}^{(k ) } \\big ) \\label{eq : longeqii}\\end{aligned}\\ ] ] where the latter expression in is obtained by expanding the kronecker product in the prior expression for the objective .",
    "using and , and applying the properties and , the objective can be further rewritten as @xmath253 _ {",
    "n , n ' }                  \\mathbf { y   } ^ { \\mathrm{h } }     \\big ( \\mathbf { y } ^ { \\mathrm { t } }      \\otimes   \\mathbf { i } _ { m p } \\big )      \\big ( \\mathbf { \\hat{e } } _ { u{\\mathopen{}\\mathclose\\bgroup\\originalleft } ( n { \\aftergroup\\egroup\\originalright } ) }                  \\nonumber              \\\\              &                   \\otimes \\mathbf { \\hat{e } } _ { v { \\mathopen{}\\mathclose\\bgroup\\originalleft } ( n { \\aftergroup\\egroup\\originalright } ) } \\big )                  \\big ( \\mathbf { a } _ p^ { \\mathrm { t } } \\otimes \\mathbf { i } _ { mp } \\big)^ { \\mathrm { h } }       \\mathrm{vec } \\big ( \\mathbf { a } _ p   \\big ) { \\mathopen{}\\mathclose\\bgroup\\originalleft } ( \\mathrm{vec } \\big ( \\mathbf { a } _ p \\big ) { \\aftergroup\\egroup\\originalright})^{\\mathrm{h } } \\big ( \\mathbf { a } _ p^ { \\mathrm { t } }               \\nonumber              \\\\              &               \\otimes",
    "\\mathbf { i } _ { mp } \\big )               \\big ( \\mathbf { \\hat{e } } _ { u{\\mathopen{}\\mathclose\\bgroup\\originalleft } ( n ' { \\aftergroup\\egroup\\originalright } ) }    \\otimes \\mathbf { \\hat{e } } _ { v { \\mathopen{}\\mathclose\\bgroup\\originalleft } ( n ' { \\aftergroup\\egroup\\originalright } ) } \\big)^ { \\mathrm { h } }                  \\big ( ( \\mathbf { y } ^{(k ) } ) ^ { \\mathrm { t } }    \\otimes   \\mathbf { i } _ { m p } \\big)^ { \\mathrm { h } }         \\mathbf { y } ^{(k ) }              \\nonumber              \\\\              & - \\tfrac{\\lambda_{\\boldsymbol{\\tilde{\\phi}}}}{2 } \\mathbf{y}^{\\mathrm h }               \\big ( \\mathbf{y}^ { \\mathrm { t } }   \\otimes   \\mathbf{i}_{mp } \\big )              \\big ( ( \\mathbf{y}^{(k ) } ) ^ { \\mathrm { t } }   \\otimes   \\mathbf{i}_{mp } \\big)^ { \\mathrm { h } }     \\mathbf{y}^{(k)}.              \\label{eq : longeqiii}\\end{aligned}\\ ] ] applying the mixed - product property of the kronecker product together with the property @xmath254 to , we obtain @xmath255 _ { n , n ' }                    \\mathbf { \\hat{e } } _ { v{\\mathopen{}\\mathclose\\bgroup\\originalleft } ( n { \\aftergroup\\egroup\\originalright } ) }   \\mathbf { a } _ p                        { \\mathopen{}\\mathclose\\bgroup\\originalleft } (                  \\big ( \\mathbf { y } ^{(k ) } \\big)^ { \\mathrm { h } }                  \\mathbf { \\hat{e } } _ { u{\\mathopen{}\\mathclose\\bgroup\\originalleft } ( n ' { \\aftergroup\\egroup\\originalright } ) }                               { \\aftergroup\\egroup\\originalright}.                  { \\aftergroup\\egroup\\originalright}.                  \\nonumber                  \\\\                  &                  \\quad                  \\times                  \\!\\ !                   { \\mathopen{}\\mathclose\\bgroup\\originalleft}. \\vphantom{\\sum_{l=1}^{m^2 p^2 } }                  { \\mathopen{}\\mathclose\\bgroup\\originalleft}.                  \\mathbf { a } _",
    "p \\mathbf { a } _ p^ { \\mathrm { h } }                    \\mathbf { \\hat{e } } _ { v{\\mathopen{}\\mathclose\\bgroup\\originalleft } ( n ' { \\aftergroup\\egroup\\originalright } ) }      \\mathbf { y } ^{(k ) }                   { \\aftergroup\\egroup\\originalright } )                  \\mathbf { a } _ p^ { \\mathrm { h } }      \\mathbf { \\hat{e } } _ { u{\\mathopen{}\\mathclose\\bgroup\\originalleft } ( n { \\aftergroup\\egroup\\originalright } ) }                    \\ !                  - \\tfrac{\\lambda_{\\boldsymbol { \\tilde { \\phi } } } } { 2 }                  \\mathbf { y   } ^ { ( k ) }   ( \\mathbf { y   } ^ { ( k ) } ) ^ { \\mathrm { h } }   \\big )                  \\!\\ !                  { \\aftergroup\\egroup\\originalright } )                  \\mathbf { y   } \\nonumber                   \\\\                  &                  =                  \\mathbf { y   } ^ { \\mathrm{h } }                   { \\mathopen{}\\mathclose\\bgroup\\originalleft } (      \\mathbf{b}^{(k ) }                   - \\tfrac{\\lambda_{\\boldsymbol { \\tilde { \\phi } } } } { 2 } \\mathbf { y   } ^ { ( k ) }   ( \\mathbf { y   } ^ { ( k ) } ) ^ { \\mathrm { h } }                      { \\aftergroup\\egroup\\originalright } )                  \\mathbf { y   }                     \\label{eq : optwecanivobj}\\end{aligned}\\ ] ] where @xmath256 and @xmath257 is an @xmath75 hermitian matrix composed of @xmath258 block matrices , i.e. , @xmath259    \\label{eq : bkmatrix}\\end{aligned}\\ ] ] with the @xmath260th block @xmath261 being a @xmath262 toeplitz matrix whose first row and column coincide with the @xmath142 vectors @xmath263 and @xmath264 , respectively . here ,",
    "the @xmath265th ( @xmath266 ) elements of @xmath267 and @xmath268 are respectively given by @xmath269 where @xmath270 , @xmath271 is the set of non - negative indices associated with the non - zero isl controlling weights ( always including zero index for the sake of simplicity ) , and @xmath272 is the complementary set of @xmath273 with the full set defined as @xmath274 $ ] . the meanings of and are that the non - zero elements of @xmath267 and @xmath275 are expressed by the sum of the off diagonal elements in the upper and lower triangular parts of @xmath276 magnified by @xmath277 , respectively . using and",
    ", we can avoid calculations for the zero elements .",
    "note that @xmath278 , therefore , only the upper ( or lower ) triangular part of @xmath279 needs to be determined .",
    "the objective function takes a quadratic form , to which the majorant of can be applied again .",
    "let @xmath280 , so that the generalized inequality @xmath281 is guaranteed for . here",
    "we can use any matrix norm of @xmath282 for @xmath283 because any matrix norm serves as an upper bound of the largest eigenvalue .",
    "thus , the objective function can be majorized by the following function @xmath284 similar to the majorant , the first two terms of are constant and therefore immaterial for optimization .",
    "ignoring these two terms , the problem can be majorized by @xmath285 due to the constant modulus property of @xmath74 , the problem is equivalent to the following optimization problem @xmath286 where @xmath287 .",
    "the problem can be then solved in closed form as @xmath288 finally , reshaping the so - obtained vector @xmath74 into a @xmath289 matrix , we obtain the designed waveform matrix @xmath60 .",
    "the wisl minimization based unimodular waveform design algorithm is summarized in algorithm  [ wecanmm ] .",
    "= < .75 < .25 @xmath145 , @xmath290 unimodular sequence with random phases .",
    "= < .75 < .25 @xmath291 = < .75 < .25 @xmath292 = < .75 < .25 @xmath293 = <",
    ".75 < .25 construct @xmath294 via = < .75 < .25 @xmath295 = < .75 < .25 @xmath296 = < .75 < .25 @xmath297 = < .75 < .25 @xmath151 convergence    to find the computational complexity of algorithm  [ wecanmm ] , we assume that the set of @xmath273 consists of @xmath298 elements",
    ". it can be seen that both @xmath263 in and @xmath268 in can be calculated with at most @xmath299 operations if @xmath276 is given .",
    "the calculation of the covariance matrix @xmath276 costs @xmath300 operations .",
    "note that we only need to do calculations for the subscripts @xmath301 and @xmath302 , and then repeat the above summarized calculations @xmath303 times .",
    "finally , the calculation of the vector @xmath304 needs @xmath305 operations .",
    "consequently , the total number of operations is upper bounded by @xmath306 . in other words ,",
    "the computational complexity of algorithm  [ wecanmm ] is at most @xmath307 that is smaller than quadratic in the problem size , and therefore suitable for large - scale optimization .. ] the accelerated version of algorithm  [ wecanmm ] is obtained by a straightforward application of the squarem acceleration scheme @xcite as in the case of algorithm  [ canmm ] .",
    "we evaluate here the performance of the proposed isl and wisl minimization - based waveform design algorithms ( algorithms  [ canmm ]  and  [ wecanmm ] ) by comparing them with existing isl and wisl minimization based algorithms . to be specific , our algorithm  [ canmm ] for isl minimization ( named hereafter as islnew ) is compared with the can of @xcite and the ( third ) algorithm in @xcite ( named hereafter as islsong ) , while our algorithm  [ wecanmm ] for wisl minimization ( named hereafter as wislnew ) is compared with the wecan of @xcite and the ( second ) algorithm in @xcite ( named hereafter as wislsong ) .",
    "the accelerated versions of the mami - based algorithms , including the islnew , wislnew , islsong , and wislsong algorithms , are also tested , where the squarem scheme @xcite is used for mami acceleration .",
    "we generate sets of unimodular sequences with random phases as the initialization for each algorithm tested , and apply the same set of sequences to all algorithms for the purpose of fair comparison .",
    "all comparisons are conducted based on the same hardware and software platforms . throughout our simulations , two stopping criteria are employed : ( i ) the absolute isl or wisl difference between the current and previous iterations normalized by the initial isl or wisl , whose tolerance is set to be @xmath308 ; and ( ii ) the norm difference between the waveform matrices ( or vectors ) obtained at the current and previous iterations , whose tolerance is set to be @xmath309 .",
    "the isl and wisl values in dbs are defined as @xmath310 and @xmath311 , respectively .      in the first example , we study the convergence properties of the waveform design algorithms ( can , islsong , islnew , accelerated islsong , and accelerated islnew ) in terms of the number of conducted iterations for a problem of relatively small size . specifically , a single waveform ( @xmath312 ) of the code length @xmath313 is designed in this example . in figs .",
    "[ fig : islvsite ] and [ fig : islvsite ] , the isl performance versus the number of conducted iterations is displayed for the aforementioned algorithms , where the stopping criteria ( i ) and ( ii ) are used , respectively .",
    "the isl values for different algorithms obtained at each iteration are normalized by the isl value associated with the initial set of sequences .",
    "it can be seen from figs .",
    "[ fig : islvsite ] and [ fig : islvsite ] that for all the algorithms tested , the isl decreases monotonically as the number of iterations increases . among the isl minimization - based algorithms tested ,",
    "the accelerated islnew algorithm shows the best convergence speed , i.e. , it requires the smallest number of iterations to converge to a solution that satisfies the pre - set tolerance parameter for both stopping criteria used .",
    "the accelerated islsong algorithm shows the second best convergence speed .",
    "this demonstrates the superiority of applying accelerated mami techniques to the isl minimization - based waveform design .",
    "the proposed islnew algorithm without acceleration shows a little slower convergence speed , but achieves around @xmath314  db better isl than that of the can algorithm .",
    "the islsong algorithm without acceleration shows the worst convergence speed among all the algorithms tested .",
    "the same convergence behavior can also be seen in figs .",
    "[ fig : islvsite ] and [ fig : islvsite ] independent on the stopping criteria used .",
    "max width=    = 7pt [ tab : isl_t1 ]    [ cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]     min . : obtained minimum wisl value ( in db ) .",
    "ave . : obtained average wisl value ( in db ) .",
    "number of conducted iterations .    in the fourth",
    "example , we compare the performance of the wisl minimization - based algorithms ( wecan , accelerated wislsong , and accelerated wislnew ) in terms of the following characteristics : the minimum and average wisl after convergence ( in dbs ) , the average consumed time ( in seconds ) , and the average number of conducted iterations .",
    "the number of waveforms and the code lengths are taken the same as in the second example , and all results are averaged over @xmath315 independent trials . moreover , the isl controlling weights are the same as in the previous example . table  [ tab : wisl_t1 ] shows the results when the stopping criterion ( i ) is used , while table  [ tab : wisl_t2 ] shows the results for the stopping criterion ( ii ) .",
    "it can be seen from table  [ tab : wisl_t1 ] that the accelerated wislnew algorithm outperforms the other two algorithms tested in this example for all code lengths .",
    "the accelerated wislsong algorithm shows the second best performance in terms of all evaluation characteristics , and the wecan algorithm performs the worst . among all code lengths , the smallest average wisl values after convergence by the wecan , accelerated wislsong , and accelerated wislnew algorithms are respectively @xmath316  db , @xmath317  db , and @xmath318  db , while the largest average wisl values are @xmath319  db , @xmath320  db , and @xmath321  db ( all at @xmath322 ) , respectively .",
    "the wecan algorithm generally consumes significantly more time , requires more iterations , and achieves higher wisl values than the other two algorithms .",
    "it is manly because it does not deal with the original wisl objective function but instead a surrogate one . the advantages of the wislnew and wislsong algorithms over the wecan algorithm become a lot more obvious when the code length @xmath323 is larger than @xmath324 , which verifies the fact that the wecan algorithm is suitable only for the wisl minimization - based waveform design with short code length .",
    "the wecan algorithm may converge very slowly when the set of isl controlling weights is not sparse .",
    "focusing on the comparisons between the accelerated wislsong and accelerated wislnew algorithms , we can see from table  [ tab : wisl_t1 ] that the accelerated wislnew algorithm is superior to the accelerated wislsong algorithm when the code length @xmath323 is larger than @xmath324 , and the biggest differences ( occurring at @xmath325 ) of the minimum and average wisl values between these two algorithms reach @xmath326  db and @xmath327  db , respectively .",
    "the accelerated wislnew algorithm always consumes less time and requires smaller number of iterations than the accelerated wislsong algorithm .",
    "the larger the code length @xmath323 is , the more obvious the superiority of the accelerated wislnew algorithm becomes .",
    "for example , the ratio of the consumed time between these two algorithms decreases from about @xmath328 ( that is , the accelerated wislnew algorithm requires only @xmath328 time required by the accelerated wislsong algorithm ) to @xmath329 , and the corresponding ratio of the number of conducted iterations for these two algorithms decreases from about @xmath330 to @xmath331 as the code length increases from @xmath332 to @xmath325 .",
    "thus , the proposed wislnew algorithm is better suited for large - scale waveform design problems . in addition , for the waveform design with smaller code length and larger number of non - zero isl controlling weights ( corresponding to the @xmath333 case in this example ) , the minimum and average wisl values after convergence for the wislnew and wislsong algorithms are close to each other , and are slightly better than those for the wecan algorithm . however , the accelerated wislnew algorithm is still superior in terms of the other characteristics .",
    "the above discussed advantages of the proposed wislnew algorithm over the wecan and wislsong algorithms are also verified by table  [ tab : wisl_t2 ] where the experiment is conducted under the stopping criterion ( ii ) .",
    "it can be seen that the data therein follow the same trends as in table  [ tab : wisl_t1 ] . to be explicit , the accelerated wislnew algorithm takes around @xmath334 times less time and @xmath335 times less number of iterations compared to the accelerated wislsong algorithm , and it achieves significantly lower minimum and average wisl values after convergence , especially for large code length . on the contrary , the wecan algorithm always demonstrates the worst performance in terms of all evaluation characteristics .    finally in the fifth example , we present the auto- and cross - correlations of @xmath336 waveforms designed by the accelerated wislsong and accelerated wislnew algorithms with code length @xmath337 .",
    "we set the isl controlling weights to the same values as those in the previous two examples . the stopping criterion ( i )",
    "is utilized in this example .",
    "the four sub figures in fig .",
    "[ fig : correvaluation ] stand for the auto- and cross - correlations of the two sets of waveforms generated by the two aforementioned algorithms . here",
    "the correlation levels , defined as @xmath338 , are shown ( in dbs ) .",
    "to better display the results , we only show the auto- and cross - correlations for the time lags within the range @xmath339 $ ] . the wecan algorithm for the large code length in this example",
    "costs significantly more time and shows the worst auto- and cross - correlations , and therefore , is not shown in fig .",
    "[ fig : correvaluation ] .",
    "it can be seen from fig .",
    "[ fig : correvaluation ] that the auto - correlations associated with the time lags @xmath340 \\cup [ 1 , 19]$ ] and cross - correlations associated with the time lags @xmath341 $ ] for both generated sets of waveforms are well controlled , while the waveform correlations associated with other time lags are not controlled .",
    "therefore , the latter results in much higher correlation levels . under the condition of using the same tolerance parameter , the correlation levels corresponding to the time lags of interest obtained by the proposed wislnew algorithm are significantly better than those obtained by the wislsong algorithm . the largest gap between the obtained correlation levels by these two algorithms has reached about @xmath342  db . moreover , the proposed wislnew algorithm needs significantly shorter time than the wislsong algorithm as it has been discussed above .",
    "in this paper , we have developed two ( one based on isl and the other based on wisl minimization ) new fast algorithms for designing single / multiple unimodular waveforms / codes with good auto- and cross - correlation or weighted correlation properties . since",
    "the corresponding optimization problems are non - convex and may be large - scale , the proposed algorithms are based on the mami framework and utilize a number of newly found inherent algebraic structures in the objective functions of the corresponding optimization problems .",
    "these properties have enabled us to reduce the computational complexity of the algorithms to the level which is suitable for large - scale optimization and at least similar to or lower than that of the existing algorithms . moreover ,",
    "the proposed algorithms also show faster convergence speed to tolerance and provide waveforms of better quality than those of the existing state - of - the - art algorithms .",
    "y.  yang and r.  s. blum , `` mimo radar waveform design based on mutual information and minimum mean - square error estimation , '' _ ieee trans .",
    "_ , vol .",
    "43 , no .  1 ,",
    "330343 , jan . 2007 .",
    "a.  de maio , s.  d. nicola , y.  huang , z .- q .",
    "luo , and s.  zhang , `` design of phase codes for radar performance optimization with a similarity constraint , '' _ ieee trans . signal process .",
    "_ , vol .",
    "57 , no .  2 , pp . 610621 ,",
    "2009 .",
    "h.  hao , p.  stoica , and j.  li , `` designing unimodular sequences sets with good correlations  including an application to mimo radar , '' _ ieee trans . signal process .",
    "_ , vol .",
    "57 , no .  11 , pp . 43914405 , nov .",
    "a.  de maio , y.  huang , m.  piezzo , s.  zhang , and a.  farina , `` design of optimized radar codes with a peak to average power ratio constraint , '' _ ieee trans . signal process .",
    "_ , vol .",
    "59 , no .  6 , pp . 26832697 , jun .",
    "a.  aubry , a.  de maio , a.  farina , and m.  wicks , `` knowledge - aided ( potentially cognitive ) transmit signal and receive filter design in signal - dependent clutter , '' _ ieee trans .",
    "_ , vol .  49 , no .  1 ,",
    "93117 , jan .",
    "2013 .",
    "q.  he , r.  s. blum , and a.  m. haimovich , `` noncoherent mimo radar for location and velocity estimation : more antennas means better performance , '' _ ieee trans . signal process .",
    "_ , vol .",
    "58 , no .  7 , pp . 36613680 , jul .",
    "2010 .",
    "l.  zhao , j.  song , p.  babu , and d.  p. palomar , `` a unified framework for low autocorrelation sequence design via majorization - mimimization , '' _ ieee trans .",
    "signal process .",
    "_ , vol .",
    "65 , no .  2 ,",
    "pp . 438453 , jan .",
    "2017 .",
    "m.  m. naghsh , m.  modarres - hashemi , s.  shahbazpanahi , m.  soltanalian , and p.  stoica , `` unified optimization framework for multi - static radar code design using information - theoretic criterion , '' _ ieee trans . signal process .",
    "_ , vol .",
    "61 , no .  21 , pp .",
    "54015416 , nov .",
    "a.  khabbazibasmenj , f.  roemer , s.  a. vorobyov , and m.  haardt , `` sum - rate maximization in two - way af mimo relaying : polynomial time solutions to a class of dc programming problems , '' _ ieee trans .",
    "signal process .",
    "_ , vol .  60 , no .  10 , pp .",
    "54785493 , oct .",
    "m.  soltanalian , a.  gharanjik , b.  shankar , and b.  ottersten . ( 2017 ) grab - n - pull : a max - min fractional quadratic programming framework with applications in signal processing .",
    "submitted to _",
    "ieee trans . signal process .",
    "_ [ online ] .",
    "available : http://msol.people.uic.edu/papers/gnp_pre.pdf    y.  li , s.  a. vorobyov , and z.  he , `` design of multiple unimodular waveforms with low auto- and cross - correlations for radar via majorization - minimization , '' in _ proc .",
    "24th european signal process .",
    "( eusipco ) _ , budapest , hungary , aug.sep .",
    "2016 , pp . 22352239 .",
    "y.  li and s.  a. vorobyov , `` efficient single / multiple unimodular waveform design with low weighted correlations , '' in _ proc .",
    "conf . acoust . , speech , , signal process .",
    "( icassp ) _ , new orleans , usa , mar ."
  ],
  "abstract_text": [
    "<S> in this paper , we develop new fast and efficient algorithms for designing single / multiple unimodular waveforms / codes with good auto- and cross - correlation or weighted correlation properties , which are highly desired in radar and communication systems . </S>",
    "<S> the waveform design is based on the minimization of the integrated sidelobe level ( isl ) and weighted isl ( wisl ) of waveforms . as the corresponding optimization problems </S>",
    "<S> can quickly grow to large scale with increasing the code length and number of waveforms , the main issue turns to be the development of fast large - scale optimization techniques . </S>",
    "<S> the difficulty is also that the corresponding optimization problems are non - convex , but the required accuracy is high . </S>",
    "<S> therefore , we formulate the isl and wisl minimization problems as non - convex quartic optimization problems in frequency domain , and then simplify them into quadratic problems by utilizing the majorization - minimization technique , which is one of the basic techniques for addressing large - scale and/or non - convex optimization problems . while designing our fast algorithms , we find out and use inherent algebraic structures in the objective functions to rewrite them into quartic forms , and in the case of wisl minimization , to derive additionally an alternative quartic form which allows to apply the quartic - quadratic transformation . </S>",
    "<S> our algorithms are applicable to large - scale unimodular waveform design problems as they are proved to have lower or comparable computational burden ( analyzed theoretically ) and faster convergence speed ( confirmed by comprehensive simulations ) than the state - of - the - art algorithms . in addition , the waveforms designed by our algorithms demonstrate better correlation properties compared to their counterparts .    </S>",
    "<S> correlation , majorization - minimization , mimo radar , waveform design . </S>"
  ]
}