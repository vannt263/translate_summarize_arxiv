{
  "article_text": [
    "in an increasingly connected world , our opinions on a phenomenon of interest or event are often not only influenced by our direct independent observations , but also by other people s public opinions on related events . in an online social network like twitter or facebook , users opinions and postings",
    "are often influenced by the opinions of those they are connected to or are `` following '' in the social network @xcite .",
    "for example , in viral marketing using social networks , marketing companies often target a few influential nodes in the network to help them push a product @xcite . similarly , widespread online access",
    "has made it easier for us to follow the opinions of experts like celebrities and industry insiders , who may have access to private information that we are unaware of .",
    "for example , we may be interested to determine the financial health of a publicly listed company .",
    "in addition to our own observations about the company through its annual financial reports and stock prices , we may also choose to incorporate the `` expert '' opinion provided by financial blogs like @xcite and @xcite .",
    "in all these examples , inference about a phenomenon of interest is not only based on direct observations but also the opinions of other entities .",
    "this is known as _",
    "social learning _ @xcite .",
    "a further example is the internet of things ( iot ) framework @xcite .",
    "sensors each make their own private observations but collaborate by exchanging public information .",
    "this can be viewed as a `` physical social network '' of devices , cooperating to improve their situational awareness .",
    "sensors originally designed for a specific purpose may collaborate with other sensors to perform inference on a phenomenon they were not specifically designed for . however , in order to ensure energy efficiency , each sensor needs to intelligently choose which other sensors to collaborate with since not all sensors may provide information relevant to it .",
    "for example , a sensor trying to estimate the temperature in a particular room of a building may choose to incorporate information from other temperature sensors or sensors tracking the number of occupants in the building , instead of information from a vibration monitoring sensor . in this paper , we investigate the problem of multihypothesis social learning in which an agent can select an expert opinion from a group of experts , to incorporate into its final decision in order to minimize its expected loss . specifically , we consider an agent @xmath0 who wishes to choose from a set of @xmath1 hypotheses based on its own observations as well as the opinion of an expert chosen from a set of @xmath2 possible experts .",
    "each expert has access to a set of private observations , which they use to form their own opinions about the true hypothesis , subject to their own local loss functions or biases , which may differ from that of agent @xmath0 . by taking into account the experts individual biases , our goal is to find an asymptotically optimal expert choice in order to minimize agent @xmath0 s expected loss .",
    "the problem of selecting the best expert opinion to follow is related to the problem of _ decentralized detection _ or decentralized hypothesis testing , which has been extensively studied in @xcite and the references therein . in the decentralized detection problem",
    ", each agent has its own private observations , but cooperate with each other so that the whole network of agents reaches a decision regarding a common underlying phenomenon of interest . here , which agent passes information to which other agent",
    "is determined by a known network topology like the parallel configuration @xcite , tandem network @xcite , and tree architectures @xcite .",
    "therefore , all these works do not consider the problem of selecting which other agent s opinion to follow . furthermore , in a decentralized detection problem , all agents are assumed to have the same hypotheses and loss functions for declaring the wrong hypothesis , or have the common goal of minimizing the loss at a last agent known as the fusion center .",
    "we study a related but somewhat different problem from the decentralized detection problem .",
    "we consider the scenario where experts may make decisions according to their own biases , instead of minimizing the loss of a particular agent or fusion center . in @xcite ,",
    "the authors consider binary hypothesis testing in a social network , in which agents sequentially observe the opinions of a stochastically generated neighborhood of agents in the network .",
    "each agent has the same 0 - 1 loss function , and conditions are derived for the bayesian error probability of the @xmath3th agent to approach to zero as @xmath3 becomes large .",
    "the network model we consider in this paper is equivalent to a two - layer hierarchical tree network , which is much simpler compared to that studied in @xcite .",
    "this is because our goal is to analyze how an expert s opinion impacts that of a particular agent .",
    "in addition , we consider a multihypothesis testing problem in which each agent has different loss functions or even different number of hypotheses .",
    "since finding optimal decision rules for general decentralized hypothesis testing problems is np - complete @xcite , it is difficult to find analytical characterizations for the best expert choice in networks of moderate size , and where agents have private observations that are not conditionally independent given the underlying hypothesis . therefore , most of the literature in decentralized detection has focused on the case where observations are conditionally independent @xcite .",
    "the same challenge applies to the social learning problem in this paper , and we therefore consider only the case where agents private observations are conditionally independent . although the problem becomes numerically tractable under this assumption , it remains hard to characterize the agents optimal policies and decision rules analytically ( see @xcite for a discussion ) . to overcome this difficulty",
    ", we consider the regime where each agent has access to an asymptotically large number of private observations ( e.g. , over a sufficiently long period of time ) but each agent s observation sources and loss functions may differ .",
    "this allows us to adopt a large deviations perspective to the expert choice problem , and derive analytical characterizations of the optimal choice and agent strategies .",
    "the reference @xcite considers a multihypothesis testing problem in a parallel configuration with a single agent , which is allowed to take actions that affect the observations it makes .",
    "the distribution of the observation at each time step depends on the action of the agent in the previous time step , and has bounded kullback - liebler divergences under any pair of hypotheses .",
    "the agent s aim is to minimize the error exponent corresponding to the 0 - 1 loss function .",
    "our work can be viewed as a generalization of a result in @xcite ( which also considers the sequential detection problem that we do not study here ) to the case where one of the agent observations is the opinion of an expert , which itself has asymptotically many private observations leading to unbounded kullback - liebler divergences for its opinion .",
    "furthermore , we consider general loss functions and the corresponding loss exponent , which is a generalization of the error exponent in @xcite .",
    "the characterization of the error exponents corresponding to 0 - 1 loss functions in multihypothesis testing has also been studied in @xcite , which derive the achievable error exponents region .",
    "our goal is to optimize the loss exponent of agent @xmath0 , the absolute value of which is the rate of decay of the expected loss incurred by agent @xmath0 as the number of private observations grows large .",
    "we suppose that agent @xmath0 has a decision space consisting of @xmath1 hypotheses , and has a choice of @xmath2 expert opinions to follow .",
    "a.   we consider a general @xmath1-ary multihypothesis social learning framework in which an agent @xmath0 and every expert have loss functions that depend on the number of private observations the agent or expert has access to .",
    "each expert makes a decision that takes values from a decision space , the size of which may not be the same as @xmath1 .",
    "we characterize the loss exponent of each expert , and provide an asymptotically optimal policy for an expert to achieve its optimal loss exponent ( theorem [ theorem : expert ] ) .",
    "b.   we derive the optimal loss exponent for agent @xmath0 after it has incorporated the opinion of a particular expert , and provide an asymptotically optimal method for agent @xmath0 to choose the best expert to follow ( theorem [ theorem : expert_choice ] ) .",
    "we also show that the worst loss exponent , up to asymptotic equivalence , for the definition of asymptotic equivalence .",
    "] for agent @xmath0 is achieved when agent @xmath0 adopts the 0 - 1 loss function ( cf .",
    "remark [ rem : worstloss ] of section [ subsect : choose ] ) . c.   we introduce the concept of hypothesis - loss neutrality in section [ subsection : special ] , and",
    "show that if agent @xmath0 adopts a hypothesis - loss neutral policy , then the opinion of any expert who has a decision space with number of states strictly less than @xmath1 , is ignored by agent @xmath0 ( proposition [ prop : expert_necessary ] ) . in this case ,",
    "additional information is useless , which is somewhat unexpected .",
    "d.   we show that if all experts have the same decision space as agent @xmath0 , then it is not necessarily optimal for agent @xmath0 to choose the expert with the same loss function as itself .",
    "this is surprising as conventional wisdom seems to suggest otherwise .",
    "if agent @xmath0 adopts the 0 - 1 loss function , we derive sufficient conditions for when it is optimal to choose an expert who also utilizes the 0 - 1 loss function ( proposition [ prop : bestexpertloss ] ) .    in this work , we do not address the case where agent @xmath0 s opinion may be utilized by one of the experts , which result in much more complex opinion dynamics than that considered in this paper .",
    "this leads to the interesting question of whether there exists an equilibrium in the choice of loss functions in a network of agents who can incorporate opinions from each other .",
    "this is however out of the scope of the current work , and will be addressed in our future research .",
    "the rest of this paper is organized as follows . in section [",
    "sect : formulation ] , we describe our system model , problem formulation and assumptions .",
    "we characterize the agents loss exponents in section [ sect : optimal ] , and provide asymptotically optimal policies to achieve the optimal loss exponents .",
    "in section [ sect : optimalchoice ] , we discuss the optimal expert choice for agent @xmath0 , and derive insights into this choice by making simplifying assumptions .",
    "we conclude in section [ sect : conclusion ] .",
    "appendix [ appendix : mathematical ] contains a brief review of some basic definitions of large deviations theory , and we defer all proofs to appendix [ appendix : proofs ] .",
    "appendix [ appendix : ak_properties ] contains a characterization of the asymptotic decision regions , which are introduced in section [ subsect : lossexp_experts ] .",
    "in this section , we define our system model , assumptions and some notations .",
    "we consider an underlying measurable space @xmath4 on which all random variables in this paper are defined .",
    "we adopt the following notations throughout this paper .",
    "let @xmath5 be the space of real numbers , and let @xmath6 be the inner product of the vectors @xmath7 and @xmath8 in @xmath9 .",
    "for @xmath10 , let @xmath11 be the vector augmented with a zero as the first element .",
    "the range of integers @xmath12 is denoted as @xmath13 $ ] .",
    "the notations @xmath14 $ ] and @xmath15 are used to represent the sequences @xmath16,x[2],\\ldots , x[n])$ ] and @xmath17 , respectively .",
    "we also make use of @xmath18 $ ] to denote the @xmath19th element in the vector or sequence @xmath20 .",
    "suppose that an agent @xmath0 wishes to determine the underlying hypothesis @xmath21 associated with a phenomenon of interest , which from agent @xmath0 s frame of reference can be modeled by a set of probability measures @xmath22 on the space @xmath4 .",
    "let @xmath23 be the mathematical expectation under @xmath24 , and let @xmath25 $ ] if all agents private observations have distributions derived from the probability measure @xmath24 .",
    "we suppose that @xmath26 has prior probability @xmath27 .",
    "the agent @xmath0 can choose to incorporate the opinion of an expert , chosen from a set of expert agents @xmath28 ( see figure [ fig : two_layer ] ) .",
    "if there is no need to distinguish between agent @xmath0 and the experts , we use the generic term `` agent '' to refer to either of them .",
    "each agent @xmath29 has access to a set of private observations @xmath30 = ( y_k[1],\\ldots,\\allowbreak y_k[n_k])$ ] . conditioned on @xmath26 , we assume that each @xmath31 $ ] , for @xmath32 , is drawn independently from a conditional distribution belonging to the set @xmath33 , where @xmath34 is a finite index set representing the information sources of agent @xmath35 .",
    "the distribution set @xmath33 varies from agent to agent , and models the differences in quality of information that each agent may have access to .",
    "we assume that for each @xmath36 , the probability measures @xmath37 for @xmath38 , are absolutely continuous with respect to ( w.r.t . ) each other , and are known to all the agents .",
    "we further assume that conditioned on @xmath21 , all the random variables @xmath39)_{k=0}^k$ ] are independent .     incorporates the decision of an agent @xmath40 . ]    to motivate our setup , consider the example alluded to in section [ sect : introduction ] , where an agent @xmath0 is interested to determine the financial health of a large publicly listed conglomerate .",
    "in addition to its own observations @xmath41 $ ] about the company through annual financial reports and other publicly available indicators like stock prices , the agent @xmath0 may also choose to incorporate the expert opinion of an investment analyst .",
    "because of limited financial resources ( since most analyst reports are not free ) , agent @xmath0 can only choose to subscribe to one analyst , and has to make an optimal choice of which analyst to use .",
    "in most of this paper , for simplicity , we restrict ourselves to the case where the opinion of a single expert is considered in the decision making of agent @xmath0 , and show how to generalize our results to a finite set of experts later in remark [ remark : multiexperts ] of section [ sect : optimalchoice ] .",
    "note also that the number of information sources for each agent is also typically finite as in this example , which justifies our assumption that @xmath42 for all @xmath43 .",
    "let @xmath44)_{\\gamma\\in\\gamma_k}$ ] be a vector of non - negative weights summing to one , where @xmath45n_k } \\rfloor}}$ ] is the number of private observations of agent @xmath35 that have conditional distribution @xmath37 when the hypothesis @xmath26 .",
    "we let the remaining @xmath46n_k } \\rfloor}}$ ] observations be drawn from an arbitrary distribution from the set @xmath33 .",
    "since we are concerned about asymptotics in this paper , the choice of the arbitrary distribution is immaterial to our analysis .",
    "we say that @xmath47 is a _",
    "policy _ for agent @xmath35 .",
    "an agent chooses its policy in order to minimize its expected loss , as described below .",
    "let @xmath48 be the simplex consisting of all agent policies .",
    "based on its observations , each expert @xmath49 makes a decision @xmath50 ) \\in [ 0,d_k-1]$ ] by minimizing a local loss criterion .",
    "we assume that every expert @xmath51 chooses its policy @xmath47 and decision rule @xmath52 so that @xmath53}}\\end{aligned}\\ ] ] is minimized , where @xmath54 is a non - negative finite loss incurred if the decision of expert @xmath35 is @xmath55 when the true hypothesis is @xmath26 .",
    "we can think of @xmath56 as encoding the `` bias '' of expert @xmath35 .",
    "we call this the _ loss function _ of expert @xmath35 , and @xmath57}}\\end{aligned}\\ ] ] the _ loss exponent _ of expert @xmath35",
    ". an example of a loss function is the 0 - 1 loss function : @xmath58 , and @xmath59 for all @xmath60 if @xmath61 , which results in being the error probability considered in @xcite . in this paper",
    ", we consider the regime where experts have asymptotically large number @xmath62 of private observations , which corresponds to the case where experts are very experienced in their respective fields ( as determined by @xmath34 ) .    by allowing the loss function to depend on the number of private observations",
    ", we can model various practical applications .",
    "for example , the expert @xmath35 may itself be part of a decentralized detection network like a tree configuration @xcite , in which case its goal is to minimize the bayesian error probability at a fusion center .",
    "then , its loss function decays exponentially fast in the number of private observations @xmath62 . in the publicly listed conglomerate example , suppose that one of the hypotheses corresponds to the conglomerate being financially bankrupt .",
    "the loss associated with a missed detection of this hypothesis can be modeled to be exponentially larger than the loss associated with a missed detection of another more benign hypothesis . in our model ,",
    "expert @xmath35 s decision space consists of @xmath63 states , where @xmath63 may not equal to @xmath1 , the number of hypotheses that agent @xmath0 is interested in .",
    "this allows us to model scenarios where different agents may have different models for the underlying state of the world .",
    "using the conglomerate example described above , agent @xmath0 may be interested in the financial health of the whole conglomerate , while a particular analyst may only be interested in the real estate arm of the conglomerate .",
    "nevertheless , the performance of the real estate arm has a bearing on the overall health of the conglomerate .",
    "in particular , expert @xmath35 may not distinguish between two hypotheses , say @xmath64 and @xmath65 .",
    "this can be modeled by assuming that the expert declares the decision @xmath66 when @xmath67 and @xmath68 if @xmath64 or @xmath69 . in this case",
    ", we let @xmath70 for all @xmath71 and @xmath72 .",
    "this model is also general enough to model different decision spaces that may not map directly to any of the hypotheses of agent @xmath0 .    on the other hand",
    ", we note that without loss of generality , there is no need to consider the case where an expert uses a model in which there are more than @xmath1 hypotheses , since agent @xmath0 can always choose a @xmath1 that is sufficiently large in its model .",
    "in addition , since our analysis is based on the frame of reference of agent @xmath0 , it has no knowledge of any additional hypotheses , and in practical applications , it simply assumes that expert @xmath35 minimizes the expected loss given in .",
    "we assume that based on the publicized expertise of each expert , agent @xmath0 knows its loss function decay rates , defined in assumption [ assumpt : loss ] below .",
    "let @xmath73,d_k ) \\in[0,m-1]$ ] be the decision made by agent @xmath0 after incorporating the opinion @xmath74 of agent @xmath35 .",
    "the expected loss of agent @xmath0 is @xmath75}},\\end{aligned}\\ ] ] where @xmath76 is the non - negative loss incurred by agent @xmath0 if it decides in favor of hypothesis @xmath55 when the true hypothesis is @xmath26 , and the number of private observations is @xmath77 .",
    "we make the following assumptions regarding the loss function of each agent .",
    "[ assumpt : loss ]    a.   [ it : c_0 ] for all @xmath78 and @xmath79 $ ] , we have @xmath80 , and for every @xmath81 $ ] such that @xmath61 , we have @xmath82 with @xmath83 b.   [ it : c_k ] for each agent @xmath51 , we have for every @xmath79 $ ] and @xmath84 $ ] , @xmath85 we assume that agent @xmath0 knows the loss function decay rates @xmath86 , for all @xmath87 , based on the publicized expertise of each expert .",
    "since the number of agents and decision states are finite , we can normalize @xmath54 by @xmath88 or @xmath89 so that there is no loss in generality in assuming that @xmath90 for all @xmath91 , @xmath55 , and @xmath35 . in assumption",
    "[ assumpt : loss ] , we make the simplifying assumption that the loss function decay rate for agent @xmath0 w.r.t .",
    "a particular hypothesis is the same for all wrong decisions .",
    "this is because otherwise , easy examples can be constructed in which agent @xmath0 declares the wrong hypothesis with high probability for large @xmath77 . to see this ,",
    "suppose that all hypotheses have the same prior probability , @xmath92 is the true hypothesis , and agent @xmath0 s observations are all drawn from the same conditional distribution .",
    "the loss of agent @xmath0 if it makes the decision @xmath55 is , with high probability , approximately proportional to @xmath93 where @xmath94 is the kullback - liebler divergence of the conditional distribution under @xmath92 versus that under @xmath26 @xcite . if @xmath95 , while @xmath96 for all @xmath97 , then agent @xmath0 decides in favor of @xmath98 instead of @xmath92 when @xmath77 is large",
    "this is clearly an undesirable model as @xmath99 for all @xmath100 implies that the agent imposes an exponentially smaller loss when declaring @xmath98 versus @xmath92 . in this case ,",
    "an arguably more appropriate modeling approach is to merge the hypothesis @xmath98 into another hypothesis . in assumption",
    "[ assumpt : loss ] , we assume that agent @xmath0 knows the loss function decay rates of the experts",
    ". this assumption may not hold in some practical applications , in which case we need to impose uncertainties on agent @xmath0 s knowledge about the experts , similar in spirit to @xcite .",
    "this unfortunately makes the problem much more challenging , and is out of the scope of our current work .",
    "the results in this work serve as the basic foundation on which the more challenging problem in which agent @xmath0 has limited knowledge of the experts , can be addressed in future research .",
    "consider two loss functions with loss decay rates @xmath101 and @xmath102 respectively .",
    "if @xmath101 and @xmath102 differ by the same constant for all @xmath91 and @xmath55 , then their corresponding loss exponents are different but the optimal policies to minimize are the same .",
    "we therefore say that two loss functions are _ asymptotically equivalent _ if their respective loss decay rates @xmath101 and @xmath102 differ by the same constant for all @xmath91 and @xmath55 .",
    "it can be shown that each loss function belongs to an equivalence class , with the equivalence relation being asymptotic equivalence .",
    "we call a loss function with @xmath103 a _ canonical loss function _ of its equivalence class . for example , the 0 - 1 loss function is a canonical loss function of its equivalence class . in another example , consider the set of all loss functions @xmath54 with @xmath104 for each @xmath91 and @xmath62 , which imposes a total loss of @xmath105 for each hypothesis . then , it can be shown that each of these loss functions is a canonical loss function .",
    "we say that two loss exponents are equivalent if they have the same policy and their loss functions are asymptotically equivalent .",
    "for fair comparison of loss exponents , we will always assume canonical loss functions .",
    "we are interested to characterize the optimal loss exponent , the loss exponent is _ negative _ , with a more negative loss exponent corresponding to a faster loss decay rate . ]",
    "@xmath106}},\\end{aligned}\\ ] ] when the number of private observations of agent @xmath0 becomes large .",
    "note that although agent @xmath0 is allowed an asymptotically large number of private observations , the quality of information available to agent @xmath0 is constrained by the set @xmath107 .",
    "the experts information sources @xmath108 are different from @xmath107 , and may thus improve the loss exponent of agent @xmath0 .",
    "we assume that for all experts @xmath109 , @xmath110 exists as a limit . if the number @xmath62 of private observations of expert @xmath35 is such that @xmath111 , agent @xmath0 will ignore the opinion of expert @xmath35 as its opinion becomes asymptotically negligible compared to agent @xmath0 s private observations .",
    "therefore , without loss of generality , we assume that @xmath112 for all @xmath51 .      in this subsection , we define notations that will be commonly used throughout the paper .",
    "we rely heavily on the mechanisms of large deviations theory to characterize the agents loss exponents and .",
    "we refer the reader to appendix [ appendix : mathematical ] for a brief overview of some basic concepts , and to @xcite for a detailed treatment of large deviations theory . as the theory of large deviations in hypothesis testing problems utilizes log moment generating functions of log likelihood ratios , and their fenchel - legendre transforms in order to characterize the loss exponents , we define these necessary quantities in the following . for any given random variable @xmath113 with marginal distribution @xmath114 under hypothesis @xmath115 , we abuse notation by letting @xmath116",
    "be the radon - nikodym derivative ( or likelihood ratio ) of @xmath114 w.r.t .",
    "note that @xmath116 is a random variable that depends on the distributions and realization of @xmath113 . by convention",
    ", we let @xmath118 for all values of @xmath19 and all realizations of @xmath113 . in addition , for simplicity , we let @xmath119 be the radon - nikodym derivative of @xmath120 w.r.t .",
    "@xmath121 , for each @xmath122 .",
    "let @xmath123 be a vector of log likelihood ratios , and the log moment generating function of @xmath124 under @xmath26 be @xmath125}},\\end{aligned}\\ ] ] for all @xmath126 .",
    "for a policy @xmath127)_{\\gamma\\in\\gamma_k}$ ] of an agent @xmath35 , the weighted log moment generating function is then given by @xmath128 \\xi_m(\\gamma , t),\\end{aligned}\\ ] ] and its fenchel - legendre transform @xcite is @xmath129 where @xmath10 .",
    "the function @xmath130 will be shown in theorem [ theorem : expert ] to characterize the rates of decay of the probabilities @xmath131 , similar to the rate functions in large deviations theory @xcite .",
    "when an expert @xmath35 s decision space has size @xmath132 , the rates of decay of the probabilities @xmath131 become easier to characterize since we can now interpret a decision @xmath55 of the expert @xmath35 to be in favor of hypothesis @xmath55 . then , under the true hypothesis @xmath26 , the log moment generating function of interest is the one involving the likelihood ratios of the observation distributions under hypothesis @xmath55 versus hypothesis @xmath91 , given by @xmath133 \\log { { \\mathbb{e}_{i}\\left[{(\\ell_{ji}^\\gamma)^s}\\right]}}.\\end{aligned}\\ ] ] the fenchel - legendre transform of @xmath134 is then given by @xmath135 where @xmath136 .",
    "we assume that the distributions @xmath137 , @xmath138 are well - behaved for all @xmath139 $ ] in the following assumption , which holds for example in the case where all conditional distributions are from the exponential families .",
    "this assumption is required in all our proofs in order to show that an agent s loss exponent can not be better than a certain achievable lower bound , which we characterize in order to derive the agent s optimal policy .",
    "[ assumption : xi ] for all @xmath139 $ ] and all @xmath140 , @xmath141 for all @xmath142 .",
    "if agent @xmath0 incorporates the opinion of expert @xmath35 , we expect the loss exponent of expert @xmath35 to determine how useful its opinion is to agent @xmath0 .",
    "therefore , we first find the loss exponent of each expert @xmath35 in theorem [ theorem : expert ] , which also provides an asymptotically optimal policy for expert @xmath35 . then",
    ", we proceed to determine the loss exponent of agent @xmath0 if it incorporates the opinion of a particular expert @xmath35 in theorem [ theorem : agent0 ] . to find the optimal expert ,",
    "we simply optimize the loss exponent found in theorem [ theorem : agent0 ] over the whole set of experts , which is essentially the content of theorem [ theorem : expert_choice ] .",
    "based on the conclusions of theorem [ theorem : expert_choice ] , we provide detailed procedures in remark [ rem : hardness ] of section [ subsect : choose ] that allow agent @xmath0 to compute its asymptotically optimal expert choice and policy .",
    "finally , we provide insights into the optimal expert choice under simplifying assumptions in propositions [ prop : expert_necessary ] and [ prop : bestexpertloss ] .",
    "in this section , we first characterize the loss exponents of the experts @xmath143 , which leads to an asymptotically optimal policy for each expert .",
    "we then characterize the loss exponent of agent @xmath0 , assuming that it is following the opinion of some expert @xmath35 .",
    "consider an expert @xmath35 , where @xmath144 . by conditioning on the observations @xmath30 $ ] , it can be shown ( proposition 2.3 of @xcite ) that the optimal decision rule for expert @xmath35 is given by @xmath145),\\end{aligned}\\ ] ] where @xmath146 ) = \\prod_{l=1}^{n_k } \\ell_{m0}(y_k[l])$ ] .",
    "in general , the right hand side of may have multiple minimizers . in order to avoid having to consider the use of randomization to determine the final decision for agent @xmath35 ( due to a mathematical technicality in the proof of theorem [ theorem : expert ] below ) , and for the ease of interpreting results",
    ", we will assume throughout this paper that the right hand side of has a unique solution with probability one .",
    "[ assumpt : unambiguous ] for every agent @xmath87 , and for any policy @xmath47 , the minimization on the right hand side of has a unique solution with probability one .",
    "assumption [ assumpt : unambiguous ] is satisfied if conditioned on any hypothesis @xmath147 , @xmath148 are continuous random variables with a joint probability density function . to see this , it can be shown via an easy inductive argument that @xmath149))_{m\\geq 1}$ ] are in turn continuous random variables under any hypothesis @xmath21 .",
    "assumption [ assumpt : unambiguous ] then follows by the same argument in lemma 5.1 of @xcite , which we refer the reader to .",
    "this shows that assumption [ assumpt : unambiguous ] holds in most practical applications as private observations are usually modeled as noisy , with the noise typically having a probability density function like the gaussian probability density @xcite .",
    "if agent @xmath0 follows expert @xmath35 , its loss exponent depends on the loss exponent of the expert @xmath35 , which is in turn related to the probability exponents @xmath150 where @xmath79 $ ] and @xmath151 $ ] . in the following ,",
    "our aim is to characterize the probability exponents .",
    "we use to characterize by first letting @xmath152 } , \\end{aligned}\\ ] ] and @xmath153 where @xmath154 , z[1 ] , \\ldots , z[m-1 ] ) \\in { \\mathbb{r}}^{m}$ ] .",
    "suppose that agent @xmath35 adopts the policy @xmath155 when it has access to @xmath62 private observations .",
    "then from and assumption [ assumpt : unambiguous ] , we obtain @xmath156 where @xmath157 ) \\right)_{m=1}^{m-1}\\end{aligned}\\ ] ] is a vector in @xmath158 of log likelihood ratios , and @xmath159 is the vector of log likelihood ratios augmented with @xmath0 as the first entry ( this corresponds to @xmath160 ) = 0 $ ] ) . in the following , we show that @xmath161 converges uniformly in @xmath8 to @xmath162 where @xmath163 - c_k(m , d ) \\}.\\end{aligned}\\ ] ]    [ lemma : f_uniform ] suppose that assumption [ assumpt : loss ] holds . for all @xmath87 , and all @xmath151 $ ] , @xmath164 and @xmath165 uniformly in @xmath166 as @xmath167 .",
    "see appendix [ appendix : proofs ] .",
    "we are now ready to present our first main result .",
    "since we are working in the regime of large @xmath62 , lemma [ lemma : f_uniform ] tells us that we can replace @xmath168 with @xmath169 in . for @xmath51 ,",
    "let @xmath170 the set @xmath171 can be interpreted as the asymptotic decision region for expert @xmath35 to declare decision @xmath55 based on its sufficient statistics @xmath172 ; see section [ subsect : adr ] for a discussion .",
    "assumption [ assumpt : unambiguous ] is required here to ensure that the sets @xmath173 $ ] are disjoint .    [",
    "theorem : expert ] suppose that assumptions [ assumpt : loss ] , [ assumption : xi ] , and [ assumpt : unambiguous ] hold .",
    "consider an agent @xmath174 who adopts a sequence of optimal policies @xmath175 that minimizes for each @xmath62 .",
    "then , we have the following :    a.   [ it : expert_opt ] the loss exponent of agent @xmath35 is given by @xmath176 } } = - \\max_{x \\in \\mathbb{s}(\\gamma_k ) } i_k(x ) ,      \\end{aligned}\\ ] ] where @xmath177 b.   [ it : policy_opt ] there is no loss in optimality asymptotically , if we restrict the sequence of policies @xmath175 such that @xmath178 , for some @xmath179 .",
    "c.   [ it : prob_exp ] let @xmath179 .",
    "for every @xmath139 $ ] , and @xmath151 $ ] , we have @xmath180    see appendix [ appendix : proofs ] .",
    "theorem [ theorem : expert ] allows each expert to find an asymptotically optimal policy by maximizing ( see remark [ rem : hardness ] in section [ subsect : choose ] ) .",
    "in addition , we will see later that theorem [ theorem : expert ] allows agent @xmath0 to characterize its own loss exponent and thus optimally choose the expert to follow .",
    "[ rem : ik ] the quantity @xmath181 in can be interpreted as the rate of loss decay for agent @xmath35 adopting policy @xmath20 , i.e. , for @xmath62 sufficiently large , we have @xmath182 } } \\approx g(n_k ) e^{-i_k(x ) } , \\end{aligned}\\ ] ] where @xmath183 is a function that decays faster than exponentially in @xmath62 . to achieve a smaller loss , agent",
    "@xmath35 then chooses a policy @xmath20 that maximizes @xmath181 .",
    "observe that @xmath181 is the minimization over all @xmath184 $ ] and @xmath185 $ ] of the terms @xmath186 , where @xmath187 is the absolute probability exponent in theorem [ theorem : expert ] , while @xmath101 is the loss function decay rate of declaring decision @xmath55 when the true hypothesis is @xmath91 .",
    "therefore , each term in the minimization of the right hand side of is the absolute decay rate of @xmath188 , and the overall loss exponent is dominated by the term that decays the slowest , which is what we expect from large deviations theory ( cf .",
    "lemma 1.2.15 of @xcite ) .",
    "we next provide an intuitive interpretation for the regions @xmath171 in the following subsection .",
    "suppose that agent @xmath109 adopts the sequence of policies @xmath189 as @xmath190 . from , for large @xmath62 , we have for each @xmath139 $ ] , and @xmath151 $ ] , @xmath191 where @xmath171 is as defined in , and @xmath192 can be interpreted as a rate function . in the same spirit as the grtner - ellis theorem @xcite , we can interpret the sets @xmath171 as the asymptotic decision region for deciding @xmath193 based on @xmath172 as @xmath190 , where the rate of decay of @xmath131 is dominated by the rate at a particular realization of @xmath172 in the region @xmath171 .",
    "we refer the reader to appendix [ appendix : ak_properties ] for a characterization of @xmath171 in terms of the union of intersections of multiple half - spaces .    in the following",
    ", we list some properties of the rate functions @xmath194 that will be useful in helping us to interpret our results .    [ lemma : phi_properties ] for every @xmath184 $ ] , @xmath130 is non - negative , convex in @xmath8 and concave in @xmath20 .",
    "furthermore , for any policy @xmath20 , @xmath195 , and the minimum is achieved at @xmath196 { { \\mathbb{e}_{m}\\left[{z^\\gamma}\\right]}},\\end{aligned}\\ ] ] where @xmath197 .",
    "see appendix [ appendix : proofs ] .    in particular ,",
    "if @xmath132 , and the loss function of agent @xmath35 adopting the policy @xmath47 is such that @xmath198 in for every @xmath91 , then we can interpret the decision @xmath91 of agent @xmath35 as in favor of hypothesis @xmath26 since @xmath199 is bounded away from 0 and has decay rate @xmath200 .      in the following ,",
    "we characterize the loss exponent of agent @xmath0 if it chooses expert @xmath35 .",
    "recall that @xmath110 .",
    "[ theorem : agent0 ] suppose that assumptions [ assumpt : loss ] , [ assumption : xi ] , and [ assumpt : unambiguous ] hold .",
    "suppose that agent @xmath0 adopts the opinion of expert @xmath201 , which has the asymptotically optimal policy @xmath202 .",
    "then , the loss exponent of agent @xmath0 is @xmath203 } } = - \\max_{x_0\\in\\mathbb{s}(\\gamma_0 ) } { \\mathcal{e}}_0(k , x_0),\\end{aligned}\\ ] ] where and @xmath204 be the minimization or maximization over all unordered pairs @xmath205 ^ 2 $ ] such that @xmath206 , respectively . ]",
    "@xmath207 } \\bigg\\",
    "{   ( 1-s)\\left(q_k\\inf_{z \\in a_k(d ) } \\phi_i^*(z , x_k^ * ) + c_0(i)\\right ) \\nonumber\\\\ & \\quad\\quad + s\\left(q_k\\inf_{z \\in a_k(d ) } \\phi_j^*(z , x_k^ * ) + c_0(j)\\right ) - \\lambda_{ij}(s , x_0 ) \\bigg\\}.\\end{aligned}\\ ] ]    see appendix [ appendix : proofs ] .",
    "following remark [ rem : ik ] , we can again interpret each term in the minimization on the right hand side of as the absolute error exponent incurred when differentiating between hypotheses @xmath19 and @xmath208 . from theorem [ theorem : expert ] and theorem [ theorem : agent0",
    "] , we see that the choice of an expert @xmath35 affects agent @xmath0 s loss exponent through the rate of decay of the probabilities @xmath209 and @xmath210 , which is to be expected . in particular , if the loss function of the expert @xmath35 is such that we can interpret the decision @xmath55 of the expert as in favor of hypothesis @xmath55 , then @xmath211 yields @xmath212 , and it does not contribute to the decay of the expected loss of agent 0 .",
    "we now address the question of how to choose an optimal expert for agent @xmath0 .",
    "we first revisit theorem [ theorem : agent0 ] to derive the optimal loss exponent for agent @xmath0 , and then we make additional simplifying assumptions in order to provide more insights into our results . finally , we discuss a numerical example to illustrate the use of our optimal loss exponent characterizations in finding the optimal policies and expert choice .",
    "if agent @xmath0 does not incorporate the opinion of any expert , we use the notation @xmath213 to denote its absolute loss exponent when using policy @xmath214 . from theorem [",
    "theorem : agent0 ] , by setting @xmath215 , we have @xmath216 } \\left\\ {    ( 1-s)c_0(i ) + sc_0(j ) - \\lambda_{ij}(s , x_0 ) \\right\\}.\\end{aligned}\\ ] ] in the case of minimizing the error probability at agent @xmath0 with 0 - 1 loss function , and without the help of any experts , we can further set @xmath217 to obtain the absolute error exponent @xmath218 } \\lambda_{ij}(s , x_0),\\end{aligned}\\ ] ] which recovers the result in @xcite .",
    "similarly , if agent @xmath0 chooses expert @xmath35 , and adopts the 0 - 1 loss function , we let its absolute loss exponent be    _ 0,b(k , x_0 ) = _ _ s \\ { ( 1-s)q_k_z a_k(d ) _",
    "i^*(z , x_k^ * ) + sq_k_z a_k(d ) _",
    "j^*(z , x_k^ * ) - _ ij(s , x_0 ) } .",
    "the following proposition follows immediately from theorem [ theorem : agent0 ] , and provides a method for agent @xmath0 to optimally choose which expert to follow .",
    "[ theorem : expert_choice ] suppose that assumptions [ assumpt : loss ] , [ assumption : xi ] , and [ assumpt : unambiguous ] hold .",
    "the optimal loss exponent of agent @xmath0 is    _",
    "1kk_n_0 = -_1k k _",
    "x_0(_0 ) _ 0(k , x_0 ) .    furthermore , for any @xmath201 and policy @xmath214 , we have @xmath219    see appendix [ appendix : proofs ] .",
    "[ rem : hardness ] theorem [ theorem : expert_choice ] shows that agent @xmath0 should choose an expert @xmath35 that maximizes @xmath220 , which depends on @xmath221 , for @xmath184 $ ] and @xmath185 $ ] .",
    "we now discuss procedures that can achieve this , depending on the amount of information that agent @xmath0 has about the experts :    a.   [ it : probexp ] if the experts probability exponents @xmath222,d\\in[0,d_k-1]\\}$ ] for all @xmath51 are publicized , then agent @xmath0 simply needs to find its optimal policy @xmath214 that maximizes @xmath223 in theorem [ theorem : expert_choice ] for each @xmath35 , and choose the expert that produces the largest @xmath220 . to find the optimal policy @xmath214 corresponding to an expert @xmath35",
    ", we can use an iterative procedure as follows : 1 .   an initial guess for the optimal policy @xmath224",
    "set @xmath225 .",
    "[ step : s ] for each pair @xmath226 $ ] , @xmath206 , and @xmath185 $ ] , find @xmath227 that is the maximizer of the optimization problem over @xmath228 $ ] on the right hand side of .",
    "note that this is equivalent to a convex minimization problem , which can be solved via standard convex optimization methods @xcite .",
    "[ step : x0 ] find @xmath229)_{\\gamma\\in\\gamma_0}$ ] by solving the linear program : @xmath230)_{\\gamma\\in\\gamma_0 } } \\quad r \\\\          & \\textrm{subject to } \\\\",
    "& r \\leq ( 1-s_{ijd}(l))\\left(q_k\\inf_{z \\in a_k(d ) } \\phi_i^*(z , x_k^ * ) + c_0(i)\\right ) \\\\          &",
    "\\quad\\quad + s_{ijd}(l ) \\left(q_k\\inf_{z \\in a_k(d ) } \\phi_j^*(z , x_k^ * ) + c_0(j)\\right ) \\\\               & \\qquad - \\sum_{\\gamma\\in\\gamma_0 } x[\\gamma ] \\log { { \\mathbb{e}_{i}\\left[{(\\ell_{ji}^\\gamma)^{s_{ijd}}}\\right ] } } , \\\\          & \\qquad \\forall i , j \\in[0,m-1 ] , i\\ne j , \\forall d\\in[0,d_k-1 ] , \\\\          & x[\\gamma ] \\geq 0 , \\ \\forall \\gamma\\in\\gamma_0,\\\\          & \\sum_{\\gamma\\in\\gamma_0 } x[\\gamma ] = 1 .          \\end{aligned}\\ ] ] 4 .",
    "set @xmath231 and repeat steps 2 - 4 till @xmath232 does not change significantly .",
    "b.   [ it : lossandpolicy ] if agent @xmath0 knows only the experts loss functions and optimal policies @xmath202 for all @xmath201 , then it can compute @xmath221 for all @xmath184 $ ] and @xmath185 $ ] by searching for the minimum of @xmath233 on the boundaries of @xmath171 , if @xmath234 in is not in @xmath171 .",
    "this is because @xmath233 is convex in @xmath8 ( cf .",
    "lemma [ lemma : phi_properties ] ) , and the search can be performed using standard convex optimization methods @xcite .",
    "the boundaries of @xmath171 can be found through its characterization in appendix [ appendix : ak_properties ] ( see section [ subsection : numerical ] for an example ) . if @xmath235 , then from lemma [ lemma : phi_properties ] , we obtain @xmath236 .",
    "once the experts probability exponents have been computed , the same procedure as in item above can now be used to choose the optimal expert .",
    "c.   [ it :",
    "lossonly ] if agent @xmath0 knows only the experts loss functions , it can utilize theorem [ theorem : expert ] to determine the policy that each expert adopts .",
    "this however may not be an easy numerical procedure if @xmath1 and @xmath63 are large , even in the case where the expert has 0 - 1 loss function @xcite .",
    "we propose the following alternating optimization approach for finding the optimal policy of expert @xmath35 : 1 .",
    "an initial guess for the optimal policy @xmath237 is made .",
    "set @xmath225 .",
    "[ step : t ] for each @xmath184 $ ] and @xmath185 $ ] , find @xmath238 .",
    "as noted in item above , this can be obtained via standard convex optimization methods .",
    "let + t_m , d(l ) ) _ t^m-1 \\ { t , z_m , d(l-1 ) - _ m(t , x_k^*(l))}. 3 .",
    "[ step : x ] find @xmath239)_{\\gamma\\in\\gamma_k}$ ] by solving the linear program @xmath230)_{\\gamma\\in\\gamma_k } } \\quad r \\\\          & \\textrm{subject to } \\\\",
    "& r \\leq { { \\left\\langle t_{m , d}(l ) , z_{m , d}(l ) \\right\\rangle } } \\\\          & \\qquad - \\sum_{\\gamma\\in\\gamma_k } x[\\gamma ] \\xi_m(\\gamma , t_{m , d}(l ) ) + c_k(m , d),\\\\          & \\qquad \\forall m\\in[0,m-1 ] , \\forall d\\in[0,d_k-1 ] , \\\\          & x[\\gamma ] \\geq 0 , \\ \\forall \\gamma\\in\\gamma_k,\\\\          & \\sum_{\\gamma\\in\\gamma_k } x[\\gamma ] = 1 .",
    "\\end{aligned}\\ ] ] 4 .",
    "set @xmath231 and repeat steps 2 - 4 till @xmath240 does not change significantly .",
    "+ unfortunately , there is no guarantee that the above procedure converges to the correct solution .",
    "however , in our numerical experiments , we were able to arrive at the correct optimal policy by using multiple initial guesses .",
    "a numerical example is presented in section [ subsection : numerical ] .",
    "[ rem : worstloss ] the first inequality in shows that there is no loss in optimality for agent @xmath0 to incorporate the opinion of any expert , verifying the adage that there is no harm in having more information .",
    "however , incorporating additional information does not necessarily improve its loss exponent ; see proposition [ prop : expert_necessary ] .",
    "the inequality in shows that of all the loss functions satisfying assumption [ assumpt : loss ] , the 0 - 1 loss is the worst canonical loss function for agent @xmath0 . in particular , consider the set of loss functions with @xmath241 for all @xmath184 $ ] and @xmath61 , where the limit @xmath242 exists .",
    "furthermore , each loss function has a total cost constraint , @xmath243 it can be shown that all such loss functions satisfy assumption [ assumpt : loss ] , and are canonical loss functions .",
    "the 0 - 1 loss function belongs to this set , and divides the total cost equally among all types of missed detections , which results in the worst loss exponent for agent @xmath0 .",
    "this can be explained intuitively by observing that if there exists a @xmath91 such that @xmath244 , then missed detection of @xmath26 incurs an exponentially decaying loss , so that the hypothesis @xmath91 can effectively be ignored .",
    "agent @xmath0 then effectively has a smaller set of hypotheses , leading to a lower expected loss .",
    "[ remark : multiexperts ] it is easy to generalize theorem [ theorem : agent0 ] or theorem [ theorem : expert_choice ] to the case where more than one agent can be chosen . in particular ,",
    "if all @xmath2 experts opinions are adopted by agent @xmath0 , theorem [ theorem : agent0 ] holds with @xmath223 replaced by @xmath245 } \\bigg\\ {   ( 1-s)\\left(\\sum_{k=1}^k q_k \\inf_{z \\in",
    "a_k(p_k ) } \\phi_i^*(z , x_k^ * ) + c_0(i)\\right ) \\nonumber\\\\ & \\quad\\quad + s\\left(\\sum_{k=1}^k q_k\\inf_{z \\in a_k(p_k ) } \\phi_j^*(z , x_k^ * ) + c_0(j)\\right ) - \\lambda_{ij}(s , x_0 ) \\bigg\\}\\end{aligned}\\ ] ] where the sequences @xmath246 $ ] .    in the following subsection",
    ", we consider the special cases where the size of each expert s decision space is less than or equal to @xmath1 under additional simplifying assumptions .      in this section , we assume that agent @xmath0 s policy has been fixed in advance .",
    "we first consider the case where an expert @xmath35 may have a decision space smaller than the number of hypotheses @xmath1 that agent @xmath0 has .",
    "to state our results , suppose that agent @xmath0 adopts policy @xmath214 and has loss decay rates given by the function @xmath247 .",
    "we define the _ loss augmented _ log moment generating function for @xmath248 $ ] as @xmath249 for the case where agent @xmath0 adopts the 0 - 1 loss function , we have @xmath250 for all @xmath19 .",
    "we observe that in this case , the chernoff information @xmath251}\\lambda_{ij}(s , x_0)$ ] tells us how well hypothesis @xmath19 can be differentiated from hypothesis @xmath208 , where a larger chernoff information corresponds to a faster error probability decay @xcite .",
    "this leads us to the following general definition : for a given policy @xmath214 , if there exists a constant @xmath252 so that @xmath253}{{\\overline{\\lambda}}}_{ij}(s , x_0,c_0 ) = \\alpha$ ] for all @xmath206 , we say that the policy @xmath214 is _ hypothesis - loss neutral _ for agent @xmath0 .    intuitively , a policy is hypothesis - loss neutral if it can differentiate any pair of hypotheses equally well when adjusted for the agent s `` biases '' . it may be argued that in practical scenarios , an agent would strive to be hypothesis - loss neutral , since otherwise there are hypotheses that are relatively less important than others , and can be dropped . in the following ,",
    "we show that if agent @xmath0 is hypothesis - loss neutral , an expert s opinion is useless if it does not have a decision space as large as @xmath1 .",
    "[ prop : expert_necessary ] suppose that assumptions [ assumpt : loss ] , [ assumption : xi ] , and [ assumpt : unambiguous ] hold .",
    "suppose that agent @xmath0 adopts a policy @xmath214 that is hypothesis - loss neutral .",
    "then , for any agent @xmath201 , if @xmath254 , we have @xmath255 , i.e. , agent @xmath0 ignores the opinion of agent @xmath35 .",
    "see appendix [ appendix : proofs ] .",
    "proposition [ prop : expert_necessary ] can be explained intuitively as follows in the case where agent 0 has 0 - 1 loss function .",
    "if an expert @xmath35 has @xmath254 , then there exists two hypotheses @xmath19 and @xmath208 of agent @xmath0 that it does not discriminate between .",
    "the probability of making an error between these two hypotheses by the expert is therefore one , and the expert s opinion does not help agent @xmath0 to differentiate between hypotheses @xmath19 and @xmath208 .",
    "the error probability of agent @xmath0 declaring @xmath115 when the true hypothesis is @xmath256 or vice versa , thus dominates when agent @xmath0 is hypothesis - loss neutral , and is the same as when agent @xmath0 ignores the expert s opinion .",
    "we next consider the case where experts have the same decision space as agent @xmath0 , and has zero loss if they decide on the true underlying hypothesis .",
    "we also make the following simplifying assumption .",
    "[ assumpt : bayesian2 ] every agent @xmath49 has @xmath257 , with loss decay rates @xmath258 where @xmath259 for all @xmath184 $ ] .",
    "[ prop : bestexpertloss ] suppose that assumptions [ assumpt : loss]-[assumpt : bayesian2 ] hold .",
    "suppose that agent @xmath0 adopts policy @xmath214 , and follows the opinion of expert @xmath51 , who adopts the policy @xmath47 .",
    "then , the loss exponent of agent @xmath0 is @xmath260 } } = - \\tilde{\\mathcal{e}}_0(k , x_0),\\end{aligned}\\ ] ] where means minimization over all _ ordered _ pairs @xmath261 with @xmath248 $ ] and @xmath206 . ]",
    "_ 0(k , x_0 ) = _ i , j : ij_s \\ { sq_k ^*_ji(c_k(i)-c_k(j),x_k ) - _ ij(s , x_0,c_0 ) } .",
    "in addition , if for some @xmath206 such that @xmath262 , and @xmath263,\\end{aligned}\\ ] ] then there is no loss in optimality for agent 0 to restrict to experts @xmath35 with canonical loss functions satisfying @xmath264 .    see appendix [ appendix : proofs ] .    surprisingly , proposition [ prop : bestexpertloss ] shows that it is not necessarily optimal for agent @xmath0 to choose an expert who utilizes the same canonical loss function as itself since agent @xmath0 s loss exponent depends only on the relative differences in agent @xmath35 s loss function at each hypothesis .",
    "we show a numerical example of this phenomenon in section [ subsection : numerical ] below . in particular , if agent @xmath0 adopts the 0 - 1 loss function , and does not hold for some @xmath206 , then an example can be constructed in which an expert with a loss function different from the 0 - 1 loss is optimal for agent @xmath0 .    on the other hand ,",
    "if agent @xmath0 is `` unbiased '' ( in terms of loss ) towards a pair of hypotheses @xmath261 and holds , proposition [ prop : bestexpertloss ] tells us that it is optimal for agent @xmath0 to choose an expert , if any , who is also `` unbiased '' towards hypotheses @xmath261 .",
    "this indicates that if agent @xmath0 has the same discriminatory power for a particular pair of hypotheses ( which is the intuitive meaning of ) , then it values information from an `` unbiased '' expert more than one who has the same `` bias '' as itself .",
    "assuming that independent news agencies are in general `` unbiased , '' our result suggests that such news agencies are unlikely to be replaced by social news reporting or social blogs .",
    "the following corollary follows immediately from proposition [ prop : bestexpertloss ] .",
    "[ cor:01loss ] suppose that assumptions [ assumpt : loss]-[assumpt : bayesian2 ] hold .",
    "suppose that agent @xmath0 adopts policy @xmath214 , and has 0 - 1 loss function .",
    "if for every distinct pair of hypotheses @xmath261 , holds , then it is optimal for agent @xmath0 to choose an expert , if any , who also has the 0 - 1 loss function .      in this section",
    ", we present a numerical example to illustrate our results .",
    "suppose that @xmath265 , there are 3 experts to choose from , and all agents have access to private observations from two information sources @xmath266 , whose conditional distributions are shown in table [ table : information_sources ] .",
    "we use the notation @xmath267 to denote the normal distribution with mean @xmath268 and variance @xmath269 .",
    "for example , the three hypotheses can correspond to the financial health of a company being `` bad '' , `` neutral '' , and `` good '' respectively .",
    "the information source @xmath270 represents a view that tends to be optimistic when the true health of the company is `` neutral '' , while @xmath271 represents a view that tends to be pessimistic .",
    ".conditional distributions of the information sources .",
    "[ cols=\"^,^,^\",options=\"header \" , ]     [ table : optimal policies ]    for experts 1 and 3 , their optimal policies are both given by @xmath272=x_1[\\gamma_2]=0.5 $ ] , as is expected from the symmetry of the problem .",
    "for expert 2 , its optimal policy is given by @xmath273=1 $ ] and @xmath274=0 $ ] .",
    "this is because with a positive loss decay rate @xmath275 , expert 2 puts exponentially less loss on confusing hypothesis 2 for the others , therefore it chooses @xmath270 as its sole information source .",
    "for the alternating optimization procedure , we started our initial guesses at @xmath276 , x[\\gamma_2 ] ) = ( 0,1)$ ] and @xmath277 .",
    ", this was not selected in order to test the convergence for experts 1 and 3 .",
    "] we repeated the procedure for different values of @xmath278 . in all cases",
    ", we were able to find the correct optimal policies within 22 iterations ( totaled over the two runs corresponding to the two initial guesses ) , as shown in figure [ fig : delta ] .",
    "in some cases however , the procedure does not converge to the correct optimal policy if we restrict ourselves to the single initial guess @xmath276 , x[\\gamma_2 ] ) = ( 0,1)$ ] .",
    "this shows that the proposed procedure can get stuck at a suboptimal policy .",
    "we next suppose that @xmath279 , and use the procedure in remark [ rem : hardness ] item to obtain the optimal policy for agent @xmath0 w.r.t .",
    "each expert @xmath280 , when @xmath281 .",
    "we found the optimal policies for agent @xmath0 within 4 iterations in each case , and that choosing expert 2 produces the best loss exponent for agent @xmath0 , as shown in table [ table : optimal policies ] . in this case , it is not optimal for agent @xmath0 to choose expert 3 , which has the same loss function as itself .",
    "observe that even if agent @xmath0 s policy is fixed at @xmath282 , it will still prefer expert 1 over expert 3 . on the other hand , if @xmath283 , we have @xmath284 , i.e. , agent @xmath0 s optimal expert choice is expert 1 .",
    "it can be shown that holds for all pairs of hypotheses in this example , thus verifying corollary [ cor:01loss ] .",
    "we have studied a multihypothesis social learning problem in which an agent makes a decision with the help of a chosen expert .",
    "we have considered a general framework that allows the agent and experts to have different loss functions ( biases ) , and different decision spaces .",
    "we have characterized the loss exponent of the agent in terms of the chosen expert s probability error exponent , which allows us to choose the asymptotically optimal expert as well as the agent s policy .",
    "we have shown that if the experts have the same decision space as the agent , then it is not necessarily optimal for the agent to choose an expert with the same loss function as itself . moreover ,",
    "if the agent is hypothesis - loss neutral , then it ignores any expert with a decision space smaller than the number of hypotheses .",
    "the results in this paper are limited by our setup and assumptions , which however allows us to obtain analytical characterizations of the asymptotically optimal policies for the agent and experts , and an asymptotically optimal expert choice . in the regime of a finite number of private observations ,",
    "these policies are in general sub - optimal .",
    "finding the exact optimal policies in this regime is however analytically difficult , and the asymptotically optimal policies can be utilized when the numbers of private observations are large . in this paper , we have assumed that the agent knows the experts loss decay rates , which may not be valid in some practical scenarios .",
    "for example , expert opinions may very well depend on the mood of the expert at the time the opinion is publicized .",
    "therefore , it is of interest to consider minimax loss exponents in which the expert s loss function or observation probability distributions are drawn from uncertainty classes .",
    "minimax decentralized hypothesis testing has been studied in @xcite , and in our recent work @xcite in which we consider robust social learning in a tandem network . however",
    ", additional research in minimax decentralized hypothesis testing is required to address more complex network architectures and applications like that considered in this paper .",
    "in this appendix , we briefly review some basic definitions and a result from large deviations theory .",
    "the reader is referred to @xcite for details .",
    "the notation @xmath285 denotes the trace of the matrix @xmath286 , @xmath287 is the gradient of @xmath288 w.r.t .  the vector @xmath7 , and @xmath289 is the hessian w.r.t .",
    "@xmath7 of the function @xmath288 .",
    "let @xmath290 be a polish space .",
    "the function @xmath291 $ ] is said to be a good rate function if @xmath292 is lower semicontinuous and has compact level sets @xmath293 for all @xmath294 .",
    "let @xmath295 be a sequence of probability measures on @xmath290 .",
    "this sequence of probability measures is said to satisfy a _ large deviation principle _",
    "( ldp ) if for some good rate function @xmath292 , and for all closed sets @xmath296 , we have @xmath297 and for all open sets @xmath298 , we have @xmath299 a sequence of random variables @xmath300 is said to satisfy a ldp if the sequence of marginal distributions @xmath301 satisfies a ldp .",
    "the celebrated grtner - ellis theorem @xcite provides sufficient conditions for a sequence of random variables to satisfy a ldp . in the following , we present a partial version of the grtner - ellis theorem",
    "let @xmath302 be a sequence of @xmath158-valued random variables , so that @xmath303}}\\end{aligned}\\ ] ] exists .",
    "let @xmath304 be the fenchel - legendre transform of @xmath305 . then , under the assumptions in theorem 2.3.6 of @xcite , the ldp holds with good rate function @xmath306 .    when not all the conditions required by the grtner - ellis theorem hold ( as is the case in some of our proofs ) , we instead make use of a _ uniform _ lower bound given by the following lemma , which is a generalization of theorem 1.3.13 of @xcite . the proof is omitted here for brevity .",
    "[ lemma : ldp_lowerbound ] let @xmath307 be independent @xmath158-valued random variables , with @xmath308 $ ] fraction of them having distribution @xmath309 , for each @xmath310 .",
    "let @xmath124 have distribution @xmath309 , @xmath311 \\log { { \\mathbb{e}\\left[{\\exp({{\\left\\langle t , z^\\gamma \\right\\rangle}})}\\right]}},\\end{aligned}\\ ] ] and @xmath312 suppose that @xmath313 } } < \\infty$ ] for all @xmath314 , then for @xmath315 such that @xmath316 , and any @xmath317 , we have     ( _ l=1^n z_l b_(z ) ) - ^*(z ) - t_z + ( 1 ( _ t^2 ( t_z ) ) ) .    in this paper , we apply lemma [ lemma : ldp_lowerbound ] in cases where @xmath305 corresponds to @xmath318 in",
    ". we will often need to further lower bound by finding an upper bound for @xmath319 that does not depend on @xmath3 or the particular policy adopted by an agent .",
    "assumption [ assumption : xi ] implies an upper bound for @xmath320 , as shown in the following elementary lemma .",
    "[ lemma : bounded_trace ] suppose that assumption [ assumption : xi ] holds .",
    "then there exists a non - decreasing function @xmath321 , finite for each @xmath322 , such that for all @xmath323 , and all @xmath122 , we have for all @xmath324 , @xmath325    the lower inequality in holds because @xmath326 is convex in @xmath7 for each @xmath327 ( see lemma 2.2.31 of @xcite ) .",
    "furthermore , we can define @xmath328 which is finite because of assumption [ assumption : xi ] , and the fact that @xmath329 is continuous on the compact set @xmath330 .",
    "the proof of the lemma is now complete .",
    "let @xmath331 be a positive number . from assumption [ assumpt : loss ] , for @xmath3 sufficiently large , we have @xmath332 , @xmath333 , and @xmath334 for all @xmath79 $ ] .",
    "this implies that for all @xmath335 , we have @xmath336\\ } + { { \\frac{1}{n } } } \\log m \\\\ & \\leq \\max_{m } \\{-c_k(m , d ) + z[m]\\ } + \\epsilon \\\\ & = \\tilde{f}_k(z , d ) + \\epsilon,\\end{aligned}\\ ] ] and @xmath337 \\right\\ } + \\min_m \\frac{\\log \\pi_m}{n } \\\\ & \\geq    \\max_{m } \\{-c_k(m , d ) + z[m]\\ } - \\epsilon\\\\ & = \\tilde{f}_k(z , d ) - \\epsilon,\\end{aligned}\\ ] ] which shows that @xmath164 uniformly in @xmath8 . since the minimum of a finite set of uniformly convergent functions is also uniformly convergent , the lemma follows .",
    "we prove claim of theorem [ theorem : expert ] by first deriving a lower bound for the loss exponent of agent @xmath35 , and showing that this bound is achievable .",
    "we have for any @xmath317 , and @xmath62 sufficiently large , @xmath338 } } \\nonumber\\\\ & = { { \\frac{1}{n_k } } } \\log \\sum_{m=0}^{m-1 } \\sum_{d=0}^{d_k-1 } \\pi_m c_k(m , d , n_k ) { \\mathbb{p}}_m(d_k = d ) \\nonumber\\\\ & \\geq \\max_{\\substack{0\\leq",
    "m \\leq m-1 \\\\ 0\\leq d \\leq d_k-1 } } \\left\\ { { { \\frac{1}{n_k } } } \\log c_k(m , d , n_k ) + { { \\frac{1}{n_k } } } \\log{\\mathbb{p}}_m(d_k = d ) \\right\\}\\nonumber\\\\ & \\qquad\\qquad +   \\min_m{{\\frac{1}{n_k } } } \\log \\pi_m \\nonumber\\\\ & \\geq \\max_{\\substack{0\\leq m \\leq m-1 \\\\ 0\\leq d \\leq d_k-1 } } \\left\\ { { { \\frac{1}{n_k } } } \\log{\\mathbb{p}}_m(d_k = d ) -c_k(m , d)\\right\\ } - \\epsilon , \\label{ck_lowerbound}\\end{aligned}\\ ] ] which can be further lower bounded by lower bounds on the probability exponents . for each @xmath10 ,",
    "let @xmath315 be the solution to the equation @xmath339 if the solution exists .",
    "for each @xmath340 , let @xmath341 , and @xmath342 . from and",
    ", we then have for any @xmath343 , @xmath344 ) \\nonumber\\\\ & \\geq { { \\frac{1}{n_k } } } \\log{\\mathbb{p}}_m(f_k(\\bar{z}_{n_k}^0(x_{k , n_k } ) , d ) \\in [ u-\\frac{\\epsilon}{2},u+\\frac{\\epsilon}{2 } ] ) \\nonumber\\end{aligned}\\ ] ] where the last inequality follows from lemma [ lemma : f_uniform ] for @xmath62 sufficiently large . is required in , without which we need to replace @xmath345 with @xmath346 if expert @xmath35 uses randomization to produce its final decision .",
    "the second term in the maximization unfortunately can not be characterized using our existing approach . ]",
    "since @xmath343 is arbitrary , we obtain for @xmath62 sufficiently large , @xmath347 where @xmath348 is an open sphere of radius @xmath331 around @xmath8 . from lemma [ lemma :",
    "ldp_lowerbound ] , we can further lower bound the right hand side of to obtain @xmath349 where the last inequality follows from lemma [ lemma : bounded_trace ] . combining with , and letting @xmath190 , and then taking @xmath350 and @xmath351",
    ", we have @xmath352 } } & \\geq - \\sup_{x \\in \\mathbb{s}(\\gamma_k ) } i_k(x ) .",
    "\\label{ck_lowerbound2}\\end{aligned}\\ ] ]    since @xmath130 is continuous in @xmath20 , @xmath353 is upper semi - continuous in @xmath20 , and @xmath181 is upper semi - continuous in @xmath20 . in addition",
    ", @xmath48 is compact , therefore the supremum over @xmath20 on the right hand side of is a maximization .",
    "consider the policy @xmath354 .",
    "for each @xmath355 , let agent @xmath35 use the policy @xmath155 where @xmath356 = { { \\lfloor { x_k^*[\\gamma ] n_k } \\rfloor}}/n_k$ ] for all @xmath36 , and if @xmath356 $ ] do not sum to 1 over @xmath36 , we simply choose the remaining private observations from an arbitrary distribution , and ignore them when making the decision for agent @xmath35 .",
    "we have @xmath357 as @xmath190 .",
    "we first show a simple lemma .",
    "[ lemma : ldp_z ] suppose that assumption [ assumption : xi ] holds , agent @xmath35 adopts the policy @xmath358)_{\\gamma\\in\\gamma_k}$ ] when it has access to @xmath62 private observations , and @xmath359 as @xmath360 .",
    "then , the sequence of random variables @xmath361 defined in satisfies a ldp under hypothesis @xmath26 , for every @xmath139 $ ] , with good rate function @xmath362 .",
    "we apply the grtner - ellis theorem @xcite to prove the lemma .",
    "let @xmath363))_{m=1}^{m-1}$ ] .",
    "we have @xmath364 since @xmath365 are independent . for every @xmath142 , we obtain @xmath366 } } \\\\ & = { { \\frac{1}{n_k } } } \\log { { \\mathbb{e}_{m}\\left[{\\exp\\left(\\big\\langle t , \\sum_{i=1}^{n_k } z_i \\big\\rangle \\right)}\\right ] } } \\\\ & = { { \\frac{1}{n_k } } } \\sum_{i=1}^{n_k } \\log { { \\mathbb{e}_{m}\\left[{\\exp\\left({{\\left\\langle t , z_i \\right\\rangle}}\\right)}\\right ] } } \\\\ & = \\sum_{\\gamma\\in\\gamma_k } x_{k , n_k}[\\gamma ] \\log { { \\mathbb{e}_{m}\\left[{\\exp\\left({{\\left\\langle t , ( \\log\\ell_{m0}^\\gamma)_{m=1}^{m-1 } \\right\\rangle}}\\right)}\\right ] } } \\\\ & \\to \\varphi_m(t , x_{k}),\\end{aligned}\\ ] ] as @xmath360 . from assumption [ assumption : xi ] and lemma 2.3.9 of @xcite , we have @xmath367 is a good rate function , and the lemma follows from the grtner - ellis theorem .    from lemma [ lemma : f_uniform ] , we have for each @xmath151 $ ] , @xmath368 and applying theorem 4.2.23 of @xcite , we obtain from and lemma [ lemma : ldp_z ] that @xmath369 we then have @xmath370 } } \\nonumber\\\\ & \\leq \\limsup_{n_k\\to\\infty } \\max_{\\substack{0\\leq",
    "m \\leq m-1 \\\\ 0\\leq d \\leq d_k-1 } } \\left\\{{{\\frac{1}{n_k } } } \\log{\\mathbb{p}}_m(d_k = d ) -c_k(m , d ) \\right\\ } \\nonumber\\\\ & \\leq   -i_k(x_k^ * ) , \\label{ck_upperbound}\\end{aligned}\\ ] ] where the last inequality follows from .",
    "finally , together with gives us claim .    to show claim , fix any @xmath179 .",
    "we note that if there exists a subsequence of policies @xmath371 with @xmath372 and @xmath373 , then using the same arguments that lead to , we have @xmath352 } } & \\geq -   i_k(x_k ) > - i_k(x_k^*),\\end{aligned}\\ ] ] a contradiction to . therefore",
    ", each policy subsequence converges to some @xmath47 with @xmath374 , and there is no loss in optimality if we restrict the sequence of policies to converge to @xmath202 .",
    "finally , to show claim , we have from that @xmath375 since @xmath130 is continuous in @xmath20 . together with , the claim now follows , and the theorem is proved .",
    "the non - negativity and convexity of @xmath376 follows from lemma 2.2.31 of @xcite . from jensen s inequality , for any @xmath142 ,",
    "we have @xmath377 { { \\mathbb{e}_{m}\\left[{{{\\left\\langle t , z^\\gamma \\right\\rangle}}}\\right ] } } = { { \\left\\langle t , \\tilde{z}_m(x ) \\right\\rangle}},\\end{aligned}\\ ] ] which implies that @xmath378 , and the lemma is proved .",
    "we first present a generalization of theorem 5 of @xcite ( see also @xcite for a slightly more updated version ) .",
    "the proof steps are similar to that in @xcite and @xcite , and are provided below for completeness .    [",
    "prop : d0_lowerbound ] suppose that assumptions [ assumpt : loss ] and [ assumption : xi ] hold , and agent @xmath0 adopts the opinion of agent @xmath51 and policy @xmath214 .",
    "let @xmath379 } \\left\\{\\frac{s}{n_0 } \\log \\frac{c_0(i , j , n_0){\\mathbb{p}}_i(d_k = d)}{c_0(j , i , n_0){\\mathbb{p}}_j(d_k = d ) } - \\lambda_{ij}(s , x_0)\\right\\}\\end{aligned}\\ ] ] where @xmath380 is as defined in .",
    "then , for any @xmath317 , and any @xmath151 $ ] , there exists @xmath3 such that for all @xmath381 , we have for all @xmath206 , @xmath382    from theorem 5 of @xcite ( or proposition a.2 of @xcite ) , we have for @xmath383 $ ] , with @xmath384 , and every @xmath385 $ ] , either    _i(d_0(k ) i d_k",
    "d ) ( n_0_ij(s , x_0 ) s n_0_ij(s , x_0 ) - s  ) ,    or    _j(d_0(k ) i d_k d ) ( n_0_ij(s , x_0 ) ( 1 s)n_0_ij(s , x_0 ) - ( 1-s )  ) .",
    "if @xmath386 , we have @xmath387 and using lemma [ lemma : bounded_trace ] , and , we obtain @xmath388 where the last inequality follows from assumption [ assumpt : loss ] for @xmath77 sufficiently large . on the other hand , if @xmath389 , we have @xmath390 since @xmath391 is convex @xmath392 .",
    "the inequality then holds trivially .",
    "a similar argument holds for @xmath393 , and the proposition is proved .",
    "we next proceed to prove theorem [ theorem : agent0 ] .",
    "suppose that agent @xmath0 adopts the policy @xmath214 .",
    "for any @xmath317 , and for @xmath77 sufficiently large , we have @xmath394 } } \\nonumber\\\\ & = { { \\frac{1}{n_0}}}\\log \\sum_{d=0}^{d_k-1 } \\sum_{i\\ne j } \\pi_i c_0(i , j , n_0){\\mathbb{p}}_i(d_0(k)=j , d_k = d ) \\nonumber\\\\ & \\geq\\hspace{-8pt } \\max_{\\substack{i\\ne j \\\\ 0\\leq d \\leq d_k-1 } } \\hspace{-8pt}{{\\frac{1}{n_0}}}\\log\\left\\ {   \\begin{array}{cc } \\min_{j ' :",
    "j'\\ne i } c_0(i , j',n_0 ) \\\\",
    "\\qquad \\cdot { \\mathbb{p}}_i(d_0(k ) \\ne i , d_k = d)\\\\ + c_0(j , i , n_0){\\mathbb{p}}_j(d_0(k)=i , d_k = d ) \\end{array } \\right\\ } \\nonumber\\\\   & \\qquad - { { \\frac{1}{n_0}}}\\log 2 + \\min_m { { \\frac{1}{n_0 } } } \\log \\pi_m \\nonumber\\\\ & \\geq \\max_{\\substack{i\\ne j \\\\ 0\\leq d \\leq d_k-1 } } \\min_{s\\in [ 0,1 ] } \\big\\ { ( 1-s)\\left({{\\frac{1}{n_0}}}\\log{\\mathbb{p}}_i(d_k = d ) - c_0(i)\\right ) \\nonumber\\\\   & + s\\left({{\\frac{1}{n_0}}}\\log{\\mathbb{p}}_j(d_k = d)- c_0(j)\\right )   + \\lambda_{ij}(s , x_0 ) \\big\\ } - \\epsilon,\\label{c0_lowerbound1}\\]]where the last inequality follows from proposition [ prop : d0_lowerbound ] . by letting @xmath395 and @xmath396 in",
    ", we obtain @xmath397 } } \\nonumber\\\\ & \\geq \\hspace{-10pt}\\max_{\\substack{i\\ne j \\\\ 0\\leq d",
    "\\leq d_k-1}}\\hspace{-10pt } \\min_{s\\in [ 0,1 ] } \\big\\ { ( 1-s)\\left(\\lim_{n_0\\to\\infty}{{\\frac{1}{n_0}}}\\log{\\mathbb{p}}_i(d_k = d ) - c_0(i)\\right ) \\nonumber\\\\   & \\quad + s\\left(\\lim_{n_0\\to\\infty}{{\\frac{1}{n_0}}}\\log{\\mathbb{p}}_j(d_k = d)- c_0(j)\\right )   + \\lambda_{ij}(s , x_0 ) \\big\\ } , \\label{c0_lowerbound1_limit}\\end{aligned}\\ ] ] and the lower bound follows from theorem [ theorem : expert ] .",
    "we next show that there exists a decision rule for agent @xmath0 that achieves @xmath398 in .",
    "given @xmath399 , consider the following rule to differentiate between hypotheses @xmath115 and @xmath256 for @xmath206 : declare @xmath115 iff @xmath400 ) \\leq h_{ji}$ ] , where @xmath401 .    by a simple generalization of cramr s theorem$ ]",
    "are not i.i.d . , but are independent and can be divided into groups of i.i.d .  observations . ]",
    "@xcite , and theorem [ theorem : expert ] , we have for every @xmath402 and all @xmath77 sufficiently large ,    ( c_0(i , j , n_0)_i(d_0(k)j , d_kd ) ) = c_0(i , j , n_0)+ _i(d_kd ) + _i(d_0(k)j d_kd ) -c_0(i ) - q_k_z a_k(d)_i^*(z , x_k^ * ) - _ s \\ { sh_ji - _ ij(s , x_0 ) } + -_s \\ { ( 1-s)(q_k_z a_k(d ) _ i^*(z , x_k^ * ) + c_0(i ) ) + s(q_k_z a_k(d ) _ j^*(z , x_k^*)+c_0(j ) ) - _ ij(s , x_0 ) } + ,    from which we obtain    _ ( c_0(i , j , n_0)_i(d_0(k ) j , d_k d ) ) + m -_0(k , x_0 ) + .    by taking @xmath395 and @xmath403",
    ", we obtain the theorem by maximizing @xmath398 over all policies @xmath214 .",
    "the proof is now complete .",
    "the first part of the theorem is a direct consequence of theorem [ theorem : agent0 ] . from lemma [ lemma : phi_properties ] , we have @xmath404 for any @xmath405 $ ] , @xmath201 , @xmath84 $ ] , and policy @xmath202 .",
    "furthermore , assumption [ assumpt : loss ] implies that @xmath406 for all @xmath405 $ ] .",
    "therefore , the inequalities and follow from , , , and , and the proof is complete .",
    "suppose that agent @xmath35 adopts the policy @xmath47 .",
    "from the pigeonhole principle , if @xmath254 , there exists a region @xmath171 in which both @xmath407 and @xmath408 achieve their minimum value of 0 , for some @xmath206 . since for any @xmath409 , we have    _ s \\ { ( 1-s)(q_k_z a_k(d ) _",
    "i^*(z , x_k^ * ) + c_0(i ) ) + s(q_k_z a_k(d ) _",
    "j^*(z , x_k^ * ) c_0(j ) ) _",
    "ij(s , x_0 ) } _ s ( -_ij(s , x_0,c_0 ) ) = -_s _ ij(s , x_0,c_0 ) ,    we obtain from and , @xmath410 } { { \\overline{\\lambda}}}_{ij}(s , x_0,c_0 ) = { \\mathcal{e}}_{0,b}(k , x_0),\\end{aligned}\\ ] ] and the proposition is proved .      since the proof is similar to that of theorem [ theorem : agent0 ] , we provide only an outline here . from the proposition assumptions",
    ", we have for every @xmath411 $ ] , @xmath412 is bounded away from zero , i.e. , @xmath413 because otherwise the expected loss of agent @xmath35 can be decreased .",
    "therefore , we have @xmath414 . by comparing ( with @xmath214 replaced by @xmath47 ) and , and using an inductive argument , we have @xmath415 , and follows .",
    "we next show the second part of the proposition .",
    "suppose that for some @xmath206 , we have @xmath262 and holds .",
    "then from , we have @xmath416 for all @xmath228 $ ] .",
    "let @xmath417 } \\",
    "{ sq_k \\lambda^*_{ji}(\\delta , x_k ) - { { \\overline{\\lambda}}}_{ij}(s , x_0,c_0 ) \\}$ ] .",
    "note that @xmath418 is non - decreasing in @xmath419 .",
    "therefore , since @xmath420 is symmetrical on @xmath228 $ ] , we have @xmath421 is maximized if @xmath422 , which holds if @xmath423 .",
    "take @xmath424 , and the proposition follows .",
    "in this appendix , we give a characterization for the asymptotic decision region @xmath171 for an agent @xmath35 , and @xmath151 $ ] . for @xmath425 $ ] and @xmath426 $ ] , define the halfspace @xmath427)_{1\\leq m\\leq m-1}\\in { \\mathbb{r}}^{m-1 } : \\nonumber\\\\ & z[i ] - z[j ] \\geq c_k(i , p ) - c_k(j , q)\\big\\},\\end{aligned}\\ ] ] where @xmath428 = 0 $ ] .",
    "for each @xmath429 $ ] , let @xmath430 $ ] be a chosen corresponding index . from",
    ", we have @xmath431 iff @xmath432-c_k(m_p , p)$ ] .",
    "consider a @xmath433 such that @xmath434 .",
    "then , there exists a sequence @xmath435^{d_k}$ ] such that @xmath432-c_k(m_p , p)$ ] for all @xmath436 $ ] and @xmath437 - z[m_d ] - c_k(m_p , p ) + c_k(m_d , d ) > 0 $ ] for all @xmath438 , i.e. , @xmath439 where @xmath440 is a polyhedron since it consists of intersections of halfspaces . on the other hand ,",
    "if such a sequence @xmath441 exists , then @xmath442 .",
    "therefore , the set @xmath171 is the union over all sequences @xmath443^{d_k}$ ] of the polyhedra @xmath440 .",
    "a.  mitchell , j.  kiley , j.  gottfried , and e.  guskin .",
    "( 2013 , oct . )",
    "the role of news on facebook . pew research center .",
    "[ online ] .",
    "available : http://www.journalism.org/files/2013/10/facebook_news_10-24-2013.pdf          y.  zhang , z.  wang , and c.  xia , `` identifying key users for targeted marketing by mining online social network , '' in _ proc .",
    "ieee international conference on advanced information networking and applications workshops _ , 2010 .",
    "p.  willett , p.  swaszek , and r.  blum , `` the good , bad and ugly : distributed detection of a known signal in dependent gaussian noise , '' _ ieee trans . signal process .",
    "_ , vol .",
    "48 , no .",
    "3266  3279 , dec .",
    "2000 .",
    "h.  p. young , `` innovation diffusion in heterogeneous populations : contagion , social influence , and social learning , '' _ american economic review _ , vol .",
    "99 , no .  5 , pp . 18991924 , 2009 .",
    "[ online ] .",
    "available : http://www.aeaweb.org/articles.php?doi=10.1257/aer.99.5.1899    x.  vives , `` social learning and rational expectations , '' _",
    "european economic review _ , vol .",
    "40 , no . 3 - 5 , pp .",
    "589  601 , 1996 , papers and proceedings of the tenth annual congress of the european economic association .",
    "[ online ] .",
    "available : http://www.sciencedirect.com/science/article/pii/0014292195000720            [ ] wee peng tay ( s06 m08 ) received the b.s .",
    "degree in electrical engineering and mathematics , and the m.s .",
    "degree in electrical engineering from stanford university , stanford , ca , usa , in 2002 .",
    "he received the ph.d .",
    "degree in electrical engineering and computer science from the massachusetts institute of technology , cambridge , ma , usa , in 2008 .",
    "he is currently an assistant professor in the school of electrical and electronic engineering at nanyang technological university , singapore .",
    "his research interests include distributed detection and estimation , distributed signal processing , sensor networks , social networks , information theory , and applied probability .",
    "tay received the singapore technologies scholarship in 1998 , the stanford university president s award in 1999 , and the frederick emmons terman engineering scholastic award in 2002 .",
    "he is the coauthor of the best student paper award at the 46th asilomar conference on signals , systems , and computers .",
    "he is currently serving as the chair of dsnig in ieee mmtc , and has served as a technical program committee member for various international conferences ."
  ],
  "abstract_text": [
    "<S> we consider a multihypothesis social learning problem in which an agent has access to a set of private observations and chooses an opinion from a set of experts to incorporate into its final decision . </S>",
    "<S> to model individual biases , we allow the agent and experts to have general loss functions and possibly different decision spaces . </S>",
    "<S> we characterize the loss exponents of both the agent and experts , and provide an asymptotically optimal method for the agent to choose the best expert to follow . </S>",
    "<S> we show that up to asymptotic equivalence , the worst loss exponent for the agent is achieved when it adopts the 0 - 1 loss function , which assigns a loss of 0 if the true hypothesis is declared and a loss of 1 otherwise . </S>",
    "<S> we introduce the concept of hypothesis - loss neutrality , and show that if the agent adopts a particular policy that is hypothesis - loss neutral , then it ignores all experts whose decision spaces are smaller than its own . on the other hand , </S>",
    "<S> if experts have the same decision space as the agent , then choosing an expert with the same loss function as itself is not necessarily optimal for the agent , which is somewhat counter - intuitive . </S>",
    "<S> we derive sufficient conditions for when it is optimal for the agent with 0 - 1 loss function to choose an expert with the same loss function .    </S>",
    "<S> social learning , decentralized detection , error exponent , social network , internet of things . </S>"
  ]
}