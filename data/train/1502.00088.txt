{
  "article_text": [
    "in systematic reviews , several studies that examine the same questions are analyzed together .",
    "viewing all the information is extremely valuable for practitioners in the health sciences .",
    "a notable example is the cochrane systematic reviews on the effects of healthcare interventions .",
    "the process of preparing and maintaining cochrane systematic reviews is described in detail in their manual @xcite .",
    "the reviews attempt to assemble all the evidence that is relevant to a specific healthcare intervention .    deriving conclusions about the overall health benefits or harms from an ensemble of studies can be difficult , since the studies are never exactly the same and there is danger that these differences affect the inference .",
    "for example , factors that are particular to the study , such as the specific cohorts in the study that are from specific populations exposed to specific environments , the specific experimental protocol used in the study , the specific care givers in the study , etc . , may have an impact on the treatment effect .",
    "a desired property of a systematic review is that the effect has been observed in more than one study , i.e. , the overall conclusion is not entirely driven by a single study .",
    "if a significant meta - analysis finding becomes non - significant by leaving out one of the studies , this is worrisome for two reasons : first , the finding may be too particular to the single study ( e.g. , the specific age group in the study ) ; second , there is greater danger that the significant meta - analysis finding is due to bias in the single study ( e.g. , due to improper randomization or blindness ) .",
    "we view this problem as a replicability problem : the conclusion about the significance of the effect is completely driven by a single study , and thus we can not rule out the possibility that the effect is particular to the single study , i.e. , that the effect was not replicated across studies .",
    "a replicability claim is not merely a vague description . a precise computation of the extent of replicability is possible . an objective way to quantify the evidence that the meta - analytic findings do not rely on single studies is as follows . for a meta - analysis of several studies ( n studies ) ,",
    "the minimal replicability claim is that results have been replicated in at least two studies .",
    "this claim can be asserted if the meta - analysis results remains significant after dropping ( leaving - out ) any single study .",
    "we suggest accompanying the review with a quantity we term the @xmath0-value , which quantifies the evidence towards replicability of the effects across studies .",
    "the @xmath0-value is the largest of these @xmath1 meta - analysis @xmath2-values . like a @xmath2-value , which quantifies the evidence against the null hypothesis of no effect",
    ", the @xmath0-value quantifies the evidence against no replicability of effects .",
    "the smaller the @xmath0-value , the greater the evidence that the conclusion about a primary outcome is not driven by a single study .",
    "the report of the @xmath0-value is valuable for meta - analyses of narrow scope as well as of broad scope . in section 5.6 of the manual @xcite",
    "the scope of the review question is addressed .",
    "if the scope is broad , then a review that produced a single meta - analytic conclusion may be criticized for ` mixing apples and oranges ' , particularly when good biologic or sociological evidence suggests that various formulations of an intervention behave very differently or that various definitions of the condition of interest are associated with markedly different effects of the intervention .",
    "the advantage of a broad scope is that it can give a comprehensive summary of evidence .",
    "the narrow scope is more manageable , but the evidence may be sparse , and findings may not be generalizable to other settings or populations .",
    "if the @xmath0-value is large ( say above 0.05 ) for a meta - analyses with a narrow scope , this is worrisome since the scope has already been selected , and the large @xmath0-value indicates that an even stricter selection that removes one single additional study can change the significant conclusion . if the @xmath0-value is large for a meta - analyses with a broad scope , this is worrisome since the reason for the significant finding may be the single  orange \" among the several ( null )  apples \" .",
    "we examined the extent of the replicability problem in systematic reviews .",
    "we found that there may be lack of replicability in a large proportion of studies . in section [ sec - lack of replicability ] , we show that out of the 21 reviews with a significant meta - analysis result on the most important outcomes of interest published on breast cancer , 13 reviews were sensitive to leaving one study out of the meta - analysis .",
    "the problem was less pronounced in the reviews published on influenza , where 2 reviews were sensitive to leaving one study out of the meta - analysis , out of 6 updated reviews with significant primary outcomes .",
    "@xcite write that a useful sensitivity analysis is one in which the meta - analysis is repeated , each time omitting one of the studies .",
    "a plot of the results of these meta - analysis , called an ` exclusion sensitivity plot ' by @xcite , will reveal any studies that have a particularly large influence on the results of the meta - analysis . in this work ,",
    "we concur with this view , but recommend the most relevant single number of summary information of such a sensitivity analysis be added to the report of the main results , and to the forest plot , of the meta - analysis .",
    "the code for the computation of the @xmath0-values and sensitivity intervals is available from the first author upon request .",
    "we took all the updated reviews in two domains : breast cancer and influenza .",
    "our eligibility criteria were as follows : ( a ) the review included forest plots ; ( b ) at least one primary outcome was reported as significant at the .05 level , which is the default significant level used in cochrane reviews ; ( c ) the meta - analysis of at least one of the primary outcomes was based on at least three studies and ( d ) there was no reporting in the review of unreliable / biased primary outcomes or poor quality of available evidence .",
    "we consider as primary outcomes the outcomes that were defined as primary by the review authors , and if none were defined we selected the most important findings from the review summaries and treated the outcomes for these findings as primary .",
    "we limit ourselves to meta - analyses that include at least three studies , since this is the minimum number of studies for which even if the single studies are not significant the meta - analysis may still be non - sensitive ( i.e. , that a meta analysis based on every subset of two studies can have a significant finding ) .    in cochrane reviews ,",
    "the meta - analyses are of two types : fixed effect and random effects . under the fixed effect model",
    "all studies in the meta - analysis are assumed to share a common ( unknown ) effect @xmath3 .",
    "since all studies share the same effect , it follows that the observed effect varies from one study to the next only because of the random error inherent in each study .",
    "the summary effect is the estimate of this common effect @xmath3 . under the random effects model",
    "the effects in the studies , @xmath4 , @xmath5 , are assumed to have been sampled from a distribution with mean @xmath6 . therefore , there are two sources of variance : the within - study error in estimating the effect in each study and the variance in the true effects across studies .",
    "the summary effect is the estimate of the effects distribution mean @xmath6 . for details on estimation of these effects and their confidence intervals ,",
    "see @xcite . in this section",
    "our results are based on the computations of the meta - analysis @xmath2-values as suggested in @xcite , for both fixed and random effects meta - analyses . in the breast cancer domain",
    "48 updated reviews were published by the cochrane breast cancer group in the cochrane library , out of which we analyzed 21 updated reviews that met our eligibility criteria ( 14 , 8 , 4 and 1 reviews was excluded due reasons a , b , c and d respectively ) . out of the 21 eligible reviews ,",
    "13 reviews were sensitive to leaving one study out in at least one primary outcome .",
    "moreover , in 8 out of 13 reviews all the significant primary outcomes were sensitive .",
    "the prevalence of sensitive meta - analyses was similar among the fixed effect and random effect meta - analyses , see table [ tab - breastcancer ] . among the 15 fixed effect meta - analyses , 6 reviews",
    "where sensitive in all their primary outcomes , 2 reviews were sensitive in 66% of the primary outcomes , 1 review was sensitive in 50% of the primary outcomes , and 6 reviews were not sensitive in any of their primary outcomes . among the 7 random effect meta - analyses ,",
    "3 reviews were sensitive in all their primary outcomes , 2 review were sensitive in 50% of their primary outcomes , and 2 reviews were not sensitive in any of their primary outcomes .",
    ".table of results for the breast cancer domain . the review name ( column 2);the type of meta - analysis ( column 3 ) ; the number of significant primary outcomes ( column 4 ) ; the number of outcomes with @xmath0-values at most ( 0.01,0.05,0.1 ) ( columns 5,6,7 ) ; the actual r - values of the primary outcomes , arranged in increasing order ( column 8).the smaller the @xmath0-value , the stronger the evidence towards replicability .",
    "the rows are arranged by order of increasing sensitivity ; the last 8 rows are sensitive in all primary outcomes . [ cols= \" < , < , < , < , < , < ,",
    "< , < \" , ]     [ tab - cd004421 ]      when more than one primary endpoint is examined , the @xmath0-value needs to be smaller in order to establish replicability .",
    "this is exactly the same logic as with @xmath2-values , for which we need to lower the significance threshold when faced with multiplicity of endpoints .",
    "family - wise error rate ( fwer ) or false discovery rate ( fdr ) controlling procedures can be applied to the individual @xmath0-values in order to account for the multiple primary endpoints , see @xcite for details .",
    "for example , in review cd005211 four endpoints were examined , with the following @xmath0-values : ( 1 ) 0.1231 ; ( 2 ) 0.0017 ; ( 3 ) 0.0167 ; ( 4 ) 0.1776 . for fwer control over replicability claims at the 0.05 level , the bonferroni - adjusted @xmath0-values are the number of endpoints multiplied by the original @xmath0-values . only endpoint ( 2 ) is reported as replicated using bonferroni at the 0.05 level , since it is the only bonferroni - adjusted @xmath0-value below 0.05 , @xmath7 .    for fdr control over replicability claims",
    ", we can use the benjamini - hochberg ( bh ) procedure ( @xcite ) on the reported @xmath0-values .",
    "the bh - adjusted @xmath0-values for a sorted list of @xmath8 @xmath0-values , @xmath9 , are @xmath10 in review cd005211 , the sorted list is @xmath11 and the adjusted @xmath0-values are @xmath12 .",
    "therefore , endoints ( 2 ) and ( 3 ) , the two endpoints with the smallest @xmath2-values in the sorted list , are reported as replicated using fdr at the 0.05 level , since for both endpoints the bh - adjusted @xmath0-values are below 0.05 .",
    "in this work we suggested enhancing the systematic reviews meta - analyses , for both fixed effect and random effects model , with a measure that quantifies the strength of replicability , i.e .",
    ", the @xmath0-value . in the reporting , if the @xmath0-value is small we have evidence that the conclusion is based on more than one study , i.e. , that the effect was replicated across studies .",
    "we suggest adding a cautionary note if the @xmath0-value is greater than the significance level ( say @xmath13 ) , that states that the conclusion depends critically on a single study .",
    "this does not mean that the conclusion is necessarily reversed , but the large @xmath0-value warrants another examination of the studies in the meta - analysis , and if the single study upon which the review relies was very well conducted the conclusion may still be justified despite it being only a single study .",
    "we would like to emphasize that replicability analysis is relevant for both fixed effect and random effects model meta analysis . in both cases ,",
    "the meta - analysis can be significant even though the true summary effect is greater than zero in only one study out of the @xmath1 and hence the replicability analysis is needed . specifically , for the random effect model in appendix [ app - sim ] we show simulations where @xmath14 studies have effects @xmath15 samples for the normal distribution with zero mean , and one study has effect @xmath16 . when @xmath17 , the fraction of times the null is rejected at the nominal 0.05 level using a @xmath18-test with @xmath14 degrees of freedoms on the sample of @xmath1 estimated effect sizes is about 0.05 , and using the meta - analysis computations suggested in @xcite the fraction is at most 0.12 .",
    "however , when @xmath19 , the fraction of times the null is rejected at the nominal 0.05 level using a @xmath18-test with @xmath14 degrees of freedoms on the sample of @xmath1 estimated effect sizes can be as high as 0.15 , and using the meta - analysis computations suggested in @xcite the fraction can reach almost 0.3 .",
    "we conclude from these simulations that for meta - analysis , it is better to use the @xmath18-test , and that even with this non - liberal test the significant conclusion can be entirely driven from a single study .",
    "therefore , a replicability analysis is necessary in order to rule out the possibility that a significant random effect meta - analysis conclusion is driven by a single study . in our two domains",
    "there were typically 1 - 4 primary endpoints per review .",
    "we briefly discussed ways to account for the multiplicity of primary endpoints in assessing replicability in section [ subsec - multiplicity ] .",
    "we regard this as an extension since the emphasis , and the new contribution , of this paper is the introduction of the @xmath0-value into the meta - analysis conclusions .",
    "99 higgins , j. and green , s. ( editors ) .",
    "the cochrane handbook for systematic reviews of interventions version 5.1.0 [ updated march 2011 ] .",
    ", www.cochrane-handbook.org .",
    "anzures - carbera , j. and higgins , j. ( 2010 ) .",
    "graphical displays for meta - analysis : an overview with suggestions for practice .",
    ", 1 : 6680 .",
    "bax , l. and yu , l. and ikeda , n. and tsuruta , h. and moons , k. ( 2006 ) .",
    "development and validation of mix : comprehensive free software for meta - analysis of causal research data .",
    ", 6 ( 50 ) .",
    "benjamini , y. and hochberg , y. ( 1995 ) . controlling the false discovery rate : a practical and powerful approach to multiple testing . , 57 ( 1 ) : 289300 .",
    "benjamini , y. and heller , r. and yekutieli , d. ( 2009 ) .",
    "selective inference in complex research .",
    ", 367 : 42554271 .",
    "benjamini , y. and heller , r. ( 2008 ) .",
    "screening for partial conjunction hypotheses .",
    ", 64:12151222 .",
    "bogomolov , m. and heller , r. ( 2013 ) . discovering findings that replicate from a primary study of high dimension to a follow - up study .",
    ", 108(504):14801492 .",
    "heller , r. , bogomolov , m. , and benjamini , y. ( 2014 ) .",
    "deciding whether follow - up studies have replicated findings in a preliminary large - scale omics study . .",
    "heller , r. ( 2011 ) .",
    "discussion of `` multiple testing for exploratory research '' by j. j. goeman and a. solari , 26 ( 4 ) : 598600 .",
    "inthout , j. and ioannidis , j. and borm , g. ( 2014 ) .",
    "the hartung - knapp - sidik - jonkman method for random effects meta - analysis is straightforward and considerably outperforms the standard dersimonian - laird method . , 14(25 ) .",
    "our first example is based on a meta - analysis in review cd001269 , analyzed by the authors as a random effect meta - analysis , which is non - sensitive and thus has a small @xmath0-value .",
    "the objective of review cd001269 was to assess the effects of vaccines against influenza in healthy adult .",
    "four studies were significant ( all favoured treatment ) , and the remaining twelve studies had non - significant effects at the .05 significance level ( seven favoured the treatment , five favoured the control ) . when combined in a meta - analysis the evidence was significant , and the review conclusion was that the placebo arm had a higher risk of influenza - like illness than the vaccine arm , see the left panel of figure [ fig - influenza - like illness ] . even after removing each significant study ( in particular the most influential : study number 9 ) there was still a significant effect in the meta - analysis at the 0.05 level , see the right panel of figure [ fig - influenza - like illness ] .",
    "the @xmath0-value is 0.0014 .",
    "the significant meta - analytic conclusion can therefore be accompanied by a statement that the replicability claim is established at the .05 level of significance .",
    "this is a stronger scientific claim than that of the meta - analysis , and it is supported by the data in this example .",
    "we suggest accompanying the original forest plot with this @xmath0-value , see figure [ fig - influenza - like illness - orig ] .",
    "note that although the referred meta - analysis is significant and the replicability claim is established at the .05 level of significance , in the main results of review cd001269 the authors write : `` the overall effectiveness of parenteral inactivated vaccine against influenza - like illness ( ili ) is limited , corresponding to a number needed to vaccinate ( nnv ) of 40 ( 95% confidence interval ( ci ) 26 to 128 ) '' . to this",
    ", we suggest adding the following information :  this result was replicated in more than one study ( @xmath0-value = 0.0014 ) \" . the replicability claim is relevant even in the presence of a limited effect size : at least two studies showed that there is a ( possibly limited ) effect of parenteral inactivated vaccine against influenza - like illness ( ili ) is limited .",
    "-value was 0.0014 .",
    "the sensitivity interval , [ 0.75,0.96 ] , is the confidence interval excluding study 9 ( the black diamond in the right panel ) with an additional ( very small ) left tail .",
    "the axis is on the logarithmic scale.,title=\"fig:\",scaledwidth=30.0% ] -value was 0.0014 .",
    "the sensitivity interval , [ 0.75,0.96 ] , is the confidence interval excluding study 9 ( the black diamond in the right panel ) with an additional ( very small ) left tail .",
    "the axis is on the logarithmic scale.,title=\"fig:\",scaledwidth=30.0% ]    -value , which was 0.0014 .",
    "the asterisks indicate which study was excluded for the @xmath0-value computation.,scaledwidth=100.0% ]    our second example , also from the influenza domain , is based on a meta - analysis in review cd001269 , analyzed by the authors as a random effects meta - analysis . in this example",
    "the random effect meta - analysis was sensitive .",
    "the objective of review cd008965 was to describe the potential benefits and harms of neuraminidase inhibitors for influenza in all age groups . in the meta - analysis a significant finding was discovered , see the left panel of figure [ fig - neuraminidase inhibitors ] .",
    "note that only one study was significant and the remaining seven studies were not significant ( with large confidence intervals ) . after removing study number 1,there",
    "was no longer a significant effect in the meta - analysis , see the right panel of figure [ fig - neuraminidase inhibitors ] .",
    "the @xmath0-value was 0.1206 based on the random effect meta - analysis computations as suggested in @xcite , and 0.0661 based on the meta - analysis computations as suggested in @xcite .",
    "the replicability claim was not established at the .05 level of significance .",
    "this lack of replicability , quantified by the @xmath0-value , cautions practitioners that the significant meta - analysis finding may depend critically on a single study .",
    "we suggest accompanying the original forest plot with this @xmath0-value , see figure [ fig - neuraminidase inhibitors - orig ] . in the main results of review cd008965",
    "the authors write `` in adults treatment trials , oseltamivir significantly reduced self reported , investigator - mediated , unverified pneumonia ( rr 0.55 , 95% ci 0.33 to 0.9 ) '' ; to this , we suggest adding the following information :  we can not rule out the possibility that this result is based on a single study ( @xmath0-value = 0.1206 ) `` .",
    "note that the conclusion was not that complication were reduced , but this was due to lack of diagnostic definitions .",
    "the authors conclusion in this review was that ' ' treatment trials with oseltamivir do not settle the question of whether the complications of influenza ( such as pneumonia ) are reduced , because of a lack of diagnostic definitions \" .",
    "-value was 0.1206 .",
    "the sensitivity interval , [ 0.24 , 1.13 ] , is the confidence interval excluding study 1 ( the black diamond in the right panel ) with an additional ( small ) right tail .",
    "the axis is on the logarithmic scale.,title=\"fig:\",scaledwidth=40.0% ] -value was 0.1206 .",
    "the sensitivity interval , [ 0.24 , 1.13 ] , is the confidence interval excluding study 1 ( the black diamond in the right panel ) with an additional ( small ) right tail .",
    "the axis is on the logarithmic scale.,title=\"fig:\",scaledwidth=40.0% ]    -value , which was 0.1206 .",
    "the asterisks indicate which study was excluded for the @xmath0-value computation.,scaledwidth=100.0% ]",
    "let @xmath20 and @xmath21 be , respectively , the left- and right- @xmath2-values from a meta - analysis on the subset @xmath22 of the @xmath1 studies in the full meta - analysis , @xmath23 .",
    "let @xmath24 denote the set of all possible subsets of size @xmath25 .      for a meta - analysis based on @xmath1 studies ,",
    "a replicability claim is a claim that the conclusion remains significant ( e.g. , rejection of the null hypothesis of no treatment effect ) using a meta - analysis of each of the @xmath26 subsets of @xmath27 studies , where @xmath28 is a parameter chosen by the investigator .",
    "specifically , for @xmath29 , a replicability claim is a claim that the conclusion remains significant using a meta - analysis of each of the @xmath1 subsets of @xmath14 studies .",
    "the @xmath0-value for replicability analysis , where we claim replicability if the conclusion remains significant using a meta - analysis of each of the @xmath26 subsets of @xmath27 studies is computed as follows . for left-",
    "sided alternative , the @xmath0-value is @xmath30 for right- sided alternative , the @xmath0-value is @xmath31 for two - sided alternavies , the @xmath0-value is @xmath32      the sensitivity interval is the union of all the meta - analysis confidence intervals using the @xmath26 subsets of @xmath27 studies . the upper limit of the @xmath33 sensitivity interval is the upper limit of the @xmath33 confidence interval from the meta - analysis on @xmath34 , where @xmath34 is the subset that achieves the maximum @xmath2-value for the left - sided @xmath0-value computation .",
    "similarly , the lower limit of the @xmath33 sensitivity interval is the lower limit of the @xmath33 confidence interval from the meta - analysis on @xmath35 , where @xmath35 is the subset that achieves the maximum @xmath2-value for the right - sided @xmath0-value computation .",
    "the meta - analysis is non - sensitive ( at the desired value of @xmath36 ) if and only if the sensitivity interval does not contain the null hypothesis value .",
    "this follows from the following argument . to see this",
    ", note that @xmath37 , if and only if @xmath38 or @xmath39 .",
    "since @xmath38 if and only if the upper limit of all the meta - analysis @xmath40 confidence intervals of subsets of size @xmath27 is below the null value , and @xmath39 if and only if the lower limit of all the meta - analysis @xmath40 confidence intervals of subsets of size @xmath27 is above the null value , the result follows .      for meta - analysis with n studies and significant effect size @xmath41 , where @xmath42 is the null effect , e.g. , 1 for hr ( two- sided alternative ) : 1 ) compute meta - analysis of each of the @xmath26 subsets of @xmath27 studies .",
    "2 ) choose the @xmath27 subset of studies that achieves the maximum @xmath2-value for the left - sided @xmath0-value computation : @xmath34 .",
    "3 ) compute the two - sided @xmath0-value : @xmath32 4 ) if the @xmath0-value @xmath43 0.05 , the replicability is established in at lease @xmath36 studies .",
    "otherwise , the replicability is established in at most @xmath44 studies ( for @xmath36=2 , @xmath0-value @xmath45 0.05 means that the finding is not replicable ) .    for meta - analysis with n studies and significant effect size @xmath46 , where @xmath42 is the null effect , e.g. , 1 for hr ( two- sided alternative ) : 1 ) compute meta - analysis of each of the @xmath26 subsets of @xmath27 studies .",
    "2 ) choose the @xmath27 subset of studies that achieves the maximum @xmath2-value for the right - sided @xmath0-value computation : @xmath35 .",
    "3 ) compute the two - sided @xmath0-value : @xmath32 4 ) if the @xmath0-value @xmath43 0.05 , the replicability is established in at lease @xmath36 studies .",
    "otherwise , the replicability is established in at most @xmath44 studies ( for @xmath36=2 , @xmath0-value @xmath45 0.05 means that the finding is not replicable ) .",
    "using the following simulation we demonstrate that a significant random effect meta - analysis is not equivalent to replicability .",
    "meaning , random effect meta - analysis can be significant even though the effect is greater than zero in only one study out of @xmath1 .",
    "we show that the probability of rejecting the null hypothesis with a single outlying study can be as high as 6 times the nominal level using the meta - analysis computations of @xcite , and as high as 3 times the nominal level using the more conservative approach of @xcite .    for @xmath47 studies , we sampled @xmath14 effects @xmath48 from the distribution @xmath49 , where @xmath50 . for the @xmath1th study ,",
    "the effect was @xmath51 . for each study @xmath52 , we sampled observed effects @xmath53 from the normal distribution with mean @xmath54 and standard deviation 0.01 .",
    "we computed the random effect meta - analysis one - sided p - value using the computations suggested in @xcite , i.e. , using the @xmath55-test on the average observed effects , as well as using the @xmath18-test on the sample of observed effects .",
    "we estimated the probability of rejection the null hypothesis of zero mean based on @xmath56 iterations .",
    "figures [ fig - ztest ] and [ fig - ttest ] show the resulting estimated probability of rejecting the null hypothesis .",
    "the random effect meta - analysis is significant in more than 5% of the iterations for all @xmath1 in values of @xmath57 that are not too large relative to the value of @xmath58 .",
    "the larger the value of @xmath59 , the greater the range of @xmath57 for which the nominal level of significance is not maintained .    in @xcite , the normal distribution is used for the random effect meta - analysis @xmath2-value , instead of the @xmath18-distribution with @xmath14 degrees of freedom which in our simulation ( with equal study weights ) results in an exact @xmath60 level test when @xmath61 .",
    "we see that the usage of the @xmath55-test instead of the @xmath18-test results in a type i error rate substantially greater than 5% under the null hypothesis ( i.e. @xmath62 ) and in a higher rejection rate of the null hypothesis for @xmath63 in comparison to the fraction of rejections using the @xmath18-test when there is no replicability .",
    "-test detailed in page 74 of @xcite : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is above @xmath70 for all @xmath1s and @xmath58s , ranging from about @xmath71 for @xmath72 and decreasing to @xmath73 for @xmath74 .",
    "the maximum fraction of rejections is @xmath75 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 and with @xmath1 .",
    "even if the @xmath55-test is acceptable for meta - analysis when the number of studies is large enough , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test detailed in page 74 of @xcite : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is above @xmath70 for all @xmath1s and @xmath58s , ranging from about @xmath71 for @xmath72 and decreasing to @xmath73 for @xmath74 .",
    "the maximum fraction of rejections is @xmath75 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 and with @xmath1 .",
    "even if the @xmath55-test is acceptable for meta - analysis when the number of studies is large enough , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test detailed in page 74 of @xcite : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is above @xmath70 for all @xmath1s and @xmath58s , ranging from about @xmath71 for @xmath72 and decreasing to @xmath73 for @xmath74 .",
    "the maximum fraction of rejections is @xmath75 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 and with @xmath1 .",
    "even if the @xmath55-test is acceptable for meta - analysis when the number of studies is large enough , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test detailed in page 74 of @xcite : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is above @xmath70 for all @xmath1s and @xmath58s , ranging from about @xmath71 for @xmath72 and decreasing to @xmath73 for @xmath74 .",
    "the maximum fraction of rejections is @xmath75 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 and with @xmath1 .",
    "even if the @xmath55-test is acceptable for meta - analysis when the number of studies is large enough , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test detailed in page 74 of @xcite : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is above @xmath70 for all @xmath1s and @xmath58s , ranging from about @xmath71 for @xmath72 and decreasing to @xmath73 for @xmath74 .",
    "the maximum fraction of rejections is @xmath75 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 and with @xmath1 .",
    "even if the @xmath55-test is acceptable for meta - analysis when the number of studies is large enough , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test detailed in page 74 of @xcite : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is above @xmath70 for all @xmath1s and @xmath58s , ranging from about @xmath71 for @xmath72 and decreasing to @xmath73 for @xmath74 .",
    "the maximum fraction of rejections is @xmath75 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 and with @xmath1 .",
    "even if the @xmath55-test is acceptable for meta - analysis when the number of studies is large enough , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ]    -test : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 . the probability of the type i error is @xmath70 for all @xmath1s and @xmath58s .",
    "the maximum fraction of rejections is @xmath78 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 as well as with @xmath1 .",
    "even though the @xmath18-test controls the probability of type i error for meta - analysis , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is @xmath70 for all @xmath1s and @xmath58s .",
    "the maximum fraction of rejections is @xmath78 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 .",
    "the range of values of @xmath77 for which it is above 5% increases with @xmath59 as well as with @xmath1 .",
    "even though the @xmath18-test controls the probability of type i error for meta - analysis , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 . the probability of the type i error is @xmath70 for all @xmath1s and @xmath58s .",
    "the maximum fraction of rejections is @xmath78 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 as well as with @xmath1 .",
    "even though the @xmath18-test controls the probability of type i error for meta - analysis , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is @xmath70 for all @xmath1s and @xmath58s .",
    "the maximum fraction of rejections is @xmath78 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 .",
    "the range of values of @xmath77 for which it is above 5% increases with @xmath59 as well as with @xmath1 .",
    "even though the @xmath18-test controls the probability of type i error for meta - analysis , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 . the probability of the type i error is @xmath70 for all @xmath1s and @xmath58s .",
    "the maximum fraction of rejections is @xmath78 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 as well as with @xmath1 .",
    "even though the @xmath18-test controls the probability of type i error for meta - analysis , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ] -test : ( a ) @xmath64 ; ( b ) @xmath65 ; ( c ) @xmath66 ; ( d ) @xmath67 ; ( e ) @xmath68 ; ( f ) @xmath69 .",
    "the probability of the type i error is @xmath70 for all @xmath1s and @xmath58s .",
    "the maximum fraction of rejections is @xmath78 for @xmath72 and @xmath76 , and decreases for increasing @xmath1 and @xmath58 . the range of values of @xmath77 for which it is above 5% increases with @xmath59 as well as with @xmath1 .",
    "even though the @xmath18-test controls the probability of type i error for meta - analysis , we still have a problem with lack of replicability.,title=\"fig:\",scaledwidth=30.0% ]"
  ],
  "abstract_text": [
    "<S> in order to assess the effect of a health care intervention , it is useful to look at an ensemble of relevant studies . the cochrane collaboration s admirable goal is to provide systematic reviews of all relevant clinical studies , in order to establish whether or not there is a conclusive evidence about a specific intervention . </S>",
    "<S> this is done mainly by conducting a meta - analysis : a statistical synthesis of results from a series of systematically collected studies . </S>",
    "<S> health practitioners often interpret a significant meta - analysis summary effect as a statement that the treatment effect is consistent across a series of studies . </S>",
    "<S> however , the meta - analysis significance may be driven by an effect in only one of the studies . </S>",
    "<S> indeed , in an analysis of two domains of cochrane reviews we show that in a non - negligible fraction of reviews , the removal of a single study from the meta - analysis of primary endpoints makes the conclusion non - significant . therefore , </S>",
    "<S> reporting the evidence towards replicability of the effect across studies in addition to the significant meta - analysis summary effect will provide credibility to the interpretation that the effect was replicated across studies . </S>",
    "<S> we suggest an objective , easily computed quantity , we term the @xmath0-value , that quantifies the extent of this reliance on single studies . </S>",
    "<S> we suggest adding the @xmath0-values to the main results and to the forest plots of systematic reviews .    </S>",
    "<S> liat shenhav + _ department of statistics and operations research , tel - aviv university , tel - aviv , israel . </S>",
    "<S> e - mail : liatshen@post.tau.ac.il_ + ruth heller + _ department of statistics and operations research , tel - aviv university , tel - aviv , israel . </S>",
    "<S> e - mail : ruheller@post.tau.ac.il_ + yoav benjamini + _ department of statistics and operations research , tel - aviv university , tel - aviv , israel . </S>",
    "<S> e - mail : ybenja@post.tau.ac.il_ + </S>"
  ]
}