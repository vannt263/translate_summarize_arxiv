{
  "article_text": [
    "the intellectual process of learning from observations can be sketched as illustrated in figure [ fig : obs_hyp ] . from experimental data we wish to ` determine ' the value of some physical quantities , or to establish which theory describes ` at best ' the observed phenomena .",
    "although these two tasks are usually seen as separate issues , and analyzed with different mathematical tools , they can be viewed as two subclasses of the same process : _ inferring hypotheses from observations_. what differs between the two kinds of inference is the number of hypotheses that enters the game : a discrete , usually small number when dealing with _ theory comparison _ ; a large , virtually infinite number when _ inferring the value of physical quantities_.    in general , given some data ( _ past observations _ ) , we wish to :    * select a theory and determine its parameters with the aim to describe and ` understand ' the physical world ; * predict _ future observations _ ( that , once they are recorded , they join the set of past observations to corroborate or diminish our confidence on each theory and its parameters ) .",
    "the process of learning from data and predicting new observations is characterized by _ uncertainty _ ( see figure [ fig : past - future ] ) .",
    "uncertainty in going from past observations to the theory and its parameters .",
    "uncertainty in predicting precise observations from the theory . and , as a consequence , uncertainty in predicting future observations from past observations .",
    "rephrasing the hypothesis - observation scheme in terms of _ causes _ and _ effects _ , we can realize that the very source of uncertainty is due to the not biunivocal relationship between causes and effects , as sketched in figure [ fig : cause - effetti ] .",
    "the fact that _ identical _ causes  identical according to our knowledge  might produce different effects can be due to _ internal _ ( intrinsic ) probabilistic aspects of the theory , as well as to our lack of knowledge about the exact set of causes .",
    "( experimental errors are one of the components of the _ external _ probabilistic behavior of the observations . )",
    "however , there is no practical difference between the two situations , as far as the probabilistic behavior of the result is concerned ( i.e. in the status of our mind concerning the possible outcomes of the experiment ) , and hence to the probabilistic character of inference .    given this cause - effect scheme ,",
    "having observed an effect , we can not be sure about its cause .",
    "( this is what happens to effects @xmath0 , @xmath1 and @xmath2 of figure [ fig : cause - effetti ]  effect @xmath3 , that can only be due to cause @xmath4 , has to be considered an exception , at least in the inferential problems scientists typically meet . )",
    "example 1 .",
    ": :    as a simple example , think about the effect identified by the number    @xmath5 resulting by one of the following random generators    chosen at random : @xmath6 = `` a gaussian generator with    @xmath7 and @xmath8 '' ; @xmath9 =    `` a gaussian generator with @xmath10 and    @xmath11 '' ; @xmath12 = `` an exponential    generator with @xmath13 '' ( @xmath14 stands for    the expected value of the exponential distribution ; @xmath15    and @xmath16 are the usual parameters of the gaussian    distribution ) .",
    "our problem , stated in intuitive terms , is to find out    which hypothesis might have caused @xmath5 :    @xmath6 , @xmath9 or @xmath12 ?",
    "note that    none of the hypotheses of this example can be excluded and , therefore ,    there is no way to reach a boolean conclusion .",
    "we can only state ,    somehow , our _ rational preferences _ , based on the experimental result    and our best knowledge of the behavior of each _ model_.    the human mind is used to live  and survive  in conditions of uncertainty and has developed mental categories to handle it . therefore , although we are in a constant status of uncertainty about many events which might or might not occur , we can be `` more or less _ sure _  or _ confident _  on something than on something else '' . in other words , `` we consider something more or less _ probable _ ( or _ likely _ ) '' , or `` we _ believe _ something more or less than something else '' .",
    "we can use similar expressions , all referring to the intuitive idea of _",
    "probability_.    the status of uncertainty does not prevent us from doing science .",
    "indeed , said with feynman s words , _ `` it is scientific only to say what is more likely and what is less likely''_@xcite .",
    "therefore , it becomes crucial to learn how to deal quantitatively with probabilities of causes , because the _ ",
    "problem_(s ) _ in the probability of causes  may be said to be the essential problem_(s ) _ of the experimental method  _",
    "( poincar@xcite ) .    however , and unfortunately , it is a matter of fact that nowadays most scientists are incapable to reason correctly about probabilities of causes , probabilities of hypotheses , probabilities of values of a quantities , and so on . this lack of expertise is due to the fact that we have been educated and trained with a statistical theory in which the very concept of probability of hypotheses is absent , although we naturally tend to think and express ourselves in such terms . in other words ,",
    "the common prejudice is that probability _ is _ the long - term relative frequency , but , on the other hand , probabilistic statements about hypotheses ( or statements implying , anyway , a probabilistic meaning ) are constantly made by the same persons , statements that are irreconcilable with their definition of probability  @xcite .",
    "the result of this mismatch between natural thinking and cultural over - structure produces mistakes in scientific judgment , as discussed e.g. in refs .",
    "@xcite .",
    "another prejudice , rather common among scientists , is that , when they deal with hypotheses , ` they think they reason ' according to the falsificationist scheme : hence , the hypotheses tests of conventional statistics are approached with a genuine intent of proving / falsifying something .",
    "for this reason we need to shortly review these concepts , in order to show the reasons why they are less satisfactory than we might navely think .",
    "( the reader is assumed to be familiar with the concepts of hypothesis tests , though at an elementary level  null hypothesis , one and two tail tests , acceptance / rejection , significance , type 1 and type 2 errors , an so on . )",
    "the essence of the so called _ falsificationism _ is that a theory should yield _ verifiable _ predictions , i.e. predictions that can be checked to be _ true _ or _",
    "false_. if an effect is observed that contradicts the theory , the theory is ruled out , i.e. it is _",
    "falsified_. though this scheme is certainly appealing , and most scientists are convinced that this is the way science proceeds , it is easy to realize that this scheme is a bit nave , when one tries to apply it literally , as we shall see in a while . before doing that , it is important to recognize that falsificationism is nothing but an extension of the classical _ proof by contradiction _ to the experimental method .",
    "the proof by contradiction of standard dialectics and mathematics consists in assuming true a hypothesis and in looking for ( at least ) one of its logical consequences that is manifestly false .",
    "if a false consequence exists , then the hypothesis under test is considered false and its opposite true ( in the sequel @xmath17 will indicate the hypothesis opposite to @xmath18 , i.e. @xmath17 is true if @xmath18 false , and vice versa ) .",
    "indeed , there is no doubt that if we observe an effect that is _ impossible _ within a theory , this theory has to be ruled out .",
    "but the _ strict _ application of the falsificationist criterion is not maintainable in the scientific practice for several reasons .    1 .",
    "what should we do of all theories which have not been falsified yet ?",
    "should we consider them all at the same level , parked in a kind of _ limbo _ ?",
    "this approach is not very effective .",
    "which experiment should we perform next ?",
    "the natural development of science shows that new investigations are made in the direction that seems mostly _ credible _ ( and fruitful ) at a given moment , a behaviour often _",
    "`` 179 degrees or so out of phase from popper s idea that we make progress by falsificating theories '' _",
    "2 .   if the predictions of a theory are characterized by the internal or external probabilistic behavior discussed above , how can we ever think of falsifying such a theory , speaking rigorously ?",
    "for instance , there is no way to falsify hypothesis @xmath6 of example 1 , because any real number is compatible with any gaussian .",
    "for the same reason , falsificationism can not be used to make an inference about the value of a physical quantity ( for a gaussian response of the detector , no value of @xmath15 can be falsified whatever we observe , and , unfortunately , falsificationism does not tell how to classify non - falsified values in credibility ) .",
    "an extension of strict falsificationism is offered by the _ statistical test _ methods developed by statisticians .",
    "indeed , the latter methods might be seen as attempts of implementing in practice the falsificationism principle .",
    "it is therefore important to understand the ` little ' variations of the statistical tests with respect to the proof of contradiction ( and hence to strict falsificationism ) .    1 .",
    "the impossible consequence is replaced by an _",
    "improbable consequence_. if this improbable consequence occurs , then the hypothesis is rejected , otherwise it is accepted .",
    "the implicit argument on the basis of the hypothesis test approach of conventional statistics is : `` if @xmath19 is _ practically impossible _ given @xmath18 , then @xmath18 is considered _ practically false _ given the observation @xmath19 . '' but this probability inversion  initially qualitative , but then turned erroneously quantitative by most practitioners , attributing to ` @xmath18 given @xmath19 ' the same probability of ` @xmath19 given @xmath18 '  is not logically justified and it is not difficult to show that it yields misleading conclusions .",
    "let us see some simple examples .",
    "+ example 2 : :    considering hypothesis @xmath6 of example 1 and taking    @xmath20 `` @xmath21 '' , we can calculate the    probability of obtaining @xmath19 from @xmath6 :    @xmath22 .",
    "this probability is rather    small , but , once @xmath19 has occurred , we can not state that    `` @xmath19 has little probability to come from    @xmath6 '' , or that `` @xmath6 has little    probability to have caused @xmath19 '' : @xmath19 is due    to @xmath6 !",
    "example 3 : :    `` i play honestly at lotto , betting on a rare combination ''    ( @xmath23 ) and `` win '' ( @xmath24 ) .",
    "you can not say that    since @xmath19 is ` practically impossible ' given    @xmath18 , then hypothesis @xmath18 has to be    ` practically excluded ' , after you have got the information that i have    won [ such a conclusion would imply that it is ` practically true ' that    `` i have cheated '' ( @xmath25 ) ] .",
    "example 4 : :    an aids test to detect hiv infection is perfect to tag hiv infected    people as ` positive ' ( = pos ) , i.e.    @xmath26 , but it can sometimes    err , and classify healthy persons    ( @xmath27 ) as positive , although with low    probability , e.g.    @xmath28 . an    italian citizen is chosen _ at random _ to undergo such a test and    he / she is tagged positive .",
    "we can not claim that `` since it was    practically impossible that a healthy person resulted positive , then    this person is practically infected '' , or , quantitatively , `` there is    only 0.2% probability that this person is not infected '' .",
    "+ we shall see later how to solve these kind of problems correctly . for the moment",
    "the important message is that _ it is not correct to replace ` improbable ' in logical methods that speak about ` impossible ' _ ( and to use then the reasoning to perform ` probabilistic inversions ' ) : impossible and improbable differ in quality , not just in quantity !",
    "2 .   in many cases",
    "the number of effects due to a hypothesis is so large that _ each effect is ` practically impossible'_. probability ) , as ` extraordinary ' are all other possible outcomes ! ] even those who trust the reasoning based on the small probability of effects to falsify hypotheses have to realize that the reasoning fails in these cases , because every observation can be used as an evidence against the hypothesis to be tested .",
    "statisticians have then worked out methods in which the observed effect is replaced by two _",
    "ensembles of effects _ , one of high chance and another of low chance .",
    "the reasoning based on the ` practically impossible ' effect is then extended to the latter ensemble .",
    "this is the essence of all tests tests based on `` p - values''@xcite ( what physicists know as  probability + of tails  upon which @xmath29 and other famous tests are based ) . logically , the situation gets worse , because conclusions do not depend anymore on what has been observed , but also on effects that have not been observed , where @xmath30 are the model parameters .",
    "but this integral is rarely simply proportional to the likelihood @xmath31 , i.e. integral and likelihood do not differ by just a constant factor not depending on @xmath30 .",
    "i would like to make clear that i dislike un - needed principles , including the likelihood one , and the maximum likelihood one above all .",
    "the reason why i refer here to the likelihood principle in my argumentation is that , generally , frequentists consider this principle with some respect , but their methods usually violate it  @xcite .",
    "instead , in the probabilistic approach illustrated in the sequel , this principle stems automatically from the theory . ]",
    "( see e.g. ref .",
    "3 .   apart from the simple case of just one observation , the data are summarized by a ` test variable ' ( e.g. @xmath29 ) , function of the data , and the reasoning discussed above is applied to the test variable .",
    "this introduces an additional , arbitrary ingredient to this already logically tottering construction . and @xmath16 of a gaussian distribution ) .",
    "however , i do not know of test variables that can be considered sufficient for hypothesis tests . ]",
    "4 .   even in simple problems ,",
    "that could be formulated in terms of a single quantity , given the empirical information there might be ambiguity about which quantity plays the role of the random variable upon which the p - value has to be calculated .",
    "white balls in @xmath32 trials can be considered in agreement with the hypothesis that the box contains a given percentage @xmath33 of white balls .",
    "you might think that you are dealing with a binomial problem , in which @xmath34 plays the role of random variable , calculate the p - value and draw your conclusions .",
    "but you might get the information that the person who made the extraction had decided to go on until he / she reached @xmath34 white balls .",
    "in this case the random variable is @xmath32 , the problem is modeled by a pascal distribution ( or , alternatively , by a negative binomial in which the role of random variable is played by the number @xmath35 of non - white balls ) and the evaluation of the p - value differs from the previous one .",
    "this problem is known as the _ stopping rule _",
    "it can be proved that the likelihood calculated from the two reasonings differ only by a constant factor , and hence the likelihood principle tells that the two reasonings should lead to identical inferential conclusions about the unknown percentage of white balls . ]    anyhow , apart from questions that might seem subtle philosophical quibbles , conventional tests lead to several practical problems .    * in my opinion the most serious problem is the fact that p - values are constantly used in scientific conclusions as if they were the probability that the hypothesis under test is true ( for example people report a p - value of 0.0003 as `` the hypothesis is excluded at 99.97% c.l . '' , as if they were 99.97% confident that the hypothesis to test is false ) .",
    "the consequence of this misunderstanding is very serious , and it is essentially responsible for all claims of fake discoveries in the past decades ( see some examples in sec .",
    "1.9 of ref .",
    "@xcite . ) * statistical tests are not based on first principles of any kind .",
    "hundreds of statistical tests have been contrived and their choice is basically arbitrary .",
    "i have experienced that discussions in experimental teams about which test to use and how to use it are not deeper than discussions in pubs among soccer fans ( italian readers might think at the ` processo di biscardi ' talk show , quite often also in the tones ) .",
    "* there is sometimes a tendency to look for the test that gives the desired result .",
    "personally , i find that _ the fancier the name of the test is , the less believable the claim is _ , because i am pretty sure that other , more common tests were discarded because ` they were not appropriate ' , an expression to be often interpreted as `` the other tests did not support what the experimentalist wanted the data to prove '' ( and i could report of people that , frustrated by the ` bad results ' obtained with frequentistic tests , contacted me hoping for a bayesian miracle  they got regularly disappointed because , ` unfortunately ' , bayesian methods , consciously applied , tend not to feed vain illusions ) . *",
    "standard statistical methods , essentially a contradictory collection of _ ad - hoc - eries _ , induce scientists , and physicists in particular , to think that ` statistics ' is something ` not serious ' , thus encouraging ` creative ' behaviors . of 37.9 , 49.1 and 52.4 for models",
    "@xmath36 , @xmath37 and @xmath37 , the common frequentistic wisdom says the three models are about equivalent in describing the data , because the expected @xmath29 is @xmath38 , or that none of the models can be ruled out because all p - values ( 0.56 , 0.15 and 0.091 , respectively ) are above the usual critical level of significance .",
    "nevertheless , superkamiokande claims that models @xmath39 and @xmath37 are ` disfavored ' at 3.3 and 3.8 @xmath16 s , respectively ! ( @xmath40 and @xmath41 probability . )",
    "it seems the result has been achieved using inopportunely a technique of parametric inference .",
    "imagine a minimum @xmath29 fit of the parameter @xmath42 for which the data give a minimum @xmath29 of 37.9 at @xmath43 , while @xmath44 and @xmath45 ( and the @xmath29 curve is parabolic ) .",
    "it follows that @xmath46 and @xmath47 are , respectively , @xmath48 s and @xmath49 s far from @xmath50 . the probability that @xmath42 differs from @xmath50 by more than @xmath51 and @xmath52 is then @xmath53 and @xmath54 , respectively . but this is quite a different problem ! ]",
    "the dominant school in statistics since the beginning of last century is based on a quite unnatural approach to probability , in contrast to that of the founding fathers ( poisson , bernoulli , bayes , laplace , gauss , etc . ) . in this dominant approach ( _ frequentism",
    "_ ) there is no room for the concept of probability of causes , probability of hypotheses , probability of the values of physical quantities , and so on .",
    "problems in the probability of the causes ( `` _ the essential problem of the experimental method_''!@xcite ) have been replaced by the machinery of the hypothesis tests .",
    "but people think naturally in terms of probability of causes , and the mismatch between natural thinking and standard education in statistics leads to the troubles discussed above .",
    "i think that the way out is simply to _ go back to the past_. in our time of rushed progress an invitation to go back to century old ideas seems at least odd ( imagine a similar proposal regarding physics , chemistry or biology ! ) .",
    "i admit it , but i do think it is the proper way to follow .",
    "this does nt mean we have to drop everything done in probability and statistics in between .",
    "most mathematical work can be easily recovered .",
    "in particular , we can benefit of theoretical clarifications and progresses in probability theory of the past century .",
    "we also take great advantage of the boost of computational capability occurred very recently , from which both symbolic and numeric methods have enormously benefitted .",
    "( in fact , many frequentistic ideas had their _",
    "raison dtre _ in the computational barrier that the original probabilistic approach met .",
    "many simplified  though often simplistic  methods were then proposed to make the live of practitioners easier .",
    "but nowadays computation can not be considered any longer an excuse . )    in summary , the proposed way out can be summarized in an invitation to _ use probability theory consistently_. but before you do it , you need to review the definition of probability , otherwise it is simply impossible to use all the power of the theory . in the advised approach probability",
    "quantifies how much we believe in something , i.e. we recover its intuitive idea .",
    "once this is done , we can essentially use the formal probability theory based on kolmogorov axioms ( which can indeed be derived , and with a better awareness about their meaning , from more general principles !  but i shall not enter this issue here ) .",
    "this ` new ' approach is called _ bayesian _ because of the central role played by bayes theorem in learning from experimental data .",
    "the theorem teaches how the probability of each hypothesis @xmath55 has to be updated in the light of the new observation @xmath19 : @xmath56 @xmath57 stands for a background condition , or status of information , under which the inference is made . a more frequent bayes formula in text books , valid",
    "if the hypotheses are exhaustive and mutually exclusive , is @xmath58 the denominator in the right hand side of ( [ eq : bayes ] ) is just a normalization factor and , as such , it can be neglected .",
    "moreover it is possible to show that a similar structure holds for probability density functions ( p.d.f . )",
    "if a continuous variable is considered ( @xmath15 stands here for a generic ` true value ' , associated to a parameter of a model ) . calling ` data ' the overall effect @xmath19 , we get the following formulae on which inference is to be ground : @xmath59 the first formula used in probabilistic comparison of hypotheses , the second ( mainly ) in _ parametric inference_. in both cases we have the same structure : @xmath60 where ` posterior ' and ` prior ' refer to our belief on that hypothesis , i.e. taking or not taking into account the ` data ' on which the present inference is based .",
    "the likelihood , that is `` how much we believe that the hypothesis can produce the data '' ( not to be confused with `` how much we believe that the data come from the hypothesis '' ! ) , models the stochastic flow that leads from the hypothesis to the observations , including the best modeling of the detector response .",
    "the structure of ( [ eq : bayes_structure ] ) shows us that the inference based on bayes theorem satisfies automatically the _ likelihood principle _ ( likelihoods that differ by constant factors lead to the same posterior ) .",
    "the proportionality factors in ( [ eq : bayes_1 ] ) and ( [ eq : bayes_2 ] ) are determined by normalization , if absolute probabilities are needed .",
    "otherwise we can just put our attention on probability ratios : @xmath61 _ odds _ are updated by data via the ratio of the likelihoods , called _",
    "bayes factor_.    there are some well known psychological ( indeed cultural and even ideological ) resistances to this approach due to the presence of the priors in the theory .",
    "some remarks are therefore in order :    * priors are unescapable , if we are interested in ` probabilities of causes ' ( stated differently , there is no other way to relate consistently probabilities of causes to probabilities of effects avoiding bayes theorem ) ; * therefore , you should mistrust methods that pretend to provide ` levels of confidence ' ( in the sense of _ how much you are confident _ ) independently from priors ( arbitrariness is often sold for objectivity ! ) ; * in many ` routine ' applications the results of measurements depend weakly on priors and many standard formulae , usually derived from maximum likelihood or least square principles , can be promptly recovered _ under well defined conditions of validity _ , * but in other cases priors might have a strong influence on the conclusions ; * if we understand the role and the relevance of the priors , we shall be able to provide useful results in the different cases ( for example , when the priors dominate the conclusions and there is no agreement about prior knowledge , it is better to refrain from providing probabilistic results : bayes factors may be considered a convenient way to report how the experimental data push toward either hypothesis ; similarly , upper / lower `` xx%  c.l.s '' are highly misleading and should be simply replaced by _",
    "sensitivity bounds_@xcite ) .    to make some numerical examples ,",
    "let us solve two of the problems met above .",
    "( in order to simplify the notation the background condition ` @xmath57 ' is not indicated explicitly in the following formulae ) .",
    "solution of the aids problem ( example 4 ) : :     +    applying eq .",
    "( [ eq : bayes_ratios ] ) we get @xmath62 the bayes factor    @xmath63 is equal to 1/0.002 = 500 .",
    "this is how much the information provided by the data ` pushes ' towards    the hypothesis ` infected ' with respect to the hypothesis ` healthy ' .",
    "_ if _ the ratio of priors were equal to 1 [ i.e.    @xmath64 ! ] , we would get    final odds of 500 , i.e.    @xmath65 .",
    "but ,    fortunately , for a randomly chosen italian @xmath66    is not 50% . putting some more reasonable numbers , that might be 1/600    or 1/700 , we have final odds of 0.83 or 0.71 , corresponding to a    @xmath67 of 45% or 42% .",
    "we    understand now the source of the mistake done by quite some people in    front of this problem : priors were unreasonable !",
    "this is a typical    situation : using the bayesian reasoning it is possible to show the    hidden assumptions of non - bayesian reasonings , though most users of    the latter methods object , insisting in claiming they `` do not use    priors '' .",
    "solution of the three hypothesis problem ( example 1 ) : :     +    +    the bayes factors between hypotheses @xmath68 and    @xmath69 , i.e.    @xmath70 , are    @xmath71 , @xmath72 and    @xmath73 .",
    "the observation @xmath5 favors    models 2 and 3 , but the resulting probabilities depend on priors .    _ assuming _ prior equiprobability among the three generators we get the    following posterior probabilities for the three models : 2.3% , 41% and    57% .",
    "( in alternative , we could know that the extraction mechanism does    not choose the three generators at random with the same probability ,    and the result would change . )",
    "+    instead , if we made an analysis based on p - value we would get that    @xmath6 is `` excluded '' at a 99.87% c.l . or at 99.7% c.l .",
    ",    depending whether a one - tail or a two - tail test is done . essentially ,    the perception that @xmath6 could be the correct cause of    @xmath5 is about 10 - 20 times smaller than that given by the    bayesian analysis . as far as the comparison between @xmath9    and @xmath12 is concerned , the p - value analysis is in    practice inapplicable ( what would you do ? ) and one says that both    models describe about equally well the result , which is more or less    what we get out of the bayesian analysis .",
    "however , the latter analysis    gives some quantitative information : a slight hint in favor of    @xmath12 , that could be properly combined with many other    small hints coming from other pieces of experimental information , and    that , all together , might allow us to finally arrive to select one of    the models .",
    "the main message of this contribution is an invitation to review critically several concepts and methods to which we are somehow accustomed .",
    "strict falsificationism is definitely nave and its implementation via frequentistic hypothesis tests is logically seriously flawed .",
    "such tests ` often work '  unfortunately i can not not go through this point for lack of space and i refer to section 10.8 of ref .  @xcite  if we want to use them to form a rough idea about whether it is worth investigating in alternative hypotheses that would describe the data better .",
    "stated in different words , there is nothing to reproach  and i admit i do it  calculating a @xmath29 variable to get a idea of the ` distance ' between a model and the data .",
    "what is not correct is to use the @xmath29 , or any other test variable to quantitatively assess our confidence on that model .",
    "an alternative way of reasoning , based on probability theory and then capable to quantify consistently our confidence in formal probabilistic terms , has been shortly outlined .",
    "i hope that , also with the help of the simple examples , the paper has been able to convey some important points .",
    "* bayes theorem provides a consistent way to learn from data both for probabilistic parametric inference and probabilistic model comparison . * in order to perform a model comparison at least two fully specified hypotheses are needed [ i.e. of which we are able to evaluate , though roughly , the likelihood @xmath74 , where @xmath30 are the model parameters ] . * scientific conclusions , i.e. how much we believe in either hypothesis , must depend on priors  would you trust an ` ad hoc ' model tailored on the data you are going to use for the inference ?",
    "* if a hypothesis is hardly believable with respect to an alternative hypothesis , then it is absolutely normal that a stronger evidence in favor of it is needed , before we reverse our preference . *",
    "the bayes factor can be considered an unbiased way to report how much the data alone ` push ' towards each hypothesis .",
    "another important class of applications , not discussed in this paper , concerns parametric inference . essentially , one starts from eq .",
    "( [ eq : bayes_2 ] ) , and all the rest is ` just math ' , including the extensions to several dimensions and some ` tricks ' to get the computation done .",
    "it can be easily shown that standard methods can be recovered as approximated application of the bayesian inference under _ some well defined assumptions _ that usually hold in routine applications .",
    "i refer to refs .",
    "@xcite and @xcite for details concerning this point , as well as for other issues in bayesian data analysis not discussed here , and a rich bibliography .    finally , i would like to add some epistemological remarks .",
    "the first one concerns falsificationism , since after my conference talk i have received quite some energetic reactions of colleagues who defended that principle . from a probabilistic perspective , falsificationism is easily recovered if the likelihood vanishes , i.e. @xmath75 . however this condition is rarely met in the scientific practice , if we speak rigorously ( zero is a very committing value ! ) .",
    "i guess we just speak of falsificationism because that is what we have being taught is the ` good thing ' , but without being aware of its implications .",
    "it seems to me we actually think in terms of something that should better be named _ testability _",
    ", that can be stated quite easily in the language of probabilistic inference .",
    "given a hypothesis @xmath55 , testability requires that the likelihood is positive in a region @xmath76 of the space of the _ achievable experimental outcomes _ of an experiment @xmath77 [ i.e. @xmath78 and is not trivially proportional to the likelihood of another hypotheses [ i.e. @xmath79 .",
    "these are in fact the conditions for a hypothesis to gain in credibility , via bayes theorem , over the alternative hypotheses in the light of the expected experimental results .",
    "the theory is definitively falsified if the experimental outcome falls on another region @xmath80 such that @xmath81 .",
    "therefore , falsificationism is just a special case of the bayesian inference .    anyway ,",
    "if there is a topic in which falsificationism can be applied in a strict sense , this topic concerns the use of conventional statistical methods , as i wrote elsewhere@xcite : `` _ i simply apply scientific methodology to statistical reasoning in the same way as we apply it in physics and in science in general . if , for example , experiments show that parity is violated , we can be disappointed , but we simply give up the principle of parity conservation , at least in the kind of interactions in which it has been observed that it does not hold .",
    "i do not understand why most of my colleagues do not behave in a similar way with the maximum likelihood principle , or with the ` prescriptions ' for building confidence intervals , both of which are known to produce absurd results .",
    "the second epistemological remark concerns another presumed myth of scientists , i.e. that `` _ since galileo an accepted base of scientific research is the repeatability of experiments_.''@xcite ( _  this assumption justifies the frequentistic definition of probability  _   continues the author . ) clearly , according to this point of view , most things discussed in this workshop are not scientific. fortunately , it is presently rather well accepted ( also by the author of ref .",
    "@xcite , i understand ) that science can be also based on a collection of individual facts that we can not repeat at will , or that might happen naturally and beyond our control ( but there is still someone claiming fields like geology , evolutionary biology and even astrophysics are not science ! ) .",
    "the relevant thing that allows us to build up a rational scientific knowledge grounded on empirical observations is that we are capable to relate , though in a stochastic way and with the usual unavoidable uncertainties , our conjectures to experimental observations , no matter if the phenomena occur spontaneously or arise under well controlled experimental conditions .",
    "in other words , we must be able to model , though approximately , the likelihoods that connect hypotheses to observations . this way of building the scientific edifice is excellently expressed in the title of one of the volumes issued to celebrate the centennial of the carnegie institute of washington  @xcite .",
    "this scientific building can be formally ( and graphically ) described by the so called ` bayesian networks ' or ` belief networks '  @xcite .",
    "if you have never heard these expressions , try to google them and you will discover a new world ( and how behind we physicists are , mostly sticking to books and lecture notes that are too often copies of copies of obsolete books ! ) .",
    "g. dagostini , `` _ bayesian reasoning versus conventional statistics in high energy physics _ '' , in maximum entropy and bayesian methods : garching , germany 1998 , eds .",
    "w. von der linden , v. dose and r. fisher , kluwer academic , 1999 .",
    "g. zech , _ frequentist and bayesian confidence limits _ ,",
    "direct * c12 * ( 2002 ) 1 .",
    "d. kielczewska at this workshop .",
    "the superkamiokande collaboration , y.ashie et al .",
    ", _ evidence for an oscillatory signature in atmospheric neutrino oscillation _ , phys",
    "* 93 * ( 2004 ) 101801 .",
    "g. dagostini , _ bayesian inference in processing experimental data : principles and basic applications _ , rep .",
    "* 66 * ( 2003 ) 1383 . c. giunti ,",
    "_ enhancing the physical significance of frequentistic confidence intervals _ , in the proceedings of the workshop on confidence limits , cern , geneva , 17 - 18 january 2000 , cern 2000 - 005 .",
    "freedman , ed .",
    ", _ measuring and modeling the universe _ , cambridge university press , 2004 ."
  ],
  "abstract_text": [
    "<S> testing hypotheses is an issue of primary importance in the scientific research , as well as in many other human activities . </S>",
    "<S> much clarification about it can be achieved if the process of learning from data is framed in a stochastic model of causes and effects . </S>",
    "<S> formulated with poincar s words , the _ </S>",
    "<S> `` essential problem of the experimental method '' _ becomes then solving a _ </S>",
    "<S> `` problem in the probability of causes '' _ , i.e. ranking the several hypotheses , that might be responsible for the observations , in credibility . </S>",
    "<S> this probabilistic approach to the problem ( nowadays known as the bayesian approach ) differs from the standard ( i.e. frequentistic ) statistical methods of hypothesis tests . </S>",
    "<S> the latter methods might be seen as practical attempts of implementing the ideal of falsificationism , that can itself be viewed as an extension of the proof by contradiction of the classical logic to the experimental method . </S>",
    "<S> some criticisms concerning conceptual as well as practical aspects of nave falsificationism and conventional , frequentistic hypothesis tests are presented , and the alternative , probabilistic approach is outlined .     </S>",
    "<S> +   + invited talk at the 2004 vulcano workshop on _ frontier objects in astrophysics and particle physics _ , vulcano ( italy ) may 24 - 29 , 2004 . </S>"
  ]
}