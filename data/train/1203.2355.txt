{
  "article_text": [
    "small - time asymptotics for the distributions of lvy processes and related markov processes have a long history going back to the seminal work of landre @xcite , who obtained the leading order term of the transition density of a markov process solving a stochastic differential equation with jumps . in the case of a lvy process , the main result of landre @xcite reads @xmath0 where @xmath1 is the marginal density of the lvy process @xmath2 and @xmath3 is the lvy density of @xmath2 , whose existence and smoothness need to be assumed . landre s approach was to consider separately the small jumps ( say , those with sizes smaller than an @xmath4 ) and the large jumps of the underlying lvy process , and to condition on the number of large jumps by time  @xmath5 .",
    "a similar approach has been applied during the last decade to obtain high - order asymptotic expansions for the transition distributions and densities of lvy processes and other markov processes with jumps ( see rschendorf and woerner  @xcite , figueroa - lpez , gong and houdr  @xcite , figueroa - lpez and houdr  @xcite , and figueroa - lpez and ouyang @xcite ) .",
    "these small - time asymptotic results have found a wide scope of applications ranging from estimation methods based on high - frequency sampling observations of the process ( see , e.g. , figueroa - lpez @xcite , comte and genon - catalot @xcite , rosenbaum and tankov @xcite , and references therein ) to asymptotic results for option prices and black  scholes volatilities in short - time ( cf .",
    "tankov  @xcite , figueroa - lpez and forde @xcite , figueroa - lpez , gong and houdr @xcite ) .    in the present paper",
    ", we adopt leandre s approach to study the asymptotic behavior of the generalized moments of the lvy process stopped at the time it exits a two - sided interval @xmath6 , conditionally on the terminal value of the process .",
    "specifically , for a lvy process @xmath7 with lvy density @xmath3 that is smooth outside any neighborhood of the origin and for a bounded lipschitz function @xmath8 , we prove that @xmath9 for any @xmath10 , where @xmath11 with @xmath12 . in the case",
    "@xmath13 , ( [ eq : intromainasympres ] ) can be written as follows : @xmath14\\dvt x_{u } \\notin(a , b)\\vert x_{t}=y \\bigr)=\\frac{t}{2 } \\int _ { ( a , b)^{c}}\\frac{s(v)s(y - v)}{s(y ) } \\,\\mathrm{d}v+\\mathrm{o}(t ) \\qquad ( t\\to 0)\\ ] ] for @xmath10 .",
    "as in the case of the small - time asymptotics for the marginal distributions of the process , the main intuition can be drawn from considering the pure - jump case with finite jump activity .",
    "intuitively , formulas ( [ eq : intromainasympres])([eq : asympexitprob ] ) tell us that if , within a small time period , a l ' evy process goes out of the interval @xmath6 and then comes back to the point @xmath15 , this essentially happens with two large jumps : the first jump takes the process out of @xmath6 , while the second jump brings it back to @xmath16 .",
    "our study of the short - time behavior of ( [ eq : intromainasympres ] ) and ( [ eq : asympexitprob ] ) is motivated by applications in the monte carlo evaluation of functionals of the form @xmath17,\\qquad",
    "\\tau= \\inf\\bigl \\{t\\geq0\\dvt x_t \\notin ( a , b)\\bigr\\}. \\label{killedlevyintro}\\end{aligned}\\ ] ] in financial mathematics , such functionals arise in structural credit risk models based on lvy processes ( fang _ et  al . _",
    "@xcite ) and in the pricing of barrier options ( cf . kou and wang @xcite , boyarchenko and levendorskii @xcite ) , which is one of the most popular classes of exotic options . very recently , a renewed interest to these problems has emerged in relation to the so - called contingent convertible bonds , where the conversion is triggered by a passage across a level and which exhibit a high sensitivity to jump risk ( corcuera _ et  al . _",
    "@xcite ) . in natural sciences , lvy processes ( under the name of lvy flights ) are used as models for certain diffusion - like phenomena in physics and chemistry ( so - called anomalous or super - diffusion ) ( metzler and klafter  @xcite , shlesinger , zaslavsky and frisch @xcite , barthelemy , bertolotti and wiersma @xcite ) as well as to describe movement patterns of foraging animals ( viswanathan _ et  al . _ @xcite , benhamou @xcite ) , and there is considerable interest toward the study of lvy flights in bounded domains and related first passage problems giving rise to functionals of type ( [ killedlevyintro ] ) ( chechkin _ et  al . _",
    "@xcite , buldyrev _",
    "et  al . _",
    "@xcite , garbaczewski and stephanovich @xcite ) . in all these settings ,",
    "closed - form expressions are rarely available and monte carlo is often the method of choice .    the simplest procedure to evaluate the functional ( [ killedlevyintro ] ) by monte carlo consists in simulating the process @xmath7 at evenly spaced times @xmath18 , with @xmath19 and @xmath20 , over the interval @xmath21 $ ] , and approximating the exit time @xmath22 by @xmath23 this simple method introduces two types of errors : the statistical error and the discretization error .",
    "the latter is known to be quite significant ( cf .",
    "baldi @xcite and example [ ex2 ] in section  [ sec : numillstr ] below ) ; metwally and atiya @xcite reports errors of up to @xmath24 in the context of barrier options for a time discretization of one point per day .    in the context of continuous diffusions ,",
    "short - time asymptotics have been successfully employed to alleviate the bias due to the discretization error .",
    "one of the earliest procedures of this type , due to baldi @xcite , is based on an approximation of the probability , @xmath25 , that the process @xmath2 has gone out of a domain @xmath6 during the small time interval @xmath26 $ ] conditioning on @xmath27 and @xmath28 ; that is , @xmath29\\dvt x_{u}\\notin ( a , b)\\vert x_{s}=x , x_{s+t}=y \\bigr).\\ ] ] given such an approximation @xmath30 of the functional @xmath25 , the procedure simulates iteratively @xmath31 at each step @xmath32 , and if @xmath33 , it proceeds to kill the process with probability @xmath34 and choose @xmath35 as an approximation of the exit time @xmath22 .",
    "a similar idea was used in moon @xcite to price barrier options with payoff @xmath36 by monte carlo .    in the context of lvy processes ,",
    "an attempt to apply a similar methodology has been made in webber @xcite , ribeiro and webber @xcite .",
    "the authors remarked that the discretization bias can be reduced by using the identity @xmath37 and replacing the exact exit probability @xmath25 with a suitable small - time approximation @xmath30 .",
    "however , these papers propose no general formula for @xmath38 and , as shown in becker @xcite , the monte carlo method proposed in webber @xcite , ribeiro and webber @xcite could lead to a large discretization bias . on the other hand , in the specific case of the parametric variance gamma model ,",
    "there exist discretization algorithms ( cf .  avramidis and lecuyer",
    "@xcite ) allowing to simulate the running minimum and maximum with error bounds .",
    "let us also remark the recent work of kuznetsov _",
    "et  al . _",
    "@xcite where a method for the joint simulation of the running maximum and the position of a lvy process is introduced based on the wiener  hopf decomposition of the process .",
    "our short - time asymptotic result ( [ eq : asympexitprob ] ) provides an approximation of the exit probability ( [ eq : gendfnexitproba ] ) via the formula @xmath39 for @xmath40 , which is valid under mild regularity conditions on the lvy process @xmath2 ( see section  [ asymp ] for details ) . the first - order approximation ( [ eq : dfnapproxexitproba0 ] ) , together with an appropriate error bound for it , enable us to develop a general adaptive monte carlo method for evaluating the functional ( [ killedlevyintro ] ) with a given precision . given a target error level @xmath41 ,",
    "the idea is to generate a `` random skeleton '' @xmath42 of the process @xmath2 such that the error in each subinterval @xmath43 $ ] , that is , @xmath44 satisfies @xmath45 .",
    "the functional ( [ killedlevyintro ] ) is then approximated as follows : @xmath46 \\approx\\bbe \\biggl({f } ( x_t ) \\prod _ { k=0}^{n-1 } \\bigl\\{1-\\tilde { p}(x_{t_{k}},x_{t_{k+1}},t_{k+1}-t_k ) \\bigr\\ } \\biggr),\\ ] ] and it is shown that the total bias of this computation will be less then @xmath41 . as a result of this adaptiveness ,",
    "the algorithm generates more frequent points when the process @xmath2 is close to the boundary , and takes large time steps ( thus saving computational time ) when the process is far from the boundary .",
    "let us remark that , unlike the formula ( [ eq : kydcmpdetermtimes ] ) , where the sampling times @xmath47 are deterministic and fixed , the decomposition ( [ eq : kydcmpfrm ] ) for random skeletons @xmath48 requires precise ( and also novel to the best of our knowledge ) conditions under which this formula holds ( see section  [ adaptive.sec ] for the details ) .    the proposed adaptive algorithm works as follows .",
    "first , the endpoint @xmath49 is generated and added to the skeleton .",
    "next , if the error ( [ eq : inierrordfn ] ) is too large for a given subinterval @xmath43 $ ] , the procedure splits the interval into two and generates the midpoint @xmath50 with @xmath51 from the bridge distribution .",
    "this is repeated iteratively until the desired error bound is satisfied for every subinterval @xmath52 $ ] of the sampling times @xmath53 .",
    "such retrospective sampling ( starting from the endpoint ) has a number of advantages over the classical uniform discretization , especially in the context of rare event simulation , where it enables one to easily implement variance reduction by importance sampling .",
    "indeed , the process can be directed to the region of interest by modifying the distribution of the terminal value , while keeping unchanged the rest of the algorithm . on the other hand",
    ", this method requires fast simulation from the bridge distribution of @xmath54 conditioned to @xmath55 . to this end , as another contribution of particular interest on its own , we also propose a new method to simulate from this lvy bridge distribution based on the classical rejection method .",
    "as previously explained , in order to implement the above adaptive algorithm , precise computable bounds for the approximation errors in ( [ eq : intromainasympres])([eq : asympexitprob ] ) are also needed .",
    "we obtain such bounds by developing explicit inequalities for the tail probabilities and transition densities of a lvy process whose lvy density has a small compact support .",
    "this type of concentration inequalities in turn allows us to estimate the different components of the error , which , as explained above , originate from conditioning the desired functional on the number of big jumps by time @xmath5 ( see section  [ estgen ] for the details ) .",
    "the resulting error bounds are given in terms of the lipschitz and @xmath56 norms of @xmath8 as well as several computable quantities related to the lvy density @xmath3 such as @xmath57 , @xmath58 .",
    "let us also remark that an adaptive simulation method similar to the one introduced in the present paper was proposed in dzougoutov _",
    "et  al . _",
    "@xcite to compute a functional of the form @xmath59 for a homogeneous diffusion process @xmath2 without jumps .",
    "adaptive numerical methods for finding weak approximation of diffusions without jumps and with finite intensity jumps ( but with the adaptiveness only concerning the diffusion part ) have also been proposed in szepessy , tempone and zouraris @xcite and mordecki _",
    "et  al . _",
    "@xcite , respectively . as in our paper",
    ", the idea therein is to sample from inside of a subinterval @xmath60 $ ] whenever the approximation error in that subinterval has not reached a desired low level , specified by the user .",
    "the paper is organized as follows . in section  [ asymp ]",
    ", we obtain the leading term of the functional @xmath61 when @xmath62 .",
    "the explicit estimate of the approximation error is given in section  [ estgen ] .",
    "the development of the adaptive discretization schemes for the monte carlo computation of the functional @xmath63 $ ] as well as the algorithm to simulate random observations from the l ' evy bridge distribution are given in section  [ adaptive.sec ] .",
    "our methods are illustrated numerically in section  [ sec : numillstr ] for cauchy process .",
    "finally , the proofs of the technical results are deferred to the .",
    "let @xmath2 be a real - valued lvy process on a probability space @xmath64 with lvy triplet @xmath65 with respect to truncation function @xmath66 . throughout",
    ", @xmath67 denotes the natural filtration generated by the process @xmath2 and augmented by the null sets of @xmath68 so that it satisfies the usual conditions ( see , e.g. , chapter i.4 in protter @xcite ) .",
    "the following standing assumptions are imposed throughout the paper :    * the lvy measure @xmath69 admits a continuously differentiable density @xmath70 , with respect to the lebesgue measure ( hereafter denoted by @xmath71 ) , which satisfies , for any @xmath4 , @xmath72 * the distribution of @xmath73 admits a density @xmath74 for all @xmath75 .",
    "since @xmath69 is already assumed to admit a density , for this assumption to hold , it suffices to additionally require that @xmath76 or @xmath77 ( see theorem 27.7 in sato  @xcite ) . *",
    "the density of @xmath78 satisfies @xmath79 for all @xmath80 and @xmath81 ( see theorem 24.10 in sato  @xcite for mild sufficient conditions for this property to hold ) .",
    "as it is usually done with lvy processes , we shall decompose @xmath2 into a compound poisson process and a process with bounded jumps . more specifically , for any @xmath82 , we select a function @xmath83 , which is decreasing on @xmath84 and increasing on @xmath85 and such that @xmath86 .",
    "next , we define the truncated lvy densities @xmath87 with @xmath88 .",
    "let @xmath89 be a compound poisson process with lvy measure @xmath90 and @xmath91 be a lvy process , independent from @xmath89 , with characteristic triplet @xmath92 , where @xmath93 it is clear that @xmath94 has the same law as @xmath2 and that the intensity and probability density of the jumps of @xmath95 are @xmath96 and @xmath97 , respectively . throughout the paper ,",
    "we let @xmath98 be the jump counting process of @xmath99 and @xmath100 be the jump sizes of @xmath99 .",
    "thus , @xmath101 note that the distribution of @xmath102 is also absolutely continuous since @xmath77 or @xmath103 , for any @xmath4 . for future reference ,",
    "let us remark that @xmath104 \\\\[-8pt ] \\nonumber \\operatorname { var } \\bigl(x^{\\varepsilon}_{t } \\bigr)&=&t \\biggl ( \\sigma^{2}+\\int x^{2}\\bar{s}_{\\varepsilon}(x)\\,\\mathrm{d}x \\biggr)= : t \\sigma_{\\varepsilon}^{2},\\end{aligned}\\ ] ] since @xmath82 ( see , e.g. , example 25.12 in sato @xcite for the mean and variance formulas of a lvy process ) .",
    "the following lemma will be needed in what follows ( cf .",
    "propositions i.4 and iii.2 in landre  @xcite ) .",
    "see also sections  [ sprmbnd][subs : bnddstysmjmp ] below for explicit expressions for the constants @xmath105 and @xmath106 .",
    "[ kylm1 ] let @xmath107 be the transition density of the small - jump component process @xmath108 .",
    "then , for any fixed positive real @xmath109 and positive integer @xmath110 , there exist an @xmath111 and positive constants @xmath112 , @xmath106 , and @xmath113 for any @xmath114 such that @xmath115 for all @xmath116 and @xmath117 .",
    "the following result provides the key tool for establishing the small - time asymptotics of the moments of the lvy bridge `` stopped '' at the exit time from an interval @xmath6 .",
    "its proof is presented in appendix [ sec : proofth : stbs ] .",
    "[ th : stbs ] for fixed constants @xmath118 and @xmath119 $ ] , define @xmath120 let @xmath121 be bounded and lipschitz on @xmath122 and let @xmath123 .",
    "then , for any @xmath124 and @xmath125 , @xmath126 where the remainder term @xmath127 is such that @xmath128    [ estextprob ] by the definition of conditional expectation , @xmath129 \\\\[-8pt ] \\nonumber & = & \\int_{{y-\\delta}}^{y+\\delta } \\bbe \\bigl ( \\varphi(x_{\\tau})\\mathbf{1}_{\\{\\tau\\leq t\\}}\\vert x_{t}=u \\bigr ) f_{t}(u ) \\,\\mathrm{d}u,\\end{aligned}\\ ] ] where @xmath130 is the density of @xmath73 and , as usual , @xmath131 is such that @xmath132 is a version of @xmath133 . comparing ( [ dmbcer ] ) and ( [ eq : fmr ] ) , it then follows that , for @xmath71-a.e .",
    "@xmath15 , @xmath134 if , in addition , the transition density @xmath74 satisfies the asymptotic formula ( [ eq : asymdstypurelevy ] ) ) holds for a large class of markov processes with jumps as proved by landre @xcite . for lvy processes , rschendorf and",
    "woerner @xcite provided a more elementary proof using the same conditions and similar approach as in landre @xcite .",
    "higher order short - time expansions for the transition densities were obtained in figueroa - lpez , gong and houdr @xcite . ] then , for @xmath71-a.e .",
    "@xmath10 , @xmath135 formulas ( [ eq : fmr ] ) and ( [ condovershoot ] ) can be interpreted as large deviation results for the trajectories of lvy processes in small time .",
    "when @xmath136 , ( [ condovershootdens2 ] ) gives the following small - time approximation for the exit probability of the l ' evy bridge : @xmath137    we conclude this section with a simpler result for the case when @xmath78 is outside the interval . its proof is outlined in appendix [ sec : proofth : stbs ] .",
    "[ th : y_out ] let @xmath138 be bounded and lipschitz on @xmath139 , and let @xmath140 . then , under the same notation and conditions as in theorem [ th : stbs ] , for any @xmath141 and @xmath142 , @xmath143 where the remainder term @xmath127 is such that @xmath144    [ estextprob2 ] analogously to remark [ estextprob ] , ( [ eq : fmrsmplcse ] ) enables us to establish the following natural asymptotic formula : @xmath145 for @xmath71-a.e .",
    "@xmath146^{c}$ ] .",
    "the second equality above holds whenever @xmath147 satisfies ( [ eq : asymdstypurelevy ] ) .",
    "in the previous section , we developed the necessary results for finding estimates of the functional @xmath148\\ ] ] in short - time . indeed , as explained in remark [ estextprob ] , theorem [ th : stbs ] yields the following natural estimate for @xmath149 : @xmath150 the estimate ( [ eq : frstdfnestkf ] ) will be used below to develop adaptive discretization schemes for the monte carlo computation of functionals of the killed lvy process ( see section  [ adaptive.sec ] ) . to this end",
    ", we first need to find an explicit estimate for the remainder @xmath151 appearing in ( [ eq : fmr ] ) .",
    "such an estimate can be expressed in terms of bounds for the tail probability and transition densities of the small - jump component @xmath108 .",
    "hence , we start by providing explicit expressions for the upper bounds appearing in ( [ kyinbn ] ) and then proceed to give a precise error bound for @xmath152 .      the following exponential inequality for lvy processes with bounded jumps will be important to estimate the supremum of the small - jump component @xmath153 defined in section  [ asymp ] .",
    "its proof , which is provided in appendix [ ap : prferrbnd ] for completeness , is a variation of the bound obtained in rschendorf and woerner @xcite ( which in turn is based on lemma 26.4 in sato @xcite ) .",
    "[ lmm : ktpbnd ] let @xmath154 be a martingale lvy process with @xmath155 and @xmath156 .",
    "then , @xmath157 with the following constants @xmath158 and corresponding conditions :    1 .",
    "@xmath159 for all @xmath160 and @xmath161 ( with the convention here and below that the fraction is @xmath162 if the denominator is zero ) ; 2 .",
    "@xmath163 for all @xmath160 and @xmath164 if either @xmath165 or @xmath166 and @xmath167 ;    in order to apply lemma [ lmm : ktpbnd ] for @xmath168 , we recall that @xmath169 so that @xmath170",
    ". then , the martingale part @xmath171 of @xmath172 is such that @xmath173 thus , fixing @xmath174 it follows that , for all @xmath175 , @xmath176 with @xmath177 is defined by @xmath178 similarly , we have @xmath179 .      to obtain explicit expressions for the constants appearing in the bounds for the density @xmath107 in lemma [ kylm1 ]",
    ", we shall assume that the process @xmath2 is such that @xmath180 has a unimodal distribution for all @xmath81 and @xmath4 .",
    "by yamazato s theorem ( see theorem 53.1 in sato @xcite ) , a sufficient condition for this is that the process @xmath2 is self - decomposable , which is the case if and only if the lvy density @xmath3 is of the form @xmath181 for a function @xmath182 which is increasing on @xmath183 and decreasing on @xmath85 ( see corollary 15.11 in sato @xcite ) . in particular , most of the parametric models used in the literature ( such as stable , tempered stable , variance gamma , and normal inverse gaussian processes ) are self - decomposable and so these processes as well as their truncated versions have unimodal densities at all times .",
    "let @xmath184 be the mode of @xmath102 . if @xmath185 $ ] and @xmath186 , then the density can be estimated by @xmath187,\\ ] ] simply because the density is decreasing in @xmath188 and increasing in @xmath189 .",
    "the relation  ( [ eq : bnd1 ] ) in turn leads to a bound of the form ( [ kyinbn])(ii ) by applying the tail bound ( [ kyinbn])(i ) .",
    "it remains to find conditions for @xmath190 $ ] .",
    "since obviously @xmath172 has finite second moment , the following bound due to johnson and rogers @xcite can be applied @xmath191 thus , recalling the mean and variance formulas given in ( [ frmlmnvarsc ] ) , @xmath192 $ ] whenever @xmath193 , where @xmath194 is such that @xmath195 by taking @xmath196 , we will have @xmath197\\leq \\frac{8 c(\\eta/4,\\varepsilon)}{\\eta } t^{{{\\eta}/{(2\\varepsilon)}}}\\ ] ] for any @xmath198 with @xmath199 defined as in ( [ eq : dfncnstest ] ) .",
    "we are now ready to give an explicit bound for the reminder term @xmath151 appearing in ( [ eq : fmr ] ) , which in turn will produce an error bound for @xmath152 . throughout",
    ", we shall use the following notation :    @xmath200 and @xmath201 , where , as before , @xmath202 is the lvy density @xmath3 , truncated in a neighborhood of the origin ;    @xmath203 , @xmath204 , and @xmath205 ;    @xmath177 is defined as in ( [ cgammaeps ] ) , @xmath206 is defined as in ( [ eq : dfncnstest ] ) , and @xmath207 is defined as in  ( [ eq : dfnt_1 ] ) .",
    "the following result , whose proof is given in appendix [ ap : prferrbnd ] , gives an estimate for @xmath151 in terms of the previously defined notation and the @xmath56- and lipschitz norms of @xmath8 denoted hereafter by @xmath208 using the notation of theorem [ th : stbs ] , assume that the process @xmath2 is such that @xmath180 has a unimodal distribution for all @xmath81 and @xmath4 .",
    "let @xmath209 and @xmath210 .",
    "then , @xmath211 for all @xmath212 , where @xmath213 \\\\[-8pt ] \\nonumber   & & { } + \\frac{\\|\\varphi\\|_\\infty\\lambda_{\\varepsilon}^{2 } a_{\\varepsilon}}{2 } t^{3}+\\|\\varphi \\|_\\infty a_{\\varepsilon}\\lambda _ { \\varepsilon}^{-1 } \\bigl(1 -\\mathrm{e}^{-\\lambda_{\\varepsilon}t}\\bigl[1+\\lambda_{\\varepsilon}t+ ( \\lambda_{\\varepsilon}t)^{2}/2 \\bigr ] \\bigr ) \\\\ & & { } + \\mathrm{e}^{-\\lambda_{\\varepsilon}t}t^{2 } \\bigl[a_{\\varepsilon}\\lambda_{\\varepsilon } \\|\\varphi\\|_\\mathrm { lip}+ { 2}\\|\\varphi\\|_{\\infty}a_{\\varepsilon}^{2}+ \\|\\varphi\\|_{\\infty}\\lambda _ { \\varepsilon}a_{\\varepsilon } ' \\bigr]\\biggl(\\sigma_{\\varepsilon}t^{1/2 } + \\frac{|{\\mu_\\varepsilon}|}{2 } t\\biggr ) . \\nonumber\\end{aligned}\\ ] ]    two immediate conclusions can be drawn .",
    "first , note that , by taking @xmath214 , we obtain a bound for the remainder satisfying condition ( [ eq : rmdbhv ] ) .",
    "second , as seen in remark [ estextprob ] , the previous bound implies the following error bound @xmath215 with @xmath216 and @xmath217 defined as in ( [ eq : frstdfnkf])([eq : frstdfnestkf ] ) .",
    "[ rem : apprxexitproba ] the approximation for the conditional exit probability @xmath218 $ ] is obtained by substituting @xmath219 into ( [ condovershoot ] ) : @xmath220 making this substitution in the previous bound , it follows that @xmath221 with @xmath222 given by @xmath223 \\\\[-8pt ] \\nonumber & & \\hspace*{28pt } { } + a_{\\varepsilon}\\lambda_{\\varepsilon}^{-1 } \\bigl(1 -\\mathrm{e}^{-\\lambda_{\\varepsilon}t}\\bigl[1+\\lambda_{\\varepsilon}t+ ( \\lambda_{\\varepsilon}t)^{2}/2 \\bigr ] \\bigr ) \\\\ & & \\hspace*{28pt } { } + \\mathrm{e}^{-\\lambda_{\\varepsilon}t}t^{2 } \\bigl [ { 2}a_{\\varepsilon}^{2}+ \\lambda_{\\varepsilon}{a'_{\\varepsilon } } \\bigr]\\biggl ( \\sigma_{\\varepsilon}t^{1/2 } + \\frac{|{\\mu_\\varepsilon}|}{2 } t\\biggr ) \\biggr ) , \\nonumber\\end{aligned}\\ ] ] valid for all @xmath224 .",
    "the one - sided case ( @xmath225 ) can similarly be obtained .",
    "our goal in this section is to design a type of adaptive monte carlo estimators for functionals of the form @xmath226 , \\label{killed}\\ ] ] where @xmath227 is a borel measurable function and @xmath228 with @xmath229 , for some @xmath118 and @xmath119 $ ] . from now on , to simplify notation and with no loss of generality , we shall take @xmath230 .    for @xmath231 , @xmath232 , and @xmath233 ,",
    "we denote by @xmath234 $ ] the bridge law of the lvy process  @xmath2 on the time interval @xmath235 $ ] with starting value @xmath236 and terminal value @xmath16 ; that is , this is a version of the regular conditional distribution of @xmath237}$ ] given @xmath238 . since @xmath78 has a strictly positive density on @xmath239 for every @xmath81 , the bridge law",
    "is uniquely defined for @xmath71-almost every @xmath233 ( recall that @xmath71 stands for the lebesgue measure ) , which is sufficient for our purposes .",
    "we also let @xmath25 denote the exit probability from the domain @xmath240 before time @xmath5 for the lvy bridge : @xmath241 = \\bbp \\bigl[\\exists u\\in[0,t]\\dvt x+x_{u}\\notin(a , b)\\vert x_{t}=y \\bigr].\\ ] ]    our approach is based on the following decomposition : @xmath242=\\bbe \\biggl[{f } ( x_1)\\prod_{i=0}^{n-1 } \\bigl(1-{p}(x_{t_{i}},x_{t_{i+1}},t_{i+1}-t_{i } ) \\bigr ) \\biggr],\\ ] ] where @xmath243 are suitable sampling times .",
    "formula ( [ eq : dtrmtmcs ] ) directly follows from the markov property when the sampling points are deterministic . in that case , the set of points @xmath244 is called a deterministic skeleton . in our setting , both the number of points  @xmath245 and the sampling times @xmath246 are random and we need to formalize under what conditions on @xmath247 ( [ eq : dtrmtmcs ] ) still holds",
    ". the following result will suffice for our purposes .",
    "[ lm : skltn ] let @xmath245 be a random variable with support @xmath248 , such that @xmath249 , and let @xmath243 be random points such that    1 .",
    "each @xmath250 takes values in a countable set @xmath251 $ ] ; 2 .   for each @xmath252 and @xmath253 with @xmath254 ,",
    "the event @xmath255 is @xmath256-measurable .    then , ( [ eq : dtrmtmcs ] ) is satisfied for any measurable function @xmath257 with @xmath258<\\infty$ ] and , furthermore , for every @xmath259 , @xmath260 , and @xmath261 , @xmath262 = \\mathbb p^{\\mathrm{br}}_{t_{i^ * } , t_{i^*+1 } , x_{t_{i^*}},x_{t_{i^*}+1 } } [ x_t \\in a ] , \\end{aligned}\\ ] ] where @xmath263 .    throughout",
    ", we let @xmath264 , @xmath265 , @xmath266 $ ] , and @xmath267 $ ] , with @xmath268 .",
    "we also use the notation @xmath269 then , by markov property @xmath270\\\\   & & \\quad=\\sum _ { n\\in\\caln}\\sum_{(s_{0},\\ldots , s_{n})\\in\\vec\\calk^{n } } \\mathbb e \\bigl[{f } ( x_1 ) \\cali_{[0,1]}\\mathbf{1}_{\\{{n}=n,(t_{0},\\ldots , t_{n})=(s_{0},\\ldots , s_{n})\\ } } \\bigr ] \\\\ & & \\quad=\\sum_{n\\in\\caln}\\sum_{(s_{1},\\ldots , s_{n})\\in\\vec\\calk^{n } } \\mathbb e \\biggl[{f } ( x_1)\\mathbf{1}_{\\{{n}=n,(t_{0},\\ldots , t_{n})=(s_{0},\\ldots , s_{n})\\}}\\bbe \\biggl[\\prod_{i=0}^{n-1 } \\cali_{u_{i } } |x_{s_{j}}\\dvt j=0,\\ldots , n \\biggr ] \\biggr ] \\\\ & & \\quad=\\sum_{n\\in\\caln}\\sum_{(s_{1},\\ldots , s_{n})\\in\\vec\\calk^{n } } \\mathbb e \\biggl[{f } ( x_1)\\mathbf{1}_{\\{n = n,(t_{0},\\ldots , t_{n})=(s_{0},\\ldots , s_{n})\\}}\\prod_{i=0}^{n-1 } \\bar { p } ( x_{t_{i}},x_{t_{i+1}},t_{i+1}-t_{i } ) \\biggr ] \\\\ & & \\quad = \\mathbb e \\biggl[{f}(x_1)\\prod_{i=0}^{n-1 } \\bar{p } ( x_{t_{i}},x_{t_{i+1}},t_{i+1}-t_{i } ) \\biggr],\\end{aligned}\\ ] ] which proves ( [ eq : dtrmtmcs ] ) . similarly , @xmath271 $ ]",
    "can be decomposed as @xmath272 \\mathbf1 _ { ( t_0,\\ldots , t_n ) = ( s_0,\\ldots , s_n ) } \\\\ & & \\qquad = \\sum_{(s_{0},\\ldots , s_{n})\\in\\vec\\calk^{n } } \\mathbb p^{\\mathrm{br}}_{s_{i^ * } , s_{i^*+1 } , x_{s_{i^*}},x_{s_{i^*}+1}}[x_t \\in a]\\mathbf1_{(t_0,\\ldots , t_n ) = ( s_0,\\ldots , s_n ) } \\\\ & & \\qquad = \\mathbb p^{\\mathrm{br}}_{t_{i^ * } , t_{i^*+1 } , x_{t_{i^*}},x_{t_{i^*}+1}}[x_t \\in a].\\end{aligned}\\ ] ]    from ( [ eq : dtrmtmcs ] ) , it is now evident that , for the computation of ( [ killed ] ) by monte carlo , it suffices to simulate independent replicas of the random variable @xmath273 , where hereafter we denote @xmath274 the exit probability @xmath25 does not typically admit a closed form expression and some type of approximation must be applied for its evaluation .",
    "the short - time asymptotics ( [ condovershoot ] ) yields the following natural estimate for @xmath25 when @xmath275 : @xmath276 we also set @xmath277 if @xmath278 or @xmath279 .",
    "this approximation satisfies @xmath280 where the error bound @xmath281 is defined as in remark [ rem : apprxexitproba ] for @xmath275 and by @xmath282 if @xmath278 or @xmath279 .",
    "we can then approximate @xmath283 by @xmath284    replacing the true exit probability @xmath25 with its approximation @xmath38 introduces a bias into the evaluation of @xmath285 , which is hard to quantify if the process @xmath2 is discretized using the uniformly spaced grid @xmath286 .",
    "for this reason , we now propose an adaptive algorithm for the determination of the sampling times , which starts by simulating the terminal value @xmath287 and then refines the sampling grid , using more discretization points when the estimate of the approximation error is `` large '' .",
    "the algorithm is parameterized by a real number @xmath288 , which represents the error tolerance and ensures that under suitable conditions on @xmath289 , the global discretization error for approximating the quantity of interest ( [ killed ] ) will be bounded by @xmath290 ( see proposition [ biasprop ] below ) .",
    "the algorithm also requires simulation from the marginal distribution @xmath291 of @xmath292 and the bridge distribution of @xmath54 conditioned to @xmath55 ( @xmath81 ) .",
    "hereafter , we denote the density of this bridge distribution by @xmath293 and recall the following well - known formula : @xmath294 at the end of this section , we introduce a new method to simulate variates from the density ( [ eq : brddsity1 ] ) .",
    "[ constrskeleton ]    @xmath295 , @xmath296 , @xmath297 @xmath298 , @xmath299 , @xmath300 generate an observation @xmath287 from the density @xmath291 @xmath301 , @xmath302 @xmath303 @xmath304 , @xmath305 generate an observation @xmath306 from the bridge density @xmath307 @xmath308 @xmath309 @xmath310 return @xmath311 .    the procedure to generate the skeleton of @xmath2",
    "is outlined in pseudo - code in algorithm [ constrskeleton ] below .",
    "assume that this algorithm terminates in finite time a.s .",
    "( see proposition [ biasprop ] for sufficient conditions for this to hold ) .",
    "the algorithm then defines a pair @xmath245 and @xmath312 , which satisfies the conditions of lemma [ lm : skltn ] .",
    "indeed , by construction , each @xmath250 takes values in the dyadic grid @xmath313 , which is a countable set . to check the second condition of the lemma",
    ", we fix @xmath314 and a partition @xmath315 of @xmath316 $ ] , and proceed as follows to write the event @xmath317 in terms of @xmath318 :    * we can and will assume with no loss of generality that @xmath319 is a _ recursive dyadic partition _ , meaning that @xmath320 and , for every @xmath321 , there exists @xmath322 with @xmath323 , and if we take the smallest such @xmath182 then also @xmath324 and @xmath325 . by construction , if @xmath319 does not have this property , the event @xmath326 has zero probability .",
    "* we shall assume that @xmath327 because if @xmath328 then necessarily @xmath329 and @xmath330 and , therefore , @xmath331 * for each @xmath332 , define @xmath333 .",
    "the number of elements of @xmath334 is denoted @xmath335 and the sorted elements of @xmath334 are denoted @xmath336 . clearly , @xmath337 and @xmath338 since @xmath339 whenever @xmath327 ; we let @xmath340 and @xmath341 .",
    "* for each @xmath342 , define the event @xmath343 if @xmath344 ; otherwise , we set @xmath345 then it follows that @xmath346 which clearly belongs to @xmath256 .    to see that @xmath306 can be sampled from the bridge density @xmath347 in algorithm  [ constrskeleton ]",
    ", we can apply the second part of lemma [ lm : skltn ] to the couple @xmath348 , where @xmath349 contains the first @xmath350 sampling times which have been added to the grid by the algorithm , in increasing order .",
    "algorithm [ constrskeleton ] terminates when at least one of the sampling observations @xmath351 is out of the domain @xmath240 or the error over each subinterval of the sampling times @xmath352 is small enough in the following sense : @xmath353 at first glance , it is not obvious that the algorithm will actually terminate in finite time .",
    "the following result gives conditions under which this is the case and shows that the global error of the estimate is of order @xmath41 .",
    "[ biasprop ] the following assertions hold :    a.   let @xmath2 be a lvy process satisfying one of the following two ( non - mutually exclusive ) conditions : 1 .",
    "@xmath2 does not hit points ; that is , @xmath354 for all @xmath236 , where @xmath355 or , equivalently , @xmath356 where @xmath357 $ ] ( see kyprianou @xcite , theorem 7.12 ) ; 2 .",
    "@xmath2 is a finite variation process .",
    "+ additionally , assume that the upper bound of the approximation error @xmath281 satisfies @xmath358 then , algorithm [ constrskeleton ] terminates in finite time a.s .",
    "b.   assume that @xmath359 .",
    "let @xmath360 be a skeleton of @xmath2 on @xmath316 $ ] satisfying ( [ errcontrol ] ) and @xmath361 be given by ( [ eq : apprxprodmc ] ) . then",
    ", @xmath362 - \\bbe \\bigl[{f}(x_1 ) \\tilde",
    "n(\\mathcal x)\\bigr]\\bigr| \\leq{\\gamma } \\bbe \\bigl[\\bigl|{f}(x_1)\\bigr|\\bigr].\\label{algoerr}\\end{aligned}\\ ] ]    [ betterbias ] in view of proposition [ biasprop ] , @xmath363 $ ] can be approximated by the monte carlo estimator @xmath364 where @xmath365 are independent copies of the process @xmath2 and @xmath366 are corresponding values computed with formula ( [ eq : apprxprodmc ] ) .",
    "this estimator has a statistical error which can be estimated in the usual way , and a discretization bias , which is bounded from above by @xmath367 $ ] . in view of ( [ precisebias ] ) below ,",
    "a more precise a posteriori estimate of the bias is @xmath368 with @xmath369 .",
    "[ jumplemma ] let @xmath2 be a lvy process such that for all @xmath81 , the law of @xmath78 has no atom . then , for all @xmath232 , @xmath370\\dvt \\delta x_t \\neq0 , x_{t- }",
    "= x\\bigr\\ } = \\varnothing\\bigr ] = 1 ; \\qquad\\mathbb p\\bigl[\\bigl\\{t \\in[0,1]\\dvt \\delta x_t \\neq0 , x_{t } = x\\bigr\\ } = \\varnothing \\bigr ] = 1.\\end{aligned}\\ ] ]    we only prove the first identity , the second one follows by similar arguments ( or alternatively by time reversal ) .",
    "let @xmath371\\dvt |\\delta x_t| > \\varepsilon , x_{t- } = x\\}$ ] .",
    "then @xmath372\\dvt \\delta x_t \\neq0 , x_{t- } = x\\bigr\\ } \\neq\\varnothing\\bigr ] \\leq\\mathbb e \\bigl[n^0_1\\bigr ] \\leq\\sum_{n=1}^\\infty \\mathbb e\\bigl[n^{{1}/{n}}_1\\bigr].\\ ] ] but by the compensation formula ( see bertoin @xcite , section  0.5 ) , @xmath373 = \\mathbb e \\biggl[\\int _ 0 ^ 1 \\int_{|y|>\\varepsilon } \\mathbf{1}_{x_s = x } \\nu(\\mathrm{d}y ) \\,\\mathrm{d}s \\biggr ] = \\int_{|y|>\\varepsilon } \\nu(\\mathrm{d}y ) \\int_0 ^ 1 \\mathbb p[x_s = x ] \\,\\mathrm{d}s = 0.\\ ] ]    proof of proposition [ biasprop ] _ part _",
    "( i ) . with the aim of obtaining a contradiction ,",
    "assume that the statement of the proposition is not true , and the algorithm does not terminate . let @xmath374 be the infinite sequence of different sampling times produced by the algorithm ( in the order in which they were generated , that is , not necessarily ordered in time ) .",
    "let @xmath375 be the corresponding sampling observations .",
    "since the sequence @xmath376 is bounded , we can find indices @xmath377 such that @xmath378 .",
    "moreover , since every point @xmath379 ( for @xmath380 ) is obtained as a midpoint of a certain interval , we can find two sequences @xmath381 and @xmath382 such that @xmath383 , @xmath384 , @xmath385 $ ] for all @xmath386 and @xmath387 for all @xmath386 .",
    "in addition , since the process @xmath2 has right and left limits , both @xmath388 and @xmath389 exist .",
    "there are three possibilities .    if @xmath390 or @xmath391 then for some @xmath386 , @xmath392 , so that the algorithm must have stopped in finite time and we have a contradiction .",
    "if @xmath393 and @xmath394 then , using the property ( [ errbound ] ) , we can find a contradiction with @xmath387 .",
    "it remains to treat the case when @xmath395 or @xmath396 , or both , are at the boundary of @xmath240 .",
    "then , either @xmath397 or @xmath398 .",
    "the latter case is ruled out by lemma [ jumplemma ] and in the case when @xmath2 can not hit points , the former case is ruled out as well .",
    "we may therefore assume that @xmath2 is a finite variation process with nonzero drift @xmath399 ( cf .",
    "kyprianou @xcite , theorem 7.12 ) and , to fix the notation , that @xmath400 .",
    "we may also assume that @xmath401 is irrational , since for every @xmath402 $ ] , @xmath403 = 0 $ ] .",
    "the fact that @xmath404 implies that @xmath405 for every @xmath386 , and we can also assume that @xmath406 and @xmath407 belong to @xmath240 for each @xmath386 , because otherwise the algorithm would have stopped in finite time .",
    "introduce two sequences of stopping times : @xmath408 with @xmath409 .",
    "the sequences @xmath410 and @xmath411 do not have an accumulation point except @xmath412 and for each @xmath413 , @xmath414 if @xmath415 and @xmath416 if @xmath417 . this holds because for a finite variation process @xmath2 with drift @xmath418 , @xmath419 is irregular for @xmath420 if @xmath421 and for @xmath422 $ ] if @xmath166 ( sato @xcite , theorem 43.20 ) , and @xmath2 may only creep in the direction opposite to the drift ( kyprianou @xcite , theorem 7.11 ) . then clearly , for every @xmath423 $ ] such that @xmath424 , either there is @xmath413 with @xmath425 , which means that for some @xmath4 , @xmath426 for @xmath427 , or there is @xmath413 with @xmath428 , which means that for some @xmath4 , @xmath426 for @xmath429 . in both cases , there is a contradiction with the fact that @xmath406 and @xmath407 belong to @xmath240 for each @xmath386 .",
    "_ part _ ( ii ) .",
    "below , we denote @xmath430 , @xmath431 , and @xmath432 .",
    "then , since @xmath433 we get @xmath434 - \\bbe \\bigl[{f}(x_1)\\tilde n(\\mathcal x)\\bigr]\\bigr| \\leq\\bbe \\biggl[\\bigl|{f}(x_1)\\bigr|{\\mathbf{1}}_{s_n}\\sum _ { i=0}^{n-1 } { e_p(x_{t_{{i}}},x_{t_{{i+1 } } } , t_{{i+1}}-t_{{i } } ) } \\biggr],\\end{aligned}\\ ] ] which can be bounded by @xmath435 $ ] .    _ simulation of lvy bridges .",
    "_ the adaptive method presented in this section requires fast simulation from the bridge distribution of @xmath54 conditioned to @xmath55 ( with @xmath81 ) , whose density is given by ( [ eq : brddsity1 ] ) .",
    "we now propose a simple yet efficient method for simulating from the bridge distribution , valid for lvy processes with unimodal density at all times .",
    "as remarked in section  [ estgen ] , a sufficient condition for a lvy process to have a unimodal density for all @xmath81 is that it belongs to the class of self - decomposable processes which includes most of the parametric models used in the literature .",
    "the algorithm is based on the following simple estimate .",
    "let @xmath2 be a lvy process such that the density @xmath436 of @xmath78 is unimodal for all @xmath81 .",
    "then , @xmath437    for all @xmath236 and @xmath16 , @xmath438 by the assumption of unimodality , the density @xmath436 may not have a local minimum , hence , for all @xmath439 , @xmath440 and the result follows .    as a consequence of the previous result , random variates with density @xmath441",
    "can be simulated using the classical rejection method ( devroye @xcite ) , with the proposal density given by @xmath442 , provided that the following two requirements are met :    * random variates with density @xmath443 can be simulated in bounded time ; * the density @xmath443 is known explicitly or can be evaluated in bounded time .",
    "assumptions ( a ) and ( b ) are satisfied , for example , for the variance gamma process , normal inverse gaussian process , or for stable processes . simulating a random variable @xmath2 with density @xmath444 is straightforward : simulate a random variate @xmath445 with density @xmath446 and an independent bernoulli random variate @xmath447 ; then , take @xmath448 if @xmath449 and @xmath450 otherwise .    the expected number of iterations needed until the acceptance for a given value of @xmath16 is equal to @xmath451 .",
    "this number is bounded for lvy processes with pareto tails such as stable . for processes with lighter tails",
    ", it may be unbounded for large @xmath16 , but the probability of having a large value of @xmath16 in an adaptive simulation is very small .",
    "for example , if we want to simulate @xmath54 and @xmath78 by first simulating @xmath78 and then @xmath54 from the bridge law using formula ( [ rejimproved ] ) , we find that the conditional expectation of the number of iterations given @xmath78 equals @xmath452 , and the unconditional expectation is @xmath453 = 2\\int_{\\mathbb r } { f}_{t/2}(x/2)\\,\\mathrm{d}x = 4.\\ ] ]",
    "in this section , to simplify the discussion , we assume that the interval @xmath240 is of the form @xmath454 . for the numerical implementation of algorithm [ constrskeleton ] given in section  [ adaptive.sec ] , one needs to be able to perform the following computations efficiently :    * simulation of the increments of @xmath78 for arbitrary @xmath5 ; * evaluation of the density @xmath455 of @xmath78 for arbitrary @xmath5 ; * evaluation of the `` incomplete convolution '' of the lvy density : @xmath456 ; * evaluation of the error bound @xmath281 , appearing in algorithm [ constrskeleton ] .",
    "these computations can be performed relatively easily , for example , for @xmath457-stable lvy processes with lvy density @xmath458 and for the variance gamma process with lvy density latexmath:[$s(x ) = |x|^{-1}(c\\mathrm{e}^{-\\lambda_- |x|}{\\mathbf{1}}_{x<0 } + c\\mathrm{e}^{-\\lambda_+    the increments can be simulated with an explicit algorithm ( cf .",
    "chambers , mallows and stuck @xcite ) , the density can be computed using a rapidly convergent series ( samorodnitsky and taqqu @xcite ) or expressed via special functions ( cf . grska and penson @xcite ) , tabulated for @xmath412 and computed by the scaling property for other values of @xmath5 .",
    "the incomplete convolution is given by @xmath460 where @xmath461 is the beta function and @xmath257 is the hypergeometric function , for which a rapidly converging series is available ( gradshetyn and ryzhik @xcite ) and which can also be tabulated prior to the monte carlo computation . for the variance gamma process , the density is explicit and the increments are straightforward to simulate ( cont and tankov @xcite ) .",
    "the incomplete convolution is given by @xmath462 where @xmath463 , which can also be tabulated , and @xmath464 .",
    "the error bound @xmath289 for the @xmath457-stable or the variance gamma process can be obtained along the lines of the general computation of section  [ estgen ] or the specific computation for the cauchy process in the appendix [ cauchy.sec ] .    for the numerical simulations in this section",
    ", we shall concentrate on the cauchy process , which is an @xmath457-stable process with @xmath465 and @xmath466 .",
    "for this process , formula ( [ stableconv ] ) simplifies to @xmath467 note that for small @xmath16 , the series representation has more stable behavior than the exact formula .",
    "the error estimate @xmath289 is computed as explained in section  [ cauchy.sec ] of the . in both examples",
    "below , we take @xmath468 .",
    "[ ex1 ] in our first example , we evaluate the probability @xmath469=\\bbp(\\tau>1)$ ] , which can be expressed in terms of the function ( [ killed ] ) by taking @xmath230 , @xmath470 , and the domain @xmath471 .",
    "note that in this case , the starting value of the process is relatively far from the boundary , and hence the advantage of using the adaptive algorithm is less important .",
    "the process will typically cross the boundary by a large jump with a large overshoot , which makes the exit easy to detect , even with a uniform discretization .",
    "we study the performance of our adaptive algorithm for various values of @xmath290 , and compare it to the standard uniform discretization .",
    "when interpreting the results of simulations , one needs to distinguish between the actual error ( i.e. , the difference between the computed value and the true value ) , and the theoretical value of the bias ( computed as explained in remark [ betterbias ] above ) , which does not require the knowledge of the true value . as an estimate of the true value , we use the value computed in an independent simulation by uniform discretization with 16384 points and @xmath472 trajectories , which is approximately equal to @xmath473 with a standard deviation of @xmath474 . the difference between the values for 8192 and 16384 points ( on the same trajectories ) is smaller than @xmath474 , hence one can presume that , for all practical purposes , convergence up to this precision has been achieved .    figure  [ actual.fig ] shows the dependence of the values computed by the two algorithms on the computational time required for @xmath475 mc trajectories , for different numbers of discretization points ( for the uniform discretization ) and different values of the tolerance parameter @xmath290 ( for the adaptive algorithm ) . while the uniform discretization algorithm exibits a clear bias which decreases as the number of discretization dates increases , the adaptive algorithm removes the bias completely ; all values returned by this algorithm are within confidence bounds of the true value .    .",
    "left : values returned by the uniform discretization algorithm and the adaptive algorithm , as function of the computational time for @xmath475 paths , measured in seconds .",
    "different points on the graph correspond to different numbers of discretization dates for the uniform discretization ( ranging from 32 to 8192 ) and different values of the tolerance parameter @xmath41 for the adaptive algorithm ( ranging from @xmath476 to @xmath477 ) .",
    "the curve for the uniform discretization is smooth because all the points have been generated using the same trajectories , while for the adaptive discretization different paths have been used .",
    "right : comparison of the theoretical bias of the adaptive algorithm with the actual discretization bias of the uniform discretization . ]",
    "the theoretical bias , computed as explained in remark [ betterbias ] , is greater than the actual error , because the error estimates of [ cauchy.sec ] are upper bounds , and because it does not take into account the possible cancellation of errors on different intervals .",
    "figure  [ actual.fig ] , right graph , compares the theoretical estimate of the bias of the adaptive algorithm with the actual bias of the uniform discretization .",
    "one can see that for small computational times , the theoretical bias for the adaptive algorithm is greater than the error of the uniform discretization , however , the theoretical bias converges to zero much faster , and for relatively large computational times is actually smaller than the error of the uniform discretization . the empirical convergence rate ( estimated from the slope of the straight lines ) is @xmath478 for the uniform discretization and @xmath479 for the theoretical bias of the adaptive algorithm .",
    "[ ex2 ] in our second example , we evaluate the probability @xmath480 $ ] , which again can be expressed in terms of the function ( [ killed ] ) by taking @xmath230 , @xmath470 , and the domain @xmath481 .",
    "in contrast to example [ ex1 ] , here we consider a situation where the starting point is close to the boundary . in this case , as we shall see below , the advantage of the adaptive algorithm is more striking , since the process can cross the boundary and come back while it is still close to the starting point and , hence , a very fine discretization will be necessary to detect this event with uniformly spaced observations . as a result , for the uniform discretization we do not observe convergence to a sufficient precision",
    "even with 16384 points , and therefore the true value can not be estimated as in the previous example .",
    "instead , we shall use as the true value the value produced by the adaptive algorithm with @xmath472 monte carlo paths and equal to @xmath482 , with standard deviation of @xmath483 and theoretical bias of @xmath484 .    similarly to the previous example , figure  [ actual2.fig ] shows the dependence of the values computed by the two algorithms on the computational time required for @xmath475 mc trajectories . here , the adaptive algorithm exhibits the same kind of behavior as in the example [ ex1 ] above : all the points generated by the algorithm are within the confidence bounds of the true value .",
    "however , for the uniform discretization , the convergence is much slower than before and only the last value obtained with 16384 discretization points falls within the confidence bounds .",
    "figure  [ actual2.fig ] , right graph , compares the theoretical estimate of the bias of the adaptive algorithm with the actual bias of the uniform discretization .",
    "once again , the behavior of the adaptive algorithm is roughly the same as in the previous example , showing that the method is robust with respect to the parameters on the problem . on the other hand , as expected , the uniform discretization presents a significant bias in this case ( the convergence rates are similar to those obtained in the previous example , but the constant for the uniform discretization is much bigger ) .    .",
    "left : values returned by the uniform discretization algorithm and the adaptive algorithm , as function of the computational time for @xmath475 paths , measured in seconds .",
    "different points on the graph correspond to different numbers of discretization dates for the uniform discretization ( ranging from 256 to 16384 ) and different values of the tolerance parameter @xmath41 for the adaptive algorithm ( ranging from @xmath485 to @xmath486 ) .",
    "right : comparison of the theoretical bias of the adaptive algorithm with the actual discretization bias of the uniform discretization . ]    [ app ]",
    "throughout the proof , we shall use the notation @xmath487 for a given cdlg process @xmath488 . without loss of generality ( by considering separately the positive and the negative part ) , we can and will assume that @xmath8 is nonnegative .",
    "additionally , assume that @xmath489 and @xmath490 .",
    "the cases @xmath225 and @xmath491 will be evident from the proof below .",
    "we also let @xmath492 , @xmath493 be the lipschitz norm of @xmath8 , @xmath494 , @xmath495 , @xmath496 , @xmath497 , @xmath498 , and @xmath499 , which are finite in light of ( [ cond1 ] ) . in what follows , @xmath500 where @xmath501 denotes the null sets of @xmath68 . to lighten the notation below , whenever the @xmath502 of a function @xmath503 , defined @xmath71-a.e . in some region , is considered , we shall simply write @xmath504 instead of @xmath505 .",
    "the idea is to condition on the number of jumps of the compound poisson component @xmath99 . to this end , let us denote @xmath506 so that clearly @xmath507 note that each of the terms on the right - hand side of the previous equation can be expressed as @xmath508 for some nonnegative functions @xmath509 . indeed , for @xmath510 , by the standard definition of conditional expectation , @xmath511 \\\\[-8pt ] \\nonumber & = & \\int_{{y-\\delta}}^{y+\\delta}\\bbe\\bigl ( \\varphi(x_{\\tau})\\mathbf{1}_{\\ { \\tau\\leq t , n_{t}^{\\varepsilon}=k\\}}\\vert x_{t}=u \\bigr)f_{t}(u)\\,\\mathrm{d}u= : \\int_{{y-\\delta}}^{y+\\delta } p_{t}^{k}(u ) \\,\\mathrm{d}u.\\end{aligned}\\ ] ] the case @xmath512 is treated in the same way .",
    "let us analyze each of the four terms in the right - hand side of ( [ t1-t4 ] ) .",
    "\\(1 ) _ no big jump_. note that , on the event @xmath513 , @xmath514 for all @xmath515 and , thus , @xmath516 , where @xmath517",
    ". therefore , @xmath518 where in the last equality we used the independence of @xmath519 and @xmath520 .",
    "next , conditioning on @xmath521 , it follows that @xmath522 by markov s property , @xmath523 where @xmath524 .",
    "note that if @xmath525 , then @xmath526 since @xmath527 and @xmath528 . on the other hand , on the event @xmath529 , @xmath530 since again @xmath531 .",
    "putting the two previous cases together and recalling ( [ wakipk ] ) , we have @xmath532 \\\\[-8pt ] \\nonumber & = : & \\int_{y-\\delta}^{y+\\delta } \\bar{p}^{0}_{t}(u)\\,\\mathrm{d}u,\\end{aligned}\\ ] ] implying that @xmath533 , for @xmath71-a.e . @xmath534 .",
    "furthermore , using ( [ kyinbn])(ii ) , @xmath535    \\(2 ) _ one big jump_. let @xmath536 and @xmath537 be the time and size of the @xmath386th jump of @xmath99 .",
    "clearly , on the event @xmath538 , @xmath539 it follows that @xmath540 where in the last equality we use the joint independence of @xmath520 , @xmath541 , and @xmath172 .",
    "conditioning on @xmath542 and applying fubini , @xmath543 \\\\[-8pt ] \\nonumber & = & \\int_{{y-\\delta}}^{y+\\delta}\\underbrace{{\\mathrm{e}^{-\\lambda_{\\varepsilon } t}}\\| \\varphi\\|_{\\infty}t \\bbe \\bigl(\\mathbf{1}_{\\{{u}_{t}^{\\varepsilon}\\geq c\\}}s_{\\varepsilon } \\bigl(u - x_{t}^{\\varepsilon}\\bigr ) \\bigr)}_{\\bar { p}_{t}^{1,1}(u)}\\,\\mathrm{d}u.\\end{aligned}\\ ] ] using ( [ cond1 ] ) and lemma [ kylm1 ] , @xmath544 where @xmath4 is chosen small enough . similarly ,",
    "conditioning on @xmath542 , making the substitution @xmath545 , and applying fubini , @xmath546 \\\\[-8pt ] \\nonumber & = & \\int_{{y-\\delta}}^{y+\\delta } \\underbrace{{\\mathrm{e}^{-\\lambda_{\\varepsilon}t}}\\| \\varphi\\|_{\\infty}t\\bbe \\bigl ( \\mathbf { 1}_{\\{u\\leq a+x_{t}^{\\varepsilon}-\\underline{x}^{\\varepsilon}_{t}\\ \\mathrm{or}\\ u\\geq b+x_{t}^{\\varepsilon}-\\bar{x}_{t}^{\\varepsilon}\\ } } s_{\\varepsilon } \\bigl(u - x_{t}^{\\varepsilon}\\bigr ) \\bigr)}_{\\bar { p}_{t}^{1,2}(u)}\\,\\mathrm{d}u.\\end{aligned}\\ ] ] using again lemma [ kylm1 ] , @xmath547 \\\\[-8pt ] \\nonumber & \\leq&{\\mathrm{e}^{-\\lambda_{\\varepsilon}t}}\\|\\varphi\\|_{\\infty } t a_{\\varepsilon}\\bbp \\bigl ( \\sup_{s\\leq t}\\bigl|{x}_{s}^{\\varepsilon}\\bigr|\\geq \\delta_{0}/2 \\bigr ) \\\\ & \\leq&{\\mathrm{e}^{-\\lambda_{\\varepsilon}t } } \\|\\varphi\\|_{\\infty } a_{\\varepsilon } c_{2 } ( \\delta_0/2,\\varepsilon ) t^{3}.\\nonumber\\end{aligned}\\ ] ] therefore , recalling from ( [ wakipk ] ) , the nonnegative function @xmath548 is such that , for @xmath71-a.e .",
    "@xmath549 , @xmath550 .",
    "\\(3 ) _ two big jumps . _ as before , let @xmath536 and @xmath537 be the time and size of the @xmath386th jump of @xmath99 . clearly ,",
    "@xmath551\\dvt x^\\varepsilon_s + y_1+y_2 \\notin(a , b ) ; x_{t}^{\\varepsilon}+y_{1}+y_{2}\\in i_{\\delta } ( y);{n_{t}^{\\varepsilon}=2}\\}}.\\end{aligned}\\ ] ] then , using the independence of @xmath520 , the @xmath537 s , and @xmath172 in the first and last terms , we have the inequality : @xmath552 \\\\[-8pt ] \\nonumber & & { } + { \\mathrm{e}^{-\\lambda_{\\varepsilon}t } } { \\bigl(t^{2}/2\\bigr)\\lambda_{\\varepsilon}^{2 } \\| \\varphi\\|_{\\infty}\\bbe ( \\mathbf { 1}_{\\{\\bar{x}^{\\varepsilon}_{t}+y_{1}+y_{2}\\geq b\\ \\mathrm{or}\\ \\underline { x}^{\\varepsilon}_{t}+y_{1}+y_{2}\\leq a ; x_{t}^{\\varepsilon } + y_{1}+y_{2}\\in i_{\\delta}(y)\\ } } ) } , \\qquad \\\\ & = : & { a_{2,1}(t)+a_{2,2}(t)+a_{2,3}(t ) . } \\nonumber\\end{aligned}\\ ] ] as before , conditioning on @xmath542 , changing variable from @xmath553 to @xmath554 , and applying fubini , @xmath555 and , hence , @xmath556 similarly , @xmath557 can be written as @xmath558 \\\\[-8pt ] \\nonumber & & \\hspace*{22pt}\\qquad{}\\times\\int\\bbe \\bigl(\\mathbf { 1}_{\\{\\bar{x}^{\\varepsilon}_{t}-x_{t}^{\\varepsilon}+u\\geq b\\ \\mathrm{or}\\ \\underline{x}^{\\varepsilon}_{t}-x_{t}^{\\varepsilon}+u\\leq a\\ } } s_{\\varepsilon}\\bigl(u - x_{t}^{\\varepsilon}-v \\bigr ) \\bigr ) s_{\\varepsilon}(v)\\,\\mathrm{d}v \\,\\mathrm{d}u \\\\ & & \\quad= : { \\int_{{y-\\delta}}^{y+\\delta}\\bar{p}_{t}^{2,3}(u)\\,\\mathrm{d}u,\\nonumber}\\end{aligned}\\ ] ] and , thus , as in ( [ in : repuppbnd ] ) , @xmath559}\\bar{p}_{t}^{2,3}(u)&\\leq & { \\mathrm{e}^{-\\lambda_{\\varepsilon}t}}2^{-1}\\|\\varphi\\|_{\\infty}t^{2 } \\lambda _ { \\varepsilon}a_{\\varepsilon}\\bbp \\bigl({x}_{t}^{\\varepsilon}- \\underline { x}_{t}^{\\varepsilon}\\geq \\delta_{0}\\ \\mathrm{or}\\ \\bar{x}_{t}^{\\varepsilon } -x_{t}^{\\varepsilon}\\geq \\delta_{0 } \\bigr ) \\\\ & \\leq&{\\mathrm{e}^{-\\lambda_{\\varepsilon}t } } 2^{-1 } \\|\\varphi\\|_{\\infty } \\lambda_{\\varepsilon}a_{\\varepsilon } c_{1}(\\delta_0/2 , \\varepsilon ) t^{3}.\\end{aligned}\\ ] ] finally , we provide an upper bound for @xmath560 .",
    "first , we use the bound @xmath561 and again the independence of @xmath520 , the @xmath537 s , and @xmath172 to get @xmath562 next , by conditioning on @xmath563 , we may write and @xmath564 for @xmath565 . ] @xmath560 as @xmath566 next , changing variables and applying fubini , @xmath567 \\\\[-12pt ] \\nonumber & = : & \\int_{{y-\\delta}}^{y+\\delta}\\bar{p}^{2,2}_{t}(u ) \\,\\mathrm{d}u.\\end{aligned}\\ ] ] in order to find a lower bound for @xmath568 , note that @xmath569 using the previous inequality and the lower bound @xmath570 together with the independence of @xmath520 , the @xmath537 s , and @xmath172 , it follows that @xmath571 where @xmath572 is defined as @xmath573 as it will be proved in lemma [ prfestrmd0 ] below , @xmath574 and @xmath575 are such that @xmath576 using ( [ eq : upbnd1 ] ) , ( [ esterb ] ) and the corresponding bounds for @xmath577 and @xmath578 , it follows that the nonnegative function @xmath579 defined in ( [ wakipk ] ) is such that @xmath580    \\(4 ) _ three or more big jumps . _ as before , we have the following bound @xmath581 using the previous inequality and ( [ wakipk ] ) , we have @xmath582\\,\\mathrm{d}u=:\\int _ { { y-\\delta}}^{y+\\delta }",
    "\\bar{p}^{3}_{t}(u ) \\,\\mathrm{d}u.\\end{aligned}\\ ] ] since @xmath583 , @xmath584 for some constant @xmath585 , and we conclude that @xmath586 for @xmath71-a.e . @xmath587 .",
    "putting the four previous steps together , we conclude that @xmath588 , for a function @xmath589 such that @xmath590 finally , it is easy to see that for any @xmath591 and @xmath592 , there exists an @xmath593 small enough such that @xmath594 , for all @xmath595 .",
    "this concludes the proof .",
    "@xmath596    [ prfestrmd0 ] verification of and .",
    "let @xmath169 and @xmath597 be the martingale component of @xmath172 .",
    "we shall analyze the expressions appearing inside the absolute values on the right - hand side of equations ( [ estera ] ) and ( [ esterb ] ) .",
    "define the random intervals @xmath598 , @xmath599 , and the corresponding limiting interval @xmath600 , under the convention @xmath601 if @xmath602",
    ". denote @xmath603 let us first analyze @xmath604 . clearly , @xmath605\\,\\mathrm{d}v \\biggr),\\end{aligned}\\ ] ] and , therefore , using that @xmath606 , under the convention @xmath607 , @xmath608 using the trivial inequalities @xmath609 and @xmath610 , together with doob s inequality , we then get the bound @xmath611 \\sigma_{\\varepsilon}t^{1/2 } \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & { } + \\bigl[a_{\\varepsilon}\\lambda_{\\varepsilon}\\|\\varphi\\|_\\mathrm { lip}+2\\| \\varphi\\|_{\\infty}a_{\\varepsilon}^{2}+\\|\\varphi \\|_{\\infty } \\lambda_{\\varepsilon}\\bigl\\|s'_{\\varepsilon } \\bigr\\|_{\\infty } \\bigr]| { \\mu_{\\varepsilon}}|t,\\end{aligned}\\ ] ] where @xmath612 . for @xmath613 , note that @xmath614 defining @xmath615 and following the same steps as above , it is easy to verify that @xmath616 admits the following upper bound : @xmath617\\sigma _ { \\varepsilon}t^{1/2 } \\\\ & & { } + \\bigl[a_{\\varepsilon}\\lambda_{\\varepsilon}\\|\\varphi\\|_\\mathrm { lip}+{2 } \\|\\varphi\\|_{\\infty}a_{\\varepsilon}^{2}+\\|\\varphi \\|_{\\infty } \\lambda_{\\varepsilon}\\bigl\\|s'_{\\varepsilon } \\bigr\\|_{\\infty } \\bigr]| { \\mu_{\\varepsilon}}|t,\\nonumber\\end{aligned}\\ ] ] where we had used the tail probability bound in ( [ kyinbn ] )",
    ".      we use the notation introduced at the beginning of section  [ sbsec : prmr ] above and , as before , we assume without loss of generality that @xmath8 is nonnegative . as it was done in ( [ t1-t4 ] ) , by partitioning the space into the different values that @xmath618 can take on",
    ", we can decompose @xmath619 into three terms : no big jumps , one big jump , and two or more big jumps .",
    "these terms can in turn be expressed as integrals of the form ( [ wakipk ] ) using a procedure similar to ( [ wakipkb ] ) .",
    "the term with no big jumps is such that @xmath620 which yields an upper bound for @xmath621 of the form @xmath622 . using ( [ kyinbn])(ii ) , we can further upper bound @xmath623 by @xmath624 uniformly in @xmath625 .",
    "the term with two or more big jumps can be bounded similarly to the term with three or more big jumps in the previous section . concretely",
    ", this term satisfies @xmath626\\,\\mathrm{d}u=:\\int _ { { y-\\delta}}^{y+\\delta } \\bar{p}^{2}_{t}(u ) \\,\\mathrm{d}u,\\end{aligned}\\ ] ] and , using that @xmath583 , we can further upper bound @xmath627 by @xmath628 for a constant @xmath629 .",
    "the term with exactly one jump is decomposed as follows : @xmath630 where @xmath631 is the time of the first big jump . out of these two terms",
    ", the first one satisfies @xmath632\\dvt x^\\varepsilon_s \\notin d ; x^\\varepsilon_t + y_1 \\in i_\\delta ; n_{t}^{\\varepsilon}=1\\bigr ] \\\\",
    "& = & \\mathrm{e}^{- \\lambda_{\\varepsilon}t}\\lambda_{\\varepsilon}t\\|\\varphi\\|_\\infty \\bbp\\bigl [ \\exists s\\in[0,t]\\dvt x^\\varepsilon_s \\notin d ; x^\\varepsilon_t + y_1 \\in i_\\delta\\bigr ] \\\\ & \\leq&\\int_{{y-\\delta}}^{y+\\delta}\\mathrm{e}^{- \\lambda_{\\varepsilon}t}t\\| \\varphi \\|_\\infty \\bbe \\bigl[{\\mathbf{1}}_{u^\\varepsilon_t \\geq c } s_\\varepsilon \\bigl(u - x_{t}^{\\varepsilon}\\bigr ) \\bigr]\\,\\mathrm{d}u,\\end{aligned}\\ ] ] where the integrand @xmath633 $ ] is uniformly bounded by @xmath634 . as for the second term @xmath635 it can be bounded from above by @xmath636 + \\mathrm{e}^{- \\lambda_{\\varepsilon}t}t \\|\\varphi \\|_{\\mathrm{lip } } \\bbe \\bigl[u^\\varepsilon_t s_\\varepsilon \\bigl(u - x_{t}^{\\varepsilon}\\bigr ) \\bigr ] \\bigr\\ } \\,\\mathrm{d}u \\\\ & & \\quad\\leq\\int_{{y-\\delta}}^{y+\\delta } \\bigl\\{t\\varphi(u ) s_\\varepsilon(u ) + t\\bigl ( \\|\\varphi\\|_{\\mathrm{lip } } a_\\varepsilon+ \\| \\varphi\\|_\\infty\\bigl\\|s'_\\varepsilon\\bigr\\|_\\infty \\bigr ) \\bbe\\bigl[\\bigl|x^\\varepsilon_t\\bigr|\\bigr ] + t \\|\\varphi \\|_{\\mathrm{lip } } a_\\varepsilon \\bbe\\bigl[u^\\varepsilon_t \\bigr ] \\bigr\\ } \\,\\mathrm{d}u.\\end{aligned}\\ ] ] similarly , this can be bounded from below by @xmath637 \\\\ & & \\hspace*{24pt}\\qquad { } -t \\|\\varphi\\|_{\\mathrm{lip } } a_\\varepsilon \\bbe\\bigl[u^\\varepsilon_t \\bigr ] - t\\|\\varphi\\|_\\infty a_\\varepsilon c_1(c , \\varepsilon ) t \\bigr\\}\\,\\mathrm{d}u.\\end{aligned}\\ ] ] to conclude , we estimate @xmath638 $ ] and @xmath639 $ ] as in the proof of lemma [ prfestrmd0 ] above .",
    "in this part , we provide the building blocks to develop an upper bound for the remainder @xmath640 appearing in ( [ eq : fmr ] ) .",
    "let us first assume that @xmath641 so that @xmath642 is a submartingale . by doob s inequality , for all @xmath643 , @xmath644}{\\mathrm{e}^{c\\eta } } = \\mathrm{e}^{t \\psi(c ) - c \\eta } \\label{doob}\\ ] ] with @xmath645 . minimizing the right - hand side over all @xmath643",
    ", we get , as in rschendorf and woerner @xcite ( see page  87 therein ) , @xmath646 where we are taking @xmath647 and @xmath648 is the inverse function of @xmath649 as in houdr @xcite , note that , for @xmath650 , @xmath651 from the previous inequality , for @xmath652 , @xmath653 where we used the fact that @xmath654 .",
    "this implies that @xmath655 and therefore , substituting this into ( [ doob ] ) and ( [ doob2 ] ) and using that @xmath656 and @xmath657 for all @xmath658 , we have @xmath659 & \\leq & \\exp \\biggl\\{-\\frac{t\\sigma_\\varepsilon^2}{\\varepsilon^2}\\int_{0}^{{\\varepsilon{(\\eta-{\\mu}t)}}/{(t\\sigma_\\varepsilon^2 ) } } \\log(1+s)\\,\\mathrm{d}s \\biggr\\ } \\\\ & = & \\exp \\biggl\\{-\\frac{t\\sigma_\\varepsilon^2}{\\varepsilon^2 } \\biggl ( \\biggl(1+\\frac{\\varepsilon { ( \\eta-{\\mu}t)}}{t\\sigma_\\varepsilon^2 } \\biggr ) \\log \\biggl(1+\\frac { \\varepsilon { ( \\eta-{\\mu}t)}}{t\\sigma_\\varepsilon^2 } \\biggr)-\\frac{\\varepsilon { ( \\eta-{\\mu}t)}}{t\\sigma_\\varepsilon^2 } \\biggr ) \\biggr\\ } \\\\ & \\leq & \\exp \\biggl\\{-\\frac{{\\eta-{\\mu}t}}{\\varepsilon}\\log \\biggl(\\frac { \\varepsilon{(\\eta-{\\mu}t)}}{\\mathrm{e } \\sigma_\\varepsilon^2 t } \\biggr ) \\biggr\\ } \\\\ & \\leq & t^{{\\eta}/{\\varepsilon}}\\mathrm{e}^{({{\\mu}}/{\\varepsilon } ) \\mathrm{e}^{-1}}\\exp \\biggl\\{-\\frac{{\\eta-{\\mu}t}}{\\varepsilon}\\log \\biggl(\\frac { \\varepsilon{(\\eta-{\\mu}t)}}{\\mathrm{e } \\sigma_\\varepsilon^2 } \\biggr ) \\biggr\\},\\end{aligned}\\ ] ] the above inequality proves the statement ( 2)(i ) for the case @xmath660 .",
    "next , it is easy to check that the function @xmath661 is strictly convex in @xmath85 and reaches its global minimum value of @xmath662 at @xmath663 . hence , whenever @xmath664 , @xmath665 \\leq t^{{\\eta}/{\\varepsilon}}\\mathrm{e}^{({{\\mu}}/{\\varepsilon})\\mathrm{e}^{-1}}\\mathrm{e}^{{\\sigma_\\varepsilon^2}/{\\varepsilon^{2}}},\\ ] ] which proves the statement ( 1 ) for @xmath666 .",
    "also , if @xmath667 , @xmath647 , and @xmath668 , we have that @xmath669 which proves the statement ( 2)(ii ) .",
    "finally , we consider the case @xmath670 . in that case , obviously , @xmath671 and @xmath672 where in the second inequality we used the case ( 2)(i ) with @xmath673 that was proved above .",
    "the previous inequality proves the bounds ( 2)(i ) and ( 1 ) for @xmath670 .      to prove the estimate ( [ tenovbnd ] ) for the remainder @xmath674",
    ", we analyze each of the four terms in ( [ t1-t4 ] ) contributing to it .",
    "( _ no big jump _ ) .",
    "the first component of the error is due to @xmath675 which , as seen in ( [ eq : frstrmrmd ] ) , can be bounded by @xmath676 next , recalling the notation @xmath677 and employing our hypothesis that @xmath102 has unimodal distribution , we can further apply the bound ( [ eq : bnd2 ] ) to get @xmath678\\leq \\frac{8 \\mathrm{e}^{-\\lambda_{\\varepsilon } t}\\|\\varphi\\|_\\infty}{\\delta_y } { c}(\\delta_y/4 , \\varepsilon)t^{{\\delta_y}/{(4\\varepsilon)}}\\end{aligned}\\ ] ] for @xmath679 .",
    "( _ one big jump _ ) .",
    "there are two sub - components to the error in this case .",
    "the first is due to @xmath680 in ( [ eq : defnp11 ] ) .",
    "this term can be bounded by @xmath681 for @xmath682 .",
    "the other sub - component is due to @xmath683 in ( [ eq : defnp12 ] ) , which can be bounded , for @xmath684 , as follows : @xmath685    ( _ three or more big jumps _ ) .",
    "this component can be bounded as in ( [ eq : dfnp3 ] ) : @xmath686 \\\\[-8pt ] \\nonumber & \\leq & \\|\\varphi\\|_\\infty a_{\\varepsilon}\\lambda_{\\varepsilon}^{-1 } \\bigl(1 -\\mathrm{e}^{-\\lambda_{\\varepsilon}t}\\bigl[1+\\lambda_{\\varepsilon}t+ ( \\lambda_{\\varepsilon}t)^{2}/2 \\bigr ] \\bigr).\\end{aligned}\\ ] ]    ( _ two big jumps _ ) .",
    "there are three sub - components to the error in this case . from ( [ eq : dfnp21 ] ) , @xmath687 \\\\[-8pt ] \\nonumber & \\leq&\\|\\varphi\\|_\\infty \\mathrm{e}^{-\\lambda_{\\varepsilon } t}{a_{\\varepsilon } \\lambda_{\\varepsilon } } { { c}(c/2,\\varepsilon)t^{2+{c}/{(2\\varepsilon)}}}\\end{aligned}\\ ] ] for @xmath688 .",
    "similarly , from ( [ eq : dfnp23 ] ) , @xmath689 for @xmath690 .",
    "next , we consider the error due to the limits ( [ estera])([esterb ] ) . these were bounded in lemma [ prfestrmd0 ] . hence , by taking the maximum of ( [ eq : bndkerr ] ) and ( [ eq : bndkerr2 ] ) , after some simplification , we get the following expression for the error term @xmath691 : @xmath692 \\biggl(\\sigma_{\\varepsilon}t^{1/2 } + \\frac{|{\\mu_\\varepsilon}|}{2 } t\\biggr ) \\biggr).\\end{aligned}\\ ] ]    finally , we also need to take into account the error due to approximating @xmath693 by @xmath694 , which is of order @xmath695 . putting all the previous bounds together , we obtain the overall bound ( [ tenovbnd ] ) .",
    "in this paragraph , our aim is to find an explicit bound for the cauchy process with lvy density @xmath697 ( and no drift ) , which is used in the numerical illustrations . for simplicity",
    ", we shall only consider the one - sided case ( @xmath225 ) .",
    "setting @xmath698 , we get @xmath699 for all @xmath700 , and the law of the process is symmetric , which means that @xmath701 for all @xmath4 and @xmath160 .",
    "moreover , @xmath702 and lemma [ lmm : ktpbnd ] implies that @xmath703 \\leq t^{{\\eta}/{\\varepsilon } } c(\\eta,\\varepsilon)$ ] and @xmath704 \\leq 2 t^{{\\eta}/{\\varepsilon } } c(\\eta,\\varepsilon)$ ] with @xmath705 .",
    "the results of the above section can now be improved to @xmath706 to estimate @xmath707 more precisely , let @xmath708",
    ". then @xmath709 } \\\\ & & { } + \\|\\varphi\\|_\\infty\\mathbb e \\biggl [ \\mathbf{\\mathbf{1}}_{u^\\varepsilon_t < \\varepsilon_0 } \\int_b^\\infty \\bigl(s_\\varepsilon\\bigl(v- \\bar{x}^\\varepsilon_t\\bigr)s_\\varepsilon\\bigl(y - v + \\bar{x}^\\varepsilon_t - x^\\varepsilon_t \\bigr ) - s_\\varepsilon(v ) s_\\varepsilon(y - v)\\bigr)\\,\\mathrm{d}v \\biggr ] \\\\ & \\leq&2a_\\varepsilon\\lambda_\\varepsilon \\bigl ( \\|\\varphi \\|_\\infty \\mathbb p \\bigl(u^\\varepsilon_t \\geq \\varepsilon_0 \\bigr ) + \\|\\varphi\\|_{\\mathrm{lip}}\\bbe \\bigl[u^\\varepsilon_t\\bigr ] \\bigr ) \\\\ & & { } - \\|\\varphi\\|_\\infty\\mathbb e \\bigl [ u^\\varepsilon_t \\bigr]\\int_b^\\infty s'_\\varepsilon(v- \\varepsilon_0)s_\\varepsilon(y - v + 2\\varepsilon_0)\\,\\mathrm{d}v \\\\ & & { } + 2\\|\\varphi\\|_\\infty\\mathbb e \\bigl [ u^\\varepsilon_t \\bigr]\\int_b^\\infty s_\\varepsilon(v)s'_\\varepsilon \\biggl(y - v + \\frac{b - y}{2 } \\biggr)\\,\\mathrm{d}v \\\\ & \\leq & 2a_\\varepsilon\\lambda_\\varepsilon \\bigl ( \\|\\varphi \\|_\\infty \\mathbb p \\bigl(u^\\varepsilon_t \\geq \\varepsilon_0 \\bigr ) + \\|\\varphi\\|_{\\mathrm{lip}}\\bbe \\bigl[u^\\varepsilon_t\\bigr ] \\bigr)\\\\ & & { } + 2\\|\\varphi \\|_\\infty\\mathbb e \\bigl [ u^\\varepsilon_t \\bigr ] s_\\varepsilon ( b-\\varepsilon_0 ) s_\\varepsilon ( b - y-2 \\varepsilon_0 ) .\\end{aligned}\\ ] ] a similar argument shows that @xmath710 + \\|\\varphi\\|_\\infty\\bbp \\bigl[\\bar x^\\varepsilon_t \\geq b\\bigr]\\bigr ) + \\|\\varphi\\| _ \\infty\\mathbb e \\bigl [ u^\\varepsilon_t",
    "\\bigr ] s_\\varepsilon ( b ) s_\\varepsilon ( { b - y } ) , \\ ] ] which means that the bound for @xmath711 always dominates . using the former bound",
    ", we finally find the following upper bound for @xmath691 : @xmath712 to specialize the estimate @xmath713 , we upper bound @xmath714 by @xmath715 the cases @xmath716 and @xmath717 are treated separately : @xmath718 for @xmath719 , @xmath720 \\\\ & & \\quad \\leq\\delta\\sup_{x } s^{*n}_\\varepsilon(x ) \\mathbb p \\bigl(u^\\varepsilon_t \\geq\\varepsilon_0 \\bigr ) + \\delta \\bar s^{*k}_\\varepsilon(b-\\varepsilon_0 ) \\int_{b}^\\infty \\,\\mathrm{d}v\\ , \\bar s^{*(n - k)}_\\varepsilon ( y - v+2\\varepsilon_0 + \\delta),\\end{aligned}\\ ] ] where @xmath721 is any function which is increasing on @xmath183 , decreasing on @xmath85 and satisfies @xmath722 for all @xmath236 . for the cauchy process , one can take @xmath723 so that @xmath724 assembling all the estimates together , we finally get @xmath725 the above estimates satisfy condition ( [ eq : rmdbhv ] ) for @xmath726 . in the numerical examples discussed in the paper , we have taken @xmath727 and @xmath728 .",
    "the authors are grateful to an anonymous referee and both the associate editor and the editor - in - chief for their constructive and insightful comments that greatly helped to improve the paper .",
    "jos e. figueroa - lpez research was partially supported by grants from the us national science foundation ( dms-0906919 , dms-1149692 ) ."
  ],
  "abstract_text": [
    "<S> we characterize the small - time asymptotic behavior of the exit probability of a lvy process out of a two - sided interval and of the law of its overshoot , conditionally on the terminal value of the process . </S>",
    "<S> the asymptotic expansions are given in the form of a first - order term and a precise computable error bound . </S>",
    "<S> as an important application of these formulas , we develop a novel adaptive discretization scheme for the monte carlo computation of functionals of killed lvy processes with controlled bias . </S>",
    "<S> the considered functionals appear in several domains of mathematical finance ( e.g. , structural credit risk models , pricing of barrier options , and contingent convertible bonds ) as well as in natural sciences . </S>",
    "<S> the proposed algorithm works by adding discretization points sampled from the lvy bridge density to the skeleton of the process until the overall error for a given trajectory becomes smaller than the maximum tolerance given by the user . </S>"
  ]
}