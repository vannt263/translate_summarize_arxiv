{
  "article_text": [
    "in this work we are interested by the asymptotic study of non - regular parametric statistical models encountered in statistical inference for stochastic processes .",
    "an exhaustive exposition of the parameter estimation theory in both regular and non - regular cases is given in the classical book  @xcite by ibragimov and khasminskii .",
    "they have developed a general theory of estimation based on the analysis of renormalized likelihood ratio .",
    "their approach consists in proving first that the renormalized likelihood ratio ( with a properly chosen renormalization rate ) weekly converges to some non - degenerate limit : the limiting likelihood ratio process .",
    "thereafter , the properties of the estimators ( namely their rate of convergence and limiting distributions ) are deduced .",
    "finally , based on the estimators , one can also construct confidence intervals , tests , and so on . note that this approach also provides the convergence of moments , allowing one to deduce equally the asymptotics of some statistically important quantities , such as the mean squared errors of the estimators .",
    "it is well known that in the regular case the limiting likelihood ratio is given by the lan property and is the same for different models ( the renormalization rate being usually @xmath0 ) .",
    "so , the classical estimators   the maximum likelihood estimator and the bayesian estimators   are consistent , asymptotically normal ( usually with rate @xmath0 ) and asymptotically efficient .",
    "in non - regular cases the situation essentially changes : the renormalization rate is usually better ( for example , @xmath1 in change - point type models ) , but the limiting likelihood ratio can be different in different models .",
    "so , the classical estimators are still consistent , but may have different limiting distributions ( though with a better rate ) and , in general , only the bayesian estimators are asymptotically efficient .    in  @xcite a relation between two different limiting likelihood ratios arising in change - point type models was established by one of the authors .",
    "more precisely , it was shown that the first one , which is an exponential functional of a two - sided poisson process driven by some parameter , can be approximated ( for sufficiently small values of the parameter ) by the second one , defined by @xmath2 where @xmath3 is a standard two - sided brownian motion . in this paper",
    "we consider yet another limiting likelihood ratio process arising in change - point type models and show that it is related to @xmath4 in a similar way .",
    "we introduce the random process @xmath5 on @xmath6 as the exponent of a two - sided compound poisson process given by @xmath7 where @xmath8 , @xmath9 is a strictly positive density of some random variable @xmath10 with mean @xmath11 and variance @xmath12 , @xmath13 and @xmath14 are two independent poisson processes of intensity @xmath12 on @xmath15 , @xmath16 are independent random variables with density @xmath9 which are also independent of @xmath17 , and we use the convention @xmath18 .",
    "we equally introduce the random variables @xmath19 , \\end{aligned } \\ ] ] related to this process , as well as their second moments @xmath20 and @xmath21 .    an important particular case of this process is the one where the density @xmath9 is gaussian , that is , @xmath22 . in this case",
    "we will omit the index @xmath9 and write @xmath23 instead of @xmath5 , @xmath24 instead of @xmath25 , and so on .",
    "note that since @xmath26 the process @xmath23 is symmetric and has gaussian jumps .",
    "the process @xmath5 , up to a linear time change , arises in some non - regular , namely change - point type , statistical models as the limiting likelihood ratio process , and the variables @xmath27 and @xmath25 as the limiting distributions of the bayesian estimators and of the appropriately chosen maximum likelihood estimator , respectively .",
    "the maximum likelihood estimator being not unique in the underlying models , the appropriate choice here is a linear combination with weights @xmath28 and @xmath29 of its minimal and maximal values .",
    "moreover , the quantities @xmath30 and @xmath31 are the limiting mean squared errors ( sometimes also called limiting variances ) of these estimators and , the bayesian estimators being asymptotically efficient , the ratio @xmath32 is the asymptotic relative efficiency of this maximum likelihood estimator .",
    "the examples include the two - phase regression model and the threshold autoregressive ( tar ) model .",
    "the linear case of the former was studied by koul and qian in  @xcite , while the non - linear one was investigated by ciuperca in  @xcite . concerning the tar model ,",
    "the first results were obtained by k.s .",
    "chan in  @xcite , while a more recent study was performed by n.h .",
    "chan and kutoyants in  @xcite .",
    "note however , that the estimator studied in  @xcite is the least squares estimator ( which is , in the gaussian case , equivalent to the maximum likelihood estimator ) , while the model considered in  @xcite is the gaussian tar model .",
    "so , only the processes  @xmath23 are known to arise as limiting likelihood ratios in the tar model .",
    "note also that in both models , the parameter  @xmath33 of the limiting likelihood ratio is related to the jump size of the model .      on the other hand , many change - point type statistical models encountered in various fields of statistical inference for stochastic processes rather have as limiting likelihood ratio process , up to a linear time change , the process @xmath4 defined by  . in this case , the limiting distributions of the bayesian estimators and of the maximum likelihood estimator are given by @xmath34 respectively , while the limiting mean squared errors of these estimators are @xmath35 and @xmath36 .",
    "the bayesian estimators are still asymptotically efficient , and the asymptotic relative efficiency of the maximum likelihood estimator is @xmath37 .",
    "a well - known example is the model of a discontinuous signal in a white gaussian noise exhaustively studied by ibragimov and khasminskii in  @xcite and  ( * ? ? ?",
    "* chapter  7.2 ) , but one can also cite change - point type models of dynamical systems with small noise considered by kutoyants in  @xcite and  ( * ? ? ?",
    "* chapter  5 ) , those of ergodic diffusion processes examined by kutoyants in ( * ? ? ?",
    "* chapter  3 ) , a change - point type model of delay equations analyzed by kchler and kutoyants in  @xcite , a model of a discontinuous periodic signal in a time inhomogeneous diffusion investigated by hpfner and kutoyants in  @xcite , and so on .",
    "let us also note that terentyev in  @xcite determined the laplace transform of @xmath38 and calculated the constant @xmath39 .",
    "moreover , the explicit expression of the density of @xmath40 was later successively provided by bhattacharya and brockwell in  @xcite , by yao in  @xcite and by fujii in  @xcite . regarding the constant @xmath41 , ibragimov and khasminskii in  ( * ? ? ?",
    "* chapter  7.3 ) showed by means of numerical simulation that @xmath42 , and so @xmath43 . later in  @xcite , golubev expressed @xmath41 in terms of the second derivative ( with respect to a parameter ) of an improper integral of a composite function of modified hankel and bessel functions .",
    "finally in  @xcite , rubin and song obtained the exact values @xmath44 and @xmath45 , where  @xmath46 is riemann s zeta function defined by @xmath47 .      in this paper",
    "we establish that the limiting likelihood ratio processes @xmath5 and @xmath4 are related .",
    "more precisely , under some regularity assumptions on @xmath9 , we show that as @xmath48 , the process @xmath49 , @xmath50 , ( where @xmath51 is the fisher information related to @xmath9 ) converges weakly in the space @xmath52 ( the skorohod space of functions on @xmath6 without discontinuities of the second kind and vanishing at infinity ) to the process  @xmath4 .",
    "hence , the random variables @xmath53 and @xmath54 converge weakly to the random variables @xmath55 and @xmath40 , respectively .",
    "we show equally that the convergence of moments of these random variables holds and so , in particular , @xmath56 , @xmath57 and @xmath58 . besides their theoretical interest",
    ", these results have also some practical implications . for example , they allow to construct tests and confidence intervals on the base of the distributions of @xmath55 and @xmath40 ( rather than on the base of those of @xmath27 and @xmath25 , which depend on the density @xmath9 and are not known explicitly ) in models having the process @xmath5 with a small @xmath33 as a limiting likelihood ratio .",
    "also , the limiting mean squared errors of the estimators and the asymptotic relative efficiency of the maximum likelihood estimator can be approximated as @xmath59 in such models .",
    "these are the main results of the present paper , and they are presented in section  [ mr ] , where we also briefly discuss the second possible asymptotics @xmath60 and present some numerical simulations of the quantities @xmath61 , @xmath62 and @xmath63 for @xmath640,\\infty\\right[$ ] .",
    "finally , the proofs of the necessary lemmas are carried out in section  [ pl ] .    concluding the introduction let us note that a preliminary exposition ( in the particular gaussian case ) of the results of the present paper can be found in  @xcite and  @xcite .",
    "let @xmath8 , and let @xmath9 be a strictly positive density of some random variable @xmath10 with mean @xmath11 and variance @xmath12 .",
    "we will always suppose that @xmath65 is continuously differentiable in @xmath66 , that is , there exists @xmath67 satisfying @xmath68 and @xmath69 , as well as that @xmath70 .",
    "note that under this assumptions , the model of i.i.d .",
    "observations with density @xmath71 is , in particular , lan at @xmath72 with fisher information @xmath73 @xmath74see , for example ,  ( * ? ? ?",
    "* chapter  2.1)@xmath75 and so , using characteristic functions , we have @xmath76 and , more generally , @xmath77 for all @xmath78 .    note also , that only the convergence   will be needed in our considerations .",
    "so , one can rather assume it directly , or make any other regularity assumptions sufficient for it as , for example , hjek s conditions : @xmath9 is differentiable and the fisher information @xmath79 is finite and strictly positive @xmath74see , for example ,  ( * ? ? ?",
    "* chapter  2.2)@xmath75 .",
    "note finally , that in the gaussian case the regularity assumptions clearly hold and we have @xmath80 .",
    "let us consider the process @xmath81",
    ", @xmath50 , where @xmath5 is defined by  .",
    "note that @xmath82 where the random variables @xmath27 and @xmath83 are defined by  .",
    "remind also the process @xmath4 on @xmath6 defined by   and the random variables @xmath55 and @xmath40 defined by  .",
    "recall finally the quantities @xmath20 , @xmath21 , @xmath32 , as well as @xmath84 , @xmath85 and @xmath86 .",
    "now we can state the main result of the present paper .",
    "[ t1 ] the process @xmath87 converges weakly in the space @xmath88 to the process @xmath4 as @xmath89 . in particular , the random variable @xmath53 converges weakly to the random variable @xmath55 and , for any @xmath90 $ ] , the random variable @xmath54 converges weakly to the random variable @xmath40 .",
    "moreover , for any @xmath91 we have @xmath92 in particular , @xmath93 , @xmath94 and @xmath58 .",
    "the results concerning the random variable @xmath27 are direct consequence of  ( * ? ? ?",
    "* theorem  1.10.2 ) and the following three lemmas .",
    "[ l1 ] the finite - dimensional distributions of the process @xmath87 converge to those of @xmath4 as @xmath89 .",
    "[ l2 ] for any @xmath95 we have @xmath96 for all sufficiently small @xmath33 and all @xmath97 .",
    "[ l3 ] for any @xmath98\\,0\\,{,}\\;1/8\\,\\right[$ ] we have @xmath99 for all sufficiently small @xmath33 and all @xmath50 .",
    "note that these lemmas are not sufficient to establish the weak convergence of the process @xmath87 in the space @xmath88 and the results concerning the random variable @xmath25 .",
    "however , the increments of the process @xmath100 being independent , the convergence of its restrictions ( and hence of those of @xmath87 ) on finite intervals @xmath101\\subset{\\mathbb{r}}$ ] @xmath74that is , convergence in the skorohod space @xmath102 $ ] of functions on @xmath101 $ ] without discontinuities of the second kind@xmath75 follows from  ( * ? ? ? * theorem  6.5.5 ) , lemma  [ l1 ] and the following lemma .",
    "[ l4 ] for any @xmath103 we have @xmath104    now , theorem  [ t1 ] follows from the following estimate on the tails of the process @xmath87 by standard argument @xmath74see , for example ,  @xcite@xmath75 .",
    "[ l5 ] for any @xmath105\\,0\\,{,}\\;1/12\\,\\right[$ ] we have @xmath106 for all sufficiently small @xmath33 and all @xmath107 .",
    "the proofs of all these lemmas will be given in section  [ pl ] .",
    "now let us discuss the second possible asymptotics @xmath60 .",
    "it can be shown that in this case , the process @xmath5 converges weakly in the space @xmath88 to the process @xmath108 , @xmath109 , where @xmath110 and @xmath111 are two independent exponential random variables with parameter @xmath12 .",
    "so , the random variables @xmath27 , @xmath112 ,",
    "@xmath113 and @xmath25 converge weakly to the random variables @xmath114 respectively . it can be equally shown that , moreover , for any @xmath91 we have @xmath115 in particular , denoting @xmath116 , @xmath117 and @xmath118 , we finally have @xmath119    let us note that these convergences are natural , since the process @xmath120 can be considered as a particular case of the process @xmath5 with @xmath121 under natural conventions @xmath122 and @xmath123 .    note also , that @xmath120 is the limiting likelihood ratio process in the problem of estimating the parameter @xmath124 by i.i.d .",
    "uniform observations on @xmath125 $ ] .",
    "so , in this problem , the variables @xmath126 and @xmath127 are the limiting distributions of the bayesian estimators and of the appropriately chosen maximum likelihood estimator , respectively , while @xmath128 and @xmath129 are the limiting mean squared errors of these estimators and , the bayesian estimators being asymptotically efficient , @xmath130 is the asymptotic relative efficiency of this maximum likelihood estimator .",
    "finally observe , that the formulae   and   clearly imply that in the latter problem ( as well as in any problem having @xmath120 as limiting likelihood ratio ) the best choice of the maximum likelihood estimator is @xmath131 , and that the so chosen maximum likelihood estimator is asymptotically efficient .",
    "this choice was also suggested for tar model ( which has limiting likelihood ratio @xmath23 ) by chan and kutoyants in  @xcite . for large values of @xmath33",
    "this suggestion is confirmed by our asymptotic results .",
    "however , we see that for small values of @xmath33 the choice of @xmath28 will not be so important , since the limits in theorem  [ t1 ] do not depend on @xmath28 .      here",
    "we present some numerical simulations ( in the gaussian case ) of the quantities @xmath61 , @xmath62 and @xmath63 for @xmath640,\\infty\\right[$ ] .",
    "besides giving approximate values of these quantities , the simulation results illustrate both the asymptotics @xmath132 with @xmath133 , @xmath39 and @xmath134 , and @xmath135 with @xmath136 , @xmath137 and @xmath138 .",
    "first , we simulate the events @xmath139 of the poisson process @xmath13 and the events @xmath140 of the poisson process @xmath14 @xmath74both of intensity @xmath141 , as well as the partial sums @xmath142 of the i.i.d .",
    "@xmath143 sequence @xmath144 and the partial sums @xmath145 of the i.i.d .",
    "@xmath143 sequence @xmath146 for convenience we also put @xmath147",
    ".    then we calculate @xmath148 where @xmath149 and we use the values @xmath150 , @xmath151 and @xmath11 for @xmath28 .",
    "note that in this gaussian case ( due to the symmetry of the process @xmath23 ) the random variable @xmath152 has the same law as the variable @xmath153 , that s why we use for @xmath28 only values less or equal than @xmath150 .    finally , repeating these simulations @xmath154 times ( for each value of @xmath33 ) , we approximate @xmath155 and @xmath156 by the empirical second moments , and @xmath157 by their ratio .    the results of the numerical simulations are presented in figures  [ fig1][fig3 ] .",
    "the @xmath48 asymptotics of the limiting mean squared errors is illustrated in figure  [ fig1 ] , where we rather plotted the functions @xmath158 and @xmath159 , making apparent the constants @xmath160 and @xmath39 .",
    "one can observe here that the choice @xmath131 is the best one , though its advantage diminishes as  @xmath33 approaches @xmath11 and seems negligible for @xmath161 .     and",
    "@xmath162 ( @xmath48 asymptotics),scaledwidth=60.0% ]    in figure  [ fig2 ] we illustrate the @xmath163 asymptotics of the limiting mean squared errors by plotting the functions @xmath61 and @xmath62 themselves . here",
    "the advantage of the choice @xmath131 is obvious , and one can observe that for @xmath164 this choice makes negligible the loss of efficiency resulting from the use of the maximum likelihood estimator instead of the asymptotically efficient bayesian estimators .     and",
    "@xmath62 ( @xmath163 asymptotics),scaledwidth=60.0% ]    finally , in figure  [ fig3 ] we illustrate the behavior both at @xmath11 and at @xmath165 of the asymptotic relative efficiency of the maximum likelihood estimators by plotting the functions @xmath63 .",
    "all the observations made above can be once more noticed in this figure .",
    "note also that as @xmath33 increases from @xmath11 to @xmath165 , the asymptotic relative efficiency seems first to decrease from @xmath166 for all the maximum likelihood estimators , before increasing back to @xmath130 for the maximum likelihood estimators with @xmath28 close to the optimal value @xmath150 .",
    "( both asymptotics),scaledwidth=60.0% ]",
    "for the sake of clarity , for each lemma we will first give the proof in the particular gaussian case ( in which it is more explicit ) and then explain how it can be extended to the general one .",
    "note that the restrictions of the process @xmath167 , @xmath50 , ( as well as those of the process @xmath168 ) on @xmath15 and on @xmath169 are mutually independent processes with stationary and independent increments .",
    "so , to obtain the convergence of all the finite - dimensional distributions , it is sufficient to show the convergence of one - dimensional distributions only , that is , the weak convergence of @xmath170 to @xmath171 for all @xmath50 .",
    "moreover , these processes being symmetric , it is sufficient to consider @xmath172 only .    the characteristic function @xmath173 of @xmath174 is @xmath175 where we have denoted @xmath176 the @xmath177-algebra related to the poisson process @xmath13 , used the independence of @xmath178 and @xmath13 and recalled that @xmath179 .",
    "then , noting that @xmath180 is a poisson random variable of parameter @xmath181 with moment generating function @xmath182 , we get @xmath183 as @xmath184 and so , in the gaussian case lemma  [ l1 ] is proved .          the process @xmath191 being symmetric",
    ", we have @xmath192 for all @xmath50 and , since @xmath193 as @xmath184 , for any @xmath98\\,0\\,{,}\\;1/8\\,\\right[$ ] we have @xmath194 for all sufficiently small @xmath33 and",
    "all @xmath50 .",
    "so , in the gaussian case lemma  [ l3 ] is proved .    in the general case ,",
    "equality   becomes @xmath195 with @xmath196 recall the convergence   of characteristic functions and note that @xmath197 are the corresponding moment generating functions at point @xmath150 .",
    "the convergence of these moment generating functions ( at any point smaller than  @xmath12 ) follows from the fact that for all @xmath33 they are equal @xmath12 at point @xmath12 ( which provides uniform integrability ) .",
    "thus we have @xmath198 , which implies @xmath199 , and so @xmath200 .",
    "first we consider the case @xmath201 ( say @xmath202 ) . using   and taking into account the stationarity and the independence of the increments of the process @xmath203 on @xmath15 , we can write @xmath204            first let @xmath201 ( say @xmath202 ) such that @xmath211 . then , noting that conditionally to @xmath176 the random variable @xmath212 is gaussian with mean @xmath213 and variance @xmath214 , we get @xmath215 where @xmath216 as @xmath48 .",
    "so , we have @xmath217 and hence @xmath218 where the supremum is taken only over @xmath201 .      finally , for @xmath206 ( say @xmath207 ) such that @xmath219 , using the elementary inequality @xmath220 we get @xmath221 which again yields the desired conclusion .",
    "so , in the gaussian case lemma  [ l4 ] is proved .",
    "another way to prove this lemma , is to notice first that the weak convergence of @xmath174 to @xmath222 ( established in lemma  [ l1 ] ) is uniform with respect to @xmath223 for any compact @xmath224 .",
    "indeed , the uniformity of the convergence of the characteristic functions in the proof of lemma  [ l1 ] is obvious , and so one can apply , for example , theorem  7 from appendix  i of  @xcite , whose remaining conditions are easily checked .      finally , reminding that @xmath228 and denoting @xmath229 the distribution function of the standard gaussian law , we get @xmath230 for @xmath231 . the last expression does not depend on @xmath232 and clearly converges to @xmath11 as @xmath233 , so the assertion of the lemma follows .          in order to estimate the last factor we write @xmath235 now , let us observe that the random walk @xmath236 , @xmath237 , has the same law as the restriction on @xmath238 of a standard brownian motion @xmath3 .",
    "so , @xmath239 with an evident notation .",
    "it is known that the random variable @xmath240 is exponential of parameter @xmath12 @xmath74see , for example ,  @xcite@xmath75 and hence , using its moment generating function @xmath241 , we get @xmath242    finally , taking @xmath105\\,0\\,{,}\\;1/12\\,\\right[$ ] we have @xmath243\\,0\\,{,}\\;1/8\\,\\right[$ ] and , combining  , and using lemma  [ l3 ] , we finally obtain @xmath244 for all sufficiently small @xmath33 and all @xmath107 , which concludes the proof in the gaussian case .    in the general case",
    "the proof is almost the same .",
    "note that we have no longer the symmetry of the process @xmath87 , so we need to consider the cases @xmath245 and @xmath246 separately . besides that , the only difference is in the derivation of the bound  .",
    "here we get @xmath247 where @xmath240 is the supremum of the random walk @xmath248 , @xmath237 , with @xmath249 .",
    "note that @xmath250 and so , the cummulant generating function @xmath251 of @xmath252 admits a strictly positive zero @xmath253 .",
    "hence , by the well - known cramr - lundberg bound on the tail probabilities of @xmath240 @xmath74see , for example , theorem  5.1 from chapter  xiii of  @xcite@xmath75 , we have @xmath254 for all @xmath255 . finally , denoting @xmath256 the distribution function of @xmath240 and using this bound",
    "we obtain @xmath257_{-\\infty}^{+\\infty}-\\ ; \\frac12\\int_{{\\mathbb{r}}}e^{\\,x/2}\\bigl(f(x)-1\\bigr)\\;dx\\\\ & = \\frac12\\int_{{\\mathbb{r}}_-}e^{\\,x/2}\\;dx+ \\frac12\\int_{{\\mathbb{r}}_+}e^{\\,x/2}\\bigl(1-f(x)\\bigr)\\;dx\\\\ & { \\leqslant}1+\\frac12\\int_{{\\mathbb{r}}_+}e^{-x/2}\\;dx=2 , \\end{aligned}\\ ] ] which concludes the proof .",
    "rubin , h. and song , k .- s . , `` exact computation of the asymptotic efficiency of maximum likelihood estimators of a discontinuous signal in a gaussian white noise '' , _ ann.statist . _  * 23 * , no .  3 , pp .",
    "732739 , 1995 ."
  ],
  "abstract_text": [
    "<S> different change - point type models encountered in statistical inference for stochastic processes give rise to different limiting likelihood ratio processes . in a previous paper of one of the authors </S>",
    "<S> it was established that one of these likelihood ratios , which is an exponential functional of a two - sided poisson process driven by some parameter , can be approximated ( for sufficiently small values of the parameter ) by another one , which is an exponential functional of a two - sided brownian motion . in this paper </S>",
    "<S> we consider yet another likelihood ratio , which is the exponent of a two - sided compound poisson process driven by some parameter . </S>",
    "<S> we establish , that similarly to the poisson type one , the compound poisson type likelihood ratio can be approximated by the brownian type one for sufficiently small values of the parameter . </S>",
    "<S> we equally discuss the asymptotics for large values of the parameter and illustrate the results by numerical simulations .    </S>",
    "<S> * keywords * : compound poisson process , non - regularity , change - point , limiting likelihood ratio process , bayesian estimators , maximum likelihood estimator , limiting distribution , limiting mean squared error , asymptotic relative efficiency    * mathematics subject classification ( 2000 ) * : 62f99 , 62m99 </S>"
  ]
}