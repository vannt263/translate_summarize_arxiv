{
  "article_text": [
    "with more than one hundred thousand new scholarly articles being published each year , there is a rapid growth in the number of citations for the relevant scientific articles . in this context , we highlight the following interesting facts about the process of citing scientific articles : ( i ) the most commonly cited paper by gerard salton , titled `` a vector space model for information retrieval '' ( alleged to have been published in 1975 ) does not actually exist in reality @xcite , ( ii ) the scientific authors read only 20% of the works they cite @xcite , ( iii ) one third of the references in a paper are redundant and 40% are perfunctory @xcite , ( iv ) 62.7% of the references could not be attributed a specific function ( definition , tool etc . )",
    "@xcite . despite these facts ,",
    "the existing bibliographic metrics consider that all citations are _ equally significant_.    in this paper , we would emphasize the fact that _ all the references of a paper are not equally influential_. for instance , we believe that for our current paper , @xcite is more influential reference than @xcite , although the former has received lower citations ( 9 ) than the latter ( 1650 ) so far . therefore the influence of a cited paper completely depends upon the context of the citing paper , not the overall citation count of the cited paper .",
    "we further took the opinion of the original authors of few selective papers and realized that around 16% of the references in a paper are highly influential , and the rest are trivial ( section [ data ] ) .",
    "this motivates us to design a prediction model , ` gralap `   to automatically label the influence of a cited paper with respect to a citing paper . here , we label paper - reference pairs rather than references alone , because a reference that is influential for one citing paper may not be influential with equal extent for another citing paper .",
    "we experiment with acl anthology network ( aan ) dataset and show that ` gralap `   along with the novel feature set , quite efficiently , predicts the intensity of references of papers , which achieves ( pearson ) correlation of @xmath0 with the human annotations .",
    "finally , we present four interesting applications to show the efficacy of considering unequal intensity of references , compared to the uniform intensity .    the contributions of the paper",
    "are four - fold : ( i ) we acquire a rich annotated dataset where paper - reference pairs are labeled based on the influence scores ( section [ data ] ) , which is perhaps the first gold - standard for this kind of task ; ( ii ) we propose a graph - based label propagation model ` gralap `  for semi - supervised learning which has tremendous potential for any task where the training set is less in number and labels are non - uniformly distributed ( section [ model ] ) ; ( iii ) we propose a diverse set of features ( section [ feature ] ) ; most of them turn out to be quite effective to fit into the prediction model and yield improved results ( section [ sec : result ] ) ; ( iv ) we present four applications to show how incorporating the reference intensity enhances the performance of several state - of - the - art systems ( section [ appli ] ) .",
    "all the references of a paper usually do not carry equal intensity / strength with respect to the citing paper because some papers have influenced the research more than others . to pin down this intuition , here we discretize the reference intensity by numerical values within the range of @xmath1 to @xmath2 , ( @xmath2 : most influential , @xmath1 : least influential ) .",
    "the appropriate definitions of different labels of reference intensity are presented in figure [ intensity_def ] , which are also the basis of building the annotated dataset ( see section [ data ] ) :     @xmath3 * label-1 : * the reference is related to the citing article with _ very limited extent _ and can be _ removed _ without compromising the competence of the references ( e.g. , @xcite for this paper ) .",
    "+ @xmath3 * label-2 : * the reference is _",
    "little mentioned _ in the citing article and can be _ replaced _ by others without compromising the adequacy of the references ( e.g. , @xcite for this paper ) .",
    "+ @xmath3 * label-3 : * the reference occurs separately in a sentence within the citing article and has _ no significant impact on the current problem _",
    "( e.g. , references to metrics , tools ) ( e.g. , @xcite for this paper ) .",
    "+ @xmath3 * label-4 : * the reference is _ important _ and highly related to the citing article .",
    "it is usually mentioned several times in the article with long reference context ( e.g. , @xcite for this paper ) .",
    "+ @xmath3 * label-5 : * the reference is _ extremely important _ and occurs ( is emphasized ) multiple times within the citing article .",
    "it generally points to the cited article from where the citing article borrows main ideas ( and can be treated as a baseline ) ( e.g. , @xcite for this paper ) .",
    "note that `` reference intensity '' and `` reference similarity '' are two different aspects .",
    "it might happen that two similar reference are used with different intensity levels in a citing paper  while one is just mentioned somewhere in the paper and other is used as a baseline .",
    "here , we address the former problem as a semi - supervised learning problem with clues taken from content of the citing and cited papers .",
    "in this section , we formally define the problem and introduce our prediction model .",
    "we are given a set of papers @xmath4 and a sets of references @xmath5 , where @xmath6 corresponds to the set of references ( or cited papers ) of @xmath7 .",
    "there is a set of papers @xmath8 whose references @xmath9 are already labeled by @xmath10 ( each reference is labeled with exactly one value ) .",
    "our objective is to define a predictive function @xmath11 that labels the references @xmath12 of the papers @xmath13 whose reference intensities are unknown , i.e. , @xmath14 .",
    "since the size of the annotated ( labeled ) data is much smaller than unlabeled data ( @xmath15 ) , we consider it as a semi - supervised learning problem .    *",
    "( semi - supervised learning ) * given a set of entries @xmath16 and a set of possible labels @xmath17 , let us assume that ( @xmath18 ) , ( @xmath19 ) , ... , ( @xmath20 ) be the set of labeled data where @xmath21 is a data point and @xmath22 is its corresponding label .",
    "we assume that at least one instance of each class label is present in the labeled dataset .",
    "let ( @xmath23 ) , ( @xmath24 ) , ... , ( @xmath25 ) be the unlabeled data points where @xmath26 are unknown .",
    "each entry @xmath27 is represented by a set of features @xmath28 .",
    "the problem is to determine the unknown labels using @xmath16 and @xmath17 .",
    "we propose ` gralap ` , a variant of label propagation ( lp ) model proposed by @xcite where a node in the graph propagates its associated label to its neighbors based on the proximity .",
    "we intend to assign same label to the vertices which are closely connected .",
    "however unlike the traditional lp model where the original values of the labels continue to fade as the algorithm progresses , we systematically handle this problem in ` gralap ` .",
    "additionally , we follow a post - processing in order to handle `` class - imbalance problem '' .",
    "+ * graph creation . *",
    "the algorithm starts with the creation of a _ fully connected weighted graph @xmath29 _ where nodes are data points and the weight @xmath30 of each edge @xmath31 is determined by the radial basis function as follows : @xmath32    the weight is controlled by a parameter @xmath33 .",
    "later in this section , we shall discuss how @xmath33 is selected .",
    "each node is allowed to propagate its label to its neighbors through edges ( the more the edge weight , the easy to propagate ) . +",
    "* transition matrix .",
    "* we create a probabilistic transition matrix @xmath34 , where each entry @xmath35 indicates the probability of jumping from @xmath36 to @xmath37 based on the following : @xmath38 . +",
    "* label matrix . * here , we allow a soft label ( interpreted as a distribution of labels ) to be associated with each node . we then define a label matrix @xmath39 , where @xmath37th row indicates the label distribution for node @xmath21 .",
    "initially , @xmath40 contains only the values of the labeled data ; others are zero .",
    "+ * label propagation algorithm .",
    "* this algorithm works as follows :    initialize @xmath41 and @xmath40 @xmath42 normalize rows of @xmath40 , @xmath43 reassign original labels to @xmath44    after initializing @xmath40 and @xmath41 , the algorithm starts by disseminating the label from one node to its neighbors ( including self - loop ) in one step ( step 3 )",
    ". then we normalize each entry of @xmath40 by the sum of its corresponding row in order to maintain the interpretation of label probability ( step 4 ) .",
    "step 5 is crucial ; here we want the labeled sources @xmath44 to be persistent . during the iterations ,",
    "the initial labeled nodes @xmath44 may fade away with other labels .",
    "therefore we forcefully restore their actual label by setting @xmath45 ( if @xmath46 is originally labeled as @xmath47 ) , and other entries ( @xmath48 ) by zero .",
    "we keep on `` pushing '' the labels from the labeled data points which in turn pushes the class boundary through high density data points and settles in low density space . in this way",
    ", our approach intelligently uses the unlabeled data in the intermediate steps of the learning . + * assigning final labels .",
    "* once @xmath49 is computed , one may take the most likely label from the label distribution for each unlabeled data .",
    "however , this approach does not guarantee the label proportion observed in the annotated data ( which in this case is not well - separated as shown in section [ data ] ) .",
    "therefore , we adopt a _ label - based normalization _ technique .",
    "assume that the label proportions in the labeled data are @xmath50 ( s.t .",
    "@xmath51 . in case of @xmath49",
    ", we try to balance the label proportion observed in the ground - truth .",
    "the label mass is the column sum of @xmath49 , denoted by @xmath52 , each of which is scaled in such a way that @xmath53 .",
    "the label of an unlabeled data point is finalized as the label with maximum value in the row of @xmath40 . +",
    "* convergence . * here we briefly show that our algorithm is guaranteed to converge .",
    "let us combine steps 3 and 4 as @xmath54 , where @xmath55 .",
    "@xmath40 is composed of @xmath56 and @xmath57 , where @xmath49 never changes because of the reassignment .",
    "we can split @xmath58 at the boundary of labeled and unlabeled data as follows : @xmath59    therefore , @xmath60 , which can lead to @xmath61 \\hat{t}_{ul}y_l$ ] , where @xmath62 is the shape of @xmath40 at iteration @xmath63 .",
    "we need to show @xmath64 . by construction , @xmath65 , and",
    "since @xmath58 is row - normalized , and @xmath66 is a part of @xmath58 , it leads to the following condition : @xmath67 .",
    "so , @xmath68    therefore , the sum of each row in @xmath69 converges to zero , which indicates @xmath64 .",
    "+ * selection of @xmath33 .",
    "* assuming a spatial representation of data points , we construct a minimum spanning tree using kruskal s algorithm @xcite with distance between two nodes measured by euclidean distance .",
    "initially , no nodes are connected .",
    "we keep on adding edges in increasing order of distance .",
    "we choose the distance ( say , @xmath70 ) of the first edge which connects two components with different labeled points in them .",
    "we consider @xmath70 as a heuristic to the minimum distance between two classes , and arbitrarily set @xmath71 , following @xmath72 rule of normal distribution @xcite .",
    "we use a wide range of features that suitably represent a paper - reference pair ( @xmath73 ) , indicating @xmath7 refers to @xmath74 through reference @xmath75 .",
    "these features can be grouped into six general classes .",
    "the `` reference context '' of @xmath75 in @xmath7 is defined by three - sentence window ( sentence where @xmath75 occurs and its immediate previous and next sentences ) . for multiple occurrences ,",
    "we calculate its average score .",
    "we refer to `` reference sentence '' to indicate the sentence where @xmath75 appears . + ( i ) _ .",
    "_ it indicates whether @xmath75 is mentioned alone in the reference context or together with other references .",
    "+ ( ii ) _ .",
    "_ when @xmath75 is grouped with others , this feature indicates whether it is mentioned first ( e.g. , `` [ 2 ] '' is first in `` [ 2,4,6 ] '' ) .",
    "next four features are based on the occurrence of words in the corresponding lists created manually ( see table [ manual_list ] ) to understand different aspects . + ( iii ) _ .",
    "_ it indicates whether @xmath75 is explicitly mentioned as relevant in the reference context ( ` rel ` in table [ manual_list ] ) .",
    "+ ( iv ) _ .",
    "_ it tells whether the reference context indicates that @xmath75 is new ( ` rec ` in table [ manual_list ] ) .",
    "+ ( v ) _ . _",
    "it implies that @xmath75 is extreme in some way ( ` ext ` in table [ manual_list ] ) .",
    "+ ( vi ) _ . _",
    "it indicates whether the reference context makes some kind of comparison with @xmath75 ( ` comp ` in table [ manual_list ] ) .",
    "note we do not consider any sentiment - based features as suggested by @xcite .",
    "it is natural that the high degree of semantic similarity between the contents of @xmath7 and @xmath74 indicates the influence of @xmath74 in @xmath7 .",
    "we assume that although the full text of @xmath7 is given , we do not have access to the full text of @xmath74 ( may be due to the subscription charge or the unavailability of the older papers ) .",
    "therefore , we consider only the title of @xmath74 as a proxy of its full text .",
    "then we calculate the cosine - similarity between the title ( _ t _ ) of @xmath74 and ( i ) _ _ the title , ( ii ) _ .",
    "_ the abstract , _ .",
    "_ the introduction , ( iv ) _ . _ the conclusion , and ( v ) _ .",
    "_ the rest of the sections ( sections other than abstract , introduction and conclusion ) of @xmath7 .",
    "we further assume that the `` reference context '' ( _ rc _ ) of @xmath74 in @xmath7 might provide an alternate way of summarizing the usage of the reference . therefore , we take the same similarity based approach mentioned above , but replace the title of @xmath74 with its _ rc _ and obtain five more features : ( vi ) _ _ , ( vii ) _ _ , ( viii ) _ _ , ( ix ) _ _ and ( x ) _ _ .",
    "if a reference appears multiple times in a citing paper , we consider the aggregation of all @xmath76s together .",
    "the underlying assumption of these features is that a reference which occurs more frequently in a citing paper is more influential than a single occurrence @xcite .",
    "we count the frequency of @xmath75 in ( i ) _ . _ the entire content , ( ii ) _ . _",
    "the introduction , ( iii ) _ . _ the related work , ( iv ) _ . _",
    "the rest of the sections ( as mentioned in section [ sf ] ) of @xmath7 .",
    "we also introduce ( v ) _ . _ to measure the fraction of different sections of @xmath7 where @xmath75 occurs ( assuming that appearance of @xmath75 in different sections is more influential ) .",
    "these features are further normalized using the number of sentences in @xmath7 in order to avoid unnecessary bias on the size of the paper",
    ".      position of a reference in a paper might be a predictive clue to measure the influence @xcite .",
    "intuitively , the earlier the reference appears in the paper , the more important it seems to us . for the first two features",
    ", we divide the entire paper into two parts equally based on the sentence count and then see whether @xmath75 appears ( i ) _ .",
    "_ in the beginning or ( ii ) _ .",
    "_ in the end of @xmath7 .",
    "importantly , if @xmath75 appears multiple times in @xmath7 , we consider the fraction of times it occurs in each part .",
    "for the other two features , we take the entire paper , consider sentences as atomic units , and measure position of the sentences where @xmath75 appears , including ( iii ) _ . _",
    "mean position of appearance , ( iv ) _ .",
    "_ standard deviation of different appearances .",
    "these features are normalized by the total length ( number of sentences ) of @xmath7 . ,",
    "thus ranging from @xmath63 ( indicating beginning of @xmath7 ) to @xmath1 ( indicating the end of @xmath7 ) .",
    "the linguistic evidences around the context of @xmath75 sometimes provide clues to understand the intrinsic influence of @xmath77 on @xmath7 .",
    "here we consider word level and structural features . +",
    "_ different levels of @xmath78-grams ( @xmath1-grams , @xmath79-grams and @xmath80-grams ) are extracted from the reference context to see the effect of different word combination @xcite .",
    "+ ( ii ) _ . _",
    "part - of - speech ( pos ) tags of the words in the reference sentence are used as features @xcite .",
    "+ ( iii ) _ . _",
    "the main verb of the reference sentence is used as a feature @xcite .",
    "+ ( iv ) _ . _",
    "the presence of modal verbs ( e.g. , `` can '' , `` may '' ) often indicates the strength of the claims .",
    "hence , we check the presence of the modal verbs in the reference sentence .",
    "+ ( v ) _ .",
    "_ we use the main - verb of the reference sentence as a direct feature in the model .",
    "+ ( vi ) _ .",
    "_ we check the presence of conjunction `` but '' , which is another clue to show less confidence on the cited paper .",
    "+ ( vii ) _ .",
    "_ following @xcite we use all the dependencies present in the reference context , as given by the dependency parser @xcite .",
    "+ ( viii ) _ . _",
    "@xcite use seven regular expression patterns of pos tags to capture syntactic information ; then seven boolean features mark the presence of these patterns .",
    "we also utilize the same regular expressions as shown below with the examples ( the empty parenthesis in each example indicates the presence of a reference token @xmath75 in the corresponding sentence ; while few examples are complete sentences , few are not ) :    * `` .*\\\\(\\\\ ) vv[dpzn ] . * '' : _ chen that cohesion is held in the vast majority of cases for english - french . _ * `` .*(vhpvhz ) vv . * '' : _ while cherry and lin ( ) it to be a strong feature for word alignment ... _ * `` .*vh(dgnpz ) ( rb ) * vbn .",
    "* '' : _ inducing features for taggers by clustering tried by several researchers ( ) . _ * `` .*md ( rb ) * vb(rb ) * vvn . * '' : _ for example , the likelihood of those generative procedures to get the likelihood of the phrase pair ( ) .",
    "_ * `` [  iw.]*vb(dpz ) ( rb ) * vv[nd ] . * '' : _ our experimental set - up after the human evaluation presented in ( ) . _ * `` ( rb ) * pp ( rb ) * v. * '' : _ crf ( ) to perform this tagging .",
    "_ * `` .*vvg ( np ) * ( cc ) * ( np ) . * '' : _ , we provide the annotators with only short sentences : those with source sentences between 10 and 25 tokens long . _",
    "these are all considered as boolean features . for each feature",
    ", we take all the possible evidences from all paper - reference pairs and prepare a vector . then for each pair",
    ", we check the presence ( absence ) of tokens for the corresponding feature and mark the vector accordingly ( which in turn produces a set of boolean features ) .",
    "this group provides other factors to explain why is a paper being cited .",
    "( i ) _ . _ to answer whether a highly - cited paper has more academic influence on the citing paper than the one which is less cited , we measure the number of other papers ( except @xmath7 ) citing @xmath74 .",
    "+ ( ii ) _ . _ to see the effect of self - citation , we check whether at least one author is common in both @xmath7 and @xmath74 . + ( iii ) _ .",
    "_ the fact that older papers are rarely cited , may not stipulate that these are less influential .",
    "therefore , we measure the difference of the publication years of @xmath7 and @xmath74 .",
    "+ ( iv ) _ . _",
    "it measures the co - citation counts of @xmath7 and @xmath74 defined by @xmath81 , which in turn answers the significance of reference - based similarity driving the academic influence @xcite .",
    "following @xcite , we further make one step normalization and divide each feature by its maximum value in all the entires .",
    "we use the aan dataset @xcite which is an assemblage of papers included in acl related venues .",
    "the texts are preprocessed where sentences , paragraphs and sections are properly separated using different markers .",
    "the filtered dataset contains 12,843 papers ( on average 6.21 references per paper ) and 11,092 unique authors .",
    "next we use _ parscit _  @xcite to identify the reference contexts from the dataset and then extract the section headings from all the papers . then each section heading is mapped into one of the following broad categories using the method proposed by @xcite : abstract , introduction , related work , conclusion and rest .",
    "* dataset labeling . *",
    "the hardest challenge in this task is that there is no publicly available dataset where references are annotated with the intensity value .",
    "therefore , we constructed our own annotated dataset in two different ways .",
    "( i )  _ expert annotation _ : we requested members of our research group to participate in this survey . to facilitate the labeling process , we designed a portal where all the papers present in our dataset are enlisted in a drop - down menu . upon selecting a paper , its corresponding references",
    "were shown with five possible intensity values . the citing and",
    "cited papers are also linked to the original texts so that the annotators can read the original papers .",
    "a total of @xmath82 researchers participated and they were asked to label as many paper - reference pairs as they could based on the definitions of the intensity provided in section [ intensity ] .",
    "the annotation process went on for one month .",
    "out of total 1640 pairs annotated , @xmath83 pairs were taken such that each pair was annotated by at least two annotators , and the final intensity value of the pair was considered to be the average of the scores . the pearson correlation and kendell s @xmath84 among the annotators are @xmath85 and @xmath86 respectively .",
    "( ii ) _ author annotation _ : we believe that the authors of a paper are the best experts to judge the intensity of references present in the paper . with this intension",
    ", we launched a survey where we requested the authors whose papers are present in our dataset with significant numbers .",
    "we designed a web portal in similar fashion mentioned earlier ; but each author was only shown her own papers in the drop - down menu . out of @xmath87 requests ,",
    "@xmath88 authors responded and total @xmath89 pairs are annotated .",
    "this time we made sure that each paper - reference pair was annotated by only one author .",
    "the percentages of labels in the overall annotated dataset are as follows : 1 : 9% , 2 : 74% , 3 : 9% , 4 : 3% , 5 : 4% .",
    "in this section , we start with analyzing the importance of the feature sets in predicting the reference intensity , followed by the detailed results .    * feature analysis . * in order to determine which features highly determine the gold - standard labeling , we measure the pearson correlation between various features and the ground - truth labels .",
    "figure [ corr_feature](a ) shows the average correlation for each feature group , and in each group the rank of features based on the correlation is shown in figure [ corr_feature](b ) .",
    "frequency - based features ( _ ff _ ) turn out to be the best , among which _ ff : rest _ is mostly correlated .",
    "this set of features is convenient and can be easily computed . both _",
    "cf _ and _ lf _ seem to be equally important .",
    "however , @xmath90 tends to be less important in this task .",
    "* results of predictive models . * for the purpose of evaluation , we report the average results after 10-fold cross - validation . here",
    "we consider five baselines to compare with ` gralap ` : ( i ) uniform : assign @xmath80 to all the references assuming equal intensity , ( ii ) svr+w : recently proposed support vector regression ( svr ) with the feature set mentioned in @xcite , ( iii ) svr+o : svr model with our feature set , ( iv ) c4.5ssl : c4.5 semi - supervised algorithm with our feature set @xcite , and ( v ) glm : the traditional graph - based lp model with our feature set @xcite .",
    "three metrics are used to compare the results of the competing models with the annotated labels : _ root mean square error _ ( _ rmse _ ) , _ pearson s correlation coefficient _ ( @xmath91 ) , and _ coefficient of determination _ ( @xmath92 ) and @xmath92 ( _ resp . _",
    "@xmath91 ) , the better the performance of the models . ] .",
    "table [ result ] shows the performance of the competing models .",
    "we incrementally include each feature set into ` gralap `  greedily on the basis of ranking shown in figure [ corr_feature](a ) .",
    "we observe that ` gralap `   with only ff outperforms ` svr+o ` with 41% improvement of @xmath91 .",
    "as expected , the inclusion of pf into the model improves the model marginally .",
    "however , the overall performance of ` gralap `   is significantly higher than any of the baselines ( @xmath93 ) .",
    "in this section , we provide four different applications to show the use of measuring the intensity of references . to this end",
    ", we consider all the labeled entries for training and run ` gralap `   to predict the intensity of rest of the paper - reference pairs .",
    "influential papers in a particular area are often discovered by considering _ equal weights _ to all the citations of a paper .",
    "we anticipate that considering the reference intensity would perhaps return more meaningful results .",
    "to show this , here we use the following measures individually to compute the influence of a paper : ( i ) ` rawcite : ` total number of citations per paper , ( ii ) ` rawpr : ` we construct a citation network ( nodes : papers , links : citations ) , and measure pagerank @xcite of each node @xmath78 : @xmath94 ; where , @xmath95 , the damping factor , is set to 0.85 , @xmath96 is the total number of nodes , @xmath97 is the set of nodes that have edges to @xmath78 , and @xmath98 is the set of nodes that @xmath99 has an edge to , ( iii ) ` infcite : ` the weighted version of ` rawcite ` , measured by the sum of intensities of all citations of a paper , ( iv ) ` infpr : ` the weighted version of ` rawpr ` : @xmath100 , where @xmath101 indicates the influence of a reference .",
    "we rank all the articles based on these four measures separately .",
    "table [ corr](a ) shows the spearman s rank correlation between pair - wise measures .",
    "as expected , ( i ) and ( ii ) have high correlation ( same for ( iii ) and ( iv ) ) , whereas across two types of measures the correlation is less .",
    "further , in order to know which measure is more relevant , we conduct a subjective study where we select top ten papers from each measure and invite the experts ( not authors ) who annotated the dataset , to make a binary decision whether a recommended paper is relevant .. the average pair - wise inter - annotator s agreement ( based on cohen s kappa @xcite ) is @xmath102 .",
    "table [ corr](b ) presents that out of @xmath103 recommendations of ` infpr ` , @xmath104 ( @xmath2 ) papers are marked as influential by majority ( all ) of the annotators , which is followed by ` infcite ` .",
    "these results indeed show the utility of measuring reference intensity for discovering influential papers .",
    "top three papers based on ` infpr ` from the entire dataset are shown in table [ list ] .",
    "h - index , a measure of impact / influence of an author , considers each citation with equal weight @xcite .",
    "here we incorporate the notion of reference intensity into it and define hif - index .    an author @xmath105 with a set of papers @xmath106 has an hif - index equals to @xmath107 , if @xmath107 is the largest value such that @xmath108 ; where @xmath109 is the sum of intensities of all citations of @xmath110 .",
    "we consider @xmath111 acl fellows as the list of gold - standard influential authors . for comparative evaluation ,",
    "we consider the total number of papers ( ` totp ` ) , total number of citations ( ` totc ` ) and average citations per paper ( ` avgc ` ) as three competing measures along with h - index and hif - index .",
    "we arrange all the authors in our dataset in decreasing order of each measure .",
    "figure [ rank](a ) shows the spearman s rank correlation among the common elements across pair - wise rankings .",
    "figure [ rank](b ) shows the @xmath112 for five competing measures at identifying acl fellows .",
    "we observe that hif - index performs significantly well with an overall precision of @xmath113 , followed by ` avgc ` ( @xmath114 ) , h - index ( @xmath115 ) , ` totc ` ( @xmath116 ) and ` totp ` ( @xmath117 ) .",
    "this result is an encouraging evidence that the reference - intensity could improve the identification of the influential authors .",
    "top three authors based on hif - index are shown in table [ list ] .      here",
    "we show the effectiveness of reference - intensity by applying it to a real paper recommendation system . to this end",
    ", we consider ` ferosa ` @xcite , a new ( probably the first ) framework of faceted recommendation for scientific articles , where given a query it provides facet - wise recommendations with each facet representing the purpose of recommendation @xcite .",
    "the methodology is based on random walk with restarts ( rwr ) initiated from a query paper .",
    "the model is built on aan dataset and considers both the citation links and the content information to produce the most relevant results .",
    "instead of using the unweighted citation network , here we use the weighted network with each edge labeled by the intensity score .",
    "the final recommendation of ` ferosa ` is obtained by performing rwr with the transition probability proportional to the edge - weight ( we call it ` inf - ferosa ` ) .",
    "we observe that ` inf - ferosa ` achieves an average precision of @xmath118 at top 10 recommendations , which is 14% higher then ferosa while considering the flat version and 12.34% higher than ` ferosa ` while considering the faceted version .     and @xmath119 and ( b ) number of citations before and after removing self - journal citations . ]      recently , thomson reuters began screening for journals that exchange large number of anomalous citations with other journals in a cartel - like arrangement , often known as `` citation stacking '' @xcite .",
    "this sort of citation stacking is much more pernicious and difficult to detect .",
    "we anticipate that this behavior can be detected by the reference intensity .",
    "since the aan dataset does not have journal information , we use dblp dataset @xcite where the complete metadata information ( along with reference contexts and abstract ) is available , except the full content of the paper ( 559,338 papers and 681 journals ; more details in @xcite ) . from this dataset , we extract all the features mentioned in section [ feature ] except the ones that require full text , and run our model using the existing annotated dataset as training instances .",
    "we measure the traditional impact factor ( @xmath120 ) of the journals and impact factor after considering the reference intensity ( @xmath119 ) .",
    "figure [ scatter](a ) shows that there are few journals whose @xmath119 significantly deviates ( 3@xmath33 from the mean ) from @xmath120 ; out of the suspected journals 70% suffer from the effect of self - journal citations as well ( shown in figure [ scatter](b ) ) , example including _ expert systems with applications _",
    "( current @xmath120 of @xmath121 ) .",
    "one of the future work directions would be to predict such journals as early as possible after their first appearance .",
    "although the citation count based metrics are widely accepted @xcite , the belief that mere counting of citations is dubious has also been a subject of study @xcite .",
    "@xcite was the first who explained the reasons of citing a paper .",
    "@xcite introduced a method for the rapid development of complex rule bases for classifying text segments .",
    "@xcite focused on a less manual approach by learning domain - insensitive features from textual , physical , and syntactic aspects to address concerns about h - index , different alternative measures are proposed @xcite .",
    "however they too could benefit from filtering or weighting references with a model of influence .",
    "several research have been proposed to weight citations based on factors such as the prestige of the citing journal @xcite , prestige of an author @xcite , frequency of citations in citing papers @xcite .",
    "recently , @xcite proposed a svr based approach to measure the intensity of citations .",
    "our methodology differs from this approach in at lease four significant ways : ( i ) they used six very shallow level features ; whereas we consider features from different dimensions , ( ii ) they labeled the dataset by the help of independent annotators ; here we additionally ask the authors of the citing papers to identify the influential references which is very realistic @xcite ; ( iii ) they adopted svr for labeling , which does not perform well for small training instances ; here we propose ` gralap `  , designed specifically for small training instances ; ( iv ) four applications of reference intensity mentioned here are completely new and can trigger further to reassessing the existing bibliometrics .",
    "we argued that the equal weight of all references might not be a good idea not only to gauge success of a research , but also to track follow - up work or recommending research papers .",
    "the annotated dataset would have tremendous potential to be utilized for other research . moreover , ` gralap `   can be used for any semi - supervised learning problem .",
    "each application mentioned here needs separate attention . in future",
    ", we shall look into more linguistic evidences to improve our model .",
    "tanmoy chakraborty , suhansanu kumar , pawan goyal , niloy ganguly , and animesh mukherjee .",
    "2014 . towards a stratified learning approach",
    "to predict future citation counts . in",
    "_ proceedings of the 14th acm / ieee - cs joint conference on digital libraries _ , jcdl 14 , pages 351360 , piscataway , nj , usa . ieee press .",
    "tanmoy chakraborty , amrith krishna , mayank singh , niloy ganguly , pawan goyal , and animesh mukherjee , 2016 . ,",
    "chapter ferosa : a faceted recommendation system for scientific articles , pages 528541 .",
    "springer international publishing , cham .",
    "maria liakata , shyamasree saha , simon dobnik , colin  r. batchelor , and dietrich rebholz - schuhmann . 2012",
    ". automatic recognition of conceptualization zones in scientific articles and two life science applications .",
    ", 28(7):9911000 .",
    "m.  marneffe , b.  maccartney , and c.  manning",
    ". 2006 . generating typed dependency parses from phrase structure parses . in _ lrec _ , pages 449454 , genoa , italy , may .",
    "european language resources association ( elra ) .",
    "son  bao pham and achim hoffmann . 2003 . a new approach for scientific citation classification using cue phrases . in tamas",
    "domonkos gedeon and lance chun  che fung , editors , _ advances in artificial intelligence : 16th australian conference on ai _ , pages 759771 .",
    "springer berlin heidelberg .",
    "dragomir  r. radev , pradeep muthukrishnan , and vahed qazvinian .",
    "2009 . the acl anthology network corpus . in _ proceedings of the 2009 workshop on text and citation analysis for scholarly digital libraries _",
    ", nlpir4dl , pages 5461 , stroudsburg , pa , usa .",
    "mayank singh , vikas patidar , suhansanu kumar , tanmoy chakraborty , animesh mukherjee , and pawan goyal .",
    "the role of citation context in predicting long - term citation profiles : an experimental study based on a massive bibliographic text dataset . in _ cikm _ , pages 12711280 , new york , ny , usa . acm ."
  ],
  "abstract_text": [
    "<S> research accomplishment is usually measured by considering all citations with equal importance , thus ignoring the wide variety of purposes an article is being cited for . here , we posit that measuring the intensity of a reference is crucial not only to perceive better understanding of research endeavor , but also to improve the quality of citation - based applications . to this end </S>",
    "<S> , we collect a rich annotated dataset with references labeled by the intensity , and propose a novel graph - based semi - supervised model , ` gralap `   to label the intensity of references . </S>",
    "<S> experiments with aan datasets show a significant improvement compared to the baselines to achieve the true labels of the references ( 46% better correlation ) . </S>",
    "<S> finally , we provide four applications to demonstrate how the knowledge of reference intensity leads to design better real - world applications . </S>"
  ]
}