{
  "article_text": [
    "measuring complexity of experimental time series is one of the important goals of mathematical modeling of natural phenomena . a measure of complexity gives an insight in to the phenomenon being studied .",
    "for example , in a study of population dynamics of the fruit - fly , a measure of complexity of the time series ( population size of generations ) will throw light on the persistence and stability of the population . if the complexity is low , then it is possible that the population is exhibiting a periodic behavior , i.e. fluctuating between a high population size and a low one alternately .",
    "complexity also plays a very important role in determining whether a sequence is random or not in cryptography applications .",
    "different measures of complexity such as lyapunov exponent , kolmogorov complexity , algorithmic complexity etc . are proposed in the literature  @xcite .",
    "while complexity has several facets , shannon entropy  @xcite is one of the reliable indicators of ` compressibility ' which can serve as a measure of complexity .",
    "it is given by the following expression : @xmath0 where @xmath1 is the symbolic sequence with @xmath2 symbols and @xmath3 is the probability of the @xmath4-th symbol for a block - size of one .",
    "block - size refers to the number of input symbols taken together to compute the probability mass function .",
    "shannon entropy plays an important role in lossless data storage and communications .",
    "shannon s noiseless source coding theorem  @xcite provides an upper limit on the compression ratio achievable by lossless compression algorithms .",
    "this limit is given by the shannon entropy .",
    "numerous algorithms have been designed with the aim of achieving this limit .",
    "huffman coding , shannon - fano coding , arithmetic coding , lempel - ziv coding are a few examples of lossless compression algorithms which achieve the shannon entropy limit for stochastic i.i.d sources ( independent and identically distributed )  @xcite .",
    "however , practical estimation of entropy of sources is non - trivial since most sources are not i.i.d but contain correlations ( short or long - range ) . as a simple example , in the english language",
    ", the probability of the occurrence of the letter ` @xmath5 ' after the letter ` @xmath6 ' has occurred , is nearly one .    in this paper",
    ", we are interested in measuring complexity of short symbolic sequences which are obtained from time series generated by chaotic non - linear dynamical systems ( we have used the logistic map in our study and we expect the results to hold for other systems as well ) .",
    "this paper is organized as follows . in the next section ,",
    "we highlight the challenges in measuring an estimate of shannon entropy for short sequences .",
    "in section iii , we introduce nsrps and propose a new measure of complexity based on this algorithm .",
    "subsequently , in section iv , we test the new measure on several ( short ) sequences from the logistic map and compare the complexity with a uniformly distributed random sequence  . the complexity measure based on nsrps",
    "is compared with lyapunov exponent . in section",
    "v , we construct chaotic sequences which are incompressible by popular lossless compression algorithms , but which can be compressed by nsrps . we conclude in section vi indicating directions for future work .",
    "shannon entropy can serve as a good indicator for complexity , but estimation of entropy is not a trivial task . determining shannon entropy of experimental time series is particularly challenging owing to the following reasons :    1 .",
    "analytical determination of the entropy is not easy even for a simple model of the experimental time series .",
    "the time series typically consists of real numbers . in order to calculate the entropy",
    ", it has to be converted into a symbolic sequence .",
    "the choice of the partition has a very important role to play in the estimation of the entropy . ebeling _",
    "et al . _",
    "@xcite shows that depending on the choice of the partition , the results can vary widely .",
    "3 .   noise is inevitable in any experiment .",
    "noise has the tendency to increase entropy .",
    "length of the time series is another important factor in the accurate determination of entropy .",
    "shannon entropy requires the estimation of the probability mass function , which is difficult to accurately estimate with a short time series .",
    "biological time series such as population sizes are typically of very small lengths , around 50 - 100 samples ( since actual experiments are time consuming ) .",
    "entropy estimation methods in literature require 1000 to 10000 samples  @xcite .",
    "in order to overcome these drawbacks , researchers have used lossless compression algorithms in order to estimate complexity or entropy  @xcite .",
    "lempel - ziv and its popular variations are extensively used by several researchers to determine complexity of time series ( @xcite and references therein ) . as we shall demonstrate in section v ,",
    "this is not always reliable for short sequences .",
    "[ figure : entle ] shows the effect of length of the time series on numerical computation of the shannon entropy . for a data - length @xmath7 , as the bifurcation parameter of the logistic map is varied from @xmath8 to @xmath9 , we observe that the numerically estimated shannon entropy ( equation ( 1 ) ) is poorly correlated with lyapunov exponent with a correlation coefficient of @xmath10 .",
    "when the data - length is increased to @xmath11 , shannon entropy comes close to the lyapunov exponent with a correlation coefficient of 0.8934 .",
    "ebeling  @xcite demonstrates that for the logistic map , shannon entropy comes very close to the lyapunov exponent as the block - size increases to 10 and for large data - lengths ( @xmath12 ) .     as the bifurcation parameter is varied .",
    "8 bins   were used for the numerical computation of shannon entropy using equation ( 1 ) and data - length @xmath7 . for computation of @xmath13 , equation ( 3 )",
    "the two graphs are poorly correlated as indicated by a correlation coefficient of -0.2682 . ]",
    "in this section , we propose a new measure of complexity based on a lossless compression algorithm called non - sequential recursive pair substitution ( nsrps ) .",
    "nsrps was first proposed by ebeling _",
    "et al . _",
    "@xcite and later improved by jimnez - montao _ et al . _",
    "it was subsequently shown to be optimal  @xcite .",
    "nsprs has also been used to estimate entropy of written english  @xcite .",
    "the algorithm is briefly described as follows .",
    "let the original sequence be called @xmath1 . at the first iteration ,",
    "find which pair of symbols have maximum number of occurrences and replace all its non - overlapping occurrences with a new symbol .",
    "for example , the input sequence ` @xmath14 ' is transformed into ` @xmath15 ' since the pair ` @xmath16 ' has maximum number of occurrences compared to other pairs ( ` @xmath17 ' , ` @xmath18 ' and ` @xmath19 ' ) . in the second iteration ,",
    "` @xmath15 ' is transformed to ` @xmath20 ' since ` @xmath21 ' has maximum frequency .",
    "the algorithm proceeds in this fashion until the length of the string is 1 ( at which stage there is no pair to substitute ) . in this example , in the third iteration , ` @xmath20 ' is transformed into ` @xmath22 ' and in the fourth iteration it is transformed into ` @xmath23 ' and the algorithm stops .",
    "the following observations can be made about the algorithm :    1 .",
    "the algorithm always terminates for finite length sequences . 2 .",
    "after each iteration , the length of the sequence reduces .",
    "the number of distinct symbols may or may not increase ( if the input sequence is ` @xmath24 ' , then it is transformed to ` @xmath25 ' and then to ` @xmath26 ' ) .",
    "3 .   the quantity ` @xmath27 ' may increase or decrease across the iterations .",
    "4 .   ultimately , the quantity ` @xmath27 ' has to go to zero since the length eventually reaches 1 at which point the entropy is 0 ( since there is now only one symbol , it occurs with probability 1 ) .",
    "a faster way for this quantity to go to zero is when the sequence gets transformed to a constant sequence ( which has only one distinct symbol and hence zero entropy ) .",
    "let @xmath28 be the number of iterations required for the quantity ` @xmath27 ' to reach zero .",
    "@xmath28 is always a positive integer .",
    "the minimum value of @xmath28 is zero ( for the constant sequence ) and maximum is @xmath29 where @xmath30 is the length of the sequence ( for a sequence either with distinct symbols are with all pairs being distinct ) .",
    "the algorithm as described above is not reversible , i.e. the original symbolic sequence ca nt be restored by the sequence at subsequent iterations . in order to make the algorithm reversible , we have to maintain a record of the specific pair of symbols which was substituted at each iteration .",
    "the bits required to store this overhead information compensates for the reduction in the number of bits needed to store the transformed sequence . for achieving the best lossless compression ratio , we stop at the iteration number at which the total number of bits required to store the transformed sequence and the overhead is a minimum ( and hopefully lesser than the size of the original sequence ) .",
    "the number of iterations @xmath28 for the quantity ` @xmath31 ' to approach zero by the nsrps algorithm ( as described above ) is defined as our new complexity measure .",
    "@xmath28 is an integer in the range @xmath32 $ ] .",
    "jimnez - montao  @xcite actually tracks the quantity ` @xmath27 ' across the iterations of nsrps . while this is important ,",
    "our motivation to use @xmath28 as a complexity measure is the following .",
    "@xmath28 actually represents the _ effort _ required by nsrps algorithm to transform the input sequence into a constant sequence ( having only one distinct symbol and hence zero entropy ) .",
    "a sequence which is highly redundant would naturally have a lower value of @xmath28 .",
    "as an example , the sequences @xmath33 and @xmath34 have the same length ( @xmath35 ) and the same entropy of 1 bits / symbol ( block - size=1 ) . however , sequence @xmath36 requires only @xmath37 iteration for the quantity @xmath27 to reach zero , whereas @xmath38 requires @xmath39 iterations   @xmath40 @xmath41 @xmath42 @xmath37 .",
    "now @xmath34 @xmath40 @xmath43 @xmath40 @xmath44 @xmath40 @xmath45 @xmath40 @xmath46 @xmath40 @xmath47 @xmath40 @xmath48 @xmath42 @xmath39 . ] .",
    "clearly , @xmath38 is more _ complex _ than @xmath36 ( @xmath36 is periodic , @xmath38 has no obvious pattern ) .",
    "in this section , we shall evaluate the usefulness of the new complexity measure based on nsrps described in the previous section .",
    "to this end , we consider sequences arising from the logistic map for various values of the bifurcation parameter ` @xmath49 ' . we know that the complexity of the time series increases with `",
    "@xmath49 ' , with occasional dips owing to the presence of _ windows _",
    "( attracting periodic orbits ) .    ):",
    "@xmath27 vs. number of iterations . ]     vs. lyapunov exponent @xmath50 as the bifurcation parameter ` @xmath49 ' is varied between 3.5 to 4.0 .",
    "we have used 8 bins for deriving the symbolic sequence from the time series .",
    "the data - length is @xmath7 . for computation of @xmath50",
    "we have used equation ( 3 ) .",
    "@xmath50 was scaled by a factor of 70 .",
    "the two graphs are highly correlated as indicated by a correlation coefficient of 0.8832 .",
    "compare this with fig .",
    "[ figure : entle ] . ]    in fig .",
    "[ figure : nsrpscomp ] , the quantity @xmath31 is plotted along the y - axis and iteration number along the x - axis .",
    "the length of all sequences is @xmath7 .",
    "the new complexity measure @xmath28 is the iteration number when the graph hits x - axis . as it can be seen , different sequences have different values of @xmath28 .",
    "as expected , the sequence with the highest complexity is the independent and uniformly distributed random sequence ( @xmath51 in matlab ) .",
    "the order of complexity ( from higher to lower ) is @xmath52 .",
    "there is an attracting periodic orbit ( _ window _ ) at @xmath53 and this explains the lower value of @xmath28 .",
    "table  1 shows the effect of data - length and number of bins on the new measure @xmath28 for the logistic map . as we vary the bifurcation parameter ` @xmath49 ' between 3.5 to 4.0 , we find that even for @xmath54 , the correlation coefficient ( cc ) of @xmath55 with the lyapunov exponent @xmath50 is quite good .",
    "the entropy @xmath56 ( calculated using equation ( 1 ) ) is very poorly correlated with @xmath13 . for 2 bins , even at @xmath11 , we found the cc of @xmath57 and @xmath50 to be 0.3565 .",
    "compare this with table  1 : for @xmath54 and 2 bins , the cc is already 0.6651 .",
    "this shows that the new measure is quite good for very short symbolic sequences .",
    "figure  [ figure : nsrpsle ] shows the graphs of @xmath55 and @xmath50 ( scaled by a factor of 70 for better visibility and ease of comparison ) .",
    "p1 cm p1.5 cm p1 cm l & # of bins & cc + & 2 & 0.6651 + 50 & 4 & 0.6654 + & 8 & 0.7324 + & 2 & 0.8352 + 100 & 4 & 0.8149 + & 8 & 0.8172 + & 2 & 0.8870 + 200 & 4 & 0.8648 + & 8 & 0.8832 +    lyapunov exponent @xmath13 is given by the equation : @xmath58 for the logistic map , we have used the following equation to estimate @xmath13 : @xmath59 where ` @xmath49 ' is the bifurcation parameter ( 3.5 to 4.0 ) and @xmath60 is a randomly chosen initial condition in the interval ( 0,1 ) .",
    "the number of bins determines the number of symbols for the initial sequence . as @xmath30 and number of bins increase",
    ", the cc gets better and better .",
    "complexity measures based on lossless data compression are not always accurate , especially for short data lengths , as we shall demonstrate .",
    "consider the skew - tent map  @xcite : @xmath61 here ` @xmath49 ' can be any value in the interval [ 0.5,1 ) . for @xmath62 , we have the well - known tent map .    using the value @xmath63 , data length @xmath64 and using a random initial condition",
    ", we first obtain a chaotic time series . from this",
    ", we find the symbolic sequence with 2 bins .",
    "the first bin is @xmath65 corresponding to symbol ` 0 ' and the second bin @xmath66 corresponding to symbol ` 1 ' .",
    "the symbols ` 0 ' and ` 1 ' are equally likely since the invariant distribution for the skew - tent map is uniform  @xcite .",
    "this implies that the shannon entropy is 1 bits / symbol .    for compression using nsrps ,",
    "the overhead information was taken in to account .",
    "table  [ tablecompression ] shows the efficacy of nsrps for compressing such chaotic sequences of short length while other popular compression algorithms expand ( all these use some variation of lempel - ziv compression algorithm ) .",
    "this behaviour was observed for values of @xmath49 between 0.5 and 0.7 .",
    "rigorous investigation of these interesting sequences needs to be performed .",
    ".chaotic sequences from the skew - tent map subjected to lossless compression algorithms .",
    "all numbers are in bits .",
    "as it can be seen , only nsrps manages to compress the sequence .",
    "[ cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "the new measure is able to correctly characterize the complexity of chaotic sequences as demonstrated for the logistic map ( for different values of the bifurcation parameter ) and a uniformly distributed random sequence .",
    "this new measure is highly correlated with the lyapunov exponent even for very small data - lengths , as low as @xmath54 .",
    "future work would be to investigate the effect of various kinds of noise ( corrupting the time series ) on the complexity measure @xmath28 .",
    "we have reasons to believe that @xmath28 would be robust to noise to some extent since we are working on the symbolic sequence .",
    "the new measure needs to be further tested for various dynamical systems ( maps and flows ) and stochastic time series of different distributions , and to non - uniform bin structures .",
    "the data compression aspect of nsrps needs to the thoroughly investigated , especially for compressing chaotic sequences which are otherwise incompressible by standard techniques.@xmath67    * acknowledgments : * the authors express their heart - felt gratitude to mata amritanandamayi devi ( affectionately known as ` amma ' which means ` mother ' ) for her constant support in material and spiritual matters .",
    "nn thanks sutirth dey ( iiser , pune ) for useful discussions and department of biotechnology , govt . of india for funding through the rgyi scheme ."
  ],
  "abstract_text": [
    "<S> we investigate the complexity of short symbolic sequences of chaotic dynamical systems by using lossless compression algorithms . </S>",
    "<S> in particular , we study non - sequential recursive pair substitution ( nsrps ) , a lossless compression algorithm first proposed by w. ebeling _ et al . _ [ math . </S>",
    "<S> biosc . </S>",
    "<S> 52 , 1980 ] and jimnez - montao _ et al . _ </S>",
    "<S> [ arxiv : cond - mat/0204134 , 2002 ] ) which was subsequently shown to be optimal . </S>",
    "<S> nsprs has also been used to estimate entropy of written english ( p. grassberger [ arxiv : physics/0207023 , 2002 ] ) . </S>",
    "<S> we propose a new measure of complexity - defined as the number of iterations of nsrps required to transform the input sequence into a constant sequence . </S>",
    "<S> we test this measure on symbolic sequences of the logistic map for various values of the bifurcation parameter . </S>",
    "<S> the proposed measure of complexity is easy to compute and is observed to be highly correlated with the lyapunov exponent of the original non - linear time series , even for very short symbolic sequences ( as short as 50 samples ) . finally , we construct symbolic sequences from the skew - tent map which are incompressible by popular compression algorithms like winzip , winrar and 7-zip , but compressible by nsrps . </S>"
  ]
}