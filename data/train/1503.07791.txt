{
  "article_text": [
    "methods of approximate bayesian computation ( abc ) are becoming increasing exploited , especially for problems in which the likelihood function is analytically intractable or very expensive to compute  @xcite .",
    "recent applications run across areas such as evolutionary genetics  @xcite , epidemiology  @xcite , astronomical model analysis  @xcite , among others  @xcite .",
    "vanilla abc simulates parameter / data pairs @xmath0 from the prior distribution whose density is @xmath1 accepting @xmath2 as an approximate posterior draw if its companion data @xmath3 is close enough  to the observed data @xmath4 if @xmath5 is the chosen measure of discrepancy , and @xmath6 is a discrepancy threshold defining close  , then accepted parameters are a sample from @xmath7 often , it is not possible or efficient to use the complete data set . in that case ,",
    "a reduced dimensional set of summary statistics @xmath8 can be used so that the accepted draws sample from @xmath9 for simplicity of notation , the posterior will be denoted by @xmath10 , with the understanding that the effective data @xmath3 potentially represents such a summary of the original data .",
    "a main issue is high rejection rates that result from : ( @xmath11 ) the requirement that @xmath6 be small to build faith that the approximate posterior is a good approximation to @xmath12 and ( @xmath13 ) the posterior @xmath14 may be concentrated in completely different regions of parameter space than the prior . to address this ,",
    "modifications of vanilla abc are emerging , including regression adjustment strategies  ( e.g. , * ? ? ? * ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , and automatic sampling schemes  @xcite utilizing techniques such as sequential monte carlo ( smc ) . in the latter abc methods ,",
    "smc is used in order to automatically , sequentially refine posterior approximations to be used to generate proposals for further steps . at each of a series of sequential steps indexed by @xmath15 these methods",
    "aim to generate draws from @xmath16 where @xmath17 define a series of decreasing thresholds .",
    "total acceptance rates can be significantly higher than with vanilla abc scheme  @xcite .",
    "the original version of the abc smc algorithm proposed in @xcite was motivated by the smc samplers methodology of  @xcite .",
    "later , @xcite realized that this original method can result in biased samples relative to the true posterior , and this was followed by development of a corrected approach  @xcite .",
    "the general form of the algorithm , which relies fundamentally on sequential importance sampling , is shown in figure  [ fig : abc_smc ] .",
    "applications of this abc smc algorithm have been presented in a variety of areas including population genetics  @xcite , systems biology  @xcite and psychology  @xcite . in terms of methodology development , there is increasing interest in extensions and improvements of this algorithm , as demonstrated in , for example , @xcite . building on this momentum and open challenges to improving the methodology ,",
    "our current focus is on the form of the abc smc of figure  [ fig : abc_smc ] .",
    "we note and comment on the abc smc approach of @xcite ; this makes use of an adaptive threshold schedule , extends smc samplers  @xcite and uses an markov chain monte carlo ( mcmc ) kernel for propagation of particles . as a result",
    ", the computation of weights has linear complexity as a function of the number of particles , while a disadvantage of this approach is that it can result in particle duplications , possibly leading to inferior overall performance ( as empirically shown in * ? ? ? * ) in comparison to the basic algorithm of figure  [ fig : abc_smc ] that we begin with here .",
    "one aspect of the algorithm of figure  [ fig : abc_smc ] is that the computational demand in evaluating weights increases quadratically as a function of the number of particles . while this appears disadvantageous , in practice it is often just not a limiting factor .",
    "the reason for this is that in practical abc applications , computation time is typically substantially dominated by the repeated data simulation steps ; this is borne out in our own experiences discussed further below , and has been clearly indicated and discussed in other studies , including @xcite , for example .",
    "( 1,0)320    1 .   initialize threshold schedule @xmath18 2",
    ".   set @xmath19 + for @xmath20 +  simulate @xmath21 and @xmath22 until @xmath23 +  set @xmath24 3 .   for @xmath25 + for @xmath20 + ",
    "repeat : + pick @xmath26 from the @xmath27 s with probabilities @xmath28 , + draw @xmath29 and @xmath30 ; +  until @xmath31 +  compute new weights as @xmath32 normalize @xmath33 over @xmath20",
    "the abc smc strategy above is intimately related to adaptive importance sampling @xcite using adaptively refined posterior approximations based on kernel mixtures as importance samplers . originating as a method for direct posterior approximation  @xcite in complex models , that approach defines kernel density representations of a current  posterior approximation @xmath34 as an importance sampler for a next step @xmath35 ,",
    "then adaptively updates the parameters defining @xmath36 as well as importance weights  @xcite .",
    "( 1,0)320    1 .   initialize threshold schedule @xmath18 2",
    ".   set @xmath19 + for @xmath20 +  simulate @xmath21 and @xmath22 until @xmath23 +  set @xmath24 3 .",
    "@xmath25 + compute data based weights @xmath37 + normalize weights @xmath38 over @xmath20 + for @xmath20 +  repeat : + pick @xmath26 from the @xmath27 s with probabilities @xmath39 , + draw @xmath40 and @xmath30 ; +  until @xmath31 +  compute new weights as @xmath41 normalize @xmath33 over @xmath20    this historical connection motivates an extension of abc smc that is the focus of this paper .",
    "that is , simply apply the idea of kernel density representation to the joint distribution of accepted values @xmath42 using a joint kernel @xmath43 for this paper , we use a product kernel @xmath44 , which leads to major benefits in terms of computational convenience . the underlying idea that we are working with kernel density approximations to the joint distribution of @xmath42",
    "means that we can rely on the utility of product kernel mixtures generally  ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "a joint approximation @xmath45 yields a marginal mixture for each of @xmath3 and @xmath2 separately , and a posterior approximation ( emulator or importance sampler ) with density @xmath46 . in our proposed extension of abc smc ,",
    "this form is used to propose new values , and we can immediately see how proximity of any one @xmath47 to the observed data @xmath48 will now help raise the importance of proposals drawn from or near to the partner particle @xmath49 as for @xmath50 , multivariate normal or @xmath51 density are natural choices for @xmath52 . for a more detailed discussion of kernel choices ,",
    "see  @xcite and @xcite .",
    "figure  [ fig : abc_smc_aw ] shows the algorithmic description of this new abc smc with adaptive weights ( abc smc aw ) .",
    "the inclusion of a new step where the weights are modified according to the respective values of @xmath3 adds computations .",
    "however , since computational time in the abc smc algorithm is usually dominated by the extensive repetition of model simulations , the increased compute burden will often be negligible .",
    "note also that the original abc smc is a particular case when @xmath52 is uniform over the region of accepted values of @xmath3 .",
    "the idea of approximating the joint distribution of parameters and data together is also present in @xcite , where mixture modeling is applied to the joint distribution and then used as a form of nonlinear regression adjustment .",
    "the smoothing step in abc smc aw can be seen as an automatic simplified version of that approach , about which we say more in the concluding section  [ sec : additional discussion ] .",
    "we discuss some of the structure of abc smc aw to provide insight as to why it can be expected to lead to improved acceptance rates .",
    "first , note that the final output of abc smc methods is an estimate of the target distribution @xmath53 .",
    "this provides the practitioner with the convenient option of using the output as a final approximation or as an input to be refined by using a preferred regression adjustment technique , such as local linear regression  @xcite or mixture modeling  @xcite .",
    "however , in the context of intermediate abc smc steps , more refined approximations have the potential to improve efficiency ; this can be automatically achieved by use of kernel smoothing techniques . at each intermediate step @xmath51 , this motivates the following approximation for the joint density @xmath54 ) , locally around @xmath55 : @xmath56 where @xmath57 represents the acceptance event at step @xmath51 , @xmath58 and @xmath59 are the kernel functions as described in section  [ sec : aw ] , and approximate draws of @xmath60 are obtained via importance sampling .",
    "this defines an implicit posterior emulator , namely @xmath61 we now explore equation  ( [ eq : abc_3 ] ) to ensure that : ( a ) it defines a valid importance sampler with target @xmath62 at each step @xmath51 , and ( b ) the resulting expected acceptance rates are higher than for regular abc smc .",
    "we address these two points in turn .",
    "[ [ a ] ] ( a ) : + + + +    at step @xmath15 note that @xmath2 is sampled from the distribution having density @xmath63 given this value , the extra step then simulates @xmath3 until the event @xmath64 is true .",
    "this event has probability @xmath65 , where @xmath66 , resulting in the overall proposal @xmath67 finally , to sample from @xmath68 based on this proposal , the importance sampling weights are @xmath69 which have exactly the same form as in figure  [ fig : abc_smc_aw ] .",
    "[ [ b ] ] ( b ) : + + + +    at step @xmath15 equation  ( [ eq : abc_2 ] ) describes the approximation for the joint density of @xmath42 locally around @xmath55 . based on this representation , it is possible to show that the proposal distribution implicitly defined in abc smc aw results in higher prior predictive density over the acceptance region for the next smc step .",
    "this is seen as follows . for simplicity of notation ,",
    "use @xmath70 to refer to @xmath71 at the current step  @xmath51 . the proposal density in abc smc",
    "is @xmath72 , whereas that for abc smc aw is @xmath73 .",
    "these two densities induce marginal prior predictive densities @xmath74 and @xmath75 respectively .",
    "integration of a prior predictive density over the acceptance region @xmath76 yields the corresponding acceptance probability for the next smc step , namely @xmath77 .",
    "we now show that @xmath78 so that abc smc aw improves acceptance rates over regular abc smc .",
    "our proof relies on the assumption that acceptance probability @xmath79 is positively correlated with @xmath80 with respect to @xmath81 .",
    "this is a reasonable assumption to make in regular cases , including the limiting case that @xmath82 when the correlation tends to 1 .",
    "under abc smc we have @xmath83 where the expectation is with respect to @xmath84 the corresponding value under abc smc aw is @xmath85 assuming @xmath86 .",
    "a simple example taken from previous studies of abc smc  @xcite concerns scalar data @xmath87 and prior @xmath88 . with observed value @xmath89 the target posterior is @xmath90 truncated to @xmath91 .",
    "we follow details in @xcite with discrepancy measure @xmath92 and threshold schedule @xmath93 and we use normal kernels @xmath94 and @xmath95 with standard deviations ( or bandwidth parameters ) @xmath96 and @xmath97 respectively . following standard recommendations in  @xcite and @xcite , the bandwidths @xmath98 , for @xmath99",
    "are set at @xmath100 where @xmath101 is the standard deviation , which is computed based on the values of the particles and their respective weights .",
    "this standard rule - of - thumb specification is an asymptotic approximation to the optimal bandwidth choice based on the mean integrated squared error of the product kernel density estimate  @xcite .",
    ".normal mixture example : average number of simulation steps per accepted particle for study with @xmath102 particles . [ cols=\"^,^,^,^ \" , ]",
    "this paper has introduced abc smc aw , shown that it is theoretically expected to improve the effectiveness of abc smc based on adaptive , data - based weights , and demonstrated some of the practical potential in two interesting model contexts from related literature . the new approach is simple to implement , requiring only a minor extension of standard abc smc code .",
    "further , the computational overheads adaptive weighting generates are in anything but trivial models typically quite negligible relative to the main expense of forward simulations of prior predictive distributions .",
    "we also note that the adaptive weighting idea has the potential to be integrated into other abc smc extensions , even though this integration requires careful study of potential computational and theoretical implications .    the basic idea of adaptive weights links closely to adaptive importance sampling and direct posterior approximations based on mixtures of kernel forms .",
    "as noted in section  [ sec : aw ] , the local smoothing for nonlinear regression adjustment in abc of  @xcite uses multivariate normal mixtures in related ways as local \" posterior approximations in regions defined by the threshold setting . there the mixture modelling , used to define posterior emulators , is based on large - scale bayesian nonparametric models that can have many mixture components and so flexibly adapt to the shapes of local posterior contours .",
    "incidentally , mixture fitting is computationally effective based on gpu parallelized code  @xcite .",
    "this connection suggests a more general adaptive weighting strategy that uses a joint kernel that is not of product form , with the potential to customize the weighting of sampled parameters further .",
    "that is , in the aw algorithm of figure  [ fig : abc_smc_aw ] , the kernel @xmath103 would be modified to have shape characteristics that depend also on the locale in which the kernel location @xmath104 sits .",
    "building on the connections with multivariate normal mixtures suggests specific ways in which these modifications could be developed , and this is under investigation . at this point , however , it is unclear just how beneficial this will be in practice .",
    "such extensions will require substantial additional computational overheads to identify and compute local kernel functions , which may more than offset the gains in efficiency the extensions can be expected to generate .",
    "the gains in acceptance rates already achieved by the very simple ( to code and run ) adaptive weighting method of this paper can already be very substantial , as our examples highlight .",
    "cameron , e. and pettitt , a. ( 2012 ) .",
    "`` approximate bayesian computation for astronomical model analysis : a case study in galaxy demographics and morphological transformation at high redshift . ''",
    "_ arxiv preprint arxiv:1202.1426_.              fearnhead , p. and prangle , d. ( 2012 ) .",
    "`` constructing summary statistics for approximate bayesian computation : semi - automatic approximate bayesian computation ( with discussion ) . ''",
    "_ journal of the royal statistical society : series b ( statistical methodology ) _ , 74(3 ) : 419474 .",
    "filippi , s. , barnes , c.  p. , cornebise , j. , and stumpf , m.  p. ( 2013 ) .",
    "`` on optimality of kernels for approximate bayesian computation using sequential monte carlo . '' _ statistical applications in genetics and molecular biology _ , 12(1 ) : 87107 .",
    "liepe , j. , barnes , c. , cule , e. , erguler , k. , kirk , p. , toni , t. , and stumpf , m.  p. ( 2010 ) .",
    "`` abc - sysbio - approximate bayesian computation in python with gpu support . '' _ bioinformatics _ , 26(14 ) : 17971799 .",
    "liu , j. and west , m. ( 2001 ) .",
    "`` combined parameter and state estimation in simulation - based filtering . '' in doucet , a. , freitas , j.  d. , and gordon , n. ( eds . ) , _ sequential monte carlo methods in practice _ , 197217 .",
    "new york : springer - verlag .",
    "pritchard , j. , seielstad , m. , perez - lezaun , a. , and feldman , m. ( 1999 ) .",
    "`` population growth of human y chromosomes : a study of y chromosome microsatellites . '' _ molecular biology and evolution _ , 16(12 ) : 1791 .",
    "silk , d. , filippi , s. , and stumpf , m.  p. ( 2013 ) .",
    "`` optimizing threshold - schedules for sequential approximate bayesian computation : applications to molecular systems . ''",
    "_ statistical applications in genetics and molecular biology _ , 12(5 ) : 603618 .",
    "suchard , m.  a. , wang , q. , chan , c. , frelinger , j. , cron , a.  j. , and west , m. ( 2010 ) .",
    "`` understanding gpu programming for statistical computation : studies in massively parallel massive mixtures . ''",
    "_ journal of computational and graphical statistics _ , 19 : 419438 .",
    "toni , t. , welch , d. , strelkowa , n. , ipsen , a. , and stumpf , m. ( 2009 ) .",
    "`` approximate bayesian computation scheme for parameter inference and model selection in dynamical systems . ''",
    "_ journal of the royal society interface _ , 6(31 ) : 187202 .",
    "this work was supported in part by grants from the u.s",
    ". national science foundation ( dms-1106516 ) and national institutes of health ( p50-gm081883 and rc1-ai086032 ) . any opinions , findings and conclusions or recommendations expressed in this work are those of the authors and do not necessarily reflect the views of the nsf or nih ."
  ],
  "abstract_text": [
    "<S> methods of approximate bayesian computation ( abc ) are increasingly used for analysis of complex models . </S>",
    "<S> a major challenge for abc is over - coming the often inherent problem of high rejection rates in the accept / reject methods based on prior : predictive sampling . </S>",
    "<S> a number of recent developments aim to address this with extensions based on sequential monte carlo ( smc ) strategies . </S>",
    "<S> we build on this here , introducing an abc smc method that uses data - based adaptive weights . </S>",
    "<S> this easily implemented and computationally trivial extension of abc smc can very substantially improve acceptance rates , as is demonstrated in a series of examples with simulated and real data sets , including a currently topical example from dynamic modelling in systems biology applications . </S>"
  ]
}