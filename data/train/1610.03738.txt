{
  "article_text": [
    "support vector machines ( boser et al . , 1992 ) belong to core machine learning techniques for binary classification .",
    "given a large number of training samples characterized by a large number of features , a linear svm is often the _ go - to _ approach in many applications . a handy collection of software packages ,",
    "e.g. , ` liblinear ` ( fan et al . ,",
    "2008 ) , ` pegasos ` ( shalev - shwartz et al . , 2011 ) , ` svm^{\\texttt{perf } } ` ( joachims , 2006 ) , ` scikit - learn ` ( pedregosa et al . , 2011 ) provide practitioners with efficient algorithms for fitting linear models to datasets .",
    "finding optimal hyperparameters of the algorithms for model selection is crucial though for good performance at test - time .",
    "a vanilla cross - validated grid - search is the most common approach to choosing satisfactory hyperparameters .",
    "however , grid search scales exponentially with the number of hyperparameters while choosing the right sampling scheme over the hyperparameter space impacts model performance ( bergstra & bengio , 2012 ) .",
    "linear svms typically require setting a single @xmath0 hyperparameter that equally regularizes the training ` loss ` of misclassified data .",
    "( klatzer & pock , 2015 ) propose bi - level optimization for searching several hyperparameters of linear and kernel svms and ( chu et al . , 2015 ) use warm - start techniques to efficiently fit an svm to large datasets but both approaches explore the hyperparameter regularization space partially .    the algorithm proposed in ( hastie et al . , 2004 )",
    "builds the entire regularization path for linear and kernel svms that use single , symmetric cost for misclassifying negative and positive data .",
    "the stability of the algorithm was improved in ( ong et al . , 2010 ) by augmenting the search space of feasible event updates from one- to multi - dimensional hyperparameter space . in this paper",
    ", we also show that a one - dimensional path following method can diverge to unoptimal solution wrt kkt conditions .",
    "many problems often require setting multiple hyperparameters ( karasuyama et al . , 2012 ) .",
    "they arise especially when dealing with imbalanced datasets ( japkowicz & stephen , 2002 ) and require training an svm with two cost hyperparameters assymetrically attributed to positive and negative examples .",
    "( bach et al . , 2006 ) builds a pencil of one - dimensional regularization paths for the assymetric - cost svms . on the other hand , ( karasuyama et al . , 2012 )",
    "build a one - dimensional regularization path but in a multidimensional hyperspace .",
    "in contrast to algorithms building one - dimensional paths in higher - dimensional hyperparameter spaces , we describe a solution path algorithm that explores the entire regularization path for an assymetric - cost linear svms .",
    "hence , our path is a two - dimensional path in the two - dimensional hyperparameter space .",
    "our main contributions include :    * development of the entire regularization path for assymetric - cost linear support vector machine ( ac - lsvm ) * algorithm initialization at arbitrary location in the @xmath1 hyperparameter space * computationally and memory efficient algorithm amenable to local parallelization .",
    "our binary classification task requires a _ fixed _ input set of @xmath2 training examples @xmath3 , where @xmath4 , @xmath5 , @xmath6 , to be annotated with corresponding binary labels @xmath7 denoting either class . then , the objective is to learn a decision function @xmath8 that will allow its associated classifier @xmath9 $ ] to predict the label @xmath10 for new sample @xmath11 at test - time .",
    "[ [ active - sets ] ] active sets + + + + + + + + + + +    solving the primal qp is often approached with the help of lagrange multipliers @xmath29 , where @xmath30^t$ ] , which are associated with @xmath2 constraints in .",
    "let @xmath31 $ ] and @xmath32^t $ ] .",
    "then , the dual problem takes the familiar form : @xmath33    the immediate consequence of applying the lagrange multipliers is the expression for the lsvm parameters @xmath34 yielding the decision function @xmath35 .",
    "the optimal solution @xmath36 of the dual problem is dictated by satisfying the usual karush - kuhn - tucker ( kkt ) conditions .",
    "notably , the kkt conditions can be algebraically rearranged giving rise to the following _ active sets _ : @xmath37 @xmath38 @xmath39 firstly , the @xmath40 sets @xmath41 cluster data points @xmath42 to the margin @xmath43 , to the left @xmath44 , and to the right @xmath45 of the margin along with their associated scores @xmath46 .",
    "secondly , the sets indicate the range within the @xmath1 space for lagrange multipliers @xmath47 over which @xmath36 is allowed to vary thereby giving rise to a convex polytope in that space .    [ [ convex - polytope ] ] convex polytope + + + + + + + + + + + + + + +    a unique region in @xmath1 satisfying a particular configuration of the @xmath40 set is bounded by a convex polytope . the first task in path exploration",
    "is thus to obtain the boundaries of the convex polytope . following ( hastie , 2004 ) , we obtain linear inequality constraints from @xmath41 : @xmath48   \\label{eq : h_alpha0}\\ ] ] @xmath49^t \\label{eq : h_alphac1}\\ ] ] @xmath50^t \\label{eq : h_alphac2}\\ ] ] @xmath51   \\label{eq : h_l}\\ ] ] @xmath52   \\label{eq : h_r}\\ ] ] where , @xmath53 is the orthogonal projector onto the orthogonal complement of the subspace spanned by @xmath54 and @xmath55 is the moore - penrose pseudoinverse if @xmath54 has full column rank .",
    "specifically , let @xmath56 be a matrix composed of constraints @xmath41 .",
    "@xmath57 \\label{eq : h}\\ ] ] then , the boundaries of the convex polytope in the @xmath1 space are indicated by a subset of active constraints in @xmath58 , which evaluate to @xmath59 for some @xmath60 $ ] .",
    "the boundaries can be determined in linear time @xmath61 with efficient convex hull ( ` ch ` ) routines ( avis et al . , 1997 ) .",
    "now , in order grow the entire regularization path in @xmath1 , the @xmath40 sets have to updated at @xmath62-th step such that the kkt conditions will hold , thereby determining an @xmath63-th convex polytope",
    ". the polytope constraints @xmath64 for which @xmath65 indicate that a point @xmath42 has to go from @xmath43 to @xmath45 in order to satisfy the kkt conditions .",
    "likewise , @xmath66 for which @xmath67 indicate updating the point from @xmath43 to @xmath44 , @xmath68 indicate point transition from @xmath45 to @xmath43 , and @xmath69 indicate point transition from @xmath44 to @xmath43 .",
    "these set transitions are usually called events , while the activated constraints are called breakpoints .    therefore , at breakpoint , we determine the event for @xmath70-th point by a function that updates the @xmath71 set from @xmath62 to @xmath72 as : @xmath73 where the direction of the transition depends on the current @xmath71 set configuration .    following ( hastie et al . , 2004 )",
    ", our algorithm requires @xmath71 set to proceed to the next set by .",
    "however , unlike ( hastie et al . , 2004 )",
    ", the constraints @xmath41 are independent of the previous computations of @xmath47 and @xmath20 .",
    "this has several implications .",
    "firstly , our algorithm does not accumulate potential numerical errors in these parameters .",
    "secondly , the algorithm can be initialized from an arbitrary location in the @xmath1 space .",
    "the evolution of @xmath36 is continuous and piecewise linear in the @xmath1 space ( bach et al . , 2006 ) .",
    "an immediate consequence is that the active constraints have to flip during the set update .",
    "[ [ flipping - constraints ] ] flipping constraints + + + + + + + + + + + + + + + + + + + +    suppose we have a single event that @xmath74 goes to @xmath75 thereby forcing the set update rule @xmath76 . then , the @xmath70-th constraint in can be rearranged using the _ matrix inversion lemma _",
    "wrt @xmath42 as : @xmath77 where @xmath78 .",
    "this constraint is equal to its corresponding , sign - flipped counterpart in at @xmath72 as : @xmath79 with @xmath80 .",
    "the same argument holds for update type @xmath81 .",
    "furthermore , ( hastie et al . , 2004 ) express the evolution of @xmath36 with a single cost parameter @xmath0 .",
    "this case is equivalent to @xmath82 that yields the identity line in the @xmath1 space .",
    "( ong et al . , 2010 ) observe that one - dimensional path exploration over a line can lead to incorrect results and resort to searching for alternative set updates over a higher - dimensional hyperparameter space .",
    "notably , when two points hit the margin at the same time at @xmath62 , the matrix updated by both points @xmath83 not necessarily needs to become singular .",
    "however , the @xmath71 sets can be incorrectly updated .",
    "we formalize this by introducing the notion of _ joint events _ that may co - occur at some point on the line . in our setting of the @xmath84d path exploration",
    ", this is always the case when a vertex of a polytope coincides with a line in the @xmath1 space .",
    "[ [ joint - events ] ] joint events + + + + + + + + + + + +    at the vertices of the convex polytope at least two events occur concurrently . in this case",
    ", the @xmath40 set can be updated twice from @xmath62 to @xmath72 .",
    "hence , this vertex calls @xmath85 different updates of the @xmath71 set , _",
    "i.e. _ two single updates for both edges and a joint update .    note that the piecewise continuous @xmath84d path of @xmath36 also implies piecewise continuous @xmath21d path of the events .",
    "moreover , as each vertex is surrounded by @xmath86 different @xmath40 sets , two events at the vertex have to satisfy the following _ vertex loop property _ : @xmath87 stating that the events have to flip at the vertex such that a sequence of up to @xmath85 single updates reaches each @xmath88 set from any other @xmath89 set associated with that vertex .",
    "we now describe our algorithm .",
    "we represent the entire regularization path for the ac - lsvm by the set of vertices @xmath90 , edges @xmath91 , and facets @xmath92 .",
    "let @xmath93 .",
    "then : @xmath94 @xmath95 @xmath96 where @xmath97 and @xmath98 denote attribute and connectivity , respectively , of each element in the @xmath99 sets .    [ [ ordering ] ] ordering + + + + + + + +    the @xmath99 sets admit the following connectivity structure .",
    "let @xmath100 , @xmath101 , and @xmath102 be partitioned into @xmath103 subsets where @xmath104 , @xmath105 , and @xmath106 .",
    "the subsets admit a sequential ordering , where @xmath107 , @xmath108 , and @xmath109 , such that edges @xmath110 determine the adjacency of facet pairs @xmath111 or @xmath112 while vertices @xmath113 determine the intersection of edges @xmath110 or @xmath114 . in effect , our algorithm orders facets into a _ layer_-like structure .",
    "we define a vertex @xmath115 as an _",
    "open vertex _",
    "@xmath116 when @xmath117 or @xmath118 , where @xmath119 is set cardinality , if the vertex does not lie on neither @xmath0 axis .",
    "we define a _ closed vertex _ when @xmath120 .",
    "when @xmath121 , the vertex is also closed if it lies on either @xmath0 axis .",
    "similarly , an edge @xmath122 is called an _ open edge _",
    "@xmath123 when @xmath124 and a _ closed edge _",
    "@xmath125 when @xmath126 .",
    "then , a facet @xmath127 is called an _",
    "open facet _",
    "when first and last edge in @xmath128 are unequal ; otherwise it is a _ closed facet_. finally , @xmath129 are called either _ single _",
    "@xmath130 when they are unique or _ replicated _",
    "@xmath131 , otherwise .",
    "we propose to explore the ac - lsvm regularization path in a sequence of layers @xmath132 .",
    "we require that @xmath133 facet attributes are given at the beginning , where @xmath134 , @xmath135 , and @xmath136 .",
    "an @xmath137-th layer is then composed of four successive steps .    *",
    "closing open edges and facets * - ` cef `    for each @xmath71 set , which is attributed to @xmath138 , the algorithm separately calls a convex hull routine ` ch ` . the routine uses to compute linear inequality constraints @xmath139 creating a convex polytope at @xmath62 .",
    "the ordered set of edges @xmath140 , where the first and last edge are open , serve as initial , mandatory constraints in the ` ch ` routine .",
    "after completion , the routine augments the set @xmath141 by closed edges @xmath142 and the set @xmath143 by open vertices @xmath144 .    *",
    "2 . merging closed edges and open vertices * - ` mev `    as the ` ch ` routine runs for each facet @xmath138 separately , some edges @xmath142 and/or vertices @xmath144 may be replicated , thereby yielding @xmath145 and @xmath146 .    notably , a vertex @xmath147 is replicated when another vertex @xmath148 ( or other vertices ) has the same attribute , i.e. @xmath149 .",
    "however , we argue that merging vertices into a single vertex based on the distance between them in some metric space may affect the numerical stability of the algorithm .    on the other hand , a closed edge @xmath150 is replicated by another closed edge @xmath151 , when both edges connect a pair of vertices that are both replicated .",
    "replicated edges can not merge solely by comparing their event attributes @xmath152 .",
    "as they are piecewise continuous in the @xmath1 space , they are not unique . similarly to vertices",
    "though , the edges might be merged by numerically comparing their associated linear constraints , which are only sign - flipped versions of each other , as shown in @xmath41 .",
    "however , this again raises concerns about the potential numeric instability of such a merging procedure .    in view of this",
    ", we propose a sequential merging procedure that leverages @xmath153 sets , which are both unique in @xmath154 and discrete . to this end , we first introduce two functions that act on attributes and connectivity of objects @xmath155 .",
    "let @xmath156 be an indexing function that groups @xmath157 by assigning labels from set @xmath158 to @xmath159 based on @xmath160 indexed over @xmath161 : @xmath162    let @xmath163 then be a relabeling function that assigns labels from @xmath164 to @xmath165 indexed over @xmath166 : @xmath167    the algorithm commences the merging procedure by populating initially empty set @xmath168 with facets @xmath169 that are obtained by separately updating the facets @xmath170 through the events attributed to each edge @xmath171 .",
    "note , however , that replicated edges @xmath172 will produce facet attributes in @xmath168 that replicate facet attributes from the preceding layer .",
    "moreover , single edges @xmath173 may as well produce replicated facet attributes in the current layer .",
    "hence , we have that @xmath174 .    in order to group facets into single and replicated @xmath40 sets , the algorithm indexes facet attributes with @xmath175 based on their equality .",
    "then , relabeling facet - edge connectivities of edges @xmath142 with @xmath176 allows for indexing the connectivities with @xmath177 also based on their equality . having indicated single and replicated edges , the algorithm relabels edge - vertex connectivities of vertices @xmath144 with @xmath178 .    note that there are two general vertex replication schemes",
    ". vertices , which indicate the occurrence of joint events , can be replicated when two facets connect ( i ) through an edge ( i.e. , vertices share replicated edge ) or ( ii ) through a vertex ( i.e. , vertices connect only to their respective , single edges ) . at this point of the merging procedure ,",
    "a vertex @xmath144 is associated indirectly through edges @xmath179 with two facets @xmath180 , when it lies on either @xmath0 axis , or three facets @xmath181 , otherwise .",
    "two vertices lying on , say , @xmath27 axis are replicated when their respective edges share a facet and are attributed the events that refer to the same , negative point @xmath182 , but yet that have opposite event types , i.e. @xmath183 .",
    "this condition follows directly from @xmath41 , as @xmath184 at @xmath185 .",
    "conversely , when vertices lie on @xmath28 axis , they are replicated when their edges have events referring to the positive point , @xmath186 .",
    "then , two vertices lying on neither @xmath0 axis are replicated when their respective edges are associated with two common facets and equal joint events .",
    "hence , vertices are indexed with @xmath187 based on the equality of edge - facet connectivities along with edge attributes .",
    "alternatively , should the joint events be unique , the vertices could then be merged solely by comparing these events .",
    "showing that joint events being unique is true or false , i.e. two @xmath21d event paths can intersect only at a single point in the entire @xmath1 space , is an interesting future work .    having grouped facets @xmath169 ,",
    "edges @xmath188 , and vertices @xmath189 , now the algorithm can merge facet - edge connectivities @xmath190 of the replicated facets , prune replicated edges @xmath191 , and merge vertex - edge connectivites @xmath192 of the replicated vertices .",
    "being left with only single facets @xmath193 , edges @xmath194 , and vertices @xmath195 , the algorithm relabels with @xmath196 the edge - vertex connectivities of single , open edges @xmath197 and single , closed edges @xmath179 intersecting with @xmath197 .",
    "finally , the algorithm relabels with @xmath198 the facet - edge connectivites of facets from the preceding and current layer .    *",
    "3 . closing open vertices * - ` cv `    in this step , the algorithm closes the vertices @xmath199 by attaching open edges . specifically , by exploiting the piecewise continuity of events at vertices , the algorithm populates the @xmath200 set with open edges @xmath201 , such that a vertex @xmath202 now connects either to ( i ) @xmath85 edges , when it lies on , say , @xmath27 axis and connects to event edge with associated positive point , or to ( ii ) @xmath86 edges when it lies on neither axis .    using the vertex loop property",
    ", the algorithm then augments the set @xmath203 with additional facets @xmath204 such that now the closed vertex @xmath202 connects indirectly through its edges @xmath205 to facets @xmath206 and additionally up to @xmath21 new facet @xmath207 .",
    "there are several advantages for generating open edges .",
    "firstly , augmenting the initialization list of edges during the call to the ` ch ` routine reduces the number of points for processing , with computational load @xmath208 .",
    "secondly , each vertex generates up to two single open edges .",
    "however , there can be two single vertices that generate the same open edge thereby merging the @xmath21d path of an event .",
    "in this case , both open edges are merged into a single closed edge and the facet is closed without processing it with ` ch ` routine .",
    "this merging step is described next .    *",
    "merging open edges and facets * - ` mef `    as open edges and their facets , which are generated in step @xmath85 , can also be single or replicated , step @xmath86 proceeds similarly to step @xmath84 .",
    "the algorithm indexes additional facets with @xmath209 and relabels the open edge connectivities with @xmath210 .",
    "then , the algorithm indexes these connectivites with @xmath211 and merges edge - vertex @xmath212 and facet - edge @xmath190 connectivities .",
    "finally , the algorithm relabels with @xmath213 the facet - edge connectivity of all facets in @xmath168 and returns to step @xmath21 .    [",
    "[ termination ] ] termination + + + + + + + + + + +    the algorithm terminates at @xmath103-th layer , in which the ` ch ` routine for @xmath40 sets of all facets in @xmath214 , where @xmath215 , produces _ open polytopes _ in the @xmath1 space .",
    "[ [ special - cases ] ] special cases + + + + + + + + + + + + +    as mentioned in ( hastie et al . , 2004 )",
    ", two special case events may occur after closing facet @xmath127 and set updating . when ( i ) replicated data points @xmath216 exist in the dataset and enter the margin , or ( ii ) single points simultaneously project onto the margin such that @xmath217 , then the matrix @xmath83 becomes singular and thus not invertible , yielding non - unique paths for some @xmath47 .",
    "in contrast to ( hastie et al . , 2004 ) , note that the case ( ii ) is likely to occur in the considered lsvm formulation ( 1)@xmath41 as the positive and negative data points span up to @xmath218 subspace after being affine transformed , yielding e.g. parameters @xmath219 $ ] . in the context of our algorithm , both cases ( i)@xmath41(ii )",
    "are detected at @xmath127 when the matrix @xmath220 formed of @xmath221 constraints @xmath41 associated with these points either has @xmath222 , producing multiple events at an edge denoted by constraints that are identical up to positive scale factor , or has @xmath223 , producing multiple joint events at a vertex denoted by constraints that intersect at the same point .",
    "we propose the following procedure for handling both special cases .",
    "namely , when some facets @xmath224 close with edges having multiple events or with vertices having multiple joint events that would lead to cases ( i)@xmath41(ii ) , the algorithm moves to step @xmath84 , as it can obtain facet updates in these special cases . however , it skips step @xmath85 for these particular facets .",
    "while we empirically observed that such vertices close with @xmath84 edges having multiple joint events , it is an open issue how to generate open edges in this case .",
    "instead , during successive layers , step @xmath84 augments the list of facets , edges , and vertices by the ones associated to ( i)@xmath41(ii ) for indexing and relabeling them with respect to successive ones that will become replicated in further layers . in effect",
    ", our algorithm goes around these special case facets and attempts to close them by computing adjacent facets .",
    "however , the path for @xmath36 in these cases is not unique and remains unexplored .",
    "nevertheless , our experiments suggest that unexplored regions occupy relatively negligibly small area in the hyperparameter space .",
    "when the algorithm starts with all points in @xmath44 and either case ( i)@xmath41(ii ) occurs at the initial layers , the exploration of the path may haltd multiple event paths referring to these cases will go to both @xmath0 axis , instead of to one @xmath0 axis and to infinity . ] due to the piecewise continuity of the ( multiple ) events .",
    "a workaround can then be to run a regular lsvm solver at yet unexplored point @xmath1 , obtain @xmath40 sets , and extract convex polytope to restart the algorithm .",
    "our future work will focus on improving our tactics for special cases .",
    "we posit that one worthy challenge in this regard is to efficiently build the entire regularization path in @xmath2-dimensional hyperparameter space .    [",
    "[ computational - complexity ] ] computational complexity + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath225 be the average size of a margin set for all @xmath62 , let @xmath226 be the average size of @xmath154 .",
    "then , the complexity of our algorithm is @xmath227 , where @xmath228 is the number of computations for solving ( without inverse updating / downdating ( hastie et al . , 2004 ) ) and we hid constant factor @xmath84 related to convex hull computation .",
    "however , note that typically we have @xmath229 .",
    "in addition , we _ empirically _ observed that @xmath230 ( but cf .",
    "( gartner et al . , 2012 ) ) , so that the number of layers @xmath137 approximates dataset size .",
    "our algorithm is sequential in @xmath103 but parallel in @xmath226 .",
    "therefore , the complexity of a parallel implementation of the algorithm can drop to @xmath231 . finally , at each facet",
    ", it is necessary to evaluate .",
    "but then the evaluation of constraints @xmath41 can be computed in parallel , as well .",
    "while this would lead to further reduce the computational burden , memory transfer remains the main bottleneck on modern computer architectures .",
    "our algorithm partitions the sets @xmath92 , @xmath91 , @xmath90 into a _ layer_-like structure such that our two - step merging procedure requires access to objects only from layer pairs @xmath137 and @xmath232 and not to preceding layers , it requires access to @xmath127 , @xmath122 , @xmath115 objects related to these cases even after @xmath233 layers , but the number of these objects is typically small . ] . in effect , the algorithm only requires @xmath234 memory to cache the sets at @xmath137 , where @xmath235 and @xmath236 are average edge and vertex subset sizes of @xmath141 and @xmath143 , respectively .",
    "in this section , we evaluate our ac - lsvmpath algorithm described in section [ sec : algo ] .",
    "we conduct three numerical experiments for exploring the two - dimensional path of assymetric - cost lsvms on synthetic data .",
    "we generate samples from a gaussian distribution @xmath237 for ( i ) a small dataset with large number of features @xmath238 , ( ii ) a large dataset with small number of features @xmath239 , and ( iii ) a moderate size dataset with moderate number of features @xmath240 .",
    "we also build two - dimensional regularization path when input features are sparse ( iv ) .",
    "we use off - the - shelf algorithm for training flexible part mixtures model ( yang & ramanan , 2013 ) , that uses positive examples from parse dataset and negative examples from inria s person dataset ( dalal & triggs , 2006 ) . the model is iteratively trained with hundreds of positive examples and millions of hard - mined negative examples .",
    "we keep original settings .",
    "the hyperparameters are set to @xmath241 and @xmath242 to compensate for imbalanced training ( akbani et al . , 2004 ) .    for experiments ( i)@xmath41(iv )",
    ", we have the following settings : ( i ) @xmath243 , @xmath244 , @xmath245 , ( ii ) @xmath246 , @xmath247 , @xmath248 , ( iii ) @xmath249 , @xmath247 , @xmath248 , ( iv ) @xmath250 , @xmath251 , @xmath245 .",
    "we set @xmath252 in all experiments , as in ( yang & ramanan , 2013 ) .",
    "the results are shown in fig . 1 and fig",
    "this work proposed an algorithm that explores the entire regularization path of asymmetric - cost linear support vector machines .",
    "the events of data concurrently projecting onto the margin are usually considered as special cases when building one - dimensional regularization paths while they happen repeatedly in the two - dimensional setting . to this end",
    ", we introduced the notion of joint events and illustrated the set update scheme with vertex loop property to efficiently exploit their occurrence during our iterative path exploration .",
    "finally , as we structure the path into successive layers of sets , our algorithm has modest memory requirements and can be locally parallelized at each layer of the regularization path . finally , we posit that extending our algorithm to the entire @xmath2-dimensional regularization path would facilitate processing of further special cases .",
    "hsieh , c. j. , chang , k. w. , lin , c. j. , keerthi , s. s. , sundararajan , s. ( 2008 ) . a dual coordinate descent method for large - scale linear svm . in _ proceedings of the 25th international conference on machine learning _",
    ", 408 - 415                pedregosa , f. , varoquaux , g. , gramfort , a. , michel , v. , thirion , b. , grisel , o. , et al . ,",
    "duchesnay , e. ( 2011 ) .",
    "scikit - learn : machine learning in python .",
    "_ the journal of machine learning research _ , 12 , 2825 - 2830      chu , b. y. , ho , c. h. , tsai , c. h. , lin , c. y. , lin , c. j. ( 2015 ) .",
    "warm start for parameter selection of linear classifiers .",
    "_ acm sigkdd international conference on knowledge discovery and data mining _ , 149 - 158"
  ],
  "abstract_text": [
    "<S> we propose an algorithm for exploring the entire regularization path of asymmetric - cost linear support vector machines . </S>",
    "<S> empirical evidence suggests the predictive power of support vector machines depends on the regularization parameters of the training algorithms . </S>",
    "<S> the algorithms exploring the entire regularization paths have been proposed for single - cost support vector machines thereby providing the complete knowledge on the behavior of the trained model over the hyperparameter space . </S>",
    "<S> considering the problem in two - dimensional hyperparameter space though enables our algorithm to maintain greater flexibility in dealing with special cases and sheds light on problems encountered by algorithms building the paths in one - dimensional spaces . </S>",
    "<S> we demonstrate two - dimensional regularization paths for linear support vector machines that we train on synthetic and real data . </S>"
  ]
}