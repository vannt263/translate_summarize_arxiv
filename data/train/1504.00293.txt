{
  "article_text": [
    "in 1867 , at the dawn of statistical physics , maxwell imagined a thought experiment that has both troubled and inspired physicists ever since @xcite . in modern language",
    ", the issue is that traditional thermodynamics posits a strict separation between observable macroscopic motion ( dynamical systems ) and unobservable degrees of freedom ( heat ) . but",
    "imagine  as can now be done experimentally on small systems where fluctuations are important  that it is possible to observe some of these hidden degrees of freedom .",
    "( maxwell s thought experiment used a  demon \" to accomplish the same task . ) in any case , the entropy of the system is reduced , and one can use the lower entropy to extract work from the surrounding heat bath , in seeming violation of the second law of thermodynamics .    this blurring of macroscopic and microscopic degrees of freedom has led to a new field , _ stochastic thermodynamics _ , which clarifies how thermodynamics should be applied to small systems where fluctuations are observable and important @xcite . as we will see below , the nature of information acquired about the fluctuations  especially the precision with which they are measured and the time they become available  is of great importance .",
    "indeed , information is itself a thermodynamic resource , and stochastic thermodynamics can be extended to accommodate the acquisition , dissipation , flow , and feedback of information @xcite .",
    "for a recent review , see @xcite .",
    "the goal of the present contribution is to combine ideas from control theory ( state estimation ) @xcite with ideas from computer science about hidden markov models @xcite in order to explain some recent surprising observations from stochastic thermodynamics about how maxwell s demon operates in the presence of measurement errors @xcite . as a bonus ,",
    "the formalism we discuss suggests a number of interesting areas where the stochastic thermodynamics of information may be extended .",
    "in the simplest non - trivial example of a discrete state space , a state @xmath0 can , at each discrete time point , take on one of two values , for example @xmath1 and @xmath2 . while systems such as spin-@xmath3 particles are inherently discrete , a broad range of physical systems  even classical , continuous state spaces  can often be well approximated by discrete systems after coarse graining .",
    "figure  [ fig : markov](a ) sketches such a system , a protein in solution that alternates between a loose unfolded ( @xmath1 ) and a compact folded ( @xmath2 ) state .",
    "other biological examples of two - state systems include ion channels that can be open or closed , gene - transcription repressor sites that can be occupied or empty , and sensory receptors that can be active or silent ( chapter 7 in @xcite ) .     states .",
    "( c ) graphical depiction of a symmetric two - state markov chain.,width=576 ]    figure  [ fig : markov ] illustrates schematically how to coarse grain from a physical situation , such as a protein in water , to a discrete - time markov model . in ( a ) , we depict two states of the protein , labeled  unfolded \" and  folded \" or , equivalently , @xmath1 and @xmath2",
    ". the word  state \" is here a shorthand for  macrostate \" and is associated with many microstates , each of which corresponds to a slightly different protein conformation that preserves the general property in question . in ( b ) , we project the full dynamics onto a one - dimensional subspace modeled by a double - well potential . states with @xmath4 are classified as @xmath1 , and states with @xmath5 are classified as @xmath2 .",
    "the symmetry of the potential implies that the protein spends equal time in the two states , which is a special situation . in ( c )",
    ", we show a graphical depiction of the discrete , two - state markov chain dynamics , where in a time @xmath6 , states remain the same with probability @xmath7 and hop to the other with probability @xmath8 . in order for a two - state description to reasonably approximate the dynamics",
    ", the dwell time spent in each well must be much longer than the time scale for fast motion within a well .",
    "this holds when a single energy barrier @xmath9 separates two states and whose height is much larger than @xmath10 .",
    "why might we want to approximate physical systems by discrete state spaces ?    * _ clarity _ : we can isolate just the important degrees of freedom , letting the others be uncontrolled and even unobserved . * _",
    "simplicity _ : the mathematical description is more straightforward . * _ generality _ : any dynamics that can be modeled on a computer is necessarily discretized in both time and state .",
    "let us briefly recall the basics of discrete - state - space systems in discrete time . consider a system described at time @xmath11 by a state @xmath12 that can be in one of @xmath13 possible states , indexed by the values @xmath14 to @xmath13 .",
    "the index is distinguished from its _ value _ , which , for a two - state system , might be @xmath15 , @xmath16 , or even @xmath17left , right@xmath18 .",
    "let @xmath19 be the probability that , at time @xmath11 , the system is in the state indexed by @xmath20 .",
    "the distribution is normalized by enforcing @xmath21 or , more succinctly , @xmath22 . for dynamics",
    ", we consider _ markov chains _ , which are systems with discrete time and discrete states .",
    "the markov property implies that the next state depends only on the current state , as illustrated graphically in figure  [ fig : graphicalmarkov ] , which may be compared with figure  [ fig : markov](c ) .",
    "depends only on @xmath12.,width=480 ]    for markov chains , the dynamics are specified in terms of an @xmath23 _ transition matrix _ @xmath24",
    "whose elements @xmath25 satisfy @xmath26 .",
    "that is , @xmath27 gives the rate of @xmath28 transitions .",
    "for example , a general two - state system has @xmath29 notice that the columns of @xmath24 sum to 1 , as required by the normalization of probability distributions . in words ,",
    "if you start in state @xmath30 then you must end up in one of the @xmath13 possible states , indexed by @xmath20 .",
    "figure  [ fig : markov](c ) depicts graphically , with @xmath31 .",
    "a matrix with elements @xmath26 and @xmath32 is a ( left ) _",
    "stochastic matrix_.    define the @xmath13-dimensional _ stochastic vector _",
    "@xmath33 , whose elements @xmath34 give the probability to be in state @xmath30 at time @xmath11 . then @xmath35 and @xmath36 and @xmath37 more compactly , @xmath38 , a linear difference equation with solution @xmath39 known as the _ discrete - time master equation_. often , we seek the steady - state distribution , defined by @xmath40 . one way to find @xmath41 is to repeatedly iterate ; another is to note that the steady - state distribution of probabilities corresponds to the eigenvector associated with an eigenvalue equal to 1 .",
    "a stochastic matrix must have such an eigenvalue , since @xmath42 is a matrix whose columns all sum to zero .",
    "they are then linearly dependent , with zero determinant .    for example , the two - state markov model with transition matrix @xmath24 given by has eigenvalues @xmath43 and @xmath44 .",
    "the normalized eigenvector corresponding to @xmath45 is @xmath46 for the symmetric case , @xmath47 and @xmath48 0.5 \\end{smallmatrix } \\bigr)$ ] , independent of @xmath8 . by symmetry ,",
    "both states are _ a priori _ equally probable .",
    "often , the states of a markov chain are not directly observable ; however , there may be measurements ( or _ emitted symbols _ ) that correlate with the underlying states .",
    "the combination is known as a _ hidden markov model _ ( hmm ) .",
    "the hidden states are also sometimes known as _ latent _ variables @xcite .",
    "the observations are assumed to have no memory : what is measured depends only on the current state , and nothing else .",
    "the graphical structure of an hmm is illustrated in figure  [ fig : hmmfig ] .",
    "form a markov process that is not directly observable .",
    "the observations @xmath49 depend only on @xmath12.,width=480 ]    in the example of proteins that alternate between unfolded and folded states , the molecule itself is not directly observable .",
    "one way to observe the configuration is to attach a particle to one end of the protein and anchor the other end to a surface @xcite , as illustrated in figure  [ fig : hmmfig](a ) . as the protein folds and unfolds , the particle moves up and down from the surface .",
    "we can illuminate the region near the surface using an evanescent wave via the technique known as total internal reflection microscopy .",
    "the intensity @xmath50 of light scattered by the bead at height @xmath51 from the surface will decrease exponentially as @xmath52 , with @xmath53 nm .",
    "the two states will then correspond to two different scattering intensities .",
    "the observation @xmath49 is the number of recorded photons , integrated over a time that is shorter than the dwell time in each local potential well .",
    "are indicated by round markers and have gaussian noise , with standard deviation @xmath54 ( top ) and @xmath55 ( bottom ) .",
    "histograms of @xmath49 are compiled from @xmath56 observations , with 100 shown.,width=576 ]    as with states , we can further simplify by discretizing the intensities , classifying as  dim \" intensities below a given threshold and  bright \" intensities above that threshold .",
    " dim \" and  bright \" then become two observation _ symbols_.",
    "because light scattering is itself a stochastic process , the protein can be in one state but emit the ",
    "wrong \" symbol , as illustrated in figure  [ fig : hmmfig](b ) .",
    "we can describe such a situation by defining the observations @xmath57 and noting that they are related to the states probabilistically via an _ observation matrix _",
    "@xmath58 having components @xmath59 : @xmath60 where we suppose , for simplicity , that errors are symmetric . because observations have no memory , the probability to observe @xmath49 depends only on the current state @xmath12 .    in words ,",
    "the matrix @xmath58 states that an observation is correct with probability @xmath61 and wrong with probability @xmath62 . like the transition matrix @xmath24 ,",
    "the matrix @xmath58 is stochastic , with columns that sum to 1 .",
    "its rows also sum to 1 , but only because of the symmetry between states .",
    "note that the number of observation symbols , @xmath63 , need not equal the number of internal states , @xmath13 .",
    "the @xmath64 matrix @xmath58 can have @xmath63 bigger or smaller than @xmath13 .",
    "the case of continuous observations ( @xmath65 ) is also straightforward .",
    "larger values of @xmath63 increase knowledge of the underlying state somewhat .",
    "one interesting feature of hmms is that states @xmath12 follow a markov process and so does the combined process for @xmath12 and @xmath49 , but not necessarily the observations @xmath49 .",
    "the analysis of hmms is thus more difficult than for ordinary markov processes .",
    "the literature on hmms is both vast and dispersed . for treatments of increasing complexity , see section 16.3 of _ numerical recipes _ @xcite , the bioinformatics book by durbin et al .",
    "@xcite , a classic tutorial from the speech - recognition literature @xcite , the control - influenced book by srkk @xcite , and the mathematical treatment of capp et al .",
    "the tutorial by rabiner @xcite has been particularly influential ; however , its notation and ways of deriving results are more complicated than need be , and some of its methods have been replaced by better algorithms .",
    "the discussion here is based largely on the cleaner derivations in @xcite .",
    "hidden markov models are specified by a transition matrix @xmath24 and observation matrix @xmath58 .",
    "let us pose the following problem : given the output of a hidden markov model ( hmm ) , what can be inferred about the states ?",
    "the answer depends both on the information available and the exact quantity desired . here",
    ", we focus on two cases :    1 .",
    "_ filtering _ , or @xmath66 .",
    "we estimate the probabilities for each state based on observations @xmath67 up to and including the present time @xmath11 .",
    "filtering is appropriate for real - time applications such as control .",
    "is @xmath68 .",
    "our notation seems cleaner and easier to read .",
    "_ smoothing _ , or @xmath69 , for @xmath70 . smoothing uses data from the future as well as the past in the offline post - processing of @xmath71 observations .",
    "another quantity of interest is the _ most likely path _ , defined as @xmath72 , which may be found by an algorithm due to viterbi @xcite . for example , mckinney et al .",
    "study transitions between different configurations of a dna holliday junction , using fluorescence resonance energy transfer ( fret ) to read out the states , and infer the most likely state sequence @xcite .",
    "since path estimates are less useful for feedback control , we will consider them only in passing , in section  [ sec : hmm - phase - trans ] .",
    "we will also see that smoothing estimates provide a useful contrast with filter estimates .",
    "the filtering problem is to find the probability distribution of the state @xmath12 based on the past and current observations @xmath73 from time 1 to time @xmath11 .",
    "we assume that the dynamics have been coarse grained to be markov , so that the state @xmath74 depends only on the state @xmath12 .",
    "then @xmath75 , where the  cancel \" slash indicates conditional independence : conditioning on @xmath12  blocks \" the influence of all other variables .",
    "the @xmath76 are blocked , too : the state at time @xmath77 depends _ only _ on the state at time @xmath11 .    from marginalization and the definition of conditional probability",
    ", we have @xmath78 equation   predicts the state @xmath74 on the basis of @xmath73 , assuming that the previous filter estimate , @xmath66 is already known .",
    "once the new observation @xmath79 is available , we can use bayes theorem and the memoryless property of observations , @xmath80 , to update the prediction to incorporate the new observation .",
    "then , @xmath81 where @xmath82 normalizes the distribution .",
    "equations  constitute the bayesian filtering equations @xcite . because of their importance , we collect them here :    align p(x_k+1 | y^k ) & = _ x_k p(x_k+1 | x_k ) p(x_k |",
    "y^k ) & & + & & & + p(x_k+1 |",
    "y^k+1 ) & = p(y_k+1 |",
    "x_k+1 ) p(x_k+1 |",
    "y^k ) & & .",
    "[ eq : hmm - bayesian - filter ]    the normalization ( _ partition function _ ) @xmath82 is given by @xmath83    note that the hmm literature , e.g. , @xcite and @xcite , expresses differently , using joint probabilities such as @xmath84 rather than conditional probabilities such as @xmath66 .",
    "using joint probabilities leads to the _",
    "forward algorithm_. our notation emphasizes the similarities between hmm and state - space models of dynamics ; the formulas of one apply mostly to the other , with @xmath85 . for continuous state spaces with linear dynamics and gaussian",
    "noise , is equivalent to the _ kalman filter _ @xcite .",
    "below , we will see that using conditional probabilities also has numerical advantages .     and @xmath86 .",
    "light gray line shows true state , which is hidden .",
    "markers show 100 observations .",
    "heavy black line shows the probability that the state equals @xmath2 , given by @xmath87 .",
    "the maximum confidence level @xmath88 ( dashed line).,width=576 ]    figure  [ fig : hmm - hmminffilter ] shows filtering in action for a symmetric , two - state , two - symbol hidden markov model .",
    "the time series of observations @xmath49 ( markers ) disagrees with the true state 30% of the time .",
    "the black line shows @xmath89 .",
    "when that probability is below the dashed line at @xmath90 , the most likely state is 0 . for the value of @xmath8 used in the dynamic matrix ( @xmath91 ) ,",
    "the filter estimate @xmath92 arg max@xmath93 @xmath66 disagrees with the observation only 7% of the time , a noticeable improvement over the naive 30% .",
    "notice that whenever the state changes , the filter probability responds , with a time constant set by both observational noise ( @xmath62 ) and dynamics ( @xmath8 ) .",
    "a long string of identical observations causes filter confidence to saturate at @xmath94 ( dashed line ) .",
    "there is an advantage to recording the probability estimates ( black line ) rather than simply the map ( maximum a posteriori ) estimate , which here is just the more likely of the two possibilities .",
    "when the filter is wrong , the two probabilities are often not that different .",
    "an example is indicated by the arrow in figure  [ fig : hmm - hmminffilter ] .",
    "thus , marginalizing ( averaging ) any prediction over all possibilities rather than just the most likely will improve estimates .",
    "of course , a string of wrong symbols can fool the filter .",
    "see , in figure  [ fig : hmm - hmminffilter ] , the three wrong symbols just to the left of the arrow .",
    "below , we will see that the filtered estimate becomes significantly more reliable as @xmath95 .",
    "intuitively , small @xmath8 means that states have a long _ dwell time _ , so that averaging observations over times of the order of the dwell time can reduce the effect of the observational noise , which is quantified by the parameter @xmath62 .",
    "if we estimate the state @xmath12 after gathering @xmath71 observations ( @xmath70 ) , we can use the  future \" information to improve upon the filter estimate . in the control - theory literature ,",
    "such estimates are called  smoother \" estimates , as they further reduce the consequences of observation noise .",
    "the smoother estimate has two stages .",
    "first , we use the filter algorithm to calculate @xmath96 and @xmath97 for each @xmath98 $ ] .",
    "then we calculate @xmath69 via a backward recursion relation from the final time @xmath71 to the initial time @xmath14 .",
    "align p(x_k | y^n ) = p(x_k | y^k ) _ x_k+1 .",
    "[ eq : hmm - backward - alg ]    the backwards recursion relation is initialized by @xmath99 , the last step of the forward filter recursion .",
    "to derive , we introduce the state @xmath74 , which we will remove later by marginalization @xcite .",
    "thus , @xmath100 but @xmath101 using conditional probability and the markov property .",
    "substituting into , @xmath102 summing both sides over @xmath74 gives .",
    "the algorithm defined by and is equivalent to the _ rauch - tung - striebel smoother _ from control theory when applied to continuous state spaces , linear dynamics , and white - noise inputs  @xcite . in the hmm literature ,",
    "a close variant is the _ forward - backward algorithm _  @xcite .     and @xmath86 .",
    "filter estimate is shown as a light gray trace .",
    "the simulation and filter estimate are both from figure  [ fig : hmm - hmminffilter].,width=576 ]    we can apply the smoother algorithm to the example of section  [ sec : hmm - filtering ] and obtain similar results . in figure",
    "[ fig : hmm - hmminfsmoother ] , we plot the smoother estimate , with the filter estimate added as a light gray trace . despite their similarity , the differences are instructive : the filter always lag ( reacts ) to observations , whereas the smoother curve is more symmetric in time . flipping the direction of time",
    "alters the overall form of the filter plot but not the smoother .",
    "the smoother estimates are more confident than the filter estimates , as they use more information .",
    "look at the time step indicated by the arrow . the filter estimate is just barely mistaken , but the smoother estimate makes the correct call , aided by the three correct observations that come before and the three after .",
    "the phase lag apparent in the filter estimate is consistent with causality .",
    "indeed , for continuous state spaces , the well - known bode gain - phase relations  the  magnitude - phase \" equivalent of the kramers - kronig relations @xcite  give the minimum phase lag for the output of a dynamical system that is consistent with causality . the smoother estimate in figure  [ fig : hmm - hmminfsmoother ]",
    "zero _ phase lag , as expected since it uses past and future information equally .",
    "sudden jumps are anticipated by the smoother _ before _ they happen .    intuitively , an estimator that uses more information should perform better .",
    "we can formalize this intuition via the notion of conditional _ shannon entropy _ @xcite . with @xmath103 , @xmath104 where using a base-2 logarithm gives units of _ bits_. for large - enough @xmath11 ,",
    "the average of @xmath105 over @xmath73 becomes independent of @xmath11 .",
    "averaging over a single long time series of observations then leads to @xmath106 , where @xmath107 denotes past and present observations .",
    "a similar definition holds for the smoother entropy , @xmath108 and leads to a steady - state smoother entropy @xmath109 , where @xmath110 includes both past and future observations . to characterize the performance of filtering and smoothing , we recall that for a two - state probability distribution , the entropy ranges from 1 bit ( equal probabilities for each possibility ) to 0 bits ( certainty about each possibility ) .",
    "has parameter @xmath111 .",
    "( b ) filter minus smoother .",
    "calculations use time series of length @xmath112.,width=480 ]    figure  [ fig : filtervsmoother](a ) shows the steady - state filter and smoother shannon entropies as a function of @xmath62 , the error rate in the observation matrix @xmath58 . at small values of @xmath8 , the smoother has a greater advantage relative to the filter : when dwell times in each state are long , the information provided by averaging is more important . figure  [ fig : filtervsmoother](b ) plots the difference between filter and smoother entropies . for @xmath113 ,",
    "the difference vanishes : with no noise , the observation perfectly determines the state , and there is no uncertainty about it afterwards . for @xmath114 ,",
    "the observations convey no information , and @xmath115 bit and the difference is again zero .",
    "for intermediate values of @xmath62 , the smoother entropy is lower than the filter entropy .",
    "the state - estimation procedures described above assume that the transition matrix @xmath24 , the emission matrix @xmath58 , and initial probability @xmath116 are known . if not , they can be estimated from the observations @xmath117 . in the context of hmms , the task is called , variously , _ parameter inference _ , _ learning _ , and _ training _ @xcite . in the control - theory literature on continuous state spaces ,",
    "it is known as _ system identification _ @xcite .",
    "the general approach is to maximize the likelihood of the unknown quantities , grouped here into a single parameter vector @xmath118 .",
    "that is , we seek @xmath119 \\ , , \\label{eq : hmm - max - likelihood - pars}\\ ] ] where it is better to compute @xmath120 because @xmath121 decreases exponentially with @xmath71 , leading to numerical underflow .",
    "the negative sign is a convention from least - squares curve fitting , where @xmath122 is also proportional to the negative log likelihood of the data @xcite .",
    "we can find the total likelihood @xmath121 from the normalization condition in : @xmath123 where @xmath124",
    ". then @xmath125 where all right - hand - side terms depend also on @xmath118 .",
    "since @xmath126 is just a function of @xmath118 , we can use standard optimization routines to find the @xmath127 that minimizes @xmath128 .    in the hmm literature , an alternate approach to finding @xmath127",
    "is based on the expectation maximization ( em ) , or baum - welch algorithm @xcite . in a two - step iteration",
    ", one finds @xmath129 by maximum likelihood assuming that the hidden states @xmath130 are known and then infers states @xmath130 from the smoother algorithm assuming @xmath118 is known .",
    "the algorithm converges locally but can be very slow . indeed , the em algorithm can seldom compete against the more sophisticated direct - optimization algorithms readily available in standard scientific programming languages .",
    "em algorithms can , however , be the starting point for recursive variants that allow for adaptation @xcite . a third approach to finding hmm parameters , based on finding the most likely ( viterbi ) path ,",
    "can also converge faster than em and be more robust @xcite .",
    "we can now discuss the control of markov models and hmms . in the context of discrete state spaces , the control @xmath131 influences the transition probability , which becomes @xmath132 and is described by a time - dependent transition matrix @xmath133 and a graphical structure illustrated in figure  [ fig : graphicalpomdp ] .",
    "note that our previous discussion of state estimation ( filtering ) never assumed that the transition matrix is time independent .",
    "form a markov process whose transitions depend both on states @xmath12 and observations @xmath49.,width=480 ]    the control of markov chains is formally known as a",
    "_ markov decision process _",
    "( mdp ) , while that of hmms is known as a _ partially observable markov decision process _ ( pomdp ) .",
    "optimal - control protocols that minimize some cost function can be found using bellman s dynamic programming , which is a general algorithm for problems involving sequential decisions @xcite . in this",
    "setting , control is viewed as a blend of state estimation and decision theory @xcite .",
    "the goal is to choose actions based on available information in order to minimize a cost function .",
    "here , we will present such ideas more informally , using a well - studied example : optimal work extraction from a two - state system with noisy observations and feedback .",
    "this problem is closely related to a famous thought experiment ( recently realized experimentally @xcite ) , maxwell s demon .      as discussed in the introduction ,",
    "a maxwell demon is a device where information about the state of a system is used to extract energy from a heat bath , in violation of the traditional form of the second law of thermodynamics .",
    "how is this possible ?",
    "the catch is that we have assumed that information carries no cost .",
    "a first attempt at resolving the paradox hypothesized that energy is dissipated in acquiring information @xcite .",
    "however , that turns out not to be true in general : one can sometimes acquire information without doing work . in its kelvin - planck formulation",
    ", the second law requires that no cyclic protocol of parameter variation can extract work from the heat bath of an equilibrium system held at constant temperature .",
    "specifying a cyclic protocol can be subtle .",
    "naively , a cyclic protocol requires that any potentials that are changed must be returned to their initial state ; any mechanical part ( pistons , etc . ) that are moved must be moved back ; and so on .",
    "but it also applies to information . in particular ,",
    "any information acquired must be erased . in 1961",
    ", landauer proposed that the erasure step necessarily required energy dissipation of at least @xmath134 per bit , an amount that equals or exceeds the amount of work that can be extracted , thus saving ( or extending ) the second law @xcite .",
    "landauer s prediction has recently been confirmed experimentally @xcite , as has its converse , the szilrd engine , which uses acquired information to extract work from a heat bath @xcite .    .",
    "if the system is observed to be in its right - well state , then we can raise the left well without doing work .",
    "after a time @xmath6 , the well is lowered .",
    "if the left state is occupied , we extract an energy @xmath135 that can be used to perform work.,width=576 ]      we consider a particle in a fluid , subject to a double - well potential that may be manipulated by the experimenter ( figure  [ fig : hmm - optimalworkextraction ] ) .",
    "it is a useful setting for thinking about the issues raised by a maxwell demon and is a situation that can now be realized experimentally @xcite .",
    "we assume that the energy barrier is large ( @xmath136 ) , so that we can coarse grain to two - state markov dynamics , as discussed in section  [ sec : hmm - coarse - graining ] . henceforth , we set @xmath137 . at intervals",
    "@xmath6 , we observe the state of the system and record which well the particle is in .",
    "for now , we assume this measurement is never wrong .    to extract work from a heat bath ,",
    "we implement the following protocol : at @xmath138 , the potential is symmetric , with no energy - level difference between left and right wells .",
    "we then observe the particle .",
    "if we determine it to be in the right well , then , with no significant time delay , we quickly raise the left well to an energy @xmath135 ( and vice versa if in the left well ) . raising the left",
    "well costs no work if we change the potential only where the particle is not present . from sekimoto",
    "s formulation of stochastic energetics , the work done by an instantaneous change of potential is just @xmath139 , the change of potential evaluated _ at the position of the particle _ @xcite .",
    "we then wait a time @xmath6 , keeping fixed the energy @xmath135 of the left well . at some time",
    ", the particle may spontaneously hop to the left well , because of thermal fluctuations . at time @xmath6",
    ", the left well is quickly lowered back to @xmath140 .",
    "if the particle happens to be in the left well , we extract an energy @xmath135 from the heat bath . if not , no energy is extracted .",
    "summarizing , the protocol is to measure the state ; then raise the appropriate well by @xmath135 and wait @xmath6 ; then lower the well back to 0 .",
    "over many trials , the average extracted work @xmath141 is given by @xmath142 , where @xmath143 is the probability for the particle to be in the left well at time @xmath6 .",
    "but @xmath144 also depends on @xmath135 . to evaluate the relation",
    ", we consider the _ continuous time _ dynamics of the state of the system , allowing hops between states at arbitrary times @xmath145 but still considering the hops themselves to be instantaneous . the discrete - time master equation",
    "@xmath38 then becomes @xmath146 , where the matrix @xmath147 has columns that sum to zero , to keep @xmath41 normalized at all times .",
    "normalization implies that a two - state system has but one independent evolution equation , @xmath148 , which obeys @xmath149 where @xmath150 is the transition rate out from the left well and @xmath151 is the transition rate into the left well . in equilibrium ,",
    "detailed balance requires that @xmath152 . scaling time so that @xmath153 then gives @xmath154    setting @xmath155 gives the steady - state solution @xmath156 .",
    "notice that @xmath140 implies @xmath157 , as expected for a symmetric double - well potential , and that @xmath158 implies that the particle is always in the right well ( @xmath159 ) . for finite times , we solve with @xmath160 .",
    "the solution , @xmath161 $ ] , implies that @xmath162 \\ , .",
    "\\label{eq : avg - energy}\\ ] ] note that we choose signs so that @xmath163 corresponds to work extraction .",
    "intuitively , for a given cycle time @xmath6 , an optimal energy @xmath164 maximizes the average work : if @xmath135 is too small , you will extract work in many cycles , but the amount each time will be small . if @xmath135 is too large , you will extract more work , but only very rarely , since the relative probability of being on the left side is @xmath165 . for the quasistatic limit @xmath166 , @xmath167 , whose maximum @xmath168 for @xmath169 .",
    "the second law of thermodynamics implies that @xmath170 , where the free energy difference @xmath171 is just the difference in entropy @xmath172 , since the internal energy difference is zero for a cyclic process where the energies of both states are identical at beginning and end .",
    "the maximum entropy difference is @xmath173 , which is considerably larger than the @xmath174 found in the quasistatic limit of our protocol .    to achieve the @xmath175 upper bound for extracted work per cycle",
    ", we need to allow @xmath176 to vary continuously in the interval @xmath177 ( and to have jump discontinuities at the beginning and end of the interval ) .",
    "such continuous - time protocols have been considered previously and lead to protocols that extract @xmath175 of work in the quasistatic limit @xcite .",
    "nonetheless , we prefer our constant-@xmath135 protocol :    * the mathematics is simpler .",
    "the continuous version uses calculus of variations .",
    "the discrete one requires only ordinary calculus . *",
    "if implemented experimentally , the protocols would almost certainly be carried out digitally , with an output that is fixed between updates .",
    "* when the goal is to optimize power extraction from the heat bath ( rather than work per cycle ) , the constant-@xmath135 and continuous protocols give identical results .",
    "to explore this last point , we rewrite for average power , @xmath178 .",
    "assuming , as a more careful analysis confirms , that maximum average power extraction occurs when @xmath179 , we have @xmath180 = e \\ , e^{-e } \\",
    ", , \\label{eq : avg - power}\\ ] ] which has a maximum @xmath181 for @xmath182 .",
    "the same result is found for the continuous protocol @xcite . since maximum energy extraction requires quasistatic , infinitely slow manipulations , the power at maximum energy tends to zero .",
    "maximizing power extraction is arguably more interesting experimentally .",
    "so far , we have assumed noise - free observations .",
    "if the observations are noisy , we have to infer the probability @xmath183 that the particle is in the left well . assuming that the particle is likely in the right well ( @xmath184 )",
    ", then we should raise the left well . after a time @xmath6 has elapsed , implies that @xmath185 with @xmath186 and @xmath187 .",
    "this expression is linear in @xmath188 , as the master equation is linear .",
    "the discrete - time master equation for time step @xmath6 then is @xmath189 matching terms with @xmath190 gives @xmath191 and @xmath192 .",
    "the complements are @xmath193 and @xmath194 .",
    "thus , when the left well is raised , the transition matrix @xmath195 is @xmath196 notice that the columns of @xmath197 sum to one , as they must and that the markov transition matrix is no longer symmetric , as expected since we raise one of the wells .",
    "the novel aspect for us is that the transition matrix @xmath197 now depends on the energy level @xmath135 , which can be set at each time step .",
    "when the right well is raised , matrix elements are switched , with left @xmath198 right .",
    "this amounts to swapping  across the diagonal \" of the matrix .",
    "thus , @xmath199    the previously analyzed case for @xmath200 then represents the best - case scenario : the particle is definitely on the right , and there is never a penalty for raising the left well . for @xmath184 , we will occasionally do work in raising the well when the particle is present . using and maximizing over @xmath135 , we can quickly calculate the maximum work extraction as a function of @xmath188 .",
    "figure  [ fig : maxwelldemonwork](a ) shows that the maximum average extracted work decreases as the initial state becomes more uncertain .",
    "when @xmath201 , we have no information about the state of the system and can not extract work from the heat bath , in accordance with the usual version of the second law . for @xmath202 , we would raise the right well , else we would be erasing information and heating the bath , rather than extracting energy from it .",
    "figure  [ fig : maxwelldemonwork](b ) shows that the work extracted is nearly a linear function of the change in shannon entropy between initial and final states . as in szilrd",
    "s analysis , information was used to extract work from the heat bath .",
    "here , the average slope ( converted to nats ) gives an efficiency of roughly 41% .",
    "less than half the information gained is extracted as work by this particular protocol .    .",
    "( a ) average work @xmath141 vs. probability to be in the left well at time 0 .",
    "( b ) vs. information gain.,width=480 ]      we have not yet specified how to estimate @xmath188 at the beginning of each time interval .",
    "we do so via the observations @xmath49 that are made at the beginning of each control period @xmath6 , before the choice of @xmath135 .",
    "the observations have two symbols and are characterized by an observation matrix of the form of , with @xmath62 the symbol error rate .",
    "we thus return to the formalism discussed in section  [ sec : hmm - state - estimation ] , where @xmath203 , the state of the system at time @xmath11 .",
    "similarly , @xmath204 .",
    "the only difference is that we modify @xmath24 by choosing @xmath135 and which well to raise at each time step .",
    "call the choice @xmath133 .",
    "we can incorporate observations in two ways .",
    "one is to use only the observation @xmath49 to estimate @xmath205 .",
    "then bayes theorem implies that @xmath206 , where the prior @xmath207 , since left @xmath208 right and right @xmath208 left state transitions are equally likely .",
    "although @xmath209 does not satisfy this condition , the time - averaged sequence of transition matrices does : since left and right levels are raised at equal frequencies , the overall statistics are symmetric in the absence of other information . here , @xmath131 is the control variable , a function of @xmath135 .",
    "the second way is to use the filtering formalism developed in section  [ sec : hmm - filtering ] to recursively compute @xmath66 .",
    "( without information about the future , we can not use smoothing . )",
    "we can say that the second strategy , which depends on past observations , uses memory whereas the first uses no memory .",
    "the procedure is then to    * measure @xmath49 .",
    "* update @xmath66 , based on @xmath210 , with the time - dependent transition matrix @xmath133 given by @xmath209 .",
    "the control @xmath131 is a function of @xmath211 . *",
    "determine @xmath212 by minimizing @xmath213 , the average work extracted in a cycle .",
    "* apply @xmath214 .     to",
    "that using only the current state @xmath49 .",
    "( b ) difference between the two extracted powers .",
    "cycle time @xmath215.,width=480 ]    iterated , the above algorithm leads to plots of the average extracted work as a function of the measurement - error probability @xmath62 ( figure  [ fig : maxwelldemon ] ) . in ( a )",
    ", the curve labeled _ memory _ , uses the bayesian filter to estimate the state of the system . by",
    " memory , \" we mean that the inference about which energy level to alter is based on all the observations @xmath73 up to time @xmath11 . by contrast , in ( b ) , the  no memory \" curve uses only the current observation , @xmath49 . as before ,",
    "the extra information from past states is most useful at intermediate values of error rate @xmath62 .",
    "the difference curve , plotted at left below , resembles figure  [ fig : filtervsmoother ] , which compared estimator entropies of the smoother and filter state estimates .",
    "the conclusion , again , is that extra information is most useful at intermediate signal - to - noise ratios . here",
    ", retaining a memory of past observations via the filter allows the maxwell demon to extract more power from the heat bath .      the continuous - protocol version of the maxwell demon shows phase transitions in the behavior of the maxwell demon as the symbol error rate @xmath62 is varied @xcite .",
    "to see that similar phenomena arise in the constant-@xmath135 protocol discussed in this paper , compare the outcomes of the strategy that uses memory ( @xmath73 ) with one using no memory ( @xmath49 ) .",
    "more precisely , we define a  discord \" order parameter @xmath216 , @xmath217 where @xmath218 represents the time series of observations and @xmath219 represents the state estimate , based in this case on the optimal filter . if @xmath220 and @xmath221 always agree , @xmath222 . if @xmath220 and @xmath221 are uncorrelated , @xmath223 .",
    "partial positive correlations imply @xmath224 .",
    "put differently , @xmath225 implies that there is value in having a memory , as the filter estimate @xmath221 can differ from the observation . when @xmath226 , the filter always agrees with the observation , implying that there is no value in calculating the filter .    .",
    "black down - pointing arrows mark jump discontinuities .",
    "red up - pointing arrow marks a continuous phase transition .",
    "( b ) similar plot for hmm , for three values of transition matrix parameter @xmath8.,width=576 ]    in figure  [ fig : maxwellhmmphasetrans](a ) , we plot the discord order parameter @xmath216 against the symbol error rate @xmath62 for three different cycle times , @xmath215 , 1 , and 10 .",
    "there are many interesting features . for long cycle times , represented by @xmath227 and hollow markers ,",
    "observations match the inferred state  defined here to be the more likely state , as determined by the probabilities from the filter algorithm . for intermediate cycle times , represented by @xmath228 and red markers , there is a continuous bifurcation , or second - order phase transition , indicated by an up - pointing red arrow at @xmath229 .",
    "( the apparent discontinuity results from the limited resolution of the plot . at higher resolution ,",
    "not shown , the bifurcations are clearly continuous . ) for @xmath230 , the filter estimate and observation always agree . for @xmath231",
    ", they disagree sometimes . for short cycle times , represented by @xmath215 and black markers ,",
    "we observe two transitions that , upon closer inspection , are both discontinuous , corresponding to first - order phase transitions and marked by down - pointing black arrows . finally , at @xmath114 , the order parameter @xmath232 , since there is no correlation between observation and the internal state ( or its estimate ) .",
    "interestingly , there is always a jump discontinuity in @xmath216 at @xmath114 .",
    "the phase transition observed in the maxwell - demon model given in the previous section can also be seen in hidden markov models that have nothing to do with thermodynamics .",
    "figure  [ fig : maxwellhmmphasetrans](b ) shows the discord order parameter @xmath216 for a two - state , two - symbol hmm with @xmath233 , for three values of @xmath8 . as in figure",
    "[ fig : maxwellhmmphasetrans](a ) , there are first - order transitions for small values of @xmath8 , continuous transitions for intermediate values , and no transitions for larger values .",
    "intuitively , we need long dwell times in states ( low values of @xmath8 ) so that we have time to average over ( filter ) the observation noise .",
    "if so , we may be confident in concluding the true state is different from the observed state .",
    "if the dwell time is short ( high value of @xmath8 ) , the best strategy is to trust the observations .",
    "note that the values of @xmath8 correspond roughly to the same regimes as implied by the values of @xmath6 ; however , we can not make an exact mapping , since the markov transition rate in the maxwell - demon depends on the control @xmath131 , which depends on observation errors @xmath62 .    as with the maxwell - demon example",
    ", for given @xmath8 there is a critical value of @xmath62 , denoted @xmath234 . to calculate @xmath234",
    ", we note that there is an upper limit to the confidence one can have in a given state estimate .",
    "as we can see in figure  [ fig : hmm - hmminffilter ] , this limit is achieved after a long string of identical observations , say @xmath235 , that is @xmath236 .",
    "see the string of eight @xmath2 states in figure  [ fig : hmm - hmminffilter ] as an example .",
    "more formally , we consider @xmath237 . for @xmath238 , the maximum value of the state probability approaches a fixed point @xmath94 at long times .",
    "the intuition is that even with a long string of @xmath2 observations , you can not be sure that there has not just been a transition and an accompanying observation error .",
    "we derive @xmath239 in [ sec : appa ] and plot the results in figure  [ fig : hmminftrans](a ) .     as a function of symbol error probability @xmath62 for markov transition probability @xmath240 0.01 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 .",
    "dotted lines show ( @xmath91 , @xmath86 ) case .",
    "( b ) critical value of symbol error probability , @xmath234 for filter ( solid markers ) and smoother ( hollow markers ) , vs.  markov transition probability @xmath8 . simulations as in figure  [ fig : maxwellhmmphasetrans](b ) , with 1000 time units . for fixed @xmath8",
    ", the parameter @xmath62 is incremented by 0.01 from 0 until @xmath241 , which defines @xmath234 .",
    "solid lines are plots of and .",
    "no parameters have been fit.,width=576 ]    let us denote @xmath242 , the filter estimate of @xmath12 . to find conditions where @xmath243 disagrees with @xmath220",
    ", we construct the extreme situation where a long string @xmath235 gives the greatest possible confidence that @xmath244",
    ". then let @xmath245 .",
    "the discordant observation must lower the confidence in @xmath74 to below @xmath3 in order for the filter estimate and observation to disagree .",
    "thus , the condition defining @xmath234 is @xmath246 writing this condition out explicitly gives , after a calculation detailed in [ sec : appa ] , @xmath247 a similar calculation for the smoother , again detailed in [ sec : appa ] , leads to @xmath248    figure  [ fig : hmminftrans](b ) shows that the thresholds of simulated data agree with and .",
    "both filter and smoother estimates imply that there is a maximum value of @xmath8 , call it @xmath249 , above which @xmath226 for all @xmath62 . for the filter @xmath250 , while for the smoother , @xmath251 .",
    "the higher value of @xmath249 reflects the greater value of smoother vs. filter inferences .",
    "although we have explained some features of figure  [ fig : maxwellhmmphasetrans ] , there is clearly more to understand .",
    "for example , there are both continuous and discontinuous transitions , as well as evidence for multiple transitions at fixed @xmath8 . to begin to understand the reason for multiple phase transitions",
    ", we note that the two - state , two - symbol hmm can be mapped onto an ising model @xcite .",
    "let us change variables : @xmath252      p(y_k | x_k ) & = & \\frac{e^{h \\",
    ", y_k x_k}}{2 \\cosh h } \\",
    ", , \\qquad           h = \\frac{1}{2 } \\ln \\left ( \\frac{1-b}{b } \\right ) \\ , .",
    "\\label{eq : hmm - markov2ising}\\end{aligned}\\ ] ] we use these definitions to formulate a  hamiltonian \" @xmath253 via @xmath254 where we have dropped constant terms that are independent of @xmath12 and @xmath49 . for @xmath255 , the interaction term @xmath256 is _ ferromagnetic _ : neighboring  spins \" tend to align .",
    "the term @xmath257 corresponds to an external field coupling constant .",
    "the field @xmath258 is of constant strength and , for @xmath259 , has a sign is equal to the observation @xmath49 .",
    "the picture is that a local , _ quenched _ field of strength @xmath258 tries to align its local spin along the direction defined by @xmath49 .",
    "notice that @xmath260 for @xmath261 : spins are independent of @xmath49 : observations and states decouple",
    ". a further change of variables ( gauge transformation ) , @xmath262 and @xmath263 , gives @xmath264 which is a random - bond ising model in a uniform external field @xmath257 @xcite .",
    "starting in the late 1970s , both random - bond and random - field one - dimensional ising chains were extensively studied as models of frustration in disordered systems such as spin glasses . in particular , derrida et al .",
    "showed that the ground state at zero temperature has a countable infinity of transitions at @xmath265 for @xmath266 @xcite .",
    "their transfer - matrix formalism is equivalent to the factorization of the partition function @xmath267 given in .",
    "the lowest - order transition , @xmath268 , corresponds to a case where the external field at a site forces the local spin to align , because we are at zero temperature . in terms of the original hmm problem",
    ", the ground state corresponds to the most likely ( viterbi ) path discussed briefly in section  [ sec : hmm - state - estimation ] @xcite .",
    "while the viterbi path differs from the filter estimate considered here , there may be a similar explanation for the multiple transitions apparent in figure  [ fig : maxwellhmmphasetrans ] .",
    "the formalism of hidden markov models , or hmms , can both simplify and clarify the discussion of stochastic thermodynamics of feedback using noisy measurements . expressed in terms of the control - theory notation developed here , state estimation based on hmm formalism",
    "is an effective way to incorporate the effects of noisy measurements . as an application , we simplified a previous analysis of a maxwell demon that uses observations to rectify thermal fluctuations .",
    "we saw that a surprising phase transition in the  discord \" between observation and inferred state is also present in simple hmm models . at least in this case",
    ", the primary source of complexity seems to lie in the process of state estimation , rather than some feature of the thermodynamics .",
    "our study of phase transitions in the discord parameter follows the methods of bauer et al .",
    "@xcite ; however , the mathematics is considerably more complicated in that case .",
    "we note that while bauer et al .",
    "do observe a series of transitions in their numerics , they have not seen evidence for jump discontinuities ( private communication ) .",
    "perhaps the differences are also associated with the continuous protocol for varying @xmath135 .",
    "more investigation is warranted .    beyond simplifying specific calculations",
    ", the use of hmms leads to other insights .",
    "for example , in figure [ fig : maxwelldemon ] , we saw that using a memory improves the performance of a maxwell demon that extracts power from a heat bath .",
    "the greatest improvement was for intermediate values of the noise parameter @xmath62 .",
    "sivak and thomson , studying a simple model of biological sensing , reached a similar conclusion @xcite .",
    "the results presented here suggest a somewhat broader view .",
    "figure  [ fig : filtervsmoother ] shows a similar result , where the smoother estimate outperforms the filter estimate . here",
    ", performance is measured by the shannon entropy of the estimated probability distribution .",
    "again , we see that the best performance , relative to without memory , is at intermediate noise levels .",
    "indeed , a variety of similar results can be obtained from many analogous quantities .",
    "for example , filter estimates based on continuous measurements with gaussian noise also exceed those based on discrete observation measurements , with , again , a maximum at intermediate values of observation noise .",
    "the common feature in all these different examples is that we compute some measure of performance ",
    "work extraction , shannon entropy , etc.as a function of added information .",
    "this added information can be previous observations (  memory \" ) , offline observations , extra measurement precision , multiple measurements , and so on . in all cases ,",
    "the greatest improvement is always at intermediate noise levels or , more precisely , at intermediate levels of signal - to - noise ratio .",
    "intuitively , the observation makes sense : if information is perfect ( zero noise ) , then more is superfluous . if information is worthless ( zero signal ) , then more is again not better .",
    "but in intermediate cases , extra information adds value .",
    "thus ,    it would be interesting to try to formalize these ideas further by defining a kind of  information susceptibility \" in terms of a derivative of power extraction , etc .",
    "with respect to added information . in this context",
    ", it is worth noting the study by rivoire and leibler , who show that the value of information can be quantified by different information theoretic quantities , such as directed and mutual information , when the analysis is causal or acausal @xcite .",
    "finally , we note that while we have been careful to discuss the smoother as an offline analysis tool whereby data is analyzed after the fact , there are more interesting possibilities . as stochastic thermodynamics is generalized to accommodate information flows",
    ", we should also consider the equivalent to open systems .",
    "for quantities such as energy , we are used to the idea that a subsystem need not conserve energy and that we must account for both energy dissipation and energy pumping .",
    "analogously , for information , we should consider both dissipation and the consequences of added information . because such information comes from  outside \" the system under direct study , causality need not be respected . for example ,",
    "consider the problem of controlling the temperature of a house .",
    "a causal control system will simply respond to temperature perturbations after they occur .",
    "if it gets cold , the heater turns on . on the other hand , we know in advance that at night it gets cold , and we know , with effectively absolute certainty , the time the sun will set .",
    "thus , we can anticipate the arrival of a cold perturbation and start to compensate for its effects _ before _ they occur .",
    "the resulting performance gain will be precisely analogous to the results shown in figure  [ fig : hmm - hmminfsmoother ] , where we compare filter and smoother estimates .",
    "( the quality of state estimates limits the quality of control . )",
    "the analysis of noisy discrete dynamics of hmms is perhaps the simplest non - trivial setting where these ideas may be explored .",
    "more generally , outside influences will appear as additional inputs to a state node in a graphical representation . in this context , the bayesian treatment of causality due to pearl shows how to generalize inferences such as filtering and smoothing to _ bayesian networks _",
    ", which have a richer graphical structure than the chain - like markov and hmms sketched in figures  [ fig : graphicalmarkov ] , [ fig : hmmfig ] , and [ fig : graphicalpomdp ] @xcite .",
    "such techniques have been used in stochastic thermodynamics to study information thermodynamics on networks @xcite and would seem to be the right approach to studying systems that are  causally open . \"    in conclusion , we have introduced some of the properties of hidden markov models that make them useful for simplifying the analysis of stochastic thermodynamics in the presence of feedback and noisy measurements , and we have seen how they suggest interesting areas for future research .",
    "this work was supported by nserc ( canada ) .",
    "i thank david sivak for his helpful comments and review of the manuscript .",
    "in the @xmath8-@xmath62 parameter plane , the critical line @xmath269 defines the border between the @xmath226 and @xmath225 phases .",
    "informally , the line separates a region where there is no benefit to using the filter estimate from one where there is .",
    "we can use both filter and smoother state estimates to calculate @xmath216 , giving two different critical lines .      for the filter case",
    ", we first calculate the maximum confidence @xmath94 . from ,",
    "@xmath270 substituting for the matrix elements in , evaluating the normalization constant , and imposing the fixed point gives a quadratic equation for @xmath94 : @xmath271 }          { ( 1-b ) \\left [ ( 1-a ) \\",
    ", p^ * + a ( 1-p^ * ) \\right ] + b \\left[(1-a)(1-p^ * ) + ap^*\\right ] } \\ , , \\label{eq : bcrit - condition0}\\end{aligned}\\ ] ] whose solution is @xmath272    for example , @xmath91 and @xmath86 gives @xmath273 , which matches the upper bound in figure  [ fig : hmm - hmminffilter ] .",
    "see also figure  [ fig : hmminftrans](a ) in the main text .    in terms of @xmath94 ,",
    "the condition for the threshold @xmath234 is given by @xmath274      & = \\frac{p(y_{k+1}=-1| x_{k+1}=1 , \\cancel{y^k=1 } ) \\",
    ",           p(x_{k+1}=1|y^k=1 ) } { p(y_{k+1}=-1| y^k=1 ) } \\nonumber \\\\[3pt ]      & = \\frac{p(y_{k+1}=-1| x_{k+1}=1 ) \\ , p(x_{k+1}=1|y^k=1 ) }       { \\sum_{x_{k+1 } } p(y_{k+1}=-1| x_{k+1 } ) \\ , p(x_{k+1 } | y^k=1 ) } \\nonumber \\\\[3pt ]      & = \\frac{b[(1-a)p^*+a(1-p^*)]}{b[(1-a)p^*+a(1-p^ * ) ] + ( 1-b)[ap^ * + ( 1-a)(1-p^ * ) ] }           \\nonumber \\\\[3pt ] & = \\frac{1}{2 } \\ , , \\label{eq : bc - filter0}\\end{aligned}\\ ] ] using mathematica , we reduce to @xmath275 rearranging and squaring leads to a remarkable simplification , @xmath276 which has solutions @xmath261 and @xmath277 .",
    "the relevant solution for the phase transition has @xmath278 , which corresponds to the negative root and .      for the smoother",
    ", the analogous threshold condition is given by @xmath279 where @xmath280 , i.e. , all the observations except @xmath49 .",
    "for the smoother , the future observations are also @xmath2 . in words :",
    "if an observation contradicts both past and future , do we trust it ?",
    "we write @xmath281 we then focus on the second term , @xmath282      & = \\frac{1}{z } p(y_{k+1}^n=1 | x_k=1,\\cancel{y^{k-1}=1 } ) \\ ,           p(x_k=1 | y^{k-1}=1 ) \\nonumber \\\\[3pt ]      & =   \\frac{1}{z } p(x_k=1 | y_{k+1}^n=1 ) \\ , \\left ( p(y_{k+1}^n=1 ) / p(x_k=1 )",
    "\\right ) \\ ,          p(x_k=1 | y^{k-1}=1 ) \\nonumber \\\\[3pt ]      & = \\frac{1}{z } p(x_k=1 | y_{k+1}^n=1 ) \\ , p(x_k=1 | y^{k-1}=1 ) \\nonumber \\\\[3pt ]      & = \\frac{1}{z } p(x_k=1 | y^{k-1}=1)^2 \\ , , \\label{eq : bc_smoother1}\\end{aligned}\\ ] ] where we absorb @xmath283 and @xmath205 into @xmath284 and set @xmath285 .",
    "the justification of this last step is that the sole difference in the two conditional probabilities is @xmath286 .",
    "but these are equal , as bayes theorem ( or detailed balance ) shows : @xmath287 where the unconditional probabilities @xmath288",
    ".    in terms of all these relations , becomes @xmath289 ^ 2 = \\frac{1}{2 } \\ , .",
    "\\label{eq : bc_smoother4}\\end{aligned}\\ ] ] using our earlier results for the filter , , and with @xmath94 given by , we have @xmath290 again , an amazing simplification leads to . that there are such simple solutions to such complicated equations suggests that a more direct derivation might be found .",
    "10 url # 1#1urlprefix[2][]#2 leff h  s and rex a  f 2003 _ maxwell s demon 2 : entropy , classical and quantum information , computing _ ( iop )"
  ],
  "abstract_text": [
    "<S> the formalism of state estimation and hidden markov models ( hmms ) can simplify and clarify the discussion of stochastic thermodynamics in the presence of feedback and measurement errors . after reviewing the basic formalism , we use it to shed light on a recent discussion of phase transitions in the optimized response of an information engine , for which measurement noise serves as a control parameter . </S>",
    "<S> the hmm formalism also shows that the value of additional information displays a maximum at intermediate signal - to - noise ratios . </S>",
    "<S> finally , we discuss how systems open to information flow can apparently violate causality ; the hmm formalism can quantify the performance gains due to such violations .    </S>",
    "<S> april 29 , 2015    _ keywords _ : nonequilibrium thermodynamics , feedback , information theory , hidden markov models </S>"
  ]
}