{
  "article_text": [
    "wireless networks span a wide spectrum in terms of their functionality ( i.e. , what they are used for ) , organization ( i.e. , how the different components are assembled to form a complete working system ) , and the technologies used to build them . a long - term project currently under way at cornell deals with the design and prototyping of networks with the following defining characteristics :    * the nodes operate under severe power constraints , support relatively large data transfer rates , and their number and density is large .",
    "* once nodes are deployed , their mobility is very limited ( if there is any at all ) . instead",
    ", the main source of uncontrolled dynamics in the network is the temporary failure of individual nodes : this will typically happen either due to exhaustion of the power source ( and for the duration of the `` refueling '' period ) , or due to variations in the wireless medium .    in our setup of interest ,",
    "the network is made up of devices whose functionality is essentially that of a traditional cisco router , with the addition that they communicate over a wireless channel , their size is many orders of magnitude smaller , and they may come equipped with sensors that generate information locally as well .",
    "such networks would prove extremely useful in a variety of very relevant scenarios , such as disaster relief operations , military and surveillance applications , cell - size reduction in cellular networks , environmental monitoring , etc .",
    "the development of a working network of this kind requires solutions to a number of technical challenges ( e.g. , routing , flow control , source and channel coding , power control , modem design , hardware , etc . ) . among all these , of particular interest in this paper",
    "is the problem of source coding , in a scenario in which the data collected by a large number of sensors is highly correlated . when network nodes are coupled with devices that sense a spatial process at different locations ( e.g. , concentration of ozone in the atmosphere , spread of a pathogen / pollutant agent , temperature of a material , etc . )",
    ", the measurements collected by each node will not be independent in general , but instead will be correlated , with a correlation structure determined by the corresponding fluid dynamics equations .",
    "furthermore , the higher the density of nodes in the network , the higher the correlation in the measurements will be .",
    "therefore , appropriate source coding capable of removing these dependencies has the potential to significantly reduce the number of bits to be transmitted ( and therefore the consumption of scarce power resources ) , when compared to a coding strategy that treats all measurements as being independently generated .",
    "the use of standard and well understood source coding techniques is not appropriate in the context of highly correlated sources : the use of classical source codes to remove redundancy in the measurements collected by different sensors requires that data be pooled at a common node prior to transmission . but this pooling action consumes valuable communication resources itself , thus defeating the very same goal it tries to achieve ( communication efficiency ) . therefore , _ distributed _ source coding techniques are required , i.e. , codes capable of removing correlation among measurements even in the presence of uncertainty about the exact value measured at remote locations . to this end",
    ", we define a simple abstraction that captures the essential properties of this problem .",
    "first , we consider the source of information to be a random process @xmath3}$ ] , defined over a bounded set , and with _ continuous _ sample paths ",
    "continuity is one simple way of capturing into our model the notion of correlation among measurements increasing with the number of nodes in a confined area .",
    "this process is observed by a finite number of sensors , and these observations are to be communicated over a wireless network , as illustrated in fig .  [",
    "fig : network - model ] .",
    "an important aspect of this problem setup is the fact that , as we increase the number of source nodes , the amount of information contained in each sample tends to zero  because the source is continous , two nearby samples are almost the same .",
    "and we know from recent work on the transport capacity of one class of wireless networks that , again for large networks , the per - node throughput of networks in this class also tends to zero  @xcite .",
    "therefore , _ provided that the rate at which information contained in each sample decays at least as fast as the throughput of the network _",
    ", appropriate source coding techniques should enable an accurate reconstruction of the source at the central decoder of fig .",
    "[ fig : network - model ] .",
    "a study of the resulting source coding problem in the context of these networks is the central subject of this paper .",
    "let @xmath4 be a sequence of independent drawings of a pair of dependent random variables @xmath0 and @xmath1 , and let @xmath5 denote a single - letter distortion measure .",
    "the problem of rate distortion with side information at the decoder asks the question of how many bits are required to encode the sequence @xmath6 under the constraint that @xmath7 , assuming the side information @xmath8 is available to the decoder but not to the encoder  ( * ? ? ?",
    "this problem , first considered by wyner and ziv in  @xcite , is a special case of the general problem of coding correlated information sources considered by slepian and wolf  @xcite , in that one of the sources ( @xmath8 ) is available _ uncoded _ at the decoder .",
    "but it also generalizes the setup of  @xcite , in that coding is with respect to a fidelity criterion rather than noiseless .",
    "one important motivation for us to consider this problem is the fact that good quantizers with side information will be used in the proof of scalability of a large sensor network .    in  @xcite , wyner and ziv",
    "derive the rate / distortion function @xmath9 for this problem , for general sources and general ( single letter ) distortion metrics . in this work",
    "however we restrict our attention only to gaussian sources , and mean squared error ( mse ) distortion .",
    "this case is of special interest because , under these conditions , it happens that @xmath10 , the conditional rate / distortion function _ assuming @xmath1 is available at the encoder _  @xcite .",
    "we are intrigued by the fact that there exist coding methods which can perform as well as if they had access to the side information at the encoder , even though they do nt .",
    "one goal pursued in this paper then is the construction a family of quantizers which realizes these promised gains .",
    "high - rate quantization theory provides much of the motivation to consider lattices  @xcite . under an assumption of fine quantization , the performance of an @xmath11-dimensional quantizer @xmath12 whose voronoi cells are all congruent to a polytope @xmath13 is given by @xmath14 where @xmath15 is the joint source distribution in @xmath11 dimensions",
    ", @xmath16 is the discrete entropy induced on the codebook @xmath12 by quantization of the source @xmath15 , @xmath17 is the differential entropy , and @xmath18 is the normalized second moment of @xmath13 ( using mse as a distortion measure )  @xcite .    in the problem of rate distortion with side information , for gaussian sources and mse distortion ,",
    "the goal is to attain a distortion value @xmath19 using @xmath20 nats / sample . in  ( [ eq : zador - gersho - bound ] )",
    "this means that , at fixed bit rate @xmath21 , we want to design quantizers that achieve distortion @xmath22 when coding @xmath0 , where @xmath23 is the coefficient of quantization in @xmath11 dimensions  @xcite .",
    "but since we do not have access to @xmath1 ( we only know @xmath24 ) , using classical quantizers we can only attain a distortion value @xmath25 ( because @xmath26 ) , or equivalently , we need to use some extra rate @xmath27 such that @xmath28 what makes this problem interesting is that we are only allowed to use @xmath21 nats / sample , not @xmath29 . one way to do that has been proposed by shamai , verd and zamir in  @xcite , which consists of : ( a ) taking a codebook with roughly @xmath30 codewords and distortion @xmath31 , ( b ) partitioning this codebook into @xmath32 sets of size @xmath33 each , ( c ) encoding only enough information to identify each one of the @xmath32 sets , and ( d ) using the side information @xmath1 to discriminate among the @xmath33 codewords collapsed into each set .",
    "one of our motivations for considering lattice codes is the fact that their structure makes it particularly easy to express these partitioning operations described in  @xcite .    we should also mention that another reason to consider lattices is our wish to answer a challenge posed by zamir and shamai in  @xcite .",
    "they present an encoding procedure very closely related to the one we propose here , they argue the existence of good lattices to use with that procedure , they study their distortion performance , but they do not present any examples of concrete constructions : their paper concludes by saying that ( sic ) `` _ beyond the question of existence , it would be nice to find specific constructions of good nested codes _ '' . finding those specific constructions is one of the original contributions in this work .",
    "note : this section contains relevant related work as of fall 2004 .",
    "the design of quantizers for the problem of rate distortion with side information was considered recently by shamai , verd and zamir , where they present design criteria for two different cases : bernoulli sources with hamming metric , and jointly gaussian sources with mean squared error metric  @xcite .",
    "the key contribution presented in that work is a constructive mechanism for , given a codebook , using the side information at the decoder to reduce the amount of information that needs to be encoded to identify codewords , while at the same time achieving essentially the distortion of the given codebook . that work provided much inspiration for our work on the design of lattice codes presented in this paper .",
    "other work on code constructions includes the application of similar codebook partitioning ideas in the context of trellis codes  @xcite , a preliminary version of this work  @xcite , generalizations to the case when the side information may be coded as well  @xcite , constructions based on ldpc codes  @xcite , and other code constructions  @xcite .      whereas there has been some interest in recent times on the more practical aspects of these problems , a significant amount of work on related topics",
    "had already been done before in the context of multiuser information theory . specifically on the problem of rate / distortion with side information , besides the above mentioned work of wyner and ziv  @xcite , kaspi and berger present a summary of known results and a number of new results ( as of 1982 ) in  @xcite , leaving only a couple of special cases still open .",
    "heegard and berger further generalize to the case when there is uncertainty on whether the side information is available at the decoder or not  @xcite .",
    "for an arbitrary pair of sources , zamir gives bounds on how far away the conditional rate / distortion function and the wyner - ziv rate / distortion function can be from each other  @xcite .",
    "closely related to the problem of rate / distortion with side information is that of _ noiseless coding of distributed correlated sources_. slepian and wolf formulate this problem , and determine the minimum number of bits per symbol required to encode two correlated sequences @xmath6 and @xmath8 separately , such that they can be faithfully reproduced by a centralized decoder , under the assumption that @xmath4 is i.i.d .",
    "cover then gives a simpler proof of the same result , which also generalizes to arbitrary ergodic processes , countably infinite alphabets , and arbitrary number of correlated sources  @xcite .",
    "wyner presents an information theoretic characterization of the minimum rates required for faithful reproduction in a general network with side information  @xcite .",
    "barros and servetto consider the slepian - wolf problem in an arbitrary network setup with noisy point - to - point links  @xcite .",
    "a long - standing open problem in network information theory is the characterization of the rate - distortion region for the _ multiterminal source coding _",
    "problem , which is basically the slepian - wolf problem , but in which a non - zero distortion is allowed in the encoding of both sources . the most significant contribution to this date can be found in tung s doctoral dissertation  @xcite .",
    "berger developed some useful notes for a tutorial lecture on this and related problems  @xcite .",
    "yet another closely related problem is _ the ceo problem_. in this version , multiple sensors observe _ noisy _ versions of the same signal , and must convey their observations to a centralized decoder at a combined rate of not more than @xmath34 bits / sample .",
    "this case generalizes the problem of encoding correlated observations , to the case when the number of sensors is large , and to the case when the signal to be communicated can not be observed directly .",
    "berger et al.present a solution to this problem in the general case  @xcite .",
    "viswanathan and berger specialize the results of  @xcite to the quadratic - gaussian case  @xcite : an interesting conclusion in this case is that the optimal rate of decay of the error is of the form @xmath35 when the sensors can not communicate prior to transmission , as opposed to an exponential decay otherwise .",
    "an interesting duality between the problem of rate / distortion with side information discussed above , and the problem of channel coding with side information at the transmitter  @xcite , has been pointed out by several groups  @xcite .",
    "cover and chiang present a comprehensive coverage of duality issues in problems with side information  @xcite , and chiang and boyd fully develop an optimization - theoretic approach to analyzing the duality of channel capacity and rate distortion problems  @xcite .",
    "merhav and shamai established a separation theorem in this context  @xcite .",
    "therefore , it should be possible to derive good codes for one problem from good codes available for the other .",
    "zamir et al .",
    "present a very interesting tutorial on noisy multiterminal networks , with many useful references  @xcite .",
    "a key result in the analysis of performance of wireless networks states that when @xmath11 non - mobile nodes are optimally placed in a disk of unit area , traffic patterns are optimally assigned , and the range of each transmission is optimally chosen , the total throughput that the network can carry is @xmath36  @xcite . as a result , the per - node throughput is only @xmath37 , i.e. , decays to zero as the number of nodes in the network increases .",
    "other results along the same lines were presented in  @xcite .",
    "the work of  @xcite sparked significant interest in this problem . when nodes are allowed to move , assuming transmission delays proportional to the mixing time of the network , the total network throughput is @xmath38 , and therefore the network can carry a non - vanishing rate per node  @xcite . using a linear programming formulation , non - asymptotic versions of the results in  @xcite",
    "are given in  @xcite .",
    "using pure network flow methods , similar results ( and generalizations thereof ) have been obtained in  @xcite .",
    "an alternative method for deriving transport capacity was presented in  @xcite .",
    "this paper presents the following original contributions :    * the construction of lattice codes for the problem of rate / distortion with side information .",
    "we propose a design procedure based on the choice of a lattice that is a good quantizer for the classical rate / distortion problem , and a geometrically - similar sublattice , inspired by the idea of partitioning codebooks to obtain good codes for this problem proposed in  @xcite , and by our previous work on the design of lattice quantizers for multiple description coding  @xcite . *",
    "an asymptotic analysis ( in rate and correlation ) of the performance of these codes which , to the best of our knowledge , is the first such analysis for wyner - ziv codes .",
    "our analysis reveals some interesting shortcomings of these codes , and suggest a simple modification to make to the construction to ensure their optimality .",
    "these optimal codes effectively answer a challenge of zamir and shamai  @xcite . *",
    "the illustration that high correlation asymptotics in source coding are indeed a new asymptotic regime with very meaningful practical implications .",
    "so far source coding has considered two asymptotic regimes : large block asymptotics  @xcite , or high rate asymptotics  @xcite .",
    "high correlation asymptotics are a new asymptotic regime that , as we will see in section  [ sec : sensor - networks ] , proves quite relevant in the context of new problems derived from sensor networking applications . * the identification of a large class of applications for which the vanishing rates property of wireless networks does not pose a problem , by virtue of the fact that the amount of information that each node needs to transmit decays at the same rate as ( or faster than ) throughput does .",
    "the rest of this paper is organized as follows . in section  [ sec : code - design ] we present the structure of lattice quantizers for the problem of rate / distortion with side information , and in section  [ sec : asymptotics ] we evaluate the performance of the codes obtained , under the assumption of high - correlation between the source @xmath0 and the side information @xmath1 . in section  [ sec : sensor - networks ]",
    "we illustrate how the proposed codes can be used to deal effectively with the vanishing rates property of an important class of large - scale sensor networks .",
    "final remarks are presented in section  [ sec : conclusions ] .",
    "a source generates a sequence of zero - mean iid pairs @xmath39 , with jointly gaussian distribution @xmath40 with covariance matrix @xmath41}$ ] , and correlation coefficient @xmath42 .",
    "the corresponding conditional and marginal densities are denoted by @xmath43 , @xmath44 , @xmath45 , @xmath46 . for a set of @xmath11 linearly independent column vectors @xmath47 , a _ lattice _",
    "@xmath48 is defined by @xmath49 and its _ generator matrix _",
    "@xmath50 $ ] .",
    "the volume of a polytope @xmath51 is denoted by @xmath52 . for a constant @xmath53 , the _ scaled lattice _",
    "@xmath54 is the lattice generated by @xmath55 , where @xmath56 is the generator matrix of a lattice @xmath12 .",
    "the _ voronoi cell _ of a lattice point @xmath57 in the lattice @xmath12 is defined by @xmath58       = \\{{\\bf x}\\in\\mathbb{r}^n:||{\\bf x}-\\lambda||^2\\leq||{\\bf x}-\\lambda'||^2 ,           \\;\\forall\\lambda'\\in\\lambda \\}.\\ ] ] the _ nearest neighbor map of a lattice _ is a function @xmath59 , defined by @xmath60 where ties are broken arbitrarily ( e.g. , numbering all the @xmath57 s , and assigning @xmath61 to the @xmath57 with smallest index ) . from the definitions it follows",
    "trivially that @xmath62 = \\{{\\bf x}\\in\\mathbb{r}^n : q_\\lambda({\\bf x})=\\lambda\\}$ ] , except possibly for a set of measure zero .",
    "a lattice @xmath63 is a _",
    "sublattice _ of a lattice @xmath12 if @xmath64 .",
    "the _ quotient group _  ( * ? ? ?",
    "6.3 ) of a lattice modulo a sublattice is denoted by @xmath65 , and its order by @xmath66",
    ".    a _ wyner - ziv lattice vector quantizer _ ( wz - lvq ) is a triplet @xmath67 , where :    * @xmath12 is a lattice .",
    "* @xmath68 is a linear operator such that @xmath69 ( for some @xmath70 ) , and such that @xmath71 .",
    "essentially , @xmath72 defines a _ similar _ sublattice of @xmath12 .",
    ", @xmath73 ( with generator matrices @xmath74 , @xmath75 ) are said to be _ similar _ when there is a constant @xmath76 , an integer matrix u with @xmath77 , and a real matrix @xmath78 with @xmath79 , such that @xmath80  @xcite .",
    "intuitively , similar lattices `` look the same '' , up to a rotation , a reflection , and a change of scale . ] * @xmath81 is a scale factor that expands ( or shrinks ) @xmath12 and @xmath82 .",
    "intuitively , the lattice @xmath12 is the fine codebook , the one whose codewords are to be partitioned into equivalence classes . we choose to implement this partition by considering a sublattice @xmath83 , and then considering the resulting quotient group @xmath65 .",
    "@xmath84 is a constant that multiplies the generator matrices of the lattices considered , which is to be adjusted as a function of the correlation between the source @xmath0 and the side information @xmath1 . a justification for the choice of a _ similar",
    "_ sublattice ( as opposed to any other sublattice ) to implement the codebook partition , and a justification for the explicit introduction of a scale factor @xmath84 as a parameter of the quantizer ( as opposed to having this lattice scale be determined by the coding rate , as in classical quantization theory ) will become apparent later , after we study the rate - distortion performance of the proposed quantizers .",
    "the question of the existence of similar sublattices arose in connection with another vector quantization problem  @xcite , and also in the study of symmetries of quasicrystals  @xcite .",
    "the subject is thoroughly covered in  @xcite , where necessary ( and in some cases sufficient ) conditions are given for their existence .",
    "let @xmath85 denote a block of @xmath11 source samples , and @xmath86 a block of @xmath11 side information samples .",
    "the encoder and decoder are maps @xmath87 and @xmath88 , defined by @xmath89 whose operation is illustrated in fig .",
    "[ fig : encoder - decoder ] , with an example based on the lattice @xmath90",
    ".      there are only @xmath91 possible different quantizer outputs , each one with probability @xmath92 ( @xmath93 ) given by @xmath94 }           f_x({\\bf x } ) \\mbox { d\\bf x},\\ ] ] where @xmath95 , and where we identify the entire equivalence class with a canonical representative taken from @xmath96 $ ] .",
    "the rate of a quantizer is then given by @xmath97 expressed in units of nats per source sample .",
    "assume now , as is standard in fine - resolution quantization theory , that voronoi cells of the quantizers under consideration are small .",
    "in this case , this translates into a requirement for _ sublattice _ cells to be small , for which we have that @xmath98 where the second equality follows from the fact that @xmath99 , where @xmath100 is the norm of the similarity defined by @xmath72  @xcite ( and therefore the corresponding scaling is @xmath101 ) , @xmath102 is unitary , and the last equality follows from assuming @xmath12 is normalized to have determinant 1  @xcite .",
    "then , we see that requiring small sublattice cells translates into requiring that @xmath103 be a small number . now",
    ", under this assumption , the rate expression above admits a much simpler form :    @xmath104 } f_x({\\bf x})\\mbox { d\\bf x } \\\\    = \\sum_{\\gamma_k\\in s\\lambda / s\\kappa(\\lambda ) }             \\underbrace{\\sum_{\\lambda\\in s\\lambda }              \\int_{v[\\kappa(\\lambda)+\\gamma_k : s\\lambda ] }                 f_x({\\bf x})\\mbox { d\\bf x}}_{p_k}.\\ ] ] the integral of the source density in @xmath92 can be approximated by @xmath105).\\ ] ] but assuming small cells for the sublattice ( standard in quantization theory ) , since the gaussian source is continuous , we have that within a cell of @xmath82 @xmath45 is approximately constant , and hence independent of the particular shift @xmath106 .",
    "furthermore , since @xmath12 is a lattice , all its cells are congruent , and therefore their volumes are all the same , thus making @xmath107 also independent of the particular shift @xmath106 . call @xmath108 this ( approximately ) constant value for @xmath92 .",
    "therefore , we have @xmath109 and hence , @xmath110 independent of @xmath84 and @xmath45 , where the approximations are tight in the limit as @xmath111 .    note",
    "that , unlike in classical quantization theory , here the rate of a quantizer seems to be independent of the size of its voronoi cells . in our context",
    ", a high - rate assumption translates into a large value for @xmath112 , i.e. , cells in the fine lattice are small _ relative _ to the size of cells in the coarse lattice . but",
    "the parameter @xmath84 , which determines the _ absolute _ the size of these cells , is not part of the rate expression .",
    "let @xmath113 denote the encoding of a source sequence @xmath61 ( @xmath93 ) , and @xmath114 denote the reconstruction codeword for a source sequence @xmath61 with side information @xmath115 .",
    "then : @xmath116 f_x({\\bf x})\\mbox{d}{\\bf x } \\nonumber \\\\    & \\stackrel{(b)}{= } & \\mbox{$\\frac 1 n$ } \\int_{{\\bf x}\\in\\mathbb{r}^n }          \\left[\\sum_{\\lambda\\in s\\kappa(\\lambda)+\\gamma_k({\\bf x } ) }                \\int_{{\\bf y}\\in v[\\lambda : s\\kappa(\\lambda)+\\gamma_k({\\bf x } ) ] }          ||{\\bf x } - \\lambda||^2 f_{y|x}({\\bf y}|{\\bf x } )          \\mbox{d}{\\bf y}\\right ] f_x({\\bf x})\\mbox{d}{\\bf x } \\nonumber \\\\    & \\stackrel{(c)}{= } & \\mbox{$\\frac 1 n$ } \\int_{{\\bf x}\\in\\mathbb{r}^n }          \\left[\\sum_{\\lambda\\in s\\kappa(\\lambda)+\\gamma_k({\\bf x } ) }          ||{\\bf x } - \\lambda||^2 { \\tt pr}\\big({\\bf",
    "y}\\in          v[\\lambda : s\\kappa(\\lambda)+\\gamma_k({\\bf x})]\\big|{\\bf x}\\big )          \\right ] f_x({\\bf x})\\mbox{d}{\\bf x } \\nonumber \\\\    & \\triangleq & \\mbox{$\\frac 1 n$ } \\int_{{\\bf x}\\in\\mathbb{r}^n }          \\partial({\\bf x } , s\\kappa(\\lambda)+\\gamma_k({\\bf x } ) )          f_x({\\bf x})\\mbox{d}{\\bf x } ,          \\label{eq : distortion}\\end{aligned}\\ ] ] where :    * is just the definition of average distortion ; * follows from , for each possible source sequence @xmath61 , partitioning the set of all side information vectors @xmath115 into voronoi cells of the sublattice @xmath117 , centered at location @xmath113 ; * follows from the fact that @xmath118 can be taken out of the integral , and what remains is an integral of the conditional density function .",
    "the last definition is introduced to highlight the concept that in quantization with side information , an entire sublattice plays the role of a single codeword in classical quantization  the average error in reconstructing @xmath61 is seen to take the form of an expectation of a suitably defined distortion metric between source sequences and sublattices . in section  [ sec : asymptotics ] we study the asymptotic behavior of  ( [ eq : distortion ] ) , assuming high correlation between @xmath85 and @xmath86 .      as we will see in section  [ sec : asymptotics ] , there are some drawbacks to implementing quantizers for the wyner - ziv problem with a fine quantizer that is essentially a truncated lattice , as follows from the construction given here .",
    "but there are also significant benefits to doing so , in terms of the simplicity of this implementation .",
    "so for the time being , if we are going to use two lattices , it is of interest to consider what kind of lattices should be used .",
    "suppose we fix the scale factor @xmath84 , and the code rate @xmath119 .",
    "among all the sublattices of @xmath12 of index @xmath120 , are there differences in terms of their distortion performance ? which sublattices should we choose ?",
    "it follows from  ( [ eq : distortion ] ) that a sensible design criteria is to choose the sublattice which results in maximizing",
    "@xmath121\\mid x\\!={\\bf x}\\right\\}$ ] , for @xmath122 $ ] .    since the vectors @xmath0 and @xmath1 are jointly gaussian and with iid components , the vector @xmath123 is also gaussian and with iid components ( although the @xmath124 s and the @xmath125 s are certainly not independent of each other ) .",
    "the pdf of @xmath123 is therefore circularly symmetric , and it follows from classical arguments of coding for gaussian channels that , to maximize @xmath126 , we need to maximize the norm of the shortest vectors in @xmath82 .",
    "this situation is illustrated in fig .",
    "[ fig : why - similar - sublattices ] , with an example based on the lattice @xmath90 .    the choice of @xmath90 for illustration purposes in fig .",
    "[ fig : why - similar - sublattices ] is not arbitrary . in that particular case",
    ", it is known that the minimal norm @xmath127 of any sublattice of index @xmath120 in @xmath90 satisfies @xmath128 , and that @xmath129 if and only if the sublattice is ideal  @xcite . furthermore , in two dimensions , @xmath90 is both the best classical quantizer and the best channel coder  @xcite .",
    "therefore , it seems clear that a hexagonal lattice and a similar sublattice are the best design choices in two dimensions : this combination simultaneously minimizes quantization error , and minimizes the probability of a source vector being decoded to an incorrect codeword .",
    "another interesting example is that of very high dimensional spaces . in this case , we know that good quantizers have ( nearly ) spherical voronoi cells .",
    "but at the same time , spherical cells maximize the minimum distance between sublattice points , and therefore an optimal sublattice will have to be similar to the base lattice .    in between dimensions 2 and @xmath130 , we are not able to make equally strong statements  but we use the insights derived from these extreme cases ( a lattice with small second - order moment and a similar sublattice ) as guiding principles , to curb the complexity of the design task .",
    "our goal in this section is to find a simpler expression for @xmath131 than that presented in section  [ sec : distortion - nonasymptotic ] . to do so",
    ", we work under some extra assumptions :    _ _    * the correlation coefficient @xmath42 between @xmath0 and @xmath1 is close to 1 . *",
    "the coding rate @xmath34 is large . *",
    "the scale factor @xmath84 is small .",
    "the effect of these assumptions is illustrated in fig .",
    "[ fig : assumptions ] .",
    "the basic intuition on which our analysis in this section is built is very simple : by considering high enough correlations , the encoder can `` roughly center '' the conditional distribution @xmath44 at the centroid of a sublattice cell , a cell that is large enough to make the probability that the source vector @xmath61 is not in the considered cell negligible , but at the same time small enough so that tools employed in classical quantization problems can be applied .",
    "recall that as mentioned earlier , unlike in classical high rate asymptotics where @xmath132 results in @xmath133 , in this case we must explicitly force @xmath134 , but not `` too fast ''  in this case , too fast would be at a rate equal or faster than the rate at which @xmath44 shrinks , as @xmath135 .",
    "we will do so by setting the scale factor @xmath84 to be @xmath136 , where @xmath137 is such that @xmath138 for example , @xmath139 satisfies these conditions .",
    "some justification seems necessary at this point for considering high - correlation asymptotics ( i.e. , @xmath135 ) , since under this assumption , the side information available uncoded at the decoder already contains almost all of the information about the source . and",
    "indeed , once we are done with our calculations , we will confirm the ( hardly surprising ) fact that for any fixed target distortion @xmath140 , using these proposed quantizers and as @xmath135 , the rate required to achieve @xmath140 vanishes .",
    "this is a condition that must be satisfied by _ any _ decent quantizer .",
    "however , that is not why we are interested in this analysis : instead , our goal is to evaluate @xmath141 where @xmath131 is the distortion of our quantizers , and @xmath142 is the wyner - ziv rate / distortion function  that is , we wish to compare the _ slope _ of the distortion function for our proposed quantizers at asymptotically high correlations , with that of the wyner - ziv bound .",
    "this _ is _ a meaningful performance metric , as it determines the rate of decay of distortion relative to the fastest possible decay .        to obtain a simpler expression for @xmath143 than that of eq .",
    "( [ eq : distortion ] ) , we start by expanding it in a different way : @xmath144 f_y({\\bf y})\\mbox{d}{\\bf y }          \\nonumber   \\\\    & \\stackrel{(b)}{= } & \\mbox{$\\frac 1 n$ }          \\sum_{\\lambda\\in s\\lambda } \\int_{{\\bf y}\\in v[\\lambda : s\\lambda ] }          \\left[\\int_{{\\bf x}\\in\\mathbb{r}^n }          ||{\\bf x } - \\gamma({\\bf x},{\\bf y})||^2 f_{x|y}({\\bf x}|{\\bf y } )          \\mbox{d}{\\bf x}\\right ] f_y({\\bf y})\\mbox{d}{\\bf y }          \\nonumber \\\\    & \\stackrel{(c)}{\\approx } &          \\mbox{$\\frac 1 n$ } \\sum_{\\lambda\\in s\\lambda }          \\left [ \\int_{{\\bf x}\\in\\mathbb{r}^n }          ||{\\bf x}-\\gamma({\\bf x},\\lambda)||^2 f_{x|y}({\\bf x}|\\lambda )          \\mbox{d}{\\bf x } \\right ] f_y(\\lambda)\\nu(s\\lambda )          \\nonumber \\\\    & \\stackrel{(d)}{= } &          \\mbox{$\\frac 1 n$ }          \\left [ \\int_{{\\bf x}\\in\\mathbb{r}^n }          ||{\\bf x}-\\gamma({\\bf x},\\mathbf{0})||^2 f_{x|y}({\\bf x}|\\mathbf{0 } )          \\mbox{d}{\\bf x } \\right ]          \\left(\\sum_{\\lambda\\in s\\lambda } f_y(\\lambda)\\nu(s\\lambda)\\right )          \\nonumber \\\\    & \\stackrel{(e)}{\\approx } & \\underbrace{\\mbox{$\\frac 1 n$ }          \\int_{{\\bf x}\\in v[{\\bf 0}:s\\kappa(\\lambda ) ] }          ||{\\bf x}-\\gamma_k({\\bf x})||^2 f_{x|y}({\\bf x}|\\mathbf{0 } )          \\mbox{d}{\\bf x}}_{\\alpha }          \\\\ & & \\mbox{\\hspace{2 mm } } + \\underbrace{\\mbox{$\\frac 1 n$ }          \\sum_{\\lambda\\in s\\kappa(\\lambda)\\backslash\\{{\\bf 0}\\ } }          \\int_{{\\bf x}\\in v[\\lambda : s\\kappa(\\lambda ) ] }          ||{\\bf x}-\\big(\\lambda+\\gamma_k({\\bf x})\\big)||^2          f_{x|y}({\\bf x}|\\mathbf{0 } ) \\mbox{d}{\\bf x}}_{\\beta }          \\label{eq : def - alpha - beta}\\end{aligned}\\ ] ] where :    * is again just the definition of average distortion ; * follows from partitioning the set of all side information sequences @xmath115 into voronoi cells of the fine lattice @xmath54 ; * follows from the assumption that @xmath145 is small , and from the continuity of @xmath146 as a function of @xmath147 ; * follows from the symmetry of @xmath44 as a function @xmath147 ; * follows from the fact that @xmath46 integrates to 1 , and from splitting the domain of integration of @xmath61 into voronoi cells of the sublattice @xmath117 .",
    "our next goal is to find simpler expressions for @xmath148 and @xmath149 .    to simplify @xmath148",
    ", we observe that this term denotes the mse incurred into when quantizing samples of a distribution @xmath150 with an @xmath120-level fixed - rate _ uniform _ quantizer , if we assume that the overload cells of the quantizer occur with negligible probability  and this assumption is justified because , for @xmath151 , sublattice cells are large relative to the spread of @xmath44 due to our choice of @xmath84 in  ( [ eq : choice - s ] ) . now , again under the assumption that @xmath34 is large , the random shift in the mean of @xmath44 given by its dependence on the unknown parameter @xmath152 is negligible compared to the size of a sublattice cell .",
    "thus , by choosing a value of @xmath153 close enough to 1 , the probability of @xmath154 $ ] can be made arbitrarily small .",
    "this is illustrated in fig .",
    "[ fig : simplify - alpha ] .",
    "the requirement that the fine and coarse quantizers be geometrically similar lattices results in cells of the coarse lattice being partitioned _ uniformly _ by the fine lattice ; this is the optimal quantizer for a source that is uniformly distributed over a sublattice cell , not distributed according to @xmath44 .",
    "therefore , defining a new pdf @xmath155 if @xmath156 is in the corresponding sublattice cell , and zero otherwise , we have that @xmath157 this follows from evaluating eqn .",
    "( 81 ) in  ( * ? ? ?",
    "2 ) for the uniform distribution @xmath108 defined above , specialized to the lattice @xmath12 .",
    "therefore , for @xmath120 large , we can ( equivalently ) say that @xmath158    since @xmath159 , we have that @xmath160 , and so @xmath161      our next step is to evaluate the figure of merit defined by  ( [ eq : figure - of - merit ] ) . to this end , consider wyner s rate / distortion bound  @xcite : ( for the low distortion region ) , where @xmath162 is the variance of @xmath0 , and @xmath163 , where @xmath102 has variance @xmath164 .",
    "a straightforward manipulation puts wyner s expression in the form shown here . ]",
    "@xmath165 plugging eqns .   and   into  ( [ eq : figure - of - merit ] ) , we get @xmath166 the divergence of this limit follows from choice of lattice scaling specified in eqn .",
    "therefore , when the fine quantizer is constrained to be a lattice that is geometrically similar to the coarse lattice , the performance of the resulting wyner - ziv quantizer is very poor in the asymptotic regime of high correlations .",
    "this observation motivates us to introduce a small modification in our code construction .",
    "the suboptimality of the code construction based on two geometrically similar lattices stems from the fact that sublattice cells are partitioned uniformly , but the source distribution @xmath44 being quantized is not uniform .",
    "therefore , we enlarge the class of codes considered :    * we keep the requirement that the coarse quantizer be a lattice ; * we keep the same quantization algorithm of eqn .  ; * but we now allow for the fine quantizer to be any arbitrary fixed - rate classical vector quantizer .    by removing the restriction that the fine quantizer also be a lattice , we can now choose one still with @xmath120 reconstruction points , but whose output point density , instead of being uniform , is matched to the distribution @xmath167 . as a result , we conclude that there exists a quantizer such that @xmath168 where @xmath169^{\\frac{n+2}{n}}$ ] , and where @xmath170 depends only on @xmath11 ( but not on the source distribution ) , and is bounded in terms of the standard @xmath171 function by @xmath172 as follows from eqns .",
    "( 81 ) and  ( 82 ) of  ( * ? ? ?",
    "* ch .  2 ) .",
    "hence , for @xmath151 and for @xmath120 large , we can approximate @xmath148 by @xmath173    to simplify @xmath149 , the following estimate is obtained in appendix  [ app : trivial1 ] : @xmath174^{\\frac{n}{2 } } }          \\left(\\frac{e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2 ) } } }                     { 1-e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2)}}}\\right ) .",
    "\\label{eq : b}\\ ] ]    combining these two estimates , we arrive at a final expression for @xmath143 : @xmath175^{\\frac{n}{2 } } }          \\left(\\frac{e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2 ) } } }                     { 1-e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2)}}}\\right )          \\label{eq : distortion - aroundzero}\\end{aligned}\\ ] ]      plugging eqns .   and   into  ( [ eq : figure - of - merit ] ) , we now get @xmath176^{\\frac{n}{2 } } }                  \\left(\\frac{e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2 ) } } }                             { 1-e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2)}}}\\right ) }               { \\sigma_x^2(1-\\rho^2)e^{-2r } } \\\\    & = & g_n          \\lim_{|\\rho|\\to 1}\\frac{||f_{x|y}||_{\\frac{n}{n+2 } } }                                 { \\sigma_x^2(1-\\rho^2 ) }          + \\;\\ ; \\lim_{|\\rho|\\to 1 } \\mbox{$\\frac 1 n$ }            \\frac{2\\nu(s\\kappa(\\lambda))e_ns^2 }                 { [ 2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }            \\left(\\frac{e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2 ) } } }                       { 1-e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2)}}}\\right )            \\frac{1}{\\sigma_x^2(1-\\rho^2)e^{-2r}}.\\end{aligned}\\ ] ]    from eqn .  ( 57 ) in  @xcite",
    ", we have that @xmath177 , where @xmath178 is the @xmath11-dimensional source distribution , and @xmath17 denotes differential entropy .",
    "we do nt know of a way to simplify this expression for small @xmath11 , so we approximate it with its limit value as @xmath11 gets large . , this does _ not _ mean that the distortion expression thus obtained is only valid for high dimensional quantizers : we can consider long source blocks , in which small sub - blocks are quantized with low dimensional codes ( for example , _ scalar _ quantizers ) , and this form would still apply . ] for the conditional gaussian distribution , @xmath179 , and hence @xmath180 note as well that the second term vanishes : for @xmath135 , from  ( [ eq : choice - s ] ) we have that @xmath181 , and thus this expression is dominated by the vanishing term @xmath182 .",
    "hence , we conclude that , by explicitly scaling the quantizers with @xmath84 satisfying conditions  ( [ eq : choice - s ] ) , @xmath183    finally , since for @xmath11 large the upper and lower bounds on @xmath170 given in eqn .   coincide and take the value @xmath184  ( * ? ? ?",
    "* pg .  58 ) , we see that indeed , as @xmath185 , there exist high - dimensional codes for which this limit can be made arbitrarily close to 1 . _ hence , asymptotically in rate and correlation , our code constructions achieve the wyner - ziv bound . _        informally , these are the key elements contributing to the optimality of our codes :    * the codes are scaled in a way such that , as correlation increases , the tails of the conditional distribution @xmath44 outside a cell of the coarse quantizer become increasingly light . * at high correlations , our scaling of the codes results in the size of cells in the coarse quantizer being small .",
    "but at high rates , the size of a cell in the fine quantizer is negligible even relative to the small coarse cells .",
    "and the side information is , with high probability , `` pinned '' within one of the small fine quantizer cells .",
    "* because the tails of @xmath44 are increasingly light as correlation increases , and @xmath44 is _ not _ uniform , an optimal quantizer for a uniform distribution is mismatched to the actual statistics of the data , thus resulting in a severe penalty in rate .",
    "however , this penalty can be eliminated entirely in a very simple way : only changing the shape of the cells for the fine quantizer is enough  if the output point density of the fine quantizer is matched to the pinned form of @xmath44 , this is an optimal code .",
    "essentially , our construction is asymptotically optimal ( in rate and correlation ) , because we scale the lattice in a way such that we create multiple copies of @xmath44 one within each cell of the coarse lattice , and we use an optimal code within that cell .",
    "this asymptotic analysis also sheds light on why there is no rate loss for wyner - ziv coding of gaussian sources , at least in the asymptotic regime of high rates and high correlations .",
    "note that the conditional distribution @xmath44 depends on the side information @xmath147 only in the form of a random shift : this random shift becomes negligible at high rates , but more importantly , the _ shape _ of @xmath44 is independent of @xmath147 . as a result , a single code can be used to quantize the @xmath44 s pinned one within each cell of the coarse lattice .",
    "it is this invariance property of the conditional gaussian distribution that results having @xmath186 , at least in the asymptotic regime considered in this section .",
    "issues in the analysis of performance of wireless networks have received considerable attention in recent times . to a large extent ,",
    "interest on these topics has been sparked by an observation made by gupta and kumar : the total throughput that can be carried by one particular class of wireless networks is only @xmath36 , denotes number of nodes in the network , and @xmath120 denotes block length .",
    "this notation should not be confused with that in previous section , where @xmath11 was used to refer to block length , and @xmath120 to the number of reconstruction codewords in a code . ] for a network having @xmath38 nodes  @xcite . as a result",
    ", each source - destination pair gets a throughput of @xmath187 , i.e. , the amount of information that any one individual node can inject into the network vanishes as the network size increases .",
    "the model used for performance analysis in  @xcite was conceived as an abstraction for emerging ad - hoc wireless networks , made up of small appliances ( such as laptop computers or microwave ovens or door locks ) , interconnected via standard air interfaces ( such as bluetooth or 802.11 ) . in that context",
    ", the fact that as more nodes join the network then the capacity available to each node decreases , clearly poses serious problems , since there is no reason to believe that there will be any dependencies in the data generated by each of these devices .",
    "and these problems prompted the conclusion in  @xcite that networks with either a small number of nodes , or with a small number of connections , may be more likely to find acceptance .    in our work , we consider a different type of wireless networks : we focus on _ sensor _ networks , i.e. , networks of devices that collect measurements of a process that is `` regular '' in some sense .",
    "for example , if the sensors measure ozone concentration in the atmosphere , then the values of each measurement will not be independent in general , but instead will be constrained by an appropriate form of the navier - stokes equations . if the sensors measure temperatures at different locations of a material , the measurements will be constrained by fourier s heat equations . and in general , when the sensors sample values of some random process at different locations , these samples will be constrained by the correlation structure of the process ( see , e.g. ,  @xcite ) . by considering correlated sources we generalize in what we believe",
    "is a very meaningful way the setup of  @xcite : now the amount of information generated by each node is no longer a constant , but instead it depends on the size of the network itself .",
    "consider the following problem setup :    * there is a source of information , modeled by a process @xmath188 : for fixed values of @xmath189 , @xmath188 is a brownian motion with parameter @xmath190 ; for fixed values of @xmath191 $ ] , @xmath188 is an iid sequence .",
    "that is , at a fixed location @xmath192 , iid samples with distribution @xmath193 are collected in discrete time , and at a fixed time slot , a wiener process unfolds in space .",
    "* network nodes are represented by points on the unit square @xmath194\\times[0,1 ] \\subset \\mathbb{r}^2 $ ] , and are classified into three groups : * * there are @xmath11 _ source _ nodes @xmath84 , that feed information into the network , uniformly spread on the left edge of the square . *",
    "* there are @xmath11 _ destination _ nodes @xmath19 , that take information out of the network , uniformly spread on the right edge of the square . *",
    "* there are @xmath11 _ router _ nodes @xmath195 , optimally placed in the interior of the square , to maximize network throughput .",
    "these nodes are pure routers , they neither inject nor extract information to / from the network , and they do nt apply any form of coding , they only forward information to other nodes . * the @xmath196-th source collects samples of @xmath197 , and encodes this information prior to sending it to the @xmath196-th destination ( @xmath198 ) .",
    "the only information available to each source is : * * the observed samples @xmath197 .",
    "* * the position in the square of all the nodes . * * the statistics of the entire process @xmath0 . *",
    "each destination node forwards whatever data it receives to a special node @xmath19 , which _ jointly _ decodes all the data received , and computes an estimate @xmath199 of the entire sample path @xmath188 based on all the decoded samples @xmath197 s .",
    "* nodes do not move , and have an unbounded power supply . *",
    "a bit is successfully sent from node @xmath200 to node @xmath201 if ( a ) @xmath202 , and ( b ) if for all other transmitting nodes @xmath203 , @xmath204 .",
    "@xmath34 bits per channel use can be transmitted over any link . *",
    "routing and power control are optimally configured to maximize network throughput .",
    "note that in this model we explicitly rule out the possibility of source nodes exchanging information to cooperate in the encoding of their observations .",
    "note also that routers only forward data , but do not apply any form of coding .",
    "that is , encoding is distributed among the sensors , data is carried over the network by relay nodes , and decoding is performed at a central location .",
    "we should point out that our model is different from the model of gupta and kumar  @xcite : whereas in their model they consider @xmath11 nodes which serve as transmitters / receivers / relays all in a single device , we break up each device into three pieces , and consider @xmath11 transmitters , @xmath11 receivers , and @xmath11 relays .",
    "however , this is not a fundamental difference : as long as we keep the same number of all three types of devices , the two models are essentially the same , and therefore their results on the property of vanishing throughputs as @xmath205 still holds for our model .",
    "the idea of splitting the devices into three separate units is to model a situation in which data is captured at some location , is transported over an ad - hoc network , and an estimate of the field of measurements is formed at a remote location .",
    "clearly , a network with a finite number of nodes and with communication links of finite capacity among nodes , can transport only a finite amount of information .",
    "therefore , exact reconstruction of the brownian field @xmath188 will not be possible in general , and a key issue then is that of understanding the rate / distortion tradeoffs involved . a thorough study of this new rate / distortion problem lies outside the scope intended for this paper , and we will deal with this problem elsewhere . of interest in this paper",
    "however is a result that relates the ability of the central destination node @xmath19 to estimate the brownian field @xmath188 to both the number of nodes in the network and the capacity of the individual network links .",
    "indeed , we have that under the assumption of a large ( but still independent of network size ) link capacity @xmath34 , for any @xmath206 and @xmath207 , there exists a large enough network of size @xmath11 nodes , such that @xmath208 uniformly for @xmath209 in the closed interval @xmath210 $ ] , where @xmath211 is an integer , for all time slots @xmath189 , and for almost all sample paths of the field @xmath212 .",
    "essentially , what this result states is that , under the assumption of a large network and with links of high capacity , it is possible for @xmath19 to estimate the sample paths of @xmath0 with arbitrarily small error .",
    "that accurate estimation is possible is indeed surprising to us , given the fact that the amount of information per sample that the network can carry vanishes  @xcite  fortunately , so does the information content per sample , and that is what we can take advantage of .",
    "first of all , we give one particular distribution of routers in the plane and one particular algorithm for scheduling transmissions .",
    "assume @xmath213 is an even integer , and define :    * the sources are located at coordinates @xmath214 , and the destinations at coordinates @xmath215 , for @xmath216 .",
    "* there are exactly @xmath11 routers , located at coordinates @xmath217 , for @xmath218 . *",
    "the transmission radius for the source nodes is @xmath219 , and for the routers it is @xmath220 .    in order to present an algorithm to schedule transmissions over time , we need some definitions .",
    "first , divide the square @xmath194\\times[0,1]\\subset\\mathbb{r}^2 $ ] into @xmath221 sets defined by @xmath222\\ ] ] @xmath223 . within each @xmath224",
    ", there are :    * @xmath221 source nodes , at coordinates @xmath225 , for @xmath226 . * @xmath221 destination nodes , at coordinates @xmath227 , for @xmath226 . * @xmath221 router nodes , at coordinates @xmath228 , for @xmath229 .",
    "next , we divide the router nodes into three groups @xmath230 : a router falls in @xmath231 if its index @xmath189 is equal to @xmath232 ( mod 3 ) .",
    "source nodes all belong to the group @xmath233 .",
    "finally , we give an algorithm to schedule transmissions :    * time is discrete , and starts at 0 . at even time slots , allow transmissions of nodes in @xmath224 s for which @xmath234 is even ; at odd time slots , allow transmissions of nodes for odd @xmath234 s . *",
    "each @xmath224 keeps its own clock @xmath235 , which advances only when transmissions from this @xmath224 are allowed to proceed : when @xmath236 ( mod 3 ) then @xmath233 sends , when @xmath237 ( mod 3 ) then @xmath238 sends , when @xmath239 ( mod 3 ) then @xmath240 sends . and",
    "source nodes send only once every @xmath221 available slots , cycling through them in round - robin order .",
    "an illustration of the placement and divisions of nodes , and of the mechanics of the algorithm , is shown in fig .",
    "[ fig : step1 ] .",
    "the calculation of throughput proceeds in three steps :    1 .",
    "each group @xmath224 is scheduled for transmission only @xmath242 of the available time slots . among these slots ,",
    "only @xmath243 are available for transmission by @xmath233 , the group that contains source nodes .",
    "when this group is scheduled , only once every @xmath221 slots is available to a particular node . and when a particular node finally gets his chance to inject a message into the network , it injects @xmath34 bits ( equal to link capacity ) .",
    "therefore , the total number of bits _ injected _ by any one source node per unit of time is @xmath244 .",
    "2 .   by construction",
    ", there is never more than one packet of @xmath34 bits in the buffer of any router .",
    "3 .   also by construction , there is never more than one active transmission within range of any receiver .",
    "so , from 1 we have that @xmath241 bits per time slot are injected into the network , from 2 we have that there is no buildup of packets in any one queue , and from 3 we have that packets are never lost or delayed .",
    "therefore , all injected bits reach destination , and hence the throughput is @xmath241 bits per time slot per node .      so far we have a network in which there is no loss of data , and which can carry a total of @xmath241 bits per time slot per node .",
    "and we collect one sample of the brownian field @xmath0 per time slot at each source node .",
    "therefore , we have @xmath241 bits per sample to encode a block of @xmath120 samples , for which the network guarantees delivery .",
    "consider encoding a block of samples @xmath245 $ ] at the @xmath196-th source node .",
    "trivially , we have that @xmath246 . from standard properties of wiener processes , we have that @xmath247 and @xmath248 are jointly gaussian , and that the increment has distribution @xmath249 independent of @xmath248 . if @xmath248 were available at the @xmath196-th encoder , the encoding procedure would be trivial : use standard codes for an iid gaussian source to send this increment .",
    "but without the reference value @xmath248 , @xmath196 can not compute that increment , which is the only `` new '' information at location @xmath250 .",
    "our encoding procedure is as follows : we encode @xmath247 using the codes developed in earlier sections , assuming the side information @xmath248 is available at the decoder .",
    "the relevant statistics are : @xmath251      next we turn to the computation of distortion for this proposed coding strategy .",
    "note that since the side information used to decode the data generated by one node is the data available at previous nodes , and that decoding errors can indeed occur with non zero probability ( and thus , in the large - network regime , _ will _ occur ) , an important issue that needs to be addressed is the effect of decoding errors on the overall achieved distortion .",
    "we proceed in two steps : first we compute the distortion resulting in the case when no decoding errors occur , and then we compute the increase in distortion due to decoding errors .      consider a fixed location @xmath209 ( @xmath252 ) , a fixed desired correlation value @xmath42 based on which a large enough value of @xmath11 is determined , and assume that no decoding errors occur in decoding samples @xmath253 .    in section  [ sec : use - lqsi ] above , we argued that we can use codes with side information to effectively approximate the performance of a genie - aided encoder capable of sending the increments at each node . we would like to point out now that in our decoder , the side information is itself quantized with the coarse lattice . as a result ,",
    "as long as @xmath254 and @xmath255 fall in the same sublattice cell , the reconstruction @xmath256 is as good as if it were based on _ uncoded _ side information .",
    "this is illustrated in fig .",
    "[ fig : coded - sideinfo ] .",
    "thus we conclude that , provided no decoding errors occur in any of the previous samples , and based on the results in section  [ sec : asymptotics ] , we can approximate the distortion in the reproduction of each sample by wyner s rate / distortion bound : @xmath257 note that the inequality in this case is because there will be nodes operating with a correlation value higher than the specified @xmath42 , and for these values @xmath258 will be even lower than this . the location - dependent correlation coefficients @xmath259 between adjacent samples forms a monotonically increasing sequence @xmath260 as @xmath261 .",
    "a trivial manipulation shows that for all @xmath262 , @xmath263 , and therefore all node locations @xmath250 in the closed interval @xmath264 $ ] will have correlation values at least @xmath42 .",
    "now , since @xmath211 , by choosing @xmath11 large enough we can make @xmath265 come arbitrarily close to zero .",
    "so we see that the distortion bound above holds uniformly for almost all samples in a large network .    at locations @xmath192",
    "in which there is no sample collected ( i.e. , any location in an open interval @xmath266 ) , we need to interpolate @xmath267 : we define @xmath268 , where @xmath269 . in this case , @xmath270 since the interpolation error is at most the size of an increment between samples , and this increment has variance @xmath271 .",
    "assume now that the sample path @xmath188 is continuous at @xmath192 :    * because @xmath11 is large , and for a fixed @xmath272 , we have a dense sampling of @xmath188 , @xmath273 .",
    "* because @xmath34 is large , encoded samples @xmath274 available at the decoder are close to the original value @xmath267 , i.e. , @xmath275 , @xmath276 .",
    "* because @xmath267 is continuous and @xmath11 is large , we have that interpolated samples @xmath277 ( @xmath278 ) , for all @xmath273",
    ".    therefore , @xmath279 holds at all points of continuity of @xmath267 . but",
    "finally , since almost all paths of a wiener process are continuous  @xcite , we conclude that @xmath280 where @xmath269 , and @xmath252 .      in the subsection above we obtained an expression for the distortion in the reconstruction of the sample paths assuming that decoding errors never occur .",
    "this is clearly a lower bound on the achievable distortion .",
    "but we still need to account for the distortion increase that results from the increasingly likely ( as @xmath185 ) event of a decoding error .",
    "our next goal is to show that , in large networks , this excess distortion is negligible compared to the distortion above induced by the quantizers .",
    "consider two definitions :    * @xmath281 is a random variable such that @xmath282 denotes the event in which @xmath283 nodes ( out of the @xmath196 right before the node at location @xmath209 ) make a decoding error . since conditioned on the side information being correct , errors are independent at each node , @xmath284 : a binomial distribution with parameters @xmath285 number of previous nodes , and @xmath286 probability of decoding error given that there are @xmath11 nodes in the network .",
    "* we refer to the term @xmath149 defined by eqn .",
    "( [ eq : def - alpha - beta ] ) as the _ excess distortion _ at node @xmath196 .",
    "both these definitions are illustrated in fig .",
    "[ fig : excess - distortion ] .",
    "consider now the distortion in a reconstruction of @xmath287 based on coded side information : @xmath288 where :    * follows from eqn .",
    "( [ eq : def - alpha - beta ] ) , and from the fact that if @xmath283 errors occured before the decoding of the @xmath196-th sample , on average each error contributes distortion @xmath289 and in the worst of cases all these errors add up coherently ( the dependence of @xmath148 and @xmath149 in eqn .",
    "( [ eq : def - alpha - beta ] ) on @xmath11 is highlighted by adding the subscript ) ; * follows from the binomial distribution of @xmath281 ; * follows from the fact that the expression above must hold for all @xmath252 ; * follows from the fact that for @xmath11 large , we can neglect the polynomial terms associated with the negative exponential , and from the fact that @xmath290 .    clearly , as @xmath185 , both @xmath291 and @xmath292 . but",
    "again , this is not an interesting observation .",
    "the interesting observation in this case is that still in the presence of coded side information and decoding errors , in the regime of high correlations , @xmath293 is negligible compared to @xmath294 , and @xmath295 : @xmath296 for any @xmath206 and @xmath11 large enough .",
    "but we also have @xmath297 ( since @xmath298 ) .",
    "thus , the excess distortion due to the use of coded side information and possible decoding errors is negligible compared to the distortion induced by the quantizers themselves .    to conclude this section",
    ", we would like to point out that there is an interesting tradeoff in this analysis , that works out favorably for us .",
    "note that by increasing the number of nodes , we increase the number of places at which errors can occur , and therefore the probability that some node will make a decoding error is increased .",
    "however , as the number of nodes increases , the correlation between their measurements increases as well , and therefore the size of errors is reduced . and",
    "as the previous analysis shows , a linear increase in the number of nodes results in an exponential decrease in the size of each error  hence , error propagation is _ not _ a problem in this setup .",
    "in this paper we presented our work on the design and performance analysis of codes for the problem of rate distortion with side information , and on the application of those codes in the context of a problem of data compression for sensor networks .",
    "first , we gave concrete constructions for the nested codes studied by shamai / verd / zamir in  @xcite , effectively answering an open question raised in  @xcite .",
    "then we studied the distortion performance of our codes , under the assumption of high correlation between the source and the side information and of high coding rates : there we showed that our codes attain the theoretically optimal distortion decay established by wyner and ziv  @xcite .",
    "finally we computed an upper bound on the error made in estimating a brownian field based on measurements collected by very `` cheap '' devices and delivered over a wireless network . in this case , even though the per - node throughput of the network vanishes as its size increases , and even if the nodes are not allowed to exchange any information at all , we showed how arbitrarily accurate estimation of the remote field is possible . to conclude the paper ,",
    "we would like to comment on some issues that follow from our work .      *",
    "the brownian model for the source considered in this work is probably one of the worst cases we could have considered , in the sense that the regularity conditions satisfied by this process are minimal .",
    "for example , almost all of its sample paths are indeed continuous at almost all points ( something we did use in our analysis ) ; but at the same time , almost all sample paths are _ not _ differentiable at almost all points . furthermore , the crucial assumption of high - resolution quantization that enabled us to apply our codes in the presence of _ coded _ side information can not be justified for processes with increments of variance @xmath299 , for any @xmath206compare this to the @xmath300 variance of the increments of the model we considered .",
    "* interesting questions arise if we consider processes more regular than brownian motion : consider for example the case when @xmath267 is a bandlimited signal ( since @xmath267 is compactly supported , take its periodic extension ) . if the samples @xmath301 were available at the decoder without distortion , it follows from shannon s sampling theorem that a network of finite size is enough to achieve a reconstruction with zero distortion .",
    "however , this would require network links of infinite capacity .",
    "for any finite value of @xmath34 , there are tradeoffs to explore between the number of nodes in the network ( i.e. , the sampling rate ) and the capacity of the network links ( i.e. , the accuracy in the representation of each sample ) , since economic constraints may favor one or the other option .",
    "this problem has received considerable attention in the signal processing and harmonic analysis literature  @xcite .    concerning coding / quantization . whereas our asymptotic analysis was performed only for jointly gaussian sources and mse distortion ,",
    "it would be interesting to learn something about the performance of the proposed quantizers for sources with non - gaussian statistics and/or other distortion measures . an interesting result of zamir states that , although the gap between @xmath302 and @xmath303 can be unbound , the gap between the wyner - ziv rate / distortion function @xmath304 and @xmath303 is bounded , and actually quite small in some cases : 0.5 bits / sample for arbitrary source statistics and mse distortion , and 0.22 bits / sample for a binary source with hamming distortion  @xcite . in our opinion this is an interesting issue because , should a result similar to zamir s hold for the performance of our codes , this would immediately allow us to conclude that arbitrarily accurate estimation is possible not just for jointly gaussian sources , but for any source statistics . and",
    "even if we do not have a formal proof , it certainly seems plausible to us that this may be so .",
    "the asymptotics we considered in this work are of neither type  instead , we focused on _ high - correlation _ asymptotics .",
    "and we believe this type of analysis is one particularly well suited for a new class of source coding problems , that originate in the context of sensor networks .",
    "this paper presents one such analysis for a simple toy problem involving a brownian process .",
    "more of our work along these lines can be found in  @xcite .    to conclude",
    ", we would like to comment on the nature of our contributions in this paper . since the seminal work of gupta and kumar  @xcite , most of the theory work on wireless networks appears to have been driven by a desire to find ways to understand , and if possible circumvent , the fact that the per - node throughput of the network vanishes as the number of nodes grows .",
    "implicit in previous work seems to have been present an assumption that each node has a constant amount of information to transmit , irrespective of the network size : in this case , the fact that the throughput per node decreases as the network size increases does indeed pose serious problems .",
    "however , we feel the asymptotic analysis of  @xcite is better suited to `` networks of small sensors '' than to `` networks of laptop computers '' : whereas there are only so many laptops that one may want to have in a single room , much higher densities of small sensing nodes are conceivable .",
    "yet it is very high densities of nodes what the asymptotic analysis of  @xcite suggests to us .",
    "now , in the context of sensor networks , the vanishing - throughput property of some wireless networks is much less of a problem . as an application for our codes with side information",
    ", we illustrated an instance of a class of wireless networking problems in which , as the size of the network grows , the amount of information generated by each transmitter decays at the same speed as the per - node throughput does .",
    "hence , contrary to the conclusions suggested in  @xcite , designers of these networks should be _ encouraged _ to consider very large numbers of nodes , for doing so may result in improved quality of the signals reconstructed at the receivers , and it may also make more economic sense .    * acknowledgements .",
    "* the author would like to thank toby berger , for much needed encouragement and guidance provided at difficult times ; anna scaglione , for discussions which resulted in a solution to a toy problem closely related to this one  @xcite ; martin vetterli , for discussions on the work of gupta and kumar  @xcite that greatly contributed to his understanding of that work ; and the anonymous referees , for their most insightful questions and constructive feedback , which led to a much improved manuscript . the author also benefited from several conversations with v.  a.  vaishampayan and n.  j.  a.  sloane , on quantization theory and lattices , in the context of some previous work  @xcite .",
    "recall from section  [ sec : average - error ] , @xmath305 }          ||{\\bf x}-\\big(\\lambda+\\gamma_k({\\bf x})\\big)||^2 f_{x|y}({\\bf x}|\\xi )          \\mbox{d}{\\bf x},\\ ] ] for any @xmath306 $ ] .",
    "our goal next is to give an estimate for @xmath149 .",
    "since each term of the sum is positive , we have a trivial lower bound : @xmath307 . as for an upper bound : @xmath308 }          ||{\\bf x}-\\big(\\lambda+\\gamma_k({\\bf x})\\big)||^2          \\frac{1}{[2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } } \\ ;          e^{-\\frac{n}{2(1-\\rho^2)}||\\frac{1}{\\sigma_x}{\\bf x }                                     -\\frac{\\rho}{\\sigma_y}{\\xi}||^2 }          \\mbox{d\\bf x }          \\nonumber \\\\    & \\stackrel{(b)}{\\leq } & \\mbox{$\\frac 1 n$ }          \\sum_{\\lambda\\in s\\kappa(\\lambda)\\!\\setminus\\{0\\ } }          \\int_{v[\\lambda : s\\kappa(\\lambda ) ] }          ||{\\bf x}||^2          \\frac{1}{[2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } } \\ ;          e^{-\\frac{n}{2(1-\\rho^2)}||\\frac{1}{\\sigma_x}{\\bf x }                                     -\\frac{\\rho}{\\sigma_y}{\\xi}||^2 }          \\mbox{d\\bf x }          \\nonumber \\\\ & & \\mbox{\\hspace{2 cm } } +          \\int_{v[\\lambda : s\\kappa(\\lambda ) ] }          ||\\lambda+\\gamma_k({\\bf x})||^2          \\frac{1}{[2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } } \\ ;          e^{-\\frac{n}{2(1-\\rho^2)}||\\frac{1}{\\sigma_x}{\\bf x }                                     -\\frac{\\rho}{\\sigma_y}{\\xi}||^2 }          \\mbox{d\\bf x }          \\nonumber \\\\    & \\stackrel{(c)}{\\approx } & \\mbox{$\\frac 1 n$ }          \\sum_{\\lambda\\in s\\kappa(\\lambda)\\!\\setminus\\{0\\ } }          2||\\lambda||^2          \\frac{1}{[2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } } \\ ;          e^{-\\frac{n}{2\\sigma_x^2(1-\\rho^2)}||\\lambda||^2 }          \\left(\\int_{v[\\lambda : s\\kappa(\\lambda)]}\\mbox{d\\bf x}\\right )          \\nonumber \\\\    & = & \\mbox{$\\frac 1 n$ }          \\frac{2\\nu(s\\kappa(\\lambda))}{[2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }          \\sum_{\\lambda\\in s\\kappa(\\lambda)\\!\\setminus\\{0\\ } }          ||\\lambda||^2          \\;e^{-\\frac{n}{2\\sigma_x^2(1-\\rho^2)}||\\lambda||^2 }          \\nonumber \\\\    & = & \\mbox{$\\frac 1 n$ }          \\frac{2\\nu(s\\kappa(\\lambda))}{[2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }          \\sum_{\\lambda\\in \\kappa(\\lambda)\\!\\setminus\\{0\\ } }          ||s\\lambda||^2          \\;e^{-\\frac{n}{2\\sigma_x^2(1-\\rho^2)}||s\\lambda||^2 }          \\nonumber \\\\    & \\stackrel{(d)}{= } & \\mbox{$\\frac 1 n$ }          \\frac{2\\nu(s\\kappa(\\lambda))s^2 }               { [ 2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }          \\sum_{m=1}^\\infty n_m(\\kappa(\\lambda ) )          \\;e^{-\\frac{s^2n}{2\\sigma_x^2(1-\\rho^2)}m }          \\label{eq : b2}\\end{aligned}\\ ] ] where :    * is just a substitution for the conditional gaussian distribution ; * follows from the fact that @xmath309 ; * is because of two reasons : under the assumption that sublattice cells are small , we have @xmath310 ( when @xmath311 $ ] ) ; and under the further assumption that @xmath34 is large , @xmath312 is negligible compared to @xmath313 ( when @xmath314 ) , and @xmath315 ( when @xmath306 $ ] ) ; * follows from defining @xmath316 as the number of points in @xmath317 such that @xmath318 . , and take @xmath196 to be an index in this list . ]    to find a useful estimate for this sum , we need to bound @xmath316 .",
    "one simple such bound is : @xmath319 this bound follows from the fact that the highest density of lattice points on the surface of a sphere can not be higher than if we assume a perfect tessellation of this @xmath320-dimensional surface into @xmath320-dimensional spheres whose radius is @xmath242 of the smallest separation between sublattice points .",
    "using standard formulas  @xcite , we find that @xmath321 for appropriate constants @xmath322 and @xmath323 , and @xmath324 .",
    "therefore , @xmath325^{\\frac{n}{2 } } }          \\sum_{m=1}^\\infty m^{n-1 }          \\;e^{-\\frac{s^2n}{2\\sigma_x^2(1-\\rho^2)}m }          \\nonumber \\\\    & = & \\mbox{$\\frac 1 n$ }          \\frac{2\\nu(s\\kappa(\\lambda))e_ns^2 }               { [ 2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }          \\sum_{m=1}^\\infty          e^{-\\frac{s^2n}{2\\sigma_x^2(1-\\rho^2)}m+(n-1)\\log(m ) }          \\nonumber \\\\    & \\stackrel{(b)}{= } & \\mbox{$\\frac 1 n$ }          \\frac{2\\nu(s\\kappa(\\lambda))e_ns^2 }               { [ 2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }          \\left(-1+\\sum_{m=0}^\\infty                   \\left(e^{-\\frac{s^2n}{2\\sigma_x^2(1-\\rho^2 ) }                            + \\frac{(n-1)\\log(m)}{m}}\\right)^m\\right )          \\nonumber \\\\    & \\stackrel{(c)}{\\leq } & \\mbox{$\\frac 1 n$ }          \\frac{2\\nu(s\\kappa(\\lambda))e_ns^2 }               { [ 2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }          \\left(-1+\\sum_{m=0}^\\infty                   \\left(e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2)}}\\right)^m\\right )          \\nonumber \\\\    & \\stackrel{(d)}{= } & \\mbox{$\\frac 1 n$ }          \\frac{2\\nu(s\\kappa(\\lambda))e_ns^2 }               { [ 2\\pi\\sigma_x^2(1-\\rho^2)]^{\\frac{n}{2 } } }          \\left(\\frac{e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2 ) } } }                     { 1-e^{-\\frac{s^2}{2\\sigma_x^2(1-\\rho^2)}}}\\right )          \\label{eq : b3 } \\\\    & \\stackrel{(e ) } { < } & \\epsilon          \\nonumber\\end{aligned}\\ ] ] where :    * follows from replacing the estimate for @xmath316 in eqn .",
    "( [ eq : b2 ] ) ; * follows from simple manipulations , and defining @xmath326 ; * follows from observing that @xmath327 , for @xmath328 close enough to 1 ; * follows from evaluation of the sum of a power series ; * where this holds for all values of @xmath42 such that @xmath329 , for a constant @xmath330 that depends on @xmath331 since , from  ( [ eq : choice - s ] ) , we have @xmath332 , thus convergence is exponential in @xmath42 .",
    "sergio d.  servetto was born in argentina , on january 18 , 1968 .",
    "he received a licenciatura en informtica from universidad nacional de la plata ( unlp , argentina ) in 1992 , and the m.sc .",
    "degree in electrical engineering and the ph.d .",
    "degree in computer science from the university of illinois at urbana - champaign ( uiuc ) , in 1996 and 1999 . between 1999 and 2001 , he worked at the cole polytechnique fdrale de lausanne ( epfl ) , lausanne , switzerland . since fall 2001",
    ", he has been an assistant professor in the school of electrical and computer engineering at cornell university , and a member of the fields of applied mathematics and computer science .",
    "he was the recipient of the 1998 ray ozzie fellowship , given to `` outstanding graduate students in computer science , '' and of the 1999 david j. kuck outstanding thesis award , for the best doctoral dissertation of the year , both from the dept .",
    "of computer science at uiuc .",
    "he was also the recipient of a 2003 nsf career award .",
    "his research interests are centered around information theoretic aspects of networked systems , with a current emphasis on problems that arise in the context of large - scale sensor networks ."
  ],
  "abstract_text": [
    "<S> _ we consider the problem of rate / distortion with side information available only at the decoder . for </S>",
    "<S> the case of jointly - gaussian source @xmath0 and side information @xmath1 , and mean - squared error distortion , wyner proved in 1976 that the rate / distortion function for this problem is identical to the conditional rate / distortion function @xmath2 , assuming the side information @xmath1 is available at the encoder . in this paper </S>",
    "<S> we construct a structured class of asymptotically optimal quantizers for this problem : under the assumption of high correlation between source @xmath0 and side information @xmath1 , we show there exist quantizers within our class whose performance comes arbitrarily close to wyner s bound . as an application illustrating the relevance of the high - correlation asymptotics , we also explore the use of these quantizers in the context of a problem of data compression for sensor networks , in a setup involving a large number of devices collecting highly correlated measurements within a confined area . </S>",
    "<S> an important feature of our formulation is that , although the per - node throughput of the network tends to zero as network size increases , so does the amount of information generated by each transmitter . </S>",
    "<S> this is a situation likely to be encountered often in practice , which allows us to cast under new  and more `` optimistic''light some negative results on the transport capacity of large - scale wireless networks . _    </S>",
    "<S> ( 0,0 ) ( -8,75)to appear in the ieee transactions on information theory .    </S>",
    "<S> * index terms : * rate / distortion , rate / distortion with side information , quantization , vector quantization , lattice quantization , lattice codes , hexagonal lattice , source coding , network information theory , ad - hoc networks , sensor networks , multihop radio networks , wireless networks , throughput , capacity . </S>"
  ]
}