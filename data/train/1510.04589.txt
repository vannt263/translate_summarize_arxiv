{
  "article_text": [
    "the excellent error correction performance of codes , alongside with the availability of low - complexity and highly parallel decoding algorithms and hardware architectures makes them an attractive choice for many high throughput communication systems .",
    "codes are traditionally decoded using iterative algorithms like the algorithm and variants thereof  @xcite , most notably the algorithm .",
    "those conventional algorithms rely on the exchange of continuous messages , which are usually quantized with resolutions of @xmath0 to @xmath1 bits in most in hardware implementations .",
    "lower resolutions are possible but entail severe performance penalties , especially in the error - floor region @xcite",
    ".    previous work on quantized algorithms for decoding has shown that decoders which are designed to operate directly on message alphabets of finite size can lead to improved performance .",
    "there are numerous different approaches towards the design of such decoders .",
    "for example , the authors of @xcite , @xcite and @xcite consider based update rules that are designed such that the resulting decoders can correct most of the error events contributing to the error floor .",
    "however , their design is restricted to codes with column weight @xmath2 and to binary output channels . in",
    "@xcite a quasi - uniform quantization was proposed which extends the dynamic range of the messages at later iterations and improves the error floor performance .",
    "however , the design of  @xcite still relies on the conventional message update rules and therefore does not reduce the required message bit - width .",
    "finally , the authors of @xcite consider message updates based on an information theoretic fidelity criterion .",
    "while @xcite , @xcite , and @xcite analyze the performance of their decoding schemes by means of simulations , @xcite only provides density evolution results and @xcite focuses solely on the algorithm for designing the message update rules . to the best of our knowledge ,",
    "none of the above schemes have been assessed in terms of their impact on hardware implementations .      in this paper , we derive a low - complexity decoding algorithm that is designed to directly operate with a finite message alphabet and that manages to achieve better error - rate performance than conventional algorithms with message resolutions as low as @xmath2 bits . based on this algorithm , we synthesize a fully unrolled decoder and compare our results with our implementation of the only existing fully unrolled decoder  @xcite .",
    "our approach for the design of the update rule is similar to @xcite , but we use a more sophisticated tree structure as well as a different update rule .",
    "a @xmath3-regular code is the set of codewords @xmath4 where all operations are performed modulo  @xmath5 .",
    "the parity check matrix @xmath6 contains @xmath7 ones per column and @xmath8 ones per row and is sparse in the sense that @xmath9 .",
    "the parity - check matrix forms an incidence matrix for a tanner graph which contains @xmath10 and @xmath11 .",
    "variable node @xmath12 is connected to check node @xmath13 if and only if @xmath14 .    codes are traditionally decoded using algorithms , where information is exchanged between the and the over the course of several decoding iterations .",
    "let the message alphabet be denoted by @xmath15 . for simplicity , in this work",
    "we assume that @xmath16 does not change over the iterations . at each iteration",
    "the messages from @xmath12 to @xmath13 are computed using the mapping @xmath17 , which is defined as @xmath18 where @xmath19 denotes the neighbours of node @xmath12 in the tanner graph , @xmath20 is a vector that contains the incoming messages from all neighboring except @xmath13 , and @xmath21 denotes the channel corresponding to @xmath12 . similarly , the -to- messages are computed using the mapping @xmath22 , which is defined as @xmath23 illustrates the message updates in the tanner graph .",
    "in addition to @xmath24 and @xmath25 , a third mapping @xmath26 is needed to provide an estimate of the transmitted codeword bit based on the incoming check node messages and the channel @xmath27 @xmath28     +    for the widely used algorithm , the mappings read @xmath29 where @xmath30 denotes the minimum of the absolute values of the vector components , @xmath31 and @xmath32 .",
    "the decision mapping @xmath33 is defined as @xmath34",
    "the ms algorithm assumes that the message set @xmath16 and the set @xmath35 are real numbers .",
    "however , it is impractical to use floating - point arithmetic in hardware implementations of such decoders and the message alphabets are usually discretized using a relatively low number of uniformly spaced quantization levels .",
    "this uniform quantization , together with the well - established two s complement and sign - magnitude binary encoding , leads to efficient arithmetic circuits , but it is not necessarily the best choice in terms of error - rate performance .",
    "recently , efforts have been made to devise decoders that are designed to work directly with finite message and alphabets  @xcite .",
    "instead of arithmetic computations such as [ eqn : vnupdatems ] and [ eqn : cnupdatems ] , the update rules for these decoders are implemented as look - up tables ( luts ) .",
    "there are numerous approaches to the design of such luts . in the following",
    ", we provide an algorithm that is a mixture between the conventional algorithm and purely -based decoders .",
    "more specifically , we only replace the update rules with , which are designed using an information theoretic metric . for the design of the",
    ", we exploit the fact that the outputs of the -based , although not representing real numbers , can be ordered and for symmetric channels , the message sign can be directly inferred from the labels , cf .",
    "[ subsec : quantdiscussion ] .",
    "this allows us to use the standard update rule , thereby avoiding the high hardware complexity that a -based design would cause for codes with high degree .",
    "our hybrid algorithm provides excellent performance even with very few message levels and leads to an efficient hardware architecture , which is described in detail in section  [ sec : architecture ] .",
    "the key idea behind the lut design method that we employ is that , given the cn - to - vn message distributions of the previous iterations , one can design the vn luts for each iteration in a way that maximizes the mutual information between the vn output messages and the codeword bit corresponding to the vn in question .",
    "we first describe how the distribution of the cn - to - vn messages can be computed based on the distribution of the incoming cn - to - vn messages",
    ". if the tanner graph is cycle - free , then the individual input messages of a at iteration @xmath36 are iid conditioned on the transmitted bit @xmath37 , and their distribution is denoted by @xmath38 .",
    "then , the joint distribution of the @xmath39 incident messages conditioned on the transmitted bit value corresponding to the recipient ( cf . fig .  [ fig : message_updates ] ) reads @xmath40 where @xmath41 denotes the modulo-@xmath5 sum of the components of @xmath42 . using the update rule [ eqn : cnupdatems ] , the distribution of the outgoing -to- message is then given by @xmath43 where @xmath44 .",
    "the output message values are given by @xmath45 conventional decoding algorithms need a high dynamic range in order to represent the growing message magnitudes , as they are using the same message representation for every iteration . in our lut - based decoder ,",
    "the message representation changes from one iteration to the next and the message values grow implicitly as the distributions @xmath46 become more and more concentrated over the course of the iterations , thus providing an explanation for the good performance we can achieve with very low resolutions .",
    "let @xmath47 denote the @xmath48 incident -to- messages that are involved in the update of a certain ( one of which is always the channel llr @xmath49 ) and let @xmath37 be the transmit bit corresponding to this .",
    "then , the joint distribution of the vn input messages is given by  @xcite @xmath50 given this distribution , we can construct an update rule @xmath51 where @xmath52 is the set of all deterministic mappings in the form of [ eqn : vnupdategeneric ] and @xmath53 denotes the mutual information between @xmath54 and @xmath37 .",
    "hence , the resulting update rule locally maximizes the information flow between the and the .",
    "an algorithm that solves [ eqn : miquantizer ] with complexity @xmath55 was provided in  @xcite . using the update rule [ eqn : miquantizer ]",
    ", we can compute the message conditional distribution of the next iteration @xmath56    given an initial message distribution @xmath57 and a distribution of the channel @xmath58 , the repeated alternating application of [ eqn : cnprodchannel , eqn : cnmsgdist , eqn : vnprodchannel , eqn : miquantizer , eqn : vnmsgdist ] produces a sequence of locally optimal update mappings @xmath59 , where @xmath60 denotes a pre - determined maximum number of performed iterations .        as the mappings @xmath24 take @xmath61 inputs , a direct application of the algorithm described in section  [ subsec : it ] is restricted to low weight codes .",
    "however , we can construct a hierarchy of mappings where each partial mapping only processes a subset of the inputs and the intermediate outputs of preceding stages .",
    "the quantizer design for such a hierarchy follows directly by considering only the messages incident to the respective mapping in [ eqn : vnprodchannel ] and , for the intermediate nodes , replacing the distributions [ eqn : cnmsgdist ] of the incident messages by the distributions [ eqn : vnmsgdist ] of the previous stage .",
    "so far we considered the initial distributions @xmath57 and @xmath58 as given .",
    "when designing practical decoders for communication applications , the initial distributions follow from the transmission channel and the quantization of the preceding signal processing .    throughout the rest of the paper ,",
    "we consider a channel followed by maximum mutual information quantization of the @xcite . in this case , the initial distributions depend on the snr , which renders the lut design snr - specific .",
    "nevertheless , we observe in our simulations that the decoder generally performs well also for snrs other than the design snr .",
    "consider the practically relevant case where @xmath62 and @xmath63 are even and the distributions @xmath64 and @xmath65 are symmetric in the sense that @xmath66 or equivalently , expressed in terms of the values @xmath67 for that case , computing the update [ eqn : cnupdatems ] is simplified as the sign follows immediately from the message labels .",
    "thus , for the update the message values do not need to be stored and the entire decoder can be implemented based on the message labels .      since the discrete messages of our decoder do not represent real numbers but are labels , a simple arithmetic decision mapping such as [ eqn : minsumdec ] is not possible .",
    "instead , @xmath33 has to be implemented as a generic mapping as well .",
    "the construction of @xmath33 is similar to the construction of @xmath24 , with the difference that all @xmath7 input messages and the channel have to be processed and that the output is binary .",
    "in the previous section , we have described an algorithm that can construct locally optimal variable node update rules in the form of for a given quantization bit - width for each iteration for any given @xmath3-regular ldpc code .",
    "most conventional ldpc decoder architectures are either partially parallel , meaning that fewer than @xmath10 vns and @xmath11 cns are instantiated , or fully parallel , meaning that @xmath10 vns and @xmath11 cns are instantiated .",
    "using a lut - based decoder with a carefully designed quantization scheme can significantly reduce the memory required to store the messages exchanged by the vns and cns due to the reduced message bit - width required to achieve the same fer performance . however , both for partially parallel and for fully parallel decoders , separate luts would be required within each vn for each one of the performed decoding iterations , significantly increasing the size of each vn , and thus possibly outweighing the gain in the memory area .",
    "an additional degree of parallelism was recently explored in  @xcite , where a _ fully unrolled _ and fully parallel ldpc decoder was presented .",
    "this decoder instantiates @xmath10 vns and @xmath11 cns for each iteration of the decoding algorithm , leading to a total of @xmath68 vns and @xmath69 cns .",
    "while such a fully unrolled decoder requires significant hardware resources , it also has a very high throughput since one decoded codeword can be output in each clock cycle .",
    "thus , the hardware efficiency ( i.e. , throughput per unit area ) of the fully unrolled decoder presented in  @xcite turns out to be significantly better than the hardware efficiency of partially parallel and fully parallel ( non - unrolled ) approaches .",
    "since in a fully unrolled ldpc decoder architecture vns and cns are instantiated for each iteration , it is a very suitable candidate for the application of our lut - based decoding algorithm .    in this section ,",
    "we describe the hardware architecture of our fully unrolled lut - based ldpc decoder .",
    "our hardware architecture is similar to the architecture used in  @xcite , while the most important differences are the optimized lut - based variable node and the significantly reduced bit - width of all quantities involved in the decoding process .",
    "an overview of our decoder architecture is shown in fig .  [",
    "fig : toplevel ] .",
    "each decoding iteration is mapped to a distinct set of variable nodes and check nodes which then form a processing pipeline .",
    "in essence , a fully unrolled and fully parallel ldpc decoder is a systolic array in which data flows from left to right .",
    "a new set of @xmath10 channel llrs can be read in each clock cycle , and a new decoded codeword is output in each clock cycle .",
    "the decoding latency as well as the maximum frequency depend on the number of performed iterations as well as the number of pipeline registers present in the decoder .",
    "our decoder consist of three types of stages , namely the cn stage , the vn stage , and the dn stage , which are described in detail in the sequel .",
    "as long as a steady flow of input channel llrs can be provided to the decoder , there is no control logic required apart from the clock and reset signals .",
    "each cn stage contains @xmath11 check node units , as well as @xmath70 @xmath71-bit registers which store the check node output messages , where @xmath71 denotes the number of bits used to represent the internal decoder messages .",
    "moreover , each cn stage contains @xmath10 @xmath72-bit channel llr registers which are used to forward the channel llrs required by the following variable node stages , where @xmath72 denotes the number of bits used to represent the channel llrs .    due to",
    ", we can use a check node architecture which is practically identical to the check node architecture used in  @xcite . more specifically , each check node consists of a sorting unit that identifies the two smallest messages among all @xmath8 input messages and an output unit which selects the first or the second minimum for each output , along with the appropriate sign .",
    "the sorting unit contains 4-input compare - and - select ( cs ) units in a tree structure , which identify and output the two smallest values out of the four input values  @xcite .",
    "we use sign - magnitude ( sm ) to represent all message labels . the sm2tc unit used in the check node of  @xcite",
    "is not required in our architecture since the variable node does not perform any arithmetic operations where the two s complement representation could be favorable .",
    "each stage contains @xmath10 variable node units , as well as @xmath73 @xmath71-bit registers that store the variable node output messages .",
    "moreover , each vn stage contains @xmath10 @xmath72-bit channel llr registers which are used to forward the channel llrs required by the following vn stages .    in the variable node architecture used in the adder - based decoder of  @xcite ,",
    "all input messages are added and then the input message corresponding to each output is subtracted from the sum in order to form the output message , thus implementing the conventional ms update rule given in  . in order to avoid overflows , in our implementation of  @xcite the bit - width of the internal signals is increased by one bit for each addition .    for our lut - based decoder",
    "the adder tree is replaced by @xmath7 lut trees , each of which computes one of the @xmath7 outputs of the variable node .",
    "one possible lut - tree structure is shown in fig .",
    "[ fig : vnodelut ] , where @xmath74 denotes an internal message from a check node and @xmath49 denotes the channel llr .",
    "lut sharing between the @xmath7 lut trees can be achieved by identifying the nodes that appear in more than one tree and instantiating them only once , thus significantly reducing the required hardware resources . moreover , keeping the number of inputs of each lut as low as possible ensures that the size of the luts , which grows exponentially with the number of inputs , is manageable for the automated logic synthesis process .",
    "the variable node that corresponds to the final decoding iteration is called a _ decision node _",
    "the dn stage contains @xmath10 decision nodes , as well @xmath10 single - bit registers that store the decoded codeword bits .",
    "the dn stage does not contain channel llr registers , as there are no subsequent decoding stages where the channel llrs would be used .",
    "the architecture of a decision node is generally simpler than that of a variable node , as a single output value ( i.e. , the decoded bit ) is calculated instead of @xmath7 distinct outputs .",
    "more specifically , in the architecture of  @xcite , the decision metric of   is already calculated as part of the variable node update rule .",
    "however , for the decision node , there is no need to subtract each input message from the sum in order to generate @xmath7 distinct output messages .",
    "it suffices to check whether the sum is positive or negative , and output the corresponding decoded codeword bit .    in our lut - based decoder , as discussed in section  [ sec : decstage ] , a lut tree is designed whose tree node has an output bit - width of a single bit , which is the corresponding decoded codeword bit .",
    "an example of a decision lut tree for a decision node that corresponds to a code with @xmath75 is shown in fig .",
    "[ fig : decnodelut ] .",
    "each decision node contains a single lut tree , in contrast with the variable nodes which contain @xmath7 lut trees .",
    "our lut - based architecture contains pipeline registers at the output of each stage ( vn , cn , and dn ) .",
    "thus , for a given number of decoding iterations @xmath60 , the decoding latency is @xmath76 clock cycles .",
    "since one decoded codeword is output in each clock cycle , the decoding throughput of the decoder , measured in gbits / s , is given by @xmath77 , where @xmath78 denotes the operating frequency measured in ghz .",
    "each pipeline stage except the dn stage requires an @xmath79 channel llr register .",
    "moreover , each vn and cn stage requires @xmath80 ( equivalently , @xmath81 ) registers to store the output messages .",
    "finally , the dn stage requires @xmath10 registers to store the decoded codeword bits .",
    "thus , the total number of register bits required by our lut - based decoder can be calculated as @xmath82 naturally , can also be used to calculate the register bits required by an adder - based ms architecture with the same pipeline register structure .",
    "in this section , we present synthesis results for a fully unrolled lut - based ldpc decoder and we compare it with synthesis results of our implementation of a fully unrolled adder - based ms ldpc decoder .",
    "we have used the parity - check matrix of the ldpc code defined in the ieee 802.3an standard  @xcite ( @xmath83 gbit / s ethernet ) , which is a @xmath84-regular ldpc code of rate @xmath85 and blocklength @xmath86 . for the fixed point decoder and the lut - based decoder , a total of @xmath87 decoding iterations are performed , since from fig .",
    "[ fig : fer ] we observe that increasing the number of iterations to , e.g. , @xmath88 , does not lead to a significant improvement in performance for this ldpc code .",
    "all synthesis results are obtained by using a tsmc  @xmath89 nm cmos library under typical operating conditions .",
    "+ [ mark= * , mark options = fill = blue , color = blue , ] table [ x index = 0 , y index = 1 , col sep = comma ] lut.csv ;    + [ mark = square * , mark options = fill = red , color = red , ] table [ x index = 0 , y index = 1 , col sep = comma ] fixed_4bit.csv ;    + [ mark = triangle * , mark options = fill = green!60!black , color = green!60!black , ] table [ x index = 0 , y index = 1 , col sep = comma ] fixed_5bit.csv ;    + [ mark = x , mark options = fill = black , color = black , ] table [ x index = 0 , y index = 1 , col sep = comma ] float_05iter.csv ;    + [ mark = diamond * , mark options = fill = red!50!yellow , color = red!50!yellow , ] table [ x index = 0 , y index = 1 , col sep = comma ] float_10iter.csv ;      for the lut - based decoder , we have used @xmath90 bits for the representation of the channel llrs and @xmath91 bits for the representation of the internal messages , as this leads to an error correction performance that is very close the floating - point ms decoder ( cf .",
    "[ fig : fer ] ) . for the variable nodes ,",
    "we use the lut tree structure of fig .",
    "[ fig : vnodelut ] and for the decision nodes we use the lut tree structure of fig .",
    "[ fig : decnodelut ] .",
    "the design snr is set to @xmath92  db . for the adder - based ms decoder which serves as a reference , we use @xmath93 bits for the representation of the channel llrs and @xmath94 bits for the representation of the internal messages , as this leads to practically the same fer performance for the lut - based and the adder - based ms decoder , as can be seen in fig .",
    "[ fig : fer ] .    .synthesis results [ cols=\"^,^,^\",options=\"header \" , ]      we present synthesis results for the adder - based and the lut - based decoders in table  [ tab : results ] . for fair comparison , we synthesized both designs for various clock constraints and selected the result with the highest hardware efficiency for each design .",
    "these results should not be regarded in absolute terms , as the placement and routing of such a large design is highly non - trivial and will increase the area and the delay of both designs significantly . however , it is safe to make relative comparisons , especially when considering the fact that the lut - based decoder will be easier to place and route due to the fact that it requires approximately 40% fewer wires for the interconnect between the vn , cn , and dn stages .",
    "we observe that the lut - based decoder is approximately 8% smaller as well as 64% faster than the adder - based ms decoder . as a result ,",
    "the area efficiency of the lut - based decoder is @xmath95 higher than that of the adder - based ms decoder . for both designs ,",
    "the critical path goes through the cn , but in the lut - based decoder the delay is smaller due to the reduced bit - width .",
    "we show the area breakdown of the lut - based and the adder - based decoders in table  [ tab : breakdown ] .",
    "we observe that the vn stage area of the lut - based decoder varies significantly over the iterations , even though the lut tree structures are identical .",
    "this is not unexpected , since the contents of the luts are different for different iterations and the resulting logic circuits can have very different complexities .",
    "moreover , we see that the cn stage of the lut - based decoder is approximately @xmath96 smaller than the cn stage of the adder - based decoder due to the bit - width reduction enabled by the optimized lut design . the vn stage of the lut - based decoder , on the other hand , is larger than the vn stage of the adder - based decoder .",
    "however , the reduction in the cn stage is larger than the increase in the vn stage , leading to an overall reduction in area . from table  [",
    "tab : breakdown ] we can see that this reduction stems mainly from the reduced number of required registers , as the area occupied by the logic of each decoder is similar .",
    "in this paper , we described a method that can be applied to design a discrete message - passing decoder for ldpc codes by replacing the standard vn update rules with locally optimal lut - based update rules . moreover , we presented a hardware architecture for a lut - based fully unrolled ldpc decoder which can reduce the area and increase the operating frequency compared to a conventional adder - based ms decoder by @xmath97 and @xmath98 , respectively , due to the significantly reduced bit - width required to achieve identical error correction performance",
    ". finally , the lut - based decoder requires approximately @xmath99% fewer wires , simplifying the routing step , which is a known problem in fully parallel architectures .",
    "z.  zhang , l.  dolecek , b.  nikolic , v.  anantharam , and m.  wainwright , `` design of ldpc decoders for improved low error rate performance : quantization and algorithm choices , '' _ communications , ieee transactions on _ , vol .",
    "57 , no .  11 , pp . 32583268 , nov 2009 .",
    "s.  planjery , d.  declercq , l.  danjean , and b.  vasic , `` finite alphabet iterative decoders  part i : decoding beyond belief propagation on the binary symmetric channel , '' _ ieee trans . on communications _",
    ", oct . 2013 .",
    "d.  declercq , b.  vasic , s.  planjery , and e.  li , `` finite alphabet iterative decoders ",
    "part ii : towards guaranteed error correction of ldpc codes via iterative decoder diversity , '' _ ieee transactions on communications _ , vol .",
    "61 , no .  10 , pp .",
    "40464057 , october 2013 .",
    "f.  cai , x.  zhang , d.  declercq , s.  planjery , and b.  vasi , `` finite alphabet iterative decoders for ldpc codes : optimization , architecture and analysis , '' _ ieee transactions on circuits and systems i : regular papers _",
    "61 , no .  5 , pp .",
    "13661375 , may 2014 .",
    "p.  schlafer , n.  wehn , m.  alles , and t.  lehnigk - emden , `` a new dimension of parallelism in ultra high throughput ldpc decoding , '' in _ ieee workshop on signal processing systems ( sips ) _ , october 2013 , pp . 153158 .",
    "a.  winkelbauer and g.  matz , `` on quantization of log - likelihood ratios for maximum mutual information , '' in _ proc .",
    "16th ieee int .",
    "workshop on signal processing advances in wireless communications ( spawc 2015)_. 1em plus 0.5em minus 0.4emstockholm , sweden : accepted for publication , jun .",
    "`` ieee standard for information technology  telecommunications and information exchange between systems  local and metropolitan area networks ",
    "specific requirements part 3 : carrier sense multiple access with collision detection ( csma / cd ) access method and physical layer specifications , '' ieee std .",
    "802.3an , sep . 2006 ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a finite alphabet message passing algorithm for ldpc codes that replaces the standard min - sum variable node update rule by a mapping based on generic look - up tables . </S>",
    "<S> this mapping is designed in a way that maximizes the mutual information between the decoder messages and the codeword bits . </S>",
    "<S> we show that our decoder can deliver the same error rate performance as the conventional decoder with a much smaller message bit - width . </S>",
    "<S> finally , we use the proposed algorithm to design a fully unrolled ldpc decoder hardware architecture . </S>"
  ]
}