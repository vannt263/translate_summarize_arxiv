{
  "article_text": [
    "the cosmic microwave background ( cmb ) is one of the most powerful observational tools for understanding our universe .",
    "indeed , an accurate knowledge of the cmb anisotropies can place tight constraints on fundamental parameters such as the amount of matter in the universe and its overall geometry .",
    "observations of the cmb also allow one to discriminate between different models of structure formation .",
    "recent cmb experiments such as boomerang ( de bernardis et al . 2000 ) and maxima ( balbi et al . 2000 ) have set strong constraints on the geometry of the universe , showing that it is close to spatially flat .",
    "nevertheless , there remain numerous unbroken degeneracies in the full set of parameters that define the currently favoured inflationary cdm cosmological model . in order to resolve these degeneracies a new generation of cmb satellite experiments",
    "is currently in preparation , most notably the nasa map mission ( bennet et al . 1996 ) and the esa planck surveyor ( puget et al .",
    "1998 , mandolesi et al . 1998 ) .",
    "these experiments will provide high - resolution all - sky maps of the cmb anisotropies which will allow a highly accurate estimation of a large set of cosmological parameters .",
    "an important issue for cmb satellite missions is the separation of foreground emission from the cmb signal .",
    "an accurate means of performing this separation is vital in order to make full use of the high - resolution cmb maps these experiments will produce . the main foregrounds to be separated from the cmb signal are those due to our own galaxy ( dust , free - free & synchrotron emission ) and extragalactic emission due , principally , to the sunyaev  zeldovich effect ( both thermal and kinetic ) and point sources .    a preliminary application of neural - network techniques in this field has recently been performed with promising results ( baccigalupi et al .",
    "2000 ) , but this approach is not at present sufficiently sophisticated to accommodate multifrequency data arising from convolutions with beams of different sizes and subject to different levels of instrumental noise .",
    "nevertheless , more traditional techniques based on the maximum - entropy method ( mem ) have been shown to provide an efficient and accurate way of performing the component separation ( hobson et al .",
    "1998 ; h98 , hereafter ) .",
    "as one might expect , the mem technique is particularly successful at using multifrequency data to identify foreground emission from physical components whose spectral signatures are ( reasonably ) well - known .",
    "it is therefore not surprising that the most problematic foreground to remove is that due to extragalactic point sources .",
    "these differ from the other components in the important respect that the spectral behaviour of point sources differs from one source to the next and , moreover , is notoriously difficult to predict .",
    "we can , however , make some headway by at least identifying the likely populations of point sources at different observing frequencies .",
    "our knowledge of point source populations is increasing with new observations , but there are still great uncertainties . in the absence of extensive observations at microwave frequencies , the currently - favoured approach is to use the toffolatti et al .",
    "( 1998 ) model , which provides an estimate of point source populations based on existing observations and basic physical mechanisms .",
    "this model can be used to generate simulated point source emission at different observing frequencies . from 30 to 100 ghz , the main point source emission is due to radio selected flat  spectrum agns ( radio - loud quasars , blazars , etc . ) . from 300 to 900 ghz ,",
    "infrared selected sources - starburst and late type galaxies at intermediate to low redshift and high redshift ellipticals - account for most point source emission . at intermediate frequencies ,",
    "both populations contribute approximately equally .",
    "the problem of removing emission due to point sources from cmb observations has been addressed by several authors .",
    "for example , tegmark & oliveira - costa ( 1998 ; toc98 , hereafter ) suggest a straightforward harmonic filter technique that is optimised to detect and subtract point sources , whereas hobson et al .",
    "( 1999 ; h99 , hereafter ) propose treating point source emission as an additional generalised ` noise ' contribution within the framework of the mem approach discussed in h98 .",
    "tenorio et al .",
    "( 1998 ) present a wavelet technique to subtract point sources , but the wavelet basis used in this work is not the optimal one for this purpose .",
    "this point is addressed in sanz , herranz & martnez - gonzlez ( 2000 ) , where it is shown that the ` mexican hat ' wavelet ( mhw ) is in fact optimal for detecting point sources under reasonable conditions , the most important assumption being that the beam is well approximated by a gaussian .",
    "the application of this wavelet to realistic simulations has been presented in cayn et al .",
    "( 2000 ; c00 , hereafter ) and extended in vielva et al .",
    "( 2001 ; v01 , hereafter ) .",
    "the main advantage of the mhw method over the previous works is that the algorithm does not require any assumptions to be made regarding the statistical properties of the point source population or the underlying emission from the cmb ( or other foreground components ) .",
    "the aim of this paper is to show how the mem and mhw approaches are in fact complementary and can be combined to improve the accuracy of the separation of diffuse foregrounds from the cmb and increase the number of points sources that are identified and successfully subtracted .",
    "the technique proposed in this paper is as follows .",
    "first , we apply the mhw to the multifrequency simulated planck maps to detect the brightest point sources at each observing frequency , which are subtracted from the original data . the mem algorithm",
    "is then applied to these processed maps in order to recover the rest of the components of the microwave sky .",
    "these reconstructed components are then used as inputs to produce ` mock ' data and subtracted from the original data maps . since we expect our reconstructions to be reasonably accurate",
    ", the residuals maps obtained in this way would mostly contain noise and the contribution from point sources .",
    "finally , we apply the mhw on these residuals maps in order to recover a more complete and accurate point source catalogue .    in this paper the combined method is applied to simulated observation by the planck satellite , but the technique could easily be applied to map data or to existing multifrequency observations by the boomerang or maxima balloon experiments .",
    "the paper is organized as follows . in the next section we present a brief overview of the mem and mhw techniques , outlining in particular the advantages and shortcomings of each approach .",
    "we then explain why the two approaches can be successfully combined to produce a more powerful joint analysis scheme . in section  3",
    "we summarise how the simulated planck observations were performed . in section  4",
    "we present the results of a component separation based on the new joint analysis method , and discuss the improved accuracy of the reconstructions of the diffuse components . in section  5",
    "we concentrate on the recovery of the point sources themselves and discuss the construction of point source catalogues from planck observations .",
    "finally , our conclusions are presented in section  6 .",
    "in this section , we briefly review the mem and mhw techniques . a complete description of the mem component separation algorithm can be found in h98 . in addition , h99 describes how to include point sources into the mem formalism .",
    "we therefore provide only a basic outline of the approach .",
    "the mhw method is introduced in c00 and extended in v01 , and so again we give only a basic summary .",
    "if we observe the microwave sky in a given direction @xmath2 at @xmath3 different frequencies , we obtain an @xmath3-component data vector that contains , for each frequency , the temperature fluctuations convolved with the beam in this direction plus instrumental noise .",
    "the @xmath4th component of the data vector in the direction @xmath2 may be written as @xmath5 in this expression we distinguish between the contributions from the point sources and the @xmath6 physical components for which it is assumed the spectral behaviour is constant and reasonably well - defined ( over the observed patch of sky ) .",
    "the latter are collected together in a signal vector with @xmath6 components , such that @xmath7 is the signal from the @xmath8th physical component at some reference frequency @xmath9",
    ". the corresponding total emission at the observing frequency @xmath4 is then obtained by multiplying the signal vector by the @xmath10 frequency response matrix @xmath11 that includes the spectral behaviour of the considered components as well as the transmission of the @xmath4th frequency channel .",
    "this contribution is then convolved with the beam profile @xmath12 of the relevant channel . since the individual spectral dependencies of the point sources are very complicated , we can not factorize their contribution in this way and so they are added into the formalism as an extra ` noise ' term . thus @xmath13 is the contribution from point sources , as observed by the instrument at the frequency @xmath4 ( hence , convolved with the beam profile ) . finally , @xmath14 is the expected level of instrumental noise in the @xmath4th frequency channel and is assumed to be gaussian and isotropic .",
    "the assumption of a spatially - invariant beam profile in ( [ datadef ] ) allows us to perform the reconstruction more effectively by working in fourier space , since we may consider each @xmath15-mode independently ( see h98 ) .",
    "thus , in matrix notation , at each mode we have @xmath16 where @xmath17 , @xmath18 and @xmath19 are column vectors each containing @xmath3 complex components and @xmath20 is a column vector containing @xmath6 complex components . in the second equality",
    "we have combined the instrumental noise vector @xmath19 and the point - source contribution @xmath18 into a single ` noise ' vector @xmath21 .",
    "the response matrix @xmath22 has dimensions @xmath23 and its elements are given by @xmath24 .",
    "the aim of any component separation / reconstruction algorithm is to invert ( [ dataft2 ] ) in some sense , in order to obtain an estimate @xmath25 of the signal vector at each value of @xmath15 independently .",
    "owing to the presence of noise , and the fact that the response matrix @xmath22 is not square and would , in any case , have some small eigenvalues , a direct inversion is not possible , and so some form of regularised inverse must be sought .",
    "typical methods include singular - valued decomposition , wiener filtering or the maximum - entropy method .",
    "the elements of the signal vector @xmath20 at each fourier mode may well be correlated , this correlation being described by the @xmath26 signal covariance matrix @xmath27 defined by @xmath28 where the dagger denotes the hermitian conjugate . moreover ,",
    "if prior information is available concerning these correlations , we would wish to include it in our analysis .",
    "we therefore introduce the vector of ` hidden ' variables @xmath29 , related to the signal vector by @xmath30 where the @xmath31 lower triangular matrix @xmath32 is obtained by performing a cholesky decomposition of the signal covariance matrix @xmath33 .",
    "the reconstruction is then performed entirely in terms of @xmath34 and the corresponding reconstructed signal vector is subsequently found using ( [ icfdef ] ) .",
    "using bayes theorem , we choose our estimator @xmath35 of the hidden vector to be that which maximises the posterior probability given by @xmath36 where @xmath37 is the likelihood of obtaining the data given a particular hidden vector and @xmath38 is the prior probability that codifies our expectations about the hidden vector before acquiring any data .",
    "as explained in h99 , the form of the likelihood function in ( [ bayes ] ) is given by @xmath39 \\label{likehd}\\end{aligned}\\ ] ] where in the last line we have used ( [ dataft2 ] ) .",
    "the noise covariance matrix @xmath40 has dimensions @xmath41 and at any given @xmath15-mode is given by @xmath42 therefore , at a given fourier mode , the @xmath4th diagonal element of @xmath40 contains the ensembled - averaged power spectrum at that mode of the instrumental noise plus the point source contribution to the @xmath4th frequency channel .",
    "the off - diagonal terms give the cross - correlations between different channels ; if the noise is uncorrelated between channels , only the point sources contribute to the off - diagonal elements .    for the prior @xmath38 in ( [ bayes ] ) , we assume the entropic form @xmath43 \\label{prior}\\ ] ] where @xmath44 is the cross entropy of the complex vectors @xmath34 and @xmath45 , where @xmath46 is a model vector to which @xmath29 defaults in absence of data .",
    "the form of the cross entropy for complex images and the bayesian method for fixing the regularising parameter @xmath47 are discussed in h98 .",
    "we note that , in the absence of non - gaussian signals , the entropic prior ( [ prior ] ) tends to the gaussian prior implicitly assumed by wiener filter separation algorithms , and so in this case the two methods coincide .",
    "the argument of the exponential in the likelihood function ( [ likehd ] ) may be identified as ( minus ) the standard @xmath48 misfit statistic , so we may write @xmath49 $ ] . substituting this expression , together with that for the prior probability given in ( [ prior ] ) , into bayes theorem , we find that maximising the posterior probability @xmath50 with respect to @xmath34 is equivalent to minimising the function @xmath51 this minimisation can be performed using a variable metric minimiser ( press et al .",
    "1994 ) and requires only a few minutes of cpu time on a sparc ultra workstation .",
    "the mhw technique presented by c00 and v01 for identifying and subtracting point sources operates on individual data maps .",
    "let us consider the two - dimensional data map @xmath52 at the frequency @xmath4 . if the map contains point sources at positions @xmath53 with fluxes or amplitudes @xmath54 , together with contributions from other physical components and instrumental noise , then the data map is given by @xmath55 where @xmath12 is the beam at the observing frequency @xmath4 , and in this case the generalised ` noise ' @xmath56 is defined as all contributions to the data map aside from the point sources . for the @xmath57th point source , we may define a ` detection level ' @xmath58 where @xmath59 is the area under the beam and @xmath60 is the dispersion of the generalised noise field @xmath56 . in general , the detection level @xmath61 will be much less than unity for all but the few brightest sources .",
    "this is the usual problem one faces when attempting to identify point sources directly in the data map .",
    "as explained in c00 , instead of attempting the identification in real space , one can achieve better results by first transforming to _",
    "wavelet space_. for a two - dimensional data map @xmath62 , we define the continuous isotropic wavelet transform by @xmath63 where @xmath64 is the wavelet coefficient associated with the scale @xmath65 at the point @xmath66 ( where the wavelet is centred ) .",
    "the function @xmath67 is the _ mother _ wavelet , which is assumed to be isotropic and satisfies the conditions @xmath68 where @xmath69 denotes the fourier transform of @xmath70 , @xmath71 and @xmath72 .",
    "the wavelet coefficients given by ( [ eq : wt ] ) characterise the contribution from structure on a scale @xmath65 to the value of the map at the position @xmath66 .    by analogy with ( [ reald ] ) , in wavelet space we define the detection level for the @xmath57th point source ( as a function of scale @xmath65 ) by @xmath73 where @xmath74 is the wavelet coefficient of the field @xmath75 at the location of the @xmath57th point source , and @xmath76 is the dispersion of the wavelet coefficients @xmath77 of the generalised noise field @xmath56 . it is straightforward to show that @xmath78 where @xmath79 is the power spectrum of @xmath56 .",
    "the integral limits , @xmath80 and @xmath81 , correspond to the maximum and minimum scales of the sky patch analysed , i.e. the patch and pixel scales respectively .",
    "the detection level @xmath82 in wavelet space will have a maximum value at some scale @xmath83 .",
    "this scale is practically the same for all point sources , and may be found by solving @xmath84 . in general ,",
    "the optimal scale is of the order of the beam dispersion @xmath85 ( see v01 , section 3 , for a discussion about how the noise and the coherence scale of the background determine the optimal scale ) . in order that the wavelet coefficients are optimally sensitive to the presence of the point source",
    ", we must make the value of @xmath86 as large as possible .",
    "this is achieved through an appropriate choice both of the mother wavelet @xmath87 and the optimal scale .",
    "if the beam profile is gaussian and the power spectrum of the generalised noise field is scale - free , sanz et al .",
    "( 2000 ) show that for a wide range of spectral indices of the power spectrum the mexican hat wavelet is optimal .",
    "the two - dimensional mhw is given by @xmath88               e^{-\\frac{x^2}{2r^2}},\\ ] ] from which we find @xmath89 where @xmath54 is the amplitude of the @xmath57th point source , @xmath59 is the area under the gaussian beam and @xmath85 is the beam dispersion . in ( [ eq : coeff ] ) it is assumed that any overlap of the ( convolved ) point sources is negligible . that is a good approximation for the brightest point sources , the ones that the mhw is able to detect .",
    "in fact , the number of point sources detected at each frequency ( see table  [ tps ] ) corresponds only to a small percentage of the number of resolution elements ( see table  [ observ ] ) contained at each planck frequency channel ( @xmath90 at 30ghz , the most unfavourable case ) .",
    "therefore , the probability of finding two or more bright point sources inside the same resolution element is very low .",
    "the advantage of identifying point sources in wavelet space rather than real space may then be characterised by the amplification factor @xmath91    in practice , it is clear that we do not have access to the wavelet coefficients of the fields @xmath75 and @xmath56 separately , but only to the wavelet coefficients of the total data map @xmath92 .",
    "nevertheless , if the detection level @xmath82 for the @xmath57th point source is reasonably large , we would expect @xmath93 .",
    "also , if we assume that the power spectrum of the point source emission is negligible as compared to that of the generalised noise field , then @xmath94 .",
    "thus our algorithm for detecting point sources is as follows . using the above approximations",
    ", we first calculate the optimal scale @xmath95 .",
    "we then calculate the wavelet transform @xmath96 of the data map at the optimal scale .",
    "the wavelet coefficients are then analysed to find sets of connected pixels above a certain threshold @xmath97 .",
    "the maxima of these spots are taken to correspond to the locations of the point sources .",
    "for every point source detected in the above way , we then go on to estimate its flux .",
    "this is achieved by performing a multiscale fit as follows . for each point source location @xmath53 ,",
    "the wavelet transform @xmath98 is calculated at a number of scales @xmath65 and compared with the theoretical curve ( [ eq : coeff ] ) .",
    "this comparison is performed by calculating the standard misfit statistic @xmath99^{\\rm t } { \\mathbfss v}^{-1 } \\left[{\\mathbfit w}^{\\rm ( exp)}-{\\mathbfit w}^{\\rm ( theo)}\\right],\\ ] ] where the @xmath100th element of the vector @xmath101 is @xmath102 ( and similarly for the vector of theoretical wavelet coefficients ) .",
    "the matrix @xmath103 is the empirical covariance matrix of the wavelet coefficients on different scales , which is given by @xmath104 where the average is over position @xmath66 .      in h99",
    "the mem technique is shown to be effective at performing a full component separation in the presence of point sources .",
    "in particular , the reconstructed maps of the separate diffuse components contain far less point - source contamination than the input data maps .",
    "moreover , by comparing the true data maps with simulated data maps produced from the separated components , it is possible to obtain point source catalogues at each observing frequency . nevertheless , the mem approach does have its limitations . since the point sources are modelled as an additional generalised noise component ,",
    "it is not surprising that mem performs well in identifying and removing the large number of point sources with low to intermediate fluxes .",
    "however , it is rather poorer at removing the contributions from the brightest point sources .",
    "these tend to remain in the reconstructed maps of the separate diffuse components , although with much reduced amplitudes .",
    "the mhw technique , on the other hand , performs best when identifying and removing the brightest point sources .",
    "indeed , in detecting bright sources the mhw technique generally out - performs other techniques such as sextractor ( bertin & arnouts , 1996 ) and standard harmonic filtering ( toc98 ) .",
    "moreover , the amplitudes of the bright sources are also accurately estimated . for weaker sources",
    ", however , the mhw technique performs more poorly by either inaccurately estimating the flux or failing to detect the source altogether .",
    "the strengths and weaknesses of the mem and mhw approaches clearly indicate that they are complementary techniques , and that a combined approach might lead to improved results as compared to using each method independently .",
    "we thus propose the following method for analysing multifrequency observations of the cmb that contain point source contamination .",
    "first , the data map at each observing frequency is analysed separately using the mhw in order to detect and remove as many bright point sources as possible and obtain accurate estimates of their fluxes .",
    "the processed data maps are then taken as the inputs to the generalised mem approach discussed in h99 .",
    "as we will demonstrate in section [ foresep ] , the mem analysis of these processed maps leads to more accurate reconstructed maps of the separate diffuse components .",
    "this leads in turn to more accurate residual maps between the true input data with the data simulated from the reconstructions .",
    "these residual maps are then analysed with the mhw in order both to refine the original estimates of the fluxes of the bright point sources and to detect fainter sources .",
    "thus , the joint analysis not only gives a more complete point source catalogue , but also improves the quality of the reconstructed maps of the cmb and other foreground components .",
    ".basic observational parameters of the 10 frequency channels of the planck surveyor satellite .",
    "column two lists the fractional banwidths .",
    "the fwhm in column three assumes a gaussian beam . in column four",
    "the instrumental noise level is @xmath105 ( @xmath106k ) per resolution element for 12 months of observation . [",
    "cols=\"^,^,^,^ \" , ]     the mem ( h98 , h99 ) and the mhw ( c00 , v01 ) techniques have complementary characteristics when recovering the microwave sky . on the one hand ,",
    "the mem technique is a powerful tool for using multifrequency data to separate the cosmological signal from foreground emission whose spectral behaviours are ( reasonably ) well - known .",
    "the most problematic foreground to remove is that due to point sources . on the other hand ,",
    "the mhw has shown to be a robust and self - consistent method to detect and subtract this point source emission from microwave maps .",
    "the aim of this paper has been to show how the performance of a combined ( mem and mhw ) analysis can improve the recovery of the components ( cmb , sunyaev - zeldovich , extragalactic point sources and galactic emission ) of simulated microwave maps . in order to test this analysis ,",
    "we have applied it to simulated esa planck satellite observations . however",
    ", the technique could straightforwardly be applied to other cmb experiments ( e.g. nasa map satellite , boomerang and maxima ) .",
    "the proposed method to analyse these data is as follows .",
    "first , we apply the mhw at each observing frequency in order to remove the brightest point sources and obtain very good amplitude estimations .",
    "the mem technique is then applied to these maps to reconstruct the different components ( except the remaining point sources contribution , which is treated as an additional ` noise ' ) .",
    "following the approach discussed in h99 , we generate mock observed data from our reconstructions .",
    "these maps are then subtracted from the initial data .",
    "this provides data residuals maps which mostly contain instrumental noise plus point source emission ( with slight traces of unrecovered diffuse components ) .",
    "these residual maps are then analysed again with the mhw in order to refine the number of detections and the amplitude estimation of the point sources .    as already discussed in section [ foresep ] ,",
    "the joint analysis improves the accuracy of the component separation of all the diffuse components .",
    "this is so because the mhw subtraction algorithm is efficient at removing the brightest point sources , whereas mem has greatly reduced the contamination due to fainter sources .",
    "we compare the reconstructions achieved when the mhw is or is not applied . in particular , figure [ dif ] shows how many point sources would remain in the reconstructed components if the mhw were not used .",
    "we can see that a large number of point sources are removed from the dust and free - free maps .",
    "there are also a handful of point source that would contaminate the synchrotron emission , coming from the low frequency channels . a lower number of point sources would affect the cmb reconstruction since the cosmological signal is the main component at the intermediate planck frequencies , where point source emission is lower . finally , a few point sources would be misidentified with sz clusters , appearing in the reconstruction at the reference frequency as sharp negative features .    in the previous section , we gave estimates of the point source catalogues that mem , mhw and the joint method provide for these simulations ( see table  [ tps ] ) .",
    "we see that the joint analysis provides , in general , a more complete catalogue than each of the methods on its own , reaching lower fluxes and with point source amplitude more accurately estimated .",
    "the improvement is especially clear at high frequencies due to the high resolution of those planck channels .",
    "the differences between the number of detections in the memc and m&mc are smaller for the channels between 30 and 100 ghz .",
    "this is due to the difficulty of detecting point sources using the mhw when the background has a similar scale variation to that of the point sources ( see v01 for more details ) .",
    "hence the main contribution of the mhw at these frequencies is in improving the amplitude estimation . in table",
    "[ 23sphere ] we give an estimate of the number of point sources that would be detected with this combined method in two  thirds of the sky after 12 months of observation with the planck satellite .",
    "this number is simply obtained by multiplying the counts of table  [ tps ] by the ratio between the solid angle covered by two - thirds of the sphere and that covered by our simulations .",
    "we compare the recovered point source catalogue with the simulated one , with a cutoff as given by the ` minimum flux ' column for m&m given in table  [ tps ] .",
    "we can see that for most of them , the percentage of detection is around or above @xmath107 .",
    "current evolution models of dust emission in galaxies ( see , e.g. , franceschini et al .",
    "1994 ; guiderdoni et al .",
    "1998 ; granato et al .",
    "2000 ) give different predictions for counts in the high frequency planck channels . on the other hand ,",
    "all these models predict a very sharp increase of the far  ir / sub  mm galaxy counts at fluxes @xmath108 mjy . therefore ,",
    "given the detection limits of table  [ tps ] , planck data alone will not be able to disentangle among different models , although it could marginally detect the sharp increase in the counts in the channels where the minimum flux achieved lies below 100 mjy . in any case",
    ", planck will provide very useful data on counts , in a flux range not probed by other experiments .",
    "these data , complementary to the deeper surveys from the ground or from the space ( esa first and astro ",
    "f / iris missions ) , will surely allow to discriminate among the various evolutionary scenarios .",
    "spectral information about the point sources could also be used to improve further the recovered catalogues .",
    "indeed , v01 have shown that following point sources through adjacent channels , one can estimate the spectral indices of the different point source populations .",
    "this would allow the recovery of point sources that , albeit below the detection limit , have an amplitude and position in agreement with those predicted from adjacent channels .",
    "finally , as pointed out in the previous section , the flux limits achieved in the m&mc are close to the noise level",
    ". indeed , the faintest point sources detected in the catalogue have a fluxes which are 3.0 , 2.4 , 1.6 , 1.2 , 1.1 , 11.2 , 6.7 , 1.1 , 1.3 and 1.4 times the noise rms in the 30 , 44 , 70 , 100(lfi ) , 100(hfi ) , 143 , 217 , 353 , 545 and 857 ghz channels , respectively . to reach fainter fluxes in these channels",
    "is a difficult task , since we are very close to the noise level except for the 143 and 217 ghz channels .",
    "on the other hand , if we subtract the mhwc sources from the original data at 143 and 217 ghz , instead of the point sources detected by the @xmath109 criterion , we could greatly increase the number of sources and the depth of the m&mc at those frequencies . a possibility to improve",
    "the results at all frequencies could be to denoise these data residual maps .",
    "one way is using wavelet techniques that have been proved to be very efficient at removing noise from cmb maps ( sanz et al .",
    "1999a , b ) .",
    "however , care must be taken when denoising the residual maps since the denoising procedure may change the profile of the point source in wavelet space . a detailed study of the properties of the denoised map",
    "would then become necessary . in this case , instead of the mexican hat , one could use a customised pseudo - filter to detect point sources in the residual maps as proposed by sanz et al ( 2000 ) .    a natural way to improve the results",
    "is to subtract the recovered m&mc from the original data and applying the mem algorithm again .",
    "this process could be performed iteratively until the flux limits and the number of counts converge . however , this method has some disadvantages . as pointed out in the previous section ,",
    "if the sources subtracted from the input maps have a large error , this could mislead the mem algorithm .",
    "this is the reason why we choose to subtract the catalogue achieved by the @xmath109 criterion instead of subtracting the one given by the @xmath107 error criterion .",
    "the number of point sources with _ large errors _ in the m&mc is larger than in the mhwc obtained with the @xmath107 error criterion .",
    "hence , a more detailed analysis becomes necessary in order to improve the results with an iterative approach .",
    "such a study will be performed in a future work , where the combined technique will be extended to the sphere",
    ". moreover , the flux limits are already close to the noise level and thus we do not expect the detection levels to change substantially ( except for the 143 and 217 ghz channel , that can be clearly improved ) .",
    "pv acknowledges support from universidad de cantabria fellowship as well as the astrophysics group of the cavendish laboratory for their hospitality during april 2000 .",
    "rbb acknowledges financial support from the pparc in the form of a research grant .",
    "pv , emg , jls and lt thank spanish dgesic project no .",
    "pb98 - 0531-c02 - 01 for partial support .",
    "emg and jls thank feder project no .",
    "1fd97 - 1769-c04 - 01 and eec project intas - open-97 - 1192 for partial financial support ."
  ],
  "abstract_text": [
    "<S> we present a maximum  entropy method ( mem ) and ` mexican hat ' wavelet ( mhw ) joint analysis to recover the different components of the microwave sky from simulated observations by the esa planck satellite in a small patch of the sky ( @xmath0 deg@xmath1 ) . </S>",
    "<S> this combined method allows one to improve the cmb , sunyaev  zeldovich and galactic foregrounds separation achieved by the mem technique alone . </S>",
    "<S> in particular , the reconstructed cmb map is free from any bright point source contamination . </S>",
    "<S> the joint analysis also produces point source catalogues at each planck frequency which are more complete and accurate than those obtained by each method on its own . </S>",
    "<S> the results are especially improved at high frequencies where infrared galaxies dominate the point source contribution . </S>",
    "<S> although this joint technique has been performed on simulated planck data , it could be easily applied to other multifrequency cmb experiments , such as the forthcoming nasa map satellite or the recently performed boomerang and maxima experiments .    </S>",
    "<S> # 1 # 1 # 1 # 1 = = = = = = = =    methods : data analysis  techniques : image processing  cosmic microwave background </S>"
  ]
}