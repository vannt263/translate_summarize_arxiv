{
  "article_text": [
    "optical flow estimation is one of the key topics of research at the core of computer vision . since the work of horn & schunk @xcite , most of the work in this area has been based on variational methods and the leading works such as deepflow @xcite and epicflow @xcite are all variants of it .",
    "but very recently , cnn - based flow estimation methods , have become the center of attention .",
    "the works of @xcite & @xcite , later followed by @xcite were the first ones to train a convnet in a simple end - to - end fashion for optical flow estimation .",
    "the impressive advantage of the network - based methods is their inherent speed at the test time , which makes them eligible to be called `` real - time '' methods .",
    "although the network - based methods are relatively successful on synthetic datasets , they are still behind the leading classical methods in real world by a large margin , mainly due to lack of training data with optical flow groud - truth on real videos . to overcome this issue ,",
    "many methods focus on creation of better synthetic datasets @xcite .",
    "in contrast to such solutions , we seek to deal with the problem by making the network `` see '' the real data during training .",
    "but this is not a straight - forward task .",
    "@xcite applies a variational method on real data to generate `` semi - truth '' data , while @xcite approach the problem by reformulating the task as an unsupervised one for the network .",
    "the latter works both use cost functions based on the constant intensity assumption , during training .",
    "we also feed the real data to the network in an unsupervised manner .",
    "however we use the self - supervised task of next - frame prediction as an auxiliary task for the network , to be able to leverage the real data without the need for flow annotations .",
    "video prediction has been widely experimented with recently @xcite .",
    "although some of these works , such as @xcite , focus on prediction as the main objective , most of the others use it as an auxiliary task .",
    "@xcite learns optical flow by trying to warp the current frame to the next one .",
    "we propose a hybrid multi - tasking scheme , which makes use of a mixture of two different types of data : synthetic video with flow ground - truth vs. real video without . only very recently , and concurrently with our work",
    ", @xcite proposes multi - tasking with diverse datasets .",
    "[ [ contributions ] ] contributions + + + + + + + + + + + + +    our contributions in this work can be summarized as :    * implementation of a multiplexer layer which together with an on - off switch inside the loss layer , form a time - variant architecture and make hybrid training of the network on datasets of different type possible .",
    "* simultanous training on supervised and self - supervised tasks to highly improve cnn - based optical flow estimation in real scenes .",
    "* prediction of the future flow instead of current flow as a more compatible task with video prediction . * state - of - the - art next - frame prediction results as a single task , just using l1 loss .",
    "in sections [ flow estimation ] and [ next - frame prediction ] we first introduce our flow estimation and next - frame prediction components as individual networks .",
    "then in section [ multi - tasking ] we show how these architectures are combined together with the time - dependent switching mechansim , to form the proposed hybrid multi - tasking architecture . finally in [ next - flow prediction ]",
    "we show how `` current flow '' estimation is replaced by a `` future flow '' prediction .",
    "the flow estimator network we use , has a fully convolutional encoder - decoder architecture , which builds on the one introduced in @xcite .",
    "we choose to stick to this particular kind of architecture to be able to clearly analyze the effects of the added auxiliary task and data type .",
    "however we extend the architecture of @xcite , by adding two more deconvolutional layers , to get the full - resolution flow - field directly from the network .",
    "we do this to keep this architecture in harmony with the frame predictor .",
    "we use the endpoint error loss ( epe ) for training of this component .    the architecture illustrated in figure [ fig : architecture ] details the contraction and expansion in the encoder and decoder components respectively . in figure",
    "[ fig : architecture ] we omit the extra details regarding the so - called `` refinement '' steps ( figure 3 in @xcite ) , to focus on the main contributions of the current study .",
    "however we depict the skip connections between the conv / deconv pairs , to show how they are extended to the two new deconv layers  note the link from input to deconv0 .",
    "also note that in figure [ fig : architecture ] number of outputs of deconv0 is set to 2 for the task of flow estimation .",
    "we adapt the architecture introduced in the previous section for flow estimation , to the task of next - frame prediction . to this end",
    ", we simply change the number of outputs of deconv0 to 3 , to represent 3 channels of an rgb image  instead of a 2-channel flow frame .",
    "as suggested in preivious work such as @xcite , we avoid using an l2 loss for this task to avoid blurriness of the results , and use l1 loss for training . as reported in section [ experiments ] , we experiment with different number of frames as input .",
    "however in the multi - tasking scheme , we only use a 2-frame set - up to be compatible with the paired task of flow estimation .",
    "[ [ multi - tasking ] ] multi - tasking + + + + + + + + + + + + +    if we were to train just on synthetic data , where flow ground - truth is available , a simple multi - tasking approach would be as easy as designing a network to produce two outputs in parallel , one for each task .",
    "the two tasks would share some parameters and during training we would minimize the total loss .",
    "we basically follow the same scheme for combination of the two tasks , such that the two networks share the encoder ( convolutional ) layers and are independent in their decoding ( deconvolutional ) branches ( figure [ fig : teaser ] ) .    in the problem at hand , however , there are two complexities to overcome .",
    "first , the data is coming from two differet sources and we should find a way to mix them . secondly , unlike synthetic data , the real data does not come with flow ground truth , and the question is what the flow - related part of the network should be doing when it faces real data .",
    "[ [ hybrid - data ] ] hybrid data + + + + + + + + + + +    for mixing the data , we implemented a time - based multiplexer layer whose task is to alternate between the two data `` channels '' ( figure [ fig : teaser ] ) .",
    "the multiplexer does this alternation at the batch level : data in a single batch is guaranteed to be taken from a single source .",
    "we can formulate the job of the multiplexer as :    @xmath0    where @xmath1 & @xmath2 are the data blobs from datasources 1 & 2 at the @xmath3 iteration , respectively , and @xmath4 is the output of this layer which is fed to the network .",
    "@xmath5 is the _ switch _ function as follows : @xmath6 in which , @xmath7 and @xmath8 define the number of cycles dedicated to each datasource .",
    "the output is a periodic signal consisting of @xmath7 0 s and @xmath8 1 s respectively .    [",
    "[ time - variant - architecture ] ] time - variant architecture + + + + + + + + + + + + + + + + + + + + + + + + +    as for the second issue , we implement an on - off switch whose job is to deactivate the flow - related part of the network when there s no flow annotation , so that no learning happens during those iterations ( figure [ fig : teaser ] ) . the on - off switch",
    "is in practice implemented inside the loss layer such that during the off state , both loss and loss gradient are set to zero .",
    "the total loss at the @xmath3 iteration is computed according to : @xmath9 in which @xmath10 & @xmath11 are the flow and frame estimation respectively ( [ fig : teaser ] ) , with their assigned weights , @xmath12 & @xmath13 .",
    "we keep this switch in sync with the multiplexer layer , to achieve the desired functionality : the network learns both tasks during the `` synthetic iterations '' , but postpones updating the flow - only branch when there s no ground - truth .",
    "of course the shared part of the network remains activated all the time .",
    "we set the loss weights such that @xmath14 is equal to @xmath15 where @xmath16 s are the estimates of the variances of input data ( frame vs. flow ) and are computed over a subset of the training sets .    in our main experiments we dedicate an equal cycle of 1 to both synthetic and real data sources , but we also provide an anaysis on the effect of different cycle ratios on the quality of the output flow field .",
    ".9   represent a single frame in a video sequence of length 3 and @xmath17 denotes a flow field . in both scenarios only @xmath18 and @xmath19 are the inputs to the network .",
    "therefore the terms `` current flow '' and `` next - flow '' refer to @xmath20 & @xmath21 respectively.,title=\"fig : \" ]    .9   represent a single frame in a video sequence of length 3 and @xmath17 denotes a flow field . in both scenarios",
    "only @xmath18 and @xmath19 are the inputs to the network",
    ". therefore the terms `` current flow '' and `` next - flow '' refer to @xmath20 & @xmath21 respectively.,title=\"fig : \" ]      in a multi - tasking scheme , for the combination to yield significant improvements in the results , the two tasks need to be `` related '' @xcite .    in context of the current work , we hypothesize that prediction of the `` next - flow '' ( i.e. the future flow to come ) , may have more in common with the task of next - frame prediction .",
    "figure [ fig : next_flow_diagram ] compares the two combinations , and gives an intuition on how the two `` prediction '' tasks might be in more harmony .    more formally : the two tasks share the encoder component of the network , that maps @xmath22 , where @xmath23 is the internal representation to be learned by the network .",
    "this mapping is affected by both tasks during the backward pass and for multi - tasking to make sense , we expect that some part of the features learned by the encoder be beneficial to both of the target tasks .",
    "we hypothesize that the pair of @xmath24 have more to share , compared to @xmath25 not only due to both being `` prediction '' tasks , but also because in obtaining the future flow , the network needs to learn , at least implicitly , about the future frame .",
    "this is not the case for the current flow ( figure [ fig : next_flow_diagram ] ) .",
    "this hypothesis is supported by experimental results in the following .",
    ".83 ( a ) ( b ) ( c ) ( d ) ( e )",
    "we evaluate the optical flow estimation capabilities of the proposed networks both qualitatively and quantitatively , where possible .      for hybrid training of the network",
    "we need 2 datasets .",
    "we use the the so called `` flyingthings3d '' dataset of @xcite as the synthetic data source .",
    "it consists of more than 20k training images and is a more suitable choice for training a convnet from scratch , compared to the famous sintel dataset with only 1064 training samples @xcite . for the real - world source of data",
    ", we use a subset of the sports1 m dataset @xcite .",
    "the subset includes all the videos with a file size less than 5 mbytes , which amounts to more than 220k videos and 220 m frames .",
    "we make the selection list available online .",
    "we use the ucf101 @xcite and hmdb51 @xcite datasets for evaluation of the optical flow on real datasets .",
    "these are both rather big datasets containing more than 2 m & 600k frames respectively . also to analyze the effect of the proposed method on synthetic data",
    ", we use the public part of the sintel dataset @xcite along with the test subset of flyingthings3d @xcite .    to compare the performance of our next - frame predictor",
    "to published work , we use a subset of ucf101 @xcite consisting of 387 videos , as suggested by @xcite .    .end point error ( epe ) measured on two _ synthetic _ datasets before and after multi - tasking .",
    "as expected the values are not changed significantly .",
    "[ cols=\"^,^,^ \" , ]      the multiplexer introduced in section [ multi - tasking ] mixes the two data - sources , assigning @xmath7 and @xmath8 cycles ( iterations ) to each ( equations [ eq : mixture],[eq : switch_function ] ) .",
    "figure [ fig : cycles ] and tables [ table : cycles_epe],[table : cycles_action ] represent the results with various @xmath26 ( or real / synthetic iterations ) .",
    "it is seen that we may get slightly better results by increasing the number of flow learning cycles , e.g. from 1:1 to 1:3 .",
    "however by going higher than this ratio , the effect of the auxiliary task starts to vanish , and the flow results are degraded .",
    "it is also interesting to see that hybrid training can , in some settings , significantly help for synthetic data too .",
    "we also train and test our next - frame predictor as an independent single - tasked network . table [ table : pred_results ] shows a comparison of our method with @xcite  which to the best of our knowledge is the current state - of - the - art in next - frame prediction on ucf .",
    "we believe that the ability to predict the static regions of the image is as important as prediction on the dynamic areas , and thus our results include evaluations on the whole image as well as only on the moving pixels .",
    "wihtout using auxiliary cost functions for the sake of sharpness , and with a single l1 loss , we obtain equivalent results on the moving regions of the image , and significantly better results on the whole image .",
    "this means that the network is doing a better job ` applying the motion' only to the dynamic areas and keeping the static areas intact .",
    "needless of looking for more synthetic data , we have boosted the performance of a cnn - based optical flow estimator using the freely available data from real - world videos .",
    "the quality of the estimated optical flow on real - world scenarios is dramatically improved , while on the synthetic data it remains more or less the same .",
    "there s still a noticable distance to the performance of classical flow estimation methods , which leaves room for more work on cnn - based methods .",
    "our suggested scheme can be plugged into future network - based flow estimators which may use more sophisticated architectures or even benefit from more synthetic data , with little to no modifications . as another possible line of work",
    ", one may incorporate auxiliary tasks other than future prediction ."
  ],
  "abstract_text": [
    "<S> cnn - based optical flow estimators have attracted attentions recently , mainly due to their impressive speed . as successful as they ve been on synthetic datasets , they are still far behind the classical methods in real - world scenarios , mainly due to lack of flow ground - truth . in the current work , </S>",
    "<S> we seek to boost cnn - based flow estimation in real scenes with the help of the freely available self - supervised task of next - frame prediction . to this end </S>",
    "<S> we train the network in a hybrid way , providing it with a mixture of synthetic and real videos . with the help of a novel time - variant multi - tasking architecture , the network decides which of the tasks to learn at each point of time , depending on the availability of ground - truth . </S>",
    "<S> our proposed method improves optical flow estimation in real scenes dramatically . </S>",
    "<S> we also experiment with prediction of `` next - flow '' instead of estimation of the current flow , which is intuitively more related to the task of next - frame prediction and improve the results even more .    </S>",
    "<S> we report and evaluate results both qualitatively and quantitatively . </S>",
    "<S> the latter is done by training a single - stream action classifier on the estimated flow fields on ucf101 & hmdb51 and demonstrate high improvements of accuracy over the baseline : 10.2% and 9.6% respectively . also as a side product of this work , </S>",
    "<S> we report significant improvements over state - of - the - art results in the task of next - frame prediction . </S>"
  ]
}