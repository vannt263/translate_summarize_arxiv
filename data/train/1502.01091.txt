{
  "article_text": [
    "neurons in the brain interact with each other in a heterogeneous and asymmetric way  @xcite , producing complex neuronal dynamics for information processing . in the past decades",
    ", there are a surge of research interests in randomly connected neural networks  @xcite .",
    "although their behavior is described by simple deterministic equations , the resulting dynamics are rich , exhibiting fixed - point behavior , limit cycles , or high - dimensional chaos .",
    "these networks are capable of generating useful dynamic activity patterns after appropriate learning  @xcite .",
    "simple models of neural networks  @xcite have been explored to elucidate characteristics of their complex dynamics . in these networks ,",
    "connections between binary neurons are independently drawn from an identical distribution , and the state of a network is updated simultaneously in discrete time steps without thermal noise .",
    "thus , every initial configuration must evolve into an attractor , which is either a fixed point or a limit cycle .",
    "because a fixed point is a limit cycle of length @xmath0 , the whole state space is divided into separated basins of attractions with heterogenous cycle lengths .",
    "extensive numerical simulations were carried out to analyze the typical cycle length and the number of cycles  @xcite .",
    "the typical length of the cycles was observed to grow exponentially with the number of neurons @xmath1 ( such kinds of cycles are called chaotic attractors ) , and the total number of attractors increases linearly with @xmath1 .",
    "these quantities were also analytically evaluated based on an empirical assumption that the dynamics loses memory of its non - immediate past  @xcite .    in this work , we develop a dynamic mean - field theory to characterize the attractors of the asymmetric neural network by extending the state concentration concept  @xcite , recently introduced to characterize the robustness and quickness of network s transient dynamics .",
    "our analysis estimates the ( cumulative ) distribution for the cycle length of attractors , the total number of attractors , and the volume of attractors in the state space .",
    "we remark that our work has three - fold contributions for understanding the statistical properties of the dynamics of randomly connected neural networks .",
    "first , a theoretical support for the markovian property of state concentration dynamics ( termed the annealed approximation in ref .",
    "@xcite ) is provided by computing the finite - size effect of the mean - field theory by explicitly evaluating the quenched randomness of network connections .",
    "second , we provide a detailed picture about how state concentration happens in randomly connected neural networks",
    ". in particular , we quantify what is the characteristic distance that typically leads to state concentration and evaluate characteristic time scales underlying the state concentration dynamics .",
    "finally , our theory gives a good consistency with numerical simulations on the distribution of the cycle length , the typical cycle length , the number of cycles , and the total number of states belonging to all attractive cycles .",
    "these three contributions complement the previous studies  @xcite and provide deep insights towards the dynamics of randomly - connected neural networks .",
    "the paper is organized as follows . in sec .",
    "[ model ] , we define the neural network model and its dynamics . mean - field analysis is presented in detail in sec .  [ theory ] .",
    "results on the state concentration and statistical properties of attractors are discussed in sec .",
    "[ stcon ] and sec .",
    "[ att ] , respectively .",
    "we summarize our results in sec .",
    "we consider randomly connected neural networks consisting of @xmath1 neurons ( units ) .",
    "each unit interacts with all the other units with an asymmetric coupling .",
    "we use @xmath2 to represent the coupling strength from unit @xmath3 to @xmath4 , and @xmath2 is independent of @xmath5 ( and others ) , and they follow the same gaussian distribution with zero mean and variance @xmath6 .",
    "the state of neuron @xmath7 at time @xmath8 is set according to the parallel deterministic dynamics in discrete time steps by its input @xmath9 as @xmath10 where the input is defined by @xmath11 therefore , by combining eqs .",
    "( [ phi0 ] ) and ( [ paradyn ] ) , the dynamics are summarized by @xmath12 in terms of the activity , or equivalently by @xmath13 in terms of the input .",
    "we later compare the dynamics of randomly connected neural networks to that of random boolean networks @xcite , where each one of @xmath14 states @xmath15 is randomly mapped to another .",
    "we study the dynamical evolution of the overlap between two states along a trajectory , expecting that its distribution across different realizations of @xmath16 contains information about the structure of attractors .",
    "let us define the overlap of two states , @xmath15 and @xmath17 along the same trajectory at different times @xmath18 , by @xmath19 this overlap takes @xmath20 if two states are the same and @xmath21 if one is the sign - flip of the other .",
    "the overlap takes a discrete value for a finite size network , but can be approximated as a continuous quantity in the large network size limit .",
    "the mean - field theory provides the dynamics of this overlap parameter and its fluctuation defined over the ensemble of random @xmath16 ( see appendix  [ dynf ] ) .",
    "the stochastic dynamics of the overlap is well approximated for large @xmath1 by a markovian process @xmath22 where @xmath23 is the probability of @xmath24 .",
    "the transition probability is approximated for large but finite @xmath1 by a simple binomial distribution @xmath25^{\\frac{n(1+q)}{2}}\\left[\\frac{1-\\varphi(q')}{2}\\right]^{\\frac{n(1-q)}{2}}\\nn\\\\ & \\approx&\\exp\\left[n\\left(h(q)+\\frac{1+q}{2}\\ln\\frac{1+\\vp(q')}{2}+\\frac{1-q}{2}\\ln\\frac{1-\\vp(q')}{2}\\right)\\right],\\end{aligned}\\ ] ] where @xmath26 and @xmath27 .",
    "note that eq .",
    "( [ eq : w ] ) summarizes the probability that @xmath28 out of @xmath1 neurons take the same sign in state @xmath29 and @xmath30 , given that @xmath31 out of @xmath1 neurons take the same sign in the previous step .",
    "the binomial distribution in eq .",
    "( [ eq : w ] ) suggests that the state overlap for each neuron is approximately independent , occurring with probability @xmath32 ( see appendix  [ dynf ] for a support ) .",
    "a similar expression is obtained for random boolean networks by replacing @xmath33 with @xmath34 , simply reflecting completely random nature of state transitions .",
    "it is worth noting that , the dynamics of the overlap becomes deterministic in the limit of large @xmath1 according to the central limit theorem , which is the so called distance law  @xcite , @xmath35 . in this equation",
    ", the equality holds only at @xmath36 and @xmath37 , and otherwise @xmath38 .",
    "hence , in the limit of large @xmath1 , the overlap monotonically converges to the stable solution of @xmath36 , implying that two distinct states would never converge . on the other hand , for finite @xmath1",
    ", the overlap fluctuates with amplitude @xmath39 about the deterministic solution ( see detailed explanations in appendix  [ dynf ] ) .",
    "thus , the overlap can evolve from @xmath40 to @xmath41 in time , indicating that system s state eventually comes back to one of previously visited states in a finite network .",
    "the markovian process of eq .",
    "( [ eq : markov ] ) sequentially provides @xmath42 for @xmath43 for some positive time difference @xmath44 given an initial distribution at @xmath45 .",
    "the initial distribution is denoted by @xmath46 . since the initial state , @xmath47 ,",
    "is selected randomly and independently from @xmath16 , we can set without losing generality the initial state to be @xmath48 for all @xmath4 ( see appendix  [ init ] ) .",
    "in this case , the initial overlap of interest is expressed by @xmath49 if @xmath50 is small , @xmath51 reflects the memory of the initial state @xmath47 and is hard to evaluate exactly .",
    "however , if @xmath50 is large , the mean - field result in appendix  [ dynf ] indicates that @xmath52 follows approximately a zero - centered independent gaussian distribution with unit variance in the large network - size limit .",
    "this means that the state overlap of eq .",
    "( [ eq : ql0 ] ) approaches a distribution centered around zero with variance @xmath53 .",
    "in particular , @xmath51 tends for large @xmath50 to a binomial distribution @xmath54 , where the probability of @xmath55 is approximately @xmath56 in the large network - size limit .",
    "we confirm this property later with numerical simulations .",
    "in this section , we consider how different states concentrate in time .",
    "the markovian dynamics of eq .",
    "( [ eq : markov ] ) are completely characterized by the eigenvalues and eigenvectors of the transition probability @xmath57 @xcite .",
    "let @xmath58 and @xmath59 respectively be the @xmath60th eigenvector and eigenvalue of @xmath57 .",
    "we rank eigenvalues in a descending order , , @xmath61 ( the number of possible values for @xmath62 is @xmath63 ) .",
    "the distribution of the overlap is expressed by a weighted sum of the eigenvectors as @xmath64 where @xmath65 is a set of initial coefficients that satisfies @xmath66 .",
    "hence , as the time step increases , @xmath42 becomes progressively dominated by the components with large eigenvalues .",
    "it is easy to see that @xmath57 has two trivial eigenvectors @xmath67 and @xmath68 with degenerate eigenvalues @xmath69 . note that @xmath70 is the kronecker delta function .",
    "the third eigenvector @xmath71 is a non - trivial one and its eigenvalue @xmath72 exponentially approaches 1 with @xmath1 ( see fig .  [",
    "fig : lam ] for the numerical result ) .",
    "the fourth eigenvalue converges to @xmath73 in the limit of large @xmath1 .",
    "the half - decay time of the @xmath60-th component is described by these eigenvalues and given by @xmath74 , or equivalently , @xmath75 .",
    "there is a clear gap between the decay time of the third and fourth eigen - components .",
    "this result indicates that , for large @xmath1 , the distribution of the overlap must approach quickly a quasi - stationary state @xmath76 at around @xmath77 and stay unchanged until @xmath78 .",
    "in particular , the quasi - stationary state is characterized solely by @xmath71 except at @xmath37 .     and @xmath79 of the transition matrix @xmath57 .",
    "]    this analysis also suggests when the mean - field theory breaks down  the theory is not applicable once the third eigen - component significantly decays at around @xmath80 . that is , after an exponential time of @xmath81 , the distribution of the overlap becomes the linear combination of @xmath82 and @xmath83 , , every state becomes either the same or the sign - flip of the others .",
    "however , this never happens in a real system .",
    "in the remaining part of this section , we characterize in more detail the quasi - stationary state in large @xmath1 limit , from which we extract the structure of attractors .",
    "we first introduce an auxiliary notation @xmath84 where @xmath85 according to the normalization constraint . with this notation",
    ", we can express the dynamics of eq .",
    "( [ eq : markov ] ) by @xmath86,\\end{aligned}\\ ] ] where the laplace s method was applied in the second line assuming large @xmath1 .",
    "note that , in the above expression , the maximizer @xmath87 of the second term is a function of @xmath62 .",
    "in particular , the well - defined asymptotic solution of eq .",
    "( [ eq : dalpha ] ) , , @xmath88,\\end{aligned}\\ ] ] with finite @xmath89 self - consistently provides the quasi - stationary state .",
    "note that eq .",
    "( [ eq : alphass ] ) permits arbitrary discontinuity of @xmath89 at @xmath37 , reflecting that @xmath37 is the sink of the markovian process .",
    "however , in the following analysis , we assume continuous @xmath89 .",
    "next , we define index @xmath90 that characterizes the probability that two states @xmath91 and @xmath92 have overlap @xmath93 before converging in the next step ( @xmath94 ) . this index is expressed , using the bayes theorem , in terms of @xmath95 by @xmath96 this means that , for large @xmath1 , most of the trajectories that lead to state concentration had an overlap specified by the peak location of @xmath97 , , @xmath98 , in the previous step .    [ cols= \" < , < \" , ]     following the same spirit , one can derive the number of attractors as @xmath99 , from which a linear dependence  @xcite is confirmed ( see also fig .",
    "[ fig : entropy ] ( a ) , the linear fit gives the slope @xmath100 , compatible with the theoretical value @xmath101 ) .",
    "another interesting quantity is the number of the attractive states @xmath102 belonging to all cycles ( e.g. , a cycle of length @xmath50 has @xmath50 attractive states ) , which is expected to grow exponentially with the network size @xmath1 .",
    "this quantity is evaluated by our theory as @xmath103 , and can be quantified as the growth rate ( entropy density ) @xmath104 . in the large @xmath1 limit ,",
    "we obtain @xmath105 , which is compared with the numerical results at finite @xmath1 . as shown in fig .",
    "[ fig : entropy ] ( b ) , as @xmath1 increases , @xmath106 decreases , approaching the asymptotic limit @xmath107 .",
    "the deviation at small @xmath1 ( or at @xmath50 far from the characteristic length , see fig .  [",
    "fig : cum ] ) comes from three approximations .",
    "one is eq .",
    "( [ eq : pinit ] ) , which becomes invalid at small @xmath50 where @xmath108 also depends on @xmath50 , but eq .",
    "( [ eq : pinit ] ) becomes reasonable for large @xmath50 ( as occurs in our case where the typical cycles are long ) .",
    "the second one is eq .",
    "( [ eq : cyc_length2 ] ) .",
    "this approximation is valid in the range of @xmath50 specified by eq .",
    "( [ eq : cond ] ) .",
    "note that this condition is consistent with the numerical results shown in fig .",
    "[ fig : cum ] .",
    "the last approximation is eq .",
    "( [ eq : markov ] ) , which breaks down for small @xmath1 at which two or more time - steps memory should be considered . in the large network size limit , these approximations become exact and the dynamics can be described by a markovian process in terms of the state overlap .",
    "thus , as we focus on the structure of attractors at a relatively large but finite @xmath1 , these effects are not significant .",
    "in this work , we studied the deterministic dynamics of a randomly connected neural network and proposed a simple markovian stochastic process to describe the evolution of the overlap of two states along the dynamics trajectories .",
    "the properties of the state concentration can be studied by a mean field computation , and furthermore , the theoretical cumulative distribution of cycle length is compared with the numerical simulation results .",
    "the typical length of cycles is predicted and observed to grow exponentially with the network size .",
    "the number of attractive states on all cycles has also an exponential growth with the network size , and its typical value can also be predicted by our theory .",
    "our theory should have potential to be generalized to treat more complex situations , e.g. , couplings between neurons are correlated , where one time - step memory is not enough to describe the dynamics and strong memory effects induced by retarded self - interaction could be incorporated by introducing a back - action field ( two time - steps memory )  @xcite .",
    "the current analysis is also restricted to the parallel type of dynamics , whereas , the sequential ( asynchronous ) dynamics seems to be more natural , and our current method may apply to this type of dynamics , although the computation will become more complicated .",
    "however , the statistical properties of attractors would not change qualitatively , as expected from numerical simulations  @xcite .",
    "our work is expected to provide insights towards understanding how the neural network processes information and stores temporal sequences  @xcite , which will be left for future study .",
    "we are grateful to ugo bastolla , naoki masuda , hiroyasu ando , and shun - ichi amari for useful discussions .",
    "this work was supported by riken brain science institute and the brain mapping by integrated neurotechnologies for disease studies ( brain / minds ) by the ministry of education , culture , sports , science and technology of japan ( mext ) .",
    "we compute the dynamics of the state overlap using the dynamic functional integral ( mean - field ) method ( see @xcite for similar calculations ) . in this section",
    ", we express time indices as lower case characters , , @xmath109 , and follow the convention that summations are neglected if the same indices appear twice in an expression , , @xmath110 .",
    "let us first define the ensemble of state trajectories , @xmath111 , averaged over different networks : @xmath112_j,\\end{aligned}\\ ] ] where @xmath113 is the dirac delta function and @xmath114_j$ ] is the average over the random couplings . in the following ,",
    "we denote by @xmath115 an average with respect to @xmath116 .",
    "the joint distribution of the overlap @xmath117 is @xmath118_j \\prod_{t > s}\\delta\\left(q\\ts-\\frac{1}{n}\\sigma\\tj\\sigma\\sj\\right)\\nn\\\\    & = & \\int \\left(\\prod_{i , t}\\frac{dh\\ti d\\hh\\ti}{2\\pi}\\right ) \\left[\\exp\\left(\\ii\\hh\\ti h\\ti-\\ii\\hh\\ti j_{ij}\\sigma_{jt}\\right)\\right]_j \\prod_{t > s}\\delta\\left(q\\ts-\\frac{1}{n}\\sigma\\tj\\sigma\\sj\\right)\\nn\\\\    & = & \\int \\left(\\prod_{i , t}\\frac{dh\\ti d\\hh\\ti}{2\\pi}\\right ) \\exp\\left(\\ii\\hh\\ti h\\ti-\\frac{1}{2n}\\hh\\ti\\hh\\si\\sigma_{jt}\\sigma_{js}\\right)\\prod_{t > s}\\delta\\left(q\\ts-\\frac{1}{n}\\sigma\\tj\\sigma\\sj\\right)\\nn\\\\    & = & \\int \\left(\\prod_{i , t}\\frac{dh\\ti d\\hh\\ti}{2\\pi}\\right ) \\exp\\left(\\ii\\hh\\ti h\\ti-\\frac{1}{2}q\\ts\\hh\\ti\\hh\\si\\right)\\prod_{t > s}\\delta\\left(q\\ts-\\frac{1}{n}\\sigma\\tj\\sigma\\sj\\right)\\nn\\\\    & = & \\int \\left(\\prod_{t > s}\\frac{n d\\hq\\ts}{2\\pi}\\right)\\int \\left(\\prod_{i , t}\\frac{dh\\ti",
    "d\\hh\\ti}{2\\pi}\\right ) \\exp\\left(n\\ii\\hq\\ts q\\ts -\\ii\\hq\\ts\\sigma\\tj\\sigma\\sj + \\ii\\hh\\ti h\\ti-\\frac{1}{2}q\\ts\\hh\\ti\\hh\\si\\right)\\nn\\\\    & = & \\int \\left(\\prod_{t > s}\\frac{n",
    "d\\hq\\ts}{2\\pi}\\right ) \\exp(-n f(\\bq,\\hat\\bq)),\\nn\\end{aligned}\\ ] ] where we have defined the action @xmath119 and @xmath120 . in the derivation , we have used the fourier transformation of the delta function @xmath121 for each delta function in eq .",
    "( [ eqa : p1 ] ) , and we have taken the average over the independent gaussian variables @xmath16 of mean 0 and variance @xmath6 . for large @xmath1 , the distribution of eq .",
    "( [ eqa : p1 ] ) is well approximated by a gaussian distribution , where the peak is specified by the saddle - point equations : @xmath122 with average @xmath123 .",
    "we can easily see that @xmath124 is a solution of eq .",
    "( [ eqa : spe ] ) @xcite .",
    "hence , if @xmath124 , the average @xmath125 is an average over gaussian @xmath126 of mean @xmath127 and covariance @xmath128 , which simplifies the saddle - point equation of eq .",
    "( [ eqa : spe ] ) in terms of a closed - form expression of @xmath129 by @xmath130 with @xmath131 and a gaussian measure @xmath132 .",
    "note that @xmath133 and the equality holds only at @xmath36 and @xmath37 . hence ,",
    "unless @xmath41 initially , the overlap rapidly converges in a few steps to zero in the @xmath134 limit .",
    "the order parameters fluctuate around the saddle - point solution of eq .",
    "( [ eqa : spe_q ] ) for finite @xmath1 .",
    "this fluctuation of @xmath129 and @xmath135 is characterized to the leading order by the hessian matrix of @xmath136 , , @xmath137 for @xmath18 and @xmath138 , where the hessian matrix is evaluated at the saddle - point solution of the order parameters , , @xmath124 and the solution of eq .",
    "( [ eqa : spe_q ] ) .    in the current setup , the hessian matrix is simply given by @xmath139 for @xmath140 and @xmath141 , where @xmath142 .",
    "note that the @xmath143 contribution in @xmath144 can be more explicitly estimated , for example by applying plackett s approximation  @xcite . here",
    ", we would like to evaluate the ( @xmath1 multiplied ) covariance of the overlap parameter , @xmath145 $ ] . by applying the matrix inversion lemma",
    ", we find that its inverse is @xmath146 this relation indicates that for small @xmath129 the linear combination , @xmath147 of the fluctuation of the overlap parameter , @xmath148 , is white gaussian random variables .",
    "to see this , one can apply the transformation of variables and find that @xmath149 thus , eq .  ( [ eqa : eta ] ) indicates that the finite - size fluctuations of the order parameter are described by @xmath150\\delta q_{t's'}\\nn\\\\ & = & \\delta q_{ts}-\\vp'(q_{t-1,s-1})\\delta q_{t-1,s-1}.\\end{aligned}\\ ] ] altogether , summarizing that @xmath151 in the @xmath134 limit and that the finite - size correction is described by eq .",
    "( [ eqa : dq0 ] ) , we obtained , for finite @xmath1 , @xmath152 which is a simple markovian process that involves white gaussian noise of variance @xmath6 .",
    "recalling the definition of the overlap parameter , @xmath153 , and that @xmath154 with different @xmath4 tend to become independent in the @xmath134 limit , we know that the overlap parameter must be distributed approximately according to a binomial distribution . extrapolating this observation , the result of eq .",
    "( [ eqa : dq ] ) is consistent with the markovian dynamics of @xmath155 with the binomial transition probability @xmath156 where @xmath157 indicates the number of units taking the same state at time @xmath158 and @xmath159 .    in summary",
    ", this result shows that the markovian dynamics of eq .",
    "( [ eqa : markov ] ) provides a good approximation of the dynamics of the overlap parameter once @xmath143 terms become negligible near the stationary state .",
    "a specific choice of the initial state @xmath47 is not important to study dynamics of the state overlap for random ensemble of networks as long as @xmath47 is selected independently of the network connections @xmath16 . without losing generality",
    ", we can set @xmath48 for all @xmath4 .    to see this point",
    ", we consider a simple transformation of variables , @xmath161 the state overlap is also described in terms of these transformed variables by @xmath162 and the initial state is given by @xmath163 for all @xmath4 .",
    "these transformed variables follow the same update rule as the original one , @xmath164 except that the coupling matrix is given by @xmath165 instead of @xmath2 .",
    "notably , the distribution of @xmath166 is the same as that of @xmath16 as long as @xmath47 is chosen independently of @xmath16 .",
    "therefore , to study the dynamics of the state overlap , we can alternatively study the dynamics of these transformed variables with the initial condition @xmath167 .",
    "the dynamics of the state overlap in random boolean networks is described by eq .",
    "( [ eq : dalpha ] ) with @xmath168 , which is simply @xmath169 where @xmath170 .",
    "let us assume that there is no perfect overlap of states initially , , @xmath171 .",
    "this means that @xmath172 and @xmath173 , because the initial overlap distribution @xmath174 must be normalized .",
    "thus , the dynamics of eq .",
    "( [ eqa : dalpha_bn ] ) converges in one step to a stationary solution @xmath175 moreover , we have from eq .  ( [ eq : beta ] ) @xmath176 this indicates that states mainly concentrate from @xmath36 if they do not already concentrate .",
    "this analysis also provides important information about the eigenvalues of the transition matrix @xmath57 at the large network size limit .",
    "the first eigenvalue is trivial , @xmath177 , with the eigenfunction @xmath67 , indicating that states never separate once they concentrate .",
    "the second eigenvalue , @xmath178 , is a non - trivial one that corresponds to the quasi - stationary state with the eigenfunction @xmath179 , where @xmath180 is given by eq .",
    "( [ eqa : dalpha_sol_bn ] ) .",
    "the other eigenvalues @xmath181 for @xmath182 are all zero because the distribution of the overlap converges in a single step to the quasi - stationary state .",
    "furthermore , the fact that state concentration happens with probability @xmath56 at each time step suggests that @xmath183 .",
    "the total number of states is @xmath184 .",
    "they form a state set called @xmath185 .",
    "we also denote a path set @xmath186 recording the states on a dynamics trajectory .",
    "only the state index is stored in both sets .",
    ": :    choose the first state @xmath187 in    @xmath185 as a starting point for the parallel    dynamics , and remove this state from @xmath185 at the    same time .",
    ": :    @xmath187 evolves to    @xmath188 by one step of the parallel    dynamics ( all neurons states are updated for one time ) .",
    "+    step 2.1 . ; ;      if @xmath189 , remove it from      @xmath185 , put the index of      @xmath188 into @xmath190 ,      and continue to perform the parallel dynamics , i.e. , let      @xmath191 , then go      to * step 2 * ;    step 2.2 ; ;      otherwise , compare @xmath188 with the one      in the set @xmath190 and if they coincide with each      other , a new cycle is identified and the length is recorded at the      same time , then go to * step 3 * ; otherwise , no new cycle is found and      go to * step 3*. step 3 .",
    ": :    go to * step 1 * until the set @xmath185 becomes empty ."
  ],
  "abstract_text": [
    "<S> the deterministic dynamics of randomly connected neural networks are studied , where a state of binary neurons evolves according to a discrete - time synchronous update rule . </S>",
    "<S> we give a theoretical support that the overlap of systems states between the current and a previous time develops in time according to a markovian stochastic process in large networks . </S>",
    "<S> this markovian process predicts how often a network revisits one of previously visited states , depending on the system size . the state concentration probability , , the probability that two distinct states co - evolve to the same state , is utilized to analytically derive various characteristics that quantify attractors structure . </S>",
    "<S> the analytical predictions about the total number of attractors , the typical cycle length , and the number of states belonging to all attractive cycles match well with numerical simulations for relatively large system sizes . </S>"
  ]
}