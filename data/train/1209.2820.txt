{
  "article_text": [
    "cited paper in the history of information theory @xcite , shannon in 1948 proved that with adequate coding , reliable communication is possible over a noisy channel , as long as the rate does not exceed a certain threshold , called the _ channel capacity . _",
    "he provided a mathematical expression for the channel capacity of any point - to - point channel , based on its statistical properties .",
    "the expression is given as the supremum over all possible input distributions of a quantity later called the _ mutual information _ @xcite .",
    "the channel capacity is often studied as a function of a cost , such as the transmit power .",
    "more specifically , the capacity  cost function is defined as the supremum of the mutual information over all input distributions whose cost is either _ equal _ to a given constant or _",
    "upperbounded _ by a constant  the convention differs between disciplines .",
    "we will return to the distinction between the two definitions at the end of this section .    for the _ additive white gaussian noise _ ( awgn ) channel ,",
    "the channel capacity is known exactly ( * ? ? ?",
    "24 ) , ( * ? ? ?",
    ".  9 ) . in recent years , the problem of calculating or estimating the channel capacity of more complicated channels has received a lot of attention ( see surveys in @xcite ) . due to the absence of exact analytical solutions and the computational intractability of optimizing over all possible input distributions , most investigations of the channel capacity of non - awgn channels rely on bounding techniques and asymptotic analysis .",
    "the main motivation for this paper comes from the type of nonlinear distortion encountered in fiber - optical communications .",
    "in contrast to linear channels , an optical fiber has the peculiar property that communications becomes virtually impossible if the signal amplitude is too high @xcite , ( * ? ? ?",
    "* ch .  9 ) .",
    "this phenomenon is well - known from experiments and simulations , and can also be explained theoretically .",
    "the lightwave propagation in an optical fiber is governed by a nonlinear differential equation , the _ nonlinear schrdinger equation _ or , if polarization effects are considered , the _ manakov equation _",
    "@xcite , ( * ? ? ?",
    "these equations include a nonlinear distortion term , whose amplitude is proportional to the cubed signal amplitude . at high enough signal amplitudes ,",
    "this nonlinear distortion dominates the other terms in the differential equation , effectively drowning the signal .",
    "similarly , one might expect that the nonlinear distortion would force the mutual information and channel capacity down to zero at sufficiently high power , and in the past two decades , many results have been published in optical communications to support this conjecture @xcite . already in 1993 ,",
    "splett _ et al .",
    "_ modeled the interference from four - wave mixing in a wavelength - division multiplexing ( wdm ) system as an awgn component , under some conditions on the noise and dispersion , in what might have been the first study ever of the channel capacity of a nonlinear optical link @xcite .",
    "the variance of this awgn depends nonlinearly on the transmit power , which is assumed equal on all wavelengths .",
    "similar nonlinear channel models have been rediscovered , modified , and further analyzed in @xcite . due to the signal - dependent noise ,",
    "their channel capacities are not monotonic : as the transmit power ( or signal - to - noise ratio ) increases , the channel capacity increases towards a peak and then decreases again as the power is further increased .",
    "other channel models with signal - dependent awgn were presented in @xcite and have similar nonmonotonic channel capacities .",
    "an essential assumption , explicit or implicit , in the derivation of these awgn - based models is that the transmitted signal consists of independent , identically distributed symbols .",
    "this assumption is valid in uncoded transmission systems , but not in the presence of error - correction coding , since coding introduces correlation between symbols . using a model derived under certain conditions on the transmitted signal is particularly risky in channel capacity calculations , since the channel capacity is by definition the maximum achievable rate using _ any _ transmission scheme  including those for which the constrained model is not valid .    a continuous - time channel model for cross - phase modulation ( xpm ) was presented by mitra and stark @xcite .",
    "although no discrete - time xpm model was obtained , they showed that the channel capacity of the xpm channel model is lowerbounded by the capacity of a signal - dependent awgn channel , and that this lower bound is nonmonotonic .",
    "they further conjectured that the true channel capacity would have a similar nonmonotonic behavior as its lower bound .",
    "many variants of the mitra ",
    "stark lower bound have been presented in recent years , often along with the conjecture that the true channel capacity is also nonmonotonic @xcite .",
    "this conjecture was disproved in the zero - dispersion case by turitsyn _",
    "@xcite , who showed that the lower bound based on the awgn channel @xcite is very far from the true channel capacity , and that the channel capacity in fact grows logarithmically with power under certain conditions .",
    "another type of lower bound on channel capacity is obtained by fixing the input distribution and calculating the mutual information @xcite or by optimizing the mutual information over a subset of all possible input distributions @xcite .",
    "all these lower bounds consistently show a nonmonotonic behavior , decreasing towards zero after a peak at a finite power , and the conjecture that the channel capacity would have a similar nonmonotonic behavior as its lower bounds is often repeated .",
    "we believe that the results cited above , while mathematically correct , do not fully exploit the potential of capacity - achieving coding over nonlinear optical channels . whereas previous studies have shown that for many cost - dependent channel models , the channel capacity is a nonmonotonic function of transmit power , we prove in this work mathematically that for any cost - independent channel model , the capacity is monotonic ( nondecreasing but not necessarily strictly increasing ) .",
    "thus , these two classes of models behave entirely differently in the nonlinear regime .",
    "the results are also extended to a wide class of cost functions and to three specific multiuser scenarios .",
    "the presented theory holds regardless of whether the capacity  cost function is defined by maximizing over all input distributions with exactly the given cost or with an upperbounded cost .",
    "the proofs are developed assuming the former definition , and they are all trivial for the latter .",
    "an interesting consequence of the nondecreasing channel capacity is that the two definitions of the capacity  cost function are fully equivalent .",
    "let @xmath0 and @xmath1 be real , @xmath2-dimensional vectors , representing the input and output , resp .",
    ", of a discrete - time memoryless communication channel",
    ". their respective domains , or alphabets , are denoted by @xmath3 and @xmath4 .",
    "the joint distribution @xmath5 for @xmath6 and @xmath7 can be factorized as @xmath8 , where @xmath9 represents the input distribution ( which is in practice determined by the modulation format ) and @xmath10 represents the channel .",
    "we denote the _ mutual information _ between @xmath0 and @xmath1 with @xmath11 , while @xmath12 denotes a _ conditional mutual information . _",
    "the _ entropy _ and _ conditional entropy _ are denoted by @xmath13 and @xmath14 , resp . , and the _ differential entropy _ and _ conditional differential entropy _ are denoted by @xmath15 and @xmath16 , resp .    using error - correction coding , codewords of input symbols @xmath17",
    "are selected from a codebook .",
    "the _ rate _ of transmission , in bits per second , is the logarithm of the codebook size divided by the codeword length .",
    "the codewords can be transmitted with arbitrarily small error probability if the codewords are sufficiently long and the rate is sufficiently small .",
    "such a rate is called an _ achievable rate , _ and the supremum of all achievable rates , over all possible codes and block lengths , is defined as the _ operational channel capacity .",
    "_    shannon s channel coding theorem ( * ? ? ?",
    "* sec .  13 , 23 ) ,",
    "7.7 , 9.1 ) states that the operational channel capacity is equal to the _ information channel capacity _ , which is defined as the supremum of the mutual information @xmath11 between the channel input and output , where the supremum is taken over all input distributions @xmath9 .",
    "the capacity - achieving distribution may be continuous or discrete @xcite    in this work , the channel capacity is characterized as a function of some kind of cost . closely following the definitions in [ 45 ] , [ 46 , ch .",
    "2 ] , we define the _ cost function _ @xmath18 as a deterministic , real , nonnegative function of an input symbol @xmath17 .",
    "the _ codeword cost _ is defined as the sum of the cost function of all symbols in the codeword divided by the codeword length . the most common cost function , and the only one that will be exemplified in this paper , is the transmit power , which is obtained by setting @xmath19 .",
    "the _ capacity  cost function _ can be defined in two , subtly different , ways , depending on whether the cost of every codeword is _ upperbounded _ by a cost @xmath20 or _ exactly _ @xmath20 .",
    "the channel coding theorem extends straightforwardly to both these cases . in the first case , which is most common in classical information theory ,",
    "the maximum achievable rate using a codebook in which all codewords have _ at most _ a given cost @xmath20 is ( * ? ? ?",
    "9 ) , ( * ? ? ?",
    "7.3 ) , ( * ? ? ?",
    "3.3 ) @xmath21 where @xmath22 is the set of all distributions @xmath9 over @xmath23 such that @xmath24 \\le \\beta$ ] .",
    "analogously , the maximum achievable rate using a codebook in which all codewords have _ exactly _ the same cost @xmath20 can be shown to be @xmath25 where @xmath26 is the set of all distributions @xmath9 over @xmath23 such that @xmath24 = \\beta$ ] .",
    "this case is prevalent in optical information theory @xcite , ( * ? ? ?",
    "* eq .  ( 11.5 ) ) and also sometimes considered in wireless communications @xcite .",
    "the second definition of the capacity  cost function is considered in this paper , i.e. , every codeword has the same cost .",
    "this is partly because the work was inspired by capacity results in optical communications , where this is the conventional definition , and partly because the fundamental question considered in this paper , about the monotonic behavior of channel capacity , is trivial in terms of @xmath27 @xcite , ( * ? ? ?",
    "* ch .  2 ) .",
    "that @xmath27 is nondecreasing for all channels follows from and the fact that @xmath28 for all @xmath29 .",
    "however , the two definitions are in fact equivalent for point - to - point channels , as a consequence of corollary  [ cor : equivalent ] in the next section .",
    "in this section , we are concerned with a discrete - time , memoryless vector channel between a single transmitter and a single receiver , formally defined as follows .",
    "[ def : ptp ] a _ point - to - point channel _ is a memoryless relationship @xmath10 between vectors @xmath30 and @xmath31 , which is independent of the codeword cost .. ]    such a relationship can represent a continuous - time bandlimited channel by sampling the transmitted and received waveforms at the nyquist rate ( * ? ? ?",
    "23 ) , and it can represent channels with an arbitrarily long ( finite ) memory by choosing the dimension @xmath2 much larger than the channel memory ( * ? ? ?",
    "4.6 ) , @xcite .",
    "the dimensions may also , in addition to time , represent frequency ( wavelength ) , space , polarization , lightwave modes , or all of these .",
    "hence , the theory applies to a wide variety of channels in different applications .    the capacity is commonly studied as a function of the transmit power , which is obtained by setting @xmath32 for all @xmath33 .",
    "the results in this paper hold not only for transmit power but also more generally for any unbounded cost function , according to the following definition .",
    "an _ unbounded cost function _",
    "@xmath18 over a domain @xmath23 is a real , nonnegative function such that for any given @xmath34 , there exists a vector @xmath17 for which @xmath35 .",
    "the main result for point - to - point channels is the following theorem , which implies that the channel capacity will either increase indefinitely or converge to a finite value as the cost increases , depending on the channel .",
    "however , it can not have a peak for any channel or any cost . despite its simple nature",
    ", it has to our knowledge not been stated before .",
    "[ th : main ] let @xmath36 be a point - to - point channel defined on @xmath17 and @xmath7 .",
    "let @xmath18 be an unbounded cost function on @xmath23 .",
    "then @xmath37 is a nondecreasing function of @xmath20 .",
    "we will show that for any given pair of costs @xmath38 , @xmath39 .",
    "let , for any @xmath40 , @xmath41 we define a time - sharing random symbol @xmath42 given an auxiliary binary random variable @xmath43 such that @xmath44 where @xmath45 and the distributions of @xmath46 and @xmath47 satisfy @xmath48 = \\beta'$ ] and @xmath49 = \\beta''$ ] , resp .",
    "such distributions exist , by assumption , for any costs @xmath50 .",
    "thus @xmath51 & = ( 1-\\epsilon){\\mathbb{e}}[b({{\\boldsymbol{x}}}')]+\\epsilon { \\mathbb{e}}[b({{\\boldsymbol{x } } } '' ) ] \\notag\\\\    & = ( 1-\\epsilon)\\beta ' + \\epsilon \\beta '' \\notag\\\\    & = \\beta    .",
    "\\end{aligned}\\ ] ]    because @xmath52 is a markov chain , the mutual information can be bounded as @xmath53 where the first inequality follows from ( * ? ? ?",
    "* eq .  ( 2.122 ) ) and @xmath54 is defined as the channel output when the input is @xmath55 .",
    "this inequality holds for any @xmath40 and any distributions @xmath56 and @xmath57 .",
    "choosing @xmath58 as a capacity - achieving distribution at cost @xmath59 , the right - hand side of becomes @xmath60 .",
    "thus , @xmath61 if now @xmath62 , then would yield a contradiction in the range @xmath63 .",
    "hence , @xmath39 .",
    "intuitively , an input distribution with a nondecreasing mutual information for a given channel can be constructed by combining two parts , a high - probability part at a moderate cost , which does not vary much as the overall average cost is changed , and a low - probability part , a `` satellite , '' which absorbs the whole increase in average cost by moving away from the other part @xcite . as @xmath64 ,",
    "the input distribution @xmath65 becomes more and more like @xmath58 , while the cost remains at @xmath20 because the lower cost @xmath66 is balanced by another cost @xmath67 .",
    "the theorem can also be proved in terms of the operational capacity , as outlined in the following .",
    "consider , for a given channel , a capacity - achieving code at cost @xmath59 .",
    "from , all codewords have the same cost @xmath59 .",
    "we construct a new code by appending a single symbol to each codeword , such that the new codewords have cost @xmath68 .",
    "this last symbol can be ignored by the receiver and does not influence the error probability .",
    "if the codeword length is large enough , the rate loss from the extra symbol is negligible .",
    "this shows that @xmath69 is an achievable rate at cost @xmath20 , and thus , @xmath70 .    by writing the channel capacity as @xmath71 , which by theorem [ th :",
    "main ] is equal to @xmath37 , the following corollary is obtained .",
    "[ cor : equivalent ] under the conditions of theorem  [ th : main ] , @xmath72 for all @xmath73 .",
    "this means that the two definitions and are equivalent : the cost - limited channel capacity @xmath27 is achieved by an input distribution @xmath9 for which the cost equals the maximum allowed value @xmath20 .",
    "a practical interpretation is that when designing a capacity - achieving code for a nonlinear channel , it suffices to consider only codes for which all codewords have the same cost @xmath20 .    as stated in definition",
    "[ def : ptp ] , the channel distribution @xmath10 considered in theorem  [ th : main ] does not change with the cost @xmath20 .",
    "in other words , the channel remains the same regardless of which codebook is used .",
    "this is a standard assumption in information theory ( * ? ? ?",
    "4.2 ) , and it is not considered to restrict generality . on the other hand , this assumption has often been relaxed in optical communications .",
    "the information capacity of a cost - dependent channel model may decrease to zero at sufficiently high cost ( power ) @xcite , thus contradicting theorem  [ th : main ] .",
    "we believe that cost - dependent channel models should be avoided in this context , because information - theoretic tools are lacking to handle and interpret them .",
    "it is not even clear whether the optimization problem @xmath74 has any operational meaning in terms of maximum achievable rates for point - to - point channels .",
    "shannon s channel coding theorem , in its standard memoryless form , assumes that the channel operates on each symbol @xmath0 independently , which is not the case if @xmath10 depends on @xmath20 .",
    "furthermore , such models are questionable from a physical viewpoint , as they imply an infinite channel memory @xcite .",
    "we consider a discrete - time , memoryless interference channel with @xmath75 users , each with the purpose of transmitting a message from a transmitter to a receiver ( * ? ? ?",
    "6 ) , for example an optical wdm system .",
    "the input and output are denoted by @xmath76 and @xmath77 , resp .",
    ", for @xmath78 .",
    "the @xmath79th receiver attempts to recover @xmath76 based on @xmath77 , without knowledge of @xmath80 for @xmath81 .",
    "the statistics of the received vectors is given by the conditional distribution @xmath82 , which does not change with the cost .",
    "independent data is transmitted by each user , and the joint input distribution @xmath83 is therefore equal to the product of the marginal distributions @xmath84 .",
    "all input distributions @xmath85 are known to all users . from the viewpoint of user @xmath79 , all interfering input symbols @xmath86 for @xmath81",
    "are assumed to be independent between channel uses .",
    "this assumption , which is conventional in optical communications , is valid if the codebook of user @xmath87 is not known to user @xmath79 or if user @xmath87 transmits uncoded data .",
    "three scenarios , or _ behavioral models _",
    "@xcite , are considered in the following subsections .",
    "two of them correspond to selfish optimization by individual users , which is presently the dominant optimization approach in optical information theory .",
    "the aim is to determine the maximum achievable rate of the primary user , referred to as user 1 , while treating the signals from the other users @xmath88 as ( nonlinear ) noise .",
    "the received vectors @xmath89 are unknown at receiver 1 and the channel can be represented by the conditional distribution @xmath90 .",
    "the third and last scenario represents joint optimization of @xmath91 , considering the full interference channel model @xmath82 .",
    "the following lemma about conditional mutual information will be useful in sec .",
    "[ sec : adaptive - dist ] .",
    "[ lem : i - diff ] for any @xmath0 and @xmath1 , and any discrete @xmath92 , @xmath93    by the chain rule for mutual information , @xmath94 eliminating @xmath95 and rearranging terms , @xmath93 since @xmath92 is discrete by assumption , the right - hand side can be upperbounded using @xmath96 which completes the proof .",
    "suppose that the distributions @xmath97 are fixed and do not change even if @xmath98 would change .",
    "from the viewpoint of the primary user , the interference caused by the other users can be included in the channel model . since the conditional distribution @xmath99 in this case depends on the distributions @xmath100 , but not on @xmath98 , theorem [ th : main ] applies and the capacity  cost function for the primary user is nondecreasing .      in this section ,",
    "we consider the scenario where all users apply the same input distribution , or linearly rescaled versions thereof .",
    "if the primary user s distribution is @xmath98 , then the other distributions are @xmath101 for some given constants @xmath102 .",
    "an important special case is @xmath103 , which makes all distributions @xmath104 identical .",
    "the primary channel is described by @xmath105\\ ! , \\end{gathered}\\ ] ] where the expectation is taken over all interferers @xmath88 .",
    "this expression changes with @xmath98 , because @xmath106 change with @xmath98 .",
    "hence , the channel is cost - dependent and theorem  [ th : main ] does not apply .",
    "it can nevertheless be proven that the channel capacity is monotonic .",
    "[ th : adaptive - distributions ] if the @xmath75 input distributions are related as in for some given constants @xmath102 , then the capacity  cost function of the primary channel is nondecreasing , for any interference channel @xmath107 .",
    "first , we verify that the channel coding theorem holds in the considered scenario . for any _ fixed _ primary user distribution @xmath98 , the interferers distributions @xmath108 are also fixed via , and the primary transmitter  receiver pair is characterized by . by the point - to - point channel coding theorem (",
    "23 ) , ( * ? ? ?",
    "* ch .  7 ) , ( * ? ? ?",
    "3 ) , the mutual information @xmath109 of this joint distribution corresponds to an achievable rate of the primary channel .",
    "hence , all rates below the primary channel capacity @xmath110 are achievable and the channel coding theorem holds .    to prove that @xmath37 is nondecreasing , let @xmath111 be a capacity - achieving distribution at some cost @xmath112 .",
    "we will show that @xmath39 for any @xmath29 .",
    "for any given @xmath113 and @xmath40 , let @xmath114 and let @xmath115 be any distribution over @xmath23 with @xmath116 = \\beta''$ ] .",
    "we now define a time - sharing random vector @xmath117 given an auxiliary binary random variable @xmath118 such that @xmath119 where @xmath120 .",
    "this vector satisfies @xmath121 & = ( 1-\\epsilon){\\mathbb{e}}[b({{\\boldsymbol{x}}}_{\\!1}')]+\\epsilon { \\mathbb{e}}[b({{\\boldsymbol{x}}}''_{\\!1 } ) ] \\notag\\\\    & = ( 1-\\epsilon)\\beta ' + \\epsilon \\beta '' \\notag\\\\    & = \\beta    .",
    "\\end{aligned}\\ ] ]    ( 75,38)(8,8 ) ( 10,40)(0,0)@xmath118 ( 10,28)(0,0)@xmath122 ( 10,21)(0,0)@xmath123 ( 10,10)(0,0)@xmath124 ( 14,40)(1,0)12 ( 14,28)(1,0)12 ( 14,10)(1,0)12 ( 30,40)(0,0)@xmath117 ( 30,28)(0,0)@xmath125 ( 30,21)(0,0)@xmath123 ( 30,10)(0,0)@xmath126 ( 34,40)(1,0)12 ( 34,28)(1,0)17 ( 51,28)(0,1)7 ( 34,10)(1,0)27 ( 61,10)(0,1)25 ( 46,35)(20,10)channel ( 66,40)(1,0)12 ( 82,40)(0,0)@xmath127    as illustrated in fig .",
    "[ fig : interference - channel ] , the interference can be generated by an analogous time - sharing method , using the auxiliary variables @xmath128 .",
    "these variables have the same distribution as @xmath118 and are independent of each other and also of @xmath118 .",
    "they control the interferers @xmath88 such that @xmath129 if @xmath130 and @xmath131 if @xmath132 , where @xmath133 for @xmath134 .",
    "obviously , the time - sharing symbol @xmath76 has the desired distribution .",
    "the mutual information of the primary channel can be bounded as @xmath135 where holds because @xmath136 is a markov chain and follows by setting @xmath137 $ ] in lemma  [ lem : i - diff ] .",
    "the first term of the right - hand side of can be bounded as @xmath138 the second term of the right - hand side of is @xmath139 where @xmath140 .",
    "combining , , , and yields @xmath141 \\notag\\\\    & = \\lim_{\\epsilon\\rightarrow 0 } \\left [ ( 1-\\epsilon)^k c(\\beta')-(k-1 ) h_2(\\epsilon ) \\right ] \\notag\\\\    & = c(\\beta ' )    , \\end{aligned}\\ ] ] which completes the proof .",
    "intuitively , the proof relies on constructing a `` satellite distribution '' @xcite for @xmath117 , where the `` satellite , '' denoted by @xmath142 in , carries a much higher cost than @xmath143 and occurs with lower probability .      in the third and last scenario",
    ", we assume that the system includes a mechanism to optimize the transmission schemes of all users jointly , for example via a central network controller . as in the previous two scenarios ,",
    "the transmitters and receivers are still _ operated _ separately , in the sense that the transmitters and receivers do not exchange information about their respective signals . and jointly decoded based on all received signals @xmath144 , then the channel is equivalent to a high - dimensional point - to - point channel and theorem  [ th : main ] applies . ]",
    "let @xmath145 be an achievable rate for the transmitter ",
    "receiver pair @xmath78 and let @xmath146 be a vector of rates that can be _ simultaneously _ achieved over the interference channel , with arbitrarily small error probability .",
    "the _ capacity region _",
    "@xmath147 , where @xmath148 , is defined as the closure of the set of all achievable rate vectors @xmath149 when every codeword used by user @xmath78 has the exact cost @xmath150 ( * ? ? ?",
    "4.1 , 6.1 ) . while no analytical expression is known for the capacity region of general interference channels (",
    "6 ) , we can still derive fundamental properties by using the time - sharing principle .",
    "[ th : joint ] let @xmath151 and @xmath152 be two cost vectors such that @xmath153 for @xmath78 .",
    "then their capacity regions satisfy @xmath154 .",
    "let , for any @xmath40 , @xmath155 let @xmath156 and @xmath157 be achievable rate vectors at costs @xmath158 and @xmath159 , resp . by time sharing ( * ? ? ?",
    "15.3.3 ) , ( * ? ?",
    "4.4 ) , the rate @xmath160 is achievable at cost @xmath161 the capacity region @xmath147 thus includes all rate vectors of the form @xmath162 , where @xmath156 is achievable at cost @xmath158 and @xmath163 is an arbitrarily small positive number . since the capacity region by definition is the _ closure _ of all achievable rate vectors ( * ? ? ?",
    "4.1 , 6.1 ) , @xmath147 also includes @xmath164 . in conclusion , @xmath165 for all @xmath166 , which implies @xmath154 .",
    "the capacity region is a @xmath75-dimensional object , and it varies as a function of the @xmath75-dimensional vector @xmath167 .",
    "the following two corollaries exemplify how linear combinations of the achievable rates change when the cost is varied linearly .",
    "[ cor : c1 ] if the cost is varied along a line as @xmath168 where all components of @xmath169 and @xmath170 are nonnegative , then all achievable rates @xmath171 are nondecreasing functions of @xmath172 , and the achievable sum rate @xmath173 is also a nondecreasing function of @xmath172 .",
    "[ cor : c2 ] if all transmitters obey the same cost constraint @xmath174 , then all achievable rates @xmath171 are nondecreasing functions of @xmath20 .",
    "in this section , examples are given for mutual information and channel capacity as functions of the transmit power , for a simple nonlinear channel .",
    "the studied channel is chosen for its simplicity , not for its resemblance to any particular physical system , because evaluating the channel capacity is numerically possible only for very low - dimensional , memoryless channels , which unfortunately excludes more realistic channel models .",
    "we consider a very simple channel with nonlinear distortion and additive noise , represented as @xmath175 where @xmath176 and @xmath177 are the real , scalar input and output of the channel , resp .",
    ", @xmath178 is a given deterministic function and @xmath179 is white gaussian noise with zero mean and variance @xmath180 . for a given channel input @xmath181 , the channel output",
    "is represented by the conditional probability density function ( pdf ) @xmath182 where @xmath183 is the zero - mean , unit - variance gaussian pdf .",
    "since @xmath184 is gaussian for any @xmath181 , the conditional entropy is ( * ? ? ?",
    "20 ) , ( * ? ? ?",
    "8.1 ) @xmath185 for a given input distribution @xmath186 , the output distribution @xmath187 is obtained by marginalizing the joint distribution @xmath188 , and the mutual information is calculated as @xmath189 .    .",
    "the channel is essentially linear for small @xmath190 and binary for large @xmath190 . ]    in this example , we select @xmath191 in as a smooth clipping function @xmath192 where @xmath193 sets an upper bound on the output .",
    "if the instantaneous channel input @xmath176 has a sufficiently high magnitude compared with @xmath194 , the channel is essentially binary . for @xmath176 close to zero ,",
    "on the other hand , the channel approaches a linear awgn channel .",
    "the channel parameters are @xmath195 and @xmath196 throughout this section .",
    "the function @xmath191 in , which represents the nonlinear part of the channel , is shown in fig .",
    "[ fig : tanh ] .",
    "the mutual information @xmath197 is evaluated by numerical integration , as a function of the average transmit power @xmath198 $ ] .",
    "no optimization over input distributions is carried out .",
    "the input distribution @xmath199 is constructed from a given unit - power distribution @xmath200 , rescaled to the desired power @xmath201 as @xmath202 , where @xmath203 .",
    "the results are presented in fig .",
    "[ fig : ixy ] for three continuous input pdfs @xmath199 : zero - mean gaussian , zero - mean uniform , and single - sided exponential , defined as , respectively , @xmath204    [ ] [ ] @xmath205 [ ] [ ] @xmath206 [ ] [ ] @xmath207 [ ] [ ] @xmath208 [ ] [ ] @xmath209 [ ] [ ] @xmath210 [ ] [ ] @xmath211   and @xmath196 with various continuous ( solid ) and discrete ( dashed ) input distributions .",
    "the discrete distributions have uniform probabilities and equal spacing .",
    "the awgn channel capacity is included for reference ( dotted).,title=\"fig : \" ]    at asymptotically low power @xmath201 , the channel is effectively an awgn channel . in this case , the mutual information is governed by the mean value of the input distribution , according to @xcite .",
    "all zero - mean input distributions achieve approximately the same mutual information , which approaches the awgn channel capacity .",
    "the asymptotic mutual information for the exponential distribution , whose mean is @xmath212 , is half that achieved by zero - mean distributions .",
    "the mutual information curves for all three input pdfs reach a peak around @xmath213 , when a large portion of the input samples still fall in the linear regime of the channel .",
    "when the transmit power @xmath201 is further increased , the mutual information decreases towards a value slightly less than 1 asymptotically for the zero - mean input pdfs and 0 for the exponential input .",
    "the asymptotes are explained by the fact that at high enough power , almost all input samples fall in the nonlinear regime , where the channel behaves as a 1-bit noisy quantizer .",
    "similar results for various discrete input distributions are also included in fig .",
    "[ fig : ixy ] .",
    "the studied one - dimensional constellations are on  off keying ( ook ) , binary phase - shift keying ( bpsk ) , and @xmath214-ary pulse amplitude modulation ( @xmath214-pam ) .",
    "the constellation points are equally spaced and the input samples @xmath176 are chosen uniformly from these constellations .",
    "the mutual information for @xmath214-pam constellations with @xmath215 exhibits the same kind of peak as the continuous distributions in fig .",
    "[ fig : ixy ] ; indeed , a uniform distribution over equally spaced @xmath214-pam approaches the continuous uniform distribution as @xmath216 .",
    "similarly to the continuous case , the mutual information for zero - mean discrete input distributions approach the awgn channel capacity as @xmath217 .",
    "half this channel capacity is achieved by the ook input , which has the same mean value @xmath212 as the exponential input above .",
    "the asymptotics when @xmath218 depends on whether @xmath214 is even or odd . for any even @xmath214 ,",
    "the channel again acts like a 1-bit quantizer and the asymptotic mutual information is slightly less than 1 . for odd @xmath214 , however , here exemplified by @xmath219-pam ,",
    "there is a nonzero probability mass at @xmath220 , which means that the possible outputs are not only @xmath221 but also @xmath222 .",
    "hence , the channel asymptotically approaches a ternary - output noisy channel , whose mutual information is upperbounded by @xmath223 .    to summarize , this particular channel has the property that the mutual information for any input distribution approaches a limit as @xmath218 , and this limit is upperbounded by @xmath224 .",
    "it might seem tempting to conclude that the channel capacity , which is the supremum of all mutual information curves , would behave similarly .",
    "however , as we shall see in the next section , this conclusion is not correct , because the limit of a supremum is in general not equal to the supremum of a limit . specifically , the asymptotical channel capacity is @xmath225 , which is not equal to @xmath226 .",
    "the standard method to calculate the channel capacity of a discrete memoryless channel is by the _ arimoto  blahut algorithm _",
    "@xcite , ( * ? ? ?",
    "10.8 ) , ( * ? ? ?",
    "* ch .  9 ) .",
    "it has been extended to continuous - input , continuous - output channels in @xcite and furthermore to cost - constrained inputs in @xcite .",
    "the idea in @xcite is to represent distributions by lists of samples , so - called _ particles . _",
    "a particle - based input distribution has the form @xmath227 where @xmath228 is the dirac delta function , @xmath229 is the number of particles , @xmath230 are the particles , and @xmath231 are the probabilities , or weights , associated with each particle . if @xmath229 is large enough , any distribution can be represented in the form with arbitrarily small error . with this representation ,",
    "@xmath232 which yields @xmath233 , and thereby @xmath197 , by numerical integration",
    ".    since @xmath234 is constant , the capacity is obtained by maximizing @xmath233 subject to constraints on the total probability and power .",
    "this problem is in general nonconvex . in @xcite ,",
    "the optimization is done by _ alternating optimization _",
    "9.1 ) , first finding @xmath235 for a given @xmath236 using the arimoto  blahut algorithm and then finding @xmath236 for a given @xmath235 using a gradient search , and so on . here",
    ", we apply gradient search techniques for both steps .",
    "the objective is to maximize the lagrangian function @xmath237 where the lagrange multipliers @xmath238 and @xmath239 are determined to maintain the constraints @xmath240 and @xmath241 during the optimization process .",
    "the gradients of @xmath242 with respect to @xmath236 and @xmath235 are calculated , and a steepest descent algorithm ( or more accurately , `` steepest ascent '' ) is applied to maximize @xmath242 . in each iteration",
    ", a step is taken in the direction of either of the two gradients .",
    ", the numerical values of @xmath236 and @xmath235 are not of the same order of magnitude . ]",
    "the step size is determined using the _ _ golden section method _ _ ( * ? ? ?",
    "several initial values @xmath243 were tried , and @xmath229 was increased until convergence . in all cases , @xmath244 turned out to be a sufficient number of particles .    the topography of @xmath242 as a function of @xmath236 and @xmath235 turned out to include vast flat fields , where a small step has little influence on @xmath242 .",
    "this made the optimization numerically challenging .",
    "no suboptimal local maxima were found for the studied channel and constraints , although for nonlinear channels in general , the mutual information as a function of the input distribution may have multiple maxima .",
    "are fixed and the only constraint is @xmath245 . in this special case ,",
    "the mutual information is a concave function of @xmath235 for any channel ( * ? ? ?",
    "* sec .  2.7 , 7.3 ) and there is thus a unique maximum .",
    "]    [ ] [ ] @xmath205 [ ] [ ] @xmath206 [ ] [ ] @xmath207 [ ] [ ] @xmath208 [ ] [ ] @xmath209 [ ] [ ] @xmath210 [ ] [ ] @xmath211   ( thin solid ) and the awgn channel capacity ( dotted )",
    ". even though most mutual information curves decrease , the channel capacity does not , thus supporting theorem  [ th : main ] .",
    "the three markers refer to distributions in fig .",
    "[ fig : pmfs].,title=\"fig : \" ]        this channel capacity , numerically obtained by the above method , is shown in fig .",
    "[ fig : channelcap ] for the studied channel ( thick solid curve ) . as promised by the law of monotonic channel capacity ( theorem [ th : main ] ) , the curve differs from most mutual information curves by not having a peak at any @xmath201 .",
    "the channel capacity follows the mutual information of the gaussian distribution closely until around @xmath213 .",
    "however , while the gaussian case attains its maximum mutual information @xmath246 bits / symbol at @xmath247 and then begins to decrease , the channel capacity continues to increase towards its asymptote @xmath248 bits / symbol .",
    "the fact that the capacity curve rises somewhat over the peak and not only flattens out is encouraging for future work on capacity - achieving coding for more realistic nonlinear channel .",
    "this asymptotical channel capacity can be explained as follows .",
    "define the random variable @xmath249 .",
    "since @xmath178 is a continuous , strictly increasing function , there is a one - to - one mapping between @xmath250 and @xmath251 .",
    "thus @xmath252 , where @xmath253 .",
    "this represents a standard discrete - time awgn channel whose input @xmath254 is subject to a peak power constraint .",
    "the capacity of a peak - power - constrained awgn channel was bounded already in ( * ? ? ?",
    "25 ) and computed numerically in @xcite , where it was also shown that the capacity - achieving distribution is discrete .",
    "the asymptote in fig .",
    "[ fig : channelcap ] , which is @xmath255 bits / symbol or , equivalently , @xmath256 nats / symbol , agrees perfectly with the amplitude - constrained capacity in ( * ? ? ?",
    "2 ) for @xmath257 .",
    "some almost capacity - achieving input distributions are shown in fig .",
    "[ fig : pmfs ] , numerically optimized as described above . for @xmath258 ,",
    "the optimized discrete input distribution is essentially a nonuniformly sampled gaussian pdf , and the obtained channel capacity , 1.61 , has the same value as the mutual information of a continuous gaussian pdf , shown in fig .",
    "[ fig : ixy ] . for @xmath213 and @xmath209 ,",
    "the distribution is more uniform in the range where the channel behaves more or less linearly , which for this channel is approximately at @xmath259 , with some high - power outliers in the nonlinear range @xmath260 . in all cases ,",
    "increasing the number of particles @xmath229 from what is shown in fig .",
    "[ fig : pmfs ] does not increase the mutual information significantly , from which we infer that these discrete input distributions perform practically as well as the best discrete or continuous input distributions for this channel .",
    "although the capacity - achieving distributions would look quite different for other types of nonlinear channels , a general observation can be made from fig .",
    "[ fig : pmfs ] : even at high average power , the input should consist of samples with moderate power , for which the channel is good , most of the time . the high average power is achieved by a single particle having a very large power ; thus , the capacity - achieving distribution is a satellite distribution @xcite .",
    "this single particle , or satellite , corresponds to @xmath261 and @xmath142 in the proofs of theorems [ th : main ] and [ th : adaptive - distributions ] , resp . , which",
    "as @xmath64 have high cost ( power ) and low probability .",
    "it was proved that the channel capacity is a nondecreasing function of a cost ( such as transmit power ) in the following cases .    * point - to - point memoryless vector channels @xmath10 that do not change with the input distribution @xmath65 .",
    "* interference channels where all users , except the one of interest , transmit data from fixed input distributions .",
    "* interference channels where all users transmit data from the same ( optimized ) distribution .",
    "* interference channels where the distributions of all users are optimized jointly .",
    "the mutual information may be decreasing with cost in all these cases , but not the channel capacity in shannon s sense .",
    "in contrast , there are numerous examples in the literature where the channel capacity has a peak at a certain cost , after which it decreases towards zero@xcite .",
    "these examples all pertain to one of the following cases :    * point - to - point channels that change depending on the transmitter settings , typically as a function of the transmit power @xcite .",
    "* interference channels where the transmission scheme of one user ( the one of interest ) is optimized while the other users satisfy the same power constraint by pure amplification @xcite .",
    "a practical interpretation is that when designing codes for nonlinear channels under the constraint of a maximum average power , it suffices to consider codes in which all codewords satisfy the power constraint with equality .",
    "this is in contrast to previous works in optical communications , which often assumed the existence of an optimal ( finite ) power .",
    "further research is needed to show whether the new approach is just a way to achieve the same rates as before at a higher power , or if it may lead to significantly increased achievable rates .",
    "the author is indebted to a.  alvarado , p.  bayvel , l.  beygi , g.  durisi , t.  eriksson , r .- j .",
    "essiambre , c.  hger , m.  karlsson , j.  karout , g.  kramer , f.  r. kschischang , and e.  telatar for helpful discussions , criticism , and comments on early versions of this manuscript .",
    "the presentation was greatly improved thanks to detailed feedback from the four insightful reviewers .",
    "m.  katz and s.  shamai ( shitz ) , `` on the capacity - achieving distribution of the discrete - time noncoherent and partially coherent awgn channels , '' _ ieee trans .",
    "inf . theory _ ,",
    "50 , no .",
    "22572270 , oct .",
    "2004 .",
    "a.  bononi , p.  serena , n.  rossi , e.  grellier , and f.  vacondio , `` modeling nonlinearity in coherent transmissions with dominant intrachannel - four - wave - mixing , '' _ opt .",
    "_ , vol .  20 , no .  7 , pp",
    ". 77777791 , mar .",
    "a.  carena , v.  curri , g.  bosco , p.  poggiolini , and f.  forghieri , `` modeling of the impact of nonlinear propagation effects in uncompensated optical coherent transmission links , ''",
    "_ j. lightw .",
    "_ , vol .  30 , no .  10 , pp . 15241539 , may 2012 .",
    "l.  beygi , e.  agrell , p.  johannisson , m.  karlsson , and h.  wymeersch , `` a discrete - time model for uncompensated single - channel fiber - optical links , '' _ ieee trans .",
    "_ , vol .  60 , no .  11 , pp . 34403450 , nov . 2012",
    "c.  hger , a.  graell i amat , a.  alvarado , and e.  agrell , `` constellation optimization for coherent optical channels distorted by nonlinear phase noise , '' in _ proc .",
    "( globecom ) _ , anaheim , ca , dec .",
    "2012 , pp . 28702875 .",
    "j.  b. stark , p.  mitra , and a.  sengupta , `` information capacity of nonlinear wavelength division multiplexing fiber optic transmission line , '' _ opt .",
    "fiber technol .",
    "_ , vol .  7 , no .  4 , pp .",
    "275288 , oct .",
    "2001 .",
    "a.  g. green , p.  b. littlewood , p.  p. mitra , and l.  g.  l. wegener , `` schrdinger equation with a spatially and temporally random potential : effects of cross - phase modulation in optical communication , '' _ phys .",
    "66 , no .  4 , pp .",
    "046627112 , oct .",
    "2002 .",
    "l.  g.  l. wegener , m.  l. povinelli , a.  g. green , p.  p. mitra , j.  b. stark , and p.  b. littlewood , `` the effect of propagation nonlinearities on the information capacity of wdm optical fiber systems : cross - phase modulation and four - wave mixing , '' _ physica d : nonlinear phenomena _ , vol .",
    "12 , pp . 8199 , feb . 2004 .",
    "i.  b. djordjevic , b.  vasic , m.  ivkovic , and i.  gabitov , `` achievable information rates for high - speed long - haul optical transmission , '' _ j. lightw",
    ". technol .",
    "_ , vol .  23 , no .  11 , pp . 37553763 , nov .",
    "2005 .",
    "m.  h. taghavi , g.  c. papen , and p.  h. siegel , `` on the multiuser capacity of wdm in a nonlinear optical fiber : coherent communication , '' _ ieee trans .",
    "inf . theory _ , vol .",
    "52 , no .  11 , pp . 50085022 , nov .",
    "2006 .",
    "t.  freckmann , r .- j .",
    "essiambre , p.  j. winzer , g.  j. foschini , and g.  kramer , `` fiber capacity limits with optimized ring constellations , '' _ ieee photon .",
    "_ , vol .",
    "21 , no .  20 , pp .",
    "14961498 , oct .",
    "i.  b. djordjevic , h.  g. batshon , l.  xu , and t.  wang , `` coded polarization - multiplexed iterative polar modulation ( pm - ipm ) for beyond 400 gb / s serial optical transmission , '' in _ proc .",
    "fiber commun .",
    "( ofc ) _ , los angeles , ca , mar .",
    "2010 , p. omk2 .",
    "b.  goebel , r .- j .",
    "essiambre , g.  kramer , p.  j. winzer , and n.  hanik , `` calculation of mutual information for partially coherent gaussian channels with applications to fiber optics , '' _ ieee trans .",
    "inf . theory _",
    "57 , no .  9 , pp .",
    "57205736 , sept .",
    "g.  bosco , p.  poggiolini , a.  carena , v.  curri , and f.  forghieri , `` analytical results on channel capacity in uncompensated optical links with coherent detection , '' _ opt .",
    "_ , vol .  19 , no .  26 , pp .",
    "b440b449 , dec .",
    "2011 .",
    "a.  splett , c.  kurtzke , and k.  petermann , `` ultimate transmission capacity of amplified optical fiber communication systems taking into account fiber nonlinearities , '' in _ proc .",
    "opt . commun .",
    "( ecoc ) _ , montreux , switzerland , sept .",
    "1993 , pp .",
    "p.  poggiolini , a.  carena , v.  curri , g.  bosco , and f.  forghieri , `` analytical modeling of nonlinear propagation in uncompensated optical transmission links , '' _ ieee photon .",
    "_ , vol .  23 , no .  11 , pp . 742744 , june 2011",
    "a.  d. ellis and j.  zhao , `` channel capacity of non - linear transmission systems , '' in _ impact of nonlinearities on fiber optic communications _ ,",
    "s.  kumar , ed.1em plus 0.5em minus 0.4emnew york , ny : springer , 2011 , ch .  13 , pp . 507538 .",
    "k.  s. turitsyn , s.  a. derevyanko , i.  v. yurkevich , and s.  k. turitsyn , `` information capacity of optical fiber channels with zero average dispersion , '' _ phys .",
    "_ , vol .",
    "91 , no .  20 , pp .",
    "20390114 , nov .",
    "2003 .",
    "i.  b. djordjevic , `` codes on graphs , coded modulation and compensation of nonlinear impairments by turbo equalization , '' in _ impact of nonlinearities on fiber optic communications _ , s.  kumar , ed.1em plus 0.5em minus 0.4emnew york , ny : springer , 2011 , ch .",
    "451505 .",
    "m.  c. gursoy , h.  v. poor , and s.  verd , `` the noncoherent rician fading channel ",
    "part i : structure of the capacity - achieving input , '' _ ieee trans .",
    "wireless commun .",
    "_ , vol .  4 , no .  5 , pp . 21932206 , sept ."
  ],
  "abstract_text": [
    "<S> motivated by results in optical communications , where the performance can degrade dramatically if the transmit power is sufficiently increased , the channel capacity is characterized for various kinds of memoryless vector channels . </S>",
    "<S> it is proved that for all point - to - point channels , the channel capacity is a nondecreasing function of power . as a consequence , maximizing the mutual information over all input distributions with a certain power is for such channels equivalent to maximizing it over the larger set of input distributions with upperbounded power . for interference channels such as optical wavelength - division multiplexing systems , the primary channel capacity is always nondecreasing with power if all interferers transmit with identical distributions as the primary user . also , if all input distributions in an interference channel are optimized jointly , then the achievable sum - rate capacity is again nondecreasing . </S>",
    "<S> the results generalizes to the channel capacity as a function of a wide class of costs , not only power . </S>"
  ]
}