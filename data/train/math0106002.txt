{
  "article_text": [
    "markov chain monte carlo ( mcmc ) methods have become extremely popular for bayesian inference problems ( consult , e.g. ,  gelfand and smith  @xcite , smith and roberts  @xcite , tierney  @xcite , gilks et al .",
    "@xcite ) , and for problems in other areas , such as spatial statistics , statistical physics , and computer science ( see , e.g. ,  fill  @xcite or propp and wilson  @xcite for pointers to the literature ) as a way of sampling approximately from a complicated unknown probability distribution  @xmath0 . an mcmc algorithm constructs a markov chain with one - step transition kernel  @xmath1 and stationary distribution  @xmath0 ; if the chain is run long enough , then under reasonably weak conditions ( cf .",
    "tierney  @xcite ) it will converge in distribution to  @xmath0 , facilitating approximate sampling .",
    "one difficulty with these methods is that it is difficult to assess convergence to stationarity .",
    "this necessitates the use of difficult theoretical analysis ( e.g. ,  meyn and tweedie  @xcite , rosenthal  @xcite ) or problematic convergence diagnostics ( cowles and carlin  @xcite , brooks , et al .",
    "@xcite ) to draw reliable samples and do proper inference .    an interesting alternative algorithm , called _ coupling from the past _ ( cftp ) , was introduced by propp and wilson  @xcite ( see also  @xcite and  @xcite ) and has been studied and used by a number of authors ( including kendall  @xcite , mller  @xcite , murdoch and green  @xcite , foss and tweedie  @xcite , kendall and thnnes  @xcite , corcoran and tweedie  @xcite , green and murdoch  @xcite , murdoch and rosenthal  @xcite ) . by searching backwards in time until paths from all starting states have coalesced , this algorithm uses the markov kernel  @xmath1 to sample _ exactly _ from  @xmath0 .",
    "another method of perfect simulation , for finite - state stochastically monotone chains , was proposed by fill  @xcite .",
    "fill s algorithm is a form of rejection sampling .",
    "this algorithm was later extended by mller and schladitz  @xcite and thnnes  @xcite to non - finite chains , motivated by applications to spatial point processes .",
    "fill s algorithm has the advantage over cftp of removing the correlation between the length of the run and the returned value , which eliminates bias introduced by an impatient user or a system crash and so is `` interruptible '' .",
    "however , it has been used only for stochastically monotone chains , making heavy use of the ordering of state space elements . in his paper , fill  @xcite indicated that his algorithm could be suitably modified to allow for the treatment of `` anti - monotone '' chains and ( see his section 11.2 ) indeed to generic chains .",
    "in this extended abstract we present a version of fill s algorithm for generic chains ; we , too , will provide an explanation in terms of rejection sampling .",
    "we have strived to keep to the spirit of the talks presented at the workshop on monte carlo methods held at the fields institute for research in mathematical sciences in toronto in october , 1998 and make our results accessible to a broad audience .",
    "technical details are provided in the full paper  @xcite .",
    "following is our interruptible algorithm for generic chains .",
    "we discuss some of the terminology used and other details of the algorithm in section  [ app1 ] .",
    "[ nontech ] choose and fix a positive integer  @xmath2 , choose an initial state @xmath3 from any distribution absolutely continuous with respect to  @xmath0 , and perform the following routine .",
    "run the time - reversed chain  @xmath4 for  @xmath2 steps , obtaining @xmath5 @xmath6 in succession . then , reversing the direction of time , generate ( possibly dependent ) markov chains , one [ say @xmath7 , with @xmath8 evolving from each element  @xmath9 of the state space  @xmath10 and each with transition kernel  @xmath1 .",
    "all these trajectories are to be multivariately coupled _ ex post facto _ with the trajectory @xmath11 , which is regarded as a trajectory from  @xmath1 ; in particular , @xmath12 . finally , we check whether all the values @xmath13 , @xmath14 , agree .",
    "if they do , we call this _ coalescence _ , and the value  @xmath6 is accepted as an observation from  @xmath0 . if not , then the value  @xmath6 is rejected and so the routine fails .",
    "we then start the routine again with an independent simulation , perhaps with a fresh choice of  @xmath2 and  @xmath3 , and repeat until the algorithm succeeds .    here is a simple intuitive explanation of why the algorithm works correctly .",
    "imagine ( 1 )  _ starting _ the construction with @xmath15 and independently ( 2 )  building all of the paths @xmath16 [ including @xmath17 _ simultaneously_. since determination of coalescence and the value of the coalesced paths at time  @xmath2 rely only on the second piece of randomness , conditionally given coalescence to @xmath18 ( for any  @xmath19 ) we will still have @xmath15 , as desired .",
    "the algorithm builds the randomness in a different order , starting from  @xmath3 .",
    "( a )  note that no assumption is made in algorithm  [ nontech ] concerning monotonicity or discreteness of the state space .",
    "( b )  see  ( [ reversal ] ) for the definition of  @xmath4 .",
    "( c )  to couple all of the trajectories  @xmath16 _ ex post facto _ with the trajectory @xmath20 means first to devise a multivariate coupling for all the trajectories by means of a transition rule and then to employ that coupling conditionally having observed the single trajectory @xmath12 .",
    "just how this is done is described in section  3 .",
    "( d )  if coalescence occurs , then of course the common value of  @xmath13 , @xmath14 , is the initial state  @xmath3 .",
    "( e )  we have reversed the direction of time , and the roles of the kernels  @xmath1 and  @xmath4 , compared to fill  @xcite .",
    "furthermore , fill s original algorithm also incorporated a search for a good value of  @xmath2 by doubling the previous value of  @xmath2 until the first success .",
    "for the most part , we shall not address such issues , instead leaving the choice of  @xmath2 entirely up to the user ; but see section  [ altalgsub ] .",
    "( f )  we have included the technical absolute continuity restriction on the distribution of  @xmath3 to ensure correctness . in a typical application , one might know a density for  @xmath0 with respect to some measure  @xmath21 ( for example , @xmath22 lebesgue measure ) up to a normalizing constant",
    ". then if , for example , that density is positive on the entire state space  @xmath10 , one need only take  @xmath3 to have any distribution having density with respect to  @xmath21 ( for example , a normal distribution ) .",
    "also , if the state space is discrete , or if it is continuous and all probabilistic ingredients to the algorithm ( such as the kernel  @xmath1 ) are sufficiently smooth , then the user may choose  @xmath3 deterministically and arbitrarily .    as mentioned above",
    ", we will discuss the details of algorithm  [ nontech ] in section  [ app1 ] .",
    "first , in section  [ motivation ] , we motivate our algorithm in the context of a rather general rejection sampling framework .",
    "a more rigorous treatment may be found in the full paper  @xcite . in section  [ app2 ]",
    "we discuss how the computational burden of tracking all of the trajectories  @xmath23 can be eased by the use of coalescence detection events in general and bounding processes in particular ; these processes take on a very simple form ( see section  [ mono ] ) when the state space is partially ordered and the transition rule employed is monotone . in the full paper",
    "we present a computationally efficient modification of algorithm  [ nontech ] that applies when  @xmath1 is assumed to be stochastically monotone .",
    "( as discussed in fill and machida  @xcite and machida  @xcite , this is a weaker assumption than that of the existence of a monotone transition rule . )",
    "when the state space is finite , the algorithm for the stochastically monotone case reduces to fill s original algorithm .",
    "the full paper also discusses a `` cross - monotone '' generalization of stochastic monotonicity . in section  [ taleof2 ]",
    "we compare algorithm  [ nontech ] and cftp .",
    "we also demonstrate a simple connection between cftp and an infinite - time - window version of algorithm  [ nontech ] ( namely , algorithm  [ altalg ] ) .",
    "this extended abstract discusses only algorithms for generating a single observation from a distribution  @xmath0 of interest . in the full paper , we discuss various strategies for perfect generation of samples of arbitrary size from  @xmath0 . the goal of this extended abstract is to describe how to apply fill s perfect sampling algorithm to a broad spectrum of problems of real interest , not to develop any specific applications in detail .",
    "but an underlying theme here is that while our extended algorithm ( algorithm  [ nontech ] ) tends to be computationally more intricate than cftp ( see section  [ comparison ] ) , theoretically it is as broadly applicable as is cftp . in this spirit",
    ", we will point to the applied perfect sampling literature at appropriate junctures , taking note of past applications of both cftp and fill s algorithm as examples .",
    "we hope that our extension of the latter algorithm will stimulate further research into this less - used alternative for perfect mcmc simulation .",
    "a valuable background resource is the annotated bibliography of perfect sampling maintained by wilson  @xcite .",
    "given a bivariate distribution @xmath24 , suppose that , for each  @xmath25 , we can simulate  @xmath26 from the conditional distribution  @xmath27 ? this is the problem confronting us in the context of algorithm  [ nontech ] , with @xmath28 and @xmath3 chosen according to  @xmath0 .",
    "indeed , we assumed there that the user can simulate from @xmath29 , where @xmath30 is the @xmath2-step time - reversal transition kernel ; and , when @xmath31 , we have @xmath32 .",
    "of course , if the user could simulate  @xmath31 , then either  @xmath3 or  @xmath6 could be used directly as an observation from  @xmath0 .",
    "but , for mcmc , this is an unreasonable assumption .",
    "so we turn to rejection sampling ( e.g. ,  devroye  @xcite ) , done conditionally given @xmath33 .",
    "our goal is to use the observation @xmath9 from @xmath34  to simulate one from  @xmath0 .",
    "this can be done by accepting  @xmath9 as an observation from  @xmath0 with probability @xmath35 for any @xmath36 chosen to make @xmath37 ; indeed , then @xmath38 the question remains how to engineer a coin - flip with probability  @xmath39 of heads , given that one can rarely _ compute _",
    "@xmath40 in practice .    however , if we can find an event  @xmath41 so that @xmath42 then we need only accept when ( and only when ) @xmath41 occurs .",
    "condition  ( [ ceq ] ) requires precisely that @xmath43 note that if we can choose  @xmath41 so that condition  ( [ eq2 ] ) holds , then setting  @xmath44 to be the entire state space  @xmath10 for  @xmath26 , we obtain @xmath45 and hence @xmath46 conversely , if we can choose  @xmath41 so that condition  ( [ fact ] ) holds , then we can choose @xmath47 to satisfy  ( [ ceq ] ) and  ( [ eq2 ] ) .",
    "how might we choose  @xmath41 to satisfy  ( [ fact ] ) ?",
    "observe that if  @xmath41 and another variable  @xmath48 are such that ( i )  @xmath49 over the event  @xmath41 and ( ii )  @xmath26 and the pair  @xmath50 are independent , then @xmath51 setting @xmath52 and then substituting , we obtain  ( [ fact ] ) .",
    "the algorithm  [ nontech ] is designed precisely so that we may take @xmath53 for an arbitrarily chosen ( but fixed ) @xmath54 to satisfy  ( i ) and  ( ii ) .",
    "this is discussed further in section  [ rigor ] below .",
    "the goal of this subsection is to describe in some detail how to apply algorithm  [ nontech ] .    _",
    "the space @xmath55 : _  it is sufficient that @xmath55 be a complete separable metric space . in particular , this covers the case that  @xmath10 is discrete or euclidean .",
    "see section  3.1 of the full paper  @xcite for further discussion .",
    "_ the kernel  @xmath1 and its time - reversal  @xmath4 : _",
    "let  @xmath1 be a markov transition kernel on  @xmath10 .",
    "the kernel is chosen ( by the user ) so that  @xmath0 is a stationary distribution , i.e. ,  so that @xmath56 the time - reversed kernel  @xmath4 ( also on  @xmath10 ) is then defined by @xmath57 _ the transition rule  @xmath58 : _  there exists a transition rule which can be used to drive the construction of the markov chain of interest .",
    "more precisely , there exists a probability space @xmath59 and a ( suitably measurable ) function @xmath60 such that @xmath61 such  @xmath58 ( with accompanying  @xmath62 ) is sometimes called a _ transition rule_. we choose and fix such a @xmath63 .",
    "[ phiremark ] ( a )  a transition rule  @xmath58 can always be found that uses @xmath64 $ ] , @xmath65 . in the special case",
    "that  @xmath10 is the unit interval , we can in fact use @xmath66 where  @xmath67 is the usual inverse probability transform corresponding to the distribution function @xmath68)$ ] .",
    "( b )  if  @xmath10 is discrete ( finite or countably infinite ) , a very simple alternative choice is the following `` independent - transitions '' transition rule .",
    "let  @xmath69 , let  @xmath62 be product measure with @xmath9th marginal @xmath70 ( @xmath14 ) , and let  @xmath58 be the evaluation function @xmath71    \\(c ) many interesting examples of transition rules can be found in the literature , including diaconis and freedman  @xcite and the references cited in section  [ intro ] .",
    "\\(d ) usually there is a wealth of choices of transition rule , and the art is to find one giving rapid and easily detected coalescence . without going into details at this point",
    ", we remark that the transition rule in  ( b ) usually performs quite badly , while transition rules having a certain monotonicity property will perform well under monotonicity assumptions on  @xmath1 .",
    "_ the markov chain and a first probability space : _   we will need to set up two probability spaces . the first space @xmath72designated in ordinary typeface  will be useful for theoretical considerations and for the computation of certain conditional probability distributions . the second space @xmath73designated in boldface type  will be the probability space actually simulated when the algorithm is run .",
    "all random variables defined on the first space ( respectively , second space ) will also be designated in ordinary typeface ( resp .",
    ",  boldface type ) .",
    "we have chosen this notational system to aid the reader :  corresponding variables , such as  @xmath74 and  @xmath6 , will play analogous roles in the two spaces .    from our previous comments",
    "it is easy to see that there exists a space  @xmath75 , a transition rule @xmath63 , and a probability space  @xmath76 on which are defined independent random variables @xmath77 with @xmath78 and each @xmath79 . now inductively",
    "define @xmath80 then @xmath81 is easily seen to be a stationary markov chain with kernel  @xmath1 , in the sense that @xmath82 in fact , for each @xmath14 we obtain a chain with kernel  @xmath1 started from  @xmath9 by defining @xmath83 and , inductively , @xmath84 let @xmath85 . in this notation",
    "we have @xmath86 .",
    "let @xmath87 denote the event that the trajectories  @xmath88 have all coalesced by time  @xmath2 .",
    "fixing @xmath54 arbitrarily and taking @xmath89 to match up with the notation in section  [ motivation ] , key observations are that , for any ( measurable ) subset  @xmath44 of  @xmath10 , @xmath49 over the event  @xmath41 , and  @xmath26 and the event @xmath90 are independent .",
    "the independence here follows from the fact that  @xmath74 and @xmath91 have been chosen to be independent .    _ a second probability space and the algorithm : _",
    "we make use of the auxiliary randomness provided by @xmath92@xmath93x_1 , ",
    ", x_t - 1@xmath94@xmath95@xmath96@xmath97(x_0 ,  ,",
    "x_t - 1)@xmath98x_t = next , we will discuss in section  [ imp ] how to compute @xmath99 .",
    "finally , whether or not  @xmath41 occurs is determined solely by the randomness in  @xmath100 , so the conditional probability of  @xmath41 given @xmath101 is degenerately either  @xmath102 or  @xmath103 .",
    "moreover , our discussion has indicated how to set up and _ simulate _ the second space . as discussed in section  [ intro ] , we assume that the user knows enough about  @xmath0 qualitatively to be able to simulate  @xmath3 so that @xmath104 .",
    "having chosen @xmath105 , the user draws an observation @xmath106 from @xmath107 , then an observation @xmath108 from @xmath109 , etc .",
    "next , having chosen @xmath110 [ i.e. , @xmath111 , the user draws an observation @xmath112 from @xmath99 and constructs @xmath113 by setting @xmath114 and , inductively , @xmath115 finally , the user declares that  @xmath116 , or _",
    "coalescence _ , has occurred if and only if the values of  @xmath13 , @xmath14 , all agree .",
    "the conditional distribution of output from algorithm  [ nontech ] given that it ultimately succeeds ( perhaps only after many iterations of the basic routine ) is  @xmath0 , as desired .",
    "[ genremark ] ( a )  if @xmath117 for suitably large  @xmath2 , then ultimate success is ( a.s.)guaranteed if the successive choices of  @xmath2 become large .",
    "a necessary condition for ultimate positivity of  @xmath118 is uniform ergodicity of  @xmath1 .",
    "this condition is also sufficient , in the ( rather weak ) sense that if  @xmath1 is uniformly ergodic , then there exists a finite integer  @xmath119 and a transition rule  @xmath120 for the @xmath119-step kernel  @xmath121 such that algorithm  [ nontech ] , applied using  @xmath120 , has @xmath117 when  @xmath2 is chosen sufficiently large .",
    "compare the analogous theorem  4.2 for cftp in foss and tweedie  @xcite .",
    "( b )  just as discussed in fill  @xcite ( see especially the end of section  7 there ) , the algorithm ( including its repetition of the basic routine ) we have described is interruptible ; that is , its running time ( as measured by number of markov chain steps ) and output are independent random variables , conditionally given that the algorithm eventually terminates .",
    "( c )  if the user chooses the value of  @xmath3 ( @xmath122 , say ) deterministically , then all that can be said in general is that the algorithm works properly for @xmath0-a.e .  such choice . in this case , let the notation @xmath123 reflect the dependence of  @xmath118 on the initial state  @xmath19 .",
    "then clearly @xmath124 which is the unconditional probability of coalescence in our first probability space and therefore equal to the probability that cftp terminates over an interval of width  @xmath2 .",
    "this provides a first link between cftp and algorithm  [ nontech ] .",
    "( very ) roughly recast , the distribution of running time for cftp is the stationary mixture , over initial states , of the distributions of running time for algorithm  [ nontech ] . for further elaboration of the connection between the two algorithms ,",
    "see section  [ conn ] .      in order to be able to run algorithm  [ nontech ] ,",
    "the user needs to be able to impute  @xmath100 from  @xmath125 , i.e. ,  to draw from @xmath99 . in this subsection",
    "we explain how to do this .",
    "we begin with the computation @xmath126 where the last equality is justified in the same fashion as for the first two .",
    "this establishes    [ condlemma ] the @xmath2-fold product of the measures @xmath127 serves as a conditional probability distribution @xmath128 .    in setting up the second probability space , therefore",
    ", the user , having chosen @xmath110 , draws an observation @xmath112 by drawing @xmath129 independently , with @xmath130 chosen according to the distribution @xmath131 .",
    "[ subtle ] ( a )  if  @xmath10 is discrete , suppose we use the `` independent - transitions '' rule  @xmath58 discussed in remark  [ phiremark](b ) .",
    "then the measure  @xmath62 , but with the @xmath132th marginal replaced by  @xmath133 , serves as @xmath134 and therefore as @xmath135 .",
    "informally stated , having chosen @xmath136 and @xmath137 , the user imputes the forward - trajectory transitions from time  @xmath138 to time  @xmath139 in algorithm  [ nontech ] by declaring that the transition from state  @xmath140 is to state  @xmath141 and that the transitions from other states are chosen independently according to their usual non-@xmath125-conditioned distributions .",
    "( b )  as another example , suppose that @xmath142 $ ] and we use the inverse probability transform transition rule discussed in remark  [ phiremark](a ) .",
    "suppose also that each distribution function @xmath143)$ ] is strictly increasing and onto  @xmath144 $ ] .",
    "then  @xmath145 serves as @xmath146 .",
    "informally stated , a generated pair @xmath147 completely determines the value @xmath148 for  @xmath130 .",
    "we illustrate algorithm  [ nontech ] for a very simple example and two different choices of transition rule .",
    "consider the discrete state space @xmath149 , and let  @xmath0 be uniform on  @xmath10 .",
    "let  @xmath1 correspond to simple symmetric random walk with holding probability  @xmath150 at the endpoints ; that is , putting @xmath151 , @xmath152 the stationary distribution is  @xmath0 .",
    "as for any ergodic birth - and - death chain , @xmath1 is reversible with respect to  @xmath0 , i.e. ,  @xmath153 . before starting the algorithm , choose a transition rule ; this is discussed further below .    for utter simplicity of description",
    ", we choose  @xmath154 and ( deterministically ) @xmath155 ( say ) ; as discussed in section  [ intro ] , a deterministic start is permissible here .",
    "we then choose @xmath156 and @xmath157 .",
    "how we proceed from this juncture depends on what we chose for  @xmath58 .",
    "one choice is the independent - transitions rule discussed in remarks  [ phiremark](b ) and  [ subtle](a ) .",
    "the algorithm s routine can then be run using  @xmath158 independent random bits : these decide  @xmath159 ( given  @xmath160 ) , @xmath6 ( given  @xmath159 ) , and the  @xmath161 transitions in the second ( forward ) phase of the routine not already determined from the rule @xmath162 there are thus a total of  @xmath163 possible overall simulation results , each having probability  @xmath164 .",
    "we check that exactly  @xmath165 of these produce coalescence . of these  @xmath165",
    "accepted results , exactly  @xmath161 have @xmath166 , another  @xmath161 have @xmath167 , and a final  @xmath161 have @xmath168 .",
    "thus @xmath169 , and we confirm that @xmath170 , as should be true .",
    "an identical result holds if instead we choose @xmath171 or @xmath172 .",
    "an alternative choice adapts remarks  [ phiremark](a ) and  [ subtle](b ) to our discrete setting .",
    "note that we can use @xmath173 and @xmath174 choosing @xmath154 and @xmath155 as before , the algorithm can now be run with just  @xmath175 random bits . in this case",
    "we check that exactly  @xmath176 of the  @xmath161 possible simulation results produce coalescence , @xmath103 each yielding @xmath177 .",
    "note that @xmath178 is much larger for this choice of  @xmath58 .",
    "in fact , since  @xmath58 is a monotone transition rule ( see definition  4.2 in fill  @xcite or definition  [ mondef ] below ) , for the choice @xmath155 it gives the highest possible value of  @xmath118 among all choices of  @xmath58 : see remark  9.3(e ) in fill  @xcite .",
    "it also is a best choice when @xmath172 .",
    "[ on a minor negative note , we observe that @xmath179 for the choice @xmath171 .",
    "also note that the @xmath180-average of the acceptance probabilities  @xmath181 , namely , @xmath150 , is the probability that forward coupling ( or cftp ) done with the same transition rule gives coalescence within  @xmath175 time units ; this corroborates remark  [ genremark](c ) . ]",
    "[ toyrate ] both choices of  @xmath58 are easily extended to handle simple symmetric random walk on @xmath182 for any  @xmath183 ; the second ( monotone ) choice is again best possible .",
    "( we assume @xmath155 . ) for fixed @xmath184 and large  @xmath183 , results in fill  @xcite and section  4 of diaconis and fill  @xcite imply that , for @xmath185 , the routine s success probability is approximately  @xmath186 ; here  @xmath186 increases smoothly from  @xmath102 to  @xmath103 as @xmath187 increases from  @xmath102 to  @xmath188 .",
    "we have not attempted the corresponding asymptotic analysis for the independent - transitions rule .",
    "of course our chain is only a `` toy '' example anyway , because direct sampling from  @xmath0 is elementary .",
    "even for large finite state spaces  @xmath10 , determining exactly whether or not coalescence occurs in algorithm  [ nontech ] can be prohibitively expensive computationally ; indeed , in principle this requires tracking each of the trajectories @xmath88 , @xmath14 to completion",
    ". however , observe that if we repeat the development of sections  [ rigor][imp ] , replacing the coalescence event @xmath189 of  ( [ cdef ] ) by any _ subset _",
    "@xmath41 of this event whose occurrence ( or not ) can still be determined solely from  @xmath100 , then everything goes through as before .",
    "we call such an event  @xmath41 a _ coalescence detection event _ and reiterate that  @xmath41 is a conservative indication of coalescence :  the occurrence of a given coalescence detection event is sufficient , but not necessary , for the occurrence of coalescence of the paths @xmath88 .    in practice ,",
    "a coalescence detection event is constructed in terms of a _",
    "detection process_. what we mean by this is a stochastic process @xmath190 , defined on the same probability space @xmath72 as  @xmath100 and  @xmath125 , together with a subset  @xmath191 of its state space  @xmath192 , such that    1 .",
    "@xmath193 is constructed from  @xmath100 , and 2 .",
    "@xmath194 .",
    "then @xmath195 is a coalescence detection event .",
    "[ detectionremark ] in practice , @xmath193 usually evolves markovianly using  @xmath100 ; more precisely , it is typically the case that there exists deterministic @xmath196 and @xmath197 such that @xmath198 and [ paralleling  ( [ drive ] ) ] @xmath199    the important consequence is that , having determined the trajectory  @xmath20 and the imputed  @xmath200 , the user need only follow a single trajectory in the forward phase of the routine , namely , that of  @xmath193 ( or rather its analogue  @xmath201 in the simulated probability space ) .    [ mtfandtrees ] we sketch two illustrative examples of the use of detection processes that do not immediately fall into the more specific settings of sections  [ bounding ] or  [ mono ] .",
    "we hasten to point out , however , that because of the highly special structure of these two examples , efficient implementation of algorithm  [ nontech ] avoids the use of the forward phase altogether ; this is discussed for example  ( a ) in fill  @xcite .",
    "( a )  our first example is provided by the move - to - front ( mtf ) rule studied in  @xcite .",
    "let  @xmath1 be the markov kernel corresponding to  mtf with independent and identically distributed record requests corresponding to probability weight vector @xmath202 ; see  ( 2.1 ) of  @xcite for specifics .",
    "the arguments of section  4 of  @xcite show that if  @xmath203 is taken to be the set of all records requested at least once among the first  @xmath139 requests and  @xmath191 is taken to consist of all @xmath204-element subsets of the records @xmath205 , then  @xmath193 is a detection process .",
    "similar detection processes can be built for the following generalizations of mtf :  move - to - root for binary search trees ( see dobrow and fill  @xcite  @xcite ) and mtf - like shuffles of hyperplane arrangement chambers and more general structures ( see bidigare , et al .",
    "@xcite and brown and diaconis  @xcite ) .",
    "( b )  a second example of quite similar spirit is provided by the ( now well - known ) markov chain  @xmath206 for generating a random spanning arborescence of the underlying weighted directed graph , with vertex set  @xmath207 , of a markov chain @xmath208 with kernel  @xmath209 .",
    "consult propp and wilson  @xcite ( who also discuss a more efficient `` cycle - popping '' algorithm ) for details .",
    "we consider here only the special case that  @xmath208 is an i.i.d .",
    "sequence , i.e. ,  that @xmath210 .",
    "a transition rule  @xmath58 for the chain  @xmath206 is created as follows :  for vertex  @xmath211 and arborescence  @xmath9 with root  @xmath212 , @xmath213 is the arborescence obtained from  @xmath9 by adding an arc from  @xmath212 to  @xmath211 and deleting the unique arc in  @xmath9 whose tail is  @xmath211 .",
    "then it can be shown that if @xmath203 is taken to be the set of all vertices appearing at least once in @xmath214 and @xmath215 , then  @xmath193 is a detection process .",
    "we obtain a natural example of a detection process  @xmath193 when ( a )  @xmath193 is constructed from  @xmath100 , ( b )  the corresponding state space  @xmath192 is some collection of subsets of  @xmath10 , with @xmath216 and @xmath217 the concept is simple : in this case , each set  @xmath203 is just a `` conservative estimate '' ( i.e. , a superset ) of the corresponding set @xmath218 of trajectory values ; thus if @xmath219 , then the trajectories  @xmath88 are coalesced to state  @xmath25 at time  @xmath139 and remain coalesced thereafter .",
    "we follow the natural impulse to call such a set - valued detection process a _ bounding process_. such bounding processes arise naturally in the contexts of monotone and anti - monotone transition rules ( and have been used by many authors):see the next subsection .",
    "other examples of bounding processes can be found in works of huber :  see  @xcite and  @xcite in connection with cftp and  @xcite in connection with our algorithm .",
    "of course , nothing is gained , in comparison to tracking all the trajectories , by the use of a bounding process unless the states of  @xmath192 have more concise representations than those of generic subsets of  @xmath10 ; after all , we could always choose @xmath220 and @xmath221 .",
    "one rather general setting where compact representations are often possible , discussed in the next subsection , is that of a partially ordered set ( poset )  @xmath10 .",
    "we now suppose that @xmath10 is equipped with a partial order .",
    "we also assume here that there exist ( necessarily unique ) elements  @xmath222 and  @xmath223 in  @xmath10 ( called _ bottom element _ and _ top element _ ,",
    "respectively ) such that @xmath224 for all @xmath14 .",
    "we will discuss the case of monotone transition rules , where we can build from  @xmath100 a bivariate process @xmath225 , taking values at each time  @xmath139 in @xmath226 , such that @xmath227 then @xmath228 = \\{x \\in { \\mathcal{x}}:\\ l_s \\leq x \\leq v_s\\}$ ] gives a bounding process , and the pair @xmath229 is a quite concise representation of  @xmath203 . recall that our construction  ( [ drive ] ) of the markov chain  @xmath125 with kernel  @xmath1 relies on the choice of a transition rule  @xmath63 satisfying  ( [ kq ] ) .    [ mondef ] _",
    "a transition rule  @xmath58 is said to be _ monotone _ if each of the mappings @xmath230 ,  @xmath231 , is monotone increasing , i.e. ,  if @xmath232 whenever @xmath233 . _",
    "suppose now that  @xmath58 is monotone .",
    "set @xmath234 and , inductively , @xmath235 one immediately verifies by induction that  ( [ squeeze ] ) is satisfied .",
    "note that  @xmath229 is determined solely by  @xmath100 ( as is the coalescence detection event @xmath236 ) and is nothing more than @xmath237 . in plain language , since monotonicity is preserved , when the chains  @xmath238 and  @xmath239 have coalesced , so must have every  @xmath88 .",
    "[ anti ] ( a )  lower and upper bounding processes can also be constructed when algorithm  [ nontech ] is applied with a so - called `` anti - monotone '' transition rule ; we omit the details .",
    "see hggstrm and nelander  @xcite , huber  @xcite , kendall  @xcite , mller  @xcite , mller and schladitz  @xcite , and thnnes  @xcite for further discussion in various specialized settings .",
    "there are at least two neat tricks associated with anti - monotone rules .",
    "the first is that , by altering the natural partial order on  @xmath10 , such rules can be regarded , in certain bipartite - type settings , as monotone rules , in which case the performance analysis in section  5.3 of  @xcite is available :  consult section  3 of  @xcite , the paper  @xcite , and definition  5.1 in  @xcite .",
    "the second is that the poset  @xmath10 is allowed to be `` upwardly unbounded '' and so need not have a  @xmath223 :  consult section  2 of  @xcite and , again , @xcite and  @xcite .",
    "( b )  dealing with monotone rules on partially ordered state spaces without  @xmath223 is problematic and requires the use of `` dominating processes . ''",
    "we comment that a dominating process provides a sort of _ random _ bounding process and is useful when the state space is noncompact , but we shall not pursue these ideas any further here . see kendall  @xcite and kendall and mller  @xcite in the context of cftp ; we hope to discuss the use of dominating processes for our algorithm in future work .",
    "how does our extension of fill s algorithm , as given by algorithm  [ nontech ] and discussed in detail in section  [ app1 ] , compare to cftp ? as we see it , our algorithm has two main advantages and one main disadvantage .    _",
    "advantages : _  as discussed in section  [ intro ] and remark  [ genremark](b ) and in  @xcite , a primary advantage of our algorithm is interruptibility . given the close connection between the algorithms described in section  [ conn ] , one may reasonably view the extra computational costs of our algorithm ( see `` _ disadvantage _ '' below ) as the costs of securing interruptibility . a related second advantage concerns memory allocation .",
    "suppose , for example , that our state space  @xmath10 is finite and that each time - step of algorithm  [ nontech ] , including the necessary imputation ( recall section  [ imp ] ) , can be carried out using a bounded amount of memory .",
    "then , for fixed  @xmath2 , our algorithm can be carried out using a fixed finite amount of memory .",
    "unfortunately , it is rare in practice that the kernel  @xmath1 employed is sufficiently well analyzed that one knows in advance a value of  @xmath2 ( and a value of the seed  @xmath3 ) giving a reasonably large probability  @xmath118 of acceptance .",
    "furthermore , the fixed amount of memory needed is in practice larger than the typical amount of memory allocated dynamically in a run of cftp .",
    "finally , we should note that wilson  @xcite has very recently presented a version of cftp which also can be carried out with a fixed finite amount of memory , and which does not require an _ a priori _ estimate of the mixing time of the chain .",
    "_ disadvantage : _  a major disadvantage of our algorithm  [ nontech ] concerns computational complexity .",
    "we refer the reader to  @xcite and  @xcite for a more detailed discussion in the setting of our section  [ mono ] ( and , more generally , the setting of stochastic monotonicity ) .",
    "briefly , if no attention is paid to memory usage , our algorithm has running time competitive with cftp : cf .  remark  [ genremark](c ) , and also the discussion in remark  9.3(e ) of  @xcite that the running time of our algorithm is , in a certain sense , best possible in the stochastically monotone setting .",
    "however , this analysis assumes that running time is measured in markov chain steps ; unfortunately , time - reversed steps can sometimes take longer than do forward steps to execute ( e.g. ,  @xcite ) , and the imputation described in section  [ imp ] is sometimes difficult to carry out . moreover , the memory usage for naive implementation of our algorithm can be exorbitant ; how to trade off speed for reduction in storage needs is described in  @xcite .",
    "thus far we have been somewhat sketchy about the choice(s ) of  @xmath2 in algorithm  [ nontech ] . as discussed in section  [ intro ] , one possibility is to run the repetitions of the basic routine independently , doubling  @xmath2 at each stage .",
    "however , another possibility is to continue back in time , reusing the already imputed values  @xmath130 and checking again for coalescence .",
    "( there is an oblique reference to this alternative in remark  9.3 of fill  @xcite . )",
    "this idea leads to the following algorithm .",
    "[ altalg ] choose an initial state @xmath240 , where @xmath241 is absolutely continuous with respect to  @xmath0 . run the time - reversed chain  @xmath4 , obtaining @xmath242 in succession .",
    "conditionally given @xmath243 , generate independent random variables @xmath244 with marginals @xmath245 where , on the right , @xmath246 is given by  ( [ kq ] ) .",
    "for @xmath247 and @xmath14 , set @xmath248 and , inductively , @xmath249 if @xmath250 is the smallest  @xmath2 such that @xmath251 then the algorithm succeeds and reports  @xmath252 as an observation from  @xmath0 . otherwise , the algorithm fails .",
    "[ altremark ] ( a )  we need only generate @xmath253 and then impute @xmath254 , @xmath255 using  ( [ altimp ] ) in order to check whether or not  ( [ altcoalescence ] ) holds .",
    "thus if @xmath250 , then the algorithm terminates in finite time .",
    "( b )  we omit the detailed description  la section  [ app1 ] . but",
    "the key in setting up the first probability space is _ first _ to choose @xmath256 and @xmath257 all mutually independent and _ then _ , having determined the backwards coalescence time  @xmath258 from @xmath257 , to set @xmath259 .",
    "( c )  we may relax the condition that  @xmath260 be the _",
    "smallest _  @xmath2 satisfying  ( [ altcoalescence ] ) , via the use of coalescence detection events as in section  [ app2 ] .",
    "in particular , to save considerably on computational effort , we may let  @xmath261 be the smallest  @xmath2 which is a power of  @xmath175 such that  ( [ altcoalescence ] ) holds and report @xmath262 instead .",
    "( d )  algorithm  [ altalg ] , and likewise its variant in remark  ( c ) , is interruptible :  @xmath260 and  @xmath263 are conditionally independent given success .",
    "there is a strong and simple connection between cftp and our algorithm  [ altalg ] . indeed , suppose we carry out the usual cftp algorithm to sample from  @xmath0 , using kernel  @xmath1 , transition rule  @xmath58 , and driving variables  @xmath264 .",
    "let  @xmath258 denote the backwards coalescence time and let @xmath78 denote the terminal state output by cftp .",
    "let @xmath265 independent of  @xmath100 , and follow the trajectory from @xmath266 to @xmath74 ; call this trajectory @xmath267 . since  @xmath74 is determined solely by  @xmath100 , the random variables  @xmath268 and  @xmath74 are independent .",
    "when @xmath269 in algorithm  [ altalg ] , the algorithm simply constructs the same probability space as for cftp , but with the ingredients generated in a different chronological order :  first @xmath270 ; then  @xmath100 ( which determines  @xmath258 ) ; then @xmath271 . again",
    "@xmath78 and @xmath265 are independent .",
    "( b )  the fact ( 1 )  that @xmath268 , unlike  @xmath74 , is independent of  @xmath100 , together with ( 2 )  that @xmath258 depends solely on  @xmath100 , explains why our algorithm is interruptible and cftp is not .",
    "( c )  in a single run of cftp , the user would of course be unable to choose @xmath273 as above , just as in a single run of algorithm  [ altalg ] we do not actually choose @xmath78 .",
    "so one might regard our described connection between the two algorithms as a bit metaphorical . but see section  7.2 of  @xcite .",
    "foss ,  s.  g.  and tweedie ,  r.  l. _ perfect simulation and backward coupling .",
    "stochastic models * 14 * ( 1998 ) , 187203 .",
    "gelfand ,  a.  e.  and smith ,  a.  f.  m. _ sampling - based approaches to calculating marginal densities .",
    "_ j. amer .",
    "* 85 * ( 1990 ) , 398409 .",
    "machida ,  m. _ stochastic monotonicity and realizable monotonicity _ , ph.d .",
    "dissertation , department of mathematical sciences , the johns hopkins university , 1999 .",
    "available from ` http://www.mts.jhu.edu/machida/ ` .",
    "propp ,  j.  g.  and wilson ,  d.  b. _ coupling from the past : a user s guide . _ aldous ,  d. and propp ,  j.  g. , editors , microsurveys in discrete probability , vol",
    ". 41 of dimacs series in discrete mathematics and theoretical computer science , amer",
    "soc . , providence , ri , 1998 , pp . 181192 .",
    "wilson ,  d.  b. _ annotated bibliography of perfectly random sampling with markov chains .",
    "_ aldous ,  d.  and propp ,  j. ,  editors , microsurveys in discrete probability , vol .",
    "41 of dimacs series in discrete mathematics and theoretical computer science , amer .",
    "soc . , providence , ri , 1998 , pp . 209220 .",
    "updated versions are posted at ` http://www.dbwilson.com/exact/ ` ."
  ],
  "abstract_text": [
    "<S> we provide an extension of the perfect sampling algorithm of fill ( 1998 ) to general chains , and describe how use of bounding processes can ease computational burden . along the way , we unearth a simple connection between the coupling from the past ( cftp ) algorithm originated by propp and wilson ( 1996 ) and our extension of fill s algorithm . </S>"
  ]
}