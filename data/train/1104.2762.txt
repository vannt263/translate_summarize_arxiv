{
  "article_text": [
    "the problem of approximating multivariate probability distributions is a central task of many fields . unfortunately in most of the cases we know nothing about the theoretical probability distribution .",
    "it is useful to exploit the dependence structure between the random variables involved .",
    "the problem is : what should we do when correlation matrices can not be used .",
    "starting from a discrete probability distribution , for example from a sample data , it is useful to discover some of the conditional independences between the variables .",
    "the markov networks ( markov random fields ) and bayesian networks encode these conditional independences . in our paper",
    "we focus on the markov networks .",
    "if the graph structure of the markov network is known , many procedures were developed for its inference , see @xcite and @xcite .",
    "there are many cases where the graph structure of the markov network is unknown . in @xcite",
    "we proposed a method for discovering some of the conditional independences between the random variables by fitting a special type of multivariate probability distribution called @xmath1-cherry junction tree distribution to the sample data .",
    "the goodness of fit was quantified by the kullback - leibler divergence ( see @xcite ) .",
    "this relates the problem to information theory ( @xcite ) . on the other side , the graph underlying the markov network links the problem to graph theory . for elements of graph theory see @xcite .    in the second section",
    "we introduce some concepts used in graph theory and probability theory that we need throughout the paper and present how these can be linked to each other . for a good overview",
    "see @xcite .    in the third part",
    "we introduce the szntai - kovcs s greedy algorithm which starting from the @xmath0-th order marginal probability distributions gives a @xmath0-th order @xmath1-cherry junction tree probability distribution as a result . for the same task malvestuto",
    "gives another algorithm in @xcite .",
    "first we compare these two algorithms from analytical point of view and then apply them on the example problem presented in malvestuto s paper @xcite .    in the fourth part",
    "we introduce the so called puzzle algorithm for @xmath0-th order @xmath1-cherry trees .",
    "this results in a puzzle numbering of the verticies . using this we give some theoretical results related to our greedy algorithm .",
    "the last part contains conclusions and some possible applications of our greedy algorithm .",
    "this part contains a summary of the concepts used throughout the paper .",
    "we first present the acyclic hypergraphs and junction trees .",
    "we then present a short reminder on markov network .",
    "we finish this part with the multivariate joint probability distribution associated to a junction tree .",
    "let @xmath3 be a set of vertices and @xmath4 a set of subsets of @xmath5 called _ set of hyperedges_. a _ hypergraph _ consists of a set @xmath5 of vertices and a set @xmath4 of hyperedges .",
    "we denote a hyperedge by @xmath6 , where @xmath6 is a subset of @xmath5 .",
    "if two vertices are in the same hyperedge they are connected , which means , the hyperedge of a hyperhraph is a complete graph on the set of vertices contained in it .",
    "a vertex is called _ simplicial _ if it belongs to precisely one hyperedge .",
    "an ordering of the vertices is a _ perfect elimination ordering _",
    "if @xmath7 the vertex @xmath8 is simplicial in the subhypergraph defined on the vertices @xmath9    the _ _ acyclic _ _  _ hypergraph _ is a special type of hypergraph which fulfills the following requirements :    * neither of the edges of @xmath4 is a subset of another edge .",
    "* there exists a numbering of edges for which the _ running intersection property _ is fullfiled : @xmath10 .",
    "( other formulation is that for all hyperedges @xmath6 and @xmath11 with @xmath12 , @xmath13 . )",
    "let @xmath14 , for @xmath15 and @xmath16 .",
    "let @xmath17 .",
    "we say that @xmath18__separates _",
    "_ @xmath19 from @xmath20 , and call @xmath18 separator set or shortly separator .",
    "now we link these concepts to the terminology of junction trees .",
    "the junction tree is a special tree stucture which is equivalent to the connected acyclic hypergraphs @xcite .",
    "the nodes of the tree correspond to the hyperedges of the connected acyclic hypergraph and are called clusters , the edges of the tree correspond to the separator sets and called separators .",
    "the set of all clusters is denoted by @xmath21 , the set of all separators is denoted by @xmath22 .",
    "the junction tree with the largest cluster containing @xmath0 variables is called _ k - width junction tree_.    an important relation between graphs and hypergraphs is given in @xcite : a hypergraph is acyclic if and only if it can be considered to be the set of cliques of a triangulated graph ( a graph is triangulated if every cycle of legth greater than 4 has a chord ) .",
    "[ theo:1 ] ( fulkerson and gross , @xcite ) : a graph is an acyclic hypergraph ( triangulated graph or junction tree ) if and only if has an perfect elimination ordering .",
    "[ alg:1 ] ( graham , @xcite ) a _ graham reduction _ of a hypergraph @xmath23 is defined by applying the following two operations to _ h _ until they can be applied no more .    * node removal",
    ": if a node appears in only one hyperedge , delete it from v and from the edge .",
    "* hyperedge removal : in the the transformed hyperedge set , delete a hyperedge if it is subset of another hyperedge .    in @xcite is shown that a hypergraph reducies to nothing by this process if and only if the hypergraph is acyclic .    in the figure [ fig:1 ]",
    "one can see a ) a triangulated graph , b ) the corresponding acyclic hypergraph and c ) the corresponding junction tree .",
    "we consider the random vector @xmath24 , with the set of indicies @xmath3 . roughly speaking a markov network",
    "encodes the conditional independences between the random variables .",
    "the graph structure associated to a markov network consists in the set of nodes v , and the set of edges @xmath25 .",
    "we say the graph structure associated to the markov network has    * the _ pairwise markov _",
    "( pm ) property if @xmath26 , @xmath8 not connected to @xmath27 implies that @xmath28 and @xmath29 are conditionally independent given all the other random variables ; * the _ local markov ( lm ) _ property if @xmath30 and @xmath31 the neighbourhood of node @xmath8 in the graph ( the nodes connected with @xmath8 ) then @xmath28 is conditionally independent from all @xmath29 , @xmath32 , given @xmath33 ; * the global markov ( gm ) property states that if in the graph @xmath34 and c separates a and b in terms of graph then @xmath35and @xmath36 are conditionally independent given @xmath37 , which means in terms of probabilities that @xmath38 * the _ factorization ( f ) _ property states that if @xmath21 denotes the set of cliques of the graph ( maximum complete graphs ) then there exist positive functions @xmath39 that @xmath40    the following implication is well known @xcite : @xmath41 .",
    "the hammersley - clifford theorem states that under assumption of positivity @xmath42 .",
    "however positivity is a very strong condition .",
    " the positivity condition is mathematically convenient ; but it hardly seems necessary  @xcite . in this paper",
    "we focus on markov network characterized by the global markov property .",
    "the concept of _ junction tree probability distribution _ is related to the junction tree graph and to the global markov property of the graph .",
    "a junction tree probability distribution is defined as a product and division of marginal probability distributions as follows :    @xmath43 ^{\\nu _ s-1}},\\ ] ] where @xmath21 is the set of clusters of the junction tree , @xmath44 is the set of separators , @xmath45 is the number of those clusters which contain the separator s. we emphasize here that the equalities written as @xmath46 , where @xmath47 hold for any possible realization of @xmath48 .",
    "[ ex:1 ] the probability distribution corresponding to figure [ fig:1 ] is : @xmath49    in our paper @xcite we introduced a special kind of @xmath0-width junction tree , called @xmath0-th order @xmath1-cherry junction tree in order to approximate a joint probability distribution .",
    "the @xmath0-th order @xmath1-cherry junction tree probability distribution is associates to the @xmath0-th order @xmath1-cherry tree , introduced in @xcite , @xcite .",
    "[ def : def1 ] the recursive construction of the _ k - th order t - cherry tree _ :    * \\(i ) the complete graph of @xmath50 nodes from @xmath5 represent the smallest @xmath0-th order _ t_-cherry tree ; * \\(ii ) by connecting a new vertex @xmath51 , with all @xmath52 vertices of a @xmath53- dimensional complete subgraph of the existing @xmath0-th order @xmath1-cherry tree , we obtain a new @xmath0-th order @xmath1-cherry tree .",
    "@xmath54 is called _ k_-th order hypercherry . *",
    "\\(iii ) a _",
    "k_-th order @xmath1-cherry tree can be obtained from ( i ) by successive application of ( ii ) .",
    "k_-th order @xmath1-cherry tree is a special triangulated graph therefore a junction tree structure is associated to it .",
    "[ def : def2 ] ( @xcite ) the _ k - th order @xmath1-cherry junction tree _ is defined in the following way :    * by using definition [ def : def1 ] we construct a _",
    "k_-th order _",
    "t_-cherry tree over @xmath5 .",
    "* to each hypercherry @xmath55 is assigned a cluster @xmath56 which a node of the junction tree and a separator @xmath52 which is an edge of the junction tree .",
    "we denote by @xmath57 , and @xmath58 , the set of clusters and separators of the @xmath1-cherry junction tree .",
    "[ def : def3 ] ( @xcite ) if the indices of the random vector @xmath59 are assigned to a @xmath1-cherry junction tree structure then there exists a probability distribution called _",
    "t - cherry junction tree probability distribution _ given by :    @xmath60    [ rem : rem1 ] the marginal probability distributions involved in the above formula are marginal probability distributions of @xmath61 .",
    "example [ ex:1 ] shows a 3-rd order @xmath1-cherry junction tree probability distribution .    in the following instead of probability distribution associated to a junction tree we will use shortly junction tree pd and similarly instead of @xmath0-th order @xmath1-cherry tree junction tree distribution we will use shortly @xmath0-th order @xmath1-cherry pd .",
    "recently we found a paper @xcite where malvestuto introduced the same junction tree pd structure in a different way and named it _ elementary model of rank",
    "the graph underlying the markov network is usually unknown , the task of the following section is to give a greedy algorithm , for finding a junction tree starting from the @xmath0-th order marginal distributions , which are supposed to be known .",
    "the problem is finding a @xmath0-width junction tree pd which gives the best approximation for a discrete probability distribution @xmath62 .",
    "the goodness of the approximation is quantified by the kullback - leibler divergence , which have to be minimized :    @xmath63    this minimization problem for @xmath2 can be solved in exact way only by exhaustive search @xcite . for k=2 the problem can be solved using kruskall s algorithm , as was first proposed by chow and liu @xcite .",
    "malvestuto @xcite and szntai et.al .",
    "@xcite proved independently and in different ways the following statement : if @xmath64 is a @xmath0-width junction tree pd approximation then there exists @xmath65 a @xmath0-th order @xmath1-cherry tree pd which gives at least as good approximation as @xmath64 does i.e. : @xmath66 hence this result we consider as search space the @xmath0-th order @xmath1-cherry junction tree pd s .    in this part we first give a greedy algorithm to minimize the kullback - leibler divergence between the true probability distribution and a @xmath1-cherry junction tree pd given the @xmath0-th order marginal probability distributions .",
    "we then compare our algorithm with malvestuto s algorithm from analytical point of view .",
    "then we apply the two algorithms to the same sample data proposed in @xcite .    in @xcite",
    "the authors give the following theorem .",
    "[ theo:2 ] the kullback - leibler divergence between the true @xmath62 and the approximation given by the @xmath0-width junction tree probability distribution @xmath67 , determined by the set of clusters @xmath21 and the set of separators @xmath22 is : @xmath68 where @xmath69 represents the information content of the random vector @xmath70 and similarly @xmath71 represents the information content of the random vector @xmath72 .    in formula ( [ equ :",
    "equ1 ] ) @xmath73 is independent from the structure of the junction tree .",
    "it is easy to see that minimizing the kullback - leibler divergence means maximizing @xmath74 .",
    "we call this sum as _ weight of the junction tree pd_. as larger this weight is , as better fits the approximation associated to the junction tree pd to the true probability distribution .",
    "it is well known that @xmath75 if @xmath76 .    in the case when the approximating probability distribution is given by a @xmath0-th order @xmath1-cherry junction tree pd all of the clusters contain @xmath0 and all of the separators contain @xmath77 vertices in formula ( [ equ : equ1 ] ) .",
    "let @xmath78a set of random variables .",
    "[ def : def4 ] we define the following concepts :    * the search space : + @xmath79 , * the weight function : + @xmath80 .    [ alg:2 ]",
    "szntai - kovcs s greedy algorithm .",
    "_ input _ : elements of e and their weights which can be calculated based on the @xmath0-th order marginal probability distributions .",
    "_ output _ : set a which contains the clusters of the @xmath0-th order @xmath1-cherry juntion tree pd and the wheight of the @xmath0-th order @xmath1-cherry junction tree pd .    _",
    "the algorithm _ :    @xmath81    sort @xmath82 into monotonically decreasing order by wheight @xmath83 ;    choose @xmath84 ;    let @xmath85 ;    do for each @xmath86 taken in monotonically decreasing order    if @xmath87 then let @xmath88    if the union of subsets of @xmath89 is @xmath90 , then stop ;    else take the next element of @xmath82 .    in our @xmath1-cherry juntion tree terminology the kl divergence formula used by malvestuto in his paper @xcite is :    @xmath91    in order to minimize the kl divergence malvestuto had to minimize @xmath92 in a greedy way .",
    "malvestuto s algorithm uses the same search space @xmath82 and independence set @xmath93 . the wheight function however is different :    @xmath94 .",
    "[ alg:3 ] malvestuto s greedy algorithm .",
    "_ input _ : elements of e and their weights which can be calculated based on the @xmath0-th order marginal probability distributions .",
    "_ output _ : set a which contains the clusters of the @xmath0-th order @xmath1-cherry juntion tree probability distribution and the wheight of the @xmath0-th order @xmath1-cherry junction tree .",
    "@xmath81    sort @xmath82 into monotonically increasing order by wheight @xmath83 ;    chose @xmath95    let @xmath96    do for each @xmath86 taken in monotonically increasing order    if @xmath87 then let @xmath97    if the union of subsets of @xmath89 is @xmath90 , then stop ;    else take the next element of @xmath82 .",
    "we present experimental results on the application of the two algorithms to the probability distribution obtained from the sample data published in the paper @xcite .",
    "these data contain informations on the structural habitat of grahami and opalinus lizards .",
    "they were published originally by bishop et al @xcite and we give them in table [ tab:1 ] .",
    "cccc cell ( @xmath98 ) & observed & cell ( @xmath98 ) & observed + 1 1 1 1 1 & 20 & 1 2 2 3 1 & 8 + 2 1 1 1 1 & 13 & 2 2 2 3 1 & 4 + 1 2 1 1 1 & 8 & 1 1 1 1 2 & 2 + 2 2 1 1 1 & 6 & 1 2 1 1 2 & 3 + 1 1 2 1 1 & 34 & 1 1 2 1 2 & 11 + 2 1 2 1 1 & 31 & 2 1 2 1 2 & 5 + 1 2 2 1 1 & 17 & 1 2 2 1 2 & 15 + 2 2 2 1 1 & 12 & 2 2 2 1 2 & 1 + 1 1 1 2 1 & 8 & 1 1 1 2 2 & 1 + 2 1 1 2 1 & 8 & 1 2 1 2 2 & 1 + 1 2 1 2 1 & 4 & 1 1 2 2 2 & 20 + 1 1 2 2 1 & 69 & 2 1 2 2 2 & 4 + 2 1 2 2 1 & 55 & 1 2 2 2 2 & 32 + 1 2 2 2 1 & 60 & 2 2 2 2 2 & 5 + 2 2 2 2 1 & 21 & 1 1 1 3 2 & 4 + 1 1 1 3 1 & 4 & 1 2 1 3 2 & 3 + 2 1 1 3 1 & 12 & 2 2 1 3 2 & 1 + 1 2 1 3 1 & 5 & 1 1 2 3 2 & 10 + 2 2 1 3 1 & 1 & 2 1 2 3 2 & 3 + 1 1 2 3 1 & 18 & 1 2 2 3 2 & 8 + 2 1 2 3 1 & 13 & 2 2 2 3 2 & 4 +    the data consists of observed counts for perch height ( @xmath99 or @xmath100)@xmath101 , perch diameter ( @xmath102 or @xmath103)@xmath104 , insolation ( sun , shade) @xmath105 , time of day categories ( early , midday , late ) @xmath106 , lizard type ( grahami , opalinus)@xmath107 .",
    "the size of the contingeny table is @xmath108 .",
    "first we compare the goodness of fit of the 4-th order @xmath1-cherry junction tree found by szntai - kovcs s algorithm , then by malvestuto s algorithm .    in table",
    "[ tab:2 ] one can see the information contents of the marginal probability distribution of 4 random variables , 3 random variables and the weights used in szntai - kovcs s algorithm , ordered in decreasing way .",
    "ccccc indices of the & indices of the & @xmath109 & @xmath110 & @xmath111 + cluster variables & separator variables & & & + & 1 3 5 & * 0.129381 * & 0.045701 & 0.083680 + 1 3 4 5 & 1 4 5 & 0.129381 & 0.047533 & 0.081848 + 2 3 4 5 & 2 3 5 & 0.116608 & 0.035137 & 0.081470 + 1 2 3 4 & 1 2 3 & 0.105531 & 0.026624 & 0.078907 + 2 3 4 5 & 2 4 5 & 0.116608 & 0.038063 & 0.078544 + 1 2 3 4 & 1 2 4 & 0.105531 & 0.029315 & 0.076216 + 1 2 4 5 & 1 2 4 & 0.100251 & 0.029315 & 0.070936 + 1 3 4 5 & 1 3 4 & 0.129381 & 0.066088 & 0.063294 + 1 2 3 5 & 1 2 3 & 0.089070 & 0.026624 & 0.062446 + 1 2 4 5 & 2 4 5 & 0.100251 & 0.038063 & 0.062187 + 1 2 3 5 & 2 3 5 & 0.089070 & 0.035137 & 0.053933 + * 1 2 4 5 * & * 1 4 5 * & 0.100251 & 0.047533 & * 0.052718 * +    the junction tree obtained by szntai - kovcs s algorithm has two clusters @xmath112 , @xmath113 and one separator @xmath114 . the kl divergence in this case is : @xmath115    in table [ tab:3 ] one can see the entropy of the marginal probability distribution of 4 random variables , 3 random variables and the weights used in malvestuto s algorithm , ordered in increasing way .    the junction tree obtained by malvestuto s algorithm has two clusters @xmath116 @xmath117 and one separator @xmath118 .",
    "the kl divergence in this case is : @xmath119    ccccc indices of the & indices of the & @xmath120 & @xmath121 & @xmath122 + cluster variables & separator variables & & & + & & * 3.288813 * & & + * 1 3 4 5 * & * 1 3 5 * & 3.743757 & 2.368490 & * 1.375267 * + 2 3 4 5 & 2 3 5 & 3.783647 & 2.406170 & 1.377478 + 1 2 3 4 & 1 2 3 & 3.943287 & 2.563246 & 1.380041 + 1 2 4 5 & 1 2 5 & 4.046977 & 2.615873 & 1.431104 +    the two results of kl divergence reflect that the junction tree obtained by our algorithm fits better to the probability distribution of the sample data .",
    "if the task is fitting a third order @xmath1-cherry junction tree , then our algorithm finds a @xmath1-cherry junction tree probability distribution , with @xmath123 .",
    "the third order @xmath1-cherry junction tree given by malvestuto s algorithm has the @xmath124 .",
    "the clusters found by our algorithm were @xmath125 , @xmath114 , @xmath126 and those found by malvestuto s algorithm were @xmath127 , @xmath126 , @xmath128 .",
    "this part contains some theoretical discussions on the algorithm introduced , regarding to assumptions related to the markov network underlying the variables .",
    "as we remind in the preliminary part a triangulated graph can be represented as a junction tree structure .",
    "if the graph is complete then the junction tree has only one cluster .    if a graph is not triangulated , then by adding edges it can be transformed into a triangulated graph .",
    "the problem of _ , , fill in as few edges as possible  _ is known to be np complete ( @xcite ) .",
    "a greedy algorithm was given by tarjan and yanakakis @xcite .",
    "if the vertices of a graph represent the indices of the random variables of a markov network with global markov property then by adding new edges to the graph results a markov network having the global markov property , too .",
    "if the graph associated to a markov network is not complete then it can be transformed into a triangulated graph by adding edges which is equivalent with a junction tree structure , let say of order @xmath0 . since the global markov property holds for this graph the probability distribution can be written as a product - division type , where the largest marginal probability distribution contains @xmath0 variables . a logical question which arises here is if the greedy algorithm does find the @xmath0-th order junction tree which gives the true probability distribution .",
    "for this question the answer is that under some assumption our greedy algorithm guaranties the optimal solution , which in this context is the true probability distribution .",
    "we need the following assertion :    [ lem:1 ] @xmath129 $ ] .",
    "@xmath130    [ rem : rem2 ] it is easy to see that maximizing @xmath131 is the same as maximizing @xmath132 .",
    "we introduce the following notations .",
    "let @xmath133 be the set of all possible @xmath0-element subsets of @xmath5 .",
    "let @xmath134 be defined as @xmath135 and let    @xmath136    we prove the following two theorems .",
    "[ theo:3 ] if * x * has a _",
    "k_-th order _",
    "t_-cherry tree representation then @xmath137is a cluster of the junction tree .",
    "we make the proof by contradiction .",
    "we suppose @xmath138 .",
    "let us consider the smallest subjunction tree which contains all the vertices @xmath139 at least once . in this subjunction tree one of the vertices",
    "@xmath139 is a simplicial vertex ( a vertex which is contained in one cluster only ) . for simplicity",
    "let this vertex be @xmath140 and the cluster which contains it @xmath141 , with @xmath142 .",
    "we emphasize here that it is not necessary that @xmath143 .",
    "since @xmath140 is a simplicial vertex @xmath144 depends on all the other random variables of the subjunction tree only through its neighbours @xmath145 , therefore    @xmath146 using lemma [ lem:1 ] this inequality is equivalent to : @xmath147 \\vspace{2 mm } \\\\ < & h\\left ( x_{i_1}\\right ) -\\left [ i\\left ( x_{i_1},x_{i_2},\\ldots , x_{i_{k}}\\right ) -i\\left ( x_{i_2},\\ldots , x_{i_{k}}\\right ) \\right ] \\end{array}\\ ] ] that is @xmath148 which is in contradiction with the hypothesis that @xmath149 .    in the following we introduce the so called puzzle - algorithm , wich results a special numbering of the verticies of t - cherry junction tree .    [ alg:4 ] puzzle algorithm",
    "_ input _ : a @xmath0-th order @xmath1-cherry juncton tree @xmath150 , ( acyclic hypergraph with edges of size k , and separators of size k-1 )    _ output _ : a numbering @xmath151 of the verticies of @xmath152 .",
    "_ step _ 1 . _",
    "let @xmath153 , call it parent edge .",
    "the verticies belonging to the parent edge are    numbered in an arbitrary order by @xmath154 .",
    "@xmath155 , where for @xmath156 @xmath157 are all the @xmath77    element subset of @xmath158 .",
    "_ step _ 2 .",
    "_ iteration_.    do @xmath159 .    do if @xmath160 then take @xmath161 , which contains one of the elements @xmath162 of @xmath163 .",
    "set @xmath164 ,    assign @xmath165 to @xmath166 .",
    "@xmath167 , where for @xmath156 @xmath157 are all the @xmath77    element subset of @xmath168 go to step 2 .",
    "else stop .",
    "[ def : def5 ] the numbering @xmath169 of the verticies of @xmath170 obtained using algorithm [ alg:4 ] , is called _",
    "puzzle numbering_.    [ theo:4 ] if the following two assumptions are fulfilled then the szntai - kovcs algorithm finds the true probability distribution .",
    "\\(i ) the markov network can be transformed into a @xmath0-th order @xmath1-cherry tree by adding some edges if it is necessary .",
    "\\(ii ) starting from the parent cluster defined by ( [ equ : equ3 ] ) there exists a puzzle numbering with the following property : for all @xmath171 and for any @xmath172    @xmath173 where @xmath174 is the separator which separates @xmath175 from the tree containing the verticies @xmath176    we proved in theorem [ theo:3 ] that the cluster @xmath177 which satisfies ( [ equ : equ3 ] ) is a cluster of the junction tree associated to the markov network .",
    "we choose this cluster as parent edge .",
    "let us suppose that the szntai - kovcs algorithm , has in the constructed junction tree already @xmath178 verticies .",
    "we denote this set of verticies by @xmath179 .",
    "the set of possible separators at this end is @xmath180 .",
    "the szntai - kovcs algorithm adds a new cluster by maximizing    @xmath181    according to remark [ rem : rem1 ] this is equivalent with maximizing    @xmath182    we suppose now by contradiction that @xmath183is not connected to the existing junction tree through @xmath184 . since the junction tree is a connected hypergraph , there exist two possibilities :    * @xmath183 is separated from the existing tree @xmath185 by another separator @xmath186 * there exists @xmath187 which is connected with the existing junction tree by @xmath188 , and the cluster @xmath189 is on the path between the existing tree @xmath185 and the cluster which contains @xmath183 .",
    "now we pove that none of the two possibilities can occur .    *",
    "if @xmath183 is separated from the existing tree @xmath185 by another separator @xmath190 then according to the global markov property we have : + @xmath191 + this implies that the kullback leibler between @xmath192 is 0 : @xmath193 thus @xmath194 on the other hand if @xmath184 does not separate @xmath183 from the existing tree then the kl between @xmath195 is positive : @xmath196 thus @xmath197 + from ( [ equ : equ5 ] ) and ( [ equ : equ6 ] ) we have @xmath198 . +",
    "according to remark [ rem : rem1 ] this implies @xmath199 which is in contradiction with maximization of ( [ equ : equ4 ] ) . * if on the path between the existing @xmath185 tree and the cluster which contains @xmath183there exists a cluster @xmath200 , where @xmath201,and@xmath188 , then according to the puzzle numbering @xmath202 . using and ( ii )",
    "we have : + @xmath203 + for any @xmath204 , and @xmath205 @xmath206 separator between @xmath207and the existing tree @xmath185 @xmath208 this is in contradiction with maximization of ( [ equ : equ4 ] ) .",
    "[ theo:5 ] if the the best aproximating @xmath0-th order t - cherry probability distribution has a puzzle numbering which starting from the parent cluster defined by ( [ equ : equ3 ] ) satisfies ( i ) and ( ii ) then the szntai - kovcs algorithm finds the best aproximating @xmath0-th order @xmath1-cherry probability distribution .    * for all @xmath209 , for any @xmath210 , @xmath211 , where @xmath212 is the separator which separates @xmath213 from the tree containing the verticies @xmath214 * for all @xmath215 @xmath216    let the cluster @xmath137 which satisfies ( [ equ : equ3 ] ) the first cluster of the junction tree .",
    "we choose this cluster as parent edge .",
    "let us suppose that the szntai - kovcs algorithm , has in the constructed junction tree already @xmath178 verticies .",
    "the set of possible separators at this end is @xmath180 .",
    "the szntai - kovcs algorithm adds a new cluster by maximizing    @xmath217    according to remark [ rem : rem1 ] this is equivalent with maximizing    @xmath218    we suppose now by contradiction that in the best approximating junction tree @xmath183 is not connected to the existing junction tree through @xmath184 . since the best approximating junction tree is a connected hypergraph there exist two possibilities :    * @xmath183 is separated from the existing tree @xmath185 by another separator @xmath186 * in the best approximating junction tree there exists @xmath187 which is connected with the existing junction tree by @xmath188 , and the cluster @xmath189 is on the path between the existing tree and the cluster which contains @xmath183 .",
    "now we pove that none of the two possibilities can occur .    *",
    "if @xmath183 is separated from the existing tree @xmath185 by another separator @xmath18 then according to the markov property we have : + @xmath219 + this implies that the kullback leibler between @xmath220 is given by : + @xmath221 + according to ( [ equ : equ7 ] ) @xmath222 and this implies that @xmath223 this is in contradiction with ( ii ) . * if on the path between the existing @xmath185 tree and the cluster which contains @xmath183there exists a cluster @xmath200 , where @xmath201,and@xmath188 , then according to the puzzle numbering @xmath202 and ( i ) we have : @xmath203 for any @xmath204 , and @xmath205 @xmath206 separator between @xmath207and the existing tree @xmath185 @xmath208 this is in contradiction with maximizing ( [ equ : equ8 ] ) .",
    "we give in this paper a greedy algorithm for fitting @xmath0-width junction tree approximation by minimizing the kullback - leibler divergence .",
    "the problem of finding the best approximation of this kind is generally an np - hard problem .",
    "we reduce the search space to the so called @xmath0-th order @xmath1-cherry junction tree probability distributions .",
    "we then compare our algorithm to malvestuto s algorithm .",
    "we proved that our algorithm in the first step finds a cluster which belongs to the junction tree .",
    "malvestuto s algorithm has not guarantee for this . beside this our formula for kullback - leibler divergence ( [ equ : equ1 ] ) detached a greater part which does not depend on the structure of the tree than malvestuto s formula ( [ equ : equ2 ] ) .      by discovering the @xmath1-cherry junction tree probability distribution assigned to a markov network",
    "we can obtain many information on the dependence structure underlying the random variables .",
    "this information can be used for storing the data in lower dimensional contingency tables .",
    "the method can be applied in classification problems where it is possible to select the  informative  variables which influence directly the classification variable , see @xcite .",
    "e. kovcs and t. szntai , on the approximation of discrete multivariate probability distribution using the new concept of @xmath1-cherry junction tree , lecture notes in economics and mathematical systems , 633 , proceedings of the ifip / iiasa / gamm workshop on coping with uncertainty , robust solutions , 2008 , iiasa , laxenburg , 3956 , ( 2010 )            szntai , t. and e. kovcs , hypergraphs as a mean of discovering the dependence structure of a discrete multivariate probability distribution , _ proc .",
    "conference applied mathematical programming and modelling ( apmod ) , 2008 _ , bratislava , 27 - 31 may 2008 , annals of operations research , to appear .",
    "t. szntai and e. kovcs , application of @xmath1-cherry junction trees in pattern recognition , broad research in artificial intelligence and neuroscience ( brain ) , special issue on complexity in sciences and artificial intelligence , eds .",
    "b. iantovics , d. radoiu , m. marusteri and m. dehmer , 4045 , ( 2010 )"
  ],
  "abstract_text": [
    "<S> in our paper @xcite we introduced a special kind of @xmath0-width junction tree , called @xmath0-th order @xmath1-cherry junction tree in order to approximate a joint probability distribution . </S>",
    "<S> the approximation is the best if the kullback - leibler divergence between the true joint probability distribution and the approximating one is minimal . </S>",
    "<S> finding the best approximating @xmath0-width junction tree is np - complete if @xmath2 ( see in @xcite ) . in @xcite </S>",
    "<S> we also proved that the best approximating @xmath0-width junction tree can be embedded into a @xmath0-th order @xmath1-cherry junction tree . </S>",
    "<S> we introduce a greedy algorithm resulting very good approximations in reasonable computing time .    in this paper </S>",
    "<S> we prove that if the markov network underlying fullfills some requirements then our greedy algorithm is able to find the true probability distribution or its best approximation in the family of the @xmath0-th order @xmath1-cherry tree probability distributions . </S>",
    "<S> our algorithm uses just the @xmath0-th order marginal probability distributions as input .    </S>",
    "<S> we compare the results of the greedy algorithm proposed in this paper with the greedy algorithm proposed by malvestuto @xcite .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}