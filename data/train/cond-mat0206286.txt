{
  "article_text": [
    "recent research has shown that the bayesian inference is a useful approach to the image restoration problem @xcite-@xcite .",
    "however , previous research has usually assumed that the superimposed noise is not correlated between pixels @xcite-@xcite .",
    "statistical mechanics provides a useful method for analyzing the image restoration problem @xcite,@xcite .",
    "still , when we take optical effects into consideration , it seems natural to take spatially correlated noise into account .",
    "we have investigated image restoration under the condition of spatially correlated noise .",
    "we considered a case in which both the original image and noise obey a gaussian distribution composed of translational - symmetric matrices .",
    "we were able to diagonalize the gaussian distribution by using fourier transformation . while previous research was done using spatially uncorrelated noise , we considered the availability of a spatially uncorrelated noise model against spatially correlated noise .",
    "we considered tow methods for estimating the hyperparameters .",
    "the first is minimizing the mean squared error - the hyperparameters are set so that the mean squared error is minimized . however , minimizing the mean squared error is not applicable to the image restoration problem because we need the original image to practice this method .",
    "the second method is maximizing the marginal likelihood @xcite - the hyperparameters are estimated by maximizing the marginal likelihood acquired from only the distorted image .",
    "when the noise probabilities for generating and restoring coincidence are the same , the results given by the two methods are the same . when the probabilities are different , we found that they are not .",
    "the images we see in our daily life are always two - dimensional , although we assume a @xmath0-dimensional image for mathematical generalization , where the length of each side is @xmath1 and the total number of pixels , @xmath2 , is @xmath3 .",
    "the @xmath4-th pixel value , @xmath5 , of an original image can be written in a multiple gaussian distribution as @xmath6 , \\label{prior}\\ ] ] @xmath7 where @xmath8 and  @xmath9 are positive scalar values , @xmath10 is a matrix , and @xmath11 is the unit matrix . the partition function , @xmath12 , is given by    @xmath13    note that eq .",
    "( [ hamil ] ) is called the hamiltonian in statistical mechanics . in this paper , we argue that matrix @xmath10 is translational invariant and that element @xmath14 is given by @xcite    @xmath15    where the @xmath0-dimensional vector @xmath16 is    @xmath17    the @xmath18 in eq .",
    "( [ greeng ] ) is the kronecker delta , which is assumed to be    @xmath19    equation ( [ greeng ] ) means that interactions occur only between nearest - neighbor pixels .",
    "if @xmath8 takes a large value , i.e. , the interaction of the first term has a large effect , the neighboring pixels tend to take the same value .",
    "when @xmath9 is large , the absolute value of the pixels tends to be small .",
    "furthermore , we use a periodic boundary condition ,    @xmath20    the distorted image , @xmath21 , is generated according to the following conditional probability , which obeys a gaussian distribution : @xmath22,\\label{noize}\\ ] ] @xmath23 where @xmath24 is a translational invariant covariance matrix . in this paper",
    ", we consider the following spatially correlated noise :    @xmath25,\\ ] ]    @xmath26 .",
    "the noise obeys an identical independent gaussian distribution with mean @xmath27 and variance @xmath28 , when @xmath29 .",
    "a general strategy commonly used in image restoration is to apply the bayes formulation to the posterior probability . here",
    ", @xmath30 is a restoration image based on the bayes formulation .",
    "when a distorted image , @xmath31 , is given , one can use the formulation to calculate the restored image , @xmath30 :    @xmath32          }          {              \\int d \\sigma              \\exp{\\left [ -h_{eff } \\right ] }          } , \\label{bayes}\\ ] ]    where    @xmath33    is an effective hamiltonian .",
    "since the covariance matrices given by eqs .",
    "( [ greeng ] ) and ( [ soukan ] ) are translational invariant , they can be diagonalized using the discrete fourier transformation .",
    "the discrete fourier transformation is @xmath34 and the inverse fourier transformation is    @xmath35    where @xmath36 is the imaginary unit , and @xmath37 is a @xmath0-dimensional vector with the same as @xmath38 , and the degree of freedom is @xmath3 .",
    "@xmath39 moreover , each component of @xmath40 takes the value @xmath41 we can diagonalize eq .",
    "( [ prior ] ) by using the fourier representation : @xmath42 ,      \\label{priorf}\\ ] ] @xmath43.\\ ] ] furthermore , we diagonalize @xmath44 in eq .",
    "( [ soukan ] ) :    @xmath45    where the range of @xmath46 , which is a component of vector @xmath47 , is given by    @xmath48    we can execute the fourier transformation on the inside of @xmath49 in eq . ( [ noize ] ) in the same way as in eq .",
    "( [ prior ] ) .",
    "@xmath50 . \\label{pout}\\end{aligned}\\ ] ]    we define @xmath51 as denoting the thermal average based on the bayes formula for the posterior probability @xmath52 in eq .",
    "( [ bayes ] ) .",
    "the expectation of the restored image , @xmath53 , is thus assumed to be @xmath54 using eq .",
    "( [ bayes ] ) , the expectation of the fourier component , @xmath55 , can be written as @xmath56 where @xmath57 is obtained by applying the fourier transformation to eq .",
    "( [ yuukoua ] ) as follows .",
    "@xmath58 @xmath8 , @xmath9 , and @xmath59 are unknown adjustable parameters that determine the properties of the original image and noise .",
    "one of our major focus here is how to estimate these hyperparameters precisely .    to proceed further",
    ", we have to assume some explicit form of the source prior and noise posterior formations , which are used when we restore the image . in this paper",
    ", we define both of these probability formations as the same formation except that they have different hyperparameters .",
    "we define the hyperparameters that correspond to @xmath60 , and @xmath59 as @xmath61 , @xmath62 , and @xmath63 , respectively .",
    "if @xmath63 is independent of @xmath37 , the noise is spatially uncorrelated .    substituting @xmath64 [ okikae ] into eqs .",
    "( [ kakkonai ] ) and ( [ yuukou ] ) , we get @xmath65 consequently , @xmath66 in eq .",
    "( [ repair ] ) is given by @xmath67          }          {              \\hat{\\beta } \\tilde{g}_{{\\mbox{\\boldmath $ k$}}}+\\hat{h }                  + \\frac{1}{2\\hat{\\tilde{r}}_{{\\mbox{\\boldmath $ k$ } } } }          } .\\label{e1kaiseki}\\ ] ] in this paper , we regard eq .",
    "( [ e1kaiseki ] ) as representing the restored image .      in this subsection , we estimate hyperparameters @xmath68 , and @xmath63 by using the criterion defined by eq .",
    "( [ e1kaiseki ] ) for minimizing the mean squared error between the original and restored images .",
    "the expectation of this mean squared error , @xmath69 , is represented by @xmath70 where @xmath71 denotes the data average of a simultaneous distribution + @xmath72 .    applying the fourier transformation to eq .",
    "( [ e1 ] ) , we can derive the next representation .",
    "@xmath73 since @xmath74 is diagonalized by the fourier transformation , we can easily calculate each @xmath40 as follows , @xmath75\\\\      & = & \\frac{1}{2\\tilde{a}_{{\\mbox{\\boldmath $ k$}}}}+          \\left (              \\frac{\\tilde{b}_{{\\mbox{\\boldmath $ k$}}}}{\\tilde{a}_{{\\mbox{\\boldmath $ k$ } } } }              -\\frac{\\hat{\\tilde{b}}_{{\\mbox{\\boldmath $ k$}}}}{\\hat{\\tilde{a}}_{{\\mbox{\\boldmath $ k$ } } } }          \\right)^2          \\frac{1 } {                  2\\tilde{b}_{{\\mbox{\\boldmath $ k$ } } }                  -\\frac{2\\tilde{b}_{{\\mbox{\\boldmath $ k$}}}^2}{\\tilde{a}_{{\\mbox{\\boldmath $ k$ } } } }          } , \\label{11}\\end{aligned}\\ ] ] where @xmath76 , @xmath77 , and @xmath78 substitute for @xmath79 @xmath80.\\end{aligned}\\ ] ] therefore , the mean squared error is represented by @xmath81.\\label{eend}\\end{aligned}\\ ] ] when the conditions @xmath82 hold , the mean squared error takes the following minimum : @xmath83\\label{saitei},\\ ] ] more precisely , when the ratio @xmath84 is equal to the ratio @xmath85 , @xmath69 is the minimum given by eq .",
    "( [ saitei ] ) .",
    "note that this equation represents the limit of the restoration .",
    "likewise , we can derive the mean squared error , @xmath86 , between the original image and the distorted image as being represented by @xmath87 @xmath86 depends only on the diagonal element of the noise covariance matrix",
    ".      the minimized mean squared error criterion generally can not be used since the unknown original image itself is needed to evaluate the squared error .",
    "if we already had the original image , there would be no need to restore the distorted image .",
    "hence , in this paper , we argue for using the maximization of the marginal likelihood .    as shown in eqs .",
    "( [ prior ] ) and ( [ noize ] ) , we already know the source prior and noise probabilities . using both probabilities , we can derive @xmath88 :    @xmath89    @xmath88 is called the marginal likelihood .    maximization of the marginal likelihood is used to set the hyperparameters , @xmath68 , and @xmath90 , to use to obtain the maximum value of @xmath91 for distorted image @xmath31 .    with eqs .",
    "( [ zprior ] ) and ( [ znoize ] ) , the marginal likelihood is given by @xmath92 where @xmath93.\\label{zpost}\\end{aligned}\\ ] ] because @xmath94 is a monotonically increasing function that maximizes the logarithmic marginal likelihood , maximizing @xmath95 is equivalent to maximizing @xmath91 .",
    "the logarithmic marginal likelihood @xmath95 can be written as , @xmath96",
    "in this section , we consider a method to restore an image distorted by spatially correlated noise by means of the spatially uncorrelated noise model . to do this ,",
    "we replace @xmath24 as one of the hyperparameters : @xmath97 we can now write eq .",
    "( [ e1kaiseki ] ) as @xmath98          }          {              \\hat{\\beta } \\tilde{g}_{{\\mbox{\\boldmath $ k$}}}+\\hat{h }                  + \\frac{1}{2\\hat{r } }          } .\\label{junsaiteki}\\ ] ]     from eq .",
    "( [ soukan ] ) ; vertical axis denotes mean squared error . ( a ) optimum decode given by eq .",
    "( [ saitei ] ) .",
    "( b ) restored using criterion of minimum restored error .",
    "( c ) restored using @xmath99 estimated by maximizing marginal likelihood .",
    "( d ) restored using @xmath68 , and @xmath99 , all estimated by maximizing marginal likelihood .",
    "( e ) error before decoding given by eq .",
    "( [ kaisekie2 ] ) .",
    ", width=321 ]    .",
    "horizontal axis denotes @xmath100 from eq .",
    "( [ soukan ] ) ; vertical axis denotes average estimated @xmath99 obtained by maximizing marginal likelihood or optimal @xmath99 obtained using criterion of minimum restored error .",
    "solid line ( b ) denotes @xmath99 used in fig .",
    "[ kekkagraf](b ) , dashed line ( c ) denotes @xmath99 used in fig .",
    "[ kekkagraf](c ) , and dotted line ( d ) denotes @xmath99 used in fig .",
    "[ kekkagraf](d ) . , width=302 ]     ( dotted line ) and @xmath61 ( dashed line ) .",
    "both values were averaged with respect to 100 artificially generated images .",
    "horizontal axis denotes @xmath100 from eq .",
    "( [ soukan ] ) ; vertical axis denotes average estimated @xmath62 or @xmath61 or actual @xmath9 or @xmath8 .",
    "solid line denotes actual @xmath101 ) .",
    ", width=302 ]    figure [ kekkagraf ] shows the analytical and simulated mean squared errors between the original image and each restored image , fig .",
    "[ reps ] shows the estimated @xmath99 , and fig .",
    "[ hbeps ] show the estimated parameters @xmath62 and @xmath61 .",
    "we used 100 artificially generated two - dimensional @xmath102 images with hyperparameters @xmath103 , @xmath104 , @xmath105 , and @xmath106 .",
    "the horizontal axes of these three figures denote @xmath100 from eq .",
    "( [ soukan ] ) ; @xmath100 represents the magnitude of the spatial correlation of the noise ( @xmath29 implies no spatial correlation ) .      curve ( e ) in fig .",
    "[ kekkagraf ] represents error @xmath86 given by eq .",
    "( [ kaisekie2 ] ) , that is , the mean squared error between the original and distorted images .",
    "( the dashed line represents the analytical error , and the solid line represents the simulated results . ) because the numbers of pixels ( @xmath102 ) and samples ( @xmath107 ) were finite , the simulated results have some fluctuation .",
    "this fluctuation tends to asymptotically disappear as the numbers are increased .",
    "curve ( a ) in fig .",
    "[ kekkagraf ] represents minimum error @xmath108 given by eq .",
    "( [ saitei ] ) , that is , the mean squared error between the original and distorted images restored using the spatially correlated noise model with the best parameters .",
    "hence , @xmath108 implies the limits of image restoration - no further error reduction is possible .",
    "curve ( b ) in fig .",
    "[ kekkagraf ] represents the error in an image restored using the uncorrelated noise model .",
    "the restoration was done using hyperparameter @xmath99 from eq .",
    "( [ e1 ] ) , which was acquired minimizing the mean squared error .",
    "( the dashed line represents the analytical results , and the solid line represents the simulated results . ) curve ( b ) in fig .",
    "[ reps ] shows the optimal values of @xmath99 by minimizing the mean squared error .    note that when @xmath109 , curve ( a ) in fig .",
    "[ kekkagraf ] is equal to curve ( b ) .",
    "curve ( b ) in fig .",
    "[ kekkagraf ] shows the optimum performance when using the minimization of the mean squared error as the criterion .",
    "however , as mentioned , the hyperparameters can not be estimated in practice by minimizing the mean squared error .",
    "therefore , we will discuss how the error can be reduced by maximizing the logarithmic marginal likelihood in the next subsection .",
    "substituting eq .",
    "( [ syuhen2 ] ) for eq .",
    "( [ kinjif ] ) , we get @xmath110 we can derive the conditions necessary for the extremal @xmath111 , and we can represent them using the following nonlinear simultaneous equations .",
    "@xmath112,\\label{b}\\end{aligned}\\ ] ] @xmath113 @xmath114.\\label{h}\\end{aligned}\\ ] ] we can then determine the convergence point by means of an iterative calculation .",
    "we next determined the unknown hyperparameter , @xmath99 , by maximizing the marginal likelihood , assuming that @xmath115 and @xmath116 .",
    "thus , we restricted ourselves to the case where the generation model of the image was already known , as was @xmath8 and @xmath9 . curve ( c ) in fig . [ kekkagraf ] shows the mean squared error when the image was restored using the estimated @xmath99 .",
    "curve ( c ) in fig .",
    "[ reps ] shows the estimated @xmath99 .",
    "note that the difference between curve ( b ) in fig .",
    "[ reps ] , the limit of the restoration , and curve ( c ) , obtained by minimizing the mean squared error increased with the noise correlation parameter , @xmath100 .",
    "therefore , the error obtained by maximizing the marginal likelihood ( curve ( c ) in fig .",
    "[ kekkagraf ] ) increases with the noise correlation parameter , @xmath100 .",
    "this implies that without knowing the noise model , estimating the hyperparameters by maximizing the marginal likelihood does not work well . that is , the conventional uncorrelated noise model can not cope with spatially correlated noise",
    ".    to confirm this , we used maximization of the marginal likelihood to estimate @xmath61 and @xmath62-the hyperparameters of the image - generation probability - as well as @xmath99 . curve ( d ) in fig .",
    "[ kekkagraf ] shows the mean squared error estimated using hyperparameters @xmath61 , @xmath62 , and @xmath99 .",
    "curve ( d ) in fig . [ reps ] shows the obtained @xmath99 , and fig .",
    "[ hbeps ] shows the obtained @xmath61 and @xmath62 .",
    "the error shown by curve ( d ) in fig .",
    "[ kekkagraf ] is much greater than that shown by curve ( c ) .    ; left vertical axis denotes mean squared error ( b ) given by eq.([eend ] ) ; right vertical axis denotes logarithmic marginal likelihood ( c ) given by eq.([syuhenapp ] ) .",
    "the parameters were @xmath117 , @xmath103 , @xmath118 , and @xmath119 .",
    "those used for ( b ) correspond to those for curve ( b ) in fig .",
    "[ kekkagraf ] when @xmath117 .",
    "likewise , those used for ( c ) correspond to those for curve ( c ) in fig .",
    "[ kekkagraf](c ) when @xmath117 .",
    ", width=302 ]    next , we demonstrate that the logarithmic marginal likelihood , curve ( c ) in fig . [ kekkagraf ] , does not have a local maximum and that the iteratively obtained solution of eq .",
    "( [ q ] ) corresponds to the global maximum .",
    "curve ( b ) in fig .",
    "[ yuudo ] shows the mean squared error , @xmath69 , given by eq.([eend ] ) , and curve ( c ) shows the logarithmic marginal likelihood , @xmath120 , given by eq .",
    "( [ syuhenapp ] ) .",
    "the horizontal axis denotes @xmath99 .",
    "curve ( b ) shows that @xmath69 takes a minimum value , @xmath121 , at @xmath122 .",
    "the parameters used for curve ( b ) correspond to those for curve ( b ) in fig .",
    "[ kekkagraf ] when @xmath117 . curve ( c ) shows that that the logarithmic marginal likelihood takes a maximum value , @xmath123 , at @xmath124 .",
    "the parameters used for curve ( c ) correspond to those for curve ( c ) in fig .",
    "[ kekkagraf ] when @xmath117 .",
    "the important point is that the logarithmic marginal likelihood , curve ( c ) in fig .",
    "[ yuudo ] , does not have a local maximum .",
    "next , we show the practical significance of these differences for a typical set of artificial images .    .",
    ", width=283 ]    figure [ art](a ) shows an original image generated using hyperparameters @xmath125 and @xmath126 .",
    "figure [ art](c ) shows the same image after it was distorted by the noise shown in fig .",
    "[ art](b ) ( @xmath127 , and @xmath106 ) .",
    "the mean squared error , @xmath86 , between the original and distorted images was 0.57 .",
    "figure [ art](d ) shows the image after it was restored using the complete restoration model : the generation model and noise model were consistent with the original models , and optimum values were used for the hyperparameters . when @xmath117 , curve ( a ) in fig .",
    "[ kekkagraf ] corresponds to fig .",
    "[ art](d ) , and the restored mean squared error , @xmath69 , is 0.27 . figure [ art](e ) shows the image after it was restored using an uncorrelated noise model with hyperparameters obtained by maximizing the marginal likelihood . when @xmath117 , curve ( d ) in fig .",
    "[ kekkagraf ] corresponds to fig .",
    "[ art](e ) , and the restored mean squared error is 0.45 . the image in fig .",
    "[ art](d ) resembles the original one , fig .",
    "[ art](a ) , while the one in fig .",
    "[ art](e ) is similar to the distorted one in fig .",
    "[ art](c ) and looks slightly out of focus .",
    "furthermore , we show the results when natural images were used .    .",
    ", width=254 ]    figure [ natural ] shows the natural images and a table of the estimated parameters .",
    "we used @xmath128 and @xmath119 for the noise parameters and three values for @xmath100 : 0.0 , 0.5 , and 1.0 .",
    "the three images on the left are distorted , and those on the right are the same images restored using @xmath61 , @xmath62 , and @xmath99 estimated using the maximized marginal likelihood . in this simulation",
    "as well , @xmath69 increased with the noise correlation parameter , @xmath100 .",
    "this tendency is reflected in the three restored images . for @xmath117 , the lower right image ,",
    "the noise looks like a stain that was not completely removed .      here",
    ", we consider why line ( a ) in fig .",
    "[ kekkagraf ] tends to decrease as @xmath100 approaches @xmath129 .",
    "this phenomenon appears to be universal , and also occurs with another parameter set as shown in fig .",
    "[ a_eps](ii ) . for reference",
    ", we also show line ( i ) which is based on the parameter set that was used in fig .",
    "[ kekkagraf](a ) with only @xmath2 changed to @xmath130 .",
    "( note that line ( a ) is independent of @xmath2 ) .     from eq .",
    "( [ soukan ] ) , and the vertical axis denotes the mean squared error . as a criterion ,",
    "the optimal decode given by eq .",
    "( [ saitei ] ) is used .",
    "the parameters @xmath105 , and @xmath130 are fixed .",
    "for the solid line ( i ) , the other parameters were set as @xmath131 , and @xmath106 .",
    "for the dashed line ( ii ) , the other parameters were set as @xmath132 , and @xmath133 .",
    ", width=302 ]    for the original image , we used the gaussian model represented by eq .",
    "( [ prior ] ) , which has neighboring interactions on each pixel . for the noise image",
    ", we used the gaussian model represented by eq .",
    "( [ noize ] ) , in which the interaction is gaussian functionally decreased .",
    "we expected the difference between these two models to become conspicuously large near @xmath117 , and this difference between the models would enable successful restoration near @xmath117 . figure [ samp_eps ] shows the typical images about fig .",
    "[ a_eps](ii ) .",
    "parameters for the original images were @xmath125 and @xmath134 .",
    "the three original prepared images were the same .",
    "parameters for noise images were @xmath135 , and @xmath105 .",
    "only @xmath100 was changed .",
    "note that when @xmath136 , the original and noise images were visually similar , and the restoration quality was lower in this case .",
    ", width=302 ]    the distorted image was most difficult to restore in fig .",
    "[ samp_eps ] when @xmath136 , as shown in fig .",
    "[ a_eps](ii ) . in this case , the original and the noise images were visually similar ; more precisely , the correlation lengths of the two images were similar .",
    "thus , to successfully restore a distorted image , it is desirable that the statistical properties of the original image should be different from those of the noise image .    here ,",
    "we summarize our explanation of why line ( a ) in fig .",
    "[ kekkagraf ] decreases near @xmath117 . as @xmath100 approaches @xmath129",
    ", the mean squared error decreases because the difference of the statistical properties , especially the correlation length , between the two images enables easier restoration .",
    "conversely , the mean squared error is greater at @xmath136 on line ( ii ) in fig .",
    "[ a_eps ] because the correlation - length similarity between the images makes it difficult to distinguish between them , and that also makes it difficult to restore the distorted image . to ensure successful restoration ,",
    "the correlation length of the original image should be different from that of the noise image , which is the case when @xmath137 and @xmath138 in fig .",
    "[ samp_eps ] .",
    "we investigated the use of the bayesian inference to restore images under conditions of spatially correlated noise .",
    "we assumed that both the original image and the noise obeyed a gaussian distribution composed of translational symmetric matrices .",
    "we used the fourier transformation to diagonalize the covariance matrices , which enabled us to apply various forms of statistical analysis .",
    "we obtained the expected value of a restored image and obtained the optimal analytical hyperparameters by minimizing the mean squared error and used these hyperparameters to determine the generation and noise models .",
    "furthermore , we discussed whether the conventional spatially uncorrelated noise model could cope with the spatially correlated noise or not .",
    "we used two methods to estimate the hyperparameters : minimizing the mean squared error and maximizing the marginal likelihood .",
    "the difference between the errors obtained using the two methods increased with the noise correlation parameter .",
    "the restoration error was larger when we used the hyperparameters obtained using the maximization of the marginal likelihood method .",
    "thus , the conventional spatially uncorrelated noise model could not cope with the spatially correlated noise .",
    "99 r. morina , , * 8 * , 231 ( 1999 ) .",
    "r. morina and k. katsaggelos , , * 8 * , 231 ( 1999 ) .",
    "j. inoue and k. tanaka , , * 65*,016125 - 1 ( 2002 ) .",
    "h. nishimori and k. y. m .wong , , * 60 * , 132 ( 1999 ) .",
    "h. nishimori , , * 73 * , 850 ( 2000 ) . k. tanaka and j. inoue , , e*84 * -d , 546 ( 2002 ) .",
    "h. derin , h. elliott , r. cristi , and d. geman , , * 6 * , 707 ( 1984 ) . s. geman and d. geman , , * 6 * , 721 ( 1984 )",
    ". j. inoue , , * 60 * , 2547 ( 1999 ) .",
    "j. inoue , , * 63 * 046114 ( 2001 ) .",
    "j. inoue , , * 64 * , 036121 ( 2001 ) .",
    "j. inoue and k. tanaka , , 383 ( 2001 ) ."
  ],
  "abstract_text": [
    "<S> we investigated the use of the bayesian inference to restore noise - degraded images under conditions of spatially correlated noise . </S>",
    "<S> the generative statistical models used for the original image and the noise were assumed to obey multi - dimensional gaussian distributions whose covariance matrices are translational invariant . </S>",
    "<S> we derived an exact description to be used as the expectation for the restored image by the fourier transformation and restored an image distorted by spatially correlated noise by using a spatially uncorrelated noise model . </S>",
    "<S> we found that the resulting hyperparameter estimations for the minimum error and maximal posterior marginal criteria did not coincide when the generative probabilistic model and the model used for restoration were in different classes , while they did coincide when they were in the same class . </S>"
  ]
}