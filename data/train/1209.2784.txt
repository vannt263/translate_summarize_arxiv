{
  "article_text": [
    "the essence of machine learning is to exploit what we observe in order to form accurate predictors of what we can not .",
    "a multi - task learning ( mtl ) algorithm learns an inductive bias to learn several tasks together .",
    "mtl is incredibly pervasive in machine learning : it has natural connections to random effects models @xcite ; user preference prediction ( including collaborative filtering ) can be framed as mtl @xcite ; multi - class classification admits the popular _ one - vs - all _ and _ all - pairs _ mtl reductions ; and mtl admits provably good learning in settings where single - task learning is hopeless @xcite .",
    "but if we see examples from a random set of tasks today , which of these tasks will matter tomorrow ? not knowing in the present what challenges nature has in store for the future , a sensible strategy is to mitigate the worst case by ensuring some minimum proficiency on each task",
    ".    consider a simple learning scenario : a music preference prediction company is in the business of predicting what 5-star ratings different users would assign to songs . at training time",
    ", the company learns a shared representation for predicting the users song ratings by pooling together the company s limited data on each user s preferences .",
    "given this learned representation , a separate predictor for each user can be trained very quickly . at test time",
    ", the environment draws a user according to some ( possibly randomized ) rule and solicits from the company a prediction of that user s preference for a particular song .",
    "the environment may also ask for predictions about new users , described by a few ratings each , and so the company must leverage its existing representation to rapidly learn new predictors and produce ratings for these new users .",
    "classically , multi - task learning has sought to minimize the ( regularized ) sum of the empirical risks over a set of tasks . in this way",
    ", classical mtl implicitly assumes that once the learner has been trained , it will be tested on test tasks drawn uniformly at random from the empirical task distribution of the training tasks .",
    "notably , there are several reasons why classical mtl may not be ideal :    = 1.5em    while at training time the usual flavor of mtl commits to a fixed distribution over users ( typically either uniform or proportional to the number of ratings available for each user ) , at test time there is no guarantee what user distribution we will encounter .",
    "in fact , there may not exist any fixed user distribution : the sequence of users for which ratings are elicited could be adversarial",
    ".    even in the case when the distribution over tasks is not adversarial , it may be in the interest of the music preference prediction company to guarantee some minimum level of accuracy per user in order to minimize negative feedback and a potential loss of business , rather than maximing the mean level of accuracy over all users .    whereas minimizing the average prediction error is very much a teleological endeavor ,",
    "typically at the expense of some locally egregious outcomes , minimizing the worst - case prediction error respects a notion of fairness to all tasks ( or people ) .",
    "this work introduces _",
    "minimax multi - task learning _ as a response to the above scenario .",
    "in addition , we cast a spectrum of multi - task learning . at one end of the spectrum",
    "lies minimax mtl , and departing from this point progressively relaxes the `` hardness '' of the maximum until full relaxation reaches the second endpoint and recovers classical mtl .",
    "we further sculpt a generalized loss - compositional paradigm for mtl which includes this spectrum and several other new mtl formulations .",
    "this paradigm equally applies to the problem of _ learning to learn _ ( ltl ) , in which the goal is to learn a hypothesis space from a set of training tasks such that this representation admits good hypotheses on future tasks . in truth ,",
    "mtl and ltl typically are handled equivalently at training time  this work will be no exception  and they diverge only in their test settings and hence the learning theoretic inquiries they inspire .",
    "[ [ contributions . ] ] contributions .",
    "+ + + + + + + + + + + + + +    the first contribution of this work is to introduce minimax mtl and a continuum of relaxations .",
    "second , we introduce a generalized loss - compositional paradigm for mtl which admits a number of new mtl formulations and also includes classical mtl as a special case .",
    "third , we empirically evaluate the performance of several mtl formulations from this paradigm in the multi - task learning and learning to learn settings , under the task - wise maximum test risk and task - wise mean test risk criteria , on four datasets ( one synthetic , three real ) .",
    "finally , theorem [ thm : max - true - risk ] is the core theoretical contribution of this work and shows the following : if it is possible to obtain maximum empirical risk across a set of training tasks below some level @xmath0 , then it is likely that the maximum true risk obtained by the learner on a new task is bounded by roughly @xmath0 .",
    "hence , if the goal is to minimize the worst case outcome over new tasks , the theory suggests minimizing the maximum of the empirical risks across the training tasks rather than their mean .    in the next section",
    ", we recall the settings of multi - task learning and learning to learn , formally introduce minimax mtl , and motivate it theoretically . in section [ sec :",
    "paradigm ] , we introduce a continuously parametrized family of minimax mtl relaxations and the new generalized loss - compositional paradigm .",
    "section [ sec : experiments ] presents an empirical evaluation of various mtl / ltl formulations with different models on four datasets .",
    "finally , we close with a discussion .",
    "we begin with a promenade through the basic mtl and ltl setups , with an effort to abide by the notation introduced by baxter @xcite . throughout the rest of the paper ,",
    "each labeled example @xmath1 will live in @xmath2 for input instance @xmath3 and label @xmath4 .",
    "typical choices of @xmath5 include @xmath6 or a compact subset thereof , while @xmath7 typically is a compact subset of @xmath8 or the binary @xmath9 .",
    "in addition , define a loss function @xmath10 . for simplicity",
    ", this work considers @xmath11 loss ( squared loss ) @xmath12 for regression and hinge loss @xmath13 for classification .",
    "mtl and ltl often are framed as applying an inductive bias to learn a common hypothesis space , selected from a fixed family of hypothesis spaces , and thereafter learning from this hypothesis space a hypothesis for each task observed at training time .",
    "it will be useful to formalize the various sets and elements present in the preceding statement .",
    "let @xmath14 be a family of hypothesis spaces .",
    "any hypothesis space @xmath15 itself is a set of hypotheses ; each hypothesis @xmath16 is a map @xmath17 .",
    "[ [ learning - to - learn . ] ] learning to learn .",
    "+ + + + + + + + + + + + + + + + + +    in learning to learn , the goal is to achieve inductive transfer to learn the best @xmath18 from @xmath14 . unlike in mtl , there is a notion of an _ environment _ of tasks : an unknown probability measure @xmath19 over a space of task probability measures @xmath20 .",
    "the goal is to find the optimal representation via the objective @xmath21 in practice , @xmath22 ( unobservable ) training task probability measures @xmath23",
    "are drawn iid from @xmath19 , and from each task @xmath24 a set of @xmath25 examples are drawn iid from @xmath26 .",
    "[ [ multi - task - learning . ] ] multi - task learning .",
    "+ + + + + + + + + + + + + + + + + + + +    whereas in learning to learn there is a distribution over tasks , in multi - task learning there is a fixed , finite set of tasks indexed by @xmath27 : = \\{1 , \\ldots , t\\}$ ] .",
    "each task @xmath28 $ ] is coupled with a fixed but unknown probability measure @xmath26 .",
    "classically , the goal of mtl is to minimize the expected loss at test time under the uniform distribution on @xmath27 $ ] : @xmath29 } \\inf_{h \\in { \\mathcal{h } } }   { \\mathsf{e}}_{(x , y ) \\sim p_t } \\ell(y , h(x ) ) .",
    "\\label{eqn : mtl - goal}\\end{aligned}\\ ] ] notably , this objective is equivalent to when @xmath19 is the uniform distribution on @xmath30 . in terms of the data generation model , mtl differs from ltl since the tasks are fixed ; however , just as in ltl , from each task @xmath24 a set of @xmath25 examples are drawn iid from @xmath26 .      a natural generalization of classical mtl results by introducing a prior distribution @xmath31 over the index set of tasks @xmath27 $ ] . given @xmath31 , the ( idealized ) objective of this generalized mtl is @xmath32 given only the training data @xmath33}$ ] .",
    "the classical mtl objective equals when @xmath31 is taken to be the uniform prior over @xmath27 $ ] .",
    "we argue that in many instances , that which is most relevant to minimize is not the expected error under a uniform distribution over tasks , or even any pre - specified @xmath31 , but rather the expected error for the worst @xmath31 .",
    "we propose to minimize the maximum error over tasks under an adversarial choice of @xmath31 , yielding the objective : @xmath34 where the supremum is taken over the @xmath22-dimensional simplex . as the supremum ( assuming it is attained ) is attained at an extreme point of the simplex , this objective is equivalent to @xmath35 } \\inf_{h \\in { \\mathcal{h } } } { \\mathsf{e}}_{(x , y ) \\sim p_t } \\ell(y , h(x ) ) .",
    "\\label{eqn : mtl - true - minimax}\\end{aligned}\\ ] ]    in practice , we approximate the true objective by using the ( regularized ) empirical objective : @xmath35 } \\inf_{h \\in { \\mathcal{h } } } \\sum_{i=1}^m \\ell(y_{t , i } , h(x_{t , i } ) ) .\\end{aligned}\\ ] ]    in the next section , we motivate minimax mtl theoretically by showing that the worst - case performance on future tasks likely will not be much higher than the maximum of the empirical risks for the training tasks . in this short paper",
    ", we restrict attention to the case of finite @xmath14 .      in this subsection , we use the following notation .",
    "let @xmath36 be probability measures drawn iid from @xmath19 , and for @xmath28 $ ] let @xmath37 be an @xmath25-sample ( a sample of @xmath25 points ) from @xmath38 with corresponding empirical measure @xmath39 .",
    "also , if @xmath40 is as a probability measure then @xmath41 ; similarly , if @xmath42 is an empirical measure , then @xmath43 .",
    "our focus is the learning to learn setting with a minimax lens : when one learns a representation @xmath44 from multiple training tasks and observes maximum empirical risk @xmath0 , we would like to guarantee that @xmath18 s true risk on a newly drawn test task will be bounded by roughly @xmath0 .",
    "such a goal is in striking contrast to the classical emphasis of learning to learn , where the goal is to obtain bounds on @xmath18 s expected true risk . using @xmath18 s expected true risk and markov s inequality , baxter ( * ? ?",
    "* the display prior to ( 25 ) ) showed that the probability that @xmath18 s true risk on a newly drawn test task is above some level @xmath0 decays as the expected true risk over @xmath0 : @xmath45 } p^{(t)}_m \\ell \\circ h_t + \\varepsilon}{\\gamma } \\label{eqn : ltl - markov}\\end{aligned}\\ ] ] where the size of @xmath46 is controlled by @xmath22 , @xmath25 , and the complexities of certain spaces .",
    "the expected true risk is not of primary interest for controlling the tail of the ( random ) true risk , and a more direct approach yields a much better bound . in this short paper",
    "we restrict the space of representations @xmath14 to be finite with cardinality @xmath47 ; in this case , the analysis is particularly simple and illuminates the idea for proving the general case .",
    "the next theorem is the main result of this section :    [ thm : max - true - risk ] let @xmath48 , and let the loss @xmath49 be @xmath50-lipschitz in its second argument and bounded by @xmath51 .",
    "suppose @xmath22 tasks @xmath36 are drawn iid from @xmath19 and from each task @xmath38 an iid @xmath25-sample @xmath37 is drawn .",
    "suppose there exists @xmath15 such that all @xmath28 $ ] satisfy @xmath52 .",
    "let @xmath40 be newly drawn probability measure from @xmath19 .",
    "let @xmath53 be the empirical risk minimizer over the test @xmath25-sample .",
    "with probability at least @xmath54 with respect to the random draw of the @xmath22 tasks and their @xmath22 corresponding @xmath25-samples : @xmath55    in the above , @xmath56 is the rademacher complexity of @xmath18 ( cf .",
    "critically , in the probability of observing a task with high true risk decays with @xmath22 , whereas in the decay is independent of @xmath22 .",
    "hence , when the goal is to minimize the probability of bad performance on future tasks uniformly , this theorem motivates minimizing the _ maximum _ of the empirical risks as opposed to their mean .    for the proof of theorem [ thm : max - true - risk ] , first consider the singleton case @xmath57 .",
    "suppose that for @xmath0 fixed a priori , the maximum of the empirical risks is bounded by @xmath0 , i.e. @xmath58 } \\min_{h \\in { \\mathcal{h}}_1 } p_m^{(t ) } \\ell \\circ h \\leq \\gamma   $ ] .",
    "let a new probability measure @xmath40 drawn from @xmath19 correspond to a new test task .",
    "suppose the probability of the event @xmath59 $ ] is at least @xmath46 .",
    "then the probability that @xmath0 bounds all @xmath22 empirical risks is at most @xmath60 .",
    "hence , with probability at least @xmath61 : @xmath62    a simple application of the union bound extends this result for finite @xmath14 :    [ lemma : max - empirical - risk ] under the same conditions as theorem [ thm : max - true - risk ] , with probability at least @xmath63 with respect to the random draw of the @xmath22 tasks and their @xmath22 corresponding @xmath25-samples : @xmath64    the bound in the lemma states a @xmath65 rate of decay for the probability that the empirical risk obtained by @xmath18 on a new task exceeds @xmath0 .",
    "next , we relate this empirical risk with the true risk obtained by the empirical risk minimizer . note that at test time @xmath18 is fixed and hence independent of any test @xmath25-sample .",
    "then , from by now standard learning theory results of bartlett and mendelson @xcite :    take loss @xmath49 as in theorem [ thm : max - true - risk ] . with probability at least @xmath63 , for all @xmath16 uniformly : @xmath66 [ lemma : basic - slt ]    in particular , with high probability the true risk of the empirical risk minimizer is not much larger than its empirical risk .",
    "theorem [ thm : max - true - risk ] now follows from lemmas [ lemma : max - empirical - risk ] and [ lemma : basic - slt ] and a union bound over @xmath67 ; note that mapping the observed maximum empirical risk @xmath0 to @xmath68 picks up the additional @xmath69 term in .    in the next section ,",
    "we introduce a loss - compositional paradigm for multi - task learning which includes as special cases minimax mtl and classical mtl .",
    "the paradigm can benefit from a bit of notation . given a set of @xmath22 tasks , we represent the empirical risk for hypothesis @xmath70 ( @xmath71 ) on task @xmath28 $ ] as @xmath72 .",
    "additionally define a set of hypotheses for multiple tasks @xmath73 and the vector of empirical risks @xmath74 .    with this notation set , the proposed loss - compositional paradigm encompasses any regularized minimization of a ( typically convex ) function @xmath75 of the empirical risks : @xmath76 where @xmath77 is a regularizer .",
    "[ [ bmell_mathbfp - mtl . ] ] @xmath78 mtl .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one notable specialization that is still quite general is the case when @xmath79 is an @xmath80-norm , yielding _",
    "@xmath80 mtl_. this subfamily encompasses classical mtl and many new mtl formulations :    = 2em    classical mtl as _",
    "@xmath81 mtl _ :    @xmath82 } \\hat{\\ell}(h_t ) + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr )   \\qquad \\,\\,\\,\\ , \\equiv \\,\\ , \\inf_{{\\mathcal{h}}\\in \\mathbb{h } } \\inf_{\\mathbf{h } \\in { \\mathcal{h}}^t } \\frac{1}{t } \\| \\hat{\\bm{\\ell}}(\\mathbf{h } ) \\|_1 + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr)$ ] .",
    "minimax mtl as _",
    "@xmath83 mtl _ :    @xmath84 } \\hat{\\ell}(h_t ) + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr )   \\qquad \\,\\,\\,\\,\\ , \\equiv \\,\\ , \\inf_{{\\mathcal{h}}\\in \\mathbb{h } } \\inf_{\\mathbf{h } \\in { \\mathcal{h}}^t } \\| \\hat{\\bm{\\ell}}(\\mathbf{h } ) \\|_\\infty + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr)$ ] .    a new formulation , _",
    "@xmath11 mtl _ :    @xmath85 } \\bigl(\\hat{\\ell}(h_t)\\bigr)^2 \\bigr)^{1/2 }   + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr ) \\,\\ ,",
    "\\equiv \\,\\ , \\inf_{{\\mathcal{h}}\\in \\mathbb{h } } \\inf_{\\mathbf{h } \\in { \\mathcal{h}}^t } \\frac{1}{\\sqrt{t } } \\| \\hat{\\bm{\\ell}}(\\mathbf{h } ) \\|_2 + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr)$ ] .",
    "a natural question is why one might consider minimizing @xmath80-norms of the empirical risks vector for @xmath86 , as in @xmath11 mtl .",
    "the contour of the @xmath81-norm of the empirical risks evenly trades off empirical risks between different tasks ; however , it has been observed that overfitting often happens near the end of learning , rather than the beginning @xcite .",
    "more precisely , when the empirical risk is high , the gradient of the empirical risk ( taken with respect to the parameter @xmath87 ) is likely to have positive inner product with the gradient of the true risk .",
    "therefore , given a candidate solution with a corresponding vector of empirical risks , a sensible strategy is to take a step in solution space which places more emphasis on tasks with higher empirical risk .",
    "this strategy is particularly appropriate when the class of learners has high capacity relative to the amount of available data .",
    "this observation sets the foundation for an approach that minimizes norms of the empirical risks .    in this work",
    ", we also discuss an interesting subset of the loss - compositional paradigm which does not fit into @xmath80 mtl ; this subfamily embodies a continuum of relaxations of minimax mtl .",
    "[ [ bmalpha - minimax - mtl . ] ] @xmath88-minimax mtl .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in some cases , minimizing the maximum loss can exhibit certain disadvantages because the maximum loss is not robust to situations when a small fraction of the tasks are fundamentally harder than the remaining tasks .",
    "consider the case when the empirical risk for each task in this small fraction can not be reduced below a level @xmath89 . rather than rigidly minimizing the maximum loss , a more robust alternative is to minimize the maximize loss in a soft way .",
    "intuitively , the idea is to ensure that most tasks have low empirical risk , but a small fraction of tasks are permitted to have higher loss .",
    "we formalize this as _ @xmath90-minimax mtl _ , via the relaxed objective : @xmath91 } \\max\\{0 , \\hat{\\ell}_t(h_t ) - b\\ } \\bigr\\ } + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr ) .",
    "\\end{aligned}\\end{aligned}\\ ] ] in the above , @xmath79 from the loss - compositional paradigm is a variational function of the empirical risks vector .",
    "the above optimization problem is equivalent to the perhaps more intuitive problem : @xmath92 } \\xi_t + \\omega \\bigl ( ( { \\mathcal{h } } , \\mathbf{h } ) \\bigr ) \\qquad     \\text{subject to } \\quad      \\hat{\\ell}_t(h_t ) \\leq   b + \\xi_t , \\ ; t \\in [ t ] .",
    "\\end{aligned}\\ ] ] here , @xmath93 plays the role of the relaxed maximum , and each @xmath94 s deviation from zero indicates the deviation from the ( loosely enforced ) maximum .",
    "we expect @xmath95 to be sparse .    to help understand how @xmath90 affects the learning problem , let us consider a few cases :    1 .",
    "when @xmath96 , the optimal value of @xmath93 is zero , and the problem is equivalent to classical mtl . to see this , note that for a given candidate solution with @xmath97 the objective always can be reduced by reducing @xmath93 by some @xmath46 and increasing each @xmath94 by the same @xmath46 .",
    "2 .   suppose one task is much harder than all the other tasks ( e.g. an outlier task ) , and its empirical risk is separated from the maximum empirical risk of the other tasks by @xmath98 .",
    "let @xmath99 ; now , at the optimal hard maximum solution ( where @xmath100 ) , the objective can be reduced by increasing one of the @xmath94 s by @xmath98 and decreasing @xmath93 by @xmath98 .",
    "thus , the objective can focus on minimizing the maximum risk of the set of @xmath101 easier tasks . in this special setting , this argument can be extended to the more general case @xmath102 and @xmath103 outlier tasks , for @xmath104 $ ] .",
    "3 .   as @xmath90 approaches @xmath105 , we recover the hard maximum case of minimax mtl .",
    "this work focuses on @xmath90-minimax mtl with @xmath106 i.e. the harmonic mean of @xmath107 and @xmath108 .",
    "the reason for this choice is that in the idealized case ( 2 ) above , for large @xmath22 this setting of @xmath90 makes the relaxed maximum consider all but the hardest 10% of the tasks .",
    "we also try the 20% level ( i.e. @xmath109 replacing @xmath110 in the above ) .",
    "[ [ models . ] ] models .",
    "+ + + + + + +    we now provide examples of how specific models fit into this framework .",
    "we consider two convex multi - task learning formulations : evgeniou and pontil s regularized multi - task learning ( the _ ep model _ ) @xcite and argyriou , evgeniou , and pontil s convex multi - task feature learning ( the _ aep model _ ) @xcite .",
    "the ep model is a linear model with a shared parameter @xmath111 and task - specific parameters @xmath112 ( for @xmath28 $ ] ) .",
    "evgeniou and pontil presented this model as @xmath113 } } \\sum_{t \\in [ t ] } \\sum_{i=1}^m \\ell(y_{t , i } , \\langle v_0 + v_t , x_{t , i } \\rangle ) + \\lambda_0 \\|v_0\\|^2 + \\frac{\\lambda_1}{t } \\sum_{t \\in [ t ] } \\|v_t\\|^2 , \\end{aligned}\\ ] ] for @xmath49 the hinge loss or squared loss .",
    "this can be set in the new paradigm via @xmath114 , @xmath115 , and @xmath116 .",
    "the aep model minimizes the task - wise average loss with the trace norm ( nuclear norm ) penalty : @xmath117 where @xmath118 is the trace norm . in the new paradigm",
    ", @xmath14 is a set where each element is a @xmath103-dimensional subspace of linear estimators ( for @xmath119 ) .",
    "each @xmath120 in some @xmath15 lives in @xmath18 s corresponding low - dimensional subspace . also , @xmath121 .    for easy empirical comparison between the various mtl formulations from the paradigm , at times it will be convenient to use constrained formulations of the ep and aep model .",
    "if the regularized forms are used , a fair comparison of the methods warrants plotting results according to the size of the optimal parameter found ( i.e. @xmath122 for aep ) . for ep , the constrained form is : @xmath113 } } \\sum_{t \\in [ t ] } \\sum_{i=1}^m \\ell(y_{t , i } , \\langle v_0 + v_t , x_{t , i } \\rangle )   \\quad \\text{subject to } \\,\\",
    ", \\|v_0\\| \\leq \\tau_0 , \\,\\ , \\|v_t\\| \\leq \\tau_1 \\ , \\text{for } t \\in [ t ] .\\end{aligned}\\ ] ] for aep , the constrained form is : @xmath123 .",
    "we consider four learning problems ; the first three involve regression ( mtl model in parentheses ) :    = 2em = 0.5pt    a synthetic dataset composed from _ two modes _ of tasks ( ep model ) ,    the _ school _ dataset from the inner london education authority ( ep model ) ,    the conjoint analysis _ personal computer _ ratings dataset @xcite ( aep model ) .",
    "the fourth problem is multi - class classification from the _ mnist _ digits dataset @xcite with a reduction to multi - task learning using a tournament of pairwise ( binary ) classifiers .",
    "we use the aep model . given data ,",
    "each problem involved a choice of mtl formulation ( e.g. minimax mtl ) , model ( ep or aep ) , and choice of regularized versus constrained .",
    "all the problems were solved using just a few lines of code using ` cvx ` @xcite . in this work",
    ", we considered convex multi - task learning formulations in order to make clear statements about the optimal solutions attained for various learning problems .",
    "-risk ( top two lines ) and mean @xmath11-risk ( bottom two lines ) . at left and",
    "center : @xmath11-risk vs noise level , for @xmath124 and @xmath125 respectively . at right : @xmath11-risk vs task variation , for @xmath126 .",
    "dashed red is @xmath81 , dashed blue is minimax .",
    "error bars indicate one standard deviation .",
    "mtl results ( not shown ) were similar to ltl results ( shown ) , with mtl - ltl relative difference below 6.8% for all points plotted .",
    ", width=162 ]    -risk ( top two lines ) and mean @xmath11-risk ( bottom two lines ) . at left and",
    "center : @xmath11-risk vs noise level , for @xmath124 and @xmath125 respectively . at right : @xmath11-risk vs task variation , for @xmath126 .",
    "dashed red is @xmath81 , dashed blue is minimax .",
    "error bars indicate one standard deviation .",
    "mtl results ( not shown ) were similar to ltl results ( shown ) , with mtl - ltl relative difference below 6.8% for all points plotted .",
    ", width=162 ]    [ [ two - modes . ] ] two modes .",
    "+ + + + + + + + + +    the two modes regression problem consists of 50 linear prediction tasks for the first type of task and 5 linear prediction tasks for the second task type .",
    "the true parameter for the first task type is a vector @xmath127 drawn uniformly from the sphere of radius 5 ; the true parameter for the second task type is @xmath128 . each task is drawn from an isotropic gaussian with mean taken from the task type and the standard deviation of all dimensions set to @xmath129 . each data point for each task is drawn from a product of 10 standard normals ( so @xmath130 ) .",
    "the targets are generated according to @xmath131 , where the @xmath132 s are iid univariate centered normals with standard deviation @xmath133 .",
    "we fixed @xmath134 to a large value ( in this case , @xmath135 is sufficient since the mean for the largest task fits into a ball of radius 10 ) and @xmath136 to a small value ( @xmath137 ) .",
    "we compute the average mean and maximum test error over 100 instances of the 55-task multi - task problem .",
    "each task s training set and test set are 5 and 15 points respectively .",
    "the average maximum ( mean ) test error is the 100-experiment - average of the task - wise maximum ( mean ) of the @xmath11 risks . for each ltl experiment ,",
    "55 new test tasks were drawn using the same @xmath127 as from the training tasks .",
    "figure [ fig : two - modes - squared - loss ] shows a tradeoff : when each task group is fairly homogeneous ( left and center plots ) , minimax is better at minimizing the maximum of the test risks while @xmath81 is better at minimizing the mean of the test risks . as task homogeneity decreases ( right plot )",
    ", the gap in performance closes with respect to the maximum of the test risks and remains roughly the same with respect to the mean .",
    ", for shared parameter bound @xmath134 fixed . in each figure ,",
    "left section is @xmath134 is 0.2 and right section is @xmath138 .",
    "solid red is @xmath81 , solid blue is minimax , dashed green is @xmath139-minimax , dashed black @xmath140 is @xmath141-minimax .",
    "the results for @xmath11 mtl were visually identical to @xmath81 mtl and hence were not plotted .",
    ", width=257 ]    [ [ school . ] ] school .",
    "+ + + + + + +    the school dataset has appeared in many previous works @xcite . for brevity",
    "we just say the goal is to predict student test scores using certain student - level features .",
    "each school is treated as a separate task .",
    "we report both the task - wise maximum of the root mean square error ( rmse ) and the taskwise - mean of the rmse ( normalized by number of points per task , as in previous works ) .",
    "the results ( see figure [ fig : school - rmse ] ) demonstrate that when the learner has moderate shared capacity @xmath134 and high task - specific capacity @xmath136 , minimax mtl outperforms @xmath81 mtl for the max objective ; additionally , for the max objective in almost all parameter settings @xmath139-minimax and @xmath141-minimax mtl outperform @xmath81 mtl , and they also outperform minimax mtl when the task - specific capacity @xmath136 is not too large .",
    "we hypothesize that minimax mtl performs the best in the high@xmath142 regime because stopping learning once the maximum of the empirical risks can not be improved invokes early stopping and its built - in regularization properties ( see e.g. @xcite ) .",
    "interestingly , for the normalized mean rmse objective , both minimax relaxations are competitive with @xmath81 mtl ; however , when the shared capacity @xmath134 is high ( right section , right plot ) , @xmath81 mtl performs the best . for high",
    "task - specific capacity @xmath136 , minimax mtl and its relaxations again seem to resist overfitting compared to @xmath81 mtl .",
    "r83 mm            [ [ personal - computer . ] ] personal computer .",
    "+ + + + + + + + + + + + + + + + + +    the personal computer dataset is composed of 189 human subjects each of which rated on a 0 - 10 scale the same 20 computers ( 16 training , 4 test ) .",
    "each computer has 13 binary features ( amount of memory , screen size , price , etc . ) .",
    "the results are shown in figure [ fig : computer ] . in the mtl",
    "setting , for both the maximum rmse objective and the mean rmse objective , @xmath81 mtl appears to perform the best .",
    "when the trace norm of @xmath143 is high , minimax mtl displays resistance to overfitting and obtains the lowest mean rmse . in the ltl setting for the maximum rmse objective ,",
    "@xmath11 , minimax , and @xmath139-minimax mtl all outperform @xmath81 mtl . for the mean rmse",
    ", @xmath81 mtl obtains the lowest risk for almost all parameter setttings .",
    "r55 mm        [ [ mnist . ] ] mnist .",
    "+ + + + + +    the mnist task is a 10-class problem ; we approach it via a reduction to a tournament of 45 binary classifiers trained via the aep model .",
    "the dimensionality was reduced to 50 using principal component analysis ( computed on the full training set ) , and only the first 2% of each class s training points was used for training .    intuitively , the performance of the tournament tree of binary classifiers can only be as accurate as its paths , and the accuracy of each path depends on the accuracy of the nodes .",
    "hence , our hypothesis is that minimax mtl should outperform @xmath81 mtl .",
    "the results in figure [ fig : mnist - test ] confirm our hypothesis .",
    "minimax mtl outperforms @xmath81 mtl when the capacity @xmath122 is somewhat limited , with the gap widening as the capacity decreases .",
    "furthermore , at every capacity minimax mtl is competitive with @xmath81 mtl .",
    "we have established a continuum of formulations for mtl which recovers as special cases classical mtl and the newly formulated minimax mtl . in between these extreme points",
    "lies a continuum of relaxed minimax mtl formulations .",
    "more generally , we introduced a loss - compositional paradigm that operates on the vector of empirical risks , inducing the additional @xmath80 mtl paradigms .",
    "the empirical evaluations indicate that @xmath90-minimax mtl at either the 10% or 20% level often outperform @xmath81 mtl in terms of the maximum test risk objective and sometimes even in the mean test risk objective .",
    "all the minimax or @xmath90-minimax mtl formulations exhibit a built - in safeguard against overfitting in the case of learning with a model that is very complex relative to the available data .",
    "although efficient algorithms may make the various new mtl learning formulations practical for large problems , a proper effort to develop fast algorithms in this setting would have detracted from the main point of this first study .",
    "a good direction for the future is to obtain efficient algorithms for minimax and @xmath90-minimax mtl .",
    "in fact , such algorithms might have applications beyond mtl and even machine learning .",
    "another area ripe for exploration is to establish more general learning bounds for minimax mtl and to extend these bounds to @xmath90-minimax mtl ."
  ],
  "abstract_text": [
    "<S> since its inception , the modus operandi of multi - task learning ( mtl ) has been to minimize the task - wise mean of the empirical risks . </S>",
    "<S> we introduce a generalized loss - compositional paradigm for mtl that includes a spectrum of formulations as a subfamily . </S>",
    "<S> one endpoint of this spectrum is minimax mtl : a new mtl formulation that minimizes the maximum of the tasks empirical risks . via a certain relaxation of minimax mtl </S>",
    "<S> , we obtain a continuum of mtl formulations spanning minimax mtl and classical mtl . </S>",
    "<S> the full paradigm itself is loss - compositional , operating on the vector of empirical risks . </S>",
    "<S> it incorporates minimax mtl , its relaxations , and many new mtl formulations as special cases . </S>",
    "<S> we show theoretically that minimax mtl tends to avoid worst case outcomes on newly drawn test tasks in the learning to learn ( ltl ) test setting . </S>",
    "<S> the results of several mtl formulations on synthetic and real problems in the mtl and ltl test settings are encouraging .    </S>",
    "<S> = 1 </S>"
  ]
}