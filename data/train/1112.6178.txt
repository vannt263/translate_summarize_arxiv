{
  "article_text": [
    "audio source separation is the process of recovering a set of audio signals from a given mixture signal .",
    "this can be addressed via established approaches such as independent component analysis ( ica ) , binary masking and sparse component analysis ( sca ) @xcite or more recent approaches such as local gaussian modeling and nonnegative matrix factorisation ( nmf ) @xcite .",
    "most current algorithms are offline algorithms which require the whole signal in order to estimate the sources . in this paper",
    ", we focus on online audio source separation , whereby only the past samples of the mixture are available .",
    "this constraint arises in particular in real - time scenarios .",
    "a few online implementations have been designed for ica @xcite @xcite , time - frequency masking @xcite , local gaussian modeling @xcite , spectral continuity - based separation @xcite and nmf @xcite . however , these algorithms rely either on spatial cues @xcite  @xcite or on spectral cues @xcite alone .",
    "such algorithms are not capable of separating mixtures where several sources have the same spatial position and several sources have similar spectral characteristics . for example , in pop music , the voice , the snare drum , the bass drum and the bass are often mixed to the centre and several voices or several guitars are present .    in order to address this issue",
    ", we consider the general flexible source separation framework in @xcite .",
    "this framework generalises a wide range of algorithms such as certain forms of ica , local gaussian modeling and nmf , and enables the specification of additional constraints on the sources such as harmonicity . by jointly exploiting spatial and spectral cues",
    ", it makes it possible to robustly separate difficult mixtures such as above .",
    "the two main approaches for online source separation are the sliding block ( also known as blockwise ) approach , as used in @xcite @xcite @xcite @xcite , and the stochastic gradient ( also known as stepwise ) approach , as used in @xcite @xcite .",
    "the sliding block method consists in applying the offline audio source separation algorithm to a block of @xmath0 time frames .",
    "once this block of signal has been processed , a frame is extracted for each of the @xmath1 sources before sliding the processing block by one frame .",
    "this approach is computationally intensive but accurate .",
    "the stepwise method offers to update the model parameters in every frame using only the latest available frame and the model parameters estimated in the previous frame .",
    "as it uses only the latest available frame at a given time , this approach is faster than the sliding block approach but can be inaccurate .",
    "in this paper , we propose a general iterative online algorithm for the source separation framework in @xcite that combines the sliding block approach and the stepwise approach using two hyper - parameters : the block size @xmath0 and the step size @xmath2 . as a by - product",
    ", we provide a way of circumventing the annealing procedure in @xcite , which would require a large number of iterations per block .",
    "moreover , we determine the best trade - off between these two approaches experimentally on a set of real - world music mixtures .",
    "the structure of the rest of the paper is as follows : the flexible framework in @xcite is introduced in section 2 .",
    "section 3 presents the online algorithm .",
    "experimental results are shown in section 4 .",
    "the conclusion can be found in section 5 .",
    "we operate in the time - frequency ( tf ) domain by means of the short - time fourier transform ( stft ) . in each frequency bin @xmath3 and each time frame @xmath4",
    ", the multichannel mixture signal @xmath5 can be expressed as @xmath6    where @xmath1 is the number of sources and @xmath7 is the stft of the spatial image of the @xmath8-th source .",
    "we assume that @xmath7 is a complex - valued gaussian random vector with zero mean and covariance matrix @xmath9 @xmath10    and that @xmath9 factors as @xmath11    where @xmath12 is the spatial covariance matrix of the @xmath8-th source and @xmath13 is its spectral variance .    in @xcite",
    ", @xmath12 is expressed as @xmath14 , and @xmath15 is estimated instead .",
    "this results in an annealing procedure , which would translate into a large number of iterations within each block in our context . in order to circumvent the annealing",
    ", we assume that @xmath12 is full - rank and directly estimate @xmath12 instead , similarly to @xcite .",
    "the spectral variance @xmath13 is modeled via a form of hierarchical nmf @xcite .",
    "the matrix of spectral variances @xmath16_{f , n}$ ] is first decomposed into the product of an excitation spectral power @xmath17 and a filter spectral power @xmath18 @xmath19    where @xmath20 denotes entrywise multiplication .",
    "@xmath17 is further decomposed into the product of a matrix of narrowband spectral patterns @xmath21 , a matrix of spectral envelope weights @xmath22 , a matrix of temporal envelope weights @xmath23 and a matrix of time - localised temporal patterns @xmath24 , so that @xmath25    @xmath26 is decomposed in a similar way .",
    "this factorisation enables the specification of various spectral or temporal constraints over the sources .",
    "for example , harmonicity can be enforced by fixing @xmath21 to a set of narrowband harmonic patterns .      in an offline context , the model parameters are estimated in the maximum likelihood ( ml ) sense by a generalised expectation - maximisation ( gem ) algorithm combined with multiplicative updates ( mu ) applied to the complete data @xmath27 .    the log - likelihood is defined using the empirical mixture covariance matrix @xmath28 @xcite as @xmath29    where @xmath30 is the covariance of the mixture @xmath5 .    in the e - step ,",
    "the expectation of the natural statistics is computed via @xcite @xmath31    where @xmath32 is the wiener filter , @xmath33 is the @xmath34 identity matrix and @xmath35 is the number of channels of the mixture .    in the m - step ,",
    "the model parameters are updated as @xcite @xmath36({\\bf u}_j^{\\textrm{x } } { \\bf g}_j^{\\textrm{x } } { \\bf h}_j^{\\textrm{x}})^{t } } { { \\bf v}_j^{\\textrm{x}}.^{-1}({\\bf u}_j^{\\textrm{x } } { \\bf g}_j^{\\textrm{x } } { \\bf h}_j^{\\textrm{x}})^{t}}\\\\ & { \\bf u}_j^{\\textrm{x } } & = { \\bf u}_j^{\\textrm{x } } \\odot \\frac{{{\\bf w}_j^{\\textrm{x}}}^t [ { \\bf \\widehat \\xi}_{j } \\odot { { \\bf v}_j^{\\textrm{x}}}.^{-2 } \\odot { { \\bf v}_j^{\\textrm{f}}}.^{-1 } ] ( { \\bf g}_j^{\\textrm{x } } { \\bf h}_j^{\\textrm{x}})^{t}}{{{\\bf w}_j^{\\textrm{x}}}^t { \\bf v}_j^{\\textrm{x}}.^{-1}({\\bf g}_j^{\\textrm{x } } { \\bf h}_j^{\\textrm{x}})^{t}}\\\\\\label{g } & { \\bf g}_j^{\\textrm{x } } & = { \\bf g}_j^{\\textrm{x } } \\odot \\frac{({\\bf w}_j^{\\textrm{x}}{\\bf u}_j^{\\textrm{x}})^t [ { \\bf \\widehat \\xi}_{j } \\odot { { \\bf v}_j^{\\textrm{x}}}.^{-2 } \\odot { { \\bf v}_j^{\\textrm{f}}}.^{-1 } ] { { \\bf h}_j^{\\textrm{x}}}^{t}}{({\\bf w}_j^{\\textrm{x}}{\\bf u}_j^{\\textrm{x}})^t { \\bf v}_j^{\\textrm{x}}.^{-1}{{\\bf h}_j^{\\textrm{x}}}^{t}}\\\\\\label{h } & { \\bf h}_j^{\\textrm{x } } & = { \\bf h}_j^{\\textrm{x } } \\odot \\frac{({\\bf w}_j^{\\textrm{x } } { \\bf u}_j^{\\textrm{x } } { \\bf g}_j^{\\textrm{x}})^t [ { \\bf \\widehat \\xi}_{j } \\odot { { \\bf v}_j^{\\textrm{x}}}.^{-2 } \\odot { { \\bf v}_j^{\\textrm{f}}}.^{-1 } ] } { ( { \\bf w}_j^{\\textrm{x } } { \\bf u}_j^{\\textrm{x } } { \\bf g}_j^{\\textrm{x}})^t { \\bf v}_j^{\\textrm{x}}.^{-1}}\\end{aligned}\\ ] ]    where @xmath37 denotes entrywise raising to the power @xmath38 , @xmath39 is the number of time frames in the stft of the signal and @xmath40_{f , n}$ ] , with @xmath41    @xmath42 , @xmath43 , @xmath44 and @xmath45 are updated in a similar way .",
    "after each em iteration , the model parameters are normalised : the mean of @xmath46 , @xmath21 , @xmath22 , @xmath23 , @xmath47 , @xmath42 , @xmath43 and @xmath45 are normalised to 1 while @xmath44 is multiplied by the product of the normalisation factors of the other variables .",
    "the separated sources are then obtained via @xmath48",
    "we now consider an online context where in each time frame @xmath49 , the data is limited to a block of @xmath0 stft frames indexed by @xmath4 with @xmath50 , where @xmath51 for the stepwise approach and @xmath52 for the full offline approach .",
    "we define a step size coefficient @xmath530 ; 1]$ ] to stabilise the parameter updates by averaging over time . for each block ,",
    "the spatial covariance matrices @xmath54 are initialised to a diffuse spatial covariance spanning a part of the audio space .",
    "the temporal weights @xmath55 are randomly initialised and the normalised to the mean spectral power of the signal . finally , the temporal patterns @xmath56 are initialised to diagonal matrices .",
    "the expectation of the natural statistics is computed using ( [ omega ] ) and ( [ hat_rc ] ) for @xmath50 , whilst the spatial covariance matrix is updated as follows : @xmath57    where the superscript @xmath58 denotes is the value of matrix for the block @xmath49 .",
    "@xmath55 and @xmath56 are updated using ( [ g ] ) and ( [ h ] ) for @xmath50 , as they are expected to significantly vary between blocks , whereas the updates of @xmath21 and @xmath22 become @xmath59    where @xmath60({{\\bf u}_j^{\\textrm{x}}}^{(t ) } { { \\bf g}_j^{\\textrm{x}}}^{(t ) } { { \\bf h}_j^{\\textrm{x}}}^{(t)})^{t}\\\\ { { \\bf c}_j^{\\textrm{x}}}^{(t ) } & = & ( 1-\\alpha){{\\bf c}_j^{\\textrm{x}}}^{(t-1 ) } + \\alpha{\\bf v}_j^{\\textrm{x}}.^{-1}({{\\bf u}_j^{\\textrm{x}}}^{(t ) } { { \\bf g}_j^{\\textrm{x}}}^{(t ) } { { \\bf h}_j^{\\textrm{x}}}^{(t)})^{t}\\\\ { { \\bf n}_j^{\\textrm{x}}}^{(t ) } & = & ( 1-\\alpha){{\\bf n}_j^{\\textrm{x}}}^{(t-1 ) } + \\alpha{{\\bf w}_j^{\\textrm{x}}}^{(t)t } [ { \\bf \\widehat \\xi}_{j } \\odot { { \\bf v}_j^{\\textrm{x}}}.^{-2 } \\odot { { \\bf v}_j^{\\textrm{f}}}.^{-1 } ] ( { { \\bf g}_j^{\\textrm{x}}}^{(t ) } { { \\bf h}_j^{\\textrm{x}}}^{(t)})^{t}\\\\ { { \\bf d}_j^{\\textrm{x}}}^{(t ) } & = & ( 1-\\alpha){{\\bf d}_j^{\\textrm{x}}}^{(t-1 ) } + \\alpha{{\\bf w}_j^{\\textrm{x}}}^{(t)t } { \\bf v}_j^{\\textrm{x}}.^{-1}({{\\bf g}_j^{\\textrm{x}}}^{(t ) } { { \\bf h}_j^{\\textrm{x}}}^{(t)})^{t}\\end{aligned}\\ ] ]    where @xmath61 is computed as in ( [ eq : xi ] ) .",
    "@xmath62 , @xmath63 , @xmath64 and @xmath65 are updated in a similar way . at each block",
    ", several iterations can be performed in order to improve the estimation of the model parameters .",
    "although equations ( [ eq : onlinerj ] ) to ( [ eq : onlineu ] ) look similar to the online update of the local gaussian model in @xcite and @xcite , there are two crucial differences :    * the framework introduced in the current paper is more general in the sense that it uses hierarchical nmf , enabling the user to apply more specific constraints than when using shallow nmf .",
    "* it is not limited to the sole use of the latest audio frame .",
    "we compared the performance of the online audio source separation framework to the offline framework introduced in section [ sec : offline ] , as a function of the number of em iterations , @xmath2 and @xmath0 .",
    "the project aiming at remixing of recordings for sound engineers , djs and consumers , we processed five 10  s long stereo commercial pop recordings composed of bass , drums , guitars , strings and voice .",
    "all the recordings were recorded at 44100 hz .",
    "the stft was computed using half - overlapping 2048 sample sine windows . in the offline algorithm as well as in the online algorithm ,",
    "each of the modeled sources were constrained in a way similar to section v._c _ in @xcite . in the case of an harmonic source , @xmath66",
    "was fixed to a set of narrowband harmonic spectral patterns and the spectral envelope weights in @xmath67 were updated , whereas for bass and percussive sources , @xmath66 was a fixed diagonal matrix and @xmath67 was a fixed matrix of basis spectra learned over a corpus of bass and drum sounds .    audio samples of the separated sounds of this experiment can be found on + http://www.irisa.fr/metiss/lssimon/lva2012/index.html .",
    "separation performance was evaluated using the signal - to - distortion ratio ( sdr ) , the signal - to - interference ratio ( sir ) , the source image to spatial distortion ratio ( isr ) and the source - to - artifacts ratio ( sar ) defined in @xcite . for each set of conditions over the number of iterations , @xmath0 and @xmath2 , each of these criteria was averaged over all the mixtures and all the separated sound sources .",
    "over all the results of this experiment , the sdr varied between -1.1 and 0.9 db , the sir between -4 and 1 db , the isr between 2.3 and 3.9 db and the sar between 10 and 19 db .",
    ".separation performance ( db ) of the offline and best online algorithms .",
    "[ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]     as shown in table [ table : results ] , when @xmath68 , @xmath69 and 30 gem iterations are performed , the separation performance of the online algorithm is close to that of the offline algorithm . for smaller block size and smaller number of iterations ,",
    "the performance decreases .",
    "for example , for @xmath70 and 6 gem iteration , the sdr is 0.53 db and the sir is 3.53 db . more generally , fig .",
    "[ fig : sdr ] shows that for @xmath68 , increasing either the block size or the number of iterations increases the sdr , though the block size has less effect on the sdr than the number of iterations .",
    "the results also show that increasing the number of iterations from 10 to 30 increases the sdr by 0.2 db , which can be considered as a significant improvement .    when @xmath71 , the sdr decreases significantly as can be seen in fig .",
    "[ fig : sdr ] .",
    "it can also be seen that increasing the number of iterations decreases the sdr and changes of block size have little to no effect on the sdr .",
    "this can be explained by an inaccurate estimation of the model parameters of certain sources in the time intervals when these sources are inactive .",
    "these inaccurate parameters are then carried over subsequent time frames and may not converge back to accurate values .",
    "this undesirable effect is particularly salient for those parameters that are less constrained .",
    "for instance , with the considered model , the spatial covariance matrices of all sources gradually diverge towards a diffuse spatial covariance spanning all directions in the mixture , while the effect is more limited for spectral parameters which are fixed or heavily constrained .",
    "potential solutions to this problem are presented in the conclusion .",
    "in this paper , a new framework for online audio source separation was presented .",
    "this algorithm offers an increased flexibility both in terms of the range of constraints that can be specified for each source and of the choice of a trade - off between separation accuracy and computational cost .",
    "it was shown that the separation accuracy is higher when the block size is large , but that small block sizes nevertheless offer an acceptable separation . however , small step sizes cause the spatial covariance matrices to diverge due to the presence of silence intervals in the sources .",
    "this issue is well - known in the beamforming literature where a voice activity detector is used to restrict the time frames in which the model parameters are updated @xcite .",
    "while this solution does not readily extend to source separation , we believe that there exist a number of alternative promising solutions , e.g. adding soft constraints over the least constrained parameters by means of probabilistic priors , using different step sizes for the most constrained and the least constrained parameters , and using signal - dependent step sizes related to the power of @xmath9 such that the parameters are not updated in the time intervals with low power .    future work should also include an optimisation of the initialisation of the model parameters for each new block .",
    "after these improvements , we expect that the proposed framework will reach its full potential and provide a better trade - off between separation performance and computational cost .        4 makino , s. , lee , t .- w . and",
    "sawada , h. : blind speech separation .",
    "springer ( 2007 ) vincent , e. , jafari , m. g. , abdallah , s. a. , plumbley , m. d. and davies , m. e. : probabilistic modeling paradigms for audio source separation . in : machine audition : principles , algorithms and systems .",
    "igi global , pp .",
    "162185 ( 2010 ) mukai , r. , sawada , h. , araki , s. and makino , s. : real - time blind source separation for moving speakers using blockwise ica and residual crosstalk subtraction . in : 4th int .",
    "independent component analysis and blind signal separation , pp .",
    "975980 ( 2003 ) mori , y. , saruwatari , h. , takatani , t. , ukai , s. , shikano , k. , hiekata , t. , ikeda , y. , hashimoto , h. and morita , t. : blind separation of acoustic signals combining simo - model - based independent component analysis and binary masking .",
    "eurasip journal on advances in signal processing , vol .",
    "2006 , issue 1 , pp .",
    "117 ( 2006 ) loesch , b. and yang , b. : online blind source separation based on time - frequency sparseness . in : proc .",
    "2009 ieee int . conf . on acoustics , speech and signal processing , pp .",
    "117120 ( 2009 ) togami , m. : online speech source separation based on maximum likelihood of local gaussian modeling . in : proc .",
    "2011 ieee int . conf . on acoustics , speech and signal processing , pp .",
    "213216 ( 2011 ) ono , n. , miyamoto , k. and sagayama , s. : a real - time equalizer of harmonic and percussive components in music signals . in : proc .",
    "2008 int . conf . on music information retrieval ,",
    "139  144 ( 2008 ) wang , d , vipperla , r. and evans , n. : online pattern learning for non - negative convolutive sparse coding . in : proc .",
    "interspeech11 , pp .",
    "6568 ( 2011 ) ozerov , a. , vincent , e. and bimbot , f. : a general flexible framework for the handling of prior information in audio source separation .",
    "ieee transactions on audio , speech , and language processing , to appear duong , n.q.k . , vincent , e. and gribonval , r. : under - determined reverberant audio source separation using a full - rank spatial covariance model .",
    "ieee transactions on audio , speech , and language processing , vol .",
    "18 , issue 7 , pp . 18301840 ( 2010 ) vincent , e. , sawada , h. , bofill , p. , makino , s. and rosca , j. p. : first stereo audio source separation evaluation campaign : data , algorithms and results . in : proc .",
    "2007 int . conf . on independent component analysis and blind source separation ,",
    "552559 ( 2007 ) brandstein , m.s . ,",
    "ward , d.b . : microphone arrays : signal processing techniques and applications .",
    "springer ( 2001 )"
  ],
  "abstract_text": [
    "<S> we consider the problem of online audio source separation . </S>",
    "<S> existing algorithms adopt either a sliding block approach or a stochastic gradient approach , which is faster but less accurate . also , they rely either on spatial cues or on spectral cues and can not separate certain mixtures . in this paper , we design a general online audio source separation framework that combines both approaches and both types of cues . </S>",
    "<S> the model parameters are estimated in the maximum likelihood ( ml ) sense using a generalised expectation maximisation ( gem ) algorithm with multiplicative updates . </S>",
    "<S> the separation performance is evaluated as a function of the block size and the step size and compared to that of an offline algorithm . </S>"
  ]
}