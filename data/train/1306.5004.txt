{
  "article_text": [
    "the goal of this appendix is two fold .",
    "first , there are a variety of technical issues which should be clarified .",
    "second , we would like to make the relevant ideas as accessible as possible , beyond a physics audience .",
    "thus , we give more than the usual background .",
    "just ten years ago , sirovich s pioneering analysis of voting patterns on the supreme court required the manual entry and coding of data from individual cases @xcite .",
    "our task has been made much easier by the efforts of spaeth and coworkers , who have compiled a large body of data and made it accessible through a web site at washington university in st louis @xcite .",
    "to illustrate , we show in fig [ rawdata ] the raw data on the rehnquist court that forms the basis for most of our analyses .",
    "this example also shows the ideologically labeled liberal vs. conservative votes which spaeth et al .",
    "assigned using the criteria they detail on their webpage ( see also appendix f ) .    )",
    "vote , and white a negative ( @xmath2 ) vote . as explained in the text , the sign is set along an ideological scale so that positive ( negative ) corresponds to a conservative ( liberal ) decision as defined by @xcite . ]    ]    as discussed in the main text , the definitions of yes and no are , to some extent , arbitrary .",
    "much of our discussion , then , is for a symmetrized data set in which we take our samples to consist both of the observed voting patterns @xmath12 and the inverted patterns @xmath13 . in fig",
    "[ graph : zipf ] we show the probability of these patterns , sorted by their rank .",
    "this representation of the data often is called a `` zipf plot , '' after zipf s discussion of the distribution of words in english @xcite . as with words",
    ", we see that the probability has an approximately power  law dependence on rank ( a straight line on the log  log plot of fig [ graph : zipf ] ) , although in the present case this is true only over a very limited dynamic range .",
    "although we have shown results primarily from the second rehnquist court , we have considered a total of 18 natural courts available in the data set ; aspects of these different courts are discussed below .",
    "the concept of entropy has its roots in thermodynamics , roughly 150 years ago .",
    "the idea that a maximum entropy principle could be used to build models of systems well outside the domain of thermodynamics is a more recent development , but still is more than 50 years old @xcite .",
    "the intuition , which has surprising consequences , is that we would like to make models that match certain experimental observations , but we would like to do this in a way that does not introduce any structure beyond that which is necessary to match the data . here",
    "we follow the classical development of this idea , leading to eqs ( [ ising1 ] , [ ising2 ] ) . for a textbook account",
    "see appendix a.7 of ref @xcite .    to be more concrete",
    ", we imagine that the system we are studying has several degrees of freedom , each described by a variable @xmath22 ; here these variables are the votes cast by the @xmath63 justices .",
    "the state of the entire system then is defined by the set of variables @xmath12 , and in the simplest case what we mean by `` making a model '' is writing down the probability distribution out of which these states are being drawn , @xmath15 .",
    "once we adopt a probabilistic description , experimental observations are averages , or expectation values in this distribution .",
    "thus , we might want to know the average vote of each justice , and this is given by @xmath64 where the sum is over all possible patterns of votes by all the justices , and the subscript reminds us that this average is being computed in the distribution @xmath65 .",
    "similarly , we might want to know the correlations between votes cast by different justices , and the pairwise correlations are given by @xmath66 these restrictions are equivalent to fixing the covariances , which be get by subtracting off the means : @xmath67 .",
    "for the symmetrized data , we have that @xmath68 so matching the pairwise correlations is the same as matching the covariances .",
    "if we want our model to match experimental observations on these expectation values , we insist that @xmath69 computed from the distribution @xmath15 be the same as the average computed from the experimental data , @xmath70 and similarly for the correlations , @xmath71 notice that we could also make other choices , matching different features of the data .",
    "the average votes and their pairwise correlations , however , seem like natural choices .",
    "as emphasized in the text , eqs ( [ match1 ] , [ match2 ] ) do not specify the distribution @xmath15 uniquely .",
    "indeed , there are infinitely many distributions that are consistent with these experimental observations . out of these infinitely many possibilities",
    ", we would like to discipline ourselves , and not introduce any structure that is not actually needed in order to match the data , where `` match the data '' now has the concrete meaning of satisfying eqs ( [ match1 ] , [ match2 ] ) .",
    "another way of saying this is that we would like a probability distribution such that , when we choose states out of this distribution , these states look as random as possible while still matching the data .",
    "the idea that a distribution has minimal structure , or generates states with maximum randomness , might seem hopelessly qualitative .",
    "but in 1948 shannon proved that there is a unique way to translate this intuition into mathematical terms if we adopt some simple requirements @xcite .",
    "the result is that the only consistent measure of the randomness of states , or the lack of structure , is given by the entropy of the probability distribution , @xmath72 \\equiv -\\sum_{{\\{{\\sigma}_{\\mathrm{i}}\\ } } } p({\\{{\\sigma}_{\\mathrm{i}}\\ } } ) \\ln p({\\{{\\sigma}_{\\mathrm{i}}\\ } } ) .\\ ] ] there is an ambiguity of units ; indeed , chemists and physicists typically choose different units for the entropy even in the thermodynamic context .",
    "the ambiguity of units is equivalent to an arbitrariness in choosing the base of the logarithm .",
    "here we choose the natural log , but in other settings it is conventional to choose the logarithm base 2 , in which case the units of entropy are bits .",
    "importantly , the entropy which shannon found as a measure of randomness or disorder in probability distributions is _ exactly _ the entropy that arises in statistical mechanics , and this is the same as the entropy for these systems in the thermodynamic sense .    in thermodynamics , coming to thermal equilibrium",
    "means finding a state with maximal entropy given whatever constraints the system experiences . in the present context , there are no heat flows and there is no notion of temperature or equilibrium .",
    "instead @xcite , the maximum entropy probability distribution provides us with a model that is consistent with observed facts  taking eqs ( [ match1 ] , [ match2 ] ) as constraints  but otherwise has as little structure as possible .    to carry out the maximum entropy construction , we need to find the probability distribution that maximizes the entropy subject to the constraints in eqs ( [ match1 ] , [ match2 ] ) . to do this",
    "we use the method of lagrange multipliers @xcite .",
    "we recall that if we want to maximize a function @xmath73 of many variables , @xmath74 subject to the constraint that @xmath75 , we can construct a new function @xmath76 , where @xmath77 is a `` lagrange multiplier . ''",
    "if we maximize @xmath78 with respect to @xmath79 , we find a one parameter family of solutions , depending on the value of @xmath77 .",
    "if we maximize again with respect to @xmath77 we will pick out the one solution in this family that satisfies the constraint @xmath75 .",
    "if we have many constraints , we add more lagrange multipliers , one for each constraint , and sum the corresponding contributions to @xmath80 .",
    "if we want to maximize the entropy of the probability distribution @xmath15 subject to the constraints in eqs ( [ match1 ] , [ match2 ] ) , the method of lagrange multipliers tells us that we need to introduce a function    @xmath81 & \\equiv & -\\sum_{{\\{{\\sigma}_{\\mathrm{i}}\\ } } } p({\\{{\\sigma}_{\\mathrm{i}}\\ } } ) \\ln p({\\{{\\sigma}_{\\mathrm{i}}\\ } } )   + \\sum_{\\rm i } h_{\\rm i } \\left [ \\sum_{\\{\\sigma_{\\rm j}\\}}\\sigma_{\\rm i } p(\\{\\sigma_{\\rm j}\\ } ) -",
    "\\langle\\sigma_{\\rm i}\\rangle_{\\rm expt}\\right ] \\nonumber\\\\ & & \\,\\,\\,\\,\\,\\,\\,\\,\\,\\ , + { 1\\over 2 } \\sum_{\\rm ij } j_{\\rm ij } \\left [   \\sum_{\\{\\sigma_{\\rm k}\\}}\\sigma_{\\rm i}\\sigma_{\\rm j } p(\\{\\sigma_{\\rm k}\\ } ) - \\langle \\sigma_{\\rm i } \\sigma_{\\rm j}\\rangle_{\\rm expt}\\right ] + \\lambda \\left [ \\sum_{\\{\\sigma_{\\rm j}\\ } } p(\\{\\sigma_{\\rm i}\\ } )   -1\\right ] .\\end{aligned}\\ ] ]    here , @xmath51 is the lagrange multiplier introduced to enforce the constraint on @xmath69 in eq ( [ match1 ] ) , and @xmath20 is the lagrange multiplier introduced to enforce the constraint on @xmath82 in eq ( [ match2 ] ) ; because the correlation matrix is symmetric we can take @xmath83 , and the factor of @xmath84 reminds us that we are counting each term twice .",
    "finally , @xmath85 is the lagrange multiplier introduced to enforce the normalization of the probability distribution , which allows us formally to treat the variables @xmath15 as independent real numbers , not worrying that they have to sum to one .    to find the maximum of @xmath86 , we take derivatives with respect to the elements of the probability distribution , and set these to zero : @xmath87 } \\over{\\partial p(\\{\\sigma_{\\rm i}\\ } ) } } & = & -   \\ln p(\\{\\sigma_{\\rm i}\\ } ) -1 + \\sum_{\\rm i } h_{\\rm i } \\sigma_{\\rm i } + { 1\\over 2 } \\sum_{\\rm ij } j_{\\rm ij } \\sigma_{\\rm i}\\sigma_{\\rm j } + \\lambda = 0\\\\ \\rightarrow   p(\\{\\sigma_{\\rm i}\\ } ) & = & { 1\\over{z } } \\exp\\left [   \\sum_{\\rm i } h_{\\rm i } \\sigma_{\\rm",
    "i } + { 1\\over 2 } \\sum_{\\rm ij } j_{\\rm ij } \\sigma_{\\rm i}\\sigma_{\\rm j } \\right ] , \\end{aligned}\\ ] ]    where @xmath88 .",
    "in addition , we need to maximize @xmath86 with respect to the lagrange multipliers . for @xmath85 ,",
    "the condition @xmath89 /\\partial \\lambda = 0 $ ] is equivalent to the normalization condition , @xmath90 this sets the value of @xmath91 , which is called the partition function in statistical physics , @xmath92   .\\ ] ] if we maximize with respect to @xmath51 we find the condition in eq ( [ match1 ] ) , and if we maximize with respect to @xmath20 we find the condition in eq ( [ match2 ] ) .",
    "we have as many experimental measurements as we have lagrange multipliers , and so there are enough equations to determine all the parameters .",
    "solving these equations is another step , discussed in the next section . strictly speaking , finding the point where derivatives vanish yields an extremum , not necessarily a maximum of the entropy .",
    "but the entropy is a convex function of the probability distribution @xcite , so that relevant second derivatives all are negative ; hence any extremum will be a maximum .    to summarize",
    ", we have shown that the least structured probability distribution consistent with measured averages and pairwise correlations has the form @xmath93 the parameters @xmath94 are not arbitrary , but must be adjusted to be sure that the predicted averages and pairwise correlations match the measured values , as in eqs ( [ match1 ] , [ match2 ] ) .",
    "equations ( [ boltza1 ] , [ boltza2 ] ) are exactly the boltzmann distribution , which describes the distribution of states taken on by a system in thermal equilibrium , where the energy of each state is given by @xmath47 . in the physical setting , there is a real temperature @xmath95 , which determines an energy scale @xmath96 , where @xmath97 is boltzmann s constant . then , to be precise , we should write @xmath98 but we are free to choose our units of energy so that @xmath99 . then it is clear that our problem of building minimally structured models leads us exactly to a statistical mechanics model of the system we are studying .",
    "the physical interpretation of our model is that the ( yes / no ) votes of judges are ising ( @xmath100 ) spins that each experience a `` magnetic field '' @xmath51 and interact in pairs through the couplings @xmath20 .",
    "we have chosen a sign convention such that @xmath101 favors a yes vote ( @xmath102 ) , and @xmath103 favors justices @xmath4 and @xmath104 voting in the same way .    because we are asking to match both the averages @xmath62 and the pairwise correlations @xmath82 , there are two sets of terms in the `` energy '' @xmath47 . in our initial formulation of the voting problem on the us supreme court , as described in the main text , yes and no votes are symmetric , and we automatically have @xmath6 for every justice @xmath4 .",
    "then we need to match only the correlations between the votes of pairs of justices , and hence the energy function simplifies to @xmath105 we see that eqs ( [ boltza1 ] , [ boltza4 ] ) are the same as eqs ( [ ising1 ] , [ ising2 ] ) of the main text . in a later discussion , we will break the symmetry between yes and no votes , and the fields @xmath51 will then be important ( appendix [ sec : ideological_votes ] ) .",
    "it is important to emphasize that the maximum entropy method is _ not _ a model .",
    "it is a framework for building models that capture particular aspects of the data while making no additional assumptions .",
    "thus , there are no free parameters to be `` fit , '' and we are able to make unambiguous , quantitative predictions , as in fig [ fit ] .",
    "the maximum entropy construction arrives at eqs ( [ boltza1 ] , [ boltza2 ] , [ boltza4 ] ) analytically . to complete the construction",
    ", we actually have to find the numerical values of the coupling parameters @xmath20 that allow the model to match the observed correlations .",
    "that is , we have to solve eq ( [ match2 ] ) , which can be written more explicitly as @xmath106 = \\langle\\sigma_{\\rm a}\\sigma_{\\rm b}\\rangle_{\\rm expt } .\\ ] ] we note that both the correlations and the couplings define symmetric matrices .",
    "thus , with @xmath107 justices , these are @xmath108 simultaneous equations for the @xmath109 independent parameters @xmath20 .",
    "these equations are relatively straightforward to solve numerically , for example using matlab s fsolve routine .",
    "results for the second rehnquist court are shown in fig [ jij ] .",
    "with @xmath110 the total number of votes recorded for the second rehnquist court . we construct independent maximum entropy models for each sample , and plot the mean couplings vs. sample size @xmath111 ; error bars are standard deviations of the couplings over multiple bootstrap samples at each @xmath111 .",
    "points have been slightly displaced along the x - axis to minimize overlap between error bars .",
    "[ graph : convergence ] ]    the maximum entropy problem is formulated on the assumption that we know the correlation functions from experiment .",
    "in fact , these measurements come with error bars , since our sample is finite",
    ". we would like to convince ourselves that these errors have only a small impact on our ability to construct the model and make predictions . as a first test",
    ", we ask what happens when we choose random fractions of the full data set .",
    "figure [ graph : convergence ] shows that , for selected elements of the matrix @xmath20 , our best estimate has a very weak systematic dependence on the size of the data set , and that these individual parameters can be determined with reasonable precision .",
    "fig [ graph : jijsigns ] surveys these errors in the entire matrix , showing that all elements are determined within @xmath112 , and many within @xmath113 ; these random errors are estimated , as in fig [ graph : convergence ] , across bootstrap resamplings of the data .",
    "importantly , for most of the @xmath20 , these resamplings have a low probability of changing our estimate of the sign of the interaction , and uncertainty about the sign is confined to the @xmath20 that have the smallest magnitude .     vs. @xmath23 .",
    "( b ) probability of a sign flip in @xmath23 over bootstrap samples .",
    "the strongest 2/3 of couplings have fixed sign with @xmath114 confidence .",
    "[ graph : jijsigns ] ]    while our model is parameterized by the @xmath20 , the fundamental prediction of the model is the probability of each voting pattern ; the logarithm of this probability is the `` energy '' of the state , from eq ( [ ising2 ] ) .",
    "if the errors in all the @xmath20 were independent , then the errors in the energy would typically be six times larger than the errors in the individual @xmath20 , and this would be quite bad .",
    "in fact the errors are unlikely to be independent , and they are not .",
    "to get some intuition , we know that if the @xmath20 themselves are drawn at random , then the correlations @xmath8 have a complicated structure @xcite .",
    "conversely , we expect that independent random additions to the @xmath8 would produce a structured change in the @xmath20 .",
    "when we draw random samples of the data to generate @xmath8 and construct the corresponding @xmath20 , we get the whole matrix of @xmath20 and hence a whole set of predictions for the energies of individual states .",
    "we can look at the standard deviations of these energies , as a function of the means , as shown in fig [ e_errors ] .",
    "low energy ( more likely ) states have errors @xmath115 , which means that we can predict the probability of these states with @xmath116 accuracy .",
    "this is possible only because the errors in the @xmath20 are correlated .",
    "once we reach @xmath117 , we can predict probabilities only within a factor of two .",
    "but this level of error is reached only for states with energy @xmath118 roughly @xmath119 units above the lowest energy state , and hence relative probability @xmath120 . with only @xmath121 samples",
    ", we thus should be able to predict , with reasonable reliability , the probabilities of all voting combinations that actually occur in the data , and this is borne out in fig [ fit ] .     vs. mean of energies @xmath122 , for each state observed in the data .",
    "states that appear only once are shown in red , and states that appear more than once are shown in blue . [ e_errors ] ]",
    "maximum entropy models express the probability of a system being in a certain state ( here , the pattern of votes by the nine justices ) in terms of an `` energy '' for that state , and this energy in turn is built out of terms that express `` interactions '' among the elements of the system ( here , the votes of the individual justices ) .",
    "it is useful to think about the energy as a landscape on the space of states , with deep valleys corresponding to states of high probability and mountains corresponding to states of low probability ; mountain passes provided the most likely paths that connect one highly likely valley to another .",
    "the model defines the energy for all possible states , not only those which are observed to occur in our finite sample of data .",
    "further , in the approach we have taken here , the entire landscape is determined by the _ measured _ correlations among the votes of pairs of justices .",
    "thus , the landscape here is not a metaphor , but something that we can construct explicitly and quantitatively , with no free parameters .        in the case of the supreme court ,",
    "the space of states is discrete : each justice votes yes or no ( @xmath1 or @xmath2 ) , and so while there are nine dimensions the allowed states live only on the corners of a ( hyper)cube in these nine dimensions .",
    "nonetheless we can identify two states as being neighbors if the jump from one state to the other involves changing the vote of only one justice .",
    "the bottom of a valley is a place where all moves take us uphill , and correspondingly we can ask for local minima of the energy function such that flipping the vote of any one justice always increases the energy . these local minima of the energy are predicted to be local maxima of the probability , and hence provide us with anchor points for thinking about the voting patterns .",
    "a local minimum of energy defines a prototypical vote , and the neighboring patterns  which are predicted to be less likely  can be thought of as `` noisy versions '' of this prototype .    as discussed in the main text , the model that we find for the patterns of votes on the us supreme court belongs to a class of models known in the physics literature as spin glasses @xcite , and a signature of these models is that their energy landscapes have multiple local minima .",
    "thus , we expect that even our small ( @xmath25 ) system will have several local minima or prototypical voting patterns , and this is what we find .    concretely , the energy landscape for the second rehnquist court has three major valleys , plus the symmetric mirror of these valleys obtained by exchanging the definitions of yes and no .",
    "together , the states in these valleys account for over 99% ( 508/512 ) of the possible voting states , corresponding to almost the full mass of the probability distribution .",
    "as noted in the main text , the prototypical states at the bottoms of the valleys are the unanimous vote , the 54 ideological split , and the 72 vote against scalia and thomas .",
    "we emphasize that these breaks along ideological lines emerge from the model even though we make no reference to ideology in our construction ; these structures are encoded in the pairwise correlations , and the maximum entropy method allows us to make these structures explicit .    leaning on the equivalence to statistical physics , we can think of the local minima in energy as the states into which the system is `` trying '' to order . if @xmath123 is the @xmath124 local minimum , we can measure how close the system has come to this state by the overlap @xmath125",
    "if the system is very deep in the valley defined by @xmath123 , then we will have @xmath126 . with two dominant valleys in the energy landscape , the unanimous vote and the 54 ideological split , there are two natural `` order parameters '' @xmath127 and @xmath128 , respectively . in fig [ e_proj ]",
    ", we show the probability distribution projected onto these two dimensions , both for the real data and as predicted by the maximum entropy model .    in the projections along ( @xmath127 , @xmath128 )",
    ", we can see the clear local maxima of probability when @xmath129 , both in the data and in the predictions of the model .",
    "more surprising is that the distribution is almost confined to the edge of the allowed space .",
    "this feature of the data , which is predicted clearly by the model , means that the full distribution is in effect dominated by the competition between the tendencies toward unanimity and ideological division , and this is not just a qualitative statement but a quantitative one .",
    "importantly , all of this structure is predicted by the maximum entropy model using only the observed pairwise correlations among votes as inputs .",
    "the idea of projecting the pattern votes onto two dimensions is not new .",
    "ten years ago , sirovich @xcite noted that the covariance of justices votes is dominated by two principal components , which are very close to the dimensions defined by @xmath127 and @xmath128 here .",
    "although we start with the same covariance matrix , the maximum entropy approach does more than identify dominant dimensions , since it makes quantitative predictions about the entire probability distribution .",
    "this is possible because the models we build respect the discrete nature of the votes  we are constructing a joint probability distribution for binary variables  while the covariance matrix itself could have arisen from a set of continuous variables , and the geometric interpretation of principal components analysis does not make reference to the `` corners of the hypercube '' structure in the space of voting patterns . by respecting the discreteness of votes , even the least structured model that is consistent with the covariance matrix exhibits a very rich structure , and one that is in detailed agreement with the data .",
    "at various points in our analyses , we estimate information theoretic quantities such as the entropy of a distribution or the mutual information between different variables .",
    "it is well known that such estimates can be systematically biased in small data sets @xcite .",
    "this problem received considerable attention in the analysis of experiments on neural coding @xcite , and here we explain how we use what was learned in that context to be sure that our estimates are reliable . for a more pedagogical discussion ,",
    "see appendix a.8 of ref @xcite .    for the second rehnquist court , it is plausible that all relevant information theoretic quantities will be well determined : there are @xmath130 states , or really @xmath131 independent probabilities in the symmetrized data , and we have @xmath132 samples ( again , doubled because of symmetry ) .",
    "for other natural courts ( cf fig [ consensus ] ) , however , the number of samples is highly variable , down to as few as 91 votes .",
    "we would like to use all of the available examples , and thus we need to understand how the limited data set sizes can bias our estimates .",
    "the hardest quantity to estimate is the entropy of the distribution of voting patterns , since this depends on the probability of every single state .",
    "the nave approach is to identify the observed frequency of occurrence of each state with its probability , and then plug these estimates into the definition of the entropy , here measured in bits , @xmath133 where @xmath134 is the frequentist estimate of probability based on @xmath40 samples .",
    "the differences between frequencies and probabilities are random  they average to zero , and as the sample size becomes larger their variance decreases uniformly . but the entropy is a nonlinear function of the probabilities , and so these random errors become systematic @xcite .",
    "if the number of samples @xmath40 is large enough , these systematic errors in the naive estimate take a simple form , @xmath135 where @xmath136 is the true entropy that we would find with an infinite number of samples , and @xmath137 and @xmath138 are constants .",
    "if we can convince ourselves that we are in the regime where this formula describes our systematic errors , then we are safe in taking the extrapolated @xmath139 as an estimate of the entropy , as shown in fig [ s_est ] .",
    "notice that the `` finite size correction , '' @xmath140 in fig [ s_est ] , is less than @xmath141 of the total entropy , and that the difference between extrapolations where we include or ignore @xmath138 in eq ( [ eq : s_expansion ] ) is even smaller ; this is true , consistently , for the data on all the natural courts that we consider .     samples , we draw multiple bootstrap samples of size @xmath40 and form the `` naive '' estimate of the entropy from eq ( [ eq : snaive ] ) ; results are shown as green points ; means and standard deviations at each @xmath40 plotted in blue .",
    "extrapolations based on eq ( [ eq : s_expansion ] ) : linear fit to samples @xmath142 is the dashed line , and the quadratic fit to all plotted points is shown as a solid line .",
    "red point is our best estimate , with errors .",
    "[ s_est ] ]    the extrapolation procedure in fig [ s_est ] should generate an unbiased estimate of the actual entropy .",
    "the maximum entropy models that we have constructed should , by definition , generate an upper bound on the entropy .",
    "this upper bound is based on measurements of the pairwise correlations , and since there are only @xmath109 independent correlation matrix elements , even small data sets give a fairly reliable basis from which to construct these models .",
    "happily , there is also a lower bound on the entropy that we can construct , and this too is rather robust to small sample sizes .    in a uniform distribution over @xmath143 states ,",
    "the probability that two states chosen at random are the same is @xmath144 and the entropy is @xmath145 .",
    "thus , in this case , we can estimate the entropy if we can estimate the probability of a coincidence , where two states are the same .",
    "notice that if we have @xmath40 samples , we can test @xmath146 independent pairs , and so we start to get a reliable estimate of @xmath147 as soon as @xmath148 , which is much less than the naive expectation that we need to see all the states ( @xmath149 ) in order to say something about the distribution from which they are drawn . as an aside ,",
    "this is the basis for the `` birthday problem , '' where the number of people needed to make it likely that two of them share the same birthday is much less than the number of possible birthdays ; a discussion appears in feller s classic text @xcite .    to go beyond the uniform distribution",
    ", we note that the probability of a coincidence among two randomly chosen states is @xmath150 ^ 2   = \\langle p(\\{\\sigma_{\\rm i}\\})\\rangle , \\label{defpc}\\ ] ] where @xmath151 stands for an expectation value over the distribution @xmath15 .",
    "but for any positive random variable @xmath152 , we have @xmath153 applying this inequality to eq ( [ defpc ] ) , we have @xmath154 but @xmath155 and so we have a lower bound on the entropy , @xmath156 we will refer to this as the `` ma bound , '' after ref @xcite",
    ".    , are small .",
    "[ bounds_fig ] ]    in figure [ bounds_fig ] we show the various entropy estimates for all the natural courts we consider , ordered by the number of votes recorded for each court ( sample size ) .",
    "we see that entropy estimates based on extrapolation , as in fig [ s_est ] , are consistently @xmath34 above the ma bound , and this is true across the full range of sample sizes . indeed , the entropies ( and the ma bounds ) for the different natural courts themselves vary by only @xmath157 , suggesting that the structure of voting patterns is quite stable across the decades .",
    "although there are @xmath158 possible voting patterns , the fact that the entropy is consistently @xmath159 indicates that , effectively , the court uses only @xmath160 of these patterns .",
    "but with these few patterns , even one hundred votes is enough to generate a reasonably good sampling .",
    "it should be noted that entropy estimates based on extrapolation can easily violate the ma bound if the number of samples we have in the data is genuinely too small ( see , for example , ref @xcite ) .",
    "taken together , these results suggest strongly that our entropy estimates are reliable for all of the natural courts , and hence we can compute the multi  information and assess the fraction of this which is captured by the maximum entropy model , as discussed in the text .    for the symmetrized data ,",
    "each justice is equally likely to vote yes or no , and hence if they voted independently the entropy would be exactly @xmath161 .",
    "then we can read from fig [ bounds_fig ] our estimate of the multi  information , @xmath162 , as well as the multi  information captured by the pairwise maximum entropy model , @xmath163 . the resulting fraction @xmath164 , where the error bar is the standard deviation across the set of natural courts .",
    "alternatively , we know that the multi ",
    "information must be greater than @xmath165 , and we thus can conclude that @xmath166 ; this is a true bound , and hence a conservative estimate .",
    "we also need to estimate other information theoretic quantities , such as the mutual information between individual justices votes and the court majority , @xmath167 . but these quantities involve probability distributions over many fewer states , and thus the sampling issues discussed here are negligible .",
    "as noted in the main text , the definition of `` yes '' and `` no '' votes in supreme court decisions has an element of arbitrariness , since the question before the court is always to affirm or overturn a previous decision . in our initial approach to the data , we elevated this arbitrariness to a symmetry , imagining that every case could have come with the opposite definition of yes and no , so that voting patterns @xmath12 and @xmath13 should be equally probable .",
    "an alternative is to note that each case presents an issue that can be mapped to the state of national politics , and there is ( except for rare cases ) a reasonable consensus that someone with leftist tendencies would vote one way and someone with rightist tendencies the other .",
    "this is , of course , only one dimension along which cases may vary .",
    "so much attention is paid to the right / left split in today s politics that we might imagine such influences are dominant @xcite .",
    "indeed , it could be that each justice responds independently to the merits of each case as seen through his or her political biases , and that what we see as correlations reflects nothing more than the fact that we are averaging over cases with different features",
    ". it may be useful to make the analogy to the case of sensory neurons .",
    "if each neuron in a network responds independently to its sensory inputs , and we average over these inputs , we will see correlations among the responses of different neurons . if we can hold the inputs fixed , however , it is possible that the correlations will vanish because there are no genuine interactions among the cells .",
    "it is not clear that we can do a completely analogous experiment with the supreme court , but mapping each yes / no vote onto a right / left decision seems like a reasonable start , as emphasized previously @xcite .",
    "in fact , the raw data of ref @xcite come labeled by the right / left sign of each vote , although we note some difficulties , emphasized also in ref @xcite .",
    "first , there is a problem of circularity , since ideologies are defined partly by the actors themselves .",
    "thus , it is not truly an external , fixed measure along which we can consider the votes of scotus . instead",
    ", the axis is partially defined by the internal dynamics of the system .",
    "the problem of circularity then implies a second problem of non - stationarity , since the definition of liberal and conservative positions evolve over time .",
    "spaeth et al . have adjusted for these changes over time , but it is difficult to gauge what the association between ideological ideals and votes may be at a given time .",
    "overall , there is evidence for an important unidimensional space similar to our intuitive concepts of conservative vs. liberals , but how this axis overlaps with our intuitions seems inexact .",
    "if we take the suggestion of ideological bias seriously , there are established definitions for what constitute the two ends of the ideological axis .",
    "spaeth et al .",
    "have used these definitions to classify the votes as liberal ( which we assign as @xmath168 ) or conservative ( @xmath1 ) @xcite .",
    "the votes that do not fall along this classification have been removed from both symmetrized and ideological analyses ( roughly 2% of votes in the second rehnquist court ) .",
    "figure [ graph : cij , jij ide ] shows the mean votes and pairwise correlations @xmath169 in the ideologically calibrated data .     against mean votes @xmath170 .",
    "green line traces the function @xmath171 , as would be expected if each justice voted independently with bias @xmath51 .",
    "error bars on @xmath51 are the standard deviation across independent constructions of maximum entropy models from multiple bootstrap samples , as for @xmath172 in fig [ graph : jijsigns ] , while errors in @xmath62 arise as usual from counting statistics .",
    "[ h_vs_s ] ]    returning to the maximum entropy model , we have now the energy function of eq ( [ boltza3 ] ) , @xmath173 solving the model on this data , we find the couplings and mean biases shown in fig [ graph : cij , jij ide]b . if each justice votes with reference to his or her own ideological bias , ignoring the other justices , then we would have @xmath174 . in fig [ h_vs_s ]",
    "we see that this relation does not describe the data well at all",
    ". thus , even if we account for individual ideological biases , interactions among the justices are still important . indeed , if we compare the interactions @xmath20 that emerge from the ideologically labeled votes with those that emerge from the symmetrized data ( fig [ jij ] ) , we see ( fig [ jvsj ] ) that these are almost the same , across their full dynamic range . putting the full model together",
    ", we see that it again provides a very good account of the data , as shown in fig [ ide_comp ] .",
    "computing entropies as in appendix e , we find that this model captures a fraction @xmath175 of the multi  information .",
    "several points about fig [ ide_comp ] seem worth noting , especially in relation to the corresponding fig [ fit ] which shows the quality of model predictions in the symmetrized data .",
    "first , it is clear that the model correctly predicts the emergence of consensus on issues that favor both conservative and liberal positions ( fig [ ide_comp]a ) ; these consensus votes would be incredibly unlikely if each justice followed his or her biases independently .",
    "the probability of each observed voting pattern is predicted , with essentially the same accuracy as in the symmetrized case ( fig [ ide_comp]b ) , and the maximum entropy model again captures very precisely the correlation between individual justices and the court majority ( fig [ ide_comp]c ) .",
    "if we map the energy landscape in the case of ideologically labeled votes , we see slight but significant differences from the symmetrized case .",
    "we still have the largest valleys around the unanimous votes , but the conservative basin has @xmath176 more weight , as can be seen from fig [ ide_comp]a .",
    "there is a valley surrounding the 54 split , with conservatives in the majority , and a second smaller valley around a 54 split with conservatives voting liberally .",
    "we still see the valley around the 72 vote against as and ct , but only one such valley exists since these two justices are so reliably conservative .",
    "while the ideologically labeled data has somewhat more structure than the symmetrized data , it seems fair to summarize our analysis by saying that keeping track of the ideological biases of the justices in relation to the content of the question before the court adds relatively little to our predictive power .",
    "how is this possible ?    the essential feature of a maximum entropy model is the predicted energy landscape . for the symmetrized model ,",
    "this landscape has multiple valleys , corresponding to unanimous votes and 54 ideological splits , as well as the smaller valleys in which as and ct dissent from their seven colleagues ( fig [ e_proj ] ) .",
    "this organization emerges collectively from the interactions among the judges , and we have seen that these interactions encode the ideological differences on the court even though we did not introduce these explicitly in constructing the model .",
    "once the court is `` polarized '' along ideological lines , it takes only very small biases to align the the polarized vote with the right / left content of the question before the court .",
    "one of the main intuitions behind the use of statistical physics ideas in the description of social dynamics is that the emergence of consensus or polarization is analogous to the emergence of order in physical systems at thermal equilibrium : having everyone in a group agree to vote the same way reminds us of all the spins in a magnet `` agreeing '' to point in the same direction .",
    "importantly , once all the spins in a magnet agree to point in the same direction , even a very small external magnetic field is sufficient to get the entire magnet pointing north . concretely , the energy difference between a single electron spin pointing up or down in the earth s magnetic field is much , much smaller than the energy @xmath96 that sets the scale of random thermal motion : individual spins _ do not _ point north reliably , although the collective magnetization of a compass magnet certainly does .",
    "similarly , the biases which couple individual justices ideological preferences to the merits of individual cases are weak , insufficient to induce unanimity or even to predict correctly the probability of a 54 split .",
    "what we see in the patterns of supreme court votes is dominated by the emergence of collective states , which then align to the particulars of individual cases .",
    "this is not a metaphor or analogy , but rather the description of a precise , quantitative model that predicts almost all the structure of these votes from the pattern of pairwise correlations .",
    "99 c castellano , s fortunato & v loreto , statistical physics of social dynamics . _",
    "rev mod phys _ * 81 , * 591646 ( 2009 ) .",
    "s fortunato , m macy & s redner , editorial .",
    "_ j stat phys _ * 151 , * 18 ( 2013 ) .",
    "this is an introduction to a special issue of _ j stat phys _ on `` the application of statistical mechanics to social phenomena . ''",
    "this paper is written for a physics audience , and thus assumes familiarity with the relevant ideas from statistical mechanics . in several appendices ,",
    "we try not only to expand on technical matters but also to give some background and discussion that we hope will make the work accessible to a broader audience .",
    "hj spaeth , l epstein , tw ruger , k whittington , ja segal & ad martin , _ supreme court database .",
    "version 2011 release 3 . _ retrieved from http://scdb.wustl.edu/index.php ( 2011 ) .",
    "justices on the second rehnquist court : js , john paul stevens ; rg , ruth bader ginsberg ; ds , david souter , sb , stephen breyer ; so , sandra day oconnor ; ak , anthony kennedy ; wr , william rehnquist ; as , antonin scalia ; ct , clarence thomas .",
    "ad martin , km quinn , & l epstein . the median justice on the united states supreme court .",
    "_ nc law rev _ * 83 , * 12751322 ( 2004 ) . see also references therein .",
    "l sirovich , a pattern analysis of the second rehnquist us supreme court .",
    "_ proc natl acad sci",
    "( usa ) _ * 100 , * 74327437 ( 2003 ) .",
    "one might expect that `` easy '' votes would be entirely unanimous , but many unanimous votes begin with dissents . in the waite court ( 18741887 ) , @xmath177 of votes at the initial conference had at least one dissent , while this was reduced to only @xmath178 in the public votes @xcite .",
    "another concern may be that unanimous decisions often originate from specific , extreme appellate courts . to test for this ,",
    "we compare the distribution across appellate courts of the unanimous and non  unanimous decisions .",
    "let the probability that a case originated from court i be written as @xmath179 for unanimous votes , and @xmath180 for non - unanimous votes .",
    "for the second rehnquist court , the kullback ",
    "leibler divergence between these distributions , @xmath181 , is small relative to entropies of the distributions @xmath182 = 4.27 $ ] and @xmath183 = 4.54 $ ] .",
    "thus , we find no strong bias . finally , we exclude votes that have no liberal vs. conservative interpretation from our analyses in case they are different  only about 2% of votes in the second rehnquist court @xcite .",
    "ce shannon , a mathematical theory of communication . _ bell sys tech j _ * 27 , * 379423 & 623656 ( 1948 ) .",
    "tm cover & ja thomas , _ elements of information theory _",
    "( wiley , new york , 1991 ) . et jaynes . information theory and statistical mechanics , _ phys rev _ * 106 , * 620630 ( 1957 ) .",
    "l epstein , ja segal & hj spaeth , the norm of consensus on the us supreme court .",
    "_ am j pol sci _",
    ", * 45 , * 362377 ( 2001 ) .",
    "d black , on the rationale of group decision  making .",
    "_ j pol econ _ , * 56 , * 2334 ( 1948 ) .",
    "e schneidman , s still , mj berry ii & w bialek , network information and connected correlations .",
    "_ phys rev lett _ * 91 , * 238701 ( 2003 ) . note that @xmath184 is the _ actual _ entropy of the voting patterns . for details on the technical problems of entropy estimation ,",
    "see appendix e. m mezard , g parisi & ma virasoro , _ spin glass theory and beyond _",
    "( world scientific , singapore , 1987 ) .",
    "we use ideological labels from @xcite and exclude cases that lack these labels .",
    "there is some disagreement  but not much  about the trustworthiness of the labels .",
    "ed lee , _ information in justice and conflict : formulating a quantitative approach to social data _ ( senior thesis , princeton university , 2012 ) .",
    "this can be seen as part of a larger effort to use the maximum entropy principle as a way of building statistical mechanics models of complex biological systems directly from data .",
    "see , as recent examples , refs @xcite , and references therein .",
    "w bialek , a cavagna , i giardina , t mora , e silvestri , m viale & a walczak , statistical mechanics for natural flocks of birds .",
    "_ proc natl acad sci ( usa ) _ * 109 , * 47864791 ( 2012 ) ; arxiv.org:1107.0604 [ physics.bioph ] ( 2011 ) .",
    "g tkaik , o marre , d amodei , e schneidman , w bialek & mj berry ii , searching for collective behavior in a network of real neurons . arxiv.og:1306.3061 [ qbio.nc ] ( 2013 ) .",
    "gk zipf , _ human behavior and the principle of least effort _",
    "( addison  wesley , cambridge , 1949 ) .",
    "w bialek _ biophysics : searching for principles _",
    "( princeton university press , princeton nj , 2012 ) .",
    "t apostol , _ calculus .",
    "volume ii : multi  variable calculus and linear algebra with applications .",
    "second edition _",
    "( wiley , new york , 1969 ) .",
    "ga miller , note on the bias of information estimates . in _ information theory in psychology : problems and methods ii - b _ h quastler , ed , pp .",
    "95100 ( free press , glencoe il , 1955 ) .",
    "a treves & s panzeri , the upward bias in measures of information derived from limited data samples .",
    "_ neural comp _ * 7 , * 399407 ( 1995 ) .",
    "sp strong , r koberle , rr de ruyter van steveninck & w bialek , entropy and information in neural spike trains .",
    "_ phys rev lett _ * 80 , * 197200 ( 1998 ) .",
    "l paninski , estimation of entropy and mutual information .",
    "_ neural comp _ * 15 , * 11911253 ( 2003 ) .",
    "i nemenman , w bialek & rr de ruyter van steveninck , entropy and information in neural spike trains : progress on the sampling problem .",
    "_ phys rev e _ * 69 , * 056111 ( 2004 ) .",
    "w feller , _ probability theory and its applications , volume i _",
    "( john wiley and sons , new york , 1950 ) .",
    "sk ma , calculation of entropy from data of motion .",
    "_ j stat phys _ * 26 , * 221240 ( 1981 ) .",
    "ja segal & hj spaeth , _ the supreme court and the attitudinal model revisited .",
    "_ ( cambridge university press , new york , 2002 ) .",
    "c kemp & jb tenenbaum , the discovery of structural form .",
    "_ proc natl acad sci ( usa ) _ * 105 , * 1068710692 ( 2008 ) ."
  ],
  "abstract_text": [
    "<S> we build simple models for the distribution of voting patterns in a group , using the supreme court of the united states as an example . </S>",
    "<S> the least structured , or maximum entropy , model that is consistent with the observed pairwise correlations among justices votes is equivalent to an ising spin glass . while all correlations ( perhaps surprisingly ) are positive , the effective pairwise interactions in the spin glass model have both signs , recovering some of our intuition that justices on opposite sides of the ideological spectrum should have a negative influence on one another . despite the competing interactions , a strong tendency toward unanimity emerges from the model , and </S>",
    "<S> this agrees quantitatively with the data . </S>",
    "<S> the model shows that voting patterns are organized in a relatively simple `` energy landscape , '' correctly predicts the extent to which each justice is correlated with the majority , and gives us a measure of the influence that justices exert on one another . </S>",
    "<S> these results suggest that simple models , grounded in statistical physics , can capture essential features of collective decision making quantitatively , even in a complex political context .    </S>",
    "<S> social and political systems , almost by definition , generate collective or emergent phenomena . </S>",
    "<S> it is natural to try describing these phenomena in the language of statistical mechanics @xcite , but it is not always clear whether this is a metaphor or a real theory within which we can make quantitative predictions . here </S>",
    "<S> we address this problem in the context of voting on the supreme court of the united states ( scotus ) . while nine justices surely are not in the thermodynamic limit </S>",
    "<S> , we argue that there still are quantitative predictions to be made , and that models grounded in statistical physics provide the simplest account of the observed voting patterns @xcite .    ]    </S>",
    "<S> scotus is the highest court in the us government , consisting of nine justices who vote on the constitutionality of legislative and executive actions . </S>",
    "<S> we consider natural courts , periods of time during which the membership stays constant , and focus on the second rehnquist court ( 19942004 , @xmath0 votes ) , which provides the largest data set @xcite . </S>",
    "<S> the court issues majority and minority opinions , and these can be supplemented with other opinions ; although opinions can be nuanced , each justice casts a yes ( @xmath1 ) or no ( @xmath2 ) vote , and the majority of votes decides the fate of the case .    a widely discussed fact of current political life in the united states is the strong polarization along party lines , so that consensus and unanimity have become rare . </S>",
    "<S> comments on the nature of decision making on the supreme court also point to strong ideological divisions between right and left , with one or two justices providing `` swing votes '' @xcite . in reality , </S>",
    "<S> unanimous decisions are much more likely than 5 - 4 splits @xcite , as shown in fig [ consensus ] . </S>",
    "<S> this pattern is consistent across more than fifty years , and there is little indication that the unanimous cases are in a special class of `` easy '' decisions @xcite .     </S>",
    "<S> votes ) . </S>",
    "<S> as explained in the text , yes / no votes are represented as binary variables @xmath3 for each justice @xmath4 , and we plot @xmath5 ; by convention , @xmath6 for all @xmath4 , and the diagonal elements @xmath7 . </S>",
    "<S> individual justices are identified by their initials @xcite , ordered roughly from ideological left ( js ) to right ( ct ) @xcite . </S>",
    "<S> note that all correlations are positive , despite ideological differences . </S>",
    "<S> the standard error in estimating @xmath8 is given by @xmath9^{1/2}$ ] ; with @xmath0 we have @xmath10 for all @xmath11.[cij ] ]    the definition of yes and no in each case is determined by decisions in lower courts , and thus is somewhat arbitrary . as a start , we imagine that the opposite definition was also possible , so that the voting patterns @xmath12 and @xmath13 are equally likely , and we return to this problem below . with this symmetry , we are guaranteed that the average vote is neutral , @xmath14 for all justices . </S>",
    "<S> then the first nontrivial voting statistic is the matrix of correlations , @xmath5 , shown in fig [ cij ] . </S>",
    "<S> while one might have expected that justices known to have opposite ideological positions would tend to cast opposing votes , we see that all correlations are positive . </S>",
    "<S> we would like to understand not just these pairwise correlations , but the entire distribution of voting patterns @xmath15 .    </S>",
    "<S> there are an infinite number of distributions @xmath15 that are consistent with the observed correlations @xmath8 . out of all these models </S>",
    "<S> , we can ask for the one which has the least structure , or equivalently the one that generates the most random patterns of votes . </S>",
    "<S> this distribution embodies the _ minimal _ implications of the pairwise correlations , and involves no further assumptions . </S>",
    "<S> we know from shannon @xcite that the qualitative concepts of `` most random '' and `` least structured '' have a unique formalization , namely that we should search for the distribution that has the maximal entropy consistent with @xmath8 @xcite . </S>",
    "<S> thus , we wish to construct @xmath15 that has the largest value of the entropy @xmath16 </S>",
    "<S> \\equiv -\\sum_{\\{\\sigma_{\\rm i}\\ } } p(\\{\\sigma_{\\rm i}\\ } ) \\ln p(\\{\\sigma_{\\rm i}\\ } ) , \\label{ent1}\\ ] ] while insisting that the correlations match their experimental values , @xmath17 the solution to this constrained optimization problem is a boltzmann  like distribution , @xmath18 where the effective energy of each state is given by @xmath19 and the parameters @xmath20 must be adjusted to satisfy the constraints in eq ( [ eq : cij ] ) ; as usual the partition function serves to normalize the distribution , so that @xmath21 we recognize eqs ( [ ising1][ising3 ] ) as mathematically equivalent to the ising model of a magnet , with `` spins '' @xmath22 interacting through `` couplings '' @xmath20 .    </S>",
    "<S> , as in eq ( [ ising2 ] ) . </S>",
    "<S> some @xmath23 are negative despite all positive @xmath24 in fig [ cij ] . for a discussion of errors in the estimates of @xmath20 , see appendix [ sec : solving inverse].[jij ] ]    with @xmath25 justices , eq ( [ eq : cij ] ) </S>",
    "<S> provides 36 simultaneous nonlinear equations for the @xmath20 , and it is straightforward to solve these numerically . </S>",
    "<S> the result for the rehnquist court ( fig [ cij ] ) is shown in fig [ jij ] . </S>",
    "<S> the first thing we notice is that the interactions @xmath20 , in contrast to the correlations @xmath8 , are both positive and negative .        </S>",
    "<S> the correlation matrix tells us that a positive vote by the most conservative justice ( ct ) raises the probability of a positive vote by the most liberal justice ( js ) by @xmath26 , but this includes all the indirect paths through other members of the court for these justices to influence one another . in the context of the joint distribution for all votes , a positive vote by ct , with all other votes held fixed , contributes a factor @xmath27 to the probability of a positive vote by js , surprisingly pulling js further in the same direction , at odds with the ideological intuition . but </S>",
    "<S> another ideological opposite like as , with a very similar voting record to ct , contributes a factor of @xmath28 , _ decreasing _ the probability by 30% . </S>",
    "<S> thus , this model constructed only from ( measured ) positive correlations unmasks the hidden negative interactions , but shows that these do not conform fully to the binary intuition of negative influence spanning the ideological spectrum and positive influence within blocs .    before proceeding , we address the errors in our estimates of the @xmath20 . </S>",
    "<S> individual @xmath20 are determined with standard deviations @xmath29 , but these errors are correlated . </S>",
    "<S> what really matters is our ability to predict the `` energy '' of each state through eq ( [ ising2 ] ) , and we find that for low energy states the errors in the energy are @xmath30 . </S>",
    "<S> thus , we can determine the parameters of the model well enough to predict probabilities of common states ( those which occur several times in the data ) with an accuracy of @xmath31 . </S>",
    "<S> for details see appendix [ sec : solving inverse ] .    </S>",
    "<S> just because the maximum entropy model is the least structured model consistent with the observed pairwise correlations does not mean that it is correct , since we can imagine interactions among groups of justices that would not be captured by measurements on pairs @xcite . </S>",
    "<S> the model , however , predicts the full distribution over voting patterns , and thus can be tested in various ways . </S>",
    "<S> first , we can calculate the probability that the vote is split @xmath32 , with @xmath33 votes in the majority , shown in fig [ fit]a . while there are small quantitative discrepancies </S>",
    "<S> , the model correctly predicts that unanimous votes are twice as likely as 54 splits , reproducing all the probabilities with @xmath34 accuracy . </S>",
    "<S> note that if the votes of the individual justices were independent , then unanimous votes would occur only @xmath35 of the time , while 54 splits would be the most common outcome . </S>",
    "<S> the observed tendency toward unanimity is described by the model as a truly emergent phenomenon , the minimal consequence of the observed correlations among pairs of justices .    </S>",
    "<S> although error bars are larger , a second test is to estimate the probability of every voting pattern in the data and compare these estimates with the predictions of the model . </S>",
    "<S> this is shown in fig [ fit]b , and we see that theory and experiment agree within error bars for almost all patterns that occur more than once in the data .    </S>",
    "<S> deviations between the model and the data are small , but could add up to significant effects . a third test , then , is to compare mutual information between the votes of individual justices and the majority vote @xmath36 , as shown in fig [ fit]c . </S>",
    "<S> the values of the mutual information @xmath37 range over a factor of four , so that so s vote provides @xmath38 bits of information about the decision of the court as a whole , while js s vote provides only @xmath39 bits . </S>",
    "<S> this pattern , related to previous observations @xcite , is reproduced very accurately by the model .    taken together , </S>",
    "<S> the three results in fig [ fit ] provide strong evidence that our model for the distribution of voting patterns captures the interesting structure in these data . </S>",
    "<S> we emphasize that this model is built only from measured pairwise correlations , and that once we have found the maximum entropy model there is no fitting of the data in fig [ fit ] ; instead we have unambiguous , quantitative predictions , with no adjustable parameters .    </S>",
    "<S> the most direct test of maximum entropy models is to measure the entropy itself . </S>",
    "<S> if we build maximum entropy models that capture correlations of order @xmath40 , then we generate a sequence of models with strictly decreasing entropy , @xmath41 @xcite . in this sequence </S>",
    "<S> , @xmath42 corresponds to a model of independent voting by each justice , while @xmath43 corresponds to the exact model which reproduces correlations of all orders . </S>",
    "<S> the total amount of correlation in the system can be measured by the multi  </S>",
    "<S> information , @xmath44 @xcite . </S>",
    "<S> the pairwise maximum entropy models capture a fraction @xmath45 of this structure . </S>",
    "<S> over all the natural courts shown in fig [ consensus ] , we find that @xmath46 .    </S>",
    "<S> the energy function @xmath47 in eq ( [ ising2 ] ) includes competing interactions , since the @xmath20 have both positive and negative signs . </S>",
    "<S> we expect that this competition will generate multiple local minima in the energy landscape @xcite , or local maxima in the probability distribution , where by a local maximum we mean that flipping the vote of any single justice lowers the probability of the voting pattern . for the rehnquist court , with @xmath20 in fig [ jij ] </S>",
    "<S> , we find that more than 99% ( 508/512 ) of the patterns fall into just @xmath48 `` valleys '' in the energy landscape . </S>",
    "<S> the most populated pair of valleys are built around the two possible unanimous votes . </S>",
    "<S> a second pair of valleys are built around 5 - 4 splits that occur precisely along ideological lines ( wr , so , as , ak , and ct vs. js , ds , rg , and sb ) . </S>",
    "<S> the third pair of valleys have at their base 7 - 2 splits , in which the most conservative and tightly correlated justices ( as and ct ) dissent from the majority . essentially all possible voting patterns thus are organized around intuitively understandable , prototypical patterns . </S>",
    "<S> importantly , this structure of coalitions among multiple justices emerges from the pairwise maximum entropy model with no additional assumptions ; for more details see appendix [ app : landscape ] . </S>",
    "<S> the organization of the energy landscape is truly emergent , since the pairwise interactions among the justices ( fig [ jij ] ) do not have a rigid block structure that would support the 54 ideological splits .    a basic question about the dynamics of a court concerns the influence that individual justices have on the majority decision . one way to measure </S>",
    "<S> this is by the mutual information @xmath37 ( fig [ fit]c ) ; because the votes are symmetric binary variables , this is equivalent to measuring the correlation @xmath49 @xcite . </S>",
    "<S> we can exploit the mapping of our model onto a system of spins and imagine what happens if we add to the energy function a term @xmath50 , such that each justice s vote is biased by a small `` magnetic field '' @xmath51 . </S>",
    "<S> then it is natural to ask how the bias of one justice propagates to the majority , that is @xmath52 . </S>",
    "<S> but because our model is equivalent to an equilibrium statistical mechanics problem , we have @xmath53 . </S>",
    "<S> thus , seemingly different ways of measuring influence are in fact the same , and none succeeds in isolating the direct effect of one justice on the majority .    in the analogy to a magnet , </S>",
    "<S> each justice experiences an effective field @xmath54 from the other justices . </S>",
    "<S> if we imagine that justice @xmath4 can `` lean '' in a positive direction by an amount @xmath55 , this creates fields @xmath56 . </S>",
    "<S> but through feedback , these fields will also bias the vote of justice @xmath4 . to isolate the influence of this one justice , we add an additional field , @xmath57 , that serves to hold fixed the average vote of justice @xmath4 , where @xmath58 . </S>",
    "<S> now we can ask how the average majority vote would change if justice @xmath4 sends a signal indicating an @xmath55 tendency toward a positive vote , but does not actually cast this vote . </S>",
    "<S> the resulting susceptibilities , @xmath59 , are summarized in table [ influence ] .    </S>",
    "<S> .measures of influence . </S>",
    "<S> mutual information @xmath60 between the vote of justice @xmath22 and of the court @xmath36 , as in fig [ fit]c . </S>",
    "<S> influence increases as we move from ideological extremes into the medians . </S>",
    "<S> susceptibility @xmath61 of the majority to a signal from justice @xmath4 , as defined in the text . </S>",
    "<S> [ cols=\"^,^,^\",options=\"header \" , ]     using the susceptibility @xmath61 as a measure of influence , we see that influence tends to increase as we move from the ideological extremes into the medians . </S>",
    "<S> the `` median justices '' </S>",
    "<S> so and ak are traditionally viewed as swing voters and indeed have maximal influence @xcite . at both ideological extremes </S>",
    "<S> , we see that justices js and ct have minimal  and nearly identical  influence . </S>",
    "<S> interestingly , the chief justice wr has a nearly median ranking according to this measure of individual influence , although his votes are more strongly predictive of the majority .    </S>",
    "<S> it is perhaps surprising that we have been able to build accurate models without accounting for justices ideological biases . on the contrary , </S>",
    "<S> structures that embody these biases emerge from the model . </S>",
    "<S> suppose , however , that we go back to the beginning and identify yes / no votes with right / left political positions @xcite . because we have lost the symmetry between yes and no , we want to build a maximum entropy model that matches both the pairwise correlations as before and the expectation values of the votes from individual justices , @xmath62 . </S>",
    "<S> this model still has the boltzmann form of eq ( [ ising1 ] ) , but now the energy function has explicit fields @xmath51 acting on each spin . </S>",
    "<S> one might expect that this is a very different model . </S>",
    "<S> in particular , it could be that the correlations between the votes of different justices are merely the reflection of their ideological biases , so that if we keep track of these , all the interactions @xmath20 will vanish . </S>",
    "<S> in fact , the couplings @xmath20 in the ideological model are almost the same as in the symmetrized model , with a correlation coefficient of 0.98 . </S>",
    "<S> this means , for example , that the correlations between votes by as and js ( discussed above ) arise not merely because they adhere to opposite biases , but because the genuinely tend to vote against one another . for a more detailed analysis , </S>",
    "<S> see appendix [ sec : ideological_votes ] and ref @xcite .    to summarize , a pairwise maximum entropy model is sufficient to capture the voting distribution of scotus . </S>",
    "<S> although there are small deviations from the predictions of the model , its success suggests that simple models , grounded in statistical physics , can provide surprisingly accurate descriptions of collective behavior even in a complex , political context . </S>",
    "<S> importantly , the notion that voting patterns  here , the competition between unanimity and ideological division  emerge from interactions among the justices in the same way that , for example , magnetism emerges from interaction among spins is _ not _ a metaphor . rather than being `` like a magnet , '' </S>",
    "<S> the voting patterns are mathematically equivalent to the spin configuration of a very particular ising magnet , whose interactions are determined by the available data @xcite .    </S>",
    "<S> we thank g berman , m castellana , b daniels , j flack , d krakauer , and m tikhonov for many helpful discussions . </S>",
    "<S> work in princeton was supported in part by the national science foundation through grants phy0957573 and ccf0939370 , by the wm keck foundation , and by the lewis  sigler fellowship . </S>",
    "<S> work at cuny was supported in part by the burroughs wellcome fund and by the winston foundation . </S>"
  ]
}