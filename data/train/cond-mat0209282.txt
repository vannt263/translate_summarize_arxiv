{
  "article_text": [
    "we consider a sequence processing neural network model described by the following equations@xmath7 @xmath10 where ising spin @xmath11 represents the firing state or resting state and @xmath12 is updating function corresponding with signum function which if @xmath13 , we get @xmath14 ; if @xmath15 , we get @xmath16 .",
    "the neurons evolve their states simultaneously with deterministic parallel dynamics and the time step is @xmath17 in all our work .    the synaptic connection matrix @xmath18 can be given by@xmath19 @xmath20 for a diluted model consisting of @xmath21 neurons .",
    "the @xmath22 vectors @xmath23 are randomly and independently stored patterns in neural networks .",
    "it means the stored patterns are organized in one @xmath22-period cycle .",
    "it can be introduced by definition @xmath24 in @xmath25 .",
    "the dilution factors @xmath26 or 1 are independent identically distributed random variables .",
    "they are selected by @xmath27 where @xmath28 $ ] is a random number and @xmath29 $ ] is the coupling degree of networks . for @xmath30 or @xmath31 , the model restore to a standard ( hopfield - hebb ) sequence processing model .    comparing with standard hopfield model , the synapses of equation @xmath32 are insufficient for the generation of stable fixed point in phase space , since they combine pattern @xmath33 with pattern @xmath34 .",
    "nevertheless , the transition from one pattern to another is so fast that it possible get into a stationary limit cycle for the modulo-@xmath22 checking of @xmath35 in @xmath36 .",
    "for measuring the retrieving ability of this model , in a similar way to the definition in hopfield models , the overlaps of state @xmath37 and the stored patterns with the initial arbitrary pattern @xmath38is defined by @xmath39 for example , in @xmath40 neurons with @xmath41 stored patterns in a cycle , we obtained a pattern sequence as @xmath42 ( see fig .",
    "it is easy to find that the series is equal to a cycle of stored patterns with 10 patterns for different retrieving times .",
    "there are another two important parameters for describing long time behaviors of networks : the cycle size @xmath43 and the relaxation time @xmath44 .",
    "they are defined by@xmath45    @xmath46\\ ] ]    @xmath47\\ ] ]    here , @xmath43 is the periodicity of attractors and @xmath44 is the time the system converging into the @xmath43-period cycles .",
    "in fact , the values of @xmath43 and @xmath44 are dependent upon the initial patterns @xmath48 and the coupling matrix @xmath18 * *  * * or the stored patterns @xmath49 .",
    "so , for a given value @xmath43 , we can choice many connection matrices * *  * * through randomly generating a large number of stored patterns .",
    "moreover , the average size of cycles and the average relaxation time can be defined by@xmath50 @xmath51 @xmath52 in which @xmath53 and @xmath54 are defined by @xmath55 and @xmath56 for the @xmath57-th sample .",
    "now , viewing the stored patterns series as a whole , our interest is the overlaps between @xmath58 and the stored cycle , not with a simple pattern in the stored series . as a special case , only for @xmath59 , we introduced the average cycle overlaps @xmath60 in which @xmath61 is the refreshed time scale .",
    "figure 1b shows that the system plotted in figure 1a is successful in forming @xmath62 for @xmath63 , but there is a very small error with @xmath64 for @xmath65 .",
    "for searching the features of period and relaxation time of attractors , we set the @xmath30 corresponding to the standard sequence processing networks in fig . 2 to 4 .",
    "we focus attention on the relations @xmath66 and @xmath67 in which the loading ratio @xmath0 is defined by @xmath68 . > from comparing the value of @xmath69 , the numbers of samples , given by @xmath70 or @xmath71 , we find simulation results of @xmath72 have only a very small error .",
    "considering our computer device , the value of @xmath21 ranges from @xmath73 to @xmath74 and the value of @xmath69 is @xmath71 in the following calculation .",
    "obviously there is a turning point @xmath75 dividing the curve of @xmath76 into two parts ( see fig .",
    "2 ) . in the first part with @xmath77 , we find stable behaviors of cycles with @xmath78 equal to @xmath79 the number of stored patterns . beyond this point",
    ", the curve gradually changes into an exponential dependence of @xmath80 . here",
    ", @xmath81 is a constant in the range from @xmath82 to @xmath83 for @xmath84 to @xmath74 .",
    "the value of @xmath85 increases so drastically that no results of @xmath86 are plotted .",
    "additionally , the @xmath75 are in the range 0.13 to 0.17 , and respectively the formation ratio @xmath87 to @xmath88 , where @xmath89 is the number of @xmath22-period attractors with @xmath90 and @xmath91 is the number of samples ( see fig .",
    "3 ) .    figure 4 shows the average relaxation times in fully coupled networks .",
    "similarly , an exponential dependence @xmath92 was observed with @xmath93 , @xmath94 and @xmath95 for @xmath84 , @xmath96 and @xmath97 , respectively .    in order to investigate the robustness of networks within the limits of @xmath98 , simulation with diluted connection",
    "have been carried out through changing the values of coupling degree @xmath99 or setting @xmath100 belong to @xmath101 randomly . in fig . 5 , in the same way as figure 2",
    ", it is easy to see that there exists a critical point @xmath102 and @xmath103 for @xmath104 , @xmath105 and @xmath106 . for stronger dilution",
    ", the average periodicity grows towards a plateau higher than @xmath107 .    in conclusion , for small systems with spin neurons",
    ", it can be seen that the ratio of the average size of attractors @xmath85 and the numbers of stored patterns is @xmath17 as long as the loading ratio @xmath108 , and then it increases strongly following an exponential law @xmath109 the more the system size increases , the more the ratio grows . from analyzing the average cycle",
    "overlaps @xmath110 ( fig .",
    "3 ) , there is a narrow quickly decreasing region near the turning point of periodicity .",
    "the maximal stored capacity@xmath8 at @xmath111 for @xmath112 , corresponding to @xmath113 , is much larger than at @xmath114 ( when @xmath115 ) , under the condition that @xmath116 .",
    "moreover , the average relaxation time depends exponentially on the loading ratio and it raises faster with larger systems .    additionally , through the simulation of the coupling degree @xmath99 in networks",
    ", it is clear that there is a narrow transition region between small and large @xmath117 centered on an inflection point @xmath118 .",
    "moreover , the larger loading ratio corresponding to the larger value of @xmath119 means its robustness of stored information is more unstable . beyond our expectation ,",
    "one result is a stable large attractor for highly diluted systems , another is that possibly @xmath119 depends only on @xmath0 for several different system sizes .",
    "this needs more detailed work in the future .",
    "above all , it is easy to see , not as in the asymmetric model given by gutfreund et al .",
    ", that the asymmetric factor is a major parameter@xmath120 , that the loading ratio @xmath0 is a very important factor in sequence processing networks .",
    "in fact , this difference from the definition of asymmetric connection strength by gutfreund et al ."
  ],
  "abstract_text": [
    "<S> the average length and average relaxation time of attractors in sequence processing neural networks are investigated . </S>",
    "<S> the simulation results show that a critical point of @xmath0 , the loading ratio , is found . below the turning point , the average length is equal to the number of stored patterns ; conversely , the ratio of length and numbers of stored patterns , grow with an exponential dependence @xmath1 . moreover , we find that the logarithm of average relaxation time is only linearly associated with @xmath0 and the turning point of coupling degree is located for examining robustness of networks .    _ keywords : _ neural network ; asymmetric neural networks ; attractor ; relaxation time ; dilution factor    [ [ section ] ]    the dynamic behavior of hopfield model@xmath2 , a global symmetric coupling neural network , is relatively simple : the system relaxes to a fixed point corresponding to a stable patterns@xmath3 . </S>",
    "<S> the latest result of its maximal stored capacity @xmath4 given by volk@xmath5 is @xmath6 because the synaptic connections in real biological neural networks have a highly degree of asymmetry and a real human idea consists of a set of patterns , many modification of hopfield model have been designed@xmath7 . in general </S>",
    "<S> , an asymmetric connection strength may arise to recall a series of patterns or even chaos behavior , and can not be studied by conventional statistical methods because it disobeys detailed balance .    in this paper </S>",
    "<S> , we study the behavior of attractors in a sequence processing model@xmath8 , a fully connected ising spin model , through numerical simulation with deterministic parallel dynamics . </S>",
    "<S> moreover , the robustness is examined by locating critical coupling degrees since the loss of synaptic connections in the human brain may occur because of brain damage@xmath9 . </S>"
  ]
}