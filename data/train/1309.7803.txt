{
  "article_text": [
    "two points inside a polygon @xmath3 are _ visible _ to each other if their connecting segment remains completely inside @xmath3 .",
    "the _ visibility polygon _ ( @xmath7 ) of a point @xmath8 inside @xmath3 ( or @xmath9 ) is the set of vertices of @xmath3 that are visible from @xmath8 .",
    "there have been many studies on computing @xmath7 s in simple polygons . in a simple polygon @xmath3 with @xmath10 vertices ,",
    "@xmath9 can be reported in time @xmath11 by spending @xmath12 time and @xmath13 of preprocessing space @xcite .",
    "this result was later improved by @xcite where the preprocessing time and space were reduced to @xmath4 and @xmath5 respectively , at the expense of more query time of @xmath14 .",
    "the visibility problem has also been considered for line segments .",
    "a point @xmath15 is said to be _ weakly visible _ from a line segment @xmath1 if there exists a point @xmath16 such that @xmath17 and @xmath15 are visible to each other .",
    "the problem of computing the _ weak visibility polygon _ of @xmath1 ( or @xmath2 ) inside @xmath3 is to compute all points of @xmath3 that are weakly visible from @xmath1 .",
    "if @xmath3 is simple ( with no holes ) , chazelle and guibas @xcite gave an @xmath18 time algorithm for this problem .",
    "et al . _",
    "@xcite showed that this problem can be solved in @xmath19 time if a triangulation of @xmath3 is given along with @xmath3 .",
    "since any @xmath3 can be triangulated in @xmath19 @xcite , the algorithm of guibas _ et al .",
    "_  always runs in @xmath19 time @xcite .",
    "another linear time solution was obtained independently by @xcite .",
    "the @xmath20 problem in the query version has been considered by few .",
    "it was shown in @xcite that a simple polygon @xmath3 can be preprocessed in @xmath12 time and @xmath13 space such that , given an arbitrary query line segment inside @xmath3 , @xmath21 time is required to recover @xmath22 weakly visible vertices .",
    "this result was later improved by @xcite in which the preprocessing time and space were reduced to @xmath4 and @xmath5 respectively , at expense of more query time of @xmath23 . in a recent work , we presented an algorithm to report @xmath2 of any @xmath1 in @xmath24 time by spending @xmath12 time and @xmath13 space for preprocessing  @xcite .",
    "later , chen and wang considered the same problem and , by improving the preprocessing time of the visibility algorithm of bose _",
    "@xcite , they improved the preprocessing time to @xmath13 @xcite .    in this paper",
    ", we show that the @xmath0 of a line segment @xmath1 can be reported in near optimal time of @xmath6 , after preprocessing the input polygon in time and space of @xmath4 and @xmath5 respectively .",
    "compared to the algorithms in @xcite and @xcite , the storage and preprocessing time has one fewer linear factor , at expense of more query time of @xmath6 .",
    "our approach is inspired by aronov _",
    "algorithm for computing the visibility polygon of a point  @xcite . in section [ sec : partial ] , we first show how to compute the _ partial weak visibility polygon _",
    "@xmath25 when @xmath1 is not inside a sub - polygon @xmath26 of @xmath27 .",
    "then , in section [ sec : balanced ] , we use a balanced triangulation to compute and report the final weak visibility polygon .",
    "in this section , we introduce some basic terminologies used throughout the paper . for a better introduction to these terms ,",
    "we refer the readers to guibas _ et al . _",
    "@xcite , bose _",
    "@xcite , and aronov _ et al .",
    "_ @xcite . for simplicity , we assume that no three vertices of the polygon are collinear .",
    "let @xmath3 be a simple polygon with @xmath10 vertices .",
    "also , let @xmath28 and @xmath8 be two points inside @xmath3 .",
    "the _ visibility sequence _ of a point @xmath28 is the sequence of vertices and edges of @xmath3 that are visible from @xmath28 .",
    "a _ visibility decomposition _ of @xmath3 is to partition @xmath3 into a set of _ visibility regions _ , such that any point inside each region has the same visibility sequence .",
    "this partition is induced by the _",
    "critical constraint edges _ , which are the lines in the polygon each induced by two vertices of @xmath3 , such that the visibility sequences of the points on its two sides are different .    in a simple polygon ,",
    "the visibility sequences of two _ neighboring _ visibility regions which are separated by an edge , differ only in one vertex .",
    "this fact is used to reduce the space complexity of maintaining the visibility sequences of the regions @xcite .",
    "this is done by defining the _ sink regions_. a sink is a region with the smallest visibility sequence compared to all of its adjacent regions .",
    "therefore , it is sufficient to maintain the visibility sequences of the sinks , from which the visibility sequences of all other regions can be computed . by constructing a directed dual graph over the visibility regions ( see figure  [ fig : f2 ] ) , one can maintain the difference between the visibility sequences of the neighboring regions @xcite .        in a simple polygon with @xmath10 vertices ,",
    "the number of visibility and sink regions are @xmath13 and @xmath5 , respectively  @xcite .      here",
    ", we present the @xmath19 time algorithm of guibas _ et al . _  for computing @xmath2 of a line segment @xmath1 inside @xmath3 , as described in @xcite",
    "this algorithm is used in computing the partial weak visibility polygons in an output sensitive way , to be explained in section  [ sec : partial : wvp ] . for simplicity , we assume that @xmath1 is a convex edge of @xmath27 , but we will show that this can be extended for any line segment in the polygon .",
    "let @xmath29 denote the shortest path tree in @xmath3 rooted at @xmath28 .",
    "the algorithm traverses @xmath29 using a dfs and checks the turn at each vertex @xmath30 in @xmath29 .",
    "if the path makes a right turn at @xmath30 , then we find the descendant of @xmath30 in the tree with the largest index @xmath31 ( see figure [ fig : f1 ] ) .",
    "as there is no vertex between @xmath32 and @xmath33 , we can compute the intersection point @xmath34 of @xmath35 and @xmath36 in @xmath37 time , where @xmath38 is the parent of @xmath30 in @xmath29 .",
    "finally the counter - clockwise boundary of @xmath3 is removed from @xmath30 to @xmath34 by inserting the segment @xmath39 .",
    "let @xmath26 denote the remaining portion of @xmath3 .",
    "we follow the same procedure for @xmath8 .",
    "this time , the algorithm checks every vertex to see whether the path makes its first left turn .",
    "if so , we will cut the polygon at that vertex in a similar way .",
    "after finishing the procedure , the remaining portion of @xmath26 would be the @xmath2 .    .",
    "in the left figure , the shortest path from @xmath28 to @xmath32 makes a first right turn at @xmath30 . in the right figure",
    ", the shortest path from @xmath8 to @xmath40 makes a first left turn at @xmath41 . ]",
    "suppose that a simple polygon @xmath3 is divided by a diagonal @xmath42 into two parts , @xmath43 and @xmath44 . for a query line segment @xmath45",
    ", we define the _ partial weak visibility polygon _ @xmath46 ( or @xmath47 for clarity ) to be the polygon @xmath48 . in other words",
    ", @xmath46 is the portion of @xmath3 that is weakly visible from @xmath1 _ through _ @xmath42 . in this section",
    ", we will show how to compute @xmath46 . later in section [ sec : balanced ] , we will use this structure to compute @xmath2 .",
    "is defined as the part of the sub - polygon @xmath43 that is weakly visible from @xmath1 . ]",
    "we will show how to use the algorithm of guibas _ et al .",
    "_ @xcite to compute @xmath46 . to do so",
    ", we preprocess the polygon so that we can answer the visibility query in an output sensitive way .",
    "the idea is to compute the visibility decomposition of the polygon and , for each decomposition cell , compute the potential shortest path tree structures .",
    "as the number of visibility regions is @xmath13 , the preprocessing cost of our approach would be high .    to overcome",
    ", we only consider the critical constraint edges that cut @xmath42 .",
    "the number of such constraint edges is @xmath19 and the complexity of the decomposition is reduced to @xmath5 .",
    "this decomposition can be computed in @xmath5 time .",
    "we call this decomposition the _ partial visibility decomposition _ of @xmath3 with respect to @xmath42",
    ". the remaining part of this section shows how to modify the linear algorithm of guibas _ et al . _",
    "@xcite so that @xmath46 can be computed in an output sensitive way .",
    "first , we show how to compute the shortest path trees , and then present our algorithm for computing @xmath46 .",
    "we define the _ partial shortest path tree _",
    "@xmath49 to be the subset of @xmath29 that lead to a leaf node in @xmath43 . in other words",
    ", @xmath49 is the union of the shortest paths from @xmath28 to all the vertices of @xmath43 . in this section ,",
    "we show how to preprocess the polygon @xmath27 , so that for any given point @xmath50 , any part of @xmath49 can be traversed in an output sensitive way . the shortest path tree @xmath49 is composed of two kinds of edges : the _ primary edges _ that connect the root @xmath28 to its direct visible vertices , and the _ secondary edges _ that connect two vertices of @xmath49 ( see figure [ fig : pspt ] ) .",
    "we also recognize two kinds of secondary edges : the 1st type of secondary edges ( 1st type for short ) are those edges that are connected to a primary edge , and the 2nd type are the ones that connect other vertices of the polygon .",
    "notice that if a point @xmath28 crosses a critical constraint and that constraint does not cut @xmath42 , then the structure of @xmath51 would not change .     for different points of @xmath44 .",
    "notice that as @xmath8 and @xmath52 are on the same visibility region w.r.t .",
    "@xmath43 , @xmath53 and @xmath54 have the same structure . ]",
    "we can compute the primary edges of @xmath55 by using aronov s output sensitive algorithm of computing the partial visibility polygon @xcite .",
    "more precisely , with a processing cost of @xmath4 time and @xmath5 space , giving a point @xmath28 in query time , a pointer to the sorted list of the vertices that are visible to @xmath28 can be computed in @xmath56 time .",
    "it is also necessary to compute the list of the secondary edges of every vertex of @xmath57 .",
    "each vertex @xmath52 in @xmath57 have @xmath19 possible 2nd type edges .",
    "depending on the parent of @xmath52 , a sub - list of these edges would appear in @xmath55 . to store all the possible 2nd type edges of @xmath52 ,",
    "we compute and store this sub - list , or to be precise , the starting and ending edges of the list , for all the possible parents of @xmath52 .",
    "as there are @xmath19 possible parents for a vertex , these calculations can be performed for all the vertices of the polygon in total time of @xmath4 and the data can be stored in @xmath5 space .",
    "having these data , we can , in the query time , access the list of the 2nd type edges of any vertex in constant time .",
    "we build the same structure for the 1st type edges .",
    "the parent of a 1st type edge is the root of the tree . as the root can be in any of the @xmath5 different visibility regions , computing and storing the starting and ending edges in the list of 1st type edges of a vertex cost @xmath12 time and @xmath13 space .",
    "we can reduce the time and space needed to compute and store these structures , having this property that two adjacent regions have only @xmath37 differences in their 1st type edges .",
    "[ lemm : lemma2 ] consider a visibility region @xmath58 in the polygon and suppose that the 1st type secondary edges are computed for a point @xmath28 in this region .",
    "for a neighboring region that share a common edge with @xmath58 , these edges can be updated in constant time .",
    "when a view point @xmath28 crosses the border of two neighboring regions , a vertex becomes visible or invisible to @xmath28 @xcite . in figure",
    "[ fig : h4 ] for example , when @xmath28 crosses the border specified by @xmath59 and @xmath15 , a 1st type secondary edge of @xmath59 becomes a primary edge of @xmath28 , and all the edges of @xmath15 become the 1st type secondary edges .",
    "we can see that no other vertex is affected by this movement .",
    "processing these changes can be done in constant time , since it includes the following changes : removing a secondary edge of @xmath59 ( @xmath60 ) , adding a primary edge ( @xmath61 ) , and moving an array pointer ( edges of @xmath15 ) from the 2nd type edges of @xmath60 to the 1st type edges of @xmath61 .",
    "note that we know the exact positions of these elements in their corresponding lists .",
    "finally , the only edge which involves in these changes can be identified in the preprocessing time ( the edge corresponding to the crossed critical constraint ) , so , the time we spent in the query time would be @xmath37 .",
    "enters a new visibility region , the combinatorial structure of @xmath49 can be maintained in constant time . ]",
    "having this fact and using a _ persistent data structure _ , e.g. _ persistent red - black tree _",
    "@xcite , we can reduce the cost of storing the 1st type edges by a linear factor .",
    "a persistent red - black tree is a red - black tree that can remember all its intermediate versions .",
    "if a set of @xmath10 linearly ordered items are stored it the tree and we perform @xmath62 update into it , any version @xmath63 , for @xmath64 , can be retrieved in time @xmath56 .",
    "this structure can be constructed in @xmath65 time by using @xmath66 space .",
    "[ theo : theo - pspt ] a simple polygon @xmath27 can be processed into a data structure with @xmath5 space and in @xmath4 time so that for any query point @xmath28 , the shortest path tree from @xmath28 can be reported in @xmath67 , where @xmath22 is the size of the tree that is to be reported .",
    "first , we use aronov s algorithm for computing the partial visibility polygon of @xmath28 . for this , @xmath5 space and @xmath4 time is needed in the preprocessing phase . for the secondary edges , @xmath4 time and @xmath5 space",
    "is needed to compute and store these edges .",
    "also , a point location structure is built on top of the arrangement .    in the query time",
    ", the partial visibility region of @xmath28 can be located in @xmath56 to have the sorted list of the visible vertices from @xmath28 .",
    "as the visible vertices from @xmath28 correspond to the primary edges of @xmath55 , we also have the primary edges of @xmath49 .    for the 1st type edges ,",
    "a tour is formed to visit all the cells of the partial visibility decomposition . from lemma [ lemm :",
    "lemma2 ] , we can start from an arbitrary cell , walk along the tour , and construct a persistent red - black tree on the 1st type edges of @xmath55 of a point in each cell .",
    "as there are @xmath5 cells and , each cell has @xmath19 1st type edges , the structure takes @xmath5 storage and can be built in @xmath4 preprocessing time . having this structure ,",
    "the 1st type edges of the cell containing @xmath28 can be retrieved from the persistent data structure in @xmath56 time .",
    "finally , at each node of the tree , we have the list of 2nd type edges from that node .",
    "therefore , the cost of traversing @xmath55 is the number of visited nodes of the tree , plus the initial @xmath56 time .",
    "in other words , the query time is @xmath67 , where @xmath22 is the number of the traversed edges of the @xmath55 .",
    "now that that we show how to compute @xmath51 for any point @xmath50 in the query time , we can use the linear algorithm presented in section [ sec : guibas ] for computing @xmath0 of a simple polygon and modify it to compute @xmath46 in an output sensitive way .",
    "as we can see in figure [ fig : polygonal - edge ] , the algorithm can be extended to the cases that @xmath1 is not a polygonal edge .",
    "we can assume @xmath1 to be a polygonal edge . ]    to achieve an output sensitive algorithm , we store some additional information about the vertices of the polygon in the preprocessing phase .",
    "we say that a vertex @xmath68 is _ left critical _ ( lc for short ) with respect to a point @xmath69 , if @xmath70 makes its first left turn at @xmath15 or one of its ancestors . in other words , each shortest path from @xmath28 to a non - lc vertex",
    "is a convex chain that makes only clockwise turns at each node .",
    "the _ critical state _ of a vertex is whether it is lc or not .",
    "if we have the critical state of all the vertices of @xmath43 with respect to a point @xmath8 , we say that we have the _ critical information _ of @xmath8 .",
    "the idea is to change the algorithm of section [ sec : guibas ] and make it output sensitive .",
    "the outline of the algorithm is as follows : in the first round , we traverse @xmath51 using dfs . at each vertex",
    ", we check whether this vertex is left critical with respect to @xmath8 or not .",
    "if so , we are sure that the descendants of this vertex are not visible from @xmath1 , so , we postpone its processing to the time it is reached from @xmath8 , and check other branches of @xmath51 .",
    "otherwise , proceed with the algorithm and check whether @xmath51 makes a right turn at this vertex . in the second round ,",
    "we traverse @xmath71 and perform the normal procedure of the algorithm .",
    "[ lemm : lemma3 ] all the traversed vertices in @xmath51 and @xmath71 are vertices of @xmath46 .    in the preprocessing phase ,",
    "we compute the critical information of a point inside each region , and assign this information to that region . in the query time and upon receiving a line segment @xmath1 , we find the regions of @xmath28 and @xmath8 . using the critical information of these two regions , the above algorithm can be applied to compute @xmath46 .    as there are @xmath5 visibility regions in the partial visibility decomposition , @xmath13 space is needed to store the critical information of all the vertices . for each region",
    ", we compute @xmath55 of a point , and by traversing the tree , we update the critical information of each vertex with respect to this region .",
    "an array of size @xmath19 is assigned to each region to store these information .",
    "we also build the structure described in section [ sec : pspt ] to compute @xmath72 in @xmath12 time and @xmath13 space . in the query time",
    ", we locate the visibility regions of @xmath28 and @xmath8 in @xmath56 time . by remark [ lemm : lemma3 ] ,",
    "when we proceed the algorithm in @xmath55s of @xmath28 and @xmath8 , we only traverse the vertices of @xmath46 .",
    "finally , as the processing time spent in each vertex is @xmath37 , the total query time is @xmath73 .    to improve this result",
    ", we use the fact that any two adjacent regions have @xmath37 differences in their critical information .",
    "[ lemm : lemma5 ] in the path between neighboring visibility regions , the changes of the critical information can be handled in constant time .",
    "0.4   w.r.t .",
    "@xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]    0.4   w.r.t .",
    "@xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]     +    0.4   w.r.t .",
    "@xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]    0.4   w.r.t .",
    "@xmath28 , as @xmath28 moves between the two regions.,title=\"fig : \" ]    suppose that we want to maintain the critical information of @xmath28 and @xmath28 is crossing the critical constraint defined by @xmath60 , where @xmath59 and @xmath15 are two reflex vertices of @xmath27 .",
    "the only vertices that affect directly by this change are @xmath59 and @xmath15 .",
    "depending on the critical states of @xmath59 and @xmath15 w.r.t .",
    "@xmath28 , four situations may occur ( see figure [ fig : e2 - 1 ] ) . in the first three cases ,",
    "the critical state of @xmath15 will not change . in the forth case ,",
    "however , the critical state of @xmath15 will change . before the cross",
    ", the shortest path makes a left turn at @xmath59 , therefore , both @xmath59 and @xmath15 are lc w.r.t .",
    "however , after the cross , @xmath15 is no longer lc .",
    "this means that the critical state of all the children of @xmath15 in the @xmath49 may change as well .    to handle these cases",
    ", we modify the way the critical information of each vertex w.r.t .",
    "@xmath28 are stored . at each vertex @xmath15 , we store two additional values : the number of lc vertices we met in the path @xmath74 from @xmath28 , or its _ critical number _ , and a _ debit number _ , which is the critical number that is to be propagated in the vertex subtree .",
    "it is clear that if a vertex is lc , it means that its critical number is greater than zero ( see figure [ fig : crtitical - numbers ] ) .",
    "also , if a vertex has a debit number , the critical numbers of all its children must be added by this debit number .",
    "notice that computing and storing these numbers along the critical information will not change the time and space requirements .     in @xmath75 .",
    "]    now let us consider the forth case in figure [ fig : e2 - 1 ] .",
    "when @xmath15 becomes visible to @xmath28 , it is no longer lc w.r.t .",
    "therefore , the critical number of @xmath15 is changed to @xmath76",
    ". however , instead of changing the critical numbers of all the children of @xmath15 , we set the debit number of @xmath15 to -1 , indicating that the critical numbers of all the vertices of its subtree must be subtracted by 1 .",
    "the actual propagation of this subtraction will happen at query time when @xmath49 is traversed .",
    "if @xmath28 moves in the reverse path , i.e. , when @xmath15 becomes invisible to @xmath28 , we handle the tree in the same way by storing @xmath77 in the debit numbers , and propagating this addition in the query time .",
    "a persistent data structure can be used to reduce the costs to @xmath4 preprocessing time and @xmath5 storage .",
    "we form a tour visiting all the cells and construct a persistent red - black tree on the critical information and the 2nd type edges of all the nodes .",
    "the structure takes @xmath5 storage and can be built in @xmath4 preprocessing time .",
    "in addition , we build a point location structure on top of the arrangement which can be done in @xmath5 time and @xmath5 space @xcite .    [",
    "theorem : partial - visibility ] given a polygon @xmath27 and a diagonal @xmath42 which cuts @xmath27 into two parts , @xmath43 and @xmath44 , and using @xmath4 time , we can construct a data structure of size @xmath5 so that , for any query line segment @xmath45 , the partial weak visibility polygon @xmath46 can be reported in @xmath73 time .",
    "there is always a diagonal @xmath42 of a simple polygon that cuts @xmath3 into two pieces , each having at most @xmath78 vertices @xcite .",
    "we can recursively subdivide and build a balanced binary tree where the leaves are triangles and each interior node @xmath79 corresponds to a subpolygon @xmath80 and a diagonal @xmath81 .",
    "each diagonal @xmath81 divides @xmath80 into two subpolygons , @xmath82 and @xmath83 , which respectively correspond to the left and right subtrees of @xmath79 ( see figure [ fig : triangulation ] ) .",
    "we build the data structures described in section [ sec : partial ] for @xmath82 and @xmath83 with respect to @xmath81 .",
    "[ cross/.style = draw = red , thick , circle , fill = red!20,minimum height=1em , leaf/.style = draw = blue , thick , circle , fill = blue!20,minimum height=1em , normal/.style = draw = yellow!4 , thick , circle , fill = yellow!10,minimum height=1em , level distance=8 mm , every node/.style = circle , inner sep=1pt , level 1/.style = sibling distance=32 mm , level 2/.style = sibling distance=16 mm , level 3/.style = sibling distance=8 mm , level 4/.style = sibling distance=4 mm , level 5/.style = sibling distance=2 mm ] child node [ cross ] 2 child node 3 child node 4 child node 5 child node 5 child node 4 child node 5 child node 5 child node [ cross ] 3 child node 4 child node 5 child node 5 child node [ cross ] 4 child node 5 child node [ leaf ] 5 child node [ cross ] 2 child node [ cross ] 3 child node [ cross]4 child node [ leaf ] 5 child node [ leaf ] 5 child node [ leaf]4 child node 5 child node 5 child node [ cross ] 3 child node [ cross]4 child node [ leaf]5 child node 5 child node 4 child node 5 child node 5 ;    to compute @xmath2 , @xmath28 and @xmath8 will be located among the leaf triangles . in the simplest case ,",
    "both @xmath28 and @xmath8 belong to the same triangle .",
    "first we explain this situation .",
    "we construct @xmath84 for each @xmath79 from the leaf to the root . here , @xmath84 is the partial weak visibility polygon of @xmath1 in @xmath80 with respect to @xmath81 . for the leaf node ,",
    "it is the corresponding triangle , and for other nodes , it can be computed inductively . in this case",
    ", the inductive step is similar to that of @xcite . in each step",
    ", the merging of the computed polygons can be done in @xmath56 .",
    "the time and space needed for building an exterior visibility decomposition of a simple polygon with @xmath62 vertices are @xmath85 and @xmath86 , respectively .",
    "thus , the space and time of the above inductive procedure can be expressed as the following equations : @xmath87 therefore , @xmath88 , and @xmath89 . with the same analysis as in @xcite",
    ", we can calculate the query time .",
    "two point locations can be done in @xmath56 time .",
    "as the triangulation is balanced , we path from the root to any node has @xmath56 length . as we showed in theorem [ theorem : partial - visibility ] , the time needed to query @xmath84 at step @xmath79 is @xmath90 .",
    "also , the merging at each step can be done in @xmath56 time .",
    "therefore , the total query time is @xmath91 , or @xmath92 .",
    "the tricky part is when @xmath28 and @xmath8 are on different triangles .",
    "assume that at step @xmath79 , the query line segment is @xmath93 and it is in sub - polygon @xmath80 .",
    "the sub - polygon @xmath80 is divided by diagonal @xmath81 to two sub - polygons @xmath82 and @xmath83 .",
    "if @xmath93 does not intersect @xmath81 , without loss of generality , assume that @xmath93 is located in @xmath83 ( see figure [ fig : inductive - step-1 ] ) .",
    "we do the normal procedure of the algorithm and compute @xmath94 .",
    "we continue to recursively compute weak visibility polygon on @xmath83 . in this case",
    ", the time needed by this step can be expressed as @xmath95 .    on the other hand , if @xmath93 and @xmath81 intersect at point @xmath96 , without loss of generality , assume that @xmath97 is in @xmath83 and @xmath98 is in @xmath82 ( see figure [ fig : inductive - step-2 ] ) .",
    "we can express @xmath99 as the union of four weak visibility polygons :    1 .",
    "the partial weak visibility polygon of @xmath100 on @xmath82 , 2 .",
    "the weak visibility polygon of @xmath100 in @xmath83 , 3 .",
    "the partial weak visibility polygon of @xmath101 on @xmath83 , 4 .",
    "the weak visibility polygon of @xmath101 in @xmath82 .    in other words ,",
    "we must compute two partial weak visibility polygons , and two weak visibility sub - problems . having these four visibility polygons ,",
    "the union of them can be merged in time @xmath102 . according to the theorem [ theorem : partial - visibility ] , the query time spent at step @xmath79",
    "can be expressed as : @xmath103 .",
    "0.48     0.48     the preprocessing costs of the algorithm is the same as before . for the query time , by induction , we can prove that @xmath104 .",
    "assume that this property holds for every simple polygon with less than @xmath10 vertices and every line segment @xmath1 in it .",
    "for a simple polygon @xmath27 with @xmath10 vertices , depending on whether @xmath1 cuts the diagonal @xmath42 , we have one of these equation : @xmath105 here , @xmath106 is the partial weak visibility polygon of @xmath1 w.r.t .  the cut @xmath42 . in the first case",
    ", we have @xmath107 in the second case , we have @xmath108 in these equations , @xmath109 is the weak visibility polygon of @xmath1 in a polygon of size @xmath110 .    as for the base case",
    ", we showed that if @xmath1 is located in single triangle , the time for computing @xmath2 would be @xmath6 . in summary",
    ", we have the following theorem :    [ theoremxx ] a simple polygon @xmath3 of size @xmath10 can be processed in @xmath4 time into a data structure of size @xmath5 so that , for any query line segment @xmath1 , @xmath2 can be reported in time @xmath111 .",
    "in this paper , we showed how to answer the weak visibility queries in a simple polygon with @xmath10 vertices in an efficient way . in the first part of the paper",
    ", we defined the partial weak visibility polygon @xmath112 of a line segment @xmath1 with respect to a diagonal @xmath42 and presented an algorithm to report it in time @xmath113 , by spending @xmath4 time to preprocess the polygon and maintaining a data structure of size @xmath5 .",
    "in the second part , we presented a data structure of size @xmath5 which can be computed in time @xmath4 so that the weak visibility polygon @xmath2 from any query line segment @xmath114 can be reported in time @xmath115 .",
    "b. aronov , l. j. guibas , m. teichmann and l. zhang .",
    "visibility queries and maintenance in simple polygons . _ discrete and computational geometry _ , 27(4):461 - 483 , 2002 .",
    "p. bose , a. lubiw , j. i. munro .",
    "efficient visibility queries in simple polygons .",
    "_ computational geometry : theory and applications _ , 23(3):313 - 335 , 2002"
  ],
  "abstract_text": [
    "<S> this paper considers the problem of computing the weak visibility polygon ( @xmath0 ) of any query line segment @xmath1 ( or @xmath2 ) inside a given simple polygon @xmath3 . </S>",
    "<S> we present an algorithm that preprocesses @xmath3 and creates a data structure from which @xmath2 is efficiently reported in an output sensitive manner .    </S>",
    "<S> our algorithm needs @xmath4 time and @xmath5 space in the preprocessing phase to report @xmath2 of any query line segment @xmath1 in time @xmath6 . </S>",
    "<S> we improve the preprocessing time and space of current results for this problem  @xcite at the expense of more query time .    computational geometry , visibility , line segment visibility </S>"
  ]
}