{
  "article_text": [
    "the basic idea behind multi - factor risk models for equities is that , in lieu of computing a sample covariance matrix ( scm ) for a large number of stocks , it allows to compute a factor covariance matrix ( fcm ) for many fewer risk factors .",
    "why is this useful ? when the number of stocks @xmath5 in the trading universe is large , it is either impracticable or impossible to reliably compute scm . in practical applications ,",
    "the number of historical observations in the time series of returns based on which scm is computed is too low , so scm is either singular or its off - diagonal elements are not out - of - sample stable .",
    "this is further exacerbated by the fact that , for applications involving shorter - horizon quantitative trading strategies , the desirable lookback for the risk model should not be too long .",
    "indeed , for extremely ephemeral short - holding alphas whose lifespan can be as short as a few months , it is not too relevant what scm matrix looked like , say , 5 years ago  and 5 years contain only about 1260 daily observations , whereas a typical quantitative trading universe can consist of as many as 2,000 - 2,500 liquid enough to trade stocks .",
    "multi - factor risk models alleviate this issue by modeling off - diagonal elements of scm as owing to a much smaller number @xmath6 of risk factors , and in the zeroth approximation one can compute sample @xmath7 fcm . in most common incarnations ,",
    "these risk factors consist of a combination of style factors and industry ( classification based ) factors .",
    "the number of style factors , which are based on some estimated ( or measured ) properties of stocks ( such as size , momentum , volatility , liquidity , value , growth , _",
    "etc_. ) , typically is limited , of order 10 or fewer .",
    "however , the number of industry factors can be much larger , from several dozen for less granular incarnations , to a few hundred for more granular risk models , where the number of industry factors can depend on the trading universe . in these cases , if the desirable lookback is short ( say , 1 - 2 years or less ) , then reliably computing sample @xmath7 fcm itself becomes impracticable or impossible",
    ". what can we do in such cases ?",
    "the idea we advance in this paper is quite simple . if sample fcm can not be computed , we can model fcm itself via a factor model with a much smaller number @xmath8 of yet new risk factors . if sample fcm can be reliably computed for these new factors  good ; if not , then we model fcm for the new factors via yet another factor model with a much smaller number @xmath9 of yet new risk factors . and",
    "so on  until either we can reliably compute fcm for the resulting ( small enough number of ) risk factors , or we altogether eliminate the need for computing non - diagonal fcm by reducing the number of risk factors to 1 ( in this case we have @xmath10 fcm , which is a variance and can be reliably computed ) or even 0 .",
    "we refer to this construction as a ( nested ) russian - doll risk model , in analogy with russian  matryoshkas \" . here",
    "one may wonder if a russian - doll model is simply equivalent to a conventional multi - factor risk model with fewer risk factors .",
    "the answer is no .",
    "a russian - doll risk model is actually equivalent to a conventional multi - factor risk model with more risk factors , but with mostly ( or completely  in the case where no fcm need be computed ) diagonal factor covariance matrix .",
    "in a russian - doll risk model , essentially , one is modeling off - diagonal elements in scm via factor loadings and specific risks for the risk factors arising at each intermediate step in the successive nested embedding . in this regard ,",
    "it is natural to wonder , given a set of risk factors , if we wish to model their fcm via a factor model , what should be the fewer new risk factors for this nested factor model ?",
    "the answer is evident in the case of industry classification based risk factors with a tree - like hierarchy such as  sector @xmath0 industry @xmath0 sub - industry \" in the case of bics ( bloomberg industry classification system )  other industry classifications such as gics , icb , sic , naics , _ etc .",
    "_ , use other namings for the levels in their hierarchical trees , and the number of levels in such trees need not be 3 either . using the bics example to illustrate our idea here ,",
    "if we start with a relatively large number @xmath11 of sub - industries , the risk factors for modeling fcm for sub - industries via a factor model would be industries , and the risk factors for modeling fcm for industries via a factor model would be sectors .",
    "the number of bics sectors is only 10 .",
    "if need be , we can take this nested russian - doll embedding a step further and use the  market \" ( _ e.g. _ , equally weighted average of all stock return , or the intercept in the regression terminology ) as the sole risk factor for modeling fcm for sectors via a single - factor model , thereby eliminating the necessity of computing non - diagonal fcm altogether : @xmath12 fcm for the remaining single factor is just its variance .    in the case of binary industry classification based risk factors",
    "the russian - doll embedding , as we saw above , is natural .",
    "what about non - binary style risk factors ? in this case there is no simple prescription for reducing their number .",
    "however , in practical applications there is no need to reduce the number of style risk factors as this number is already small , especially for short - horizon returns  recently it was argued in ( kakushadze , 2014 ) that the number of relevant style risk factors for overnight ( and similarly short - horizon ) returns is at most 4 . as we discuss in detail in section [ sec3 ] , this allows us to construct a russian - doll model for a combination of style plus industry classification based risk factors , where we keep the style risk factors intact and reduce the number of industry factors via a russian - doll embedding . at the end , we only need to compute fcm for a small number of risk factors , which include the original style risk factors ( plus , _",
    "e.g. _ , sector or  market \" risk factors ) .",
    "one question that arises in all multi - factor model building is how to compute fcm and specific risk in a consistent fashion .",
    "there exist nontrivial algorithms for doing this , and they are typically deemed proprietary , so they are not discussed in the literature . in section 3",
    "we explain why such algorithms are needed and why a naive approach fails .",
    "in the context of russian - doll risk models one can use such an algorithm at each stage of modeling fcm by a factor model .",
    "however , in section 4 we discuss an illustrative example and a cruder way of constructing a russian - doll risk model in the case of industry classification based risk factors without the need to employ such sophisticated proprietary algorithms . while this is admittedly a",
    " layman s \" way of building a russian - doll risk model , it serves the purpose of illustrating the construction and enables us to run backtests on some simple intraday mean - reversion alphas to make sure that it adds value .",
    "in a multi - factor risk model , a sample covariance matrix @xmath13 for @xmath5 stocks , @xmath14 is modeled by @xmath15 given by @xmath16 where @xmath17 is the kronecker delta ; @xmath15 is an @xmath18 matrix ; @xmath19 is specific risk ( a.k.a .",
    "idiosyncratic risk ) for each stock ; @xmath20 is an @xmath21 factor loadings matrix ; and @xmath22 is a @xmath7 factor covariance matrix , @xmath23 . _",
    "i.e. _ , the random processes @xmath24 corresponding to @xmath5 stock returns are modeled via @xmath5 random processes @xmath25 ( corresponding to specific risk ) together with @xmath11 random processes @xmath26 ( corresponding to factor risk ) : @xmath27 the main reason for replacing the sample covariance matrix @xmath13 by @xmath15 is that the off - diagonal elements of @xmath13 typically are not expected to be too stable out - of - sample .",
    "a constructed factor model covariance matrix @xmath15 is expected to be much more stable as the number of risk factors , for which the factor covariance matrix @xmath22 needs to be computed , is @xmath28 .",
    "also , if @xmath29 , where @xmath30 is the number of observations in each time series , then @xmath13 is singular with @xmath31 nonzero eigenvalues . assuming all @xmath32 and @xmath22 is positive - definite , then @xmath15 is automatically positive - definite ( and invertible ) .",
    "while the factor model covariance matrix @xmath15 is expected to be more stable than the sample covariance matrix @xmath13 , in practical applications , if the number of risk factors @xmath11 is too large , the factor covariance matrix @xmath22  and consequently @xmath15  may not be stable enough .",
    "in fact , if @xmath33 , then @xmath22 itself would be singular .",
    "this is the case not only when the number of available observations in the time series of stock returns is limited , but also when it is not desirable to consider long lookbacks , _",
    "e.g. _ , when the risk model is intended to be used for ( ultra-)short horizon strategies . in such cases , due to the ephemeral nature of underlying alphas , often it makes little to no sense to go back years or even months when computing the factor covariance matrix and specific risk .",
    "this then implies that the number of risk factors @xmath11 can not be too large .",
    "however , in some cases there is a way to effectively enlarge the number of risk factors by capturing a partial ( and out - of - sample stable ) effects of more than @xmath31 risk factors .",
    "we discuss this methodology in the next section , first for the case of a binary industry classification , and then for a more general setting .",
    "the general idea behind nested risk models is simple .",
    "suppose we have @xmath11 risk factors @xmath26 .",
    "if the desirable / available number of observations @xmath33 , then the factor covariance matrix @xmath22 is singular . even if @xmath34 ,",
    "unless @xmath35 , @xmath22 typically is not expected to be too stable out - of - sample .",
    "so , the idea is to model @xmath22 itself via a factor model ( as opposed to computing it as a sample covariance matrix of the risk factors @xmath26 ) : @xmath36 where @xmath37 is the specific risk for @xmath26 ; @xmath38 , @xmath39 , @xmath40 is the corresponding factor loadings matrix ; and @xmath41 is the factor covariance matrix for the underlying risk factors @xmath42 , @xmath40 , where we assume that @xmath43 .    with the factor covariance matrix @xmath22 modeled as above , we have the following factor model covariance matrix for stocks : @xmath44 where ( in matrix notation ) @xmath45 note that the first and third terms on the r.h.s . in ( [ gamma.doll ] ) comprise nothing but an @xmath46-factor model .",
    "however , it is the presence of the second term that makes a difference .",
    "in addition to the @xmath46 risk factors ( the third term on the r.h.s . in ( [ gamma.doll ] ) ) , it models off - diagonal terms in @xmath15 via the factor loadings @xmath20 and the specific risks @xmath37 for the factors @xmath26 .",
    "if computed properly ( see below ) , specific risk  just as total risk  is much more stable out - of - sample than sample correlations .",
    "this is because  just as for total risk  specific risk corresponds to variances ( as opposed to off - diagonal elements in a sample covariance matrix ) .",
    "this makes the nested  russian - doll \" (  matryoshka \" ) risk model construction ( [ gamma.doll ] ) much more stable out - of - sample than the direct construction ( [ gamma ] ) , yet it captures off - diagonal contributions in @xmath15 beyond what an @xmath46-factor model would account for .",
    "in fact , ( [ gamma.doll ] ) is a @xmath47-factor model of a special form .",
    "indeed , we can rewrite ( [ gamma.doll ] ) as follows : @xmath48 where @xmath49 is an @xmath50 factor loadings matrix of the form @xmath51 and @xmath52 is a @xmath53 factor covariance matrix of the form @xmath54 so @xmath52 is almost diagonal  except for the off - diagonal elements in @xmath41 .",
    "our discussion above might sound like a free lunch .",
    "it is not .",
    "there is still work to be done .",
    "in particular , it is not always evident what the risk factors @xmath42 for modeling the risk factors @xmath26 should be .",
    "fortunately , there are cases where ( most of ) the required work has already been done .",
    "binary industry classifications are one such case .",
    "first we keep our discussion general and then apply the binary property .    for concreteness we will use the bics terminology for the levels in the industry classification , albeit this is not critical here . also , bics has three levels  sector @xmath0 industry @xmath0 sub - industry \" ( where  sub - industry \" is the most detailed level ) . for definiteness",
    ", we will assume three levels here , albeit generalization to more levels is straightforward .",
    "so , we have : @xmath5 stocks labeled by @xmath55 ; @xmath11 sub - industries labeled by @xmath39 ; @xmath46 industries labeled by @xmath40 ; and @xmath56 sectors labeled by @xmath57 .",
    "a nested russian - doll risk model then is constructed as follows : is the specific risk for the risk factors @xmath42 corresponding to industries , @xmath58 is the factor covariance matrix for sectors , and @xmath59 is the corresponding factor loadings matrix .",
    "other notations are as above and self - explanatory . ]",
    "@xmath60 where @xmath61 note that it is the second and third terms on the r.h.s . of ( [ gamma.doll.3 ] ) that make ( in an out - of - sample stable fashion ) this construction different from an @xmath56-factor model corresponding to sectors as risk factors .    here",
    "too , we can view ( [ gamma.doll.3 ] ) as a larger , @xmath62-factor model of a special form : @xmath48 where @xmath49 is an @xmath63 factor loadings matrix of the form @xmath64 and @xmath52 is a @xmath65 factor covariance matrix of the form @xmath66 so @xmath52 is almost diagonal  except for the off - diagonal elements in @xmath58 .",
    "we can take the above construction one step further and reduce it to a  single - factor \" model by modeling @xmath58 via a 1-factor risk model .",
    "the factor loadings matrix @xmath67 is just a column , an ( @xmath68 ) matrix , which can be chosen to be simply the intercept : @xmath69 .",
    "the corresponding factor covariance matrix @xmath70 is just a positive number ( @xmath10 matrix ) , so we have @xmath71 and @xmath72 where @xmath73 this  single - factor \" model is actually a @xmath74-factor model with the factor loadings matrix given by @xmath75 and a diagonal factor covariance matrix given by @xmath76 .",
    "further , note that if we set @xmath77 , we obtain a ",
    "zero - factor \" russian - doll model , where all off - diagonal elements are modeled via the second , third and forth terms on the r.h.s . of ( [ gamma.doll.3 ] ) , which is actually a @xmath62-factor model with a diagonal factor covariance matrix .",
    "the binary property implies that each stock belongs to one and only one sub - industry , industry and sector .",
    "the factor loadings matrices @xmath20 , @xmath38 and @xmath59 are given by @xmath78 where @xmath79 is the map between stocks and sub - industries , @xmath80 is the map between sub - industries and industries , and @xmath81 is the map between industries and sectors : @xmath82 this implies that @xmath83 where @xmath84 is the map between stocks and industries , and @xmath85 is the map between stocks and sectors . eq .",
    "( [ gamma.doll.sec ] ) then simplifies as follows : @xmath86 the key simplifying feature of a binary industry classification below . ]",
    "is that the risk factors @xmath26 , @xmath42 and @xmath87 ( where @xmath87 are the risk factors for the factor model ( [ psi ] ) for @xmath41 ) are explicitly known once the industry classification tree is specified : @xmath26 correspond to the sub - industry risk , @xmath42 correspond to the industry risk , and @xmath87 correspond to the sector risk .",
    "therefore , constructing the russian - doll risk model boils down to calculating @xmath58 factor covariance matrix for the sector risk factors @xmath88 and also fixing the specific risks @xmath19 , @xmath37 and @xmath89 ( see below ) .",
    "the beauty of dealing with a binary ] classification is that the hierarchy of risk factors ( _ i.e. _ , @xmath90 ) is fixed by the classification hierarchy ( _ i.e. _ ,  sector @xmath0 industry @xmath0 sub - industry \" ) , and the latter is readily available ",
    "the industry classification provider has already done all the hard work of analyzing companies products and/or services , revenue sources , _ etc . _ , that determine the company taxonomy and industry classification . with non - industry risk factors",
    "it is not always as straightforward to identify a nested hierarchy of risk factors .",
    "_ e.g. _ , in the case of principal component based risk factors there is no evident guiding principle to do so .",
    "however , not all is lost . in practice ,",
    "the most popular multi - factor risk models combine non - binary style risk factors and binary industry risk factors .",
    "the number of style factors typically is substantially smaller than the number of industry factors , especially for ( ultra-)short horizon models .",
    "_ e.g. _ , recently in ( kakushadze , 2014 ) it was argued that for overnight returns there are essentially 4 relevant style risk factors .",
    "the question we wish to address here is whether we can start with a few style risk factors plus many more industry based risk factors ( typically , @xmath91 or more ) , and build a russian - doll risk model .",
    "it is precisely the fact that we have only a few style risk factors that allows us to build a russian - doll model  this is because there is no need to reduce the number of style risk factors , only that of the industry based risk factors .",
    "so , the idea here is quite simple . we will use the mid - greek symbols @xmath92 to label the style risk factors , and we use the @xmath93 labels as above .",
    "let @xmath94 , @xmath95 and @xmath96 . let @xmath97 be the number of style risk factors .",
    "let @xmath98 , @xmath99 and @xmath100 .",
    "then we can apply the method of subsection [ sub3.1 ] to @xmath101 : @xmath102 so we have @xmath103 where @xmath104 and we further have @xmath105",
    "so , at the end , everything is fixed via the @xmath106 factor covariance matrix @xmath107 and the specific risks @xmath19 , @xmath37 and @xmath89 . as before ,",
    "the factor loadings matrices @xmath20 , @xmath38 and @xmath59 are binary .",
    "one may ask , this is all good , but how do i compute the remaining factor covariance matrix @xmath108 and the specific risks @xmath19 , @xmath37 and @xmath89 ? a simple answer is that , if one knows how to compute the factor covariance matrix and specific risk for the usual factor model ( [ gamma ] ) , then the same methods can be applied to the russian - doll factor models with some straightforward adjustments .",
    "however , the methodologies for computing the factor covariance and specific risk are usually deemed proprietary solutions llc . ] and , therefore , are well outside of the scope of this note .",
    "nonetheless , here we wish to discuss what appears to be a common misconception for how to compute the factor covariance matrix and specific risk and point out where and why it fails .",
    "this misconception apparently stems from a formal similarity between ( [ upsilon ] ) and a linear ( cross - sectional ) regression @xmath109 where @xmath110 labels time series , @xmath111 are stock returns ( _ e.g. _ , daily close - to - close returns , in which case @xmath110 labels trading dates ) , @xmath112 are the regression residuals ( for each date @xmath110 ) , @xmath113 are factor betas , and @xmath114 are factor returns ( note that we have @xmath11 factors ) .",
    "if for some period @xmath113 are independent of @xmath110 , @xmath115 ( _ e.g. _ , we compute them monthly ) , then we can identify @xmath116 with @xmath20 , and , for each date @xmath110 , @xmath111 is identified with @xmath24 , @xmath112 is identified with @xmath25 , and @xmath114 is identified with @xmath26 .",
    "it is then tempting to erroneously conclude that the factor covariance matrix @xmath22 is simply given by @xmath117 , while the specific variance @xmath118 is given by @xmath119 , where the covariance @xmath120 is computed over the time series ( and we have suppressed the index @xmath110 ) .",
    "however , a quick computation reveals the fallacy of this approach .",
    "indeed , from the definition of the linear regression ( without intercept and unit weights ) we have ( in matrix notation ) @xmath121 r\\end{aligned}\\ ] ] where ( note that @xmath122 is a projection operator : @xmath123 ) @xmath124 consequently , we have : @xmath125 c \\left[1 - q\\right]\\\\   & & \\omega\\left \\langle f , f^t\\right\\rangle\\omega^t = q~c~q\\end{aligned}\\ ] ] where @xmath126 is the sample covariance matrix .",
    "now we can immediately see the issue with identifying @xmath22 with @xmath117 and @xmath118 with @xmath119 .",
    "the total variance @xmath127 according to the factor model is given by @xmath128 with the above ( erroneous ) identifications , the factor model total variance @xmath127 does _ not _ coincide . ] with the in - sample total variance @xmath129  and a factor model had better reproduce the in - sample total variance ( while attempting to predict out - of - sample total variance as precisely as possible ) . also note that if we keep the above identification of @xmath22 with @xmath117 and simply _ define _ @xmath130 ,",
    "generally we will ( unacceptably ) have some negative @xmath118 .",
    "while computing the factor covariance matrix and specific risk(s ) is nontrivial ( and a proprietary topic ) , the russian - doll risk modeling allows to bypass such complications by using simple heuristics .",
    "we emphasize that using the full - fledged risk modeling by carefully computing the factor covariance matrix and specific risk(s ) generally yields better results .",
    "however , if the latter is not possible , the heuristic approach , which we illustrate in this section , provides an approximate method for incorporating off - diagonal correlations into the covariance matrix .",
    "the idea here is very simple . to avoid the headaches discussed in subsection [ fix.cov.mat ] ,",
    "let us simply avoid computing _ any _ factor covariance matrix .",
    "we are then led to consider the  single - factor \" russian - doll factor model ( [ gamma.doll.3 ] ) , where the only  factor covariance matrix \" is the @xmath10 matrix @xmath70 , which is in fact the _ variance _ of the single factor , which in turn can be interpreted as the overall  market \" exposure .. ] not to overcomplicate our discussion here , let us stick to the binary case . then , using the same notations as above , we have : @xmath131 so , the total variance is given by @xmath132 as above , we wish to identify @xmath127 with the in - sample total variance @xmath129 .",
    "this gives us @xmath5 equations for @xmath133 unknowns @xmath19 , @xmath37 , @xmath89 , @xmath134 and @xmath70",
    ". then , as before , the main issue here is that generally some @xmath118 , @xmath135 , @xmath136 , @xmath137 and/or @xmath70 will ( unacceptably ) be negative . thus , if we require that all @xmath118 , @xmath135 , @xmath136 , @xmath137 and @xmath70 are non - negative , then we get @xmath138 , @xmath139 , @xmath140 and @xmath141 , and since the variances @xmath129 have a skewed ( theoretically , log - normal ) distribution , this implies that @xmath37 , @xmath89 , @xmath134 and @xmath70 will have a small effect on most tickers with larger @xmath129 , including on the corresponding off - diagonal elements , _",
    "i.e. _ , the correlations involving such tickers will be small . here",
    "we discuss a simple heuristic  fix \" ( or  hack \" ) .",
    "the key observation here is that , if @xmath129 were more uniform , then requiring that all @xmath118 , @xmath135 , @xmath136 , @xmath137 and @xmath70 are non - negative generically would not yield small correlations .",
    "therefore , let us factor out the non - uniformity in @xmath129 by considering the correlation matrix @xmath142 instead of @xmath13 : @xmath143 where @xmath144 .",
    "so , _ ad hoc _ , instead of @xmath13 , we now model @xmath142 via a russian - doll factor model , _",
    "i.e. _ , we identify @xmath127 with @xmath145 , so we have @xmath146 and @xmath147 and we are left with only @xmath148 unknowns @xmath37 , @xmath89 , @xmath134 and @xmath70 .    to make progress ,",
    "let us observe that there is no unique solution or magic prescription here . with this in mind ,",
    "let us consider the following simple ansatz : @xmath149 _ i.e. _ , the  market \" , sectors , industries and sub - industries are assumed to contribute into the total variance with equal weights , same as the stock - specific ( idiosyncratic ) risk .",
    "again , this is a simplified assumption , but it will suffice for _ illustrative _ purposes .",
    "next , we wish to see if the above simplified russian - doll model adds value . one way to test this is to run a horse race given a trading universe and the corresponding expected returns ( see below ) . on the one hand , to obtain desired holdings , we can use the russian - doll model in optimization via sharpe ratio maximization subject to the dollar neutrality constraint . on the other hand",
    ", we can run the same optimization with a diagonal sample covariance matrix @xmath150 subject to the dollar neutrality constraint , or even sector , industry and sub - industry neutrality constraints .",
    "in fact , optimization with a diagonal covariance matrix and subject to linear homogeneous constraints is equivalent to weighted cross - sectional regression with the columns of the loadings matrix ( over which the returns are regressed ) identified with the vectors of constraint coefficients and the regression weights identified with inverse variances @xmath151  see ( kakushadze , 2015 ) for details .",
    "for this reason , for terminological convenience , we will refer to the horse race as between optimization ( using the russian - doll model ) and weighted regression ( using various constraints ) .",
    "let us set up our notations .",
    "@xmath152 , @xmath55 is the stock price for the stock labeled by @xmath153 .",
    "in fact , the price for each stock is a time - series : @xmath154 , @xmath155 , where the index @xmath110 labels trading dates , with @xmath156 corresponding to the most recent date in the time series",
    ". we will use superscripts @xmath157 and @xmath158 ( unadjusted open and close prices ) and @xmath159 and @xmath160 ( open and close prices fully adjusted for splits and dividends ) , so , _ e.g. _ , @xmath161 is the unadjusted close price .",
    "@xmath162 is the unadjusted daily volume ( in shares ) .",
    "also , we define the overnight return as the close - to - next - open return : @xmath163 note that both prices in this definition are fully adjusted .",
    "the portfolio is established at the open is used in the alpha , and as the establishing fill price . ]",
    "assuming fills at the open prices @xmath164 , and liquidated at the close on the same day assuming fills at the close prices @xmath161 , with no transaction costs or slippage  our goal here is not to build a trading strategy , but to check if our russian - doll factor model adds value .",
    "the p&l for each stock is @xmath165\\ ] ] where @xmath166 are the desired _ dollar",
    "_ holdings .",
    "the shares bought plus sold ( _ i.e. _ , for the establishing and liquidating trades combined ) for each stock on each day are computed via @xmath167 .",
    "before we can run our simulations , we need to select our universe .",
    "we wish to keep our discussion here as simple as possible , so we select our universe based on the average daily dollar volume ( addv ) defined via @xmath168 we take @xmath169 ( _ i.e. _ , one month ) , and then take our universe to be top 2000 tickers by addv . however , to ensure that we do not inadvertently introduce a universe selection bias , we do not rebalance the universe daily .",
    "instead , we rebalance monthly , every 21 trading days , to be precise . _",
    "i.e. _ , we break our 5-year backtest period ( see below ) into 21-day intervals , we compute the universe using addv ( which , in turn , is computed based on the 21-day period immediately preceding such interval ) , and use this universe during the entire such interval . the bias that we do have , however , is the survivorship bias .",
    "we take the data for the universe of tickers as of 9/6/2014 that have historical pricing data on http://finance.yahoo.com ( accessed on 9/6/2014 ) for the period 8/1/2008 through 9/5/2014 .",
    "we restrict this universe to include only u.s . listed common stocks and class shares ( no otcs , preferred shares , _ etc . _ ) with bics sector , industry and sub - industry assignments as of 9/6/2014 .",
    "however , it does not appear that the survivorship bias is a leading effect here  see section 7 of ( kakushadze , 2015 ) for details . also , addv - based universe selection is by no means optimal and is chosen here for the sake of simplicity . in practical applications , the trading universe of liquid stocks",
    "is carefully selected based on market cap , liquidity ( addv ) , price and other ( proprietary ) criteria .",
    "we run our simulation over a period of 5 years .",
    "more precisely , @xmath170 , and @xmath156 is 9/5/2014 ( see above ) .",
    "the annualized return - on - capital ( roc ) is computed as average daily p&l divided by the ( intraday  see below ) investment level @xmath171 ( with no leverage ) and multiplied by 252 . the annualized sharpe ratio ( sr )",
    "is computed as daily sharpe ratio multiplied by @xmath172 .",
    "cents - per - share ( cps ) is computed as the total p&l divided by total shares traded .",
    "the constrains on the desired dollar holdings @xmath166 in our portfolio are of the form : @xmath173 note that sector , industry and sub - industry neutrality automatically implies dollar neutrality as @xmath174 , @xmath175 and @xmath176 , _",
    "i.e. _ , the intercept ( that is , the unit @xmath5-vector ) is subsumed in the loadings matrices @xmath177 , @xmath178 and @xmath20 via linear combinations of their columns .",
    "next , for each date labeled by @xmath110 , we run cross - sectional regressions of the returns @xmath111 over the corresponding loadings matrix , call it @xmath179 ( with indices suppressed ) , which has 4 different incarnations : i ) for dollar neutrality @xmath179 is an @xmath180 unit matrix ( that is , the intercept ) ; ii ) for sector neutrality @xmath179 is the @xmath181 matrix @xmath177 ; iii ) for industry neutrality @xmath179 is the @xmath182 matrix @xmath178 ; and iv ) for sub - industry neutrality @xmath179 is the @xmath21 matrix @xmath20 .",
    "note that in the case i ) , the regression is simply over the intercept , while in the cases ii)-iv ) the intercept is automatically included .",
    "the regression weights are given by @xmath183 .",
    "more precisely , for each date @xmath110 the sample variances @xmath184 are computed out - of - sample as follows : @xmath185 _ i.e. _ , for each date @xmath110 we take the overnight returns for the preceding @xmath186 trading days and compute the variances @xmath184 based on the corresponding @xmath186-day time series .",
    "we take @xmath169 ( _ i.e. _ , one month ) .",
    "however , to avoid unnecessary variations in the weights @xmath187 ( as such variations could result in unnecessary overtrading ) , just as with the trading universe , we do not recompute @xmath187 daily but monthly , every 21 trading days , to be precise .",
    "i.e. _ , we break our 5-year backtest period into 21-day intervals , we compute the variances @xmath129 based on the 21-day period immediately preceding such interval , and use these variances to compute the weights via @xmath188 during the entire such interval .    in each of the above 4 cases i)-iv ) , we compute the residuals @xmath189 of the weighted regression and then the desired holdings @xmath166 via ( we use matrix notation and suppress indices ) :    @xmath190    where @xmath191 is the inverse of the matrix @xmath192 ( in the case i ) it is a @xmath10 matrix ) , and we have : @xmath193 where @xmath171 is the total _ intraday _ dollar investment level ( long plus short ) , which is the same for all dates @xmath110 . eq .",
    "( [ d.n ] ) implies that the portfolio is dollar neutral .",
    "this is because the  regressed returns \" @xmath194 have 0 cross - sectional means , which in turn is due to the intercept either being included ( the case i ) ) , or being subsumed in the loadings matrix @xmath179 ( the cases ii)-iv ) ) .    the results are given in table 1 and p&ls for the 4 cases i)-iv ) are plotted in figure 1 . in table 2 , for comparison purposes , we also give the results in the same 4 cases when the regression weights are set to 1 .",
    "we denote the corresponding regression residuals via @xmath195 , which we will also use below . using inverse variances as regression weights clearly adds value , which is not surprising considering that this amounts to suppressing contributions of the higher volatility stocks into the portfolio by their sample variances  as mentioned above , the weighted regression is the same as optimization via sharpe ratio maximization with a diagonal sample covariance matrix subject to the corresponding linear homogeneous constrains .",
    "next , we turn to the optimized alpha . in maximizing the sharpe ratio",
    ", we use the approximate covariance matrix given by @xmath196\\end{aligned}\\ ] ] where the sample variances @xmath129 are computed the same way as for the weighted regression alphas ( based on 21-day intervals ) , and as above , for the sake of simplicity , we will set @xmath197 .    for each date",
    "( we omit the index @xmath110 ) we are maximizing the sharpe ratio subject to the dollar neutrality constraint : @xmath198 where @xmath199 are the expected returns ( @xmath200 are the _ unit - weight _ regression residuals of overnight returns over @xmath20 ( sub - industries )  see above ) .",
    "the solution is given by @xmath201\\ ] ] where @xmath202 is the inverse of @xmath108 , and the overall normalization constant @xmath203 is fixed via the requirement that @xmath204 note that ( [ h.opt ] ) satisfies the dollar neutrality constraint ( [ d.n.opt ] ) .",
    "the simulation results are given in table 1 in the bottom row .",
    "the p&l plot for this optimized alpha is included in figure 1 .",
    "it is evident that the ( crude and _ ad hoc _ ) russian - doll model we use here adds value  even though we did not compute the factor covariance matrix or specific risk and simply made some heuristic approximations .",
    "the optimized model in the bottom row of table 1 has slightly better roc , sr and cps than the sub - industry - based regression model  for all practical purposes their performances are at par .",
    "however , the difference is that the russian - doll model  albeit this particular version is crude and this is a layman s way of constructing it  is a full risk model that predicts off - diagonal correlations , while what is used in the regression consists of only the loadings matrix and regression weights , and does not predict off - diagonal correlations .",
    "one can do substantially better than the crude russian - doll model we used here for illustrative purposes by utilizing the proprietary algorithms for computing the factor covariance matrix and specific risk , albeit there is cost associated with such algorithms .",
    "however , for evident reasons , such algorithms are outside of the scope of this note .",
    "it is also important to note that in the above illustrative example we purposefully did not include any style factors  had we included style factors , we would have to compute the factor covariance matrix for the style factors plus at least the  market \" factor in the above construction , which would require utilizing a proprietary algorithm .",
    "in this regard , the above example is clearly watered down and is used here for illustrative purposes only . in the next section we further elaborate on this .",
    "to summarize , the basic idea and motivation behind russian - doll risk model construction is that , in some cases it might be undesirable and/or impracticable to compute the factor covariance matrix based on ( or , more generally , using ) historical time series data . in such cases",
    ", one can use the russian - doll construction to model the factor covariance matrix itself as a factor model thereby reducing the number of factors for which the factor covariance matrix must be computed .",
    "if need be , one can apply this ( approximation ) process successively to dramatically reduce the number of remaining risk factor for which the factor covariance matrix must be computed or eliminate them altogether . in this note",
    "we have discussed how to apply this construction in the case of ( binary ) industry classification based risk factors , and also when ( non - binary ) style factors are present . in practical applications",
    "the russian - doll model building can be a powerful tool when a factor model is required to estimate / forecast off - diagonal correlations , but a full - fledged factor model is not available or impracticable to construct .    in this regard , let us go back to the crude construction we employed in section [ sec4 ] .",
    "we can generalize this construction to an arbitrary risk model , not necessarily involving the russian - doll construction .",
    "suppose we identify our factor loadings matrix @xmath20 , which may contain industry classification based factors , style factors , principal component based factors , _ etc .",
    "_  _ a priori _ it can be arbitrary .",
    "a cruder version of the russian - doll approximation then is that the factor covariance matrix @xmath22 is diagonal : @xmath205 .",
    "however , as before , even with this approximation there is no guarantee that all @xmath206 , where @xmath19 is specific risk . as in section",
    "[ sec4 ] , instead of modeling the covariance matrix @xmath13 via a factor model , we can _ ad hoc _ approximate the correlation matrix @xmath142 via a factor model ( @xmath207 ) : @xmath208 in the binary case @xmath209 we have the conditions @xmath210 so , as above , we can apply a simple ansatz , _",
    "e.g. _ , @xmath211 .",
    "however , for non - binary @xmath20 a simple ansatz does not exist and the aforementioned proprietary algorithms are required .",
    "this is also the case when we have a combination of ( a small number of ) style factors and binary industry factors .",
    "the bulk of this work was completed during my visit at the institute for advanced study at hong kong university of science and technology .",
    "i would like to thank the ias and its director prof .",
    "henry tye for their hospitality .",
    "black , j. , jensen , m. and scholes , m. ( 1972 ) the capital asset pricing model : some empirical tests . in : jensen , m. ( ed . )",
    "_ studies in the theory of capital markets_. new york : praeger publishers , pp ."
  ],
  "abstract_text": [
    "<S> we give a simple explicit algorithm for building multi - factor risk models . </S>",
    "<S> it dramatically reduces the number of or altogether eliminates the risk factors for which the factor covariance matrix needs to be computed . </S>",
    "<S> this is achieved via a nested  russian - doll \" embedding : the factor covariance matrix itself is modeled via a factor model , whose factor covariance matrix in turn is modeled via a factor model , and so on . </S>",
    "<S> we discuss in detail how to implement this algorithm in the case of ( binary ) industry classification based risk factors ( _ e.g. _ ,  sector @xmath0 industry @xmath0 sub - industry \" ) , and also in the presence of ( non - binary ) style factors . </S>",
    "<S> our algorithm is particularly useful when long historical lookbacks are unavailable or undesirable , _ e.g. _ , in short - horizon quant trading .    </S>",
    "<S> * russian - doll risk models *    zura kakushadze@xmath1@xmath2@xmath3    _ @xmath1 quantigic@xmath4 solutions llc _    _ 1127 high ridge road # 135 , stamford , ct 06905 solutions llc , the website or any of their other affiliates . ] _    _ @xmath2 free university of tbilisi , business school & school of physics _    </S>",
    "<S> _ 240 , david agmashenebeli alley , tbilisi , 0159 , georgia _    _ @xmath3 institute for advanced study _    _ hong kong university of science and technology , hong kong _    ( december 14 , 2014 ) </S>"
  ]
}