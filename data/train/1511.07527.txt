{
  "article_text": [
    "[ [ approximate - nearest - neighbors - ann . ] ] approximate nearest neighbors ( ann ) .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a central computational problem in many areas of research , such as machine learning , coding theory , pattern recognition , data compression , and cryptanalysis  @xcite , is the _",
    "nearest neighbor problem _ : given a @xmath17-dimensional data set @xmath18 of cardinality @xmath2 , design a data structure and preprocess @xmath19 in a way that , when later given a query vector @xmath20 , we can quickly find a nearest vector to @xmath21 in @xmath19 .",
    "a common relaxation of this problem is the _ approximate nearest neighbor problem ( ann ) _ : given that the nearest neighbor in @xmath19 lies at distance at most @xmath22 from @xmath21 , design an efficient algorithm that finds an element @xmath23 at distance at most @xmath24 from @xmath21 , for a given approximation factor @xmath25 .",
    "we will consider the case where @xmath17 scales with @xmath2 ; for fixed @xmath17 it is well - known that one can answer queries in time@xmath26 with @xmath27 with only a polynomial increase in the space complexity  @xcite .    [ [ ann - on - the - sphere . ] ] ann on the sphere .",
    "+ + + + + + + + + + + + + + + + + +    depending on the notion of distance , different solutions have been proposed in the literature ( e.g.  @xcite ) . in this work",
    "we will restrict out attention to the _ angular distance _",
    ", where two vectors are considered nearby iff their common angle is small  @xcite .",
    "this equivalently corresponds to spherical ann under the @xmath28-norm , where the entire data set is assumed to lie on the euclidean unit sphere .",
    "recent work of andoni and razenshteyn  @xcite showed how to reduce ann in the entire euclidean space to ann on the sphere , which further motivates why finding optimal solutions for the spherical case is relevant .",
    "for spherical , low - density settings ( @xmath29 ) , we will further focus on the _ random _ setting described in  @xcite , where _ nearby _ corresponds to a euclidean distance of @xmath30 on the unit sphere ( i.e.  an angle @xmath31 ) and _ far away _ corresponds to a distance @xmath32 ( angle @xmath33 ) .    [ [ spherical - locality - sensitive - hashing . ] ] spherical locality - sensitive hashing .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a well - known method for solving ann in high dimensions is _ locality - sensitive hashing ( lsh ) _",
    "using locality - sensitive hash functions , with the property that nearby vectors are more likely to be mapped to the same output value than distant pairs of vectors , one builds several hash tables with buckets containing sets of vectors with the same hash value . to answer a query @xmath21 , one computes @xmath21 s hash values and checks the corresponding buckets in each of the hash tables for potential near neighbors . for spherical ann in the random setting , two recent works",
    "@xcite have shown how to solve ann with query time @xmath34 and space @xmath35 with @xmath36 where @xmath37 as @xmath38 . for large @xmath3 and @xmath2 ,",
    "this improved upon e.g.  hyperplane lsh  @xcite and euclidean lsh  @xcite . within the class of lsh algorithms ,",
    "these results are known to be essentially optimal  @xcite .",
    "[ [ spherical - locality - sensitive - filters . ] ] spherical locality - sensitive filters .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    recently becker  ducas  gama  laarhoven  @xcite introduced spherical filters , which map the data set @xmath19 to a subset @xmath39 consisting of all points lying in a certain spherical cap .",
    "filtering could be considered a relaxation of locality - sensitive hashing : for lsh a hash function is required to _ partition _ the space in regions , while for lsf this is not necessarily the case .",
    "similar filtering constructions were previously proposed in  @xcite . for dense data sets of size @xmath40 ,",
    "the approach of  @xcite led to a query exponent @xmath41 for the random setting .",
    "[ [ asymmetric - ann . ] ] asymmetric ann .",
    "+ + + + + + + + + + + + + + +    the exponents @xmath42 described so far are all for _ balanced _ or _",
    "symmetric _ ann : both the time to answer a query and the time to insert / delete vectors from the data structure are then equal to @xmath34 , and the time complexity for preprocessing the data and the total space complexity are both equal to @xmath35 . depending on the application however , it may be desirable to obtain a different tradeoff between these costs . in some cases",
    "it may be beneficial to use even more space and more time for the preprocessing , so that queries can be answered even faster .",
    "in other cases , memory constraints might rule out the use of balanced parameters , in which case one has to settle for a lower space and update complexity and it would be interesting to know the best time complexity that can be achieved for a given space complexity . finding optimal tradeoffs between the different costs of ann is therefore essential for achieving the best performance in different contexts .    [",
    "[ smooth - tradeoffs - for - asymmetric - ann . ] ] smooth tradeoffs for asymmetric ann .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    various works have analyzed tradeoffs for ann , among others using multi - probing in lsh to reduce the memory complexity at the cost of a higher query complexity  @xcite .",
    "however , most existing techniques either describe one particular tradeoff between the costs , or do not offer provable asymptotic bounds on the query and update exponent as the parameters increase .",
    "recently kapralov  @xcite showed how to obtain smooth and provable asymptotic tradeoffs for euclidean ann , but as the exponents for the balanced setting are a factor @xmath14 above the lower bound @xmath43 for large @xmath3 , it may be possible to improve upon these techniques not only for symmetric but also for asymmetric ann .      in this work",
    "we extend the symmetric ann technique of  @xcite for dense regimes to asymmetric ann on the sphere for both sparse and dense regimes , showing how to obtain smooth and significantly improved tradeoffs between the query and update complexities compared to e.g.  @xcite in both the small @xmath3 and large @xmath3 regimes . for sparse settings ,",
    "the tradeoff between the query complexity @xmath0 and the update complexity @xmath1 can essentially be summarized by the non - negative solution pairs @xmath44 to the following equation , which can be expressed either in terms of @xmath45 ( left ) or @xmath3 ( right ) by substituting @xmath46 .",
    "@xmath47 the space complexity for the preprocessed data , as well as the time for preprocessing the data , are both @xmath48 .",
    "the resulting tradeoffs for the random case for small and large @xmath3 are illustrated in table  [ tab : tradeoff ] and figure  [ fig : tradeoff ] , and can be derived from   by substituting @xmath49 ( minimize the space ) , @xmath50 ( balanced ann ) , or @xmath51 ( minimize the time ) , and computing taylor expansions around @xmath52 .",
    "[ [ small - approximation - factors . ] ] small approximation factors .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the regime of small @xmath7 , as described in table  [ tab : tradeoff ] we obtain an update complexity @xmath10 and space complexity @xmath53 with query complexity @xmath54 .",
    "this improves upon results of kapralov , where a sublinear query complexity and a quasi - linear space complexity could only be achieved for approximation factors @xmath55  @xcite . balancing the complexities",
    "leads to asymptotic exponents @xmath56 , which means that both exponents scale as @xmath57 for small @xmath25 .",
    "these exponents match the asymptotic complexities previously obtained by  @xcite and the lower bounds from  @xcite .",
    "a query complexity @xmath10 can be achieved for arbitrary @xmath3 with an update complexity @xmath58 , matching the asymptotic lower bounds of  @xcite in the exponent even matches the lower bound for single - probe schemes of  ( * ? ? ?",
    "* theorem 1.5 ) . ] and the constructions of  @xcite with a smaller leading constant in the exponent and @xmath59 respectively , compared to our @xmath60 . ] .",
    "this also improves upon  @xcite , achieving a query complexity @xmath10 only for @xmath55 .",
    "[ [ large - approximation - factors . ] ] large approximation factors .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    for large @xmath3 , both @xmath4 and @xmath5 are proportional to @xmath61 , with leading constants @xmath62 in the balanced regime , and leading constant @xmath14 if the other complexity is minimized .",
    "this improves upon results from  @xcite , whose leading constants are a factor @xmath14 higher in all cases , and matches the lower bound on the space complexity of @xmath15 of  @xcite for query complexities @xmath10 .",
    "[ [ high - density - regime . ] ] high - density regime .",
    "+ + + + + + + + + + + + + + + + + + + +    finally , for data sets of size @xmath40 , we obtain improved tradeoffs between the query and update complexities compared to results obtained using locality - sensitive hashing , even for balanced settings .",
    "we show that also for this harder problem we obtain query exponents less than @xmath63 regardless of the tradeoff , while a query exponent @xmath64 is impossible to achieve with our methods .      in section  [ sec : prelim ]",
    "we describe preliminary notation and results regarding spherical filters .",
    "section  [ sec : sparse ] describes asymptotic tradeoffs for the sparse regime of @xmath29 , and section  [ sec : dense ] then discusses the application of these techniques to the dense regime of @xmath40 .",
    "section  [ sec : discussion ] concludes with a discussion on extending our methods to slightly different problems , and open problems for future work .",
    "[ cols=\"<,<,<,<\",options=\"header \" , ]      next , to make sure that the query costs are balanced , and not much more time is spent on looking for relevant filters rather than actually doing comparisons , we again look for parameters such that these costs are balanced . in this case",
    "we want to solve the asymptotic equation @xmath65 or @xmath66 .",
    "solving for @xmath67 leads to @xmath68 leading to the parameter choice described in theorem  [ thm : maindense ] .",
    "for now we again set @xmath69 with @xmath70 to be chosen later .",
    "we now evaluate the costs for large @xmath17 and @xmath40 , in terms of the ratio @xmath70 between the two parameters @xmath71 and @xmath67 , and the nearby angle @xmath45 .",
    "this leads to @xmath72 and : @xmath73 combining these expressions , we can then derive asymptotic estimates for all of the costs of the algorithm . for the query and update exponents @xmath74 / \\log n$ ] and @xmath75 / \\log n$ ]",
    "we then obtain : @xmath76 + \\frac{d}{2 \\log n } \\log \\left[1 - \\left(1 - n^{-2/d}\\right ) \\beta^2 \\right ] , \\\\   { \\rho_{\\mathrm{u}}}&= \\frac{-d}{2 \\log n } \\log \\left[1 - \\left(1 - n^{-2/d}\\right )",
    "\\frac{1 + \\beta^2 - 2 \\beta \\cos \\theta}{\\sin^2",
    "\\theta}\\right ] - 1.\\end{aligned}\\ ] ] these are also the expressions given in theorem  [ thm : maindense ] .",
    "we observe that again the best exponents @xmath4 and @xmath5 are obtained by choosing @xmath77 $ ] ; beyond this range , the complexities are strictly worse .",
    "this completes the derivation of theorem  [ thm : maindense ] .",
    "algorithm  [ alg : interval ] describes how to perform list - decoding for intervals , which may be relevant in practice for e.g.  computing probing sequences as described in section  [ sec : discussion ] .",
    "the algorithm is based on ( * ? ? ?",
    "* algorithm 1 ) , where now two sets of bounds are maintained to make sure that we only consider solutions which lie within the given range , rather than above a threshold .",
    "the bounds @xmath78 and @xmath79 indicate the minimum and maximum sum of inner products that can still be obtained in the last @xmath80 sorted lists of vectors and inner products ; if in the nested for - loops , the current sum of inner products @xmath81 is not in the interval @xmath82 $ ] , then there are no solutions anymore in the remaining part of the tree .",
    "conversely , if this sum of inner products does lie in the interval , then there must be at least one solution .    the description @xmath83 of the code @xmath84 ; a target vector @xmath85 ; and @xmath86 .",
    "return all code words @xmath87 with @xmath88 $ ] sort each list @xmath89 by decreasing dot - products @xmath90 with @xmath91 .",
    "precompute @xmath92 bounds @xmath93 .",
    "precompute @xmath92 bounds @xmath94 .",
    "initialize an empty output set @xmath95 .",
    "compute the lower bound @xmath96 .",
    "compute the upper bound @xmath97 .",
    "compute the lower bound @xmath98 .",
    "compute the upper bound @xmath99 .",
    "compute the lower bound @xmath100 .",
    "compute the upper bound @xmath101 . add the code word @xmath102 to @xmath103 ."
  ],
  "abstract_text": [
    "<S> we consider tradeoffs between the query and update complexities for the ( approximate ) nearest neighbor problem on the sphere , extending the spherical filters recently introduced by [ becker  ducas  gama  laarhoven , soda16 ] to sparse regimes and generalizing the scheme and analysis to account for different tradeoffs . in a nutshell , for the sparse regime the tradeoff between the query complexity @xmath0 and </S>",
    "<S> update complexity @xmath1 for data sets of size @xmath2 can be summarized by the following equation in terms of the approximation factor @xmath3 and the exponents @xmath4 and @xmath5 : @xmath6    for small @xmath7 , minimizing the time for updates leads to a linear space complexity at the cost of a query time complexity of approximately @xmath8 . </S>",
    "<S> balancing the query and update costs leads to optimal complexities of @xmath9 , matching lower bounds from [ andoni  razenshteyn , 2015 ] and [ dubiner , ieee trans .  </S>",
    "<S> inf .  theory 2010 ] and matching the asymptotic complexities previously obtained by [ andoni  razenshteyn , stoc15 ] and [ andoni  indyk  laarhoven  razenshteyn  schmidt , nips15 ] . </S>",
    "<S> a subpolynomial query time complexity @xmath10 can be achieved at the cost of a space complexity of the order @xmath11 , matching the lower bound @xmath12 of [ andoni  indyk  ptracu , focs06 ] and [ panigrahy  talwar  wieder , focs10 ] and improving upon results of [ indyk  motwani , stoc98 ] and [ kushilevitz  ostrovsky  rabani , stoc98 ] with a considerably smaller leading constant in the exponent .    for large @xmath3 , minimizing the update complexity results in a query complexity of @xmath13 , improving upon the related asymptotic exponent for large @xmath3 of [ kapralov , pods15 ] by a factor @xmath14 , and matching the lower bound @xmath15 of [ panigrahy  talwar  wieder , focs08 ] . </S>",
    "<S> balancing the costs leads to optimal complexities of the order @xmath9 , while a minimum query time complexity can be achieved with update and space complexities of approximately @xmath13 and @xmath16 , also improving upon the previous best exponents of kapralov by a factor @xmath14 for large @xmath2 and @xmath3 .    </S>",
    "<S> for the regime where @xmath2 is exponential in the dimension , we obtain further improvements compared to results obtained with locality - sensitive hashing . </S>",
    "<S> we provide explicit expressions for the query and update complexities in terms of the approximation factor @xmath3 and the chosen tradeoff , and we derive asymptotic results for the case of the highest possible density for random data sets . </S>"
  ]
}