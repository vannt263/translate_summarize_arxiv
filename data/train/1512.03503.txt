{
  "article_text": [
    "in this paper , we study fast algorithms for generalizations of classical _ pad approximation _ and _ polynomial interpolation _ problems .",
    "two typical examples of such problems are the following .    in coding theory ,",
    "some decoding algorithms rely on solving a bivariate interpolation problem which may be formulated as follows . given a set of @xmath1 points @xmath7 with",
    "coordinates in a field @xmath8 , find a non - zero polynomial @xmath9 $ ] of @xmath10-degree less than @xmath0 satisfying @xmath11 as well as a weighted degree constraint . in terms of linear algebra , we interpret this using the @xmath8-linear functionals @xmath12 defined by @xmath13 for polynomials @xmath14 in @xmath15 $ ] . then , given the points , the problem is to find a polynomial @xmath14 satisfying the degree constraints and such that @xmath16 for each @xmath17 .",
    "writing @xmath18 , in this context , one may actually want to compute a whole basis @xmath19 of such interpolants @xmath20 , and the weighted degree constraint is satisfied through the minimization of some suitably defined degree of @xmath19",
    ".    given a vector of @xmath0 polynomials @xmath21}^{m}$ ] , with coefficients in a field @xmath8 , and given a target order @xmath1 , find another vector of polynomials @xmath22 such that @xmath23 with some prescribed degree constraints on @xmath24 .    here",
    "as well , one may actually wish to compute a set of such vectors @xmath25 , forming the rows of a matrix @xmath19 over @xmath26}$ ] , which describe a whole basis of solutions .",
    "then , these vectors may not all satisfy the degree constraints , but by requiring that the basis matrix @xmath19 minimizes some suitably defined degree , we will ensure that at least one of its rows does ( unless the problem has no solution ) .    concerning hermite - pad approximation , a minimal basis of solutions can be computed in @xmath27 operations in @xmath8  @xcite . here and hereafter , the soft - o notation @xmath28 indicates that we omit polylogarithmic terms , and the exponent @xmath3 is so that we can multiply @xmath29 matrices in @xmath30 ring operations on any ring , the best known bound being @xmath31  @xcite . for constrained bivariate interpolation , assuming that @xmath32 are pairwise distinct , the best known cost bound for computing a minimal basis is @xmath33  @xcite ; the cost bound @xmath27 was achieved in  @xcite with a probabilistic algorithm which outputs only one interpolant satisfying the degree constraints .    following the work of @xcite , @xcite , and mceliece s presentation of ktter s algorithm  ( * ? ? ?",
    "* section 7 ) , we adopt a framework that encompasses both examples above , and many other applications detailed in ; we propose a deterministic algorithm for computing a minimal basis of solutions to this general problem .",
    "consider a field @xmath8 and the vector space @xmath34 , for some positive integer @xmath1 ; we see its elements as row vectors .",
    "choosing a @xmath35 matrix @xmath36 with entries in @xmath8 allows us to make @xmath37 a @xmath26}$]-module in the usual manner , by setting @xmath38 , for @xmath39 in @xmath26}$ ] and @xmath40 in @xmath37 .",
    "we will call @xmath41 the _ multiplication matrix _ of @xmath42 .",
    "[ dfn : interp ] given a vector @xmath43 in @xmath44 and a vector @xmath22 in @xmath26}^{m}$ ] , we write @xmath45 .",
    "we say that @xmath25 is an _",
    "interpolant for @xmath46 _ if @xmath47    here , @xmath48 is seen as a row vector , and @xmath49 is seen as a column vector of @xmath0 elements of @xmath37 : as a matter of notation , @xmath49 will often equivalently be seen as an @xmath50 matrix over @xmath8 .",
    "interpolants @xmath25 are often called _ relations _ or _",
    "syzygies _ of @xmath51 .",
    "this notion of interpolants was introduced by @xcite , with the requirement that @xmath41 be upper triangular .",
    "one of the main results of this paper holds with no assumption on @xmath41 ; for our second main result , we will work under the stronger assumption that @xmath41 is a jordan matrix : it has @xmath52 jordan blocks of respective sizes @xmath53 and with respective eigenvalues @xmath54 .    in the latter context , the notion of interpolant directly relates to the one introduced by @xcite in terms of @xmath55$]-modules .",
    "indeed , one may identify @xmath37 with the product of residue class rings @xmath56}/(x^{{{\\sigma}}_1 } ) \\times \\cdots \\times { { \\mathbb{k}}[{x}]}/(x^{{{\\sigma}}_{n}}),\\ ] ] by mapping a vector @xmath57 in @xmath58 to the vector @xmath59 made from the concatenation of the coefficient vectors of @xmath60 .",
    "then , over @xmath58 , the @xmath26}$]-module structure on @xmath37 given by @xmath61 simply becomes @xmath62 now , if @xmath63 in @xmath44 is associated to @xmath64 in @xmath65 , with @xmath66 and @xmath67 in @xmath26}/(x^{{{\\sigma}}_j})$ ] for all @xmath68 , the relation @xmath69 means that for all @xmath17 in @xmath70 , we have @xmath71 applying a translation by @xmath72 , this is equivalent to @xmath73 thus , in terms of vector m - pad approximation as in  @xcite , @xmath74 is an interpolant for @xmath75 , @xmath76 , and @xmath53 .",
    "both examples above , and many more along the same lines , can be cast into this setting . in the second example above , this is straightforward : we have @xmath77 , @xmath78 , so that the multiplication matrix is the upper shift matrix @xmath79 it is a nilpotent jordan block . in the first example , we have @xmath80 , and the multiplication matrix is the diagonal matrix @xmath81 then , for @xmath39 in @xmath26}$ ] and @xmath82 $ ] in @xmath37 , @xmath83 is the row vector @xmath84 $ ] . in this case , to solve the interpolation problem , we start from the tuple of bivariate polynomials @xmath85 ; their evaluations @xmath86 in @xmath44 are the vectors @xmath87 $ ] and the relation @xmath88 precisely means that @xmath89 vanishes at all points @xmath90 , where @xmath22 .",
    "let us come back to our general context .",
    "the set of all interpolants for @xmath46 is a submodule of @xmath26}^{m}$ ] , which we will denote by @xmath91 . since it contains @xmath92}^{m}$ ] , where @xmath93}$ ] is the minimal polynomial of @xmath41 , this submodule is free of rank @xmath0 ( see for example  ( * ? ? ?",
    "* chapter 12 , theorem 4 ) ) .",
    "[ dfn : ib ] given @xmath49 in @xmath44 and @xmath41 in @xmath94 , a matrix @xmath95 in @xmath96}^{{}\\times { } } } } [ { m}]}$ ] is an _ interpolation basis for @xmath46 _ if its rows form a basis of @xmath91 .    in terms of notation , if a matrix @xmath97}^{{}\\times { } } } } [ { m}]$ ] has rows @xmath98 , we write @xmath99 for @xmath100 , seen as a column vector",
    "thus , for @xmath101 , if @xmath95 is an interpolation basis for @xmath46 then in particular @xmath102 .    in many situations , one wants to compute an interpolation basis which has sufficiently small degrees : as we will see in , most previous algorithms compute a basis which is _ reduced _ with respect to some degree _ shift_. in what follows , by shift , we mean a tuple of nonnegative integers which will be used as degree weights on the columns of a polynomial matrix .",
    "before giving a precise definition of shifted minimal interpolation bases , we recall the notions of shifted row degree and shifted reducedness for univariate polynomial matrices ; for more details we refer to  @xcite and ( * ? ? ?",
    "* chapter 2 ) .",
    "the row degree of a matrix @xmath103_{i , j}$ ] in @xmath104}^{{}\\times { } } } } [ { m}]$ ] with no zero row is the tuple @xmath105 with @xmath106 for all  @xmath107 . for a shift @xmath108 , the diagonal matrix with diagonal entries @xmath109",
    "is denoted by @xmath110 , and the @xmath5-row degree of @xmath19 is @xmath111 .",
    "then , the @xmath5-leading matrix of @xmath19 is the matrix in @xmath112 $ ] whose entries are the coefficients of degree zero of @xmath113 , and we say that @xmath19 is @xmath5-reduced when its @xmath5-leading matrix has full rank .",
    "in particular , if @xmath19 is square ( still with no zero row ) , it is @xmath5-reduced if and only if its @xmath5-leading matrix is invertible .",
    "we note that @xmath19 is @xmath5-reduced if and only if @xmath114 is @xmath115-reduced , where @xmath116 is called the _ uniform _ shift .",
    "[ dfn : mib ] consider @xmath34 and a multiplication matrix @xmath41 in @xmath94 .",
    "given @xmath43 in @xmath44 and a shift @xmath117 , a matrix @xmath118}^{{}\\times { } } } } [ { m}]}$ ] is said to be an _",
    "@xmath5-minimal interpolation basis for",
    "@xmath46 _ if    * @xmath95 is an interpolation basis for @xmath46 , and * @xmath95 is @xmath5-reduced .",
    "we recall that all bases of a free @xmath26}$]-module of rank @xmath0 are unimodularly equivalent : given two bases @xmath119 and @xmath120 , there exists @xmath121}^{{}\\times { } } } } [ { m}]}$ ] such that @xmath122 and @xmath123 is unimodular ( that is , @xmath123 is invertible in @xmath96}^{{}\\times { } } } } [ { m}]}$ ] ) . among all the interpolation bases for @xmath46 , an @xmath5-minimal basis @xmath95 has a type of minimal degree property .",
    "indeed , @xmath19 is @xmath5-reduced if and only if @xmath124 for any unimodular @xmath123 ; in this inequality , the tuples are first sorted in non - decreasing order and then compared lexicographically .",
    "in particular , a row of @xmath95 which has minimal @xmath5-row degree among the rows of @xmath95 also has minimal @xmath5-row degree among _ all _ interpolants for @xmath46 .      in this article , we propose fast deterministic algorithms that solve .    our first main result deals with an arbitrary matrix @xmath41 , and uses techniques from fast linear algebra .",
    "taking @xmath41 _ upper triangular _ as in  @xcite would allow us to design a divide - and - conquer algorithm , using the leading and trailing principal submatrices of @xmath41 for the recursive calls .",
    "however , this assumption alone is not enough to obtain an algorithm with cost quasi - linear in @xmath1 , as simply representing @xmath41 would require a number of coefficients in @xmath8 quadratic in @xmath1 .",
    "taking @xmath41 a jordan matrix solves this issue , and is not a strong restriction for applications : it is satisfied in all those we have in mind , which are detailed in .",
    "if @xmath125 is a jordan matrix with @xmath52 diagonal blocks of respective sizes @xmath126 and with respective eigenvalues @xmath127 , we will write it in a compact manner by specifying only those sizes and eigenvalues .",
    "precisely , we will assume that @xmath41 is given to us as the form @xmath128 for some pairwise distinct @xmath129 , with @xmath130 and @xmath131 for all @xmath107 ; we will say that this representation is _",
    "standard_. if @xmath41 is given as an arbitrary list @xmath132 , we can reorder it ( and from that , permute the columns of @xmath49 accordingly ) to bring it to the above form in time @xmath133 using the algorithm of ( * ? ? ? * proposition  12 ) ; if @xmath8 is equipped with an order , and if we assume that comparisons take unit time , it is of course enough to sort the @xmath134 s . here",
    ", @xmath135 is a multiplication time function for @xmath26}$ ] : polynomials of degree at most @xmath136 in @xmath26}$ ] can be multiplied using @xmath137 operations in @xmath8 , and @xmath135 satisfies the super - linearity properties of  ( * ? ? ?",
    "* chapter 8) .",
    "it follows from the algorithm of @xcite that @xmath137 can be taken in @xmath138 .    adding a constant to every entry of @xmath5",
    "does not change the notion of @xmath5-reducedness , and thus does not change the output matrix @xmath95 of ; in particular , one may ensure that @xmath6 without loss of generality .",
    "the shift @xmath5 , as a set of degree weights on the columns of @xmath95 , naturally affects how the degrees of the entries of @xmath95 are distributed .",
    "although no precise degree profile of @xmath95 can be stated in general , we do have a global control over the degrees in @xmath95 , as showed in the following results ; in these statements , for a shift @xmath5 , we write @xmath4 to denote the quantity @xmath139 .",
    "we start with the most general result in this paper , where we make no assumption on  @xmath41 . in this case",
    ", we obtain an algorithm whose cost is essentially that of fast linear algebra over @xmath8 .",
    "the output of this algorithm has an extra uniqueness property : it is in _ popov form _ ; we refer the reader to or  @xcite for a definition .",
    "[ thm : mib - linear ] there is a deterministic algorithm which solves using @xmath140 operations in @xmath8 and returns the unique @xmath5-minimal interpolation basis for @xmath46 which is in @xmath5-popov form .",
    "besides , the sum of the column degrees of this basis is at most @xmath1 .    in the usual case",
    "where @xmath141 , the cost is thus @xmath142 ; this is to be compared with the algorithm of  @xcite , which we discuss in .",
    "next , we deal with the case of @xmath41 in jordan canonical form , for which we obtain a cost bound that is quasi - linear with respect to @xmath1 .",
    "[ thm : mib ] assuming that @xmath143 is a jordan matrix , given by a standard representation , there is a deterministic algorithm which solves using @xmath144 operations in @xmath8 , where @xmath145 . besides , the sum of the row degrees of the computed @xmath5-minimal interpolation basis is at most @xmath146 .",
    "the reader interested in the logarithmic factors should refer to the more precise cost bound in .",
    "masking logarithmic factors , this cost bound is @xmath147 .",
    "we remark that the bound on the output row degree implies that the size of the output matrix @xmath19 is @xmath148 , where by size we mean the number of coefficients of @xmath8 needed to represent this matrix .",
    "we are not aware of a previous cost bound for the general question stated in that would be similar to our result ; we give a detailed comparison with several previous algorithms and discuss useful particular cases in .",
    "to deal with an arbitrary matrix @xmath41 , we rely on a linear algebra approach presented in , using a linearization framework that is classical for this kind of problems  @xcite .",
    "our algorithm computes the rank profile of a block krylov matrix using techniques that are reminiscent of the algorithm of @xcite ; this framework also allows us to derive a bound on the sum of the row degrees of shifted minimal interpolation bases .",
    "is the last section of this paper ; it is the only section where we make no assumption on @xmath41 , and it does not use results from other parts of the paper .",
    "we give in a divide - and - conquer algorithm for the case of a matrix @xmath41 in jordan canonical form .",
    "the idea is to use a knuth - schnhage - like half - gcd approach  @xcite , previously carried over to the specific case of simultaneous hermite - pad approximation in  @xcite .",
    "this approach consists in reducing a problem in size @xmath1 to a first sub - problem in size @xmath149 , the computation of the so - called _ residual _ , a second sub - problem in size @xmath149 , and finally a recombination of the results of both sub - problems via polynomial matrix multiplication .",
    "the shift to be used in the second recursive call is essentially the @xmath5-row degree of the outcome of the first recursive call .",
    "the main difficulty is to control the sizes of the interpolation bases that are obtained recursively .",
    "the bound we rely on , as stated in our main theorems , depends on the input shift . in our algorithm",
    ", we can not make any assumption on the shifts that will appear in recursive calls , since they depend on the degrees of the previously computed bases .",
    "hence , even in the case of a uniform input shift for which the output basis is of size @xmath150 , there may be recursive calls with an unbalanced shift , which may output bases that have large size .",
    "our workaround is to perform all recursive calls with the uniform shift @xmath151 , and resort to a change of shift that will be studied in ; this strategy is an alternative to the linearization approach that was used by  @xcite in the specific case of simultaneous hermite - pad approximation .",
    "we note that our change of shift uses an algorithm in  @xcite , which itself relies on simultaneous hermite - pad approximation ; with the dimensions needed here , this approximation problem is solved efficiently using the algorithm of  @xcite , without resorting to  @xcite .",
    "another difficulty is to deal with instances where @xmath1 is small .",
    "our bound on the size of the output states that when @xmath152 and the shift is uniform , the average degree of the entries of a minimal interpolation basis is at most @xmath153 .",
    "thus , in this case our focus is not anymore on using fast polynomial arithmetic but rather on exploiting efficient linear algebra over @xmath8 : the divide - and - conquer process stops when reaching @xmath152 , and invokes instead the algorithm based on linear algebra proposed in .",
    "the last ingredient is the fast computation of the residual , that is , a matrix in @xmath154 $ ] for restarting the process after having found a basis @xmath155 for the first sub - problem of size @xmath149 .",
    "this boils down to computing @xmath156 and discarding the first @xmath149 columns , which are known to be zero . in",
    ", we design a general procedure for computing this kind of product , using hermite interpolation and evaluation to reduce it to multiplying polynomial matrices .",
    "concerning the multiplication of the bases obtained recursively , to handle the fact that they may have unbalanced row degrees , we use the approach in  ( * ? ? ?",
    "* section 3.6 ) ; we give a detailed algorithm and cost analysis in .",
    "in this section , we review and expand the scope of the examples described in the introduction , and we compare our results for these examples to previous work . _ for ease of comparison ,",
    "in all this section we consider the case @xmath157 . _      in this paragraph , we consider the general , without assuming that @xmath41 is a jordan matrix . the only previous work that we are aware of is  @xcite , where it is still assumed that @xmath41 is upper triangular .",
    "this assumption allows one to use an iteration on the columns of @xmath49 , combining gaussian elimination with multiplication by monic polynomials of degree @xmath153 to build the basis @xmath95 : after @xmath107 iterations , @xmath95 is an @xmath5-minimal interpolation basis for the first @xmath107 columns of @xmath49 and the @xmath158 leading principal submatrix of @xmath41 .",
    "this algorithm uses @xmath159 operations and returns a basis in @xmath5-popov form .",
    "we note that in this context the mere representation of @xmath41 uses @xmath160 elements .    as a comparison , the algorithm of computes an interpolation basis for @xmath46 in @xmath5-popov form for _ any _ matrix @xmath41 in @xmath94 . for any shift @xmath5",
    ", this algorithm uses @xmath161 operations when @xmath162 and @xmath163 operations when @xmath164 .",
    "we continue with the case of a matrix @xmath41 in jordan canonical form .",
    "as pointed out in the introduction , can be formulated in this case in terms of polynomial equations and corresponds to an m - pad approximation problem ; this problem was studied in @xcite and named after the work of mahler , including in particular @xcite .",
    "indeed , up to applying a translation in the input polynomials , the problem stated in   can be rephrased as follows .    here , @xmath165 .",
    "previous work on this particular problem includes  @xcite ; note that in  @xcite , the input consists of a single column @xmath166 in @xmath167}^{{}\\times { } } } } [ 1]$ ] of degree less than @xmath1 : to form the input of our problem , we compute @xmath168 operations , which can be lowered to @xmath169 if one computes only the small degree rows of an @xmath5-minimal basis ( gradually discarding the rows of degree more than , say , @xmath170 during the computation ) . to the best of our knowledge ,",
    "no algorithm with a cost quasi - linear in @xmath1 has been given in the literature .",
    "specializing the discussion of the previous paragraph to the case where all @xmath171 are zero , we obtain the following important particular case .    here , @xmath172 . our main result says that there is an algorithm which solves using @xmath173 operations in @xmath8 , where @xmath145 .",
    "as we will see , slightly faster algorithms for this problem exist in the literature , but they do not cover the same range of cases as we do ; to the best of our knowledge , for instance , most previous work on this problem dealt with the case @xmath174 and @xmath175 .",
    "first algorithms with a cost quadratic in @xmath1 were given in  @xcite in the case of hermite - pad approximation ( @xmath77 ) , assuming a type of genericity of @xmath166 and outputting a single approximant @xmath176}^{{}\\times { } } } } [ { m}]$ ] which satisfies some prescribed degree constraints .",
    "for @xmath77 , @xcite propose an algorithm which uses @xmath177 operations to compute a @xmath5-minimal basis of approximants for @xmath166 at order @xmath1 , for any @xmath166 and @xmath5 .",
    "this result was extended by @xcite to the case of any @xmath175 , with the additional remark that the cost bound is @xmath169 if one restricts to computing only the rows of small degree of an @xmath5-minimal basis .    in  @xcite , the authors also propose a divide - and - conquer algorithm using @xmath33 operations in @xmath8 ; the base case of the recursion deals with the constant coefficient of a single column of the input @xmath166 .",
    "then , @xcite follow a similar divide - and - conquer approach , introducing a base case which has matrix dimension @xmath178 and is solved efficiently by means of linear algebra over @xmath8 ; this yields an algorithm with the cost bound @xmath179 , which is particularly efficient when @xmath180 . on the other hand , in the case of hermite - pad approximation ( @xmath77 ) it was noticed by @xcite that the cost bound @xmath33 is pessimistic , at least when some type of genericity is assumed concerning the input @xmath166 , and that in this case there is hope to achieve @xmath181 .",
    "this cost bound was then obtained by  @xcite , for computing only the small degree rows of an @xmath5-minimal basis , via a reduction of the case of small @xmath52 and order @xmath1 to a case with larger column dimension @xmath182 and smaller order @xmath183 .",
    "this was exploited to compute a full @xmath5-minimal basis using @xmath184 operations  @xcite , under the assumption that either @xmath185 or @xmath186 ( which both imply that an @xmath5-minimal basis has size @xmath150 ) . we note that this algorithm is faster than ours by a logarithmic factor , and that our result does not cover the second assumption on the shift with a similar cost bound ; on the other hand , we handle situations that are not covered by that result , when for instance all @xmath187 s are not equal .",
    "* section 3.6 ) gives a fast algorithm for the case @xmath188 , for the uniform shift and @xmath189 .",
    "for an input of dimensions @xmath190 , the announced cost bound is @xmath27 ; a more precise analysis shows that the cost is @xmath191 . for this particular case",
    ", there is no point in using our divide - and - conquer algorithm , since the recursion stops at @xmath152 ; our general algorithm in handles these situations , and its cost ( as given in with @xmath192 ) is the same as that of zhou s algorithm in this particular case .",
    "in addition , this cost bound is valid for any shift @xmath5 and the algorithm returns a basis in @xmath5-popov form .      in this subsection",
    ", we discuss how our algorithm can be used to solve bivariate interpolation problems , such as those appearing in the list - decoding  @xcite and the soft - decoding  ( * ? ? ?",
    "* sec.iii ) of reed - solomon codes ; as well as multivariate interpolation problems , such as those appearing in the list - decoding of folded reed - solomon codes  @xcite and in robust private information retrieval  @xcite .",
    "our contribution leads to the best known cost bound we are aware of for the interpolation steps of the list - decoding and soft - decoding of reed - solomon codes : this is detailed in .    in those problems",
    ", we have @xmath193 new variables @xmath194 and we want to find a multivariate polynomial @xmath195 which vanishes at some given points @xmath196 with prescribed _ supports _ @xmath197 . in this context ,",
    "given a point @xmath198 and an exponent set @xmath199 , we say that _",
    "@xmath14 vanishes at @xmath200 with support @xmath201 _ if the shifted polynomial @xmath202 has no monomial with exponent in @xmath201 . besides , the solution @xmath195 should also have sufficiently small _ weighted degree _ @xmath203 for some given weight @xmath204 .    to make this fit in our framework",
    ", we first require that we are given an exponent set @xmath205 such that any monomial @xmath206 appearing in a solution @xmath195 should satisfy @xmath207 .",
    "then , we can identify @xmath208 with @xmath209_{j\\in{\\gamma } } \\in { \\renewcommand{}{1}{{{\\mathbb{k}}[{x}]}^{{}\\times { } } } } [ { m}]$ ] , where @xmath0 is the cardinality of @xmath210",
    ". we will show below how to construct matrices @xmath49 and @xmath41 such that solutions @xmath195 to those multivariate interpolation problems correspond to interpolants @xmath211_{j\\in{\\gamma}}$ ] for @xmath46 that have sufficiently small shifted degree .",
    "we also require that each considered support @xmath201 satisfies @xmath212 then , the set @xmath213}^{{}\\times { } } } } [ { m } ] \\;\\big| \\\\    & \\sum_{j\\in{\\gamma } } p_j(x ) y^j \\text { vanishes at } ( { x}_k , y_k ) \\text {      with support } { \\mu}_k \\text { for } 1 { \\leqslant}k { \\leqslant}{p}\\bigg\\}\\end{aligned}\\ ] ] is a @xmath26}$]-module , as can be seen from the equality @xmath214    finally , as before , we assume that we are given a shift @xmath5 such that we are looking for polynomials of small @xmath5-row degree in @xmath215 . in this context , the shift is often derived from a weighted degree condition which states that , given some input weights @xmath216 , the degree @xmath217 should be sufficiently small . since @xmath218 , this @xmath219-weighted degree of @xmath14 is exactly the @xmath5-row degree of @xmath25 for the shift @xmath220 .",
    "an @xmath5-reduced basis of @xmath215 contains a row of minimal @xmath5-row degree among all @xmath221 ; we note that in some applications , for example in robust private information retrieval  @xcite , it is important to return a whole basis of solutions and not only a small degree one .",
    "this problem can be embedded in our framework as follows .",
    "we consider @xmath222 $ ] and the @xmath8-linear functionals @xmath223 , where @xmath224 is the coefficient of @xmath225 in @xmath226 .",
    "these functionals are linearly independent , and the intersection @xmath227 of their kernels is the @xmath26}$]-module of polynomials in @xmath228 vanishing at @xmath229 with support @xmath230 for all @xmath231 . the quotient @xmath232 is a @xmath8-vector space of dimension @xmath233 where @xmath234 ; it is thus isomorphic to @xmath34 , with a basis of the dual space given by the functionals @xmath235 .",
    "our assumption on the supports @xmath230 implies that @xmath232 is a @xmath55$]-module ; we now describe the corresponding multiplication matrix @xmath41 . for a given @xmath231 ,",
    "let us order the functionals @xmath235 in such a way that , for any @xmath236 such that @xmath237 is in @xmath230 , the successor of @xmath235 is @xmath238 .",
    "equation   implies that @xmath239 holds for all @xmath14 , all @xmath240 , and all @xmath241 with @xmath242 .",
    "hence , @xmath41 is block diagonal with diagonal blocks @xmath243 , where @xmath244 is a @xmath245 jordan matrix with only eigenvalue @xmath246 and block sizes given by the support @xmath230 .",
    "more precisely , denoting @xmath247 and @xmath248 for each @xmath249 , we have the disjoint union @xmath250 then , @xmath244 is block diagonal with @xmath251 blocks : to each @xmath252 corresponds a @xmath253 jordan block with eigenvalue @xmath246 .",
    "it is reasonable to consider @xmath254 ordered as we would like for a standard representation of @xmath41 .",
    "for example , in problems coming from coding theory , these points are part of the code itself , so the reordering can be done as a pre - computation as soon as the code is fixed .",
    "to complete the reduction to , it remains to construct @xmath49 .",
    "for each exponent @xmath255 we consider the monomial @xmath256 and take its image in @xmath232 : this is the vector @xmath257 having for entries the evaluations of the functionals @xmath235 at @xmath256 .",
    "let then @xmath49 be the matrix in @xmath258 $ ] with rows @xmath259 : our construction shows that a row @xmath260}^{{}\\times { } } } } [ { m}]$ ] is in @xmath215 if and only if it is an interpolant for @xmath46 .    to make this reduction to efficient",
    ", we make the assumption that the exponent sets @xmath210 and @xmath230 are _ stable under division _ : this means that if @xmath207 then all @xmath261 such that @xmath262 ( for the product order on @xmath263 ) belong to @xmath210 ; and if @xmath236 is in @xmath201 , then all @xmath264 such that @xmath265 ( for the product order on @xmath266 ) belong to @xmath230 .",
    "this assumption is satisfied in the applications detailed below ; besides , using the straightforward extension of   to multiplication by @xmath267 , it allows us to compute all entries @xmath268 of the matrix @xmath49 inductively in @xmath150 , which is negligible compared to the cost of solving the resulting instance of .",
    "( as a side note , we remark that this assumption also implies that @xmath227 is a zero - dimensional ideal of @xmath228 . )",
    "[ prop : multi - int ] assuming that @xmath210 and @xmath269 are stable under division , there is an algorithm which solves using @xmath270 operations in @xmath8 , where @xmath271 and @xmath145 .      in the algorithms of @xcite , the bivariate interpolation step deals with with @xmath272 , @xmath273 , pairwise distinct points @xmath274 , and @xmath275 for all @xmath231",
    "; @xmath276 is the _ multiplicity parameter _ and @xmath277 is the _ list - size parameter_. as explained above , the shift @xmath5 takes the form @xmath278 ; here @xmath279 is the message length of the considered reed - solomon code and @xmath280 is its block length .",
    "we will see below , in the more general interpolation step of the soft - decoding , that @xmath281 . as a consequence , states that this bivariate interpolation step can be performed using @xmath282 operations . to our knowledge ,",
    "the best previously known cost bound for this problem is @xmath283 and was obtained using a randomized algorithm  ( * ? ? ?",
    "* corollary  14 ) .",
    "in contrast , in this paper makes no random choices .",
    "the algorithm in  @xcite uses fast structured linear algebra , following an approach studied in  @xcite . restricting to deterministic algorithms , the best previously known cost bound is @xmath284  @xcite , where @xmath285 is the multiplicity parameter mentioned above .",
    "this is obtained by first building a known @xmath29 interpolation basis with entries of degree at most @xmath286 , and then using fast deterministic reduction of polynomial matrices  @xcite ; other references on this approach include  @xcite .",
    "a previous divide - and - conquer algorithm can be found in  @xcite .",
    "the recursion is on the number of points @xmath280 , and using fast multiplication of the bases obtained recursively , this algorithm has cost bound @xmath287 ( * ? ?",
    "* proposition  3 ) . in this reference ,",
    "the bases computed recursively are allowed to have size as large as @xmath288 , with @xmath285 .    for a more detailed perspective of the previous work on this specific problem ,",
    "the reader may for instance refer to the cost comparisons in the introductive sections of  @xcite .      in ktter and vardy s algorithm , the so - called soft - interpolation step  ( * ? ?",
    "* section  iii ) is with @xmath289 , @xmath290 , and @xmath291 .",
    "the points @xmath254 are not necessarily pairwise distinct , and to each @xmath246 for @xmath240 is associated a multiplicity parameter @xmath292 and a corresponding support @xmath293 . then , @xmath294 is called the _ cost _ ( * ? ? ?",
    "* section  iii ) , since it corresponds to the number of linear equations that one obtains in the straightforward linearization of the problem .    in this context , one chooses for @xmath0 the smallest integer such that the number of linear unknowns in the linearized problem is more than @xmath1 .",
    "this number of unknowns being directly linked to @xmath4 , this leads to @xmath281 , which can be proven for example using ( * ? ? ?",
    "* lemma  1 and equations  ( 10 ) and  ( 11 ) ) .",
    "thus , our algorithm solves the soft - interpolation step using @xmath295 operations in @xmath8 , which is to our knowledge the best known cost bound to solve this problem .",
    "iterative algorithms , now often referred to as _",
    "ktter s algorithm _ in coding theory , were given in  @xcite ; one may also refer to the general presentation of this solution in  ( * ? ? ?",
    "* section 7 ) .",
    "these algorithms use @xmath169 operations in @xmath8 ( for the considered input shifts which satisfy @xmath281 ) .",
    "we showed above how the soft - interpolation step can be reduced to a specific instance of m - pad approximation ( ): likewise , one may remark that the algorithms in  @xcite are closely linked to those in  @xcite .",
    "in particular , up to the interpretation of row vectors in @xmath167}^{{}\\times { } } } } $ ] as bivariate polynomials of degree less than @xmath0 in @xmath10 , they use the same recurrence .",
    "our recursive is a fast divide - and - conquer version of these algorithms .",
    "an approach based on polynomial matrix reduction was developed in  @xcite and in  @xcite .",
    "it consists first in building an interpolation basis , that is , a basis @xmath296}^{{}\\times { } } } } [ { m}]}$ ] of the @xmath26}$]-module @xmath215 , and then in reducing the basis for the given shift @xmath5 to obtain an @xmath5-minimal interpolation basis .",
    "the maximal degree in @xmath120 is @xmath297 one can check using @xmath298 for all @xmath231 that @xmath299 using the fast deterministic reduction algorithm in  @xcite , this approach has cost bound @xmath300 ; the cost bound of our algorithm is thus smaller by a factor @xmath301 .    in  ( * ?",
    "* section  5.1 ) the so - called key equations commonly used in the decoding of reed - solomon codes were generalized to this soft - interpolation step .",
    "it was then showed in  @xcite how one can efficiently compute a solution to these equations using fast structured linear algebra . in this approach ,",
    "the set of points @xmath302 is partitioned as @xmath303 , where in each @xmath304 the points have pairwise distinct @xmath305-coordinates .",
    "we further write @xmath306 for each @xmath307 , and @xmath308 .",
    "then , the cost bound is @xmath309 , with a probabilistic algorithm  ( * ? ? ?",
    "* section  iv.c ) .",
    "we note that @xmath310 depends on the chosen partition of the points .",
    "the algorithm in this paper is deterministic and has a better cost .",
    "all the mentioned algorithms for the interpolation step of list- or soft - decoding of reed - solomon codes , including the one presented in this paper , can be used in conjunction with the _ re - encoding technique _",
    "@xcite for the decoding problem .",
    "the case @xmath311 is used for example in the interpolation steps of the list - decoding of parvaresh - vardy codes  @xcite and of folded reed - solomon codes  @xcite , as well as in private information retrieval  @xcite . in these contexts , one deals with for some @xmath312 with , in most cases , @xmath313 where @xmath314 is the list - size parameter , and @xmath315 where @xmath276 is the multiplicity parameter . then , @xmath316 and @xmath317 . besides , the weight ( as mentioned in ) is @xmath318 for a fixed positive integer @xmath319 ; then",
    ", the corresponding input shift is @xmath320 .    to our knowledge",
    ", the best known cost has been obtained by a probabilistic algorithm which uses @xmath321 operations  ( * ? ? ? * theorem  1 ) to compute one solution with some degree constraints related to @xmath5 .",
    "however , this is not satisfactory for the application to private information retrieval , where one wants an @xmath5-minimal basis of solutions : using the polynomial matrix reduction approach mentioned in , such a basis can be computed in @xmath322 operations  @xcite ( we note that @xmath323 ) .",
    "it is not clear to us what bound we have on @xmath4 in this context , and thus how our algorithm compares to these two results .",
    "in this section , we assume that @xmath324 is a jordan matrix given by means of a standard representation as in  , and we provide a description of our divide - and - conquer algorithm together with a proof of the following refinement of our main result , .",
    "[ prop : mib ] without loss of generality , assume that @xmath6 ; then , let @xmath325",
    ". solves deterministically , and the sum of the @xmath5-row degrees of the computed @xmath5-minimal interpolation basis is at most @xmath146 .",
    "if @xmath326 , a cost bound for this algorithm is given by @xmath327      { \\mathcal{o } ( & { m}{\\mathsf{m}({\\sigma } ) } ( \\log({m})^3 + \\log({\\sigma } ) \\log({\\sigma}/{m } ) ) + { m}^2 { \\mathsf{m}({\\sigma}/{m } ) }      \\log({\\sigma } ) \\log({\\sigma}/{m } ) \\log({m } ) \\\\       & + { m}{\\mathsf{m}(\\xi ) } \\log({m})^2 + { m}^2 { \\mathsf{m}(\\xi/{m } ) }    \\log(\\xi/{m } ) \\log({m } ) ) }      & \\text{if } { \\omega}=2 ;    \\end{aligned}\\ ] ] if @xmath152 , it is given in .",
    "this algorithm relies on some subroutines , for which cost estimates are given in the following sections and are taken for granted here :    * in , the fast multiplication of two polynomial matrices with respect to the average row degree of the operands and of the result ; * in , the _ change of shift _ : given an @xmath5-minimal interpolation basis @xmath19 and some shift @xmath328 , compute an @xmath329-minimal interpolation basis ; * in , the fast computation of a product of the form @xmath99 ; * in , the computation of an @xmath5-minimal interpolation basis using linear algebra , which is used here for the base case of the recursion .",
    "first , we focus on the divide - and - conquer subroutine given in .",
    "in what follows , @xmath330 and @xmath331 always denote the leading and trailing principal @xmath332 submatrices of @xmath333 .",
    "these two submatrices are still in jordan canonical form , albeit not necessarily in standard representation ; this can however be restored by a single pass through the array .",
    "[ lem : mib - rec ] solves deterministically for the uniform shift @xmath334 , and the sum of the row degrees of the computed @xmath115-minimal interpolation basis is at most @xmath1 . if @xmath326 , a cost bound for this algorithm is given by @xmath335 if @xmath152 , it is given in .    in the rest of this paper",
    ", we use convenient notation for the cost of polynomial matrix multiplication and for related quantities that arise when working with submatrices of a given degree range as well as in divide - and - conquer computations .",
    "hereafter , @xmath336 always stands for the logarithm in base @xmath337 .",
    "[ dfn : polmatmul ] let @xmath0 and @xmath136 be two positive integers .",
    "then , @xmath338 is such that two matrices in @xmath167}^{{}\\times { } } } } $ ] of degree at most @xmath136 can be multiplied using @xmath338 operations in @xmath8 .",
    "then , writing @xmath339 and @xmath340 for the smallest powers of @xmath337 at least @xmath0 and @xmath136 , we also define    * @xmath341 , * @xmath342 , * @xmath343 , * @xmath344 .",
    "we note that one can always take @xmath345 .",
    "upper bounds for the other quantities are detailed in .    concerning the base case @xmath152 , the correctness and the cost bound both follow from results that will be given in , in particular .",
    "let us now consider the case of @xmath346 , and assume that @xmath155 and @xmath347 , as computed by the recursive calls , are @xmath115-minimal interpolation bases for @xmath348 and @xmath349 , respectively .",
    "the input @xmath49 takes the form @xmath350 $ ] and we have @xmath351 $ ] as well as @xmath352 . besides , @xmath353 is by construction unimodularly equivalent to @xmath347 , so there exists @xmath123 unimodular such that @xmath354 .",
    "defining @xmath355 , our goal is to show that @xmath95 is a minimal interpolation basis for @xmath356 .",
    "first , since @xmath333 is upper triangular we have @xmath357 = [ \\;{\\mathbf{\\makeuppercase{0}}}\\ ; |    { \\mathbf{\\makeuppercase{u}}}{{\\mathbf{\\makeuppercase{p}}}}^{(2)}{\\cdot}{{\\mathbf{\\makeuppercase{e}}}}^{(2 ) } ] = 0 $ ] , so that every row of @xmath95 is an interpolant for @xmath356 .",
    "let us now consider an arbitrary interpolant @xmath358}^{{}\\times { } } } } [ { m}]$ ] for @xmath356 .",
    "then , @xmath48 is in particular an interpolant for @xmath348 : there exists some row vector @xmath359 such that @xmath360 .",
    "furthermore , the equalities @xmath361 $ ] show that @xmath362 .",
    "thus , there exists some row vector @xmath363 such that @xmath364 , which gives @xmath365 .",
    "this means that every interpolant for @xmath356 is a @xmath26}$]-linear combination of the rows of @xmath95 .",
    "then , it remains to check that @xmath95 is @xmath115-reduced .",
    "as a @xmath115-minimal interpolation basis , @xmath347 is @xmath115-reduced and has full rank . then , the construction of @xmath353 using algorithm shift ensures that it is @xmath328-reduced , where @xmath366 .",
    "define @xmath367 ; the predictable - degree property  ( * ? ? ?",
    "* theorem  6.3 - 13 ) implies that @xmath368 . using the identity @xmath369",
    ", we obtain that the @xmath115-leading matrix of @xmath19 is the product of the @xmath328-leading matrix of @xmath353 and the @xmath115-leading matrix of @xmath370 , which are both invertible .",
    "thus , the @xmath115-leading matrix of @xmath19 is invertible as well , and therefore @xmath19 is @xmath115-reduced .",
    "thus , for any @xmath1 , the algorithm correctly computes an @xmath5-minimal interpolation basis for @xmath356 . as shown in",
    ", there is a direct link between m - pad approximation and shifted minimal interpolation bases with a multiplication matrix in jordan canonical form .",
    "then , the result in ( * ? ? ?",
    "* theorem 4.1 ) proves that for a given @xmath1 , the determinant of a @xmath115-minimal interpolation basis @xmath95 has degree at most @xmath1 .",
    "hence @xmath371 follows the fact that the sum of the row degrees of a @xmath115-reduced matrix equals the degree of its determinant .",
    "let us finally prove the announced cost bound for @xmath346 . without loss of generality , we assume that @xmath372 is a power of @xmath337 . each of steps  * 2.b * and  * 2.d * calls the algorithm recursively on an instance of with dimensions @xmath0 and @xmath149 .",
    "* the leaves of the recursion are for @xmath373 and thus according to each of them uses @xmath374 operations if @xmath157 , and @xmath375 operations if @xmath376 . for @xmath326 ( with @xmath377 a power of @xmath337 )",
    ", the recursion leads to @xmath377 leaves , which thus yield a total cost of @xmath378 operations if @xmath157 , and @xmath379 operations if @xmath376 . * according to , step  * 2.c * uses @xmath380 operations . using the super - linearity property of @xmath381",
    ", we see that this contributes to the total cost as @xmath382 operations . * for step  * 2.e * , we use with @xmath383 , remarking that both the sum of the entries of @xmath384 and that of @xmath385 are at most @xmath149 .",
    "then , the change of shift is performed using @xmath386 operations .",
    "thus , altogether the time spent in this step is @xmath387 operations ; we give an upper bound for this quantity in . * from we obtain that @xmath388 .",
    "then , using with @xmath383 , the polynomial matrix multiplication in step  * 2.f * can be done in time @xmath389 .",
    "besides , it is easily verified that by definition @xmath390 , so that the cost for this step is dominated by the cost for the change of shift .    adding these costs and using the bounds in leads to the conclusion .",
    "we now prove our main result .",
    "the correctness of follows from the correctness of .",
    "concerning the cost bound when @xmath346 , gives the number of operations used by step  * 2.a * to produce @xmath95 , which satisfies @xmath391 .",
    "then , considering @xmath6 without loss of generality , we have @xmath392 : states that step  * 2.b * can be performed using @xmath393 operations .",
    "the cost bound then follows from the bounds in .",
    "furthermore , from we also know that the sum of the @xmath5-row degrees of the output matrix is exactly @xmath394 , which is itself at most @xmath395 .",
    "in this section , we give a detailed complexity analysis concerning the fast algorithm from  ( * ? ? ?",
    "* section 3.6 ) for the multiplication of matrices with controlled , yet possibly unbalanced , row degrees . for completeness",
    ", we recall this algorithm below in . it is a central building block in our algorithm : it is used in the multiplication of interpolation bases ( step  * 2.f * of ) and also for the multiplication of nullspace bases that occur in the algorithm of  @xcite , which we use to perform the change of shift in step  * 2.e * of .    in the rest of the paper ,",
    "most polynomial matrices are interpolation bases and thus are square and nonsingular .",
    "in contrast , in this section polynomial matrices may be rectangular and have zero rows , since this may occur in nullspace basis computations ( see ) .",
    "thus , we extend the definitions of shift and row degree as follows . for a matrix @xmath396_{i , j}$ ] in @xmath104}^{{}\\times { } } } } [ { m}]$ ] for some @xmath231 , and a shift @xmath397 , the @xmath5-row degree of @xmath119 is the tuple @xmath398 , with @xmath399 for all  @xmath107 , and using the usual convention that @xmath400 . besides , @xmath4 denotes the sum of the non - negative entries of @xmath5 , that is , @xmath401 .    in order to multiply matrices with unbalanced row degrees ,",
    "we use in particular a technique based on _ partial linearization _ , which can be seen as a simplified version of the one in  ( * ? ? ?",
    "* section  6 ) for the purpose of multiplication . for a matrix @xmath120 with sum of row degrees @xmath402 , meant to be the left operand in a product @xmath403 for some @xmath404}^{{}\\times { } } } } $",
    "] , this technique consists in expanding the high - degree rows of @xmath120 so as to obtain a matrix @xmath405 with @xmath406 rows and degree at most @xmath407 , then computing the product @xmath408 , and finally retrieving the actual product @xmath409 by grouping together the rows that have been expanded ( called _ partial compression _ in what follows ) .",
    "more precisely , let @xmath410}^{{}\\times { } } } } [ { m}]$ ] for some @xmath231 and @xmath0 , with @xmath411 and write @xmath412 .",
    "we are given a target degree bound @xmath136 .",
    "for each @xmath107 , the row @xmath413 of degree @xmath414 is expanded into @xmath415 rows @xmath416 of degree at most @xmath136 , related by the identity @xmath417 then , the expanded matrix @xmath405 has @xmath418 rows @xmath419 .",
    "we will mainly use this technique for @xmath420 and @xmath421 or @xmath422 , in which case @xmath405 has fewer than @xmath423 rows .",
    "the partial compression is the computation of the row @xmath107 of the product @xmath403 from the rows @xmath424 of @xmath408 using the formula in  .",
    "[ prop : unbalanced - polmatmul ] let @xmath119 and @xmath120 in @xmath167}^{{}\\times { } } } } $ ] , and @xmath425 .",
    "let @xmath426 be an integer such that @xmath427 and @xmath428 .",
    "then , the product @xmath409 can be computed using @xmath429 operations in @xmath8 .    in this proof ,",
    "we use notation from .",
    "the correctness of this algorithm follows from the identity @xmath430 . in what follows",
    "we focus on proving the cost bound @xmath431 ; the announced upper bounds on this quantity follow from .",
    "we start with step  * 6 * , which adds the @xmath29 matrices @xmath432 obtained after the first five steps . for each @xmath107 in @xmath433",
    ", we have @xmath434 componentwise , hence @xmath435 . recalling that @xmath436 , the sum at step  * 6 * thus uses @xmath437 additions in @xmath8 .",
    "on the other hand , by definition of @xmath438 , the trivial lower bound @xmath439 for any @xmath440 implies that @xmath441 .",
    "now we study the loop .",
    "we remark that only step  * 5.c * involves arithmetic operations in @xmath8 .",
    "therefore the main task is to give bounds on the dimensions and degrees of the matrices we multiply at step  * 5.c*. for @xmath107 in @xmath433 , the column dimension of @xmath442 is @xmath0 and the row dimension of @xmath443 is @xmath444 .",
    "we further denote by @xmath445 the row dimension of @xmath442 ( and column dimension of @xmath446 ) , and we write @xmath447 = [ { \\mathbf{d}}_0 | \\cdots |    { \\mathbf{d}}_\\ell ] $ ] where the sizes of @xmath448 correspond to those of the blocks of @xmath449 as in step  * 4 * of the algorithm .",
    "first , let @xmath450 .",
    "then , @xmath451 is @xmath452 of degree at most @xmath407 and @xmath453 is @xmath454 with @xmath455 and @xmath456 ( we note that for @xmath450 these may be equalities and thus one does not need to discard the zero rows of @xmath453 to obtain efficiency ) . besides , we have the componentwise inequality @xmath457 , so that @xmath458",
    ". then , @xmath459 can be partially linearized into a matrix @xmath460 which has at most @xmath423 rows and degree at most @xmath407 , and the computation at step  * 5.c * for @xmath450 uses @xmath461 operations .",
    "now , let @xmath462 . by assumption",
    ", the sum of the row degrees of @xmath119 does not exceed @xmath402 : since all rows in @xmath442 have degree more than @xmath463 , this implies that @xmath464 . besides , since @xmath465",
    ", we obtain that every nonzero row of @xmath466 has @xmath467-row degree more than @xmath463 .",
    "then , @xmath468 implies that @xmath469 .",
    "furthermore , since we have @xmath470 , the partial linearization at step * 5.b * can be done by at most doubling the number of rows of @xmath443 , producing @xmath446 with fewer than @xmath471 rows and of degree at most @xmath463 .",
    "to summarize : @xmath442 has @xmath0 columns , @xmath472 rows , and degree at most @xmath473 ; @xmath446 has fewer than @xmath471 rows , and degree less than @xmath473",
    ". then , the computation of @xmath474 uses @xmath475 operations in @xmath8 .",
    "thus , overall the loop uses @xmath476 operations in @xmath8 .",
    "in our interpolation [ algo : mib ] , a key ingredient to achieve efficiency is to control the size of the intermediate interpolation bases that are computed in recursive calls . for this , we compute all minimal bases for the _ uniform _ shift and then recover the _ shifted _ minimal basis using what we call a change of shift , that we detail in this section .",
    "more precisely , we are interested in the ability to transform an @xmath5-reduced matrix @xmath477}^{{}\\times { } } } } $ ] with full rank into a unimodularly equivalent matrix that is @xmath329-reduced for some given shift @xmath478 : this is the problem of polynomial lattice reduction for the shift @xmath479 , knowing that the input matrix is already reduced for the shift @xmath5 .",
    "compared to a general row reduction algorithm such as the one in  @xcite , our algorithm achieves efficient computation with regards to the average row degree of the input @xmath19 rather than the maximum degree of the entries of @xmath19 .",
    "the main consequence of having an _ @xmath5-reduced _ input @xmath19 is that no high - degree cancellation can occur when performing unimodular transformations on the rows of @xmath19 , which is formalized as the predictable - degree property  ( * ? ? ?",
    "* theorem 6.3 - 13 ) .",
    "in particular , the unimodular transformation between @xmath19 and an @xmath329-reduced equivalent matrix has small row degree , and the proposition below shows how to exploit this to solve our problem via the computation of a shifted minimal ( left ) nullspace basis of some @xmath480 polynomial matrix .",
    "we remark that similar ideas about the use of minimal nullspace bases to compute reduced forms were already in  ( * ? ? ?",
    "* section  3 ) .",
    "[ lem : change - shift ] let @xmath481 and @xmath482 , let @xmath483}^{{}\\times { } } } } $ ] be @xmath5-reduced and nonsingular , and define @xmath484",
    ". then @xmath485}^{{}\\times { } } } } $ ] is an @xmath329-reduced form of @xmath19 with unimodular transformation @xmath486}^{{}\\times { } } } } $ ] if and only if @xmath487 $ ] is a @xmath488-minimal nullspace basis of @xmath489^\\mathsf{t}}$ ] .",
    "we first assume that the result holds for the uniform shift @xmath490 , and we show that the general case @xmath481 follows .",
    "indeed , considering the @xmath115-reduced matrix @xmath114 we have @xmath491 . hence @xmath492 $ ]",
    "is a @xmath488-minimal nullspace basis of @xmath489^\\mathsf{t}}$ ] if and only if @xmath493 is a @xmath328-reduced form of @xmath114 with unimodular transformation @xmath123 such that @xmath494 ; that is , if and only if @xmath495}^{{}\\times { } } } } $ ] is a @xmath329-reduced form of @xmath19 with unimodular transformation @xmath123 such that @xmath496 .",
    "let us now prove the proposition for the uniform shift @xmath497 .",
    "first , we assume that @xmath498}^{{}\\times { } } } } $ ] is a @xmath328-reduced form of @xmath19 with unimodular transformation @xmath123 . from @xmath499",
    "it follows that the rows of @xmath500 $ ] are in the nullspace of @xmath501^\\mathsf{t}}$ ] .",
    "writing @xmath502 $ ] with @xmath503}^{{}\\times { } } } } $ ] to denote an arbitrary basis of that nullspace , we have @xmath500 = { \\mathbf{\\makeuppercase{v } } }    [ { \\mathbf{\\makeuppercase{n}}}|\\,*\\,]$ ] for some @xmath504}^{{}\\times { } } } } $ ] and thus @xmath505 . since @xmath123 is unimodular , @xmath506 is unimodular too and @xmath500 $ ] is a basis of the nullspace of @xmath501^\\mathsf{t}}$ ] .",
    "it remains to check that @xmath500 $ ] is @xmath488-reduced .",
    "since @xmath19 is reduced , we have @xmath507 by the predictable - degree property  ( * ? ? ?",
    "* theorem 6.3 - 13 ) and , using @xmath508 , we obtain @xmath509",
    ". hence @xmath510 } =    { \\mathrm{rdeg}_{{{{\\mathbf{t}}(})}\\,}}{{\\mathbf{\\makeuppercase{r}}}}$ ] and , since @xmath493 is @xmath328-reduced , this implies that @xmath500 $ ] is @xmath488-reduced .",
    "now , let @xmath492 $ ] be a @xmath488-minimal nullspace basis of @xmath501^\\mathsf{t}}$ ] .",
    "first , we note that @xmath123 satisfies @xmath511 .",
    "it remains to check that @xmath123 is unimodular and that @xmath493 is @xmath328-reduced . to do this ,",
    "let @xmath512 denote an arbitrary @xmath328-reduced form of @xmath19 and let @xmath513 be the associated unimodular transformation .",
    "from the previous paragraph , we know that @xmath514 $ ] is a basis of the nullspace of @xmath515^\\mathsf{t}}$ ] , and since by definition @xmath492 $ ] is also such a basis , we have @xmath516 = { \\mathbf{\\makeuppercase{w } } } [ \\widehat{{\\mathbf{\\makeuppercase{u } } } } |    \\widehat{{\\mathbf{\\makeuppercase{r } } } } ] $ ] for some unimodular matrix @xmath517}^{{}\\times { } } } } $ ] . in particular , @xmath518 is unimodular .",
    "furthermore , the two unimodularly equivalent matrices @xmath516 $ ] and @xmath519 $ ] are @xmath488-reduced , so that they share the same shifted row degree up to permutation ( see for instance  ( * ? ? ?",
    "* lemma 6.3 - 14 ) ) .",
    "now , from the previous paragraph , we know that @xmath520 } =    { \\mathrm{rdeg}_{{{{\\mathbf{t}}(})}\\,}}{\\widehat{{\\mathbf{\\makeuppercase{r}}}}}$ ] , and similarly , having @xmath19 reduced , @xmath499 , and @xmath521 imply that @xmath522 }    = { \\mathrm{rdeg}_{{{{\\mathbf{t}}(})}\\,}}{{\\mathbf{\\makeuppercase{r}}}}$ ] .",
    "thus @xmath523 and @xmath524 are equal up to permutation , and combining this with the fact that @xmath525 where @xmath512 is @xmath328-reduced and @xmath526 is unimodular , we conclude that @xmath493 is @xmath328-reduced .",
    "this leads to , and in particular such a change of shift can be computed efficiently using the minimal nullspace basis algorithm of @xcite .",
    "[ prop : change_shift ] let @xmath481 and @xmath482 , let @xmath483}^{{}\\times { } } } } $ ] have full rank and be @xmath5-reduced , and define @xmath527 .",
    "we write @xmath402 to denote a parameter such that @xmath426 and @xmath528 .",
    "then , an @xmath329-reduced form @xmath498}^{{}\\times { } } } } $ ] of @xmath19 and the corresponding unimodular transformation @xmath529}^{{}\\times { } } } } $ ] can be computed using @xmath530 operations in @xmath8 . besides , we have @xmath531 .    write @xmath532 and @xmath533^\\mathsf{t}}$ ] . according to ,",
    "is correct : it computes @xmath534 $ ] a @xmath535-minimal nullspace basis of @xmath536 , and returns @xmath537 which is an @xmath329-reduced form of @xmath19 . for a fast solution , the minimal nullspace basis can be computed using  ( * ? ? ?",
    "* algorithm 1 ) , which we have rewritten in ( ) along with a detailed cost analysis .    here",
    ", we show that the requirements of this algorithm on its input are fulfilled in our context . concerning the input matrix",
    ", we note that @xmath536 has more rows than columns , and @xmath536 has full rank since by assumption @xmath19 has full rank .",
    "now , considering the requirement on the input shift , first , each element of the shift @xmath535 bounds the corresponding row degree of @xmath536 ; and second , the rows of @xmath536 can be permuted before the nullspace computation so as to have @xmath535 non - decreasing , and then the columns of the obtained nullspace basis can be permuted back to the original order . in details",
    ", we first compute @xmath538 being the tuple @xmath535 sorted in non - decreasing order together with the corresponding permutation matrix @xmath539 such that , when @xmath538 and @xmath535 are seen as column vectors in @xmath540 , we have @xmath541 .",
    "now that @xmath538 is non - decreasing and bounds the corresponding row degree of @xmath542 , we compute @xmath543 a @xmath538-minimal nullspace basis of @xmath542 using , then , @xmath544 is a @xmath535-minimal nullspace basis of @xmath536 .",
    "since by assumption @xmath545 , the announced cost bound follows directly from in .",
    "finally , we prove the bound on the sum of the @xmath546-row degrees of @xmath493 . since @xmath19 is @xmath5-reduced and @xmath493 is @xmath546-reduced , we have @xmath547 as well as @xmath548 ( * ? ? ?",
    "* section  6.3.2 ) .",
    "then , we have that @xmath549 , which concludes the proof .",
    "let @xmath550 and @xmath324 be as in the introduction ; in particular , we suppose that @xmath41 is a jordan matrix , given by a standard representation as in  .",
    "given @xmath49 in @xmath551}$ ] and a matrix @xmath19 in @xmath167}^{{}\\times { } } } } $ ] , we show how to compute the product @xmath552 .",
    "we will often call the result _ residual _ , as this is the role this vector plays in our main algorithm .    to give our complexity estimates ,",
    "we will make two assumptions , namely that @xmath553 and that the sum of the row degrees of @xmath19 is in @xmath554 ; they will both be satisfied when we apply the following result .    [ prop : update - evaluations ] there exists an algorithm computeresiduals that computes the matrix @xmath555 . if @xmath556 and if the sum of the row degrees of @xmath19 is @xmath554 , this algorithm uses @xmath557 operations in @xmath8 .    remark that when the sum of the row degrees of @xmath19 is @xmath554 , storing @xmath19 requires @xmath150 elements in @xmath8 , so that representing the input and output of this computation involves @xmath150 field elements . at best , one could thus hope for an algorithm of cost @xmath150 .",
    "our result is close , as we get a cost of @xmath558 with the best known value of @xmath3 .",
    "the following lemma writes the output in a more precise manner .",
    "the proof is a straightforward consequence of the discussion in about writing the notion of interpolant in terms of m - pad approximation .",
    "[ lem : evaluations ] suppose that @xmath41 has the form @xmath559 .",
    "let @xmath477}^{{}\\times { } } } } $ ] and @xmath560 $ ] , and write @xmath561 $ ] with @xmath562 in @xmath563 $ ] for @xmath564 . for @xmath564 , define the following matrices :    * @xmath565^\\mathsf{t } } \\in { \\renewcommand{}{{m}}{{{\\mathbb{k}}[{x}]}^{{}\\times { } } } } [ 1]$ ] is the column vector with polynomial entries built from the columns of @xmath562 , * @xmath566}^{{}\\times { } } } } [ 1]$ ] , * @xmath567 \\in { \\renewcommand{}{{m}}{{\\mathbb{k}}^{{}\\times { } } } } [ { { \\sigma}}_j]$ ] is the matrix whose columns are the coefficients of @xmath568 of degrees @xmath569 .    then , @xmath570 with @xmath571 \\in{\\renewcommand{}{{m}}{{\\mathbb{k}}^{{}\\times { } } } } [ { \\sigma}]$ ] .    to give an idea of our algorithm s behaviour ,",
    "let us first consider the case where @xmath41 is the upper shift matrix @xmath572 as in  , so there is only one jordan block whose eigenvalue is @xmath573 .",
    "this corresponds to having @xmath77 in the previous lemma , which thus says that we can turn the input @xmath49 into a vector of @xmath0 polynomials of degree at most @xmath1 , and that we simply have to left - multiply this vector by  @xmath19 .",
    "suppose furthermore that all entries in @xmath19 have degree @xmath574 ( this is the most natural situation ensuring that the sum of its row degrees is @xmath554 , as assumed in ) , so that we have to multiply an @xmath575 matrix with entries of degree @xmath574 by an @xmath576 vector with entries of degree @xmath1 .",
    "for this , we use the partial linearization presented in : we expand the right - hand side into an @xmath29 polynomial matrix with entries of degree @xmath574 , we multiply it by @xmath19 , and we recombine the entries of the result ; this leads us to the cost @xmath577 .    on the other side of the spectrum",
    ", we encountered the case of a diagonal matrix @xmath41 , with diagonal entries @xmath578 ( so all @xmath187 s are equal to @xmath153 ) ; suppose furthermore that these entries are pairwise distinct . in this case",
    ", if we let @xmath579 be the columns of @xmath49 , shows that the output is the matrix whose columns are @xmath580 .",
    "evaluating @xmath19 at all @xmath171 s would be too costly , as simply representing all the evaluations requires @xmath581 field elements ; instead , we interpolate a column vector of @xmath0 polynomials @xmath582 of degree less than @xmath1 from the respective rows of @xmath49 , do the same matrix - vector product as above , and evaluate the output at the @xmath171 s ; the total cost is @xmath583 .",
    "our main algorithm generalizes these two particular processes .",
    "we now state a few basic results that will be needed for this kind of calculation , around problems related to polynomial modular reduction and chinese remaindering .",
    "[ lemma : multirem ] the following cost estimates hold :    * given @xmath39 of degree @xmath136 in @xmath26}$ ] , and @xmath584 in @xmath8 , one can compute @xmath585 in @xmath586 operations in @xmath8 . *",
    "given moduli @xmath587 in @xmath26}$ ] , whose sum of degrees is @xmath588 , and @xmath39 of degree @xmath589 , one can compute @xmath590 using @xmath591 operations in @xmath8 . *",
    "conversely , chinese remaindering modulo polynomials with sum of degrees @xmath136 can be done in @xmath592 operations in @xmath8 .",
    "for the first and third point , we refer the reader to ( * ? ? ?",
    "* chapters  9 and  10 ) . for the second point",
    ", we first compute @xmath593 in time @xmath594 , reduce @xmath39 modulo @xmath595 in time @xmath596 , and use the simultaneous modular reduction algorithm of  , which takes time @xmath597 . besides",
    ", we have @xmath598 , as can be seen by considering the cases @xmath599 and @xmath600 .      for a jordan matrix @xmath324 given in standard representation , and for any @xmath584 in @xmath8",
    ", we will denote by @xmath601 the number of pairs @xmath602 appearing in that representation , counting repetitions ( so that @xmath603 ) .",
    "for an integer @xmath604 , we select from the representation of @xmath41 all those pairs @xmath602 with @xmath605 in @xmath606 , obtaining a set @xmath607 .",
    "since @xmath41 is in standard representation , we can compute all @xmath607 by a single pass through the array @xmath41 , and we can ensure for free that all @xmath607 themselves are in standard representation .",
    "we decompose @xmath607 further into two classes @xmath608 , where all pairs @xmath602 are such that @xmath609 is greater than @xmath0 , and @xmath610 , which contains all other pairs .",
    "as above , this decomposition can be done in linear time , and we can ensure for no extra cost that @xmath608 and @xmath610 are in standard representation . explicitly , these sequences will be written as @xmath611 with @xmath612 non - increasing , and where for @xmath107 in @xmath613 , @xmath614 and @xmath615 is a non - increasing sequence of elements in @xmath606 .",
    "the corresponding sets of columns in the input matrix @xmath49 and the output @xmath166 will be written @xmath616 and @xmath617 they will be treated using a direct application of .",
    "similarly , we write @xmath618 with @xmath619 non - increasing , and where for @xmath107 in @xmath620 , @xmath621 and @xmath622 is a non - increasing sequence of elements in @xmath606",
    ". the corresponding sets of columns in the input matrix @xmath49 and the output @xmath166 will be written @xmath623 and @xmath624 ; more precisely , they take the form @xmath625 and @xmath626 and will be treated using a chinese remaindering approach .    in the main loop ,",
    "the index @xmath231 will range from @xmath573 to @xmath627 .",
    "after that stage , all entries @xmath602 in @xmath41 that were not processed yet are such that @xmath628 .",
    "in particular , if we call @xmath629 the set of these remaining entries , we deduce that this set has cardinality at most @xmath0 ; thus @xmath630 holds for all @xmath584 and we process these entries using the chinese remaindering approach .",
    "algorithm computeresiduals constructs all these sets @xmath631 , @xmath610 , and @xmath629 , then extracts the corresponding columns from  @xmath49 ( this is the subroutine extractcolumns ) , and processes these subsets of columns , before merging all the results .      we start with the case of the sets @xmath633 , for which we follow a direct approach .",
    "below , recall that we write @xmath634 with @xmath635 for any @xmath231 , @xmath107 , and @xmath17 . for a fixed @xmath231 , we compute @xmath636 , for @xmath107 in @xmath613 , and do the corresponding matrix products .",
    "this is described in ; we give below a bound on the total time spent in this algorithm , that is , for all @xmath231 in @xmath637 . before that , we give two lemmas : the first one will allow us to control the cost of the calculations in this case ; in the second one , we explain how to efficiently compute the polynomial matrices @xmath638 .",
    "[ lemma : sumdeg ] the following bound holds : @xmath639    by construction , we have the estimate @xmath640 since this represents the total size of all blocks contained in the sequences @xmath633 .",
    "now , for fixed @xmath231 and @xmath107 , the construction of @xmath607 implies that the inequality @xmath641 holds for all @xmath17 .",
    "this shows that we have @xmath642 and the conclusion follows by summing over all @xmath231 and @xmath107 .    in the following lemma",
    ", we explain how to compute the polynomial matrices @xmath638 in an efficient manner , for @xmath107 in @xmath613 and for all the values of @xmath231 we need .",
    "[ lemma : allsimulmod ] suppose that the sum of the row degrees of @xmath19 is @xmath554 .",
    "then one can compute the matrices @xmath638 for all @xmath231 in @xmath643 and @xmath107 in @xmath613 using @xmath644 operations in @xmath8 .",
    "we use the second item in to first compute @xmath645 , for all @xmath231 and @xmath107 as in the statement of the lemma . here , the sum of the degrees is @xmath646 so we get a total cost of @xmath647 for an entry of @xmath19 of degree @xmath136 .",
    "summing over all entries , and using the fact that the sum of the row degrees of @xmath19 is @xmath554 , we obtain a total cost of @xmath648 now , because we consider here @xmath608 , we have @xmath649 for all @xmath231 and @xmath107 . hence , using the super - linearity of @xmath135 , the term @xmath650 admits the upper bound @xmath651 which is in @xmath652 in view of",
    ".    then we apply a variable shift to all these polynomials to replace @xmath653 by @xmath654 .",
    "using the first item in , for fixed @xmath231 and @xmath107 , the cost is @xmath655 .",
    "hence , the total time is again @xmath656 , so the same overall bound as above holds .",
    "[ lem : update - evaluations - direct ] is correct . given the polynomial matrices computed in , the total time spent in this algorithm for all @xmath231 in @xmath657 is @xmath658 operations in @xmath8 .",
    "correctness of the algorithm follows from , so we focus on the cost analysis .",
    "gives the cost of computing all polynomial matrices needed at step  * 1*. the only other arithmetic operations are those done in the matrix products at step  * 2.b * : we multiply matrices of respective sizes @xmath29 and @xmath659 , with entries of degree less than @xmath660 . for given @xmath231 and @xmath107 , since we have @xmath661 , the cost is @xmath662 ; using the super - linearity of @xmath663 , this is in @xmath664 .",
    "applying again , we deduce that the sum over all @xmath231 and @xmath107 is @xmath665 .      the second case to consider is @xmath666 .",
    "recall that for a given index @xmath231 , we write this sequence as @xmath667 with @xmath668 for all @xmath107 in @xmath620 . in this case",
    ", @xmath669 may be large so the previous approach may lead us to compute too many matrices @xmath670 . instead ,",
    "for fixed @xmath231 and  @xmath17 , we use chinese remaindering to transform the corresponding submatrices @xmath671 into a polynomial matrix @xmath672 of small column dimension ; this allows us to efficiently perform matrix multiplication by @xmath19 on the left , and we eventually get @xmath673 by computing the first coefficients in a taylor expansion of this product around every @xmath674 .    to simplify the notation in the algorithm , we also suppose that for a fixed @xmath231 , the points @xmath675 all appear the same number of times in @xmath666 .",
    "this is done by replacing @xmath676 by their maximum @xmath677 ( simply written @xmath678 in the pseudo - code ) and adding suitable blocks @xmath679 , with all new @xmath680 set to zero .",
    "[ lem : update - evaluations - interpolation ] is correct .",
    "if the sum of the row degrees of @xmath19 is in @xmath554 , the total time spent in this algorithm for all @xmath231 in @xmath681 is @xmath682 operations in @xmath8 .    proving correctness amounts to verifying that we compute the quantities described in .",
    "indeed , the formulas in the algorithm show that for all @xmath683 , we have @xmath684 ; the link with is made by observing that @xmath685 and @xmath686 .    in terms of complexity , the first item in shows that for a given index @xmath231 , step  * 1.a * can be done in time @xmath687 for a total cost of @xmath688 .",
    "step  * 1.b * can be done in quasi - linear time as well : for each @xmath231 and @xmath17 , we can compute each of the @xmath0 entries of the polynomial vector @xmath689 by fast chinese remaindering ( third item in ) , using @xmath690 operations in @xmath8 , with @xmath691 . taking all rows into account , and summing over all indices @xmath231 and @xmath17",
    ", we obtain again a total cost of @xmath692 .    the next step to examine",
    "is the polynomial matrix product at step  * 2*. the matrix @xmath19 has size @xmath29 , and the sum of its row degrees is by assumption @xmath554 ; using the partial linearization technique presented in , we can replace @xmath19 by a matrix of size @xmath693 with entries of degree at most @xmath377 .    for a fixed choice of @xmath231 , the right - hand side has size @xmath694 , and its columns have respective degrees less than @xmath695 .",
    "we split each of its columns into new columns of degree at most @xmath377 , so that the @xmath17th column is split into @xmath696 columns ( the constant term 1 dominates when @xmath697 ) .",
    "thus , the new right - hand side has @xmath698 columns and degree at most  @xmath377 .",
    "now , taking all @xmath231 into account , we remark that the left - hand side remains the same ; thus , we are led to do one matrix product with degrees @xmath377 , with left - hand side of size @xmath699 , and right - hand side having column dimension at most @xmath700 since all @xmath678 are at most @xmath0 , the first term sums up to @xmath701 ; by construction , the second one adds up to @xmath406 . hence , the matrix product we need can be done in time @xmath702 .    for a given @xmath231 , @xmath703 are vectors of size @xmath0 .",
    "furthermore , for each @xmath17 the entries of @xmath704 have degree less than @xmath705 respectively , where @xmath706 are the degrees of the rows of @xmath19 .",
    "in particular , for a fixed @xmath231 , the reductions at step  * 3.a * can be done in time @xmath707 using fast multiple reduction , by means of the second item in .",
    "using our assumption on @xmath19 , and the fact that @xmath708 , we see that the first term is @xmath709 , which adds up to @xmath710 if we sum over @xmath231 .",
    "the second term adds up to @xmath711 , as was the case for step   * 1.b*.    the same analysis is used for the shifts taking place at step  * 3.b * as for those in step  * 1.a * : for fixed @xmath231 and @xmath17 , the cost is @xmath712 , and we conclude as above .",
    "in this section , we give an efficient algorithm based on linearization techniques to compute interpolation bases for the case of an arbitrary matrix @xmath41 and an arbitrary shift ; in particular , we prove .",
    "in addition to being interesting on its own , the algorithm in this section allows us to handle the base cases in the recursion of the divide - and - conquer algorithm presented in . for that particular case ,",
    "we have @xmath373 ; the algorithm we give here solves this base case using @xmath374 operations in @xmath8 .",
    "[ prop : lin - mib ] let @xmath324 , @xmath560 $ ] , @xmath117 , and let @xmath713 be a bound on the degree of the minimal polynomial of @xmath41 .",
    "then , solves deterministically , using @xmath714 operations in @xmath8 ; it returns the unique interpolation basis @xmath95 for @xmath46 which is in @xmath5-popov form . besides , the maximal degree in @xmath95 is at most @xmath715 and the sum of the _ column _ degrees of @xmath95 is at most @xmath1 .",
    "we remark that the degree of the minimal polynomial of @xmath41 is at most @xmath1 . in , we require that @xmath715 be a power of @xmath337 and thus we may have @xmath716 ;",
    "still we can always choose @xmath717 . the proof is deferred until , where we also recall the definition of the shifted popov form  @xcite .    to obtain this result , we rely on linear algebra tools via the use of the linearization in  @xcite , where an interpolant is seen as a linear relation between the rows of a striped krylov matrix .",
    "the reader may also refer to  ( * ? ? ? * and  6.4 ) for a presentation of this point of view . in @xcite , it is assumed that @xmath333 is upper triangular : this yields recurrence relations , leading to an iterative algorithm to compute an interpolation basis in shifted popov form in a fraction - free way .    here , to obtain efficiency and deal with a general @xmath333 , we proceed in two steps .",
    "first , we compute the row rank profile of the striped krylov matrix @xmath718 with an algorithm _  la _",
    "@xcite , which uses at most @xmath719 steps and supports different orderings of the rows in @xmath718 depending on the input shift .",
    "then , we use the resulting independent rows of @xmath718 to compute the specific rows in the nullspace of @xmath718 which correspond to the interpolation basis in shifted popov form .",
    "we note that when @xmath720 , the cost bound in is linear in @xmath0 , while the dense representation of the output @xmath575 polynomial matrix will use at least @xmath721 field elements .",
    "we will see in that when @xmath722 , at least @xmath723 columns of the basis in @xmath5-popov form have only one nonzero coefficient which is @xmath153 , and thus those columns can be described without involving any arithmetic operation .",
    "hence , the actual computation is restricted to an @xmath50 submatrix of the output basis .",
    "our goal is to explain how to transform the problem of finding interpolants into a problem of linear algebra over @xmath8 .",
    "this will involve a straightforward linearization of the polynomials in the output interpolation basis @xmath95 , expanding them as a list of coefficients so that @xmath95 is represented as a matrix over @xmath8 .",
    "correspondingly , we show how from the input @xmath46 one can build a matrix @xmath718 over @xmath8 which is such that an interpolant for @xmath46 corresponds to a vector in the left nullspace of @xmath718 .",
    "then , since we will be looking for interpolants that have a small degree with respect to the column shifts given by @xmath5 , we describe a way to adapt these constructions so that they facilitate taking into account the influence of @xmath5 .",
    "this gives a first intuition of some properties of the linearization of an interpolant that has small shifted degree : this will then be presented in details in .",
    "let us first describe the linearization of interpolants , which are seen as row vectors in @xmath724}^{{}\\times { } } } } [ { m}]$ ] . in what follows , we suppose that we know a bound @xmath725 on the degree of the minimal polynomial of @xmath41 ; one can always choose @xmath726",
    ". in , we will exhibit @xmath5-minimal interpolation bases for @xmath46 whose entries all have degree at most @xmath715 ( while in general such a basis may have degree up to @xmath727 ) .",
    "thus , in this , we focus on solutions to that have degree at most @xmath715 .",
    "correspondingly , @xmath26}_{{\\leqslant}{\\delta}}$ ] denotes the set of polynomials in @xmath26}$ ] of degree at most @xmath715 .",
    "given @xmath728}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] for some @xmath729 , we write it as a polynomial of matrices : @xmath730 where each @xmath731 is a scalar matrix in @xmath732 $ ] ; then the _ expansion _",
    "of @xmath19 ( in degree @xmath715 ) is the matrix @xmath733 \\in{\\renewcommand{}{{n}}{{\\mathbb{k}}^{{}\\times { } } } } [ { m}({\\delta}+1)]$ ] .",
    "the reciprocal operation is called _ compression _ ( in degree @xmath715 ) : given a scalar matrix @xmath734 $ ] , we write it with blocks @xmath735 $ ] where each @xmath736 is in @xmath732 $ ] , and then we define its compression as @xmath737}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] .",
    "these definitions of @xmath738 and @xmath739 hold for any row dimension @xmath740 ; this @xmath740 will always be clear from the context .",
    "now , given some matrices @xmath741}$ ] and @xmath742 , our interpolation problem asks to find @xmath743}^{{}\\times { } } } } [ { m}]}_{{\\leqslant}{\\delta}}$ ] such that @xmath102 .",
    "writing @xmath744 , we recall that @xmath745 .",
    "then , in accordance to the linearization of @xmath95 , the input @xmath46 is expanded as follows : @xmath746 \\in { \\renewcommand{}{{m}({\\delta}+1)}{{\\mathbb{k}}^{{}\\times { } } } } [ { \\sigma}].\\ ] ] this way , we have @xmath747 for any polynomial matrix @xmath748}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] .",
    "in particular , a row vector @xmath176}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] is an interpolant for @xmath49 if and only if @xmath749 , that is , @xmath750 is in the ( left ) nullspace of @xmath751 . up to some permutation of the rows and different degree constraints ,",
    "this so - called _ striped - krylov _ matrix @xmath751 was used in  @xcite for the purpose of computing interpolants .",
    "* notation .",
    "* for the rest of this , we will use the letter @xmath107 for rows of @xmath751 and for columns of @xmath738 ; the letter @xmath17 for columns of @xmath751 ; the letter @xmath136 for the block of columns of @xmath738 which correspond to coefficients of degree @xmath136 in @xmath19 , as well as for the corresponding block @xmath752 of rows of @xmath751 ; the letter @xmath753 for the columns of this degree @xmath136 block in @xmath738 and for the rows of the block @xmath752 in @xmath751 .",
    "[ eg : linearization ]    in this example , we have @xmath754 and the base field is the finite field with @xmath755 elements ; the input matrices are @xmath756 then , we have @xmath757 it is easily checked that @xmath758}^{m}$ ] is an interpolant for @xmath759 , since @xmath760 .",
    "other interpolants are for example @xmath761 which has row degree @xmath153 , @xmath762 which has row degree @xmath337 , and @xmath763 which has row degree @xmath764 .",
    "we have @xmath765   \\\\    { \\mathcal{e}_{}({\\mathbf{\\makelowercase{p}}}_2 ) } & = & [ & 13 & 57 & 0 & | & 3   & 1 &   0 & | & 0 & 0 & 0 & | & 0 & 0 & 0 & ]   \\\\    { \\mathcal{e}_{}({\\mathbf{\\makelowercase{p}}}_3 ) } & = & [ & 0   & 0   & 0 & | & 36 & 31 & 0 & | & 1 & 0 & 0 & | & 0 & 0 & 0 & ]   \\\\    { \\mathcal{e}_{}({\\mathbf{\\makelowercase{p}}}_4 ) } & = & [ & 0   & 0   & 0 & | & 0   & 0 &   0 & | & 0 & 0 & 0 & | & 1 & 0 & 0 & ] .",
    "\\end{array}\\ ] ] besides , one can check that the matrix @xmath766 whose rows are @xmath767 is a reduced basis for the module @xmath768 of hermite - pad approximants of order @xmath764 for @xmath769 .",
    "now , we need tools to interpret the @xmath5-minimality of an interpolation basis . in",
    ", we see that @xmath770 has @xmath115-row degree @xmath573 and therefore appears in @xmath95 ; however @xmath771 has @xmath115-row degree @xmath764 and does not appear in @xmath95 . on the other hand , considering @xmath772 , the @xmath5-row degree of @xmath771 is @xmath764 , while the one of @xmath770 is @xmath773 : when forming rows of a @xmath774-minimal interpolation basis , @xmath771 is a better candidate than @xmath770 .",
    "we see through this example that the uniform shift @xmath334 leads to look in priority for relations involving the first rows of the matrix @xmath751 ; on the other hand , the shift @xmath772 leads to look for relations involving in priority the rows @xmath775 , @xmath776 , @xmath777 , and @xmath778 in @xmath751 before considering the rows @xmath779 and @xmath780 .",
    "going back to the general case , we define a notion of _ priority _ of the row @xmath753 of @xmath752 in @xmath751 .",
    "let @xmath781 $ ] be any relation between the rows of @xmath751 involving this row , meaning that , writing @xmath782 for the corresponding interpolant , the coefficient in column @xmath753 of @xmath783 is nonzero .",
    "this implies that the @xmath5-row degree of @xmath25 is at least @xmath784 .",
    "since the @xmath5-row degree is precisely what we want to minimize in order to obtain an @xmath5-minimal interpolation basis , the priority of the rows of @xmath751 can be measured by the function @xmath785 defined by @xmath786 .",
    "then , when computing relations between rows of @xmath751 , we should use in priority the rows with low @xmath787 in order to get interpolants with small @xmath5-row degree .",
    "to take this into account , we extend the linearization framework by using a permutation of the rows of @xmath751 so that they appear in non - increasing order of their priority given by @xmath5 .",
    "this way , an interpolant with _ small _ @xmath5-row degree is always one whose expansion forms a relation between the _ first _ rows of the permuted @xmath751 . to preserve properties such as @xmath788",
    ", we naturally permute the columns of @xmath738 accordingly . if @xmath789 $ ] in @xmath790 denotes the row vector indicating the priorities of the rows of @xmath751",
    ", then we choose an @xmath791 permutation matrix @xmath792 such that the list @xmath793 is non - decreasing .",
    "then , the matrix @xmath794 is the matrix @xmath751 with rows permuted so that they are arranged by non - increasing priority , that is , by non - decreasing values of @xmath785 .",
    "furthermore , the permutation @xmath792 induces a bijection @xmath795 which keeps track of the position changes when applying the permutation : it associates to @xmath796 the index @xmath797 of the element @xmath798 in the sorted list @xmath799 .",
    "we now give precise definitions .",
    "[ dfn : priority ] let @xmath560 $ ] and @xmath324 , and let @xmath117 .",
    "the priority function @xmath800 is defined by @xmath786 .",
    "let @xmath789 $ ] be the sequence of priorities in @xmath801 .",
    "then , we define @xmath792 as the unique permutation matrix in @xmath802 along with the corresponding indexing function @xmath803 = [ 1,2,\\ldots,{m}({\\delta}+1 ) ] \\ ; { { \\mathbf{\\makeuppercase{\\pi}}}_{{\\mathbf{s}}}}\\end{aligned}\\ ] ] which are such that    a.   @xmath799 is non - decreasing ; b.   whenever @xmath804 are such that @xmath805 , we have @xmath806 and assuming without loss of generality that @xmath807 , then @xmath808 .    besides , we define @xmath809 as well as the shifted expansion @xmath810 and the shifted compression @xmath811 .    in other words , @xmath792 is the unique permutation which lexicographically sorts the sequence @xmath812.\\ ] ] a representation of @xmath792 can be computed using @xmath813 integer comparisons , and a representation of @xmath795 can be computed using its definition in time linear in @xmath814 . in the specific case of the uniform shift @xmath334 , we have @xmath815 , @xmath792 is the identity matrix , and @xmath816 , and we have the identities @xmath817 , @xmath818 , @xmath819 .",
    "the main ideas of the rest of can be understood focusing on this particular case .",
    "[ eg : linearization - bis ]    in the context of , if we consider the shifts @xmath820 and @xmath821 , then we have @xmath822 besides , one can check that the shifted expansions of the interpolants @xmath770 , @xmath823 , @xmath824 , and @xmath771 with respect to @xmath5 and @xmath328 are @xmath825 \\\\   { \\mathcal{e}_{{{\\mathbf{t}(})}}}{{\\mathbf{\\makelowercase{p}}}_1 }",
    "& = & [ & 96 & 0 & 0 & 1 & 96 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ]   \\\\   { \\mathcal{e}_{{{\\mathbf{s}}}}({\\mathbf{\\makelowercase{p}}}_2 ) }     & = & [ & 13 & 3 & 0 & 0 & 57 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & ] \\\\   { \\mathcal{e}_{{{\\mathbf{t}(})}}}{{\\mathbf{\\makelowercase{p}}}_2 } & = & [ & 57 & 1 & 0 & 0 & 13 & 0 & 0 & 3 & 0 & 0 & 0 & 0 & ] \\\\   { \\mathcal{e}_{{{\\mathbf{s}}}}({\\mathbf{\\makelowercase{p}}}_3 ) }     & = & [ & 0 & 36 & 1 & 0 & 0 & 31 & 0 & 0 & 0 & 0 & 0 & 0 & ] \\\\   { \\mathcal{e}_{{{\\mathbf{t}(})}}}{{\\mathbf{\\makelowercase{p}}}_3 } & = & [ & 0 & 31 & 0 & 0 & 0 & 0 & 0 & 36 & 0 & 1 & 0 & 0   & ] \\\\   { \\mathcal{e}_{{{\\mathbf{s}}}}({\\mathbf{\\makelowercase{p}}}_4 ) }     & = & [ & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0   & ]   \\\\   { \\mathcal{e}_{{{\\mathbf{t}(})}}}{{\\mathbf{\\makelowercase{p}}}_4 } & = & [ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & ] .",
    "\\text{\\qed}\\end{array}\\ ] ]      from the previous subsection , the intuition is that the minimality of interpolants can be read on the corresponding linear relations between the rows of @xmath826 , as the fact that they involve in priority the first rows . here",
    ", we support this intuition with rigorous statements , presenting a notion of minimality for linear relations between the rows of @xmath826 , and showing that an @xmath5-minimal interpolation basis for @xmath46 corresponds to a specific set of @xmath0 such minimal relations .",
    "first we show that , given a polynomial row vector and a degree shift , one can directly read the pivot index  ( * ? ? ?",
    "* section 2 ) of the vector from its expansion . extending the definitions in  @xcite to the shifted case",
    ", we define the @xmath5-pivot index , @xmath5-pivot entry , and @xmath5-pivot degree of a nonzero row vector as follows .",
    "[ dfn : pivot ] let @xmath827_c \\in { \\renewcommand{}{1}{{{\\mathbb{k}}[{x}]}^{{}\\times { } } } } [ { m}]$ ] be a nonzero row vector and let @xmath117 be a degree shift .",
    "@xmath5-pivot index _ of @xmath25 is the largest column index @xmath828 such that @xmath829 is equal to the @xmath5-row degree @xmath830 of this row ; then , @xmath831 and @xmath832 are called the _ @xmath5-pivot entry _ and the _ @xmath5-pivot degree _ of @xmath25 , respectively",
    ".    the following result will be useful for our purpose , since pivot indices can be used to easily identify some specific forms of reduced polynomial matrices .    [",
    "lem : pivot ] let @xmath827_c \\in { \\renewcommand{}{1}{{{\\mathbb{k}}[{x}]}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] be a nonzero row vector .",
    "then , @xmath833 is the column index of the rightmost nonzero coefficient in @xmath834 if and only if @xmath25 has @xmath5-pivot index  @xmath753 and @xmath5-pivot degree @xmath835 .",
    "we distinguish three sets of entries of @xmath834 with column index @xmath836 : the one at index @xmath107 , the ones that have a higher @xmath785 , and the ones that have the same @xmath785 :    * if the coefficient at index @xmath837 in @xmath834 is nonzero then @xmath838 , and if @xmath839 then the coefficient at index @xmath837 in @xmath834 is nonzero ; * the coefficient at index @xmath840 in @xmath834 is zero for all @xmath841 such that @xmath842 if and only if @xmath843 for all @xmath844 ; * assuming @xmath845 for all @xmath846 , the coefficient at index @xmath840 in @xmath834 is zero for all @xmath841 such that @xmath847 with @xmath848 ( by definition of @xmath792 , this implies @xmath849 ) if and only if we have @xmath850 for all @xmath851 ;    these three points prove the equivalence .    we have seen that an interpolant for @xmath46 corresponds to a linear relation between the rows of @xmath826 . from this perspective",
    ", the preceding result implies that an interpolant with @xmath5-pivot index @xmath753 and @xmath5-pivot degree @xmath136 corresponds to a linear relation which expresses the row at index @xmath797 in @xmath826 as a linear combination of the rows at indices smaller than @xmath797 .",
    "now , we give a precise correspondence between minimal interpolation bases and sets of linear relations which involve in priority the first rows of @xmath826 .",
    "[ eg : minimal - relations ] let us consider the context of with the uniform shift . as mentioned above ,",
    "the matrix @xmath95 whose rows are @xmath767 is a minimal interpolation basis .",
    "the pivot indices of @xmath852 are @xmath153 , @xmath337 , @xmath764 , and their pivot degrees are @xmath337 , @xmath153 , @xmath573 . besides , we remark that    * the relation @xmath853 involves the row @xmath854 of @xmath49 and the rows above this one in @xmath751 ; * @xmath855 involves the row @xmath856 of @xmath857 and the rows above this one in @xmath751 , and there is no linear relation involving the row @xmath856 of @xmath49 and the rows above it in @xmath751 ; * @xmath858 involves the row @xmath859 of @xmath860 and the rows above it in @xmath751 : one can check that there is no linear relation between the row @xmath859 of @xmath857 and the rows above it in @xmath751 .",
    "this example suggests that we can give a link between the minimal row degree of a minimal interpolation basis and some minimal exponent @xmath861 such that the row @xmath753 of the block @xmath862 is a linear combination on the rows above it in @xmath751 .",
    "extending this to the case of any shift @xmath5 leads us to the following definition , which is reminiscent of the so - called _ minimal indices _ ( or _ kronecker indices _ ) for @xmath115-minimal nullspace bases  ( * ? ? ?",
    "* section 6.5.4 ) .",
    "[ dfn : min - deg ] let @xmath324 and @xmath560 $ ] , and let @xmath117 .",
    "the _ @xmath5-minimal degree _ of @xmath46 is the tuple @xmath863 where for each @xmath828 , @xmath864 is the smallest exponent such that the row @xmath865 is a linear combination of the rows in @xmath866 .",
    "we note that we have @xmath867 for every @xmath753 , since the minimal polynomial of the matrix @xmath324 is of degree at most @xmath715 .",
    "we now state in and that the minimal degree of @xmath46 indeed corresponds to a notion of minimality of interpolants and interpolation bases . until the end of this [ subsec : rel - int ]",
    ", we fix a matrix @xmath741}$ ] and a matrix @xmath742 .",
    "[ lem : lin - piv - deg ] let @xmath868 \\in{\\renewcommand{}{1}{{{\\mathbb{k}}[{x}]}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] , @xmath117 , and @xmath753 in @xmath869 . if @xmath48 is an interpolant for @xmath46 with @xmath5-pivot index @xmath753 , then @xmath48 has @xmath5-pivot degree @xmath870 . besides , there is an interpolant @xmath871}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] for @xmath46 which has @xmath5-pivot index @xmath753 and @xmath5-pivot degree @xmath872 .",
    "first , assume @xmath48 is an interpolant with @xmath5-pivot index @xmath753 , and let @xmath873 be the degree of the @xmath5-pivot entry of @xmath48 . according to",
    ", the rightmost nonzero element of @xmath874 is at index @xmath797 , and since @xmath48 is an interpolant for @xmath46 we have @xmath875 .",
    "this implies that the row @xmath797 of @xmath826 is a linear combination of the rows in @xmath876 , which in turn implies @xmath877 by definition of @xmath861 .",
    "now , the definition of @xmath861 also ensures that the row @xmath878 of @xmath826 is a linear combination of the rows @xmath879 .",
    "this linear combination forms a vector @xmath880 in the nullspace of @xmath826 with its rightmost nonzero element at index @xmath878 ; then by , @xmath881 is an interpolant with @xmath5-pivot index @xmath753 and @xmath5-pivot degree @xmath861 . besides , @xmath48 has degree at most @xmath715 by construction .",
    "now , we want to extend these considerations on row vectors and interpolants to matrices and interpolation bases . in connection with the notion of pivot of a row",
    ", there is a specific form of reduced matrices called the weak popov form  @xcite , for which we extend the definition to any shift @xmath5 as follows .",
    "[ dfn : weak - popov ]",
    "let @xmath19 in @xmath167}^{{}\\times { } } } } $ ] have full rank , and let @xmath5 in @xmath882 .",
    "then , @xmath19 is said to be in _",
    "@xmath5-weak popov form _ if the @xmath5-pivot indices of its rows are pairwise distinct .",
    "furthermore , the _ @xmath5-pivot degree _ of @xmath19 is the tuple @xmath883 where for @xmath828 , @xmath884 is the @xmath5-pivot degree of the row of @xmath19 which has @xmath5-pivot index @xmath753 .",
    "a matrix @xmath19 in @xmath5-weak popov form is in particular @xmath5-reduced .",
    "then , leads to the following result ; we remark that even though the matrix @xmath19 in this corollary is @xmath5-reduced and each of its rows is an interpolant , we do not yet claim that it is an interpolation basis .",
    "[ cor : weak - popov - mib ] there is a matrix @xmath477}^{{}\\times { } } } } _ { { \\leqslant}{\\delta}}$ ] in @xmath5-weak popov form , with @xmath5-pivot entries on the diagonal and @xmath5-pivot degree @xmath863 , such that every row of @xmath19 is an interpolant for @xmath46 .    for every @xmath753 in @xmath869",
    ", shows that there is an interpolant @xmath885 for @xmath46 which has degree at most @xmath715 , has @xmath5-pivot index @xmath753 , and has @xmath5-pivot degree @xmath861 .",
    "then , considering the matrix @xmath19 in @xmath167}^{{}\\times { } } } } $ ] whose row @xmath753 is @xmath885 gives the conclusion .",
    "we conclude this section by proving that the @xmath5-minimal degree of @xmath46 is directly linked to the @xmath5-row degree of a minimal interpolation basis , which proves in particular that the matrix @xmath95 in is an @xmath5-minimal interpolation basis for @xmath46 .",
    "[ lem : red - to - mib ] let @xmath886}^{{}\\times { } } } } [ { m}]}$ ] be @xmath5-reduced such that each row of @xmath887 is an interpolant for @xmath46 . then , @xmath887 is an interpolation basis for @xmath46 if and only if the @xmath5-row degree @xmath888 of @xmath887 is @xmath889 up to a permutation of the rows of @xmath887 . in particular ,",
    "if @xmath95 is a matrix as in , then @xmath95 is an @xmath5-minimal interpolation basis for @xmath46 .",
    "we denote @xmath118}^{{}\\times { } } } } [ { m}]}_{{\\leqslant}{\\delta}}$ ] a matrix as in ; @xmath95 is in particular @xmath5-reduced and has @xmath5-row degree exactly @xmath890 .",
    "first , we assume that @xmath887 is an interpolation basis for @xmath46 . remarking that a matrix @xmath891 is in @xmath5-weak popov form if and only if @xmath892 is in weak popov form , we know from  ( * ? ? ?",
    "* section 2 ) that @xmath887 is left - unimodularly equivalent to a matrix @xmath891 in @xmath5-weak popov form .",
    "besides , up to a permutation of the rows of @xmath891 , we assume without loss of generality that the pivot entries @xmath891 are on the diagonal .",
    "then , denoting its @xmath5-pivot degree by @xmath893 , the @xmath5-row degree of @xmath891 is @xmath894 .",
    "since @xmath887 and @xmath891 are @xmath5-reduced and unimodularly equivalent , they have the same @xmath5-row degree up to a permutation ( * ? ? ?",
    "* lemma 6.3 - 14 ) : thus it is enough to prove that @xmath895 . by applied to each row of @xmath891 ,",
    "@xmath706 are at least @xmath896 , respectively . on the other hand , since @xmath891 is an interpolation basis , there is a nonsingular matrix @xmath121}^{{}\\times { } } } } [ { m}]}$ ] such that @xmath897 .",
    "since @xmath95 is @xmath5-reduced with the @xmath5-row degree @xmath898 , we have @xmath899 ( * ? ? ?",
    "* lemma  2.10 ) .",
    "similarly , we have @xmath900 . considering the determinantal degree in the identity @xmath901 yields @xmath902 ,",
    "from which we conclude @xmath903 for all @xmath904 .",
    "now , we note that this also implies that the determinant of @xmath123 is constant , thus @xmath123 is unimodular and consequently @xmath95 is an interpolation basis : since @xmath95 is @xmath5-reduced by construction , it is an @xmath5-minimal interpolation basis .",
    "finally , we assume that @xmath887 has @xmath5-row degree @xmath889 up to a permutation .",
    "since @xmath95 is an interpolation basis , there is a nonsingular matrix @xmath121}^{{}\\times { } } } } [ { m}]}$ ] such that @xmath905 .",
    "since @xmath887 is @xmath5-reduced , we have @xmath906 . then",
    ", considering the determinantal degree in the identity @xmath905 shows that the determinant of @xmath123 is a nonzero constant , that is , @xmath123 is unimodular .",
    "thus , @xmath887 is an interpolation basis .",
    "[ rmk : elimination ] as can be observed in the definition of the @xmath5-minimal degree and in the proof of , one can use gaussian elimination on the rows of @xmath826 to build each row of the @xmath5-minimal interpolation basis  @xmath95 .",
    "this gives a method for solving using linear algebra .",
    "then , the main goal in the rest of this section is to show how to perform the computation of @xmath95 efficiently .",
    "the reader may have noted that @xmath826 has @xmath907 coefficients in @xmath8 , and in general @xmath908 may be beyond our target cost bound given in .",
    "here , we show that one can focus on a small subset of the rows of @xmath826 which contains enough information to compute linear relations leading to a matrix @xmath19 as in .",
    "then , we present a fast algorithm to compute this subset of rows .",
    "we also use these results to bound the average @xmath5-row degree of any @xmath5-minimal interpolation basis .    to begin with , we give some helpful structure properties of @xmath826 , which will be central in choosing the subset of rows and in the designing a fast algorithm which computes independent rows in @xmath826 without having to consider the whole matrix .",
    "[ lem : structure ] let @xmath324 and @xmath909 $ ] , and let @xmath117 .",
    "let @xmath910 be as in .",
    "* for each @xmath753 , @xmath911 is strictly increasing . * if @xmath796 and @xmath841 are such that @xmath912 , then for any @xmath913 we have @xmath914 .",
    "* suppose that for some @xmath915 , the row at index @xmath107 in @xmath826 is a linear combination of the rows of @xmath826 with indices in @xmath916 .",
    "then , writing @xmath917 , for every @xmath918 the row at index @xmath919 in @xmath826 is a linear combination of the rows of @xmath826 with indices in @xmath920 .",
    "the first item is clear since @xmath786 . for the second item",
    ", we consider two cases .",
    "first , if @xmath921 , this means @xmath922 from which we obviously obtain @xmath923 , and in particular @xmath914 .",
    "second , if @xmath924 , we must have @xmath925 by choice of @xmath795 , and then we also have @xmath926 with @xmath925 which implies that @xmath914 .",
    "the third item is a direct rewriting in the linearization framework of the following property .",
    "let @xmath176}^{{}\\times { } } } } [ { m}]_{{\\leqslant}{\\delta}}$ ] be an interpolant for @xmath46 with @xmath5-pivot index @xmath753 and @xmath5-row degree @xmath136 , and consider @xmath927 ; then the row vector @xmath928 , with entries of degree more than @xmath929 taken modulo the minimal polynomial of @xmath41 , is an interpolant for @xmath46 with @xmath5-pivot index @xmath753 and @xmath5-row degree @xmath930 .",
    "we remark that , when choosing a subset of @xmath931 linearly independent rows in @xmath826 , all other rows in the matrix are linear combinations of those . because our goal is to find relations which involve in priority the first rows of @xmath826 ,",
    "we are specifically interested in the _ first _ @xmath932 independent rows in @xmath826 .",
    "more precisely , we focus on the _ row rank profile _ @xmath933 of @xmath826 , that is , the lexicographically smallest tuple with entries in @xmath934 such that the submatrix of @xmath826 formed by the rows with indices in @xmath935 has rank @xmath936 .",
    "then , for each @xmath753 the row @xmath937 is a linear combination of the rows in @xmath938 .",
    "we now show that this row rank profile is directly related to the @xmath5-minimal degree of @xmath46 .",
    "[ lem : rank - profile ] let @xmath324 and @xmath909 $ ] , let @xmath117 , and let @xmath933 be the row rank profile of @xmath826",
    ". for @xmath939 , we write @xmath940 for some ( unique ) @xmath941 and @xmath942 . given @xmath943 ,    * for all @xmath944 we have @xmath945 , * @xmath946 if and only if @xmath947 for all @xmath948 , * if @xmath949 we have @xmath950 .",
    "let us fix @xmath828 .",
    "we recall that @xmath861 is the smallest exponent such that the row @xmath951 is a linear combination of the rows in @xmath866 .",
    "first , we assume that @xmath949 and we let @xmath952 . by definition of @xmath861 , the row at index @xmath797 in @xmath826 is linearly independent from the rows with smaller indices .",
    "thus , by minimality of the row rank profile , @xmath953 .    in particular , choosing @xmath954 , we obtain that @xmath955 , or in other words , there is some @xmath939 such that @xmath956 .",
    "this proves that if @xmath949 , then @xmath957 for some @xmath939 .",
    "now , we assume that @xmath946 and we show that @xmath958 for all @xmath959 .",
    "the definition of @xmath946 and the third item in together prove that for every @xmath960 , the row @xmath961 which is at index @xmath797 in @xmath826 is a linear combination of the rows with smaller indices .",
    "then , by minimality of the row rank profile , @xmath962 for all @xmath960 , and thus in particular @xmath963 for all @xmath964",
    ".    finally , we assume that @xmath949 and we show that @xmath965 . using the first item with @xmath966 ,",
    "there exists @xmath967 such that @xmath968 . as in the previous paragraph ,",
    "the definition of @xmath861 , the third item in , and the minimality of the row rank profile imply that @xmath969 for all @xmath970 ; in particular , @xmath963 for all @xmath939 such that @xmath971 . thus , we have @xmath972 .",
    "[ eg : mindeg ] in the context of ,    * for the uniform shift , the row rank profile of @xmath973 is @xmath974 with @xmath975 , @xmath976 , and @xmath977 : then , the @xmath115-minimal degree of @xmath759 is @xmath978 ; * for the shift @xmath979 , the row rank profile of @xmath751 is @xmath980 with @xmath981 , @xmath982 , and @xmath983 : the @xmath5-minimal degree of @xmath759 is @xmath984 ; * for the shift @xmath985 , the row rank profile of @xmath986 is @xmath980 with @xmath987 , @xmath988 , and @xmath989 : the @xmath328-minimal degree of @xmath759 is @xmath990 .",
    "in particular , the previous lemma implies a bound on the @xmath5-minimal degree of @xmath46 .",
    "since the minimal polynomial of the matrix @xmath324 is of degree at most @xmath715 , we have @xmath991 for @xmath992 : we actually have the following stronger identity , which shows that the sum of @xmath896 is at most @xmath1 .",
    "[ lem : sum - mindeg ] let @xmath324 and @xmath560 $ ] , and let @xmath117 .",
    "let @xmath863 be the @xmath5-minimal degree of @xmath46 .",
    "then , @xmath993 .    from",
    ", we see that one can partition the set @xmath935 as the disjoint union of the sets @xmath994 for each @xmath753 with @xmath949 .",
    "this union has cardinality @xmath995 , and the set @xmath935 has cardinality @xmath996 .",
    "[ rmk : sum_rdeg ] combining this with , one can directly deduce the following bound on the average row degree of minimal interpolation bases :    _ let @xmath324 and @xmath997 $ ] , and let @xmath117 .",
    "then , for any @xmath5-minimal interpolation basis @xmath95 for @xmath46 , the sum of the @xmath5-row degrees of @xmath95 satisfies @xmath998 .",
    "_    this bound has already been given before in ( * ? ? ? * theorem 7.3.(b ) ) , and also in the context of m - pad approximation ( * ? ? ?",
    "* theorem 4.1 ) , which includes order basis computation .",
    "this result is central regarding the cost of algorithms which compute shifted minimal interpolation bases since it gives a bound on the size of the output matrix . in particular",
    "it is a keystone for the efficiency of our divide - and - conquer algorithm in , where it gives a bound on the average row degree of all intermediate bases and thus allows fast computation of the product of bases ( ) , of the change of shift ( ) , and of the residuals ( ) .",
    "now , we show how to compute the row rank profile of @xmath826 efficiently . in the style of the algorithm of  @xcite ,",
    "our algorithm processes submatrices of @xmath826 containing all rows up to some degree , doubling this degree at each iteration .",
    "the structure property in allows us to always consider at most @xmath999 rows of @xmath826 , discarding most rows with indices not in @xmath935 without computing them .",
    "( there is one exception at the beginning , where the @xmath0 rows of @xmath49 are considered , with possibly @xmath0 much larger than @xmath932 . )",
    "this algorithm also returns the submatrix formed by the rows corresponding to the row rank profile , as well as the column rank profile of this submatrix , since they will both be useful later in .",
    "[ prop : algo - rank - profile ] is correct and uses @xmath1000 operations in @xmath8 if @xmath157 , and @xmath1001 operations if @xmath376 .",
    "the algorithm takes as input @xmath715 a power of @xmath337 : one can always ensure this by taking the next power of @xmath337 without impacting the cost bound .",
    "after steps  * 2 * ,  * 3 * , and  * 4 * , @xmath933 correspond to the indices in @xmath826 of the row rank profile of @xmath49 , and @xmath536 is the submatrix of @xmath826 formed by the rows with indices in @xmath935 . relying on the algorithm in  ( * ? ? ?",
    "* section 2.2 ) , step  * 2 * can be performed using @xmath1002 operations , and step  * 6 * can be computed using @xmath1003 operations ( where the logarithmic terms account for the possibility that @xmath376 ) .",
    "the loop performs @xmath719 iterations . in each iteration @xmath1004 , since the matrix @xmath536 has @xmath1 columns and has at most @xmath999 rows with @xmath1005 , one can compute the square @xmath1006 and the product @xmath1007 using @xmath1008 operations , and the row rank profile of @xmath536 using @xmath1009 operations  ( * ? ? ?",
    "* section 2.2 ) .",
    "thus , overall , the for loop uses @xmath1010 operations if @xmath157 , and @xmath1011 operations if @xmath376 . adding these costs leads to the announced bound .",
    "let us now prove the correctness of the algorithm .",
    "for each @xmath1012 let @xmath1013 denote the set of indices of rows of @xmath826 which correspond to degrees less than @xmath1014 , and let @xmath1015 be the submatrix of @xmath826 formed by the rows with indices in @xmath1016 , that is , the submatrix @xmath1015 of @xmath826 which is a row permutation of the matrix @xmath1017 \\in { \\renewcommand{}{(2^{\\ell}-1){m}}{{\\mathbb{k}}^{{}\\times { } } } } [ { \\sigma}];\\ ] ] for ease of presentation , we continue to index the rows of @xmath1015 with @xmath1016 . now",
    ", suppose that at the beginning of the iteration @xmath1004 of the loop , @xmath933 is the row rank profile of @xmath1015 , and @xmath536 is the submatrix of @xmath826 formed by the rows with indices in @xmath935 .",
    "then , we claim that at the end of this iteration , @xmath1018 is the row rank profile of @xmath1019 ; it is then obvious that the updated matrix @xmath536 , after step  * 5.g * , is the corresponding submatrix of @xmath826 .",
    "first , the indices @xmath1020 computed at step  * b * are in @xmath1021 , which is the set of indices of the rows of @xmath1022 in the matrix @xmath826 ( or in the matrix @xmath1019 since we chose to keep the same indexing ) . from , we know that if two indices @xmath1023 are in @xmath1016 , then we also have @xmath1024 in @xmath1021 .",
    "this means that @xmath1025 is not only formed by the rows of @xmath1019 with indices in @xmath1021 : it is actually the submatrix of @xmath1019 formed by these rows , keeping the same row order .    in particular , for a given @xmath1026 , if the row @xmath231 of @xmath1015 is a linear combination of the rows of this matrix with smaller indices , then the same property holds in the matrix @xmath1019 ; and similarly if the row @xmath1027 of @xmath1022 is a linear combination of the rows of this matrix with smaller indices , then the same holds in @xmath1019 .",
    "another consequence is that the sequence @xmath1020 defined in step  * 5.b * is strictly increasing , as stated in step  * 5.c * ; besides , it does not share any common element with @xmath933 , so that their merge @xmath1028 in step  * 5.c * is unique and strictly increasing ) .",
    "now , since the row rank profile of @xmath1022 is a subsequence of the row rank profile of @xmath1015 , the row rank profile of the submatrix of @xmath1019 formed by the rows in @xmath1021 is a subsequence of @xmath1020 .",
    "thus , if @xmath231 is an index in @xmath1029 , then the row @xmath231 of @xmath1019 is a linear combination of the rows with smaller indices , and thus @xmath231 will not appear in the row rank profile of @xmath1019 .",
    "thus , the row rank profile of @xmath1019 , that is , of the submatrix of @xmath826 formed by the rows in @xmath1030 , is a subsequence of @xmath1028 .",
    "this justifies that in steps  * 5.e * and  * 5.f * one may only focus on the rows with indices in @xmath1031 .",
    "the conclusion follows .      as noted in , an @xmath5-minimal interpolation basis for @xmath46",
    "can be retrieved from linear relations which express the rows of @xmath826 of indices @xmath1032 as combinations of the rows with smaller indices . concerning the latter rows",
    ", one can for example restrict to those given by the row rank profile @xmath933 : thus , one can build an interpolation basis by considering only @xmath1033 rows in @xmath826 . in many useful cases ,",
    "@xmath1034 is significantly smaller than the total number of rows @xmath814 in the matrix .",
    "[ dfn : pivot - target ] let @xmath324 and @xmath560 $ ] , and let @xmath117 .",
    "then @xmath1035 $ ] is the submatrix of @xmath826 formed by its rows with indices in @xmath1036 , and @xmath1037 $ ] is the submatrix of @xmath826 formed by the rows with indices in @xmath1038 .",
    "the matrix @xmath1039 $ ] can be thought of as a _",
    "pivot _ matrix ,",
    "since its rows are used as pivots to find relations through the elimination of the rows in @xmath1040 $ ] , which we therefore think of as the _ target _ matrix . from , we know that these relations correspond to an interpolation basis @xmath95 in @xmath5-weak popov form .",
    "it turns out that restricting our view of @xmath826 to the submatrix @xmath1041 leads to find such relations with a minimal number of coefficients , which corresponds to a stronger type of minimality : @xmath95 is in @xmath5-popov form  @xcite .",
    "[ dfn : popov ] let @xmath477}^{{}\\times { } } } } $ ] have full rank , and let @xmath5 in @xmath882 .",
    "then , @xmath19 is said to be in _",
    "@xmath5-popov form _ if the @xmath5-pivot entries are monic and on the diagonal of @xmath19 , and in each column of @xmath19 the nonpivot entries have degree less than the pivot entry .",
    "a matrix in @xmath5-popov form is in particular in @xmath5-weak popov form and @xmath5-reduced ; besides , this is a normal form in the sense that , for a given @xmath1042}^{{}\\times { } } } } $ ] with full rank and a given shift @xmath5 , there is a unique matrix @xmath19 in @xmath5-popov form which is unimodularly equivalent to @xmath119 . in particular , given @xmath46 , for each shift @xmath5 there is a unique ( @xmath5-minimal ) interpolation basis for @xmath46 which is in @xmath5-popov form .",
    "since all rows in @xmath826 are linear combinations of those in the submatrix @xmath1041 , there is an @xmath1043 matrix @xmath1044 such that @xmath1045 , which we think of as the _ relation _ matrix ; besides , since the pivot matrix has full rank , this defines @xmath1044 uniquely",
    ". then , the linear relations that we are looking for are @xmath1046 $ ] , and they can be computed for example using gaussian elimination on the rows of @xmath1047 ^\\mathsf{t}}$ ] .",
    "more precisely , @xmath1046 $ ] is the set of columns with indices in @xmath1048 of the relations that we are looking for between the rows of @xmath826 , and the interpolation basis in @xmath5-popov form is the compression of these relations . generally , given a matrix @xmath1049 in @xmath1050 $ ] for some @xmath740 , we see it as formed by the columns with indices @xmath1051 ( in this order ) of a matrix @xmath1052 in @xmath1053 $ ] which has other columns zero .",
    "then , the compression of @xmath1049 is the compression @xmath1054 of @xmath1052 as defined in ; we abusively denote it @xmath1055 since there will be no ambiguity .",
    "[ lem : lin - mib ] let @xmath324 and @xmath560 $ ] , and let @xmath117 .",
    "let @xmath1035 $ ] and @xmath1040 $ ] be as in , and let @xmath1044 be the unique matrix in @xmath1056 $ ] such that @xmath1057 .",
    "then , @xmath1058 ) } \\ ] ] is an interpolation basis for @xmath46 in @xmath5-popov form .    besides",
    ", if @xmath1059 denotes the column rank profile of @xmath1041 , and @xmath1060 and @xmath1061 $ ] are the submatrices of @xmath1041 and @xmath1062 , respectively , formed by the columns with indices in @xmath1063 , then we have @xmath1064    first , restricting the identity @xmath1045 to the submatrices with column indices in @xmath1063 we have in particular @xmath1065 . by construction",
    ", @xmath1066 is invertible and thus @xmath1067 .",
    "let @xmath1068 $ ] be the matrix whose columns at indices @xmath1069,@xmath1070,@xmath1071 , @xmath1072 , @xmath1070 , @xmath1073 are the columns @xmath1074 of @xmath1075 $ ] , respectively , and other columns are zero ; let also latexmath:[${{\\mathbf{\\makeuppercase{p}}}}= { \\mathcal{c}_{{\\mathbf{s } } } ( [ -{\\mathcal{r}_{{\\mathbf{s}}}({{\\mathbf{\\makeuppercase{e } } } } ) }    by construction , every row @xmath753 of @xmath95 is the compression @xmath1077 of a linear relation between the rows of @xmath826 and is thus an interpolant for @xmath46 .",
    "we will further prove that @xmath95 is in @xmath5-popov form with @xmath5-pivot degree @xmath863 ; in particular , this implies that @xmath95 is @xmath5-reduced and has @xmath5-row degree @xmath1078 , so that shows that @xmath95 is an interpolation basis for @xmath46 . for @xmath939 , we write @xmath1079 for some unique @xmath1080 .",
    "we fix @xmath1081 .",
    "first , we consider the column @xmath753 of @xmath95 and we show that all its entries have degree less than @xmath861 except the entry on the diagonal , which is monic and has degree exactly @xmath861 . indeed , for any @xmath231 such that @xmath1082 , by definition of @xmath1083 the column @xmath1084 of @xmath493 is compressed into the coefficient of degree @xmath1085 in the column @xmath753 of @xmath95 , and by we know that @xmath1086 . besides , the column of @xmath493 at index @xmath878 , which has all its entries @xmath573 except the entry on row @xmath753 which is @xmath153 , only brings a coefficient @xmath153 of degree @xmath861 in the diagonal entry @xmath1087 of @xmath95 .",
    "second , we consider the row @xmath753 of @xmath95 and we show that it has @xmath5-pivot index @xmath753 and @xmath5-pivot degree @xmath861 .",
    "thanks to , it is enough to show that the rightmost nonzero entry in the row @xmath753 of @xmath493 is the entry @xmath153 at column index @xmath878 .",
    "all entries in the row @xmath753 of @xmath493 with indices greater than @xmath878 and not in @xmath935 are obviously zero .",
    "now , by definition of @xmath861 , we know that the row of @xmath826 at index @xmath878 is a linear combination of the rows at indices smaller than @xmath878 ; in particular , because the rows of @xmath826 at indices @xmath1088 are linearly independent , the linear combination given by the row @xmath753 of @xmath493 has entries @xmath573 on the columns at indices @xmath1084 for @xmath231 such that @xmath1089 .",
    "now , we turn to the fast computation of an interpolation basis @xmath95 for @xmath46 in @xmath5-popov form . in view of what precedes ,",
    "this boils down to two steps , detailed in : first , we compute the row rank profile @xmath933 of @xmath826 from which we also deduce the @xmath5-minimal degree @xmath863 , and second , we compute the linear relations @xmath1090 .",
    "we now prove , by showing that is correct and uses @xmath1091 operations in @xmath8 if @xmath157 , and @xmath1092 operations if @xmath376 .",
    "the correctness follows from and from the correctness of the algorithm krylovrankprofile .",
    "since @xmath1093 , the computation of @xmath1094 at step  * 7 * uses @xmath1095 operations , and the computation of @xmath1096 uses @xmath1008 operations when @xmath553 , and @xmath1097 operations when @xmath152 . then , the announced cost bound follows from .",
    "we thank b. beckermann , e. kaltofen , g. labahn , and e. tsigaridas for useful discussions .",
    "we also thank the reviewers for their thorough reading and helpful comments .",
    "jeannerod and g. villard were partly supported by the anr hpac project ( anr 11 bs02 013 ) .",
    "v. neiger was supported by the international mobility grants from _ projet avenir lyon saint - tienne _ , _ mitacs globalink - inria _ , and explora doc from _ rgion rhne - alpes_.  .",
    "schost was supported by nserc and by the canada research chairs program .",
    "in this appendix , we give upper bounds for the quantities in .",
    "[ lem : polmatmul - bound ] we have the upper bounds @xmath1098    it is enough to show these bounds for @xmath0 and @xmath136 powers of @xmath337 .",
    "the bound on @xmath1099 follows from the super - linearity property @xmath1100 .    using the super - linearity property @xmath1101",
    ", we obtain @xmath1102 .",
    "this concludes the proof since we have @xmath1103 , where the logarithmic term accounts for the possibility that @xmath376 .",
    "[ lem : polmatmuldnc - bound ] we have the upper bounds @xmath1104    it is enough to show these bounds for @xmath0 and @xmath136 powers of @xmath337 .",
    "the first two bounds are obtained from , which implies that @xmath1105 and from the fact that @xmath1106 is upper bounded by a constant if @xmath157 .",
    "now , we focus on the last two bounds . by definition ,",
    "@xmath1107 in the inner sum , @xmath17 goes from @xmath573 to @xmath1108 : we will separately study the first terms with @xmath1109 and the remaining terms with @xmath1110 .    first ,",
    "using the super - linearity property @xmath1111 , we obtain @xmath1112 since when @xmath157 , the sum @xmath1113 is known to be less than its limit @xmath1114 when @xmath1115 .",
    "we note that the second term @xmath1116 accounts for the possibility that @xmath376 .",
    "then , using the super - linearity property @xmath1117 when @xmath1110 , we obtain @xmath1118 which concludes the proof .",
    "[ lem : polmatmuldoublednc - bound ] let @xmath340 denote the power of @xmath337 such that @xmath1119 ; we have the upper bounds @xmath1120    it is enough to show these bounds for @xmath0 and @xmath136 powers of @xmath337 ; in particular , @xmath1121 .",
    "let us study the first two bounds . by definition ,",
    "@xmath1122 considering the terms with @xmath1123 , we use @xmath1124 to obtain @xmath1125 from which we conclude since the sum @xmath1126 is @xmath1127 if @xmath157 , and @xmath1128 if @xmath376 .",
    "now , considering the terms with @xmath1129 , we use @xmath1130 to obtain @xmath1131 where again the sum on @xmath17 and @xmath231 is @xmath1127 if @xmath157 , and @xmath1132 if @xmath376 .    then , we study the last two bounds . by definition , @xmath1133 considering the terms with @xmath1134",
    ", we use @xmath1135 to obtain @xmath1136 this is @xmath1137 if @xmath157 and @xmath1138 if @xmath376 .",
    "now , considering the terms with @xmath1139 , and thus also @xmath1140 , we use @xmath1141 to obtain @xmath1142 this gives the conclusion , since @xmath1143 is @xmath1127 if @xmath157 and @xmath1128 if @xmath376 .",
    "here , we give a detailed cost analysis for the minimal nullspace basis algorithm of @xcite , which we rewrite in using our convention here that basis vectors are rows of the basis matrix ( whereas in the above reference they are its columns ) .",
    "furthermore , we assume that the input matrix has full rank , which allows us to better control the dimensions of the matrices encountered in the computations : in the recursive calls , we always have input matrices with more rows than columns .    here",
    ", the quantity @xmath1144 arises in the cost analysis of fast algorithms for the computation of hermite - pad approximants  @xcite , which use a divide - and - conquer approach on the degree @xmath136 .",
    "the minimal nullspace basis algorithm in  @xcite follows a divide - and - conquer approach on the dimension of the input matrix , and computes at each node of the recursion some products of matrices with unbalanced row degrees as well as a minimal basis of hermite - pad approximants . in particular",
    ", its cost will be expressed using the quantities @xmath1145 and @xmath1146 introduced in .",
    "[ prop : cost - mnb ] let @xmath166 in @xmath167}^{{}\\times { } } } } [ { n}]$ ] have full rank with @xmath1147 , and let @xmath5 in @xmath882 which bounds the row degree of @xmath166 componentwise .",
    "let @xmath426 be an integer such that @xmath1148 .",
    "assuming that @xmath1149 , computes an @xmath5-minimal nullspace basis of @xmath166 using @xmath1150 operations in @xmath8 .",
    "step  * 2 * : using the algorithm ` pm - basis ` in  @xcite , @xmath19 can be computed using @xmath1153 operations in @xmath8 ; see ( * ? ? ?",
    "* theorem  2.4 ) . since @xmath1154 and @xmath1149",
    ", this step uses @xmath1155 operations . besides , from on the sum of the @xmath5-row degrees of an @xmath5-minimal interpolation basis , we have @xmath1156 .",
    "step  * 3 * : finding @xmath1157 and @xmath1158 can be done by computing @xmath1159 .",
    "the matrix @xmath166 is @xmath190 with row degree @xmath1160 ( componentwise ) ; in particular , @xmath1161 . besides",
    ", @xmath19 is an @xmath29 matrix and @xmath1162 .",
    "then , one can augment @xmath166 with @xmath1163 zero columns and use to compute @xmath1159 ; according to , this uses @xmath1164 operations",
    ".    steps  * 5.a * and * 5.b * : computing @xmath1165 involves no arithmetic operation since the product @xmath1159 has already been computed in step  * 3 * ; @xmath1165 has row degree bounded by @xmath328 ( componentwise ) .",
    "let us denote @xmath1166 the number of rows of @xmath1158 .",
    "because both @xmath19 and @xmath166 have full rank and @xmath1167 , @xmath1165 has full rank and at least @xmath52 rows in @xmath19 are not in the nullspace of @xmath166 , which means @xmath1168 . furthermore , according to  ( * ? ? ?",
    "* theorem  3.6 ) , we have @xmath1169 .",
    "then , @xmath1165 is an @xmath1170 matrix with @xmath1171 and with row degree bounded by @xmath328 .",
    "in addition , we have @xmath1172 ( * ? ? ? * lemma  3.12 ) , and thus in particular @xmath1173 .",
    "step  * 5.c * : for the recursive calls of steps  * 5.d * and  * 5.e * , we will need to check that our assumptions on the dimensions , the degrees , and the rank of the input are maintained . here",
    ", we first remark that @xmath1174 and @xmath1175 have full rank and respective dimensions @xmath1176 and @xmath1177 , with @xmath1178 .",
    "their row degrees are bounded by @xmath328 , which is in non - decreasing order and satisfies @xmath1179 .",
    "step  * 5.d * : @xmath1180 is a @xmath328-minimal nullspace basis of  @xmath1174 and therefore it has @xmath1181 rows and @xmath1166 columns .",
    "besides , @xmath1182 and by  ( * ? ? ? * theorem  3.4 ) , we have @xmath1183 .",
    "step  * 5.e * : we remark that @xmath1184 has @xmath1185 columns and @xmath1186 rows .",
    "we now show that it has full rank .",
    "let us consider @xmath1187 any @xmath535-minimal nullspace basis of @xmath1188 .",
    "then @xmath1187 has @xmath1189 rows , where @xmath932 is the rank of @xmath1184 .",
    "our goal is to prove that @xmath1190 .",
    "the matrix @xmath1191^\\mathsf{t}}$ ] is an @xmath5-minimal nullspace basis of @xmath166 ( * ? ? ?",
    "* theorems 3.9 and 3.15 ) . in particular , since @xmath166 has full rank , @xmath1192 has @xmath1163 rows .",
    "since @xmath1157 has @xmath1193 rows , this gives @xmath1194 .",
    "thus @xmath1195 , and @xmath1196 .    furthermore , @xmath1175 has row degree bounded by @xmath328 and @xmath1180 has @xmath328-row degree exactly @xmath535 , so that @xmath1197 .",
    "we have @xmath1173 and @xmath1198 . augmenting @xmath1180 and @xmath1175 so that they are @xmath1199 , by",
    ", @xmath1184 can be computed using @xmath1200 operations .",
    "then , @xmath1201 is a @xmath328-minimal nullspace basis of  @xmath1184 ; it has @xmath1202 rows and @xmath1203 columns , its @xmath535-row degree is @xmath1204 , and we have @xmath1205  ( * ? ? ?",
    "* theorem  3.4 ) .",
    "step  * 5.f * : using the previously given dimensions and degree bounds for @xmath1180 and @xmath1201 , one can easily check that the product @xmath1206 can be computed by using @xmath1207 operations .",
    "now , @xmath1158 is @xmath1208 with @xmath1209 , and denoting @xmath1210 , @xmath1158 has its row degree bounded by @xmath1211 , with @xmath1212 . besides , @xmath1213 .",
    "then , the product @xmath1214 can be computed with using @xmath1215 operations , since @xmath1216 and @xmath1168 .",
    "thus , we have two recursive calls with half the column dimension and the same bound @xmath402 , and additional @xmath1217 operations for the matrix products and the computation of a minimal basis of hermite - pad approximants . overall uses @xmath1218 operations : since @xmath1219 , we obtain the announced cost estimate ; the upper bound is a direct consequence of .",
    "beckermann , b. , labahn , g. , jul . 1994 . a uniform approach for the fast computation of matrix - type pad approximants .",
    "siam j. matrix anal .",
    "appl . 15",
    "( 3 ) , 804823 .",
    "http://dx.doi.org/10.1137/s0895479892230031          beelen , t. g.  j. , van  den hurk , g.  j. , praagman , c. , 1988 .",
    "a new method for computing a column reduced polynomial matrix .",
    "systems and control letters 10  ( 4 ) , 217224 .",
    "http://dx.doi.org/10.1016/0167-6911(88)90010-2          brent , r.  p. , gustavson , f.  g. , yun , d. y.  y. , 1980 . fast solution of toeplitz systems of equations and computation of pad approximants .",
    "j. of algorithms 1  ( 3 ) , 259295 .",
    "http://dx.doi.org/10.1016/0196-6774(80)90013-9        chowdhury , m. , jeannerod , c .- p .",
    ", neiger , v. , schost , e. , villard , g. , 2015 .",
    "faster algorithms for multivariate interpolation with multiplicities and simultaneous polynomial approximations .",
    "ieee trans .",
    "theory 61  ( 5 ) , 23702387 .",
    "http://dx.doi.org/10.1109/tit.2015.2416068    cohn , h. , heninger , n. , 2012 - 2013 .",
    "approximate common divisors via lattices . in : tenth algorithmic number theory symposium .",
    "mathematical sciences publishers ( msp ) , pp .",
    "http://dx.doi.org/10.2140/obs.2013.1.271                gupta , s. , sarkar , s. , storjohann , a. , valeriote , j. , 2012 .",
    "triangular @xmath584-basis decompositions and derandomization of linear algebra algorithms over @xmath1220 $ ] .",
    "j. symbolic comput .",
    "47  ( 4 ) , 422453 .",
    "http://dx.doi.org/10.1016/j.jsc.2011.09.006    guruswami , v. , rudra , a. , 2008 .",
    "explicit codes achieving list decoding capacity : error - correction with optimal redundancy .",
    "ieee trans .",
    "theory 54  ( 1 ) , 135150 . http://dx.doi.org/10.1109/tit.2007.911222                        lee , k. , osullivan , m. , july 2006 .",
    "an interpolation algorithm using grbner bases for soft - decision decoding of reed - solomon codes . in : 2006 ieee international symposium on information theory .",
    ". 20322036 .",
    "http://dx.doi.org/10.1109/isit.2006.261906      lbbe , w. , 1983 .",
    "ber ein allgemeines interpolationsproblem  lineare identitten zwischen benachbarten lsungssystemen .",
    "thesis , department of applied mathematics , university of hannover , germany .",
    "nielsen , r.  r. , hholdt , t. , 2000 .",
    "decoding reed - solomon codes beyond half the minimum distance . in : coding theory ,",
    "cryptography and related areas .",
    "springer , pp .",
    "http://dx.doi.org/10.1007/978-3-642-57189-3_20                              zeh , a. , gentner , c. , augot , d. , 2011 .",
    "an interpolation procedure for list decoding reed - solomon codes based on generalized key equations .",
    "ieee trans .",
    "theory 57  ( 9 ) , 59465959 ."
  ],
  "abstract_text": [
    "<S> we consider the problem of computing univariate polynomial matrices over a field that represent minimal solution bases for a general interpolation problem , some forms of which are the _ vector m - pad approximation problem _ in [ van barel and bultheel , numerical algorithms 3 , 1992 ] and the _ rational interpolation problem _ in [ beckermann and labahn , siam j. matrix anal . </S>",
    "<S> appl . </S>",
    "<S> 22 , 2000 ] . </S>",
    "<S> particular instances of this problem include the bivariate interpolation steps of guruswami - sudan hard - decision and ktter - vardy soft - decision decodings of reed - solomon codes , the multivariate interpolation step of list - decoding of folded reed - solomon codes , and hermite - pad approximation .    in the mentioned references , </S>",
    "<S> the problem is solved using iterative algorithms based on recurrence relations . here , we discuss a fast , divide - and - conquer version of this recurrence , taking advantage of fast matrix computations over the scalars and over the polynomials . </S>",
    "<S> this new algorithm is deterministic , and for computing shifted minimal bases of relations between @xmath0 vectors of size @xmath1 it uses @xmath2 field operations , where @xmath3 is the exponent of matrix multiplication , and @xmath4 is the sum of the entries of the input shift @xmath5 , with @xmath6 . </S>",
    "<S> this complexity bound improves in particular on earlier algorithms in the case of bivariate interpolation for soft decoding , while matching fastest existing algorithms for simultaneous hermite - pad approximation .    </S>",
    "<S> m - pad approximation ; hermite - pad approximation ; polynomial interpolation ; order basis ; polynomial matrix . </S>"
  ]
}