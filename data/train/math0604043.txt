{
  "article_text": [
    "the linear transformation model states that a continuous outcome @xmath2 , given a @xmath3-dimensional covariate vector @xmath4 , has the form @xmath5 where @xmath6 is an increasing , unknown transformation function , @xmath7 are the unknown regression parameters of interest , and @xmath8 has a known distribution @xmath9 .",
    "this model is readily applied to a failure time @xmath10 by letting @xmath11 and @xmath12 , where @xmath13 is an unspecified integrated baseline hazard . setting @xmath14 results in the cox model , while setting @xmath15 results in the proportional odds model .",
    "more generally , the transformation model for a survival time @xmath10 conditionally on a time - dependent covariate @xmath16 , takes the form @xmath17}=s_z(t)&\\equiv&\\lambda\\left(\\int_0^te^{\\beta'z(s ) } da(s)\\right),\\label{new.e1}\\end{aligned}\\ ] ] where @xmath18 is a known decreasing function with @xmath19 .",
    "the model  ( [ new.e1 ] ) becomes model  ( [ s1.e1 ] ) when the covariates are time - independent and @xmath20 .    in data analysis ,",
    "the assumption of linearity of the regression effect in  ( [ new.e1 ] ) is not always satisfied over the whole range of the covariate , and the fit may be improved with a two - phase transformation model having a change - point at an unknown threshold of a one - dimensional covariate @xmath21 .",
    "let @xmath22 , where @xmath23 and @xmath24 are possibly time - dependent covariates in @xmath25 and @xmath26 , respectively , where @xmath27 and @xmath28 .",
    "the new model is obtained by replacing @xmath29 in  ( [ new.e1 ] ) with @xmath30{\\mbox{\\large\\bf 1}}\\{y > \\zeta\\},\\label{new.e2}\\end{aligned}\\ ] ] where @xmath31 is a scalar , @xmath32 , @xmath33 is the indicator of @xmath34 , and @xmath35 denotes the collected parameters @xmath36 .",
    "we also require @xmath21 to be time - independent but allow it to possibly be one of the covariates in @xmath37 .",
    "the overall goal of this paper is to develop methods of inference for this model applied to right censored data .",
    "we note that for the special case when @xmath38 and @xmath39 , the model  ( [ new.e2 ] ) becomes the cox model considered by @xcite under a slightly different parameterization . permitting a nonzero @xmath31",
    "allows the possibility of a `` bent - line '' covariate effect .",
    "suppose , for example , that @xmath24 is one - dimensional and time - independent , while @xmath40 may be time - dependent . if we set @xmath41 and @xmath42 , where @xmath43 and @xmath44 , the model  ( [ new.e2 ] ) becomes @xmath45 .",
    "when @xmath46 , the covariate effect for @xmath24 consists of two connected linear segments .",
    "in many biological settings , such a bent - line effect is realistic and can be much easier to interpret than a quadratic or more complex nonlinear effect @xcite . hence including the intercept term @xmath31 is useful for applications .",
    "linear transformation models of the form  ( [ s1.e1 ] ) have been widely used and studied ( see , for example , @xcite ) .",
    "efficient methods of estimation in the uncensored setting were rigorously studied by @xcite , among others .",
    "the model  ( [ new.e1 ] ) for right - censored data has also been studied rigorously for a variety of specific choices of @xmath18 @xcite ; for general but known @xmath18 @xcite ; and for certain parameterized families of @xmath18 @xcite .",
    "change - point models have also been studied extensively and have proven to be popular in clinical research .",
    "several researchers have considered a nonregular cox model involving a two - phase regression on time - dependent covariates , with a change - point at an unknown time @xcite .",
    "as mentioned above , @xcite considered the cox model with a change - point at an unknown threshold of a covariate .",
    "these authors studied the maximum partial likelihood estimators of the parameters and the estimator of the baseline hazard function .",
    "they show that the estimator of the threshold parameter is @xmath1-consistent , while the regression parameters are @xmath47-consistent .",
    "this happens because the likelihood function is not differentiable with respect to the threshold parameter , and hence the usual taylor expansion is not available . in this paper",
    ", we focus on the covariate threshold setting .",
    "while time threshold models are also interesting , we will not pursue them further in this paper because the underlying techniques for estimation and inference are quite distinct from the covariate threshold setting .",
    "the contribution of our paper builds on @xcite in three important ways .",
    "firstly , we extend to general transformation models .",
    "this results in a significant increase in complexity over the cox model since estimation of the baseline hazard can no longer be avoided through the use of the partial - profile likelihood .",
    "secondly , we study nonparametric maximum likelihood inference for all model parameters . as part of this",
    ", we show that the estimation procedure is adaptive in the sense that the non - threshold parameters  including the infinite - dimensional parameter  @xmath13are estimable with the same precision as if the true threshold parameter were known .",
    "thirdly , we develop hypothesis tests for the existence of a change - point .",
    "this is quite challenging since some of the model parameters are no longer identifiable under the null hypothesis of no change - point .",
    "@xcite considers similar nonstandard testing problems when the model is fully parametric and establishes asymptotic null and local alternative distributions of a number of likelihood - based test procedures .",
    "unfortunately , andrews results are not directly applicable to our setting because of the presence of an infinite dimensional nuisance parameter , the baseline integrated hazard @xmath13 , and new methods are required .",
    "the next section , section  2 , presents the data and model assumptions .",
    "the nonparametric maximum log - likelihood estimation ( npmle ) procedure is presented in section  3 . in section  4",
    ", we establish the consistency of the estimators .",
    "score and information operators of the regular parameters are given in section  5 .",
    "results on the convergence rates of the estimators are established in section  6 .",
    "section  7 presents weak convergence results for the estimators , including the asymptotic distribution of the change - point estimator and the asymptotic normality of the other parameters .",
    "this section also establishes the adaptive semiparametric efficiency mentioned above .",
    "monte carlo inference for the parameters is discussed in section  8 .",
    "methods for testing the existence of a change - point are then presented in section  9 . a brief discussion on implementation and a small simulation study evaluating the moderate sample size performance of the proposed change - point tests are given in section  10 .",
    "proofs are given in section  11 .",
    "the data @xmath48 @xmath49 , @xmath50 , consists of @xmath1 i.i.d . realizations of @xmath51 , where @xmath52 , @xmath53 , and @xmath54 is a right censoring time .",
    "the analysis is restricted to the interval @xmath55 $ ] , where @xmath56 .",
    "the covariate @xmath57 and @xmath58 \\}$ ] is assumed to be a caglad ( left - continuous with right - hand limits ) process with @xmath59 , for all @xmath60 $ ] , where @xmath28 but @xmath61 is allowed .",
    "we assume that conditionally on @xmath4 and @xmath21 , the survival function at time @xmath62 has the form : @xmath63 where @xmath18 is a known , thrice differentiable decreasing function with @xmath19 , @xmath64 is as defined in  ( [ new.e2 ] ) , and @xmath13 is an unknown increasing function restricted to @xmath65 $ ] .",
    "let @xmath66 , and define the derivatives @xmath67 , @xmath68 , @xmath69 , @xmath70 , and @xmath71 .",
    "we also define the collected parameters @xmath72 , @xmath73 , and @xmath74 .",
    "we use @xmath75 to denote the true probability measure , while the true parameter values are indicated with a subscript 0 .",
    "we now make the following additional assumptions :    * : @xmath76=0 $ ] , @xmath77 = p[c = \\tau | z , y ] > 0 $ ] almost surely , and censoring is independent of @xmath10 given @xmath78 and uninformative . * : the total variation of @xmath79 on @xmath55 $ ] is @xmath80 almost surely . * : @xmath81 , for some known @xmath82 with @xmath83>0 $ ] and @xmath84>0 $ ] . * : for some neighborhood @xmath85 of @xmath86 : * * the density of @xmath21 , @xmath87 , exists and is strictly positive , bounded and continuous for all @xmath88 ; and * * the conditional law of @xmath89 given @xmath90 , @xmath91 , is left - continuous with right - hand limits over @xmath85 . * : for some @xmath92 $ ] , both var@xmath93 $ ] and var@xmath94 $ ] are positive definite . * : for some @xmath95 $ ] , both var@xmath96 $ ] and var@xmath97 $ ] are positive definite . * : @xmath98 , @xmath99 , @xmath100 , where @xmath101 , and @xmath102 , @xmath103 and @xmath104 are open , convex , bounded and known . * : either @xmath105 or @xmath106 . * : @xmath107 , where @xmath108 is the set of all increasing functions @xmath109\\mapsto[0,\\infty)$ ] with @xmath110 and @xmath111 ; and @xmath112 has derivative @xmath113 satisfying @xmath114 for all @xmath115 $ ] . * : @xmath116 is thrice continuously differentiable , with @xmath117 , and , for each @xmath118 , @xmath119 and @xmath120}|\\dddot g(s)|<\\infty$ ] . * : for some @xmath121 , both @xmath122 and @xmath123 .",
    "conditions  a1 , a2 , c1 and  c3 are commonly used for npmle consistency and identifiability in right - censored transformation models , while conditions  b1 , b2 , b3 and  c2 are needed for change - point identifiability . as pointed out by a referee",
    ", the use of a time - dependent covariate will require that @xmath124 be observed for each individual @xmath125 and for every @xmath126 such that @xmath127 and @xmath128 . while this is often assumed in theoretical contexts",
    ", it can be unrealistic in practice , where missing values of @xmath129 are not unusual ( see @xcite ) .",
    "frequently , data analysts will simply carry the last observation of @xmath129 forward to avoid the missingness problem .",
    "unfortunately , this simple solution is not necessarily valid .",
    "however , addressing this issue thoroughly is beyond the scope of this paper , and we will only mention it again briefly in section  9 , where we develop a test of the null hypothesis that there is no change - point ( @xmath130 and @xmath131 ) . also in section  9 , we will relax condition  c2 to allow for a sequence of contiguous alternative hypotheses that includes @xmath132 .",
    "condition  b2(ii ) is also needed to obtain weak convergence for the npmle of @xmath86 .",
    "the continuity requirements at each point @xmath133 can be restated in the following way : @xmath134 converges weakly to @xmath91 , as @xmath135 ; and @xmath134 converges weakly to @xmath136 , as @xmath137 , for some law @xmath136 .",
    "it would require a fairly pathological relationship among the variables @xmath138 for this not to hold .",
    "condition  b4 will also be needed for the change - point test developed in section  9 .",
    "conditions  d1 and  d2 are also needed for asymptotic normality .",
    "d1  is quite similar to conditions  ( g.1 ) through  ( g.4 ) in @xcite who use the condition for developing asymptotic theory for transformation models without a change - point .",
    "condition  d2 is slightly weaker than conditions  d2 and  d3 of @xcite who use the condition to obtain asymptotic theory for frailty regression models without a change - point .",
    "the following are several instances that satisfy conditions  d1 and d2 :    1 .",
    "@xmath139 corresponds to the extreme value distribution and results in the cox model .",
    "2 .   @xmath140 , for any @xmath141 , corresponds to the family of log - pareto distributions and results in the odds - rate transformation family . taking the limit as @xmath142 yields the cox model , while @xmath143 yields the proportional odds model .",
    "3 .   @xmath144}$ ] , where @xmath145 is a positive frailty with @xmath146}<\\infty$ ] , for some @xmath147 , and @xmath148}<\\infty$ ] , corresponds to the family of frailty transformations .",
    "in addition to the odds - rate family , these conditions are satisfied by both the inverse gaussian and log - normal families ( see @xcite ) , as well as many other frailty families .",
    "@xmath149^{-1}$ ] , where @xmath150 .",
    "because this is the laplace transform of @xmath151 @xmath152 , it is not the laplace transform of a density .",
    "hence this family is not a member of the family of frailty transformations .",
    "note , however , that taking the limit as @xmath153 results in the laplace transform of the frailty density @xmath154 .",
    "verification of these conditions is routine for examples  1 , 2 and  4 above , but verification for example  3 is slightly more involved :    [ l.v1 ] conditions  d1 and  d2 are satisfied for example  3 above .",
    "the nonparametric log - likelihood has the form @xmath155 @xmath156 where @xmath157 dn(s)-g(h^{\\psi}_1(v)),\\\\ l_2^{\\psi}(v,\\delta , z ) & \\equiv&\\int_0^{\\tau}\\left[\\log\\dot{g}\\left(h^{\\psi}_2(s ) \\right)+\\beta'z(s)+\\alpha+\\eta'z_2(s)\\right]dn(s)\\\\ & & -g(h^{\\psi}_2(v)),\\end{aligned}\\ ] ] where @xmath158 , @xmath159 , @xmath160 , @xmath161 , @xmath162 , and @xmath163 is the empirical probability measure .    as discussed by @xcite , the maximum likelihood estimator for @xmath164 does not exist , since any unrestricted maximizer of  ( [ s3.e1 ] ) puts mass only at observed failure times and is thus not a continuous hazard .",
    "we replace @xmath165 in @xmath166 with @xmath167 as suggested in @xcite who remarked that this form of the empirical log - likelihood function is asymptotically equal to the true log - likelihood function in certain instances .",
    "let @xmath168 be this modified log - likelihood .",
    "note that the maximum likelihood estimator for @xmath169 is not unique , since the likelihood is constant in @xmath169 over the intervals @xmath170 , where @xmath171 are the order statistics of  @xmath21 .",
    "for this reason , we only need to consider @xmath169 at the values of the @xmath21 order statistics .",
    "the estimators are obtained in the following way : for fixed @xmath169 , we maximize the fully nonparametric log - likelihood over @xmath172 , to obtain the profile log - likelihood @xmath173 .",
    "we then maximize @xmath174 over @xmath169 , to obtain @xmath175 ; and then compute @xmath176 .",
    "this yields the npmle @xmath177 for @xmath178 .",
    "hence we obtain an estimator for @xmath112 but not for @xmath113 .",
    "to study consistency , we first characterize the npmle @xmath179 .",
    "consider the following one - dimensional submodels for a : @xmath180 where @xmath181 is an arbitrary non - negative bounded function .",
    "a score function for @xmath13 , defined as the derivative of @xmath182 with respect to @xmath62 at @xmath183 , is @xmath184   \\int_0^{\\tau}\\tilde{y}(s ) e^{r_{\\xi}(s;z , y)}g(s)da(s ) \\right\\ } , ~\\label{c4:e1}\\end{aligned}\\ ] ] where @xmath185 . for",
    "any fixed @xmath35 , let @xmath186 denote the maximizer of @xmath187 , and let @xmath188 .",
    "then the score function  ( [ c4:e1 ] ) is equal to zero when evaluated at @xmath189 .",
    "we select @xmath190 , insert this into  ( [ c4:e1 ] ) , and equate the resulting expression to zero : @xmath191 @xmath192\\right)^{-1}{\\mathbb{p}}_n\\{dn(s)\\}&&\\nonumber\\\\ \\equiv\\int_0^u\\{\\mathbb{p}_nw(s ; \\hat{\\theta}_{\\xi})\\}^{-1}{\\mathbb{p}}_n\\{dn(s)\\}.&&\\nonumber\\end{aligned}\\ ] ] now the profile likelihood has the form @xmath193 .",
    "the above characterization facilitates the following consistency results for @xmath194 :    [ l1 ] under the regularity conditions of section  2 , the transformation model with a change - point based on a covariate threshold is identifiable .",
    "[ l2 ] under the regularity conditions of section  2 , @xmath195 is asymptotically bounded , and thus the npmle @xmath194 exists .    using these results , we can establish the uniform consistency of @xmath196 :    [ t1 ] under the regularity conditions of section  2 , @xmath197 converges outer almost surely to @xmath178 in the uniform norm .",
    "in this section , we derive the score and information operators for the collected parameters @xmath172 .",
    "we refer to these parameters as the regular parameters because , as we will see in section  6 , these parameters converge at the @xmath47 rate . on the other hand",
    ", @xmath175 converges at the @xmath1 rate and thus the parameter @xmath169 is not regular .",
    "the score and information operators for @xmath172 are needed for the convergence rate and weak limit results of sections  6 and  7 .",
    "let @xmath198 denote the space of the elements @xmath199 such that @xmath200 , @xmath201 , @xmath202 , and @xmath203 $ ] , where @xmath204 $ ] is the space of cadlag functions ( right - continuous with left - hand limits ) on @xmath65 $ ] .",
    "we denote by @xmath205 the subspace of @xmath204 $ ] consisting of functions that are of bounded variation over the interval @xmath65 $ ] .",
    "define , for future use , the following linear functional for each @xmath206 and each @xmath207 $ ] : @xmath208 where @xmath209 is an element or vector of elements in @xmath205 . also let @xmath210 and @xmath211 , where @xmath212 is the total variation norm on @xmath205 and @xmath213 .",
    "the parameter @xmath214 can be considered a linear functional on @xmath215 by defining @xmath216 , @xmath217 .",
    "viewed this way , @xmath218 is a subset of @xmath219 with uniform norm @xmath220 , where @xmath221 is the space of bounded functionals on  @xmath34 .",
    "note that @xmath222 is rich enough to extract all components of @xmath172 .",
    "this is easy to see for the euclidean components ; and , for the @xmath13 component , it works by using the elements @xmath223\\}\\subset{\\cal h}_1 $ ] .    in section  5.1 ,",
    "we derive the score operator ; while in section  5.2 we derive the information operator and establish its continuous invertibility .      using the one - dimensional submodel",
    "@xmath224 the score operator takes the form @xmath225 where @xmath226 , and @xmath227 and where , for @xmath228 , @xmath229.\\ ] ] the dependence in the notation on @xmath230 will prove useful in later developments .      to obtain the information operator , we can differentiate the expectation of the score operator using the map @xmath231 , where @xmath232 .",
    "the information operator , @xmath233 , where @xmath234 , satisfies @xmath235 for every @xmath236 . taking the gteaux derivative in  ( [ new.j12.e1 ] ) , we obtain @xmath237 @xmath238 @xmath239 , where @xmath240 @xmath241 and where @xmath242.\\end{aligned}\\ ] ] note that all of the above operators are clearly bounded whenever @xmath243 is bounded .    the following lemma strengthens the above gteaux derivative to a frchet derivative .",
    "we will need this strong differentiability to obtain weak convergence of our estimators .",
    "[ l3 ] under the regularity conditions of section  2 and for any @xmath244 $ ] and @xmath245 , the operator @xmath246 is frchet differentiable at @xmath247 , with derivative @xmath248 , where @xmath249 ranges over @xmath250 and is the index for @xmath251 , @xmath172 ranges over the linear span @xmath252 of @xmath218 , and @xmath253 .",
    "the following lemma gives us the desired continuous invertibility of both @xmath254 and the operator @xmath255 .",
    "this last operator will be needed for weak convergence of regular parameters .",
    "[ l4 ] under the regularity conditions of section  2 , the linear operator @xmath256 is continuously invertible and onto , with inverse @xmath257 .",
    "moreover , the linear operator @xmath258 , as a map from and to @xmath252 , is also continuously invertible and onto , with inverse @xmath259 .",
    "to determine the convergence rates of the estimators , we need to study closely the log - likelihood process @xmath260 near its maximizer . in the parametric setting , this process can be approximated by its expectation which can be shown to be locally concave .",
    "for the cox model , as in @xcite , this same procedure can be applied to the partial likelihood which shares the local concavity features of a parametric likelihood .",
    "unfortunately , in our present set - up , studying the expectation of @xmath260 will lead to problems since @xmath112 has a density and thus @xmath261 for all @xmath115 $ ] .",
    "hence @xmath262 , and a new approach is needed .",
    "the approach we take involves a careful reparameterization of @xmath195 .    from section  4 , we know that the maximizer @xmath263 @xmath264 , where @xmath265 and @xmath266 is as defined in  ( [ c4:e2 ] ) .",
    "it is easy to see that for all @xmath1 large enough and all @xmath243 sufficiently close to @xmath178 , @xmath267 is bounded below and above and in total variation , with large probability .",
    "thus , if we use the reparameterization @xmath268 , and maximize @xmath269 over @xmath35 and @xmath270 , where @xmath271 , we will achieve the same npmle as before .",
    "note that the @xmath270 component of the maximizer of @xmath272 is therefore just @xmath273 .",
    "define @xmath274 and @xmath275 , and note that the reparameterized npmle @xmath276 is the maximizer of the process @xmath277\\right.\\\\ & & \\mbox{\\hspace{0.2 in } } \\left.\\rule[-0.3cm]{0cm}{1.0cm}\\times dn(t ) -(g(h^{\\theta_n(\\zeta,\\gamma,\\gamma)}(v ) ) -g(h^{\\theta_n(\\zeta_0,\\gamma_0,\\gamma_0)}(v ) ) ) \\right\\}.\\end{aligned}\\ ] ] we will argue shortly that @xmath278 is uniformly consistent for the function @xmath279dn(t)\\right.\\\\ & & \\left.\\rule[-0.3cm]{0cm}{1.0cm}-(g(h^{\\theta_0(\\zeta,\\gamma,\\gamma)}(v ) ) -g(h^{\\theta_0}(v ) ) ) \\right\\},\\end{aligned}\\ ] ] where @xmath280 , @xmath281 , and @xmath282 .",
    "it will occasionally be useful to use the shorthand @xmath283 , @xmath284 and @xmath285 .",
    "define the modified parameter space @xmath286 ; and , for each @xmath287 , define the metric @xmath288 , where @xmath289 is the uniform norm .",
    "note that @xmath290 is deliberately not squared . for each @xmath291 and @xmath292 , define @xmath293 .",
    "note that for some @xmath294 and any @xmath291 , @xmath295 is eventually in @xmath296 for all @xmath1 large enough by theorem  [ t1 ] above combined with lemma  [ l5 ] below :    [ l5 ] there exists a @xmath294 such that @xmath297 and @xmath298 outer almost surely .",
    "now we study the local behavior of @xmath299 .",
    "first fix @xmath300 .",
    "since , for any @xmath301 , @xmath302 we obtain that the first derivative of @xmath303 in the direction @xmath236 , is precisely @xmath304 . moreover , by definition of the score and information operators , the second derivative in the same direction is @xmath305 , where @xmath306 . at the point @xmath307 , the first derivative is @xmath308 , while the second derivative is @xmath309 , by lemma  [ l4 ] . by the smoothness of the score and",
    "information operators ensured by condition  d1 and  d2 , and by the arbitrariness of @xmath249 , we now have that the function @xmath310 is concave for every @xmath311 , for sufficiently small @xmath312 .",
    "now note that @xmath313 , where @xmath314 @xmath315 and where @xmath316 , @xmath228 , are as defined in section  3 , and @xmath317 . by condition  b2",
    ", we now have that for small enough @xmath291 , @xmath318 is right and left continuously differentiable for all @xmath311 , with left partial derivative @xmath319 and right partial derivative @xmath320    we now have the following lemmas on the local behavior of @xmath299 with respect to @xmath169 :    [ l6 ] under the conditions of section  2 , @xmath321 and @xmath322 .",
    "[ l7 ] there exists @xmath323 such that @xmath324 for all @xmath325 .",
    "the two previous lemmas can be combined with the next lemma , lemma  [ l8 ] , to yield @xmath47 rates for all of the parameters ( theorem  [ t.l9 ] ) :    [ l8 ] there exists an @xmath326 such that @xmath327 converges weakly to a tight mean zero gaussian process @xmath328 , in @xmath329 , for which @xmath330 in probability , as @xmath331.@xmath332    [ t.l9 ] under the conditions of section  2 , @xmath333 , @xmath334 , and @xmath335 .",
    "to refine the rate for @xmath175 , we need two more lemmas , lemmas  [ l10 ] and  [ l11 ] below",
    ". we will also need to define the process @xmath336 @xmath337dn(t)\\right.\\\\ & & \\mbox{\\hspace{0.4 in } } \\left.\\rule[-0.3cm]{0cm}{1.0cm}-(g(h^{\\theta_0(\\zeta,\\gamma_0,\\gamma_0)}(v ) ) -g(h^{\\theta_0}(v)))\\right\\}.\\end{aligned}\\ ] ]    [ l10 ] @xmath338 .",
    "[ l11 ] there exists an @xmath339 and @xmath340 such that , for all @xmath341 and @xmath342 , @xmath343 } \\leq k_2\\sqrt{\\epsilon}$ ] , where @xmath344 .",
    "we now have the following theorem about the convergence rate for @xmath175 :    [ t2 ] under the conditions of section  2 , @xmath345 .",
    "_ the method of proof involves a `` peeling device '' ( see , for example , the proof of theorem  5.1 of @xcite , or the proof of theorem  2 of @xcite ) .",
    "fix @xmath291 . by consistency and lemma  [ l5 ] , @xmath346 for all @xmath1 large enough , where @xmath347 . by lemma  [ l10 ]",
    ", there exists an @xmath348 such that @xmath349 . for integers @xmath350 , let @xmath351 . we now have , for any integer @xmath350 , that @xmath352 @xmath353 by lemma  [ l7 ] , where @xmath354 .",
    "but , by lemma  [ l11 ] , @xmath355 we can now choose @xmath292 large enough so that this last term @xmath356 . since @xmath291 was arbitrary , we now have that @xmath357 , and the desired conclusion follows.@xmath332",
    "denote @xmath358,|u|\\leq m\\}$ ] and @xmath359 .",
    "the limiting distribution of @xmath360 will be deduced from the behavior of the restriction of the process @xmath361 $ ] to the compact set @xmath362 , for @xmath363 sufficiently large .",
    "[ t3 ] the following approximation holds for all @xmath364 , as @xmath365 : @xmath366=   q_n(u)+o_p^{\\mathbb{u}_{n , m}}(1),\\ ] ] where @xmath367 denotes a term going to zero in probability uniformly over the set @xmath34 and @xmath368 @xmath369\\right\\}.\\end{aligned}\\ ] ]    let @xmath370 .",
    "we now study the weak convergence of @xmath371 as a random variable on the space of cadlag functions @xmath372 with the skorohod topology , and on its restriction to the space @xmath373 of cadlag functions on @xmath374 $ ] , for any @xmath364 , similar to the approach taken in @xcite . in order to describe the asymptotic distribution of @xmath371 ,",
    "let @xmath375 and @xmath376 be two independent jump processes on  @xmath377 such that @xmath378 is a poisson variable with parameter @xmath379 and @xmath380 is a poisson variable with parameter @xmath381 . here",
    ", @xmath382 denotes @xmath383 .",
    "let @xmath384 and @xmath385 be independent sequences of i.i.d .",
    "random variables with characteristic functions @xmath386",
    "= p\\left[\\left.e^{it\\left\\{l_1^{\\psi_0}(v,\\delta , z)-l_2^{\\psi_0}(v,\\delta , z ) \\right\\}}\\right|y=\\zeta_0^+\\right],\\ ] ] and @xmath387 = p\\left[\\left.e^{it\\left\\{l_1^{\\psi_0}(v,\\delta , z)-l_2^{\\psi_0}(v,\\delta , z ) \\right\\}}\\right|y=\\zeta_0\\right],\\ ] ] respectively , where @xmath388 and @xmath385 are independent of @xmath375 and @xmath376 .",
    "let @xmath389 be the right - continuous jump process defined by @xmath390 where @xmath391 . using a modification of the arguments in @xcite",
    ", we obtain :    [ t4 ] under the regularity conditions of section  2 , the process @xmath371 converges weakly to @xmath392 in @xmath373 , for every @xmath364 ; @xmath393 which converges weakly to @xmath394 ; and @xmath360 and @xmath395 are asymptotically independent for all @xmath236 .",
    "we use hoffmann - jrgensen weak convergence as described in @xcite .",
    "we have the following result :    [ t5 ] under the conditions of theorem 1 , @xmath396 is asymptotically linear , with influence function @xmath397 , @xmath398 , converging weakly in the uniform norm to a tight , mean zero gaussian process @xmath399 with covariance @xmath400 $ ] , for all @xmath401 . thus @xmath360 and @xmath402 are asymptotically independent .",
    "[ r1 ] since @xmath403 is asymptotically linear , with influence function contained in the closed linear span of the tangent space ( since @xmath254 is continuously invertible ) , @xmath404 is regular and hence as efficient as if @xmath86 were known , by theorem 5.2.3 and theorem 5.2.1 of @xcite .",
    "in this section we develop monte carlo methods for inference for the parameter estimators when it is known that either @xmath105 or @xmath106 , i.e. , it is known that condition  c2 is satisfied . in section  9",
    ", we develop a hypothesis testing procedure to assess whether @xmath405 holds ( i.e. , that  c2 does not hold ) . when it is known that @xmath132 holds , the model reduces to the usual transformation model ( see @xcite ) , and thus validity of the bootstrap",
    "will follow from arguments similar to those used in the proof of corollary  1 of @xcite .",
    "one possibility for inference for @xmath169 is to use the subsampling bootstrap @xcite which is guaranteed to work , provided the subsample sizes @xmath406 satisfy @xmath407 and @xmath408 .",
    "however , this approach is very computationally intense since , for each subsample , the likelihood must be maximized over the entire parameter space . to ameliorate the computational strain , we propose as an alternative the following specialized parametric bootstrap .",
    "let @xmath409 and @xmath410 be the distribution functions corresponding to the moment generating functions @xmath411 and @xmath412 , respectively .",
    "we need to make the following additional assumption :    1 .",
    "both @xmath409 and @xmath410 are continuous .",
    "now let @xmath413 be the minimum of the number of @xmath21 observations in the sample @xmath414 and the number of @xmath21 observations @xmath415 .",
    "now choose sequences of possibly data dependent integers @xmath416 such that @xmath417 , @xmath418 , and @xmath419 , in probability , as @xmath420 .",
    "note that if one chooses @xmath421 to be the closest integer to @xmath422 and @xmath423 to be the closest integer to @xmath424 , the given requirements will be satisfied since @xmath425 , in probability , by assumption  b1 .",
    "let @xmath426 be the complete data observations corresponding to the order statistics @xmath427 of the @xmath21 observations .",
    "also let @xmath428 , and define @xmath429 to be the integer satisfying @xmath430 .",
    "the existence of this integer follows from the form of the mle .",
    "now , for @xmath431 , and any @xmath432 , define @xmath433 @xmath434 , and @xmath435 .",
    "also let @xmath436 be the data - dependent distribution function for a random variable drawn with replacement from @xmath437 , and let @xmath438 be the data - dependent distribution function for a random variable drawn with replacement from @xmath439 @xmath440 . by the smoothness of the terms involved , it is easy to verify that both @xmath441 @xmath442 and @xmath443 .",
    "moreover , by assumption  b2(i ) , the fact that @xmath444 , and the conditions on @xmath421 and @xmath423 , we have that both @xmath445 and @xmath446 . thus , by assumption  b2(ii ) , the collection @xmath447 @xmath448 converges in distribution to an i.i.d . sample of random variables with characteristic function @xmath411 , while the collection @xmath449 is independent of the first collection and converges in distribution to an i.i.d .",
    "sample of random variables with characteristic function @xmath412 . by assumption  b5 and the fact that @xmath450 , in probability , we now have that both @xmath451 and @xmath452 .    now let @xmath453 be a consistent estimator of @xmath454 .",
    "such an estimator can be obtained from a kernel density estimator of @xmath87 based on the @xmath21 observations and evaluated at @xmath175 .",
    "the basic idea of our parametric bootstrap is to create a stochastic process @xmath455 defined similarly to the process @xmath392 described in section  7.1 . to this end , let @xmath456 and @xmath457 be two independent jump processes defined on the interval @xmath458 $ ] such that @xmath459 is poisson with parameter @xmath460 and @xmath461 is poisson with parameter @xmath462 . also let @xmath463 and @xmath464 be two independent sequences of i.i.d .",
    "random variables drawn from @xmath436 and @xmath438 and independent of the poisson processes .",
    "now construct @xmath465 on the interval @xmath466 , where @xmath467 and @xmath468 .",
    "finally , we compute @xmath469 .",
    "the following proposition now follows from the fact that @xmath470 for all compact @xmath471 :    [ p1 ] the conditional distribution of @xmath472 given the data is asymptotically equal to the distribution of @xmath473 defined in theorem  [ t4 ] .    hence for any @xmath474 , we can consistently estimate the @xmath475 and @xmath476 quantiles of @xmath473 based on a large number of independent draws from @xmath472 , which estimates we will denote by @xmath477 and @xmath478 , respectively .",
    "thus an asymptotically valid @xmath479 confidence interval for @xmath86 is @xmath480 $ ] .      because @xmath175 is @xmath1-consistent for @xmath86 , @xmath86 can be treated as known in constructing inference for the regular parameters .",
    "accordingly , we propose bootstrapping the likelihood and maximizing over @xmath172 while holding @xmath169 fixed at @xmath175 .",
    "this will significantly reduce the computational demands of the bootstrap . also , to avoid the occurrence of ties during resampling , we suggest the following weighted bootstrap alternative to the usual nonparametric bootstrap . first generate @xmath1 i.i.d .",
    "positive random variables @xmath481 , with mean @xmath482 , variance @xmath483 , and with @xmath484 .",
    "divide each weight by the sample average of the weights @xmath485 , to obtain `` standardized weights '' @xmath486 which sum to  @xmath1 . for a real , measurable function @xmath209 ,",
    "define the weighted empirical measure @xmath487 .",
    "recall that the nonparametric bootstrap empirical measure @xmath488 uses multinomial weights @xmath489 , where @xmath490}=1 $ ] , @xmath50 , and @xmath491 almost surely .    the proposed weighted bootstrap estimate @xmath492 is obtained by maximizing @xmath493 over @xmath432 , where @xmath494 is obtained by replacing @xmath495 with @xmath496 in the definition of @xmath497 from section  3 .",
    "we can similarly defined a modified nonparametric bootstrap @xmath498 as the @xmath499 of @xmath500 , where @xmath501 is obtained by replacing @xmath495 with @xmath502 in the definition of @xmath497 .",
    "the following corollary establishes the validity of both kinds of bootstraps :    [ c1 ] under the conditions of theorem  [ t5 ] , the conditional bootstrap of @xmath503 , based on either @xmath498 or @xmath492 , is asymptotically consistent for the limiting distribution @xmath399 in the following sense : both @xmath504 and @xmath505 are asymptotically measurable , and both    1 .",
    "@xmath506 in outer probability and 2 .",
    "@xmath507 in outer probability ,    where @xmath508 is the space of functions mapping @xmath509\\mapsto{\\mathbb{r}}$ ] which are bounded in absolute value by  1 and have lipschitz norm @xmath510 . here ,",
    "@xmath511 and @xmath512 are expectations that are taken over the multinomial and standardized weights , respectively , conditional on the data .",
    "[ r2 ] as discussed in remark  15 of @xcite , the choice of weights @xmath481 in this kind of setting does not effect the first order asymptotics .",
    "however , it may have an effect on finite samples . in our experience",
    ", we have found that both exponential and truncated exponential weights perform quite well .",
    "constructing a valid test of the null hypothesis that there is no change - point , @xmath405 , poses an interesting challenge .",
    "since the location of the change - point is no longer identifiable under @xmath132 , this is an example of the issue studied in @xcite .",
    "the test statistic we propose is a functional of the @xmath31 and @xmath513 components of the score process , @xmath514 , where @xmath244 $ ] , @xmath515 , and where @xmath516 is the restricted mle of @xmath517 under the assumption that @xmath38 and @xmath518 .",
    "this mle is relatively easy to compute since estimation of @xmath169 is not needed . specifically , we have from section  3 , that @xmath519 is the maximizer of @xmath520 we also define for future use @xmath521 , where @xmath522",
    ". the statistic we propose using is @xmath523}\\left\\{\\hat{s}_{1}'(\\zeta)\\hat v_n^{-1}(\\zeta)\\right.$ ] @xmath524 , where @xmath525 is a consistent estimator of the covariance of @xmath526 .",
    "there are several reasons for us to consider the sup functional of score statistics instead of wald or likelihood ratio statistics .",
    "firstly , the score statistic is much less computational intense which makes the bootstrap implementation feasible .",
    "secondly , we choose the sup functional because of its guarantee to have some power under local alternatives , as argued in @xcite and which we prove below .",
    "we note , however , that @xcite argue that certain weighted averages of score statistics are optimal tests in some settings .",
    "a careful analysis of the relative merits of the two approaches in our setting is beyond the scope of the current paper but is an interesting topic for future research .",
    "however , as a step in this direction , we will compare @xmath527 with the integrated statistic @xmath528}\\left\\{\\hat{s}_{1 } ' ( \\zeta )   \\hat v_n^{-1}(\\zeta ) \\hat{s}_{1 } ( \\zeta)\\right\\}d\\zeta$ ] .    in this section ,",
    "we first discuss a monte carlo technique which enables computation of @xmath529 , so that @xmath527 and @xmath530 can be calculated in the first place , as well as computation of critical values for hypothesis testing .",
    "we then discuss the asymptotic properties of the statistics under a sequence of contiguous alternatives so that power can be verified .",
    "specifically , we assume that all the conditions of section  2 hold except for c2 which we replace with    1 .   for each @xmath342 , @xmath531 and @xmath532 , for some fixed @xmath533 and @xmath534 .",
    "the joint distribution of @xmath138 does not change with @xmath1 .",
    "note that when @xmath535 or @xmath536 , condition  c2 will cause the distribution of the failure time @xmath10 , given the covariates @xmath78 , to change with @xmath1 , and the value of @xmath86 will affect this distribution .",
    "while the nonparametric bootstrap may be a reasonable approach , it is unclear how to verify its theoretical properties in this context .",
    "we will use instead the weighted bootstrap , based on the multipliers @xmath486 defined in section  8.2 .",
    "let @xmath496 be the corresponding weighted empirical measure , and define @xmath537 to be the maximizer of  ( [ s9.e1 ] ) after replacing @xmath495 with @xmath496 .",
    "also let @xmath538 .",
    "note that the same sample of weights @xmath486 are used for computing both @xmath537 and the process @xmath539\\}$ ] , so that the proper dependence between the score statistic and @xmath519 will be captured .",
    "the structure of the set - up only requires considering values of @xmath169 in the set @xmath540 $ ] , since @xmath541 does not change over the intervals @xmath542 , @xmath543 . now repeat the bootstrap procedure a large number of times @xmath544 , to obtain the bootstrapped score processes @xmath545 .",
    "note that we are allowing the number of bootstraps to depend on  @xmath1 .",
    "define @xmath546 and let @xmath547 now we can compute the test statistics @xmath527 and @xmath530 with this choice for @xmath548 .    to estimate critical values ,",
    "we compute the standardized bootstrap test statistics @xmath549}\\left\\ { \\left[\\hat{s}_{1,k}^{\\circ}(\\zeta)-\\hat{\\mu}_n(\\zeta)\\right ] ' \\hat{v}_n^{-1}(\\zeta)\\left [ \\hat{s}_{1,k}^{\\circ}(\\zeta)-\\hat{\\mu}_n(\\zeta)\\right]\\right\\}$ ] and @xmath550}\\left\\ { \\left[\\hat{s}_{1,k}^{\\circ}(\\zeta)-\\hat{\\mu}_n(\\zeta)\\right ] ' \\hat{v}_n^{-1}(\\zeta)\\left [ \\hat{s}_{1,k}^{\\circ}(\\zeta)-\\hat{\\mu}_n(\\zeta)\\right]\\right\\}d\\zeta$ ] , for @xmath551 . for a test of size @xmath552",
    ", we compare the test statistics with the @xmath553th quantile of the corresponding @xmath544 standardized bootstrap statistics .",
    "the reason we subtract off the sample mean when computing the bootstrapped test statistics is to make sure that we are approximating the null distribution even when the null hypothesis may not be true .",
    "what is a little unusual about this procedure is that the bootstrap must be performed before the statistics @xmath527 and @xmath530 can be calculated in the first place .",
    "we also reiterate again that we are assuming the covariates @xmath554 are observed at all time points @xmath128 for which @xmath555 . as noted in section  2 , we are aware that this is not necessarily valid in practice . as pointed out by a referee this is an important issues and it would be worth investigating whether the bootstrap weighting scheme could be modified to perform and account for imputation of the missing covariate values . nevertheless , this issue is beyond the scope of this paper and we do not pursue it further here .      in this section",
    "we establish the asymptotic validity of the proposed test procedure .",
    "let @xmath75 denote the fixed probability distribution under the null hypothesis @xmath132 , and let @xmath556 be the sequence of probability distributions under the contiguous sequence of alternatives @xmath557 defined in c2. note that @xmath75 and @xmath556 can be equal if @xmath558 .",
    "we need to study the proposed procedure under general @xmath556 to determine both its size under the null and its power under the alternative .",
    "we will use the notation @xmath559 to denote weak convergence under @xmath556 .",
    "we need the following lemmas and theorem :    [ s9.l1 ] the sequence of probability measures @xmath556 satisfies @xmath560 ^ 2 \\rightarrow 0,\\nonumber \\end{aligned}\\ ] ] where @xmath561 .",
    "[ s9.l2 ] @xmath562 in probability under @xmath556 .",
    "[ s9.t1 ] under the conditions of section  2 , with condition c2 replaced by c2 , @xmath563 converges under @xmath556 in distribution in @xmath564^{q+1})$ ] to the @xmath565-vector process @xmath566 , where @xmath567 is a tight , mean zero gaussian @xmath565-vector process with @xmath568 = \\sigma_{\\ast}(\\zeta_1,\\zeta_2)\\equiv \\sigma_{\\ast}^{11}(\\zeta_1\\vee\\zeta_2)-\\sigma_{\\ast}^{12}(\\zeta_1 ) [ \\sigma_{\\ast}^{22}]^{-1}\\sigma_{\\ast}^{21}(\\zeta_2)$ ] , for all @xmath569 $ ] , where , for each @xmath244 $ ] , @xmath570^{-1 } \\sigma_{\\ast}^{21}(\\zeta_0)\\right\\ } \\left(\\begin{array}{c}\\alpha_{\\ast}\\\\ \\eta_{\\ast}\\end{array}\\right),\\\\ \\sigma_{\\ast}^{11}(\\zeta ) & \\equiv&\\left(\\begin{array}{cc}\\sigma_{\\psi_0^{\\ast},\\zeta}^{11 } & \\sigma_{\\psi_0^{\\ast},\\zeta}^{12}\\\\ \\\\",
    "\\sigma_{\\psi_0^{\\ast},\\zeta}^{21 } & \\sigma_{\\psi_0^{\\ast},\\zeta}^{22}\\end{array}\\right),\\;\\;\\;\\ ; \\sigma_{\\ast}^{12}(\\zeta)\\;\\;\\equiv\\;\\;\\left ( \\begin{array}{cc}\\sigma_{\\psi_0^{\\ast},\\zeta}^{13 } & \\sigma_{\\psi_0^{\\ast},\\zeta}^{14}\\\\ \\\\",
    "\\sigma_{\\psi_0^{\\ast},\\zeta}^{23 } & \\sigma_{\\psi_0^{\\ast},\\zeta}^{24}\\end{array}\\right),\\\\ \\sigma_{\\ast}^{21}(\\zeta)&\\equiv&\\left ( \\begin{array}{cc}\\sigma_{\\psi_0^{\\ast},\\zeta}^{31 } & \\sigma_{\\psi_0^{\\ast},\\zeta}^{32}\\\\ \\\\ \\sigma_{\\psi_0^{\\ast},\\zeta}^{41 } & \\sigma_{\\psi_0^{\\ast},\\zeta}^{42}\\end{array}\\right),\\;\\;\\;\\ ; \\sigma_{\\ast}^{22}\\;\\;\\equiv\\;\\;\\left ( \\begin{array}{cc}\\sigma_{\\psi_0^{\\ast},\\zeta_0}^{33 } & \\sigma_{\\psi_0^{\\ast},\\zeta_0}^{34}\\\\ \\\\",
    "\\sigma_{\\psi_0^{\\ast},\\zeta_0}^{43 } & \\sigma_{\\psi_0^{\\ast},\\zeta_0}^{44}\\end{array}\\right),\\end{aligned}\\ ] ] and where @xmath571 , for @xmath572 , is as defined in section  5.2 .",
    "the following is the main result on the limiting distribution of the test statistics .",
    "for the remainder of this section , we require condition  b4 to hold .",
    "as will be shown in the proof of corollary  [ c2 ] , condition  b4 implies that @xmath573 is positive definite for all @xmath244 $ ] . note that we will establish consistency of @xmath548 after we verify the validity of the proposed bootstrap .",
    "[ c2 ] assume  b4 holds and @xmath574 in probability under @xmath556 , uniformly over @xmath244 $ ]",
    ". then @xmath575}\\left\\ { \\left[\\mathbb{z}_{\\ast}(\\zeta)+\\nu_{\\ast}(\\zeta)\\right]'\\right.$ ] @xmath576\\right\\}$ ] and @xmath577}\\left\\ { \\left[\\mathbb{z}_{\\ast}(\\zeta)+\\nu_{\\ast}(\\zeta)\\right ] ' v_{\\ast}^{-1}(\\zeta ) \\left[\\mathbb{z}_{\\ast}(\\zeta)\\right.\\right.$]@xmath578\\right\\}$ ] .",
    "thus the limiting null distributions of @xmath527 and @xmath530 are @xmath579}$ ] @xmath580 and @xmath581}\\left\\ { \\mathbb{z}_{\\ast}'(\\zeta)v_{\\ast}^{-1}(\\zeta ) \\mathbb{z}_{\\ast}(\\zeta)\\right\\}d\\zeta$ ] , respectively .",
    "[ r3 ] note that @xmath582 equals the matrix @xmath583 times @xmath584 . by arguments in the proof of lemma  [ l4 ] , we know that @xmath583 is positive definite . thus @xmath582 will be strictly nonzero whenever @xmath585 .",
    "thus both @xmath527 and @xmath530 will have power to reject  @xmath132 under strictly non - null contiguous alternatives @xmath557 .",
    "the following theorem is the first step in establishing the validity of the bootstrap .",
    "for brevity , we will use the notation @xmath586 to denote conditional convergence of the bootstrap , either weakly in the sense of corollary  [ c1 ] or in probability , but under @xmath556 rather than @xmath75 .",
    "[ s9.t2 ] under the conditions of theorem  [ s9.t1 ] , @xmath587 in @xmath588^{q+1})$ ] .",
    "the following corollary yields the desired consistency of @xmath548 and the validity of the proposed bootstrap for obtaining critical values .",
    "define @xmath589 and @xmath590 .",
    "[ c3 ] there exists a sequence @xmath591 , as @xmath420 , such that @xmath592 , @xmath593 , and both @xmath594 and @xmath595 @xmath596 .",
    "we have implemented the proposed estimation and inference procedures for both the proportional hazards and proportional odds models .",
    "the maximum likelihood estimates were computed using the profile likelihood @xmath597 defined in section  4 .",
    "a line search over the order statistics of @xmath21 is used to maximize over @xmath169 , while newton s method is used to maximize over @xmath172 .",
    "the stationary point equation  ( [ c4:e2 ] ) can be used to profile over @xmath13 for each value of @xmath169 and @xmath598 . in our experience",
    ", the computational time of the entire procedure is reasonable .",
    "a thorough simulation study to validate the moderate sample size performance of this procedure and the proposed bootstrap procedures of section  8 is underway and will be presented elsewhere .    because of the unusual form of the statistical tests proposed in section  9 , we feel it is worthwhile at this point to present a small simulation study evaluating their moderate sample size performance .",
    "both the proportional hazards and proportional odds models were considered .",
    "a single time - independent covariate with a standard normal distribution was used , so that @xmath599 , and the change - point @xmath21 also had a standard normal distribution .",
    "the parameter values were set at @xmath600 , @xmath601 , @xmath602 , @xmath603 , and @xmath604 .",
    "the range of @xmath605 values includes the null hypothesis @xmath132 ( when @xmath131 ) and several alternative hypotheses . the censoring time was exponentially distributed with rate @xmath606 and truncated at 10 .",
    "this resulted in a censoring rate of about 25% .",
    "the sample size for each simulated data set was 300 .",
    "for each simulated data set , 250 bootstraps were generated with standard exponential weights truncated at 5 , to compute @xmath548 and the critical values for the two test statistics , @xmath527 ( the `` sup score test '' ) and @xmath530 ( the `` mean score test '' ) .",
    "the range for @xmath169 was restricted to the inner 80% of the @xmath21 values .",
    "each scenario was replicated 250 times .",
    "the results of the simulation study are presented in table  [ table1 ] on page",
    ". the type  i error ( the @xmath131 column ) is quite close to the targeted 0.05 level , and the power increases with the magnitude of @xmath605 . also , the sup test is notably more powerful than the mean test for all alternatives .",
    "we also tried the nonparametric bootstrap and found that it did not work nearly as well .",
    "while it is difficult to make sweeping generalizations with this small of a numerical study , it appears as if the proposed test statistics match the theoretical predictions and have reasonable power .",
    "more simulation studies into the properties of these statistics would be worthwhile , especially studies of the impact of time - dependent covariates .",
    "c|c|c|c|c|c + & null @xmath131 & @xmath607 & @xmath608 & @xmath609 & @xmath610 + & 5.078&5.590 & 7.874 & 13.524&35.507 + & 2.728&2.859 & 3.919 & 6.992 & 11.337 + & 0.044&0.076 & 0.180 & 0.536&0.980 + & null @xmath131 & @xmath607 & @xmath608 & @xmath611 & @xmath610 + & 1.403 & 1.694 & 2.560 & 5.412 & 5.529 + & 1.206 & 1.104 & 1.597 & 2.492 & 2.683 + & 0.040 & 0.050 & 0.120 & 0.236 &",
    "0.304 +   + & null @xmath131 & @xmath607 & @xmath608 & @xmath609 & @xmath610 + & 3.950&4.762 & 5.693 & 8.327 & 13.956 + & 2.390&1.610 & 1.255 & 2.901 & 4.244 + & 0.043&0.068 & 0.112 & 0.364 & 0.660 + & null @xmath131 & @xmath607 & @xmath608 & @xmath611 & @xmath610 + & 1.177 & 1.912 & 2.848 & 3.265 & 4.349 + & 0.946 & 1.078 & 1.360 & 1.498 & 1.718 + & 0.048 & 0.056 & 0.116 & 0.167 & 0.285 +",
    "_ proof of lemma  [ l.v1 ] .",
    "_ verification of  d1 is straightforward . for  d2",
    ", we have for all @xmath612 , @xmath613}}{{\\mbox{e}\\left[we^{-uw}\\right]}}\\leq\\frac{{\\mbox{e}\\left[w^2\\right]}}{{\\mbox{e}\\left[w\\right]}}<\\infty.\\ ] ] the second - to - last inequality requires some justification .",
    "note that the probability measure @xmath614}/{\\mbox{e}\\left[w\\right]}$ ] is well - defined for functions @xmath209 bounded by @xmath615 by the positivity of @xmath145 and the existence of a fourth moment .",
    "now we have @xmath616}}{{\\mbox{e}\\left[we^{-uw}\\right]}}=\\frac{q[we^{-uw } ] } { q[e^{-uw}]}\\leq q[w]=\\frac{{\\mbox{e}\\left[w^2\\right]}}{{\\mbox{e}\\left[w\\right]}},\\ ] ] since @xmath617 uniformly down - weights larger values of @xmath145 and thus forces the left term of the inequality to be decreasing in  @xmath618 .",
    "this proves the first part .    for the second part ,",
    "take @xmath619 , and note that @xmath620}={\\mbox{e}\\left[w^{-c}(uw)^ce^{-uw}\\right ] } \\leq k{\\mbox{e}\\left[w^{-c}\\right]},\\ ] ] where @xmath621 .",
    "similarly , @xmath622 } = { \\mbox{e}\\left[w^{-c}(uw)^{1+c}e^{-uw}\\right]}\\leq k'{\\mbox{e}\\left[w^{-c}\\right]},\\ ] ] where @xmath623 .",
    "this concludes the proof.@xmath332    _ proof of lemma  [ l1 ] . _",
    "suppose that @xmath624 for all @xmath625 $ ] almost surely under @xmath75 .",
    "the target is to show that  ( [ c12:e1 ] ) implies that @xmath626 and @xmath627 on @xmath55 $ ] . by condition  a1 , ( [ c12:e1 ] )",
    "implies @xmath628 for all @xmath625 $ ] almost surely . taking the radon - nikodym derivative of both sides with respect to @xmath112 , and taking logarithms",
    ", we obtain @xmath629 almost surely , where @xmath630 .",
    "assume that @xmath631 .",
    "now choose @xmath632 such that @xmath88 and @xmath633 $ ] is positive definite , where @xmath634 is as defined in  b3 .",
    "note that this is possible by assumptions  b2 and  b3 .",
    "conditioning the left - hand side of  ( [ c12:e2 ] ) on @xmath90 and evaluating at @xmath635 yields that @xmath636 .",
    "now choose @xmath637 such that @xmath88 and @xmath638 $ ] is positive definite .",
    "conditioning the left - hand side of  ( [ c12:e2 ] ) on @xmath90 , and evaluating at @xmath639 yields that @xmath131 .",
    "because the density of @xmath21 is positive in @xmath85 , we also see that @xmath601 .",
    "but this is not possible by condition  c2 .",
    "a similar argument can be used to show that @xmath640 is impossible .",
    "thus @xmath641 .",
    "now it is not hard to argue that condition  b3 forces @xmath636 , @xmath642 and @xmath643 .",
    "hence @xmath644 for all @xmath115 $ ] , and the proof is complete.@xmath332    _ proof of lemma  [ l2 ] .",
    "_ note that for each @xmath1 , maximizing the log - likelihood over @xmath13 is equivalent to maximizing over a fixed number of parameters since the number of jumps @xmath645 . thus maximizing over",
    "the whole parameter @xmath243 involves maximizing an empirical average of functions that are smooth over @xmath172 and cadlag over @xmath169 .",
    "note also that @xmath646}=\\sum_{j=1}^{k } \\left(\\left|\\hat{a}_n(t_j-)-a_0(t_j)\\right|\\vee \\left|\\hat{a}_n(t_j)-a_0(t_j)\\right|\\right),\\ ] ] where @xmath647 is the uniform norm over the set @xmath34 , and thus @xmath648}$ ] is measurable .",
    "hence the uniform distance between @xmath194 and @xmath178 is also measurable .",
    "thus almost sure convergence of @xmath194 is equivalent to outer almost sure convergence .",
    "now we return to the proof .",
    "assume @xmath649 with probability @xmath650 .",
    "we will show that this leads to a contradiction .",
    "it is now possible to choose a data sequence such that  ( [ c12:e4 ] ) holds and @xmath651 uniformly , since the latter happens with probability  1 .",
    "fix one such sequence @xmath652 , and define @xmath653 , where @xmath654 .",
    "note that the log - likelihood difference , @xmath655 , should be non - negative for all @xmath1 , since @xmath194 maximizes the log - likelihood .",
    "we are going to show that the difference is asymptotically negative under the assumption  ( [ c12:e4 ] ) .",
    "now choose a subsequence @xmath656 such that @xmath657 , as @xmath658 .",
    "we now have , for @xmath121 from assumption  d2 , that @xmath659 @xmath660\\nonumber\\\\ & & -\\mathbb{p}_{n_k}(1-\\delta)g(h^{\\hat{\\theta}_n}(v))\\nonumber\\\\ & \\leq & o(1)+\\mathbb{p}_{n_k } \\delta\\log   \\left(n_k \\delta \\hat{a}_{n_k}(v ) \\right ) -\\mathbb{p}_{n_k}(\\delta+c_0)\\log\\hat{a}_n(v),\\label{c12:e5}\\end{aligned}\\ ] ] since , for all @xmath661 , @xmath662-\\log[\\lambda(u)]$ ] ; @xmath663=\\log[-u^{1+c_0}$ ] @xmath664-(1+c_0)\\log(u ) \\leq o(1)-(1+c_0)\\log(u)$ ] by condition  d2 ; and since @xmath665-c_0\\log(u)\\leq o(1)-c_0\\log(u)$ ] also by condition  d2 .",
    "next we take a partition of @xmath55 $ ] , @xmath666 , for some finite @xmath363 . the right hand side of  ( [ c12:e5 ] ) is now dominated by @xmath667 \\ } - ( \\delta + c_0){\\mbox{\\large\\bf 1}}\\{v \\in [ \\tau , \\infty \\ }   \\right)&&\\\\ + \\sum_{m=1}^{m-1}\\log \\hat{a}_{n_k}(v_m ) \\mathbb{p}_{n_k }   \\left(\\delta { \\mbox{\\large\\bf 1}}\\{v \\in [ v_{m-1 } , v_m ] \\ } - ( \\delta + c_0 ) { \\mbox{\\large\\bf 1}}\\{v \\in [ v_{m } , v_{m+1 } ] \\ }   \\right).&&\\nonumber\\end{aligned}\\ ] ] for a fixed constant @xmath668 , we can choose this partition such that @xmath669\\ } = p_0[n(\\tau ) + c_0/c]{\\mbox{\\large\\bf 1}}\\{v \\in [ \\tau , \\infty ] \\},\\end{aligned}\\ ] ] and , for @xmath670 @xmath671\\ } = p_0[n(\\tau ) + c_0/c]{\\mbox{\\large\\bf 1}}\\{v \\in [ v_m , v_{m+1 } ] \\}.\\end{aligned}\\ ] ] recalling that @xmath672 uniformly , we obtain that  ( [ c12:e6 ] ) tends to @xmath673 as @xmath674 , which is the intended contradiction .",
    "thus , @xmath675 almost surely.@xmath332    _ proof of theorem  [ t1 ] .",
    "_ by the opening arguments in the proof of lemma  [ l2 ] , we have that outer almost sure convergence is equivalent to the usual almost sure convergence in this instance .",
    "note that @xmath676 is bounded almost surely , @xmath677 almost surely , and the class @xmath678,\\xi\\in{\\cal x } , a\\in{\\cal a}_{(k)}\\right\\},\\ ] ] where @xmath679 , is donsker ( and hence also glivenko - cantelli ) for every @xmath292 by lemma  [ l.t1.1 ] below . by similar arguments to those used in lemma  [ l.t1.1 ] , we have that the class @xmath680 is also glivenko - cantelli for all @xmath292 .",
    "we therefore have the following with probability  1 : @xmath676 is bounded asymptotically , @xmath681 uniformly , @xmath682 uniformly , and @xmath683\\rightarrow 0 $ ] .",
    "now , fix a sequence @xmath652 for which these last four asymptotic events hold .",
    "we can now use the helly selection theorem to find a subsequence @xmath656 and a function @xmath13 such that @xmath684 for all @xmath625 $ ] at which @xmath13 is continuous . from  ( [ c4:e2 ] ) , we obtain @xmath685 for all @xmath686 $ ] . since @xmath687 is continuous by condition  c3 , we know that @xmath13 must be continuous on all of @xmath65 $ ] .",
    "thus @xmath688 uniformly .",
    "without loss of generality , we can also assume that along this subsequence @xmath689 for some @xmath690 .",
    "denote @xmath691 .",
    "consider now @xmath692 , where @xmath693 we can use the same technique as in the derivation of  ( [ c4:e2 ] ) to show that @xmath112 satisfies @xmath694 for all @xmath115 $ ] .",
    "thus @xmath695 uniformly , as @xmath658 .",
    "at this point , we have @xmath696 d\\tilde{g}_{n_k}(u)-\\mathbb{p}_{n_k}\\left[g(h^{\\hat{\\theta}_{n_k}}(v))- g(h^{\\theta_{n_k}}(v))\\right]\\\\ & \\rightarrow&\\int_0^{\\tau}\\log\\frac{da(u)}{da_0(u)}d\\tilde{g}_0(u ) -p\\left[g(h^{\\theta}(v))-g(h^{\\theta_0}(v))\\right]\\\\ & = & \\int\\log\\frac{dp_{\\theta}}{dp}dp\\\\ & \\leq&0.\\end{aligned}\\ ] ] but this forces @xmath697 by the identifiability of the model as given in lemma  [ l1 ] .",
    "thus all convergent subsequences of @xmath194 , on a set of probability  1 , converge to @xmath178 . the desired result now follows.@xmath332    [ l.t1.1 ] @xmath698 , the class @xmath699,\\xi\\in{\\cal x } , \\right.$ ] @xmath700 , is @xmath75-donsker .",
    "_ routine arguments can be used to establish that the class @xmath701,\\xi\\in{\\cal x}\\}$ ] is donsker .",
    "consider the map @xmath702\\mapsto \\left\\{\\int_0^th(s)da(s):t\\in[0,\\tau],a\\in{\\cal a}_{(k)}\\right\\ } \\in\\ell^{\\infty}([0,\\tau]\\times{\\cal a}_{(k)}),\\ ] ] and note that it is uniformly equicontinuous and linear .",
    "thus the class @xmath703,\\xi\\in{\\cal x},a\\in{\\cal a}_{(k)}\\right\\}\\ ] ] is donsker by the continuous mapping theorem .",
    "now condition  d1 ensures that both @xmath704 and @xmath705 are lipschitz on compacts .",
    "this fact , combined with the facts that sums of donsker classes are donsker and products of bounded donsker classes are donsker , yields the desired results.@xmath332    _ proof of lemma  [ l3 ] .",
    "_ by the smoothness assumed in  d1 of the involved derivatives , we have for each @xmath244 $ ] and @xmath706 , @xmath707 thus , @xmath708 , as @xmath709.@xmath332    _ proof of lemma  [ l4 ] .",
    "_ first note that for any @xmath710 , @xmath711 , where @xmath712 , @xmath713 , and @xmath714 $ ] .",
    "it is not hard to verify that since @xmath715 is bounded below , @xmath716 is one - to - one and onto with continuous inverse defined by @xmath717 .",
    "it is also not hard to verify that the operator @xmath718 is compact as an operator on @xmath250 for any @xmath253 .",
    "thus the first part of the theorem is proved by lemma  25.93 of @xcite , if we can show that @xmath254 is one - to - one .",
    "this will then imply that for each @xmath719 , there is an @xmath720 with @xmath721 .",
    "now we have @xmath722 @xmath723 , since @xmath724 .",
    "thus @xmath725 is continuously invertible on its range by proposition  a.1.7 of @xcite . that it is also onto with inverse @xmath726 follows from @xmath254 being onto .",
    "all that remains is verifying that @xmath254 is one - to - one .",
    "let @xmath727 such that @xmath728 .",
    "for the one - dimensional submodel defined by the map @xmath729 , we have @xmath730 define the random set @xmath731 \\}$ ] .",
    "the equality  ( [ c12:e9 ] ) implies that @xmath732 for all @xmath733 such that @xmath734 , which implies that @xmath735 almost surely for all @xmath736 $ ] .",
    "consider the set on which the observation @xmath737 is censored at a time @xmath625 $ ] . from ( [ c12:e9 ] ) and the preceding argument , @xmath738 taking the radon - nikodym derivative of ( [ c12:e11 ] ) with respect to @xmath112 and dividing throughout by @xmath739 yields @xmath740 arguments quite similar to those used in the proof of lemma  [ l1 ]",
    "can now be used to verify that  ( [ c12:e12 ] ) forces @xmath741 .",
    "hence @xmath728 implies @xmath741 , and thus @xmath254 is one - to - one.@xmath332    _ proof of lemma  [ l5 ] .",
    "_ for the first part , note that @xmath742 has total variation bounded by  1 ; and , by the model assumptions , the total variation of @xmath743 is bounded by a universal constant that does nt depend on @xmath243 .",
    "thus there exists a universal constant @xmath744 such that @xmath745 . by the smoothness of the functions involved , and the fact that @xmath746 is lipschitz on compacts bounded above zero , we obtain the first result of the lemma .",
    "the consistency part follows from lemma  [ l.t1.1 ] combined with theorem  [ t1 ] , the continuity of @xmath747 , and reapplication of the lipschitz continuity of @xmath746.@xmath332    _ proof of lemma  [ l6 ] .",
    "the right - hand derivative of @xmath748 with respect to @xmath169 at @xmath641 is : @xmath749 @xmath750-p[l_2^{\\psi}(v,\\delta , z)|y = y+ ] \\right \\ }   \\tilde{\\delta}_{\\zeta_0}(y)\\tilde{h}(y)dy \\\\ & = & \\left(p[l_1^{\\psi}(v,\\delta , z ) |y=\\zeta_0+]- p[l_2^{\\psi}(v,\\delta , z)|y=\\zeta_0+]\\right)\\tilde{h}(\\zeta_0),\\end{aligned}\\ ] ] where the superscript  @xmath751 denotes differentiating from the right and @xmath752 is the dirac delta function assigning counting measure  1 to the event @xmath753 .",
    "now , @xmath754- p[l_2^{\\psi}(v,\\delta , z)|y=\\zeta_0+]$ ] @xmath755 \\ell_2(v , d , z)\\ell_0^{+}(v , d , z)d\\mu(v , d , z)\\ ] ] @xmath756 , where @xmath757 , for @xmath228 ; @xmath758 is the dominating measure ; and @xmath759 consists of the remaining components of the conditional distribution of @xmath760 given @xmath761 .",
    "note that under the model assumptions , @xmath762 does not depend on the parameters .",
    "thus @xmath763\\ell_2(v , d , z)\\ell_0^{+}(v , d , z)d\\mu(v , d , z)\\\\ & = & \\int\\log\\left[\\frac{\\ell_1\\ell_0^{+}}{\\ell_2\\ell_0^{+}}\\right ] \\ell_2\\ell_0^{+}d\\mu \\;\\;<\\;\\;\\log\\int\\left[\\frac{\\ell_1\\ell_0^{+ } } { \\ell_2\\ell_0^{+}}\\right]\\ell_2\\ell_0^{+}d\\mu\\\\ & = & \\log\\int\\ell_1(v , d , z)\\ell_0^{+}(v , d , z)d\\mu(v , d , z)\\;\\;=\\;\\;0,\\end{aligned}\\ ] ] since the integral of a density is  1 .",
    "thus @xmath322 .    a similar argument",
    "is used for the left - hand derivative . in this case , the true density of @xmath760 given @xmath764 is @xmath765 , where @xmath766 does not involve the parameters .",
    "we now have @xmath767- p[l_2^{\\psi}(v,\\delta , z)|y=\\zeta_0]}\\mbox{\\hspace{1.0cm}}&&\\\\ & = & \\int\\left [ l_1^{\\psi_0}(v , d , z )   -l_2^{\\psi_0}(v , d , z)\\right]\\ell_2(v , d , z)\\ell_0^{-}(v , d , z)d\\mu(v , d , z)\\\\ & = & -\\int\\log\\left[\\frac{\\ell_2\\ell_0^{-}}{\\ell_1\\ell_0^{-}}\\right ] \\ell_1\\ell_0^{-}d\\mu \\;\\;>\\;\\;-\\log\\int\\left[\\frac{\\ell_2\\ell_0^{-}}{\\ell_1\\ell_0^{-}}\\right ] \\ell_1\\ell_0^{-}d\\mu\\\\ & = & \\log\\int\\ell_2(v , d , z)\\ell_0^{-}(v , d , z)d\\mu(v , d , z)\\;\\;=\\;\\;0,\\end{aligned}\\ ] ] and thus we conclude that @xmath321.@xmath332    _ proof of lemma  [ l7 ] .",
    "_ this follows from lemma  [ l6 ] , the local concavity of @xmath299 , and the smoothness of the derivatives involved.@xmath332    _ proof of lemma  [ l8 ] . _ note that @xmath768 @xmath769,\\ ] ] where @xmath770 .",
    "the classes @xmath771 for any @xmath291 , and @xmath772 , for some @xmath326 , can be shown to be donsker .",
    "that this holds for the second class follows from arguments similar to those used in the proof of lemma  [ l.t1.1 ] . for the first class , note that @xmath773 . since @xmath774 , @xmath270 can be written as the difference between two monotone increasing functions , each with total variation bounded by @xmath775 . by theorem  2.7.5 of @xcite ,",
    "the class of all monotone functions with a given compact range is universally donsker . since sums of donsker classes are donsker , we have that the class @xmath776 is donsker . that the first class is donsker now follows since products of bounded donsker classes are donsker .",
    "since we also have that @xmath777 converges to a gaussian process , we have that @xmath778\\ ] ] converges weakly in @xmath329 to the tight gaussian process @xmath779,\\ ] ] where @xmath780 is the brownian bridge measure .    by the smoothness of the functions and derivatives involved",
    ", we also have @xmath781-\\right.$ ] @xmath782 @xmath783\\;\\;=\\;\\;$ ] @xmath784e^{-\\gamma(t ) } -p[w(t;\\theta_0)]e^{-\\gamma_0(t)}\\right\\}$ ] @xmath785+\\epsilon_n(\\zeta,\\lambda ) \\equiv-\\int_0^{\\tau}\\tilde{c}(t;\\zeta,\\lambda)d{\\cal z}_n(t)+ \\epsilon_n(\\zeta,\\lambda)$ ] , where @xmath786 @xmath787 .",
    "the fact that the class of functions @xmath788 has uniformly bounded total variation yields asymptotic linearity and normality of @xmath789 , and the desired result follows.@xmath332    _ proof of theorem  [ t.l9 ] .",
    "_ by lemma  [ l8 ] , @xmath790 combining this with lemma  [ l7 ] , we obtain @xmath791 @xmath792 thus the first part of the lemma is proved .",
    "for the second part , denote @xmath793 . by arguments similar to those used in the proof of lemma  [ l.t1.1 ]",
    ", we can verify that for some @xmath794 , @xmath795 is donsker .",
    "moreover , the continuity of the functions involved also yields that , as @xmath796 , @xmath797 .",
    "thus @xmath798 note also that @xmath333 implies that @xmath799 .",
    "thus , since @xmath800 , ( [ l9.e1 ] )  implies @xmath801 @xmath802 where @xmath803 denotes a term bounded in probability uniformly over the set @xmath34 . by lemma  [ l4 ] , we know that there exists a constant @xmath804 such that @xmath805 as @xmath806 .",
    "hence @xmath807 , and we obtain the second conclusion of the lemma .    for the third part , we have @xmath808}\\left| { \\mathbb{p}}_n w(t;\\hat{\\theta}_n)-pw(t;\\hat{\\theta}_n ) \\right|=\\sqrt{n}\\sup_{t\\in[0,\\tau]}|({\\mathbb{p}}_n - p)w(t;\\theta_0)|+o_p(1)\\ ] ] @xmath809 and @xmath810}|pw(t;\\hat{\\theta}_n)- pw(t;\\theta_0)|=o_p(1)$ ] by the first two parts of this lemma . hence @xmath810 } \\left|{\\mathbb{p}}_n w(t;\\hat{\\theta}_n)-pw(t;\\theta_0)\\right|=o_p(1)$ ] .",
    "the result now follows by the lipschitz continuity of @xmath811 over strictly positive compact intervals.@xmath332    _ proof of lemma  [ l10 ] . _",
    "the first inequality follows from the definitions . for the second inequality , we use a taylor s expansion around @xmath276 to obtain @xmath812 @xmath813 for some",
    "@xmath814 $ ] , where @xmath815 ; @xmath816 ; @xmath817 ; and , for any @xmath236 , @xmath818 .",
    "the score term is zero by definition of the npmle , and the second term has absolute value bounded by @xmath819 , where @xmath820 is bounded in probability by the uniform consistency of @xmath821 and by the form of the information terms listed in section  5.2 .",
    "now , letting @xmath822 , we have @xmath823 @xmath824\\right\\}\\nonumber\\end{aligned}\\ ] ] @xmath825 $ ] , where @xmath826e^{\\beta_0'z(s)}\\\\ & & -\\left[\\dot{g}(h_2^{\\psi_{n , t}}(v ) ) -\\delta\\frac{\\ddot{g}(h_2^{\\psi_{n , t}}(v))}{\\dot{g}(h_2^{\\psi_{n , t}}(v ) ) } \\right]e^{\\beta_0'z(s)+\\alpha_0+\\eta_0'z_2(s)}\\end{aligned}\\ ] ] and @xmath827\\right)$ ] , for some @xmath814 $ ] , by the mean value theorem . by the conditions given in section  2 , we have that there is a constant @xmath828 such that @xmath829 with probability  1 for all @xmath342 .",
    "thus the absolute value of  ( [ l10.e1 ] ) is bounded above by @xmath830 .",
    "this last statement follows because @xmath831 , @xmath832 , and @xmath833 by theorem  [ t.l9 ] .",
    "now the desired result follows.@xmath332    _ proof of lemma  [ l11 ] .",
    "_ note first that @xmath834\\times \\left[l_1^{\\psi_0}-l_2^{\\psi_0}\\right](v,\\delta , z)\\right\\}.\\ ] ] denote @xmath835(v,\\delta , z)$ ] , and note that @xmath836 almost surely for a fixed constant @xmath837 .",
    "thus @xmath838 serves as an envelope for the class of functions @xmath839\\tilde{h}:|\\zeta-\\zeta_0|\\leq\\epsilon\\},\\ ] ] for each @xmath291 . note that by the assumptions on the density @xmath87 in a neighborhood of @xmath86 , we have for some @xmath339 that there exists @xmath840 such that @xmath841\\leq k_{\\ast\\ast}\\epsilon$ ] for all @xmath341 .",
    "thus the bracketing entropy @xmath842}(u\\|f_{\\epsilon}\\|_{p,2},{\\cal f}_{\\epsilon},l_2(p))\\leq o\\left(\\frac{\\epsilon}{u^2\\tilde{p}(\\epsilon)}\\right)\\leq o\\left(\\frac{1}{c_{\\ast}u^2}\\right),\\ ] ] for all @xmath661 and @xmath341 ; and thus , by theorem  2.14.2 of @xcite , there exists a @xmath843 such that @xmath844 for all @xmath341 .",
    "the result now follows for @xmath845.@xmath332    _ proof of theorem  [ t3 ] .",
    "_ we can deduce from section  3 that @xmath846(v,\\delta , z)\\right\\}\\\\ & \\mbox{\\hspace{0.5cm}}=&n^{-1}q_n(u)+\\hat{e}_n(u),\\;\\;\\;\\;\\mbox{where}\\end{aligned}\\ ] ] @xmath847(v,\\delta , z)\\right\\}$ ] . by arguments similar to those used in the proof of lemma  [ l10 ]",
    ", we can obtain constants @xmath848 such that @xmath849 almost surely , for @xmath228 .",
    "hence @xmath850 by arguments given in the proof of lemma  [ l11 ] , we know that @xmath851 since also @xmath852 by condition b2(i ) , we now have that @xmath853 .",
    "the desired result now follows.@xmath332    _ proof of theorem  [ t4 ] . _",
    "fix @xmath236 .",
    "we first establish that @xmath854 @xmath855 converges weakly to @xmath856 , on @xmath857 , where @xmath858 and @xmath859 are independent , for each fixed @xmath860 , and @xmath859 is mean zero gaussian with variance @xmath861 $ ] .",
    "accordingly , fix @xmath363 , and let @xmath862 be a finite collection of points and @xmath863 be arbitrary real numbers .",
    "our plan is to first show that the characteristic function of @xmath864 converges to that of @xmath865 times that of @xmath859 .",
    "since the choice of points @xmath866 is arbitrary , this will imply convergence of all finite - dimensional distributions .",
    "we will then show that @xmath867 is asymptotically tight , and this will imply the desired weak convergence .",
    "let @xmath868 , @xmath869 ; and @xmath870(v_i,\\delta_i , z_i)$ ] and @xmath871 , @xmath50 .",
    "in other words , @xmath872 is the score contribution from the @xmath125th observation .",
    "thus @xmath873 + \\tilde{q}{\\cal z}^n(h)\\right\\}\\right]}\\mbox{\\hspace{1.0in}}&&\\label{t4.e1}\\\\ & = & \\prod_{k=1}^n p\\left[\\exp\\left\\{\\sum_{j=1}^j i q_ji_{nj}(y_k)f_k\\right\\ } e^{i\\tilde{q}{\\cal z}_k/\\sqrt{n}}\\right].\\nonumber\\end{aligned}\\ ] ] however , using the facts that @xmath874 when only one of the @xmath875 s differs from zero and @xmath876 when @xmath618 is dichotomous , we have @xmath877 . combining this with condition  b2 and the boundedness of @xmath878 and @xmath879",
    ", we obtain @xmath880 $ ] @xmath881\\\\ & & + o(n^{-1})\\\\ & = & 1+n^{-1}\\left[-\\frac{\\tilde{q}^2\\tilde{\\sigma}_h^2}{2 } + \\tilde{h}(\\zeta_0)\\sum_{j=1}^j(u_j - u_{j-1})\\{\\phi^+(q_j)-1\\}\\right ] + o(n^{-1}),\\end{aligned}\\ ] ] where @xmath882 denotes a quantity going to zero uniformly over @xmath883 .",
    "thus the right - hand side of  ( [ t4.e1 ] ) is @xmath884,\\ ] ] which is precisely @xmath885.\\ ] ] thus the finite dimensional distributions converge as desired .",
    "we next need to verify that @xmath867 is asymptotically tight on  @xmath886 $ ] . since there exists a constant @xmath837 such that @xmath887 , for all @xmath888 .",
    "thus we are done if we can show that @xmath889 is tight on @xmath886 $ ] . to this",
    "end , fix @xmath888 .",
    "now , the expectation of @xmath890 is @xmath891 is monotone .",
    "we have now established that @xmath892 converges weakly to @xmath856 , on @xmath857 , where @xmath858 and @xmath859 are independent , for each fixed @xmath860 .",
    "similar arguments also yield the weak convergence of @xmath893 to @xmath894 , on @xmath857 , where @xmath895 and @xmath859 are again independent , for each fixed @xmath860 .",
    "thus also @xmath896 converges weakly to @xmath897 , on @xmath857 , where @xmath392 and @xmath859 are independent , for each fixed @xmath860 .",
    "since @xmath444 , the argmax continuous mapping theorem ( theorem  3.2.2 of @xcite ) now yields that @xmath898 converges weakly to @xmath899 , with the desired asymptotic independence .",
    "the remaining results follow.@xmath332    _ proof of theorem  [ t5 ] .",
    "_ we have @xmath900 where the index set for the score terms is @xmath222 . by arguments similar to those used in the proof of theorem  [ t.l9 ] , combined with the fact that @xmath444 , we have that both @xmath901 and @xmath902 . thus @xmath903 .",
    "we also have that @xmath904 combining this with lemma  [ l4 ] , the z - estimator master theorem ( theorem  3.3.1 of @xcite ) now yields the desired results.@xmath332    _ proof of corollary  [ c1 ] . _",
    "we first derive the unconditional limiting distribution of @xmath905 . if a class of measurable functions @xmath906 is @xmath75-glivenko - cantelli with @xmath907 , then the class @xmath908 , where @xmath909 denotes a generic version of one of the weights @xmath910 , is also @xmath75-glivenko - cantelli , by theorem  3 of @xcite .",
    "thus we can apply the results of theorem  [ t1 ] , with only minor modification , combined with the simple fact that @xmath911 almost surely , to yield that @xmath912 outer almost surely .",
    "note that the proof is made somewhat easier than before since we already know @xmath913 almost surely .",
    "furthermore , if a class of measurable functions  @xmath906 is @xmath75-donsker with @xmath907 , then the multiplier central limit theorem ( theorem  2.9.2 of @xcite ) yields that the class @xmath914 is also @xmath75-donsker .",
    "hence we can apply the results of theorem  [ t4 ] , with only minor modification , to yield that @xmath905 is asymptotically linear with influence function @xmath915 , @xmath522 .",
    "the factor @xmath916 occurs because the information operator for the weighted version of the likelihood is @xmath917 .",
    "we now have that @xmath918 , unconditionally .    finally , the conditional multiplier central limit theorem ( theorem  2.9.6 of @xcite ) yields part  ( ii ) of the theorem .",
    "the factor @xmath919 arises because @xmath920 .",
    "similar arguments establish  ( i ) by using parallel glivenko - cantelli and donsker results for the nonparametric bootstrapped empirical process.@xmath332    _ proof of lemma  [ s9.l1 ] .",
    "_ let @xmath921 denote the baseline measure and @xmath922 , @xmath923 the density function under @xmath556 and @xmath75 respectively . in the general situation , verifying  ( [ c8.e1 ] ) is equivalent to finding a function @xmath249 such that : @xmath924 ^ 2d\\mu(x)}&&\\\\ & = & \\int \\left [ \\frac{\\rho_n(x)^{1/2}-\\rho(x)^{1/2 } } { 1/\\sqrt{n } } - \\frac{1}{2}h(x)\\rho(x)^{1/2 } \\right]^2 d \\mu(x)\\\\ & \\rightarrow & \\int \\left [ \\frac{1}{2 }   \\frac{\\dot { \\rho}(x)}{(\\rho(x))^{1/2}}- \\frac{1}{2}h(x)\\frac{\\rho(x)}{(\\rho(x))^{1/2 } } \\right]^2 d\\mu(x)\\\\ & = & \\int \\left [ \\frac{1}{2 } \\frac{\\dot{\\rho}(x ) } { \\rho(x)}(\\rho(x))^{1/2 } -\\frac{1}{2}h(x)(\\rho(x))^{1/2 }",
    "\\right]^2 d\\mu(x)\\\\ & = & 0.\\end{aligned}\\ ] ] hence the given score function satisfies  ( [ c8.e1 ] ) by the smoothness of the log - likelihood.@xmath332    _ proof of lemma  [ s9.l2 ] . _ note that a consequence of the donsker theorem for contiguous alternatives ( theorem  3.10.12 of @xcite ) is that for any bounded @xmath75-donsker class @xmath906 , @xmath925 .",
    "thus the proof of lemma  [ l2 ] can be reconstituted to yield that @xmath926}$ ] is bounded in probability under @xmath556 , since all of the classes of functions involved are bounded @xmath75-donsker classes .",
    "we can similarly modify the proof of theorem  [ t1 ] to yield the desired results since , once again , the only classes of functions involved are bounded and @xmath75-donsker .",
    "this is true , in particular , for the key class given in lemma  [ l.t1.1 ] , for any @xmath292 .",
    "thus @xmath927.@xmath332    _ proof of theorem  [ s9.t1 ] . _ the basic idea of the proof is to use the donsker theorem for contiguous alternatives in combination with key arguments in the proof of theorem  [ t5 ] and the form of the score and information operators under model c2. pursuing this course , we obtain for any @xmath928 , @xmath929^{-1 } \\sigma_{\\ast}^{21}(\\zeta)\\left(\\begin{array}{c}h_1\\\\h_2 \\end{array}\\right)\\right)\\right]+o_{p_n}^{[a , b]}(1)\\\\ & \\equiv&\\sqrt{n}{\\mathbb{p}}_n h_{\\ast}(\\zeta)+o_{p_n}^{[a , b]}(1),\\end{aligned}\\ ] ] where @xmath930 denotes a quantity going to zero in probability , under @xmath556 , uniformly over the set @xmath34 . now the donsker theorem for contiguous alternatives yields that the right - hand side converges to a tight , gaussian process with covariance @xmath931 $ ] , for all @xmath569 $ ] , and mean @xmath932 $ ] . note that we only need to compute the moments under the null distribution  @xmath75 .",
    "careful calculations verify that this yields the desired results.@xmath332    _ proof of corollary  [ c2 ] . _",
    "the limiting results under @xmath556 follow from theorem  [ s9.t1 ] and the continuous mapping theorem , provided we can show that @xmath933,v\\in{\\mathbb{r}}^{q+1}:\\|v\\|=1}v'v_{\\ast}(\\zeta)v&>&0 .",
    "\\label{e1.m9}\\end{aligned}\\ ] ] the limiting null distribution results will similarly follow from the fact that under the null distribution  @xmath75 , @xmath934 for all @xmath244 $ ] . note that in both the null and alternative settings , @xmath935 only depends on the null limiting distribution .",
    "it is sufficient to verify that @xmath936 is one - to - one for all sequences @xmath937 $ ] and @xmath938 .",
    "note that we can ignore any differences between @xmath86 and @xmath169 in calculating @xmath939 because of the non - identifiability of @xmath169 under the null hypothesis , ie .",
    ", @xmath939 is constant .",
    "assume now that there exists sequences @xmath937 $ ] and @xmath938 such that @xmath940 .",
    "we will now show that this forces @xmath941 . without loss of generality",
    ", we can assume @xmath942 and @xmath943 .",
    "since the map @xmath944 is continuous and since @xmath945 is cadlag , we can further assume without loss of generality that either @xmath946 or that @xmath947 ( the @xmath948 denotes that we are converging to @xmath949 from below ) .",
    "the arguments for either case are the same , so we will for brevity only give the proof for the first case .    by the arguments surrounding expressions  ( [ c12:e9 ] ) , ( [ c12:e11 ] ) and  ( [ c12:e12 ] ) , combined with the non - identifiability of @xmath169 under the null model",
    ", we obtain that expression  ( [ c12:e12 ] ) must now hold for all @xmath950 $ ] but with @xmath949 replacing @xmath86 . in ortherwords ,",
    "@xmath951 , almost surely , for all @xmath950 $ ] . since var@xmath952\\geq\\mbox{var}[z(t_4)|y > b ] \\times{\\mbox{p}\\left[y > b\\right]}/{\\mbox{p}\\left[y>\\zeta_{\\ast}\\right]}$ ] is positive definite by condition  b4 , we have @xmath953",
    ". we can similarly use  b4 to verify that var@xmath954 $ ] is positive definite and thus @xmath955 .",
    "now @xmath956 and @xmath957 easily follow .",
    "hence @xmath944 is uniformly one - to - one in a manner which yields the conclusion  ( [ e1.m9]).@xmath332    _ proof of theorem  [ s9.t2 ] . _",
    "the results follow from arguments similar to those used in the proof of theorem  [ s9.t1 ] , but based on the conditional multiplier central limit theorem for contiguous alternatives , theorem  [ s9.t2.t1 ] below.@xmath332    [ s9.t2.t1 ] ( conditional multiplier central limit theorem for contiguous alternatives ) let @xmath906 be a @xmath75-donsker class of measurable functions , and let @xmath556 satisfy @xmath958^{1/2}\\rightarrow 0\\label{s9.t2.t1.e1},\\ ] ] as @xmath420 , for some real valued , measurable function @xmath249 .",
    "also assume @xmath959 @xmath960 for all @xmath961 , and that the multipliers in the weighted bootstrap , @xmath481 , are i.i.d . and independent of the data , with mean @xmath482 and variance @xmath483 , and with @xmath484 .",
    "then @xmath962 in @xmath963 , where @xmath780 is a tight , mean zero brownian bridge process .",
    "_ the detailed proof can be found in chapter  11 of kosorok ( to appear ) .",
    "we now present a synopsis of the proof .",
    "let @xmath964 , @xmath50 , and note that @xmath965 where @xmath966 is the dirac measure of the observation @xmath967 . since @xmath906 is @xmath75-donsker , we also have that @xmath968 is @xmath75-donsker .",
    "thus by the unconditional multiplier central limit theorem , we have that @xmath969 is also @xmath75-donsker .",
    "now , by that fact that @xmath970 ( trivially ) combined with the central limit theorem under contiguous alternatives , we have that both @xmath971 and @xmath972 $ ] in @xmath963 . thus the last two terms in  ( [ s9.t2.t1.e3])@xmath973 , and hence @xmath974 in @xmath963 .",
    "this now implies the unconditional asymptotic tightness and desired asymptotic measurability of @xmath975 .",
    "fairly standard arguments can now be used along with the given pointwise uniform square integrability condition to verify that @xmath976 applied to any finite dimensional collection @xmath977 converges under @xmath556 in distribution , conditional on the data , to the appropriate limiting gaussian process .",
    "this now implies @xmath978.@xmath332    _ proof of corollary  [ c3 ] . _",
    "assume at first that @xmath544 is a fixed number @xmath979 .",
    "theorem  [ s9.t2 ] now yields that the collection @xmath980 converges jointly , conditionally on the data , to @xmath981 i.i.d .",
    "copies of @xmath567 .",
    "thus @xmath548 converges weakly to the sample covariance process ( divided by @xmath544 instead of @xmath982 ) of an i.i.d .",
    "sample of @xmath544 copies of @xmath567 .",
    "the same result holds true if we allow @xmath544 to go to  @xmath983 slowly enough",
    ". since the gaussian processes involved are tight , @xmath548 will thus be consistent for @xmath984 , uniformly over @xmath244 $ ] .",
    "similar arguments yield pointwise consistency of @xmath985 and @xmath986 at continuity points of @xmath987 and @xmath988 . since it is not hard to verify that both @xmath987 and @xmath988 have continuous distributions , the pointwise consistency extends to the desired uniform consistency.@xmath332",
    "the authors thank editor morris eaton , an associate editor , and two referees for their extremely careful review and helpful suggestions that led to an improved paper ."
  ],
  "abstract_text": [
    "<S> we consider linear transformation models applied to right censored survival data with a change - point in the regression coefficient based on a covariate threshold . we establish consistency and weak convergence of the nonparametric maximum likelihood estimators . </S>",
    "<S> the change - point parameter is shown to be @xmath0-consistent , while the remaining parameters are shown to have the expected root-@xmath1 consistency . </S>",
    "<S> we show that the procedure is adaptive in the sense that the non - threshold parameters are estimable with the same precision as if the true threshold value were known . </S>",
    "<S> we also develop monte - carlo methods of inference for model parameters and score tests for the existence of a change - point . </S>",
    "<S> a key difficulty here is that some of the model parameters are not identifiable under the null hypothesis of no change - point . </S>",
    "<S> simulation studies establish the validity of the proposed score tests for finite sample sizes . </S>"
  ]
}