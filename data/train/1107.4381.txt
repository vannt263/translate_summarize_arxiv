{
  "article_text": [
    "association of two random variables @xmath7 and @xmath8 has been thoroughly investigated in the statistical literature but much less work concerns association of two random vectors @xmath9 and @xmath10 . in the classical statistical framework of multivariate normality and linear correlation the theory of canonical correlation ( see @xcite ) and the socalled rv coefficient ( see @xcite and @xcite )",
    "are well known and often applied , in particular in the natural sciences .    the focus of our application , however , is financial data which is notoriously non - normal .",
    "it has further been pointed out ( see @xcite ) that linear correlation might be inappropriate to measure the strength of association of financial data .",
    "finally the above mentioned measures are not capable of distinguishing between positive and negative association which is a must in dealing with financial data .",
    "the recently introduced distance correlation ( see @xcite and @xcite ) suffers from similar weaknesses .",
    "further it depends on the marginal distributions of @xmath11 and @xmath12 and requires moment restrictions .",
    "this should be considered as a disadvantage in application to financial data ( see again @xcite and @xcite ) .",
    "the increasing use of copulas in the analysis and modeling of financial data suggests the development of copula based measures of association .",
    "concerning association _ within _",
    "one vector @xmath13 there exist various such measures ( see @xcite for a recent survey ) . in this paper , we propose copula based measures of association _ between _ two vectors @xmath14 and @xmath15 they are invariant with respect to marginal distributions as association is solely determined by the joint copula of @xmath11 and @xmath12",
    ". therefore distributional assumptions ( beside continuity ) as well as moment restrictions are not necessary .",
    "the measures are further capable of measuring negative association .",
    "the measures are defined in such a way that they reduce to spearman s rank correlation coefficient for @xmath16 instead of spearman s coefficient , other measures , such as kendall s coefficient , could have been used .",
    "the details of this approach are very similar and are omitted .",
    "note that it is not the aim of this paper to derive tests for independence of @xmath11 and @xmath12 ( see @xcite , @xcite and @xcite for recent contributions ) . on the contrary",
    "the focus is measurement of type and strength of association in the case where @xmath11 and @xmath12 are dependent .",
    "the structure of the paper is as follows : in section [ sec.notdef ] , we describe the notation and terminology used within the paper . in section [ sec.popver ] , we state population versions of the five copula based measures of association and derive some of their properties . for convenience ,",
    "some calculations are collected in the appendix .",
    "estimators for the measures are introduced in section [ sec.empest ] .",
    "their finite sample properties are analysed in a simulation study .",
    "matlab code for the estimators is available on request .",
    "section [ sec.empex ] contains an empirical example with financial data , illustrating the usefulness of the new measures .",
    "section [ sec.concl ] concludes .",
    "let @xmath14 and @xmath17 be random vectors of dimensions @xmath18 and @xmath19 , respectively , defined on the same probability space . throughout the paper we assume that the marginal distribution functions @xmath20 for @xmath21 and @xmath22 for @xmath23",
    "are continuous functions .",
    "therefore , according to the theorem of @xcite there exists a unique copula @xmath24 ^{p+q}\\longrightarrow \\left [ 0,1\\right]$ ] with @xmath25 for @xmath26 and @xmath27 .",
    "extensive portrayals of copulas are given in @xcite , @xcite and @xcite .",
    "let @xmath28and@xmath29 the copula @xmath30 is the joint distribution function of @xmath31 .",
    "the marginal copulas of @xmath11 and @xmath12 are given by @xmath32  and @xmath33 for @xmath34 ^{p}$ ] and @xmath35 ^{q}$ ] . here ,",
    "@xmath36 and @xmath37 denote vectors of ones of length @xmath18 and @xmath19 , respectively . by construction ,",
    "@xmath38 and @xmath39 are the marginal distribution functions of @xmath40 and @xmath41 , respectively .",
    "this section introduces population versions of five copula based measures of association between random vectors @xmath11 and @xmath12 .",
    "the simplest measure of association between @xmath11 and @xmath12 is the mean of all bivariate associations of @xmath42 and @xmath43 for  @xmath21  and  @xmath23 ,  i.e. , @xmath44where @xmath45 is spearman s rho of @xmath42 and @xmath43 .",
    "note that @xmath46 is copula based because of@xmath47 } \\int_{\\left[0,1\\right ] } c_{ij}\\left ( u_{i},v_{j}\\right ) \\",
    ", du_{i } \\ , dv_{j}-3\\ ] ] and @xmath48 is the marginal copula of @xmath42 and @xmath43 ( see @xcite ) .",
    "the properties of @xmath49 are easy to derive and follow directly from its definition .    1 .",
    "we have @xmath50 and the measure is invariant with respect to permutations within @xmath11 and @xmath12 .",
    "2 .   @xmath51 if and only if @xmath52 for every combination of @xmath53 and @xmath54 , i.e. , @xmath42 and @xmath43 are countermonotonic for all @xmath53 and @xmath54 .",
    "this implies that @xmath55for a random variable @xmath7 and strictly increasing functions @xmath56 and strictly decreasing functions @xmath57 , and it follows that @xmath58 3 .",
    "@xmath59 if and only if @xmath60 for every combination @xmath21  and  @xmath23 . here ,",
    "@xmath42 and @xmath61 are comonotonic for all @xmath53 and @xmath54 .",
    "this implies that@xmath55for strictly increasing functions @xmath56 and @xmath57 for a random variable @xmath7 .",
    "the copula @xmath30 is then @xmath62 + for given and fixed marginal copulas @xmath38 and @xmath39 it is in general not possible to find a copula @xmath30 with @xmath63  and  @xmath64 which entails @xmath65  or  @xmath66 the latter cases are only possible in the special cases  @xmath67  and  @xmath68 4 .",
    "if @xmath42 and @xmath43 are independent for all combinations @xmath21  and  @xmath23 then @xmath69 .",
    "the converse is not true as there may be some @xmath45 different from zero , but @xmath70 : + consider two 2-dimensional random vectors @xmath71 and @xmath72 with the following matrix of spearman s rank correlations : @xmath73 choosing , for example , @xmath74 and @xmath75 , the matrix @xmath76 is positive semi - definite and thus a correlation matrix . in this case , the random vectors @xmath4 and @xmath5 are clearly dependent , whereas the mean of the pairwise associations is equal to @xmath77 5",
    ".   association as measured by @xmath78 can be decomposed into two parts that describe the association within and between the two random vectors .",
    "let @xmath79 and let @xmath80 denote total association _ within _",
    "@xmath81 defined by @xmath82 where @xmath83 denotes spearman s rho of @xmath84 and @xmath85 .",
    "then @xmath86 note that@xmath87    this property might be useful since decomposition of @xmath80 into a between and within part can be interesting in analysing financial data .",
    "the vectors @xmath11 and @xmath12 are independent if and only if @xmath88 for @xmath89 ^{p}$ ] and @xmath90 ^{q}$ ] .",
    "equivalently , @xmath11 and @xmath12 are independent if and only if @xmath91for  @xmath89 ^{p}$ ] and @xmath92 ^{q}$ ] .",
    "therefore , we may measure the distance of @xmath30 to the independence case of @xmath4 and @xmath5 by @xmath93^p } \\int_{\\left[0,1\\right]^q } \\left(c\\left ( \\mathbf{u},\\mathbf{v}\\right ) -a\\left ( \\mathbf{u}\\right ) b\\left ( \\mathbf{v}\\right)\\right ) \\",
    ", d\\mathbf{v } \\ , d\\mathbf{u}.\\]]this expression is equal to @xmath94where @xmath95for @xmath89 ^{p}$ ]  and  @xmath90 ^{q}$ ] ( see appendix i for a proof ) .",
    "the covariance is bounded by the product of the respective standard deviations .",
    "thus , a measure of association between @xmath11 and @xmath12 which is bounded by @xmath96 and @xmath97 is@xmath98the variances may be expressed by @xmath99^p } \\int_{\\left[0,1\\right]^p } \\left ( a\\left ( \\mathbf{u}\\wedge \\mathbf{u}^{\\prime } \\right ) -a\\left ( \\mathbf{u}\\right ) a\\left ( \\mathbf{u}^{\\prime } \\right ) \\right ) d\\mathbf{u}^{\\prime } d\\mathbf{u},\\]]analogously for @xmath100 ( see appendix i for a derivation ) . by @xmath101",
    "we denote the component wise minimum of @xmath102 and @xmath103 .",
    "the measure @xmath104 is based on the covariance of @xmath40 and @xmath41 transformed by the functions @xmath105 and @xmath106 an alternative approach is to transform @xmath40 and @xmath41 by their respective distribution functions @xmath38 and @xmath39 ( see @xcite ) and consider the measure of association defined by@xmath107 it is shown in appendix i that @xmath108^p } \\int_{\\left[0,1\\right]^q } \\left ( \\overline{c}\\left ( \\mathbf{u},\\mathbf{v}\\right ) -\\overline{a}\\left ( \\mathbf{u}\\right ) \\overline{b}\\left ( \\mathbf{v}\\right ) \\right ) \\ , db\\left ( \\mathbf{v}\\right ) \\ , da\\left ( \\mathbf{u}\\right)\\]]and @xmath109^p } \\int_{\\left[0,1\\right]^q } \\left ( \\overline{a}\\left ( \\mathbf{u}\\vee \\mathbf{u}^{\\prime } \\right ) -\\overline{a}\\left ( \\mathbf{u}\\right ) \\overline{a}\\left ( \\mathbf{u}^{\\prime } \\right ) \\right ) \\ , da\\left ( \\mathbf{u}\\right ) \\ , da\\left ( \\mathbf{u}^{\\prime } \\right)\\]]with an analogous expression for @xmath110 by @xmath111 : = @xmath112 @xmath113 we denote component wise maximum of @xmath102 and @xmath103 .",
    "the properties of @xmath104 and @xmath114 are as follows :    1 .",
    "we have @xmath115 and @xmath116 and the measures are invariant with respect to permutations within @xmath11 and @xmath12 .",
    "if the vectors @xmath11 and @xmath12 are independent , @xmath117 and @xmath118 again , the converse is not true .",
    "measures @xmath104 and @xmath114 are in general not capable to achieve @xmath119 or @xmath96 for given and fixed arbitrary copulas @xmath38 and @xmath39 of @xmath11 and @xmath120 to calculate the maximal and minimal values of , for example , @xmath121 for given copulas @xmath38 and @xmath39 we have to maximise and minimise @xmath121 over all random vectors @xmath122 where the copula of @xmath11 is @xmath38 and the one of @xmath12 is @xmath39 . for fixed @xmath38 and @xmath39 ,",
    "the only term in the definition of @xmath121 that can vary is @xmath123^{p+q } } c(\\textbf{u},\\textbf{v } ) \\,d\\textbf{u } \\,d\\textbf{v } & = & e \\left [ \\pi_p ( \\textbf{u } ) \\pi_q ( \\textbf{v } ) \\right ] \\\\ & = & \\int_{[0,1]^2 } p \\left [ \\pi_p ( \\textbf{u } ) > s,\\pi_q ( \\textbf{v } ) > t   \\right ] \\ , ds \\ , dt.\\end{aligned}\\ ] ] the joint survival function of @xmath124 and @xmath125 will be maximal ( minimal ) if they are comonotone ( countermonotone ) : @xmath126^{p+q } } c(\\textbf{u},\\textbf{v } ) \\,d\\textbf{u } \\,d\\textbf{v }   \\\\",
    "\\ge \\int_{[0,1]^2 } \\max \\left ( p \\left [ \\pi_p ( \\textbf{u } ) > s \\right ] + p \\left [ \\pi_p ( \\textbf{v } ) > t \\right ] -1,0\\right ) \\ , ds \\ , dt,\\end{gathered}\\ ] ] @xmath126^{p+q } } c(\\textbf{u},\\textbf{v } ) \\,d\\textbf{u } \\,d\\textbf{v }   \\\\ \\le \\int_{[0,1]^2 } \\min \\left ( p \\left [ \\pi_p ( \\textbf{u } ) > s \\right ] , p \\left [ \\pi_p ( \\textbf{v } ) > t \\right ] \\right ) \\ , ds \\ , dt.\\end{gathered}\\ ] ] + consider two 2-dimensional random vectors @xmath127 and @xmath128 with copulas @xmath129 and @xmath130 , where @xmath131 is the independence copula and @xmath132 the countermonotone copula . in this case",
    "+ @xmath133 & = & p \\left [ ( 1-u_1)(1-u_2 ) > s \\right ] \\nonumber \\\\      & = & \\int_{0}^{1-s } p \\left ( u_2 < \\left .",
    "\\frac{1-s - u_1}{1-u_1 } \\right| u_1 = u_1 \\right ) \\ , du_1 \\nonumber \\\\      & = & \\int_{0}^{1-s } \\dot{\\pi}_1 \\left(u_1 , \\frac{1-s - u_1}{1-u_1}\\right ) \\ , du_1 \\nonumber \\\\      & = & \\int_{0}^{1-s } \\frac{1-s - u_1}{1-u_1 } \\ , du_1 \\nonumber \\\\      & = & 1 - s + s \\log(s),\\end{aligned}\\ ] ] + and @xmath134 & = & p \\left [ ( 1-v_1)(1-v_2 ) > t \\right ] \\nonumber \\\\   & = & p \\left [ ( 1-v_1 ) v_1 > t \\right ] \\\\   & = &    2 \\sqrt { \\max \\left\\ { \\frac{1}{4 } - t,0\\right\\}}.\\end{aligned}\\ ] ] the upper bound is given by @xmath135 ^ 4 } c(\\mathbf{u},\\mathbf{v } ) \\,d\\textbf{u } \\,d\\textbf{v }   \\nonumber \\\\   & \\le \\int_{[0,1]^2 } \\min \\left ( p \\left [ \\pi_2(\\textbf{u } > s \\right ] , p \\left [ \\pi_2 ( \\textbf{v } ) > t \\right ] \\right ) \\ , ds \\,dt \\nonumber \\\\   &   =   \\int_{[0,1]^2 } \\min \\left ( 1 -s + s \\log(s ) , 2 \\sqrt { \\max \\left\\ { \\frac{1}{4 } - t,0\\right\\ } }   \\right ) \\ , ds \\,dt \\nonumber \\\\   &   = \\frac{767}{13824 } \\approx 0.0555\\end{aligned}\\ ] ] thus , the maximal association between @xmath4 and @xmath5 in terms of @xmath104 is @xmath136 ^ 4 } \\left ( c(u , v ) - \\pi ( u )",
    "w(v ) \\right ) \\ , du \\,dv}{\\sqrt { { \\operatorname{var}}\\pi_2(\\textbf{u } ) { \\operatorname{var}}\\pi_2 ( \\textbf{v } ) } } \\nonumber\\\\ & \\le & \\frac{\\frac{767}{13824 } - \\frac{1}{4}\\frac{1}{6}}{\\sqrt { \\frac{1}{30 } - \\frac{1}{36 } } \\sqrt { \\frac{1}{9 } - \\frac{1}{16 } } } \\nonumber\\\\ & \\approx & 0.8408\\end{aligned}\\ ] ] + note that similar examples can be given for @xmath137      instead of applying pearson correlation to @xmath138 and @xmath139 as in @xmath104 or to @xmath140 and @xmath141 as in @xmath114 one may apply rank correlation , leading to the measures @xmath142 and @xmath143 .",
    "let @xmath144 , \\\\ k_{\\pi _ { q}\\left ( \\mathbf{v}\\right ) } ( t)&:=p\\left ( \\pi _ { q}\\left ( \\mathbf{v } \\right ) \\leqslant t\\right)\\,\\,\\,t\\in [ 0,1 ] \\end{aligned}\\ ] ] and @xmath145 , \\\\ k_{b\\left ( \\mathbf{v}\\right)}(t)&:=p\\left ( b\\left ( \\mathbf{v}\\right ) \\leqslant t\\right)\\,\\,\\,t\\in \\left [ 0,1\\right]\\end{aligned}\\ ] ] and let @xmath146  and @xmath147 , @xmath148 and @xmath149 . from @xmath150 $ ]",
    "it follows that @xmath151^p } \\int_{\\left[0,1\\right]^q } \\mathds{1}_{\\left\\ {   k_{\\pi_p(\\mathbf{u } ) } ( \\pi_p(\\mathbf{u } ) )   \\leqslant s\\right\\ } } \\mathds{1}_{\\left\\ { k_{\\pi_q(\\mathbf{v } ) } ( \\pi_q(\\mathbf{v } ) ) \\leqslant t\\right\\ } } dc\\left ( \\mathbf{u},\\mathbf{v}\\right)\\end{aligned}\\ ] ] is the joint distribution function and copula of  @xmath152  and  @xmath153 . implicitly , since @xmath154,$ ] the copula @xmath155^p } \\int_{\\left[0,1\\right]^q }",
    "\\mathds{1}_{\\left\\ { k_{a(\\mathbf{u } ) } ( a(\\mathbf{u } ) ) \\leqslant s\\right\\ } } \\mathds{1}_{\\left\\ { k_{b(\\mathbf{v } ) } ( b(\\mathbf{v } ) ) \\leqslant t\\right\\ } } dc\\left ( \\mathbf{u},\\mathbf{v}\\right)\\end{aligned}\\]]is the distribution function and copula of @xmath156 based on these copulas , we define the measures @xmath157i.e . ,",
    "spearman s rho of @xmath158 and @xmath159 and @xmath160i.e .",
    ", spearman s rho of @xmath161 and @xmath162 .",
    "note that - contrary to the case in section [ sec.pearsmeas ] - normalisation is not necessary as it is impicitly ensured .",
    "+ properties of @xmath163 and @xmath164    1 .",
    "we have @xmath165 and @xmath166 and the measures are invariant with respect to permutations within @xmath11 and @xmath12 .",
    "2 .   if @xmath11 and @xmath12 are independent then @xmath167 and thus @xmath168 .",
    "again , the converse is not true .",
    "@xmath169  is equivalent to @xmath170 and@xmath171 + @xmath172  is equivalent to @xmath173 + and@xmath174 4 .",
    "@xmath175  is equivalent to  @xmath176 and@xmath177 @xmath178  is equivalent to @xmath179 and@xmath180 5 .",
    "contrary to @xmath181 and @xmath182 , the rank correlation based measures @xmath163 and @xmath183 can achieve every value between @xmath96 and @xmath119 for any given and fixed marginal copulas @xmath38 and @xmath39 . to show this for @xmath163 and @xmath119",
    "let @xmath184 be a comonotone pair of random variables such that s has the same distribution as @xmath185 and @xmath186 has the same distribution as @xmath187 .",
    "second , conditionally on @xmath188 let @xmath189 and @xmath190 be independent random vectors whose conditional distributions are given by the one of @xmath40 given @xmath191 and the one of @xmath41 given @xmath192 respectively .",
    "now , the copulas of @xmath189 and @xmath190 are @xmath38 and @xmath39 by construction and @xmath193 due to the comonotonicity of @xmath194 analogous arguments hold for @xmath172 and @xmath195",
    "in this section we propose nonparametric estimators of the discussed measures .",
    "it is assumed that the marginal distribution functions @xmath196 and @xmath197 are unknown for @xmath21 and @xmath198    let @xmath199 be i.i.d .",
    "samples from @xmath200 let @xmath201 and @xmath202  denote the empirical distribution function of @xmath42 and @xmath43 for  @xmath21 and  @xmath198 then , for @xmath203@xmath204 and @xmath205are called the pseudo observations of@xmath206 and @xmath207 the empirical distribution function of @xmath208 for @xmath209 , i.e. , @xmath210is the empirical copula of @xmath211 ( see , e.g. , @xcite ) .",
    "the marginal empirical copulas of @xmath11 and @xmath12 are estimated by @xmath212 in the following , estimation is based on the pseudo observations @xmath213    * estimation of * @xmath214 .",
    "the estimator for @xmath49 is given by @xmath215 ^ 2 } \\widehat{c}_{ij , n}\\left ( u_{i},v_{j}\\right ) \\",
    ", du_{i } \\ , dv_{j}-3\\right ) \\\\ & = &    \\frac{1}{pq } \\sum_{i=1}^{p } \\sum_{j=1}^{q } \\left ( 12\\left ( \\frac{1}{n } \\sum_{k=1}^{n } \\left ( 1-\\widehat{u}_{ki , n}\\right ) \\left ( 1-\\widehat{v}_{kj , n}\\right ) \\right ) -3\\right ) .\\end{aligned}\\ ] ] * estimation of * @xmath181 .",
    "the estimator @xmath216 for @xmath181 is the pearson coefficient of correlation of @xmath217    * estimation of * @xmath182 .",
    "we first estimate @xmath38 and @xmath39 by @xmath218and obtain pseudo observations on @xmath219 and @xmath220 by@xmath221@xmath222 is the pearson coefficient of correlation of these pseudo observations .",
    "* estimation of * @xmath163 . in order to estimate @xmath223",
    "we first have to estimate @xmath224 by @xmath225for  @xmath226 $ ]  and similarly @xmath227 .",
    "let@xmath228and @xmath229for @xmath230 . then with @xmath231an estimator for @xmath142 is @xmath232    * estimation of * @xmath183 .",
    "the estimator @xmath233 for @xmath183 is derived in a similar way as @xmath234 let @xmath235 and @xmath236 then @xmath237 and @xmath238 for @xmath230 . for @xmath239",
    "it follows @xmath240 and thus @xmath241we have derived asymptotic normality of @xmath242 and @xmath243 using the asymptotic theory of the copula process introduced by @xcite ( see , e.g. , @xcite and @xcite for recent references ) and the functional delta method ( see , e.g. , @xcite ) .",
    "details can be obtained from the authors .",
    "the asymptotic normality of @xmath244 for @xmath245 has not yet been derived .    in the following ,",
    "the finite sample properties of @xmath242 and @xmath246 , i.e. their bias and standard deviation are investigated by a monte carlo simulation . in order to estimate the standard deviation of the estimators , we use the bootstrap and the jackknife .    for a given sample @xmath247 of i.i.d .",
    "observations , the bootstrap draws @xmath248 observations of the sample with replacement .",
    "ties are solved by mid - ranks . for @xmath39 bootstrap samples ,",
    "the standard deviation is estimated by @xmath249 where @xmath250 is the estimator of the association of the @xmath251-th bootstrap sample and @xmath252 their mean .",
    "for the jackknife estimator of the standard deviation of @xmath253 let @xmath254 denote the estimator , where the @xmath54-th observation of @xmath255 is deleted .",
    "the jackknife estimate of the standard deviation is then given by @xmath256    for the simulation study , we consider observations from the gaussian copula ( see @xcite ) and the clayton copula ( see @xcite ) with different dimensions and different sample sizes .",
    "the gaussian copula is defined by @xmath257 where @xmath258 is the distribution function of the multivariate normal distribution with zero mean , unit variances and positive definite correlation matrix @xmath259 .",
    "further , @xmath260 denotes the quantile function of the univariate standard normal distribution .",
    "the @xmath261-dimensional clayton copula ( see @xcite ) is given by @xmath262 for @xmath263 .",
    "to reduce the number of parameters in our model , we only consider the case of equi - correlation for the gaussian copula , although simulations with more complex correlation matrices show similar results .",
    "the results are based on 10,000 monte carlo simulations and @xmath264 bootstrap iterations , respectively .",
    "tables [ table : bootstrap - gaussian_rho_bar ] to [ table : bootstrap - gaussian_rho_4 ] show simulation results with the gaussian copula for @xmath78 , @xmath114 and @xmath143 for two random vectors of dimensions @xmath265 and @xmath266 and sample sizes @xmath267 @xmath268 and @xmath264 as well as different correlation parameters @xmath269 .",
    "results for the remaining measures and for the clayton copula are omitted , but can be obtained from the authors .",
    "they are , however , very similar to the results presented .",
    "the first two columns in the tables contain the value of the dependence parameters and the sample sizes .",
    "the third column of the tables shows an approximation to the true value of the measures of association , which has been derived from samples of size 1,000,000 .",
    "comparing the true values to the mean of the estimated associations @xmath270 in column 4 , we observe a small finite sample bias , which decreases with increasing sample size .",
    "the standard deviation of the estimator @xmath271 and the means of the bootstrap estimation @xmath272 and the jackknife estimation @xmath273 are shown in colums @xmath274 and @xmath275 .",
    "it can be seen that both procedures for the estimation of the standard deviation perform well for the gaussian copula . furthermore , the standard deviation of the estimator decreases with increasing sample size in a reasonable way .",
    "finally , columns @xmath276 and @xmath277 show that the standard error of the bootstrap standard deviation estimates is slightly smaller than the obtained jackknife estimates .    *",
    "9c @xmath269 & n & @xmath78 & @xmath278 & @xmath279 & @xmath272 & @xmath273 & @xmath280 & @xmath281 +   + -0.1 & 50 & -0.096 & -0.094 & 0.040 & 0.039 & 0.040 & 0.007 & 0.007 + & 100 & -0.096 & -0.095 & 0.027 & 0.028 & 0.028 & 0.003 & 0.003 + & 500 & -0.096 & -0.096 & 0.012 & 0.012 & 0.012 & 0.001 & 0.001 + 0.2 & 50 & 0.191 & 0.188 & 0.063 & 0.063 & 0.064 & 0.008 & 0.008 + & 100 & 0.191 & 0.189 & 0.045 & 0.044 & 0.045 & 0.004 & 0.004 + & 500 & 0.191 & 0.191 & 0.020 & 0.020 & 0.020 & 0.001 & 0.001 + 0.5 & 50 & 0.483 & 0.474 & 0.069 & 0.070 & 0.071 & 0.007 & 0.008 + & 100 & 0.483 & 0.479 & 0.049 & 0.049 & 0.049 & 0.004 & 0.004 + & 500 & 0.483 & 0.482 & 0.022 & 0.022 & 0.022 & 0.001 & 0.001 +   + -0.1 & 50 & -0.096 & -0.094 & 0.028 & 0.027 & 0.028 & 0.005 & 0.005 + & 100 & -0.096 & -0.095 & 0.019 & 0.019 & 0.020 & 0.003 & 0.003 + & 500 & -0.096 & -0.095 & 0.009 & 0.009 & 0.009 & 0.001 & 0.001 + 0.2 & 50 & 0.191 & 0.188 & 0.054 & 0.054 & 0.055 & 0.007 & 0.007 + & 100 & 0.191 & 0.189 & 0.038 & 0.038 & 0.039 & 0.004 & 0.004 + & 500 & 0.191 & 0.191 & 0.017 & 0.017 & 0.017 & 0.001 & 0.001 + 0.5 & 50 & 0.483 & 0.474 & 0.064 & 0.064 & 0.065 & 0.006 & 0.007 + & 100 & 0.483 & 0.478 & 0.045 & 0.045 & 0.046 & 0.003 & 0.003 + & 500 & 0.483 & 0.481 & 0.020 & 0.020 & 0.020 & 0.001 & 0.001 +    * 9c @xmath269 & n & @xmath114 & @xmath282 & @xmath283 & @xmath272 & @xmath273 & @xmath280 & @xmath281 +   + -0.1 & 50 & -0.225 & -0.218 & 0.104 & 0.113 & 0.110 & 0.029 & 0.038 + & 100 & -0.225 & -0.220 & 0.071 & 0.072 & 0.073 & 0.018 & 0.021 + & 500 & -0.225 & -0.225 & 0.031 & 0.031 & 0.031 & 0.005 & 0.005 + 0.2 & 50 & 0.349 & 0.335 & 0.146 & 0.143 & 0.155 & 0.021 & 0.030 + & 100 & 0.349 & 0.343 & 0.103 & 0.102 & 0.106 & 0.012 & 0.015 + & 500 & 0.349 & 0.347 & 0.046 & 0.046 & 0.046 & 0.003 & 0.003 + 0.5 & 50 & 0.682 & 0.664 & 0.095 & 0.098 & 0.100 & 0.021 & 0.025 + & 100 & 0.682 & 0.673 & 0.066 & 0.066 & 0.067 & 0.012 & 0.012 + & 500 & 0.682 & 0.681 & 0.029 & 0.029 & 0.029 & 0.003 & 0.002 +   + -0.1 & 50 & -0.235 & -0.226 & 0.073 & 0.123 & 0.087 & 0.025 & 0.033 + & 100 & -0.235 & -0.231 & 0.048 & 0.058 & 0.054 & 0.013 & 0.015 + & 500 & -0.235 & -0.234 & 0.021 & 0.021 & 0.021 & 0.003 & 0.003 + 0.2 & 50 & 0.388 & 0.370 & 0.157 & 0.151 & 0.168 & 0.025 & 0.045 + & 100 & 0.388 & 0.378 & 0.110 & 0.108 & 0.115 & 0.016 & 0.023 + & 500 & 0.388 & 0.387 & 0.050 & 0.049 & 0.050 & 0.004 & 0.004 + 0.5 & 50 & 0.723 & 0.666 & 0.094 & 0.097 & 0.099 & 0.021 & 0.026 + & 100 & 0.723 & 0.674 & 0.065 & 0.066 & 0.067 & 0.011 & 0.012 + & 500 & 0.723 & 0.721 & 0.028 & 0.028 & 0.028 & 0.003 & 0.003 +    * 9c @xmath269 & n & @xmath143 & @xmath284 & @xmath285 & @xmath272 & @xmath273 & @xmath280 & @xmath281 +   + -0.1 & 50 & -0.310 & -0.250 & 0.126 & 0.133 & 0.147 & 0.010 & 0.017 + & 100 & -0.310 & -0.277 & 0.091 & 0.089 & 0.100 & 0.006 & 0.008 + & 500 & -0.310 & -0.302 & 0.041 & 0.039 & 0.042 & 0.002 & 0.001 + 0.2 & 50 & 0.375 & 0.330 & 0.123 & 0.118 & 0.135 & 0.012 & 0.016 + & 100 & 0.375 & 0.353 & 0.086 & 0.083 & 0.092 & 0.007 & 0.008 + & 500 & 0.375 & 0.369 & 0.039 & 0.038 & 0.040 & 0.002 & 0.002 + 0.5 & 50 & 0.694 & 0.635 & 0.081 & 0.084 & 0.090 & 0.015 & 0.019 + & 100 & 0.694 & 0.665 & 0.057 & 0.057 & 0.060 & 0.008 & 0.010 + & 500 & 0.694 & 0.688 & 0.025 & 0.025 & 0.025 & 0.002 & 0.002 +   + -0.1 & 50 & -0.462 & -0.265 & 0.110 & 0.150 & 0.144 & 0.011 & 0.021 + & 100 & -0.462 & -0.337 & 0.085 & 0.101 & 0.102 & 0.007 & 0.010 + & 500 & -0.462 & -0.428 & 0.038 & 0.036 & 0.040 & 0.002 & 0.002 + 0.2 & 50 & 0.433 & 0.356 & 0.118 & 0.116 & 0.137 & 0.012 & 0.017 + & 100 & 0.433 & 0.394 & 0.085 & 0.080 & 0.092 & 0.007 & 0.009 + & 500 & 0.433 & 0.426 & 0.037 & 0.036 & 0.038 & 0.002 & 0.002 + 0.5 & 50 & 0.740 & 0.667 & 0.077 & 0.080 & 0.086 & 0.015 & 0.020 + & 100 & 0.740 & 0.704 & 0.052 & 0.052 & 0.055 & 0.008 & 0.010 + & 500 & 0.740 & 0.733 & 0.022 & 0.022 & 0.023 & 0.002 &",
    "0.002 +    we further investigate how well the finite sample distribution of the introduced empirical measures of association can be approximated by the normal distribution .",
    "to this end , we compute @xmath286 and @xmath143 for @xmath28710,000 monte carlo simulations from two @xmath288-dimensional random vectors from the gaussian copula and the clayton copula . for each copula",
    ", we use different dependence parameters and various sample sizes .",
    "we standardise the 10,000 measures obtained from the monte carlo simulation by their sample mean and standard deviation , respectively , and use a kernel estimator to approximate their density .",
    "the left panel of figure [ fig : asymptotics ] shows the results for @xmath142 in case of the gaussian copula , where the correlation matrix has the form @xmath289 with @xmath290 and @xmath291 .",
    "whereas the density of the estimator is highly skewed for @xmath292 and @xmath293 for a sample size of @xmath294 , this asymmetry vanishes with increasing sample size and the density of the @xmath142 for all of the considered values of @xmath295 is barely distinguishable from the normal density for a sample size of 500 .",
    "it has to be noted that @xmath296 and @xmath291 are the upper and lower bound of @xmath295 such that @xmath297 is a correlation matrix . for values closer to @xmath298 , the asymmetries are smaller .",
    "the right panel of figure [ fig : asymptotics ] shows the results for a clayton copula with parameters @xmath299 and @xmath300 .",
    "again , we used @xmath142 to measure the association .",
    "the other measures , however , show similar results , which are available upon request by the authors . for a sample size of @xmath294 , the density of the estimator",
    "is slightly skewed for all parameters , nevertheless the highest skewness occurs for @xmath301 .",
    "as for the gaussian copula , the skewness decreases with increasing sample size and is barely observable for a sample size of 500 .",
    "having performed similar monte carlo simulations for other dimensions and dependence parameters , we conclude that for a sample size of @xmath264 the finite sample distribution of the association measure can very well be approximated by the normal distribution .     for the gaussian copula with @xmath302 and @xmath291 (",
    "left panel ) and the 4 dimensional clayton copula with @xmath299 and @xmath300 ( right panel ) .",
    "the solid line depicts the standard normal distribution.,scaledwidth=100.0% ]",
    "in our empirical example we make an attempt to measure strength and direction of association of the bond and the stock market . we make use of the five copula based measures of association presented in section [ sec.popver ] .",
    "moreover , for the sake of comparison , the traditional canonical correlation , the rv coefficient and distance correlation are applied .",
    "we consider daily returns of the stock market indices of five major countries as well as government bonds indices from the bank of america merrill lynch for the respective countries during the period from january 3rd , 1996 to december 30th , 2010 .",
    "figure [ fig : dependence - plot ] shows the evolution of the association of bond and stock market , based on a forward - looking moving window with a window size of 250 days . in particular , the first value of each measure is based on the 250 daily returns following january , 2rd , 1996 .",
    "the last value is estimated from the 250 daily returns from january 18th , 2010 until the end of 2010 .",
    "the top panel shows that canonical correlation , distance correlation and the rv coefficient exhibit similar patterns of association .",
    "their scaling is quite different , however .",
    "canonical correlation is always highest , rv coefficient always lowest .",
    "distance correlation is somehow between the two , but closer to the canonical correlation in general .",
    "the evolution of association over time as indicated by the five measures @xmath78 and @xmath303 is shown in the bottom panel .",
    "the differences between their values are in general smaller than these of the aforementioned measures .",
    "the evolution of @xmath78 seems to be smoothest which is not surprising , while @xmath142 is most erratic .",
    "it can be seen that there is a tendency of decreasing association from 1996 to 2002 , association is close to zero between 2002 and 2006 and becomes negative afterwards .",
    "a pattern of association like this can only be recorded by using measures of the type which we introduced in section [ sec.popver ] .",
    "note that the identified pattern of association is an empirical finding , for which we do not attempt to provide an economic explanation .",
    "the graphs in figure [ fig : dependence - plot ] are based on the returns themselves .",
    "we have , however , made similar graphs for filtered data where autocorrelation and heteroscedasticity have been removed .",
    "the results for the filtered data are very close to those of the unfiltered data .     and @xmath303 ( bottom panel ) .",
    "the analysis is based on a moving window approach with a window size of 250 days.,scaledwidth=100.0% ]",
    "five measures of association between two random vectors @xmath11 and @xmath12 have been introduced .",
    "they are copula based and do therefore not depend on the marginal distributions of the components @xmath2 and @xmath304 they measure strength and direction of association , so they are capable of distinguishing positive and negative association .",
    "this is a substantial advantage in applications to real life data , in particular financial data .",
    "estimators for the measures have been proposed and it was demonstrated by simulation that they have favorable small sample properties at least for @xmath305 there is space for extension and complementation of the measures .",
    "first , it can be seen that the measures @xmath306 have in common that they are based on transformations @xmath307 and @xmath308 , say , where @xmath309 and @xmath310 may , or may not , depend on the marginal copulas @xmath38 and @xmath311 therefore more general classes of measures can be defined , if further measures of bivariate association are applied to @xmath307 and @xmath312    second , measures for association between @xmath261 vectors @xmath313 of dimensions @xmath314 respectively , can be defined if measures of @xmath261-variate association ( see , e.g. , @xcite ) are applied to @xmath315 for appropriate functions @xmath316",
    "funding for johan segers research was provided by iap research network grant p6/03 of the belgian government ( belgian science policy ) and by `` projet dactions de recherche concertes '' number 07/12/002 of the communaut franaise de belgique , granted by the acadmie universitaire de louvain .",
    "funding in support of julius schnieders work was provided by the deutsche forschungsgemeinschaft ( dfg ) .",
    "morever , we are grateful to the regional computing center at the university of cologne for providing the computational resources required .",
    "23 natexlab#1#1url # 1`#1`urlprefix    beran , r. , bilodeau , m. , lafaye  de micheaux , p. , 2007 .",
    "nonparametric tests of independence between random vectors .",
    "journal of multivariate analysis 98  ( 9 ) , 18051824 .",
    "cherubini , u. , luciano , e. , vecchiato , w. , 2004 .",
    "copula methods in finance .",
    "clayton , d. , 1978 . a model for association in bivariate life tables and",
    "its application in epidemiological studies of familial tendency in chronic disease incidence .",
    "biometrika 65 , 141151 .",
    "deheuvels , p. , 1979 .",
    "la fonction de dpendance empirique et ses proprits . acad .",
    "belg . bull .",
    "65  ( 5 ) , 274292 .",
    "embrechts , p. , mcneil , a. , straumann , d. , 2002 .",
    "risk management : value at risk and beyond .",
    "cambridge university press , ch .",
    "correlation and dependency in risk management : properties and pitfalls , pp .",
    "176223 .",
    "escoufier , y. , 1973 .",
    "le traitment des variables vectorielles .",
    "biometrics 29  ( 4 ) , 751760 .    fermanian , j .- d . , radulovi , d. , wegkamp , m. , 2004 .",
    "weak convergence of empirical copula processes .",
    "bernoulli 10  ( 5 ) , 847860 .",
    "hotelling , h. , 1936 .",
    "relations between two sets of variates .",
    "biometrika 28 , 321377 .",
    "joe , h. , 1997 .",
    "multivariate models and dependence concepts .",
    "chapman & hall , london .",
    "kojadinovic , i. , holmes , m. , 2009 .",
    "tests of independence among continuous random vectors based on cramr - von mises functionals of the empirical copula process .",
    "journal of multivariate analysis 100 , 11371154 .",
    "nelsen , r.  b. , 2006 .",
    "an introduction to copulas , 2nd edition .",
    "springer series in statistics .",
    "springer , new york .",
    "nelsen , r.  b. , quesada - molina , j.  j. , rodrguez - lallena , j.  a. , beda flores , m. , 2003 .",
    "kendall distribution functions .",
    "statistics & probability letters 65  ( 3 ) , 263  268 .    quessy , j. , 2010 . applications and asymptotic power of marginal - free tests of stochastic vectorial independence .",
    "journal of statistical planning and inference 140 , 30583075 .",
    "rmillard , b. , 2009 .",
    "discussion of : brownian distance covariance .",
    "the annals of applied statistics 3  ( 4 ) , 12951298 .    robert , p. , escoufier , y. , 1976 . a unifying tool for linear multivariate statistical methods : the rv - coefficient .",
    "25  ( 3 ) , 257265 .    rschendorf , l. , 1976 .",
    "asymptotic distributions of multivariate rank order statistics .",
    "annals of statistics 4  ( 5 ) , 912923 .",
    "schmid , f. , schmid , r. , blumentritt , t. , gaisser , s. , ruppert , m. , 2009 .",
    "copula - based measures of multivariate association . in : jaworski ,",
    "p. , durante , f. , hrdle , w. , rychlik , t. ( eds . ) , copula theory and its applications .",
    "lecture notes in statistics - proceedings .",
    "schmid , f. , schmidt , r. , 2007 .",
    "multivariate extensions of spearman s rho and related statistics .",
    "statistics probability letters 77  ( 4 ) , 407416 .    segers , j. , accepted .",
    "asymptotics of empirical copula processes under nonrestrictive smoothness assumptions .",
    "bernoulli , arxiv:1012.2133v2 .",
    "sklar , a. , 1959 .",
    "fonctions de rparation  n dimensions et leurs marges .",
    "paris 8 , 229231 .",
    "szkely , g. , rizzo , m. , 2009 .",
    "brownian distance covariance .",
    "the annals of applied statistics 3  ( 4 ) , 12361265 .    szkely , g. , rizzo , m. , bakirov , n. , 2007 . measuring and testing dependence by correlation of distances .",
    ". statist .",
    "35  ( 6 ) , 27692794 .",
    "van  der vaart , a.  w. , wellner , j.  a. , 1996 .",
    "weak convergence and empirical processes .",
    "springer verlag , new york .",
    "1 .   let @xmath317  and  @xmath318 + then@xmath319^p}\\int_{[0,1]^q } \\pi _ { p}\\left ( \\mathbf{u}\\right ) \\pi _ { q}\\left ( \\mathbf{v}\\right)dc(\\mathbf{u},\\mathbf{v } ) - \\int_{[0,1]^p}\\pi _ { p}\\left ( \\mathbf{u}\\right)da(\\mathbf{u } ) \\int_{[0,1]^q}\\pi _ { q}\\left ( \\mathbf{v}\\right)db(\\mathbf{v } ) \\\\ & = \\int_{[0,1]^p}\\int_{[0,1]^q } c(\\mathbf{u},\\mathbf{v})d\\mathbf{u}d\\mathbf{v } - \\int_{[0,1]^p}a(\\mathbf{u})d\\mathbf{u } \\int_{[0,1]^q}b(\\mathbf{v})d\\mathbf{v } \\\\ & = \\int_{[0,1]^p}\\int_{[0,1]^q } \\left ( c(\\mathbf{u},\\mathbf{v})- a(\\mathbf{u})b(\\mathbf{v } )           \\right)d(\\mathbf{u},\\mathbf{v})\\end{aligned}\\ ] ] 2 .",
    "consider @xmath320  and  @xmath321 + we then have@xmath322 and @xmath323^p}\\int_{[0,1]^q}a\\left ( \\mathbf{u}\\right ) b\\left ( \\mathbf{v}\\right ) dc\\left ( \\mathbf{u},\\mathbf{v}\\right ) \\\\ & = & \\int_{[0,1]^p}\\int_{[0,1]^q}\\overline{c}\\left ( \\mathbf{u},\\mathbf{v}\\right ) da\\left ( \\mathbf{u}\\right ) db\\left ( \\mathbf{v}\\right).\\end{aligned}\\ ] ] further @xmath324^p}a\\left ( \\mathbf{u}\\right ) da\\left ( \\mathbf{u}\\right ) = \\int_{[0,1]^p } \\overline{a}\\left ( \\mathbf{u}\\right ) da\\left ( \\mathbf{u}\\right)\\]]and@xmath325^q}b\\left ( \\mathbf{u}\\right ) db\\left ( \\mathbf{u}\\right ) = \\int_{[0,1]^q } \\overline{b}\\left ( \\mathbf{u}\\right ) db\\left ( \\mathbf{u}\\right ) .\\ ] ]    therefore@xmath326^p}\\int_{[0,1]^q}\\left ( \\overline{c}\\left ( \\mathbf{u},\\mathbf{v}\\right ) -\\overline{a}\\left ( \\mathbf{u}\\right ) \\overline{b}\\left ( \\mathbf{v}\\right ) \\right ) da\\left ( \\mathbf{u}\\right ) db\\left ( \\mathbf{v}\\right ) .\\]]the measure to be defined is therefore based on the weighted difference@xmath327where the weights are given by @xmath38 and @xmath39 .",
    "further @xmath328^p}a\\left ( \\mathbf{u}\\right ) a\\left ( \\mathbf{u}\\right ) da\\left ( \\mathbf{u}\\right ) -\\left",
    "( \\int_{[0,1]^p}a\\left ( \\mathbf{u}\\right ) da\\left ( \\mathbf{u}\\right ) \\right ) ^{2 } \\\\ & = & \\int_{[0,1]^p}\\int_{[0,1]^p}a\\left ( \\mathbf{u}\\right ) a\\left ( \\mathbf{u}^{\\prime } \\right ) da\\left ( \\mathbf{u\\wedge u}^{\\prime }",
    "\\right ) \\\\ & & \\qquad \\mbox { } -\\int_{[0,1]^p}\\int_{[0,1]^p}a\\left ( \\mathbf{u}\\right ) a\\left ( \\mathbf{u}^{\\prime } \\right ) da\\left ( \\mathbf{u}\\right ) da\\left ( \\mathbf{u}^{\\prime } \\right ) \\\\ & = & \\int_{[0,1]^p}\\int_{[0,1]^p}\\left ( \\overline{a}\\left ( \\mathbf{u\\vee u}^{\\prime } \\right ) -\\overline{a}\\left ( \\mathbf{u}\\right ) \\overline{a}\\left ( \\mathbf{u}^{\\prime } \\right ) \\right ) da\\left ( \\mathbf{u}\\right ) da\\left ( \\mathbf{u}^{\\prime } \\right).\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> this paper suggests five measures of association between two random vectors @xmath0 and @xmath1 . </S>",
    "<S> they are copula based and therefore invariant with respect to the marginal distributions of the components @xmath2 and @xmath3 . </S>",
    "<S> the measures capture positive as well as negative association of @xmath4 and @xmath5 . in case </S>",
    "<S> @xmath6 they reduce to spearman s rho . </S>",
    "<S> various properties of these new measures are investigated . </S>",
    "<S> nonparametric estimators , based on ranks , for the measures are derived and their small sample behavior is investigated by simulation . </S>",
    "<S> the measures are applied to characterise strength and direction of association of bond and stock indices of five countries over time .    </S>",
    "<S> copula , pearson correlation , rank correlation , simulation , bootstrap , jackknife </S>"
  ]
}