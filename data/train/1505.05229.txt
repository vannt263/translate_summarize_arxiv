{
  "article_text": [
    "count data often arise in healthcare and epidemiology data sets . for example , the number of outcomes observed ( _ i.e. _ cases of a disease ) in a specific group of people ( _ i.e. _ citizens residing in knox county ) .",
    "we tend to treat count data as realizations from a poisson distribution , so that the probability of observing @xmath0 events given an expected number of events , @xmath1 , is precisely @xmath2 = \\frac{\\mu^y \\exp(-\\mu)}{y!}.\\ ] ]    in regression analysis , poissonian data are most often related to a linear combination of independent variables ( _ i.e. _ , covariates , exposures ) via a log - link function .",
    "hence , the poisson regression model is defined as @xmath3\\right ) = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j,\\ ] ] where @xmath4 , @xmath5 , are the measured effects of @xmath6 indpendent exposures , @xmath7 . for a binary exposure , @xmath8 , the amount @xmath9 is the increase ( or decrease ) in outcome incidence for subjects in which the exposure was observed , relative to subjects in which the exposure was not observed @xcite .",
    "the amount @xmath10 is the expected number of counts in baseline subjects .",
    "researchers are responsible for determining the criteria defining a baseline measurement .",
    "a major assumption in poisson regression modeling is that the mean and variance of the observed counts are equivalent .",
    "when this assumption is violated , as is often true of real data , we say the data are overdispersed .",
    "a negative binomial distribution may more appropriate than a poisson for describing overdispersed count data , due to its excessive tail behavior @xcite .",
    "the difference between negative binomial regression ( also referred to as nb-2 models ) and poisson regression comes from our treatment of the observed count data .",
    "we still make the assumption that these counts come from a poisson distribution , but we make the added assumption that the mean number of events , @xmath1 , comes from a 2-parameter gamma distribution .      finite mixture ( fm ) modeling has emerged within the past 20 years as a popular means for handling unsupervised classification tasks .",
    "the underlying principle behind mixture modeling is that we treat our observed data as having been sampled from a convex sum of distributions @xcite .",
    "this concept is particularly useful for explainining overdispersion in count data as being due to an underlying heterogeneous population .",
    "fm modeling has appeared in tandem with poisson regression models .",
    "the extent of this type of research has mostly been limited to zero - inflated , zero - truncated , and hurdle - type models @xcite .",
    "these models are designed to handle zero - counts , and are largely inappropriate for explaining heterogeneities due to covariates .",
    "( 2014 ) described a methodology that can address covariate heterogeneity using fms of poisson regression models in the context of high - throughput sequencing data @xcite .",
    "their em algorithms for estimating @xmath11 mixtures are freely available online from cran .",
    "in addition , park and lord ( 2009 ) have developed fms of poisson and negative binomial regression models for explaining hetergeneities in vehicle crash data @xcite .",
    "of the modeling frameworks that have been suggested in the literature , theirs is most similar to ours in that they proposed using the information criteria aic , bic , and dic to choose the optimal number of mixing components .",
    "however , these criteria did not give conclusive results , and so they were forced to subjectively choose a mixture of 2 nb-2 models . in the proceeding sections ,",
    "we will discuss potential reasons for these inconclusive results . for more information on finite mixtures of negative binomial regression models , see also zou _ et al . _",
    "( 2013 ) @xcite .",
    "model selection exists as an alternative approach to classical hypothesis - drive statistics which require distributional assumptions and an arbitrary selection of a confidence level to evaluate @xmath12-values .",
    "akaike was the first to propose a criterion for conducting model selection when he introduced his celebrated akaike information criterion ( aic ) in 1973 .",
    "the formula , which involves a tradeoff between a candidate model s lack of fit given by the maximized log - likelihood function , and a penalty term for the number of parameters , @xmath13 , is shown below : @xmath14 when we compare 2 or more models that have been fit to the same set of data , we prefer to choose the model that minimizes the aic score .    as it turns out , the original penalty term that akaike proposed , @xmath15 , is not enough to prevent model overfitting @xcite .",
    "numerous other information criteria ( ic ) have been proposed , including but not limited to schwarz s bayesian criterion ( sbc or bic ) @xcite , the deviance information criterion ( dic ) ( which we will not consider here ) , the consistent form of aic ( caic ) @xcite , and the information - theoretic measure of complexity ( icomp ) @xcite which involves evaluating the inverse fisher s information matrix ( ifim ) .",
    "the reader is directed to the respective citations for derivations of the formulae .",
    "we will point out that each of the criteria we consider in this paper all share the lack - of - fit term in common ",
    "what makes them different is how they penalize overparameterization .",
    "our ultimate goal when we carry out model selection in this framework is to determine the optimal number of components in a fm model , given a fixed maximum number of components ( see @xcite for heuristics on choosing this number ) .",
    "this optimal number is reflective of the number of subpopulations composing the entire population from which we have sampled our data . before we can perform model selection",
    ", we must be able to generate the various criteria discussed previously .",
    "to do so requires that we compute the log - likelihood function .",
    "recall equation ( [ poissmodel ] ) when dealing with poissonian data whose mean and variance are similar .",
    "it follows that @xmath16 = \\exp(\\beta^t x)$ ] .",
    "since our outcome is sampled from a convex sum of poisson distributions we have the following probability for observing @xmath17-dimensional count data , @xmath18 :    @xmath19 = \\prod_{i = 1}^n \\sum_{g = 1}^g \\pi_g \\frac{\\exp(y_i \\beta^t_g x_i ) \\exp\\left(-\\exp(\\beta^t_g x_i ) \\right)}{y!}.\\ ] ]    in equation ( [ poisspdf ] ) , @xmath20 is the total number of components in the fm model ; @xmath21 is the weight assigned to component @xmath22 ; and , @xmath23 refers to the effects in the @xmath22-th component , as this will vary within components .",
    "it follows directly from equation ( [ poissmodel ] ) that the log - likelihood is @xmath24 \\right\\}.\\ ] ]    when data are significantly overdispersed , recall that we assume our @xmath17 counts , @xmath18 , come from a poisson distribution whose mean parameter , @xmath25 , is gamma - distributed .",
    "this additional constraint gives us the following probability density for @xmath18 :    @xmath26 = \\displaystyle \\prod_{i=1}^n \\sum_{g = 1}^g \\left\\ { \\pi_g \\frac{\\gamma\\left(y_i + 1 / \\alpha_g \\right)}{\\gamma\\left(1 / \\alpha_g\\right ) y_i ! }   \\left ( \\frac{\\alpha_g \\beta_g^t x_i}{1 + \\alpha_g \\beta^t_g x_i}\\right)^{y_i }   \\left(\\frac{1}{1 + \\alpha_g \\beta_g^t x_i}\\right)^{\\frac{1}{\\alpha_g } } \\right\\}.\\ ] ]    the interpretation of @xmath27 and @xmath28 follows as before .",
    "the @xmath29 are overdispersion parameters , satisfying @xmath30 ( note : @xmath31 ) .",
    "the quadratic dependence of the variance on the mean is why we refer to these as nb-2 models .    finally , following directly from equation ( [ nbpdf ] )",
    ", the log - likelihood function for the negative binomial regression model is shown below @xcite : @xmath32 & & \\left .",
    "\\left . - \\log(1 + \\alpha_g \\beta_g^t x_i)\\right ) - \\left(\\frac{1}{\\alpha_g}\\right ) \\log(1 + \\alpha_g \\beta_g^t x_i ) - \\log(y_i ! ) \\right ] \\right\\}. \\end{array}\\ ] ]    note that when @xmath33 , the data are not overdispersed and so the assumption that @xmath34 is satisfied . using our methodology , if the overdispersion parameter is below a certain threshold , we elect to perform poisson regression , otherwise we perform nb-2 regression .",
    "this is especially important for computing the log - likelihood functions once we carry out scoring .",
    "the choice of an appropriate initialization scheme was a source of great concern for papastamoulis _ et al .",
    "_ in their algorithm @xcite .",
    "they used a `` small - em '' strategy from biernacki _ et al . _",
    "( 2003 ) , which was necessary for dealing with a large number of component mixtures ( @xmath35 ) @xcite .",
    "we are not interested in exploring the possibility of more than @xmath36 components unless there is some justifiable epidemiological reason for doing so .",
    "because of this , we opted for using a poisson mixture model to perform unsupervised classification of our observed counts ( see @xcite ) . as a result ,",
    "our methodology involves first sorting the count data into @xmath37 groups , and then assigning observations in each group to an initial poisson or nb-2 regression model .",
    "all numerical simulations were carried out in matlab 2015a .",
    "we used arcgis 10.2 for generating the map of tennessee counties .",
    "we begin using our proposed model framework to choose the optimal number of components in a simple set of simulated data .",
    "each observation in the data is an ordered pair , @xmath38 , where @xmath39 , and @xmath40 , @xmath41 .",
    "the parameters @xmath42 and @xmath43 for all @xmath44 are randomly generated integers between 1 and 50 . in this way",
    ", each observation comes from 1 of 4 potential groups .",
    "we tried fitting fms of 1 to 5 poisson regression models to these data ; their scores are shown in table [ tab : sim ] .",
    "we see that all 3 scores select @xmath45 as the optimal number of components .",
    "the regression models corresponding to the solution when @xmath45 are shown in the right pane of figure [ fig : sim ] . the regression models each seem to do well modeling these data .         lcccc variable & @xmath28 & s. e. & 2.5% & 97.5% +   + urb &  &  &  &  + nhw & -2.14 & 1.30 & -4.69 & 0.41 + int & 4.06 & 1.20 & 1.70 & 6.41 + & & & & +   + urb & 0.40 & 0.091 & 0.22 & 0.58 + nhw & -1.85 & 0.51 & -2.85 & -0.85 + int & 4.84 & 0.45 & 3.96 & 5.72 + & & & & +   + urb & 0.35 & 0.11 & 0.12 & 0.57 + nhw & -1.05 & 0.39 & -1.81 & -0.29 + int & 4.94 & 0.28 & 4.38 & 5.50 + & & & & +   + urb &  &  &  &  + nhw & -7.12 & 1.40 & -9.86 & -4.37 + int & 11.57 & 1.08 & 9.46 & 13.68 +    lcccc variable & mean & st . dev . & min . & max .",
    "+   + hiv & 8.03 & 4.00 & 2.00 & 15.00 + sch & 0.24 & 0.04 & 0.16 & 0.30 + pov & 0.20 & 0.04 & 0.10 & 0.30 + inc & 10.43 & 0.15 & 10.01 & 10.71 + urb & 0.00 & 0.00 & 0.00 & 0.00 + ump & 0.12 & 0.03 & 0.07 & 0.17 + nhb & 0.03 & 0.05 & 0.00 & 0.26 + nhw & 0.93 & 0.06 & 0.68 & 0.99 + hsp & 0.02 & 0.02 & 0.00 & 0.09 + & & & & +   + hiv & 27.55 & 8.89 & 15.00 & 45.00 + sch & 0.21 & 0.03 & 0.15 & 0.30 + pov & 0.17 & 0.03 & 0.12 & 0.23 + inc & 10.54 & 0.10 & 10.30 & 10.81 + urb & 0.27 & 0.45 & 0.00 & 1.00 + ump & 0.11 & 0.02 & 0.08 & 0.18 + nhb & 0.05 & 0.07 & 0.00 & 0.41 + nhw & 0.89 & 0.08 & 0.56 & 0.97 + hsp & 0.03 & 0.03 & 0.01 & 0.11 + & & & & +   + hiv & 72.92 & 16.84 & 45.00 & 94.00 + sch & 0.17 & 0.04 & 0.12 & 0.26 + pov & 0.14 & 0.05 & 0.09 & 0.23 + inc & 10.70 & 0.21 & 10.40 & 11.02 + urb & 0.54 & 0.52 & 0.00 & 1.00 + ump & 0.10 & 0.02 & 0.07 & 0.15 + nhb & 0.14 & 0.15 & 0.01 & 0.49 + nhw & 0.81 & 0.15 & 0.45 & 0.94 + hsp & 0.03 & 0.01 & 0.02 & 0.06 + & & & & +   + hiv & 1051.31 & 1913.88 & 101.00 & 6408.00 + sch & 0.13 & 0.03 & 0.05 & 0.18 + pov & 0.13 & 0.03 & 0.05 & 0.17 + inc & 10.80 & 0.21 & 10.60 & 11.42 + urb & 1.00 & 0.00 & 1.00 & 1.00 + ump & 0.09 & 0.02 & 0.05 & 0.12 + nhb & 0.16 & 0.15 & 0.02 & 0.52 + nhw & 0.75 & 0.16 & 0.39 & 0.94 + hsp & 0.05 & 0.02 & 0.01 & 0.10 +"
  ],
  "abstract_text": [
    "<S> count data , for example the number of observed cases of a disease in a city , often arise in the fields of healthcare analytics and epidemiology . in this paper </S>",
    "<S> , we consider performing regression on multivariate data in which our outcome is a count . </S>",
    "<S> specifically , we derive log - likelihood functions for finite mixtures of regression models involving counts that come from a poisson distribution , as well as a negative binomial distribution when the counts are significantly overdispersed . within our proposed modeling framework , we carry out optimal component selection using the information criteria scores aic , bic , caic , and icomp . </S>",
    "<S> we demonstrate applications of our approach on simulated data , as well as on a real data set of hiv cases in tennessee counties from the year 2010 . finally , using a genetic algorithm within our framework , we perform variable subset selection to determine the covariates that are most responsible for categorizing tennessee counties . </S>",
    "<S> this leads to some interesting insights into the traits of counties that have high hiv counts . </S>"
  ]
}