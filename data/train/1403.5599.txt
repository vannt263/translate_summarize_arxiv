{
  "article_text": [
    "the monte carlo simulation is a popular numerical method across sciences , engineering , statistics , and computational mathematics . in simple terms",
    ", the method involves solving a problem by simulating the underlying model using pseudorandom numbers , and then estimates the quantity of interest as a result of the simulation . simulating the model involves generating pseudorandom numbers from various probability distributions used in the model .",
    "there is an extensive literature on algorithms that transform pseudorandom numbers from the uniform distribution to pseudorandom numbers from the target distribution ( see , for example , devroye @xcite , fishman @xcite ) .",
    "many of these algorithms are based on two main methods and their combinations : the inverse transformation method and the acceptance - rejection method .",
    "the latter is used especially when the inverse transformation method is computationally expensive .",
    "an alternative numerical tool to the monte carlo ( mc ) method is the quasi - monte carlo ( qmc ) method .",
    "it is easier to describe these methods in the context of numerical integration .",
    "both methods estimate the expected value of a random variable @xmath0 , @xmath1 $ ] , using sample means @xmath2 where @xmath3 , ... , @xmath4 are i.i.d .",
    "random variables from the distribution of @xmath0 in mc , and a low - discrepancy sequence ( or , a qmc sequence ) from the cumulative distribution function ( cdf ) @xmath5 of @xmath0 . the definition of low - discrepancy sequences and a comprehensive treatment of its theory can be found in niederreiter @xcite .",
    "one reason qmc has become popular in some fields such as computational finance is its faster rate of convergence . theoretical convergence rate of qmc is @xmath6 , where @xmath7 is the dimension of the integral in the computation of the expectation .",
    "this deterministic rate of convergence is asymptotically better than the probabilistic monte carlo rate of @xmath8 .",
    "however , in many applications , researchers have observed rates close to @xmath9 for qmc .",
    "we will not discuss the reasons for this better than theoretical rate of convergence which involve concepts like effective dimension and decreasing importance of variables ( @xcite ) .",
    "how do we generate a qmc sequence from a distribution @xmath5 ?",
    "the process is somewhat similar to mc .",
    "one starts with a qmc sequence from the uniform distribution on @xmath10 and then applies a transformation method to the sequence in order to obtain a sequence from the target distribution .",
    "currently , the only main transformation method used for qmc is the inverse transformation method ( the box - muller method is also applicable in qmc ( @xcite ) , but its scope is smaller . )",
    "the acceptance - rejection method is usually avoided in qmc , though  smoothed \" versions of it were introduced by moskowitz & caflisch @xcite and wang @xcite .",
    "the reasons for this avoidance has to do with some theoretical difficulties that involve the inapplicability of koksma - hlawka type inequalities to indicator functions with infinite variation .",
    "if the inverse transformation method is computationally expensive for a particular distribution , then its application to a qmc sequence can make the overall qmc simulation too expensive to provide any advantages over the mc simulation .",
    "an example of costly inverse transformation algorithm appears in the simulation of a stochastic process known as the variance gamma model by qmc .",
    "avramidis et .",
    "@xcite comment on the additional cost of computing inverse of beta , gamma , and normal distributions , which are needed in the generation of the variance gamma model , and suggest that this additional cost needs to be considered while assessing the efficiency of different estimators .    in this paper , we present a qmc version of the acceptance - rejection method , prove a convergence result , and develop error bounds .",
    "we present qmc algorithms based on acceptance - rejection for the beta and gamma distributions .",
    "we illustrate the advantages of these algorithms , and their application to the variance gamma model , numerically .",
    "the availability of acceptance - rejection as a transformation method for qmc significantly broadens its scope .",
    "the acceptance - rejection method is one of the standard methods used for generating distributions .",
    "assume we want to generate from the density @xmath11 , and there is another density @xmath12 ( with cdf @xmath13 ) we know how to sample from , say , by using the inverse transformation method .",
    "assume the density functions @xmath14 have the same domain , @xmath15 , and there exists a finite constant @xmath16 .",
    "let @xmath17 .",
    "the monte carlo acceptance - rejection algorithm is :    algorithm 1 : acceptance - rejection algorithm to generate pseudorandom numbers from the density @xmath11 .    1 .",
    "generate pseudorandom numbers @xmath18 , @xmath19 from the uniform distribution on @xmath20 2 .",
    "generate @xmath0 from @xmath12 by @xmath21 3 .   if @xmath22 accept @xmath0",
    "; otherwise reject @xmath0 4 .",
    "repeat steps 1 to 3 , until the necessary number of points have been accepted .",
    "acceptance - rejection is usually avoided in qmc because it involves integration of a characteristic function : this is the step that corresponds to accepting a candidate by a certain probability . since characteristic functions can have infinite variation in the sense of hardy and krause , and since the celebrated koksma - hlawka inequality ( @xcite ) links the integration error to the variation of the integrand , researchers for the most part have stayed away from the acceptance - rejection method with low - discrepancy sequences .",
    "two notable exceptions are moskowitz and caflisch @xcite and wang @xcite . in these papers ,",
    "smoothed versions of acceptance - rejection are introduced .",
    "these methods replace the characteristic functions by continuous ones , thereby removing functions with infinite variation",
    ". however , these smoothing methods can be very time consuming ; if one considers efficiency ( time multiplied by error ) , the smoothing method can be worse than crude mc simulation .",
    "we will present such examples in section [ smooth section ] . perhaps for this reason , the smoothing methods have not gained much ground in applications .    for mc , acceptance - rejection is a very powerful tool .",
    "there are several specialized algorithms that combine acceptance - rejection with other techniques to obtain fast simulation methods for many distributions used in computing ; for a recent reference see fishman @xcite .",
    "currently , the qmc method can not be effectively used in these algorithms , since the smoothing techniques are expensive .",
    "let @xmath23 be numbers obtained from a qmc algorithm that generates the distribution function @xmath5 .",
    "how well these numbers approximate @xmath5 is given by the @xmath24-star discrepancy of @xmath25 :    @xmath26 } \\left\\vert \\frac{a([a,\\alpha);\\{x_1, ... ,x_n\\})}{n}-f(\\alpha ) \\right\\vert\\ ] ] where @xmath15 is the support of @xmath24 , and the function @xmath27 counts how many numbers in @xmath25 belong to the interval @xmath28 . if @xmath24 is the uniform distribution , we simply write @xmath29 and call it star discrepancy . note that @xmath24-star discrepancy is the kolmogorov - smirnov statistic that measures the distance between the empirical and theoretical distribution functions . in our numerical results",
    "we will use the anderson - darling statistic which is a generalization of the kolmogorov - smirnov statistic ( see @xcite ) .",
    "the anderson - darling statistic corresponds to the  weighted \" @xmath24-star discrepancy of a point set .",
    "more on the weighted discrepancy and corresponding koksma - hlawka type error bounds can be found in niederreiter & tichy @xcite and kten @xcite .",
    "next we introduce the acceptance - rejection method for low - discrepancy sequences .",
    "algorithm 2 : qmc acceptance - rejection algorithm to generate a sequence whose @xmath24-star discrepancy converges to zero .    1 .",
    "generate a low - discrepancy sequence @xmath30 from the uniform distribution on @xmath31 @xmath32 2 .   for @xmath33",
    "* generate @xmath0 from @xmath12 by @xmath34 * if @xmath35 accept @xmath0 ; otherwise reject @xmath0 3 .",
    "stop when the necessary number of points have been accepted .",
    "the algorithm starts with a point set in @xmath31 @xmath36 and then applies inversion ( step 2 ) to obtain the new point set @xmath37 assume @xmath38 points are accepted at step 2 of the algorithm .",
    "after a renumbering of the indices , we obtain the set of `` accepted points '' in @xmath15 :    @xmath39    the next theorem shows that the accepted points have @xmath24-star discrepancy that goes to zero with @xmath40 .",
    "this result generalizes theorem 2.4 of wang @xcite who proves a similar convergence result when the density @xmath12 is the uniform density on @xmath10 , and @xmath11 is a density function on @xmath10 .",
    "[ main ] we have @xmath41 where @xmath42 is the @xmath24-star discrepancy of the point set @xmath43 .",
    "we need to prove that for any @xmath44 @xmath45 where @xmath46 is the empirical cdf .",
    "define the set @xmath47 ( for simplicity we will assume @xmath13 is strictly increasing ) . consider a point @xmath48 this point belongs to @xmath43 and falls into @xmath28 if and only if    1 .",
    "@xmath49 , 2 .",
    "@xmath50 is accepted in step 2 , i.e. , @xmath51 is such that @xmath52 .",
    "therefore , @xmath53 if and only if @xmath54 , which implies @xmath55 now , we work on the local discrepancy : @xmath56    here @xmath57 refers to the lebesgue measure of the set @xmath58 .",
    "note that @xmath59 is a u.d .",
    "mod 1 sequence in @xmath31 , and the boundary of the set @xmath58 has lebesgue measure zero since @xmath60 is a continuous function on @xmath20 .",
    "thus , we have : @xmath61 as @xmath62 . substituting @xmath63 in ( [ local discrep ineq ] ) , we obtain @xmath64 indeed , note that @xmath65 from @xmath59 belongs to @xmath66 if and only if @xmath67 which gives us all the accepted points , i.e. , @xmath68 then , we have@xmath69 equations ( [ lim ] ) and ( [ lim vol ] ) imply the first term of the upper bound of inequality ( [ local discrep ineq ] ) converges to zero . to prove that the second term also goes to zero",
    ", it suffices to show that @xmath70 from ( [ ealpha ] ) we have @xmath71 change of variables yields : @xmath72 , @xmath73 , and thus @xmath74 similarly , we have @xmath75 since @xmath76 is the density function on @xmath15 .",
    "this completes the proof .",
    "note that theorem [ main ] generalizes to the case when @xmath0 is an @xmath7-dimensional random vector in a straightforward way . in algorithm 2 ,",
    "the low - discrepancy sequence @xmath30 would be replaced by an @xmath77-dimensional sequence @xmath78 where @xmath79",
    "the classical qmc error bound is the celebrated koksma - hlawka inequality @xmath80 where @xmath81 is the variation of @xmath76 in the sense of hardy and krause ( @xcite ) .",
    "indicator functions , unless some conditions are satisfied ( @xcite ) , have infinite variation and thus koksma - hlawka inequality can not be used to bound their error .",
    "this has been the main theoretical obstacle for the use of low - discrepancy sequences in acceptance - rejection algorithms . as a remedy , smoothing methods ( @xcite , @xcite ) were introduced to replace the indicator functions by smooth functions so that koksma - hlawka is applicable . in this section we present error bounds that do not require the bounded variation assumption , and allow the analysis of our qmc acceptance - rejection algorithm . in the following section",
    ", we will compare our algorithm with the smoothing approach numerically .",
    "consider a general probability space @xmath82 , where @xmath83 is an arbitrary nonempty set , @xmath84 is a @xmath85-algebra of subsets of @xmath83 , and @xmath86 is a probability measure defined on @xmath84 .",
    "let @xmath87 be a nonempty subset of @xmath88 .",
    "for a point set @xmath89 and @xmath90 define @xmath91 as the number of elements in @xmath92 that belong to @xmath93 a point set @xmath94 of @xmath40 elements of @xmath83 is called @xmath95-uniform if @xmath96 for all @xmath97 .",
    "the definition of @xmath95-uniform point sets is due to niederreiter @xcite who developed error bounds when uniform point sets are used in qmc integration .",
    "a useful feature of these bounds is that they do not require the integrand to have finite variation .",
    "we need the following result from gnc and kten @xcite :    [ collision ] if @xmath76 is any bounded @xmath86-integrable function on a probability space @xmath98 and @xmath99 a partition of @xmath100 then for a point set @xmath101 we have @xmath102 where @xmath103 , @xmath104 and @xmath105 @xmath106    theorem [ collision ] provides a general error bound for any point set @xmath94 . if the point set is an @xmath95-uniform point set then the second summation on the right hand side becomes zero and the result simplifies to theorem 2 of niederreiter @xcite . setting @xmath107 , the indicator function of the set @xmath108 , in theorem [ collision ] , we obtain a simple error bound for indicator functions :    [ cor ] under the assumptions of theorem [ collision ] , we have @xmath109    now consider algorithm 2 ( qmc acceptance - rejection algorithm ) where a low - discrepancy sequence is used to generate the point set @xmath110 ( see ( [ accepted points ] ) ) .",
    "we proved that @xmath111 as @xmath112 in theorem [ main ] .",
    "corollary [ cor ] yields an upper bound for the error of convergence .",
    "indeed , let @xmath113 for an arbitrary @xmath114 , @xmath83 be the domain for the distribution function @xmath24 , and @xmath86 the corresponding measure .",
    "we obtain the following bound :    @xmath115    if the point set @xmath110 happens to be an @xmath95-uniform point set with respect to the partition , then the term @xmath116 vanishes .",
    "next , we will discuss randomized quasi - monte carlo ( rqmc ) methods and another error bound that addresses the bounded variation hypothesis .",
    "although qmc methods have a faster asymptotic convergence rate than mc , measuring the actual error of a qmc estimate is not easy . as a remedy",
    ", one can use rqmc methods .",
    "these methods allow independent simulations via qmc , and the resulting estimates can be analyzed statistically .",
    "the rqmc method uses a family of @xmath7-dimensional low - discrepancy sequences @xmath117 , indexed by the random parameter @xmath118 .",
    "each sequence @xmath119 gives rise to the quadrature rule @xmath120 then , @xmath121 is estimated by taking the average of @xmath122 samples @xmath123 rqmc has three general properties :    1 .",
    "@xmath124=i(f)$ ] 2 .",
    "@xmath125 3 .",
    "@xmath126    let @xmath127 be the class of real continuous functions defined on @xmath128 and equipped with wiener sheet measure @xmath86 .",
    "theorem [ hickernell thm ] shows that the mean variance of @xmath129 under this measure is @xmath130 .",
    "since a function @xmath11 chosen from the brownian sheet measure has unbounded variation with probability one , this result provides an alternative error analysis approach to classical koksma - hlawka inequality which requires the integrand to be of finite variation .",
    "this result was obtained by wang and hickernell @xcite ( theorem 5 , page 894 ) for a particular rqmc method called  random - start halton sequences \" . however , their proof is valid for any rqmc method .",
    "[ hickernell thm ] the average variance of the estimator , @xmath129 , taken over function set @xmath131 , equipped with the brownian sheet measure @xmath132 , is : @xmath133 ^ 2 d\\mu = o(n^{-2}(\\log n)^{2s}).\\ ] ]    in our numerical results that follow , we use random - start halton sequences ( @xcite , @xcite ) .",
    "theorem [ collision ] can be used to analyze error for both inverse transformation and acceptance - rejection implementations that we will discuss .",
    "theorem [ hickernell thm ] applies only for the inverse transformation implementations , since it is not known whether the accepted points given by the acceptance - rejection algorithm satisfy the discrepancy bound @xmath134 .",
    "in this section we will compare the qmc acceptance - rejection algorithm with the smoothed acceptance - rejection algorithms by moskowitz & caflisch @xcite , and wang @xcite .",
    "the algorithms will be compared numerically in terms of efficiency , which is defined as sample variance times computation time .",
    "we will use the same numerical examples that were considered in @xcite and @xcite .    consider the problem of estimating the integral @xmath121 using the importance function @xmath135 @xmath136 the mc estimator for @xmath137 is @xmath138 the standard acceptance - rejection algorithm , algorithm 1 , takes the following form for this problem :    acceptance - rejection +    1",
    ".   select @xmath139 2 .",
    "repeat until @xmath40 points have been accepted : * sample @xmath140 , @xmath141 * if @xmath142 , accept @xmath143 + otherwise , reject @xmath143    the smoothed acceptance - rejection method of moskowitz and caflisch @xcite introduces a weight function @xmath144 such that @xmath145 the weight function @xmath144 is generated by the following algorithm we call sar1 .",
    "algorithm 3 ( sar1 ) : smoothed acceptance - rejection by moskowitz and caflisch @xcite[a1 ] +    1 .",
    "select @xmath139 , and @xmath146 2 .   repeat until weight of accepted points is within one unit of @xmath40 : * sample @xmath140 , @xmath141 * if @xmath147 set @xmath148 + else if @xmath149 set @xmath150 + else set @xmath151    wang @xcite extended the sar1 algorithm by choosing functions @xmath152 , @xmath153 such that @xmath154 and setting the weight function using the following algorithm ( which we call sar2 ) .",
    "algorithm 4 ( sar2 ) : smoothed acceptance - rejection by wang @xcite[a2 ] +    1 .",
    "select @xmath139 , and functions @xmath152 , @xmath153 such that @xmath155 2 .   repeat until weight of accepted points is within one unit of @xmath40 : * sample @xmath140 , @xmath141 * if @xmath156 set @xmath148 + else if @xmath157 set @xmath150 + else if @xmath158 set @xmath159 + else set @xmath160    now we consider the example used in @xcite ( example 3 , page 43 ) and @xcite .",
    "the problem is to estimate the integral @xmath121 , where @xmath161 and @xmath162 the importance function is @xmath163 where @xmath164 three estimators are used :    * crude monte carlo ( cr ) : @xmath165 * acceptance - rejection ( ar ) : @xmath166 * smoothed acceptance - rejection ( sar1 and sar2 ) : @xmath167 where @xmath168 is a positive integer such that @xmath169 is approximately @xmath40 .",
    "table [ w1 ] displays the efficiency of the algorithms .",
    "we normalize the efficiency of the algorithms by the efficiency of the crude monte carlo algorithm .",
    "for example , the efficiency of the acceptance - rejection ( ar ) algorithm , @xmath170 is computed by @xmath171 where @xmath172 is the sample standard deviation of @xmath122 estimates obtained using the crude monte carlo algorithm , and @xmath173 is the corresponding computing time .",
    "similarly , the parameters @xmath174 and @xmath175 refer to the sample standard deviation and computing time for the acceptance - rejection ( ar ) algorithm .",
    "although we are primarily interested in how these algorithms compare when they are used with low - discrepancy sequences , for reference , we also report efficiencies when the algorithms are used with pseudorandom numbers .",
    "the first part of the table reports the monte carlo values ( mc ) where the pseudorandom sequence mersenne twister @xcite is used , and the second part reports the ( randomized ) quasi - monte carlo ( rqmc ) values where random - start halton sequences ( @xcite , @xcite ) are used .    in the numerical results , @xmath176 , @xmath177 in the algorithm sar1 , and @xmath178 , @xmath179 in the algorithm sar2 .",
    "we consider the same sample sizes @xmath40 as in @xcite so that our results can be compared with theirs .",
    "table [ w1 ] reports the sample standard deviation and efficiency ( in parenthesis ) for each algorithm .",
    "note that in our notation , larger efficiency values suggest the method is better .    based on the numerical results in table [ w1 ] , we make the following conclusions . in qmc , the acceptance - rejection ( ar )",
    "algorithm has better efficiency than the smoothed algorithms sar1 and sar2 , by approximately factors between 2 and 28 .",
    "a part of the improved efficiency is due to the faster computing time of the ar algorithm .",
    "however , the ar algorithm also provides lower standard deviation for all samples . in the case of mc",
    ", the ar algorithm has still better efficiency , but with a smaller factor of improvement .",
    ".comparison of acceptance - rejection algorithm ar with its smoothed versions sar1 and sar2 , in terms of sample standard deviation and efficiency ( in parenthesis ) .",
    "[ cols=\"^,^,^,^,^,^,^,^,^ \" , ]",
    "the use of low - discrepancy sequences in computational problems , especially in numerical integration , is increasing mainly because of the faster convergence rates these sequences provide , compared to pseudorandom sequences .",
    "for example , in the application of derivative pricing from computational finance , this faster rate of convergence is quite useful , and some well known low - discrepancy sequences have taken their place in the numerical methods toolbox of financial engineers .    currently , the main method for transforming low - discrepancy sequences to nonuniform distributions is the inverse transformation technique .",
    "however , this technique can be computationally expensive for complicated distributions .",
    "the acceptance - rejection technique was developed precisely for this reason for pseudorandom sequences . in this paper",
    ", we presented theoretical and numerical results to argue that the acceptance - rejection technique is similarly useful in the context of low - discrepancy sequences .",
    "the availability of acceptance - rejection for low - discrepancy sequences significantly increases the scope of applications where quasi - monte carlo methods can improve traditional monte carlo .",
    "there is an extensive literature on efficient monte carlo algorithms for generating distributions , and many of them are based on acceptance - rejection .",
    "the results of this paper motivate the study of quasi - monte carlo versions of these algorithms .",
    "we thank dr .",
    "burkardt , department of scientific computing , florida state university , for the inverse transformation codes used in this paper .      a.n .",
    "avramidis , p. lecuyer , p.a .",
    "tremblay ( 2003 ) , _ efficient simulation of gamma and variance - gamma processes _ , winter simulation conference .",
    "eds . , s. chick , p. j. sanchez , d. ferrin , and d. j. morrice .",
    "cran , k.j .",
    "martin , g.e .",
    "thomas ( 1977 ) , _ a remark on algorithms as 63 : the incomplete beta integral and as 64 : inverse of the incomplete beta integral _",
    ", j. r. stat .",
    "soc . ser .",
    "stat . , 26(1 ) ,",
    "111 - 114 .",
    "m. matsumoto and t. nishimura ( 1998 ) .",
    "_ mersenne twister : a 623-dimensionally equidistributed uniform pseudorandom number generator _ , acm transactions on modeling and computer simulations , 8(1 ) , pp . 3 - 30 .",
    "n. webber , c. riveiro ( 2003 ) , _ valuing path dependent options in the variance - gamma model by monte carlo with a gamma bridge _",
    ", no 4 , computing in economics and finance 2003 , society for computational economics , http://econpapers.repec.org/repec:sce:scecf3:4 ."
  ],
  "abstract_text": [
    "<S> generation of pseudorandom numbers from different probability distributions has been studied extensively in the monte carlo simulation literature . </S>",
    "<S> two standard generation techniques are the acceptance - rejection and inverse transformation methods . </S>",
    "<S> an alternative approach to monte carlo simulation is the quasi - monte carlo method , which uses low - discrepancy sequences , instead of pseudorandom numbers , in simulation . </S>",
    "<S> low - discrepancy sequences from different distributions can be obtained by the inverse transformation method , just like for pseudorandom numbers . in this paper </S>",
    "<S> , we will present an acceptance - rejection algorithm for low - discrepancy sequences . </S>",
    "<S> we will prove a convergence result , and present error bounds . </S>",
    "<S> we will then use this acceptance - rejection algorithm to develop quasi - monte carlo versions of some well known algorithms to generate beta and gamma distributions , and investigate the efficiency of these algorithms numerically . </S>",
    "<S> we will also consider the simulation of the variance gamma model , a model used in computational finance , where the generation of these probability distributions are needed . </S>",
    "<S> our results show that the acceptance - rejection technique can result in significant improvements in computing time over the inverse transformation method in the context of low - discrepancy sequences .    </S>",
    "<S> acceptance - rejection method , low - discrepancy sequences , quasi - monte carlo , beta distribution , gamma distribution , variance gamma model .    11k45 , 65c05 , 65c10 , 65c60 , 68u20 </S>"
  ]
}