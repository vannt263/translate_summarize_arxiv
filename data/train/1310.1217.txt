{
  "article_text": [
    "[ sec : intro ] in recent years , compressed sensing ( cs ) @xcite has drawn great attention thanks to its remarkable results concerning signal recovery from vastly undersampled measurements .",
    "cs opened a new path to signal sampling and acquisition , showing that signals could be acquired directly in a compressed fashion , in the perspective of replacing the traditional approach based on collecting as many samples as possible and then removing the redundancy .",
    "however , from the standpoint of practical systems , cs measurements typically need to be transmitted to a receiver .",
    "this raises the concern of how to protect the measurements when the communication channel is unreliable .",
    "a possible protection technique is represented by multiple description coding ( mdc ) .",
    "mdc allows to increase the robustness to channel losses by creating multiple correlated representations of the original data , each carrying enough information to decode separately the data with a certain fidelity , in case of loss of the other descriptions .",
    "the decoding stage consists of _ side decoders _",
    ", able to recover a low - quality version of the data when a single description is received , and a _ central decoder _ , able to jointly exploit all the descriptions for the best decoding quality .",
    "multiple descriptions can be produced in various stages of the transmission chain .",
    "the mdc literature proposes methods which generate descriptions by preprocessing the source ( _ e.g. _ , a trivial method is to separate even and odd samples @xcite ) , by applying a correlating transform @xcite , by using an ad - hoc quantizer @xcite , or by applying channel codes to a layered version of the data to be transmitted @xcite .    in this paper",
    "we propose an mdc approach to cs to make it more robust to unreliable channels .",
    "previous techniques are based on the idea of generating descriptions before sensing , _",
    "e.g. _ , in @xcite an image is partitioned into two subimages before sensing the wavelet coefficients of each .",
    "however , we argue that it could be much more appealing to create the descriptions _ after _ the measurement process . this is supported by the fact that specialised hardware ( _ e.g. _ , @xcite ) may be used to directly acquire the measurements , preventing any preprocessing of the signals . in particular ,",
    "in this paper we propose two novel techniques , graded quantization ( cs - gq ) and cs - split , for multiple description coding of the measurements .",
    "we compare their performance to cs - mdsq , a system applying a multiple description scalar quantizer to the measurement vector .",
    "we will show that cs - gq and cs - split , which exploit the democracy property of the measurements , have lower complexity and better performance than cs - mdsq , which instead relies on a classic mdc method and , as such , does not fully exploit the properties of cs .",
    "moreover , we show how the parameters of cs - gq could be optimized on the expected description - loss probability .",
    "we also address the decoding process , proposing a variant of the basis pursuit denoising ( bpdn ) algorithm for cs reconstruction , which is tailored to cs - gq and can provide significant gains with respect to the standard bpdn .",
    "finally , we provide a bound on the rate - distortion performance of cs - split and cs - mdsq .",
    "[ sec : bkg ] cs is a novel theory for signal sensing and acquisition @xcite able to acquire signals in an already compressed fashion , using fewer coefficients than dictated by the classical nyquist - shannon theory .",
    "let us consider a signal @xmath0 , having a sparse representation under basis @xmath1 : @xmath2 , being @xmath3 the @xmath4 norm of @xmath5 , _",
    "i.e. _ , the number of its nonzero entries .",
    "we acquire measurements as a vector of random projections @xmath6 , @xmath7 , using a sensing matrix @xmath8 . a very popular way to recover the original signal from the measurements is to solve an optimization problem that minimises the @xmath4 norm of the signal in the domain where the signal is sparse . however , this problem is computationally intractable due to its np - hard complexity , so it is common to consider a relaxed form using the @xmath9 norm , which can be solved by means of convex optimization techniques . in presence of bounded noise",
    "it is common to consider an @xmath10 norm constraint using a bound @xmath11 on the noise norm , see .",
    "this is also used when dealing with quantization , which is an important issue in practical systems that require finite precision in the representation of the measurements . in the remainder of the paper we deal with quantized measurements . @xmath12",
    "these methods are successful provided that enough measurements have been acquired , typically @xmath13 .",
    "it is relevant to notice the _ democracy _ of the measurements @xcite , in the sense that each contributes roughly in the same manner to the reconstruction of the signal and no measurement carries significantly more information than the others .",
    "[ graded ]    in this section we describe the proposed multiple description techniques with particular focus on the case of two balanced descriptions .",
    "cs - gq and cs - split rely on partitioning the vector of measurements and quantize the subsets .",
    "those methods are compared against cs - mdsq that is derived from the classical mdc technique of the mdsq .",
    "the measurements are quantized with a uniform scalar quantizer ( with the exception of cs - mdsq ) .",
    "more complex quantizers could also be used , _",
    "e.g. _ , the lloyd - max method or vector quantization , but they are regarded as computationally too complex and with little or no gain as shown in @xcite .",
    "cs - gq ( see fig . [",
    "graded ] ) creates two descriptions by having each measurement coded in a redundant way .",
    "the first description contains the first @xmath14 measurements quantized with @xmath15 levels and the other half with @xmath16 levels , with @xmath17 , corresponding to quantization step sizes @xmath18 and @xmath19 respectively .",
    "conversely , the second description uses @xmath16 and @xmath15 levels respectively .",
    "since the uniform scalar quantizer produces an embedded codebook , it is possible to regard the measurement quantized with the lower rate as being made of the most significant bits of the high - rate version of the same measurement .",
    "thanks to the democracy of the measurements , it is indifferent which measurements are actually finely or coarsely quantized .",
    "this is also the reason why the two descriptions turn out to be balanced . it would also be possible to obtain unbalanced descriptions by varying the ratio of measurements quantized at high and low rates",
    "; this is left for further work .",
    "because each description contains as many measurements as acquired during the sensing process , any of them can be decoded separately to provide a basic quality level , essentially depending on the quantization step sizes employed ( see sec .",
    "[ sec : exp_perf ] ) .",
    "since there are two distinct groups of measurements ( fine and coarse quantization ) inside each description , we can use this knowledge to improve the bpdn algorithm in the reconstruction phase at the side decoders .",
    "in particular we set two @xmath10 constraints , one for each subset , instead of a single one .",
    "moreover , we add two extra constraints called _ quantization consistency _ to ensure that the measurements of the reconstructed signal fall inside the quantization bins of size @xmath18 and @xmath19 of the original measurements . hence , reconstruction at each side decoder is performed solving the following problem :    @xmath20        [ 4c - bpdn ]    in our simulations ( see fig .",
    "[ 4c - bpdn ] ) the modified reconstruction problem shows significant gains with respect to standard bpdn .",
    "this is mainly due to the double @xmath10 constraint , while quantization consistency provides a small gain overall .",
    "the central decoder instead always selects the measurement with finer quantization and runs the standard bpdn procedure .",
    "this means that some pieces of information are discarded by the central decoder because they are redundant .",
    "the issue of redundancy is central in mdc .",
    "the descriptions must share some information on the signal , in order to be independently decodable . in the proposed cs - gq scheme , the amount of redundancy can be tuned in a very flexible way through the choice of parameters @xmath21 and @xmath22 , depending on the desired level of quality at the side and central decoders .",
    "these levels may also depend on the channel error or packet loss rate , in that frequent losses are typically coped with by selecting a higher degree of redundancy .",
    "[ split ]      cs - split ( see fig . [ split ] ) consists in quantizing all the measurements with rate @xmath23 and partitioning the measurements vector into two subsets with @xmath14 measurements each .",
    "the side decoders receive only one subset and recover the signal using , where @xmath24 is the appropriate submatrix of the original sensing matrix . instead , the central decoder can use all the measurements .",
    "cs - split can be regarded as a special case of cs - gq in which @xmath25 and @xmath26 . in this special case",
    "no redundant information is transmitted .",
    "in fact , the central decoder does not discard any information as it happens in cs - gq .",
    "cs - split may be an appealing solution thanks to its extreme simplicity , as it does not require any additional processing other than splitting the measurement vector .",
    "however , we shall discuss in sec .",
    "[ sec : exp_perf ] how cs - split always outperforms cs - gq when the number of measurements is high .",
    "cs - mdsq creates multiple descriptions of the measurements using a special quantizer called mdsq .",
    "the mdsq is a general technique for mdc developed before the advent of cs , so it does not leverage the democracy property as the previous systems do .",
    "the mdsq can be optimised at several levels and can be tuned to operate at different points on the central distortion vs. side distortion curve .",
    "for the results in this paper we used the optimization method outlined in @xcite , using nested assignment for the index assignment matrix .",
    "[ sec : rd ]    consider a @xmath27-sparse signal @xmath28 and its measurements @xmath29 , @xmath30 .",
    "assume that the nonzero entries have zero mean and variance @xmath31 .",
    "assume that the entries of the sensing matrix @xmath24 are i.i.d .",
    "gaussian random variables with @xmath32 and such that @xmath33 and @xmath34 , where @xmath35 is the coherence of @xmath24 .",
    "furthermore , assume that the bpdn algorithm is used for reconstruction .",
    "then the distortion @xmath36 in the reconstructed signal as a function of rate @xmath23 is bounded as follows , with high probability : @xmath37 @xmath38    a very similar argument can be used to analyse cs - mdsq .",
    "the assumptions are the same as before , but the mdsq performance is limited by the ozarow bound @xcite .    under the same hypotheses of theorem 1 ,",
    "the distortion @xmath36 in the reconstructed signal as a function of rate @xmath23 is bounded as follows , with high probability : @xmath39 @xmath40 with    @xmath41^{-1}\\ ] ]    and @xmath42 $ ] .",
    "the proofs of the previous results and experimental results showing their validity are omitted for brevity . by looking at the lower bounds it can be seen that cs - split can potentially achieve @xmath43 points that are unavailable for cs - mdsq .",
    "[ sec : exp_perf ]        \\(a ) side relative distortion        \\(b ) central relative distortion    [ perf_vs_redundancy ]        [ centr_side_tradeoff ]        \\(a ) side relative distortion        \\(b ) central relative distortion    [ perf_vs_m ]",
    "\\(a ) side relative distortion        \\(b ) central relative distortion    [ perf_vs_bits ]    in this section we compare the reconstruction performance of the side and central decoders of the proposed methods . as distortion",
    "we consider the normalised error norm @xmath44 .",
    "first , we characterise the relative performance of cs - gq and cs - split at equal bit - rate for the same number of measurements .",
    "suppose that cs - split uses a rate of @xmath23 bits per measurement , then we must have @xmath45 . from fig .",
    "[ perf_vs_redundancy ] we can see that cs - gq improves side decoding performance for increasing redundancy until the full redundancy case ( @xmath46 ) is reached , while at the same time central decoding performance worsens .",
    "cs - split is the extreme case with best central but worst side performance .",
    "the appropriate values of @xmath22 and @xmath21 can be selected from the trade - off plot show in fig .",
    "[ centr_side_tradeoff ] , according to the desired trade - off between side and central distortion .",
    "if a memoryless channel has a probability @xmath47 of losing a description , we can define an average distortion @xmath48 . keeping in mind that @xmath49 is a function of @xmath50 and letting @xmath51",
    ", we get @xmath52 .",
    "this is the slope of the straight line that is tangent to the trade - off plot in the point representing the optimal trade - off between central and side distortion , so it can be used to determine the optimal values of @xmath22 and @xmath21 for a channel with given packet - loss rate . in our case",
    "the feasible points are a discrete set and this method can only select one of the points lying on the convex hull .",
    "notice that @xmath53 selects cs - split ( there are no losses , hence we seek the best central performance and minimum redundancy ) and that for @xmath54 full redundancy is approached where cs - gq behaves like a repetition code .",
    "we should also notice that cs - gq providing gains at the side decoders , with respect to cs - split , is the typical behaviour when @xmath55 is small ( _ e.g. _ , @xmath55 is so small that cs - split fails side decoding , or bigger but still in the regime in which extra measurements are more important than finer quantization ) .",
    "in fact , when @xmath55 grows very large , cs - split is always favourable due to the convenience in investing the budgeted bits in finer quantization rather than in extra measurements .    comparing the performance with respect to cs - mdsq , we can see that if the number of measurements is fixed a priori , cs - gq and cs - split can benefit from higher quantization rates and thus outperform cs - mdsq most of the times as shown in fig .",
    "[ perf_vs_m ] .",
    "cs - mdsq can be advantageous only when we are forced to acquire few measurements , but for the same total bit - rate a slight oversampling can allow to use the more efficient graded quantization .",
    "[ perf_vs_bits ] shows the case of a fully tunable system in which both the number of measurements and the rate can be adjusted .",
    "also in this case we can see that graded quantization has lower reconstruction distortion both for central and side decoding in many practical settings .",
    "in this paper we showed how the democracy property of cs measurements enables to address the multiple descriptions problem in a simple and yet effective manner .",
    "we proposed methods to generate multiple descriptions from cs measurements , without the need of preprocessing the signal .",
    "as a term of comparison with classical literature on mdc , cs - mdsq is derived from the mdsq , and does not explicitly rely on properties of cs .",
    "in fact , we showed that it can be outperformed by the other proposed methods in many cases .",
    "cs - gq and its limit case cs - split leverage the democracy of the measurements to create balanced descriptions in a straightforward manner , yet allowing great flexibility in selecting the desired trade - off between central and side distortion .",
    "mohr , e.a .",
    "riskin , and r.e .",
    "ladner , `` unequal loss protection : graceful degradation of image quality over packet erasure channels through forward error correction , '' , vol .",
    "18 , no . 6 , pp .",
    "819 828 , june 2000 .",
    "d.  liu , d.  gao , and g.  shi , `` compressive sensing - based multiple description image coding for wireless channel , '' in _ wireless communications and signal processing ( wcsp ) , 2010 international conference on _ , oct .",
    "2010 , pp . 1 5 ."
  ],
  "abstract_text": [
    "<S> the compressed sensing paradigm allows to efficiently represent sparse signals by means of their linear measurements . </S>",
    "<S> however , the problem of transmitting these measurements to a receiver over a channel potentially prone to packet losses has received little attention so far . in this paper </S>",
    "<S> , we propose novel methods to generate multiple descriptions from compressed sensing measurements to increase the robustness over unreliable channels . in particular , we exploit the democracy property of compressive measurements to generate descriptions in a simple manner by partitioning the measurement vector and properly allocating bit - rate , outperforming classical methods like the multiple description scalar quantizer . </S>",
    "<S> in addition , we propose a modified version of the basis pursuit denoising recovery procedure that is specifically tailored to the proposed methods . </S>",
    "<S> experimental results show significant performance gains with respect to existing methods .    </S>",
    "<S> compressed sensing , multiple description coding , error resilience </S>"
  ]
}