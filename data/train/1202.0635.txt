{
  "article_text": [
    "computer simulation is an essential tool for studying physical properties of many - particle systems .",
    "the metropolis - type monte carlo simulation @xcite with a single spin flip has been a success as a standard method of simulation of many - particle systems .",
    "however , the single - spin - flip algorithm often suffers from the problem of slow dynamics or the critical slowing down ; that is , the relaxation time diverges at the critical temperature . to overcome difficulty ,",
    "a cluster flip algorithm was proposed by swendsen and wang @xcite .",
    "they applied the fortuin - kasteleyn @xcite representation to identify clusters of spins .",
    "the problem of the thermal phase transition is mapped onto the geometric percolation problem in the cluster formalism . in the cluster algorithm , spins in the cluster are updated at a time . in the swendsen - wang ( sw )",
    "algorithm , all the spins are partitioned into clusters ; thus , the sw algorithm is called the multi - cluster algorithm .",
    "wolff @xcite proposed another type of cluster algorithm , that is , a single - cluster algorithm , where only a single cluster is generated , and the spins of that cluster are updated . although the cluster algorithm was originally formulated for the scalar order parameter , such as the potts model , wolff @xcite introduced the idea of embedded cluster to deal with systems of vector spins , such as the classical xy model or the classical heisenberg model .",
    "computational physics develops with the advance in computer technology .",
    "recently the use of general purpose computing on graphics processing unit ( gpu ) is a hot topic in computer science .",
    "drastic reduction of processing times can be realized in scientific computations .",
    "using the common unified device architecture ( cuda ) released by nvidia , it is now easy to implement algorithms on gpu using standard c or c++ language with cuda specific extension .",
    "preis _ et al . _",
    "@xcite studied the two - dimensional ( 2d ) and three - dimensional ( 3d ) ising models by using the metropolis algorithm with cuda .",
    "they used a variant of sublattice decomposition for a parallel computation on gpu .",
    "the spins on one sublattice do not interact with other spins on the same sublattice .",
    "therefore one can update all spins on a sublattice in parallel when making the metropolis simulation . as a result",
    "they were able to accelerate 60 times for the 2d ising model and 35 times for the 3d ising model compared to a current cpu core .",
    "recently , the gpu acceleration of the multispin coding of the ising model was discussed @xcite . moreover ,",
    "many attempts for simulating lattice spin models on gpu using the metropolis algorithm were reported @xcite .    since the metropolis algorithm has the problem of slow dynamics as mentioned above , and this problem becomes conspicuous with increasing the system size , it is highly desirable to apply the gpu - based calculation to cluster algorithms .",
    "only limited trials have been reported so far .",
    "the present authors @xcite have proposed the gpu - based calculation with cuda for the wolff single - cluster algorithm , where parallel computations are performed for the newly added spins in the growing cluster .",
    "_ @xcite have studied the cuda implementation of the wolff algorithm using a modified connected component labeling for the assignment of the cluster .",
    "they put more emphasis on the hybrid implementation of metropolis and wolff updates and the optimal choice of the ratio of both updates . quite recently , weigel @xcite has studied parallelization of cluster labeling and cluster update algorithms for calculations with cuda .",
    "he realized the sw multi - cluster algorithm by using the combination of self - labeling algorithm and label relaxation algorithm or hierarchical sewing algorithm . in this paper , we present the gpu - based calculation with cuda for the sw multi - cluster algorithm of 2d classical spin systems .",
    "we realize the sw cluster algorithm by using the connected component labeling algorithm for the assignment of clusters . the rest of the paper is organized as follows . in section 2 ,",
    "we briefly describe the standard way of implementing the sw algorithm on cpu . in section 3 , we explain two types of connected component labeling which are used in the present calculation , and the idea of implementing the sw cluster algorithm on gpu . in section 4 , we compare the performance of gpu calculation with that of cpu calculation . the summary and discussion are given in section 5 .",
    "we start with the potts model whose hamiltonian is given by @xmath4 and for @xmath0 = 2 this corresponds to the ising model . here , @xmath5 is the coupling and @xmath6 is the potts spin on the lattice site @xmath7 .",
    "the summation is taken over the nearest neighbor pairs @xmath8 .",
    "periodic boundary conditions are employed .",
    "swendsen and wang proposed a monte carlo algorithm of multi - cluster flip @xcite .",
    "there are three main steps in the sw algorithm : ( 1 ) construct a bond lattice of active or non - active bonds .",
    "( 2 ) the active bonds partition the spins into clusters which are identified and labeled using a cluster - labeling algorithm . ( 3 ) all spins in each cluster are set randomly to one of @xmath0 .",
    "the cluster identification problem is a variant of connected component labeling , which is an algorithmic application of graph theory . for an efficient cluster - labeling algorithm ,",
    "the hoshen - kopelman algorithm @xcite , which was first introduced in context of cluster percolation , is often used .",
    "the hoshen - kopelman algorithm is a special version of the class of union - and - find algorithms @xcite , and has an advantage over other methods in low computer memory usage and short computational time .",
    "the actual spin - update process of the sw cluster algorithm on a cpu can be formulated as follows @xcite :    * choose a site @xmath7 .",
    "* look at each of the nearest neighbors @xmath9 . if @xmath10 is equal to @xmath11 , generate bond between site @xmath7 and @xmath9 with probability @xmath12 , where @xmath13 is the inverse temperature @xmath14 .",
    "* choose the next spin and go to ( i ) until all sites are checked .",
    "* apply the hoshen - kopelman algorithm @xcite to identify all clusters .",
    "* choose a cluster .",
    "* assign the spins @xmath11 in the cluster to one of @xmath0 with probability @xmath15 .",
    "* choose another cluster and go to ( vi ) until all clusters are checked .",
    "* go to ( i ) .",
    "the procedures from ( i ) to ( iii ) correspond to the step of active bond generation .",
    "the procedure ( iv ) corresponds to the step of cluster labeling . those from ( v ) to ( vii )",
    "correspond to the step of spin flip .    in the hoshen - kopelman cluster - labeling algorithm ,",
    "integer labels are assigned to each spin in a cluster .",
    "each cluster has its own distinct set of labels .",
    "the proper label of a cluster , which is defined to be the smallest label of any spin in the cluster , is found by the following function .",
    "the array ` label ` is used , and if ` label ` is a label belonging to a cluster , the ` label[label ] ` is the index of another label in the same cluster which has a smaller value if such a smaller value exists .",
    "the proper label for the cluster is found by evaluating ` label[label ] ` repeatedly .",
    "since the calculations of the step of active bond generation and the step of spin flip are done independently on each site , these steps are well suited for parallel computation on gpu . on the other hand , in the step of cluster labeling the assignment of label of cluster",
    "is done on each site piece by piece sequentially ; thus the cluster - labeling algorithm such as the hoshen - kopelman algorithm can not be directly applied to the parallel computation on gpu .",
    "two steps of iterations of the `` label equivalence '' method proposed by hawick _",
    "the connection of sites in the same cluster is represented by the same color , and the arrow shows the neighboring sites to check for comparison .",
    "the thread number is denoted by `` index '' .",
    "the variable for saving label and the temporal variable are represented by `` label '' and `` r '' , respectively .",
    "the scanning function compares `` label '' of each site with that of the nearest - neighbor sites . if `` label '' of the nearest - neighbor site is smaller than `` label '' of that site , `` r[label ] ''",
    "is updated to the smallest one .",
    "the equivalence chain of `` r '' is resolved in the analysis function from the starting site to the new site if `` label[index ] '' is equal to `` index '' .",
    "the labeling function updates `` label '' by label[index ] @xmath16 r[label[index ] ] .",
    "although some clusters are not represented by the same `` label '' at the end of the 1st step in this case , all the sites reaches the final label by two steps of iteration . the process of update of `` r '' in the 2nd step is also shown in the figure . ]    recently , hawick _ et al . _",
    "@xcite studied the cluster - labeling algorithm efficient for gpu calculation . checking four implementations of multi - pass labeling method",
    ", they proposed the labeling method of `` label equivalence '' , which is the most efficient among four proposals .",
    "the procedure of their algorithm is explained in figure [ fig : fig1 ] .",
    "their algorithm consists of three kernel functions , that is , scanning function , analysis function and labeling function , and two variables for labeling ; one is a variable for saving the label , `` label '' in figure [ fig : fig1 ] , and the other is a temporal variable for updated label , `` r '' in figure [ fig : fig1 ] .",
    "the scanning function compares the label of each site with that of the nearest - neighbor sites when the bond between each site and the nearest - neighbor site is active .",
    "if the label of the nearest - neighbor site is smaller than the label of that site , the temporal variable with the label number , r[label[index ] ] in figure [ fig : fig1 ] , is updated to the smallest one . for the update of the temporal variable on the scanning function , the atomic operation ` atomicmin ( ) `",
    "atomic operations provided by cuda are performed without interference from any other threads .",
    "the analysis function resolves the equivalence chain of `` r '' obtained in the scanning function ; the temporal variable ` r[index ] ` is updated from the starting site to the new site , which is similar to the method of the hoshen - kopelman algorithm .",
    "each thread checks the temporal variable and the label on each site . when the label number , `` label '' , is equal to the thread number , `` index ''",
    ", each thread tracks back the temporal variable until the temporal variable , `` r '' , remains unchanged .",
    "since each thread executes this operation concurrently , the final value is reached quickly .",
    "the labeling function updates the label for saving by ` label[index ] ` @xmath16 ` r[label[index ] ] ` . in the cluster - labeling algorithm due to hawick _",
    "_ , the loop including three functions is iterated up to the point when the information of the labeling needs no more process of scanning function",
    ". a small number of iterations are needed ; 4096@xmath174096 systems with free boundary conditions were labeled in 9 or less iterations @xcite .     the first step of iterations of the refinement of label equivalence method proposed by kalentev _",
    "the meanings of color and arrow are the same as figure [ fig : fig1 ] .",
    "the thread number is denoted by `` index '' .",
    "the scanning function compares `` label '' of each site with that of the nearest - neighbor sites .",
    "the equivalence chain is resolved in the analysis function from the starting site to the new site if `` label[label ] '' is not equal to `` label '' , which results in the update of `` label '' . since the cluster - labeling due",
    "to kalentev is the refined version of that due to hawick , the output of labeling is the same as figure [ fig : fig1 ] .",
    "some clusters are not represented by the same `` label '' at the end of the 1st step in this case , but all the sites reaches the final label by two steps of iteration . ]    more recently , kalentev _ et al . _",
    "@xcite reported the refinement of the algorithm due to hawick _",
    "et al._. the procedure of their algorithm is shown in figure [ fig : fig2 ] .",
    "first , they used only one variable for labeling instead of two because there is no need for a temporal reference ; the implementation was improved in terms of memory consumption .",
    "it means that the number of kernel functions are reduced from three to two because the process of the labeling function is no more needed .",
    "second , they changed the execution condition on the analysis function from `` when ` label[index ] ` is equal to ` index ` '' to `` when ` label[label ] ` is not equal to ` label ` '' .",
    "finally , they eliminated the atomic operation .",
    "the update of labeling is executed up to the point when the labeling needs no more process of the scanning function ; thus even if collision between threads happens because of the absence of the atomic operations , it will be resolved during the next iterative step . with the refinements due to kalentev _",
    "_ , the improvement of computational speed and the reduction of the memory usage were realized .",
    "we adapt the two cluster - labeling algorithms , that due to hawick _",
    "_ @xcite and that due to kalentev _",
    "@xcite , to the sw multi - cluster algorithm of monte carlo simulation . in the cluster - labeling algorithms ,",
    "the label of the cluster is not given serially .",
    "to flip the spins in the cluster of the sw algorithm , we do not have to know the serial number for the label of the cluster .",
    "we assign the new spin to any label number even if the cluster of that label does not exist .",
    "because of parallel computation , the assignment of new spin to all the possible number of labels requires no extra cost . to improve the computational speed and save memory , we store the information on spin , bond and label in one word ; this idea was used by hawick _",
    "_ @xcite . in the case of treating the system with many spin states , for example , we separate the information on spin from the one - word information .",
    "we finally note that we use a linear congruential random generator which was proposed by preis _",
    "@xcite when random numbers are generated .",
    "we have tested the performance of our code on nvidia geforce gtx580 and gtx285 . for comparison , we run the code on a current cpu , intel(r ) xeon(r ) cpu w3680 @ 3.33ghz .",
    "only one core of the cpu is used . for compiler ,",
    "we have used gcc 4.1.2 with option -o3 .",
    "we first show the data for the 2d @xmath0-state potts models . for the cluster - labeling algorithm , we use both the algorithm due to hawick _",
    "_ @xcite and that due to kalentev _",
    "we compare the gpu computational time with the cpu computational time at the critical temperature , @xmath18 for the @xmath1 potts model ( ising model ) and @xmath19 for the @xmath20 potts model .",
    "the average computational times per a spin update at the critical temperature for the @xmath1 potts model and the @xmath20 potts model are tabulated in tables [ tb : gpu_cpu_time_q=2_potts ] and [ tb : gpu_cpu_time_q=3_potts ] , respectively . there , the time for only a spin update and that including the measurement of energy and magnetization are given .",
    "we show the measured time per a spin flip in units of nano sec .",
    "the linear system sizes @xmath21 are @xmath21=256 , 512 , 1024 , 2048 and 4096 .",
    "we can see from tables [ tb : gpu_cpu_time_q=2_potts ] and [ tb : gpu_cpu_time_q=3_potts ] that the computational time of our gpu implementation of the sw algorithm is almost constant for @xmath22 . and the computational speed using the algorithm of kalentev _ et al .",
    "_ is superior to that of hawick _ et al .",
    "_ for all system sizes . the performance for @xmath1 with the algorithm of hawick _ et al",
    "_ is 2.96 nano sec per a spin flip and that with the algorithm of kalentev _ et al . _",
    "is 2.51 nano sec per a spin flip with @xmath3 on gtx580 .",
    "the comparison of the performance on gtx580 and that on cpu leads to the acceleration of computational speed with the algorithm of kalentev _ et al .",
    "_ as 12.4 times for a spin flip and 12.6 times for a spin flip with the measurement of energy and magnetization for the @xmath1 potts model with @xmath3 .",
    "the number of iterations at the critical temperature is about 6.6 , 7.1 , 7.6 , 8.1 and 8.6 on average for @xmath21 = 256 , 512 , 1024 , 2048 and 4096 , respectively ; that is , the loop count gradually increases with system size .",
    "we here mention the amount of memory used .",
    "the amount of register is 10 to 13 bytes per thread , and the amount of shared memory is 2048 bytes per block for each kernel function . these values remain unchanged by system size . using `` gpu occupancy calculator '' , we checked that the gpu occupancy is 100% for each kernel function , which indicates that the best performance of gpu is attained .    [ cols=\"<,<,<,<,<,<,<\",options=\"header \" , ]     although the calculation of the clock model on cpu takes much more time than that of the potts model , the computational time for the gpu - based calculation of the clock model is almost the same as that of the potts model .",
    "the proper use of shared memories may contribute to the good performance for the clock model .",
    "the performance of the @xmath2 clock model with the cluster - labeling algorithm of hawick _ et al . _ is 2.88 nano sec per a spin flip and that with the algorithm of kalentev _ et al . _ is 2.42 nano sec per a spin flip with @xmath3 on gtx580 .",
    "the acceleration of computational speed over the calculation on cpu with the algorithm of kalentev _ et al . _ is 35.6 times for a spin flip and 42.7 times for a spin flip including the measurement of energy , magnetization and correlation function with distances @xmath23 and @xmath24 for the @xmath2 clock model with @xmath3 .",
    "the temperature dependence of our gpu - based calculation of the sw algorithm for the @xmath2 clock model is plotted in figure [ fig : fig5 ] .",
    "the linear system size is @xmath25 .",
    "we show the average computational time per a spin flip in units of nano sec . from figure",
    "[ fig : fig5 ] we can see that the computational time weakly depends on the temperature . thus , we can say that our gpu implementation of the sw multi - cluster algorithm is also effective for the clock model in all range of temperatures .",
    "temperature dependence of the computational time for gpu computation for the @xmath2 clock model with @xmath25 . ]    as an illustration , we plot the ratio of the correlation function @xmath26 of the @xmath2 clock model in figure [ fig : fig6 ] .",
    "we discarded the first 10,000 monte carlo updates and the next 400,000 monte carlo updates were used for measurement . from figure",
    "[ fig : fig6 ] , we see that the curves of different sizes overlap in the intermediate kosterlitz - thouless phase ( @xmath27 ) , and spray out for the low - temperature ordered and high - temperature disordered phases .",
    "the graph reproduces the result shown in fig .",
    "2 of ref .",
    "@xcite for small sizes .",
    "recently , the estimate of two transition temperatures of @xmath2 clock model is an issue of controversy @xcite .",
    "the detailed analysis of the clock models using the finite - size scaling analysis will be given elsewhere .",
    "temperature dependence of the ratio of the correlation function for the @xmath2 clock model for @xmath21=256 , 512 , 1024 and 2048 .",
    "we have formulated a gpu parallel computing of the sw multi - cluster algorithm by using the two connected component labeling algorithms , the algorithm by hawick _",
    "_ @xcite and that by kalentev _",
    "@xcite , for the assignment of clusters .",
    "starting with the @xmath0-state potts model , we also extended our implementation to systems of vector spins using the idea of embedded cluster by wolff @xcite .",
    "we have tested the @xmath0-state potts models with @xmath0=2 and 3 and the @xmath0-state clock model with @xmath2 by use of our implementation of the sw algorithm . as a result , the gpu computational time by using the cluster - labeling algorithm by kalentev _",
    "is 2.51 nano sec per a spin update for the @xmath1 potts model and 2.42 nano sec per a spin update for the @xmath2 clock model on gtx580 with the linear size @xmath3 at the critical temperature .",
    "the performance of the algorithm by kalentev _",
    "et al . _ is superior to that of hawick _ et al .",
    "_ for all models and sizes .",
    "it confirms the effectiveness of refinement by kalentev _",
    "et al . _ ; that is , the elimination of atomic operation and the reduction of the number of kernel functions .",
    "we obtained that the computational time of our implementation is almost constant for the linear size @xmath22 , and there is little temperature dependence for our sw multi - cluster algorithm .",
    "now we compare the performance of our implementation of the sw multi - cluster algorithm with that of weigel @xcite .",
    "he uses the combination of self - labeling algorithm and label relaxation algorithm or hierarchical sewing algorithm . comparing with the breadth - first search and the tree - based union - and - find approach ,",
    "the self - labeling algorithm is used in partitioning a set of elements into disjoint subsets . to consolidate cluster labels , the label relaxation algorithm and the hierarchical sewing algorithm",
    "the gpu computational time of his algorithm was reported as 2.70 nano sec per a spin update for the @xmath1 potts model at the critical temperature with the linear size @xmath28 on gtx580 .",
    "the performance of the algorithm of weigel strongly depends on system size and temperature , and this speed of 2.70 nano sec per a spin update is reached only for @xmath28 .",
    "the performance becomes much worse for @xmath29 and at temperatures below the critical temperature . on the other hand ,",
    "the gpu computational time of our algorithm is 2.51 nano sec for the same model with @xmath3 on the same gpu , gtx580 , and our implementation of the sw algorithm has little dependence on system size and temperature .",
    "we have shown the data up to @xmath3 in this paper because we use one - dimensional index in launching a cuda kernel .",
    "since the amount of memory on gtx580 is 1.5 gbyte , we can treat the system up to @xmath28 by using the two - dimensional index .",
    "the algorithm employed here implements the labeling over the whole lattice instead of partitioning . because of the flexibility of our implementation",
    ", it will be interesting to apply the present formulation to multi - gpu calculations .",
    "there are advantages in both our implementation and that by weigel .",
    "the application of gpu to cluster algorithms has just started .",
    "this problem deserves further attention .",
    "this work was supported by a grant - in - aid for scientific research from the japan society for the promotion of science .                                t. h. cormen , c. e. leiserson , r. l. rivest , c. stein , introduction to algorithms , mit press , third edition , 2009 . w. janke , monte carlo simulations of spin systems , in _ computational physics _ , edited by k. h. hoffmann and m. schreiber ( springer , berlin , 1996 ) , pp ."
  ],
  "abstract_text": [
    "<S> we present the gpu calculation with the common unified device architecture ( cuda ) for the swendsen - wang multi - cluster algorithm of two - dimensional classical spin systems . </S>",
    "<S> we adjust the two connected component labeling algorithms recently proposed with cuda for the assignment of the cluster in the swendsen - wang algorithm . starting with the @xmath0-state potts model , we extend our implementation to the system of vector spins , the @xmath0-state clock model , with the idea of embedded cluster . </S>",
    "<S> we test the performance , and the calculation time on gtx580 is obtained as 2.51 nano sec per a spin flip for the @xmath1 potts model ( ising model ) and 2.42 nano sec per a spin flip for the @xmath2 clock model with the linear size @xmath3 at the critical temperature , respectively . </S>",
    "<S> the computational speed for the @xmath1 potts model on gtx580 is 12.4 times as fast as the calculation speed on a current cpu core . that for the @xmath2 clock model on gtx580 is 35.6 times as fast as the calculation speed on a current cpu core .    </S>",
    "<S> monte carlo simulation , cluster algorithm , ising model , parallel computing , gpu </S>"
  ]
}