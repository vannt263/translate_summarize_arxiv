{
  "article_text": [
    "the problem of amputations is very actual . according to data from the national center for health statistics , there are 50,000 new amputations every year in the usa .",
    "the statistics of copc ( center for orthotic @xmath0 prosthetic care ) show that the level of amputation concerns the upper limb in 86 @xmath1 of cases and lower limb in 14 @xmath1 . among upper limb amputees ,",
    "the trans - radial ones make up the 60 @xmath1 of total wrist and hand amputations . + starting from this statistics",
    "we focus our attention on upper limb trans - radial amputees .",
    "reasons for amputations include cardiovascular disease , traumatic accidents , infection , cancer , nerve injury and congenital anomalies ( in according to ishn statistics ) . in the figure [ fig : pie ]",
    "statistic for upper limb amputees is shown .",
    "[ h ]     nowadays there exists two types of prosthetic hands : invasive and non - invasive .",
    "the first ones provide for direct installation in the arm of the amputee with the surgery .",
    "the second ones can be put on during day and removed in the night or when an amputee wants . in this work",
    "we focus on myoelectric prosthetic hands that belong to the second type of prosthesis .",
    "these are very advanced from the hardware point of view thanks to the exploitation of several portable sensors used to gather the electrical signal from the stump of an amputee . from a software view of point",
    ", the prosthesis is controlled with several algorithms that analyse the input signal and provide the best output movement .",
    "examples of prosthesis are shown in figure [ fig : prosthhand ] .",
    "+    [ h ]     nowadays robotics has reached great heights and there exist robotic hands designed to perform any desired task or a predetermined sequence of these .",
    "also the prosthesis , built for the amputees , are very advanced : these have five fingers and can potentially perform all the possible configurations , like a human hand . + despite the rapid progress that robotics has had in last years , for an amputee the control of non - invasive robotic prosthetic hand is still far ( @xcite ) .",
    "the real challenge in the world of robotic hands is to achieve the total control of prosthesis .",
    "in fact , in most cases the tasks that an amputee can perform with this are limited to opening and closing .",
    "the control of prosthetic hand is far from simulation of natural movements and the training process to make amputees familiar with them is still long and sometime painful ( @xcite and references therein ) .",
    "+ the open challenge in the world of bio - robotics is to try to reduce the time required for learning of use of prosthesis and to make this control as natural as possible .",
    "+      this thesis tackles the control of prosthesis with an approach based on machine learning , as previous works in this field suggest ( @xcite , @xcite , @xcite ) .",
    "our purpose is to increase the level of dexterity in the use of prosthesis , in order to favour a natural form of control . + the prosthesis to which we refer in this work are composed by several electrodes that gather the electromyography ( emg ) signal , i.e. the electrical manifestation of muscular activation . with machine learning techniques , we analyse this signal in order to decide the most probable movement that the subject wants to perform .",
    "+ currently , machine learning algorithms have success in this field , and not only , for their generality and for the possibility to enlarge the traditional theory .",
    "one of the most famous definition of machine learning is provided by tom m. mitchell and can be summarized as follow : a computer program is said to learn if its performance at a given task is improving with experience .",
    "+ the given definition is enough intuitive because it is not very far from the traditional human learning and skill .",
    "human beings do nt learn new things in isolation but with the help of what it is already known : i.e. their previous experience ( @xcite ) .",
    "+ this intuition can be extended also for the control of prosthesis : for an amputee could be simpler to learn a movement using experience from other subjects that are already able to perform this . if this statement is true , which previous experience to exploit could play a key role and could change the final learning result .",
    "thus , the questions that this thesis aims to answer are essentially two :    * is it possible to speed up the process of control of prosthesis with the help of prior experience ? * what does it change when we use for an amputee the experience from other amputees , as opposed to that from intact subjects ?    the contribution of this work is to answer to these queries following an experimental approach . in order to achieve this goal we performed a thorough series of simulations exploiting data from a public database .",
    "our results show that the help of previous experiences boost the control of prosthetic hands and speed up the learning process . for an amputee",
    "it is not achieved a different result when experience from amputated or intact subjects is exploited .",
    "+      the content of this thesis is organized as follows : + in chapter [ cha : few_land ] we give some landmarks useful to have an introduction of the problems tackled in the following and a general vision of the entire work .",
    "we begin with an overview of different kind of prosthesis and the general problems and challenges related to their usage and control . in the end of the chapter we enumerate all the contributions given by previous works in this field about data , analysis and algorithms .",
    "+ in chapter [ cha : data ] we describe the experiment ninapro that gathered kinematic , dynamic and electromyographic data from intact and amputated subjects and built the database that we used in our experiments . in the first part of the chapter we describe in detail the acquisition protocol , used devices and the data collection .",
    "in the second part we describe the path generally followed in this field for processing and representation of raw data acquired",
    ". + chapter [ cha : algorith ] focuses on the learning algorithms used in this work to solve the problem of recognition and classification of different hand movements .",
    "first we present an introduction about the traditional and innovative theories on which these methods are based . in the second part we introduce the used algorithms and their implementation .",
    "+ in chapter [ cha : results ] we present our experiments and results obtained .",
    "we have worked with three different settings using data described in chapter [ cha : data ] and algorithms introduced in chapter [ cha : algorith ] .",
    "first we present each experimental protocol and the results obtained in the three experiments done .",
    "we conclude with an overall discussion and comparison of our findings .",
    "+ the thesis ends with a conclusive summary and possible direction of research and future works .",
    "this chapter gives a general vision of the entire works : it aims to focus the problems linked to prosthesis , the best path to tackle them and the related works useful in this task .",
    "+ section [ sec : pros ] focuses on different prosthesis currently used by amputees . after a general introduction , we list the problems that an amputee tackles when he / she learns how to use a prosthetic hand .",
    "+ section [ sec : challeng ] is about challenges and questions that this work aims to solve .",
    "we explain the general path taken and , briefly , the results obtained .",
    "+ in section [ sec : exp_frame ] we report a general vision and a summary of all the work developed . + in section",
    "[ sec : prev_work ] we list the principal works that have dealt with related problems .",
    "+      as said in the introduction , our study is referred to upper limb amputated , that are the majority in the community of amputees , and to non - invasive prosthesis .",
    "+ the most common non - invasive prosthesis are : cosmetics , body - powered and myoelectrics ( figure [ fig : prosthesis ] ) . +    [ h ]     [ fig : prosthesis ]    the cosmetic ones are only aesthetic hands , they are comfortable but any type of grasping or movement is forbidden .",
    "+ the body - powered are mechanical prosthesis , they work by using cables to link the movement of the body to the prosthesis and to control it . when an amputee moves the body in a certain way he / she drives the cables , consequently the prosthetic hand is opened , closed , or bended . obviously only few movements can be performed .",
    "+ the myoelectric prosthesis use several electrodes placed in contact with the skin of the stump .",
    "these kind of electrodes are called electromyography surface and they detect electrical activity produced by skeletal muscles when a movement is performed .",
    "the recorded electromyographic signal ( emg ) varies in : @xmath2 ( @xcite and references therein ) .",
    "the electrodes record the muscular activity , the signal is analysed in order to decide the intentional movement and , theoretically , infinite positions can be performed .",
    "+ in this work we study the control of non - invasive myoelectric prosthesis .",
    "they could potentially improve the quality of life of an amputee , but the control system is difficult . the open challenge in the world of myoelectric prosthesis is to try to reduce the training time , i.e. the time required for learning how to use them .",
    "nowadays , this is still a very long process , often with great mismatch between desired and performed movements .",
    "moreover this is generally perceived as very tiring and sometimes painful by the users .",
    "these reasons make the use of myoelectric prosthesis still limited in practice .",
    "often the amputees stop using this kind of prosthetic hands and replace them with a cosmetic ones ( @xcite ) .",
    "+      the control of robotic prosthetic hands using non - invasive techniques , like myoelectrical surface , is still a challenge nowadays . in bio - robotics and rehabilitation community",
    "it is clear that the success of myoelectric prosthesis is linked to the creation of an accurate control system to make them easy to use by the patient ( see @xcite and references therein ) .",
    "+ the path generally chosen to tackle the problem is machine learning ( @xcite , @xcite , @xcite and references therein ) .",
    "it makes it possible to analyse the electromyography signal with modern statistical techniques like support vector machines , neural networks and linear discriminant , in order to guess the movement that the subject wants to perform ( @xcite ) . generally with these techniques",
    "a subject can choose among a finite number of hand postures .",
    "thus , the final configurations are not all the possible ones but only a selection of these . + in a machine learning problem a learner system tries to perform a task with the help of previous experience . in our work",
    "the learner is the subject that wants to learn to perform several movements with a robotic hand .",
    "evidently , the choice of experience influences the whole problem .",
    "+ most of the existing machine learning methods build a new learning model directly over the data from the learner itself . in our case , starting from the emg signals collected from the user , it is built a function that , for any future unknown emg signal , chooses the most probable hand posture associated .",
    "this method gives good results only if a large amount of training samples of the subject is available .",
    "+ most recent algorithms suggest to exploit a source of knowledge external to the subject studied : i.e. experience from other subjects .",
    "if this previous experience consists in robust statistical models built in the past , these can be reused when a new patient trains the prosthesis .",
    "+ obviously a form of adaptation is needed when we use experience from a subject to boost the learning of a new patient because the two domains could differ .",
    "the emg signal recorded from different subjects can vary due to characteristics of the forearm ( like size and shape ) , personal characteristics of subjects ( like gender , age , use of the arm ) , electrode displacement and muscular fatigue ( @xcite ) .",
    "+ by using state of the art adaptive learning algorithms , we want to understand if knowledge from other subjects can boost the control of prosthesis and reduce the learning time for a new amputee .",
    "previous experience that an amputee exploits to achieve the goal of a natural use of prosthesis could come from amputees or from intact subjects .",
    "our task is to study how the final result might change in the two cases .",
    "+      we clarify now all the passages to perform an experiment that aims at the control of non - invasive myoelectric prosthesis .",
    "+ we consider intact and amputated subjects from which we gather electromyographic data .",
    "these data are collected by using , as sensors , surface electrodes placed on the last part of the arm for an amputee , or on the forearm for an intact subject .",
    "these electrodes detect the electromyographic signal generated by muscular contractions , where each signal corresponds to a different movement .",
    "+ the aim of prosthetic control is to establish the best output movement for each given input signal . in order to achieve this goal",
    "the input data are processed to remove a component of noise . in a second step ,",
    "we extract useful information from the data , in order to determine the discriminant characteristics of signal that we want to classify .",
    "this process is called features extraction .",
    "+ data appropriately processed are used as input of different recognition algorithms .",
    "these algorithms solve in different ways a classification problem : given an input signal their aim is to find the right output movement ( i.e. the right class ) between the ones proposed . in this kind of problem",
    "is not possible to select other classes than the initial ones , thus the final hand movements are not all those that are the possible .",
    "each algorithm works by exploiting differently the previous experience coming from source subjects .",
    "+ all the described steps are reported schematically in figure [ fig : movprocesses ] . +    [ h ]     in this work we exploited data acquired during the experiment _ ninapro _ ( 2011 - 2013 ) and online available . after the choice of data with which to work , we were dedicated to their processing and representations , following what the literature proposes . to solve the final classification problem we used the adaptive learning algorithms that constitute the state of the art in the field of machine learning .",
    "+      [ [ database - and - emg - signal . ] ] database and emg signal .",
    "data used in this work have been collected in the experiment _ ninapro _ , where 10 or 12 semg electrodes ( it depends on the chosen configuration ) gather the electical signal from the arm of the users . in @xcite , @xcite , @xcite all the details about used devices ,",
    "the acquisition protocol and any information on database are present .",
    "+ ninapro represents an important contribution in this field because it is , in according to our knowledge , the only existing public database that gathers data of a consistent number of subjects and postures .",
    "as @xcite and references therein underline , previous studies usually include too few subjects and too few tasks : the maximum is represented by 11 intact subjects and 6 amputees with a maximum of 12 tasks . the ninapro database collects data and clinical information of 78 subjects , 67 intact and 11 trans - radial amputees , that perform 53 or 50 postures ( it depends on the chosen experiment ) .",
    "this large amount of data makes results obtained with this database statistically relevant . + data acquired need several preprocessing steps in order to make them available for a recognition process or for movements classification .",
    "the preprocessing of emg data and their final representation , called features extraction , could have a profound impact on the final performance of the algorithm chosen to solve the classification problem of emg signal .",
    "+ in @xcite the interested reader can find all the details about feature extraction methods used in order to analyse semg signals .",
    "the methods described in that work can take into account amplitude or spectral properties of the signal .",
    "the first ones are the algorithms that work in the time domain : mean absolute value , variance , waveform length or cepstral coefficients .",
    "the second ones are the algorithms that operate in the frequency domain : frequency ratio or mean frequency . considering time and frequency domain at",
    "once we obtain the time - frequency domain features : short time fourier transform , wavelet transform , or wavelet packet transform .",
    "these are richer of information about the signal but the computational cost increases .",
    "+ authors of @xcite studied and compared different methods in order to understand which are the ones that give the best ratio between the final performance and computational cost .",
    "their results show that mean absolute value and waveform length , despite their simplicity , can reach similar performance to the computationally more demanding marginal discrete wavelet transform .",
    "+    [ [ domain - adaptation . ] ] domain adaptation .",
    "it is a field associated with machine learning used to overcome the distribution mismatch between different domains . in general , in order to solve a new target problem with few labelled data , we can exploit solid models from sources , built with a large amount of data .",
    "the adaptive learning methods transfer useful information from the source domain to the target domain , although these are different , when the task to solve is the same . with this technique",
    "we avoid the collection of new samples from our target and the building of a little robust model based only on the few data gathered .",
    "+ how to exploit the source prior knowledge and how to adapt it to the new target model depends on the algorithm used . over the last years different directions have been proposed on how to tackle the problem .",
    "each one suggests a different adaptive method between sources and target .",
    "+ there are methods that aim to approach directly data from target and sources using some mathematical tricks . in @xcite",
    "a process based on two stage of weighting for each source sample is used in order to overcome the distribution mismatch .",
    "the authors of @xcite take into account the fact that source and target live in different space ; in order to overcome this problem it is exploited a function that builds a path from source to target in a dimensional reduced space . +",
    "another possible solution is to leverage over source models exploiting their parameters .",
    "the basic idea is that the new parameters of the target models must be close to the source ones and that they must be found solving an optimization problem .",
    "the first algorithm proposed in this direction is presented in @xcite , in this case only a single source model is exploited ( the best one ) . in @xcite",
    "this approach is enlarged by exploiting different linear combinations of source models .",
    "+ in the last method proposed in domain adaptation the sources are considered as experts . the judgement given by them for each target sample consists in extra features .",
    "we can distinguish three different levels in this approach , depending on the processing of the extra features .",
    "a middle level method based on this theory is proposed in @xcite and @xcite .",
    "an high level method is instead exploited in @xcite .",
    "+ all these different approaches evaluate autonomously the importance of each previous knowledge and decide individually from where and how much to transfer .",
    "+ the traditional fields in which domain adaptation is applied are : language processing for speech recognition ( @xcite ) and computer vision for image classification ( @xcite , @xcite ) . +    [ [ application - of - domain - adaptation - to - biological - signal . ] ] application of domain adaptation to biological signal .",
    "the problem that we tackle in the prosthetic control is a domain adaptation problem due to the differences of emg signal distribution among different subjects .",
    "in fact , the direct use of sources data for the solution of a target problem could result poorly in performance due to the many differences between the two domains .",
    "emg signal from sources and target can differ for the user s age , gender , height , weight , dominant hand , different exercise of the arm muscle and placement of electrodes ( @xcite ) .",
    "thus an adaptation process is necessary . +",
    "this kind of studies and application are very recent . one of the first work , according to our knowledge , proposed in this environment is @xcite .",
    "this proposes a method that chooses automatically the best source that the target problem can exploit .",
    "it uses directly its parameters in order to build the new target model .",
    "this algorithm is generally called _",
    "best - adapt_. + previous method is resumed and revisited in @xcite , where two adaptive algorithms able to exploit many prior knowledge models are proposed and compared with the previous one .",
    "the two methods are called _ multi - adapt _ and _ multi - perclass - adap_. the first exploits a weighted combination of sources , the second assigns a different weight to each class of each source . in @xcite",
    "these algorithms are tested on semg data from 10 and 20 intact subjects with 6 postures .",
    "the algorithm that gives the best result in performance is _ multi - perclass - adap_. + in @xcite several existing algorithms are tested .",
    "the adaptive methods that are compared come from @xcite , @xcite , @xcite and @xcite ( see previous paragraph ) .",
    "the experiments of this work involve 10 intact subjects with 9 postures and 27 intact subjects with 12 , 17 , 23 and 52 postures .",
    "the results show that the method proposed by authors of @xcite need a running time much longer than the others .",
    "generally the method that achieve the best performance is the one proposed by authors of @xcite .",
    "+ in both cases ( @xcite,@xcite ) experiments showed that for intact subjects the postures recognition and classification can be improved and boosted by the use of prior knowledge of other intact subjects .",
    "research in the area of hand prosthetics suffered from a number of problems .",
    "first , previous studies in this field are based on few subjects with few hand postures : according to our knowledge , up to 11 intact subjects and 6 amputees that perform a maximum of 12 movements ( see @xcite and references therein ) .",
    "it makes it hard to obtain statistically relevant results .",
    "second , it is necessary to establish a data analysis method accepted in order to compare final results . + currently , the best public database is ninapro ( non invasive adaptive prosthetics ) .",
    "its data have been collected during the experiment ninapro ( 2011 - 2013 ) and , according to our knowledge , represents the state of the art among public database in this field . in this work",
    ", we decided to use data coming from ninapro for our experiments in order to overcome the first problem described above .",
    "+ regarding data processing , we decide to use the algorithms of features extraction proposed in literature that , currently , represent the state of the art in the field of analysis of raw data .",
    "+ in section [ sec : data_acq ] it is introduced the ninapro database .",
    "we describe the acquisition set - up with particular attention to the experimental protocol and used devices to collect data from subjects . in the last part of this section we focus on the organization and structure of the dataset . + in section",
    "[ sec : feat_ext ] we explain all the procedures for data processing .",
    "+ data and all the reference papers are available in http://ninapro.hevs.ch/. +      the ninapro ( non invasive adaptive prosthetics ) database holds data and clinical information about 78 subjects : 67 intact and 11 trans - radial amputees . according to our knowledge , it is the only existing public database with a consistent number of subjects .",
    "data have been acquired from 2011 to 2013 .",
    "+ all the information about data acquirement and database can be found in @xcite,@xcite and @xcite .      the acquisition setup ( @xcite ) is composed by several devices for the recording of hand kinematics , dynamics and muscular activity .",
    "all the sensors are connected to the laptop to make the data recording possible .",
    "+ the _ cyberglove ii _",
    "( cyberglove systems llc , www.cyberglovesystems.com ) is a motion capture data glove that takes information about hand kinematic using 22 sensors ( see figure [ fig : cyberglove ] ) .",
    "these sensors register hand and fingers motions and return 22 8-bit values of resistance . that resistance is proportional to the angles between pairs of hand joints of interest ( for example metacarpum - phalanx , inter - finger , palm arch angles and so on ) .",
    "the average resolution is less than one degree and it depends on the size of the subject s hand .",
    "+    [ h ]    a standard commercially available 2-axis _ is40 _ inclinometer ( fritz kbler gmbh , www.kuebler.com ) is fixed to the subject s wrist to measure the wrist orientation .",
    "this device covers a range of 120and it has a resolution of 0.15 .",
    "+ hand dynamics is measured by a strain gauge sensor : _ finger - force linear sensor _ ( ffls ) .",
    "it records flexion and extension forces of all fingers and abduction and adduction of the thumb .",
    "+ muscular activity is measured using semg electrodes . in the first configuration of the experiment 10 _",
    "myobock 13e200 - 50 _ electrodes ( otto bock healthcare gmbh , www.ottobock.com ) were used .",
    "these electrodes are set to amplify the signal of about 14.000 times .",
    "they have also a shielding and filtering system in order to avoid low and high frequency interferences , for example from 5060 _ hz _ power sources , mobile phones or security systems .",
    "semg signals are sampled at a rate of 100 _ hz_. in the second configuration of the experiment 12 _ trigno wireless _ electrodes ( delsys inc , www.delsys.com ) are used .",
    "semg signals are sampled at a rate of 2 _ khz_. in both cases the equipment is fixed on the forearm using a hypoallergenic elastic latex  free band .",
    "+ figure [ fig : semgelectrodes ] shows how electrodes are placed . in the first configuration , with 10 electrodes , eight of these are equally spaced around the forearm , at the height of the radio - humeral joint .",
    "two are placed on the main activity spots of the flexor digitorum superficialis and of the extensor digitorum superficialis . in the second configuration",
    "two electrodes are added on the main activity spots of the biceps brachii and of the triceps brachii .",
    "[ h ]    in the case of intact subjects , the recording of semg and kinematic data is from the same arm . in the case of amputees ,",
    "semg signals are recorded from the missing limb while kinematic and dynamic data from the intact limb .",
    "+      before the beginning of data acquisition , each subject has a written and an oral explanation about the experiment and he / she has to sign an informed consent form .",
    "all the experiments are approved by the ethics commission of the canton valais ( switzerland ) .",
    "+ as first step , several clinical data like age , gender , height , weight and laterality are annotated .",
    "for amputated subjects , information about date , type and reason of the amputation , remaining forearm percentage , use of prostheses and phantom limb sensation are collected .",
    "the remaining forearm percentage is the ratio between the length of the amputated forearm and the length of the intact forearm from the elbow to the wrist , rounded to the tens .",
    "+ as second step , subjects are seated on a office chair .",
    "a laptop in front of the subjects shows with a movie the exercises that they have to perform .",
    "the intact subjects are asked to mimic movies on the screen with their dominant hand .",
    "amputees are asked to mimic as naturally as possible the same movement with their missing limb . for amputees ,",
    "generally , it is very difficult to reproduce an action with missing limb .",
    "thus , they can simulate a task bilaterally or they can follow a visual stimulus , that could be the movie on the screen or the experimenter that performs the same movement .",
    "+ before starting to record data , there is a training phase .",
    "this consists of a mix of the future exercises , it is important to make the subject practical with the experiment . +",
    "all the performed movements are divided in four different group : a , b , c and d ( see figure [ fig : allmovements ] ) .",
    "the first group ( exercise a ) is about 12 basic movements of fingers .",
    "the second ( exercise b ) is about 8 hand configuration and 9 basic movements of the wrist .",
    "the third ( exercise c ) is about 23 grasping movements and it involves everyday objects that are presented to the subject to mimic daily - life actions .",
    "the fourth ( exercise d ) is about 9 force pattern , it consists in a press combinations of fingers with an increasing force .",
    "+ the movements are chosen from the literature about taxonomy , robotics and rehabilitation .",
    "each movement is alternated by rest posture to avoid muscular fatigue .",
    "the expected execution time of each movement is about 5 _ s _ , of rest posture is about 3 _ s_. the sequence of movements is not randomized in order to favour unconscious movements .",
    "+    [ h ]      the ninapro database , acquired with the setup and procedure explained in the previous section , consists of three sub - datasets , according to the devices used and the subjects characteristics .",
    "+ the first database contains data from 27 intact subjects : 7 females and 20 males , 2 left handed and 25 right handed with 28 @xmath3 3.4 years .",
    "the electrodes used for semg data acquisition are the 10 _ otto bock_. the subjects perform the exercise a , b and c described in the previous section .",
    "each movement has been repeated 10 times and each repetition is interspaced by the rest posture .",
    "+ the second database contains data obtained from 40 intact subjects : 11 females and 29 males , 5 left handed and 35 right handed with 29.9 @xmath3 3.9 years .",
    "the electrodes used for semg data acquisition are the 12 _ delsys_. the subjects perform the exercise b , c and d described in the previous section . each movement has been repeated 6 times and each repetition is interspaced by the rest posture . + the third database contains data obtained from 11 trans - radial amputated subject : 11 male , 1 left handed and 10 right handed with 42.36 @xmath3 11.96 years .",
    "the subjects perform the exercise b , c and d described in the previous section .",
    "each movement has been repeated 6 times and each repetition is interspaced by the rest posture . +",
    "all the details about the datasets are reported in table [ tab : dataset ] .",
    "before the raw data could be used for classification , several steps are necessary .",
    "the first step is the filtering : the delsys semg signals , that are not shielded against power line interferences , are cleaned from 50 hz power - line interference using a hampel filter ( @xcite ) .",
    "the second step is the synchronization : it is a linear interpolation or nearest - neighbour interpolation of data .",
    "the third step is the relabelling : it is a correction of movements label by maximizing the likelihood of a rest - movement - rest sequence .",
    "in fact the movements performed by the subjects may not perfectly match with the stimuli proposed , due to human reaction times and experimental conditions .",
    "+ the raw data are not online but are available upon request . + for each subject and exercise one can find online ( http://ninapro.hevs.ch/ ) a _ matlab _ file with the following data :    * subject : subject number ; * exercise : exercise number ; * emg ( 10 or 12 columns ) : semg signal of the 10 or 12 electrodes .",
    "columns from 1 to 8 include the signal from 8 electrodes around the forearm , columns 9 and 10 include the signal of the muscle flexor / extensor digitorum superficialis , columns 11 and 12 include signal of the muscle biceps / triceps brachii ; * acc ( 36 columns ) : three - axes acceleration values of the 12 electrodes ( only for database 1 and 2 ) ; * glove ( 22 columns ) : signal from the 22 sensors of the cyberglove ; * inclin ( 2 columns ) : signal from the 2 axes inclinometer ( of the wrist ) ; * stimulus ( 1 column ) : the original label of the movements repeated by the subject ( before the relabelling phase ) ; * restimulus ( 1 column ) : label of the movements a - posteriori ( after the relabelling phase ) ; * repetition ( 1 column ) : repetition of the stimulus ; * rerepetition ( 1 column ) : repetition of restimulus ; * force ( 6 columns ) : force recorded during the third exercise of database 2 and 3 ; * forcecal ( 2 @xmath4 6 values ) : minimal and maximal force values for each sensor ;    the database 3 presents some exceptions .",
    "the amputated subjects 7 and 8 had only 10 electrodes instead of 12 due to insufficient space .",
    "the amputated subjects 1 , 3 and 10 asked to interrupt the experiment before its end due to fatigue or pain .",
    "they performed respectively 39 , 49 and 43 postures ( including rest ) .",
    "+      online semg data require some processes to make them available for classification .",
    "thus , we want to extract from them useful information to achieve this goal .",
    "this process is called features extraction .",
    "it consists in several steps of preprocessing in order to clean up data from the component of noise and in choosing of the algorithm for data representation .",
    "+ for a complete reading about this approach we refer to @xcite and @xcite .",
    "+ the described approach and processes are universally accepted in this field .",
    "+ in this thesis we work with data of exercise 1 ( 17 hand configuration and movements of the wrist ) of the second and third database .",
    "thus the reported values of parameters are referred to this analysis .",
    "the initial data consists of a single continuous signal ( one for each electrode ) that contains the information about the sequence that goes from the first movement to the last , interspaced by rest posture .",
    "+ the first step consists of the division of a movement from another . signals with different labels are separated .",
    "each resulting matrix identifies different movements or rest , the columns of this matrix are the channels ( 10 for first database , 12 for second and third ) . in figure [ fig : movementsdivision ] is shown the movements division process .",
    "+    [ h ]     the second operation is called windowing .",
    "each matrix from the previous point is divided in overlapping windows of fixed length .",
    "the windows length used in the literature is of 100 _ ms _ , 200 _ ms _ and 400 _ ms _ , the shift considered is of 10 _ ms _ ( @xcite ) .",
    "thus , between windows there is an overlap of @xmath5 , where @xmath6 is the window length considered . +",
    "all the parameters are analysed in the literature .",
    "the experiments of @xcite show that a window length of 200 _ ms _ or 400 _ ms _ results in higher accuracy . indeed , if a window is long enough , the error of label on the edge of a movement can be reduced . in this work",
    "the used windows length is @xmath7 ( i.e. 400 samples ) and the increment of the sliding window is 10 _ ms _",
    "( i.e. 20 samples ) .",
    "+ an example of windowing is shown in figure [ fig : windowing ] .",
    "+    [ h ]    as said before , each movement is repeated a fixed number of times .",
    "the third passage consists of the split of the signal in test and training part , depending on number of repetitions considered .",
    "+ for the second and third database the repetitions @xmath8 1 , 3 , 4 , 6 @xmath9 are used as training , the others ( @xmath8 2 , 5 @xmath9 ) as test .",
    "+ at this point the training part can be sub - sampled to reduce the amount of data and to achieve a computationally feasible problem .",
    "the training set is reduced by keeping every 10th sample .",
    "+      the last step is the choice of the algorithm for the data representation .",
    "+ there are some experimental evidence that we can consider in semg processing operation . first , there is a quasi - linear relation between root mean square ( rms ) amplitude of semg signal and force exerted by a muscle ( @xcite , @xcite ) .",
    "second , semg spectral characteristics might be related to conduction velocity of muscle fibers ( @xcite , @xcite ) . if a time domain algorithm is used the first aspect is privileged .",
    "if a frequency domain algorithm is used the second aspect is favoured . +",
    "the most important algorithms are reported in table [ table : featureext ] .",
    "we refer to @xmath10 as a feature computed from a signal @xmath11 of length @xmath12 , where its elements are indexed as @xmath13 .",
    "the authors of @xcite compared the previous different algorithms for features extraction .",
    "+ from these studies emerge that , in the time domain , mean absolute value and waveform length have similar performance to the computationally more demanding marginal discrete wavelet transform . in the frequency domain",
    "short time fourier transform is more robust than simple fourier transform when dealing with non - stationary signal .",
    "+ in this thesis we work in time domain with the mean between mean absolute value , variance and waveform length to be as independent as possible from the method . in figure",
    "[ fig : featuresexample ] is shown the representation of a movement after features extraction .",
    "[ h ]    in figure [ fig : signalbefaftprocess ] we show the total signal before and after processing and feature extraction .",
    "[ h ]    at the end of the feature extraction step , we have a set of vectors with dimension equal to the number of channels .",
    "the output of each vector is one of the possible movements inside the three exercises with the adding of rest .",
    "the number of training vectors and test vectors for each subject are respectively of the order of @xmath14 and @xmath15 .",
    "after extracting features , we have a set of data to classify . in this chapter",
    "we present the state of art learning algorithms that solve classification problems and the theory on which they are based .",
    "+ the section [ sec : mat_frame ] is an introduction about the mathematical framework and background required to understand the rest of the work . + in section [ sec : sup_learn_sd ] we focus on the traditional form of supervised learning , where we exploit only the information from the target domain .",
    "it is the supervised learning on a single domain .",
    "+ in section [ sec : svm ] we introduce support vector machines ( svms ) .",
    "it is one of the most used and theoretically well motivated methods in machine learning scenario .",
    "it represents the state of the art of supervised learning on a single domain .",
    "+ in section [ sec : sup_learn_dd ] we introduce a new form of supervised learning , where we exploit information from target domain and source domains .",
    "it is the supervised learning on different domains .",
    "+ section [ sec : da ] begins with a general introduction about different proposed directions to tackle the problem of domain adaptation . in the last part of the section we introduce the state of the art algorithms for supervised learning on different domains .",
    "we explain the theory on which each algorithm is based and the main structure of the code with the help of flow charts .",
    "all the mentioned algorithms are implemented with @xmath16 . +      in this section we present mathematical tools necessary to tackle the rest of the work . in the following we indicate column vectors with small bold letters ,",
    "e.g. @xmath17 $ ] and matrices with capital bold letters , e.g. @xmath18 . with @xmath19 and @xmath20",
    "we denote respectively the element @xmath21 and the _ i_-th column of matrix @xmath22 .",
    "+ in the rest of the work we refer to @xmath23 as an input vector of a learning algorithm and to @xmath24 as its associated output . @xmath25 and @xmath26 are respectively the input space and the output space .",
    "+ we denote with @xmath27 a set of data that come from an unknown probability distribution .",
    "the goal of a learning algorithm is to find a function that , for any future input vector @xmath28 , can determine the best corresponding output @xmath29 .",
    "+ in a classification problem , like the one analysed in this work , @xmath29 can assume values from a finite set that are the possible output classes .",
    "if the possible outputs are only two we have a binary problem , if these are more we have a multiclass problem . in this thesis",
    "we have the second type of problem and classes are equal to the possible hand postures . in the following we refer to @xmath30 as the total number of classes , or possible output label",
    ". +    [ [ loss - function . ] ] loss function .",
    "in general we can define a loss function as a function that associates a real number to a given event in order to represent some  cost \" associated with the event . in a classification problem it is the function that represents the price paid for a misclassification . for a binary problem",
    "let us refer to @xmath29 and @xmath31 as , respectively , the true and the predicted label of a vector @xmath28 .",
    "the loss function can be defined as :    @xmath32     + where different choices of parameter @xmath33 lead to different penalties for misclassified vectors .",
    "+ in a multiclass problem , let us define with @xmath34 the column of the confidences for each class referred to a given vector @xmath28 . the loss function is modified as follow :    @xmath35     + the loss is zero if the confidence value for the correct class is at least greater than one with respect to the other confidence values . otherwise , the loss is linearly proportional to the differences between the confidence values of real class and the maximum confidence referred to another class .",
    "+ the goal of a learning problem is to minimize this risk .",
    "+      we refer to training samples and test samples as a set of vectors , or items , for which we know the output classification , i.e. the label value .",
    "+ in a supervised learning problem the first ones are used in the training phase to build a classification model .",
    "the second ones are exploited in the test phase to evaluate the performance of a learning algorithm from the agreement between the predicted labels and their real values .",
    "thus , the learner receives a set of labelled examples as training data and makes predictions for all unseen points .",
    "+ in the following we refer to @xmath6 as the total number of training vectors .",
    "+ we define the target problem as the new classification problem that we aim to solve . in our case",
    "it is the new subject that learns to perform some hand postures .",
    "+ in the simplest case , in order to build a classification model for the new target subject , we can exploit only the training data of the target himself .",
    "thus , data used to train the model and data used to test it come from the same domain , i.e. the target domain . taking this into account",
    ", it is reasonable to assume that the data present the same distribution .",
    "+ we refer to this process as a supervised learning on a single domain : in fact in order to build the model , we use available labelled data ( i.e. supervised process ) from only the target subject ( i.e. single domain ) . in section",
    "[ sec : svm ] we present the support vector machines ( svms ) method .",
    "it represents the state of art of supervised learning on a single domain for classification problem .",
    "+      in this section we introduce one of the most effective classification algorithms in machine learning : support vector machines ( svms ) .",
    "the goal of svms is to produce a model , based on the training data , able to predict the output of a given test vector .",
    "+ for a complete reading about topics , one can refer to @xcite , @xcite and @xcite .",
    "+      we start with the introduction of linear svms for the solution of a binary problem .",
    "we refer to the two types of vectors as positive and negative ones , i.e. @xmath36 .",
    "+ the aim of a classification problem is to find an hyperplane which separates positive from negative vectors .",
    "for a point that lies on this hyperplane the following equation holds :    @xmath37     + where * w * identifies the hyperplane ( it is the direction vector of the plane ) and @xmath38 is the normal distance from the hyperplane to the origin . + usually there are many hyperplanes that a learning algorithm can choose to solve a problem .",
    "the svms algorithm returns the hyperplane with the maximum margin _",
    "m_. the margin is the maximum distance between the separating hyperplane and the closest points of each sets . + all these concepts are reported in figure [ fig : separablecase ] .",
    "[ h ]    if we define marginal hyperplanes as @xmath39 , the following inequalities hold :    @xmath40     + the vectors that lie on marginal hyperplanes are called support vectors . the equations [ eq : hyperp1 ]",
    "can be combined in order to obtain a unique inequality :    @xmath41     + using equations of marginal hyperplanes we can find that @xmath42 , thus it is clear that searching the hyperplane that maximizes the margin is equivalent to minimize @xmath43 with constrain ( [ eq : hyperp1_const ] ) .    in",
    "most of classification problems , data present a component of noise , an example is shown in figure [ fig : nonseparablecase ] .",
    "[ h ]    to take into account the possible noise in the data , we can introduce the slack variables @xmath44 .",
    "this variable measures the distance by which vector @xmath28 violates the desired inequality : @xmath45 .",
    "+ at this point we can define the minimization problem to solve as :    @xmath46.\\\\ \\end{aligned}\\ ] ]     + this can be formulated as a lagrangian problem as follows :    @xmath47 - \\sum\\limits_{i=1}^n \\beta_{i } \\xi_{i}.\\ ] ]     + first and second terms of sum are the objective function that we want to minimize .",
    "the others are the constraints multiplied by different lagrangian multipliers @xmath48 and @xmath49 . in this optimization problem",
    ", we minimize the amount of slack variables and @xmath43 .",
    "generally , these two requests are conflicting .",
    "the parameter that sets this trade - off is c. the parameter @xmath33 describes different penalties for misclassified vectors as we explain in the end of this paragraph .",
    "+ until objective function and constrains are convex and differentiable , the kkt conditions can be applied at the optimum :    @xmath50 & = 0 \\ > \\rightarrow \\",
    "> \\alpha_{i } = 0 \\vee y_{i}(\\textbf{w } \\cdot \\textbf{x}_{i } + b ) = 1 - \\xi_{i } , \\\\ \\label{eq : kktcondns5 }      \\forall \\textit{i } , \\quad \\beta_{i}\\xi_{i } & = 0 \\ > \\rightarrow \\ > \\beta_{i } = 0 \\vee \\xi_{i } = 0.\\end{aligned}\\ ] ]     + the first equation shows that @xmath51 is a liner combination of training vectors .",
    "the forth equation indicates that the vectors that really appear in that combination are only the support vectors .",
    "indeed for other vectors the lagrangian multiplier is zero . in this case",
    "we have two different types of support vectors .",
    "the first ones are vectors that lie on margin hyperplane ( they have @xmath52 ) .",
    "the second ones are called outlier and are the misclassified vectors for which @xmath53 .",
    "+ the task of determine a classifier is equivalent to find the parameters @xmath51 and @xmath54 of the model .",
    "in the test phase , given a new vector @xmath55 with unknown label , the output hypothesis is :    @xmath56     + the second equality can be simply obtained using equation ( [ eq : kktcondns1 ] ) .",
    "+ the extension of the theory to the multiclass case , i.e. @xmath57 , is straightforward .",
    "we solve different optimization problems , one for each class @xmath58 $ ] .",
    "thus , during the training phase , a pair @xmath59 is found for each class . the considered class takes the label @xmath60 and the others @xmath61 ( one - vs - all approach ) , in this way we solve @xmath30 different binary problems .",
    "+ in the test phase , given a vector @xmath55 , we choose the class @xmath62 that gives the maximum output according to :    @xmath63    [ [ loss - function.-1 ] ] loss function .    as anticipated in section [ sec : mat_frame ] the loss function is the penalty associated to a misclassified vector . + for a binary problem",
    "the most common loss functions are the hinge loss and the quadratic hinge loss .",
    "these are respectively associated to @xmath64 and @xmath65 in equation ( [ eq : lossbinaryprob ] ) . as shown figure [ fig : lossfunctions ] , penalties are different depending on the value of @xmath33 chosen .",
    "+    [ h ]    we have no loss if the prediction falls in the right part of the hypersurface ( i.e. distance between point and hyperplane is greater than 1 ) .",
    "when the prediction falls into the margin we have a loss @xmath66 .",
    "if the loss is greater than one the prediction is in the wrong part of the hypersurface .",
    "+      until now , a linear decision boundary is used to solve a classification problem .",
    "however there are techniques that extend svm algorithms in order to define non - linear decision boundaries .",
    "kernel methods are an example of these .",
    "+ a way to define a non - linear decision boundary is to use a non - linear map function defined as : @xmath67 .",
    "@xmath25 is the input space of training vectors and @xmath68 is a high - dimensional ( possibly infinite - dimensional ) hilbert space called feature space .",
    "in other words , if the training vectors are not linearly separable in the input space we can replace each of them with @xmath69 to make the problem solvable by changing the metric .",
    "an example is shown in figure [ fig : fromnonlineartolinearhyperplane ] .",
    "+    [ h ]    however , determining the hyperplane solution requires multiple computations of inner products in high - dimensional spaces : @xmath70 instead of the simple product between training vectors .",
    "a solution to this problem is to use kernel methods . +",
    "a kernel over @xmath68 is a function @xmath71 .",
    "the idea is to define a kernel k such that :    @xmath72     + an inner product is a measure of the similarity between two vectors , thus @xmath73 can be interpreted as a similarity measure between elements of the input space @xmath74 .",
    "@xmath73 is often significantly less complex to compute than @xmath75 and its inner product .",
    "but there is another bigger advantage : under precise conditions ( _ mercer s conditions _ ) we can work directly with @xmath73 without knowing @xmath75 .",
    "+ now given a vector @xmath55 with unknown label , the output hypothesis is :    @xmath76     + one of the most used kernel is the gaussian one , or radial basis function ( rbf ) :    @xmath77     + it is also the kernel chosen in the computer s implementation of algorithms used in this work . for completeness , we underline that there are many kinds of kernel like : linear , polynomial and sigmoid .",
    "[ [ least - square - support - vector - machines - ls - svm . ] ] least square support vector machines ( ls - svm ) .",
    "the ls - svm ( @xcite ) problem is a new formulation of equation ( [ eq : objfunc_const_primalns ] ) in order to avoid the high computational burden of the original svm problem . in this formulation",
    "we replace the inequality constraints with equality .",
    "the quadratic hinge loss ( @xmath65 ) and the kernel method are used .",
    "+ the optimization problem is written as follow :    @xmath78,\\\\ \\end{aligned}\\ ] ]     + the solution of the reformulated lagrangian problem is characterized by a linear system which takes a similar form as the linear system of standard svm ( see equations from [ eq : kktcondns1 ] to [ eq : kktcondns5 ] ) . +",
    "let us indicate with @xmath79 the identity matrix and with @xmath80 the kernel matrix defined as :    @xmath81     + the solution of the problem is given by :    @xmath82     + where @xmath83 and * y * is the vector of outputs .",
    "+ the ls - svm solution that we obtain now presents a difference with respect to the original svms .",
    "sparsity is lost and all data contribute to the model .",
    "up to now we have dealt with the traditional learning .",
    "one of the main assumptions on which it is based is that the training data , used to learn the target model , and the test data , used to test this model , come from the same distribution .",
    "however in many real problems this assumption is not true : this happens because data can be dependent on dynamic factors like time , acquisition devices and space ( @xcite ) .",
    "+ we tackle a similar problem when we want to learn a model with few available labelled data . to avoid the creation of a not very solid model we can exploit also data coming from different domains ( for example from different data acquisitions or databases , gathered with different devices and so on ) . for example",
    ", we can have a lot of labelled data on a source problem and the need to solve the same problem for a different target domain with few labelled data .",
    "if source and target present a distribution mismatch the source data ca nt be used directly to solve the target problem , hence a form of adaptation is needed .",
    "+ let us define the concept of source as a known classification model built with a great number of training vectors . in a domain adaptation problem we aim to solve a new target problem exploiting information from a source domain .",
    "the classification problem of target and source is the same .",
    "in particular we have the same output label set , @xmath84 . however , the target domain @xmath85 and the source domain @xmath86 are different in terms of marginal data distribution , @xmath87 .",
    "thus , the conditional probability distribution @xmath88 might be slightly different for source and target ( @xcite ) .",
    "+ when we attempt to leverage over existing source knowledge to solve a target problem , we are combining information from different domains : the target domain and all the available sources domains .",
    "we can consider the source as a type of prior knowledge that , after an appropriate adaptation , can be used to learn something for new target problem .",
    "+ the application on prosthetic hands treated in this work is an example of domain adaptation problem . in particular , the task is to catalogue different hand s postures of new target subject using , as sources , subjects that already performed the same movements .",
    "we refer about domain adaptation problem because biological signals of the same movement can be different for different users in terms of marginal data distribution .",
    "in fact , the emg signal from different subjects varies depending on gender , age , muscular activity , dominant hand , position of the electrodes during the data collection and so on ( see figure [ fig : dahand ] ) .",
    "+    [ h ]     the goal of a domain adaptation algorithm is to find the best way to exploit useful informations from the available sources , in order to solve the new target problem .",
    "+ in the following we refer to @xmath73 as the total number of sources . +      we present here several different algorithms that use adaptive learning in order to boost the training phase of a prosthetic hand with the exploitation of previous experience .",
    "each methods try to combine in different ways informations from target domain ( represented by training labelled vectors ) and from domains of sources ( represented by source classification models ) .",
    "+ in the following it is explained how informations coming from different sources can be combined .",
    "each algorithm adds in different ways informations given by training vectors of target and this particular aspect is treated in the sessions dedicated to individual algorithms .",
    "+ some methods exploit the prior knowledge directly .",
    "these use a combination of the parameters ( @xmath89 ) of source models in order to obtain the new parameters of new model solving an optimization problem ( see algorithm in section [ sec : muliadaalg ] ) .",
    "+ in other methods the sources are seen like experts , or feature extractors .",
    "the outputs obtained using source s models for the classification of training data are considered as a descriptor , or as an extra - features . at this point there are different methods to combine informations derived from different sources .",
    "we can discern three different levels of integration : low , mid and high .",
    "+ in the low level the extra - features , coming from each source , are combined into a single new vector . for this feature vector",
    "a classifier ( for example a linear or non - liner svms ) is trained .",
    "the different information from different sources influence in the same way the final decision .",
    "in fact , no weight factor is used .",
    "+ in the middle level the extra - features of each source are kept separately , but a single classifier is used for the final hypothesis .",
    "this classifier is based on svm algorithm with a new kernel that is a liner combination of kernels of sources appropriately weighed ( see algorithm in section [ sec : mkal - alg ] ) .",
    "+ in the high level a classifier is trained for each extra - feature vectors .",
    "each classifier produces a final hypothesis about training vectors .",
    "all these assumptions are combined together to produce the final output ( see algorithm in section [ sec : h - l2lalg ] ) .",
    "+ the different ways of integration explained above are called cue integration methods ( @xcite and @xcite ) and are summarised in figure [ fig : cueintegration ] .",
    "[ h ]    with respect to the domain adaptation algorithms chosen , there are two baseline .",
    "the first is given by the solution of a classification problem using only the training data of the target .",
    "this method is called _ no transfer _ and it solves non - linear ls - svm problem trained on the target data only ( see section [ sec : nl - svm ] ) .",
    "the second is represented by the exploitation of training data of the source only .",
    "this method is called _ prior features _ and it solves a linear ls - svm problem trained on the source data only ( see section [ sec : l - svm ] ) .",
    "+ in the rest of the section we present the algorithms used in the simulations of this work for the classification problem of hand movements .",
    "the main structure of the code is the same for all of them .",
    "we have a training phase and a test phase . in the first one ,",
    "the classification problem is tackled for each target subject and models are built .",
    "for each subject the models are calculated several times for an increasing number of training vectors . in the second phase models",
    "are tested using new vectors . in the following",
    "we explain the training phase of each algorithms .",
    "it is the point that distinguish one adaptive methods from the others .",
    "+      the first form of _ multi adapt _ algorithm was proposed in @xcite and after extended in @xcite .",
    "it solves a classification problem exploiting a combination of source models already known and properly weighted .",
    "+ an optimization problem based on non - linear svms with gaussian kernel is solved for every source .",
    "the result is a vector @xmath90 for each of these .",
    "+ we begin to treat a binary problem to simplify the notation , in the end we extend the results to a multiclass problem . + as a starting point , it is possible to use one of the pre - trained models to build the new model for the new subject . the basic idea is to search a solution for the new problem that is close to the pre - trained one . the optimization problem that we tackle is the following :    @xmath91     + as described in section [ sec : svm ] we can use the lagrangian formulation that leads to the following optimality conditions :    @xmath92     + where @xmath93^{t}$ ] is the vector of lagrangian multipliers . as in non - linear svm algorithm , the new model @xmath51 is given by a combination of feature functions @xmath94 .",
    "in addition , it appears the pre - trained model @xmath95 weighted by @xmath96 .",
    "+ previous equations can be combined and written in matrix form :    @xmath97     + where @xmath98^{t}$ ] is the vector that contains the real label of each training vector and @xmath99 $ ] is the vector of labels predicted using the model @xmath100 .",
    "@xmath80 is the kernel matrix introduced in [ eq : k_matrix ] and @xmath79 is the identity matrix .",
    "+ inverting equation ( [ eq : muladasol ] ) the solution is :    @xmath101     + where @xmath102 is the inverse of the first matrix on the left of equation ( [ eq : muladasol ] ) . + in order to evaluate @xmath96 , the leave - one - out error is introduced .",
    "let us define with @xmath31 the prediction obtained on _",
    "i_-th sample when it is removed from the training set .",
    "starting from equation ( [ eq : muladasol2 ] ) and writing the lagrangian multiplier as @xmath103 , it can be shown that the prediction vector has the following equation :    @xmath104     + thus , given a set of training vectors , the weight @xmath96 , that gives the minimum distance between true and predicted label , is chosen in agreement with :    @xmath105    where @xmath106 is a loss function . + the method described above exploits only one source , although many of them are available .",
    "the best source is selected by evaluating the minimal leave - one - out error .",
    "+ the previous approach can be extended in case of multiple sources by defining the following learning problem :    @xmath107     + where @xmath73 are the number of sources and @xmath108^{t}$ ] is the vector of the importance weight of each prior .",
    "now the optimal solution is composed by a linear weighted combination of previous models :    @xmath109     + the parameters of the new model are given by :    @xmath110     + where @xmath111^{t}$ ] is the vector of labels predicted using the @xmath112-th source model . as in the previous case , @xmath113 can be evaluated with live - one - out error , the only difference is that now the minimization problem ( [ eq : min_loss - lou ] ) is with respect to a vector ( @xmath49 ) .",
    "+ the last case is the more general and it is an extension to the multiclass problem .",
    "it consists in the use of different weights for different classes of the same source . indeed , in a problem of domain adaptation",
    ", it can be reasonable to think that a subject learns better a task from a source and another task from on different source .",
    "+ starting from the previous cases , the new implementation is straightforward .",
    "now the weight parameters are inside a matrix @xmath114 . @xmath73 and @xmath30 are respectively the number of sources and classes , thus @xmath115 is the weight associated to class @xmath62 of source @xmath112 . given a sample @xmath28 we refer respectively to @xmath116 , @xmath117 and @xmath34 as the column vector with real output ( in one - vs - all approach ) , output predicted by prior and output predicted with live - one - out .",
    "the loss function used to evaluate the live - one - out prediction is reported in equation ( [ eq : lossmulticlass ] ) . +",
    "the three different cases are shown in figure [ fig : multiadaptcases ] .",
    "[ h ]    in this work we use the case of different weights for different classes .",
    "+ during the test phase , for each test vector @xmath55 , we choose the class @xmath62 that gives the maximum output in according with :    @xmath118     + the flow char of the code that implements _ multi adapt _ method is shown in figure [ fig : multiadapt ] . for each subject and class , during the training phase , is solved the optimization problem with different weights for different classes in order to find the parameters of new models .",
    "[ h ]      there are several types of algorithms that exploit a kernel combination to obtain a better performance in test phase .",
    "the authors of @xcite , @xcite present the _",
    "multi kernel adaptive learning _ ( mkal ) algorithm for a multiclass problem .",
    "this is described in detail also in @xcite .",
    "+ the mkal algorithm belongs to middle level of features integration , it is based on a linear combination of kernels .",
    "kernels may be different for type , or these may be of the same type with different parameters .",
    "the weights of this linear combination reflect the importance of each kernel . + in order to introduce this algorithm , we define its final prediction as :    @xmath119     + where the index @xmath62 runs over classes and the index @xmath112 over sources .",
    "@xmath120 are the weights of the score function @xmath121 defined as :    @xmath122     + in the previous equation @xmath123 $ ] is the hyperplane referred to source @xmath112 .",
    "it is composed by @xmath30 blocks , one for each class . the feature map @xmath124 $ ] is represented as a vector with all the elements null except that for the @xmath62-th position , that corresponds to the output class of vector @xmath55 .",
    "the kernel corresponding to the source @xmath112 is defined as : @xmath125 .",
    "+ let us define with :    @xmath126 \\quad \\text{and } \\\\ & \\bar{\\phi}(\\textbf{x},y ) = [ \\phi^{0}(\\textbf{x},y),\\phi^{1}(\\textbf{x},y),\\phi^{2}(\\textbf{x},y), ... ,\\phi^{k}(\\textbf{x},y ) ] \\end{aligned}\\ ] ]     + respectively the concatenated vectors of hyperplanes and feature maps .",
    "these are both composed by @xmath127 blocks : one for each source plus the block labelled with @xmath128 that is referred to the original training vectors . +",
    "let as define also the ( 2,@xmath33 ) group norm @xmath129 of vector @xmath130 as :    @xmath131\\parallel_{p},\\ ] ]     + that is the @xmath33-norm of a vector with @xmath132 elements , where each element is given by the 2-norm of the vector @xmath133 composed by @xmath30 elements .",
    "the dual norm of @xmath134 is defined as @xmath135 where @xmath33 and @xmath136 satisfy @xmath137 .",
    "+ at this point we introduce the optimization problem in order to find the vector @xmath130 :    @xmath138     + where @xmath139 is a regularization term and @xmath140 is the predicted class of the vector @xmath28 . the previous equation can be written as :    @xmath141     + the function that appears in the second term is the loss function for a multiclass problem .",
    "it is defined as :    @xmath142     + the element @xmath33 that appears in the first term of equation ( [ eq : minprobloss_mkal ] ) can vary in the range @xmath143 $ ] . by changing the value of @xmath33 , the level of sparsity of the solution changes . with @xmath64",
    "we have only the sum of all the 2-norm of each hyperplane @xmath144 of each source .",
    "thus a solution with few hyperplanes is favoured .",
    "the @xmath145 norm introduces sparsity in the solution by reducing the complexity , but often it produces a non - convex problem . to select @xmath65",
    "is equivalent to choose an unweighted sum of kernels .",
    "to overcame these problems usually a @xmath146 is chosen .",
    "+ summarizing , the task of finding the vector @xmath130 that minimize equation ( [ eq : minprobloss_mkal ] ) is equivalent to search for the best kernels combination that minimizes the loss function for a given set of training vectors .",
    "+ there are several algorithms that solve computationally the minimal problem ( [ eq : minprobloss_mkal ] ) .",
    "the one used in our implementation is called _ obscure _ ( @xcite , @xcite ) .",
    "+ the described process is iterated for @xmath12 times for all the training vectors . at each step",
    "the algorithm takes a random sample of the training set .",
    "the output of the training vector is evaluated using equation ( [ eq : pred_mkal ] ) . at the first step",
    "all the parameters are null , in the others the parameters of previous iteration are taken .",
    "+ for each training vector the loss function is evaluated with equation ( [ eq : lossmcfunction ] ) .",
    "the minimization problem that is tackled if the loss function is greater than zero is slightly different to the one earlier presented .",
    "it is formulated as follows :    @xmath147.\\ ] ]     + the loss function is replaced with its sub - gradient , in order to linearise the problem .",
    "the first term of the equation is the regularization term + @xmath148 . in the second term",
    "the @xmath149 are a set of trade - off parameters that balance the speed of convergence and the precision .",
    "+ the solution of above equation is :    @xmath150     + where @xmath151 is the fenchel conjugate of @xmath152 . in the considered case",
    "the earlier equation is written as follows :    @xmath153     + where @xmath154 is the dual weight of @xmath130 and @xmath136 is the dual coefficient of @xmath33 .",
    "if we have a positive loss function the vector @xmath130 is updated , if the loss is null the vector does nt change . + in order to exploit the kernel definition in final prediction ( [ eq : pred_mkal ] ) we can express as follow the vector @xmath130 :    @xmath155     + the flow char of the code that implements _ multi kernel adaptive learning _",
    "method is shown in figure [ fig : mkal ] .",
    "for each subject , during the training phase , is solved the optimization problem ( [ eq : minprobloss_mkal ] ) in order to find the parameters of the new models .",
    "[ h ]      the algorithm _ high level - learning2learn _ ( h - l2l ) belongs to the high level cue integration methods ( @xcite and @xcite ) . +",
    "this algorithm is composed by two layers . in the first one , it is calculated the confidence score on each source model and on a target model built with a multiclass ls - svm .",
    "the vectors used to train the target model are a part of the original training vectors ( @xmath156 for each class ) .",
    "the ones exploited in the calculation of confidence are all the test vectors and the remaining training vectors ( @xmath157 for each class ) .",
    "+ thus , given a vector @xmath55 , for each output class @xmath62 we have the score @xmath158 and @xmath73 different scores @xmath159 in according to :    @xmath160     + the vectors used to train the new model in the second layer are the concatenation of confidence scores of target and sources for the @xmath157 of the original training vectors .",
    "these are exploited to solve a multiclass ls - svm problem and the final score is given by :    @xmath161     + where the the index @xmath128 refers to the target model .",
    "the concatenation of confidence scores of target and sources of the original test vectors are used to test the model of second layer .",
    "+ the flow chart of the code that implements _ high level - learning2learn algorithm _ method is shown in figure [ fig : h - l2l ] . in the two training phases two different ls - svm problems",
    "are solved , the first one exploiting original vectors and the second one using the output scores obtained previously .",
    "in this chapter we evaluate and compare the performance and the results obtained using the state of the art algorithms described in chapter [ cha : algorith ] for data processed as explained in chapter [ cha : data ] .",
    "+ our goal is to understand how and if , for a new target subject , prior knowledge coming from other subjects can boost the control of prosthesis and reduce the time needed to learn how to control the device .",
    "furthermore , when we consider a new amputee that is learning how to control the prosthesis , it is interesting to investigate which sources he / she exploits .",
    "in particular our task is to understand how the learning curve for an user might change when using intact or amputees as sources .",
    "+ we present in section [ sec : expprot ] the experimental protocol used for each experiment .",
    "+ sections [ sec : ii ] , [ sec : aa ] and [ sec : ai ] focus on results obtained in the three different experiments done . in the first we consider an intact subject that exploits prior knowledge from other intact subjects . in the second we have an amputated subject that uses prior knowledge from other amputated subjects . in the third",
    "we consider an amputated subject that exploits prior knowledge from intact subjects .",
    "+ we conclude with an overall discussion of our findings in section [ sec : compariosonres ] .",
    "as said above , in this work we ran three different experiments . in this section we describe the experimental settings that are common to all of them . + we consider a target subject that exploits prior knowledge of source subjects in order to learn how to perform hand postures",
    ". each experiment is repeated for several targets : 20 in the first and 9 in the second and third .",
    "the considered source models are 19 , 8 and 20 in , respectively , the first , second and third set - up",
    ". each protocol will be explained in detail in the following sections .",
    "+ the goal that a target subjects aims to achieve is to learn to perform the same movements that source subjects are already able to do .",
    "for all the experiments we consider the postures of exercise b , i.e. 8 hand configurations and 9 basic movements of the wrist ( see section [ sec : ninapro_dataset ] ) .",
    "thus , we are solving for each target a classification problem with 18 classes : 17 movements and rest posture .",
    "+ each experiment for each target subject has two phases : training and test . during the first , starting from few training vectors and prior models , each new target builds a classification model . during the second the model",
    "is tested with new vectors unused during the training phase .",
    "+ the classification models of sources are built with a non - linear svm with gaussian kernel using the library _ libsvm _ available online ( https://www.csie.ntu.edu.tw/~cjlin/libsvm/ ) .",
    "+ in all settings the target model is built with an increasing number of training vectors , up to a maximum of @xmath162 . for each subject",
    "the experiment is repeated @xmath163 times where at each step we increase the training vectors of @xmath164 .",
    "+ the algorithms used in the training phase of each experiment are the same and represent the state of the art in adaptive learning .",
    "these are described in section [ sec : da ] and are : _ multi kernel adaptive learning _ ( mkal ) , _ high level - learning2learn _ ( h - l2l ) and _ multi adapt_. we consider as reference two baseline : _ no transfer _ and _ prior features _ ( see section [ sec : da ] ) .",
    "+ in the test phase , the final performance is evaluated using the formula of balanced accuracy that takes into account a possible imbalance in the number of vectors in different classes .",
    "we report the formulation for a binary problem :    @xmath165     + we refer to the positive or negative samples classified correctly with tp ( true positive ) and tn ( true negative ) . with fp ( false positive ) and fn ( false negative )",
    "we indicate the negative or positive samples misclassified . this formulation can be straightforwardly extended to multiclass case . an average performance is calculated for each algorithm",
    ", it comes from the mean between the performance obtained for all the target subjects . for each subject",
    "the performance is evaluated for each considered set of training vectors .",
    "thus , we evaluate the trend of mean performance as the number of training vectors increases .",
    "+ all the classification models used are based on non - linear svm with gaussian kernel ( see equation [ eq : gausker ] ) .",
    "these need the setting of the hyperparameters @xmath166 and @xmath167 .",
    "the method generally used to determine them is called cross - validation .",
    "a grid with the following values for parameters is taken into account : @xmath168 and @xmath169 .",
    "for each subject and for each possible combination of @xmath166 and @xmath167 , a classification model is built using the library _",
    "libsvm_. the couple of parameters that gives the best result in performance is chosen .",
    "+ all the obtained results for each experiment are available in https://sites.google.com / site / noninvasiveprosthetichand/. +      [ [ setup . ] ] setup .",
    "the first experiment that we tackle is close to the experiments already performed in the literature ( @xcite and @xcite ) .",
    "it involves 20 intact random subjects from the second sub - database of ninapro ( see table in section [ sec : ninapro_dataset ] ) . in this case",
    "we consider intact subjects as target and source .",
    "in particular , one by one , each of the 20 subjects is the new target problem .",
    "the remaining 19 intact subjects are considered as sources .",
    "+ the data taken into account are those of the exercise b : 8 hand configurations and 9 basic movements of the wrist .",
    "+ during the training phase the classification models are built for each target subject and for each of the five algorithms .",
    "we repeat the process for an increasing number of training vectors with steps of @xmath164 up to a maximum of @xmath162 . in the test phase",
    "we evaluate the performance of each model .",
    "+ in this work we performed the same experiment for 10 , 20 and 30 intact random subjects .",
    "taking into account that the final performance slightly increases from 10 to 20 but does nt change from 20 to 30 , in this section we report only the results and analysis for 20 subjects .",
    "the interested readers can find all results in https://sites.google.com / site / noninvasiveprosthetichand/. + in the tables [ tab : datasetii ] and [ tab : datasetiialg ] we report the principal characteristics of the first experiment .",
    "[ [ results - recognition - rate . ] ] results : recognition rate .",
    "for all the algorithms , the trend of the mean performance as a function of the training vectors of the target problem is reported in figure [ fig:20intactsubj ] .",
    "it comes from the mean between performance obtained for all the target subjects .",
    "[ h ]    in figure [ fig:20intactsubjbw ] the best and worst cases are reported .",
    "these are respectively the subjects for which each algorithm gives the best and worst result in performance .",
    "[ h ]    mkal and h - l2l achieve the best performance followed by multi adapt , prior features and no transfer .",
    "the same order is preserved in the best and worst case , but a component of noise is present for the single subject and the trend appears not very smooth .",
    "+ as shown in figure [ fig:20intactsubj ] h - l2l outperforms mkal for more than 1000 training samples of about 3 @xmath1 ( @xmath170 ) .",
    "the difference between mkal and multi adapt shows an average advantage in recognition rate of around 10 @xmath1 ( @xmath170 ) .",
    "multi adapt has an average gain of 2 @xmath1 with respect to prior features ( @xmath170 ) . +",
    "no transfer is the method that shows the lowest performance .",
    "multi adapt , mkal and h - l2l outperform no transfer with an average of about 12 @xmath1 , 23 @xmath1 and 22 @xmath1 respectively . at the last step , i.e. 2160 training vectors ,",
    "no transfer achieves a performance in recognition of about 47 @xmath1 .",
    "the adaptive methods reach before this goal : 57 @xmath1 for mkal at 240 training samples , 49 @xmath1 for h - l2l at 360 and 47 @xmath1 for multi adapt at 600 .",
    "this result means that the use of prior knowledge allows us to reduce by one order of magnitude the training time .",
    "+ the adaptive methods achieve faster than no transfer the asymptotic performance .",
    "in fact , passing from 600 training samples to 2160 the performance of no transfer , multi adapt , mkal and h - l2l increases of respectively : 16 @xmath1 , 5 @xmath1 , 5 @xmath1 and 12 @xmath1",
    ". +    [ [ results - confusion - matrices . ] ] results : confusion matrices .",
    "let us introduce the confusion matrix .",
    "this matrix contains information about real labels and labels predicted by a classification model .",
    "each row represents the predicted values associated to a class for each real label .",
    "each column represents the prediction given for each real class , so the cumulative is 1 .",
    "+ the analysis of confusion matrices shows several aspects of recognition in a classification problem that the single performance analysis hides .",
    "we can check if a set of classes are better recognize than others or if there are differences in recognition of a single posture changing algorithm .",
    "thus we obtain a statistic of recognition about single class , changing algorithm and number of training samples .",
    "+ we report the confusion matrices for no transfer ( figure [ fig : ntconfmat ] ) , prior features ( figure [ fig : priorconfmat ] ) and mkal ( figure [ fig : mkalconfmat ] ) for 120 ( i.e. initial step ) , 1080 ( i.e. middle step ) and 2160 ( i.e. final step ) training vectors .",
    "the label 1 is associated to rest posture .",
    "+ we can find the confusion matrices for all algorithms in https://sites.google.com / site / noninvasiveprosthetichand/. +    [ h ]    [ h ]    [ h ]    as we can evaluate from colorbar , the warm colors are associated to high probability and cool colors to low probability .",
    "the ideal case is represented by red colour into the diagonal of matrix ( i.e. the prediction labels are equal to the true ones ) and blue colours outside ( i.e. wrong prediction is equal to zero ) . in all three cases , augmenting the number of training vectors , the warm colours move towards the diagonal . + it is interesting to analyse the case of no transfer",
    ". it does nt exploit any type of source and predictions are based only on training vectors of the target used at each step . at first one the classes with higher predictions are 8 , 10 , 11 and 12 .",
    "it means that the 120 training vectors of first step in majority belong to these classes .",
    "+ the situation at first step is different for prior features and mkal , it means that the recognition task is helped by the presence of the source knowledge . with no transfer , at the first step ,",
    "each class has as output the predicted value of 8 . with prior features all the classes , except 1 and 14 ,",
    "have the highest prediction associated to the true label .",
    "with mkal for each true label the highest prediction is always on the diagonal .",
    "+ the increasing of training samples gives stability in all cases . at the last step",
    "there are nt attractors , i.e. there are no rows with higher cumulative probability than others .",
    "for all methods the highest predictions are inside the diagonal except one class for no transfer .",
    "+ in all cases we can note that the posture with lowest accuracy on the diagonal is the 1 , i.e. the rest .",
    "we recall that , in data acquisition process , each movement is inter - spaced by rest .",
    "it makes this posture different than others and easily confused . +",
    "another analysis can be done to evaluate if there is an adaptive method that recognizes a class better than others and if this statistic changes increasing the number of training vectors .",
    "it is based on the results obtained with confusion matrices . for each column",
    "( i.e. each real class ) we consider the four classes with highest predictions .",
    "+ the details of this analysis are reported in the appendix [ sec : histi ] .",
    "+ from this analysis we can conclude that , given a class , different methods , generally , misclassify it with the same wrong classes .",
    "the situation does nt change as we increase the number of training vectors .",
    "thus , different algorithms have different mean performances but , paying our attention to a single class , the type of misclassification are the same",
    ". +      [ [ setup.-1 ] ] setup .",
    "the second experiment involves 9 amputated subjects from the third sub - database of ninapro ( see table in section [ sec : ninapro_dataset ] ) .",
    "+ in this set - up we consider amputees as target and sources . in particular ,",
    "one by one , each of the 9 subjects is the new target problem .",
    "the remaining 8 amputated subjects are considered as sources .",
    "thus , we have an amputee that learns to use the prosthetic hand with the help of prior knowledge from other amputees .",
    "+ the data taken into account are those of the exercise b : 8 hand configurations and 9 basic movements of the wrist .",
    "+ in the training phase a model , using each of the five algorithms , is built for each target subject .",
    "the process is repeated for an increasing number of training vectors with steps of @xmath164 up to a maximum of @xmath162 . in the test phase",
    "we evaluate the performance of each model .",
    "+ the 9 subjects of this experiment are not chosen randomly .",
    "as explained in section [ sec : data_acq ] , @xmath171 of the @xmath172 amputees had only @xmath173 electrodes instead of @xmath174 because of insufficient space in the stump . at the beginning we tested all the 11 subjects , but those with less electrodes had a lower performance than others .",
    "thus , in the following we report only the results for 9 subjects ; the results for 11 subjects are available in https://sites.google.com / site / noninvasiveprosthetichand/. + in tables [ tab : datasetaa ] and [ tab : datasetaaalg ] we report the principal characteristics of second experiment .",
    "+    [ [ results - recognition - rate.-1 ] ] results : recognition rate .",
    "the trend of the performance averaged over all the subjects as a function of the training vectors of the target problem is reported in figure [ fig:9amputatedsubj ] for all the algorithms .",
    "it comes from the mean between performance obtained for all the target subjects .",
    "+    [ h ]    in figure [ fig:9amputatedsubjbw ] the best and worst cases are reported .",
    "these are respectively the subjects for which each algorithm gives the best and worst result in performance .",
    "[ h ]    asymptotically mkal and h - l2l achieve the best performance followed by multi adapt and prior features with no transfer .",
    "a similar order is preserved in the best and worst case but a component of noise is present for single subject and the trend appears not very smooth .",
    "the only difference is that prior features outperforms no transfer of about 2 @xmath1 in the worst case ( @xmath175 ) .",
    "+ as shown in figure [ fig:9amputatedsubj ] mkal performs better than h - l2l with an average of 4 @xmath1 until 1080 training vectors ( @xmath175 ) , after these curves give the same result in performance . the difference between",
    "mkal and multi adapt shows an average advantage in recognition rate of around 10 @xmath1 for first curve ( @xmath170 ) .",
    "multi adapt has an average gain of 6 @xmath1 with respect to prior features ( @xmath170 ) .",
    "+ no transfer and prior show the lowest performance and their difference is not statistically significant ( @xmath176 ) .",
    "multi adapt , mkal and h - l2l outperform no transfer with an average of about 6 @xmath1 , 16 @xmath1 and 14 @xmath1 respectively . at 2160 training samples ,",
    "i.e. the last step , no transfer achieves a performance of 35 @xmath1 .",
    "the same performance is reached by multi adapt , mkal and h - l2l at only 840 , 240 and 480 training vectors , respectively .",
    "this result shows that the use of prior knowledge allows us to reduce by one order of magnitude the training time .",
    "+ the adaptive methods achieve faster than no transfer the asymptotic performance .",
    "passing from 600 training samples to 2160 the performance of no transfer , multi adapt , mkal and h - l2l increases of respectively : 9 @xmath1 , 6 @xmath1 , 5 @xmath1 and 8 @xmath1 .",
    "+    [ [ results - confusion - matrices.-1 ] ] results : confusion matrices .",
    "as done for intact subjects in previous section we can analyse the confusion matrices in order to evaluate the level of recognition and misclassification of a single class changing the number of training vectors and the algorithm .",
    "+ we report the confusion matrices for no transfer ( figure [ fig : ntconfmata ] ) , prior features ( figure [ fig : priorconfmata ] ) and mkal ( figure [ fig : mkalconfmata ] ) for 120 ( i.e. initial step ) , 1080 ( i.e. middle step ) and 2160 ( i.e. final step ) training vectors .",
    "the label 1 is associated to rest posture .",
    "+ one can find the confusion matrices for all algorithms in https://sites.google.com / site / noninvasiveprosthetichand/. +    [ h ]    [ h ]    [ h ]    as explained previously the warm colors are associated to high probability and the cool colors to low probability . in ideal case",
    "the prediction labels are equal to the true ones with the maximum probability and , graphically , we have red cells on the diagonal and blue outside . in all the three reported cases , augmenting the number of training vectors , the warm colours move towards the diagonal .",
    "+ no transfer makes prediction exploiting only the training vectors . at the first step there is an imbalance due to the training samples considered . from first image of figure",
    "[ fig : ntconfmata ] it is evident that the majority of first 120 training vectors belong to classes 2 , 3 , 7 and 8 . at the last step , with 2160 training vectors ,",
    "this displacement is solved .",
    "only the predictions associated to class 8 are higher than others out of the diagonal , but the highest prediction is always associated to the right classes except two cases .",
    "+ with prior , using only 120 training vectors , the highest prediction is associated to classes 8 and 9 . passing to 1080 training vectors",
    "the highest prediction is inside the diagonal for all classes except three . at the last step only a class suffers of this problem . + with mkal only a class has the highest prediction outside the diagonal using only 120 training vectors , but the problem is solved at the next steps .",
    "+ also in this case we evaluate for each real class the first four classes with highest predictions .",
    "this analysis is done in order to understand if there is an adaptive method that recognizes a class better than others , or if the misclassification changes increasing the number of training vectors . + the details of this analysis are reported in the appendix [ sec : hista ] .",
    "+ the obtained results show that , generally , a class is always misclassified with the same wrong classes and it is independent from the number of training vectors and the adaptive algorithm used .",
    "+      [ [ setup.-2 ] ] setup .",
    "the third experiment involves 9 amputated subjects and 20 intact subjects from respectively the third and the second sub - database of ninapro ( see table in section [ sec : ninapro_dataset ] ) .",
    "considering previous results we used the same amputated and intact subjects exploited in the first and second experiment .",
    "+ in this set - up we consider amputees as target and intact subjects as sources .",
    "in particular the sources are fixed and , one by one , we consider as target an amputated subject .",
    "thus , we have an amputee that learns to use the prosthetic hand with the help from the prior knowledge of intact subjects .",
    "+ the data taken into account are those of the exercise b : 8 hand configurations and 9 basic movements of the wrist .",
    "+ in the training phase we build a classification model with each of the five algorithms for each target subject .",
    "the process is repeated for an increasing number of training vectors with steps of @xmath164 up to a maximum of @xmath162 . in the test phase",
    "we evaluate the performance of each model .",
    "+ in the tables [ tab : datasetai ] and [ tab : datasetaialg ] we report the principal characteristics of third experiment .",
    "+    [ [ results - recognition - rate.-2 ] ] results : recognition rate .",
    "the trend of performance averaged over all the subjects as a function of the training vectors of the target problem is reported in figure [ fig:9amp20intsubj ] for all the algorithms .",
    "it comes from the mean between performance obtained for all the target subjects . +    [ h ]    in figure [ fig:9amp20intsubjbw ] the best and worst cases are reported .",
    "these are respectively the subjects for which each algorithm gives the best and worst result in performance .",
    "[ h ]    mkal achieves the best performance asymptotically and considering the whole trend .",
    "it is followed by h - l2l , multi adapt , prior features and no transfer .",
    "a similar order is preserved in the best and worst case but a component of noise is present for single subject and the trend appears not very smooth . we can note that no transfer and prior features perform in the same way and their differences are not statistically significant ( @xmath176 ) . +",
    "as shown in figure [ fig:9amp20intsubj ] mkal outperforms h - l2l with an average of 4 @xmath1 ( @xmath175 ) .",
    "the difference between h - l2l and multi adapt shows an average advantage in recognition rate of around 5 @xmath1 ( @xmath170 ) .",
    "multi adapt has an average gain of 8 @xmath1 with respect to prior features ( @xmath170 ) .",
    "+ until 720 training vectors prior features outperforms no transfer with an average of 6 @xmath1 , after the two curves keep the same performance .",
    "multi adapt , mkal and h - l2l outperform no transfer with an average of about 11 @xmath1 , 20 @xmath1 and 15 @xmath1 respectively . at 2160 training samples ,",
    "i.e. the last step , no transfer achieves a performance of 31 @xmath1 .",
    "the same performance is reached by multi adapt , mkal and h - l2l with only 480 , 240 and 360 training vectors , respectively .",
    "also in this case , the use of prior knowledge allows us to reduce by one order of magnitude the training time .",
    "+ the adaptive methods achieve faster than no transfer the asymptotic performance . in fact , passing from 600 training samples to 2160 the performance of no transfer , multi adapt , mkal and h - l2l increases of respectively : 10 @xmath1 , 7 @xmath1 , 4 @xmath1 and 7 @xmath1 .",
    "+    [ [ results - confusion - matrices.-2 ] ] results : confusion matrices .",
    "as done in previous sections we evaluate the level of recognition and misclassification of all classes from analysis of confusion matrices for each algorithm changing the number of training vectors .",
    "+ we report the confusion matrices for no transfer ( figure [ fig : ntconfmatai ] ) , prior features ( figure [ fig : priorconfmatai ] ) and mkal ( figure [ fig : mkalconfmatai ] ) for 120 ( i.e. initial step ) , 1080 ( i.e. middle step ) and 2160 ( i.e. final step ) training vectors .",
    "the label 1 is associated to rest posture .",
    "+ one can find the confusion matrices for all algorithms in https://sites.google.com / site / noninvasiveprosthetichand/. +    [ h ]    [ h ]    [ h ]    in the matrices the warm and cool colors represent respectively an high and low probability . in the case of a perfect prevision",
    "we have red cells on diagonal and blue outside . in all three reported cases , augmenting the number of training vectors , the warm colours move towards the diagonal . + no transfer at first step presents an imbalance in predictions because the models are built with few training vectors . from first image of figure",
    "[ fig : ntconfmata ] it is evident that the majority of first 120 training vectors belong to classes 3 , 4 , 5 and 16 . with 120 training samples the predictions associated to classes 2 and 10 are higher than others out of the diagonal . in this case",
    "the highest prediction is always associated to right classes except three cases .",
    "+ with prior features the highest prediction is associated to classes 10 , 11 and 18 at the first step . passing to 1080 and after to 2160 training vectors the highest prediction is inside the diagonal for all classes except one .",
    "+ with mkal only a class has the highest prediction outside the diagonal using only 120 training vectors and the problem is solved at next steps .",
    "+ also in this case we evaluate for each real class the first four classes with highest predictions . from this analysis",
    "we can evaluate if there is an adaptive method than in the recognition of a particular class is is better than others .",
    "+ the details of this analysis are reported in the appendix [ sec : histai ] . + as in previous cases , the obtained results show that , generally , a class is always misclassified with the same wrong classes and it is independent from the number of training vectors and the adaptive algorithm used . +      [ [ comparison - recognition - rate . ] ] comparison : recognition rate .    in this section",
    "we compare results obtained in different experiments .",
    "+ for the comparison in performance of all the algorithms in the three experiments we report in figure [ fig : comparisonperformance ] the asymptotic classification rate ( i.e. 2160 training vectors ) obtained averaging over all the subjects , in the best and in the worst case .",
    "+    [ h ]    the order in performance of the different algorithms is the same in the three experiments , thus the average behaviours are maintained .",
    "only h - l2l presents some differences : it outperforms mkal in the first case , instead in the second and third case the two algorithms reach the same final performance .",
    "+ the performance achieved for intact target ( first experiment ) is higher than the performance obtained for amputated target ( second and third experiment ) .",
    "it means that an intact is able to adapt his domain on domain of other intact subjects successfully ( mkal and h - l2l reach a performance of respectively 63 @xmath1 and 67 @xmath1 at 2160 training samples ) . the same performance is not reached by amputees , in fact mkal and h - l2l achieve an asymptote of about 50 @xmath1 .",
    "it means that , with respect to intact , for an amputee is more difficult to extract useful informations from different domains .",
    "+ the most interesting point concerns the comparison between the results from the second and the third experiment .",
    "the obtained performance appears unchanged in the two cases for all the algorithms .",
    "it means that an amputee learns in the same way from intact and amputated sources .",
    "it is a very important result , in fact as it is difficult to recruit amputees and to perform an experiment with them .",
    "amputees are obviously outnumbered with respect to intact subjects and , for them , the proposed exercises are usually difficult and painful to perform . +    [ [ comparison - correlation - matrix . ] ] comparison : correlation matrix .",
    "we study now if there are movements learned with ease or difficulty by intact subjects and vice versa by amputees . in order to achieve this goal",
    "we consider the recognition percentage of each movement for a given number of training vectors .",
    "we normalize each recognition with respect to the maximum in order to compare results from different settings and algorithms without considering the absolute performance . for these values",
    "( one for each algorithm and experiment ) the correlation matrix is calculated and reported in figure [ fig : corrmatrix_trainvec2160 ] .",
    "+    [ h ]    in previous matrix the warm colors and cool colors represent respectively high and low correlation between algorithms . as figure [ fig : corrmatrix_trainvec2160 ] shows",
    ", we obtain a block matrix .",
    "the two diagonal blocks contain respectively the correlations between intact and amputees . the block outside the diagonal holds the correlation between intact and amputees .",
    "+ the correlations between different methods of the same experiment is high .",
    "it means that there are nt movements learned simply with a method and hardly with another .",
    "+ the correlation between second and third experiment is high , thus an amputee learns a movement with the same simplicity or difficulty from intact and amputated subjects .",
    "instead the correlation between amputees and intact is low .",
    "it means that for amputees and intact simple and difficult movements are different .",
    "in this work we have dealt with the control of non - invasive myoelectric prosthesis in order to overcome the most common problems that an amputee tackles : fatigue and pain due to the long learning process and the discouragement due to the mismatch between desired and performed movements .",
    "in particular we have investigated the variation of the learning curve when a form of prior knowledge is used and if the type of knowledge ( from amputees or intact ) is significant with respect to the final learning performance for an amputee .",
    "+ our approach has been computational .",
    "we worked with public data from database ninapro to make the experiment reproducible and results statistically relevant ( considering the large number of subjects in the database ) .",
    "the algorithms used for data representation , and to solve the movements classification problem represent , respectively , the state of the art in the field of features extraction and domain adaptation .",
    "+ we have done three experiments in order to answer the previous questions . in the first we have considered intact that exploit the knowledge from other intact subjects . in the second we have studied amputated subjects that use other amputees as prior . in the last experiment we looked at amputees as target and intact subjects as their sources .",
    "+ our findings are very interesting and can contribute to improve this field of research .",
    "our results show that the prior knowledge positively affects the trend of recognition curve . with respect to the case in which no kind of knowledge is transferred , with adaptive algorithms the asymptotic performance",
    "is reached before and with an higher value .",
    "the performance achieved without transfer considering the maximum number of training vectors ( i.e. 2160 ) is typically reached by adaptive methods exploiting an order of magnitude less of training vectors .",
    "these results allow us to reduce the training time , speeding up the learning .",
    "+ the last two experiments have been done in order to answer the question about previous knowledge for an amputee target : our findings show that there is not any change in the trend and in the asymptotic performance of each algorithms when amputees or intact subjects are used as source .",
    "this means that an amputee , in order to boost the control learning of her prosthetic hand , can exploit the knowledge of intact subjects that are simpler to recruit than amputees . furthermore , for an intact user to complete the experiment requires less time and effort with respect to an amputee , thus the source models are created with ease",
    ". +    [ [ future - work . ] ] future work .",
    "the asymptotic performance reached by amputees is not very high ( 50 @xmath1 at the best ) .",
    "a possible direction for future works could be to try to improve this result focusing on deep learning theory that has had very interesting results in the field of machine learning .",
    "+ from analysis of confusion matrices we have seen that , given different algorithms and number of training vectors , a posture ( i.e. a class ) is , in most cases , misclassified with the same wrong classes . in order to solve the problem a possible direction for",
    "future research could be to insert a sort of classes selector that , a priori , cuts out on classification for some postures .",
    "lastly , we have made in this work the hypothesis that all source subjects had performed the same exercises and are therefore able to perform the same postures , both among them and with respect to the target subject .",
    "this in general will not be the case .",
    "different people might require different functionalities from their prostheses .",
    "as of today , there are no domain adaptation algorithms able to deal with this scenario .",
    "future work will focus on these research threads .",
    "this analysis is done in order to evaluate if there is an adaptive method that recognizes a class better than others and if this statistic changes increasing the number of training vectors . for each real class",
    "we consider the four classes with highest predictions , in order to evaluate the differences in misclassification . generally the fifth predicted class has a recognition lower than 5 @xmath1 , for this reason it and the following classes are not taken into account .",
    "+ in the following we analyse the results obtained for each experiment .",
    "+ we can find the complete results in + https://sites.google.com / site / noninvasiveprosthetichand/. +      we report the histogram of the first four classes predicted for each true label .",
    "methods involved in this analysis are multi adapt ( figure [ fig : mahist ] ) , mkal ( figure [ fig : mkalhist ] ) and h - l2l ( figure [ fig : h - l2lhist ] ) for 120 ( i.e. initial step ) , 1080 ( i.e. middle step ) and 2160 ( i.e. final step ) training vectors .",
    "[ h ]    [ h ]    [ h ]    we study the change in misclassification of each class when the number of training vectors increases . for each algorithm",
    "we calculate the percentage of classes that have at least the @xmath177 of predicted labels equal , changing the number of training vectors .",
    "the results are reported in table [ tab : percii ] .    for adaptive methods , increasing the number of training vectors ,",
    "a posture is misclassified always with the same wrong classes .",
    "+ the same analysis can be done considering different algorithms with the same number of training vectors .",
    "results of percentage are reported in table [ tab : percii ] .    from this analysis",
    "we can conclude that , given a class , different methods , generally , misclassify it with the same wrong classes . thus the misclassification is due to the similarity between the classes and it is independent from the algorithm .",
    "+ we must remember that the problem that we tackle is the recognition and classification of 8 fingers movements and 9 wrist postures ( see figure [ fig : allmovements ] ) .",
    "these movements are very similar , thus it is reasonable to expect an high degree of confusion between different postures .",
    "+      we report the histogram of the first four classes predicted for each true label .",
    "methods involved in this analysis are multi adapt ( figure [ fig : mahista ] ) , mkal ( figure [ fig : mkalhista ] ) and h - l2l ( figure [ fig : h - l2lhista ] ) for 120 ( i.e. initial step ) , 1080 ( i.e. middle step ) and 2160 ( i.e. final step ) training vectors .",
    "+    [ h ]    [ h ]    [ h ]    we study the change in misclassification of each class when the number of training vectors increases . for each algorithm",
    "we calculate the percentage of classes that have at least the @xmath177 of predicted labels equal , changing the number of training vectors .",
    "the results are reported in table [ tab : percaa ] .    for adaptive methods , increasing the number of training vectors ,",
    "a posture is misclassified always with the same wrong classes .",
    "only multi adapt shows a low percentage passing from 120 to 1080 training vectors .",
    "probably this model is not very reliable at first step , in fact from first image of figure [ fig : mahista ] we can see that the bins with highest probability have not the label equal to the right one . + the same analysis can be done considering different algorithms with the same number of training vectors .",
    "results of percentage are reported in table [ tab : percaa ] .    from values of previous table",
    "we conclude that , given a class , different methods , generally , misclassify it with the same wrong classes .",
    "+ we remember that the problem that we tackle is the recognition and classification of 8 fingers movements and 9 wrist postures ( see figure [ fig : allmovements ] ) .",
    "these movements are very similar , thus it is reasonable to expect an high degree of confusion between different postures .",
    "+      we report the histogram of the first four classes predicted for each true label .",
    "methods involved in this analysis are multi adapt ( figure [ fig : mahistai ] ) , mkal ( figure [ fig : mkalhistai ] ) and h - l2l ( figure [ fig : h - l2lhistai ] ) for 120 ( i.e. initial step ) , 1080 ( i.e. middle step ) and 2160 ( i.e. final step ) training vectors .",
    "+    [ h ]    [ h ]    [ h ]    we study the change in misclassification of each class when the number of training vectors increases .",
    "as done in previous sections , for each algorithm we calculate the percentage of classes that have at least the @xmath177 of predicted labels equal , changing the number of training vectors .",
    "the results are reported in table [ tab : percai ] .    for adaptive methods , increasing the number of training vectors , a posture is misclassified always with the same wrong classes .",
    "it means that the increment of training samples helps in term of average recognition , but the classifier mistakes in the same way different postures .",
    "+ the same analysis can be done considering different algorithms with the same number of training vectors .",
    "results of percentage are reported in table [ tab : percai ] .    from values of previous table",
    "we conclude that , given a class , different methods , generally , misclassify it with the same wrong classes . +",
    "as done in previously we underline that our classification problem involves very similar classes ( 8 finger movements and 9 wrist postures , see figure [ fig : allmovements ] ) , thus it is reasonable to expect an high degree of confusion between similar postures .",
    "+    9    richard o. duda , peter e. hart and david g. stork ,  pattern classification \" , john wiley & sons , canada , november 2000 .",
    "mehryar mohri , afshin rostamizadeh and ameet talwalkar ,  foundations of machine learning \" , the mit press , cambridge , massachusetts , 2012 .",
    "shai shalev - shwartz and shai ben - david  understanding machine learning , from theory to algorithms \" , cambridge university press , 32 avenue of the americas , new york , 2014 .",
    "tatiana tommasi ,  learning to learn by exploiting prior knowledge \" , lausanne , epfl , 2012 .",
    "jie luo ,  open - ended learning of visual and multi - modal patterns \" , lausanne , epfl , 2011 .",
    "suykens , j. de brabanter , l. lukas , j. vandewalle ,  weighted least squares support vector machines : robustness and sparse approximation \" , neurocomputing , vol .",
    "85 - 105 , october 2002 .",
    "christopher j. c. burgers ,  a tutorial on support vector machine for pattern recognition \" , data mining and knowledge discovery , pp .",
    "121 - 167 , 1998 .",
    "tatiana tommasi , francesco orabona , claudio castellini , and b. caputo ,  improving control of dexterous hand prostheses using adaptive learning \" , ieee , _ transactions on robotics _ , vol .",
    "207 - 219 , 2013 .",
    "novi patricia , tatiana tommasi , and barbara caputo ,  multi - source adaptive learning for fast control of prosthetics hand \" , 22nd international conference on pattern recognition ( icpr ) , pp .",
    "2769 - 2774 , 2014 .",
    "f. orabona , c. castellini , b. caputo , e. fiorilla , and g. sandini , `` model adaptation with least - squares svm for hand prosthetics '' , in proceedings of icra - international conference on robotics and automation , 2009 , pp .",
    "28972903 .",
    "k. saenko , b. kulis , m. fritz , and t. darrell , `` adapting visual category models to new domains '' , european conference on computer vision ( eccv ) , pp . 213226 , 2010 .",
    "s. b. david , j. blitzer , k. crammer , a. kulesza , f. pereira , and j. w. vaughan , `` a theory of learning from different domains '' , machine learning , vol .",
    "1 , pp . 151175 , may 2010 .",
    "qian sun , rita chattopadhyay , sethuraman panchanathan , jieping ye , `` a two - stage weighting framework for multi - source domain adaptation '' , nips , pp .",
    "505 - 513 , 2011    francesco orabona , luo jie , and barbara caputo , ",
    "multi kernel learning with online - batch optimization \" , journal of machine learning research 13 , pp .",
    "227 - 253 , 2012 .",
    "francesco orabona , luo jie , and barbara caputo ,  online - batch strongly convex multi kernel learning \" , 23rd ieee conference on computer vision and pattern recognition , june 2010 .",
    "luo jie , tatiana tommasi , and barbara caputo ,  multiclass transfer learning from unconstrained priors \" , ieee international conference on computer vision ( iccv ) , pp .",
    "1863 - 1870 , 2011 .",
    "tatiana tommasi , francesco orabona , and barbara caputo ,  discriminative cue integration for medical image annotation \" , pattern recognition letters , pp . 1996 - 2002 , 2008 .",
    "novi patricia , and barbara caputo ,  learning to learn , from transfer learning to domain adaptation : a unifying perspective \" , ieee , conference on computer vision and pattern recognition ( cvpr ) , pp . 1442 - 1449 , 2014 .",
    "manfredo atzori , arjan gijsberts , claudio castellini , barbara caputo , anne - gabrielle mittaz hager , simone elsig , giorgio giatsidis , franco bassetto , and henning mller ,  electromyography data for non - invasive naturally - controlled robotic hand prostheses \" , scientific data 1:140053 doi : 10.1038/sdata.2014.53 , 2014 .",
    "manfredo atzori , arjan gijsberts , simone heynen , anne - gabrielle mittaz hager , olivier deriaz , patrick van der smagt , claudio castellini , barbara caputo , and henning mller ,  building the ninapro database : a resource for the biorobotics community \" , ieee ras & embs international conference on biomedical robotics and biomechatronics ( biorob ) , 2012 .",
    "manfredo atzori , arjan gijsberts , ilja kuzborskij , simone heynen , anne - gabrielle mittaz hager , olivier deriaz , claudio castellini , henning mller , and barbara caputo ,  a benchmark database for myoelectric movement classification \" , transactions on neural systems & rehabilitation engineering , 2013 .",
    "arjan gijsberts , manfredo atzori , claudio castellini , henning mller , and barbara caputo ,  the movement error rate for evaluation of machine learning methods for semg - based hand movement classification \" , ieee trans .",
    "neural syst .",
    "735 - 744 , 2014 .",
    "ilja kuzborskij , arjan gijsberts , and barbara caputo ,  on the challenge of classifying 52 hand movements from surface electromyography \" , 34th annu .",
    "4931 - 4937 , 2012 .",
    "m. zecca , s. micera , m. carrozza , and p. dario , `` control of multifunctional prosthetic hands by processing the electromyographic signal '' , critical reviews in biomedical engineering , vol .",
    "4 - 6 , p. 459",
    ", 2002 .",
    "claudio castellini , patrick van der smagt , ",
    "surface emg in advanced hand prosthetics \" , biol cybern , 2009 .    c. de luca , `` the use of surface electromyography in biomechanics '' , journal of applied biomechanics , vol .",
    "13 , pp . 135163 , 1997 .",
    "d. farina , r. merletti , and r. m. enoka , `` the extraction of neural strategies from the surface emg '' , journal of applied physiology , vol .",
    "4 , pp . 14861495 , 2004 .",
    "b. gong , y. shi , f. sha , and k. grauman , `` geodesic flow kernel for unsupervised domain adaptation '' , proceedings of the ieee conference on computer vision and pattern recognition ( cvpr ) , providence , ri , june 2012 .",
    "la domanda pi frequente che mi hanno fatto in questi otto mesi di tesi  stata :  perch , te che hai studiato fisica , sei venuta a fare la tesi a ingegneria informatica ? ",
    "+ ... in realt _  tutto accadde su un vagone che portava a frosinone ... \" _ ( _ cit . _ p.f . )",
    "+ ... e quindi , per primo , vorrei ringraziare il professor giovanni b. bachelet che mi ha spinto a intraprendere una nuova strada e ad iniziare una nuova avventura .",
    "vorrei poi ringraziare la professoressa barbara caputo , perch non avrei potuto trovare una relatrice che mi seguisse in modo pi attento e stimolante .",
    "grazie per avermi dato subito fiducia , per avermi insegnato a non aver paura di tutti quegli argomenti inizialmente incomprensibili e , infine , per avermi fatto appassionare al mio lavoro .",
    "+ nonostante questo lavoro sia dedicato a loro , non trover mai sufficienti parole per ringraziare i miei genitori e mia sorella .",
    "grazie per aver creduto in me durante tutto il viaggio !",
    "+ un ringraziamento speciale va a luca , senza il quale il mio percorso universitario e questi ultimi cinque anni di vita non sarebbero stati gli stessi .",
    "grazie per la tua vicinanza in ogni momento , grazie per avermi incoraggiata e avermi anche messo di fronte ai miei errori .",
    "questo mio traguardo  anche un po tuo . + vorrei poi ringraziare le mie coinquiline , vecchie e nuove , per avermi accompagnata in questi  anni di roma \" .",
    "grazie ad anto e novi per avermi sopportata in questi mesi di tesi , grazie per aver condiviso dei bei momenti e di essermi state vicine , anche quando il computer era sulle mie gambe dalla mattina alla sera !",
    "le vecchie coinquiline sono troppe per essere nominate tutte , ma vorrei ringraziare in modo particolare dila e noemi per non essere solo delle ex - coinquiline , ma delle amiche . + inutile dire che in questi otto mesi ho",
    "incontrato tantissime persone che non avrei mai conosciuto se non avessi scelto di fare questa tesi .",
    "ringrazio quindi tutti i membri del gruppo vandal per avermi aiutata a capire e risolvere anche i dubbi che per voi erano cos banali .",
    "a particular thanks goes to ilja , who , despite my english and my poor initial preparation , helped me without discouraging .",
    "+ lultimo ringraziamento , ma non per questo meno importante , va a tutti i miei amici : quelli di fisica , per aver condiviso questo percorso con me , e tutti gli altri , per avermi sempre fatto il tifo da fuori ."
  ],
  "abstract_text": [
    "<S> the electromyography ( emg ) signal is the electrical activity produced by cells of skeletal muscles in order to provide a movement . </S>",
    "<S> the non - invasive prosthetic hand works with several electrodes , placed on the stump of an amputee , that record this signal . in order to favour the control of prosthesis , </S>",
    "<S> the emg signal is analysed with algorithms based on machine learning theory to decide the movement that the subject is going to do . + in order to obtain a significant control of the prosthesis and avoid mismatch between desired and performed movements , a long training period is needed when we use the traditional algorithm of machine learning ( i.e. support vector machines ) . an actual challenge in this field </S>",
    "<S> concerns the reduction of the time necessary for an amputee to learn how to use the prosthesis . </S>",
    "<S> + recently , several algorithms that exploit a form of prior knowledge have been proposed . in general </S>",
    "<S> , we refer to prior knowledge as a past experience available in the form of models . in our case </S>",
    "<S> an amputee , that attempts to perform some movements with the prosthesis , could use experience from different subjects that are already able to perform those movements . </S>",
    "<S> + the aim of this work is to verify , with a computational investigation , if for an amputee this kind of previous experience is useful in order to reduce the training time and boost the prosthetic control . </S>",
    "<S> furthermore , we want to understand if and how the final results change when the previous knowledge of intact or amputated subjects is used for a new amputee . </S>",
    "<S> + our experiments indicate that : ( 1 ) the use of experience , from other subjects already trained to perform a task , makes us able to reduce the training time of about an order of magnitude ; ( 2 ) it seems that an amputee that tries to learn to use the prosthesis does nt reach different results when he / she exploits previous experience of amputees or intact . </S>"
  ]
}