{
  "article_text": [
    "a common and important task in observational astronomy is to find or select a certain type of objects from a sample of candidates according to particular physical properties .",
    "examples include selecting active galaxy candidates from a multi - color optical photometry survey , selecting good pulsar candidates from a large number of candidates produced in pulsar searches .",
    "such tasks are time consuming , especially when the number of candidates is large .",
    "in this situation , computers can offer significant help when the selection rules can be derived based on prior experiences or physical considerations . however , for some applications , it is hard to determine the _ a priori _ criteria and one has to search for the selection criterion using the _ empirical _ knowledge embedded in the data themselves .",
    "for example , different types of sources usually form clusters in different regions of parameter space .",
    "when a large population of candidates is available , the clustering becomes statistically significant , and one can then use this to determine the selection criterion .    in order to build up the empirical selection criterion , we need to find a method to _ learn _ the knowledge from the data and apply this to generate the selection rules .",
    "machine learning algorithms are designed to extract empirical knowledge from a sample of data , and improve its performance based on the knowledge it learnt .",
    "machine learning algorithms also contain methods to classify data .",
    "there are already many successful applications of machine learning algorithms since the 1960s , some of which were recently used in the pulsar community ( e.g. @xcite ) .",
    "we refer to @xcite for the details of such algorithms and their applications in broader fields .",
    "clearly , machine learning and related classification algorithms can help to determine the criteria required to select desirable objects from a large sample of candidates in the context of observational astronomy .",
    "this paper demonstrates the application of gaussian mixture model ( gmm ) in the context of pulsar astronomy .",
    "the gmm , which we use here , is one type of un - supervised learning algorithms based on bayesian decision theory @xcite .",
    "it assumes that the data clusters in parameter space follow a superposition of several multivariate gaussian distributions .",
    "the parameters of each cluster are determined from data using the expectation - maximization ( em ) algorithm .",
    "we use two examples to show the application of gmm in pulsar astronomy .",
    "our first example is to classify pulsars in the parameter space of pulsar period ( @xmath1 ) and period derivative ( @xmath2 ) , and the second example is to calculate the likelihood of a gamma - ray point source being a pulsar . here",
    "gamma - ray point source parameters are from the _ fermi _ gamma - ray space telescope large area telescope 2-year point source catalog ( 2fgl catalog , @xcite ) .",
    "this article is organized as follows .",
    "we introduce the statistical technique , the gmm , in section  [ sec : stmt ] .",
    "we use two problems as examples to show properties and applications of gmm in section  [ sec : app ] .",
    "the first application in section  [ sec : psrapp ] is to find an empirical definition for millisecond pulsars ( msps ) from the period - period derivative ( @xmath3 ) distribution of known pulsars .",
    "the second application in section  [ sec : ferapp ] is to describe the 2fgl catalog point source distribution , to calculate the likelihood of a particular source being a pulsar , and to produce a pulsar candidate list for later confirmation observations .",
    "conclusions and discussions are given in section  [ sec : con ] .",
    "in this section , we introduce the basic concepts of gmm as well as related techniques to classify the data in parameter space .    the gmm is a probabilistic model to describe the distribution of data with clusters in the parameter space , where each cluster is assumed to follow the gaussian distribution . for a total of @xmath4 clusters in a @xmath5-dimensional parameter space ,",
    "the probability distribution @xmath6 of data @xmath7 is given by a weighted summation of all @xmath4 gaussian clusters , i.e. @xmath8 where the mixture weight of the @xmath9-th gaussian is @xmath10 and the distribution of each individual gaussian cluster is @xmath11}{(2\\pi)^{n/2 }          \\sqrt{|{{\\boldsymbol { { \\sigma}}}}_{k}|}}\\ , .",
    "\\label{eq : e2}\\ ] ] @xmath12 is the determinant of @xmath13 , the @xmath14 and @xmath15 are the mean vector and co - variance of the @xmath9-th gaussian respectively .    the parameters of gmm , i.e. @xmath10 , @xmath16 and @xmath13 , can be determined from the data by an unsupervised machine learning technique , namely the expectation - maximization ( em ) algorithm @xcite , which assumes no prior knowledge about the clustering structures . for @xmath17 data",
    "points @xmath18 , where @xmath19 , the em algorithm starts from an initial guess and learns gmm parameters from the data .",
    "the steps involved are :    * guess starting values for @xmath20 , and @xmath10 * expectation - step ( e - step ) : calculate @xmath21 and @xmath6 using equations ( [ eq : e1 ] )  and  ( [ eq : e2 ] ) . * maximization - step ( m - step ) : update model parameters @xmath22 using @xmath23 where @xmath24 is the index for data points .",
    "@xmath25 is the symbol for ` outer product ' , i.e. for any vectors @xmath7 and @xmath26 , @xmath27 is the matrix , of which the @xmath28-th row @xmath29-th column element is the product of the @xmath28-th element of @xmath7 and the @xmath29-th element of @xmath26 .",
    "* repeat the em steps , until the total likelihood @xmath30 converges , where @xmath31    it can be shown that the above iteration of the em algorithm increases the total likelihood @xmath30 , and the iterations always converge .",
    "indicates a data point .",
    "the index for each gaussian is labeled . here",
    "the total number of gaussian clusters is @xmath32 , where four of them belong to the subset @xmath33 ( @xmath34 ) , as indicated by the shaded area , thus @xmath35 [ fig : clsill ] ]    with the gmm and its parameters , one can infer the association of any data point @xmath7 with these clusters .",
    "one can also ask if @xmath7 belongs to a certain subset @xmath33 , which contains @xmath36 gaussian clusters out of a total of @xmath4 gaussian clusters .",
    "an illustration of the definitions is presented in figure  [ fig : clsill ] , where the indexes of gaussian clusters in @xmath33 are @xmath37 , and @xmath38 .",
    "the question of association can be answered via the standard likelihood ratio test .",
    "the neyman - pearson lemma @xcite claims that the most powerful test for the binary hypotheses : @xmath39 is to compare the logarithmic likelihood ratio @xmath40 against a statistical decision threshold @xmath41 , i.e. choose @xmath42 , if @xmath43 , otherwise choose @xmath44 . according to the gmm , the logarithmic likelihood ratio @xmath45 is @xmath46 where summation @xmath47 sums over the index @xmath9 for those clusters in the subset @xmath33 and @xmath48 sums over the complementary set of @xmath33 , i.e. those clusters not in the subset @xmath33 .",
    "the number of gaussian clusters @xmath4 , as an input parameter , can be determined using statistical methods . in practice ,",
    "one usually starts from @xmath49 , and then increases @xmath4 .",
    "as @xmath4 is increased , one can describe the data better . to avoid over - fitting",
    ", it is necessary to check the modelling using the multi - dimensional kolmogorov - smirnov test ( k - s test ) .",
    "similar to a 1-d k - s test , the multi - dimensional k - s test is used to test whether two data set differ significantly from each other or whether a data set differs from a known distribution .",
    "the statistic ( @xmath50 ) for k - s test is the maximal difference between the cumulative distribution of two data sets or between the data and the model .",
    "however , the cumulative distribution of multi - dimensional data is not well defined , thus it was proposed to compute such ` cumulative distribution ' for any possible order and then calculate the @xmath50 . for example , in order to determine the maximal difference @xmath50 between data and data or between data and distribution , it is necessary to check the cumulative probability for all of the four cases @xmath51 , and @xmath52 for any data point @xmath53 belonging to the two dimensional data set @xmath54 $ ] . for a multi - dimensional k - s test",
    ", the statistical threshold and p - values are usually calculated numerically via monte - carlo simulation , which generates the mock data sets and calculates the null - hypothesis distribution of @xmath50 accordingly .",
    "we refer readers to @xcite and @xcite for more details of such tests .    in summary",
    ", the technique of using the gmm to describe a data distribution and to determine the data association is given in the following recipe :    \\1 .",
    "determine the parameter space and form the data vector @xmath7 for the data set .",
    "guess the number of clusters @xmath4 and their initial parameters , i.e. @xmath16 and @xmath55 , where @xmath56 .",
    "use the em algorithm to find the true model parameters .",
    "check if gmm describes the data distribution well enough using the multi - dimensional kolmogorov - smirnov test .",
    "increase the number of gaussian clusters , if the test fails .    \\5 .",
    "once the model parameters are found , use equation  ( [ eq : likelyrank ] ) to determine the data association .",
    "we present two examples in next section to show its applications .",
    "as the first example , we apply gmm to the well - known pulsar @xmath3 diagram to find a quantitative description for the pulsar distribution . we also seek the ` empirical msp definition ' here , especially because a precise definition for msps using their periods and period derivatives is not available yet .",
    "the standard picture for pulsar evolution contains several major stages , i ) the birth of pulsar in a supernova explosion , ii ) the spin - down of pulsar due to radiation energy loss , iii ) the pulsar death due to the decrease in radiation power , and possibly for some binary system , iv ) the pulsar recycling by accretion induced spin - up .",
    "after birth in the supernova , the _ young pulsars _ usually have short periods and large period derivatives .",
    "they occupy the upper left part of the @xmath3 diagram , and are frequently associated with supernova remnants . as the pulsars age , they slow down , while , for those pulsars with breaking index @xmath57 , their @xmath2 also decreases . the pulsars",
    "then enter the main population in the centre of the diagram , referred to as the _",
    "normal pulsars_. eventually such spin - down causes the _ death _ of pulsars , i.e. the radiation of pulsar ceases or becomes too weak to detect .",
    "pulsars may also get _ recycled _ via the accretion process @xcite . the _ millisecond pulsars _",
    "( msps ) , which occupy the lower left corner of the @xmath3 diagram , are commonly believed to form due to such a spin - up of a normal pulsar via accretion materials from a companion stars .",
    "a continuum of pulsars from the msp population to the normal pulsar population is already observed , where the intermediate population are referred to as _ mildly recycled pulsars_. there are also pulsars occupying the upper right part of the @xmath3 diagram .",
    "the origin and evolution of these _ high magnetic field pulsars _ is still unclear .",
    "we use pulsar @xmath1 and @xmath2 values from the atnf pulsar catalogue @xcite .",
    "the distribution of pulsars is plotted in figure  [ fig : psrdis ] .",
    "the distribution of the whole pulsar population does not follow a gaussian distribution , but we can approximate the overall distribution with multiple gaussian clusters , i.e. the gmm is still valid for the modelling purposes .",
    "we apply the gmm in the @xmath3 diagram , so our parameter vector @xmath7 is @xmath58    we directly apply the gmm to the data set .",
    "the em algorithm for gmm is stable so the em algorithm converges for most initial values , although the em algorithm does not guarantee that it converges to the best global maximum of the total likelihood @xmath30 .",
    "in order to attain the global maximum , initial gmm parameters are generated randomly from a uniform distribution covering the whole @xmath3 diagram ( in particular , we choose the range of @xmath1 from @xmath59 to 20 s , and the range of @xmath2 from @xmath60 to @xmath61 ) .",
    "we then use these initial parameters in the em algorithm .",
    "we repeat this process @xmath62 times to determine the best global model parameters giving the largest likelihood value . in this case , the probability to converge to the best model is more than 30% for all guesses . the gmm is tested using the multi - dimensional kolmogorov - smirnov test @xcite , for which the @xmath63-value is chosen to be 95% . to pass such test ,",
    "we need six different gaussian components in the gmm .",
    ".numerical values of the gmm parameters for the pulsar distribution in the @xmath3 space .",
    "the definitions are in equations ( [ eq : e1 ] ) and ( [ eq : e2 ] ) .",
    "the mixture weights , @xmath64 , as probabilities , are dimensionless .",
    "the central vectors of clusters , @xmath65 , have the same units with respect to @xmath7 , i.e. @xmath66s@xmath67 , @xmath68s / s@xmath69 .",
    "the covariance matrices @xmath70 are in the linear space of @xmath71 , so their units are @xmath72 [ tab : parappd ] [ cols=\"^,<\",options=\"header \" , ]     ccccccccc index & 2fgl name & 1fgl name & ra & dec & semimajor & semiminor & @xmath40 & class + & & & j2000 & j2000&@xmath73deg & @xmath73deg & + 1 & 2fgl j1801.3@xmath742326e & & 18:01:22 & @xmath7423:26:24 &  &  & 38.2 & snr + 2 & 2fgl j1745.6@xmath742858 & & 17:45:42 & @xmath7428:58:42 & 1.0 & 1.0 & 29.0 & spp + 3 & 2fgl j1855.9@xmath750121e & & 18:55:58 & @xmath7501:21:18 &  &  & 27.5 & snr + 4 & 2fgl j0617.2@xmath752234e & 1fgl j0617.2@xmath752233 & 06:17:14 & @xmath7522:34:47 &  &  & 27.1 & snr + 5 & 2fgl j1906.5@xmath750720 & 1fgl j1906.6@xmath750716c & 19:06:35 & @xmath7507:20:33 & 3.5 & 2.9 & 18.2 & + 6 & 2fgl j1923.2@xmath751408e & & 19:23:16 & @xmath7514:08:42 &  &  & 18.0 & snr + 7 & 2fgl j1045.0@xmath745941 & 1fgl j1045.2@xmath745942 & 10:45:00 & @xmath7459:41:31 & 1.5 & 1.4 & 17.7 & + 8 & 2fgl j1704.9@xmath744618 & & 17:04:59 & @xmath7446:18:14 & 15.9 & 11.1 & 16.6 & + 9 & 2fgl j0848.7@xmath744324 & & 08:48:45 & @xmath7443:24:24 & 9.4 & 6.9 & 16.5 & + 10 & 2fgl j1738.9@xmath742908 & & 17:38:57 & @xmath7429:08:24 & 15.1 & 6.6 & 15.7 & spp +   + 11 & 2fgl j1819.3@xmath741523 & 1fgl j1819.4@xmath741518c & 18:19:21 & @xmath7415:23:29 & 7.4 & 5.5 & 15.5 & + 12 & 2fgl j1747.3@xmath742825c & & 17:47:24 & @xmath7428:25:52 & 3.6 & 3.2 & 15.4 & + 13 & 2fgl j1805.6@xmath742136e & & 18:05:38 & @xmath7421:36:42 &  &  & 15.4 & snr + 14 & 2fgl j1748.0@xmath742447 & 1fgl j1747.9@xmath742448 & 17:48:00 & @xmath7424:47:04 & 2.3 & 2.2 & 14.8 & glc + 15 & 2fgl j2018.0@xmath753626 & & 20:18:03 & @xmath7536:26:54 & 3.7 & 3.1 & 14.3 & + 16 & 2fgl j1839.0@xmath740539 & & 18:39:04 & @xmath7405:39:21 & 1.7 & 1.6 & 14.2 & + 17 & 2fgl j1901.1@xmath750427 & & 19:01:11 & @xmath7504:27:27 & 7.1 & 5.7 & 14.1 & + 18 & 2fgl j1748.6@xmath742913 & 1fgl j1748.3@xmath742916c & 17:48:39 & @xmath7429:13:52 & 4.1 & 3.5 & 13.8 & + 19 & 2fgl j1932.1@xmath751913 & 1fgl j1932.1@xmath751914c & 19:32:10 & @xmath7519:13:25 & 4.2 & 3.8 & 13.8 & spp + 20 & 2fgl j1847.2@xmath740236 & 1fgl j1846.8@xmath740233c & 18:47:14 & @xmath7402:36:40 & 7.0 & 4.6 & 13.4 & +   + 21 & 2fgl j1856.2@xmath750450c & & 18:56:14 & @xmath7504:50:16 & 8.0 & 6.4 & 13.3 & + 22 & 2fgl j0858.3@xmath744333 & & 08:58:20 & @xmath7443:33:34 & 9.1 & 8.7 & 12.6 & + 23 & 2fgl j1521.8@xmath745735 & 1fgl j1521.8@xmath745734c & 15:21:50 & @xmath7457:35:53 & 3.4 & 3.1 & 12.4 & spp + 24 & 2fgl j1625.2@xmath740020 & 1fgl j1625.3@xmath740019 & 16:25:13 & @xmath7400:20:04 & 3.5 & 3.2 & 12.2 & + 25 & 2fgl j0224.0@xmath756204 & 1fgl j0224.0@xmath756201c & 02:24:06 & @xmath7562:04:35 & 3.5 & 3.1 & 12.2 & + 26 & 2fgl j1857.8@xmath750355c & 1fgl j1857.9@xmath750352c & 18:57:53 & @xmath7503:55:29 & 10.0 & 6.9 & 11.9 & + 27 & 2fgl j1739.6@xmath742726 & & 17:39:40 & @xmath7427:26:03 & 12.3 & 7.0 & 11.8 & + 28 & 2fgl j1619.0@xmath744650 & & 16:19:04 & @xmath7446:50:48 & 26.4 & 15.3 & 11.5 & + 29 & 2fgl j1405.5@xmath746121 & 1fgl j1405.1@xmath746123c & 14:05:30 & @xmath7461:21:51 & 3.5 & 2.9 & 11.5 & + 30 & 2fgl j0842.9@xmath744721 & & 08:42:58 & @xmath7447:21:53 & 7.4 & 7.1 & 11.4 & spp +   + 31 & 2fgl j1814.1@xmath741735c & 1fgl j1814.0@xmath741736c & 18:14:09 & @xmath7417:35:31 & 4.9 & 4.3 & 11.0 & + 32 & 2fgl j1636.3@xmath744740c & 1fgl j1636.4@xmath744737c & 16:36:22 & @xmath7447:40:58 & 4.3 & 3.3 & 10.9 & + 33 & 2fgl j2022.8@xmath753843c & & 20:22:50 & @xmath7538:43:21 & 8.2 & 7.7 & 10.6 & snr + 34 & 2fgl j1714.5@xmath743829 & 1fgl j1714.5@xmath743830c & 17:14:31 & @xmath7438:29:32 & 2.8 & 2.3 & 10.5 & spp + 35 & 2fgl j1056.0@xmath745853 & & 10:56:00 & @xmath7458:53:16 & 8.4 & 7.2 & 10.5 & + 36 & 2fgl j1911.0@xmath750905 & 1fgl j1910.9@xmath750906c & 19:11:03 & @xmath7509:05:38 & 1.6 & 1.5 & 10.4 & snr + 37 & 2fgl j1638.0@xmath744703c & & 16:38:03 & @xmath7447:03:10 & 3.9 & 3.2 & 10.3 & + 38 & 2fgl j1536.4@xmath744949 & 1fgl j1536.5@xmath744949 & 15:36:30 & @xmath7449:49:45 & 1.7 & 1.6 & 10.2 & + 39 & 2fgl j1628.1@xmath744857c & & 16:28:11 & @xmath7448:57:36 & 11.8 & 6.7 & 10.1 & spp + 40 & 2fgl j1311.7@xmath743429 & 1fgl j1311.7@xmath743429 & 13:11:46 & @xmath7434:29:19 & 2.1 & 2.0 & 10.1 & +   + 41 & 2fgl j1650.6@xmath744603c & 1fgl j1651.5@xmath744602c & 16:50:36 & @xmath7446:03:16 & 3.5 & 3.1 & 10.1 & + 42 & 2fgl j1112.1@xmath746040 & 1fgl j1112.1@xmath746041c & 11:12:07 & @xmath7460:40:17 & 2.1 & 2.0 & 9.9 & spp + 43 & 2fgl j0608.3@xmath752037 & 1fgl j0608.3@xmath752038c & 06:08:20 & @xmath7520:37:55 & 7.0 & 6.4 & 9.9 & + 44 & 2fgl j1615.0@xmath745051 & & 16:15:02 & @xmath7450:51:06 & 5.4 & 4.6 & 9.9 & spp + 45 & 2fgl j1740.4@xmath743054c & 1fgl j1740.3@xmath743053c & 17:40:25 & @xmath7430:54:41 & 10.1 & 6.2 & 9.8 & spp + 46 & 2fgl j0340.5@xmath755307 & 1fgl j0341.5@xmath755304 & 03:40:36 & @xmath7553:07:52 & 9.0 & 7.6 & 9.7 & + 47 & 2fgl j2033.6@xmath753927 & 1fgl j2032.8@xmath753928 & 20:33:39 & @xmath7539:27:05 & 7.2 & 5.6 & 9.7 & + 48 & 2fgl j1914.0@xmath751436 & & 19:14:05 & @xmath7514:36:15 & 9.6 & 7.8 & 9.6 & + 49 & 2fgl j1027.4@xmath745730c & & 10:27:27 & @xmath7457:30:39 & 5.4 & 4.7 & 9.6 & + 50 & 2fgl j1843.7@xmath740312c & & 18:43:43 & @xmath7403:12:56 & 8.1 & 5.8 & 9.5 & +",
    "in this paper , we reviewed the gaussian mixture model and its application in data modelling and classification .",
    "as examples , we apply it to pulsar classification in the @xmath3 diagram as well as modelling and ranking the 2fgl catalog point sources .    in the application of the gmm to model pulsar populations ,",
    "we find that the pulsar distribution in the @xmath3 diagram should be described by six gaussian clusters .",
    "based on the gmm , we present a rule to separate the msp population from normal pulsar population . as caveats , the six gaussian clusters from gmm algorithm may be artifacts due to the requirement of approximating a non - gaussian distribution of pulsars .",
    "such a non - gaussian distribution can be induced by selection effects , pulsar evolution , star formation history , etc .",
    "however these six gaussian components coincide with other observational evidence , e.g. chemical composition of companion , radiation and polarization properties , timing behaviors etc .",
    "although it is still far from drawing any solid conclusion , those clusters found by the gmm algorithm may imply : i ) there are two different msp populations with different evolution scenarios , which is supported by the evidence that one cluster contains mainly co - white dwarf companions and the other contains mainly he - white dwarfs companions .",
    "ii ) there are two possible different groups of normal pulsars .",
    "iii ) high magnetic field pulsars may come from the evolution of normal pulsars .",
    "iv ) although there are different formation channels , recycled pulsars appear to form a continuum in the @xmath3 diagram .",
    "hence the spectrum of accreted mass for both fully recycled and mildly recycled msps should be smooth , otherwise we would identify more clusters .",
    "in the application to the 2fgl catalog , we use a 3-d parameter space spanned by @xmath76 , @xmath77 , and @xmath78 .",
    "we found that the distribution can be well described by three gaussian clusters , two of which correspond to pulsar and ag populations .",
    "the remaining cluster contains sources with lower detection significance . using the gmm",
    ", we calculate the pulsar likelihood for each source and sort the 2fgl catalog accordingly . in the sorted list ,",
    "we find that the top 5% sources contain 50% known pulsars , the top 50% contain 99% known pulsars , and no known active galaxy appears in the top 6% .",
    "clearly this algorithm has the ability to prioritize the follow - up searching observation scheme to find new pulsars . the statistical behavior of the sorted list is given in figure  [ fig : prob ] and a sample with the first and the last 5 sources of the sorted list is presented in table  [ tab : samp ] . in table",
    "[ tab : cand ] , we also present a list of un - associated 2fgl catalog sources with high pulsar likelihood for future pulsar searching projects .",
    "we include the gamma - ray flux as one dimension of our parameter space , although most discrimination comes from @xmath76 and @xmath77 .",
    "the reason to do so is that both @xmath76 and @xmath79 correlate with the test statistics . by introducing the gamma - ray flux , we can",
    ", to a certain degree , correct such a correlation . instead of flux1000 ( the integral flux from 1 to 100 gev )",
    ", we have also tried using other flux measurements available in the 2fgl catalog .",
    "in particular , we have experimented using energy_flux100 ( the energy flux from 100 mev to 100 gev obtained by spectral fitting ) , which yields a ranking result with a slightly lower detection rate compared to the result using flux1000 .",
    "we have tried with four dimensional gmms . in these experiments , various photon flux , energy flux ,",
    "test statistics of different energy bands , and galactic coordinates were tried as the forth dimension .",
    "the classification results show little differences .",
    "this is mainly due to the fact that most other variables available in the 2fgl catalog are correlated with the flux1000 , and thus do not provide much extra information to improve the classification .",
    "there are alternatives to the un - supervised machine learning techniques , where one uses supervised machine learning @xcite .",
    "one particular benefit of being un - supervised is that , since we use no prior information of source associations in our ranking algorithm , we can investigate the statistics quality of the algorithm easily by comparing the results with known pulsar and ag populations , as shown in figure  [ fig : prob ] .",
    "we note that the gmm algorithm detects three clusters in the @xmath78-@xmath76-@xmath77 parameter space , one of which is in the confused region with low gamma - ray fluxes .",
    "such component is likely to be an artifact due to the low signal - to - noise statistic .",
    "we gratefully acknowledge support from erc advanced grant `` leap '' , grant agreement number 227947 ( pi michael kramer ) .",
    "y. l. yue is supported by the national natural science foundation of china ( grant 11103045 ) , the national basic research program of china ( grant 2012cb821800 ) and the young researcher grant of national astronomical observatories , chinese academy of sciences .",
    "we thank ramesh karuppusamy and thomas tauris for reading the manuscript and their very helpful comments .",
    "we also appreciate the valuable inputs and help from the anonymous referee ."
  ],
  "abstract_text": [
    "<S> machine learning , algorithms to extract empirical knowledge from data , can be used to classify data , which is one of the most common tasks in observational astronomy . in this paper </S>",
    "<S> , we focus on bayesian data classification algorithms using the gaussian mixture model and show two applications in pulsar astronomy . after reviewing the gaussian mixture model and the related expectation - maximization algorithm </S>",
    "<S> , we present a data classification method using the neyman - pearson test . to demonstrate the method </S>",
    "<S> , we apply the algorithm to two classification problems . </S>",
    "<S> firstly , it is applied to the well known period - period derivative diagram , where we find that the pulsar distribution can be modeled with six gaussian clusters , with two clusters for millisecond pulsars ( recycled pulsars ) and the rest for normal pulsars . from this distribution </S>",
    "<S> , we derive an empirical definition for millisecond pulsars as @xmath0 . </S>",
    "<S> the two millisecond pulsar clusters may have different evolutionary origins , since the companion stars to these pulsars in the two clusters show different chemical composition . </S>",
    "<S> four clusters are found for normal pulsars . </S>",
    "<S> possible implications for these clusters are also discussed . </S>",
    "<S> our second example is to calculate the likelihood of unidentified _ fermi _ point sources being pulsars and rank them accordingly . in the ranked point source list , </S>",
    "<S> the top 5% sources contain 50% known pulsars , the top 50% contain 99% known pulsars , and no known active galaxy ( the other major population ) appears in the top 6% . </S>",
    "<S> such a ranked list can be used to help the future follow - up observations for finding pulsars in unidentified _ fermi _ point sources .    </S>",
    "<S> [ firstpage ]    pulsar : general  gamma - rays : stars  methods : statistical </S>"
  ]
}