{
  "article_text": [
    "many future wireless systems , such as low - power wireless sensor networks , one may encounter transmitters that harvest and store energy for transmission .",
    "such communication systems were first introduced by ulukus et al .",
    "@xcite and have received a lot of recent interest .",
    "when the battery is unlimited , @xcite shows that the entire capacity of an additive white gaussian noise ( awgn ) channel can be achieved . when there is no battery , in the continuous setting @xcite provides an analysis of the awgn channel capacity , but there are gaps in the proof . for the discrete setting , however , the treatment with zero - battery is rather elementary ( cf .",
    "section  [ subsec : numerical - ach - rates ] ) . the intermediate case , i.e. , the case with a finite nonzero battery , was first considered in @xcite , where the optimum offline transmission policy for an energy harvesting node is obtained .",
    "however , in general , determining the channel capacity in such a case remains open .",
    "for the simplest case of a binary energy harvesting transmitter with a unit - sized battery connected to a noiseless channel , under the assumption that the transmitter only uses the causal battery state information ( which is called scenario  1 in the current paper , see section  [ subsec : three - models ] ) @xcite derives a capacity formula involving an auxiliary random variable and obtains its upper and lower bounds . also under scenario  1",
    ", @xcite further assumes that the receiver also has the energy information and studies the discrete setting with an i.i.d .",
    "energy harvesting process .",
    "assuming some recent results on finite state channels ( see @xcite ) can be generalized to finite state channels with _ input constraints _ , @xcite suggests the possibility of a single - letter capacity formula under some extra assumptions .",
    "for the continuous setting with i.i.d .",
    "energy harvesting , @xcite and @xcite explore the awgn channel and provide upper and lower bounds that have a constant gap .",
    "in addition , for general energy harvesting channels with i.i.d .",
    "energy harvesting @xcite obtains a multi - letter mutual information capacity formula , and also shows that the capacity does not depend on the initial battery level .",
    "@xcite explores some special cases with feedback and shows that in these cases feedback can increase capacity .    in this work",
    "we study the capacity of a discrete energy harvesting channel with a finite battery in its full generality .",
    "we study both transmitter - side energy information scenarios that have appeared in the literature ( i.e. , causal battery information v.s",
    ". causal harvested energy information ) , with a general energy utilization model and a general energy cost function . in all the ( finite - battery )",
    "literature above the energy harvesting process is assumed to be i.i.d . , whereas in this paper we derive capacity formulas for arbitrary energy harvesting processes . in the special case when this process is finite - order markov ( which is not necessarily stationary ) , we obtain computable upper and lower bounds .",
    "as we will see , the difficulty of the finite - battery energy harvesting channel is mainly caused by 1 ) the random instantaneous input constraint , which is influenced by both the input and the energy harvesting process and evolves with time , and 2 ) the causal energy information that is available to the transmitter only . in what follows",
    "we briefly outline our approaches to tackle this capacity problem .",
    "since energy harvesting channels have both channel side information and input constraints , we first use results from channels with causal transmitter - side information ( csit ) to convert each of them to a certain equivalent channel without side information or constraint , but with an enlarged alphabet and a more complicated channel transition probability .",
    "we then express the capacity of this channel in terms of a multi - letter formula using the verd - han general framework @xcite .",
    "as such formulas are not easy to evaluate in general , we impose some restrictions on the input of the equivalent channel to obtain a certain surrogate channel model , whose capacity provides a lower bound on the original channel capacity . for this surrogate channel",
    "we study the required stationarity and ergodicity conditions and use the shannon - mcmillan - breiman theorem to obtain some achievable rates , which serve as capacity lower bounds for the energy harvesting channel .",
    "these rates can be computed and optimized using the generalized blahut - arimoto algorithm@xcite . for the capacity",
    "upper bounds , we assume that the energy information is also known at the receiver , and use gallager s methods for finite state channels@xcite to obtain an upper bound in terms of maximized block mutual information for every block length . these bounds have high computational complexity as they are derived from the equivalent channel , so we use results from feedback channels@xcite to rewrite them in terms of maximized directed information on the original channel , which have much less complexity .",
    "it turns out that in this form the upper bounds for scenario  1 allow for a linear complexity dynamic programming recursion , whereas those for scenario  2 can also be relaxed to obtain a similar recursion . apart from the upper bounds ,",
    "we also obtain a capacity lower bound in scenario  2 for i.i.d .",
    "energy harvesting processes , in terms of maximized block mutual information .",
    "this bound can serve as a simpler alternative achievability proof for the multi - letter capacity formula in @xcite .",
    "in addition to these main results , using the same methods we also analyze a certain finite state channel model that is closely related to energy harvesting channels .",
    "the rest of the paper is organized as follows .",
    "first , in the rest of this section , we introduce our major notations .",
    "section  [ sec : sys - model ] describes the channel models for two different energy information scenarios , as well as a related finite state channel based model , and transforms them to their respective equivalent channels . in section  [ sec : channel - capacity ] we express the channel capacities using the verd - han formula . in the next section , section  [ sec : ach - rates ]",
    ", we impose some restrictions on the equivalent channels , derive the required stationarity and ergodicity conditions , and use the shannon - mcmillan - breiman theorem to compute some achievable rates . the capacity upper bounds are derived in section  [ sec : capacity - bounds ] , together with a lower bound for scenario  2 with i.i.d .",
    "energy harvesting .",
    "section  [ sec : simplified - upper - bounds ] then simplifies and relaxes these high - complexity upper bounds . in section  [ sec : numerical ] some numerical examples are given for the computation of the achievable rates and various capacity bounds .",
    "section  [ sec : conclusions ] concludes the paper .",
    "the appendices are devoted to the stationarity and ergodicity theory for our channels , which are necessary for the results in section  [ sec : ach - rates ] .      in the main text of this paper we use the following notational conventions :    * for random variables : *",
    "* capital letters denote the random variables , e.g. , @xmath0 , @xmath1 . *",
    "* corresponding lowercase letters denote the realizations , e.g. , @xmath2 , @xmath3 . * * corresponding script letters denote the alphabets , e.g. , @xmath4 , @xmath5 .    * a vector @xmath6 is usually denoted by @xmath7 , whereas @xmath8 . when @xmath9 , @xmath7 denotes the empty set .",
    "in addition , sometimes we use the abbreviation @xmath10 for @xmath11 . *",
    "bold lowercase letters also denote vectors , e.g. , @xmath12 , @xmath13 . *",
    "bold capital letters denote certain infinite collections , e.g. , @xmath14 , @xmath15 .",
    "* @xmath16 denotes the indicator function : @xmath17 when @xmath18 is the solution set of an equation @xmath19 , we simply denote the function by @xmath20 . *",
    "@xmath21 denotes a sequence of symbols , indexed by @xmath22 .",
    "for example , @xmath23 denotes the random process @xmath24 to be concise we sometimes drop the sub-/super- scripts and just write @xmath25 when the context is clear .",
    "we consider a communication system powered by some energy harvesting mechanism with a battery , as depicted in fig .",
    "[ fig : eh - model ] . at each transmission cycle",
    "@xmath22 , the system first harvests some amount of energy , @xmath26 , from the environment , and combines it with @xmath27 , the energy stored in the battery after the last transmission , to transmit a symbol @xmath28 .",
    "@xmath0 consumes some amount of energy @xmath29 , which can not exceed the total available energy @xmath30 for the current cycle .",
    "the remainder , not exceeding the battery capacity @xmath31 , is saved in the battery for future transmissions .",
    "the symbol @xmath0 is sent over the channel @xmath32 and at the receiver a symbol @xmath33 is received .",
    "the alphabets @xmath4 and @xmath5 are assumed to be finite with @xmath34 or @xmath35 , and the channel is discrete memoryless .    to be precise , the energy constraint on the system can be written as @xmath36 where the total available energy @xmath30 is expressed as a function @xmath37 of the battery energy @xmath27 and the harvested energy @xmath26 .",
    "the form of @xmath38 depends on how the system combines and utilizes @xmath27 and @xmath26 .",
    "for example , if @xmath26 is immediately available for transmission , then simply @xmath39 however , if the system can only use @xmath26 to charge the battery and draws energy solely from the battery for transmission , then @xmath40 this energy model can also take account of more real world influences .",
    "for example , if the battery is inefficient at charging and also has leakage , characterized by the ratios @xmath41 and @xmath42 , respectively , then the model becomes @xmath43 in view of the expression for @xmath44 in , for @xmath45 sometimes we also write @xmath46    the energy cost function @xmath47 , in general , can be any non - negative function on the alphabet @xmath4 .",
    "however , in this work , we require @xmath4 to always include a zero symbol @xmath48 and that transmitting a zero does not consume any energy , i.e. , @xmath49 in addition , @xmath50 is usually endowed with some physical meaning .",
    "for example , we often use the quadratic cost function to denote the instantaneous power : @xmath51    for readers convenience the notations for the energy harvesting channel are summarized in table  [ table : eh - notations ] .",
    "assume the initial energy @xmath52 stored in the battery is a random variable and the sequence of harvested energy @xmath23 is a random process independent of @xmath52 . to simplify the problem",
    ", we only consider a _ finite discrete _ system .",
    "specifically , we assume @xmath53 , and that all the energy quantities involved are quantized with the same interval size , i.e. , all @xmath26 , @xmath27 , @xmath30 , @xmath29 and @xmath31 are integral multiples of some common unit of energy @xmath54 . hence without loss of generality",
    "we can assume all these quantities are integers .",
    "moreover , we further assume that the alphabet of @xmath26 is a bounded set @xmath55 of non - negative integers , so that @xmath27 and @xmath30 can also only take values in finite integral sets @xmath56 and @xmath57 , respectively .",
    ".energy harvesting channel notations [ cols=\"^,<,^\",options=\"header \" , ]     because of the energy constraint , the operation of energy harvesting channels is much more complex than an ordinary dmc . during each transmission",
    "the transmitter is not free to choose any letter in @xmath4 ; instead , at time @xmath22 it can only send a symbol @xmath0 that does not demand more than the current available energy @xmath30 . since @xmath30 determines how much energy the system can spend for the current transmission , we also call it the _ energy state _ at time @xmath22 . from the functional dependence of @xmath30 on @xmath27 and @xmath26 , we see that @xmath58 is a random process with memory .",
    "such a type of input constraints is unprecedented in traditional communication systems , which poses a major challenge for the analysis of the channels .      for such energy harvesting channels , we study the following two scenarios with regard to the availability of energy information at transmitter .    * _ scenario 1 _ :",
    "before the @xmath22-th transmission only the energy states @xmath59 are observed at the transmitter . *",
    "_ scenario 2 _ : the transmitter knows the initial battery level @xmath52 and observes the harvested energy @xmath60 before the @xmath22-th transmission .",
    "in both scenarios the receiver has no energy information .",
    "for convenience , in the following we refer to the channel models under these two scenarios as _ eh - sc1 _ and _ eh - sc2 _ , respectively . in a sense",
    "the second scenario is more general than the first , since we can recover the energy information for eh - sc1 from eh - sc2 : by , with @xmath61 the transmitter can deduce @xmath62 from @xmath63 and @xmath52 ( but not vice versa ) .",
    "the energy information is a certain form of channel side information causally known at the transmitter , which is reminiscent of channels with causal csit @xcite .",
    "the difference is that , in this new setting the energy states affect the input alphabets , instead of the channel transition probabilities . to assist the analysis of such type of channels , we introduce a closely related , but simpler channel model : a certain finite state channel with causal csit and state - dependent input constraints , which is referred to as fsc - x .",
    "[ def : gallager - fsc ] a finite state channel for more discussion .",
    "compared to the original definition in @xcite , we increase the indices of the states by 1 to better accommodate our channel model . ]",
    "( fsc ) is a channel with finite input , output , and state alphabets @xmath4 , @xmath5 , and @xmath57 .",
    "the corresponding symbols at time @xmath22 are denoted by @xmath0 , @xmath1 , and @xmath30 , respectively , and the channel transitions is governed by a condtional probability @xmath64 which satisfies @xmath65 and which is time - invariant ( i.e. , independent of @xmath22 ) .",
    "a channel _ fsc - x _ is an fsc with causal transmitter side csi whose input is constrained by the current state .",
    "precisely , at each time @xmath22 , the state @xmath30 is fed to the encoder , which limits the input symbol @xmath0 to a subset @xmath66 .",
    "the channel model is illustrated in fig .",
    "[ fig : fsc - model ] .",
    "the connection of fsc - x to the energy harvesting channels is given by the following proposition .",
    "[ proposition : eh - sc1-fsc - x ] when the energy harvesting process @xmath25 is i.i.d .",
    ", the channel eh - sc1 becomes a special case of fsc - x , whose states are exactly the energy states @xmath58 .    by the dmc property and , for eh - sc1 @xmath67 where @xmath68 holds by the i.i.d .",
    "property of @xmath25 , @xmath69 is established by expanding @xmath64 similarly .",
    "the expression of @xmath64 is independent of @xmath22 , and so an fsc is defined .",
    "furthermore , by the input is constrained by @xmath70 , where @xmath71 , @xmath72 since @xmath30 is causally known at the transmitter , the model fits exactly into the definition of fsc - x .",
    "note that all the channels eh - sc1 , eh - sc2 , and fsc - x are subject to random input constraints , so an ordinary channel encoding scheme can not function properly .",
    "in fact , if a message is mapped to any fixed input vector @xmath73 , then chances are that some symbol @xmath2 does not satisfy the input constraint at the time of transmission , since the constraint value at that time might be incompatible with @xmath2 . hence for these channels",
    "we define new encoding schemes analogous to @xcite , taking the csit into account to resolve this issue .",
    "denote the set of messages to be transmitted as @xmath74 .",
    "a block code @xmath75 of length @xmath76 for eh - sc1 is defined by a sequence of @xmath76 encoding functions @xmath77 , such that @xmath78 and @xmath79 , i ) the output @xmath73 of the encoder @xmath75 takes the form @xmath80 for all @xmath81 ( i.e. , @xmath82 is causal in @xmath83 ) ; ii ) the energy constraint is satisfied : @xmath84 for all @xmath22 .",
    "a block code @xmath75 of length @xmath76 for eh - sc2 is defined by a sequence of @xmath76 encoding functions @xmath85 , such that @xmath78 , @xmath86 and @xmath87 , i ) the output @xmath73 of the encoder @xmath75 takes the form @xmath88 for all @xmath81 ( i.e. , @xmath82 is causal in @xmath89 ) ; ii ) the energy constraint is satisfied .",
    "a block code for fsc - x takes the same form as in eh - sc1 , except that the second requirement is changed to the input constraint @xmath90 for all @xmath22 .    as usual ,",
    "the decoder for all the channels above is defined as @xmath91 , which maps the output @xmath92 to an estimated message @xmath93 . with the block codes",
    "properly defined , the definitions of probability of error , code rate , achievable rate , and channel capacity follow standard texts ( see , e.g. , @xcite ) .",
    "[ rmk : eh - sc1 - 2 ] the capacity for eh - sc1 is smaller than or at most equal to eh - sc2 , since the latter has more energy information at the transmitter , as mentioned above . hence any capacity lower bound / achievable rate for eh - sc1 is also a capacity lower bound / achievable rate for eh - sc2 , while any capacity upper bound of eh - sc2 is also a capacity upper bound of eh - sc1 .",
    "that said , whether the first channel has a strictly smaller capacity is an open question and is not investigated in this paper .      from the evolution of @xmath94 in",
    ", the energy state @xmath30 depends on the full history of the harvested energy @xmath63 , all the past transmitted symbols @xmath95 , and the initial battery level @xmath52 .",
    "this ever - growing memory of the energy constraint poses a major difficulty for the analysis of energy harvesting channels . if @xmath25 is i.i.d . and",
    "the battery capacity @xmath96 , then the system is actually memoryless , and it is easy to show that the channel for either scenario is simply equivalent to a dmc with an enlarged alphabet ( similar to @xcite ) .",
    "however , if these conditions do not hold , then the system ( under either scenario ) has infinite memory and the analysis is much more involved  which is also the case for the channel fsc - x .    for such type of channels we use the approaches for channels with causal csit in @xcite to convert them to equivalent channels without side information or constraints ( which have enlarged input alphabets and still have memory )",
    "for each of our three models , the equivalent channel can be expressed as @xmath97 where we use @xmath98 and @xmath1 to denote the new input and output symbols , respectively , and @xmath99 to denote the @xmath76-symbol channel transition probability . for each @xmath76",
    "this new channel corresponds to @xmath76 operations of the original channel , starting from the beginning of transmission .",
    "the output alphabet @xmath100 is the same as before .",
    "the input alphabet @xmath101 , however , is different : a valid input symbol @xmath98 at each time @xmath22 is now a function of the causal side information , which respects the input constraints is no longer the cartesian product of @xmath76 single - channel - use alphabet , and thus it is denoted by @xmath101 instead of @xmath102 . ] . for each transmission cycle",
    ", such a function @xmath98 is sent to the channel input , which reads in the ( causal ) side information to produce a symbol @xmath28 .",
    "this symbol is then sent to the original channel and an output symbol @xmath33 is received . the transition probabilities for @xmath14",
    "are thus obtained by averaging those for the original channel over the randomness of the environment ( or channel states ) .",
    "below these definitions are made precise for each model , starting from the simplest case fsc - x .",
    "[ def : equiv - fsc - x ] the @xmath22-th input symbol is a function @xmath103 , which can also be viewed as a vector in @xmath104 . the function needs to satisfy the input constraint @xmath105 , @xmath106 , and so the input alphabets for time @xmath22 and for block length @xmath76 are , respectively , @xmath107 the @xmath76-symbol channel transition probability is determined as follows .",
    "first with the fsc probability model and the functional relation @xmath108 , @xmath109 then as @xmath110 is independent of @xmath111 : @xmath112 .    the input symbols / alphabets take the same forms as in the previous case , with @xmath113 defined by . for the channel transition probability , observe that i ) @xmath52 and @xmath114 are independent , and are independent of @xmath111 ( since they are unknown at the encoder ) ; ii ) @xmath73 is determined by @xmath115 , @xmath116 , and @xmath117 from the recursion @xmath118 and @xmath119 is a function of @xmath115 , @xmath120 and @xmath121 ; iii ) @xmath92 is produced by the dmc with input @xmath73 .",
    "so @xmath122    [ def : equiv - eh - sc2 ] the @xmath22-th input symbol for the equivalent channel is a function @xmath123 , which is also a vector in @xmath124 .",
    "the function @xmath125 needs to be compatible with the previous input symbols , @xmath121 , in terms of the the energy constraint .",
    "in particular , for each block length @xmath76 , a feasible input vector @xmath117 needs to satisfy @xmath126 for all @xmath81 , @xmath86 and @xmath127 . here",
    "@xmath128 is determined recursively by @xmath129 note that the permitted function values of @xmath125 depends not only on the energy sequence @xmath130 , but also on all previous input symbols @xmath121 .",
    "so the input alphabet for time @xmath22 takes the form @xmath131 where @xmath132 is defined in ; further , the input alphabet for block length @xmath76 is @xmath133 which is the collection of all vectors of @xmath76 causal functions on the energy sequence ( and the initial battery ) that are consistent with the energy constraint . for the channel transition probability , by the same arguments above ( but with recursion instead )",
    "we have @xmath134    since there is no csi or constraints for these new channels , the encoding maps now take the usual form @xmath135 , whereas the form of the decoders are not changed . for each model",
    "the new channel is equivalent to the original one , in the sense that they have the same capacity : in fact , as stated in @xcite , block codes for the original and equivalent channels can be easily translated into each other , which induce the same output distribution  hence using the same decoder , the same probability of error can be achieved .",
    "the use of equivalent channels avoids the difficulty of dealing with either the csit or the input constraints , at the cost of more complicated input alphabets , whose sizes grow with @xmath22 . roughly speaking",
    ", the cardinality for the input alphabet at time @xmath22 grows double - exponentially ( cf .",
    "* example  4.3.1 ) ) .",
    "to compute the capacity for a channel as general as , we need to invoke verd and han s general capacity formula for arbitrary channels without feedback @xcite .",
    "define an _ input distribution process _",
    "@xmath15 to be a sequence of probability distributions defined on @xmath101 for each @xmath76 ( which need not have any relation among them ) .",
    "equivalently , @xmath15 can be represented by a collection of random vectors @xmath136 , where each @xmath137 is a random vector instead of the usual @xmath111 here , since the first @xmath138 entries of @xmath137 need not agree with @xmath139 . ] in @xmath101 that exactly has the @xmath76-th distribution of @xmath15 .",
    "the corresponding _ output distribution process _",
    "@xmath140 is the collection of random vectors @xmath141 in @xmath100 , where each @xmath141 is induced by the input random vector @xmath137 and the @xmath76-symbol channel transition probability @xmath99 .",
    "furthermore , define the _ information density _ between @xmath137 and @xmath141 as @xmath142 for all @xmath143 , @xmath144 .",
    "the _ inf - information rate _ between @xmath15 and @xmath145 is then defined as @xmath146 where for any sequence of random variables @xmath147 , define its _ liminf in probability _ as the supremum of all the real numbers @xmath148 for which @xmath149 vanishes as @xmath150 : @xmath151    [ thm : c - equivalent - channel ] the capacity of the channel @xmath14 in is given by @xmath152 where the supremum is taken over all input distribution processes @xmath15 .",
    "the channel capacities of the three models in this paper can all be obtained from their respective equivalent channels in section  [ subsec : equiv - ch ] and theorem  [ thm : c - equivalent - channel ] . despite its generality , however , the capacity formula has the following issues :    1 .",
    "the supremum is taken over all possible input distribution processes , which is hard to enumerate / parameterize .",
    "2 .   given an arbitrary input distribution processes @xmath15 , the inf - information rate is not always readily computable , as the asymptotic behavior for the corresponding random sequence might be unknown .",
    "3 .   as the input alphabet size @xmath153 grows double - exponentially ( roughly ) , the computational complexity is also double - exponential when calculating either the information density distribution or the mutual information for a single block length @xmath76 .",
    "hence this formula is too complicated to evaluate in general .",
    "nonetheless , it provides us a useful tool to analyze the channel capacities . in the next section",
    "we will try to resolve these difficulties under some simplifying conditions and assumptions to make the computation tractable .",
    "such simplifications give us achievable rates for our channels , which are lower bounds of their respective capacities .",
    "note that in the following special cases , simpler ( but still not computable ) capacity formulas might be possible . for the binary noiseless eh - sc1",
    ", @xcite proposes a single - letter capacity formula involving an auxiliary variable .",
    "more recently , for eh - sc2 , @xcite shows that when the energy harvesting process @xmath25 is i.i.d .",
    ", the channel capacity has a multi - letter mutual information expression : it can be written as the limit of maximum mutual information per channel use for the equivalent channel , as the block size tends to infinity .",
    "the achievability is proved using a complex transmission scheme , while the converse is given by fano s inequality as in @xcite ( see also section  [ subsec : ub - gallager - type ] ) .",
    "furthermore , in ( * ? ? ?",
    "* proposition  1 ) the authors also prove that in this case the capacity does not depend on the initial battery value is stationary and ergodic , and for both energy harvesting scenarios eh - sc1 and eh - sc2 . ] . in section  [ subsec : eh - ub ] we show that with this proposition our theorem  [ thm : lb - eh ] can provide a much simpler achievability proof .",
    "to address the issues in computing the channel capacity , we restrict the input symbols of the channel model to a constant - sized subset of its alphabet and obtain a surrogate channel @xmath154 , whose capacity @xmath155 provides a lower bound for the capacity @xmath156 of the channel @xmath14 . in particular , instead of the full csi history , the input functions now can only depend on a limited amount of the causal side information , with which the transmitter can still compute the instantaneous input constraint .",
    "let @xmath157 denote the new input function at time @xmath22 and @xmath158 denote its ( constant - sized ) alphabet . similar to , the surrogate channel can be expressed as @xmath159 it turns out that in many cases we are interested in , @xmath154 becomes a finite state channel ( fsc ) .",
    "the capacity of a general fsc is studied in @xcite , both of which give two series as the capacity upper and lower bounds , in terms of the mutual information between the input and output for each block size @xmath76 . when the fsc is _ _ indecomposable _ _ in appendix  [ sec : ergodicity - markov - channels ] or @xcite . ] , the upper and lower bounds both converge to the capacity .",
    "however , these bounds are not very useful for us : i ) since @xmath155 is less than or equal to @xmath156 , the lower bounds are genuine , but the upper bounds are not meaningful ; ii ) the computational complexity of such bounds is exponential in @xmath76 ; iii ) the bounds in @xcite are too loose for small @xmath76 and their convergence is slow ( see @xcite ) ; iv ) the bounds in @xcite are supposed to be tighter , but the computation is not easy for a general @xmath76 .",
    "another way of describing the capacity @xmath155 is ( again ) through the verd - han formula ( cf .",
    "theorem  [ thm : c - equivalent - channel ] ) : @xmath160 for which we define the same concepts and similar notations , as in section  [ sec : channel - capacity ] , with respect to the surrogate channel @xmath154 .",
    "the supremum in is taken over all input distribution processes @xmath161 .",
    "although in general this formula is still not computable , for any given input distribution process that yields a computable inf - information rate we can obtain an achievable rate for @xmath154 ( and hence also for @xmath14 ) , which lower bounds the capacity @xmath155 ( and @xmath156 ) . in particular , assume the input distribution process @xmath161 is induced by a source random process @xmath162 , so that the @xmath76-th distribution of @xmath161 corresponds exactly to the random vector @xmath163 for each @xmath76 .",
    "assume further that the induced joint input - output process @xmath164 satisfies the shannon - mcmillan - breiman ( smb ) theorem ( see appendix  [ sec : smb ] ) , then the sample entropies for @xmath164 converge almost surely to their respective entropy rates .",
    "accordingly , the normalized information density , which can be written as @xmath165 converges almost surely to the mutual information rate ( a.k.a . _ information rate _ ) @xmath166 where @xmath167 , @xmath168 , and @xmath169 denote the ( joint ) entropy rates of @xmath162 , @xmath170 , and @xmath164 , respectively . as a result",
    ", the liminf in probability of @xmath171 evaluates to the same value @xmath172 , and so the inf - information rate @xmath173 becomes the mutual information rate , which yields , at least theoretically , a computable achievable rate .",
    "alternatively , since aep holds in this case ( see appendix  [ sec : smb ] ) , we can use the idea of typical set decoding as in @xcite to directly prove the achievability of the rate @xmath172 .",
    "the shannon - mcmillan - breiman theorem demands certain stationarity and ergodicity properties of the joint input - output process , which in turn require the source and channel to satisfy some conditions in that aspect .",
    "specifically , the version of smb theorem ( theorem  [ thm : smb ] ) suitable for our models requires the joint process @xmath164 to be _ _",
    "asymptotically mean stationary _ _ ( ams ) and ergodic .",
    "when the surrogate channel @xmath154 is an fsc , it belongs to the category of _ markov channels _ and always produces an ams joint input - state - output process for any ams or stationary source .",
    "for such a channel @xmath154 , if ( i ) the source @xmath162 is stationary and ergodic while @xmath154 satisfies some further ergodicity conditions with respect to the source , or ( ii ) the source @xmath162 is finite - order markov and induces a joint source - channel markov chain with some irreducibility condition , then the joint input - state - output process is ams and ergodic , and so is the process @xmath164 . ] .",
    "the descriptions of the specific conditions for each model are given in the next three subsections .",
    "due to the technical nature , however , the exposition of the underlying stationarity and ergodicity theory is deferred to the appendices .",
    "such a theory is largely based on the theory of markov channels developed in @xcite and the ergodic theory of stationary markov chains in @xcite .    in practice ,",
    "the computation of the mutual information rate @xmath172 for general source processes @xmath162 is a challenging problem .",
    "one can use the sequence of finite block length mutual information to approximate @xmath172 , but since the alphabet sizes grow exponentially with the block length , so does the computational complexity .",
    "moreover , the convergence of such a sequence is often rather slow . with the above stationarity and ergodicity conditions for the source and channel",
    ", however , we have the smb theorem and so can estimate the information rate using the sample entropies ( through ) of a very long sample sequence , which can be computed using the transition probabilities in and the input distribution .",
    "in addition to that , when the source is a finite - order markov process and the channel is an fsc , the computation of the sample entropies in has a complexity linear in @xmath76 ; in fact one can use the well - known bcjr algorithm@xcite ( a.k.a .",
    "the sum - product algorithm@xcite ) to compute them .",
    "this stochastic method for information rate computation was proposed independently in @xcite , and is summarized in @xcite .",
    "so far by restricting the input alphabet and imposing extra stationarity and ergodicity conditions on the source and channel , we are able to resolve the issues 2 ) and 3 ) in section  [ sec : channel - capacity ] and efficiently compute some achievable rates for the channel @xmath14 . if we further fix the order of a markov input process , under some conditions ( described below ) we can maximize the achievable rate over a given set of transition probabilities for the markov chain , thus also resolving the issue 1 ) in section  [ sec : channel - capacity ] to some extent .",
    "specifically , we use the generalized blahut - arimoto algorithm ( gbaa ) for the achievable rate optimization , which is proposed by vontobel  et al . in @xcite . in their work ,",
    "the traditional blahut - arimoto algorithm@xcite , originally used for computing the capacity of a dmc , is generalized in the setting of an indecomposable fsc with a finite - order markov input process , whose underlying chain is stationary , ergodic , and aperiodic , to optimize the information rate over a given set of transition probabilities of the input markov chain .- values is erroneous for some channel models .",
    "however , surprisingly , this issue does not affect the correct calculation of the information rate at each iteration , but it only affects the selection of new optimization parameters for the next iteration .",
    "furthermore , after we communicated with them , the authors corrected the @xmath174-values and fixed this issue . ]",
    "the core part of the gbaa is to estimate the so - called `` @xmath174-values '' defined in ( * ? ? ?",
    "* definition 41 ) through the algorithms in ( * ? ? ?",
    "* lemma 70 ) in each iteration , which are then used both to calculate the information rate and to update the optimization parameters ( i.e. , the transition probabilities ) .",
    "as we examine the derivations and proofs in @xcite , we find that , to the best of our knowledge , the sole purpose of both the indecomposable assumption of the fsc and the ergodicity and aperiodicity of the input markov chain is to guarantee the almost sure convergence of the estimated @xmath174-values in ( * ? ? ?",
    "* lemma  70 ) .",
    "hence we speculate that the required convergence still holds as long as the joint input - state - output process satisfies the smb theorem ; in particular , when the joint process is ams and ergodic .",
    "such a requirement is fulfilled when the source is a stationary finite - order markov process whose underlying chain is irreducible . ] , while the channel is an fsc with the ergodicity conditions mentioned earlier ( which are weaker than indecomposability ) .",
    "consequently , we conjecture that the gbaa still works under these relaxed conditions .",
    "besides , at the very least , we can use the gbaa primarily as a means to find a good set of input process parameters ( i.e. , the markov transition probabilities ) ; the resulting information rates can always be cross - checked using the stochastic methods described above , since the smb theorem applies . therefore ,",
    "when these conditions hold , we can apply the gbaa to our surrogate channel @xmath154 for each fixed markov order of the input process , the states of the underlying chain are the tuples of @xmath175 successive input symbols .",
    "again , the optimization space is a subset of the transition probabilities ( which satisfy the ergodicity conditions ) . ] to find an optimized achievable rate .    in what follows",
    "we apply the above general methodology to each of our three channel models .",
    "first we describe the restriction on the input and show that the surrogate channel @xmath154 is an fsc ( under certain conditions ) , then give the stationarity and ergodicity conditions , with which the computation and optimization of achievable rates are possible .",
    "some numerical examples are given in section  [ sec : numerical ] to illustrate the computation .",
    "we restrict the input function @xmath125 to depend only on the @xmath176 most recent states , where @xmath177 is a fixed integer . to be specific , let @xmath158 be the collection of all functions @xmath178 such that @xmath179 therefore @xmath180 has a constant alphabet size .",
    "we restrict @xmath125 in such a way that each @xmath125 is associated with a symbol @xmath181 and satisfies and @xmath9 , we define the dummy variables @xmath182 as the _ pre - historical states _ , which are deterministic .",
    "these artificial states are only used in the arguments of @xmath183 for @xmath9 , but do not affect the distribution of @xmath110 ( which is determined by the environment / nature ) .",
    "see @xcite for a more detailed discussion . ]",
    "@xmath184 with such a configuration we define a surrogate channel @xmath154 with the input alphabet @xmath158 , whose transition probability is defined through the corresponding @xmath117 for each @xmath76 .",
    "in other words , according to , @xmath185 @xmath186    we claim that the channel @xmath154 is an fsc for @xmath187 , whose state is defined as @xmath188 with alphabet @xmath189 .",
    "in fact , for @xmath187 , the transition probability satisfies the following : if @xmath190 is compatible with @xmath191 , i.e. , for some @xmath192 , @xmath193 while @xmath194 , then by the fsc transition probability , @xmath195 if @xmath190 is not compatible with @xmath191 , then both the first and the last term are 0 and still holds .    for the required stationarity and ergodicity properties for the smb theorem , we provide the following two sets of simple conditions .",
    "we also have some stronger but more complicated conditions , see corollary  [ cor : gray - dunham - gobbi - thm-2-extension - cor - markov ] and lemma  [ lem : fsc - markov - input ] in the appendices .",
    "assume the input process @xmath162 of the surrogate channel @xmath154 for fsc - x is stationary and ergodic .",
    "then the joint process @xmath164 is ams and ergodic , if any of the following holds .    1",
    ".   @xmath154 is indecomposable .",
    "2 .   there is a finite vector @xmath196 with @xmath197 satisfying the following property : given @xmath198 , for any @xmath199 , there exists @xmath200 and @xmath201 such that when @xmath202 or @xmath203 , we both have @xmath204 with positive probability .",
    "the first condition follows from lemma  [ lem : gray - dunham - gobbi - cor-2 ] and theorem  [ thm : gray - dunham - gobbi - thm-2-extension ] ( or corollary  [ cor : gray - dunham - gobbi - thm-2-extension - cor - markov ] ) , and the second follows from corollary  [ cor : gray - dunham - gobbi - thm-2-extension - cor - fsc ] .",
    "assume the input process @xmath162 of the surrogate channel @xmath154 for fsc - x is finite - order markov , then so is the joint process @xmath205 .",
    "if the underlying markov chain for the latter is irreducible , then @xmath164 is ams and ergodic .",
    "this lemma is a simple case of lemma  [ lem : fsc - markov - input ] .",
    "again we restrict the input function @xmath125 to depend only on the @xmath177 most recent ( energy ) states , and supply the dummy pre - historical states @xmath182 when @xmath206",
    ". then the surrogate channel @xmath154 has the same input alphabet as in the previous section , with @xmath113 defined in . according to the transition probabilities",
    "are are given by the dummy variables . ] @xmath207    if the energy harvesting process @xmath25 is i.i.d .",
    ", then , as shown in section  [ sec : sys - model ] , the channel eh - sc1 is an instance of fsc - x , and by the previous section @xmath154 is an fsc with state variable @xmath208 .",
    "note in passing that since the argument @xmath209 for @xmath183 is contained in @xmath190 , by and we have @xmath210 more generally , if @xmath25 is markov of order @xmath211 , the surrogate channel is still an fsc for @xmath212 , with the states @xmath213 whose alphabet is @xmath214 . in fact , for @xmath212 , the transition probability satisfies the following : if @xmath190 is compatible with @xmath191 , i.e. , for some @xmath215 and @xmath192 , @xmath216 while @xmath217 , then @xmath218 by the structure of the channel .",
    "if @xmath190 is not compatible with @xmath191 , then both the first and the last term are 0 .",
    "again note that the argument @xmath209 for @xmath183 is contained in @xmath190 , and so holds .",
    "observe that at time @xmath22 , the energy state @xmath30 contains all the information about the energy constraint on the current immediate input symbol @xmath0 , which is the only influence the full history of energy information has on the transmission .",
    "we conjecture that for the equivalent channel @xmath14 , it is enough to only consider input functions @xmath125 that depends only on the current energy state @xmath219 , as stated below formally .",
    "this form of optimal input function is conjectured for both channels eh - sc1 and eh - sc2 , but we are not able to prove it yet .",
    "setting @xmath220 in the surrogate channel @xmath154 yields a capacity @xmath221 .",
    "next we give the stationarity and ergodicity conditions .",
    "since is true , by appendix  [ sec : joint - marginal ] we can just consider a smaller fsc whose transition probability is @xmath222 .",
    "as before , we also have the following two set of simple conditions , as well as some stronger but more complicated ones  see corollaries  [ cor : gray - dunham - gobbi - thm-2-extension - cor - markov ] and  [ cor : fsc - separable - markov - input ] in the appendices .    [",
    "lem : eh - sc1-erg - conds1 ] assume the input process @xmath162 of the surrogate channel @xmath154 for eh - sc1 is stationary and ergodic .",
    "then the joint process @xmath164 is ams and ergodic , if any of the following holds .    1",
    ".   @xmath154 is indecomposable .",
    "there is a finite vector @xmath196 with @xmath197 satisfying the following property : given @xmath198 , for any @xmath199 , there exists @xmath201 such that when @xmath202 or @xmath203 , we both have @xmath223 with positive probability .",
    "assume the input process @xmath162 of the surrogate channel @xmath154 for eh - sc1 is finite - order markov , then so is the joint process @xmath224 .",
    "if the underlying markov chain for the latter is irreducible , then @xmath164 is ams and ergodic .",
    "this lemma is a simple case of corollary  [ cor : fsc - separable - markov - input ] .",
    "when we know more properties of the energy harvesting channel , we have more concrete conditions .",
    "two such example theorems are :    [ thm : erg - conds - markov ] for the fsc @xmath154 above , assume there exists @xmath225 such that the order-@xmath226 markov chain @xmath25 satisfies @xmath227 for all @xmath228 . if , in addition , one of the following is satisfied , then @xmath154 is indecomposable .    1 .",
    "the energy model is and @xmath229 .",
    "2 .   the energy model is or , and @xmath230 .",
    "we prove @xmath154 is indecomposable by showing the strong positive column property in the appendix .",
    "] holds , i.e. , there exist @xmath76 such that for any input sequence , there exist a state @xmath231 that can be reached from any initial state @xmath232 .",
    "now for i ) let @xmath233 .",
    "we can see that @xmath234 with a positive probability conditioned on any @xmath232 , with the corresonding @xmath235 .",
    "hence the state @xmath236 can always reached for any initial state and any input sequence . for ii ) , let @xmath237 . if @xmath234 , then starting from @xmath238 , after at most @xmath31 transmission and energy replenishment cycles the battery is full , i.e. , we have @xmath239 for all @xmath240 .",
    "now we can use an argument similar to i ) to prove the result , where for energy model set @xmath241 , and for energy model set @xmath236 .",
    "[ thm : erg - conds - iid ] for the fsc @xmath154 with @xmath220 , assume @xmath25 is i.i.d .",
    ", the energy model is or , and the distribution of @xmath26 is supported on the full set @xmath55 .    1 .   if there exists @xmath76 such that for each input sequence @xmath242 and any @xmath243 , @xmath244 with a positive probability , then @xmath154 is indecomposable .",
    "if @xmath55 is a continuous interval of non - negative integers and @xmath245 for the energy model , or @xmath246 for the model , then @xmath154 is indecomposable .",
    "3 .   if @xmath162 is stationary and ergodic , and there is @xmath247 with @xmath248 such that for any @xmath243 , either @xmath249 or @xmath244 with positive probability , then @xmath164 is ams and ergodic .",
    "both i ) and iii ) hold if @xmath250 .",
    "note that in this case @xmath251 .",
    "i ) : whenever such @xmath76 exists , the strong positive column condition holds and so @xmath154 is indecomposable .",
    "ii ) : with a positive probability @xmath252 can always be boosted up to @xmath253 for the model , or @xmath31 for the model , hence the strong positive column condition holds .",
    "iii ) : this is a straightforward application of lemma  [ lem : eh - sc1-erg - conds1 ] , condition ii ) .",
    "iv ) : if @xmath250 , then for any @xmath242 and @xmath254 , at most after @xmath255 transmissions , @xmath256 with a probability no smaller than @xmath257^{n}>0}$ ] , in which case @xmath258 .",
    "note that there is some overlap between these two theorems .",
    "the conditions in theorem  [ thm : erg - conds - markov ] and conditions  ii ) and iv ) of theorem  [ thm : erg - conds - iid ] are satisfied if @xmath26 can always reach a relatively high energy level ( compared to @xmath4 or @xmath31 ) with even a very small positive probability , which is not a harsh requirement for many natural energy sources . alternatively ,",
    "if the input process @xmath162 is stationary ergodic , and put a positive probability on a moderately long sequence of `` all zero '' functions ( that is , @xmath259 for all @xmath219 ) , or `` all - consuming '' functions ( that is , @xmath260 for all @xmath219 ) , then condition iii ) of theorem  [ thm : erg - conds - iid ] is satisfied .      as commented in section  [ subsec : three - models ] , eh - sc1 is a scenario with strictly less side information than eh - sc2 .",
    "hence any further restriction on the input alphabet of eh - sc1 also works for eh - sc2 , and hence all results from the previous subsection apply to the second scenario .",
    "in addition , more generally , since now we also have causal knowledge of @xmath25 , we can restrict the input function to ( essentially ) depend only on the @xmath177 most recent energy states and an energy harvesting history of memory length @xmath261 , to obtain a constant alphabet size .",
    "consider such a special input symbol @xmath262 , whose @xmath22-th coordinate function @xmath125 is only a function of @xmath263 and @xmath264 . to be precise , each @xmath125",
    "is associated with an auxiliary function @xmath181 , where @xmath158 is the collection of all functions @xmath265 such that @xmath266 with @xmath113 defined in . the input function @xmath125 is defined through @xmath183 in the following way : for each @xmath130 , it first computes @xmath128 through the recursion , then together with @xmath267 and the previously computed @xmath268 ( which may also includes the dummy pre - historical states when necessary ) , @xmath125 assigns the function value @xmath269 hence the vector @xmath270 uniquely determines the input symbol @xmath117 , and for each @xmath76 there is a one - to - one correspondence between @xmath271 and the collection of all such special input symbols @xmath117 .",
    "such a restriction again gives us a surrogate channel @xmath154 , whose channel transition probability is defined through .",
    "similar to the subsection above , we can show that if @xmath25 is markov of order @xmath11 ( including i.i.d . ) , then @xmath154 is an fsc for @xmath272 , with the states @xmath273 note that for this fsc still holds .",
    "we can derive similar stationarity and ergodicity conditions as in the previous subsection , which is omitted .",
    "also , in this case we have the same optimal input conjecture .    setting @xmath220 and @xmath274 in the surrogate channel @xmath154",
    "yields a capacity @xmath221 .",
    "compared to the lower bounds / achievable rates , nontrivial capacity upper bounds are much more difficult to obtain in the study of energy harvesting channels . for the special case of binary noiseless eh - sc1 , @xcite derives an upper bound , assuming full csi at the receiver ( csir ) .",
    "@xcite tries to tighten this bound , though there appear to be gaps in the mathematical proofs . in this section",
    "we derive capacity bounds for our more general energy harvesting models , as well as the channel fsc - x .",
    "in particular , we obtain upper bounds for the energy harvesting channels when @xmath23 is finite - order markov is i.i.d .",
    ", a proof idea for the same bounds also appears in @xcite . ] .",
    "these results are motivated by gallager s study of finite state channels@xcite , where as mentioned in the previous section , two convergent sequences in the form of maximized finite block length mutual information are shown to give series of upper and lower bounds of the channel capacity , respectively .",
    "we begin our study by describing a general upper - bounding approach , which is based on techniques of verd and han , and gallager .",
    "then we use this approach to derive the upper bounds for fsc - x , which also includes eh - sc1 as a special case , when the energy harvesting process is i.i.d .",
    "( as shown in section  [ subsec : three - models ] ) . after that we study the lower and upper bounds for eh - sc2 .",
    "note that all the bounds in this section are in the form of maximized block mutual information on the equivalent channels .",
    "theoretically , these bounds are computable for each block length @xmath76 ; however , as @xmath76 grows the computation memory ( and also time ) increases rapidly , since the input alphabet size has a double - exponential growth rate .",
    "this complexity issue is addressed for the upper bounds in the next section .",
    "let @xmath275 be a general channel without feedback , with input / output alphabets @xmath276 , @xmath277 and transition probabilities @xmath278 for each block length @xmath76 .",
    "using fano s inequality verd and han @xcite showed that its capacity is upper bounded by @xmath279 in general , the upper bound is not easy to compute , since the limiting behavior of @xmath280 is unknown .",
    "on the other hand , gallager @xcite uses the following lemma to derive a series of computable upper bounds for finite state channels :    [ lem : fekete ] if the sequence @xmath281 is subadditive , i.e. , @xmath282 for all @xmath176 and @xmath22 , then the limit @xmath283 exists and is equal to @xmath284 .",
    "similarly , if the sequence is superadditive , then @xmath285 .",
    "if we can show that for each @xmath76 , there is a @xmath286 such that    1 .",
    "@xmath287 , 2 .",
    "@xmath288 is subadditive ,    then by fekete s lemma , @xmath289 exists and is equal to @xmath290 . hence is upper bounded by @xmath291 , and so @xmath286 is an upper bound for the general channel capacity for each finite @xmath76 .",
    "in other words , the limiting process in is not needed anymore , which greatly simplifies the computation of upper bounds , especially when such computable @xmath286 s can be easily found .",
    "we apply the technique above to the equivalent channel ( see definition  [ def : equiv - fsc - x ] ) to derive a series of gallager - type upper bounds for fsc - x , which by proposition  [ proposition : eh - sc1-fsc - x ] also includes the channel eh - sc1 when the energy harvesting process is i.i.d .. to begin with , the capacity can be upper bounded by a system with full csir , and so in we consider the mutual information @xmath292 . as @xmath110 is independent of @xmath111 , @xmath293 where @xmath294 .",
    "define @xmath295 then @xmath286 satisfies ( r1 ) in the previous subsection .",
    "furthermore , we have the following theorem :    [ thm : ub - fsc - x ] for each @xmath76 , @xmath286 defined in is an upper bound for the capacity of the channel fsc - x .    as described above , we can use for the full csir case as an upper bound . since @xmath286 satisfies ( r1 ) for this upper bound , if we can show it satisfies ( r2 ) as well , then @xmath286 is an upper bound for each @xmath76 by the argument above .",
    "let @xmath76 be arbitrary and let @xmath296 be positive integers that sum to @xmath76 .",
    "in the following we will show that @xmath297 i.e. , @xmath288 is subadditive . for any @xmath298 and @xmath254 consider the decomposition    r / c / l i(u^n;y^ns_2^n+1s_1 )",
    "& = & i(u^n;y^ns_2^n+1s_1 ) + i(u^n;y_n+1^ns_n+2^n+1y^ns_2^n+1s_1 ) + & = & i(u^n;y^ns_2^n+1s_1 ) + i(u_n+1^n;y^ns_2^n+1u^ns_1 ) + & & + i(u_n+1^n;y_n+1^ns_n+2^n+1y^ns_2^n+1s_1 ) + & & + i(u^n;y_n+1^ns_n+2^n+1u_n+1^ny^ns_2^n+1s_1 ) + & = & i_1 + i_2 + i_3 + i_4 , [ eq : i - decomp - fsc ]    where @xmath299@xmath300 are respectively defined as the first to fourth terms in the line above them . by the definition , @xmath301 .",
    "next , using the property of fsc conditional probabilities as in , for @xmath302 and @xmath300 we respectively have @xmath303 @xmath304 therefore @xmath305 .",
    "furthermore , @xmath306    fix @xmath307 . for each @xmath308 and @xmath309 ,",
    "define @xmath310 to be the projection @xmath311 , i.e. , @xmath312 then @xmath313 , @xmath314 and so @xmath315 . by again @xmath316 where @xmath317 is the @xmath176-block channel transition probability given @xmath110 .",
    "denote the projection map @xmath318 , which depends on @xmath119 .",
    "then @xmath174 and @xmath319 induce a probability distribution @xmath320 on @xmath321 : for all @xmath322 , @xmath323 now it is easy to verify that @xmath324 where @xmath325 is the @xmath176-block channel output distribution given @xmath326 , induced by @xmath320 and the channel @xmath327 . thus if we denote the relative entropy @xmath328 then @xmath329 .",
    "therefore we can write @xmath330 where @xmath331 denotes the mutual information induced by the input distribution @xmath320 . since this inequality holds for all @xmath307 ,",
    "by we have @xmath332 .    combining the results for @xmath333@xmath300 with , we have @xmath334 this inequality is true for all @xmath298 and @xmath254 , so it must be true for the maximization over them , and thus holds .",
    "[ rem : ub - fsc - x ] note that since the order of maximization in can be exchanged , @xmath286 can be calculated by finding the capacities of @xmath335 discrete memoryless channels ( dmc ) , which can be efficiently computed using the blahut - arimoto algorithms ( see , e.g. , @xcite ) .      for this channel",
    "we also use the equivalent channel model ( definition  [ def : equiv - eh - sc2 ] ) to derive series of capacity bounds , including a new type of lower bounds and the gallager - type upper bounds .",
    "note that the energy harvesting process and the initial battery level are independent , and are both independent of the input in the equivalent channel .",
    "let us define a notation @xmath336 for @xmath11 .",
    "we have @xmath337    we first develop some preliminary results on the input alphabet and block conditional mutual information . recall that @xmath101 is the collection of all causal mappings @xmath338 that are consistent with the energy constraint .",
    "let @xmath339 denote all causal mappings @xmath340 , and define @xmath341 as the `` @xmath115-th section of @xmath101 '' , which consists of all mappings in @xmath339 that together with @xmath342 satisfy the energy constraint , i.e. , @xmath343 let @xmath344 .",
    "for each @xmath116 , @xmath73 satisfies with @xmath345 whenever it does with @xmath115 , so @xmath346 .",
    "in particular , @xmath347    now fix @xmath115 .",
    "define the projection map @xmath348 with @xmath349 , and denote @xmath350 .",
    "then the image of @xmath174 is in @xmath351 .",
    "furthermore , for @xmath352 and @xmath11 we define @xmath353 and @xmath354 through @xmath355 and @xmath32 .",
    "then by we have @xmath356 by the same argument as in the proof of theorem  [ thm : ub - fsc - x ] , @xmath357 where the distribution of @xmath358 is supported on @xmath351 .",
    "[ lem : i - u - v - max ] let @xmath359 denote the family of all probability distributions on @xmath351 .",
    "we have @xmath360    we only prove the second equation since the proof of the first is essentially the same .",
    "denote the lhs and rhs by @xmath361 and @xmath362 , respectively . for any @xmath298",
    ", we have @xmath363 and so @xmath364 by .",
    "hence @xmath365 . on the other hand , for every @xmath366 we have @xmath367 .",
    "thus for any @xmath368 , define a @xmath298 such that @xmath369 for all @xmath366 , then @xmath370 is induced by @xmath298 and @xmath174",
    ". then by again , @xmath371 and so @xmath372 .",
    "we are now ready to present the capacity bounds .",
    "[ thm : lb - eh ] for the channel eh - sc2 , if @xmath23 is i.i.d .",
    ", then for each @xmath76 @xmath373 is a capacity lower bound .",
    "moreover , @xmath374 .",
    "consider using the channel in blocks of length @xmath76 and restrict the input functions to those that i ) ignore the initially stored energy in the battery , and ii ) essentially comprise concatenations of functions in @xmath375 .",
    "that is , for @xmath376 the input @xmath377 is only a function of @xmath378 and can be identified with the collection @xmath379 , where for any @xmath115 and @xmath378 , @xmath380 it is a legitimate input symbol since between the transition of blocks the function ignores the remaining battery energy , thus is always compatible with the energy constraint .",
    "let @xmath381 , @xmath382 and @xmath12 denote @xmath383 , @xmath384 and @xmath385 , respectively . by and the i.i.d .",
    "assumption for @xmath25 , @xmath386 hence if we define the transition probability @xmath387 , then @xmath388 since @xmath25 is i.i.d . and",
    "@xmath389 is obtained from the dmc @xmath32 , @xmath390 is the same for each @xmath391 and hence is denoted by @xmath327 .",
    "thus @xmath392 times of using the original channel in the specified manner is equivalent to @xmath175 times of using a dmc @xmath393 with input alphabet @xmath375 , whose capacity is @xmath394 by lemma  [ lem : i - u - v - max ] and considering the block length @xmath76 , @xmath395 is achievable .",
    "finally we use lemma  [ lem : fekete ] to prove @xmath374 .",
    "it suffices to show that @xmath396 is superadditive .",
    "fix @xmath76 and let @xmath397 with @xmath398 . as @xmath399 can be written as , let @xmath400 and @xmath401 be the distributions that achieve the maximum of for block lengths @xmath176 and @xmath22 , respectively . for block length @xmath76 consider the subset @xmath402 of @xmath375 that comprises all concatenations of functions in @xmath403 and @xmath404 .",
    "specifically , each input function @xmath247 in @xmath402 can be represented by a pair @xmath405 such that @xmath406 for any @xmath116 , and for each such pair there is a corresponding function @xmath407 .",
    "then similar to the argument above , with we can show that @xmath408 define a distribution @xmath409 that satisfies @xmath410 for all @xmath407 , and @xmath411 for @xmath412 , then @xmath413 since in the equation above , @xmath414 while @xmath415 , superadditivity holds .    as mentioned at the end of section  [ sec : channel - capacity ] , theorem  [ thm : lb - eh ] can serve as a simple achievability proof for the multi - letter mutual information capacity formula ( 18 ) in @xcite .",
    "in fact , from above we know @xmath416 is achievable for any initial battery distribution . using verd and han s method ( see the beginning part of section  [ subsec : ub - gallager - type ] , or @xcite ) , one can show that @xmath417 is also a capacity upper bound when the initial battery @xmath418 .",
    "thus the channel capacity for the case @xmath419 is @xmath420 the result for arbitrary @xmath52 follows from ( * ? ? ?",
    "* proposition  1 ) .",
    "[ thm : ub - eh ] if @xmath23 is a homogeneous markov chain of order @xmath11 , then for each @xmath76 @xmath421 is an upper bound of the channel capacity for eh - sc2 .",
    "we use the same upper bounding technique as in the fsc - x / eh - sc1 case and the proof parallels that of theorem  [ thm : ub - fsc - x ] . by providing full csir to the receiver , in we consider @xmath422 due to the independence between @xmath423 and @xmath111 .",
    "now define @xmath424 we will show that it is equivalent to the definition in the theorem . for each @xmath425 , by lemma  [ lem : i - u - v - max ] , and the independence between @xmath25 and the input symbols , @xmath426 with the equality attained when @xmath427 . now , taking the maximum of both sides over @xmath428 and exchanging the order of maximization , we see the equivalence of both definitions .    from the analysis above @xmath286 satisfies ( r1 ) in section  [ subsec : ub - gallager - type ] .",
    "next we will show the subadditivity and then the theorem is proved .",
    "let @xmath76 be arbitrary and let @xmath296 be positive integers that sum to @xmath76 .",
    "we have the decomposition    r / c / l i(u^n;y^ne^n|b_1e^-r ) & = & i(u^n;y^ne^n|b_1e^-r ) + i(u_n+1^n;y^ne^n|u^nb_1e^-r ) + & & + i(u_n+1^n;y_n+1^ne_n+1^n|y^ne^nb_1e^-r ) + & & + i(u^n;y_n+1^ne_n+1^n|u_n+1^ny^ne^nb_1e^-r ) + & = & i_1 + i_2 + i_3 + i_4 , [ eq : i - decomp - eh ]    where @xmath299@xmath300 are respectively defined as the first to fourth terms above . by the definition , @xmath301 . next using",
    "we can show that @xmath305 .",
    "furthermore , @xmath429    fix @xmath430 . for each",
    "@xmath308 define the projection map @xmath431 since @xmath308 is extracted from a legal input function @xmath143 , for any @xmath432 the output @xmath433 needs to satisfy with the intermediate battery level @xmath434 , which is determined by @xmath435 and @xmath436 . hence @xmath437 by . now by @xmath438 where we used the markov property of @xmath26 and @xmath439 is defined by .",
    "again similar to theorem  [ thm : ub - fsc - x ] , for an induced distribution @xmath320 on @xmath440 @xmath441 where we used lemma  [ lem : i - u - v - max ] .",
    "since this inequality holds for all @xmath430 , by we have @xmath442 .    combining the results for @xmath333@xmath300 with",
    ", we have @xmath443 for arbitrary @xmath298 and @xmath425 , thus holds .",
    "as stated in remark  [ rem : ub - fsc - x ] , @xmath286 can be computed by finding the capacities of a finite number of dmc s .",
    "in the equivalent channel models , the input alphabet size for each channel use grows double exponentially , and so does the ( spatial ) computational complexity of the bounds in the previous section . to address this problem , in this section we rewrite the upper bounds in the form of maximized directed information on the original channels , which has a constant input alphabet size and the complexity becomes exponential .",
    "it turns out that for the case of fsc - x / eh - sc1 , this new formulation also allows for a nice dynamic programming recursion , which only has a linear complexity . for eh - sc2",
    ", we need to loosen the upper bounds a bit to obtain a similar recursion .",
    "if we relax these bounds even further , the recursions can be solved analytically .",
    "although such relaxed upper bounds are looser than the original ones for each block length @xmath76 , since we can compute them for very large @xmath76 , the results are sometimes tighter ( as verified by the numerical results in next section ) .",
    "first we introduce some notations .",
    "the directed information between @xmath444 and @xmath445 is defined as @xmath446 the directed information @xmath447 conditioned on a initial state @xmath243 is defined similarly . for the channel fsc - x , a collection of conditional input distributions @xmath448",
    "is called _ legal _ if it puts zero probability on @xmath449 , @xmath81 .",
    "fix @xmath254 and consider the mutual information @xmath450 in the context of feedback channel @xcite , where @xmath111 is the code function . at each time",
    "@xmath22 the output is @xmath451 and the feedback is @xmath30 . then similar to lemmas  5.1 , 5.2 , and 5.4 of @xcite , we can show the following for fsc - x .    1 .",
    "any input function distribution @xmath298 on @xmath101 induces a collection of legal conditional input distributions @xmath448 .",
    "( we say @xmath298 and @xmath448 are compatible in this case . )",
    "conversely , if the collection @xmath448 is legal , one can construct a distribution on @xmath101 that is compatible with it .",
    "we have the relation @xmath452 where the directed information is determined by the induced collection @xmath448 .    as a result we can rewrite the upper bound in theorem  [ thm : ub - fsc - x ] as @xmath453 where `` l.g .",
    "'' stands for `` legal '' .",
    "next we show that this expression can be simplified further to allow for a dynamical programming recursion similar to @xcite .",
    "let us start with a few more notations .",
    "for each @xmath454 define @xmath455 to be the set of all probability distributions on @xmath113 and @xmath456 .",
    "we say the conditional distribution @xmath457 iff @xmath458 for all @xmath454 .",
    "let @xmath459 , we write @xmath460 if @xmath461 for all @xmath81 .",
    "for a fixed @xmath462 , we can write @xmath463 observe that every legal collection @xmath448 together with @xmath464 determines a random tuple @xmath465 , which further induces a set of conditional probabilities @xmath460 .",
    "following the argument for eq .",
    "( 117 ) in @xcite we have @xmath466 on the other hand , by setting @xmath467 we see that @xmath460 indeed belongs to the family of legal conditional input distributions . thus by the argument for eq .",
    "( 120 ) in @xcite , in fact the above inequality holds with equality .    summarizing the discussion above we have the following theorem .",
    "is actually the capacity in this case .",
    "however , @xcite only deals with fsc s without input constraints",
    ". given that the results therein are built up gradually through a series of sophisticated theorems and lemmas , they should be re - proved ( if this is indeed possible ) for the case with input constraints before being applied to eh - sc1 . ]",
    "[ thm : fsc - linub ] for each @xmath76 , the fsc - x capacity upper bound in theorem  [ thm : ub - fsc - x ] can be written as @xmath468    the terms @xmath469 can be calculated using a dynamic programming recursion similar to @xcite . to see that denote @xmath470 and thus @xmath471",
    "moreover , for any conditional distribution @xmath472 define @xmath473    [ thm : fsc - linub - recursion ] let @xmath110 have an arbitrary distribution @xmath474 , define @xmath475 then @xmath476 where for each @xmath477 @xmath478,\\ ] ] with the initial condition @xmath479 , @xmath71 .    from the definitions , @xmath480 where @xmath481 puts probability 1 on @xmath477 . for @xmath482 ,",
    "the theorem is true ( note that the optimization for @xmath483 is over @xmath484 , which can be separated ) . assume it is true for @xmath485 , then for @xmath486 , @xmath487.\\ ] ] given @xmath474 and @xmath488 , @xmath489 now define @xmath490 and so @xmath491 using the theorem for @xmath485 , we have @xmath492 as the value of @xmath493 is uniquely determined by @xmath494 , @xmath495 and the time - invariant transition probabilities @xmath496",
    ". thus @xmath497 \\\\ & = \\max_{p_{1}\\in{\\mathcal{p}^{*}}}{\\left } [ \\sum_{s}\\pi(s)i(p_{1},s ) + \\sum_{s}\\pi(s)\\sum_{x}p_{1}(x|s)\\sum_{t}q(t|xs)\\cdot{\\tilde{c}}_{k , t } { \\right } ] \\\\ & = \\sum_{s}\\pi(s)\\!\\!\\max_{p_{1}(\\cdot|s)\\in{\\mathcal{p}^{*}}_{s}}{\\left } [ i(p_{1},s ) + \\sum_{x}p_{1}(x|s)\\sum_{t}q(t|xs)\\cdot{\\tilde{c}}_{k , t } { \\right}].\\end{aligned}\\ ] ] letting @xmath498 for each @xmath477 we obtain the statement for @xmath499 , which can be plugged back into the expression above to obtain the result for @xmath500 .",
    "so the theorem is true for @xmath486 and hence true for all @xmath76 .",
    "note that for every recursion we only need to maximize the sum of a concave function @xmath501 and a linear term over the same space @xmath455 , which is simple to compute using convex optimization .",
    "also note that the alphabet size is constant and the computational complexity is linear .",
    "the recursion can even be solved analytically if we relax @xmath286 further .",
    "using the inequality @xmath502 we can replace the mutual information in the expressions of @xmath503 and @xmath504 in theorems  [ thm : fsc - linub ] and [ thm : fsc - linub - recursion ] by the corresponding conditional entropies to define @xmath505 and @xmath506 and obtain a corresponding new theorem :    [ thm : fsc - linub - analytical ] assume the base of @xmath507 is @xmath508 .",
    "we have @xmath509 , @xmath510 and @xmath511,\\ ] ] with the initial condition @xmath512 , @xmath71 .    by , @xmath509 .",
    "using arguments similar to theorem  [ thm : fsc - linub - recursion ] and defining @xmath513 we have @xmath514 with @xmath515.\\ ] ] denote @xmath516 and @xmath517 .",
    "the optimization problem above can be written as @xmath518 whose solution @xmath519 can be easily found using kkt conditions : @xmath520 plugging into the objective function , we obtain the desired formula for @xmath521 .",
    "[ rmk : fsc - i - h - exact ] when @xmath0 is uniquely determined by @xmath1 ( e.g. , @xmath522 ) , holds with equality and so @xmath523 .",
    "first let us rewrite the upper bounds in theorem  [ thm : ub - eh ] in the form of maximized directed information . from the proof of theorem  [ thm : ub - eh ]",
    ", the upper bound can be expressed as @xmath524 since @xmath525 is independent of @xmath163 given @xmath526 , also @xmath527 is independent of @xmath163 and @xmath445 given @xmath114 and @xmath526 , we know that @xmath528 and @xmath529 are both 0 .",
    "thus @xmath530 now in the context of feedback channel in @xcite , consider @xmath163 as the code function , @xmath531 as the channel output and @xmath26 as the feedback at each time @xmath22 .",
    "define a collection of conditional input distributions @xmath532 to be _ legal _ if for @xmath81 , the conditional probability is zero whenever @xmath533 does not satisfy the energy constraint with @xmath120 and @xmath534 . then similar to lemmas  5.1 , 5.2 , and 5.4 of @xcite and the previous subsection",
    ", we can show :    1 .   any input function distribution @xmath535 induces a collection of legal conditional input distributions @xmath532 ( almost everywhere ) , in which case we say they are compatible .",
    "conversely , if the collection @xmath532 is legal , one can construct a distribution on @xmath536 that is compatible with it .",
    "we have the relation @xmath537 where the directed information is determined by the induced collection @xmath532 .",
    "[ thm : eh - fb - ub ] for each @xmath76 , the capacity upper bound in thereom  [ thm : ub - eh ] can be rewritten as @xmath538    an extended blahut - arimoto algorithm is proposed in @xcite to maximize the directed information for feedback channels .",
    "this algorithm can be adapted to compute the inner maximization of the directed information in .",
    "in fact , by ( * ? ? ? * lemma  1 ) , the causal conditioning distributions form a polyhedron in @xmath539 . adding energy constraints ( i.e. , requiring the conditional distributions to be legal ) forces some coordinates to be zero , which imposes some extra linear equalities on this set . therefore ,",
    "the resulting collection of distributions still form a polyhedron , which is convex . thus ( * ? ? ?",
    "* lemma  1 ) guarantees that the corresponding alternating maximization procedure converges to the global maximum .",
    "furthermore , examining the algorithm in @xcite we see that if we start with a conditional distribution that satisfies the energy constraint , then every iteration returns a legal collection of conditional distributions .",
    "hence indeed this algorithm can be used to compute @xmath286 , and the ( spatial ) computational complexity is exponential in @xmath76 .",
    "next we want to relax the upper bounds @xmath286 to obtain a dynamic programming recursion similar to the case fsc - x / eh - sc1 .",
    "recall that the energy harvesting process @xmath23 is a homogeneous markov chain of order @xmath11 .",
    "define the `` overall '' state @xmath540 with alphabet @xmath541 . when @xmath542 , @xmath26 is i.i.d . and @xmath251 , whose transition probability @xmath543 can be obtained through .",
    "now assume @xmath544 .",
    "for each @xmath545 , if @xmath546 for some @xmath547 , then @xmath548 otherwise @xmath549 . note that these transition probabilities are independent of @xmath22 .",
    "furthermore , let @xmath550 denote the distribution of @xmath551 when @xmath552 and @xmath526 , which is determined by @xmath553",
    ".    we relax @xmath286 by providing more energy information to the receiver in . for fixed @xmath554 and @xmath526",
    ", we know @xmath555 is conditionally independent of @xmath163 and so @xmath556 now in the setting of feedback channel view @xmath557 as the channel output and @xmath26 as the feedback . then similar to 2 ) above we can show @xmath558 where @xmath559 .",
    "since given @xmath560 , @xmath561 is independent of all other previous random variables , we have @xmath562 @xmath563 and as a result of these ( in)equalies @xmath564    for @xmath565 define @xmath566 to be the @xmath57-component of @xmath567 , and let @xmath568 similar to the previous subsection , we define @xmath569 , and @xmath327 w.r.t .",
    "the state @xmath570 , and write @xmath571 moreover , for an arbitrary distribution @xmath474 on @xmath572 , define @xmath573 observe that when @xmath554 and @xmath526 are fixed , for any @xmath370 , @xmath574 induces a random tuple @xmath575 .",
    "it further induces a set of conditional probabilities @xmath460 , which together with @xmath576 and @xmath577 uniquely determines the rhs of ( cf .",
    "thus for any @xmath535 we have @xmath578 and so with we can establish the following theorems .",
    "[ thm : eh - linub ] assume @xmath23 is markov of order @xmath11 .",
    "then for each @xmath76 , @xmath579 is an upper bound for the channel capacity of eh - sc2 .",
    "[ thm : eh - linub - recursion ] define @xmath580 for all @xmath565 .",
    "then @xmath581 and @xmath582,\\ ] ] with the initial condition @xmath583 , @xmath584 .",
    "since @xmath585 is independent of @xmath0 given @xmath570 , we can rewrite the expression @xmath586 with @xmath587 to further simplify the computation .",
    "also , since @xmath588 we can replace the mutual information in the definitions of @xmath589 and @xmath504 by the corresponding conditional entropies to define @xmath590 and @xmath506 and obtain :    [ thm : eh - linub - analytical ] assume the base of @xmath507 is @xmath508 .",
    "we have @xmath591 , @xmath592 and @xmath593,\\ ] ] with the initial condition @xmath594 , @xmath584 .",
    "the proofs for theorems  [ thm : eh - linub - recursion ] and  [ thm : eh - linub - analytical ] are similar to theorems  [ thm : fsc - linub - recursion ] and [ thm : fsc - linub - analytical ] , respectively , and hence are omitted .",
    "[ rmk : eh - i - h - exact ] when @xmath0 is uniquely determined by @xmath1 ( e.g. , @xmath522 ) , we have @xmath595 .",
    "we illustrate the computation and optimization of the achievable rates in section  [ sec : ach - rates ] with the following energy harvesting example .",
    "let @xmath25 be an i.i.d .",
    "bernoulli(0.5 ) process with @xmath596 , and assume the battery limit @xmath597 .",
    "the energy model satisfies and , i.e. , the harvested energy is immediately available and the energy cost is quadratic . since @xmath597 , the energy states take value in @xmath598 .",
    "the dmc in the model is bsc(@xmath599 ) , i.e. , the binary symmetric channel with crossover probability @xmath599 .",
    "the energy information scenario can be either eh - sc1 or eh - sc2 , but we only use results for the former to compute achievable rates ( which work in both cases ) .",
    "let @xmath220 in section  [ subsec : ach - rate - eh - sc1 ] , then case  ii ) of theorem  [ thm : erg - conds - iid ] is satisfied and so @xmath154 is indecomposable .",
    "furthermore , the input alphabet of the surrogate channel is @xmath600 with @xmath601 where we use vectors in @xmath602 to represent functions .",
    "the channel state transition probability is given by @xmath603 , where @xmath604 for @xmath605 and @xmath606 for @xmath607 , and @xmath608 for the surrogate channel @xmath154 we compute the i.u.d .",
    "rate , which is the information rate for the i.i.d .",
    "uniform input process , and optimize the information rate over markov input processes of order 0 ( which is i.i.d . ) , 1 and 2 . the results of these computations are shown in fig .",
    "[ fig : rates ] . for comparison , in the same figure",
    "we also show the capacities for the same bsc without energy constraint , and with zero battery .",
    "the bsc capacity is @xmath609 , which is an upper bound for the case of infinite battery , and this bound is tight when @xmath610 ( using an argument similar to @xcite ) .",
    "the zero battery capacity , as commented in section  [ subsec : equiv - ch ] , can be obtained by constructing an equivalent dmc using shannon s method @xcite . the new input alphabet @xmath611 , where @xmath612 and @xmath613 , both of which are functions of @xmath26 .",
    "the transition probability is @xmath614 in particular , @xmath615 and @xmath616 .",
    "the capacity of this dmc is @xmath617 where @xmath618 and @xmath619 .    observing from fig .",
    "[ fig : rates ] , we have the following remarks for this energy harvesting channel :    1 .   compared to the zero battery case , using the minimum non - zero battery ( whose energy storage is just enough to transmit any single symbol ) can obtain a remarkable channel capacity gain ; it even achieves a significant fraction ( around 70% ) of the capacity for the infinite battery case .",
    "2 .   the optimized markov input processes ( including the iid case )",
    "achieve much higher information rates than the i.u.d .",
    "however , while the information rates are higher for higher order markov processes , the increase is quite limited ( even slight in many cases ) . this phenomenon is also observed in the numerical simulation results in @xcite .",
    "the numerical results can provide some guidance in the design of an energy harvesting communication system .",
    "for example , if battery storage is expensive , a small non - zero battery might be desirable ; as it can provide a significant capacity gain over a system with no battery , while investing in a big battery can only yield a limited increase in channel capacity .",
    "furthermore , when designing channel codes for transmission , observation 2 ) may suggest that i.i.d .",
    "random codes ( with an optimized distribution ) could achieve a good data rate .      .",
    "ub - sc1 , ub - lnx , and ub - sc2-ln = upper bounds from theorems  [ thm : fsc - linub ] , [ thm : fsc - linub - analytical]/[thm : eh - linub - analytical ] , and [ thm : eh - linub ] , resp .",
    "( @xmath620 ) ; ub - sc2 = upper bound from theorem  [ thm : eh - fb - ub ] ( @xmath621 ) ; ub@xmath622-sc1 = upper bound from @xcite ; lb - r0 , -r1 = optimized information rates for markov order 0 and 1 , resp . ; lb - sc2 = lower bound from theorem  [ thm : lb - eh ] ( @xmath623 ) . ]    .",
    "the notations are the same as fig .",
    "[ fig : numerical - bounds - q0 ] . ]",
    "we use a slightly different energy harvesting example to demonstrate the computation of the bounds in sections  [ sec : capacity - bounds ] and  [ sec : simplified - upper - bounds ] . in this model @xmath26",
    "bernoulli(@xmath624 ) , @xmath625 , @xmath626 .",
    "the dmc is bsc(@xmath599 ) and we require @xmath26 to be stored in the battery first , i.e. , the energy model satisfies and .",
    "[ fig : numerical - bounds - q0 ] and fig .",
    "[ fig : numerical - bounds - q0dot1 ] show various capacity bounds and achievable rates for @xmath627 and @xmath628 , respectively .",
    "the notations are explained under fig .",
    "[ fig : numerical - bounds - q0 ] .",
    "each bound is prefixed by ub or lb , to denote whether it is an upper or lower bound . in many notations",
    "we also explicitly indicate the scenario from which the corresponding bounds are derived ; but also recall that the lower bounds / achievable rates for eh - sc1 also work for eh - sc2 , and that the upper bounds for the latter are also upper bounds for the former . with that in mind",
    ", we can see that for both @xmath627 and @xmath628 , the true channel capacity for either scenario actually lies in the shaded region , which happens to be the area between the smallest upper bound and the largest lower bound in the respective figures .",
    "the optimized achievable rates lb - r0 , -r1 are calculated in the setting of section  [ subsec : ach - rate - eh - sc1 ] ( i.e. , eh - sc1 ) with @xmath220 , as in the previous subsection ( where they are denoted by ir - r0 , -r1 ) .",
    "the relaxed upper bound from theorem  [ thm : eh - linub ] is denoted by ub - sc2-ln to emphasize its linear complexity .",
    "the notation ub - lnx for the upper bounds from theorem  [ thm : fsc - linub - analytical]/[thm : eh - linub - analytical ] is similarly defined , where x denotes the relaxation from conditional mutual information to conditional entropy of @xmath0 in or . since @xmath26 is i.i.d .",
    ", the overall state @xmath570 in section  [ subsec : eh - fb - linub ] become @xmath30 , and in this example one can show that these two theorems indeed give the same bound .",
    "in addition , ub@xmath622-sc1 ( from @xcite ) is an upper bound for eh - sc1 when @xmath629 , whereas when @xmath630 this result does not apply .    for the linear complexity bounds ub - sc1 , ub - sc2-ln , and ub - lnx",
    ", we can easily compute their values for block length @xmath620 , when the bounds seem to have converged to their respective limits ( cf .",
    "[ fig : numerical - ub - fb - lin - conv ] ) . for the exponential complexity bound ub - sc2 , we are able to compute it up to @xmath621 ; for the double - exponential complexity bound lb - sc2 , however , we are only able to compute it up to @xmath631 .    in the noiseless case fig .",
    "[ fig : numerical - bounds - q0 ] , the four upper bounds ub - sc1 , ub - lnx , ub - sc2-ln and ub@xmath622-sc1 collapse to a single one .",
    "the coincidence of ub - sc1 ( resp .",
    "ub - sc2-ln ) and ub - lnx is guaranteed by remark  [ rmk : fsc - i - h - exact ] ( resp .",
    "remark  [ rmk : eh - i - h - exact ] ) .",
    "the coincidence of ub - sc1 and ub@xmath622-sc1 hints that the best full - csir upper bound in eh - sc1 can be achieved when taking the bound in theorem  [ thm : fsc - linub ] ( or equivalently theorem  [ thm : ub - fsc - x ] ) to its limit / infimum .",
    "furthermore , the coincidence of ub - sc1 and ub - sc2-ln suggests that when supplying the information of @xmath30 to the receiver , the information of @xmath26 is not necessary for the noiseless case . also from fig .",
    "[ fig : numerical - bounds - q0 ] we can observe that ub - sc2 ( considered as an upper bound for eh - sc1 ) appears uniformly looser than ub - sc1 , but it is unclear whether this is still the case when @xmath150 , since we are only able to compute the former up to @xmath632 . for the same reason , although ub - sc2-ln and ub - lnx are both relaxations of ub - sc2 and yield looser bounds for every fixed @xmath76 , the end results in fig .",
    "[ fig : numerical - bounds - q0 ] are indeed tighter when we compute them for a much larger @xmath76 .    , @xmath633 , as a function of block length .",
    "upper plot = ub - sc2 , lower plot = ub - sc2-ln . ]    in the noisy case fig .",
    "[ fig : numerical - bounds - q0dot1 ] , all curves are separated .",
    "the upper bound ub - lnx is the same as the case @xmath629 , which can be seen from the relaxation or .",
    "the bound ub - sc2-ln is looser than ub - sc1 , which suggests that supplying the information of @xmath26 in addition to @xmath30 at the receiver helps identifying the source message in the noisy case .",
    "moreover , the bound ub - sc2 is now tighter than ub - sc1 , despite the fact that the latter is computed at a much larger block length .",
    "this phenomenon may hint that providing @xmath30 to the receiver gives away more information of the source than providing @xmath26 .",
    "furthermore , from fig .  [",
    "fig : numerical - bounds - q0dot1 ] the relaxations ub - lnx and ub - sc2-ln now both appear uniformly looser than the bound ub - sc2 .",
    "however , when @xmath624 is small , the advantage of linear complexity can still yield a tighter bound , as illustrated for the case @xmath633 in fig .",
    "[ fig : numerical - ub - fb - lin - conv ] : we can only compute the exponential - complexity upper bound ub - sc2 up to @xmath621 and the resulting best bound is 0.1432 bit / channel use , whereas ub - sc2-ln gives a much smaller bound 0.0492 at block length @xmath620 .",
    "we study the channel capacity problem of a discrete energy harvesting channel with a finite battery in its full generality . after introducing two energy harvesting channel models and a related finite state channel model ,",
    "we convert them into their respective equivalent channels and express the capacities using verd - han s formula .",
    "then some simplifying restrictions are imposed on the inputs to give a surrogate channel for each equivalent model .",
    "such types of channels allow us to use the shannon - mcmillan - breiman theorem to compute some achievable rates , under the necessary stationarity and ergodicity conditions .",
    "these rates are then optimized using the gbaa algorithm . following that we utilize gallager s technique and verd - han s bounds to arrive at series of capacity upper bounds by providing channel side information to the receiver .",
    "in addition , a lower bound in a similar form is also derived .",
    "the upper bounds are further simplified and relaxed to reduce the computational complexity .",
    "our results can be extended to several directions .",
    "the theory in section  [ sec : ach - rates ] can be generalized to continuous energy harvesting channels , especially when the input alphabet is finite , e.g. , an awgn channel with discrete input .",
    "although the fsc and markov channel results both can only work in the finite alphabet case , we can consider just the state process itself as the output of an markov channel , and then connect a continuous memoryless channel to its output ( cf .",
    "appendix  [ sec : joint - marginal ] ) .",
    "for such a case we can still derive ergodicity results and apply the smb theorem . in addition , we can extend the results for both the achievable rates and capacity bounds to certain discrete energy harvesting channels with channel memory .",
    "for example , if the channel is not dmc , but an fsc , we can easily incorporate the channel state of the fsc in the derivations in both section  [ sec : ach - rates ] and section  [ sec : capacity - bounds ] and obtain corresponding results .",
    "the results in this paper can also provide some guidelines in the design of practical energy harvesting communication systems .",
    "for example , one implication of our numerical results is that it might be a good strategy to invest in a small but nonzero battery if battery storage is costly .",
    "furthermore , if the conjectures in section  [ sec : ach - rates ] are true , namely , the optimal input functions depend only on the current energy state , then designing energy harvesting channel codes can be greatly simplified  we would only need to consider codewords whose input symbols take this special form .",
    "the numerical results further suggest that i.i.d .",
    "random codes with an optimized distribution can have a good performance .",
    "to apply the shannon - mcmillan - breiman theorem in our channel models , we need to derive the required stationarity and ergodicity conditions . for that purpose in the appendices of this paper",
    "we introduce the theory of stationarity and ergodicity for markov channels , mostly established by @xcite ( also see gray s books @xcite ) .",
    "it turns out , however , that some results in gray et  al .",
    "@xcite are inaccurate and/or not properly proved ; thus before making use of them we must fix these issues first .",
    "in addition , besides the existing theory we also want to develop some extended results tailored for our own purposes , especially for the application in the finite state channels arising from energy harvesting systems .",
    "hence in the following sections we first present the necessary background and preliminary results , then state the relevant theory of markov channels from the literature , correct or supplement it if necessary , and in the meantime derive some extended or additional stationarity / ergodicity results of our own . in addition , we study the special case of a finite state channel with a finite - order markov input , and obtain some other ergodicity conditions using results from @xcite for stationary markov chains . following that we present the shannon - mcmillan - breiman theorem in the setting of an ams ergodic process , and then develop some specific results for the models used in this work .    throughout the appendices we follow the notations in @xcite , which uses a convention different from our main text .",
    "the reason is , we want to make the notations consistent with the related literature to facilitate a coherent understanding of the material .",
    "due to space limitation , we omit some long proofs and detailed derivations and refer the interested readers to @xcite .",
    "in this section we gather the most frequently used notations , concepts and preliminary results for the theory , and refer the interested readers to the original works on markov channels @xcite for the rest .",
    "most of the terminology and basic results can also be found in gray s books @xcite .",
    "let @xmath634 be a measurable space and @xmath635 be a measurable mapping on it .",
    "define a probability measure @xmath636 on @xmath634 to be _ _",
    "stationary___. but for conciseness we usually omit this modifying phrase . ]",
    "if @xmath637 for a probability measure @xmath636 on @xmath634 , if @xmath638 exists for all @xmath639 , we say @xmath636 is _ asymptotically mean stationary _ ( ams ) .",
    "the above equation also defines a stationary probability measure on @xmath634 , which is called the _ stationary mean _ of @xmath636 and is usually denoted by @xmath640 .",
    "define an event @xmath641 to be _ invariant _ if @xmath642 .",
    "@xmath636 is _ ergodic _ if @xmath643 is either 0 or 1 for all invariant events @xmath641 .",
    "note that an ams measure is ergodic iff its stationary mean is ( * ? ? ?",
    "* lemma 6.7.1 ) .",
    "we say a dynamical system @xmath644 is stationary , ams , or ergodic if the measure @xmath636 is .",
    "the following lemmas provide some useful results regarding the ams property of a dynamical system ( see ( * ? ? ?",
    "6.26.3 ) ) :    [ lem : pre - ams - iff ] @xmath644 is ams iff there exists a probability measure @xmath640 on @xmath634 which is stationary and which agrees with @xmath636 on each invariant event .",
    "[ lem : pre - ams - if ] @xmath644 is ams if there exists a stationary probability measure @xmath640 on @xmath634 such that for any invariant @xmath639 , @xmath645 whenever @xmath646 .",
    "the dynamical systems we are interested in are sources and source - channel hookups , both of which can be either two - sided or one - sided .",
    "let @xmath647 be a measurable space , on which we want to define the one- and two - sided sequence spaces and sources .",
    "let @xmath648 denote the measurable space of one - side sequences from alphabet @xmath18 , whose sample space is composed of all sequences @xmath649 from @xmath18 and whose @xmath650-field @xmath651 is the usual product @xmath650-field of @xmath652 . let @xmath174 be the left shift on @xmath652 , i.e. , @xmath653 which is a measurable map .",
    "a dynamical system @xmath654 of this form is called a one - sided _ source _ , or _ process _ , and is abbreviated to @xmath655 $ ] .",
    "a two - sided source @xmath656 is defined analogously :",
    "the sample space @xmath657 consists of all two - sided sequences @xmath658 from @xmath18 and the @xmath650-field @xmath651 is the corresponding product @xmath650-field .",
    "again , @xmath174 is the left shift , which maps a sequence @xmath659 to @xmath660 , where @xmath661 note that in this case @xmath174 has an inverse ( the right shift ) , and both @xmath174 and @xmath662 are measurable .",
    "the same notation @xmath174 is used for the left shifts on both spaces , but context should make clear what the underlying space is .",
    "furthermore , for unified treatment of both cases , let @xmath663 denote the one- or two - sided sequence space of @xmath647 , and let @xmath664 denote the time index set , which equals @xmath665 or @xmath666 for the one- or two - sided cases , respectively .",
    "recall that the basic events of the sequence spaces are the ( finite dimensional ) _ rectangles _ , also called the _ cylinder sets _ , which are subsets @xmath641 of the form @xmath667 where @xmath668 is a finite subset of @xmath664 and @xmath669 for all @xmath670 .",
    "the sets @xmath671 , @xmath670 are called the _",
    "coordinate events_. when @xmath671 is a singleton for each @xmath670 , @xmath641 is called a _",
    "thin cylinder_.    a _ channel _ @xmath672 $ ] with input alphabet @xmath18 and output alphabet @xmath673 is defined by a family of probability measures @xmath674 on @xmath675 such that for each event @xmath676 , the map @xmath677 from @xmath663 into @xmath678 $ ] with its borel @xmath650-field is measurable . a channel is called one- or two - sided if the underlying sequence space is . given a source @xmath655 $ ] and a channel @xmath672 $ ] , the _ source - channel hookup _ , or the _ input - output process _",
    ", is the process @xmath679 $ ] , where the measure @xmath680 is defined by @xmath681 with @xmath682 being the section of @xmath641 at @xmath683 : @xmath684 the corresponding left shift for this process is still denoted by @xmath174 , with @xmath685    sometimes when the alphabets are understood we simply denote the above source , channel , and their hookup by the corresponding measures @xmath636 , @xmath686 , and @xmath680 , respectively . as usual , the random processes corresponding to the source and hookup can be denoted by their respective sequences of coordinate random variables @xmath687 and @xmath688 , where for any @xmath22 we define @xmath689 sometimes we also drop the subscript @xmath690 when there is no confusion .",
    "we say these random processes are stationary , ams , or ergodic if the underlying dynamic systems are . furthermore , for convenience we define the projection map @xmath474 between the one- and two - sided spaces on @xmath18 as @xmath691 where @xmath692 and @xmath693 similarly define the projection maps for the alphabets @xmath673 and @xmath694 , which are still denoted by @xmath474 .",
    "it is easy to verify that @xmath474 is always measurable and _ stationary _ , namely , @xmath695 .",
    "a channel @xmath672 $ ] is said to be _ stationary _ if @xmath696 , @xmath697 @xmath698 the term `` stationary '' is justified by ( * ? ? ?",
    "* lemma  9.3.1 ) , which shows that connecting a stationary source to a stationary channel yields a stationary input - output process .",
    "the channel is said to be _ ams _ if , for every ams source , the source - channel hookup is ams .",
    "an ams channel @xmath686 is _ ergodic _ if the hookup @xmath680 is ergodic whenever @xmath636 is ams and ergodic .",
    "a simple example of stationary channels is the family of _ _ stationary memoryless channels__. every channel @xmath672 $ ] in this family is associated with a collection of probability measures @xmath699 on @xmath700 , such that for each output rectangle @xmath676 , @xmath701 where @xmath668 is the index set and @xmath671 , @xmath670 are the coordinate events of @xmath641 .",
    "when @xmath18 and @xmath673 are finite sets , @xmath686 is called a _ discrete memoryless channel _ ( dmc ) .",
    "fix the input and output measurable spaces @xmath647 and @xmath700 , where @xmath647 is arbitrary , but @xmath673 is a finite set with cardinality @xmath702 and @xmath703 consists of all subsets of @xmath673 .",
    "let @xmath704 denote the space of all @xmath705 stochastic matrices @xmath706 , whose @xmath707-th entry is denoted by @xmath708 for @xmath709 . using the euclidean metric on @xmath704 we can construct its borel @xmath650-field to form a measurable space , which in turn induces a one- or two - sided sequence space @xmath710 .",
    "given a sequence @xmath711 , let @xmath712 denote the set of all probability measures on @xmath675 with respect to which @xmath713 forms a ( non - homogeneous ) markov chain with transition matrices @xmath714 for any integer @xmath715 .",
    "that is , @xmath716 iff @xmath717 , @xmath718 , and @xmath719 , @xmath720 in the one - sided case only @xmath220 need be verified .",
    "as before we say a map @xmath721 is _ stationary _ if @xmath722 .",
    "a channel @xmath672 $ ] is called _ markov _ if there exists a stationary measurable map @xmath721 such that @xmath723 the major results proved in @xcite by kieffer and rahe for markov channels is summarized in the following theorem :    [ thm : markov - channel - ams ] every one- and two - sided markov channel is ams .",
    "now let @xmath18 also be finite and let @xmath724 . if a one - sided markov channel @xmath672 $ ] satisfies @xmath725_{n } = p_{x_{n}},\\qquad \\forall n>0,\\ ] ] then @xmath686 is called a _",
    "finite state channel_. in this case , the matrix produced by @xmath726 at time @xmath22 depends only on the input at that time , @xmath2 .",
    "this definition is equivalent to gallager s finite state channel ( fsc ) defined in@xcite ( see definition  [ def : gallager - fsc ] ) , in terms of channel transitions .",
    "in fact , for the latter definition we have finite input , output , and state alphabets with respective symbols @xmath727 , and @xmath30 that fulfill the conditional probability requirement @xmath728 in other words , conditioned on @xmath729 , the pair @xmath730 is independent of all prior inputs , outputs , and states is also conditionally independent of the future inputs , i.e. , the channel is causal .",
    "it is also implicitly assumed when computing the block conditional probability in @xcite ( equation ( 4.6.1 ) ) .",
    "this condition is indeed satisfied by the fsc models we study .",
    "( see @xcite for more discussion ) . ] .",
    "if we define the new output @xmath731 of the channel as the output - state pair @xmath732 with @xmath733 then gallager s model fits in the definition here .",
    "the other direction is obvious if we define @xmath734 . in light of their equivalence",
    ", we do not explicitly distinguish the two definitions in this paper .",
    "most of the time we will find out that it is more convenient to work with the first one when studying the general theory , while the second one provides more flexibility when dealing with specific channel models .      to prove theorem  [ thm : markov - channel - ams ] , keiffer and rahe establish some intermediate source and channel constructions in @xcite , which we will need for the relevant ergodicity results and are summarized below .",
    "let @xmath655 $ ] be an ams source and @xmath672 $ ] be a markov channel , with @xmath726 being the corresponding stationary map . since @xmath636 is ams , by lemma  [ lem : pre - ams - iff ] there is a stationary measure @xmath640 on @xmath663 that agrees with @xmath636 on each invariant event in @xmath735 .",
    "( @xmath640 can be simply taken to be the stationary mean of @xmath636 . )",
    "define a two - sided stationary source @xmath736 $ ] as follows : if the original source is two - sided , then @xmath737 ; otherwise let @xmath738 be the two - sided stationary extension is _ standard _ , which is true for countable or euclidean spaces .",
    "interested readers may consult ( * ? ? ?",
    "2,3 ) for details . ] of the one - sided measure @xmath640 , which is specified by @xmath739 in particular , considering",
    "@xmath220 we have @xmath740 also , define a two - sided stationary map @xmath741 by setting @xmath742 if the original system is two - sided , and defining @xmath743 otherwise , where @xmath744 . in particular , for the latter case @xmath745 furthermore , @xcite constructs a measurable subset @xmath746 and proves that the measurable set @xmath747 is invariant and has probability 1 under any stationary probability measure on @xmath748 , in particular @xmath749    with these constructions kieffer and rahe define a two - sided channel @xmath750 $ ] which has the following properties :    1 .",
    "@xmath751 is stationary and hence so is the input - output process @xmath752 .",
    "2 .   @xmath753 for @xmath754 , so @xmath751 has the same transition structure as @xmath686 , @xmath738-a.e .    besides , if the original system is two - sided , then @xmath680 is absolutely continuous w.r.t .",
    "@xmath752 . in particular , for any invariant event @xmath755 , @xmath756 whenever @xmath757 , whereas if @xmath686 is one - sided , @xcite defines the `` one - sided restriction '' of the two - sided measure @xmath752 as @xmath758 which is also stationary since @xmath474 is .",
    "moreover , if @xmath759 is invariant and @xmath760 , then also @xmath756 . therefore in both cases @xmath680 is ams by lemma  [ lem : pre - ams - if ] , and so is @xmath686 .",
    "[ rmk : r-issue ] in @xcite property 2 ) of @xmath751 is assumed to be true for all @xmath761 , which is not the case in the original construction of @xcite .",
    "this misrepresentation is one source of inaccuracy for lemma  2 and the proof of theorem  2 in @xcite , which we will fix in later sections .    from these facts",
    "we can also obtain the following two results regarding the ergodicity of certain related processes , which are indispensable in current approaches for proving ergodicity of markov channels .",
    "although their proofs are not difficult and @xcite uses these results without explicitly proving them , we provide the proofs below for the sake of clarity and completeness .",
    "[ lem : mu - auxiliary - ergodicity ] if @xmath636 is ergodic , then so is the auxiliary measure @xmath738 for both one- and two - sided systems .    by construction @xmath640 is ergodic iff @xmath636 is , so for the two - sided case we are done .",
    "for the one - sided case , by the generating field structure of @xmath762 and ( * ? ? ?",
    "* lemma  6.7.4 ) it is enough to prove that @xmath763 for all rectangles @xmath764 when @xmath636 is ergodic .",
    "but by the stationarity of @xmath738 , without loss of generality we can assume the relevant coordinates for the rectangles @xmath641 and @xmath765 are positive .",
    "thus there exists rectangles @xmath766 such that @xmath767 and @xmath768 .",
    "now by the relation of @xmath640 and @xmath738 and the stationarity of @xmath474 , becomes @xmath769 which is true by ( * ? ? ?",
    "* lemma  6.7.3 ) when @xmath640 is ergodic .",
    "[ lem : mu - nu - auxiliary - ergodicity ] if the auxiliary measure @xmath752 is ergodic , then so is @xmath680 for both one- and two - sided systems .",
    "observe that the complement of an invariant event is also invariant .",
    "in the two - sided case , if @xmath770 for an invariant @xmath641 , then @xmath771 and so @xmath772 , and thus @xmath773 .",
    "hence ergodicity of @xmath752 implies ergodicity of @xmath680 .",
    "for the one - sided case , let @xmath774 be invariant , then @xmath775 is also invariant as @xmath474 is stationary .",
    "assume @xmath752 is ergodic , then @xmath776(f ) = { \\bar{\\mu}^{*}}{\\hat{\\nu}}(\\pi^{-1}f),\\ ] ] which is either 1 or 0 .",
    "again by the same argument , @xmath773 or 0 and hence @xmath680 is also ergodic .",
    "we are now ready to present the relevant results in @xcite , together with our comments , amendments , and corrections . in the meantime",
    ", we will develop some supplementary or extended results to apply in our own work .",
    "assume the same setting as the previous section , where we have an ams source @xmath655 $ ] and a markov channel @xmath672 $ ] with the corresponding auxiliary constructions .",
    "for any @xmath715 , @xmath718 and @xmath696 , we denote the output transition probability matrix for @xmath686 from time @xmath176 to @xmath22 by @xmath777 . in other words , for @xmath778 , @xmath779_{jk } \\triangleq \\nu_{x}(y_{n}=b_{k}{\\,|\\,}y_{m}=b_{j}),\\ ] ] where we fix an ordered enumeration @xmath780 of @xmath673 .",
    "since @xmath781 , @xmath782 similarly , for the auxiliary two - sided channel @xmath751 , for any @xmath783 and @xmath784 we define the matrix @xmath785 by @xmath786_{jk } \\triangleq { \\hat{\\nu}}_{x}(y_{n}=b_{k}{\\,|\\,}y_{m}=b_{j})\\ ] ] for @xmath778 .",
    "since @xmath753 on @xmath787 , we have @xmath788 thus if @xmath686 is two - sided , then @xmath742 and so @xmath789 whereas if @xmath686 is one - sided , as @xmath790 for all @xmath761 , @xmath791    [ def : weakly - ergodic ] let @xmath792 denote the transition matrix from time @xmath176 to @xmath22 for a non - homogeneous markov chain with @xmath702 states , for @xmath793 .",
    "the markov chain is called _ weakly ergodic _",
    "if @xmath794 a markov channel @xmath686 is _ weakly ergodic _",
    "if for all @xmath795 , @xmath796_{ij } - [ h_{mn}(x)]_{kj } { \\right}| = 0,\\qquad \\forall m\\in{\\boldsymbol{i}},\\ \\forall1\\leq i , j , k\\leq k.\\ ] ] we also say it is _ weakly ergodic on a set @xmath641 _ if holds for all @xmath797 .",
    "furthermore , @xmath686 is called _ weakly ergodic @xmath636-a.e . _ for a probability measure @xmath636 if it is weakly ergodic on a set with @xmath636-measure 1 .",
    "since @xmath726 is stationary , by @xmath798 this relation is true for both one- and two - sided channels for all @xmath715 , noting that in the latter case @xmath174 is invertible and so @xmath799 is always a single point .",
    "hence we only need to verify for the special case @xmath220 to prove the weak ergodicity of a markov channel .",
    "similarly , for the almost everywhere definition we have    [ lem : gray - dunham - gobbi - lem-1 ] suppose @xmath636 is a stationary source .",
    "then a markov channel @xmath686 is weakly ergodic @xmath636-a.e .",
    "iff for @xmath220 , holds with @xmath636-probability 1 .    given a @xmath705 stochastic matrix @xmath706 ,",
    "define @xmath800 where @xmath801 .",
    "it is the maximum total variation distances between the rows of @xmath706 , with @xmath802 .",
    "@xmath706 is called _ scrambling _ if @xmath803 , which holds iff for any two rows @xmath391 and @xmath175 there is at least one column @xmath804 for which both @xmath805 and @xmath806 ; or equivalently , no two rows of @xmath706 are orthogonal .",
    "moreover , for any stochastic matrices @xmath706 and @xmath327 , @xmath807    observe that for any fixed @xmath176 , is true iff @xmath808 this gives an equivalent definition for the weak ergodicity of a non - homogeneous markov chain . by the same token we have the following lemma .",
    "its first part comes from ( * ? ? ?",
    "* lemma  2 ) with the issue of @xmath751 ( metioned in remark  [ rmk : r-issue ] ) fixed , while the second part comprises two statements supplemented by ourselves .",
    "[ lem : gray - dunham - gobbi - lem-2 ] a markov channel @xmath686 is weakly ergodic iff @xmath809 in this case , the induced channel @xmath751 is weakly ergodic on @xmath787 . given a source @xmath655 $ ] , a markov channel @xmath686 is weakly ergodic @xmath636-a.e .",
    "iff the event @xmath810 has @xmath636-probability 1 .",
    "if the @xmath636 is stationary , then only @xmath220 need be considered .",
    "furthermore , if @xmath636 is ams , then @xmath686 is weakly ergodic @xmath636-a.e .",
    "iff @xmath640-a.e . ,",
    "in which case @xmath751 is also weakly ergodic on a subset of @xmath787 with @xmath738-probability 1 .",
    "see @xcite .",
    "the first main result in @xcite provides an alternative characterization of a.e .",
    "weakly markov channels .",
    "let @xmath811}$ ] denote expectation , i.e. , the integration w.r.t . the corresponding measure .",
    "[ thm : gray - dunham - gobbi - thm-1 ] a necessary condition for a markov channel @xmath686 to be weakly ergodic @xmath636-a.e . for a stationary measure",
    "@xmath636 is that there exists an @xmath76 such that @xmath812 } < 0.\\ ] ] a sufficient condition for @xmath686 to be weakly ergodic @xmath636-a.e . for a stationary and ergodic measure",
    "@xmath636 is that there exists an @xmath76 such that holds .",
    "gray et al .",
    "further derive three corollaries of this theorem in @xcite .",
    "however , all of them are inaccurate in that they all require an additional condition to hold : the source @xmath636 need be ergodic , apart from being stationary .",
    "that is because essentially the proofs all need to use the sufficient condition of the theorem .",
    "below we state these corollaries as lemmas , together with the corrections and some extended results .",
    "[ lem : gray - dunham - gobbi - cor-1 ] given a markov channel @xmath686 and a stationary ergodic source @xmath636 the following conditions are equivalent .    1 .",
    "the channel is weakly ergodic @xmath636-a.e .. 2 .   for @xmath636-a.e .",
    "each @xmath683 , @xmath813 such that no two rows of @xmath814 are orthogonal ; or equivalently , @xmath814 is scrambling , i.e. , @xmath815 .",
    "3 .   the channel has the `` positive column property '' @xmath636-a.e . ; that is , for @xmath636-a.e .",
    "each @xmath683 there is an @xmath22 for which @xmath814 has a positive column .",
    "the proof provided in @xcite is mostly correct , except that the result that b ) implies a ) does require the sufficient condition of theorem  [ thm : gray - dunham - gobbi - thm-1 ] . to prove that result , assume b ) is true but a ) is false . then @xmath816 }",
    "= 0 $ ] for all @xmath22 , otherwise by the sufficient condition @xmath686 is indeed weakly ergodic @xmath636-a.e .. as @xmath817 , for each @xmath22 we must have @xmath818 on a set @xmath819 with @xmath636-probability 1 .",
    "thus the intersection @xmath820 also has @xmath636-probability 1 , on which @xmath821 for all @xmath22 . as a result ,",
    "the set @xmath822 is null , i.e. , @xmath823 .",
    "this is a contradiction , since @xmath824 by b ) .",
    "from the proof above , the contradiction still exists as long as @xmath825the set on which the requirement for b ) holds  has a positive @xmath636-probability .",
    "also , for each point @xmath683 the requirement for b ) is implied by that of c ) .",
    "hence we can relax the conditions b ) and c ) , to only requiring them to hold on a set with positive @xmath636-probability , and the lemma is still correct . however , actually this is not a true relaxation , in view of our next lemma .",
    "[ lem : gray - dunham - gobbi - cor-1-relaxation ] let @xmath636 be stationary and ergodic .",
    "the corresponding requirement for each condition of lemma  [ lem : gray - dunham - gobbi - cor-1 ] holds @xmath636-a.e .",
    "iff it holds on a set of positive @xmath636-probability .",
    "see @xcite .    furthermore , note that for both conditions b ) and c ) , the corresponding properties only need to hold on a finite segment of a sequence . combining this observation with the definition of finite state channels",
    ", we have the following corollary .",
    "[ cor : gray - dunham - gobbi - cor-1-relaxation - cor ] let @xmath636 be a stationary ergodic source and @xmath686 be a markov channel . for either condition",
    "b ) or c ) of lemma  [ lem : gray - dunham - gobbi - cor-1 ] , if there exists a finite - dimensional rectangle @xmath641 possessing positive @xmath636-probability such that the corresponding requirement holds for all @xmath797 , then @xmath686 is weakly ergodic @xmath636-a.e . in particular ,",
    "when @xmath686 is a finite state channel and @xmath641 is a thin cylinder , we have a specific result : let @xmath826 , if    1 .",
    "@xmath827 , 2 .",
    "@xmath828 is scrambling , or has a positive column ,    then @xmath686 is weakly ergodic @xmath636-a.e .",
    "the first statement follows from the two lemmas above . for a finite state channel @xmath686 ,",
    "let @xmath641 be the thin cylinder with coordinate events @xmath829 for @xmath830 .",
    "then by @xmath831 hence the second statement holds as a special case of the first one .",
    "the second corollary of theorem  [ thm : gray - dunham - gobbi - thm-1 ] deals with gallager s concept of indecomposable finite state channels@xcite , which is generalized to all markov channels in @xcite as follows .",
    "[ def : gallager - indecomposable ] a markov channel @xmath686 is _ _ indecomposable in the gallager sense _ _ if for every @xmath832 there is an @xmath76 such that for all @xmath833 @xmath834_{ij } - [ h_{1n}(x)]_{kj } { \\right}| < \\epsilon,\\qquad \\forall x\\in\\sigma_{a},\\ \\forall1\\leq i , j , k\\leq k.\\ ] ]    for a markov channel both the indecomposability in the gallager sense and the weak ergodicity require that asymptotically the rows of the transition matrix become more and more alike .",
    "however , the former requires uniform convergence for all input sequences @xmath683 while the latter does not .    if a markov channel @xmath686 is indecomposable in the gallager sense , then @xmath686 has the _ strong positive column property _",
    ", that is , there is an @xmath22 such that @xmath814 has a positive column for every @xmath683 .",
    "if @xmath686 is a finite state channel , then @xcite shows that the relation is indeed _ if and only if_. since obviously strong positive column property implies positive column property , by lemma  [ lem : gray - dunham - gobbi - cor-1 ] we have the following lemma .",
    "[ lem : gray - dunham - gobbi - cor-2 ] a sufficient condition for a markov channel to be weakly ergodic @xmath636-a.e . for a stationary and ergodic source @xmath636",
    "is that it is indecomposable in the gallager sense @xmath636-a.e .",
    "the third corollary of theorem  [ thm : gray - dunham - gobbi - thm-1 ] is not used in our work and requires some extra definitions , hence we only correct it below and refer the interested readers to the original paper of gray et al . for the concept of indecomposability for a markov channel ( which is different from definition  [ def : gallager - indecomposable ] ) .",
    "[ lem : gray - dunham - gobbi - cor-3 ] a sufficient condition for a markov channel to be weakly ergodic @xmath636-a.e . for a stationary and ergodic source @xmath636",
    "is that it is indecomposable @xmath636-a.e .",
    "[ rmk : gray - dunham - gobbi - cor2 - 3-relaxation ] since lemma  [ lem : gray - dunham - gobbi - cor-2 ] and [ lem : gray - dunham - gobbi - cor-3 ] essentially use lemma  [ lem : gray - dunham - gobbi - cor-1 ] , by lemma  [ lem : gray - dunham - gobbi - cor-1-relaxation ] we only need their corresponding conditions to hold on a set of positive probability .      before presenting the main ergodicity results for markov channels , we require yet another definition of a class of channels , which was first introduced by adler in @xcite .",
    "[ def : strongly - mixing ] a channel @xmath686 is called _ strongly mixing _ , or _ _ output mixing__@xcite , or _ _ asymptotically independent of the remote past__@xcite if for all output rectangles @xmath641 and @xmath765 and all input sequences @xmath683 @xmath835 it is called _ strongly mixing @xmath636-a.e . _ for a probability measure @xmath636 if the above condition holds for all @xmath683 in a set of @xmath636-measure 1 .    immediately from the definition we can see that stationary memoryless channels are strongly mixing .",
    "in fact , the strongly mixing channels are proposed in @xcite to generalize the idea of channels with finite memory ( which obviously include the memoryless channels ) .",
    "the importance of strongly mixing channels lies in the following theorem , which is adapted from @xcite and ( * ? ? ?",
    "* lemma  9.4.3 ) .",
    "[ thm : adler ] let @xmath686 be a stationary channel .",
    "if @xmath636 is a stationary ergodic source and @xmath686 is strongly mixing @xmath636-a.e . , then @xmath680 is also stationary and ergodic . similarly , if @xmath636 is ams ergodic and @xmath686 is strongly mixing @xmath636-a.e . , then @xmath680 is also ams and ergodic .    for the statement with stationary @xmath636 ,",
    "see @xcite or ( * ? ? ?",
    "* lemma  9.4.3 ) for a proof . for the ams case",
    "the proof can be easily adapted from the stationary case with ( * ? ? ?",
    "* lemma  9.3.2 ) .",
    "the following lemma connects the a.e .",
    "weak ergodicity and a.e . strongly mixing property of markov channels .",
    "[ lem : gray - dunham - gobbi - lem-3 ] given a stationary source @xmath636 , if a markov channel is weakly ergodic @xmath636-a.e . , then it is also strongly mixing @xmath636-a.e .    the original statement of lemma  3 in @xcite claims that the reverse direction is also true .",
    "however , the proof for this direction has a missing link : equation ( 12 ) in @xcite is not necessarily true when @xmath836 , thus one can not deduce weak ergodicity from strongly mixing property by ( 12 ) . nevertheless ,",
    "since the reverse direction is not used in our work , we will not discuss possible fixes of that proof .",
    "the proof of the above lemma in @xcite indeed gives the following specific pointwise result , which we will use later .",
    "[ lem : gray - dunham - gobbi - lem-3-enhanced ] let @xmath672 $ ] be a channel ( not necessarily markov ) and @xmath795 . if @xmath837 corresponds to a weakly ergodic markov chain , namely , is true for @xmath683 , then holds for @xmath683 for all output rectangles @xmath641 and @xmath765 .",
    "next we state the second main result in @xcite .",
    "[ thm : gray - dunham - gobbi - thm-2 ] if a stationary markov channel @xmath686 is weakly ergodic @xmath636-a.e . for a stationary and ergodic source @xmath636 ,",
    "then @xmath680 is stationary and ergodic .",
    "a markov channel is ergodic if it is weakly ergodic @xmath636-a.e .",
    "with respect to all stationary measures @xmath636 ( e.g. , if it is weakly ergodic everywhere ) .    in fact",
    "the condition for the second statement can be weakened to just requiring @xmath686 to be weakly ergodic @xmath636-a.e . with respect to all stationary and ergodic measures @xmath636 .",
    "the proof of this theorem in @xcite is mostly correct , except that the proof for the second statement has the issue of @xmath751 mentioned in remark  [ rmk : r-issue ] .",
    "also it is too sketchy . in the following we use the same proof idea to extend this theorem to a more specific one tailored for our own purposes .",
    "its proof not only rigorously assembles various results built up in the appendices , but also demonstrates the proper treatment of the corresponding measurable sets on which the desired properties hold . in particular , the above issue of @xmath751 is fixed in this proof .",
    "[ thm : gray - dunham - gobbi - thm-2-extension ] let @xmath686 be a markov channel and @xmath636 be an ams ergodic source . if @xmath686 is weakly ergodic @xmath636-a.e .",
    ", then the input - output process @xmath680 is also ams and ergodic .    construct the auxiliary measures / processes @xmath640 and @xmath738 and the auxiliary two - sided channel @xmath751 as in section  [ subsec : kieffer - rahe - auxilliary - construction ] .",
    "first from theorem  [ thm : markov - channel - ams ] we know @xmath680 is ams and by lemma  [ lem : mu - auxiliary - ergodicity ] the stationary measure @xmath738 is also ergodic .",
    "next , as @xmath686 is weakly ergodic @xmath636-a.e . and @xmath636 is ams , @xmath751 is weakly ergodic on a subset @xmath838 with @xmath738-probability 1 by lemma  [ lem : gray - dunham - gobbi - lem-2 ] .",
    "hence by lemma  [ lem : gray - dunham - gobbi - lem-3-enhanced ] the condition in definition  [ def : strongly - mixing ] for the channel @xmath751 holds for all @xmath839 , so @xmath751 is strongly mixing @xmath738-a.e .",
    "now as @xmath751 is also stationary while @xmath738 is stationary and ergodic , @xmath752 is also stationary and ergodic by theorem  [ thm : adler ] .",
    "finally , @xmath680 is also ergodic by lemma  [ lem : mu - nu - auxiliary - ergodicity ] .",
    "[ cor : gray - dunham - gobbi - thm-2-extension - cor - markov ] let @xmath686 be a markov channel and @xmath636 be a stationary ergodic source . if any one of the conditions in lemmas  [ lem : gray - dunham - gobbi - cor-1 ] , [ lem : gray - dunham - gobbi - cor-2 ] , and [ lem : gray - dunham - gobbi - cor-3 ] holds on a set of positive @xmath636-probability , then @xmath680 is ams and ergodic .",
    "the result is obtained by combining lemmas  [ lem : gray - dunham - gobbi - cor-1][lem : gray - dunham - gobbi - cor-3 ] , and remark  [ rmk : gray - dunham - gobbi - cor2 - 3-relaxation ] together with theorem  [ thm : gray - dunham - gobbi - thm-2-extension ] .",
    "[ cor : gray - dunham - gobbi - thm-2-extension - cor - fsc ] let @xmath686 be a finite state channel and @xmath636 be a stationary ergodic source .",
    "let @xmath826 , if    1 .",
    "@xmath827 , 2 .",
    "@xmath828 is scrambling , or has a positive column ,    then @xmath680 is ams and ergodic .",
    "the result is obtained by combining corollary  [ cor : gray - dunham - gobbi - cor-1-relaxation - cor ] and theorem  [ thm : gray - dunham - gobbi - thm-2-extension ] .",
    "in this section we specialize to the case of connecting a finite - order markov input process to a finite state channel , and obtain some stationarity and ergodicity results .",
    "these results provide an alternative set of sufficient conditions for the shannon - mcmillan - breiman theorem .",
    "we start our development with the ergodicity of finite - order markov processes , and then extend to finite state channels with finite - order markov sources .",
    "the main theoretical tool is the following theorem for the ergodicity of stationary markov chains from @xcite .",
    "[ thm : markov - process - ergodic - irreducible ] consider a markov chain on a finite state space @xmath840 with transition matrix @xmath706 .",
    "assume the initial distribution @xmath474 is a positive stationary distribution for this chain , namely , @xmath841 and @xmath842 for all @xmath843 .",
    "then the corresponding stationary random process is ergodic iff @xmath706 is irreducible , in which case @xmath474 is the unique stationary distribution for @xmath706 .",
    "assume @xmath844 is a markov process of order @xmath175 , with a finite alphabet @xmath18 .",
    "let @xmath845 denote the state @xmath846 of the underlying markov chain for @xmath847 .",
    "the state process @xmath848 and the original process @xmath844 uniquely determine each other , and the stationarity , ams property , or ergodicity of one process implies the same property for the other .",
    "let @xmath706 denote the transition matrix of the markov chain .",
    "the process measure @xmath849 of @xmath850 is determined by @xmath706 and the initial distribution , and is ams by ( * ? ? ?",
    "* theorem  9 ) .",
    "let @xmath851 be the stationary mean of @xmath849 and @xmath474 be the initial distribution for @xmath851 , then @xmath474 is a stationary distribution of @xmath706 .",
    "denote the support of @xmath474 by @xmath852 , which is called the _ contingent stationary support _ of the markov process @xmath850 ( since it depends on the initial distribution ) .",
    "it is easy to see that @xmath852 is a _ closed _ subset of @xmath853 , that is , @xmath854 for all @xmath855 .",
    "now assume that the markov chain @xmath706 is irreducible on @xmath852 .",
    "as the conditions for theorem  [ thm : markov - process - ergodic - irreducible ] are satisfied on @xmath852 with the initial distribution @xmath474 , the stationary measure @xmath851 is ergodic , and so is @xmath849 ( see ( * ? ? ?",
    "* lemma 6.7.1 ) ) .",
    "hence @xmath850 and @xmath856 are ams ergodic processes .",
    "conversely , if @xmath856 or @xmath850 is ergodic , then @xmath849 , and so @xmath851 are ergodic , and by theorem  [ thm : markov - process - ergodic - irreducible ] , @xmath706 is irreducible on @xmath852 .",
    "moreover , when either of the above conditions holds , theorem  [ thm : markov - process - ergodic - irreducible ] states that @xmath474 is the unique stationary distribution for the chain on @xmath852 .",
    "thus if another initial distribution on the markov chain induces a process measure @xmath857 , whose stationary mean has a ( stationary ) initial distribution @xmath858 that is also supported on @xmath852 , then necessarily @xmath859 and the stationary mean is @xmath851 . in particular , if @xmath860 , or equivalently , ( the full matrix ) @xmath706 is irreducible , then the stationary process measures for @xmath850 and @xmath856 are unique .    summarizing the discussions above we have the following lemma .",
    "[ lem : finite - order - markov - ergodicity ] let @xmath856 be a finite - alphabet finite - order markov process , with an underlying state process @xmath850 , whose markov transition matrix is @xmath706",
    ". then both @xmath856 and @xmath850 are ams .",
    "let @xmath852 denote the contingent stationary support of @xmath850 , then @xmath850 ( and @xmath856 ) are ergodic iff @xmath706 is irreducible on @xmath852 .",
    "furthermore , when this is the case , any other initial distribution of the markov chain that leads to the same contingent stationary support induces the same stationary mean for @xmath850 ( and hence also the same stationary mean for @xmath856 ) , and so the corresponding processes are ergodic .",
    "in particular , if @xmath852 is the full state space , or equivalently , @xmath706 is irreducible , then these stationary process measures are unique .    now consider a finite state channel defined in gallager s form .",
    "assume the source process @xmath844 is markov of order @xmath376 and is independent of the initial state @xmath110 of the fsc , then the joint process @xmath861 is also markov of order @xmath175 .",
    "when @xmath856 is i.i.d .",
    "( i.e. , @xmath862 ) , @xmath861 is simply markov ( i.e. , of order-1 ) .",
    "( see @xcite for the details . )",
    "hence by the lemma above , we have :    [ lem : fsc - markov - input ] if the source @xmath856 of an fsc is an order-@xmath175 markov process with @xmath863 , then @xmath864 is a markov process of order @xmath865 . if the underlying markov chain for the latter is irreducible on the contingent stationary support , then @xmath864 is ams and ergodic .    in our energy harvesting channels we often encounter fsc s that satisfy @xmath866 for which we will show that if the input - state process is ams ergodic , then so is the full joint process ( see lemma  [ lem : ergodicity - fsc - dmc - y ] in appendix  [ sec : joint - marginal ] ) .",
    "thus for such channels we have :    [ cor : fsc - separable - markov - input ] if the source @xmath856 of an fsc satisfying is an order-@xmath175 markov process with @xmath863 , then @xmath867 is a markov process of order @xmath865 .",
    "if the underlying markov chain for the latter is irreducible on the contingent stationary support , then @xmath864 is ams and ergodic .",
    "for a finite alphabet random process @xmath856 whose probability measure is denoted by @xmath624 , we are interested in the convergence of the sample entropy @xmath868 to the entropy rate @xmath869 whenever the limit exists . in information theory , this property is called the _ asymptotic equipartition property _ ( aep ) @xcite . when the process is i.i.d .",
    ", aep is easily proved using law of large numbers .",
    "when @xmath856 is stationary and ergodic , the shannon - mcmillan - breiman ( smb ) theorem for stationary processes @xcite also gives the aep ; in particular , the sample entropy converges to the entropy rate with probability 1 . yet",
    "this result is still not general enough for our application in the energy harvesting systems , since the joint input - output process produced by the surrogate channel is often not stationary , but ams instead .",
    "hence we require an smb theorem for ams processes , which is also called the entropy ergodic theorem in @xcite .",
    "( shannon - mcmillan - breiman / entropy ergodic theorem @xcite)[thm : smb ] let @xmath856 be a finite alphabet random process with an ams ergodic process distribution @xmath624 , whose stationary mean is denoted by @xmath870 . then the entropy rate exists and @xmath871 where the convergence is both @xmath624-a.e . and in @xmath872-norm",
    ". furthermore , the value of @xmath873 is the same as @xmath874 , the entropy rate defined under the stationary measure @xmath870 .",
    "in this section we discuss the stationarity and ergodicity of a joint process and its marginals . in the settings of this paper",
    "we usually have a joint process , say @xmath875 , and want to apply the smb theorem on its various marginal processes , e.g. , @xmath164 or @xmath170 .",
    "it is enough to show the required ams and ergodic properties for the joint process @xmath875 , since from their respective definitions we can easily see that these properties are inherited by the marginal processes from the joint one .",
    "we also have some remarks for the other direction .",
    "consider a general channel @xmath876 $ ] whose input and output symbols are @xmath0 and @xmath731 , respectively .",
    "let @xmath877}$ ] be another channel , whose input symbols are the pairs @xmath878 and output symbols are @xmath1 .",
    "assume @xmath849 is a stationary memoryless channel , then it is stationary and strongly mixing and so adler s theorem applies . in particular ,",
    "if a source @xmath655 $ ] gives an ams ergodic hookup @xmath680 , then by theorem  [ thm : adler ] , connecting @xmath680 to @xmath849 gives an ams ergodic hookup @xmath879 .",
    "in other words , the joint process @xmath880 is also ams and ergodic .    for the application in our energy harvesting channels , consider a special class of fsc models whose transition probability satisfies @xmath881 we can view @xmath882 as the transition probability of a smaller finite state channel @xmath686 , with input symbols @xmath0 and output symbols @xmath883 .",
    "furthermore , @xmath1 can be viewed as the output of another dmc @xmath849 , whose input symbols are the pairs @xmath878 with transition probability @xmath884 applying the argument from the previous paragraph to the channels @xmath686 and @xmath849 , we have the lemma below . consequently , to show the full joint process @xmath885 is ams and ergodic we only need to consider the smaller finite state channel @xmath882 .",
    "[ lem : ergodicity - fsc - dmc - y ] for the fsc model let @xmath844 be an input process that yields an ams ergodic joint input - state process @xmath886 , then the joint input - state - output process @xmath885 is also ams ergodic .",
    "the authors would like to thank pascal vontobel and guangyue han for the helpful discussions on the stochastic algorithms for the optimization of achievable rates .",
    "w.  mao and b.  hassibi , `` on the capacity of a communication system with energy harvesting and a limited battery , '' in _ proc .",
    "of 2013 ieee international symposium on information theory _ , istanbul , turkey , jul .",
    "2013 .",
    "o.  ozel , j.  yang , and s.  ulukus , `` optimal broadcast scheduling for an energy harvesting rechargeable transmitter with a finite capacity battery , '' _ ieee trans .",
    "wireless commun .",
    "_ , vol .  11 , no .  6 , pp .",
    "21932203 , jun 2012 .         , `` awgn channel under time - varying amplitude constraints with causal information at the transmitter , '' in _ proc . of the 45th asilomar conference on signals , systems and computers _ , pacific grove , ca , nov . 2011 .",
    "k.  tutuncuoglu , o.  ozel , a.  yener , and s.  ulukus , `` binary energy harvesting channel with finite energy storage , '' in _ proc .",
    "of 2013 ieee international symposium on information theory _ , istanbul , turkey , jul .",
    "o.  ozel , k.  tutuncuoglu , s.  ulukus , and a.  yener , `` capacity of the discrete memoryless energy harvesting channel with side information , '' in _ proc .",
    "of 2014 ieee international symposium on information theory _ , honolulu , hi , jun .",
    "2014 .",
    "o. vontobel , a.  kavi , d.  m. arnold , and h .- a .",
    "loeliger , `` a generalization of the blahut - arimoto algorithm to finite - state channels , '' _ ieee trans .",
    "inf . theory _ ,",
    "54 , no .  5 , pp .",
    "18871918 , may 2008 .",
    "w.  mao , `` information - theoretic studies and capacity bounds : group network codes and energy harvesting communication systems , '' ph.d .",
    "dissertation , california institute of technology , 2015 .",
    "[ online ] .",
    "available : http://thesis.library.caltech.edu/8834/                d.  arnold and h .- a .",
    "loeliger , `` on the information rate of binary - input channels with memory , '' in _ proc .",
    "of 2001 ieee international conference on communications _ , helsinki , finland , jun .",
    "2001 , pp . 26922695 .",
    "v.  sharma and s.  k. singh , `` entropy and channel capacity in the regenerative setup with applications to markov channels , '' in _ proc .",
    "of 2001 ieee international symposium on information theory _ ,",
    "washington , dc , jun .",
    "2001 , p. 283 .",
    "h.  d. pfister , j.  b. soriaga , and p.  h. siegel , `` on the achievable information rates of finite - state isi channels , '' in _ proc of 2001 ieee global telecommunications conference ( globecom 01 ) _ , san antonio , tx , nov .",
    "2001 , pp . 29922996 .",
    "d.  m. arnold , h .- a .",
    "loeliger , p.  o. vontobel , a.  kavi , and w.  zeng , `` simulation - based computation of information rates for channels with memory , '' _ ieee trans .",
    "inf . theory _",
    "52 , no .  8 , pp . 34983508 , august 2006 .",
    "k.  tutuncuoglu , o.  ozel , a.  yener , and s.  ulukus , `` improved capacity bounds for the binary energy harvesting channel , '' in _ proc .",
    "of 2014 ieee international symposium on information theory _ , honolulu , hi , jul .",
    "o.  ozel , k.  tutuncuoglu , s.  ulukus , and a.  yener , `` capacity of the energy harvesting channel with energy arrival information at the receiver , '' in _ proc . of the 2014 information theory workshop _ , hobart , australia , nov ."
  ],
  "abstract_text": [
    "<S> we study the channel capacity of a general discrete energy harvesting channel with a finite battery . </S>",
    "<S> contrary to traditional communication systems , the transmitter of such a channel is powered by a device that harvests energy from a random exogenous energy source and has a finite - sized battery . as a consequence , at each transmission opportunity </S>",
    "<S> the system can only transmit a symbol whose energy is no more than the energy currently available . </S>",
    "<S> this new type of power supply introduces an unprecedented input constraint for the channel , which is simultaneously random , instantaneous , and influenced by the full history of the inputs and the energy harvesting process . </S>",
    "<S> furthermore , naturally , in such a channel the energy information is observed causally at the transmitter . </S>",
    "<S> both of these characteristics pose great challenges for the analysis of the channel capacity . in this work </S>",
    "<S> we use techniques developed for channels with side information and finite state channels , to obtain lower and upper bounds on the capacity of energy harvesting channels . in particular , in a general case with markov energy harvesting processes we use stationarity and ergodicity theory to compute and </S>",
    "<S> optimize the achievable rates for the channels , and derive series of computable capacity upper and lower bounds .    channel capacity , energy harvesting , causal csit , finite state channel , ergodicity . </S>"
  ]
}