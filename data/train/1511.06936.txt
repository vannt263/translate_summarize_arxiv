{
  "article_text": [
    "the definition of an _ anomaly _ depends on what context is of interest .",
    "a video event is considered as being an anomaly if it is not very likely to occur in the video  @xcite .",
    "describing unusual events in complex scenes is a cumbersome task , often solved by employing high - dimensional features and descriptors .",
    "developing a reliable model to be trained with such descriptors is quite challenging and requires an enormous amount of training samples ; it is also of large computational complexity .",
    "therefore , this might face the so - called `` curse of dimensionality '' , in which the predictive power of the trained model reduces , as the dimensionality of the feature descriptors increases .",
    "in recent work , one or a set of reference normal models are learned from training videos , which are then applied for detecting an anomaly in the test phase .",
    "such methods usually consider a test video as being an anomaly if it does not resemble the learned model(s ) . in order to build these reference models ,",
    "some specific feature descriptors should be used . in general , features usually are extracted to represent either ( 1 ) trajectories or ( 2 ) spatio - temporal changes .",
    "for instance , @xcite and @xcite focus on the trajectories of objects in videos , in which each object is to be labeled as an anomaly or not , based on how they follow the learned normal trajectory .",
    "these methods could not handle the occlusion problem , and are also computationally very expensive , for the case of crowded scenes .    to overcome these weaknesses , researchers proposed methods using low - level features such as optical flow or gradients .",
    "they learn the shape and spatio - temporal relations using low - level features distributions . as an example",
    ", @xcite fits a gaussian mixture model as the features , while @xcite uses an exponential distribution .",
    "clustering of test data using low - level features is exploited in @xcite . in @xcite",
    ", the normal patterns were fitted to a markov random field , and @xcite apply latent dirichlet allocations .",
    "@xcite introduces a joint detector of temporal and spatial anomalies , where the authors use a mixture of dynamic textures ( mdt ) model .    in recent studies , sparse representations of events  @xcite in videos",
    "is being heavily explored .",
    "notably , the proposed models in @xcite achieve favorable performance in anomaly detection , however they normally fail in the task of anomaly localization .",
    "all these methods , except @xcite , are not designed for real - time applications and commonly fail in real - world anomaly detection problems .    in this paper",
    ", we propose to represent videos from two different aspects or views , and thus two partially independent feature descriptors .",
    "then , we introduce an approach for integrating these views in a testing step to simultaneously perform anomaly _ detection _ and _ localization _ , in real - time . unlike previous work , instead of using low - level features",
    ", we propose to learn a set of representative features , based on auto - encoders @xcite .",
    "our detection framework identifies an anomaly in a real - time manner .",
    "our anomaly detection method has high true - positive and low false - positive rates which make it quite reliable .",
    "we evaluate our anomaly detection and localization framework on popular datasets and report the running time for the whole procedure .",
    "the comparison with state - of - the - art methods shows the superiority of our method , both in terms of performance and running time .",
    "the main contributions of our work are as follows : ( 1 ) presenting a feature learning procedure for describing videos for the task of video anomaly localization .",
    "this method is time - consuming for training , but the learned features are very discriminative to model the normal patches .",
    "( 2 ) introducing a descriptor - based similarity metric between adjacent patches for detecting sudden changes in spatio - temporal domains . ( 3 ) representing video patches from two different aspects or views .",
    "both local and global feature sets are used for each view . in the final decision , these views support each other .",
    "( 4 ) modeling all normal patches with gaussian distributions . for a test video , the mahalanobis distance is used to figure out its relevance for the normal patches .",
    "( 5 ) being real - time , we are able to detect and localize anomalies soon after they occur in a test video or stream .        the overall scheme of our algorithm is shown in fig .",
    "[ fig:2 ] .",
    "we achieve 25 fps processing power , and with enduring some bit errors we reach up to 200 fps using a pc with 3.5 ghz cpu and 8 g ram in matlab 2012a .",
    "the rest of the paper is organized as follows .",
    "the proposed approach is introduced in section  [ sec : ps ] , where we first introduce the overall schema , and then we focus on global descriptors , local descriptors , anomaly classification scheme , and finally anomaly detection through feature learning , one after the other . experimental results , comparisons , and analysis are presented in section  [ sec : er ] . ultimately , section  [ sec : c ] concludes the paper .",
    "* overall scheme . * to represent each video ,",
    "first each video is converted into a number of non - overlapping cubic patches ; a sketch of this video representation is shown in fig .",
    "[ fig : vp ] . generally , every video has one or a set of dominant events .",
    "thus , one expects that _ normal patches _ have similar relations with their adjacent patches and a high likelihood of occurrence in the video .",
    "therefore , these _ anomaly patches _ should meet three conditions :        1 .",
    "the similarity between the anomaly patches and their adjacent ( , defined by spatial changes ) patches does not follow the same pattern as from normal patches to their adjacent patches . 2 .",
    "it is most likely that the temporal changes of an anomaly patch would not follow the pattern in the temporal changes of normal patches .",
    "it is obvious that the occurrence likelihood of an anomaly patch is less than that of normal patches .",
    "it can be easily inferred that the above conditions 1 and 2 are characterized locally .",
    "therefore , they can be encoded by local feature descriptors , and condition 3 is analogous to the global nature of the scene . in other words , conditions 1 and 2",
    "consider the relation between a patch and its adjacent patches , and condition 3 describes the overall appearance of patches in the video . as a result ,",
    "the first two conditions are corresponding to the spatio - temporal changes , while the latter one is different .",
    "therefore , we model a combination of 1 and 2 through a _ local _ representation , and 3 by a more _ global _ one . on the other hand , in order to avoid the so - called `` curse of dimensionality '' , we model these two aspects independently .",
    "so far , we have defined two different aspects that we approach the problem , leading to two independent models . in order to make a final decision",
    ", we aggregate the decisions from both models . if both models reject a patch it is considered to be an anomaly .",
    "this leads to a system with better performance in terms of true - positive and false - positive , since this way of combination of the two models guarantees a concrete selection of a patch as anomaly if both models agree on its being an anomaly .    in summary",
    ", the input videos are represented in two different aspects .",
    "then , these representations are fitted to a set of gaussian distributions and a decision boundary is calculated for each of them .",
    "finally , based on global and local model results , a decision is reached about a patch being an anomaly or not ( _ detection _ ) .",
    "the _ localization _ could be then easily inferred , based on which patches throughout the video are classified as anomaly . in the subsequent sections , the two sets of features ( global and local ) are introduced .",
    "a video global descriptor is a set of features that describes the video as a whole and therefore is best able to describe the normal video patches . in @xcite",
    "it is argued that classical handcrafted low - level features , such as hog and hof , may not be universally suitable and discriminative enough for every type of video .",
    "so , unlike previous works , that use low - level features , we use an unsupervised feature learning method based on auto - encoders .",
    "the structure of the auto - encoder is depicted in fig .",
    "[ fig : auto ] .",
    "the auto - encoder learns sparse features based on gradient descent , by modeling a neural network .",
    "suppose that we have @xmath0 normal patches with the dimensions @xmath1 , creating a data structure of @xmath2 ( the raw data ) .",
    "the auto - encoder minimizes the objective defined in eq .   by re - reconstructing the original raw data : @xmath3 where @xmath4 is the number nodes in the auto - encoder s hidden layer , @xmath5 and @xmath6 are the weight matrices , which map the input layer nodes to hidden layer nodes , and hidden layer nodes to the output layer nodes , respectively .",
    "@xmath7 is the weight between the @xmath8 hidden layer node and the @xmath9 output layer node , and @xmath10 is equal to the sigmoid function .",
    "furthermore , @xmath11 and @xmath12 , are the bias of the output layer and the hidden layer , respectively .",
    "@xmath13 is a regularization function and is set to enforce the activation of the hidden layer to be sparse .",
    "@xmath14 is based on the similarity between a bernoulli distribution with @xmath15 as parameter , and the active node distribution .",
    "the parameter @xmath16 is the weight of the penalty term ( in the sparse auto - encoder objective ) .",
    "we can efficiently optimize the above objective with respect to @xmath17 via the stochastic gradient descent approach .            to describe each video patch",
    ", we use a set of local features . the similarity between each patch and its neighboring patches",
    "are calculated . as for the neighbors",
    ", we consider nine spatial neighboring patches and one temporal neighboring patch ( the one right behind the patch of interest when arranged temporally ) , yielding to 10 neighbors for each single patch . for temporal neighbors ,",
    "we only consider the patch before the patch of interest ( not the next one ) , as we aim to detect the anomaly soonest possible , even before the next video frames ( and therefore patches ) in the video stream arrive .",
    "we use ssim for computing the similarity between two patches , which is a well - known image - quality assessment tool  @xcite .",
    "further , as a second type of local descriptor , we calculate the ssim of each single frame with its subsequent frame in the patch of interest .",
    "figure  [ fig:3 ] illustrates our local feature assessment through the spatio - temporal neighboring .",
    "the local descriptor would be the combination of the ssim values , , @xmath18 $ ] .    to model the normal activities in each video patch , we incorporate two gaussian classifiers @xmath19 and @xmath20 .",
    "for classifying @xmath21 patches , as described , we use two partially independent feature sets ( global and local ) , and compute the mahalanobis distance @xmath22 . if @xmath22 is larger than the threshold then it is considered to specify an abnormal patch , where @xmath23 equals @xmath24 in the global classifier , and @xmath25 $ ] for the case of the local classifier . to avoid numerical instabilities ,",
    "density estimates are avoided . as a result , the @xmath26 and @xmath20 classifiers are defined as follows : @xmath27 with @xmath28 where @xmath29 and @xmath30 are mean and covariance matrix , respectively . selecting a `` good '' threshold",
    "is important for the performance ; it can be selected based on training patches . as mentioned before ,",
    "if both @xmath19 and @xmath20 classifiers label a patch as being an anomaly , it is considered to be an anomaly , but if one or neither of them considers the patch as being an anomaly , our algorithm classifies it as being a normal patch .",
    "a summary of these criteria is shown as @xmath31 function in the following equation : @xmath32    we learn the features from raw training data , and classify the video patches as specified in the previous section . but based on the idea in @xcite , using both small patches and large patches usually leads to increased values of false - positive rate and decreased value of true - positive rate , respectively .",
    "when the patches become larger , the input dimension of the auto - encoder increases , so the number of weights in the network , which need to be learned , will also increase .",
    "under the condition of limited training examples , learning of features from large patches is impractical ( for example 40@xmath3340@xmath335 ) , to overcome these challenges , we learn the features from ( small ) 10@xmath3310@xmath335 patches . to create a model using these features , in the test phase the large patches ( 40@xmath3340@xmath335 )",
    "are considered . because the learned classifier is adapted for 10@xmath3310@xmath335 patch representations , we convolve the learned feature ( @xmath17 ) in 40@xmath3340@xmath335 patches , without overlapping , and pool the 16 extracted feature vectors from the 40@xmath3340@xmath335 patches .",
    "so , we use mean pooling to achieve a representation of 40@xmath3340@xmath3310 patches that can be checked with the learned classifier using 10@xmath3310@xmath335 patches . this procedure is shown in figure  [ fig:4 ] .",
    "we compare our algorithm with state - of - the - art methods on ped2 ucsd and umn benchmarks .",
    "we empirically demonstrate that our approach is suitable to be used in surveillance systems .",
    "* experimental settings . *",
    "feature learning is done with 10@xmath3310@xmath335 patches .",
    "training and testing phases in anomaly detection is done with 10@xmath3310@xmath335 and 40@xmath3340@xmath335 patch sizes , respectively . in anomaly detection ,",
    "the size 40@xmath3340@xmath335 is exploited .",
    "feature learning is done with an auto - encoder with 0.05 sparsity .",
    "each 10@xmath3310@xmath335 patch is represented by a 1000-dimensional feature vector . before feature learning",
    ", normalization is performed to set the mean and variance to 0 and 1 , respectively .",
    "* ucsd datasets . *",
    "this dataset includes two subsets , ped1 and ped2 , that are from two different outdoor scenes .",
    "both are recorded with a static camera at 10 fps , with the resolutions @xmath34 and @xmath35 , respectively .",
    "the dominant mobile objects in these scenes are pedestrians .",
    "therefore , any object ( , a car , skateboarder , wheelchair , or bicycle ) is considered as being an anomaly .",
    "we evaluate our algorithm on ped2 .",
    "this subset includes 12 video samples , and each sample is divided into training and test frames . to evaluate the localization ,",
    "we utilize the ground truth of all test frames .",
    "we compare our results with state - of - the - art methods using receiver operating curve ( roc ) and equal error rate ( eer ) analysis , similar to  @xcite .",
    "we use two evaluation measures , one at frame level and the other at pixel level .",
    "in addition to these , we define a new measure for the accuracy of anomaly localization , called _ dual pixel level_. these measures are defined as follows :    _ frame level measure _ : if one pixel detects an anomaly then it is considered as being an anomaly .",
    "_ pixel level measure _ : if at least 40 percent of anomaly ground truth pixels are covered by pixels detected by the algorithm , then the frame is considered to be an anomaly .",
    "suppose that the algorithm detects some region as being an anomaly , and just one of these regions has an overlap with anomaly ground truth ; the number of false regions is not considered in the two former measures .",
    "such a region is called a `` lucky guess '' . for considering the `` lucky guess '' regions",
    ", we introduce the dual pixel level .",
    "this measure is sensitive to a `` lucky guess '' .    _",
    "dual pixel level _ : in this measure , a frame is considered as being an anomaly if ( 1 ) it satisfies the anomaly condition at pixel level and ( 2 ) at least @xmath16 percent ( , @xmath36 ) of the pixels detected as anomaly are covered by the anomaly ground truth . if , in addition to the anomaly region , irrelevant regions are also considered as being an anomaly , then this measure does not identify the frame as being positive .",
    "figure  [ fig:5 ] shows an example for the different measures of anomaly detection .",
    "percent of blue is not covered by red .",
    "( d ) dual - pixel level ]    * performance evaluations . *",
    "figure  [ fig:6 ] shows a qualitative comparison with other methods .",
    "this figure indicates that our algorithm has the best performance in comparisons with all the competing algorithms . for the run - time comparisons ,",
    "see table  [ tab : time ] .",
    ".run time comparison [ cols=\"^,^\",options=\"header \" , ]     * umn dataset . *",
    "the umn dataset has three different scenes . in each scene",
    ", a group of people are walking in an area , suddenly all people run away ( escape ) ; the escape is considered to be the anomaly .",
    "figure  [ fig : umn ] shows examples of normal and abnormal frames of this dataset .",
    "this dataset has some limitations .",
    "there are only three anomaly scenes in the dataset , and the temporal - spatial changes between normal and abnormal frames are very high .",
    "this dataset has no pixel - level ground truth .",
    "based on this limitations , to evaluate our method , the eer and auc in frame - level are used .",
    "the eer and auc results are shown in table  [ tbl : umn ] . because this dataset is simple , and anomaly localization is not important ,",
    "only the global detector is used .",
    "previous methods performed reasonably good on this dataset .",
    "the auc of our method is comparable with the otherwise best result , and the eer of our approach is better ( by 0.3 percent ) than the one of the best previous method .",
    "we presented an anomaly detection and localization method . in our method , we propose to represent a video using both global and local descriptors .",
    "two classifiers are proposed based on these two forms of representation .",
    "our fusion strategy on the outputs of these two classifiers achieves accurate and reliable anomaly detection and localization .",
    "however , each of the two classifiers has a good performance for anomaly detection , solely .",
    "this is especially shown on the umn dataset where the global descriptor achieves state - of - the - art results .",
    "we introduced a new metric for region level anomaly detection for suspicious regions , as well .",
    "the performance of our approach on the ucsd dataset is better compared to recent approaches .",
    "it is also worth noting that we achieve all these good results in a much better running time than all the competing methods .",
    "our method enjoys a low computational complexity , and can be run in real - time .",
    "this makes it quite useful for real - time surveillance applications , in which we are dealing with live streams of videos .",
    "a.  adam , e.  rivlin , i.  shimshoni , and d.  reinitz .",
    "robust real - time unusual event detection using multiple fixed location monitors .",
    "_ ieee trans .",
    "pattern analysis machine intelligence _",
    ", 30(3):555560 , 2008 .",
    "m.  j. roshtkhari and m.  d. levine .",
    "an on - line , real - time learning method for detecting anomalies in videos using spatio - temporal compositions . _ computer vision image understanding _",
    ", 117(10):14361452 , 2013 ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a method for real - time anomaly detection and localization in crowded scenes . </S>",
    "<S> each video is defined as a set of non - overlapping cubic patches , and is described using two local and global descriptors . </S>",
    "<S> these descriptors capture the video properties from different aspects . by incorporating simple and cost - effective gaussian classifiers </S>",
    "<S> , we can distinguish normal activities and anomalies in videos . </S>",
    "<S> the local and global features are based on structure similarity between adjacent patches and the features learned in an unsupervised way , using a sparse auto - encoder . </S>",
    "<S> experimental results show that our algorithm is comparable to a state - of - the - art procedure on ucsd ped2 and umn benchmarks , but even more time - efficient . </S>",
    "<S> the experiments confirm that our system can reliably detect and localize anomalies as soon as they happen in a video . </S>"
  ]
}