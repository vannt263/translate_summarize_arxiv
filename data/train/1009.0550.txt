{
  "article_text": [
    "until the mid-1970s most chess programs attempted to perform search by mimicking the way humans think , i.e. , by generating `` plausible '' moves . by using extensive chess knowledge , these programs selected at each node a few moves which they considered plausible , thereby pruning large parts of the search tree .",
    "however , as soon as brute - force search programs like tech @xcite and chess 4.x @xcite managed to reach depths of 5 plies and more , plausible move generating programs frequently lost to these brute - force searchers due to their significant tactical weaknesses .",
    "brute - force searchers rapidly dominated the computer chess field .",
    "the introduction of null - move pruning @xcite in the early 1990s marked the end of an era , as far as the domination of brute - force programs in computer chess is concerned . unlike other forward - pruning methods which had great tactical weaknesses , null - move pruning enabled programs to search more deeply with minor tactical risks .",
    "forward - pruning programs frequently outsearched brute - force searchers , and started their own reign which has continued ever since ; they have won all world computer chess championships since 1992 .",
    "deep blue @xcite was probably the last brute - force searcher .    nowadays",
    ", top tournament - playing programs use a range of methods for adding selectivity to their search .",
    "the most popular methods include null - move pruning , futility pruning @xcite , multi - cut pruning @xcite , and selective extensions @xcite . for each of these methods , a wide range of parameter values can be set .",
    "for example , different reduction values can be used for null - move pruning , various thresholds can be used for futility pruning , etc .    for each chess program",
    ", the parameter values for various selective search methods are manually tuned through years of experiments and manual optimizations . in this paper",
    "we introduce a novel method for automatically tuning the search parameters of a chess program using genetic algorithms ( ga ) .    in the following section , we review briefly the main methods that have been used for selective search . for each of these methods ,",
    "we enumerate the parameters that need to be optimized .",
    "section 3 provides a review of past attempts at automatic learning of various parameters in chess . in section 4",
    "we present our automatic method of optimizing the parameters in question , which is based on the use of genetic algorithms , and in section 5 we provide experimental results .",
    "section 6 contains concluding remarks .",
    "in this section we review several popular methods for selective search .",
    "all these methods work within the alphabeta / pvs framework and introduce selectivity in various forms .",
    "a simple alphabeta search requires the search tree to be developed to a fixed depth in each iteration .",
    "forward pruning methods , such as null - move pruning , futility pruning , and multi - cut pruning , enable the program to prune some parts of the tree at an earlier stage , and devote the time gained to other , more promising parts of the search tree .",
    "selective extensions , on the other hand , extend certain parts of the tree to be searched deeper , due to tactical considerations associated with a position in question .",
    "the following subsections briefly cover each of these pruning and extension methods , and specify which parameters should be tuned for each method .",
    "null - move pruning @xcite is based on the assumption that `` doing nothing '' in every chess position ( i.e. , doing a null - move ) is not the best choice even if it were a legal option . in other words ,",
    "the best move in any position has to be better than the null - move .",
    "this assumption enables the program to establish a lower bound @xmath0 on the position by conducting a _ null - move search_. the idea is to make a null - move , i.e. , merely swap the side whose turn it is to move .",
    "( note that this can not be done in positions where the side to move is in check , since the resulting position would be illegal .",
    "also , two null - moves in a row are forbidden , since they result in nothing . ) a regular search is then conducted with reduced depth @xmath1 .",
    "the returned value of this search can be treated as a lower bound on the position s strength , since the value of the best ( legal ) move has to be better than that obtained from the null - move search . in a negamax framework ,",
    "if the returned value is greater than or equal to the current upper bound ( i.e. , @xmath2 ) , it results in a cutoff ( fail - high ) .",
    "otherwise , if the value is greater than the current lower bound ( i.e. , @xmath3 ) , we define a narrower search window , as the returned value becomes the new lower bound .",
    "if the value is smaller than the current lower bound , it does not contribute to the search in any way .",
    "the main benefit of the null - move concept is the pruning obtained due to the cutoffs , which take place whenever the returned value of the null - move search is greater than the current upper bound .",
    "thus , the best way to apply null - move pruning is by conducting a minimal - window null - move search around the current upper bound @xmath4 , since such a search will require a reduced search effort to determine if a cutoff takes place .",
    "donninger was the first to suggest an adaptive rather than a fixed value for @xmath1 .",
    "experiments conducted by heinz in his article on adaptive null - move pruning showed that , indeed , an adaptive rather than a fixed value could be selected for the reduction factor . by using @xmath5 in upper parts of the search tree and @xmath6 in its lower parts ( close to the leaves )",
    "pruning can be achieved at a smaller cost ( as null - move searches will be shallower in comparison to using a fixed reduction value of @xmath6 ) while maintaining the overall tactical strength .",
    "an in - depth review of null - move pruning and our _ extended null - move reductions _ improvement can be found in @xcite .    over the years many variations of null - move pruning",
    "have been suggested , but the set of key parameters to be determined has remained the same .",
    "these parameters are : ( 1 ) the reduction value @xmath1 , ( 2 ) the boolean adaptivity variable , and ( 3 ) the adaptivity depth for which the decremented value of @xmath1 is applied .",
    "futility pruning and extended futility pruning @xcite suggest pruning nodes near a leaf where the sum of the current static evaluation value and some threshold ( e.g. , the value of a knight ) is smaller than @xmath0 . in these positions , assuming that the value gained in the remaining moves until reaching the leaf is not greater than the threshold , it is safe to assume that the position is `` weak enough '' , i.e. , that it is worth pruning ( as its score will not be greater than @xmath0 ) .",
    "naturally , the larger the threshold , the safer it is to apply futility pruning , although fewer nodes will be pruned .",
    "the main parameters to be set for futility pruning are : ( 1 ) the futility depth and ( 2 ) the futility thresholds for various depths ( usually up to a depth of 3 plies ) .",
    "bjrnsson and marsland s multi - cut pruning suggests searching the moves at a given position to a shallower depth first , such that if several of them result in a cutoff , the current node is pruned without conducting a full depth search .",
    "the idea is that if there are several moves that produce a cutoff at a shallower depth , there is a high likelihood that at least one of them will produce a cutoff if searched to a full depth . in order to apply",
    "multi - cut pruning only to potentially promising nodes , it is applied only to cut - nodes ( i.e. , nodes at which a cutoff has occurred previously , according to a hash table indication ) .",
    "the primary parameters that should be set in multi - cut pruning are : ( 1 ) the depth reduction value , ( 2 ) the depth for which multi - cut is applied , ( 3 ) the number of moves to search , and ( 4 ) the number of cutoffs to require .      selective extensions @xcite are used for extending potentially critical moves to be searched deeper .",
    "the following is a list of major extensions used in most programs :    * check extension : * extend the move if it checks the opponent s king . + * one - reply extension : * extend the move if it is the only legal move . + * recapture extension : * extend the move if it is a recapture of a piece captured by the opponent ( such moves are usually forced ) . + * passed pawn extension : * extend the move if it involves moving a passed pawn ( usually to 7th rank ) . + * mate threat extension : * extend the move",
    "if the null - move search returns a mate score ( the idea is that if doing a null - move results in being checkmated , a potential danger lies at the horizon , so we extend the search to find the threat ) .    for each of the above extensions ,",
    "fractional extensions have been widely employed .",
    "these are implemented usually by defining one ply to be a number greater than one ( e.g. , 1 ply = 4 units ) , such that several fractional extensions along a line ( i.e. , a series of moves from the root to a leaf ) cause a full ply extension . for example , if a certain extension is defined as half a ply , two such extensions must occur along a line in order to result in an actual full ply extension .",
    "for each extension type , a value is defined ( e.g. , assuming that 1 ply = 4 units , an extension has a value between 0 to 4 ) .    from this brief overview of selective search",
    ", there are a number of parameters for each method which have to be set and tuned . currently , top tournament - playing programs use manually tuned values which take years of trial and improvement to fine tune . in the next section we review the limited success of past attempts at automatic learning of the values of these search parameters , and in section 4 we present our ga - based method for doing so .",
    "the selective search methods covered in the previous section are employed by most of the current top tournament - playing chess programs .",
    "they use manually tuned parameter values that were arrived at after years of experiments and manual optimizations .    past",
    "attempts at automatic optimization of search parameters have resulted in limited success .",
    "moriarty and miikkulainen used neural networks for tuning the search parameters of an othello program , but as they mention in their paper , their method is not easily applicable to more complex games such as chess .",
    "temporal difference learning has been successfully applied in backgammon and checkers @xcite .",
    "although the latter has also been applied to chess @xcite , the results show that after three days of learning , the playing strength of the program was only 2150 elo , which is a very low rating for a chess program .",
    "et al . _   reported that using reinforcement learning , their chess program achieves a playing strength of only 2016 elo .",
    "s work on bootstrapping from game tree search improved upon previous work , but their resulting chess program reached a performance of between 2154 to 2338 elo , which is still considered a very low rating for a chess program .",
    "kocsis and szepesvri s work on universal parameter optimization in games based on spsa does not provide any implementation for chess .",
    "bjrnsson and marsland presented a method for automatically tuning search extensions in chess .",
    "given a set of test positions ( for which the correct move is predetermined ) and a set of parameters to be optimized ( in their case , four extension parameters ) , they tune the values of the parameters using gradient - descent optimization .",
    "their program processes all the positions and records , for each position , the number of nodes visited before the solution is found .",
    "the goal is to minimize the total node count over all the positions . in each iteration of the optimization process",
    ", their method modifies each of the extension parameters by a small value , and records the total node count over all the positions .",
    "thus , given @xmath7 parameters to optimize ( e.g. , @xmath8 ) , their method processes in each iteration all the positions @xmath7 times .",
    "the parameter values are updated after each iteration , so as to minimize the total node count .",
    "bjrnsson and marsland applied their method for tuning the parameter values of the four search extensions : check , passed pawn , recapture , and one - reply extensions .",
    "their results showed that their method optimizes fractional ply values for the above parameters , as the total node count for solving the test set is decreased .",
    "despite the success of this gradient - descent method for tuning the parameter values of the above four search extensions , it is difficult to use it efficiently for optimizing a considerably larger set of parameters , which consists of all the selective search parameters mentioned in the previous section .",
    "this difficulty is due to the fact that unlike the optimization of search extensions for which the parameter values are mostly independent , other search methods ( e.g. , multi - cut pruning ) are prone to a high interdependency between the parameter values , resulting in multiple local maxima in the search space , in which case it is more difficult to apply gradient - descent optimization .    in the next section we present our method for automatically tuning all the search parameters mentioned in the previous section by using genetic algorithms",
    "in david - tabibi _ et al . _",
    "we showed that genetic algorithms ( ga ) can be used to efficiently evolve the parameter values of a chess program s evaluation function . here",
    "we present a ga - based method for optimizing a program s search parameters .",
    "we first describe how the search parameters are represented as a chromosome , and then discuss the details of the fitness function .",
    "the parameters of the selective search methods which were covered in section 2 can be represented as a binary chromosome , where the number of allocated bits for each parameter is based on a reasonable value range of the parameter .",
    "table  [ tab : chromosome ] presents the chromosome and the range of values for each parameter ( see section 2 for a description of each parameter ) .",
    "note that for search extensions fractional ply is applied , where 1 ply @xmath9 4 units ( e.g. , an extension value of 2 is equivalent to half a ply , etc . ) .",
    ".chromosome representation of 18 search parameters ( length : 70 bits ) . [ cols=\"<,^,^\",options=\"header \" , ]     the results of the matches show that the evolved parameters of evol * perform on par with those of falcon , which have been manually tuned and refined for the past eight years .",
    "note that the performance of falcon is by no means a theoretical upper bound for the performance of evol * , and the fact that the automatically evolved program matches the manually tuned one over many years of world championship level performance , is by itself a clear demonstration of the capabilities achieved due to the automatic evolution of search parameters .",
    "the results further show that evol * outperforms crafty , not only in terms of solving more tactical test positions , but more importantly in its overall strength .",
    "these results establish that even though the search parameters are evolved from scratch ( with randomly initialized chromosomes ) , the resulting organism outperforms a grandmaster - level chess program .",
    "in this paper we presented a novel method for automatically tuning the search parameters of a chess program . while past attempts yielded limited success in tuning a small number of search parameters , the method presented here succeeded in evolving a large number of parameters for several search methods , including complicated interdependent parameters of forward pruning search methods .",
    "the search parameters of the falcon chess engine , which we used for our experiments , have been manually tuned over the past eight years .",
    "the fact that ga manages to evolve the search parameters automatically , such that the resulting performance is on par with the highly refined parameters of falcon is in itself remarkable .",
    "note that the evolved parameter sets are not necessarily the best parameter sets for every chess program .",
    "undoubtedly , running the evolutionary process mentioned in this paper on each chess program will yield a different set of results which are optimized for the specific chess program .",
    "this is due to the fact that the performance of the search component of the program depends on other components as well , most importantly the evaluation function .",
    "for example , in a previous paper on _ extended null - move pruning _",
    "@xcite , we discovered that while the common reduction value for null - move pruning is @xmath6 or @xmath5 , a more aggressive reduction value of adaptive @xmath10 performs better for falcon .",
    "it is interesting to note that our ga - based method managed to independently find that these aggressive reduction values work better for falcon .",
    "y. bjrnsson and t.a .",
    "marsland ( 1998 ) .",
    "multi - cut pruning in alpha - beta search . in _ proceedings of the first international conference on computers and games",
    "_ , pages 1524 , tsukuba , japan , november 1998 .",
    "o. david - tabibi , m. koppel , and n.s .",
    "netanyahu ( 2008 ) .",
    "genetic algorithms for mentor - assisted evaluation function optimization . in _ proceedings of the 2008 genetic and evolutionary computation",
    "conference _ , pages 14691476 .",
    "atlanta , ga , july 2008 .",
    "o. david - tabibi and n.s .",
    "netanyahu ( 2008 ) . extended null - move reductions . in _ proceedings of the 6th international conference on computers and games _ , eds .",
    "van den herik , x. xu , z. ma , and m.h.m .",
    "winands , pages 205216 .",
    "springer ( lncs 5131 ) , beijing , china , october 2008 .",
    "o. david - tabibi , h.j .",
    "van den herik , m. koppel , and n.s .",
    "netanyahu ( 2009 ) . simulating human grandmasters : evolution and coevolution of evaluation functions . in _ proceedings of the 2009 genetic and evolutionary computation conference _ , pages 14831489 .",
    "montreal , canada , july 2009 .",
    "o. david - tabibi , m. koppel , and n.s .",
    "netanyahu ( 2010 ) .",
    "expert - driven genetic algorithms for simulating evaluation functions .",
    "_ genetic programming and evolvable machines _",
    ", accepted for publication ( online version available at www.springerlink.com/content/3346t8432n718821 ) .",
    "d.e . moriarty and r. miikkulainen ( 1994 ) .",
    "evolving neural networks to focus minimax search . in _ proceedings of the 12th national conference on artificial intelligence _ ,",
    "pages 13711377 .",
    "seattle , wa , july 1994 .",
    "j. schaeffer , m. hlynka , and v. jussila ( 2001 ) .",
    "temporal difference learning applied to a high - performance game - playing program . in _ proceedings of the 17th international joint conference on artificial intelligence _ ,",
    "pages 529534 .",
    "seattle , wa , august 2001 .",
    "j. veness , d. silver , w. uther , and a. blair ( 2009 ) .",
    "bootstrapping from game tree search .",
    "_ advances in neural information processing systems 22 _ , eds .",
    "y. bengio , d. schuurmans , j. lafferty , c.k.i .",
    "williams , and a. culotta ."
  ],
  "abstract_text": [
    "<S> in this paper we introduce a novel method for automatically tuning the search parameters of a chess program using genetic algorithms . </S>",
    "<S> our results show that a large set of parameter values can be learned automatically , such that the resulting performance is comparable with that of manually tuned parameters of top tournament - playing chess programs . </S>"
  ]
}