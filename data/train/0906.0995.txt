{
  "article_text": [
    "the accurate estimation of redshifts from photometric data is a key component to fulfilling the promise of next - generation cosmological surveys .",
    "for instance , photometry to @xmath4 30 is expected for billions of galaxies from the large synoptic survey telescope ( lsst ; @xcite ) alone ; compare this to , e.g. , the @xmath5 10@xmath6 spectra collected to a depth @xmath4 24 by the deep2 galaxy redshift survey ( @xcite , @xcite ) .",
    "it is clear that redshift - dependent analyses of galaxies that aim to undercover signatures of , e.g. , weak lensing or baryon acoustic oscillations in imaging data will require the use of photometric redshifts .",
    "redshifts estimated via , e.g. , @xmath3 photometry will necessarily lack the precision of those that are spectroscopically derived due to noise , outliers , weak spectral features , and incomplete spectral energy distribution ( sed ) templates . for this reason ,",
    "one major goal of photometric redshift estimation is to generate accurate ensembles of estimates , i.e. , to have the mean redshift within a photometric redshift bin be an accurate estimator of true redshift ( see , e.g. , @xcite , @xcite ) .",
    "such ensembles are typically generated via one of two methods : either template fitting , wherein redshifted sed templates are generally compared to a given vector of magnitudes with the goal of minimizing the @xmath7 statistic or maximizing the likelihood ( e.g. , @xcite , @xcite , @xcite ) , or empirical methods , wherein one uses photometry from a small collection of objects with spectroscopically confirmed redshifts to train a model relating photometric colours to redshifts ( e.g. , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ) .",
    "some combine the two approaches ( e.g. , @xcite , @xcite ) , while others propose folding in information beyond photometric colours ( e.g. , @xcite , @xcite , @xcite , @xcite ) .    in this paper",
    "we propose a new empirical method for photometric redshift estimation based on the diffusion map ( @xcite , @xcite ) , which is an approach to _ spectral connectivity analysis ( sca)_. sca is a suite of established non - linear eigen - techniques that capture the underlying geometry of data by propagating local neighborhood information through a markov process .",
    "sca thus allows one to find a natural coordinate system for data such as photometric colours whose original parametrization is not amenable to available statistical techniques . in @xcite and @xcite",
    ", we apply the diffusion map to two different astronomical problems . in @xcite",
    ", we develop a framework combining diffusion map and adaptive linear regression and apply it to sdss spectroscopic data , demonstrating how it may be used to reduce the dimensionality of the data space and to predict , e.g. , redshifts in a computationally efficient manner .",
    "we also demonstrate the superiority of the diffusion map to principal components analysis , a related , much more commonly used linear technique . in @xcite , we utilize the diffusion map and the k - means clustering algorithm to determine optimal bases of simple stellar population spectra that we use to estimate the star - formation histories of galaxies .",
    "in  [ sect : alg ] , we review the basics of our diffusion map and regression framework , and introduce a new component : the application of the nystrm extension ( see , e.g. , @xcite ) , a computationally efficient and accurate technique for estimating diffusion coordinates for new objects given those of the training set . in  [ sect : apply ] , we apply our framework to sloan digital sky survey data , specifically main sample galaxies ( msgs ) and luminous red galaxies ( lrgs ) , and demonstrate that we achieve accuracy on par with that of more computationally intensive techniques .",
    "we also apply our framework to data from the deep2 galaxy redshift survey that is matched to @xmath3 photometry of the canada - france - hawaii telescope legacy survey ( cfhtls ; @xcite ) and demonstate that it provides accurate estimation of redshifts to @xmath8 given four colours alone .",
    "we demonstrate that the bivariate distributions of photometric and spectroscopic redshifts for sdss and deep2 are affected by attenuation bias , the tendency of measurement error in the predictor to reduce the slope of linear models .",
    "last , in ",
    "[ sect : summary ] , we summarize our results and discuss how we can extend our framework to the high redshift regime where spectroscopic coverage will be incomplete .",
    "in this section we review the basics of diffusion map construction , an approach to sca . for more details ,",
    "we refer the reader to @xcite , @xcite , and @xcite . in @xcite ,",
    "we compare and contrast the use of diffusion maps with a more commonly utilized linear technique , principal components analysis , and demonstrate the superiority of diffusion maps in predicting spectroscopic redshifts of sdss data from the galaxy spectra .",
    "here,``spectral connectivity analysis '' refers to a class of methods which utilize a local distance measure to `` connect '' similar observations .",
    "the eigenmodes ( i.e. , `` spectral decomposition '' ) of the rescaled matrix of similarities ( see below for the definition of this matrix ) can reveal a natural coordinate system for data that was absent in the original representation .",
    "for instance , imagine data in two dimensions that to the eye clearly exhibit spiral structure ( e.g. , fig . 1 of @xcite ) .",
    "for such data , the euclidean distance between data points @xmath9 and @xmath10 would not be an optimal description of the ` true ' distance between them along the spiral .",
    "diffusion map is a leading example of an approach to sca . in the diffusion map framework ,",
    "the ` true ' distance is estimated via a fictive diffusion process over the data , with one proceeding from @xmath9 to @xmath10 via a random walk along the spiral .",
    "we construct diffusion maps as follows .",
    "we define a similarity measure @xmath11 that quantitatively relates two data points @xmath9 and @xmath10 . in this work ,",
    "a data ` point ' is a vector of colours \\{@xmath12 } of length @xmath0 for a single galaxy , and the similarity measure that we apply is the euclidean distance @xmath13 a key feature of sca is that the choice of @xmath11 is not crucial , as it is often simple to determine whether or not two data points are ` similar . '",
    "we remove extreme outliers from our dataset , not because of their effect on diffusion map construction ( a hallmark of the diffusion map is its robustness in the presence of outliers ) , but rather because they can bias the coefficients of the linear regression model ( see  [ sect : regress ] ) and because we find that individual predictions made for these objects are highly inaccurate .",
    "we compute the empirical distributions of euclidean distances in colour space from each object to its @xmath14 nearest neighbor , where @xmath15 $ ] .",
    "these distributions are well - described as exponential , with estimated mean and standard deviation @xmath16 for median value @xmath17 .",
    "we exclude all data whose @xmath14 nearest neighbor is at a distance @xmath18 , for any value of @xmath15 $ ] .",
    "we find that @xmath19 80% of extreme outliers are removed with the first nearest - neighbor cut alone , with the fraction of those removed falling as @xmath20 increases .    with outliers removed ,",
    "we construct a weighted graph where the nodes are the observed data points : @xmath21 where @xmath22 is a tuning parameter that should be small enough that @xmath23 unless @xmath9 and @xmath10 are similar , but large enough such that the graph is fully connected .",
    "( we discuss how we estimate @xmath22 in  [ sect : regress ] . )",
    "the probability of stepping from @xmath9 to @xmath10 in one step is @xmath24 .",
    "we store the one - step probabilities between all @xmath20 data points in an @xmath25 matrix ; then , by the theory of markov chains , the probability of stepping from @xmath9 to @xmath10 in @xmath26 steps is given by the element @xmath27 of the matrix @xmath28 .",
    "the diffusion distance between @xmath9 and @xmath10 at time @xmath26 is defined as @xmath29 where @xmath30 and @xmath31 represent eigenvectors and eigenvalues of , respectively . by retaining the @xmath32 eigenmodes corresponding to the @xmath32 largest nontrivial eigenvalues and by introducing the diffusion map @xmath33 \\label{eqn : diffusion_map}\\ ] ] from @xmath34 to @xmath35",
    ", we have that @xmath36 i.e. , the euclidean distance in the @xmath32-dimensional embedding defined by equation  [ eqn : diffusion_map ] approximates diffusion distance .",
    "( we discuss how we estimate @xmath32 in  [ sect : regress ] , and show that , in this work , the choice of @xmath26 is unimportant . )",
    "we stress that the diffusion map reparametrizes the data into a coordinate system that reflects the connectivity of the data , and does not necessarily affect dimension reduction",
    ". if the original parametrization in @xmath34 is sufficiently complex , then it may be the case that @xmath37 .",
    "as in @xcite , we perform linear regression to predict the function @xmath38 , where @xmath39 is true redshift and @xmath40 is a vector of diffusion coordinates in @xmath35 , representing a vector of photometric colours @xmath9 in @xmath34 : @xmath41 we see that the choice of the parameter @xmath26 is unimportant , as changing it simply leads to a rescaling in @xmath42 , with no change in @xmath43",
    ". we present relevant regression formulae in appendix [ sect : regform ] .",
    "we determine optimal values of the tuning parameters ( @xmath22,@xmath32 ) by minimizing estimates of the prediction risk , @xmath44 , where @xmath45 is the expected value of a loss function @xmath46 over all possible realizations of the data ( one example of @xmath46 is the so - called @xmath47 loss function , which is simply the mean - squared error of the fit ; see , e.g. , @xcite for a discussion of this and other topics introduced below ) .",
    "@xmath48 quantifies the ` bias - variance ' tradeoff : too much smoothing ( @xmath32 too low ) yields prediction estimators with low variance and high bias , while too little smoothing ( @xmath32 too high ) yields estimators with high variance and low bias . using the full data set to estimate @xmath48 underestimates the error and leads to a best - fit model with high bias , thus we apply @xmath49-fold cross - validation ( cv ) .",
    "the data are partitioned into 10 blocks of ( approximately ) equal size .",
    "we regress upon the data in nine of the blocks and use the best - fit regression model to predict the responses @xmath50 for the data in the tenth block .",
    "( we note that for algorithmic consistency we use the nystrm extension to estimate the diffusion coordinates of the data in the tenth block ; see  [ sect : nystrom ] . )",
    "the process is repeated 10 times , for different block combinations , so that predictions are generated for each datum .",
    "the individual predictions are combined into an overall risk estimate @xmath51 where we apply the redshift - corrected rms dispersion as our loss function .",
    "@xmath52 is the estimated spectroscopic redshift for object @xmath53 .",
    "( we capitalize to underscore the fact that the spectroscopic redshift is a random variable not necessarily equal to the true redshift @xmath54 . ) to ensure robustness , for each set of tuning parameters @xmath55 , we compute the mean @xmath56 of 10 estimates of @xmath57 , and select those values of @xmath55 such that @xmath56 is minimized , i.e. , @xmath58 .",
    "the computation of diffusion coordinates ( equation  [ eqn : diffusion_map ] ) relies upon eigen - decomposition , which is computationally intractable for datasets of @xmath59 10@xmath2 galaxies .",
    "( however , see @xcite , who propose an incremental methodology for computing eigenvectors . )",
    "photometric datasets can , of course , be much larger , and thus we require a computationally efficient scheme for estimating eigenvectors for new galaxies given those computed for a small set of galaxies used to train the regression model . a standard method in applied mathematics for ` extending ' a set of eigenvectors is the nystrm extension .",
    "the implementation is simple : determine the distance in colour space from each new galaxy to its nearest neighbors in the training set , then take a weighted average of those neighbors eigenvectors .",
    "let represent the @xmath60 matrix containing the colour data of the training set , where @xmath20 and @xmath61 are the number of objects and colours , respectively .",
    "let represent a similar @xmath62 matrix containing colour data for @xmath63 objects in the validation set .",
    "the first step of the nystrm extension is to compute the @xmath64 weight matrix , with elements equivalent to those shown in equation  [ eqn : weighted ] above ( except that there , @xmath9 and @xmath10 are both members of the training set , while here , @xmath9 is a new point while @xmath10 belongs to the training set ) .",
    "we assume the same value @xmath65 as was selected during diffusion map construction ; since the training set is a random sample of galaxies from our original set , we expect the validation set to be sampled from the same underlying probability distribution .",
    "we row - normalize by dividing by each element in row @xmath66 by @xmath67 .",
    "let @xmath68 be the @xmath69 matrix of eigenvectors with corresponding vector of eigenvalues @xmath70 . to estimate the eigenvectors for the new galaxies , we compute the @xmath71 matrix @xmath72 : @xmath73 where @xmath74 is a @xmath75 diagonal matrix with entries @xmath76 .",
    "then the redshift predictions for the @xmath63 objects are @xmath77 , where @xmath78",
    "are the linear regression coefficients generated for the original training set .",
    "in this work , we use the princeton / mit reductions of sdss spectroscopic data .",
    "features of these data include the so - called ` uber - calibration ' of @xmath3 magnitudes in six magnitude systems ( @xcite ) . to facilitate a direct comparison of our results with those of @xcite , we utilize colours , i.e. , differences between the magnitudes measured in different bands determined in each of four magnitude systems : _ psf _ , _ fiber _ , _ petrosian _ , and _",
    "model_. thus the colour data occupy a @xmath0 = 16 dimensional space .",
    "the necessary data are contained in the files spall-@xmath79rel@xmath80.fits , where @xmath79rel@xmath80 = edr and dr1@xmath81dr6 .",
    "we extract data from all publicly available plates for which progname = ` main ' and platequality = ` good , ' keeping 1001 plates in all .",
    "( we keep only one instance of each plate when repeated observations are made , making the ad hoc choice to retain the most recent observation . ) for each plate , we examine data for those fibers for which class = ` galaxy , ' z @xmath80 0.01 , and zwarning = 0 . for each of these fibers ,",
    "we apply extinction corrections \\{@xmath82 } ( from column extinction ) to the set of fluxes @xmath83 and the set of estimated standard errors @xmath84 ( @xcite ) : @xmath85 if for any object , one or more elements of the set @xmath86 , we exclude the object from analysis .",
    "the flux units are nanomaggies ; the conversion from @xmath87 to magnitude @xmath88 is @xmath89 , while the conversion to colours is @xmath90 .    the final number of galaxies in our sample is 417,224 .      from our data sample ,",
    "we extract those 360,122 galaxies with petrosian @xmath91-band magnitude @xmath92 ( or @xmath93 77.983 ; @xcite ) .",
    "this is our main sample galaxy or msg sample .",
    "we randomly select 10,000 galaxies from this sample to train our regression model .",
    "application of the outlier - removal algorithm described in ",
    "[ sect : regress ] leads to the removal of 251 galaxies from this set .",
    "the application of the algorithm outlined in   2.1 - 2 yields tuning parameter estimates ( @xmath94 ) = ( 0.05,150 ) , i.e. , in order for a linear model to be appropriate , the 16-dimensional colour data is reparametrized into 150-dimensional space .    as each object",
    "s eigenvector estimates are independent of those for other objects , we apply the nystrm extension to validation set objects one plate at a time , then concatenate the resulting predictions .",
    "we determine which members of the validation set are 5@xmath95 outliers relative to the members of the training set , and compute the value of @xmath96 with those objects excluded .",
    "( not excluding these outliers , which lie too far from the training set in colour space for their diffusion coordinates to be estimated accurately , results in @xmath96 rising from @xmath19 0.02 to 0.56 . ) out of 350,122 objects in the validation set , we exclude 9,133 ; the percentage of outliers is 2.61% .",
    "this is consistent with the 2.51% rate of outliers in the training set .",
    ".parameters of optimal regression [ cols=\"<,^,^,^,^,^\",options=\"header \" , ]     in the column ` dataset , ' t = training set and v = validation set .",
    "@xmath97 is the rate of catastrophic failures ( i.e. , the rate at which @xmath98 ) , @xmath20 is the number of galaxies used in analysis after outlier removal , and @xmath99 is the number of 5@xmath95 outliers removed from sample .",
    "the number ( outside / inside ) the parantheses in column @xmath100 ( includes / does not include ) normalization by @xmath101 .",
    "@xmath102-band data are excluded from lrg analyses . for _ deep2-t _ , the first and second rows represent analyses of objects for which zquality = 4 and zquality @xmath103 3 , respectively . [",
    "tab : results ]    we show our results in table [ tab : results ] and the top panel of fig .",
    "[ fig : sdss ] , in which we display predictions for 10,000 randomly chosen objects of the validation set .",
    "the accuracy of prediction via the nystrm extension versus directly fitting a linear regression model to the diffusion map coordinates of the data is indicated in table [ tab : results ] .",
    "we find that @xmath96 increases by 2.4% from 0.0206 to 0.0211 , with catastrophic failure rate @xmath97 increasing but still small .",
    "( here , a catastrophic failure for object @xmath53 is defined as @xmath104 0.15 ; see equation [ eqn : rcv ] and , e.g. , @xcite . )",
    "the small degradation in accuracy is more than balanced by computational speed ; our naive implementation allowed extension to 350,373 galaxies in @xmath5 10 cpu hours on a single ghz processor , a computation time that will be markedly reduced in future implementations of the algorithm .",
    "@xmath96 = 0.0211 ( 0.0240 without normalization by @xmath105 ) compares favorably with a myriad of other analyses of msg data ( see , e.g. , @xcite , who obtain @xmath95 = 0.0207 without @xmath105 normalization , and references therein ) , and the empirical bivariate distribution of @xmath106 is visually indistinguishable from those of , e.g. , @xcite and @xcite .     = ( 0.05,150 ) .",
    "bottom : same as top , for the lrg validation set , with @xmath107 = ( 0.012,200 ) . in both cases , we remove 5@xmath95 outliers from the sample prior to plotting , thus the actual number of plotted points is 9,740 ( top ) and 9,579 ( bottom ) . , width=317 ]     for msg redshift estimates @xmath108 , computed in bins of width @xmath109 = 0.01 in the range @xmath110 $ ] .",
    "top right : estimated standard deviation for msg redshift estimates ( normalized by @xmath105 ) .",
    "middle left and right : same as top left and right , except for lrg redshift estimates in bins of width @xmath109 = 0.02 in the range @xmath111 $ ] . bottom left and right : same as top left and right , except for deep2 redshift estimates ( zquality = 4 ) in bins of width @xmath109 = 0.05 in the range @xmath112 $ ] .",
    ", width=317 ]    we determine estimator bias by binning the predictions @xmath108 as a function of @xmath113 , then in each bin computing @xmath114 , with @xmath115 being a 10% trimmed mean .",
    "see the top left panel of fig .  [",
    "fig : bias ] .",
    "it is readily apparent that there is a downward slope in the bias ( i.e. , redshifts are overestimated at low @xmath113 , and underestimated at high @xmath113 ) .",
    "this is not caused by model bias ( a bias that one would mitigate by adding complexity to the model , e.g. , changing from linear to quadratic regression ) , but rather by _ attenuation bias _",
    ", in which measurement error ( i.e. , uncertainty in the predictor , in this case the diffusion coordinates ) reduces the slope of the regression line ( see fig .",
    "[ fig : atten ] ; see also , e.g. , @xcite ) .    , where @xmath116 , i.e. , each value of @xmath117 is sampled from a gaussian distribution with mean @xmath118 and variance 0.04 .",
    "the black dots indicate the observed data , while the open circles show the true @xmath119 values .",
    "right : same as left , but with measurement error applied to the predictor : @xmath120 .",
    "the effect of this measurement error is to reduce the slope of the regression line , on average .",
    "the mean reduction in slope for this toy example is 0.25 ( from 1 to 0.75 ) , as estimated via 10,000 simulations .",
    ", width=317 ]    to demonstrate that our data are affected by attenuation bias , we perform a simple experiment .",
    "first , we take the msg training set fluxes and resample them according to the prescription given in appendix [ sect : sample ] .",
    "this increases all measurement errors .",
    "( to see this intuitively , imagine sampling random variables @xmath121 , i.e. , each value of @xmath122 is sampled from a gaussian distribution with mean 0 and variance 1 .",
    "then resample from the observed values @xmath122 : @xmath123 .",
    "the standard deviation of the resulting sample is now @xmath124 , i.e. , the error has been artificially increased by resampling . )",
    "then we resample fluxes for 1,000 randomly selected validation set objects . by doing each resampling ( training set and validation set ) 25 times , we build up a set of 625 predictions of @xmath108 for each of the 1,000 selected objects . following the same prescription as",
    "above , we estimate the bias ; the top panel of fig . [",
    "fig : comp_bias ] shows how for the msg dataset , increasing the measurement error via resampling leads to a steepening of the bias slope , i.e. , the effect of attenuation bias is magnified .",
    "there exist methods for correcting the bias in linear regression coefficient estimation caused by additive , heteroscedastic ( i.e. , non - constant ) measurement errors of known magnitude that are based on the simex , or simulation - extrapolation , algorithm ( @xcite ; see , e.g. , @xcite and references therein ) . indeed , one of the advantages to our approach is that the non - linearity is in the reparametrization , not the fitted model .",
    "hence , available methods for correcting for measurement error could be utilized .",
    "we are currently exploring the implementation of simex - based methods in a computationally efficient manner , and we will present our results in a future publication",
    ".     induced by resampling msg training and validation set fluxes and refitting . because resampling increases the measurement error ( i.e.",
    ", the error in the predictor , in this case the diffusion coordinates ) , the slope of the regression line is reduced , increasing overestimates of @xmath108 at low @xmath113 and underestimates of @xmath108 at high @xmath113 .",
    "bottom : same as top , for lrg datasets .",
    ", width=317 ]    while attenuation bias is caused by measurement error , its magnitude is affected by the distribution of the predictors , i.e. , the design .",
    "expressions relating the design to the bias magnitude are highly problem dependent . in the simplest , one - dimensional example of attenuation bias ,",
    "the predictors are assumed to be normally distributed@xmath125and the effect on the slope @xmath126 is to reduce its value : @xmath127 , where @xmath128 and @xmath129 is the measurement error .",
    "the smaller the value of @xmath130 , the greater the effect upon the bias .",
    "we mention this explicitly to underscore that analyzing samples for which the predictors are , e.g. , uniformly distributed may reduce the magnitude of the bias magnitude but will not eliminate it since measurement error is still present . in fig .",
    "[ fig : bias_unif ] , we show the estimated sample bias as a function of @xmath113 for a 10,000-galaxy sample constructed so as to be uniform in @xmath113 ( though the distribution of the predictors themselves",
    " the diffusion coordinates  is not necessarily uniform ) . comparing these results with the top panels of fig .",
    "[ fig : bias ] , we find that uniformity in @xmath113 reduces the bias slightly ( while also slightly increasing sample standard deviation ) .",
    "this indicates that measurement error is the dominant cause of the observed bias .",
    "for msg redshift estimates @xmath108 , computed in bins of width @xmath109 = 0.01 in the range @xmath110 $ ] , for a 10,000-galaxy sample constructed so as to be uniform in @xmath113 .",
    "uniformity in @xmath113 reduces the bias slightly ( cf .",
    "the top panel of fig .",
    "[ fig : bias ] ) .",
    "this result indicates that measurement error is the dominant cause of the bias .",
    "right : estimated standard deviation for msg redshift estimates ( normalized by @xmath105 ) .",
    ", width=317 ]    nonparametric estimators such as k - nearest neighbor ( knn ) and local polynomial regression are also affected by measurement error bias ( whose mitigation is dubbed the  deconvolution problem \" ) and design bias , and in addition by boundary bias ( see , e.g. , chapter 5 of @xcite and chapter 12 of @xcite and references therein ) . thus the similarity of our bivariate distribution to that of , e.g. , @xcite ( see their fig .  6 . in this figure , we note slightly larger deviations from the @xmath131 locus at the endpoints than our bivariate distribution exhibits , which may indicate boundary bias but also could be a result of the fact that @xcite do not minimize risk and thus could be adopting a solution with relatively higher bias and lower variance than our solution . )    in addition to estimator bias , we also examine the estimator variance , i.e. , the width of the observed bivariate distribution ( given as a function of @xmath113 in the right column of fig .",
    "[ fig : bias ] ) .",
    "contributing to the variance is ( a ) model uncertainty , i.e. , the standard deviation of the estimates @xmath108 ( given by the square root of the diagonal elements of the matrix given in equation  [ eqn : vy ] ) ; ( b ) uncertainty in the flux for each object ; and ( c ) intrinsic scatter , i.e. , the fact that the msg sample does not necessarily contain a homogeneous set of objects .",
    "model uncertainty contributes little to the observed scatter ; the mean , median , and standard deviation of the model uncertainties are @xmath1 10@xmath132 .",
    "flux uncertainty enters via attenuation bias ; as flux errors increase , the linear regression slope flattens and acts to decrease the sample variance within a redshift bin .",
    "however , in our simple attenuation - bias demonstration we observe only negligible changes in the sample variance .",
    "thus we conclude that the observed sample variance is primarily due to intrinsic scatter , and can only be reduced by introducing more data ( cf .",
    "@xcite , who achieve @xmath133 0.01 by utilizing data from 30 bands in the uv , optical , and ir regimes ) .      from our data sample ,",
    "we extract those 30,700 galaxies for which @xmath134 and primtarget = 32 ( targetgalaxyred ; @xcite ) .",
    "this is our luminous red galaxy or lrg sample . as with the msg training set",
    ", we randomly select 10,000 galaxies and then remove outliers . because the @xmath102 band data of high - redshift lrgs lacks",
    "constraining power ( as lrgs are faint in @xmath102 and thus the magnitudes are noisy ) , we use only @xmath135 fluxes in analyses ( so that @xmath0 = 12 ) .",
    "the training set contains 9,734 objects .",
    "application of the algorithm outlined in ",
    " 2.1 - 2.2 yields tuning parameter estimates @xmath107 = ( 0.012,200 ) .",
    "the results of fitting are shown in table [ tab : results ] and the bottom panel of fig .",
    "[ fig : sdss ] . as in the case of the msg analysis , our value @xmath96 = 0.0195 ( 0.0270 without @xmath105 normalization ) compares favorably with , e.g. , @xcite , who achieve @xmath95 = 0.0242 ( without @xmath105 normalization ) , and references therein .",
    "we find that the outlier rate is consistent from training set to validation set ( increasing from 2.7% to 3.1% ) , and that @xmath96 increases by only 3.1% when we use the nystrm extension as opposed to directly fitting the data .",
    "( note that if we include the @xmath102 band , the estimate of @xmath65 increases by two orders of magnitude , indicating the scatter in colour space introduced by non - constraining @xmath102-band data , although @xmath96 itself only rises by @xmath19 5% . )",
    "the lrg redshift predictions , like their msg counterparts , are biased , with a similar downward trend in the bias as a function of @xmath113 ( left middle panel , fig .",
    "[ fig : bias ] ) .",
    "we repeat our simple resampling experiment with lrg data and find that the bias slope increases upon resampling , demonstrating that attenuation bias also affects lrg data analysis ( as expected ; see fig .",
    "[ fig : comp_bias ] ) .",
    "the deep2 galaxy redshift survey ( @xcite , @xcite ) studied both galaxy properties and large - scale structure primarily at redshifts @xmath136 , in four fields of total area @xmath5 3 square degrees .",
    "deep2 targets are selected to have @xmath137 24.1 using cfht bri photometric data ( @xcite ) . in three of the four deep2 fields ,",
    "colour cuts are used to select @xmath138 0.7 objects for observation ; however , in this paper we utilize the deep2 sample in the extended groth strip , for which no colour cuts have been applied .",
    "deep2 collected spectra typically covering the wavelength range 6,500@xmath819,100   for @xmath80 50,000 objects . from the survey we select the 6,552 galaxies",
    "for which single - system @xmath3 photometry exists from the cfht legacy survey ( field d3 ) and for which the deep2 zquality flag is either 3 or 4 ( @xmath80 95% or 99.5% confidence that the redshift is correct , respectively ) .",
    "thus the dimensionality of colour - space for these data is @xmath0 = 4 .",
    "we further remove data for which the redshift error , or any magnitude or magnitude error , is not provided , leaving 6,418 galaxies ; after outlier removal , the final sample size is 6,067 .",
    "if we restrict ourselves to data for which zquality = 4 , the sample size is 5,223 .",
    "application of the algorithm outlined in ",
    " 2.1 - 2.2 yields tuning parameter estimates @xmath107 = ( 0.002,850 ) for zquality = 4 and ( 0.002,1050 ) for zquality @xmath103 3 .",
    "we display our results in table [ tab : results ] and fig .",
    "[ fig : deep2 ] ; note that because we do not apply the nystrm extension here ( but rather , fit to the data directly after @xmath107 are determined ) , the observed scatter is smaller than we would observe with a larger , nystrm - extended dataset . in both cases ,",
    "we exclude 5.8% of the objects from analysis as outliers .     3 . for these data , @xmath107 = ( 0.002,1050 ) and @xmath96 = 0.0539",
    "bottom : same as top , for the 5,223 objects for which zquality = 4 ; @xmath107 = ( 0.002,850 ) and @xmath96 = 0.0507 .",
    ", width=317 ]    in fig .",
    "[ fig : deep2 ] , we observe that the quality of the fits below @xmath139 0.75 ( @xmath96 = 0.038 for zquality",
    "= 4 ) is superior to that at higher redshifts ( @xmath96 = 0.064 ) . to understand why this is so",
    ", we examine the deep2 colour data ( fig .",
    "[ fig : deep2colours ] ) .",
    "colours for the 5,223 objects in the deep2 training set for which zquality = 4 . , width=317 ]    pick an object at @xmath140 , and compute the euclidean distance in colour - space to a random object at any other redshift @xmath141 $ ] .",
    "this distance is a nearly constant function of @xmath109 ; thus for values of @xmath22 similar to those chosen in the sdss analyses , there is only a slightly lesser probability of diffusing from @xmath142 0.75 to , e.g. , @xmath142 0.2 as to , e.g. , @xmath142 0.74 . to achieve accurate predictions at @xmath140",
    ", @xmath22 must be made smaller ( lessening the probability of large @xmath109 jumps ) ; this is what our optimization yields .",
    "a consequence of a smaller @xmath65 is that the weighted graph of the deep2 objects is not fully connected ( see discussion around equation  [ eqn : weighted ] ) .",
    "one can discern connectedness by examining the vector of eigenvalues ; for @xmath65 = 0.002 , the first @xmath19 20 eigenvalues are all @xmath80 0.95 , implying the presence of several disconnected clumps on the graph .",
    "the most visually obvious manifestation of disconnectedness in the deep2 analysis is the presence of a marked knee in the predictions at @xmath139 0.75 for small values of @xmath32 ( see fig .",
    "[ fig : deep2ev ] ) ; the dominant eigenvectors describe the low redshift data well , but not the high redshift data .",
    "= 0.002 and @xmath32 = 40 ( top left ) , 100 ( top right ) , 400 ( bottom left ) , and 850 ( @xmath143 ; bottom right ) .",
    ", width=317 ]    as @xmath32 increases , the knee straightens out ; however , because of the bias - variance tradeoff , @xmath32 can only increase so much before @xmath96 begins to increase as well , due to increasing variance . for @xmath143 = 850 ( zquality = 4 ) we have not yet achieved an optimal description for the high - redshift data . to demonstrate that we can achieve a better description of these data , we split the full dataset into low- and high - redshift sets ( at , e.g. , @xmath144 = 0.9 ) and compute diffusion maps for each .",
    "we find that we can achieve , e.g. , @xmath145 0.035 for high - redshift data with as few as 40 eigenvectors , while the predictions at low redshifts change only slightly .",
    "while splitting the data yields better results for our deep2 sample , we do not propose such splitting as part of our general diffusion map framework , for multiple reasons : ( a ) it adds a tuning parameter ( @xmath144 ) , ( b ) it complicates the nystrm extension ( to which data split do we assign a new object ? ) , and most importantly ( c ) a data split can be rendered moot with the inclusion of new data in other bandpasses ( e.g. , the inclusion of near - ir data in the deep2 sample would mitigate the euclidean - distance issue seen at @xmath140 ) .    concentrating on the regime @xmath146 , we find that our result @xmath147 with @xmath148 1.1% compares favorably with that of @xcite , who train a template - based photometric redshift code using 2,867 spectroscopic redshifts from the vimos vlt deep survey ( vvds ) in the cfhtls d1 field and obtain @xmath149 and @xmath150 4% ( see their  6.3 and fig .",
    "our smaller catastrophic failure rate is presumably largely due to our removal of colour - space outliers prior to analysis .",
    "we note that @xcite perform a similar analysis with cfhtls @xmath39-band data removed , with the result that a marked knee appears at @xmath139 0.8 that is similar to what we observe in analyzing our intrinsically bluer deep2 sample .",
    "this supports the hypothesis that adding data from other bandpasses to our deep2 sample will lead to a marked improvement in fit at redshifts @xmath151 1 .",
    "in this paper we apply an eigenmode - based framework utilizing the diffusion map and linear regression to the problem of estimating redshifts given sdss and deep2/cfhtls @xmath3 photometry . because estimating diffusion map coordinates via eigen - decomposition limits the size of training sets to @xmath5 10@xmath2 objects , we implement the nystrm extension , which allows for computationally efficient estimation of diffusion coordinates with a relatively small degradation of accuracy .    for our sdss msg sample ,",
    "we train our linear regression model on 9,749 randomly selected objects and via the nystrm extension estimate redshifts for another 340,989 galaxies .",
    "since the nystrm extension is not robust to extreme outliers , we use a nearest - neighbor algorithm to eliminate 5@xmath95 outliers in colour space ; this eliminates @xmath19 2.5% of the msg sample .",
    "the loss in accuracy resulting from use of the nystrm extension is @xmath19 2.4% ( as compared with directly fitting the data of the training set ) . for our sdss lrg sample ,",
    "we train our regression model on 9,734 objects and via the nystrm extension estimate redshifts for another 20,082 , with an outlier rate @xmath19 3% and a degradation of accuracy @xmath19 3% .",
    "as the deep2/cfhtls sample has only @xmath19 6,000 objects ( with an outlier rate of @xmath19 5.8% ) , we do not define a validation set to check the accuracy of predictions generated via the nystrm extension .",
    "however , we will apply our regression model to a test set comprised of all galaxies in cfhtls fields d1-d4 and make that catalog publicly available .",
    "the observed bivariate distributions @xmath106 for our sdss datasets are similar to those computed by , e.g. , @xcite using annz ( specifically , for the sdss msg dataset ) and by @xcite using a numerically intensive nearest - neighbor algorithm ( for both the sdss msg and lrg datasets ) , with dispersion on par with those techniques ( @xmath152 ; see @xcite and references therein ) .",
    "these distributions indicate that redshifts are generally overestimated at low @xmath113 and underestimated at high @xmath113 .",
    "we demonstrate that this is a manifestation of attenuation bias , wherein measurement error ( uncertainty in the diffusion coordinates resulting from uncertainty in the sdss flux estimates ) reduces the measured slope of the regression line . in statistical parlance ,",
    "the measured slope is not a consistent estimator of the true slope . in order to use photometric redshift estimates in precision cosmology , it is vital that methods for producing consistent estimates ( i.e. , mitigating the bias ) be developed and implemented .",
    "we are exploring using the simex , or simulation - extrapolation , algorithm ( e.g. , @xcite ) to produce consistent estimates in a computationally efficient manner , and we will present our results in a future publication .    for the deep2 data , the dominant feature in the observed bivariate distribution , beyond attenuation bias , is a marked reduction in prediction accuracy at redshifts @xmath151 0.75 . we demonstrate that this is due to a degeneracy in the colour - space manifold that would be mitigated with the introduction of more data from other bandpasses .",
    "we note that we also can mitigate the effects of the degeneracy by splitting the training set into low- and high-@xmath113 samples , but we do not prefer this approach because of the complexity it adds to the prediction algorithm ( through the addition of a tuning parameter @xmath144 and the necessity of providing a quantitative measure for robustly choosing between the two predictions we would generate for each test object ) . at lower redshifts , we find that the observed bivariate distribution @xmath106 compares favorably with that derived by @xcite ( @xmath145 0.035 versus @xmath95 = 0.032 )",
    ".    our current statistical framework yields a single photometric redshift estimate for each object in the validation set , as opposed to a probability distribution function ( pdf ) for each estimate ( cf .",
    "this is a valid approach for analyzing , at the very least , the galaxies of the sdss sample that we consider in this work , as @xcite demonstrate that the pdfs in the low - redshift regime are approximately normal ; we expect our single estimates to match the pdf means .",
    "however , we would have to alter our framework if we were to analyze quasars , for which the pdfs are often bimodal ( e.g. , fig .  5 of @xcite ) .",
    "bimodality is an indication of ( near-)degeneracy in the colour - space manifold ; when its colours are perturbed , a quasar s nearest neighbor sometimes belongs to one range of redshifts , and sometimes to a completely different range . within our current framework",
    ", such a degeneracy would not affect the computation of the diffusion map , but the subsequent application of linear regression would yield inaccurate redshift estimates for those quasars in the vicinity of the degeneracy . for quasar analysis , we would explore a variety of options , which include ( a ) utilizing a different form of regression , ( b ) incorporating the response variables into the construction of the diffusion map ( @xcite ) , and/or ( c ) incorporating gradient information into diffusion map construction , such that nearby objects that lie along the manifold have higher similarity measures .",
    "such schemes would mitigate but not entirely lift the degeneracy and thus we would also have to quantify the relative probabilities of dual estimates .    in this work ,",
    "we demonstrate the efficacy of sca , in particular our diffusion map framework , for analyzing datasets for which the spectroscopic redshifts are known .",
    "the next step is to extend our framework such that it yields accurate photometric redshift estimates for objects in datasets where the spectroscopic coverage will be minimal , such as deep sky surveys ( e.g. , lsst ) or pointed surveys beyond @xmath153 . even with long exposure times , the deep2 galaxy redshift survey is only able to determine secure redshifts for @xmath5 70% of its objects , with about half the missed targets being star - forming galaxies at @xmath154 that have no features in deep2 spectral window ; cf .",
    "even when spectroscopic redshifts are available for a significant subset of these objects , it is likely that they will be gleaned from intrinsically luminous objects whose seds may not closely match those for fainter objects .",
    "thus it becomes imperative to fold additional information into analyses .",
    "@xcite , @xcite , and @xcite propose using structural properties such as surface brightness and angular radius to obtain more accurate redshift estimates ; however , this is of limited utility at higher redshifts .",
    "@xcite proposes that photometric redshifts can be calibrated using their correlations on the sky with objects of known redshift , as a function of that known redshift .",
    "a related idea would be to take into account the redshifts of nearby objects on the sky in estimating photometric redshifts ( @xcite ) ; because of the clustering of galaxies , there is a significant probability that two galaxies near each other on the sky are at very similar redshifts .    in a future work , we will fold additional quantities into our similarity measure and will determine if photometric redshift can be estimated with sufficient accuracy so as to fulfill their promise as a cosmological probe .",
    "we would like to thank both the referee and larry wasserman for helpful comments .",
    "this work was supported by nsf grant # 0707059 .",
    "funding for the deep2 survey has been provided by nsf grants ast95 - 09298 , ast-0071048 , ast-0071198 , ast-0507428 , and ast-0507483 as well as nasa ltsa grant nng04gc89 g .",
    "deep2 data presented herein were obtained at the w. m. keck observatory , which is operated as a scientific partnership among the california institute of technology , the university of california and the national aeronautics and space administration .",
    "the observatory was made possible by the generous financial support of the w. m. keck foundation .",
    "the cfhtls data were obtained with megaprime / megacam , a joint project of cfht and cea / dapnia , at the canada - france - hawaii telescope ( cfht ) which is operated by the national research council ( nrc ) of canada , the institut national des science de lunivers of the centre national de la recherche scientifique ( cnrs ) of france , and the university of hawaii .",
    "this work is based in part on data products produced at terapix and the canadian astronomy data centre as part of the canada - france - hawaii telescope legacy survey , a collaborative project of nrc and cnrs .",
    "albrecht a.  et al .",
    "2006 , ( preprint : astro - ph/0609591 ) ball n.  m.  et al .",
    "2004 , mnras , 348 , 1038 ball n.  m.  et al .",
    "2007 , apj , 663 , 774 ball n.  m. , brunner r.  j. , myers a.  d. , strand n.  e. , alberts s.  l. , tcheng d.  2008 , apj , 683 , 12 bentez n.  2000 , apj , 536 , 571 budavri t.  et al .",
    "2005 , apj , 619 , l31 budavri t. , wild v. , szalay a.  s. , dobos l. , yip c .- w .",
    "2009 , mnras , 394 , 1496  2005 , apj , 619 , l31 carroll r. , ruppert d. , stefanski l. , crainiceanu c.  2006 , measurement error in nonlinear models , chapman and hall , new york , ny coifman r.  r. , lafon s.  2006 , appl .",
    "comput . harmon .",
    ", 21 , 5 coil a.  l.  et al .  2004 ,",
    "apj , 617 , 765 collister a.  a. , lahav o.  2004 , pasp , 16 , 345 connolly a.  j. , csabai i. , szalay a.  s. , koo d.  c. , kron r.  g. , munn j.  a.  1995 , aj , 110 , 2655 cook j.  r. , stefanski l.  a.  1994 , jasa , 89 , 1314 cooper m.  c.  et al .",
    "2006 , mnras , 370 , 198 costa j.  a. , hero a.  o.  2005 , icassp , 5 , 1077 davis m.  et al .",
    "2003 , spie proceedings , 4834 , 161 davis m.  et al .",
    "2007 , apj , 660 , l1 eisenstein d.  j.  et al .",
    "2001 , aj , 122 , 2267 feldmann r.  et al .  2006 ,",
    "mnras , 372 , 565 fernndez - soto a. , lanzetta k.  m. , yahil a.  1999 , apj , 513 , 34 finkbeiner d.  p.  et al .",
    "2004 , aj , 128 , 2577 gwyn s.  d.  j.  2008 , pasp , 120 , 212 ilbert o.  et al .  2006 , a&a , 457 , 841 ilbert o.  et al .",
    "2008 , apj , 690 , 1236 ivezi   et al .",
    "2008 , ( preprint : arxiv/0805.2366 ) kovac k.  et al .",
    "2009 , baas , 41 , 378 lafon s. , lee a.  2006 , ieee trans . pattern anal . and mach .",
    ", 28 , 1393 lee , a. , wasserman , l.  2009 , jrss b , submitted ( preprint : arxiv/0811.0121 ) ma z. , hu w. , huterer d.  2006 , apj , 636 , 21 newman j.  a.  2008 , apj , 684 , 88 oyaizu h. , lima m. , cunha c.  e. , lin h. , frieman j. , sheldon e.  s.  2008 , apj , 674 , 768 padmanabhan n.  et al .",
    "2008 , apj , 674 , 1217 press w. , teukolsky s. , vetterling w. , flannery b. , numerical recipes in c , cambridge univ . press , cambridge richards j.  w. , freeman p.  e. , lee a.  b. , schafer c.  m.  2009 , apj , 691 , 32 richards j.  w. , freeman p.  e. , lee a.  b. , schafer c.  m.  2009 , mnras , submitted ( preprint : arxiv/0905.4683 ) strauss m.  a.  et al .",
    "2002 , aj , 124 , 1810 vanzella e.  et al .",
    "2004 , a&a , 423 , 761 wasserman l.  w.  2006 , all of nonparametric statistics , springer , new york , ny wray j.  j. , gunn j.  e.  2008 , apj , 678 , 144",
    "let @xmath155 represent a matrix of predictors ( in this work , the matrix of diffusion coordinates @xmath68 , where each row represents the coordinates for a single object ) , let @xmath117 represent the vector of responses ( the estimated spectroscopic redshift values ) , and let @xmath156 represent the covariance matrix for @xmath117 , which we assume to be diagonal : @xmath157 then the best - fit coefficients are @xmath158 the variance - covariance matrix for @xmath159 is @xmath160 and the variance - covariance matrix for @xmath161 is @xmath162",
    "we assume each flux is a normal deviate with error estimated by the princeton / mit data reduction pipeline . however , fluxes in , e.g. , different sdss magnitude bands and systems are correlated random variables . in order",
    "to resample fluxes accurately , we must take these correlations into account . for each object in the validation set , we have 20 flux measurements @xmath163 and estimates of flux standard error @xmath164 .",
    "the covariance matrix @xmath156 is defined as @xmath165 where @xmath166 is the sample correlation coefficient between measurements @xmath53 and @xmath167 ( e.g. , between the psf @xmath102-band and the petrosian @xmath91-band ) .",
    "we estimate @xmath166 using pearson s product - moment correlation estimator @xmath168 where @xmath169 is the sample standard deviation . as expected , we find that fluxes measured via different systems within a single magnitude band are strongly positively correlated ( @xmath170 ) ; also , we find that fluxes across bands have non - negligible positive correlations , which we attribute to the relative homogeneity of the msg sample ( whose objects lie at relatively similar distances and display relatively similar physical characteristics ) . however ,",
    "so as not to impose this homogeneity in resampling , we set @xmath166 = 0 if indices @xmath53 and @xmath167 represent different magnitude bands .",
    "we use the cholesky method to decompose @xmath156 into lower- and upper - triangular matrices @xmath171 and @xmath172 .",
    "then we can compute a new vector of fluxes : @xmath173 where @xmath39 is a vector of standard normal deviates ."
  ],
  "abstract_text": [
    "<S> the development of fast and accurate methods of photometric redshift estimation is a vital step towards being able to fully utilize the data of next - generation surveys within precision cosmology . in this paper </S>",
    "<S> we apply a specific approach to _ spectral connectivity analysis _ </S>",
    "<S> ( sca ; @xcite ) called diffusion map . </S>",
    "<S> sca is a class of non - linear techniques for transforming observed data ( e.g. , photometric colours for each galaxy , where the data lie on a complex subset of @xmath0-dimensional space ) to a simpler , more natural coordinate system wherein we apply regression to make redshift predictions . in previous applications of sca to other astronomical problems ( @xcite , @xcite ) , we demonstrate its superiority vis - a - vis principal components analysis ( pca ) , a standard linear technique for transforming data . </S>",
    "<S> as sca relies upon eigen - decomposition , our training set size is limited to @xmath1 10@xmath2 galaxies ; we use the nystrm extension to quickly estimate diffusion coordinates for objects not in the training set . </S>",
    "<S> we apply our method to 350,738 sdss main sample galaxies , 29,816 sdss luminous red galaxies , and 5,223 galaxies from deep2 with cfhtls @xmath3 photometry . </S>",
    "<S> for all three datasets , we achieve prediction accuracies on par with previous analyses , and find that use of the nystrm extension leads to a negligible loss of prediction accuracy relative to that achieved with the training sets . as in some previous analyses ( e.g. , @xcite , @xcite ) , we observe that our predictions are generally too high ( low ) in the low ( high ) redshift regimes . </S>",
    "<S> we demonstrate that this is a manifestation of attenuation bias , wherein measurement error ( i.e. , uncertainty in diffusion coordinates due to uncertainty in the measured fluxes / magnitudes ) reduces the slope of the best - fit regression line . </S>",
    "<S> mitigation of this bias is necessary if we are to use photometric redshift estimates produced by computationally efficient empirical methods in precision cosmology .    </S>",
    "<S> [ firstpage ]    galaxies : distances and redshifts  galaxies : fundamental parameters  galaxies : statistics  methods : statistical  methods : data analysis </S>"
  ]
}