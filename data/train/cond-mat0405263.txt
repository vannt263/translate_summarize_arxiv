{
  "article_text": [
    "for completeness we recall here the graphical representation of the green s function .",
    "the details of the diagrammatic method can be found in @xcite .",
    "the green s function @xmath92 can be represented as a sum over diagramms : @xmath227{graph1.eps } \\label{eq : fgraph}\\ ] ] where the @xmath3-type and @xmath5-type indices of @xmath8 are denoted by filled and empty circles , respectively .",
    "the matrix @xmath8 is denoted by an ordered pair of neighbouring filled and empty circles , while @xmath7 is drawn as an pair of such circles in the reverse order . a horizontal solid line stands for @xmath228 , a dashed line for @xmath229 , a solid arc for @xmath21 and a dashed arc for @xmath22 .",
    "the two point function ( [ ca ] ) is drawn as a double arc .",
    "matrices on a line are multiplied in the order of appearance on this line .",
    "if a line is closed , the trace is taken .    in the thermodynamical limit",
    "only planar diagrams give contribution to @xmath230 .",
    "in particular the last term in ( [ eq : fgraph ] ) vanishes .",
    "the green s function @xmath231 is represented by an identical set of diagrams with dashed and solid lines exchanged .",
    "it is convenient to introduce one - line irreducible diagrams and corresponding generating functions @xmath232 and @xmath233 .",
    "the green s functions can be expressed in terms of @xmath232 and @xmath233 as follows : @xmath234{gsig.eps}\\ ] ] @xmath235{gsigma.eps}\\ ] ] in the planar limit there are two additional equations which relate the sums over one - line irreducible diagrams to the green s functions : @xmath236{sg.eps } \\qquad , \\qquad \\psfrag{s}{{\\small $ { \\mathbf{\\sigma_c}}$}}\\psfrag{g}{{\\small $ { \\mathbf{g_{*c}}}$ } } \\psfrag{k}{{\\small $ \\dots$ } } \\includegraphics[width=4.5cm]{sg.eps}\\ ] ] analogous diagrammatic equations can be written for @xmath237 with the only difference that the solid line shall denote the propagator @xmath238 and the dashed line @xmath239 .",
    "we use the equations ( [ zz_ca ] ) and ( [ map ] ) to determine the relations ( [ mcmm ] ) . as for the case @xmath108 we shall do this using @xmath117 expansion .",
    "the function @xmath124 is given by the series : @xmath240 let us determine the expansion for the inverse function @xmath131 as a series around zero : @xmath241 the coefficients of the series can be directly calculated from the condition : @xmath242 which gives us : @xmath243 the equation ( [ zz_ca ] ) takes the form : @xmath244 or if written for @xmath117 : @xmath245 where : @xmath246 thus we have expressed @xmath117 as a series of @xmath120 . inserting this series to the equation ( [ map ] ) and comparing coefficients at @xmath247 we eventually obtain ( [ mcmm ] ) .    99 j. wishart , biometrica * a20 * , 32 ( 1928 ) .",
    "anderson , _ introduction to multivariate statistical analysis _ ( wiley , 1958 ) .",
    "y. demasure , r. a. janik , phys.lett . *",
    "b553 * , 105 ( 2003 ) .",
    "moustakas , et al . , science * 287 * , 287 ( 2000 ) .",
    "a.m. sengupta and p.p .",
    "mitra , physics/0010081 .",
    "skipetrov , phys . rev . *",
    "e67 * , 036621 ( 2003 ) .",
    "s. maslov , y.c .",
    "zhang phys .",
    "lett . * 87 * 248701 ( 2001 ) .",
    "l. laloux , p. cizeaux , j .-",
    "bouchaud and m. potters , phys .",
    "lett . * 83 * 1467 ( 1999 ) .",
    "v. plerou , et al .",
    "* 83 * 1471 ( 1999 ) .",
    "z. burda and j. jurkiewicz , cond - mat/0312496 , to appear in physica * a*. s.h .",
    "simon , a.l .",
    "moustakas , math - ph/0401038 .",
    "because of the multiplicative nature of the price changes instead of the changes : @xmath248 themselves , in the financial analysis one rather uses returns @xmath249 as random variables .",
    "j.  feinberg , a.  zee , _ jour .",
    "phys . _ * 87 * 473 ( 1997 ) .",
    "a.m. sengupta and p.p .",
    "mitra , phys .",
    "rev . * e60 * 3389 , ( 1999 ) .",
    "z. burda , a. goerlich , a. jarosz , j. jurkiewicz , cond - mat/0305627 , to appear in physica * a*. r.a .",
    "janik , m.a .",
    "nowak , j.phys .",
    "* a36 * 3629 ( 2003 ) ."
  ],
  "abstract_text": [
    "<S> we present an analytic method to determine spectral properties of the covariance matrices constructed of correlated wishart random matrices . </S>",
    "<S> the method gives , in the limit of large matrices , exact analytic relations between the spectral moments and the eigenvalue densities of the covariance matrices and their estimators . </S>",
    "<S> the results can be used in practice to extract information about the genuine correlations from the given experimental realization of random matrices .                </S>",
    "<S> wishart random matrices play an important role in the multivariate statistical analysis @xcite . </S>",
    "<S> they are useful in some problems of fundamental physics @xcite , communication and information theory @xcite , internet trading @xcite and quantitative finance @xcite .    </S>",
    "<S> a wishart ensemble of correlated random matrices is defined by a gaussian probability measure : @xmath0 \\prod_{i,\\alpha=1}^{n , t }   d x_{i\\alpha } \\ , \\label{preal}\\ ] ] where @xmath1 is a real rectangular matrix of dimension @xmath2 . </S>",
    "<S> it has two types of indices : an @xmath3-type index runnig over the set @xmath4 and a @xmath5-type index over @xmath6 . throughout the paper </S>",
    "<S> the @xmath3-type indices will be denoted by latin letters and the @xmath5-type by greek ones . </S>",
    "<S> @xmath7 denotes the transpose of @xmath8 . </S>",
    "<S> the matrices @xmath9 and @xmath10 are symmetric square matrices of dimensions @xmath11 and @xmath12 , respectively . </S>",
    "<S> they are positive definite . </S>",
    "<S> @xmath13 is a normalization constant : @xmath14 chosen to have @xmath15 .    </S>",
    "<S> let @xmath16 be a quantity depending on @xmath8 . </S>",
    "<S> the average of @xmath17 over the random matrix ensemble ( [ preal ] ) is defined as : @xmath18 in particular , the two - point correlation function is : @xmath19 as directly follows from the gaussian integration . in this paper </S>",
    "<S> we are interested in the spectral behaviour , the eigenvalue distribution and the spectral moments of the following random matrices : @xmath20 these matrices can be used as estimators of the correlation matrices @xmath21 and @xmath22 if some realizations of random matrices @xmath8 are given </S>",
    "<S> . we will refer to @xmath23 and @xmath24 as to covariance matrices or statistically dressed correlation matrices . </S>",
    "<S> we will present an analytic method to determine the eigenvalue distribution and the spectral moments of @xmath23 and @xmath24 in the limit of large matrix size . </S>",
    "<S> another method of calculating the eigenvalue density of correlated wishart matrices has been recently discussed in @xcite .    in parallel to ( [ preal ] ) one can define a wishart ensemble of correlated complex matrices : @xmath25 \\prod_{i , \\alpha }   d   x^{re}_{i\\alpha } d x^{im}_{i\\alpha } . </S>",
    "<S> \\label{pcompl}\\ ] ] the matrices @xmath21 and @xmath22 are now hermitean and positive definite . </S>",
    "<S> @xmath26 denotes the hermitean conjugate of @xmath8 . </S>",
    "<S> the normalization constant is now @xmath27 . in the analysis of the complex ensemble </S>",
    "<S> the estimators ( [ ca ] ) of the correlation matrices are replaced correspondingly by @xmath28 notice that the factor one half in front of the trace in the measure for real matrices ( [ preal ] ) is dropped in ( [ pcompl ] ) . with this choice of the measure </S>",
    "<S> the two - point correlations take a similar form as for real matrices ( [ ca ] ) : @xmath29 the star stands for the complex conjugation . </S>",
    "<S> additionally we also have : @xmath30 as a consequence , as we shall discuss towards the end of the paper , the matrices @xmath23 and @xmath24 ( [ ca ] ) in the real ensemble have an identical large @xmath3 behaviour as the corresponding matrices ( [ cac ] ) in the complex ensemble . </S>",
    "<S> since we are interested here only in the large @xmath3 behaviour it is sufficient to consider one of the two ensembles and draw conclusions for the other . </S>",
    "<S> we will focus the presentation on the ensemble of real matrices .    </S>",
    "<S> an example of a problem which can be formulated in terms of wishart random matrices ( [ preal ] ) is the following . </S>",
    "<S> imagine that we probe a statistical system of @xmath3 correlated degrees of freedom by doing @xmath5 measurements . </S>",
    "<S> we store the measured values of the @xmath31-th degree of freedom in the @xmath32-th measurement in a rectangular matrix @xmath33 . </S>",
    "<S> the degrees of freedom as well as the measurements may be correlated . </S>",
    "<S> this is expressed by the equation ( [ ca ] ) , which tells us that the covariance matrix for the correlations between degrees of freedom in the system is @xmath9 and for the ( auto)correlation between measurements is @xmath10 . </S>",
    "<S> note that in general the correlations between @xmath34 and @xmath35 may have a more complicated form : @xmath36 , where the matrix @xmath37 has double indices . </S>",
    "<S> such a situation takes place if the autocorrelations are different for various degrees of freedom . </S>",
    "<S> we shall not discuss this case here . </S>",
    "<S> moreover , we shall assume that only gaussian effects are important for the studied system .    </S>",
    "<S> a perfect example of the situation described above is the problem of optimal portfolio assessment - one of the fundamental problems of quantitative finance . </S>",
    "<S> the portfolio assessment is based on the knowledge of the covariance matrix @xmath21 for stocks returns @xcite . in practice </S>",
    "<S> , the covariance matrix is estimated from the historical data which are stored in a rectangular matrix representing @xmath5 historical values of @xmath3 stocks . </S>",
    "<S> fluctuations of returns are well described by the gaussian ensemble ( [ preal ] ) . </S>",
    "<S> the estimator of the covariance matrix is given by ( [ ca ] ) . </S>",
    "<S> another problem of modern financial analysis which can be directly cast into the form ( [ preal ] ) is the problem of taste matching @xcite . </S>",
    "<S> this problem is encountered for instance in the large - scale internet trading .    </S>",
    "<S> it is worth mentioning that the random matrix framework may also be used in a statistical description of data generated in monte carlo simulations for a system with many degrees of freedom , in particular of data concerning the correlation functions . </S>",
    "<S> one frequently encounters such a problem in monte - carlo simulations of lattice field theory , where the field is represented by correlated numbers distributed on a lattice . </S>",
    "<S> usually , one is forced to use a dynamical monte carlo algorithm to sample such a system . </S>",
    "<S> the basic idea standing behind a dynamical algorithm is to generate a markov chain  a sort of a random walk  in the space of configurations . </S>",
    "<S> the degrees of freedom on the lattice as well as the successive configurations are usually correlated . outside a critical region </S>",
    "<S> no long range correlations are observed and the fluctuations can be treated as gaussian .    </S>",
    "<S> complex random matrices are useful for instance in telecommunication or information theory @xcite .    </S>",
    "<S> let us come back to the ensemble of real matrices ( [ preal ] ) . </S>",
    "<S> as we mentioned the matrices ( [ ca ] ) can be treated as estimators of the correlation matrices @xmath21 and @xmath22 . indeed , from equation ( [ ca ] ) </S>",
    "<S> we see that : @xmath38 where @xmath39 and @xmath40 . </S>",
    "<S> this notation will be explained later . </S>",
    "<S> the last equation tells us that measuring the average of @xmath23 over the ensemble ( [ preal ] ) we obtain the matrix @xmath21 up to a constant . in other words having a realization of random matrices @xmath8 we can use ( [ ca ] ) to estimate @xmath21 . </S>",
    "<S> similarly , we can use @xmath24 to estimate @xmath22 . </S>",
    "<S> notice that the measure ( [ preal ] ) is invariant under the transformation @xmath41 and @xmath42 , where @xmath43 is an arbitrary positive real number . </S>",
    "<S> in particular @xmath44 and @xmath45 are independent of the rescaling factor @xmath43 . </S>",
    "<S> this independence is ensured by the presence of the factors @xmath46 and @xmath47 in equations ( [ cest],[aest ] ) . in practical calculations , </S>",
    "<S> if @xmath48 and @xmath49 are not specified , one can remove the redundancy with respect to the rescaling by @xmath43 , setting @xmath50 . in this case the constants @xmath51 can be determined from the data by evaluating the traces of @xmath23 or @xmath24 : @xmath52    while considering the covariance matrices for the wishart ensemble we can formulate two reciprocal problems , which we shall call * direct * and * inverse problem*. in the direct problem we want to learn as much as possible about the probability distribution of the estimators @xmath23 and @xmath24 ( [ ca ] ) assuming that the matrices @xmath21 and @xmath22 are given . in particular , we want to calculate the eigenvalue density functions : @xmath53 where @xmath54 and @xmath55 are eigenvalues of @xmath23 and @xmath24 , respectively . </S>",
    "<S> the determination of the eigenvalue density functions is equivalent to the determination of all their spectral moments : @xmath56 the moments @xmath57 are related to each other : @xmath58 where @xmath59 , as follows from the cyclicity of the trace : @xmath60 in the inverse problem we want to learn as much as possible about the genuine correlations in the system , which are given by @xmath21 and @xmath22 , using a measured sample of random matrices @xmath8 . </S>",
    "<S> we can do this by computing the estimators @xmath23 and @xmath24 ( [ ca ] ) and relating them to matrices @xmath61 . </S>",
    "<S> in particular we would like to estimate the eigenvalue distributions and the moments of @xmath61 : @xmath62 where @xmath63 and @xmath64 are eigenvalues of @xmath21 and @xmath22 , respectively . </S>",
    "<S> the inverse problem is very important for practical applications , since in practice it is very common to reconstruct the properties of the underlying system from the experimental data .    in the analysis of the spectral properties of the matrices @xmath24 and @xmath23 it is convenient to apply the green s function technique . </S>",
    "<S> one can define green s functions for the correlation matrix @xmath21 and its statistically fluctuating counterpart @xmath23 : @xmath65 and correspondingly @xmath66 and @xmath67 for @xmath22 and @xmath24 . </S>",
    "<S> the symbol @xmath68 stands for the @xmath11 identity matrix . </S>",
    "<S> a corresponding symbol @xmath69 appears in the definition of @xmath66 and @xmath67 . </S>",
    "<S> the green s functions are related to the generating functions for the moments : @xmath70 or inversely : @xmath71 the analogous relations exist for @xmath66 and @xmath67 . </S>",
    "<S> the green s functions can be used for finding the densities of eigenvalues : @xmath72 and similarly for @xmath73 . </S>",
    "<S> the eigenvalue densities @xmath73 and @xmath74 are not independent . </S>",
    "<S> as follows from ( [ mak_mck ] ) the corresponding generating functions ( [ mcz ] ) fulfill the equation : @xmath75 combining the last equation with ( [ gm ] ) we obtain : @xmath76 applying now ( [ rhoc ] ) we have : @xmath77 the meaning of the last term on the right hand side of this equation is that there are @xmath78 zero modes in the matrix @xmath24 if @xmath79 . </S>",
    "<S> the zero modes disappear when @xmath80 . moving the term containing the delta function to the other side of equation , dividing both sides of the equation by @xmath81 and substituting the parameter @xmath82 by @xmath83 we obtain : @xmath84 therefore , for @xmath85 the zero modes appear in the spectrum @xmath74 . in this case </S>",
    "<S> it is more convenient to use the parameter @xmath86 instead of @xmath82 . </S>",
    "<S> the zero modes appear in the eigenvalue distribution of either @xmath24 or @xmath23 . </S>",
    "<S> the two equations ( [ rac ] ) and ( [ rca ] ) are dual to each other . </S>",
    "<S> for @xmath87 they are identical . because of the duality it is sufficient to solve the problem for @xmath88 . </S>",
    "<S> we will present a solution for the limit @xmath89 and @xmath90 neglecting effects of the order @xmath91 .    </S>",
    "<S> using a diagrammatic method @xcite one can write down a closed set of equations for the green s function @xmath92 ( [ gc ] ) : @xmath93 the set contains four equation for four unknown matrices including @xmath92 which we want to calculate , and three auxiliary ones : @xmath94 , @xmath95 , @xmath96 ( see appendix 1 ) . </S>",
    "<S> each of them can be interpreted in terms of a generating function for appropriately weighted diagrams with two external lines : @xmath97 for all diagrams and @xmath98 for one - line - irreducible diagrams @xcite ( see appendix 1 ) . in the limit @xmath90 </S>",
    "<S> the weights of non - planar diagrams vanish at least as @xmath91 . </S>",
    "<S> thus in this limit only planar diagrams give a contribution to the green s function . </S>",
    "<S> therefore the large @xmath3 limit is alternatively called the planar limit . </S>",
    "<S> the diagrammatic equations ( [ 4gc ] ) hold only in this limit . </S>",
    "<S> an analogous set of equations can be written for the green s function @xmath67 . </S>",
    "<S> the equations are identical to those of ( [ 4gc ] ) if one exchanges @xmath99 , @xmath100 and @xmath101 . </S>",
    "<S> the two sets can be solved independently of each other . however , as follows from the duality ( [ gac ] ) it is sufficient to solve only one of them and deduce the solution of the other .    </S>",
    "<S> the equations ( [ 4gc ] ) can be solved for @xmath92 by a successive elimination of @xmath94 , @xmath95 and @xmath96 . </S>",
    "<S> however , the resulting equation is very entangled @xcite : @xmath102 and can not be easily used in practical calculations of the moments @xmath103 or spectral density @xmath74 .    </S>",
    "<S> another way of solving the equations ( [ 4gc ] ) was proposed in @xcite . </S>",
    "<S> it relies on introducing a new complex variable @xmath104 conjugate to @xmath105 which is defined by the equation : @xmath106 at the first glance this equation looks useless because it refers to an unknown function @xmath107 which we actually want to determine . </S>",
    "<S> quite contrary to this , as we shall see , the introduction of the conjugate variable @xmath104 allows us to write down a closed functional equation for @xmath107 . </S>",
    "<S> first , let us illustrate how the method works for @xmath108 @xcite . in this case </S>",
    "<S> , the elimination of the auxiliary functions ( [ 4gc ] ) leads to @xmath109 or equivalently to @xmath110 suppose we solve the direct problem . </S>",
    "<S> in this case we know the matrix @xmath21 and hence also the generating function @xmath111 . inserting ( [ zz ] ) to ( [ map ] ) we obtain a closed compact functional relation for @xmath107 : @xmath112 </S>",
    "<S> if @xmath113 has a simple form , one can solve the equation for @xmath107 analytically @xcite . </S>",
    "<S> in general , one can write a numerical program to calculate the eigenvalue density @xmath74 from the last equation . in case of solving the inverse problem </S>",
    "<S> , we assume that we can determine moments @xmath114 from the data and hence that we can approximate the generating function @xmath107 . </S>",
    "<S> then we can insert ( [ zz ] ) to ( [ map ] ) and obtain a functional equation for @xmath111 : @xmath115 the problem is solved in principle . </S>",
    "<S> however , in practical terms the inverse problem is much more difficult , because one can not compute all experimental moments @xmath114 with an arbitrary accuracy , unless one has an infinitely long series of measurements . </S>",
    "<S> but one never has . in practice </S>",
    "<S> one can estimate only a few lower moments @xmath114 with a good accuracy . because of this practical limitation one can not entirely solve the inverse problem . </S>",
    "<S> however , as we discussed in @xcite the inverse problem can be partially solved even in specific practical applications using a moments method . </S>",
    "<S> let us sketch this method below .    </S>",
    "<S> we can gain some insight into the spectral properties of the correlation matrix @xmath21 by determining the relation between the moments @xmath116 and @xmath114 . </S>",
    "<S> expanding the functions @xmath113 and @xmath107 in ( [ mcmc ] ) in @xmath117 using ( [ mcz],[mcz ] ) and comparing the coefficients at @xmath118 we obtain : @xmath119 we can also invert the equations for @xmath116 . </S>",
    "<S> the result of inversion gives a set of equations which can be directly obtained from the @xmath120 expansion of the functions in the equation ( [ mcmc ] ) which is the inverse transform of ( [ mcmc ] ) . </S>",
    "<S> we can also determine the corresponding relations for negative moments @xmath114 and @xmath116 , that is for @xmath121 , or determine the spectral density @xmath74 @xcite . using a computer tool for symbolic calculations one can easily write a program which successively generates the relations between spectral moments ( [ mm ] ) from the equation ( [ mcmc ] ) .    </S>",
    "<S> the calculations get more complicated in the general case when both @xmath122 and @xmath123 are arbitrary . </S>",
    "<S> the guiding principle is the same , though . </S>",
    "<S> we introduce the conjugate variable @xmath104 ( [ map ] ) and , using it , write down the solution of the equations ( [ 4gc ] ) . in the direct problem we assume that the generating functions @xmath111 and @xmath124 are known . </S>",
    "<S> we will show that in this case the solution of ( [ 4gc ] ) takes a form of an explicit equation for @xmath125 , where the function @xmath126 depends on the functions @xmath111 and @xmath124 . </S>",
    "<S> inserting this solution back to ( [ 4gc ] ) we eventually obtain a functional equation @xmath127 from which we can extract the function @xmath107 .    </S>",
    "<S> the solution of ( [ 4gc ] ) takes the form : @xmath128 where @xmath64 are eigenvalues of @xmath123 . </S>",
    "<S> it can be rewritten as : @xmath129 and can be formally solved for @xmath105 : @xmath130 where @xmath131 is the inverse function of @xmath132 . </S>",
    "<S> thus we have obtained an explicit equation for @xmath125 in terms of the known functions @xmath132 and @xmath133 . </S>",
    "<S> one can easily check that for @xmath134 the last equation reduces to ( [ zz ] ) . in this case </S>",
    "<S> @xmath135 , @xmath136 .    combining the equation for @xmath125 given by ( [ zz_ca ] ) with ( [ map ] ) we arrive at a closed equation for the generating function @xmath137 . </S>",
    "<S> it can be used for example to calculate the moments @xmath114 s ( see appendix 2 ) . </S>",
    "<S> the calculations yield a set of equations expressing @xmath114 s in terms of the bare moments @xmath138 and </S>",
    "<S> @xmath116 : @xmath139 the equations reduce to the form ( [ mm ] ) for @xmath134 .    using the relations ( [ mak_mck ] ) we can also determine the moments of the matrix @xmath24 . </S>",
    "<S> it is more convenient to write them using the variable @xmath140  the dual counterpart of @xmath82  instead of @xmath82 itself : @xmath141 the equations are completely symmetric to ( [ mcmm ] ) with respect to the change @xmath142 ( which amounts to @xmath143 ) , and @xmath144 , @xmath145 . </S>",
    "<S> using this method one can obtain equations ( [ mcmm ] ) and ( [ mamm ] ) to an arbitrary order .    </S>",
    "<S> the above relations are useful for computing the dressed moments @xmath146 for given matrices </S>",
    "<S> @xmath147 or inversely , the genuine moments @xmath148 from the experimental data . </S>",
    "<S> as mentioned , the spectral moments give us in principle full information about the eigenvalue distribution . in practice </S>",
    "<S> the reconstruction of the eigenvalue density may be difficult , because to do it we would need to know all moments with a very good precision . </S>",
    "<S> usually , in practical applications one can accurately evaluate only a few lower moments .    in some special cases if we can make some extra assumptions about the form of the matrices @xmath21 or @xmath22 we can improve significantly the reconstruction of the eigenvalue density . in the previous work </S>",
    "<S> @xcite we have analysed the case of @xmath108 and of the matrix @xmath21 which had only a few distinct eigenvalues . in this case the green s function @xmath92 is given by an algebraic equation of the order which is equal to the number of distinct eigenvalues . </S>",
    "<S> it can be analytically solved when this number is less or equal four . </S>",
    "<S> if it is larger the problem can be handled numerically . </S>",
    "<S> the duality tells us that the solution also holds when we change the roles of @xmath22 and @xmath21 .    </S>",
    "<S> below we will discuss the case of exponential autocorrelations . </S>",
    "<S> exponential correlations are encountered in many situations . </S>",
    "<S> the general solution , which we have discussed so far , simplifies in this case to a more compact relation for the green s function , which allows us to find analytically an approximate form of the eigenvalue density of the random matrices @xmath23 and @xmath24 . </S>",
    "<S> the approximation becomes exact in the large @xmath3 limit . </S>",
    "<S> we consider purely exponential autocorrelations given by the autocorrelation matrix : @xmath149 \\ , \\label{aexp}\\ ] ] where @xmath150 controls the range of autocorrelations . </S>",
    "<S> the inverse of the matrix @xmath123 reads : @xmath151 . </S>",
    "<S> \\label{binv}\\ ] ] we have introduced here a shorthand notation @xmath152 , @xmath153 and @xmath154 . </S>",
    "<S> the spectrum of this matrix can be approximated by the spectrum of a matrix @xmath155 : @xmath156 , \\label{m}\\ ] ] whose eigenvalues can be found analytically : @xmath157 the corresponding eigenvectors are given by the fourier modes . </S>",
    "<S> the matrix @xmath158 can be viewed as of a sum : @xmath159 , of a unity matrix multiplied by a constant and a discretized one - dimensional laplacian @xmath160 for a cyclic chain of length @xmath5 . </S>",
    "<S> the matrix @xmath161 can be obtained from @xmath155 by adding to it a perturbation @xmath162 : @xmath163 , where @xmath162 has only four non - vanishing elements : @xmath164 and @xmath165 . </S>",
    "<S> the first order corrections to the eigenvalues of @xmath161 , which stem from the perturbation @xmath162 , behave as @xmath166 . </S>",
    "<S> the perturbation @xmath162 can be viewed as a change of a boundary condition of the laplacian . as usual , boundary conditions affect mostly the longest ( small momentum ) modes . </S>",
    "<S> indeed , a careful analysis shows that the two diagonal terms of the perturbation matrix , @xmath167 , introduce a constant correction independent of @xmath5 of the lowest eigenvalues which does not vanish when @xmath5 goes to infinity . </S>",
    "<S> however , since the differences between unperturbed eigenvalues of @xmath155 and the corresponding perturbed eigenvalues of @xmath161 disappear for all other eigenvalues , we expect that for @xmath168 the spectral properties of @xmath123 can be well approximated by the eigenvalues of @xmath169 : @xmath170 in this limit we can also approximate the sum ( [ zzsum ] ) by an integral : @xmath171 where @xmath172 and the symbol @xmath173 is introduced for brevity </S>",
    "<S> . note that in the definition of @xmath174 we have replaced @xmath111 , which would rather be dictated by ( [ zzsum ] ) , by @xmath107 . </S>",
    "<S> this change is legitimate due to ( [ map ] ) . </S>",
    "<S> the integral ( [ zzint ] ) can be done : @xmath175 setting back @xmath176 we eventually obtain : @xmath177 this is an explicit equation for @xmath178 which can be now inserted into @xmath179 giving us a compact relation for @xmath107 in the presence of the exponential autocorrelations ( [ aexp ] ) : @xmath180 in the limit @xmath181 , the parameters @xmath182 , @xmath183 and @xmath184 increase to infinity and @xmath185 . as a consequence , the form of equation ( [ z(z ) ] ) </S>",
    "<S> simplifies to ( [ zz ] ) , which corresponds to the case without autocorrelations , as expected . </S>",
    "<S> using the equation ( [ mmexp ] ) we can recursively generate equations for the consecuitive moments : @xmath186 where @xmath187 . </S>",
    "<S> the coefficients on the right hand side , which depend on @xmath188 , can be directly expressed in terms of the moments @xmath138 of the matrix @xmath123 . </S>",
    "<S> approximating again a sum by an integral in the large @xmath5 limit we can write : @xmath189 the integrals can be calculated yielding : @xmath190 we see that if we insert these coefficients into the equations ( [ mcmm ] ) we obtain ( [ mmsc ] ) . </S>",
    "<S> this is a consistency check for the approximation which we use here . </S>",
    "<S> the quality of this approximation can also be checked by comparing the moments @xmath138 of the matrix ( [ aexp ] ) for finite @xmath5 with the result ( [ approx ] ) which corresponds to @xmath191 . </S>",
    "<S> we expect that for @xmath168 the numerical values shall approach the result ( [ approx ] ) . </S>",
    "<S> the results of this comparison confirm our expectations ( see table 1 ) .    </S>",
    "<S> @xmath192    thus we see that the formula ( [ mmsc ] ) for @xmath107 in the presence of the exponential autocorrelations becomes exact in the limit @xmath193 . </S>",
    "<S> this formula allows us to compute the eigenvalue distribution of the random matrices @xmath23 and @xmath24 ( [ ca ] ) . </S>",
    "<S> let us illustrate this on the simplest example of the system which has no correlations : @xmath194 and @xmath195 . </S>",
    "<S> in this case the equation ( [ mmexp ] ) for @xmath107 takes the form : @xmath196 where we have used the notation @xmath197 . for @xmath198 ( @xmath199 ) </S>",
    "<S> this equation reduces to : @xmath200 = 0 \\ , \\ ] ] which has a solution : @xmath201 where @xmath202 , which leads to the well - known result for the uncorrelated wishart ensemble : @xmath203 for @xmath204 it is still possible to find analytically a solution of ( [ eq : x ] ) . </S>",
    "<S> let us rewrite ( [ eq : x ] ) as a polynomial equation : @xmath205 it has two trivial solutions @xmath206 . dividing out the polynomial @xmath207 we get : @xmath208 </S>",
    "<S> this is a quartic equation which can be solved analytically by the ferrari method . </S>",
    "<S> we will not present the formal solution which is neither transparent nor informative . </S>",
    "<S> instead , we show in fig . </S>",
    "<S> [ fig1 ] the eigenvalue density functions @xmath74 , for different @xmath150 , resulting from this solution . the lower part of the distribution approaches zero when @xmath150 increases , but zero modes do not appear in the distribution as long as @xmath209 .     for exponential matrix @xmath22 , @xmath210 and for three different autocorrelation times </S>",
    "<S> @xmath150 : @xmath211 ( solid line ) , @xmath212 ( dashed line ) and @xmath213 ( dotted line).,width=377 ]    the formula ( [ mmexp ] ) applies to any correlation matrix @xmath21 but in the general case one has to use a numerical procedure to calculate from it the density function .    </S>",
    "<S> let us stop here the presentation of results for the ensemble of real matrices . as we mentioned all results in the large @xmath3 limit </S>",
    "<S> hold also in the ensemble of complex matrices if the covariance matrices ( [ ca ] ) are replaced by ( [ cac ] ) . </S>",
    "<S> the reason why it is so is related to the fact that the moments of @xmath214 in the ensemble of complex matrices ( [ pcompl ] ) are equal to the moments of @xmath215 in the real ensemble ( [ preal ] ) up to a @xmath91 corrections which disappear in the large @xmath3 limit : @xmath216 let us illustrate this by explicit calculations of the second moment . </S>",
    "<S> using the wick s theorem for gaussian integrals and the equation ( [ ca ] ) for the two - point correlation function , we have : @xmath217 the corresponding calculations for the complex ensemble read : @xmath218 the difference between the two calculations appears in the third term which in the real ensemble gives a contribution of the order @xmath91 while in the complex ensemble disappears by virtue of ( [ cacc ] ) . </S>",
    "<S> we recognize that @xmath219 which are the leading terms in the @xmath91 expansion are identical as in the second equation in the set ( [ mcmm ] ) . </S>",
    "<S> generally one can show that the leading contributions which correspond to the planar diagrams in the expansion of @xmath92 are identical for both ensembles . </S>",
    "<S> non - planar diagrams are different but they contribute in the subleading orders : it turns out that in the diagrammatic expansion of the green s function @xmath220 for the complex matrix ensemble ( [ pcompl ] ) , which would be a counterpart of ( [ eq : fgraph ] ) in the appendix , all diagrams which contain a double arc with dashed and solid line crossed are identically equal zero since such an arc corresponds to the propagator @xmath221 or @xmath222 . </S>",
    "<S> a crossing of two arcs is however allowed and leads to a factor @xmath223 .    to summarize : in the paper we have considered an wishart ensemble of correlated random matrices . </S>",
    "<S> we have obtained in the limit of large matrices a closed set of equations relating the green s function or equivalently the moments generating functions @xmath107 and @xmath224 for statistically dressed correlations to the generating functions for genuine correlation matrices @xmath113 and @xmath225 . </S>",
    "<S> the equations in the large @xmath3 limit are the same for the ensemble of real and complex matrices . using these equations we can write down exact relations between genuine and experimental spectral moments of correlation functions of an arbitrary order . </S>",
    "<S> the relations can be used in practical problems to learn about correlations in the studied system from the experimental samples . in the case of exponential correlations </S>",
    "<S> we have also found an explicit form the spectral density function of the covariance matrix . </S>",
    "<S> a natural generalization of the work presented here is to consider a more general type of time correlations than purely exponential ( [ aexp ] ) . </S>",
    "<S> if the correlations are of the form which depends on the time difference @xmath226 and if they are short - ranged then one can apply fourier transform to determine in the large @xmath5 limit an approximate spectrum of the matrix @xmath22 and approximate values of its spectral moments . </S>",
    "<S> another interesting issue which can be addressed in the future is the determination of the probability distribution for individual elements of the covariance matrices @xmath23 and @xmath24 similarly as it was done for the uncorrelated case @xcite .    </S>",
    "<S> * acknowledgments *    we thank r. janik , a. jarosz and m.a . </S>",
    "<S> nowak for discussions . </S>",
    "<S> this work was partially supported by the polish state committee for scientific research ( kbn ) grants 2p03b 09622 ( 2002 - 2004 ) and 2p03b-08225 ( 2003 - 2006 ) , and by eu ist center of excellence `` copira '' . </S>"
  ]
}