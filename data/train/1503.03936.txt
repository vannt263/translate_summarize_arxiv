{
  "article_text": [
    "consider the large scale discrete linear ill - posed problem @xmath2 where @xmath3 is symmetric and extremely ill conditioned with its singular values decaying gradually to zero without a noticeable gap .",
    "this kind of problem arises in many science and engineering areas @xcite .",
    "the right - hand side @xmath4 is noisy and typically affected by a white noise , caused by measurement , modeling or discretization errors , i.e. , @xmath5 where @xmath6 represents a white noise vector and @xmath7 denotes the noise - free right - hand side , and it is supposed that @xmath8 . because of the presence of noise @xmath9 in @xmath4 and the high ill - conditioning of @xmath3 , the naive solution @xmath10 of is far from the true solution @xmath11 and meaningless .",
    "therefore , one needs to use regularization to determine a regularized solution so that it is close to @xmath11 as much as possible @xcite .    for @xmath3 symmetric ,",
    "its svd is closely related to its spectral decomposition as follows : @xmath12 where @xmath13 and @xmath14 are orthogonal , whose columns are the left and right singular vectors of @xmath3 , respectively , the diagonal matrix @xmath15 with the singular values labeled as @xmath16 , @xmath17 is a signature matrix such that @xmath18 with the @xmath19 the eigenvalues of @xmath3 , and @xmath20 . obviously , @xmath21 with the @xmath22 sign depending on @xmath23 . with",
    ", we can express the naive solution of as @xmath24    throughout the paper , we assume that @xmath25 satisfies the discrete picard condition @xcite : on average , the coefficients @xmath26 decay faster than the singular values @xmath18 .",
    "this is a necessary hypothesis that controls the size of @xmath27 and makes regularization possible to find meaningful approximations to @xmath28 @xcite . for the sake of simplicity",
    ", we assume that they satisfy a widely used model @xcite : @xmath29    similar to the truncated svd ( tsvd ) method @xcite , for @xmath3 symmetric , a truncated spectral decomposition method obtains the tsvd regularized solutions @xmath30 where @xmath31 with @xmath32 and @xmath33 the first @xmath0 columns of @xmath34 and @xmath35 , respectively , @xmath36 , and @xmath37 the moore - penrose generalized inverse of a matrix . obviously , @xmath38 is the minimum 2-norm least squares solution of the perturbed problem that replaces @xmath3 in by its best rank @xmath0 approximation @xmath39 .",
    "let @xmath40 denote the transition point such that @xmath41 and @xmath42 , which divides the eigenvalues @xmath19 or equivalently the singular values @xmath18 into the dominant or large ones for @xmath43 and the small ones for @xmath44 .",
    "it is known from @xcite and @xcite that the best tsvd regularized solution is @xmath45 , which consists of the @xmath40 dominant svd components of @xmath3 , i.e. , the dominant spectral components corresponding to the first @xmath40 large eigenvalues in magnitude when @xmath3 is symmetric .",
    "a number of approaches have been proposed for determining @xmath40 , such as discrepancy principle , the discrete l - curve criterion and the generalized cross validation ( gcv ) ; see , e.g. , @xcite for comparisons of the classical and new ones . in our numerical experiments",
    ", we do this using the l - curve criterion in the tsvd method and krylov iterative methods .",
    "the tsvd method is important in its own right and plays a central role in analyzing the standard - form tikhonov regularization @xcite .",
    "it and the standard - form tikhonov regularization expand their solutions in the basis vectors @xmath46 and produce very similar solutions with essentially the minimum 2-norm error ; see @xcite and ( * ? ? ?",
    "* sections 4.2 and 4.4 ) .",
    "therefore , the tsvd method can get a best regularized solution to , and it has long been used as a general - purpose reliable and efficient numerical method for solving a small and/or moderate sized @xcite . as a result , we will take the tsvd solution @xmath45 as a standard reference when assessing the regularizing effects of iterative solvers and accuracy of iterates under consideration in this paper .",
    "for is large , it is generally impractical to compute the spectral decomposition of @xmath3 . in this case",
    ", one typically solves it iteratively via some krylov subspace methods @xcite . for with a general matrix @xmath3 , the mathematically equivalent lsqr @xcite and cgls @xcite have been most commonly used for years and have been shown to have intrinsic regularizing effects @xcite .",
    "they exhibit the semi - convergence ; see @xcite , @xcite , @xcite : the iterates tend to be better and better approximations to the exact solution @xmath28 and their norms increase slowly and the residual norms decrease . in later stages , however , the noise @xmath9 starts to deteriorate the iterates , so that they will start to diverge from @xmath28 and instead converge to @xmath47 , while their norms increase considerably and the residual norms stabilize .",
    "for lsqr , the semi - convergence is due to the fact that the projected problem at some iteration starts to inherit the ill - conditioning of , that is , the noise progressively enters the solution subspace , so that a small singular value of the projected problem appears and the regularized solution is deteriorated @xcite .",
    "as far as an iterative solver for solving is concerned , a central problem is whether or not it has already obtained a best possible regularized solution at semi - convergence . here ,",
    "as defined in the abstract , a best possible regularized solution means that it is at least as accurate as the best tsvd solultion @xmath45 .",
    "this problem has been intensively studied but has had no definitive solutions . for krylov",
    "iterative solvers , their regularizing effects critically rely on how well the underlying @xmath0-dimensional krylov subspace captures the @xmath0 dominant right singular vectors of @xmath3 @xcite .",
    "the richer information the krylov subspace contains on the @xmath0 dominant right singular vectors ,",
    "the less possible it is that the resulting projected problem has a small singular value .",
    "that is , the solvers capture the large svd components of @xmath3 more effectively , and thus have better regularizing effects .    to precisely measure the regularizing effects , we introduce the term of _ full _ or _ partial _ regularization .",
    "if a pure iterative solver itself computes a best possible regularized solution at semi - convergence , it is said to have the full regularization ; in this case , no additional regularization is necessary .",
    "otherwise , it is said to have the partial regularization ; in this case , a sophisticated hybrid variant is needed that combines the solver with some additional regularization in order to improve the accuracy of the regularized solution by the iterative solver at semi - convergence @xcite .",
    "it appears that the regularizing effects are closely related to the degree of ill - posedness of the problem . to this end",
    ", we introduce the following definition of the degree of ill - posedness , which follows hofmann s book @xcite and has been commonly used in the literature , e.g. , @xcite : if there exists a positive real number @xmath48 such that the singular values satisfy @xmath49 , the problem is termed as mildly or moderately ill - posed if @xmath50 or @xmath51 ; if @xmath52 with @xmath53 considerably , @xmath54 , the problem is termed severely ill - posed . clearly , the singular values @xmath55 of a severely ill - posed problem decay exponentially at the same rate @xmath56 , while those of a moderately or mildly ill - posed problem decay more and more slowly at the decreasing rate @xmath57 approaching one with increasing @xmath58 , which , for the same @xmath58 , is smaller for the moderately ill - posed problem than it for the mildly ill - posed problem .    for @xmath3 symmetric , its @xmath0-dimensional dominant eigenspace is identical to the @xmath0-dimensional dominant left and right singular subspaces . in this case ,",
    "minres and its variant mr - ii are natural alternatives to lsqr and cgls @xcite .",
    "mr - ii was originally designed for solving singular and inconsistent linear systems , and it uses the starting vector @xmath59 and restricts the resulting krylov subspace to the range of @xmath3 .",
    "thus , the iterates are orthogonal to the null space of @xmath3 , and mr - ii computes the minimum 2-norm least squares solution @xcite . for , we are not interested in such solution but a regularized solution that is close to @xmath28 as much as possible .",
    "minres and mr - ii have been shown to have regularizing effects and exhibit semi - convergence @xcite , and mr - ii usually provides better regularized solutions than minres . intuitively , this is because the noise @xmath9 in the initial krylov vector @xmath59 is filtered by multiplication with @xmath3 @xcite .",
    "different implementations associated with mr - ii have been studied @xcite . in this paper , we first prove that the minres iterates are filtered svd solutions , similar to the form of the lsqr iterates . based on this result",
    ", we show why minres , in general , has only the partial regularization , independent of the degree of ill - posedness of . as a result ,",
    "a hybrid minres that combines minres with a regularization method applied to the lower dimensional projected problems should be used to compute a best possible regularized solution ; see ( * ? ? ?",
    "* section 6.4 ) for details .",
    "afterwards , we take a closer look at the regularization of minres and mr - ii in more detail , which , from a new perspective , shows that minres has only the partial regularization .",
    "we prove that , though mr - ii has globally better regularizing effects than minres , the @xmath0th minres iterate is always more accurate than the @xmath1th mr - ii iterate until the semi - convergence of minres . in a manner different from those used in @xcite ,",
    "we then analyze the regularizing effects of mr - ii and draw some definitive conclusions .",
    "we establish bounds for the 2-norm distance between the underlying @xmath0-dimensional krylov subspace and the @xmath0-dimensional dominant eigenspace .",
    "the bounds indicate that the krylov subspace better captures the @xmath0-dimensional dominant eigenspace for severely and moderately ill - posed problems than for mildly ill - posed problems . as a consequence ,",
    "mr - ii has better regularizing effects for the first two kinds of problems than for the third kind , for which mr - ii has only the partial regularization .",
    "we then use the results to derive an estimate for the accuracy of the rank @xmath0 approximation generated by mr - ii to @xmath3 .",
    "finally , we derive estimates for the entries generated by the symmetric lanczos process that mr - ii is based on , and show how fast they decay .",
    "the paper is organized as follows . in section [ sectionrev ] , we describe minres and mr - ii . in section [ sectionmin ] , we prove that the minres iterates are filtered svd solutions , followed by an analysis on the regularizing effects of minres . in section [ sectioncom ] , we compare the regularizing effects of minres and mr - ii , and shed light on some new features of them . in section [ sectionmr2 ] , we present our theoretical results on mr - ii with a detailed analysis . in section [ sectionex ]",
    ", we numerically confirm our theory that minres has only the partial regularization for a general ill - posed problem and its hybrid variant is needed .",
    "also , we experimentally illustrate that mr - ii has the full regularization for severely and moderately ill - posed problems , which is stronger than our theory , and it has the partial regularization for mildly ill - posed problems .",
    "we also compare mr - ii with lsqr , demonstrating that mr - ii is as effective as and at least twice as efficient as lsqr .",
    "we conclude the paper in section [ sectioncon ] .    throughout the paper ,",
    "we denote by @xmath60 the @xmath0-dimensional krylov subspace generated by the matrix @xmath61 and the vector @xmath62 , by @xmath63 and @xmath64 the 2-norm of a matrix or vector and the frobenius norm of a matrix , respectively , and by @xmath65 the identity matrix with order clear from the context .",
    "minres @xcite is based on the symmetric lanczos process that constructs an orthonormal basis of the krylov subspace @xmath66 .",
    "let @xmath67 .",
    "the @xmath0-step symmetric lanczos process can be written in the matrix form @xmath68 where @xmath69 has orthonormal columns which form @xmath66 , and @xmath70 is a tridiagonal matrix with its leading @xmath71 submatrix symmetric .    at iteration @xmath0 ,",
    "minres solves @xmath72 for the iterate @xmath73 with @xmath74 where @xmath75 is the first canonical vector of dimension @xmath76 . for our analysis purpose , it is important to write @xmath77 which is the minimum 2-norm least squares solution of the perturbed problem that replace @xmath3 in by its rank @xmath0 approximation @xmath78 .",
    "mr - ii @xcite is a variant of minres applied to @xmath79 which excludes the noisy @xmath4 .",
    "the method is based on the @xmath0-step symmetric lanczos process @xmath80 where @xmath81 has orthonormal columns with @xmath82 , @xmath83 is a tridiagonal matrix with the diagonals @xmath84 , the subdiagonals @xmath85 and the superdiagonals @xmath86 , and the first @xmath0 rows of @xmath87 is symmetric . the columns of @xmath88 form an orthonormal basis of @xmath79 .",
    "mathematically , since the eigenvalues of @xmath3 are simple and @xmath59 has nonzero components in the directions of all the eigenvectors @xmath46 of @xmath3 , the lanczos process can be run to @xmath89 steps without breakdown , i.e. , @xmath90 and @xmath91 .    at iteration @xmath0",
    ", mr - ii solves @xmath92 for the iterate @xmath93 with @xmath94 similar to , we have the expression @xmath95 which is the minimum 2-norm least squares solution of the perturbed problem that replace @xmath3 in by its rank @xmath0 approximation @xmath96 .",
    "the significance of and lies that the minres and mr - ii iterates are the minimum 2-norm least squares solutions of the perturbed problems that replace @xmath3 in by its rank @xmath0 approximations @xmath78 and @xmath96 , respectively , whose @xmath0 nonzero singular values are just those of @xmath97 and @xmath87 , respectively",
    ". if the singular values of @xmath97 or @xmath87 approximate the @xmath0 large singular values of @xmath3 in natural order for @xmath98 , then @xmath78 and @xmath96 are near best rank @xmath0 approximations to @xmath3 with accuracy similar to that of the best rank @xmath0 approximation @xmath99 .",
    "if this is the case , minres and mr - ii must have the full regularization , and @xmath100 and @xmath101 are best possible regularized solutions and are as accurate as the best tsvd regularized solution @xmath45 .",
    "similar to the cgls and lsqr iterates @xcite , we can establish the following result on the minres iterates .",
    "[ thm1 ] for minres to solve with the starting vector @xmath67 , the @xmath0th iterate @xmath102 has the form @xmath103 where the filters @xmath104 with latexmath:[$|\\lambda_1| > |\\lambda_2|>\\cdots >    the harmonic ritz values of @xmath3 with respect to @xmath66 and labeled as @xmath106 .    _",
    "proof_. from @xcite , the residual @xmath107 of the minres iterate @xmath102 can be written as @xmath108 where the residual polynomial @xmath109 has the form @xmath110 with the @xmath111 the harmonic ritz values of @xmath3 with respect to @xmath66 . from , we get @xmath112 substituting @xmath113 into the above gives @xmath114 where @xmath115    relation shows that the minres iterate @xmath102 has a filtered svd expansion . for a general symmetric @xmath3 , the harmonic ritz values have an attractive feature : they usually favor extreme eigenvalues of @xmath3 , provided that a krylov subspace contains substantial information on all the eigenvectors @xmath46 @xcite . in our current context , if at least a small harmonic ritz value in magnitude starts to appear for some @xmath116 , i.e. , @xmath117 , the corresponding filter factors @xmath118 , @xmath119 , are not small , meaning that @xmath102 is already deteriorated . on the other hand ,",
    "if no small harmonic ritz value in magnitude appears before @xmath116 , the @xmath102 are expected to become better approximations to @xmath28 until @xmath120 .",
    "unfortunately , since @xmath66 includes the noisy @xmath121 , which contains non - negligible components of @xmath46 corresponding to small eigenvalues @xmath19 , it is generally possible that a small harmonic ritz value can appear for @xmath116 .",
    "this demonstrates that , in general , minres only has the partial regularization and can not obtain a best possible regularized solution .",
    "it was known a long time ago that mr - ii has better regularizing effects than minres , that is , mr - ii obtains a more accurate regularized solution than minres does @xcite .",
    "such phenomenon is simply due to the fact that @xmath66 for minres includes the noisy @xmath4 and @xmath79 for mr - ii contains less information on @xmath46 corresponding to small eigenvalues in magnitude since the noise @xmath9 in the starting vector @xmath59 is filtered by multiplication with @xmath3 .",
    "previously , we have given an analysis on the regularizing effects of minres and shown that a hybrid minres is generally needed for an ill - posed problem , independent of the degree of ill - posedness of .",
    "next we shed more light on the regularization of minres , compare it with mr - ii , and reveal some new features of them .    to simplify our discussions , without loss of generality",
    ", we can well assume that for a standard nonsingular linear system , the smaller residual , the more accurate the approximate solution is . given the residual minimization property of minres and mr - ii , one might be confused that , since @xmath122 , the @xmath0th minres iterate @xmath102 should be at least as accurate as the @xmath1th mr - ii iterate @xmath123 .",
    "this is true for solving the standard linear system where the right - hand side is supposed to be _ exact _ , but it is nontrivial and depends for solving an ill - posed problem , for which the @xmath4 is noisy and we are concerned with regularized approximations to the true solution @xmath28 other than the naive solution @xmath47 . our previous analysis has shown that a small harmonic ritz value @xmath124 generally appears for minres before some iteration @xmath116 , causing that minres has only the partial regularization . on the other hand , however , note that the regularized solutions @xmath102 by minres converge to @xmath28 until the semi - convergence of minres . as a result , because @xmath125 , the @xmath0th minres iterate @xmath102 is more accurate than the @xmath1th mr - ii iterate @xmath123 _ only until _ the semi - convergence of minres .",
    "we can also explain the partial regularization of minres in terms of the rank @xmath0 approximation @xmath78 to @xmath3 as follows : since the @xmath0-dimensional dominant eigenspace of @xmath3 is identical to its @xmath0-dimensional dominant left and right singular subspaces , @xmath66 contains substantial information on all the @xmath46 . as a result , it is generally possible that the projected matrix @xmath97 has a singular value smaller than @xmath126 for some @xmath116 .",
    "this means that @xmath78 is a poor rank @xmath0 approximation to @xmath3 , causing , from , that @xmath127 is generally large , i.e. , @xmath102 is already deteriorated .",
    "conversely , if no singular value of @xmath97 is smaller than @xmath126 and the semi - convergence of minres does not yet occur , the minres iterate @xmath102 should be at least as accurate as the mr - ii iterate @xmath123 because of @xmath122 .    in summary , we need to use a hybrid minres with the tsvd method or the standard - form tikhonov regularization applied to the projected problem in to expand the krylov subspace until it contains all the @xmath40 dominant spectral components and a best regularized solution is found , in which the additional regularization aims to remove the effects of small singular values of @xmath128 , similar to the hybrid lsqr see ( * ? ? ?",
    "* section 6.4 ) .",
    "before proceeding , we point out that , unlike for the minres iterates @xmath102 , we have found that the mr - ii iterates @xmath129 do not have filtered svd expansions of similar form .",
    "even so , we can establish a number of other results that help to better understand the regularization of mr - ii .",
    "we first investigate a fundamental problem : how well does the underlying subspace @xmath79 capture the @xmath0 dimensional dominant eigenspace of @xmath3 ?",
    "this problem is of basic importance because it critically affects the accuracy of @xmath96 as a rank @xmath0 approximation to @xmath3 .    in terms of the definition of canonical angles",
    "@xmath130 between the two subspaces @xmath131 and @xmath132 of the same dimension @xcite , we present the following result .    [ thm2 ] let @xmath133 be defined as , and assume that the singular values of @xmath3 are @xmath134 with @xmath53 .",
    "let @xmath135 be the @xmath0-dimensional dominant spectral subspace spanned by the columns of @xmath136 , and @xmath137 .",
    "then @xmath138 with the @xmath139 matrix @xmath140 to be defined by and @xmath141    _ proof_. note that @xmath142 is spanned by the columns of the @xmath143 matrix @xmath144 with @xmath145 partition @xmath146 and @xmath147 as follows : @xmath148 where @xmath149 .",
    "since @xmath150 is a vandermonde matrix with @xmath151 distinct for @xmath152 , it is nonsingular .",
    "noting @xmath153 , we have @xmath154 with @xmath155 define @xmath156 .",
    "then @xmath157 , and the columns of @xmath158 form an orthonormal basis of @xmath159 .",
    "write @xmath160 . by definition",
    ", we obtain @xmath161 which proves .",
    "we next estimate @xmath162 and establish upper bound for the right - hand side of .",
    "we have @xmath163    we now estimate @xmath164 .",
    "it is easily justified that the @xmath165th column of @xmath166 consists of the coefficients of the lagrange polynomial @xmath167 that interpolates the elements of the @xmath165th canonical basis vector @xmath168 at the abscissas @xmath169 .",
    "consequently , the @xmath165th column of @xmath170 is @xmath171 from which we obtain @xmath172 for a fixed @xmath173 satisfying @xmath174 , let @xmath175 .",
    "then we have @xmath176 therefore , for @xmath177 and @xmath174 , making use of taylor series expansions , we get @xmath178 by absorbing those higher order terms into @xmath179 . note that in the above numerator we have @xmath180 @xmath181 and @xmath182 it is easy to check that for any @xmath183 the product of the above three terms is no more than @xmath184 by definition , the factor @xmath185 in the denominator of , which is exactly one when @xmath186 , and it is bigger than one when @xmath187 ; the other factor @xmath188 is between @xmath189 and @xmath190 .",
    "therefore , for any @xmath0 and @xmath174 , we have @xmath191 from this estimate and it follows that @xmath192 as a result , for @xmath193 , from we have @xmath194    * remark 5.1 *  trivially , we have @xmath195 but in our context it is impossible to have @xmath196 since @xmath140 is not a zero matrix .",
    "we have seen from the proof that the factor @xmath197 in it is intrinsic and unavoidable in .",
    "but the factor @xmath198 in is an overestimate and can certainly be reduced .",
    "the reason is that is an overestimate since @xmath199 for @xmath165 not near to @xmath0 is considerably smaller than @xmath200 , @xmath201 but we replace all them by the maximum @xmath202 .",
    "in fact , our derivation before and when replacing @xmath203 by @xmath165 clearly illustrates that the smaller @xmath165 is , the smaller @xmath199 than @xmath204 , @xmath201 .",
    "recall the discrete picard condition .",
    "then the coefficients @xmath205 we see that , the larger @xmath206 is , the smaller @xmath207 , which is a constant for @xmath116 , and thus the better @xmath159 captures @xmath208 . for @xmath209 , since all the @xmath210 are roughly the same , we have @xmath211 , meaning that @xmath159 may not capture @xmath208 so well after iteration @xmath40 .",
    "* remark 5.2 *  the theorem can be extended to moderately ill - posed problems with the singular values @xmath212",
    ", @xmath51 considerably and @xmath0 not big , where the factor @xmath213 in is replaced by a bigger @xmath214 .",
    "let us look into why it is so .",
    "recall that , by definition , @xmath215 for @xmath174 . using a similar proof to that of theorem  [ thm2 ] and the first order taylor expansion",
    ", we can roughly estimate @xmath216 as follows : @xmath217 this estimate is not as accurate as that for severely ill - posed problems .",
    "more important is that it depends on @xmath0 and increases slowly as @xmath0 increases .",
    "the above estimate can be improved when @xmath3 is symmetric definite : @xmath218 smaller than the previous one .",
    "the two estimates mean that @xmath159 may capture @xmath208 better for @xmath3 symmetric definite than for @xmath3 symmetric indefinite where there are both positive and negative ones among the first @xmath76 large eigenvalues .    * remark 5.3 *",
    "a combination of and and the above analysis indicate that @xmath159 captures @xmath208 better for severely ill - posed problems than for moderately ill - posed problems .",
    "there are two reasons for this .",
    "the first is that the factors @xmath219 are basically fixed constants for severely ill - posed problems as @xmath0 increases , and they are smaller than the counterparts for moderately ill - posed problems unless the degree @xmath48 of its ill - posedness is far bigger than one and @xmath0 small . the second is that the factor @xmath213 is smaller for severely ill - posed problems than the factor @xmath214 for moderately ill - posed problems .",
    "* remark 5.4 *  the situation is fundamentally different for mildly ill - posed problems : firstly , we always have @xmath220 substantially for @xmath221 , @xmath222 and any @xmath0 .",
    "secondly , @xmath223 defined by is closer to one than that for moderately ill - posed problems for @xmath98 .",
    "thirdly , for the same noise level @xmath224 and @xmath206 , from the discrete picard condition and the definition of @xmath40 we see that @xmath40 is bigger for a mildly ill - posed problem than that for a moderately ill - posed problem .",
    "all of them show that @xmath159 captures @xmath208 _ considerably better _ for severely and moderately ill - posed problems than for mildly ill - posed problems .",
    "in other words , our results imply that @xmath159 contains substantial information on the other @xmath225 eigenvectors for mildly ill - posed problems , causing that a small harmonic ritz value generally appears for some @xmath116 , especially when @xmath40 is not small .",
    "equivalently , the projected matrix @xmath87 generated by mr - ii generally has a small singular value for some @xmath116 , such that the solution @xmath129 is deteriorated , as deduced from . as a result , we are certain that mr - ii has better regularizing effects for severely and moderately ill - posed problems than for mildly ill - posed problems .",
    "most importantly , by this property , since mr - ii has _ at most _ the full regularization for severely and moderately ill - posed problems , we deduce and are thus sure that mr - ii generally has only the partial regularization for mildly ill - posed problems .",
    "we mention that , in comparison with the results , i.e. , theorem 2.1 , in @xcite on lsqr , we find that @xmath79 is as comparably effective as @xmath226 , on which lsqr works , for capturing the @xmath0-dimensional dominant eigenspace .",
    "let us get more insight into the regularization of mr - ii .",
    "recall , where @xmath227 define @xmath228 which measures the quality or accuracy of the rank @xmath0 approximation @xmath96 to @xmath3 .",
    "this quantity is central and fundamental to understand the regularizing effects of mr - ii and measures how the iterates @xmath129 by mr - ii behave like the tsvd regularized solution @xmath229 .",
    "particularly , note that the best rank @xmath40 approximation @xmath230 satisfies @xmath231 .",
    "then if @xmath232 for @xmath126 reasonably small , @xmath233 is a near best rank @xmath40 approximation to @xmath3 with approximate accuracy @xmath126 and has no small nonzero singular value . in this case , the regularized solution @xmath101 is close to the best tsvd regularized solution @xmath45 , and mr - ii has the full regularization . otherwise , if @xmath234 considerably , then @xmath233 deviates from the best rank @xmath0 approximation @xmath230 considerably and @xmath101 is not close to @xmath45 , meaning that mr - ii has only the partial regularization .",
    "based on theorem  [ thm2 ] and remark 5.2 , we can derive the following estimates for @xmath235 .",
    "[ thm3 ] assume that is severely or moderately ill posed .",
    "then latexmath:[\\[\\label{gamma }        _ proof_. note that @xmath96 is of rank @xmath0",
    ". the lower bound in is trivial since the best @xmath0 approximation @xmath99 to @xmath3 satisfies @xmath237 .",
    "we next prove the upper bound . from",
    ", we obtain @xmath238 from theorem [ thm2 ] , it is known that @xmath239 .",
    "let @xmath240 and @xmath241 .",
    "then by the definition of @xmath242 we obtain @xmath243    our later numerical experiments will indicate that @xmath244 for severely and moderately ill - posed problems , illustrating that @xmath96 is a near best rank @xmath0 approximation to @xmath3 with the approximate accuracy @xmath245 .",
    "particularly , since @xmath232 , the mr - ii iterate @xmath246 is close to the tsvd solution @xmath45 provided that @xmath126 .",
    "furthermore , we will find that the error @xmath247 of mr - ii iterate @xmath101 is as small as the error @xmath248 of the best tsvd solution @xmath45 .",
    "this indicates that mr - ii has the full regularization .",
    "experimentally , for severely and moderately ill - posed problems , the observations @xmath249 appear to be general and thus should have strong theoretical supports .",
    "our upper bound in appears to be a considerable overestimate .",
    "recall that @xmath84 and @xmath250 denote the diagonals and subdiagonals of @xmath87 defined by , respectively .",
    "we next establish some interesting and intimate relationships between them and @xmath235 , showing how fast @xmath251 and @xmath252 decay .",
    "[ thm4 ] for @xmath253 we have @xmath254    _",
    "proof_. since the lanczos process can be run to completion , we have @xmath255 where @xmath256 is orthogonal , and @xmath257 is symmetric tridiagonal .",
    "thus , from we have @xmath258 where @xmath259 from which and @xmath260 it follows that @xmath261 and @xmath262 for @xmath253 . therefore , and hold .",
    "this theorem indicates that @xmath263 and @xmath264 decay at least as fast as @xmath235 .",
    "moreover , based on the experimental observations that @xmath265 for severely and moderately ill - posed problems , the theorem illustrates that @xmath263 and @xmath264 decay as fast as @xmath245 , @xmath253 , for these two kinds of problems .",
    "in this section , we report numerical experiments to illustrate the regularizing effects of minres and mr - ii and make a number of comparisons .",
    "we justify our theory : ( i ) minres has only the partial regularization , independent of the degree of ill - posedness , and a hybrid minres is generally needed ; ( ii ) the @xmath0th minres iterate @xmath102 is always more accurate than the @xmath1th mr - ii iterate @xmath123 until the semi - convergence of minres ; ( iii ) mr - ii has only the partial regularization for mildly ill - posed problems , and a hybrid mr - ii is needed .",
    "in the meantime , experimentally , we demonstrate a remarkable and attractive feature , stronger than our theory predicts : mr - ii has the full regularization for severely and moderately ill - posed problems and its iterates at semi - convergence is as accurate as the best tsvd solutions for these two kinds of problems .",
    "we will use the function @xmath266 in @xcite to depict the l - curves . in order to simulate exact arithmetic ,",
    "the lanczos process with reorthogonalization is used in minres and mr - ii .",
    "table  [ table ] lists test problems and their degree of ill - posedness , all of which are symmetric and arise from the discretization of the first kind fredholm integral equations ; see hansen s regularization toolbox @xcite for details . for each problem except the 2d image deblurring problem ` blur ' , we use the corresponding code in @xcite to generate a @xmath267 matrix @xmath3 , the true solution @xmath28 and noise - free right - hand @xmath25 . in order to simulate the noisy data",
    ", we generate the white noise vector @xmath9 whose entries are normally distributed with mean zero , such that the relative noise level @xmath268 , respectively . to simulate exact arithmetic ,",
    "the full reorthogonalization is used during the lanczos process .",
    "we remind that , as far as ill - posed problem is concerned , our primary goal consists in justifying the regularizing effects of iterative solvers , which are _ unaffected by sizes _ of ill - posed problems and only depends on the degree of ill - posedness . therefore , for this purpose , as extensively done in the literature ( see , e.g. , @xcite and the references therein ) , it is enough to test not very large problems . indeed , for @xmath89 large , say , 1,0000 , we have observed completely the same behavior as that for @xmath89 not large , e.g. , @xmath269 used in this paper except for the problem ` blur ' with @xmath270 .",
    "a reason for using @xmath89 not large is because such choice makes it practical to fully justify the regularization effects of lsqr by comparing it with the tsvd method , which suits only for small and/or medium sized problems for computational efficiency .",
    "all the computations are carried out using matlab 7.8 with the machine precision @xmath271 under the microsoft windows 7 64-bit system .",
    "12.1cm@lll problem & description & ill - posedness + shaw & one - dimensional image restoration model & severe + foxgood & severely ill - posed test problem & severe + gravity & one - dimensional gravity surveying problem & severe + phillips & phillips `` famous '' test problem & moderate + deriv2 & computation of second derivative & mild + blur & 2d image deblurring test problem & mild / moderate +    [ table ]      we now compare minres and mr - ii and justify our theory : ( i ) the mr - ii iterate is always more accurate than the minres iterate at their respective semi - convergence , meaning that minres can not obtain best possible regularized solutions and has only the partial regularization , independent of the degree of ill - posedness ; ( ii ) the minres iterates @xmath102 are always more accurate that the mr - ii iterates @xmath123 until the semi - convergence of minres .    in this subsection , we only report the results for the noise level @xmath272 .",
    "results for the other two @xmath273 are analogous and thus omitted .     by minres and mr - ii ;",
    "( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for shaw ( left ) and foxgood ( right).,width=264,height=188 ]    ( a )     by minres and mr - ii ; ( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for shaw ( left ) and foxgood ( right).,width=264,height=188 ]    ( b )     by minres and mr - ii ; ( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for shaw ( left ) and foxgood ( right).,width=264,height=188 ]    ( c )     by minres and mr - ii ; ( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for shaw ( left ) and foxgood ( right).,width=264,height=188 ]    ( d )     by minres and mr - ii ; ( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for gravity ( left ) and phillips ( right ) . , width=264,height=188 ]    ( a )     by minres and mr - ii ; ( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for gravity ( left ) and phillips ( right ) .",
    ", width=264,height=188 ]    ( b )     by minres and mr - ii ; ( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for gravity ( left ) and phillips ( right ) .",
    ", width=264,height=188 ]    ( c )     by minres and mr - ii ; ( c)-(d ) : plots of the singular values ( circles for minres , stars for mr - ii ) of the projected matrices and the ones ( solid lines ) of @xmath3 for gravity ( left ) and phillips ( right ) . , width=264,height=188 ]    ( d )    figures  [ fig1 ] and [ fig2 ] display numerous curves for severely and moderately ill - posed problems",
    ". clearly , all the mr - ii ierates are always more accurate than the minres iterates at their respective semi - convergence .",
    "this indicates that minres has only the partial regularization . as elaborated previously , this is because that a small singular value of the projected matrix @xmath97 appears before a regularized solution becomes best , causing that its error does not reach the same error level as that obtained by mr - ii .",
    "for instance , we see from figure  [ fig1 ] ( a ) and ( c ) that all the singular values of @xmath87 in mr - ii are excellent approximations to the @xmath0 large singular values of @xmath3 in natural order for @xmath274 .",
    "we see that the semi - convergence of mr - ii occurs at iteration @xmath275 . by the comments in the end of section  [ sectionrev ] and the explanations after",
    ", this clearly justifies the full regularization of mr - ii , and the best possible regularized solution by mr - ii includes _ seven _ dominant spectral or svd components . on the other hand ,",
    "it is clearly seen from figure  [ fig1 ] ( c ) that the smallest singular value of @xmath276 in minres is smaller than @xmath277 , making the relative error starts to increase dramatically at iteration 5 and minres have only the partial regularization .",
    "similar phenomena are observed for foxgood , and mr - ii has the full regularization with @xmath278 , as indicated by figure  [ fig1 ] ( b ) and ( d ) , where the smallest singular value of @xmath279 lies between @xmath280 and @xmath281 and the best iterate @xmath102 by minres at semi - convergence is considerably less accurate than the best iterate @xmath129 by mr - ii at semi - convergence , meaning that minres has only the partial regularization .",
    "we have analogous findings for gravity and phillips , as shown by figure  [ fig2 ] ( b ) and ( d ) , which again demonstrate that mr - ii has the full regularization but minres has only the partial regularization .    as for the mildly ill - posed problem deriv2",
    ", we also see from figure  [ fig3 ] ( a ) that the relative error obtained by mr - ii clearly reaches the lower minimum level than that by minres , indicating that mr - ii has better regularizing effects than minres .",
    "the above experiments have illustrated that mr - ii always obtains more accurate regularized solutions than minres does for the test severely , moderately and mildly problems .",
    "this justifies our theory that minres only has the partial regularization , independent of the degree of ill - posedness .",
    "therefore , one must use a hybrid minres with some regularization method applied to the projected problems in order to remove the effects of small singular values of @xmath97 and improve the accuracy of regularized solutions until a best regularized solution is found .",
    "it is clear from figures  [ fig1][fig2 ] and figure  [ fig3 ] ( a ) that , for each test problem , the minres iterates @xmath102 are more accurate than the corresponding mr - ii iterates @xmath123 until the semi - convergence of minres .",
    "afterwards , the regularized solutions @xmath102 are deteriorated more and more seriously .",
    "this confirms our theory in section  [ sectioncom ] , i.e. , assertion ( ii ) in the beginning of this subsection .",
    "we first test mr - ii , minres and their hybrid variants for the mildly ill - posed problem deriv2 , and justify our theory that mr - ii has only the partial regularization and one must use its hybrid variant to compute a best possible regularized solution .     by the pure minres and mr - ii as well as the hybrid minres and mr - ii ; ( b ) : the l - curves of minres and mr - ii for deriv2.,width=264,height=188 ]    ( a )     by the pure minres and mr - ii as well as the hybrid minres and mr - ii ; ( b ) : the l - curves of minres and mr - ii for deriv2.,width=264,height=188 ]    ( b )    for deriv2 , figure  [ fig3 ] ( a ) shows that the relative errors of regularized solutions obtained by the hybrid minres and mr - ii with the tsvd regularization method applied to the projected problems reach a considerably smaller minimum level than those by minres and mr - ii themselves . for this problem , before minres or mr - ii captures all the dominant spectral components needed , a small singular value of @xmath97 or @xmath87 appears and starts to deteriorate the regularized solutions .",
    "in contrast , their hybrid variants expand krylov subspaces until enough dominant spectral components are captured and the tsvd regularization method effectively dampens the svd components corresponding to small singular values of the projected matrices @xmath97 by minres and @xmath87 by mr - ii .",
    "for example , we see from figure  [ fig3 ] ( a ) that the semi - convergence of mr - ii occurs at iteration @xmath282 , which is also observed by the corner of the l - curve depicted by figure  [ fig3 ] ( b )",
    ". however , as shown by figure  [ fig3 ] ( a ) , such regularization of mr - ii is not enough , and the hybrid mr - ii uses a larger six dimensional krylov subspace @xmath283 to improve the solutions and get a best possible regularized solution , whose residual norm is smaller than that obtained by the pure mr - ii .",
    "after @xmath284 , the regularized solutions almost stabilize with the minimum error as @xmath0 increases .",
    "we observe similar phenomena for minres and its hybrid variant , where we find that the relative error by the hybrid minres reaches the same minimum level as that by the hybrid mr - ii .",
    "next we test mr - ii , minres and their hybrid variants for severely and moderately ill - posed problems .",
    "we attempt to get more insight into the regularizing effects of mr - ii . as a matter of fact",
    ", we have already justified the full regularization of mr - ii for the four test problems in section  [ seccom ] . in what follows",
    ", we will give more details and justifications on the full regularization of mr - ii .",
    "we show that ( i ) the relative error obtained by the hybrid minres reaches the same minimum level as that by the hybrid mr - ii ; ( ii ) mr - ii has the full regularization effects : at semi - convergence , the regularized solution by the pure mr - ii is as accurate as that by the hybrid mr - ii with the tsvd regularization used within projected problems ; ( iii ) mr - ii generates near best rank @xmath0 approximations @xmath96 to @xmath3 , i.e. , the relation @xmath285 holds with different noise levels .",
    "keep in mind and .",
    "this means that @xmath96 generated by mr - ii plays the same role as @xmath99 , the best rank @xmath0 approximation to @xmath3 , so that mr - ii has the full regularization .     by mr - ii , and",
    "hybrid mr - ii and minres with additional tsvd regularization for shaw , foxgood , gravity , phillips ( from top left to bottom right ) .",
    ", width=264,height=188 ]    ( a )     by mr - ii , and hybrid mr - ii and minres with additional tsvd regularization for shaw , foxgood , gravity , phillips ( from top left to bottom right ) .",
    ", width=264,height=188 ]    ( b )     by mr - ii , and hybrid mr - ii and minres with additional tsvd regularization for shaw , foxgood , gravity , phillips ( from top left to bottom right ) . , width=264,height=188 ]    ( c )     by mr - ii , and hybrid mr - ii and minres with additional tsvd regularization for shaw , foxgood , gravity , phillips ( from top left to bottom right ) .",
    ", width=264,height=188 ]    ( d )    for mr - ii and the hybrid mr - ii , we observe from figure  [ fig4 ] that mr - ii reaches the same error level as the hybrid mr - ii , and the tsvd regularization applied to projected problems simply makes the regularized solutions with the minimum error almost stabilize and does not improve the regularized solution by mr - ii at semi - convergence .",
    "this justifies the full regularization of mr - ii .",
    "compared with figures  [ fig1][fig2 ] , we find from figure  [ fig4 ] that the hybrid minres improves on minres substantially and the relative errors of iterates by the hybrid minres reach the same minimum level as mr - ii and the hybrid mr - ii .",
    "these phenomena again justify our assertion in section [ sectioncom ] that the hybrid minres is necessary , independent of the degree of ill - posedness , and the hybrid minres is as effective as the hybrid mr - ii .",
    "figure  [ fig5 ] and figure  [ fig7 ] display the curves of sequences @xmath235 with the noise levels @xmath286 , respectively , for the four severely and moderately problems . we see that @xmath285 , almost independent of noise level @xmath273 .",
    "we point out that , due to the round - offs in finite precision arithmetic , they level off at the level of @xmath287 when @xmath288 for shaw , @xmath289 for foxgood and @xmath290 for gravity .",
    "the results indicate that the @xmath96 are near best rank @xmath0 approximations to @xmath3 with the approximate accuracy @xmath245 so that @xmath87 does not become ill - conditioned before @xmath116 . as a result ,",
    "the regularized solutions @xmath129 become increasingly better approximations to @xmath28 until iteration @xmath40 , and they are deteriorated after that iteration . at iteration @xmath40 , @xmath101 captures the @xmath40 dominant spectral or equivalent svd components of @xmath3 and is a best possible regularized solution , i.e. , mr - ii has the full regularization for the severely ill - posed problems tested .",
    "figure  [ fig6 ] and figure  [ fig8 ] plot the relative errors @xmath291 with different noise levels for these four severely and moderately ill - posed problems . for smaller noise levels",
    ", mr - ii gets more accurate best regularized solutions at cost of more iterations .",
    "this is expected since , from and @xmath292 , a bigger @xmath40 is needed for a smaller noise level @xmath224 . moreover , mr - ii needs more iterations to achieve semi - convergence for moderately ill - posed problems with the same noise level , since @xmath55 does not decay as fast as that for a severely ill - posed problem .     and",
    "@xmath293 for shaw with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for foxgood with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( a )     and @xmath293 for shaw with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for foxgood with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( b )     and @xmath293 for shaw with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for foxgood with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( c )     and @xmath293 for shaw with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for foxgood with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( d )     with respect to @xmath286 for shaw ( left ) and foxgood ( right ) by mr - ii.,width=264,height=188 ]    ( a )     with respect to @xmath286 for shaw ( left ) and foxgood ( right ) by mr - ii.,width=264,height=188 ]    ( b )     and @xmath293 for gravity with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for phillips with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( a )     and @xmath293 for gravity with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for phillips with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( b )     and @xmath293 for gravity with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for phillips with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( c )     and @xmath293 for gravity with @xmath294 ( left ) and @xmath272 ( right ) by mr - ii ; ( c)-(d ) : plots of decaying behavior of the sequences @xmath235 and @xmath293 for phillips with @xmath272 ( left ) and @xmath295 ( right ) by mr - ii.,width=264,height=188 ]    ( d )     with respect to @xmath286 for gravity ( left ) and phillips ( right ) by mr - ii.,width=264,height=188 ]    ( a )     with respect to @xmath286 for gravity ( left ) and phillips ( right ) by mr - ii.,width=264,height=188 ]    ( b )    figures  [ figpl ] display the decreasing curves of quantities @xmath296 , @xmath252 and @xmath297 , @xmath298 . from figure  [ figpl ] ( a )",
    ", we see that , for the severely ill - posed problem shaw , @xmath296 and @xmath252 decrease as fast as @xmath299 and the three quantities level off at the level of @xmath287 for @xmath0 no more than 20 , and after that these quantities are purely round - offs and not reliable any more .",
    "similar phenomena are also observed for the other two severely ill - posed problems foxgood and gravity , as indicated by figure  [ figpl ] ( b ) and ( c ) . figure  [ figpl ] ( d ) illustrates that @xmath252 decreases as fast as @xmath299 but @xmath296 decays as fast as @xmath297 in the first iterations and then considerably faster than @xmath297 as @xmath0 increases in the later stage for moderately ill - posed problem phillips .",
    ", @xmath252 and @xmath299 for shaw , foxgood , gravity , phillips ( from top left to bottom right ) with @xmath272 by mr - ii.,width=264,height=188 ]    ( a )    , @xmath252 and @xmath299 for shaw , foxgood , gravity , phillips ( from top left to bottom right ) with @xmath272 by mr - ii.,width=264,height=188 ]    ( b )    , @xmath252 and @xmath299 for shaw , foxgood , gravity , phillips ( from top left to bottom right ) with @xmath272 by mr - ii.,width=264,height=188 ]    ( c )    , @xmath252 and @xmath299 for shaw , foxgood , gravity , phillips ( from top left to bottom right ) with @xmath272 by mr - ii.,width=264,height=188 ]    ( d )    finally , we report some comparison results on lsqr , the hybrid lsqr and mr - ii , the hybrid mr - ii .",
    "as already proved in @xcite , a hybrid lsqr should be used to compute best possible regularized solutions for mildly ill - posed problems .",
    "it has also been experimentally justified in @xcite that lsqr has the full regularization for severely and moderately ill - posed problems .",
    "we have tested lsqr and the hybrid lsqr , and compared their effectiveness and efficiency with mr - ii and the hybrid mr - ii .",
    "we have found that , for each of the severely and moderately ill - posed problems in table  [ table ] and with the same noise level , both the pure",
    "mr - ii and lsqr obtain the best regularized solutions with almost the same accuracy using almost the same iterations . for deriv2 ,",
    "the hybrid mr - ii and lsqr compute the best possible regularized solutions using almost the same iterations .",
    "these results tell us two things : ( i ) as an iterative regularization method , mr - ii is as effective as lsqr for an ill - posed problem ; ( ii ) mr - ii is twice as efficient as lsqr .",
    "the problem blur is a 2d image deblurring problem and more complex than the other five 1d problems in table  [ table ] .",
    "it arises in connection with the degradation of digital images by atmospheric turbulence blur .",
    "we use the code @xmath300 in @xcite to generate an @xmath301 matrix @xmath3 , the true solution @xmath28 and noise - free right - hand @xmath25 .",
    "the vector @xmath28 is a columnwise stacked version of a simple test image , while @xmath302 holds for a columnwise stacked version of the blurred image .",
    "the blurring matrix @xmath3 is block toeplitz with toeplitz blocks , which has two parameters @xmath303 and @xmath304 ; the former specifies the half - bandwidth of the toeplitz blocks , and the latter controls the shape of the gaussian point spread function and thus the amount of smoothing .",
    "we generate a blurred and noisy image @xmath121 by adding a while noise vector @xmath9 .",
    "the goal is to restore the true image @xmath28 from @xmath4 .",
    "we take @xmath305 and the relative noise level @xmath306 , giving rise to @xmath3 with order @xmath307 .",
    "it is known that the larger the @xmath304 , the less ill - posed the problem .",
    "purely for an experimental purpose , we computed all the singular values of a few @xmath3 with @xmath308 using the matlab function svd . since the degree of ill - posedness is the same for different large @xmath309 , we have deduced from the computed singular values for these matrices @xmath3 that @xmath310 ( the default setting ) generates",
    "mildly ill - posed problems , while @xmath311 gives rise to moderately ill - posed problems .",
    "we next test minres , mr - ii and their hybrid variants for these two problems , and verify the regularizing effects similar to the previous mildly and moderately ill - posed problems : deriv2 and phillips .     by minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath310.,width=226,height=170 ]    ( a )     by minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath310.,width=264,height=188 ]    ( b )     by minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath310.,width=264,height=188 ]    ( c )     by minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath310.,width=264,height=188 ]    ( d )     with respect to minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath311.,width=226,height=170 ]    ( a )     with respect to minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath311.,width=264,height=188 ]    ( b )     with respect to minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath311.,width=264,height=188 ]    ( c )     with respect to minres , hybrid minres , mr - ii , and hybrid mr - ii ; ( b ) : the original image ; ( c ) : the blurred and noisy image ; ( d ) : the restored image with @xmath311.,width=264,height=188 ]    ( d )    figure  [ fig11 ] ( a ) shows that minres and mr - ii have the partial regularization for the mildly ill - posed problem blur .",
    "the semi - convergence of the two methods occurs at the very first iteration , then regularized solutions are progressively deteriorated , while the hybrid minres finds the best possible regularized solution at iteration @xmath312 and the hybrid mr - ii does so at @xmath313 .",
    "moreover , we see that the hybrid minres and mr - ii reaches the same minimum error level .",
    "figure  [ fig11 ] exhibits the restoration performance , where the restored image is chosen by the regularized solution at the iteration where the hybrid mr - ii first reaches the minimum error level .",
    "we observe from figure  [ fig11 ] ( d ) that the outline of original image is restored quite well by the restored image .    from figure  [ fig12 ] ( a )",
    ", we see that the semi - convergence of mr - ii occurs at the first iteration and the regularized solution at this iteration is as accurate as those obtained by the hybrid mr - ii and minres for the moderately ill - posed problem blur . therefore , mr - ii has the full regularization for this problem .",
    "in contrast , minres has only the partial regularization because its regularized solution at semi - convergence is much less accurate than that obtained by mr - ii .",
    "in addition , we observe that the hybrid minres and the hybrid mr - ii simply make the regularized solutions almost stabilize with the minimum error .",
    "figure  [ fig12 ] ( d ) exhibits the restored image , which is a good approximation to the original image .",
    "for large scale symmetric discrete linear ill - posed problems , minres and mr - ii are natural alternatives to lsqr .",
    "our theory and experiments have shown that minres has only the partial regularization and its hybrid variant is needed to find best possible regularized solutions , independent of the degree of ill - posedness .",
    "we have proved that mr - ii has better regularizing effects for severely and moderately ill - posed problems than for mildly ill - posed problems , and it generally has only the partial regularization for mildly ill - posed problems .",
    "we have shown that although mr - ii is a better regularization method than minres , the @xmath0th minres iterate is always more accurate than the @xmath1th mr - ii iterate until the semi - convergence of minres .",
    "we have also established estimates for the entries generated by the lanczos process working on @xmath314 , showing how fast they decay .",
    "all these results have been confirmed numerically .",
    "remarkably , stronger than our theory predicts , we have numerically demonstrated that mr - ii has the full regularization for severely and moderately ill - posed problems and can compute best possible regularized solutions . as a comparison of mr - ii and lsqr for a general symmetric ill - posed problem ,",
    "our theory experiments have indicated that two methods have very similar regularizing effects but mr - ii is twice as efficient as lsqr , so do their hybrid variants .",
    "therefore , for a large scale symmetric problem , mr - ii may be preferable to lsqr .",
    "some problems need to be further considered .",
    "as we have seen , more appealing is a sharp estimate for @xmath162 other than @xmath315 .",
    "the quantity @xmath242 needs a more subtle analysis and plays a central role in accurately estimating the accuracy @xmath235 of the rank @xmath0 approximation generated by the lanczos process working on @xmath314 .",
    "as we have elaborated , studying how near @xmath235 is to @xmath245 is a central problem that completely understands the regularizing effects of mr - ii .",
    "our bounds in theorems  [ thm2][thm3 ] are less sharp and need to be improved on ."
  ],
  "abstract_text": [
    "<S> for large scale symmetric discrete ill - posed problems , minres and mr - ii are often used iterative regularization solvers . </S>",
    "<S> we call a regularized solution best possible if it is at least as accurate as the best regularized solution obtained by the truncated singular value decomposition ( tsvd ) method . in this paper </S>",
    "<S> , we analyze their regularizing effects and establish the following results : ( i ) the filtered svd expression are derived for the regularized solutions by minres ; ( ii ) a hybrid minres that uses explicit regularization within projected problems is needed to compute a best possible regularized solution to a given ill - posed problem ; ( iii ) the @xmath0th iterate by minres is more accurate than the @xmath1th iterate by mr - ii until the semi - convergence of minres , but mr - ii has globally better regularizing effects than minres ; ( iv ) bounds are obtained for the 2-norm distance between an underlying @xmath0-dimensional krylov subspace and the @xmath0-dimensional dominant eigenspace . they show that mr - ii has better regularizing effects for severely and moderately ill - posed problems than for mildly ill - posed problems , and a hybrid mr - ii is needed to get a best possible regularized solution for mildly ill - posed problems ; ( v ) bounds are derived for the entries generated by the symmetric lanczos process that mr - ii is based on , showing how fast they decay . </S>",
    "<S> numerical experiments confirm our assertions . </S>",
    "<S> stronger than our theory , the regularizing effects of mr - ii are experimentally shown to be good enough to obtain best possible regularized solutions for severely and moderately ill - posed problems .    </S>",
    "<S> * keywords : * symmetric ill - posed problem , regularization , partial regularization , full regularization , semi - convergence , mr - ii , minres , lsqr , hybrid .    </S>",
    "<S> * mathematics subject classifications ( 2010 ) * : 65f22 , 65j20 , 15a18 . </S>"
  ]
}