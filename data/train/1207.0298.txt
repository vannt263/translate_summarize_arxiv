{
  "article_text": [
    "correlations are an established feature of neural activity @xcite and evidence increases that they can provide insights into the information processing in the brain @xcite . the temporal relationship between the activity of pairs of neurons",
    "is described by correlation functions .",
    "their shape has early been related to the direct coupling between neurons and to the common input shared by pairs of neurons . on the one hand",
    ", correlations may limit the signal - to - noise ratio of population rate signals @xcite , on the other hand they have been shown to increase the amount of information available to unbiased observers @xcite .",
    "furthermore , synchronous neural activity has been proposed to bind elementary representations into more complex objects @xcite and experimental evidence for such a correlation code is provided by task related modulation of synchrony in primary visual cortex @xcite and in motor cortex @xcite .",
    "the small magnitude @xcite of pairwise correlations in the asynchronous irregular state @xcite of cortex has recently been related to the balance between excitation and inhibition in local networks @xcite and inhibitory feedback was identified as a general mechanism of decorrelation @xcite .",
    "however , a quantitative theory explaining the temporal shape of correlation functions in recurrently impulse coupled networks of excitatory and inhibitory cells remained elusive .    assuming random connectivity with identical numbers and strengths of incoming synapses per neuron , as illustrated in , suggests by mean field arguments @xcite that the resulting activity of two arbitrarily selected neurons and hence the power spectra of activities averaged over excitatory or inhibitory neurons should be the same .",
    "direct simulations , however , exhibit different power spectra for these sub - populations @xcite .",
    "a similar argument holds for the covariance @xmath0 between the two neurons : if the covariance @xmath1 between any pair of inputs is known , the covariance between their outgoing activity @xmath0 is fully determined @xcite . by self - consistency , as both neurons belong to the same recurrent network , one concludes that @xmath2 .",
    "in particular the covariance averaged over excitatory pairs should be identical to the corresponding average over inhibitory pairs , which is in contrast to direct simulation ( b ) . in this work ,",
    "we elucidate why this mean field argument for covariances fails and derive a self - consistency equation for pairwise covariances in recurrent random networks which explains the differences in the power spectra and covariances .    ) and inhibitory ( @xmath3 ) neurons in the network , so the input statistics of all neurons is the same .",
    "the covariance @xmath1 within the network determines the covariance between the inputs to a pair of neurons and hence the covariance @xmath0 of their outputs .",
    "self - consistency seems to require @xmath4 . *",
    "( b ) * covariance functions averaged over pairs of excitatory ( @xmath5 ) and over pairs of inhibitory ( @xmath6 ) integrate - and - fire model neurons are different in a direct simulation .",
    "other parameters are given in . ]",
    "theories for pairwise covariances have been derived for binary neuron models @xcite and for excitatory stochastic point process models @xcite .",
    "however , the lack of either inhibition or delayed pulsed interaction limits the explanatory power of these models . a theory for networks of leaky integrate - and - fire ( lif ) model neurons @xcite",
    "is required , because this model has been shown to well approximate the properties of mammalian pyramidal neurons @xcite and novel experimental techniques allow to reliably assess the temporal structure of correlations in cortex @xcite . moreover , the relative timing of action potentials is the basis for models of synaptic plasticity @xcite , underlying learning in biological neural networks .",
    "analytical methods to treat population fluctuations in spiking networks are well advanced @xcite and efficient hybrid analytical - numerical schemes exist to describe pairwise covariances @xcite . here",
    "we present an analytically solvable theory of pairwise covariances in random networks of spiking leaky integrate - and - fire model neurons with delayed pulsed interaction in the asynchronous irregular regime .",
    "we consider recurrent random networks of @xmath7 excitatory and @xmath8 inhibitory leaky integrate - and - fire model neurons receiving pulsed input ( spikes ) from other neurons in the network .",
    "each neuron has @xmath9 incoming excitatory synapses independently and randomly drawn from the pool of excitatory neurons , and @xmath10 inhibitory synapses ( homogeneous erds - rnyi random network with fixed in - degree ) .",
    "an impulse at time @xmath11 arrives at the target neuron after the synaptic delay @xmath12 and elicits a synaptic current @xmath13 that decays with time constant @xmath14 and causes a response in the membrane potential @xmath15 ( with time constant @xmath16 proportional to the synaptic efficacy @xmath17 ( excitatory ) or @xmath18 ( inhibitory ) , respectively .",
    "the coupled set of differential equations governing the subthreshold dynamics of a single neuron @xmath19 is @xcite @xmath20 where the membrane resistance was absorbed into @xmath21 .",
    "if @xmath15 reaches the threshold @xmath22 at time point @xmath23 the neuron emits an action potential and the membrane potential is reset to @xmath24 , where it is clamped for the refractory time @xmath25 .",
    "the spiking activity of neuron @xmath19 is described by this sequence of action potentials , the spike train @xmath26 .",
    "the activity of a given neuron @xmath19 depends on the history of the other neurons activities @xmath27 in the network , so formally we can consider the spike train of neuron @xmath19 as a functional of all other spike trains .",
    "the time averaged covariance matrix expresses these interrelations and is defined as @xmath28 , where @xmath29 is the vector of time averaged firing rates .",
    "the diagonal contains the autocovariance functions ( diagonal matrix @xmath30 ) which are dominated by a @xmath31-peak at zero time lag and for @xmath32 exhibit a continuous shape mostly determined by refractoriness , the inability of the neuron to fire spikes in short succession due to the voltage reset , as shown in d. the off - diagonal elements contain the cross covariance functions @xmath33 that originate from interactions .",
    "we therefore decompose the covariance matrix into @xmath34 .",
    "a basic property of covariance matrices is the symmetry @xmath35 , so we only need to consider @xmath36 and obtain the solution for @xmath37 by symmetry .",
    "each spike at time @xmath38 can influence the other neurons at time @xmath39 .",
    "formally we express this influence of the history up to time @xmath11 on a particular neuron @xmath19 in the network as @xmath40 , which is a functional of all spike times until @xmath11 . in the asynchronous state of the network @xcite and for small synaptic amplitudes",
    "@xmath21 a single spike of neuron @xmath41 causes only a small perturbation of @xmath42 .",
    "the other inputs to neuron @xmath19 effectively act as additional noise .",
    "we may therefore perform a linear approximation of @xmath41 s direct influence on neuron @xmath19 and average over the realizations of the remaining inputs @xmath43 , as illustrated in a. this linearization and the superposition principle lead to the convolution equation @xmath44(t),\\nonumber \\end{aligned}\\ ] ] where we define as the linear response kernel @xmath45 the functional derivative of @xmath46 with respect to @xmath47 , formally defined in .",
    "the kernel @xmath48 quantifies the effect of a single spike at time @xmath38 of neuron @xmath41 on the expected density of spikes of neuron @xmath19 at time @xmath11 by a direct synaptic connection from neuron @xmath41 to neuron @xmath19 , earlier introduced as the `` synaptic transmission curve '' @xcite .",
    "this density vanishes for @xmath49 due to causality . for the stationary network state",
    "studied here , the kernel further only depends on the time difference @xmath50 . in a consistent linear approximation",
    "there are no higher order terms , so the effects of two inputs @xmath51 and @xmath52 superimpose linearly .",
    "in general , the response of a cell is typically supra - linear in the number of synchronously arriving excitatory spikes @xcite . if , however , the network state to be described is sufficiently asynchronous , as is the case here , a linear approximation is adequate . using this linear expansion and the definition of the covariance matrix , the off - diagonal elements of the covariance matrix",
    "fulfill a linear convolution equation @xmath53(\\tau)\\quad\\text{for } \\tau>0.\\label{eq : integral_equation_corrfunction}\\end{aligned}\\ ] ] the equation is by construction valid for @xmath36 and needs to be solved simultaneously obeying the symmetry condition @xmath54 . up to linear order in the interaction , equation is the correct replacement of the intuitive self - consistency argument sketched in .    in order to relate the kernel @xmath48 to the leaky integrate - and - fire model ,",
    "we employ earlier results based on fokker - planck theory @xcite . for small synaptic amplitudes @xmath55 and weak pairwise covariances the summed synaptic input @xmath56 can be approximated as a gaussian white noise with mean @xmath57 and variance @xmath58 for neurons firing with rates @xmath59 and poisson statistics . for short synaptic time constants @xmath60 the stationary firing rate",
    "@xmath61 depends on these two moments @xcite . in a homogeneous random recurrent network",
    "the input to each neuron is statistically the same , so the stationary rate @xmath62 is identical for all neurons .",
    "it is determined by the self - consistent solution of @xmath63 , taking into account the dependence of @xmath64 and @xmath65 on the rate @xmath66 itself @xcite .",
    "the integral @xmath67 of the response kernel is equivalent to the dc susceptibility @xmath68 @xcite and has earlier been termed `` asynchronous gain '' @xcite .",
    "the approximation is second order in the synaptic amplitude @xmath69 .",
    "the first order term originates from the dependence of @xmath64 on @xmath59 , the second order term stems from the dependence of @xmath65 on @xmath59 .",
    "determines the transient effect of an incoming impulse at time point @xmath70 ( black arrow ) on the density @xmath46 of outgoing action potentials , averaged over realizations of the stochastic activity of the remaining inputs ( indicated as red and blue triangles ) . *",
    "( b ) * response kernel ( green ) compared to direct simulation for an impulse of amplitude @xmath71 ( black dots ) and @xmath72 ( gray dots ) .",
    "time constant @xmath73 determined by a least squares fit to a single exponential .",
    "the background activity causes a mean @xmath74 and fluctuations @xmath75 . *",
    "( c ) * linear and quadratic dependence of the integral response @xmath76 on @xmath21 ( dark gray curve ) and linear term alone ( light gray line ) . *",
    "( d ) * autocovariance function of the spike train with a @xmath31 peak at @xmath77 and covariance trough due to refractoriness . ]    throughout this work we choose the working point of the neurons in the network such that the firing of the cells is driven by strong fluctuations and the mean membrane potential is close to threshold , in order to have irregular firing .",
    "this is achieved by appropriate choices of the external driving poisson sources , as described in . for the small networks considered here ,",
    "it is realistic to assume that about @xmath78 percent of the inputs to a neuron come from outside the local network @xcite .",
    "b shows the deflection of the firing rate from baseline caused by an impulse in the input averaged over many repetitions . for sufficiently strong fluctuations @xmath79",
    ", the quadratic term in @xmath21 is negligible , as seen from c. for smaller membrane potential fluctuations @xmath79 we expect the linear approximation to be less accurate .",
    "the kernel shows exponential relaxation with an effective time constant @xmath80 that depends on the working point @xmath81 and the parameters of the neuron , which is obtained by a least squares fit of a single exponential to the simulated response in b for one particular amplitude @xmath21 .",
    "we therefore approximate the response @xmath82 as @xmath83 where @xmath12 is the synaptic delay and @xmath84 the heaviside step function .    in experiments covariance functions",
    "are typically averaged over statistically equivalent pairs of neurons .",
    "such averages are important , because they determine the behavior of the network on the macroscopic scale of populations of neurons .",
    "we therefore aim at a corresponding effective theory . assuming identical dynamics , all neurons have , to good approximation , the same autocovariance function @xmath85 and response kernel @xmath86 .",
    "so each incoming excitatory impulse causes a response @xmath87 , an inhibitory impulse @xmath88 .",
    "we define the covariance function averaged over all pairs of excitatory neurons as @xmath89 ( setting @xmath90 for @xmath91 ) , where @xmath92 denotes the set of all excitatory neurons .",
    "the pairings @xmath93 and @xmath94 are defined analogously . inserting equation into the average @xmath95 , the first term proportional to the autocovariance @xmath85 only contributes if neuron @xmath41 projects to neuron @xmath19 . for fixed @xmath19",
    ", there are @xmath96 such indices @xmath41 , so the first term yields @xmath97 .",
    "the second sum @xmath98 can be decomposed into a sum over all intermediate excitatory neurons @xmath99 and over all inhibitory neurons @xmath100 projecting to neuron @xmath19 . replacing the individual covariances by their population average , @xmath101 and @xmath102 , respectively , and considering the number of connections and their amplitude we obtain @xmath103 , with @xmath104 and @xmath105 the relative number of inhibitory neurons and the relative linearized inhibitory synaptic amplitude .",
    "similar relations hold for the remaining three averages , so we arrive at a two - by - two convolution matrix equation for the pairwise averaged covariances for @xmath36    @xmath106(\\tau)+\\q\\left[h\\ast a\\right](\\tau)\\label{eq : integral_equation_corrfunction_avg}\\\\ \\text{with } \\m & = & kw\\left(\\begin{array}{cc } 1 & -\\gamma g\\\\ 1 & -\\gamma g \\end{array}\\right),\\quad\\q=\\frac{kw}{n}\\left(\\begin{array}{cc } 1 & -g\\\\ 1 & -g \\end{array}\\right),\\nonumber \\\\ \\text{and } \\c(\\tau ) & = & \\left(\\begin{array}{cc } c_{\\ex\\ex}(\\tau ) & c_{\\ex\\in}(\\tau)\\\\ c_{\\in\\ex}(\\tau ) & c_{\\in\\in}(\\tau ) \\end{array}\\right).\\nonumber \\end{aligned}\\ ] ]    the convolution equation only holds for positive time lags @xmath107 . for negative time",
    "lags it is determined by the symmetry @xmath108 .",
    "the solution of this equation can be obtained by an extension of the method used in @xcite employing wiener - hopf theory @xcite to the cross spectrum @xmath109 in frequency domain , as shown in ( here capital letters denote the fourier transform of the respective lower case letters ) . with the definition of the propagator @xmath110 the cross spectrum takes the form @xmath111\\p^{t}(-\\omega),$ ] where we split the term @xmath112 so that @xmath113 and @xmath114 vanish for times @xmath37 and @xmath36 , respectively .",
    "for the averaged cross spectrum , the matrix @xmath115 is defined in , the non - averaged cross spectrum can be recovered as a special case setting @xmath116 , because the convolution equations and have the same structure and symmetries .",
    "if all eigenvalues of @xmath117 have an absolute value smaller than unity , the propagator @xmath118 can be expanded into a geometric series in which the @xmath119-th term contains only interactions via @xmath119 steps in the connectivity graph .",
    "this expansion has been used to obtain the contribution of different motifs to the integral of covariance functions @xcite and their temporal shape @xcite .    in the following ,",
    "we neglect the continuous part of the autocovariance function , setting @xmath120 , because the @xmath31-peak is typically dominant . with this replacement",
    "we mainly neglect the trough around @xmath121 due to the relative refractoriness .",
    "an estimate of the error can be obtained considering the respective weights of the delta peak ( @xmath66 ) and the through . from the relation",
    "@xmath122 @xcite the integral weight of the trough follows as @xmath123 , which is small for irregular spike trains with a coefficient of variation @xmath124 close to unity .    for an arbitrary causal kernel @xmath125 it follows that @xmath126 so the cross spectrum takes the form @xmath127 the limit @xmath128 corresponds to the time integral of the cross covariance function , approximating the count covariance for long time bins @xcite . with @xmath129 ,",
    "the integral correlation coefficient averaged over neuron pairs fulfills the equation    @xmath130    which has previously been derived from a noise - driven linear rate dynamics @xcite .",
    "the quantity @xmath131 plays a key role here : it determines the feedback magnitude of in - phase fluctuations of the excitatory and inhibitory population .",
    "stability of the average firing rate requires this feedback to be sufficiently small @xcite , i.e. @xmath132 , indicated by the pole in equation at @xmath133 .",
    "typically cortical networks are in the balanced regime @xcite , i.e. @xmath134 . for such inhibition dominated networks , the denominator in equation is larger than unity , indicating a suppression of covariances @xcite . as shown in a , the prediction agrees well with the results of simulations of leaky integrate - and - fire networks for a broad range of network sizes @xmath7 .",
    "previous works have investigated neural networks in the thermodynamic limit @xmath135 @xcite , scaling the synaptic amplitudes @xmath136 in order to arrive at analytical results .",
    "such a scaling increases the feedback on the network level @xmath137 and therefore changes the collective network state .",
    "equation provides an alternative criterion to scale the synapses while keeping the dynamics comparable : the two terms in equation depend differently on the feedback @xmath131 . in order to maintain their ratio",
    ", we need to keep the population feedback @xmath131 constant .",
    "the synaptic amplitude @xmath17 ( approximately @xmath138 ) hence needs to scale as @xmath139 in addition , the response kernel @xmath125 of each single neuron must remain unchanged , requiring the same working point , characterized by the mean @xmath64 and fluctuations @xmath79 in the input into each cell .",
    "constant mean directly follows from @xmath140 , but the variance due to local input from other neurons in the network decreases as @xmath141 . to compensate , we supply each neuron with an additional external uncorrelated balanced noise whose variance appropriately increases with @xmath7 ( as described in detail in ) .",
    "b shows that the shape of the covariance functions is invariant over a large range of network sizes @xmath7 , in particular the apparent time lag of inhibition behind excitation observed as the asymmetry in b does not vanish in the limit @xmath135 .",
    "the magnitude of the covariance decreases as @xmath141 as expected from equation , because @xmath142     for delay @xmath143 ( two rightmost poles appear as one point ) .",
    "the two rightmost poles change with delay @xmath12 . at @xmath144 ( gray st .",
    "andrew s cross ) the poles become a conjugate pair , at @xmath145 ( black crosses ) both poles have a zero real part , causing oscillations ( hopf bifurcation ) . *",
    "( b ) * right : phase diagram spanned by @xmath146 and feedback @xmath131 .",
    "onset of oscillations below the black curve ( hopf bifurcation , black crosses in * a * ) , damped oscillations below the gray curve ( gray cross in * a * ) .",
    "left : oscillation frequency at the hopf bifurcation . *",
    "( c ) * averaged cross covariance between excitatory neurons and theory ( black ) .",
    "simulated data averaged over @xmath147 neuron pairs for @xmath148 . *",
    "( d ) * autocovariance of excitatory neurons ( @xmath31-peak not shown ) averaged over @xmath149 neurons for @xmath148.[fig : phase_diagram ] ]    global properties of the network dynamics can be inferred by considering the spectrum of equation , those complex frequencies @xmath150 at which the expression has a pole due to the function @xmath151 .",
    "these poles are resonant modes of the network , where the real part @xmath152 denotes the damping of the mode , and the imaginary part @xmath153 is the oscillation frequency .",
    "a pole appears whenever @xmath150 is a single root of @xmath154 . with the fourier representation @xmath155 of the response kernel ,",
    "the poles correspond to the spectrum of the delay differential equation @xmath156 , ( cf .",
    "@xcite ) which describes the evolution of the population averaged activity .",
    "as shown in , the location of the poles can be expressed by the branches @xmath157 of the lambert @xmath158 function , the solution of @xmath159 @xcite , as @xmath160 the spectrum only depends on the population feedback @xmath131 , the delay @xmath12 and the effective time constant @xmath80 of the neural response kernel .",
    "this explains why keeping @xmath131 constant while scaling the network in yields shape invariant covariance functions .",
    "a typical spectrum is shown in a as an inset , where each dot marks one of the poles @xmath150 .",
    "the two principal branches of @xmath161 are the modes with the largest real part @xmath152 , and hence with the least damping , dominating the network dynamics .",
    "the remaining branches appear as conjugate pairs and their real parts are more negative , corresponding to stronger damping . investigating the location of the principal branches",
    "therefore enables us to classify the dynamics in the network .",
    "their dependence on the delay is shown in a as a parametric plot in @xmath12 .",
    "the point at which the two real principal solutions turn into a complex conjugate pair marks a transition from purely exponentially decaying dynamics to damped oscillations .",
    "this happens at sufficiently strong negative coupling @xmath131 or sufficiently long delay @xmath12 , precisely when the argument of @xmath161 is smaller than @xmath162 @xcite , leading to the condition @xmath163 the gray cross marks this point in a , the gray curve shows the corresponding relation of feedback and delay in the phase diagram b. in the region below the curve , the dominant mode of fluctuations in the network is thus damped oscillatory , whereas above the curve fluctuations are relaxing exponentially in time .    for sufficiently long delay",
    "@xmath12 the principal poles may assume positive real values , leading to ongoing oscillations , a hopf bifurcation .",
    "the condition under which this happens can be derived from @xmath164 , as detailed in .",
    "equating the absolute values on both sides leads to the condition @xmath165 : oscillations can only be sustained , if the negative population feedback is sufficiently strong @xmath166 .",
    "the oscillation frequency increases the stronger the negative feedback .",
    "the condition for the phases leads to the critical delay required for the onset of oscillations ( see for details ) @xmath167 this relation is shown as the black curve in the phase diagram b. the oscillatory frequency on the bifurcation line , at the onset of oscillations can be expressed as @xmath168 which is shown in the left sub - panel of the phase diagram b. consequently , the oscillation frequency @xmath169 at the onset is between @xmath170 and @xmath171 , depending on the strength of the feedback @xmath131 , approaching @xmath172 at the onset with increasing negative feedback .",
    "changing the synaptic delay homogeneously for all synapses in the network allows us to observe the transition of the network from exponentially damped , to oscillatory damped , and finally to oscillatory dynamics . for a short delay of @xmath173 the dynamics",
    "is dominated by the single real pole near @xmath174 ( brown dot in a ) and the covariance function is exponentially decaying ( c ) . increasing the delay to @xmath143 the principal poles split into a complex conjugate pair",
    "as the delay crosses the gray curve in b so that side troughs become visible in the covariance function in c. further increasing the delay , the network approaches the point of oscillatory instability , where a hopf bifurcation occurs , marked by black crosses in a and the black curve in b. the damping of oscillations decreases as the system approaches the bifurcation ( c ) .",
    "the structure of the auto covariance function of single spike trains ( d ) is dominated by the dip due to refractoriness of the neuron after reset . at pronounced network oscillations ,",
    "the autocorrelation function shows a corresponding modulation .",
    "the neglect of the oscillating continuous part of the autocorrelation function in the theory does apparently not have a pronounced effect on the obtained cross correlation functions , evidenced by the good agreement between direct simulation and theory for @xmath175 . for weaker oscillations ,",
    "e.g. at @xmath176 , the coherence time of the oscillations is typically shorter than the width of the dip in the autocorrelation .",
    "the phase coherence of the oscillation is then shorter than the typical inter - spike - interval and single neuron spike trains are irregular .",
    "this state is known as synchronous irregular activity @xcite , where the activity of a single neuron is irregular , but collectively the neurons participate in a global oscillation .",
    "if the network is not in the oscillatory state , all modes are damped in time , i.e. all poles @xmath150 of the function @xmath151 appearing in equation lie in the left complex half plane , @xmath177 .",
    "hence , the dynamics is stable , and we can expect to obtain a unique solution for the covariance as an observable of this stable dynamics .",
    "we perform the fourier transform to time domain using the residue theorem @xmath178 , where the integration path @xmath179 proceeds along the imaginary axis from @xmath180 to @xmath181 and is then closed in infinity in the left half plane ( for @xmath182 ) or the right half plane ( for @xmath183 ) to ensure convergence , resulting in ( see for the detailed calculation )    @xmath184    the back transform of @xmath185 proceeds along similar lines and results in    @xmath186    the population averaged covariance functions in the time domain then follow from equation for @xmath187 as    @xmath188    which is the central result of our work .",
    "shows the comparison of the theory with the covariance functions obtained by direct simulation .",
    "the analytical expression unveils that the covariance functions are composed of two components : the first line in equation has heterogeneous matrix elements and hence depends on the neuron types under consideration .",
    "its origin is illustrated in a : if one of the neurons emits a spike , as indicated , this impulse travels along its axon and reaches the target neurons after one synaptic delay @xmath12 .",
    "depending on the type of the source neuron , the impulse excites ( synaptic amplitude @xmath17 ) or inhibits ( @xmath18 ) its targets .",
    "its effect is therefore visible in the pairwise covariance function as a positive ( blue ) or negative ( red ) deflection , respectively in c. this deflection not only contains the direct synaptic effect , but also infinitely many reverberations of the network , seen formally in equation .",
    "this expression is not proportional to the kernel @xmath86 directly , but is rather a series including the whole spectrum of the network .",
    "the shape of the spike echo consequently shows onsets of reverberations at integer multiples of the synaptic delay ( c ) , being transmitted over multiple synaptic connections .",
    "the contribution of the second line in equation follows the intuitive argument illustrated in b. the incoming activity from the network to a pair of neurons is correlated . as the input statistics is the same for each neuron , this contribution is identical for any pair of neurons ( green curve in c ) .",
    "the sum of both components results in the covariance functions shown in d - f .",
    "the same analytical solution is shown for different delays in c showing good agreement with direct simulation . for different sizes of simulated networks in b -",
    "d the analytical expression explains why the spike echo does not become negligible in the thermodynamic limit @xmath135 : for fixed population feedback @xmath131 , both contributions in equation scale as @xmath141 , so the relative contribution of the echo stays the same .",
    "this also explains the apparent paradox ( see ) , that covariance functions in recurrent networks not only depend on the input statistics , but in addition the spike feedback causes a reverberating echo .",
    "the power spectrum of population - averages is dominated by pairwise covariances , explaining the different spectra observed in the excitatory and inhibitory population activity @xcite . scaling the network such as to keep the marginal statistics of single neurons constant , @xmath189 @xcite changes the spectrum , because the feedback increases as @xmath137 which can ultimately lead to oscillations as shown in c.    ) , analogously between inhibitory contributions ( red ) , between excitatory and inhibitory contribution ( green , @xmath190 ) , and @xmath191 analogously ( brown ) .",
    "currents filter spiking input by an exponential kernel with time constant @xmath192 , leading to the filtering of the covariances by @xmath193 . ]",
    "the present work qualitatively explains certain features of the correlation structure of simultaneously recorded synaptic currents of two cells in vivo .",
    "novel experimental techniques are able to separate contributions of excitatory and inhibitory inputs @xcite .",
    "we calculate such covariances in a random network and show that the covariance between synaptic impulses decomposes into a linear combination of the covariance of the spiking activity and the autocovariance functions ( see caption of ) .",
    "each synaptic impulse has a certain time course , here modeled as a first - order low - pass filter with time constant @xmath192 ( see ) .",
    "the covariances between these filtered currents are shown in .",
    "their temporal structure resembles those measured in cortex in vivo ( * ? ? ?",
    "* their figure 1e , f ) : covariances between afferents of the same type are monophasic and positive , while the covariances between excitatory and inhibitory afferents are biphasic and mostly negative .",
    "the lag reported between inhibitory and excitatory activity ( * ? ? ?",
    "* their figure 2b ) , which was also observed in binary random networks @xcite , is explained by the echo of the spike contributing to the covariance function .",
    "in contrast to previous work , we take the delayed and pulsed synaptic interaction into account . without delays and with binary neurons @xcite the echo appears as a time lag of inhibition with respect to excitation .",
    "measurements of membrane potential fluctuations during quiet wakefulness in the barrel cortex of mice @xcite showed that correlations between inhibitory neurons are typically narrower than those between two excitatory neurons ( * ? ? ? * their figure 4a , 5b and figure 5c , e ) .",
    "these results qualitatively agree with our theory for covariances between the spiking activity , because fluctuations of the membrane potential are uniformly transferred to fluctuations of the instantaneous firing intensity .",
    "the direct measures of spiking activity ( * ? ? ?",
    "* their figure 6 ) confirm the asymmetric correlation between excitation and inhibition . the low correlation between excitatory neurons reported in that study",
    "may partly be due to the unnormalized , firing rate dependent measure and the low rates of excitatory neurons .",
    "the qualitative features of the cross correlation functions , namely their different widths and their asymmetry for excitatory - inhibitory pairs , are generic and agree with experimental results . they are fully explained by the decomposition into an echo term and a term corresponding to the feed - forward transmission of correlation .",
    "this decomposition merely relies on the fact that the autocorrelation of a spike train has a delta peak and that a spike triggers a response in the target cell with positive or negative sign for excitatory and inhibitory connections , respectively .",
    "hence , we expect that these features are robust and survive also for more realistic network models with many heterogeneous subpopulations . for weakly correlated fluctuations , if the input to each cell is sufficiently noisy , a linear approximation of the neuronal response provides a viable first order approximation also for non - linear neuron dynamics , as shown here .",
    "we suspect that a deeper reason why such a linearization is possible is the inherent decorrelation @xcite by negative feedback in networks in the inhibition dominated regime .",
    "the decorrelation keeps population fluctuations small and hence prevents strong excursions that would exceed the validity of the linear approximation .",
    "oscillations in the @xmath194 range ( @xmath195 ) are ubiquitous in population measures of neural activity in humans , and have earlier been explained in networks of leaky integrate - and - fire model neurons @xcite by the hopf bifurcation induced by delayed negative feedback .",
    "for the regime of high noise we here uncover a simpler analytical condition for the onset and frequency of fast global oscillations . for lower noise , deviations of the non - linear leaky integrate - and - fire dynamics from the linear theory presented here are expected .",
    "a traditional motivation to scale the network size to infinity is to obtain an analytic solution for an otherwise hard problem .",
    "biologically realistic networks have a finite size . in the present work we have determined the correlation structure for such finite sized networks analytically .",
    "we present the scaling of the correlation functions in to relate our work to previous results that applied scaling arguments to obtain the correlation structure @xcite .",
    "the latter work investigated networks of binary neurons without conduction delays and assumed a scaling of the synaptic amplitudes @xmath136 .",
    "such a scaling increases the overall feedback strength @xmath196 .",
    "this has two consequences : firstly , as seen from , the relative contributions of the spike echo and the feed forward term change with @xmath131 and hence with network size .",
    "therefore the shape of correlation functions depends on the network size .",
    "secondly , the overall dynamic regime of the network is affected by the scaling .",
    "this can be seen from b. for non - zero synaptic conduction delays , the network eventually becomes oscillatory if the network size exceeds a certain value .",
    "this happens precisely at the point where @xmath131 crosses the bifurcation line shown in b. we therefore propose an alternative scaling @xmath197 here for which we show that it preserves the shape of correlation functions and the overall network state .",
    "only the magnitude of the cross correlation functions decreases @xmath198 .",
    "however , a caveat of this scaling is that while it preserves the global network properties , it affects the working point of each individual neuron , because the fluctuations due to the local synaptic input decrease @xmath199 .",
    "we alleviated this shortcoming by supplying each neuron with additional , uncorrelated noise .",
    "our results are based on a simplified network model composed of two homogeneous ( excitatory and inhibitory ) subpopulations of leaky integrate - and - fire neurons .",
    "the real cortex , in contrast , is highly heterogeneous in several respects : its layered structure with layer - specific neuron and connection properties ( e.g. time constants , spike thresholds , synaptic weights , in - degrees ) requires the distinction of more than two subpopulations . even within each subpopulation and for each combination of subpopulations ,",
    "the neuron and connection parameters are not constant but broadly distributed .",
    "further , a plethora of cortical neurons , in particular various types of interneurons , exhibit a much richer dynamical repertoire ( e.g. resonating behavior ) than the leaky integrate - and - fire neuron model ( regular spiking integrator ) . in principle",
    ", the mathematical framework presented in this article can be extended to networks composed of @xmath119 ( @xmath200 ) heterogeneous subpopulations of different neuron types .",
    "this would require to account for subpopulation - specific working points ( e.g. due to layer - specific firing rates ; see @xcite ) and for the effect of parameter distributions @xcite and the single - neuron dynamics on the effective linearized subpopulation responses . this extended theory would result in an @xmath119-dimensional linear algebraic equation for the subpopulation - averaged cross spectra , similar to where @xmath201 . for @xmath200 , this equation",
    "most likely needs to be solved numerically .",
    "a fundamental assumption of the presented theory is that the network states show irregular single neuron dynamics .",
    "this requirement arises from the analytical description replacing spike trains by spike densities and a stochastic realization of spikes .",
    "regular spike trains are outside the scope of such a description .",
    "moreover , the approximation of the neuronal response to linear order is only a viable approach in sufficiently asynchronous network states with low correlations .",
    "states with stronger correlations , such as observed in convergent - divergent feed - forward structures @xcite , require an explicit treatment of the non - linear response @xcite .    from a physics viewpoint ,",
    "neuronal networks unite several interesting properties .",
    "they do not reach thermodynamic equilibrium even in the stationary state , as detailed balance does not hold for all pairs of states of the system . in detailed balance , the rate of transition from one state to another is equal to the rate of the reverse transition . for a leaky integrate - and - fire neuron the state of the neuron",
    "is uniquely determined by its membrane voltage . in the stationary state neurons fire with a constant rate , so there is a continuous flux of the neurons voltage from reset up to threshold . imagining a discretization of the voltage axis we see that a pair of adjacent voltage - intervals between reset and threshold is more often traversed from lower to higher voltage than in the reverse direction , so obviously detailed balance does not hold even for a single neuron in the stationary state .",
    "moreover , the interaction between pairs of neurons is directed , delayed , pulsed , and depends on the flux of the sending neuron s state variable at threshold . in contrast , pairwise interactions frequently studied in physics , like the coulomb interaction or exchange interaction , can be expressed by a pair potential and are thus symmetric ( undirected ) , instantaneous , and depend directly on the state variables ( e.g. spatial coordinates or spins ) of the pair of interacting particles .",
    "non - equilibrium systems are at the heart of ubiquitous transport phenomena , like heat or electric conduction . understanding fluctuations in such a system marks the starting point to infer macroscopic properties by the assertion of the fluctuation - dissipation theorem that connects microscopic fluctuations to macroscopic transport properties .",
    "despite the non - equilibrium dynamics and the non - conservative pairwise interaction , in this manuscript we develop a simple analytical framework merely based on linear perturbation theory that explains time dependent covariance functions of the activity of pairs of integrate - and - fire model neurons in a recurrent random network .",
    "formally our approach resembles the step from the kinetic ising model near equilibrium to its non - equilibrium counterpart , the network of binary neurons @xcite .",
    "a difference is the spiking interaction considered in our work , which led us to the describe each neuron in terms of the flux over threshold ( spike train ) rather than by its state variables ( membrane voltage and synaptic current ) . in this respect ,",
    "we follow the established mean - field approach for spiking neuronal systems @xcite . however , while this mean field approach proceeds by assuming vanishing correlations to obtain the dynamics of the ensemble averaged activity , we here derive and solve the self - consistency equation for the pairwise averaged covariances of the microscopic system .    the typical time",
    "scale of covariance functions found here coincides with the time window of biological synaptic plasticity rules @xcite , so that non - trivial interactions of dynamics and structure are expected .",
    "it is our hope that the novel capability to resolve the temporal structure of covariances in spiking networks presented here proves useful as a formal framework to further advance the theory of these correlated non - equilibrium systems and in particular serves as a further stepping stone in the endeavor to understand how learning on the system level is implemented by the interplay of neuronal dynamics and synaptic plasticity .",
    "we are thankful to birgit kriener , sonja grn and george gerstein for discussions and exploratory simulations in fall 2005 that led to the observation of asymmetric covariance functions .",
    "partially supported by the helmholtz association : hasb and portfolio theme smhb , the next - generation supercomputer project of mext , eu grant 15879 ( facets ) , eu grant 269921 ( brainscales ) .",
    "all network simulations carried out with nest ( http://www.nest-initiative.org ) .",
    "the response kernel kernel @xmath48 needs to be related to the dynamics of the neuron model . here",
    "we present an approximation of this kernel which is sufficiently accurate to allow quantitative predictions , but yet simple enough to enable an analytical solution for the correlation structure .",
    "if the synaptic time constant is short @xmath60 , the synaptic amplitude @xmath17 can be thought of as the amplitude of the jump in the membrane potential @xmath202 caused upon arrival of an incoming impulse .",
    "if correlations between incoming spike trains are sufficiently small , the first and second moments of the summed impulses @xmath203 are @xmath57 and @xmath58 , respectively , if the inputs statistics can be approximated by poisson processes of rate @xmath59 each . for small @xmath17 and a high total rate ,",
    "the system of differential equations is hence approximated by a stochastic differential equation driven by a unit variance gaussian white noise @xmath204",
    "@xmath205    the stationary firing rate in this limit is given by @xcite @xmath206 with riemann s zeta function @xmath207 .",
    "the rate @xmath208 is the density of action potentials per time .",
    "the response of the firing density of the neuron @xmath19 at time point @xmath11 with respect to a point - like deflection of the afferent input @xmath51 at time point @xmath38 defines the response kernel as the functional derivative @xmath209 here we used the homogeneity , namely the identical input statistics of each neuron @xmath19 , leading to the same temporal shape @xmath86 independent of @xmath19 and the stationarity , so that the kernel only depends on the time difference @xmath210 .",
    "we choose @xmath86 to have unit integral and define @xmath76 as the integral of the kernel .",
    "we determine the temporal integral of the kernel as @xmath211 the second equality holds because the integral of the impulse response equals the step response @xcite .",
    "further , a step in the density @xmath51 corresponds to a step of @xmath59 .",
    "up to linear approximation the effect of the step in the rate @xmath59 on the rate @xmath208 can be expressed by the derivative considering the perturbation of the mean @xmath64 and the variance @xmath65 upon change of @xmath59 . using equation",
    "we note that by chain rule @xmath212 .",
    "the latter derivative follows as @xmath213 .",
    "the first derivative in both terms yields @xmath214 with @xmath215 .",
    "the second derivative evaluates with @xmath216 to @xmath217 .",
    "so together we obtain @xmath218",
    "the autocovariance @xmath219 in the frequency domain ( @xmath220(\\omega)=\\int_{-\\infty}^{\\infty}f(t)e^{-i\\omega t}\\ , dt$ ] ) has two different terms .",
    "the first term is a constant @xmath66 due to the spiking with rate @xmath66 resulting from the delta peak @xmath221 in time domain .",
    "the second term is the continuous function @xmath222 , for example due to refractoriness of the neuron .",
    "further follows from @xmath223 that @xmath224 . for @xmath36",
    "the covariance matrix fulfills the linear convolution equation .",
    "as this equation only holds for the positive half of the time axis , we can not just apply the fourier transform to obtain the solution . for negative time",
    "lags @xmath37 the covariance matrix is determined by the symmetry @xmath225 .",
    "here we closely follow @xcite and employ wiener - hopf theory @xcite to derive an equation for the cross spectral matrix in the frequency domain that has the desired symmetry and solves simultaneously . to this end we introduce the auxiliary matrix @xmath226 for @xmath227 . obviously , @xmath228 for @xmath36 .",
    "since the defining equation for @xmath229 holds on the whole time axis , we may apply the fourier transform to obtain @xmath230 . solving for @xmath231 @xmath232 and using the symmetry @xmath233 we obtain the equation @xmath234 we observe that @xmath235 is symmetric and with @xmath224 the term proportional to @xmath236 cancels on both sides , remaining with @xmath237 we next introduce @xmath238 which we split into @xmath239 , chosen such that @xmath240 ( in time domain ) vanishes for @xmath241 and @xmath242 vanishes for @xmath187 .",
    "consequently the fourier transforms of both terms may have poles in distinct complex half - planes : @xmath243 may only have poles in the upper half plane @xmath244 and the function vanishes for @xmath245 , following from the definition of the fourier integral .",
    "for @xmath246 the half planes are reversed .",
    "the analytical properties of @xmath247 are thus similar to those of @xmath243 , those of @xmath248 are similar to @xmath246 .",
    "we sort the terms in such that the left hand side only contains terms that vanish at infinity in the lower half plane @xmath249 , the right hand side those that vanish in infinity in the upper half plane @xmath244 @xmath250 the left hand side consequently is analytic for @xmath249 the right hand side is analytic for @xmath244 , so defines a function that is analytic on the whole complex plane and that vanishes at the border for @xmath251 .",
    "hence by liouville s theorem it is @xmath121 and we can solve the right hand side of for @xmath252    @xmath253    inserted into this yields with the definition @xmath110    @xmath254    the latter expression can be brought to the form    @xmath255    which has the advantage that the first two terms have poles in distinct half planes @xmath244 , and @xmath249 , respectively .",
    "this means these terms only contribute for positive and negative times , respectively , the last term contributes for positive and negative times .",
    "with the fourier representation @xmath155 of the delayed exponential kernel the averaged cross spectrum contains the two functions @xmath151 and @xmath256 defined on the complex frequency plane @xmath257 .",
    "these functions may exhibit poles .",
    "the function @xmath258 has a pole @xmath150 whenever the denominator has a single root @xmath259 which amounts to the condition @xmath260 .",
    "these complex frequencies can be expressed by the lambert @xmath158 function , the solution of @xmath261 @xcite , by    @xmath262    as    @xmath263    leading to .",
    "the lambert @xmath264 function has infinitely many branches @xmath157 @xcite .",
    "the principal branch has two real solutions , if @xmath265 .",
    "the remaining branches appear in conjugate pairs . for @xmath266",
    "the principal solutions turn into a complex conjugate pair .",
    "this happens at sufficiently strong negative coupling @xmath131 or long delays @xmath12 @xmath267 the principal poles may assume positive real values , leading to oscillations .",
    "the condition under which this happens can be derived from . at the point of transition",
    "the pole can be written as @xmath268 ; it is a solution to @xmath269 in order for this equation to be fulfilled , the absolute value and the phase must be identical on both sides .",
    "the equation for the absolute value requires @xmath270 .",
    "this means there are only oscillatory solutions , if the magnitude of the feedback exceeds unity @xmath166 .",
    "since the poles come in conjugate pairs , we can assume w.l.o.g . that @xmath271 .",
    "the condition for the absolute value hence reads    @xmath272    this is the frequency of oscillation at the onset of the hopf bifurcation . for strong feedback",
    "@xmath273 the frequency increases linearly with the magnitude of the feedback .",
    "the condition for the agreement of the phase angles reads @xmath274 , so @xmath275 , which leads to @xmath276 this equation has a solution in @xmath277 . in the limit of vanishing delay @xmath278",
    "the frequency goes to infinity , as the solution converges to @xmath279 .",
    "this corresponds to the frequency @xmath280 . inserting leads to @xmath281 , which can be solved for the critical delay @xmath282 where we took care that the argument of the tangent is in @xmath283 $ ] .",
    "so with and the oscillatory frequency at the transition can be related to the synaptic delay as @xmath284",
    "in the non - oscillatory state all poles @xmath150 have a negative real part .",
    "the function @xmath285 in then has all poles in the left complex half plane , @xmath286 .",
    "we perform the fourier back transform @xmath287 replacing the integration path by a closed contour @xmath179 following the imaginary axis from @xmath180 to @xmath181 . in order to ensure convergence of the integral , for @xmath288 we need @xmath289 , so we close @xmath290 in infinity within the right half - plane , where the integrand vanishes . since there are no poles in the right half - plane , for @xmath288 the path @xmath290 does not enclose any poles , so @xmath291 . for @xmath292",
    "the path @xmath293 must be closed in the left half - plane to ensure convergence of , so the residue theorem yields @xmath294 the residue can be calculated by linearizing the denominator of @xmath295 around @xmath150    @xmath296    which yields @xmath297 where we used in the last step .",
    "the poles of @xmath298 are located in both half - planes , consequently @xmath299 is nonzero on the whole time axis .",
    "here we only calculate @xmath299 for positive times @xmath187 , because it follows for negative times by symmetry @xmath300 .",
    "the path has to be closed in the left half - plane , where the poles @xmath150 have the residues @xmath301 so applying the functions @xmath302 and @xmath303 are    @xmath304    the amplitude of the modes decrease with @xmath157 .",
    "for all figures in the manuscript we truncated the series after @xmath305 .",
    "all network simulations were performed using nest @xcite .",
    "the parameters of the leaky integrate - and - fire neuron model throughout this work are @xmath306 , .",
    "all simulations are performed with precise spike timing and time stepping of @xmath307 @xcite . * * and - of the main text all consider recurrent random networks of @xmath7 excitatory and @xmath8 inhibitory leaky integrate - and - fire model neurons receiving input from randomly drawn neurons in the network and external excitatory and inhibitory poisson input , so that the first and second moments are @xmath74 and @xmath308 , respectively . unless stated explicitly , we use @xmath309 neurons except in where the number of neurons is given in the legend .",
    "each neuron has @xmath9 incoming excitatory synapses with synaptic amplitude @xmath17 independently and randomly drawn from the pool of excitatory neurons , and @xmath10 inhibitory synapses with amplitude @xmath18 ( homogeneous erds - rnyi random network with fixed in - degree ) , realizing a connection probability @xmath310 .",
    "cross covariance functions are measured throughout as the covariance between two disjoint populations of @xmath311 neurons each taken from the indicated populations in the network .",
    "correlation functions are evaluated with a time resolution of @xmath307 .      in",
    "we keep the feedback of the population rate constant @xmath312 increasing the size of the network @xmath7 the synaptic amplitude @xmath17 ( which is proportional to @xmath313 in linear approximation ) needs to scale as @xmath314 , where we chose @xmath315 and @xmath316 here .",
    "the variance caused by local input from the network then decreases with increasing network size @xmath198 , while the local mean is constant because @xmath140 each cell receives in addition uncorrelated external balanced poisson input , adjusted to keep the mean @xmath74 , and fluctuations @xmath75 constant .",
    "this is achieved by choosing the rates of the external excitatory ( @xmath317 , amplitude @xmath318 ) and inhibitory ( @xmath319 , amplitude @xmath320 ) inputs as @xmath321 where @xmath322 and @xmath323 are the mean and variance due to local input from other neurons of the network firing with rate @xmath66 . from @xmath140",
    "follows that also @xmath142 , so that predicts a scaling of the magnitude of the covariance functions in proportion to @xmath141 .",
    "other network parameters are @xmath176 and @xmath324 .",
    "the firing rate in the network is @xmath325 .      in",
    "we use @xmath326 , @xmath328 , @xmath324 , and @xmath329 and the remaining parameters as in .",
    "we obtain the filtered synaptic currents by filtering the spike trains with an exponential filter of time constant @xmath192 .",
    "this results in an effective filter for the cross covariances of .",
    "the different contributions shown are @xmath330 , @xmath331 , @xmath332 , and @xmath333 , where @xmath334 denotes the convolution .    for , we simulate two populations of @xmath335 neurons each .",
    "each neuron receives independent background activity from poisson processes and in addition input from a common poisson process with rate @xmath336 causing in population 1 a positive synaptic amplitude of @xmath17 and for population 2 a negative synaptic amplitude @xmath17 ( @xmath17 is given on the x - axis ) .",
    "the synaptic amplitude of the background inputs is @xmath337 for an excitatory impulse and @xmath338 for an inhibitory impulse .",
    "the rates of the excitatory and inhibitory background inputs are chosen so that the first and second moments @xmath339 and @xmath340 are independent of @xmath17 .",
    "the spikes produced by each population are triggered to the arrival of an impulse in the common input and averaged over a duration of @xmath341 to obtain the impulse response .",
    "gerstein , g.  l. , & perkel , d.  h. ( 1969 ) . simultaneously recorded trains of action potentials : analysis and functional interpretation .  _",
    "881_(164 ) , 828830 .",
    "cohen , m.  r. , & kohn , a. ( 2011 ) . measuring and interpreting neuronal correlations .  _",
    "14_(7 ) , 811819 . doi:10.1038/nn.2842 .",
    "zohary , e. , shadlen , m.  n. , & newsome , w.  t. ( 1994 ) .",
    "correlated neuronal discharge rate and its implications for psychophysical performance .",
    "_ 370 _ , 140143 .",
    "abbott , l.  f. , & dayan , p. ( 1999 ) .",
    "the effect of correlated variability on the accuracy of a population code .  _ 11 _ , 91101 . , c. ( 1986 ) .",
    "am i thinking assemblies ?",
    "in g.  palm & a.  aertsen ( eds . ) , _ brain theory _ , pp .",
    "berlin : springer - verlag .",
    "maldonado , p. , babul , c. , singer , w. , rodriguez , e. , berger , d. , & grn , s. ( 2008 ) .",
    "synchronization of neuronal responses in primary visual cortex of monkeys viewing natural images .  _",
    "100_(3 ) , 15231532 .",
    "kilavik , b.  e. , roux , s. , ponce - alvarez , a. , confais , j. , gruen , s. , & riehle , a. ( 2009 ) .",
    "long - term modifications in motor cortical dynamics induced by intensive practice .  _ 29",
    "_ , 1265312663 .",
    "ecker , a.  s. , berens , p. , keliris , g.  a. , bethge , m. , & logothetis , n.  k. ( 2010 ) .",
    "decorrelated neuronal firing in cortical microcircuits .  _",
    "327_(5965 ) , 584587 .",
    "brunel , n. ( 2000 ) .",
    "dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons .  _",
    "8_(3 ) , 183208 . hertz , j. ( 2010 ) .",
    "cross - correlations in high - conductance states of a model cortical network .  _ 22",
    "_ , 427447 .",
    "renart , a. , de  la  rocha , j. , bartho , p. , hollender , l. , parga , n. , reyes , a. , & harris , k.  d. ( 2010 ) .",
    "the asynchronous state in cortical cicuits .",
    "_ 327 _ , 587590 .",
    "tetzlaff , t. , helias , m. , einevoll , g. , & diesmann , m. ( 2012 ) .",
    "decorrelation of neural - network activity by inhibitory feedback .  _",
    "8_(8 ) , e1002596 .",
    "van vreeswijk , c. , & sompolinsky , h. ( 1996 ) .",
    "chaos in neuronal networks with balanced excitatory and inhibitory activity .",
    "_ 274 _ , 17241726 .",
    "amit , d.  j. , & brunel , n. ( 1997 ) .",
    "model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex .",
    "_ 7 _ , 237252 .",
    "kriener , b. , tetzlaff , t. , aertsen , a. , diesmann , m. , & rotter , s. ( 2008 ) . correlations and population dynamics in cortical networks .",
    "_ 20 _ , 21852226 .",
    "shadlen , m.  n. , & newsome , w.  t. ( 1998 ) . the variable discharge of cortical neurons : implications for connectivity , computation , and information coding .  _",
    "18_(10 ) , 38703896 .",
    "stroeve , s. , & gielen , s. ( 2001 ) .",
    "correlation between uncoupled conductance - based integrate - and - fire neurons due to common and synchronous presynaptic firing .  _",
    "13_(9 ) , 20052029 .",
    "tetzlaff , t. , buschermhle , m. , geisel , t. , & diesmann , m. ( 2003 ) .",
    "the spread of rate and correlation in stationary cortical networks .  _",
    "5254 _ , 949954 .",
    "moreno - bote , r. , & parga , n. ( 2006 ) .",
    "auto- and crosscorrelograms for the spike response of leaky integrate - and - fire neurons with slow synapses .",
    "_ 96 _ , 028101",
    ". de  la rocha , j. , doiron , b. , shea - brown , e. , kresimir , j. , & reyes , a. ( 2007 ) .",
    "correlation between neural spike trains increases with firing rate .  _",
    "448_(16 ) , 802807 .",
    "shea - brown , e. , josic , k. , de  la rocha , j. , & doiron , b. ( 2008 ) .",
    "correlation and synchrony transfer in integrate - and - fire neurons : basic properties and consequences for coding .",
    "_ 100 _ , 108102 .",
    "burak , y. , lewallen , s. , & sompolinsky , h. ( 2009 ) .",
    "stimulus - dependent correlations in threshold - crossing spiking neurons .  _ 21",
    "_ , 22692308 .",
    "rosenbaum , r. , & josic , k. ( 2011 ) .",
    "mechanisms that modulate the transfer of spiking correlations .  _",
    "23_(5 ) , 12611305 .",
    "tchumatchenko , t. , malyshev , a. , geisel , t. , volgushev , m. , & wolf , f. ( 2010 ) .",
    "correlations and synchrony in threshold neuron models .  _ 104",
    "_ , 058102 .",
    "ginzburg , i. , & sompolinsky , h. ( 1994 ) .",
    "theory of correlations in stochastic neural networks .  _",
    "50_(4 ) , 31713191 .",
    "hawkes , a. ( 1971 ) .",
    "point spectra of some mutually exciting point process .  _",
    "33_(3 ) , 438443 . stein , r.  b. ( 1965 ) . a theoretical analysis of neuronal variability .",
    "_ 5 _ , 173194 .",
    "rauch , a. , la  camera , g. , lscher , h. , senn , w. , & fusi , s. ( 2003 ) .",
    "neocortical pyramidal cells respond as integrate - and - fire neurons to in vivo like input currents .",
    "_ 90 _ , 15981612 .",
    "okun , m. , & lampl , i. ( 2008 ) .",
    "instantaneous correlation of excitation and inhibition during sensory - evoked activities .  _",
    "11_(5 ) , 535537 .",
    "morrison , a. , diesmann , m. , & gerstner , w. ( 2008 ) .",
    "phenomenological models of synaptic plasticity based on spike - timing .",
    "_ 98 _ , 459478 .",
    "cai , d. , tao , l. , shakarayev , m.  s. , rangan , a.  v. , mclaughlin , d.  w. , & kovai , g. ( 2012 ) .",
    "the role of fluctuations in coarse - grained descriptions of neuronal networks .  _",
    "10_(1 ) , 307354 .",
    "cai , d. , tao , l. , & mclaughlin , d.  w. ( 2004 ) . an embedded network approach for scale - up of fluctuation - driven systems with preservation of spike information .  _",
    "101_(39 ) , 1428814293 .",
    "fourcaud , n. , & brunel , n. ( 2002 ) .",
    "dynamics of the firing probability of noisy integrate - and - fire neurons .",
    "_ 14 _ , 20572110 .",
    "abeles , m. ( 1991 ) .",
    "( 1st ed . ) .",
    "cambridge : cambridge university press .",
    "abeles , m. ( 1982 ) .",
    "role of cortical neuron : integrator or coincidence detector ?",
    "_ 18 _ , 8392 .",
    "goedeke , s. , & diesmann , m. ( 2008 ) .",
    "the mechanism of synchronization in feed - forward neuronal networks .  _",
    "10 _ , 015007 .",
    "helias , m. , deger , m. , rotter , s. , & diesmann , m. ( 2010 ) .",
    "instantaneous non - linear processing by pulse - coupled threshold units .  _",
    "6_(9 ) , e1000929 .",
    "stepanyants , a. , martinez , l.  m. , ferecsk , a.  s. , & kisvrday , z.  f. ( 2009 ) .",
    "the fractions of short- and long - range connections in the visual cortex .  _",
    "106_(9 ) , 35553560 .",
    "hazewinkel , m. ( ed . )",
    "( 2002 ) . .",
    "pernice , v. , staude , b. , cardanobile , s. , & rotter , s. ( 2011 ) .",
    "how structure determines correlations in neuronal networks .  _",
    "7_(5 ) , e1002059 .",
    "trousdale , j. , hu , y. , shea - brown , e. , & josic , k. ( 2012 ) . impact of network structure and cellular response on spike time correlations .  _",
    "8_(3 ) , e1002408 .",
    "rieke , f. , warland , d. , de ruyter van steveninck , r. , & bialek , w. ( 1997 ) . .",
    "cambridge , ma : the mit press .",
    "moreno - bote , r. , renart , a. , & parga , n. ( 2008 ) .",
    "theory of input spike auto- and cross - correlations and their effect on the response of spiking neurons .",
    "_ 20 _ , 16511705 .",
    "guillouzic , s. , lheureux , i. , & longtin , a. ( 1999 ) .",
    "small delay approximation of stochastic delay differential equations .",
    "_ 59 _ , 39703982 .",
    "corless , r.  m. , gonnet , g.  h. , hare , d. e.  g. , jeffrey , d.  j. , & knuth , d.  e. ( 1996 ) . on the lambert w function .",
    "_ 5 _ , 329359 .",
    "gentet , l. , avermann , m. , matyas , f. , staiger , j.  f. , & petersen , c.  c. ( 2010 ) .",
    "membrane potential dynamics of gabaergic neurons in the barrel cortex of behaving mice .  _ 65 _ , 422435 .",
    "potjans , t.  c. , & diesmann , m. ( 2012 ) .",
    "the cell - type specific cortical microcircuit : relating structure and activity in a full - scale spiking network model .",
    ", doi : 10.1093/cercor / bhs358 .",
    "tetzlaff , t. , einevoll , g.  t. , & diesmann , m. ( 2009 ) .",
    "synchronization and rate dynamics in embedded synfire chains : effect of network heterogeneity and feedback .  _",
    "10_(suppl i ) , p258 .",
    "roxin , a. ( 2011 ) .",
    "the role of degree distribution in shaping the dynamics in networks of sparsely connected spiking neurons .  _",
    "diesmann , m. , gewaltig , m .- o . , & aertsen , a. ( 1999 ) . stable propagation of synchronous spiking in cortical neural networks .  _",
    "402_(6761 ) , 529533 .",
    "oppenheim , a. , & wilsky , a. ( 1996 ) . .",
    "prentice hall .",
    "gewaltig , m .- o . , & diesmann , m. ( 2007 ) .",
    "( neural simulation tool ) .  _",
    "2_(4 ) , 1430 .",
    "hanuschkin , a. , kunkel , s. , helias , m. , morrison , a. , & diesmann , m. ( 2010 ) . a general and efficient method for incorporating precise spike times in globally time - driven simulations .",
    "_ 4 _ , 113 ."
  ],
  "abstract_text": [
    "<S> correlations are employed in modern physics to explain microscopic and macroscopic phenomena , like the fractional quantum hall effect and the mott insulator state in high temperature superconductors and ultracold atoms . </S>",
    "<S> simultaneously probed neurons in the intact brain reveal correlations between their activity , an important measure to study information processing in the brain that also influences macroscopic signals of neural activity , like the electro encephalogram ( eeg ) . </S>",
    "<S> networks of spiking neurons differ from most physical systems : the interaction between elements is directed , time delayed , mediated by short pulses , and each neuron receives events from thousands of neurons </S>",
    "<S> . even the stationary state of the network can not be described by equilibrium statistical mechanics . here </S>",
    "<S> we develop a quantitative theory of pairwise correlations in finite sized random networks of spiking neurons . </S>",
    "<S> we derive explicit analytic expressions for the population averaged cross correlation functions . </S>",
    "<S> our theory explains why the intuitive mean field description fails , how the echo of single action potentials causes an apparent lag of inhibition with respect to excitation , and how the size of the network can be scaled while maintaining its dynamical state . </S>",
    "<S> finally , we derive a new criterion for the emergence of collective oscillations from the spectrum of the time - evolution propagator .    </S>",
    "<S> c     _ keywords _ : spiking neural networks , correlations , non - equilibrium dynamics , integrate - and - fire model </S>"
  ]
}