{
  "article_text": [
    "market risk management deals with the estimation of loss distribution of a portfolio of assets over a fixed time horizon . the widely used risk measures value - at - risk ( var ) and expected shortfall require accurate estimates of loss probability and conditional excess under a realistic model that captures dependence structure of the log - returns of multiple assets . as a flexible and accurate model for the logarithmic returns of stocks , we use the @xmath0-copula dependence structure and marginals following the generalized hyperbolic distribution",
    "( see * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) .    as there are no closed - form analytical results for loss probability and conditional excess under the @xmath0-copula model , we need to use a computational method like monte carlo simulation . in most cases ,",
    "monte carlo simulation is a better alternative compared to other methods as it leads to error bounds on the estimated values . due to the fact that monte carlo simulation has a slow convergence rate of @xmath1",
    ", we need to increase the efficiency of the estimates using variance reduction techniques .",
    "there are papers proposing variance reduction methods in portfolio market risk estimation ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "an alternative to monte carlo simulation is the quasi - monte carlo method ( qmc ) , which uses low - discrepancy sequences instead of pseudorandom numbers .",
    "the rate of convergence of the quasi - monte carlo method is close to @xmath2 , which is faster than @xmath1 .",
    "however , an error bound under plain qmc can not be estimated as low - discrepancy sequences do not have an i.i.d . property .",
    "randomized quasi - monte carlo solves this problem by applying a randomization on low - discrepancy sequences .",
    "randomized quasi - monte carlo ( rqmc ) has been used in pricing extensively ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "however , the application of rqmc to measure portfolio risk is rarely found in the literature ( see * ? ? ?",
    "* ; * ? ? ?",
    "this can be explained by the fact that the integrand in risk management applications is a non - smooth function ( e.g. , indicator function ) of high - dimensional random inputs .",
    "( as pointed out by @xcite , the performance of quasi - monte carlo method diminishes when the integrands are not smooth and high - dimensional . ) to compute var using qmc , @xcite apply principal component analysis to reduce the dimensionality of the risk factor space .",
    "@xcite efficiently simulate var by smoothing the expectation of an indicator function via fourier transformation and then applying rqmc .",
    "the motivation of this paper is to investigate whether rqmc and variance reduction techniques can be combined efficiently for simulating loss probability and conditional excess under the @xmath0-copula model . in order to solve the problem of high - dimensionality of the integrands",
    ", we apply a linear transformation on the random input to reduce the effective dimension .",
    "furthermore , the discontinuity of the simulation integrand is reduced using importance sampling .",
    "we finally apply stratification to further improve the accuracy of the estimates .",
    "numerical experiments illustrate the effectiveness of rqmc implementations of variance reduction methods over their monte carlo implementations .",
    "although , the methodology of the paper is explained on market risk management under the @xmath0-copula model , it is much more generally applicable to other fields like credit risk , insurance , and operational risk where @xmath0-copula models are widely used .",
    "the rest of the paper is organized as follows .",
    "section  2 describes the @xmath0-copula model for portfolio market risk .",
    "section  3 presents background on efficient monte carlo simulation methods for estimating loss probability and conditional excess .",
    "section  4 combines the rqmc method with importance sampling and stratified importance sampling for estimating loss probability and conditional excess .",
    "we present numerical results in section  5 .",
    "the essence of any model of portfolio market risk is its ability to capture dependence among assets . in this section ,",
    "we describe the widely used @xmath0-copula model ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "we are interested in the distribution of losses caused by depreciation of stocks over a fixed time period .",
    "the following notation is used in order to represent this distribution .",
    "* @xmath3 = the number of stocks in portfolio * @xmath4 = the weight of the @xmath5th stock * @xmath6 = the log - return of the @xmath5th stock * @xmath7 = portfolio loss ( initial value of portfolio is assumed to be equal to one )    we assume that we are given a portfolio of stocks with known weights @xmath8 and unknown future log - returns @xmath9 .",
    "the main objective is to estimate loss probability @xmath10 , and conditional excess @xmath11 $ ] , especially at large values of @xmath12 .    to model dependence among stocks , we need to introduce dependence among the log - returns .",
    "the log - return vector @xmath9 of the stocks is assumed to follow a @xmath0-copula with @xmath13 degrees of freedom .",
    "the dependence is introduced through a multivariate @xmath0-vector @xmath14 with @xmath13 degrees of freedom .",
    "each log - return is represented as @xmath15 in which    * @xmath16 denotes the cumulative distribution function ( cdf ) of a @xmath0-distribution with @xmath13 degrees of freedom ; * @xmath17 denotes the cdf of the marginal distribution of the @xmath5th log - return ; * @xmath18 is the scaling factor for the @xmath5th log - return .    through this representation , the dependence among the log - returns , @xmath6 , can be determined by the correlations among @xmath19 .",
    "suppose , we are given the correlation matrix @xmath20 of vector @xmath21 and let @xmath22 be the lower triangular cholesky factor of @xmath20 satisfying @xmath23 .",
    "then , @xmath21 can be generated using @xmath24 where @xmath25 is a standard multi - normal random vector and @xmath26 is an independent chi - squared random variable with @xmath13 degrees of freedom .",
    "in this section , we provide a brief summary of efficient monte carlo simulation algorithms designed for the estimation of portfolio market risk . before that , we start with the implementation of the naive monte carlo algorithm . the naive identity of the loss probability is @xmath27 $ ] , where @xmath28 denotes the indicator of the event in braces .",
    "we are also interested in the conditional excess that can be represented as the ratio of two expectations @xmath29 = \\frac{{e\\left [ { l{\\mathbf 1_{\\left\\ { { l > \\tau } \\right\\ } } } } \\right]}}{{p\\left ( { l > \\tau } \\right ) } } = \\frac{{e\\left [ { l{\\mathbf 1_{\\left\\ { { l > \\tau } \\right\\ } } } } \\right]}}{{e\\left [ { { \\mathbf 1_{\\left\\ { { l > \\tau } \\right\\ } } } } \\right ] } } , \\label{eq : ratioest}\\ ] ] which can be estimated in a single simulation run .",
    "each replication of the naive monte carlo algorithm follows the steps given below :    1 .",
    "generate @xmath3 independent standard normal random variables , @xmath30 , and a chi - squared random variable @xmath26 with @xmath13 degrees of freedom , independent of @xmath31 .",
    "2 .   calculate @xmath32 in ( [ eq : multit ] ) .",
    "3 .   calculate the log - returns @xmath6 , @xmath33 in ( [ eq : logreturns ] ) .",
    "4 .   compute the portfolio loss @xmath34 and return the estimators @xmath35 and @xmath36 .      at a large threshold value @xmath12 ,",
    "most of the replications of the naive simulation algorithm return the value zero for the estimator @xmath35 . to increase the number of replications that fall in the region @xmath37 , importance sampling modifies the joint density of the random input .",
    "suppose @xmath38 is the joint probability density function ( pdf ) of input variables @xmath31 and @xmath26 , and @xmath39 is the modified density .",
    "importance sampling uses the following identity to estimate the loss probability @xmath40 = \\tilde e\\left [ { { { \\bf{1}}_{\\left\\ { { l > \\tau } \\right\\}}}\\frac{{f\\left ( { { \\bf{z}},y } \\right)}}{{\\tilde f\\left ( { { \\bf{z}},y } \\right ) } } } \\right],\\ ] ] where @xmath41 is the expectation taken using the modified density @xmath39 .",
    "finding an importance sampling density that minimizes the variance of monte carlo estimators is a subtle problem .",
    "but it is possible to use the zero - variance is function in search of an effective is density ( see , e.g. , @xcite and @xcite ) . @xcite",
    "add the mode of the zero - variance is function as a mean shift to the original density for pricing path - dependent options .",
    "@xcite utilize the same idea to find a close - to - optimal optimal parameters for simulating loss probabilities in the @xmath0-copula model of portfolio market risk .",
    "@xcite add a mean shift vector with negative entries to the normal vector @xmath31 and use a scale parameter less than two for the chi - square ( i.e. , gamma ) random variable @xmath26 to construct the is density . the shift vector and the scale value are selected so that the mode of the resulting is density is equal to the mode of the zero - variance is function . for more details on the determination of the is parameters and implementation of the simulation algorithm ,",
    "see section  4 of @xcite .      to obtain further variance reduction , one can stratify the importance sampling density along one or possibly more directions . for",
    "the @xmath0-copula model , suppose that @xmath42 , @xmath43 , is a partition of @xmath44 into @xmath45 disjoint subsets with probabilities @xmath46 under the is density .",
    "then the stratified importance sampling ( sis ) identity is given by @xmath47 = \\sum\\limits_{i = 1}^i { { { \\tilde p}_i}\\tilde e\\left [ { { { \\bf{1}}_{\\left\\ { { l > \\tau } \\right\\}}}\\frac{{f\\left ( { { \\bf{z}},y } \\right)}}{{\\tilde f\\left ( { { \\bf{z}},y } \\right)}}|\\left ( { { \\bf{z}},y } \\right ) \\in { \\xi _ i } } \\right]}.\\ ] ]    although stratified sampling is a simple variance reduction technique , its performance is adversely affected by the high - dimensionality of the sample space ( see * ? ? ?",
    "thus , we need to reduce the effective dimension for stratification . under the @xmath0-copula setting for portfolio market risk ,",
    "@xcite reduce the number of stratified dimensions from @xmath48 to two by stratifying @xmath31 along a single direction and stratifying @xmath26 .",
    "they use the is shift of @xcite as the stratification direction for @xmath31 , since the is shift provides a good stratification direction for multivariate normal input ( see * ? ? ?",
    "to elaborate on the implementation of stratification in @xcite , they use equiprobable strata and minimize the variance of the stratified estimator using an optimal sample allocation . for equiprobable strata , the optimal allocation of replications to a stratum is proportional to the conditional standard deviation of that stratum ( see , e.g. , * ? ? ?",
    "estimates of standard deviations can be computed using a pilot run .",
    "an iterative version of the same idea is presented in @xcite under the name of adaptive optimal allocation ( aoa ) . in each iteration",
    ", the aoa algorithm modifies the proportion of further replications by using conditional standard deviation estimates .",
    "these proportions converge to the optimal allocation fractions through the iterations .",
    "@xcite show that the stratified estimator of the aoa algorithm is asymptotically normal and its asymptotic variance is minimal .",
    "@xcite utilize the aoa algorithm of @xcite with minor modifications . for more details on the estimation of loss probabilities using the stratified importance sampling method ,",
    "see section  5 of @xcite .    for conditional excess simulation , the allocation strategy of the sis algorithm should be different than the one that we use for loss probability simulation . in that case",
    ", we use optimal allocation fractions that minimize the variance of the stratified ratio estimator of conditional excess ( see * ? ? ?",
    "* ) . for equiprobable strata ,",
    "the allocation fractions should be proportional to @xmath49 where @xmath50 $ ] , @xmath51 $ ] , @xmath52 and @xmath53 are the variances of @xmath54 and @xmath55 conditional on the @xmath56th stratum , and @xmath57 is the covariance of @xmath54 and @xmath55 conditional on the @xmath56th stratum .",
    "these values can be estimated through the iterations of the aoa algorithm .",
    "in this section , we first shortly describe the difference between randomized quasi - monte carlo and monte carlo simulation adapted to the problem of estimating portfolio market risk . in monte carlo simulation ,",
    "we randomly sample points from @xmath58 to approximate the integrals ( this is implicitly done while generating @xmath26 and @xmath31 ) .",
    "quasi - monte carlo sampling utilizes sample points in @xmath58 that come from a low - discrepancy point set .",
    "in contrast to a monte carlo sample , low - discrepancy point sets do not have the i.i.d .",
    "therefore , we can not directly employ the error bound formula used in monte carlo simulation .",
    "however , a random sample of quasi - random estimators can be constructed based on a low - discrepancy point set .",
    "this can be achieved by creating independent copies of a low - discrepancy point set @xmath59 by the following randomization    @xmath60    where @xmath61 is a uniformly distributed vector in @xmath58 .",
    "the vector @xmath62 is uniformly distributed in the unit hypercube ( see * ? ? ?",
    "thus , the estimators based on @xmath62 are unbiased , and the error bounds for the estimates can be obtained using @xmath63 independent randomized copies of @xmath64 .    given a low - discrepancy point sequence @xmath64 in @xmath58 , each replication of the randomized quasi - monte carlo version of the naive simulation algorithm ( see section  [ sec : effmc ] ) follows the steps given below :    1 .",
    "generate a randomized copy @xmath65 of @xmath66 using ( [ eq : shift ] ) .",
    "2 .   for @xmath67",
    "; 1 .   compute @xmath68 using the inverse cdf @xmath69 of the gamma distribution .",
    "2 .   compute @xmath70 for @xmath33 , using the inverse cdf @xmath71 of the standard normal distribution .",
    "3 .   calculate @xmath72 in ( [ eq : multit ] ) .",
    "4 .   calculate the log - returns @xmath73 , @xmath33 , in ( [ eq : logreturns ] ) .",
    "compute the portfolio loss @xmath74 .",
    "3 .   return the estimators @xmath75 and @xmath76 .    as pointed out by @xcite , the performance of qmc methods",
    "is degraded by the high dimension and the non - smoothness of the integrand .",
    "the rqmc implementation given above suffer from these problems since the number of stocks @xmath3 in a portfolio can be large and the integrands contain an indicator function . in order to improve the efficiency of rqmc estimators , one needs to solve these problems or decrease their impact",
    ".    the first problem , high - dimensionality , can be solved by applying a linear transformation to the vector @xmath31 so that the effective dimension of the integrand can be reduced ( see * ? ? ?",
    "furthermore , the impact of the second problem , non - smoothness , can be reduced using variance reduction techniques ( see , e.g. * ? ? ? * for an application in asian option pricing ) . in the rest of the section ,",
    "we first explain the linear transformation methodology that we use .",
    "then , we describe how rqmc can be efficiently combined with is and sis .",
    "the natural implementation of rqmc on naive simulation given above simply changes pseudorandom numbers with randomized low - discrepancy point sets .",
    "our numerical experiments indicate that this approach does not yield a significant improvement over the naive monte carlo method .",
    "this is due to the high dimension of the problem , i.e. , every random input ( @xmath77 ) has a significant contribution to the variance of the estimators . in order to increase",
    "the efficiency of rqmc on is , the effective dimension of the problem should be reduced such that the most of the variance can be explained by only a few random inputs .",
    "then , these random inputs can be generated through the first few elements of the randomized low - discrepancy points .",
    "the rationale behind this is the fact that the first low dimensional projections of the low - discrepancy point sets have better uniformity properties ( see * ? ? ?",
    "we apply a linear transformation to the random vector @xmath31 so that the first element @xmath78 corresponds to the is shift @xmath79 given in @xcite . the linear transformation can be applied by first multiplying @xmath31 with an orthogonal matrix @xmath80 that has its first column equal to @xmath81 .",
    "the remaining columns can be arbitrarily selected .",
    "this transformation increases the impact of @xmath78 on the variance of the estimators .",
    "then , we use the first two elements of the randomized low - discrepancy points to generate @xmath26 and @xmath78 , respectively .    in the application of linear transformation , the only change in the replications of the naive rqmc algorithm is the computation of the @xmath32 vector using @xmath82 where @xmath83 .",
    "the linear transformation described above reduces the effective dimension of the integrand considerably .",
    "but , as it was mentioned earlier , the non - smoothness of the integrands , caused by the indicator function @xmath35 , still has a strong impact on the performance of rqmc . at a large threshold value @xmath12 ,",
    "most of the replications of the naive simulation algorithm return zero values for the estimator @xmath35 .",
    "this results in large - sized jumps in the naive monte carlo integrands .",
    "figure  [ fig:2dexc_nv ] illustrates the non - smoothness problem of the naive integrand @xmath84 for a numerical example of section  [ sec : numres ] .",
    "we use the portfolio that consists of two stocks with @xmath0 marginals ( for the parameter values , see section  [ sec : numres ] ) . in this case",
    ", the integrand @xmath84 is a function on @xmath85 .",
    "indeed , such an integrand can not be illustrated in three - dimensional space .",
    "however , for demonstration purposes , it is possible to fix @xmath86 to zero ( @xmath87 ) as the impact of @xmath86 on the integrand is considerably reduced after the linear transformation .",
    "0.48   on @xmath88.,title=\"fig : \" ]       0.48   on @xmath88.,title=\"fig : \" ]    figure  [ fig:2dexc_is ] illustrates the monte carlo integrand under importance sampling density .",
    "the main difference between figure  [ fig:2dexc_is ] and figure  [ fig:2dexc_nv ] is the reduced size of the jumps for most of the domain .",
    "we achieve this by multiplying the integrand @xmath84 with the likelihood ratio @xmath89 in is .",
    "in the rqmc implementation of is , we simply shift @xmath78 with @xmath90 and generate @xmath26 under the is scale parameter @xmath91 .",
    "then , we apply the linear transform to @xmath31 using ( [ eq : lt ] ) .",
    "finally , the responses @xmath35 and @xmath36 are multiplied with the likelihood ratio @xmath92      as observed in figure  [ fig:2dexc_is ] , importance sampling reduces the size of the jumps over most of the integrand domain . however ,",
    "if we focus on the region where both @xmath93 and @xmath94 take values close to one , we see large - sized jumps .",
    "the variance contribution of such regions on the is estimator is significant . to remedy this problem ,",
    "one may allocate more replications to those regions through stratification .",
    "in previous subsections , we have explained how rqmc can be combined with linear transformation and is .",
    "this subsection describes how stratification can be combined with the previously discussed techniques .    in the rqmc version of the sis algorithm",
    ", we utilize the same low - discrepancy point sequence in each stratum .",
    "to guarantee independence across strata , we use different random shifts for each stratum .",
    "these random shifts remain the same throughout the iterations of the aoa algorithm .",
    "when the algorithm decides to allocate more replications in a stratum , we start with the first point of the low - discrepancy sequence that has not been used in the previous iterations .",
    "furthermore , the sample allocation decision is made based on the optimal allocation fractions described in section  [ sec : sis ] .",
    "the error bound for the randomized quasi - monte carlo sis estimator can be computed using the @xmath63 outer replications of the algorithm .",
    "in order to illustrate the efficiency of the randomized quasi - monte carlo method , we implement all algorithms in r @xcite . to generate randomized low - discrepancy point sets , we employ randomly shifted sobol nets using the implementation of @xcite using the r - package `` randtoolbox '' @xcite .",
    "in our experiments , we use stock portfolios with sizes @xmath3 equal to 2 , 5 , and 10 . for the choice of marginal distributions",
    ", we use the generalized hyperbolic and the @xmath0 distribution , as they seem to be the best fitting distributions for the stock log - returns . for the model parameters",
    ", we use the fitted values for nyse data reported in @xcite ( see page 65 for the list of stocks , tables e.1 , e.6 , e.7 , and e.8 for the @xmath0-copula parameters , and tables 6.4 and 6.5 for the marginal parameters ) .",
    "we present @xmath95 error bounds of naive ( @xmath96 ) , is ( @xmath97 ) , and sis ( @xmath98 ) mc simulations and naive ( @xmath99 ) , linear transformation ( @xmath100 ) , and is ( @xmath101 ) rqmc simulations for loss probability and conditional excess estimation using the @xmath0 and the generalized hyperbolic ( gh ) marginals in table  1 .",
    "threshold values ( @xmath12 ) that gives loss probabilities of @xmath102 and @xmath103 are also provided for different parameter settings . for each parameter setting",
    ", the first row gives the error bounds for loss probability estimates and the second row for the conditional excess estimates .",
    "note that the loss probability and the conditional excess simulations are performed separately .    in these experiments ,",
    "the total number of replications used is @xmath104 for naive and is simulations and approximately @xmath105 for sis simulation .",
    "we terminate sis in four iterations , using approximately 10 , 20 , 30 , and 40 percent of the total sample size in each iteration , sequentially . the number of outer replications in rqmc simulations is selected as @xmath106 in order to give reliable error bounds on the estimate .",
    "thus , we do @xmath107 inner replications . for this setting , the randomized quasi - monte carlo version of stratified importance sampling does not provide reliable error bounds , since @xmath108 is not sufficiently large to satisfy the asymptotic normality of the stratified estimators .",
    "for this reason , we do not provide error bounds of the randomized quasi - monte carlo version of stratified importance sampling . in the following paragraphs",
    ", we provide information on the convergence properties of the randomized quasi - monte carlo version of stratified importance sampling .    from table  [",
    "tab : tlp ] , we observe that the use of rqmc sampling clearly reduces the error bound of the naive mc for loss probability estimates , however , the improvement is less clear for probability of 0.001 . for conditional excess simulation ,",
    "rqmc implementation is only efficient for loss probability of 0.05 .",
    "combination of rqmc with linear transformation further reduces the error bounds of the estimates when the loss probability level is 0.05 .",
    "when we compare the error bounds of monte carlo is with rqmc is , we observe a reasonable improvement for all cases .",
    "the reason behind this performance boost of rqmc over mc is the fact that the is integrand is smoother ( see section  [ sec : rqmcis ] ) .",
    "figure  [ fig : convergence ] shows the convergence of rqmc sis estimates to the nearly exact values ( we use @xmath109 replications in sis to compute these values ) as the total sample size increases . on the vertical axes , we give the absolute percentage relative errors of rqmc sis and mc sis methods . for comparison purposes",
    ", we use mc sis as it yields the smallest error bounds in table  [ tab : tlp ] . the relative error bound for the mc sis estimates",
    "are also provided .",
    "these figures suggest that rqmc sis converges faster than mc sis .",
    "note that these figures are drawn for @xmath0-marginals and loss probability of 0.05 .",
    "0.48   marginals for loss probability of 0.05.,title=\"fig : \" ]       0.48   marginals for loss probability of 0.05.,title=\"fig : \" ]    0.48   marginals for loss probability of 0.05.,title=\"fig : \" ]       0.48   marginals for loss probability of 0.05.,title=\"fig : \" ]",
    "we have combined rqmc with variance reduction techniques , is and sis for simulating loss probability and conditional excess under the @xmath0-copula model of market risk . in the implementation of rqmc ,",
    "high - dimensionality and non - smoothness stand in the way as two main problems .",
    "the first problem , high - dimensionality , is solved by applying a linear transformation on the random input to reduce the effective dimension .",
    "the discontinuity of simulation integrand , the second problem , is reduced using importance sampling .",
    "we have analyzed the performance improvement of rqmc implementations of is and sis over their monte carlo implementations .",
    "the effectiveness of rqmc is illustrated in realistic portfolio examples .",
    "the authors would like to thank the institute for statistics and mathematics at the vienna university of economics and business for permitting the use of their computing cluster.this work was supported by xian jiaotong - liverpool university research fund project rdf-14 - 01 - 33 .        .",
    "baolu and w.  hrmann .",
    "efficient stratified sampling implementations in multiresponse simulation . in _ proceedings of the 2014 winter simulation conference a. tolk , s. y. diallo , i. o. ryzhov , l. yilmaz , s. buckley , and j. a. miller , eds .",
    "_ , pages 757768 .",
    "winter simulation conference , dec 2014 .",
    "k.  dinge and w.  hrmann .",
    "improved monte carlo and quasi - monte carlo methods for the price and the greeks of asian options . in _ proceedings of the 2014 winter simulation conference a. tolk , s. y. diallo , i. o. ryzhov , l. yilmaz , s. buckley , and j. a. miller , eds .",
    "_ , pages 441452 .",
    "winter simulation conference , dec 2014 .",
    "j.  imai and k.  s. tan .",
    "pricing derivative securities using integrated quasi ",
    "monte carlo methods with dimension reduction and discontinuity realignment .",
    "_ siam journal on scientific computing _ , 360 ( 5):0 a2101a2121 , 2014 ."
  ],
  "abstract_text": [
    "<S> we consider the problem of simulating loss probabilities and conditional excesses for linear asset portfolios under the @xmath0-copula model . </S>",
    "<S> although in the literature on market risk management there are papers proposing efficient variance reduction methods for monte carlo simulation of portfolio market risk , there is no paper discussing combining the randomized quasi - monte carlo method with variance reduction techniques . in this paper , we combine the randomized quasi - monte carlo method with importance sampling and stratified importance sampling . numerical results for realistic portfolio examples suggest that replacing pseudorandom numbers ( monte carlo ) with quasi - random sequences ( quasi - monte carlo ) in the simulations increases the robustness of the estimates once we reduce the effective dimension and the non - smoothness of the integrands .    </S>",
    "<S> keywords : risk management ; quasi - monte carlo ; importance sampling ; stratified sampling ; t - copula    halis sak + department of mathematical sciences , xian jiaotong - liverpool university , suzhou , china + ismail baolu + school of economics and administrative sciences , istanbul kemerburgaz university , istanbul , turkey + </S>"
  ]
}