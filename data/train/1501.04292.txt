{
  "article_text": [
    "inspired by the success of bag - of - words ( bow ) in text information retrieval , we can similarly represent an image as a histogram of visual words through quantizing the local keypoints within the image into visual words , which is known as visual bow in the areas of image analysis and computer vision . as an intermediate representation , the visual bow model can help to reduce the semantic gap between the low - level visual features and the high - level semantics of images to some extent .",
    "hence , many efforts have been made to apply the visual bow model to image classification .",
    "in fact , the visual bow model has been shown to give rise to encouraging results in image classification @xcite . in the following ,",
    "we refer to the visual words as mid - level features to distinguish them from the low - level visual features and high - level semantics of images",
    ".    however , as reported in previous work @xcite , the traditional visual bow model has two distinct drawbacks .",
    "firstly , for efficiency purposes , the visual vocabulary is commonly constructed by directly clustering @xcite the low - level visual feature vectors extracted from local keypoints within images , without considering the high - level semantics of images .",
    "that is , although the visual bow model can help to reduce the semantic gap to some extent , it still suffers from the problem of semantic gap and thus may lead to significant performance degradation in more challenging tasks ( e.g. , social image classification with larger intra - class variations ) .",
    "secondly , typically thousands of mid - level features are generated to obtain better performance on a relatively large image dataset .",
    "due to such large vocabulary size , the subsequent image classification may take sheer amount of time .",
    "this means that visual bow reduction becomes crucial for the efficient use of the visual bow model in social image classification . in this paper ,",
    "our main motivation is to simultaneously overcome these two drawbacks by proposing a new framework for visual bow refinement and reduction , which will be elaborated in the following .",
    "it should be noted that these two drawbacks are usually considered separately in the literature @xcite .",
    "more thorough reviews of previous methods can be found in section  [ sect : rw ] .    to overcome the first drawback",
    ", we develop a graph - based method to exploit the tags of images for visual bow refinement . the basic idea is to formulate visual bow refinement as a multi - class semi - supervised learning ( ssl ) problem .",
    "that is , we can regard each visual word as a  class \" and thus take the visual bow representation as the initial configuration of ssl . in this paper , we focus on solving this problem by the graph - based ssl techniques @xcite .",
    "considering that graph construction is the key step of graph - based ssl , we construct a new @xmath0-graph over images with structured sparse representation by exploiting both the original visual bow model and the tags of images , which is different from the traditional @xmath0-graph @xcite constructed only with sparse representation @xcite . through semi",
    "- supervised learning with such new @xmath0-graph , we can explicitly utilize the tags of images ( i.e. high - level semantics ) to reduce the semantic gap associated with the visual bow model to some extent .",
    "although the semantic information can be exploited for visual bow refinement using the above graph - based ssl , the vocabulary size of the refined visual bow model remains unchanged .",
    "hence , given a large initial visual vocabulary , the subsequent image classification may still take sheer amount of time .",
    "for efficient image classification , we further reduce the refined visual bow model to a much smaller size through spectral clustering @xcite over mid - level features .",
    "a reduced set of high - level features is generated by regarding each cluster of mid - level features as a new higher level feature .",
    "moreover , since the tags of images has been incorporated into the refined visual bow model , we indirectly consider the semantic information in visual bow reduction by using the refined visual bow model for spectral clustering . in the following ,",
    "our method is thus called as semantic spectral clustering . when tested in image classification ,",
    "the reduced set of high - level features is shown to cause much less time but with little performance degradation .        in summary",
    ", we propose a new framework for visual bow refinement and reduction , and the system overview is illustrated in figure  [ fig.1 ] .",
    "in fact , upon our short conference version @xcite , we have made two extra contributions ( also see figure  [ fig.1 ] ) : visual bow refinement , and semantic graph construction for visual bow reduction .",
    "moreover , the advantages of the proposed framework can be summarized as follows : ( 1 ) our visual bow refinement and reduction are both efficient even for large image datasets ; ( 2 ) when the global visual features are fused for image classification , we can _ obtain the best results so far _ ( to the best of our knowledge ) on the pascal voc07 @xcite and mir flickr @xcite benchmark datasets , as shown in our later experiments ; ( 3 ) although only tested in image classification , our visual bow refinement and reduction can be extended to other tasks ( e.g. image annotation ) .",
    "the remainder of this paper is organized as follows .",
    "section  [ sect : rw ] provides an overview of related work . in section  [",
    "sect : refine ] , we develop a graph - based method to explicitly utilize the tags of images for visual bow refinement . in section  [ sect : reduct ] , the refined visual bow model is further reduced to a much smaller size through semantic spectral clustering . in section  [",
    "sect : exp ] , the refined and reduced visual bow models are evaluated by directly applying them to image classification .",
    "finally , section  [ sect : con ] gives the conclusions .",
    "since visual bow refinement and reduction , and structured sparse representation are considered in the proposed framework , we will give an overview of these techniques in the following .",
    "in this paper , visual bow refinement refers to adding the semantics of images to the visual bow model .",
    "the main goal of visual bow refinement is to bridge the semantic gap associated with the traditional visual bow model . to the best of our knowledge , there exist at least two types of semantics which can be exploited for visual bow refinement : ( 1 ) the constraints with respect to local keypoints , and ( 2 ) the tags of images .",
    "derived from prior knowledge ( e.g. the wheel and window of a car should occur together ) , the constraints with respect to local keypoints can be directly used as the clustering conditions for clustering - based visual bow generation @xcite .",
    "however , the main disadvantage of this approach is that the constraints are commonly very expensive to obtain in practice .",
    "in contrast , the tags of images are much easier to access for social image collections . hence ,",
    "in this paper , we focus on exploiting the tags of images for visual bow refinement .",
    "unlike our idea of utilizing the tags of images to refine the visual bow model and then improve the performance of image classification , this semantic information can also be directly used as features for image classification .",
    "for example , by combining the tags of images with the global ( e.g. color histogram ) and local ( e.g. bow ) visual features , one influential work @xcite has reported the best classification results so far ( to the best of our knowledge ) on the pascal voc07 @xcite and mir flickr @xcite benchmark datasets .",
    "however , when the global visual features ( actually much weaker than those used in @xcite ) are also considered for image classification in this paper , our later experimental results demonstrate that our method performs better than @xcite on these two benchmark datasets .    besides the tags of images ,",
    "other types of information can also be used to bridge the semantic gap associated with the visual representation . in @xcite ,",
    "local or global spatial information is incorporated into the visual representation , which leads to obvious performance improvements in image classification . in @xcite ,",
    "extra depth information is considered for image classification in the imageclef 2013 robot vision task . in @xcite ,",
    "inspired from the biological / cognitive models , a hierarchical structure is learnt for computer vision tasks .",
    "although the goal of these approaches is the same as that of our method , we focus on utilizing the tags of images to bridge the semantic gap in this paper . in fact , the spatial , depth , or hierarchical information can be similarly added to our refined visual bow model .",
    "for example , our refined visual bow model can be used just as the original one to define spatial pyramid matching kernel @xcite .",
    "the goal of visual bow reduction is to reduce the visual bow model of large vocabulary size to a much smaller size .",
    "this is mainly motivated by the fact that a large visual bow model causes sheer amount of time in image classification although it can achieve better performance on a relatively large image dataset . in this paper , to handle this problem",
    ", we propose a semantic spectral clustering method for visual bow reduction .",
    "the distinct advantage of our method is that the manifold structure of mid - level features can be preserved explicitly , unlike the traditional topic models @xcite for visual bow reduction without considering such intrinsic geometric information .",
    "this is also the reason why our method significantly outperforms latent dirichlet allocation @xcite ( one of the most outstanding methods for visual bow reduction in the literature ) as shown in our later experiments .",
    "similar to our semantic spectral clustering , the diffusion map method proposed in @xcite can also exploit the intrinsic geometric information for visual bow reduction .",
    "however , the main disadvantage of this method is that it requires fine parameter tuning for graph construction which can significantly affect the performance of visual bow reduction .",
    "in contrast , we construct semantic graphs in a parameter - free manner in this paper .",
    "as shown in our later experiments , our spectral clustering with semantic graphs can help to discover more intrinsic manifold structure of mid - level features and thus lead to obvious performance improvements .",
    "moreover , since we focus on parameter - free graph construction for spectral clustering in this paper , we only adopt the commonly used technique introduced in @xcite , without considering other spectral clustering techniques @xcite developed in the literature .",
    "although our visual bow reduction can be regarded as kind of dimension reduction over mid - level features , it has two distinct advantages over the traditional dimension reduction approaches @xcite directly using spectral embedding .",
    "firstly , each higher level feature learnt by our visual bow reduction is actually a group of mid - level features which tend to be semantically related as shown in figure  [ fig.4 ] .",
    "however , the traditional dimension reduction approaches performing spectral embedding over all the data fail to give explicit explanation of each reduced feature , since they directly utilize the eigenvectors of the laplacian matrix to form the new feature representation . secondly , our visual bow reduction by semantic spectral clustering over mid - level features takes much less time than the traditional dimension reduction approaches by spectral embedding with graphs over all the data .      in this paper , we formulate visual bow refinement as a multi - class graph - based ssl problem . considering that graph construction is the key step of graph - based ssl",
    ", we develop a new @xmath0-graph construction method using structured sparse representation , other than the traditional @xmath0-graph construction method only using sparse representation .",
    "as compared with sparse representation , our structured sparse representation has a distinct advantage , i.e. , the extra structured sparsity can be induced into @xmath0-graph construction and thus the noise in the data can be suppressed to the most extent .",
    "in fact , the structured sparsity penalty used in this paper is defined as @xmath0-norm laplacian regularization , which is formulated directly over all the eigenvectors of the normalized laplacian matrix .",
    "hence , our new @xmath0-norm laplacian regularization is different from the @xmath1-laplacian regularization @xcite as an ordinary @xmath0-generalization ( with @xmath2 ) of the traditional laplacian regularization ( see further comparison in section [ sect : refine : ssr ] ) . in this paper , we focus on exploiting the manifold structure of the data for @xmath0-graph construction with structured sparse representation , regardless of other types of structured sparsity @xcite used in the literature .",
    "this section presents our visual bow refinement method in detail .",
    "we first give our problem formulation for visual bow refinement from a graph - based ssl viewpoint , and then construct a new @xmath0-graph using structured sparse representation for such graph - based ssl . finally , we provide the complete algorithm for our visual bow refinement based on the new @xmath0-graph .",
    ", while each row denotes an image @xmath3 .",
    "here , each column actually provides an initial configuration ( e.g. labeled and unlabeled data along @xmath4 ) of graph - based ssl for a single class.,scaledwidth=75.0% ]    in this paper , we focus on visual bow refinement by exploiting the tags of images , which are easy to access for social image collections .",
    "similar to the formation of the visual bow model , we generate a new textual bow model with the tags of images .",
    "this means that our goal is actually to refine the visual bow model based on the textual bow model .",
    "as stated in section i , we can transform visual bow refinement into a multi - class ssl problem , which is also illustrated in figure  [ fig.2 ] .",
    "although this multi - class problem can be solved by many other machine learning techniques , we only consider the graph - based ssl method @xcite in this paper .",
    "the problem formulation is elaborated as follows .",
    "let @xmath5 denote the visual bow model and @xmath6 denote the kernel ( affinity ) matrix computed over the textual bow model , where @xmath7 is the number of images and @xmath8 is the number of visual words . in this paper , we only adopt linear kernel to define the similarity matrix over the textual bow model . by directly setting the weight matrix @xmath9 , we construct an undirected graph @xmath10 with its vertex set @xmath11 being the set of images .",
    "the normalized laplacian matrix of @xmath12 is given by @xmath13 where @xmath14 is an identity matrix and @xmath15 is a diagonal matrix with its @xmath16-th diagonal element being the sum of the @xmath16-th row of @xmath17 .",
    "the normalized laplacian matrix @xmath18 is nonnegative definite .",
    "based on the above preliminary notations , the problem of visual bow refinement can be formulated from a multi - class graph - based ssl viewpoint as illustrated in figure  [ fig.2 ] : @xmath19 where @xmath20 denotes the refined visual bow model , @xmath21 denotes the positive regularization parameter , and @xmath22 denotes the trace of a matrix .",
    "the first term of the above objective function is the fitting constraint , which means a good @xmath23 should not change too much from the initial @xmath24 .",
    "the second term is the smoothness constraint , which means that a good @xmath23 should not change too much between similar images .",
    "according to @xcite , the above graph - based ssl problem has an analytical solution : @xmath25 we can clearly observe that _ the semantic information has been added to the visual bow model _ by defining the normalized laplacian matrix @xmath18 using the tags of images ( i.e. the textual bow model ) .",
    "more notably , such visual bow refinement can effectively bridge the semantic gap associated with the traditional visual bow model , as shown in our later experiments",
    ". the only disadvantage of the above analytical solution is that it is not efficient for large image datasets , since it has a time complexity of @xmath26 .    to apply our visual bow refinement to large datasets",
    ", we have to concern two key subproblems : how to construct the graph efficiently , and how to solve the problem in equation  ( [ eq : bowsr ] ) efficiently .",
    "moreover , since noisy tags may be used for our visual bow refinement , we also need to ensure that our graph construction is noise - robust .",
    "these two subproblems will be addressed in the next two subsections , respectively .",
    "considering the important role of @xmath12 in the above visual bow refinement , we first focus on graph construction over images . in the literature , the @xmath27-nearest neighbor ( @xmath27-nn ) graph has been widely used for graph - based ssl , since the problem in equation  ( [ eq : bowsr ] ) can be solved by the algorithm proposed in @xcite with linear time complexity based on this simple graph ( @xmath28 )",
    ". however , the @xmath27-nn graph suffers from inherent limitations ( e.g. sensitivity to noise ) . to deal with the noise ( e.g. noisy tags here )",
    ", a new @xmath0-graph construction method has recently been developed based on sparse representation .",
    "the basic idea of @xmath0-graph construction is to seek a sparse linear reconstruction of each image with the other images .",
    "unfortunately , such @xmath0-graph construction may become infeasible since it takes sheer amount of time given a large data size @xmath7 . to make a tradeoff",
    ", we only consider the @xmath27 nearest neighbors of each image for sparse linear reconstruction of this image , which thus becomes a much smaller scale optimization problem ( @xmath28 ) .",
    "moreover , to induce the structured sparsity into @xmath0-graph construction and further suppress the noise in the data , we exploit the manifold structure of the @xmath27 nearest neighbors for sparse linear reconstruction of each image .",
    "this @xmath0-graph construction will be elaborated as follows .",
    "we start with the problem formulation for sparse linear reconstruction of each image in its @xmath27-nearest neighborhood . given an image @xmath29 ( @xmath30 ) represented by the textual bow model ( of the vocabulary size @xmath31 ) ,",
    "we suppose it can be reconstructed using its @xmath27-nearest neighbors ( their indices are collected into @xmath32 ) as follows : @xmath33 , where @xmath34 is a vector that stores unknown reconstruction coefficients , @xmath35_{i_j\\in \\mathcal{n}_k(i ) , j=1, ... ,k } \\in r^{m_t \\times k}$ ] is a dictionary with each column being regarded as a base , and @xmath36 is the noise term . here",
    ", it should be noted that we just follow the idea of @xcite to introduce the noise term @xmath37 into the linear reconstruction of @xmath38 .",
    "the main concern is that @xmath39 may not be exactly satisfied since we have @xmath40 in this paper .",
    "let @xmath41 \\in r^{m_t \\times ( m_t+k)}$ ] and @xmath42^t$ ] .",
    "the linear reconstruction of @xmath38 can be transformed into : @xmath43 , which is now an underdetermined system with respect to @xmath44 since we always have @xmath45 . according to @xcite ,",
    "if the solution ( i.e. @xmath44 ) with respect to @xmath38 is sparse enough , it can be recovered by solving the following @xmath0-norm optimization problem : @xmath46 where @xmath47 is the @xmath0-norm of @xmath44 .",
    "given the kernel ( affinity ) matrix @xmath48 computed over the textual bow model ( also used as the weight matrix in equation ( [ eq : lap ] ) ) , we utilize the kernel trick and transform the linear reconstruction of @xmath38 into : @xmath49 .",
    "let @xmath50_{j\\in \\mathcal{n}_k(i ) } \\in r^k$ ] , @xmath51_{j , j'\\in \\mathcal{n}_k(i ) } \\in r^{k\\times k}$ ] , and @xmath52 .",
    "the original @xmath0-norm optimization problem in equation  ( [ eq : srori ] ) can be reformulated as : @xmath53||_1,~~\\mathrm{s.t.}~~y_i = c_i \\alpha_i + \\zeta_i .",
    "\\label{eq : sr}\\end{aligned}\\ ] ] let @xmath54 \\in r^{k \\times 2k}$ ] and @xmath55^t$ ] , the above problem can be further transformed into : @xmath56 which is similar to the original problem in equation  ( [ eq : srori ] ) .",
    "this is a standard @xmath0-norm optimization problem , and we can solve it just as @xcite . in this paper , we directly use the matlab toolbox @xmath57-magic .    after we have obtained the reconstruction coefficients for all the images by the above sparse linear reconstruction , the weight matrix @xmath58 can be defined the same as @xcite : @xmath59 where @xmath60 denotes the @xmath61-th element of the vector @xmath44 , and @xmath62 means that @xmath63 is the @xmath61-th element of the set @xmath32 . by setting the weight matrix @xmath64 , we then construct an undirected graph @xmath65 with the vertex set @xmath11 being the set of images . in the following ,",
    "this graph is called as @xmath0-graph , since it is constructed by @xmath0-optimization .    in this @xmath0-graph",
    ", the similarity between images is defined as the reconstruction coefficients of the sparse linear reconstruction solution .",
    "however , the structured sparsity of these reconstruction coefficients is actually ignored in such sparse representation . to address this problem",
    ", we further induce the structured sparsity into @xmath0-graph construction . in this paper",
    ", we only consider one special type of structured information , i.e. , the manifold structure of images .",
    "in fact , this structured information can be explored in sparse representation through laplacian regularization @xcite .",
    "since the textual bow model has been used for the above sparse representation , we define laplacian regularization with the visual bow model .",
    "the distinct advantage of using laplacian regularization is that we can induce the extra structured sparsity into sparse representation and thus suppress the noise in the data .    to define the laplacian regularization term for structured sparse representation with respect to each image @xmath38 , we first compute the normalized laplacian matrix as follows : @xmath66 where @xmath67_{j\\in \\mathcal{n}_k(i)}$ ] with @xmath68 being the @xmath63-th row of the visual bow model @xmath24 , and @xmath69 is a diagonal matrix with its @xmath63-th diagonal element being the sum of the @xmath63-th row of @xmath70 . here",
    ", we define the similarity matrix ( i.e. @xmath70 ) in the @xmath27-nearest neighborhood @xmath32 of @xmath38 only with linear kernel .",
    "we further define the laplacian regularization term for the sparse representation problem in equation ( [ eq : sr ] ) as @xmath71 .",
    "let @xmath72 be a @xmath73 orthonormal matrix with each column being an eigenvector of @xmath74 , and @xmath75 be a @xmath76 diagonal matrix with its diagonal element @xmath77 being an eigenvalue of @xmath74 ( sorted as @xmath78 ) .",
    "given that @xmath74 is nonnegative definite , we have @xmath79 . meanwhile , since @xmath80 and @xmath72 is orthonormal , we have @xmath81 . hence , @xmath71 can be reformulated as : @xmath82 where @xmath83 .",
    "that is , we have successfully formulated @xmath71 as an @xmath84-norm term .",
    "however , if this laplacian regularization term is directly added into the sparse representation problem in equation  ( [ eq : sr ] ) , we would have difficulty in solving this problem efficiently . hence",
    ", we further formulate an @xmath0-norm version of laplacian regularization as : latexmath:[\\ ] ] where the reconstruction error and laplacian regularization with respect to @xmath87 are controlled by @xmath88 and @xmath89 , respectively .",
    "let @xmath90^t$ ] , @xmath91 $ ] , and @xmath92^t$ ] .",
    "we finally solve the following structured sparse representation problem for @xmath0-graph construction : @xmath93 which takes the same form as the original sparse representation problem in equation  ( [ eq : srsol ] ) .",
    "the weight matrix @xmath17 of the @xmath0-graph @xmath65 can be defined the same as equation ( [ eq : l1wt ] ) .",
    "as we have mentioned , our @xmath0-norm laplacian regularization can be smoothly incorporated into the original sparse representation problem in equation ( [ eq : sr ] ) .",
    "however , this is not true for the traditional laplacian regularization , which may introduce extra parameters ( hard to tune in practice ) into the @xmath0-optimization for sparse representation .",
    "more importantly , our @xmath0-norm laplacian regularization can induce the extra structured sparsity ( i.e. the sparsity of the noise term @xmath89 ) , which is not ensured by the traditional laplacian regularization .",
    "it should be noted that the @xmath1-laplacian regularization @xcite can also be regarded as an @xmath0-generalization of laplacian regularization with @xmath2 . by defining a matrix @xmath94 ,",
    "the @xmath1-laplacian regularization can be formulated as @xmath95 @xcite , similar to our @xmath0-norm laplacian regularization .",
    "hence , we can apply @xmath1-laplacian regularization similarly to structured sparse representation .",
    "however , this laplacian regularization causes much more time since @xmath96 has a much larger size as compared to the matrix @xmath97 used by our @xmath0-norm laplacian regularization proposed above .      after we have constructed the @xmath0-graph over images with structured sparse representation , we further solve the visual bow refinement problem in equation ( [ eq : bowsr ] ) using the algorithm proposed in @xcite .",
    "the complete algorithm for visual bow refinement is outlined as follows :    ( 1 ) : :    construct an @xmath0-graph    @xmath65 by solving the    structured sparse representation problem in equation ( [ eq : ssrnew ] ) in    the @xmath27-nearest neighborhood of each image .",
    "( 2 ) : :    compute the matrix @xmath98 , where    @xmath15 is a diagonal matrix with its @xmath16-th    diagonal element being the sum of the @xmath16-th row of    @xmath17 .",
    "( 3 ) : :    iterate @xmath99 for visual    bow refinement until convergence , where the parameter    @xmath100 ( see the explanation below ) . ( 4 ) : :    output the limit @xmath101 of the sequence    @xmath102 as the final refined visual bow model .",
    "according to @xcite , the above algorithm converges to @xmath103 , which is equal to equation ( [ eq : bowsrsol ] ) with @xmath100 .",
    "since the structured sparse representation problem in equation ( [ eq : ssrnew ] ) is limited to @xmath27-nearest neighborhood , our @xmath0-graph construction in step 1 has the same time complexity ( with respect to the data size @xmath7 ) as @xmath27-nn graph construction .",
    "moreover , given that @xmath104 is very sparse , step 3 has a linear time complexity .",
    "hence , the proposed algorithm can be applied to large datasets .        to give an explicit explanation of the refined visual bow model @xmath101",
    ", we show the illustrative comparison between the refined and original visual bow models in figure  [ fig.3 ] . here",
    ", we conduct the experiment of visual bow refinement on a subset of the pascal voc07 dataset @xcite . the immediate observation from figure  [ fig.3 ]",
    "is that the intra - class variations due to scale changes and cluttered backgrounds can be reduced by our visual bow refinement in terms of hik values .",
    "that is , the semantic gap associated with the original visual bow is indeed bridged to some extent by exploiting the tags of images .",
    "another interesting observation from figure  [ fig.3 ] is that some visual words of the refined visual bow model tend to be explicitly related to the high - level semantics of images .",
    "for example , the visual word marked by an orange box is clearly shown to be related to  bike \" , considering that this visual word becomes dominative ( _ originally far from dominative _ ) in the histogram of the fourth image after visual bow refinement . such observation",
    "further verifies the effectiveness of our visual bow refinement .",
    "this section presents our visual bow reduction on the refined visual bow model @xmath101 in detail .",
    "we first formulate visual bow reduction as a semantic spectral clustering problem , and then construct two semantic graphs with the refined visual bow model for such spectral clustering .",
    "finally , we provide the complete algorithm for visual bow reduction with the constructed semantic graphs .",
    "since the semantic information has been successfully exploited for visual bow refinement in section  [ sect : refine ] , the semantic gap associated with the visual bow model can be bridged to some extent .",
    "however , the vocabulary size of the refined visual bow model remains unchanged , which means that the subsequent image classification may still take sheer amount of time given a large initial visual vocabulary . in this paper , for efficient image classification",
    ", we further reduce the refined visual bow model to a much smaller size . to explicitly preserve the manifold structure of mid - level features ,",
    "we formulate visual bow reduction as spectral clustering over mid - level features just as our short conference version @xcite , which is also shown in figure  [ fig.1 ] .",
    "the goal of spectral clustering is to extract a reduced set of higher level features from the original large vocabulary of mid - level features . in this paper , spectral clustering of mid - level features",
    "is selected for visual bow reduction , because it can give explicit explanation of each reduced feature ( also see figure  [ fig.4 ] ) . however ,",
    "this is not true for the traditional dimension reduction methods _ directly using spectral embedding over images _ ( or other similar techniques ) , since the meaning of each dimension in the reduced space is unknown . in the following",
    ", we will elaborate the key step of spectral clustering used for our visual bow reduction , i.e. , _ spectral embedding over mid - level features_.    given a vocabulary of mid - level features @xmath105 , we construct an undirected weighted graph @xmath106 with its vertex set @xmath107 and @xmath108_{m_v \\times m_v}$ ] , where @xmath109 denotes the similarity between two mid - level features @xmath110 and @xmath111 . in this paper ,",
    "the weight matrix @xmath112 is computed based on the refined visual bow model @xmath101 . since spectral",
    "embedding aims to represent each vertex in the graph as a lower dimensional vector that preserves the similarities between the vertex pairs , it is actually equivalent to finding the leading eigenvectors of the normalized graph laplacian @xmath113 , where @xmath114 is a diagonal matrix with its @xmath115-element equal to the sum of the @xmath16-th row of @xmath112 . in this paper , we only consider this type of normalized laplacian @xcite , regardless of other normalized versions ( e.g. @xcite ) .",
    "let @xmath116 be the set of eigenvalues and the associated eigenvectors of @xmath117 , where @xmath118 and @xmath119 .",
    "the _ spectral embedding _ of the graph @xmath120 is represented by @xmath121 with the @xmath63-th row @xmath122 being the new representation for mid - level feature @xmath111 .",
    "given that @xmath123 , the mid - level features have actually been represented as lower dimensional vectors .",
    "since we have only formulated the key step of spectral clustering ( i.e. spectral embedding ) in detail , we will further elaborate _",
    "graph construction for spectral clustering _ and _ the complete visual bow reduction algorithm by spectral clustering _ in the next two subsections , respectively .",
    "in this subsection , we focus on graph construction for spectral clustering of mid - level features .",
    "more concretely , based on the refined visual bow model @xmath101 , we construct two graphs over mid - level features , which are different only in how we quantify the similarity between mid - level features .",
    "the details of the two graph construction approaches are presented as follows .    the first graph @xmath124 is constructed by defining the weight matrix @xmath108_{m_v \\times m_v}$ ] based on the pearson product moment ( ppm ) correlation @xcite .",
    "that is , given the refined visual bow model @xmath101 , the similarity between mid - level features @xmath110 and @xmath111 is computed by @xmath125 where @xmath126 and @xmath127 are the mean and standard deviation of @xmath128 ( the @xmath16-th column of @xmath101 ) , respectively . if @xmath110 and @xmath111 are not positively correlated , @xmath109 will be negative . in this case",
    ", we set @xmath129 to ensure that the weight matrix @xmath112 is nonnegative .",
    "moreover , we construct the second graph @xmath124 by directly defining the weight matrix @xmath112 in the following matrix form : @xmath130 where @xmath131 denotes the similarity ( affinity ) matrix computed over the textual bow model ( also used as the weight matrix in equation ( [ eq : lap ] ) ) .",
    "since the refined visual bow model @xmath101 used to construct the above two graphs has taken the tags of images into account , we call them as semantic graphs",
    ". it should noted that these two graphs have a significant difference : the first graph is constructed only with the refined visual bow model @xmath101 , while the second graph exploits the textual bow model besides @xmath101 .",
    "more notable , the first method using equation ( [ eq : swt1 ] ) for graph construction is proposed in our short conference paper @xcite , while the second method using equation ( [ eq : swt2 ] ) is newly proposed in the present work . since the textual bow model is not used in equation ( [ eq : swt1 ] )",
    ", the first method can handle images even without user - shared tags ( just as @xcite ) , which is not the case for the second method using equation ( [ eq : swt2 ] ) .",
    "meanwhile , our later experiments show that the second method for graph construction generally outperforms the first method due to the extra use of the textual bow model .",
    "the distinct advantage of using the above two graphs for spectral clustering is that we have eliminated the need to tune any parameter for graph construction which can significantly affect the performance and has been noted as an inherent weakness of graph - based methods .",
    "in contrast , the graph over mid - level features is defined by a gaussian function in @xcite when each mid - level feature is represented as a vector of point - wise mutual information . as reported in @xcite , the choice of the variance in the gaussian function affects the performance significantly .",
    "more importantly , as shown in later experiments , our spectral clustering with semantic graphs can help to discover more intrinsic manifold structure of mid - level features and thus lead to obvious performance improvements over @xcite .",
    "are derived from the original visual vocabulary @xmath132 , where each high - level feature refers to a cluster of mid - level features .",
    "it can be observed that the semantically related mid - level features tend to be grouped together ( e.g. wheel and window , or head and fur ) by spectral clustering .",
    ", scaledwidth=76.0% ]    after a semantic graph has been constructed based on the refined visual bow model , we perform spectral embedding on this graph . in the new low - dimensional embedding space defined by equation ( 13 ) , we reduce the visual vocabulary @xmath133 into a set of higher level features by @xmath27-means clustering .",
    "the complete algorithm for visual bow reduction is summarized as follows :    ( 1 ) : :    find @xmath134 smallest nontrivial eigenvectors    @xmath135 of    @xmath113 . here , @xmath112    can be defined by either equation ( [ eq : swt1 ] ) or equation ( [ eq : swt2 ] ) .",
    "( 2 ) : :    form    @xmath136 $ ] , and    normalize each row of @xmath137 to have unit length . here",
    ",    the @xmath16-th row @xmath138 denotes the new    low - dimensional feature vector for mid - level feature    @xmath110 .",
    "( 3 ) : :    perform @xmath27-means clustering on the new low - dimensional    feature vectors @xmath139 to partition    the vocabulary @xmath133 of @xmath8    mid - level features into @xmath134 clusters . here , each cluster    of mid - level features denotes a new higher level feature .",
    "the above semantic spectral clustering algorithm is denoted as ssc in the following . in particular , this algorithm is called ssc1 ( or ssc2 ) when the weight matrix is defined by equation ( [ eq : swt1 ] ) ( or equation ( [ eq : swt2 ] ) ) .",
    "it should be noted that our ssc algorithm can run very efficiently even on a large dataset when the data size @xmath140 , since it has a time complexity of @xmath141 .",
    "let @xmath142 be the reduced set of high - level features which are learnt from the large vocabulary of mid - level features by our ssc algorithm . according to the spectral clustering results illustrated in figure  [ fig.4 ]",
    ", the relationships between high - level and mid - level features can be represented using a single matrix @xmath143_{k\\times m_v}$ ] , where @xmath144 if mid - level feature @xmath111 occurs in cluster @xmath16 ( i.e. high - level feature @xmath145 ) and @xmath146 otherwise .",
    "the reduced visual bow model @xmath147 defined over @xmath148 can be readily derived from the refined visual bow model @xmath101 defined over @xmath133 as follows : @xmath149 as compared to the original visual bow model @xmath24 , this reduced visual bow model @xmath147 has two distinct advantages : the tags of images have been added to it to bridge the semantic gap , and it has a much smaller vocabulary size .",
    "moreover , the semantic information associated with the high - level features is also explicitly illustrated in figure  [ fig.4 ] .",
    "we find that the semantically related mid - level features are grouped together ( e.g. wheel and window , or head and fur ) by spectral clustering and thus the high - level features tend to be related to the semantics of images ( e.g. vehicle , or animal ) . in the following ,",
    "the reduced visual bow model will be directly applied to image classification .",
    "in this section , the proposed methods for visual bow refinement and reduction are evaluated in image classification .",
    "we first describe the experimental setup , including information of the two benchmark datasets and the implementation details .",
    "moreover , our methods are compared with other closely related methods on the two benchmark datasets .",
    "we select two benchmark datasets for performance evaluation .",
    "the first dataset is pascal voc07 @xcite that contains around 10,000 images .",
    "each image is annotated by users with a set of tags , and the total number of tags used in this paper is reduced to 804 by the same preprocessing step as @xcite .",
    "this dataset is organized into 20 classes .",
    "moreover , the second dataset is mir flickr @xcite that contains 25,000 images annotated with 457 tags .",
    "this dataset is organized into 38 classes .",
    "for the pascal voc07 dataset , we use the standard training / test split , while for the mir flickr dataset we split it into a training set of 12,500 images and a test set of the same size just as @xcite .",
    "it should be noted that image classification on these two benchmark datasets is rather challenging , considering that each image may belong to multiple classes and each class may have large intra - class variations .",
    "some example images from these two datasets are shown in figure  [ fig.5 ] .",
    "for each dataset , we extract the same feature set as @xcite .",
    "that is , we use local sift features @xcite and local hue histograms @xcite , both computed on a dense regular grid and on regions found with a harris interest - point detector .",
    "we quantize the four types of local descriptors using @xmath27-means clustering , and represent each image using four visual word histograms . here , we only consider the four types of local descriptors to make a fair comparison with @xcite , and other low - level visual features can be used similarly . moreover ,",
    "following the idea of @xcite , each visual bow representation is also computed over a @xmath150 horizontal decomposition of the image , and concatenated to form a new representation that encodes some of the spatial layout of the image . finally , by concatenating all the visual bow representations into a single representation , we generate a large visual vocabulary of about 10,000 mid - level features just as @xcite . in our experiments ,",
    "we only adopt @xmath27-means clustering for visual bow generation , regardless of other clustering techniques @xcite .",
    "our main considerations are as follows : ( 1 ) we focus on visual bow refinement and reduction , but not visual bow generation ; ( 2 ) we can make a fair comparison with the state - of - the - art , since @xmath27-means clustering is commonly used in related work ( e.g. @xcite ) .            to evaluate the refined and reduced visual bow models , we apply them directly to image classification using svm with @xmath151 kernel .",
    "since we actually perform multi - label classification on the two benchmark datasets , the classification results are measured by mean average precision ( map ) just the same as @xcite . to show the effectiveness of the refined visual bow model obtained by our graph - based ssl with structured sparse representation ( ssl - ssr ) , we compare it with the original visual and textual bow models . moreover , our ssl - ssr is compared to graph - based ssl with sparse representation ( ssl - sr ) and @xmath27-nn graph - based ssl ( ssl - knn ) . in the experiments ,",
    "the parameters of our ssl - ssr are selected by cross - validation on the training set .",
    "for example , according to figure  [ fig.6 ] , we set the two parameters of our ssl - ssr on the pascal voc07 dataset as : @xmath152 and @xmath153 ( which appear in steps 1 and 3 of our algorithm proposed in section [ sect : refine : alg ] ) .",
    "in fact , our algorithm is shown to be not much sensitive to the choice of these parameters , and we select relatively smaller values for @xmath27 to ensure its efficient running . for fair comparison ,",
    "the same parameter selection strategy is used for other visual bow refinement methods .",
    "finally , our two ssc methods for visual bow reduction are compared with diffusion map ( dm ) @xcite , locally linear embedding ( lle ) , eigenmap , latent dirichlet allocation ( lda ) @xcite , and principal component analysis ( pca ) . here",
    ", ssc , dm , lle , and eigenmap are used for visual bow reduction based on nonlinear manifold learning , while lda actually ignores the manifold structure of mid - level features and pca is only a linear dimension reduction method . for fair comparison , these methods for visual bow reduction are all performed over the refined visual bow model obtained by our refinement method ssl - ssr .      to verify the effectiveness of our refined visual bow model in image classification ,",
    "we show the comparison between different bow models in figure  [ fig.7:a ] .",
    "the immediate observation is that the refined visual bow model by our ssl - ssr algorithm significantly outperforms ( 38% gain for pascal voc07 and 19% gain for mir flickr ) the original visual bow model .",
    "that is , the tags of images have been successfully added to the refined visual bow model and thus the semantic gap associated with the original visual bow model has been bridged effectively .",
    "more notably , our refined visual bow model is even shown to achieve more than 38% gains over the original textual bow model for both of the two benchmark datasets . the significant gains over",
    "both the original visual and textual bow models are due to the fact that our ssl - ssr algorithm can exploit these two types of bow models simultaneously for visual bow refinement . in other words ,",
    "the original visual and textual bow models can complement each other well for image classification .",
    "this is also the reason why we have made much effort to explore them not only in graph - based ssl but also in @xmath0-graph construction .    the comparison between different visual bow refinement methods is further shown in figure  [ fig.7:b ] . in this paper , to effectively explore both visual and textual bow models in graph construction , we have developed a new @xmath0-graph construction method using structured sparse representation ( ssr ) , which is limited to @xmath27-nearest neighborhood so that the @xmath0-graph can be constructed efficiently even on large datasets . from figure  [ fig.7:b ]",
    ", we find that our ssr method can achieve about 10% gains over the other two graph construction methods ( i.e. sr and knn ) .",
    "these impressive gains are due to the fact that the manifold structure of images derived from the original visual bow model can be explored by @xmath0-norm laplacian regularization to suppress the negative effect of noisy tags , while such important structured information is completely ignored by the other two graph construction methods .",
    "0.1 cm    .comparison of our ssl - ssr method with the state - of - the - art on the two benchmark datasets ( lvf : local visual features ; gvf : global visual features ) [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]",
    "we have proposed a new framework for visual bow refinement and reduction to overcome the two drawbacks associated with the visual bow model . to overcome the first drawback , we have developed a graph - based ssl method with structured sparse representation to exploit the tags of images ( easy to access for social images ) for visual bow refinement .",
    "more importantly , for efficient image classification , we have further developed a semantic spectral clustering algorithm to reduce the refined visual bow model to a much smaller size .",
    "the effectiveness of our visual bow refinement and reduction has been verified by the extensive results on the pascal voc07 and mir flickr benchmark datasets . in particular ,",
    "when the global visual features are fused with visual bow models , we can obtain the best results so far ( to the best of our knowledge ) on the two benchmark datasets .",
    "the present work can be further improved in the following ways : ( 1 ) our visual bow refinement and reduction can be readily extended to other challenging applications such as cross - media retrieval and social image parsing ; ( 2 ) the depth information can be similarly used by our algorithms instead of the tags of images , which plays an important role in the imageclef robot vision task ; ( 3 ) our main ideas can be used reversely to refine the textual information using visual content .",
    "this work was supported by national natural science foundation of china under grants 61202231 and 61222307 , national key basic research program ( 973 program ) of china under grant 2014cb340403 , beijing natural science foundation of china under grant 4132037 , ph.d .",
    "programs foundation of ministry of education of china under grant 20120001120130 , the fundamental research funds for the central universities and the research funds of renmin university of china under grant 14xnlf04 , and a grant from microsoft research asia .",
    "m.  everingham , l.  van  gool , c.  williams , j.  winn , a.  zisserman , the pascal visual object classes challenge 2007 ( voc2007 ) results , http://www.pascal-network.org/challenges/voc/voc2007/workshop/index.html .",
    "n.  kruger , p.  janssen , s.  kalkan , m.  lappe , a.  leonardis , j.  piater , a.  j. rodriguez - sanchez , l.  wiskott , deep hierarchies in the primate visual cortex : what can we learn for computer vision ?",
    ", ieee trans .",
    "pattern analysis and machine intelligence 35  ( 8) ( 2013 ) 18471871 .",
    "s.  lafon , a.  lee , diffusion maps and coarse - graining : a unified framework for dimensionality reduction , graph partitioning , and data set parameterization , ieee trans .",
    "pattern analysis and machine intelligence 28  ( 9 ) ( 2006 ) 13931403 .",
    "s.  yan , d.  xu , b.  zhang , h.  zhang , q.  yang , s.  lin , graph embedding and extensions : a general framework for dimensionality reduction , ieee trans .",
    "pattern analysis and machine intelligence 29  ( 1 ) ( 2007 ) 4051 .",
    "d.  donoho , for most large underdetermined systems of linear equations the minimal @xmath155-norm solution is also the sparsest solution , communications on pure and applied mathematics 59  ( 7 ) ( 2004 ) 797829 ."
  ],
  "abstract_text": [
    "<S> this paper presents a new framework for visual bag - of - words ( bow ) refinement and reduction to overcome the drawbacks associated with the visual bow model which has been widely used for image classification . </S>",
    "<S> although very influential in the literature , the traditional visual bow model has two distinct drawbacks . </S>",
    "<S> firstly , for efficiency purposes , the visual vocabulary is commonly constructed by directly clustering the low - level visual feature vectors extracted from local keypoints , without considering the high - level semantics of images . </S>",
    "<S> that is , the visual bow model still suffers from the semantic gap , and thus may lead to significant performance degradation in more challenging tasks ( e.g. social image classification ) . </S>",
    "<S> secondly , typically thousands of visual words are generated to obtain better performance on a relatively large image dataset . </S>",
    "<S> due to such large vocabulary size , the subsequent image classification may take sheer amount of time . to overcome the first drawback </S>",
    "<S> , we develop a graph - based method for visual bow refinement by exploiting the tags ( easy to access although noisy ) of social images . more notably , for efficient image classification , we further reduce the refined visual bow model to a much smaller size through semantic spectral clustering . </S>",
    "<S> extensive experimental results show the promising performance of the proposed framework for visual bow refinement and reduction .    image classification , visual bow refinement , visual bow reduction , graph - based method , semantic spectral clustering </S>"
  ]
}