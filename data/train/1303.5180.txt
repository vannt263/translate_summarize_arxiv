{
  "article_text": [
    "in this note we study the problem concerning the optimality of the aew in the regression model with random design . to formulate the problem , we need to introduce several definitions .",
    "let @xmath7 and @xmath8 be two measure spaces , and set @xmath9 and @xmath10 to be @xmath11 i.i.d . random variables with values in @xmath7 . from a statistical standpoint , @xmath12 is the set of given data at our disposal .",
    "the _ risk _ of a measurable real - valued function @xmath13 defined on @xmath8 is given by @xmath14 where @xmath15 is a non - negative function , called the _",
    "loss function _ and",
    "@xmath16 is the set of all real - valued measurable functions defined on @xmath8 .",
    "if @xmath17 is a statistic constructed using the data @xmath18 , then the risk of @xmath17 is the random variable @xmath19.\\ ] ] throughout this article , we restrict our attention to functions @xmath13 , loss functions @xmath20 , and random variables @xmath9 for which @xmath21 almost surely .",
    "( note that some results have been obtained in the same setup for unbounded loss functions in @xcite , and  @xcite . )",
    "the loss function on which we focus throughout most of the article is the quadratic loss function , defined when @xmath22 by @xmath23 .    in the aggregation framework ,",
    "one is given a finite set @xmath0 of real - valued functions defined on  @xmath8 , usually called a _",
    "dictionary_. the problem of _ aggregation _ ( see , e.g. , @xcite , and  @xcite ) is to construct a procedure , usually called an _ aggregation procedure _ , that produces a function with a risk as close as possible to the risk of the best element in @xmath0 . keeping this in mind",
    ", one can define the _ optimal rate of aggregation _",
    "@xcite , which is the smallest price , as a function of the cardinality of the dictionary @xmath24 and the sample size @xmath25 , that one has to pay to construct a function with a risk as close as possible to that of the best element in the dictionary .",
    "we recall the definition for the `` expectation case ; '' a similar definition for the `` probability case '' can be formulated as well ( see , e.g. ,  @xcite ) .    [ def : definition - optimality ] let @xmath26 .",
    "we say that @xmath27 is an optimal rate of aggregation in expectation when there exist two positive constants , @xmath28 and @xmath5 , depending only on @xmath29 , for which the following holds for any @xmath30 and @xmath31 :    1 .   there exists an aggregation procedure @xmath32 such that for any dictionary @xmath0 of cardinality @xmath24 and any random variable @xmath9 satisfying @xmath21 almost surely for all @xmath33 , one has @xmath34 2 .   for any aggregation procedure @xmath35 , there exists a dictionary @xmath0 of cardinality @xmath24 and a random variable @xmath9 such that @xmath21 almost surely for all @xmath33 and @xmath36    in our setup , one can show ( cf .",
    "@xcite ) that in general , an optimal rate of aggregation ( in the sense of @xcite [ optimality in expectation ] and of  @xcite [ optimality in probability ] ) is lower - bounded by @xmath37 .",
    "thus , procedures satisfying an exact oracle inequality like ( [ eq : exact - oracle - inequality])that is , an oracle inequality with a factor of 1 in front of @xmath38with a residual term of @xmath39 are said to be optimal",
    ". only a few aggregation procedures have been shown to achieve this optimal rate , including the exponential aggregating schemes of @xcite , the the `` empirical star algorithm '' in  @xcite , and the `` preselection / convexification algorithm '' in  @xcite . for a survey on optimal aggregation procedures ,",
    "see the hdr dissertation of j .- y .",
    "audibert .",
    "our main focus here is on the problem of the optimality of the aggregation procedure with exponential weights ( aew ) .",
    "this procedure originate from the thermodynamic standpoint of learning theory ( see  @xcite for the state of the art in this direction ) .",
    "aew can be viewed as a relaxed version of the trivial aggregation scheme , which is to minimize the empirical risk @xmath40 in the dictionary @xmath0 .",
    "a procedure that minimizes ( [ eq : r - n ] ) is called _ empirical risk minimization _ ( erm ) .",
    "it is well known that erm generally can not achieve the optimal rate of @xmath41 , unless one assumes that the given class @xmath0 has certain geometric properties , which we discuss below ( see also @xcite ) . to have any chance of obtaining better rates , one has to consider aggregation procedures that take values in larger sets than @xmath0 .",
    "the most natural set is the convex hull of @xmath0 .",
    "aew is a very popular candidate for the optimal procedure , and it was one of the first procedures to be studied in the context of the aggregation framework @xcite .",
    "it is defined by the following convex sum : @xmath42 for the dictionary @xmath43 .",
    "the parameter @xmath2 is called the _",
    "temperature_. can be seen as a gibbs measure with temperature @xmath44 on the dictionary @xmath0 . ]    thus far , there have been three main results concerning the optimality of the aew .",
    "the first of these is that the progressive mixture rule is optimal in expectation for @xmath44 larger than some parameters of the model ( see  @xcite and @xcite ) , and under certain convexity assumption on the loss function @xmath20 .",
    "this procedure is defined by @xmath45 where @xmath46 is the function generated by aew ( with a common temperature parameter  @xmath44 ) associated with the dictionary @xmath0 and constructed using only the first @xmath47 observations @xmath48 .",
    "( see  @xcite for more details and for other procedures related to the progressive mixture rule . )",
    "second , the optimality in expectation of aew was obtained by @xcite for the regression model @xmath49 with a deterministic design @xmath50 with respect to the risk @xmath51 ( with its empirical version being @xmath52 ) .",
    "that is , it was shown that for @xmath53 , where @xmath54 is the variance of the noise @xmath55 , @xmath56 finally ,  @xcite , and  @xcite proved that in the high - temperature regime , aew can achieve the optimal rate @xmath37 under the bernstein assumption , recalled below in definition  [ def : bernstein ] in expectation and in high probability .",
    "this result is discussedin more detail later .    despite the long history of aew",
    ", the literature contains no results on the optimality ( or suboptimality ) of aew in the regression model with random design in the general case ( when the dictionary does not necessarily satisfy the bernstein condition ) . in this article",
    ", we address this issue and complement the results ( assuming the bernstein condition ) of  @xcite for the low - temperature regime by proving the following :    1 .",
    "aew is suboptimal for low temperatures @xmath4 ( where @xmath5 is an absolute positive constant ) , both in expectation and in probability , for the quadratic loss function and a dictionary of cardinality @xmath57 ( theorem  [ tha ] ) .",
    "aew is suboptimal in probability for some large dictionaries ( of cardinality @xmath58 ) and small temperatures @xmath59 ( theorem  [ thb ] ) .",
    "3 .   aew achieves the optimal rate @xmath37 for low temperatures under the bernstein condition on the dictionary ( theorem [ thc ] ) .",
    "together with the high - temperature results of @xcite and  @xcite , this proves that the temperature parameter has almost no impact ( as long as @xmath60 ) on the performance of the aew under this condition , with a residual term of the order of @xmath61 for every @xmath2 .",
    "[ tha]there exist absolute constants @xmath62 for which the following holds . for any integer @xmath63",
    ", there are random variables @xmath64 and a dictionary @xmath65 such that @xmath66 almost surely for @xmath67 , for which the quadratic risk of the aew satisfies the following :    1",
    ".   if @xmath4 and @xmath25 is odd , then @xmath68 2 .",
    "if @xmath69 , then , with probability greater than @xmath70 , @xmath71    theorem  [ tha ] proves that aew is suboptimal in expectation in the low - temperature regime and suboptimal in probability in both the low- and high - temperature regimes , since it is possible to construct procedures that achieve the rate @xmath72 with high probability @xcite and in expectation @xcite in the same setup as for theorem  [ tha ] . it should be noted that the problem of the optimality in probability of the progressive mixture rule ( and other related procedures ) was studied by  @xcite , who proved that , for a loss function @xmath20 satisfying some convexity and regularity assumption ( e.g. , the quadratic loss used in theorem  [ tha ] ) , the progressive mixture rule @xmath73 defined in ( [ eq : progressive - mixture ] ) satisfies that for any temperature parameter , with probability greater than an absolute constant @xmath74 , @xmath75    in addition , it is important to observe that the suboptimality in probability does not imply suboptimality in expectation for the aggregation problem , or vice versa .",
    "this property of the aggregation problem was first noted by  @xcite , who found the progressive mixture rule ( and other related aggregation procedures ) to be suboptimal in probability for dictionaries of cardinality two but , on the other hand , to be optimal in expectation ( @xcite and @xcite ) .",
    "this peculiar property of the problem of aggregation comes from the fact that an aggregate @xmath17 is not restricted to the set @xmath0 , which allows @xmath76 to take negative values .",
    "@xcite showed that for the progressive mixture rule @xmath73 , these negative values do compensate on average for larger values , but there is still an event of constant probability on which @xmath77 takes values greater than @xmath78 .",
    "the proof of theorem  [ tha ] shows that a dictionary consisting of two functions is sufficient to yield a lower bound in expectation in the low - temperature regime and in probability in both the small temperature regime , @xmath79 , and the large temperature regime , @xmath80 . in the following theorem",
    ", we study the behavior of aew for larger dictionaries . to the best of our knowledge ,",
    "negative results on the behavior of exponential weights based aggregation procedures are not known for dictionaries with more than two functions , and we show that the behavior of the aew deteriorates in some sense as the cardinality of the dictionary increases .",
    "[ thb ] there exist an integer @xmath81 and absolute constants @xmath5 and @xmath82 for which the following holds . for every @xmath83 , there are random variables @xmath64 and a dictionary @xmath43 of cardinality , @xmath84 , for which the quadratic loss function of any element in @xmath0 is bounded by @xmath57 almost surely , and for every @xmath85 , if @xmath86 , then with probability at least @xmath87 , @xmath88 moreover , if @xmath89 denotes the optimal function in @xmath0 with respect to the quadratic loss ( the oracle ) , then there exists @xmath90 with an excess risk greater than @xmath91 and for which the weight of @xmath92 in the aew procedure satisfies @xmath93    theorem  [ thb ] implies that the aew procedure might cause the weights to concentrate around a `` bad '' element in the dictionary ( i.e. , an element whose risk is larger than the best in the class by at least @xmath94 ) with high probability .",
    "in particular , theorem  [ thb ] provides additional evidence that the aew procedure is suboptimal for low temperatures .",
    "the analysis of the behavior of aew for a dictionary of cardinality larger than two is considerably harder than in the two - function case and requires some results on rearrangement of independent random variables that are almost gaussian ( see proposition  [ prop : shahar - proposition ] below ) .",
    "fortunately , not all is lost as far as optimality results for aew go .",
    "indeed , we show that under some geometric condition , aew can be optimal and in fact can even adapt to the `` real complexity '' of the dictionary .",
    "intuitively , a good aggregation scheme should be able to ignore the elements in the dictionary whose risk is far from the optimal risk in @xmath0 , or at least the impact of such elements on the function produced by the aggregation procedure should be small .",
    "thus , a good procedure is one with a residual term of the order of @xmath95 , where @xmath96 is a complexity measure that is determined only by the richness of the set of `` almost minimizers '' in the dictionary .",
    "this leads to the following question :    [ qu : adaptivitytocomplexityofdictionary ] is it possible to construct an aggregation procedure that adapts to the real complexity of the dictionary ?",
    "this question was first addressed by the pac - bayesian approach .",
    "@xcite and  @xcite showed that in the high - temperature regime , aew satisfies the requirements of question  [ qu : adaptivitytocomplexityofdictionary ] , assuming that the class has a geometric property , called the bernstein condition .",
    "[ def : bernstein ] we say that a function class @xmath0 is a @xmath97-bernstein class ( @xmath98 and @xmath99 ) with respect to @xmath9 if every @xmath100 satisfies @xmath101 and @xmath102    there are many natural situations in which the bernstein condition is satisfied . for instance , when @xmath20 is the quadratic loss function and the regression function is assumed to belong to @xmath0 , the excess loss function class @xmath103 satisfies the bernstein condition with @xmath104 , where @xmath105 is the minimizer of the risk in the class  @xmath0 .",
    "another generic example is when the target function @xmath106 is far from the set of targets with `` multiple minimizers '' in @xmath0 and @xmath107 satisfies the bernstein condition with @xmath104 .",
    "( see @xcite for an exact formulation of this statement and related results . )",
    "the bernstein condition is very natural in the context of erm because it has two consequences : that the empirical excess risk has better concentration properties around the excess risk , and that the complexity of the subset of @xmath0 consisting of almost minimizers is smaller under this assumption .",
    "consequently , if the class @xmath107 is a @xmath97-bernstein class for @xmath108 , then the erm algorithm can achieve fast rates ( see , e.g. ,  @xcite and references therein ) .",
    "as the results below show , the same is true for aew .",
    "indeed , under a bernstein assumption , @xcite and  @xcite proved that if @xmath109 is a convex risk function and if @xmath0 is such that @xmath110 almost surely for any @xmath33 , then for every @xmath111 and @xmath112 , with probability greater than @xmath113 , @xmath114    although the pac - bayesian approach can not be used to obtain ( [ eq : pac - bound ] ) in the low - temperature regime ( @xmath115 ) , such a result is not surprising . indeed , because fast error rates for the erm are expected when the underlying excess loss functions class satisfies the bernstein condition , and because aew converges to the erm when the temperature @xmath44 tends to 0 , it is likely that for `` small values '' of @xmath44 , aew inherits some of the properties of erm , such as fast rates under a bernstein condition .",
    "we show this in theorem  [ thc ] , proving that aew answers question  [ qu : adaptivitytocomplexityofdictionary ] for low temperatures under the bernstein condition .    before formulating theorem  [ thc ]",
    ", we introduce the following measure of complexity . for every @xmath116 ,",
    "let @xmath117 where @xmath118 denotes the cardinality of the set @xmath119 .",
    "observe that @xmath120 is a weighted sum of the number of elements in @xmath0 that assigns smaller and smaller weights to functions with a relatively large excess risk .",
    "[ thc ] there exist absolute constants @xmath28 , @xmath121 , and @xmath122 for which the following holds .",
    "let  @xmath0 be a class of functions bounded by @xmath29 such that the excess loss class @xmath107 is a @xmath123-bernstein class with respect to @xmath9 . if the risk function @xmath109 is convex and if @xmath124 , then for every @xmath125 , with probability at least @xmath113 , the function @xmath126 produced by the aew algorithm satisfies @xmath127 where @xmath128 .",
    "in particular , @xmath129    in other words , the scaling factor @xmath130 that we use is proportional to @xmath131 , and if the class is regular ( in the sense that the complexity of @xmath0 is well spread and not concentrated just around one point ) , then @xmath132 is roughly the cardinality of the elements in @xmath0 with risk at most latexmath:[$\\sim\\!(b+b)(\\log     observe that for every @xmath116 , @xmath134 for a suitable absolute constant @xmath135 .",
    "thus , if @xmath44 is reasonably small ( below a level proportional to @xmath136 ) , then the resulting aggregation rate is the optimal one , proportional to @xmath137 with probability @xmath113 , and proportional to @xmath138 in expectation .",
    "thus , theorem  [ thc ] indeed gives a positive answer to question [ qu : adaptivitytocomplexityofdictionary ] in the presence of a bernstein condition and for low temperatures .",
    "although the residual terms in theorem  [ thc ] and in ( [ eq : pac - bound ] ) are not the same , they are comparable . indeed , the contribution of each element in @xmath0 in the residual term depends exponentially on its excess risk .",
    "theorem  [ thc ] together with the results for high temperatures from @xcite and  @xcite show that the aew is an optimal aggregation procedure under the bernstein condition as long as @xmath60 when @xmath24 and @xmath25 tend to infinity .",
    "in general , the residual term obtained is on the order of @xmath139 , and it can be proven that the optimal rate of aggregation under the bernstein condition is proportional to @xmath37 using the classical tools in  @xcite .    finally , a word about the organization of the article . in the next section we present some comments about our results .",
    "the proofs of the three theorems follow in the subsequent sections . throughout",
    ", we denote absolute constants or constants that depend on other parameters by @xmath5 , @xmath82 , etc .",
    "( of course , we specify when a constant is absolute and when it depends on other parameters . )",
    "the values of constants may change from line to line .",
    "we write @xmath140 if there are absolute constants @xmath135 and @xmath141 such that @xmath142 , and write @xmath143 if @xmath144 .",
    "although from a theoretical standpoint , whether aew is an optimal procedure in expectation and for high temperatures in the regression model with random design remains to be seen , from a practical standpoint , we believe that exponential aggregating schemes simply should not be used in the setup of this article , because of the following reasons ( see also the comments in  @xcite ) :    1 .   for any temperature @xmath145 , there is an event of constant probability on which aew performs poorly ( this is the second part of theorem  [ tha ] ) .",
    "2 .   if the temperature parameter is chosen to be too small , then the aew can perform poorly even in expectation ( the first part of theorem  [ tha ] ) .",
    "another consequence of the lower bounds stated in theorem  [ tha ] is that aew can not be an optimal aggregation procedure both in expectation and in probability at low temperatures for two other aggregation problems : the problem of _ convex aggregation _ , in which one wants to mimic the best element in the convex hull of @xmath0 , and the problem of _ linear aggregation _ , where one wishes to mimic the best linear combination of elements in @xmath0 . indeed , clearly @xmath146 moreover , the optimal rates of aggregation for the convex and linear aggregation problems for dictionaries of cardinality two are of the order of @xmath147 ( see  @xcite ) , whereas the residual terms obtained in theorem  [ tha ] are on the order of @xmath148 for such a dictionary .",
    "thus aew is suboptimal for these two other aggregation problems in the low - temperature regime .",
    "we end this section by comparing two seemingly related assumptions , the margin assumption of  @xcite and the bernstein condition of  @xcite .",
    "note that in the proof of theorem  [ thc ] , we have restricted ourselves to the case @xmath104 simply to make the presentation as simple as possible .",
    "a  very similar result , with the residual term @xmath149 for the exact oracle inequality in probability and @xmath150 for the exact oracle inequality in expectation , holds if one assumes a bernstein condition for any @xmath151 , and the proof is identical to that in the case where @xmath104 .",
    "this makes the discussion about @xmath152-bernstein classes relevant here .",
    "recall the definition of the margin assumption :    we say that @xmath0 has margin with parameters @xmath97 ( @xmath98 and @xmath99 ) if for every @xmath153 , @xmath154 where @xmath155 is defined such that @xmath156 , and the minimum is taken with respect to all measurable functions @xmath13 on the given probability space .",
    "although the margin condition appears similar to the bernstein condition , they are in fact very different , and have been introduced in the context of different types of problems . in the first of these , the `` classical '' statistical setup , one is given a function class @xmath0 ( the _ model _ ) with an upper bound on its complexity and an unknown target function @xmath155 , the minimizer of the risk over _ all _ measurable functions .",
    "one usually assumes that @xmath155 belongs to @xmath0 , and the aim is to construct an estimator @xmath157 for which the risk @xmath158 tends to 0 quickly as the sample size tends to infinity . in this setup , the margin assumption can improve this rate of convergence because of a better concentration of empirical means of @xmath159 around its mean  @xcite . the margin assumption ( ma ) for @xmath104",
    "compares the performance of each @xmath153 with the _ best possible measurable function _ , but it has nothing to do with the geometric structure of @xmath0 .",
    "the margin is determined for every @xmath13 separately , because @xmath155 does not depend on the choice of @xmath0 .    in the second type of problem , the `` learning theory '' setup",
    ", one does not assume that the target function @xmath155 belongs to @xmath0 .",
    "the aim is to construct a function @xmath17 with a risk as close as possible to that of the best element @xmath160 . assuming that the excess loss class @xmath107 satisfies the bernstein condition ( bc ) , the error rate can be improved ( see , e.g. ,  @xcite ) .    at a first glance ,",
    "ma and bc ( for @xmath104 ) share very strong similarities . indeed , saying that @xmath107 is a @xmath123-bernstein class means that for every @xmath33 , @xmath161 but nevertheless they are different . indeed , as mentioned earlier , ma is only a matter of concentration ( and classical statistics questions are mostly a question of the trade - off between concentration and complexity ) .",
    "on the other hand , bc involves a lot of geometry of the function class @xmath0 , because @xmath162 might change significantly by adding a single function to @xmath0 or by removing a function .",
    "in fact , the difficulty of learning theory problems is determined by the trade - off between concentration and complexity , _ and _ the geometry of the given class , since one measures the performance of the learning algorithm relative to the best _ in the class_. assuming that @xmath163 , as is usually done in classical statistics , exempts one from the need to consider the geometry of  @xmath0 , but one does not have that freedom in the aggregation framework .",
    "indeed , since in the aew algorithm the estimator is determined by the empirical means @xmath164 , this is a learning problem rather than a problem in classical statistics , despite the fact that it has been used in statistical frameworks to construct adaptive estimators ( see , e.g. ,  @xcite ) .",
    "therefore , given their nature , aggregation procedures like the aew are more natural under a bc assumption than under the ma .",
    "( a by - product of theorem  [ tha ] is that the ma can not improve the performance of aew since in the setup of theorem  [ tha ] , it is easy to check that ma is satisfied with the best possible margin parameter @xmath104 . )",
    "our starting point is the berry  essen theorem on gaussian approximation .",
    "let @xmath165 be a sequence of i.i.d .",
    ", mean-0 random variables with variance @xmath166 , set @xmath167 to be a standard gaussian variable , and write @xmath168    [ theo : berry - esseen]there exists an absolute constant @xmath169 such that for every integer  @xmath25 , @xmath170-{\\mathbb{p}}[g\\leq x]|\\leq\\frac{a{\\mathbb{e}}|w_1|^3}{\\sqrt{n}}.\\ ] ]    from here on , we let @xmath119 denote the constant appearing in theorem [ theo : berry - esseen ] .",
    "when the tail behavior of the @xmath171 has a subexponential decay , the gaussian approximation can be improved . indeed ,",
    "recall that a real - valued random variable @xmath172 belongs to @xmath173 for some @xmath174 if there exists @xmath175 such that @xmath176 the infimum over all constants @xmath135 for which ( [ eq : psi - alpha ] ) holds defines an orlicz norm , which is called the @xmath177 norm and is denoted by @xmath178 .",
    "( for more information on orlicz norms , see , e.g. ,  @xcite and  @xcite . )",
    "[ prop : petrov ] for every @xmath179 , there exist constants @xmath180 , and @xmath82 that depend only on @xmath181 for which the following holds . if @xmath182 , then for any @xmath183 , such that @xmath184 , @xmath185={\\mathbb{p}}[g\\geq x]\\exp\\biggl(\\frac{x^3 { \\mathbb{e}}w^3 } { 6\\sqrt { n}}\\biggr)\\biggl[1+\\mathrm{o}\\biggl(\\frac{x+1}{\\sqrt{n}}\\biggr)\\biggr]\\ ] ] and @xmath186={\\mathbb{p}}[g\\leq - x]\\exp\\biggl(-\\frac{x^3{\\mathbb{e}}w^3 } { 6\\sqrt { n}}\\biggr)\\biggl[1+\\mathrm{o}\\biggl(\\frac{x+1}{\\sqrt{n}}\\biggr)\\biggr],\\ ] ] where by @xmath187 we mean that @xmath188 .    in particular , if @xmath189 and @xmath190 , then @xmath191-{\\mathbb{p}}[g\\leq x]| \\leq c_2\\bigl(n^{-1/2}\\exp(-x^2/2)\\bigr).\\ ] ]    from here on , we let @xmath192 denote the constant appearing in proposition  [ prop : petrov ] .",
    "before presenting the proof of theorem  [ tha ] , we introduce the following notation . given a probability measure @xmath193 and @xmath194 selected independently according to @xmath193 , we set @xmath195 the empirical measure supported on @xmath194 .",
    "we let @xmath196 denote the expectation @xmath197 .",
    "we assume that @xmath198 and recall that @xmath25 is an odd integer .",
    "let @xmath199 and define @xmath200 by @xmath201=1/2-n^{-1/2}$ ] and @xmath202=1/2+n^{-1/2}$ ] .",
    "let @xmath203}$ ] and @xmath204}$ ] , and consider the dictionary @xmath65 .",
    "it is easy to verify that the best function in @xmath0 ( the oracle ) with respect to the quadratic risk is @xmath205 , and that the excess loss function of @xmath206 , @xmath207 , satisfies that @xmath208 to simplify notation , set @xmath209 and @xmath210 .",
    "an important parameter that lies at the heart of this counterexample is the bernstein constant ( which is very bad in this case ) , @xmath211 straightforward computation shows that aew on @xmath0 with temperature @xmath44 is given by @xmath212 and that for @xmath213 defined for all @xmath214 $ ] , @xmath215&=&{\\mathbb{e}}[1-{\\widehat}\\theta _ 1-\\alpha{\\widehat}\\theta_1(1-{\\widehat}\\theta_1)]p{\\mathcal { l}}_2={\\mathbb{e}}[1-h({\\widehat}\\theta _ 1)]p{\\mathcal { l}}_2 \\nonumber\\\\ & = & \\biggl[1-\\int_0^\\infty h^\\prime(t){\\mathbb{p}}[{\\widehat}\\theta_1\\geq t]\\ , \\mathrm{d}t\\biggr]p{\\mathcal { l}}_2 \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & = & \\biggl[1+\\int_0 ^ 1\\bigl(2\\alpha t-(1+\\alpha)\\bigr){\\mathbb{p}}[{\\widehat}\\theta _ 1\\geq t]\\,\\mathrm{d}t\\biggr]p{\\mathcal { l}}_2 \\\\ & = & \\biggl[1+\\int_0 ^ 1\\bigl(2\\alpha t-(1+\\alpha)\\bigr){\\mathbb{p } } [ p_n{\\mathcal { l}}_2\\geq\\gamma(t ) ] \\ , \\mathrm{d}t\\biggr]p{\\mathcal { l}}_2,\\nonumber\\end{aligned}\\ ] ] where @xmath216 is an increasing function defined for any @xmath217 by @xmath218 in particular , @xmath219=[i_1+i_2]p{\\mathcal { l}}_2\\ ] ] for @xmath220\\,\\mathrm{d}t+1\\ ] ] and @xmath221\\,\\mathrm{d}t.\\ ] ]    first , we bound @xmath222 from below . to that end",
    ", we note the following facts . first , for every @xmath223 , @xmath224 and @xmath225 second , if we set @xmath226 , then for @xmath227 , @xmath228 .",
    "in particular , this holds under our assumption that @xmath229 .",
    "moreover , because @xmath230 is increasing , for @xmath231 , @xmath232 .",
    "therefore , @xmath233\\,\\mathrm{d}t+1 \\\\ & = & \\int_0^{\\alpha^{-1}}\\bigl(2\\alpha t-(1+\\alpha)\\bigr)\\bigl({\\mathbb{p}}[p_n{\\mathcal { l}}_2\\geq \\gamma ( t)]-1\\bigr)\\,\\mathrm{d}t \\\\ & \\geq&\\int_{(1+e)^{-1}}^{\\alpha^{-1}}(1+\\alpha-2\\alpha t){\\mathbb{p}}[p_n{\\mathcal { l}}_2<\\gamma(t)]\\,\\mathrm{d}t \\\\ & \\geq&\\int_{(1+e)^{-1}}^{\\alpha^{-1}}(1+\\alpha-2\\alpha t)\\,\\mathrm{d}t \\cdot{\\mathbb{p}}\\bigl[\\bigl(\\sqrt{n}/\\sigma\\bigr)(p_n{\\mathcal { l}}_2-p{\\mathcal { l}}_2)<\\bigl(\\sqrt{n}/\\sigma \\bigr)(-2p{\\mathcal { l}}_2)\\bigr ] \\\\ & \\geq&\\int_{(1+e)^{-1}}^{\\alpha^{-1}}(1+\\alpha-2\\alpha t)\\,\\mathrm { d}t\\bigl({\\mathbb{p}}[g\\leq-8]-a/\\sqrt{n}\\bigr)\\geq c_0>0,\\end{aligned}\\ ] ] where in the last step we used the berry  essen theorem , with @xmath234 and @xmath235)^2 $ ] , implying that @xmath236 .",
    "we turn to a lower bound for @xmath237 . applying a change of variables @xmath238 in the second term of @xmath237 ,",
    "it is evident that @xmath239\\,\\mathrm{d}t \\\\ & & { } + \\int_{({\\alpha+1})/({2\\alpha})}^1\\bigl(2\\alpha t-(1+\\alpha)\\bigr){\\mathbb{p}}[p_n{\\mathcal { l}}_2\\geq \\gamma(t)]\\,\\mathrm{d}t \\\\ & = & \\int_{\\alpha^{-1}}^{({\\alpha+1})/({2\\alpha})}\\bigl(2\\alpha t-(1+\\alpha ) \\bigr){\\mathbb{p}}[\\gamma(t)\\leq p_n{\\mathcal { l}}_2<\\gamma(1+\\alpha^{-1}-t)]\\,\\mathrm{d}t = i_3+i_4\\end{aligned}\\ ] ] for @xmath240\\,\\mathrm{d}t\\ ] ] and @xmath241\\ , \\mathrm{d}t.\\ ] ] to estimate @xmath242 , note that @xmath243 for @xmath244 $ ] , and thus @xmath245 for our choice of @xmath246 .",
    "the final step of the proof is to bound @xmath247 and in particular to show that for small values of @xmath44 , @xmath248 .    for any @xmath249 ,",
    "consider the intervals @xmath250 , and set @xmath251 , which is the number of integers in @xmath252 . because @xmath253 , @xmath254 = { \\mathbb{p}}\\biggl[\\sum_{i=1}^n - x_i\\in i_t(t)\\biggr]={\\mathbb{p}}_t(t).\\ ] ] recall that @xmath255 , and thus @xmath256={\\mathbb{p}}[\\sum_{i}-x_i\\in i_t(t ) \\cap{\\mathbb{z}}]$ ] . because @xmath257 is increasing and non - negative for @xmath258 , then if @xmath259 , it follows that @xmath260 , provided that @xmath198 .",
    "thus , for such values of @xmath261 , @xmath262 , implying that @xmath263 . on the other hand , if @xmath264 , then @xmath265 . in particular ,",
    "if @xmath266 , then @xmath267 , and since @xmath25 is odd , then @xmath268=0 $ ] . otherwise , @xmath269 , which implies that @xmath270 , where @xmath271 is the length of @xmath252 , given by @xmath272 therefore , for every @xmath261 in our range , @xmath273\\leq 2\\delta_t(t)\\max_{k\\in{\\mathbb{z}}}{\\mathbb{p}}\\biggl[\\sum_{i=1}^nx_i = k\\biggr].\\ ] ] since @xmath274 for every @xmath275 , it is evident that @xmath276 \\cdot\\int _ { ( 1+c_0/4)\\alpha^{-1}}^{({\\alpha+1})/({2\\alpha } ) } \\bigl(2\\alpha t-(1+\\alpha)\\bigr)\\log\\biggl(\\frac{(1-t)(\\alpha+1-\\alpha t)}{t(\\alpha t-1)}\\biggr ) \\,\\mathrm{d}t.\\ ] ] it can be shown that @xmath277 $ ] is on the order of @xmath148 either by a direct computation or by the berry  essen theorem . moreover , for any @xmath278 , one has @xmath279 , and thus , @xmath280 therefore , combining the two observations with a change of variables @xmath281 for @xmath282 , it is evident that there are absolute constants @xmath121 for which @xmath283 thus , there is an absolute constant @xmath122 such that if @xmath284 , then @xmath285 , implying that @xmath219\\geq\\frac{c_0}{3\\sqrt{n}},\\ ] ] and proving the first part of theorem  [ tha ] .    to prove the second part of the theorem , note that by the berry  ess ' een theorem , for every @xmath286 , with probability greater than @xmath287 - 2a/\\sqrt{n}$ ] , @xmath288 thus , if @xmath25 is large enough to ensure that @xmath289 - 2a/\\sqrt{n}\\geq{\\mathbb{p}}[g\\leq-4]/2=c_4 $ ] , and taking @xmath290 , then with probability at least @xmath70 , @xmath291 . in that case ,",
    "@xmath292 , which yields that @xmath293 provided that @xmath294 .",
    "the first step in the proof of theorem  [ thb ] involves a general statement regarding a monotone rearrangement of independent random variables that are close to being gaussian .",
    "let @xmath172 be a mean  0 , variance 1 random variable that is absolutely continuous with respect to the lebesgue measure .",
    "further assume that @xmath295 has a finite third moment ( in fact , the random variables in which we are interested are bounded ) and set @xmath296 , where @xmath119 is the constant appearing in the berry  essen theorem ( theorem  [ theo : berry - esseen ] ) .",
    "let @xmath297 be independent random variables distributed as @xmath172 and set @xmath298 .",
    "let @xmath299 be @xmath300 independent copies of @xmath301 , and put @xmath302 to satisfy that @xmath303=1-\\frac{1}{n}.\\ ] ] note that such a @xmath304 exists because @xmath172 has a density with respect to the lebesgue measure .    throughout the proof of theorem  [ thb ]",
    ", we require the following simple estimates on @xmath304 .",
    "[ lemma : gamma-1 ] there exist absolute constants @xmath305 for which the following hold :    1 .   if @xmath306 , then @xmath307 \\leq1-c_1\\frac { \\log n}{\\ell}.\\ ] ] 2 .   if @xmath300 and @xmath25 are such that @xmath308 $ ] , then @xmath309 .",
    "3 .   if @xmath309 and @xmath310 , then @xmath311    before we present the proof of lemma  [ lemma : gamma-1 ] , recall that for every @xmath312 , @xmath313\\leq\\frac{1}{\\sqrt{2\\uppi}}\\frac{\\exp(-x^2/2)}{x}.\\ ] ]    proof of lemma [ lemma : gamma-1 ] to prove the first part , note that by independence and because @xmath314 , @xmath315={\\mathbb{p}}\\bigl[\\min_{1 \\leq j \\leq\\ell}\\bar x_j>\\gamma_1\\bigr]^{{1}/{\\ell}}=\\biggl(\\frac{1}{n}\\biggr)^{1/\\ell } \\geq1-\\frac{\\log n}{\\ell}.\\ ] ] the reverse inequality follows in an identical fashion , because @xmath316 if @xmath317 .    turning to the second part , if @xmath318 , then @xmath319 \\geq{\\mathbb{p}}\\bigl[\\min_{1 \\leq j \\leq\\ell } \\bar x_j \\leq-2\\bigr ] = 1-({\\mathbb{p}}[\\bar x > -2])^\\ell,\\ ] ] implying that @xmath320 \\leq(\\log n)/\\ell$ ] . on the other hand , by the berry  essen theorem , @xmath320 \\geq { \\mathbb{p}}[g \\leq-2 ] - \\beta(w)/\\sqrt{n}$ ] , which is impossible under the assumptions of ( 2 ) .    finally , to prove ( 3 ) , we use the berry  essen theorem combined with the lower and upper estimates on the gaussian tail ( [ eq : gaussian - tail - estimate ] ) and ( [ eq : def - gamma1 - 2 ] ) .",
    "thus , @xmath321\\leq{\\mathbb{p}}[\\bar x<\\gamma_1]+\\frac{\\beta(w)}{\\sqrt{n}}\\leq \\frac{\\beta(w)}{\\sqrt{n}}+c_1\\frac{\\log n}{\\ell},\\ ] ] and @xmath322 from which both parts of the third claim follow .    [ prop : shahar - proposition ] there exist constants @xmath323 , and @xmath70 that depend only on @xmath324 for which the following holds .",
    "let @xmath325 , and assume that @xmath190 and that @xmath326 .",
    "then @xmath327 \\\\ & & \\quad \\geq 1-\\frac{1}{n}-c_2\\biggl(\\frac{1}{\\sqrt{n}}+\\delta\\biggr)(\\log n)^2\\sqrt{\\log m},\\end{aligned}\\ ] ] provided that @xmath328 .",
    "for every @xmath329 , let @xmath330 the events @xmath331 for @xmath329 are disjoint , and thus @xmath332\\\\ & & \\quad={\\mathbb{p}}\\biggl[\\bigcup_{j=2}^m\\omega_j\\biggr]=(m-1){\\mathbb{p}}[\\omega_2].\\end{aligned}\\ ] ] since the variables @xmath333 are independent , we have @xmath334=\\int_{-\\infty}^{\\gamma_1}f_{\\bar x}(z)\\biggl(\\int_{z+\\delta}^\\infty f_{\\bar x}(t)\\,\\mathrm{d}\\mu(t)\\biggr)^{m-2}\\,\\mathrm{d}\\mu(z),\\ ] ] where @xmath335 is a density function of @xmath301 with respect to the lebesgue measure @xmath336 .",
    "on the other hand , for any @xmath337 , @xmath338>0 $ ] because of ( [ eq : def - gamma1 - 2 ] ) .",
    "thus , for every @xmath337 , @xmath339 note that for every @xmath317 , @xmath340 , and applied to ( [ eq : proba - omega2 - 2 ] ) , @xmath341&\\geq&\\int_{-\\infty}^{\\gamma_1}f_{\\bar x}(z)\\biggl(\\int _",
    "z^\\infty f_{\\bar x}(t)\\,\\mathrm{d}\\mu(t)\\biggr)^{m-2}\\,\\mathrm{d}\\mu(z ) \\\\[-2pt ] & & { } -(m-2)\\int_{-\\infty}^{\\gamma_1 } f_{\\bar x}(z)\\biggl(\\int_{z}^{\\infty } f_{\\bar x}(t)\\,\\mathrm{d}\\mu(t)\\biggr)^{m-3 } \\biggl(\\int_{z}^{z+\\delta}f_{\\bar x}(t)\\,\\mathrm{d}\\mu(t)\\biggr)\\,\\mathrm { d}\\mu(z ) \\\\[-2pt ] & \\geq & { \\mathbb{p}}[\\bar x_2\\leq\\gamma_1 \\mbox { and } \\bar x_k\\geq\\bar x_2 , \\mbox{for every } k \\geq3]-t_2 \\\\[-2pt ] & = & \\frac{1}{m-1}{\\mathbb{p}}\\bigl[\\min_{2\\leq j\\leq m}\\bar x_j\\leq\\gamma_1\\bigr]-t_2,\\end{aligned}\\ ] ] where @xmath342 recall the if @xmath343 are independent mean-0 random variables and @xmath344 are real numbers , then @xmath345 , where @xmath135 is an absolute constant @xcite .",
    "thus , @xmath346 , and for any @xmath347 , @xmath348\\leq2\\exp(-t^2/c^2\\|{w}\\|^2_{\\psi_2}).\\ ] ] let @xmath349 be such that @xmath350 thus , @xmath351 note that if @xmath352 , then our claim follows .",
    "indeed , because @xmath353 = 1-n^{-1}$ ] , we have @xmath334 \\geq\\frac{1}{m-1}\\biggl(1-\\frac{1}{n}\\biggr ) - \\delta\\frac { \\sqrt { \\log(m-1)}}{m-1}.\\ ] ] otherwise , we split the interval @xmath354=(-\\infty , t_0)\\cup [ t_0,\\gamma_1]$ ] , and to upper bound @xmath355 , it remains to control the integral on the second interval @xmath356 $ ] .",
    "recall that @xmath357 and that @xmath190 .",
    "therefore , by proposition  [ prop : petrov ] , it is evident that if @xmath358 and @xmath359 satisfy that @xmath360 and @xmath361 , then @xmath362 \\nonumber \\\\[-9pt ] \\\\[-9pt ] \\nonumber & \\leq&{\\mathbb{p}}[z\\leq g\\leq z+\\delta]+\\frac{b_1}{\\sqrt{n}}\\exp(-z^2/2),\\end{aligned}\\ ] ] where @xmath192 and @xmath363 are constants that depend only on @xmath364 .",
    "in addition , for every @xmath365 , @xmath366\\leq\\frac{1}{\\sqrt{2\\uppi}}\\exp(-z^2/2 ) \\int_0^\\delta\\exp(-zt)\\,\\mathrm{d}t\\leq\\frac{\\delta}{\\sqrt { 2\\uppi}}\\exp(-z^2/2).\\ ] ]    if @xmath367 , then @xmath368 . combining ( [ eq : delta - part ] ) and ( [ eq : upper - bound - gaussian1 ] ) with the definition of @xmath355 , we have @xmath369 \\\\ & & \\quad\\leq ( m-2)\\biggl(\\frac{b_1}{\\sqrt{n}}+\\frac{\\delta}{\\sqrt{2\\uppi}}\\biggr ) \\exp(-\\gamma_1 ^ 2/2)\\frac{\\log n}{m-1},\\end{aligned}\\ ] ] where the last inequality follows from ( [ eq : def - gamma1 - 2 ] ) . by lemma  [ lemma : gamma-1 ] , and since @xmath370 , @xmath371 for some constant @xmath372 , from which our claim follows .",
    "we next describe the construction needed for the proof of theorem  [ thb ] .",
    "let @xmath64 and @xmath43 be defined by @xmath373 where @xmath374 are @xmath24 independent random variables with density @xmath375}(u)$ ] for @xmath376 to be fixed later .",
    "note that for this choice of density function , @xmath377 is uniformly distributed on @xmath378 $ ] , and the best element in @xmath0 with respect to the quadratic risk is @xmath205 .",
    "let @xmath379 be a family of independent random variables distributed as @xmath380 .",
    "thus , for every @xmath381 , @xmath382 for every @xmath383 and @xmath384 . for every @xmath385 , set @xmath386 and observe that if @xmath387 , then @xmath172 is a mean 0 , variance @xmath166 random variable that is absolutely continuous with respect to the lebesgue measure and @xmath388 and satisfies that @xmath190 .",
    "these properties allow us to apply proposition  [ prop : shahar - proposition ] to the random variables @xmath389 .",
    "let @xmath390 ( to be named later ) , and set @xmath391-\\sqrt{12}\\lambda(2-\\lambda)\\sqrt{n},\\ ] ] and @xmath392.\\ ] ] consider the system of inequalities    @xmath393    and recall that for each @xmath394 @xmath395 denotes the weight of @xmath92 in the aew procedure .",
    "[ prop : large - weights ] there exist absolute constants @xmath5 and @xmath82 for which the following holds .",
    "let @xmath396 and @xmath329 . if the system ( [ eq : system - cj ] ) is satisfied , then @xmath397 moreover , if @xmath398 , then the quadratic risk of the function produced by the aew procedure satisfies @xmath399    let @xmath329 , and assume that ( [ eq : system - cj ] ) is satisfied . recall that @xmath400 is the empirical risk of @xmath13 , and note that for any @xmath401 ,    @xmath402 = \\frac{\\bar r_k-\\bar r_j}{\\sqrt{n } } \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & \\geq&\\frac{\\delta}{\\sqrt{n } } = \\frac{-t}{n}\\log\\biggl[\\frac{\\rho}{2(m-2)(1-\\rho)}\\biggr].\\end{aligned}\\ ] ] in addition , since @xmath403 almost surely for any @xmath404 , @xmath405 \\nonumber\\\\ & = & \\frac{\\bar r_1-\\bar r_j}{\\sqrt{n}}-\\sqrt{12}\\biggl(\\lambda^2+\\frac { 2\\lambda } { n}\\sum_{i=1}^n{\\mathcal { u}}_1^{(i)}\\biggr ) \\\\ & \\geq&\\frac{\\bar r_1-\\xi(\\bar r_1)}{\\sqrt{n}}-\\sqrt{12}\\lambda(2-\\lambda)\\geq \\frac{-t}{n}\\log\\biggl[\\frac{\\rho}{2(1-\\rho)}\\biggr].\\nonumber\\end{aligned}\\ ] ] combining ( [ eq : empirical - risk - kj ] ) and ( [ eq : empirical - risk-1j ] ) , it is evident that @xmath406}\\\\ & \\geq & \\frac{1}{1+(m-2){\\rho}/(2(m-2)(1-\\rho))+{\\rho}/(2(1-\\rho))}= 1-\\rho.\\end{aligned}\\ ] ] since the functions @xmath407 are independent in @xmath408 and @xmath409 , @xmath410 and there is an absolute constant @xmath28 for which @xmath411 .",
    "thus , @xmath412 provided that @xmath398 , giving @xmath413 as claimed .",
    "next , we formulate a general statement , from which theorem  [ thb ] follows immediately .",
    "there exist absolute constants @xmath414 and an integer @xmath81 for which the following holds . for any @xmath83 , @xmath415 , @xmath416 , and @xmath417 , let @xmath418 , @xmath419 , and @xmath420 .",
    "set @xmath0 to be the class of functions defined above with those parameters .",
    "then , with probability at least @xmath421 there exists @xmath422 such that @xmath423 in particular , with the same probability and if @xmath424 , @xmath425    set @xmath426,\\ ] ] and , by proposition  [ prop : large - weights ] , @xmath427={\\mathbb{p}}_1.\\ ] ] let @xmath428 be defined by @xmath429=1-n^{-1}$ ] , and observe that @xmath304 is well defined and satisfies all three parts of lemma [ lemma : gamma-1 ] for @xmath430 .",
    "set , @xmath431 and @xmath432 since the functions @xmath433 are independent , we have @xmath434 { \\mathbh{1}}_{\\omega_0 } ] \\geq{\\mathbb{p}}[b ] { \\mathbb{p}}[\\omega_0].\\ ] ] applying proposition  [ prop : shahar - proposition ] , we then have @xmath435 \\geq1-\\frac{1}{n } -c_2\\biggl(\\frac{1}{\\sqrt{n}}+\\delta\\biggr)(\\log n)^2\\sqrt{\\log m},\\ ] ] provided that @xmath328 .    to lower bound @xmath436 $ ] , note that @xmath437={\\mathbb{p}}\\biggl[\\bar r_1\\geq \\gamma_1-\\frac{t}{\\sqrt{n}}\\log\\biggl(\\frac{\\rho}{2(1-\\rho)}\\biggr ) + \\sqrt{12}\\lambda(2-\\lambda)\\sqrt{n}\\biggr].\\ ] ] fix @xmath438 and assume that @xmath439 and @xmath44 are such that @xmath440 by the berry  essen theorem and ( [ eq : gaussian - tail - estimate ] ) , @xmath441&\\geq&{\\mathbb{p}}[\\bar r_1\\geq(1 - 2\\varepsilon)\\gamma_1 ] = 1-{\\mathbb{p}}[\\bar r_1<(1 - 2\\varepsilon)\\gamma_1 ] \\\\ & \\geq & 1-{\\mathbb{p}}[g\\leq ( 1 - 2\\varepsilon)\\gamma_1]-\\frac{2\\beta(w)}{\\sqrt{n } } \\\\ & \\geq & 1-\\frac{1}{\\sqrt{2\\uppi}(1 - 2\\varepsilon)|\\gamma_1|}\\exp \\bigl(-(1 - 2\\varepsilon ) ^2\\gamma_1 ^ 2/2\\bigr ) -\\frac{2a}{\\sqrt{n}},\\end{aligned}\\ ] ] and by lemma  [ lemma : gamma-1 ] , @xmath442 therefore , @xmath443 provided that @xmath444 .    to complete the proof , we need to chose @xmath445 and @xmath446 for which ( [ eq : def - theta - rho ] ) holds . by lemma [ lemma : gamma-1 ] ,",
    "@xmath447 and thus ( [ eq : def - theta - rho ] ) holds for @xmath445 and @xmath446 for which @xmath448^{1/2}\\quad \\mbox{and}\\quad \\rho\\geq 2\\exp\\biggl[\\frac{-c_9\\varepsilon\\sqrt{n}}{t}\\log^{1/2}\\biggl(\\frac{m}{\\log n}\\biggr)\\biggr].\\ ] ] in particular , when we take @xmath449 , @xmath450 , and @xmath451 , @xmath446 satisfies the required condition as long as @xmath452 and @xmath453 , as assumed .",
    "moreover , @xmath454 implying that @xmath455 the lower bound on the risk of the aew procedure now follows from proposition  [ prop : large - weights ] .",
    "in this section we prove theorem  [ thc ] , which we reformulate below . from here on , we assume that the dictionary @xmath0 is finite , consisting of @xmath24 functions , and that the functions are indexed according to their risk in an increasing order .",
    "thus , @xmath456 . in addition , we denote @xmath457 , and thus @xmath458 .    for every @xmath116 , recall that @xmath459 which serves as a measure of complexity for the class @xmath0 .",
    "the first component needed in the proof of theorem  [ thc ] is the level @xmath460 with the following property : with probability at least @xmath113 , @xmath461 is equivalent to @xmath462 if @xmath463 .",
    "this `` isomorphism '' constant was introduced by  @xcite . to formulate the exact properties that we need , first recall the following definitions and notation .",
    "if @xmath464 is the excess loss functions class @xmath465 , then let @xmath466 is the star - shaped hull of @xmath467 and @xmath468 .",
    "set @xmath469 , that is , the set of functions in the star - shaped hull of @xmath470 and @xmath468 , with expectation @xmath471 .",
    "let @xmath472 where , as always , @xmath473 denotes the empirical mean and @xmath196 is the mean according to the underlying probability measure of @xmath9 .",
    "[ thm : isomorphic - coordinate - proj ] there exists an absolute constant @xmath135 for which the following holds .",
    "let @xmath0 be a class of functions bounded by @xmath29 , such that @xmath107 is a @xmath123-bernstein class .",
    "for every @xmath112 and an integer @xmath25 , let @xmath474 then , with probability at least @xmath113 , for every @xmath153 with @xmath475 , @xmath476    let @xmath477 , where @xmath478 is an absolute constant to be named later . recall that functions in @xmath0 are indexed according to their risk in an increasing order .",
    "let @xmath479 , and set @xmath480 as its complement .",
    "define the sets @xmath481 and , for @xmath482 , @xmath483 ( note that some of the sets @xmath484 may be empty . )",
    "set @xmath485 and let @xmath486 .    from theorem  [ thm : isomorphic - coordinate - proj ]",
    ", it follows that for every @xmath487 and every @xmath488 , @xmath489 .",
    "this is because @xmath490 by the definition of @xmath480 , and @xmath491 .",
    "the key factor in the proof of theorem  [ thc ] is theorem [ thm : optimal - agg ] .",
    "[ thm : optimal - agg ] there exist absolute constants @xmath5 and @xmath82 for which the following holds .",
    "let @xmath0 be a class of functions bounded by @xmath29 , such that @xmath107 is a @xmath123-bernstein class with respect to a convex risk function @xmath492 .",
    "then , with probability at least @xmath113 , if @xmath126 is produced by the aew algorithm and @xmath493 , then @xmath494 where @xmath460 is as defined in  ( [ eq : lambda ] ) .",
    "let @xmath495 be the weights of the aew algorithm , and set @xmath496 to be the aggregate function . because @xmath492 is a convex function , @xmath497    note that for every @xmath498 , @xmath499 .",
    "in particular , because @xmath500 , @xmath501 on the other hand , with probability at least @xmath113 , for every @xmath502 and every @xmath488 , @xmath503 applying the definition of the weights in the aew algorithm and given that @xmath504 , @xmath505 from the definition of @xmath506 , it is evident that for every @xmath507 , @xmath508 , and thus if @xmath509 and @xmath478 is sufficiently large , then @xmath510 indeed , this follows because for that choice of @xmath44 , @xmath511 , with @xmath70 an absolute constant .",
    "thus , with probability at least @xmath113 , @xmath512 as claimed .",
    "the next step in the proof of theorem  [ thc ] requires several simple facts regarding the empirical process indexed by a localization of the star - shaped hull of a bernstein class .",
    "first , it is simple to verify that the star - shaped hull of a @xmath123-bernstein class is a @xmath123-bernstein class as well .",
    "second , if @xmath513 and @xmath514 , then @xmath515 in particular , @xmath516    [ lemma : localized - estimates ] there exists an absolute constant @xmath135 for which the following holds .",
    "if @xmath107 is a @xmath123-bernstein class with respect to @xmath9 , then for every @xmath471 and @xmath517 , @xmath518    fix @xmath116 and @xmath517 , and let @xmath519 note that every @xmath520 satisfies that @xmath521 for some @xmath33 , and for which @xmath522 . therefore , using the bernstein condition on @xmath107 , @xmath523 moreover , @xmath524",
    "thus , by the gin  zinn symmetrization theorem and a contraction argument ( see , e.g. ,  @xcite and  @xcite ) , @xmath525 where the last inequality is evident by the sub - gaussian properties of the rademacher process ( cf .",
    "@xcite ) . since @xmath526",
    ", it follows that @xmath527 implying that @xmath528 thus , again using a symmetrization argument and the sub - gaussian properties of the rademacher process , we have @xmath529    [ cor : est - for - r^ * ] there exist absolute constants @xmath5 and @xmath82 for which the following holds .",
    "let @xmath0 be a finite class consisting of @xmath24 functions bounded by @xmath29 , such that the excess loss class @xmath107 is a @xmath123-bernstein class .",
    "if we set @xmath530 , then @xmath531    observe that for every @xmath116 , @xmath532 where we define @xmath533 .",
    "let @xmath534 .",
    "since @xmath535 for every @xmath536 , we have @xmath537 and thus @xmath538 moreover , the functions of @xmath471 , @xmath539 and @xmath540 are increasing , and thus for any @xmath541 , @xmath542 and @xmath543 thus , if we consider @xmath544 for appropriate constants @xmath122 and @xmath70 , then @xmath545 .",
    "thus , @xmath546 and , therefore , @xmath547 finally , because @xmath548 and @xmath549 , we have @xmath550 .    proof of theorem [ thc ] the proof of theorem  [ thc ] follows from estimates of @xmath460 and @xmath551 . from corollary [ cor : est - for - r^ * ] , it is evident that @xmath552 where @xmath5 is an absolute constant to be identified later .",
    "( note that @xmath96 is an increasing function . )    next , by the definition of @xmath506 , @xmath553 .",
    "therefore , using the notation of theorem  [ thm : optimal - agg ] , @xmath554 and , in particular , @xmath555 for an appropriate choice of constant @xmath5 .",
    "the second part of theorem  [ thc ] follows from a standard integration argument .",
    "this article was written while g. lecu was visiting the department of mathematics , technion , and the centre for mathematics and its applications , australian national university .",
    "the authors thank both of these institutions for their hospitality .",
    "they also thank pierre alquier and olivier catoni for useful discussions .",
    "g. lecu was supported by french agence nationale de la recherche anr grant `` prognostic '' anr-09-jcjc-0101 - 01 .",
    "s. mendelson was supported in part by the centre for mathematics and its applications , the australian national university , canberra , act 0200 , australia , by an australian research council discovery grant dp0559465 , dp0986563 and by the european community s seventh framework programme ( fp7/2007 - 2013 ) , erc grant agreement 203134 ."
  ],
  "abstract_text": [
    "<S> given a finite class of functions @xmath0 , the problem of aggregation is to construct a procedure with a risk as close as possible to the risk of the best element in the class . a classical procedure ( pac - bayesian statistical learning theory ( 2004 ) paris 6 , _ statistical learning theory and stochastic optimization _ ( 2001 ) springer , _ ann . </S>",
    "<S> statist . </S>",
    "<S> _ * 28 * ( 2000 ) 7587 ) is the aggregate with exponential weights ( aew ) , defined by @xmath1 where @xmath2 is called the temperature parameter and @xmath3 is an empirical risk .    in this article , we study the optimality of the aew in the regression model with random design and in the low - temperature regime . we prove three properties of aew . </S>",
    "<S> first , we show that aew is a suboptimal aggregation procedure in expectation with respect to the quadratic risk when @xmath4 , where @xmath5 is an absolute positive constant ( the low - temperature regime ) , and that it is suboptimal in probability even for high temperatures . </S>",
    "<S> second , we show that as the cardinality of the dictionary grows , the behavior of aew might deteriorate , namely , that in the low - temperature regime it might concentrate with high probability around elements in the dictionary with risk greater than the risk of the best function in the dictionary by at least an order of @xmath6 . </S>",
    "<S> third , we prove that if a geometric condition on the dictionary ( the so - called `` bernstein condition '' ) is assumed , then aew is indeed optimal both in high probability and in expectation in the low - temperature regime . moreover , under that assumption , the complexity term is essentially the logarithm of the cardinality of the set of `` almost minimizers '' rather than the logarithm of the cardinality of the entire dictionary . </S>",
    "<S> this result holds for small values of the temperature parameter , thus complementing an analogous result for high temperatures . </S>"
  ]
}