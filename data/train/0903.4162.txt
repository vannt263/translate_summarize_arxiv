{
  "article_text": [
    "the standard statistical models of coherent imaging systems , such as synthetic aperture radar / sonar ( sar / sas ) , ultrasound imaging , and laser imaging , are supported on multiplicative noise mechanisms . with respect to a given resolution cell of the imaging device , a coherent system acquires the so - called in - phase and quadrature components ) and @xmath0 , where @xmath1 is the carrier angular frequency . ] which are collected in a complex reflectivity ( with the in - phase and quadrature components corresponding to the real and imaginary parts , respectively ) .",
    "the complex reflectivity of a given resolution cell results from the contributions of all the individual scatterers present in that cell , which interfere in a destructive or constructive manner , according to their spatial configuration .",
    "when this configuration is random , it yields random fluctuations of the complex reflectivity , a phenomenon which is termed _",
    "speckle_. the statistical properties of speckle have been widely studied and there is a large body of literature @xcite , @xcite . assuming no strong specular reflectors and a large number of randomly distributed scatterers in each resolution cell ( relative to the carrier wavelength ) , the squared amplitude ( _ intensity _ ) of the complex reflectivity",
    "is exponentially distributed @xcite .",
    "the term _ multiplicative noise _ is clear from the following observation : an exponential random variable can be written as the product of its mean value ( parameter of interest ) by an exponential variable of unit mean ( noise ) .",
    "the scenario just described , known as _ fully developed speckle _ , leads to observed intensity images with a characteristic granular appearance due to the very low _ signal to noise ratio _ ( snr ) .",
    "notice that the snr , defined as the ratio between the squared intensity mean and the intensity variance , is equal to one ( @xmath2db ) .      a common approach to improving the snr in coherent imaging consists in averaging independent observations of the same pixel . in sar / sas systems , this procedure",
    "is called _ multi - look _",
    "( @xmath3-look , in the case of @xmath3 looks ) , and each independent observation may be obtained by a different segment of the sensor array . for fully developed speckle , the snr of an @xmath3-look image is @xmath3 .",
    "another way to obtain an m - look image is to low pass filter ( with a moving average kernel with support size @xmath3 ) a 1-look fully developed speckle image , making evident the tradeoff between snr and spatial resolution .",
    "a great deal of research has been devoted to developing nonuniform filters which average large numbers of pixels in homogeneous regions yet avoid smoothing across discontinuities in order to preserve image detail / edges @xcite .",
    "many other speckle reduction techniques have been proposed ; see @xcite for a comprehensive literature review up to 1998 .",
    "a common assumption is that the underlying reflectivity image is piecewise smooth . in image restoration under multiplicative noise",
    ", this assumption has been formalized using markov random fields , under the bayesian framework @xcite , @xcite and , more recently , using _ total variation _ ( tv ) regularization @xcite , @xcite , @xcite , @xcite .      in this paper , we adopt tv regularization . in comparison with the canonical additive gaussian noise model ,",
    "we face two difficulties : the noise is multiplicative ; the noise is non - gaussian , but follows rayleigh or gamma distributions .",
    "we tackle these difficulties by first converting the multiplicative model into an additive one ( which is a common procedure ) and then adopting the recently proposed split bregman approach to solve the optimization problem that results from adopting a total variation regularization criterion .",
    "other works that have very recently addressed the restoration of speckled images using tv regularization include @xcite , @xcite , @xcite , @xcite .",
    "the commonalities and differences between our approach and the ones followed in those papers will be discussed after the detailed description of our method , since this discussion requires notation and concepts which will be introduced in the next section .",
    "let @xmath4 denote an @xmath5-pixels observed image , assumed to be a sample of a random image @xmath6 , the mean of which is the underlying reflectivity image @xmath7 , _",
    "i.e. _ , @xmath8 = { { \\bf x}}$ ] . adopting a conditionally independent multiplicative noise model",
    ", we have @xmath9 where @xmath10 is an image of independent and identically distributed ( iid ) noise random variables with unit mean , @xmath11 , following a common density @xmath12 . for @xmath3-look",
    "fully developed speckle noise , @xmath12 is a gamma density with @xmath13=1 $ ] , and @xmath14 , _ i.e. _ , @xmath15    an additive noise model is obtained by taking logarithms of ( [ eq : multiply ] ) . for some pixel of the image ,",
    "the observation model becomes @xmath16 the density of the random variable @xmath17 is @xmath18 thus @xmath19    under the regularization and bayesian frameworks , the original image is inferred by solving a minimization problem with the form @xmath20 where @xmath21 is the penalized minus log - likelihood , @xmath22 with @xmath23 an irrelevant additive constant , @xmath24 the penalty / regularizer ( negative of the log - prior , from a the bayesian perspective ) , and @xmath25 the regularization parameter .    in this work",
    ", we adopt the tv regularizer , that is , @xmath26 where @xmath27 and @xmath28 denote the horizontal and vertical first order differences at pixel @xmath29 , respectively .    each term @xmath30 of ( [ eq : neg_like ] ) , corresponding to the negative log - likelihood ,",
    "is strictly convex and coercive , thus so is their sum . since the tv regularizer is also convex ( though not strictly so ) , the objective function @xmath31 possesses a unique minimizer @xcite . in terms of optimization , these are desirable properties that would not hold if we had formulated the inference in the original variables @xmath32 , since the resulting negative log - likelihood is not convex ; this was the approach followed in @xcite and @xcite .",
    "there are several efficient algorithms to compute the tv regularized solution for a quadratic data term ; for recent work , see @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , and other references therein . when the data term is not quadratic , as in ( [ eq : neg_like ] )",
    ", the problem is more difficult and far less studied .",
    "herein , we follow the split bregman approach @xcite which is composed of the following two steps : ( splitting ) a constrained problem equivalent to the original unconstrained one is formulated ; ( bregman ) this constrained problem is solved using the bregman iterative approach @xcite . before describing these two steps in detail , we briefly review the bregman iterative approach .",
    "the reader is referred to @xcite , @xcite , for more details .",
    "consider a constrained optimization problem of the form @xmath33 with @xmath34 and @xmath35 convex , @xmath35 differentiable , and @xmath36 .",
    "the so - called bregman divergence associated with the convex function @xmath34 is defined as @xmath37 where @xmath38 belongs to the subgradient of @xmath34 at @xmath39 , _",
    "i.e. _ , @xmath40    the bregman iteration is given by @xmath41 where @xmath42 .",
    "it has been shown that this procedure converges to a solution of ( [ eq : constrained_general ] ) @xcite,@xcite .    concerning the update of @xmath43 , we have from , that @xmath44 , when this sub - differential is evaluated at @xmath45 , that is @xmath46 since it was assumed that @xmath35 is differentiable , and since @xmath47 at this point , @xmath48 should be chosen as @xmath49    in the particular case where @xmath50 , it can be shown ( see @xcite ) that the iteration ( [ eq : updatex2 ] ) is equivalent to @xmath51      the original unconstrained problem ( [ eq : l_uncons ] ) is equivalent to the constrained formulation @xmath52 with @xmath53    notice how the original variable ( image ) @xmath54 is split into a pair of variables @xmath55 , which are decoupled in the objective function ( [ eq : l_cons_obj ] ) .",
    "notice that the problem ( [ eq : l_cons])-([eq : z_u_c ] ) has exactly the form ( [ eq : constrained_general ] ) , with @xmath56^t$ ] , @xmath57 , and @xmath58 , with @xmath59 $ ] and @xmath60 . using this equivalence ,",
    "the bregman iteration ( [ eq : bregman1a])-([eq : bregman1b ] ) becomes @xmath61    we address the minimization in ( [ eq : bregman_u_z ] ) using an alternating minimization scheme with respect to @xmath62 and @xmath63 .",
    "the complete resulting algorithm is summarized in algorithm 1 .",
    "[ alg : ]    @xmath64 , @xmath65 , @xmath66 , @xmath25 , @xmath67 , @xmath68 .",
    "@xmath69 @xmath70 .",
    "@xmath71 @xmath72    the minimization with respect to @xmath54 , in line 3 , has closed form in terms of the lambert w function @xcite . however , we found that the newton method yields a faster solution by running just four iterations .",
    "notice that the minimization in line 3 is in fact a set of @xmath5 decoupled scalar minimizations . for the minimization with respect to @xmath73 ( line 4 ) , which is a tv denoising problem , we run a few iterations ( typically 10 ) of chambolle s algorithm @xcite .",
    "the number of inner iterations @xmath74 was set to one in all the experiments reported below .",
    "the stopping criterion ( line 8) is the same as in @xcite .",
    "the estimate of @xmath75 produced by the algorithm is naturally @xmath76 , component - wise .",
    "notice how the split bregman approach converted a difficult problem involving a non - quadratic term and a tv regularizer into two simpler problems : a decoupled minimization problem ( line 3 ) and a tv denoising problem with a quadratic data term ( line 4 ) .      in the case of linear constraints",
    ", the bregman iterative procedure defined in ( [ eq : updatex2 ] ) is equivalent to an augmented lagrangian method @xcite ; see @xcite , @xcite for proofs .",
    "it is known that the augmented lagrangian is better conditioned that the standard lagrangian for the same problem , thus a better numerical behavior is expectable .",
    "tv - based image restoration under multiplicative noise was recently addressed in @xcite .",
    "the authors apply an inverse scale space flow , which converges to the solution of the constrained problem of minimizing @xmath77 under an equality constraint on the log - likelihood ; this requires a carefully chosen stopping criterion , because the solution of this constrained problem is not a good estimate .    in @xcite , a splitting of the variable",
    "is also used to obtain an objective function with the form @xmath78 this is the so - called splitting - and - penalty method .",
    "notice that the minimizers of @xmath79 converge to those of ( [ eq : l_cons])-([eq : z_u_c ] ) only when @xmath80 approaches infinity .",
    "however , since @xmath79 becomes severely ill - conditioned when @xmath80 is very large , causing numerical difficulties , it is only practical to minimize @xmath79 with moderate values of @xmath80 ; consequently , the solutions obtained are not minima of the regularized negative log - likelihood ( [ eq : neg_like ] ) .",
    "in this section we report experimental results comparing the performance of the proposed approach with that of the recent state - of - the - art methods in @xcite and @xcite .",
    "all the experiments use synthetic data , in the sense that the observed image is generated according to ( [ eq : multiply])-([eq : gamma ] ) , where @xmath75 is a clean image . as in @xcite",
    ", we select the regularization parameter @xmath25 by searching for the value leading to the lowest mean squared error with respect to the true image . the algorithm is initialized with the observed noisy image .",
    "the quality of the estimates is assessed using the relative error ( as in @xcite ) , @xmath81    table  [ tab : results ] reports the results obtained using lena and the cameraman as original images , for the same values of the number of looks ( @xmath3 in ( [ eq : gamma ] ) ) as used in @xcite . in these experiments",
    ", our method always achieves lower relative errors with fewer iterations , when compared with the methods from @xcite and @xcite ( the results concerning the algorithm from @xcite are those reported in @xcite ) .",
    "it s important to point out that the computational cost of each iteration of the algorithm of @xcite is essentially the same as that of our algorithm .",
    ".experimental results ( iter denotes the number of iterations ; cam . is the cameraman image ) .",
    "[ cols= \" < , < , < , < , < ,",
    "< , < , < \" , ]     figure  [ fig : images ] shows the noisy and restored images , for the same experiments reported in table  [ tab : results ] . finally , figure  [ fig : plots ] plots the evolution of the objective function @xmath82 and of the constraint function @xmath83 along the iterations , for the example with the cameraman image and @xmath84 . observe the extremely low value of @xmath83 at the final iterations , showing that , for all practical purposes , the constraint ( [ eq : z_u_c ] ) is satisfied .     and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ] and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ]     and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ] and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ]     and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ] and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ]     and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ] and @xmath85 .",
    "third and fourth rows : cameraman , @xmath84 and @xmath86.,title=\"fig:\",width=151 ]     and of the constraint function @xmath83 , along the iterations of the algorithm , for the experiment with the cameraman image and @xmath84 .",
    ", title=\"fig:\",width=156 ] and of the constraint function @xmath83 , along the iterations of the algorithm , for the experiment with the cameraman image and @xmath84 .",
    ", title=\"fig:\",width=164 ]",
    "we have proposed an approach to total variation denoising of images contaminated by multiplicative noise , by exploiting a split bregman technique .",
    "the proposed algorithm is very simple and , in the experiments herein reported , exhibited state of the art performance and speed .",
    "we are currently working on extending our methods to problems involving linear observation operators ( _ e.g. _ , blur ) and other related noise models , such as poisson .",
    "l.  rudin , p.  lions , and s.  osher ,  multiplicative denoising and deblurring : theory and algorithms \" , in _ geometric level set methods in imaging , vision , and graphics , _ s.  osher and n.  paragios ( editors ) , pp .",
    "103120 , 2003 .",
    "w.  yin , s.  osher , d.  goldfarb , j.  darbon , ",
    "bregman iterative algorithms for @xmath87-minimization with applications to compressed sensing \" , _ siam jour .",
    "imaging sciences _ , vol .  1 , no .  1 ,",
    "pp .  143168 , 2008 ."
  ],
  "abstract_text": [
    "<S> multiplicative noise models occur in the study of several coherent imaging systems , such as synthetic aperture radar and sonar , and ultrasound and laser imaging . </S>",
    "<S> this type of noise is also commonly referred to as _ </S>",
    "<S> speckle_. multiplicative noise introduces two additional layers of difficulties with respect to the popular gaussian additive noise model : ( 1 ) the noise is multiplied by ( rather than added to ) the original image , and ( 2 ) the noise is not gaussian , with rayleigh and gamma being commonly used densities . </S>",
    "<S> these two features of the multiplicative noise model preclude the direct application of state - of - the - art restoration methods , such as those based on the combination of total variation or wavelet - based regularization with a quadratic observation term . in this paper , we tackle these difficulties by : ( 1 ) using the common trick of converting the multiplicative model into an additive one by taking logarithms , and ( 2 ) adopting the recently proposed split bregman approach to estimate the underlying image under total variation regularization . </S>",
    "<S> this approach is based on formulating a constrained problem equivalent to the original unconstrained one , which is then solved using bregman iterations ( equivalently , an augmented lagrangian method ) . </S>",
    "<S> a set of experiments show that the proposed method yields state - of - the - art results .    </S>",
    "<S> speckle , multiplicative noise , total variation , bregman iterations , augmented lagrangian , synthetic aperture radar . </S>"
  ]
}