{
  "article_text": [
    "sensory information is often encoded in irregularly spiking neural populations .",
    "one well - studied example is given by direction - selective cells in area mt , whose firing rates depend on the degree and direction of coherent motion in the visual field  @xcite . individual neurons in mt  as in many other brain areas  exhibit noisy and variable spiking @xcite , as can be modeled by poisson point processes  @xcite . moreover , this variable spiking is generally not independent from cell to cell . returning to our example ,",
    "a number of studies have measured pairwise correlations in mt during direction discrimination tasks as well as smooth - pursuit eye movements @xcite ; while this measurement is a subtle endeavor experimentally , a number of studies suggest a value near @xmath0 ( @xcite summarizes these observations , for a number of brain areas . )    what are the consequences of correlated spike variability for the speed and accuracy of sensory decisions ? the role of pairwise correlations in stimulus encoding has been the subject of many prior studies  @xcite .",
    "the results are rich , showing that correlations can have positive , negative , or neutral effects on levels of encoded information .",
    "the present study serves to extend this body of work in two ways .",
    "first , as done in a different context by  @xcite , we contrast the impact of correlations that have the same pairwise level but a different structure at higher orders .",
    "second , as in @xcite , we consider the impact of correlations on decisions that unfold over time , by combining a sequence of samples observed over time in the sensory populations .",
    "a classical example that we will use to describe and motivate our studies is the _ moving dots _ direction discrimination task . here , a fraction of dots in a visual display move coherently in a given direction , while the remainder display random motion ; the task is to identify the direction from two possible alternatives .",
    "decisions become increasingly accurate as subjects take ( or are given ) longer to make the decision .    in analyzing decisions that develop over time ,",
    "we utilize a central result from sequential analysis .",
    "this is the sequential probability ratio test ( sprt )  @xcite , which linearly sums the log - odds of independent observations from a sampling distribution until a predetermined evidence threshold is reached .",
    "the sprt is the optimal statistical test in that it gives the minimum expected number of samples for a required level of accuracy in deciding among two task alternatives .",
    "we pose two related questions based on the sprt .",
    "first , how does the presence of correlated spiking in the sampled pools impact the speed and accuracy of decisions produced by the sprt ?",
    "our focus is on how the structure of population - wide correlations determines the answer .",
    "second , how does the presence of correlated spiking impact the computations that are necessary to perform the sprt ?",
    "this question is intriguing , because the sprt may be performed via the simple , linear computation of integrating spikes over time and across the populations for a surprisingly broad class of inputs , including independent poisson spike trains  @xcite .",
    "thus , in this setting optimal decisions can be made by integrator circuits  @xcite .",
    "our goal here is to determine whether and when this continues to hold true for correlated neural populations .",
    "we answer these questions for two illustrative models of correlated , poissonian spiking .",
    "we emphasize that the spikes that these models produce are indistinguishable at the level of both single cells and pairs of cells .",
    "however , they differ in higher - order correlations , in that they can only be distinguished by examining the statistics of three or more neurons . in the first model ,",
    "correlations are introduced via shared spike events across the entire pool . in this case",
    "optimal inference via the sprt produces fast and accurate decisions , but depends on a nonlinear computation . as a result ,",
    "the simpler computation of spike integration requires , on average , longer times to reach the same level of accuracy .",
    "in contrast , when shared spiking events are more frequent but are common to fewer neurons within a pool , performance under the sprt is significantly diminished . however , in this case both sprt and spike integration perform comparably , so a linear computation can produce decisions that are close to optimal .",
    "we begin by introducing the notation for the two decision making models that will be compared . in this study",
    "we consider the case of discrimination between two alternatives , and therefore model two populations of neurons that encode the strength of evidence for each alternative .",
    "returning to the moving dots task for illustration , each population could be the set of mt cells that are selective for motion in a given direction . here",
    ", the firing rates in each population represents the dot motion @xmath1 via their firing rates @xmath2 and @xmath3 ; here the subscripts indicate the  preferred \" and  null \" populations , which correspond to the motion direction of the visual stimulus versus the alternate direction . in this way , the firing rate of neurons encoding the preferred direction will be higher than the null direction , @xmath4 . following @xcite ( see also @xcite ) , we model this relationship as linear : @xmath5 throughout the text we consider present results at @xmath6 ,",
    "however the results do not depend on this particular value of dot motion or its precise relationship firing rate .    in our model",
    ", we assume that each population consists of @xmath7 neurons firing spikes via a homogenous poisson process , with rate @xmath2 or @xmath3 .",
    "we use the notation @xmath8 to each spike train . integrating these processes over a time interval @xmath9",
    "provides two time series of @xmath10dimensional vectors of poisson random variables ; these independent vectors provide the input to the decision making models .",
    "specifically , for the @xmath11 neuron in a pool , on the @xmath12 time step , @xmath13 the properties of poisson processes imply that @xmath14 is independent from @xmath15 ( @xmath16 ) , i.e. for different time steps .",
    "however , the outputs of different neurons in the same time are not , in general , independent . following experimental observations that neurons with similar directional tuning tend to be correlated , while those with very different tuning are not  @xcite , we model neurons from different pools as independent and those within a single pool as correlated with a correlation coefficient @xmath17 : @xmath18}{\\sqrt{\\text{var}[s^i_{k}]\\text{var}[s^i_{l}]}},\\;\\ ; k\\neq l.                      \\label{eq : rho}\\ ] ] this implies that , with vector notation for the probability distribution of spike counts for each pool , @xmath19 = p[{\\boldsymbol{s^i_p}}]p[{\\boldsymbol{s^i_n}}].\\ ] ]    next , we introduce notation for decision making between the two task alternatives .",
    "the task of determining , e.g. , direction in the moving dots task is that of determining which of the two pools fires spikes with the higher firing rate .",
    "we frame this as decision making between the hypotheses @xmath20 where each alternative corresponds to a decision as to the motion direction .",
    "this formalism allows us to define accuracy as the fraction of trials on which the correct hypothesis @xmath21 is accepted . in this study",
    "we consider decision making tasks at a fixed level of difficulty , so that @xmath2 and @xmath3 do not vary from trial to trial ( i.e. , this hypothesis test is simple and not composite ) .",
    "we relate the decision making task to a discrete random walk , which follows in turn from the sequential accumulation of independent and identically distributed ( iid ) realizations from the sampling distribution @xmath22",
    ". we will specify this distribution below ; for now , we note that the random walk takes the general form : @xmath23 @xmath24 in a drift - diffusion model of decision making , accumulation continues as long as @xmath25 , the decision threshold  @xcite .",
    "the number of increments necessary to cross one of the two increments multiplied by its duration @xmath9 defines the decision time ; this is a random variable , as it varies from trial to trial .",
    "crossing the threshold corresponding to @xmath21 is interpreted as a correct trial ; the fraction of correct ( fc ) trials defines the accuracy of a the model .",
    "together , the expected ( mean ) decision time ( @xmath26 ) and accuracy ( @xmath27 ) determine the performance of a decision making model .    formulas for the mean decision time and accuracy are given in wald @xcite as a function of the sampling distribution and the decision threshold .",
    "importantly , these formulas are exact under the assumption that the final increment in @xmath28 does not overshoot the threshold , a point we return to below . given the moment generating function for the sampling distribution : @xmath29,\\ ] ] speed and accuracy are given by : @xmath30 } \\tanh \\left ( \\frac{-h_0 \\theta } { 2}\\right ) \\label{eq : rt}\\end{aligned}\\ ] ] where @xmath31 is the nontrivial root of @xmath32 , i.e. @xmath33 we notice here that as @xmath34 increases ( and assuming @xmath35 ) , both @xmath27 and @xmath36 will increase .",
    "we now return to the definition of the random increments @xmath22 .",
    "we consider two different ways in which this can be done .",
    "first , in the spike integration ( si ) model , increments are constructed by counting the spikes emitted in a @xmath9 window by the preferred pool , and subtracting the number emitted by the null pool .",
    "this is equivalent to the time evolution of a neural integrator model that receives spikes as impulses with opposite signs from the preferred and null populations .",
    "this integrate - to - bound model is an analog of drift - diffusion model ( ddm ) with inputs that are not  white noise \" , but rather poisson spikes : @xmath37 @xcite , cf .",
    "@xcite .",
    "second , in the sequential probability ratio test ( sprt ) , the increment is defined as the log - odds ratio of observing the spike count from both of the pools , under each of the two competing hypothesis : @xmath38p[{\\boldsymbol{s^i_n}}|h_1]}{p[{\\boldsymbol{s^i_p}}|h_0]p[{\\boldsymbol{s^i_n}}|h_0 ] }         \\right ] \\label{eq : sprtsamplingrv}\\ ] ]      @xcite present an analysis of speed and accuracy of decision making based on independent neural pools ; for completeness , and to help contrast this result with the correlated case , we give the key calculations in appendices [ sec : mgf_sprt ] ,  [ sec : siuncorr ] . here , choosing increments via the sprt yields : @xmath39 & = & \\delta t n\\left ( \\lambda_p-\\lambda_n \\right)\\log \\left ( \\frac{\\lambda_p}{\\lambda_n}\\right ) .",
    "\\label{eq : indsprtez }      \\end{aligned}\\ ] ] under the spike integration model , zhang and bogacz @xcite ( see also appendix [ sec : siuncorr ] ) find that : @xmath40 & = & \\delta t n\\left ( \\lambda_p-\\lambda_n \\right).\\label{eq : uncorrsiez }      \\end{aligned}\\ ] ] therefore , by applying a change of variables @xmath41 in equations  [ eq : fc ] and [ eq : rt ] , spike integration can implement the sprt .",
    "the implication is that simply counting spikes , positive for one pool and negative for the other , can implement statistically optimal decisions for when the neural pools are independent @xcite .",
    "we next describe two models for introducing correlations into the poisson spike trains of each neural population .",
    "both models are studied in @xcite , and rely on shared input from a single correlating process to generate the correlations in each pool .",
    "these authors termed the two model sip and mip for single- and multiple - interaction process ; here we use the added descriptors  additive \" and  subtractive . \" in both models , a realization of correlated spike trains that provide the input to the accumulation models is achieved via a common correlating train .    before describing the models in detail",
    ", we note that in this study , these models are statistical approaches chosen to illustrate a range of impacts that correlations can have on decision making ( see also  @xcite ) . in contrast , in neurobiological networks , correlated spiking arises as through a complex interplay of many mechanisms , including recurrent connectivity and shared feedforward interactions ( for example ,  @xcite ) . while beyond the scope of the present paper , avenues for bridging the gap between statistical and network - based models of correlations in the context of decision making are considered in the discussion .",
    "the first case is the additive ( sip ) model , in which the spike train for each neuron is generated as the sum of two homogenous poisson point processes .",
    "the first poisson train is generated with an overall firing rate of @xmath42 , where @xmath43 is the intended firing rate of the neuron , and @xmath17 is the intended pairwise spike count correlation between any two neurons in the pool .",
    "the second train , with a rate of @xmath44 , is added to every neuron in the pool , and serves as the common source of correlations .",
    "an example of this model of spike train generation is depicted in the rastergrams in figure [ fig : intsprtoverview]a and b ; the common spike events are evident as shared spikes across the entire population .",
    "the second case is the subtractive ( mip ) model , in which correlated spikes are generated through random , independent deletions from an original  mother \" spike - train ; we refer to this as the correlating spike train  @xcite .",
    "there is a separate correlating spike train for each of the two independent populations . in order to achieve an overall firing rate for the pool of @xmath43 spikes per second , with a pairwise correlation @xmath17 between any two individual neurons ,",
    "the correlating train has a rate of @xmath45 spikes per second .",
    "then , for each neuron in the pool , a spike is included from this train iid with a probability of @xmath17 .",
    "an example of this model of spike train generation is depicted in the rastergrams in figure [ fig : intsprtoverview]d and e.    in summary , the two models both include correlated spike events that originate in from a single  mother . \"",
    "although they produce identical correlations among cell pairs , these events are distributed in different ways across the entire population .",
    "we note that the results of @xcite can be seen as a limiting case as @xmath46 of either the additive ( sip ) or subtractive ( mip ) models .     for preferred ( a , d ) and null ( b , e ) populations of @xmath47 neurons , with spike count correlation within pools @xmath48 . in ( c ,",
    "f ) these spikes are either integrated ( black line ) or provide input for the sprt ( gray line ) , until a decision threshold is reached .",
    "the decision threshold has been set so that all four cases will yield the same mean reaction time ( in c , @xmath49 and @xmath50 , and in f @xmath51 and @xmath50 ; in both cases the sprt lines have been scaled for plotting purposes ) . on these trials , the sprt accumulator crosses the  correct \" , upper , threshold , as opposed to the  incorrect \" , lower , threshold for the spike integrator . unlike the independent case ,",
    "the time evolution of the spike integration process is not simply a scaled version of the sprt ( though they are clearly similar ) under either model of correlations.,width=576 ]",
    "we now study the impact of subtractive ( mip ) correlations on decision making performance .",
    "as noted above , recall that within a time window @xmath9 , the spike counts from each neuron form a vector of random variables which are independent from window to window .",
    "these independent vectors provide the evidence for each of the two alternatives , which is then weighed via log - likelihood at each step in sprt . in appendices [ sec : mgf_sprt ] and [ sec :",
    "mipsprtappendix ] , we compute the values @xmath31 and @xmath52 $ ] that define the speed and accuracy of the sprt ( see equations  [ eq : fc]-[eq : rt ] ) , for two pools with subtractive ( mip ) correlations . as this computation is done in continuous time , it is natural to take @xmath53 ; doing so , we find :    @xmath54    @xmath55 =   \\frac{1-(1-\\rho)^n}{\\rho}(\\lambda_p-\\lambda_n)\\log \\frac{\\lambda_p } { \\lambda_n } \\delta t+o(\\delta t^2 ) \\label{eq : mipsprtez}\\ ] ]    comparing these values against those of the independent sprt given in equations [ eq : indsprth0 ] and [ eq : indsprtez ] , we see that the only effect of correlations is a scaling of the expected increment via @xmath56 . in the limit as @xmath46 ,",
    "this scale factor approaches n , which in turn reduces decision time ( the scale factor is inversely proportional to @xmath26 via equation [ eq : rt ] ) .",
    "on the other hand , as @xmath57 , the scale factor itself approaches 1 ; this agrees with the intuition that as all neurons become perfectly redundant , the performance should resemble that of a single neurons .",
    "in fact , the mechanism of the sprt on a given sample can be seen as inferring the firing rate of the correlating train from a derived vector of noisy random variables . as @xmath7 gets large , then",
    ", performance should be limited by performing an sprt on the correlating  mother \" trains themselves .",
    "this is precisely what happens when @xmath58 in equation [ eq : mipsprtez ] : we obtain @xmath52 \\sim \\frac{1}{\\rho}(\\lambda_p-\\lambda_n)\\log \\frac{\\lambda_p } { \\lambda_n } \\delta t,$ ] corresponding to decision making based on mother spikes of rate @xmath59 and @xmath60 .",
    "one consequence of this interpretation is that the particular realization of a spike vector ( in a sufficiently small time - bin @xmath9 ) carries no evidence about the decision of @xmath21 vs. @xmath61 , beyond its identity as either the zero vector @xmath62 or not .",
    "of course , this is a consequence of the construction of the mip model , as the spike deletions that create the realization of the spike vector have no dependence on the firing rate of the population .",
    "concretely then , the increments ( or decrements ) are based solely on whether the vector of spikes in the preferred ( or null ) pool contains any spikes at all ; the actual number of spikes is irrelevant in the sprt .",
    "it follows that the accumulation process @xmath28 is a discrete - space random walk , with steps @xmath63 . to see this , note that",
    "for sufficiently small @xmath9 , there are only three possibilities for how spikes will be emitted from the two populations .",
    "first , both the preferred and null pools could produce no spikes .",
    "this event provides no information to distinguish the firing rates of the pools , so the increment is 0 .",
    "second , one of the pools could produce a vector of spikes caused by iid deletions from the  mother \" spike train .",
    "if the spiking pool is the preferred one , each possible nonzero spike vector will increment the accumulator by the @xmath64 of the ratio @xmath65 ; the opposite sign occurs if the null pool spikes . events in which both pools spike are of higher order in @xmath9 , and thus become negligible for small time windows .",
    "the discrete nature of the sprt effect causes the @xmath27 curve in figure [ fig : mipsprt](a ) to take on only discrete values of accuracy ; a small increase in @xmath34 above a multiple of @xmath66 will not improve accuracy because @xmath28 on the final , threshold - crossing - step will overshoot the threshold .",
    "this also explains why some of the @xmath27 values at a given @xmath34 do not lie on the theoretical line defined by equation @xmath67 ; that equation is only exactly true in the case of zero overshoot past the threshold .",
    "we will return to this point later , and also in appendix [ sec : overshootappendix ] .",
    "we next insert the values for @xmath31 and @xmath52 $ ] computed above into equations [ eq : fc ] and [ eq : rt ] , and plot the resulting speed - accuracy curves relating @xmath26 and @xmath27 parametrically in the threshold @xmath34 ( figure [ fig : mipsprt](b ) ) .",
    "( we plot the full @xmath27 and @xmath36 functions , although only discrete values of performance along each of the lines are achievable in practice , as indicated by the dots for the @xmath48 case ; see caption ) . by comparing speed - accuracy curves for different values of @xmath17 ranging from 0 to 0.3",
    ", we see our first main result : _ introducing mip correlations within neural populations substantially diminishes the best - possible decision performance , that obtained via the sprt .",
    "_ we will next derive the analogous results for the simpler spike integration model .    , @xmath68 ) .",
    "( a ) the discrete nature of the sprt diffusion process implies that only discrete values of accuracy are possible .",
    "these occur at values of @xmath34 that are multiples of @xmath69 .",
    "( similar results hold for decision time , not shown . )",
    "the solid dots are simulations of the sprt , and gray dots are exact values taken at multiples of the log ratio ; the interpolating line is equation [ eq : fc ] .",
    "( b ) accuracy ( equation [ eq : fc ] ) and decision time ( equation [ eq : rt ] ) are plotted parametrically as a function of threshold , for 8 different values of @xmath17 ( linearly spaced on [ 0,.35 ] with the a double - thickness line at @xmath70 ) .",
    "performance of the simulation at multiples of the log - ratio of firing rates are plotted as solid dots , and theoretical values in gray ( gray dots are enlarged to be distinguished).,width=576 ]       and [ eq : rt ] despite overshoot past past the decision threshold .",
    "( a ) gray lines are reproductions of speed accuracy curves from the sprt ( figure [ fig : mipsprt ] ) , and black lines are speed accuracy curves for spike integration .",
    "( b , c ) overshoot past the decision boundaries reduces the validity of wald s approximations , but a constant shift in threshold can help mitigate the effect ( see @xcite and appendix [ sec : overshootappendix ] ) .",
    "such a shift is automatically accounted for when comparing curves that are parametric in @xmath34 ( panel a , for example).,title=\"fig:\",width=288 ] [ fig : mipsi ]    next , we consider decision making performance for the simpler model in which spikes are simply integrated over time , as opposed to the likelihood ratio computation of the sprt . in this case , the moment generating function of the difference in spike counts from the two pools is more straightforward ( see appendix [ sec : mipsiappendix ] ) , and provides an easy computation of @xmath52 $ ] : @xmath55=\\delta t n\\left ( \\lambda_p-\\lambda_n \\right ) \\label{eq : mipsiimplicitez}\\ ] ] the nontrivial root of the mgf @xmath31 is found to be the implicit solution of : @xmath71 here we see that correlations only impact the performance of the model through changing @xmath31 , as the expected increment is the same is in the independent case ( equation [ eq : uncorrsiez ] ) .",
    "moreover , performance under spike integration is diminished to a degree that is comparable to the performance loss of sprt . to illustrate this , figure [ fig : mipsi]a plots the speed - accuracy tradeoff curves from both models of decision making under subtractive correlations , for the same values of @xmath17 . as we must (  @xcite ) , we see the optimal character of the sprt in the fact that at a given level of accuracy , the sprt requires , on average , fewer samples than spike integration . however , the difference is very slight .",
    "this yields our next main result , that _ nearly optimal decisions are produced by the simple operation of linear integration over time for the mip model of spike correlations across neural populations . _    having established this , we pause to note a subtlety in our analysis . figures [ fig : mipsi]b and c show @xmath27 and @xmath26 as a function @xmath34 , for both simulated data and plots of equations @xmath67 and [ eq : rt ] .",
    "the solid lines are the graphs of those equations as written ( using the values for @xmath31 and @xmath52 $ ] in equations [ eq : mipsiimplicith0 ] and [ eq : mipsiimplicitez ] ) , and the mismatch between the lines and the data are a consequence of overshoot past the threshold .",
    "the broken line is a graph of the same formulas , with a shift in @xmath72 , an offset computed as the sample mean of the overshoot distribution ( see figure [ fig : overshootmip ] as well as the discussion in appendix [ sec : overshootappendix ] ; also @xcite ) .",
    "this correction term helps the @xmath27 and @xmath26 equations better approximate the data when there is potential overshoot .",
    "interestingly , however , parametric plots like figure [ fig : mipsi]a already take this effect into account .",
    "as described in section [ s.corr ] , the additive ( sip ) model of spike train correlations also utilizes a common spike train to generate correlations , but does so in a manner that gives a distinct population - wide correlation structure .",
    "we now derive the consequences for decision making performance under the sprt . in appendices [ sec : mgf_sprt ] and [ sec : sipsprtewappendix ]",
    "we find the expressions for the parameters of the @xmath27 and @xmath26 curves , as the window size @xmath73 : @xmath54 @xmath55 = \\left(n(1-\\rho)+\\rho\\right )   ( \\lambda_p-\\lambda_n ) \\log \\frac{\\lambda_p } { \\lambda_n}\\delta t+o(\\delta t^2 ) \\label{eq : sipsprtez}\\ ] ] comparing these with equations [ eq : indsprth0 ] and [ eq : indsprtez ] , we see that , as in the subtractive ( mip ) correlations model , the only difference with the independent case is a scaling factor on the average increment @xmath52 $ ] in equation [ eq : sipsprtez ] .",
    "to explain the form of the scale factor , note that the spike vector from each pool is composed of @xmath7 independent spike trains firing at rate @xmath74 , and a single ( highly redundant ) spike train firing at a rate @xmath75 .",
    "as in the subtractive ( mip ) model , @xmath28 here also becomes a discrete random walk with increment @xmath76 .",
    "this can be seen by noting that for either pool , in a sufficiently small @xmath9 window , only one of two events is possible : ( i ) no spikes occur at all , or ( ii ) a single spike occurs in one neuron , in one of the two pools .",
    "the first case is uninformative about either @xmath21 or @xmath61 .",
    "the second case occurs with probability @xmath74 under @xmath21 and @xmath74 under @xmath61 ( here @xmath77 if the spike occurred in the preferred pool , for example ) ; taking the log ratio , we find our increment is independent of correlations . the resulting decision accuracy ( fc ) is plotted vs. threshold in figure [ fig : sipsprt]a , and is qualitatively similar to the subtractive ( mip ) correlations case , with plateaus following from the discrete nature of @xmath28 .",
    "however , the speed - accuracy tradeoff pictured in figure [ fig : sipsprt]b is very different from that found in the subtractive ( mip ) model .",
    "in particular , we see our third main result : _ the impact of additive correlations on optimal ( sprt ) decision performance is relatively minor . _ for example , in the presence of pairwise correlations as strong as @xmath78 , the mean decision time required to reach a typical value of accuracy is increased by only a few milliseconds compared with the independent case , instead of by hundreds of milliseconds as for subtractive correlations .",
    "equation [ eq : sipsprtez ] offers an intuitive explanation for this fact : @xmath52 $ ] is inversely proportional to @xmath26 , and does not diminish nearly as fast for sip correlations than mip correlations ( cf . equation [ eq : mipsprtez ] ) .",
    "gives the same accuracy as the subtractive ( mip ) correlations case ( figure [ fig : mipsprt]a ) _ at each value of @xmath34 . _ because of the absence of overshoot , the @xmath27 and @xmath26 relationships can be applied exactly .",
    "( b ) however , the resulting speed - accuracy curves are very different . in particular",
    "the impact of correlations on the speed - accuracy tradeoff is much smaller than for subtractive correlations ( cf .",
    "figure [ fig : mipsprt]b , noting that here the abscissa ranges up to 30 ms , in contrast to 800 ms ) . here",
    "only @xmath79 and @xmath80 are plotted for clarity.,width=576 ]       and @xmath52 $ ] from equations [ eq : sipsih0maintext ] and [ eq : sipsiezmaintext ] ( and thereby assuming no overshoot of the decision threshold ) .",
    "performance is similar to the subtractive - correlations case ( broken gray lines ) , and significantly worse than performing sprt on additive - correlated inputs ( solid gray lines ) .",
    "( b ) at @xmath48 , for example , major differences arise between this theory ( again , solid black line , reproduced from a ) and simulation of the model ( dots ) , especially at short reaction times .",
    "this is a consequence of significant overshoot of @xmath28 over the decision threshold , on the threshold crossing step .",
    "( inset ) at short reaction times , the simulations actually perform closer to the sprt ( gray line , reproduced from figure [ fig : sipsprt]a ) ; see text.,width=576 ]    what about the ability of the simple spike integrator to perform decision making when confronted with additive correlations ? proceeding as in the subtractive - correlations case , we derive an implicit relationship for @xmath31 , and the expected increment @xmath52 $ ] : @xmath81 @xmath55=\\delta t n\\left ( \\lambda_p-\\lambda_n \\right ) \\label{eq : sipsiezmaintext}\\ ] ] by comparing with ( equation [ eq : uncorrsiez ] ) , we see that , as for spike integration in the subtractive ( mip ) case , correlation affects only the value of @xmath31 and not the expected increment . substituting these values into equations [ eq : fc ] and [ eq : rt ]",
    ", we then plot the speed - accuracy tradeoff curves for this model _ under the assumption of no overshoot _ in figure [ fig : sipsi]a .",
    "it appears that , when decisions are made via spike integration , correlations impact performance quite significantly ( black lines ) , in contrast to the sprt case ( solid gray lines , reproduced from figure [ fig : sipsprt]b ) .",
    "overall , the degree of performance loss is comparable to that under subtractive correlations ( broken gray lines , reproduced from figure [ fig : mipsi]b ) .",
    "this is our fourth main result : _ for additive correlations , if decisions are made via spike integration instead of the sprt , correlations have a significant impact on reducing decision performance . _    however , the assumption that integrated spikes do not overshoot the decision threshold might seem suspect under the additive model of correlations , as there is a possibility that the threshold crossing step might occur as a result of every neuron in a pool simultaneously spiking at once .",
    "in fact , when the number of neurons in the pool is large ( as in the cases we consider ) , additive correlations can indeed cause significant overshooting of thresholds ; importantly , and unlike for subtractive ( mip ) correlations , this effect can not be compensated via a constant offset in the decision threshold .",
    "figure [ fig : sipsi]b demonstrates the consequences for the speed - accuracy tradeoff . here ,",
    "when the spike integration model is simulated directly , we see a surprising non - monotonic relationship between @xmath27 and @xmath26 in the presence of additive correlations of strength @xmath48 .",
    "this violates the usual intuition of that accuracy should increase at slower decision speeds .",
    "the explanation comes from the fact that , as the decision threshold is raised increases , @xmath26 correspondingly increases while accuracy suffers  a consequence of not finishing a trial before a ( relatively rare ) spike in a correlating spike train in one of the two pools causes the accumulator to jump far beyond the threshold .     indicates the distribution of @xmath82 conditioned on crossing the upper threshold",
    "( similar results for the lower threshold are not shown ) .",
    "the probability mass function ( pmf ) of @xmath83 varies as a function of @xmath34 , and two vertical slices through this density are shown at @xmath84 and @xmath85 .",
    "here the overshoot distributions are discrete , due to the integral nature of the increment distribution . for plotting purposes ,",
    "the vertical axis has been split in the sip case , to allow plotting of the outlier point at zero .",
    "the black line indicates @xmath86 $ ] as @xmath34 varies ; crucially , this quantity varies significantly and for higher values of @xmath34 under sip correlations , resulting in the non - monotonic speed - accuracy tradeoff pictured in figure [ fig : sipsi].,width=576 ]    for large thresholds , the sequential sampling theory of equations [ eq : fc ] and [ eq : rt ] , which assume no overshoot , accurately approximates the simulated data ; however for low values of @xmath34 the approximation is poor .",
    "in fact , the inset to figure [ fig : sipsi]b shows that in this regime , the decision making performance of the spike integration model is far better described by the theory predicted by the sprt .",
    "the intuition behind this observation is that for short reaction times , there is a small probability of a shared spike that will send the integrator significantly over the threshold .",
    "this allows accumulation to occur one spike at a time ( for sufficiently small @xmath9 ) , where each spike arrives from an independent spike train . as we have seen , the process of integrating independent spikes is equivalent to the sprt .",
    "it is only at longer decision times , when the chances of having integrated a large common spike event are larger , that a significant impact of correlations appears .",
    "figure [ fig : nonlinearity ] provides further evidence for this scenario .",
    "density plots of the distribution of the overshoot @xmath87 ( conditioned on crossing the upper threshold ) , for both additive ( sip ) and subtractive ( mip ) correlations are shown as a function of the decision threshold , with particular overshoot distributions plotted at @xmath84 and @xmath85 .",
    "for the additive correlations model , a significant fraction of the trials terminate with zero overshoot at low values of @xmath34 ( because , for example , large correlating events are relatively rare ) , implying that many trials underwent optimal accumulation of evidence , without experiencing a common , correlating spike event as discussed above .",
    "overall , the monotonic dependence of accuracy ( fc ) on decision time ( @xmath26 ) follows from the invariance of the moments of the overshoot distribution relative to changes in the threshold value @xmath34 ; this is particularly true for the first moment ( see appendix [ sec : overshootappendix ] ) .",
    "figure [ fig : nonlinearity](sip ) demonstrates that these moments continue to fluctuate over a larger range of @xmath34 , and with larger magnitude , for the additive correlations model .",
    "this serves to explain the strange shape of the speed - accuracy tradeoff curve pictured in figure [ fig : sipsi]b that ( unlike the subtractive correlations model ) can not be explained by a constant shift in @xmath34 .",
    "this stands in direct contrast to the optimality of linear summation in the zero - correlations case .",
    "( c ) a nonlinear computation also appears as a consequence of the additive correlations model , however the nonlinearity is much less severe than in the subtractive model .",
    "( all results pictured hold in the case of vanishing @xmath9.),width=576 ]    ) .",
    "( b ) spike integration with this nonlinearity is suggested by figure [ fig : nonlinearity]c , and recovers performance of the decision making model ( black dots ) to agreement with the results of sprt ( gray line ) . without this nonlinearity to discount shared events , performance suffers ( gray dots , reproduced from figure [ fig : sipsi]b , inset),width=576 ]    when the neurons in each pool spike independently , zhang and bogacz @xcite demonstrated that linear summation of spikes across the two pools at each time step implements the sprt . because the sprt is optimal in the sense of minimizing @xmath26 for a prescribed level of @xmath27 , the conclusion is that linear integration of spikes across pools , and then across time , provides an optimal decision making strategy . however , is this optimality of linear integration confined to the case of independent activity within the pool ?",
    "above , we showed that when correlations are introduced into this model , it is no longer true that each spike should be given the same  weight \" , as in linear integration .",
    "moreover , knowing only the pairwise correlations and firing rates alone does not allow one to write down a rule for the function that should be applied to incoming spikes in order to implement the sprt , although in these cases this function takes the form of the difference between the result of a nonlinearity applied to both pools .",
    "this dependence on higher order statistics is demonstrated in figure [ fig : nonlinearity ] by the fact that the nonlinearities for mip correlations ( panel b ) and sip correlations ( panel c ) take a significantly different form .    for mip correlations ,",
    "the nonlinearity pictured in figure [ fig : nonlinearity]b that implements the sprt ( up to a change in threshold ) takes the form : @xmath88 @xmath89 at first glance , it is surprising that such a severe nonlinearity , applied to two mip - correlated spiking pools , results in nearly the same performance is simple spike integration ( c.f .",
    "figure [ fig : mipsi ] ) .",
    "the intuition here is that optimal inference requires essentially performing spike integration on the correlating spike train , as no information about the firing rate is added through spike deletions .",
    "this random walk on one of three cases ( -1,0 , or + 1 ) is approximated by linear integration , in the limit as the size of the pool ( @xmath7 ) increases .",
    "another perspective on the nonlinearities that enable optimal computation is that they leverage knowledge about the mechanism of correlations , to improve performance . in the sip model , the nonlinear function depicted in figure [ fig : nonlinearity]c is , as in the mip case , a consequence of applying a nonlinearity to each pool , and then subtracting .",
    "however , in this case , the form is not as drastic  a shared spike event coming from the correlating train only registers as a single spike : @xmath90 @xmath91 intuitively , this strategy uses the fact the a simultaneous spike in every neuron in a pool only has one explanation for a sufficiently small window of integration , and therefore uses the correlating spike train as an additional independent input in the likelihood ratio . at low values of @xmath34 ,",
    "this does not confer much of an advantage ; however as the threshold increases , higher accuracy is achievable at much shorter decision times .",
    "the nonlinearity is pictured figure [ fig : sipsinonlinear]a , and also offers an intuition as to why , for low threshold values , spike integration performs almost optimally : when spikes from the correlating train are rare ( or can be properly weighted ) , spike integration implements sprt ( figure [ fig : sipsinonlinear]b ) .",
    "neurons is constant for all @xmath92 . in contrast",
    ", the joint cumulants of the subtractive ( mip ) model decay geometrically as the pool size increases , and this difference helps to characterized the differences in higher - order correlations between the two models .",
    "( see appendix [ sec : jointcumulantappendix ] for supplementary computations.),width=288 ]    correlated spiking among the neurons that encode sensory evidence appear ubiquitous .",
    "such correlations might arise arise from any number of neuroanatomical features  the simplest being overlapping feedforward connectivity which can cause collective fluctuations across a population  @xcite .",
    "they can also result from sensory events that impact an entire population , or from rapid modulatory effects .",
    "moreover , for large neural populations it appears that accurate descriptions of population - wide activity can require more than the typically measured pairwise correlations , but higher order interactions as well  @xcite .",
    "the aim of our study is to improve our understanding of how correlated activity in these populations can impact the speed and accuracy of decisions that require accumulating sensory information over time . faced with the wide range of possible mechanisms and structures of correlations alluded to above , we choose to focus on two models for population - wide correlations that illustrate a key distinction in how correlations can occur .",
    "these models have identical first - order and pairwise statistics , but differ in how each common spiking events either involves a small subset of the neurons ( the subtractive , mip case ) or each neuron in the pool ( the additive , sip case ) @xcite .",
    "figure [ fig : cumulant ] quantifies this difference : based on calculations in appendix [ sec : jointcumulantappendix ] , we plot the joint cumulant across @xmath93 neurons in a pool under both subtractive ( mip ) and additive ( sip ) correlations . while the additive model possesses a constant joint cumulant no matter how many neurons",
    "are included , the joint cumulant of @xmath93 neurons falls off geometrically for the subtractive case .",
    "we conjecture that this is a statistical signature that could suggest when other , more general patterns of correlated activity  measured experimentally or arising in mechanistic models of neural circuits",
    "@xcite  will produce similar effects on decisions . exploring this conjecture via models and",
    "data is a target of our future research .",
    "we summarize our main findings are as follows . for both models of correlated spiking , decisions produced by a simple , linear spike integration model ( i.e. , a neural integrator ) become slower and less accurate as correlations increase",
    ". however , a strong difference appears for decisions made via the optimal decision strategy ( sprt ) . here , additive correlations have only a minor impact on decision performance , while subtractive correlations continue to strongly diminish this performance .",
    "the conclusion is that decision making circuits , faced with subtractive ( mip ) correlated sensory populations , will invariably produce diminished decision performance , and stand little to gain by implementing computations more complex that a simple integration of spikes over time and neurons .",
    "however , in the presence of additive ( sip ) correlations , circuit mechanisms that implement or approximate the sprt  perhaps via a nonlinearity such as that shown in fig .  [",
    "fig : sipsinonlinear ] applied to the sum of incoming spikes  stand to produce substantially better decision performance than their linear counterparts .",
    "in other contexts , nonlinear computations have also been shown to improve discrimination between two alternatives .",
    "field and rieke @xcite demonstrated the importance of a thresholding nonlinearity in pooling the responses of rod cells , where this nonlinearity served to reject  background \" noise .",
    "closer to the present setting , gating inhibition that prevents accumulation of noise samples before the onset of evidence - encoding stimulus can account for visual search performance @xcite , and recent results suggest that related nonlinearities can improve performance for mistuned neural integrators ( @xcite , see also @xcite ) .    our cases in which correlations decrease performance  in particular , when spikes are linearly integrated  are consistent with several prior studies of the role of correlated activity in decision making  @xcite .",
    "we note , however , two differences in our models .",
    "the first is the mechanism through which correlated spikes are generated ; while we use additive and subtractive models based on poisson processes , the authors of  @xcite use a multivariate gaussian description of spike counts .",
    "the second is that in @xcite , decisions are rendered after a duration that is fixed before the trial begins ( either a single duration ,  @xcite , or one that is drawn from a distribution of reaction times , in  @xcite ) .",
    "this is different from the setting here , where incoming signal on each trial determines the reaction time through a bound crossing .",
    "our result , in the case of subtractive ( mip ) correlations , that linear integration of spikes closely approximates the optimal decision making strategy is similar to findings of beck et al .",
    "specifically , they model a dense range of differently tuned populations , and find that optimal bayesian inference can be based on linear integration of inputs , for a wide set of correlation models . our additive ( sip ) case , however , behaves differently , as nonlinearities are needed to achieve the optimal strategy .",
    "an aim of future work is extending the setting of our study to include tuning curves as in  @xcite .",
    "this is more realistic for many decision tasks ( including the direction discrimination task ) , and will also allow progress toward models with multiple decision alternatives .",
    "an important challenge will come from defining pairwise correlations that vary as a function of preferred tuning orientation ( see @xcite ) , while also including the full structure of correlating events across multiple cells in a realistic way .",
    "for example , in the present paper , additive correlating events occurred independently in the two populations ; future work could take a more graded approach , in which some events impact the entire sensory population ( i.e. , as in an eyeblink or possibly an attentional shift during a visual task ) .    as long as each neuron remains modeled as a poisson point process",
    ", the sequential accumulation theory utilized here will carry over directly .",
    "this points to another limitation of the present study and opportunity for future work .",
    "this is the lack of temporal correlations in the statistics of the inputs .",
    "a model of correlations that includes spikes from a correlating train that are temporally jittered @xcite could provide a starting place for a model of the input trains , however defining updates to the likelihood ratio for the two competing hypotheses will be more difficult .",
    "nevertheless , it will be interesting to see how our results carry over ; in particular , there will be many more different combinations of spike events that will contribute to increments for both spike integration and sprt decision models .",
    "while we therefore view the present study as a first step in exploring many possibilities , our findings demonstrate how the population - wide structure of correlations  beyond pairwise correlation coefficients  can strongly impact the speed and accuracy of decisions , and the circuit operations necessary to achieve optimal performance .",
    "this suggests that multi - electrode and imaging technologies , together with theoretical work on neural coding , will continue to play an exciting role in understanding the structure of basic computations like decision making over time .",
    "[ [ acknowledgements ] ] acknowledgements : + + + + + + + + + + + + + + + + +    we thank yu hu , adrienne fairhall , and michael shadlen for their valuable comments on the manuscript .",
    "we gratefully acknowledge the support of a career award at the scientific interface from the burroughs welcome fund and nsf grant career dms-1026125 ( e. s. b. ) , and the university of washington escience institute s hyak computer cluster .",
    "the nontrivial real root of the moment generating function ( mgf ) of a sampling distribution is critical to finding @xmath27 and @xmath26 of an independently sampled sequential hypothesis test ( via equations [ eq : fc ] and [ eq : rt ] ) . for the sprt",
    ", the increment distribution is given in equation [ eq : sprtsamplingrv ] as : @xmath94 }         { p[{\\boldsymbol{s^i_p}},{\\boldsymbol{s^i_n}}|h_0 ] }             \\right ] \\label{eq : sprtsamplingrvappendix}\\ ] ] the  correct \" hypothesis @xmath21 is in the numerator in order to orient a crossing of the positive decision threshold with a correct choice . correspondingly , the probability of observing a _ given _",
    "sample @xmath95,@xmath96 is known from assumption of this hypothesis , and by definition follows the distribution : @xmath97=p[{\\boldsymbol{s^i_p}}|h_1]p[{\\boldsymbol{s^i_n}}|h_1],\\ ] ] where the independence assumption of the spike count vectors from the two separate pools @xmath95 and @xmath96 have allowed the factoring of the distribution . dropping the sampling index @xmath98 for notational convenience , the mgf",
    "can then be computed as : @xmath99=\\sum_{{\\boldsymbol{s_p}},{\\boldsymbol{s_n } } } p[{\\boldsymbol{s_p}}|h_1]p[{\\boldsymbol{s_n}}|h_1 ] \\left (      \\frac{p[{\\boldsymbol{s_p}}|h_1]p[{\\boldsymbol{s_n}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]p[{\\boldsymbol{s_n}}|h_0 ] }         \\right)^{s}\\ ] ] the nontrivial root ( @xmath100 ) can then be seen by inspection ( cf . equation [ eq : indsprth0 ] ) : @xmath101 we note that this computation is fully general , without any assumptions on the structure of correlations both within and across pools .",
    "the other parameter of the sampling distribution critical to computing the @xmath27 and @xmath26 functions , @xmath52 $ ] , is computed for independent spike count distributions ( @xmath70 , cf .",
    "[ eq : indsprtez ] ) as follows ( see also @xcite ) : @xmath55=\\sum_{{\\boldsymbol{s_p}},{\\boldsymbol{s_n } } } p[{\\boldsymbol{s_p}}|h_1]p[{\\boldsymbol{s_n}}|h_1 ] \\log\\left [     \\frac{p[{\\boldsymbol{s_p}}|h_1]p[{\\boldsymbol{s_n}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]p[{\\boldsymbol{s_n}}|h_0 ] }         \\right]\\ ] ] @xmath103p[{\\boldsymbol{s_n}}|h_1 ]       \\left (          \\log      p[{\\boldsymbol{s_p}}|h_1]+          \\log      p[{\\boldsymbol{s_n}}|h_1]-          \\log      p[{\\boldsymbol{s_p}}|h_0]-          \\log      p[{\\boldsymbol{s_n}}|h_0 ]      \\right)\\ ] ] @xmath104 \\log      p[{\\boldsymbol{s_p}}|h_1]+        \\sum_{{\\boldsymbol{s_n } } } p[{\\boldsymbol{s_n}}|h_1 ] \\log    p[{\\boldsymbol{s_n}}|h_1 ] \\\\      & & -   \\sum_{{\\boldsymbol{s_p } } } p[{\\boldsymbol{s_p}}|h_1 ] \\log     p[{\\boldsymbol{s_p}}|h_0]-        \\sum_{{\\boldsymbol{s_n } } } p[{\\boldsymbol{s_n}}|h_1 ] \\log    p[{\\boldsymbol{s_n}}|h_0 ] \\label{eq : preind}\\end{aligned}\\ ] ] @xmath105}{p[s_p|h_0]}|h_1\\right ] +              e\\left[\\log \\frac{p[s_n|h_1]}{p[s_n|h_0]}|h_1\\right ]           \\right ) \\label{eq : postind}\\ ] ] @xmath106 @xmath107 when this quantity is substituted into equation [ eq : rt ] , the @xmath9 will cancel off , implying that @xmath26 is not a function of the sampling increment size .",
    "we compute this quantity for correlated spike count distributions next .",
    "when neurons within pools are correlated , the joint pdf of the spike count vector is no longer decomposable into the product of the marginal distributions ( the critical step between equations [ eq : preind ] and [ eq : postind ] ) .",
    "however , an expression for @xmath52 $ ] can be obtained in the limit as @xmath53 , by repeatedly expanding via taylor series about @xmath108 throughout the computation .",
    "first , we simplify the expression for the expected increment by using the independence of the two pools : @xmath55 = e\\left[\\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]}|h_1\\right ]           + e\\left[\\log \\frac{p[{\\boldsymbol{s_n}}|h_1]}{p[{\\boldsymbol{s_n}}|h_0]}|h_1\\right ] \\label{eq : twopartssipsprt}\\ ] ] next we expand each term to first order in @xmath9 ; below , we only demonstrate the expansion for the  preferred \" population ; the calculation for the null pool follows by exchanging @xmath2 and @xmath3 . in that case , by using the law of total expectation conditioned on the number of spikes in the common spike train  shared \" across the pool @xmath109 ( which spikes at a rate @xmath110 ) , we have : @xmath111}{p[{\\boldsymbol{s_p}}|h_0]}|h_1\\right ]       = e\\left[e\\left[\\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p , h_1\\right]|h_1\\right]\\ ] ] @xmath112 e\\left[\\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=\\hat{s}_p , h_1\\right ] \\label{eq : lastequivalenteqn}\\ ] ] @xmath113}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=0,h_1\\right]+      \\delta t\\lambda_p e\\left[\\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=1,h_1\\right]+      o(\\delta t^2 ) \\label{eq : sipsprtfirstexpansion}\\ ] ] taking the case of @xmath114 , @xmath111}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=0,h_1\\right ]      = \\sum_{{\\boldsymbol{s_p } } } p[{\\boldsymbol{s_p}}|\\hat{s}_p=0,h_1 ] \\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0 ] } \\label{eq : sipderiv1}\\ ] ]    the aim here is to take advantage of the conditioning ; because the spike counts of neurons within the same pool are conditionally independent , given the number of spikes in the correlating spike train , the joint distribution across the vector @xmath115 becomes the product of the conditioned marginal distributions .",
    "however , this is only true for the first factor in the summand of equation [ eq : sipderiv1 ] . to continue , we must expand the log - ratio of the probability distributions , using the law of total probability , in @xmath9 : @xmath116 & = & \\sum_{\\hat{s}_p}^{\\infty}p[\\hat{s}_p|h_1]p[{\\boldsymbol{s_p}}|\\hat{s}_p=\\hat{s}_p , h_1]\\\\      & = & ( 1-\\rho\\lambda_p\\delta t)p[{\\boldsymbol{s_p}}|\\hat{s}_p=0,h_1 ] +       \\rho\\lambda_p\\delta t p[{\\boldsymbol{s_p}}|\\hat{s}_p=1,h_1 ] + o(\\delta t^2)\\end{aligned}\\ ] ] @xmath117 & = & \\sum_{\\hat{s}_p}^{\\infty}p[\\hat{s}_p|h_0]p[{\\boldsymbol{s_p}}|\\hat{s}_p=\\hat{s}_p , h_0]\\\\      & = & ( 1-\\rho\\lambda_n\\delta t)p[{\\boldsymbol{s_p}}|\\hat{s}_p=0,h_0 ] +       \\rho\\lambda_n\\delta t p[{\\boldsymbol{s_p}}|\\hat{s}_p=1,h_0 ] + o(\\delta t^2 ) \\end{aligned}\\ ] ] moreover , the @xmath10term summation in equation [ eq : sipderiv1 ] need only be over @xmath118 , as higher values will produce contributions of higher than first order in @xmath9 .",
    "two cases emerge for the expansion : if @xmath119 for any @xmath98 , @xmath120 = p[{\\boldsymbol{s_p}}|\\hat{s}_p=1,h_0 ] = 0 $ ] , and we have : @xmath121}{p[{\\boldsymbol{s_p}}|h_0 ] } =          \\log \\frac{p[{\\boldsymbol{s_p}}|\\hat{s}_p=0,h_1]}{p[{\\boldsymbol{s_p}}|\\hat{s}_p=0,h_0 ] } \\label{eq : sprtsiprecycle}\\ ] ] on the other hand , if @xmath122 for all @xmath98 , we can compute the expression directly via total probability , as there are only four possible ways for the event to originate ; to first - order in @xmath9 , this is : @xmath123}{p[{\\boldsymbol{s_p}}={\\boldsymbol{1}}|h_0 ] } & = & \\sum_{i=0}^1\\sum_{\\hat{s}_p=0}^1 p[{\\boldsymbol{s_p}}={\\boldsymbol{1}}|\\hat{s}_p=\\hat{s}_p , h_i]p[\\hat{s}_p=\\hat{s}_p , h_i ] \\\\      & = & \\rho ( \\lambda_p+\\lambda_n ) \\delta t + o(\\delta t^n)\\end{aligned}\\ ] ] therefore , this single element of the sum offers no order one contribution ( it is multiplied by @xmath124 $ ] which is itself is o@xmath125 ) ; thus , @xmath126\\log \\frac{p[{\\boldsymbol{s_p}}|\\hat{s}_p=0,h_1]}{p[{\\boldsymbol{s_p}}|\\hat{s}_p=0,h_0 ] } = n(1-\\rho)\\delta t \\left ( \\lambda_n - \\lambda_p+\\lambda_p \\log \\frac{\\lambda_p}{\\lambda_n}\\right ) + o(\\delta t^2)\\label{eq : sipsprtfirstpart}\\ ] ] the case of @xmath127 is simpler , as only zero - order terms must be kept ( due to the coefficient in equation [ eq : sipsprtfirstexpansion ] ) . recycling the expansion from equation [ eq : sprtsiprecycle ]",
    ", we have that to zero - order : @xmath111}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=1,h_1\\right ]      = \\sum_{{\\boldsymbol{s_p } } } p[{\\boldsymbol{s_p}}|\\hat{s}_p=1,h_1 ] \\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0 ] } = \\log \\frac{\\lambda_p}{\\lambda_n } + o(\\delta t ) \\label{eq : sprtsiplast}\\ ] ] finally , combining equations [ eq : sipsprtfirstexpansion ] , [ eq : sipsprtfirstpart ] , and [ eq : sprtsiplast ] , we have that : @xmath128}{p[{\\boldsymbol{s_p}}|h_0]}|h_1\\right ] & = &        ( 1-\\rho \\lambda_p \\delta t )       \\left (           n(1-\\rho)\\delta t \\left ( \\lambda_n - \\lambda_p+\\lambda_p \\log \\frac{\\lambda_p}{\\lambda_n}\\right ) + o(\\delta t^2 )       \\right ) \\\\       & + &        \\delta t \\rho \\lambda_p       \\left (           \\log \\frac{\\lambda_p}{\\lambda_n } + o(\\delta t^2 )       \\right)\\end{aligned}\\ ] ] repeating the exercise for the other component of equation [ eq : twopartssipsprt ] amounts to exchanging  @xmath129 \" for  @xmath130 \" ; adding everything together gives the final result , to first - order in @xmath9 : @xmath55 = \\left(n(1-\\rho)+\\rho\\right ) \\delta t ( \\lambda_p-\\lambda_n ) \\log \\frac{\\lambda_p } { \\lambda_n}+o(\\delta t^2)\\ ] ] we note here that as @xmath46 and @xmath57 , we reproduce the results that would be expected from equation [ eq : poissonuncorrsprtrt ] . also , a more intuitive and tractable computation can be done for an analogous additively - correlated bernoulli process , resulting in the same solution .      in the case of subtractive correlations within pools ,",
    "the derivation of @xmath52 $ ] is the same as the additive correlation case , up to equation [ eq : lastequivalenteqn ] . in this case , however , we now have : @xmath55=(1-\\frac{\\lambda_p}{\\rho}\\delta t)e\\left[\\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=0,h_1\\right]+      \\frac{\\lambda_p}{\\rho } \\delta t e\\left[\\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=1,h_1\\right]+      o(\\delta t^2 ) \\label{eq : mipsprtmaineq}\\ ] ] taking the @xmath114 case first , we notice that it is impossible for any spikes to occur without a spike in the correlating spike train : @xmath131=0\\ ] ] because of this , we can simplify : @xmath128}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=0,h_1\\right ] & = & p[{\\boldsymbol{0}}|\\hat{s}_p=0,h_1]\\log \\frac{p[{\\boldsymbol{0}}|h_1]}{p[{\\boldsymbol{0}}|h_0]}\\\\      & = & \\log \\frac{p[{\\boldsymbol{0}}|h_1]}{p[{\\boldsymbol{0}}|h_0 ] } \\label{eq : mipsprtcoeff0}\\end{aligned}\\ ] ] interestingly , after conditioning on the number of correlating spikes , the probability of the zero vector ( or any vector @xmath115 ) is the same under both @xmath61 and @xmath21 : @xmath132 = p[{\\boldsymbol{0}}|\\hat{s}_p=\\hat{s}_p , h_1]\\ ] ] we then expand to first - order in @xmath9 : @xmath133}{p[{\\boldsymbol{0}}|h_0 ] } & = &       \\log \\frac{\\left(1-\\frac{\\lambda_p}{\\rho } \\delta t   \\right ) + \\frac{\\lambda_p}{\\rho}\\delta t p[{\\boldsymbol{0}}|\\hat{s}_p=1]+o(\\delta t^2 ) }      { \\left(1-\\frac{\\lambda_n}{\\rho } \\delta t   \\right ) + \\frac{\\lambda_n}{\\rho } \\delta t",
    "p[{\\boldsymbol{0}}|\\hat{s}_p=1]+o(\\delta t^2)}\\\\      & = & \\frac{(\\lambda_p - \\lambda_n ) \\delta t}{\\rho}\\left((1-\\rho)^n-1\\right ) + o(\\delta t^2 ) \\label{eq : nocontribatzeroorder}\\end{aligned}\\ ] ] in the case of @xmath134 , only zero - order terms must be computed . when computing @xmath128}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=1,h_1\\right ] = \\sum_{{\\boldsymbol{s_p } } } p[{\\boldsymbol{s_p}}|\\hat{s}_p=1,h_1]\\log \\frac{p[{\\boldsymbol{s_p}}|h_1]}{p[{\\boldsymbol{s_p}}|h_0]},\\end{aligned}\\ ] ] the summation only carries over @xmath135 for each element of @xmath115 .",
    "the case of @xmath136 provides no contribution at zero - order , as can be seen by equation [ eq : nocontribatzeroorder ] ; for any other case , there will be a degeneracy in the expansion of the log , caused by an absence of order 0 terms : @xmath137}{p[{\\boldsymbol{s_p}}|h_0 ] }      & = & \\log \\frac{\\left(\\frac{\\lambda_p}{\\rho } -\\frac{\\lambda_p^2}{\\rho^2}\\delta t   \\right)p[{\\boldsymbol{s_p}}|\\hat{s}_p=1 ] + \\frac{\\lambda_p^2}{2\\rho^2}p[{\\boldsymbol{s_p}}|\\hat{s}_p=2]+ ... }      { \\left ( \\frac{\\lambda_n}{\\rho } -\\frac{\\lambda_n^2}{\\rho^2}\\delta t \\right)p[{\\boldsymbol{s_p}}|\\hat{s}_p=1]+ \\frac{\\lambda_n^2}{2\\rho^2}p[{\\boldsymbol{s_p}}|\\hat{s}_p=2]+ ... }\\\\      & = & \\log \\frac{\\lambda_p}{\\lambda_n } + o(\\delta t ) \\end{aligned}\\ ] ] therefore , to first - order in @xmath9 , @xmath128}{p[{\\boldsymbol{s_p}}|h_0]}|\\hat{s}_p=1,h_1\\right ]      & = &       \\log \\frac{\\lambda_p}{\\lambda_n}\\sum_{{\\boldsymbol{s_p}}\\neq 0}p[{\\boldsymbol{s_p}}|\\hat{s}_p=1,h_1 ] + o(\\delta t)\\\\       & = &       \\log \\frac{\\lambda_p}{\\lambda_n}(1-(1-\\rho)^n ) + o(\\delta t )       \\label{eq : lastmipsprteqtouse}\\end{aligned}\\ ] ] combining equations [ eq : mipsprtmaineq ] , [ eq : mipsprtcoeff0 ] , [ eq : nocontribatzeroorder ] , and [ eq : lastmipsprteqtouse ] , we find that : @xmath111}{p[{\\boldsymbol{s_p}}|h_0]}|h_1\\right ] =      \\frac {      \\left(1-(1-\\rho)^n \\right ) \\left(\\lambda_n-\\lambda_p + \\lambda_p \\log \\frac{\\lambda_p}{\\lambda_n}\\right )      } { \\rho}\\delta t\\ ] ] as before , exchanging  @xmath129 \" for  @xmath130 \" takes care of the expression for the null pool , and adding together gives : @xmath55 =   \\frac{\\left(1-(1-\\rho)^n \\right)}{\\rho}(\\lambda_p-\\lambda_n)\\log \\frac{\\lambda_p } { \\lambda_n } \\delta t+o(\\delta t^2)\\ ] ] once again , as @xmath46 and @xmath57 , we reproduce the results that would be expected from equation [ eq : poissonuncorrsprtrt ] .",
    "computing @xmath27 and @xmath26 for the spike integration accumulation model relies on computation of the mgf for the sampling distribution .",
    "we begin with several identities that will be useful below .",
    "the mgf for the sum of n independent random variables is : @xmath138 given that the mgf for a random variable @xmath139 , it follows that @xmath140 finally , the mgf for a poisson random variable is : @xmath141 given the definition of the increment variable in equation [ eq : sisamplingrv ] , and noting that each spike count random variable is independent , we can combine these observations to construct the mgf for the sampling random variable , over a time window @xmath9 : @xmath142 now the nontrivial root can be calculated ( cf .",
    "equation [ eq : uncorrsi ] ) : @xmath143 because the mgf is known explicitly , the computation of the expected increment is simple ( cf . equation [ eq : uncorrsiez ] ) : @xmath55=\\phi_w'(0)=\\delta t n\\left ( \\lambda_p-\\lambda_n \\right).\\label{eq : uncorrsiezappendix}\\ ] ]      when additive correlations are introduced within pools , the spike count distribution mgf over a time period @xmath9 can still be broken into the product of two separate mgf s , one each for the preferred and null pools , which are identical in form but differ in their poisson rate parameters ( indicated by the semicolon ) : @xmath144 for the preferred pool , the spike count can be broken into two independent contributions  spikes @xmath145 from the shared ( i.e. correlating ) spike train that get counted @xmath7 times ( firing at a rate @xmath44 ) , and spikes from the @xmath7 independent spike trains that get counted once ( each firing at a rate @xmath42 ) : @xmath146 the mgf for the shared spike train can be computed directly from the definition , using its probability mass function ( pmf ) : @xmath147 = \\left\\ {       \\begin{array}{ll }         \\frac{e^{-\\lambda}\\lambda^i}{i ! }   &    i \\in { \\mathbb{n}_0}\\\\         0 & \\;\\;\\;\\;\\;\\ ; \\text{otherwise , }       \\end{array }     \\right.\\ ] ] and thus : @xmath148       \\;=\\ ;       \\sum_{k=0}^\\infty e^{ntk}\\frac{e^{-\\lambda}\\lambda^k}{k ! }      \\;=\\ ;      e^{(e^{nt}-1)\\lambda}\\ ] ] the mgf for the independent spike trains @xmath149 follows from section [ sec : siuncorr ] , giving the form of the mgf of the increment over a time @xmath9 as : @xmath150 after rearranging , @xmath31 is implicitly defined as the nontrivial root of : @xmath151 as @xmath46 , we recover the solution from section [ sec : siuncorr ] . the expected increment can be directly computed as : @xmath55=\\delta t n\\left ( \\lambda_p-\\lambda_n \\right ) \\\\\\ ] ]",
    "note that this last expression is the same as in the independent case ( equation [ eq : uncorrsiez ] ) , as expected , and that unlike the sprt , no limits in @xmath9 were necessary to compute the parameters for the @xmath27 and @xmath26 functions .      with subtractive correlations",
    ", we again derive an mgf for the spike count vector of an individual pool @xmath152 , and apply equation [ eq : uncorrpoolsirelation ] . in this case , however , the number of spikes in a pool , conditioned on the number of spikes in that pools correlating train , is binomially distributed . thus applying the law of total probability : @xmath153 = \\sum_{\\hat{s}=0}^\\infty \\text{poiss}[\\hat{s};\\frac{\\lambda}{\\rho}]\\text{binom}[\\hat{s}n , s;\\rho]\\ ] ] using the definitions for the pmf s of the poiss@xmath154 $ ] and binom@xmath155 $ ] distributions , we have : @xmath156      = \\sum_{s=0}^\\infty p[s = s]e^{st }       = e^{\\left (                  ( ( 1+\\rho(e^t-1))^n -1 )          \\right ) \\frac{\\lambda}{\\rho}}\\ ] ] after applying equation [ eq : uncorrpoolsirelation ] with this mgf for both the preferred and null population , we find an implicit relationship for the non - trivial real root @xmath157 that does not depend on @xmath9 : @xmath158 as before , the expected increment can be directly computed by differentiation , and we find the same expression as in the additive correlation case : @xmath55=\\delta t n\\left ( \\lambda_p-\\lambda_n \\right ) \\\\\\ ] ]",
    "the identities provided in equations [ eq : fc ] and [ eq : rt ] are very useful , however are simplifications of the full formulas for @xmath27 and @xmath26 ( assuming @xmath52\\neq0 $ ] ) derived by wald @xcite , which are : @xmath159 - 1}{e[e^{h_0e_n}|e_n\\geq \\theta]-e[e^{h_0e_n}|e_n\\leq -\\theta ] } \\label{eq : fcfull } \\\\",
    "dt & = & \\frac{\\delta t}{e[w]}\\left (      e[e_n|e_n\\geq \\theta](fc )      + e[e_n|e_n\\leq -\\theta](1-fc)\\right ) \\label{eq : rtfull}\\end{aligned}\\ ] ] specifically , equations [ eq : fc ] and [ eq : rt ] hold under the assumption that the value of the state variable on the decision step is exactly equal to the decision threshold . in practice , however , this  no - overshoot \" assumption may not provide a particularly good approximation .    a correction term based on the mean of the overshoot distribution  that is , the distribution of the random variable defined by the excess distance over either the positive or negative threshold on the threshold crossing step  is suggested by lee et al @xcite . this correction is based on the taylor expansion of the conditional expectations in equation [ eq : fcfull ] , and takes the form of a shift in the decision threshold .",
    "a correction of this form is relevant to our analysis , as the performance of two models are compared parametrically in the threshold to isolate the effects of the speed - accuracy tradeoff imparted by freely adjusting the threshold .",
    "denote the value of @xmath28 conditioned on crossing the first threshold as @xmath160 , and let @xmath161 overshoot random variable , with mean @xmath162 .",
    "expanding the conditional expectation ( although dropping the conditional notation for convenience ) via a taylor series centered on this mean ( the so - called delta method ) , we have @xmath163 = e[e^{h_0r_0}+h_0e^{h_0r_0}(\\hat{e}_n - r_0)+\\frac{h_0 ^ 2e^{h_0r_0}(\\hat{e}_n - r_0)^2}{2}+ ... ]\\ ] ] choosing @xmath164 yields an expression of wald s truncation : @xmath165 & = &       e^{h_0\\theta } \\left(1          + h_0e[x ]           + \\frac{h_0 ^ 2e[x^2]}{2}+ ... \\right)\\\\      & \\approx & e^{h_0\\theta}\\end{aligned}\\ ] ] here we see that if @xmath166 , each term in the expansion becomes zero and wald s approximation holds exactly . on the other hand ,",
    "if @xmath28 overshoots @xmath34 , error will accumulate at each term in the expansion , as a function of the moments of the overshoot distribution .",
    "if instead the expansion is performed about @xmath167 , a threshold - shifted approximation expresses the truncation error terms of the second and higher centered moments of the overshoot distribution : @xmath168 & = &       e^{h_0(\\theta+\\mu_x ) } \\left(1          + \\frac{h_0 ^ 2e[(x-\\mu_x)^2]}{2}+ ... \\right)\\\\      & \\approx & e^{h_0(\\theta+e[x_n])}\\end{aligned}\\ ] ] in practice , the overshoot distribution is often nonzero ; however , if its mean can be calculated and @xmath35 , the truncation error associated with the latter approximation might provide a more favorable approximation as long as the higher - order moments do not grow too large . for the decision time , using this alternative approximation is exactly correct , and results in no additional error .",
    "staude et al . @xcite",
    "suggest that cumulants provide a  natural and intuitive higher - order generalization of the covariance \" for multineuron spiking .",
    "the two models of correlated activity examined here are indistinguishable when only examining first - order ( i.e. , mean firing rate ) or second - order ( i.e. , pairwise correlations ) statistics . here , we derive the joint cumulants for each of these two models , to clarify how the spike count distributions produced by the two models differ at higher orders .",
    "the derivation relies on the conditional independence of the spike counts for each neuron in a pool , conditioned upon the spike count in the common spike train .",
    "let @xmath169 be the random variables giving spike counts in a windows of size @xmath9 from each of the @xmath170 neurons in a correlated pool , and @xmath145 be the spike count in the common spike train .",
    "the law of total cumulance @xcite allows a relatively simple expression of the joint cumulant on @xmath93 members @xmath169 ( because of the homogeneity of the pool , we will express the @xmath171 joint cumulant as calculated on @xmath172 , but the same expression holds for any @xmath93-sized subset of @xmath169 ) : @xmath173 here @xmath174 is the set of all partitions of @xmath175 , for example @xmath176 & = &       \\ {           \\ {       \\{1\\},\\{2\\},\\{3\\ }            \\ } ,          \\ {       \\{1,2\\},\\{3\\ }                \\ } ,          \\ {       \\{1\\},\\{2,3\\ }                \\ } ,          \\ {       \\{1,3\\},\\{2\\ }                \\ } ,          \\ {       1,2,3                        \\ }      \\}\\\\      & = & \\ { \\pi_1 , \\pi_2,\\pi_3,\\pi_4,\\pi_5   \\ } \\label{eq : partitionexample}\\end{aligned}\\ ] ] and @xmath177 is the conditional joint cumulant over the set of all spike counts indexed by an element of @xmath178that is , the set @xmath179 .    in our special case ,",
    "@xmath180 whenever @xmath181 , owing to the conditional independence of each neuron given the common spike train .",
    "moreover , from the definition of the cumulant , the term of for the partition @xmath182 that contains such a block @xmath178 will also be zero .",
    "this implies that the only @xmath183 that contributes in equation [ eq : condcumulantformula ] is @xmath184 ( @xmath185 in the example of equation [ eq : partitionexample ] ) ; thus @xmath186, ... ,e[s_k|\\hat{s } ] ) = \\kappa_k(e[s_1|\\hat{s}]),\\ ] ] where we have used the fact that the first cumulant is simply the expected value . using the cumulant generating function",
    ", we then have a formula for the joint cumulant : @xmath187 } ] \\right]\\right|_{t=0}\\ ] ] thus , for the two models of correlations ( assuming a firing rate @xmath43 ) , we have : @xmath188 & = & \\sum_{s_1=0}^{\\hat{s } } s_1 { \\hat{s } \\choose s_1 } \\rho^{s_1 } ( 1-\\rho)^{\\hat{s}-s_1 } = \\rho \\hat{s}\\\\      & { \\mbox{$\\longrightarrow$ } } &   \\log e[e^{t e[s_1|\\hat{s}=\\hat{s } ] } ] = \\log          \\sum_{\\hat{s}=0}^{\\infty }        \\frac{e^{-\\delta t \\lambda/\\rho}(\\delta t \\lambda/\\rho)^{\\hat{s}}}{\\hat{s } ! }     e^{t \\rho \\hat{s}}\\\\          & & \\hspace{.1 in } = \\frac{\\lambda \\delta t ( e^{\\rho t}-1)}{\\rho}\\\\          & { \\mbox{$\\longrightarrow$ } } & \\kappa(s_1 ...",
    "s_k ) = \\left . \\frac{d^k}{(dt)^k}\\left",
    "[ \\frac{\\lambda \\delta t ( e^{\\rho t}-1)}{\\rho}\\right]\\right|_{t=0 } \\end{aligned}\\ ] ] @xmath189 @xmath190 & = & \\sum_{s_1=\\hat{s}}^{\\infty } s_1       \\frac{e^{-(1-\\rho)\\delta t \\lambda } ( ( 1-\\rho)\\delta t \\lambda)^{s_1-\\hat{s } } } { ( s_1-\\hat{s } ) ! } = \\hat{s } + \\lambda \\delta t ( 1-\\rho)\\\\      & { \\mbox{$\\longrightarrow$ } } &   \\log e[e^{t e[s_1|\\hat{s}=\\hat{s } ] } ] = \\log          \\sum_{\\hat{s}=0}^{\\infty }        \\frac{e^{-\\delta t \\lambda \\rho}(\\delta t \\lambda \\rho)^{\\hat{s}}}{\\hat{s } ! }     e^{t ( \\hat{s } + \\lambda \\delta t ( 1-\\rho))}\\\\          & & \\hspace{.1 in } = \\lambda \\delta t ( \\rho[e^t - t-1]+t ) \\label{e.esb } \\\\          & { \\mbox{$\\longrightarrow$ } } & \\kappa(s_1 ...",
    "s_k ) = \\left . \\frac{d^k}{(dt)^k}\\left",
    "[ \\lambda \\delta t ( \\rho[e^t - t-1]+t)\\right]\\right|_{t=0 } \\end{aligned}\\ ] ] @xmath191 comparing equations [ eq : mipcumulant ] and [ eq : sipcumulant ] ( see also figure [ fig : cumulant ] ) , we see agreement for @xmath192 as expected ; these correspond the the intended firing rate and pairwise covariance of neurons within the pool .",
    "however , for @xmath193 , we see the signature of the differences in the structure of the correlations . for the mip model ,",
    "the joint cumulant decays geometrically as more and more neurons are considered .",
    "in contrast , the joint cumulant remains constant for the sip model .",
    "william  t newsome , kenneth  h britten , j  anthony movshon , and michael  n shadlen . .",
    "in dominic man - kit lam and charles  d. gilbert , editors , _ neural mechanisms of visual perception _",
    ", pages 171198 . portfolio pub .",
    "co. , woodlands , tex . , april 1989 ."
  ],
  "abstract_text": [
    "<S> stimulus from the environment that guides behavior and informs decisions is encoded in the firing rates of neural populations . </S>",
    "<S> each neuron in the populations , however , does not spike independently : spike events are correlated from cell to cell . to </S>",
    "<S> what degree does this apparent redundancy impact the accuracy with which decisions can be made , and the computations that are required to optimally decide ? </S>",
    "<S> we explore these questions for two illustrative models of correlation among cells . </S>",
    "<S> each model is statistically identical at the level of pairs cells , but differs in higher - order statistics that describe the simultaneous activity of larger cell groups . </S>",
    "<S> we find that the presence of correlations can diminish the performance attained by an ideal decision maker to either a small or large extent , depending on the nature of the higher - order interactions . </S>",
    "<S> moreover , while this optimal performance can in some cases be obtained via the standard integration - to - bound operation , in others it requires a nonlinear computation on incoming spikes . </S>",
    "<S> overall , we conclude that a given level of pairwise correlations  even when restricted to identical neural populations  may not always indicate redundancies that diminish decision making performance . </S>"
  ]
}