{
  "article_text": [
    "modelling dna sequences with stochastic models and developing statistical methods to analyse the enormous set of data that results from the multiple projects of dna sequencing are challenging questions for statisticians and biologists .",
    "many dna sequence analysis are based on the distribution of the occurrences of patterns having some special biological function .",
    "the most popular model in this domain is the markov chain model that gives a description of the local behaviour of the sequence ( see @xcite ) .",
    "an important problem is to determine the statistical significance of a word frequency in a dna sequence .",
    "@xcite discuss about this relevance of finding over- or under - represented words .",
    "the naive idea is the following : a word may have a significant low frequency in a dna sequence because it disrupts replication or gene expression , whereas a significantly frequent word may have a fundamental activity with regard to genome stability .",
    "well - known examples of words with exceptional frequencies in dna sequences are biological palindromes corresponding to restriction sites avoided for instance in _ e. coli _ ( @xcite ) , the cross - over hotspot instigator sites in several bacteria , again in _ e. coli _ for example ( @xcite ) , and uptake sequences ( @xcite ) or polyadenylation signals ( @xcite ) .    the exact distribution of the number of a word occurrences under the markovian model is known and some softwares are available ( @xcite ) but , because of numerical complexity , they are often used to compute expectation and variance of a given count ( and thus use , in fact , gaussian approximations for the distribution ) .",
    "in fact these methods are not efficient for long sequences or if the markov model order is larger than @xmath1 or @xmath2 . for such cases ,",
    "several approximations are possible : gaussian approximations ( @xcite ) , binomial ( or poisson ) approximations ( @xcite ) , compound poisson approximations ( @xcite ) , or large deviations approach ( @xcite ) . in this paper",
    "we only focus on the poisson approximation .",
    "we approximate @xmath3 by @xmath4^k(k!)^{-1}$ ] where @xmath3 is the stationary probability under the markov model that the number of occurrences @xmath5 of word @xmath6 is equal to @xmath7 , @xmath8 is the probability that word @xmath6 occurs at a given position , and @xmath9 is the length of the sequence .",
    "intuitively , a binomial distribution could be used to approximate the distribution of occurrences of a particular word .",
    "length @xmath9 of the sequence is large , @xmath8 is small and @xmath10 is almost constant .",
    "thus , we use the more numerically convenient poisson approximation .",
    "our aim is to bound the error between the distribution of the number of occurrences of word @xmath6 and its poisson approximation . in @xcite , the authors prove an upper bound for a compound poisson approximation .",
    "they use a chen - stein method , which is the usual method in this purpose .",
    "this method has been developed by chen on poisson approximations ( @xcite ) after a work of stein on normal approximations ( @xcite ) .",
    "its principle is to bound the difference between the two distributions in total variation distance for all subsets of the definition domain .",
    "since we are interested in under- or over - represented words , we are only interested in this difference for the tails of the distributions .",
    "then , the uniform bound given by the chen - stein method is too large for our purpose .",
    "we present here a new method , based on the property of mixing processes .",
    "our method has the useful particularity to give a bound on the error at each point of the distribution .",
    "more precisely , it offers an error term @xmath11 , for the number of occurrences @xmath7 , of word @xmath6 : @xmath12 moreover , @xmath13 decays factorially fast with respect to @xmath7 .",
    "@xcite presents lower and upper bounds for the exponential approximation of the first occurrence time of a rare event , also called _ hitting time _",
    ", in a stationary stochastic process on a finite alphabet with @xmath14- or @xmath15-mixing property .",
    "@xcite describe the statistics of _ return times _ of a string of symbols in such a process . in @xcite ,",
    "the authors prove a poisson approximation for the distribution of occurrence times of a string of symbols in a @xmath15-mixing process .",
    "the first part of our work is to determine some constants not explicitly computed in the results of the above mentioned articles but necessary for the proof of our theorem .",
    "our work is complementary to all these articles , in the sense that it relies on them for preliminary results and it adapts them to @xmath0-mixing processes .",
    "since markov chains are mixing processes , all these results established for mixing processes also apply to markov chains which model biological sequences .",
    "this paper is organised in the following way . in section [ cs ] ,",
    "we introduce the chen - stein method . in section",
    "[ ma ] , we define a @xmath0-mixing process and state some preliminary notations , mostly on the properties of a word .",
    "we also present in this section the principal result of our work : the poisson approximation ( theorem [ bigt2 ] ) . in section [ prel ] , we state preliminary results .",
    "mainly , we recall results of @xcite , computing all the necessary constants and we present lemmas and propositions necessary for the proof of theorem [ bigt2 ] . in section [ fin ] , we establish the proof of our main result : theorem [ bigt2 ] on poisson approximation . using @xmath0-mixing properties and preliminary results , we prove an upper bound for the difference between the exact distribution of the number of occurrence of word @xmath6 and the poisson distribution of parameter @xmath10 .",
    "section [ bio ] is dedicated to numerical results . for the search of over - represented words ,",
    "we compare our method to chen - stein method on both synthetic and biological data . in this section",
    ", we also present results obtained by a similar method , the @xmath15-mixing method .",
    "we end the paper presenting some examples of biological applications , and some conclusions and perspectives of future works .",
    "for any two random variables @xmath16 and @xmath17 with values in the same discrete space @xmath18 , the total variation distance between their probability distributions is defined by @xmath19    we remark that for any subset @xmath20 of @xmath18 @xmath21      the chen - stein method is used to bound the error between the distribution of the number of occurrences of a word @xmath6 in a sequence @xmath16 and the poisson distribution with parameter @xmath10 where @xmath9 is the length of the sequence and @xmath8 the stationary measure of @xmath6 .",
    "the chen - stein method for poisson approximation has been developed by @xcite ; a friendly exposition is in @xcite and a description with many examples can be found in @xcite and @xcite .",
    "we will use theorem @xmath22 in @xcite with an improved bound by @xcite ( theorem @xmath22.a and theorem @xmath23.a ) .",
    "first , we will fix a few notations .",
    "let @xmath24 be a finite set ( for example , in the dna case @xmath25 ) .",
    "put @xmath26 . for each @xmath27 , we denote by @xmath28 the @xmath29-th coordinate of the sequence @xmath30 : @xmath31 .",
    "we denote by @xmath32 the one - step - left shift operator : so we will have @xmath33 .",
    "we denote by @xmath34 the @xmath35-algebra over @xmath36 generated by strings and by @xmath37 the @xmath35-algebra generated by strings with coordinates in @xmath38 with @xmath39 .",
    "we consider an invariant probability measure @xmath40 over @xmath34 .",
    "consider a stationary markov chain @xmath41 on the finite alphabet @xmath24 .",
    "let us fix a word @xmath42 .",
    "for @xmath43 , let @xmath44 be the following random variable @xmath45 where @xmath46 denotes the indicator function of set @xmath47 .",
    "we put @xmath48 , the random variable corresponding to the number of occurrences of a word , @xmath49 and @xmath50 .",
    "then , @xmath51 . let @xmath52 be a poisson random variable with parameter @xmath29 : @xmath53 . for each @xmath54",
    ", we arbitrarily define a set @xmath55 containing the point @xmath54 .",
    "the set @xmath56 will play the role of a neighbourhood of @xmath54 .",
    "[ chenstein ] let i be an index set . for each @xmath57 ,",
    "let @xmath44 be a bernoulli random variable with @xmath58 .",
    "suppose that , for each @xmath57 , we have chosen @xmath59 with @xmath60 .",
    "let @xmath61 , be independent poisson variables with mean @xmath62 .",
    "the total variation distance between the dependent bernoulli process @xmath63 and the poisson process @xmath64 satisfies @xmath65 where @xmath66 @xmath67 @xmath68 moreover , if @xmath69 and @xmath70 , then @xmath71    we think of @xmath56 as a neighbourhood of strong dependence of @xmath44 .",
    "intuitively , @xmath72 describes the contribution related to the size of the neighbourhood and the weights of the random variables in that neighbourhood ; if all @xmath44 had the same probability of success , then @xmath72 would be directly proportional to the neighbourhood size .",
    "the term @xmath73 accounts for the strength of the dependence inside the neighbourhood ; as it depends on the second moments , it can be viewed as a `` second order interaction '' term .",
    "finally , @xmath74 is related to the strength of dependence of @xmath44 with random variables outside its neighbourhood . in particular , note that @xmath75 if @xmath44 is independent of @xmath76 .",
    "one consequence of this theorem is that for any indicator function of an event , i.e. for any measurable functional @xmath77 from @xmath36 to @xmath78 $ ] , there is an error bound of the form @xmath79 .",
    "thus , if @xmath80 is a test statistic then , for all @xmath81 , @xmath82 which can be used to construct confidence intervals and to find p - values for tests based on this statistic .",
    "we focus on markov processes in our biological applications ( see [ bio ] ) but the theorem given in the following subsection is established for more general mixing processes : the so called @xmath0-mixing processes .",
    "let @xmath83 be a sequence of real numbers decreasing to zero .",
    "we say that @xmath84 is a @xmath0-mixing process if for all integers @xmath85 , the following holds @xmath86 where the supremum is taken over the sets @xmath87 and @xmath88 , such that @xmath89 .    for a word @xmath6 of @xmath36 , that is to say a measurable subset of @xmath36",
    ", we say that @xmath90 if and only if @xmath91 with @xmath92 .",
    "then , the integer @xmath93 is the length of word @xmath6 . for @xmath90 , we define the hitting time @xmath94 , as the random variable defined on the probability space ( @xmath36,@xmath34,@xmath40 ) : @xmath95 @xmath96 is the first time that the process hits a given measurable @xmath6 .",
    "we also use the classical probabilistic shorthand notations .",
    "we write @xmath97 instead of @xmath98 , @xmath99 instead of @xmath100 and @xmath101 instead of @xmath102 .",
    "also we write for two measurable subsets @xmath6 and @xmath87 of @xmath36 , the conditional probability of @xmath87 given @xmath6 as @xmath103 and the probability of the intersection of @xmath6 and @xmath87 by @xmath104 or @xmath105 . for @xmath106 and @xmath107 , we write @xmath108 for the event consisting of the _ last _ @xmath109 symbols of  @xmath6 .",
    "we also write @xmath110 for the supremum of two real numbers @xmath111 and @xmath112 .",
    "we define the periodicity @xmath113 of @xmath90 as follows : @xmath114 @xmath113 is called the principal period of word @xmath6",
    ". then , we denote by @xmath115 the set of words @xmath116 with periodicity @xmath117 and we also define @xmath118 as the set of words @xmath116 with periodicity less than  @xmath119 $ ] , where @xmath120 $ ] defines the integer part of a real number : @xmath121}\\mathcal{r}_p.\\ ] ] @xmath118 is the set of words which are self - overlapping before half their length ( see example  [ mot ] ) .",
    "we define @xmath122 the set of return times of @xmath6 which are not a multiple of its periodicity @xmath113 : @xmath123p_a+1 , \\dots , n-1\\}| a\\cap t^{-k}(a )   \\neq { \\emptyset}\\right\\}.\\ ] ] let us denote @xmath124 , the cardinality of the set @xmath122 .",
    "define also @xmath125 if @xmath126 and @xmath127 otherwise .",
    "@xmath122 is called the set of secondary periods of @xmath6 and @xmath128 is the smallest secondary period of @xmath6 . finally , we introduce the following notation . for an integer @xmath129 ,",
    "let @xmath130 .",
    "the random variable @xmath131 counts the number of occurrences of @xmath6 between @xmath132 and @xmath9 ( we omit the dependence on  @xmath6 ) .",
    "for the sake of simplicity , we also put @xmath133 .",
    "[ mot ] consider the word @xmath134 . since @xmath135 , we have @xmath136 where @xmath137 .",
    "see the following figure to note that @xmath138 , @xmath139 and @xmath140 .",
    "@xmath141      we present a theorem that gives an error bound for the poisson approximation .",
    "compared to the chen - stein method , it has the advantage to present non uniform bounds that strongly control the decay of the tail distribution of @xmath142 .",
    "[ bigt2 ] let @xmath143 be a @xmath0-mixing process .",
    "there exists a constant @xmath144 , such that for all @xmath145 and all non negative integers @xmath7 and @xmath9 , the following inequality holds : @xmath146 @xmath147 @xmath148,\\ ] ] @xmath149    this result is at the core of our study .",
    "it shows an upper bound for the difference between the distribution of the number of occurrences of word @xmath6 in a sequence of length @xmath9 and the poisson distribution of parameter @xmath10 .",
    "proof is postponed in section [ fin ] .",
    "our goal is to compute a bound as small as possible to control the error between the poisson distribution and the distribution of the number of occurrences of a word .",
    "thus , we determine the global constant @xmath150 appearing in theorem [ bigt2 ] by means of intermediary bounds appearing in the proof .",
    "general bounds are interesting asymptotically in @xmath93 , but for biological applications , @xmath93 is approximately between @xmath23 or @xmath151 , which is too small .",
    "then along the proof , we will indicate the intermediary bounds that we compute . before establishing the proof of that theorem [ bigt2 ] , we point out here , for easy references , some results of @xcite , and some other useful results . in @xcite ,",
    "these results are given only in the @xmath15-mixing context .",
    "moreover exact values of the constants are not given , while these are necessary for practical use of these methods .",
    "we provide the values of all the constants appearing in the proofs of these results .",
    "[ p11 ] let @xmath143 be a @xmath0-mixing process .",
    "there exist two finite constants @xmath152 and @xmath153 , such that for any @xmath93 , any word @xmath154 , and any @xmath155 $ ] satisfying @xmath156 there exists @xmath157 , with @xmath158 , such that for all positive integers @xmath7 , the following inequalities hold : @xmath159 @xmath160.\\ ] ]    both inequalities provide an approximation of the hitting time distribution by a geometric distribution at any point @xmath9 of the form @xmath161 .",
    "the difference between these distributions is that in [ in6 ] , the geometric term inside the modulus is the same as in the upper bound , while in [ in7 ] , the geometric term inside the modulus is larger than the one in the upper bound .",
    "that is , the second bound gives a larger error .",
    "we will use both in the proof of theorem [ ht ] .",
    "we have @xmath162 and @xmath163 .    for the details of the proof of proposition [ p11 ] , we refer to proposition @xmath164 in  @xcite . for any @xmath155",
    "$ ] and @xmath165 $ ] , we denote @xmath166 and @xmath167 for the sake of simplicity .",
    "@xcite obtains the following bound : @xmath168 @xmath169 , + @xmath170 , + @xmath171 .",
    "+ first , for any measurable @xmath172 , we have @xmath173 .",
    "we can also remark that @xmath174 .",
    "then , by iteration of the mixing property , we have the following inequality for all @xmath175 : @xmath176 we apply this bound in the inequalities ( 14 ) and ( 15 ) of @xcite to get + @xmath177 , + @xmath178 .",
    "+ we also have @xmath179 . + we obtain ( [ in6 ] ) : @xmath180 .",
    "+ we deduce ( [ in7 ] ) : @xmath181 .",
    "+ then , @xmath182 and @xmath183 .",
    "[ ht ] let @xmath143 be a @xmath0-mixing process .",
    "then , there exist constants @xmath184 and @xmath185 , such that for all @xmath186 and any @xmath90 , there exists @xmath187}$ ] , for which the following inequality holds for all @xmath188 : @xmath189 @xmath160 \\mbox { and } f_1(a , t)=(t{\\mathbb{p}}(a)\\vee1){e}^{-t{\\mathbb{p}}(a)}.\\ ] ]    we prove an upper bound for the distance between the rescaled hitting time and the exponential law of expectation equal to one .",
    "the factor @xmath190 in the upper bound shows that the rate of convergence to the exponential law is given by a trade off between the length of this time and the velocity of loosing memory of the process .",
    "we have @xmath191 .",
    "we fix @xmath192 and @xmath157 given by proposition [ p11 ] .",
    "we define @xmath193 there are three steps in the proof of the theorem .",
    "first , we consider @xmath9 of the form @xmath161 with @xmath7 a positive integer .",
    "secondly , we prove the theorem for any @xmath9 of the form @xmath194 with @xmath195 positive integers and @xmath196 with @xmath197 .",
    "we also put @xmath198 .",
    "finally , we consider the remaining cases . here , for the sake of simplicity , we do not detail the two first steps ( for that , see @xcite ) , but only the last one .",
    "let @xmath9 be any positive real number .",
    "we write @xmath199 , with @xmath7 a positive integer and @xmath200 such that @xmath201 .",
    "we can choose a @xmath202 such that @xmath203 and @xmath204 with @xmath117 , @xmath205 as before .",
    "@xcite obtains the following bound : @xmath206 the first term in the triangular inequality is bounded in the following way : @xmath207    the second term is bounded like in the two first steps of the proof in @xcite .",
    "we apply inequalities ( [ in6 ] ) and ( [ in7 ] ) to obtain @xmath208 finally , the third term is bounded using the mean value theorem ( see for example @xcite ) @xmath209 thus we have @xmath210 and the theorem follows by the change of variables @xmath211 . then @xmath212 .",
    "[ pbc ] @xmath213 be a @xmath0-mixing process .",
    "suppose that @xmath214 , @xmath215 with @xmath216 .",
    "the following inequality holds : @xmath217    since @xmath218 , obviously @xmath219 . by the @xmath0-mixing property @xmath220 .",
    "we divide the above inequality by @xmath8 and the lemma follows .",
    "for all the following propositions and lemmas , we recall that @xmath148.\\ ] ]    [ : lambda ] let @xmath213 be a @xmath0-mixing process .",
    "let @xmath221 .",
    "then the following holds :    * for all @xmath222 , @xmath223,\\nonumber \\end{aligned}\\ ] ] and similarly @xmath224.\\nonumber \\end{aligned}\\ ] ] * for all @xmath225 , with @xmath226 , @xmath227    the above proposition establishes a relation between hitting and return times with an error bound uniform with respect to @xmath9 . in particular , @xmath228 says that these times coincide if and only if @xmath229 , namely , the string @xmath6 is non - self - overlapping .    in order to simplify notation , for @xmath230 , @xmath231}$ ] stands for @xmath232 .",
    "we introduce a gap of length @xmath233 after coordinate @xmath234 to construct the following triangular inequality @xmath235}>m'-g",
    "\\right)\\right\\vert \\label{mix1 } \\\\",
    "& + & \\left\\vert{\\mathbb{p}}_a\\left(\\tau_a > m ; \\tau_a^{[m+g]}>m'-g\\right)-     { \\mathbb{p}}_a\\left(\\tau_a > m\\right){\\mathbb{p}}\\left(\\tau_a > m'-g\\right)\\right\\vert \\label{mix2 } \\\\ & + &       { \\mathbb{p}}_a\\left ( \\tau_a > m \\right ) \\left\\vert { \\mathbb{p}}\\left ( \\tau_a > m'-g \\right ) -   { \\mathbb{p}}\\left(\\tau_a > m ' \\right ) \\right\\vert.\\label{mix3 } \\end{aligned}\\ ] ] term ( [ mix1 ] ) is bounded with lemma  [ pbc ] by @xmath236 } \\leq",
    "g\\right ) \\leq { \\mathbb{p}}_a\\left ( \\tau_a > m -g \\right ) g{\\mathbb{p}}(a)\\left [ 1+\\psi(g ) \\right].\\ ] ] term ( [ mix2 ] ) is bounded using the @xmath0-mixing property by @xmath237 .",
    "the modulus in ( [ mix3 ] ) is bounded using stationarity by @xmath238 this ends the proof of both inequalities of item @xmath239 .",
    "+ item @xmath228 for @xmath240 is proven similarly to item @xmath239 with @xmath241 , @xmath242 , and @xmath243 with @xmath244 .",
    "consider now @xmath245 .",
    "@xmath246 first and second equalities follow by definition of @xmath96 and @xmath122 .",
    "the inequality follows by lemma [ pbc ] .",
    "let @xmath247 and @xmath248 , then @xmath249 .",
    "[ l12 ] let @xmath143 be a @xmath0-mixing process .",
    "then the following inequality holds : @xmath250    hence , we have @xmath251    @xmath252    where @xmath253 therefore @xmath254 the above modulus is bounded by @xmath255 now note that @xmath256 for @xmath257 small enough",
    ". apply it with @xmath258 to bound the most left term of the above expression by @xmath259 .",
    "further by proposition [ : lambda ] @xmath228 and the fact that @xmath260 we have @xmath261 for all @xmath262 .",
    "yet as before @xmath263 finally , by definition of @xmath77 @xmath264 this ends the proof of the lemma .",
    "[ mprop ] let @xmath143 be a @xmath0-mixing process .",
    "then the following inequality holds : @xmath265    we bound the first term with theorem [ ht ] and the second with lemma  [ l12 ]  : @xmath266 this ends the proof of the proposition with @xmath267 .",
    "given @xmath90 , we define for @xmath268 , the @xmath269-th occurrence time of @xmath6 as the random variable @xmath270 , defined on the probability space @xmath271 as follows : for any @xmath272 , @xmath273 and for @xmath274 , @xmath275    [ 18 ] let @xmath143 be a @xmath0-mixing process . then , for all @xmath276 , all @xmath277 , and all @xmath278 for which @xmath279 , there exists a positive constant @xmath280 independent of @xmath6 , @xmath93 , @xmath9 and @xmath7 such that @xmath281 where @xmath282",
    ".    we will show this proposition by induction on @xmath7 .",
    "we put @xmath283 for @xmath284 , @xmath285 and @xmath286 .",
    "firstly , we note that by stationarity @xmath287 for @xmath288 , by a triangular inequality we obtain @xmath289 term ( [ 18a ] ) is equal to @xmath290 and then    @xmath291 since @xmath292 , for @xmath293 , the above probability is zero .",
    "thus , using mixing property @xmath294 term ( [ 18b ] ) is bounded using @xmath0-mixing property @xmath295 analogous computations are used to bound terms ( [ 18c ] ) and ( [ 18d ] ) .",
    "now , let us suppose that the proposition holds for @xmath296 and let us prove it for @xmath7 .",
    "we put @xmath297 .",
    "we use a triangular inequality again to bound the term in the left hand side of the inequality of the proposition by a sum of five terms : @xmath298 @xmath299 @xmath300 @xmath301 we use the inductive hypothesis for the term @xmath302 and the case with @xmath303 for the term  @xmath304 .",
    "@xmath305 @xmath306 finally , we obtain @xmath307 to conclude the proof , it is sufficient that @xmath308 , therefore @xmath309 .",
    "this ends the proof of the proposition .",
    "in this section , we prove the main result of our work ( see section [ mixmet ] ) : an upper bound for the difference between the exact distribution of the number of occurrences of word @xmath6 and the poisson distribution of parameter @xmath10 . throughout the proof , we will note in italic the terms computed by our software ` panow ` ( see section [ panow ] ) .    for @xmath310 ,",
    "the result comes from proposition  [ mprop ] ( @xmath311 ) . + for @xmath312 , since @xmath276 , we have @xmath313 .",
    "hence , @xmath314 indeed , since @xmath315 then @xmath316 .    now , let us consider @xmath317 .",
    "we consider a sequence which contains exactly @xmath7 occurrences of @xmath6 .",
    "these occurrences can be isolated or can be in clumps .",
    "we define the following set : @xmath318 we recall that we put @xmath282 , @xmath283 for @xmath284 , @xmath285 and @xmath286 .",
    "define @xmath319 .",
    "we say that the occurrences of @xmath6 are isolated if @xmath320 and we say that there exists at least one clump if @xmath321 .",
    "we also denote @xmath322 the set @xmath323 is the disjoint union between @xmath324 and @xmath325 , then @xmath326 @xmath327 we will prove an upper bound for the two quantities on the right hand side of the above inequality to conclude the proof of the theorem .    * we prove an upper bound for * @xmath328**. * * define @xmath329 .",
    "@xmath330 computes how many clusters there are in a given @xmath331 .",
    "suppose that @xmath331 is such that @xmath332 and fix the position @xmath333 of the first occurrence of @xmath6 .",
    "further , each occurrence inside the cluster ( with the exception of the most left one which is fixed at @xmath333 ) can appear at distance @xmath334 of the previous one , with @xmath335 .",
    "therefore , the @xmath0-mixing property leads to the bound @xmath336 suppose now that @xmath331 is such that @xmath337 .",
    "assume also that the most left occurrence of the @xmath54 clusters of @xmath331 occurs at @xmath338 , with @xmath339 fixed .",
    "by the same argument used above , we have the inequalities @xmath340 to obtain an upper bound for @xmath341 we must sum the above bound over all @xmath331 such that @xmath342 with @xmath54 running from @xmath22 to @xmath296 . fixed @xmath337 ,",
    "the locations of the most left occurrences of @xmath6 of each one of the @xmath54 clusters can be chosen in at most @xmath343 many ways .",
    "the cardinality of each one of the @xmath54 clusters can be arranged in @xmath344 many ways .",
    "( this corresponds to breaking the interval @xmath345 in @xmath54 intervals at points chosen from @xmath346 . )",
    "collecting these informations , we have that @xmath341 is bounded by @xmath347 this ends the proof of the bound for @xmath348 .",
    "+ _ we compute @xmath349 .",
    "_    * we prove an upper bound for * @xmath350**. * * it is bounded by four terms by the triangular inequality @xmath351 we will bound these terms to obtain theorem [ bigt2].first , we bound the cardinal of @xmath325 @xmath352 term ( [ 14 ] ) is bounded with proposition [ 18 ] @xmath353 term ( [ 15 ] ) is bounded with proposition [ mprop ] @xmath354 where @xmath355 is defined in proposition [ mprop ] . + _ we compute @xmath356             { e}^{-(\\zeta_a-11e_{\\psi}(a ) ) t{\\mathbb{p}}(a)}. \\nonumber\\end{aligned}\\ ] ] _",
    "+ term ( [ 16 ] ) is bounded by @xmath357 to bound term ( [ 17 ] ) , we bound the following difference @xmath358 then , we have @xmath359    now , we just have to add the five bounds to obtain the theorem with the constant @xmath360 .",
    "proposition  [ 18 ] shows that @xmath309 and proposition [ mprop ] with theorem [ ht ] that @xmath361 .",
    "then , we prove the theorem with @xmath144 .",
    "with the explicit value of the constant @xmath150 of theorem [ bigt2 ] , and more particularly thanks to all the intermediary bounds given in the proof of this theorem , we can develop an algorithm to apply this formula to the study of rare words in biological sequences . in order to compare different methods",
    ", we also compute the bounds corresponding to a @xmath15-mixing , process for which a proof of poisson approximation is given in @xcite .",
    "let us recall the definition of such a mixing process .",
    "let @xmath362 be a sequence decreasing to zero .",
    "we say that @xmath84 is a @xmath15-mixing process if for all integers @xmath85 , the following holds @xmath363 where the supremum is taken over the sets @xmath87 and @xmath88 , such that @xmath364 .",
    "note that obviously , @xmath0-mixing implies @xmath15-mixing .",
    "then , we obtain two new methods for the detection of over- or under - represented words in biological sequences and we compare them to the chen - stein method .",
    "we recall that markov models are @xmath0-mixing processes and then also @xmath15-mixing processes .",
    "then , we first need to know the functions @xmath0 and @xmath15 for a markov model .",
    "it turns out that we can use @xmath365 where @xmath366 and @xmath367 have to be estimated ( see @xcite ) .",
    "there are several estimations of @xmath366 and @xmath367 .",
    "we choose @xmath367 equal to the second eigenvalue of the transition matrix of the model and @xmath368 where @xmath369 is the alphabet size , @xmath7 the order of the markov model and @xmath370 the stationary distribution of the markov model .",
    "we recall that we aim at guessing a relevant biological role of a word in a sequence using its number of occurrences .",
    "thus we compare the number of occurrences expected in the markov chain that models the sequence and the observed number of occurrences .",
    "it is recommended to choose a degree of significance @xmath132 to quantify this relevance .",
    "we fix arbitrarily a degree of significance and we want to calculate the smallest number of occurrences @xmath371 necessary for @xmath372 , where @xmath373 is the number of occurrences of the studied word . if the number of occurrences counted in the sequence is larger than this @xmath371 , we can consider the word to be relevant with a degree of significance @xmath132 .",
    "we have @xmath374 where @xmath375 is the probability under the poisson model that @xmath373 is equal to @xmath7 and @xmath376 is the error between the exact distribution and its poisson approximation , bounded using theorem [ bigt2 ] .",
    "then , we search the smallest threshold @xmath371 such that @xmath377 then , we have @xmath372 and we consider the word relevant with a degree of significance @xmath132 if it appears more than @xmath371 times in the sequence .    in order to compare the different methods",
    ", we compare the thresholds that they give .",
    "obviously , the smaller the degree of significance , the more relevant the studied word is .",
    "but for a fixed degree of significance , the best method is the one which gives the smallest threshold @xmath371 . indeed , to give the smallest @xmath371 is equivalent to give the smallest error in the tail of the distribution between the exact distribution of the number of occurrences of word @xmath6 and the poisson distribution with parameter @xmath10 .",
    "we developed ` panow ` , dedicated to the determination of threshold @xmath371 for given words .",
    "this software is written in ansi ` c++ ` and developed on x86 gnu / linux systems with gcc 3.4 , and successfully tested with gcc latest versions on sun and apple mac osx systems .",
    "it relies on ` seq++ ` library ( @xcite ) .",
    "compilation and installation are compliant with the gnu standard procedure .",
    "it is available at ` http://stat.genopole.cnrs.fr/software/panowdir/ ` . on - line documentation",
    "is also available . `",
    "panow ` is licensed under the gnu general public license ( ` http://www.gnu.org/licenses/licenses.html ` ) .",
    "we can compare the mixing methods and the chen - stein method through the values of threshold  @xmath371 obtained with ` panow ` using @xcite in the first case and @xcite in the second one .",
    "we recall that the method which gives the smallest threshold @xmath371 is the best method for a fixed degree of significance .",
    "table [ t1 ] offers a good outline of the possibilities and limits of each method .",
    "it displays some results on different words randomly selected ( no biological meaning for any of these words ) .",
    ".table of thresholds @xmath371 obtained by the three methods ( sequence length @xmath9 equal to @xmath378 ) . for each one of the three methods and for each word",
    ", we compute the threshold which permits to consider the word as an over - represented word or not , for degree of significance @xmath132 equal to @xmath379 or @xmath380 .",
    "imp means that the method can not return a result . [",
    "cols=\"^,^,^,^,^,^,^ \" , ]     we observe that in all the cases the @xmath0-mixing method is the best one because it gives the smallest @xmath371 , except for the word ` ggtggtgg ` which has a periodicity less than @xmath381 $ ] ( and then we can not study it : see assumptions in theorem [ bigt2 ] )",
    ". we can not assume the good significance of the first chi ( ` gatggtgg ` ) because we count only @xmath151 occurrences in the sequence , whereas @xmath382 occurrences are necessary to consider this word as exceptional .",
    "on the other hand , the uptake sequence is very significant ( and then very relevant ) .",
    "indeed , we could fix a significance degree equal to @xmath383 and consider it as an over - represented word from @xmath384 occurrences with the @xmath0-mixing method . as ` aagtgcggt ` is counted @xmath385 times in the sequence , we obtain the well - known fact that this word is biologically relevant .",
    "to conclude this paper , we recall the advantages of our new methods .",
    "we give an error valid for all the values @xmath7 of the random variable @xmath142 corresponding to the number of occurrences of word @xmath6 in a sequence of length @xmath9 .",
    "then , we can find a minimal number of occurrences to consider a word as biologically relevant for a very large number of words and for all degrees of significance .",
    "that is the main advantage of our methods on the chen - stein one which is based on the total variation distance and for which small degrees of significance can not be obtained .",
    "results of our @xmath0-mixing method and the chen - stein method remain similar but our method has less limitations .",
    "note that our methods provide performing results for general modelling processes such as markov chains as well as every @xmath15- and @xmath0-mixing processes .    in terms of perspectives ,",
    "as we expect more significant results , we hope to improve these methods adapting them directly to markov chains instead of @xmath0- or @xmath15-mixing .",
    "moreover , it is well - known that a compound poisson approximation is better for self - overlapping words ( see @xcite and @xcite ) .",
    "an error term for the compound poisson approximation for self - overlapping words can be easily derived from our results .",
    "the authors would like to thank bernard prum for his support and his useful comments .",
    "the authors would like to thank sophie schbath for her program , vincent miele for his very relevant help in the conception of the software and catherine matias for her invaluable advices ."
  ],
  "abstract_text": [
    "<S> using recent results on the occurrence times of a string of symbols in a stochastic process with mixing properties , we present a new method for the search of rare words in biological sequences generally modelled by a markov chain . we obtain a bound on the error between the distribution of the number of occurrences of a word in a sequence ( under a markov model ) and its poisson approximation . </S>",
    "<S> a global bound is already given by a chen - stein method . </S>",
    "<S> our approach , the @xmath0-mixing method , gives local bounds . </S>",
    "<S> since we only need the error in the tails of distribution , the global uniform bound of chen - stein is too large and it is a better way to consider local bounds . </S>",
    "<S> we search for two thresholds on the number of occurrences from which we can regard the studied word as an over - represented or an under - represented one . </S>",
    "<S> a biological role is suggested for these over- or under - represented words . </S>",
    "<S> our method gives such thresholds for a panel of words much broader than the chen - stein method . </S>",
    "<S> comparing the methods , we observe a better accuracy for the @xmath0-mixing method for the bound of the tails of distribution . </S>",
    "<S> we also present the software ` panow ` dedicated to the computation of the error term and the thresholds for a studied word .    </S>",
    "<S> poisson approximation , chen - stein method , mixing processes , markov chains , rarewords , dna sequences </S>"
  ]
}