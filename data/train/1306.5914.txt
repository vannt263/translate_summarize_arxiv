{
  "article_text": [
    "perceptual completion is a low level visual process studied for more than a century , starting from the pioneers of the phenomenology of the gestalt @xcite .",
    "the psychologist gaetano kanizsa introduced in @xcite a number of stunning examples of images allowing to clearly perceive the phenomenon of pop up of illusory figures .",
    "for example in fig .",
    "1 ) a triangle with curved boundaries is perceived out of the three pac - men inducers .",
    "kanizsa called this pop up effect `` modal completion '' because the illusory figure and its boundaries is really perceived with the modality of vision , while the three pac - men are completed to disks with `` a - modal completion '' , meaning that they remain invisible , partially masked by the triangle .    [ kanizsa ]        a starting point to afford the task of modal completion is to consider illusory boundaries @xcite and a number of mathematical models have been proposed on this topic .",
    "the celebrated model of elastica has been introduced by d.mumford in @xcite to take into account curvilinear illusory boundaries .",
    "williams and jacobs proposed a stochastic version of completion fields @xcite .",
    "recent models of boundary completion are based on the neurogeometrical structure of the visual cortex and they showed a strong explicative power of perceptual completion .",
    "the first neurogeometrical model has been introduced by petitot and y.tondut @xcite to describe the functional architecture of the visual cortex with instruments of differential geometry .",
    "in particular in @xcite the hypercolumnar structure of the simple cells organization , responsible for contour detection , is modelled as a fiber bundle ( see also section 2.2 below ) .",
    "the model has been further developed by citti and sarti @xcite , @xcite who proposed to interpret the whole fiber bundle as the group of position and orientation with a subriemannian metric .",
    "this metric allows to reconstruct rectilinear or curved illusory boundaries .",
    "other models of boundary completion have been developed in the same space @xcite .",
    "the problem of modal completion of both boundaries and figures together has been much less covered in literature . in @xcite modal completion has been achieved by non - linear functional minimization by means of combinatorial techniques . in @xcite@xcite",
    "it was proposed a technique to construct the kanizsa triangle by minimization of an area functional measured with respect to a metric induced by the image . in both models @xcite and @xcite a complete boundary / figure reconstruction was provided but a correct filling in of figures with the perceived brighness is still missing .    in this paper",
    "we would like to introduce a formal field theory of low level vision , able to afford the problem of modal completion .",
    "the theory will couple two models of low level vision , i.e. a neurogeometrical model of boundary completion and the celebrated retinex algorithm as a model for filling in .",
    "in particular we will show that it is possible to integrate the retinex model of @xcite with the neurogeometrical approach of @xcite and to propose a new model of modal completion , based on complete contrast invariance .",
    "the two equations will act as a particle and a field term of a complete gauge field theory .",
    "the paper is organized as follows . in section 2",
    "we recall the main properties of the retinex algorithm and the neurogeometrical model , and reinterpret them with instruments of gauge field theory . in section 3",
    "we couple the models by introducing a complete gauge field lagrangian .",
    "the corresponding euler lagrange equations are calculated by variational calculus . in section 4",
    "the euler lagrange equations are solved , providing results on the pop up of the kanizsa figure . in section 5 a plausible neural implementation of the model",
    "is proposed and discussed .",
    "in this section we recall the main properties of two previously recalled models retinex and the neurogeometrical one .",
    "the retinex algorithm has been inspired by the functionality of the retina in detecting image gradients and implementing contrast invariance .",
    "the second one has been inspired by the ability of the cortex to detect and complete boundaries .",
    "we will provide here a short description of the two processes , stressing the similarity of the mathematical instruments adopted by both .",
    "the celebrated retinex model has been introduced in @xcite@xcite to explain lightness perception , i.e. the phenomenon causing a gray patch to appear brighter when viewed against a dark background , and darker when viewed against a bright background . here , we are more interested in his capacity of filling in figures from boundaries . after its introduction",
    "this model has inspired a wide range of improvements and new models have been proposed @xcite .    in horn s work",
    "@xcite the authors proposed a physically based algorithm , which recovers the reflectance @xmath0 of an image @xmath1 as @xmath2    in @xcite , it has been proved that the original retinex algorithm can be equivalently espressed by the same equation .",
    "precisely then retinex is equivalent to a neumann problem for a linear equation .",
    "the equation is identical to the poisson equation for image editing proposed in perez et al .",
    "@xcite . in @xcite",
    "a new interpretation was given in terms of covariant derivatives and fiber bundles .",
    "indeed setting @xmath3 equation [ logretinexclassical ] can be considered the euler lagrange equation of the functional @xmath4 this functional is invariant with respect to the transformation @xmath5 so that the choice @xmath6 is compatible with the transformations which leaves invariant the functional . the quantity @xmath7 can be interpreted as a covariant derivative .",
    "also note that , setting @xmath8 equation [ logretinexclassical ] further simplify as @xmath9 and with the same choice as before : @xmath10 the functional becomes @xmath11 while the transformations which leave invariant the operator become @xmath12      let us recall here the neurogeometrical model of boundary completion proposed by @xcite .",
    "the model mimic the ability of simple cells of detecting boundaries and level lines of images , and to complete missing boundaries .",
    "the retina can be modelled as a 2d plane , whose points will be denoted by @xmath13 . over each retinic point",
    "@xmath13 the primary visual cortex implements a whole fiber of cells , each one sensible to a specific direction @xmath14 .",
    "hence the set of simple cells is identified with the 3d space @xmath15 .",
    "a visual stimulus will be expressed as an image @xmath16 defined on the retinal 2d plane , and we will denote @xmath17 the orientation of his level lines at every point . in presence of a visual stimulus , at every point",
    "@xmath13 the simple cell sensible to the orientation @xmath17 will be maximally activated .",
    "hence the set of activated cells defines a surface in the 3d cortical space @xmath18 @xmath19 the condition on the gradient of @xmath1 is a treshold , which ensures that the function @xmath20 is well defined around boudaries of the image .",
    "if we set @xmath21 , @xmath22 will be identified with the 0-level set of @xmath23 : @xmath24 simple cells are connected one to the other by the so called cortico - cortical connectivity .",
    "this connectivity is strongly anysotropic , and a cell located at a point @xmath13 and sensible to an orientation @xmath14 mainly propagate in the direction of its orientation @xmath14 .",
    "more precisely the connectivity allows a propagation of the signal in the @xmath18 along the integral curves of the vector fields @xmath25    propagation along the cortical connectivity seems to be at the basis of the process of boundary completion . indeed the lifted surface @xmath22 is not defined on the whole space , but only over the region where boundaries or level lines are detected .",
    "the joint action of orientation detection and cortical propagation along the vector fields completes the surface extending it on the set @xmath26 . in @xcite",
    "it is shown that it can be expressed as the solution of the minimal surface equation @xmath27 with internal boundary condition @xmath28 this last condition ensures that the existing boundaries are preserved , while the orientations of illusory boundaries or level lines are recovered as the 0 level set of the solution @xmath29 .",
    "this model performs completion of boundaries , giving rise to illusory contours , and of level lines , giving rise to amodal completion , as in the case of the macula cieca .",
    "but it is unable to perform filling when the level lines of the image are parallel to the missing or occluded regions , as in the case of modal completion of the kanizsa triangle .",
    "we explicitly note that this is a model of cortical 3d space of position and orientations . on the other hand",
    "the model defines a surface , that can be also expressed as a graph on the 2d space .    in facts ,",
    "if we project the previous two vector fields on the @xmath30 plane , we end up with a unique derivative @xmath31 since the projection of the vector @xmath32 on the same plane is @xmath33 .",
    "we explicitly note that the vector @xmath34 here is only formally similar to the vector @xmath35 in ( [ fields ] ) .",
    "indeed @xmath36 in [ field1 ] is a function while in ( [ fields ] ) @xmath14 was simply an axis of the 3d space .",
    "the minimal surfaces equation can now be represented as the equation for a graph of @xmath36 , which is a function of the two variables @xmath13 alone .",
    "hence the equation becomes : @xmath37 where @xmath14 coincides with @xmath20 on the existing boundaries .",
    "taking explicitly the derivative , the equation is equivalent to @xmath38 this equation can be interpreted as a second order directional derivative , in the direction @xmath39 .",
    "hence the norm , of the gradient coincides with the directional derivative : @xmath40 the projected norm of the gradient of @xmath14 reads : @xmath41@xmath42 it s easy to check that the second order equation is simply the euler langrangian equation of the dirichlet functional @xmath43 hence minima of this functional give rise to the same minimal graphs proposed in @xcite for boundary propagation ( see also @xcite for a detailed proof ) .",
    "we will provide a description of the low level vision process taking into account both the retinex model and the cortical neurogeometry .",
    "the task will be accomplished by considering the retinex model of section 2.1 as the particle term and the cortical model of section 2.2 as the field term of a classical gauge field theory .    in this way",
    "we will obtain an analogous of the classical theory of electromagnetism where both the particle and the fields are the unknown of the problem .",
    "indeed , instead of equation ( [ functional ] ) we propose a complete lagrangian , sum of three terms : a particle term , an interaction term and a field term .",
    "the particle term is @xmath44 and is directly inspired by the retinex model [ functional ] : it describes the reconstruction of the image from image boundaries .",
    "as described above it implements the perceptual invariance with respects to contrast .",
    "the next term describes the interaction beetween particle and field and it is again a retinex term acting not anymore on existing boundaries but on existing and illusory boundaries marked by the gauge field @xmath45 , that now is unknown :    @xmath46    it expresses the reconstruction of the image from the old and new boundaries explaining perceptual figure completion , by keeping contrast invariance properties .",
    "we explicitly note that in the minimization process @xmath45 will have the direction of @xmath47 , hence it will tend to be orthogonal to the existing boundaries or level lines .",
    "the orthogonality condition can be expressed in terms of directional derivatives in the direction of @xmath45 .",
    "finally the gauge field term will be analogous to the one of classical fields theories : @xmath48 in our case it expresses the propagation of existing contours allowing the creation of subjective contours , and it will be modified accordingly to the the model presented in section in 2.2 , making use of the previously recalled subriemannian metric .",
    "in fact , propagation is expected in the direction of the boundary , which is orthogonal to @xmath45 : @xmath49 .",
    "since this vector is not unitary , we will normalize it to reduce to the norm defined in ( [ norm ] ) .",
    "the induced squared norm of @xmath50 reads : @xmath51    equivalently , if we call @xmath52    this norm can be computed as @xmath53 hence the norm is formally the norm associated to the matrix @xmath54 . in this setting @xmath55",
    "is not invertile . on the contrary , in the riemannian setting",
    ", @xmath55 is invertible , and it has the role of the inverse of the metric of the space .",
    "when needed we will assume to introduce a small perturbation which makes its determinant non zero : @xmath56 we recall that the differential of @xmath45 is independent of the norm chosen , and it is the usual curl operator : @xmath57    the resulting functional @xmath58 is then @xmath59      the euler lagrange equation of the functional [ functionalnorm ] becomes : @xmath60    these equations clearly have the meaning inherited by the corresponding terms of the functional : the first term is the particle equation that takes the two boundary terms ( i.e. the rescaled laplacian @xmath61 of the original image and the contribution @xmath62 generated by the gauge field @xmath45 and performs a reconstruction of the image by filling in objects .",
    "note that the two terms @xmath63 and @xmath64 which generalize the retinex functional give rise to an unique particle equation .",
    "note that @xmath65 is a vector , hence the equation for @xmath45 is indeed a system . in the same equation the directional gradient is defined as @xmath66    where @xmath55 is defined in ( [ matrixg ] ) .",
    "the term @xmath67 coincides with @xmath68 ( see appendix a ) and precisely : @xmath69 ( here @xmath70 denotes the @xmath71 component of @xmath45 , not the derivative ) . in appendix",
    "a we provide its explicit expression as sum of three terms : @xmath72 the terms @xmath73 , @xmath74 , @xmath75 are defined in ( [ t12h ] ) .",
    "precisely @xmath76 is the directional laplacian associated to the considered metric .",
    "@xmath77 are advection terms , with coefficients depending on the metric , and @xmath78    the field equation on @xmath45 propagates the gradient of the image , in the subriemmanian metric , and allows to recover existing and subjective boundaries .",
    "we explicitly note that the equation is of second order in the variable @xmath45 . in general functional of higher order are necessary to obtain completion of curved boundaries ( as for example in the model of elastica @xcite ) .",
    "however here the field @xmath45 has the role of approximating the gradient of the image , following the lagrangian @xmath79 , hence its second derivatives express third derivatives of the image function .",
    "we remark that the differential equation for @xmath45 is non linear , in the sense that the metric @xmath55 depends on @xmath45 this means that we need to find an initial approximated solution @xmath80 .",
    "a natural choice is the solution of the vector laplace equation @xmath81 of course this is only an approximated solution @xmath80 , but we can recover a better one @xmath82 as a solution of @xmath83 using the subriemmannian operator associated to @xmath80 . recall that @xmath84 . from here",
    "we start an iteration : @xmath85 at each step we get a better approximation of the solution , moreover the sequence has a limit @xmath86 .",
    "passing to the limit in the previous expression , we will get : @xmath87 so that the limit provides a solution of the nonlinear equation .",
    "the functional @xmath88 is invariant with respect to the transformations : @xmath89 indeed @xmath90 since @xmath91 .",
    "this implies that the functional assumes the same values on @xmath92 and @xmath93 @xmath94    since the equation is invariant with respect to the choice of the gauge @xmath0 , we can freely choose it , and the choice of the gauge will not affect the value of the lagrangian . hence we will make the choice which decouples and symplifies the system , imposing @xmath95 . since @xmath96 the expression of @xmath97 reduces to @xmath98 where @xmath0 is an arbitrary choosen gauge function . to obtain @xmath95 we choose",
    "the function @xmath0 as a solution of @xmath99 that is a second order subriemannian differential equation .    with this choice of the gauge , the second order term of the system reduces to the simpler form :    @xmath100 where @xmath101 @xmath102@xmath103 in conclusion we can rewrite the euler lagrange equation ( [ euler ] ) in the form    @xmath104      the implementation of the algorithm consists in solving the system of coupled differential equation sequentially .",
    "we first apply the retinex equation to the initial ] and solve it by convolution @xmath105 with the fundamental solution of the 2d laplacian : @xmath106    then we solve the field equation for boundaries propagation . in this first phase",
    "we choose @xmath107 in the right hand side , and the nonlinear equation reduces to @xmath108 as we explained in the previous section , this equation will be solved by linearization , stopped after the first two steps : @xmath109 the solution of the first equation in can be computed by convolution @xmath110 where @xmath111 is the fundamental solution of the vector laplacian . when applied to the kanizsa inducers , the solution @xmath80 is visualized in figure [ a_lin ] , where the triangle inducers have been manually selected ( figure [ grad_ind ] ) .",
    "[ grad_ind ]     and @xmath112 components of @xmath113 related to the kanizsa triangle inducers . , title=\"fig:\",width=245 ]   and @xmath112 components of @xmath113 related to the kanizsa triangle inducers .",
    ", title=\"fig:\",width=245 ]    [ a_lin ]   generated by the kanizsa triangle inducers .",
    ", title=\"fig:\",width=207 ]    the second equation in the same system is a liner degenerate equation .",
    "if we approximate the matrix @xmath114 with its riemannian approximation @xmath115 , it becomes elliptic .",
    "the solution of the linear elliptic differential equation @xmath116 provides a good approximation of solution of the second equation in and it can be obtained by finite differences methods ( centered differences in space ) .",
    "the solution @xmath82 is shown in figure [ a_ind ] .",
    "[ a_ind ]     related to the kanizsa triangle inducers .",
    "@xmath82 is an approximation of the field @xmath45 , solution of the gauge field equation.,title=\"fig:\",width=245 ]   related to the kanizsa triangle inducers .",
    "@xmath82 is an approximation of the field @xmath45 , solution of the gauge field equation.,title=\"fig:\",width=245 ]    since particle and field equations are coupled we can now solve the complete particle equation @xmath117    again by convolution with the fundamental solution @xmath118 .",
    "this is a version of the retinex equation able to reconstruct the original image together with the subjective surface . in figure [ reconst_fig ]",
    "left it is visualized the forcing term @xmath119 of the particle equation while in figure [ reconst_fig ] right the solution @xmath120 is shown .",
    "[ reconst_fig ]   of the particle equation .",
    "right : the reconstructed kanizsa triangle as the solution @xmath120 of the particle equation.,title=\"fig:\",width=245 ]   of the particle equation .",
    "right : the reconstructed kanizsa triangle as the solution @xmath120 of the particle equation.,title=\"fig:\",width=245 ]      in order to further support our model , we will discuss how the different terms of the lagrangian can be implemented in neurophysiological structures .",
    "we recall that the visual signal is first elaborated by the retina whose receptive profiles are well modeled by the classical laplacian of gaussian : @xmath121 where @xmath122 is the standard laplacian .",
    "we can observe that the same receptive profiles are found in the lateral geniculate nucleus ( lgn ) , that is a copy of the retina but stricly in contact with the visual cortex .",
    "the action of these receptive fields on the visual signal can be represented as the output of the neural cell @xmath123 where @xmath124 is a smoothed version of the @xmath125 and the logarithmic function is due to the non linearity of the cell response .",
    "the output of lgn cells is propagated via the horizontal connectivity in lgn .",
    "since this connectivity is isotropic , it can be modeled with the fundamental solution @xmath126 of the 2d laplacian operator .",
    "lgn horizontal connectivity with strength @xmath127 acts linearly on the feedforward input @xmath128 , giving a total contribution @xmath129 this is exactly the solution of the laplacian equation ( [ deltafi ] ) of the particle term , implementing the reconstruction of the image from the boundaries .",
    "note that the action of receptive profiles @xmath130 and the one of lgn horizontal connectivity @xmath131 is dual in a differential sense .",
    "the gauge field equation in @xmath45 performs boundaries propagation and we will conjecture now how it is implemented at the cortical level .",
    "simple cells performs stimulus differentiation @xmath47 that is propagated by horizontal connectivity in the direction of the stimulus orientation@xcite . for this reason",
    "horizontal connectivity can be modelled by the fundamental solution of the vector laplacian @xmath132 and the total connectivity excited by the stimulus can be accounted as @xmath133 now , the feedforward output of simple cells @xmath47 is propagated by the excited connectivity @xmath80 generating the distribution @xmath82 , solution of : @xmath134 we have shown in @xcite that @xmath82 is the field tangent to the perceptual association fields measured by fields , hayes and hess in @xcite and it is cortically implemented by means of horizontal connectivity propagation .",
    "finally , the forcing term @xmath45 in the particle equation can be interpreted as the feedback of the cortical processing to lgn , showing the strength of the gauge field theory in coupling the activity of different physiological layers .",
    "equation ( [ complete ] ) is again the retinex equation , but with the feedback from v1 that takes into account illusory boundaries .",
    "in this paper we made the effort to construct a formal field theory of low level vision .",
    "contemporary instruments of field theory based on gauge invariances have been used to introduce a complete lagrangian with its particle , interaction and field terms .",
    "the lagrangian couples two well known models for lightness and boundary propagation , i.e. the retinex and the neurogeometrical models . particularly the problem of modal completion of illusory figures is faced and it is shown how the euler - lagrange field equations well represent the process of constitution of the kanizsa triangle with curved boundaries .",
    "but the interest of the model overcome the formal analogy with particle - fields physical theory .",
    "in facts it has to be considered as a plausible model for the interaction between different structures of the visual systems , particularly regarding the coupling between the activity of lgn and the one of the visual cortex .",
    "the gauge lagrangian formulation seems to be strongly enough to describe both the feedforward and the feedback processes of low level vision , by keeping the desired invariances .",
    "we rapidly recall here the definition of differential in the riemannian setting , in the special case where det @xmath55 is a constant , which is the case of the metric in [ ] .",
    "we will call @xmath135 since @xmath55 plays the role of inverse of the metric .",
    "then the riemannian scalar product is defined as :    @xmath136 if @xmath97 is a function then we will denote @xmath137 the usual differential , whose components are @xmath138 @xmath139 the gradient of the function @xmath97 in the metric @xmath124 is defined as @xmath140 in the sequel we will denote @xmath141 its components .",
    "the laplacian is expressed as @xmath142    if @xmath143 , then @xmath144 and the laplacian is not the laplacian of the two components in general , but can be expressed in terms of the @xmath145 and @xmath146 operators , which we will now define . since @xmath147 is a 2-form , first recall that for a general 2-form @xmath148              @xmath156 a_x    - \\partial_x ( \\nabla_g a_y)_y     - [ \\partial_x ,",
    "( \\nabla_g)_y ]   a_y   = 0\\\\   \\\\    \\partial_x(\\nabla_g a_y)_x   + [ \\partial_x , ( \\nabla_g)_x ] a_y    - \\partial_y(\\nabla_g a_x)_x    -   [ \\partial_y , ( \\nabla_g ) _ x]a_x   = 0 \\end{matrix}\\right.\\ ] ]      @xmath158 a_x     - [ \\partial_x ,   ( \\nabla_g)_y ] a_y   - \\partial_x (   ( \\nabla_g   a_x)_x     +   ( \\nabla_g a_y)_y ) = 0\\\\   \\\\   div (   \\nabla_g a_y )        + [ \\partial_x , ( \\nabla_g)_x ] a_y     -   [ \\partial_y , ( \\nabla_g ) _ x]a_x   - \\partial_y((\\nabla_g a_x)_x   + \\nabla_g a_y ) _ y)=0 \\end{matrix}\\right.\\ ] ]    now we give a name of each term in this expression , @xmath159 a_x     - [ \\partial_x ,   ( \\nabla_g)_y ] a_y = \\quad \\quad \\quad \\quad\\quad \\quad \\quad \\quad \\quad\\quad \\quad \\quad \\quad\\\\ \\quad \\quad \\quad \\quad\\quad \\quad \\quad \\quad = -\\partial_{y } g^{11}\\partial_{x } a_x - \\partial_{y}g^{12 } \\partial_{y } a_x - \\partial_{x}g^{21}\\partial_{x}a_y-\\partial_{x}g^{22}\\partial_{y}a_y   \\\\ t_y(\\vec{a})= [ \\partial_x , ( \\nabla_g)_x ] a_y-   [ \\partial_y , ( \\nabla_g ) _ x]a_x = \\quad \\quad \\quad \\quad\\quad \\quad \\quad \\quad \\quad\\quad \\quad \\quad \\quad\\\\ \\quad \\quad \\quad \\quad\\quad \\quad \\quad \\quad = - \\partial_{y}g^{12 } \\partial_{x } a_y -   \\partial_{y}g^{22}\\partial_{y } a_y   - \\partial_{x}g^{11 } \\partial_{x } a_x     - \\partial_{x}g^{12 } \\partial_{y } a_x   \\\\ a=   ( \\nabla_g a_x)_x   + ( \\nabla_g a_y ) _ y= g^{12 } \\partial_{x } a_y +   g^{22}\\partial_{y } a_y    + g^{11 } \\partial_{x } a_x    + g^{12 } \\partial_{y } a_x   \\end{matrix } \\right.\\ ] ]                            r. duits and e. m. franken , left invariant parabolic evolution equations on se(2 ) and contour enhancement via invertible orientation scores , part i : linear left - invariant diffusion equations on se(2 ) , quarterly of applied mathematics , ams , 68 , 255 - 292 , 2010 .",
    "r. duits and e. franken , left invariant parabolic evolution equations on se(2 ) and contour enhancement via invertible orientation scores , part ii : nonlinear left - invariant diffusion equations oninvertible orientation scores , \" quarterly of applied mathematics , ams , 68 , 293 - 331 , 2010 .",
    "t. georgiev , covariant derivatives and vision lecture notes in computer science ( including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics ) 3954 lncs , 56 - 69 , 2006 .",
    "r. palma - amestoy , e. provenzi , m. bertalmio , and v. caselles , a perceptually inspired variational framework for color enhancement , ieee transactions on pattern analysis and machine intelligence , 31 ( 3 ) , 458 - 474 , 2009 .",
    "a. sarti , r. malladi , j.a .",
    "sethian , subjective surfaces : a method for completing missing boundaries , proceedings of the national academy of sciences of the united states of america , 97 ( 12 ) , 6258 - 6263 , 2000 ."
  ],
  "abstract_text": [
    "<S> perceptual completion of figures is a basic process revealing the deep architecture of low level vision . in this paper a complete gauge field lagrangian </S>",
    "<S> is proposed allowing to couple the retinex equation with neurogeometrical models and to solve the problem of modal completion , i.e. the pop up of the kanizsa triangle . </S>",
    "<S> euler - lagrange equations are derived by variational calculus and numerically solved . </S>",
    "<S> plausible neurophysiological implementations of the particle and field equations are discussed and a model of the interaction between lgn and visual cortex is proposed . </S>"
  ]
}