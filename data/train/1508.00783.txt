{
  "article_text": [
    "nonlinear filters are important tools for dynamical data assimilation with applications in a variety of research areas , including biology @xcite , mathematical finance @xcite , signal processing @xcite , image processing @xcite , and multi - target tracking @xcite . to put it succinctly , nonlinear filtering is an extension of the bayesian framework to the estimation and prediction of nonlinear stochastic dynamics . in this effort",
    ", we consider the following nonlinear filtering model @xmath0 where @xmath1 and @xmath2 are two nonlinear functions , @xmath3 and @xmath4 are the stochastic state and observation processes , respectively , @xmath5 is a random vector representing the uncertainty in @xmath6 , and @xmath7 denotes the random measurement error in @xmath8 . in the discrete setting , the nonlinear filtering model in takes the form @xmath9 where @xmath10 and @xmath11 are mutually independent white noises .",
    "let @xmath12 denote the @xmath13 filed generated by the observational data up to the step @xmath14 .",
    "the goal of nonlinear filtering is to find the posterior probability density function ( pdf ) of the state @xmath15 , given the observation data @xmath16 , so as to compute the quantity of interest ( qoi ) , given by @xmath17 = \\inf\\left\\ { \\mathbb{e } [ | \\phi({x}_k ) - z |^2 ] ; z \\in \\mathcal{z}_k \\right\\},\\ ] ] where @xmath18 is a test function , and @xmath19 denotes the space of all @xmath16-measurable and square integrable random variables .",
    "tremendous efforts have been made to solve nonlinear filtering problems in the last few decades .",
    "two of the well - known bayesian filters are extended kalman filters ( ekfs ) @xcite , and particle filters @xcite .",
    "the key ingredient of the ekfs is the linearization of both @xmath1 and @xmath2 in , so that the standard kalman filter can be applied directly .",
    "thus , if the nonlinearity of the state and the observation systems is not severe , then the ekfs can provide efficient and reasonable inferences about the state , otherwise , the performance of the ekfs can be very poor . for particle filters , the central theme is to approximate the desired posterior pdf of the state by the empirical distribution of a set of adaptively selected random samples ( referred to as `` particles '' ) .",
    "the particle filter method is essentially a sequential monte carlo approach , which requires no assumption on the linearity of the underlying system . as such , with sufficiently large number of particles",
    ", it is capable of providing an accurate approximation of the posterior pdf for a highly nonlinear filtering problems .",
    "however , there are some fundamental issues concerning the efficiency and robustness of particle filters @xcite . for example , since the empirical pdf is constructed based on particles with equal weights after resampling , the particle filter still needs a lot of samples in order to accurately approximate the target distribution .    to overcome such a disadvantage , the authors proposed a new nonlinear filter named  implicit filter \" @xcite .",
    "this approach adopts the framework of bayesian filtering , which has two stages at each time step , i.e. , prediction and update . at the prediction stage",
    ", we estimate the prior pdf @xmath20 of the future state @xmath21 given the current available observation information @xmath22 ; at the update stage , we update the prior pdf by assimilating the newly received data @xmath23 to obtain the estimate of the posterior pdf @xmath24 . the implicit filter is distinguished from the particle filters by the use of interpolatory approximations to the prior and posterior pdfs .",
    "specifically , in the particle filter , @xmath20 is approximated by _",
    "explicitly _ propagating the samples of the current state @xmath25 through the nonlinear state equation @xmath26 , and constructing the empirical pdf of @xmath27 . in the implicit filter",
    ", the interpolation of @xmath20 requires its function values at a set of grid points of the future state @xmath28 . under the condition that @xmath29",
    ", we solve _ implicitly _ the state equation @xmath30 given a set of monte carlo samples of @xmath31 , so that the value of @xmath32 , at the grid point of @xmath33 , can be estimated by averaging the function values of @xmath34 at all the solutions of the state equation . as an implicit scheme , the implicit filter has a stabilizing effect which provides more accurate numerical approximations to the solution of the nonlinear filtering problem than the particle filter method @xcite .",
    "the main challenge of the implicit filter method is that the conditional pdf of the nonlinear filtering solution is estimated at grid points .",
    "as such the method suffers the so called `` the curse of dimensionality '' when the dimension of the state variable is high .",
    "in addition , the efficiency of the method may be significantly reduced when the domain of the pdf is unbounded . in this paper",
    ", we propose to construct a meshfree implicit filter algorithm to alleviate the aforementioned challenges .",
    "motivated by the particle filter method , we first generate a set of random particles and propagate these particles through the system model and use these particles to replace the grid points in the state space .",
    "after that we generate other necessary points through the shepard s method which constructs the interpolant by the weighted average of the values on state points @xcite . in order to prevent particle degeneracy in the generation of random state points",
    ", we introduce a resample step in the particle propagation .",
    "in addition we choose state points according to the system state , which make them adaptively located in the high probability region of the pdf of state . in this way , we solve the nonlinear filtering problem in a relatively small region in the state space at each time step and approximate the solution on a set of meshfree state points distributed adaptively to the desired pdf of the state .",
    "furthermore , since we approximate the pdf as a function on each state point , instead of using state points themselves to describe the empirical distribution , the implicit filter algorithm requires much fewer points than the particle filter method to depict the pdf of the state .",
    "the rest of this paper is organized as follows . in  [ bf ] , we introduce the mathematical framework of the bayesian optimal filter . in ",
    "[ algorithm ] , we construct meshfree implicit algorithm . in ",
    "[ sec : ex ] , we demonstrate the efficiency and accuracy of our algorithm through numerical experiments . finally ,  [ sec : con ] contains conclusions and directions for the future research .",
    "for @xmath35 , let @xmath36 and @xmath37 denote the @xmath13 fields generated by @xmath38 and @xmath39 , respectively . for @xmath40",
    ", we use @xmath41 to represent a realization of the random variable @xmath28 , and define @xmath42 for notational simplicity .",
    "it is easy to see that the dynamical model in is markovian in the sense that @xmath43 we also know that the measurements are conditionally independent given @xmath41 , i.e. , @xmath44 the bayesian optimal filter constructs the conditional distribution @xmath45 recursively in two stages : prediction stage and update stage .",
    "for @xmath46 , assume that @xmath47 is given .",
    "in the prediction stage @xmath48 is evaluated through the chapman - kolmogorov formula : @xmath49 in the update stage , the prior pdf obtained in is used to obtain the posterior pdf @xmath50 via the bayes formula : @xmath51",
    "in this section , we construct the meshfree implicit filter algorithm .",
    "the algorithm is based the implicit filter algorithm on grid points @xcite . the implicit filter algorithm introduced in @xcite",
    "is developed from the general framework of the bayesian optimal filter discussed above , in which the primary computational challenge is the numerical approximation of the term @xmath52 in .      for @xmath53 ,",
    "the goal of this stage is to approximate the prior distribution @xmath48 of the state @xmath28 , given the posterior distribution @xmath54 of the state @xmath55 . due to the the fact that @xmath56 = \\int_{\\mathbb{r}^{r } } p(x_k | x_{k-1 } , w_{k-1 } ) \\cdot p(w_{k-1 } ) d w_{k-1 } , \\ ] ] the prior pdf @xmath57 derived in identity can be rewritten as @xmath58 p(x_{k-1 } | y_{1:k-1 } ) d x_{k-1 } , \\end{aligned}\\ ] ] where @xmath59 $ ] represents the expectation with respect to the white noise @xmath31 , and the pdf @xmath60 is @xmath61 with @xmath62 for any @xmath63 and @xmath64 . the definition in can be viewed as a generalization of the dirac delta function in the space @xmath65 , where the mass is located according to the state equation @xmath66 .",
    "note that the estimation of requires an approximation to the expectation @xmath67 $ ] . to this end , we first draw @xmath68 independent samples @xmath69 of the white noise @xmath31 , and define an approximation to @xmath60 as @xmath70 with @xmath71 which is essentially a restriction of @xmath72 in the subset @xmath69",
    ". therefore , the expectation @xmath73 $ ] in can be approximated by @xmath74 & \\approx \\mathbb{e}_w\\left[\\pi^m(x_k | x_{k-1 } , w_{k-1})\\right ] , \\\\ & =   \\sum_{j=1}^m \\int_{\\mathbb{r}^r } \\delta_{w_{k-1}^{j}}(x_k| x_{k-1 } , w_{k-1 } ) p(w_{k-1})dw_{k-1}. \\end{aligned}\\ ] ] to construct an interpolation of @xmath75 , the next step is to approximate @xmath75 at a point set @xmath76 with @xmath77 . by substituting @xmath78 into - , we have @xmath79 p(x_{k-1 } | y_{1:k-1 } ) d x_{k-1 } + \\mathcal{r}_{k | k-1}^i , \\label{integ}\\ ] ] where @xmath80 p(x_{k-1 } | y_{1:k-1 } ) d x_{k-1}$ ] is the approximation error .",
    "then , by further fixing @xmath81 , the location of the mass of @xmath82 in the space of @xmath83 , denoted by @xmath84 , can be obtained by _",
    "implicitly _ solving the state equation @xmath85 which is the reason we named the approach the implicit filter . now substituting @xmath86 into , and using the same sample set @xmath87 as above to approximate the integral on the right hand side of",
    ", we obtain @xmath88 & =   \\sum_{j=1}^m \\left({\\frac}{1}{m}\\sum_{j'=1}^m \\delta_{w_{k-1}^{j}}(x_k^i| x_{k-1 } , w_{k-1}^{j'})\\right)\\\\ & = { \\frac}{1}{m}\\sum_{j=1}^m \\delta_{w_{k-1}^{j}}\\left(x_k^i| x_{k-1 } , w_{k-1}^{j}\\right ) , \\end{aligned}\\ ] ] then replacing @xmath89 $ ] in with , we have @xmath90 p(x_{k-1 } | y_{1:k-1 } ) d x_{k-1 } + \\mathcal{r}_{k | k-1}^i\\\\     & = { \\frac}{1}{m}\\sum^m_{j=1 } p \\left ( x^{i , j}_{k-1 } \\big| y_{1:k-1 } \\right ) + \\mathcal{r}_{k | k-1}^i ,    \\end{aligned}\\ ] ] where @xmath91 is the value of @xmath92 at @xmath93 . neglecting the error term @xmath94 in",
    ", we obtain the following iterative numerical scheme for constructing an approximation , denoted by @xmath95 , of the prior pdf @xmath96 , i.e. , @xmath97    in our previous work @xcite , the subsets @xmath98 , for @xmath99 , were defined by a full tensor product mesh , denoted by @xmath100 on a @xmath101-dimensional hyper - cube @xmath102 \\times \\cdots \\times [ a_d , b_d]$ ] , where @xmath103 , is a uniform partition of the interval @xmath104 $ ] with @xmath105 grid points .",
    "it is simple to implement but has several significant disadvantages .",
    "first , at each time step , one needs to approximate the prior pdf @xmath106 at a total of @xmath107 grid points which grows exponentially as the dimension @xmath101 increases .",
    "this is also known as `` the curse of dimensionality '' . on the other hand ,",
    "since the construction of @xmath108 is not informed by the target pdf , the domain @xmath102 \\times \\cdots \\times [ a_d , b_d]$ ] needs to be defined sufficiently large , so as to capture the statistically significant region of the pdf .",
    "this may lead to a great waste of computation effort in the low probability region of @xmath106 .",
    "to alleviate such disadvantages , we propose to develop a distribution - informed meshfree interpolation approach to efficiently approximate the prior pdf .",
    "the central idea of the generation of random points for the state variable is to build a set of points , denoted by @xmath98 , according to the state distribution . to begin with ,",
    "we generate @xmath109 of @xmath110 random samples from the initial pdf @xmath111 of the initial state : @xmath112 if the initial pdf @xmath111 is close to the true state distribution , it s obvious that our random state points are more concentrated near the target state . for @xmath113 ,",
    "we propagate points @xmath114 to @xmath115 through the state equation : @xmath116 where @xmath117 are @xmath110 random samples according to the pdf of @xmath31 . denote @xmath118 and approximate the conditional pdf @xmath119 on @xmath98 with the scheme given by . in this way , the random points in @xmath98 move according to the state model .",
    "as opposed to particle filter methods , which use the number of particles to represent empirical distributions and require a large number of particles to follow the state distribution , in the implicit filter method we provide an approximation of the value of the pdf at each state point .",
    "therefore , much fewer points are needed to describe the state pdf and the random state points are not necessary to accurately follow the state distribution .      by incorporating the new data @xmath23 , we update the prior pdf @xmath48 at each grid point @xmath86 , using the bayesian formula , to obtain @xmath120 where @xmath121 is given in , @xmath122 is the normalization factor , and @xmath123 is the approximation error . by neglecting the error term @xmath124 in @xmath125 , we obtain the following iterative numerical scheme for the update stage on @xmath98 , i.e. , @xmath126 where @xmath127 is desired the approximation of the posterior pdf @xmath128 .",
    "next , we use interpolation methods to construct the approximation @xmath129 of @xmath130 from values @xmath131 via @xmath132 where @xmath133 is the set of basis functions .",
    "since the state points in @xmath98 are generated randomly in the meshfree framework , standard polynomial interpolation @xcite is unstable due to the uncontrollable lebesgue constant .",
    "instead , we propose to use the shepard s method @xcite , which is an efficient meshfree interpolation technique , to construct the interpolant @xmath129 .",
    "the basic idea of the shepard s method is to use the weighted average of @xmath134 in the interpolating approximation .",
    "specifically , for a given point @xmath135 , we re - order the points in @xmath136 by the distances to @xmath137 to get a sequence @xmath138 such that @xmath139 where @xmath140 is the euclidean norm in @xmath141 .",
    "then , for a pre - chosen integer @xmath142 we use the first @xmath142 values in @xmath143 to approximate @xmath129 as follows @xmath144 where the weight @xmath145 is defined by @xmath146 note that @xmath147 . from",
    ", we have @xmath148 where @xmath149 is the error of the shepard s interpolation .",
    "we assume that @xmath130 has bounded first order derivative . for each pair",
    "@xmath150 and @xmath151 the approximation error @xmath152 is controlled by the distance @xmath153 and the derivative @xmath154 , where @xmath155 is a point between @xmath137 and @xmath156 .",
    "it is reasonable to assume that in high probability region of the derivative @xmath154 is large .",
    "it s worth pointing out that the random state points generated in this algorithm are concentrated in the high probability region .",
    "thus , if @xmath137 lies in the high probability region , the distance @xmath153 is small , which balances the error brought by the large derivative . on the other hand , if @xmath137 lies in the low probability region , although the distance @xmath153 is relatively large , the approximation error is still small due to the small value of the derivative @xmath154 .",
    "similar to the particle filter method , the above random state points generation suffers from the degeneracy problem for long term simulations , especially for high - dimensional problems .",
    "after several time steps , the probability density tends to concentrate on a few points which dramatically reduces the number of effective sample points in @xmath98 .    in this work ,",
    "we propose an occasional resampling procedure to address these problems and rejuvenate the random points cloud . at the time step @xmath157",
    ", the resampling procedure takes place after we obtain @xmath158 , in order to remove the degenerated points in @xmath159 using the information provided by @xmath158 .",
    "specifically , the first step is to develop a degeneracy metric to determine the necessity of doing resampling . to this end , we define the following degenerated subset @xmath160 , @xmath161 where @xmath162 is a user - defined threshold .",
    "we also define @xmath163 to be the index set of @xmath164 .",
    "then , the degeneracy of @xmath159 can be measured by the ratio @xmath165 $ ] , where @xmath166 denotes the number of points in a set .",
    "if the ratio is smaller than a threshold @xmath167 $ ] , then we will skip the resampling step and propagate @xmath159 to get @xmath136 ; otherwise , the set @xmath159 is considered degenerated , and the resampling procedure is needed .    in resampling , instead of propagating @xmath168 to @xmath169 , we aim at constructing an intermediate point set , denoted by @xmath170 and propagate @xmath171 through the state model to obtain @xmath136 . according to the definition of @xmath164 in",
    ", we consider the state points in @xmath172 are in the statistically significant region of @xmath173 , so that we first put those points in @xmath171 , i.e. , @xmath174 for the state points in @xmath164 , we replace them by generating new samples from @xmath175 using the importance sampling @xcite , i.e. , @xmath176 as a result , the resampling procedure helps us remove the state points with low probabilities , and makes the state point set @xmath136 concentrated in the high probability region of the posterior pdf @xmath175 at each time step .",
    "finally , we summarize the entire meshfree implicit filter algorithm introduced in  [ prediction]-[resampling ] in algorithm 1 below .",
    "p0.95 : _ the meshfree implicit filter algorithm _ +    1.1    [ algorithm2 ] : set the number of samples @xmath68 for estimating @xmath59 $ ] , the number of state points @xmath110 , the resampling thresholds @xmath177 and @xmath178 compute the ratio @xmath179 propagate @xmath159 through the state model to obtain @xmath136 resample and construct the intermediate state set @xmath171 propagate @xmath171 through the state model to obtain @xmath136 : solve @xmath180 using , at each point in @xmath98 : solve @xmath181 using and     +",
    "in this section , we present two numerical examples to examine the performance of our meshfree implicit filter method . in example 1",
    ", we use a two dimensional nonlinear filtering problem to show the distributions of the random points @xmath98 . in example 2 , we solve a three dimensional bearing - only tracking problem , which is a six dimensional nonlinear filtering problem . for this higher dimensional problem , we compare the accuracy and efficiency of our meshfree implicit filter method with the extended kalman filter and the particle filter .      in this example , we consider the two dimensional noise perturbed tumoral growth model @xcite    @xmath182    where @xmath183 is a two dimensional standard brownian motion and @xmath184 .",
    "the state process @xmath185 is a two dimensional vector , @xmath186 is defined as @xmath187 and @xmath188 here , @xmath189 models the gompertzian growth rate of the tumor and @xmath190 gives the degree of vascularization of the tumor which is also called `` angiogenic capacity '' .    to approximate the state variables ,",
    "we discretize the dynamic system in time and obtain a discrete state model @xmath191 here , @xmath192 is a two dimensional zero mean gaussian white noise process with covariance @xmath193 , where @xmath194 is the @xmath195 identity matrix and @xmath196 is the time partition stepsize .",
    "the measurement of the state model is given by @xmath197 where @xmath198 is a two dimensional zero mean gaussian white noise process with covariance @xmath199 , @xmath194 is a @xmath195 identity matrix and @xmath200 .    in the numerical experiment ,",
    "we use uniform time partition with stepsize @xmath201 and simulate the state process for @xmath202 with initial state @xmath203 and parameters @xmath204 , @xmath205 , @xmath206 . at time step @xmath207 , we initialize the prior pdf @xmath111 by @xmath208 , where @xmath209 and @xmath210    [ scatter_1 ] [ scatter_2 ] + [ scatter_3 ] [ scatter_10 ] + [ scatter_20 ] [ scatter_40 ] +    in figure [ scatter_0 ] , we plot @xmath211 random samples generated from the initial pdf @xmath111 , which are our initial random points @xmath212 .",
    "figure [ 2d_grids ] illustrates the behavior of random state points @xmath98 at time steps @xmath213 , respectively . in figure",
    "[ 2d_grids ] , the blue dots in each figure plot the random state points obtained by using the dynamic state points generation method introduced in section [ algorithm ] and the red cross in each figure gives the true state @xmath214 at the corresponding time step . from the figures we can see that all the points are moving according to the state model and",
    "are concentrated around the true state .    to present the accuracy of the algorithm",
    ", we show the simulation of the tumoral growth states in figure [ 2d_simulation ] .",
    "the black curves are the true @xmath215 and @xmath216 coordinate values of the tumoral growth states , respectively .",
    "the blue curves show the simulated states obtained by using the meshfree implicit filter method .",
    "[ 2d_simulation_x1 ] [ 2d_simulation_x2 ]      in this example , we study a six dimensional target tracking problem . in figure",
    "[ model_6d ] , the target , denoted by the red line , moves in the three dimensional space and two platforms on the ground , denoted by pentagons , take angular observations of the moving target .",
    "the state process @xmath217 is described by the following dynamic model @xmath218 where @xmath219 describes the position of the moving target which is controlled by parameters @xmath220 .",
    "the system noise @xmath221 is a zero mean gaussian white noise process with covariance @xmath222 , @xmath194 is the @xmath223 identity matrix and @xmath196 is a given time period , @xmath224 is a constant vector and @xmath1 is given by @xmath225    the measurements @xmath226 of the state process from the two locations are given by @xmath227 where @xmath198 is a 4 dimensional zero mean gaussian white noise process with covariance @xmath199 , @xmath194 is a @xmath228 identity matrix , @xmath229 , @xmath230 and @xmath231 are locations of two observers .",
    "[ com_6d_x1 ] [ com_6d_x2 ] + [ com_6d_x3 ] [ com_6d_x4 ] + [ com_6d_x5 ] [ com_6d_x6 ] +    we choose @xmath232 , @xmath233 , @xmath234 .",
    "also , we assume that platforms are located at @xmath235 , @xmath236 and the initial sate is given by a gaussian @xmath237 where @xmath238 and    @xmath239    the target will be observed over the time period @xmath240 . in the numerical experiments ,",
    "we compare the performance of our meshfree implicit filter with the extended kalman filter and the particle filter .",
    "in particular , we compare the estimated mean values of the states process along each dimension in figure [ 6d_state_comparison ] . in the particle filter method , we choose @xmath241 particles . in the meshfree implicit filter method",
    ", we choose the number of state points to be @xmath242 and the number of random samples in the implicit filter monte carlo simulation to be @xmath243 .",
    "the black curves in figure [ 6d_state_comparison ] show the real states process along each direction , the green curves give the estimated means obtained by the extended kalman filter method , the red curves give the estimated means obtained by the particle filter method , and the blue curves give the estimated means obtained by the meshfree implicit filter .",
    "we also plot the @xmath244 error @xmath245 corresponding to all three methods in figure [ 6d_l2 ] .",
    "as we can see from figure [ 6d_state_comparison ] and [ 6d_l2 ] , the implicit filter and the particle filter are much more accurate than the extended kalman filter and the implicit filter is the most accurate approximation in this experiment .    to further compare the efficiency between the meshfree implicit filter and the particle filter , we repeat the above experiment over @xmath246 realizations and show the average cpu time and the corresponding global root mean square error @xmath247 defined by @xmath248 where @xmath249 is the @xmath244 error of the @xmath250-realization at time step @xmath14 . in table [ efficiency ] , we can see that with @xmath241 particles , the cpu time of the particle filter method is comparable to that of the implicit filter with @xmath251 random state points , but the global rmse of the particle filter is more than doubled the rmse of the implicit filter . with @xmath252 particles , the particle filter method achieves an accuracy comparable to the implicit filter , but at a significantly higher cost .",
    ".example 2 : efficiency comparison [ cols=\"^,^,^\",options=\"header \" , ]",
    "in this work , we proposed an efficient meshfree implicit filter algorithm by evaluating the conditional pdf on meshfree points in the state space .",
    "these meshfree points are chosen adaptively according to the system state evolution .",
    "we also apply shepard s method as the meshfree interpolation method to compute interplants with random state points . in order to address the degeneracy of the random points , we use importance sampling method to construct a resample step .",
    "numerical examples demonstrate the effectiveness and efficiency of our algorithm . in the future",
    ", we plan to perform a rigorous numerical analysis for the meshfree implicit filter algorithm ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a meshfree approximation method for the implicit filter developed in @xcite , which is a novel numerical algorithm for nonlinear filtering problems . </S>",
    "<S> the implicit filter approximates conditional distributions in the optimal filter over a deterministic state space grid and is developed from samples of the current state obtained by solving the state equation implicitly . </S>",
    "<S> the purpose of the meshfree approximation is to improve the efficiency of the implicit filter in moderately high - dimensional problems . </S>",
    "<S> the construction of the algorithm includes generation of random state space points and a meshfree interpolation method . </S>",
    "<S> numerical experiments show the effectiveness and efficiency of our algorithm .    </S>",
    "<S> nonlinear filtering , implicit algorithm , meshfree approximation , shepard s method </S>"
  ]
}