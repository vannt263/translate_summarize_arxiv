{
  "article_text": [
    "the present distribution of galaxies brought to us by redshift surveys indicates that the universe on large scales exhibits a high degree of clumpiness with coherent structures such as voids , great walls , filaments and clusters . the cosmic microwave background ( cmb )",
    "explorers , however , indicate that the universe was highly homogeneous billions of years ago .",
    "when studying these data , among the questions that are of concern in cosmology are the initial conditions of the universe and the dynamics under which it grew into its present form .",
    "cmb explorers provide us with valuable knowledge into the initial conditions of the universe , but the present distribution of the galaxies opens a second , complementary window into its early state .    unraveling the properties of the early universe from the present data is an instance of the general class of _ inverse problems _ in physics . in cosmology",
    "this problem is frequently tackled in an empirical way by taking a _",
    "forward approach_. in this approach , a cosmological model is proposed for the initial power spectrum of dark matter .",
    "next , a particle presentation of the initial density field is made which provides the initial data for an n - body simulation which is run using newtonian dynamics and is stopped at the present time .",
    "subsequently , a _ statistical _ comparison between the outcome of the simulation and the observational data can be made , assuming that a suitable _ bias _ relation exists between the distribution of galaxies and that of dark matter .",
    "if the statistical test is satisfactory then the implication is that the initial condition was viable ; otherwise one changes the cosmological parameters and goes through the whole process again .",
    "this is repeated until one obtains a satisfactory statistical test , affirming a good choice for the initial condition .",
    "however , this inverse problem does not have to be necessarily dealt with in a forward manner .",
    "can one fit the present distribution of the galaxies _ exactly _ rather than statistically and run it back in time to make the _ reconstruction _ of the primordial density fluctuation field ?",
    "since newtonian gravity is time - reversible , one would have been able to integrate the equations of motions back in time and solve the reconstruction problem trivially , if in addition to their positions , the present velocities of the galaxies were also known . as a matter of fact , however , the peculiar velocities of only a few thousands of galaxies are known out of the hundreds of thousands whose redshifts have been measured . indeed , one goal of reconstruction is to evaluate the peculiar velocities of the galaxies and in this manner put direct constraints on cosmological parameters .    without a second boundary condition ,",
    "reconstruction would thus be an infeasible task .",
    "newton s equation of motion requires two boundary conditions , whereas , for reconstruction so far we only have mentioned the present positions of the galaxies .",
    "the second condition is the homogeneity of the initial density field : as we go back in time the peculiar velocities of the galaxies vanish .",
    "thus , contrary to the forward approach where one solves an _ initial - value problem _ , in the reconstruction approach one is dealing with a _ two - point boundary value problem_. in the former , one starts with the initial positions and velocities of the particles and solves newton s equations arriving at a _",
    "unique _ final position and velocity for a given particle . in the latter one",
    "does not always have _",
    "uniqueness_. this has been one of the shortcomings of reconstruction , which was consequently taken to be an ill - posed problem .    in this work , we report on a new method of reconstruction which guarantees uniqueness ( frisch et al .",
    "2002 ) . in section",
    "ii , we review the previous works on reconstruction .",
    "we describe our mathematical formulation of the reconstruction problem in section iii and show that the cosmological reconstruction problem , under our hypotheses , is an example of assignment problems in optimisation theory . in section iv , we describe the numerical algorithms to solve the assignment problem . in section",
    "v , we test our reconstruction method with numerical n - body simulation both in real and redshift spaces .",
    "section vi contains our conclusions .",
    "the history of reconstruction goes back to the work of peebles ( peebles 1989 ) on tracing the orbits of the members of the local group . in his approach ,",
    "reconstruction was solved as a variational problem .",
    "instead of solving the equations of motion , one searches for the stationary points of the corresponding euler - lagrange action .",
    "the action in the comoving coordinates is ( peebles 1980 ) s= _ 0^t_0 dt , [ action ] where summation over repeated indices and @xmath0 is implied , @xmath1 denotes the present time , the path of the @xmath2th particle with mass @xmath3 is @xmath4 , @xmath5 is the mean mass density , and the present value of the expansion parameter @xmath6 is @xmath7 .",
    "the equation of motion is obtained by requiring s= _ 0^t_0 dt = 0 , which leads to _ 0^t_0 dt _ i -m_i ^t_0_0 = 0 .",
    "[ umixed ] the boundary conditions _",
    "i&=&0 t = t_0 + a^2_i&=&0 t0 [ mixed ] would then eliminate the boundary terms in ( [ umixed ] ) .",
    "the components @xmath8 of the orbit of the @xmath2th particle are modeled as x_i^=x_i^(t_0)+_n c_i , n^f_n(t ) .",
    "[ coef ] the functions @xmath9 are normally convenient functions of the scale factor @xmath10 and should satisfy the boundary conditions ( [ mixed ] ) .",
    "initially , trial functions such as @xmath11 or @xmath12 with @xmath13 were used .",
    "the coefficients @xmath14 are then found by substituting expression ( [ coef ] ) in the action ( [ action ] ) and finding the stationary points .",
    "that is for physical trajectories = 0 , leading to m_i_0^t_0 dt f_n(t)= -ga^t_0_0 dt _",
    "j m_j x_j^-x_i^_i-*x*_j . [ actionmin ]    in his first work , peebles ( 1989 ) considered only the minimum of the action , while reconstructing the trajectories of the galaxies back in time . in a low - density universe , assuming a linear bias , the predicted velocities agreed with the observed ones for most galaxies of the local group but failed with a large discrepancy for the remaining members .",
    "later on , it was found that when the trajectories corresponding to the saddle - point of the action were taken instead of the minimum , much better an agreement between predicted and observed velocities was obtained , for almost all the galaxies in the local group ( see fig .",
    "[ peebles ] ) .",
    "thus , by adjusting the orbits until the predicted and observed velocities agreed , reasonable bounds on cosmological parameters were found ( peebles 1989 , 1990 ) .",
    "= 0.47    although rather successful when applied to catalogues such as ngb ( tully 1988 ) , reconstruction with such an aim , namely establishing bounds on cosmological parameters using measured peculiar velocities , could not be applied to larger galaxy redshift surveys , containing hundreds of thousands of galaxies for the majority of which the peculiar velocities are unknown . for large datasets , it is not possible to use the velocities , to choose the right orbit from the many which are all physically possible . in order to resolve the problem of multiple solutions ( the existence of many mathematically possible orbits ) one normally had to do significant smoothing and",
    "then try the computationally costly reconstruction using peebles variational approach ( shaya et al .",
    "1995 , branchini et al .",
    "however , one was still not guaranteed to have chosen the right orbit ( see hjorteland 1999 for a review of the action variational method ) .",
    "the multiple solution can be caused by various factors .",
    "for example , the discretisation in the numerical integrations ( [ actionmin ] ) can produce spurious valleys in the landscape of the euler  lagrange action .",
    "however , even overcoming all these numerical artifacts one is still not guaranteed uniqueness .",
    "there is a genuine physical reason for the lack of uniqueness which is often referred to in cosmology as _",
    "multistreaming_. cold dark matter ( cdm ) is a collisionless fluid with no velocity dispersion .",
    "an important feature that arises in the course of the evolution of a self - gravitating cdm universe is the formation of multistream regions on which the velocity field is non - unique .",
    "these regions are bounded by caustics at which the density is divergent . at a multistream point",
    "where velocity is multiple - valued , a particle can have many different mathematically viable trajectories each of which would correspond to a different stationary point of the euler  lagrange action which is no - longer _",
    "convex_.    in addition to the variational approach to reconstruction , there is the well - known potent reconstruction of the three - dimensional velocity field from its radial component ( dekel et al .",
    "the potent method is the non - iterative eulerian version of the original iterative lagrangian method ( bertschinger and dekel 1989 ) and assumes potential flow in eulerian space .",
    "potent finds the velocity potential field by integrating the radial components of the velocities along the line of sight .",
    "since this is an eulerian method , its validity does not extend much beyond the linear eulerian regime .    in following works , with the use of potent - reconstructed velocity field or the density field obtained from the analysis of the redshift surveys ,",
    "the gravitational potential field was also reconstructed ( nusser and dekel 1992 ) .",
    "the gravitational potential was then traced back in time using the so - called zeldovich  bernoulli equation which combines the zeldovich approximation with the euler momentum conservation equation .",
    "later on , it was further shown ( gramann 1993 ) that the initial gravitational potential is more accurately recovered using the zeldovich - continuity equation which combines the zeldovich approximation with the mass continuity equation ( nusser et al .",
    "the eulerian formulations of zeldovich approximation was also extended to second - order and it was found that this extension does not give significant improvement in the reconstruction ( monaco and efstathiou 1999 , see sahni and coles 1995 for various approximation schemes ) .",
    "however , these procedures are valid only as long as the density fluctuations are in the eulerian linear or quasi - linear regimes ( defined by @xmath15 ) .",
    "they do not robustly recover the initial density in regions of high density when the present - day structures are highly nonlinear ( @xmath16 ) .",
    "therefore , they require that the final density field be smoothed quite heavily to remove any severe nonlinearities , before the dynamical evolution equations are integrated backward in time .    here , we describe a new method of reconstruction ( frisch et al .",
    "2002 ) which not only overcomes the problem of nonuniqueness encountered in the least - action - based methods but also remains valid well beyond the linear eulerian approximations employed in many other popular reconstruction methods , a few of which have been mentioned previously .",
    "thus , reconstruction is a well - posed problem for as long as we avoid multistream regions .",
    "the mathematical formulation of this problem is as follows ( frisch et al . 2002 ) . unlike most of the previous works on reconstruction where one studies the euler - lagrange action , we start from a constraint equation , namely the mass conservation , ( * x*)d*x*=_0(*q * ) d*q * , where @xmath17 is the density at the initial ( or lagrangian ) position , @xmath18 , and @xmath19 is the density at the present ( or eulerian ) position , @xmath20 , of the fluid element .",
    "the above mass conservation equation can be rearranged in the following form = ( * x*)_0(*q * ) , [ det ] where @xmath21 stands for determinant and @xmath17 is constant .",
    "the right - hand - side of the above expression is basically given by our boundary conditions : the final positions of the particles are known and the initial distribution is homogeneous , @xmath22 . to solve the equation , we make the following two hypotheses : first that the lagrangian map ( @xmath23 ) is the _ gradient _ of a potential @xmath24 and second that the potential @xmath24 is _ convex _ . that is ( * q*,t)=_q(*q*,t ) .",
    "the convexity guarantees that a single lagrangian position corresponds to a single eulerian position , _",
    "i.e. _ , there has been no multistreaming .",
    "these assumptions imply that the inverse map @xmath25 has also a potential representation = * * _ * x*(*x*,t ) , where the potential @xmath26 is also a convex function and is related to @xmath27 by the legendre ",
    "fenchel transform ( e.g. arnold 1978 ) ( * x*)=_*q*;(*q*)= _ * x*. the inverse map is now substituted in ( [ det ] ) yielding = ( * x*)_0(*q * ) , [ ma ] which is the well - known monge  ampre equation .",
    "the solution to this 222 years old problem has recently been discovered ( brenier 1987 , benamou and brenier 2000 ) when it was realised that the map generated by the solution to the monge  ampre equation is the unique solution to an optimisation problem .",
    "this is the monge  kantorovich mass transportation problem , in which one seeks the map @xmath28 which minimises the quadratic _ cost _ function i=_*q * _ 0(*q*)-*q*^2 d^3q= _ * x * ( * x*)-*q*^2 d^3x .",
    "[ cost ] a sketch of the proof is as follows . a small variation in the cost function yields i=_*x * d^3x , which must be supplemented by the condition _ * x*((*x*))=0 , which expresses the constraint that the eulerian density remains unchanged .",
    "the vanishing of @xmath29 should then hold for all @xmath30 which are orthogonal ( in @xmath31 ) to functions of zero divergence .",
    "these are clearly gradients . hence @xmath32 and thus @xmath33 is a gradient of a function of @xmath20 .",
    "discretising the cost ( [ cost ] ) into equal mass units yields i=_j()(_i=1^n(*q*_j(i)- * x*_i)^2 ) .",
    "[ assign ] the formulation presented in ( [ assign ] ) is known as the _ assignment problem _ : given @xmath34 initial and @xmath34 final entries one has to find the permutation which minimises the quadratic cost function ( see fig .",
    "[ poobles ] ) .",
    "if one were to solve the assignment problem for @xmath34 particles directly , one would need to search among @xmath35 possible permutations for the one which has the minimum cost .",
    "however , advanced assignment algorithms exist which reduce the complexity of the problem from factorial to polynomial ( so far for our problem as verified by numerical tests for @xmath36 , _",
    "e.g. _ , burkard and derigs 1980 algorithm has a complexity of @xmath37 for a constant - volume sampling of particles and a complexity of @xmath38 for a constant - density sampling .",
    "the bertsekas 1998 auction algorithm has a complexity of @xmath39 in both cases ) . before discussing these methods ,",
    "let us briefly comment on a class of stochastic algorithms , which do not give uniqueness and hence should be avoided .    in the piza method of solving the assignment problem ( croft & gaztaaga 1997 ) , initially a random pairing between @xmath34 lagrangian and @xmath34 eulerian coordinates",
    "starting from this initial random one - to - one assignment , subsequently a pair ( corresponding to two eulerian and two lagrangian positions ) is chosen at random .",
    "for example , let us consider the randomly - selected pair @xmath40 and @xmath41 which have been assigned in the initial random assignment to @xmath42 and @xmath43 respectively .",
    "next one swaps their lagrangian coordinates and assigns @xmath40 to @xmath43 and @xmath41 to @xmath42 in this example .",
    "if > , then one swaps the lagrangian positions , otherwise , one keeps the original assignment .",
    "this process is repeated until one is convinced that a lower cost can not be achieved . however , in this manner there is no guarantee that the optimal assignment has been achieved and the true minimum cost has been found . moreover , there is a possibility of deadlock when the cost can be decreased only by a simultaneous interchange of three or more particles , while the piza algorithm reports a spurious minimum of the cost with respect to two - particle interchanges .",
    "results obtained in this way depend strongly on the choice of initial random assignment and on the random selection of the pairs and suffer severely from the lack of uniqueness ( see fig .",
    "[ exactpizaseed1-exactpizaseed2 - 2 ] ) .    in spite of these problems associated with piza - type algorithms in solving the assignment problem ,",
    "it has been shown ( narayanan and croft 1999 ) in a point - by - point comparison of the reconstructed with the true initial density field from a n - body simulation , that piza performs better than other methods such as those based on a eulerian formulation of the zeldovich approximation ( discussed at the end of section ii ) .",
    "= 0.47    there are various deterministic algorithms which guarantee that the optimal assignment is found .",
    "an example is an algorithm written by hnon ( hnon 1995 ) , demonstrated in fig .",
    "[ henon1 ] . in this approach ,",
    "a simple mechanical device is defined and then simulated which solves the assignment problem .",
    "the device acts as an _ analog computer _ :",
    "the numbers entering the problem are represented by physical quantities and the equations are replaced by physical laws .",
    "one starts with @xmath34 columns @xmath44s ( which represent the lagrangian positions of the particles ) and @xmath34 rows , @xmath45s ( which represent the eulerian positions of the particles ) .",
    "on each row there are @xmath34 studs whose lengths are directly related to the distances between that row and each column .",
    "the columns are given negative weights of @xmath46 and act as floats and the rows are given weights of @xmath47 .",
    "the potential energy of the system shown in fig .",
    "[ henon1 ] , within an additive constant , is u=_i _",
    "i-_j _ j , [ pe ] where @xmath48 is the height of the row @xmath49 and @xmath50 is the height of the column @xmath51 , since all rows and columns have the same weight ( @xmath47 and @xmath46 respectively ) .",
    "initially , all rods are maintained at a fixed position by two additional rods @xmath52 and @xmath53 with the row @xmath49 above column @xmath51 , so that there is no contact between the rows and the studs .",
    "next , the rods are released by removing the holds @xmath52 and @xmath53 and the system starts evolving : rows go down and columns go up and the contacts are made with the studs . aggregates of rows and columns are progressively formed .",
    "as new contacts are made , these aggregates are modified and thus a complicated evolution follows which is graphically demonstrated with a simple example in fig .",
    "[ henon2 ] .",
    "one can then show that an equilibrium where the potential energy ( [ pe ] ) of the system is minimum will be reached after a _ finite time_. it can then be shown ( hnon 1995 ) that if the system is in equilibrium and the column @xmath51 is in contact with row @xmath49 then the force @xmath54 is the optimal solution of the assignment problem . when @xmath54 is equal to one there is an assignment between rows and columns and when @xmath54 is equal to zero there is no assignment .",
    "the potential energy of the corresponding equilibrium is equivalent to the total _ cost _ of the optimal solution .",
    "true in    .",
    "[ henon1 ]    = 5 true in",
    "thus , in our reconstruction method , the initial positions of the particles are uniquely found by solving the assignment problem .",
    "this result was based on our reconstruction hypothesis .",
    "we could test the validity of our hypothesis by direct comparison with numerical n - body simulations which is what we shall demonstrate later in this section .",
    "however , it is worth commenting briefly on the theoretical , observational and numerical justifications for our hypothesis .",
    "it is well - known that the zeldovich approximation ( zeldovich 1970 ) works well in describing the large - scale structure of the universe . in",
    "the zeldovich approximation particles move with their initial velocities on inertial trajectories in appropriately redefined coordinates .",
    "it is also known that the irrotationality of the particle displacements ( expressed in lagrangian coordinates ) remains valid even at the second - order in the lagrangian perturbation theory ( moutarde et al .",
    "1991 ; buchert 1992 ; munshi et al .",
    "1994 ; catelan 1995 ) .",
    "this provides the theoretical motivation for our first hypothesis .",
    "the lack of severe multistream regions is confirmed by the geometrical properties of the cosmological structures . in the presence of significant multistreaming such as the one that occurs in zeldovich approximation",
    ", one could not expect the formation of long - lived structures such as filaments and walls which is observed in numerical n - body simulations . in the presence of significant multistreaming",
    "these structures would form and would smear out and disappear rapidly .",
    "this is not backed by numerical simulations .",
    "the latter show the formation of shock - like structures well - described by burgers model ( a model of shock formation and evolution in a compressible fluid ) , which has been extensively used to describe the large - scale structure of the universe ( gurbatov & saichev 1984 ; gurbatov , saichev & shandarin 1989 ; shandarin & zeldovich 1989 ; vergassola et al .",
    "the success of burgers model indicates that a viscosity - generating mechanism operates at small scales in collisionless systems resulting in the formation of shock - like structures rather than caustic - like structures .    in spite of this evidence in support of our reconstruction hypothesis , one needs to test it before applying it to real galaxy catalogues .",
    "we have tested our reconstruction against numerical n - body simulation .",
    "we ran a @xmath55cdm simulation of @xmath56 dark matter particles , using the adaptive p@xmath57 m code hydra ( couchman et al .",
    "our cosmological parameters are @xmath58 and a box size of @xmath59mpc / h . we took two sparse samples of @xmath60 and @xmath61 particles corresponding to grids of @xmath62mpc and @xmath63mpc respectively , at @xmath64 and placed them initially on a uniform grid . for the @xmath60 particle reconstruction , the sparse sampling was done by first selecting a subset of @xmath65 particles on a regular eulerian grid and then selecting all the particles which remained inside a spherical cut of radius half the size of the simulation box .",
    "the sparse sample of @xmath61 points was made randomly .",
    "an assignment algorithm , similar to that of hnon described in the previous section , is used to find the correspondence between the eulerian and the lagrangian positions .",
    "the results of our test are shown in fig .",
    "[ pobles ] .",
    "= 0.49    it is instructive to compare our results presented in fig .",
    "[ pobles ] with those obtained by a stochastic piza - type algorithms .",
    "[ mak1-piza_nonmonotonic_seed1 ] demonstrates such a comparison .",
    "we see that not only the stochastic algorithms do not guarantee uniqueness , as demonstrated in fig .",
    "[ exactpizaseed1-exactpizaseed2 - 2 ] , but also the number of exactly reconstructed points by these algorithms are much below those obtained by our deterministic algorithm .",
    "= 0.6    when reconstructing from observational data , in redshift space , the galaxies positions are displaced radially by an amount proportional to the radial component of the peculiar velocity in the line of sight .",
    "thus for real catalogues , the cost minimisation need be performed using redshift space coordinates ( valentine et al .",
    "the redshift position of a galaxy is given by = * x*+(h ) , [ red ] where under our assumption of irrotationality and convexity of the lagrangian map and to first order in lagrangian perturbation theory , = h ( * x*-*q * ) and @xmath66 with @xmath67 and the bias factor is @xmath68 .",
    "the quadratic cost function can then be easily found in terms of redshift space coordinates as follows ( * x*-*q*)^2= ( * s*-*q*)^2- ( 2+)(1+)^2 ( ( * s*-*q*))^2 .",
    "[ costred ] using mak , based now on the modified cost ( [ assign ] ) we can then find the corresponding @xmath18 for each @xmath69 and hence find the peculiar velocities . indeed , using ( [ red ] ) -*q*= h(1+b_m^0.6 ) .",
    "note that in this approach the motion of the local group itself is ignored , which however should also be accounted for ( taylor & valentine 1999 ) .",
    "furthermore , the effect of catalogue selection function can be handled by giving each galaxy an _ effective - mass _ inversely proportional to the catalogue selection function ( nusser and branchini 2000 ) .",
    "we have also assumed that galaxies are unbiased tracers of the mass distribution .",
    "however , the relative bias between galaxies of different luminosities and of different morphological types indicate that galaxies are likely to be biased tracers of mass distribution ( e.g. loveday et al .",
    "biasing can be taken into account in a similar manner to the catalogue selection function ( nusser and branchini 2000 ) .",
    "the net effect of biasing for our scheme is that it changes the effective - mass associated to the galaxies which can be easily incorporated in our cost function ( [ assign ] ) , by multiplying the quadratic function inside the sum by the effective - mass @xmath3 associated with each eulerian position @xmath70 .",
    "we have also performed mak reconstruction with the redshift - modified cost function which led to somewhat degraded results but at the same time provided an approximate determination of peculiar velocities ( see fig .",
    "[ fig3-marseille ] ) . a more accurate determination of peculiar velocities can be made using second - order lagrangian perturbation theory ( e.g. catelan 1995 and refs .",
    "therein ) .",
    "= 0.58    we have also compared the redshift - space mak reconstruction to real space mak reconstruction , which shows that almost @xmath71 of exactly - reconstructed positions correspond to the same points ( see fig .  [ redshiftreal ] ) .",
    "this test shows that mak is robust against systematic errors .",
    "= 0.45    therefore the question that one asks at this point is : where does reconstruction perform poorly ?",
    "= 0.47    fig .",
    "[ failed ] highlights where exact reconstruction fails .",
    "we see that exact reconstruction is not achieved in particular in the dense regions . achieving reconstruction at small scales",
    "remains a subject of on - going research .",
    "as long as multistreaming effects are unimportant , that is above @xmath72 mpc , uniqueness of the reconstruction is guaranteed .",
    "approximate algorithms capturing such highly nonlinear effects are now being developed .",
    "an accurate reconstruction allows us to test cosmological models by simulating the evolution starting from the reconstructed primordial state and comparing it to observations .",
    "efficient and unique reconstruction would allows us to determine the peculiar velocities of a large number of galaxies , using their positions in redshift catalogues .",
    "one could use reconstruction to search for the presence of primordial non - gaussianity and examine the self - consistency of cosmological hypotheses such as the choice of the global cosmological parameters and the assumed biasing scheme . by obtaining a point - by - point reconstruction of the specific realisation that describes the observed patch of our universe , one could separate the universal properties and the influence of the large - scale environment on the galaxy formation process .    many previous reconstruction techniques have either suffered from the lack of uniqueness or limited validity which could not be extended beyond the linear eulerian regime .",
    "our reconstruction scheme overcomes such shortcomings .",
    "we have shown that under suitable hypotheses , there is a unique transformation from the present positions @xmath20 of galaxies ( taken as mass tracers ) to their respective initial positions @xmath18 .",
    "our reconstruction hypothesis first assumes that the lagrangian map @xmath28 can be written in terms of a potential @xmath73 .",
    "this hypothesis is supported by numerical n - body simulations and is valid up to second order lagrangian perturbation theory .",
    "the second assumption is the convexity of the potential @xmath74 , a consequence of which is the absence of multi - streaming : for almost any eulerian position , there is a single lagrangian antecedent .",
    "as is well - known , the zeldovich approximation leads to caustics and multistreaming .",
    "this can be modified in various ways , for example by the introduction of a mock viscosity as is done in the adhesion model ( gurbatov and saichev 1984 , gurbatov et al .",
    "1989 , shandarin and zeldovich 1994 ) .",
    "the latter which leads to shocks rather than caustics , is known to have a convex potential ( vergassola et al .",
    "1994 ) and to be in a better agreement with numerical n - body simulations ( weinberg and gunn 1990 ) .    by testing our mak reconstruction against numerical n - body simulations both in real and redshift spaces",
    ", we have demonstrated that our reconstruction hypothesis works well down to the scales comparable to the size of collapsed structures , below which the hydrodynamical description of gravitational structure formation ceases to be meaningful ( at scales larger than @xmath62 mpc / h we achieve more than @xmath75 exact reconstruction ) .",
    "thus , our reconstruction is rather suitable for large - scale galaxy redshift surveys .",
    "we thank e. branchini , m. hnon , j.a . de freitas pacheco and p. thomas for discussions and comments .",
    "u.f thanks the indo - french center for the promotion of advanced research ( ifcpar 2404 - 2 ) .",
    "a.s . is supported by a cnrs henri poincar fellowship and rfbr 02 - 01 - 01062 .",
    "is supported by the european union marie curie fellowship hpmf - ct-2002 - 01532 .",
    "arnold v.i .",
    ", _ mathematical methods of classical mechanics _",
    "( springer , berlin 1978 ) benamou j .- d . &",
    "brenier y. 2000 , _ the optimal time - continuous mass transport problem and its augmented lagrangian numerical resolution _",
    ", numer . math . *",
    "84 * , 375 @xmath76also at http://www.inria.fr/rrrt/rr-3356.html @xmath77 bertsekas d.p . , _ network optimisation : continuous and discrete models _ ( athena scientific 1998 ) @xmath76auction algorithm also available at http://web.mit.edu/dimitrib/www/auction.txt@xmath77 bertschinger e. and dekel a. 1989 , apj * 336 * , l5 branchini e. , nusser a. and eldar a. 2001 , mnras * 335 * , 53 brenier y. 1987 , c.r.acad.sci . * 305 * , 805 buchert t. 1992 , mnras * 254 * , 729 burkard r.e . and derigs u. , _ assignment and matching problems : solution methods with fortran - programs _ , lecture notes in economics and mathematical systems no . 184 ( springer , berlin 1980 ) catelan p. 1995",
    ", mnras * 276 * , 115 couchman h.m.p . ,",
    "thomas p.a . and pearce f.r .",
    "1995 , apj * 452 * , 797 croft r.a . and gaztaaga 1997 , mnras * 285 * , 793 dekel a. , bertschinger e. and faber s.m .",
    "1990 , apj * 364 * , 349 frisch u. , matarrese s. , mohayaee r. and sobolevskii a. 2002 , nature * 417 * , 260 gramann , m. 1993 , apj * 405 * , 449 gurbatov s. and saichev a.i . 1984 ,",
    "* 27 * , 303 gurbatov s. , saichev a.i . and",
    "shandarin s.f . , 1989 , mnras",
    "* 236 * , 385 hnon m.a .",
    "1995 , c.r.acad.sci . *",
    "321 * , 741 @xmath76a detailed version with the optimisation algorithm is available at http://arxiv.org/abs/math.oc/0209047 @xmath77 hjorteland t.,_the action variational principle in cosmology _ , thesis , institute of theoretical physics , univ . of oslo ,",
    "june 1999 @xmath76also available at : http://trond.gothamnights.com/thesis/ thesis.pdf @xmath77 loveday j. , maddox s.j . , efstathiou g. and peterson b.a . 1995 ,",
    "apj * 442 * , 457 monaco p. and efstathiou g. 1999 , mnras * 308 * , 763 moutarde f. , alimi j .-",
    ", bouchet f.r .",
    ", pellat r. and ramani a. 1991 , apj * 382 * , 377 munshi d. , sahni v. and starobinsky 1994 , apj * 436 * , 517 narayanan v.k . and",
    "croft r.a.c .",
    "1999 , apj * 515 * , 471 nusser a. and branchini e. 2000 , mnras * 313 * , 587 nusser a. , dekel a. bertschinger e. and blumenthal g. 1991 apj * 379 * , 6 nusser a. and dekel a. 1992 apj * 391 * , 443 peebles p.j.e . _ the large scale structure of the universe _ ( princeton university press , 1980 ) peebles p.j.e .",
    "1989 , apj * l344 * , 53 peebles p.j.e . 1990 ,",
    "apj * 362 * , 1 sahni v. and coles p. 1995",
    ", phys . rept . *",
    "262 * , 1 shandarin s.f . and zeldovich y.b . 1989 , rev .",
    "* 61 * , 185 shaya e.j .",
    ", peebles p.j.e . and tully r.b .",
    "1995 , apj * 454 * , 15 taylor a. and valentine h. , 1999 , mnras * 306 * 491 tully r.b .",
    ", _ nearby galaxies catalog _ , cambridge university press ( cambridge , uk 1988 ) valentine h. , saunders w. and taylor a. 2000 , mnras * 319 * l13 vergassola m. , dubrulle b. , frisch u. and noullez a. 1994 , a&a * 289 * 325 weinberg d.h . and",
    "gunn j.e . 1990 , mnras * 247 * , 260 zeldovich y.b .",
    "1970 , astron . & astrophys . * 5 * , 84"
  ],
  "abstract_text": [
    "<S> a method for the reconstruction of the primordial density fluctuation field is presented . various previous approaches to this problem rendered _ non - unique _ solutions . here </S>",
    "<S> , it is demonstrated that the initial positions of dark matter fluid elements , under the hypothesis that their displacement is the gradient of a convex potential , can be reconstructed uniquely . in our approach , </S>",
    "<S> the cosmological reconstruction problem is reformulated as an assignment problem in optimisation theory . when tested against numerical simulations , </S>",
    "<S> our scheme yields excellent reconstruction on scales larger than a few megaparsecs . </S>"
  ]
}