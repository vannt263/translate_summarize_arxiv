{
  "article_text": [
    "[ [ randomized - rounding ] ] randomized rounding : + + + + + + + + + + + + + + + + + + + + +    randomized rounding @xcite is a probabilistic method @xcite for the design of approximation algorithms . typically , one formulates an np - hard problem as an integer linear program , disregards the integrality constraints , solves the resulting linear program , and randomly rounds each coordinate of the solution up or down with probability depending on the fractional part .",
    "one shows that , with non - zero probability , the rounded solution approximates the optimal solution .",
    "this yields a randomized algorithm ; in most cases it can be derandomized by the method of conditional probabilities @xcite .",
    "the probabilistic analyses are often simple , relying on just a few basic techniques . yet for many np - hard problems , randomized rounding yields the best approximation known by any polynomial time algorithm @xcite .",
    "[ [ oblivious - rounding ] ] oblivious rounding : + + + + + + + + + + + + + + + + + + + +    derandomized or not , a main drawback of randomized rounding algorithms has been that they first solve a linear program to find a solution to round .",
    "we show that this bottleneck can sometimes be avoided as follows : ( 1 ) show that randomly rounding an optimal solution ( possibly to smaller - than - integer units ) yields an approximate solution ; ( 2 ) apply the method of conditional probabilities , finding pessimistic estimators @xcite that are essentially _ independent _ of the optimal solution .",
    "the method of conditional probabilities is used not to derandomize per se , but to achieve the independence .",
    "[ [ generalized - packing - and - covering ] ] generalized packing and covering : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the resulting algorithms find the approximate solution without first computing the optimal solution .",
    "this allows randomized rounding to give simpler and more efficient algorithms and makes it applicable for integer _ and _ non - integer linear programming . to demonstrate this , we give approximation algorithms for general packing and covering problems corresponding to integer and non - integer linear programs of small _ width _ , including a parallel algorithm for finding sparse , near - optimal strategies for zero - sum games .",
    "packing and covering problems have been extensively studied ( see  [ related - work ] ) .",
    "for example , plotkin , shmoys , and tardos @xcite approached these problems using lagrangian - relaxation techniques directly .",
    "their algorithms and ours share the following features : ( 1 ) they depend similarly on the width , ( 2 ) they are lagrangian - relaxation algorithms , ( 3 ) they allow the packing or covering set to be given by a ( possibly approximate ) subroutine for optimizing over it , ( 4 ) they produce dual solutions that prove near - optimality , and ( 5 ) they can provide integer solutions comparable to those obtainable by randomized rounding .",
    "our approach shows a strong connection between probabilistic techniques and lagrangian relaxation .",
    "our algorithms are also relatively simple , although they are not as effective for some problems of large width .    [ [ flavor - of - oblivious - rounding - algorithms ] ] flavor of oblivious rounding algorithms : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for the ( integer ) set cover problem , oblivious rounding yields the greedy set cover algorithm @xcite . for",
    "the _ fractional _ set cover problem , it yields an algorithm that repeatedly chooses a set whose elements have the largest net weight , where the weight of an element is initially @xmath0 and is multiplied by @xmath1 each time a set containing it is chosen . to obtain the final cover , each set",
    "is assigned a weight proportional to the number of times it was chosen ( this is similar in spirit to @xcite and related works ) . for multicommodity flow , it yields algorithms that repeatedly augment flow along a shortest path , where the length of an edge is initially @xmath0 and is multiplied by @xmath2 each time the edge is used ( @xmath3 is the capacity of the edge and @xmath4 is the minimum edge capacity ) .",
    "[ [ problem - definitions ] ] problem definitions : + + + + + + + + + + + + + + + + + + + + +    let @xmath5 be a convex set in @xmath6 and let @xmath7 be a linear function ( not nec .",
    "homogenous ) from @xmath5 to @xmath8 .",
    "the _ width _ of @xmath5 with respect to @xmath7 is @xmath9 , where @xmath10 .",
    "the _ generalized packing problem _ is to compute @xmath11 .",
    "the _ packing problem _ occurs when @xmath7 is non - negative on @xmath5 .",
    "the _ covering problem _ is to compute @xmath12 , assuming @xmath7 is non - negative .",
    "( this is equivalent to the generalized packing problem with the restriction that @xmath7 is non - positive . )",
    "our algorithms assume an _ optimization oracle _ for @xmath5 and @xmath7  given non - negative @xmath13 , the oracle returns @xmath14 and @xmath15 , where @xmath14 minimizes @xmath16 .",
    "( this models , e.g. , packing source - sink paths subject to edge constraints ; in this case the oracle would compute a shortest path for given non - negative edge lengths . ) for covering , the oracle must _ maximize _ the sum .    [ [ quality - of - solutions ] ] quality of solutions : + + + + + + + + + + + + + + + + + + + + + +    given the oracle , @xmath17 , @xmath18 , @xmath19 , @xmath20 , and @xmath21 , our algorithms return @xmath22-approximate solutions .",
    "for generalized packing , @xmath22 is the additive error with respect to @xmath23 . for packing and covering ,",
    "the error is a factor of @xmath24 .",
    "[ [ complexity ] ] complexity : + + + + + + + + + + + +    table  [ results ] shows the number of iterations required and the complexity per iteration . in that caption ,",
    "`` explicitly given '' means that @xmath25 , where @xmath26 and @xmath27 are , respectively , an explicitly given matrix and vector , while @xmath28 .",
    "[ [ granularity ] ] granularity : + + + + + + + + + + + + +    the oracle is called once in each iteration of the algorithm ; the algorithm returns the average of the solutions returned by the oracle .",
    "thus , the granularity of the final solution is the granularity of the solutions returned by the oracle , divided by the number of iterations . for the abstract problems we consider ,",
    "this can provide integer solutions comparable to those obtainable by other techniques .",
    "[ [ dual - solutions ] ] dual solutions : + + + + + + + + + + + + + + + +    our algorithms maintain a dual solution , represented by a vector @xmath29 , initially uniform . in each iteration , each @xmath30 is multiplied by a factor depending on @xmath31 where @xmath14 is the solution returned by the oracle ( e.g. , for packing , @xmath30 is multiplied by @xmath32 ) .",
    "the average over all iterations of the values of these dual solutions is @xmath22-optimal with respect to the value of the final ( primal ) solution .",
    ".number of iterations .",
    "each iteration requires @xmath33 time and @xmath34 operations ( on an erew - pram ) , plus one oracle call . for an explicitly given problem ( no oracle )",
    ", each iteration requires @xmath35 time and @xmath36 operations . [ cols= \" > , < \" , ]     [ [ sparse - strategies - for - zero - sum - games ] ] sparse strategies for zero - sum games : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the explicitly given general packing problem generalizes the problem of finding near - optimal strategies for zero - sum matrix games : @xmath5 is the set of mixed strategies for one player",
    ", @xmath31 is the expected payoff if the player plays according to @xmath14 and the opponent plays the pure strategy @xmath37 , and @xmath23 is the value of the game .",
    "an approximate solution is a mixed strategy @xmath14 guaranteeing an expected payoff within an additive @xmath22 of optimal .",
    "each iteration chooses the best pure strategy given that the opponent plays the mixed strategy represented by @xmath29 .",
    "the final solution returned is a mixed strategy that plays uniformly from @xmath38 pure strategies , one for each iteration .",
    "( the opponent has @xmath18 pure strategies ; @xmath19 is the maximum minus the minimum payoff . )",
    "the existence of such sparse , near - optimal strategies was shown probabilistically @xcite ; our existence proof of the approximate solution for generalized packing is a generalization of the proof in @xcite .",
    "plotkin , shmoys , and tardos @xcite ( generalizing a series of works on multicommodity flow @xcite ) gave approximation algorithms for general packing and covering problems similar to those we consider .",
    "for these abstract problems , their results are comparable to those in this paper , but for many problems their results are stronger .",
    "most importantly , they give techniques for reducing the effective width of a linear program and techniques for problems ( such as concurrent multicommodity flow ) when the packing or covering set is a cartesian product .",
    "luby and nisan @xcite give a parallel approximation algorithm for positive linear programming  the special cases of linear programming of the form @xmath39 ( a packing problem ) , or the dual @xmath40 ( a covering problem ) , where @xmath26 , @xmath27 , and @xmath4 have non - negative coefficients . here",
    "@xmath26 , @xmath27 , and @xmath4 are explicitly given .",
    "previous algorithms applicable to zero - sum games either required the solution of a linear program @xcite or did not provide sparse strategies @xcite .",
    "to introduce oblivious rounding , we give a simple example .",
    "the set cover problem is the following : given a family of sets @xmath41 , with each @xmath42 , a _ set cover _",
    "@xmath43 is a sub - family such that every element @xmath44 is in some set in @xmath43 .",
    "the problem is to find a cover @xmath43 that is not much larger than @xmath45 , a minimum - cardinality cover .",
    "we derive an algorithm that , without knowing @xmath45 , emulates a random experiment that draws sets randomly from @xmath45 .",
    "the algorithm finds a cover of size at most @xmath46 .",
    "let @xmath47 .",
    "consider drawing @xmath48 sets uniformly at random from @xmath45 .",
    "what is the expected number of elements left uncovered ? for any given element @xmath49 , the probability that it is not covered in a given round is at most @xmath50 , because it is in at least one set in @xmath45 .",
    "thus the expected number of elements left uncovered is at most @xmath51 .",
    "thus , with non - zero probability we obtain a cover @xmath43 of size @xmath48 .",
    "the method of conditional probabilities naively applied to the above proof yields an algorithm that depends on @xmath45 .",
    "we outline this next .",
    "our ultimate goal is not derandomization per se , but an algorithm that does not require knowledge of @xmath45 .",
    "consider an algorithm that chooses the sets sequentially , making each choice deterministically to do `` as well '' as the corresponding random choice would .",
    "specifically , the algorithm chooses each set to minimize the expected number of elements that would remain uncovered _ if _ the remaining sets were chosen randomly from @xmath45 . letting @xmath43",
    "denote the collection of sets chosen so far , this expected number is @xmath52 ( we use @xmath53 to denote @xmath0 if @xmath54 and @xmath55 otherwise ; we use @xmath56 to denote the union of sets in @xmath43 . ) @xmath57 is called a _ pessimistic estimator _ @xcite , because ( a ) it is an upper bound on the conditional probability of failure ( in this case , by markov s inequality ) , ( b ) it is initially less than @xmath0 , and ( c ) each choice can be made without increasing it .",
    "( the latter property follows in this case because @xmath57 is an expected value conditioned on the choices made so far . )",
    "these three properties imply the invariant that if the remaining @xmath58 sets were to be chosen randomly from @xmath45 , the probability of failure would be less than one .",
    "when @xmath59 , @xmath43 is a cover .    [ [ achieving - obliviousness ] ] achieving obliviousness : + + + + + + + + + + + + + + + + + + + + + + + + +    because an uncovered element that occurs in several sets in @xmath45 contributes less to @xmath57 , the above algorithm depends on the number of times each element is covered by @xmath45 .",
    "this is counter - intuitive , in that the only aspect of @xmath45 used in the proof was @xmath60 .",
    "replacing each corresponding term in @xmath57 yields @xmath61 @xmath62 is a pessimistic estimator .",
    "more importantly , among collections of sets of the same size , @xmath62 is uniformly proportional to the number of uncovered elements in the set . thus , the algorithm that uses @xmath62 instead of @xmath57 does not depend on @xmath45 , it simply chooses each set to minimize the number of elements remaining uncovered .",
    "nonetheless , it is guaranteed to keep up with the random experiment , finding a cover within @xmath46 steps .",
    "this is the greedy set cover algorithm , originally analyzed non - probabilistically by johnson  @xcite and lovsz  @xcite .",
    "[ [ versus - fractional - cover ] ] versus fractional cover : + + + + + + + + + + + + + + + + + + + + + + + + +    if the cover @xmath45 is a fractional cover , the analyses of both algorithms carry over directly to show a @xmath63 performance guarantee .",
    "[ [ what - enables - oblivious - rounding ] ] what enables oblivious rounding ?",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we call such algorithms _ oblivious rounding _ algorithms .",
    "what kinds of randomized rounding schemes admit them ?",
    "the key property is that the proof bounds the probability of failure by the expected value of a sum of products and bounds the terms corresponding across products uniformly .",
    "to illustrate , here is the explicit proof that @xmath64 @xmath65 the first inequality is obtained by `` undoing '' one step of the substitution that yielded @xmath62 from @xmath57 .",
    "the standard argument then applies .",
    "we use this principle for each of our analyses .",
    "fix an instance @xmath66 of the generalized packing problem .",
    "we consider randomly rounding an optimal solution to obtain an @xmath22-approximate solution ; we then derive the algorithm that finds such a solution .",
    "let @xmath23 and @xmath67 be an optimal solution .",
    "let @xmath68 be a multiset obtained by repeatedly choosing random elements of @xmath5 , where each random element is chosen from a distribution over @xmath5 with @xmath17-dimensional mean @xmath67 .",
    "let @xmath69 be the average of the points in @xmath68 .",
    "[ gen - packing - existence ] the probability that @xmath69 is not an @xmath22-approximate solution is less than @xmath70 $ ] .    without loss of generality , assume @xmath71 and @xmath72 .",
    "otherwise take @xmath73 and @xmath74 .",
    "the convexity of @xmath5 ensures that @xmath75 . for each @xmath37 , @xmath76 , which is the average of @xmath77 independent random variables in @xmath78 $ ] .",
    "since @xmath79=f_j(x^*)\\le \\lambda^*$ ] , by hoeffding s bound @xcite , @xmath80 $ ] is less than @xmath81 .",
    "since @xmath37 ranges from @xmath0 to @xmath18 , the result follows .      as in the set cover example",
    ", our algorithm mimics the random experiment . each round it adds an element to @xmath68 to minimize a pessimistic estimator .",
    "this pessimistic estimator is implicit in the existence proof . to find it , we need the inequalities that prove ( a simplified version of ) hoeffding s bound :    let @xmath82 be the sum of @xmath48 independent random variables in @xmath78 $ ] , with @xmath83 and @xmath84",
    ". then @xmath85 < 1/\\exp(2s\\epsilon^2)$ ] .",
    "[ hoeffding - lemma ]    let @xmath86 .",
    "@xmath87 }      \\nonumber      \\\\ & = & \\pr\\bigg[\\prod_i \\frac{(1+\\alpha)^{x_i }        } { ( 1+\\alpha)^{\\mu_i+\\epsilon } } \\ge 1 \\bigg ]      \\nonumber      \\\\ & \\le & { { \\mathop{\\rm e}}}\\bigg[\\prod_i \\frac{1+\\alpha x_i        } { ( 1+\\alpha)^{\\mu_i+\\epsilon}}\\bigg ]      \\label{hoeffding - est }      \\\\ & = & \\prod_i \\frac{1+\\alpha e(x_i )        } { ( 1+\\alpha)^{\\mu_i+\\epsilon } }      \\nonumber      \\\\ & \\le & \\prod_i \\frac{1+\\alpha \\mu_i        } { ( 1+\\alpha)^{\\mu_i+\\epsilon } }      \\nonumber      \\\\ & < & \\prod_i 1/e^{2\\epsilon^2}.      \\nonumber    \\end{aligned}\\ ] ] the second step follows from @xmath88 for @xmath89 and markov s inequality .",
    "the last step uses @xmath90 for @xmath21 , @xmath86 , and @xmath91 .",
    "the proof of lemma ( [ gen - packing - existence ] ) bounds the probability of failure by a sum of probabilities , each of which is bounded by an expected value ( [ hoeffding - est ] ) in hoeffding s proof . thus ( when @xmath71 and @xmath72 ) , the proof bounds the probability of failure by the expected value of @xmath92 the expectation of which is less than @xmath93 .",
    "the conditional expectation of the sum given @xmath94 is @xmath95    \\cdot \\bigg[\\frac{1+\\alpha f_j(x^ * ) ]      } { ( 1+\\alpha)^{\\lambda^*+\\epsilon}}\\bigg]^{s-|t|}\\ ] ] where @xmath48 is the desired size of @xmath68 . to obtain the pessimistic estimator for the algorithm , replace each @xmath96 by the upper bound @xmath23 : @xmath95    \\cdot \\bigg[\\frac{1+\\alpha \\lambda^ *      } { ( 1+\\alpha)^{\\lambda^*+\\epsilon}}\\bigg]^{s-|t|}\\ ] ] when @xmath48 is large enough that @xmath97 , this quantity is a pessimistic estimator : ( a ) it is an upper bound on the conditional probability of failure , ( b ) it is initially less than @xmath0 , and ( c ) some @xmath14 can always be added to @xmath68 without increasing it .",
    "properties ( a ) and ( b ) follow from the choice of @xmath48 and the inequalities in the proof of hoeffding s lemma .",
    "property ( c ) follows from the derivation , as explained for the set cover example . among multisets of a given size , this pessimistic estimator is uniformly proportional to @xmath98 thus , to augment a given multiset @xmath99 , the algorithm adds the element @xmath14 minimizing @xmath16 , where @xmath100 .",
    "this , accounting for the normalization @xmath71 and @xmath72 , is the algorithm in figure  [ gen - packing - fig ] .",
    "@xmath101   + .",
    "@xmath102 ; @xmath103 ; @xmath104 ; @xmath105   + .",
    "@xmath106  ( @xmath107 )   + .",
    "* repeat *   + .",
    "choose @xmath108 to minimize @xmath16   + .",
    "@xmath109   + .",
    "@xmath110}$ ]  ( @xmath107 )   + .",
    "* until * @xmath111   + .",
    "* return * @xmath112",
    "we derive the packing algorithm analogously .",
    "fix an instance @xmath113 of the packing problem .",
    "let @xmath23 , @xmath67 , @xmath68 and @xmath69 be as for lemma  [ gen - packing - existence ] .",
    "note that , for this problem , an @xmath22-approximate solution is an @xmath108 with @xmath114 .",
    "[ packing - existence ] the probability that @xmath69 is not an @xmath22-approximate solution is less than @xmath115 $ ] .    without loss of generality ,",
    "assume @xmath72 .",
    "otherwise take @xmath116 and @xmath117 .",
    "the convexity of @xmath5 ensures that @xmath75 . for each @xmath37 , @xmath76 , which is the average of @xmath77 independent random variables in @xmath78 $ ] , each with expectation @xmath118 . by",
    "raghavan s bound @xcite , @xmath119 $ ] is less than @xmath120 $ ] .",
    "since @xmath37 ranges from @xmath0 to @xmath18 , the result follows .      here",
    "is raghavan s proof :    let @xmath82 be the sum of independent random variables in @xmath78 $ ] with @xmath83 and @xmath121 .    then @xmath122 < 1/\\exp[b(\\epsilon)\\mu]$ ] .",
    "[ raghavan - lemma ]    @xmath123 }      \\nonumber      \\\\ & = & \\pr\\bigg[\\prod_i \\frac{(1+\\epsilon)^{x_i }        } { ( 1+\\epsilon)^{(1+\\epsilon)\\mu_i } } \\ge 1 \\bigg ]      \\nonumber      \\\\ & \\le & { { \\mathop{\\rm e}}}\\bigg[\\prod_i \\frac{1+\\epsilon x_i        } { ( 1+\\epsilon)^{(1+\\epsilon)\\mu_i}}\\bigg ]      \\label{raghavan - est }      \\\\ & = &   \\prod_i \\frac{1+\\epsilon { { \\mathop{\\rm e}}}(x_i )        } { ( 1+\\epsilon)^{(1+\\epsilon)\\mu_i } }      \\nonumber      \\\\ & < & \\prod_i \\frac{e^{\\epsilon \\mu_i }        } { ( 1+\\epsilon)^{(1+\\epsilon)\\mu_i } }      \\nonumber    \\end{aligned}\\ ] ]    the last line equals @xmath124 $ ] .",
    "the second step uses @xmath88 for @xmath89 and markov s inequality .",
    "the last uses @xmath125 and @xmath126 , which is strict if @xmath127 .    thus ( assuming @xmath72 ) , the proof of lemma [ packing - existence ] bounds the probability of failure by the expectation of @xmath128 corresponding to ( [ raghavan - est ] ) .",
    "the expectation given @xmath129 is @xmath130    \\cdot\\bigg[\\frac{1+\\epsilon f_j(x^ * )      } { ( 1+\\epsilon)^{(1+\\epsilon)\\lambda^*}}\\bigg]^{s-|t|},\\ ] ] where @xmath48 is the desired size of @xmath68 .",
    "when @xmath48 is large enough that @xmath131 \\le 1 $ ] , replacing @xmath96 by @xmath23 gives a pessimistic estimator . among multisets @xmath99 of the same size ,",
    "the pessimistic estimator is proportional to @xmath132 thus , to augment a given multiset @xmath99 , the algorithm adds the element @xmath14 minimizing @xmath133 where @xmath134 .",
    "this , accounting for the normalization to the case @xmath72 , gives the algorithm in figure  [ packing - fig - s ] .",
    "this algorithm assumes @xmath48 is given .",
    "we remove this requirement in section  [ dual - sec ] .",
    "@xmath135   + .",
    "@xmath104   + .",
    "@xmath106  ( @xmath107 )   + .",
    "* repeat *   + .",
    "choose @xmath108 to minimize @xmath16   + .",
    "@xmath109   + .",
    "@xmath136}$ ]  ( @xmath107 )   + .",
    "* until * @xmath137   + .",
    "* return * @xmath112      the covering algorithm is described in figure  [ packing - fig - s ] .",
    "its derivation is analogous to that of the packing algorithm .",
    "fix an instance @xmath113 of the approximate covering problem .",
    "let @xmath23 , @xmath67 , @xmath68 and @xmath69 be as for lemma  [ gen - packing - existence ] .",
    "note that , for this problem , @xmath138 and an @xmath22-approximate solution @xmath108 satisfies @xmath139 .",
    "the probability that @xmath69 is not an @xmath22-approximate solution is less than @xmath140 $ ] .",
    "[ covering - existence ]    we omit the proof , which is essentially the same as for packing , except it is based on the following variant of raghavan s bound :    [ raghavan - variant ] let @xmath82 be the sum of independent random variables in @xmath78 $ ] with @xmath141 and @xmath121 .    then @xmath142 < 1/\\exp[b(-\\epsilon)\\mu]$ ] .",
    "we omit the derivation of the algorithm , noting only that the proof of lemma  [ covering - existence ] implicitly bounds the probability of failure by the expectation of @xmath143",
    "our algorithms implicitly find good approximate solutions to the underlying dual linear programs .",
    "the argument that the algorithm `` keeps up '' with the random rounding of an unknown optimal solution implicitly uses a dual solution to bound the optimal at each iteration .",
    "the value of the solution generated by the algorithm thus converges not only to the value of the optimum , but also to the average of the values of these dual solutions .",
    "the basic principle in each case is similar to that for set cover , which we give first for illustration .",
    "the dual problem is to assign non - negative weights to the elements so that the net weight assigned to the elements in any set is at most one .",
    "the value of the dual solution is the net weight assigned .    at the start of a given iteration ,",
    "suppose @xmath144 elements remain uncovered , and let @xmath145 denote the largest number in any set in @xmath146 . then assigning each uncovered element a weight of @xmath147 yields a dual solution of value @xmath148 .",
    "during the course of the algorithm , let @xmath149 denote the harmonic mean of the dual solutions corresponding to the iterations so far .",
    "the set cover algorithm maintains the invariant that the number of elements not covered by the current partial cover @xmath43 is less than @xmath150 .",
    "the proof is essentially the same as the proof that @xmath62 is a pessimistic estimator , except the values of the dual solutions take the place of @xmath151 .    in an iteration where the dual solution has value @xmath152 , the number of uncovered elements decreases from @xmath144 to @xmath153 . by induction on the iterations ,",
    "the algorithm maintains the invariant that the number of uncovered elements is less than @xmath154 where @xmath155 is the value of the dual solution corresponding to the @xmath156th iteration and @xmath156 ranges over the iterations so far .",
    "note that @xmath157 .    before the last iteration at least one element is left , so at that point @xmath158 .",
    "thus ,    the harmonic mean of the values of the dual solutions over the first @xmath159 iterations is larger than @xmath160 , where @xmath161 is the size of the final cover .",
    "the maximum value is at least the arithmetic mean , which is at least the harmonic mean , so at least one of these simple dual solutions has value above @xmath160 .      the vector @xmath29 maintained by the generalized packing algorithm represents a dual solution . at the start of a given iteration ,",
    "the value of the dual solution associated with @xmath29 is @xmath162 ( since @xmath163 , a simple argument shows this is a lower bound on @xmath164 . )",
    "[ [ notation ] ] notation : + + + + + + + + + +    during the course of the algorithm , let @xmath69 denote the current solution @xmath165 represented by @xmath68 .",
    "let @xmath166 denote @xmath167 .",
    "let @xmath149 denote the average of the values of the dual solutions for the previous iterations .",
    "let @xmath168 denote @xmath169 .",
    "the generalized packing algorithm maintains the invariant @xmath170 [ gen - packing - inv ]    wlog , assume @xmath71 and @xmath72 .",
    "we show that @xmath171 is at least the left - hand side and at most the right - hand side .",
    "the first part follows from the same sequence of inequalities that was used in ",
    "[ gen - packing - const - sec ] to derive the ( numerator of the ) pessimistic estimator : @xmath172 since @xmath173 , the first part follows .    for the second part",
    ", we first note the role of the dual solution in each iteration : given the current @xmath14 and @xmath29 , the iteration increases the quantity @xmath171 by a factor of @xmath174 .",
    "( this follows from inspection of the algorithm and the definition of @xmath168 . )",
    "next we apply the sequence of inequalities that bounded the pessimistic estimator below @xmath0 in  [ gen - packing - const - sec ] : by the last inequality in hoeffding s bound ( lemma  [ hoeffding - lemma ] ) , @xmath175 .",
    "let @xmath155 denote the value of @xmath168 at the @xmath156th iteration ( for @xmath176 ) .",
    "by induction on the iterations @xmath177 since @xmath178 , this gives the result .",
    "after @xmath38 iterations of the generalized packing algorithm , @xmath179 .",
    "that is , the primal and average dual values differ by at most @xmath22 .",
    "[ gen - packing - corollary ]      the packing and covering algorithms also generate implicit dual solutions whose average values converge to the primal value .",
    "let @xmath180 and @xmath149 be defined as for the generalized packing dual .",
    "the packing algorithm maintains the invariant that @xmath181 [ packing - inv ]    we omit this and subsequent proofs in this section , since they are similar to that of lemma  [ gen - packing - inv ] .",
    "after @xmath182 iterations of the packing algorithm , @xmath183 .",
    "that is , the primal and average dual values differ by at most a factor of @xmath184 .",
    "our final packing algorithm detects convergence by comparing the primal value to the best dual value so far .",
    "the algorithm is shown in figure  [ packing - fig ] .",
    "the algorithm maintains @xmath185 ( in the variable @xmath186 ) instead of @xmath69 .",
    "@xmath187   + .",
    "@xmath104 ; @xmath106  ( @xmath107 )   + . *",
    "repeat *   + .",
    "choose @xmath108 to minimize @xmath188   + .",
    "@xmath109   + .",
    "@xmath136}$ ]  ( @xmath107 )   + . @xmath189   + .",
    "@xmath190/|s|$ ]  ( @xmath107 )   + .",
    "@xmath191   + . * until * @xmath192   + .",
    "* return * @xmath165      the covering algorithm maintains the invariant that @xmath193 [ covering - inv ]    after @xmath194 iterations of the covering algorithm , @xmath195 , that is , the primal and average dual values differ by at most a factor of @xmath1 .",
    "the algorithm is described in figure  [ packing - fig ] .",
    "if the subroutine for computing @xmath196 returns only an _ approximate _ minimizer @xmath14 , our algorithms still work well .",
    "the degree of approximation ( absolute and/or relative ) of the subroutine carries over into the performance guarantee of the algorithm . for covering , it can also affect the convergence rate ( and therefore the granularity ) .",
    "we model the error by assuming that , given @xmath29 , the oracle returns an @xmath14 such that @xmath197 where @xmath198 , @xmath199 denotes the relative error and @xmath200 denotes the absolute error .",
    "we call this a _ ( @xmath201)-approximate _ oracle .",
    "( for covering , the notion of approximation is defined analogously . )    in each iteration , @xmath29 still represents a dual solution . since @xmath14 is only an approximate minimizer ,",
    "the value of the dual solution is no longer @xmath168 , but it is at least @xmath202 . still using @xmath149 to denote the average of the values of the dual solutions for the previous iterations ,",
    "define @xmath203 to be the average of the corresponding @xmath168 s .",
    "lemmas  [ gen - packing - inv ] ,  [ packing - inv ] , and  [ covering - inv ] go through directly provided `` @xmath203 '' is substituted for `` @xmath149 '' . from the ( modified ) lemmas , by the same reasoning that gives the corollaries to those lemmas , together with the fact that @xmath204 , we get the following propositions .",
    "suppose the generalized packing algorithm uses a @xmath205-approximate oracle .",
    "after @xmath206 iterations , @xmath207 .",
    "[ gen - packing - app - corollary ]    suppose the packing algorithm uses a @xmath205-approximate oracle .",
    "after @xmath208 iterations , @xmath209 .    for covering , @xmath210 .",
    "suppose the covering algorithm uses a @xmath205-approximate oracle .",
    "after @xmath211 b(-\\epsilon)}\\right\\rceil}\\ ] ] iterations , @xmath212 .",
    "these results hold for the algorithms without modification .",
    "in particular , @xmath213 in the packing algorithm in figure  [ packing - fig ] equals the best @xmath168 seen so far , which is at least @xmath203 , so is guaranteed to be within a @xmath184 factor of @xmath166 within the required number of rounds .",
    "the packing and covering algorithms in figure  [ packing - fig ] , as they stand , do not allow explicit control over the granularity of the final solution . because the number of iterations can be less than the upper bound , the algorithms only guarantee a lower bound on the granularity . of course , the lower bound is the difficult part , so it is not surprising that exact control over the granularity can be obtained . in this section ,",
    "we discuss briefly how to modify those algorithms to find , e.g. , an integer solution .    for simplicity , we consider a particular case of integer packing .",
    "fix an instance of the packing problem @xmath113 .",
    "let @xmath23 and @xmath67 be an optimal solution .",
    "in addition , let @xmath214 be the extreme points on the boundary of @xmath5 ( if @xmath5 is a polytope , @xmath213 is its vertex set ) .",
    "we assume that the oracle returns only elements of @xmath213 .",
    "the _ integer packing _",
    "problem is to compute a maximum cardinality multiset @xmath215 such that @xmath216 .",
    "note that , for any such @xmath68 , @xmath217 because @xmath218 , where @xmath219 .",
    "@xmath22-approximate integer solution _ is a set @xmath68 such that @xmath220 and @xmath221 .",
    "let @xmath68 be a multiset obtained by repeatedly choosing random elements of @xmath213 , where each random element is chosen from a distribution on @xmath213 with mean @xmath67 .",
    "( such distributions exist because @xmath5 is the convex closure of @xmath213 . )",
    "when @xmath222 , @xmath223     < m/\\exp[b(\\epsilon)/\\omega].\\ ] ]    the proof is essentially the same as that of lemma  [ packing - existence ] , except @xmath224 replaces @xmath23 .",
    "a corollary to the lemma is that , provided @xmath225 \\le 1 $ ] , there exists an @xmath22-approximate integer solution .",
    "the corresponding algorithm is the same as the basic packing algorithm , except the termination condition is different .",
    "the algorithm terminates when adding another element would cause @xmath226 for some @xmath37 . because the algorithm keeps up with the random process , the resulting set has size at least @xmath227 .",
    "[ [ complexity - and - performance - guarantee ] ] complexity and performance guarantee : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the algorithm is given in figure  [ int - packing - fig ] .",
    "note that @xmath228 , so the number of iterations in this case is at most @xmath229 . for the condition",
    "@xmath225 \\le 1 $ ] , it suffices that , for instance , @xmath230    [ [ covering ] ] covering : + + + + + + + + + +    the same techniques apply for integer covering . for covering , define an _",
    "@xmath22-approximate integer solution _ to be a set @xmath68 such that @xmath231 and @xmath232 .",
    "( many variations are possible . )",
    "let @xmath68 be a random multiset as above .    when @xmath233 , @xmath234     < m/\\exp[b(-\\epsilon)/\\omega].\\ ] ]    the resulting algorithm is described in figure  [ int - packing - fig ] .",
    "the number of iterations in this case is at most @xmath235 . for the condition @xmath236 \\le 1",
    "$ ] , it suffices that @xmath237    @xmath238   + assumption : @xmath225 \\le 1 $ ] .",
    "@xmath104 ; @xmath106 , @xmath239  ( @xmath107 )   + . *",
    "repeat *   + .",
    "choose @xmath108 to minimize @xmath16   + .",
    "@xmath240  ( @xmath107 )   + .",
    "@xmath241 * return * @xmath68   + .",
    "@xmath109   + .",
    "@xmath136}$ ]  ( @xmath107 )",
    "[ [ partial - derandomization ] ] partial derandomization : + + + + + + + + + + + + + + + + + + + + + + + + +    the point of oblivious rounding is not derandomization per se , but to achieve independence from the unknown aspects of the optimal solution .",
    "for some random rounding schemes , some of the parameters of the random process are known ; these can be left in the algorithm .",
    "for instance , in concurrent multicommodity flow , the relative amount of flow of each commodity is known .",
    "a natural randomized rounding scheme is to choose a commodity with probability proportional to its ( known ) demand , and then to choose a flow path among paths for that commodity with probability proportional to its ( unknown ) weight in the optimal flow .",
    "applying oblivious rounding to only the second random choice gives a randomized algorithm in the style of @xcite .",
    "each of the random analyses in this paper employed a single type of probabilistic bound .",
    "this is not a limitation of the technique .",
    "oblivious rounding can be applied to analyses using , e.g. , sums of probabilities bounded by raghavan s bounds , hoeffding s bound , and markov s inequality .",
    "this is relatively straightforward , if technically more tedious .",
    "chernoff - type bounds exist for more general classes of functions than linear functions ( e.g. , azuma s inequality @xcite ) . a natural question is whether oblivious rounding can be applied to such bounds to optimize more general functions .",
    "m.  d. grigoriadis and l.  g. kachiyan . a sublinear - time randomized approximation algorithm for matrix games .",
    "technical report lcsr - tr-222 , rutgers university computer science department , new brunswick , nj , april 1994 .",
    "p.  klein , s.  plotkin , c.  stein , and e.  tardos .",
    "faster approximation algorithms for the unit capacity concurrent flow problem with applications to routing and finding sparse cuts . , 23(3):466487 , june 1994 .",
    "t.  leighton , f.  makedon , s.  plotkin , c.  stein , e.  tardos , and s.  tragoudas .",
    "fast approximation algorithms for multicommodity flow problems . in _ proc . of the 23rd ann .",
    "acm symp . on theory of computing _ ,",
    "pages 101111 , 1991 .",
    "serge plotkin , david shmoys , and va tardos .",
    "fast approximation algorithms for fractional packing and covering problems . in _ proc . of the 32nd ieee annual symp . on foundation of computer science _ ,",
    "pages 495504 , 1991 ."
  ],
  "abstract_text": [
    "<S> we introduce a new technique called oblivious rounding  a variant of randomized rounding that avoids the bottleneck of first solving the linear program . avoiding this bottleneck yields more efficient algorithms and brings probabilistic methods to bear on a new class of problems . </S>",
    "<S> we give oblivious rounding algorithms that approximately solve general packing and covering problems , including a parallel algorithm to find sparse strategies for matrix games . </S>"
  ]
}