{
  "article_text": [
    "the _ software - defined networking ( sdn ) _ paradigm separates the control plane from the network data plane , and introduces a ( software ) _ controller _ that manages the _ flows _ in the network from a ( logically ) centralized perspective . this architecture has the potential to make the network management and operation more flexible and simpler , and to enable faster innovation also in the network core .",
    "for example , the controller may exploit application and network state information ( including the switches under its control ) to optimize the routing of the flows through the network , e.g. , to implement isolation properties or improve performance .",
    "however , the separation of the control from the data plane may have drawbacks .",
    "for example , a reactive flow control can introduce higher latencies due to the interaction of the switch with the remote controller .",
    "moreover , the separation raises the question of what happens if the switches lose connectivity to the controller .",
    "one solution to mitigate these problems is to keep certain functionality closer to the switches or in the data plane  @xcite .",
    "an important tradeoff occurs in the context of network failures : theoretically , e.g. , a link failure , is best handled by the controller which has the logic to update forwarding rules according to the current network policies .",
    "however , as the indirection via the controller may take too long , modern network designs incorporate failover ( or `` backup '' ) paths into the ( switches or routers ) _ forwarding tables_. for example , openflow ( since the 1.1 specification  @xcite ) , incorporates such a fast failover mechanism : it allows to predefine resilient and in - band failover routes which kick in upon a topological change .",
    "only after the failover took place , the controller may learn about the new situation and install forwarding ( and failover ) rules accordingly .",
    "* our contributions .",
    "* given that the in - band failover tables need to be pre - computed and the corresponding rules are based on limited local network information only , we ask the question : `` can you shoot in your foot with local fast failover ? ''",
    "we formalize a simplified local failover problem , and first assume a conservative ( or worst - case ) perspective where link failures are chosen by an adversary who knows the entire network and all the pre - installed failover rules . for this setting",
    ", we provide a lower bound which shows that a safe fast failover can potentially come at a high network load , especially if the failover rules are destination - based only ( section  [ sec : worstcase ] ) .",
    "we then present randomized and deterministic algorithms to pre - compute resilient forwarding sets and show that the algorithms are ( almost ) optimal in the sense that they match the lower bound mentioned above ( section  [ sec : algorithms ] ) .",
    "finally , we report on a simulation study ( section  [ sec : sims ] ) which indicates that under random link failures , local fast failover performs better in general . in the appendix",
    ", we give the formal specification of the two additional algorithms used in our simulations , and we extend the discussion to alternative adversary and traffic models .    * model and terminology . * we attend to the following model .",
    "we assume an sdn - network @xmath0 with @xmath1 switches ( or _ nodes _ ) @xmath2 ( e.g. , openflow switches ) connected by bidirectional links @xmath3 .",
    "we assume that all nodes are directly connected , i.e. , @xmath4 forms a full mesh ( a _ clique _ ) .",
    "this network serves an _ all - to - one _ communication pattern where any node @xmath5 communicates with a single destination @xmath6 ; in other words , we have @xmath7 communicating ( source - destination ) pairs .",
    "henceforth , by slightly abusing terminology , we will refer to the corresponding @xmath7 communication paths as the _ flows _ @xmath8 .",
    "the source - destination flows are unsplittable , i.e. , each flow @xmath9 travels along a single path . for simplicity",
    ", we will assume that all flows @xmath10 carry a constant amount of traffic @xmath11 , and that edge capacities @xmath12 are infinite .    in order to ensure an efficient failover ,",
    "each switch @xmath13 can store the following kind of _ failover rules _ : each rule @xmath14 considers a specific local failure scenario , namely the set of failed incident links , and defines an alternative forwarding port for each source - destination pair .",
    "( this is slightly more general than what is provided e.g. , by openflow today : in openflow , all paths need to resort to the same failover port , rending the connectivity - load tradeoff even worse . )    formally , let @xmath15 denote the links ( or equivalently : the _ switch ports _ ) incident to node @xmath16 in @xmath4 , and let @xmath17 define how the source - destination pairs ( or flows ) that are routed via node @xmath16 ( the `` forwarding set '' ) .",
    "a rule @xmath18 is of the form : @xmath19 that is , for each possible failure scenario @xmath20 ( i.e. , the subset of ports which failed at @xmath16 ) , the failover rule defines an alternative set of forwarding rules @xmath17 at @xmath16 .",
    "note that the number of rules can theoretically be large ; however , as we will see , small rule tables are sufficient for the algorithms presented in this paper .",
    "we study failover schemes that pursue two goals : ( 1 ) _ correctness : _ each source - destination pair is connected by a valid path ; there are no forwarding loops .",
    "( 2 ) _ performance : _ the resulting flow allocations are well balanced .",
    "formally , we want to minimize the load of the maximally loaded link in @xmath4 after the failover : @xmath21 , where @xmath22 describes the number of flows @xmath10 crossing edge @xmath23 . henceforth , let @xmath24 denote the maximum load .    for our randomized failover schemes , we will typically state our results _ with high probability _",
    "_ w.h.p . _ ) : this means that the corresponding claim holds with at least polynomial probability @xmath25 for an arbitrary constant @xmath26 .",
    "moreover , throughout this paper , @xmath27 will refer to the _ binary _ logarithm .",
    "let us first investigate the limitations of local failover mechanisms from a conservative worst - case perspective . concretely",
    ", we will show that even in a fully meshed network ( i.e. , a _ clique _ ) , a small number of link failures can either quickly disrupt connectivity ( i.e. , the forwarding path of at least one source - destination pair is incorrect ) , or entail a high load .",
    "this is true even though the remaining physical network is still well connected : the minimum edge cut ( short : _ mincut _ ) is high , and there still exist many disjoint paths connecting each source - destination pair .",
    "[ thm : worstcase ] no local failover scheme can tolerate @xmath7 or more link failures without disconnecting source - destination pairs , even though the remaining graph ( i.e. , after the link failures ) is still @xmath28-connected .",
    "we consider a physical network that is fully meshed , and we assume a traffic matrix where all nodes communicate with a single destination @xmath6 .",
    "to prove our claim , we will construct a set of links failures that creates a loop , for any local failover scheme . consider a flow @xmath29 connecting the source - destination pair @xmath30 .",
    "the idea is that whenever the flow from @xmath31 would be directly forwarded to @xmath6 in the absence of failures , we fail the corresponding physical link : that is , if @xmath31 would directly forward to @xmath6 , we fail @xmath30 . similarly ,",
    "if @xmath31 forwards to ( the backup ) node @xmath32 , and if @xmath32 would send to @xmath6 , we fail @xmath33 , etc .",
    "we do so until the number of intermediate ( backup ) nodes for the flow @xmath34 becomes @xmath35 .",
    "this will require at most @xmath35 failures ( of links to @xmath6 ) since every such failure adds at least one intermediate node .    in the following ,",
    "let us assume that the last link on the path @xmath34 is @xmath36 .",
    "we simultaneously fail all the links @xmath37 , where @xmath38 are all the nodes that are not the intermediate nodes on the path @xmath34 , and not @xmath31 .",
    "so , there are @xmath39 nodes @xmath38 ( the last minus @xmath40 accounts for @xmath31 ) . by failing the links to @xmath38",
    ", we left @xmath41 without a valid routing choice : all the remaining links from @xmath41 point to nodes which are already on the path @xmath34 , and a loop is inevitable .    in total , we have at most @xmath42 failures .",
    "notice , that the two nodes with the smallest degrees in the graph are the nodes @xmath6 and @xmath41 .",
    "the latter is true since the first @xmath35 failures were used to disconnect links to @xmath6 , and another @xmath43 failures were used to disconnect links from @xmath41 .",
    "formally , @xmath44 , where the last minus @xmath40 accounts for the link @xmath36 .",
    "so , @xmath45 . and",
    "regarding the degree of @xmath41 , we have : @xmath46 .",
    "all the other nodes have a degree of @xmath47 .",
    "the network is still @xmath48 connected : the mincut of the network is at least @xmath48 .",
    "consider some cut with @xmath49 nodes on the one side of the cut , and @xmath50 nodes on the other side .",
    "obviously , one of the sets has a size of at most @xmath51 ; let us denote this smaller set by @xmath52 .",
    "if @xmath52 includes at least one of the nodes @xmath53 , then the number of outgoing edges form the set is at least @xmath54 , thus the mincut is at least @xmath55 .",
    "if @xmath52 includes only both @xmath41 and @xmath6 , the mincut is at least @xmath7 ( the link @xmath36 was failed ) .",
    "if only one of the nodes @xmath56 is in @xmath52 , then the mincut is at least @xmath48 .",
    "@xmath57    regarding the maximal link load , we have the following lower bound .",
    "[ thm : lowerbound ] for any local failover scheme tolerating @xmath58 link failures @xmath59 without disconnecting any source - destination pair , there exists a failure scenario which results in a link load of at least @xmath60 , although the minimum edge cut ( mincut ) of the network is still at least @xmath61 .",
    "_ let us first describe an adversarial strategy that induces a high load : _ recall that in the absence of failures , each node @xmath32 ( @xmath62 ) may use its direct link to @xmath6 for forwarding .",
    "however , after some links failed , @xmath32 may need to resort to the remaining ( longer ) paths from @xmath32 to @xmath6 .",
    "since the failover scheme @xmath63 tolerates @xmath58 failures and @xmath32 remains connected to @xmath6 , @xmath63 will fail over to one of @xmath64 possible paths . to see this ,",
    "let @xmath65 ( @xmath66 $ ] ) be one of the @xmath58 possible last hops on the path @xmath67 , and let us consider the paths generated by @xmath63 : @xmath68 for example , the path @xmath69 will be generated if the first failure is link @xmath33 , and the path @xmath70 if the second failure is link @xmath71 ( see fig .  [",
    "fig : failover_example ] for an illustration ) . notice that the last hop @xmath65 is unique for every path ; otherwise , the loop - freeness property would be violated .     where each time the last hop to @xmath6 is failed.,title=\"fig : \" ]   where each time the last hop to @xmath6 is failed.,title=\"fig : \" ]   where each time the last hop to @xmath6 is failed.,title=\"fig : \" ]   where each time the last hop to @xmath6 is failed.,title=\"fig : \" ] +    for each @xmath72 $ ] ( i.e. , for each possible source ) consider the set @xmath73 , and accordingly , the multiset @xmath74 is of size @xmath75 many nodes . since we have @xmath7 distinct nodes ( we do not count @xmath6 ) , by a counting argument , there exists a node @xmath76 which appears in at least @xmath77 sets @xmath78 .    if for each @xmath79 such that @xmath80 , the adversary will cause @xmath32 to route to @xmath6 via @xmath81 , then the load of the link @xmath82 will be at least @xmath77 .",
    "this can be achieved by failing at most @xmath77 links to @xmath6 in each such set @xmath78 .",
    "thus , the adversary will fail @xmath83 links incident to @xmath6 , while the maximum loaded link @xmath82 will have a load of at least @xmath77 .",
    "_ it remains to prove that the network remains highly connected , despite these failures : _ the proof is simple . in a clique network without failures ,",
    "the mincut is @xmath7 . in the worst case",
    ", each link failure will remove one link from some cut , and hence the mincut must eventually be at least @xmath61 . by the same argument",
    ", there are at least @xmath61 many disjoint paths from each node @xmath32 to the destination : initially , without failures , there are @xmath7 disjoint paths ( a direct one and @xmath7 indirect ones ) , and each failure affects at most one path .",
    "interestingly , it can be proved analogously that if a failover rule only depends on destination addresses , the situation is even worse .",
    "[ thm : dst - based ] consider any local destination - based failover scheme in a clique graph .",
    "there exists a set of @xmath58 failures @xmath59 , such that the remaining graph will have a mincut of @xmath61 and @xmath84    in order to construct a bad example , we first fail the direct link @xmath30 , and hence @xmath31 will need to reroute to some path with the last node before @xmath6 being some node @xmath32 .",
    "when we fail the link @xmath33 , @xmath32 will have to reroute and some other node @xmath85 will become the last hop on the path to @xmath6 .",
    "we repeat this strategy to fail the links from the newly selected last hop and the destination @xmath6 .",
    "this results in a routing path @xmath86 with at least @xmath58 intermediate nodes .",
    "since the algorithm is destination - based , i.e. , forwarding rules depend only on the destination address of a packet , the load on the link @xmath82 will be at least @xmath64 : all the nodes on the path @xmath34 will send their packets via the same route . @xmath57",
    "we have seen that what can be achieved with local fast failover is rather limited . on the positive side",
    ", this section shows that there exist algorithms to pre - compute failover schemes which at least match the derived lower bounds : we present algorithms to pre - compute robust failover paths that _ jointly optimize _ the loop - freeness property and the load , i.e. , find an almost optimal tradeoff .",
    "naturally , randomization can help to spread the communication load well , but we must ensure that paths remain loop - free .",
    "we first present such a randomized solution , discuss how to derandomize it , and finally look at deterministic failover algorithms .",
    "we introduce a family of failover schemes @xmath63 which can be represented in a generic _ matrix form _ @xmath87 . any failover scheme instance in this family",
    "will always forward a message directly to the destination if the corresponding link is available .",
    "otherwise , if a given node @xmath32 can not reach the destination @xmath6 via @xmath33 , it will resort to the sequence of alternatives represented as the row @xmath79 in the matrix @xmath88 ( the `` backup nodes '' for @xmath32 ) : @xmath32 will first try to forward to node @xmath89 , if this link is not available to node @xmath90 , and so on . similarly and more generally , starting from node @xmath87 , if the link @xmath91 is not available , the failover scheme will try @xmath92 , @xmath93 , etc . in summary , the matrix representation can be depicted as follows : @xmath94    the following auxiliary claim characterizes the best adversarial strategy against the failover schemes @xmath63 .",
    "[ claim : best_adv_strategy ] for the family of failover schemes @xmath63 , the highest load is induced if links towards the destination node @xmath6 are failed .    to achieve a load of @xmath58 on some link , the adversary first needs to bring at least @xmath58 flows to some node @xmath81 .",
    "consider a failover sequence @xmath88 in which @xmath81 is located at @xmath95 s position , i.e. , @xmath96 . in order to bring the flow @xmath97 to node @xmath81 ,",
    "the adversary needs to fail at least @xmath95 links ( every failure requires at most a single additional backup node ) .",
    "thus , the adversary can remove the links to the destination from every node @xmath98 and from the source @xmath32 .",
    "the optimality is due to the fact that once one of the _ nodes _ @xmath98 appears in other sequences , these failures are automatically reused : the links @xmath99 already failed . if the adversary would instead choose to fail other _ links _",
    "( not towards the destination ) , e.g. , @xmath100 , the failures can only be reused if the same _ link _ ( and not only an endpoint ) appears in other sequences before @xmath81 .",
    "therefore , we conclude that the strategy of failing the links to the destination is optimal : ( 1 ) it requires no more failures to bring a specific flow to @xmath81 than any other strategy , and ( 2 ) link failures to the destination can strictly be reused more often than the failures of links to any other nodes .",
    "@xmath57      what does a good failover matrix @xmath87 look like ? naively , one may choose the matrix entries ( i.e. , the `` failover ports '' ) uniformly at random from the set of next hops which are still available , and depending on the source and destination address , in order to balance the load .",
    "however , note that a random and _ independent _ choice will quickly introduce loops in the forwarding sequences : it is likely that a switch will forward traffic to a switch which was already visited before on the failover path .",
    "thus , our randomized failover scheme @xmath101 will choose random _ permutations _ , i.e. , for a source - destination pair @xmath33 , the sequence @xmath102 ( with @xmath103 ) is _ always loop - free _ ( deterministically ) .",
    "technically , @xmath101 draws all @xmath87 uniformly at randomly from @xmath104 but eliminates repetitions ( e.g. , by redrawing a repeated node ) .",
    "we can show that @xmath101 is almost optimal , in the following sense .",
    "[ thm : rand_strong_adv ] using the @xmath101 scheme , in order to create a maximum load of @xmath105 , the adversary will have to fail at least @xmath106 links _",
    "_ , where @xmath107 .    to create a link load of @xmath77 with the minimal number of link failures ,",
    "the adversary must in particular be able to route at least @xmath77 flows to some node @xmath81 . given the @xmath77 load on the node , in the best case ( for the adversary ) , the entire flow will be forwarded by @xmath81 on a single outgoing link .",
    "( e.g. , the link to the destination @xmath6 . )",
    "we will show that w.h.p . , it is impossible for the adversary to route more than @xmath77 flows to a single node .",
    "the adversary can put a high load on some node @xmath81 only if : 1 ) node @xmath81 is located close to the beginning of many sequences ( i.e. , is in a small `` prefix '' of the sequences ) ; thus , a small number of failures is sufficient to redirect the flow to @xmath81 .",
    "2 ) many nodes appearing before @xmath81 in the sequence prefixes occur early in many other prefixes as well ; thus , the adversary can `` reuse '' failed links to redirect also other source - destination pairs .",
    "note that these two requirements may conflict , but to prove the lower bound on the number of required failures , we can assume that both conditions are satisfied : the set of @xmath77 sequences with the largest number of node repetitions in the @xmath81-prefixes also have the shortest @xmath81-prefixes .    with this intuition in mind ,",
    "let us compute the probability that a node @xmath81 appears more than approximately @xmath108 times at position @xmath95 .",
    "let @xmath109 be an indicator random variable that indicates whether @xmath81 is located at position @xmath110 $ ] in sequence @xmath111 $ ] .",
    "let @xmath112 be a random variable representing the number of times that @xmath81 appears at position @xmath95 .",
    "since the failover sequences are random , @xmath113 ( @xmath81 is neither the source nor the destination ) and thus , @xmath114 = \\tfrac{n-1}{n-2}$ ] .",
    "applying the chernoff bound on the sum of @xmath1 _ i.i.d . _  poisson trials , we obtain ( for any @xmath115 ) : @xmath116\\right ) & \\le 2^{-\\delta \\e \\left[y^j\\right ] } \\nonumber\\\\ \\pr \\left(y^j > \\frac{(1",
    "+ 3\\log n)(n-1)}{n-2}\\right ) & \\le 2^{-(3\\log",
    "n ) \\times \\frac{n-1}{n-2}}\\nonumber\\\\ & \\le 2^{-3\\log n}=1/n^3 . \\nonumber\\end{aligned}\\ ] ] let us denote @xmath117 and rewrite : @xmath118 we can now apply a union bound argument over all possible nodes @xmath81 and over all possible positions @xmath95 , which yields that with probability at least @xmath119 , any node will appear no more than @xmath120 times at each position .    the adversary needs to select the @xmath77 sequences with the shortest @xmath81-prefixes . for a chosen sequence @xmath79 ,",
    "let us denote by @xmath121 the prefix length for node @xmath81 ( the prefix length includes @xmath81 itself ) .",
    "since each node will appear no more than @xmath120 times at each position ( with probability of at least @xmath119 ) the minimum length of a _ total prefix _ for any node @xmath81 can be derived .",
    "let us denote the minimum _ total prefix _ by @xmath49 .",
    "clearly , @xmath49 is minimized for the shortest possible prefixes @xmath121 . according to the analysis above , with high probability , there are no more than @xmath120 prefixes of length @xmath40 , no more than @xmath120 prefixes of length @xmath122 , and so on .",
    "therefore : @xmath123 eq .",
    "[ eq : simple_den ] is true since for @xmath124 , @xmath125 .    in conclusion",
    ", we know that in order to achieve a load of @xmath77 , the adversary has to fail the entire total prefix of @xmath81 that consists of at least @xmath126 nodes . however , the nodes in the prefixes are not necessarily all distinct , and the number of links the adversary needs to fail only depends on the _ distinct _ nodes in the _ total prefix _ of the node @xmath81 .",
    "the latter is true due to the fact that the best adversarial strategy is to fail only the links to the destination since in this case every such failure is reused once the same node appears again in the _ total prefix _ of @xmath81 ( see claim [ claim : best_adv_strategy ] ) . hence , we next compute the minimum number of distinct nodes @xmath127 in any set of @xmath49 random nodes . as we are interested in lower bounding @xmath127 , we can choose @xmath49 minimal , i.e. , @xmath128 .",
    "the analysis follows from a _ balls - and - bins _ argument where bins represent node ids and balls are the @xmath49 positions that should be failed by the adversary .",
    "thus , @xmath127 is a number of occupied bins ( i.e. , bins that contain at least one ball ) .",
    "let @xmath129 be a binary random variable indicating that the @xmath79-th ball falls into an empty bin ( i.e. , @xmath130 ) .",
    "so , @xmath131 .",
    "since @xmath132 and @xmath133 , we obtain that : @xmath134 thus , @xmath135=k\\e[d_i]\\ge 0.8k .",
    "$ ] now we can apply the chernoff bound ( for any @xmath136 $ ] ) : @xmath137 ) \\nonumber\\\\ & \\le e^{-\\e[d]\\delta^2/2 } \\le e^{-0.8k\\delta^2/2 } \\nonumber.\\end{aligned}\\ ] ] by taking @xmath138 we obtain @xmath139    it remains to prove that this bound still holds under the union bound for all @xmath140 possible sets of sequences that the adversary can choose .",
    "in other words , we have to ensure that @xmath141 ( we took a larger number , since : @xmath142 ) .",
    "@xmath143    for @xmath144 , we have @xmath145 , and hence @xmath146 . since @xmath147 , w.h.p .",
    ", any set of @xmath77 sequences ( i.e. , @xmath81-prefixes ) will require @xmath148 failures .",
    "@xmath57      theoretically , the result of theorem  [ thm : rand_strong_adv ] can be derandomized , i.e. , the @xmath101 scheme can _ deterministically _ ensure low loads .",
    "the idea is that we could _ verify _ whether an ( improbable ) situation occurred and the random sequences generated by @xmath101 actually yield a _",
    "high _ load ( we just need to check all possible loads at any @xmath81 ) ; if so , another set of random permutations is generated .",
    "however , this verification is computationally expensive .",
    "we hence now initiate the discussion of efficient deterministic schemes .",
    "in particular , we propose an optimal failover scheme ( which matches our lower bound in section  [ sec : worstcase ] ) , at least for small @xmath58 .",
    "similar to @xmath101 , the deterministic failover scheme @xmath149 is defined by a _",
    "failover matrix _ @xmath87 ; however , here @xmath87 will simply refer to a node s _ index _ ( and not the node itself ) : we define the index of any node @xmath150 to be @xmath151 , i.e. , the nodes @xmath152 are mapped to the indices @xmath153 . given a destination node @xmath6 , @xmath149 is defined by the following index matrix :    @xmath154    in general , the index in sequence @xmath155 $ ] at position @xmath156 $ ] is @xmath157 .",
    "for example , if the link @xmath30 fails , @xmath31 will reroute via the node with index @xmath40 , i.e. , via @xmath158 ; and so on .",
    "we can show the following result .",
    "[ thm : dfs ] the @xmath149 scheme achieves a maximum load of @xmath159 in any scenario with @xmath160 failures .",
    "we will prove something even stronger : the adversary can not choose link failures such that any _ node _ @xmath81 forwards more than @xmath77 flows .",
    "clearly , an upper bound on the node load is an upper bound on the ( incident ) links : in the worst case , @xmath81 will forward all traffic to the same link . to create a high load at some node @xmath81",
    ", the adversary needs to find failover sequences in the matrix @xmath87 where the node @xmath81 appears close to the _ beginning _ of the sequence , and fail _ all _ the links @xmath33 , where @xmath32 is a node preceding @xmath81 in a sequence : i.e. , the adversary fails the _ total prefix _ of @xmath81 .",
    "note that failing the links to the destination is the best strategy for the adversary as failures are automatically reusable in other sequences ( see claim [ claim : best_adv_strategy ] ) .",
    "the following two claims will help us to show that the adversary wastes its entire failure budget in order to achieve a maximum load of @xmath77 .",
    "every node index participates in only @xmath161 sequences .",
    "the @xmath149 failover matrix is defined as @xmath157 , where @xmath72 $ ] and @xmath162 $ ] . from this construction",
    ", it follows that there are no index repetitions in the matrix columns .",
    "since there are @xmath161 columns , the claim follows .",
    "@xmath57    for any node index @xmath163 , all @xmath163-prefixes ( sets of indices preceding @xmath163 in the sequences ) are disjoint .",
    "let us define @xmath164 and @xmath165 .",
    "the index in sequence @xmath166 $ ] at position @xmath167 $ ] is @xmath168 .",
    "consider a sequence @xmath169 where the index @xmath81 appears at position @xmath170 and a sequence @xmath171 where the index @xmath163 appears at position @xmath172 . without loss of generality , assume that @xmath173 .",
    "let @xmath174 and @xmath175 represent the indices in the prefixes of @xmath163 in sequences @xmath169 and @xmath171 accordingly .",
    "assume by contradiction that these indices are the same .",
    "we have that @xmath176    and hence    @xmath177    therefore    @xmath178    where @xmath179 and @xmath180 are some integer constants .",
    "notice that @xmath181 , so the only possible values for @xmath180 are : @xmath182 .",
    "moreover , @xmath183 , while @xmath184 , and since the absolute value of these differences is bounded by @xmath185 , we can write : @xmath186 thus , @xmath187 remains the only possible value for @xmath180 .",
    "the values @xmath188 are distinct since there are no repetitions in the columns of the sequence matrix . since @xmath189 , due to a geometric series argument ( the largest element is greater than the sum of all previous elements ) , we can state that @xmath190 we conclude that there is no integer constant @xmath180 satisfying our assumption @xmath191 ( i.e. , there are two identical indices in the @xmath163-prefixes ) .",
    "@xmath57    , but under random failures.,title=\"fig : \" ] +     +    armed with these claims , we are ready to continue with the proof . since all prefixes are disjoint , the adversary can not reuse failures of one flow for another . thus",
    ", the adversary will be able to route _",
    "one _ flow to @xmath81 using a single failure ( by finding a sequence in which @xmath81 appears at the first position ) ; to add another flow , the adversary takes a sequence @xmath192 in which @xmath81 is located at position 2 and will fail the links @xmath193 , and @xmath194 .",
    "and so on .",
    "thus , the number of used failures can be represented as @xmath195 where @xmath196 is the number of flows passing through @xmath81 on the way to the destination @xmath6 .",
    "so : @xmath197     +    note that the index of the destination node ( @xmath7 in our case ) can appear inside the failover sequences . in this case , the index will be skipped since the link to it from the source already failed . by skipping one index ,",
    "we shorten the failover sequence by 1 , and since every sequence has length @xmath161 , our failover scheme holds for any @xmath198 . @xmath57",
    "r0.5     to complement our worst - case bounds , we conducted simulations with different failure scenarios .",
    "( 1 ) * ran * : links are failed uniformly at random ; ( 2 ) * ecl * ( an `` eclipse attack '' ) : links are removed at random around destination @xmath6 .",
    "we used two traffic patterns .",
    "( 1 ) _ single dest : _ one unit of flow from each node to @xmath6 ; ( 2 ) _ all - to - all : _ one unit of flow from each node to every other node .",
    "in addition to our failover schemes @xmath101 and @xmath149 , we also simulate the following naive strategies .",
    "( 1 ) * bal * ( `` balanced '' ) : if the destination can not be reached directly , forward to an available port chosen uniformly at random ( depending on the destination and the set of failed links ) .",
    "this strategy seeks to balance traffic but does not ensure loop - freeness .",
    "( 2 ) * rob * ( `` robust '' ) : if the destination can not be reached , forward to the available neighboring switch which has the lowest identifier ( in a modulo manner , and assuming that switches have unique identifiers ) .",
    "we start with the _ single dest _ traffic pattern",
    ". figure  [ fig : single - ecplise ] ( _ left _ ) plots the load as a function of the number of failed links under * ecl*. ( note the logarithmic scale on the y - axis . )",
    "we observe that compared to theorem  [ thm : rand_strong_adv ] which deals with worst - case failures , @xmath101 performs significantly better : while our conservative bound suggests that to create a load of @xmath199 , @xmath200 failures are needed , more than 300 are necessary in our experiment .",
    "moreover , we observe that @xmath101 yields a much lower load than the naive approach * rob * ; for the single - destination scenario , * bal * is similar to * rob * and is not shown explicitly here .",
    "the @xmath149 algorithm also gives a low load ; however , it is only defined up to a certain @xmath58 ( see theorem  [ thm : dfs ] ) .",
    "the variance of these experiments is typically small , see the boxplot in figure  [ fig : single - ecplise ] ( _ right _ ) .",
    "as expected , under * ran * failures , the load is generally lower , and our scheme can tolerate more failures without creating loops ( see figure  [ fig : ran ] ) .    as the maximal link load reveals a partial picture only , figure  [ fig : single - loaddist ] studies the load distribution over multiple links ( under * ecl * ) , once for 150 failures ( _ left _ ) and once for 450 failures ( _ right _ ) . obviously , most links hardly contain more than one or two flows under @xmath101 ; again , under the naive * rob * strategy ( and similarly for * bal * ) , the situation is worse .",
    "let us have a look at alternative traffic matrices .",
    "figure  [ fig : all - to - all - logy ] shows the results for an all - to - all communication pattern ( under * ran * ) .",
    "interestingly , for @xmath101 , the load is not much higher than in the single - destination scenario ; this confirms the good load - balancing properties of @xmath101 .",
    "however , we also see that @xmath149 performs poorly and needs to be generalized for the multi - destination scenario .",
    "finally , we note that in this scenario , we can exploit * bal * s flexibility and in contrast to the single destination case , the algorithm significantly outperforms * rob * ( in terms of load ) .",
    "this work is motivated by the trend towards software - defined networking and in particularly the fast failover mechanism which supports the in - band masking of failures ( see section  5.8 of the openflow 1.1 specification ) . however , as the convergence time of routing algorithms is often relatively high compared to packet forwarding speeds , ranging from 10s of milliseconds to seconds depending on the network  @xcite , many networks today incorporate some robustness already in the forwarding tables of a router or switch : thus , robust routing concepts and link protection schemes have been studied intensively for many years , also outside sdn .    for example , robust multiprotocol label switching ( mpls ) supports local and global path protection to compute shortest backup paths around an outage area  @xcite , where `` shortest '' is often meant in terms of congestion  @xcite .",
    "related to our connectivity and load - balancing tradeoff is also the work by suchara et al .",
    "@xcite who analyze how to jointly optimize traffic engineering and failure recovery from pre - installed mpls backup paths .",
    "however , in contrast to our paper , their solution is path - based and not local , and the focus is on robust optimization .",
    "alternative solutions to make routing more resilient rely on special header bits ( e.g. , to determine when to switch from primary to backup paths , as in _ mpls fast reroute _",
    "@xcite , or to encode failure information to make failure - aware forwarding decisions  @xcite ) , or on fly table modifications  @xcite .",
    "recently , feigenbaum et al .",
    "@xcite made an interesting first step towards a better theoretical understanding of resilient sdn tables .",
    "the authors prove that routing tables can provide guaranteed resilience ( i.e. , loop - freeness ) against a _ single _ failure , when the network remains connected .",
    "so , will or wo nt you shoot in your foot with fast failover ?",
    "our results show that there exists an interesting tradeoff between a `` safe '' and `` efficient '' failover .",
    "the usefulness of the local failover depends on whether link failures are rather adversarial or random , and on how flexibly the failover rules can be specified . in particular , we have seen that the possibilities of destination - based failover schemes are very limited . but also more expressive failover schemes where flows can be forwarded depending on arbitrary local matching rules ( this is more general than today s openflow specification ) , can lead to high network loads in the worst case . on the positive side ,",
    "relatively simple algorithms exist which match these lower bounds .",
    "* acknowledgments .",
    "* we would like to thank chen avin for valuable discussions and advice .",
    "the @xmath201 algorithm is executed sequentially for each node @xmath32 and for each failed link incident to @xmath32 chooses the new next hop based on the current node ( @xmath32 ) and the second end of the currently failed link .",
    "current node ",
    "@xmath32 , second end of failed link ",
    "@xmath85 new next hop",
    "@xmath202 @xmath203 @xmath204 @xmath205    the @xmath206 algorithm always selects the next available neighbor as the new next hop .",
    "current node  @xmath32 new next hop @xmath207",
    "in this section we take a broader look at the problem and study additional scenarios and adversarial models .",
    "so far , we have concentrated on a worst - case adversary which fails exactly those links which will lead to the highest load .",
    "we now want to have a look at a more realistic , `` weak adversary '' @xmath208 , who fails links at random ( _ independently _ of the installed failover rules ) .",
    "[ thm : rand_weak_adv ] using the @xmath101 failover scheme , in order to create a load of @xmath77 , @xmath208 will have to fail at least @xmath209 links",
    "_ the same results hold even if @xmath208 knows the destination of the traffic .",
    "we build upon the proof of theorem  [ thm : rand_strong_adv ] .",
    "let us assume that @xmath208 knows the destination node @xmath6 .",
    "then , it will only fail the links incident to the destination : consider any failover sequence @xmath192 and assume that the @xmath95 first nodes in this sequence are already in use as backup nodes . in order to make use of the node @xmath210",
    ", the adversary needs to fail either the link @xmath91 or the link @xmath211 .",
    "if the adversary will fail only links to the destination @xmath6 , the probability of reaching the node @xmath92 is at least @xmath212 , while a random link selection will succeed only with probability @xmath213 .",
    "moreover , such failures ( i.e. , failures of links towards the destination ) can be reused better ( see claim [ claim : best_adv_strategy ] ) .    from the proof of theorem [ thm :",
    "rand_strong_adv ] , we know that the minimal _ total prefix length _",
    "( i.e. , the sum of all @xmath77-prefixes ) of any node @xmath81 is @xmath126 and the number of distinct nodes in the prefix is at least @xmath214 .",
    "the number of possible total prefixes is @xmath140 .",
    "we now ask the following question : if the adversary fails @xmath18 ( of course @xmath215 ) random links adjacent to the destination , what is the probability that these failures will cover at least one possible _ total _",
    "first , we will compute the probability @xmath216 that @xmath18 random failures will cover a single total prefix ( with @xmath217 distinct nodes ) ; subsequently , we will apply a union bound argument over all possible total prefixes .",
    "simple combinatorics give us the expression for @xmath216 : @xmath218 using stirling s approximation for the factorial , we have : @xmath219                  since @xmath234 , we can use the union bound from the proof of theorem [ thm : rand_strong_adv ] ( see equation ( [ eq : union_reuse ] ) in that proof ) : we conclude that for @xmath144 , in order to create a load of @xmath77 , a weak adversary will have to fail at least @xmath235 links with probability of at least @xmath236 .",
    "@xmath57      we can also generalize the traffic model : instead of having a single destination , each node @xmath32 for all @xmath237 $ ] needs to send one unit of flow to each other node @xmath85 with @xmath238 .",
    "we can adapt the @xmath101 scheme in the sense that we generate @xmath239 random failover permutations , one for each source - destination pair .",
    "note that this corresponds to a matrix representation @xmath240 with @xmath239 rows and @xmath47 columns .",
    "again , the permutations ensure loop - freeness .      in the generalized @xmath101 , we have @xmath243 failover sequences : each set of @xmath7 sequences are for a specific destination .",
    "consider now the first column of this @xmath244 matrix .",
    "since there are @xmath243 rows , there exists a node @xmath81 that appears at least @xmath7 times in the first column .",
    "now , for each row @xmath79 in which @xmath245 , the adversary can fail the link from @xmath32 to the appropriate destination , thus making the flow to go through @xmath81 .",
    "hence , a single failure is enough to bring an additional flow to @xmath81 , i.e. , the adversary needs at most @xmath58 failures in order to create a load of @xmath58 on @xmath81 .",
    "it remains to show that these failures can not be reused by the adversary , i.e. , the adversary indeed will need to invest @xmath58 failures .",
    "the argument is simple . in order to create a load of @xmath58 on @xmath81 ,",
    "the adversary has to ` finish ' the prefixes of @xmath58 sequences . in order to do so",
    ", it first needs to fail the direct @xmath30 link of every such sequence , i.e. , for each sequence at least this link has to be failed . but these links are unique ( each sequence serves a different source - destination pair ) and thus can not be reused . the last implies that the adversary indeed needs to invest at least @xmath58 failures . @xmath57"
  ],
  "abstract_text": [
    "<S> this paper studies the resilient routing and ( in - band ) fast failover mechanisms supported in software - defined networks ( sdn ) . </S>",
    "<S> we analyze the potential benefits and limitations of such failover mechanisms , and focus on two main metrics : ( 1 ) _ correctness _ ( in terms of connectivity and loop - freeness ) and ( 2 ) _ load - balancing_. we make the following contributions . </S>",
    "<S> first , we show that in the _ worst - case _ </S>",
    "<S> ( i.e. , under adversarial link failures ) , the usefulness of local failover is rather limited : already a small number of failures will violate connectivity properties under _ any _ fast failover policy , even though the underlying substrate network remains highly connected . </S>",
    "<S> we then present randomized and deterministic algorithms to compute resilient forwarding sets ; these algorithms achieve an almost optimal tradeoff . </S>",
    "<S> our worst - case analysis is complemented with a simulation study . </S>"
  ]
}