{
  "article_text": [
    "( teuben 1994 ) and are traditional programming environments with which n - body simulations can be setup , run and analyzed .",
    "nemo also has a number of tools to import and export data in tables , ccd type images , fits files and a large number of other n - body formats .",
    "nemo is more geared towards collisionless stellar dynamics , while starlab has more sophisticated programs to deal with close encounters , and can now also incorporate stellar evolution through the seba package ( portegies zwart et al . 2001 ) .",
    "nemo and starlab present themselves to a user as a large set of programs , often glued together using pipes in shell scripts to set up and run complex simulations . for the programmer ,",
    "a large set of classes and functions are available to construct new integrators and analysis programs .",
    "for example , in the following starlab example an anisotropic king model with 2048 particles has been evolved with 50% binaries ( i.e. 3096 actual stars ) and stellar evolution :    ....    mk_aniso_king -i -n 2048 -u -w 4 -f 3                       |\\    mkmass -i -u 100 -l 0.1 -f 3                              |\\    mksecondary -f 0.5 -l 0.1                                 |\\    addstar -q 0.5 -r 2.5                                     |\\    scale -m 1 -e -0.25 -q 0.5                                |\\    mkbinary -f 2 -l 1 -u 1000000 -o 2                        |\\    kira -a 0.1 -d 1 -d 25 -n 25 -t 4000 -q -g 2 -u",
    "-b -z 1 > run001 ....    the grape special purpose hardware ( hut and makino , 1999 ) , now running at 100 terraflops speed , has been successfully interfaced with starlab , and now is starting to produce massive datasets .",
    "analysis and visualization techniques of those dataset are becoming increasingly challenging .",
    "the american museum for natural history ( amnh ) in new york city has recently renovated its planetarium , and converted it into a state - of - the - art digital planetarium with capabilities for scientific visualization .",
    "their computer system consists of an onyx2 , with 28 cpus , 14 gb of memory , 2 tb diskspace and 7 graphics pipes .",
    "each graphics pipe controls one of 7 projectors which illuminate the dome in a dodecahedral pattern .",
    "the software that drives most visualization is an ncsa product called ( virdir ) , that we have now been using during a number of night sessions in the dome , much like optical observers ( during daytime the planetarium is of course used for public viewing ) .",
    "it allows us to `` fly '' through the data , in space and time . by adding complete orbital information for a select number of stars we have started fully interactive data mining of our 4d spacetime histories of these star cluster simulations runs .    in order for us to test new visualization techniques , algorithms and interfaces with the starlab environment , we used an existing program partiview , which had been derived from virdir , and which can be run on a normal workstation or laptop .",
    "it uses the fltk and mesa / opengl libraries for its user interface and fast graphics .",
    "a screenshot of partiview in action can be seen in figure  [ p1 - 39-fig-1 ] .",
    "we have modified partiview to understand our starlab simulatation data , and added interfaces that allow this workstation version to animate and move in time and space .",
    "partiview comes with a small but powerful set of commands with which dataselections and viewing can be made , and we hope to expand this into a more mature scripting language .",
    "it is also fairly straightforward for other packages to benefit from using partiview .",
    "in the spirit of the federated model of archiving observational data , recently proposed by the nvo ( national virtual observatory ) initiative , we will develop a starlab - based archive .",
    "a simulation of a globular cluster with a million stars stars for ten billion years will generate 100 tbytes of raw data , of which we would like to store at least 1 tbyte , and preferably more , for 4d visualization of the full history of the evolution of a star cluster . although our main goal will be to enable rapid and intelligent access to our simulation output files , we will simultaneously develop a flexible and transparent interface with the nvo databace and protocols . our starlab policy will be to make all simulation results freely and publicly available to ` guest observers ' ."
  ],
  "abstract_text": [
    "<S> in dense clusters a bewildering variety of interactions between stars can be observed , ranging from simple encounters to collisions and other mass - transfer encounters . with faster and special - purpose computers like grape </S>",
    "<S> , the amount of data per simulation is now exceeding 1 tb . visualization of such data has now become a complex 4d data - mining problem , combining space and time , and finding interesting events in these large datasets . </S>",
    "<S> we have recently starting using the virtual reality simulator , installed in the hayden planetarium in the american museum for natural history , to tackle some of these problem . </S>",
    "<S> reports on our first `` observations '' , modifications needed for our specific experiments , and perhaps field ideas for other fields in science which can benefit from such immersion . </S>",
    "<S> we also discuss how our normal analysis programs can be interfaced with this kind of visualization . </S>"
  ]
}