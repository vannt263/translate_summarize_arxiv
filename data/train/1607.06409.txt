{
  "article_text": [
    "when releasing microdata to the public , methods of statistical disclosure control ( sdc ) are used to protect confidential data , that is `` data which allow statistical units to be identified , either directly or indirectly , thereby disclosing individual information '' @xcite , while enabling valid statistical inference to be drawn on the relevant population .",
    "sdc methods include data swapping , additive and multiplicative noise , top and bottom coding , and also the creation of synthetic data . in this paper , the authors provide inferential tools for the statistical analysis of a singly imputed synthetic dataset when the real dataset can not be released . the multiple imputation case is also addressed , using a new adapted method of generating synthetic data , which the authors call fixed - posterior predictive sampling ( fpps ) .",
    "the use of synthetic data for sdc started with little @xcite and rubin @xcite using multiple imputation @xcite .",
    "reiter @xcite was the first to present methods for drawing inference based on partially synthetic data .",
    "moura et al .",
    "@xcite complemented this work with the development of likelihood - based exact inference methods for both single and multiple imputation , that is , inferential procedures developed based on exact distributions , and not on asymptotic results , in the case where synthetic datasets were generated via plug - in sampling .",
    "the procedures of reiter @xcite are general in that they can be applied to a variety of estimators and statistical models , but these procedures are only applicable in the multiple imputation case , and are based on large sample approximations .",
    "there are two major objectives in the present research .",
    "first , to make available likelihood - based exact inference for singly imputed synthetic data via posterior predictive sampling ( pps ) where the usual available procedures are not applicable , therefore extending the work of klein and sinha @xcite , under the multivariate linear regression ( mlr ) model .",
    "second , to propose a different approach for release of multiple synthetic datasets , fpps , which can use a similar way of gathering information from the synthetic datasets to that used in @xcite , when these synthetic datasets are generated via the plug - in sampling method .",
    "this second objective arises from the fact that when using the classical pps it is too hard to construct an exact joint probability density function ( pdf ) for the estimators , under the mlr model , since one would face the problem of deriving the distribution of a sum of variables that follow wishart distributions with different parameter matrices .",
    "it is with this problem in mind , that we propose an adapted method that we will call the fpps method .",
    "we show that this method offers a higher level of confidentiality than the plug - in sampling method , and it still allows one to draw inference for the unknown parameters using a joint pdf of the proposed estimators .",
    "a brief description of the pps and fpps methods follows .",
    "suppose that @xmath0 are the original data which are jointly distributed according to the pdf @xmath1 , where @xmath2 is the unknown ( scalar , vector or matrix ) parameter .",
    "a prior @xmath3 for @xmath4 is assumed and then the posterior distribution of @xmath4 is obtained as @xmath5 , and used to draw a replication @xmath6 of @xmath4 , when applying the fpps , or draw @xmath7 independent replications @xmath8 of @xmath9 , when applying the pps . in the case of fpps , we generate @xmath10 replicates of @xmath11 , namely , @xmath12 , @xmath13 drawn all independently from the same @xmath14 , where @xmath14 is the joint pdf of the original @xmath11 with @xmath15 replacing the unknown @xmath9 . in the case of the usual pps method for each @xmath16-th generated synthetic dataset",
    "we would use the corresponding @xmath16-th posterior draw @xmath17 and corresponding @xmath16-th joint pdf s @xmath18 , for @xmath13 . in either case , these synthetic datasets @xmath19 will be the datasets available to the general public .",
    "one may observe that , for @xmath20 , the posterior predictive sampling and fixed - posterior predictive sampling methods concur .",
    "regarding the mlr model , in our context , we consider the _ sensitive _ response variables @xmath21 @xmath22 forming the vector of response variables @xmath23 , and a set of p non-_sensitive _ explanatory variables @xmath24 .",
    "it is assumed that @xmath25 , with @xmath26 and @xmath27 unknown , and the original data consist of @xmath28 , where @xmath29 will be the sample size .",
    "let us consider @xmath0 with @xmath30 and @xmath31 with @xmath32 .",
    "we assume @xmath33 and @xmath34 . therefore the following regression model is considered @xmath35 where @xmath36 is distributed as @xmath37 .",
    "based on the original data , @xmath38 is the maximum likelihood estimator ( mle ) and the uniformly minimum - variance unbiased estimator ( umvue ) of @xmath26 , distributed as @xmath39 , independent of @xmath40 which is the mle of @xmath27 , with @xmath41",
    ". therefore @xmath42 will be the umvue of @xmath27 .",
    "the organization of the paper is as follows . in section [ sec : post ] ,",
    "based on singly and multiply imputed synthetic datasets generated via fixed - posterior predictive sampling , two procedures are proposed to draw inference for the matrix of regression coefficients . under the single imputation case",
    ", we recall that the fpps and the pps methods coincide .",
    "the test statistics proposed will be pivot statistics , different from the classical test statistics for @xmath26 under the mlr model ( see ( * ? ? ?",
    "* secs 8.3 and 8.6 ) ) since it is shown that these classical test statistics are not pivotal in the present context .",
    "section [ sec : sim ] presents some simulations in order to check the accuracy of theoretically derived results .",
    "also in this section , the authors use a measure for the _ radius _ ( distance between the center and the edge ) of the confidence sets for the regression coefficients adapted from @xcite , computed for the original data and also for the synthetic data generated via fpps .",
    "these _ radius _ measures are compared with the ones obtained when synthetic datasets are generated via plug - in sampling .",
    "section [ sec : app ] presents data analyses under the proposed methods in the context of public use data from the u.s .",
    "current population survey comparing with the same data analysis given by @xcite under the plug - in sampling method . in section [ sec : pri ] , we compare the level of privacy protection obtained via our fpps method and via plug - in sampling method .",
    "some concluding remarks are added in section [ sec : con ] .",
    "proofs of the theorems , and other technical derivations are presented in appendices [ app : a ] and [ app : last ] .",
    "in this section , we present two new exact likelihood - based procedures for the analysis of synthetic data generated using fixed - posterior predictive sampling method , under the mlr model in ( [ eq : model ] ) . for the single imputation case , the two new procedures developed also offer the possibility of drawing inference for a single synthetic dataset generated via posterior predictive sampling .      in this subsection , the synthetic data will consist of @xmath10 synthetic versions of @xmath11 generated based on the fpps method .",
    "consider the joint prior distribution @xmath43 leading to the posterior distributions for @xmath27 and @xmath26 @xmath44 and @xmath45 where we assume that @xmath46 ( see proof in appendix [ aapp : last0 ] ) .",
    "consequently , we draw @xmath47 from ( [ eq : postsigma ] ) and @xmath48 from ( [ eq : postb ] ) , upon replacing @xmath27 by @xmath47 in this latter expression . we then generate the @xmath10 synthetic datasets , denoted as @xmath12 , for @xmath13 , where @xmath49 , are independently distributed as @xmath50 for @xmath51 and @xmath13 , let @xmath52 and @xmath53 be the estimators of @xmath26 and @xmath27 , based on the synthetic data @xmath54 , which by lemma 1.1 in @xcite are jointly sufficient .",
    "conditional on @xmath55 , for every @xmath13 , @xmath56 is independent of @xmath57 and @xmath58 are jointly sufficient estimators for @xmath26 and @xmath27 .",
    "define then @xmath59 which are also mutually independent , given @xmath60 and @xmath61 . for @xmath62 and @xmath63 , we derive the following main results .    1 .",
    "the mle of @xmath26 is @xmath64 , which is unbiased for @xmath26 , with @xmath65@xmath66 , where @xmath67 ( see theorem [ thm : pdf ] and appendix [ aapp : last3 ] ) .",
    "an unbiased estimator ( ue ) of @xmath27 will be @xmath68 ( see theorem [ thm : pdf ] and appendix [ aapp : last3 ] ) ; for @xmath69 , @xmath70 will also be an ue for @xmath27 , 3 .   in theorem [ thm : dist ]",
    "( see below ) , we prove that @xmath71 a statistic somewhat related with the hotelling @xmath72 , this one built to make inference on a matrix parameter , is a pivotal quantity , and that for @xmath73 , @xmath74 and @xmath75@xmath76 , all independent random variables , @xmath77 where @xmath78 has the same distribution as @xmath79 and where @xmath80 means ` stochastic equivalent to ' .",
    "4 .   if one wants to test a linear combination of the parameters in @xmath26 , namely , @xmath81 where @xmath82 is a @xmath83 matrix with @xmath84 and @xmath85 , one defines @xmath86and proceeds by noting that @xmath87 with @xmath88 being independent random variables and @xmath78 defined as in the previous item .",
    "+ ( i)_test for the significance of @xmath89 : _ in order to test @xmath90 versus @xmath91 , we reject @xmath92 whenever @xmath93 exceeds @xmath94 where @xmath94 satisfies @xmath95 when @xmath92 is true . to perform",
    "a test for @xmath96 one has to take @xmath97 .",
    "+ ( ii)_confidence set for @xmath89 : _ a @xmath98 level confidence set for @xmath89 is given by @xmath99 where the value of @xmath100 can be obtained by simulating the distribution in ( [ eq : tc1 ] ) .",
    "results in 1 - 4 are derived based on theorems [ thm : pdf ] and [ thm : dist ] below .",
    "[ thm : pdf ]    the joint pdf of @xmath101 and @xmath102 , for @xmath103 and @xmath70 defined in ( [ eq : parameters1st ] ) , is proportional to @xmath104 so that @xmath64 and @xmath105 , given @xmath61 , are independent , with @xmath106 and @xmath107    see appendix [ app : a ] .",
    "[ thm : dist ] the distribution of the statistic @xmath108 defined in ( [ eq : t1st ] ) can be obtained from the decomposition @xmath109 where @xmath75 are independent random variables , themselves independent of @xmath78 , which has the same distribution as @xmath79 with @xmath73 and @xmath74 , two independent random variables .",
    "see appendix [ app : a ] .",
    "when @xmath110 and @xmath20 , the statistic in ( [ eq : t1st ] ) reduces to the statistic @xmath72 used in @xcite whose pdf is obtained by noting that @xmath111    we remark that the statistic @xmath108 in ( [ eq : t1st ] ) degenerates towards zero when @xmath112 or @xmath113 , but @xmath114{d}\\left\\{\\prod_{i=1}^{m}\\chi^2_{p - i+1}\\right\\}\\left|\\frac{m+1}{m}\\mathbf{i}_{m}+\\mathbf{\\omega}\\right|\\ ] ] and @xmath115{d}\\left\\{\\prod_{i=1}^{m}\\chi^2_{p - i+1}\\right\\}\\left|\\mathbf{i}_{m}+\\mathbf{\\omega}\\right|,\\ ] ] where @xmath116 represents convergence in distribution .",
    "consequently , if instead of using @xmath108 one uses @xmath117 one would have @xmath118{d}\\left\\{\\prod_{i=1}^{m}\\chi^2_{p - i+1}\\right\\}\\left|\\frac{m+1}{m}\\mathbf{i}_{m}+\\mathbf{\\omega}\\right|\\ ] ] and @xmath119{d}\\left\\{\\prod_{i=1}^{m}\\chi^2_{p - i+1}\\right\\}\\left|\\mathbf{i}_{m}+\\mathbf{\\omega}\\right|,\\ ] ] which corresponds to the use of a simple scale change .",
    "in table 1 , we list the simulated @xmath120 cut - off points for @xmath108 , for @xmath20 for some values of @xmath121 , @xmath122 and @xmath29 .    c    [ cols= \" > ,",
    "< , < , < , < \" , ]     looking at tables [ table : t12 ] and [ table : t3 ] , we observe that the values of the privacy measures in ( [ eq : conf ] ) increase for increasing values of @xmath10 for both procedures developed in subsections [ ssec : mul1 ] and [ ssec : mul2 ] , showing that the disclosure risk increases with the increase in the number of released synthetic datasets . compared with the measures obtained under plug - in sampling , we may observe a smaller disclosure risk in all cases , leading to the conclusion that the proposed fpps procedures have an overall higher level of confidentiality . regarding measures @xmath123 and @xmath124 this increase reaches in some cases an increase of 50% or more in confidentiality .",
    "in the single imputation case , under the pps we also register an increase of confidentiality when comparing the same measure under plug - in sampling , nevertheless this increase is relatively small .",
    "in this paper the authors derive likelihood - based exact inference for single and multiple imputation cases where synthetic datasets are generated via fixed - posterior predictive sampling ( fpps ) .",
    "if only one synthetic dataset is released , then fpps is equivalent to the usual posterior predictive sampling ( pps ) method .",
    "thus the proposed methodology can be used to analyze a singly imputed synthetic data set generated via pps under the multivariate linear regression ( mlr ) model .",
    "therefore this work fills a gap in the literature because the state of the art methods apply only to multiply imputed synthetic data . under the mlr model",
    ", the authors derived two different exact inference procedures for the matrix of regression coefficients , when multiply imputed synthetic datasets are released .",
    "it is shown that the methodologies proposed lead to confidence sets matching the expected level of confidence , for all sample sizes .",
    "furthermore , while the second proposed procedure displays a better precision for smaller samples and/or smaller values of @xmath10 by yielding smaller confidence sets , the two procedures concur for larger sample sizes and larger values of @xmath10 , as it is corroborated in theory by remarks 2.2 and 2.3 .",
    "when compared with inference procedures for plug - in sampling , the procedures proposed based on fpps lead to synthetic datasets that give respondents a higher level of confidentiality , that is , a reduced disclosure risk , nevertheless at the expense of accuracy , since the confidence sets are larger , as illustrated in the application with the cps data .",
    "once likelihood - based exact inferential methods are now made available both for fpps / pps and plug - in sampling , it is therefore the responsibility of those in charge of releasing the data to decide which method to use in order to better respect the demands and objectives of their institution .",
    "ricardo moura s research is supported by a fulbright research grant , and he sincerely thanks the faculty of mathematics and statistics at umbc for their support and encouragement .",
    "ricardo moura and carlos a. coelho also thank fct ( portuguese foundation for science and technology ) project uid / mat/00297/2013 awarded through cma / unl .",
    "martin klein and bimal sinha thank laura mckenna , eric slud , william winkler , and tommy wright at the u.s .",
    "census bureau for their support .",
    "the authors would also like to thank the referees for the helpful comments and suggestions leading to the improvement of the paper .",
    "given @xmath55 , from ( [ eq : synt ] ) we have that , for every @xmath13 , @xmath125 and @xmath126 therefore , we have for @xmath127 and @xmath128 in ( [ eq : parameters1st ] ) , @xmath129 and @xmath130    since @xmath127 and @xmath128 are independent , the conditional joint pdf of @xmath131 , given @xmath60 and @xmath61 , is @xmath132\\rbrace}\\times                   \\frac{\\vert\\mathbf{\\overline{s}}^{\\bullet}_m\\vert^{\\frac{m(n - p)-m-1}{2}}}{\\vert\\mathbf{\\tilde{\\sigma}}\\vert^{\\frac{m(n - p)+p}{2 } } } ,   { \\end{array}}\\ ] ] while , due to the independence of @xmath133 and @xmath134 , generated from ( [ eq : postsigma ] ) and ( [ eq : postb ] ) , respectively , the joint pdf of @xmath135 , given @xmath136 , is @xmath137\\rbrace}\\frac{\\vert \\mathbf{s}\\vert^{\\frac{n+\\alpha - p - m-1}{2}}}{\\vert\\mathbf{\\tilde{\\sigma}}\\vert^{\\frac{n+\\alpha - p}{2}-m-1}}.\\!\\!\\!\\ ] ] on the other hand , given the independence of @xmath138 and @xmath136 , defined in ( [ eq : orb ] ) and ( [ eq : ors ] ) , the joint pdf of @xmath139 is given by @xmath140\\rbrace}\\frac{\\vert                       \\mathbf{s}\\vert^{\\frac{n - p - m-1}{2}}}{\\vert\\mathbf{\\sigma}\\vert^{\\frac{n}{2}}}.\\ ] ]    thus , by multiplying the three pdf s in ( [ eq : syntjoint ] ) , ( [ eq : postdist ] ) and ( [ eq : origjoint ] ) , we obtain the joint pdf of @xmath141 .",
    "since @xmath142 and since from appendix [ aapp : last2 ] we may write @xmath143 @xmath144'\\!\\mathbf{xx'}\\left[\\mathbf{\\tilde{b}}\\!-\\!\\frac{1}{m+1}\\mathbf{(b^{\\bullet}+\\hat{b})}\\right]\\!\\ ] ] @xmath145 by integrating out @xmath48 , we obtain the joint pdf of @xmath146 proportional to    e^-tr^-1+^-1 + .    since @xmath147\\right\\ }                  \\end{aligned}\\ ] ] and since from the identities in 1.-3 .",
    "in appendix b1 in @xcite we may write @xmath148\\\\                   & \\left(\\!\\frac{m}{m+1}\\!\\mathbf{\\tilde{\\sigma}^{-1}}\\!+\\!\\mathbf{\\sigma^{-1}}\\right)\\left[\\mathbf{\\hat{b}}\\!-\\!\\left(\\frac{m}{m+1}\\mathbf{\\overline{b}}^{\\bullet}_m\\mathbf{\\tilde{\\sigma}^{-1}}\\!+\\!\\mathbf{b}\\mathbf{\\sigma^{-1}}\\right)\\left(\\frac{m}{m+1}\\mathbf{\\tilde{\\sigma}^{-1}}\\!+\\!\\mathbf{\\sigma^{-1}}\\right)^{-1}\\right]'\\\\                   & \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+(\\mathbf{\\overline{b}}^{\\bullet}_m-\\mathbf{b})\\left(\\frac{m+1}{m}\\mathbf{\\tilde{\\sigma}}+\\mathbf{\\sigma}\\right)^{-1}(\\mathbf{\\overline{b}}^{\\bullet}_m-\\mathbf{b } ) ' , \\end{aligned}\\ ] ] integrating out @xmath138 we will have the joint pdf of @xmath149 proportional to    & e^-tr(^-1(^_m-)(^_m-)+(n - p)(m^_m+)+(n - p)^-1 + &   |+|^-p/2 .",
    "consequently , if we integrate out @xmath136 we will end up with the joint pdf of @xmath150 proportional to    [ eq : likelihood ] & e^-tr(^-1(^_m-)(^_m-)+m(n - p)^_m + & ^- |+|^-p/2 ||^-    as we wanted to prove .",
    "it is easy to see that in ( [ eq : likelihood ] ) , @xmath70 and @xmath103 , given @xmath151 , are separable , with the distributions in the body of the theorem .    from the distributions of @xmath70 and @xmath103 in theorem [ thm : pdf ] , and by theorem 2.4.1 in @xcite we have that , for @xmath152 @xmath153 from theorem 2.4.2 in @xcite and subsection 7.3.3 in @xcite we have @xmath154 and @xmath155 we may thus write @xmath108 in ( [ eq : t1st ] ) as @xmath156 where , @xmath157 and @xmath158 , with independent chi - square random variables in each product , we end up with a product of independent f - distributions , due to the independence of @xmath159 and @xmath160 , inherited from the independence of @xmath103 and @xmath70 .",
    "so , conditionally on @xmath102 , we have @xmath161 where @xmath162 @xmath163    as such , from ( [ eq : likelihood ] ) , integrating out @xmath103 and @xmath70 , we end up with the pdf of @xmath151 proportional to    & ||^||^^- + &  |+|^-p/2 ||^- + & = |^-1|^||^^- + &  |+|^-p/2 ||^- .    making the transformation @xmath164 , which implies @xmath165 , with the jacobian of the transformation from @xmath151 to @xmath78 being @xmath166",
    ", we have the pdf of @xmath78 proportional to        since @xmath167 we end up with    f()||^||^-    independent of @xmath27 .",
    "therefore , we may conclude that @xmath168 where from ( * ? ? ?",
    "* theorem 8.2.8 . )",
    "@xmath78 has the same distribution as @xmath79 with @xmath169 and @xmath170 , two independent random variables .",
    "the proof is identical to the proof of theorem [ thm : pdf ] replacing the joint pdf of @xmath131 by the joint pdf of @xmath171 , noting that we have @xmath172    the proof is identical to that of theorem [ thm : dist ] replacing @xmath173 by @xmath174 , noting that from corollary [ cor : pdf ] , conditional on @xmath61 , @xmath103 is @xmath175 and @xmath176 is @xmath177 , independent of @xmath103 .",
    "let us start by observing that @xmath178 and that the likelihood function for @xmath11 will be @xmath179 we may then get the joint posterior distribution of @xmath180 from the product of the prior and likelihood functions as @xmath181    the exponent in ( [ eq : posterior ] ) may be written as @xmath182\\right\\}\\\\                  & \\hspace{40pt}+tr\\big\\{\\mathbf{\\sigma}^{-1}\\big[(\\mathbf{y-\\hat{b}'x})(\\mathbf{\\hat{b}'x - b'x})'+(\\mathbf{\\hat{b}'x - b'x})(\\mathbf{y-\\hat{b}'x})'\\\\                  & \\hspace{230pt}+(\\mathbf{\\hat{b}'x - b'x})(\\mathbf{\\hat{b}'x - b'x})'\\big]\\big\\}\\\\                  & = tr\\left\\{\\mathbf{\\sigma}^{-1}\\left[(\\mathbf{y-\\hat{b}'x})(\\mathbf{y-\\hat{b}'x})'\\right]+(\\mathbf{b}-\\mathbf{\\hat{b}})'(\\mathbf{xx'})(\\mathbf{b}-\\mathbf{\\hat{b}})\\right\\}\\\\                  & \\hspace{190pt}+2 tr\\left\\{{\\mathbf{\\sigma}}^{-1}\\left[(\\mathbf{y-\\hat{b}'x})(\\mathbf{\\hat{b}'x - b'x})'\\right]\\right\\ } ,                  \\end{aligned}\\ ] ] where , using @xmath183'=\\mathbf{yx'(xx')^{-1}}$ ] , @xmath184 therefore , the joint posterior distribution of @xmath185 is proportional to        in conclusion , by corollary 2.4.6.2 . in @xcite , the posterior distribution for @xmath27 is @xmath186 and the posterior distribution for @xmath26",
    "is @xmath187 assuming @xmath46 .        since ,",
    "@xmath190 we may write @xmath191'\\mathbf{xx'}\\left[\\mathbf{\\tilde{b}}-\\frac{1}{m+1}(m\\mathbf{\\overline{b}}^\\bullet_m+\\mathbf{\\hat{b}})\\right ] & \\\\              & \\hspace{200pt } + \\frac{m}{m+1}(\\mathbf{\\overline{b}}^\\bullet_m-\\mathbf{\\hat{b}})'\\mathbf{xx}'(\\mathbf{\\overline{b}}^\\bullet_m-\\mathbf{\\hat{b } } )              \\end{aligned}\\ ] ]      _ details on result 1 _    from ( [ eq : likelihood ] ) we may immediately conclude that the mle of @xmath26 based on the synthetic data will be @xmath103 with @xmath192 and @xmath193+e[var(\\mathbf{\\overline{b}}^{\\bullet}_m|\\mathbf{\\tilde{b},\\tilde{\\sigma}})].\\ ] ]    for the first term in ( [ eq : var1 ] ) , we have @xmath194=var[\\mathbf{\\tilde{b}}]=var[e(\\mathbf{\\tilde{b}|\\hat{b},\\tilde{\\sigma}})]+e[var(\\mathbf{\\tilde{b}|\\hat{b},\\tilde{\\sigma}})]=\\ ] ] @xmath195=\\mathbf{\\sigma\\otimes ( xx')^{-1}}+\\frac{n - p}{n+\\alpha - p-2m-2}\\mathbf{\\sigma\\otimes ( xx')^{-1}}\\ ] ] and for the second term , we have @xmath196=e\\left[\\frac{1}{m}\\mathbf{\\tilde{\\sigma}\\otimes ( xx')^{-1}}\\right]=\\frac{1}{m}\\frac{n - p}{n+\\alpha - p-2m-2}\\mathbf{\\sigma\\otimes ( xx')^{-1}},\\ ] ] so that @xmath197 under the condition that @xmath63 .",
    "_ details on result 2 _",
    "@xmath198    _ details on result 5 _    let us consider @xmath159 and @xmath160 given by ( [ eq : h ] ) and ( [ eq : g ] ) .",
    "we will begin by rewriting all four classical statistics @xmath199 , @xmath200 , @xmath201 and @xmath202 in subsection [ ssec : mul1 ] , in order to make them assume the same kind of form and then we will prove why all of them are non - pivotal , without loss of generality considering @xmath20 .",
    "the first statistic , @xmath203may be rewritten as    t^_1,1 & = .    while @xmath200 and @xmath201 may be rewritten as    t^_2,1 & = ( n - p)tr ,    t^_3,1 & = tr(n - p ) .",
    "concerning @xmath204 , we have @xmath205 where @xmath206 denotes the largest eigenvalue of    & ( n - p ) .",
    "we can observe that a term in the denominator of the expression @xmath207 is @xmath208 while in the expressions for the other statistics there are similar terms .",
    "these terms involve a product similar to @xmath209 that can not be simplified to an expression which is not a function of @xmath27 , therefore making these statistics non - pivotal .",
    "thus , in order to illustrate how these statistics are dependent on @xmath27 , we can analyze in figure [ fig : fig ] the empirical distributions of @xmath207 , @xmath210 , @xmath211 and @xmath204 when we consider a simple case where @xmath212 , @xmath213 , @xmath214 , @xmath215 and @xmath216 with @xmath217 for a simulation size of 1000 .",
    ".5 ) of @xmath207 , @xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] ) of @xmath207 , @xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] [ fig : wilks ]    .5 ) of @xmath207 ,",
    "@xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] ) of @xmath207 , @xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] [ fig : lawley ]    .5 ) of @xmath207 , @xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] ) of @xmath207 , @xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] [ fig : pillai ]    .5 ) of @xmath207 , @xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] ) of @xmath207 , @xmath210 , @xmath211 and @xmath204 for @xmath218.,title=\"fig : \" ] [ fig : roy ]      recalling that @xmath219 and that @xmath220 we immediately obtain @xmath221      _ details on the expected values in section [ sec : sim ] _",
    "recall that @xmath222 , thus implying that @xmath223 and recall that @xmath224 thus implying that , making @xmath225 , given @xmath136 ,    e(|| ) & = e(|^-1|^-1)=|(n - p)|e ( ) + & = |(n - p)| ,    since @xmath226 is a product of independent @xmath227 variables . also recalling that , given @xmath47 , we have @xmath228 and @xmath229",
    ", we may conclude that , given @xmath47 , @xmath230 and @xmath231    combining the results for @xmath232 and @xmath233 with each of the expected values for @xmath234 and @xmath235 , we end up with the expression for @xmath236 found in section [ sec : sim ] .",
    "let us consider the @xmath10 synthetic datasets as one only dataset of size @xmath237 @xmath238 where @xmath239 is the @xmath240 matrix of the synthesized data under fpps and @xmath241 the @xmath242 matrix of the @xmath10 repeated ` fixed ' sets of covariates , from the original data .",
    "let @xmath243 be the estimator for @xmath26 , based on the dataset of size @xmath237 , obtained by joining the @xmath10 synthetic datasets in one only dataset .",
    "consequently one has that @xmath244 which is same estimator for @xmath26 as in ( [ eq : par2nd1 ] ) .",
    "now let us consider the estimator @xmath251 of @xmath27 , defined in the text , before expression ( [ eq : par2nd1 ] ) .",
    "this estimator may be written as @xmath252 where @xmath253 is the @xmath254-th column of @xmath255 @xmath256 .",
    "we may thus write @xmath257 and the estimator @xmath258 of @xmath27 , defined right after expression ( [ eq : par2nd2 ] ) as @xmath259    we may therefore write the combination estimator @xmath260 defined in ( [ eq : par2nd2 ] ) as @xmath261{\\medskip}\\\\                  \\hskip 1.5 cm { \\displaystyle}+\\frac{1}{nm - p}\\left[m\\times \\left(\\frac{1}{m}\\mathbf{w}_a\\mathbf{r}-\\frac{1}{m}\\mathbf{b}_a'\\mathbf{x}_a\\mathbf{r}\\right)\\left(\\frac{1}{m}\\mathbf{w}_a\\mathbf{r}-\\frac{1}{m}\\mathbf{b}_a'\\mathbf{x}_a\\mathbf{r}\\right)'\\right ]                  { \\end{array}}\\ ] ]"
  ],
  "abstract_text": [
    "<S> the authors derive likelihood - based exact inference methods for the multivariate regression model , for singly imputed synthetic data generated via posterior predictive sampling ( pps ) and for multiply imputed synthetic data generated via a newly proposed sampling method , which the authors call fixed - posterior predictive sampling ( fpps ) . in the single imputation case , our proposed fpps method concurs with the usual posterior predictive sampling ( pps ) method , thus filling the gap in the existing literature where inferential methods are only available for multiple imputation . </S>",
    "<S> simulation studies compare the results obtained with those for the exact test procedures under the plug - in sampling method , obtained by the same authors . </S>",
    "<S> measures of privacy are discussed and compared with the measures derived for the plug - in sampling method . an application using u.s .  </S>",
    "<S> 2000 current population survey data is discussed .    </S>",
    "<S> finite sample inference ; maximum likelihood estimation ; pivotal quantity ; plug - in sampling ; statistical disclosure control ; unbiased estimators .    </S>",
    "<S> 62h10 , 62h15 , 62h12 , 62j05 , 62f10 , 62e15 , 62e10 , 62e17 , 62d99 . </S>"
  ]
}