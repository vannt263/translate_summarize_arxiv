{
  "article_text": [
    "as a means of fast solving `` sparse '' linear systems which can be the most time - consuming part in many physical simulations , a preconditioned iterative method is one of the most frequently used computational methods . among many existing preconditioning methods , ilu preconditioning is highly regarded for its generality in application because it can be applied to arbitrary matrices with nonzero entry structures . in particular ilu with no fill - in , denoted by ilu(0 ) @xcite , which is the most basic form of ilu preconditioning , requires no other information except the equations themselves , i.e. , it is a parameter - free method , making it extremely practical . because of these properties",
    ", it has achieved success in a wide variety of physical simulations .",
    "several ilu - based methods have been proposed to improve the computational performance of ilu(0 ) @xcite .",
    "these are classified into two types : one changes only the nonzero entry values in the preconditioning matrices obtained by ilu(0 ) and the other changes both the nonzero entry structure and their values .",
    "the first type includes shifted ilu @xcite and modified ilu ( milu ) @xcite .",
    "shifted ilu performs ilu factorization on a matrix obtained by shifting the diagonal entries .",
    "milu subtracts the products of a relaxation parameter and fill - ins to be discarded from the diagonal entries to reduce the approximation error .",
    "the second type includes ilu with @xmath1 extra diagonals @xcite , fill - in level ilu @xcite , and ilut @xcite , as well as crout ilu @xcite .",
    "the ilu with @xmath1 extra diagonals chooses whether to allow or discard fill - ins , depending on the position in the discrete space .",
    "the fill - in level ilu is the extended version of this method for a general sparse matrix .",
    "ilut and crout ilu allow fill - ins only within certain ranges set up for the number of nonzero entries and those values . the first type of method can be applied to other ilu - based methods .",
    "each of these ilu - based methods obtains the improvement of the performance by introducing unique parameters .",
    "the performance is degraded , however , by setting inadequate parameter values .",
    "since none of these methods sets up the parameters automatically , this should be left to users .",
    "a straightforward way to optimize the parameters is brute force searching over a set of candidates .",
    "here we denote the number of candidates as @xmath2 .",
    "this type of optimization needs to solve a given linear equation @xmath2 times .",
    "this approach is therefore available only when we solve the equation with the same coefficient matrix for a different right - hand - side vector much more than @xmath2 times .    at workplaces where computer - aided engineering is used ,",
    "a wide variety of physical simulations is used to describe various physical phenomena by different modeling methods . even for one physical simulation",
    ", calculations are carried out for different conditions and constraints , depending on the computational size as well as the physical properties and structures of the materials .",
    "since the different conditions and constraints change coefficient matrices , one needs to solve a large number of different linear systems .",
    "hence , to use the ilu - based methods listed above , one has no choice but to set up the same parameter value predetermined empirically for each linear system .",
    "however , since every linear system has different optimum parameter values , these methods can not deliver high performance and may sometimes produce solutions that diverge . in summary , the previous ilu - based methods have traded in the parameter - free advantage of ilu(0 ) preconditioning to improve performance , and as a result they have significant problems in practice .",
    "in recent years , new indices to evaluate the effect of ilu preconditioning have been proposed @xcite .",
    "these indices are some functions of ilu - factorized matrices .",
    "however , they can not be described as explicit functions of the parameters because the parameters directly change not only the values of entries but also the sequence of operations in ilu factorization .",
    "therefore , they could be available only for brute force optimization as well as the previous ilu - based methods described above .",
    "more sophisticated methods have been proposed to determine the ordering of the ilu factorization using some indices calculated from the matrices being processed @xcite .",
    "the indices are called the minimum update matrix and minimum discarded fill . because these self - ordering processes take a tremendously long time , the total calculation time is much increased in almost all cases",
    ". therefore , these methods are not practical except for the special usage as described above .    with this background , in this paper we attempt to improve ilu preconditioning performance without losing practicality for physical simulations @xcite .",
    "first , we introduce to ilu preconditioning new acceleration parameters which make themselves easy to be optimized automatically .",
    "we then describe a mechanism which automatically optimizes these acceleration parameters and propose the process as auto - accelerated ilu preconditioning , or a@xmath0ilu .",
    "a@xmath0ilu can also be applied to the previous ilu - based methods , including shifted ilu , milu , fill - in level ilu , and crout ilu .",
    "the rest of the paper is organized as follows .",
    "section 2 gives an overview of ilu preconditioning .",
    "section 3 explains the basics of a@xmath0ilu preconditioning ; acceleration parameters for ilu preconditioning are introduced first , followed by an explanation of the mechanism that automatically optimizes the acceleration parameters . in section 4 ,",
    "the performance of a@xmath0ilu preconditioning is evaluated by numerical experiments . in subsection 4.1",
    ", we evaluate the performance of a@xmath0ilu(0 ) preconditioning with respect to linear systems obtained by discretization of the pde on rectangular grids and validate its generality , practicality , and scalability .",
    "we also consider applying auto - acceleration to the major ilu - based methods and validate the results . in subsection 4.2 , we evaluate the performance of shifted a@xmath0ilu(0 ) ( shifted ilu(0 ) with auto - acceleration ) preconditioning for general sparse matrices by using more than 200 sample matrices obtained from the university of florida sparse matrix collection @xcite .",
    "in this section we present a brief introduction of ilu preconditioning before proposing our method .",
    "consider a system of linear equations whose coefficients are given by a sparse matrix @xmath3 , denoted as follows : @xmath4 when such a system is solved by an iterative method , the convergence strongly depends on the property of the coefficient matrix .",
    "it can be expected that the number of iterations decreases as a coefficient matrix tends to be close to an identity matrix .",
    "preconditioning reconstructs the system as ( [ eqn : re - constructedlinearsystem ] ) , @xmath5 @xmath6 here , the matrix @xmath7 in ( [ eqn : preconditioningmatrix ] ) is called the preconditioning matrix .",
    "the closer @xmath7 is to @xmath3 , the closer @xmath8 ( the coefficient matrix after the reconstruction ) is to the identity matrix , thus improving the convergence significantly .",
    "ilu preconditioning performs lu factorization on coefficient matrix @xmath3 in an incomplete way and uses the result as a preconditioning matrix .",
    "lu factorization completely decomposes coefficient matrix @xmath3 into the product of a strictly lower - triangular matrix @xmath9 , a diagonal matrix @xmath10 , and a strictly upper - triangular matrix @xmath11 , @xmath12 on the other hand , ilu factorization keeps a certain degree of sparsity in these matrices by discarding part of the fill - in in the course of the factorization process . some sophisticated ilus such as crout ilu",
    "discard not only fill - in but also the updated original entries .",
    "in particular , ilu(0 ) requires that these matrices inherit the nonzero entry structure of coefficient matrix @xmath3 by discarding all fill - ins .",
    "let @xmath13 and @xmath14 denote the strictly lower - triangular matrix and the strictly upper - triangular matrix thus obtained , respectively . using these matrices ,",
    "the ilu preconditioning matrix @xmath7 can be expressed as follows : @xmath15 neither @xmath13 and @xmath9 nor @xmath14 and @xmath11 generally coincide , so there is a difference between matrices @xmath3 and @xmath7 .",
    "the difference between @xmath3 and @xmath7 is called remainder matrix @xmath16 as @xmath17 which is used later to evaluate the approximation accuracy of a preconditioning matrix .",
    "in this section we propose the auto - acceleration of ilu preconditioning .",
    "our new acceleration parameters are used to change only nonzero entry values after ilu factorization .",
    "these parameters can be optimized automatically because the ilu factorized matrix can be described as an explicit function of them .      in order to improve the computational performance ,",
    "ilu preconditioning is requested to reduce both the number of iterations and the operation count per iteration step .",
    "the former can be obtained by the reconstruction of a coefficient matrix shown in ( [ eqn : re - constructedlinearsystem ] ) .",
    "the latter can be given by keeping the sparsity of a coefficient matrix .",
    "however , the sparsity degrades the approximation accuracy of the preconditioned matrix resulting in an increase in the number of iterations .    to achieve a balance between the two factors , ilu preconditioning performs lu factorization on coefficient matrix @xmath3 under some sort of constraints related to the structure of the nonzero entries",
    "however , the effects of the constraints on the accuracy of ilu factorization are quantitatively unknown .",
    "there is no guarantee that the preconditioning matrix obtained by ilu factorization has an optimum level of approximation for coefficient matrix @xmath3 while preserving its nonzero entry structure .",
    "we focus on this point and attempt to improve the approximation accuracy of coefficient matrix @xmath3 by modifying only the values ( without changing the nonzero entry structure ) of the preconditioning matrix obtained by ilu factorization .",
    "if such an attempt is successful , the number of iterations can be reduced without increasing the computational time for each iteration process , ensuring faster computation without any trade - off . in our proposed method , we introduce distinct scalar parameters for the matrices obtained by ilu(0 ) or the other ilu - based methods : @xmath18 for strictly triangular matrices @xmath13 and @xmath14 , and @xmath19 for diagonal matrix @xmath20 , @xmath21 in the rest of this paper , we refer to @xmath18 and @xmath19 as acceleration parameters .",
    "we discuss the mechanism which automatically optimizes the acceleration parameters . from the discussion in the previous section , minimizing the approximation error of the preconditioning matrix relative to the coefficient matrix",
    "is thought to be equal to improving the convergence of the iterative method maximally .",
    "therefore , if we express the approximation error with some kind of objective function of @xmath16 , we can optimize the acceleration parameters automatically with gradient - based methods because the objective function of @xmath16 can be written explicitly as a function of these acceleration parameters .",
    "we adopt the squared euclidean norm of @xmath22 , where @xmath23 as the objective function of @xmath16 , @xmath24 here , @xmath25 is the size of the matrix , @xmath26 is the index for the rows , and @xmath27 is the index for the columns . the objective function is based on an idea of milu in which the condition number , and consequently the number of iterations , is reduced by minimizing @xmath28 for solving an elliptic pde .    the objective function @xmath29 is written as a nonlinear explicit function of @xmath18 and @xmath19 , @xmath30 - 1}l_{ik}{d_{kk}}^{-1}u_{kj}\\right)\\right)^2 .",
    "\\label{eqn : objectivefunctionexpanded}\\end{aligned}\\ ] ]    the optimum values of the acceleration parameters are obtained by minimizing ( [ eqn : objectivefunctionexpanded ] ) .",
    "when we use newton  raphson method to optimize , an update equation for the parameters is given as @xmath31= \\left[\\begin{array}{c}\\phi^{(t ) } \\\\",
    "\\gamma^{(t ) } \\end{array}\\right]-h^{-1}g .",
    "\\label{eqn : newtonraphsonmethod}\\ ] ] here , @xmath32 and @xmath33 are , respectively , a hessian matrix and a gradient vector defined by @xmath34 , \\label{eqn : hessematrix } \\\\ g&=&\\left[\\begin{array}{cc}((\\partial/\\partial\\phi)f(r)&(\\partial/\\partial\\gamma)f(r)\\end{array}\\right]^t .",
    "\\label{eqn : gradientvector}\\end{aligned}\\ ] ] a pair of the acceleration parameters @xmath18 and @xmath19 in ( [ eqn : a2ilu - preconditioningmatrix ] ) and the optimization of them by minimizing the @xmath29 in ( [ eqn : objectivefunction ] ) are referred to as auto - acceleration . since this auto - acceleration",
    "is applied to a matrix described in ( [ eqn : ilu - preconditioningmatrix ] ) , it is expected that the auto - acceleration is incorporated with any other ilu - based methods .",
    "applications of the auto - acceleration to major ilu - based methods are validated by numerical experiments as well as ilu(0 ) . in the rest of this paper , we abbreviate ilu - based preconditioning method with auto - acceleration to a@xmath0ilu . for example , shifted ilu(0 ) with auto - acceleration is referred to as shifted a@xmath0ilu(0 ) .      here",
    "we evaluate the computational cost of auto - acceleration by comparing it with milu factorization .",
    "it can be helpful for the evaluation to divide the computational cost into three parts , i.e. , costs of loading from memory , operating on cpu , and storing into memory .",
    "hereafter , we refer to these three costs as loading cost , operating cost , and storing cost , respectively",
    ".    in the auto - acceleration , the matrix - matrix product @xmath35 in ( [ eqn : objectivefunctionexpanded ] ) dominates its computational cost . on the other hand",
    ", milu performs the following operations : @xmath36 - 1}l_{ik}{d_{kk}}^{-1}u_{kj } \\mbox { if } \\ ( i , j ) \\in p { \\rm , }   \\label{eqn : ilufactorization } \\\\",
    "d_{ii } & = & d_{ii } - \\omega \\sum_{k=0}^{\\min[i , j]-1}l_{ik}d_{kk}^{-1}u_{kj } \\mbox { otherwise } , \\label{eqn : milufactorization}\\end{aligned}\\ ] ] where @xmath37 is a set of indices with nonzero entries of the resultant preconditioned matrix .",
    "milu updates @xmath13 , @xmath20 , and @xmath14 by using ( [ eqn : ilufactorization ] ) with an additional modification in ( [ eqn : milufactorization ] ) .",
    "we can see that both equations are also dominated by the matrix - matrix product .",
    "since the matrix - matrix product must be done for all nonzero elements in both methods , their loading and operating costs are , respectively , identical .    as for the storing cost",
    ", we can see a difference between these methods .",
    "the auto - acceleration stores only two scalar acceleration parameters , @xmath18 and @xmath19 , and a constant number of additional variables temporarily used in ( [ eqn : newtonraphsonmethod ] ) to ( [ eqn : gradientvector ] ) , while milu stores all nonzero elements of three matrices , @xmath13 , @xmath20 , and @xmath14 . therefore , the storing cost of milu is much larger than that of the auto - acceleration for large practical problems .    the computational cost of a simple ilu is less than milu by the matrix - matrix product of the additional modification in ( [ eqn : milufactorization ] ) .",
    "the comparison between the auto - acceleration and ilu is much more complicated than the case of the auto - acceleration and milu .",
    "computational cost of auto - acceleration in sample problems will be compared with that of whole a@xmath0ilu preconditioned iterative method in later sections .      by preliminary numerical experiments",
    ", we found that the parameters satisfying @xmath38 degraded the computational performance in almost all cases .",
    "although the theoretical aspect of this problem is under investigation , we employ the condition @xmath39 as an empirical constraint on the parameter values . in numerical experiments described in the subsequent section ,",
    "the acceleration parameters of all auto - accelerated methods are subject to this constraint .",
    "the proposed method is validated by numerical experiments .",
    "numerical experiments described below are classified into two groups according to the type of coefficient matrix used .",
    "the first one uses multidiagonal sparse matrices given by discretizing partial differential equations ( pdes ) on rectangular grids , while the second one uses general sparse matrices obtained from the university of florida sparse matrix collection .",
    "practicality and performance of a@xmath0ilu and auto - accelerated ilu - based methods are evaluated in the first experiment .",
    "the second experiment mainly shows the effect of the auto - acceleration on shifted ilu(0 ) .      in this subsection",
    "we evaluate the performance of a@xmath0ilu preconditioning for systems of linear equations obtained through discretization of pdes on rectangular grids .",
    "we also validate its effectiveness from various aspects . here , the coefficient matrices of the system of equations will be multidiagonal ( e.g. , tridiagonal , pentadiagonal ) matrices where multiple arrays of nonzero entries are lined up on and along the main diagonal .      here",
    "we validate the generality of a@xmath0ilu(0 ) preconditioning using linear systems derived from five different types of physical simulation .",
    "table [ table : physicalsimulations ] shows the details of each physical simulation .",
    "type of pde and stationary refer to the specifications of pdes obtained by modeling physical phenomena .",
    "these pdes were discretized on rectangular grids using the method described in the discretization column to produce linear systems .",
    "table [ table : matricesandsolver1 ] shows the details of the coefficient matrix of the linear system and the iterative method used .",
    "the size of the coefficient matrix is denoted by n , and nnz / row refers to the number of nonzero entries for each row .",
    "the convergence criterion of the iterative methods is given by @xmath40 , where @xmath41 is the recursive residual vector calculated by the recurrence formula , @xmath42 with the cg method .",
    "the threshold value @xmath43 is determined to avoid pseudo - convergence so that @xmath44 is satisfied until the iterative method is terminated , where @xmath45 is the true residual vector calculated by @xmath46 . in each problem we carry out diagonal scaling first to normalize the coefficient matrix so that every diagonal entry is 1 .",
    "table [ table : calculationenvironment1 ] summarizes the details of the computation environment used .",
    ".physical simulations examined . [ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ table : calculationenvironment2 ]    when solving systems of linear equations arising from an unstructured grid , ilu factorization may result in a diagonal matrix @xmath20 with some tiny entries , which significantly degrade the convergence @xcite .",
    "shifted ilu preconditioning is an effective way to avoid this occurrence and thus is widely used , so we now validate the effectiveness of auto - acceleration on shifted ilu preconditioning . to obtain the best performance of",
    "the original shifted ilu , we use a set of candidate values for the parameters .",
    "we applied shifted ilu(0 ) preconditioning and shifted a@xmath0ilu(0 ) preconditioning to every combination of the sample matrices and the candidate parameter values and analyzed the results from the following multiple aspects .      in this subsection",
    "we examine how auto - acceleration affected the convergence .",
    "figure [ fig : convergencedetermination ] shows the total result of convergence determination for shifted ilu(0 ) preconditioning and shifted a@xmath0ilu(0 ) preconditioning .",
    "the left graph is the result of shifted ilu(0 ) and the right shifted a@xmath0ilu(0 ) .",
    "the horizontal axis indicates the values of shift parameters , while the vertical axis indicates the number of matrices tallied .",
    "the type of convergence is classified into the following three : convergent , pseudo - convergent , and not convergent .",
    "pseudo - convergent refers to a case where the norm of the true residual vector reaches its lower bound , while the norm of the recursive residual vector continues to decrease . in this case ,",
    "an approximate solution with a desired accuracy is not expected to be obtained even if the iteration proceeds .        as shown in the left side of the figure , the shifted ilu(0 ) made only 148 matrices converge where @xmath47 .",
    "the number of convergent cases increased up to 181 as @xmath48 increased until @xmath49 .",
    "hence , the results clearly show the effects of using shift parameters . however , when @xmath48 increased beyond 0.3 , this tendency reversed itself , decreasing the number of convergent cases monotonically .",
    "thus , @xmath50 is the optimum value for this collection of matrices .",
    "next , we look at the results of the shifted a@xmath0ilu(0 ) .",
    "overall , any reduction in the number of convergent cases compared to the shifted ilu(0 ) is not found for any value of @xmath48 .",
    "when @xmath51 or above , there is a significant increase , avoiding the reduction in the number of convergent cases with an increase of the value of @xmath48 .",
    "hence , the use of auto - acceleration keeps or enhances the robustness of shifted ilu(0 ) preconditioning against the variety of coefficient matrices .      in this subsection",
    "we further analyze the effects of auto - acceleration , not only on the types of convergence but also the speed of convergence . in the discussion",
    "below , we evaluate the computing time by using the number of iterations because we found that the computing cost of auto - acceleration can be ignorable for the total cost ( no more than 1 @xmath52 for @xmath53 ) .",
    "we have divided the increase ratio of the number of iterations into several classes and show the number of matrices in each of these classes in figures [ fig : convergencerate0.2 ] and [ fig : convergencerate0.5 ] . here , the increase ratio is defined as @xmath54 , where @xmath55 and @xmath56 are the number of iterations obtained in shifted a@xmath0ilu(0 ) and shifted ilu(0 ) , respectively .",
    "figure [ fig : convergencerate0.2 ] shows the results when the shift parameter is @xmath57 , while figure [ fig : convergencerate0.5 ] shows the results at @xmath58 .",
    "we assigned the ratio of below @xmath5950% to a problem that converges by shifted a@xmath0ilu(0 ) but not by shifted ilu(0 ) .",
    "the inverse case was indicated by above @xmath6050% .",
    "there is no change if both methods obtained convergence by the same number of iterations or if neither of them produced convergence .    ) . ]    ) . ]",
    "figure [ fig : convergencerate0.2 ] shows that when shift parameter @xmath48 is 0.2 , the number of solutions whose convergence rate improves by auto - acceleration is 123 ( below @xmath5950% and @xmath5950% ",
    "0% ) , which is 56.7% overall .",
    "meanwhile , the convergence rate remained the same for 69 solutions ( no change ) , or 31.8% of the total number .",
    "the number of solutions whose convergence rate got worse was only 25 ( 0%  @xmath6050% and above @xmath6050% ) , which is 11.5% of the total number .",
    "the application of the auto - acceleration resulted in many more merits than demerits in convergence rate as well as robustness .",
    "further , figure [ fig : convergencerate0.5 ] shows that at shift parameter @xmath58 , the percentage in which the convergence rate is improved by the application of auto - acceleration increases to 70.5% , while the convergence rate did not change in 22.6% and got worse in 6.9% ( both of these numbers dropped here ) .",
    "hence , we conclude that the auto - acceleration more clearly shows its effectiveness with a larger shift parameter value @xmath48 .      in subsections 4.2.1 and 4.2.2 , we demonstrated the effectiveness of auto - acceleration on the robustness over the variety of general sparse matrices from the standpoint of performance . in this subsection , we further show the effectiveness of auto - acceleration on the robustness over the shift parameter values from the standpoint of applicability .",
    "specifically , we address the selection of the shift parameter , a major practical challenge in shifted ilu(0 ) , by studying what effects the auto - acceleration has on parameter selection and verifying the practicality of shifted a@xmath0ilu(0 ) . to help us understand this ,",
    "we show in figure [ fig : cfd2 ] the calculation results for the sample matrix rothberg / cfd2 .",
    "the horizontal axis represents the shift parameter while the vertical axis represents the number of iterations .",
    "there are two main effects of using a shift parameter in shifted ilu preconditioning .",
    "one is the positive effect of helping the convergence of solutions that would otherwise not converge .",
    "figure [ fig : cfd2 ] shows this effect when @xmath61 .",
    "the other is the negative effect of gradually reducing the convergence rate .",
    "this is shown by the increase of the number of iterations when @xmath48 exceeds 0.1 .",
    "because of these two opposing effects , the responsiveness of shifted ilu(0 ) to the shift parameter value is quite sensitive .",
    "in contrast , with shifted a@xmath0ilu(0 ) preconditioning , only the latter effect , namely , the negative effect of reduced convergence rate when @xmath48 exceeds 0.1 , is kept low .",
    "so the robustness of shifted a@xmath0ilu(0 ) against the shift parameter value is improved .",
    "we examine this point below .",
    "the positive effect of the shift parameter exists for the following reason . in ilu preconditioning , the convergence is significantly degraded if , during ilu factorization , a tiny entry appears in diagonal matrix @xmath20 .",
    "shifted ilu avoids this problem by enlarging the diagonal entries of the matrix being ilu factorized . as a result , linear systems",
    "whose solutions are not supposed to converge can have convergent solutions .",
    "the drastic increase , seen in figure [ fig : convergencedetermination ] , in the number of convergent cases for @xmath47 ",
    "@xmath62 is thought to be caused by this effect .",
    "on the other hand , the auto - acceleration process does not change the sign of each entry of diagonal matrix @xmath20 ( even though it scales the matrix ) and so does not prevent this effect .",
    "therefore , shifted a@xmath0ilu(0 ) has proved as effective as shifted ilu(0 ) , a fact revealed by figures [ fig : cfd2 ] and [ fig : convergencedetermination ] .",
    "next , the negative effect of the shift parameter exists for the following reason . in shifted ilu ,",
    "the larger the parameter is , the farther the matrix being ilu factorized becomes from coefficient matrix @xmath3 .",
    "this reduces the accuracy of the preconditioning matrix , causing the convergence rate to decrease .",
    "the decrease in the number of convergent cases when @xmath48 is 0.3 or greater , shown in figure [ fig : convergencedetermination ] , is thought to be caused by this effect .",
    "on the other hand , the auto - acceleration process improves this accuracy of the preconditioning matrix by the acceleration parameters , reducing this negative effect .",
    "in particular , because the acceleration parameters are automatically optimized in accordance with the remainder matrix , this effect becomes more pronounced as the shift parameter increases .",
    "this fact is supported by the results of figures [ fig : convergencerate0.2 ] and [ fig : convergencerate0.5 ] that the larger the value of @xmath48 , the higher the percentage where the convergence rate improved .",
    "consequently , as figures [ fig : cfd2 ] and [ fig : convergencedetermination ] show , shifted a@xmath0ilu(0 ) maintains high performance even when the shift parameter takes larger values than the optimum one .",
    "for these reasons , we conclude that the auto - acceleration cancels only the negative effect of the shift parameter while smoothing out the responsiveness to shift parameter increases .    with this stated",
    ", we consider the practicality of shifted ilu(0 ) and shifted a@xmath0ilu(0 ) .",
    "shifted ilu is often used to avoid the breakdown caused by tiny diagonal elements .",
    "as described above , a user needs to find the minimum value of @xmath48 that avoids the breakdown . to do this ,",
    "shifted ilu(0 ) requests a user to perform a line search along the value of @xmath48 , in which one should check whether the breakdown is occurs at each point on the line .",
    "this brute force optimization consumes obviously extremely huge computational cost . shifted a@xmath0ilu(0 ) is expected to request no such brute force optimization of @xmath48 because a@xmath0 inhibits the negative effects .",
    "therefore , shifted a@xmath0ilu(0 ) tremendously improves the practicality of shifted ilu(0 ) .",
    "in this paper we have proposed a@xmath0ilu preconditioning , which improves performance without losing the practicality of ilu preconditioning .",
    "preconditioning is a process in which new acceleration parameters are incorporated in ilu preconditioning and these parameters are automatically optimized .",
    "previous ilu - based methods all have practicality issues because their own parameters must be set up by users .",
    "in contrast , a@xmath0ilu(0 ) preconditioning is highly practical because , like ilu(0 ) preconditioning , it is a parameter - free method for users .",
    "we verified the following merits of a@xmath0ilu(0 ) preconditioning by using systems of linear equations arising from physical simulations based on rectangular grids :    * for five sample problems with the coefficient matrices of hundred - thousands dimension , a@xmath0ilu(0 ) preconditioning is 1.65 times as fast as ilu(0 ) preconditioning on average . even compared with other ilu - based methods in which their original parameters are optimized manually , this speed is still higher .",
    "we concluded that a@xmath0ilu(0 ) is superior to the previous ilu - based methods with respect to both practicality and performance . *",
    "its scalability relative to the size of the coefficient matrix is superior to ilu(0 ) preconditioning .",
    "it is concluded that the number of iterations is @xmath63 which is less than @xmath64 for ilu(0 ) , where @xmath65 denotes the mesh size .",
    "once the matrix size exceeds 260 million , its speed exceeds 3.5 times that of ilu(0 ) preconditioning .",
    "furthermore , the proposed auto - acceleration was applied to previous major ilu - based methods with the following confirmed merits :    * for shifted ilu(0 ) , modified ilu(0 ) , and fill - in level ilu , regardless of the value of the parameter unique to these methods , the performance improves . * for crout ilu",
    ", the performance improves even in the case when a denser preconditioned matrix is generated and therefore the original crout ilu shows good performance . * for shifted ilu(0 ) and modified ilu(0 ) , because the performance is stable with respect to any change in the unique parameter , the burden of setting up the parameter is reduced so that its practicality is improved .    for general sparse matrices ,",
    "we have shown the effectiveness of shifted a@xmath0ilu(0 ) .",
    "we evaluated the performance of shifted a@xmath0ilu(0 ) preconditioning using over 200 general sparse matrices obtained from the university of florida sparse matrix collection .",
    "the results confirmed the following merits :    * there is no reduction in the number of convergent cases compared with shifted ilu(0 ) preconditioning over all the shift parameters examined in this paper .",
    "in addition , when the shift parameter is beyond 0.3 , auto - acceleration increased the number of convergent cases of shifted ilu(0 ) . *",
    "many more cases improve the convergence rate , rather than worsen , compared with shifted ilu(0 ) preconditioning . *",
    "even if the value of the shift parameter is raised to ensure convergence , the convergence rate does not drop significantly , unlike shifted ilu(0 ) preconditioning . hence , this method is able to maintain both safety and performance and is thus more practical .",
    "the authors would like to thank anonymous reviewers for their insightful comments and encouragement ."
  ],
  "abstract_text": [
    "<S> the ilu - based preconditioning methods in previous work have their own parameters to improve their performances . </S>",
    "<S> although the parameters may degrade the performance , their determination is left to users . </S>",
    "<S> thus , these previous methods are not reliable in practical computer - aided engineering use . </S>",
    "<S> this paper proposes a novel ilu - based preconditioner called the auto - accelerated ilu , or a@xmath0ilu . in order to improve the convergence , a@xmath0ilu introduces acceleration parameters which modify the ilu factorized preconditioning matrix . </S>",
    "<S> a@xmath0ilu needs no more operations than the original ilu because the acceleration parameters are optimized automatically by a@xmath0ilu itself . </S>",
    "<S> numerical tests reveal the performance of a@xmath0ilu is superior to previous ilu - based methods with manually optimized parameters . </S>",
    "<S> the numerical tests also demonstrate the ability to apply auto - acceleration to ilu - based methods to improve their performances and robustness of parameter sensitivities . </S>"
  ]
}